{"cell_type":{"904aba48":"code","66daadac":"code","13c4bf33":"code","09278be5":"code","7f58773d":"code","d0d0c99b":"code","5621bbcc":"code","827fc2c8":"code","e32af732":"code","c892f7bb":"code","3857a9b2":"code","7aa5f50c":"code","1a82ac22":"code","488ba312":"code","30aa3300":"code","8163780b":"code","f081c878":"code","d5897067":"code","739fdd5d":"code","424de660":"code","48ef8ac3":"code","54134159":"code","5e443c09":"code","bfb16d60":"code","5278f86e":"code","a6a9c017":"markdown","1acb4a2c":"markdown","6b3cf163":"markdown","fa5a8806":"markdown","a0dfec9c":"markdown","360cba45":"markdown","efbe2e4e":"markdown","14b9cbd9":"markdown","00675376":"markdown","72a545cc":"markdown","7f1f921f":"markdown","00e8a9a8":"markdown","fcfaf292":"markdown","93ed9eb3":"markdown","633957aa":"markdown","4c554d0c":"markdown","99d7a98a":"markdown"},"source":{"904aba48":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nfrom scipy.stats import pearsonr","66daadac":"!pip install vaderSentiment","13c4bf33":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nimport re\nfrom wordcloud import WordCloud","09278be5":"df = pd.read_csv(\"..\/input\/all-of-trumps-tweets-20092020\/trump_tweets.csv\")","7f58773d":"df.head()","d0d0c99b":"%%time\n\nSIA = SentimentIntensityAnalyzer()\n\nsentiment = []\nfor i in range(len(df)):\n    sentiment.append(SIA.polarity_scores(df.loc[i]['text'])['compound'])\n    \ndf['sentiment'] = sentiment","5621bbcc":"def month_rounder(t):\n    return (t.replace(month=t.month, day=1, hour=0, second=0, microsecond=0, minute=0))\n\nmonth = []\nfor i in range(len(df)):\n    month.append(month_rounder(datetime.strptime(df['date'][i], '%m\/%d\/%Y %H:%M')))\n    \ndf['month'] = month","827fc2c8":"df.groupby('month').mean().reset_index().plot(x=\"month\", y=\"sentiment\", figsize=(16, 9))\nplt.axvline(datetime(2015, 6, 15), color='yellow', linewidth=2)\nplt.axvline(datetime(2017, 1, 20), color='green', linewidth=2)\nplt.axvline(datetime(2020, 1, 15), color='black', linewidth=2)\nplt.axvline(datetime(2020, 11, 7), color='red', linewidth=2)\nplt.xlim(df['month'][0], df['month'][len(df)-1])\nplt.ylim(-1, 1)\nplt.axhline(0, linestyle='--')\nplt.legend(['Sentiment per Month', 'Trump Announces Presidential Campaign', 'Trump Inaguration Speech', 'COVID Starts in US', 'Biden is Elected'], prop={'size': 12})\nplt.title(\"Average Sentiment of Trump's Tweets Per Month\", fontsize=20)\nplt.xlabel(\"\")\nplt.ylabel(\"Number of Tweets\", fontsize=14)\nplt.show()","e32af732":"px.scatter(df, x=\"favorites\", y=\"sentiment\", title=\"Number of Likes vs Sentiment Interactive Graph\")","c892f7bb":"px.scatter(df, x=\"retweets\", y=\"sentiment\", title=\"Number of Retweets vs Sentiment Interactive Graph\")","3857a9b2":"stop_words = set(stopwords.words('english'))\ntable = str.maketrans('', '', string.punctuation)\nlemmatizer = WordNetLemmatizer()\n\ndef clean(text):\n    text = re.sub(r\"www\\S+\", '', str(text), flags=re.MULTILINE) #filters out links\n    text = re.sub(r\"http\\S+\", '', str(text), flags=re.MULTILINE) #filters out links\n    tokens = word_tokenize(text) #split into words\n    tokens = [w.lower() for w in tokens] #make everything lowercase\n    stripped = [w.translate(table) for w in tokens] #get rid of punctuation\n    words = [word for word in stripped if word.isalpha()] #idk\n    words = [w for w in words if not w in stop_words] #get rid of stop words like \"no\"\n    lemma = [lemmatizer.lemmatize(word, 'v') for word in words] #lemmatization\/stemming\n    return lemma","7aa5f50c":"%%time\n\nblacklisted_words = ['realdonaldtrump', 'rt', 'amp', 'nt']\nwords_dict = {}\n\nfor i in range(len(df)):\n    curr_tweet = clean(df.loc[i]['text'])\n    for word in curr_tweet:\n        if word in blacklisted_words:\n            continue\n        if word in words_dict:\n            words_dict[word] += 1\n        else:\n            words_dict[word] = 1","1a82ac22":"sorted_dict = dict(sorted(words_dict.items(), key=lambda item: item[1], reverse=True))\nwords_df = pd.DataFrame.from_dict(sorted_dict, orient='index', columns=['count']).reset_index()\nwords_df[:30]","488ba312":"px.bar(words_df[:30], x=\"index\", y=\"count\", title=\"Trump's Top 30 Most Tweeted Words\")","30aa3300":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white')\nwordcloud.generate_from_frequencies(words_dict)\nplt.figure(figsize=(10, 10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","8163780b":"def day_rounder(t):\n    return (t.replace(day=t.day, hour=0, second=0, microsecond=0, minute=0))\n\ndef hour_rounder(t):\n    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour)\n               +timedelta(hours=t.minute\/\/30))\n\nday = []\nfor i in range(len(df)):\n    day.append(day_rounder(datetime.strptime(df['date'][i], '%m\/%d\/%Y %H:%M')))\n\nhour = []\nfor i in range(len(df)):\n    hour.append(hour_rounder(datetime.strptime(df['date'][i], '%m\/%d\/%Y %H:%M')))\n    \ndf['day'] = day\ndf['hour'] = hour","f081c878":"day_df = pd.DataFrame(df.groupby('day').size(), columns=['count']).reset_index()\nday_df","d5897067":"hour_df = pd.DataFrame(df.groupby('hour').size(), columns=['count']).reset_index()\nhour_df","739fdd5d":"df.groupby('day').size().plot(figsize=(16, 9))\nplt.axvline(datetime(2015, 6, 15), color='yellow', linewidth=3)\nplt.axvline(datetime(2017, 1, 20), color='green', linewidth=3)\nplt.axvline(datetime(2020, 1, 15), color='black', linewidth=3)\nplt.axvline(datetime(2020, 11, 7), color='red', linewidth=3)\nplt.annotate(\"Average Tweets: %.3f\" % day_df.loc[day_df['day'] < datetime(2015, 6, 15)]['count'].mean(), (datetime(2011, 6, 1), 110), fontsize=10)\nplt.annotate(\"Average Tweets: %.3f\" % day_df.loc[(datetime(2015, 6, 15) <= day_df['day']) & (day_df['day'] < datetime(2017, 1, 20))]['count'].mean(), (datetime(2015, 6, 30), 110), fontsize=10)\nplt.annotate(\"Average Tweets: %.3f\" % day_df.loc[(datetime(2017, 1, 20) <= day_df['day']) & (day_df['day'] < datetime(2020, 1, 15))]['count'].mean(), (datetime(2017, 11, 1), 110), fontsize=10)\nplt.annotate(\"%.3f\" % day_df.loc[(datetime(2020, 1, 15) <= day_df['day']) & (day_df['day'] < datetime(2020, 11, 7))]['count'].mean(), (datetime(2020, 2, 1), 160), fontsize=17)\nplt.xlim(df['day'][0], df['day'][len(df)-1])\nplt.legend(['Number of Tweets per Day', 'Trump Announces Presidential Campaign', 'Trump Inaguration Speech', 'COVID Starts in US', 'Biden is Elected'], prop={'size': 12})\nplt.title(\"Trump's Tweeting Per Day\", fontsize=20)\nplt.xlabel(\"\")\nplt.ylabel(\"Number of Tweets\", fontsize=14)\nplt.show()","424de660":"df.groupby('hour').size().plot(figsize=(16, 9))\nplt.axvline(datetime(2015, 6, 15), color='yellow', linewidth=3)\nplt.axvline(datetime(2017, 1, 20), color='green', linewidth=3)\nplt.axvline(datetime(2020, 1, 15), color='black', linewidth=3)\nplt.axvline(datetime(2020, 11, 7), color='red', linewidth=3)\nplt.xlim(df['day'][0], df['day'][len(df)-1])\nplt.legend(['Number of Tweets per Hour', 'Trump Announces Presidential Campaign', 'Trump Inaguration Speech', 'COVID Starts in US', 'Biden is Elected'], prop={'size': 12})\nplt.title(\"Trump's Tweeting Per Hour\", fontsize=20)\nplt.xlabel(\"\")\nplt.ylabel(\"Number of Tweets\", fontsize=14)\nplt.show()","48ef8ac3":"fig = go.Figure()\npx.line(day_df, x = \"day\", y = \"count\", title=\"Trump's Tweeting Per Hour Interactive Graph\")","54134159":"px.line(hour_df, x = \"hour\", y = \"count\", title=\"Trump's Tweeting Per Day Interactive Graph\")","5e443c09":"most_tweets_hour = df.groupby('hour').size().sort_values(ascending=False).reset_index()['hour'][0] # 122 tweets in this hour!\ndf.loc[df['hour'] == most_tweets_hour]","bfb16d60":"fig = go.Figure()\npx.scatter(df, x=\"retweets\", y=\"favorites\", title=\"Retweets vs Favorites Interactive Scatter Plot, Correlation Coefficient: %.3f\" % pearsonr(df['retweets'], df['favorites'])[0])","5278f86e":"df.sort_values('favorites', ascending=False)['text'].iloc[0]","a6a9c017":"# Trump's Most Favorited & Retweeted Tweet","1acb4a2c":"Of course, he tweets ```great``` the most...","6b3cf163":"# Sentiment Analysis!!\n\nDefinitely everyone's favorite when it comes to tweets. Here's a loose template which you can use as a foundation for your own sentiment analysis.","fa5a8806":"# Some Additional Interactive Graphs in Plotly","a0dfec9c":"# Quick EDA on All of Trump's Tweets\n\nThis is a notebook I quickly created as an introduction for analyzing <a href=\"https:\/\/www.kaggle.com\/ironicninja\/all-of-trumps-tweets-20092020\"> my dataset <\/a> which includes all of Trump's tweets from 2009 to 2020. If you think this notebook is a valuable resource, please upvote! I would greatly appreciate it.","360cba45":"President Trump really pulled off a \"tweetstorm\" at 12PM on June 5, 2020, with an absurd 122 tweets in just one hour! Most of his tweets look like retweets, but still retweeting once every 15 seconds is quite impressive. <a href=\"https:\/\/deadline.com\/2020\/06\/president-donald-trump-tweetstorm-the-saturday-edition-76-1202952754\/\"> News article describing a bit more in-depth this phenomenon <\/a>","efbe2e4e":"# Most Tweeted Hour","14b9cbd9":"# Essential NLP Imports","00675376":"# Trump's Tweeting Per Hour\/Day\n\nHow much does Trump like to tweet? Did he start tweeting more after becoming the President?","72a545cc":"# Reading the Data","7f1f921f":"The below code generates a wordcloud! Keep in mind that each iteration generates the word cloud a bit differently, so if you find one that you like, make sure to save it!","00e8a9a8":"Well then...","fcfaf292":"# Likes vs Retweets","93ed9eb3":"I hope this notebook has served as a valuable introduction to what you can do with Trump's tweets and just tweets in general. There's still alot out there to explore. Good luck and have fun!","633957aa":"President Trump clearly used the additional time COVID\/quarantine provided him to tweet even more, averaging an absurd 35 tweets a day!","4c554d0c":"# What Words does Trump like to Tweet...\n\nIs his most tweeted word America? Maybe great? Maybe liberals? Well, you'll just have to see...","99d7a98a":"# Essential General Imports"}}