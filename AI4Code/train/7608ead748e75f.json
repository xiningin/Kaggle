{"cell_type":{"9426735f":"code","be23bb68":"code","a2383772":"code","690c11aa":"code","0d988be0":"code","8684fcb9":"code","01bd7953":"code","6e2d8f50":"code","b91f73a9":"code","a00f0de1":"code","68644bb4":"code","11424d60":"code","77ae4db8":"code","107bfc11":"code","b13e3136":"code","903772a5":"code","796ad4cf":"code","14303ccb":"code","bc1535f5":"code","ec1cc936":"code","5184d712":"code","f7c5d6f0":"code","fd97ed7f":"code","9922afaa":"code","62e01b89":"code","d4a57071":"code","0a06ec2b":"code","cbf2ada7":"code","d5ef0b24":"code","31e701b7":"code","f8975f38":"code","7774f29e":"code","9305ee04":"code","be56c9ac":"code","81ad138f":"code","db5d2903":"code","cc2165cd":"code","ea1a652b":"code","62767085":"code","683e6046":"code","26def9f3":"code","be44104d":"code","cefd0bb2":"code","01662de0":"code","cb8398a7":"code","54735f1f":"code","5fccffd4":"code","5ccdb2ef":"code","18b2d512":"code","3eff2dbb":"code","08e0d73a":"code","139693b9":"code","e5cc1b1f":"code","9fc461e6":"markdown","fc8550b9":"markdown","1f906c6b":"markdown","7c2d1d42":"markdown","13208977":"markdown","c1cf5884":"markdown","8f2e5812":"markdown","0c5bf08f":"markdown","be208af6":"markdown","c81896ad":"markdown","e13a5f18":"markdown","2d2d304f":"markdown","8fe69dec":"markdown","d5b4185c":"markdown","4fa5b127":"markdown","9b58cbe7":"markdown","d2d870cf":"markdown","802f587d":"markdown","fc96938c":"markdown","46ba7970":"markdown","233aee2c":"markdown","02832767":"markdown","3c4d4bdd":"markdown","cd9086a1":"markdown","a2db8233":"markdown","fe4adb88":"markdown","dae68ae6":"markdown","96d0af43":"markdown","ace0ca3d":"markdown","dafc798e":"markdown","b810d177":"markdown","fbfb723e":"markdown","fb72ef49":"markdown","0fe043d5":"markdown","bb2f2f59":"markdown","dfe6fd2c":"markdown","9de11655":"markdown","1a6211bb":"markdown"},"source":{"9426735f":"import torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n    !nvidia-smi\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","be23bb68":"!pip install transformers==4.12.2\n!pip install farasapy==0.0.14\n!pip install pyarabic==0.6.14\n!git clone https:\/\/github.com\/aub-mind\/arabert\n!pip install emoji==1.6.1\n!pip install sentencepiece==0.1.96","a2383772":"!git clone https:\/\/github.com\/elnagara\/HARD-Arabic-Dataset\n!git clone https:\/\/github.com\/mahmoudnabil\/ASTD\n!git clone https:\/\/github.com\/nora-twairesh\/AraSenti\n!git clone https:\/\/github.com\/mohamedadaly\/LABR\n!wget http:\/\/homepages.inf.ed.ac.uk\/wmagdy\/Resources\/ArSAS.zip\n!unzip ArSAS.zip\n!unrar x '\/content\/HARD-Arabic-Dataset\/data\/unbalanced-reviews.rar'\n!unzip '\/content\/HARD-Arabic-Dataset\/data\/balanced-reviews.zip'","690c11aa":"import pandas as pd\nimport numpy as np\nfrom typing import List\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split","0d988be0":"class CustomDataset:\n    def __init__(\n        self,\n        name: str,\n        train: List[pd.DataFrame],\n        test: List[pd.DataFrame],\n        label_list: List[str],\n    ):\n        \"\"\"Class to hold and structure datasets.\n\n        Args:\n\n        name (str): holds the name of the dataset so we can select it later\n        train (List[pd.DataFrame]): holds training pandas dataframe with 2 columns [\"text\",\"label\"]\n        test (List[pd.DataFrame]): holds testing pandas dataframe with 2 columns [\"text\",\"label\"]\n        label_list (List[str]): holds the list  of labels\n        \"\"\"\n        self.name = name\n        self.train = train\n        self.test = test\n        self.label_list = label_list","8684fcb9":"# This will hold all the downloaded and structred datasets\nall_datasets= []\nDATA_COLUMN = \"text\"\nLABEL_COLUMN = \"label\"","01bd7953":"df_HARD = pd.read_csv(\"\/content\/balanced-reviews.txt\", sep=\"\\t\", header=0,encoding='utf-16')\n\ndf_HARD = df_HARD[[\"review\",\"rating\"]]  # we are interested in rating and review only\ndf_HARD.columns = [DATA_COLUMN, LABEL_COLUMN]\nprint(df_HARD[LABEL_COLUMN].value_counts())\n# code rating as +ve if > 3, -ve if less, no 3s in dataset\n\nhard_map = {\n    5: 'POS',\n    4: 'POS',\n    2: 'NEG',\n    1: 'NEG'\n}\n\ndf_HARD[LABEL_COLUMN] = df_HARD[LABEL_COLUMN].apply(lambda x: hard_map[x])\ntrain_HARD, test_HARD = train_test_split(df_HARD, test_size=0.2, random_state=42)\nlabel_list_HARD = ['NEG', 'POS']\n\ndata_Hard = CustomDataset(\"HARD\", train_HARD, test_HARD, label_list_HARD)\nall_datasets.append(data_Hard)","6e2d8f50":"df_ASTD_UN = pd.read_csv(\n    \"\/content\/ASTD\/data\/Tweets.txt\", sep=\"\\t\", header=None\n)\n\ndf_ASTD_UN.columns = [DATA_COLUMN, LABEL_COLUMN]\n\ndf_ASTD_UN = df_ASTD_UN[df_ASTD_UN[LABEL_COLUMN]!= 'OBJ']\n\ntrain_ASTD_UN, test_ASTD_UN = train_test_split(\n    df_ASTD_UN, test_size=0.2, random_state=42\n)\n\nlabel_list_ASTD_UN = list(df_ASTD_UN[LABEL_COLUMN].unique())\nprint(label_list_ASTD_UN)\nprint(df_ASTD_UN[LABEL_COLUMN].value_counts())\n\ndata_ASTD_UN = CustomDataset(\n    \"ASTD-Unbalanced\", train_ASTD_UN, test_ASTD_UN, label_list_ASTD_UN\n)\n\nall_datasets.append(data_ASTD_UN)","b91f73a9":"df_ASTD_B = pd.read_csv(\n    \"\/content\/drive\/My Drive\/Datasets\/Dahou\/data_csv_balanced\/ASTD-balanced-not-linked.csv\",\n    sep=\",\",\n    header=0,\n)\n\ndf_ASTD_B.columns = [DATA_COLUMN, LABEL_COLUMN]\n\ndf_ASTD_B[LABEL_COLUMN] = df_ASTD_B[LABEL_COLUMN].apply(lambda x: 'NEG' if (x == -1) else 'POS')\n\ntrain_ASTD_B, test_ASTD_B = train_test_split(df_ASTD_B, test_size=0.2, random_state=42)\nlabel_list_ASTD_B = list(df_ASTD_B[LABEL_COLUMN].unique())\n\ndata_ASTD_B = CustomDataset(\n    \"ASTD-Dahou-Balanced\", train_ASTD_B, test_ASTD_B, label_list_ASTD_B\n)\nall_datasets.append(data_ASTD_B)","a00f0de1":"# df_ArSenTD = pd.read_csv(\n#     \"\/content\/drive\/MyDrive\/Datasets\/ArSenTD-LEV\/ArSenTD-LEV.tsv\", sep=\"\\t\", header=0\n# )\n\n# df_ArSenTD = df_ArSenTD[['Tweet','Sentiment']]\n\n# df_ArSenTD.columns = [DATA_COLUMN, LABEL_COLUMN]\n\n# print(df_ArSenTD[LABEL_COLUMN].value_counts())\n# label_list_ArSenTD = list(df_ArSenTD[LABEL_COLUMN].unique())\n\n# train_ArSenTD, test_ArSenTD = train_test_split(\n#     df_ArSenTD, test_size=0.2, random_state=42\n# )\n\n# data_ArSenTD = CustomDataset(\"ArSenTD-LEV\", train_ArSenTD, test_ArSenTD, label_list_ArSenTD)\n# all_datasets.append(data_ArSenTD)","68644bb4":"df_AJGT = pd.read_excel(\"\/content\/drive\/My Drive\/Datasets\/Ajgt\/AJGT.xlsx\", header=0)\n\ndf_AJGT = df_AJGT[[\"Feed\", \"Sentiment\"]]\ndf_AJGT.columns = [DATA_COLUMN, LABEL_COLUMN]\n\n\n\ntrain_AJGT, test_AJGT = train_test_split(df_AJGT, test_size=0.2, random_state=42)\n\nprint(df_AJGT[LABEL_COLUMN].value_counts())\nlabel_list_AJGT = list(df_AJGT[LABEL_COLUMN].unique())\n\ndata_AJGT = CustomDataset(\"AJGT\", train_AJGT, test_AJGT, label_list_AJGT)\nall_datasets.append(data_AJGT)","11424d60":"#@title\n%%writefile labr.py\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Mar 10 16:27:03 2013\n\n@author: Mohamed Aly <mohamed@mohamedaly.info>\n\"\"\"\n\nimport codecs\nimport numpy as np\nimport pandas as pd\nimport re\n\nclass LABR:\n    def __init__(self):\n        self.REVIEWS_PATH = \"LABR\/data\/\"\n        self.RAW_REVIEWS_FILE = \"raw_reviews.tsv\"\n        self.DELETED_REVIEWS_FILE = \"deleted_reviews.tsv\"\n        self.CLEAN_REVIEWS_FILE = \"reviews.tsv\"\n\n    # Copied from the PyArabic package.\n    def arabicrange(self):\n        \"\"\"return a list of arabic characteres .\n        Return a list of characteres between \\u060c to \\u0652\n        @return: list of arabic characteres.\n        @rtype: unicode;\n        \"\"\"\n        mylist=[];\n        for i in range(0x0600, 0x00653):\n            try :\n                mylist.append(unichr(i));\n            except ValueError:\n                pass;\n        return mylist;\n\n    # cleans a single review\n    def clean_raw_review(self, body):\n         # patterns to remove first\n        pat = [\\\n            (u'http[s]?:\/\/[a-zA-Z0-9_\\-.\/~\\?=%&]+', u''),               # remove links\n            (u'www[a-zA-Z0-9_\\-?=%&\/.~]+', u''),\n#            u'\\n+': u' ',                     # remove newlines\n            (u'<br \/>', u' '),                  # remove html line breaks\n            (u'<\/?[^>]+>', u' '),              # remove html markup\n#            u'http': u'',\n            (u'[a-zA-Z]+\\.org', u''),\n            (u'[a-zA-Z]+\\.com', u''),\n            (u':\/\/', u''),\n            (u'&[^;]+;', u' '),\n            (u':D', u':)'),\n#            (u'[0-9\/]+', u''),\n#            u'[a-zA-Z.]+': u'',\n#            u'[^0-9' + u''.join(self.arabicrange()) + \\\n#                u\"!.,;:$%&*%'#(){}~`\\[\\]\/\\\\\\\\\\\"\" + \\\n#                u'\\s^><\\-_\\u201D\\u00AB=\\u2026]+': u'',          # remove latin characters\n            (u'\\s+', u' '),                     # remove spaces\n            (u'\\.+', u'.'),                     # multiple dots\n            (u'[\\u201C\\u201D]', u'\"'),          #\u201c\n            (u'[\\u2665\\u2764]', u''),           # heart symbol\n            (u'[\\u00BB\\u00AB]', u'\"'),\n            (u'\\u2013', u'-'),                # dash\n        ]\n\n        # patterns that disqualify a review\n        remove_if_there = [\\\n            (u'[^0-9' + u''.join(self.arabicrange()) + \\\n                u\"!.,;:$%&*%'#(){}~`\\[\\]\/\\\\\\\\\\\"\" + \\\n                u'\\s\\^><\\-_\\u201D\\u00AB=\\u2026+|' + \\\n                u'\\u0660-\\u066D\\u201C\\u201D' + \\\n                u'\\ufefb\\ufef7\\ufef5\\ufef9]+', u''),                   # non arabic characters\n        ]\n\n        # patterns that disqualify if empty after removing\n        remove_if_empty_after = [\\\n            (u'[0-9a-zA-Z\\-_]', u' '),             #alpha-numeric\n            (u'[0-9' + u\".,!;:$%&*%'#(){}~`\\[\\]\/\\\\\\\\\\\"\" + \\\n                u'\\s\\^><`\\-=_+]+', u''),                  # remove just punctuation\n            (u'\\s+', u' '),                     # remove spaces\n        ]\n\n        # remove again\n        # patterns to remove\n        pat2 = [\\\n#            u'[^0-9' + u''.join(self.arabicrange()) + \\\n#                u\"!.,;:$%&*%'#(){}~`\\[\\]\/\\\\\\\\\\\"\" + \\\n#                u'\\s^><\\-_\\u201D\\u00AB=\\u2026]+': u'',          # remove latin characters\n        ]\n\n        skip = False\n\n        # if empty body, skip\n        if body == u'': skip = True\n\n        # do some subsitutions\n        for k,v in pat:\n            body = re.sub(k, v, body)\n\n        # remove if exist\n        for k,v in remove_if_there:\n            if re.search(k, body):\n                skip = True\n\n        # remove if empty after replacing\n        for k,v in remove_if_empty_after:\n            temp = re.sub(k, v, body)\n            if temp == u\" \" or temp == u\"\":\n                skip = True\n\n        # do some more subsitutions\n        if not skip:\n            for k,v in pat2:\n                body = re.sub(k, v, body)\n\n        # if empty string, skip\n        if body == u'' or body == u' ':\n            skip = True\n\n        if not skip:\n            return body\n        else:\n            return u\"\"\n\n    # Read raw reviews from file and clean and write into clean_reviews\n    def clean_raw_reviews(self):\n        # input file\n        in_file = codecs.open(self.REVIEWS_PATH + self.RAW_REVIEWS_FILE,\n                              'r', encoding=\"utf-8\")\n        reviews = in_file.readlines()\n\n        # Output file: rating<tab>content\n        out_file = open(self.REVIEWS_PATH + self.CLEAN_REVIEWS_FILE,\n                        'w', buffering = 100)\n        deleted_file = open(self.REVIEWS_PATH + self.DELETED_REVIEWS_FILE,\n                            'w', buffering = 100)\n\n        counter = 1\n        for i in xrange(0, len(reviews)):\n            review = reviews[i]\n            skip = False\n\n#           # If line starts with #, then skip\n#            if review[0] == u\"#\": continue\n\n            # split by <tab>\n            parts = review.split(u\"\\t\")\n\n            # rating is first part and body is last part\n            rating = parts[0]\n            review_id = parts[1]\n            user_id = parts[2]\n            book_id = parts[3]\n            body = parts[4].strip()\n\n            # clean body\n            body = self.clean_raw_review(body)\n            if body == u\"\": skip = True\n\n            if i % 5000 == 0:\n                print(\"review %d:\" % (i))\n\n            # write output\n            line = u\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (rating, review_id, user_id,\n                                              book_id, body)\n            if not skip:\n                out_file.write(line.encode('utf-8'))\n                counter += 1\n            else:\n                deleted_file.write(line.encode('utf-8'))\n\n    # Read the reviews file. Returns a tuple containing these lists:\n    #   rating: the rating 1 -> 5\n    #   review_id: the id of the review\n    #   user_id: the id of the user\n    #   book_id: the id of the book\n    #   body: the text of the review\n    def read_review_file(self, file_name):\n        reviews = codecs.open(file_name, 'r', 'utf-8').readlines()\n\n        # remove comment lines and newlines\n        reviews = [r.strip() for r in reviews if r[0] != u'#']\n\n        # parse\n        rating = list()\n        review_id = list()\n        user_id = list()\n        book_id = list()\n        body = list()\n        for review in reviews:\n            # split by <tab>\n            parts = review.split(u\"\\t\")\n\n            # rating is first part and body is last part\n            rating.append(int(parts[0]))\n            review_id.append(parts[1])\n            user_id.append(parts[2])\n            book_id.append(parts[3])\n            if len(parts) > 4:\n                body.append(parts[4])\n            else:\n                body.append(u\"\")\n\n        return (rating, review_id, user_id, book_id, body)\n\n    # Writes reviews to a file\n    def write_review_file(self, file_name, rating, review_id, user_id,\n                          book_id, body):\n\n        lines = list()\n        # loop\n        for i in xrange(len(rating)):\n            line = u\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (rating[i], review_id[i],\n                                              user_id[i], book_id[i],\n                                              body[i])\n            lines.append(line)\n\n        open(file_name, 'w').write(u''.join(lines).encode('utf-8'))\n\n    def read_clean_reviews(self):\n        return self.read_review_file(self.REVIEWS_PATH +\n                                     self.CLEAN_REVIEWS_FILE)\n\n    def read_raw_reviews(self):\n        return self.read_review_file(self.REVIEWS_PATH + self.RAW_REVIEWS_FILE)\n\n    # Splits the dataset into a training\/test sets in the setting of using 5\n    # classes (predicting the rating value from 1 to 5)\n    def split_train_test_5class(self, rating, percent_test,\n                                balanced = \"unbalanced\"):\n        np.random.seed(1234)\n\n        num_reviews = len(rating)\n        review_ids = np.arange(0, num_reviews)\n\n        if balanced == \"unbalanced\":\n            ntest = np.floor(num_reviews * percent_test)\n            np.random.shuffle(review_ids)\n\n            test_ids = review_ids[:ntest]\n            train_ids = review_ids[ntest:]\n\n        elif balanced == \"balanced\":\n            (sizes, bins) = np.histogram(rating, [1, 2, 3, 4, 5, 6])\n            min_size = np.min(sizes)\n            print(min_size)\n\n            # sample review ids equally among classes\n            test_ids = np.zeros((0,), dtype=\"int32\")\n            train_ids = np.zeros((0,), dtype=\"int32\")\n            rating = np.array(rating)\n            ntest = np.floor(min_size * percent_test)\n            for c in range(1, 6):\n                cids = review_ids[np.nonzero(rating == c)]\n                np.random.shuffle(cids)\n\n                test_ids = np.r_[test_ids, cids[:ntest]]\n                train_ids = np.r_[train_ids, cids[ntest:min_size]]\n\n        train_file = self.REVIEWS_PATH + \"5class-\" + balanced+ \"-train.txt\"\n        test_file = self.REVIEWS_PATH + \"5class-\" + balanced+ \"-test.txt\"\n\n        open(train_file, 'w').write('\\n'.join(map(str, train_ids)))\n        open(test_file, 'w').write('\\n'.join(map(str, test_ids)))\n\n        return (train_ids, test_ids)\n\n    # Splits the dataset into a training\/test sets in the setting of using 2\n    # classes (predicting the polarity of the review where ratings 1 & 2\n    # are considered negative, ratings 4 & 5 are positive, and rating 3 is\n    # ignored)\n    def split_train_test_2class(self, rating, percent_test,\n                                balanced = \"unbalanced\"):\n        np.random.seed(1234)\n\n        rating = np.array(rating, dtype='int32')\n        # length\n        num_reviews = len(rating)\n        review_ids = np.arange(0, num_reviews)\n\n        # convert to binary, with ratings [1, 2] --> neg and [4, 5] --> pos\n        rating[rating == 2] = 1\n        rating[rating == 4] = 5\n\n        ids = (rating == 1) + (rating == 5)\n        review_ids = review_ids[ids]\n        rating = rating[ids]\n        rating[rating == 1] = 0\n        rating[rating == 5] = 1\n\n        # get length after filtering\n        num_reviews = rating.shape[0]\n\n        if balanced == \"unbalanced\":\n            ntest = np.floor(num_reviews * percent_test)\n            np.random.shuffle(review_ids)\n\n            test_ids = review_ids[:ntest]\n            train_ids = review_ids[ntest:]\n\n        elif balanced == \"balanced\":\n            (sizes, bins) = np.histogram(rating, [0, 1, 2])\n            min_size = np.min(sizes)\n            print(min_size)\n\n            # sample review ids equally among classes\n            test_ids = np.zeros((0,), dtype=\"int32\")\n            train_ids = np.zeros((0,), dtype=\"int32\")\n            rating = np.array(rating)\n            ntest = np.floor(min_size * percent_test)\n            for c in [0, 1]:\n                cids = review_ids[np.nonzero(rating == c)]\n                np.random.shuffle(cids)\n\n                test_ids = np.r_[test_ids, cids[:ntest]]\n                train_ids = np.r_[train_ids, cids[ntest:min_size]]\n\n        train_file = self.REVIEWS_PATH + \"2class-\" + balanced+ \"-train.txt\"\n        test_file = self.REVIEWS_PATH + \"2class-\" + balanced+ \"-test.txt\"\n\n        open(train_file, 'w').write('\\n'.join(map(str, train_ids)))\n        open(test_file, 'w').write('\\n'.join(map(str, test_ids)))\n\n        return (train_ids, test_ids)\n\n    # Reads a training or test file. The file contains the indices of the\n    # reviews from the clean reviews file.\n    def read_train_test_file(self, file_name):\n        ins = open(file_name).readlines()\n        ins = [int(i.strip()) for i in ins]\n\n        return ins\n\n    # A helpter function.\n    def set_binary_klass(self, ar):\n        ar[(ar == 1) + (ar == 2)] = 0\n        ar[(ar == 4) + (ar == 5)] = 1\n\n    # Returns (train_x, train_y, test_x, test_y)\n    # where x is the review body and y is the rating (1->5 or 0->1)\n    def get_train_test(self, klass = \"2\", balanced = \"balanced\"):\n        (rating, a, b, c, body) = self.read_clean_reviews()\n        rating = np.array(rating)\n        body = pd.Series(body)\n\n        train_file = (self.REVIEWS_PATH + klass + \"class-\" +\n            balanced+ \"-train.txt\")\n        test_file = (self.REVIEWS_PATH + klass + \"class-\" +\n            balanced+ \"-test.txt\")\n\n        train_ids = self.read_train_test_file(train_file)\n        test_ids = self.read_train_test_file(test_file)\n\n        train_y = rating[train_ids]\n        test_y = rating[test_ids]\n        train_x = body[train_ids]\n        test_x = body[test_ids]\n\n        if klass == \"2\":\n            self.set_binary_klass(train_y)\n            self.set_binary_klass(test_y)\n\n        return (train_x, train_y, test_x, test_y)\n","77ae4db8":"from labr import LABR\n\nlabr_helper = LABR()\n\n(d_train, y_train, d_test, y_test) = labr_helper.get_train_test(\n    klass=\"2\", balanced=\"unbalanced\"\n)\n\ntrain_LABR_B_U = pd.DataFrame({DATA_COLUMN: d_train, LABEL_COLUMN: y_train})\ntest_LABR_B_U = pd.DataFrame({DATA_COLUMN: d_test, LABEL_COLUMN: y_test})\n\ntrain_LABR_B_U[LABEL_COLUMN] = train_LABR_B_U[LABEL_COLUMN].apply(lambda x: 'NEG' if (x == 0) else 'POS')\ntest_LABR_B_U[LABEL_COLUMN] = test_LABR_B_U[LABEL_COLUMN].apply(lambda x: 'NEG' if (x == 0) else 'POS')\n\nprint(train_LABR_B_U[LABEL_COLUMN].value_counts() + test_LABR_B_U[LABEL_COLUMN].value_counts())\nlabel_list_LABR_B_U = list(test_LABR_B_U[LABEL_COLUMN].unique())\n\ndata_LABR_B_U = CustomDataset(\n    \"LABR-UN-Binary\", train_LABR_B_U, test_LABR_B_U, label_list_LABR_B_U\n)\nall_datasets.append(data_LABR_B_U)","107bfc11":"for x in all_datasets:\n  print(x.name) ","b13e3136":"df_ArSAS = pd.read_csv(\"\/content\/ArSAS..txt\", sep=\"\\t\",encoding='utf-8')\ndf_ArSAS = df_ArSAS[[\"Tweet_text\",\"Sentiment_label\"]]  # we are interested in rating and review only\ndf_ArSAS.columns = [DATA_COLUMN, LABEL_COLUMN]\nprint(\"Total length: \", len(df_ArSAS))\nprint(df_ArSAS[LABEL_COLUMN].value_counts())\n\nlabel_list_ArSAS = list(df_ArSAS[LABEL_COLUMN].unique())\nprint(label_list_ArSAS)\n\ntrain_ArSAS, test_ArSAS = train_test_split(df_ArSAS, test_size=0.2, random_state=42)\nprint(\"Training length: \", len(train_ArSAS))\nprint(\"Testing length: \", len(test_ArSAS))\ndata_ArSAS = CustomDataset(\"ArSAS\", train_ArSAS, test_ArSAS, label_list_ArSAS)\nall_datasets.append(data_ArSAS)","903772a5":"import numpy as np\nimport torch\nimport random\nimport matplotlib.pyplot as plt\nimport copy\n\nfrom arabert.preprocess import ArabertPreprocessor\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                             confusion_matrix, f1_score, precision_score,\n                             recall_score)\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import (AutoConfig, AutoModelForSequenceClassification,\n                          AutoTokenizer, BertTokenizer, Trainer,\n                          TrainingArguments)\nfrom transformers.data.processors.utils import InputFeatures","796ad4cf":"for x in all_datasets:\n  print(x.name)","14303ccb":"# select a dataset\ndataset_name = 'ArSAS'\n# select a model from the huggingface modelhub https:\/\/huggingface.co\/models?language=ar\nmodel_name = 'aubmindlab\/bert-base-arabertv02-twitter' # we are going to use the twitter AraBERT since it has emojis and dialects","bc1535f5":"for d in all_datasets:\n  if d.name==dataset_name:\n    selected_dataset = copy.deepcopy(d)\n    print('Dataset found')\n    break","ec1cc936":"arabic_prep = ArabertPreprocessor(model_name)\n\nselected_dataset.train[DATA_COLUMN] = selected_dataset.train[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))\nselected_dataset.test[DATA_COLUMN] = selected_dataset.test[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))  ","5184d712":"# Sanity check on the dataset\nlist(selected_dataset.train[DATA_COLUMN][0:10])","f7c5d6f0":"tok = AutoTokenizer.from_pretrained(model_name)","fd97ed7f":"print(\"Training Sentence Lengths: \")\nplt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.train[DATA_COLUMN].to_list()],bins=range(0,128,2))\nplt.show()\n\nprint(\"Testing Sentence Lengths: \")\nplt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.test[DATA_COLUMN].to_list()],bins=range(0,128,2))\nplt.show()","9922afaa":"max_len = 128","62e01b89":"print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))\n\nprint(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))","d4a57071":"class ClassificationDataset(Dataset):\n    def __init__(self, text, target, model_name, max_len, label_map):\n      super(ClassificationDataset).__init__()\n      \"\"\"\n      Args:\n      text (List[str]): List of the training text\n      target (List[str]): List of the training labels\n      tokenizer_name (str): The tokenizer name (same as model_name).\n      max_len (int): Maximum sentence length\n      label_map (Dict[str,int]): A dictionary that maps the class labels to integer\n      \"\"\"\n      self.text = text\n      self.target = target\n      self.tokenizer_name = model_name\n      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n      self.max_len = max_len\n      self.label_map = label_map\n      \n\n    def __len__(self):\n      return len(self.text)\n\n    def __getitem__(self,item):\n      text = str(self.text[item])\n      text = \" \".join(text.split())\n        \n      inputs = self.tokenizer(\n          text,\n          max_length=self.max_len,\n          padding='max_length',\n          truncation=True\n      )      \n      return InputFeatures(**inputs,label=self.label_map[self.target[item]])","0a06ec2b":"label_map = { v:index for index, v in enumerate(selected_dataset.label_list) }\nprint(label_map)\n\ntrain_dataset = ClassificationDataset(\n    selected_dataset.train[DATA_COLUMN].to_list(),\n    selected_dataset.train[LABEL_COLUMN].to_list(),\n    model_name,\n    max_len,\n    label_map\n  )\ntest_dataset = ClassificationDataset(\n    selected_dataset.test[DATA_COLUMN].to_list(),\n    selected_dataset.test[LABEL_COLUMN].to_list(),\n    model_name,\n    max_len,\n    label_map\n  )","cbf2ada7":"print(next(iter(train_dataset)))","d5ef0b24":"def model_init():\n    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))","31e701b7":"def compute_metrics(p): #p should be of type EvalPrediction\n  preds = np.argmax(p.predictions, axis=1)\n  assert len(preds) == len(p.label_ids)\n  #print(classification_report(p.label_ids,preds))\n  #print(confusion_matrix(p.label_ids,preds))\n  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n  acc = accuracy_score(p.label_ids,preds)\n  return {       \n      'macro_f1' : macro_f1,\n      'accuracy': acc\n  }","f8975f38":"def set_seed(seed=42):\n  random.seed(seed)\n  np.random.seed(seed)\n  torch.manual_seed(seed)\n  torch.cuda.manual_seed(seed)\n  torch.cuda.manual_seed_all(seed)\n  torch.backends.cudnn.deterministic=True\n  torch.backends.cudnn.benchmark = False","7774f29e":"training_args = TrainingArguments( \n    output_dir= \".\/train\",    \n    adam_epsilon = 1e-8,\n    learning_rate = 2e-5,\n    fp16 = False, # enable this when using V100 or T4 GPU\n    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n    per_device_eval_batch_size = 128,\n    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n    num_train_epochs= 2,\n    warmup_ratio = 0,\n    do_eval = True,\n    evaluation_strategy = 'epoch',\n    save_strategy = 'epoch',\n    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n    metric_for_best_model = 'macro_f1',\n    greater_is_better = True,\n    seed = 25\n  )\n\nset_seed(training_args.seed)","9305ee04":"trainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics,\n)","be56c9ac":"#start the training\ntrainer.train()","81ad138f":"inv_label_map = inv_label_map = { v:k for k, v in label_map.items()}\nprint(inv_label_map)\ntrainer.model.config.label2id = label_map\ntrainer.model.config.id2label = inv_label_map\ntrainer.save_model(\"output_dir\")\ntrain_dataset.tokenizer.save_pretrained(\"output_dir\")","db5d2903":"#copy the model to drive\n!cp output_dir \/content\/drive\/MyDrive","cc2165cd":"from transformers import pipeline","ea1a652b":"# initialize pipline\npipe = pipeline(\"sentiment-analysis\", model=\"output_dir\", device=0, return_all_scores=True)","62767085":"pipe(\"Some Text\")","683e6046":"# do kfold on the training. Check the perfomance on the test set\nkfold_dataset = selected_dataset.train\n# do kfold on all the dataset. Here we will not have any dataset to checl final performance on (this is used mainly in competitions)\n# kfold_dataset = pd.concat([selected_dataset.train,selected_dataset.test])\nkfold_dataset.reset_index(inplace=True,drop=True)","26def9f3":"# this is used later\ninv_label_map = { v:k for k, v in label_map.items()}","be44104d":"from sklearn.model_selection import StratifiedKFold\n\nkf = StratifiedKFold(\n    n_splits=5,\n    shuffle=True,\n    random_state=123\n  )","cefd0bb2":"all_results = []\nfold_best_f1 = 0\nbest_fold = None\nfor fold_num , (train, dev) in enumerate(kf.split(kfold_dataset,kfold_dataset['label'])):\n  print(\"**************************Starting Fold Num: \", fold_num,\" **************************\")\n  \n  train_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][train]),\n                              list(kfold_dataset[LABEL_COLUMN][train]),\n                              model_name,\n                              max_len,\n                              label_map)\n  \n  val_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][dev]),\n                              list(kfold_dataset[LABEL_COLUMN][dev]),\n                              model_name,\n                              max_len,\n                              label_map)\n  \n  training_args = TrainingArguments( \n    output_dir= f\".\/train_{fold_num}\",    \n    adam_epsilon = 1e-8,\n    learning_rate = 2e-5,\n    fp16 = False,\n    per_device_train_batch_size = 64,\n    per_device_eval_batch_size = 128,\n    gradient_accumulation_steps = 2,\n    num_train_epochs= 2,\n    warmup_ratio = 0,\n    do_eval = True,\n    evaluation_strategy = 'epoch',\n    save_strategy = 'epoch',\n    load_best_model_at_end = True,\n    metric_for_best_model = 'macro_f1',\n    greater_is_better = True,\n    seed = 123\n  )\n\n  set_seed(training_args.seed)\n\n  trainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n  )\n  trainer.model.config.label2id = label_map\n  trainer.model.config.id2label = inv_label_map\n\n  trainer.train()\n\n  results = trainer.evaluate()\n  all_results.append(results)\n  print(results)\n\n  trainer.save_model(f\".\/train_{fold_num}\/best_model\")\n  val_dataset.tokenizer.save_pretrained(f\".\/train_{fold_num}\/best_model\")\n\n  # delete the rest of the checkpoints\n  !rm -rf f\".\/train_{fold_num}\/checkpoint-*\" \n  \n  if results['eval_macro_f1'] > fold_best_f1:\n    print('**************************New Best Model Found!**************************')\n    fold_best_f1 = results['eval_macro_f1']\n    best_fold = fold_num","01662de0":"all_results","cb8398a7":"from statistics import mean\nmean([x['eval_macro_f1'] for x in all_results])","54735f1f":"from transformers import pipeline\nimport more_itertools","5fccffd4":"inv_label_map = { v:k for k, v in label_map.items()}","5ccdb2ef":"# pred_df = prediction['Text']\n# pred_df = pred_df.apply(lambda x:   arabic_prep.preprocess(x))\n\npred_df = selected_dataset.test[DATA_COLUMN]","18b2d512":"cross_val_df = pd.DataFrame([])\nfor i in range(0,5):\n  pipe = pipeline(\"sentiment-analysis\", model=f\"train_{i}\/best_model\", device=0, return_all_scores =True, max_length=max_len, truncation=True)\n  preds = []\n  for s in tqdm(more_itertools.chunked(list(pred_df), 32)): # batching for faster inference\n    preds.extend(pipe(s))\n  cross_val_df[f'model_{i}'] = preds","3eff2dbb":"from collections import defaultdict\n\nfinal_labels = []\nfinal_scores = []\nfor id, row in cross_val_df.iterrows():\n  total_score = defaultdict(lambda: 0)  \n  for pred in row:\n    for cls in pred:\n      total_score[cls['label']] += cls['score']\n\n  avg_score = { k: v\/ 5 for k, v in total_score.items()}\n\n  final_labels.append(max(avg_score, key=avg_score.get))\n  final_scores.append(avg_score[max(avg_score, key=avg_score.get)])","08e0d73a":"cross_val_df['preds'] = final_labels \ncross_val_df['sentiment_score'] = final_scores ","139693b9":"cross_val_df['preds'].value_counts()","e5cc1b1f":"print(classification_report(selected_dataset.test[LABEL_COLUMN],cross_val_df['preds']))","9fc461e6":"## predict using the saved model","fc8550b9":"## ASTD- Unbalanced","1f906c6b":"Create and apply preprocessing using the AraBERT processor","7c2d1d42":"# K-fold","13208977":"# installing dependencies","c1cf5884":"Let's download some Arabic text classification datasets","8f2e5812":"# Trainer","0c5bf08f":"Check the dataset output","be208af6":"This custom dataset class will help us hold our datasets in a structred manner.\nIt's not necessary to use it with your own data","c81896ad":"Now we need to check the tokenized sentence length to decide on the maximum sentence length value","e13a5f18":"Save the model, the tokenizer and the config","2d2d304f":"Defing the number of Stratified kfold splits","8fe69dec":"##ASTD-Dahou-Balanced","d5b4185c":"## ArSAS","4fa5b127":"Define our training parameters.\nCheck the TrainingArguments documentation for more options https:\/\/huggingface.co\/transformers\/main_classes\/trainer.html#trainingarguments","9b58cbe7":"This notebook works fine with transformers 4.12, it is not tested on newer versions","d2d870cf":"Create the trainer","802f587d":"This notebook was tested on Colab https:\/\/colab.research.google.com\/drive\/19zAYftPaXcNDZ6N6Pyj8K8BJXtkEgglx?usp=sharing","fc96938c":"Load some file which has text that we need to run inference on. \nI will use the test set for that","46ba7970":"Start the training procedure","233aee2c":"Train using cross validation and save the best model at each fold","02832767":"Create a function that return a pretrained model ready to do classification","3c4d4bdd":"## AJGT","cd9086a1":"This section is bit more advanced.\n\nWe will divide the training set into K-folds and train model with cross-validation to check for the best hyper-parameters before check the performance on the test set.\n\nAlternatively, you can combine the training and testing set if you are participating in a competition, then ensemble the output models","a2db8233":"List all the datasets we have","fe4adb88":"## LABR-Unbalanced","dae68ae6":"8 out of ~4000 for testing isn't bad","96d0af43":"# Creating training datasets","ace0ca3d":"After checking for the best hyper parameters you should use the regular training section and retrain the model with the parameters that you had here.\n\nOr Ensemble the models together.","dafc798e":"Define whatever metric you want here","b810d177":"Let's select 100 as our maximum sentence length, and check how many sequences will be truncated","fbfb723e":"Now let's create a classification dataset to load the data","fb72ef49":"# Regular Training","0fe043d5":"You need to manualy get the ArSenTD-LEV.tsv before running this ","bb2f2f59":"## HARD - Balanced","dfe6fd2c":"You can choose which ever dataset you like or use your own.\nAt this stage we don't do any preprocessing on the text, this is done later when loading the text.","9de11655":"## Ensemble all the cross validation models","1a6211bb":"## Arsentv-lev"}}