{"cell_type":{"73d7985d":"code","3bbc788e":"code","f57db6fa":"code","9c998be1":"code","44630566":"code","dbeaa0f6":"code","1f161114":"code","907b93e6":"code","24b4cb9b":"code","18363625":"code","90e8e6b0":"code","923c2b43":"code","c072b682":"code","1d7d4efa":"code","8067ce88":"code","a95b8082":"code","754ffdfd":"code","87352d6b":"code","c775e78b":"code","7494c78c":"code","13957c26":"code","cd3aad8a":"code","84ae6f86":"code","25ca5cd2":"code","07252fec":"code","a4ba43ad":"code","1093eb17":"code","0c04a229":"code","00f3e3f2":"code","9646f723":"code","0ebd1dd3":"code","3260237b":"code","145986d7":"code","0dd90037":"code","fe9334f0":"code","ac8b4daf":"code","e192367c":"code","fe624128":"code","8e287dc4":"code","77343b6f":"code","b77b248a":"code","9b72e2ff":"code","8d04d277":"code","aef170d4":"code","e8ebe072":"code","9040782d":"code","2e8471ad":"code","0c9ef3d3":"code","0f493b25":"code","1f5dc068":"code","2f143093":"code","3c248ff2":"code","1791d580":"code","7849c598":"code","431c868b":"markdown","1471e74e":"markdown","ac8e49cc":"markdown","a4100d3d":"markdown","9ae5efab":"markdown","2edc4feb":"markdown","83c3e5f1":"markdown","48e7b11a":"markdown","bc1e65f2":"markdown","d6dfb64f":"markdown","acb90aef":"markdown","483636cf":"markdown","679f8123":"markdown","4a838e8a":"markdown"},"source":{"73d7985d":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport keras\nimport time\nimport keras.backend as K\nimport os\nimport shutil\nimport random\nimport cv2\nimport matplotlib.cm as cm\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.utils import Progbar\n\nfrom keras.losses import CategoricalCrossentropy,BinaryCrossentropy\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.optimizers.schedules import InverseTimeDecay,ExponentialDecay\nfrom keras.applications.densenet import DenseNet121\nfrom keras.applications import InceptionV3\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Sequential\nfrom keras.metrics import CategoricalAccuracy, Precision, Recall\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPool2D, AveragePooling2D, Flatten, Input,GlobalAveragePooling2D\nfrom keras.utils.vis_utils import plot_model\n\nfrom sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\nfrom PIL import Image","3bbc788e":"try:\n    shutil.rmtree(\".\/train\")\n    shutil.rmtree(\".\/test\")\n    shutil.rmtree(\".\/val\")\nexcept OSError as e:\n    print(\"Directories never existed\")","f57db6fa":"def getImage(path):\n    myImage = Image.open(path)\n    myImage = myImage.resize((224, 224), Image.BICUBIC)\n    return (np.array(myImage)\/255.)","9c998be1":"path = \"..\/input\/covid19normalpneumonia-ct-images\/\"\n\nclassesPath = ['COVID2_CT', 'Normal_CT', 'pneumonia_CT']\n\nnp.random.seed(seed = 90)\n\nval_ratio = 0.1\ntest_ratio = 0.1\nseed = 90\n\nfor cls in classesPath:\n    os.makedirs('.\/train\/' + cls)\n    os.makedirs('.\/val\/' + cls)\n    os.makedirs('.\/test\/' + cls)\n\n    src = path + cls\n\n    allFileNames = os.listdir(src)\n    np.random.shuffle(allFileNames)\n    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n                                                              [int(len(allFileNames) * (1 - (val_ratio + test_ratio))), \n                                                               int(len(allFileNames) * (1 - test_ratio))])\n\n    train_FileNames = [src + '\/' + name for name in train_FileNames.tolist()]\n    val_FileNames = [src + '\/' + name for name in val_FileNames.tolist()]\n    test_FileNames = [src + '\/' + name for name in test_FileNames.tolist()]\n\n    print('Total ', str(cls), len(allFileNames))\n    print('Training', len(train_FileNames))\n    print('Validation', len(val_FileNames))\n    print('Testing', len(test_FileNames))\n    print(\"\\n\")\n\n    for name in train_FileNames:\n        shutil.copy(name, '.\/train\/' + cls)\n\n    for name in val_FileNames:\n        shutil.copy(name, '.\/val\/' + cls)\n\n    for name in test_FileNames:\n        shutil.copy(name, '.\/test\/' + cls)","44630566":"path_train = \".\/train\"\npath_val = \".\/val\"\npath_test = \".\/test\"\n\nbatch_size = 64\nbatch_test_size = 16\nseed = 90\ninterpolation = \"bicubic\"\ntarget_size = (224, 224)\nepochs = 50\n\ntrain_data_gen = ImageDataGenerator(rescale = 1.\/ 255,\n                                    rotation_range = 10,\n                                    zoom_range = 0.5)\n\ntest_data_gen = ImageDataGenerator(rescale = 1.\/ 255)\n\nds_train = train_data_gen.flow_from_directory(directory = path_train,\n                                              color_mode = \"rgb\",\n                                              batch_size = batch_size,\n                                              target_size = target_size,\n                                              shuffle = True,\n                                              interpolation = interpolation,\n                                              seed = seed)\n\nds_val = test_data_gen.flow_from_directory(directory = path_val,\n                                           color_mode = \"rgb\",\n                                           batch_size = batch_size,\n                                           target_size = target_size,\n                                           shuffle = True,\n                                           interpolation = interpolation,\n                                           seed = seed)   \n\nds_test = test_data_gen.flow_from_directory(directory = path_test,\n                                            color_mode = \"rgb\",\n                                            batch_size = batch_test_size,\n                                            target_size = target_size,\n                                            shuffle = False,\n                                            interpolation = interpolation,\n                                            seed = seed)","dbeaa0f6":"def train_one_step(x_batch, y_batch, metric, model, loss_function):\n    with tf.GradientTape() as tape:\n        y_hat = model(x_batch, training = True)\n        loss = loss_function(y_batch, y_hat)\n    gradients = tape.gradient(loss, model. trainable_weights)\n    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n    metric.update_state(y_batch, y_hat)\n    return loss\n\ndef val_one_step(x_batch, y_batch, metric, model, loss_function):\n    y_hat = model(x_batch, training = False)\n    loss = loss_function(y_batch, y_hat)\n    metric.update_state(y_batch, y_hat)\n    return loss","1f161114":"def train(model, optimizer, metric, metric_val, epochs):\n    losses = []\n    losses_val = []\n    accuracies = []\n    accuracies_val = []\n    best_loss = 999999\n    patience=0\n    loss_function = CategoricalCrossentropy()\n    for epoch in range(epochs):\n        print(\"\\nepoch {}\/{}\".format(epoch + 1, epochs))\n        batch_num = 0\n        metric_names = [metric.name, \"loss\"]\n        pb_i = Progbar(3108, stateful_metrics = metric_names)\n        loss_train=0\n        for batch_num, (x_batch_train, y_batch_train) in enumerate(ds_train):\n            loss_train += train_one_step(x_batch_train, y_batch_train, metric, model, loss_function)\n            values = [('acc', metric.result().numpy()), ('loss', loss_train)]\n            pb_i.add(x_batch_train.shape[0], values=values)\n            accuracy = metric.result().numpy()\n            accuracies.append(accuracy)\n\n            if batch_num == (3108 \/\/ batch_size):\n                break\n        losses.append(loss_train)\n\n        print(\"\\nepoch {}\/{}\".format(epoch + 1, epochs))\n        metric_val_names = [metric_val.name, \"val_loss\"]\n        pb_i = Progbar(388, stateful_metrics = metric_val_names)\n        loss_val = 0\n        for val_batch_num,(x_batch_val, y_batch_val) in enumerate(ds_val):\n            loss_val += val_one_step(x_batch_val, y_batch_val, metric_val, model, loss_function)\n            values = [('val_acc', metric_val.result().numpy()), ('val_loss', loss_val)]\n            pb_i.add(x_batch_val.shape[0], values = values)\n            accuracy_val = metric_val.result().numpy()\n            accuracies_val.append(accuracy_val)\n            \n            if val_batch_num == (388\/\/batch_size):\n                break\n\n        losses_val.append(loss_val)\n        \n        if(best_loss > loss_val):\n            best_weights = model.get_weights()\n            model.save_weights(model.name + \".h5\")\n            best_loss = loss_val\n            patience=0\n        else:\n            patience=patience+1\n\n                \n        print(metric.name + \" over epoch \" + str(epoch + 1) + \" = \" + str(accuracy) + \" and \" + metric_val.name + \" = \" + str(accuracy_val))\n        print(\"loss over epoch \" + str(epoch + 1) + \" = \" + str(loss_train.numpy()) + \" and val_loss = \" + str(loss_val.numpy()))\n        \n        metric.reset_states()\n        metric_val.reset_states()\n        \n        if patience>=10:\n            model.set_weights(best_weights)\n            return losses, accuracies, losses_val, accuracies_val\n    \n    model.set_weights(best_weights)\n    return losses, accuracies, losses_val, accuracies_val","907b93e6":"def evaluate(model, metric, classifier_layer_names = None, last_conv_name = None):\n    loss_function = CategoricalCrossentropy()\n    heatmaps = []    \n    y_pred = np.array([])\n    y_test = np.array([])\n    metric_names = [metric.name, \"loss\"]\n    pb_i = Progbar(755, stateful_metrics = metric_names)\n    loss_test = 0\n    \n    for batch_num, (x_batch_test, y_batch_test) in enumerate(ds_test):\n        if classifier_layer_names!=None:\n            heatmap = make_gradcam_heatmap(x_batch_test, model, last_conv_name, classifier_layer_names)\n            heatmaps.append(heatmap)\n        loss_test += val_one_step(x_batch_test, y_batch_test, metric, model, loss_function)\n        values = [('acc',metric.result().numpy()), ('loss', loss_test)]\n        pb_i.add(x_batch_test.shape[0], values = values)\n        y_pred = np.append(y_pred, model.predict(x_batch_test))\n        y_test = np.append(y_test, y_batch_test)\n        \n        if batch_num == (755 \/\/ batch_test_size):\n            break\n    \n    print(int(len(y_pred)))\n    y_pred = np.reshape(y_pred, (int(len(y_pred)\/3), 3))\n    print(int(len(y_test)))\n    y_test = np.reshape(y_test, (int(len(y_test)\/3), 3))\n    y_pred = np.argmax(y_pred, axis = 1)\n    y_test = np.argmax(y_test, axis = 1)\n    confusion_mat = confusion_matrix(y_pred = y_pred, y_true = y_test)\n    report = classification_report(y_true = y_test, y_pred = y_pred)\n    metric.reset_states()\n    \n    return report, confusion_mat, heatmaps","24b4cb9b":"def make_gradcam_heatmap(img_array_batch, model, last_conv_layer_name, classifier_layer_names):\n\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n    classifier_input = keras.Input(shape = last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n    with tf.GradientTape() as tape:\n        last_conv_layer_output = last_conv_layer_model(img_array_batch)\n        tape.watch(last_conv_layer_output)\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis = (0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output.numpy()\n    pooled_grads = pooled_grads.numpy()\n    \n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :,  :, i] *= pooled_grads[i]\n\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","18363625":"def overlay_heatmaps(heatmap, x):\n    img = x\/255.\n\n    heatmap = np.uint8(223 * heatmap)\n\n    jet = cm.get_cmap('jet')\n\n    \n    jet_colors = jet(np.arange(224))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    \n    jet_heatmap=tf.image.resize(jet_heatmap, (224, 224), method = 'bicubic').numpy()\n    superimposed_img= jet_heatmap * 0.5 + img\n    \n    \n    return superimposed_img","90e8e6b0":"def plotVisuals(lossTraining, lossValidation, accTraining, accValidation):\n    rangeLossTraining = range(1, len(lossTraining) + 1)\n    rangeLossValidation = range(1, len(lossValidation) + 1)\n\n    rangeAccuracyTraining = range(1, len(accTraining) + 1)\n    rangeAccuracyValidation = range(1, len(accValidation) + 1)\n\n    plt.plot(rangeLossTraining, lossTraining, 'g', label = 'Training loss')\n    plt.title('Training loss')\n    plt.xlabel('Batches')\n    plt.ylabel('Loss')\n    plt.show()\n\n    plt.plot(rangeLossValidation, lossValidation, 'b', label = 'validation loss')\n    plt.title('Validation loss')\n    plt.xlabel('Batches')\n    plt.ylabel('Loss')\n    plt.show()\n\n    plt.plot(rangeAccuracyTraining, accTraining, 'g', label = 'Training Accuracy')\n    plt.title('Training Accuracy')\n    plt.xlabel('Batches')\n    plt.ylabel('Accuracy')\n    plt.show()\n    \n    plt.plot(rangeAccuracyValidation, accValidation, 'b', label = 'validation Accuracy')\n    plt.title('Validation Accuracy')\n    plt.xlabel('Batches')\n    plt.ylabel('Accuracy')\n    plt.show()\n","923c2b43":"model_fc_3 = Sequential([\n    Flatten(input_shape = (256, 256, 3), name = \"flatten_1\"),\n    Dense(512, 'relu', name = \"hidden_1\"),\n    Dense(1024, 'relu', name = \"hidden_2\"),\n    Dense(512, 'relu', name = \"hidden_3\"),\n    Dense(256, 'relu', name = \"hidden_4\"),\n    Dense(3, 'softmax', name = \"Output\")],\n    name = \"ShallowFullyConnected\")\nmodel_fc_3.load_weights('..\/input\/weightssss\/weights\/ShallowFullyConnected.h5')","c072b682":"plot_model(model_fc_3, show_shapes = True, show_layer_names = True)","1d7d4efa":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate, staircase = True)\noptimizer = Adam(learning_rate = schedule)\n\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_fc_3, optimizer, metric, metric_val, epochs+1)","8067ce88":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","a95b8082":"metric = CategoricalAccuracy(name = \"Accuracy\")\nreport, confusion_mat, heatmaps = evaluate(model_fc_3, metric, classifier_layer_names = None, last_conv_name = None)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","754ffdfd":"model_fc_10 = Sequential([\n    Flatten(input_shape = (256, 256, 3), name = \"flatten_1\"),\n    Dense(512, 'relu', name = \"hidden_1\"),\n    Dense(512, 'relu', name = \"hidden_2\"),\n    Dense(1024, 'relu', name = \"hidden_3\"),\n    Dense(1024, 'relu', name = \"hidden_4\"),\n    Dense(1024, 'relu', name = \"hidden_5\"),\n    Dense(512, 'relu', name = \"hidden_6\"),\n    Dense(512, 'relu', name = \"hidden_7\"),\n    Dense(256, 'relu', name = \"hidden_8\"),\n    Dense(128, 'relu', name = \"hidden_9\"),\n    Dense(3, 'softmax', name = \"Output\")], \n    name = \"DeepFullyConnected\")\nmodel_fc_10.load_weights('..\/input\/weightssss\/weights\/DeepFullyConnected.h5')","87352d6b":"plot_model(model_fc_10, show_shapes = True, show_layer_names = True)","c775e78b":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate, staircase = True)\noptimizer = Adam(learning_rate = schedule)\n\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_fc_10, optimizer, metric, metric_val, epochs+2)","7494c78c":"plotVisuals(train_loss, train_accuracy, val_loss, val_accuracy)","13957c26":"metric = CategoricalAccuracy(name = \"Accuracy\")\nreport, confusion_mat, heatmaps = evaluate(model_fc_10, metric, classifier_layer_names = None, last_conv_name = None)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","cd3aad8a":"model_conv = Sequential([\n    Conv2D(6, (5, 5), input_shape = (256, 256, 3), activation = \"relu\", strides = 1, name = \"convolutional_1\"), \n    AveragePooling2D((5, 5), strides = 2, name = \"AveragePooling_1\"),\n    Conv2D(6, (5, 5), activation = \"relu\", strides = 1, name = \"convolutional_2\"), \n    AveragePooling2D((5, 5), strides = 2, name = \"AveragePooling_2\"),\n    GlobalAveragePooling2D(name = \"GlobalAveragePooling_1\"),\n    Dense(120, \"relu\", name = \"hidden_1\"),\n    Dense(84, \"relu\", name = \"hidden_2\"),\n    Dense(3, \"softmax\", name = \"output\")], \n    name = \"ShallowConvolutional\")\nmodel_conv.load_weights('..\/input\/weightssss\/weights\/ShallowConvolutional.h5')","84ae6f86":"plot_model(model_conv, show_shapes = True, show_layer_names = True)","25ca5cd2":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate, staircase = True)\noptimizer = Adam(learning_rate=schedule)\n\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_conv, optimizer, metric, metric_val, epochs+3)","07252fec":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","a4ba43ad":"metric = CategoricalAccuracy(name = \"Accuracy\")\n\nreport, confusion_mat, heatmaps = evaluate(model_conv, metric, classifier_layer_names = None, last_conv_name = None)\n\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","1093eb17":"model_conv_deep = Sequential([\n    Conv2D(64, (3, 3), input_shape = (256, 256, 3), activation = \"relu\", strides = 1, name = \"convolutional_1\"), \n    MaxPool2D((2, 2), strides = 2, name = \"MaxPooling_1\"),\n    Conv2D(128, (3, 3), activation = \"relu\", strides = 1, name = \"convolutional_2\"), \n    MaxPool2D((2, 2), strides = 2, name = \"MaxPooling_2\"),\n    Conv2D(256, (3, 3), activation = \"relu\", strides = 1, name = \"convolutional_3\"), \n    MaxPool2D((2, 2), strides = 2, name = \"MaxPooling_3\"),\n    Conv2D(512, (3, 3), activation = \"relu\", strides = 1, name = \"convolutional_4\"), \n    MaxPool2D((2, 2), strides = 2, name = \"MaxPooling_4\"),\n    Conv2D(512, (3, 3), activation = \"relu\", strides = 1, name = \"convolutional_5\"), \n    MaxPool2D((2, 2), strides = 2, name = \"MaxPooling_5\"),\n    GlobalAveragePooling2D(name = \"GlobalAveragePooling_1\"), \n    Dense(4096, \"relu\", name = \"hidden_1\"),\n    Dense(4096, \"relu\", name = \"hidden_2\"),\n    Dense(1000, \"relu\", name = \"hidden_3\"),\n    Dense(3, \"softmax\", name = \"output\")],\n    name = \"DeepConvolutional\")\nmodel_conv_deep.load_weights('..\/input\/weightssss\/weights\/DeepConvolutional.h5')","0c04a229":"plot_model(model_conv_deep, show_shapes = True, show_layer_names = True)","00f3e3f2":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate,staircase=True)\noptimizer = Adam(learning_rate = schedule)\n\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_conv_deep, optimizer, metric, metric_val, epochs+4)","9646f723":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","0ebd1dd3":"last_layer_names = [\n    'GlobalAveragePooling_1',\n    'hidden_1',\n    'hidden_2',\n    'hidden_3',\n    'output'\n]\nlast_conv_layer = 'convolutional_5'\nreport, confusion_mat, heatmaps = evaluate(model_conv_deep, metric, classifier_layer_names = last_layer_names, last_conv_name = last_conv_layer)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","3260237b":"model_resnet50 = ResNet50(include_top = False, weights = \"imagenet\", input_shape = (256, 256, 3))\nmodel_resnet50.trainable = False\n\nx = model_resnet50.output\nx = GlobalAveragePooling2D(name = \"GlobalAveragePooling_1\")(x)\nx = Dense(512, activation = 'relu', name = \"hidden_1\")(x)\nx = Dense(256, activation = 'relu', name = \"hidden_2\")(x)\nx = Dense(128, activation = 'relu', name = \"hidden_3\")(x)\ny_hat = Dense(3, 'softmax', name = \"Output\")(x)\n\nmodel_resnet50 = Model(inputs = model_resnet50.input, outputs = y_hat, name = \"ResNet50\")\nmodel_resnet50.load_weights('..\/input\/weightssss\/weights\/ResNet50.h5')","145986d7":"plot_model(model_resnet50, show_shapes = True, show_layer_names = True)","0dd90037":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate,staircase=True)\noptimizer = Adam(learning_rate = schedule)\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_resnet50, optimizer, metric, metric_val, epochs+5)","fe9334f0":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","ac8b4daf":"heatmaps_array=[]","e192367c":"metric = CategoricalAccuracy(name = \"Accuracy\")\nlast_layer_names = [\n    'GlobalAveragePooling_1',\n    'hidden_1',\n    'hidden_2',\n    'hidden_3',\n    'Output'\n]\nlast_conv_layer = 'conv5_block3_out'\nreport, confusion_mat, heatmaps = evaluate(model_resnet50, metric, classifier_layer_names = last_layer_names, last_conv_name = last_conv_layer)\nheatmaps_array.append(heatmaps)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","fe624128":"model_DenseNet121 = DenseNet121(include_top = False, weights = \"imagenet\", input_shape = (224, 224, 3))\nmodel_DenseNet121.trainable = False\n\nx = model_DenseNet121.output\nx = GlobalAveragePooling2D(name = \"GlobalAveragePooling_1\")(x)\nx = Dense(256, activation = 'relu', name = \"hidden_1\")(x)\nx = Dense(128, activation = 'relu', name = \"hidden_2\")(x)\n\ny_hat = Dense(3, 'softmax', name = \"Output\")(x)\n\nmodel_DenseNet121 = Model(inputs = model_DenseNet121.input, outputs = y_hat, name = \"DenseNet121\")\nif os.path.isfile('..\/input\/model-weights\/DenseNet121 (1).h5'):\n    print(\"Loaded weights\")\n    model_DenseNet121.load_weights('..\/input\/model-weights\/DenseNet121 (1).h5')\nelse:\n    print(\"No weights recognized\")","8e287dc4":"plot_model(model_DenseNet121, show_shapes = True, show_layer_names = True)","77343b6f":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate,staircase=True)\noptimizer = Adam(learning_rate=schedule)\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model = model_DenseNet121, optimizer = optimizer, metric = metric, metric_val = metric_val, epochs = 50)","b77b248a":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","9b72e2ff":"heatmaps_array = []\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nlast_layer_names = [\n    'GlobalAveragePooling_1' ,\n    'hidden_1',\n    'hidden_2',\n    'Output'\n]\nlast_conv_layer = 'conv5_block16_concat'\nreport,confusion_mat,heatmaps = evaluate(model_DenseNet121, metric, classifier_layer_names = last_layer_names, last_conv_name = last_conv_layer)\nheatmaps_array.append(heatmaps)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","8d04d277":"model_InceptionV3 = InceptionV3(include_top = False, weights = \"imagenet\", input_shape = (256, 256, 3))\nmodel_InceptionV3.trainable = False\n\nx = model_InceptionV3.output\nx = GlobalAveragePooling2D(name = \"GlobalAveragePooling_1\")(x)\nx = Dense(512, activation = 'relu', name = \"hidden_1\")(x)\nx = Dense(256, activation = 'relu', name = \"hidden_2\")(x)\nx = Dense(128, activation = 'relu', name = \"hidden_3\")(x)\n\ny_hat = Dense(3,'softmax', name = \"Output\")(x)\n\nmodel_InceptionV3 = Model(inputs = model_InceptionV3.input, outputs = y_hat)\nmodel_InceptionV3.load_weights('..\/input\/weightssss\/weights\/functional_201.h5')","aef170d4":"plot_model(model_InceptionV3, show_shapes = True, show_layer_names = True)","e8ebe072":"decay_step = 250.0\ninitial_learning_rate = 0.001\ndecay_rate = 2.0\nschedule = InverseTimeDecay(initial_learning_rate, decay_step, decay_rate, staircase = True)\noptimizer = Adam(learning_rate = schedule)\n\nmetric = CategoricalAccuracy(name = \"Accuracy\")\nmetric_val = CategoricalAccuracy(name = \"Val_Accuracy\")\n\ntrain_loss, train_accuracy, val_loss, val_accuracy = train(model_InceptionV3, optimizer, metric, metric_val, epochs+7)","9040782d":"plotVisuals(train_loss, val_loss, train_accuracy, val_accuracy)","2e8471ad":"metric = CategoricalAccuracy(name = \"Accuracy\")\nlast_layer_names = [\n    'GlobalAveragePooling_1',\n    'hidden_1',\n    'hidden_2',\n    'hidden_3',\n    'Output'\n]\nlast_conv_layer = 'mixed10'\nreport, confusion_mat, heatmaps = evaluate(model_InceptionV3, metric, classifier_layer_names = last_layer_names, last_conv_name = last_conv_layer)\nheatmaps_array.append(heatmaps)\nprint(report)\nConfusionMatrixDisplay(confusion_matrix = confusion_mat).plot()","0c9ef3d3":"heatmaps=heatmaps_array[0][2]\nims = np.array(np.zeros((0,224,224,3)))\nimgs = np.array(np.zeros((0,224,224,3)))\nfor i in range(8):\n    ims = np.append(ims,overlay_heatmaps(heatmaps[i],ds_test.__getitem__(i)[0]),axis=0)\n    imgs = np.append(imgs,ds_test.__getitem__(i)[0],axis=0)\nw = 224\nh = 224\nfig = plt.figure(figsize=(w, h))\ncolumns = 4\nrows = 8\nj = 0\nfor i in np.random.randint(low = 1, high = 121, size = 16):\n    fig.add_subplot(rows, columns, j + 1)\n    img = imgs[i - 1]\n    plt.imshow(img)\n    fig.add_subplot(rows, columns, j + 2)\n    img2 = ims[i - 1]\n    plt.imshow(img2)\n    j = j + 2\nplt.show()","0f493b25":"def overlay_heatmaps(heatmap,x):\n    \n    superimposed_img = heatmap * 0.7 + img\n    \n    return superimposed_img","1f5dc068":"img = getImage(\"..\/input\/test-srta\/coronacases_001_z156.png\")\nnp.array(img).shape\n","2f143093":"import matplotlib.cm as cm\nfrom PIL import Image\nimport cv2\ndef getImage(path):\n    myImage = Image.open(path)\n    myImage = np.expand_dims(myImage.resize((224, 224)),axis=2)\n    return myImage","3c248ff2":"def make_gradcam_heatmap_ayman(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    img_array=np.expand_dims(img_array,axis=0)\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    print(preds)\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) \/ tf.math.reduce_max(heatmap)\n    heatmap=np.array(heatmap)\n    #heatmap=heatmap[heatmap < 0.7] =0.0\n    super_threshold_indices = heatmap < 0.9\n    heatmap[super_threshold_indices] = 0\n    \n    jet_heatmap = np.uint8(255 * heatmap)\n\n    jet = cm.get_cmap('jet')\n\n    \n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[jet_heatmap]\n\n    \n    jet_heatmap=tf.image.resize(jet_heatmap, (224, 224), method = 'bicubic').numpy()\n\n    return heatmap,jet_heatmap","1791d580":"img = getImage(path=\"..\/input\/filemostafa\/coronacases_001_z116 (1).png\")\nimg = img\/255.\nimg = cv2.merge([img,img,img])\nheatmaps_t,jet_heatmap = make_gradcam_heatmap_ayman(img, model_DenseNet121,\"relu\")\nims = overlay_heatmaps(jet_heatmap,img)\nplt.imshow(ims)","7849c598":"heatmap,jet_heatmap=make_gradcam_heatmap_ayman(img,model_DenseNet121,\"conv5_block16_concat\")","431c868b":"# 1.2. Deep-Fully Connected Network Model","1471e74e":"# Implementing GradCams for Heatmaps","ac8e49cc":"# 2.2. Deep-Convolutional Network Model","a4100d3d":"# 3.1. ResNet50 Model","9ae5efab":"# 3.2. DenseNet121 Model","2edc4feb":"# 2.1. Shallow-Convolutional Network Model","83c3e5f1":"# Loading the data with Image Augmentation using real-time augmentation with Keras Image Data Generator","48e7b11a":"# 1.1. Shallow-Fully Connected Network Model","bc1e65f2":"# Splitting Data \n### Training (80) : Validation (10) : and Testing (10)","d6dfb64f":"# Heatmaps","acb90aef":"# Importing a single test image","483636cf":"# Implementing Visualization","679f8123":"# Creating the custom training loop","4a838e8a":"# 3.3 InceptionV3 Model"}}