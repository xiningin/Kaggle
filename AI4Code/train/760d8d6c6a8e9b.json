{"cell_type":{"6aa8da13":"code","1d37a9b7":"code","3c0d5ec9":"markdown","bac780c7":"markdown","56bc11e4":"markdown","4d70ced6":"markdown","edf99218":"markdown","16039c2d":"markdown","89ed615f":"markdown"},"source":{"6aa8da13":"def perceptron_output(w, x):\n    z = 0.0\n    for i in range(len(w)): z += x[i] * w[i]\n    if z < 0: return -1\n    else: return 1","1d37a9b7":"x = [1, 1, 3]\nw = [0.9, -0.6, -0.5]\nperceptron_output(w, x)","3c0d5ec9":"It is the architecture everyone learns before jumping into concepts like \"Multilayer Perceptrons\" or \"Neural Networks\". And as you learn you'll see that complex Neural Networks are just a colection of simple units, with individually simple architectures.","bac780c7":"#### An example:","56bc11e4":"#### The for loop computes this sum:\n$$z\\ =\\ \\sum _{i=0}^nw_ix_i$$","4d70ced6":"#### And the output of the perceptron is results from the following function:\n$$f\\left(z\\right)\\ =\\ \\begin{cases}\n-1{,}\\ \\ if\\ \\ \\ z<0\\\\\n\\ \\ \\ 1{,}\\ otherwise\n\\end{cases}$$","edf99218":"#### So how are the $w_i$ determined? Google \"Perceptron Learning Algorith\" and be happy !","16039c2d":"### That's it. The perceptron has a simple architecture.","89ed615f":"#### Here it is..."}}