{"cell_type":{"709e5fc9":"code","6d05f051":"code","0662be47":"code","ba6524c3":"code","e200d76c":"code","015efe4b":"code","7d782b4e":"code","753b790b":"code","a0cc91c5":"code","ec03ac21":"code","450ad72b":"code","8d07da82":"code","5cabeae0":"code","18135016":"code","46cef7ba":"code","4b6760cb":"code","31f3ca25":"code","b9c9d72d":"code","1dbf2059":"code","a8a898cf":"code","d979391f":"code","fcb17a67":"code","5c456c2c":"code","3b019640":"code","a2c463a8":"code","57fb9974":"markdown","43b2e106":"markdown","891c058a":"markdown","d5a179f9":"markdown","9b44d831":"markdown","647a4b7a":"markdown","5066d17e":"markdown","04e55170":"markdown","cf0cc9ce":"markdown","972b1bbc":"markdown","dcf7326d":"markdown","994afc88":"markdown","9e9ecfd2":"markdown","ca1b07e5":"markdown","adb4ca10":"markdown","d2943cf6":"markdown","c1f9ae44":"markdown","956e0f53":"markdown","19a003a4":"markdown","61a3c5de":"markdown","7b8fec09":"markdown","91da624d":"markdown","5927fdd1":"markdown","7c3c3b75":"markdown","169df3cb":"markdown","44d735ea":"markdown"},"source":{"709e5fc9":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6d05f051":"iris = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset","0662be47":"iris.head() #show the first rows from the dataset","ba6524c3":"iris.info()  #checking if there is any inconsistency in the dataset\n#as we see there are no null values in the dataset, so the data can be processed","e200d76c":"iris.drop('Id',axis=1,inplace=True) #dropping the Id column as it is unecessary, axis=1 specifies that it should be column wise, inplace =1 means the changes should be reflected into the dataframe","015efe4b":"fig = px.scatter_3d(iris, x='SepalLengthCm', y='SepalWidthCm', z='PetalWidthCm',color='Species')\nfig.show()","7d782b4e":"fig = px.scatter_3d(iris, x='SepalLengthCm', y='SepalWidthCm', z='PetalWidthCm',color='PetalLengthCm', symbol='Species')\nfig.show()","753b790b":"iris.hist(edgecolor='black', linewidth=1.2)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()","a0cc91c5":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='PetalWidthCm',data=iris)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris)","ec03ac21":"# importing alll the necessary packages to use the various classification algorithms\nfrom sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\nfrom sklearn.model_selection import train_test_split #to split the dataset for training and testing\nfrom sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\nfrom sklearn import svm  #for Support Vector Machine (SVM) Algorithm\nfrom sklearn import metrics #for checking the model accuracy\nfrom sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm","450ad72b":"iris.shape #get the shape of the dataset","8d07da82":"plt.figure(figsize=(7,4)) \nsns.heatmap(iris.corr(),annot=True) #draws  heatmap with input as the correlation matrix calculted by(iris.corr())\nplt.show()","5cabeae0":"train, test = train_test_split(iris, test_size = 0.3)# in this our main data is split into train and test\n# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\nprint(train.shape)\nprint(test.shape)","18135016":"train_X = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]# taking the training data features\ntrain_y=train.Species# output of our training data\ntest_X= test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking test data features\ntest_y =test.Species   #output value of test data","46cef7ba":"train_X.head(2)","4b6760cb":"test_X.head(2)","31f3ca25":"train_y.head()  ##output of the training data","b9c9d72d":"petal=iris[['PetalLengthCm','PetalWidthCm','Species']]\nsepal=iris[['SepalLengthCm','SepalWidthCm','Species']]","1dbf2059":"train_p,test_p=train_test_split(petal,test_size=0.3,random_state=0)  #petals\ntrain_x_p=train_p[['PetalWidthCm','PetalLengthCm']]\ntrain_y_p=train_p.Species\ntest_x_p=test_p[['PetalWidthCm','PetalLengthCm']]\ntest_y_p=test_p.Species\n\n\ntrain_s,test_s=train_test_split(sepal,test_size=0.3,random_state=0)  #Sepal\ntrain_x_s=train_s[['SepalWidthCm','SepalLengthCm']]\ntrain_y_s=train_s.Species\ntest_x_s=test_s[['SepalWidthCm','SepalLengthCm']]\ntest_y_s=test_s.Species","a8a898cf":"best_scores = {'Model':[], 'Score':[]}","d979391f":"model=svm.SVC()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the SVM using Petals is:',metrics.accuracy_score(prediction,test_y_p))\nbest_scores['Model'].append('SVM_petal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_p))\n\nmodel=svm.SVC()\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the SVM using Sepal is:',metrics.accuracy_score(prediction,test_y_s))\nbest_scores['Model'].append('SVM_sepal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_s))","fcb17a67":"model = LogisticRegression()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Logistic Regression using Petals is:',metrics.accuracy_score(prediction,test_y_p))\nbest_scores['Model'].append('LogisticRegresseion_petal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Logistic Regression using Sepals is:',metrics.accuracy_score(prediction,test_y_s))\nbest_scores['Model'].append('LogisticRegresseion_sepal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_s))","5c456c2c":"model=DecisionTreeClassifier()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Decision Tree using Petals is:',metrics.accuracy_score(prediction,test_y_p))\nbest_scores['Model'].append('DecisionTree_petal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Decision Tree using Sepals is:',metrics.accuracy_score(prediction,test_y_s))\nbest_scores['Model'].append('DecisionTree_sepal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_s))","3b019640":"model=KNeighborsClassifier(n_neighbors=3) \nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the KNN using Petals is:',metrics.accuracy_score(prediction,test_y_p))\nbest_scores['Model'].append('KNeighbors_petal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the KNN using Sepals is:',metrics.accuracy_score(prediction,test_y_s))\nbest_scores['Model'].append('KNeighbors_sepal')\nbest_scores['Score'].append(metrics.accuracy_score(prediction,test_y_s))","a2c463a8":"df_bestScores = pd.DataFrame(best_scores)\ndf_bestScores = df_bestScores.sort_values(by=['Score'],ascending=False)\ndf_bestScores","57fb9974":"I hope the notebook was useful to you to get started with Machine Learning.\n\nIf  find this notebook, **Please Upvote**.\n\nThank You!!","43b2e106":"> This notebook is an update of [this work](https:\/\/www.kaggle.com\/ash316\/ml-from-scratch-with-iris). Please consider giving an upvote to the original as well.\n\n> This is a very basic tutorial to Machine Learning for complete Beginners using the Iris Dataset. You can learn how to implement a machine learning to a given dataset by following this notebook. I have explained everything related to the implementation in detail . Hope you find it useful.\n\n> If this notebook to be useful, **Please Upvote!!!**","891c058a":"### Now the given problem is a classification problem. Thus we will be using the classification algorithms to build a model.","d5a179f9":"### K-Nearest Neighbours","9b44d831":"## 3. Machine Learning","647a4b7a":"## 1. EDA - Exploratory Data Analysis","5066d17e":"### Creating Petals And Sepals Training Data ","04e55170":"> The graphic below is interactive in 3D and can be moved and changed its axes. This way it is possible to perform multiple analyzes on a single plot. Just click, hold and drag.","cf0cc9ce":"> Before we start, we need to clear some ML notations.\n\n> **attributes**-->An attribute is a property of an instance that may be used to determine its classification. In the following dataset, the attributes are the petal and sepal length and width. It is also known as **Features**.\n\n> **Target variable**, in the machine learning context is the variable that is or should be the output. Here the target variables are the 3 flower species.","972b1bbc":"> Lets check the Train and Test Dataset","dcf7326d":"> We will create a DataFrame to store the results of each model.","994afc88":"### Splitting The Data into Training And Testing Dataset","9e9ecfd2":"### Decision Tree","ca1b07e5":" - Using Petals over Sepal for training the data gives a much better accuracy.\n - This was expected as we saw in the heatmap above that the correlation between the Sepal Width and Length was very low whereas the correlation between Petal Width and Length was very high. ","adb4ca10":"> Now let's test some machine learning models and store their scores in a table so we can compare them.","d2943cf6":"## 2. Train and Test Dataset","c1f9ae44":"## 4. Conclusion","956e0f53":"### SVM","19a003a4":"> The violinplot shows density of the length and width in the species. The thinner part denotes that there is less density whereas the fatter part conveys higher density","61a3c5de":"### Logistic Regression","7b8fec09":"**Observation:**\n\n> The Sepal Width and Length are not correlated\nThe Petal Width and Length are highly correlated\n\n> We will use all the features for training the algorithm and check the accuracy.\n","91da624d":"> As we can see that the Petal Features are giving a better cluster division compared to the Sepal features. This is an indication that the Petals can help in better and accurate Predictions over the Sepal. We will check that later.","5927fdd1":"### Now let us see how the length and width vary according to the species","7c3c3b75":"### Steps To Be followed When Applying an Algorithm\n\n >1. Split the dataset into training and testing dataset. The testing dataset is generally smaller than training one as it will help in training the model better.\n >2. Select any algorithm based on the problem (classification or regression) whatever you feel may be good.\n >3. Then pass the training dataset to the algorithm to train it. We use the **.fit()** method\n >4. Then pass the testing data to the trained algorithm to predict the outcome. We use the **.predict()** method.\n >5. We then check the accuracy by **passing the predicted outcome and the actual output** to the model.","169df3cb":"### Now let us see how are the length and width are distributed","44d735ea":"#### Removing the unneeded column"}}