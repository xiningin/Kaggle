{"cell_type":{"0a376967":"code","05eccaa2":"code","d94898f3":"code","a8e8b0f4":"code","35eb2986":"code","99c7f4e0":"code","1cf60d78":"code","c31eb564":"code","598d6309":"code","4fe6dff7":"code","77c568f8":"code","a53e8a4c":"code","9534c654":"code","a74697a3":"code","94ceae62":"code","2949aa19":"code","945110a8":"code","9ffa398c":"code","15162b20":"code","41690a9a":"code","f52e6874":"code","aab0aafc":"code","2a4c1435":"code","9de88915":"code","e9f77d6f":"code","e4d4b520":"code","f2dbed2c":"code","3591a08e":"code","e354633d":"code","f4ed00f0":"code","ae576170":"code","a5545e5c":"code","33c27264":"code","8a7233ec":"code","259d1332":"code","19826098":"markdown","cd4dd585":"markdown"},"source":{"0a376967":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport glob\n\nimport nibabel as nib\nimport cv2\nimport imageio\nfrom tqdm.notebook import tqdm\nfrom ipywidgets import *\nfrom PIL import Image\n","05eccaa2":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html > \/dev\/null\n!pip install --upgrade kornia > \/dev\/null\n!pip install allennlp==1.1.0.rc4 > \/dev\/null\n!pip install --upgrade fastai > \/dev\/null\nimport fastai; fastai.__version__","d94898f3":"from fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import *","a8e8b0f4":"# Create a meta file for nii files processing\n\nfile_list = []\nfor dirname, _, filenames in os.walk('..\/input\/liver-tumor-segmentation'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        file_list.append((dirname,filename)) \n\nfor dirname, _, filenames in os.walk('..\/input\/liver-tumor-segmentation-part-2'):\n    for filename in filenames:\n        file_list.append((dirname,filename)) \n\ndf_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \ndf_files.sort_values(by=['filename'], ascending=True)    ","35eb2986":"# Map CT scan and label \n\ndf_files[\"mask_dirname\"] = \"\" ; df_files[\"mask_filename\"] = \"\"\n\nfor i in range(131):\n    ct = f\"volume-{i}.nii\"\n    mask = f\"segmentation-{i}.nii\"\n    \n    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"..\/input\/liver-tumor-segmentation\/segmentations\"\n\ndf_files_test= df_files[df_files.mask_filename=='']\n# drop segment rows\ndf_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \nprint(len(df_files))\ndf_files\n#df_files_test","99c7f4e0":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","1cf60d78":"# Read sample\nsample = 96\nsample_ct   = read_nii(df_files.loc[sample,'dirname']+\"\/\"+df_files.loc[sample,'filename'])\nsample_mask  = read_nii(df_files.loc[sample,'mask_dirname']+\"\/\"+df_files.loc[sample,'mask_filename'])\nprint(sample_ct.shape) \nprint(sample_mask.shape)\nprint(df_files.loc[sample,'dirname']+\"\/\"+df_files.loc[sample,'filename'])","c31eb564":"print(np.amin(sample_ct), np.amax(sample_ct))\nprint(np.amin(sample_mask), np.amax(sample_mask))","598d6309":"# Preprocess the nii file \n# Source https:\/\/docs.fast.ai\/medical.imaging\n\ndicom_windows = types.SimpleNamespace(\n    brain=(80,40),\n    subdural=(254,100),\n    stroke=(8,32),\n    brain_bone=(2800,600),\n    brain_soft=(375,40),\n    lungs=(1500,-600),\n    mediastinum=(350,50),\n    abdomen_soft=(400,50),\n    liver=(150,30),\n    spine_soft=(250,50),\n    spine_bone=(1800,400),\n    custom = (200,60)\n)\n\n@patch\ndef windowed(self:Tensor, w, l):\n    px = self.clone()\n    px_min = l - w\/\/2\n    px_max = l + w\/\/2\n    px[px<px_min] = px_min\n    px[px>px_max] = px_max\n    return (px-px_min) \/ (px_max-px_min)\n\nplt.imshow(tensor(sample_ct[...,50].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);","4fe6dff7":"def plot_sample(array_list, color_map = 'nipy_spectral'):\n    '''\n    Plots and a slice with all available annotations\n    '''\n    fig = plt.figure(figsize=(18,15))\n\n    plt.subplot(1,4,1)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.title('Original Image')\n    \n    plt.subplot(1,4,2)\n    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n    plt.title('Windowed Image')\n    \n    plt.subplot(1,4,3)\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Mask')\n    \n    plt.subplot(1,4,4)\n    plt.imshow(array_list[0], cmap='bone')\n    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n    plt.title('Liver & Mask')\n\n\n    plt.show()","77c568f8":"sample=130\nsample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n\nplot_sample([sample_ct[...,sample], sample_mask[...,sample]])","a53e8a4c":"# Check the mask values\nmask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\nunique, counts = np.unique(mask, return_counts=True)\nprint( np.array((unique, counts)).T)\nplt.imshow(mask , cmap = 'bone')","9534c654":"# Preprocessing functions\n# Source https:\/\/docs.fast.ai\/medical.imaging\n\nclass TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n\n@patch\ndef freqhist_bins(self:Tensor, n_bins=100):\n    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n    imsd = self.view(-1).sort()[0]\n    t = torch.cat([tensor([0.001]),\n                   torch.arange(n_bins).float()\/n_bins+(1\/2\/n_bins),\n                   tensor([0.999])])\n    t = (len(imsd)*t).long()\n    return imsd[t].unique()\n    \n@patch\ndef hist_scaled(self:Tensor, brks=None):\n    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n    if brks is None: brks = self.freqhist_bins()\n    ys = np.linspace(0., 1., len(brks))\n    x = self.numpy().flatten()\n    x = np.interp(x, brks.numpy(), ys)\n    return tensor(x).reshape(self.shape).clamp(0.,1.)\n    \n    \n@patch\ndef to_nchan(x:Tensor, wins, bins=None):\n    res = [x.windowed(*win) for win in wins]\n    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n    dim = [0,1][x.dim()==3]\n    return TensorCTScan(torch.stack(res, dim=dim))\n\n@patch\ndef save_jpg(x:(Tensor), path, wins, bins=None, quality=90):\n    fn = Path(path).with_suffix('.jpg')\n    x = (x.to_nchan(wins, bins)*255).byte()\n    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n    im.save(fn, quality=quality)\n\n_,axs=subplots(1,1)\n\nsample_slice.save_jpg('test.jpg', [dicom_windows.liver,dicom_windows.custom])\nshow_image(Image.open('test.jpg'), ax=axs[0])\n","a74697a3":"df_files=df_files[100:131]\ndf_files","94ceae62":"# Make custom JPG files for Unet training\n# Total number of 131 nii files contains 67072 slices \n\nGENERATE_JPG_FILES = True   # warning: generation takes ~ 1h\nslice_sum=0\nif (GENERATE_JPG_FILES) :\n    \n    path = Path(\".\")\n\n    os.makedirs('train_images',exist_ok=True)\n    os.makedirs('train_masks',exist_ok=True)\n\n    for ii in tqdm(range(100+0,100+len(df_files))): # take 1\/3 nii files for training\n        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"\/\"+df_files.loc[ii,'filename'])\n        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"\/\"+df_files.loc[ii,'mask_filename'])\n        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n        slice_sum = slice_sum+curr_dim\n        \n        for curr_slice in range(0,curr_dim,1): # export every 2nd slice for training\n            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode=\"L\")\n            data.save_jpg(f\"train_images\/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n            mask.save(f\"train_masks\/{curr_file_name}_slice_{curr_slice}_mask.png\")\n            \nelse:\n    \n    path = Path(\"..\/input\/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output\nprint(slice_sum)\n","2949aa19":"!zip -q -r train_masks.zip \".\/train_masks\"\n!zip -q -r train_images.zip \".\/train_images\"","945110a8":"!rm -rf .\/train_images\n!rm -rf .\/train_masks\n","9ffa398c":"# bs = 16\n# im_size = 128\n\n# codes = np.array([\"background\",\"liver\",\"tumor\"])\n    \n# def get_x(fname:Path): return fname\n# def label_func(x): return path\/'train_masks'\/f'{x.stem}_mask.png'\n\n# tfms = [IntToFloatTensor(),Normalize()]\n\n# db = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),  #codes = {\"Backround\": 0,\"Liver\": 1,\"Tumor\": 2}\n#                batch_tfms=tfms,\n#                splitter=RandomSplitter(),\n#                item_tfms=[Resize(im_size)],\n#                get_items=get_image_files,\n#                get_y=label_func\n#               )\n\n# ds = db.datasets(source=path\/'train_images')\n","15162b20":"# idx=20\n# imgs = [ds[idx][0],ds[idx][1]]\n# fig,axs = plt.subplots(1, 2)\n# for i,ax in enumerate(axs.flatten()):\n#     ax.axis('off')\n#     ax.imshow(imgs[i]) #, cmap='gray'","41690a9a":"# unique, counts = np.unique(array(ds[idx][1]), return_counts=True)\n\n# print( np.array((unique, counts)).T)\n","f52e6874":"# dls = db.dataloaders(path\/'train_images',bs = bs) #, num_workers=0\n# dls.show_batch()","aab0aafc":"# def foreground_acc(inp, targ, bkg_idx=0, axis=1):  # exclude a background from metric\n#     \"Computes non-background accuracy for multiclass segmentation\"\n#     targ = targ.squeeze(1)\n#     mask = targ != bkg_idx\n#     return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean() \n\n# def cust_foreground_acc(inp, targ):  # # include a background into the metric\n#     return foreground_acc(inp=inp, targ=targ, bkg_idx=3, axis=1) # 3 is a dummy value to include the background which is 0","2a4c1435":"# learn = unet_learner(dls, resnet34, loss_func=CrossEntropyLossFlat(axis=1), metrics=[foreground_acc, cust_foreground_acc]) ","9de88915":"# learn.lr_find()","e9f77d6f":"# learn.fine_tune(5, wd=0.1, cbs=SaveModelCallback() )","e4d4b520":"# learn.show_results()","f2dbed2c":"# # Save the model\n# learn.export(path\/f'Liver_segmentation')","3591a08e":"# import gc\n# del learn\n# gc.collect()\n# torch.cuda.empty_cache()","e354633d":"# # Load saved model\n# if (GENERATE_JPG_FILES) :\n    \n#     tfms = [Resize(im_size), IntToFloatTensor(),Normalize()]\n#     learn0               = load_learner(path\/f'Liver_segmentation',cpu=False )\n#     learn0.dls.transform = tfms","f4ed00f0":"# def nii_tfm(fn,wins): \n\n#     test_nii  = read_nii(fn)\n#     curr_dim  = test_nii.shape[2] # 512, 512, curr_dim\n#     slices = []\n    \n#     for curr_slice in range(curr_dim):\n#         data = tensor(test_nii[...,curr_slice].astype(np.float32))\n#         data = (data.to_nchan(wins)*255).byte()\n#         slices.append(TensorImage(data))\n                      \n#     return slices ","ae576170":"# tst = 20\n\n# test_nii   = read_nii(df_files.loc[tst,'dirname']+\"\/\"+df_files.loc[tst,'filename'])\n# test_mask  = read_nii(df_files.loc[tst,'mask_dirname']+\"\/\"+df_files.loc[tst,'mask_filename'])\n# print(test_nii.shape)\n\n# test_slice_idx = 500\n\n# sample_slice = tensor(test_nii[...,test_slice_idx].astype(np.float32))\n\n# plot_sample([test_nii[...,test_slice_idx], test_mask[...,test_slice_idx]])","a5545e5c":"# # Prepare a nii test file for prediction \n\n# test_files = nii_tfm(df_files.loc[tst,'dirname']+\"\/\"+df_files.loc[tst,'filename'],[dicom_windows.liver, dicom_windows.custom])\n# print(\"Number of test slices: \",len(test_files))","33c27264":"# # Check an input for a test file\n# show_image(test_files[test_slice_idx])","8a7233ec":"# # Get predictions for a Test file\n\n# test_dl = learn0.dls.test_dl(test_files)\n# preds, y = learn0.get_preds(dl=test_dl)\n\n# predicted_mask = np.argmax(preds, axis=1)\n# plt.imshow(predicted_mask[test_slice_idx])","259d1332":"# a=np.array(predicted_mask[test_slice_idx])\n# np.amin(a),np.amax(a),","19826098":"# MODEL TRAINING","cd4dd585":"# TESTING MODEL"}}