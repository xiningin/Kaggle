{"cell_type":{"33b5c7cd":"code","84606bf8":"code","879a90c6":"code","026c0c4f":"code","bd8ef5ad":"code","2cb590fe":"code","7cd89537":"code","34545ba7":"code","64b9f464":"code","77712188":"code","4b07b5e5":"code","b986b36a":"code","7cb99c4c":"code","d49d6bdd":"code","669842e4":"code","2039e1ef":"code","1ece3405":"code","7606211a":"code","62400ccb":"code","d1e2d302":"code","d506fc72":"code","69915647":"code","e0609cb3":"code","3185140f":"code","45f15545":"code","7f7cb85f":"code","8a2def72":"code","a6180823":"code","2bdd4853":"code","f7e54902":"code","e4406d1d":"code","19341e1b":"code","b91d2b1e":"code","09a8df3a":"code","1a998315":"code","233181b6":"code","66c4eb4f":"code","7c45193f":"code","55532b1b":"code","98159548":"code","ee1e8cf0":"code","8ace7871":"code","80b9fff3":"code","200b0b40":"code","42925af0":"code","7cdb2a21":"markdown","61456f18":"markdown","82eaa4b2":"markdown","3d17549c":"markdown","c2cfe73c":"markdown","e9e59d10":"markdown","946576c5":"markdown","a94dad93":"markdown","de22ab17":"markdown","2e3221e1":"markdown","6acde69d":"markdown","f95f4e22":"markdown","ad4b2834":"markdown","5bd97fe1":"markdown","a7161922":"markdown","e1572171":"markdown","a04076c0":"markdown","b8289ae9":"markdown","2fc9b9ed":"markdown","5e25469e":"markdown","2480c44e":"markdown"},"source":{"33b5c7cd":"#-------------------\n# importing libraries\n#-------------------\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport shutil\nimport csv\n\nimport matplotlib.image as img\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import Model,layers","84606bf8":"!pip install tensorflow_addons\n\nimport tensorflow_addons as tfa","879a90c6":"# Define the distributed strategy\nAUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","026c0c4f":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_DS_PATH)\n\nTRAIN_PATH = GCS_DS_PATH + \"\/train_images\/\"\n\ntrain = pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/train.csv\")\n\ntrain.head()","bd8ef5ad":"labels_counts = train[\"labels\"].value_counts()\n\nplt.barh(labels_counts.index,labels_counts)\nplt.title(\"Labels counts\")","2cb590fe":"from sklearn.model_selection import train_test_split\n\n\n# splitting on labels\nX_train, X_test, y_train, y_test = train_test_split(train['image'], train['labels'], test_size=0.1, random_state = 12,\n                                                      stratify =  train['labels'] )\n\n# using test set as training sample\ndata_sample = train.iloc[y_test.index]\n\nprint(\"sample shape\")\nprint(data_sample.shape)","7cd89537":"labels_counts = data_sample[\"labels\"].value_counts()\n\nplt.barh(labels_counts.index,labels_counts)\nplt.title(\"sample labels counts\")","34545ba7":"data_sample[\"path\"] = TRAIN_PATH + data_sample[\"image\"]\n\nclass_dict = {\n    'scab': 0,\n    'frog_eye_leaf_spot' : 1,\n    'rust' : 2,\n    'complex' : 3,\n    'powdery_mildew' : 4,\n    \"healthy\" : 5\n}\nnum_classes = len(class_dict)    \nclass_names = dict([(value, key) for key, value in class_dict.items()])\ndata_sample[\"labels\"] = data_sample[\"labels\"].map(lambda x : [i for i in x.split(\" \")])\n#train_df[\"labels\"] = train_df[\"labels\"].map(lambda x : x.split(\" \"))\ndata_sample[\"labels\"] = data_sample[\"labels\"].map(lambda x : [class_dict[i] for i in x])\n\ndata_sample.head()\n","64b9f464":"#--------------\n#initialize constants\n#--------------\nHEIGHT,WIDTH = 299,299\nCHANNELS = 3\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nSEED = 143\nSPLIT = int(0.8*len(data_sample))\nAUTO = tf.data.experimental.AUTOTUNE\n\ndef process_img(filepath,label):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label","77712188":"# Spliting sample data to train and valid set\nX_train, X_test, y_train, y_test = train_test_split(data_sample[\"path\"], data_sample['labels'],\n                                                    test_size=0.33, random_state = 12,\n                                                      stratify =  data_sample['labels'] )\n\ntrain_ds = pd.concat([X_train, y_train], axis = 1)\nvalid_ds = pd.concat([X_test, y_test], axis = 1)\n\nfiles_ls = list(train_ds[\"path\"])\nlabels = np.zeros((len(train_ds),num_classes))\n\nfor i,file in enumerate(train_ds.values):\n    labels[i][train_ds.iloc[i][\"labels\"]] = 1\n    \ntrain_ds = tf.data.Dataset.from_tensor_slices((files_ls,labels))\ntrain_ds = train_ds.map(process_img,num_parallel_calls=AUTO)\n\n\nfiles_ls = list(valid_ds[\"path\"])\nlabels = np.zeros((len(valid_ds),num_classes))\n\nfor i,file in enumerate(valid_ds.values):\n    labels[i][valid_ds.iloc[i][\"labels\"]] = 1\n    \nval_ds = tf.data.Dataset.from_tensor_slices((files_ls,labels))\nval_ds = val_ds.map(process_img,num_parallel_calls=AUTO)\n\nprint(\"Nb obs train set:\",len(train_ds))\nprint(\"Nb obs valid set:\",len(val_ds))","4b07b5e5":"#--------------\n#initialize constants\n#--------------\n\nSTEPS_PER_EPOCH  = (len(train_ds))\/\/BATCH_SIZE\nVALID_STEPS = (len(val_ds))\/\/BATCH_SIZE","b986b36a":"train_ds = train_ds.cache().repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO)\nval_ds = val_ds.cache().repeat().batch(BATCH_SIZE).prefetch(AUTO)\nprint(\"Data Pipeline achieved !\")","7cb99c4c":"# Define epochs for each training and scoring metric\nEPOCHS = 5\n\nmetrics = tfa.metrics.F1Score(num_classes = num_classes,average = \"macro\",name = \"f1_score\",\n                             threshold= 0.5)","d49d6bdd":"def compile_model(model, lr=1e-3):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.BinaryCrossentropy()\n        \n    metrics = tfa.metrics.F1Score(num_classes = num_classes,\n                                            average = \"macro\",name = \"f1_score\") \n\n    model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n\n    return model","669842e4":"\n\ndef create_model():\n    pre_trained_model = InceptionV3(input_shape = (HEIGHT,WIDTH, CHANNELS), \n                                  include_top = False, \n                                  weights = \"imagenet\")\n\n  # Setting pretrained model to no trainable\n    pre_trained_model.trainable = False\n\n    last_layer = pre_trained_model.get_layer('mixed7')\n\n    last_output = last_layer.output\n\n    x = layers.GlobalMaxPooling2D()(last_output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)    \n    x = layers.Dense(num_classes, activation='sigmoid',dtype='float32')(x)           \n\n    model = Model( pre_trained_model.input, x )\n    return model","2039e1ef":"\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=1e-3)    \n    \n    history = model.fit(\n                        train_ds,\n                        epochs=EPOCHS,\n                        \n                        validation_data = val_ds,\n                        verbose=VERBOSE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps=VALID_STEPS\n                                           )","1ece3405":"# Plotting accuracy and val loss\nacc = history.history['f1_score']\nval_acc = history.history['val_f1_score']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history['loss']))\n\nplt.figure(figsize=(14, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training f1_score')\nplt.plot(epochs_range, val_acc, label='Validation f1_score')\nplt.legend(loc='lower right')\nplt.title('Training and Validation f1_score')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","7606211a":"model.save('.\/my_model.h5')","62400ccb":"def create_model():\n    pre_trained_model = tf.keras.applications.MobileNetV2(input_shape = (HEIGHT,WIDTH, CHANNELS), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n    # Setting pretrained model to no trainable\n    pre_trained_model.trainable = False\n\n    last_layer = pre_trained_model.get_layer('out_relu')\n    \n    last_output = last_layer.output\n\n    x = layers.GlobalMaxPooling2D()(last_output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)    \n    x = layers.Dense(num_classes, activation='sigmoid',dtype='float32')(x)           \n\n    model = Model( pre_trained_model.input, x )\n    return model","d1e2d302":"tf.keras.backend.clear_session()\n\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=1e-3)\n   \n    \n    \n    history = model.fit(\n                        train_ds,\n                        epochs=EPOCHS,\n                        \n                        validation_data = val_ds,\n                        verbose=VERBOSE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps=VALID_STEPS\n                       )\n                       ","d506fc72":"# Plotting accuracy and val loss\nacc = history.history['f1_score']\nval_acc = history.history['val_f1_score']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history['loss']))\n\nplt.figure(figsize=(14, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training f1_score')\nplt.plot(epochs_range, val_acc, label='Validation f1_score')\nplt.legend(loc='lower right')\nplt.title('Training and Validation f1_score')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","69915647":"def create_model():\n    pre_trained_model = tf.keras.applications.ResNet50(input_shape = (HEIGHT,WIDTH, CHANNELS), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n    # Setting pretrained model to no trainable\n    pre_trained_model.trainable = False\n\n    last_layer = pre_trained_model.get_layer('conv5_block3_out')\n    \n    last_output = last_layer.output\n\n    x = layers.GlobalMaxPooling2D()(last_output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)    \n    x = layers.Dense(num_classes, activation='sigmoid',dtype='float32')(x)           \n\n    model = Model( pre_trained_model.input, x )\n    return model","e0609cb3":"#EPOCHS = 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=1e-3)\n   \n    \n    \n    history = model.fit(\n                        train_ds,\n                        epochs=EPOCHS,\n                        \n                        validation_data = val_ds,\n                        verbose=VERBOSE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps=VALID_STEPS\n                       )\n                       ","3185140f":"# Plotting accuracy and val loss\nacc = history.history['f1_score']\nval_acc = history.history['val_f1_score']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history['loss']))\n\nplt.figure(figsize=(14, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training f1_score')\nplt.plot(epochs_range, val_acc, label='Validation f1_score')\nplt.legend(loc='lower right')\nplt.title('Training and Validation f1_score')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","45f15545":"def model_builder(hp):\n    pre_trained_model = tf.keras.applications.MobileNetV2(input_shape = (HEIGHT,WIDTH, CHANNELS), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n    # Setting pretrained model to no trainable\n    pre_trained_model.trainable = False\n\n    last_layer = pre_trained_model.get_layer('out_relu')\n    \n    last_output = last_layer.output\n\n    x = layers.GlobalMaxPooling2D()(last_output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)    \n    # Tune a drop out layer\n    # Choose an optimal value from 0.0 to 0.5\n    x = layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.2))(x)\n    x = layers.Dense(num_classes, activation='sigmoid',dtype='float32')(x)           \n\n    model = Model( pre_trained_model.input, x )\n\n    # Tune the learning rate for the optimizer\n    # Choose an optimal value from 0.01, 0.001, or 0.0001\n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n\n    loss = tf.keras.losses.BinaryCrossentropy()\n\n    metrics = tfa.metrics.F1Score(num_classes = num_classes,\n                                    average = \"macro\",name = \"f1_score\") \n\n\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n            loss=loss,\n            metrics=[metrics])\n\n    return model\n","7f7cb85f":"import kerastuner as kt\n\ntf.keras.backend.clear_session()\n\ntuner = kt.Hyperband(\n    model_builder,\n    objective= kt.Objective(\"val_f1_score\", direction=\"max\"),\n    max_epochs=10,\n    distribution_strategy=strategy    )","8a2def72":"print(\"Search space summary\")\ntuner.search_space_summary()","a6180823":"tuner.search(train_ds, epochs=5,steps_per_epoch = STEPS_PER_EPOCH,validation_steps = STEPS_PER_EPOCH,\n             validation_data = val_ds)\n\n","2bdd4853":"print(\"Search results summary\")\ntuner.results_summary()","f7e54902":"best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\ndropout = best_hps.get('dropout')\nlr = best_hps.get('learning_rate') ","e4406d1d":"lr","19341e1b":"class_dict = {\n    'scab': 0,\n    'frog_eye_leaf_spot' : 1,\n    'rust' : 2,\n    'complex' : 3,\n    'powdery_mildew' : 4,\n    \"healthy\" : 5\n}\nnum_classes = len(class_dict)    \nclass_names = dict([(value, key) for key, value in class_dict.items()])\ntrain[\"labels\"] = train[\"labels\"].map(lambda x : [i for i in x.split(\" \")])\n#train_df[\"labels\"] = train_df[\"labels\"].map(lambda x : x.split(\" \"))\ntrain[\"labels\"] = train[\"labels\"].map(lambda x : [class_dict[i] for i in x])\n\ntrain[\"path\"] = TRAIN_PATH + train[\"image\"]\n\ntrain.head()","b91d2b1e":"# splitting for a train and valid set\n\nX_train, X_test, y_train, y_test = train_test_split(train[\"path\"], train['labels'], test_size=0.2, random_state = 12,\n                                                      stratify =  train['labels'] )","09a8df3a":"train_ds = pd.concat([X_train, y_train], axis = 1)\nvalid_ds = pd.concat([X_test, y_test], axis = 1)\n\nfiles_ls = list(train_ds[\"path\"])\nlabels = np.zeros((len(train_ds),num_classes))\n\nfor i,file in enumerate(train_ds.values):\n    labels[i][train_ds.iloc[i][\"labels\"]] = 1\n    \ntrain_ds = tf.data.Dataset.from_tensor_slices((files_ls,labels))\ntrain_ds = train_ds.map(process_img,num_parallel_calls=AUTO)\n\n\nfiles_ls = list(valid_ds[\"path\"])\nlabels = np.zeros((len(valid_ds),num_classes))\n\nfor i,file in enumerate(valid_ds.values):\n    labels[i][valid_ds.iloc[i][\"labels\"]] = 1\n    \nval_ds = tf.data.Dataset.from_tensor_slices((files_ls,labels))\nval_ds = val_ds.map(process_img,num_parallel_calls=AUTO)\n\nSTEPS_PER_EPOCH  = (len(train_ds))\/\/BATCH_SIZE\nVALID_STEPS = (len(val_ds))\/\/BATCH_SIZE\n\ntrain_ds = train_ds.cache().repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO)\nval_ds = val_ds.cache().repeat().batch(BATCH_SIZE).prefetch(AUTO)\nprint(\"Data Pipeline achieved !\")","1a998315":"# Create a callback that saves the model's weights\n\ncheckpoint_dir = \".\/raw_model.h5\"\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir,\n                                                 save_weights_only=True,\n                                                 save_best_only=True,\n                                                 verbose=1,\n                                                 monitor= \"val_f1_score\",\n        mode='max')\n\n# Create a callback that stops fitting when val loss do not decrease\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\"val_f1_score\", patience=10, mode='max')\n\nreducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor= \"val_f1_score\",\n        mode='max',\n        factor=0.1,\n        patience=2,\n        verbose=1\n    )\n\ncallbacks=[callback,cp_callback,reducelr]","233181b6":"\n\ndef create_model():\n    pre_trained_model = tf.keras.applications.MobileNetV2(input_shape = (HEIGHT,WIDTH, CHANNELS), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n  # Setting pretrained model to no trainable\n    pre_trained_model.trainable = False\n\n    last_layer = pre_trained_model.get_layer('out_relu')\n\n    last_output = last_layer.output\n\n    x = layers.GlobalMaxPooling2D()(last_output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)   \n    x = layers.Dropout(dropout)(x)\n    x = layers.Dense(num_classes, activation='sigmoid',dtype='float32')(x)           \n\n    model = Model( pre_trained_model.input, x )\n    return model","66c4eb4f":"EPOCHS = 100\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=lr) \n\n    history = model.fit(train_ds,\n            epochs=EPOCHS,\n            validation_data = val_ds,\n            verbose=VERBOSE,\n            steps_per_epoch = STEPS_PER_EPOCH,\n            validation_steps=STEPS_PER_EPOCH,\n            callbacks = callbacks)","7c45193f":"# Plotting accuracy and val loss\nacc = history.history['f1_score']\nval_acc = history.history['val_f1_score']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(history.history['loss']))\n\nplt.figure(figsize=(14, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training f1_score')\nplt.plot(epochs_range, val_acc, label='Validation f1_score')\nplt.legend(loc='lower right')\nplt.title('Training and Validation f1_score')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","55532b1b":"model.load_weights(checkpoint_dir)\n\nmodel.save('.\/my_model.h5')","98159548":"# loading the model\nnew_model = tf.keras.models.load_model('.\/my_model.h5')","ee1e8cf0":"# Taking 9 images as sample\n\ntrain = pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/train.csv\")\n\nfiles_ls = tf.io.gfile.glob(TRAIN_PATH + '*.jpg')\n\nfrom random import sample\n\nfiles_ls_sample = sample(files_ls,9)\n\ntrain[\"path\"] = TRAIN_PATH  +  train[\"image\"]\n\ntest_df = train[train[\"path\"].isin(files_ls_sample)]\n\nprint(\"Sample shape\")\ntest_df.shape\n\n","8ace7871":"test_df.head(9)","80b9fff3":"# preprocessing without labels\n\ndef process_img_test(filepath):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(files_ls_sample)\n    .map(process_img_test\n).batch(BATCH_SIZE)\n)\n\n","200b0b40":"# making predictions\npredicts = new_model.predict(test_dataset) \n\nthreshold = 0.5\n\ndef get_labels(prediction):\n  pred = []\n  idx = np.where(prediction>threshold)[0]\n  for i in idx:\n    pred.append(class_names[i])\n  pred = ' '. join(pred)\n  if len(pred) == 0:\n    pred = []\n    idx = np.argmax(prediction)\n    pred.append(class_names[idx])\n    pred = ' '. join(pred)\n    return pred\n  else :\n    return pred\n\nlabels = []\nfor i in range(len(predicts)):\n  pred = predicts[i]\n\n  labels.append(get_labels(pred))\n    \ntest_df[\"pred\"] = labels","42925af0":"test_df[\"path\"] = \"..\/input\/plant-pathology-2021-fgvc8\/train_images\/\" + test_df[\"image\"]\n\n# Showing image sample\nplt.figure(figsize=(14,9))\nn=1\nfor i in test_df.index :\n    plt.subplot(3,3,n)\n    \n    testImage = img.imread(test_df[\"path\"][i])\n\n    # displaying the image\n    plt.imshow(testImage)\n    color = \"blue\" if test_df[\"pred\"][i] == test_df[\"labels\"][i] else \"red\"\n    \n    plt.title(test_df[\"pred\"][i].title(), color=color)\n    plt.axis(\"off\")\n    n+=1\n_ = plt.suptitle(\"Model predictions on sample set (blue: correct, red: incorrect)\")","7cdb2a21":"### INCEPTION V3","61456f18":"## MOBILNET Tuner\n\nWe will use Keras tuner Hyperband to tune :\n* A dropout layer (as there is clear overfitting)\n* Learning rate\n","82eaa4b2":"### Callbacks","3d17549c":"## Data prep","c2cfe73c":"### MOBILENET","e9e59d10":"# Full data\n\nWe will now train the tuned model on the full dataset","946576c5":"## Split","a94dad93":"Sample dataset seems to have same distribution as full dataset","de22ab17":"## Training ","2e3221e1":"We will use 10% of the full dataset avec use sklearn train_test_split to create our sample.","6acde69d":"## Problem Statement\nPlant Pathology 2021 - FGVC8 is a [Kaggle competition](https:\/\/www.kaggle.com\/c\/plant-pathology-2021-fgvc8) launched on march 15 2021 and closed on mai 27 2021.\n\nExploration notebook can be find on [Kaggle](https:\/\/www.kaggle.com\/xavierbarbier\/plant-pathology-2021-fgvc8-eda) and the [full project on Github](https:\/\/github.com\/xavierbarbier\/Plant_Pathology_2021_FGVC8).\n\nThe goals of this notebook are:\n\n* Use a distributed approach (TPU) to optimise training time\n* Create a sample dataset for training\n* Compare differents pre-trained model\n* Optimise and tune the selected model\n* Train the optimised model on the full dataset","f95f4e22":"## Pre trained models","ad4b2834":"## Data prep","5bd97fe1":"### Keras hyperband tuner","a7161922":"## Pre-trained models conclusion\n\nMobileNet model seems to have better results","e1572171":"### RESNET 50","a04076c0":"# Load data","b8289ae9":"# Create a stratify sample","2fc9b9ed":"We now want to make some prediction on a small sample of images.","5e25469e":"## Showing some predictions","2480c44e":"### Predictions"}}