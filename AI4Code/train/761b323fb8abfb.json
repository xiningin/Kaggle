{"cell_type":{"093288cb":"code","ae998ba8":"code","719ef450":"code","1b2d732f":"code","f430b645":"code","4beb5b30":"code","f6bb7859":"code","27b734b4":"code","26c6b6fd":"code","7007555d":"code","798e17c8":"code","5bc95307":"code","f33f3824":"code","acd8abee":"code","fffd7f91":"code","078c7674":"code","21f001fb":"code","39a4fbc4":"code","a49047d3":"code","fc2b180d":"code","b769f06f":"code","d6923d54":"code","9dc2ca12":"code","b50eb33a":"code","6e4fe2f1":"code","1e950772":"code","db59f5d4":"code","a1cee27c":"code","79a748a8":"code","d2a6a565":"markdown","290751f8":"markdown","c66981d3":"markdown","e43ae344":"markdown","ddb07971":"markdown","cfb967ae":"markdown"},"source":{"093288cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae998ba8":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","719ef450":"df.diagnosis.value_counts()","1b2d732f":"df.columns.values","f430b645":"df.corr()","4beb5b30":"df.isnull().sum()","f6bb7859":"df.drop(['Unnamed: 32'], inplace=True, axis=1)","27b734b4":"df.columns","26c6b6fd":"df.info()","7007555d":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(df['diagnosis'])\ndf['diagnosis'] = le.transform(df['diagnosis'])","798e17c8":"df","5bc95307":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15,10))\nsns.heatmap(df.corr(), annot=True)","f33f3824":"df_new = df[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'radius_se', 'perimeter_se', 'area_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst']]","acd8abee":"X = df.drop(['id','diagnosis'], axis=1)\ny = df[['diagnosis']]","fffd7f91":"X","078c7674":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.3, random_state=42)","21f001fb":"print(X_train.shape, X_valid.shape, X_test.shape)","39a4fbc4":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\nknc = KNeighborsClassifier(n_neighbors=5)\nknc.fit(X_train, y_train)\n\nprint(\"Train Accuracy : \", knc.score(X_train, y_train))\nprint(\"Validation Accuracy : \", knc.score(X_valid, y_valid))\n# print(\"Test Accuracy : \", knc.score(X_test, y_test))","a49047d3":"y_pred_knc = knc.predict(X_test)\nprint(classification_report(y_pred_knc, y_test))","fc2b180d":"accuracy_list = []\nfor i in range(50, 100, 10):\n    model_knn = KNeighborsClassifier(n_neighbors=i)\n    model_knn.fit(X_train, y_train)\n    knn_pred = model_knn.predict(X_test)\n    accuracy_list.append(accuracy_score(knn_pred, y_test))\nplt.figure(figsize=(12,8))\nplt.plot(range(50, 100, 10), accuracy_list)\nplt.title(\"Hasil n_neighbors dari 5 - 10\")\nplt.show()","b769f06f":"knn_best = KNeighborsClassifier(n_neighbors=90)\nknn_best.fit(X_train, y_train)\n\npred_knn_best = knn_best.predict(X_test)\nprint(\"Akurasi knn n_neighbors = 90 \\n\", accuracy_score(pred_knn_best, y_test))","d6923d54":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\n\nprint(\"Train acc : \", svc.score(X_train, y_train))\nprint(\"Val acc : \", svc.score(X_valid, y_valid))","9dc2ca12":"svc_pred = svc.predict(X_test)\nprint(classification_report(svc_pred, y_test))","b50eb33a":"from sklearn.model_selection import GridSearchCV\n\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvc1 = SVC()\nclf = GridSearchCV(svc1, parameters)\nclf.fit(X_train, y_train)","6e4fe2f1":"clf.best_params_","1e950772":"clf.best_score_","db59f5d4":"svc_best = SVC(C=10, kernel='linear')\nsvc_best.fit(X_train, y_train)\n\nprint(\"Train acc : \", svc_best.score(X_train, y_train))\nprint(\"Val acc : \", svc_best.score(X_valid, y_valid))\n\npred_svc_best = svc_best.predict(X_test)\nprint(classification_report(pred_svc_best, y_test))","a1cee27c":"print(accuracy_score(pred_svc_best, y_test))","79a748a8":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(pred_svc_best, y_test))","d2a6a565":"# KNN","290751f8":"# Preprocessing","c66981d3":"# GridSearchCV for SVM","e43ae344":"# Starter","ddb07971":"# SVM","cfb967ae":"# Data Split"}}