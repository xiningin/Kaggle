{"cell_type":{"284f21c8":"code","85ffa016":"code","517ca99d":"code","02f214cd":"code","3565ae44":"code","3ac39983":"code","6cf169b1":"code","0dff1950":"code","9fc44484":"code","15f7f2ba":"code","de25d2e0":"code","8b02f8df":"code","4fb9c8be":"code","46ae2170":"code","e1d3b653":"code","2267f964":"code","77e557d7":"code","4e2f04b8":"code","43859415":"code","244384ea":"code","21ef7615":"code","8ddb4481":"code","fbb9e33a":"code","3ce8abe5":"code","1c37981c":"markdown","46441687":"markdown","5e08649c":"markdown","48329f90":"markdown"},"source":{"284f21c8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","85ffa016":"from glob import glob\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nimport tensorflow as tf\nfrom keras.layers import Dense, Flatten, Input, Lambda\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator","517ca99d":"train_path = \"\/kaggle\/input\/fruits\/fruits-360\/Training\"\nvalidation_path = \"\/kaggle\/input\/fruits\/fruits-360\/Test\"","02f214cd":"# images has both jpeg and jpg file extensions hence fetching all the image path using pattern matching\ntrain_image_files = glob(train_path + '\/*\/*.jp*g')\nvalidation_image_files = glob(validation_path + '\/*\/*.jp*g')\nprint(f\"Total Number of train image files: {len(train_image_files)}\")\nprint(f\"Total Number of validation image files: {len(validation_image_files)}\")","3565ae44":"# Loading the number of folders to get total classes\nfolders = glob(train_path + '\/*')\nk = len(set(folders))\nprint(f\"Total number of classes: {k}\")","3ac39983":"# Diaply a sample image \n\nplt.imshow(image.img_to_array(image.load_img(train_image_files[10])).astype('uint8'))\nplt.show()","6cf169b1":"IMAGE_SIZE = [100, 100]\nEPOCHS = 5\nBATCH_SIZE = 32","0dff1950":"# Initialize the network\n\nresnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","9fc44484":"# freeze the network\n\nfor layer in resnet.layers:\n    layer.trainable = False","15f7f2ba":"# Add dense layer\nx = Flatten()(resnet.output)\npred = Dense(k, activation='softmax')(x)","de25d2e0":"model = Model(inputs = resnet.inputs, outputs = pred)","8b02f8df":"model.compile(optimizer = 'rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])","4fb9c8be":"model.summary()","46ae2170":"# Creating data generator object with the same preprocessing done in the Resnet\ndata_gen = ImageDataGenerator(rotation_range=20,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             shear_range=0.1,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             preprocessing_function=preprocess_input)","e1d3b653":"# Test the data_gen \ntest_gen = data_gen.flow_from_directory(validation_path, target_size=IMAGE_SIZE)\nprint(test_gen.class_indices)","2267f964":"# Extract the labels \n\nlabels = [None] * len(test_gen.class_indices)\nfor k, v in test_gen.class_indices.items():\n      labels[v] = k","77e557d7":"# should be a strangely colored image (due to Resnet weights being BGR)\nfor x, y in test_gen:\n    print(\"min:\", x[0].min(), \"max:\", x[0].max())\n    plt.title(labels[np.argmax(y[0])])\n    plt.imshow(x[0])\n    plt.show()\n    break","4e2f04b8":"train_generator = data_gen.flow_from_directory(train_path,\n                                              target_size=IMAGE_SIZE,\n                                              shuffle=True,\n                                              batch_size=BATCH_SIZE)\n\nvalidation_generator = data_gen.flow_from_directory(validation_path,\n                                             target_size=IMAGE_SIZE,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE)","43859415":"spe = int(len(train_image_files)\/\/BATCH_SIZE)\nval = int(len(validation_image_files)\/\/BATCH_SIZE)\nprint(f\"Training steps per epoch: {spe}\")\nprint(f\"Validation steps per epoch: {val}\")\nprint(f\"Number of epochs: {EPOCHS}\")\nprint(f\"Batch size: {BATCH_SIZE}\")","244384ea":"res = model.fit_generator(train_generator,\n                          validation_data=validation_generator,\n                          epochs=EPOCHS,\n                          steps_per_epoch=spe,\n                          validation_steps= val,\n                          verbose=1)","21ef7615":"from sklearn.metrics import confusion_matrix\n\ndef get_confusion_matrix(data_path, N):\n    # we need to see the data in the same order\n    # for both predictions and targets\n    print(\"Generating confusion matrix\", N)\n    predictions = []\n    targets = []\n    i = 0\n    for x, y in data_gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=BATCH_SIZE * 2):\n        i += 1\n        if i % 1000 == 0:\n            print(i)\n        p = model.predict(x)\n        p = np.argmax(p, axis=1)\n        y = np.argmax(y, axis=1)\n        predictions = np.concatenate((predictions, p))\n        targets = np.concatenate((targets, y))\n        if len(targets) >= N:\n            break\n\n    cm = confusion_matrix(targets, predictions)\n    return cm","8ddb4481":"cm = get_confusion_matrix(train_path, len(train_image_files))\nprint(cm)\nvalidation_cm = get_confusion_matrix(validation_path, len(validation_image_files))\nprint(validation_cm)","fbb9e33a":"# loss\n\nplt.plot(res.history['loss'], label='loss')\nplt.plot(res.history['val_loss'], label='val_loss')\nplt.legend()\nplt.show()\n\n","3ce8abe5":"# accuracies\nplt.plot(res.history['accuracy'], label='acc')\nplt.plot(res.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","1c37981c":"### Load ResNet50 model \n\n- Add the Resnet preprocessing at the front of the network\n- Freeze other trainable network\n- Add Dense layer for K classes with softmax function","46441687":"### Data agumentation for training ","5e08649c":"### Train the model","48329f90":"### Load in the Data"}}