{"cell_type":{"b0a75334":"code","b6f10094":"code","18133c6e":"code","b0af013d":"code","8d51405d":"code","a6c55afc":"code","f7a5d1ec":"code","0b0da48e":"code","210bb83e":"markdown","4a81b422":"markdown","e08c9f69":"markdown"},"source":{"b0a75334":"DATA_PATH = '\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv'","b6f10094":"import pandas as pd\nfrom tqdm import tqdm","18133c6e":"class DecisionNode(object):\n    def __init__(self, feature, value, true_branch, false_branch):\n        self.feature = feature\n        self.value = value\n        self.true_branch = true_branch\n        self.false_branch = false_branch\n        \n    def trace(self, idx=0):\n        print(f'[{idx}] {self.feature} ({self.value})')\n        print(' ' * idx + f'\/ ', end='')\n        self.true_branch.trace(idx+1)\n        print(' ' * idx + f'\\\\ ', end='')\n        self.false_branch.trace(idx+1)\n        \n        \nclass Leaf(object):\n    def __init__(self, sub_df, label_col):\n        self.predictions = sub_df[label_col].value_counts().to_dict()\n        \n    def trace(self, idx=0):\n        final_prediction = max(self.predictions, key=self.predictions.get)\n        print(f'[{idx}]' + str(final_prediction))","b0af013d":"class DecisionTree(object):\n    def __init__(self, data_path, label_col='quality'):\n        self.label_col = label_col\n        self.df = pd.read_csv(data_path)\n        self.feature_cols = self.df.columns.drop(self.label_col)\n        \n    @staticmethod\n    def is_numeric(value):\n        return isinstance(value, int) or isinstance(value, float)\n    \n    def _count_classes(self, sub_df):\n        return sub_df['quality'].value_counts().to_dict()\n    \n    def _get_gini(self, sub_df):\n        ''' https:\/\/en.wikipedia.org\/wiki\/Decision_tree_learning#Gini_impurity\n        '''\n        count_dict = self._count_classes(sub_df)\n        impurity = 1\n        \n        for label, count in count_dict.items():\n            prob = count \/ len(sub_df)\n            impurity -= prob ** 2\n            \n        return impurity\n    \n    def _compute_info_gain(self, left, right, current_uncertainty):\n        p = len(left) \/ (len(left) + len(right))\n        \n        return current_uncertainty - p * self._get_gini(left) - (1 - p) * self._get_gini(right)\n    \n    def _partition(self, sub_df, feature, value):\n        ''' Partitions a dataset\n        '''\n        if self.is_numeric(value):\n            mask = sub_df[feature] >= value\n        else:\n            mask = sub_df[feature] == value\n            \n        return sub_df.loc[mask], sub_df.loc[~mask]\n        \n    \n    def _find_best_split(self, sub_df):\n        best_gain = 0\n        best_feature = None\n        best_value = None\n        current_uncertainty = self._get_gini(sub_df)\n        \n        for feature in self.feature_cols:\n            unique_values = sub_df[feature].unique()\n            \n            for value in unique_values:\n                true_sub_df, false_sub_df = self._partition(sub_df, feature, value)\n                \n                if len(true_sub_df) == 0 or len(false_sub_df) == 0:\n                    continue\n                    \n                gain = self._compute_info_gain(true_sub_df, false_sub_df, current_uncertainty)\n                \n                if gain >= best_gain:\n                    best_gain = gain\n                    best_feature = feature\n                    best_value = value\n                    \n        return best_gain, best_feature, best_value\n    \n    def _build_tree(self, sub_df):\n        gain, best_feature, best_value = self._find_best_split(sub_df)\n        \n        if gain == 0:\n            return Leaf(sub_df, self.label_col)\n        \n        true_sub_df, false_sub_df = self._partition(sub_df, best_feature, best_value)\n        \n        true_branch = self._build_tree(true_sub_df)\n        false_branch = self._build_tree(false_sub_df)\n        \n        return DecisionNode(best_feature, best_value, true_branch, false_branch)\n    \n    def build_tree(self):\n        return self._build_tree(self.df)","8d51405d":"dt = DecisionTree(data_path=DATA_PATH)","a6c55afc":"tree = dt.build_tree()","f7a5d1ec":"tree.trace()","0b0da48e":"# root = tree\n# stack = [root]\n\n# while True:\n#     node = stack[0]\n#     del stack[0]\n\n#     if isinstance(node, DecisionNode):\n#         feature = node.feature\n#         value = node.value\n#         true_branch = node.true_branch\n#         false_branch = node.false_branch\n        \n#         print(feature, value)\n        \n#         stack.append(true_branch)\n#         stack.append(false_branch)\n#     else:\n#         predictions = node.predictions\n        \n#         print(predictions)\n        \n#     if len(stack) == 0:\n#         break","210bb83e":"# Configure hyper-parameters","4a81b422":"# Import libraries","e08c9f69":"# The implementation in this notebook is influenced by https:\/\/www.youtube.com\/watch?v=LDRbO9a6XPU"}}