{"cell_type":{"d1c06970":"code","37d3dded":"code","a4e51f0c":"code","0f412861":"code","50e62a10":"code","975073b0":"code","22f363a5":"code","1f4b2382":"code","98cadb66":"code","65e9dc53":"code","14de11e7":"code","92e616fa":"code","7887bffe":"code","fde45efe":"code","6fbefdc2":"code","399e5675":"code","3d68fcbe":"code","d240318a":"code","2b85a8ca":"code","c96a06b3":"code","3910e163":"code","e8fb892d":"code","3a467d98":"code","6a8701e9":"code","9ab52679":"code","4c7f9038":"code","4719f469":"code","131f5aeb":"code","f82ce6af":"code","855c869e":"code","2730fdef":"code","241b3277":"markdown","0a433712":"markdown","6124c3f6":"markdown","13bd5928":"markdown","18e1b6a5":"markdown","a0ae3582":"markdown"},"source":{"d1c06970":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","37d3dded":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","a4e51f0c":"%matplotlib inline","0f412861":"iris = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\niris.head()","50e62a10":"iris.info","975073b0":"iris.describe()","22f363a5":"sns.pairplot(iris.drop('Id',axis=1))","1f4b2382":"sns.pairplot(iris.drop('Id',axis=1),hue='Species')","98cadb66":"sns.heatmap(iris.isnull(),yticklabels = False,cbar=False,cmap='viridis')","65e9dc53":"# Data cleaning","14de11e7":"iris['Species'] = iris['Species'].replace(\"Iris-setosa\",0).replace(\"Iris-versicolor\",1).replace(\"Iris-virginica\",2)","92e616fa":"iris.drop(\"Id\",axis=1,inplace=True)","7887bffe":"iris.head()","fde45efe":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, classification_report,r2_score,accuracy_score","6fbefdc2":"X = iris.drop('Species',axis=1)\ny = iris['Species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","399e5675":"lr = LinearRegression()\nlr.fit(X_train,y_train)\npredict_lr = lr.predict(X_test)\n\nprint(r2_score(y_test,predict_lr))","3d68fcbe":"logr = LogisticRegression()\nlogr.fit(X_train,y_train)\npredict_logr = logr.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_logr))\nprint(classification_report(y_test,predict_logr))","d240318a":"dt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\npredict_dt = dt.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_dt))\nprint(classification_report(y_test,predict_dt))","2b85a8ca":"rf = RandomForestClassifier(n_estimators = 200)\nrf.fit(X_train,y_train)\npredict_rf = rf.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_rf))\nprint(classification_report(y_test,predict_rf))","c96a06b3":"# K Nearest Neighbor","3910e163":"k =  KNeighborsClassifier(n_neighbors = 1)\nk.fit(X_train,y_train)\npredict_k = k.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_k))\nprint(classification_report(y_test,predict_k))","e8fb892d":"error_rate = []\n\nfor i in range(1,40):\n    k = KNeighborsClassifier(n_neighbors = i)\n    k.fit(X_train,y_train)\n    predict_i = k.predict(X_test)\n    error_rate.append(np.mean(predict_i != y_test))","3a467d98":"plt.figure(figsize=(10,7))\nplt.plot(range(1,40),error_rate, color=\"blue\",linestyle='dashed',marker=\"o\",markerfacecolor='red',markersize=10)","6a8701e9":"knn =  KNeighborsClassifier(n_neighbors = 6)\nknn.fit(X_train,y_train)\npredict_knn = knn.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_knn))\nprint(classification_report(y_test,predict_knn))","9ab52679":"svm = SVC()\nsvm.fit(X_train,y_train)\npredict_svm = svm.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_svm))\nprint(classification_report(y_test,predict_svm))","4c7f9038":"# grid Search","4719f469":"param_grid = {\"C\":[0.1,1,10,100,1000],'gamma':[1,0.1,0.01,0.001,0.0001],'kernel':['linear','poly','rbf','sigmoid']}","131f5aeb":"grid = GridSearchCV(SVC(),param_grid,verbose=3)\ngrid.fit(X_train,y_train)","f82ce6af":"grid.best_params_","855c869e":"grid.best_score_","2730fdef":"predict_grid = grid.predict(X_test)\n\nprint(confusion_matrix(y_test,predict_grid))\nprint(classification_report(y_test,predict_grid))","241b3277":"# Support Vector Machine","0a433712":"# Accuracy of SVM is best compared to other models","6124c3f6":"# Logistic Regression","13bd5928":"# Random Forest","18e1b6a5":"# Decision Tree","a0ae3582":"# Linear Regression"}}