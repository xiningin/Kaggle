{"cell_type":{"8a1d4e0f":"code","edc64834":"code","008ee05e":"code","5271ca71":"code","b6469a66":"code","a3064bfb":"code","8e8b7fa7":"code","022893c2":"code","3c8408fe":"code","f1a41bf8":"code","866768ee":"code","fe9f1433":"code","ee2f2362":"code","2c0adee8":"code","f2937fe4":"code","3cbae231":"code","bbac6cc3":"code","4388b6cc":"code","1f26fb4d":"code","9d330d4a":"code","f29b570b":"code","76fda469":"code","b04c224f":"markdown","7ce32811":"markdown","0dd3b210":"markdown","8092a1b2":"markdown","d7c25d99":"markdown","b74bc1ee":"markdown","e387bc23":"markdown","d9b4d9dc":"markdown","9f579345":"markdown","3addec52":"markdown","32066157":"markdown","7a0d0916":"markdown"},"source":{"8a1d4e0f":"import numpy as np \nimport pandas as pd \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict","edc64834":"iris = pd.read_csv('..\/input\/iris\/Iris.csv')\niris","008ee05e":"# We Dont Need Column Id \niris.drop('Id', axis='columns', inplace=True)","5271ca71":"le = LabelEncoder()\niris['Species'] = le.fit_transform(iris['Species'])","b6469a66":"scaler = StandardScaler()\niris.iloc[:, :4] = scaler.fit_transform(iris.iloc[:, :4])","a3064bfb":"# x Represent Data And y Represent Label\nx = iris.iloc[:, :4]\ny = iris.iloc[:, -1:]","8e8b7fa7":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)","022893c2":"from sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","3c8408fe":"parametr_decision = [{'max_depth':[10,15, 13, 12, 50],'criterion':['entropy', 'gini']}]","f1a41bf8":"de_clf = DecisionTreeClassifier()\ngrid_de = GridSearchCV(de_clf, parametr_decision, cv=3)","866768ee":"grid_de.fit(x_train, y_train)\ngrid_de.best_params_","fe9f1433":"y_predict = grid_de.predict(x_test)\naccuracy_score(y_test, y_predict)","ee2f2362":"de_clf = DecisionTreeClassifier(max_depth=10, criterion='entropy')\nde_clf.fit(x_train, y_train)","2c0adee8":"tree.plot_tree(de_clf)","f2937fe4":"from sklearn.svm import SVC","3cbae231":"parametr_svm = [{'kernel':['rbf', 'poly'],'degree':[2, 3, 4, 5], 'gamma':['auto', 'scale'], 'C':[0.001, 1000]}]","bbac6cc3":"sv_clf = SVC(probability=True)\nsvc_grid = GridSearchCV(sv_clf, parametr_svm)\nsvc_grid.fit(x_train, y_train)","4388b6cc":"y_predict_svm = svc_grid.predict(x_test)\naccuracy_score(y_test, y_predict_svm)","1f26fb4d":"from sklearn.svm import LinearSVC\nlinear = LinearSVC(C=100, loss='hinge')\nlinear.fit(x_train, y_train)\npredict_linear = linear.predict(x_test)\naccuracy_score(y_test, predict_linear)","9d330d4a":"from sklearn.ensemble import VotingClassifier","f29b570b":"voting = VotingClassifier(estimators=[('svm', svc_grid), ('decision', grid_de)], voting='soft')\n\nvoting.fit(x_train, y_train)\n","76fda469":"for clf in (svc_grid, voting, grid_de):\n    clf.fit(x_train, y_train)\n    y_predict = clf.predict(x_test)\n    print(clf.__class__.__name__, accuracy_score(y_test, y_predict))","b04c224f":"3. # Ensemble Learning ","7ce32811":"# Befor We Gothrough We Need To Know Which Hyperparamiter Is Good Use GridsearchCV To Undrestand","0dd3b210":"## TASK2: Conver DataSet To X, y; After That Use Train_test_split For Our Model \n### Let's Do It \n","8092a1b2":"2. ## Support Vector Machine: (support vector machine and logistic regression are binary classification)","d7c25d99":"# For Visualize Gridsearch Not have parameter plot_tree \n## It's Not Neccesary You Do It ","b74bc1ee":"## TIP:\n### In Some Case We Need To Have SimpleImputer And StandardScaler It's Good To Use Pipeline ( Just Work For fit_transform Method )","e387bc23":"## If OverFit Occure reduce parametr C and Gamma ","d9b4d9dc":"* Iris Dataset Is Simple Task For Machine-learning As You Can See It Has 6 Columns And 150 Row That Represent 3 Different of class Each Class Has 50 Instance \n","9f579345":"# You Should Always Try Linear Kernel first , especially if the training set is very larg","3addec52":"# TASK3: Make Model\n1. ## Decision-Tree","32066157":"### **Some Algorithm Need StandardScaler To Have Better Performace (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models)**","7a0d0916":"# Task1: We Must Have 0, 1, 2 In Species Not iris-setosa,....\n\n1. ### We Have Different Way To Change It To Number \n2. ### first you can use simple way iris['Species'][:50] = 0 , iris['Species'][50:100] = 1, iris['Species'][:-50] = 2 \n## TIP:\n3. ### Other Way You Can Use Get_dummies:Convert categorical variable into dummy\/indicator variables        If You Want To Have BinaryClassifier You Must Have 2 Class And Get_dummies Work Fine For That Just 0,1\n\n4. ### Other Way You Can Use Function And Return 0,1,2 If See iris-setosa, iris-verginica, iris-versicolor\n\n5. ### Final Way Use LabelEncode :\n### le = LabelEncoder()\n### le.fit_transform(iris['Species'])"}}