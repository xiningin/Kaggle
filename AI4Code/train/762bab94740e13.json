{"cell_type":{"2836948c":"code","c931fa56":"code","12a745cc":"code","b06f488c":"code","a2979760":"code","2dd00062":"code","4074f926":"code","7269c0ca":"code","d543600e":"code","12b270f5":"code","e62789f6":"code","98c493f9":"code","16d5e240":"code","97eb8cf7":"code","5893f658":"code","fb2748a1":"code","7f4ed814":"code","14702412":"code","a175bd39":"code","fa5e6f23":"code","d5860394":"code","37690cd4":"code","cb68e3a9":"code","85b49e38":"code","a7404cac":"code","21cef49c":"code","aada5e2c":"markdown","7ff1ba1e":"markdown","a997feca":"markdown","372533f0":"markdown","33c489c1":"markdown","8dd9ad58":"markdown","5842592e":"markdown","02c2d3f8":"markdown","28c93b57":"markdown","ab8a45d2":"markdown","a429ecfd":"markdown","6ace0eb1":"markdown","3a1031f4":"markdown","385562f9":"markdown","2540efd3":"markdown","ae0c9e7d":"markdown","f6eb1ce9":"markdown","4917b89e":"markdown","fcf7a795":"markdown"},"source":{"2836948c":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as snb","c931fa56":"# read csv\ndf = pd.read_csv(\"\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","12a745cc":"df.head()","b06f488c":"df.isnull().sum()","a2979760":"\ndf['test preparation course'].value_counts()\n","2dd00062":"mapping = {\"none\" : 0, \"completed\" : 1}\ndf['test preparation course'] = df['test preparation course'].map(mapping)\ndf.head()","4074f926":"import seaborn as sns\nsns.pairplot(data=df,hue='test preparation course',plot_kws={'alpha':0.2},palette='Set1')","7269c0ca":"df = pd.get_dummies(df, columns = ['gender', 'race\/ethnicity', 'parental level of education', 'lunch'],drop_first = True)","d543600e":"df.columns","12b270f5":"df.head()","e62789f6":"#Set the value of the axis parameter to 1\nX= df.drop(\"test preparation course\", axis = 1)\ny = df[\"test preparation course\"]","98c493f9":"# split train test data set\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)","16d5e240":"from sklearn.ensemble import RandomForestClassifier\nRandomForest = RandomForestClassifier(n_estimators = 100, max_features= 10) ","97eb8cf7":"RandomForest.fit(X_Train, y_Train) ","5893f658":"print(\"Accuracy train:\", RandomForest.score(X_Train, y_Train))","fb2748a1":"print(\"Accuracy test:\",RandomForest.score(X_Test, y_Test))","7f4ed814":"predictions = RandomForest.predict(X_Test)","14702412":"from sklearn.metrics import classification_report\nprint(classification_report(y_Test,predictions))","a175bd39":"#from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_Test,predictions)\nfig, ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); ","fa5e6f23":"n_features = X.shape[1]\nplt.barh(range(n_features),RandomForest.feature_importances_)\nplt.yticks(np.arange(n_features),df.columns[1:])","d5860394":"df.head()","37690cd4":"df.columns","cb68e3a9":"df[\"mean_grade\"] = (df[\"math score\"] + df[\"reading score\"] + df[\"writing score\"]) \/ 3\ndf[\"math score_squared\"] = df[\"math score\"] * df[\"math score\"]\ndf[\"reading score_squared\"] = df[\"reading score\"] * df[\"reading score\"]\ndf[\"writing score_squared\"] = df[\"writing score\"] * df[\"writing score\"]","85b49e38":"df.head()","a7404cac":"df.columns","21cef49c":"#X= df[['math score', 'reading score','writing score', 'gender_male','mean_grade', 'math score_squared', 'reading score_squared','writing score_squared']]\nX = df.drop(\"test preparation course\", 1)\ny = df[\"test preparation course\"]\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n# split train test data set\n\nfrom sklearn.model_selection import train_test_split\nX_Train, X_Test, y_Train, y_Test = train_test_split(X, y)\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression() \nmodel.fit(X_Train, y_Train) \n\nprint (model.score(X_Train, y_Train))#score of train\nprint (model.score(X_Test, y_Test))#score to test","aada5e2c":"* get test preparation course values count","7ff1ba1e":"<p>A random forest is* a meta estimator* that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.<\/p>\n\n<code>n_estimators<\/code> <i>integer, optional (default=10)<\/i>  The number of trees in the forest.<br\/>\n\n","a997feca":"* plot the pairplot graph of the original dataset using the target 'test preparation course' as the hue of the graph\n","372533f0":"# Categorical data\npanda.get_dummies is to edit fake variables of strings that you want to put in a tree or random forest.","33c489c1":"# Create x and y\nFor column-based operation\n    ","8dd9ad58":"* Turn categorical values of the target into number","5842592e":" * Score of the training data ","02c2d3f8":"Import libraries","28c93b57":"1. # Another approach - Logistic Regression and polynomial features","ab8a45d2":"* Score of the testing data \n","a429ecfd":"* Classification report of your true labels y_test compared to the predictions","6ace0eb1":"## Random Forest Classifier","3a1031f4":"****Looks like the model is not able to generalise very well on unseen data. Let's investigate more evaluation metrics","385562f9":"* Explore the target\n","2540efd3":"![](http:\/\/)** Predict Using a Random Forest Classifier**\n\n\nWe are using scikit-learn Random Forest Classifier to predict, if a particular student has already completed **test preparation course** .\n\n* So given how well they did in the course, we predict if they did the preparation course before doing the course.","ae0c9e7d":"* Check missing values\n* .<code>isnull()<\/code> and <code>sum()<\/code> is used to find whether there are any missing values in the CSV file.","f6eb1ce9":"# Split train and test ","4917b89e":"**Fit X_Train and y_Train**","fcf7a795":"* Read top few rows from the file using the head() method of Pandas."}}