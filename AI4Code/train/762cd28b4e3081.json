{"cell_type":{"d4c471d8":"code","ba92eabc":"code","3ee2b848":"code","62e5517c":"code","15b2b568":"code","3398fd1d":"code","a9348507":"code","d30a4665":"code","19f4f420":"code","6abf6fea":"code","34719de0":"code","789ce222":"code","25804bc0":"code","f610fe8f":"code","dd81a65b":"code","39a8f87d":"code","d9572d27":"code","e0732d36":"code","5b7553c0":"code","acf9a3c2":"code","2b3cbeeb":"code","0c294105":"code","8b8f744f":"code","77e5dd02":"code","e0e596c0":"code","03ac3a58":"code","6528006e":"code","2015e641":"code","ee035542":"code","e878e8f3":"code","9197b26c":"code","0bf1fc38":"code","b24e5425":"code","7878b0a6":"code","6e5c85e3":"code","0e7e390c":"code","7ff069b4":"code","14dc4a5e":"code","db6318b4":"code","a1086fe6":"code","5ddcf6c0":"code","2861a6bf":"code","e2468625":"code","4b3391af":"code","4ac6a656":"code","f6c146ba":"code","96edd395":"code","63229b33":"code","e9232b5c":"code","392de9e6":"code","4685390e":"code","4a75fb48":"markdown"},"source":{"d4c471d8":"# !pip install git+https:\/\/github.com\/keras-team\/keras-applications.git -q\n\n# import keras_applications as ka\n# def set_to_tf(ka):\n#     from tensorflow.keras import backend, layers, models, utils\n#     ka._KERAS_BACKEND = backend\n#     ka._KERAS_LAYERS = layers\n#     ka._KERAS_MODELS = models\n#     ka._KERAS_UTILS = utils\n    \n    \n# set_to_tf(ka)\n\n!pip install \/kaggle\/input\/keras-pretrained-imagenet-weights\/image_classifiers-1.0.0-py3-none-any.whl\n\nfrom classification_models.tfkeras import Classifiers\nClassifiers.models_names()","ba92eabc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import Model\n# import tensorflow.keras.applications.efficientnet as efn\nfrom tensorflow.keras.applications import *\nimport os\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","3ee2b848":"df = pd.read_csv('..\/input\/nih-dataframe\/NIH_Dataframe.csv')\ndf.img_ind= df.img_ind.apply(lambda x: x.split('.')[0])\ndisplay(df.head(4))\nprint(df.shape)","62e5517c":"target_cols = df.drop(['img_ind'], axis=1).columns.to_list()\nn_classes = len(target_cols)\nimg_size = 600\nn_epochs = 35\nlr= 0.0001\nseed= 11\nval_split= 0.2\nseed= 33\nbatch_size= 32\nn_classes","15b2b568":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n\n'''\nReference\nhttps:\/\/www.kaggle.com\/xhlulu\/ranzcr-efficientnet-tpu-training\n\n'''\n\ndef build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) \/ 255.0 # Casts a tensor to the type float32 and divides by 255.\n        img = tf.image.resize(img, target_size) # Resizing to target size\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO) # overlaps data preprocessing and model execution while training\n    return dset\n","3398fd1d":"DATASET_NAME = \"nih-image-600x600-data\"\nstrategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)","a9348507":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(DATASET_NAME)\nGCS_DS_PATH","d30a4665":"paths = GCS_DS_PATH + \"\/NIH_Images\/\" + df['img_ind'] + '.jpg'\n\n\n#Get the multi-labels\nlabel_cols = df.columns[:-1]\nlabels = df[label_cols].values","19f4f420":"# Train test split\n(train_paths, valid_paths, \n  train_labels, valid_labels) = train_test_split(paths, labels, test_size=val_split, random_state=11)\n\nprint(train_paths.shape, valid_paths.shape)\ntrain_labels.sum(axis=0), valid_labels.sum(axis=0)","6abf6fea":"valid","34719de0":"valid.drop(['index'],inplace=True, axis = 1)","789ce222":"valid","25804bc0":"valid['img_ind'][0]","f610fe8f":"# Build the tensorflow datasets\n\ndecoder = build_decoder(with_labels=True, target_size=(img_size, img_size))\n\n# Build the tensorflow datasets\ndtrain = build_dataset(\n    train_paths, train_labels, bsize=batch_size, decode_fn=decoder\n)\n\ndvalid = build_dataset(\n    valid_paths, valid_labels, bsize=batch_size, \n    repeat=False, shuffle=False, augment=False, decode_fn=decoder\n)","dd81a65b":"data, _ = dtrain.take(2)\nimages = data[0].numpy()","39a8f87d":"fig, axes = plt.subplots(3, 4, figsize=(20,10))\naxes = axes.flatten()\nfor img, ax in zip(images, axes):\n    ax.imshow(img)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","d9572d27":"def build_model():\n    seresnet152, _ = Classifiers.get('seresnet152')\n    base = seresnet152(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n    \n    inp = layers.Input(shape = (img_size, img_size, 3))\n    x= base(inp)\n    x= layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))\n    x= layers.Dropout(0.3)(x)\n    x= layers.Dense(n_classes, 'sigmoid')(x)\n    return Model(inp, x)\n    ","e0732d36":"with strategy.scope():\n    model= build_model()\n    loss= tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n    model.compile(optimizers.Adam(lr=lr),loss=loss,metrics=[tf.keras.metrics.AUC(multi_label=True)])","5b7553c0":"model.summary()","acf9a3c2":"name= 'NIH_Seresnet152_model.h5'\n\nrlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \nckp = ModelCheckpoint(name,monitor = 'val_loss',\n                      verbose = 1, save_best_only = True, mode = 'min')\n        \nes = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                    restore_best_weights = True, verbose = 1)","2b3cbeeb":"steps_per_epoch = (train_paths.shape[0] \/\/ batch_size)\nsteps_per_epoch","0c294105":"ensemble = model.fit(dtrain,                      \n                    validation_data=dvalid,                                       \n                    epochs=1,\n                    callbacks=[rlr,es,ckp],\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1)","8b8f744f":"from keras.models import load_model\nimport cv2\nensemble = load_model('..\/input\/seresnet152-14-diseases-sigmoid\/NIH_Seresnet152_model.h5')","77e5dd02":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot( ensemble.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( ensemble.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","e0e596c0":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot( ensemble.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( ensemble.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","03ac3a58":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"AUC\")\nplt.plot( ensemble.history[\"auc\"], label = \"Training AUC\" , marker='o')\nplt.plot( ensemble.history[\"val_auc\"], label = \"Validation AUC\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","6528006e":"tf.keras.backend.clear_session()\n\nfrom sklearn.metrics import roc_auc_score\n\nmodel= tf.keras.models.load_model(name)\npred= model.predict(dvalid, verbose=1)\n\nprint('AUC CKECK-UP per CLASS')\n\nclasses= df.columns[:-1]\nfor i, n in enumerate(classes):\n  print(classes[i])\n  print(i, roc_auc_score(valid_labels[:, i], pred[:, i]))\n  print('---------')","2015e641":"from keras.models import load_model\nimport cv2\ndenseNet_model = load_model('..\/input\/densenet121-14-diseases-softmax\/Densenet_model.h5')\n# inceptionv2_model = load_model('..\/input\/project-dataset\/InceptionV2.h5')\nmobilenet_model = load_model('..\/input\/project-dataset\/mobilenet.h5')","ee035542":"disease_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]","e878e8f3":"def DensepredictClass(path):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = img\/255\n    img = cv2.resize(img, (256, 256))\n    img = img.reshape((1,256,256,3))\n    return denseNet_model.predict(img)","9197b26c":"def InceptionpredictClass(path):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = img\/255\n    img = cv2.resize(img, (256, 256))\n    img = img.reshape((1,256,256,3))\n    return inceptionv2_model.predict(img)","0bf1fc38":"def mobilepredictClass(path):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = img\/255\n    img = cv2.resize(img, (128, 128))\n    img = img.reshape((1,128,128,3))\n    return mobilenet_model.predict(img)","b24e5425":"disease_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]","7878b0a6":"def classnames(arr):\n    print(arr.size)\n    for i in range(arr.size):\n        print(\"Disease:\", disease_names[i], \" Probability:\",arr[i]*100)","6e5c85e3":"def meanf(arr1, arr2, arr3):\n    for i in range(14):\n        print(\"Disease:\", disease_names[i], \" Probability:\",((arr1[i]+0+arr3[i])\/3) * 100)\n      ","0e7e390c":"def soft_voting(path):\n    x = DensepredictClass(path)\n#     y = InceptionpredictClass(path)\n    z = mobilepredictClass(path)\n#     print(\"\\nDenseNet\")\n#     classnames(x[0])\n#     print(\"\\nInceptionV2\")\n#     classnames(y[0])\n#     print('\\nMobileNet')\n#     classnames(z[0])\n    print('\\nSoft Voting')\n    return meanf(x[0], 0, z[0]) ","7ff069b4":"import cv2","14dc4a5e":"#Prediction\npath = \"..\/input\/data\/images_001\/images\/00000001_000.png\"\n#Prediction\npred_result = soft_voting(path)","db6318b4":"test = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\ntest.head()","a1086fe6":"valid = valid_paths.reset_index()\nvalid.drop(['index'],inplace=True, axis = 1)\nprint(valid)","5ddcf6c0":"valid['img_ind']","2861a6bf":"\ndf = pd.read_csv('..\/input\/nih-dataframe\/NIH_Dataframe.csv')\ndf.img_ind= df.img_ind.apply(lambda x: x.split('.')[0])\ndisplay(df.head(4))\nprint(df.shape)","e2468625":"df = df.reset_index()\ndf.drop(['index'],inplace=True, axis = 1)\ndf.head(2)","4b3391af":"df.set_index('img_ind')\nk = df[['img_ind', \"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural_Thickening\",\"Hernia\"]]\n","4ac6a656":"#prints whole row \ndf.loc[df['img_ind'] == '00000001_001']","f6c146ba":"#print those disease who have 1 \ndiseases = [\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural_Thickening\",\"Hernia\"]\nfor disease in diseases:\n    if df.loc[df['img_ind'] == '00000001_001'][disease][1]:\n        print(disease)","96edd395":"result = []\nfor i in range(2):\n    img = valid['img_ind'][i]\n    img = '..\/input\/nih-image-600x600-data\/NIH_Images\/' + img.split('\/')[-1]\n    result.append(soft_voting(img))\n    ","63229b33":"img = valid['img_ind'][0]\n# img = cv2.imread(img, cv2.IMREAD_COLOR)\n# plt.imshow(img)\nprint(img)","e9232b5c":"img = '..\/input\/nih-image-600x600-data\/NIH_Images\/00014379_003.jpg'\nimg = cv2.imread(img, cv2.IMREAD_COLOR)\nplt.imshow(img)","392de9e6":"l = 'gs:\/\/kds-6ba337acb78b30be6ad828a19720818407a57038a026c41e61df4852\/NIH_Images\/00014379_003.jpg'","4685390e":"l.split('\/')[-1]","4a75fb48":"# For Accuracy"}}