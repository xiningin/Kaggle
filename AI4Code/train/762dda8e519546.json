{"cell_type":{"9fb037e5":"code","d4f31d79":"code","c2c472ab":"code","b9af6f16":"code","abb205c7":"code","aacd5261":"code","9db39b82":"code","aba580c6":"code","f5ac0770":"code","15669c39":"markdown"},"source":{"9fb037e5":"# Imporing Necessary Libraries\nimport torch \nimport numpy as np\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport helper\nimport matplotlib.pyplot as plt\nimport os","d4f31d79":"# Loading the datasets from the folder, and converting the data to greyscale and resizing the data\n\ntransform = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor()])\ntrain_dataset = datasets.ImageFolder('..\/input\/cell_images\/cell_images\/train', transform=transform)\ntest_dataset = datasets.ImageFolder('..\/input\/cell_images\/cell_images\/test', transform=transform)\n","c2c472ab":"# Train loader to make iterator for the images\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)","b9af6f16":"trainloader","abb205c7":"images, labels = next(iter(trainloader))\nimages.shape\n","aacd5261":"images.view(32,-1).shape","9db39b82":"# View the images\nplt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');","aba580c6":"# Defining the model - Multilayer Perceptron with 3 hidden layers, two classes\n\nclass classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(50176,1000)\n        self.fc2 = nn.Linear(1000,500)\n        self.fc3 = nn.Linear(500,100)\n        self.fc4 = nn.Linear(100,2)\n        self.dropout = nn.Dropout(p=0.02)\n     \n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n\n        # Now with dropout\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n\n        # output so no dropout here\n        x = F.log_softmax(self.fc4(x), dim=1)\n\n        return x","f5ac0770":"# Running the model on GPU, finding out the Training loss, Test Loss and the Accuracy\n\ntorch.manual_seed(100)\nmodel = classifier()\ncriterion = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nmodel.to('cuda')\nepochs = 10\nsteps = 0\n\ntrain_losses, test_losses = [], []\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in trainloader:\n        images, labels = images.to('cuda'), labels.to('cuda')\n        optimizer.zero_grad()\n        \n        log_ps = model(images)\n        loss = criterion(log_ps, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n    else:\n        test_loss = 0\n        accuracy = 0\n        \n        # Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n            model.eval()\n            for images, labels in testloader:\n                images, labels = images.to('cuda'), labels.to('cuda')\n                log_ps = model(images)\n                test_loss += criterion(log_ps, labels)\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        model.train()\n        \n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n\n        print(\"Epoch: {}\/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss\/len(trainloader)),\n              \"Test Loss: {:.3f}.. \".format(test_loss\/len(testloader)),\n              \"Test Accuracy: {:.3f}\".format(accuracy\/len(testloader)))","15669c39":"# Malaria Cell Images - MLP\nIn this kernel I have implemented a MLP with stochastic Gradient Descent on Pytorch. The details of the dataset and dataset can be found on\nhttps:\/\/www.kaggle.com\/iarunava\/cell-images-for-detecting-malaria\n\n\nMy MLP is 3 hidden layer network, and the activation fuction used for this model is RELU Function. I have also used early stopping."}}