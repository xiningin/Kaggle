{"cell_type":{"c5c44205":"code","988e6812":"code","122d17a2":"code","de2b6c5b":"code","77cb1157":"code","24988349":"code","c403d406":"code","61562ef4":"code","5baf73b2":"code","ca4c7b0c":"code","7740438e":"code","3356d79e":"code","95a96af3":"code","74d551d1":"code","73256557":"code","d9d32736":"code","4882ca25":"code","34f96179":"code","b8a52a3f":"code","30712983":"code","90ad9a7a":"code","cf68bcf1":"code","c5d02c9f":"code","38ccf178":"code","3998d409":"code","3fd17725":"code","cfd15b72":"code","ac283507":"code","3ae2e6c9":"code","e50beded":"code","3a297722":"code","2433b0a0":"code","06bcfece":"code","9dd78609":"code","c9d66323":"code","a021fd47":"code","cc008fee":"code","891a5960":"code","4833318a":"code","2ef890ee":"code","57e8266c":"code","ca1f2274":"code","484d7644":"code","7263a2c3":"code","9ea5c085":"code","319e80e5":"code","4331c0ef":"code","1ccfe862":"code","962b4b46":"code","318f26fd":"code","b3622b5c":"markdown","fa2e51c6":"markdown","ea7d5d47":"markdown","2d1ee6ae":"markdown","90a1b274":"markdown","d11db6ef":"markdown","2b93da48":"markdown","66c2a677":"markdown","0aeb566e":"markdown","6870e2fb":"markdown","7fa1bd6b":"markdown","1dca6173":"markdown","cb0199c5":"markdown","b5c5f0c7":"markdown","680e12a4":"markdown","8e3a7bb7":"markdown","c1bb2e7c":"markdown","67602d3a":"markdown","97297d48":"markdown","58155209":"markdown","3ee07743":"markdown","6a865d60":"markdown","e0c39a5b":"markdown","9383885e":"markdown","89ebf62f":"markdown","8548547b":"markdown","a26efb43":"markdown","edd68107":"markdown","2624c74c":"markdown","2f8eec6d":"markdown","002bb7c6":"markdown","67efe031":"markdown","2cf4d8de":"markdown","9c1b4875":"markdown","d6998037":"markdown","4d880c00":"markdown","8faa35e3":"markdown","674cfc45":"markdown","40318b84":"markdown"},"source":{"c5c44205":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport json\nfrom urllib.request import urlopen\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","988e6812":"#Read the data\nraw_path = \"\/kaggle\/input\/brazilian-ecommerce\/\"\n\ncustomers = pd.read_csv(raw_path + 'olist_customers_dataset.csv')\ngeolocalization = pd.read_csv(raw_path + 'olist_geolocation_dataset.csv')\norder_items = pd.read_csv(raw_path + 'olist_order_items_dataset.csv')\norder_payments = pd.read_csv(raw_path +'olist_order_payments_dataset.csv')\norder_reviews = pd.read_csv(raw_path +'olist_order_reviews_dataset.csv')\norders=pd.read_csv(raw_path + 'olist_orders_dataset.csv')\nproducts_dataset=pd.read_csv(raw_path + 'olist_products_dataset.csv')\nsellers_dataset=pd.read_csv(raw_path + 'olist_sellers_dataset.csv')\ntranslation=pd.read_csv(raw_path + 'product_category_name_translation.csv')","122d17a2":"#Basic info\ncustomers.info()","de2b6c5b":"customers.head()","77cb1157":"orders.info()","24988349":"orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\norders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\norders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'])\norders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\norders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\norders.info()","c403d406":"# Let's check for missing values\norders.isna().sum()","61562ef4":"# Orders by order_status\norders['order_status'].value_counts()","5baf73b2":"orders[orders['order_approved_at'].isna()]['order_status'].value_counts()","ca4c7b0c":"# Visualize those 14 orders\nfiltro1 = ((orders['order_approved_at'].isna()) & (orders['order_status']=='delivered'))\norders[filtro1]","7740438e":"# modify the value of the field 'order_approved_at' of the records with this filter to the value of the field 'order_purchase_timestamp'.\norders.loc[filtro1, 'order_approved_at'] = orders.loc[filtro1, 'order_purchase_timestamp']","3356d79e":"orders[orders['order_approved_at'].isna()]['order_status'].value_counts()","95a96af3":"orders[orders['order_delivered_carrier_date'].isna()]['order_status'].value_counts()","74d551d1":"#Visualize those 2 orders\nfilter2 = ((orders['order_delivered_carrier_date'].isna()) & (orders['order_status']=='delivered'))\norders[filter2]","73256557":"# modify the value of the field 'order_approved_at' of the records with this filter to the value of the field 'order_approved_at'.\norders.loc[filter2, 'order_delivered_carrier_date'] = orders.loc[filter2, 'order_approved_at']","d9d32736":"orders[orders['order_delivered_carrier_date'].isna()]['order_status'].value_counts()","4882ca25":"orders[orders['order_delivered_customer_date'].isna()]['order_status'].value_counts()","34f96179":"#Visualize those 8 orders\nfilter3 = ((orders['order_delivered_customer_date'].isna()) & (orders['order_status']=='delivered'))\norders[filter3]","b8a52a3f":"orders['carrier_time'] = orders['order_delivered_customer_date'] - orders['order_delivered_carrier_date']","30712983":"avg_carrier_time = orders['carrier_time'].mean()\navg_carrier_time","90ad9a7a":"# modify the value of the field 'order_delivered_customer_date' of the records with this filter to the value of the field 'order_delivered_carrier_date' + avg_carrier_time\n\norders.loc[filter3, 'order_delivered_customer_date'] = orders.loc[filter3, 'order_delivered_carrier_date']+avg_carrier_time\norders.loc[filter3, 'carrier_time'] = avg_carrier_time\norders[filter3]","cf68bcf1":"orders.isna().sum()","c5d02c9f":"# create fields to date and time management (based on purchase time)\norders['year'] = orders['order_purchase_timestamp'].dt.year\norders['month'] = orders['order_purchase_timestamp'].dt.month\norders['day'] = orders['order_purchase_timestamp'].dt.day\norders['weekday'] = orders['order_purchase_timestamp'].dt.dayofweek\norders['day_name'] = orders['order_purchase_timestamp'].dt.day_name()\norders['hour'] = orders['order_purchase_timestamp'].dt.hour\norders['weeknum'] = orders['order_purchase_timestamp'].dt.week\norders['month_year'] = pd.to_datetime(orders['order_purchase_timestamp']).dt.to_period('M').astype(str)\norders['date'] = pd.to_datetime(orders['order_purchase_timestamp']).dt.to_period('D').astype(str)\norders","38ccf178":"fig = px.bar(orders.groupby(\"year\").count().reset_index(), x='year', y='order_id', text='order_id',\n             labels={\"order_id\":\"Number of orders\"},\n             template=\"plotly_dark\",\n              color_discrete_sequence =['green'],             \n             title=\"Number of orders per year\")\n\nfig.update_layout(width=550, height=350)\n\nfig.show()","3998d409":"fig2 = px.bar(orders.groupby(\"month_year\").count().reset_index(), x='month_year', y='order_id', text='order_id',\n             labels={\"orders\":\"Number of orders\", \"mes_a\u00f1o\":\"month-year\"},\n             template=\"plotly_dark\",\n              color_discrete_sequence =['green'],              \n             title=\"Number of orders per month-year\")\n\nfig2.update_layout(width=900, height=500)\n\nfig2.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ]),\n        bgcolor=\"#2D572C\"\n    )\n)\n\nfig2.show()","3fd17725":"fig3 = px.bar(orders.groupby(\"date\").count().reset_index(), x='date', y='order_id', text='order_id',\n             labels={\"orders\":\"Number of orders\", \"date\":\"day\"},\n             template=\"plotly_dark\",\n              color_discrete_sequence =['green'],              \n             title=\"Number of orders per day\")\n\nfig3.update_layout(width=900, height=500)\n\nfig3.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ]),\n        bgcolor=\"#2D572C\"\n    )\n)\n\nfig3.show()","cfd15b72":"fig4 = px.bar(orders.groupby(\"weekday\").count().reset_index(), x='weekday', y='order_id', text='order_id',\n             labels={\"orders\":\"Number of orders\"},\n             template=\"plotly_dark\",\n              color_discrete_sequence =['green'],              \n             title=\"Number of orders per day of week\")\n\nfig4.update_layout(width=700, height=400)\n\nfig4.show()","ac283507":"fig5 = px.bar(orders.groupby(\"hour\").count().reset_index(), x='hour', y='order_id', text='order_id',\n             labels={\"orders\":\"Number of orders\"},\n             template=\"plotly_dark\",\n              color_discrete_sequence =['green'],\n             title=\"Number of orders per hour of the day\")\n\nfig5.update_layout(width=900, height=550)\n\nfig5.show()","3ae2e6c9":"day_hour_df=orders.groupby(['day_name','hour']).agg({'order_id':'count'}).rename(columns={'order_id':'num_orders'}).reset_index()\nday_hour_df","e50beded":"### Sorting it so that the plot order is correct.\nday_hour_df['day_name']=pd.Categorical(day_hour_df['day_name'],categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],ordered=True)\nday_hour_df","3a297722":"day_hour_df=day_hour_df.pivot('day_name','hour','num_orders')","2433b0a0":"day_hour_df","06bcfece":"fig6 = px.imshow(day_hour_df,\n                labels=dict(x=\"Hour of the day\", y=\"Day of the week\"), color_continuous_scale='bugn', template=\"plotly_dark\",)\nfig6.update_xaxes(side=\"top\")\nfig6.show()","9dd78609":"month_day_df=orders.groupby(['month','day_name']).agg({'order_id':'count'}).rename(columns={'order_id':'num_orders'}).reset_index()\n### Sorting it so that the plot order is correct.\nmonth_day_df['day_name']=pd.Categorical(month_day_df['day_name'],categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],ordered=True)\nmonth_day_df","c9d66323":"# pivot the table\nmonth_day_df=month_day_df.pivot('month', 'day_name','num_orders')\nmonth_day_df","a021fd47":"fig7 = px.imshow(month_day_df,\n                labels=dict(xmonth=\"Day of the week\", y=\"Month\"), color_continuous_scale='bugn', template=\"plotly_dark\",)\nfig7.update_xaxes(side=\"top\")\nfig7.show()","cc008fee":"order_items.head()","891a5960":"order_items.describe()","4833318a":"order_items.info()","2ef890ee":"order_items.duplicated().sum()","57e8266c":"order_items.isna().sum()","ca1f2274":"# merging the data\norders = orders.merge(order_items, on='order_id', how=\"left\")\norders","484d7644":"orders_grouped = orders.groupby('order_id').agg({'price':'sum', 'order_item_id': 'count'}).reset_index().rename(columns={'order_item_id':'num_items'}).sort_values(by='num_items')\norders_grouped","7263a2c3":"fig7 = px.bar(orders_grouped.groupby(\"num_items\").count().reset_index(), x=\"num_items\", y=\"order_id\", text=\"order_id\",\n               labels={\"num_items\":\"Number of items\"},\n               template=\"plotly_dark\",\n               color_discrete_sequence =['green'],     \n               title=\"Number of orders per items in the order\")\n\n\nfig7.show()","9ea5c085":"orders.isna().sum()","319e80e5":"filter4 = (orders['order_item_id'].isna())\norders[filter4].groupby('order_status')['order_id'].count()","4331c0ef":"filter5 = ((orders['order_item_id'].isna()) & (orders['order_status']=='shipped') )\norders[filter5]","1ccfe862":"orders = orders.drop(orders[filter5].index)","962b4b46":"filter6 = (orders['order_status'].notna())\norders_grouped2 = orders[filter6].groupby('order_id').agg({'price':'sum', 'order_item_id': 'count'}).reset_index().rename(columns={'order_item_id':'num_items'}).sort_values(by='num_items')\norders_grouped2","318f26fd":"fig8 = px.histogram(orders_grouped2['price'],\n                    nbins=500,\n                    title=\"Distribuci\u00f3n por importe del pedido\", \n                    color_discrete_sequence =['green'],     \n                    template=\"plotly_dark\")\nfig8.update_layout(width=900, height=600)\n\nfig8.update_layout(bargap=0.1)\n\nfig8.show()","b3622b5c":"### 2.2.2. Missing values\nWe start by looking for null values in the Dataframe","fa2e51c6":"Let's start with the orders that have the order_approved_at field empty. All those orders should be in 'created', 'canceled', or 'unavailable' status. Let's check:","ea7d5d47":"When using the day name, we need the grouped dataset to be sorted correctly. For that:","2d1ee6ae":"We pivot the table so that the 24 time slots appear in columns and the days of the week in rows:","90a1b274":"# Data Cleaning","d11db6ef":"We see that 2016 has hardly any orders, 2017 does seem to be whole, and 2018 we don't know if it is whole or not. We will see in the following graphs.\n\nNow we see the distribution by year and month in another bar chart (adding a bottom slider and selector buttons for the period):","2b93da48":"There aren't null values or duplicates in customer's dataset (see customer_unique_id). Nice!","66c2a677":"It seems that the columns refer to this:\n* **`order_status`** --> status of order (delivered, canceled...)\n* **`order_purchase_timestamp`** --> purchase date & time in timestamp format\n* **`order_approved_at`** --> date of purchase approval, can they be denied, for example, because there is no stock?\n* **`order_delivered_carrier_date`** --> date of receipt of the order by the delivery person\n* **`order_delivered_customer_date`** --> date of receipt of the order by the customer\n* **`order_estimated_delivery_date`** --> estimated delivery date of the order\n\nAnd it appears that the status of the order is changing at the stages reported in the 'order_status' field:\n\n* **created** --> the order has just been placed\n* **unavailable** --> order not available... due to out of stock?\n* **approved** --> order approved\n* **processing** --> order under preparation\n* **shipped** --> order shipped, the delivery person has it\n* **delivered** --> order delivered to customer\n* **canceled** --> order canceled\n* **invoiced** --> ?\n\n","0aeb566e":"We can now see some interesting values, such as the amounts of orders and their distribution:","6870e2fb":"At first glance we see a very exaggerated peak around 11\/24\/2017, which corresponds to that year's Black Friday.\n\nLet's look at the distribution by day of the week. If we use the weekday field it shows us the number of day of the week, with 0 on Monday:","7fa1bd6b":"## 2.3. Order Items\nOrder_items is the dataset containing all the items that go on each order. A quick inspection:","1dca6173":"Now let's take a look at the `order_delivered_customer_date` field","cb0199c5":"Let's see the distribution of amounts in a histogram, with a high number of intervals. Once painted, use zoom in to see the lower values.","b5c5f0c7":"We verify that now orders with `order_approved_at` field set to NULL correspond to orders with correct `order_status`.","680e12a4":"Let's continue analyzing the rest of the fields. Now let's look at the `order_delivered_carrier_date` field.","8e3a7bb7":"## 2.2. Orders\nLet's analyze the `orders` table to see what we find and if we need to do some data cleaning (missing_values, etc.).\n\n### 2.2.1. Description","c1bb2e7c":"### 2.2.3. Orders Visualizations\nLet's see some visualizations about the orders data, which will give us information about the orders. Analyzing the orders dataset we can see some interesting data (distributions by dates, times...). For quick visualizations we can use plotly express which allows us to create interactive charts.","67602d3a":"For this single order, we have decided to eliminate it, in case further analysis could cause a problem.","97297d48":"We see growth since November 2017 and that 2018 is not yet complete. \n\nLet's go down one more level by showing the orders per day:","58155209":"## 2.1. Customers","3ee07743":"Let's aggregate this dataset, to see number of items and total price in each order","6a865d60":"Purchases are higher from Monday to Friday. We can go down one more novel and see the distribution by time slots:","e0c39a5b":"The purpose of this notebook is to make an in-depth analysis of ecommerce dataset. \n\n1. Read Data\n2. Data cleaning\n2.1. Customers\n2.2. Orders\n2.3. Order items\n\n","9383885e":"This graph shows the hourly distribution of orders on each day of the week. You can see the difference between the Monday-Friday and weekend hourly distribution.\n\nAnother possible quick analysis is to see if the distribution by day of the week is maintained over the months of the year, or if there is a seasonal difference. Group by month and day of the week","89ebf62f":"First, let's modify all the date field types to datetime:","8548547b":"And now we modify the value of the field `order_delivered_customer_date`.","a26efb43":"There are no duplicates or null values, so no additional processing is required.\n\nLet's merge with the orders table to associate the items to each order","edd68107":"Everything looks correct except for one order in shipped status that has no items.","2624c74c":"El gr\u00e1fico no resulta muy clarificador porque el 2018 no est\u00e1 completo, y vemos que los datos para el mes de septiembre est\u00e1n muy bajos.","2f8eec6d":"We can correct them, and for that we can make a replacement by adding to the delivery date the average delivery time of the rest of the orders. \nWe will have to add a column that is the difference between the date of delivery to the customer and the date of delivery to the delivery person.","002bb7c6":"There are 2 orders in delivered status but without a delivery date. Assuming the same as before, we'll fix them by assigning them the order approval date. \nLet's look at the two orders","67efe031":"There are 8 orders that have an empty customer delivery date but are in 'delivered' status. Let's look at those 8 orders","2cf4d8de":"Indeed, there are null values in several of the columns (order approved, delivery date to delivery person, delivery date to customer). However, these do not seem to be errors, but correspond to the casuistry of the business operations.  \nLet's check that the order statuses are correct according to the delivery dates to the delivery person and to the customer.  ","9c1b4875":"And now we show a heatmap using imshow from Plotly Express","d6998037":"And an even more interesting analysis is to show the distribution of orders by time slot and by day of the week. Let's see:\n\nWe create a Dataframe grouping by day name and time, counting the orders there are.","4d880c00":"We found 14 orders that have been delivered (order_status = 'delivered') but have no approval date. This seems to be an error that we should fix.\n\nTo fix it, for the moment, we can replace the approval date by the order date, as if there was an automatic approval.\n\n**NOTE**: we could check if those 14 orders correspond to a specific case, for example that they are for a specific product for which an approval is required and therefore are not an error. We could also delete them, given the volume of orders in the dataset. However, I prefer to do it this way in order to work with the complete dataset.","8faa35e3":"There are 775 orders that do not have any items. Let's check those orders to see if there is something wrong:","674cfc45":"We now have a clean dataset of orders without inconsistencies.","40318b84":"To create the distribution visualizations by year we use a bar chart, grouping the dataset by the `year` field."}}