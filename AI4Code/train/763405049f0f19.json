{"cell_type":{"eb2cd7a6":"code","eea2cd59":"code","266c8cd3":"code","8a7488c5":"code","613d7257":"code","a9117ff8":"code","7e851e4d":"code","74678829":"code","a2aa4b8e":"code","32f6f85e":"code","18c605de":"code","306a551e":"markdown","99c3b0c4":"markdown","0f685d1c":"markdown","5b5c87ad":"markdown","8c18bf08":"markdown","e881f52e":"markdown","fba0785f":"markdown","007c4d36":"markdown","33ddbb43":"markdown","9f0959e4":"markdown"},"source":{"eb2cd7a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eea2cd59":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","266c8cd3":"dataset = pd.read_csv('\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')\ndataset.head()","8a7488c5":"dataset['workex'].replace(to_replace = 'Yes', value = 1, inplace = True)\ndataset['workex'].replace(to_replace = 'No', value = 0, inplace = True)\ndataset['status'].replace(to_replace = 'Placed', value = 1, inplace = True)\ndataset['status'].replace(to_replace = 'Not Placed', value = 0, inplace = True)\ndataset.head()","613d7257":"data = dataset[['ssc_p', 'hsc_p', 'degree_p', 'etest_p','mba_p', 'status']]\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\ndata.head()","a9117ff8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state =1)","7e851e4d":"    from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)","74678829":"y_pred_train = classifier.predict(X_train)","a2aa4b8e":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_train, y_pred_train)\nprint(cm)\naccuracy_score(y_train, y_pred_train)","32f6f85e":"y_pred_test = classifier.predict(X_test)","18c605de":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_test)\nprint(cm)\naccuracy_score(y_test, y_pred_test)","306a551e":"## Assessing Model Performance on training set","99c3b0c4":"## Encoding the columns with bicategorical data","0f685d1c":"## Training the Kernel SVM model on the Training set","5b5c87ad":"## Importing the libraries","8c18bf08":"## Assessing Model Performance on test set","e881f52e":"## Splitting the dataset into the Training set and Test set","fba0785f":"## Importing the dataset","007c4d36":"## Data Cleaning","33ddbb43":"## Predicting the Training set results","9f0959e4":"## Predicting the generated Test set results"}}