{"cell_type":{"f278b506":"code","35c3118a":"code","4c65c2c8":"code","0e05d7b8":"code","58f35fc6":"code","6bd5f0b6":"code","7590ecc9":"code","ff598627":"code","82bf464b":"code","9754a7ef":"code","9227b548":"markdown","e339c076":"markdown","e8620573":"markdown","64014048":"markdown","cc445b9b":"markdown","13a58207":"markdown","02f3f486":"markdown","e8c14bdb":"markdown","f2d0f4ea":"markdown","721f5a2a":"markdown"},"source":{"f278b506":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","35c3118a":"df = pd.read_csv('\/kaggle\/input\/breast-cancer\/Breast_Cancer.csv')","4c65c2c8":"df.head()","0e05d7b8":"df.info()","58f35fc6":"df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)","6bd5f0b6":"df.dtypes","7590ecc9":"sns.heatmap(df.corr())","ff598627":"X = df.loc[:, df.columns != 'diagnosis']\ny = df.loc[:, 'diagnosis']\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X))","82bf464b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)\n\nlr = LogisticRegression(max_iter=10000)\nlr.fit(X_train, y_train)\npreds = lr.predict(X_test)","9754a7ef":"accuracy_score(y_test, preds)","9227b548":"We can use .dtypes to see that all the remaining features are numerical besides the target column 'diagnosis' so preprocessing is fairly straight forward and will not require any categorical encoding","e339c076":"# Benign or Malignant?  ","e8620573":"# Exploratory Data Analysis","64014048":"The id column shown below is irrelevant to the diagnosis, so we can drop that column","cc445b9b":"We apply standard scaling to the data given that most of the features are heavily skewed","13a58207":"# Feature Engineering","02f3f486":"We split the data into 80% train, 20% test and use a simple Logistic Regression model to fit the data","e8c14bdb":"With .info() below we see that all values of the last column is null so we can drop that column as well. All other features have 569 non-null values and so we do not need to fill in any missing values","f2d0f4ea":"Reading in the data","721f5a2a":"The goal of this notebook is to create a model that predicts whether a tumour is benign or malignant. Here we use a simple Logistic Regression model to fit the data and achieve 99% accuracy.\n\nFirst, we import the necessary libraries "}}