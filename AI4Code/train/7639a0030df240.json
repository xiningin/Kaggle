{"cell_type":{"3011c3d7":"code","ab9a0d27":"code","6687f59c":"code","a28f5ab6":"code","14497ac4":"code","e03a3dc7":"code","24ff651b":"code","284ffa33":"code","cc6444b4":"code","fba3e5e8":"code","a1914bba":"code","5278541c":"code","197b5c7a":"code","6542034c":"code","94393cc5":"code","b874fd63":"code","30b205a4":"code","ad2592d8":"code","f6fdce07":"code","dd0d345b":"code","daf37f25":"code","6fed733e":"code","86992e94":"code","4b662672":"code","625974d3":"code","e1c271ad":"code","1f7a3ee5":"code","b9c9dd34":"markdown","fc37d6b4":"markdown","86ef273d":"markdown","daebc09d":"markdown","c35bedb8":"markdown","84ab728b":"markdown","22c92992":"markdown","d5a917be":"markdown","5c25b8e7":"markdown","3c518c8b":"markdown"},"source":{"3011c3d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ab9a0d27":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport os\n\nfrom shutil import copy, move\nfrom glob import glob as g\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.optim import lr_scheduler \nimport time\nimport matplotlib.pyplot as plt\n\nimport copy\n\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torchvision import datasets, models, transforms\nfrom torchvision.models import resnet18","6687f59c":"batch_size =64\n\nnum_class =10\nnum_epochs=20\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nval_loss = []\ntrain_loss = []\nval_acc = []\ntrain_acc = []","a28f5ab6":"train_cane_dir = '..\/Output\/dataset\/training\/cane'\ntrain_cavallo_dir = '..\/Output\/dataset\/training\/cavallo'\ntrain_elefante_dir = '..\/Output\/dataset\/training\/elefante'\ntrain_gallina_dir = '..\/Output\/dataset\/training\/gallina'\ntrain_gatto_dir = '..\/Output\/dataset\/training\/gatto'\ntrain_mucca_dir = '..\/Output\/dataset\/training\/mucca'\ntrain_pecora_dir = '..\/Output\/dataset\/training\/pecora'\ntrain_ragno_dir = '..\/Output\/dataset\/training\/ragno'\ntrain_scoiattolo_dir = '..\/Output\/dataset\/training\/scoiattolo'\ntrain_farfalla_dir = '..\/Output\/dataset\/training\/farfalla'\n\ntest_cane_dir = '..\/Output\/dataset\/test\/cane'\ntest_cavallo_dir = '..\/Output\/dataset\/test\/cavallo'\ntest_elefante_dir = '..\/Output\/dataset\/test\/elefante'\ntest_gallina_dir = '..\/Output\/dataset\/test\/gallina'\ntest_gatto_dir = '..\/Output\/dataset\/test\/gatto'\ntest_mucca_dir = '..\/Output\/dataset\/test\/mucca'\ntest_pecora_dir = '..\/Output\/dataset\/test\/pecora'\ntest_ragno_dir = '..\/Output\/dataset\/test\/ragno'\ntest_scoiattolo_dir = '..\/Output\/dataset\/test\/scoiattolo'\ntest_farfalla_dir = '..\/Output\/dataset\/test\/farfalla'\nto_create = [\n    train_cane_dir ,\n    train_cavallo_dir ,\n    train_elefante_dir ,\n    train_gallina_dir,\n    train_gatto_dir,\n    train_mucca_dir ,\n    train_pecora_dir,\n    train_ragno_dir,\n    train_scoiattolo_dir,\n    train_farfalla_dir,\n    test_cane_dir,\n    test_cavallo_dir,\n    test_elefante_dir,\n    test_gallina_dir ,\n    test_gatto_dir ,\n    test_mucca_dir ,\n    test_pecora_dir ,\n    test_ragno_dir,\n    test_scoiattolo_dir,\n    test_farfalla_dir\n]\nfor dir in to_create:\n    os.makedirs(dir,exist_ok=True)","14497ac4":"all_cane = sorted(g(\"..\/input\/animals10\/raw-img\/cane\/*\"))\nall_cavallo = sorted(g(\"..\/input\/animals10\/raw-img\/cavallo\/*\"))\nall_elefante = sorted(g(\"..\/input\/animals10\/raw-img\/elefante\/*\"))\nall_farfalla= sorted(g(\"..\/input\/animals10\/raw-img\/farfalla\/*\"))\nall_gallina= sorted(g(\"..\/input\/animals10\/raw-img\/gallina\/*\"))\nall_gatto = sorted(g(\"..\/input\/animals10\/raw-img\/gatto\/*\"))\nall_mucca= sorted(g(\"..\/input\/animals10\/raw-img\/mucca\/*\"))\nall_pecora = sorted(g(\"..\/input\/animals10\/raw-img\/pecora\/*\"))\nall_ragno= sorted(g(\"..\/input\/animals10\/raw-img\/ragno\/*\"))\nall_scoiattolo= sorted(g(\"..\/input\/animals10\/raw-img\/scoiattolo\/*\"))","e03a3dc7":"print(len(all_cane))\nprint(len(all_cavallo))\nprint(len(all_elefante))\nprint(len(all_farfalla))\nprint(len(all_gallina))\nprint(len(all_gatto))\nprint(len(all_mucca))\nprint(len(all_pecora))\nprint(len(all_ragno))\nprint(len(all_scoiattolo))","24ff651b":"cane_train, cane_test = train_test_split(all_cane, test_size = 0.2, random_state = 101, shuffle = True)\n\ncavallo_train, cavallo_test = train_test_split(all_cavallo, test_size = 0.2, random_state = 101, shuffle = True)\n\nelefante_train, elefante_test = train_test_split(all_elefante, test_size = 0.2, random_state = 101, shuffle = True)\n\nfarfalla_train, farfalla_test = train_test_split(all_farfalla, test_size = 0.2, random_state = 101, shuffle = True)\n\ngallina_train, gallina_test = train_test_split(all_gallina, test_size = 0.2, random_state = 101, shuffle = True)\n\ngatto_train, gatto_test = train_test_split(all_gatto, test_size = 0.2, random_state = 101, shuffle = True)\n\nmucca_train, mucca_test = train_test_split(all_mucca, test_size = 0.2, random_state = 101, shuffle = True)\n\npecora_train, pecora_test = train_test_split(all_pecora, test_size = 0.2, random_state = 101, shuffle = True)\n\nragno_train, ragno_test = train_test_split(all_ragno, test_size = 0.2, random_state = 101, shuffle = True)\n\nscoiattolo_train,scoiattolo_test = train_test_split(all_scoiattolo, test_size = 0.2, random_state = 101, shuffle = True)","284ffa33":"from shutil import copy, move\nfor name in tqdm(cane_train):\n    copy(name , os.path.join(train_cane_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(cavallo_train):\n    copy(name , os.path.join(train_cavallo_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(elefante_train):\n    copy(name , os.path.join(train_elefante_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(gallina_train):\n    copy(name , os.path.join(train_gallina_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(gatto_train):\n    copy(name , os.path.join(train_gatto_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(mucca_train):\n    copy(name , os.path.join(train_mucca_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(pecora_train):\n    copy(name , os.path.join(train_pecora_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(ragno_train):\n    copy(name , os.path.join(train_ragno_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(farfalla_train):\n    copy(name , os.path.join(train_farfalla_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(scoiattolo_train):\n    copy(name , os.path.join(train_scoiattolo_dir , name.split('\/')[-1]))","cc6444b4":"print(len(os.listdir(train_cane_dir)))\nprint(len(os.listdir(train_cavallo_dir)))\nprint(len(os.listdir(train_elefante_dir)))\nprint(len(os.listdir(train_gallina_dir)))\nprint(len(os.listdir(train_gatto_dir)))\nprint(len(os.listdir(train_mucca_dir)))\nprint(len(os.listdir(train_pecora_dir)))\nprint(len(os.listdir(train_ragno_dir)))\nprint(len(os.listdir(train_scoiattolo_dir)))\nprint(len(os.listdir(train_farfalla_dir)))","fba3e5e8":"for name in tqdm(cane_test):\n    copy(name , os.path.join(test_cane_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(cavallo_test):\n    copy(name , os.path.join(test_cavallo_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(elefante_test):\n    copy(name , os.path.join(test_elefante_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(gallina_test):\n    copy(name , os.path.join(test_gallina_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(gatto_test):\n    copy(name , os.path.join(test_gatto_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(mucca_test):\n    copy(name , os.path.join(test_mucca_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(pecora_test):\n    copy(name , os.path.join(test_pecora_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(ragno_test):\n    copy(name , os.path.join(test_ragno_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(farfalla_test):\n    copy(name , os.path.join(test_farfalla_dir , name.split('\/')[-1]))\n    \nfor name in tqdm(scoiattolo_test):\n    copy(name , os.path.join(test_scoiattolo_dir , name.split('\/')[-1]))","a1914bba":"print(len(os.listdir(test_cane_dir)))\nprint(len(os.listdir(test_cavallo_dir)))\nprint(len(os.listdir(test_elefante_dir)))\nprint(len(os.listdir(test_gallina_dir)))\nprint(len(os.listdir(test_gatto_dir)))\nprint(len(os.listdir(test_mucca_dir)))\nprint(len(os.listdir(test_pecora_dir)))\nprint(len(os.listdir(test_ragno_dir)))\nprint(len(os.listdir(test_scoiattolo_dir)))\nprint(len(os.listdir(test_farfalla_dir)))","5278541c":"train_dir = '..\/Output\/dataset\/training'\ntest_dir = '..\/Output\/dataset\/test'","197b5c7a":"transform = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),transforms.ToTensor()])\ntrain_dataset = torchvision.datasets.ImageFolder(root=train_dir,transform=transform)\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=64)\n\ndef get_mean_and_std(dataloader):\n    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n    for data, _ in dataloader:\n        # Mean over batch, height and width, but not over the channels\n        channels_sum += torch.mean(data, dim=[0,2,3])\n        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n        num_batches += 1\n    \n    mean = channels_sum \/ num_batches\n\n    # std = sqrt(E[X^2] - (E[X])^2)\n    std = (channels_squared_sum \/ num_batches - mean ** 2) ** 0.5\n    \n    \n    std=std.tolist()\n    mean=mean.tolist()\n    return mean, std\nmean, std=get_mean_and_std(train_dataloader)","6542034c":"print(f\"mean:{mean},std:{std}\")\n","94393cc5":"def get_data_loader(data_dir, batch_size,mean,std ,train = True):\n    \"\"\"\n    Define the way we compose the batch dataset including the augmentation for increasing the number of data\n    and return the augmented batch-dataset\n    :param data_dir: root directory where the either train or test dataset is\n    :param batch_size: size of the batch\n    :param train: true if current phase is training, else false\n    :return: augmented batch dataset\n    \"\"\"\n\n    # define how we augment the data for composing the batch-dataset in train and test step\n    transform = {\n        'train': transforms.Compose([\n            transforms.Resize([224,224]), # Resizing the image \n            transforms.RandomHorizontalFlip(), # Flip the data horizontally\n            #TODO if it is needed, add the random crop\n            transforms.ToTensor(),\n            transforms.Normalize(mean=mean, std=std)\n        ]),\n        'test': transforms.Compose([\n            transforms.Resize([224,224]),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=mean, std=std)\n        ])\n    }\n\n    # ImageFloder with root directory and defined transformation methods for batch as well as data augmentation\n    data = torchvision.datasets.ImageFolder(root=data_dir, transform=transform['train'] if train else 'test')\n    data_loader = torch.utils.data.DataLoader(dataset=data, batch_size=batch_size, shuffle=True, num_workers=4)\n\n    return data_loader\n\n","b874fd63":"train_dir = '..\/Output\/dataset\/training'\ntest_dir = '..\/Output\/dataset\/test'\n\ntrain_loader = get_data_loader(train_dir,batch_size,mean,std)\ntest_loader = get_data_loader(test_dir,batch_size,mean,std)","30b205a4":"train_loader_size=0\nfor image , labels in train_loader:\n\n    train_loader_size+=image.shape[0]\nprint(train_loader_size)","ad2592d8":"test_loader_size=0\nfor image , labels in test_loader:\n\n    test_loader_size+=image.shape[0]\nprint(test_loader_size)","f6fdce07":"net = resnet18(pretrained=False)\nnet.fc = nn.Linear(512, 10)\nnet = net.to(device)","dd0d345b":"def count_parameters(model):\n    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return params\/1000000","daf37f25":"count_parameters(net)","6fed733e":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01,\n                      momentum=0.9, weight_decay=5e-4)","86992e94":"import copy\ndef train_model(model, dataloaders,riterion, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train',\"val\"]:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/dataloaders_size[phase]\n            epoch_acc = running_corrects.double() \/dataloaders_size[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            info_loss_plot[phase].append(round(epoch_loss,4))\n            info_acc_plot[phase].append(round(epoch_acc.item(),4))\n\n#             deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts =copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","4b662672":"exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\ndataloaders_dict={\"train\":train_loader,\"val\":test_loader}\ndataloaders_size={\"train\":train_loader_size,\"val\":test_loader_size}\ninfo_loss_plot={\"train\":train_loss,\"val\":val_loss }\ninfo_acc_plot={\"train\":train_acc,\"val\":val_acc}","625974d3":"model_ft= train_model(net, dataloaders_dict, criterion, exp_lr_scheduler, num_epochs=num_epochs)","e1c271ad":"plt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss\")\nplt.plot(val_loss,label=\"val loss\")\nplt.plot(train_loss,label=\"train loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","1f7a3ee5":"plt.figure(figsize=(10,5))\nplt.title(\"Training and Validation acc\")\nplt.plot(val_acc,label=\"val acc\")\nplt.plot(train_acc,label=\"train acc\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","b9c9dd34":"# **Config**","fc37d6b4":"# **Dataset**","86ef273d":"**Get mean and std**","daebc09d":"# **Initialization** ","c35bedb8":"# **Model**","84ab728b":"# train_test_split","22c92992":"#  **Trainer**","d5a917be":"# **Import**","5c25b8e7":"# **plot**","3c518c8b":"# Data Loader"}}