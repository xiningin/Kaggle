{"cell_type":{"a1ad130e":"code","8e3dc5c2":"code","6ee9d3f9":"code","0984154f":"code","6ef6ef05":"code","b5981cc4":"code","d601c655":"code","50af4650":"code","9f9abab3":"code","0aa5a84c":"code","d507c513":"code","881287f8":"code","2ffba680":"code","11770494":"code","c46f05d7":"code","a10a8645":"code","a6d05ab7":"code","427d76da":"code","2da3d43b":"code","6812ad97":"code","5a8373dc":"code","c1fd82b9":"code","dc91629c":"code","26f6e99d":"code","77cd90bf":"code","c007947d":"code","b93ee449":"code","548aca62":"code","a2b81390":"code","41af49f4":"code","b60081df":"code","1b8a3113":"code","34c30818":"code","2beb6867":"code","23ad17a4":"markdown","f52e0f42":"markdown","3b506865":"markdown","3e875345":"markdown","6d729344":"markdown","07f0f212":"markdown","0a1e90bb":"markdown","5a48da9c":"markdown","9b01efa7":"markdown","f4b9f203":"markdown","15ea3065":"markdown","a9bda7b1":"markdown","42883f15":"markdown"},"source":{"a1ad130e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf","8e3dc5c2":"# load training data\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","6ee9d3f9":"print(f'There are {train_data.shape[0]} rows and {train_data.shape[1]} columns')","0984154f":"train_data.head()","6ef6ef05":"# Separate features X (independent variables) and target\/label y (dependent variable)\nX_train = train_data.values[:, 1:]\ny_train = train_data.values[:, 0]","b5981cc4":"# the value range of X\nX_train.min(), X_train.max()","d601c655":"# the array shape of a single data (image)\nX_train[0].shape","50af4650":"np.sqrt(784)","9f9abab3":"idx = 10\n\n# reshape the image data into 2D array, and plot the image\nplt.imshow(X_train[idx].reshape(28,28), cmap=plt.cm.binary);\n\n# show the label of the corresponding image\ny_train[idx]","0aa5a84c":"# count and show the number of data for each label\/target y\nsns.countplot(y_train);","d507c513":"# normalizing features (pixels)\nX_train = X_train \/ 255.0\n\n# one-hot-encoding target (digit 0-9)\ny_train = tf.keras.utils.to_categorical(y_train)","881287f8":"y_train","2ffba680":"def build_model():\n    tf.keras.backend.clear_session()\n\n    # define a model\n    model = tf.keras.Sequential()\n\n    # add the first convolution layer\n    model.add(tf.keras.layers.Convolution2D(filters = 16, kernel_size = (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n\n    # add the first pooling layer\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n\n    # add regularization\n    model.add(tf.keras.layers.Dropout(0.3))\n\n    # add the second convolution layer\n    model.add(tf.keras.layers.Convolution2D(filters = 16, kernel_size = (3,3), activation = 'relu'))\n\n    # add the second pooling layer\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n\n    # add regularization\n    model.add(tf.keras.layers.Dropout(0.3))\n\n    # flatten the array (from 2D to 1D)\n    model.add(tf.keras.layers.Flatten())\n\n    # add the first fully-connected-layer\n    model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n\n    # add the second fully-connected-layer\n    model.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n\n    # add the output layer\n    model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))\n\n    # compile the model\n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n    \n    return model","11770494":"# show the network architecture\nmodel = build_model()\nmodel.summary()","c46f05d7":"# create train and validation data\nfrom sklearn.model_selection import train_test_split\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=9999)","a10a8645":"# reshape data to fit Keras's input configuration (rank 4 tensor: (rows, pixel, pixel, channel))\n\nX_tr = X_tr.reshape(X_tr.shape[0], 28, 28, 1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1)","a6d05ab7":"# define early stopping\nearlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\n# fit the model and save the information in history\nhistory = model.fit(\n    X_tr,\n    y_tr,\n    batch_size = 64,\n    epochs = 100,\n    validation_data = (X_val, y_val),\n    callbacks = [earlystop])","427d76da":"# plot history\nfig, ax = plt.subplots(1, 2, figsize=(18,6))\nax[0].plot(history.history['loss'], label='train')\nax[0].plot(history.history['val_loss'], label='valid')\nax[1].plot(history.history['acc'], label='train')\nax[1].plot(history.history['val_acc'], label='valid')\nax[0].set_title('Loss')\nax[1].set_title('Accuracy')\nax[0].legend(); ax[1].legend();","2da3d43b":"results = model.evaluate(X_val, y_val, batch_size=64)\nprint(f\"valid loss: {results[0]}, valid acc: {round(results[1]*100,2)}%\")","6812ad97":"# get probabilities\nprobabilities = model.predict(X_val)\n\n# get the prediction class\ny_pred = np.argmax(probabilities, axis=1)","5a8373dc":"# pick random data\nidx = np.random.randint(0, X_val.shape[0], 32)\n\nfig, ax = plt.subplots(4, 8, figsize=(18,12))\nk = 0\nfor i in range(4):\n    for j in range(8):\n        x = X_val[idx[k]]\n        y = np.argmax(y_val[idx[k]])\n        ypred = y_pred[idx[k]]\n        ax[i,j].imshow(x.reshape(28,28), cmap = plt.cm.binary)\n        ax[i,j].set_title(f'pred:{ypred} ---- truth:{y}')\n        ax[i,j].axis('off')\n        k += 1    \nplt.tight_layout()","c1fd82b9":"# get Convolution and Pooling layers\nlayer_number = [0,1,3,4]\nlayers = [model.layers[i].output for i in layer_number]\n\n# get the layer names\nlayer_names = [model.layers[i].name for i in layer_number]\n\n# define visualization model\nviz_model = tf.keras.models.Model(inputs = model.input, outputs = layers)","dc91629c":"# define a sample input image\nidx = 16\nxviz = X_val[idx].reshape(1,28,28,1)\nyviz = y_val[idx]\n\n# get feature maps for the image\nfeature_maps = viz_model.predict(xviz)","26f6e99d":"# merge feature maps for each layer\n\nfeats = []\nfor i, name in enumerate(layer_names):\n    N = feature_maps[i].shape[-1]\n    size = feature_maps[i].shape[1]\n    ll = [feature_maps[i][:,:,:,j].reshape(size,size) for j in range(N)]\n    feats.append(np.hstack(ll))\n\n# plot the feature maps\nfig, ax = plt.subplots(len(layer_names), 1, figsize=(18,2*len(layer_names)))\nfor i, (name, feat) in enumerate(zip(layer_names,feats)):\n    ax[i].axis('off')\n    ax[i].set_title(name)\n    ax[i].imshow(feat)","77cd90bf":"# get probabilities\nprobabilities = model.predict(xviz)","c007947d":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\nax[0].imshow(xviz.reshape(28,28), cmap = plt.cm.binary)\nax[0].set_title(f'truth: {np.argmax(yviz)} --- prediction: {np.argmax(probabilities)}')\nax[0].axis('off')\nax[1].set_xlabel('digit')\nax[1].set_ylabel('probability')\nsns.barplot(np.arange(10), probabilities[0], ax=ax[1]);\ndf = pd.DataFrame({'digit': range(10), 'probability (%)': probabilities[0]*100})\ndf.sort_values(['probability (%)'], ascending=False)","b93ee449":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nX_test = test.values \/ 255.0\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","548aca62":"test.head()","a2b81390":"test.shape","41af49f4":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\ndef kfold_validation(X_train, y_train, X_test, n_folds=5, seed=9999):\n    \n    # Kfold split\n    kf = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = seed)\n\n    # Create oof sets for prediction storage.\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_folds))\n    \n    # Save all models validation accuracy\n    folds_acc = []\n    \n    # Define early stopping\n    earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n    \n    # Reshape data to fit Keras's input configuration (rank 4 tensor: (rows, pixel, pixel, channel))\n    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n        \n    for ifold, (train_index, valid_index) in enumerate(kf.split(X=X_train, y=y_train)):\n        assert len(np.intersect1d(train_index, valid_index)) == 0, '\\\n        Train and test indices must not overlap.'\n        \n        print('Running on Dataset: {}'.format(ifold + 1))\n\n        # Create train and validation sets based on KFold indices.\n        X_tr = X_train[train_index,:]\n        X_val = X_train[valid_index,:]\n        y_tr = y_train[train_index]\n        y_val = y_train[valid_index]\n\n        # Reshape data to fit Keras's input configuration (rank 4 tensor: (rows, pixel, pixel, channel))\n        X_tr = X_tr.reshape(X_tr.shape[0], 28, 28, 1)\n        X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n\n        # one-hot-encoding target (digit 0-9)\n        y_tr = tf.keras.utils.to_categorical(y_tr)\n        y_val = tf.keras.utils.to_categorical(y_val)\n\n        # Restart model\n        model = build_model()\n        \n        # Train model\n        model.fit(\n            X_tr,\n            y_tr,\n            batch_size = 64,\n            epochs = 100,\n            validation_data = (X_val, y_val),\n            verbose = 0,\n            callbacks = [earlystop])\n\n        # Evaluation\n        results = model.evaluate(X_val, y_val, batch_size=64)\n        print(f\"valid loss: {results[0]}, valid acc: {round(results[1]*100,2)}%\\n\")\n        \n        # Prediction on validation data and store them in oof (out of folds) sets\n        oof_train[valid_index] = np.argmax(model.predict(X_val), axis=1)\n        oof_test[:, ifold] = np.argmax(model.predict(X_test), axis=1)\n        \n        # Save accuracy\n        folds_acc.append(accuracy_score(np.argmax(y_val, axis=1), oof_train[valid_index]))\n             \n    print('Mean KFold ACC: {:.4f}'.format(round(np.mean(folds_acc)*100,2)))\n    print('Std KFold ACC: {:.4f}'.format(round(np.std(folds_acc)*100,2)))\n\n    return oof_train, oof_test","b60081df":"y_train = train_data.values[:, 0]\noof_train, oof_test = kfold_validation(X_train, y_train, X_test)","1b8a3113":"# final prediction (average)\nfinal_pred = np.mean(oof_test, axis=1)\nfinal_pred.shape","34c30818":"# build data frame\ndf = pd.DataFrame({\"ImageId\": range(1,28001), \"Label\": np.round(final_pred).astype('int16')})\ndf.head()","2beb6867":"# submission\ndf.to_csv(\"pred.csv\", index=False)","23ad17a4":"## Load Train Data","f52e0f42":"## Check History","3b506865":"## Exploratory Data Analysis","3e875345":"## Build CNN Model","6d729344":"# Visualize The Layers","07f0f212":"## Submit The Prediction","0a1e90bb":"## Load Test Data","5a48da9c":"## Import Necessary Packages","9b01efa7":"## Train Model (Single Validation)","f4b9f203":"## Evaluation on Validation Data","15ea3065":"## Train Models (Cross Validation)","a9bda7b1":"## Out of Folds (OOF) Prediction","42883f15":"## Data Preprocessing"}}