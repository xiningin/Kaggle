{"cell_type":{"da01edf1":"code","5191677f":"code","81cbdc95":"code","0c62c493":"markdown"},"source":{"da01edf1":"import json\nimport numpy as np \nimport os\nimport pandas as pd \n","5191677f":"counter = 0\ncounter_errors = 0\n# for debugging, change counter_max to 10\ncounter_max = 9999999999\n\nall_data = []\n\n# walk the input files\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    if counter >= counter_max or counter_errors >= counter_max:\n        break\n    for filename in filenames:\n        if counter >= counter_max:\n            break\n# for v19 just look in pdf_json folder - no HTML tables in other folders\n        if \"pdf_json\" in dirname:  # debug and \"000b0174f992cb326a891f756d4ae5531f2845f7\" in filename:\n#             print(os.path.join(dirname, filename))\n            try:\n                with open(os.path.join(dirname, filename), 'rb') as f:\n                    each_paper_dict = json.load(f)\n#             print(each_paper_dict['ref_entries'])\n\n#find each key: ref_entries, type: table, key: html\n                for ref_id, ref_object in each_paper_dict['ref_entries'].items():\n                    if \"html\" in ref_object:\n                        counter = counter + 1\n#                     print('html table: ' + str(ref_object['text']) + ' found in: ' + os.path.join(dirname, filename))\n\n# read the html code into a pandas df\n                        each_data = pd.read_html(ref_object['html'])\n# insert some reference columns\n                        each_data[0].insert(0, 'Table Title' , str(ref_object['text']))\n                        each_data[0].insert(0, 'Table Name' , str(ref_id))\n                        each_data[0].insert(0, 'File Path', dirname)\n                        each_data[0].insert(0, 'File Name', filename)\n# concatenate with prior table data\n                        all_data.append(each_data[0])\n            except Exception as e:\n                print('Error thrown while reading file: ' + os.path.join(dirname, filename) + ' | ' + str(e) )\n                counter_errors = counter_errors + 1\n\nall_data = pd.concat(all_data, axis=0, ignore_index=True, sort=False)\n","81cbdc95":"\n# read CORD-19 metadata, explode sha (delimited by ;) onto rows\nmetadata_df = pd.read_csv(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv\", usecols = ['cord_uid', 'sha'], low_memory = False)\nmetadata_df = metadata_df.assign(sha=metadata_df['sha'].str.split(';')).explode('sha')\nmetadata_df['sha'] = metadata_df['sha'].str.strip()\n\n# debug\n# metadata_df = metadata_df[metadata_df['sha'].str.contains(\"000b0174f992cb326a891f756d4ae5531f2845f7\", na = False)]\n# print(metadata_df)\n\n# derive sha from File Name (without extension)\nall_data['sha'] = all_data['File Name'].str.replace('.json', '')\n\ncombined_df = all_data.merge(metadata_df, how=\"left\", left_on=['sha'], right_on=['sha'])\n              \n#finish by writing out a concatenated CSV file                      \ncombined_df.to_csv(\"CORD-19 HTML table data.csv\", index=False)\n# print(combined_df)\n\nprint(\"Finished! Found: \" + str(counter) + \" HTML tables in CORD-19, wrote a CSV file with: \" + \n      str(len(all_data.index)) + \" rows of table data. Errors found in \" + str(counter_errors) + \" input files - see above for details\" )            \n","0c62c493":"# CORD-19 HTML table data\n\nThis notebooks attempts to extract the HTML table data which was added to the CORD-19 dataset at v19 2020-05-14.\n\nWhat's new:\n* 2020-10-15 03:30 UTC - refreshed for CORD-19 v57 2020-10-12.\n* 2020-07-17 01:00 UTC - added error handling for corrupted files.\n* 2020-06-06 14:00 UTC - added cord_uid from CORD-19 metadata."}}