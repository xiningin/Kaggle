{"cell_type":{"b5b9d14d":"code","4a37bb85":"code","6f4d5219":"code","73d54deb":"code","c0d46e45":"code","a7fead67":"code","a6fadfe8":"code","a2b4eab7":"code","28149f29":"code","e534b567":"code","e3d94f31":"code","3b312aa8":"code","ca370fb5":"code","713e2603":"code","245bb389":"code","e4f36fd4":"code","df75d06a":"code","aafdf11c":"code","f3b7d41e":"code","fe8ffdad":"code","cb58dff3":"code","cc4e63df":"code","dcc88d7b":"code","d746eba7":"code","7ce7f4f9":"code","ecb4202e":"code","f9832f75":"code","9635a314":"code","c3d78a2b":"code","6721e4dc":"code","8b3b8c5f":"code","7a5191bd":"code","06ef7b68":"code","bc91930e":"code","4fa87466":"code","f0d9fa89":"markdown","b7f52954":"markdown","a54e7448":"markdown","ce3b7145":"markdown","0907b08e":"markdown","e2647d1d":"markdown","63490fff":"markdown","c16c6839":"markdown","180941e3":"markdown","9aa4dcbf":"markdown"},"source":{"b5b9d14d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a37bb85":"!pip install imutils","6f4d5219":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport os\nimport cv2","73d54deb":"print(os.listdir(\"..\/input\"))","c0d46e45":"imagePaths = list(paths.list_images('..\/input\/concrete-cracks-mendley'))\nprint(\"Total Images\",len(imagePaths))\nPositiveimagePaths = list(paths.list_images('..\/input\/concrete-cracks-mendley\/Positive'))\nprint(\"Positive Images\",len(PositiveimagePaths))\nNegativeimagePaths = list(paths.list_images('..\/input\/concrete-cracks-mendley\/Negative'))\nprint(\"Negative Images\",len(NegativeimagePaths))","a7fead67":"from skimage.color import rgb2gray\nfrom skimage.filters import median\nfrom skimage.morphology import disk\nfrom scipy import ndimage\n\ndef sobel_filters(img):\n    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n    \n    Ix = ndimage.filters.convolve(img, Kx)\n    Iy = ndimage.filters.convolve(img, Ky)\n    \n    G = np.hypot(Ix, Iy)\n    G = G \/ G.max() * 255\n    theta = np.arctan2(Iy, Ix)\n    \n    return (G, theta)\n\n","a6fadfe8":"?bilater","a2b4eab7":"img=cv2.imread(PositiveimagePaths[3])\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nfrom skimage.filters import laplace\n#noise removal\nblur_img=median(img_gray,disk(3))\nblur_img = np.array(blur_img,dtype=np.uint8)\n#s = np.array(s,dtype=np.uint8)\n# Image smoothing: bilateral filter\nbilateral = cv2.bilateralFilter(blur_img, 5, 75, 75)\n# Canny edge detection\nedges = cv2.Canny(bilateral,100,220)\nplt.imshow(edges,cmap='gray')","28149f29":"import matplotlib.pyplot as plt\nk=1\nplt.figure(figsize=(16,16))\nsub=\"20\"\nfor x in range(0,5):\n  for y in range(0,4):\n    plt.subplot(5,4,k)\n    plt.title('Image'+str(k))\n    img=cv2.imread(PositiveimagePaths[k])\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    #noise removal\n    blur_img=median(img_gray,disk(3))\n    #blur_img = np.array(blur_img,dtype=np.uint8)\n    # Image smoothing: bilateral filter\n    bilateral = cv2.bilateralFilter(blur_img, 5, 75, 75)\n    # Canny edge detection\n    edges = cv2.Canny(bilateral,100,220)\n    plt.imshow(edges,cmap='gray')\n    k+=1","e534b567":"import matplotlib.pyplot as plt\nk=1\nplt.figure(figsize=(16,16))\nsub=\"20\"\nfor x in range(0,5):\n  for y in range(0,4):\n    plt.subplot(5,4,k)\n    plt.title('Image'+str(k))\n    img=cv2.imread(NegativeimagePaths[k])\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    #noise removal\n    blur_img=median(img_gray,disk(3))\n    #blur_img = np.array(blur_img,dtype=np.uint8)\n    # Image smoothing: bilateral filter\n    bilateral = cv2.bilateralFilter(blur_img, 5, 75, 75)\n    # Canny edge detection\n    edges = cv2.Canny(bilateral,100,220)\n    plt.imshow(edges,cmap='gray')\n    k+=1","e3d94f31":"data = []\nlabels = []","3b312aa8":"print(\"[INFO] loading images...\")\n# loop over the image paths\ni=0\nfor imagePath in PositiveimagePaths:\n    # label\n    label =\"with\"\n\n    # load the input image (224x224) and preprocess it\n    image = load_img(imagePath, target_size=(224, 224))\n    image = img_to_array(image)\n    image = preprocess_input(image)\n#     img=cv2.imread(imagePath)\n#     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     #noise removal\n#     blur_img=median(img_gray,disk(3))\n#     #blur_img = np.array(blur_img,dtype=np.uint8)\n#     # Image smoothing: bilateral filter\n#     bilateral = cv2.bilateralFilter(blur_img, 5, 75, 75)\n#     # Canny edge detection\n#     edges = cv2.Canny(bilateral,100,220)\n#     edges = cv2.cvtColor(edges,cv2.COLOR_GRAY2RGB)\n#     # update the data and labels lists, respectively\n    data.append(image)\n    labels.append(label)\n    i+=1\n    if(i==3000):\n        break","ca370fb5":"print(\"[INFO] loading images...\")\n# loop over the image paths\ni=0\nfor imagePath in NegativeimagePaths:\n    # label\n    label =\"without\"\n\n    # load the input image (224x224) and preprocess it\n    image = load_img(imagePath, target_size=(224, 224))\n    image = img_to_array(image)\n    image = preprocess_input(image)\n#     img=cv2.imread(imagePath)\n#     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     #noise removal\n#     blur_img=median(img_gray,disk(3))\n#     #blur_img = np.array(blur_img,dtype=np.uint8)\n#     # Image smoothing: bilateral filter\n#     bilateral = cv2.bilateralFilter(blur_img, 5, 75, 75)\n#     # Canny edge detection\n#     edges = cv2.Canny(bilateral,100,220)\n#     edges = cv2.cvtColor(edges,cv2.COLOR_GRAY2RGB)\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append(label)\n    i+=1\n    if(i==3000):\n        break","713e2603":"len(data)","245bb389":"# convert the data and labels to NumPy arrays\ndata = np.array(data, dtype=\"float32\")\nlabels = np.array(labels)","e4f36fd4":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)","df75d06a":"labels","aafdf11c":"# construct the training image generator for data augmentation\naug = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")","f3b7d41e":"(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, stratify=labels, random_state=42)","fe8ffdad":"from tensorflow.keras.applications import VGG16\n# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\nbaseModel = VGG16(weights='..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,\n    input_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n    layer.trainable = False","cb58dff3":"INIT_LR = 1e-4\nEPOCHS = 14\nBS = 32","cc4e63df":"trainX.shape","dcc88d7b":"trainY","d746eba7":"print(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ 10)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit(\n    aug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) \/\/ BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ BS,\n    epochs=10)","7ce7f4f9":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\ntrainlabels=[]\nfor x,y in trainY:\n    if(x==1):\n        trainlabels.append(0)\n    else:\n        trainlabels.append(1)\n        \ntestlabels=[]\nfor x,y in testY:\n    if(x==1):\n        testlabels.append(0)\n    else:\n        testlabels.append(1)\n\nfrom sklearn.metrics import confusion_matrix,f1_score\nprint(confusion_matrix(testlabels, predIdxs))\nprint(\"f1_score\",f1_score(testlabels, predIdxs))\n  ","ecb4202e":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nimport tensorflow.keras.layers as layers\n# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\nbaseModel = InceptionV3(weights='..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = layers.Flatten()(baseModel.output)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False","f9832f75":"print(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ 10)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit(\n    aug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) \/\/ BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ BS,\n    epochs=10)","9635a314":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\ntrainlabels=[]\nfor x,y in trainY:\n    if(x==1):\n        trainlabels.append(0)\n    else:\n        trainlabels.append(1)\n        \ntestlabels=[]\nfor x,y in testY:\n    if(x==1):\n        testlabels.append(0)\n    else:\n        testlabels.append(1)\n\nfrom sklearn.metrics import confusion_matrix,f1_score\nprint(confusion_matrix(testlabels, predIdxs))\nprint(\"f1_score\",f1_score(testlabels, predIdxs))\n  ","c3d78a2b":"model.save(\"crack_model.model\",save_format='h5')","6721e4dc":"data=[]\ntest_image_path=list(paths.list_images('..\/input\/cracks-validation'))\nprint(test_image_path)\nfor imagePath in test_image_path:\n\t# load the input image (224x224) and preprocess it\n\timage = load_img(imagePath, target_size=(224, 224))\n\timage = img_to_array(image)\n\timage = preprocess_input(image)\n\t# update the data and labels lists, respectively\n\tdata.append(image)","8b3b8c5f":"len(data)","7a5191bd":"data=np.array(data,dtype='float32')","06ef7b68":"pred=model.predict(data, batch_size=32)\npred = np.argmax(pred, axis=1)","bc91930e":"pred","4fa87466":"import matplotlib.pyplot as plt\nk=1\nimagenumber=6\nplt.figure(figsize=(16,16))\nsub=\"20\"\nfor x in range(0,3):\n  for y in range(0,2):\n    plt.subplot(3,2,k)\n    s=\"\"\n    if(pred[imagenumber]==0):\n      s=\"Crack\"\n      c='r'\n    else:\n      s=\"NO Crack!!\"\n      c='g'\n    pob=plt.title(s)\n    plt.setp(pob,color=c)\n    t=plt.imread(test_image_path[imagenumber])\n    plt.imshow(t)\n    k+=1\n    imagenumber+=1","f0d9fa89":"![image.png](attachment:image.png)","b7f52954":"# Canny Edge Detection ","a54e7448":"Preprocessing for visualixatin","ce3b7145":"# Inception v3","0907b08e":"# Loading Paths","e2647d1d":"# Preprocessing ","63490fff":"# Training\n# Transfer learning\nIt is an optimization that allows rapid progress or improved performance when modeling the second task. Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned.\nThe basic premise of transfer learning is simple: take a model trained on a large dataset and transfer its knowledge to a smaller dataset. For object recognition with a CNN, we freeze the early convolutional layers of the network and only train the last few layers which make a prediction. The idea is the convolutional layers extract general, low-level features that are applicable across images \u2014 such as edges, patterns, gradients \u2014 and the later layers identify specific features within an image such as eyes or wheels.\n# VGG16","c16c6839":"![image.png](attachment:image.png)","180941e3":"**We got 6\/6 , That looks good.**","9aa4dcbf":"# Testing on unknown data "}}