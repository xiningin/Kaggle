{"cell_type":{"247db50b":"code","f5f40ae3":"code","2984cb58":"code","2bb09abc":"code","23cd225c":"code","3fd55c2f":"code","02bca141":"code","2c95c7db":"code","6376aaae":"code","beaae6f9":"code","5297a448":"code","025353f8":"code","2de30a8f":"code","4f5b74d5":"code","72c64d87":"code","4270bbff":"code","454005e5":"code","7b9ad16a":"code","3db37408":"code","993856fb":"code","bdab3f55":"code","b84f1faf":"code","e3053ade":"code","d5fb2dbf":"code","43be83ce":"code","52102856":"code","f91893a9":"code","dbfe1940":"code","5de485bc":"code","78e73d13":"code","5804d976":"code","6ed56437":"code","35e42569":"code","bb6cf31d":"markdown","5c9cf5c7":"markdown"},"source":{"247db50b":"!pip install -q deeptables[gpu]","f5f40ae3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15,15\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split,StratifiedShuffleSplit,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score,accuracy_score ,confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import ClusterCentroids , NearMiss\n\nfrom tqdm.notebook import tqdm ,tnrange\nimport deeptables\nfrom deeptables.models.deeptable import DeepTable, ModelConfig\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler , EarlyStopping\nimport tensorflow as tf\nfrom keras import backend as K","2984cb58":"train_data = pd.read_csv('..\/input\/healthcareanalyticsii\/train.csv')\ntest_data = pd.read_csv('..\/input\/healthcareanalyticsii\/test.csv')","2bb09abc":"print(train_data.shape)\ntrain_data.head()","23cd225c":"print(test_data.shape)\ntest_data.head()","3fd55c2f":"def nullColumns(train_data):\n    list_of_nullcolumns =[]\n    for column in train_data.columns:\n        total= train_data[column].isna().sum()\n        try:\n            if total !=0:\n                print('Total Na values is {0} for column {1}' .format(total, column))\n                list_of_nullcolumns.append(column)\n        except:\n            print(column,\"-----\",total)\n    print('\\n')\n    return list_of_nullcolumns\n\n\ndef percentMissingFeature(data):\n    data_na = (data.isnull().sum() \/ len(data)) * 100\n    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n    return data_na\n\n\ndef plotMissingFeature(data_na):\n    f, ax = plt.subplots(figsize=(15, 12))\n    plt.xticks(rotation='90')\n    if(data_na.empty ==False):\n        sns.barplot(x=data_na.index, y=data_na)\n        plt.xlabel('Features', fontsize=15)\n        plt.ylabel('Percent of missing values', fontsize=15)\n        plt.title('Percent missing data by feature', fontsize=15)","02bca141":"print('train data')\nprint(nullColumns(train_data))\nprint(percentMissingFeature(train_data))\nprint('\\n')\nprint('test_data')\nprint(nullColumns(test_data))\nprint(percentMissingFeature(test_data))","2c95c7db":"stay = train_data.loc[:,\"Stay\"].value_counts().rename('Count')\nplt.xlabel(\"Stay\")\nplt.ylabel('Count')\nsns.barplot(stay.index , stay.values).set_title('Stay')","6376aaae":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(3, 2, figsize=(15, 15))\n\nradiotherapy = train_data[train_data.Department =='radiotherapy'][\"Stay\"].value_counts().rename('Count')\n\nanesthesia = train_data[train_data.Department =='anesthesia'][\"Stay\"].value_counts().rename('Count')\n\ngynecology = train_data[train_data.Department =='gynecology'][\"Stay\"].value_counts().rename('Count')\n\nsurgery = train_data[train_data.Department =='surgery'][\"Stay\"].value_counts().rename('Count')\n\ntb = train_data[train_data.Department =='TB & Chest disease'][\"Stay\"].value_counts().rename('Count')\n\nsns.barplot(radiotherapy.index,radiotherapy,  color=\"b\", ax=axes[0, 0]).set_title('Department : radiotherapy')\n\nsns.barplot(anesthesia.index,anesthesia,   color=\"r\", ax=axes[0, 1]).set_title('Department : anesthesia')\n\nsns.barplot(gynecology.index,gynecology,  color=\"g\", ax=axes[1, 0]).set_title('Department : gynecology')\n\nsns.barplot(surgery.index,surgery, color=\"m\", ax=axes[1, 1]).set_title('Department : surgery')\n\nsns.barplot(tb.index,tb, color=\"m\", ax=axes[2, 0]).set_title('Department : TB & Chest disease')\n\nsns.barplot(stay.index,stay, color=\"m\", ax=axes[2, 1]).set_title('Department : ALL')\n\nplt.xlabel(\"Stay\")\n\nplt.setp(axes,yticks = np.arange(0,50000,5000))\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()\n","beaae6f9":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(6, 2, figsize=(15, 15))\n\nstay0 = train_data[train_data.Stay =='0-10'][\"Department\"].value_counts().rename('Count')\n\nstay1 = train_data[train_data.Stay =='11-20'][\"Department\"].value_counts().rename('Count')\n\nstay2 = train_data[train_data.Stay =='21-30'][\"Department\"].value_counts().rename('Count')\n\nstay3 = train_data[train_data.Stay =='31-40'][\"Department\"].value_counts().rename('Count')\n\nstay4 = train_data[train_data.Stay =='41-50'][\"Department\"].value_counts().rename('Count')\n\nstay5 = train_data[train_data.Stay =='51-60'][\"Department\"].value_counts().rename('Count')\n\nstay6 = train_data[train_data.Stay =='61-70'][\"Department\"].value_counts().rename('Count')\n\nstay7 = train_data[train_data.Stay =='71-80'][\"Department\"].value_counts().rename('Count')\n\nstay8 = train_data[train_data.Stay =='81-90'][\"Department\"].value_counts().rename('Count')\n\nstay9 = train_data[train_data.Stay =='91-100'][\"Department\"].value_counts().rename('Count')\n\nstay10 = train_data[train_data.Stay =='More than 100 Days'][\"Department\"].value_counts().rename('Count')\n\nsns.barplot(stay0.index,stay0,  color=\"b\", ax=axes[0, 0]).set_title('Stay : 0-10')\n                   \nsns.barplot(stay1.index,stay2,  color=\"r\", ax=axes[0, 1]).set_title('Stay : 11-20')\n\nsns.barplot(stay2.index,stay2,  color=\"b\", ax=axes[1, 0]).set_title('Stay : 21-30')\n\nsns.barplot(stay3.index,stay3,  color=\"g\", ax=axes[1, 1]).set_title('Stay : 31-40')\n\nsns.barplot(stay4.index,stay4,  color=\"b\", ax=axes[2, 0]).set_title('Stay : 41-50')\n\nsns.barplot(stay5.index,stay5,  color=\"b\", ax=axes[2, 1]).set_title('Stay : 51-60')\n\nsns.barplot(stay6.index,stay6,  color=\"m\", ax=axes[3, 0]).set_title('Stay : 61-70')\n\nsns.barplot(stay7.index,stay7, color=\"b\", ax=axes[3, 1]).set_title('Stay : 71-80')\n\nsns.barplot(stay8.index,stay8,  color=\"b\", ax=axes[4, 0]).set_title('Stay : 81-90')\n\nsns.barplot(stay9.index,stay9,  color=\"g\", ax=axes[4, 1]).set_title('Stay : 91-100')\n\nsns.barplot(stay10.index,stay10, color=\"r\", ax=axes[5, 0]).set_title('Stay : >100')\n\nplt.setp(axes, yticks = np.arange(0,20000,5000))\n\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()","5297a448":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(3, 1, figsize=(15, 15))\n\nemergency = train_data[train_data['Type of Admission'] =='Emergency'][\"Stay\"].value_counts().rename('Count')\n\ntrauma = train_data[train_data['Type of Admission'] =='Trauma'][\"Stay\"].value_counts().rename('Count')\n\nurgent = train_data[train_data['Type of Admission'] =='Urgent'][\"Stay\"].value_counts().rename('Count')\n\nsns.barplot(emergency.index,emergency,  color=\"b\", ax=axes[0]).set_title('Admn. Type : Emergency')\n\nsns.barplot(trauma.index,trauma,   color=\"r\", ax=axes[1]).set_title('Admn. Type : Trauma')\n\nsns.barplot(urgent.index,urgent,  color=\"g\", ax=axes[2]).set_title('Admn. Type : Urgent')\n\nplt.setp(axes, yticks = np.arange(0,50000,10000))\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()","025353f8":"train_data['City_Code_Patient'] = train_data['City_Code_Patient'].fillna(-1)\ntrain_data['Bed Grade'] = train_data['Bed Grade'].fillna(-1)","2de30a8f":"test_data['City_Code_Patient'] = test_data['City_Code_Patient'].fillna(-1)\ntest_data['Bed Grade'] = test_data['Bed Grade'].fillna(-1)","4f5b74d5":"cat_cols = ['Hospital_code','Hospital_type_code','City_Code_Hospital','Hospital_region_code'\n            ,'Department','Ward_Type','Ward_Facility_Code','Bed Grade','City_Code_Patient',\n           # 'Type of Admission','Severity of Illness',\n            'Age']","72c64d87":"label = 'Stay'","4270bbff":"def encode_cat_cols(train, test, cat_cols): #target\n\n    train_df = train_data.copy()\n    \n    test_df = test_data.copy()\n    \n    # Making a dictionary to store all the labelencoders for categroical columns to transform them later.\n    \n    le_dict = {}\n\n    for col in cat_cols:\n        \n        le = LabelEncoder()\n        \n        le.fit(train_df[col].unique().tolist() + test_df[col].unique().tolist())\n        \n        train_df[col] = le.transform(train_df[[col]])\n        \n        test_df[col] = le.transform(test_df[[col]])\n\n        le_dict[col] = le\n\n    le = LabelEncoder()\n    \n    train_df[label] = le.fit_transform(train_df[[label]])\n    \n    le_dict[label] = le\n    \n    train_df['Type of Admission'] = train_df['Type of Admission'].map({'Urgent':0,'Emergency':1,'Trauma':2})\n    \n    train_df['Severity of Illness'] = train_df['Severity of Illness'].map({'Minor':0,'Moderate':1,'Extreme':2})\n    \n    test_df['Type of Admission'] = test_df['Type of Admission'].map({'Urgent':0,'Emergency':1,'Trauma':2})\n    \n    test_df['Severity of Illness'] = test_df['Severity of Illness'].map({'Minor':0,'Moderate':1,'Extreme':2})\n    \n    return train_df, test_df, le_dict","454005e5":"def feature_importance(model, X_train):\n\n    print(model.feature_importances_)\n    \n    names = X_train.columns.values\n    \n    ticks = [i for i in range(len(names))]\n    \n    plt.bar(ticks, model.feature_importances_)\n    \n    plt.xticks(ticks, names,rotation = 90)\n    \n    plt.show()","7b9ad16a":"train_df, test_df, le_dict = encode_cat_cols(train_data,test_data,cat_cols)","3db37408":"#After Feature Engineering\n# https:\/\/www.kaggle.com\/gcspkmdr\/lets-get-rid-of-the-patients-feature-engineering\n\ncombined_data = pd.read_csv('..\/input\/lets-get-rid-of-the-patients-feature-engineering\/combined.csv')","993856fb":"train_df = combined_data[combined_data['train']==1]\n\ntest_df = combined_data[combined_data['train']==0]","bdab3f55":"train_df.drop(columns = ['case_id','train','patientid','Hospital_code',\n                         'Hospital_type_code','City_Code_Hospital','Ward_Facility_Code'],inplace = True)\n\ntarget = train_df.pop('Stay')\n\ntest_df.drop(columns = ['case_id','train','Stay','patientid','Hospital_code',\n                        'Hospital_type_code','City_Code_Hospital','Ward_Facility_Code'],inplace = True)","b84f1faf":"cat_features = ['Hospital_region_code','Department','Ward_Type','Bed Grade','City_Code_Patient','Type of Admission','Severity of Illness','Age']\n\ntarget = target.astype('category') # you have to tell deep table architecture that your target is categorical otherwise it will treat the problem as one of regression","e3053ade":"sns.heatmap(train_df.corr())","d5fb2dbf":"# Model Parameters\n\nepochs = 100  #keeping this high as i am using lr scheduler\n\nbatch_size = 256\n\nseeds = [32,432 ,73]\n\n#Callbacks\n\nearly_stop = EarlyStopping(monitor='val_loss', patience = 5 ,restore_best_weights= True)\n\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) #for plateau","43be83ce":"def build_model():\n    \n    conf = ModelConfig(dnn_params={'hidden_units':((300, 0.3, True),(300, 0.3, True),), #hidden_units\n                                'dnn_activation':'relu',},\n                            fixed_embedding_dim=True,\n                            embeddings_output_dim=20,\n                            nets =['dcn_nets'],\n                            stacking_op = 'add',\n                            output_use_bias = False,\n                            metrics=['accuracy'],\n                            categorical_columns = cat_features,\n                       home_dir = None\n                        )\n    dt = DeepTable(config = conf)\n    \n    return dt","52102856":"%%time\n\n##DNN\n\nscores = []\n\navg_loss = []\n\nX_train_cv,y_train_cv = train_df.copy(), target.copy()\n\nsssf = StratifiedShuffleSplit(n_splits=5, test_size = 0.45 ,random_state=1)\n\nfor i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):\n    \n    K.clear_session()\n    \n    steps_per_epoch = len(X_train_cv.iloc[idxT])\/\/batch_size\n        \n    validation_steps = len(X_train_cv.iloc[idxV])\/\/batch_size\n    \n    print('Fold',i)\n    \n    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n    \n    dt_cv =  build_model()\n    \n    model_dnn_cv, history_cv = dt_cv.fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n                                                 validation_data = (X_train_cv.iloc[idxV],y_train_cv.iloc[idxV]),\n                                                 steps_per_epoch = steps_per_epoch,\n                                                 validation_steps = validation_steps,\n                                                 batch_size=batch_size, epochs=epochs, \n                                                 verbose=0, callbacks=[early_stop,annealer])\n    \n    val_stats = dt_cv.evaluate(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV], batch_size=batch_size, verbose=0)\n    \n    acc= val_stats['accuracy']*100\n    \n    scores.append(acc)\n            \n    avg_loss.append(val_stats['loss'])\n    \n    print ('LGB Val CV=',acc)\n    \n    print('#'*100)\n    \n    print('\\n')\n    \nprint(\"Multi Log Loss Stats {0:.5f},{1:.5f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.3f (%.3f)' % (np.array(scores).mean(), np.array(scores).std()))\n\n!rm -rf '.\/dt_output'","f91893a9":"nets = 5\n\ndt = [0] * nets\n\nmodel_dnn = [0] *nets\n\nhistory = [0] *nets\n\nseeds = [32 ,432 ,73]\n\nsubmission = pd.read_csv('..\/input\/healthcareanalyticsii\/sample_submission.csv')\n\nprobs = np.zeros(shape=(len(test_df),11))\n\nsubmission_probs = pd.DataFrame(columns = ['case_id'] + list(le_dict['Stay'].classes_))\n\nsubmission_probs.iloc[:,0] = submission.iloc[:,0]\n\nsubmission_probs.iloc[:,1:] = 0","dbfe1940":"scores = []\n\navg_loss = []\n\nsubmission_name = [] \n\nX_train_cv,y_train_cv = train_df.copy(), target.copy()\n\nfor seed in tnrange(len(seeds)):\n\n    sssf = StratifiedShuffleSplit(n_splits=5, test_size = 0.3 ,random_state=seeds[seed])\n    \n    for j, (idxT, idxV) in tqdm(enumerate(sssf.split(X_train_cv, y_train_cv))):\n        \n        print('Fold',j)\n\n        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n        \n        steps_per_epoch = len(X_train_cv.iloc[idxT])\/\/batch_size\n        \n        validation_steps = len(X_train_cv.iloc[idxV])\/\/batch_size\n        \n        K.clear_session()\n    \n        for i in tnrange(nets):\n\n            dt[i] =  build_model()\n\n            model_dnn[i], history[i] = dt[i].fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n                                                 validation_data = (X_train_cv.iloc[idxV],y_train_cv.iloc[idxV]),\n                                                 steps_per_epoch = steps_per_epoch,\n                                                 validation_steps = validation_steps,\n                                                 batch_size=batch_size, epochs=epochs, \n                                                 verbose=0, callbacks=[early_stop,annealer])\n        \n            val_stats = dt[i].evaluate(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV], batch_size=batch_size, verbose=0)\n            \n            probs_file_name = 'probs_'+str(seeds[seed])+'_'+str(j)+'_'+str(i)+\".csv\"\n            \n            submisssion_file_name  = 'submission_'+str(seeds[seed])+'_'+str(j)+'_'+str(i)+\".csv\"\n            \n            model_dnn_probs = dt[i].predict_proba(test_df)\n            \n            submission_probs.iloc[:,1:] = model_dnn_probs\n            \n            # probablity file per seed per split per tree\n            submission_probs.to_csv(probs_file_name,index = False)\n            \n            submission['Stay'] = le_dict['Stay'].inverse_transform(np.argmax(model_dnn_probs,axis =1))\n            \n            # submission file per seed per split per tree\n            submission.to_csv(submisssion_file_name,index =False)\n        \n            probs += model_dnn_probs\n            \n            acc = val_stats['accuracy']*100\n            \n            scores.append(acc)\n            \n            avg_loss.append(val_stats['loss'])\n            \n            submission_name.append(submisssion_file_name)\n            \n            print('#'*100)\n            \n            !rm -rf '.\/dt_output'\n            \nprint(\"Average Multi Log Loss Stats {0:.5f},{1:.5f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.3f (%.3f)' % (np.array(scores).mean(), np.array(scores).std()))\n\n!rm -rf '.\/dt_output'","5de485bc":"plot_model(dt[0].get_model().model,rankdir='TB')","78e73d13":"submission_probs.iloc[:,1:] = probs\n\n# probablity combined\nsubmission_probs.to_csv('probs.csv',index =False)","5804d976":"submission['Stay'] = le_dict['Stay'].inverse_transform(np.argmax(probs,axis =1))\n\n# submission file combined            \nsubmission.to_csv('submission.csv',index =False)\n\nsubmission.head()      ","6ed56437":"model_stats = pd.DataFrame({'submission':submission_name,'accuracy':scores,'validation_loss':avg_loss})\n\nmodel_stats.head()","35e42569":"model_stats.to_csv('model_stats.csv',index =False)","bb6cf31d":"# Model Building","5c9cf5c7":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Cross Validation\n![](https:\/\/4.bp.blogspot.com\/-wpr6O3EBAfU\/WbHyt6UCOVI\/AAAAAAAAjPw\/Y1DaO6qcV8oDYjJHzJ1PaPB2EXHmYtBBQCLcBGAs\/s1600\/%25E6%2593%25B7%25E5%258F%2596.JPG)\n\n* **The CV score generated using the methodology shown in the above figure is a better indicator of model performance than public LB**"}}