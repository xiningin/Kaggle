{"cell_type":{"f2d85bdf":"code","40f08000":"code","45c74046":"code","194ced46":"code","17ec8eb3":"code","d9240f3d":"code","d3a948c0":"code","d109669b":"code","2bb83828":"code","ba1e4b25":"code","6825ea88":"code","1162e535":"code","3b71e6ef":"code","44ccea07":"code","7cc1f0f3":"markdown","db9bc98c":"markdown","d4dfbbf2":"markdown","e203f0e3":"markdown","299d07bc":"markdown","4cd3a832":"markdown","9b58db2c":"markdown","fe930df2":"markdown","e50d3d5d":"markdown","86ca92f3":"markdown","0082ea42":"markdown","18991227":"markdown","34503731":"markdown","b6df523f":"markdown"},"source":{"f2d85bdf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.python import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten, Conv2D, BatchNormalization, MaxPooling2D\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\n\n","40f08000":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n","45c74046":"X_train = (train.iloc[:,1:].values).astype('float32')\ny_train = train.iloc[:,0].values.astype('int32')\nX_test = test.values.astype('float32')\n","194ced46":"img_rows, img_cols = 28, 28 # As explained in the competition's data description\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)","17ec8eb3":"mean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px\n\nX_train = standardize(X_train)\nX_test = standardize(X_test)","d9240f3d":"y_train = to_categorical(y_train)\nnum_classes = y_train.shape[1]","d3a948c0":"# An example image (randomly chosen)\nplt.imshow(X_train[np.random.randint(low=0, high=len(X_train))][:,:,0], cmap='gray')","d109669b":"gen = ImageDataGenerator(rotation_range = 10,\n                         zoom_range = 0.1,\n                         width_shift_range = 0.1,\n                         height_shift_range = 0.1,\n                         shear_range = 0.1)","2bb83828":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=4)\n\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","ba1e4b25":"\nmodel = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n","6825ea88":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","1162e535":"# Audjusting learning rate\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nhistory=model.fit_generator(generator=batches,\n                            steps_per_epoch=batches.n,\n                            epochs=3,\n                            validation_data=val_batches,\n                            validation_steps=val_batches.n,\n                            callbacks=[learning_rate_reduction])\n","3b71e6ef":"# Draw the loss and accuracy curves of the training set and the validation set.\n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","44ccea07":"predictions = model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","7cc1f0f3":"## **Reshaping images**","db9bc98c":"## **Submitting Predictions**","d4dfbbf2":"Welcome everybody! This Notebook summarizes the work I have done in the Digit recognizer competition, as I wanted to get started with Convolutional Neural Networks (CCN). It has the minimum necessary information to get a good result in the competition while being simple and easy to understand. I'm sorry if it doesn't include more plots or EDA, because I think the problem is quite simple.\n\nIf any of you don't really understand CNN's and want to take a little course about it I strongly recommend the Kaggle's course about it (https:\/\/www.kaggle.com\/learn\/deep-learning), which is not very long but very informative. Most of the work of this notebook has been extracted from there.","e203f0e3":"## Plot loss and accuracy curves","299d07bc":"## **Data Augmentation**","4cd3a832":"# Digit Recognizer solution using CNN's","9b58db2c":"# Preprocessing images","fe930df2":"# Model generation","e50d3d5d":"Reshape pictures to 3D arrays: height = 28px, width = 28px, canal = 1 (BW images)","86ca92f3":"## **Feature Standardization**","0082ea42":"## **One Hot encoding the labels**","18991227":"## Model fitting","34503731":"## Compile model","b6df523f":"## Define model"}}