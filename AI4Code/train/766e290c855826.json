{"cell_type":{"f1ed7110":"code","5b30a93a":"code","d760645e":"code","0c165fb1":"code","7e73214f":"code","4beef950":"code","fb9fa248":"code","cf3f1cf9":"code","41b3021a":"code","e5ba5507":"code","dd127732":"code","3f87d663":"code","79f818cd":"code","422f1e4a":"code","aa3789f0":"code","1d3a6d19":"code","d9569e6c":"code","64b35f4d":"code","cfa7d6f9":"code","b11bf475":"code","45f7e054":"code","787a5bd2":"code","f71e0a8b":"code","e724f283":"code","f76936e5":"code","8d34515b":"code","e8b98ecf":"code","2d5c18ce":"code","bdc36ea3":"code","0da79434":"code","9920fafb":"code","98b90c78":"code","23415a7d":"code","03620c8e":"code","86e047e5":"code","5f260e63":"code","bef91a1a":"code","22317f7b":"code","714a0834":"code","f33c295b":"code","13b50751":"code","9aae8ebf":"code","37596688":"code","528bd458":"code","004f4a15":"code","bf66898d":"code","6c1f3838":"markdown","5e73f437":"markdown","909ce5d1":"markdown","f4a5ef98":"markdown","cfeef409":"markdown","9e905186":"markdown","5e104129":"markdown","0646b2f3":"markdown","84a9cf88":"markdown","0f5c7d91":"markdown","ff53d135":"markdown"},"source":{"f1ed7110":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport cudf #Rapids\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)\n\nfrom tqdm import tqdm\nfrom glob import glob\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12,8)\nplt.rcParams['axes.titlesize'] = 16\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","5b30a93a":"base_dir = '\/kaggle\/input\/widsdatathon2021\/'","d760645e":"%%time\ntrain = cudf.read_csv(base_dir + 'TrainingWiDS2021.csv')\nprint(train.shape)\ntrain.head()","0c165fb1":"test = cudf.read_csv(base_dir + 'UnlabeledWiDS2021.csv')\nprint(test.shape)\ntest.head()","7e73214f":"train.drop('Unnamed: 0', axis = 1, inplace = True)\ntest.drop('Unnamed: 0', axis = 1, inplace = True)","4beef950":"train.describe().T","fb9fa248":"sub = pd.DataFrame({'encounter_id': test['encounter_id'].to_pandas()})\nsub","cf3f1cf9":"def features_to_drop(df):\n    nans = df.isna().sum().reset_index().sort_values(by = 0, ascending = False)\n    missing = nans[nans[0] != 0]\n    missing['drop_thres'] = (missing[0] \/ len(df)) * 100\n    to_drop = missing[missing['drop_thres'] > 50].to_pandas()\n    return to_drop['index'].values","41b3021a":"to_drop_train = features_to_drop(train)\nto_drop_test = features_to_drop(test)\nprint('There are {} columns to be dropped in train'.format(len(to_drop_train)))\nprint('There are {} columns to be dropped in train'.format(len(to_drop_test)))\n\ntry:\n    assert set(to_drop_train) == set(to_drop_test)\nexcept:\n    print('Number of features mismatch')","e5ba5507":"odd = next(iter(set(to_drop_test) - set(to_drop_train)))\nprint(odd)\nprint(f'NaNs % of {odd} in train: {train[odd].isna().sum() \/ len(train) * 100}')\ndrop_columns = to_drop_test\n\ndel to_drop_train, to_drop_test\ngc.collect()","dd127732":"train.drop(drop_columns, axis = 1, inplace = True)\ntest.drop(drop_columns, axis = 1, inplace = True)\ntrain.shape, test.shape","3f87d663":"train = train.to_pandas()\ntest = test.to_pandas()","79f818cd":"target_col = 'diabetes_mellitus'\ntargets = train[target_col].copy()\n\nax = sns.countplot(train[target_col])\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(train)), (p.get_x() + 0.1, p.get_height() + 5))","422f1e4a":"train_cat_cols = [c for c in train.columns if train[c].dtype == 'object']\ntest_cat_cols = [c for c in test.columns if test[c].dtype == 'object']\n\nprint(f'There are {len(train_cat_cols)} categorical features: {train_cat_cols}')\nprint(f'There are {len(test_cat_cols)} categorical features: {test_cat_cols}')\n\nassert set(train_cat_cols) == set(test_cat_cols), 'Categorical Features not same in train and test'\n\ncat_cols = train_cat_cols\n\ndel train_cat_cols, test_cat_cols\ngc.collect()","aa3789f0":"for c in cat_cols:\n    ax = sns.countplot(c, data = train, hue = target_col)\n    plt.setp(ax.get_xticklabels(), rotation = 45)\n    for p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(train[c])), (p.get_x() + 0.1, p.get_height() + 5))\n    plt.title(c.upper())\n    plt.show()","1d3a6d19":"#Drop the target column from the trainset\n\ntrain_copy = train.copy()\n\ntrain.drop(target_col, axis = 1, inplace = True)","d9569e6c":"num_cols = list(set(train.columns) - set(cat_cols))\nprint(f'There are {len(num_cols)} numerical features in the dataset: \\n{sorted(num_cols)}')","64b35f4d":"fig, ax = plt.subplots(1, 2)\nplt.suptitle('Distribution Plot of Age in Train and Test')\nsns.distplot(train['age'], ax = ax[0])\nsns.distplot(test['age'], ax = ax[1])","cfa7d6f9":"fig, ax = plt.subplots(1, 2)\nplt.suptitle('Distribution Plot of Age in Train and Test')\nsns.distplot(train['bmi'], ax = ax[0])\nsns.distplot(test['bmi'], ax = ax[1])","b11bf475":"fig, ax = plt.subplots(1, 2)\nplt.suptitle('Distribution Plot of Weight in Train and Test')\nsns.distplot(train['weight'], ax = ax[0])\nsns.distplot(test['weight'], ax = ax[1])","45f7e054":"fig, ax = plt.subplots(1, 2)\nplt.suptitle('Distribution Plot of Height in Train and Test')\nsns.distplot(train['height'], ax = ax[0])\nsns.distplot(test['height'], ax = ax[1])","787a5bd2":"int64_cols = [c for c in num_cols if train[c].dtype == 'int64']\nprint(f'There are {len(int64_cols)} features with int64 dtype: \\n{int64_cols}')\n\n#Check their unique values\n\nfor c in int64_cols:\n    if len(train[c].value_counts().index.values) < 5:\n        cat_cols.append(c)\n        num_cols.remove(c)\n        print(f'{c.upper()}: {train[c].nunique()}, {test[c].nunique()}')\nprint(len(num_cols), len(cat_cols))","f71e0a8b":"for c in num_cols:\n    print(f'{c.upper()}: {train[c].nunique()}, {test[c].nunique()}')","e724f283":"df_bin = train_copy[['hospital_id', 'encounter_id', 'gender', 'age', 'bmi', 'weight', 'height', 'diabetes_mellitus']].copy()\nbins = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\ndf_bin['age_binned'] = pd.cut(df_bin['age'], bins)\ndf_bin.head()","f76936e5":"plt.suptitle('Diabetes among Male patients by age group')\nax = sns.countplot('age_binned', data = df_bin[df_bin['gender'] == 'M'], hue = 'diabetes_mellitus')\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(df_bin)), (p.get_x() + 0.1, p.get_height() + 5))","8d34515b":"plt.suptitle('Diabetes among Female patients by age group')\nax = sns.countplot('age_binned', data = df_bin[df_bin['gender'] == 'F'], hue = 'diabetes_mellitus')\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(df_bin)), (p.get_x() + 0.1, p.get_height() + 5))","e8b98ecf":"bins = [16, 18.5, 24.9, 29.9, 35]\ndf_bin['bmi_binned'] = pd.cut(df_bin['bmi'], bins)\ndf_bin.head()","2d5c18ce":"plt.suptitle('Diabetes among Male patients by BMI group')\nax = sns.countplot('bmi_binned', data = df_bin[df_bin['gender'] == 'M'], hue = 'diabetes_mellitus')\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(df_bin)), (p.get_x() + 0.1, p.get_height() + 5))","bdc36ea3":"plt.suptitle('Diabetes among Female patients by BMI group')\nax = sns.countplot('bmi_binned', data = df_bin[df_bin['gender'] == 'F'], hue = 'diabetes_mellitus')\nfor p in ax.patches:\n        ax.annotate('{:.1f}%'.format(100 * p.get_height() \/ len(df_bin)), (p.get_x() + 0.1, p.get_height() + 5))","0da79434":"train.head()","9920fafb":"temp = train.isna().sum().reset_index()\nimpute_cols = temp[temp[0] != 0][\"index\"].values\nprint(f'Total Number of features to be imputed: {len(impute_cols)}')\n\ntemp = train[num_cols].isna().sum().reset_index()\nimpute_num = temp[temp[0] != 0][\"index\"].values\nprint(f'Number of Numerical features to be imputed: {len(impute_num)}')\n\ntemp = train[cat_cols].isna().sum().reset_index()\nimpute_cat = temp[temp[0] != 0][\"index\"].values\nprint(f'Number of Categorical features to be imputed: {len(impute_cat)} \\n {impute_cat}')\n\ndel temp\ngc.collect()","98b90c78":"#Check how many NaNs in cat features and their cardinality\n\nfor c in cat_cols:\n    #print(c.upper())\n    print(f'Number of NaNs in Train - {c}: {train[c].isnull().sum()}')\n    print(f'Number of NaNs in Test - {c}: {test[c].isnull().sum()}')\n    print(f'Cardinality:- Train: {len(train[c].value_counts(dropna = False))} -- Test: {len(test[c].value_counts(dropna = False))}')\n    if len(train[c].value_counts(dropna = False)) != len(test[c].value_counts(dropna = False)):\n        print(f'WARNING -- Cardinality mismatch in Categorical feature: {c}')\n    print('\\n')","23415a7d":"for c in num_cols:\n    train[c] = train[c].fillna(train[c].mean())\n    test[c] = test[c].fillna(test[c].mean())\ntrain.isnull().any().sum(), test.isnull().any().sum()","03620c8e":"for c in cat_cols:\n    train[c] = train[c].fillna(train[c].value_counts().index[0])\n    test[c] = test[c].fillna(test[c].value_counts().index[0])\ntrain.isnull().any().sum(), test.isnull().any().sum()","86e047e5":"scl = StandardScaler()\ntrain[num_cols] = scl.fit_transform(train[num_cols])\ntest[num_cols] = scl.transform(test[num_cols])","5f260e63":"train['ethnicity'].value_counts().index[0]","bef91a1a":"train['ethnicity'].astype('category').unique()","22317f7b":"for c in cat_cols: \n    lbl = LabelEncoder() \n    lbl.fit(list(train[c].astype(str).values) + list(test[c].astype(str).values))\n    train[c] = lbl.transform(list(train[c].astype(str).values))\n    test[c] = lbl.transform(list(test[c].astype(str).values))","714a0834":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(train, targets, test_size = 0.2, stratify = targets, \n                                                      random_state = 42, shuffle = True)\n\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","f33c295b":"import lightgbm as lgbm","13b50751":"params = {'num_leaves': 256,\n          'min_child_samples': 79,\n          'objective': 'binary',\n          'max_depth': 15,\n          'learning_rate': 0.02,\n          \"boosting_type\": \"gbdt\",\n          \"subsample_freq\": 3,\n          \"subsample\": 0.9,\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3,\n          'reg_lambda': 0.3,\n          'colsample_bytree': 0.9\n         }","9aae8ebf":"ltrain = lgbm.Dataset(Xtrain, label = ytrain)\nlvalid = lgbm.Dataset(Xvalid, label = yvalid)\n\nnum_rounds = 10000\nclf = lgbm.train(params, ltrain, num_rounds, valid_sets = [ltrain, lvalid], verbose_eval = 50, \n                    early_stopping_rounds = 50)\nvalid_preds = clf.predict(Xvalid, num_iteration = clf.best_iteration)\nprint('ROC_AUC_SCORE: ', roc_auc_score(yvalid, valid_preds))","37596688":"preds = clf.predict(test, num_iteration = clf.best_iteration)\n\nprint(preds.shape)\nprint(preds[:10])","528bd458":"lgbm.plot_importance(clf, figsize = (10, 55))","004f4a15":"sub_df = pd.DataFrame({'encounter_id': sub['encounter_id'].values, 'diabetes_mellitus': preds})\nsub_df.to_csv('.\/submission.csv', index = False)\nsub_df","bf66898d":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","6c1f3838":"__Standardize Num Features and Label Encode Cat Features__","5e73f437":" __WIP__","909ce5d1":"- _readmission_status_ has got only '0' value in both train and test - we may drop it\n- encounter_id_ seems to have index like values","f4a5ef98":"__LGBM Model__","cfeef409":"Let's check for other categorical features in dataset","9e905186":"There seems to be one column in test which has more NaNs but not in train","5e104129":"__Data Split__","0646b2f3":"__NaNs Imputation__","84a9cf88":"Check the features with dtype = 'object'","0f5c7d91":"Check for features with more than 50% NaNs - to be dropped","ff53d135":"Test set has more older patients"}}