{"cell_type":{"9cce6896":"code","f0455a87":"code","7dfa6c22":"code","77785f20":"code","ea15ea0d":"code","a7827fd4":"code","7732a304":"code","6c052d19":"code","b63ee85f":"code","989ed882":"code","fcad9449":"code","d9c4953a":"code","72b473b0":"code","93b4ec5b":"code","84b7bd95":"code","bd554105":"code","cc15610c":"code","84a5f7bd":"code","b7757a3e":"code","e1cf154b":"code","f80eeefc":"code","aa2e3dc7":"code","acf54052":"code","f94c5b6a":"code","d0fdd5c3":"code","e8085f9d":"code","afaa9ccb":"code","61d47e7d":"code","4b303653":"code","f7603ef6":"code","24ea05d8":"code","a22ecd2c":"markdown","a6686b80":"markdown"},"source":{"9cce6896":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0455a87":"data = pd.read_excel(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")\ndf = data.copy()","7dfa6c22":"pd.set_option ('display.float_format', lambda x: '%.2f' % x)","77785f20":"# First look to dataset\ndf.head ()","ea15ea0d":"# Columns' datatypes\n# There are four categorical, three numerical and one datetime variables in dataset.\n# We could also see that there are 541910 observation in this dataset.\ndf.info()","a7827fd4":"# How many missing values are there for each columns(variables) in dataset?\ndf.isnull ().sum ()","7732a304":"# Let's take a quick look to numerical variables in this dataset.\n# I will get rid of negative values in \"Quantity\" and \"Price\"\ndf.describe ([0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","6c052d19":"df = df[~((df[\"Quantity\"] < 0) | (df[\"Price\"] < 0))]\ndf.describe()","b63ee85f":"# Let's check if there is any invoice cancelation.\ndf[df[\"Invoice\"].str.contains (\"C\", na=False)]","989ed882":"# Unique number of products\n\ndf[\"Description\"].nunique ()","fcad9449":"# The most ordered products\ndf.groupby (\"Description\")[[\"Quantity\"]].sum ().sort_values (by=\"Quantity\", ascending=False).head ()","d9c4953a":"# The number of total Invoice\ndf[\"Invoice\"].nunique ()","72b473b0":"# How much money has been earned per invoice?\ndf[\"TotalPrice\"] = df[\"Quantity\"] * df[\"Price\"]\ndf.groupby (\"Invoice\")[[\"TotalPrice\"]].mean ().sort_values (by=\"TotalPrice\", ascending=False)","93b4ec5b":"# The most expensive products\ndf.sort_values (\"Price\", ascending=False).head ()","84b7bd95":"# How many orders per country?\ndf[\"Country\"].value_counts ().sort_values (ascending=False)","bd554105":"# How much has been made money per country?\ndf.groupby (\"Country\")[[\"TotalPrice\"]].sum ().sort_values (by=\"TotalPrice\", ascending=False).head ()","cc15610c":"df.head ()","84a5f7bd":"# The last invoice date\ndf[\"InvoiceDate\"].max ()","b7757a3e":"import datetime as dt\n\n# I accepted the date of today as following\ntoday_date = dt.datetime (2011, 12, 11)","e1cf154b":"# To get Recency, Frequency and Monetary values, I grouped by Customer id and I made operations following\nrfm = df.groupby (\"Customer ID\").agg ({\"InvoiceDate\": lambda day: (today_date - day.max ()).days,\n                                       \"Invoice\": \"nunique\",\n                                       \"TotalPrice\": \"sum\"})","f80eeefc":"rfm.head()","aa2e3dc7":"rfm.columns = [\"Recency\", \"Frequency\", \"Monetary\"]","acf54052":"rfm.head()","f94c5b6a":"# I categorized Recency, Frequency and Monetary according to their values, as numbers from 1 to 5.\n# For Recency, the lowest value is ideal. Recency means, the time since last purchase date.\n# For Frequency and Monetary, the highest value is ideal.\nrfm[\"Recency_Score\"] = pd.qcut (rfm[\"Recency\"], q=5, labels=[5, 4, 3, 2, 1])\nrfm[\"Frequency_Score\"] = pd.qcut (rfm[\"Frequency\"].rank(method=\"first\"), q=5, labels=[1, 2, 3, 4, 5])\nrfm[\"Monetary_Score\"] = pd.qcut (rfm[\"Monetary\"], q=5, labels=[1, 2, 3, 4, 5])","d0fdd5c3":"rfm[\"RFM_Score\"] = rfm[\"Recency_Score\"].astype (\"str\") + rfm[\"Frequency_Score\"].astype (\"str\") + rfm[\n    \"Monetary_Score\"].astype (\"str\")","e8085f9d":"rfm.head()","afaa9ccb":"#\u00a0The segmentation of customers by using regex\nseg_map = {\n    r'[1-2][1-2]': 'Hibernating',\n    r'[1-2][3-4]': 'At_Risk',\n    r'[1-2]5': 'Cant_Loose',\n    r'3[1-2]': 'About_to_Sleep',\n    r'33': 'Need_Attention',\n    r'[3-4][4-5]': 'Loyal_Customers',\n    r'41': 'Promising',\n    r'51': 'New_Customers',\n    r'[4-5][2-3]': 'Potential_Loyalists',\n    r'5[4-5]': 'Champions'\n}\n\nrfm[\"Segment\"] = [row[0] + row[1] for row in rfm[\"RFM_Score\"].values]\n\nrfm[\"Segment\"] = rfm[\"Segment\"].replace (seg_map, regex=True)","61d47e7d":"rfm.head()","4b303653":"seg = rfm.groupby (\"Segment\").agg ([\"mean\", \"count\"])","f7603ef6":"seg.columns = [row[0] + \"_\" + row[1] if row[1] != \"\" else row[0] for row in seg.columns]","24ea05d8":"seg","a22ecd2c":"# **DATA PREPARATION**","a6686b80":"# **CUSTOMER SEGMENTATION**"}}