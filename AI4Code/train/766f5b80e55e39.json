{"cell_type":{"4f06a621":"code","a74dde63":"code","a865c44e":"code","d42ff2f1":"code","2c56c3b7":"code","384cf149":"code","c1e05c93":"code","2d92db4a":"code","4200a6cb":"code","85881465":"code","0d751d43":"code","bcacad86":"code","bb97088f":"code","aa1d9177":"code","3cb2820d":"code","0d9c3519":"code","5ef7dbf4":"code","b37348fe":"code","a20dcf1b":"code","29ee63a2":"code","26dbb74b":"code","2d2db91f":"code","babd0343":"code","4675b51b":"markdown","55189a0c":"markdown","9e55a095":"markdown","3043fa88":"markdown","6e31d3b0":"markdown","c871bf2b":"markdown","28baaf8b":"markdown"},"source":{"4f06a621":"#Install the yfinance package and import other packagesa\n\n!pip install yfinance\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport datetime as dt\nimport yfinance as yf\nimport matplotlib as mpl\n\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom statsmodels import regression\n\n#Import the 5 indexes from Yahoo Finance as data\nsymbols_list = [\"IBGM.MI\",\"DAX\",\"EWG\",\"EWGS\",\"SDEU.L\"]\nstart = dt.datetime(2019,9,1)\nend = dt.datetime(2020,8,31)\ndata = yf.download(symbols_list, start=start, end=end)\ndata.head()\n\n# filter column adjusted close\ndf = data['Adj Close']\ndf.head()","a74dde63":"#The daily closing price of the 5 assets\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(30,10))\n\ndf['DAX'].plot()\ndf['EWG'].plot()\ndf['EWGS'].plot()\ndf['IBGM.MI'].plot()\ndf['SDEU.L'].plot()\nplt.ylabel(\"Daily Closing Price\")\nplt.legend()\n\nplt.show()\nprint(plt.style.available)","a865c44e":"# Percentage Change for returns for the 5 assets\n\n# Remove first NaN\nplt.style.use('fivethirtyeight')\ndf_pct =df.pct_change()[1:]\ndf_pct.head()\n\nplt.figure(figsize=(30,10))\ndf_pct['DAX'].plot()\ndf_pct['EWG'].plot()\ndf_pct['EWGS'].plot()\ndf_pct['IBGM.MI'].plot()\ndf_pct['SDEU.L'].plot()\nplt.ylabel(\"% Change of Returns\")\nplt.legend()\nplt.show()\n","d42ff2f1":"#Import COVID Germany Data (Daily from Jan to Sep)\ncovid = pd.read_csv('..\/input\/germany-covid19-janseptember\/Germany COVID-19.csv')\ncovid = covid[['Date','Confirmed']]\ncovid[\"Date\"] = pd.to_datetime(covid[\"Date\"])\ncovid.tail()\n_ = covid.plot(x = 'Date', y = 'Confirmed', kind = 'scatter', color = 'r')","2c56c3b7":"#Import Power Consumption Data (Non-Fin Indicator) and parse the data\npw_consumption = pd.read_csv('..\/input\/western-europe-power-consumption\/de.csv')\npw_consumption['Date'] = pd.to_datetime(pw_consumption['end'])\npw_consumption['Date'] = pd.to_datetime(pw_consumption['Date']).dt.date\npw_consumption['Date'] = pd.to_datetime(pw_consumption['Date'])\npw_consumption = pw_consumption[['Date', 'load']]\n\n\n#Resample data to days and sum the different time range\npw_consumption = pw_consumption.resample('D', on = 'Date').sum()\n\npw_consumption = pw_consumption.sort_values('Date', ascending = False)\n\n#Leave the data of the recent 1 year\npw_consumption = pw_consumption[:366]\n\npw_consumption.plot()\n","384cf149":"#Create a base line percentage change of the different assets and merge with the power consumption data (Remove the top NaN)\n\nbaseline=df_pct.merge(pw_consumption,how=\"left\",on=\"Date\")\nbaseline =baseline[1:]\nbaseline.head(20)","c1e05c93":"#Import City Info (Adapted from Bootcamp 3A)\ncty_info = pd.read_csv('..\/input\/countryinfo\/covid19countryinfo.csv').rename(columns={'country':'Country'})\n\n# Filter observations with aggregate country-level information\n# The column region for region-level observations is populated\ncty_info = cty_info[cty_info.region.isnull()]\n\n# Convert string data type to floating data type\n# Remove comma from the fields\ncty_info['healthexp'] = cty_info[~cty_info['healthexp'].isnull()]['healthexp'].str.replace(',','').astype('float')\ncty_info['gdp2019'] = cty_info[~cty_info['gdp2019'].isnull()]['gdp2019'].str.replace(',','').astype('float')\n\n# Convert to date objects with to_datetime method\ngov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace']\n\nfor gov_action in gov_actions:\n    cty_info[gov_action] = pd.to_datetime(cty_info[gov_action], format = '%m\/%d\/%Y')\n    \n# Filter columns of interest\n# Note: feel free to explore other variables or datasets\ncty_info = cty_info[['Country','quarantine', 'schools', 'publicplace', 'gatheringlimit', 'gathering', 'nonessential']]\n\n# cty_info.describe()\ncty_info.info()\n#cty_info.head(20)\n","2d92db4a":"#Import COVID Full Table Info\n\nfull_table = pd.read_csv('..\/input\/corona-virus-report\/covid_19_clean_complete.csv')\nfull_table['Date'] = pd.to_datetime(full_table['Date'])\n\n# Examine DataFrame (object type, shape, columns, dtypes)\nfull_table.info()\n\n#type(full_table)\n#full_table.shape\n#full_table.columns\n#full_table.dtypes\n\n# Deep dive into the DataFrame\nfull_table.head()","4200a6cb":"#Merge COVID Info with Germany's Financial and Daily Life indicators\n\nfull_grouped = pd.read_csv('..\/input\/corona-virus-report\/full_grouped.csv')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n#full_grouped.loc[full_grouped['Country\/Region'] == 'US', 'Country\/Region'] = 'USA'\n\n\n# Correct country names in worldometer to make them consistent with dataframe full_grouped column Country\/Region before merging \n\n\n# Draw population and country-level data\n\nfull_grouped = full_grouped.merge(cty_info, how = 'left', left_on = 'Country\/Region', right_on = 'Country')\n\n# Backfill data\nfull_grouped = full_grouped.fillna(method='ffill')\n\n# Create post-invention indicators\ngov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace']\n\nfor gov_action in gov_actions:\n    full_grouped['post_'+gov_action] = full_grouped['Date'] >= full_grouped[gov_action]\n    full_grouped['day_rel_to_' + gov_action] = (full_grouped['Date'] - full_grouped[gov_action]).dt.days\n\n# Create percent changes in covid19 outcomes\ncovid_outcomes = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\nfor covid_outcome in covid_outcomes:\n    full_grouped['pct_change_' + covid_outcome] = full_grouped.groupby(['Country\/Region'])[covid_outcome].pct_change()\n    full_grouped[full_grouped['pct_change_' + covid_outcome] == np.inf] = 0\n\n# Replace space in variable names with '_'\nfull_grouped.columns = full_grouped.columns.str.replace(' ', '_')\n    \nfull_grouped.info()\n#full_grouped.tail(20)\n#print(full_grouped.iloc[0,0])\n# full_grouped[full_grouped[\"quarantine\"] != None][\"Country\/Region\"].unique()\nfull_grouped=full_grouped[full_grouped['Country\/Region'] == 'Germany']\nfull_grouped=full_grouped.drop(columns=[\"Country\/Region\"])\n\nfull_grouped.tail()\n\n# full_grouped.describe()","85881465":"full_grouped[\"Date\"] = pd.to_datetime(full_grouped[\"Date\"])\n\nbaseline_merged=baseline.merge(full_grouped, how=\"inner\",on=\"Date\")\n\nbaseline_merged.head()\n\n","0d751d43":"#Define a function to plot government interventions' effect\n\ndef plot_gov_action (covid_outcome, gov_action):\n    fig = px.scatter(baseline_merged[baseline_merged[gov_action] != None], x = 'day_rel_to_' + gov_action \\\n                     , y=covid_outcome, \\\n                     title='N days from ' + gov_action, height=300)\n    fig.update_layout(yaxis=dict(range=[-0.2,1]))\n    fig.show()","bcacad86":"#Investigate after government intervention, how the rise of the confirm cases changes\nimport plotly as py\nimport plotly.io as pio\nimport plotly.express as px\npio.templates.default = \"ggplot2\"\nplot_gov_action('pct_change_Confirmed', 'quarantine')\nplot_gov_action('pct_change_Confirmed', 'schools')\nplot_gov_action('pct_change_Confirmed', 'gathering')","bb97088f":"#Regression Scatter Plot of Covid Cases Against Short Term Bond\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'SDEU.L', data = baseline_merged)\n\nX = baseline_covid[[\"pct_change_Recovered\",\"pct_change_Active\",\"pct_change_Deaths\",\"pct_change_Confirmed\"]]\ny = baseline_covid[\"SDEU.L\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\n#Covid_Short Term Bond\n\n#Regression Scatter Plot of Covid Cases Against Power Consumption\nbaseline_merged['Date'] = pd.to_datetime(baseline_merged['Date'])\nbaseline_merged.head()\n#baseline_covid = baseline_merged[baseline_merged['Date'] >= '2020-01-01']\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'SDEU.L', data = baseline_merged)\nprint(model.summary())","aa1d9177":"#Regression Scatter Plot of Covid Cases Against Long Term Bond\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'IBGM.MI', data = baseline_merged)\n\n#OLS\nX = baseline_covid[[\"pct_change_Recovered\",\"pct_change_Active\",\"pct_change_Deaths\",\"pct_change_Confirmed\"]]\ny = baseline_covid[\"IBGM.MI\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\nprint(model.summary())","3cb2820d":"#Regression Scatter Plot of Covid Cases Against DAX\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'DAX', data = baseline_merged)\n\n#OLS\nX = baseline_covid[[\"pct_change_Recovered\",\"pct_change_Active\",\"pct_change_Deaths\",\"pct_change_Confirmed\"]]\ny = baseline_covid[\"DAX\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\nprint(model.summary())","0d9c3519":"#Regression Scatter Plot of Covid Cases Against EWG (Large and Mid Capitalisation Companies in DAX)\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'EWG', data = baseline_merged, color = 'G')\n\n#OLS\nX = baseline_covid[[\"pct_change_Recovered\",\"pct_change_Active\",\"pct_change_Deaths\",\"pct_change_Confirmed\"]]\ny = baseline_covid[\"EWG\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\nprint(model.summary())","5ef7dbf4":"#Regression Scatter Plot of Covid Cases Against EWGS (Small Capitalisation Companies in DAX)\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'EWGS', data = baseline_merged, color = 'B')\n\n\nX = baseline_covid[[\"pct_change_Recovered\",\"pct_change_Active\",\"pct_change_Deaths\",\"pct_change_Confirmed\"]]\ny = baseline_covid[\"EWGS\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\n#Regression Scatter Plot of Covid Cases Against EWGS (Small Capitalisation Companies in DAX)\nreg_covid_load = sns.regplot(x = 'pct_change_Confirmed', y = 'EWGS', data = baseline_merged, color = 'B')\nprint(model.summary())","b37348fe":"#Regression Scatter Plot of Covid Cases Against Government Interventions (Fiscal Policy indicated by short-term bond price)\n\nX = baseline_covid[[\"pct_change_Confirmed\",\"SDEU.L\"]]\ny = baseline_covid[\"DAX\"]\n\n# Note the difference in argument order\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\n# Print out the statistics\nprint(model.summary())","a20dcf1b":"#Regression Scatter Plot of Covid Cases Against Power Consumption \n\n\nbaseline_merged['Date'] = pd.to_datetime(baseline_merged['Date'])\nbaseline_merged.head()\nbaseline_covid = baseline_merged[baseline_merged['Date'] >= '2020-01-01']\nreg_covid_load = sns.regplot(x = 'Confirmed', y = 'load', data = baseline_covid, color = 'B')\n\n#Regression OLS Analysis\n\n\nX = baseline_covid[\"Confirmed\"]\ny = baseline_covid[\"load\"]\n\nX = sm.add_constant(X)\nmodel = sm.OLS(y.astype(float), X.astype(float), missing='drop').fit()\npredictions = model.predict(X.astype(float)) # make the predictions by the model\n\nprint(model.summary())","29ee63a2":"#Create 2 series of power consumption data before and after the government interventions\npw_consump1=baseline_covid[baseline_covid[\"Date\"]<=\"2020-03-21\"]\npw_consump2=baseline_covid[baseline_covid[\"Date\"]>=\"2020-03-21\"]","26dbb74b":"#Hypothesis testing at Alpha level of 5%\n\nfrom scipy import stats\nfrom statsmodels.stats import weightstats as stests\nztest ,pval1 = stests.ztest(pw_consump1[\"load\"], x2=pw_consump2['load'], value=0,alternative='two-sided')\nprint(float(pval1))\nif pval1<0.05:\n    print(\"Reject null hypothesis H0: 'The average daily power consumption after the government intervention is the same as that of before'\")\nelse:\n    print(\"Accept null hypothesis H0: 'The average daily  power consumption after the government intervention is the same as that of before'\")","2d2db91f":"#Conduct an Chi Square Test to analyse if Power Consumption After Intervention has any dependency on that of before intervention.\n\n#Create 3 bins for power comsumptions before and after the intervention and merge into a contingency table\npw_consume = pd.DataFrame()\npw_consume=pd.concat([pw_consump1[\"load\"],pw_consump2[\"load\"]],axis=1, ignore_index = True)\nbin_labels_3 = ['Bin 1', 'Bin 2', 'Bin 3']\n\npw_consume['before_quarantine'] = pd.qcut(pw_consump1[\"load\"], q=3, labels=bin_labels_3)\npw_consume['after_quarantine'] = pd.qcut(pw_consump2[\"load\"], q=3, labels=bin_labels_3)\n\ncontingency_table = [[pw_consume.groupby('before_quarantine')[0].mean(),pw_consume.groupby('after_quarantine')[1].mean()]]\ncontingency_table","babd0343":"#Conduct Chi Square Test\n\nfrom scipy.stats import chi2_contingency \nstat, p, dof, expected = chi2_contingency(contingency_table) \n  \n# interpret p-value \nalpha = 0.05\nprint(\"p value is \" + str(p)) \nif p <= alpha: \n    print('Reject Ho, Power Consumption Before and After the Intervention are Dependent') \nelse: \n    print('Fail to reject H0 as Power Consumption Before and After the Intervention are Independent') ","4675b51b":"**For Financial Indicators, we adopted the following ETF and Stock Indexes,**\n\n**EQUITY RELATED**\n\n1)SDEU.L \uff08iShares Germany Govt Bond UCITS ETF EUR (Dist)\uff09\n    ->The performance of the Barclays Germany Treasury Bond Index with underlying bonds of AAA ratings that has highest possible credit worthiness.\n    ->292M Euro asset under management\n\n2)EWG -> 80% of assets in the securities of large and mid capitalisation companies under Frankfurt SE\n\n3)EWGS -> EWG Small. Measures the performance of equity securities of small capitalisation companies\n\n**BOND RELATED**\n\n4)IBGM.MI (Govt Bond 7-10yr UCITS ETF EUR (Dist))\n    -> Euro government bonds at investment grade with more than 7 years of calculated life and min asset value of 2M Euro\n    \n5)SDEU.L\n    -> The ETF invests in physical index securities to Euro demoninated German government bonds with credit ratings that are the same as the country rating, with minimum remaining TTM of 1 year and 300M assets\n\n**For non-Financial Indicator, we adopted the power consumption in Germany during the COVID period**","55189a0c":"Preparation Complete.\n\nFirst of all, we investigate how government intervention helps with the new confirmed COVID cases in Germany","9e55a095":"# Bootcamp Problem Set 3\n\nGroup 7 \n- Dharshen Mahalingam - A0220515W\n- Fanyanqing Sun - A0220382R\n- Simon Kleppe - A0220490R\n- Sun Shaofei - A0220536N\n\n#### This Problem set investigates how COVID affects the financial market in Germany and people's daily lives.\n","3043fa88":"The government intervention in Germany seems very effective against the rise of COVID cases, shown by a drop of daily % increase","6e31d3b0":"#End Note\n\nMost of our data, actually all of our data in this analysis are time series which progress over time. It means that within each data, there's an auto-regression. \n\nWhile an regression model can show some relationship between the data we analysed today, there are actually some assumptions that need to be fulfilled.\n* > Linear relationship\n* > Multivariate normality\n* > No or little multicollinearity\n* > No auto-correlation\n* > Homoscedasticity\n\nRegression model may not be the best fit to the analysis above even though it shows some relationships\n\nWe will investigate further into the daily life affected by COVID in Germany and would try to adopt time series analysis in the final project.\n","c871bf2b":"**Inferential Statistics**\n\nAfter analysing the regression plots and OLS, we will conduct an hypothesis testing on if Government Intervention on COVID has an influence on the power consumption in Germany,\n\n> H0: The average daily power consumption after the government intervention is the same as that of before.\n\n> H1: The average daily power consumption after the government intervention is different as that of before.","28baaf8b":"**Regression Analysis**\n\nSecondly, we will use regression model to investigate how COVID has affected \n- The financial market in Germany (Stock and Bond Market)\n- The daily lives of the people in Germany (Power consumption)"}}