{"cell_type":{"9ecdcf68":"code","bc409ffa":"code","7e631b2d":"code","b37d70bc":"code","fb4a3809":"code","3d4ed3f7":"code","4f24f346":"code","c19ab670":"code","a1a3153c":"code","f37958ec":"code","c7fcba78":"code","fe3186a7":"code","50c74c8f":"code","45cd4fed":"code","73579c98":"code","02c16288":"code","c5ece250":"markdown"},"source":{"9ecdcf68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc409ffa":"submission0 = pd.read_csv('\/kaggle\/input\/m5-final-models\/submission_LSTM.csv') \nsubmission1 = pd.read_csv('\/kaggle\/input\/m5-final-models\/submission_XGBoost.csv') \nsubmission2 = pd.read_csv('\/kaggle\/input\/m5-final-models\/submission_LGBM.csv')\nsubmission3 = pd.read_csv('\/kaggle\/input\/m5-final-models\/submission_prophet.csv')\nsubmission4 = pd.read_csv('\/kaggle\/input\/m5-final-models\/submission_SARIMAX.csv')","7e631b2d":"#submission0 = pd.read_csv('\/kaggle\/input\/basemodels\/submissionRod.csv') # 0.64\n#submission1 = pd.read_csv('\/kaggle\/input\/basemodels\/LightGBM.csv') # 0.47\n#submission2 = pd.read_csv('\/kaggle\/input\/basemodels\/submissionDeepNeuralNet(DNN).csv')  \n#submission3 = pd.read_csv('\/kaggle\/input\/basemodels\/submissionWitchTime.csv') # Eval = 0----------------------------------\n#submission4 = pd.read_csv('\/kaggle\/input\/basemodels\/submissionm5-baseline.csv')  # Eval = 0 \n#submission5 = pd.read_csv('\/kaggle\/input\/basemodels\/STOREandCAT.csv') #Eval=0\n#submission6 = pd.read_csv('\/kaggle\/input\/basemodels\/M5ForecasteR.csv')\n#submission7 = pd.read_csv('\/kaggle\/input\/basemodels\/NolanLightGBM.csv') \n#submission8 = pd.read_csv('\/kaggle\/input\/basemodels\/DNNwithCategoricalEmbeddings day-to-day.csv') #Eval = 0\n#submission9 = pd.read_csv('\/kaggle\/input\/basemodels\/SARIMAX_submission.csv')\n#submission10 = pd.read_csv('\/kaggle\/input\/basemodels\/submission_XGB.csv') # Evaluation values are all zero!!!!!\n","b37d70bc":"\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nprices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nvalidation = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv') \nsample_sub = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv')","fb4a3809":"def perfect_sub(): # returns a perfect submition just to be sure that we are validating on the right window of values\n    submission = OperateBaseModels(submission0,submission1, a=0, b=1)\n    diference = validation.merge(submission, how='right')\n    shift= 56\n    perfect_submission = diference[diference.columns[-shift:-shift+28]]\n\n\n    #\n    col = { 'd_'+str(1914+i):'F'+str(i+1) for i in range(28)}\n    perfect_submission = perfect_submission.rename(columns=col)\n    perfect_submission.insert(loc=0, column='id', value= submission0['id']) \n    perfect_submission = perfect_submission.fillna(0)\n    return perfect_submission\n\n\ndef OperateBaseModels(ModelA,ModelB, a,b):\n    submissionMerge = pd.merge(ModelA, ModelB, on='id', how='left', suffixes=('_x', '_y'))#.mean(level=0)\n    submissionMerge\n    submission = pd.DataFrame()\n    submission.insert(loc=0, column='id', value= ModelB['id']) \n\n    for j in range(28):\n        i =j+1\n        \n        submission.insert(loc=i, column='F'+str(i), value= ((submissionMerge[submissionMerge.columns[i]]*a)+(submissionMerge[submissionMerge.columns[i+28]])*b)\/(a+b)) \n     \n\n    return submission\n\n\n                                       ","3d4ed3f7":"from typing import Union\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm_notebook as tqdm\n\n\nclass WRMSSEEvaluator(object):\n\n    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n        train_target_columns = train_y.columns.tolist()\n        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n\n        train_df['all_id'] = 0  # for lv1 aggregation\n\n        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n\n        if not all([c in valid_df.columns for c in id_columns]):\n            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.calendar = calendar\n        self.prices = prices\n\n        self.weight_columns = weight_columns\n        self.id_columns = id_columns\n        self.valid_target_columns = valid_target_columns\n\n        weight_df = self.get_weight_df()\n\n        self.group_ids = (\n            'all_id',\n            'state_id',\n            'store_id',\n            'cat_id',\n            'dept_id',\n            ['state_id', 'cat_id'],\n            ['state_id', 'dept_id'],\n            ['store_id', 'cat_id'],\n            ['store_id', 'dept_id'],\n            'item_id',\n            ['item_id', 'state_id'],\n            ['item_id', 'store_id']\n        )\n\n        for i, group_id in enumerate(tqdm(self.group_ids)):\n            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n            scale = []\n            for _, row in train_y.iterrows():\n                series = row.values[np.argmax(row.values != 0):]\n                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n            setattr(self, f'lv{i + 1}_train_df', train_y)\n            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n\n            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n            setattr(self, f'lv{i + 1}_weight', lv_weight \/ lv_weight.sum())\n\n    def get_weight_df(self) -> pd.DataFrame:\n        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n\n        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n        return weight_df\n\n    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n        valid_y = getattr(self, f'lv{lv}_valid_df')\n        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n        scale = getattr(self, f'lv{lv}_scale')\n        return (score \/ scale).map(np.sqrt)\n\n    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n\n        all_scores = []\n        for i, group_id in enumerate(self.group_ids):\n            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n            weight = getattr(self, f'lv{i + 1}_weight')\n            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n            all_scores.append(lv_scores.sum())\n\n        return np.mean(all_scores)\ndf_train_full =  pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv\")\ndf_calendar = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")\ndf_prices = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\n\ndf_train = df_train_full.iloc[:, :-28]\ndf_valid = df_train_full.iloc[:, -28:]\nevaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)\n\n\ndef WRMSSEE(sub): # Add a function to take the standard submission format \n    val_preds = sample_sub[['id']].merge(sub, on = 'id')  #Order values like the submission example\n    \n    val_preds.columns = ['id'] + list(df_valid.columns)  # Rename columns\n    valid_preds = val_preds.iloc[:30490, -28:] #Take just validation data from the submition dataframe\n    return evaluator.score(valid_preds)","4f24f346":"\ndef function(solution):\n    solution = np.abs(solution )\n    submission = OperateBaseModels(submission0,submission1, a=solution[0], b=solution[1])\n    submission = OperateBaseModels(submission,submission2, a=1, b=solution[2]) \n    submission = OperateBaseModels(submission,submission3, a=1, b=solution[3]) \n    submission = OperateBaseModels(submission,submission4, a=1, b=solution[4])\n                                   \n                                   \n    #submission = OperateBaseModels(submission,submission2, a=1, b=solution[2]) #I just added this for fun to see how much it affects to have more models into consideration \n    #submission = OperateBaseModels(submission,submission3, a=1, b=solution[3]) #00\n    #submission = OperateBaseModels(submission,submission4, a=1, b=solution[4])#00\n    #submission = OperateBaseModels(submission,submission5, a=1, b=solution[5])#00\n    #submission = OperateBaseModels(submission,submission6, a=1, b=solution[3])\n    #submission = OperateBaseModels(submission,submission7, a=1, b=solution[4])\n    #submission = OperateBaseModels(submission,submission8, a=1, b=solution[8])#00\n    #submission = OperateBaseModels(submission,submission9, a=1, b=solution[5])\n    #submission = OperateBaseModels(submission,submission10, a=1, b=solution[10])#00\n\n    #Mean_error = np.mean(np.mean(np.abs(perfect_sub._get_numeric_data()-submission._get_numeric_data())))\n    error = WRMSSEE(submission) #+Mean_error\/2\n    return error \n\n","c19ab670":"perfect_sub = perfect_sub()","a1a3153c":"from scipy.optimize import OptimizeResult\nfrom scipy.optimize import minimize\nhist = []\ndef custmin(fun, x0, args=(), maxfev=None, stepsize=0.1,  # Then we optimize the coeficients to minimize error\n        maxiter=500, callback=None, **options):\n    bestx = x0\n    besty = fun(x0)\n    funcalls = 1\n    niter = 0\n    improved = True\n    stop = False\n\n    while improved and not stop and niter < maxiter:\n        improved = False\n        niter += 1\n        print('Iteration number',niter,'WRMSSEE',besty, 'using ', str(np.abs(np.array(bestx)) ))\n        hist.append(besty)\n        for dim in range(np.size(x0)):\n            for s in [bestx[dim] - stepsize, bestx[dim] + stepsize]:\n                testx = np.copy(bestx)\n                testx[dim] = s\n                testy = fun(testx, *args)\n                funcalls += 1\n                if testy < besty:\n                    besty = testy\n                    bestx = testx\n                    improved = True\n            if callback is not None:\n                callback(bestx)\n            if maxfev is not None and funcalls >= maxfev:\n                stop = True\n                break\n\n    return OptimizeResult(fun=besty, x=bestx, nit=niter,\n                          nfev=funcalls, success=(niter > 1))\nx0 = np.random.rand(5)\nres = minimize(function, x0, method=custmin, options=dict(stepsize=0.05))\n\n\n","f37958ec":"Plot_solution =np.abs(res.x)\n# [9.35946038e-04, 1.00239378e+01, 1.67410230e-02, 4.01652749e+00,   1.16401096e-02, 9.17120136e-01]\nsns.set()\nplt.plot(hist)\nplt.ylabel('WRMSSEE')\nplt.xlabel('Iteration')\n\nPlot_solution","c7fcba78":"plt.figure()\n\n\nax = sns.barplot( x=pd.DataFrame(Plot_solution).index,y=0, data=pd.DataFrame(Plot_solution));\nax.set(xlabel='Model', ylabel='Coeficients form weighted average ');\nax.set_xticklabels(['DNN Embedings','XGBoost','LGBM','SARIMAX','Prophet'], rotation=30);\n\n","fe3186a7":"solution = Plot_solution\n\nsolution = np.abs(solution )\nsubmission = OperateBaseModels(submission0,submission1, a=solution[0], b=solution[1])\nsubmission = OperateBaseModels(submission,submission2, a=1, b=solution[2]) \nsubmission = OperateBaseModels(submission,submission3, a=1, b=solution[3]) \nsubmission = OperateBaseModels(submission,submission4, a=1, b=solution[4])\n\n\n#submission = OperateBaseModels(submission,submission2, a=1, b=solution[2]) #I just added this for fun to see how much it affects to have more models into consideration \n#submission = OperateBaseModels(submission,submission3, a=1, b=solution[3]) #00\n#submission = OperateBaseModels(submission,submission4, a=1, b=solution[4])#00\n#submission = OperateBaseModels(submission,submission5, a=1, b=solution[5])#00\n#submission = OperateBaseModels(submission,submission6, a=1, b=solution[3])\n#submission = OperateBaseModels(submission,submission7, a=1, b=solution[4])\n#submission = OperateBaseModels(submission,submission8, a=1, b=solution[8])#00\n#submission = OperateBaseModels(submission,submission9, a=1, b=solution[5])\n#submission = OperateBaseModels(submission,submission10, a=1, b=solution[10])#00\n\n\n\n\n","50c74c8f":"WRMSSEE(submission)","45cd4fed":"#error\n#perfect_sub\ndiference = validation.merge(submission,how='left')                                      \nerror = np.mean(np.mean(np.abs(perfect_sub._get_numeric_data()-submission._get_numeric_data())))","73579c98":"submission.to_csv(\"submission.csv\", index=False)\nsubmission","02c16288":"# import seaborn as sns\n# sns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\n# solution = pd.DataFrame(solution)\n# ax = sns.barplot( x=solution.index,y=0, data=solution,palette=\"Blues_d\")\n# ax.set(xlabel='Model', ylabel='Optimized weight in the average ')\n# ax.set_xticklabels(['DNN Embedings','NolanFirstSubmission','DeepNeuralNet(DNN)'], rotation=30)","c5ece250":"the WRMSSEEvaluator class is from  https:\/\/www.kaggle.com\/c\/m5-forecasting-accuracy\/discussion\/133834"}}