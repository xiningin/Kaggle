{"cell_type":{"2fb2d9f2":"code","e0816cb1":"code","6a02b751":"code","6fab667d":"code","b69b08b7":"code","5a3315eb":"code","6dbbdfe3":"code","6fe3d78e":"code","e4cff44c":"code","e0b26972":"code","9f332d3d":"code","e3494c5a":"code","6fe56ee6":"code","de3298a1":"code","fdf18587":"code","b38a88d1":"code","89895d14":"code","54e81c6b":"code","1caf4aa1":"code","14710528":"code","af7f5cd9":"code","6ee01d84":"code","f5ff5e4f":"code","d84c247f":"code","3121ebe8":"code","536af599":"code","8a32b688":"code","83eb3b2c":"code","7e39cbd0":"code","908a6ac7":"code","2945653c":"code","e91f995b":"code","ef331c37":"code","23f2491f":"code","f25d23ad":"code","3eba75a1":"code","8b982c3f":"code","f3ed4a78":"code","5542ddc1":"code","fbd98ba9":"code","2a9c18bf":"code","9fff0b9c":"code","ec457d33":"code","03597aed":"code","b595cd1a":"code","d0db54ad":"code","0c559a08":"code","4d7f4831":"code","1f8a0884":"code","5f613d72":"code","e4179ec4":"code","eb2f6127":"code","e7956e61":"code","63eb7364":"code","5038b228":"code","d19d9c87":"code","045e28ab":"code","2786eeb4":"code","4ef82ec0":"code","ec21ccac":"code","823bbb70":"code","d355f04f":"code","10da7ed9":"code","47f37e81":"code","b96f54f1":"code","1146e5d1":"code","fb793768":"code","d5472ec5":"code","0da6b694":"code","beb3227d":"code","c8a55e6b":"code","9d1b9b2d":"code","855dfd7c":"code","1ff2b55b":"markdown","1ae1d192":"markdown","2b7ed887":"markdown","2057d6f0":"markdown","23317c62":"markdown","aaee707c":"markdown","35ec382c":"markdown","9e5e18bc":"markdown","308f2908":"markdown","1f2e54ca":"markdown","c3361b2d":"markdown","f1a8d744":"markdown","92ccfca2":"markdown","c8b66911":"markdown","2a49765d":"markdown","dd745164":"markdown","811c0871":"markdown","ed8431ff":"markdown","b4f83aaa":"markdown","907a36ab":"markdown","54851607":"markdown","836bc316":"markdown","a47eedb9":"markdown","357f834a":"markdown","eef77336":"markdown","2c47af65":"markdown","84b8faa9":"markdown","19d49095":"markdown","cf4b900f":"markdown"},"source":{"2fb2d9f2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e0816cb1":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","6a02b751":"df.describe()","6fab667d":"# no null values\ndf.isnull().sum().max()","b69b08b7":"df.columns","5a3315eb":"print('No Frauds:', round(df.Class.value_counts()[0] \/ len(df) * 100, 2), '%')\nprint('Frauds:', round(df.Class.value_counts()[1] \/ len(df) * 100, 2),  '%')","6dbbdfe3":"sns.countplot('Class', data=df)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\nplt.show()","6fe3d78e":"fig, ax = plt.subplots(1, 2, figsize=(18, 4))\n\namount_val = df.Amount.values\ntime_val = df.Time.values\n\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])\nplt.show()","e4cff44c":"from sklearn.preprocessing import StandardScaler, RobustScaler\n\n# std_scaler = StandardScaler()\nrob_scaler = RobustScaler() #more robust to outliers\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df.Amount.values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df.Time.values.reshape(-1, 1))\n\ndf_scaled = df.drop(['Time', 'Amount'], axis=1)","e0b26972":"scaled_amount = df.scaled_amount\nscaled_time = df.scaled_time\n\ndf_scaled.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndf_scaled.insert(0, 'scaled_amount', scaled_amount)\ndf_scaled.insert(1, 'scaled_time', scaled_time)","9f332d3d":"df_scaled.head()","e3494c5a":"from sklearn.model_selection import train_test_split, StratifiedKFold\n\nX = df_scaled.drop('Class', axis=1)\ny = df_scaled.Class\n\nskf = StratifiedKFold(n_splits=5, shuffle=False)\n\nfor train_index, test_index in skf.split(X, y):\n    original_X_train, original_X_test = X.iloc[train_index], X.iloc[test_index]\n    original_y_train, original_y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    original_X_train, original_X_test = original_X_train.values, original_X_test.values\n    original_y_train, original_y_test = original_y_train.values, original_y_test.values\n\n    # see if the train and test set have similar distributed labels\n    _, train_label_count = np.unique(original_y_train, return_counts=True)\n    _, test_label_count = np.unique(original_y_test, return_counts=True)\n\n    print('Label Distributions:')\n    print(train_label_count \/ len(original_y_train))\n    print(test_label_count \/ len(original_y_test))","6fe56ee6":"# see if the train and test set have similar distributed labels\n# _, train_label_count = np.unique(original_y_train, return_counts=True)\n# _, test_label_count = np.unique(original_y_test, return_counts=True)\n\n# print('Label Distributions:')\n# print(train_label_count \/ len(original_y_train))\n# print(test_label_count \/ len(original_y_test))","de3298a1":"y.value_counts()","fdf18587":"# shuffle before creating subsamples\ndf_scaled = df_scaled.sample(frac=1, random_state=42)\n\ndf_fraud = df_scaled.loc[df_scaled.Class == 1]\ndf_non_fraud = df_scaled.loc[df_scaled.Class == 0][:492]\n\ndf_norm = pd.concat([df_fraud, df_non_fraud]).sample(frac=1, random_state=42)","b38a88d1":"df_norm.head()","89895d14":"print('Label Distribution:')\nprint(df_norm.Class.value_counts() \/ len(df_norm))","54e81c6b":"sns.countplot('Class', data=df_norm)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\nplt.show()","1caf4aa1":"plt.figure(figsize=(12, 10))\ncorr = df_norm.corr()\nfig = sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20})\nfig.set_title('Correlation Matrix', fontsize=14)\nplt.show()","14710528":"corr","af7f5cd9":"# top 3 most positive\/negative correlated features\nabs(corr['Class']).sort_values(ascending=False)[1:4]","6ee01d84":"fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\nsns.boxplot(x='Class', y='V14', data=df_norm, ax=ax[0])\nax[0].set_title('V14 vs Class')\nsns.boxplot(x='Class', y='V4', data=df_norm, ax=ax[1])\nax[1].set_title('V4 vs Class')\nsns.boxplot(x='Class', y='V11', data=df_norm, ax=ax[2])\nax[2].set_title('V11 vs Class')\nplt.show()","f5ff5e4f":"from scipy.stats import norm\n\nfig, ax = plt.subplots(1, 3, figsize=(20, 6))\n\nv14_fraud_dist = df_norm.V14.loc[df_norm.Class == 1].values\nsns.distplot(v14_fraud_dist, ax=ax[0], fit=norm, color='red')\nax[0].set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv4_fraud_dist = df_norm.V4.loc[df_norm.Class == 1].values\nsns.distplot(v4_fraud_dist, ax=ax[1], fit=norm, color='green')\nax[1].set_title('V4 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv11_fraud_dist = df_norm.V11.loc[df_norm.Class == 1].values\nsns.distplot(v11_fraud_dist, ax=ax[2], fit=norm, color='blue')\nax[2].set_title('V11 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nplt.show()","d84c247f":"df_norm.shape","3121ebe8":"# removing outliers of V14 feature\nv14_fraud = v14_fraud_dist\nq25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\nv14_iqr = q75 - q25\n\nv14_cut_off = v14_iqr * 1.5\nv14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\nprint('V14 Lower Threshold: {}'.format(v14_lower))\nprint('V14 Upper Threshold: {}'.format(v14_upper))\nv14_outliers = [x for x in v14_fraud if  x < v14_lower or x > v14_upper]\nprint('V14 Outliers: {}'.format(v14_outliers))\nprint('Number of V14 Outliers: {}'.format(len(v14_outliers)))\ndf_final = df_norm.drop(df_norm[(df_norm.V14 < v14_lower) | (df_norm.V14 > v14_upper)].index)\n\nprint('---' * 50)\n\n# removing outliers of V4 feature\nv4_fraud = df_final.V4.loc[df_final.Class == 1].values\nq25, q75 = np.percentile(v4_fraud, 25), np.percentile(v4_fraud, 75)\nv4_iqr = q75 - q25\n\nv4_cut_off = v4_iqr * 1.5\nv4_lower, v4_upper = q25 - v4_cut_off, q75 + v4_cut_off\nprint('V4 Lower Threshold: {}'.format(v4_lower))\nprint('V4 Upper Threshold: {}'.format(v4_upper))\nv4_outliers = [x for x in v4_fraud if  x < v4_lower or x > v4_upper]\nprint('V4 Outliers: {}'.format(v4_outliers))\nprint('Number of V4 Outliers: {}'.format(len(v4_outliers)))\ndf_final = df_final.drop(df_final[(df_final.V4 < v4_lower) | (df_final.V4 > v4_upper)].index)\n\nprint('---' * 50)\n\n# removing outliers of V10 feature\nv11_fraud = df_final.V11.loc[df_final.Class == 1].values\nq25, q75 = np.percentile(v11_fraud, 25), np.percentile(v11_fraud, 75)\nv11_iqr = q75 - q25\n\nv11_cut_off = v11_iqr * 1.5\nv11_lower, v11_upper = q25 - v11_cut_off, q75 + v11_cut_off\nprint('V11 Lower Threshold: {}'.format(v11_lower))\nprint('V11 Upper Threshold: {}'.format(v11_upper))\nv11_outliers = [x for x in v11_fraud if  x < v11_lower or x > v11_upper]\nprint('V11 Outliers: {}'.format(v11_outliers))\nprint('Number of V11 Outliers: {}'.format(len(v11_outliers)))\ndf_final = df_final.drop(df_final[(df_final.V11 < v11_lower) | (df_final.V11 > v11_upper)].index)","536af599":"df_final.shape","8a32b688":"from sklearn.manifold import TSNE\n\nX = df_final.drop('Class', axis=1)\ny = df_final['Class']\n\nX_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)","83eb3b2c":"import matplotlib.patches as mpatches\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\nax.scatter(X_reduced_tsne[:, 0], X_reduced_tsne[:, 1], c=(y==0), cmap='coolwarm', label='No Fraud')\nax.scatter(X_reduced_tsne[:, 0], X_reduced_tsne[:, 1], c=(y==1), cmap='coolwarm', label='Fraud')\nax.set_title('t_SNE', fontsize=14)\nax.grid(True)\nax.legend(handles=[blue_patch, red_patch])\nplt.show()","7e39cbd0":"# note that we are using the undersampled dataset\n# undersampling before cross validation will prone to overfit the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_test, y_train, y_test = X_train.values, X_test.values, y_train.values, y_test.values","908a6ac7":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","2945653c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifiers = {'LogisticRegression': LogisticRegression(), \n               'KNearest': KNeighborsClassifier(), \n               'Support Vector Classifer': SVC(), \n               'DecisionTreeClassifier': DecisionTreeClassifier()}","e91f995b":"from sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print('{} Cross Validation Score: {}%'.format(key, round(training_score.mean() * 100, 2)))","ef331c37":"from sklearn.model_selection import GridSearchCV\n\nlog_reg_params = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(X_train, y_train)\nlog_reg = grid_log_reg.best_estimator_\n\nknears_params = {'n_neighbors': list(range(2, 5, 1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(X_train, y_train)\nknears_neighbors = grid_knears.best_estimator_\n\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(X_train, y_train)\nsvc = grid_svc.best_estimator_\n\ntree_params = {'criterion': ['gini', 'entropy'], 'max_depth': list(range(2, 4, 1)), 'min_samples_leaf': list(range(5, 7, 1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(X_train, y_train)\ntree_clf = grid_tree.best_estimator_","23f2491f":"log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\nprint('Logistic Regression Cross Validation Score: {}%'.format(round(log_reg_score.mean() * 100, 2)))\n\nknears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\nprint('Knears Neighbors Cross Validation Score: {}%'.format(round(knears_score.mean() * 100, 2)))\n\nsvc_score = cross_val_score(svc, X_train, y_train, cv=5)\nprint('Support Vector Classifier Cross Validation Score: {}%'.format(round(svc_score.mean() * 100, 2)))\n\ntree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\nprint('DecisionTree Classifier Cross Validation Score: {}%'.format(round(tree_score.mean() * 100, 2)))","f25d23ad":"df_scaled.head()","3eba75a1":"# undersampling during cross validation\nundersample_X = df_scaled.drop('Class', axis=1)\nundersample_y = df_scaled['Class']\n\nfor train_index, test_index in skf.split(undersample_X, undersample_y):\n    undersample_X_train, undersample_X_test = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n    undersample_y_train, undersample_y_test = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n    \nundersample_X_train, undersample_X_test = undersample_X_train.values, undersample_X_test.values\nundersample_y_train, undersample_y_test = undersample_y_train.values, undersample_y_test.values\n\nundersample_accuracy = []\nundersample_precision = []\nundersample_recall = []\nundersample_f1 = []\nundersample_auc = []","8b982c3f":"from imblearn.under_sampling import NearMiss\nfrom collections import Counter\n\nX_nearmiss, y_nearmiss = NearMiss().fit_resample(undersample_X.values, undersample_y.values)\nprint('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))","f3ed4a78":"from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n\nfor train, test in skf.split(undersample_X_train, undersample_y_train):\n    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg)\n    undersample_model = undersample_pipeline.fit(undersample_X_train[train], undersample_y_train[train])\n    undersample_prediction = undersample_model.predict(undersample_X_train[test])\n    undersample_accuracy.append(undersample_pipeline.score(undersample_X_train[test], undersample_y_train[test]))\n    undersample_precision.append(precision_score(undersample_y_train[test], undersample_prediction))\n    undersample_recall.append(recall_score(undersample_y_train[test], undersample_prediction))\n    undersample_f1.append(f1_score(undersample_y_train[test], undersample_prediction))\n    undersample_auc.append(roc_auc_score(undersample_y_train[test], undersample_prediction))","5542ddc1":"from sklearn.model_selection import ShuffleSplit, learning_curve\n\ndef plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(0.1, 1.0, 5)):\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 14), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n        \n    train_sizes, train_scores, test_scores = learning_curve(estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='red')\n    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='blue')\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color='red', label='Training score')\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color='blue', label='Cross-validation score')\n    ax1.set_title('Logistic Regression Learning Curve', fontsize=14)\n    ax1.set_xlabel('Training size (m)')\n    ax1.set_ylabel('Score')\n    ax1.grid(True)\n    ax1.legend(loc='best')\n    \n    train_sizes, train_scores, test_scores = learning_curve(estimator2, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='red')\n    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='blue')\n    ax2.plot(train_sizes, train_scores_mean, 'o-', color='red', label='Training score')\n    ax2.plot(train_sizes, test_scores_mean, 'o-', color='blue', label='Cross-validation score')\n    ax2.set_title('K-Nearest Neighbors Learning Curve', fontsize=14)\n    ax2.set_xlabel('Training size (m)')\n    ax2.set_ylabel('Score')\n    ax2.grid(True)\n    ax2.legend(loc='best')\n    \n    train_sizes, train_scores, test_scores = learning_curve(estimator3, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='red')\n    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='blue')\n    ax3.plot(train_sizes, train_scores_mean, 'o-', color='red', label='Training score')\n    ax3.plot(train_sizes, test_scores_mean, 'o-', color='blue', label='Cross-validation score')\n    ax3.set_title('Support Vector Classifier Learning Curve', fontsize=14)\n    ax3.set_xlabel('Training size (m)')\n    ax3.set_ylabel('Score')\n    ax3.grid(True)\n    ax3.legend(loc='best')\n    \n    train_sizes, train_scores, test_scores = learning_curve(estimator4, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='red')\n    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color='blue')\n    ax4.plot(train_sizes, train_scores_mean, 'o-', color='red', label='Training score')\n    ax4.plot(train_sizes, test_scores_mean, 'o-', color='blue', label='Cross-validation score')\n    ax4.set_title('Decision Tree Classifier Learning Curve', fontsize=14)\n    ax4.set_xlabel('Training size (m)')\n    ax4.set_ylabel('Score')\n    ax4.grid(True)\n    ax4.legend(loc='best')\n    return","fbd98ba9":"cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\nplot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, ylim=(0.87, 1.01), cv=cv, n_jobs=4)","2a9c18bf":"from sklearn.metrics import roc_curve\nfrom sklearn.model_selection import cross_val_predict\n\nlog_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5, method='decision_function')\nknears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)\nsvc_pred = cross_val_predict(svc, X_train, y_train, cv=5, method='decision_function')\ntree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)","9fff0b9c":"print('Logistic Regression:', roc_auc_score(y_train, log_reg_pred))\nprint('K-Nearest Neighbors:', roc_auc_score(y_train, knears_pred))\nprint('Support Vector Classifier:', roc_auc_score(y_train, svc_pred))\nprint('Decision Tree Classifier:', roc_auc_score(y_train, tree_pred))","ec457d33":"log_fpr, log_tpr, log_threshold = roc_curve(y_train, log_reg_pred)\nknears_fpr, knears_tpr, knears_threshold = roc_curve(y_train, knears_pred)\nsvc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\ntree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n\ndef graph_roc_curve_multiple(log_fpr, log_tpr, knears_fpr, knears_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):\n    plt.figure(figsize=(16,8))\n    plt.title('ROC Curve \\n Top 4 Classifiers', fontsize=18)\n    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n    plt.plot(knears_fpr, knears_tpr, label='K-Nearest Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.01, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.legend()\n    \ngraph_roc_curve_multiple(log_fpr, log_tpr, knears_fpr, knears_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)\nplt.show()","03597aed":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, threshold = precision_recall_curve(y_train, log_reg_pred)","b595cd1a":"from sklearn.metrics import accuracy_score\n\ny_pred = log_reg.predict(X_train)\n\n# overfitting case (undersampling before cross validation)\nprint('Overfitting case:')\nprint('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))\nprint('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))\nprint('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))\nprint('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))\nprint('---' * 50)\n\n# normal case (undersampling during cross validation)\nprint('Normal case:')\nprint('Recall Score: {:.2f}'.format(np.mean(undersample_recall)))\nprint('Precision Score: {:.2f}'.format(np.mean(undersample_precision)))\nprint('F1 Score: {:.2f}'.format(np.mean(undersample_f1)))\nprint('Accuracy Score: {:.2f}'.format(np.mean(undersample_accuracy)))","d0db54ad":"from sklearn.metrics import average_precision_score\n\nundersample_y_score = log_reg.decision_function(undersample_X_test)\nundersample_average_precision = average_precision_score(undersample_y_test, undersample_y_score)\nprint('Average precision-recall score: {0:0.2f}'.format(undersample_average_precision))","0c559a08":"fig = plt.figure(figsize=(12, 6))\nprecision, recall, _ = precision_recall_curve(undersample_y_test, undersample_y_score)\nplt.step(recall, precision)\nplt.fill_between(recall, precision, alpha=0.2)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('Precision-Recall Curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(undersample_average_precision), fontsize=16)\nplt.show()","4d7f4831":"len(original_X_train), len(original_X_test)","1f8a0884":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import RandomizedSearchCV\n\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\n\nlog_reg_params = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\nrand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n\nfor train, test in skf.split(original_X_train, original_y_train):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg)\n    model = pipeline.fit(original_X_train[train], original_y_train[train])\n    best_est = rand_log_reg.best_estimator_\n    prediction = best_est.predict(original_X_train[test])\n    \n    accuracy_lst.append(pipeline.score(original_X_train[test], original_y_train[test]))\n    precision_lst.append(precision_score(original_y_train[test], prediction))\n    recall_lst.append(recall_score(original_y_train[test], prediction))\n    f1_lst.append(f1_score(original_y_train[test], prediction))\n    auc_lst.append(roc_auc_score(original_y_train[test], prediction))\n    \nprint(\"Accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"Precision: {}\".format(np.mean(precision_lst)))\nprint(\"Recall: {}\".format(np.mean(recall_lst)))\nprint(\"F1: {}\".format(np.mean(f1_lst)))","5f613d72":"from sklearn.metrics import classification_report\n\nlabels = ['No Fraud', 'Fraud']\nsmote_prediction = best_est.predict(original_X_test)\n\nprint(classification_report(original_y_test, smote_prediction, target_names=labels))","e4179ec4":"y_score = best_est.decision_function(original_X_test)","eb2f6127":"average_precision = average_precision_score(original_y_test, y_score)\nprint('Average precision-recall score: {0:0.2f}'.format(average_precision))","e7956e61":"fig = plt.figure(figsize=(12, 6))\nprecision, recall, _ = precision_recall_curve(original_y_test, y_score)\nplt.step(recall, precision)\nplt.fill_between(recall, precision, alpha=0.2)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('Precision-Recall Curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(average_precision), fontsize=16)\nplt.show()","63eb7364":"from sklearn.metrics import confusion_matrix\n\n# y_pred_log_reg = best_est.predict(X_test)\n# y_pred_knears = knears_neighbors.predict(X_test)\n# y_pred_svc = svc.predict(X_test)\n# y_pred_tree = tree_clf.predict(X_test)\n\ny_pred_log_reg = best_est.predict(original_X_test)\ny_pred_knears = knears_neighbors.predict(original_X_test)\ny_pred_svc = svc.predict(original_X_test)\ny_pred_tree = tree_clf.predict(original_X_test)\n\n# log_reg_cf = confusion_matrix(y_test, y_pred_log_reg)\n# kneighbors_cf = confusion_matrix(y_test, y_pred_knears)\n# svc_cf = confusion_matrix(y_test, y_pred_svc)\n# tree_cf = confusion_matrix(y_test, y_pred_tree)\n\nlog_reg_cf = confusion_matrix(original_y_test, y_pred_log_reg)\nkneighbors_cf = confusion_matrix(original_y_test, y_pred_knears)\nsvc_cf = confusion_matrix(original_y_test, y_pred_svc)\ntree_cf = confusion_matrix(original_y_test, y_pred_tree)\n\nfig, ax = plt.subplots(2, 2, figsize=(22, 12))\n\nsns.heatmap(log_reg_cf, ax=ax[0][0], annot=True, cmap=plt.cm.copper)\nax[0, 0].set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\nax[0, 0].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[0, 0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nsns.heatmap(kneighbors_cf, ax=ax[0][1], annot=True, cmap=plt.cm.copper)\nax[0][1].set_title(\"K-Nearest Neighbors \\n Confusion Matrix\", fontsize=14)\nax[0][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[0][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nsns.heatmap(svc_cf, ax=ax[1][0], annot=True, cmap=plt.cm.copper)\nax[1][0].set_title(\"Support Vector Classifier \\n Confusion Matrix\", fontsize=14)\nax[1][0].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[1][0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nsns.heatmap(tree_cf, ax=ax[1][1], annot=True, cmap=plt.cm.copper)\nax[1][1].set_title(\"Decision Tree Classifier \\n Confusion Matrix\", fontsize=14)\nax[1][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[1][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\n\nplt.show()","5038b228":"print('Logistic Regression:')\nprint(classification_report(original_y_test, y_pred_log_reg))\n\nprint('K-Nearest Neighbors:')\nprint(classification_report(original_y_test, y_pred_knears))\n\nprint('Support Vector Classifier:')\nprint(classification_report(original_y_test, y_pred_svc))\n\nprint('Decision Tree Classifier:')\nprint(classification_report(original_y_test, y_pred_tree))","d19d9c87":"# comparing models fit on undersampled & oversampled dataset\ny_pred = log_reg.predict(original_X_test)\nundersample_score = accuracy_score(original_y_test, y_pred)\n\ny_pred_sm = best_est.predict(original_X_test)\noversample_score = accuracy_score(original_y_test, y_pred_sm)\n\nd = {'Technique': ['Random Undersampling', 'Oversampling (SMOTE)'], 'Score': [undersample_score, oversample_score]}\ndf_result = pd.DataFrame(data=d)\ndf_result","045e28ab":"n_inputs = X_train.shape[1]\n\nundersample_model = keras.models.Sequential([keras.layers.Dense(n_inputs, input_shape=(n_inputs,), activation='relu'), \n                                             keras.layers.Dense(32, activation='relu'), \n                                             keras.layers.Dense(1, activation='sigmoid')])","2786eeb4":"undersample_model.summary()","4ef82ec0":"undersample_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","ec21ccac":"undersample_model.fit(X_train, y_train, validation_split=0.2, batch_size=25, epochs=20, shuffle=True)","823bbb70":"undersample_predictions = undersample_model.predict(original_X_test)","d355f04f":"undersample_fraud_predictions = np.array([1 if prediction >= 0.5 else 0 for prediction in undersample_predictions])","10da7ed9":"import itertools\n\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=14)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'),horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","47f37e81":"undersample_cm = confusion_matrix(original_y_test, undersample_fraud_predictions)\nundersample_cm","b96f54f1":"labels = ['No Fraud', 'Fraud']\nfig = plt.figure(figsize=(8, 8))\nplot_confusion_matrix(undersample_cm, labels, title='Random Undersampling \\n Confusion Matrix')\nplt.show()","1146e5d1":"# oversample dataset using SMOTE\nsm = SMOTE(sampling_strategy='minority', random_state=42)\nXsm_train, ysm_train = sm.fit_resample(original_X_train, original_y_train)","fb793768":"n_inputs = Xsm_train.shape[1]\n\noversample_model = keras.models.Sequential([keras.layers.Dense(n_inputs, input_shape=(n_inputs,), activation='relu'), \n                                             keras.layers.Dense(32, activation='relu'), \n                                             keras.layers.Dense(1, activation='sigmoid')])","d5472ec5":"oversample_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","0da6b694":"oversample_model.fit(Xsm_train, ysm_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True)","beb3227d":"oversample_predictions = oversample_model.predict(original_X_test)","c8a55e6b":"oversample_fraud_predictions = np.array([1 if prediction >= 0.5 else 0 for prediction in oversample_predictions])","9d1b9b2d":"oversample_cm = confusion_matrix(original_y_test, oversample_fraud_predictions)\noversample_cm","855dfd7c":"fig = plt.figure(figsize=(8, 8))\nplot_confusion_matrix(oversample_cm, labels, title='Oversampling (SMOTE) \\n Confusion Matrix')\nplt.show()","1ff2b55b":"## Neural Networks","1ae1d192":"## Undersampling during cross validation","2b7ed887":"Since the features V1 to V28 has been scaled beforehand, we will also scale the columns Time and Amount:","2057d6f0":"Now we will take a look at the confusion matrix of predicting the original test dataset (i.e., original_X_test). <br>\nNote that: <br>\nTrue Negatives (Top-left): Correctly classifying 0 Class (No Fraud) <br>\nFalse Positives (Top-right): Incorrectly classifying as 1 Class (Fraud). Actual is 0 Class (No Fraud) <br>\nFalse Negatives (Bottom-left): Incorrectly classifying 0 Class (No Fraud). Actual is 1 Class (Fraud) <br>\nTrue Positives (Bottom-right): Correctly classifying 1 Class (Fraud)","23317c62":"## Undersampling before cross validation","aaee707c":"We will first plot out the correlation matrix to determine the most correlated features with respect to the target variable:","35ec382c":"In this project, we will be predicting whether a transaction is fraud or not fraud by using predictive models. The dataset given contains features V1 to V28 which are a result of PCA dimensionality reduction to protect user identities and sensitive features (according to the description).","9e5e18bc":"## Scaling and Undersampling","308f2908":"Note that the dataset is highly imbalaced. If we use this dataset straight away for fitting models, we will probably overfit it since the models will assume that most transaction are not fraud.","1f2e54ca":"## Detecting Anomalies","c3361b2d":"We can see that the recall of this model has improved compared to the models we implemented previously.","f1a8d744":"We will be splitting the original DataFrame first before proceeding to undersample the dataset. This is because we want to evaluate our models based on the original test dataset.","92ccfca2":"Let's see if the t-SNE algorithm can accurately classify the dataset:","c8b66911":"## Dimensionality Reduction and Clustering","2a49765d":"The neural network we fitted on the oversampled dataset has lower recall than the previous neural network. However, the precision has also significantly improved.","dd745164":"When we are building a classifier, both precision and recall are important, but it all comes down to the task we are given. In this particular project, higher recall means we can detect more frauds which leads to a more safer platform, whereas higher precision means that we can correctly detect the fraud cases which leads to customer satisfaction (from avoiding their accounts getting blocked). Moreover, we can still improve on our oversampled dataset by removing outliers, and also fine tuning our neural network models.","811c0871":"# Conclusion","ed8431ff":"Next we will be removing the outliers with respect to V14, V4 and V11, starting with the most postive\/negative correlated feature (i.e., V14). We will be setting our thresholds to 1.5 times the Interquartile Range (75th percentile - 25th percentile). Note that we have to be aware of not removing too many data points because the model might underfit the data.","b4f83aaa":"Note that there is only 492 fraud transactions, so we will be including only 492 non-fraud trasactions to achieve a 50\/50 ratio.","907a36ab":"We will see if implementing neural networks can increase our performance for both undersampled and oversampled datasets.","54851607":"# Data Pre-processing","836bc316":"## SMOTE (Oversampling)","a47eedb9":"Let's look into Logistic Regression specifically:","357f834a":"Comparing the distributions of the 3 most positive\/negative correlated features to the target variable (i.e., V14, V4, V11), only V4 has a slightly skewed distribution.","eef77336":"# Model Building","2c47af65":"Logistic Regression has the highest accuracy score among the classifiers. Let's further tune the hyperparameters of each classifier by using GridSearchCV:","84b8faa9":"# Introduction","19d49095":"The code below shows how to implement the NearMiss method for undersampling;","cf4b900f":"The common mistake while undersampling or oversampling is doing it before cross validation. It will directly influence the validation set, hence it will show good precision and recall scores but in reality the data is overfitted. More info on this kernel: https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets\/notebook"}}