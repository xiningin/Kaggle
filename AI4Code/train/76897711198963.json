{"cell_type":{"798afe82":"code","2a5e49dc":"code","7694d84e":"code","b9e1adb4":"code","eb515f30":"code","8df73497":"code","dc2eb72d":"code","6d43873d":"code","eb1b7b61":"code","befd1d38":"code","2f9a0dc0":"code","c2fa80bd":"code","d7df7009":"code","f448e7d2":"code","8c417856":"markdown","6be3d614":"markdown","ac1f9866":"markdown","d643e236":"markdown","1eefc07d":"markdown","fbdda854":"markdown","a3c70aa9":"markdown"},"source":{"798afe82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import MaxPool2D, Dropout\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.utils.np_utils import to_categorical\nfrom keras.optimizers import RMSprop,Adam\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline","2a5e49dc":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nX_train = train.drop(\"label\",axis=1)\ny_train = train[\"label\"]\nX_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","7694d84e":"# Explore the shape of the training set. There are 42000 observations with 784 features (28x28) and a label\nX_train.shape","b9e1adb4":"# Plot barchart to visualize distribution of digits in the labelled data\n# The distribution of digits is fairly uniform\nsns.set_palette(\"pastel\")\nax = sns.barplot(train['label'].value_counts().index, train['label'].value_counts()\/len(train))\nax.set_title(\"Distribution of digits in labelled data\")\nax.set_ylabel(\"Percentage\")\nax.set_xlabel(\"Digit\")\nsns.despine();","eb515f30":"# This function plots the image of a particular value in the training set\ndef plot_image(id):\n    img = X_train.iloc[id].values\n    img = img.reshape((28,28))\n    plt.imshow(img,cmap='gray')\n    plt.title(train.iloc[id,0])\n    plt.axis(\"off\")\n    plt.show()\n\n# Change the argument of the function to visualize other numbers\nplot_image(19)","8df73497":"# We split the data with labels into training set and validation set\n# 95% of data in training set, 5% in hold-out validation set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.05, random_state=2)","dc2eb72d":"# Perform feature normalisation by dividing all values by 255 to get decimal values between 0 and 1\n# Activation functions tend to work better with values between 0 and 1\nX_train\/=255\nX_val\/=255\nX_test\/=255","6d43873d":"# Reshape the X values. The 784 features attributed to each observation is converted to 28x28x1\nX_train=X_train.values.reshape(-1,28,28,1)\nX_val=X_val.values.reshape(-1,28,28,1)\nX_test=X_test.values.reshape(-1,28,28,1)","eb1b7b61":"#### Build Convolutional Neural Network using Keras\n# # Objective of zero padding is to pad the border of the input with zeroes so as not to lose information at the edges of the image\n# Batch normalization helps to accelerate the learning process by adjusting and scaling the activations\n# Max Pooling helps to reduce the size of the representation, thereby speeding up learning process\n# Dropout Regularization helps to reduce overfitting (randomly selected neurons are ignored during training)\nmodel = Sequential()\n\n\n# Conv --> Batch Norm --> ReLU --> MaxPool --> Dropout \nmodel.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                 input_shape = (28,28,1)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Conv --> Batch Norm --> ReLU --> MaxPool --> Dropout \nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Convert to vector\nmodel.add(Flatten())\n\n# Fully connected layers\nmodel.add(Dense(784, activation = \"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation = \"softmax\"))","befd1d38":"# Compile the model\n# Since this is a multi-class classification problem, we use the categorical cross entropy loss function\nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model on the training set\nmodel.fit(X_train, y_train, epochs=20)","2f9a0dc0":"# Predict the probabilities of each class\nval_predictions = model.predict(X_val)\n\n# For each training observation, identify the predicted class\nval_pred = np.argmax(val_predictions, axis = 1)\n\n# Generate confusion matrix\nconfusion_mtx = confusion_matrix(y_val, val_pred) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Blues\",linecolor=\"grey\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# We are reasonably happy with the model, with most images being classified correctly","c2fa80bd":"# See accuracy score when tested on cross-validation set\nprint(\"The accuracy score is \"+str(accuracy_score(y_val,val_pred)))","d7df7009":"# Predict the probabilities of each class\ntest_predictions = model.predict(X_test)\n\n# For each training observation, identify the predicted class\ntest_pred = np.argmax(test_predictions, axis = 1)\nprint(test_pred)","f448e7d2":"submission = pd.DataFrame({'ImageId':np.arange(1,28001),'Label':test_pred})\nsubmission.to_csv('submission.csv', index=False)","8c417856":"# 5) Generate predictions on validation set and evaluate our model\n","6be3d614":"# 1) Import libraries and packages","ac1f9866":"# 3) Exploratory data analysis","d643e236":"# 2) Load datasets","1eefc07d":"# Kaggle Project: Digit Recognition using Convolutional Neural Networks\nThe goal of this project is to recognize digits (0-9) using a training set of 42,000 handwritten images from the MNIST dataset.  To achieve this objective, I built a convolutional neural network (CNN) using Keras.\n\nPlease upvote this notebook if you find it helpful! Thank you :)\n\n# Acknowledgements\nhttps:\/\/www.kaggle.com\/kshitijkarnawat\/basic-3-layer-neural-network\n\nhttps:\/\/www.kaggle.com\/kanncaa1\/convolutional-neural-network-cnn-tutorial\n","fbdda854":"# 6) Generate predictions on test set","a3c70aa9":"# 4) Build CNN model using Keras"}}