{"cell_type":{"1ba1e9c8":"code","acd42962":"code","79ec5d53":"code","3c21200e":"code","aab12970":"code","d918dd37":"code","f8a08fe3":"code","25ca42c0":"code","5b14b426":"code","16be3877":"code","557415fd":"code","8e84c3fc":"code","e0e0e36b":"code","3760e261":"markdown","2a5a7cc0":"markdown","0fb6e854":"markdown"},"source":{"1ba1e9c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Plotting libraries\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","acd42962":"data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_ids = test[\"PassengerId\"]\n\ndata.head()","79ec5d53":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ncols = [\"Sex\", \"Embarked\"]\n\n\n# Embarked contains some missing entries so\ndata.Embarked.fillna(\"U\", inplace=True)\n\nfor col in cols:\n    data[col] = le.fit_transform(data[col])\n    test[col] = le.transform(test[col])\n    print(le.classes_)\n\ndata.head()","3c21200e":"corelation = data.corr()\nplt.figure(figsize=(15, 10))\nsns.heatmap(corelation, annot=True, cmap=\"Blues\")","aab12970":"data.isnull().sum()","d918dd37":"def clean(data):\n    data = data.drop([\"Ticket\", \"Name\", \"Cabin\", \"PassengerId\"], axis=1)\n    \n    cols = [\"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n    \n    for col in cols:\n        data[col].fillna(data[col].median(), inplace=True)\n    return data\n    \ndata = clean(data)\ntest = clean(test)","f8a08fe3":"data.head()","25ca42c0":"from sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ny = data[\"Survived\"]\nx = data.drop(\"Survived\", axis=1)\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.2, random_state=42)","5b14b426":"model = LogisticRegression(random_state=0, max_iter=1000).fit(x_train, y_train)","16be3877":"predictions = model.predict(x_val)\naccuracy_score(y_val, predictions)","557415fd":"submittion_preds = model.predict(test)","8e84c3fc":"df = pd.DataFrame({\n    \"PassengerId\":test_ids.values,\n    \"Survived\": submittion_preds\n})","e0e0e36b":"df.to_csv(\".\/submission.csv\", index=False)","3760e261":"## Loading Data & Preprocessing","2a5a7cc0":"## Corelational Analysis","0fb6e854":"## Data Cleansing"}}