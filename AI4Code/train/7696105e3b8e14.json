{"cell_type":{"7d380290":"code","dd87f888":"code","6c0c8482":"code","e1236112":"code","895f6643":"code","b4f3892d":"code","56d007ff":"code","21736a11":"code","807ee11a":"code","8154e634":"code","968c7462":"code","4a04125b":"code","063a2044":"code","b6ba17e3":"code","c1732b11":"code","58e31519":"code","6b69b408":"code","fa8b17f8":"code","c88b4a8a":"code","4e8a29d5":"code","ab4ba76c":"code","b55e12eb":"code","08b01ddd":"code","93409d1c":"code","dff3f357":"code","6a45f316":"code","6926cea5":"code","5efce1d6":"code","81b6b023":"code","b36330f4":"code","75241e3c":"code","a2860248":"code","9b9bb24e":"code","93cd0df5":"code","5b37132c":"code","8513666c":"code","7e9cf1aa":"code","7a04d969":"code","436a7460":"code","8cc2f762":"code","1160a6d6":"code","3452ddb4":"code","999c8b1e":"code","9280781a":"code","e111853e":"code","5c4a2cee":"code","eaa9304a":"code","4e7225f0":"code","be2f6a67":"code","dcc1ea5c":"code","bd620c93":"code","5b0365b5":"code","04a8526f":"code","572ed290":"code","601e6e68":"code","b61b4dcc":"code","82e8e1cf":"code","635ac914":"code","ea91c607":"code","0de20d3c":"code","a197588e":"code","71f42654":"code","9bc5f1d7":"code","9721ec2f":"code","0f445207":"code","46c4c8a8":"code","97cd52ac":"code","b8dce456":"code","2de1678f":"code","6b782cad":"code","b7076481":"code","3d35826a":"code","220ae647":"code","7d969caa":"code","6dde3cb6":"code","e20d13fd":"code","af0ce421":"code","fa364d0f":"code","b877b50f":"code","268f9ef9":"code","55e8ff62":"code","6179433b":"code","a0c8538b":"code","429500c8":"code","48fd7046":"code","99b3ff23":"code","f023c2f4":"code","13cff5f2":"code","ed80a6af":"code","377832e9":"code","2189e1df":"code","21e0e023":"code","ae67aaaf":"code","98a49a68":"code","cf448af7":"code","16693a06":"code","6830e3ac":"markdown","4f08186b":"markdown","8e96deaf":"markdown","e8702d0f":"markdown","59b0a697":"markdown","d394a399":"markdown","ad72cb1c":"markdown","bd3e0b53":"markdown","7ee2116b":"markdown","b556045d":"markdown","8a7672ae":"markdown","162f1e6c":"markdown","56ecf999":"markdown","e9c8999f":"markdown","68a3b01f":"markdown","68dc22e2":"markdown","ab742cd8":"markdown","dd1f40d8":"markdown","b4943f73":"markdown","18dea23a":"markdown","e501904a":"markdown","bf3d3b92":"markdown","cf38f87d":"markdown","e075c50f":"markdown","a14847df":"markdown","57483c54":"markdown","25b6ccaa":"markdown","8ae82dc9":"markdown"},"source":{"7d380290":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","dd87f888":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6c0c8482":"##\u5bfc\u5165\u6587\u4ef6\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nPassengerId = test['PassengerId']","e1236112":"train##\u8bad\u7ec3\u96c6\u6587\u4ef6 \u770b\u4e00\u4e0b","895f6643":"test ##\u770b\u4e00\u4e0b\u6d4b\u8bd5\u96c6\u6587\u4ef6","b4f3892d":"full_data = [train, test]\nSurvival = train['Survived']  ##\u76ee\u6807\u503c \nSurvival.describe()","56d007ff":"train.info()\n\ntest.info()","21736a11":"#full.isnull()\ntrain.isnull().sum()  #\u67e5\u770b\u7f3a\u5931\u503c\u603b\u6570","807ee11a":"train.Embarked.mode()  ##\u67e5\u770bEmbarked\u7684\u4f17\u6570\u4e3a\u591a\u5c11","8154e634":"train['Embarked'].fillna('S',inplace=True) ","968c7462":"train.Embarked.isnull().sum()\n##\u53ef\u4ee5\u770b\u5230Embarked\u7684\u7532\u677f\u6570\u636e\u5df2\u7ecf\u6ca1\u6709\u7f3a\u5931\u503c","4a04125b":"test[test.Fare.isnull()] \n##\u627e\u51faFare\u7684\u90a3\u4e2a\u4eba\u662f\u8c01\n##\u56e0\u4e3a\u8239\u7968\u4e0e\u5ba2\u623f\u7b49\u7ea7\u6709\u4e00\u5b9a\u5173\u7cfb,\u6240\u4ee5\u5728\u8fd9\u53c2\u8003\u5979\u662f\u54ea\u4e2a\u5ba2\u623f\u7684\u7b49\u7ea7","063a2044":"##\u627e\u51faPclass3\u7684\u5ba2\u4eba\u8239\u7968\u5e73\u5747\ntest[test.Pclass ==3]['Fare'].median()","b6ba17e3":"#\u5c06\u7f3a\u5931\u503c\u7684\u4eba\u586b\u6ee1 \ntest.Fare.fillna(test[test.Pclass ==3]['Fare'].median(),inplace = True)\ntest.loc[153] ","c1732b11":"##\u56e0\u4e3a\u6709\u5f88\u591a\u4eba\u6ca1\u6709\u8fd9\u7c7b\u6570\u636e,\u6240\u4ee5\u5c06\u5b83\u5355\u72ec\u63d0\u53d6\u51fa\u6765,\u5c06\u6709\u503c\u7684\u8bbe\u4e3a1,\u7f3a\u5931\u503c\u8bbe\u4e3a0 \n\ntrain.loc[train.Cabin.notnull(),'Cabin'] = 1\ntrain.loc[train.Cabin.isnull(),'Cabin'] = 0\ntrain['Cabin'] ##\u73b0\u5728\u770b\u5230Cabin\u7684\u503c\u90fd\u662f0\u6216\u662f1\u4e86,\u5e76\u65e0\u7f3a\u5931\u503c\n#print(full.Cabin.isnull().sum())\n\ntest.loc[test.Cabin.notnull(),'Cabin'] = 1\ntest.loc[test.Cabin.isnull(),'Cabin'] = 0\ntest['Cabin'] ##\u73b0\u5728\u770b\u5230Cabin\u7684\u503c\u90fd\u662f0\u6216\u662f1\u4e86,\u5e76\u65e0\u7f3a\u5931\u503c\n#print(full.Cabin.isnull().sum())\n","58e31519":"train.Cabin.isnull().sum()","6b69b408":"## \u53ef\u4ee5\u770b\u5230Name\u88ab','\u4ee5\u53ca'.'\u9694\u5f00,\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u4ec5\u62bd\u53d6\u4e24\u8005\u4e2d\u95f4\u7684title\n\ntrain['title'] = train['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\ntrain['title'] ##\u770b\u4e00\u4e0btitle \u533a\u5206\u51fa\u6765\u4e86!!!\n\ntest['title'] = test['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\ntest['title'] ##\u770b\u4e00\u4e0btitle \u533a\u5206\u51fa\u6765\u4e86!!!","fa8b17f8":"train.title.value_counts()\n##\u770b\u770btitle\u7684\u4e2a\u6570\u6392\u5217","c88b4a8a":"pd.crosstab(train.title,train.Sex)\n##crosstab\u5c31\u662f\u7528\u6765\u63d0\u53d6\u4e24\u79cd\u7279\u5f81\u6765\u770b\u770b\u603b\u6570","4e8a29d5":"train[(train.title=='Dr')&(train.Sex == 'female')]\n##\u627e\u51faDr\u7684\u90a3\u4f4d\u5973\u58eb","ab4ba76c":"change_title = {'Capt':'Rareman', 'Col':'Rareman','Don':'Rareman','Dona':'Rarewoman',\n    'Dr':'Rareman','Jonkheer':'Rareman','Lady':'Rarewoman','Major':'Rareman',\n    'Master':'Master','Miss':'Miss','Mlle':'Rarewoman','Mme':'Rarewoman',\n    'Mr':'Mr','Mrs':'Mrs','Ms':'Rarewoman','Rev':'Mr','Sir':'Rareman',\n    'the Countess':'Rarewoman'}","b55e12eb":"train.title = train.title.map(change_title ) \n##map\u662f\u4e2a\u51fd\u6570!!!!\n##\u73b0\u5728\u6765\u770b\u770bfull\u7684title\u7684\u5f62\u6001\ntrain.title.value_counts()\n\ntest.title = test.title.map(change_title ) \n##map\u662f\u4e2a\u51fd\u6570!!!!\n##\u73b0\u5728\u6765\u770b\u770bfull\u7684title\u7684\u5f62\u6001\ntest.title.value_counts()","08b01ddd":"train.loc[train.PassengerId==797,'title']='Rarewoman' \n##\u5c06\u90a3\u4f4d\u5973\u751f\u6539\u6210\u5bf9\u5e94\u7684\u7279\u5f81 \n##\u6ce8\u610f797 \u662f\u56e0\u4e3a\u4ece0\u5f00\u59cb\u6578,\u6240\u4ee5\u662f\ntrain.title.value_counts()\n##Rarewoman\u4ece8\u53d8\u62109","93409d1c":"\n    train['Name_length'] = train['Name'].apply(len)\n    # Qcut is a quantile based discretization function to autimatically create categories\n    # dataset['Name_length'] = pd.qcut(dataset['Name_length'], 6, labels=False)\n    # train['Name_length'].value_counts()\n\nsum_Name = train[[\"Name_length\", \"Survived\"]].groupby(['Name_length'],as_index=False).sum()\naverage_Name = train[[\"Name_length\", \"Survived\"]].groupby(['Name_length'],as_index=False).mean()\nfig, (axis1,axis2,axis3) = plt.subplots(3,1,figsize=(18,6))\nsns.barplot(x='Name_length', y='Survived', data=sum_Name, ax = axis1)\nsns.barplot(x='Name_length', y='Survived', data=average_Name, ax = axis2)\nsns.pointplot(x = 'Name_length', y = 'Survived', data=train, ax = axis3)","dff3f357":"test['Name_length'] = test['Name'].apply(len)","6a45f316":"train[train.title == 'Mr']['Age'].describe()","6926cea5":"train[train.title=='Master']['Age'].describe()","5efce1d6":"train[train.title=='Miss']['Age'].describe()","81b6b023":"train.Age.fillna(999,inplace=True) \ntest.Age.fillna(999,inplace=True) ","b36330f4":"def girl(girl):\n    if (girl.Age!=999)&(girl.title=='Miss')&(girl.Age<=14):\n        return 'Girl'\n    elif (girl.Age==999)&(girl.title=='Miss')&(girl.Parch!=0):\n        return 'Girl'\n    else:\n        return girl.title","75241e3c":"train['title']=train.apply(girl,axis=1)\ntrain.title.value_counts()","a2860248":"test['title']=train.apply(girl,axis=1)\ntest.title.value_counts()","9b9bb24e":"train[train.Age==999]['Age'].value_counts() \n##\u522b\u5fd8\u8bb0 \u6211\u4eec\u6709263\u4e2a\u7f3a\u5931\u503c\u7684\u6570\u636e","93cd0df5":"test[test.Age==999]['Age'].value_counts() ","5b37132c":"Tit=['Mr','Miss','Mrs','Master','Girl','Rareman','Rarewoman']\nfor i in Tit:\n    train.loc[(train.Age==999)&(train.title==i),'Age']=train.loc[train.title==i,'Age'].median()\n    ##\u5c06\u5269\u4e0b\u7684\u7f3a\u5931\u503c\u7528\u4e2d\u4f4d\u6570\u4ee3\u66ff","8513666c":"train.isnull().sum() \n##\u73b0\u5728\u518d\u770b\u4e00\u4e0b\u7f3a\u5931\u503c,\u5c31\u53ea\u5269","7e9cf1aa":"test.isnull().sum() \n##\u73b0\u5728\u518d\u770b\u4e00\u4e0b\u7f3a\u5931\u503c,\u5c31\u53ea\u5269","7a04d969":"train['FamilySize'] = train.apply(lambda x: x['SibSp']  +  x['Parch']+1, axis=1)\ntrain['IsAlone'] = 0\ntrain.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\ntrain\n\ntest['FamilySize'] = test.apply(lambda x: x['SibSp']  +  x['Parch']+1, axis=1)\ntest['IsAlone'] = 0\ntest.loc[test['FamilySize'] == 1, 'IsAlone'] = 1\ntest","436a7460":"train","8cc2f762":"train.FamilySize.value_counts()\n","1160a6d6":"test.FamilySize.value_counts()","3452ddb4":"train.FamilySizeCut=pd.cut(train.FamilySize,5)\ntest.FamilySizeCut=pd.cut(test.FamilySize,5)\n\npd.cut(train.FamilySize,5)  ##\u5c06\u5e74\u9f84\u5206\u6210\u4e94\u4e2a\u533a\u95f4 \n#full.Age\npd.cut(test.FamilySize,5)","999c8b1e":"test.FamilySizeCut.value_counts()","9280781a":"train.FamilySizeCut.value_counts().sort_index()\ntest.FamilySizeCut.value_counts().sort_index()","e111853e":"train.loc[train.FamilySize<=3,'FamilySizeCut']=1\ntrain.loc[(train.FamilySize>3)&(train.FamilySize<=5),'FamilySizeCut']=2\ntrain.loc[(train.FamilySize>5)&(train.FamilySize<=7),'FamilySizeCut']=3\ntrain.loc[(train.FamilySize>7)&(train.FamilySize<=9),'FamilySizeCut']=4\ntrain.loc[train.FamilySize>9,'FamilySizeCut']=5","5c4a2cee":"test.loc[test.FamilySize<=3,'FamilySizeCut']=1\ntest.loc[(test.FamilySize>3)&(test.FamilySize<=5),'FamilySizeCut']=2\ntest.loc[(test.FamilySize>5)&(test.FamilySize<=7),'FamilySizeCut']=3\ntest.loc[(test.FamilySize>7)&(test.FamilySize<=9),'FamilySizeCut']=4\ntest.loc[test.FamilySize>9,'FamilySizeCut']=5","eaa9304a":"#\u5c06\u5e74\u9f84\u5207\u5206\ntrain.AgeCut=pd.cut(train.Age,5)\ntest.AgeCut=pd.cut(test.Age,5)","4e7225f0":"pd.cut(train.Age,5)  ##\u5c06\u5e74\u9f84\u5206\u6210\u4e94\u4e2a\u533a\u95f4 \n#full.Age\npd.cut(test.Age,5)  ##\u5c06\u5e74\u9f84\u5206\u6210\u4e94\u4e2a\u533a\u95f4 ","be2f6a67":"train.FareCut=pd.qcut(train.Fare,5) ##\u5c06fare\u5206\u6210\u4e94\u4e2a\u533a\u95f4\ntest.FareCut=pd.qcut(test.Fare,5) ##\u5c06fare\u5206\u6210\u4e94\u4e2a\u533a\u95f4\n\npd.qcut(test.Fare,5)\npd.qcut(train.Fare,5)","dcc1ea5c":"train.loc[train.Fare<=7.854,'FareCut']=1\ntrain.loc[(train.Fare>7.854)&(train.Fare<=10.5),'FareCut']=2\ntrain.loc[(train.Fare>10.5)&(train.Fare<=21.558),'FareCut']=3\ntrain.loc[(train.Fare>21.558)&(train.Fare<=41.579),'FareCut']=4\ntrain.loc[train.Fare>41.579,'FareCut']=5\n\ntest.loc[test.Fare<=7.854,'FareCut']=1\ntest.loc[(test.Fare>7.854)&(test.Fare<=10.5),'FareCut']=2\ntest.loc[(test.Fare>10.5)&(test.Fare<=21.558),'FareCut']=3\ntest.loc[(test.Fare>21.558)&(test.Fare<=41.579),'FareCut']=4\ntest.loc[test.Fare>41.579,'FareCut']=5","bd620c93":"train.AgeCut.value_counts().sort_index()\n##\u5c06\u503c\u7684\u603b\u548c\u76f8\u52a0\u5e76\u5c0f\u6392\u5230\u5927\ntest.AgeCut.value_counts().sort_index()\n##full.AgeCut.value_counts()  \u53ef\u4ee5\u662f\u770b\u770b\u4e0d\u7528.sort_index() \u4ed6\u4f1a\u4f9d\u7167\u6700\u591a\u7684\u6570 \u800c\u4e0d\u662f\u4f9d\u7167\u533a\u95f4\u5927\u5c0f","5b0365b5":"train.AgeCut.value_counts()","04a8526f":"test.AgeCut.value_counts()","572ed290":"\ntrain.loc[train.Age<=16.136,'AgeCut']=1\ntrain.loc[(train.Age>16.136)&(train.Age<=32.102),'AgeCut']=2\ntrain.loc[(train.Age>32.102)&(train.Age<=48.068),'AgeCut']=3\ntrain.loc[(train.Age>48.068)&(train.Age<=64.034),'AgeCut']=4\ntrain.loc[train.Age>64.034,'AgeCut']=5\n\ntest.loc[test.Age<=16.136,'AgeCut']=1\ntest.loc[(test.Age>16.136)&(test.Age<=32.102),'AgeCut']=2\ntest.loc[(test.Age>32.102)&(test.Age<=48.068),'AgeCut']=3\ntest.loc[(test.Age>48.068)&(test.Age<=64.034),'AgeCut']=4\ntest.loc[test.Age>64.034,'AgeCut']=5","601e6e68":"train","b61b4dcc":"train.columns","82e8e1cf":"test.columns","635ac914":"train.drop(['Name'],axis=1,inplace=True)\ntrain.drop(['Fare'],axis=1,inplace=True)\ntrain.drop(['Age'],axis=1,inplace=True)\ntrain.drop(['IsAlone'],axis=1,inplace=True)\ntrain.drop(['PassengerId'],axis=1,inplace=True)\ntrain.drop(['FamilySize'],axis=1,inplace=True)\ntrain.drop(['Ticket'],axis=1,inplace=True)\n\ntest.drop(['Name'],axis=1,inplace=True)\ntest.drop(['Fare'],axis=1,inplace=True)\ntest.drop(['Age'],axis=1,inplace=True)\ntest.drop(['IsAlone'],axis=1,inplace=True)\ntest.drop(['PassengerId'],axis=1,inplace=True)\ntest.drop(['FamilySize'],axis=1,inplace=True)\ntest.drop(['Ticket'],axis=1,inplace=True)","ea91c607":"train","0de20d3c":"predictors=['Embarked','Parch','Pclass','Sex','SibSp','title','AgeCut','FamilySizeCut','FareCut','Cabin']","a197588e":"##\u505a\u72ec\u70ed\u7f16\u7801\ntrain_dummies=pd.get_dummies(train[predictors])\ntest=pd.get_dummies(test[predictors])","71f42654":"train_dummies","9bc5f1d7":"y = train['Survived']  ##\u6807\u7b7e\nframes = [train_dummies,y]  \ntrain_final = pd.concat(frames,axis = 1)  ##\u7279\u5f81","9721ec2f":"train.columns","0f445207":"test.columns","46c4c8a8":"X_train = train_final.drop(\"Survived\", axis=1)\nY_train = train_final[\"Survived\"]\nX_train.shape, Y_train.shape, test.shape\n\nfrom sklearn.model_selection import train_test_split\nX_train, x_test, Y_train, y_test = train_test_split(X_train, Y_train, test_size=0.3, random_state=101)\n\nX_test = test.copy()","97cd52ac":"import re           # Regular expression operations\nimport matplotlib.pyplot as plt # Collection of functions for scientific and publication-ready visualization\n%matplotlib inline\nimport plotly.offline as py     # Open source library for composing, editing, and sharing interactive data visualization \nfrom matplotlib import pyplot\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom collections import Counter\n\nimport seaborn as sns  # Visualization library based on matplotlib, provides interface for drawing attractive statistical graphics\n\nimport sklearn         \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier)\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report, precision_recall_curve, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')","b8dce456":"X_train.shape,Y_train.shape","2de1678f":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred1 = logreg.predict(x_test)\nacc_log = round(logreg.score(x_test, y_test) * 100, 2)\nacc_log","6b782cad":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, Y_pred1))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred1), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","b7076481":"svc=SVC()\nsvc.fit(X_train, Y_train)\nY_pred2 = svc.predict(x_test)\nacc_svc = round(svc.score(x_test, y_test) * 100, 2)\nacc_svc","3d35826a":"print(classification_report(y_test, Y_pred2))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred2), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","220ae647":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n                           metric_params=None, n_jobs=1, n_neighbors=10, p=2, \n                           weights='uniform')\nknn.fit(X_train, Y_train)\nknn_predictions = knn.predict(x_test)\nacc_knn = round(knn.score(x_test, y_test) * 100, 2)\n\n# Preparing data for Submission 1\ntest_Survived = pd.Series(knn_predictions, name=\"Survived\")\nSubmission1 = pd.concat([PassengerId,test_Survived],axis=1)\nacc_knn","7d969caa":"print(classification_report(y_test, knn_predictions))\ncm = pd.DataFrame(confusion_matrix(y_test, knn_predictions), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","6dde3cb6":"## Selecting the right n_neighbors for the k-NN classifier\nfrom sklearn.model_selection import KFold\n#x_trainknn, x_testknn, y_trainknn, y_testknn = train_test_split(X_train,Y_train,test_size = 0.2, random_state = 0)\ncross_score_list = []\nfold = KFold(n_splits=5,shuffle=True,random_state=20)\nk_list = range(1,100)\nfor k in k_list:\n    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='minkowski', p =2)\n    cross_score = cross_val_score(knn,X_train, Y_train,cv=fold).mean()\n    cross_score_list.append(cross_score)\n    print(cross_score)\n    cross_score.astype(np.int)\n    type(cross_score)\n    #cross_score.reset_index(inplace=True)\n    #plt.plot(k_list,cross_score)","e20d13fd":"##\u7528\u5b66\u4e60\u66f2\u7ebf\u627e\u6700\u4f73n\u503c\nx_trainknn, x_testknn, y_trainknn, y_testknn = train_test_split(X_train,Y_train,test_size = .33, random_state = 0)\nnn_scores = []\nbest_prediction = [-1,-1]\nfor i in range(1,100):\n    knn = KNeighborsClassifier(n_neighbors=i, weights='distance', metric='minkowski', p =2)\n    knn.fit(x_trainknn, y_trainknn)\n    score = accuracy_score(y_testknn, knn.predict(x_testknn))\n    #print i, score\n    if score > best_prediction[1]:\n        best_prediction = [i, score]\n    nn_scores.append(score)\nprint (best_prediction)\nplt.plot(range(1,100),nn_scores)","af0ce421":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred3 = gaussian.predict(x_test)\nacc_gaussian = round(gaussian.score(x_test, y_test) * 100, 2)\nacc_gaussian","fa364d0f":"print(classification_report(y_test, Y_pred3))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred3), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","b877b50f":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred4 = perceptron.predict(x_test)\nacc_perceptron = round(perceptron.score(x_test, y_test) * 100, 2)\nacc_perceptron","268f9ef9":"print(classification_report(y_test, Y_pred4))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred4), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","55e8ff62":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred6 = sgd.predict(x_test)\nacc_sgd = round(sgd.score(x_test, y_test) * 100, 2)\nacc_sgd","6179433b":"print(classification_report(y_test, Y_pred6))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred6), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","a0c8538b":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred7 = decision_tree.predict(x_test)\nacc_decision_tree = round(decision_tree.score(x_test, y_test) * 100, 2)\nacc_decision_tree","429500c8":"\nprint(classification_report(y_test, Y_pred7))\ncm = pd.DataFrame(confusion_matrix(y_test, Y_pred7), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","48fd7046":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_predictions = random_forest.predict(x_test)\nacc_random_forest = round(random_forest.score(x_test, y_test) * 100, 2)\n\n\n\nacc_random_forest","99b3ff23":"print(classification_report(y_test, random_forest_predictions))\ncm = pd.DataFrame(confusion_matrix(y_test, random_forest_predictions), ['Actual: NOT', 'Actual: SURVIVED'], ['Predicted: NO', 'Predicted: SURVIVED'])\nprint(cm)","f023c2f4":"objects = ('Logistic Regression', 'SVC', 'KNN', 'Gaussian', 'Perceptron', 'SGD', 'Decision Tree', 'Random Forest')\nx_pos = np.arange(len(objects))\naccuracies1 = [acc_log, acc_svc, acc_knn, acc_gaussian, acc_perceptron, acc_sgd, acc_decision_tree, acc_random_forest]\n    \nplt.bar(x_pos, accuracies1, align='center', alpha=0.5, color='r')\nplt.xticks(x_pos, objects, rotation='vertical')\nplt.ylabel('Accuracy')\nplt.title('Classifier Outcome')\nplt.show()","13cff5f2":"from sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=10)\n# Modeling step Test differents algorithms \nrandom_state = 2\n\nclassifiers = []\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(GaussianNB())\nclassifiers.append(Perceptron(random_state=random_state))\nclassifiers.append(SGDClassifier(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state = random_state))\nclassifiers.append(RandomForestClassifier(random_state = random_state))\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":['Logistic Regression',  'KNN', 'Gaussian',\n    'Perceptron',  'SGD', 'Decision Tree','SVMC', 'Random Forest']})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","ed80a6af":"# Adaboost\nDTC = DecisionTreeClassifier()\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsadaDTC.fit(X_train,Y_train)\nadaDTC_best = gsadaDTC.best_estimator_\ngsadaDTC.best_score_","377832e9":"# ExtraTrees \nExtC = ExtraTreesClassifier()\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 7],\n              \"min_samples_split\": [2, 3, 7],\n              \"min_samples_leaf\": [1, 3, 7],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[300,600],\n              \"criterion\": [\"gini\"]}\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsExtC.fit(X_train,Y_train)\nExtC_best = gsExtC.best_estimator_\ngsExtC.best_score_","2189e1df":"# Gradient boosting tunning\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] }\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsGBC.fit(X_train,Y_train)\nGBC_best = gsGBC.best_estimator_\ngsGBC.best_score_","21e0e023":"# SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1,10,50,100,200,300, 1000]}\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsSVMC.fit(X_train,Y_train)\nSVMC_best = gsSVMC.best_estimator_\n# Best score\ngsSVMC.best_score_","ae67aaaf":"# Random Forest\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 7],\n              \"min_samples_split\": [2, 3, 7],\n              \"min_samples_leaf\": [1, 3, 7],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[300,600],\n              \"criterion\": [\"gini\"]}\ngsrandom_forest = GridSearchCV(random_forest,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsrandom_forest.fit(X_train,Y_train)\n# Best score\nrandom_forest_best = gsrandom_forest.best_estimator_\ngsrandom_forest.best_score_","98a49a68":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\u753b\u5b66\u4e60\u66f2\u7ebf\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n    plt.legend(loc=\"best\")\n    return plt\ng = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsExtC.best_estimator_,\"ExtC ExtraTrees learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsGBC.best_estimator_,\"GBC Gradient Boost learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsrandom_forest.best_estimator_,\"RandomForest learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsSVMC.best_estimator_,\"SVMC learning curves\",X_train,Y_train,cv=kfold)","cf448af7":"##\u6295\u7968\u96c6\u6210\u6cd5\u5c06\u4e4b\u524d\u7b97\u7684\u6a21\u578b\u603b\u6574\u7406\nVotingPredictor = VotingClassifier(estimators=[('ExtC', ExtC_best), ('GBC',GBC_best),\n('SVMC', SVMC_best), ('random_forest', random_forest_best)], voting='soft', n_jobs=4)\nVotingPredictor = VotingPredictor.fit(X_train, Y_train)\nVotingPredictor_predictions = VotingPredictor.predict(test)\ntest_Survived = pd.Series(VotingPredictor_predictions, name=\"Survived\")\n\n# \u63d0\u4ea4!!\ntest_Survived = pd.Series(VotingPredictor_predictions, name=\"Survived\")\nSubmission3 = pd.concat([PassengerId,test_Survived],axis=1)\nSubmission3.head(15)","16693a06":"# Submit File \nSubmission3.to_csv(\"StackingSubmission1.csv\", index=False)\nprint(\"Completed.\")","6830e3ac":"\n\u53ef\u4ee5\u770b\u5230Fare \u8fd9\u884c\u5df2\u7ecf\u51fa\u73b012.1833\u7684\u6570\u636e","4f08186b":"\u6240\u4ee5\u4e0d\u7528 Adaboost!! \n\u6709\u8fc7\u62df\u5408\u7684\u73b0\u8c61","8e96deaf":"\u63a5\u4e0b\u6765\u770b\u770btitle\u4e0eage\u7684\u5173\u7cfb","e8702d0f":"# Stochastic Gradient Descent (sgd)\n","59b0a697":"# \u7279\u5f81\u5de5\u7a0b","d394a399":"# Embarked","ad72cb1c":"# Support Vector Machines","bd3e0b53":"\u56e0\u4e3a\u59d3\u540d\u5927\u4f19\u90fd\u4e0d\u540c,\u6240\u4ee5\u5f88\u96be\u6709\u5171\u540c\u7279\u5f81.\u8fd9\u91cc\u6211\u5c06\u5927\u5bb6\u7684title\u53d6\u51fa\u6765 \u53d6\u5171\u540c\u6240\u6709\u7684\u7279\u5f81,\u770b\u770b\u662f\u5426\u6709\u5173\u7cfb","7ee2116b":"# Random Forests\n","b556045d":"\n# Naive Bayes classifier\n","8a7672ae":"# k-Nearest Neighbors","162f1e6c":"# \u8d85\u53c2\u6570\u8c03\u53c2\u4ee5\u53ca\u5b66\u4e60\u66f2\u7ebf\u7ed9\u6a21\u578b\u9009\u62e9","56ecf999":"# Fare","e9c8999f":"\u9664\u4e86Dr\u4e4b\u5916,\u5176\u4ed6\u90fd\u662f\u5355\u4e00\u6027\u522b","68a3b01f":"# Model cross-validation with K-Fold\n","68dc22e2":"#  Model summary\n","ab742cd8":"# Name","dd1f40d8":"\n\u8fd9\u662f\u6211\u53c2\u8003\u5404\u533a\u5927\u795e\u7684\u7ec3\u4e60 \n\u6211\u4e5f\u662f\u521a\u8e0f\u5165\u6df1\u5ea6\u5b66\u4e60\/\u673a\u5668\u5b66\u4e60\u7684\u5c0f\u767d\n\u5e0c\u671b\u5927\u5bb6\u80fd\u76f8\u4e92\u5b66\u4e60!!!","b4943f73":"# Decision tree\n","18dea23a":"# \u5c06\u4e00\u4e9b\u7279\u5f81\u505a\u6574\u7406!!!\n","e501904a":"\n\u7b2c\u4e00\u6b65:\u5148\u770b\u662f\u5426\u6709\u7f3a\u5931\u503c","bf3d3b92":"\u867d\u7136\u6210\u529f\u5206\u51fa\u6765\u6240\u6709\u4eba\u7684title\u4e5f\u89c2\u5bdf\u51fa\u6027\u522b,\u4f46\u662f\u9ad8\u8fbe18\u4e2a,\u5728\u7279\u5f81\u4e2d\u7684\u6837\u6570\u8fd8\u662f\u592a\u591a\u4e86 \u6240\u4ee5\u6211\u4eec\u73b0\u5728\u8981\u518d\u6b21\u5f52\u7c7b 'Raraman' \u3001'Rarawoman'","cf38f87d":"# Perceptron","e075c50f":"\n#  Logistic Regression\n","a14847df":"# \u67e5\u770b\u6570\u636e\u7ec6\u8282\u4e0e\u6570\u636e\u6e05\u6d17","57483c54":"\n\u53d1\u73b0 \n\n1.Embarked\u3001Fare\u90fd\u53ea\u6709\u4e00\u4e2a\u7f3a\u5931\u503c\uff0c\u6240\u4ee5\u53ef\u4ee5\u7528\u4f17\u6570\u6216\u662f\u5e73\u5747\u6570\u6765\u586b\u8865!!\n\n2.Cabin \u6709\u9ad8\u8fbe1014\u4e2a\u7f3a\u5931\u503c \u6240\u4ee5\u53ef\u4ee5\u5c06NaN\u89c6\u4e3a\u4e00\u79cd\u7279\u5f81\n\n3.Survived \u7684\u7f3a\u5931\u503c\u90fd\u6765\u81ea\u4e8e\u6d4b\u8bd5\u96c6","25b6ccaa":"\u7531\u4e0a\u9762\u53ef\u77e5,Master \u6700\u5927\u7684\u5e74\u9f84\u53ea\u670914\u5c81,\u5e73\u5747\u4e5f\u662f5\u5c81,\u6240\u4ee5\u4e3a\u5c0f\u5b69,\u4f46\u662f\u90fd\u4ec5\u4ec5\u53ea\u662f\u7537\u751f \u6240\u4ee5\u5973\u751f\u7684\u5c0f\u5b69\u5e94\u8be5\u90fd\u88ab\u5f52\u5728Miss\u91cc\u5934,\u63a5\u4e0b\u6765\u8981\u628a\u5176\u63d0\u53d6\u51fa\u6765\n\u5148\u5047\u8bbelittle girl\u90fd\u6ca1\u7ed3\u5a5a\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\u8be5\u5047\u8bbe\u90fd\u6210\u7acb\uff09\uff0c\u6240\u4ee5little girl\u80af\u5b9a\u90fd\u5305\u542b\u5728Miss\u91cc\u9762\u3002little boy\uff08Master\uff09\u7684\u5e74\u9f84\u6700\u5927\u503c\u4e3a14\u5c81\uff0c\u6240\u4ee5\u76f8\u5e94\u7684\u53ef\u4ee5\u8bbe\u5b9a\u5e74\u9f84\u5c0f\u4e8e\u7b49\u4e8e14\u5c81\u7684Miss\u4e3alittle girl\u3002\u5bf9\u4e8e\u5e74\u9f84\u7f3a\u5931\u7684Miss\uff0c\u53ef\u4ee5\u7528(Parch!=0)\u6765\u5224\u5b9a\u662f\u5426\u4e3alittle girl\uff0c\u56e0\u4e3alittle girl\u5f80\u5f80\u662f\u5bb6\u957f\u966a\u540c\u4e0a\u8239\uff0c\u4e0d\u4f1a\u4e00\u4e2a\u4eba\u53bb\u3002","8ae82dc9":"# Cabin"}}