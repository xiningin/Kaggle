{"cell_type":{"99e68f71":"code","ad24c4f3":"code","0b7bccb9":"code","bbf3377c":"code","08abf2ca":"code","ef914fe7":"code","24a1279b":"code","2f53b2eb":"code","dba3a111":"code","4e865149":"markdown","ac7a73ee":"markdown","e170685d":"markdown","1ffb98b6":"markdown","11bb9e34":"markdown","0d63613b":"markdown","489fed21":"markdown","aa90d40e":"markdown","91471869":"markdown"},"source":{"99e68f71":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","ad24c4f3":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntargets = train['target']\ntrain = train.drop(columns=['id', 'target'])\nids = test['id']\ntest = test.drop(columns=['id'])\n\nfrom sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(train.values)\ntrans_x = transformer.transform(train.values)\ntrans_test = transformer.transform(test.values)","0b7bccb9":"from sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nscores = []\nparam_grid = {\"C\": [.01, .1, 1, 10, 100, 1000],\n                \"penalty\": ('l1','l2')}\nclf = LogisticRegression(random_state=0, solver='liblinear', class_weight='balanced', max_iter = 1000)\ngs = GridSearchCV(clf, param_grid, cv=5)\ngs.fit(trans_x, targets)\n\nbest_score = gs.best_score_\nbest_estimator = gs.best_estimator_\nbest_pca = 'N\/a'\nprint(best_score)\n\"\"\"\nfor i in range(10,250, 10):\n    pca = PCA(n_components=i)\n    pca.fit(train.values)\n    \n    X = pca.transform(trans_x)\n    transformed_test = pca.transform(test.values)\n    #Find the best model for these components\n    param_grid = {\"C\": [.01, .1, 1, 10, 100, 1000],\n                \"penalty\": ('l1','l2')}\n    clf = LogisticRegression(random_state=0, solver='liblinear', class_weight='balanced', max_iter = 1000)\n    gs = GridSearchCV(clf, param_grid, cv=5)\n    gs.fit(X, targets)\n    print(\"Best Score for : \", str(i), \" is \", str(gs.best_score_))\n    scores.append(gs.best_score_)\n    if gs.best_score_ > best_score:\n        best_score = gs.best_score_\n        best_estimator = gs.best_estimator_\n        best_pca = i\nprint(\"Best score was : \", str(best_score), \" with estimator \", str(best_estimator), ' \\n and PCA : ', str(best_pca))\"\"\"\npca = PCA(n_components=2)\npca.fit(train.values)\nvals_2d = pca.transform(train.values)\nimport matplotlib.pyplot as plt\ncolors = ['red' if t == 1 else 'blue' for t in targets]\nfor i in range(len(vals_2d)):\n    plt.scatter(x=vals_2d[i,0], y=vals_2d[i,1], color=colors[i])\n","bbf3377c":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2)\nvals_2d = tsne.fit_transform(train.values)\nimport matplotlib.pyplot as plt\ncolors = ['red' if t == 1 else 'blue' for t in targets]\nfor i in range(len(vals_2d)):\n    plt.scatter(x=vals_2d[i,0], y=vals_2d[i,1], color=colors[i])\n","08abf2ca":"from sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import cross_validate\nselector = RFECV(best_estimator, step=1, cv=5)\nselector = selector.fit(trans_x, targets)\nnew_trans_x = selector.transform(trans_x)\nnew_trans_test = selector.transform(trans_test)\n","ef914fe7":"pca = PCA(n_components=2)\npca.fit(new_trans_x)\nvals_2d = pca.transform(new_trans_x)\nimport matplotlib.pyplot as plt\ncolors = ['red' if t == 1 else 'blue' for t in targets]\nfor i in range(len(vals_2d)):\n    plt.scatter(x=vals_2d[i,0], y=vals_2d[i,1], color=colors[i])\n    \n","24a1279b":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2)\nvals_2d = tsne.fit_transform(new_trans_x)\nimport matplotlib.pyplot as plt\ncolors = ['red' if t == 1 else 'blue' for t in targets]\nfor i in range(len(vals_2d)):\n    plt.scatter(x=vals_2d[i,0], y=vals_2d[i,1], color=colors[i])","2f53b2eb":"\nparam_grid = {\"C\": [.01, .1],\n                \"penalty\": ('l1','l2')}\nclf = LogisticRegression(random_state=0, solver='liblinear', class_weight='balanced', max_iter = 1000)\ngs = GridSearchCV(clf, param_grid, cv=5)\ngs.fit(new_trans_x, targets)\nprint(gs.best_estimator_)\nprint(gs.best_score_)\nprint(gs.score(new_trans_x, targets))\npredictions = gs.predict_proba(new_trans_test)[:,1]","dba3a111":"output = pd.DataFrame({'id' : ids, 'target' : predictions})\noutput.to_csv('output.csv',index=None)","4e865149":"These are not very good visualizations :I","ac7a73ee":"**t-SNE**","e170685d":"**Write Out Predictions**\n\n","1ffb98b6":"**Predict With Best Model**\n","11bb9e34":"**Try Reduction Now With Only The Selected\/Transformed Components**","0d63613b":"**Loading The Data**","489fed21":"**Principal Component Analysis**\n\nFirst I am going to use PCA to reduce colinearity in the data, I am going to try a range of values for dimensionality reduction and use the best performing through testing with K fold cross validation","aa90d40e":"**RFE**","91471869":"PCA actually seems to be negatively affecting the model across the board... oops"}}