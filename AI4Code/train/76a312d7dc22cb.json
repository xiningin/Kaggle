{"cell_type":{"8618415f":"code","a888847c":"code","bcde288d":"code","1f734bc7":"code","0ae18e99":"code","ffa346a1":"code","2ef97bbe":"code","0184914b":"code","7f27765f":"code","b2d47e8a":"code","b7389ecb":"code","ad5d7c1a":"code","884f72f0":"code","8175486a":"code","81b5925d":"code","54c1a417":"code","19ec87b2":"code","e3b99e2d":"code","d8d8221f":"code","809bcab9":"code","f11828f3":"code","5bbdeb24":"code","8f32dc75":"code","bf90bcf1":"code","f4671bc4":"code","9bbee5b0":"code","4cfa1030":"code","32363833":"code","1362592f":"code","a074bd74":"code","ba475233":"code","8790e734":"code","45b60a54":"code","7c2fe6ed":"code","a3179295":"code","d0481824":"code","f26844c8":"code","699b2ce5":"code","5f2d3c4a":"code","3d324f6d":"code","abea7bfc":"code","63c23cb0":"code","bd83299e":"code","a4ac2fbc":"code","c353e1ac":"code","55e85e63":"code","7575c66c":"code","f1ef6686":"markdown","23ba4ae1":"markdown","816e3060":"markdown","75f7a530":"markdown","38893015":"markdown","3da4c1d6":"markdown","a46d5ab9":"markdown","6a109613":"markdown","2e32c93c":"markdown","6eabe4cf":"markdown","0a08c68b":"markdown","94e46dc8":"markdown","dac93642":"markdown","ee6d3305":"markdown","c3d5bdc8":"markdown","42fa7b71":"markdown","be2622f8":"markdown","170b19f8":"markdown","4bd9c516":"markdown","c2a0d123":"markdown","d5515424":"markdown","3647a8d4":"markdown","ccca6b0d":"markdown","b0eb3c15":"markdown","df190256":"markdown","c87012ef":"markdown","122ae300":"markdown","29ef65fa":"markdown","7b94d8c1":"markdown","556ba775":"markdown","1e20c105":"markdown","e1b3f882":"markdown","2f202d5c":"markdown"},"source":{"8618415f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a888847c":"# inviting pandas and friends to the party\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style(\"whitegrid\") # set seaborn styles","bcde288d":"df = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\")","1f734bc7":"# drop questions\ndf = df.drop(df.index[0])\n\n# check for and drop duplicate rows\ndf = df.drop_duplicates()\n\n# dropping columns based on string pattern\ndrop_all = [\"Q26\", \"Time from Start to Finish\", \"Q11\", \"Q19\"]\n\nfor col in drop_all:\n    df = df.loc[:,~df.columns.str.contains(col)]\n\n# rename columns for better readability\nrename = {\"Q1\" : \"age\",\n          \"Q2\" : \"gender\",\n          \"Q3\" : \"country\",\n          \"Q4\" : \"degree\",\n          \"Q5\" : \"position\",\n          \"Q6\" : \"company_size\",\n          \"Q10\": \"salary\"\n          }\ndf = df.rename(columns=rename)","0ae18e99":"# preparing 2017 and 2018 datasets for comparison\n\n# import 2017\ndf_2017 = pd.read_csv(\"..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv\", encoding = \"ISO-8859-1\")\n\n# drop duplicates\ndf_2017 = df_2017.drop_duplicates()\n\n# rename columns\nrename_2017 = {\"Age\" : \"age\",\n                \"GenderSelect\" : \"gender\",\n                \"Country\" : \"country\",\n                \"FormalEducation\" : \"degree\",\n                \"EmployerSize\" : \"company size\",\n                \"LearningDataScienceTime\" : \"experience\",\n                \"CompensationAmount\" : \"salary\",\n                \"CompensationCurrency\" : \"currency\",\n                }\n\n# select columns\ndf_2017 = df_2017[list(rename_2017.keys())]\n\n# rename columns\ndf_2017 = df_2017.rename(columns=rename_2017)\n\n# select countries\ndf_2017 = df_2017[(df_2017[\"country\"] == \"India\") | (df_2017[\"country\"] == \"United States\")]","ffa346a1":"# import 2018\ndf_2018 = pd.read_csv(\"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\", encoding = \"UTF-8\")\n\n# drop duplicates\ndf_2018 = df_2018.drop_duplicates()\n\n# rename columns\nrename_2018 = {\"Q2\" : \"age\",\n                \"Q1\" : \"gender\",\n                \"Q3\" : \"country\",\n                \"Q4\" : \"degree\",\n                \"Q8\" : \"experience\",\n                \"Q9\" : \"salary\",\n                }\n# select columns\ndf_2018 = df_2018[list(rename_2018.keys())]\n\n# rename columns\ndf_2018 = df_2018.rename(columns=rename_2018)\n\n# select countries\ndf_2018 = df_2018[(df_2018[\"country\"] == \"India\") | (df_2018[\"country\"] == \"United States of America\")]","2ef97bbe":"# creating seperate dataframes for India and the US to make normalization more easy\nindia = df[df[\"country\"] == \"India\"]\nusa = df[df[\"country\"] == \"United States of America\"]","0184914b":"# creating comparison dataframe containing both India and the US\ndf_comp = df[(df[\"country\"] == \"India\") | (df[\"country\"] == \"United States of America\")].copy()\ndf_country_comp = df_comp[[\"country\"]]","7f27765f":"# data manipulation functions\n\n# function to reverse dummy valiables based on column string pattern for whole dataframe\n# may return list of unique values when labels_only is set to True\n\ndef undummy(df, col_pattern, labels_only=False):\n    df_tmp = df.loc[:,df.columns.str.contains(col_pattern)]\n    cols_to_bool = list(df_tmp.columns)\n\n    df_tmp = df_tmp.fillna(0)\n\n    labels = []\n    for col in cols_to_bool:\n        labels.append(df_tmp[col].value_counts().keys()[1])\n\n\n    for col in cols_to_bool:\n        df_tmp[col] = np.where(df_tmp[col] != 0, 1, 0)\n        df_tmp[col] = df_tmp[col].astype(int)\n\n    resources = []\n    for col in cols_to_bool:\n        resources.append(df_tmp[col].sum())\n\n    labels\n\n    resources = pd.DataFrame(data=resources, index=labels)\n    resources = resources.rename(columns={0: \"value\"})\n    resources = resources.sort_values(by=\"value\", ascending=False)\n    \n    if labels_only == True:\n        return labels\n    return resources","b2d47e8a":"# function to reverse dummy valiables based on column string pattern for single column\n\ndef undummy_single_col(df, col_name):\n    sr_tmp = df[col_name]\n    sr_tmp = sr_tmp.fillna(0)\n\n    labels = sr_tmp.value_counts().keys().tolist()\n    labels = pd.Series(labels).astype(str)\n    labels = labels.str.replace(\"0\", \"None\")\n\n    resources = sr_tmp.value_counts().tolist()\n    \n    resources = pd.DataFrame(data=resources, index=labels)\n    resources = resources.rename(columns={0: \"value\"})\n    resources = resources.sort_values(by=\"value\", ascending=False)\n\n    return resources","b7389ecb":"# functions for calculating value percentages within given column\ndef perc(df, col):\n    return round(100 * df[col].value_counts(normalize=True),2).to_frame()","ad5d7c1a":"# function for normalizing value distribution within given column for both India and the US\n# return dataframe containing normalized values for given columns\n\ndef total_to_perc(df, df1, df2, col1, col2):\n    df_perc = df.copy()\n    df_perc = df_perc.drop(columns=[col1, col2])\n    df_perc = df_perc.assign(india = df[col1].apply(lambda x: (x\/len(df1))*100))\n    df_perc = df_perc.assign(usa = df[col2].apply(lambda x: (x\/len(df2))*100))\n    return df_perc","884f72f0":"# global plotting variables\n\n# global figure size to use in the plots\nfigure_size = (12,6)\n\ncolors_pie_3 = [\"yellowgreen\", \"coral\", \"cornflowerblue\"]\ncolors_pie_2 = [\"coral\", \"cornflowerblue\"]\ncolors_bar_3 = [\"cornflowerblue\", \"coral\", \"yellowgreen\"]\ncolors_bar_2 = [\"cornflowerblue\", \"coral\"]\n\ncolors_years_2_in = [\"peachpuff\", \"coral\"]\ncolors_years_2_us = [\"lightsteelblue\", \"cornflowerblue\"]\ncolors_years_3_in = [\"peachpuff\", \"coral\", \"sienna\"]\ncolors_years_3_us = [\"lightsteelblue\", \"cornflowerblue\", \"royalblue\"]","8175486a":"# plotting global survey participant ratio by country (countries other than India and US are aggregated in\n# \"Other countries\")\n\nlabels = [\"Other countries\", \"India\", \"US\"]\nsizes = [len(df), len(india), len(usa)]\ncolors = colors_pie_3\n\nfig1, ax1 = plt.subplots(figsize=figure_size)\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=False, startangle=90, colors=colors)\nax1.axis('equal')\nax1.set_title(\"India \/ USA as a subset\")\nplt.show()","81b5925d":"# plotting ratio of survey participants for India and the US\n\nlabels = df_country_comp[\"country\"].value_counts().keys().tolist()\nsizes = [len(india), len(usa)]\ncolors = colors_pie_2\n\nfig1, ax1 = plt.subplots(figsize=figure_size)\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=False, startangle=90, colors=colors_pie_2)\nax1.axis('equal')\nax1.set_title(\"India \/ US Proportion 2019\")\nplt.show()","54c1a417":"# creating dataframes for India and the US for the years 2017 and 2018\nindia_2017 = df_2017[df_2017[\"country\"] == \"India\"]\nusa_2017 = df_2017[df_2017[\"country\"] == \"United States\"]\nindia_2018 = df_2018[df_2018[\"country\"] == \"India\"]\nusa_2018 = df_2018[df_2018[\"country\"] == \"United States of America\"]","19ec87b2":"# plotting ratio of participants from India and the US over the last three years\n\nlabels = [\"India\", \"US\"]\n\nsizes17 = [len(india_2017), len(usa_2017)]\nsizes18 = [len(india_2018), len(usa_2018)]\nsizes19 = [len(india), len(usa)]\ncolors = colors_pie_2\n\nfig = plt.figure()\n\nax1 = fig.add_axes([.1, .3, 1, 1], aspect=1)\nax1.pie(sizes17, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n\nax2 = fig.add_axes([.8, .3, 1, 1], aspect=1)\nax2.pie(sizes18, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n\nax3 = fig.add_axes([1.5, .3, 1, 1], aspect=1)\nax3.pie(sizes19, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n\nax1.set_title(\"2017\")\nax2.set_title(\"2018\")\nax3.set_title(\"2019\")\n\nplt.show()","e3b99e2d":"# preparing data for plotting: combining gender distribution of India and the US in dataframe\nglobal_gender_dist = perc(df, \"gender\").rename(columns={\"gender\" : \"global\"})\nindia_gender_dist = perc(india, \"gender\").rename(columns={\"gender\" : \"india\"})\nusa_gender_dist = perc(usa, \"gender\").rename(columns={\"gender\" : \"usa\"})\n\ndf_gender = usa_gender_dist.merge(right=india_gender_dist, how=\"inner\", left_index=True, right_index=True)\ndf_gender= df_gender.merge(right=global_gender_dist, how=\"inner\", left_index=True, right_index=True)","d8d8221f":"# plotting gender distribution\nfig, ax = plt.subplots(figsize=figure_size)\ndf_gender.plot(kind=\"bar\", ax=ax, rot=45, color=colors_bar_3)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Gender Distribution\");","809bcab9":"# preparing age dataframes\nglobal_age_dist = perc(df, \"age\").rename(columns={\"age\" : \"global\"})\nindia_age_dist = perc(india, \"age\").rename(columns={\"age\" : \"india\"})\nusa_age_dist = perc(usa, \"age\").rename(columns={\"age\" : \"usa\"})\n\n# merge age dataframes\ndf_age = usa_age_dist.merge(right=india_age_dist, how=\"inner\", left_index=True, right_index=True)\ndf_age = df_age.merge(right=global_age_dist, how=\"inner\", left_index=True, right_index=True)\ndf_age = df_age.reset_index()\ndf_age = df_age.rename(columns={\"index\": \"age\"}).sort_values(by=\"age\")\ndf_age = df_age.set_index(\"age\")","f11828f3":"# plotting age distribution\nfig, ax = plt.subplots(figsize=figure_size)\ndf_age.plot(kind=\"bar\", ax=ax, stacked=True, rot=45, color=colors_bar_3);\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Age Distribution\");","5bbdeb24":"#get data 2018\nage_in = (df_2018[df_2018[\"country\"]==\"India\"][\"age\"]\n           .value_counts(normalize=True)\n           .to_frame()\n           .rename(columns={\"age\" : \"2018\"}))\nage_us = (df_2018[df_2018[\"country\"]==\"United States of America\"][\"age\"]\n           .value_counts(normalize=True)\n           .to_frame()\n           .rename(columns={\"age\" : \"2018\"}))\n\nage_in = age_in.reindex(index = [\"18-21\", \"22-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-69\", \"70-79\", \"80+\"])\nage_us = age_us.reindex(index = [\"18-21\", \"22-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-69\", \"70-79\", \"80+\"])\n\n#get data 2019\nage_in = age_in.assign(age2019=df[df[\"country\"]==\"India\"][\"age\"].value_counts(normalize=True))\nage_in.rename(columns={\"age2019\" : \"2019\"}, inplace=True)\n\nage_us = age_us.assign(age2019=df[df[\"country\"]==\"United States of America\"][\"age\"].value_counts(normalize=True))\nage_us.rename(columns={\"age2019\" : \"2019\"}, inplace=True)","8f32dc75":"# plotting age distribution over time for US and India\nfig, ax = plt.subplots(ncols=2, figsize=(18,8))\nplt.rcParams.update({'font.size': 10})\ndata1 = age_in*100\ndata2 = age_us*100\nax1 = data1.plot(kind=\"bar\", ax=ax[0], grid=True, rot=45, color=colors_years_3_in)\nax2 = data2.plot(kind=\"bar\", ax=ax[1], grid=True, rot=45, color=colors_years_3_us)\nax1.set_title(\"Distribution of participants age (India)\")\nax2.set_title(\"Distribution of participants age (USA)\")\nax1.set_ylabel('Distribution [%]')\nax2.set_ylabel('Distribution [%]')\nax1.get_yticks()\nax2.get_yticks();","bf90bcf1":"# preparing dataframes for educational degrees for US and India\nglobal_degree_dist = perc(df, \"degree\").rename(columns={\"degree\" : \"global\"})\nindia_degree_dist = perc(india, \"degree\").rename(columns={\"degree\" : \"india\"})\nusa_degree_dist = perc(usa, \"degree\").rename(columns={\"degree\" : \"usa\"})\n\ndf_degree = usa_degree_dist.merge(right=india_degree_dist, how=\"inner\", left_index=True, right_index=True)\ndf_degree = df_degree.merge(right=global_degree_dist, how=\"inner\", left_index=True, right_index=True)","f4671bc4":"# plotting educational degrees for India and the US\nax = df_degree.plot(kind=\"bar\", figsize=figure_size, rot=45, color=colors_bar_3);\nlabels = [item.get_text() for item in ax.get_xticklabels()]\nlabels[3] = 'College\/University study without degree'\nax.set_xticklabels(labels)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Educational Degree\");","9bbee5b0":"# get data 2017\ndegree_in = (df_2017[df_2017[\"country\"]==\"India\"][\"degree\"]\n           .value_counts(normalize=True)\n           .to_frame()\n           .rename(columns={\"degree\" : \"2017\"}))\ndegree_us = (df_2017[df_2017[\"country\"]==\"United States\"][\"degree\"]\n           .value_counts(normalize=True)\n           .to_frame()\n           .rename(columns={\"degree\" : \"2017\"}))\n\n# uniform degrees \nreplace_degree = {\"Bachelor's degree\" : \"Bachelor\u2019s degree\",\n                  \"Master's degree\" : \"Master\u2019s degree\",\n                  \"Some college\/university study without earning a bachelor's degree\" : \"Some college\/university study without earning a bachelor\u2019s degree\",\n                  \"I did not complete any formal education past high school\" : \"No formal education past high school\",\n                 }\ndegree_in.rename(index=replace_degree, inplace=True)\ndegree_us.rename(index=replace_degree, inplace=True)","4cfa1030":"# get data 2018\ndegree_in = degree_in.assign(deg2018=df_2018[df_2018[\"country\"]==\"India\"][\"degree\"]\n                               .value_counts(normalize=True))\ndegree_in.rename(columns={\"deg2018\" : \"2018\"}, inplace=True)\ndegree_us = degree_us.assign(deg2018=df_2018[df_2018[\"country\"]==\"United States of America\"][\"degree\"]\n                               .value_counts(normalize=True))\ndegree_us.rename(columns={\"deg2018\" : \"2018\"}, inplace=True)","32363833":"# get data 2019\ndegree_in = degree_in.assign(deg2019=df[df[\"country\"]==\"India\"][\"degree\"]\n                               .value_counts(normalize=True))\ndegree_in.rename(columns={\"deg2019\" : \"2019\"}, inplace=True)\ndegree_us = degree_us.assign(deg2019=df[df[\"country\"]==\"United States of America\"][\"degree\"]\n                               .value_counts(normalize=True))\ndegree_us.rename(columns={\"deg2019\" : \"2019\"}, inplace=True)\n\n# uniform degrees \nrename_values = {\"Some college\/university study without earning a bachelor\u2019s degree\" : \"Studied without earning degree\",\n                \"Bachelor\u2019s degree\" : \"Bachelor\",\n                \"Master\u2019s degree\" : \"Master\",\n                \"Professional degree\" : \"Professional\",\n                \"Doctoral degree\" : \"Doctor\",\n                \"No formal education past high school\" : \"No formal education\",\n                \"I prefer not to answer\" : \"No answer\"\n                }\ndegree_us.rename(index=rename_values, inplace=True)\ndegree_in.rename(index=rename_values, inplace=True)","1362592f":"#reorder the index\nindex_degree = (['Bachelor', 'Master', 'Doctor', 'Professional', 'Studied without earning degree', 'No formal education', 'No answer'])\ndegree_us = degree_us.reindex(index_degree)\ndegree_in = degree_in.reindex(index_degree)","a074bd74":"# plotting educational degrees over time for US and India\nfig, ax = plt.subplots(ncols=2, figsize=(18,8))\nplt.rcParams.update({'font.size': 10})\ndata1 = degree_in*100\ndata2 =data2 = degree_us*100\nax1 = data1.plot(kind=\"bar\", ax=ax[0], grid=True, rot=45, color=colors_years_3_in)\nax2 = data2.plot(kind=\"bar\", ax=ax[1], grid=True, rot=45, color=colors_years_3_us)\nax1.set_title(\"Distribution of educational degree of participants (India)\")\nax2.set_title(\"Distribution of educational degree of participants (USA)\")\nax1.set_ylabel('Distribution [%]')\nax2.set_ylabel('Distribution [%]')\nax1.get_yticks()\nax2.get_yticks();","ba475233":"# preparing dataframes for job position names for India and the US\nglobal_position_dist = perc(df, \"position\").rename(columns={\"position\" : \"global\"})\nindia_position_dist = perc(india, \"position\").rename(columns={\"position\" : \"india\"})\nusa_position_dist = perc(usa, \"position\").rename(columns={\"position\" : \"usa\"})\n\ndf_position = usa_position_dist.merge(right=india_position_dist, how=\"inner\", left_index=True, right_index=True)\ndf_position = df_position.merge(right=global_position_dist, how=\"inner\", left_index=True, right_index=True)","8790e734":"ax = df_position.plot(kind=\"bar\", figsize=figure_size, rot=45, color=colors_bar_3)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Current Job Position\");\n","45b60a54":"# preparing dataframes for salary distribution within Data Science for India and the US\nglobal_salary_dist = perc(df, \"salary\").rename(columns={\"salary\" : \"global\"})\nindia_salary_dist = perc(india, \"salary\").rename(columns={\"salary\" : \"india\"})\nusa_salary_dist = perc(usa, \"salary\").rename(columns={\"salary\" : \"usa\"})\n\ndf_salary = usa_salary_dist.merge(right=india_salary_dist, how=\"inner\", left_index=True, right_index=True)\ndf_salary = df_salary.merge(right=global_salary_dist, how=\"inner\", left_index=True, right_index=True)\ndf_salary = df_salary.reset_index().rename(columns={\"index\" : \"salary\"}).sort_values(\"salary\").set_index(\"salary\")\n\n# reordering salaries\ndf_salary = df_salary.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\",  \"3,000-3,999\", \"4,000-4,999\", \n                                       \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \"15,000-19,999\", \"20,000-24,999\", \n                                       \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \n                                       \"60,000-69,999\", \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \n                                       \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"200,000-249,999\",\n                                       \"250,000-299,999\", \"300,000-500,000\", \"> $500,000\"])","7c2fe6ed":"ax = df_salary.plot(kind=\"line\", figsize=figure_size, rot=45, color=colors_bar_3)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Yearly Salary\");","a3179295":"# preparing dataframes for company size distribution\nglobal_company_size_dist = perc(df, \"company_size\").rename(columns={\"company_size\" : \"global\"})\nindia_company_size_dist = perc(india, \"company_size\").rename(columns={\"company_size\" : \"india\"})\nusa_company_size_dist = perc(usa, \"company_size\").rename(columns={\"company_size\" : \"usa\"})\n\ndf_company_size = usa_company_size_dist.merge(right=india_company_size_dist, how=\"inner\", left_index=True, right_index=True)\ndf_company_size = df_company_size.merge(right=global_company_size_dist, how=\"inner\", left_index=True, right_index=True)\n\n# reordering index\ndf_company_size = df_company_size.reset_index().rename(columns={\"index\" : \"company_size\"}).sort_values(\"company_size\").set_index(\"company_size\")\ndf_company_size = df_company_size.reindex(index = [\"0-49 employees\", \"50-249 employees\", \"250-999 employees\", \"1000-9,999 employees\", \"> 10,000 employees\"])","d0481824":"ax = df_company_size.plot(kind=\"line\", figsize=figure_size, rot=45, color=colors_bar_3)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Company Size\");","f26844c8":"# preparing dataframes for the use of programming languages in India and the US\nlanguages_india = undummy(india, \"Q18\")\nlanguages_india = languages_india.drop(\"-1\", axis=0)\nlanguages_india = languages_india.rename(index={0: \"Python\"})\n\nlanguages_usa = undummy(usa, \"Q18\")\nlanguages_usa = languages_usa.drop(\"-1\", axis=0)\nlanguages_usa = languages_usa.rename(index={0: \"Python\"})\n\n# merging dataframes\nlanguages = languages_india.merge(right=languages_usa, how=\"inner\", left_index=True, right_index=True)\nlanguages = languages.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\n\n# normalizing\nlanguages_perc = total_to_perc(languages, india, usa, \"india\", \"usa\")\nlanguages_perc = languages_perc[['usa', 'india']]","699b2ce5":"# plotting programming languages percentages\nfig, ax = plt.subplots(figsize=figure_size)\nlanguages_perc.plot(kind=\"bar\", ax=ax, rot=45, color=colors_bar_2)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of the Use of Programming Languages\");","5f2d3c4a":"# preparing dataframes for programming experience in India and the US\nindia_exp_dist = perc(india, \"Q15\").rename(columns={\"Q15\": \"india\"})\nusa_exp_dist = perc(usa, \"Q15\").rename(columns={\"Q15\": \"usa\"})\ndf_exp = usa_exp_dist.merge(right=india_exp_dist, how=\"inner\", left_index=True, right_index=True)\n\n# reordering index\ndf_exp = df_exp.reindex([\"I have never written code\", \"< 1 years\", \"1-2 years\", \"3-5 years\", \"5-10 years\", \"10-20 years\", \"20+ years\"])","3d324f6d":"# plotting programming experience percentages\nfig, ax = plt.subplots(figsize=figure_size)\ndf_exp.plot(kind=\"line\", ax=ax, color=colors_bar_2)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Programming Experience in Years\");","abea7bfc":"# preparing dataframes for machine learning experience in India and the US\nindia_exp_ml_dist = perc(india, \"Q23\").rename(columns={\"Q23\": \"india\"})\nusa_exp_ml_dist = perc(usa, \"Q23\").rename(columns={\"Q23\": \"usa\"})\ndf_exp_ml = usa_exp_ml_dist.merge(right=india_exp_dist, how=\"inner\", left_index=True, right_index=True)","63c23cb0":"# plotting machine learning experience percentages\nfig, ax = plt.subplots(figsize=figure_size)\ndf_exp_ml.plot(kind=\"line\", ax=ax, color=colors_bar_2)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of Machine Learning Experience in Years\");","bd83299e":"# preparing dataframes for machine learning algorithms used in India and the US\nml_tools_india = undummy(india, \"Q24\")\nml_tools_india = ml_tools_india.rename(index={0: \"Linear or Logistic Regression\"})\nml_tools_usa = undummy(usa, \"Q24\")\nml_tools_usa = ml_tools_usa.rename(index={0: \"Linear or Logistic Regression\"})\n\nml_tools = ml_tools_india.merge(right=ml_tools_usa, how=\"inner\", left_index=True, right_index=True)\nml_tools = ml_tools.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\nml_tools = ml_tools.drop(\"-1\", axis=0)","a4ac2fbc":"ml_tools_perc = total_to_perc(ml_tools, india, usa, \"india\", \"usa\")\nml_tools_perc = ml_tools_perc[['usa', 'india']]","c353e1ac":"# plotting machine learning algorithms percentage\nfig, ax = plt.subplots(figsize=figure_size)\nml_tools_perc.plot(kind=\"bar\", ax=ax, color=colors_bar_2)\nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of the Use of Machine Learning Algorithms\");","55e85e63":"# preparing dataframes for Data Science learning resources used in India and the US\nresources_india = undummy(india, \"Q13\")\nresources_usa = undummy(usa, \"Q13\")\n\nresources = resources_india.merge(right=resources_usa, how=\"inner\", left_index=True, right_index=True)\nresources = resources.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\nresources = resources.drop(\"-1\", axis=0)\n\nresources_perc = total_to_perc(resources, india, usa, \"india\", \"usa\")\n\nresources_perc = resources_perc[['usa', 'india']]","7575c66c":"# plotting learning resources percentages\nfig, ax = plt.subplots(figsize=figure_size)\nresources_perc.plot(kind=\"bar\", ax=ax, color=colors_bar_2)   \nax.set_ylabel('Distribution [%]')\nax.set_title(\"Distribution of the Use of Learning Resources\");","f1ef6686":"### Observations:\n* We see higher percentages for shorter amounts of programming experience in years (< one year until 1 \u2013 2 years) for participants in India. \n* For participants in the US we see a moderate increasing in percentages until the 3 \u2013 5 years mark. After this point the percentages flatten slowly.\n\n### Conclusions:\n* As assumed the distribution of programming experience in years is similar to the age distribution for both India and the US","23ba4ae1":"### Observations:\n* Compared to the global age distribution we can see that in India there is a higher percentage of young people between 18 and 29 years of age\n* Starting at the 30-34 years bucked there are lower and lower percentages for users from India\n* In comparison there are lower percentages for US than globally from young people between 18 and 24 years of age\n* Starting at the bucket of 25-29 years there are higher percentages for the US proportionally in comparison to the global age distribution\n\n### Conclusion\n* The age distribution shows that the majority of answers from Indian Kaggle users came from younger people under 30 while the majority of answers from US Kaggle users came from people in the middle age between 25 and 39\n* This may represent the age distribution of Data Scientists by country, the Kaggle user group by country or both","816e3060":"# 1. Demographical exploration\n## 1.1 Answer ratio by country\nIn this analysis we are only interested in answers from two distinct countries: India and the US.\nLet's have a look at the ratio of the answers from people who live in India and the answers from people who live in the US.","75f7a530":"### Observations\n* While the gender ratio in India is quite similar to the global total ratio the gender ratio in the US shows that there are more answers from people described themselves as women and less from people who described themselves as men in comparison to the global gender ratio","38893015":"### Observations:\n* Within the India sample there is a relatively high percentage of people with an income between 0 and 999 Dollars. Apart from that the most value accumulate around the 5.000 \u2013 10.000 buckets.\n* Within the US sample there also is a moderate percentage of people with an income between 0 and 999 Dollars but this percentage is smaller than the percentage within the Indian sample. Apart from that the most values accumulate around the 100.000 and 150.000 Dollar buckets.\n\n### Conclusions:\n* We expected to find a relatively lower average income within the Indian sample - both due to the high percentage of students and the economical differences between India and the US. In fact we do find a significantly high amount of people with no or a really low income in India.\n* Within the group of survey participants from India the income of people with a regular income seems to accumulate around the 5.000 \u2013 10.000 buckets which may be the mean average salary for Data Scientists in India. The higher the income is the lower the percentage within the Indian sample.\n* In the US respectively there is only a relatively small percentage of people with a really low income. The majority groups between 100.000 and 150.000 Dollars which is probably the mean regular salary of Data Scientist of any kind in the US.\n* This distribution fits our assumptions regarding the distribution of studying versus working Data Scientists within both samples.","3da4c1d6":"## 1.2 Gender ratio\nIn tech we still encounter a significant difference in the ratio between men, females and other genders. We were interested in seeing if this ratio would be different between India and the US.","a46d5ab9":"## 1.1.1 Answer ratio by country over time","6a109613":"# 3. Tools and technologies","2e32c93c":"## 1.3 Age distribution\nLet's have a look at the age distribution in India, in the US and globally in comparison.","6eabe4cf":"## Looking at the survey results: A comparison between India and the US\n\n\nSince over the last three years the two countries with the highest amount of responses for the Kaggle User Survey stayed the same we decided to take a closer look at these two lone giants in Data Science: the *United States* as a leading IT nation and *India* as a rapidly developing tech country.\n\n\n**Working questions:** \n1. Is there a trend in tools, education, resources and job positions in India and the US?\n2. Can we make assumptions on the role of India regarding the use and development of Data Science?\n3. Where is the new generation of Data Scientist going to come from?\n\n<b>Please note<\/b> when talking about the population from India and the US we refer to the participants of the Kaggle User Surveys (2017\/2018\/2019) who stated their current origin is India or the US respectively.\nThis survey is not generally representative to the US, the Indian population or the Data Science community.","0a08c68b":"### Observations:\n* The most popular learning resource among both participants from India and the US seems to be Coursera\n* We see bigger differences in the percentages for participants from India and the US in the use of \"Other\" learning resorces as well as learning within University Courses\n\n### Conclusions:\n* Surprisingly round double the percentage of participants from the US stated to learn through University Courses compared to participants from India. This may mean that even though a higher percentage of Indian participants interested in Data Science is currently studying at university not all of these students study a topic related to Data Science.\n* Due to the difference in the student\/employed ratio and the ratio of people who learn from University Courses versus people who learn from online resources we assume that a significantly amount of Indian students learn about Data Science online while studying a different topic. This may be an indicator for the assumption that Data Science is of growing importance in different industries in India.","94e46dc8":"### Observations:\n* We see that for almost all algorithms a slightly higher percentage of participants from the US stated to use these in comparison to participants from India\n* The only exception are Convolutional Neural Network algorithms - a slightly higher percentage of participants from India seem to use these\n\n### Conclusions:\n* We are not surprised to see lower percentages for most machine learning algorithms in India than in the US since we saw that many participants from India are still in the process of learning about Data Science. \n* Since the machine learning experience of participants from the US is longer on average these participants of course had more time to practice and apply different types of ML algorithms e.g. in their jobs.\n* The distribution of the regular application of these machine learning algorithms can also relate to the educational degree and age of the participants: With growing age and education the experience with ML algorithms on a regular basis increases in the field of Data Science.","dac93642":"### Observations:\n* Percentage wise most people from India who answered to the Kaggle User Survey do have a Bachelor's degree followed by a Master's degree while Doctoral degrees do have lower percentages in the Indian sample\n* Answers from people from the US showed that the relative majority of American users does have a Master's degree\n\n### Conclusions:\n* Considering the age distribution of Indian and American contributions we assume that Indian participants on average do have slightly lower educational degrees than participants from the US because of their age","ee6d3305":"# 2. Data Science in India and the US","c3d5bdc8":"## 2.3 Salary\nWhen looking at the proportion of educational degrees among India and the US we would expect to find a slightly different salary distribution in the US and India. Due to the high amount of students within the Indian participants we expect a higher percentage of people with a low income from India versus a higher percentage of people with a medium or high income in the US according to the high percentage of Master's degrees within the survey answers from the US.","42fa7b71":"### Observations:\n* Within the participants from the US \"Data Scientist\" is the most commonly chosen job description\n* Percentage wise most of the participants from India are currently students\n\n### Conclusions:\n* Indeed over one third of the participants from India are currently students. Since this is much more than the percentage of participants from India who stated to be without any educational degree we assume that many  students from India interested in Data Science are currently aming for a second degree, e.g. a Master's degree.\n* We assume that these students are going to finish their studies within the next years and become some great Data Scientists, Engineers, Analysts, etc. (or at least some of them is going to be!)","be2622f8":"\n# Summary\n\nBased on the analysis of selected features we assume, that India has the potential to be an upcoming Data Science superpower and can have a high impact on the future of Data Science globally.\n\nThe ratio of Indian participants in the survey grew compared to the ratio of US participants by 20% from 2017 to 2019. Assuming these Indian participants are interested, apply or support digital technologies they increase their contribution to digital sciences.\n\nMost of the Indian participants are young (<25 years) with less experience in Data Science and Machine Learning than US participants. But we could reveal, that they provide twice as many young developers into the digital market.\n\nIndian participants are more likely to have a lower education degree than US participants. This could be derived by the assumption, that many aspiring Data Scientists from India are still in the process of obtaining a Bachelor's or Master's Degree before entering the global job market.","170b19f8":"## 1.3.1 Age distribution over time","4bd9c516":"## 3.5 Learning Resources\nLast but not least we wanted to know which resources participants use to learn about Data Science related topics - especially since we saw that a high percentage of participants from India are currently students.","c2a0d123":"### Observations:\n* Together India and the US make around 28.5% of all answers to the Kaggle User Survey 2019\n* We can see a 60\/40 ratio for answers from India versus answers from the US\n\n### Conclusions:\n* In order to compare different features of Indian and American Data Scientists we will need to normalize values since the samples are not equal in size","d5515424":"# Battle of the Giants\n\n## ***Is India going to be a future superpower in Data Science?***\n\n\n\n\n\n\n***An exploration of the Kaggle Data Science and Machine Learning Survey  2019 results***","3647a8d4":"### Observations:\n* Within both India and the US Python is the programming language most participants use\n* In the US higher percentages of programmers use SQL, R and Bash than in India\n* In India higher percentages of programmers use C++, C and Java than in the US","ccca6b0d":"## 2.1 Highest educational degree\nSince the age distribution of survey participants from India versus participants from the US showed that Kaggle users from India on average are younger than Kaggle users from the US we had a look at the highest educational degree of the users to see if the age distribution reflects in the distribution of educational degrees.","b0eb3c15":"### Observations:\n* We see a high percentage of Indian participants with machine learning experience between less than one year and 1 \u2013 2 years\n* In comparison the distribution of machine learning experience of participants from the US is more flat and more equally distributed between < one year and 20+ years\n\n### Conclusions:\n* As assumed there is a high percentage of people from India with a lower amount of machine learning experience fitting the age and degree distribution for people from India\n* Other than the programming experience almost 50% of participants from India seem to have started learning about machine learning within the last year. This may be an indicator for a growing interest towards machine learning in India and this topic being part of educational programs of Indian students.","df190256":"## 2.2 Current job position\nAfter looking at the educational degrees let's have a look at the current position of the survey participants and see if our assumption of a relatively high percentage of students in India will be confirmed.","c87012ef":"### Observations:\n* Compared to the US a higher percentage of small Indian companies with 1 \u2013 250 employees applies DS methodology\n* Within the company size range between 1.000 and 9.999 employees more companies in the US use DS\n* In companies with more than 10.000 employees Indian companies take over again regarding the use of DS tools and methodology. \n\n### Conclusions:\n* Over all company sizes both India and the US do not vary a lot from the global distribution.\n* Higher percentages of people from India than from the US work in very small or very big companies applying any kind of Data Science. We can assume that quite small and quite big companies tend to apply Data Science more often than companies of middle size.","122ae300":"## 2.1.1 Highest educational degree over time","29ef65fa":"## 3.1 Programming languages\nWe want to know if the tools and technologies used in the Data Science context differ between India and the US. The use of different programming languages could show trends and help young Data Scientists decide which languages to practice first.","7b94d8c1":"# What's next?\n* Evaluate the industries and company fields currently applying Data Science\n* Finding a way how to measure the impact of Data Science on different industries and countries\n* Predicting trends and developments in Data Science - both for India and the US ans globally\n* Taking into account social and economical differences between countries when looking at the development of Data Science","556ba775":"## 3.4 Machine learning algorithms\nBased on the observations regarding programming and machine learning experience of the survey participants we wanted to know if there are any differences in the distribution of machine learning algorithms between India and the US.","1e20c105":"## 2.4 Company size\nLooking at the potential of upcoming Data Scientists of any kind within India and the US we want to examine the current state of the DS industry in both our samples. Evaluating the company size offers insights on the exploitment of the potentials of DS across India and the US. ","e1b3f882":"## 3.3 Machine Learning experience\nThe machine learning experience in years can be an indicator for a digital transformation towards machine learning in the field of Data Science.\nSimilar to the programming experience in years we assume a high percentage of people from India having a shorter machine learning experience in comparison to people from the US.","2f202d5c":"## 3.2 Programming experience\nThe programming experience in years in conjunction with age and degree can be an indicator for the time the surveys participants have been interested in or practicing Data Science.\nBased on the results of the age and educational degree visualization we expect a high percentage of people from India with less programming experience and a more flat distribution for people in the US."}}