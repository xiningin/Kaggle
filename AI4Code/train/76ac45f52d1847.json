{"cell_type":{"d9843658":"code","bcf16ef8":"code","1da82e1e":"code","4446c309":"code","db343b7e":"code","67b747fd":"code","5d1fdefa":"code","a32af38f":"code","4f987993":"code","349e0cb9":"code","0cf39e14":"code","82e816f2":"code","5e63cb35":"code","9040b525":"code","9f1dc7de":"code","278a4436":"code","0971a647":"code","b54c5abc":"code","62d6999c":"code","ff8b517e":"code","a64cd1b2":"code","c09f6e6f":"code","ba9c8989":"code","aa604c52":"code","91cf6148":"markdown","74ddfdfc":"markdown","bf98cf8e":"markdown","30c3a928":"markdown","810200fe":"markdown","68bc02f3":"markdown","db67a778":"markdown","509b39c8":"markdown","b985efcf":"markdown","45feda4b":"markdown","8ed684a8":"markdown","eaca0df3":"markdown","a1865b9b":"markdown"},"source":{"d9843658":"import os\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nimport numpy as np\nimport plotly.express as px\nwarnings.filterwarnings('ignore')\ntrain = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","bcf16ef8":"list_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\nlist_order_trade_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/*')","1da82e1e":"def log_return(wap):\n    return np.log(wap).diff()\n\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef wap_1(df):\n    df['wap1'] =(df['bid_price1'] * df['ask_size1']+df['ask_price1'] * df['bid_size1'])  \/ (\n                              df['bid_size1']+ df['ask_size1'])\n    return df['wap1']\ndef wap_2(df):\n    df['wap2'] =(df['bid_price2'] * df['ask_size2']+df['ask_price2'] * df['bid_size2'])  \/ (\n                              df['bid_size2']+ df['ask_size2'])\n    return df['wap2'] ","4446c309":"## I use this package to exploit the groupby function under numpy\n!pip install  ..\/input\/numpy-indexed-v035\/numpy_indexed-0.3.5-py2.py3-none-any.whl\n\nimport numpy_indexed as npi\n","db343b7e":"def wap_logreturn_numpy(df,index):\n    np_df = np.array(df).astype(np.float32)\n    np_df_unique_id = np.unique(np_df[:,0]).reshape(-1,1)\n    #rv = np.array([])\n\n    wap_grouby_timeid_flatten = npi.group_by(np_df[:, 0]).split(np_df[:, -2 + index]) \n    for i in range(len(wap_grouby_timeid_flatten)):\n        wap_grouby_timeid_flatten[i] = np.diff(np.log(wap_grouby_timeid_flatten[i]))\n\n    rv_list = []\n    for i in range(len(wap_grouby_timeid_flatten)):\n        rv_list.append(realized_volatility(wap_grouby_timeid_flatten[i]))\n      \n    rv_array = np.array(rv_list).reshape(-1,1)\n    rv = np.concatenate((np_df_unique_id,rv_array),axis=1)\n    return  rv","67b747fd":"def trade_per_time_id(file_path):\n    df_trade = pd.read_parquet(file_path)\n    df_realized_vol_per_stock = pd.DataFrame()\n\n    np_df_unique_id = np.unique(np.array(df_trade)[:,0]).flatten()\n    \n    stock_id = np.int(file_path.split('=')[1])\n    \n    list_of_index = []\n    for i in range(len(np.unique(np_df_unique_id))):\n        list_of_index.append(f'{stock_id}-{np.int(np_df_unique_id[i])}')\n\n    df_realized_vol_per_stock['row_id'] = list_of_index\n    df_realized_vol_per_stock[['seconds_in_bucket','price','size','order_count']] = df_trade.groupby(['time_id']).mean()[['seconds_in_bucket','price','size','order_count']].values\n\n    return df_realized_vol_per_stock\n\ndef trade_groupby(list_file):\n    df_past_realized = pd.DataFrame()\n\n    for f1 in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     trade_per_time_id(f1)])\n  \n    return df_past_realized\n","5d1fdefa":"time df_trade_train = trade_groupby(list_order_trade_file_train)","a32af38f":"def numpy_realized_volatility_per_time_id(file_path):\n\n\n    df_book = pd.read_parquet(file_path)\n    np_df_unique_id = np.unique(np.array(df_book)[:,0]).flatten()\n\n    df_realized_vol_per_stock = pd.DataFrame()\n    ## Calculate WAP\n    df_book['wap1'] = wap_1(df_book)\n    df_book['wap2'] = wap_2(df_book)\n    \n    ## Apply log return after grouping by id ( 5 then 6 then 7 ..... ) in order to apply the log return lag correctly\n    df_realized_vol_per_stock['rv1'] = wap_logreturn_numpy(df_book,0)[:,-1]\n    df_realized_vol_per_stock['rv2'] = wap_logreturn_numpy(df_book,1)[:,-1]\n\n\n    ## Extract the stock index \/ indice    \n    stock_id = np.int(file_path.split('=')[1])\n    \n    list_of_index = []\n    for i in range(len(np.unique(np_df_unique_id))):\n        list_of_index.append(f'{stock_id}-{np.int(np_df_unique_id[i])}')\n\n    df_realized_vol_per_stock['row_id'] = list_of_index\n\n    return df_realized_vol_per_stock[['row_id','rv1','rv2']]#,'vol1','vol2','fft1','fft2']]\n\ndef past_realized_volatility_per_book(list_file):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     numpy_realized_volatility_per_time_id(file)])\n  \n    return df_past_realized\n\n\n","4f987993":"df_past_realized_train = past_realized_volatility_per_book(list_order_book_file_train)","349e0cb9":"df_data = df_past_realized_train.merge(df_trade_train, on = ['row_id'], how='left')","0cf39e14":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain_ = train[['row_id','target']]\ndf_joined = train_.merge(df_data[['row_id','rv1', 'rv2', 'seconds_in_bucket', 'price', 'size',\n       'order_count']], on = ['row_id'], how = 'left').dropna()","82e816f2":"## Add new variable Rv3\ndf_joined['rv3'] = df_joined['rv1'] ** df_joined['rv2'] ","5e63cb35":"## Split the data\nX_train_, y_train = np.log10(df_joined[['rv1','rv2','rv3','price', 'size',\n       'order_count']]), np.log10(df_joined[['target']])","9040b525":"\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr = lr.fit(X_train_,y_train)\nlr.score(X_train_,y_train)","9f1dc7de":"y_pred_train_log10 = lr.predict(X_train_)\ny_pred_train = 10**(y_pred_train_log10)","278a4436":"from sklearn.metrics import r2_score\n\nR2 = r2_score(df_joined['target'].values, y_pred_train)\n\nprint(R2)","0971a647":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\nRMSPE = round(rmspe(10**y_train,y_pred_train),3)\nprint(f'Performance of the naive prediction:, RMSPE: {RMSPE}')","b54c5abc":"def log_return(wap):\n    return np.log(wap).diff()\n\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef wap_1(df):\n    df['wap1'] =(df['bid_price1'] * df['ask_size1']+df['ask_price1'] * df['bid_size1'])  \/ (\n                              df['bid_size1']+ df['ask_size1'])\n    return df['wap1']\ndef wap_2(df):\n    df['wap2'] =(df['bid_price2'] * df['ask_size2']+df['ask_price2'] * df['bid_size2'])  \/ (\n                              df['bid_size2']+ df['ask_size2'])\n    return df['wap2'] \n\n\ndef wap_logreturn(df,index):\n    df['log_return{}'.format(index)] = df.groupby(['time_id'])['wap{}'.format(index)].apply(log_return)\n    df = df[~df['log_return{}'.format(index)].isnull()]\n    \n    ## Compute the realized volatility of the stock per time id \n    df_realized_vol_per_stock =  pd.DataFrame(df.groupby(['time_id'])['log_return{}'.format(index)].agg(realized_volatility)).reset_index()\n\n    return df_realized_vol_per_stock['log_return{}'.format(index)]\n\n\n\ndef realized_volatility_per_time_id(file_path):\n    df = pd.read_parquet(file_path)\n    df_realized_vol_per_stock = pd.DataFrame()\n\n\n    ## Calculate WAP\n    df['wap1'] = wap_1(df)\n    df['wap2'] = wap_2(df)\n    \n    ## Apply log return after grouping by id ( 5 then 6 then 7 ..... ) in order to apply the log return lag correctly\n    df_realized_vol_per_stock['rv1'] = wap_logreturn(df,1)\n    df_realized_vol_per_stock['rv2'] = wap_logreturn(df,2)\n    df_realized_vol_per_stock['time_id'] =  np.unique(np.array(df)[:,0]).flatten().astype(int)\n\n\n    ## Extract the stock index \/ indice\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n\n\n\n    return df_realized_vol_per_stock[['row_id','rv1','rv2']]\n\n\ndef past_realized_volatility_per_stock(list_file):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file)])\n    return df_past_realized","62d6999c":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\nlist_order_trade_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_test.parquet\/*')\n\ndf_book_test  = past_realized_volatility_per_stock(list_file=list_order_book_file_test)\ndf_trade_test = trade_groupby(list_order_trade_file_test)[['row_id','price','size','order_count']]                                                      \n","ff8b517e":"df_test = df_book_test.merge(df_trade_test, on = ['row_id'], how=\"left\")\ndf_test[['rv1','rv2','price', 'size','order_count']] = df_test[['rv1','rv2','price', 'size','order_count']].apply(lambda x: x.fillna(x.mean()),axis=0)\n","a64cd1b2":"df_test['rv3'] = df_test['rv1'] ** df_test['rv2']\ndf_test2 = df_test[['rv1','rv2','rv3','price', 'size','order_count']]\n#df_test2 = df_test2.apply(lambda x: x.fillna(x.mean()),axis=0)\nX_test = np.log10(df_test2)\n\n","c09f6e6f":"y_pred_test = 10**lr.predict(X_test).flatten()\ny_pred_test","ba9c8989":"df_test_2 = df_test[['row_id']]\ndf_test_2['target'] = y_pred_test","aa604c52":"df_test_2.to_csv('submission.csv',index = False)","91cf6148":"Because, internet must be disable for submission, I loaded the library from kaggle datasets.","74ddfdfc":"## Import libraries","bf98cf8e":" See my notebook [here](https:\/\/www.kaggle.com\/rayanaay\/12x-faster-variable-extraction-using-numpy) for a minimal example where I compare execution time between Numpy and Pandas.\n\nIf you use parts of this notebook in your scripts\/notebooks, giving some kind of credit would be very much appreciated :) You can for instance link back to this notebook, and upvote it. Thanks!","30c3a928":"# Deal with Book Data","810200fe":"## Some useful functions to calculate WAP","68bc02f3":"# Simple Solution with Optimal variable extraction: 12X TIMES FASTER !","db67a778":"# Deal with Trade Data","509b39c8":"# Numpy implementation for computing realized volatility on all the data","b985efcf":" - `numpy_realized_volatility_per_time_id`is a global function that calls  `wap1` and `wap2`function, as well as   the previous one `wap_logreturn_numpy`.\n\n- Path name `split` was handled using simple list comprehension loop. ","45feda4b":"Merge the two datafram on `row_id`column","8ed684a8":"# Linear Regression","eaca0df3":"# Preprocessing","a1865b9b":"# Submission"}}