{"cell_type":{"78f62a7a":"code","077e55c8":"code","e5a49109":"code","feabf856":"code","3dfc0094":"code","a281adc0":"code","dc46de96":"code","305a3f70":"code","16f1c1c5":"code","d9ee6ff2":"code","031eb399":"code","f0e07c68":"code","64e8875d":"code","d619f9ee":"code","57a38fa6":"markdown","ad2e3aba":"markdown","774dc26c":"markdown","2c5632b6":"markdown","dc2817d8":"markdown","d5fea92f":"markdown","6c278ba6":"markdown","33c320e7":"markdown","c6179a8d":"markdown","db7ca620":"markdown","4e799fef":"markdown","4bd05628":"markdown","1d5093d9":"markdown","c26ae8b9":"markdown","7af5a94d":"markdown"},"source":{"78f62a7a":"#Necessary imports\nimport numpy as np\nimport pandas as pd\nimport os\n\n#For Preprocessing\nimport cv2\nimport itertools\nfrom tqdm import tqdm_notebook as tqdm\n\n#Additional imports for functionality\nfrom sklearn.utils import class_weight, shuffle\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n\n#For Graphing and Plotting Images\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n%matplotlib inline\n\n#For model building\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint","077e55c8":"#Getting foldernames from dataset\nfoldernames = os.listdir('..\/input\/animals10\/raw-img')\n\n#Creating Empty lists for categories and the files\ncategories = []\nfiles = []\ni = 0\n\n#Going over all the folders and their categories in the foldernames\nfor k, folder in enumerate(foldernames):\n    #Getting the filenames\n    filenames = os.listdir(\"..\/input\/animals10\/raw-img\/\" + folder);\n    for file in filenames:\n        #Appending all the image files into one list\n        files.append(\"..\/input\/animals10\/raw-img\/\" + folder + \"\/\" + file)\n        #Appending categories into one list\n        categories.append(k)\n\n#Defining a DataFrame to store data\ndf = pd.DataFrame({\n    'filename': files,\n    'category': categories\n})\n\n#Taking 500 files of each category from the data into train_df\ntrain_df = pd.DataFrame(columns=['filename', 'category'])\nfor i in range(10):\n    train_df = train_df.append(df[df.category == i].iloc[:500,:])\n\n#Taking a peek at the data using head()\ntrain_df.head()\ntrain_df = train_df.reset_index(drop=True)\ntrain_df","e5a49109":"#Assigning x and y to be the values and their target labels respectively\ny = train_df['category']\nx = train_df['filename']\n\n#Shuffling the data\nx, y = shuffle(x, y, random_state=8)","feabf856":"#Standard DataPreprocessing from OpenCV used for formatting the input to fit \n#the specifications of the input of the VGG-16 model\n\ndef centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    #Finding the centre of the image by calculating horizontal\n    #and vertical distances\n    row = (size[1] - img_size[0]) \/\/ 2\n    col = (size[0] - img_size[1]) \/\/ 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\nimages = []\n#tqdm is used for visualing the progress of the image preprocessing as a progress bar\nwith tqdm(total=len(train_df)) as pbar:\n    #Going over all the filenames in train_df\n    for i, file_path in enumerate(train_df.filename.values):\n        #Read image using imread\n        img = cv2.imread(file_path)\n        \n        #Converting colour channels of all pictures to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        #Centering all the images\n        img = centering_image(cv2.resize(img, dsize=(256, 256)))\n\n        #We have to shape the output to 224x224px because the VGG-16 model takes in input shape of 224x224px \n        img = img[16:240, 16:240]\n        images.append(img)\n        pbar.update(1)\n\nimages = np.array(images)","3dfc0094":"#10 images one for each category\nrows,cols = 2,5\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,20))\n\n#Going over each category\nfor i in range(10):\n    #Getting path for each category\n    path = train_df[train_df.category == i].values[2]\n    axes[i\/\/cols, i%cols].imshow(images[train_df[train_df.filename == path[0]].index[0]])","a281adc0":"#Getting a list of the number of images used and a random index permutation from the data\n#to randomly append images into x_shuffle along with their labels\ndata_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\n#Empty lists to store shuffled data\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(images[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)\n\n#Partitioning 20% of the dataset into test set\ntest_split_num = int(round(0.2*len(y)))\nx_train = x[test_split_num:]\ny_train = y[test_split_num:]\nx_test = x[:test_split_num]\ny_test = y[:test_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)\n\n#Converting categories into binary matrix of 0s and 1s where 1 represents the correct class\n#and 0s in all other places\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n#Converting all pixel values to float\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n#Formatting all the pixel values to be in between 0 and 1\nx_train \/= 255\nx_test \/= 255\n\n#Changing category labels from given language into english\nimg_rows, img_cols, img_channel = 224, 224, 3\nname_animal = []\nfor i in range(10):\n    path = train_df[train_df.category == i].values[2]\n    if path[0].split('\/')[-2] == 'scoiattolo':\n        name_animal.append('squirrel')\n    elif path[0].split('\/')[-2] == 'cavallo':\n        name_animal.append('horse')\n    elif path[0].split('\/')[-2] == 'farfalla':\n        name_animal.append('butterfly')\n    elif path[0].split('\/')[-2] == 'mucca':\n        name_animal.append('cow')\n    elif path[0].split('\/')[-2] == 'gatto':\n        name_animal.append('cat')\n    elif path[0].split('\/')[-2] == 'pecora':\n        name_animal.append('sheep')\n    elif path[0].split('\/')[-2] == 'gallina':\n        name_animal.append('chicken')\n    elif path[0].split('\/')[-2] == 'elefante':\n        name_animal.append('elephant')\n    elif path[0].split('\/')[-2] == 'ragno':\n        name_animal.append('spider')\n    elif path[0].split('\/')[-2] == 'cane':\n        name_animal.append('dog')","dc46de96":"#Getting the base VGG-16 model\nbase_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n\n#Sequential model used for the task\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(10, activation='softmax'))\n\n#Defining the model\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","305a3f70":"batch_size = 32\nepochs = 3\n\n#Data Augmentation\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n#Fitting the model\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc')]\n)","16f1c1c5":"print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,history.history['accuracy'][epochs-1],history.history['val_accuracy'][epochs-1]))\n\n#Function to plot Graphs\ndef show_plots(history):\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss']\n    epochs = range(1, len(history['accuracy'])+1)\n    \n    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n    \n    #Plotting Graph for the Losses\n    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n    ax[0].set_title('Training & Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend(loc='best')\n    ax[0].grid(True)\n    \n    #Plot Graph for the Accuracies\n    acc_vals = history['accuracy']\n    val_acc_vals = history['val_accuracy']\n\n    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n    ax[1].set_title('Training & Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend(loc='best')\n    ax[1].grid(True)\n    \n    plt.show()\n    plt.close()\n    \n    #Delete locals from heap before exiting\n    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals\n    \nshow_plots(history.history)","d9ee6ff2":"#Getting test labels and predictions\npreds = np.round(model.predict(x_test),0)  \ncategorical_test_labels = pd.DataFrame(y_test).idxmax(axis=1)\ncategorical_preds = pd.DataFrame(preds).idxmax(axis=1)\n\nconfusion_matrix= confusion_matrix(categorical_test_labels, categorical_preds)","031eb399":"#Function to Plot Confusion Matrix\ndef plot_confusion_matrix(cm, classes,\n             title='Confusion matrix',\n             cmap=plt.cm.Blues):\n    #Normalize the values\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    print('Confusion matrix')\n    \n    #Plot the matrix\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    \n    #Going over all ten categories, and for each category going over all \n    #ten categories to get a square matrix for every category \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], '.2f'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() \/ 2. else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","f0e07c68":"#Call plotting function\nplot_confusion_matrix(confusion_matrix, \n                      ['butterflies', 'chickens', 'elephants', 'horses', 'spiders',\n                       'squirells', 'dog', 'sheep', 'cow', 'cat'])","64e8875d":"#Empty list to get images for testing\ntest_images = []\nj = 76\n\n#Getting one image from each category for testing\nfor i in range(10):\n    #Getting File Path\n    path = train_df[train_df.category == i].values[j]\n    #Getting Image from File\n    a = images[train_df[train_df.filename == path[0]].index[0]]\n    #Converting image into pixel array\n    img = np.array(a)\n    \n    #Preprocessing images using opencv\n    img = img[:, :, ::-1].copy() \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = centering_image(cv2.resize(img, dsize=(256, 256)))\n    \n    #Reshaping into 224x224psx for VGG-16 model \n    img = img[16:240, 16:240]\n    test_images.append(img)\n\ntest_images = np.array(test_images).reshape(-1,224,224,3)\n\n#Making predictions on test_images\npredictions = model.predict(test_images)\nanimals = name_animal\n\n#Plotting predictions\ni = 0\nfor pred in predictions:\n    path = train_df[train_df.category == i].values[2]\n    plt.imshow(test_images[i])\n    plt.show()\n    print('Actual  :', animals[i])\n    print('Predict :', animals[np.where(pred.max() == pred)[0][0]])\n    i += 1\n","d619f9ee":"#Plotting model as png\nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png')","57a38fa6":"Here we can see we have 5000 total images numbered from 0 -4999. All the filenames are listed along with their respective categories.","ad2e3aba":"We perform image preprocessing using OpenCV to resize all the images and center them to make sure all data looks uniform.","774dc26c":"# Model Fitting\n\nWe declare the batch size, i.e. the number of training images from the data thath we will be using to measure the loss of the model and perform gradient descent, for training the model and also the number of epochs, i.e. the number of times the entire datatset will be run throguh the model.\n\nImageDataGenerator is used to do Data Augmentation, i.e. slightly change tha data in certain ways such as to rotate it horizontally\/ vertically, horiontally\/vertically shift the image by a few pixels, flip the image horiontally, apply various filters and masks which change the pixel values of the original picture. This is very helpful for creating more data from a given small dataset and can be used to increase the size of the data so that the model can learn from more examples and give us a more effectiv estimation accuracy and decreased loss.\n\nFitGenerator is used to fit and describe the model, to specify the data that will be used to train the model(X_train and y_train), how much of the batch size to use per step, how many epochs to run the entire data for. We have also added a Keras CallBack feature which keeps checkpoints of the model and updates after a certain time, so that if something goes wrong with the model we can revert it back to a point where it was still properly functional.","2c5632b6":"The above is a summary of all the layers in the VGG-16 model.","dc2817d8":"We have managed to achieve an accuracy of 97% using this model!\n\nBelow we take a look at some metric graphs of validation loss vs training loss as well as validation accuracy vs training accuracy.","d5fea92f":"# Importing necessary libararies\n\n* numpy - NumPy is a library for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n\n* pandas - Pandas is a software library for data manipulation and analysis.\n\n* keras - Keras is an open-source library that provides a Python interface for artificial neural networks. We will use to implement the model.\n\n* matplotlib - Matplotlib is a plotting library used for plotting various charts and graphs to better understand the data and progress of our model.\n\n* sklearn - Sci-kit Learn is a library with various functionalities that ease several data handling and feature preprocessing tasks.\n\n\n\n\n\n\n\n","6c278ba6":"Splitting the data into train and test sets. Train sets will be used to train and build the model and then we wil use the test set for model to evaluation to see how accurate our model is.","33c320e7":"# Testing Images\n\nWe now check our models predictions on some test images.","c6179a8d":"# Confusion Matrix\n\nWe will be taking a look at the confusion matrix to get a deeper insight into our model.","db7ca620":"# Exploring the data\nHere we will get the data from the main Animals 10 Dataset. The Data is divided into 10 folder categories with one folder for each type of animasl. The animals that are present in this dataset are:\n\n1. Dog\n2. Squirrel\n3. Horse \n4. Elephant\n5. Butterfly\n6. Chicken\n7. Cat\n8. Cow\n9. Sheep\n10. Spider\n\nWe will get the folders from the dataset and create a list of categories. As we go through the foldernames, we will append each of them to the categories list to keep track of them. In a files list, we will store all the images from the dataset as train_df. This will be used for training the model. \nWe then take a loot at the data with train_df.head().\n\n","4e799fef":"# Project Description\n\nThis is an animal classification project we have created to classify various animals into different categories.We have used the Animals-10 dataset on Kaggle to perform this task.\n","4bd05628":"# Conclusion\n\nAfter studying various outputs, we have seen that the model tends to be weak at ditinguishing between the categories when the colours of the animals tend to match colours more common to specific species, such as white dogs and cats being classified as sheep. This can possibly be solved with acquiring more data,\ntweaking the hyperparameters such as using a deeper network or more neurons per layer, etc.","1d5093d9":"Now we take a look at few of the examples from the dataset.","c26ae8b9":"# Data Preprocessing\n\nWe shuffle train_df to randomly distribute the images along with their categories.","7af5a94d":"# Model Selection\nWe will be using a pretrained VGG-16 model trained on the Imagenet Dataset. All the paramteres except for those on the top layer will be freezed so that we can effectively use transfer learning on our task on Animal Classification. The Sequential Model of Keras is used in which we can add layers as we need. Two Dense layers have been added to the top, a layer with 256 neurons that uses a relu activation function and finally a layer with 10 output neurons and a softmax function is used to classify the images into one of the ten categories that we have."}}