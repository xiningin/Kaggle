{"cell_type":{"76e79d54":"code","35078978":"code","3121dfdb":"code","0dccabad":"code","743681c2":"code","ced9d62d":"code","84cede3d":"markdown"},"source":{"76e79d54":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\nimport seaborn as sns\n\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)","35078978":"# Read the data\nX = pd.read_csv('..\/input\/train.csv', index_col='Id') \nX_test = pd.read_csv('..\/input\/test.csv', index_col='Id')\n\ny = X.SalePrice\nX.drop(columns=['SalePrice'], inplace=True)","3121dfdb":"categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\nnumerical_cols = [col for col in X.columns if (X[col].dtype == 'int64' or X[col].dtype == 'float64')]","0dccabad":"numerical_transformer = SimpleImputer()\ncategorical_transformer = Pipeline(steps=\n                                   [('imputer', SimpleImputer(strategy='most_frequent')),\n                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=\n                                 [('num', numerical_transformer, numerical_cols), \n                                  ('cat', categorical_transformer, categorical_cols)])\n\nmodel = XGBRegressor(random_state=0)\n\npipeline = Pipeline(steps=\n                   [('preprocess', preprocessor),\n                   ('model', model)])\n\ngrid = GridSearchCV(pipeline,  \n                    param_grid={'model__n_estimators': [2000, 3000],\n                                'model__learning_rate' : [0.01, 0.05],                                \n                                'model__min_child_weight' : [0, 1]\n                               },\n                    cv = 10,\n                    scoring = 'neg_mean_absolute_error')\n\ngrid.fit(X, y)","743681c2":"print(f\"Best model parameters: {grid.best_params_}\")\nprint(f\"Best score: {-1 * grid.best_score_}\")","ced9d62d":"# save test predictions to file\npredictions = grid.predict(X_test)\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","84cede3d":"Pipelines are a convenient way to preprocess data and estimate a model with very few lines of code. The approach we will take is the following:\n- impute missing data (use mean for numerical values, most frequent for strings)\n- add one-hot encoded columns for categorical variables\n- run gradient-boosted regression using XGBoost and k-fold cross validation\n\nWe will also use GridSearchCV to iterate through different parameter values to find the best performing model before generating our predictions on the test set."}}