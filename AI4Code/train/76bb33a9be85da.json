{"cell_type":{"62fa6887":"code","77b90812":"code","1a7fe75c":"code","eb1578ad":"code","63ddf493":"code","ffc6b585":"code","d2c40cf8":"code","fa7302cb":"code","4f0a7acd":"code","c2901fe1":"code","31648d6d":"code","58d42dad":"code","bf00b920":"code","a22c8ac8":"code","db7d91cf":"code","1d770eed":"code","4186a866":"code","52a5e31d":"code","d3d5c422":"code","571bfef9":"code","7e47856c":"code","418492d2":"code","640316a6":"code","6331da52":"code","6488c7aa":"code","1f6503b7":"code","4e5f1ac9":"code","d5cbdcf6":"code","8544052a":"code","c9a50bac":"code","45ae35f0":"code","63b59287":"code","f923df46":"code","e10c7ee6":"code","0d17a72d":"code","782dc0fc":"code","6a299a4d":"code","d7b5db10":"code","a5fe4a14":"markdown","3012fd41":"markdown","dc697efd":"markdown","bee4f70d":"markdown","37a41f0c":"markdown","229d8dda":"markdown","3e2ab014":"markdown","1e57a7d5":"markdown","318d7477":"markdown","76d0a9c4":"markdown","e0c7af07":"markdown"},"source":{"62fa6887":"#Import some basic libraries\nimport numpy as np\nimport pandas as pd","77b90812":"#Read the data present in dataset\ndata = pd.read_csv('..\/input\/kerela-flood\/kerala.csv')\n#Using data.head() we can see the top 5 rows of the dataset\ndata.head()","1a7fe75c":"#Now we will cheak if any colomns is left empty\ndata.apply(lambda x:sum(x.isnull()), axis=0)","eb1578ad":"#We want the data in numbers, therefore we will replace the yes\/no in floods coloumn by 1\/0\ndata['FLOODS'].replace(['YES','NO'],[1,0],inplace=True)","63ddf493":"#Let's see how are data looks like now\ndata.head()","ffc6b585":"#Now let's seperate the data which we are gonna use for prediction\nx = data.iloc[:,1:14]\nx.head()","d2c40cf8":"#Now seperate the flood label from the dataset\ny = data.iloc[:, -1]\ny.head()","fa7302cb":"#Let's see hoe the rainfall index vary during rainy season\nimport matplotlib.pyplot as plt\n%matplotlib inline\nc = data[['JUN','JUL','AUG','SEP']]\nc.hist()\nplt.show()","4f0a7acd":"#Data might be widely distributed so let's scale it between 0 and 1\nfrom sklearn import preprocessing\nminmax = preprocessing.MinMaxScaler(feature_range=(0,1))\nminmax.fit(x).transform(x)","c2901fe1":"#Let's divide the dataset into 2 sets:train and test in ratio (4:1)\nfrom sklearn import model_selection,neighbors\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","31648d6d":"#Let's see how our train set looks like\nx_train.head()","58d42dad":"y_train.head()","bf00b920":"clf = neighbors.KNeighborsClassifier()\nknn_clf = clf.fit(x_train,y_train)","a22c8ac8":"#Let's predict chances of flood\ny_predict = knn_clf.predict(x_test)\nprint('predicted chances of flood')\nprint(y_predict)","db7d91cf":"#Actual chances of flood\nprint(\"actual values of floods:\")\nprint(y_test)","1d770eed":"from sklearn.model_selection import cross_val_score","4186a866":"knn_accuracy = cross_val_score(knn_clf,x_test,y_test,cv=3,scoring='accuracy',n_jobs=-1)","52a5e31d":"knn_accuracy.mean()","d3d5c422":"x_train_std = minmax.fit_transform(x_train)\nx_test_std = minmax.transform(x_test)","571bfef9":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr_clf = lr.fit(x_train_std,y_train)\n\nlr_accuracy = cross_val_score(lr_clf,x_test_std,y_test,cv=3,scoring='accuracy',n_jobs=-1)","7e47856c":"lr_accuracy.mean()","418492d2":"y_predict = lr_clf.predict(x_test_std)\nprint('Predicted chances of flood')\nprint(y_predict)","640316a6":"print('Actual chances of flood')\nprint(y_test.values)","6331da52":"from sklearn.metrics import accuracy_score,recall_score,roc_auc_score,confusion_matrix\nprint(\"\\naccuracy score: %f\"%(accuracy_score(y_test,y_predict)*100))\nprint(\"recall score: %f\"%(recall_score(y_test,y_predict)*100))\nprint(\"roc score: %f\"%(roc_auc_score(y_test,y_predict)*100))","6488c7aa":"from sklearn.tree import DecisionTreeClassifier\ndtc_clf = DecisionTreeClassifier()\ndtc_clf.fit(x_train,y_train)\ndtc_clf_acc = cross_val_score(dtc_clf,x_train_std,y_train,cv=3,scoring=\"accuracy\",n_jobs=-1)\ndtc_clf_acc","1f6503b7":"#Predicted flood chances\ny_pred = dtc_clf.predict(x_test)\nprint(y_pred)","4e5f1ac9":"#Actual flood chances\nprint(\"actual values:\")\nprint(y_test.values)","d5cbdcf6":"from sklearn.metrics import accuracy_score,recall_score,roc_auc_score,confusion_matrix\nprint(\"\\naccuracy score:%f\"%(accuracy_score(y_test,y_pred)*100))\nprint(\"recall score:%f\"%(recall_score(y_test,y_pred)*100))\nprint(\"roc score:%f\"%(roc_auc_score(y_test,y_pred)*100))","8544052a":"from sklearn.ensemble import RandomForestClassifier\nrmf = RandomForestClassifier(max_depth=3,random_state=0)\nrmf_clf = rmf.fit(x_train,y_train)\nrmf_clf","c9a50bac":"rmf_clf_acc = cross_val_score(rmf_clf,x_train_std,y_train,cv=3,scoring=\"accuracy\",n_jobs=-1)\n#rmf_proba = cross_val_predict(rmf_clf,x_train_std,y_train,cv=3,method='predict_proba')","45ae35f0":"rmf_clf_acc","63b59287":"y_pred = rmf_clf.predict(x_test)","f923df46":"from sklearn.metrics import accuracy_score,recall_score,roc_auc_score,confusion_matrix\nprint(\"\\naccuracy score:%f\"%(accuracy_score(y_test,y_pred)*100))\nprint(\"recall score:%f\"%(recall_score(y_test,y_pred)*100))\nprint(\"roc score:%f\"%(roc_auc_score(y_test,y_pred)*100))","e10c7ee6":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\nlog_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\nrnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\nknn_clf = KNeighborsClassifier()\n\nvoting = VotingClassifier(\n    estimators=[('lr', log_clf), ('rf', rnd_clf), ('knn', knn_clf)],\n    voting='hard')","0d17a72d":"voting_clf = voting.fit(x_train, y_train)","782dc0fc":"from sklearn.metrics import accuracy_score\n\nfor clf in (log_clf, rnd_clf, knn_clf, voting_clf):\n    clf.fit(x_train, y_train)\n    y_pred = clf.predict(x_test)\n    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))","6a299a4d":"models = []\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('DT', DecisionTreeClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('EL', VotingClassifier(\n    estimators=[('lr', log_clf), ('rf', rnd_clf), ('knn', knn_clf)],\n    voting='hard')))\n\n\nnames = []\nscores = []\nfor name, model in models:\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    scores.append(accuracy_score(y_test, y_pred))\n    names.append(name)\ntr_split = pd.DataFrame({'Name': names, 'Score': scores})\nprint(tr_split)","d7b5db10":"import seaborn as sns\naxis = sns.barplot(x = 'Name', y = 'Score', data =tr_split )\naxis.set(xlabel='Classifier', ylabel='Accuracy')\nfor p in axis.patches:\n    height = p.get_height()\n    axis.text(p.get_x() + p.get_width()\/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n    \nplt.show()","a5fe4a14":"# 2. Logistic Regression","3012fd41":"# 3. Decision tree classification","dc697efd":"# As we can observe and Compare different Models and Choose the best One.","bee4f70d":"# 5. Enseble Learning","37a41f0c":"# 4. Random Forest Classification","229d8dda":"# Prediction Algorithms:","3e2ab014":"# Give an Upvote if you like this Notebook.","1e57a7d5":"# 1. KNN Classifier","318d7477":"# Data Insight","76d0a9c4":"# Comparing all the prediction models","e0c7af07":"# Flood prediction Model"}}