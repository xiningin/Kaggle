{"cell_type":{"efd556b7":"code","b7100928":"code","85d88ac5":"code","632c3200":"code","3ead65e2":"code","1a09d746":"code","135b4325":"code","e60e65ab":"code","dfd72d83":"code","eb7a6dcf":"code","7c7f64f8":"code","32a6b15c":"code","42ec120b":"code","1ad33f7e":"code","e2cd2da4":"code","fdd275ae":"code","4044e21a":"code","3f23bc81":"code","42d12529":"code","ec0f8aa9":"markdown","388a46f4":"markdown","24d1aca4":"markdown","e4cb7b6e":"markdown","f329c86f":"markdown","bca10854":"markdown","da7cf8f0":"markdown","87f442b8":"markdown","471e5a89":"markdown"},"source":{"efd556b7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# !pip install timm\nimport os\nimport cv2\nimport torch\nimport random\nfrom torch.utils.data import Dataset, DataLoader\n# import timm\nfrom torchvision import models","b7100928":"\n\ndef seed_everything(seed=2021):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()","85d88ac5":"data = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","632c3200":"data","3ead65e2":"test","1a09d746":"data.info()","135b4325":"#Sample Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg = mpimg.imread('..\/input\/petfinder-pawpularity-score\/train\/0007de18844b0dbbb5e1f607da0606e0.jpg')\nimgplot = plt.imshow(img)\nplt.show()","e60e65ab":"import torchvision.transforms as transforms\ntransform_train = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.Resize((224 ,224)),\n     transforms.ToTensor(),\n     transforms.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n\n     transforms.ColorJitter(contrast=0.8, saturation=0.5),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n)\n    ])\n\ntransform_valid = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.Resize((224, 224)),\n     transforms.ToTensor(),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","dfd72d83":"import torch.nn.functional as F\nimport torch.nn as nn\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nimport timm \nimport torch.optim as optim\n\n\n\nclass Pet_Model(nn.Module):\n    def __init__(self):\n        super(Pet_Model, self).__init__()\n        self.eff = timm.create_model('twins_pcpvt_base', pretrained=False, in_chans=3)\n        self.rlogit = nn.Linear(1000,128)\n      \n        self.fc1 = nn.Linear(140,64)\n        self.fc2 = nn.Linear(64,1)\n    \n        \n\n   \n    def forward(self, image, dense):\n        x = image\n        x = self.eff(x)  \n\n        \n        x = self.rlogit(x)\n        x = torch.cat([x, dense], dim=1)\n        x = F.relu(x)\n        x = self.fc1(x)\n#         x = F.relu(x)\n#         x = self.fc2(x)\n        score = self.fc2(x)\n        \n        return score\n    \nmodel = Pet_Model()\n\n# print(model)\nprint(timm.list_models())","eb7a6dcf":"class Petfinder_Data(torch.utils.data.Dataset):\n    def __init__(self, data, mode=None):\n        self.data = data\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image = cv2.imread('..\/input\/petfinder-pawpularity-score\/train\/'+row[0]+'.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.mode=='train':\n            image = transform_train(image)\n        else:\n            image = transform_valid(image)\n        \n        features = torch.tensor(np.array(row[1:13],dtype=np.float32))\n        label = torch.tensor(np.array(row[-1:],dtype=np.float32))\n        return image, features, label\n","7c7f64f8":"x = data.drop(columns=['Pawpularity'])\ny = data.drop(columns=['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])","32a6b15c":"from torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nimport gc\n# optim.\ntorch.cuda.empty_cache()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# optimizer = optim.SGD(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\noptimizer = optim.Adamax(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)\ncriterion = nn.MSELoss()\nmodel.to(device)\ne_=[]\nrmse_=[]\nvalid_rmse_=[]\nkfold = StratifiedKFold(n_splits=3)\nfor train_indicies, valid_indicies in kfold.split(X=x ,y=y):\n\n    train_x, valid_x = data.loc[train_indicies], data.loc[valid_indicies]\n    train = Petfinder_Data(train_x,mode='train')\n    valid = Petfinder_Data(valid_x,mode='valid')\n    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False, num_workers=0)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=64, shuffle=False, num_workers=0)\n    for epoch in range(2):\n        running_loss = 0.0\n        it_num = 0.0\n        error = 0.0\n        dataset_size = 0\n        model.train()\n        for i, t in enumerate(train_loader, 0): \n            \n            image, features, label = t\n            features=Variable(features.cuda().to(torch.float32))\n            image=Variable(image.cuda().to(torch.float32))\n            label=Variable(label.cuda().to(torch.float32))\n        \n            batch_size = image.size(0)\n        \n            outputs = model(image, features)\n            outputs=outputs.to(torch.float32)\n        \n            loss = criterion(outputs, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        \n            lr = optimizer.param_groups[0]['lr']\n            running_loss += loss.item()\n            dataset_size += batch_size\n            \n            if i != 0:\n                if running_loss \/ dataset_size < e_[0] :\n                    if mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)< rmse_[0]:\n                        e_.clear()\n                        e_.append(running_loss \/ dataset_size)\n                        rmse_.clear()\n                        rmse_.append(mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False))\n                        print('Epoch:',epoch,'loss: %.3f RMSE: %.3f'%(running_loss \/ dataset_size,mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)))\n            else:\n                rmse_.append(mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False))\n                e_.append(running_loss \/ dataset_size)\n                print('Epoch:',epoch,'loss: %.3f RMSE: %.3f'%(running_loss \/ dataset_size,mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)))\n            running_loss = 0.0\n\n        \n        scheduler.step()\n        model.eval()\n        with torch.no_grad():\n            for i, v in enumerate(valid_loader, 0):\n                image, features, label = v\n                features=Variable(features.cuda().to(torch.float32))\n                image=Variable(image.cuda().to(torch.float32))\n                label=Variable(label.cuda().to(torch.float32))\n    \n                outputs = model(image, features)\n                outputs=outputs.to(torch.float32)\n                error = mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)\n                it_num = i\n                \n                if i!=0:\n                    if error < valid_rmse_[0]:\n                        valid_rmse_.clear()\n                        valid_rmse_.append(error)\n                        print('valid_RMSE:', error )\n                else:\n                    valid_rmse_.append(error)\n                    print('valid_RMSE:', error )\n                        \ntorch.save(model.state_dict(), f'.\/pet_model.pth')\ndel model\ngc.collect()\ntorch.cuda.empty_cache()","42ec120b":"model =  Pet_Model()\nmodel.load_state_dict(torch.load('.\/pet_model.pth'))\n# model.eval()","1ad33f7e":"class Petfinder_Data(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image = cv2.imread('..\/input\/petfinder-pawpularity-score\/test\/'+row[0]+'.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = transform_valid(image)\n        features = torch.tensor(np.array(row[1:13],dtype=np.float32))\n        return image, features\ntest_df = test.copy()\ntest=Petfinder_Data(test)\ntest_loader = torch.utils.data.DataLoader(test)\nop=[]\nmodel.to(device)\nop.clear()\nfor i, t in enumerate(test_loader, 0): \n            \n        image, features = t\n        features=Variable(features.cuda().to(torch.float32))\n        image=Variable(image.cuda().to(torch.float32))\n\n        \n        outputs = model(image, features)\n        outputs=outputs.to(torch.float32)\n        \n        op.append(outputs.tolist())\n        ","e2cd2da4":"predictions = np.squeeze(op)","fdd275ae":"test_df['Pawpularity'] = predictions","4044e21a":"test_df = test_df.drop(columns=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])","3f23bc81":"test_df","42d12529":"test_df.to_csv('submission.csv', index=False)","ec0f8aa9":"## Data Generator","388a46f4":"## Model","24d1aca4":"## Flow:\n1) Loading data \n\n2) Pre-processing data\n\n3) Modelling\n\n4) Training\n\n5) Postprocessing\n\n6) Predictions\n\n7) Submission","e4cb7b6e":"Visualizaing sample image","f329c86f":"## Post Processing \/ Predictions","bca10854":"## Preprocessing \/ training","da7cf8f0":"## Augmentation","87f442b8":"## Performance","471e5a89":"# PetFinder.my - Pawpularity Contest- A perfect starter \ud83e\udd20\n[Amit Nikhade](http:\/\/amitnikhade.com)"}}