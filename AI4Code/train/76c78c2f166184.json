{"cell_type":{"6502909a":"code","f1f414cc":"code","ac9ff69f":"code","9407a632":"code","06b92cb4":"code","40352dab":"code","a37675ed":"code","23bd7a64":"code","e5097969":"code","565ac3da":"code","f124ef9f":"code","aa09b5e0":"code","5177b029":"code","eefd3279":"code","485d0c94":"markdown","f75b1591":"markdown","1d784d6b":"markdown","04ddec71":"markdown","a05d7384":"markdown","c8c2dc5d":"markdown","dee61540":"markdown","4694f8f7":"markdown","287a07b0":"markdown","596881cb":"markdown","ebf8cf6f":"markdown","6f1d826d":"markdown","379aa608":"markdown","99000f48":"markdown","9e6e068c":"markdown","625cb964":"markdown","0e43ffca":"markdown","d02eb279":"markdown","d8a77eef":"markdown","adf7ce16":"markdown","23cf2137":"markdown","3fd00ee4":"markdown","fc6816c6":"markdown","8240227c":"markdown","a65e0259":"markdown"},"source":{"6502909a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.datasets import mnist\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Flatten,Reshape\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras import backend as K","f1f414cc":"(train_data, _), (test_data, _) = mnist.load_data()","ac9ff69f":"# How it looks like\nplt.imshow(train_data[225])","9407a632":"rows,columns = 28, 28\nif K.image_data_format() == 'channels_first':\n    train_data = train_data.reshape(train_data.shape[0], 1, rows, columns)\n    test_data = test_data.reshape(test_data.shape[0], 1, rows, columns)\n    input_shape = (1, rows, columns)\nelse:\n    train_data = train_data.reshape(train_data.shape[0], rows, columns, 1)\n    test_data = test_data.reshape(test_data.shape[0], rows, columns, 1)\n    input_shape = (rows, columns, 1)\n\ntrain_data = train_data.astype(\"float32\") \/ 255\ntest_data = test_data.astype(\"float32\") \/ 255","06b92cb4":"class DigitReg:\n    \n    def create_instance(self,input_shape):\n        # Encoding\n        encoder_input = keras.Input(shape=input_shape, name=\"original_img\")\n        layer = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n        layer = layers.Conv2D(32, 3, activation=\"relu\")(layer)\n        layer = layers.MaxPooling2D(3)(layer)\n        layer = layers.Conv2D(32, 3, activation=\"relu\")(layer)\n        layer = layers.Conv2D(16, 3, activation=\"relu\")(layer)\n        encoder_output = layers.GlobalMaxPooling2D()(layer)\n\n        encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n        encoder.summary()\n        # Decoding\n        decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n        layer = layers.Reshape((4, 4, 1))(decoder_input)\n        layer = layers.Conv2DTranspose(16, 3, activation=\"relu\")(layer)\n        layer = layers.Conv2DTranspose(32, 3, activation=\"relu\")(layer)\n        layer= layers.UpSampling2D(3)(layer)\n        layer = layers.Conv2DTranspose(16, 3, activation=\"relu\")(layer)\n        decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(layer)\n\n        decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n        decoder.summary()\n\n        # AutoEncoding\n        autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n        encoded_img = encoder(autoencoder_input)\n        decoded_img = decoder(encoded_img)\n        autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n        autoencoder.summary()\n        \n        return encoder,decoder,autoencoder\n    \n    def plot_shape(self,encoder,decoder):\n        \n        keras.utils.plot_model(encoder, \"encoder.png\",show_shapes=True)\n        plt.show()\n        keras.utils.plot_model(decoder, \"decoder.png\",show_shapes=True)\n        plt.show()\n        \n        \n    def train(self,model,train_data,batch_sizes=64, epoch=5):\n        print('---------# IMAGE SHAPE #-------------------')\n        print('Train shape:', train_data.shape)\n        print(train_data.shape[0], 'Train samples')\n        \n        model.compile(\n                  optimizer=keras.optimizers.RMSprop(),\n                  loss='mean_squared_error',)\n\n\n        autoencoder.fit(train_data, train_data, batch_size=batch_sizes, epochs=epoch, validation_split=0.2)\n        return autoencoder\n\n    def loss(self,model):\n        \n        loss = pd.DataFrame(autoencoder.history.history)\n        loss.plot()\n        \n    def prediction(self,encoder,decoder,autoencoder,img):\n        \n        encode_imgs = encoder.predict(img)\n        decode_imgs = autoencoder.predict(img)\n        self.plot_test_data(10,test_data,encode_imgs,decode_imgs)\n        \n\n    \n    def plot_test_data(self,number_of_img,test_data,encode,decode):\n        print('---------# IMAGE SHAPE #-------------------')\n        print('Test shape:', test_data.shape)\n        print(test_data.shape[0], 'Test samples')\n        plt.figure(figsize=(20, 4))\n        for i in range(number_of_img):\n            # Original Image\n            ax = plt.subplot(3, number_of_img, i + 1)\n            plt.imshow(test_data[i].reshape(28, 28))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n            # Encoded Images\n            ax = plt.subplot(3, number_of_img, i + 1 + number_of_img)\n            plt.imshow(encode[i].reshape(4, 4))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n            # Decoded Image\n            ax = plt.subplot(3, number_of_img, i + 1 + 2*number_of_img)\n            plt.imshow(decode[i].reshape(28, 28))\n            plt.gray()\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)\n\n        plt.show()\n\n    ","40352dab":"find_number = DigitReg()\nhelp(find_number)","a37675ed":"input_shape = (28,28,1)","23bd7a64":"encoder,decoder,autoencoder = find_number.create_instance(input_shape)","e5097969":"find_number.plot_shape(encoder,decoder)\nkeras.utils.plot_model(encoder, \"encoder.png\",show_shapes=True)","565ac3da":"keras.utils.plot_model(decoder, \"decoder.png\",show_shapes=True)","f124ef9f":"keras.utils.plot_model(autoencoder, \"auto_encoder.png\",show_shapes=True)","aa09b5e0":"autoencoder = find_number.train(autoencoder,train_data,batch_sizes=64, epoch=5)","5177b029":"find_number.loss(autoencoder)","eefd3279":"find_number.prediction(encoder,decoder,autoencoder,test_data)","485d0c94":"## <font color=orange>Creat Class Instance","f75b1591":"###  <font color=orange>Adjust Data Format","1d784d6b":"###  <font color=orange>Visualization image, encoded and decoded versions\n> 1. number_of_img : how many image to plot\n> 2. encode : encoded verision of image\n> 3. decode : decoded verision of image\nthis function return all images as subplot","04ddec71":"# <font color=orange>Train","a05d7384":"\n# <font color=orange> AutoEncoder with Keras's Functional API\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/blog.keras.io\/img\/ae\/autoencoder_schema.jpg\" alt=\"Heat beating\" style=\"height:500px;margin-top:3rem;\"> <\/div>\n","c8c2dc5d":"#  <font color=orange> Libraries\ud83d\udcda","dee61540":"# <font color=orange>Approach\n<div style=\"color:black;\n           display:fill;\n           border-radius:1px;\n           background-color:#b5e48c;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:1px\">\n\n<p style=\"padding: 10px;\n              color:white;\"> or this aim, we will be using Keras (with TensorFlow as our backend) as the main package to create a simple neural network to predict, as accurately as we can, digits from handwritten images. In particular, we will be calling the Functional Model API of Keras..<\/p>\n\n<p style=\"padding: 1px;\n              color:white;\">Also, we will be experimenting with various optimizers: the plain vanilla Stochastic Gradient Descent optimizer and the Adam optimizer. However, there are many other parameters, such as training epochs which will we will not be experimenting with.<\/p>\n<p style=\"padding: 1px;\n              color:white;\">\nIn addition, the choice of hidden layer units are completely arbitrary and may not be optimal. This is yet another parameter which we will not attempt to tinker with. Lastly, we introduce dropout, a form of regularisation, in our neural networks to prevent overfitting.<\/p>","4694f8f7":"#  <font color=orange> Load Data","287a07b0":" # <font color=orange> Autoencoder Components:","596881cb":"###  <font color=orange>Single Image","ebf8cf6f":"###### resource https:\/\/towardsdatascience.com\/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726","6f1d826d":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/www.oreilly.com\/library\/view\/mastering-predictive-analytics\/9781789617740\/assets\/29266a1b-4e37-493c-b841-555f004034c3.png\" alt=\"Heat beating\" style=\"height:700px;margin-top:3rem;\"> <\/div>\n","379aa608":"###  <font color=orange>Decoder model as a graph","99000f48":"###  <font color=orange>AutoEncoder model as a graph","9e6e068c":"<div style=\"color:black;\n           display:fill;\n           border-radius:1px;\n           background-color:#b5e48c;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:1px\">\n\n<p style=\"padding: 10px;\n              color:white;\"> MNIST stands for Mixed National Institute of Standards and Technology, which has produced a handwritten digits dataset. This is one of the most researched datasets in machine learning, and is used to classify handwritten digits. This dataset is helpful for predictive analytics because of its sheer size, allowing deep learning to work its magic efficiently. This dataset contains 60,000 training images and 10,000 testing images, formatted as 28 x 28 pixel monochrome images. The following screenshot shows the images contained in this dataset:<\/p>","625cb964":"<div style=\"color:black;\n           display:fill;\n           border-radius:1px;\n           background-color:#bde0fe;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:1px\">\n\n<p style=\"padding: 10px;\n              color:white;\"> Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.\n    Autoencoder, by design, reduces data dimensions by learning how to ignore the noise in the data.<\/p>","0e43ffca":"### <font color=orange>Functional API","d02eb279":"###  <font color=orange>Thanks for reading. I hope you enjoyed\ud83d\ude0a\n> <img src=\"https:\/\/i.pinimg.com\/originals\/f8\/89\/1e\/f8891ef65e086abc67e5b448acb8bc12.gif\">","d8a77eef":"<div style=\"color:white;\n           display:fill;\n           border-radius:0px;\n           background-color:#bde0fe;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 3px;\n              color:white;\"> \nThe Keras functional API is a way to create models that are more flexible than the Sequential API. The functional API can handle models with non-linear topology shared layers, and even multiple inputs or outputs. The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.<\/p>","adf7ce16":"###  <font color=orange>Encoder model as a graph","23cf2137":"\n#### Autoencoders consists of 4 main parts:\n* 1\ufe0f\u20e3- Encoder: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n\n* 2\ufe0f\u20e3- Bottleneck: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.\n\n* 3\ufe0f\u20e3- Decoder: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n\n* 4\ufe0f\u20e3- Reconstruction Loss: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.\n\nThe training then involves using back propagation in order to minimize the network\u2019s reconstruction loss.\nYou must be wondering why would I train a neural network just to output an image or data that is exactly the same as the input! This article will cover the most common use cases for Autoencoder. Let\u2019s get started:\nAutoencoder Architecture:\nThe network architecture for autoencoders can vary between a simple FeedForward network, LSTM network or Convolutional Neural Network depending on the use case. We will explore some of those architectures in the new next few lines.","3fd00ee4":"#  <font color=orange>AutoEncoder\n\nOur model will take a digit as input and try to predict that digit.","fc6816c6":"# <font color=orange>Introduction to the MNIST dataset\n>  0\ufe0f\u20e3   1\ufe0f\u20e3   2\ufe0f\u20e3   3\ufe0f\u20e3   4\ufe0f\u20e3   5\ufe0f\u20e3   6\ufe0f\u20e3   7\ufe0f\u20e3   8\ufe0f\u20e3   9\ufe0f\u20e3 \n","8240227c":"<div style=\"color:black;\n           display:fill;\n           border-radius:1px;\n           background-color:#b5e48c;\n           font-size:200%;\n           font-family:Arial;\n           letter-spacing:1px\">\n\n<p style=\"padding: 10px;\n              color:white;\"> AutoEncoder It is an unsupervised Neural Network type used to reconstruct multidimensional data first from multidimensional data and then from reduced space. Autoencoders  are a family of neural networks for which the input is the same as the output. They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation. In this research, we are going to build the AutoEncoder model with keras's functional api.\n<\/p>\n","a65e0259":"In this case, we don't need output data due to the our research is unsupervised learning."}}