{"cell_type":{"ef176513":"code","63ab5def":"code","294a56f6":"code","6ac7b612":"code","e2215c01":"code","af52115d":"code","62955ebc":"code","f8cf4c38":"code","09e87ff4":"code","24f84c69":"markdown","7ae86e53":"markdown","3eab781a":"markdown","cb6db617":"markdown","18c79c9e":"markdown","4374a1f7":"markdown","2c899484":"markdown","a255da50":"markdown","6f50fad3":"markdown","96d1d2be":"markdown"},"source":{"ef176513":"import tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as implt\nimport os","63ab5def":"train_dir = \"\/kaggle\/input\/rock-paper-scissor\/rps\/rps\"\ntest_dir = \"\/kaggle\/input\/rock-paper-scissor\/rps-test-set\/rps-test-set\"\n\ntrain_rock = os.listdir(train_dir + \"\/rock\")\ntrain_paper = os.listdir(train_dir + \"\/paper\")\ntrain_scissors = os.listdir(train_dir + \"\/scissors\")\n\ntest_rock = os.listdir(test_dir + \"\/rock\")\ntest_paper = os.listdir(test_dir + \"\/paper\")\ntest_scissors = os.listdir(test_dir + \"\/scissors\")","294a56f6":"print(\"Number of images in the train-set:\", len(train_rock) + len(train_paper) + len(train_scissors))\nprint(\"Number of images in the test-set:\", len(test_rock) + len(test_paper) + len(test_scissors))\n\nprint(\"\\nNumber of rocks in the train-set:\", len(train_rock))\nprint(\"Number of papers in the train-set:\", len(train_paper))\nprint(\"Number of scissors in the train-set:\", len(train_scissors))\n\nprint(\"\\nNumber of rocks in the test-set:\", len(test_rock))\nprint(\"Number of papers in the test-set:\", len(test_paper))\nprint(\"Number of scissors in the test-set:\", len(test_scissors))","6ac7b612":"import random\n\nfig, ax = plt.subplots(3,4, figsize=(12, 8))\nfor i in range(4):\n    x = random.randint(0, len(train_rock))\n    #Rock\n    ax[0, i].imshow(implt.imread(train_dir + '\/rock\/' + train_rock[x]))\n    ax[0, 0].set_ylabel('rock')\n    #Paper\n    ax[1, i].imshow(implt.imread(train_dir + '\/paper\/' + train_paper[x]))\n    ax[1, 0].set_ylabel('paper')\n    #Scissors\n    ax[2, i].imshow(implt.imread(train_dir + '\/scissors\/' + train_scissors[x]))\n    ax[2, 0].set_ylabel('scissors')","e2215c01":"fig, ax = plt.subplots(3,4, figsize=(12, 8))\nfor i in range(4):\n    x = random.randint(0, len(test_rock))\n    #Rock\n    ax[0, i].imshow(implt.imread(test_dir + '\/rock\/' + test_rock[x]))\n    ax[0, 0].set_ylabel('rock')\n    #Paper\n    ax[1, i].imshow(implt.imread(test_dir + '\/paper\/' + test_paper[x]))\n    ax[1, 0].set_ylabel('paper')\n    #Scissors\n    ax[2, i].imshow(implt.imread(test_dir + '\/scissors\/' + test_scissors[x]))\n    ax[2, 0].set_ylabel('scissors')","af52115d":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size = (150, 150),\n                                                    class_mode = 'categorical',\n                                                    batch_size = 126)\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                 target_size = (150, 150),\n                                                 class_mode = 'categorical',\n                                                 batch_size = 126)","62955ebc":"my_callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\nmy_callback_rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, factor=0.5, min_lr=0.00001, verbose=1)\n\nmodel = tf.keras.models.Sequential([\n    # Conv layer-1\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPool2D((2, 2)),\n    # Conv layer-2\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D((2, 2)),\n    # Conv layer-3\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D((2, 2)),\n    # Conv layer-4\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D((2, 2)),\n    # Flatten output from Conv-4 \n    tf.keras.layers.Flatten(),\n    # Dropout layer to prevent overfitting\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    # We have three class\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',              \n              optimizer='rmsprop',\n              metrics = ['accuracy'])","f8cf4c38":"history = model.fit(train_generator,\n                    validation_data=test_generator,\n                    epochs=25,\n                    steps_per_epoch= 20, #(2520 \/\/ 126), # train-set size = 2520, batch_size = 126\n                    validation_steps= 3, #(372 \/\/ 126), # train-set size = 372, batch_size = 126\n                    verbose = 1,\n                    callbacks=[my_callback_es, my_callback_rlr])","09e87ff4":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n#plt.ylim(bottom=0.8)\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","24f84c69":"## 1.2 Sample images in test-set","7ae86e53":"# 3. Build the Model","3eab781a":"## 1.1 Sample images in train-set","cb6db617":"# 1. Explore the dataset","18c79c9e":"# 6. Visualize accuracy scores","4374a1f7":"# 4. Train the model","2c899484":"# 5. About Callbacks\n\n## Got 100% validation accuracy during training and training stopped due to *[EarlyStopping](https:\/\/keras.io\/api\/callbacks\/early_stopping\/)* callback. (If there are no improvement in validation-accuracy for five epochs, training stops.)\n\n## Also learning rate dropped by half two times because of *[ReduceLROnPlateau](https:\/\/keras.io\/api\/callbacks\/reduce_lr_on_plateau\/)* callback. (If there is no improvement in validation-accuracy for two epochs, learning rate halves.)","a255da50":"<center>\n<img src=\"https:\/\/camo.githubusercontent.com\/200d24b84fb905e680fa1ebaa71af582e3d6e24e\/68747470733a2f2f64327776666f7163396779717a662e636c6f756466726f6e742e6e65742f636f6e74656e742f75706c6f6164732f323031392f30362f576562736974652d5446534465736b746f7042616e6e65722e706e67\" width=800><br><\/center>\n\n\n## I decided to create this notebook while working on [Tensorflow in Practice Specialization](https:\/\/www.coursera.org\/specializations\/tensorflow-in-practice) on Coursera. I highly recommend this course, especially for beginners. Most of the ideas here belong to this course.","6f50fad3":"# 2. Image augmentation with ImageDataGenerator\n## Train and Test generators ","96d1d2be":"# Import necessary libraries"}}