{"cell_type":{"c84d9f67":"code","34f90d74":"code","e5c0248d":"code","8b344d2d":"code","8a9367a8":"code","a73f7ed0":"code","ec9bc4b5":"code","751f71b2":"code","026f7243":"code","33c2b169":"code","bcc56f57":"code","4520e30b":"code","3ea3d171":"code","366450cb":"code","f9e7918a":"code","3c835178":"code","e1fbcfd5":"code","bfe31a35":"code","27326996":"code","a74f688a":"code","57e6aa18":"code","a83aa3f2":"code","66970ac1":"code","3dd0c350":"code","49a96d9c":"code","2e0ef2a3":"code","b3a294d1":"code","9486a90c":"code","8eb54d3d":"code","65dadff1":"code","ddb2f124":"code","ae9d26b9":"code","5c271b6d":"code","420f7814":"code","16c960d9":"code","7785edfc":"code","d73863af":"code","1838df93":"code","f80e74b6":"code","387b74e6":"markdown","e2e95fa7":"markdown","5782f059":"markdown","1bd428dc":"markdown","3a7749f3":"markdown","598d259c":"markdown","4793fa33":"markdown","3df5f46b":"markdown","459665ae":"markdown","d1f78b26":"markdown","df0feb8e":"markdown","7889f309":"markdown","e288631e":"markdown","c5ddcbef":"markdown"},"source":{"c84d9f67":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","34f90d74":"df_train = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')","e5c0248d":"df_train.head()","8b344d2d":"df_train.describe()","8a9367a8":"df_train.info()","a73f7ed0":"df_test.info()","ec9bc4b5":"df_train.nunique()","751f71b2":"# Drop the identity column\ndf_train = df_train.drop(['id'], axis = 1)","026f7243":"df_test.nunique()","33c2b169":"target = ['target']\nvar_categorical = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9' ]\nvar_numerical = list(set(df_train.columns) - set(var_categorical) - set(target))","bcc56f57":"# Function to label the count on top of each bar in graph\ndef label_values(ax, spacing=5):\n    total = 0\n    for rect in ax.patches:\n        total += rect.get_height()\n\n    for rect in ax.patches:\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n\n        space = spacing\n        \n        va = 'bottom'\n        \n        if y_value < 0:\n            space *= -1\n            va = 'top'\n        label = \"{:.2f}, {:.2f}\".format(y_value, y_value\/total*100)\n        ax.annotate(\n            label,                      \n            (x_value, y_value),         \n            xytext=(0, space),          \n            textcoords=\"offset points\", \n            ha='center',                \n            va=va)","4520e30b":"sns.boxplot(x = df_train[\"target\"])\nplt.show()","3ea3d171":"for column in var_categorical:\n    plt.figure(figsize=(15, 6))\n    print(column.title())\n    ax = sns.countplot(x = df_train[column])\n    label_values(ax)\n    plt.show()","366450cb":"for column in var_categorical:\n    plt.figure(figsize=(15, 6))\n    print(column.title())\n    ax = sns.boxplot(x = df_train[column], y = df_train['target'])\n    label_values(ax)\n    plt.show()","f9e7918a":"i = 1\nfor column in var_numerical:\n    print(column.title())\n    plt.subplots(figsize=(16, 50))\n    plt.subplot(len(var_numerical) + 1, 3, i)\n    sns.boxplot(y = df_train[column])\n    i += 1\n    plt.subplot(len(var_numerical) + 1, 3, i)\n    sns.distplot(x = df_train[column])\n    i += 1\n    plt.subplot(len(var_numerical) + 1, 3, i)\n    sns.scatterplot(y = df_train[\"target\"], x = df_train[column])\n    i += 1\n    plt.show()","3c835178":"plt.figure(figsize=(15, 15))\nsns.heatmap(df_train.corr(), annot=True)\nplt.show()","e1fbcfd5":"from sklearn.preprocessing import OrdinalEncoder","bfe31a35":"# df_train = pd.get_dummies(df_train, columns=var_categorical, drop_first=True)\nordinal_encoder = OrdinalEncoder()\ndf_train[var_categorical] = ordinal_encoder.fit_transform(df_train[var_categorical])\ndf_test[var_categorical] = ordinal_encoder.transform(df_test[var_categorical])","27326996":"y_train = df_train.pop('target')\nX_train = df_train","a74f688a":"X_train.duplicated().sum()","57e6aa18":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, KFold","a83aa3f2":"# Train model using hyperparmeter tuning\ndef training_model_hyperparameter(model, scoring, params_grid, X_train, y_train):\n    folds = KFold(n_splits = 5, shuffle = True, random_state=100)\n\n    grid = GridSearchCV(estimator = model, scoring=scoring, param_grid = params_grid, cv = folds, \n                           verbose=0, return_train_score=True, n_jobs=-1)\n    grid.fit(X_train, y_train)\n    return grid","66970ac1":"lr = LinearRegression()\nlr.fit(X_train, y_train)","3dd0c350":"y_pred_train_lr = lr.predict(X_train)\n\nmse_train_lr = mean_squared_error(y_train, y_pred_train_lr)\nprint(\"Mean Squared Train Error: \", mse_train_lr)\nprint(\"Root Mean Squared Train Error: \", mse_train_lr**0.5)","49a96d9c":"# Initialisation of ridge linear regression model\nridge_lr = Ridge(random_state = 100)","2e0ef2a3":"# Create the param grid for logistic regression\nparam_ridge = {\n    'alpha': [0.0001, 0.0002, 0.0004, 0.0008, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]\n}\nprint(param_ridge)","b3a294d1":"ridge_grid = training_model_hyperparameter(ridge_lr, 'neg_mean_squared_error', param_ridge, X_train, y_train)","9486a90c":"ridge_grid.best_params_","8eb54d3d":"y_pred_train_ridge = ridge_grid.predict(X_train)\n\nmse_train_ridge = mean_squared_error(y_train, y_pred_train_ridge)\nprint(\"Mean Squared Train Error: \", mse_train_ridge)\nprint(\"Root Mean Squared Train Error: \", mse_train_ridge**0.5)","65dadff1":"# Initialise the lasso model\nlasso_lr = Lasso(random_state = 100)","ddb2f124":"# Create the param grid for logistic regression\nparam_lasso = {\n    'alpha': [0.0001, 0.0002, 0.0004, 0.0008, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]\n}\nprint(param_lasso)","ae9d26b9":"lasso_grid = training_model_hyperparameter(lasso_lr, 'neg_mean_squared_error', param_lasso, X_train, y_train)","5c271b6d":"lasso_grid.best_params_","420f7814":"y_pred_train_lasso = lasso_grid.predict(X_train)\n\nmse_train_lasso = mean_squared_error(y_train, y_pred_train_lasso)\nprint(\"Mean Squared Train Error: \", mse_train_lasso)\nprint(\"Root Mean Squared Train Error: \", mse_train_lasso**0.5)","16c960d9":"submission = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/sample_submission.csv')\nsubmission.head()","7785edfc":"id_ = df_test['id']\ndf_test = df_test.drop(['id'], axis = 1)","d73863af":"final_submission_lr = pd.DataFrame(\n    {'id': id_, \n    'target': lr.predict(df_test)})\nfinal_submission_lr.to_csv('submission_file_lr.csv', index=False)\nfinal_submission_lr.head()","1838df93":"final_submission_ridge = pd.DataFrame(\n    {'id': id_, \n    'target': ridge_grid.predict(df_test)})\nfinal_submission_ridge.to_csv('submission_file_ridge.csv', index=False)","f80e74b6":"final_submission_lasso = pd.DataFrame(\n    {'id': id_, \n    'target': lasso_grid.predict(df_test)})\nfinal_submission_lasso.to_csv('submission_file_lasso.csv', index=False)","387b74e6":"We have to predict a continuous target based on a number of feature columns given in the data. <br>\nAll of the feature columns, **cat0 - cat9** are **categorical**, and the feature columns **cont0 - cont13** are **continuous**.","e2e95fa7":"# Exploratory Data Analysis","5782f059":"# Ordinal encoding on categorical variables","1bd428dc":"# **30 DAYS ML CHALLENGE**","3a7749f3":"# Model Building","598d259c":"## Files\n**train.csv** - the training data with the target column <br>\n**test.csv** - the test set; you will be predicting the target for each row in this file <br>\n**sample_submission.csv** - a sample submission file in the correct format <br>","4793fa33":"# Scaling the numerical variables","3df5f46b":"We don't need to do the scaling on numerical variables as the values are already scaled.","459665ae":"# Predictions","d1f78b26":"# Divide the train data into X and y","df0feb8e":"## Data Description","7889f309":"# 3. Lasso Regression","e288631e":"# 2. Ridge Regression","c5ddcbef":"# 1.  Linear Regression"}}