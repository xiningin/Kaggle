{"cell_type":{"267ffacd":"code","2b95e32b":"code","1dd59f81":"code","47682723":"code","2e5fb879":"code","4cf30dfe":"code","c29a5443":"code","ff1c5afc":"code","8a3b9324":"code","cf651dd4":"code","3dc8f70e":"code","b5ea9ee6":"code","f93f45e4":"code","81dccf62":"code","9a0999bf":"code","8343d662":"code","05b5c6e8":"code","7c432bcf":"code","5652d68d":"code","b2452553":"code","876f1efe":"code","bc797644":"code","7cb30fa7":"code","03dfa525":"code","e079a562":"code","53c4a603":"code","60e295ca":"code","1be9b791":"code","19e23879":"code","6ebb4a5c":"code","ddca4512":"code","25f638da":"code","776ac022":"code","63028090":"code","001a6828":"code","acffdd96":"code","327fb4bc":"markdown","5ae49638":"markdown","f743bc71":"markdown","5c92eea9":"markdown","26793544":"markdown","a19a4dfa":"markdown","bc63c798":"markdown","2553e0e1":"markdown","feedf687":"markdown","bbf23df3":"markdown","2876db75":"markdown","4613b11e":"markdown","d9fe9f6d":"markdown","b0228f11":"markdown","d6b8ee40":"markdown","9aa0b3a0":"markdown","54dc6811":"markdown","5b3ef717":"markdown","7258989c":"markdown","eea6936f":"markdown","07462ac4":"markdown"},"source":{"267ffacd":"import warnings\nwarnings.filterwarnings('ignore')","2b95e32b":"import pandas as pd\nimport numpy as np\nfrom pandas_profiling import ProfileReport\nfrom imblearn.over_sampling import SMOTE,SMOTENC,SVMSMOTE\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score,make_scorer\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom datetime import date\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt","1dd59f81":"df_train = pd.read_csv('..\/input\/hackerearth-ml-challenge-pet-adoption\/train.csv')\ndf_test = pd.read_csv('..\/input\/hackerearth-ml-challenge-pet-adoption\/test.csv')\ndf_train.head()","47682723":"profile = ProfileReport(df_train,title='Detailed Customer Report')\nprofile.to_widgets()","2e5fb879":"def evaluate():\n    # f1 score\n    s1 = f1_score(y_test,y_pred_breed,average='weighted')\n    s2 = f1_score(y_test,y_pred_pet,average='weighted')\n    score = 100*((s1+s2)\/2)\n    return score\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndef generate_model_report(y_actual, y_predicted):\n    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n    print(\"Precision = \" ,precision_score(y_actual, y_predicted,average='weighted'))\n    print(\"Recall = \" ,recall_score(y_actual, y_predicted,average='weighted'))\n    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted,average='weighted'))\n    pass\n\ndef generate_auc_roc_curve(y_test, y_score,n_classes):\n   # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot of a ROC curve for a specific class\n    for i in range(n_classes):\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic example')\n    pass","4cf30dfe":"# 1) To clean the data and see which are the redundant or unnecessary cols\ndef del_col(col,data):\n    clean_data = data.drop(col, axis=1)\n    return clean_data\n\n# 2) Dropping the duplicates from the dataset.\ndef del_duplicates(data):\n    clean_data = data.drop_duplicates(keep='first')\n    return clean_data\n\n# 3) Imputing missing data\ndef impute_col(data,filler):\n    data.fillna(filler,inplace=True)\n    return data\n\n# 4) Typecasting Variables\ndef typecast_col(col,data,types):\n    clean_data = data.col.astype(types)\n    return clean_data\n  \n# 5) To Replace the spaces between the strings with '_' and also converting all strings to LowerCase\ndef convert_case(col,data,chars):\n    data = data.str.replace(' ',chars) \n    data = data.str.lower() \n    return data\n\n# 6) Encoding using Label Encoder or OHE which converts categorical features to numerical features\ndef label_encoder(data):\n    le = LabelEncoder()\n    data = le.fit_transform(data)\n    return data\n","c29a5443":"# Removing Unnecessary Columns\nX = del_col('pet_id',df_train)\n\n# Generating new feature \nX[['issue_date','listing_date']] = X[['issue_date','listing_date']].apply(pd.to_datetime) #if conversion required\nX['diff_days'] = (X['listing_date'] - X['issue_date']).dt.days\nX = del_col('issue_date',X)\nX = del_col('listing_date',X)\n\n# Imputing missing values with new category \nX['condition'] = impute_col(X['condition'],3.0)\nX['condition'] = X['condition'].astype('int')\n\n# Standardization - converting cm to mts\n# X['height(cm)'] = X['height(cm)']*0.01\nX['length(cm)'] = X['length(m)'].apply(lambda x: x*100)\nX = del_col('length(m)',X)\n# replace all 0 length with mean of lengths\nval = X['length(cm)'].mean()\nX['length(cm)'] = X['length(cm)'].replace(to_replace=0, value=val)\n","ff1c5afc":"quantile_list = [0, .25, .5, .75, 1.]\nquantiles = X['length(cm)'].quantile(quantile_list)\nquantiles","8a3b9324":"quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\nX['length_label'] = pd.qcut(X['length(cm)'],q=quantile_list, labels=quantile_labels)\nX.head()","cf651dd4":"X['diff_days'] = abs(X['diff_days'])\nX['diff_days'] =np.array(np.array(X['diff_days']) \/ 365.)","3dc8f70e":"# Encoding category using One Hot Encoding\nX = pd.concat([X,pd.get_dummies(X['condition'], prefix='condition')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['X2'], prefix='X2')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['X1'], prefix='X1')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['color_type'], prefix='color_type')],axis=1)\nX = pd.concat([X,pd.get_dummies(X['length_label'], prefix='length_label')],axis=1)\n\nX = del_col('condition',X)\nX = del_col('color_type',X)\nX = del_col('X2',X)\nX = del_col('X1',X)\nX = del_col('length(cm)',X)\nX = del_col('length_label',X)\n","b5ea9ee6":"X['breed_category'] = X['breed_category'].astype('int')\nX['pet_category'] = X['pet_category'].astype('int')\nX.head()","f93f45e4":"Y1 = X['breed_category']\nY2 = X['pet_category']\n\n#Splitting up for MultiLabel Classification\nX1 = X.drop(['pet_category','breed_category'], axis=1)\nX2 = X.drop(['pet_category','breed_category'], axis=1)","81dccf62":"X1.head()","9a0999bf":"X2.head()","8343d662":"smote = SMOTE('auto',random_state=42)\nX_train1_smote,y_train1_smote = smote.fit_resample(X1,Y1)","05b5c6e8":"smote1 = SMOTE('auto',random_state=42)\nX_train2_smote,y_train2_smote = smote1.fit_resample(X2,Y2)","7c432bcf":"from collections import Counter\nprint(\"Before SMOTE :\", Counter(Y1))\nprint(\"Before SMOTE :\", Counter(y_train1_smote))","5652d68d":"from collections import Counter\nprint(\"Before SMOTE :\", Counter(Y2))\nprint(\"Before SMOTE :\", Counter(y_train2_smote))","b2452553":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\ncategorical_features_indices=[0]\nrf1_2 = CatBoostClassifier(learning_rate=0.055, \n                          n_estimators=1000, \n                          subsample=0.075, \n                          max_depth=3, \n                          verbose=100,\n                          l2_leaf_reg = 7,\n                          bootstrap_type=\"Bernoulli\",\n                          class_weights=[1, 1, 1],\n                          loss_function='MultiClass')\n#                           eval_metric='F1')\n\nkf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\nf1 = []\n\nfor fold,(t_id,v_id) in enumerate(kf.split(X_train1_smote,y_train1_smote)):\n    tx = X_train1_smote.iloc[t_id]; ty = y_train1_smote.iloc[t_id]\n    vx = X_train1_smote.iloc[v_id]; vy = y_train1_smote.iloc[v_id]\n    rf1_2.fit(tx,ty)        \n    val_y = rf1_2.predict(vx)\n    \n    F1_score = f1_score(vy, val_y,average='weighted')\n    f1.append(F1_score)\n    print(f\"fold {fold} f1 {F1_score}\")\n    print(confusion_matrix(val_y, vy))\n\nprint(f\"Mean f1 score {np.mean(f1)}\")","876f1efe":"categorical_features_indices=[0]\nfrom catboost import CatBoostClassifier\nrf2_2 = CatBoostClassifier(learning_rate=0.035, \n                          n_estimators=1000, \n                          subsample=0.075, \n                          max_depth=4,\n                          l2_leaf_reg = 40,\n                          verbose=100,\n                          bootstrap_type=\"Bernoulli\",\n                          class_weights=[1, 1, 1, 1],\n                          loss_function='MultiClass')\n\nkf = StratifiedKFold(n_splits=7,shuffle=True,random_state=99)\nf1 = []\n\nfor fold,(t_id,v_id) in enumerate(kf.split(X_train2_smote,y_train2_smote)):\n    tx = X_train2_smote.iloc[t_id]; ty = y_train2_smote.iloc[t_id]\n    vx = X_train2_smote.iloc[v_id]; vy = y_train2_smote.iloc[v_id]\n    rf2_2.fit(tx,ty)\n           \n    val_y = rf2_2.predict(vx)\n    F1_score = f1_score(vy, val_y,average='weighted')\n    f1.append(F1_score)\n    print(f\"fold {fold} f1 {F1_score}\")\n    print(confusion_matrix(val_y, vy))\n\nprint(f\"Mean f1 score {np.mean(f1)}\")","bc797644":"df_test.head()","7cb30fa7":"df_test.info()","03dfa525":"test_profile = ProfileReport(df_test,title='Detailed Customer Report')\ntest_profile.to_widgets()","e079a562":"# Removing Unnecessary Columns\nZ = del_col('pet_id',df_test)\n\n\n# Imputation\nZ['condition'] = impute_col(Z['condition'],3.0)\nZ['condition'] = Z['condition'].astype('int')\n\n# Standardization - converting cm to mts\nZ['length(cm)'] = Z['length(m)'].apply(lambda x: x*100)\nZ = del_col('length(m)',Z)\nval = Z['length(cm)'].mean()\nZ['length(cm)'] = Z['length(cm)'].replace(to_replace=0, value=val)","53c4a603":"Z[['issue_date','listing_date']] = Z[['issue_date','listing_date']].apply(pd.to_datetime) #if conversion required\nZ['diff_days'] = (Z['listing_date'] - Z['issue_date']).dt.days\nZ = del_col('issue_date',Z)\nZ = del_col('listing_date',Z)","60e295ca":"# Diff days Standardization\nZ['diff_days'] = abs(Z['diff_days'])\nZ['diff_days'] =np.array(np.array(Z['diff_days']) \/ 365.)\n\n# Quantile Based Binning\nquantile_list = [0, .25, .5, .75, 1.]\nquantiles = Z['length(cm)'].quantile(quantile_list)\nquantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\nZ['length_label'] = pd.qcut(Z['length(cm)'],q=quantile_list, labels=quantile_labels)\n","1be9b791":"Z = pd.concat([Z,pd.get_dummies(Z['condition'], prefix='condition')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['X2'], prefix='X2')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['X1'], prefix='X1')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['color_type'], prefix='color_type')],axis=1)\nZ = pd.concat([Z,pd.get_dummies(Z['length_label'], prefix='length_label')],axis=1)\n\nZ = del_col('condition',Z)\nZ = del_col('color_type',Z)\nZ = del_col('X2',Z)\nZ = del_col('X1',Z)\nZ = del_col('length(cm)',Z)\nZ = del_col('length_label',Z)\n","19e23879":"Z.head()","6ebb4a5c":"# Adding Missing Columns from training Set\nZ['color_type_Black Tiger'] = 0\nZ['color_type_Brown Tiger'] = 0\nZ['X1_3'] = 0\nZ['X1_19'] = 0\nZ = Z[X1.columns]","ddca4512":"breed_category = rf1_2.predict(Z)\nbreed_category","25f638da":"pet_category = rf2_2.predict(Z)\npet_category","776ac022":"submission = pd.DataFrame(df_test['pet_id'],columns=['pet_id',])\nsubmission['breed_category'] = breed_category\nsubmission['pet_category'] = pet_category","63028090":"submission['breed_category'].value_counts()","001a6828":"submission['pet_category'].value_counts()","acffdd96":"submission.head(10)","327fb4bc":"## Data Overview","5ae49638":"## SMOTE Analysis for highly imbalaced class Balancing","f743bc71":"## Prediction on Test Data","5c92eea9":"### Model to predict Breed category","26793544":"A leading pet adoption agency is planning to create a virtual tour experience for \ntheir customers showcasing all animals that are available in their shelter. \nTo enable this tour experience, you are required to build a Machine Learning model that \ndetermines type and breed of the animal based on its physical attributes and other factors.","a19a4dfa":"## Problem Statement","bc63c798":"## Prediction","2553e0e1":"## Feature Engineering","feedf687":"### Model to predict Pet category","bbf23df3":"### Quantile Based Binning","2876db75":"## Evaluation","4613b11e":"### Custom Based Binning","d9fe9f6d":"## EDA","b0228f11":"## Loading Data","d6b8ee40":"## Importing Modules","9aa0b3a0":"## Train Test Split","54dc6811":"### Submission","5b3ef717":"# HackerEarth Machine Learning Challenge - Adopt a Pet Buddy \n## Best Score - 89.58 (Top 4%)","7258989c":"### One Hot Encoding","eea6936f":"### CatBoost Classifier used with different set of parameters separately ","07462ac4":"## Model"}}