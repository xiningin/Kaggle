{"cell_type":{"afeb3dfe":"code","c9642598":"code","a318c431":"code","74298e3d":"code","341dee74":"code","667ecaa2":"code","54915b08":"code","cac27311":"code","5e4a3278":"code","2efa9abd":"code","753eaf71":"code","26e4d6fb":"code","a0d38268":"code","eae44a38":"code","043f2014":"code","545494d3":"code","c804ce7c":"code","3a9435c2":"code","46655846":"code","bbf206d0":"code","531de72c":"code","c8b729de":"code","ccb4cda0":"code","2bd3fbc4":"code","3a39683a":"code","bf909744":"code","f6e13da3":"code","033f0447":"code","751f3176":"code","4aeb7f37":"code","ddcba6a4":"code","51a595ca":"code","a4935839":"code","3910e0c0":"markdown","65c74b86":"markdown","16b76a9a":"markdown","a4a7d96c":"markdown","e1d00c35":"markdown","de8de79c":"markdown","c8b47a08":"markdown","527c9bc2":"markdown","25cb9dd8":"markdown","023f4cd9":"markdown","b60e4b98":"markdown","06b31395":"markdown","9e79aceb":"markdown","eebd5a17":"markdown","c8cf6f76":"markdown","299aa35d":"markdown","00a01ff8":"markdown","a1b70ce2":"markdown","352326e6":"markdown","54f5da96":"markdown"},"source":{"afeb3dfe":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","c9642598":"# Import the numpy and pandas packages\n\nimport numpy as np\nimport pandas as pd","a318c431":"movies = pd.read_csv(\"..\/input\/MovieAssignmentData.csv\") \nmovies.head()","74298e3d":"# Code for inspection here\nprint(movies.columns)","341dee74":"#Printing the dimensions of the movies dataframe\nprint(movies.shape)","667ecaa2":"# Looking at the datatypes of each column\nprint(movies.info())","54915b08":"# Code for column-wise null count here\nmovies.isnull().sum(axis=0)","cac27311":"# Code for row-wise null count here\nmovies.isnull().sum(axis=1)","5e4a3278":"# Code for column-wise null percentages here\nprint(round(100*(movies.isnull().sum()\/len(movies.index)), 2))","2efa9abd":"# Code for dropping the columns here. It is advised to keep inspecting the dataframe after each set of operations \nmovies = movies.drop(['color','director_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes',\n                     'actor_2_name','cast_total_facebook_likes','actor_3_name','duration','facenumber_in_poster','content_rating',\n                     'country','movie_imdb_link','aspect_ratio','plot_keywords'], axis=1)\n\n#printing the datatype and dataframe information after dropping the unneccesary columns\nprint(movies.info())","753eaf71":"#printing the column-wise null percentage for the remaining columns in the dataset\nprint(round(100*(movies.isnull().sum()\/len(movies.index)), 2))","26e4d6fb":"# Write your code for dropping the rows for columns having more that 5% null values here\nmovies = movies[~(movies['gross'].isnull() | movies['budget'].isnull())]\n\n#printing the column-wise null percentage for the remaining columns in the dataset\nprint(round(100*(movies.isnull().sum()\/len(movies.index)), 2))","a0d38268":"#length of rows with more than 5 NaN values\nprint(len(movies[movies.isnull().sum(axis=1) > 5]))\n\n#length of rows with less or equal to 5 NaN values\nprint(len(movies[movies.isnull().sum(axis=1) <= 5]))\n\n# Code for dropping the rows here\nmovies = movies[movies.isnull().sum(axis=1) <= 5]\n\n#printing the column-wise null percentage for the remaining columns in the dataset\nprint(round(100*(movies.isnull().sum()\/len(movies.index)), 2))","eae44a38":"#converting language column as a category\nmovies['language'] = movies['language'].astype('category')\n\n#printing the value counts for the language column\nprint(movies['language'].value_counts())\n\n#imputing the NaN values by English - top language \nmovies.loc[movies['language'].isnull(), ['language']] = 'English'\n\n#printing the null percentage column-wise again\nprint(round(100*(movies.isnull().sum()\/len(movies.index)), 2))","043f2014":"# Code for checking number of retained rows here\nprint(len(movies.index))\n\n#Percentage of retained rows\nprint(100*(len(movies.index)\/5043))","545494d3":"# Code for unit conversion here\nmovies['gross'] = movies['gross']\/1000000\nmovies['budget'] = movies['budget']\/1000000\nmovies","c804ce7c":"#Code for creating the profit column here\nmovies['profit'] = movies['gross'] - movies['budget']\nmovies","3a9435c2":"# Code for sorting the dataframe here\nmovies.sort_values('profit',ascending = False)","46655846":"# Code to get the top 10 profiting movies here\ntop10 = movies.sort_values('profit',ascending = False).head(10) \ntop10","bbf206d0":"# Code for dropping duplicate values here\nmovies = movies[~movies.duplicated()]\nmovies","531de72c":"# Code for repeating subtask 2 here\ntop10 = movies.sort_values('profit',ascending = False).head(10)\ntop10","c8b729de":"# Code for extracting the top 250 movies as per the IMDb score here. Make sure that you store it in a new dataframe \n# and name that dataframe as 'IMDb_Top_250'\nIMDb_Top_250 = movies.sort_values(by = 'imdb_score', ascending = False)\nIMDb_Top_250 = IMDb_Top_250.loc[IMDb_Top_250.num_voted_users > 25000]\nIMDb_Top_250 = IMDb_Top_250.iloc[:250, ]\nIMDb_Top_250['Rank'] = range(1,251)\nIMDb_Top_250","ccb4cda0":"# Code to extract top foreign language films from 'IMDb_Top_250' here\nTop_Foreign_Lang_Film = IMDb_Top_250[IMDb_Top_250['language'] != 'English']\nTop_Foreign_Lang_Film","2bd3fbc4":"# Code for extracting the top 10 directors here\ntop10director = pd.DataFrame(movies.groupby('director_name').imdb_score.mean().sort_values(ascending = False).head(10))\ntop10director","3a39683a":"# Code for extracting the first two genres of each movie here\nmovies['genre_1'] = movies['genres'].apply(lambda x: x.split('|')[0])\nmovies['genre_2'] = movies['genres'].apply(lambda x: x.split('|')[0] if len(x.split('|'))<2 else x.split('|')[1])\nmovies","bf909744":"# Code for grouping the dataframe here\nmovies_by_segment = movies.groupby(['genre_1','genre_2'])","f6e13da3":"# Code for getting the 5 most popular combo of genres here\nPopGenre = pd.DataFrame(movies_by_segment.gross.mean().sort_values(ascending = False).head(5))\nPopGenre","033f0447":"# Code for creating three new dataframes here\n# Including all movies in which Meryl_Streep is the lead\nMeryl_Streep = movies.loc[movies['actor_1_name'] == 'Meryl Streep']\nMeryl_Streep","751f3176":"# Including all movies in which Leo_Caprio is the lead\nLeo_Caprio = movies.loc[movies['actor_1_name'] == 'Leonardo DiCaprio']\nLeo_Caprio","4aeb7f37":"# Including all movies in which Brad_Pitt is the lead\nBrad_Pitt = movies.loc[movies['actor_1_name'] == 'Brad Pitt']\nBrad_Pitt","ddcba6a4":"# Code for combining the three dataframes here\ncombined = Meryl_Streep.append(Leo_Caprio.append(Brad_Pitt))\ncombined","51a595ca":"# Code for grouping the combined dataframe here\ncombined = combined.groupby('actor_1_name')","a4935839":"# Code for finding the mean of critic reviews and audience reviews here\ncombined['num_critic_for_reviews','num_user_for_reviews'].mean().sort_values('num_critic_for_reviews',ascending = False)","3910e0c0":"**Note 1:** We still have around `77%` of the rows!","65c74b86":"-  ### Subtask 1.2: Inspect the dataframe\n\nInspect the dataframe's columns, shapes, variable types etc.","16b76a9a":"-  ### Subtask 2.2: Drop unecessary columns\n\nDropping the columns which are not required for the analysis.","a4a7d96c":"-  ### Subtask 3.7: Find the critic-favorite and audience-favorite actors\n\n    1. Create three new dataframes namely, `Meryl_Streep`, `Leo_Caprio`, and `Brad_Pitt` which contain the movies in which the actors: 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' are the lead actors. Use only the `actor_1_name` column for extraction. Also, make sure that you use the names 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' for the said extraction.\n    2. Append the rows of all these dataframes and store them in a new dataframe named `Combined`.\n    3. Group the combined dataframe using the `actor_1_name` column.\n    4. Find the mean of the `num_critic_for_reviews` and `num_user_for_review` and identify the actors which have the highest mean.","e1d00c35":"-  ### Subtask 2.4: Drop unecessary rows\n\nSome of the rows might have greater than five NaN values. Such rows aren't of much use for the analysis and hence, should be removed.","de8de79c":"## Task 3: Data Analysis\n\n-  ### Subtask 3.1: Change the unit of columns\n","c8b47a08":"**Note 4:** `Leonardo` has aced both the lists!","527c9bc2":"-  ### Subtask 2.5: Fill NaN values\n","25cb9dd8":"## Task 1: Reading and Inspection\n\n-  ### Subtask 1.1: Import and read","023f4cd9":" ## Objective : \nIn this assignment, you will try to find some interesting insights into a few movies released between 1916 and 2016, using Python. This is a compulsory individual assignment wherein you will download a movie dataset, write Python code to explore the data, gain insights into the movies, actors, directors, and collections, and submit the code.","b60e4b98":"- ### Subtask 3.5: Find the best directors\n\n    1. Find out the top 10 directors for whom the mean of `imdb_score` is the highest and store them in a new dataframe `top10director`. ","06b31395":"-  ### Subtask 3.4: Find IMDb Top 250\n\n    1. Create a new dataframe `IMDb_Top_250` and store the top 250 movies with the highest IMDb Rating (corresponding to the column: `imdb_score`). Also make sure that for all of these movies, the `num_voted_users` is greater than 25,000.\nAlso add a `Rank` column containing the values 1 to 250 indicating the ranks of the corresponding films.\n    2. Extract all the movies in the `IMDb_Top_250` dataframe which are not in the English language and store them in a new dataframe named `Top_Foreign_Lang_Film`.","9e79aceb":"-  ### Subtask 2.3: Drop unecessary rows using columns with high Null percentages\n\nDrop all the rows which have more that 5% Null values for such columns.","eebd5a17":"**Note 2:** We have two movies directed by `James Cameron` in the list.","c8cf6f76":"-  ### Subtask 3.2: Find the movies with highest profit","299aa35d":"## Task 2: Cleaning the Data\n\n-  ### Subtask 2.1: Inspect Null values\n\nFind out the number of Null values in all the columns and rows. Also, find the percentage of Null values in each column. Round off the percentages upto two decimal places.","00a01ff8":"-  ### Subtask 3.3: Dropping duplicate values\n","a1b70ce2":"-  ### Subtask 2.6: Check the number of retained rows\n","352326e6":"-  ### Subtask 3.6: Find popular genres\n\n    1. Extract the first two genres from the `genres` column and store them in two new columns: `genre_1` and `genre_2`. Some of the movies might have only one genre. In such cases, extract the single genre into both the columns, i.e. for such movies the `genre_2` will be the same as `genre_1`.\n    2. Group the dataframe using `genre_1` as the primary column and `genre_2` as the secondary column.\n    3. Find out the 5 most popular combo of genres by finding the mean of the gross values using the `gross` column and store them in a new dataframe named `PopGenre`.","54f5da96":"**Note 3:** Well, as it turns out. `Family + Sci-Fi` is the most popular combo of genres out there!"}}