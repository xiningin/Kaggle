{"cell_type":{"fad3b3c0":"code","ceed7383":"code","aa399297":"code","0bfd4142":"code","69dcafc3":"code","629901a8":"code","772e6f7d":"code","a1ec3980":"code","e2e79961":"code","2a871b4f":"code","fb65232a":"code","26d89596":"code","88aa3a14":"code","c1c1a63f":"code","bc95ec61":"code","b60cdc12":"code","38b2f9fe":"markdown"},"source":{"fad3b3c0":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.applications import imagenet_utils\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os\n","ceed7383":"Cblu ='\\33[34m'\nCend='\\33[0m'\nCred='\\033[91m'\nCblk='\\33[39m'\nCgreen='\\33[32m'","aa399297":"def get_paths(source_dir,output_dir,mode,subject):\n    # NOTE if running on kaggle these directories will need to be amended\n    # if all files are in a single kaggle input directory change the string 'consolidated'\n    # to match the directory name used in the database.\n    #if files are seperated in training, test and validation directories change the strings\n    # 'train', 'test' and 'valid' to match the directory names used in the database\n    if mode =='ALL':\n        # all data is in a single directory must be split into train, test, valid data sets\n        train_path=os.path.join(source_dir, 'Training')    \n        classes=os.listdir(train_path) \n        class_num=len(classes)\n        test_path=os.path.join(source_dir, 'Test')\n        valid_path=None\n       \n    else:\n        # data is seperated in 3 directories train, test, valid\n        test_path=os.path.join(source_dir,'test')\n        classes=os.listdir(test_path)\n        class_num=len(classes)  #determine number of class directories in order to set leave value intqdm    \n        train_path=os.path.join(source_dir, 'train')\n        valid_path=os.path.join(source_dir,'valid')\n                  \n    # save the class dictionary as a text file so it can be used by classification.py in the future\n    msg=''\n    for i in range(0, class_num):\n        msg=msg + str(i) + ':' + classes[i] +','\n    id=subject  + '.txt'   \n    dict_path=os.path.join (output_dir, id)\n    f=open(dict_path, 'w')\n    f.write(msg)\n    f.close()\n    return [train_path, test_path, valid_path,classes]\n      \n    \n   ","0bfd4142":"def print_data(train_labels, test_labels, val_labels, class_list):\n    # this function is not used in this implementation\n    #data_sets[0]=train data, [1]train labels, [2]=test data, [3]=test labels, [4]=value data, [5]=val labels, [6]=test files\n    # data_sets[7]=class_list\n    print('{0:12s}Class Name{0:13s}Class No.{0:4s}Train Files{0:7s}Test Files{0:5s}Valid Files'.format(' '))\n    for i in range(0, len(class_list)):\n        c_name=class_list[i]\n        tr_count=train_labels.count(i)\n        tf_count=test_labels.count(i)\n        v_count=val_labels.count(i)\n        print('{0}{1:^35s}{0:5s}{2:3.0f}{0:9s}{3:4.0f}{0:15s}{4:^4.0f}{0:12s}{5:^3.0f}'.format(' ',\n                                                                                               c_name,i,tr_count,\n                                                                                               tf_count,v_count))\n    print('{0:40s} ______________________________________________________'.format(' '))\n    msg='{0:20s}{1:6s}{0:16s}{2:^3.0f}{0:8s}{3:3.0f}{0:15s}{4:3.0f}{0:13s}{5}\\n'\n    print(msg.format(' ', 'Totals',len(class_list),len(train_labels),len(test_labels),len(val_labels)))","69dcafc3":"def get_steps(train_data, test_data,val_data,batch_size):\n    # this function is not used in this implementation\n    length=train_data.shape[0]\n    if length % batch_size==0:\n        tr_steps=int(length\/batch_size)\n    else:\n        tr_steps=int(length\/batch_size) + 1\n    length=val_data.shape[0]\n    if length % batch_size==0:\n        v_steps=int(length\/batch_size)\n    else:\n        v_steps=int(length\/batch_size) + 1\n    length=test_data.shape[0]\n    batches=[int(length\/n) for n in range(1,length+1) if length % n ==0 and length\/n<=80]\n    batches.sort(reverse=True)\n    t_batch_size=batches[0]\n    t_steps=length\/t_batch_size        \n    return [tr_steps,t_steps, v_steps, t_batch_size]","629901a8":"def make_model(output_dir,classes, image_size, subject,model_size, rand_seed):\n    size=len(classes)\n    check_file = os.path.join(output_dir, 'tmp.h5')\n    \n    if model_size=='L':\n        # mobile = keras.applications.mobilenet_v2.MobileNetV2(input_shape=input_shape)\n        mobile = tf.keras.applications.mobilenet.MobileNet()        \n        #remove last 5 layers of model and add dense layer with 128 nodes and the prediction layer with size nodes\n        # where size=number of classes\n        x=mobile.layers[-6].output\n        x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.015), activation='relu')(x)\n        x=Dropout(rate=.5, seed=rand_seed)(x)\n        predictions=Dense (size, activation='softmax')(x)\n        model = Model(inputs=mobile.input, outputs=predictions)\n        for layer in model.layers:\n            layer.trainable=True\n        model.compile(Adam(lr=lr_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n        \n    else:\n        if model_size=='M':\n            fm=2\n        else:\n            fm=1\n        model = Sequential()\n        model.add(Conv2D(filters = 4*fm, kernel_size = (3, 3), activation ='relu', padding ='same', name = 'L11',\n                         kernel_regularizer = regularizers.l2(l = 0.015),input_shape = (image_size, image_size, 3)))\n        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name ='L12'))\n        model.add(BatchNormalization(name = 'L13'))\n        model.add(Conv2D(filters = 8*fm, kernel_size = (3, 3), activation ='relu',\n                         kernel_regularizer = regularizers.l2(l = 0.015), padding ='same', name = 'L21')) \n        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name ='L22'))\n        model.add(BatchNormalization(name = 'L23'))\n        model.add(Conv2D(filters = 16*fm, kernel_size = (3, 3), activation ='relu',\n                         kernel_regularizer = regularizers.l2(l = 0.015), padding ='same', name ='L31')) \n        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name ='L32'))\n        model.add(BatchNormalization(name = 'L33'))\n        if fm==2:\n            model.add(Conv2D(filters = 32*fm, kernel_size = (3, 3), activation ='relu',\n                             kernel_regularizer = regularizers.l2(l = 0.015),padding ='same', name ='L41')) \n            model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name ='L42'))\n            model.add(BatchNormalization(name = 'L43'))\n            model.add(Conv2D(filters = 64*fm, kernel_size = (3, 3), activation ='relu', \n                             kernel_regularizer = regularizers.l2(l = 0.015),padding ='same', name ='L51')) \n            model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name ='L52'))\n            model.add(BatchNormalization(name = 'L53'))\n            \n        model.add(Flatten())\n        model.add(Dense(256 *fm,kernel_regularizer = regularizers.l2(l = 0.015), activation='relu', name ='Dn1'))\n        model.add(Dropout(rate=.5))\n        model.add(Dense(size, activation = 'softmax', name ='predict'))\n        model.compile(Adam(lr=lr_rate, ),loss='categorical_crossentropy', metrics=['accuracy'])\n    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, mode='min', verbose=1)\n    checkpoint = ModelCheckpoint(check_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n    lrck=keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.8, patience=1,\n                                           verbose=1, mode='min', min_delta=0.000001, cooldown=1, min_lr=1.0e-08)\n    callbacks=[checkpoint,lrck, early_stop, ]\n    return [model, callbacks,]","772e6f7d":"def make_generators( paths, mode, batch_size, v_split, classes, image_size):\n    #paths[0]=train path,paths[1]=test path paths[2]= valid path paths[3]=classes\n    v_split=v_split\/100.0\n    file_names=[]\n    labels=[]\n    if mode != 'ALL':\n        train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                             horizontal_flip=True,\n                             samplewise_center=True,\n                             samplewise_std_normalization=True).flow_from_directory(paths[0],\n                                                                                    target_size=(image_size, image_size),\n                                                                                    batch_size=batch_size, seed=rand_seed)\n        \n        val_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                                   samplewise_center=True,\n                                   samplewise_std_normalization=True).flow_from_directory(paths[2],\n                                                                                          target_size=(image_size, image_size),\n                                                                                          batch_size=batch_size,seed=rand_seed)\n        test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                                    samplewise_center=True,\n                                    samplewise_std_normalization=True).flow_from_directory(paths[1],\n                                                                                           target_size=(image_size, image_size),\n                                                                                           batch_size=batch_size,\n                                                                                           seed=rand_seed,\n                                                                                           shuffle=False)\n        for file in test_gen.filenames:\n            file_names.append(file)\n        for label in test_gen.labels:\n            labels.append(label)\n        \n        return [train_gen, test_gen, val_gen, file_names, labels]\n                  \n    else:\n        # all data is in a single directory there are no test images use validation images as test images\n        train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                             horizontal_flip=True,\n                             samplewise_center=True,\n                             validation_split=v_split,\n                             samplewise_std_normalization=True).flow_from_directory(paths[0],\n                                                                                    target_size=(image_size, image_size),\n                                                                                    batch_size=batch_size,\n                                                                                    subset='training',seed=rand_seed)\n        val_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                             horizontal_flip=False,\n                             samplewise_center=True,\n                             validation_split=v_split,\n                             samplewise_std_normalization=True).flow_from_directory(paths[0],\n                                                                                    target_size=(image_size, image_size),\n                                                                                    batch_size=batch_size,\n                                                                                    subset='validation',\n                                                                                    seed=rand_seed, shuffle=False)\n        test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n                                    samplewise_center=True,\n                                    samplewise_std_normalization=True).flow_from_directory(paths[1],\n                                                                                           target_size=(image_size, image_size),\n                                                                                           batch_size=batch_size,\n                                                                                           seed=rand_seed,\n                                                                                           shuffle=False)\n        \n        for file in test_gen.filenames:\n            file_names.append(file)\n        for label in test_gen.labels:\n            labels.append(label)\n    return [train_gen, test_gen, val_gen, file_names, labels]","a1ec3980":"def train(model, callbacks, train_gen, val_gen, epochs,start_epoch):\n    start=time.time()\n    data = model.fit_generator(generator = train_gen, validation_data= val_gen, epochs=epochs, initial_epoch=start_epoch,\n                       callbacks = callbacks)\n    stop=time.time()\n    duration = stop-start\n    hrs=int(duration\/3600)\n    mins=int((duration-hrs*3600)\/60)\n    secs= duration-hrs*3600-mins*60\n    msg='{0}Training took\\n {1} hours {2} minutes and {3:6.2f} seconds {4}'\n    print(msg.format(Cblu,hrs, mins,secs,Cend))\n    return data\n    ","e2e79961":"def tr_plot(tacc,vacc,tloss,vloss):\n    #Plot the training and validation data\n    Epoch_count=len(tloss)\n    Epochs=[]\n    for i in range (0,Epoch_count):\n        Epochs.append(i+1)\n    index=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index]\n    sc_label='best epoch= '+ str(index+1)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index+1,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    plt.style.use('fivethirtyeight')\n    plt.show()\n ","2a871b4f":"def display_pred(output_dir, pred, file_names, labels, subject, model_size,classes, kaggle):    \n    trials=len(labels)\n    errors=0\n    e_list=[]\n    prob_list=[]\n    true_class=[]\n    pred_class=[]\n    x_list=[]\n    index_list=[]\n    pr_list=[]\n    error_msg=''\n    for i in range (0,trials):\n        p_class=pred[i].argmax()\n        if p_class !=labels[i]: #if the predicted class is not the same as the test label it is an error\n            errors=errors + 1\n            e_list.append(file_names[i])  # list of file names that are in error\n            true_class.append(classes[labels[i]]) # list classes that have an eror\n            pred_class.append(classes[p_class]) #class the prediction selected\n            prob_list.append(100 *pred[i][p_class])# probability of the predicted class\n            add_msg='{0:^24s}{1:5s}{2:^20s}\\n'.format(classes[labels[i]], ' ', file_names[i])\n            error_msg=error_msg + add_msg\n            \n    accuracy=100*(trials-errors)\/trials\n    print('{0}\\n There were {1} errors in {2} trials for an accuracy of {3:7.3f}{4}'.format(Cblu,errors, trials,accuracy,Cend))\n    if kaggle==True and errors<26:\n        ans='Y'\n    else:\n        ans='N'\n    if kaggle==False:\n        ans=input('To see a listing of prediction errors enter Y to skip press Enter\\n ')\n    if ans== 'Y' or ans  =='y':\n        msg='{0}{1}{2:^18s}{1:3s}{3:^20s}{1:3s}{4:20s}{1:3s}{5}{6}'\n        print(msg.format(Cblu, ' ', 'File Name', 'True Class', 'Predicted Class', 'Probability', Cend))\n        for i in range(0,errors):\n            msg='{0}{1:^18s}{0:3s}{2:^20s}{0:3s}{3:20s}{0:5s}{4:^6.2f}'\n            print (msg.format(' ',e_list[i], true_class[i], pred_class[i], prob_list[i]))\n    if kaggle==True:\n        ans='Y'\n    else:\n        ans=input('\\nDo you want to save the list of error files?. Enter Y to save or press Enter to not save  ')\n    if ans=='Y' or ans=='y':\n        acc='{0:6.2f}'.format(accuracy)\n        if model_size=='L':\n            ms='Large'\n        elif model_size=='M':\n            ms= 'Medium'\n        else:\n            ms= 'Small'\n        header='Classification subject: {0} There were {1} errors in {2} tests for an accuracy of {3} using a {4} model\\n'.format(subject,errors,trials,acc,ms)\n        header= header +'{0:^24s}{1:5s}{2:^20s}\\n'.format('CLASS',' ', 'FILENAME') \n        error_msg=header + error_msg\n        file_id='error list-' + model_size + acc +'.txt'\n        file_path=os.path.join(output_dir,file_id)\n        f=open(file_path, 'w')\n        f.write(error_msg)\n        f.close()\n    for c in classes:\n        count=true_class.count(c)\n        x_list.append(count)\n        pr_list.append(c)\n    for i in range(0, len(x_list)):  # only plot classes that have errors\n        if x_list[i]==0:\n            index_list.append(i)\n    for i in sorted(index_list, reverse=True):  # delete classes with no errors\n        del x_list[i]\n        del pr_list[i]      # use pr_list - can't change class_list must keep it fixed\n    fig=plt.figure()\n    fig.set_figheight(len(pr_list)\/4)\n    fig.set_figwidth(6)\n    plt.style.use('fivethirtyeight')\n    for i in range(0, len(pr_list)):\n        c=pr_list[i]\n        x=x_list[i]\n        plt.barh(c, x, )\n        plt.title('Errors by class')\n    plt.show()\n    if kaggle==False:\n        ans=input('Press Enter to continue')\n    return accuracy        ","fb65232a":"def save_model(output_dir,subject, accuracy, image_size, model, weights):\n    # save the model with the  subect-accuracy.h5\n    acc=str(accuracy)[0:5]\n    tempstr=subject + '-' +str(image_size) + '-' + acc + '.h5'\n    model.set_weights(weights)\n    model_save_path=os.path.join(output_dir,tempstr)\n    model.save(model_save_path)\n    model_path=os.path.join(output_dir,'tmp.h5')\n    os.remove(model_path) ","26d89596":"def make_predictions( model, weights, test_gen):\n    model.set_weights(weights)\n    # the best model was saved as a file need to read it in and load it since it is not available otherwise\n    test_gen.reset()\n    msg='{0} Training has completed. Now loading test set to see how accurate the model is{1}'\n    print (msg.format(Cblu, Cend))    \n    predictions=model.predict_generator(test_gen, verbose=1) # make predictions on the test set\n    return predictions","88aa3a14":"def evaluation(model, weights, test_gen):\n    model.set_weights(weights)\n    results=model.evaluate(test_gen, verbose=1) \n    print('\\n{0} test set loss= {1:6.4f}   test set accuracy= {2:6.4f}\\n{3}'.format(Cgreen,results[0], results[1], Cend))\n    return [results[1], results[0]]\n    ","c1c1a63f":"def wrapup (output_dir,subject, accuracy, image_size, model, weights,run_num, kaggle):\n    accuracy=accuracy * 100\n    if accuracy >= 95:\n        msg='{0} With an accuracy of {1:5.2f} % the results appear satisfactory{2}'\n        print(msg.format(Cgreen, accuracy, Cend))\n        if kaggle:\n            save_model(output_dir, subject, accuracy, image_size , model, weights)\n            print ('*********************Process is completed******************************')            \n            return [False, None]        \n    elif accuracy >=85 and accuracy < 95:\n        if kaggle:\n            if run_num==2:\n                save_model(output_dir, subject, accuracy, image_size , model, weights)\n                print ('*********************Process is completed******************************')\n                return [False, None]\n            else:\n                print('running for 8 more epochs to see if accuracy improves')\n                return[True,8] # run for 8 more epochs\n        else:\n            msg='{0}With an accuracy of {1:5.2f} % the results are mediocure. Try running more epochs{2}'\n            print (msg.format(Cblu, accuracy,Cend))\n    else:\n        if kaggle:\n            if run_num==2:\n                save_model(output_dir, subject, accuracy, image_size , model, weights)\n                print ('*********************Process is completed******************************')\n                return [False, None]\n            else:\n                print('Running for 12 more epochs to see if accuracy improves')\n                return[True,12] # run for 12 more epochs\n        else:\n            msg='{0} With an accuracy  of {1:5.2f} % the results would appear to be unsatisfactory{2}'\n            print (msg.format(Cblu, accuracy, Cend))\n            msg='{0}You might try to run for more epochs or get more training data '\n            msg=msg + 'or perhaps crop your images so the desired subject takes up most of the image{1}'\n            print (msg.format(Cblu, Cend))\n    \n    tryagain=True\n    if kaggle==False:\n        while tryagain==True:\n            ans=input('To continue training from where it left off enter the number of additional epochs or enter H to halt  ')\n            if ans =='H' or ans == 'h':\n                run=False\n                tryagain=False\n                save_model(output_dir, subject, accuracy, image_size , model, weights)                                      \n                print ('*********************Process is completed******************************')\n                return [run,None]\n            else:\n                try:\n                    epochs=int(ans)\n                    run=True\n                    tryagain=False\n                    return [run,epochs]\n                except ValueError:\n                    print('{0}\\nyour entry {1} was neither H nor an integer- re-enter your response{2}'.format(Cred,ans,Cend))\n","bc95ec61":"def TF2_classify(source_dir, output_dir, mode, subject, v_split=5, epochs=20, batch_size=80,\n                 lr_rate=.002, image_size=224, rand_seed=128, model_size='L', kaggle=False):\n    model_size=model_size.upper()\n    mode=mode.upper()\n    if model_size=='L':\n        image_size=224              # for the large model image size must be 224    \n    paths=get_paths(source_dir,output_dir,mode,subject)\n    #paths[0]=train path,paths[1]=test path paths[2]= valid path paths[3]=classes\n    gens=make_generators( paths, mode, batch_size, v_split, paths[3], image_size)\n    #gens[0]=train generator gens[1]= test generator  gens[2]= validation generator\n    #gens[3]=test file_names  gens[4]=test labels\n    model_data=make_model(output_dir,paths[3], image_size, subject,model_size, rand_seed)\n    # model_data[0]=model  model_data[1]=callbacks\n    model=model_data[0]\n    class save_best_weights(tf.keras.callbacks.Callback):\n        # callback to save weights from the epoch with lowest value loss avoids having to save the model to a file\n        # then to reload the saved model. load.model takes almost 40 seconds so this avoids that problem\n        best_weights=model.get_weights()    \n        def __init__(self):\n            super(save_best_weights, self).__init__()\n            self.best = np.Inf\n        def on_epoch_end(self, epoch, logs=None):\n            current_loss = logs.get('val_loss')\n            accuracy=logs.get('val_accuracy')* 100\n            if np.less(current_loss, self.best):\n                self.best = current_loss            \n                save_best_weights.best_weights=model.get_weights()\n                print('\\nSaving weights with validation loss= {0:6.4f}  validation accuracy= {1:6.3f} %\\n'.format\n                      (current_loss, accuracy))      \n    model_data[1].append(save_best_weights()) # add to list of callbacks to save best model\n    run_num=0\n    run=True\n    tacc=[]\n    tloss=[]\n    vacc=[]\n    vloss=[]\n    start_epoch=0\n    while run:\n        run_num=run_num +1\n        results=train(model,model_data[1], gens[0], gens[2], epochs,start_epoch)\n        # returns data from training the model - append the results for plotting\n        tacc_new=results.history['accuracy']\n        tloss_new=results.history['loss']\n        vacc_new =results.history['val_accuracy']\n        vloss_new=results.history['val_loss']\n        for d in tacc_new:  # need to append new data from training to plot all epochs\n            tacc.append(d)\n        for d in tloss_new:\n            tloss.append(d)\n        for d in vacc_new:\n            vacc.append(d)\n        for d in vloss_new:\n            vloss.append(d)       \n        last_epoch=results.epoch[len(results.epoch)-1] # this is the last epoch run\n        tr_plot(tacc,vacc,tloss,vloss) # plot the data on loss and accuracy\n        weights=save_best_weights.best_weights # retrieve the best weights \n        predictions=make_predictions( model, weights, gens[1])\n        test_results=evaluation(model, weights, gens[1])\n        display_pred(output_dir, predictions, gens[3], gens[4], subject, model_size, paths[3], kaggle)\n        # test_results[0]=accuracy  test_results[1]=test loss\n        decide=wrapup(output_dir,subject, test_results[0], image_size, model, weights,run_num, kaggle)\n        run=decide[0]\n        decide[1]\n        if run==True:\n            epochs=last_epoch + decide[1]+1\n            start_epoch=last_epoch +1","b60cdc12":"source_dir=r'\/kaggle\/input\/fruits\/fruits-360_dataset\/fruits-360'\noutput_dir=r'c:\\Temp\\tfstorage'\nsubject='autism'\nv_split=2.7\nepochs=5\nbatch_size=80\nlr_rate=.0015\nimage_size=224\nrand_seed=256\nmodel_size='L'\nmode='All'\nkaggle=True  # added to deal with fact that kaggle 'commit' does not allow user entry\n              # set to True if you are doing a kaggle commit\nif kaggle:\n    output_dir=r'\/kaggle\/working'\n    \n\nTF2_classify(source_dir, output_dir, mode,subject, v_split= v_split, epochs=epochs,batch_size= batch_size,\n         lr_rate= lr_rate,image_size=image_size,rand_seed=rand_seed, model_size=model_size, kaggle=kaggle)","38b2f9fe":"This is a general purpose image classifier that can be used for most image classification problems. No knowledge of neural networks or Tensorflow is required to use it. An example of use on the Autism data set is shown below\nsource_dir='c:\/\/Temp\/\/autism'\nsubject='autism'\nt_split=5\nv_split=5\nepochs=30\nbatch_size=80\nlr_rate=.0025\nimage_size=128\nrand_seed=256\nmodel_size='L'\nmode='sep'\n\nTF2_classify(source_dir,mode,subject, t_split=t_split, v_split=v_split, epochs=epochs,batch_size=batch_size,\n         lr_rate=lr_rate,image_size=image_size,rand_seed=rand_seed, model_size=model_size)\n         \nthe program operates in one of two modes, If mode-'all' the training, test and validation files are taken from the source_dir and split into train, test and validation files as defined by t_split and v_split integer percentages.\nIf model='sep' images are read in from the train, test and valid directories within the source directory. T-split and\nv_split values are not used.\nepochs is the number of training epochs\nlr_rate is the learning rate \nbatch size is the number of images processed as a group during training. \nThe program has 3 models. model_size='L' is a large model based on the MobileNet architecture. It is accurate but propcessing time and memory requirements can be large. For this model set batch_size-80. If you get a resource exhaust error reduce its value. If model_size=\"M' the program uses a medium sixed model. Execution is fairly fast but it is less accurate. A batch size of 150 works well. If model_size=\"S\" a small model is used. Execution is fast but accuracy is reduced.\nrand_seed sets the seed for the random generators. It's value is arbitrary  but when changed will give a different mix of training, test and validation files when mode='all'.\nimage_size is the size that images are converted to for processing. If mode=\"L\" image size is set internally at 224.\nsubject is a string you can use to denote the name of files that are stored in your source directory at the conclusion of\nthe program.\nAt the conclusion of training test results are displayed and you can save the error list to a file in the source directory.\nYou are also given the option to run for additional epochs starting from where you left off. At the conclusion of the \nprogram two files are stored in the source_dir. One of them is the resulting trained model file. It is labelled as\nsubject-image_size-accuracy.h5 , For example autism-224-95.35.h5 means the subject was autism, the image size was 224 X 224 and the accuracy on the test set was 95.35%. This model file can then be used with a prediction program.\nThe other file saved is a text file that can be easily converted into a python dictionary. The key is the class number and the value is the associated class name. It is labelled as subject.txt. This file will also be needed by a prediction program to generate a list of classes. \nIf you elected to save the error list it is stored in the source directory as error-list-M-accuracy.txt where M is the model type.\nTo use the program you need a python 3 environment in which you have loaded the modules\ntensorflow 2.0, numpy, matplot, sklearn, tqdm cv2,random and PIL"}}