{"cell_type":{"7023b628":"code","23d4edeb":"code","3f82dd3a":"code","36db16ce":"code","38d0e552":"code","10ee19b5":"code","69760c32":"code","b74af8cf":"code","452620b0":"code","589022d4":"code","8269a714":"markdown","f4c2db48":"markdown","1f1e3b98":"markdown","efa2af60":"markdown","5067d7ec":"markdown","cabe5c0f":"markdown","e6956de6":"markdown","7ccb5273":"markdown","b276ef62":"markdown","73d04093":"markdown","fe9e59a2":"markdown","ec8af9a2":"markdown"},"source":{"7023b628":"import cv2\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import plot_model\nfrom keras.utils.np_utils import to_categorical\n\nBATCH_SIZE = 16\nIMAGE_SIZE = (300, 300, 3)\nCLASSES = ['rock', 'paper', 'scissors']","23d4edeb":"# 0->rock, 1->paper, 2->scissors\ntrain_data_x = []\ntrain_data_y = []\nval_data_x = []\nval_data_y = []\ntest_data_x = []\ntest_data_y = []\n\nfolder = '\/kaggle\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/train\/'\nfor item in CLASSES:\n    for file in os.listdir(os.path.join(folder, item)):\n        img = cv2.imread(os.path.join(folder, item, file))\n        if(img.shape != IMAGE_SIZE):\n            img = cv2.resize(img, IMAGE_SIZE[:2])\n        train_data_x.append(img)\n        train_data_y.append(item)\n\nfolder = '\/kaggle\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/validation\/'\nfor file in os.listdir(folder):\n    img = cv2.imread(os.path.join(folder, file))\n    if(img.shape != IMAGE_SIZE):\n        img = cv2.resize(img, IMAGE_SIZE[:2])\n    val_data_x.append(img)\n    if(re.match(r'rock.*', file)):    val_data_y.append('rock')\n    elif(re.match(r'paper.*', file)):    val_data_y.append('paper')\n    else:    val_data_y.append('scissors')\n        \nfolder = '\/kaggle\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/test\/'\nfor item in CLASSES:\n    for file in os.listdir(os.path.join(folder, item)):\n        img = cv2.imread(os.path.join(folder, item, file))\n        if(img.shape != IMAGE_SIZE):\n            img = cv2.resize(img, IMAGE_SIZE[:2])\n        test_data_x.append(img)\n        test_data_y.append(item)\n        \nprint(\"No. of training items   = \" + str(len(train_data_x)))\nprint(\"No. of validation items = \" + str(len(val_data_x)))\nprint(\"No. of test items       = \" + str(len(test_data_x)))","3f82dd3a":"plt.figure(figsize=(16,5))\nplt.subplot(131)\nsns.countplot(x = train_data_y)\nplt.title(\"Training set\")\nplt.subplot(132)\nsns.countplot(x = val_data_y)\nplt.title(\"Validation set\")\nplt.subplot(133)\nsns.countplot(x = test_data_y)\nplt.title(\"Test set\")\nplt.show()","36db16ce":"X_train = np.array(train_data_x, dtype=np.float)\ny_train = np.zeros((len(train_data_y), len(CLASSES)), dtype=np.float)\nfor i in range(len(train_data_y)):\n    for j in range(len(CLASSES)):\n        if(train_data_y[i]==CLASSES[j]):\n            y_train[i][j] = 1\ndel train_data_x\ndel train_data_y\n\nX_val = np.array(val_data_x, dtype=np.float)\ny_val = np.zeros((len(val_data_y), len(CLASSES)), dtype=np.float)\nfor i in range(len(val_data_y)):\n    for j in range(len(CLASSES)):\n        if(val_data_y[i]==CLASSES[j]):\n            y_val[i][j] = 1\ndel val_data_x\ndel val_data_y\n\nX_test = np.array(test_data_x, dtype=np.float)\ny_test = np.zeros((len(test_data_y), len(CLASSES)), dtype=np.float)\nfor i in range(len(test_data_y)):\n    for j in range(len(CLASSES)):\n        if(test_data_y[i]==CLASSES[j]):\n            y_test[i][j] = 1\ndel test_data_x\ndel test_data_y","38d0e552":"print(\"X_train size = \" + str(X_train.shape))\nprint(\"y_train size = \" + str(y_train.shape))\nprint(\"X_val size   = \" + str(X_val.shape))\nprint(\"y_val size   = \" + str(y_val.shape))\nprint(\"X_test size  = \" + str(X_test.shape))\nprint(\"y_test size  = \" + str(y_test.shape))","10ee19b5":"model = Sequential([Conv2D(32, kernel_size=(10,10), padding='Same', activation=tf.nn.relu, input_shape=IMAGE_SIZE),\n                    Conv2D(32, kernel_size=(10,10), padding='Same', activation=tf.nn.relu),\n                    MaxPooling2D(pool_size=(3,3)),\n                    Dropout(0.2),\n                    Conv2D(32, kernel_size=(5,5), padding='Same', activation=tf.nn.relu),\n                    Conv2D(32, kernel_size=(5,5), padding='Same', activation=tf.nn.relu),\n                    MaxPooling2D(pool_size=(2,2)),\n                    Dropout(0.2),\n                    Conv2D(32, kernel_size=(3,3), padding='Same', activation=tf.nn.relu),\n                    Conv2D(32, kernel_size=(5,5), padding='Same', activation=tf.nn.relu),\n                    MaxPooling2D(pool_size=(2,2)),\n                    Dropout(0.2),\n                    BatchNormalization(),\n                    Flatten(),\n                    Dense(256, activation=tf.nn.relu),\n                    Dropout(0.2),\n                    Dense(64, activation=tf.nn.relu),\n                    Dropout(0.2),\n                    Dense(3, activation=tf.nn.softmax)])","69760c32":"model.summary()","b74af8cf":"model.compile(optimizer = tf.keras.optimizers.Adam(),\n             loss = tf.keras.losses.CategoricalCrossentropy(),\n             metrics = ['accuracy'])\n\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n                    batch_size=BATCH_SIZE, epochs=10, verbose=1)","452620b0":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs= range(len(acc))\n\nplt.figure(figsize=(16, 5))\nplt.subplot(121)\nplt.plot(epochs, acc, label='Train_acc')\nplt.plot(epochs, val_acc, label='Val_acc')\nplt.legend()\nplt.title('Accuracy')\n\nplt.subplot(122)\nplt.plot(epochs, loss, label='Train_loss')\nplt.plot(epochs, val_loss, label='Val_loss')\nplt.legend()\nplt.title('Loss')\nplt.show()","589022d4":"train_acc, test_acc, img = 0, 0, 0\nfor i in range(X_train.shape[0]):\n    img = np.reshape(X_train[i], (1,) + IMAGE_SIZE)\n    if(np.argmax(model.predict(img)) == np.argmax(y_train[i])):\n        train_acc = train_acc + 1\n\nfor i in range(X_test.shape[0]):\n    img = np.reshape(X_test[i], (1,) + IMAGE_SIZE)\n    if(np.argmax(model.predict(img)) == np.argmax(y_test[i])):\n        test_acc = test_acc + 1\n\nprint(\"{:<15} {:<20} {:<15}\".format(\"Dataset\", \"Passed Cases\", \"Accuracy\"))\nprint(\"-\"*14 + \"  \" + \"-\"*19 + \"  \" + \"-\"*18)\nprint(\"{:<15} {:<20} {:<15}\".format(\"Training set\", \n                                    str(train_acc)+\" out of \"+str(X_train.shape[0]), \n                                    str(train_acc*100\/X_train.shape[0])+\"%\"))\nprint(\"{:<15} {:<20} {:<15}\".format(\"Test set\", \n                                    str(test_acc)+\" out of \"+str(X_test.shape[0]), \n                                    str(test_acc*100\/X_test.shape[0])+\"%\"))","8269a714":"Now we have 3 datasets, the `train`, the `val` and the `test`. Let's see the shapes of the numpy arrays holding the data. We can easily distinguish the no of examples in each dataset and the image size for each image.","f4c2db48":"Let us have a look on the epoch-wise changes in the loss and accuracy registered by the model and compare them for both the training and the validation data together.","1f1e3b98":"Now I will build the model. This model is somewhat inspired by the AlexNet model. I have implemeneted a general layout with the model having 2 parts - The CNN part and the DNN part\n- The CNN part consists of 3 segments, and in each segment, there are 2 convolutional layers, one pooling layer and a dropout layer. The convolutional layers follow 'same' padding and incorporate a ReLU activation function. The dropout ration is kept as 0.2. The kernel size for the convolutions and the pool size for the pooling vary over the segments. The CNN part ends with a Normalization layer to feed to the DNN part.\n- The DNN part has two hidden layers of 256 and 64 neurons each with a dropout layer after each hidden dense layer. The dense layers have a ReLU activation. The DNN part ends with the output layer, whoch basically produces the probability corresponding to the image classification and it does this using a softmax activation.","efa2af60":"It is pretty clear that the dataset has been carefully curated, because of which it has an equal number of samples for each label.\n\nAfter this, we will convert them to numpy arrays for proper and compatible flow in the model to be used further. Furthermore, converting the data into numpy arrays enable us to utlise various useful functions and properties of the Numpy library, which makes computation easy.\n\nNote - The total data occupies around 6 GBs of memory. Since kaggle provides limited amount of memory allocation for the general users, I have also deleted the initial lists to free up space and avoid abrupt termination. ","5067d7ec":"# Rock-Paper-Scissors Classifier\n\nDisclaimer - This is one of my naive attempts to apply simple Convolutional Neural Networks for a basic classification task as this. I have tried to be very descriptive at each step in the notebook, but still if you still feel something's missing, do ping your concerns in the comments below. All feedbacks are welcome\n\nRock-Paper-Scissors is a game that, arguably, most children and adults in the world have played at some point in their life. It is like an evergreen game. And, here we have a dataset of about 3000 images of hands with the corresponding hand signs for rock, paper and scissors. I have used a very simple and basic Convolutional Neural Network architecture to try to build a classifier. Further details will follow as we build the model.","cabe5c0f":"Note - The staggered and sharp changes in loss and accuracy associated to validation data is due to the fact that the data has a very few number of exmaples. So for each new classification, the accuracy changes abruptly. The opposite happens for the training dataset because of the presence of more than 2500 exmaples in that dataset.\n\nNow I will calculate the final accuracies for the training and the test datasets to conclude the model's performance. Here, the usual approach would be to use `model.evaluate()` but as mentioned before, there were some issues related to the memory allocation by kaggle. So I had to revert to calculate the accuracy explicitly so that there is less memory consumption.","e6956de6":"So this model gives an accuracy of 80.376% on the testing dataset which I presume is good enough for a start. Further fine tuning can be excercised to increase the performance.","7ccb5273":"Now lets compile our model and set our optimizer as Adam optimizer. Then we would train our model on the training set and use the validation set to validate our model's accuracy and performance.","b276ef62":"Now we will extract the images from the respective directories and store them in a python list. Along with it, we will use the image file name to select the correct label for the stored images in the same order. I will also be checking for proper and uniform shapes of the images, as there are some images in the dataset which are of different size.\n\nNote - The extraction of the data from the folder containing the validation dataset is slightly different from extracting the data from the folders containing the training and testing datasets. The is simply due to the way the data is present in the given directories. ","73d04093":"The following function helps us understand the the summary of our model, including the number of parameters to be learnt in each layer and the size of the outputs of each layer.","fe9e59a2":"Let's us have a look at the actual distribution of the labels among the datasets\n","ec8af9a2":"We will start with importing necessary libraries and modules"}}