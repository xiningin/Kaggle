{"cell_type":{"df0dca72":"code","0e678a51":"code","8cd4572f":"code","043475e2":"code","40be4e67":"code","d55c943c":"code","c2cbbbb7":"code","58879d02":"code","08826afa":"code","4cb232f3":"code","4c6baa5e":"code","4588281f":"code","c8577b9f":"code","425f7ab6":"code","85ce95d6":"code","b039bb0a":"code","87b2b876":"code","11d1fb82":"code","e502ffec":"code","450f4e84":"code","2a175c1d":"code","82c701a1":"code","6f4fd51c":"code","46f68f0f":"code","bc8879f6":"code","4794f8af":"code","d3c79501":"code","88e0834f":"code","0ab81dac":"code","33b896e1":"code","6f7a284d":"code","3b78564c":"code","9034379d":"code","60b3c747":"code","f50f7b4e":"code","bc6e1608":"code","ed12bce8":"code","14676fa7":"code","ca2a470e":"code","8db1c8c6":"code","043a337c":"code","f23340dc":"code","a485d2c9":"code","f3d82d8d":"code","33fb8be8":"code","e14adf99":"code","48bf9df6":"code","4af7f034":"code","dcf1ad2a":"code","a0b716b4":"code","048dd607":"markdown","94e73a68":"markdown","b477e59d":"markdown","be10fd62":"markdown","da8b1589":"markdown","01e0e613":"markdown","5d5bad18":"markdown","d6459637":"markdown","229ad0a5":"markdown","0bca8a18":"markdown","3be74459":"markdown","cd2b1be4":"markdown","600798f2":"markdown","42dbe177":"markdown","041f51dc":"markdown","4425db3b":"markdown","6241cecc":"markdown","e9030570":"markdown","4340b5eb":"markdown","fc7a47d4":"markdown","49689d97":"markdown","dc360423":"markdown","3ed1a15b":"markdown","80ab3721":"markdown"},"source":{"df0dca72":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('dark')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e678a51":"items=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nshops=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ncats=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\ntrain=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")","8cd4572f":"#\ud2b9\uc774\uce58 \uc81c\uac70","043475e2":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nflierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n                  linestyle='none', markeredgecolor='black')\nsns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price, flierprops=flierprops)","40be4e67":"train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)] # 1000\uac1c\uc774\uc0c1 \ud314\ub9b0 \ud488\ubaa9 \uc81c\uac70, 30\ub9cc\uc6d0\uc774\uc0c1 \ud488\ubaa9 \uc81c\uac70","d55c943c":"train = train[train.item_price > 0].reset_index(drop = True) # \uac00\uaca9\uc774 \ub9c8\uc774\ub108\uc2a4\uc778 \uac00\uaca9 \uc81c\uac70, \ud658\ubd88\ub420 \uac00\ub2a5\uc131\uc774\uc788\uc74c\ntrain.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0 # \ud310\ub9e4\uac2f\uc218\uac00 0\uac1c\uc778\uac74 -1\ub85c \ubcc0\uacbd","c2cbbbb7":"train.loc[train.shop_id == 0, 'shop_id'] = 57 # \ub458\uc774 \uac19\uc740 \uc0c1\uc810\uc778\ub370 \uc774\ub984\uc5d0 pah\uac00 \uaef4\uc788\uc74c\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","58879d02":"shops.loc[ shops.shop_name == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"',\"shop_name\" ] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"' # \ub744\uc5b4\uc4f0\uae30 \ub418\uc788\ub294 \ub3c4\uc2dc \uc774\ub984 \ubc14\uafb8\uae30\nshops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] ) # \uacf5\ubc31\uc744 \uae30\uc900\uc73c\ub85c \ubb38\uc790\ub97c \ub098\ub204\uace0 0\ubc88\uc9f8\nshops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] ) # 1\ubc88\uc9f8\nshops.loc[shops.city == \"!\u042f\u043a\u0443\u0442\u0441\u043a\", \"city\"] = \"\u042f\u043a\u0443\u0442\u0441\u043a\"  # \ub3c4\uc2dc\uc774\ub984\uc5d0 !\uac00 \ub4e4\uc5b4\uac00\uba74 \ubc14\uafd4\uc90c","08826afa":"category = []\nfor cat in shops.category.unique(): # category\uc758 \ubb38\uc790\uc5f4 \uc720\ub2c8\ud06c\uac12\n    if len(shops[shops.category == cat]) >= 5: # \ub9cc\uc57d shops['category'] \uac1c\uc218\uac00 5\uac00 \ud06c\uac70\ub098 \uac19\uc744\ub54c\n        category.append(cat) # category\uc548\uc5d0 \uc720\ub2c8\ud06c\uac12\uc744 \ub123\ub294\ub2e4 \nshops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" ) # 5\uac1c\uac00 \uc788\ub294 \uc0c1\uc810\uc774 \uce74\ud14c\uace0\ub9ac \uc548\uc5d0\uc788\uc73c\ub2c8\uae4c\n                                                                                     # 5\uac1c\uc778 \uc0c1\uc810\uc740 \uadf8\ub300\ub85c \ubc14\uafb8\uace0 \uadf8 \uc544\ub798\uac83\ub4e4\uc740 other\ub85c \ubcc0\uacbd","4cb232f3":"from sklearn.preprocessing import LabelEncoder \nshops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category ) # category\ub97c \uc22b\uc790\ub85c\nshops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )# shops.city\ub97c \uc22b\uc790\ub85c\nshops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]] # shops\uc548\uc5d0 shops_name\ube7c\uace0 \uc694\ub807\uac8c","4c6baa5e":"cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str) #  \" \" \uacf5\ubc31\uae30\uc900 \ubb38\uc790\ub098\ub204\uace0, 0\ubc88\uc9f8\ub85c \ubc14\uafb8\uae30\ncats.loc[ (cats.type_code == \"\u0418\u0433\u0440\u043e\u0432\u044b\u0435\")| (cats.type_code == \"\u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b\"), \"category\" ] = \"\u0418\u0433\u0440\u044b\" # type_code\uac00 \uc800\uac70\uac70\ub098 \uc774\uac70\uac70\ub098 \ub9cc\uc871\ud558\uba74 category\uc5f4\uc740 \ub9cc\ub4e0 \ud6c4 \uc694\uac78\ub85c \ubc14\uafc8","4588281f":"category = []\nfor cat in cats.type_code.unique(): \n    if len(cats[cats.type_code == cat]) >= 5: # \uc720\ub2c8\ud06c\uac12\uc758 \ud06c\uae30\uac00 5\ubcf4\ub2e4 \ud06c\uac70\ub098 \uac19\uc744\ub54c \n        category.append( cat ) # category\uc5d0 \uc720\ub2c8\ud06c\uac12 \ucd94\uac00\ncats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\") # cats['type_code']\uc548\uc5d0 category \uac12\uc774 \uc788\uc73c\uba74 \uadf8\ub300\ub85c \uc544\ub2c8\uba74 etc \ubc18\ud658","c8577b9f":"cats.type_code = LabelEncoder().fit_transform(cats.type_code)\ncats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\")) # -\uae30\uc900\uc73c\ub85c \ub098\ub220\uc11c\ncats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip()) # \ub9cc\uc57d \ubb38\uc790\uc5f4 x\uc758 \ud06c\uae30\uac00 1\ubcf4\ub2e4\ud06c\uba74 1\uc744 \uae30\uc900\uc73c\ub85c\ub098\ub214 \uc544\ub2c8\uba74 0\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub214\ncats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] ) # \ub77c\ubca8\uc778\ucf54\ub529\ncats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]] # item_category_name \ube7c\uace0 \ub098\uba38\uc9c0\ub85c \ub370\uc774\ud130\ud504\ub808\uc784\uad6c\uc131","425f7ab6":"import re\ndef name_correction(x):\n    x = x.lower() # \uc18c\ubb38\uc790\ub85c \ubc14\uafd4\n    x = x.partition('[')[0] # [\uc744 \uae30\uc900\uc73c\ub85c \ubb38\uc790\uc5f4\ub098\ub220\n    x = x.partition('(')[0] # (\uc744 \uae30\uc900\uc73c\ub85c \ubb38\uc790\uc5f4\ub098\ub220\n    x = re.sub('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ', x) # x\uc758 \ud328\ud134\uc774\uc678 ' '\ub85c \ubc14\uafb8\uc2ec\n    x = x.replace('  ', ' ') # \uc2a4\ud398\uc774\uc2a4\ubc14 \ub450\ubc88\ub204\ub978\uac78 \ud55c\ubc88\uc73c\ub85c\ubc14\uafc8\n    x = x.strip() # \uc55e\ub4a4 \uacf5\ubc31\uc9c0\uc6b0\uae30\n    return x","85ce95d6":"\nitems[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str # 1\ubc88\uc5d0 [\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub214\nitems[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str # 1\ubc88\uc5d0 (\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub214\n\n\nitems[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', \" \").str.lower() # \ub300\ubb38\uc790\ub97c \uc18c\ubb38\uc790\ub85c\nitems[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', \" \").str.lower() # \ub300\ubb38\uc790\ub97c \uc18c\ubb38\uc790\ub85c\n\n\nitems = items.fillna('0') # items\uc5d0 \uacf5\ubc31\uc740 0\uc73c\ub85c \ucc44\uc6c0\n\nitems[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x)) # item_name \ud074\ub9ac\ub2dd\n\nitems.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\") # items['name2']\uc5d0 0\uc774\uc5c6\uc73c\uba74 \uadf8\ub300\ub85c \uc544\ub2c8\uba74 0","b039bb0a":"items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] ) # \" \"\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub220, 0\ubc88\uc9f8\uac00 xbox\uba74 x\uc758 0:8\uae38\uc774 \uae4c\uc9c0\ub9cc, \uc544\ub2c8\uba74 0\ubc88\uc9f8\uc804\uccb4\nitems.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\" # items['type']\uc774 x360 or xbox360 or xbox 360 \ubaa8\ub450 xbox 360\uc73c\ub85c \ubcc0\ud658\nitems.loc[ items.type == \"\", \"type\"] = \"mac\" # type\uc548\uc5d0 type\uc774 \uacf5\ubc31\uc774\uba74 mac\uc73c\ub85c \nitems.type = items.type.apply( lambda x: x.replace(\" \", \"\") ) # \" \"\uc774\uba74 \uacf5\ubc31\uc73c\ub85c\nitems.loc[ (items.type == 'pc' )| (items.type == 'p\u0441') | (items.type == \"pc\"), \"type\" ] = \"pc\" # \uae00\uc790\uac00 \ub2e4\ub984\nitems.loc[ items.type == '\u0440s3' , \"type\"] = \"ps3\" # \uae00\uc790\uac00 \ub2e4\ub984","87b2b876":"group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"}) # type\uc744 \uae30\uc900\uc73c\ub85c item_id\ub97c \uc815\ub82c\ud6c4 group_sum\uc5d0 \uc800\uc7a5\ngroup_sum = group_sum.reset_index() #\uc778\ub371\uc2a4\ub97c \uc6d0\ub798\ub300\ub85c \ndrop_cols = []\nfor cat in group_sum.type.unique():\n    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40: # item_id\uc5d0 type\uac12\uc774 cat\uc774\ub791 \uac19\uc744\ub54c \uadf8 \uac12\uc774 40\ubcf4\ub2e4 \uc791\uc740\uacbd\uc6b0\n        drop_cols.append(cat) # drop_cols\uc5d0 \ucd94\uac00\nitems.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x ) # items['name2']\uc5d0 drop_cols\uac12\uc774 \uc788\uc73c\uba74 other \uc544\ub2c8\uba74 \uadf8\ub300\ub85c\nitems = items.drop([\"type\"], axis = 1) # type\uc744 \uc81c\uac70","11d1fb82":"group_sum.loc[(group_sum.type == cat), 'item_id']","e502ffec":"items.name2 = LabelEncoder().fit_transform(items.name2) # \ub77c\ubca8\uc778\ucf54\ub529\nitems.name3 = LabelEncoder().fit_transform(items.name3)\n\nitems.drop([\"item_name\", \"name1\"],axis = 1, inplace= True) # items\uc5d0 item_name, name1 \uceec\ub7fc\uc81c\uac70\nitems.head()","450f4e84":"from itertools import product\nimport time\nts = time.time() # \ud604\uc7ac\uc2dc\uac04\uc774\uc694\nmatrix = []\ncols  = [\"date_block_num\", \"shop_id\", \"item_id\"] \nfor i in range(34):\n    sales = train[train.date_block_num == i] # date_block_num(\ub2ec\ub9c8\ub2e4 \uc22b\uc790\ub85c \ud45c\ud604)\n    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n    # i, sale['shop_id'], sale['item_id'] \uc720\ub2c8\ud06c\uac12\uc744 \uacf1\uc9d1\ud569\ud55c\uac78 \ub9ac\uc2a4\ud2b8\ub85c \ub098\ud0c0\ub0b4\uc5b4 \ubc30\uc5f4\ub85c \ub9cc\ub4e0\uac78 \ucd94\uac00\n\nmatrix = pd.DataFrame( np.vstack(matrix), columns = cols ) # matrix\ub97c \uc138\ub85c\ub85c \uacb0\ud569\ud6c4 col\ub300\ub85c \ub370\uc774\ud130\ud504\ub808\uc784\ub9cc\ub4ec\nmatrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8) # matrix['date_block_num']\uc744 \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8) # matrix['shop_id']\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16) # matrix['item_id']\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix.sort_values( cols, inplace = True ) # \uc5f4\uc744 \uc624\ub984\ucc28\uc21c\uc73c\ub85c \uc815\ub82c\ntime.time()- ts # \uc544\uae4c \uc2dc\uac04 - \uc9c0\uae08 \uc2dc\uac04 = \uc2e4\ud589\uc2dc\uac04","2a175c1d":"matrix","82c701a1":"# add revenue to train df\ntrain[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"] # \ud310\uac2f\uc218 * \ud310\ub9e4\uac00\uaca9\uc73c\ub85c train['revenue'] \uceec\ub7fc\ub9cc\ub4ec","6f4fd51c":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} ) # 3\uac1c\uc5f4 \uae30\uc900\uc73c\ub85c item_cnt_day\ub97c \ngroup.columns = [\"item_cnt_month\"] # group\uc5d0 item_cnt_month \uc5f4 \ucd94\uac00\ngroup.reset_index( inplace = True)\nmatrix = pd.merge( matrix, group, on = cols, how = \"left\" ) # matrix\uc640 group\uc744 cols\uae30\uc900\uc73c\ub85c \uc67c\ucabd\uc73c\ub85c \ubcd1\ud569\nmatrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16) # item_cnt_month\uc758 null\uac12\uc740 0\uc774\uace0 \uc18c\uc218\uc810\ud615\ud0dc\ub85c \ub098\ud0c0\ub0b8\ub2e4\ntime.time() - ts","46f68f0f":"test[\"date_block_num\"] = 34 # test['date_block_num']\uc5d0\ub294 34\uc744 \ub123\uc74c\ntest[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8) # \uc815\uc218\ud615\uc73c\ub85c \ud45c\ud604\ntest[\"shop_id\"] = test.shop_id.astype(np.int8) # shop_id\ub97c \uc815\uc218\ud615\uc73c\ub85c\ntest[\"item_id\"] = test.item_id.astype(np.int16)# item_id\ub97c \uc815\uc218\ud615\uc73c\ub85c","bc8879f6":"ts = time.time()\n\nmatrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n# matrix\uc640 drop\ub418\ub294 ID\uc774\uc678\uc5d0 \uceec\ub7fc\ub4e4\uc744 \ud569\uce68? \uae30\uc874 index\ub97c \uc778\ub371\uc2a4\ub97c \uc720\uc9c0\ud558\uc9c0\uc54a\uace0, \ub0b4\ub9bc\ucc28\uc21c \uacc4\uce35\uc801 \uc778\ub371\uc2a4 \uc0ac\uc6a9\nmatrix.fillna( 0, inplace = True ) # matrix \uacf5\ubc31\uac12\uc740 0\uc73c\ub85c\ntime.time() - ts","4794f8af":"ts = time.time()\nmatrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" ) # shop_id\ub97c \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \uacb0\ud569\nmatrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\") # item_id\ub97c \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \uacb0\ud569\nmatrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" ) # item_category_id\ub97c \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \uacb0\ud569\nmatrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8) # shop_city \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8) # shop_category\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8) # item_category_id\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8) # subtype_code\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"name2\"] = matrix[\"name2\"].astype(np.int8) # name2\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"name3\"] = matrix[\"name3\"].astype(np.int16) # name3\ub97c \uc815\uc218\ud615\uc73c\ub85c\nmatrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8) # type_code\ub97c \uc815\uc218\ud615\uc73c\ub85c\ntime.time() - ts","d3c79501":"def lag_feature( df,lags, cols ):\n    for col in cols:\n        print(col)\n        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]  # \ub370\uc774\ud130\ud504\ub808\uc784\uc548\uc5d0 'item_cnt_month' \uac12\uc744\ub123\ub294\ub2e4.\n        for i in lags:\n            shifted = tmp.copy() # tmp \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \ubcf5\uc0ac\n            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)] # item_cnt_month + _lag_ + str(i)\n            shifted.date_block_num = shifted.date_block_num + i # date_block_num \uac12\uc5d0 i\uac12\uc744 \ub354\ud558\ub2e4\n            print(i)\n            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left') # df\uc5d0 3\uac1c \uc5f4\uc744 \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ubcd1\ud569\n            # item_cnt_month + _lag_ + str(1) item_cnt_month + _lag_ + str(2) item_cnt_month + _lag_ + str(3) \uc774\ub7f0\uc2dd\uc73c\ub85c\n    return df","88e0834f":"ts = time.time()\nmatrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\ntime.time() - ts","0ab81dac":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]}) # date_block_num \uc744 \uae30\uc900\uc73c\ub85c ite_cnt_month\uc758 \ud3c9\uade0\ngroup.columns = [\"date_avg_item_cnt\"] # date_avg_item_cnt \uc5f4 \ucd94\uac00\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\") # date_block_num \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \uacb0\ud569\nmatrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16) # date_avg_item_cnt\ub97c \uc18c\uc218\ud615\uc73c\ub85c\nmatrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\n# date_avg_item_cnt  + _lag_ + 1, date_avg_item_cnt  + _lag_ + 2, date_avg_item_cnt  + _lag_ + 3 \uc0dd\uc131 \nmatrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True ) # date_avg_item_cnt \uc81c\uac70 (\uc0ac\uc6a9\ud588\uae30 \ub54c\ubb38\uc5d0)\ntime.time() - ts","33b896e1":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']}) # \ub450\uac1c \uc5f4\uc744 \uae30\uc900\uc73c\ub85c item_cnt_month\uc758 \ud3c9\uade0\ngroup.columns = [ 'date_item_avg_item_cnt' ] # date_item_avg_item_cnt \uc5f4 \uc0dd\uc131\ngroup.reset_index(inplace=True) # index\ub97c \uc6d0\ub798\ub300\ub85c \ub9cc\ub4e0\ub2e4\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left') # \ub450\uac1c\uc758 \uc5f4\uc744 \uae30\uc900\uc73c\ub85c \uc67c\ucabd \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \uacb0\ud569\nmatrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16) # date_item_avg_item_cnt \uc18c\uc218\ud615\uc73c\ub85c\nmatrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt']) \n# date_item_avg_item_cnt  + _lag_ + 1, date_item_avg_item_cnt  + _lag_ + 2, date_item_avg_item_cnt  + _lag_ + 3 \uc0dd\uc131\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","6f7a284d":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","3b78564c":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_item_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","9034379d":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","60b3c747":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\nmatrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","f50f7b4e":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\nmatrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","bc6e1608":"ts = time.time()\ngroup = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]}) # item_id \uadf8\ub8f9\uc5d0 item_price \ud3c9\uade0\uc744 group\uc5d0 \uc800\uc7a5\ngroup.columns = [\"item_avg_item_price\"] # item_avg_item_price \uc5f4\uc5d0 \ucd94\uac00\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" ) # matrix\uc5d0 item_id\ub97c \uae30\uc900\uc73c\ub85c group\uc744 \uacb0\ud569\nmatrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n\n\ngroup = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n# date_block_num\uc744 \uae30\uc900\uc73c\ub85c item_id\ub97c \uc815\ub82c\ud558\uace0 item_id\uc5d0 \ub300\ud55c item_price\uc758 \ud3c9\uade0\uc744 \uc815\ub82c\n\ngroup.columns = [\"date_item_avg_item_price\"] # date_item_avg_item_price \uc5f4 \ucd94\uac00\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\") \n# matrix\uc5d0 date_block_num, item_id \uae30\uc900\uc73c\ub85c group\ubcd1\ud569\n\nmatrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n\n\nlags = [1, 2, 3]\nmatrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n# date_item_avg_item_price_lag_1, date_item_avg_item_price_lag_2, date_item_avg_item_price_lag_3 \uc0dd\uc131 \n\nfor i in lags:\n    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )\/ matrix[\"item_avg_item_price\"]\n# delta\uac12 \uad6c\ud558\uae30 #  \uae30\ucd08\uc790\uc0b0\uc758 \uac00\uaca9\ubcc0\ud654\uc5d0 \ub300\ud55c \uc635\uc158\uac00\uaca9\uc758 \ubcc0\ud654\ub7c9, delta_price_lag_1, delta_price_lag_2, delta_price_lag3 \uc5f4 \ucd94\uac00\n    \ndef select_trends(row) :\n    for i in lags:\n        if row[\"delta_price_lag_\" + str(i)]: \n            return row[\"delta_price_lag_\" + str(i)]\n    return 0\n\nmatrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1) \nmatrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\nmatrix[\"delta_price_lag\"].fillna( 0 ,inplace = True) # null\uac12\uc744 0\uc73c\ub85c \ubc18\ud658\n\nfeatures_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"] \n\nfor i in lags:\n    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) ) \n    features_to_drop.append(\"delta_price_lag_\" + str(i) ) # \uc544\uae4c \ub9cc\ub4e4\uc5c8\ub358\uac83\ub4e4 \uc81c\uac70\nmatrix.drop(features_to_drop, axis = 1, inplace = True)\ntime.time() - ts","ed12bce8":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] }) # \ub2ec\ubcc4 shopid\uc758 revenue \uc804\uccb4\uac12\ngroup.columns = [\"date_shop_revenue\"] # date_shop_revenue \uceec\ub7fc\uc0dd\uc131\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" ) # \ub450\uac1c\uc758 \uc5f4 \uae30\uc900\uc73c\ub85c group\uc744 \uc67c\ucabd\uc73c\ub85c \ubcd1\ud569\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32) # \uc18c\uc218\ud615\uc73c\ub85c\n\ngroup = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] }) # shop_id\uc5d0 date_block_num \ud3c9\uade0 group \ubcc0\uc218\uc5d0 \uc785\ub825\ngroup.columns = [\"shop_avg_revenue\"] # shop_avg_revenue \uc5f4 \ucd94\uac00\ngroup.reset_index(inplace = True )\n\nmatrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" ) # shop_id\ub97c \uae30\uc900\uc73c\ub85c group \ubcd1\ud569\nmatrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\nmatrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) \/ matrix['shop_avg_revenue']\n#revenue\uc758 delta\uac12 \uad6c\ud558\uae30\n\nmatrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n\nmatrix = lag_feature(matrix, [1], [\"delta_revenue\"]) # delta_revenue_lag_1 \uc5f4 \uc0dd\uc131\nmatrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32) # \uc18c\uc218\ud615\uc73c\ub85c\nmatrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True) # delta_revenue_lag_1 \ub0a8\uae30\uace0 \ub2e4 \uc9c0\uc6b0\ub294\ub4ef\ntime.time() - ts","14676fa7":"matrix[\"month\"] = matrix[\"date_block_num\"] % 12 # 12\ub85c \ub098\ub208 \ubaab\uad6c\ud558\uae30\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31]) # \uac01 \uc6d4\uc758 \ub05d\ub098\ub294 \uc77c\nmatrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)","ca2a470e":"ts = time.time()\nmatrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n# date_block_num - item_id, shop_id\ub85c \ubb36\uc740 date_block_num\uc758 \ucd5c\uc18c\uac12\nmatrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\ntime.time() - ts","8db1c8c6":"ts = time.time()\nmatrix = matrix[matrix[\"date_block_num\"] > 3] # 3\uc744 \ub118\ub294 date_block_num\uac12\ub4e4\ub9cc \ucd94\ucd9c\ntime.time() - ts","043a337c":"matrix.head().T","f23340dc":"import gc\nimport pickle\nfrom xgboost import XGBRegressor\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4","a485d2c9":"data = matrix.copy() # data \ubcc0\uc218\uc5d0 matrix\ub97c \ubcf5\uc0ac\ndel matrix\ngc.collect() # \uac00\ube44\uc9c0 \ucf5c\ub809\uc158","f3d82d8d":"data[data[\"date_block_num\"]==34].shape","33fb8be8":"X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1) \nY_train = data[data.date_block_num < 33]['item_cnt_month'] # 33 \uc544\ub798\uae4c\uc9c0\ub294 train set\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month'] # 33\uc740 vaildation set\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1) # 34\ub294 test set","e14adf99":"Y_train = Y_train.clip(0, 20)\nY_valid = Y_valid.clip(0, 20)","48bf9df6":"del data\ngc.collect();","4af7f034":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n#     tree_method='gpu_hist',\n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 20)\n\ntime.time() - ts","dcf1ad2a":"Y_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","a0b716b4":"from xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(model, (10,14))","048dd607":"# Add lag values for item_cnt_month for month\/city\/item.","94e73a68":"# Preprocessing","b477e59d":"# Add lag values for item_cnt_month for month\/city.","be10fd62":"# Add the previous month's average item_cnt.","da8b1589":"# Cleaning Item Data","01e0e613":"# Add shop, items and categories data onto matrix df.","5d5bad18":"# Add average item price on to matix df.\n# Add lag values of item price per month.\n# Add delta price values - how current month average pirce relates to global average.","d6459637":"# Add lag values for item_cnt_month for month\/shop\/item.","229ad0a5":"# Delete first three months from matrix. They don't have lag values.","0bca8a18":"# Use month 34 as validation for training.","3be74459":"# \ubaa8\ub378\ub9c1","cd2b1be4":"# Create a test set for month34","600798f2":"# Add total shop revenue per month to matix df.\n# Add lag values of revenue per month.\n# Add delta revenue values - how current month revenue relates to global average.","42dbe177":"# Add lag values of item_cnt_month for month \/ item_id.","041f51dc":"# Add item_cnt_month lag features.","4425db3b":"# Clean item names","6241cecc":"# Clean item type","e9030570":"# Concatenate train and test sets","4340b5eb":"# Add the month of each shop and item first sale.","fc7a47d4":"1. # Feature Engineering\nAdd lag features to matrix df.","49689d97":"# Add lag values for item_cnt_month for every month \/ shop combination.","dc360423":"# Add lag values for item_cnt_month for month\/shop\/item subtype.","3ed1a15b":"# Add month and number of days in each month to matrix df.","80ab3721":"# Cleaning Item Category Data"}}