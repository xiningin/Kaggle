{"cell_type":{"a469ca17":"code","05c88b5d":"code","ad1b0d5b":"code","c32a656b":"code","2fc82d32":"code","7a67a8ec":"code","440f8502":"code","49af8e09":"code","b9cd238b":"code","dedd9b8f":"code","58d2cdec":"code","3730b819":"code","a93b4adb":"code","4c1ae0c5":"code","0d04a983":"code","e25d7adb":"code","5b302076":"code","6c5c1bb7":"code","35fab481":"code","6625bb65":"code","7e1a46ab":"code","1de3c135":"code","1bf83b66":"code","4aa5189f":"code","29d1355b":"code","6d909324":"code","e6124a7a":"code","35d7233f":"code","26e09ec9":"code","8f8ede15":"code","33ec797b":"code","c12542b9":"markdown","febd9f35":"markdown","9ac3834e":"markdown","7e2ecda6":"markdown","4d5e2e18":"markdown","694d48f0":"markdown","4969bfc6":"markdown","4bc92d05":"markdown","1bd64378":"markdown","4e33a0a9":"markdown","a7e5460d":"markdown","4fdb1821":"markdown"},"source":{"a469ca17":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","05c88b5d":"original_data=pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","ad1b0d5b":"original_data.head(10)","c32a656b":"original_data.info()","2fc82d32":"original_data.describe()","7a67a8ec":"data = original_data.copy()\ndata.isnull().sum()","440f8502":"data.columns","49af8e09":"diagnosis_B , diagnosis_M = data.diagnosis.value_counts()\nprint(f'B : {diagnosis_B}\\nM : {diagnosis_M}')","b9cd238b":"labels = [\"B\", \"M\"]\nsizes = [357, 212]\nexplode = (0,0)\ncolors = [\"purple\",\"gold\"]\nfig1, ax1 = plt.subplots(figsize =(10,10))\nax1.pie(sizes,colors = colors ,explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Diagnosis\")\nplt.show()","dedd9b8f":"fig1, ax1 = plt.subplots(figsize =(10,10))\nplt.scatter(x = data.radius_mean, y = data.concavity_mean ,marker =\"h\", c = \"brown\" )\nplt.grid()\nplt.xlabel(\"Radius Mean\")\nplt.ylabel(\"Concavity Mean\")","58d2cdec":"g = sns.jointplot(\n    data=data,\n    x=\"radius_mean\", y=\"concavity_mean\", \n    kind=\"kde\",\n)\nplt.show()\n","3730b819":"sns.violinplot(data=data, x=\"diagnosis\", y=\"radius_mean\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()\n","a93b4adb":"sns.violinplot(data=data, x=\"diagnosis\", y=\"concavity_mean\",\n               split=True, inner=\"quart\", linewidth=1,)\nsns.despine(left=True)\nplt.show()","4c1ae0c5":"data.drop([\"Unnamed: 32\"],axis = 1, inplace = True)\ndata.drop([\"id\"],axis = 1,inplace = True)\ndata.columns","0d04a983":"y = [1 if each == 'M' else 0 for each in data.diagnosis]\ndata.drop(['diagnosis'],inplace = True, axis = 1)\ndata = (data - data.min())\/ (data.max() - data.min())\ndata","e25d7adb":"all_scores = {}\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data, y, test_size = 0.2, random_state = 24)","5b302076":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\nsvc = svm.SVC()\nparameters_svc = {\n              'kernel' : ('sigmoid','poly','rbf'),\n              'degree' : (range(2,5)),\n              'gamma' : ('scale', 'auto')}\nsvc_grid = GridSearchCV( svc, parameters_svc)\nsvc_grid.fit(x_train, y_train)\nsvc_grid_score = svc_grid.score(x_test, y_test)\nprint('Score : ',svc_grid_score)\nprint('Best parameters : ',svc_grid.best_params_)\nall_scores['Support Vector'] = round((svc_grid_score*100),2)","6c5c1bb7":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,svc_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","35fab481":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nlog_reg = LogisticRegression()\nparameters_log_reg = {\n    'penalty' : ('l1', 'l2', 'elasticnet', 'none'),\n    'tol' : (1e-4,1e-3,1e-5),\n    'C' : (1.0,1.1,1.2,1.5,2.0), \n    'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n    'multi_class' : ('auto', 'ovr', 'multinomial')\n}\nlog_reg_grid = GridSearchCV( log_reg, parameters_log_reg)\nlog_reg_grid.fit(x_train, y_train)\nlog_reg_score = log_reg_grid.score(x_test, y_test)","6625bb65":"print('Score : ',log_reg_score)\nprint('Best parameters : ',log_reg_grid.best_params_)\nall_scores['Logistic Regression'] = round((log_reg_score*100),2)","7e1a46ab":"cm = confusion_matrix(y_test,log_reg_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","1de3c135":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nparameters_nb = {\n    'var_smoothing' : (1e-8, 1e-9, 1e-10)\n}\n\nnb_grid = GridSearchCV( nb, parameters_nb)\nnb_grid.fit(x_train, y_train)\nnb_grid_score = nb_grid.score(x_test, y_test)\nprint('Score : ',nb_grid_score)\nprint('Best parameters : ',nb_grid.best_params_)\nall_scores['Naive Bayes'] = round((nb_grid_score*100),2)\n","1bf83b66":"cm = confusion_matrix(y_test,nb_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","4aa5189f":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nparameters_knn = {\n    'n_neighbors' : (3,4,5,6),\n    'weights' : ('uniform', 'distance'),\n    'algorithm' : ('auto', 'ball_tree', 'kd_tree', 'brute'),\n    'leaf_size' : (24,30,32,48),\n    'p' : (1,2,3),\n}\n\nknn_grid = GridSearchCV( knn, parameters_knn)\nknn_grid.fit(x_train, y_train)\nknn_grid_score = knn_grid.score(x_test, y_test)\nprint('Score : ',knn_grid_score)\nprint('Best parameters : ',knn_grid.best_params_)\nall_scores['K-Nearest Neighbour'] = round((knn_grid_score*100),2)","29d1355b":"cm = confusion_matrix(y_test,knn_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","6d909324":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nparameters_rf = {\n    'n_estimators' : (10,64,100,128),\n    'criterion' : ('gini', 'entropy'),\n    'max_features' : ('auto', 'sqrt', 'log2'),\n}\n\nrf_grid = GridSearchCV( rf, parameters_rf)\nrf_grid.fit(x_train, y_train)\nrf_grid_score = rf_grid.score(x_test, y_test)\nprint('Score : ',rf_grid_score)\nprint('Best parameters : ',rf_grid.best_params_)\nall_scores['Random Forest'] = round((rf_grid_score*100),2)","e6124a7a":"cm = confusion_matrix(y_test,rf_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","35d7233f":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\nparameters_gb = {\n    'loss' : ('deviance', 'exponential'),\n    'learning_rate' : (1.0,1.1,1.2),\n    'criterion' : ('friedman_mse', 'mse', 'mae'),    \n}\n\ngb_grid = GridSearchCV( gb, parameters_gb)\ngb_grid.fit(x_train, y_train)\ngb_grid_score = gb_grid.score(x_test, y_test)\nprint('Score : ',gb_grid_score)\nprint('Best parameters : ',gb_grid.best_params_)\nall_scores['Gradient Boost'] = round((gb_grid_score*100),2)","26e09ec9":"cm = confusion_matrix(y_test,gb_grid.predict(x_test))\n\nf, ax = plt.subplots(figsize =(10,10))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"blue\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Original values\")\nplt.show()","8f8ede15":"_, ax = plt.subplots(figsize =(8,8))\nax.bar(all_scores.keys(), all_scores.values(), color = 'dodgerblue', align = 'center')\nplt.xticks(rotation='vertical')\nplt.title('% ACCURACY')\n","33ec797b":"results = pd.DataFrame(all_scores.items(), columns=['Classifier', 'Score'])\nresults = results.sort_values(by=['Score'],ascending = False)\nresults.index = range(1,7)\nresults","c12542b9":"<a id = \"6\"><\/a>\n<font color ='gold'>\n# 4.2 Logistic Regression","febd9f35":"<a id = \"5\"><\/a>\n<font color ='gold'>\n# 4.1 Support Vector Classifier","9ac3834e":"<a id = \"11\"><\/a>\n<font color ='red'>\n# 5. Comparing Results","7e2ecda6":"\n<font color ='red'>\nContent :\n    \n    \n    \n1. [  Load and Check Data](#1)\n    \n2. [ Visualizing Data](#2)  \n    \n3. [Feature Engineering](#3)    \n  \n4. [Prediction](#4)                \n    4.1 [Support Vector Classifier](#5)          \n    4.2 [Logistic Regression](#6)        \n    4.3 [Naive Bayes Classifier](#7)           \n    4.4 [K-Nearest Neighbour Classifier](#8)          \n    4.5 [Random Forest Classifier](#9)         \n    4.5 [Gradient Boosting Classifier](#10)  \n    \n5. [Comparing Results](#11) ","4d5e2e18":"<a id = \"4\"><\/a>\n<font color ='gold'>\n# 4. Prediction","694d48f0":"<a id = \"3\"><\/a>\n<font color ='gold'>\n# 3. Feature Engineering","4969bfc6":"<a id = \"2\"><\/a>\n<font color ='red'>\n## 2. Visualizing Data","4bc92d05":"<a id = \"7\"><\/a>\n<font color ='red'>\n# 4.3 Naive Bayes Classifier","1bd64378":"<a id = \"8\"><\/a>\n<font color ='red'>\n# 4.4 K-Nearest Neighbour Classifier","4e33a0a9":"<a id = \"1\"><\/a>\n<font color ='red'>\n## 1. Load and Check Data","a7e5460d":"<a id = \"10\"><\/a>\n<font color ='red'>\n# 4.6 Gradient Boosting Classifier","4fdb1821":"<a id = \"9\"><\/a>\n<font color ='red'>\n# 4.5 Random Forest Classifier"}}