{"cell_type":{"efb83dca":"code","f4381f07":"code","2d17f12f":"code","9c5f7289":"code","43301205":"code","40b31380":"code","97a3e99d":"code","7b44450e":"code","7d670cf7":"code","07f75d40":"code","2fd3add1":"code","4c7367c3":"code","5b583a93":"code","2b5c238b":"code","57a30819":"code","00d50a1a":"code","ce742167":"code","ec74c499":"code","ffa9caa4":"code","b238acdd":"code","9fc25bca":"code","dc6a07b7":"code","bae95935":"code","a5e78b5e":"markdown","2bd6c54e":"markdown","2a0c4e72":"markdown","acaf547b":"markdown","5c56b707":"markdown","d1c80bdf":"markdown","4f84a9e6":"markdown","e79db77e":"markdown","78174844":"markdown","84314133":"markdown","8d07db5d":"markdown","ec37947c":"markdown","a6f4036b":"markdown","684b11ae":"markdown"},"source":{"efb83dca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n%matplotlib inline\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\n\nfrom sklearn.decomposition import PCA\nfrom sklearn import ensemble\nfrom sklearn.ensemble import RandomForestClassifier\n#from scipy.stats import linregress\nimport scipy\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.import zipfilepath.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f4381f07":"import zipfile\n\nzf=zipfile.ZipFile('\/kaggle\/input\/forest-cover-type-kernels-only\/train.csv.zip')\nzf2=zipfile.ZipFile('\/kaggle\/input\/forest-cover-type-kernels-only\/test.csv.zip')\n\nsample_submission= pd.read_csv('..\/input\/forest-cover-type-kernels-only\/sample_submission.csv.zip')\nsampleSubmission= pd.read_csv('..\/input\/forest-cover-type-kernels-only\/sampleSubmission.csv.zip')\ntrain= pd.read_csv(zf.open('train.csv'))\ntest= pd.read_csv(zf2.open('test.csv'))\n\nprint('train (r,c)=',train.shape)\nprint('test (r,c)=',test.shape)\nprint('sample_submission (r,c)=',sample_submission.shape)\nprint('sampleSubmission (r,c)=',sampleSubmission.shape)","2d17f12f":"train.head()","9c5f7289":"test.head().describe()","43301205":"test.head()","40b31380":"test.head().describe()","97a3e99d":"sample_submission.head()","7b44450e":"sample_submission.head().describe()","7d670cf7":"sampleSubmission.head()","07f75d40":"sampleSubmission.head().describe()","2fd3add1":"train.set_index('Id')","4c7367c3":"test.set_index('Id')","5b583a93":"sample_submission.set_index('Id')","2b5c238b":"sampleSubmission.set_index('Id')","57a30819":"print('Number of null values in the dataset=', len(train[train.isnull()]) )","00d50a1a":"train.fillna('unknown')","ce742167":"plt.plot(train.Elevation, train.Aspect)\nplt.show()\n\n# plt.show()","ec74c499":"#first we group the data by its elevation and compare it by the number of aspects , minumin of aspects and max of aspects\np=train.groupby(['Elevation']).Aspect.agg([len, min, max])\n\n#plt.scatter(p)\nplt.plot(p.len)\nplt.xlabel('Elevation')\nplt.ylabel('Number of Apects')\nplt.show()  # or plt.savefig(\"name.png\")\n# plt.scatter(x, y)\n# y = train.\n# z=\n# plt.scatter(train.Elevation, )\n# plt.show()  # or plt.savefig(\"name.png\")","ffa9caa4":"p=train.groupby(['Elevation']).Aspect.mean()\np.astype('int')\nplt.plot(p)\nplt.show()","b238acdd":"x=train.Elevation.mean()\nplt.scatter(x,train.Aspect.mean())\n\nplt.show()","9fc25bca":"#row1 is Id OF train row2 is Id of Cover_Type\n# def add(row1,row2) :\n#     if (row1.Id == row2.Id):\n#         x= pd.concat([row1, row2.Cover_Type])\n#     else:\n#         print('unkown value')\n#     return x    \n# ","dc6a07b7":"left= train.set_index('Id')\nright= sample_submission.set_index('Id')\noutput=left.join(right, lsuffix='_')\nfinal_data = output.drop(columns=\"Cover_Type\")\nfinal_data\n","bae95935":"final_data.to_csv('FinalSampleSubmition', index = False)","a5e78b5e":"Overview of sampleSubmission dataset","2bd6c54e":"As we can see its hard to judge the realationship between them by ploting them as raw data so we will only use thier mean,number,min and max","2a0c4e72":"Now to the main task which is clarifying each tree cover type according to its ID","acaf547b":"Overview of sample_submission dataset","5c56b707":"The next step is to identify the data values with Nan values in the train dataset that we will work with and replace them with 'unkown'.","d1c80bdf":"Replacing the null values","4f84a9e6":"Overview of train dataset","e79db77e":"Submiting the final output","78174844":"We start by importing the libraries we will use.","84314133":"We will make a simple graph to see the realation between Elevation and Aspect by making a perfect fit line in each graph.\nBy this perfect fit line we will be able to judge the realtionship between Elevation and Aspect.","8d07db5d":"importing the database csv file and getting a general overview of the dataset.","ec37947c":"Overview of test dataset","a6f4036b":"> Now based on our observation of the dataset we will change its indexing to be based on the ID .","684b11ae":"In this project ,we will try to predict the forest cover type ,inorder to achieve this goal we first need to explore and imporve each section in the database using pandas for data proccessing and matplotlib for data anlysis on graphs."}}