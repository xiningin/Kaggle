{"cell_type":{"26a81786":"code","24f7e885":"code","fcbb78f9":"code","37d8f5a1":"code","554e4c0d":"code","b1291e24":"code","5cebcbd9":"code","a3465829":"code","b3cc7cab":"code","cb236758":"code","a79d9255":"code","4eea0949":"code","8c8717a8":"markdown","d4b64484":"markdown","6713d4e1":"markdown","da60d4b4":"markdown","996d9924":"markdown","ed5099a2":"markdown","aecc864b":"markdown","b0abfbb6":"markdown","cdafda2d":"markdown"},"source":{"26a81786":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn import cluster\nfrom sklearn import preprocessing\nimport plotly.express as px\nfrom sklearn.datasets import make_blobs\nplt.style.use('dark_background')","24f7e885":"class KMeansClustering:\n    def __init__(self, X, num_clusters):\n        self.K = num_clusters # cluster number\n        self.max_iterations = 100 # max iteration. don't want to run inf time\n        self.num_examples, self.num_features = X.shape # num of examples, num of features\n        self.plot_figure = True # plot figure\n        \n    # randomly initialize centroids\n    def initialize_random_centroids(self, X):\n        centroids = np.zeros((self.K, self.num_features)) # row , column full with zero \n        for k in range(self.K): # iterations of \n            centroid = X[np.random.choice(range(self.num_examples))] # random centroids\n            centroids[k] = centroid\n        return centroids # return random centroids\n    \n    # create cluster Function\n    def create_cluster(self, X, centroids):\n        clusters = [[] for _ in range(self.K)]\n        for point_idx, point in enumerate(X):\n            closest_centroid = np.argmin(\n                np.sqrt(np.sum((point-centroids)**2, axis=1))\n            ) # closest centroid using euler distance equation(calculate distance of every point from centroid)\n            clusters[closest_centroid].append(point_idx)\n        return clusters \n    \n    # new centroids\n    def calculate_new_centroids(self, cluster, X):\n        centroids = np.zeros((self.K, self.num_features)) # row , column full with zero\n        for idx, cluster in enumerate(cluster):\n            new_centroid = np.mean(X[cluster], axis=0) # find the value for new centroids\n            centroids[idx] = new_centroid\n        return centroids\n    \n    # prediction\n    def predict_cluster(self, clusters, X):\n        y_pred = np.zeros(self.num_examples) # row1 fillup with zero\n        for cluster_idx, cluster in enumerate(clusters):\n            for sample_idx in cluster:\n                y_pred[sample_idx] = cluster_idx\n        return y_pred\n    \n    # plotinng scatter plot\n    def plot_fig(self, X, y):\n        fig = px.scatter(X[:, 0], X[:, 1], color=y)\n        fig.show() # visualize\n        \n    # fit data\n    def fit(self, X):\n        centroids = self.initialize_random_centroids(X) # initialize random centroids\n        for _ in range(self.max_iterations):\n            clusters = self.create_cluster(X, centroids) # create cluster\n            previous_centroids = centroids\n            centroids = self.calculate_new_centroids(clusters, X) # calculate new centroids\n            diff = centroids - previous_centroids # calculate difference\n            if not diff.any():\n                break\n        y_pred = self.predict_cluster(clusters, X) # predict function\n        if self.plot_figure: # if true\n            self.plot_fig(X, y_pred) # plot function \n        return y_pred\n            \nif __name__ == \"__main__\":\n    np.random.seed(10)\n    num_clusters = 3 # num of cluster\n    X, _ = make_blobs(n_samples=1000, n_features=2, centers=num_clusters) # create dataset using make_blobs from sklearn datasets\n    Kmeans = KMeansClustering(X, num_clusters)\n    y_pred = Kmeans.fit(X)","fcbb78f9":"df = pd.read_csv(\"\/kaggle\/input\/wholesale-customers-data-set\/Wholesale customers data.csv\")\ndf.head()","37d8f5a1":"df.describe()","554e4c0d":"scaler = preprocessing.StandardScaler()\ndata_scaled = scaler.fit_transform(df)\n\npd.DataFrame(data_scaled).describe()","b1291e24":"kmeans = cluster.KMeans(n_clusters=2, init='k-means++') # \u2018k-means++\u2019 : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.\nkmeans.fit(data_scaled)","5cebcbd9":"kmeans.inertia_","a3465829":"SSE = []\nfor i in range(1,20):\n    kmeans = cluster.KMeans(n_clusters = i, init='k-means++') # iterate from range (1, 20)\n    kmeans.fit(data_scaled)\n    SSE.append(kmeans.inertia_)\n\n# converting the results into a dataframe and plotting them\nframe = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\nplt.figure(figsize=(12,6))\nplt.plot(frame['Cluster'], frame['SSE'], marker=\"*\")\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')","b3cc7cab":"kmeans = cluster.KMeans(n_clusters=5, init='k-means++')\nkmeans.fit(data_scaled)\npred = kmeans.predict(data_scaled)\npred","cb236758":"frame = pd.DataFrame(data_scaled)\nframe['cluster'] = pred\nframe['cluster'].value_counts()","a79d9255":"dataset = df.copy()\ndataset[\"cluster\"] = pred","4eea0949":"fig = px.scatter_3d(dataset, x=\"Grocery\", y=\"Milk\", z=\"Fresh\", color='cluster', size=\"Fresh\", size_max=30)\nfig.show()","8c8717a8":"# we can choose any number of clusters between 5 to 8","d4b64484":"# KMeans From Scratch","6713d4e1":"# 3D scatter plot","da60d4b4":"# dataset describe","996d9924":"# elbow method\n**let\u2019s see how we can use the elbow curve to determine the optimum number of clusters in Python.**\n> Keeping this in mind, we can say that the lesser the inertia value, the better our clusters are.","ed5099a2":"# Clustering is the process of dividing the entire data into groups (also known as clusters) based on the patterns in the data.\n> # The main objective of the K-Means algorithm is to minimize the sum of distances between the points and their respective cluster centroid.\n> Step 1: Choose the number of clusters k\n\n> Step 2: Select k random points from the data as centroids\n\n> Step 3: Assign all the points to the closest cluster centroid\n\n> Step 4: Recompute the centroids of newly formed clusters\n\n> Step 5: Repeat steps 3 and 4","aecc864b":"# Read dataset","b0abfbb6":"# preprocessing with standard scaler","cdafda2d":"# Fit Data"}}