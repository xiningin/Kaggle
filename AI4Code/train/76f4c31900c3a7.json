{"cell_type":{"32b7b3dd":"code","5b85b298":"code","c0bf1631":"code","2a585f26":"code","1b3c9105":"code","d5d4e948":"code","f9e2314a":"code","8b0f81fc":"code","5c3d879f":"code","d2c19d6f":"code","8820c3ba":"code","f184a551":"code","82fdcdd8":"code","00e92582":"code","6298cce4":"code","06c29633":"code","5acd671c":"code","887a0757":"markdown","9e8696ab":"markdown","ddb61adf":"markdown","4f49c55a":"markdown","13c1083e":"markdown"},"source":{"32b7b3dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5b85b298":"data = pd.read_csv('\/kaggle\/input\/market-basket-optimization\/Market_Basket_Optimisation.csv', header=None)\n","c0bf1631":"data.head()","2a585f26":"data.shape # Dataset Shape and Size","1b3c9105":"# Most Frequent Items Bar plot\n\nplt.rcParams['figure.figsize'] = (10,6)\ncolor = plt.cm.inferno(np.linspace(0,1,20))\ndata[0].value_counts().head(20).plot.bar(color = color)\nplt.title('Top 20 Most Frequent Items')\nplt.ylabel('Counts')\nplt.xlabel('Items')\nplt.show()","d5d4e948":"# Tree Map of Most Frequent Items\nimport squarify\nplt.rcParams['figure.figsize']=(10,10)\nItems = data[0].value_counts().head(20).to_frame()\nsize = Items[0].values\nlab = Items.index\ncolor = plt.cm.copper(np.linspace(0,1,20))\nsquarify.plot(sizes=size, label=lab, alpha = 0.7, color=color)\nplt.title('Tree map of Most Frequent Items')\nplt.axis('off')\nplt.show()","f9e2314a":"data['Items'] = 'items'\ndf = data.truncate(before=-1,after=15)\n\nimport networkx as nx\n\nItems = nx.from_pandas_edgelist(df, source = 'Items', target = 0, edge_attr = True)\n\nplt.rcParams['figure.figsize'] = (20,20)\nnx.draw_networkx_nodes(G=Items,pos=nx.spring_layout(Items), node_size=15000,node_color='green')\nnx.draw_networkx_edges(G=Items,pos=nx.spring_layout(Items), alpha=0.6, width=3 ,edge_color='black')\nnx.draw_networkx_labels(G=Items,pos=nx.spring_layout(Items),font_size=20, font_family = 'sans-serif')\nplt.axis('off')\nplt.grid()\nplt.title('Top 15 First Choices', fontsize = 20)\nplt.show()","8b0f81fc":"data.drop(columns='Items',axis=1, inplace=True)\ndata.head()","5c3d879f":"# list of list is needed as an input for transaction encoder\ntransactions = []\nfor i in range(0,7501):\n    transactions.append([str(data.values[i,j]) for j in range(0,20)])","d2c19d6f":"# TransactionEncoder learns the unique labels in the dataset, and via the transform method, \n# it transforms the input dataset (a Python list of lists) into a one-hot encoded NumPy boolean array:\n\nfrom mlxtend.preprocessing import TransactionEncoder\ntransac = TransactionEncoder()\ndataset = transac.fit_transform(transactions)\ndataset","8820c3ba":"df = pd.DataFrame(dataset, columns= transac.columns_)\ndf.head()","f184a551":"#Apriori Algorithm to find out most frequent itemset with min support of 0.003\n\nfrom mlxtend.frequent_patterns import apriori, association_rules\nfrequent_itemsets = apriori(df, min_support=0.003, use_colnames=True)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x : len(x))\n","82fdcdd8":"frequent_itemsets.head(20)","00e92582":"#Filter Frequent itemset of minimum length 2\n\nfrequent_itemsets[frequent_itemsets['length'] >= 2].head(20)","6298cce4":"# Association Rules Mining to generate the rules with their coresponding support\nrules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\nrules.head(50)","06c29633":"rules[(rules['lift'] >= 5) & (rules['confidence'] >= 0.4)]","5acd671c":"#association analysis is easy to run and relatively easy to interpret. \n#the most frequent association itemset are mineral water and whole wheat pasta with \n#olive oil and people always buy this three items together!!!\n#more significant rules can be find with lower lift and confidence and suport!!!","887a0757":"**Import Dataset**","9e8696ab":"**Check Head of Dataset**","ddb61adf":"**Conclusion**","4f49c55a":"**Visualization**","13c1083e":"**Association Analysis** **And**\n**Apriori Algorithm** "}}