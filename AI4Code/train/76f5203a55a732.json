{"cell_type":{"cba13f4d":"code","76f70188":"code","c8f18c70":"code","6c51f566":"code","86e0789e":"code","116a3a99":"code","bc425020":"code","580c31f9":"code","1f04a763":"code","9601dc81":"code","081a866b":"code","362e4705":"code","be06c768":"code","39e531b6":"code","4d6f6069":"code","132e3735":"code","4e18e5c5":"code","c4853649":"code","1360f99f":"code","2c830c3f":"code","9be231cd":"code","777b9b51":"code","7be8f5e8":"code","d05b5e9b":"code","57a03ddb":"code","7b1e7900":"code","e38afb73":"code","62d4bcc3":"code","9eb214ab":"code","54a91856":"code","d6282dec":"code","45b85f76":"code","e54f7511":"code","73756282":"code","7f77e488":"code","c1f24d1c":"code","54b01b42":"code","72f22206":"code","b35e8d0d":"code","fad6efb0":"code","0aba98d4":"code","fa19f606":"code","61490902":"code","e54712af":"markdown","d858b1d1":"markdown","fc45b0ea":"markdown","bd345777":"markdown","c522ccbb":"markdown"},"source":{"cba13f4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","76f70188":"data = pd.read_csv(\"\/kaggle\/input\/forest-fires-in-brazil\/amazon.csv\" ,encoding='latin1')","c8f18c70":"data.head()","6c51f566":"data.shape","86e0789e":"data.info()","116a3a99":"data.describe().T","bc425020":"#checking if there are any nulls we are dealing with (missing data)\ndata.isna().sum()","580c31f9":"data.state.unique()","1f04a763":"data.month.unique()","9601dc81":"import seaborn as sns\nimport plotly.express as px\nimport geopandas as gpd\n\n\nimport folium\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\n\nimport matplotlib.pyplot as plt","081a866b":"latitude={'Acre':-9.02,'Alagoas':-9.57,'Amapa':02.05,'Amazonas':-5.00,'Bahia':-12.00,'Ceara':-5.00,\n          \n          'Distrito Federal':-15.45,'Espirito Santo':-20.00,'Goias':-15.55,'Maranhao':-5.00,'Mato Grosso':-14.00\n          \n          ,'Minas Gerais':-18.50,'Par\u00e1':-3.20,'Paraiba':-7.00,'Pernambuco':-8.00,'Piau':-7.00,'Rio':-22.90,\n          \n          'Rondonia':-11.00,'Roraima':-2.00,'Santa Catarina':-27.25,'Sao Paulo':-23.32,'Sergipe':-10.30,\n         \n         'Tocantins':-10.00\n         }\n\n\nlongitude={\n    'Acre':-70.8120,'Alagoas':-36.7820,'Amapa':-50.50,'Amazonas':-65.00,'Bahia':-42.00,'Ceara':-40.00,\n    \n    'Distrito Federal':-47.45,'Espirito Santo':-40.45,'Goias':-50.10,'Maranhao':-46.00,'Mato Grosso':-55.00,\n    \n    'Minas Gerais':-46.00,'Par\u00e1':-52.00,'Paraiba':-36.00,'Pernambuco':-37.00,'Piau':-73.00, 'Rio':-43.17,\n    \n    'Rondonia':-63.00,'Roraima':-61.30,'Santa Catarina':-48.30,'Sao Paulo':-46.37,'Sergipe':-37.30,\n    \n    'Tocantins':-48.00\n}\n\n","362e4705":"data['latitude']=data['state'].map(latitude)\ndata['longitude']=data['state'].map(longitude)\ndata","be06c768":"data.number.sum()","39e531b6":"'''Seaborn and Matplotlib Visualization'''\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\nimport geopandas as gpd            # Python Geospatial Data Library\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\n'''Plotly Visualizations'''\nimport plotly as plotly                # Interactive Graphing Library for Python\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\ninit_notebook_mode(connected=True)\n\n'''Spatial Visualizations'''\nimport folium\nimport folium.plugins\n\n'''NLP - WordCloud'''\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n'''Machine Learning'''\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor","4d6f6069":"plt.figure(figsize=(16,7))\nsns.distplot(data['number'])","132e3735":"plt.figure(figsize=(16,7))\nsns.scatterplot(x='year',y='number',data=data)","4e18e5c5":"plt.figure(figsize=(16,7))\nsns.scatterplot(x='month',y='number',data=data)","c4853649":"plt.figure(figsize=(10,6))\nsns.scatterplot(data.longitude,data.latitude)\nplt.ioff()","1360f99f":"fire_file_gpd=gpd.GeoDataFrame(data,geometry=gpd.points_from_xy(data['longitude'],data['latitude']))\nfire_file_gpd.crs={'init':'epsg:4326'}\n\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\namericas = world.loc[world['continent'].isin([ 'South America'])]\namericas=americas.loc[americas['name']=='Brazil']\n\nax = americas.plot(figsize=(10,10), color='white', linestyle=':', edgecolor='gray')\nfire_file_gpd.plot(ax=ax, markersize=50,color='red')\n","2c830c3f":"import folium\nfrom folium.plugins import HeatMap\nm=folium.Map([-14.23,-51.92],zoom_start=3)\nHeatMap(data[['latitude','longitude']].dropna(),radius=8,gradient={0.2:'blue',0.4:'purple',0.6:'orange',1.0:'red'}).add_to(m)\ndisplay(m)","9be231cd":"import folium\nfrom folium.plugins import MarkerCluster\nfrom folium import plugins\nprint(\"State With More Burn\")\nLong = 51.9253\nLat = 14.2350\nmapdf1 = folium.Map([Lat, Long], zoom_start=13)\nmapdf1_rooms_map=plugins.MarkerCluster().add_to(mapdf1)\n\nfor lat,lon, label in zip(data.latitude,data.longitude,data.state):\n    folium.Marker(location=[lat,lon],icon=folium.Icon(icon='home'),popup=label).add_to(mapdf1_rooms_map)\nmapdf1.add_child(mapdf1_rooms_map)\n\nmapdf1","777b9b51":"#we are already given the year column, however for good practice we can also extract it from the date one\ndata['Year']=pd.DatetimeIndex(data['date']).year\n#cheking unique years in new created column \ndata.Year.unique()","7be8f5e8":"#we are not going to be using old year column and date column as they serve no significant purpose anymore \n#amazon_df.drop(columns=['date', 'year'], axis=1, inplace=True)\n#changing order of columns for preffered format\n#amazon_df=amazon_df[['state','number','month','Year']]\n#changing names of columns for preffered format\n#amazon_df.rename(columns={'state': 'State', 'number': 'Fire_Number', 'month': 'Month'}, inplace=True)\n#checking changes made\n#amazon_df.head()\n","d05b5e9b":"plt.figure(figsize = (8,8))\nsns.heatmap(data.corr(),annot = True,linewidths = 0.5,cmap='cubehelix_r');\nplt.savefig('Correlation Heatmap.png')\n","57a03ddb":"year_fires=data[data.year==1998] # to see the monthly fires trend for year 1998\nyear_fires","7b1e7900":"# Function for displaying the map\ndef embed_map(m, file_name):\n    from IPython.display import IFrame\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='500px')\n\n# Create a base map\nm_4 = folium.Map(location=[-14.23,-51.92], tiles='cartodbpositron', zoom_start=4)\n\n\ndef color_producer(val):\n    if val =='january':\n        return 'darkred'\n    \n    elif val=='feburary':\n        return 'blue'\n    \n    elif val=='march':\n        return 'darkgreen'\n    \n    elif val=='april':\n        return 'green'\n    \n    elif val=='may':\n        return 'yellow'\n    \n    elif val=='june':\n        return 'orange'\n    \n    elif val=='july':\n        return 'red'\n    \n    elif val=='september':\n        return 'darkpurple'\n    \n    elif val=='october':\n        return 'black'\n    \n    elif val=='november':\n        return 'lightred'\n    elif val=='december':\n        return 'lightgreen'\n    \n    ","e38afb73":"# Add a bubble map to the base map\nfor i,row in year_fires.iterrows():\n    Circle(\n        location=[row['latitude'], row['longitude']],\n        radius=20,\n        color=color_producer(row['month'])).add_to(m_4)\n\n# Display the map\nembed_map(m_4, 'm_4.html')","62d4bcc3":"months_portugese=list(pd.unique(data['month']))\nmonths_english=['january','feburary','march','april','may','june','july','august','september','october','november','december']\ndict_month=dict(zip(months_portugese,months_english))\ndict_month","9eb214ab":"print(data[(data[\"state\"] == \"Rio\") & (data[\"year\"] == 1998)])\nprint(data[(data[\"state\"] == \"Amazonas\") & (data[\"year\"] == 1998)])","54a91856":"data['state'].value_counts()","d6282dec":"data[\"month\"].value_counts()","45b85f76":"data[(data[\"year\"] == 2017) & (data[\"state\"] == 'Acre')]","e54f7511":"amazonia_legal = ['Amazonas', 'Par\u00e1', 'Roraima', 'Amapa', 'Rondonia', 'Acre', 'Tocantins', 'Mato Grosso', 'Maranhao']\n\nestados = data.groupby('state')['number'].sum().sort_values(ascending=False)\n\nax = plt.gca()\ncolors = ['C0' if i not in amazonia_legal else 'r' for i in estados.index]\nestados.plot(kind='bar',ax=ax,color=colors, figsize=(10, 5))\nh,l = ax.get_legend_handles_labels()\nax.set_title(\"States with the largest fires\")\nax.set_ylabel('Number of fires')\nax.set_xlabel('States')\nax.legend([\"Amazonia Legal\", \"Other states\"], labelspacing=2)","73756282":"amazonia_legal = ['Amazonas', 'Par\u00e1', 'Roraima', 'Amapa', 'Rondonia', 'Acre', 'Tocantins', 'Mato Grosso', 'Maranhao']\n\nestados = data.groupby('month')['number'].sum().sort_values(ascending=False)\n\nax = plt.gca()\ncolors = ['C0' if i not in amazonia_legal else 'r' for i in estados.index]\nestados.plot(kind='bar',ax=ax,color=colors, figsize=(10, 5))\nh,l = ax.get_legend_handles_labels()\nax.set_title(\"States with the largest fires\")\nax.set_ylabel('Number of fires')\nax.set_xlabel('States')\nax.legend([\"Amazonia Legal\", \"Other states\"], labelspacing=2)","7f77e488":"meses_incendio = data.groupby('month')['number'].sum()\nmeses_incendio_amazonia = data[data.state.isin(amazonia_legal)].groupby('month')['number'].sum()\n\nax = plt.gca()\nmeses_incendio.plot(kind='bar',x='month',y='number', ax=ax, stacked=True, figsize=(10, 5))\nmeses_incendio_amazonia.plot(kind='bar',x='month',y='number', ax=ax, stacked=True, color='r', figsize=(10, 5))\nax.set_title(\"Total fires and fires in Amazonia\")\nax.set_ylabel('Number of fires')\nax.set_xlabel('Month')\nax.legend([\"Total fires\", \"Fires in Amazon\"])","c1f24d1c":"#Total Number  on each state in descending order\ndata.groupby('state').sum().sort_values(by='number',ascending=False)[['number']].plot(kind='bar',figsize=(16,8),title='Total Number By State')","54b01b42":"#Total Number on each state in descending order\ndata.groupby('month').sum().sort_values(by='number',ascending=False)[['number']].plot(kind='bar',figsize=(16,8),title='Total Number By State')","72f22206":"def annual_analysis_for_state(state_name):\n\n    states=data.groupby('state') # gropuing dataframe state wise\n\n    state_name_group=states.get_group(str(state_name))# statename\n\n    state_name_year=state_name_group.groupby('year')# Year by Groups\n\n    years=list(data.year.unique())# list of years from 1998 to 2019\n\n    total_annual_fires=[]# list to calculate numnber of forest fires from 1998 to 2019 \n\n\n    for year in years:\n        total_annual_fires.append(state_name_year.get_group(year).number.sum())\n    years_df=pd.DataFrame(data={'Years':years,\n                                'Total_Fires':total_annual_fires})\n\n    plt.figure(figsize=(20,10))\n\n\n    fig = px.bar(years_df, x='Years', y='Total_Fires',color='Total_Fires')\n\n    fig.update_layout(\n        title=\"TRENDS OF FOREST FIRES IN \"+str(state_name.upper()),\n        xaxis_title=\"YEARS\",\n        yaxis_title=\"TOTAL NUMBER OF FIRES\",\n        font=dict(\n            family=\"Courier New\",\n            size=18,\n            color=\"black\"\n        )\n    )\n    fig.show()\n","b35e8d0d":"annual_analysis_for_state('Rio')#put the name of state here","fad6efb0":"months_portugese=list(pd.unique(data['month']))\nmonths_english=['january','feburary','march','april','may','june','july','august','september','october','november','december']\ndict_month=dict(zip(months_portugese,months_english))\ndict_month","0aba98d4":"data.month=data['month'].map(dict_month)\ndata","fa19f606":"def monthly_fires_for_states(state_name,year_name):\n    states=data.groupby('state')\n    state_name_group=states.get_group(str(state_name))\n    state_name_year=state_name_group.groupby('year')\n    year_X=state_name_year.get_group(year_name)\n    month_X=year_X.groupby('month')\n    months=['january','feburary','march','april','may','june','july','august','september','october','november','december']\n\n    monthly_fires=[]\n    for month in months:\n        monthly_fires.append(month_X.get_group(month).number.sum())\n\n\n    annual_df=pd.DataFrame(data={\n        'Months':months,\n        'Monthly_fires':monthly_fires\n    })\n    plt.figure(figsize=(20,8))\n\n    fig = px.bar(annual_df, x='Months', y='Monthly_fires',color='Monthly_fires')\n\n    title=\"MONTHLY TRENDS OF FOREST FIRES IN \"+str(state_name.upper()+\" FOR YEAR \"+str(year_name))\n    fig.update_layout(\n        title=title,\n        xaxis_title=\"MONTHS\",\n        yaxis_title=\"TOTAL NUMBER OF FIRES\",\n        font=dict(\n            family=\"Courier New\",\n            size=18,\n            color=\"black\"\n        )\n    )\n    fig.show()\n","61490902":"# monthly analysis for STATE OF RIO in year 2010\nmonthly_fires_for_states('Rio',2010)# put the name of state and year","e54712af":"# MONTHLY ANALYSIS FOR FOREST FIRES IN EACH STATE ","d858b1d1":"## Print Some Selecte Data ","fc45b0ea":"## Latitude and Longitude for states of Brazil","bd345777":"\n#### Exploring and Visualizing Data\n\nExploring the data by analyzing its statistics and visualizing the values of features and correlations between different features. Explaining the process and the results\n","c522ccbb":"### Now we have same quantity of datas."}}