{"cell_type":{"01b3e64c":"code","c7c0d3fa":"code","4ffe29f7":"code","9d2e0de5":"code","3f13e940":"code","4f16d305":"code","618976c0":"code","077abc80":"code","e78ff6d4":"code","0eb189c1":"code","f74bdf6e":"code","17e6c6b5":"code","619df6d4":"code","0c3be440":"code","4778885e":"code","49cbc00e":"code","f7f1d722":"code","c3908bfa":"code","10c1176a":"code","964f35b3":"code","fec7e00c":"code","dd78d675":"code","469a7ca5":"code","b9e4a9d5":"code","06b11623":"code","9cad72d3":"markdown","3de773c6":"markdown","ef22d2b7":"markdown","3c7e4bdf":"markdown","53f33c56":"markdown","66fd51b0":"markdown","021129e1":"markdown","abdf0805":"markdown","3131103b":"markdown","9429ac66":"markdown","d963a834":"markdown","f31b3eab":"markdown","46a2c8ee":"markdown","036acbff":"markdown","35d10a03":"markdown","e06ee770":"markdown","73938a2d":"markdown","7c0c06cc":"markdown","9c210794":"markdown","27b139c9":"markdown","b3b86206":"markdown","a1f0639f":"markdown","3b267e1d":"markdown"},"source":{"01b3e64c":"!nvidia-smi","c7c0d3fa":"!nvcc --version","4ffe29f7":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","9d2e0de5":"!pip install detectron2 -f \\\n  https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu110\/torch1.7\/index.html","3f13e940":"import numpy as np \nimport pandas as pd \nfrom datetime import datetime\nimport time\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nimport matplotlib.pyplot as plt\n\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nimport pickle\nfrom pathlib import Path\nfrom typing import Optional\nfrom tqdm import tqdm\n\n# torch\nimport torch\n\n\n\n# Albumenatations\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#from pycocotools.coco import COCO\nfrom sklearn.model_selection import StratifiedKFold\n\n# glob\nfrom glob import glob\n\n# numba\nimport numba\nfrom numba import jit\n\nimport warnings\nwarnings.filterwarnings('ignore') #Ignore \"future\" warnings and Data-Frame-Slicing warnings.\n\n\n# detectron2\nfrom detectron2.structures import BoxMode\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import Visualizer\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\n\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\nsetup_logger()","4f16d305":"# --- Read data ---\nimgdir = \"..\/input\/nfl-health-and-safety-helmet-assignment\/images\"\n# Read in the data CSV files\ntrain_df = pd.read_csv(\"..\/input\/nfl-health-and-safety-helmet-assignment\/image_labels.csv\")\nprint('Number of ground truth bounding boxes: ', len(train_df))\n# Number of unique labels\n\n\n\ncategory_name_to_id  = {label: i for i, label in enumerate(train_df.label.unique())}\nprint('Classes_id: ', category_name_to_id )\n\nthing_classes=['Helmet','Helmet-Blurred','Helmet-Difficult','Helmet-Sideline','Helmet-Partial']\nprint('Classes: ', thing_classes )","618976c0":"train_df[\"Fold\"]=\"train\"\ntrain_df.head()","077abc80":"debug=False\nsplit_mode=\"valid20\" # all_train Or  valid20 \nimage_Width=1280\nimage_Height=720\n\nnum_folds=5\nSelected_fold=1 #1,2,3,4,5 ","e78ff6d4":"train_meta = pd.DataFrame(train_df.image.unique(), columns = ['image'])\ntrain_meta[\"width\"]=image_Width\ntrain_meta[\"height\"]=image_Height\ntrain_meta","0eb189c1":"from sklearn.model_selection import KFold,StratifiedKFold\nsfolder = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\nX = train_df[['image']]\ny = train_df[['label']]\n\nfold_no = 1\nfor train, valid in sfolder.split(X,y):\n    if fold_no==Selected_fold:\n        train_df.loc[valid, \"Fold\"] = \"valid\"\n    fold_no += 1","f74bdf6e":"df_train=train_df[train_df.Fold==\"train\"]\ndf_valid=train_df[train_df.Fold==\"valid\"]\nprint(\"length df_train=\",len(df_train),\"-- length df_valid=\",len(df_valid))","17e6c6b5":"from glob import glob\n\ndef get_NFL_data_dicts(\n    imgdir: Path,\n    train_df: pd.DataFrame,\n    train_meta: pd.DataFrame,\n    use_cache: bool = True,\n    target_indices: Optional[np.ndarray] = None,\n    debug: bool = False,\n    data_type:str=\"train\"\n   \n):\n\n    cache_path = Path(\".\") \/ f\"dataset_dicts_cache_{data_type}.pkl\"\n    if not use_cache or not cache_path.exists():\n        print(\"Creating data...\")\n        if debug:\n            train_meta = train_meta.iloc[:100]  # For debug....\n\n        dataset_dicts = []\n        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n            record = {}\n            image_id, width,height = train_meta_row.values\n            filename = str(f'{imgdir}\/{image_id}')\n            record[\"file_name\"] = filename\n            record[\"image_id\"] = image_id\n            record[\"width\"] = width\n            record[\"height\"] = height\n            \n            objs = []\n            for index2, row in train_df.query(\"image == @image_id\").iterrows():\n\n                class_id = category_name_to_id[row[\"label\"]]\n                bbox_resized = [\n                    float(row[\"left\"]), # x_min\n                    float(row[\"top\"]), # y_min\n                    float(row[\"left\"]) + float(row[\"width\"]),#x_max\n                    float(row[\"top\"]) + float(row[\"height\"]),#y_max\n                ]\n                obj = {\n                    \"bbox\": bbox_resized,\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"category_id\": class_id,\n                }\n                objs.append(obj)\n            record[\"annotations\"] = objs\n            dataset_dicts.append(record)\n        with open(cache_path, mode=\"wb\") as f:\n            pickle.dump(dataset_dicts, f)\n\n    print(f\"Load from cache {cache_path}\")\n    with open(cache_path, mode=\"rb\") as f:\n        dataset_dicts = pickle.load(f)\n    if target_indices is not None:\n        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n    return dataset_dicts\n\n\n","619df6d4":"Data_Resister_training=\"NFL_data_train\";\nData_Resister_valid=\"NFL_data_valid\";\n\nif split_mode == \"all_train\":\n    DatasetCatalog.register(\n        Data_Resister_training,\n        lambda: get_NFL_data_dicts(\n            imgdir,\n            train_df,\n            \n            debug=debug,\n            data_type=\"train\"\n        ),\n    )\n    MetadataCatalog.get(Data_Resister_training).set(thing_classes=thing_classes)\n    \n    \n    dataset_dicts_train = DatasetCatalog.get(Data_Resister_training)\n    metadata_dicts_train = MetadataCatalog.get(Data_Resister_training)\n    \n    \nelif split_mode == \"valid20\":\n\n    n_dataset = len(\n        get_NFL_data_dicts(\n            imgdir, train_df,train_meta, debug=debug,data_type=\"All\"\n        )\n    )\n    n_train = int(n_dataset * 0.90)\n    print(\"n_dataset\", n_dataset, \"n_train\", n_train)\n    rs = np.random.RandomState(42)\n    inds = rs.permutation(n_dataset)\n    train_inds, valid_inds = inds[:n_train], inds[n_train:]\n\n    DatasetCatalog.register(\n        Data_Resister_training,\n        lambda: get_NFL_data_dicts(\n            imgdir,\n            train_df,\n            train_meta,\n            target_indices=train_inds,\n            debug=debug,\n            data_type=\"train\"\n        ),\n    )\n    MetadataCatalog.get(Data_Resister_training).set(thing_classes=thing_classes)\n    \n\n    DatasetCatalog.register(\n        Data_Resister_valid,\n        lambda: get_NFL_data_dicts(\n            imgdir,\n            train_df,\n            train_meta,\n            target_indices=valid_inds,\n            debug=debug,\n            data_type=\"val\"\n            ),\n        )\n    MetadataCatalog.get(Data_Resister_valid).set(thing_classes=thing_classes)\n    \n    dataset_dicts_train = DatasetCatalog.get(Data_Resister_training)\n    metadata_dicts_train = MetadataCatalog.get(Data_Resister_training)\n\n    dataset_dicts_valid = DatasetCatalog.get(Data_Resister_valid)\n    metadata_dicts_valid = MetadataCatalog.get(Data_Resister_valid)\n    \nelse:\n    raise ValueError(f\"[ERROR] Unexpected value split_mode={split_mode}\")","0c3be440":"fig = plt.figure(figsize =(40,20))\nax = fig.add_subplot(1,1,1)\n\nd=dataset_dicts_train[12]   \nimg = cv2.imread(d[\"file_name\"])\nv = Visualizer(img[:, :, ::-1],\n                metadata=metadata_dicts_train, \n                scale=0.7, \n                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\nout = v.draw_dataset_dict(d)\nax.grid(False)\nax.axis('off')\nax.imshow(out.get_image()[:, :, ::-1])","4778885e":"def custom_mapper(dataset_dict):\n    \n    dataset_dict = copy.deepcopy(dataset_dict)\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [T.RandomBrightness(0.8, 1.2),\n                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False)\n                      ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict\nclass AugTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","49cbc00e":"cfg = get_cfg()\nconfig_name = \"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\" \n#config_name = \"COCO-Detection\/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\n#config_name = \"COCO-Detection\/faster_rcnn_R_101_C4_3x.yaml\"\n\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\n\ncfg.DATASETS.TRAIN = (Data_Resister_training,)\n\nif split_mode == \"all_train\":\n    cfg.DATASETS.TEST = ()\nelse:\n    cfg.DATASETS.TEST = (Data_Resister_valid,)\n    cfg.TEST.EVAL_PERIOD = 1000\n\ncfg.DATALOADER.NUM_WORKERS = 0\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n#cfg.MODEL.WEIGHTS=\"..\/input\/nfl-extra-images-detectron2-weights\/output\/model_final.pth\"\n\n\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.0025\n\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 20000 #adjust up if val mAP is still rising, adjust down if overfit\n#cfg.SOLVER.STEPS = (100, 500) # must be less than  MAX_ITER \n#cfg.SOLVER.GAMMA = 0.05\n\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 100000  # Small value=Frequent save need a lot of storage.\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n\n#Training using custom trainer defined above\ntrainer = AugTrainer(cfg) \n#trainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","f7f1d722":"evaluator = COCOEvaluator(Data_Resister_valid, cfg, False, output_dir=\".\/output\/\")\n#cfg.MODEL.WEIGHTS=\".\/output\/model_final.pth\"\n#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.001   # set a custom testing threshold\nval_loader = build_detection_test_loader(cfg, Data_Resister_valid)\ninference_on_dataset(trainer.model, val_loader, evaluator)","c3908bfa":"import pandas as pd\nmetrics_df = pd.read_json(\".\/output\/metrics.json\", orient=\"records\", lines=True)\nmdf = metrics_df.sort_values(\"iteration\")\nmdf.head(10).T","10c1176a":"fig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"total_loss\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\nif \"validation_loss\" in mdf.columns:\n    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"], c=\"C1\", label=\"validation\")\n\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Loss curve\")\nplt.show()","964f35b3":"\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"fast_rcnn\/cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn\/cls_accuracy\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Accuracy curve\")\nplt.show()","fec7e00c":"fig, ax = plt.subplots()\nmdf1 = mdf[~mdf[\"loss_box_reg\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"loss_box_reg\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"loss_box_reg\")\nplt.show()","dd78d675":"fig, ax = plt.subplots()\nmdf1 = mdf[~mdf[\"loss_rpn_cls\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"loss_rpn_cls\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"loss_rpn_cls\")\nplt.show()","469a7ca5":"fig, ax = plt.subplots()\nmdf1 = mdf[~mdf[\"fast_rcnn\/fg_cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn\/fg_cls_accuracy\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"fg_cls_accuracy\")\nplt.show()","b9e4a9d5":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n#cfg.MODEL.WEIGHTS = \"...\/model_final.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.03   # set a custom testing threshold for this model\ncfg.DATASETS.TEST = (\"Data_Resister_valid\", )\npredictor = DefaultPredictor(cfg)","06b11623":"fig, ax = plt.subplots(2, 2, figsize =(20,20))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1] ]\ni=-1\n# Show some qualitative results by predicting on test set images\nNUM_TEST_SAMPLES = 4\nsamples = random.sample(dataset_dicts_valid, NUM_TEST_SAMPLES)\nfor i, sample in enumerate(samples):\n    img = cv2.imread(sample[\"file_name\"])\n    outputs = predictor(img)\n    visualizer = Visualizer(img, metadata=metadata_dicts_valid,scale=0.5,)\n    visualizer = visualizer.draw_instance_predictions(\n        outputs[\"instances\"].to(\"cpu\"))\n    display_img = visualizer.get_image()[:, :, ::-1]\n    indices[i].grid(False)\n    indices[i].imshow(display_img)","9cad72d3":"* It seems CUDA=11.0 and torch==1.7.0 is used in this kaggle docker image.\n* See installation for details. https:\/\/detectron2.readthedocs.io\/en\/latest\/tutorials\/install.html","3de773c6":"## fg_cls_accuracy","ef22d2b7":"* Famouns dataset's evaluator is already implemented in detectron2.\n* For example, many kinds of AP (Average Precision) is calculted in COCOEvaluator.\n* COCOEvaluator only calculates AP with IoU from 0.50 to 0.95","3c7e4bdf":"# Predictor","53f33c56":"<a id=\"data_vis\"><\/a>\n# Data Visualization\n\nIt's also very easy to visualize prepared training dataset with `detectron2`.<br\/>\nIt provides `Visualizer` class, we can use it to draw an image with bounding box as following.","66fd51b0":"# Install Pre-Built Detectron2","021129e1":"# References\n1. https:\/\/www.kaggle.com\/ammarnassanalhajali\/training-detectron2-for-blood-cells-detection\n1. https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-covid-19-detectron2-training\n","abdf0805":"# Data Augmentation\nThe dataset is transformed by changing the brighness and flipping the image with 50% probability.","3131103b":"# Installation\n* detectron2 is not pre-installed in this kaggle docker, so let's install it.\n* we need to know CUDA and pytorch version to install correct detectron2.","9429ac66":"### Hi kagglers, This is `training` notebook using `Detectron2`.\n\n### Other notebooks \n- [NFL Big Data Bowl 2021:Animating Players](https:\/\/www.kaggle.com\/ammarnassanalhajali\/nfl-big-data-bowl-2021-animating-players)\n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>\n","d963a834":"# Folds","f31b3eab":"## cls_accuracy","46a2c8ee":"# configs","036acbff":"# Import Libraries","35d10a03":"## loss_rpn_cls","e06ee770":"# Data preparation\n* `detectron2` provides high-level API for training custom dataset.\n\nTo define custom dataset, we need to create **list of dict** (`dataset_dicts`) where each dict contains following:\n\n - file_name: file name of the image.\n - image_id: id of the image, index is used here.\n - height: height of the image.\n - width: width of the image.\n - annotation: This is the ground truth annotation data for object detection, which contains following\n     - bbox: bounding box pixel location with shape (n_boxes, 4)\n     - bbox_mode: `BoxMode.XYXY_ABS` is used here, meaning that absolute value of (x_min, y_min, x_max, y_max) annotation is used in the `bbox`.\n     - category_id: class label id for each bounding box, with shape (n_boxes,)\n\n`get_COVID19_data_dicts` is for train dataset preparation and `get_COVID19_data_dicts_test` is for test dataset preparation.","73938a2d":"## loss_box_reg","7c0c06cc":"# ** Training NFL Extra Images Detectron2 **","9c210794":"## total_loss","27b139c9":"# Detectron2\nDetectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark.","b3b86206":"# Data Loading","a1f0639f":"# Evaluator","3b267e1d":"# Training"}}