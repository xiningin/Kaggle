{"cell_type":{"e624c9d8":"code","6e9b0916":"code","ed6a7689":"code","d461a63f":"code","b7fff87a":"code","7984de9d":"code","10db2778":"code","a04f9279":"code","56c1e893":"code","233f7efa":"code","9d609cf8":"code","2cfe944d":"code","80eab3a1":"code","aa340fbf":"code","15ea14d0":"code","aac04c61":"code","46749463":"code","0260aa5e":"code","2fd64e38":"code","82b9f8fb":"code","51f1ece8":"code","1a007086":"code","35092e7f":"code","dea68be4":"code","c89c7d85":"code","4b67e6e2":"code","43abaef9":"code","39aae073":"code","418ad817":"code","d3510b1c":"code","1280607b":"code","e0fb0738":"code","6d0b775c":"code","e3f5ac83":"code","3e939f70":"code","0c69eca8":"code","c4b93af7":"code","b746f891":"code","0dd2026c":"code","f836c9eb":"code","32cc305d":"code","704a6831":"code","1a4f0263":"code","109d005d":"code","b4e30035":"code","ffe83eea":"code","486e505f":"code","bd9a3ae5":"code","87812ae4":"code","17eac0f1":"code","3058c79b":"code","5880ca92":"code","39da9771":"code","4b9bebfd":"code","4fc9c459":"code","d5a78864":"code","ea4912c4":"code","399ba4aa":"code","b6de7298":"code","3259e0af":"code","072a7db4":"code","b2160520":"code","af4a437b":"code","df3ff059":"code","0a677079":"code","d6dd6e6c":"code","e9498419":"code","deef34b5":"code","cb5fc9c4":"code","5889617b":"code","b1f72310":"code","3b520adf":"code","154766b9":"code","8ec90d51":"code","3e34f9d4":"code","32ad06b8":"code","5d524488":"code","a083cd89":"code","8976db24":"code","b010e285":"markdown","6bebd424":"markdown","cd894f26":"markdown","0f62d6b1":"markdown","9efcc261":"markdown","0a6b70cd":"markdown","40374e79":"markdown","1bdc49ae":"markdown","aaa730d1":"markdown","d55639b0":"markdown","d63e281a":"markdown","fc09644e":"markdown","f21ef362":"markdown","18e728d0":"markdown","e2e0fbbf":"markdown","c0587b2b":"markdown","9226c8e1":"markdown","8df5fa90":"markdown","a336813d":"markdown","cb16d68c":"markdown","2e7d7d29":"markdown","8b3c03ca":"markdown"},"source":{"e624c9d8":"# importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt  \nfrom tqdm.notebook import tqdm\nimport plotly.graph_objects as go\nimport os\nfrom urllib.parse import urlparse\n%matplotlib inline\nfrom IPython.display import Image \nsns.set()","6e9b0916":"os.listdir('..\/input\/google-quest-challenge')","ed6a7689":"# reading the data into dataframe using pandas\ntrain = pd.read_csv('..\/input\/google-quest-challenge\/train.csv')\ntest = pd.read_csv('..\/input\/google-quest-challenge\/test.csv')\nsubmission = pd.read_csv('..\/input\/google-quest-challenge\/sample_submission.csv')","d461a63f":"# Let's check the top 5 entries of train data.\ntrain.head()","b7fff87a":"# Let's check the statistical description of the numerical features in train data\ntrain.describe()","7984de9d":"train.iloc[:, 11:].columns","10db2778":"# let's check the unique values in target features\nnp.unique(train.iloc[:, 11:].values)","a04f9279":"# These are the features provided in the test data\ntest.columns","56c1e893":"# these are the features that we need to include while submitting the results\nsubmission.columns","233f7efa":"Image('..\/input\/google-quest-qna-eda-img\/url.png', width=920, height=480)","9d609cf8":"# A text feature that represents the title of the question.\ntrain['question_title'].head()","2cfe944d":"# Let's calculate the length of each question title\nlength = train['question_title'].apply(lambda x:len(x.split(' ')))","80eab3a1":"length.describe()","aa340fbf":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length)], \n                layout = go.Layout(title='histogram of length of question title in train data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","15ea14d0":"test['question_title'].head()","aac04c61":"# Let's calculate the length of each question title\nlength = test['question_title'].apply(lambda x:len(x.split(' ')))","46749463":"length.describe()","0260aa5e":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length)], \n                layout = go.Layout(title='histogram of length of question title in test data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","2fd64e38":"# this is another and the main text feature that represents the full description of the question asked\ntrain['question_body'].head()","82b9f8fb":"# Lets check the length of the questions body\nlength = train['question_body'].apply(lambda x:len(x.split(' ')))","51f1ece8":"length.describe()","1a007086":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length, marker_color='#39f79b')], \n                layout = go.Layout(title='histogram of length of question body in train data',\n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","35092e7f":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length), marker_color='#39f79b')], \n                layout = go.Layout(title='histogram of log of length of question body in train data', \n                                  xaxis=dict(title='log of length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","dea68be4":"test['question_body'].head()","c89c7d85":"# length of question in test data\nlength = test['question_body'].apply(lambda x:len(x.split(' ')))","4b67e6e2":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length, marker_color='#39f79b')], \n                layout = go.Layout(title='histogram of length of question body in test data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","43abaef9":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length), marker_color='#39f79b')], \n                layout = go.Layout(title='histogram of log of length of question body in test data', \n                                  xaxis=dict(title='log of length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","39aae073":"train['question_user_name'].head()","418ad817":"train['answer_user_name'].head()","d3510b1c":"# Another important text type feature that represents the answers that given to the questions.\ntrain['answer'].head()","1280607b":"# Length of answers\nlength = train['answer'].apply(lambda x:len(x.split(' ')))","e0fb0738":"length.describe()","6d0b775c":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length, marker_color='#eb4034')], \n                layout = go.Layout(title='histogram of length of answer in train data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","e3f5ac83":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length), marker_color='#eb4034')], \n                layout = go.Layout(title='histogram of log of length of answer in train data', \n                                  xaxis=dict(title='log of length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","3e939f70":"test['answer'].head()","0c69eca8":"length = test['answer'].apply(lambda x:len(x.split(' ')))","c4b93af7":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=length, marker_color='#eb4034')], \n                layout = go.Layout(title='histogram of length of answer in test data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","b746f891":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length), marker_color='#eb4034')], \n                layout = go.Layout(title='histogram of length of answer in test data', \n                                  xaxis=dict(title='length of sentences'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","0dd2026c":"# This feature represents the category that the question answer pair belong to.\ntrain['category'].head(10)","f836c9eb":"# There are 5 categories\ntrain['category'].value_counts()","32cc305d":"categories = train['category'].value_counts()\nfig = go.Figure([go.Pie(labels=categories.keys(), values=categories)])\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\nfig.update_layout(title_text=\"'category' Pie chart for train data\",\n                  annotations=[dict(text='category', x=0.5, y=0.5, \n                                    font_size=20, showarrow=False)])\nfig.show()","704a6831":"# This feature represents the category that the question answer pair belong to.\ntest['category'].head(10)","1a4f0263":"# There are 5 categories\ntest['category'].value_counts()","109d005d":"categories = test['category'].value_counts()\nfig = go.Figure([go.Pie(labels=categories.keys(), values=categories)])\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\nfig.update_layout(title_text=\"'category' Pie chart for test data\",\n                  annotations=[dict(text='category', x=0.5, y=0.5, \n                                    font_size=20, showarrow=False)])\nfig.show()","b4e30035":"# this feature represents the host\/domain name of the question answer page url.\ntrain['host'].head(10)","ffe83eea":"# We can see that there are 63 type of these host names\ntrain.host.value_counts()","486e505f":"categories = train['host'].value_counts()\nfig = go.Figure([go.Pie(labels=categories.keys(), values=categories)])\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\nfig.update_layout(title_text=\"'host' Pie chart for train data\",\n                  annotations=[dict(text='host', x=0.5, y=0.5, \n                                    font_size=20, showarrow=False)])\nfig.show()","bd9a3ae5":"# this feature represents the host\/domain name of the question answer page url.\ntest['host'].head(10)","87812ae4":"# We can see that there are 63 type of these host names\ntest.host.value_counts()","17eac0f1":"categories = test['host'].value_counts()\nfig = go.Figure([go.Pie(labels=categories.keys(), values=categories)])\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\nfig.update_layout(title_text=\"'host' Pie chart for test data\",\n                  annotations=[dict(text='host', x=0.5, y=0.5, \n                                    font_size=20, showarrow=False)])\nfig.show()","3058c79b":"Image('..\/input\/google-quest-qna-eda-img\/posts.png', width=920, height=480)","5880ca92":"Image('..\/input\/google-quest-qna-eda-img\/upvotes_comments.png', width=920, height=480)","39da9771":"train['url'].head(10)","4b9bebfd":"# function for scraping the answers and their topmost comment. \n# Since all of the urls are of stackoverflow, they have the same html hierarchy.\ndef get_answers_comments(url): \n  try:\n    get = request.urlopen(url).read() # read the html data from the url page\n    src = BeautifulSoup(get, 'html.parser') # convert the data into a beautifulsoup object\n    upvotes, answer = [], [] \n    correct_ans, comments = [], []\n    new_features = []\n    post_layout = src.find_all(\"div\", class_ = 'post-layout') # Collecting all the posts from the page\n    l = len(post_layout) # number of answers present\n    for p in post_layout[:l]: # collecting answer, upvotes, comments from posts\n      answer.append(p.find_all('div', class_='post-text')[0].text.strip())\n      upvotes.append(int(p.find_all(\"div\", class_ = 'js-vote-count grid--cell fc-black-500 fs-title g rid fd-column ai-center')[0].get('data-value')))\n      correct_ans.append(len(p.find_all(\"div\", class_ = 'js-accepted-answer-indicator grid--cell fc-g reen-500 ta-center py4')))\n      comments.append('\\n'.join([i.text.strip() for i in p.find_all('span', class_='comment-copy')]))\n    idx = np.argmax(correct_ans) # index of the correct answer among all the posts\n    new_features.append(upvotes.pop(idx)) # correct answer's upvotes\n    new_features.append(comments.pop(idx)) # correct answer's comments\n    del answer[idx]\n    # collecting the answer and top comment from the top 3 posts apart from the one already provided in train.csv\n    if l < 3: k=l\n    else: k=3\n    for a,b in zip(answer[:k], comments[:k]): \n      new_features.append(a) \n      new_features.append(b)\n    for a,b in zip(answer[:3-k], comments[:3-k]): \n      new_features.append('') \n      new_features.append('')\n\n    return new_features\n    \n  except:\n    return [np.nan]*8 # return np.nan if the code runs into some error like page not found","4fc9c459":"Image('..\/input\/google-quest-qna-eda-img\/user.png', width=920, height=480)","d5a78864":"train['question_user_page'].head()","ea4912c4":"train['answer_user_page'].head()","399ba4aa":"# code for scraping the data. Since all of the urls are of stackoverflow, they have the same html hierarchy.\ndef get_user_rating(url):\n  try:\n    get = request.urlopen(url).read()\n    src = BeautifulSoup(get, 'html.parser')\n    reputation, gold = [], []\n    silver, bronze = [], []\n    template = src.find_all(\"div\", class_ = 'grid--cell fl-shrink0 ws2 overflow-hidden')[0] \n    reputation = int(''.join(template.find_all('div', class_='grid--cell fs-title fc-dark')[0].text.strip().split(',')))\n    gold = int(''.join(template.find_all('div', class_='grid ai-center s-badge s-badge__gold')[0].text.strip().split(',')))\n    silver = int(''.join(template.find_all('div', class_='grid ai-center s-badge s-badge__silver')[0].text.strip().split(',')))\n    bronze = int(''.join(template.find_all('div', class_='grid ai-center s-badge s-badge__bronze')[0].text.strip().split(',')))\n    output = [reputation, gold, silver, bronze] \n  except:\n    output = [np.nan]*4 # return np.nan if the code runs into some error like page not found return output\n\n  return output","b6de7298":"a = [[1,2],[3,4]]\nb = [[4,5,6],[7,8,9]]\nnp.hstack((a,b))","3259e0af":"from tqdm.notebook import tqdm\ndef scrape_data(df):\n    answers_comments = []\n    for url in tqdm(df['url']):\n      answers_comments.append(get_answers_comments(url))\n    question_user_rating = []\n    for url in tqdm(df['question_user_page']):\n      question_user_rating.append(get_user_rating(url))\n    answer_user_rating = []\n    for url in tqdm(df['answer_user_page']):\n      answer_user_rating.append(get_user_rating(url))\n    \n    return np.hstack((answerd_comments, user_rating, answer_user_rating))\n\n# # Saving as dataframe\n# columns = ['upvotes', 'comments_0', 'answer_1', 'comment_1', 'answer_2','comment_2',\n#             'answer_3', 'comment_3', 'reputation_q', 'gold_q','silver_q', 'bronze_q', \n#             'reputation_a', 'gold_a', 'silver_a','bronze_a']\n# scraped_train = pd.DataFrame(scrape_data(train), columns=columns)\n# scraped.to_csv(f'scraped_train.csv', index=False)\n# scraped_test = pd.DataFrame(scrape_data(train), columns=columns)\n# scraped.to_csv(f'scraped_test.csv', index=False)","072a7db4":"# Since I've already scraped the data once, I'll use that for the further analysis\nscraped_train = pd.read_csv('..\/input\/google-quest-qna-scraped-data\/scraped_features_train.csv')\nscraped_test = pd.read_csv('..\/input\/google-quest-qna-scraped-data\/scraped_features_test.csv')","b2160520":"scraped_train.head()","af4a437b":"upvotes = scraped_train['upvotes'].replace(' ', np.nan).dropna().apply(lambda x:int(x.split('.')[0]))","df3ff059":"# histogram of upvotes\nplt = go.Figure(data=[go.Histogram(x=upvotes, marker_color='#00a0a0')], \n                layout = go.Layout(title='histogram upvotes for train data', \n                                  xaxis=dict(title='upvotes count'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","0a677079":"upvotes = scraped_test['upvotes'].replace(' ', np.nan).dropna().apply(lambda x:int(x.split('.')[0]))","d6dd6e6c":"# histogram of length of question titles\nplt = go.Figure(data=[go.Histogram(x=upvotes, marker_color='#00a0a0')], \n                layout = go.Layout(title='histogram upvotes for test data', \n                                  xaxis=dict(title='upvotes count'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","e9498419":"length_c0 = scraped_train['comments_0'].apply(lambda x:len(x.split(' ')))\nlength_c1 = scraped_train['comment_1'].apply(lambda x:len(x.split(' ')))\nlength_c2 = scraped_train['comment_2'].apply(lambda x:len(x.split(' ')))\nlength_c3 = scraped_train['comment_3'].apply(lambda x:len(x.split(' ')))","deef34b5":"# histogram of length of comments\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length_c0), marker_color='#941759', name='comment_0'),\n                      go.Histogram(x=np.log1p(length_c1), marker_color='#386082', name='comment_1'),\n                      go.Histogram(x=np.log1p(length_c2), marker_color='#789501', name='comment_2'),\n                      go.Histogram(x=np.log1p(length_c3), marker_color='#e80995', name='comment_3')], \n                layout = go.Layout(title='histogram of log of length of comments for train data', \n                                  xaxis=dict(title='comment length'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","cb5fc9c4":"length_c0 = scraped_test['comments_0'].apply(lambda x:len(x.split(' ')))\nlength_c1 = scraped_test['comment_1'].apply(lambda x:len(x.split(' ')))\nlength_c2 = scraped_test['comment_2'].apply(lambda x:len(x.split(' ')))\nlength_c3 = scraped_test['comment_3'].apply(lambda x:len(x.split(' ')))","5889617b":"# histogram of length of comments\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length_c0), marker_color='#941759', name='comment_0'),\n                      go.Histogram(x=np.log1p(length_c1), marker_color='#386082', name='comment_1'),\n                      go.Histogram(x=np.log1p(length_c2), marker_color='#789501', name='comment_2'),\n                      go.Histogram(x=np.log1p(length_c3), marker_color='#e80995', name='comment_3')], \n                layout = go.Layout(title='histogram of log of length of comments for test data', \n                                  xaxis=dict(title='comment length'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","b1f72310":"length_a1 = scraped_train['answer_1'].apply(lambda x:len(x.split(' ')))\nlength_a2 = scraped_train['answer_2'].apply(lambda x:len(x.split(' ')))\nlength_a3 = scraped_train['answer_3'].apply(lambda x:len(x.split(' ')))","3b520adf":"# histogram of length of answers\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length_a1), marker_color='#386082', name='answer_1'),\n                      go.Histogram(x=np.log1p(length_a2), marker_color='#789501', name='answer_2'),\n                      go.Histogram(x=np.log1p(length_a3), marker_color='#e80995', name='answer_3')], \n                layout = go.Layout(title='histogram of log of length of answers for train data', \n                                  xaxis=dict(title='answer_length'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","154766b9":"length_a1 = scraped_test['answer_1'].apply(lambda x:len(x.split(' ')))\nlength_a2 = scraped_test['answer_2'].apply(lambda x:len(x.split(' ')))\nlength_a3 = scraped_test['answer_3'].apply(lambda x:len(x.split(' ')))","8ec90d51":"# histogram of length of answers\nplt = go.Figure(data=[go.Histogram(x=np.log1p(length_a1), marker_color='#386082', name='answer_1'),\n                      go.Histogram(x=np.log1p(length_a2), marker_color='#789501', name='answer_2'),\n                      go.Histogram(x=np.log1p(length_a3), marker_color='#e80995', name='answer_3')], \n                layout = go.Layout(title='histogram of log of length of answers for test data', \n                                  xaxis=dict(title='answer_length'), \n                                  yaxis=dict(title='frequency')))\nplt.show()","3e34f9d4":"scraped_train.columns[-8:]","32ad06b8":"# For train data\nscraped_train.iloc[:, -8:].describe()","5d524488":"# For test data\nscraped_test.iloc[:, -8:].describe()","a083cd89":"import matplotlib.pyplot as plt\n# histograms of the target labels\nf,ax = plt.subplots(5,6, figsize=(24,20))\nfor i,label in enumerate(train.columns[11:]):\n  plt.subplot(5,6,i+1)\n  plt.hist(train[label], bins=20)\n  plt.title(label)\n\nplt.show()","8976db24":"plt.figure(figsize=(16,14))\nVar_Corr = train.iloc[11:].corr()\nsns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns) \nplt.title('Correlation between target features.')\nplt.show()","b010e285":"#### There are 2 more features that we can scrape-- 'upvotes' and 'comments'. The feature 'upvotes' will hold the number of upvotes that the accepted answer received and the feature 'comments' will hold the comments in the  posts.","6bebd424":"#### In the beginning of the EDA, we saw the anatomy of the webpage that we land on using the links in feature 'url'. Now let's see what else new features can be extracted from teh webpage.\n#### For each question, there can be multiple answers. The accepted answer (one with a green tick) is the one that is provided in the original dataset. But we can scrape the other answers from the webpage as well.\n*I've denoted the other answers as 'post' below.","cd894f26":"#### Question title","0f62d6b1":"## Data Scraping","9efcc261":"## Challenge description: \n#### In this competition, we're challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. The raters received minimal guidance and training and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task.\n#### Demonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like.","0a6b70cd":"#### For illustration, below is the anatomy of a webpage (unsing the link in 'url') and the top 6 features on the webpage.\n#### The features question_user_page and answer_user_page are links to the user's page that can be accessed by clinking on the features question_user_name and answer_user_name below.","40374e79":"#### Question body","1bdc49ae":"#### Answer","aaa730d1":"#### Question user page, Answer user page","d55639b0":"#### Description of the last 8 scraped features from question and answer user page links\n#### 'reputation_q', 'gold_q', 'silver_q', 'bronze_q', 'reputation_a', 'gold_a', 'silver_a', 'bronze_a'","d63e281a":"#### Host","fc09644e":"#### URL\nthis feature holds the webpage url's of the questions and answers","f21ef362":"#### Upvotes","18e728d0":"## EDA","e2e0fbbf":"## About the data:\n#### The data for this competition includes questions and answers from various StackExchange properties. Our task is to predict the target values of 30 labels for each question-answer pair.\n#### The list of 30 target labels is the same as the column names in the sample_submission.csv file. Target labels with the prefix question_ relate to the question_title and\/or question_body features in the data. Target labels with the prefix answer_ relate to the answer feature.\n#### Each row contains a single question and a single answer to that question, along with additional features. The training data contains rows with some duplicated questions (but with different answers). The test data does not contain any duplicated questions.\n#### Target labels can have continuous values in the range [0,1]. Therefore, predictions must also be in that range.\n#### The files provided are:\n- train.csv\u200a-\u200athe training data (target labels are the last 30 columns)\n- test.csv\u200a-\u200athe test set (you must predict 30 labels for each test set row)\n- sample_submission.csv\u200a-\u200aa sample submission file in the correct format; column names are the 30 target labels","c0587b2b":"#### data provided by Kaggle","9226c8e1":"#### Question user name, Answer user name\n(these are irrelevant features so I have not done EDA for them)","8df5fa90":"#### Category","a336813d":"#### comments_0","cb16d68c":"### Target features","2e7d7d29":"#### The remaining 3 features 'url', 'question_user_page', 'answer_user_page' can be a great source for some external data let's see how.","8b3c03ca":"#### If we go to the userpage using the link provided in the features 'question_user_page' and 'answer_user_page' there are 4 new useful features that we can scrape.\n#### The 4 new features are 'reputation', 'gold_score', 'silver_score', 'bronze_score'."}}