{"cell_type":{"1a53a2e3":"code","cce72267":"code","0aecf466":"code","f1e980b4":"code","3d7e3dab":"code","60f10cb9":"code","16811c43":"code","29067a01":"code","b013187a":"code","3b691c10":"code","6b4eccee":"code","38e0b1ce":"code","2914f545":"code","4e7e232f":"code","6b056750":"code","f33033e2":"code","d8ca543b":"code","aee7d926":"code","d39039d4":"code","1e25929a":"code","8cfb2773":"markdown","61e3455c":"markdown","1acd0fdc":"markdown","8020eb26":"markdown","20dc5321":"markdown","4ff579b8":"markdown","a9a6b6dd":"markdown","5b6664cc":"markdown","dc15fc26":"markdown","1680ca10":"markdown","84863250":"markdown","fef55d69":"markdown"},"source":{"1a53a2e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cce72267":"# Load libraries\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow\ntensorflow.random.set_seed(0)\nfrom numpy.random import seed\nseed(1)","0aecf466":"# Load training data\ntrain_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv')\nlen(train_data)","f1e980b4":"train_data.head()","3d7e3dab":"# Load testing data\ntest_data = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv')\nlen(test_data)","60f10cb9":"test_data.head()","16811c43":"# Get the number of missing data points per column\nmissing_values_count_train = train_data.isnull().sum()\nprint(missing_values_count_train)","29067a01":"# Get the number of missing data points per column\nmissing_values_count_test = test_data.isnull().sum()\nprint(missing_values_count_test)","b013187a":"print(train_data.columns)","3b691c10":"num_of_classes = train_data['target'].value_counts()\nprint(num_of_classes)","6b4eccee":"le = LabelEncoder()\ntrain_data['target'] = le.fit_transform(train_data['target'])","38e0b1ce":"train_corr = train_data.corr()\ntrain_corr.head()","2914f545":"features_list = list(train_data.columns)\nfeatures_num = features_list[1:-1]\n#features_num = ['feature_42', 'feature_17', 'feature_11', 'feature_36', 'feature_13', 'feature_30', 'feature_39', 'feature_52', 'feature_1', 'feature_64', 'feature_15', 'feature_2', 'feature_27', 'feature_53', 'feature_19', 'feature_20', 'feature_71', 'feature_38', 'feature_55', 'feature_24', 'feature_43', 'feature_61', 'feature_4', 'feature_0', 'feature_22', 'feature_18', 'feature_49', 'feature_47', 'feature_12', 'feature_29', 'feature_66', 'feature_7', 'feature_40', 'feature_54', 'feature_69', 'feature_60', 'feature_68', 'feature_48', 'feature_23', 'feature_37', 'feature_67', 'feature_6', 'feature_8', 'id', 'feature_33', 'feature_62', 'feature_65', 'feature_63', 'feature_31', 'feature_44']\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n)\n\ny = train_data['target']\nX = preprocessor.fit_transform(train_data[features_num])\n\ntest_X = preprocessor.transform(test_data[features_num])","4e7e232f":"# Check summary of each class\ntrain_data.groupby('target').describe()","6b056750":"print(X.shape)","f33033e2":"from xgboost import XGBClassifier\nfrom sklearn.metrics import mean_absolute_error\n\ny = train_data['target']\nlc = LabelEncoder() \nlc = lc.fit(y) \nlc_y = lc.transform(y)\n\nfeatures_list = list(train_data.columns)\nfeatures_num = features_list[1:-1]\n#features_num = ['feature_42', 'feature_17', 'feature_11', 'feature_36', 'feature_13', 'feature_30', 'feature_39', 'feature_52', 'feature_1', 'feature_64', 'feature_15', 'feature_2', 'feature_27', 'feature_53', 'feature_19', 'feature_20', 'feature_71', 'feature_38', 'feature_55', 'feature_24', 'feature_43', 'feature_61', 'feature_4', 'feature_0', 'feature_22', 'feature_18', 'feature_49', 'feature_47', 'feature_12', 'feature_29', 'feature_66', 'feature_7', 'feature_40', 'feature_54', 'feature_69', 'feature_60', 'feature_68', 'feature_48', 'feature_23', 'feature_37', 'feature_67', 'feature_6', 'feature_8', 'id', 'feature_33', 'feature_62', 'feature_65', 'feature_63', 'feature_31', 'feature_44']\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n)\n\nX = preprocessor.fit_transform(train_data[features_num])\ntest_X = preprocessor.transform(test_data[features_num])\n\n# Define the model\nxgb_model = XGBClassifier(n_estimators = 50)\n\n# Fit the model\nxgb_model.fit(X,lc_y)","d8ca543b":"test_preds = xgb_model.predict_proba(test_X)\nprint(test_preds[0])","aee7d926":"# The lines below shows how to save predictions in format used for competition scoring.\noutput = pd.DataFrame({'id': test_data.id,\n                       'Class_1': test_preds[:, 0],\n                       'Class_2': test_preds[:, 1],\n                       'Class_3': test_preds[:, 2],\n                       'Class_4': test_preds[:, 3],\n                       'Class_5': test_preds[:, 4],\n                       'Class_6': test_preds[:, 5],\n                       'Class_7': test_preds[:, 6],\n                       'Class_8': test_preds[:, 7],\n                       'Class_9': test_preds[:, 8],\n                      })\n\noutput.to_csv('submission_tps.csv', index=False)","d39039d4":"output.head()","1e25929a":"from IPython.display import FileLink\nFileLink('.\/submission_tps.csv')","8cfb2773":"Check the list of features available:","61e3455c":"## Obtaining the test predictions","1acd0fdc":"## Preparing the format for submission","8020eb26":"Check for missing values in the test data:","20dc5321":"## XGB Classifier","4ff579b8":"Visualizing the class statistics below:","a9a6b6dd":"## Load and get a glimpse of the training and test sets","5b6664cc":"Check for missing values in the training data:","dc15fc26":"Visualizing the submission file below:","1680ca10":"## Pre-processing of data","84863250":"## Loading the necessary libraries","fef55d69":"Obtain the number of classes, and values in each:"}}