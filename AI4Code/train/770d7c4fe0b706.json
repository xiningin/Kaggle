{"cell_type":{"282d387a":"code","1f4acccb":"code","8eb7560a":"code","e5de27c3":"code","5bc00728":"code","7d1ca1e7":"code","616aa128":"code","e476b9e2":"code","452a5da4":"code","7e653c19":"code","0394cf54":"code","79d73775":"code","6d49beb8":"code","8888f817":"code","102c897b":"code","2d9497d4":"code","5b59d549":"code","4d9fc306":"code","8e896ac7":"code","6964f216":"code","9325fc71":"code","a47ed067":"code","ba2cfb9b":"code","63884f46":"code","f5e36c9e":"code","ed756f16":"code","418fb272":"code","bfe23686":"code","97e83aba":"code","f91b0b22":"code","c2a69d1d":"code","f22fdc58":"code","5f64cb82":"code","9b8288fb":"code","84f9ccd1":"code","7330ba16":"code","9c1d0ee3":"code","8b5c4d80":"code","6006a37c":"code","aefcf885":"code","91c16c5e":"code","d6d52fb2":"code","cd235214":"code","6708ec80":"code","098f6dc8":"code","9aa8b9c5":"code","9330af23":"code","e7df7154":"code","ef9e66b0":"code","705defe6":"code","e1287e6f":"code","7006682b":"code","08910fa6":"code","2f3a2f87":"code","ae7cb18c":"code","0c0dfa82":"code","15b08199":"code","0a225259":"code","7f4393c2":"markdown","8db9f2ff":"markdown","878a85ce":"markdown","2977cb5a":"markdown","9245bc18":"markdown","7ce55479":"markdown","4762f554":"markdown","fb6381a9":"markdown","99c0d39d":"markdown","7b18eb98":"markdown","b95aa4d1":"markdown","62cf64f6":"markdown","2f090e4d":"markdown","990589c7":"markdown"},"source":{"282d387a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")","1f4acccb":"df = pd.read_csv(\"..\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")\ndf.head()","8eb7560a":"# Looking for missing values in the dataset\ndf.isna().sum()","e5de27c3":"df.shape","5bc00728":"df.dtypes","7d1ca1e7":"df.describe()","616aa128":"df.dtypes","e476b9e2":"# Re-naming the columns\ndf.rename(columns={'Dataset':'Outcome'}, inplace=True)\ndf.info()","452a5da4":"df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 2})","7e653c19":"# Having a look at the dataset after the numerical transformation\ndf.head()","0394cf54":"# Dropping the missing values\ndf = df.dropna()","79d73775":"# Having a look at the correlation matrix\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.heatmap(df.corr(), annot=True, fmt='.1g', cmap=\"viridis\", cbar=False);","6d49beb8":"print ('Total Unhealthy Livers : {} '.format(df.Outcome.value_counts()[1]))\nprint ('Total Healthy Livers : {} '.format(df.Outcome.value_counts()[2]))","8888f817":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(7,7))\n\nplt.pie(x=df[\"Outcome\"].value_counts(), \n        colors=[\"firebrick\",\"seagreen\"], \n        labels=[\"UnHealthy Liver\",\"Healthy Liver\"], \n        shadow = True, \n        explode = (0, 0.1)\n        )\n\nplt.show()","102c897b":"df.Gender.value_counts()","2d9497d4":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(7,7))\nplt.pie(x=df[\"Gender\"].value_counts(), \n        colors=[\"skyblue\",\"pink\"], \n        labels=[\"Male\",\"Female\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","5b59d549":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.histplot(x=df[\"Age\"], kde=True, color=\"seagreen\");","4d9fc306":"fig, ax =plt.subplots(4,2, figsize=(20,25)) \nplt.style.use(\"seaborn\")\n\nsns.histplot(x = df[\"Total_Bilirubin\"], hue = df[\"Outcome\"], palette=\"viridis\", kde=True, ax=ax[0,0]);\nax[0,0].set_xlabel(\"Total_Bilirubin\",fontsize=15)\n\nsns.histplot(x = df[\"Direct_Bilirubin\"], hue = df[\"Outcome\"], palette=\"viridis\", kde=True, ax=ax[0,1]);\nax[0,1].set_xlabel(\"Direct_Bilirubin\",fontsize=15)\n\n\nsns.histplot(x = df[\"Alkaline_Phosphotase\"], hue = df[\"Outcome\"], palette=\"dark\", kde=True, ax=ax[1,0]);\nax[1,0].set_xlabel(\"Alkaline_Phosphotase\",fontsize=15)\n\nsns.histplot(x = df[\"Alamine_Aminotransferase\"], hue = df[\"Outcome\"], palette=\"dark\", kde=True, ax=ax[1,1]);\nax[1,1].set_xlabel(\"Alamine_Aminotransferase\",fontsize=15)\n\n\nsns.histplot(x = df[\"Aspartate_Aminotransferase\"], hue = df[\"Outcome\"], palette=\"flare\", kde=True, ax=ax[2,0]);\nax[2,0].set_xlabel(\"Aspartate_Aminotransferase\",fontsize=15)\n\nsns.histplot(x = df[\"Total_Protiens\"], hue = df[\"Outcome\"], palette=\"flare\", kde=True, ax=ax[2,1]);\nax[2,1].set_xlabel(\"Total_Protiens\",fontsize=15)\n\n\nsns.histplot(x = df[\"Albumin\"], hue = df[\"Outcome\"], palette=\"viridis\", kde=True, ax=ax[3,0]);\nax[3,0].set_xlabel(\"Albumin\",fontsize=15)\n\nsns.histplot(x = df[\"Albumin_and_Globulin_Ratio\"], hue = df[\"Outcome\"], palette=\"viridis\", kde=True, ax=ax[3,1]);\nax[3,1].set_xlabel(\"Albumin_and_Globulin_Ratio\",fontsize=15);","8e896ac7":"plt.style.use(\"seaborn\")\nfig, ax = plt.subplots(figsize=(8,6))\nsns.histplot(x = df[\"Age\"], hue = df[\"Outcome\"], palette=\"spring\", kde=True);","6964f216":"# X data\nX = df.drop(\"Outcome\", axis=1)\nX.head()","9325fc71":"# y data\ny = df[\"Outcome\"]\ny.head()","a47ed067":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","ba2cfb9b":"len(X_train), len(X_test)","63884f46":"# Scaling the data \n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","f5e36c9e":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)","ed756f16":"LogisticRegressionScore = lr.score(X_test, y_test)\nprint(\"Accuracy obtained by Logistic Regression model:\",LogisticRegressionScore*100)","418fb272":"# Having a look at the confusion matrix\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ny_pred_lr = lr.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_lr)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for Logistic Regression\", fontsize=14, fontname=\"Helvetica\", y=1.03);","bfe23686":"# Having a look at the classification report of Logistic Regression\n\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred_lr))","97e83aba":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators = 100)\nrfc.fit(X_train,y_train)","f91b0b22":"RandomForestClassifierScore = rfc.score(X_test, y_test)\nprint(\"Accuracy obtained by Random Forest Classifier model:\",RandomForestClassifierScore*100)","c2a69d1d":"# Having a look at the confusion matrix\n\ny_pred_rfc = rfc.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_rfc)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for Random Forest Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","f22fdc58":"# Classification report of Random Forest Classifier\n\nprint(metrics.classification_report(y_test, y_pred_rfc))","5f64cb82":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(4)\nknn.fit(X_train,y_train)","9b8288fb":"KNeighborsClassifierScore = knn.score(X_test, y_test)\nprint(\"Accuracy obtained by K Neighbors Classifier model:\",KNeighborsClassifierScore*100)","84f9ccd1":"# Having a look at the confusion matrix\ny_pred_knn = knn.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_knn)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for K Neighbors Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","7330ba16":"# Classification report of K Neighbors Classifier\n\nprint(metrics.classification_report(y_test, y_pred_knn))","9c1d0ee3":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)","8b5c4d80":"DecisionTreeClassifierScore = dtc.score(X_test,y_test)\nprint(\"Accuracy obtained by Decision Tree Classifier model:\",DecisionTreeClassifierScore*100)","6006a37c":"# Confusion matrix\ny_pred_dtc = dtc.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_dtc)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for Decision Tree Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","aefcf885":"# Classification Report of Decision Tree Classifier\n\nprint(metrics.classification_report(y_test, y_pred_dtc))","91c16c5e":"from catboost import CatBoostClassifier\ncat = CatBoostClassifier(iterations=10)\ncat.fit(X_train, y_train);","d6d52fb2":"CatBoostClassifierScore = cat.score(X_test,y_test)\nprint(\"Accuracy obtained by CatBoost Classifier model:\",CatBoostClassifierScore*100)","cd235214":"# Confusion matrix\ny_pred_cat = cat.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_cat)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for CatBoost Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","6708ec80":"# Classification Report of CatBoost Classifier\n\nprint(metrics.classification_report(y_test, y_pred_cat))","098f6dc8":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)","9aa8b9c5":"GradientBoostingClassifierScore = gb.score(X_test,y_test)\nprint(\"Accuracy obtained by Gradient Boosting Classifier model:\",GradientBoostingClassifierScore*100)","9330af23":"# Confusion matrix\ny_pred_gb = gb.predict(X_test)\ncf_matrix = confusion_matrix(y_test, y_pred_gb)\nsns.heatmap(cf_matrix, annot=True, cmap=\"Spectral\")\nplt.title(\"Confusion Matrix for Gradient Boosting Classifier\", fontsize=14, fontname=\"Helvetica\", y=1.03);","e7df7154":"# Classification Report of Gradient Boosting Classifier\n\nprint(metrics.classification_report(y_test, y_pred_gb))","ef9e66b0":"plt.style.use(\"seaborn\")\n\nx = [\"LogisticRegression\", \n     \"Decision Tree Classifier\", \n     \"RandomForestClassifier\", \n     \"KNeighborsClassifier\", \n     \"CatBoost Classifier\", \n     \"Gradient Boosting Classifier\"]\n\ny = [LogisticRegressionScore, \n     DecisionTreeClassifierScore, \n     RandomForestClassifierScore, \n     KNeighborsClassifierScore, \n     CatBoostClassifierScore, \n     GradientBoostingClassifierScore]\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=x,y=y, palette=\"crest\");\nplt.ylabel(\"Model Accuracy\")\nplt.xticks(rotation=40)\nplt.title(\"Model Comparison - Model Accuracy\", fontsize=14, fontname=\"Helvetica\", y=1.03);","705defe6":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\n      \"penalty\": [\"l1\", \"l2\", \"elastic\", \"none\" ],\n      \"C\" : np.logspace(-4, 4, 20),\n      \"solver\" : [\"sag\", \"saga\", \"lbfgs\", \"liblinear\", \"newton-cg\"],\n      \"max_iter\" : [100, 1000, 2500, 5000]\n    }\n]\n\ngrid_search_lr = GridSearchCV(estimator = lr, \n                              param_grid = param_grid, \n                              cv = 5, \n                              n_jobs = -1, \n                              verbose = True)","e1287e6f":"grid_search_lr.fit(X_train, y_train)","7006682b":"grid_search_lr.best_params_","08910fa6":"grid_search_lr.best_score_","2f3a2f87":"grid_search_lr_predict = grid_search_lr.predict(X_test)","ae7cb18c":"print('Improvement in Logistic Regression after GridSearchCV: {:0.2f}%.'.format(100 * (grid_search_lr.best_score_ - LogisticRegressionScore) \/ LogisticRegressionScore))","0c0dfa82":"# Comparing the results after the improvement in Logistic Regression\n\nplt.style.use(\"seaborn\")\n\nx = [\"Logistic Regression\",\n     \"GridSearch-LogisticRegression\"]\n\ny = [LogisticRegressionScore,\n     grid_search_lr.best_score_]\n\nfig, ax = plt.subplots(figsize=(7,7))\nsns.barplot(x=x,y=y, palette=\"viridis\");\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=30)\nplt.title(\"LogisticRegression  vs  GridSearched LogisticRegression\", fontsize=14, fontname=\"Helvetica\", y=1.03);","15b08199":"# Comparing the GridSearch-Logistic Regression and Gradient Boosting Classifier \n\nplt.style.use(\"seaborn\")\n\nx = [\"Gradient Boosting Classifier\",\n     \"GridSearch-LogisticRegression\"]\n\ny = [GradientBoostingClassifierScore,\n     grid_search_lr.best_score_]\n\nfig, ax = plt.subplots(figsize=(7,7))\nsns.barplot(x=x,y=y, palette=\"viridis\");\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=30)\nplt.title(\"Gradient Boosting Classifier  vs  GridSearched LogisticRegression\", fontsize=14, fontname=\"Helvetica\", y=1.03);","0a225259":"# Classification Report of GridSearch-LogisticRegression\n\nprint(classification_report(y_test, grid_search_lr_predict))","7f4393c2":"## DecisionTreeClassifier","8db9f2ff":"#### If you like my work, It will be really great of you to upvote this notebook!\n#### If not then you leaving a comment on what do I need to work on and improve will be really helpful!","878a85ce":"## K Neighbors Classifier","2977cb5a":"## Splitting the data into training and test datasets\nHere, we are trying to predict whether the patient has an Unhealthy Liver or not using the given data. Hence, the `Outcome` will be the y label and rest of the data will be the X or the input data.","9245bc18":"## Gradient Boosting Classifier","7ce55479":"*  `Gradient Boosting Classifier` and `Logistic Regression Model` perform the best on the test set.","4762f554":"## Logistic Regression","fb6381a9":"## Loading up the data","99c0d39d":"## Hyperparameter Tuning on Logistic Regression","7b18eb98":"#### After Hyperparameter tuning Logistic Regression model performs even better than the Gradient Boosting Classifier which was not the case before!","b95aa4d1":"## Random Forest Classifier","62cf64f6":"## Importing Libraries","2f090e4d":"# Liver Patient Predictions \ud83e\ude7a","990589c7":"## CatBoost Classifier"}}