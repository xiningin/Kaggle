{"cell_type":{"02d5e6e3":"code","795868e8":"code","8f0d54b8":"code","b8d32749":"code","837d678f":"code","d2df8f8c":"code","9e93029f":"code","c57d400e":"code","38b6c79e":"code","5dab8b8d":"code","59f2d04e":"code","eb26abba":"code","8e69e370":"code","0146b039":"code","b030b492":"code","15f86a84":"code","1ec6bfbd":"code","d5971874":"code","b07a09fb":"code","0acb0ae5":"code","76578ea2":"code","30317ffc":"code","0c35a498":"code","231d02f0":"code","e7e3ec98":"code","dd2f0d05":"code","3d6b5202":"code","bde547aa":"code","d6531580":"code","a0ee38d5":"code","b6cb580d":"code","12c21c32":"code","18b34b6a":"code","2b15d83a":"code","36f6e968":"code","78816056":"code","6ea0e1dc":"code","31d2f7ed":"code","9e59b725":"code","17b2e41c":"code","f7e93d5f":"code","53727fb7":"code","4bc64192":"code","8f30e11a":"code","a0f50f64":"code","30d9c0a2":"markdown","1b20eebd":"markdown","d82de472":"markdown","ae365dfb":"markdown","a01572e2":"markdown","db111d86":"markdown","c75514b3":"markdown","1f389e6f":"markdown","638491d4":"markdown"},"source":{"02d5e6e3":"# Loading Libraries\nimport torch \nimport torch.nn as nn\nimport torchvision \nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nimport numpy as np\nimport matplotlib.pyplot as plt","795868e8":"# Model to device\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","8f0d54b8":"# Transforming data\ntransform = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(0.2),\n                                transforms.ToTensor(),\n                                transforms.Resize((80,80))\n                               ])\n\n\n# Loading Data\ndataset = torchvision.datasets.ImageFolder(root = '..\/input\/flowers-recognition\/flowers\/flowers',\n                                           transform = transform)\n\n\n# Print no. of classes\nprint(\"No of Classes: \", len(dataset.classes))\n\n\n# Splitting the data in train and validation set and loading it.\ntrain, val = torch.utils.data.random_split(dataset, [3000, 1323])\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train,\n                                           batch_size = 32, \n                                           shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(dataset = val,\n                                         batch_size = 32, \n                                         shuffle = True)\n","b8d32749":"Accuracies = []","837d678f":"class ConvNet(nn.Module):          # nn.Modules - base class for nn modules\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        \n        \n        # since colored images, so input channel = 3(For layer 1), then changes acoording to layers\n        # stride - by how many pixel should our window moves\n        # padding - how may 0's we want to add to our compressed image\n        # Batch Normalization can improve lr of model, minimize internal covariate shift(mean-0, variance-1)\n        # Max pooling will reduce th size of image into half\n        \n        \n                                                     \n        # Layer 1\n        self.layer1 = nn.Sequential(\n                                        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=2),\n                                        nn.BatchNorm2d(64),\n                                        nn.ReLU(),\n                                        nn.MaxPool2d(kernel_size=2, stride=2)\n                                    )\n        \n        \n        # Layer 2\n        self.layer2 = nn.Sequential(\n                                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2),\n                                        nn.BatchNorm2d(128),\n                                        nn.ReLU(),\n                                        nn.MaxPool2d(kernel_size=2, stride=2)\n                                    )\n\n        \n        # Layer 3\n        self.layer3 = nn.Sequential(\n                                        nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n                                        nn.BatchNorm2d(256),\n                                        nn.ReLU(),\n                                        nn.MaxPool2d(kernel_size=2, stride=2)\n                                    )\n    \n    \n        # Layer 4\n        self.layer4 = nn.Sequential(\n                                        nn.Conv2d(256, 512, kernel_size=5, stride=1, padding=2),\n                                        nn.BatchNorm2d(512),\n                                        nn.ReLU(),\n                                        nn.MaxPool2d(kernel_size=2, stride=2)\n                                    )\n        \n        \n        # Layer 5\n        self.layer5 = nn.Sequential(\n                                        nn.Conv2d(512, 1024, kernel_size=5, stride=1, padding=2),\n                                        nn.BatchNorm2d(1024),\n                                        nn.ReLU(),\n                                        nn.MaxPool2d(kernel_size=2, stride=2)\n                                    )\n        \n        \n        \n        \n        # fully connected network, applies linear transformation to the upcoming data\n        # Fully Connected Layers\n        self.fc1 = nn.Linear(2*2*1024, 256)\n        self.fc2 = nn.Linear(256, 512)\n        self.fc3 = nn.Linear(512, 5)\n        \n    \n    \n    # Function to execute CNN\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc1(out)\n        out = F.dropout(out, training=self.training)\n        out = self.fc2(out)\n        out = F.dropout(out, training=self.training)\n        out = self.fc3(out)\n        return F.log_softmax(out,dim=1)\n","d2df8f8c":"model = ConvNet().to(device)","9e93029f":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss() # Used for classification problems\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Default learning rate for Adam is 0.001","c57d400e":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\n\n# first loop for the epochs\n# second loop for the training batches\n\nfor epoch in range(40):\n  acc = 0\n  val_acc = 0\n    \n  for i, (images, labels) in enumerate(train_loader):\n    model.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = model(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()                                  # to optimize the loss,to not accumulate the previous gradient\n    loss.backward()                                        # to calculate the gradient\n    optimizer.step()                                       # it applies the optimizer to change the parameter\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n  \n    \n    \n  # For validation batches\n  for i, (images, labels) in enumerate(val_loader):\n    model.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = model(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","38b6c79e":"plt.plot(range(40),Loss)\nplt.plot(range(40),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","5dab8b8d":"plt.plot(range(40),Acc)\nplt.plot(range(40),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","59f2d04e":"# Test the model\n\nmodel.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = model(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n        \n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))\n","eb26abba":"vgg = torchvision.models.vgg19(pretrained=True)","8e69e370":"print(vgg)","0146b039":"vgg.classifier[6].out_features = 5\nfor param in vgg.features.parameters(): \n    param.requires_grad = False\n\nvgg = vgg.cuda()","b030b492":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg.parameters(), lr=0.001)","15f86a84":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(20):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    vgg.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    vgg.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","1ec6bfbd":"plt.plot(range(20),Loss)\nplt.plot(range(20),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","d5971874":"plt.plot(range(20),Acc)\nplt.plot(range(20),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","b07a09fb":"# Test the model\n\nvgg.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = vgg(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","0acb0ae5":"resnet18 = torchvision.models.resnet18(pretrained= True)","76578ea2":"print(resnet18)","30317ffc":"ftr = resnet18.fc.in_features\nresnet18.fc = nn.Linear(ftr, 5)\n\nresnet18 = resnet18.cuda()","0c35a498":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)","231d02f0":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(10):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    resnet18.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet18(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    resnet18.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet18(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","e7e3ec98":"plt.plot(range(10),Loss)\nplt.plot(range(10),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","dd2f0d05":"plt.plot(range(10),Acc)\nplt.plot(range(10),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","3d6b5202":"# Test the model\n\nmodel.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = resnet18(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","bde547aa":"resnet34 = torchvision.models.resnet34(pretrained=True)","d6531580":"print(resnet34)","a0ee38d5":"ftr = resnet34.fc.in_features\nresnet34.fc = nn.Linear(ftr, 5)\n\nresnet34 = resnet34.cuda()","b6cb580d":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet34.parameters(), lr=0.001)","12c21c32":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(10):\n  acc = 0\n  val_acc = 0\n  for i, (images, labels) in enumerate(train_loader):\n    resnet34.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet34(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    resnet34.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet34(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","18b34b6a":"plt.plot(range(10),Loss)\nplt.plot(range(10),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","2b15d83a":"plt.plot(range(10),Acc)\nplt.plot(range(10),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","36f6e968":"# Test the model\n\nmodel.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = resnet34(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","78816056":"alexnet = torchvision.models.alexnet(pretrained=True)","6ea0e1dc":"print(alexnet)","31d2f7ed":"alexnet.classifier[6].out_features = 5\nfor param in alexnet.features.parameters(): \n    param.requires_grad = False\n\nalexnet = alexnet.cuda()","9e59b725":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)","17b2e41c":"total_step = len(train_loader)\nLoss = []\nAcc = []\nVal_Loss = []\nVal_Acc = []\n\n\nfor epoch in range(10):\n  acc = 0\n  val_acc = 0\n\n  for i, (images, labels) in enumerate(train_loader):\n    alexnet.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = alexnet(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  acc = acc\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(val_loader):\n    alexnet.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = alexnet(images)\n    val_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim=1,keepdim=True)[1]\n    val_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  val_acc = val_acc\/len(val_loader.dataset) * 100\n    \n  \n\n  print(\"Epoch {} =>  loss : {loss:.2f};   Accuracy : {acc:.2f}%;   Val_loss : {val_loss:.2f};   Val_Accuracy : {val_acc:.2f}%\".format(epoch+1, loss=loss.item(), acc=acc, val_loss=val_loss.item(), val_acc=val_acc))\n  \n  Loss.append(loss)\n  Acc.append(acc)\n\n  Val_Loss.append(val_loss)\n  Val_Acc.append(val_acc)","f7e93d5f":"plt.plot(range(10),Loss)\nplt.plot(range(10),Val_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","53727fb7":"plt.plot(range(10),Acc)\nplt.plot(range(10),Val_Acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title(\"Accuracy\")\nplt.legend([\"Training Accuracy\", \"Validation Accuracy\"])\nplt.show()","4bc64192":"# Test the model\n\nalexnet.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_loader:\n        y_pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = alexnet(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        y_pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n\n    acc = 100 * correct \/ total\n    Accuracies.append(acc)\n    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct \/ total))","8f30e11a":"print(Accuracies)","a0f50f64":"# Comparision of Accuracies of different models\n\nplt.plot(range(5), Accuracies, color='green', linestyle='dashed', linewidth = 2, \n         marker='o', markerfacecolor='blue', markersize=10) \nplt.ylabel('Acc')\nplt.xlabel('Models')\nplt.title(\"Accuracies\")\nplt.xticks(range(5), ['Custom CNN', 'Vgg19', 'Resnet18', 'Resnet34', 'Alexnet'])\nplt.show()","30d9c0a2":"### Steps in VGG 19","1b20eebd":"## Steps in Resnet34","d82de472":"# Resnet 18","ae365dfb":"# Custom CNN","a01572e2":"## Steps in Alexnet","db111d86":"## Steps in Resnet18","c75514b3":"# Alexnet","1f389e6f":"# Resnet 34","638491d4":"# VGG 19"}}