{"cell_type":{"8e6f8dcb":"code","b7b182f0":"code","92719860":"code","95d5dd05":"code","17e06e65":"code","c9acd0ef":"code","4f5032d2":"code","bae25227":"code","fa78b709":"code","3efbeaf7":"code","37143eee":"code","3c57380d":"code","09c44ab1":"code","6c4a0e71":"code","3ee1a7a9":"code","12dba2bd":"code","3c129978":"markdown","bb460982":"markdown","a4c16238":"markdown","79b66178":"markdown","21f07eff":"markdown","c6c74ae3":"markdown","9f2abfd7":"markdown","2d441a10":"markdown","82c1865f":"markdown","48a18b85":"markdown"},"source":{"8e6f8dcb":"#Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","b7b182f0":"#Load data as dataframe\ndata=pd.read_csv(\"..\/input\/creditcard.csv\")\ndata.head()","92719860":"#normalising data except time and class columns\ndata2= (data.iloc[:,1:-1] - data.iloc[:,1:-1].mean()) \/ (data.iloc[:,1:-1].max() - data.iloc[:,1:-1].min())\ndata2['Class']=data['Class']\n\n#Converting time in seconds to hours \ndata2['Hour'] = data['Time'] \/\/3600\ndata2['Hour'].replace(-0,0,inplace=True)\ndata=data2\nprint(\"Normalised data :\")\ndata.head()","95d5dd05":"from imblearn.over_sampling import SMOTE\nsmt = SMOTE()\ndef do_smote(data):\n    names=list(data)\n    y_t = data.Class\n    X_t = data.drop('Class', axis=1)\n    X_t, y_t = smt.fit_sample(X_t, y_t)\n    #np.bincount(y_t)\n    X=pd.DataFrame(X_t)\n    X['Class']=y_t\n    X.columns = names\n    return X","17e06e65":"smoted_data=do_smote(data)","c9acd0ef":"for j in list(smoted_data):\n    for i in range(2):\n        sns.kdeplot(smoted_data[smoted_data.Class==i][j])\n    plt.show()","4f5032d2":"keep=['V1','V2','V3','V4','V5','V7','V9','V10','V11','V12','V14','V16','V17','V18','V19','V21','V26','Amount','Hour','Class']","bae25227":"data=data[keep]","fa78b709":"data.head()\ndata.Class.value_counts()","3efbeaf7":"final_data=do_smote(data)","37143eee":"final_data.Class.value_counts()","3c57380d":"from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, roc_auc_score\ndef get_performance_metrics(y_test,model_predictions):\n    # Accuracy\n    model_accuracy = accuracy_score(y_test,model_predictions)\n    print(\"Accuracy is \", model_accuracy)\n\n    # precision, recall, f1 score\n    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_test,model_predictions)\n    print('Precision for each class is ', model_precision)\n    print('Recall\/sensitivity for each class is ', model_recall)\n    print('F1 Score for each class is ', model_f1)\n\n    # roc_auc\n    model_roc_auc = roc_auc_score(y_test,model_predictions)\n    print('AUC-ROC score is ', model_roc_auc)\n\n    # confusion matrix\n    model_confusion_matrix = confusion_matrix(y_test,model_predictions)\n    print('confusion matrix is :-->')\n    print(model_confusion_matrix)","09c44ab1":"# Separate input features (X) and target variable (y)\n\ny = final_data.Class\nX = final_data.drop('Class', axis=1)\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","6c4a0e71":"from sklearn.linear_model import LogisticRegression\n# Train model\nreg = LogisticRegression().fit(X_train, y_train)\n \n# Predict\npred_y = reg.predict(X_test)\n \nget_performance_metrics(y_test, pred_y)","3ee1a7a9":"from sklearn.ensemble import RandomForestClassifier\n\n# Train model\nrf = RandomForestClassifier(class_weight={0: 100,1: 1})\nrf.fit(X_train, y_train)\n # Predict on training set\npred_y = rf.predict(X_test)\nget_performance_metrics(y_test, pred_y)","12dba2bd":"from sklearn.svm import SVC\nsvc_model = SVC(kernel='linear', \n            class_weight={0: 100,1: 1},\n            probability=True)\n#train\nsvc_model.fit(X_train,y_train)\n#predict\nsvc_predictions= svc_model.predict(X_test)\nget_performance_metrics(y_test,svc_predictions)","3c129978":"# SVM","bb460982":"# Load libraries","a4c16238":"# Normalise data","79b66178":"# SMOTE (to remove imbalance problem)","21f07eff":"After visualising kdeplots of all features,following features are of more importance and are kept.","c6c74ae3":"# Splitting data","9f2abfd7":"# Metric function","2d441a10":"# Logistic Regression","82c1865f":"# Visualise features","48a18b85":"# Random Forest"}}