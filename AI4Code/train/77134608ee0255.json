{"cell_type":{"4e6a6313":"code","de4f4903":"code","4dbb5c51":"code","5d8eae69":"code","bb9df1e3":"code","50446bfd":"code","7305239c":"code","a9ea2981":"code","4ef87347":"code","76a72a26":"code","f241e573":"code","6c506442":"code","6c06adc7":"code","db3c30a2":"code","b81a7bec":"code","f5bb17ae":"code","2d0bf17d":"code","ee56055c":"markdown"},"source":{"4e6a6313":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de4f4903":"df=pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","4dbb5c51":"df","5d8eae69":"df.dtypes","bb9df1e3":"df.shape","50446bfd":"df.isnull().sum()","7305239c":"df.corr()","a9ea2981":"#chi-squared statistical test for feature selection\n\nfrom sklearn.feature_selection import SelectKBest, chi2\n\nx=df.iloc[:,:8]\ny=df.iloc[:,-1]\nbestfeatures = SelectKBest(score_func=chi2, k=8)\nfit = bestfeatures.fit(x,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(x.columns) \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Features','Score']  \nprint(featureScores.nlargest(8,'Score'))\n","4ef87347":"#feture importance\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n\nmodel = RandomForestClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(8).plot(kind='barh')\nplt.show()","76a72a26":"#correlation heatmap\n\nimport seaborn as sns\n\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","f241e573":"from sklearn.model_selection import train_test_split\n\nx=df[df.loc[:,df.columns != 'Outcome'].columns]\ny=df['Outcome']\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","6c506442":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=100,random_state=0)","6c06adc7":"from sklearn.metrics import mean_absolute_error\n\ndef score_model(model, x_t=x_train, x_v=x_test, y_t=y_train, y_v=y_test):\n    model.fit(x_t,y_t)\n    pred = model.predict(x_v)\n    return mean_absolute_error(y_v,pred)\n\nmae = score_model(model)\nprint(\"model mae:\",mae)","db3c30a2":"model.fit(x_train,y_train)\npred_test=model.predict(x_test)\n\n\noutput=pd.DataFrame({'ID':x_test.index,\n                    'output':pred_test})\n\noutput.to_csv('dia_submission.csv',index=False)","b81a7bec":"out_df=pd.read_csv('.\/dia_submission.csv')","f5bb17ae":"out_df.head(10)","2d0bf17d":"out_df.round()","ee56055c":"**age,insulin, bmi, glucose are the most important features**"}}