{"cell_type":{"bed03e05":"code","1cdd9c9d":"code","b522368d":"code","b9b4b8b6":"code","6bd66601":"code","c9f15985":"code","dca8500e":"code","606c9b84":"code","5781baa4":"code","201da900":"code","c2f25a24":"markdown"},"source":{"bed03e05":"#Importing Libraries\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.optimizers import SGD \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n","1cdd9c9d":"max_features = 10000 # input features\nmaxlen = 500 # timesteps","b522368d":"#Loading the IMDB Data set and printing the length of train and test sequences\nprint('Loading data...')\n(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\nprint(len(input_train), 'train sequences')\nprint(len(input_test), 'test sequences')\n","b9b4b8b6":"#Padding the train and test data\nprint('Pad sequences (samples x time)')\ninput_train = sequence.pad_sequences(input_train, maxlen=maxlen)\ninput_test = sequence.pad_sequences(input_test, maxlen=maxlen)\nprint('input_train shape:', input_train.shape)\nprint('input_test shape:', input_test.shape)","6bd66601":"#Building the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(max_features, 32), # no_of_samples, sequence_length=batch_size\n    tf.keras.layers.GRU(32, activation='tanh', return_sequences=True), # rnn_units=output_features\n    tf.keras.layers.GRU(32, activation='tanh'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n    \n])\n","c9f15985":"#Summary of the model\nmodel.summary()","dca8500e":"#Compiling the model\nmodel.compile(optimizer=SGD(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","606c9b84":"#Checking model fit\nhistory = model.fit(input_train, y_train,\n                    epochs=30,\n                    batch_size=32,\n                    validation_split=0.2)","5781baa4":"#Defining the plots\ndef display_models_plots(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(accuracy) + 1)\n    plt.plot(epochs, accuracy, 'r', label='Training acc')\n    plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","201da900":"# Plotting the results\ndisplay_models_plots(history)","c2f25a24":"## To classify the reviews from the IMDB dataset into positive and negative reviews."}}