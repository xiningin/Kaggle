{"cell_type":{"97f6bf49":"code","82ef3bab":"code","51795382":"code","d8efc36a":"code","458b6714":"code","77d0723a":"code","ee484bf1":"code","2f32b86c":"code","f2047bad":"code","a521b1a6":"code","b0407490":"code","80cfa800":"code","a115304d":"code","e73e5df6":"code","5b2c8ab3":"code","baf12b9e":"code","3e712b1d":"code","af83ca38":"markdown","bb8e8190":"markdown","54563537":"markdown","704e91c0":"markdown","576ecf5b":"markdown","4eb5d8e0":"markdown","ed228552":"markdown","cd57745f":"markdown","56307921":"markdown","85d4ea2f":"markdown","78737c03":"markdown","0b1fbc00":"markdown","308e3f28":"markdown","77e8b3a7":"markdown","b1b45053":"markdown","dcbdc171":"markdown","46d3c05d":"markdown","ff0aab2f":"markdown","9ad8847b":"markdown","28a4c59e":"markdown","88749285":"markdown","05e6a389":"markdown","a410e980":"markdown","0585081c":"markdown","8f91ad3f":"markdown","54e4d6a6":"markdown"},"source":{"97f6bf49":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","82ef3bab":"data = pd.read_csv('..\/input\/spam.csv', encoding='latin-1')\ndata.head(n=10)","51795382":"count_Class=pd.value_counts(data[\"v1\"], sort= True)\ncount_Class.plot(kind = 'bar',color = [\"green\",\"red\"])\nplt.title('Bar Plot')\nplt.show();","d8efc36a":"count_Class.plot(kind = 'pie',autopct='%1.0f%%')\nplt.title('Pie chart')\nplt.ylabel('')\nplt.show()","458b6714":"count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20)\ndf1 = pd.DataFrame.from_dict(count1)\ndf1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\ncount2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20)\ndf2 = pd.DataFrame.from_dict(count2)\ndf2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})","77d0723a":"df1.plot.bar(legend = False)\ny_pos = np.arange(len(df1[\"words in non-spam\"]))\nplt.xticks(y_pos, df1[\"words in non-spam\"])\nplt.title('More frequent words in non-spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","ee484bf1":"df2.plot.bar(legend = False, color = 'orange')\ny_pos = np.arange(len(df2[\"words in spam\"]))\nplt.xticks(y_pos, df2[\"words in spam\"])\nplt.title('More frequent words in spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","2f32b86c":"f = feature_extraction.text.TfidfVectorizer(stop_words = 'english')\nX = f.fit_transform(data[\"v2\"])\nnp.shape(X)","f2047bad":"data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.33, random_state=42)\nprint([np.shape(X_train), np.shape(X_test)])","a521b1a6":"list_alpha = np.arange(1\/100000, 20, 0.11)\nscore_train = np.zeros(len(list_alpha))\nscore_test = np.zeros(len(list_alpha))\nrecall_test = np.zeros(len(list_alpha))\nprecision_test= np.zeros(len(list_alpha))\ncount = 0\nfor alpha in list_alpha:\n    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n    bayes.fit(X_train, y_train)\n    score_train[count] = bayes.score(X_train, y_train)\n    score_test[count]= bayes.score(X_test, y_test)\n    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n    count = count + 1","b0407490":"matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\nmodels = pd.DataFrame(data = matrix, columns = \n             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\nmodels.head(n=10)","80cfa800":"best_index = models['Test Precision'].idxmax()","a115304d":"models.iloc[best_index, :]","e73e5df6":"models[models['Test Precision']==1].head(n=5)","5b2c8ab3":"best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\nbayes = naive_bayes.MultinomialNB(alpha=list_alpha[best_index])\nbayes.fit(X_train, y_train)\nmodels.iloc[best_index, :]","baf12b9e":"m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\npd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n            index = ['Actual 0', 'Actual 1'])","3e712b1d":"from _pickle import dump\nfilename = 'finalized_model.sav'\ndump(bayes, open(filename, 'wb'))","af83ca38":"We want to find the frequencies of words in the spam and non-spam messages. The words of the messages will be model features.\n\nWe use the function Counter.","bb8e8190":"## Exploring the Dataset","54563537":"## Feature engineering","704e91c0":"The best model I have found is Naive Bayes with 98% accuracy.\n\nIt classifies every non-spam message correctly (Model precision)\n\nIt classifies the 82.5% of spam messages correctly (Model recall)","576ecf5b":"Between these models with the highest possible precision, we are going to select which has more test accuracy.","4eb5d8e0":"Text preprocessing, tokenizing and filtering of stopwords are included in a high level component that is able to build a dictionary of features and transform documents to feature vectors.","ed228552":"## Distribution spam\/non-spam plots","cd57745f":"## Predictive Analysis","56307921":"github - https:\/\/github.com\/ahkhalwai\/SMS_Spam_Detection","85d4ea2f":"## Finalize Model","78737c03":"## Conclusion","0b1fbc00":"## Multinomial naive bayes classifier","308e3f28":"**We remove the stop words in order to improve the analytics**","77e8b3a7":"## Libraries","b1b45053":"We misclassify 44 spam messages as non-spam emails whereas we don't misclassify any non-spam message.","dcbdc171":"# SMS Spam classification with Naive Bayes.","46d3c05d":"Confusion matrix with naive bayes classifier","ff0aab2f":"I select the model with the most test precision","9ad8847b":"## Text Analytics","28a4c59e":"We can see that the majority of frequent words in both classes are stop words such as 'to', 'a', 'or' and so on.\n\nWith stop words we refer to the most common words in a lenguage, there is no simgle, universal list of stop words.","88749285":"We train different bayes models changing the regularization parameter \u03b1 .\n\nWe evaluate the accuracy, recall and precision of the model with the test set.","05e6a389":"My goal is to predict if a new sms is spam or non-spam. I assume that is much worse misclassify non-spam than misclassify an spam. (I don't want to have false positives)\n\nThe reason is because I normally don't check the spam messages.\n\nThe two possible situations are:\n\n- New spam sms in my inbox. (False negative).\n\n  OUTCOME: I delete it.\n\n- New non-spam sms in my spam folder (False positive).\n    \n    OUTCOME: I probably don't read it.\n\nI prefer the first option!!!\n\nFirst we transform the variable spam\/non-spam into binary variable, then we split our data set in training set and test set.","a410e980":"We have created more than 8400 new features. The new feature j in the row i is equal to 1 if the word wj appears in the text example i . It is zero if not.","0585081c":"Let's see the first 10 learning models and their metrics","8f91ad3f":"- Libraries\n- Exploring the Dataset\n- Distribution spam and non-spam plots\n- Text Analytics\n- Feature Engineering\n- Predictive analysis (Multinomial Naive Bayes)\n- Conclusion\n","54e4d6a6":"**My best model does not produce any false positive, which is our goal.**\n\nLet's see if there is more than one model with 100% precision !"}}