{"cell_type":{"0929e347":"code","dbe4f833":"code","678d16be":"code","3091d0c7":"markdown"},"source":{"0929e347":"#@markdown * Clone The Project\n#@markdown * Download Pretrained Models\n#@markdown * Initialize The Voice Cloning Models\n\n%tensorflow_version 1.x\nimport os\nfrom os.path import exists, join, basename, splitext\n\ngit_repo_url = 'https:\/\/github.com\/CorentinJ\/Real-Time-Voice-Cloning.git'\nproject_name = splitext(basename(git_repo_url))[0]\nif not exists(project_name):\n  # clone and install\n  !git clone -q --recursive {git_repo_url}\n  # install dependencies\n  !cd {project_name} && pip install -q -r requirements.txt\n  !pip install -q gdown\n  !apt-get install -qq libportaudio2\n  !pip install -q https:\/\/github.com\/tugstugi\/dl-colab-notebooks\/archive\/colab_utils.zip\n\n  # download pretrained model\n  !cd {project_name} && wget https:\/\/github.com\/blue-fish\/Real-Time-Voice-Cloning\/releases\/download\/v1.0\/pretrained.zip && unzip -o pretrained.zip\n\nimport sys\nsys.path.append(project_name)\n\nfrom IPython.display import display, Audio, clear_output\nfrom IPython.utils import io\nimport ipywidgets as widgets\nimport numpy as np\nfrom dl_colab_notebooks.audio import record_audio, upload_audio\n\nfrom synthesizer.inference import Synthesizer\nfrom encoder import inference as encoder\nfrom vocoder import inference as vocoder\nfrom pathlib import Path\n\nencoder.load_model(project_name \/ Path(\"encoder\/saved_models\/pretrained.pt\"))\nsynthesizer = Synthesizer(project_name \/ Path(\"synthesizer\/saved_models\/pretrained\/pretrained.pt\"))\nvocoder.load_model(project_name \/ Path(\"vocoder\/saved_models\/pretrained\/pretrained.pt\"))","dbe4f833":"#@title Record or Upload\n#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) \n\nSAMPLE_RATE = 22050\nrecord_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\nrecord_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n\nembedding = None\ndef _compute_embedding(audio):\n  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n  global embedding\n  embedding = None\n  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\ndef _record_audio(b):\n  clear_output()\n  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n  _compute_embedding(audio)\ndef _upload_audio(b):\n  clear_output()\n  audio = upload_audio(sample_rate=SAMPLE_RATE)\n  _compute_embedding(audio)\n\nif record_or_upload == \"Record\":\n  button = widgets.Button(description=\"Record Your Voice\")\n  button.on_click(_record_audio)\n  display(button)\nelse:\n  #button = widgets.Button(description=\"Upload Voice File\")\n  #button.on_click(_upload_audio)\n  _upload_audio(\"\")","678d16be":"#@title Synthesize a text { run: \"auto\" }\ntext = \"One of the two people who tested positive for the novel coronavirus in the United Kingdom is a student at the University of York in northern England.\" #@param {type:\"string\"}\n  \ndef synthesize(embed, text):\n  print(\"Synthesizing new audio...\")\n  #with io.capture_output() as captured:\n  specs = synthesizer.synthesize_spectrograms([text], [embed])\n  generated_wav = vocoder.infer_waveform(specs[0])\n  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n  clear_output()\n  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n\nif embedding is None:\n  print(\"first record a voice or upload a voice file!\")\nelse:\n  synthesize(embedding, text)","3091d0c7":"# DEDEEPFAKE-AUDIO"}}