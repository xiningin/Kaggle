{"cell_type":{"166ac7f2":"code","a5725ad1":"code","2a137e67":"code","8e1663bf":"code","77ceddb2":"code","785ad18a":"code","6ccc7c4b":"code","26c71be2":"code","a36a4bbb":"code","df7ce08a":"code","d325766c":"code","48107f4f":"code","abffb548":"code","0a16bf60":"code","6be39926":"code","da415af2":"code","00ce49a7":"code","4a683a1d":"code","65829242":"code","022d1236":"markdown"},"source":{"166ac7f2":"#Those are libraries that I used\nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Visualization libraries\nfrom matplotlib import pyplot as plt\nimport seaborn\n\n# For manupulating the data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\n\n# Models under the Sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\n\n# to calculate the performances of the models \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score # score evaluation\nfrom sklearn.model_selection import cross_val_predict # prediction","a5725ad1":"# Loading the data into the notebook\n# With respect to kaggle working directory the data in 'mushroom-classification' folder\nmush = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\nmush.info()","2a137e67":"# Data types of attributes\nmush.dtypes","8e1663bf":"# Quick overlook to the data\nmush.head()","77ceddb2":"# checking the is there any 'na' data points in the data \nmush.isnull().sum()","785ad18a":"# Plotting the number of classes as in bar plot\nplt.figure(figsize=(7, 3))\nplt.bar(mush['class'].value_counts().index, mush['class'].value_counts().values,color=['orange','pink'])\nplt.show()","6ccc7c4b":"# To do manipulation on data we need to copy of data\ndf = mush.copy()\n# Data has ordinal attributes, The LabelEncoder has been used to make into numerical values  \nLb = LabelEncoder()\n# iterating the encoding all the attributes\nfor features in df.columns:\n    df[features] = Lb.fit_transform(df[features])\ndf.head()","26c71be2":"# \ndf[-100:-1][['class']].value_counts().plot(kind='bar')","a36a4bbb":"# Training varaibles\nX = df.drop(columns=['class'],axis=1)[:-100]\n# Training classes\nY = df['class'][:-100]\n# Testing variables with 100 samples\nx = df.drop(columns=['class'], axis=1)[-100:]\n# Testing classe with 100 samples\ny = df['class'][-100:] ","df7ce08a":"# As in needed my task I have to apply 2-Fold cross validation\nkfold = KFold(n_splits=2, random_state=42, shuffle=True)\ntrain_scores = []\nfor i in range(2,11):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    cv_result = cross_val_score(knn,X,Y,cv=kfold, scoring=\"accuracy\")\n    train_scores.append(cv_result.mean())\nknn_models_performances = pd.DataFrame({'Mean_training_scores':train_scores},index=range(2,11))       ","d325766c":"plt.plot(knn_models_performances.Mean_training_scores,color='orange')\nplt.ylabel('Mean accuracies')\nplt.xlabel('n_neighbors')\nplt.title('Accuricies with respect to number of neighbors')\nplt.legend()\nplt.show()","48107f4f":"# After the getting the results the accurcy has the best result on 2 neighbors\nknn = KNeighborsClassifier(n_neighbors=2)\ntraining_score = []\ntesting_score = []\n\n# For training the KNN on 2 neighbors\nfor train_index, test_index in kfold.split(X):\n#     print(train_index)\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n    knn.fit(X_train,Y_train)\n    training_score.append(knn.score(X,Y))\n    train_predictions = knn.predict(X_test)\n    testing_score.append(accuracy_score(Y_test, train_predictions))","abffb548":"# Results scores\nprint(\"training_score{training_score}\".format(training_score=training_score))\nprint(\"testing_score{testing_score}\".format(testing_score=testing_score))","0a16bf60":"# Validation part of KNN\nval_predictions = knn.predict(x)\ncm = confusion_matrix(y, val_predictions)\nseaborn.heatmap(cm, annot=True)","6be39926":"# Validation scores with using 'classification_report'\nprint(classification_report(y,val_predictions))","da415af2":"# Due to kmeans is a unsupervised learning algorithm no need to split the data into folds\n# Just feeding with training attributes\n# Aim is classification so clustering number is choosed as 2, n_init is choosed randomly, n_jobs is choosed -1 for using all cpus\nkmeans = KMeans(2,init='k-means++',n_init=100,n_jobs=-1)\n# training the kmeans\nkmeans.fit(X)\n\n# Getting the labels which are trained on the data and training classes into the confusion matrix\ncm_1 = confusion_matrix(Y,kmeans.labels_)\n\n# Printing and plotting the results to better see\nprint(cm_1)\nplt.figure(figsize=(7,7))\nseaborn.heatmap(cm_1,annot=True, cmap='Blues')\nplt.show()","00ce49a7":"# Classification report of training\nprint(classification_report(Y,kmeans.labels_))","4a683a1d":"# Validation part\nval_preds = kmeans.predict(x)\ncm_2 = confusion_matrix(y,val_preds)\nprint(cm_2)\n\nseaborn.heatmap(cm_2,annot=True)","65829242":"# Validation results\nprint(classification_report(y,val_preds))","022d1236":"Attribute Information:\n\n1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n4. bruises?: bruises=t,no=f\n5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n6. gill-attachment: attached=a,descending=d,free=f,notched=n\n7. gill-spacing: close=c,crowded=w,distant=d\n8. gill-size: broad=b,narrow=n\n9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n10. stalk-shape: enlarging=e,tapering=t\n11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n16. veil-type: partial=p,universal=u\n17. veil-color: brown=n,orange=o,white=w,yellow=y\n18. ring-number: none=n,one=o,two=t\n19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d"}}