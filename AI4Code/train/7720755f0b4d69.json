{"cell_type":{"91afd203":"code","aaa85868":"code","74aece76":"code","ce24dff1":"code","63641b1b":"code","9f3da6d6":"code","b66f6044":"code","0b2b5945":"code","8af5c6f5":"code","cfa0a12f":"code","f8d4c7b6":"code","6abd7ca1":"code","23eea2ea":"code","6a08f980":"code","27996416":"code","59426532":"code","a9d627a5":"code","e5a4fde6":"markdown","8ed3bb81":"markdown"},"source":{"91afd203":"# ideas: \n# have CSV data -> datetime, url, tags\n\n# about 10.000 articles\n\n# 1. STATISTICAL\n# histograms \/ frequency : how does everything vary by day?\n# browsing during a day: how does everything vary by hour in a day?\n# boxplots: daily frequency\n# by week? \n# \n# frequency: most re-visited articles\n# \n# wordclouds\n# inverse frequency?\n# todo: other\n# \n# 2. CLUSTERING\n# can things be clustered by time? set an alpha and nucleate them (1 hour alpha)\n# do things share similarities inside clusters\n#\n# 3. Wikidata?\n# 4. Transformers\/RNN -> prediction?\n# ","aaa85868":"import pandas\nimport numpy as np\nimport matplotlib.pylab as plt\nimport matplotlib.dates as mdates","74aece76":"a = pandas.read_csv('..\/input\/wikipedia-browsed-articles-timeseries\/wikidata.csv', encoding='ISO-8859-1')","ce24dff1":"a.count()","63641b1b":"print(\"There are {0} rows in the table.\".format(a.count()[\"id\"]))","9f3da6d6":"# which is the oldest entry?\naSorted = a.sort_values([\"browsing_date\"])\naSorted","b66f6044":"aSorted['browsing_date'].max()","0b2b5945":"oldest_entry = aSorted.loc[aSorted['browsing_date'] == aSorted['browsing_date'].min()]\nnewest_entry = aSorted.loc[aSorted['browsing_date'] == aSorted['browsing_date'].max()]","8af5c6f5":"oldest_entry.append(newest_entry)","cfa0a12f":"oldest_date = pandas.to_datetime(oldest_entry['browsing_date'])\nnewest_date = pandas.to_datetime(newest_entry['browsing_date'])","f8d4c7b6":"print(\"Oldest date: {0}\".format(oldest_date.tolist()[0]))\nprint(\"Newest date: {0}\".format(newest_date.tolist()[0]))\nprint((newest_date.tolist()[0] - oldest_date.tolist()[0]))","6abd7ca1":"array = {}\nfor c in aSorted['browsing_date']:\n    today = c.split()[0]\n    array[today] = 1 if today not in array else array[today] + 1","23eea2ea":"x = list(array.keys())\ny = list(array.values())\nprint(len(x))\nprint(len(y))\ndf_plot = pandas.DataFrame()\ndf_plot['x'] = x\ndf_plot['y'] = y\ndf_plot.index = x","6a08f980":"df_plot","27996416":"plt.figure(figsize=(15, 6))\nplt.bar(pandas.to_datetime(df_plot['x']), df_plot['y'])\nax = plt.gca()\nax.xaxis.set_major_locator(mdates.DayLocator(interval=13))\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\nplt.gcf().autofmt_xdate() # Rotation\nplt.show()","59426532":"# Most revisited articles (does not for urls), the browse URL is distinct.\n# Interesting metric is instead tags.","a9d627a5":"dDict = {}\nfor k in aSorted['tags']:\n    dDict[k] = 1 if k not in dDict else dDict[k] + 1\n    # todo: document frequency with library\n    # todo: bag of words\n    # todo: word2vec\n    \nasList = []\nfor k in dDict.keys():\n    #print(k)\n    #print(dDict[k])\n    asList.append((int(dDict[k]), k))\n    \n\nsorted_list_1 = sorted(asList, key=lambda x: x[0], reverse=True)\n#print(sorted_list_1[0:100])\n\n\"\"\"x = np.array(range(0, len(sorted_list_1[0:100])))\ny = np.array([k[0] for k in sorted_list_1][0:100])\nmy_xticks = [k[1] for k in sorted_list_1][0:100]\n\nplt.figure(figsize=(15,10))\nplt.yticks(y, my_xticks, rotation=0)\nplt.barh(y, x)\nplt.show()\"\"\"\n\n\nplt.rcdefaults()\nfig, ax = plt.subplots(figsize=(10, 16))\n\n# Example data\npeople = [k[1] for k in sorted_list_1][0:100]\ny_pos = np.arange(len(people))\nperformance = [k[0] for k in sorted_list_1][0:100]\n\nax.barh(y_pos, performance, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(people)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Number of hits')\nax.set_title('Page hits vs tags')\nplt.yticks(fontsize=7)\nplt.show()","e5a4fde6":"# The sampling covers a period of 255 days.","8ed3bb81":"# There are 10376 rows in the table."}}