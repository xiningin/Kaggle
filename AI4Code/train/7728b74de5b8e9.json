{"cell_type":{"1504f362":"code","55aa5666":"code","696f2a19":"code","7aff4c0f":"code","e2be4780":"code","0047bfe4":"code","365deaa4":"code","cffc5b63":"markdown","c139fe34":"markdown","28d27d1a":"markdown","93ab273f":"markdown","90df5354":"markdown","9800d10e":"markdown","a64605be":"markdown","0928f8c5":"markdown","2101c56a":"markdown"},"source":{"1504f362":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","55aa5666":"# install the following packages in your local notebook\n\n#!pip install google_auth_oauthlib\n#!pip install googleapiclient","696f2a19":"import os\nfrom googleapiclient.discovery import build\nfrom google_auth_oauthlib.flow import InstalledAppFlow\n\n# The CLIENT_SECRETS_FILE variable specifies the name of a file that contains\n# the OAuth 2.0 information for this application, including its client_id and\n# client_secret.\n\n\n\n###########################################\nCLIENT_SECRETS_FILE = \"client_secret.json\" #This is the name of your JSON file, which should be store locally in a folder. This is your access credential file the fucntion is trying to call\n###########################################\n# Here is an example client_secrets.json\n# here is not it should look like once you open it\n#{\n#  \"installed\": {\n#    \"client_id\": \"837647042410-75ifg...usercontent.com\",\n#    \"client_secret\":\"asdlkfjaskd\",\n#    \"redirect_uris\": [\"http:\/\/localhost\", \"urn:ietf:wg:oauth:2.0:oob\"],\n#    \"auth_uri\": \"https:\/\/accounts.google.com\/o\/oauth2\/auth\",\n#    \"token_uri\": \"https:\/\/accounts.google.com\/o\/oauth2\/token\"\n#  }\n#}\n\n\n\n# This OAuth 2.0 access scope allows for full read\/write access to the\n# authenticated user's account and requires requests to use an SSL connection.\nSCOPES = ['https:\/\/www.googleapis.com\/auth\/youtube.force-ssl']\nAPI_SERVICE_NAME = 'youtube'\nAPI_VERSION = 'v3'\n\ndef get_authenticated_service():\n  flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n  credentials = flow.run_console()\n  return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)\n\nos.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\nservice = get_authenticated_service()","7aff4c0f":"query = 'Donald Trump impeachment' #querying subject, same as advanced search option in Youtube\n\nquery_results = service.search().list(\n        part = 'snippet',\n        q = query,\n#       channelId='string', if you want to query a specific channel\n#        videoDuration='any', # long\/med\/short\n        #location='string', specify location of the origin video\n        #locationRadius='string', the serach radius of the origin videos\n        order = 'relevance', # You can consider using viewCount\n        maxResults = 8,\n        type = 'video', # Channels might appear in search results\n        relevanceLanguage = 'en',\n        safeSearch = 'moderate',\n    \n        ).execute()","e2be4780":"# Get Video IDs setup\n\nvideo_id = []\nchannel = []\nvideo_title = []\nvideo_desc = []\nfor item in query_results['items']:\n    video_id.append(item['id']['videoId'])\n    channel.append(item['snippet']['channelTitle'])\n    video_title.append(item['snippet']['title'])\n    video_desc.append(item['snippet']['description'])","0047bfe4":"# Retrive top comments from vide_title\n\nvideo_id_top=[]\nchannel_top = []\nvideo_title_top = []\nvideo_desc_top = []\ncomments_top = []\ncomment_id_top = []\nreply_count_top = []\nlike_count_top = []\n\nfrom tqdm import tqdm # just a visual process bar\n\nfor i, video in enumerate(tqdm(video_id, ncols = 100)):\n# digging into reponse can derive even more information about the user that commented on the video\n    response = service.commentThreads().list(\n                         \n                    part = 'snippet',\n                    videoId = video,\n                    maxResults = 100, # Only take top 100 comments...\n                    order = 'relevance', #... ranked on relevance\n                    textFormat = 'plainText',\n                    ).execute()\n    \n    comments_temp = []\n    comment_id_temp = []\n    reply_count_temp = []\n    like_count_temp = []\n    for item in response['items']:\n        comments_temp.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n        comment_id_temp.append(item['snippet']['topLevelComment']['id'])\n        reply_count_temp.append(item['snippet']['totalReplyCount'])\n        like_count_temp.append(item['snippet']['topLevelComment']['snippet']['likeCount'])\n    comments_top.extend(comments_temp)\n    comment_id_top.extend(comment_id_temp)\n    reply_count_top.extend(reply_count_temp)\n    like_count_top.extend(like_count_temp)\n    \n    video_id_top.extend([video_id[i]]*len(comments_temp))\n    channel_top.extend([channel[i]]*len(comments_temp))\n    video_title_top.extend([video_title[i]]*len(comments_temp))\n    video_desc_top.extend([video_desc[i]]*len(comments_temp))\n    \nquery_top = [query] * len(video_id_top)","365deaa4":"# Read into Dataframe\n\nimport pandas as pd\n\noutput_dict = {\n        'Query': query_top,\n        'Channel': channel_top,\n        'Video Title': video_title_top,\n        'Video Description': video_desc_top,\n        'Video ID': video_id_top,\n        'Comment': comments_top,\n        'Comment ID': comment_id_top,\n        'Replies': reply_count_top,\n        'Likes': like_count_top,\n        }\n\noutput_df = pd.DataFrame(output_dict, columns = output_dict.keys())","cffc5b63":"![image.png](attachment:image.png)","c139fe34":"### use this script to collect youtube video comments in neat pandas format for NLP or advanced analytics\n\n#### The following code **works on any local python 3 notebook**. Currently, this cannot be done directly on Kaggle, there isn't a method that I know of to call json file directly into Kaggle notebook. I know that you can do it for google collab, but this is for youtube, thus the credentials are a bit different.\n\n#### step 1. before you can start using this code, you need to get Google API authentication with OAuth 2.0\n\n#### here is a link to a medium blog by Pawe\u0142 \u015awiderski for steps to get access. He does a good job at explaining the process and it's surely easier than trying to obtain twitter API access.\n\n#### https:\/\/medium.com\/@pablo127\/google-api-authentication-with-oauth-2-on-the-example-of-gmail-a103c897fd98\n\n#### once you have Google API authentication credential then you can use the following code **locally**.\n\n#### note: ignore the errors in this illustration it will not occur in local notebook\n","28d27d1a":"for more indepth control for all the avaliable parameters\n\nhttps:\/\/developers.google.com\/youtube\/v3\/docs\/commentThreads\/list","93ab273f":"![image.png](attachment:image.png)","90df5354":"#### Once the previous step successfully called the client_secret.json file the notebook will ask you to click on the following link for permission to access your google account.\n\n#### click on the URL to authorize this application, paste the authorization code","9800d10e":"![image.png](attachment:image.png)","a64605be":"![image.png](attachment:image.png)","0928f8c5":"#output_df, ready for analysis","2101c56a":"![image.png](attachment:image.png)"}}