{"cell_type":{"98d7a770":"code","462352c7":"code","9049014f":"code","b5e0c638":"code","b3ece38b":"code","b5ef16a7":"code","0f0ca169":"code","cf363ca8":"code","b9c4be98":"code","ad9ad369":"code","b312416f":"code","cce03a9a":"code","010dfeec":"code","5156fce5":"code","d2ca21e0":"code","7c7d34f8":"code","78496d7f":"code","7b37b260":"code","adb88975":"code","a0468d46":"code","0353513c":"code","aa631d0e":"code","3898228f":"code","ae15136e":"code","ef761ec2":"code","cffde6df":"code","e4e24738":"code","1d7d07ca":"code","40c2dc6e":"code","0f41d34b":"code","fbc8a5a2":"code","40fec9fb":"code","d6bff50d":"code","eb508fb2":"code","414065da":"code","51033be7":"code","fd42c315":"code","f7233c27":"code","fe5b7f80":"code","2ad66b70":"code","ed97f79f":"code","d06287fe":"code","497b521b":"code","e0e5385c":"code","0c9f09cf":"code","154533ef":"code","21a88116":"code","aa0b93f7":"code","96b83858":"code","2fb59d3b":"code","f8ad9363":"code","613c5702":"code","5bebf142":"code","cb79743c":"code","68005aa7":"code","23ae6311":"code","66a98fa4":"code","9a5fb6eb":"code","fb635817":"code","07a63ec6":"code","960f2b04":"code","c48b5540":"code","13dc2f60":"code","6a018b7a":"code","1e1de308":"code","375ba260":"code","11c430ed":"code","494868ac":"code","7d21c23f":"code","98b72845":"code","9176377f":"code","d8772bf3":"code","15a7fc18":"code","1568d293":"code","e036195d":"code","605281f4":"code","5c05bac1":"code","12a902be":"code","648da4a6":"code","cc149b3f":"code","bda110be":"code","35ef97ed":"code","51c8f98d":"code","cec75549":"code","c68d9e99":"code","48247aa1":"code","0e8d44b0":"code","e6dca9c3":"code","e28a4412":"code","615550e8":"code","0421db9e":"code","d070a12d":"code","59da5d82":"code","731a5341":"code","b23ea2d8":"code","8807ec08":"code","22f8a9f5":"code","423911ff":"code","66373a22":"code","ada48f9b":"code","942e5d81":"code","31be7ee9":"code","a24bb721":"code","7d951455":"markdown","c76d4595":"markdown","0cbb5321":"markdown","076a41ef":"markdown","7cfe0ea9":"markdown"},"source":{"98d7a770":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","462352c7":"import gc\ngc.collect()","9049014f":"# !pip install pretrainedmodels\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n!pip install fastai==1.0.52\nimport fastai\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.tabular import *\n\n# from torchvision.models import *\n# import pretrainedmodels\n\nfrom utils import *\nimport sys\n\nfrom fastai.callbacks.hooks import *\n\nfrom fastai.callbacks.tracker import EarlyStoppingCallback\nfrom fastai.callbacks.tracker import SaveModelCallback","b5e0c638":"from sklearn.metrics import roc_auc_score\n\ndef auroc_score(input, target):\n    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n    return roc_auc_score(target, input)\n\nclass AUROC(Callback):\n    _order = -20 #Needs to run before the recorder\n\n    def __init__(self, learn, **kwargs): self.learn = learn\n    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n    \n    def on_batch_end(self, last_target, last_output, train, **kwargs):\n        if not train:\n            self.output.append(last_output)\n            self.target.append(last_target)\n                \n    def on_epoch_end(self, last_metrics, **kwargs):\n        if len(self.output) > 0:\n            output = torch.cat(self.output)\n            target = torch.cat(self.target)\n            preds = F.softmax(output, dim=1)\n            metric = auroc_score(preds, target)\n            return add_metrics(last_metrics, [metric])","b3ece38b":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","b5ef16a7":"df_train.shape, df_test.shape","0f0ca169":"df_train.columns","cf363ca8":"df_test.columns","b9c4be98":"df_train['target'].value_counts()","ad9ad369":"df_train.head()","b312416f":"df_train.drop(['id'], axis=1, inplace=True)","cce03a9a":"df_train.head()","010dfeec":"df_test.drop(['id'], axis=1, inplace=True)","5156fce5":"df_test.head()","d2ca21e0":"from scipy.special import erfinv\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import *\nfrom torch.optim import *\nfrom fastai.tabular import *\nimport torch.utils.data as Data\nfrom fastai.basics import *\nfrom fastai.callbacks.hooks import *\nfrom tqdm import tqdm_notebook as tqdm","7c7d34f8":"def to_gauss(x): return np.sqrt(2)*erfinv(x)  #from scipy\n\ndef normalize(data, exclude=None):\n    # if not binary, normalize it\n    norm_cols = [n for n, c in data.drop(exclude, 1).items() if len(np.unique(c)) > 2]\n    n = data.shape[0]\n    for col in norm_cols:\n        sorted_idx = data[col].sort_values().index.tolist()# list of sorted index\n        uniform = np.linspace(start=-0.99, stop=0.99, num=n) # linsapce\n        normal = to_gauss(uniform) # apply gauss to linspace\n        normalized_col = pd.Series(index=sorted_idx, data=normal) # sorted idx and normalized space\n        data[col] = normalized_col # column receives its corresponding rank\n    return data","78496d7f":"norm_data = normalize(df_train, exclude=['target'])","7b37b260":"norm_data.head()","adb88975":"norm_data_new = norm_data.drop(['target'], axis=1)\ncont_names = norm_data_new.columns\ndep_var = 'target'\nprocs = [FillMissing, Categorify]\ncat_names=[]","a0468d46":"data = (TabularList.from_df(norm_data, procs = procs, cont_names=cont_names)\n        .split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols=dep_var)\n        .databunch(bs=1024))","0353513c":"# data.add_test(TabularList.from_df(df_test, cont_names=cont_names))","aa631d0e":"data.show_batch()","3898228f":"learn = tabular_learner(data, layers=[1000,500], ps=[0.1, 0.1], metrics=accuracy, emb_drop=0.04)","ae15136e":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","ef761ec2":"lr = 1e-3\nlearn.fit_one_cycle(5, max_lr=lr,  pct_start=0.3, wd = 0.2)","cffde6df":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","e4e24738":"learn.recorder.plot_losses()","1d7d07ca":"lr=1e-4\nlearn.fit_one_cycle(5, max_lr=lr,  pct_start=0.3, wd = 0.2)","40c2dc6e":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","0f41d34b":"learn.recorder.plot_losses()","fbc8a5a2":"lr= 5e-4\nlearn.fit_one_cycle(5, max_lr=lr, wd=0.2)","40fec9fb":"learn.recorder.plot_losses()","d6bff50d":"learn.save('1st-round')\nlearn.load('1st-round')","eb508fb2":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","414065da":"interp.plot_confusion_matrix(figsize=(8,8), dpi=60)","51033be7":"class SaveFeatures():\n    features=None\n    def __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n        self.features = None\n    def hook_fn(self, module, input, output): \n        out = output.detach().cpu().numpy()\n        if isinstance(self.features, type(None)):\n            self.features = out\n        else:\n            self.features = np.row_stack((self.features, out))\n    def remove(self): \n        self.hook.remove()","fd42c315":"learn.model","f7233c27":"sf = SaveFeatures(learn.model.layers[4])","fe5b7f80":"_= learn.get_preds(data.train_ds)","2ad66b70":"label = [data.classes[x] for x in (list(data.train_ds.y.items))]","ed97f79f":"len(label)","d06287fe":"df_new = pd.DataFrame({'label': label})","497b521b":"df_new['label'].value_counts()","e0e5385c":"array = np.array(sf.features)","0c9f09cf":"x=array.tolist()","154533ef":"df_new['img_repr'] = x","21a88116":"df_new.head()","aa0b93f7":"d2 = pd.DataFrame(df_new.img_repr.values.tolist(), index = df_new.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","96b83858":"df_new_2 = df_new.join(d2)","2fb59d3b":"df_new_2.head(10)","f8ad9363":"df_new_2.shape","613c5702":"sf = SaveFeatures(learn.model.layers[4])","5bebf142":"_=learn.get_preds(DatasetType.Valid)","cb79743c":"data.valid_ds.y.items","68005aa7":"label = [data.classes[x] for x in (list(data.valid_ds.y.items))]","23ae6311":"df_new_valid = pd.DataFrame({'label': label})","66a98fa4":"df_new_valid['label'].value_counts()","9a5fb6eb":"array = np.array(sf.features)","fb635817":"x=array.tolist()","07a63ec6":"df_new_valid['img_repr'] = x","960f2b04":"df_new_valid.head()","c48b5540":"d2 = pd.DataFrame(df_new_valid.img_repr.values.tolist(), index = df_new_valid.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","13dc2f60":"df_new_valid_2 = df_new_valid.join(d2)","6a018b7a":"df_new_valid_2.head(10)","1e1de308":"df_new_valid_2.shape","375ba260":"df_new_valid_2.drop(['img_repr'], axis=1, inplace=True)","11c430ed":"df_new_valid_2.head()","494868ac":"df_new_2.drop(['img_repr'], axis=1, inplace=True)","7d21c23f":"df_new_2.shape","98b72845":"df_new_2.describe()","9176377f":"matfig = plt.figure(figsize=(10,10))\ncorr_matrix = df_new_2.corr()\nplt.matshow(corr_matrix, fignum=matfig.number)\nplt.show()","d8772bf3":"X = df_new_2\ny = df_new_2.label.copy()\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42)","15a7fc18":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","1568d293":"X_train = X_train.drop(\"label\", axis =1)\ny_train = y_train\n\nX_test = X_test.drop(\"label\", axis =1)\ny_test = y_test","e036195d":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","605281f4":"X_train.columns","5c05bac1":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, attributes_names):\n        self.attributes_names = attributes_names\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attributes_names].values","12a902be":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_train.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\nX_train_transformed = num_pipeline.fit_transform(X_train)\nX_test_transformed = num_pipeline.fit_transform(X_test)","648da4a6":"X_train_transformed.shape, X_test_transformed.shape","cc149b3f":"# import scipy.stats as st\n# from sklearn.model_selection import RandomizedSearchCV\n# from sklearn.ensemble import RandomForestClassifier\n\n# rf_clf = RandomForestClassifier(random_state=42)\n\n# one_to_left = st.beta(10, 1)  \n# from_zero_positive = st.expon(0, 50)\n\n# params = {  \n#     \"n_estimators\": st.randint(50, 300),\n#     \"max_depth\": st.randint(3, 40),\n#    \"min_samples_leaf\": st.randint(3, 40),\n#     \"min_samples_split\": st.randint(3, 20),\n#     \"max_features\":['auto', 0.2, 0.5]\n# }\n\n# gs = RandomizedSearchCV(rf_clf, params, cv=3)","bda110be":"# gs.fit(X_train_transformed, y_train)  ","35ef97ed":"# gs.best_params_","51c8f98d":"from sklearn.ensemble import RandomForestClassifier\nimport time\n\nstart = time.time()\n\nrf_clf = RandomForestClassifier(bootstrap=True,\n            criterion='gini', max_depth=35, max_features=0.2,\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=14,\n            min_samples_split=8, min_weight_fraction_leaf=0.0,\n            n_estimators=180, n_jobs=1, oob_score=False, random_state=42,\n            verbose=3, warm_start=False)\n\nrf_clf.fit(X_train_transformed, y_train)\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","cec75549":"from sklearn.model_selection import cross_val_predict, cross_val_score\n\nimport time\n\nstart = time.time()\n\nscore_rf = cross_val_score(rf_clf, X_train_transformed, y_train, cv=3, scoring='accuracy', verbose=0)\nprint(score_rf.mean())\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","c68d9e99":"from sklearn.model_selection import cross_val_predict\n\nimport time\n\nstart = time.time()\n\ny_train_pred_rf = cross_val_predict(rf_clf, X_train_transformed, y_train, cv=3, verbose=0)\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","48247aa1":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_train, y_train_pred_rf)","0e8d44b0":"import seaborn as sns\nimport matplotlib.pyplot as plt  \n\nplt.figure(figsize=(15,12))\n\nax= plt.subplot()\nsns.heatmap(cm.astype('float').astype('int'), annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']); ax.yaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']);","e6dca9c3":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_train, y_train_pred_rf, average='weighted'))\nprint(recall_score(y_train, y_train_pred_rf, average='weighted'))\nprint(f1_score(y_train, y_train_pred_rf, average='weighted'))\nprint(cohen_kappa_score(y_train, y_train_pred_rf))\n\nprint(classification_report(y_train, y_train_pred_rf))","e28a4412":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_train, y_train_pred_rf, average='macro'))\nprint(recall_score(y_train, y_train_pred_rf, average='macro'))\nprint(f1_score(y_train, y_train_pred_rf, average='macro'))\nprint(cohen_kappa_score(y_train, y_train_pred_rf))\n\nprint(classification_report(y_train, y_train_pred_rf))","615550e8":"y_pred_test_rf = rf_clf.predict(X_test_transformed)","0421db9e":"confusion_matrix(y_test, y_pred_test_rf)","d070a12d":"cm = confusion_matrix(y_test, y_pred_test_rf)","59da5d82":"import seaborn as sns\nimport matplotlib.pyplot as plt  \n\nplt.figure(figsize=(15,12))\n\nax= plt.subplot()\nsns.heatmap(cm.astype('float').astype('int'), annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']); ax.yaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']);","731a5341":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_test, y_pred_test_rf, average='weighted'))\nprint(recall_score(y_test, y_pred_test_rf, average='weighted'))\nprint(f1_score(y_test, y_pred_test_rf, average='weighted'))\nprint(cohen_kappa_score(y_test, y_pred_test_rf))\n\nprint(classification_report(y_test, y_pred_test_rf))","b23ea2d8":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_test, y_pred_test_rf, average='macro'))\nprint(recall_score(y_test, y_pred_test_rf, average='macro'))\nprint(f1_score(y_test, y_pred_test_rf, average='macro'))\nprint(cohen_kappa_score(y_test, y_pred_test_rf))\n\nprint(classification_report(y_test, y_pred_test_rf))","8807ec08":"X = df_new_valid_2\ny = df_new_valid_2.label.copy()","22f8a9f5":"X_val = X.drop(\"label\", axis =1)\ny_val = y","423911ff":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_val.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\n\nX_val_transformed = num_pipeline.fit_transform(X_val)","66373a22":"y_pred_test_rf_val = rf_clf.predict(X_val_transformed)","ada48f9b":"cm = confusion_matrix(y_val, y_pred_test_rf_val)","942e5d81":"import seaborn as sns\nimport matplotlib.pyplot as plt  \n\nplt.figure(figsize=(15,12))\n\nax= plt.subplot()\nsns.heatmap(cm.astype('float').astype('int'), annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']); ax.yaxis.set_ticklabels([ '1', '2', '3', '4', '5', '6', '7', '8', '9']);","31be7ee9":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_val, y_pred_test_rf_val, average='weighted'))\nprint(recall_score(y_val, y_pred_test_rf_val, average='weighted'))\nprint(f1_score(y_val, y_pred_test_rf_val, average='weighted'))\nprint(cohen_kappa_score(y_val, y_pred_test_rf_val))\n\nprint(classification_report(y_val, y_pred_test_rf_val))","a24bb721":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_val, y_pred_test_rf_val, average='macro'))\nprint(recall_score(y_val, y_pred_test_rf_val, average='macro'))\nprint(f1_score(y_val, y_pred_test_rf_val, average='macro'))\nprint(cohen_kappa_score(y_val, y_pred_test_rf_val))\n\nprint(classification_report(y_val, y_pred_test_rf_val))","7d951455":"# Embeddings for Valid Data","c76d4595":"# Performance on Unseen Test","0cbb5321":"# Fastai Hooks & Embeddings for Train data","076a41ef":"# Random Forest","7cfe0ea9":"# Performance on Valid Data"}}