{"cell_type":{"e83d8385":"code","650681a5":"code","cb6ae969":"code","60df2486":"code","7e1e33f0":"code","be8c8f02":"code","c4c3bdb9":"code","1e17a6d3":"code","77948959":"code","d0cc80b2":"code","fbff0f66":"code","754bc262":"code","b8b2e83b":"code","8b1d06f5":"code","3b31adc3":"code","7eef522f":"code","0eaa5437":"code","2e1ccd11":"code","d50ef443":"code","9451b430":"markdown","aa427002":"markdown","35db9a4c":"markdown"},"source":{"e83d8385":"%matplotlib inline\n#\u9019\u662fjuoyter notebook\u7684magic word\u02d9\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom IPython import display","650681a5":"import os\n#\u5224\u65b7\u662f\u5426\u5728jupyter notebook\u4e0a\ndef is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv('_', ''))\n\n    if ('jupyter-notebook' in program_name or # jupyter-notebook\n        'ipython'          in program_name or # ipython\n        'jupyter' in program_name or  # jupyter\n        'JPY_PARENT_PID'   in os.environ):    # ipython-notebook\n        return True\n    else:\n        return False\n\n\n#\u5224\u65b7\u662f\u5426\u5728colab\u4e0a\ndef is_in_colab():\n    if not is_in_ipython(): return False\n    try:\n        from google import colab\n        return True\n    except: return False\n\n#\u5224\u65b7\u662f\u5426\u5728kaggke_kernal\u4e0a\ndef is_in_kaggle_kernal():\n    if 'kaggle' in os.environ['PYTHONPATH']:\n        return True\n    else:\n        return False\n\nif is_in_colab():\n    from google.colab import drive\n    drive.mount('\/content\/gdrive')","cb6ae969":"os.environ['TRIDENT_BACKEND'] = 'pytorch'\n\nif is_in_kaggle_kernal():\n    os.environ['TRIDENT_HOME'] = '.\/trident'\n    \nelif is_in_colab():\n    os.environ['TRIDENT_HOME'] = '\/content\/gdrive\/My Drive\/trident'\n\n#\u70ba\u78ba\u4fdd\u5b89\u88dd\u6700\u65b0\u7248 \n!pip uninstall tridentx -y\n!pip install tridentx --upgrade\n\nimport copy\nimport numpy as np\n#\u8abf\u7528trident api\nimport trident as T\nfrom trident import *\nfrom trident.models import resnet,efficientnet","60df2486":"import glob\n#\u900f\u904eglob\u6240\u5168\u90e8train\u8cc7\u6599\u593e\u4e2d\u6240\u6709\u53ef\u7528\u5716\u7247\nimgs=glob.glob('..\/input\/histopathologic-cancer-detection\/train\/*.tif')\nprint(len(imgs))\n\n#ImageDatset(imgs,symbol='image')\nf=open('..\/input\/histopathologic-cancer-detection\/train_labels.csv','r',encoding='utf-8-sig')\nrows=f.readlines()\nprint(rows[:3])\nimage_path=[]\nlabels=[]\ntest_image_path=[]\ntest_labels=[]\n\nrows=rows[1:] #\u62ff\u6389\u7b2c\u4e00\u7b46\u6a19\u982d\nrandom.shuffle(rows)#\u96a8\u6a5f\u6d17\u724c\nfor row in rows:\n    cols=row.strip().split(',') #\u79fb\u9664\\n\u7136\u5f8c\u9017\u865f\u5206\u5272\n    if random.random()<=0.3:\n        test_image_path.append('..\/input\/histopathologic-cancer-detection\/train\/{0}.tif'.format(cols[0]))\n        test_labels.append(int(cols[1]))\n    else:\n        image_path.append('..\/input\/histopathologic-cancer-detection\/train\/{0}.tif'.format(cols[0]))\n        labels.append(int(cols[1]))\nprint(len(image_path))\nprint(len(labels))\nprint(len(test_image_path))\nprint(len(test_labels))\n","7e1e33f0":"#\u8cc7\u6599\u96c6\nds1=ImageDataset(image_path,symbol='image')\nds2=LabelDataset(labels,symbol='label')\n\nds1_t=ImageDataset(test_image_path,symbol='image')\nds2_t=LabelDataset(test_labels,symbol='label')\n\n#\u8207Iterator\u69cb\u6210data provider\ndata_provider=DataProvider(traindata=Iterator(data=ds1,label=ds2),testdata=Iterator(data=ds1_t,label=ds2_t))\n\n#\u8a2d\u5b9aDataProvider\u7684\u9810\u8655\u7406\u6d41\u7a0b\ndata_provider.image_transform_funcs=[Normalize(127.5,127.5)]\n\n#\u5373\u53ef\u5b8c\u6210\u8a2d\u5b9a\uff0c\u53ef\u4ee5\u900f\u904enext()\u4f86\u78ba\u8a8d\u6578\u64da\u662f\u5426\u6b63\u5e38\u62cb\u51fa\uff0c\u4ee5\u53ca\u662f\u5426\u6709\u6b63\u78ba\u7522\u751f\u8f38\u51fa\u6578\u64da\u7684signature\nimg_data,label_data=data_provider.next()\nprint(data_provider.signature)\nprint(img_data.shape)\nprint(label_data.shape)\n\ndata_provider.image_transform_funcs=[\n    RandomAdjustGamma(scale=(0.6,1.4)),#\u8abf\u6574\u660e\u6697\n    RandomAdjustHue(scale=(-0.5,0.5)),#\u8abf\u6574\u8272\u76f8\n    RandomAdjustSaturation(scale=(0.6,1.4)),#\u8abf\u6574\u98fd\u548c\u5ea6\n    SaltPepperNoise(0.05),#\u52a0\u5165\u80e1\u6912\u9e7d\u566a\u97f3\n    RandomErasing(), #\u52a0\u5165\u96a8\u6a5f\u64e6\u53bb\n    Normalize(127.5,127.5)] #\u6a19\u6e96\u5316\n\n#\u6e2c\u8a66\u96c6\u6578\u64da\u4e0d\u9700\u8981\u505a\u6578\u64da\u589e\u5f37\ndata_provider.testdata.data.image_transform_funcs=[\n    Normalize(127.5,127.5)] #\u6a19\u6e96\u5316\n\nimg_data,label_data=data_provider.next()\nprint(img_data.shape)\nprint(label_data.shape)\ntest_img_data,test_label_data=data_provider.next_test()\nprint(test_img_data.shape)\nprint(test_label_data.shape)\ndata_provider.preview_images()","be8c8f02":"from trident.models import efficientnet,densenet,resnet\nnet1=efficientnet.EfficientNetB0(pretrained=True,include_top=True,freeze_features=True,input_shape=(3,96,96),classes=2)\nnet1.model[-1].add_noise=True\nnet1.model[-1].noise_intensity=0.12\n","c4c3bdb9":"class CustomCropFlatten(Layer):\n    \"\"\"\n  \n    \"\"\"\n    def __init__(self,name='CustomCropFlatten'):\n        super(CustomCropFlatten, self).__init__()\n        self.name = name\n\n    def forward(self, x, **kwargs):\n        #(None, 112, 6, 6)\n        #target_area=2x2\n        target=x[:,:,2:4,2:4]\n        B,C,H,W=int_shape(target)\n        outside1=reduce_max(x[:,:,1,1:5],axis=-1)\n        outside2=reduce_max(x[:,:,4,1:5],axis=-1)\n        outside3=reduce_max(x[:,:,1:5,1],axis=-1)\n        outside4=reduce_max(x[:,:,1:5,4],axis=-1)\n        outside=stack([outside1,outside2,outside3,outside4],axis=-1)\n        target=reshape(target,(B,C,-1))\n        return reshape(concate([target,outside],axis=-1),(B,-1))\n\nnet2=efficientnet.EfficientNetB0(pretrained=True,include_top=False,freeze_features=True,input_shape=(3,96,96),classes=2)\nnet2.model.remove_at(-1)\nnet2.model.remove_at(-1)\nnet2.model.remove_at(-1)\nnet2.model.remove_at(-1)\nnet2.model.remove_at(-1)\nnet2.model.remove_at(-1)\nnet2.model.add_module('custom',CustomCropFlatten())\nnet2.model.add_module('fc',Dense(2,activation=None))\nnet2.model.add_module('softmax',SoftMax(-1,add_noise=True,noise_intensity=0.12))\nnet2.summary()\n","1e17a6d3":"net3=resnet.ResNet50(pretrained=True,include_top=False,freeze_features=True,input_shape=(3,96,96),classes=2)\nnet3.model.remove_at(-1)\nnet3.model.add_module('custom',CustomCropFlatten())\nnet3.model.add_module('fc',Dense(2,activation=None))\nnet3.model.add_module('softmax',SoftMax(axis=-1,add_noise=True,noise_intensity=0.12))\nnet3.summary()","77948959":"from sklearn.metrics import roc_curve, auc, roc_auc_score\n# make a prediction\n\ndef auc(output,target):\n    \n    output_np=to_numpy(exp(output))[:,1]\n    target_np=to_numpy(target)\n    return roc_auc_score(target_np, output_np)\n\n","d0cc80b2":"def punishment(output,target):\n    mask=target==1\n    mask_neg=target==0\n    output=where(is_abnormal_number(output),zeros_like(output),output.copy())#\u5982\u679c\u51fa\u73fe\u7570\u5e38\u503c\uff0c\u5247\u88dc\u96f6\n    masked_positive=exp(output)[:,1][mask]\n    masked_negative=exp(output)[:,1][mask_neg]\n    return 1-clip(masked_positive.mean()-masked_negative.mean(),0.0,1.0)\n    ","fbff0f66":"#challenger1 \u4f7f\u7528DiffGrad\u512a\u5316\u5668\u3001\u7d2f\u7a4d\u68af\u5ea6\nnet1.with_optimizer(AdaBelief,lr=2e-3,gradient_centralization='all')\\\n.with_loss(CrossEntropyLoss(auto_balance=True, label_smooth=True))\\\n.with_loss(F1ScoreLoss,loss_weight=0.5)\\\n.with_loss(punishment,loss_weight=0.01)\\\n.with_metric(accuracy,ignore_index=0)\\\n.with_metric(recall,ignore_index=0)\\\n.with_metric(auc)\\\n.with_regularizer('l2',1e-3)\\\n.with_model_save_path('.\/Models\/eff_1.pth')\\\n.with_callbacks(CosineLR(max_lr=2e-3, min_lr=1e-7,period=5000))\\\n.unfreeze_model_scheduling(300,unit='batch',module_name='block7a')\\\n\n\n#challenger1 \u4f7f\u7528DiffGrad\u512a\u5316\u5668\u3001\u7d2f\u7a4d\u68af\u5ea6\nnet2.with_optimizer(AdaBelief,lr=2e-3,gradient_centralization='all')\\\n.with_loss(CrossEntropyLoss(auto_balance=True, label_smooth=True))\\\n.with_loss(F1ScoreLoss,loss_weight=0.5)\\\n.with_loss(punishment,loss_weight=0.01)\\\n.with_metric(accuracy,ignore_index=0)\\\n.with_metric(recall,ignore_index=0)\\\n.with_metric(auc)\\\n.with_regularizer('l2',1e-3)\\\n.with_model_save_path('.\/Models\/eff_2.pth')\\\n.with_callbacks(CosineLR(max_lr=2e-3, min_lr=1e-7,period=5000))\\\n.unfreeze_model_scheduling(300,unit='batch',module_name='block5c')\n\n\n\n#challenger1 \u4f7f\u7528DiffGrad\u512a\u5316\u5668\u3001\u7d2f\u7a4d\u68af\u5ea6\nnet3.with_optimizer(AdaBelief,lr=2e-3,gradient_centralization='all')\\\n.with_loss(CrossEntropyLoss(auto_balance=True, label_smooth=True))\\\n.with_loss(F1ScoreLoss,loss_weight=0.5)\\\n.with_loss(punishment,loss_weight=0.01)\\\n.with_metric(accuracy,ignore_index=0)\\\n.with_metric(recall,ignore_index=0)\\\n.with_metric(auc)\\\n.with_regularizer('l2',1e-3)\\\n.with_model_save_path('.\/Models\/resnet_1.pth')\\\n.with_callbacks(CosineLR(max_lr=2e-3, min_lr=1e-7,period=5000))\\\n.unfreeze_model_scheduling(300,unit='batch',module_name='layer3.5')","754bc262":"\n#\u4f7f\u7528outsample\u9a57\u8b49\ndef draw_roc(training_context): #\u5efa\u6a21\u8a13\u7df4\u968e\u6bb5\u90fd\u9760training_context\u901a\u8a0a\uff0c\u50b3\u905e\u6240\u6709\u9700\u8981\u7684\u8a0a\u606f\n    if training_context['steps']==10 or (training_context['steps']+1)%100==0:\n        model=training_context['current_model']\n        model.eval()  #\u5207\u63db\u70ba\u63a8\u8ad6\u6a21\u5f0f\n        traindata=training_context['train_data'] #\u53d6\u51fa\u6e2c\u8a66\u6578\u64da\n        input_data=traindata['image'].copy()#\u8907\u88fd\u4e00\u4efd\u907f\u514d\u8207\u640d\u5931\u51fd\u6578\u8a08\u7b97\u6642\u5e72\u64fe\n        target_data=traindata['label'].copy() #\u8907\u88fd\u4e00\u4efd\u907f\u514d\u8207\u640d\u5931\u51fd\u6578\u8a08\u7b97\u6642\u5e72\u64fe\n        \n       \n        if not any_abnormal_number(input_data):#\u78ba\u8a8d\u8f38\u5165\u6578\u64da\u6c92\u6709nan\u8207inf\n            target_np=to_numpy(target_data)\n            \n            output=model(input_data)\n            output=where(is_abnormal_number(output),zeros_like(output),output.copy())#\u5982\u679c\u51fa\u73fe\u7570\u5e38\u503c\uff0c\u5247\u88dc\u96f6\n            output_np=to_numpy(output) #\u63a8\u8ad6\u968e\u6bb5softmax\u5c31\u6703\u662f\u4e00\u822csoftmax(\u8a13\u7df4\u968e\u6bb5\u662flog_softmax)\uff0c\u6240\u4ee5\u4e0d\u5fc5\u518d\u505a\u8655\u7406\uff0c\u800c\u4e14\u6240\u6709noise, dropout\u90fd\u6703\u6d88\u5931\n            model.train()#\u8a08\u7b97\u5b8c\u5207\u56de\u8a13\u7df4\u6a21\u5f0f\n            fpr, tpr,_=roc_curve(target_np, output_np[:,1])\n            if not any_abnormal_number(fpr) and not any_abnormal_number(tpr):\n                plt.figure(1)\n                plt.plot([0, 1], [0, 1], 'k--')\n                plt.plot(fpr, tpr, label='area = {:.3f}'.format(roc_auc_score(target_np, output_np[:,1])))\n                plt.xlabel('False positive rate')\n                plt.ylabel('True positive rate')\n                plt.title('ROC curve')\n                plt.legend(loc='best')\n                plt.show()\n        \nnet1.trigger_when('on_batch_end', frequency=1, action=draw_roc)\nnet2.trigger_when('on_batch_end', frequency=1, action=draw_roc)\nnet3.trigger_when('on_batch_end', frequency=1, action=draw_roc)","b8b2e83b":"plan=TrainingPlan()\\\n    .add_training_item(net1,name='net1')\\\n    .add_training_item(net2,name='net2')\\\n    .add_training_item(net3,name='net3')\\\n    .with_data_loader(data_provider)\\\n    .with_batch_size(256)\\\n    .repeat_epochs(1)\\\n    .out_sample_evaluation_scheduling(100)\\\n    .print_gradients_scheduling(100,unit='batch')\\\n    .print_progress_scheduling(10,unit='batch')\\\n    .display_loss_metric_curve_scheduling(200)\\\n    .save_model_scheduling(20,unit='batch')","8b1d06f5":"plan.start_now(collect_data_inteval=10)","3b31adc3":"for dirname, _, filenames in os.walk('.'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#\u53d6\u56de\u4f60\u7684\u6a21\u578b\u7684\u6700\u7c21\u55ae\u65b9\u6cd5\nfrom IPython.display import FileLink\nFileLink('.\/Models\/net3.pth')","7eef522f":"f=open('..\/input\/histopathologic-cancer-detection\/sample_submission.csv','r',encoding='utf-8-sig')\nrows=f.readlines()\nprint(rows[:5])","0eaa5437":"from tqdm import tqdm\nsummit_imgs=glob.glob('..\/input\/histopathologic-cancer-detection\/test\/*.tif')\nbest_model=net3\n#\u9019\u53e5\u8d85\u6975\u91cd\u8981\uff0c\u5fd8\u8a18\u4e86\u5c31\u4e00\u5207\u767d\u505a\u4e86\nbest_model.eval()\nbest_model.class_names=[]\nbest_model.preprocess_flow=[Normalize(127.5,127.5)]\n\nresults=OrderedDict()\nsubmission_rows=[]\nsubmission_rows.append('id,label\\n')\n\nfor i in tqdm(range(len(summit_imgs))):\n    summit_key=summit_imgs[i].split('\/')[-1].replace('.tif','')#\u5f9e\u5716\u6a94\u4f4d\u7f6e\u53d6\u51fa\u5716\u6a94\u7de8\u865f\n    infer_results=best_model.infer_single_image(summit_imgs[i])#\u5192\u865f\u662f\u6307\u53d6\u6240\u6709\u6279\u6b21\u8ef8\uff0c1\u662f\u6307\u53d6\u967d\u6027\u7684\u6a5f\u7387  \n    results[summit_key]=infer_results[1].item() #\u4ee5key-value\u5f62\u5f0f\u5beb\u5165\n    submission_rows.append('{0},{1}\\n'.format(summit_key,results[summit_key]))\n    if len(submission_rows)<=10:\n        print('submission_rows',submission_rows[-1],len(submission_rows))\n    \n   \n\nprint(len(results),len(submission_rows)-1)#\u6bd4\u4e00\u4e0b\u5169\u908a\u6578\u5b57\u61c9\u8a72\u4e00\u6a23\n\nwith open('results\/submission.csv','w',encoding='utf-8-sig') as f:\n    f.writelines(submission_rows)\n\nfr=open('results\/submission.csv','r',encoding='utf-8-sig')\nrows=fr.readlines()\nprint(rows[:3])","2e1ccd11":"\n\n#\u9019\u53e5\u8d85\u6975\u91cd\u8981\uff0c\u5fd8\u8a18\u4e86\u5c31\u4e00\u5207\u767d\u505a\u4e86\nnet1.eval()\nnet2.eval()\nnet3.eval()\nnet1.class_names=[]\nnet2.class_names=[]\nnet3.class_names=[]\nnet1.preprocess_flow=[Normalize(127.5,127.5)]\nnet2.preprocess_flow=[Normalize(127.5,127.5)]\nnet3.preprocess_flow=[Normalize(127.5,127.5)]\n\n\nresults=OrderedDict()\nsubmission_rows=[]\nsubmission_rows.append('id,label\\n')\n\nfor i in tqdm(range(len(summit_imgs))):\n    summit_key=summit_imgs[i].split('\/')[-1].replace('.tif','')#\u5f9e\u5716\u6a94\u4f4d\u7f6e\u53d6\u51fa\u5716\u6a94\u7de8\u865f\n    infer_results=(net1.infer_single_image(summit_imgs[i])[1]+net2.infer_single_image(summit_imgs[i])[1]+net3.infer_single_image(summit_imgs[i])[1])\/3.0#\u5192\u865f\u662f\u6307\u53d6\u6240\u6709\u6279\u6b21\u8ef8\uff0c1\u662f\u6307\u53d6\u967d\u6027\u7684\u6a5f\u7387  \n    results[summit_key]=infer_results.item() #\u4ee5key-value\u5f62\u5f0f\u5beb\u5165\n    submission_rows.append('{0},{1}\\n'.format(summit_key,results[summit_key]))\n    if len(submission_rows)<=10:\n        print('submission_rows',submission_rows[-1],len(submission_rows))\n\n\nprint(len(results),len(submission_rows)-1)#\u6bd4\u4e00\u4e0b\u5169\u908a\u6578\u5b57\u61c9\u8a72\u4e00\u6a23\n\nwith open('results\/submission1.csv','w',encoding='utf-8-sig') as f:\n    f.writelines(submission_rows)\n\nfr=open('results\/submission1.csv','r',encoding='utf-8-sig')\nrows=fr.readlines()\nprint(rows[:3])","d50ef443":"api_token= {\"username\":\"your_username\",\"key\":\"your_token\"} #\u8acb\u63db\u6210\u4f60\u81ea\u5df1\u7684kaggle\u8a8d\u8b49#\u8acb\u63db\u6210\u4f60\u81ea\u5df1\u7684kaggle\u8a8d\u8b49\nimport json\nimport zipfile\nimport os\n \nif not os.path.exists(\"\/root\/.kaggle\"):\n    os.makedirs(\"\/root\/.kaggle\")\n \nwith open('\/root\/.kaggle\/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n!chmod 600 \/root\/.kaggle\/kaggle.json\n \nif not os.path.exists(\"\/kaggle\"):\n    os.makedirs(\"\/kaggle\")\n!kaggle competitions submit -c histopathologic-cancer-detection -f 'results\/submission1.csv' -m 'Resnet50+\/EfficientNetB0 ensembles custom layer for 32x32 handling'","9451b430":"\u7136\u5f8c\u6211\u5011\u793a\u7bc4\u4e00\u4e0b\u5982\u4f55\u7522\u51fa\u8981\u63d0\u4ea4\u7684\u5167\u5bb9\uff0c\u6211\u5011\u505a\u5169\u500b\u793a\u7bc4\uff0c\u7b2c\u4e00\u7a2e\u662f\u6211\u5011\u6839\u64da\u6548\u5ea6\u6307\u6a19\u770b\u8d77\u4f86\u6700\u9ad8\u7684\u6a21\u578b\u70ba\u57fa\u790e\uff0c\u7b2c\u4e8c\u7a2e\u662f\u57fa\u65bc\u5e7e\u500b\u6a21\u578b\u7684\u7d9c\u5408\u8a55\u6bd4","aa427002":"\u5982\u679c\u4f60\u4ed4\u7d30\u7af6\u8cfd\u898f\u5247\uff0c\u88e1\u9762\u6709\u5c0d\u5716\u50cf\u7684\u6a19\u8a3b\u4f5c\u660e\u78ba\u7684\u8aaa\u660e\uff0c\u6bcf\u5f3596x96\u7684\u5716\u50cf\u6240\u8b02\u7684\u967d\u6027\uff0c\u662f\u6307\u5728\u5716\u50cf\u4e2d\u5fc3\u9ede\u768432x32\u5340\u57df\u4e2d\u662f\u5426\u6709\u764c\u75c7\u7d30\u80de\uff0c\u5728\u6b64\u5340\u57df\u5916\u5373\u4f7f\u6709\u764c\u75c7\u7d30\u80de\u4e5f\u7b97\u662f\u9670\u6027\uff0c\u9019\u500b\u898f\u5247\u53ef\u4ee5\u8aaa\u662f\u9817\u5947\u8469\uff0c\u800c\u6211\u5728\u8a0e\u8ad6\u4e2d\u770b\u8d77\u4f86\u6c92\u6709\u592a\u591a\u4eba\u8a0e\u8ad6\u9019\u500b\uff0c\u53ea\u6709\u5c11\u90e8\u5206\u7684\u4eba\u8aaa\u5b83\u6539\u6210\u5207\u51fa\u4e2d\u5fc332x32\u5340\u57df\u8dd1\u7d50\u679c\u5f88\u721b\uff0c\u5176\u5be6\u4e0d\u7528\u505a\u5c31\u77e5\u9053\u6703\u5f88\u721b\u3002  \n- \u73fe\u5728\u9810\u8a13\u7df4\u6a21\u578b\u57fa\u672c\u4e0a\u90fd\u662f\u57fa\u65bc224*224\uff0c32x32\u9019\u5c3a\u5bf8\u592a\u5c0f  \n- \u76f4\u63a5\u4f7f\u752832x32\uff0c\u5468\u570d\u5340\u57df\u6703\u88ab0\u586b\u6eff\u7684\u884c\u70ba\u6240\u5f71\u97ff\uff0c\u82e5\u6539\u5176\u4ed6padding\u53c8\u6703\u8b93\u9810\u8a13\u7df4\u6a21\u578b\u5931\u6548  \n- \u5982\u679c\u520732x32\uff0c\u5f88\u591a\u770b\u8d77\u4f86\u662f\u767d\u767d\u7684\u7d14\u9ed1\u7684\u4e00\u7247\uff0c\u56e0\u70ba\u5b83\u53ef\u80fd\u4f4d\u65bc\u4e00\u500b\u5927\u7684\u816b\u7624\u5167\u90e8\uff0c\u53cd\u800c\u55aa\u5931\u4e86\u8b58\u5225\u80fd\u529b\uff0c\u5b83\u9700\u8981\u5916\u570d\u5716\u50cf\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002  \n\n\u6240\u4ee5\u70ba\u4e86\u89e3\u6c7a\u9019\u554f\u984c\uff0c\u6211\u81ea\u5df1\u8a2d\u8a08\u4e86\u4e00\u500b\u81ea\u5b9a\u7fa9\u5c64CustomCropFlatten\uff0c\u50b3\u7d71\u5377\u7a4d\u5c64\u5207\u63db\u81f3\u5168\u9023\u63a5\u5c64\uff0c\u591a\u534a\u662f\u4f7f\u7528Flattened\u6524\u5e73\uff0c\u4f46\u662f\u5728\u9019\u984c\u4e2d\uff0c\u6211\u5011\u5c31\u6703\u628a32x32\u8ddf\u5916\u570d\u5340\u57df\u7684\u4fe1\u606f\u6df7\u518d\u4e00\u8d77\u3002\u7531\u65bc\u6211\u5e0c\u671b\u9396\u5b9a32x32\u5340\u57df\u6709\u7121\u816b\u7624\uff0c\u4f46\u6211\u53c8\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u6240\u4ee5\u6211\u9996\u5148\u6aa2\u67e5\u4e00\u4e0b\u5982\u679c\u6211\u752896*96\uff0c\u4e1f\u5230\u9810\u8a13\u7df4\u6a21\u578b\u5230\u5e95\u5716\u7247\u6703\u7e2e\u591a\u5c0f\uff0c\u7531\u65bc32\u662f96\u7684\u4e09\u5206\u4e4b\u4e00\uff0c\u6240\u4ee5\u6211\u60f3\u8981\u627e\u5230\u6703\u628a\u5b83\u7e2e\u62106x6\u7684\u4f4d\u7f6e\uff0c\u9019\u6a23\u516d\u500b\u50cf\u7d20\u5206\u5225\u70ba  \\[padding\u5340\\]-\\[\u5468\u570d\u5340\\]-\\[\u89c0\u6e2c\u5340\\]-\\[\u89c0\u6e2c\u5340\\]-\\[\u5468\u570d\u5340\\]-\\[padding\u5340\\]\u3002\n\n\u9996\u5148\u6211\u5047\u8a2dpadding\u6548\u679c\u61c9\u8a72\u4e0d\u81f3\u65bc\u5360\u6389\u5de6\u53f3\u7e3d\u548c1\/3\uff0c\u6240\u4ee5\u4e0a\u8ff0\u7684padding\u5340\u662f\u6211\u8981\u4e1f\u68c4\u7684\uff0c\u800c\u5468\u570d\u5340\u624d\u662f\u6211\u95dc\u5fc3\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u800c\u89c0\u6e2c\u5340\u5df2\u7d93\u5f9e32*32\u8b8a\u62102*2\uff0c\u6240\u4ee5\u9019\u500b\u5b57\u5b9a\u7fa9\u5c64\u5148\u628a2*2\u5340\u57df\u6316\u51fa\u4f86\u6524\u5e73\uff0c\u63a5\u8457\u628a\u89c0\u6e2c\u5340\u7684\u4e0a\u4e0b\u5de6\u53f3\u56db\u584a\u5468\u570d\u5340\u53d6\u51fa\u4f86\uff0c\u6bcf\u584a\u5404\u81ea\u53d6\u9010\u901a\u9053\u7684\u6975\u5927\u503c(\u53d6\u51fa\u7279\u5fb5\u7684\u6975\u5927\u503c)\uff0c\u7b49\u65bc\u7a7a\u9593\u4e0a\u9019\u662f\u56db\u500b\u9ede\u800c\u975e\u4e00\u5927\u584a\u9762\u7a4d\uff0c\u9019\u6a23\u5728\u91cd\u8981\u6027\u4e0a\u6703\u88ab\u6291\u5236\uff0c\u4f46\u662f\u7279\u5fb5\u9084\u662f\u53ef\u4ee5\u4f9b\u5f8c\u7e8c\u5206\u985e\u5668\u53c3\u8003","35db9a4c":"\u5728\u9019\u908a\u6211\u5011\u7684cross entropy\u52a0\u4e0a\u4e86auto_balace\u7684\u9078\u9805\uff0c\u9019\u662f\u6211\u7684api\u4e00\u500b\u6bd4\u8f03\u7368\u7279\u7684\u529f\u80fd\uff0c\u5b83\u6703\u81ea\u52d5\u8a08\u7b97\u500b\u6a19\u7c64\u7684\u6a23\u672c\u5206\u5e03(\u5c31\u50cf\u4e4b\u524d\u4ecb\u7d39\u904e\u7684label statistics)\uff0c\u7136\u5f8c\u6839\u64da\u7279\u6a23\u672c\u6578\u91cf\u5dee\u7570\uff0c\u9032\u884c\u81ea\u52d5\u7684\u5e73\u8861\u6b0a\u91cd\u8a08\u7b97\uff0c\u81ea\u52d5\u8b93\u6240\u6709\u985e\u5225\u7684\u5f71\u97ff\u529b\u5747\u7b49\u3002\u81f3\u65bclabel smooth\u5247\u662f\u8981\u89e3\u6c7a\u7b54\u6848\u975e1\u53730\u7684\u554f\u984c\uff0c\u96a8\u6a5f\u628a1\u8b8a\u62100.9~1\u9019\u6a23\u6709\u52a9\u65bc\u7de9\u89e3\u76f8\u4f3c\u5716\u50cf\u537b\u5fc5\u9808\u88absoftmax\u5206\u5f88\u958b\u7684\u9650\u5236\u3002  \n\n\u6b64\u5916\u6211\u5011\u9084\u52a0\u5165\u4e86F1ScoreLoss\uff0c\u5f9e\u516c\u5f0f\u4e0a\u770b\u4f86\u5b83\u878d\u5408\u4e86\u6e96\u78ba\u7387\u8207\u53ec\u56de\u7387\uff0c\u5176\u4e2d\u7684beta\u5f15\u6578\uff0c\u7576beta>1\uff0c\u5247\u6a21\u578b\u6703\u66f4\u95dc\u6ce8\u53ec\u56de\u7387\uff0c\u82e5\u662f\u5c0f\u65bc1\u5247\u66f4\u95dc\u6ce8\u6e96\u78ba\u7387\uff0c\u6240\u4ee5\u6211\u6253\u7b97\u5148\u4e0d\u52d5\u9019\u500b\u6578\u5b57\u8b93\u4ed6\u8dd1\u4e00\u4e0b\uff0c\u5230\u6642\u770b\u6b63\u78ba\u7387\u8207\u53ec\u56de\u7387\u6578\u5b57\u518d\u6c7a\u5b9a\u5982\u4f55\u8abf\u6574\u5b83\u3002\n\n    f1 score = (1 + beta ** 2) * precision * recall \/ (beta ** 2 * precision + recall)\n"}}