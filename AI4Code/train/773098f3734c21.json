{"cell_type":{"60a414cd":"code","fcabe59c":"code","59521a2f":"code","b45a4f7f":"code","8a6e446d":"code","a1317e66":"code","c74e5978":"code","643a37ad":"code","6fcaf0fb":"code","4b9fe05f":"markdown","6c6fe979":"markdown","db4d1dba":"markdown","a75d4090":"markdown","d1b190e8":"markdown","96fb4d56":"markdown","e1530a9b":"markdown","25f6d68d":"markdown","14d90a0e":"markdown","bc799646":"markdown","cd3208e7":"markdown","45dd3b00":"markdown","52263745":"markdown","73e42c34":"markdown","67b939b3":"markdown"},"source":{"60a414cd":"# Importing the libraries\nimport numpy as np\nimport pandas as pd","fcabe59c":"# Importing the dataset\ndataset = pd.read_csv('..\/input\/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)","59521a2f":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","b45a4f7f":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","8a6e446d":"# Creating the Bag of Words model using CountVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values","a1317e66":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","c74e5978":"# Multinomial NB\n\n# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB(alpha=0.1)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint (\"Confusion Matrix:\\n\",cm)\n\n# Accuracy, Precision and Recall\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nscore1 = accuracy_score(y_test,y_pred)\nscore2 = precision_score(y_test,y_pred)\nscore3= recall_score(y_test,y_pred)\nprint(\"\\n\")\nprint(\"Accuracy is \",round(score1*100,2),\"%\")\nprint(\"Precision is \",round(score2,2))\nprint(\"Recall is \",round(score3,2))","643a37ad":"# Bernoulli NB\n\n# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import BernoulliNB\nclassifier = BernoulliNB(alpha=0.8)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint (\"Confusion Matrix:\\n\",cm)\n\n# Accuracy, Precision and Recall\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nscore1 = accuracy_score(y_test,y_pred)\nscore2 = precision_score(y_test,y_pred)\nscore3= recall_score(y_test,y_pred)\nprint(\"\\n\")\nprint(\"Accuracy is \",round(score1*100,2),\"%\")\nprint(\"Precision is \",round(score2,2))\nprint(\"Recall is \",round(score3,2))","6fcaf0fb":"# Logistic Regression\n\n# Fitting Logistic Regression to the Training set\nfrom sklearn import linear_model\nclassifier = linear_model.LogisticRegression(C=1.5)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint (\"Confusion Matrix:\\n\",cm)\n\n# Accuracy, Precision and Recall\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nscore1 = accuracy_score(y_test,y_pred)\nscore2 = precision_score(y_test,y_pred)\nscore3= recall_score(y_test,y_pred)\nprint(\"\\n\")\nprint(\"Accuracy is \",round(score1*100,2),\"%\")\nprint(\"Precision is \",round(score2,2))\nprint(\"Recall is \",round(score3,2))","4b9fe05f":"**Logistic Regression**","6c6fe979":"**Bernoulli NB**","db4d1dba":"In this study, an attempt has been made to classify sentiment analysis for restaurant reviews using machine learning techniques. Two algorithms namely Multinomial Naive Bayes and Bernoulli Naive Bayes are implemented.\n\nEvaluation metrics used here are accuracy, precision and recall.\n\nUsing Multinomial Naive Bayes,\n\n* Accuracy of prediction is 77.67%.\n* Precision of prediction is 0.78.\n* Recall of prediction is 0.77.\n\nUsing Bernoulli Naive Bayes,\n\n* Accuracy of prediction is 77.0%.\n* Precision of prediction is 0.76.\n* Recall of prediction is 0.78.\n\nUsing Logistic Regression,\n\n* Accuracy of prediction is 76.67%.\n* Precision of prediction is 0.8.\n* Recall of prediction is 0.71.\n\nFrom the above results, Multinomial Naive Bayes is slightly better method compared to Bernoulli Naive Bayes and Logistic Regression, with 77.67% accuracy which means the model built for the prediction of sentiment of the restaurant review gives 77.67% right prediction.","a75d4090":"### Preprocessing Dataset","d1b190e8":"Importing the Restaurant Review dataset using pandas library.","96fb4d56":"# Sentiment Analysis of Restaurant Reviews","e1530a9b":"### Analysis and Conclusion","25f6d68d":"### Importing Dataset","14d90a0e":"### Vectorization","bc799646":"### Training and Classification","cd3208e7":"From the cleaned dataset, potential features are extracted and are converted to numerical format. The vectorization techniques are used to convert textual data to numerical format. Using vectorization, a matrix is created where each column represents a feature and each row represents an individual review.","45dd3b00":"Further the data is splitted into training and testing set using Cross Validation technique. This data is used as input to classification algorithm.\n\n**Classification Algorithms:**\n\nAlgorithms like Decision tree, Support Vector Machine, Logistic Regression, Naive Bayes were implemented and on comparing the evaluation metrics two of the algorithms gave better predictions than others.\n\n* Multinomial Naive Bayes\n* Bernoulli Naive Bayes\n* Logistic Regression","52263745":"The purpose of this analysis is to build a prediction model to predict whether a review on the restaurant is positive or negative. To do so, we will work on Restaurant Review dataset, we will load it into predicitve algorithms Multinomial Naive Bayes, Bernoulli Naive Bayes and Logistic Regression. In the end, we hope to find a \"best\" model for predicting the review's sentiment.\n\nDataset: [Restaurant_Reviews.tsv](https:\/\/www.kaggle.com\/hj5992\/restaurantreviews) is a dataset from Kaggle datasets which consists of 1000 reviews on a restaurant.\n\nTo build a model to predict if review is positive or negative, following steps are performed.\n\n* Importing Dataset\n* Preprocessing Dataset\n* Vectorization\n* Training and Classification\n* Analysis Conclusion","73e42c34":"Each review undergoes through a preprocessing step, where all the vague information is removed.\n\n* Removing the Stopwords, numeric and speacial charecters.\n* Normalizing each review using the approach of stemming.","67b939b3":"**Multinomial NB**"}}