{"cell_type":{"596390bc":"code","931bdb7a":"code","11a973b2":"code","f2a859ee":"code","5ab214fd":"code","6a4a0011":"code","0b4d0172":"code","0d33aace":"code","8ba5fe5f":"code","6e9725a9":"code","3ec503ed":"code","1186d4d7":"code","7e01f9a7":"code","83f75c8f":"code","2df7d9b9":"code","da86fbc9":"code","a0c49c34":"code","e0950cb3":"code","ddd30037":"code","e12d1064":"code","5def06e6":"code","096eecf6":"code","708f3ac0":"code","c549c38e":"code","8f020d91":"markdown","a508977e":"markdown","17be33fd":"markdown","19626a41":"markdown","5890b1ac":"markdown","84b278da":"markdown","e17d7f0a":"markdown","9c75e5d8":"markdown","7c7a6a9b":"markdown","4e485bf8":"markdown","584fd22d":"markdown","d4c448bf":"markdown","037dc76c":"markdown","03e4e10d":"markdown","81e32ed9":"markdown","9cd1b1be":"markdown","e199dfc5":"markdown"},"source":{"596390bc":"#library imports\nimport os\nimport random\nimport math\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport xml.etree.ElementTree as ET\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models","931bdb7a":"# READ IMAGES IN COLORED FORMAT\ndef read_image(path):\n    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n\n# CREATE IMAGE LIST\ndef create_image_list(image_path):\n    image_list = []\n    # ITERATE THROUGH IMAGES FOLDER\n    for image in os.listdir(image_path):\n        # APPEND THE NAME OF IMAGES TO THE LIST\n        image_list.append(image)\n    return image_list","11a973b2":"# CREATE MASK FOR BOUNDING BOX\ndef create_mask(bb, image):\n    # EXTRACT THE IMAGE SHAPE\n    rows,cols,*_ = image.shape\n    # CREATE A MATRIX OF ZERO OF THE IMAGE SHAPE\n    mask = np.zeros((rows, cols))\n    # FILL THE MATRIX CONTAINING THE BOUNDING BOX WITH VALUE 1\n    mask[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n    return mask\n\n# CONVERT RESIZED MASK TO BOUNDING BOX\ndef convert_to_bb(mask):\n    # EXTRACT THE SHAPE OF THE MASK OF BOUNDING BOX CREATED\n    cols, rows = np.nonzero(mask)\n    # RETURN ZERO COORDINATES IF NO MASK\n    if len(cols)==0: \n        return np.zeros(4, dtype=np.float32)\n    # EXTRACT THE BOUNDING BOX COORDINATES\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n# RESIZE THE IMAGES AND SAVE IT IN ANOTHER FOLDER\ndef image_resize(image_path, new_path, bb, size):\n    # READ THE IMAGE FILE\n    image = read_image(image_path)\n    # RESIZE THE IMAGE\n    image_resized = cv2.resize(image, (int(1.49*size), size))\n    # CREATE MASK FROM THE BOUNDING BOX\n    mask = create_mask(bb, image)\n    # RESIZE THE MASK \n    mask_resized = cv2.resize(mask, (int(1.49*size), size))\n    # WRITE THE NEW IMAGE INTO ANOTHER FOLDER\n    cv2.imwrite(new_path, cv2.cvtColor(image_resized, cv2.COLOR_RGB2BGR))\n    return new_path, convert_to_bb(mask_resized)\n\n# PLOT THE BOUNDING BOX AROUND THE IMAGE\ndef plot_bb(path, bb):\n    image = read_image(path)\n    # CONVERT BOUNDING BOXES (BB) INTO FLOAT\n    bb = np.array(bb, dtype=np.float32)\n    # CREATE A RECTANGLE FROM THE BB\n    rect_box = plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color='red',\n                         fill=False, lw=3)\n    # RENDER THE IMAGE\n    plt.imshow(image)\n    # APPLY THE BB TO THE CURRENT AXIS RENDERING IMAGE\n    plt.gca().add_patch(rect_box)","f2a859ee":"image = read_image(dataframe['filename'][360])\nbb = np.array(dataframe['bb'][360], dtype=np.int32)\nmask = create_mask(bb, image)\nplt.imshow(mask, cmap='gray')","5ab214fd":"# EXTRACT BOUNDING BOX FROM THE ANNOTATION FILE\ndef extract_bb(anno_path):\n    # PARSE THE XML FILE TO EXTRACT BB COORDINATES AND CLASS_NAME\n    root = ET.parse(anno_path).getroot()\n    class_name = root.find(\".\/object\/name\").text\n    xmin = int(root.find(\".\/object\/bndbox\/xmin\").text)\n    ymin = int(root.find(\".\/object\/bndbox\/ymin\").text)\n    xmax = int(root.find(\".\/object\/bndbox\/xmax\").text)\n    ymax = int(root.find(\".\/object\/bndbox\/ymax\").text)\n    # RETURN BOUNDING BOX COORDINATES\n    bb = [ymin, xmin, ymax, xmax]\n    return bb, class_name\n\n# GENERATE DATAFRAME\ndef generate_dataframe(image_list, anno_path, image_path, new_path, size):\n    dataset = []\n    for image in image_list:\n        path = image_path + image\n        a_path = anno_path + image.split('.')[0] + '.xml'\n        # EXTRACT BB AND CLASS_NAME FROM ANNOTATION FILE\n        bb, class_name = extract_bb(a_path)\n        # FILENAME OF THE NEW RESIZED IMAGE\n        n_path = new_path + image \n        # RESIZE THE IMAGE AND CORRESPONDING BOUNDING BOX \n        img_path, resized_bb = image_resize(path, n_path, bb, size)\n        # APPEND EVERYTHING TO A DICTIONARY \n        data = dict()\n        data['filename'] = img_path\n        data['bb'] = resized_bb\n        data['class_name'] = class_name\n        # APPEND THE DICTIONARY TO THE LIST\n        dataset.append(data)\n    # APPEND THE LIST TO THE DATAFRAME \n    return pd.DataFrame(dataset) ","6a4a0011":"# NORMALIZE THE IMAGE PIXELS TO MATCH IMAGE_NET STATS\ndef normalize_image(image):\n    # IMAGENET STATS \n    stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n    return (image - stats[0])\/stats[1] \n\n# SCALE THE IMAGE PIXELS\ndef scale_image(path):\n    x = cv2.imread(str(path)).astype(np.float32)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\/255\n    return x\n\n# TRAIN THE MODEL \ndef train_model(model, optimizer, train_dl, val_dl, epochs, C=1000):\n    idx = 0\n    # ITERATE THROUGH EPOCHS\n    for i in range(epochs):\n        model.train()\n        total = 0\n        sum_loss = 0\n        # ITERATE THROUGH THE TENSORS\n        for x, y_class, y_bb in train_dl:\n            batch = y_class.shape[0]\n            # IMAGE PIXELS TENSOR\n            x = x.cuda().float()\n            # CLASS TENSORS\n            y_class = y_class.cuda()\n            # BB TENSORS\n            y_bb = y_bb.cuda().float()\n            # LOAD THE TENSORS INTO MODEL AND PREDICT THE CLASS_NAMES AND BB\n            out_class, out_bb = model(x)\n            # CALCULATE LOSS BETWEEN THE ACTUAL & PREDICTED CLASS \n            loss_class = torch.nn.functional.cross_entropy(out_class, y_class, reduction=\"sum\")\n            # CALCULATE LOSS BETWEEN THE ACTUAL & PREDICTED BB COORDINATES\n            loss_bb = torch.nn.functional.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n            # ADD THE 4 BB LOSSES INTO A SINGLE VALUE\n            loss_bb = loss_bb.sum()\n            # SCALE THE BB LOSS BY 1000 TO HAVE CLASS LOSS AND BB LOSS IN SAME RANGE\n            loss = loss_class + loss_bb\/C\n            # SET GRADIENTS TO ZERO\n            optimizer.zero_grad()\n            # BACKPROPOGATE THE LOSS\n            loss.backward()\n            # UPDATE ALL PARAMETERS\n            optimizer.step()\n            idx += 1\n            total += batch\n            sum_loss += loss.item()\n        # CALCULATE THE TOTAL TRAINING LOSS\n        train_loss = sum_loss\/total\n        # CALCULATE THE VALIDATION LOSS AND ACCURACY\n        val_loss, val_acc = calculate_validation_metrics(model, valid_dl, C)\n        print(\"epoch %d train_loss %.3f val_loss %.3f val_acc %.3f\" % (i, train_loss, val_loss, val_acc))\n    return sum_loss\/total\n\n# FOR CALCULATING VALIDATION LOSS AND ACCURACY\ndef calculate_validation_metrics(model, valid_dl, C=1000):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    correct = 0 \n    for x, y_class, y_bb in valid_dl:\n        batch = y_class.shape[0]\n        x = x.cuda().float()\n        y_class = y_class.cuda()\n        y_bb = y_bb.cuda().float()\n        out_class, out_bb = model(x)\n        loss_class = torch.nn.functional.cross_entropy(out_class, y_class, reduction=\"sum\")\n        loss_bb = torch.nn.functional.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n        loss_bb = loss_bb.sum()\n        loss = loss_class + loss_bb\/C\n        _, pred = torch.max(out_class, 1)\n        correct += pred.eq(y_class).sum().item()\n        sum_loss += loss.item()\n        total += batch\n    return sum_loss\/total, correct\/total","0b4d0172":"# PREPARE THE DATASET TO PASS THROUGH MODEL\nclass Currency(Dataset):\n    def __init__(self, paths, bb, y):\n        self.paths = paths.values\n        self.bb = bb.values\n        self.y = y\n\n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        path = self.paths[index]\n        y_class = self.y[index]\n        y_bb = self.bb[index]\n        x = scale_image(path)\n        x = normalize_image(x)\n        x = np.rollaxis(x, 2)\n        return x, y_class, y_bb\n\n# DEFINE MODEL ARCHITECTURE\nclass ResNetModel(torch.nn.Module):\n    def __init__(self):\n        super(ResNetModel, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        layers = list(resnet.children())[:8]\n        self.features1 = torch.nn.Sequential(*layers[:6])\n        self.features2 = torch.nn.Sequential(*layers[6:])\n        self.classifier = torch.nn.Sequential(torch.nn.BatchNorm1d(512), torch.nn.Linear(512, 7))\n        self.bb = torch.nn.Sequential(torch.nn.BatchNorm1d(512), torch.nn.Linear(512, 4))\n        \n    def forward(self, x):\n        x = self.features1(x)\n        x = self.features2(x)\n        x = torch.nn.functional.relu(x)\n        x = torch.nn.AdaptiveAvgPool2d((1,1))(x)\n        x = x.view(x.shape[0], -1)\n        y_class = torch.nn.functional.softmax(self.classifier(x), dim=1)\n        return y_class, self.bb(x)","0d33aace":"# CREATE NEW FOLDER\n!mkdir resized_image","8ba5fe5f":"image_path = '..\/input\/currency-datasets\/images\/'\nanno_path =  '..\/input\/currency-datasets\/annotations\/'\nnew_path = '.\/resized_image\/'\n\n# CREATE IMAGE LIST\nimage_list = create_image_list(image_path)\n# SHUFFLE THE LIST\nnp.random.shuffle(image_list)\n\nimage_list[:5]","6e9725a9":"# CREATE DATAFRAME\ndataframe = generate_dataframe(image_list, anno_path, image_path, new_path, 300)\n\nX = dataframe[['filename', 'bb']]\nY = dataframe['class_name']\n\n# ENCODE THE CLASS NAMES\nlabel_encoder = LabelEncoder()\nY = label_encoder.fit_transform(Y)\n\n# SPLIT INTO TRAIN AND VALIDATION SETS\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n# CREATE DATASETS\ntrain_ds = Currency(x_train['filename'],x_train['bb'] ,y_train)\nvalid_ds = Currency(x_val['filename'],x_val['bb'],y_val)\n\n# PREPARE THE BATCH OF TRAINING AND VALIDATION TO LOAD\nbatch_size = 64\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","3ec503ed":"dataframe.head()","1186d4d7":"plot_bb(dataframe['filename'][360], dataframe['bb'][360])","7e01f9a7":"# 0:50 1:500 2:100 3:10 4:20 5:200 6:2000\nlabel_encoder.inverse_transform([0,1,2,3,4,5,6])","83f75c8f":"# CALL MODEL AND SET PARAMETERS\nres_model = ResNetModel().cuda()\nparameters = filter(lambda param: param.requires_grad, res_model.parameters())\noptimizer = torch.optim.Adam(parameters, lr=0.001)\n\ntrain_model(res_model, optimizer, train_dl, valid_dl, epochs=200)","2df7d9b9":"test_image = '500_1.jpeg'\n\n# PREPARE THE DATA TO LOAD\ntest_ds = Currency(pd.DataFrame([{'path':'.\/resized_image\/{}'.format(test_image)}])['path'],pd.DataFrame([{'bb':np.array([0,0,0,0])}])['bb'],pd.DataFrame([{'y':[0]}])['y'])\nx, y_class, y_bb = test_ds[0]\n\n# CONVERT IT INTO TENSOR\nxx = torch.FloatTensor(x[None,])\n\n# PASS THE TENSOR TO THE MODEL\nout_class, out_bb = res_model(xx.cuda())\nout_class, out_bb","da86fbc9":"currency_map = {0:'50Rs', 1:'500Rs', 2:'100Rs', 3:'10Rs', 4:'20Rs', 5:'200Rs', 6:'2000Rs'}\n\ndef identify_currency(image_path):\n\n    im = read_image(image_path)\n    test_ds = Currency(pd.DataFrame([{'path':'{}'.format(image_path)}])['path'],pd.DataFrame([{'bb':np.array([0,0,0,0])}])['bb'],pd.DataFrame([{'y':[0]}])['y'])\n    x, y_class, y_bb = test_ds[0]\n    xx = torch.FloatTensor(x[None,])\n    out_class, out_bb = res_model(xx.cuda())\n    index = out_class.cpu().data.numpy().argmax()\n    confidence = out_class.cpu().data.numpy()[0][index]\n\n    bb_hat = out_bb.detach().cpu().numpy()\n    bb_hat = abs(bb_hat)\n    plot_bb(image_path, bb_hat[0])\n    output = '{}:{}'.format(currency_map[index], confidence)\n    print(output)","a0c49c34":"test_image = '500_1.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","e0950cb3":"test_image = '10_1.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","ddd30037":"test_image = '50_10.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","e12d1064":"test_image = '200_10.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","5def06e6":"test_image = '20_1.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","096eecf6":"test_image = '2000_55.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","708f3ac0":"test_image = '100_23.jpeg'\nimg_path = '.\/resized_image\/{}'.format(test_image)\nidentify_currency(img_path)","c549c38e":"torch.save(res_model, 'new_res_model.pth')","8f020d91":"## SAVE YOUR MODEL AND USE IT FOR LATER PURPOSES.","a508977e":"### CREATE DATASET","17be33fd":"### HELPER FUNCTIONS\n\nFollowing are the various functions that we need :-\n****\n**read_image(path)** - Read images from the given path into colored format as opencv opens in grayscale\n****\n**create_image_list(image_path)** - Iterates through the images folder and create a list of all the images.\n****","19626a41":"## CONCLUSION\n\n\nI know its not that perfect because the model has been trained only 400 images which are very very less. Also I have tested the model on the same images on which I have trained it.\n\nIf you have a dataset with atleast 10,000 images, then your model will be very good. Also you can use other models like Xception, VGG or can make your own architecture. Try to train it on epochs not less than 100. \n\nIf you are someone who didn't manage to configure YOLO or TensorFlow Object Detection API for custom dataset training (like me :) then remember this is for you. I invested my 4 days on making this model as I am beginner into this field and I am really glad that I did it. This is my very first Object detection model and for the very first time I used PyTorch also. \n\n\nIf you want to download this pretrained model use it on your images (Indian Currency) clicked by you , click on the link below\n\nMODEL LINK - https:\/\/drive.google.com\/drive\/u\/1\/folders\/1VP9KRs4np64AMctirHPjvtu2Am7tKwRa\n\n#### HAPPY LEARNING!!!","5890b1ac":"## TRAIN THE MODEL","84b278da":"# OBJECT DETECTION (CLASSIFICATION + LOCALIZATION) ON CUSTOM DATA\n\n\nThis notebook trains a model that detects an object from an image and creates a rectangular bounding box around it with a label and confidence score. \"Classification\" means classifying the image with a label and \"Localization\" means detecting the objects position in the image. The model is a classifier plus regressor. Classifier detects the class and Regressor detects the bounding box coordinates which is a continuous number.\n\n****\n\n**DATASET** - Dataset contains two folders images and annotations. \n\n>>images folder contains all the images of Indian currencies. I have manually collected all the images from the internet. Total 414 images are there with some duplicates, which is very less. \n\n>>annotations folder contains all the xml file of the images that contains the information about the images like width, height, label and bounding box coordinates. I have used \"LabelImg\" annotation tool to label them. I have used PASCAL VOC format to save them (i.e. xml). *Labelling images is a time intensive* \n\n****\n**TOTAL IMAGES** - 414 (Indian Currencies)\n****\n**CLASSES** - 7 classes (Rs. 10, 20, 50, 100, 200, 500 & 2000)\n****\n**MODEL** - Residual Network (ResNet34) \n****\n**MODE OF TRAINING** - Transfer Learning\n****\n**LIBRARY** - PyTorch, OpenCV, scikit-learn\n****","e17d7f0a":"Following code snippet tests the model","9c75e5d8":"****\n**out_class**  - array with 7 values showing probablities of falling into 7 classes, choose the maximum probability. These values are also known as \"confidence score\"\n****\n**out_bb**  - array with 4 values showing the coordinates of the bounding box i.e. ( ymin, xmin, ymax, xmax)\n****","7c7a6a9b":"This is the mask created from the bounding box that I referred in the above cell. Then later we can resize this white patch to the scale of the resized image and convert it again into bounding box.","4e485bf8":"****\n**extract_bb()** - It will iterate through the xml files and extract bounding box coordinates from it. \n****\n**generate_dataframe()** - it will generate dataframe with columns \"filename\",*(image_path)*, \"bb\",*(bounding-box)*, and \"class_name\",*(label)*\n****","584fd22d":"****\n**Currency()** - Currency is the name of the class that inherits the property of Dataset (torch) required for loading into the PyTorch model.\n****\n**ResNetModel()** - creates architecture for the model, it outputs two outputs, probability distribution of classlabels and 4 float values representing bounding box values.\n****","d4c448bf":"## INFERENCE CODE \n\n**identify_currency()** - A function in which you can pass the path of the image and it will output the class_label, confidence score in the \n\nformat \"50Rs:0.99\" 50Rs is the class of the image and 0.99 is the confidence score representing 99% assurity of image being Rs.50 with \n\nbounding box drawn around the image. ","037dc76c":"## ERRORS\n\nYou might get following errors :-\n\n**AssertionError: Torch not compiled with CUDA enabled**  - Enable your GPU then.\n\n**RuntimeError: CUDA error: device-side assert triggered** - Refer to this, I have answered there https:\/\/stackoverflow.com\/a\/64156344\/7850174\n\nAfter any of the CUDA error, restart the notebook, otherwise you will keep on getting the CUDA error because the earlier assertion hasn't been flushed out. By restarting the notebook, you will flush out all the cuda assertions. ","03e4e10d":"****\n**normalize_image()** - it normalizes the image pixels to imagenet format by subtracting mean and dividing by standard deviation because ResNet is trained on ImageNet dataset.\n****\n**scale_image()** - it scales the image pixels into same range\n****\n**train_model()** - trains the model caluclates the loss, gradients, backpropagates the loss and update the weights.\n****\n**calculate_validation_metrics()** - calculates the validation loss and accuracy\n****","81e32ed9":"### ALERT !!! Following code will run after you create dataframe, run next to next cells first to create dataset. I have created this cell for demo purpose.","9cd1b1be":"****\n**image_resize(image_path, new_path, bb, size)** - It resizes the image as all the images should of be of same size.\n****\nWhen we resize the image, its bounding box should also be resized. For that we have to make a mask(filled rectangle) from the rectangular coordinates i.e. we will make everything black and area surrounded by the bounding box white. Then resize that mask and convert it again into empty rectangular shape (bounding box). Don't worry if you didn't get it, following cells will clarify the things.\n****\n**create_mask(bb, image)** - create mask from the image and bounding box.\n****\n**convert_to_bb(mask)** - convert mask to bounding box \n****\n**plot_bb(path, bb)** - plot image with bounding box, path is the image path.\n****","e199dfc5":"## EVALUATE THE MODEL"}}