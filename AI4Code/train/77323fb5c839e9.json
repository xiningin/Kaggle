{"cell_type":{"d024d9a4":"code","d5393612":"code","a4941061":"code","480039c7":"code","73b59695":"code","1e65153c":"code","6ec56648":"code","58a13414":"code","a9168947":"code","6dc1379c":"code","cf650791":"markdown","d63bbbe1":"markdown","91e4cc69":"markdown","c68d5d1c":"markdown","e5ee4fc0":"markdown","108a3c49":"markdown","d11aa87e":"markdown","660c130a":"markdown"},"source":{"d024d9a4":"#First Let us import all the libraries that are required\nimport struct\nimport numpy as np\nfrom numpy import expand_dims\nfrom keras.layers import Conv2D\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import UpSampling2D\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom matplotlib import pyplot\nfrom matplotlib.patches import Rectangle","d5393612":"#This function is used to create convolutional layers\ndef _conv_block(inp, convs, skip=True):\n\tx = inp\n\tcount = 0\n\tfor conv in convs:\n\t\tif count == (len(convs) - 2) and skip:\n\t\t\tskip_connection = x\n\t\tcount += 1\n\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n\t\tx = Conv2D(conv['filter'],\n\t\t\t\t   conv['kernel'],\n\t\t\t\t   strides=conv['stride'],\n\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n\t\t\t\t   use_bias=False if conv['bnorm'] else True)(x)\n\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n\treturn add([skip_connection, x]) if skip else x\n#'''This function define the Keras model for YOLOv3.'''\ndef make_yolov3_model():\n\tinput_image = Input(shape=(None, None, 3))\n\t# Layer  0 => 4\n\tx = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n\t# Layer  5 => 8\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n\t# Layer  9 => 11\n\tx = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n\t# Layer 12 => 15\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n\t# Layer 16 => 36\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n\tskip_36 = x\n\t# Layer 37 => 40\n\tx = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n\t# Layer 41 => 61\n\tfor i in range(7):\n\t\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n\tskip_61 = x\n\t# Layer 62 => 65\n\tx = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n\t# Layer 66 => 74\n\tfor i in range(3):\n\t\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n\t# Layer 75 => 79\n\tx = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n\t# Layer 80 => 82\n\tyolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n\t# Layer 83 => 86\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_61])\n\t# Layer 87 => 91\n\tx = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n\t# Layer 92 => 94\n\tyolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n\t# Layer 95 => 98\n\tx = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n\tx = UpSampling2D(2)(x)\n\tx = concatenate([x, skip_36])\n\t# Layer 99 => 106\n\tyolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n\treturn model\n \n#This class reads and weights from file and rather manually\n#decoding the weights from yolo weights file than we can use it.    \nclass WeightReader:\n\tdef __init__(self, weight_file):\n\t\twith open(weight_file, 'rb') as w_f:\n\t\t\tmajor,\t= struct.unpack('i', w_f.read(4))\n\t\t\tminor,\t= struct.unpack('i', w_f.read(4))\n\t\t\trevision, = struct.unpack('i', w_f.read(4))\n\t\t\tif (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n\t\t\t\tw_f.read(8)\n\t\t\telse:\n\t\t\t\tw_f.read(4)\n\t\t\ttranspose = (major > 1000) or (minor > 1000)\n\t\t\tbinary = w_f.read()\n\t\tself.offset = 0\n\t\tself.all_weights = np.frombuffer(binary, dtype='float32')\n \n\tdef read_bytes(self, size):\n\t\tself.offset = self.offset + size\n\t\treturn self.all_weights[self.offset-size:self.offset]\n \n\tdef load_weights(self, model):\n\t\tfor i in range(106):\n\t\t\ttry:\n\t\t\t\tconv_layer = model.get_layer('conv_' + str(i))\n\t\t\t\tprint(\"loading weights of convolution #\" + str(i))\n\t\t\t\tif i not in [81, 93, 105]:\n\t\t\t\t\tnorm_layer = model.get_layer('bnorm_' + str(i))\n\t\t\t\t\tsize = np.prod(norm_layer.get_weights()[0].shape)\n\t\t\t\t\tbeta  = self.read_bytes(size) # bias\n\t\t\t\t\tgamma = self.read_bytes(size) # scale\n\t\t\t\t\tmean  = self.read_bytes(size) # mean\n\t\t\t\t\tvar   = self.read_bytes(size) # variance\n\t\t\t\t\tweights = norm_layer.set_weights([gamma, beta, mean, var])\n\t\t\t\tif len(conv_layer.get_weights()) > 1:\n\t\t\t\t\tbias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel, bias])\n\t\t\t\telse:\n\t\t\t\t\tkernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n\t\t\t\t\tkernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n\t\t\t\t\tkernel = kernel.transpose([2,3,1,0])\n\t\t\t\t\tconv_layer.set_weights([kernel])\n\t\t\texcept ValueError:\n\t\t\t\tprint(\"no convolution #\" + str(i))\n \n\tdef reset(self):\n\t\tself.offset = 0","a4941061":"class BoundBox:\n\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n\t\tself.xmin = xmin\n\t\tself.ymin = ymin\n\t\tself.xmax = xmax\n\t\tself.ymax = ymax\n\t\tself.objness = objness\n\t\tself.classes = classes\n\t\tself.label = -1\n\t\tself.score = -1\n \n\tdef get_label(self):\n\t\tif self.label == -1:\n\t\t\tself.label = np.argmax(self.classes)\n \n\t\treturn self.label\n \n\tdef get_score(self):\n\t\tif self.score == -1:\n\t\t\tself.score = self.classes[self.get_label()]\n \n\t\treturn self.score\n \ndef _sigmoid(x):\n\treturn 1. \/ (1. + np.exp(-x))\n\ndef decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n\tgrid_h, grid_w = netout.shape[:2]\n\tnb_box = 3\n\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n\tnb_class = netout.shape[-1] - 5\n\tboxes = []\n\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n \n\tfor i in range(grid_h*grid_w):\n\t\trow = i \/ grid_w\n\t\tcol = i % grid_w\n\t\tfor b in range(nb_box):\n\t\t\t# 4th element is objectness score\n\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n\t\t\tif(objectness.all() <= obj_thresh): continue\n\t\t\t# first 4 elements are x, y, w, and h\n\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n\t\t\tx = (col + x) \/ grid_w # center position, unit: image width\n\t\t\ty = (row + y) \/ grid_h # center position, unit: image height\n\t\t\tw = anchors[2 * b + 0] * np.exp(w) \/ net_w # unit: image width\n\t\t\th = anchors[2 * b + 1] * np.exp(h) \/ net_h # unit: image height\n\t\t\t# last elements are class probabilities\n\t\t\tclasses = netout[int(row)][col][b][5:]\n\t\t\tbox = BoundBox(x-w\/2, y-h\/2, x+w\/2, y+h\/2, objectness, classes)\n\t\t\tboxes.append(box)\n\treturn boxes\n\n#The correct_yolo_boxes() function to perform the translation of bounding box\n#coordinates, taking the list of bounding boxes, the original shape of our\n#loaded photograph, and the shape of the input to the network as arguments.\n#The coordinates of the bounding boxes are updated directly.\n \ndef correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n\tnew_w, new_h = net_w, net_h\n\tfor i in range(len(boxes)):\n\t\tx_offset, x_scale = (net_w - new_w)\/2.\/net_w, float(new_w)\/net_w\n\t\ty_offset, y_scale = (net_h - new_h)\/2.\/net_h, float(new_h)\/net_h\n\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) \/ x_scale * image_w)\n\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) \/ x_scale * image_w)\n\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) \/ y_scale * image_h)\n\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) \/ y_scale * image_h)\n \ndef _interval_overlap(interval_a, interval_b):\n\tx1, x2 = interval_a\n\tx3, x4 = interval_b\n\tif x3 < x1:\n\t\tif x4 < x1:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn min(x2,x4) - x1\n\telse:\n\t\tif x2 < x3:\n\t\t\t return 0\n\t\telse:\n\t\t\treturn min(x2,x4) - x3\n \ndef bbox_iou(box1, box2):\n\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n\tintersect = intersect_w * intersect_h\n\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n\tunion = w1*h1 + w2*h2 - intersect\n\treturn float(intersect) \/ union\n \n","480039c7":"def do_nms(boxes, nms_thresh):\n\tif len(boxes) > 0:\n\t\tnb_class = len(boxes[0].classes)\n\telse:\n\t\treturn\n\tfor c in range(nb_class):\n\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n\t\tfor i in range(len(sorted_indices)):\n\t\t\tindex_i = sorted_indices[i]\n\t\t\tif boxes[index_i].classes[c] == 0: continue\n\t\t\tfor j in range(i+1, len(sorted_indices)):\n\t\t\t\tindex_j = sorted_indices[j]\n\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n\t\t\t\t\tboxes[index_j].classes[c] = 0","73b59695":"# get all of the results above a threshold\ndef get_boxes(boxes, labels, thresh):\n\tv_boxes, v_labels, v_scores = list(), list(), list()\n\t# enumerate all boxes\n\tfor box in boxes:\n\t\t# enumerate all possible labels\n\t\tfor i in range(len(labels)):\n\t\t\t# check if the threshold for this label is high enough\n\t\t\tif box.classes[i] > thresh:\n\t\t\t\tv_boxes.append(box)\n\t\t\t\tv_labels.append(labels[i])\n\t\t\t\tv_scores.append(box.classes[i]*100)\n\t\t\t\t# don't break, many labels may trigger for one box\n\treturn v_boxes, v_labels, v_scores\n \n# draw all results\ndef draw_boxes(filename, v_boxes, v_labels, v_scores):\n\tpyplot.figure(figsize=(20,10))\n\t# load the image\n\tdata = pyplot.imread(filename)\n\t# plot the image\n\tpyplot.imshow(data)\n\t# get the context for drawing boxes\n\tax = pyplot.gca()\n\t# plot each box\n\tfor i in range(len(v_boxes)):\n\t\tbox = v_boxes[i]\n\t\t# get coordinates\n\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n\t\t# calculate width and height of the box\n\t\twidth, height = x2 - x1, y2 - y1\n\t\t# create the shape\n\t\trect = Rectangle((x1, y1), width, height, fill=False, color='blue',lw=3)\n\t\t# draw the box\n\t\tax.add_patch(rect)\n\t\t# draw text and score in top left corner\n\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n\t\tpyplot.text(x1-20, y1-20, label, color='red',fontsize=16)\n\t# show the plot\n\tpyplot.show()\n    ","1e65153c":"# load and prepare an image\ndef load_image_pixels(filename, shape):\n    # load the image to get its shape\n    image = load_img(filename)\n    width, height = image.size\n    # load the image with the required size\n    image = load_img(filename, target_size=shape)\n    # convert to numpy array\n    image = img_to_array(image)\n    # scale pixel values to [0, 1]\n    image = image.astype('float32')\n    image \/= 255.0\n    # add a dimension so that we have one sample\n    image = expand_dims(image, 0)\n    return image, width, height","6ec56648":"# define the model\nmodel = make_yolov3_model()","58a13414":"#read weights from yolov3 weights file provided in the data\nweight_reader = WeightReader('..\/input\/data-for-yolo-v3-kernel\/yolov3.weights')","a9168947":"# set the model weights into the model\nweight_reader.load_weights(model)","6dc1379c":"# define the expected input shape for the model\ninput_w, input_h = 416, 416\n# define our new photo\nphoto_filename = '..\/input\/data-for-yolo-v3-kernel\/office.jpg'\n# load and prepare image\nimage, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n# make prediction\nyhat = model.predict(image)\n# summarize the shape of the list of arrays\nprint([a.shape for a in yhat])\n# define the anchors\nanchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n# define the probability threshold for detected objects\nclass_threshold = 0.7\nboxes = list()\nfor i in range(len(yhat)):\n\t# decode the output of the network\n\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n# correct the sizes of the bounding boxes for the shape of the image\ncorrect_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n# suppress non-maximal boxes\ndo_nms(boxes, 0.4)\n# define the labels\nlabels = []\nwith open(\"..\/input\/data-for-yolo-v3-kernel\/coco.names\", \"r\") as f:\n    labels = [line.strip() for line in f.readlines()]\nv_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n# summarize what we found\nfor i in range(len(v_boxes)):\n\tprint(v_labels[i], v_scores[i])\n# draw what we found\ndraw_boxes(photo_filename, v_boxes, v_labels, v_scores)","cf650791":"In this notebook, I am only going to through the implementation part and if you are interested in a bit of theory and other implementation, Here are list of topics that I have covered in an article [YOLO object detection using OpenCV ](https:\/\/www.mygreatlearning.com\/blog\/yolo-object-detection-using-opencv\/):\n* What is object detection?\n* How does object detection work?\n* What is YOLO object detection?\n* Overview of  YOLO object detection algorithm\n* Non-Maximum Suppression\n* Implementation of YOLO with OpenCV\nThis Implementation is really easy and more convinient if you just want to try out object detection.\n\nAlso to know about [Custom Object detection with YOLOion Using Tensorflow API](https:\/\/www.mygreatlearning.com\/blog\/object-detection-using-tensorflow), click here\n\n","d63bbbe1":"If we use the above model and try to make predictions, we ll get an encoded output which is encoded candidate bounding boxes from different grid sizes, and the boxes are defined the context of **anchor boxes**, carefully chosen based on an analysis of the size of objects in the MSCOCO dataset. The function  decode_netout() is defined that will take each one of the NumPy arrays, one at a time, and decode the candidate bounding boxes and class predictions. Further, any bounding boxes that don\u2019t confidently describe an object (e.g. all class probabilities are below a threshold) are ignored.The function returns a list of BoundBox instances that define the corners of each bounding box in the context of the input image shape and class probabilities.","91e4cc69":"Now Here are some of the functions that I am using from repo witha bit of description on what they do.","c68d5d1c":"Now let us use all the above defined functions to detect objects in an image.First we define a model and load weights in it.Then we start loading the picture and preproceesing it.","e5ee4fc0":"# Object Detection Using YOLO (Keras Implementation)","108a3c49":"Now coming on to this implementation, I am going to use code from [this](https:\/\/github.com\/experiencor\/keras-yolo3) github repository and also use machine learning mastery as guide. In my opinion this github repo provides a lot of capability for using YOLOv3 models, including object detection, transfer learning, and training new models from scratch.\nAlso we are going to use the pre-trained weights and load them into the model.The above repositotry has different functions that can help us to achieve all the tasks necessary for this notebook","d11aa87e":"get_boxes() function  takes the list of boxes, known labels, and our classification threshold as arguments and returns parallel lists of boxes, labels, and scores.","660c130a":"Here is a function that perform non max suppression. Go to the article above and see what is NMS and why is it important."}}