{"cell_type":{"b5dcb652":"code","b0bd6824":"code","8873e282":"code","c169bf6f":"code","0650e835":"code","34203d07":"code","0bbbf9b7":"code","1c60cd44":"code","7a029e80":"code","6a27f02c":"code","3b9137cf":"code","de7b45ae":"code","4d45bf6e":"code","d8f82671":"code","ba707b55":"code","43ef1eb5":"code","bf83e040":"code","02f68e7e":"code","82624a45":"code","e0de93e2":"code","666b5c87":"code","6b183d76":"code","d0f32caf":"code","f792cfc6":"code","f7f9522d":"code","97fa1a24":"code","89be57dc":"code","c3c2de36":"code","1440734a":"code","027d76af":"code","3ff9439f":"code","eec4319a":"code","714d694c":"code","d0551890":"code","fb7ac78f":"code","1280f941":"code","5c014379":"code","5c9b3c74":"code","56cb2f24":"code","13967aef":"code","8d70aade":"code","57d8fba7":"code","9e16a4ee":"code","b214e670":"code","4e0828f2":"code","ca84a7b6":"code","f921a9bb":"code","36069796":"code","76e291eb":"code","4be512ee":"code","0db613b8":"code","23dc8562":"code","fa96043a":"code","12c8aebe":"code","421aa0b7":"code","369ff12b":"code","1d1f9e43":"code","268ba1f4":"code","9287442c":"code","b989925f":"code","07e2fd29":"code","a2344e6d":"code","f82c9de6":"code","b4300c8b":"code","898ab97f":"code","a24c186c":"code","6bbdcd9f":"code","15f8947a":"code","0ed90bdc":"code","5d03df61":"code","568cd09d":"markdown","9efe37cd":"markdown","5276a80e":"markdown","9a0f9ef7":"markdown","8d108012":"markdown","ce88438b":"markdown","c6512286":"markdown","20642829":"markdown","8e49c5d3":"markdown","653b0d42":"markdown","0f4efbd6":"markdown","933692f8":"markdown","b4c06fed":"markdown","bb36ab19":"markdown","ebe0a127":"markdown","b6eadf42":"markdown","969f1129":"markdown","480175e4":"markdown","50396c96":"markdown","6945fd6a":"markdown","3e9d6bf0":"markdown","fd1e56b5":"markdown","bae299ed":"markdown","69daf791":"markdown","eac5ff1b":"markdown","533b89a9":"markdown"},"source":{"b5dcb652":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b0bd6824":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom imblearn.over_sampling import SMOTE \nfrom sklearn.svm import SVC\nfrom sklearn import model_selection","8873e282":"import itertools\nfrom datetime import datetime\nimport io\n","c169bf6f":"data=pd.read_csv(\"..\/input\/bank-personal-loan-modelling\/Bank_Personal_Loan_Modelling.csv\")\n","0650e835":"des=data.head()\ncm = sns.light_palette(\"b\", as_cmap=True)\ns = des.style.background_gradient(cmap=cm)\ns","34203d07":"data.shape","0bbbf9b7":"data.info()","1c60cd44":"des=data.describe().T\ncm = sns.light_palette(\"tan\", as_cmap=True)\ns = des.style.background_gradient(cmap=cm)\ns","7a029e80":"data['Personal Loan'].value_counts().head()","6a27f02c":"data.Experience.describe()","3b9137cf":"data[data['Experience'] < 0]['Experience'].count()","de7b45ae":"data[data['Experience'] < 0]['Experience'].value_counts()\n","4d45bf6e":"data['Mortgage'].value_counts().head()","d8f82671":"d=data.isnull().sum()\nsns.heatmap(data.isnull(),cmap='YlGnBu',cbar=False,yticklabels=False)\n\nplt.title('missing data')\nplt.show()\nprint(\"Missing Value: \",data.isna().sum().values.sum())","ba707b55":"data.nunique()","43ef1eb5":"sns.pairplot(data.iloc[:,1:])","bf83e040":"plt.figure(figsize=(12, 8)) \nsns.heatmap(data.corr(), cmap=\"YlGnBu\",  linewidths=.2,annot = True)","02f68e7e":"q_Var = ['Age', 'Income', 'CCAvg', 'Mortgage']\nexpGrid = sns.PairGrid(data, y_vars = 'Experience', x_vars = q_Var)\nexpGrid.map(sns.regplot)","82624a45":"df_sum = data.describe()","e0de93e2":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\ndef draw_axvlines(plt, col):\n    mean = df_sum.loc[\"mean\", col]\n    q1 = df_sum.loc[\"25%\", col]\n    q2 = df_sum.loc[\"50%\", col]\n    q3 = df_sum.loc[\"75%\", col]\n    plt.axvline(mean, color = \"g\");              # Plotting a line to mark the mean \n    plt.axvline(q1, color = \"b\");                # Plotting a line to mark Q1 \n    plt.axvline(q2, color = \"navy\");             # Plotting a line to mark Q2 \n    plt.axvline(q3, color = \"purple\");           # Plotting a line to mark Q3\n    plt.legend({\"Mean\": mean, \"25%\" : q1, \"50%\" : q2, \"75%\" : q3});\n\nfig, axes = plt.subplots(3, 2, figsize = (20,12));\nfig.suptitle('Distribution charts for Age, Experience and income.');\n\n\n# Create boxplot and histogram to show distribution of Age\nsns.boxplot(data[\"Age\"], ax = axes[0][0], color = \"mediumslateblue\");\naxes[0][0].set(xlabel = 'Distribution of Age');\n\npp = sns.distplot(data[\"Age\"], ax = axes[0][1], bins = 10, color = \"mediumslateblue\");\naxes[0][1].set(xlabel = 'Distribution of Age');\ndraw_axvlines(pp, \"Age\");\n\n\n# Create boxplot and histogram to show distribution of Experience\nsns.boxplot(data[\"Experience\"], ax = axes[1][0], color = \"mediumslateblue\");\naxes[1][0].set(xlabel = 'Distribution of Experience');\n\npp = sns.distplot(data[\"Experience\"], ax = axes[1][1], bins = 10, color = \"mediumslateblue\");\naxes[1][1].set(xlabel = 'Distribution of Experience');\ndraw_axvlines(pp, \"Experience\")\n\n\n# Create boxplot and histogram to show distribution of Income\nsns.boxplot(data[\"Income\"], ax = axes[2][0], color = \"mediumslateblue\");\naxes[2][0].set(xlabel = 'Distribution of income');\n\npp = sns.distplot(data[\"Income\"], ax = axes[2][1], color = \"mediumslateblue\");\naxes[2][1].set(xlabel = 'Distribution of income');\ndraw_axvlines(pp, \"Income\")","666b5c87":"data['Experience']=data['Experience'].apply(abs)","6b183d76":"data.isna().sum()","d0f32caf":"data['Experience'].value_counts().head()","f792cfc6":"data[data['Experience'] < 0]['Experience'].count()","f7f9522d":"data.Experience.describe()","97fa1a24":"data.columns","89be57dc":"numcols = ['Age', 'Experience', 'Income','CCAvg','Mortgage','Education']","c3c2de36":"fig, ax = plt.subplots(figsize=(20,10), dpi=50)\nfor i in range(0,len(numcols)):\n    plt.subplot(2,3,i+1)\n    sns.distplot(data[numcols[i]],color=\"b\")\n    plt.xlabel(numcols[i])\n  ","1440734a":"data.columns","027d76af":"\ncat_columns = ['Family',   'Education',   'Personal Loan',   'Securities Account',\n               'CD Account',   'Online',   'CreditCard']\ntitle=['Number of Family', 'Education','Customers who took Personal Loan',\n       ' Customer has Securities Account','Customers has a CD Account',\n       'Customers  who transcat  Online',' Customers who has  Credit Card']\nplt.figure(figsize=(7,14))\n\nsns.set_theme(style=\"white\") # just trying to make visualisation better. This will set background to white\n#list_palette=['Blues_r','Greens_r','Purples_r','Reds_r','Blues_r','Greens_r','Purples_r','Reds_r','Blues_r']\n\nfor i, variable in enumerate(cat_columns):\n                     plt.subplot(5,2,i+1)\n                     order = data[variable].value_counts(ascending=False).index   \n                     #sns.set_palette(list_palette[i]) # to set the palette\n                     sns.set_palette('Set2')\n                     ax=sns.countplot(x=data[variable], data=data )\n                     sns.despine(top=True,right=True,left=True) # to remove sijjde line from graph\n                     for p in ax.patches:\n                           percentage = '{:.1f}%'.format(100 * p.get_height()\/len(data[variable]))\n                           x = p.get_x() + p.get_width() \/ 2 - 0.05\n                           y = p.get_y() + p.get_height()\n                           plt.annotate(percentage, (x, y),ha='center')\n                     plt.tight_layout()\n                     plt.title(title[i].upper())\n                                     ","3ff9439f":"loan_counts = pd.DataFrame(data[\"Personal Loan\"].value_counts()).reset_index()\nloan_counts.columns =[\"Labels\",\"Personal Loan\"]\nloan_counts","eec4319a":"#Report business\nfig, ax = plt.subplots(nrows=1, ncols=2,squeeze=True)\nfig.set_size_inches(14,6)\nfrequency_colums= pd.crosstab(index=data[\"Personal Loan\"],columns=\"count\")\nfrequency_colums.plot(kind='bar',ax=ax[0],color=\"c\",legend=False,rot=True,fontsize=10)\nfrequency_colums.plot(kind='pie',ax=ax[1],subplots=True,legend=False,fontsize=10,autopct='%.2f')\nax[0].set_title('Frequency Distribution of Dependent variable: Survived',fontsize=10)\nax[1].set_title('Pie chart representation of Dependent variable: Survived',fontsize=10)\n\n#adding the text labels\nrects = ax[0].patches\nlabels = frequency_colums[\"count\"].values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax[0].text(rect.get_x() + rect.get_width()\/2, height +1,label, ha='center', va='bottom',fontsize=10)\nplt.show()","714d694c":"sns.set_palette(sns.color_palette(\"Set2\", 8))\nsns.pairplot(data, hue=\"Personal Loan\",corner=True)\nplt.show()","d0551890":"def cat_view(x = 'Education'):\n    \"\"\"\n    Function to create a Bar chart and a Pie chart for categorical variables.\n    \"\"\"\n    from matplotlib import cm\n    color1 = cm.inferno(np.linspace(.4, .8, 30))\n    color2 = cm.viridis(np.linspace(.4, .8, 30))\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n    \n     \n    \"\"\"\n    Draw a Pie Chart on first subplot.\n    \"\"\"    \n    s = data.groupby(x).size()\n\n    mydata_values = s.values.tolist()\n    mydata_index = s.index.tolist()\n\n    def func(pct, allvals):\n        absolute = int(pct\/100.*np.sum(allvals))\n        return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n\n\n    wedges, texts, autotexts = ax[0].pie(mydata_values, autopct=lambda pct: func(pct, mydata_values),\n                                      textprops=dict(color=\"w\"))\n\n    ax[0].legend(wedges, mydata_index,\n              title=\"Index\",\n              loc=\"center left\",\n              bbox_to_anchor=(1, 0, 0.5, 1))\n\n    plt.setp(autotexts, size=12, weight=\"bold\")\n\n    ax[0].set_title(f'{x.capitalize()} Piechart')\n    \n    \n    \"\"\"\n    Draw a Bar Graph on second subplot.\n    \"\"\"\n    \n    df = pd.pivot_table(data, index = [x], columns = ['Personal Loan'], values = ['Income'], aggfunc = len)\n\n    labels = df.index.tolist()\n    loan_no = df.values[:, 0].tolist()\n    loan_yes = df.values[:, 1].tolist()\n    \n    l = np.arange(len(labels))  # the label locations\n    width = 0.35  # the width of the bars\n\n    rects1 = ax[1].bar(l - width\/2, loan_no, width, label='No Loan', color = 'tan')\n    rects2 = ax[1].bar(l + width\/2, loan_yes, width, label='Loan', color = 'pink')\n\n    # Add some text for labels, title and custom x-axis tick labels, etc.\n    \n    ax[1].set_ylabel('Scores')\n    ax[1].set_title(f'{x.capitalize()} Bar Graph')\n    ax[1].set_xticks(l)\n    ax[1].set_xticklabels(labels)\n    ax[1].legend()\n    \n    def autolabel(rects):\n        \n        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n        \n        for rect in rects:\n            height = rect.get_height()\n            ax[1].annotate('{}'.format(height),\n                        xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                        xytext=(0, 3),  # 3 points vertical offset\n                        textcoords=\"offset points\",\n                        fontsize = 'large',   \n                        ha='center', va='bottom')\n\n\n    autolabel(rects1)\n    autolabel(rects2)\n\n    fig.tight_layout()\n    plt.show()\n","fb7ac78f":"cat_view('Family')\n","1280f941":"cat_view('Education')","5c014379":"cat_view('Online')","5c9b3c74":"cat_view('Securities Account')","56cb2f24":"cat_view('CD Account')","13967aef":"A= sns.FacetGrid(data, col='Personal Loan')\nA.map(plt.hist,'Age', bins=20,color='b')","8d70aade":"E= sns.FacetGrid(data, col='Personal Loan')\nE.map(plt.hist,'Experience', bins=20,color='b')","57d8fba7":"F= sns.FacetGrid(data, col='Personal Loan')\nF.map(plt.hist,'Family', bins=20,color='b')","9e16a4ee":"I = sns.FacetGrid(data, col='Personal Loan')\nI.map(plt.hist,'Income', bins=20,color='b')","b214e670":"C= sns.FacetGrid(data, col='Personal Loan')\nC.map(plt.hist,'CCAvg', bins=20,color='b')","4e0828f2":"M= sns.FacetGrid(data, col='Personal Loan')\nM.map(plt.hist,'Mortgage', bins=20,color='b')","ca84a7b6":"filterwarnings(\"ignore\")\n\nsns.catplot(x='Family', y='Income', hue='Personal Loan', data = data, kind='swarm') #Report businesss","f921a9bb":"sns.boxplot(x='Education', y='Income', hue='Personal Loan', data = data)","36069796":"sns.boxplot(x='Family',y='CCAvg',hue='Personal Loan',data=data)","76e291eb":"sns.boxplot(x=\"CreditCard\", y='CCAvg', hue=\"Personal Loan\", data=data)","4be512ee":"plt.figure(figsize=(10,4))\nsns.scatterplot(data.CCAvg, data.Income, hue = data['Personal Loan'], palette= ['Brown','g'])\n\nplt.title('Income and CCAvg Scatter Distribution',fontsize=20)","0db613b8":"plt.figure(figsize=(10,4))\nsns.scatterplot(data.Income, data.Mortgage,hue = data['Personal Loan'], palette= ['Silver','g'])\n\nplt.title('Income and  Mortgage Distribution',fontsize=20)","23dc8562":"fig, axes = plt.subplots(1, 2, figsize = (20,5))\n\nxx = data[[\"CCAvg\", \"CreditCard\", \"Personal Loan\"]]\nxx['ccavg_bin'] = pd.cut(xx['CCAvg'], bins = [0, 2, 4, 6, 100], labels = ['0-2', '3-4', '5-6', '7+'])\nxx = xx.groupby([\"ccavg_bin\", \"CreditCard\"])[\"CCAvg\"].sum().reset_index()\nsns.barplot(xx[\"ccavg_bin\"], xx[\"CCAvg\"], hue = xx[\"CreditCard\"], palette= \"cividis\", ax=axes[0]);\naxes[0].set(xlabel = 'CC avg bins', ylabel = 'Count of customers');\n\nsns.scatterplot(x = \"Income\", y = \"CCAvg\", data = data, hue = \"Personal Loan\", ax = axes[1], palette=[\"skyblue\", \"darkgreen\"], alpha = 0.7)","fa96043a":"\ndef plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    ax = plt.gca()\n    ax.set_ylim(-.5, 5.5)\n        \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","12c8aebe":"def perform_model(model, X_train, y_train, X_test, y_test,class_labels, cm_normalize=True,print_cm=True, cm_cmap=plt.cm.Reds):\n    \n    \n    # to store results at various phases\n    results = dict()\n    \n    # time at which model starts training \n    train_start_time = datetime.now()\n    print('training the model..')\n    model.fit(X_train, y_train)\n    print('Done \\n \\n')\n    train_end_time = datetime.now()\n    results['training_time'] =  train_end_time - train_start_time\n    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n    \n    \n    # predict test data\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred = model.predict(X_test)\n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n   \n\n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    \n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    \n    return results","421aa0b7":"def print_grid_search_attributes(model):\n    # Estimator that gave highest score among all the estimators formed in GridSearch\n    print('--------------------------')\n    print('|      Best Estimator     |')\n    print('--------------------------')\n    print('\\n\\t{}\\n'.format(model.best_estimator_))\n\n\n    # parameters that gave best results while performing grid search\n    print('--------------------------')\n    print('|     Best parameters     |')\n    print('--------------------------')\n    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n\n\n    #  number of cross validation splits\n    print('---------------------------------')\n    print('|   No of CrossValidation sets   |')\n    print('--------------------------------')\n    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n\n\n    # Average cross validated score of the best estimator, from the Grid Search \n    print('--------------------------')\n    print('|        Best Score       |')\n    print('--------------------------')\n    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n","369ff12b":"df = data.drop(['ID','ZIP Code'], axis=1)","1d1f9e43":"df.head(1)","268ba1f4":"labels=[0,1]","9287442c":"X = df.drop('Personal Loan',axis=1)\ny=df['Personal Loan']","b989925f":"from imblearn.over_sampling import SMOTE ","07e2fd29":"ms=SMOTE(random_state=1)\nX_ms , y_ms = ms.fit_resample(X,y)","a2344e6d":"X_train, X_test, y_train, y_test = train_test_split(X_ms, y_ms, test_size=0.30, random_state=1)\nprint('x train data {}'.format(X_train.shape))\nprint('y train data {}'.format(y_train.shape))\nprint('x test data  {}'.format(X_test.shape))\nprint('y test data  {}'.format(y_test.shape))","f82c9de6":"parameters = {'n_neighbors': [1,3, 10, 11,]}\nlog_knn = KNeighborsClassifier(n_neighbors=6)\nlog_knn_grid = GridSearchCV(log_knn, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\nlog_knn_grid_results =  perform_model(log_knn_grid, X_train, y_train, X_test, y_test, class_labels=labels)","b4300c8b":"print_grid_search_attributes(log_knn_grid_results['model'])","898ab97f":"log_NB = GaussianNB()\nlog_NB_grid_results =  perform_model(log_NB, X_train, y_train, X_test, y_test, class_labels=labels)","a24c186c":"parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\nlr_svc = LinearSVC(tol=0.00005)\nlr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\nlr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)","6bbdcd9f":"parameters = {'C':[2,8,16],\\\n              'gamma': [ 0.0078125, 0.125, 2]}\nrbf_svm = SVC(kernel='rbf')\nrbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, n_jobs=-1)\nrbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)","15f8947a":"print_grid_search_attributes(rbf_svm_grid_results['model'])","0ed90bdc":"params = {'n_estimators': np.arange(10,500,20), 'max_depth':np.arange(3,15,2)}\nrfc = RandomForestClassifier()\nrfc_grid = GridSearchCV(rfc, param_grid=params, n_jobs=-1)\nrfc_grid_results = perform_model(rfc_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(rfc_grid_results['model'])","5d03df61":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\nmodels = []\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('LSVC', LinearSVC()))\nmodels.append(('KSVC', SVC()))\nmodels.append(('RF', RandomForestClassifier()))\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n\tkfold = model_selection.KFold(n_splits=10, random_state=12345)\n\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n\tresults.append(cv_results)\n\tnames.append(name)\n\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n\nprint('\\n                     Accuracy     Error')\nprint('                     ----------   --------')\n\nprint('KNN                 : {:.04}%       {:.04}% '.format(log_knn_grid_results['accuracy'] * 100,\\\n                                                        100-(log_knn_grid_results['accuracy'] * 100)))\nprint('Naive Bayes         : {:.04}%       {:.04}% '.format(log_NB_grid_results['accuracy'] * 100,\\\n                                                        100-(log_NB_grid_results['accuracy'] * 100)))\nprint('Linear SVC          : {:.04}%        {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n                                                           100-(lr_svc_grid_results['accuracy'] * 100)))\nprint('Kernel SVM          : {:.04}%       {:.04}% '.format(rbf_svm_grid_results['accuracy'] * 100,\\\n                                                           100-(rbf_svm_grid_results['accuracy'] * 100)))\nprint('Random Forest       : {:.04}%       {:.04} % '.format(rfc_grid_results['accuracy'] * 100,\\\n                                                           100-(rfc_grid_results['accuracy'] * 100)))\n# boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n","568cd09d":"10- Personal_Loan: Did this customer accept the personal loan offered in the last campaign?\n","9efe37cd":"**Data Descripsion:**\n","5276a80e":"13- Online: Do customers use internet banking facilities?\n","9a0f9ef7":"12- CD_Account: Does the customer have a certificate of deposit (CD) account with the bank?\n","8d108012":"# KNN","ce88438b":"11- Securities_Account: Does the customer have securities account with the bank?\n","c6512286":"4- Income: Annual income of the customer (in thousand dollars)\n","20642829":"9- Mortgage: Value of house mortgage if any. (in thousand dollars)\n","8e49c5d3":"8- Education: 1: Undergrad; 2: Graduate;3: Advanced\/Professional\n","653b0d42":"3- Experience: years of professional experience\n","0f4efbd6":"5- ZIP Code: Home Address ZIP code.\n","933692f8":"**Analyze by visualizing data**","b4c06fed":"6- Family: the Family size of the customer\n","bb36ab19":"1-ID: Customer ID\n","ebe0a127":"This case is about a bank (Thera Bank) which has a growing customer base. Majority of these customers are liability customers (depositors) with varying size of deposits. The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business and in the process, earn more through the interest on loans. In particular, the management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio with minimal budget.\n\nBank provided data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.","b6eadf42":"** Model Building **","969f1129":"# Naive Bayes","480175e4":"14- CreditCard: Does the customer use a credit card issued by any other Bank (excluding All life Bank)?","50396c96":"# Comparing all models","6945fd6a":"**Context:**","3e9d6bf0":"# Linear SVC","fd1e56b5":"# Random Forest ","bae299ed":"7- CCAvg: Average spending on credit cards per month (in thousand dollars)\n","69daf791":"Experience The distribution is verry similar to that of Age.\n\n---\n\n\n","eac5ff1b":"# Kernel SVM","533b89a9":"2- Age: Customer\u2019s age in completed years\n"}}