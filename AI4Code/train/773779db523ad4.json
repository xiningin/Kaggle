{"cell_type":{"67f70853":"code","fc9ac69d":"code","e3b0bbd9":"code","7fcce227":"code","e3dcb30e":"code","345af520":"code","491b92f2":"code","130c5a42":"code","c4b2ea85":"code","e8262966":"code","9cf3c83d":"code","6bf2403f":"code","a1c0bd6f":"code","0d3ed590":"code","5e412079":"code","2bd8fb7e":"code","e268ddc5":"code","816bb30a":"code","98ee0118":"code","9ad12808":"code","3ad10107":"markdown","157bc0db":"markdown","cdd70b21":"markdown"},"source":{"67f70853":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc9ac69d":"#  Data Tabulated\nfrom tabulate import tabulate\n# ML Algoritmos\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.dummy import DummyRegressor","e3b0bbd9":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","7fcce227":"def eda(dataset, titulo='EDA'):\n    print(f'=={titulo}==')\n    print('INFO \\n')\n    print(tabulate(dataset.info(), headers='keys', tablefmt='psql'))\n    print('\\nHEAD \\n', tabulate(dataset.head(), headers='keys', tablefmt='psql'))\n    print('\\nTAIL \\n', tabulate(dataset.tail(), headers='keys', tablefmt='psql'))\n    print('\\nDESCRIBE \\n', tabulate(dataset.describe(), headers='keys', tablefmt='psql'))\n    print('\\nEXAMPLES \\n', tabulate(dataset.sample(5), headers='keys', tablefmt='psql'))\n    print('\\nNULL QTY \\n', tabulate([dataset.isnull().sum()], headers=dataset.columns, tablefmt='psql'))\n    print('\\nSHAPE \\n', tabulate([dataset.shape], headers=['ROWS', 'COLS'], tablefmt='psql'))","e3dcb30e":"# eda in train dataset\neda(dataset=train, titulo='EDA [ data train ]')","345af520":"# eda in test dataset\neda(dataset=test, titulo='EDA [ data test ]')","491b92f2":"# data calculated\n# rate women survived\nw = train.query(\"Sex == 'female' and Survived == 1\")\ntotw = train.loc[train.Sex == 'female']\nws = len(w) * 100 \/ len(totw)\n\n# rate men survived\nm = train.query(\"Sex == 'male' and Survived == 1\")\ntotm = train.loc[train.Sex == 'male']\nms = len(m) * 100 \/ len(totm)\n\n# rate people survived\ntp = len(train)\nts = (len(m) + len(w)) * 100 \/ tp","130c5a42":"print(f'Titanic Data Passengers:\\n\\n'\n      f'Total: {tp}\\n'\n      f'Survives: {len(m) + len(w)}\\n'\n      f'Rate Survive: {ts:.2f}')","c4b2ea85":"print(f'\\nPassenger Female:\\n'\n      f'Total: {len(totw)}\\nSurvives: {len(w)}'\n      f'\\nRate Survive: {ws:.2f}')","e8262966":"print(f'\\nPassenger Male:\\n'\n      f'Total: {len(totm)}\\nSurvives: {len(m)}'\n      f'\\nRate Survive: {ms:.2f}')","9cf3c83d":"# target\ny = train['Survived']\n# Features\nfeatures = ['Pclass', 'Sex', 'SibSp', 'Parch']","6bf2403f":"# Data dummy extract\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])","a1c0bd6f":"# regressors list\nprint('\\nAnalisando regressores:')\nalg = []\nscore = []\nregressors = [\n        DecisionTreeRegressor(),\n        RandomForestRegressor(),\n        SVR(),\n        LinearRegression(),\n        GradientBoostingRegressor(),\n        PoissonRegressor(),\n        DummyRegressor(),\n        LogisticRegression(),\n        GaussianNB()\n    ]\nfor regressor in regressors:\n    model = regressor\n    model.fit(X, y)\n    score.append(model.score(X, y))\n    alg.append(regressor)\n\nbestML = pd.DataFrame(columns=['Regressor', 'Score'])\nbestML['Regressor'] = alg\nbestML['Score'] = score\nbestML = bestML.sort_values(by='Score', ascending=False)\nprint(tabulate(bestML, headers='keys', tablefmt='psql'))\n","0d3ed590":"# selecting best model\nbestmodel = bestML.values[0][0]\nprint(f'Selected model: {bestmodel}\\n')","5e412079":"# training \nbestmodel.fit(X, y) \nprint('Model trained')\n","2bd8fb7e":"# predict survive\npredict = bestmodel.predict(X_test)\nprint(f'Predict created. \\nTarget: Survived')","e268ddc5":"# show predicts\npredict","816bb30a":"# creating a dictionary\nmydict = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predict})","98ee0118":"# creating CSV File - content: mydict\nmydict.to_csv('my_submission_ItaloCosta.csv', index=False)","9ad12808":"print('Score: ', bestmodel.score(X, y))","3ad10107":"# My Titanic\n\ncreated by: **Italo Costa**","157bc0db":"**Training and Predicts**","cdd70b21":"**Exploration Dataset Analysis**"}}