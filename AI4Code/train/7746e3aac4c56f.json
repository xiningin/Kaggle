{"cell_type":{"7a44f932":"code","72056959":"code","c86fe206":"code","098bbef4":"code","8d957ec0":"code","575d62e5":"code","8f1af6d9":"code","1a547cfa":"code","89a55d75":"code","e1c3270b":"code","1d607722":"code","cc9eed0f":"code","b81389bc":"code","85f59492":"code","febe60bd":"code","b8e1defa":"code","022ef677":"code","e6decd78":"code","448b81f5":"code","34442b87":"code","d9f1969f":"code","dd5cbaa3":"code","a8199192":"code","5a45e0ab":"code","35bfc9f5":"code","a084bb7f":"code","8911827a":"code","4eb2923e":"code","7f0a446f":"code","ffe1fb20":"code","1678cd36":"markdown","dc02b234":"markdown","46675325":"markdown","52a6788d":"markdown"},"source":{"7a44f932":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport plotly.graph_objects as go\nimport plotly\nimport plotly.offline as py\nfrom plotly.offline import iplot\nimport plotly.io as pio\nimport cufflinks as cf\nimport plotly.express as px\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","72056959":"data = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv',sep=',')","c86fe206":"#Making the First Row the column names\nnew_header = data.iloc[0] #grab the first row for the header\ndata = data[1:] #take the data less the header row\ndata.columns = new_header #set the header row as the df header\ndata.rename(columns=data.iloc[0])\ndata.head()","098bbef4":"#Extracting the basic information about people\nbasic_information = data.iloc[:,1:7]\nbasic_information.columns = ['AgeRange','DataScientistGender','Country','CurrentEducation','CurrentRole','CodingExperience']","8d957ec0":"#Creating interactive countplot for age range\nAgeRange = basic_information['AgeRange'].value_counts()\nAgeRange.iplot(kind=\"bar\",color='green',title='KAGGLE USERS AGE',size=15)","575d62e5":"#Checking Gender for Data Scientists\nbasic_information['DataScientistGender'].isnull().values.any()\nscientist_gender = basic_information['DataScientistGender'].value_counts()\nscientist_gender = pd.DataFrame(scientist_gender)\nscientist_gender.columns = ['DataScientistCount']\nscientist_gender.index.names = ['Gender']\nfig = px.bar(scientist_gender, y='DataScientistCount', x=scientist_gender.index,text='DataScientistCount',title='K A G G L E  U S E R S  G E N D E R')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","8f1af6d9":"#Percentage per gender\nfig = px.pie(scientist_gender, values='DataScientistCount', names=scientist_gender.index, title='K A G G L E R S  G E N D E R  D I S T R I B U T I O N',height=600)\nfig.show()","1a547cfa":"country = basic_information['Country'].value_counts()\ncountry.columns = [['Countries_Count']]\ncountry.index.names = ['Countries']\nfig = px.bar(country, x=country.index, y='Country',\n             hover_data=[country.index, 'Country'], color='Country',\n             labels={'Country':'Count'}, height=800,title='K A G G L E  U S E R S  B Y  C O U N T R Y')\nfig.show()","89a55d75":"#Percentage per country\nfig = px.pie(country, values='Country', names=country.index, title='Percentage of kagglers distributed by countries',height=1000)\nfig.show()","e1c3270b":"#Country WordCloud\nallwords = ' '.join([twts for twts in country.index])\nwordcloud = WordCloud(width=600, height=300, random_state=21, max_font_size=119,max_words=300,background_color='white').generate(allwords)\nplt.figure(figsize=(12,8))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","1d607722":"#Filter Genders by Country\ncountryAndGender = basic_information[['DataScientistGender','Country']]\nmancountry = countryAndGender[countryAndGender['DataScientistGender']=='Man']\nwomancountry = countryAndGender[countryAndGender['DataScientistGender']=='Woman']\nprefer_not_country = countryAndGender[countryAndGender['DataScientistGender']=='Prefer not to say']\nself_describe_country = countryAndGender[countryAndGender['DataScientistGender']=='Prefer to self-describe']\nnonBinaryCountry = countryAndGender[countryAndGender['DataScientistGender']=='Nonbinary']\n\n#Value count for each dataframe\nmancountry = mancountry ['Country'].value_counts()\nwomancountry = womancountry['Country'].value_counts()\nprefer_not_country = prefer_not_country ['Country'].value_counts()\nself_describe_country = self_describe_country['Country'].value_counts()\nnonBinaryCountry = nonBinaryCountry['Country'].value_counts()\n#Man Barchart\nmancountry = pd.DataFrame(mancountry)\nmancountry.columns = ['Count']\nmancountry.index.names = ['Countries']\nfig = px.bar(mancountry , y='Count', x=mancountry.index,text='Count',color='Count')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='M A L E  U S E R S')\nfig.show()\n\n#woman Barchart\nwomancountry = pd.DataFrame(womancountry)\nwomancountry.columns = ['Count']\nwomancountry.index.names = ['Countries']\nfig = px.bar(womancountry , y='Count', x=womancountry.index,text='Count',color='Count')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='F E M A L E  U S E R S')\nfig.show()\n\n#prefer not to say Barchart\nprefer_not_country  = pd.DataFrame(prefer_not_country )\nprefer_not_country.columns = ['Count']\nprefer_not_country.index.names = ['Countries']\nfig = px.bar(prefer_not_country  , y='Count', x=prefer_not_country.index, text='Count',color='Count')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='P R E F E R  N O T  T O S H A R E   U S E R S')\nfig.show()\n\n#self describe Barchart\nself_describe_country  = pd.DataFrame(self_describe_country )\nself_describe_country.columns = ['Count']\nself_describe_country.index.names = ['Countries']\nfig = px.bar(self_describe_country  , y='Count', x=self_describe_country.index ,text='Count',color='Count')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='S E L F  D E S C R I B E  U S E R S')\nfig.show()\n\n#nonbinary Barchart\nnonBinaryCountry = pd.DataFrame(nonBinaryCountry)\nnonBinaryCountry.columns = ['Count']\nnonBinaryCountry.index.names = ['Countries']\nfig = px.bar(nonBinaryCountry, y='Count', x=nonBinaryCountry.index,text='Count',color='Count')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='N O N  B I N A R Y  U S E R S')\nfig.show()","cc9eed0f":"#Percentage pe male kagglers\nfig = px.pie(mancountry, values='Count', names=mancountry.index, title='Percentage of kagglers by male gender for each country',height=950)\nfig.show()\n\n#Percentage per woman kagglers\nfig = px.pie(womancountry, values='Count', names=womancountry.index, title='Percentage of kagglers by Woman gender for each country',height=950)\nfig.show()\n\n#Percentage per prefer not to say kagglers\nfig = px.pie(prefer_not_country, values='Count', names=prefer_not_country.index, title='Percentage of kagglers by \"Perefer not to say\" gender for each country',height=950)\nfig.show()\n\n#Percentage per self describe kagglers\nfig = px.pie(self_describe_country, values='Count', names=self_describe_country.index, title='Percentage of kagglers by \"Prefer to self-describe\" gender for each country',height=950)\nfig.show()\n\n#Percentage nonbinary kagglers\nfig = px.pie(nonBinaryCountry, values='Count', names=nonBinaryCountry.index, title='Percentage of kagglers by Nonbinary gender for each country',height=950)\nfig.show()","b81389bc":"#Taking info about current education\ncurrentEducation = basic_information[['CurrentEducation']]\ncurrentEducation = currentEducation.value_counts()\ncurrentEducation = pd.DataFrame(currentEducation)\ncurrentEducation.columns = ['Count']\ncurrentEducation.reset_index(level=0, inplace=True)\n#Percentage per country\nfig = px.pie(currentEducation, values='Count', title='K A G G L E R S  C U R R E N T  E D U C A T I O N',height=700,names='CurrentEducation')\nfig.show()","85f59492":"#Creating Dataframe for coding exp\ncodingExp = basic_information['CodingExperience']\ncodingExp = pd.DataFrame(codingExp)\ncodingExp = codingExp.value_counts()\ncodingExp.columns = ['ExpCount']\nexpCountlist = codingExp.tolist()\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=['3-5 years','1-2 years','< 1 years','5-10 years','10-20 years','20+ years'],\n    y=expCountlist ,\n    marker=dict(color=\"green\", size=12),\n    mode=\"markers\",\n    name ='Programmers Count Based on Years Writing Code',\n))\nfig.add_trace(go.Scatter(\n    x=['3-5 years','1-2 years','< 1 years','5-10 years','10-20 years','20+ years'],\n    y=[(round(codingExp[0] \/ sum(codingExp) * 100)),(round(codingExp[1] \/ sum(codingExp) * 100)),(round(codingExp[2] \/ sum(codingExp) * 100)),(round(codingExp[3] \/ sum(codingExp) * 100)),(round(codingExp[4] \/ sum(codingExp) * 100)),(round(codingExp[5] \/ sum(codingExp) * 100)),(round(codingExp[6] \/ sum(codingExp) * 100))],\n    marker=dict(color=\"red\", size=12),\n    mode=\"markers\",\n    name=\"% Percentage\",\n))\n\nfig.update_layout(title=\"W R I T I N G  C O  D E  E X P E R I E N C E  C O U N T  B A S E D  O N  Y E A R S  D O I N G  I T\",\n                  xaxis_title=\"Years Writing Code\",\n                  yaxis_title=\"Count Based on Years\")\n\nfig.show()\n","febe60bd":"#Programming Language use\nprogBasis = data.iloc[:,7:20]\nprogBasis.columns =  ['language1','language2','language3','language4','language5','language6','language7','language8','language9','language10','language11','language12','language13']\npython = progBasis['language1'].value_counts()\nR = progBasis['language2'].value_counts()\nSQL = progBasis['language3'].value_counts()\nC = progBasis['language4'].value_counts()\nCplus = progBasis['language5'].value_counts()\njava = progBasis['language6'].value_counts()\njavascript = progBasis['language7'].value_counts()\njulia = progBasis['language8'].value_counts()\nswift = progBasis['language9'].value_counts()\nbash = progBasis['language10'].value_counts()\nmatlab = progBasis['language11'].value_counts()\nnone = progBasis['language12'].value_counts()\nother = progBasis['language13'].value_counts()\n#concat Dataframes\nprogBasis = pd.concat([python,R,SQL,C,Cplus,java,javascript,julia,swift,bash,matlab,none,other])\nprogBasis.index.names = ['Programming_Languages']\nfig = px.bar(progBasis, x=progBasis, y=progBasis.index, color=progBasis.index, orientation='h',\n             height=500,)\nfig.update_layout(title=\"P R O G R A M M I N G  L A N G U A G E S  U S E D  B Y  K A G G L E R S\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Programming Languages')\nfig.show()\n\n#Percentage\nfig = px.pie(progBasis, values=progBasis, title='D I S T R I B U T I O N  O F  \"IDE\"  U S E D  B Y  M O S T  K A G G L E R S',height=700,names=progBasis.index)\nfig.show()\n\n#programming Language WordCloud\nallwords = ' '.join([programminglanguage for programminglanguage in progBasis.index])\nwordcloud = WordCloud(width=600, height=300, random_state=21, max_font_size=119,max_words=300,background_color='pink').generate(allwords)\nplt.figure(figsize=(12,8))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","b8e1defa":"#Selecting Columns related to ide`s\nIDE = data.iloc[:,21:33]\nIDE.columns =  ['IDE1', 'IDE2', 'IDE3', 'IDE4', 'IDE5', 'IDE6', 'IDE7', 'IDE8', 'IDE9', 'IDE10', 'IDE11', 'IDE12']\njupyter = IDE['IDE1'].value_counts()\nrstudio = IDE['IDE2'].value_counts()\nvisualStudio = IDE['IDE3'].value_counts()\nvisualStudioCode = IDE['IDE4'].value_counts()\npycharm = IDE['IDE5'].value_counts()\nspyder = IDE['IDE6'].value_counts()\nnotepadplus = IDE['IDE7'].value_counts()\nsublimetext = IDE['IDE8'].value_counts()\nvim = IDE['IDE9'].value_counts()\nmatlab = IDE['IDE10'].value_counts()\nnone = IDE['IDE11'].value_counts()\nother= IDE['IDE12'].value_counts()\n#concat Dataframes\nIDE = pd.concat([jupyter,rstudio,visualStudio,visualStudioCode,pycharm,spyder,notepadplus,sublimetext,vim,matlab,none,other])\nIDE.index.names = ['IDE']\nfig = px.bar(progBasis, x=IDE, y=IDE.index, color=IDE.index, orientation='h',\n             height=500,)\nfig.update_layout(title=\"C O U N T  O F  E N V I R O N M E N T S  U S E D  B Y  K A G G L E R S\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Integrated development environment')\nfig.show()\n\n#Percentage\nfig = px.pie(IDE, values=IDE, title='D I S T R I B U T I O N  O F  \"IDE\"  U S E D  B Y  M O S T  K A G G L E R S',height=700,names=IDE.index)\nfig.show()","022ef677":"#Selecting Columns related to ide`s\nnotebooks = data.iloc[:,33:47]\nnotebooks.columns =  ['notebooks1', 'notebooks2', 'notebooks3', 'notebooks4', 'notebooks5', 'notebooks6', 'notebooks7', 'notebooks8', 'notebooks9', 'notebooks10', 'notebooks11', 'notebooks12','notebooks13','notebooks14']\nkagglenotebook = notebooks['notebooks1'].value_counts()\ncolab = notebooks['notebooks2'].value_counts()\nazure = notebooks['notebooks3'].value_counts()\npaperspace = notebooks['notebooks4'].value_counts()\nbinder = notebooks['notebooks5'].value_counts()\nocean = notebooks['notebooks6'].value_counts()\nibm = notebooks['notebooks7'].value_counts()\nsagemaker = notebooks['notebooks8'].value_counts()\namazonEMR = notebooks['notebooks9'].value_counts()\ngoogleplatform = notebooks['notebooks10'].value_counts()\ngoogledatalab = notebooks['notebooks11'].value_counts()\ndatabricks = notebooks['notebooks12'].value_counts()\nnone = notebooks['notebooks13'].value_counts()\nother= notebooks['notebooks14'].value_counts()\n#concat Dataframes\nnotebooks = pd.concat([kagglenotebook,colab,azure,paperspace,binder,ocean,ibm,sagemaker,amazonEMR,googleplatform,googledatalab,databricks,none,other])\nnotebooks.index.names = ['notebooks']\nfig = px.bar(notebooks, x=notebooks, y=notebooks.index, color=notebooks.index, orientation='h',\n             height=500,)\nfig.update_layout(title=\"C O U N T  O F  E N V I R O N M E N T S  U S E D  B Y  K A G G L E R S\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Notebook')\nfig.show()\n\n#Percentage\nfig = px.pie(notebooks, values=notebooks, title='D I S T R I B U T I O N  O F  N O T E B O O K S   U S E D  B Y  M O S T  K A G G L E R S',height=700,names=notebooks.index)\nfig.show()","e6decd78":"#Plaftorm\ndsplatform = data.iloc[:,47]\ndsplatform = dsplatform.value_counts()\ndsplatform = pd.DataFrame(dsplatform)\ndsplatform.columns = ['platformcount']\ndsplatform.index.names = ['platform']\n#Only 5 rows with Na values, let\u00b4s drop it\ndsplatform.dropna(inplace=True)\n\n#Plots\nfig = px.bar(dsplatform , y='platformcount', x=dsplatform.index,text='platformcount',color='platformcount')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='COUNT OF COMPUTER PLATFORMS USED BY USERS')\nfig.show()\n\n#Percentage\nfig = px.pie(dsplatform, values='platformcount', title='D I S T R I B U T I O N  O F  C O M P U T E R  P L A T F O R M S  U S E D  A T  D A T A  S C I E N C E  P R O J E C T S',height=900,names=dsplatform.index,hole=0.4)\nfig.show()","448b81f5":"#Hardware use\nhardware = data.iloc[:,48:52]\nhardware.columns =  ['hardware1','hardware2','hardware3','hardware4']\ngpu = hardware['hardware1'].value_counts()\ntpu = hardware['hardware2'].value_counts()\nnone = hardware['hardware3'].value_counts()\nother = hardware['hardware4'].value_counts()\n#concat Dataframes\nhardware = pd.concat([gpu,tpu,none,other])\nhardware.index.names = ['hardware']\nfig = px.bar(hardware, x=hardware, y=hardware.index, color=hardware.index, orientation='h',\n             height=500,)\nfig.update_layout(title=\"H A R D W A R E  U S E D  B Y  K A G G L E R S\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Hardware')\nfig.show()\n\n#Percentage\nfig = px.pie(hardware, values=hardware, title='D I S T R I B U T I O N  O F  H A R D WA R E  U S E D  B Y  M O S T  K A G G L E R S',height=700,names=hardware.index,hole=0.5)\nfig.show()\n","34442b87":"#How many times have you used a TPU\ntpu_use = data.iloc[:,52]\ntpu_use = tpu_use.value_counts()\ntpu_use = pd.DataFrame(tpu_use)\ntpu_use.columns = ['count']\ntpu_use.index.names = ['tpu']\n#Percentage\nfig = px.pie(tpu_use , values='count' , title='\u00bfHOW MANY TIMES KAGGLERS HAVE USED A TPU?',height=700,names=tpu_use.index,color_discrete_sequence=px.colors.sequential.RdBu,hole=0.3)\nfig.show()\n","d9f1969f":"#libraries use\nlibraries = data.iloc[:,53:65]\nlibraries.columns = ['library1','library2','library3','library4','library5','library6','library7','library8','library9','library10','library11','library12']\nmatplotlib = libraries ['library1'].value_counts()\nseaborn = libraries ['library2'].value_counts()\nplotly = libraries ['library3'].value_counts()\nggplot = libraries ['library4'].value_counts()\nshiny = libraries ['library5'].value_counts()\nd3 = libraries ['library6'].value_counts()\naltair = libraries ['library7'].value_counts()\nbokeh = libraries ['library8'].value_counts()\ngeoplotlib = libraries ['library9'].value_counts()\nfolium = libraries ['library10'].value_counts()\nnone = libraries ['library11'].value_counts()\nother = libraries ['library12'].value_counts()\n\n#Concat Dataframes\nlibraries = pd.concat([matplotlib,seaborn,plotly,ggplot,shiny,d3,altair,bokeh,geoplotlib,folium,none,other])\nlibraries.columns = ['libraryCount']\nlibraries.index.names = ['library']\n\n#plot\nfig = px.bar(libraries, x=libraries, y=libraries.index, color=libraries.index, orientation='h',\n             height=500)\nfig.update_layout(title=\"L I B R A R I E S  U S E D  B Y  K A G G L E R S\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Library')\nfig.show()\n\n#Percentage\nfig = px.pie(libraries , values=libraries  , title='L I B R A R I E S  U S E D  B Y  K A G G L E R S',height=700,names=libraries.index,color_discrete_sequence=px.colors.sequential.RdBu,hole=0.3)\nfig.show()","dd5cbaa3":"#For how many years have you used machine learning methods?\nml_methods = data.iloc[:,65]\nml_methods = ml_methods.value_counts()\nml_methods.index.names = ['Time']\n\n#plot\nfig = px.bar(ml_methods , x=ml_methods , y=ml_methods .index, color=ml_methods .index, orientation='h',\n             height=700)\nfig.update_layout(title=\"\u00bfFor how many years have you used machine learning methods?\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Time')\nfig.show()\n\n#Percentage\nfig = px.pie(ml_methods, values=ml_methods  , title='DISTRIBUTION OF YEARS',height=700,names=ml_methods.index,color_discrete_sequence=px.colors.sequential.RdBu,hole=0.3)\nfig.show()","a8199192":"#Which of the following machine learning frameworks do you use on a regular basis? \nml_frameworks = data.iloc[:,66:82]\nml_frameworks.columns = ['frameworks1','frameworks2','frameworks3','frameworks4','frameworks5','frameworks6','frameworks7','frameworks8','frameworks9','frameworks10','frameworks11','frameworks12','frameworks13','frameworks14','frameworks15','frameworks16']\nskn = ml_frameworks['frameworks1'].value_counts()\ntf = ml_frameworks['frameworks2'].value_counts()\nkeras = ml_frameworks['frameworks3'].value_counts()\npytorch = ml_frameworks['frameworks4'].value_counts()\nfast = ml_frameworks['frameworks5'].value_counts()\nmxnet = ml_frameworks['frameworks6'].value_counts()\nxgboost = ml_frameworks['frameworks7'].value_counts()\nlightgbm = ml_frameworks['frameworks8'].value_counts()\ncatboost = ml_frameworks['frameworks9'].value_counts()\nprophet = ml_frameworks['frameworks10'].value_counts()\nh2o = ml_frameworks['frameworks11'].value_counts()\ncaret = ml_frameworks['frameworks12'].value_counts()\ntidymodels = ml_frameworks['frameworks13'].value_counts()\njax = ml_frameworks['frameworks14'].value_counts()\nnone = ml_frameworks['frameworks15'].value_counts()\nother = ml_frameworks['frameworks16'].value_counts()\n\n#dataframe concat\nml_frameworks = pd.concat([skn,tf,keras,pytorch,fast,mxnet,xgboost,catboost,prophet,h2o,caret,tidymodels,jax,none,other])\nml_frameworks.index.names = ['frameworks']\nml_frameworks.columns = ['frameworkcount']\n\n#plot\nfig = px.bar(ml_frameworks , x=ml_frameworks , y=ml_frameworks.index, color=ml_frameworks.index, orientation='h',\n             height=700)\nfig.update_layout(title=\"MACHINE LEARNING FRAMEWORK COUNT BY USERS\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='FRAMEWORKS')\nfig.show()\n\n#Percentage\nfig = px.pie(ml_frameworks ,values=ml_frameworks  , title='DISTRIBUTION OF FRAMEWORKS',height=700,names=ml_frameworks.index,color_discrete_sequence=px.colors.sequential.RdBu,hole=0.3)\nfig.show()\n\n#Machine learning frameworks WordCloud\nallwords = ' '.join([framework for framework in ml_frameworks.index])\nwordcloud = WordCloud(width=600, height=300, random_state=21, max_font_size=119,max_words=300,background_color='skyblue').generate(allwords)\nplt.figure(figsize=(12,8))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","5a45e0ab":"#Which of the following ML algorithms do you use on a regular basis\nalgorithms = data.iloc[:,82:94]\nalgorithms.columns = ['algorithm1','algorithm2','algorithm3','algorithm4','algorithm5','algorithm6','algorithm7','algorithm8','algorithm9','algorithm10','algorithm11','algorithm12']\nlr = algorithms['algorithm1'].value_counts()\nrf = algorithms['algorithm2'].value_counts()\nxgboost_alg = algorithms['algorithm3'].value_counts()\nbayesian = algorithms['algorithm4'].value_counts()\nevolutionary = algorithms['algorithm5'].value_counts()\nMLP = algorithms['algorithm6'].value_counts()\nCNN = algorithms['algorithm7'].value_counts()\nGAN = algorithms['algorithm8'].value_counts()\nRNN = algorithms['algorithm9'].value_counts()\nBERT = algorithms['algorithm10'].value_counts()\nnone = algorithms['algorithm11'].value_counts()\nother = algorithms['algorithm12'].value_counts()\n\n#Concat Dataframes\nalgorithms = pd.concat([lr,rf,xgboost_alg,bayesian,evolutionary,MLP,CNN,GAN,RNN,BERT,none,other])\nalgorithms.columns = ['algorithmCount']\nalgorithms.index.names = ['Algorithm']\n\n#Barchart\nfig = px.bar(algorithms, x=algorithms.index, y=algorithms,color=algorithms.index)\nfig.update_layout(title=\"ALGORITHMS COUNT BY USERS\",\n                  xaxis_title=\"Count\",\n                  yaxis_title='Algorithms')\nfig.show()\n\n#Percentage\nfig = px.pie(algorithms ,values=algorithms  , title='DISTRIBUTION OF ALGORITHMS',height=700,names=algorithms.index,hole=0.3)\nfig.show()\n\n#Percentage column based on count column\nalgorithms = pd.DataFrame(algorithms)\nalgorithms.columns = ['Count']\nalgorithms['Percentage'] = (algorithms['Count'] \/ algorithms['Count'].sum()) * 100\nalgorithms.reset_index(level=0, inplace=True)\n\nfig = px.scatter(algorithms, x=\"Count\", y=\"Percentage\", text='Algorithm', log_x=False, size_max=60,color='Algorithm')\n\nfig.update_traces(textposition='top center')\n\nfig.update_layout(\n    height=900,\n    title_text='PERCENTAGE AND COUNT BY ALGORITHM'\n)\n\nfig.show()","35bfc9f5":"#Which categories of computer vision methods do you use on a regular basis\ncomputer_vision = data.iloc[:,95:101]\ncomputer_vision.columns = ['computervision1','computervision2','computervision3','computervision4','computervision5','computervision6']\nimage_seg = computer_vision['computervision1'].value_counts()\nobject_det = computer_vision['computervision2'].value_counts()\nimage_classification = computer_vision['computervision3'].value_counts()\ngan_cv = computer_vision['computervision4'].value_counts()\nnone = computer_vision['computervision5'].value_counts()\nother = computer_vision['computervision6'].value_counts()\n\n#Concat\ncomputer_vision = pd.concat ([image_seg, object_det, image_classification, gan_cv, none, other])\ncomputer_vision.columns = ['computervisionCount']\ncomputer_vision.index.names = ['ComputerVision']\n\n\n#Percentage\nfig = px.pie(computer_vision ,values=computer_vision   , title='DISTRIBUTION OF COMPUTER VISION TECHNIQUES',height=1200,names=computer_vision.index,hole=0.3)\nfig.show()\n\n","a084bb7f":"#Which of the following natural language processing (NLP) methods do you use on a regular basis\nnlp = data.iloc[:,101:107]\nnlp.columns = ['nlp1','nlp2','nlp3','nlp4','nlp5','nlp6']\nword_embeddings = nlp['nlp1'].value_counts()\nenconder_decoder = nlp['nlp2'].value_counts()\ncontextualized_embeddings = nlp['nlp3'].value_counts()\ntransformer_language = nlp['nlp4'].value_counts()\nnone = nlp['nlp5'].value_counts()\nother = nlp['nlp6'].value_counts()\n\n#Concat\nnlp = pd.concat([word_embeddings ,enconder_decoder,contextualized_embeddings,transformer_language,none,other])\nnlp.index.names = ['Natural Language Processing']\n\n#Barchart\nfig = px.bar(nlp  , y=nlp , x=nlp.index,text=nlp ,color=nlp.index,orientation='v')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=1000,title='NATURAL LANGUAGE PROCESSING TECNHIQUES COUNT BY USERS')\nfig.show()\n\n\n#Percentage\nfig = px.pie(nlp , values=nlp  , title='DISTRIBUTION OF NLP TECHNIQUES',height=1200,names=nlp.index,color_discrete_sequence=px.colors.sequential.RdBu,hole=0.4)\nfig.show()\n","8911827a":"#Company Size\ncompany_size = data.iloc[:,108]\ncompany_size = pd.DataFrame(company_size)\n#Drop NA values\ncompany_size.dropna(inplace=True)\ncompany_size.columns = ['CompanySize']\ncompany_size = company_size['CompanySize'].value_counts()\ncompany_size.index.names = ['Company Size']\n#Percentage\ncolors = ['pink','skyblue','purple','green','yellow','lightgreen','orange']\nfig = px.pie(company_size , values=company_size  , title='DISTRIBUTION OF COMPANY SIZE BASED ON EMPLOYEES',height=900,names=company_size.index,hole=0.8,color_discrete_sequence=colors)\nfig.show()\n","4eb2923e":"#Select any activities that make up an important part of your role at work:\ncompany_role = data.iloc[:,110:118]\ncompany_role.columns = ['role1','role2','role3','role4','role5','role6','role7','role8']\ninfluence_business = company_role['role1'].value_counts()\ninfrastructure = company_role['role2'].value_counts()\nprototypes = company_role['role3'].value_counts()\nworkflows = company_role['role4'].value_counts()\nexperimentation = company_role['role5'].value_counts()\nresearch = company_role['role6'].value_counts()\nnone = company_role['role7'].value_counts()\nother = company_role['role8'].value_counts()\n\n#DF concat\ncompany_role = pd.concat([influence_business, infrastructure, prototypes, workflows, experimentation, research, none, other])\ncompany_role.columns = ['roleCount']\ncompany_role.index.names = ['role']\n\n#Pie Chart\nrole_pie = px.pie(company_role, values=company_role,title='DISTRIBUTION OF ROLES AT COMPANIES',height=1200,names=company_role.index,hole=0.1)\nrole_pie.show()","7f0a446f":"#What is your current yearly compensation (approximate $USD)?\nyear_compensation = data.iloc[:,119]\nyear_compensation = year_compensation.value_counts()\nyear_compensation.index.names = ['SalaryRange']\n\n#Barchart\nfig = px.bar(year_compensation  , y=year_compensation , x=year_compensation.index,text=year_compensation ,color=year_compensation.index,orientation='v')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide',height=900,title='COUNT OF SALARY COMPENSATION BY USERS ON ONE YEAR',yaxis_title='Count')\nfig.show()\n\n","ffe1fb20":"#Cloud Computing Platforms\ncloud_platform = data.iloc[:,120:132]\ncloud_platform.columns = ['cloudplatform1','cloudplatform2','cloudplatform3','cloudplatform4','cloudplatform5','cloudplatform6','cloudplatform7','cloudplatform8','cloudplatform9','cloudplatform10','cloudplatform11','cloudplatform12']\n#Dataframes\naws = cloud_platform['cloudplatform1'].value_counts()\nazure = cloud_platform['cloudplatform2'].value_counts()\ngpc = cloud_platform['cloudplatform3'].value_counts()\nred_hat = cloud_platform['cloudplatform4'].value_counts()\noracle_cloud = cloud_platform['cloudplatform5'].value_counts()\nsap_cloud = cloud_platform['cloudplatform6'].value_counts()\nsalesforce_cloud = cloud_platform['cloudplatform7'].value_counts()\nvmware_cloud = cloud_platform['cloudplatform8'].value_counts()\nalibaba = cloud_platform['cloudplatform9'].value_counts()\ntencent = cloud_platform['cloudplatform10'].value_counts()\nnone = cloud_platform['cloudplatform11'].value_counts()\nother = cloud_platform['cloudplatform12'].value_counts()\n\n#Concat Dataframes\ncloud_platform = pd.concat([aws, azure, gpc, red_hat, oracle_cloud, sap_cloud, salesforce_cloud, vmware_cloud, alibaba, tencent, none, other])\ncloud_platform.index.names = ['CloudPlatform']\ncloud_platform.columns = ['PlatformCount']\n\n#Barchart\nfig = px.bar(cloud_platform, x=cloud_platform.index, y=cloud_platform,\n             hover_data=[cloud_platform.index,], color=cloud_platform.index,\n              height=800,title='PLATFORM COUNT BY KAGGLERS')\nfig.update_layout(yaxis_title='Count')\nfig.show()","1678cd36":"## **2020 Kaggle ML and DS Survey Results**\n\nThe challenge objective: tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. A \u201cstory\u201d could be defined any number of ways, and that\u2019s deliberate. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners. That group can be defined in the macro (for example: anyone who does most of their coding in Python) or the micro (for example: female data science students studying machine learning in masters programs).","dc02b234":"## **Kagglers Countries**","46675325":"# **EDA**\n\nBasic information about people who is filling the survey","52a6788d":"# **Reading Data**"}}