{"cell_type":{"c6ed6a90":"code","2ec1bb43":"code","9ec2c7e8":"code","b016f71c":"code","e16caa76":"code","08aa81a4":"markdown"},"source":{"c6ed6a90":"! pip install git+https:\/\/github.com\/LIAAD\/yake","2ec1bb43":"from brown_clustering_yangyuan import *\nimport pandas as pd\nfrom nltk.tokenize import RegexpTokenizer\nimport yake\n\n\nforum_posts = pd.read_csv(\"..\/input\/meta-kaggle\/ForumMessages.csv\")","9ec2c7e8":"def keywords_yake(sample_posts):\n    # take keywords for each post & turn them into a text string \"sentence\"\n    simple_kwextractor = yake.KeywordExtractor()\n\n    # create empty list to save our \"sentnecs\" to\n    sentences = []\n\n    for post in sample_posts:\n        post_keywords = simple_kwextractor.extract_keywords(post)\n\n        sentence_output = \"\"\n        for word, number in post_keywords:\n            sentence_output += word + \" \"\n\n        sentences.append(sentence_output)\n        \n    return(sentences)\n\ndef tokenizing_after_YAKE(sentences):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    sample_data_tokenized = [w.lower() for w in sentences]\n    sample_data_tokenized = [tokenizer.tokenize(i) for i in sample_data_tokenized]\n    \n    return(sample_data_tokenized)\n\ndef get_clusters_maybe(megacluster):\n    # so it looks like all the clustres have been concatenated to a single array\n    # but they're in alphabetical order so we can use that to un-cat them \n\n    # create list with one sub list\n    cluster_list = [[]] \n    list_index = 0\n\n    # look at all words but last (since we compare each word\n    # to the next word)\n    for i in range(len(megacluster) - 1):\n        if megacluster[i - 1] < megacluster[i]:\n            # add current word to current sublist\n            cluster_list[list_index].append(megacluster[i])\n        else:\n            # create a new sublist\n            cluster_list.append([])\n            list_index = list_index + 1\n\n            # add current word\n            cluster_list[list_index].append(megacluster[i])\n    \n    return(cluster_list)","b016f71c":"# subsample forum posts\nsample_posts = forum_posts.Message[-1000:].astype(str)\n\n# extract keywords and token\nkeyword_output = keywords_yake(sample_posts)\ntokenized_output = tokenizing_after_YAKE(keyword_output)\n\n# cluster\ncorpus = Corpus(tokenized_output, 0.001)\nclustering = BrownClustering(corpus, 2)\nclustering.train()\n\n# seperate output into different clusters\nmegacluster = clustering.helper.get_cluster(0)\nclusters_maybe = get_clusters_maybe(megacluster)","e16caa76":"clusters_maybe[10:20]","08aa81a4":"Rachael's note: I'm  not particiuarly happy with these clusters for my specific use case. Going forward I'm going to try a different approach. ="}}