{"cell_type":{"94b0738d":"code","f251c27a":"code","4fa276a5":"code","172f1625":"code","1e8b2eb4":"code","ffb9a0e8":"code","0959a264":"code","f86d8174":"code","9a446370":"code","74281e2c":"code","3b8cf0dd":"code","3ef631e7":"code","59d4f17c":"code","be09a251":"code","24ce1217":"code","1d9774ac":"code","871e6b2e":"code","4837f37b":"code","03852e76":"code","3358b877":"code","573f2c67":"code","13e0e51b":"code","7f952e7a":"code","f13260d8":"code","4fa83a77":"code","c3b66811":"code","17bb5c70":"code","4ba91256":"code","8a25aea8":"code","8ccc9706":"code","16f9214d":"code","ebfc8990":"code","b9feaf29":"code","696fc5c5":"code","207854f5":"code","18aad86b":"code","22cd8d07":"code","b5084a2c":"code","bc974504":"code","61706fff":"code","95250a1c":"code","b1f422f6":"code","d523cf7e":"code","2ac9e73e":"markdown","d0f58c78":"markdown","ebb0f97a":"markdown","2112718a":"markdown","037fb540":"markdown","83b1a495":"markdown","5a126023":"markdown","cab415af":"markdown","6a84e867":"markdown","82608711":"markdown","05db30f2":"markdown","72ba6983":"markdown","b3ae6257":"markdown","d8a1631a":"markdown","b8eb3dc6":"markdown","a1b93a5e":"markdown","3723eeaf":"markdown","747cc808":"markdown","365968c1":"markdown","78eb2b77":"markdown","89668597":"markdown","ea6167b9":"markdown","d9f7efe9":"markdown","32dece5e":"markdown","e8a8ba68":"markdown","e00315f6":"markdown","92a4cbf9":"markdown","a3686620":"markdown","bbdb1413":"markdown","556b39ea":"markdown"},"source":{"94b0738d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n## statistical tests\nfrom scipy.stats import ttest_ind\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current sessionda","f251c27a":"data = pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\nmy_data = data.copy()\nmy_data.head()\n## our target variable is \"DEATH_EVENT\". we store it in a variable\ntarget_variable = \"DEATH_EVENT\"","4fa276a5":"my_data.shape","172f1625":"my_data.dtypes","1e8b2eb4":"sns.heatmap(my_data.isna(), cbar=False)","ffb9a0e8":"((my_data.shape[0]-my_data.isna().sum())\/my_data.shape[0])*100","0959a264":"my_data = my_data.drop([\"time\"],axis=1)","f86d8174":"not_dead = my_data[my_data[target_variable] == 0][target_variable].value_counts().tolist()[0]\ndead = my_data[my_data[target_variable] == 1][target_variable].value_counts().tolist()[0]\n\ndead_percentage = dead \/ my_data.shape[0] * 100\nnot_dead_percentage = not_dead \/ my_data.shape[0] * 100\n\nprint(\"the percentage of dead people from heart failure is {:.2f}%\".format(dead_percentage))\nprint(\"the percentage of people that didn't die from heart failure is {:.2f}%\".format(not_dead_percentage))","9a446370":"float_features = my_data.select_dtypes(\"float64\")\nprint(\"float features are : {}\".format(float_features.transpose().index.tolist()))\nfor float_feature in float_features:\n   plt.figure()\n   sns.distplot(my_data[float_feature])","74281e2c":"for float_feature in float_features:\n   print(\"skewness of the feature \\\"{}\\\" is {:.2f}\".format(float_feature,my_data[float_feature].skew()))","3b8cf0dd":"int_features = my_data.select_dtypes(\"int\")\nfor int_feature in int_features:\n    print(\"{} #{}\".format(int_feature,my_data[int_feature].nunique()))","3ef631e7":"int_features_with_two_values = []\nfor int_feature in int_features:\n    if my_data[int_feature].nunique() <= 2 and int_feature != target_variable:\n        int_features_with_two_values.append(int_feature)\nint_features_with_two_values","59d4f17c":"for int_feature_with_two_values in int_features_with_two_values:\n    print(\"{:<20} {} \".format(int_feature_with_two_values,my_data[int_feature_with_two_values].unique()))","be09a251":"def show_percentage(label,list,indexes):\n    for i in range(0,len(list)):\n        percentage = list[i] \/ sum(list) * 100\n        print(\"the number of {} in \\\"{}\\\" variable is {}  [ {:.2f}% ]\".format(indexes[i],label,list[i],percentage))","24ce1217":"for int_feature_with_two_values in int_features_with_two_values:\n   if int_feature_with_two_values == \"sex\":\n    show_percentage(int_feature_with_two_values,my_data[int_feature_with_two_values].value_counts(),[\"woman\",\"man\"])\n   else:\n    show_percentage(int_feature_with_two_values,my_data[int_feature_with_two_values].value_counts(),[\"no\",\"yes\"])\n   print(\"-----------\")","1d9774ac":"int_features_with_multiple_values = []\nfor int_feature in int_features:\n    if my_data[int_feature].nunique() > 2:\n        int_features_with_multiple_values.append(int_feature)\nint_features_with_multiple_values","871e6b2e":"for int_feature_with_multiple_values in int_features_with_multiple_values:\n    plt.figure()\n    sns.distplot(my_data[int_feature_with_multiple_values])\n    \nfor int_feature_with_multiple_values in int_features_with_multiple_values:\n   print(\"skewness of the feature \\\"{}\\\" is {:.2f}\".format(int_feature_with_multiple_values,my_data[int_feature_with_multiple_values].skew()))","4837f37b":"for int_feature_with_multiple_values in int_features_with_multiple_values:\n    print(my_data[int_feature_with_multiple_values].describe())\n    print(\"---------------------------------\")","03852e76":"# dead people\ndead_people_data = my_data[my_data[target_variable] == 1]\n# alive people\nalive_people_data = my_data[my_data[target_variable] == 0]","3358b877":"print(float_features.columns.tolist())\nprint(int_features_with_multiple_values)\nprint(int_features_with_two_values)","573f2c67":"#fig, ax =plt.subplots(1,len(int_features_with_two_values),constrained_layout=True,figsize=(15,4))\nfor int_feature_with_two_values in int_features_with_two_values:\n    plt.figure()\n    sns.heatmap(pd.crosstab(my_data[target_variable],my_data[int_feature_with_two_values]),annot=True,cbar=False,fmt='d')","13e0e51b":"## ejection_fraction\nplt.figure()\nsns.distplot(dead_people_data[\"ejection_fraction\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"ejection_fraction\"],hist=False,label='alive people')\nplt.legend()\n\n## creatinine_phosphokinase\nplt.figure()\nsns.distplot(dead_people_data[\"creatinine_phosphokinase\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"creatinine_phosphokinase\"],hist=False,label='alive people')\nplt.legend()\n\n## serum_sodium\nplt.figure()\nsns.distplot(dead_people_data[\"serum_sodium\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"serum_sodium\"],hist=False,label='alive people')\nplt.legend()","7f952e7a":"## age\nplt.figure()\nsns.distplot(dead_people_data[\"age\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"age\"],hist=False,label='alive people')\nplt.legend()\n\n## platelets\nplt.figure()\nsns.distplot(dead_people_data[\"platelets\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"platelets\"],hist=False,label='alive people')\nplt.legend()\n\n## age\nplt.figure()\nsns.distplot(dead_people_data[\"serum_creatinine\"],hist=False,label='dead people')\nsns.distplot(alive_people_data[\"serum_creatinine\"],hist=False,label='alive people')\nplt.legend()","f13260d8":"sus_variables = [\"serum_creatinine\",\"ejection_fraction\",\"serum_sodium\"] \nsns.heatmap(my_data[sus_variables].corr())","4fa83a77":"for sus_variable in sus_variables:\n    sns.lmplot(x=\"age\",y=sus_variable,hue=target_variable,data=my_data)\n    print(\"correlation is {}\".format(my_data.corr()[\"age\"][sus_variable]))","c3b66811":"## we split our data with sex.\nman_data = my_data[(my_data[\"sex\"] == 1)]\nwoman_data = my_data[(my_data[\"sex\"] == 0)]\nfor sus_variable in sus_variables:\n    plt.figure()\n    sns.distplot(man_data[sus_variable],hist=False,label='man')\n    sns.distplot(woman_data[sus_variable],hist=False,label='woman')\n    plt.legend()","17bb5c70":"# smokers and non smokers\npeople_true_data = my_data[my_data[\"smoking\"] == 1]\npeople_false_data = my_data[my_data[\"smoking\"] == 0]\nfor sus_variable in sus_variables:\n    plt.figure()\n    sns.distplot(people_true_data[sus_variable],hist=False,label='smokers')\n    sns.distplot(people_false_data[sus_variable],hist=False,label='non_smokers')\n    plt.legend()","4ba91256":"# diabetes and non diabetes\npeople_true_data = my_data[(my_data[\"diabetes\"] == 1)]\npeople_false_data = my_data[my_data[\"diabetes\"] == 0]\nfor sus_variable in sus_variables:\n    plt.figure()\n    sns.distplot(people_true_data[sus_variable],hist=False,label='diabetes')\n    sns.distplot(people_false_data[sus_variable],hist=False,label='non diabetes')\n    plt.legend()","8a25aea8":"# high blood pressure and non high blood pressure \npeople_true_data = my_data[my_data[\"high_blood_pressure\"] == 1]\npeople_false_data = my_data[my_data[\"high_blood_pressure\"] == 0]\nfor sus_variable in sus_variables:\n    plt.figure()\n    sns.distplot(people_true_data[sus_variable],hist=False,label='high blood pressure ')\n    sns.distplot(people_false_data[sus_variable],hist=False,label='non high blood pressure ')\n    plt.legend()","8ccc9706":"# aneamia and non aneamia \npeople_true_data = my_data[my_data[\"anaemia\"] == 1]\npeople_false_data = my_data[my_data[\"anaemia\"] == 0]\nfor sus_variable in sus_variables:\n    plt.figure()\n    sns.distplot(people_true_data[sus_variable],hist=False,label='anaemia')\n    sns.distplot(people_false_data[sus_variable],hist=False,label='non anaemia')\n    plt.legend()","16f9214d":"## we need to balance our datas for tests.\nprint(dead_people_data.shape)\nprint(alive_people_data.shape)","ebfc8990":"balanced_alive_people_data = alive_people_data.sample(dead_people_data.shape[0])","b9feaf29":"def t_test(data1,data2,alpha):\n    stat, p = ttest_ind(data1,data2)\n    return p < alpha","696fc5c5":"print(t_test(balanced_alive_people_data[\"serum_sodium\"],dead_people_data[\"serum_sodium\"],0.05))\nprint(t_test(balanced_alive_people_data[\"ejection_fraction\"],dead_people_data[\"ejection_fraction\"],0.05))\nprint(t_test(balanced_alive_people_data[\"serum_creatinine\"],dead_people_data[\"serum_creatinine\"],0.05))","207854f5":"balanced_man_data = man_data.sample(woman_data.shape[0])\nprint(t_test(balanced_man_data[\"serum_sodium\"],woman_data[\"serum_sodium\"],0.05))","18aad86b":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nimportant_features = [\"serum_sodium\",\"ejection_fraction\",\"serum_creatinine\"]\n\ndata_for_processing = data.copy()\n\nfor important_feature in important_features:\n    data_gross = data_for_processing[important_feature].values.reshape(-1, 1).astype(float)\n    data_normalized = preprocessing.normalize(data_gross,axis=0)\n    data_for_processing[important_feature] = data_normalized\n    \n\ndata_for_training = data_for_processing[important_features+[target_variable]]\n\ntrain_set,test_set = train_test_split(data_for_training,test_size=0.25)\n    \ntrain_set_y = train_set.pop(target_variable)\ntest_set_y = test_set.pop(target_variable)","22cd8d07":"## logistic regression\nlr_parameters = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],'C': [0.001, 0.01, 0.1, 1,10],'penalty': ['l2']}\nlr = GridSearchCV(LogisticRegression(),param_grid=lr_parameters,cv=5,refit=True)\nlr.fit(train_set,train_set_y)\nprint(lr.best_params_)\nlr_score = lr.score(test_set, test_set_y)","b5084a2c":"## gaussian naive bayesian\ngnb = GaussianNB()\ngnb.fit(train_set,train_set_y)\ngnb_score = gnb.score(test_set, test_set_y)","bc974504":"## MLP\nparameters = {'solver': ['lbfgs','adam'], 'max_iter': [1500,2000], 'alpha': 10.0 ** -np.arange(2, 5), 'hidden_layer_sizes':np.arange(3,9)}\nMLP_gs = GridSearchCV(MLPClassifier(),parameters,cv=5)\nMLP_gs.fit(train_set,train_set_y)\nprint(MLP_gs.best_params_)","61706fff":"MLP_score = MLP_gs.score(test_set, test_set_y)","95250a1c":"SVM_parameters = {'kernel': ['rbf','sigmoid','linear'], 'gamma': 10.0 ** -np.arange(1, 7),'C': [0.001, 0.10, 0.1,1, 10, 25, 50, 100, 1000]}\nSVM_gs = GridSearchCV(svm.SVC(),SVM_parameters,cv=5)\nSVM_gs.fit(train_set,train_set_y)\nprint(SVM_gs.best_params_)","b1f422f6":"SVM_score = SVM_gs.score(test_set, test_set_y)","d523cf7e":"global_metrics = pd.DataFrame([{\"model\" : 'SVM' , \"score\" : SVM_score },{\"model\" : 'Logistic Regression' , \"score\" : lr_score },{\"model\" : 'Naive Bayesian' , \"score\" : gnb_score },\\\n                               {\"model\" : 'Neural Network' , \"score\" : MLP_score }])\n\nplt.figure(figsize=(7,7))\nsplot = sns.barplot(x=\"model\", y=\"score\",data=global_metrics)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.3f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')","2ac9e73e":"# Data exploratory analysis","d0f58c78":"as we can see, the age variable distribution is close to normal distribution, while others are skewed!","ebb0f97a":"let's print again every variable we have.","2112718a":"since our dataset is small, and from the cross tables, the previous variables don't give us any idea if they contribute in the heart failure or not since counts are close to each other.\n\nnow, let's check the relation of our target variable with *creatinine_phosphokinase*  , *ejection_fraction* and *serum_sodium*","037fb540":"from the ttest, sex doesn't really contribute on the levels of serum sodium.","83b1a495":"there's no correlation between age and the different variables we suspected their contribution.\nlet's see if sex is related.","5a126023":"## deep analysis\n\nwhat we will do now is to find relations between variables themselves.\n\nfirst we check if **serum creatinine** , **serum sodium** and **ejection fraction** are correlated.\n\nsecondly, we see if these variables are related to age, sex.\n\nfinally, we check if smoking, diabetes, high blood pressure or aneamia affect variables that we think they contribute in heart failure ( serum creatinine, serum sodium, ejection fraction).","cab415af":"based on the distributions,we conclude that those variables don't have any effect on our suspected variables.","6a84e867":"let's plot the values now.","82608711":"as we can see here, there are 0 and 1 as values. it's obvious that, for *anaemia*, *diabetes*, *high blood pressure* and *smoking* are boolean variables where 0 represents **FALSE\/NO** and 1 represents **TRUE\/YES**.\nfor the *sex* feature, 0 represents a **woman**, and 1 represents a **man**.\n\nlet's check the categories distribution using pies.","05db30f2":"now, lets explore our features.\n\n## float features \n \nwe first began with our float variables ( continous ones ) and draw histograms to know more about their distribution.","72ba6983":"now let's check other integer values that are not categorical.","b3ae6257":"# Summary\n\nwhat we concluded from our analysis is:\n\n- serum sodium, ejection fraction and serum creatinine may contribute to heart failure.\n- serum sodium levels can differ from man to woman\n\ntime to test these hypothesis:\n- dead people had significantly different levels of serum sodium, ejection fraction and serum creatinine.\n    H0 = means are equal for dead and alive people.\n- women & men have significantly different means of serum sodium.","d8a1631a":"from our plots, we see that **serum sodium** and **ejection fraction** distribution in both classes are quite different. maybe they are linked to the heart failure. we need to **test this hypothesis**\n\nlet's plot other float variables and check if there's a difference between dead and alive people.","b8eb3dc6":"let see each value of these features.","a1b93a5e":"as we see here, we have 2 groups of features.\nlets first see in detail every feature that has only 2 unique values.","3723eeaf":"let's start with diabetes, smoking, high blood pressure and anaemia.we check if they contribute to the heart failure.","747cc808":"after getting an idea about types in our dataset, we need to check missing values.\none way is to use a *heatmap* along with *isna()*","365968c1":"there's a slight difference between dead and alive people in the **serum creatinine**. we will test our hypothesis.","78eb2b77":"thanks to ttest, we confirmed that the 3 variables contribute in heart failure.\nlet's test our last hypothesis.","89668597":"we got an idea about every variable in our dataset. Now let's check the relationship between the target variable and other variables.\n\n## relation between target variable & other variables:\n\nfirst, we split our data into 2 groups ( based on the classes we have on the *target* variable ). so we will have 2 groups.","ea6167b9":"as we can see, there's a slight difference between dead man & woman when it comes to serum sodium. we need to **test** if sex has a relation with the level of that variable.","d9f7efe9":"## integer features\n\nlets explore our integer features.","32dece5e":"we have 299 rows and 12 features ( we exclude the **DEATH_EVENT** which is our target variable )\nnow, we need to check the types of our features. To do so, we use the dtype of pandas.","e8a8ba68":"what we're gonna do now is show the summary and the histogram for these variables.","e00315f6":"the heatmap and the previous table shows that there are no missing values.\n\nbased on the description of the dataset, time captures the time of the event. That is, the time at which the patient died or were censored which means that it won't be included as a feature in our analysis. no end user will be able to providethe value of time, since they do not know at what time in the future the patient will die\/get censored!","92a4cbf9":"first we check the target variable.\nthe name of our target variable is **DEATH_EVENT** and it has 2 classes, 1 for **DEAD** and 0 for **ALIVE**","a3686620":"## explore the target variable\n\nnow what we need to do is to exlore the target variable, know how many deaths caused by heart failure.","bbdb1413":"# Data preprocessing & training","556b39ea":"as we can see from the heatmap, variables are not collerated."}}