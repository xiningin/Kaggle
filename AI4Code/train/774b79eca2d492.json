{"cell_type":{"dae589cd":"code","4a7567c3":"code","3d7a4e34":"code","671bab11":"code","786b30c9":"code","752d4abb":"code","d6738592":"code","4cad852b":"code","e7a29663":"code","854e6be6":"code","8ed94161":"code","a05ff650":"code","83bc1229":"code","978a7654":"code","fed4ad21":"code","9b055733":"code","0d2b4a52":"code","8eb89e8d":"code","d8a27ddf":"code","d1ba5256":"code","a9f0f439":"code","c1008156":"code","7bad8d30":"markdown","b4bc68c4":"markdown","63ce1b27":"markdown","4712166c":"markdown","38a391ea":"markdown","828b0c64":"markdown","ce59aa5f":"markdown","3d7e92b5":"markdown","38349c0b":"markdown","599881ae":"markdown","78f175f2":"markdown","e465daab":"markdown"},"source":{"dae589cd":"%matplotlib inline\nimport json\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Tuple\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nplt.rcParams['figure.figsize'] = [18, 9]\nnp.random.seed(1)","4a7567c3":"fm_dataset = pd.read_csv(\"\/kaggle\/input\/football-manager-data\/dataset.csv\")\n","3d7a4e34":"fm_dataset.head()","671bab11":"print(fm_dataset.columns)","786b30c9":"# Almost 160k players\nprint(len(fm_dataset.Name))","752d4abb":"# 213 nations\nprint(len(np.unique(fm_dataset.NationID)))\nprint(np.unique(fm_dataset.NationID))","d6738592":"# Distribution of players per country\nfm_dataset.NationID[fm_dataset.NationID<100000].hist(bins=len(np.unique(fm_dataset.NationID)))","4cad852b":"# Distribution of players by age\nfm_dataset.Age.hist(bins=len(np.unique(fm_dataset.Age)))","e7a29663":"# Distribution of values suited for a striker\nfm_dataset.Striker.hist(bins=20)","854e6be6":"# Distribution of values suited for a left and right defender\n# There are more right than left defenders\nfig, ax = plt.subplots()\nbins = 20\n\na_heights, a_bins = np.histogram(fm_dataset.DefenderLeft, bins=20)\nb_heights, b_bins = np.histogram(fm_dataset.DefenderRight, bins=20)\n\nwidth = (a_bins[1] - a_bins[0])\/3\n\nax.bar(a_bins[:-1], a_heights, width=width, facecolor='cornflowerblue', label=\"Left defender\")\nax.bar(b_bins[:-1]+width, b_heights, width=width, facecolor='seagreen', label=\"Right defender\")\nfig.legend()","8ed94161":"features = ['Age', 'Height', 'Weight', 'AerialAbility', 'CommandOfArea',\n            'Communication', 'Eccentricity', 'Handling', 'Kicking',\n            'OneOnOnes', 'Reflexes', 'RushingOut', 'TendencyToPunch', 'Throwing',\n            'Corners', 'Crossing', 'Dribbling', 'Finishing', 'FirstTouch',\n            'Freekicks', 'Heading', 'LongShots', 'Longthrows', 'Marking', 'Passing',\n            'PenaltyTaking', 'Tackling', 'Technique', 'Aggression', 'Anticipation',\n            'Bravery', 'Composure', 'Concentration', 'Vision', 'Decisions',\n            'Determination', 'Flair', 'OffTheBall', 'Positioning',\n            'Teamwork', 'Workrate', 'Acceleration', 'Agility', 'Balance', 'Jumping',\n            'LeftFoot', 'NaturalFitness', 'Pace', 'RightFoot', 'Stamina',\n            'Strength']\n\nclassification_labels = ['Goalkeeper', 'Sweeper', 'Striker',\n                         'AttackingMidCentral', 'AttackingMidLeft', 'AttackingMidRight',\n                         'DefenderCentral', 'DefenderLeft', 'DefenderRight',\n                         'DefensiveMidfielder', 'MidfielderCentral', 'MidfielderLeft',\n                         'MidfielderRight', 'WingBackLeft', 'WingBackRight']\n\n\nfeatures = fm_dataset[features]\nclassification = fm_dataset[classification_labels]","a05ff650":"# Player can play in a position if its skill is >=15\nclassification[classification<15] = 0\nclassification[classification>=15] = 1","83bc1229":"def evaluate_predictions(labels: List[str], actual_values: np.ndarray, predictions: np.ndarray) -> Tuple[dict, float]:\n    \"\"\"Evaluate the predictions of the model.\n    \n    Returns a dictionary with the recall, precision and F1-score for each label\n    and the overall average F1-score.\n    \"\"\"\n    f1_scores = []\n    results = {}\n    for label, actual, pred in zip(labels, actual_values, predictions):\n        results[label] = {\"recall\": recall_score(actual, pred),\n                          \"precision\": precision_score(actual, pred),\n                          \"f1-score\": f1_score(actual, pred)}\n        f1_scores.append(f1_score(actual, pred))\n    return results, sum(f1_scores)\/len(f1_scores)","978a7654":"scaler = StandardScaler()\nkf = KFold(5)\n\n#classifier = KNeighborsClassifier()\nclassifier = RandomForestClassifier()\n\nall_train_y = None\nall_test_y = None\nall_train_predictions = None\nall_test_predictions = None\n\nfor train_index, test_index in kf.split(features):\n    \n    train_X, train_y = features.loc[train_index], classification.loc[train_index]\n    test_X, test_y = features.loc[test_index], classification.loc[test_index]\n    \n    train_X_scaled = scaler.fit_transform(train_X)\n    classifier.fit(train_X, train_y)\n    \n    train_predictions = classifier.predict(train_X)\n    test_predictions = classifier.predict(test_X)\n    \n    if all_test_y is None:\n        all_train_y = train_y.values.T\n        all_test_y = test_y.values.T\n        all_train_predictions = train_predictions.T\n        all_test_predictions = test_predictions.T\n    else:\n        all_train_y = np.hstack((all_train_y, train_y.values.T))\n        all_test_y = np.hstack((all_test_y, test_y.values.T))\n        all_train_predictions = np.hstack((all_train_predictions, train_predictions.T))\n        all_test_predictions = np.hstack((all_test_predictions, test_predictions.T))","fed4ad21":"train_results, train_mean_f1_score = evaluate_predictions(classification_labels, all_train_y, all_train_predictions)\ntest_results, test_mean_f1_score = evaluate_predictions(classification_labels, all_test_y, all_test_predictions)\nprint(f'Mean train F1-score: {train_mean_f1_score}')\nprint(f'Mean test F1-score: {test_mean_f1_score}')\n\nwith open(\"resultsRF.json\", \"w+\") as f:\n    json.dump(test_results, f, indent=4)\n\nnp.savetxt('predictionsRF.txt', all_test_predictions, fmt='%d')","9b055733":"scaler = StandardScaler()\nclassifier = RandomForestClassifier()\n\ntrain_X, train_y = features.values, classification.values\n\ntrain_X_scaled = scaler.fit_transform(train_X)\nclassifier.fit(train_X_scaled, train_y)\n\npickle.dump(classifier, open(\"RF.bin\", \"wb+\"))\npickle.dump(scaler, open(\"scaler.bin\", \"wb+\"))","0d2b4a52":"predictions = np.loadtxt('predictionsRF.txt', dtype=int)\nprint(predictions.shape)","8eb89e8d":"def position_to_text(position, labels):\n    \"\"\"\n    Convert a binary list of positions to text describing the position.\n    \"\"\"\n    positions_indexes = np.where(position == 1)[0]\n    predicted_position = [labels[index] for index in positions_indexes]\n    return predicted_position\n\npredicted_positions = [position_to_text(player, classification_labels) for player in predictions.T]\nfm_dataset['predicted_positions'] = predicted_positions","d8a27ddf":"players_name = [\"Cristiano Ronaldo\",\n                \"Lionel Messi\",\n                \"Sergio Ag\u00fcero\",\n                \"Talisca\",\n                \"Jonas\",\n                \"Sergio Ramos\",\n                \"Bojan\",\n                \"Casemiro\",\n                \"Iker Casillas\",\n                \"F\u00e1bio Coentr\u00e3o\",\n                \"Enzo P\u00e9rez\",\n                \"Rapha\u00ebl Guerreiro\",\n                \"Luis\u00e3o\",\n                \"Roberto\",\n                \"Pablo Aimar\",\n                \"Sebasti\u00e1n Coates\",\n                \"Xavi\",\n                \"Iniesta\",\n                \"Ricardo Quaresma\",\n                \"Giorgio Chiellini\",\n                \"Kak\u00e1\"]\n\nfor player_name in players_name:\n    print(player_name, fm_dataset.loc[fm_dataset['Name'] == player_name].predicted_positions.values[0])","d1ba5256":"# Load classifier and scaler\nclassifier = pickle.load(open(\"RF.bin\", \"rb\"))\nscaler = pickle.load(open(\"scaler.bin\", \"rb\"))","a9f0f439":"attributes = {\n\"Age\": 31,\n\"Height\": 186,\n\"Weight\": 84,\n\"AerialAbility\": 2,\n\"CommandOfArea\": 1,\n\"Communication\": 3,\n\"Eccentricity\": 1,\n\"Handling\": 3,\n\"Kicking\": 2,\n\"OneOnOnes\": 2,\n\"Reflexes\": 3,\n\"RushingOut\": 1,\n\"TendencyToPunch\": 3,\n\"Throwing\": 2,\n\"Corners\": 12,\n\"Crossing\": 14,\n\"Dribbling\": 15,\n\"Finishing\": 19,\n\"FirstTouch\": 16,\n\"Freekicks\": 14,\n\"Heading\": 18,\n\"LongShots\": 19,\n\"Longthrows\": 6,\n\"Marking\": 2,\n\"Passing\": 14,\n\"PenaltyTaking\": 19,\n\"Tackling\": 8,\n\"Technique\": 15,\n\"Aggression\": 6,\n\"Anticipation\": 17,\n\"Bravery\": 16,\n\"Composure\": 13,\n\"Concentration\": 16,\n\"Vision\": 13,\n\"Decisions\": 17,\n\"Determination\": 20,\n\"Flair\": 18,\n\"OffTheBall\": 18,\n\"Positioning\": 5,\n\"Teamwork\": 6,\n\"Workrate\": 7,\n\"Acceleration\": 13,\n\"Agility\": 12,\n\"Balance\": 13,\n\"Jumping\": 16,\n\"LeftFoot\": 15,\n\"NaturalFitness\": 19,\n\"Pace\": 17,\n\"RightFoot\": 20,\n\"Stamina\": 17,\n\"Strength\": 16\n}","c1008156":"feat = [[attributes[feature] for feature in features]]\nfeat = scaler.transform(feat)\nprediction = classifier.predict(feat)[0]\npredicted_positions = position_to_text(prediction, classification_labels)\npositions = \", \".join(predicted_positions) if len(predicted_positions) > 0 else \"No Predicted Positions.\"\nprint(positions)","7bad8d30":"What if we could change the attributes directly and see which positions the model predicts?\n\nIt could help us inspect model interpretability, as well as to understand what attributes are most important for each position. Let's do that!","b4bc68c4":"## Test different approaches with 5-fold cross-validation","63ce1b27":"First, we will calculate 5-fold cross-validation with K-Nearest Neighbors and with a Random Forest. You can tweak the hyper-parameters to try to improve the accuracy. We will also store the predictions for every player.\n\nIf you are training with all the data, it can take a while.","4712166c":"## Feature Selection","38a391ea":"Store the predictions and the metrics in a file.\n\nMean test F1-score for KNN: 59.63%.\n\nMean test F1-score for RF: 58.54%.\n\nThe results seem similar for both approaches, but Random Forest train time is faster.","828b0c64":"## Data Visualization","ce59aa5f":"The problem will be formulated as a multi-label classification problem, where it is possible for a player to be labeled with more than one position.","3d7e92b5":"The chosen approach to train with all data is the Random Forest (it is the faster and it has a mean F1-score almost as good as the KNN).","38349c0b":"## Predict the position of real players","599881ae":"## Train model with all data and save it","78f175f2":"Let's load the best predictions for all the players, and let's see which positions the algorithm predicted for each player.\n\nThis can be useful because it can give us insights about what players might actually play better in other positions, if trained to do so, based on their attributes.","e465daab":"## Which attributes are most important for each position?"}}