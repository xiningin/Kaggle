{"cell_type":{"f6385400":"code","b3a05888":"code","8e497099":"code","22bbb987":"code","33de13f6":"code","8d6397c1":"code","f01be94c":"code","68ac224e":"code","6aaa3aff":"code","b786029d":"code","d70e8720":"code","66afd9f0":"code","8ab4b6d9":"code","d3add6de":"code","22fd0b6b":"code","b0e9c1d1":"code","3158d164":"code","ee96af8c":"code","6cbe01cc":"code","afe20556":"code","9da82a06":"code","8c08bb56":"code","55a50c84":"code","1445cee8":"code","727e80f1":"code","cb9c362e":"code","0282597a":"code","201a00ac":"code","accbc8dd":"markdown","1daea691":"markdown"},"source":{"f6385400":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(322)","b3a05888":"from tqdm import tqdm_notebook","8e497099":"df_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","22bbb987":"df_train.head() # 784 features, 1 label","33de13f6":"df_features = df_train.iloc[:, 1:785]\ndf_label = df_train.iloc[:, 0]\n\nX_test = df_test.iloc[:, 0:784]\n\nprint(X_test.shape)\nprint(df_features.shape)\nprint(df_label.shape)","8d6397c1":"sample = df_features.sample(1)","f01be94c":"plt.figure()\nplt.imshow(sample.values.reshape(28,28), cmap='gray')\nplt.show()\n","68ac224e":"plt.figure()\nplt.imshow(df_features.mean(0).values.reshape(28,28), cmap='gray')\nplt.show()\n","6aaa3aff":"plt.figure()\nplt.imshow(df_features.std(0).values.reshape(28,28), cmap='gray')\nplt.show()","b786029d":"plt.figure()\nplt.imshow(df_features.max(0).values.reshape(28,28), cmap='gray')\nplt.show()","d70e8720":"# df_features\nmean_img = []\nfor i in range(10):\n    mean_img.append(df_features[df_label==i].mean(0))\n    \nfig, axs = plt.subplots(2, 5, figsize=(15,7))\nfig.suptitle('Vertically stacked subplots')\nfor i in range(2):\n    for j in range(5):\n        \n        item = mean_img[i*5+j]\n\n        axs[i,j].imshow(item.values.reshape(28,28), cmap='bwr')\n        axs[i,j].set_title('\u0426\u0438\u0444\u0440\u0430 '+str(i*5+j))\nplt.show()\n","66afd9f0":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nfrom torch.utils.data import Dataset, DataLoader","8ab4b6d9":"class MLP(nn.Module):\n    \n    def __init__(self, input_size):\n        super().__init__()\n        \n        self.layer = nn.Sequential(\n            \n            nn.Linear(input_size, 10),\n            \n        )\n        \n    def forward(self, x):\n        x = self.layer(x)\n        return x","d3add6de":"class MLPDataset(Dataset):\n    \n    def __init__(self, X, Y):\n        super().__init__()\n        self.X = X\n        self.Y = Y\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self, idx):\n        y = np.zeros(10)\n        y[self.Y[idx]] = 1\n        return self.X[idx], y ","22fd0b6b":"_dataset = MLPDataset(df_features.values, df_label.values)\ntrain_dataloader = DataLoader(dataset=_dataset, batch_size=128, shuffle=True)","b0e9c1d1":"\nmlp = MLP(input_size=784)\n\ncriterion = nn.BCEWithLogitsLoss()\n\nop = torch.optim.Adam(\n    \n    lr=0.00001,\n    params=mlp.parameters(),\n    \n    weight_decay=0.0001\n)","3158d164":"mlp.train()\n\ntorch.set_grad_enabled(True)\nif torch.cuda.is_available() :\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\nmlp.to(device)","ee96af8c":"epoch_count = 15\n\nmean_loss = []\nfor ep in range(epoch_count):\n    \n    for batch_id, (batch_x, batch_y) in enumerate(tqdm_notebook(train_dataloader)):\n        \n        batch_x = batch_x.to(device)\n        batch_y = batch_y.to(device)\n        \n        y_pred = mlp(batch_x.float())\n        \n        \n        loss = criterion(y_pred, batch_y.float())\n        \n        mean_loss.append(loss.detach().cpu().numpy())\n        \n        \n        loss.backward()\n        op.step()\n          \n        \n#         if not batch_id % 50:\n    print(ep, batch_id, np.mean(mean_loss))\n    mean_loss = []","6cbe01cc":"W, b = list(mlp.layer[0].parameters())\nweight = W.detach().cpu().numpy()","afe20556":"fig, axs = plt.subplots(2, 5, figsize=(15,7))\nfig.suptitle('Vertically stacked subplots')\nfor i in range(2):\n    for j in range(5):\n        \n        item = weight[i*5+j]\n\n        axs[i,j].imshow(item.reshape(28,28), cmap='bwr')\n        axs[i,j].set_title('\u0426\u0438\u0444\u0440\u0430 '+str(i*5+j))\nplt.show()\n","9da82a06":"class MLP2(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        \n        self.layer1 = nn.Sequential(\n            \n            nn.Linear(input_size, 32),\n            nn.Tanh(),\n            \n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Linear(32, 10),\n        )\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        return x","8c08bb56":"mlp2 = MLP2(input_size=784)\ncriterion = nn.BCEWithLogitsLoss()\nop =  torch.optim.Adam(\n    lr=0.00001,\n    params=mlp.parameters(),\n    weight_decay=0.0001\n)","55a50c84":"mlp2.train()\ntorch.set_grad_enabled(True)\nif torch.cuda.is_available() :\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\nmlp2.to(device)","1445cee8":"epoch_count = 3\n\nmean_loss = []\nfor ep in range(epoch_count):\n    \n    for batch_id, (batch_x, batch_y) in enumerate(tqdm_notebook(train_dataloader)):\n        \n        batch_x = batch_x.to(device)\n        batch_y = batch_y.to(device)\n        y_pred = mlp2(batch_x.float())\n        loss = criterion(y_pred, batch_y.float())\n        \n        mean_loss.append(loss.detach().cpu().numpy())\n        \n        loss.backward()\n        op.step()\n        \n    print(ep, batch_id, np.mean(mean_loss))\n    mean_loss = []","727e80f1":"W, b = list(mlp2.layer1[0].parameters())\nweight = W.detach().cpu().numpy()\noutlayer =  list(mlp2.layer2[0].parameters())[0].detach().cpu().numpy()","cb9c362e":"weight.shape","0282597a":"fig, axs = plt.subplots(4, 8, figsize=(15,7))\nfig.suptitle('Vertically stacked subplots')\nfor i in range(4):\n    for j in range(8):\n        item = weight[i*8+j]\n        axs[i,j].imshow(item.reshape(28,28), cmap='bwr')\nplt.show()\n","201a00ac":"plt.figure()\nplt.imshow(outlayer, cmap='bwr')\nplt.show()","accbc8dd":"Importing key libraries, and reading data","1daea691":"## Splitting into training and validation dataset"}}