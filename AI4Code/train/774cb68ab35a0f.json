{"cell_type":{"b59af3bc":"code","818e22e1":"code","8e81a84c":"code","4d4cffc9":"code","df54d6b7":"code","c35cfe82":"code","f96410bd":"code","bdb1a35e":"code","f81b6fc7":"code","0e315675":"code","335d1548":"code","a7649071":"code","50783bc3":"code","24353820":"code","e2d830b6":"code","6460acb1":"code","7475f91f":"code","7bcbbcf8":"markdown"},"source":{"b59af3bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","818e22e1":"!pip install pycaret","8e81a84c":"train = pd.read_csv(\"\/kaggle\/input\/train_fNxu4vz.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/test_fjtUOL8.csv\")","4d4cffc9":"\ntrain_id = train['Loan_ID']\ntrain = train.drop('Loan_ID',axis=1)\n\ntest_id = test['Loan_ID']\ntest = test.drop('Loan_ID',axis=1)","df54d6b7":"print('train ids', train_id)\nprint('test ids', test_id)","c35cfe82":"train.head()","f96410bd":"test.head()","bdb1a35e":"from pycaret.classification import *\n#intialize the setup\nclassifier =  setup(data = train, target = 'Interest_Rate',\n                    normalize = True)\n\n\n\n                 ","f81b6fc7":"\ncompare_models(turbo=True)","0e315675":"#tuned_lightgbm = tune_model('lightgbm')","335d1548":"\ntuned_cat = tune_model('catboost')","a7649071":"\n#tuned_et = tune_model('et')","50783bc3":"'''\net = create_model('et')\ncatboost = create_model('catboost')\nada = create_model('ada')\nridge = create_model('ridge')\nlightgbm = create_model('lightgbm')\n\n# stack trained models\nstacked_models = stack_models(estimator_list=[et,catboost,ada,ridge,lightgbm])\n'''","24353820":"\nfinal_model = finalize_model(tuned_cat)","e2d830b6":"pred = predict_model(final_model, data=test)","6460acb1":"submission = pd.DataFrame({'Loan_ID': test_id, 'Interest_Rate': pred['Label']})","7475f91f":"submission.to_csv('submission_pycaret.csv', index = False)","7bcbbcf8":"Have you ever wondered how lenders use various factors such as credit score, annual income, the loan amount approved, tenure, debt-to-income ratio etc. and select your interest rates? \n\nThe process, defined as \u2018risk-based pricing\u2019, uses a sophisticated algorithm that leverages different determining factors of a loan applicant. Selection of significant factors will help develop a prediction algorithm which can estimate loan interest rates based on clients\u2019 information. On one hand, knowing the factors will help consumers and borrowers to increase their credit worthiness and place themselves in a better position to negotiate for getting a lower interest rate. On the other hand, this will help lending companies to get an immediate fixed interest rate estimation based on clients information. Here, your goal is to use a training dataset to predict the loan rate category (1 \/ 2 \/ 3) that will be assigned to each loan in our test set.\n\nYou can use any combination of the features in the dataset to make your loan rate category predictions. Some features will be easier to use than others.\n\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-machine-learning-for-banking\/True\/#ProblemStatement"}}