{"cell_type":{"f3b3e65b":"code","ab5a574a":"code","017d4420":"code","8f4b173e":"code","aaa04581":"code","f3ec66cc":"code","6d062b9f":"code","03200d36":"code","d6bfa62b":"code","70c34256":"code","feb2acba":"code","1d434f4f":"markdown","ab59f273":"markdown","fbfc8352":"markdown","853077cf":"markdown","13be14b8":"markdown","de3f7fea":"markdown","8252eec7":"markdown","b3de1063":"markdown","c13841de":"markdown"},"source":{"f3b3e65b":"!pip install -U sentence-transformers","ab5a574a":"import numpy as np\nimport pandas as pd\nimport scipy as sc\n\nimport os\nimport json\nimport warnings\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\nimport time\n\nt = time.time()\nelapsed = time.time() - t\n\nclass Timer(object):\n    def __init__(self, name=None):\n        self.name = name\n\n    def __enter__(self):\n        self.tstart = time.time()\n\n    def __exit__(self, type, value, traceback):\n        if self.name:\n            print('[%s]' % self.name,)\n        print('Elapsed: %s' % (time.time() - self.tstart))\n        \nwarnings.filterwarnings(\"ignore\")\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')","017d4420":"question_embedding = model.encode(['What do we know about virus genetics, origin, and evolution?'])\n\nqueries = ['What is known about transmission, incubation, and environmental stability?', 'What do we know about COVID-19 risk factors?', \n           'What do we know about virus genetics, origin, and evolution?', 'What do we know about vaccines and therapeutics?',\n           'Are there geographic variations in the rate of COVID-19 spread?', 'Are there geographic variations in the mortality rate of COVID-19?',\n           'Is there any evidence to suggest geographic based virus mutations?','What do we know about diagnostics and surveillance?',\n           'What do we know about non-pharmaceutical interventions?','What has been published about medical care?',\n           'What has been published about ethical and social science considerations?', 'What has been published about information sharing and inter-sectoral collaboration?']\n\nquery_embeddings = model.encode(queries)","8f4b173e":"count = 0\nfile_exts = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        count += 1\n        file_ext = filename.split(\".\")[-1]\n        file_exts.append(file_ext)\n\nfile_ext_set = set(file_exts)\nfile_ext_list = list(file_ext_set)\n\ncount = 0\nfor root, folders, filenames in os.walk('\/kaggle\/input'):\n    print(root, folders)\n    \njson_folder_path = \"\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/pdf_json\"\njson_file_name = os.listdir(json_folder_path)[0]\njson_path = os.path.join(json_folder_path, json_file_name)\n\nwith open(json_path) as json_file:\n    json_data = json.load(json_file)\n    \njson_data_df = pd.io.json.json_normalize(json_data)","aaa04581":"from tqdm import tqdm\n\n# to process all files, uncomment the next line and comment the line below\n#list_of_files = list(os.listdir(json_folder_path))\nlist_of_files = list(os.listdir(json_folder_path))[0:100]\ncomm_use_subset_df = pd.DataFrame()\n\nfor file in tqdm(list_of_files):\n    json_path = os.path.join(json_folder_path, file)\n    with open(json_path) as json_file:\n        json_data = json.load(json_file)\n    json_data_df = pd.io.json.json_normalize(json_data)\n    comm_use_subset_df = comm_use_subset_df.append(json_data_df)","f3ec66cc":"comm_use_subset_df","6d062b9f":"comm_use_subset_df['abstract_text'] = comm_use_subset_df['abstract'].apply(lambda x: x[0]['text'] if x else \"\")\ncomm_use_subset_df['abstract_text_cleaned'] = comm_use_subset_df['abstract_text'].str.replace('\\d+', 'XXX')\ncomm_use_subset_df.reset_index(drop = True, inplace = True)","03200d36":"with Timer('abstract_cleaned embeddings'):   \n    abstract_embeddings = model.encode(comm_use_subset_df['abstract_text_cleaned'])","d6bfa62b":"# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\nclosest_n = 5\nfor query, query_embedding in zip(queries, query_embeddings):\n    distances = sc.spatial.distance.cdist([query_embedding], abstract_embeddings, \"cosine\")[0]\n\n    results = zip(range(len(distances)), distances)\n    results = sorted(results, key=lambda x: x[1])\n\n    print(\"\\n\\n======================\\n\\n\")\n    print(\"Query:\", query)\n    print(\"\\nTop 5 most similar sentences in corpus:\")\n\n    for idx, distance in results[0:closest_n]:\n        print(comm_use_subset_df['abstract_cleaned'][idx].strip(), \"\\n(Score: %.4f)\" % (1-distance),\"\\n\")","70c34256":"question_abstract = []\nbert_scores = []\n\nfor abstract_embedding, abstract_text in zip(abstract_embeddings, comm_use_subset_df['abstract_text']):\n    bert_score = cosine_similarity([question_embedding[0], abstract_embedding])[1][0]\n    question_abstract.append(bert_score)\n","feb2acba":"print(\"Index of the document: \", question_abstract.index(max(question_abstract)), \"\\nAbstract of the document: \", comm_use_subset_df['abstract_text'].ix[question_abstract.index(max(question_abstract))],\n     \"\\nBert Similarity between the question and the document: \", max(question_abstract))","1d434f4f":"# Bert Embedding\nBert Embedding of the text data cleaned.\n\n![](https:\/\/cdn.drawception.com\/drawings\/915760\/b8Taco5fmM.png)","ab59f273":"# Parser - Cleaning\nIn order to use the text data, we have to parse it and clean it.","fbfc8352":"# Bert Score for several questions","853077cf":"# Input - Questions or keywords\nIn this part of the notebook, you have to put the question or the keywords related to the topic that you want to identify through the research papers. Example with the second task of the challenge.","13be14b8":"# Results","de3f7fea":"I get just 1000 research papers, but in this folder you can find more than 9k research papers. Of course, it is too long to get all of them through the notebook.","8252eec7":"<h1> COVID-19 - Search Engine with Bert Score <\/h1>\n\n![](https:\/\/cdn.drawception.com\/drawings\/661287\/54Z1tooqg4.png)\n\nThis notebook is inspired by CORD-19 Solution Toolbox released by Gabriel Preda. Thanks for sharing!\n\nThe goal is really simple! We want to find the articles who talk about a specific topics. The idea of this notebook is to provide to the community the possiiblity to put in input a question, a topic (defined by keywords or sentences) or just keywords and use BERT to vectorize the input, vectorize the abstract of the articles and compare the similarity between them. Like that you can identify one or more articles who are a strong similarity (With cosinus similarity).\n\n# 1. Import & install the packages needed\n* \nWe have to install a package in order use BERT but for sentences. For that I use the package sentence transformers. Here you can find more informations: https:\/\/github.com\/UKPLab\/sentence-transformers. I am not here to explain BERT or Cosinu Similarity. You can find a lot of information about these topics. I want to stay pragmatic and give the possibility to re-use this notebook for other project.","b3de1063":"# Get the data\nThe part about the collect was developped by Gabriel Preda. Thanks for sharing again :)! There too much data in this challenge. In order to show you how to use the search engine, I will use it just in a subset of the data in the folder comm_use_subset.","c13841de":"# Bert Score for a specific question\nThe Bert Score computed is the cosinus similarity between the Bert Embedding of the input and the abstract text cleaned."}}