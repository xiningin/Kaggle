{"cell_type":{"afe2f975":"code","233e2f43":"code","0a8faf6e":"code","a49bb796":"code","8f718e87":"code","41445e85":"code","b5035050":"code","f73e3c1c":"code","9473ed4b":"code","973275c8":"code","c6599619":"code","599e60a2":"code","874cd844":"code","cbc3eea8":"code","33aea020":"code","c1afecf7":"code","33f5bea9":"code","eedcffc8":"code","a6c718c8":"code","de67a0b8":"code","9d981abe":"code","152e81a9":"code","e3b4b2c1":"code","02af461b":"code","7b43742d":"code","da248cc1":"code","cd98c0cb":"code","16959636":"code","3e0581ea":"code","53fdaad4":"code","7e1077f9":"code","ffaa6fb4":"code","48585d5b":"code","86ff5530":"code","b074854f":"code","a5e54aa9":"code","1515bc4a":"code","7820ed23":"code","2aa94ec1":"code","f7bf80fc":"code","873fa3a3":"code","4ebfe922":"code","98da327b":"code","7b691880":"code","ce817084":"code","c670d070":"code","53936e34":"code","a9493879":"code","dd947fc6":"code","54cc9e48":"code","26f65b3d":"markdown","5a66ced5":"markdown","bd3c3684":"markdown","2a27f3db":"markdown","cda18c0f":"markdown","d8cf6c04":"markdown","bef79620":"markdown","930ceb35":"markdown","f6c6974e":"markdown","ed2b035f":"markdown","c003ee92":"markdown","770e09eb":"markdown","bd7266aa":"markdown","efcf7d7b":"markdown","cbb1fd90":"markdown","89b7b90b":"markdown","e60d64b3":"markdown","06a0a240":"markdown","1b08c146":"markdown","1d183257":"markdown","1a509083":"markdown","a8dc7b53":"markdown","d67d553f":"markdown","d9580ba6":"markdown","99438e89":"markdown","ef9ffe3e":"markdown","e1856193":"markdown","87932a97":"markdown","32e3aea6":"markdown","7b872c21":"markdown","abc8cbfb":"markdown","af55f6e9":"markdown","270a36b4":"markdown","c5c075dc":"markdown","89b600fd":"markdown","4161cb19":"markdown","3ba87be5":"markdown","8bc85c19":"markdown","fe5d60cb":"markdown","910cbf98":"markdown","f4d74f78":"markdown","f8f871c4":"markdown","c8c6e6d7":"markdown","e36b81f7":"markdown"},"source":{"afe2f975":"#import necessary modules\nimport pandas as pd\n\nlife_data = pd.read_csv(\"..\/input\/life-expectancy-who\/Life Expectancy Data.csv\")\n","233e2f43":"life_data.head()          #View top 5 rows","0a8faf6e":"#Lets look at the columns\nlife_data.columns","a49bb796":"#Remove Leading spaces : use lstrip() method\nlife_data.columns =  [names.lstrip() for names in life_data.columns]\n\n#Remove Trailing spaces : use lstrip() method\nlife_data.columns =  [names.rstrip() for names in life_data.columns]\n\n#Capliatize column name, making them consistent\n\nlife_data.columns = [names.capitalize() for names in life_data.columns]","8f718e87":"#Lets view our Columns\nlife_data.columns","41445e85":"life_data.info()","b5035050":"life_data.rename(columns={'thinness_1-19_years':'thinness_10-19_years'}, inplace=True)","f73e3c1c":"life_data.describe()","9473ed4b":"#import \n%matplotlib inline    \n\nimport matplotlib.pyplot as plt\n","973275c8":"#creating histogram for each numeric attribute\nlife_data.hist(bins = 50,\n               figsize = (20,15))\nplt.show()","c6599619":"life_data[\"Country\"].value_counts()","599e60a2":"life_data[\"Status\"].value_counts()","874cd844":"#Copy the test data\nlife_copy = life_data.copy()","cbc3eea8":"plt.figure(figsize=(15,10))\n\nfor i,column in enumerate(['Adult mortality', 'Infant deaths', 'Bmi', 'Under-five deaths', 'Gdp', 'Population'],start=1):\n    plt.subplot(2, 3,i)\n    life_copy.boxplot(column)","33aea020":"#import\nimport numpy as np","c1afecf7":"#Adult mortality rates lower than the 5th percentile\nmortality_less_5_per = np.percentile(life_copy[\"Adult mortality\"].dropna(),5) \nlife_copy[\"Adult mortality\"] = life_copy.apply(lambda x: np.nan if x[\"Adult mortality\"] < mortality_less_5_per else x[\"Adult mortality\"], axis=1)\n","33f5bea9":"#Remove Infant deaths of 0\nlife_copy[\"Infant deaths\"] = life_copy[\"Infant deaths\"].replace(0,np.nan)","eedcffc8":"#Remove the invalid BMI\nlife_copy[\"Bmi\"] =life_copy.apply(lambda x : np.nan if (x[\"Bmi\"] <10 or x[\"Bmi\"] >50) else x[\"Bmi\"],axis =1)","a6c718c8":"#Remove Under five deaths\nlife_copy[\"Under-five deaths\"] =life_copy[\"Under-five deaths\"].replace(0,np.nan)","de67a0b8":"def count_null(df):\n    df_cols = list(df.columns)\n    cols_total_count = len(df_cols)\n    cols_count = 0\n    \n    for loc,col in enumerate(df_cols):\n        null_count = df[col].isnull().sum()                                  #total null values\n        total_count = df[col].isnull().count()                               #Total rows\n        percent_null = round(null_count\/total_count*100, 2)                  #Percentage null \n      \n        if null_count > 0:\n            cols_count += 1\n            print('[iloc = {}] {} has {} null values: {}% null'.format(loc, col, null_count, percent_null))\n    \n    cols_percent_null = round(cols_count\/cols_total_count*100, 2)\n    print('Out of {} total columns, {} contain null values; {}% columns contain null values.'.format(cols_total_count, cols_count, cols_percent_null))","9d981abe":"count_null(life_copy)","152e81a9":"life_copy.drop(columns='Bmi', inplace=True)","e3b4b2c1":"imputed_data = []\n\nfor year in list(life_copy.Year.unique()):\n    year_data = life_copy[life_copy.Year == year].copy()\n    \n    for col in list(year_data.columns)[3:]:\n        year_data[col] = year_data[col].fillna(year_data[col].dropna().mean()).copy()\n\n    imputed_data.append(year_data)\ndf = pd.concat(imputed_data).copy()","02af461b":"count_null(df)","7b43742d":"life_numeric_data = df.drop(columns=[\"Year\",\"Country\",\"Status\"])","da248cc1":"%matplotlib inline\n\ndef plot_numeric_data(data):\n    i = 0\n    for col in data.columns:\n        i += 1\n        plt.subplot(9, 4, i)\n        plt.boxplot(data[col])\n        plt.title('{} boxplot'.format(col))\n        i += 1\n        plt.subplot(9, 4, i)\n        plt.hist(data[col])\n        plt.title('{} histogram'.format(col))\n        \n    plt.show()\n","cd98c0cb":"plt.figure(figsize=(15,40))\nplot_numeric_data(life_numeric_data)","16959636":"def outlier_count(col, data=df):\n    \n    print(\"\\n\"+15*'-' + col + 15*'-'+\"\\n\")\n    \n    q75, q25 = np.percentile(data[col], [75, 25])\n    iqr = q75 - q25\n    min_val = q25 - (iqr*1.5)\n    max_val = q75 + (iqr*1.5)\n    outlier_count = len(np.where((data[col] > max_val) | (data[col] < min_val))[0])\n    outlier_percent = round(outlier_count\/len(data[col])*100, 2)\n    print('Number of outliers: {}'.format(outlier_count))\n    print('Percent of data that is outlier: {}%'.format(outlier_percent))","3e0581ea":"cont_vars = list(life_numeric_data)\nfor col in cont_vars:\n    outlier_count(col)","53fdaad4":"from scipy.stats.mstats import winsorize\n\ndef test_wins(col, lower_limit=0, upper_limit=0, show_plot=True):\n    wins_data = winsorize(df[col], limits=(lower_limit, upper_limit))\n    wins_dict[col] = wins_data\n    if show_plot == True:\n        plt.figure(figsize=(15,5))\n        plt.subplot(121)\n        plt.boxplot(df[col])\n        plt.title('original {}'.format(col))\n        plt.subplot(122)\n        plt.boxplot(wins_data)\n        plt.title('wins=({},{}) {}'.format(lower_limit, upper_limit, col))\n        plt.show()","7e1077f9":"wins_dict = {}\ntest_wins(cont_vars[0], lower_limit=.01, show_plot=True)\ntest_wins(cont_vars[1], upper_limit=.04, show_plot=False)\ntest_wins(cont_vars[2], upper_limit=.05, show_plot=False)\ntest_wins(cont_vars[3], upper_limit=.0025, show_plot=False)\ntest_wins(cont_vars[4], upper_limit=.135, show_plot=False)\ntest_wins(cont_vars[5], lower_limit=.1, show_plot=False)\ntest_wins(cont_vars[6], upper_limit=.19, show_plot=False)\ntest_wins(cont_vars[7], upper_limit=.05, show_plot=False)\ntest_wins(cont_vars[8], lower_limit=.1, show_plot=False)\ntest_wins(cont_vars[9], upper_limit=.02, show_plot=False)\ntest_wins(cont_vars[10], lower_limit=.105, show_plot=False)\ntest_wins(cont_vars[11], upper_limit=.185, show_plot=False)\ntest_wins(cont_vars[12], upper_limit=.105, show_plot=False)\ntest_wins(cont_vars[13], upper_limit=.07, show_plot=False)\ntest_wins(cont_vars[14], upper_limit=.035, show_plot=False)\ntest_wins(cont_vars[15], upper_limit=.035, show_plot=False)\ntest_wins(cont_vars[16], lower_limit=.05, show_plot=False)\ntest_wins(cont_vars[17], lower_limit=.025, upper_limit=.005, show_plot=False)","ffaa6fb4":"plt.figure(figsize=(15,5))\n\nfor i, col in enumerate(cont_vars, 1):\n    plt.subplot(2, 9, i)\n    plt.boxplot(wins_dict[col])\n\n    plt.tight_layout()\nplt.show()","48585d5b":"#A new dataframe with the winsorized data \nwins_df = df.iloc[:, 0:3]\nfor col in cont_vars:\n    wins_df[col] = wins_dict[col]","86ff5530":"dataset = wins_df.drop(columns= [\"Year\",\"Country\"],axis = True)","b074854f":"#Dealing with Categorical data","a5e54aa9":"status = pd.get_dummies(dataset.Status)\ndataset = pd.concat([dataset, status], axis = 1)\ndataset= dataset.drop(['Status'], axis=1)","1515bc4a":"dataset.columns","7820ed23":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(dataset.drop(columns = [\"Life expectancy\"],axis = 1),\n                                                 dataset[\"Life expectancy\"],\n                                                 test_size = 0.2,\n                                                 random_state = 42)","2aa94ec1":"from sklearn.preprocessing import StandardScaler\nstd_scaler = StandardScaler()\nX_train_scaled = std_scaler.fit_transform(X_train)\n","f7bf80fc":"#import necessary modules\nfrom sklearn.linear_model import LinearRegression\n\nlinear_regressor = LinearRegression()\n\nlinear_regressor.fit(X_train_scaled,y_train)\n","873fa3a3":"from sklearn.metrics import r2_score\n\n#Make predictions\ny_pred = linear_regressor.predict(X_train_scaled)\n\n#Calculating RMSE\nlinear_r2_score = r2_score(y_train,y_pred)\n\nprint(linear_r2_score)","4ebfe922":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer\nscoring = make_scorer(r2_score)\n\nlinear_scores = cross_val_score(linear_regressor,X_train_scaled,y_train,\n                       scoring = scoring,cv=10)\nlinear_scores","98da327b":"#import necessary modules\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\n\ntree_reg.fit(X_train_scaled,y_train)\n","7b691880":"#Make predictions\ny_pred = tree_reg.predict(X_train_scaled)\n\n#Calculating RMSE\ntree_r2_score = r2_score(y_train,y_pred)\n\nprint(tree_r2_score)","ce817084":"from sklearn.metrics import make_scorer\nscoring = make_scorer(r2_score)\nscores = cross_val_score(tree_reg,X_train_scaled,y_train,\n                       scoring = scoring,cv=10)\n","c670d070":"scores","53936e34":"#RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer\nsocre = make_scorer(\"r2_score\")\nforest_reg = RandomForestRegressor()\n\nforest_reg.fit(X_train_scaled,y_train)\n\n","a9493879":"#Make predictions\ny_pred = forest_reg.predict(X_train_scaled)\n#Calculating RMSE\nforest_r2_score = r2_score(y_train,y_pred)\n\nprint(forest_r2_score)","dd947fc6":"forest_score = cross_val_score(forest_reg, X_train_scaled,y_train,\n                              scoring=scoring,cv=10)\n\nforest_score","54cc9e48":"X_test_scaled = std_scaler.fit_transform(X_test)\ny_pred = forest_reg.predict(X_test_scaled)\n\n#Calculating RMSE\ntree_r2_score = r2_score(y_test,y_pred)\n\nprint(\"R^2 score: %.2f\"%tree_r2_score)","26f65b3d":"#### Conclusions:\n* All these attributes are in different scales. Feature scaling is needed.\n* Many histogram are tail heavily i.e. left skewed. So we need to convert them to a bell-shaped distribution.\n* Diphtheria is right skewed. So we need to convert it to a bell shaped-distribution.","5a66ced5":"All the variables have now been winsorized as little as possible in order to keep as much data in tact as possible while still being able to eliminate the outliers. Finally, small boxplots will be shown for each variable's winsorized data to show that the outliers have indeed been dealt with.","bd3c3684":"Things that may not make sense from above:\n\n* Adult mortality of 1? This is likely an error in measurement, but what values make sense here? May need to change to null if under a certain threshold.\n* Infant deaths as low as 0 per 1000? That just isn't plausible - I'm deeming those values to actually be null. Also on the other end 1800 is likely an outlier, but it is possible in a country with very high birthrates and perhaps a not very high population total - this can be dealt with later.\n* BMI of 1 and 87.3? Pretty sure the whole population would not exist if that were the case. A BMI of 15 or lower is seriously underweight and a BMI of 40 or higher is morbidly obese, therefore a large number of these measurements just seem unrealistic...this variable might not be worth digging into at all.\n* Under Five Deaths, similar to infant deaths just isn't likely (perhaps even impossible) to have values at zero.\n* GDP per capita as low as 1.68 (USD) possible? Doubtful - but perhaps values this low are outliers.\n* Population of 34 for an entire country? Hmm...","2a27f3db":"### 2.Get the Data","cda18c0f":"### Better Evaluation Using Cross-Validation","d8cf6c04":"Dataset used : https:\/\/www.kaggle.com\/kumarajarshi\/life-expectancy-who","bef79620":"First a boxplot and histogram will be created for each continuous variable in order to visually see if outliers exist.","930ceb35":"### 1. Frame the problem and look at the big picture.\n","f6c6974e":"### Train the model using Decision Tree Classifier\n#### [OVERFITTING]","ed2b035f":"### Better Evaluation Using Cross-Validation","c003ee92":"## Train the model using Linear Regression\n#### [UNDERFITTING]","770e09eb":"Since each variable has a unique amount of outliers and also has outliers on different sides of the data, the best route to take is probably winsorizing (limiting) the values for each variable on its own until no outliers remain. The function below allows me to do exactly that by going variable by variable with the ability to use a lower limit and\/or upper limit for winsorization. By default the function will show two boxplots side by side for the variable (one boxplot of the original data, and one with the winsorized change). Once a satisfactory limit is found (by visual analysis), the winsorized data will be saved in the wins_dict dictionary so the data can easily be accessed later.","bd7266aa":"Note that the standard deviation of the features Infant deaths, Percentage Expenditure , Measles, Under five deaths,GDP,Population is a lot higher than the mean(more than twice). \n\nThis implies that the data is not centered around its mean and are more spread out. Or we can say there is large variation in the data ranging from min-max.","efcf7d7b":"The info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute\u2019s type and number of non-null values","cbb1fd90":"Lets Plot the histogram of each attribute to get more insight of the data","89b7b90b":"Since the column names are inconsistent as some names start with capital letters and some names begins with spaces. Lets make the column name consistent by removing the leading and trailing spaces","e60d64b3":"### Take a Quick Look at the Data Structure","06a0a240":"After making above transformations the missing values must have increased. Following function will count for issing values in the dataset.","1b08c146":"The describe() method shows a summary of the numerical attributes","1d183257":"### Better Evaluation Using Cross-Validation\n","1a509083":"There are 2,934 instances in the dataset, which means that it is fairly small by Machine Learning standards, but it\u2019s perfect to get started.\n\nNotice that there are missing values in Life Expentancy(our target variable),Adult mortailty, Alcohol,Hepatitis B, Bmi,Gdp Diphtheria,Hiv\/aids, Population,Thinness  1-19 years,\nThinness 5-9 years, Income composition of resource, Schooling\n","a8dc7b53":"It is clearly a typical supervised learning task since you are given labeled training examples (each instance comes with the expected output, i.e., Life Expentancy).\n\nMoreover, it is also a typical regression task, since you are asked to predict a value. More specifically, this is a multivariate regression problem since the system will use multiple features to make a prediction (it will use the Adult Mortality,Population,Income composition of resources etc.).\n\nFinally, there is no continuous flow of data coming in the system, there is no particular need to adjust to changing data rapidly, and the data is small enough to fit in memory, so plain batch learning should do just fine.","d67d553f":"Clearly the Decicion Tree Regressor is Overfitting the data. Lets check the cross validation scores","d9580ba6":"#### Checking for outlier\nBest way to plot a box-plot","99438e89":"## Refrences\n\nDataset used : https:\/\/www.kaggle.com\/kumarajarshi\/life-expectancy-who\n\nExploratory Data Analysis : https:\/\/www.kaggle.com\/philbowman212\/life-expectancy-exploratory-data-analysis","ef9ffe3e":"Lets look at our categorical attributes","e1856193":"#### Drop irrelevant features","87932a97":"### EDA: Data Cleaning","32e3aea6":"Your next step is to select a performance measure. A typical performance measure for regression problems is the R2_Score.","7b872c21":"### Outliers Detection","abc8cbfb":"### Lets Split the data into training and test data","af55f6e9":"> ## Evaluate Your System on the Test Set","270a36b4":"There are a few of the above that could simply be outliers, but there are some that almost certainly have to be errors of some sort. Of the above variables, changes to null will be made for the following since these numbers don't make any sense:\n\n* Adult mortality rates lower than the 5th percentile\n* Infant deaths of 0\n* BMI less than 10 and greater than 50\n* Under Five deaths of 0","c5c075dc":"### Select a Performance Measure","89b600fd":"### Feature Scaling ","4161cb19":"#### Dealing with missing values","3ba87be5":"Nearly half of the BMI variable's values are null, it is likely best to remove this variable altogether.","8bc85c19":"As stated above it would be useful to change the name of the variable thinness_1-19_years to thinness_10-19_years as it is a more accurate depiction of what the variable means.","fe5d60cb":"###### Lets deal with the Missing values\nAlright, so it looks like there are a lot of columns containing null values, since this is time series data assorted by country, the best course of action would be to interpolate the data by country. However, when attempting to interpolate by country it doesn't fill in any values as the countries' data for all the null values are null for each year, therefore imputation by year may be the best possible method here. Imputation of each year's mean is done below.","910cbf98":"Lets replace these values with NULL","f4d74f78":"Visually, it is plain to see that there are a number of outliers for all of these variables - including the target variable, life expectancy. The same will be done statistically using Tukey's method below - outliers being considered anything outside of 1.5 times the IQR.","f8f871c4":"# Train the model using Random Forest Classifier\n#### [Prefect Fit]","c8c6e6d7":"Earlier there were 10 missing values (for Life Expectancy feature) in our total dataset. But there are only 2 in our training set. This means our testing data consists of a lot missing values for the variable to be predicted. We will take careof this later.","e36b81f7":" The data contains 21 columns and 2938 rows with the header row. The table contains data about:\n* country (Nominal) - the country in which the indicators are from (i.e. United States of America or Congo)\n* year (Ordinal) - the calendar year the indicators are from (ranging from 2000 to 2015)\n* status (Nominal) - whether a country is considered to be 'Developing' or 'Developed' by WHO standards\n* life_expectancy (Ratio) - the life expectancy of people in years for a particular country and year\n* adult_mortality (Ratio) - the adult mortality rate per 1000 population (i.e. number of people dying between 15 and 60 years per 1000 population); if the rate is 263 then that means 263 people will die out of 1000 between the ages of 15 and 60; another way to think of this is that the chance an individual will die between 15 and 60 is 26.3%\n* infant_deaths (Ratio) - number of infant deaths per 1000 population; similar to above, but for infants\n* alcohol (Ratio) - a country's alcohol consumption rate measured as liters of pure alcohol consumption per capita\n* percentage_expenditure (Ratio) - expenditure on health as a percentage of Gross Domestic Product (gdp)\n* hepatitis_b (Ratio) - number of 1 year olds with Hepatitis B immunization over all 1 year olds in population\n* measles (Ratio) - number of reported Measles cases per 1000 population\n* bmi (Interval\/Ordinal) - average Body Mass Index (BMI) of a country's total population\n* under-five_deaths (Ratio) - number of people under the age of five deaths per 1000 population\n* polio (Ratio) - number of 1 year olds with Polio immunization over the number of all 1 year olds in population\n* total_expenditure (Ratio) - government expenditure on health as a percentage of total government expenditure\n* diphtheria (Ratio) - Diphtheria tetanus toxoid and pertussis (DTP3) immunization rate of 1 year olds\n* hiv\/aids (Ratio) - deaths per 1000 live births caused by HIV\/AIDS for people under 5; number of people under 5 who die due to HIV\/AIDS per 1000 births\n* gdp (Ratio) - Gross Domestic Product per capita\n* population (Ratio) - population of a country\n* thinness_1-19_years (Ratio) - rate of thinness among people aged 10-19 (Note: variable should be renamed to thinness_10-19_years to more accurately represent the variable)\n* thinness_5-9_years (Ratio) - rate of thinness among people aged 5-9\n* income_composition_of_resources (Ratio) - Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n* schooling (Ratio) - average number of years of schooling of a population\n\nWith the exclution of Country name and Status(either developed or developing) all of the data is numeric. The values are either in years, precentages, millions or dollars in the case of Gross Domestic Product (GDP)"}}