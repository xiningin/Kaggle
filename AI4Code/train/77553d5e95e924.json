{"cell_type":{"0f7fc979":"code","25f00aac":"code","6f629907":"code","b28ed720":"code","46f083d2":"code","fed50fa9":"code","dd9e04aa":"code","a85285d3":"code","5d271ec3":"code","1bf9cbe0":"code","0adb3fa4":"code","30024444":"code","be053bc3":"code","e70f02ef":"code","bfac0b35":"code","5f129493":"code","c1ce8ba7":"markdown","ff2a7bb1":"markdown"},"source":{"0f7fc979":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\nfrom sklearn.metrics import mean_squared_error","25f00aac":"\n# Original code from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16 or not. feather format does not support float16.\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","6f629907":"%%time\nroot = Path('..\/input\/ashrae-feather-format-for-fast-loading')\n\ntrain_df = pd.read_feather(root\/'train.feather')\ntest_df = pd.read_feather(root\/'test.feather')\n#weather_train_df = pd.read_feather(root\/'weather_train.feather')\n#weather_test_df = pd.read_feather(root\/'weather_test.feather')\nbuilding_meta_df = pd.read_feather(root\/'building_metadata.feather')","b28ed720":"# i'm now using my leak data station kernel to shortcut.\nleak_df = pd.read_feather('..\/input\/ashrae-leak-data-station\/leak.feather')\n\nleak_df.fillna(0, inplace=True)\nleak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\nleak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 # remove large negative values\nleak_df = leak_df[leak_df.building_id!=245]\nlead_site_id_0 = leak_df[leak_df['meter']==0]","46f083d2":"sample_submission3 = pd.read_csv(\"..\/input\/ashrae-final-submission\/fe2_lgbm_tz.csv\", index_col=0)\nsample_submission2 = pd.read_csv(\"..\/input\/ashrae-final-submission\/submission.csv\", index_col=0)\nsample_submission1 = pd.read_csv(\"..\/input\/ashrae-final-submission\/submission_final_day.csv\", index_col=0)","fed50fa9":"test_df['pred1'] = sample_submission1.meter_reading\ntest_df['pred2'] = sample_submission2.meter_reading\ntest_df['pred3'] = sample_submission3.meter_reading\n\n\ndel  sample_submission1,  sample_submission2,  sample_submission3\ngc.collect()\n\ntest_df = reduce_mem_usage(test_df)\nleak_df = reduce_mem_usage(leak_df)","dd9e04aa":"leak_df = leak_df.merge(test_df[['building_id', 'meter', 'timestamp', 'pred1', 'pred2', 'pred3','row_id']], left_on = ['building_id', 'meter', 'timestamp'], right_on = ['building_id', 'meter', 'timestamp'], how = \"left\")\nleak_df = leak_df.merge(building_meta_df[['building_id', 'site_id']], on='building_id', how='left')","a85285d3":"leak_df['pred1_l1p'] = np.log1p(leak_df.pred1)\nleak_df['pred2_l1p'] = np.log1p(leak_df.pred2)\nleak_df['pred3_l1p'] = np.log1p(leak_df.pred3)\nleak_df['meter_reading_l1p'] = np.log1p(leak_df.meter_reading)","5d271ec3":"v = 0.1 * leak_df['pred1'].values + 0.6 * leak_df['pred2'].values + 0.2 * leak_df['pred3'].values\nvl1p = np.log1p(v)\ncurr_score = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))   \nprint(curr_score)","1bf9cbe0":"sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\n\n# extract best combination\n#final_combi = filtered_combis[best_combi[0][0]]\nw1 = 0.1#final_combi[0]\nw2 = 0.6#final_combi[1]\nw3 = 0.2#final_combi[2]\nprint(\"The weights are: w1=\" + str(w1) + \", w2=\" + str(w2) + \", w3=\" + str(w3))\n\nsample_submission['meter_reading'] = w1 * test_df.pred1 +  w2 * test_df.pred2  + w3 * test_df.pred3\nsample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0","0adb3fa4":"sample_submission.head()","30024444":"#sns.distplot(np.log1p(sample_submission.meter_reading))","be053bc3":"leak_df = leak_df[['meter_reading', 'row_id']].set_index('row_id').dropna()\nsample_submission.loc[leak_df.index, 'meter_reading'] = leak_df['meter_reading']","e70f02ef":"#sns.distplot(np.log1p(sample_submission.meter_reading))","bfac0b35":"sample_submission.head()","5f129493":"sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')","c1ce8ba7":"# Submit","ff2a7bb1":"# Future Work\n\n- Increase the range of weights\n- Vary tolerance for sum of weights (currently tol = 0.95)"}}