{"cell_type":{"653730b1":"code","aa24c7cc":"code","d9a4e0d9":"code","b9ea0ae1":"code","4bf977b8":"code","30ed8e55":"code","7fcf9b29":"code","e48e6b92":"code","2370b02c":"code","ebef87e5":"code","3e0966a0":"code","d7891d6a":"code","ce121845":"code","f6d32182":"code","fc9c1579":"code","d9a98133":"code","32efd333":"code","1cf22d9c":"code","bf3ff3cd":"code","9dcb49f3":"code","7287424a":"code","a32ad841":"code","4516e20f":"code","5ce2cbae":"code","643a1968":"code","cdae3f0f":"code","72cc45bd":"code","e18fc438":"code","bb5ac1a4":"code","e41e8bdc":"code","96507a81":"code","6489dc43":"code","6942aa4e":"code","9f17926a":"code","ce875e8b":"code","624b02d0":"code","8ea93585":"code","a7975f30":"code","48ceaeaf":"code","12547c98":"code","23ac8bd6":"code","d6f9a691":"code","c7473f40":"code","9f0e6ff3":"code","97c339a2":"code","61e6a4e3":"code","d387d2b8":"code","c0e8e1cb":"code","7b930afe":"code","1c2f1a7e":"code","577b4748":"code","9cb0ced8":"code","df996d74":"code","1bd8feab":"code","8e5255b3":"code","8f90245c":"code","c5c83a44":"code","6442fb85":"code","28d121be":"code","ba83e828":"code","6caab823":"code","2b1c5a1b":"code","79f58651":"code","77e6accf":"code","56a00347":"code","953fce56":"code","ed7c0b25":"code","9f22d62e":"code","00119a35":"code","b032ca26":"code","05488309":"code","716a7a23":"code","ebec2a32":"code","fa42475a":"code","d1acf72f":"markdown","ffc53ce8":"markdown","bb439bbc":"markdown","6179c3e6":"markdown","0bde2acb":"markdown","a0d46099":"markdown","1a55d125":"markdown","871c6342":"markdown","ba18fd97":"markdown","08897e94":"markdown","22620fc9":"markdown","68dc77cf":"markdown","b70fe01b":"markdown","e781ed1e":"markdown","67d748f8":"markdown","921e36d3":"markdown","6ef4129c":"markdown","a44c0a34":"markdown","653c5a31":"markdown","2af3940e":"markdown","c26dd1b5":"markdown","0d232224":"markdown","7196b25a":"markdown","bab11410":"markdown","3fea9116":"markdown","66fe5dee":"markdown","dce4e72f":"markdown","1b65a1b3":"markdown","2984fa6b":"markdown","d673e3f5":"markdown","4cc41157":"markdown","e0e1e188":"markdown","f322b028":"markdown","d5bec5ba":"markdown","5a0b0e4a":"markdown","497bf785":"markdown","cda1636d":"markdown"},"source":{"653730b1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.compose import TransformedTargetRegressor\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import HuberRegressor, LinearRegression\nfrom sklearn import metrics","aa24c7cc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d9a4e0d9":"dataset = pd.read_csv('\/kaggle\/input\/movies\/movies.csv',encoding='latin1')\ndataset.sample(50)","b9ea0ae1":"dataset.info()","4bf977b8":"dataset_fs = dataset.drop(['name','score','gross', 'votes'],axis=1)\ndataset_fs.info()","30ed8e55":"dataset_fs['released'] = pd.to_datetime(dataset_fs['released'])\ndataset_fs['released']=(dataset_fs['released'].dt.month).astype('object')","7fcf9b29":"dataset_fs.info()","e48e6b92":"dataset_fs[dataset_fs['budget']==0.0]= np.nan\ndataset_fs=dataset_fs.dropna()","2370b02c":"dataset_fs.sample(10)","ebef87e5":"plt.figure(figsize=(10,7))\nsns.heatmap(dataset_fs.corr(),annot=True)","3e0966a0":"sns.pairplot(dataset_fs[['budget','runtime','year']])","d7891d6a":"dataset_fs['budget'].plot(kind='box')","ce121845":"def exclui_outliers(DataFrame, col_name):\n  Q1 = DataFrame[col_name].quantile(.25)\n  Q3 = DataFrame[col_name].quantile(.75)\n  IIQ =Q3 -Q1\n  limite_inf = Q1 -1.5*IIQ\n  limite_sup = Q3 +1.5*IIQ\n  \n  return DataFrame[(DataFrame[col_name]>=limite_inf) & (DataFrame[col_name]<=limite_sup)]","f6d32182":"#dataset_fs = exclui_outliers(dataset_fs, 'budget')\n#dataset_fs['budget'].plot(kind='box')","fc9c1579":"def group_low_freq_cats(DataFrame, col_name, threshold=0.01, name='others'):\n  df = DataFrame.copy()\n  cat_freq = df[col_name].value_counts()\n  cat_low_freq = cat_freq[cat_freq\/cat_freq.sum() <= threshold].index\n  df.loc[df[col_name].isin(cat_low_freq),col_name]='others'\n  return df","d9a98133":"def val_couts_cols (Dataframe,cols):\n  for x in cols:\n    print('coluna: {0}, categorias: {1}'.format(x,len(Dataframe[x].value_counts())))\n  print('Total samples: ' + str(len(Dataframe)))","32efd333":"def feature_selection(Dataset, feature, target ,in_out, method='na'): \n  fs_score =[]\n  oe = OrdinalEncoder()\n\n  X = (np.array(Dataset[feature])).reshape(-1,1)\n  oe.fit(X)\n  X_enc = oe.transform(X)\n\n  y = np.array(Dataset[target]).reshape(-1,1)\n  oe.fit(y)\n  y_enc = oe.transform(y)\n  \n  if in_out == 'cat_cat': \n    if method == 'chi2':\n      fs = SelectKBest(score_func=chi2, k='all') \n    else:\n      fs = SelectKBest(score_func=mutual_info_classif, k='all')\n    fs.fit(X_enc, y_enc)\n    fs_score = fs.scores_\n  elif in_out == 'num_num':\n    fs = SelectKBest(score_func=f_regression, k='all')\n    fs.fit(X, y.ravel())\n    fs_score = fs.scores_\n  elif in_out == 'num_cat':\n    fs = SelectKBest(score_func=f_classif, k='all')\n    fs.fit(X, y_enc)\n    fs_score = fs.scores_\n  elif in_out == 'cat_num':\n    fs = SelectKBest(score_func=f_classif, k='all')\n    fs.fit(X_enc, y.ravel())\n    fs_score = fs.scores_\n  else:\n    fs_score=[]\n\n  return fs_score","1cf22d9c":"def get_col_type(df,col_type):\n  cols_types=df.dtypes.reset_index()\n  cols_types.columns=['col','type']\n  cols_type = cols_types.apply(lambda x: x['col'] if x['type']==col_type else np.nan ,axis=1)\n  return cols_type.dropna()","bf3ff3cd":"def boxplot_by_col(df,cat_cols,target):\n  fig, ax = plt.subplots(len(cat_cols), 1, figsize=(25, 18))\n  fig.subplots_adjust()\n  t=0\n  for var, subplot in zip(cat_cols, ax.flatten()):\n      ax[t].set_xlabel(var,fontsize=18)\n      sort_qtl_index = df.groupby(var)[target].quantile(0.5).sort_values().index\n      sort_qtl_values = df.groupby(var)[target].quantile(0.5).sort_values()\n      sns.boxplot(x=var, y=target, data=df, ax=subplot,order=sort_qtl_index)\n      sns.pointplot(x=sort_qtl_index,y= sort_qtl_values,ax=subplot,color='r')\n      t+=1    \n  plt.tight_layout(pad=3) ","9dcb49f3":"def remove_incoherence(DataFrame,expression, replace_val, columns=[]):\n  if len(columns)==0:\n    columns = DataFrame.columns\n  \n  DataFrame_aux=DataFrame.copy()\n  \n  if str(replace_val) == str(np.nan):\n    DataFrame_aux=DataFrame.replace(expression, replace_val, regex=True) # n\u00e3o usar str.replace pois n\u00e3o aceita np.nan\n    return DataFrame_aux\n  else: \n    for col in columns:\n      i=0\n      while (True): # quando trabalhamos com grupos no regex, ele n\u00e3o \u00e9 capaz de substituir todos os grupos, ent\u00e3o \u00e9 necessario iterar a cada nova substitui\u00e7\u00e3o\n        DataFrame_aux[col]=DataFrame[col].str.replace(expression, replace_val, regex=True)\n        #warnings.filterwarnings('ignore','UserWarning') # para evitar warning quando str.contains chamar expressions contendo groups que n\u00e3o ser\u00e3o utilizados\n        num_matchs = len(DataFrame_aux[DataFrame_aux[col].str.contains(expression, na=False)])#  verifica se regex funcionou, caso sim retorna 0, sen\u00e3o retorna o numero de matchs\n        DataFrame = DataFrame_aux\n        \n        if num_matchs == 0:\n            break\n        if i == 100:\n            DataFrame_aux =pd.DataFrame([])\n            break\n        i+=1\n    return DataFrame_aux","7287424a":"cat_cols = get_col_type(dataset_fs, 'object')\ncat_cols","a32ad841":"val_couts_cols(dataset_fs,cat_cols)","4516e20f":"fs_scores =[]\nfor x in cat_cols:\n  fs_score = feature_selection(dataset_fs, x, 'budget','cat_num')\n  print('coluna: {0}, fs_score: {1}'.format(x,fs_score))\n  fs_scores.append(fs_score)","5ce2cbae":"np.mean(fs_scores)","643a1968":"dataset_fs['company'].value_counts()","cdae3f0f":"#(group_low_freq(dataset_fs,'company',threshold=0.005))['company'].value_counts()\ndataset_fs = group_low_freq_cats(dataset_fs,'company',threshold=0.005) # group categories that represent less than 0.5% of the data set in a single 'outhers' category\ndataset_fs['company'].value_counts()","72cc45bd":"feature_selection(dataset_fs, 'company', 'budget','cat_num')","e18fc438":"dataset_fs['director'].value_counts()","bb5ac1a4":"(group_low_freq_cats(dataset_fs,'director',threshold=0.005))['director'].value_counts()","e41e8bdc":"dataset_fs=dataset_fs.drop('director',axis=1)","96507a81":"dataset_fs['star'].value_counts()","6489dc43":"(group_low_freq_cats(dataset_fs,'star',threshold=0.005))['star'].value_counts()","6942aa4e":"dataset_fs=dataset_fs.drop('star',axis=1)","9f17926a":"(group_low_freq_cats(dataset_fs,'writer',threshold=0.005))['writer'].value_counts()","ce875e8b":"dataset_fs=dataset_fs.drop('writer',axis=1)","624b02d0":"dataset_fs=remove_incoherence(dataset_fs,r'UNRATED|NOT RATED|Not specified', 'Others', columns=['rating'])","8ea93585":"cat_cols = get_col_type(dataset_fs, 'object')\ncat_cols","a7975f30":"val_couts_cols(dataset_fs,cat_cols)","48ceaeaf":"boxplot_by_col(dataset_fs,cat_cols,'budget')","12547c98":"dataset_fs['company'].unique()","23ac8bd6":"df =dataset_fs.copy()\ndf= df[(df['company']=='Universal Pictures') & (dataset_fs['genre']=='Comedy') ]\nsns.scatterplot(x=df['year'],y=df['budget'],hue=df['company'])","d6f9a691":"dataset_fs['country'].unique()","c7473f40":"df =dataset_fs.copy()\ndf= dataset_fs[(dataset_fs['country']=='USA') & (dataset_fs['company']=='Walt Disney Pictures') ]\nsns.scatterplot(x=df['year'],y=df['budget'],hue=df['company'])","9f0e6ff3":"df =dataset_fs.copy()\ndf= dataset_fs[(dataset_fs['country']=='USA') & (dataset_fs['company']=='Warner Bros.') ]\nsns.scatterplot(x=df['year'],y=df['budget'],hue=df['company'])","97c339a2":"dataset_fs['genre'].unique()","61e6a4e3":"df =dataset_fs.copy()\ndf= dataset_fs[(dataset_fs['genre']=='Action') & (dataset_fs['rating']=='PG-13')]\nsns.scatterplot(x=df['runtime'],y=df['budget'],hue=df['rating'])","d387d2b8":"df =dataset_fs.copy()\ndf= dataset_fs[(dataset_fs['genre']=='Biography') & (dataset_fs['rating']=='R') ]\nsns.scatterplot(x=df['runtime'],y=df['budget'],hue=df['rating'])","c0e8e1cb":"dataset_fs_f=dataset_fs.copy()","7b930afe":"#as noted in the previous analysis, a significant improvement in the R2 score was expected when dropping this feature\ndataset_fs_f = dataset_fs_f.drop(['country'],axis=1) ","1c2f1a7e":"company_dummies = pd.get_dummies(dataset_fs_f['company'],drop_first=True)\ndataset_fs_f=pd.concat([dataset_fs_f.drop('company',axis=1),company_dummies],axis=1)","577b4748":"genre_dummies = pd.get_dummies(dataset_fs_f['genre'],drop_first=True)\ndataset_fs_f=pd.concat([dataset_fs_f.drop('genre',axis=1),genre_dummies],axis=1)","9cb0ced8":"rating_dummies = pd.get_dummies(dataset_fs_f['rating'],drop_first=True)\ndataset_fs_f=pd.concat([dataset_fs_f.drop('rating',axis=1),rating_dummies],axis=1)","df996d74":"month_dummies = pd.get_dummies(dataset_fs_f['released'],drop_first=True)\ndataset_fs_f=pd.concat([dataset_fs_f.drop('released',axis=1),month_dummies],axis=1)","1bd8feab":"dataset_fs_f.info()","8e5255b3":"X = dataset_fs_f.drop('budget',axis=1).values\nX.shape","8f90245c":"dataset_fs_f.info()","c5c83a44":"y = dataset_fs_f['budget'].values\ny.shape","6442fb85":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=31, test_size=0.20)","28d121be":"def plot_hists_scatters(*args,cols=['none'],type_plot='scatter',target=[]):\n  \n  if np.array_equal(target,[]) & (type_plot  == 'scatter'):\n    print('No target')\n  elif len(args)==1:\n    if type_plot  == 'scatter':\n      plt.title(cols[0],fontsize=18)\n      sns.scatterplot(x=args[0],y=target)\n    else:\n      plt.title(cols[0],fontsize=18)\n      sns.histplot(args[0])\n  else:\n    fig, ax = plt.subplots(1, len(args), figsize=(10, 4))\n    t=0\n    for arg, subplot in zip(args,ax.flatten()):  \n      if type_plot == 'hist':\n        if len(cols) == 1:\n          ax[t].set_title(cols[0],fontsize=18)\n        else:\n          ax[t].set_title(cols[t],fontsize=18)\n        sns.histplot(arg, ax=subplot)\n      else:\n        if len(cols) == 1:\n          ax[t].set_title(cols[0],fontsize=18)\n        else:\n          ax[t].set_title(cols[t],fontsize=18)\n        sns.scatterplot(x=arg,y=target, ax=subplot)\n      t+=1\n    plt.tight_layout(pad=3) ","ba83e828":"norm_box = PowerTransformer(method='box-cox') #runtime feture transformation\nX_train[:,0]= norm_box.fit_transform(X_train[:,0].reshape(-1, 1)).ravel() \nX_test[:,0] = norm_box.transform(X_test[:,0].reshape(-1, 1)).ravel()","6caab823":"plot_hists_scatters(X_train[:,0],X_test[:,0],type_plot='hist',cols=['runtime (train)', 'runtime (test)'])","2b1c5a1b":"regr = TransformedTargetRegressor(regressor=LinearRegression(),transformer=PowerTransformer(method='yeo-johnson')) \nregr.fit(X_train,y_train)","79f58651":"#regr = TransformedTargetRegressor(regressor=HuberRegressor(),transformer=PowerTransformer())\n#regr.fit(X_train,y_train)","77e6accf":"#from tensorflow.keras.models import Sequential\n#from tensorflow.keras.layers import Input,Dense,Dropout","56a00347":"'''def r_square(y_true, y_pred):\n    from keras import backend as K\n    SS_res =  K.sum(K.square(y_true - y_pred)) \n    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n    return ( 1 - SS_res\/(SS_tot + K.epsilon()) ) '''","953fce56":"'''model = Sequential()\nmodel.add(Input((X.shape[1],)))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam',loss='mse',metrics=['mae',r_square])'''","ed7c0b25":"#model.fit(x=X_train,y=y_train, validation_data=(X_test,y_test),epochs=100 )\n#losses = pd.DataFrame(model.history.history)","9f22d62e":"#losses.plot(y=['mae','val_mae'])","00119a35":"#losses.plot(y=['r_square'])","b032ca26":"#losses.tail(1)","05488309":"# from sklearn.ensemble import GradientBoostingRegressor","716a7a23":"#regr = TransformedTargetRegressor(regressor=GradientBoostingRegressor(),transformer=PowerTransformer(method='yeo-johnson')) # Melhor performance, utilizando Transforma\u00e7\u00e3o \n#regr.fit(X_train,y_train)","ebec2a32":"y_pred = regr.predict(X_test)\nmae = metrics.mean_absolute_error(y_test, y_pred)\n\nprint('R2_score train: ',regr.score(X_train,y_train))\nprint('R2_score test: ', regr.score(X_test,y_test))\nprint('MAE:', mae)","fa42475a":"result = pd.DataFrame([y_test,y_pred.astype('f')]).T\nresult.columns=['Test','Predicted']\nresult.head(4)","d1acf72f":"* Company\n\n\n","ffc53ce8":"Even if restricted by other features, for the most frequent category (USA), the data remains very dispersed, if this feature impairs the performance of the model it will be eliminated.","bb439bbc":"# 6- Results","6179c3e6":"Basically a constant in the 'others' category and will be eliminated","0bde2acb":"### Count categories by feature","a0d46099":"## 2.2- Eliminating records with budget equal to '0'","1a55d125":"As you can see, there is a well-defined correlation between runtime x budget when we isolate these features from genre and rating.","871c6342":"### Functions","ba18fd97":"### Graphically analyzing categorical feature x target distribution","08897e94":"# 2- EDA (Exploratory Data Analysis) and Data Wrangling \n\n","22620fc9":"* Genre","68dc77cf":"### Frequency analysis for features with high cardinality","b70fe01b":"### Obtaining categorical features","e781ed1e":"We can observe a slight variation in relation to the medians of these features x target, \npossibly these features positively affect features with heteroscedastic distribution. Let's analyze:","67d748f8":"Basically a constant in the 'others' category and will be eliminated","921e36d3":"Basically a constant in the 'others' category and will be eliminated","6ef4129c":"## 6.1- Metrics","a44c0a34":"# 5- Training\n \n\n\n","653c5a31":"## 5.2- Deep Learning (keras) - low results","2af3940e":"## 2.4- Treating outliers with IIQ (because it is a very aggressive method and it ended up damaging the model and will be treated with a Yeo-Johnson and box-cox transformation)\n","c26dd1b5":"* Country","0d232224":"## 2.1- Eliminating irrelevant features by empirical inference\n\n*   The name is information that obviously has no influence on the budget\n*   The score, votes and gross are information that cannot be obtained for future predictions\n*   'Released' is a date containing year, month and day, the year can explain some trend as well as the month of production. Let's delete the year and day of the feature realease and keep only the month.\n\n\n\n\n\n\n\n\n\n\n\n","7196b25a":"## 5.1- Linear regression with yeo-johnson transformation of target (sklearn) - Best result","bab11410":"# Goal: \n\nPredict the planned cost (budget) based on the characteristics of the production ('company','country','director','genre','runtime', 'year','rating','star','writer')","3fea9116":"## 2.3- Checking linear correlation of numeric features","66fe5dee":"### Excluding feature rating inconsistencies","dce4e72f":"Conclusion: Basically all invoices with fs_score below the average were eliminated (except for countries that already had a low number of categories)","1b65a1b3":"As you can see, there is a correlation (with some level of dispersion) between year x budget when we isolate these features from other features like company and genre.","2984fa6b":"## 2.6- Dummies for categorical features","d673e3f5":"The reduction of categories did not change the fs_score.","4cc41157":"# 3- Spliting Dataset train\/test\n\n","e0e1e188":"## 2.5- Checking strength of association between numeric target and categorical features","f322b028":"### Association strength feature x target (ANOVA F-value)","d5bec5ba":"# 4- 'box-cox' transformation (features)\n\nTransformation of the data based on the training data and the parameters of this distribution are applied in the test","5a0b0e4a":"## 6.2- Conclusion\n\nEliminating categorical features with low strength of association with the target, as well as numerical features of low correlation in addition to data transformation, an R2 score of 0.55 (test) was obtained, which is a reasonable value considering the points below.\n\nPossible points for improvement:\n\n- As we are considering the budget and not the realized one, the target data is data that does not reflect the actual spending of the project and is possibly inserting a lot of noise (estimates with a certain degree of randomness since it was 'kicked' by the budgeter). \n\n- Obtain other features with greater association strength or high correlation with target.","497bf785":"\n## Gradient Boosting Regressor with yeo-johnson transformation of target (sklearn) - Result slightly less than linear regression","cda1636d":"It is possible to verify a positive average trend line for budget x runtime and budget x year which has a heteroscedastic distribution. These features can be better absorbed by the model from others features (interaction effects). After the grouping of low frequency categories for high cardinality features (item 2.5), we will be able to validate better.\n\n The budget and runtime distribution needs to undergo a transformation to fit a normal symmetrical curve and treat autliers more efficiently. We will do this after the split of the training and test base to avoid data leaking, where the target distribution will be treated with a Yeo-Johnson transformation and the feature runtime with a box-cox transformation."}}