{"cell_type":{"459f1ca7":"code","3e91c62d":"code","84dbd4b0":"code","0e9755f6":"code","546090e2":"code","9ad786e0":"code","15b6139e":"code","45d6cf53":"code","61c78927":"code","c6fe61a2":"code","2f190a46":"code","46392bf7":"markdown","6e7123c6":"markdown","84eff3ce":"markdown","983d0247":"markdown","e1a35a75":"markdown","cc850645":"markdown","0c669ede":"markdown","32dd7b10":"markdown","a13e04ea":"markdown","44f86801":"markdown"},"source":{"459f1ca7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#json\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nfrom gensim.models.doc2vec import Doc2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom tqdm import tqdm\nfrom collections import Counter\nimport re\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport random\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import NearestNeighbors","3e91c62d":"def create_taggedDocument_from_json(dataInd,fileId):\n    \n    filename = \"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/\" + dataInd + \"\/\" + fileId + \".json\"\n    \n    fd = open(filename, mode='r')\n    data = json.load(fd)\n    fd.close()\n    json_text = ''\n    for sections in data:\n        json_text = json_text + ' ' + sections.get('text')\n    \n    json_text = json_text.replace('\\\\n',' ').replace('\\\\f',' ').replace('\\\\u','!!!').replace('\\\\b',' ').replace('\\\\t',' ').replace('\\\\',' ')\n    json_text = re.sub('!{3}[A-Za-z0-9]{4}',' ',json_text)\n    json_text= re.sub('r[^\\w\\s]',' ',json_text)\n    \n    textWordlist = nltk.word_tokenize(json_text)\n\n    #STOPWORD\u306a\u3057\n    #return TaggedDocument(words=textWordlist, tags=[fileId])\n\n    #STOPWORD\u3042\u308a\n    stopWords = stopwords.words('english') + \\\n    ['\"','{', '}', '[', ']', '(',')',  ',', ':', '``', \"''\", ';', '.']\n    \n    wordlist = [snowball.stem(word.lower()) for word in textWordlist if word.lower() not in stopWords]\n    return TaggedDocument(words=wordlist, tags=[fileId])","84dbd4b0":"sample_submission_df = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\")\ntrain_df = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv\")","0e9755f6":"snowball = SnowballStemmer(language='english')","546090e2":"# \u7a7a\u306e\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\uff08\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u306a\u308b\u5404\u6587\u66f8\u3092\u683c\u7d0d\uff09\ntraining_docs = []\n\ndistinct_train_df = train_df.drop_duplicates(subset=[\"Id\"])\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u8fbc\u307f\nfor Id in distinct_train_df[\"Id\"]:\n    training_docs.append(create_taggedDocument_from_json(\"train\", Id))\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u8fbc\u307f\nfor Id in sample_submission_df[\"Id\"]:\n    training_docs.append(create_taggedDocument_from_json(\"test\", Id))\n\n# \u5b66\u7fd2\u5b9f\u884c\uff08\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u53ef\u80fd\uff09\n# documents:\u5b66\u7fd2\u30c7\u30fc\u30bf\uff08TaggedDocument\u306e\u30ea\u30b9\u30c8\uff09\n# min_count=1:\u6700\u4f4e1\u56de\u51fa\u73fe\u3057\u305f\u5358\u8a9e\u3092\u5b66\u7fd2\u306b\u4f7f\u7528\u3059\u308b\n# dm=0:\u5b66\u7fd2\u30e2\u30c7\u30eb=DBOW\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\u306fdm=1:\u5b66\u7fd2\u30e2\u30c7\u30eb=DM\uff09\nmodel = Doc2Vec(documents=training_docs, \n                vector_size=200, \n                alpha=0.0025, \n                min_alpha=0.000001, \n                window=15, \n                min_count=1, \n                dm=1)","9ad786e0":"#Doc2Vec\u304b\u3089\u30d9\u30af\u30c8\u30eb\u3092\u7279\u5fb4\u91cf\u3068\u3057\u3066\u62bd\u51fa\ntrain_docvecs_df = pd.DataFrame()\nsubmit_docvecs_df = pd.DataFrame()\n\n\nfor Id in distinct_train_df[\"Id\"]:\n    train_docvecs_df[Id] = model.docvecs[Id]\nfor Id in sample_submission_df[\"Id\"]:\n    submit_docvecs_df[Id] = model.docvecs[Id]\n\ntrain_docvecs_df = train_docvecs_df.T\ntrain_docvecs_df = train_docvecs_df.rename_axis('Id').reset_index()\ntrain_docvecs_df = train_docvecs_df.sort_values('Id')\ntrain_docvecs_df = train_docvecs_df.drop(\"Id\", axis=1)\n\nsubmit_docvecs_df = submit_docvecs_df.T\nsubmit_docvecs_df = submit_docvecs_df.rename_axis('Id').reset_index()","15b6139e":"#\u30e9\u30d9\u30eb\u3092\u4f5c\u6210\nlabel_df = pd.DataFrame(train_df['Id'])\nwork_df = pd.get_dummies(train_df['cleaned_label']) \nlabel_list = list(work_df.columns)\nlabel_df = pd.concat([label_df, work_df], axis=1)\nlabel_df = label_df.groupby(by=['Id']).sum()\nlabel_df = label_df.sort_values('Id')","45d6cf53":"# \u63d0\u51fa\u7528\u30c7\u30fc\u30bf\u4f5c\u6210\nmy_submission = pd.DataFrame(submit_docvecs_df['Id'])\nmy_submission['PredictionString'] = ''","61c78927":"for label in label_list:\n    print(label)\n    temp_label_df = pd.DataFrame()\n    temp_label_df[label] = label_df[label]\n    \n    #\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\n    positive_count_train = temp_label_df.sum()\n    ros = RandomOverSampler(random_state=71)\n    X_res, y_res = ros.fit_resample(train_docvecs_df.reset_index().drop('index', axis=1), temp_label_df.reset_index().drop('Id', axis=1))\n    \n    \n    #\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5206\u5272\n    train_X, val_X, train_y, val_y = train_test_split(X_res, y_res, test_size = 0.3, random_state=71)\n\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u751f\u6210\u3059\u308b\n    lgb_train = lgb.Dataset(train_X.values, train_y[label].values)\n    lgb_eval = lgb.Dataset(val_X.values, val_y[label].values, reference=lgb_train)\n\n    # LightGBM \u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\n    params = {\n        # \u4e8c\u5024\u5206\u985e\u554f\u984c\n        'objective': 'binary',\n        # AUC \u306e\u6700\u5927\u5316\u3092\u76ee\u6307\u3059\n        'metric': 'auc',\n        # Fatal \u306e\u5834\u5408\u51fa\u529b\n        'verbosity': -1,\n    }\n\n    # \u4e0a\u8a18\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3059\u308b\n    model = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n                      verbose_eval=50,  # 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                      num_boost_round=1000,  # \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                      early_stopping_rounds=100\n                     )\n\n    # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c\u3059\u308b\n    y_pred = model.predict(val_X.values, num_iteration=model.best_iteration)\n\n    fpr, tpr, thresholds = metrics.roc_curve(val_y[label].values, y_pred)\n    auc = metrics.auc(fpr, tpr)\n    print(auc)\n\n    temp_df = submit_docvecs_df.drop('Id', axis=1)\n    predicted = model.predict(temp_df.values, num_iteration=model.best_iteration)\n    predicted = np.round(predicted)\n    predicted_list = ['|' + label if i > 0 else '' for i in predicted]    \n    my_submission['tempString'] = predicted_list\n    my_submission['PredictionString'] = my_submission['PredictionString'] + my_submission['tempString']\n    my_submission = my_submission.drop('tempString', axis=1)","c6fe61a2":"# you could use any filename. We choose submission here\nmy_submission['PredictionString'] = my_submission['PredictionString'].str[1:]\nmy_submission.to_csv('submission.csv', index=False)","2f190a46":"my_submission.head()","46392bf7":"### Create label","6e7123c6":"### Submit","84eff3ce":"### Train Doc2Vec Model","983d0247":"### Import module","e1a35a75":"### Extract document vector","cc850645":"### read CSV File","0c669ede":"### create TaggedDocument from Json File","32dd7b10":"### Initialize the data for submission","a13e04ea":"### Train LGB Model & Predict","44f86801":"## Doc2Vec & LightGBM"}}