{"cell_type":{"5f1f898b":"code","9aec0d55":"code","fc20d9a7":"code","89b17ad5":"code","9b720ab1":"code","c2e5866e":"code","bd647682":"code","0b0b3131":"code","77c4abce":"code","72bab6ee":"code","59e9eeee":"code","ceb09dc6":"code","980cffc4":"code","b25af87f":"code","b872b365":"code","2c4af368":"code","5e1f0ad9":"code","7d468f60":"code","ecb31ddc":"code","6291b239":"code","6b7fd317":"code","a859e245":"code","e51a52bf":"code","df90fe16":"markdown","314f6c5f":"markdown","dd497686":"markdown","b74e129b":"markdown","0526e509":"markdown","e796680b":"markdown","928022e2":"markdown","885e80a6":"markdown"},"source":{"5f1f898b":"!which python # should return \/usr\/local\/bin\/python\n!python --version","9aec0d55":"!echo $PYTHONPATH # returns \/env\/python","fc20d9a7":"# unset PYTHONPATH to prevent problems later\n%env PYTHONPATH= ","89b17ad5":"# To verify the Miniconda installation\n!conda --version # now returns 4.10.3\n!python --version # now returns Python 3.6.13 :: Anaconda, Inc.","9b720ab1":"import sys\nprint(sys.path)","c2e5866e":"import sys\nsys.path.append(\"\/kaggle\/working\/chaii-packages\")","bd647682":"%%bash\nmkdir \/kaggle\/working\/chaii-packages\ncd \/kaggle\/working\/chaii-packages\ncp \/kaggle\/input\/external-packages\/* \/kaggle\/working\/chaii-packages\nmv .\/botocore-1.21.17.xyz .\/botocore-1.21.17.tar.gz\nmv .\/jieba-0.42.1.xyz .\/jieba-0.42.1.tar.gz\nmv .\/seqeval-1.2.2.xyz .\/seqeval-1.2.2.tar.gz","0b0b3131":"%%bash\n# First, we need to install required dependencies. Instead of running their install_tools.sh, run this cell, which has a few minor modifications. This may take a few minutes to run.\n# TODO: look into pip install forever\ncd \/kaggle\/input\/ # Optional but recommended\ncd modified-xtreme\/\n# Copyright 2020 Google and DeepMind.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nREPO=$PWD\necho $REPO\nLIB=$REPO\/third_party\nmkdir -p $LIB\n\n# install latest transformer\ncd $LIB\ncd transformers\npip install . --no-index --find-links \/kaggle\/working\/chaii-packages\/\ncd $LIB\n\n# pip install seqeval --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install tensorboardx --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install tqdm --no-index --find-links \/kaggle\/working\/chaii-packages\/\n\n# # install XLM tokenizer\n# pip install sacremoses --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install pythainlp --no-index --find-links \/kaggle\/working\/chaii-packages\/\n# pip install jieba --no-index --find-links \/kaggle\/working\/chaii-packages\/\n\n# #git clone https:\/\/github.com\/neubig\/kytea.git && cd kytea\n# #.\/configure --prefix=${CONDA_PREFIX}\n# #make && make install\n# pip install kytea --no-index --find-links \/kaggle\/working\/chaii-packages\/","77c4abce":"# Load ChAII dataset\nimport json\nimport random\nimport pandas as pd\nfrom pathlib import Path\n\npd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n\ndata_path = Path(\"\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/\")\njson_dicts = []\n\ndef get_dataframe(file_path):\n    df = pd.DataFrame()\n    with open(file_path,'r') as f:\n        df = pd.read_csv(f)\n    df = df.astype(str)\n    df = df.apply(lambda x: x.str.strip())\n    return df\n\ntrain_data = get_dataframe(data_path \/ \"train.csv\")\ntest_data = get_dataframe(data_path \/ \"test.csv\")\ntest_data","72bab6ee":"# Convert TyDiQA format to a QA format\ndef convert_to_qa_format_kaggle(row):\n    answer = {}\n    try:\n        answer[\"text\"] = row[\"answer_text\"]\n        answer[\"answer_start\"] = int(row[\"answer_start\"])\n    except:\n        answer[\"text\"] = ''\n        answer[\"answer_start\"] = -1\n    qa_json = {\n        \"title\": \"\",\n        \"paragraphs\": [\n            {\n                \"context\": row[\"context\"],\n                \"qas\": [\n                    {\n                        \"question\": row[\"question\"],\n                        \"id\": row[\"language\"] + '-' + str(row[\"id\"]),\n                        \"answers\": [answer]\n                    }\n                ]\n            }\n        ],\n    }\n    \n    return qa_json\n\n# Process one language at a time\n# Here chaii_data is a pandas dataframe\ndef get_qa_data_from_kaggle_format(chaii_data, language):\n    qa_data = {\"data\":[], \"version\":f\"chaii_{language}\"}\n    for index, row in chaii_data.iterrows():\n        if row[\"language\"] == language:\n            qa_datapoint = convert_to_qa_format_kaggle(row)\n            qa_data[\"data\"].append(qa_datapoint)\n\n    print(\"QA (SQuAD) format:\")\n    print(qa_data[\"data\"][0])\n    return qa_data\n\nhi_qa_data = get_qa_data_from_kaggle_format(train_data, 'hindi')\nhi_test_qa_data = get_qa_data_from_kaggle_format(test_data, 'hindi')\nta_qa_data = get_qa_data_from_kaggle_format(train_data, 'tamil')\nta_test_qa_data = get_qa_data_from_kaggle_format(test_data, 'tamil')","59e9eeee":"# Split datapoints language-wise and into QA format\n# Run this cell only if you need to convert from TyDiQA to SQuAD format, otherwise run the nexy one.\nimport re\n\nfrom pprint import pprint\n\ndef byte_str(text):\n  return text.encode(\"utf-8\")\n\ndef byte_len(text):\n  # Python 3 encodes text as character sequences, not byte sequences\n  # (like Python 2).\n  return len(byte_str(text))\n\ndef byte_slice(text, start, end, errors=\"replace\"):\n  # Python 3 encodes text as character sequences, not byte sequences\n  # (like Python 2).\n  return byte_str(text)[start:end].decode(\"utf-8\", errors=errors)\n\ndef convert_to_qa_format_tydiqa(tydi_json):\n  answer = {}\n  for annotation in tydi_json[\"annotations\"]:\n    minimal_answer = annotation[\"minimal_answer\"]\n    if minimal_answer[\"plaintext_start_byte\"] != -1 and minimal_answer[\"plaintext_end_byte\"] != -1:\n      answer[\"text\"] = byte_slice(tydi_json[\"document_plaintext\"],minimal_answer[\"plaintext_start_byte\"],minimal_answer[\"plaintext_end_byte\"])\n      answer[\"answer_start\"] = [m.start() for m in re.finditer(answer[\"text\"],tydi_json[\"document_plaintext\"])][0]\n      break\n  if answer == {}:\n    return {}\n  \n  qa_json = {\n      \"title\" : tydi_json[\"document_title\"],\n      \"paragraphs\" : [\n                      {\n                          \"context\": tydi_json[\"document_plaintext\"],\n                          \"qas\" : [\n                                   {\n                                    \"question\" : tydi_json[\"question_text\"],\n                                    \"id\" : tydi_json[\"language\"] + '-' + str(tydi_json[\"example_id\"]),\n                                    \"answers\" : [answer],\n                                   }\n                          ]\n                      }\n      ],\n  }\n\n  return qa_json\n\n# Here chaii_data is json list\ndef get_qa_data_from_tydiqa_format(chaii_data, language):\n    language = 'hindi'\n    qa_data = {\"data\":[], \"version\":f\"chaii_{language}\"}\n    for json_dict in json_dicts:\n      if json_dict[\"language\"] == language:\n        qa_datapoint = convert_to_qa_format_tydiqa(json_dict)\n        if qa_datapoint != {}:\n          qa_data[\"data\"].append(qa_datapoint)\n        qa_data['data'].append(json_dict)\n\n    print(\"QA (SQuAD) format:\")\n    print(qa_data[\"data\"][0])","ceb09dc6":"# Splitting data into train and dev and saving converted QA formats\ndef split_data(qa_data, test_qa_data, lang_code):\n    split_data_path = Path(\"\/kaggle\/working\/chaii_data\/\")\n    !mkdir \/kaggle\/working\/chaii_data\n\n    qa_data_datapoints = qa_data[\"data\"]\n    test_qa_data_datapoints = test_qa_data[\"data\"]\n    random.shuffle(qa_data_datapoints)\n    train_size = int(len(qa_data_datapoints)*0.8)\n    train_qa_data_datapoints, dev_qa_data_datapoints = qa_data_datapoints[:train_size], qa_data_datapoints[train_size:]\n    \n    train_qa_data = {\"data\":train_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_train\"}\n    dev_qa_data = {\"data\":dev_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_dev\"}\n    test_qa_data = {\"data\": test_qa_data_datapoints, \"version\":f\"chaii_{lang_code}_test\"}\n\n    with open(split_data_path \/ f\"train.{lang_code}.qa.jsonl\",'w') as f:\n      json.dump(train_qa_data,f)\n\n    with open(split_data_path \/ f\"dev.{lang_code}.qa.jsonl\",'w') as f:\n      json.dump(dev_qa_data,f)\n\n    with open(split_data_path \/ f\"test.{lang_code}.qa.jsonl\",'w') as f:\n      json.dump(test_qa_data,f)\n\n    print(f\"{lang_code} Training data size: %d\" % len(train_qa_data_datapoints))\n    print(f\"{lang_code} Dev data size: %d\" % len(dev_qa_data_datapoints))\n    print(f\"{lang_code} Test data size: %d\" % len(test_qa_data_datapoints))\n    \nsplit_data(hi_qa_data, hi_test_qa_data, 'hi')\nsplit_data(ta_qa_data, ta_test_qa_data, 'ta')","980cffc4":"# Now that the data is downloaded, you can run the training script directly from the repo. Here the best way to do it, is to create a new file called run.sh in home folder, and copy paste the below commands, then just run this cell:\n# Also ensure that you set your runtime type to GPU for training.\n\n# Since you would want to experiment with different models, download the modified-xtreme codebase, modify the \n# code and upload the codebase as a new dataset (private or public). \n\n# run.sh ${TASK} ${DATA_DIR} ${OUT_DIR} ${MODEL} ${GPU} ${TRAIN_FILE_NAME} ${PREDICT_FILE_NAME} ${MODEL_NAME}\n# train.sh ${MODEL} ${TASK} ${GPU} ${DATA_DIR} ${OUT_DIR} ${TRAIN_FILE_NAME} ${PREDICT_FILE_NAME} ${MODEL_NAME}\n# train_qa.sh ${MODEL} ${MODEL_NAME} ${SRC} ${TGT} ${GPU} ${DATA_DIR} ${OUT_DIR} ${TRAIN_FILE_NAME} ${PREDICT_FILE_NAME}\n# predict_qa.sh ${MODEL} ${MODEL_TYPE} ${MODEL_PATH} ${TGT} ${GPU} ${DATA_DIR} ${PREDICTIONS_DIR} ${PREDICT_FILE_NAME}\n\n!bash \/kaggle\/input\/modified-xtreme\/run.sh chaii_hi \/kaggle\/working\/chaii_data \/kaggle\/working\/outputs-temp \/kaggle\/input\/bert-base-multilingual-cased 0 train.hi.qa.jsonl \/kaggle\/working\/eval_dir\/predictions dev.hi.qa.jsonl ","b25af87f":"# Tamil Training\n\n!bash \/kaggle\/input\/modified-xtreme\/run.sh chaii_ta \/kaggle\/working\/chaii_data \/kaggle\/working\/outputs-temp \/kaggle\/input\/bert-base-multilingual-cased 0 train.ta.qa.jsonl \/kaggle\/working\/eval_dir\/predictions dev.ta.qa.jsonl","b872b365":"# Predict on train to see performance\n\n!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/working\/outputs-temp\/chaii_hi\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\" \\\n      chaii_hi \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\" \"bert-base-multilingual-cased\" \"bert\" 0 train.hi.qa.jsonl","2c4af368":"!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/working\/outputs-temp\/chaii_ta\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\" \\\n      chaii_ta \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\" \"bert-base-multilingual-cased\" \"bert\" 0 train.ta.qa.jsonl","5e1f0ad9":"# If you trained the model on a local machine and want to evaluate you can use this cell\n# predict.sh ${MODEL_PATH} ${TASK} ${DATA_DIR} ${PREDICTIONS_DIR} ${MODEL} ${MODEL_TYPE} ${GPU} ${PREDICT_FILE_NAME}\n# predict_qa.sh ${MODEL} ${MODEL_TYPE} ${MODEL_PATH} ${TGT} ${GPU} ${DATA_DIR} ${PREDICTIONS_DIR} ${PREDICT_FILE_NAME}\n\n!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/working\/outputs-temp\/chaii_hi\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\" \\\n      chaii_hi \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\"","7d468f60":"# Tamil Inference\n\n!bash \/kaggle\/input\/modified-xtreme\/predict.sh \"\/kaggle\/working\/outputs-temp\/chaii_ta\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\" \\\n      chaii_ta \"\/kaggle\/working\/chaii_data\/\" \"\/kaggle\/working\/eval_dir\/predictions\/\"","ecb31ddc":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\ndef evaluate(lang_code):\n    # For evaluating the predictions, we will use our custom script which uses jaccard mean \n    import json\n#     with open(f\"\/kaggle\/working\/outputs-temp\/chaii_{lang_code}\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\/predictions_{lang_code}_.json\") as f:\n#       preds = json.load(f)\n    with open(f\"\/kaggle\/working\/eval_dir\/predictions\/predictions_{lang_code}_.json\") as f:\n        preds = json.load(f)\n\n    with open(f\"\/kaggle\/working\/chaii_data\/dev.{lang_code}.qa.jsonl\") as f:\n      dev_data = json.load(f)\n    \n    submission_preds = [{'id':k.split('-')[1], 'PredictionString': v} for k, v in preds.items()]\n    \n    # write submissions file\n    df_ = pd.DataFrame.from_dict(submission_preds)\n    df_.to_csv(f'\/kaggle\/working\/eval_dir\/chaii_{lang_code}_submission.csv', index=False)\n    \n    from pprint import pprint\n    jaccard_mean = 0\n    dev_answer_pair_matches = []\n    for d in dev_data['data']:\n        for para in d['paragraphs']:\n            for qa in para['qas']:\n                sample_jaccard = jaccard(qa['answers'][0]['text'], preds[qa['id']])\n                jaccard_mean += sample_jaccard\n                dev_answer_pair_matches.append({'context':para['context'],'question':qa['question'],'gold_answer':qa['answers'],'mbert_pred':preds[qa['id']],'id':qa['id']})\n\n    jaccard_mean \/= len(dev_answer_pair_matches)\n    print(f\"Jaccard Mean for chaii_{lang_code}: {jaccard_mean}\")\n    \n    return dev_answer_pair_matches\n    \n    \n    \ndev_answer_pair_matches_hi = evaluate(\"hi\")\n# dev_answer_pair_matches_ta = evaluate(\"ta\")","6291b239":"%%bash\n# Combine predictions for all languages into a single submission.csv file\ncd \/kaggle\/working\/eval_dir\ncat chaii_hi_submission.csv >> \/kaggle\/working\/submission.csv\ntail -n +2 chaii_ta_submission.csv >> \/kaggle\/working\/submission.csv","6b7fd317":"!wc -l \/kaggle\/working\/eval_dir\/chaii_hi_submission.csv\n!wc -l \/kaggle\/working\/eval_dir\/chaii_ta_submission.csv\n!wc -l \/kaggle\/working\/submission.csv","a859e245":"def write_dev_answer_pair_matches(dev_answer_pair_matches, lang_code):\n    #Matches in predictions\n    correct_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']==d['gold_answer'][0]['text']]\n    with open(f'\/kaggle\/working\/eval_dir\/correct_chaii_{lang_code}_mbert.txt','w',encoding='utf-8') as f:\n      for c in correct_ans:\n        f.write(f\"id:{c['id']}\\n\")\n        f.write(f\"context:{c['context']}\\n\")\n        f.write(f\"question:{c['question']}\\n\")\n        f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n        f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n        f.write(\"\\n\\n\")\n        \n    #Mismatches in predictions\n    wrong_ans = [d for d in dev_answer_pair_matches if d['mbert_pred']!=d['gold_answer'][0]['text']]\n    with open(f'\/kaggle\/working\/eval_dir\/wrong_chaii_{lang_code}_mbert.txt','w',encoding='utf-8') as f:\n      for c in wrong_ans:\n        f.write(f\"id:{c['id']}\\n\")\n        f.write(f\"context:{c['context']}\\n\")\n        f.write(f\"question:{c['question']}\\n\")\n        f.write(f\"gold_answer:{c['gold_answer'][0]['text']}\\n\")\n        f.write(f\"mbert_pred:{c['mbert_pred']}\\n\")\n        f.write(\"\\n\\n\")\n    \n    return correct_ans, wrong_ans\n        \ncorrect_ans, wrong_ans = write_dev_answer_pair_matches(dev_answer_pair_matches_hi, \"hi\")","e51a52bf":"len(correct_ans),len(wrong_ans)","df90fe16":"The cell below is optional (we have not used it for our baseline model), but it downloads the original TyDiQA data in the QA format. You can combine it with our ChAII data and boost training!","314f6c5f":"This cell below is a modified version of ```xtreme\/install_tools.sh```. \n\n**Note:** who are using Xtreme repo locally may also encounter errors with the original script, such as with ```conda activate```. You can copy-paste this script to resolve the error.","dd497686":"### Xtreme codebase setup\n\nNow, we will set up the Xtreme repo ([link](https:\/\/github.com\/google-research\/xtreme)). The below cells do the following:\n1. Clone Xtreme - Here we use a modified version of xtreme which can be added in kaggle notebook as a dataset. \n2. Create a Conda env called ```xtreme``` and install dependencies into it.","b74e129b":"### Data conversion to QA format\n\nThe below cells convert TyDiQA and ChAII Kaggle data format to the SQuAD QA format, so it can be used with the Xtreme pipeline. ","0526e509":"## Training\n\nAlthough this codebase can be used for many varieties of training methods and experiments, we will only train a straightforward baseline. We will create a monolingual Hindi QA model. We encourage you to read and experiment with the Xtreme codebase, and also with other repos. Some promising avenues:\n\n* Train model on both Hindi and Tamil ChAII data,\n* Multi-task learning with Xtreme,\n* Annotate your own data into a QA format and augment training,\n* Zero-shot transfer learning\n\nThe cells below do the following:\n\n1. Convert the given ChAII data (from competition) to QA (SQuAD) format, split into train and dev sets.\n2. Finetune mBERT (bert-base-multilingual-cased) on the ChAII data.\n3. Save the model and dev predictions into Kaggle outputs folder for evaluation later","e796680b":"## Inference and Evaluation\n\nFor inference, we do the following modifications to Xtreme repo:\n1. In ```predict_qa.sh```, add the following (line 40):\n```\nelif [ $TGT == 'chaii_hi' ]; then\n  langs=( hi )\n```\n\n\nAlso, we create a bash file (similar to ```run.sh```) called ```predict.sh```, and copy the commands below into it:\n\n```\n#!\/bin\/bash\n\nsource activate xtreme\ncd \/root\/xtreme\n\nMODEL_PATH=${1:-\"\/root\/xtreme\/outputs-temp\/chaii_hi\/bert-base-multilingual-cased_LR3e-5_EPOCH2.0_maxlen384\"}\nTASK=${2:-chaii_hi}\nDATA_DIR=${2:-\"\/root\/xtreme\/download\/chaii_data\/\"}\nPREDICTIONS_DIR=${3:-\"\/root\/xtreme\/predictions\/\"}\nMODEL=${4:-bert-base-multilingual-cased}\nMODEL_TYPE=${5:-bert}\nGPU=${6:-0}\nPREDICT_FILE_NAME=${7}\n \nbash scripts\/predict_qa.sh bert-base-multilingual-cased bert $MODEL_PATH $TASK $GPU $DATA_DIR $PREDICTIONS_DIR $PREDICT_FILE_NAME\n```","928022e2":"### Training mBERT on Hindi ChAII data\n\nThe below script uses the Xtreme script to train the data. Here, we need to modify the code in the folders to train it on the ChAII data. You can double click on the scripts, modify the code and change them. \n\nFor the baseline, the following changes were made to the Xtreme repo code:\n\n\n1.   In ```scripts\/train.sh```, an additional task called \"chaii_hi\" was added as such:\n```\n...\nelif [ $TASK == 'chaii_hi' ]; then\n  bash $REPO\/scripts\/train_qa.sh $MODEL chaii_hi $TASK $GPU $DATA_DIR $OUT_DIR\n...\n```\n2.   In ```scripts\/train_qa.sh```, the following flags were added:\n```\nTRAIN_LANG=\"en\"\nEVAL_LANG=\"en\"\n```\nAnother elif condition was added as such to modify path of data dir:\n```\n...\nelif [ $SRC == 'chaii_hi' ]; then\n  TASK_DATA_DIR=${DATA_DIR}\n  TRAIN_FILE=${TASK_DATA_DIR}\/train.hi.qa.jsonl\n  PREDICT_FILE=${TASK_DATA_DIR}\/dev.hi.qa.jsonl\n  TRAIN_LANG=\"hi\"\n  EVAL_LANG=\"hi\"\n...\n```\nFinally, TRAIN_LANG and EVAL_LANG replaced the hardcoded \"en\":\n```\n --weight_decay 0.0001 \\\n  --threads 8 \\\n  --train_lang ${TRAIN_LANG} \\\n  --eval_lang ${EVAL_LANG}\n```\n\nIf you want to make your own changes for experimentation, clone the xtreme repo locally in the mount folder and mount it as part of the docker container. \n\nFinally, we create a run.sh script in the current root directory, and paste the following commands:\n\n```\n#!\/bin\/bash\n\nTASK=${1:-chaii_hi}\nDATA_DIR=${2:-\"\/root\/xtreme\/download\/chaii_data\/\"}\nOUT_DIR=${3:-\"\/root\/xtreme\/outputs-temp\/\"}\nMODEL=${4:-bert-base-multilingual-cased}\nGPU=${5:-0}\nTRAIN_FILE_NAME=${6}\nPREDICTIONS_DIR=${7:-\"\/kaggle\/working\/predictions\/\"}\nPREDICT_FILE_NAME=${8}\n\nsource activate xtreme\ncd \/root\/xtreme\nbash scripts\/train.sh $MODEL $TASK $GPU $DATA_DIR $OUT_DIR $TRAIN_FILE_NAME $PREDICTIONS_DIR $PREDICT_FILE_NAME\n\n```\nYour model should be stored in ```\/kaggle\/working\/outputs-temp\/```.\nSimilar instructions were followed for chaii_ta task. ","885e80a6":"# ChAII starter notebook\n\n** Please do not edit this notebook. Make a copy of this notebook and have fun experimenting with different methods. **\n\nThis is a starter notebook for running a baseline mBERT model on the task. This is a standalone notebook which will allow you to do the following:\n1. Train an mBERT model on the ChAII data (utilizing Colab GPUs), \n2. Get dev evaluation numbers, \n3. Generate a submission for the Kaggle leaderboard with the appropriate format.\n\nWe will not submit this notebook, rather we will use this notebook to verify our results and use the [ChAII-1 Inference](https:\/\/www.kaggle.com\/deeplearning10\/chaii-1-inference?scriptVersionId=71218416) for submitting the results.\n\nThis notebook uses the [Xtreme](https:\/\/github.com\/google-research\/xtreme) codebase for training QA-finetuned models. Feel free to run your own scripts\/variants locally, experiment with other models and pipelines, not necessarily limited to Xtreme. Here are some caveats of this method:\n1. Since runtimes (GPU\/TPU) are re-allocated on restarting the notebook, some pip packages installations need to be rerun everytime the notebook has to be reconnected. (Refer to [this](https:\/\/www.kaggle.com\/samsammurphy\/pip-install-forever) if you want to use Kaggle notebooks for the task).\n\nGiven the above conditions, we encourage you to have local installations and clones of the Xtreme codebase (with some changes mentioned below), use this notebook for training with GPU (and inference), and conduct evaluations locally.\n\nSince the internet should be disabled while submitting the notebook, we will add all the external packages and codebase as a Kaggle dataset. You can find a list of all these resources below. \n1. [Modified Xtreme codebase](https:\/\/www.kaggle.com\/deeplearning10\/modified-xtreme): This link contains the Xtreme codebase along with some convenience scripts to run the experiments. \n2. [External Packages](https:\/\/www.kaggle.com\/deeplearning10\/external-packages): Since we will be building Xtreme codebase from source we will need some python packages. Normally you can install all the packages needed via `!pip install package`, but it needs internet. So we have downloaded the .whl files for these packages and uploaded them as a Kaggle dataset, now we can build the python packages offline. \n3. [Bert-base-multilingual-cased](https:\/\/www.kaggle.com\/deeplearning10\/bert-base-multilingual-cased): This is a pretrained mBert model provided by Huggingface. "}}