{"cell_type":{"9e14d476":"code","4e73e01f":"code","ec4aad97":"code","1fa13ef8":"code","77432522":"code","3d27fbda":"code","fcc9d254":"code","6dd29244":"code","e9995542":"code","8924dcd3":"code","c1be02e7":"code","5fcf05dd":"code","d3aad364":"code","98cb709a":"code","3783d58b":"code","6a201780":"code","963a0241":"code","39f602ba":"code","9566bdc5":"code","f232b67a":"code","2292fd61":"code","332b9df5":"code","6c3d55af":"code","9c89d9c4":"code","54da3cef":"code","e55f96ce":"code","863d8e0b":"code","f6f3171f":"code","dc103500":"code","97fd6a32":"code","90d13c2d":"code","27c805c5":"code","731fab49":"code","fb9ff29e":"code","9739a947":"code","ae2c3212":"code","3e550016":"code","2fbc5af8":"markdown","0d5075ee":"markdown","b31899c7":"markdown","728b8be4":"markdown","b202eb3c":"markdown","2090b652":"markdown","c1ff5fc7":"markdown","aa0ff563":"markdown","43ae4a24":"markdown","32b8b746":"markdown","0c3d28fe":"markdown","d5fa03a2":"markdown","bf05ba2f":"markdown","1927fe3d":"markdown","1a393030":"markdown","c1a19208":"markdown","e8f76aca":"markdown","caf714e3":"markdown","4d2b1dad":"markdown","83eff460":"markdown","a6013217":"markdown","f2a8d1d6":"markdown","e7879555":"markdown","c6a8ecd0":"markdown","51ae128d":"markdown"},"source":{"9e14d476":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\npd.set_option('display.max_columns',None)","4e73e01f":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","ec4aad97":"df","1fa13ef8":"df.isnull().sum()","77432522":"features = [feature for feature in df.columns if feature!= 'target']","3d27fbda":"dis_feature = [ feature for feature in features if len(df[feature].unique()) < 10 ]","fcc9d254":"dis_feature","6dd29244":"for feature in dis_feature:\n    sns.countplot(x=feature,data=df,hue='target')\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","e9995542":"for feature in dis_feature:\n    df.groupby(feature)['target'].mean().plot()\n    plt.xlabel(feature)\n    plt.show()","8924dcd3":"for feature in dis_feature:\n    mean = df.groupby(feature)['target'].mean()\n    index = mean.sort_values().index\n    ordered_labels = { k:i for i,k in enumerate(index,0) }\n    df[feature] = df[feature].map(ordered_labels)\n    ","c1be02e7":"for feature in dis_feature:\n    df.groupby(feature)['target'].mean().plot()\n    plt.xlabel(feature)\n    plt.show()","5fcf05dd":"con_feature = [ feature for feature in features if feature not in dis_feature]","d3aad364":"con_feature","98cb709a":"for feature in con_feature:\n    df[feature].hist(bins=10)\n    plt.xlabel(feature)\n    plt.show()","3783d58b":"for feature in con_feature:\n    sns.boxplot(x=feature,data=df)\n    plt.show()","6a201780":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","963a0241":"selectk = SelectKBest(score_func=chi2,k=9)","39f602ba":"feature_scores = selectk.fit(df.drop('target',axis=1),df['target'])","9566bdc5":"feature_scores.scores_","f232b67a":"df_scores = pd.DataFrame(feature_scores.scores_)\ndf_features = pd.DataFrame(features)","2292fd61":"features_scores = pd.concat([df_features,df_scores],axis=1)","332b9df5":"features_scores.columns = ['features','scores']","6c3d55af":"features_scores.sort_values(by='scores',ascending=False,inplace=True)","9c89d9c4":"features_scores","54da3cef":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","e55f96ce":"Best_features = features_scores[features_scores['scores']>18]['features'].values","863d8e0b":"Best_features","f6f3171f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","dc103500":"model = RandomForestClassifier()","97fd6a32":"cross_val_score(model,df[Best_features],df['target'],cv=10).mean()","90d13c2d":"from sklearn.model_selection import RandomizedSearchCV","27c805c5":"params = {\n    'n_estimators' : list(np.arange(10,101,1)),\n    'max_depth' :  list(np.arange(3,30,1)),\n    'min_samples_leaf' :  list(np.arange(1,10,1)),\n    'min_samples_split' :  list(np.arange(1,10,1))\n}","731fab49":"random_search = RandomizedSearchCV(model,param_distributions=params,n_jobs=-1,n_iter=10,scoring='f1_macro',cv=5,verbose=3)","fb9ff29e":"random_search.fit(df[Best_features],df['target'])","9739a947":"random_search.best_estimator_","ae2c3212":"model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=22, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=4, min_samples_split=7,\n                       min_weight_fraction_leaf=0.0, n_estimators=41,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)","3e550016":"cross_val_score(model,df[Best_features],df['target'],cv=10).mean()","2fbc5af8":"For Feature selection, we are using SelectKbest and chi2","0d5075ee":"As you can see there are no nan values present in the dataset.","b31899c7":"As, they are not in perfect relationship, we will bring it to monotonic relationship with the help of target guided encoding. ","728b8be4":"As you can see we have got 82% accuracy.\n","b202eb3c":"we will first check for nan values.","2090b652":"There are many features with correlation more than 0.4.","c1ff5fc7":"Above all the features, oldpeak is highly skewed.\n\nThe 1\/3 rd of oldpeak are 0(zeros). so,we will use it as it is.","aa0ff563":"As predicted there are very few outliers.","43ae4a24":"Relationship of every feature with respect to target.","32b8b746":"We will tune the parameters of Random Forest to improve further accuracy.","0c3d28fe":"From above,\n\n            1 : cp,ca,slope,thal are playing important role with respect to target.\n            2 : fbs has 50-50% probability. so,it is weak to predict the target","d5fa03a2":"As you can see,Hyper Parameter tuninig improved accuracy to 84%","bf05ba2f":"We are using Ensemble technique because it does not over fit. ","1927fe3d":"We will extract all the features.","1a393030":"Extracting those features which scored more than 18.","c1a19208":"As I already discussed in Feature engneering cp,thal are more correlated with target.","e8f76aca":"#### Thank You.","caf714e3":"#### I hope you learned some new things...","4d2b1dad":"First and foremost we will check histogram of each feature. ","83eff460":"Extracting Continous features.","a6013217":"Dividing it into Discrete and Continous.","f2a8d1d6":"Now, we will check for outliers","e7879555":"According to above histograms, there we will be very few outliers.","c6a8ecd0":"As you can see, all the features are now in monotonic relationship. ","51ae128d":"We will go for count plot for understanding insight of data."}}