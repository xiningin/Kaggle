{"cell_type":{"85c7614a":"code","da66cea8":"code","95b5ea10":"code","01b8828d":"code","39651444":"code","41f26cd6":"code","0d7b1ad7":"code","50b4ca63":"code","34b3fca6":"code","f414cf31":"code","5ce3dc97":"code","70144eda":"code","c84c56ce":"code","c669a99e":"code","7603790a":"code","948bb0c8":"code","51254af2":"code","8eaccee6":"code","5201770b":"code","b8718574":"code","ce6d2ce9":"code","68096ee5":"code","beb085f8":"code","e5cc94a3":"code","fa22dfe5":"code","0e18931d":"code","5114dec4":"code","2864d8ce":"code","36b92cfd":"code","fe1f1d03":"markdown","720ccde1":"markdown","80a08945":"markdown","2299f799":"markdown","b2a4aa39":"markdown","3d3c3d9a":"markdown"},"source":{"85c7614a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da66cea8":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","95b5ea10":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","01b8828d":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show()","39651444":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","41f26cd6":"from sklearn.preprocessing import StandardScaler\ndf['normAmount'] = StandardScaler().fit_transform(df['Amount'].values.reshape (-1,1))\ndf = df.drop (['Time', 'Amount'], axis = 1);","0d7b1ad7":"df.head()","50b4ca63":"number_records_fraud = len(df[df.Class==1])\nprint(number_records_fraud)","34b3fca6":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","f414cf31":"from sklearn import ensemble\n\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","5ce3dc97":"print(classification_report(y_test, y_rf))","70144eda":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","c84c56ce":"from imblearn.under_sampling import RandomUnderSampler \n\nrus = RandomUnderSampler()\nX_train, y_train = rus.fit_resample(X_train, y_train)","c669a99e":"y_train.value_counts()","7603790a":"rf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","948bb0c8":"print(classification_report(y_test, y_rf))","51254af2":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","8eaccee6":"X = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","5201770b":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_train, y_train = smote.fit_resample(X_train, y_train)","b8718574":"y_train.value_counts()","ce6d2ce9":"rf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","68096ee5":"print(classification_report(y_test, y_rf))","beb085f8":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","e5cc94a3":"plot_learning_curve(rf, X_train, y_train)","fa22dfe5":"plot_roc_curve(rf,X_test,y_test)","0e18931d":"X = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","5114dec4":"y_train.value_counts()","2864d8ce":"from xgboost import XGBClassifier\nxgb = XGBClassifier(scale_pos_weight=227440\/405)\nxgb.fit(X_train,y_train)\ny_xgb = xgb.predict(X_test)","36b92cfd":"print(classification_report(y_test, y_xgb))\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)","fe1f1d03":"C'est pire.","720ccde1":"Nettoyage des donn\u00e9es","80a08945":"## For\u00eat al\u00e9atoire","2299f799":"## xgboost pond\u00e9r\u00e9","b2a4aa39":"## Sur\u00e9chantillonage et RFC","3d3c3d9a":"## Sous \u00e9chantillonage et RFC"}}