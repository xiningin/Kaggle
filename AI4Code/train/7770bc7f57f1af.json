{"cell_type":{"a24a82c0":"code","afcc159a":"code","6848113a":"code","aec95f46":"code","2d313bcb":"code","b8bfc037":"code","120c1645":"code","45499d45":"code","218f1dcc":"code","8e50b832":"code","b1011431":"code","5d432a05":"code","c096b46d":"code","5d1e7d04":"code","43408c61":"code","24ab35ac":"code","f7411030":"code","6ef8d582":"code","7be51a56":"code","31ec8a57":"code","eb5e809f":"code","40f59dde":"code","cfa0cf52":"code","64b84247":"code","0c383470":"code","7dc2a34a":"code","33fc5ba2":"markdown","6c068514":"markdown","31af30f1":"markdown","e3180adf":"markdown","9287ff5e":"markdown","4bb2c34a":"markdown","4e4a719e":"markdown","cfb96a59":"markdown","51a81a9d":"markdown","80506bbd":"markdown","6b433486":"markdown","39c29b46":"markdown"},"source":{"a24a82c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n       # print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","afcc159a":"import cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport random\nimport keras","6848113a":"path = '\/kaggle\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/'\nlabels = pd.read_csv(path+'labels.csv')","aec95f46":"labels.head()","2d313bcb":"labels.shape","b8bfc037":"x = list(labels.query('is_validation == 0 & is_final_validation == 0')['label'].unique())\ny = list(labels.query('is_validation == 0 & is_final_validation == 0')['label'].value_counts())\nx_1 = list(labels.query('is_validation == 1 & is_final_validation == 0')['label'].unique())\ny_1 = list(labels.query('is_validation == 1 & is_final_validation == 0')['label'].value_counts())\nx_2 = list(labels.query('is_validation == 0 & is_final_validation == 1')['label'].unique())\ny_2 = list(labels.query('is_validation == 0 & is_final_validation == 1')['label'].value_counts())\nfigure, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(15,4))\nax1.bar(x,y)\nax1.set_title('Training set value counts')\nax2.bar(x_1,y_1)\nax2.set_title('Validation set value counts')\nax3.bar(x_2,y_2)\nax3.set_title('Test set value counts')\nplt.show()","120c1645":"for i in labels.index:\n    labels.loc[i,'path']=labels.loc[i]['path'].replace('\\\\','\/')","45499d45":"figure, ax = plt.subplots(nrows=1, ncols=5, figsize=(15,5))\nfor i in range(5):\n    ind = i+random.randint(1,11420)\n    img = cv2.imread(path+labels.loc[ind,'path'])\n    ax[i].set_title(labels.loc[ind,'label'])\n    ax[i].imshow(img) ","218f1dcc":"labels.head()","8e50b832":"train_set = labels.query('is_validation == 0 & is_final_validation == 0').reset_index(drop=True)\nvalidation_set = labels.query('is_validation == 1 & is_final_validation == 0').reset_index(drop=True)\ntest_set = labels.query('is_validation == 0 & is_final_validation == 1').reset_index(drop=True)","b1011431":"def build_data(df, img_size):\n    imgs = []\n    df = df.query('photo_quality == 1')\n    df = df.query('is_bee == 1 | is_wasp ==1')\n    for i in df['path']:\n        img = cv2.imread(path+i)\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img,(img_size,img_size))\n        imgs.append(img)\n    imgs = np.array(imgs, dtype='int16')\n    imgs = imgs\/255\n    df = pd.get_dummies(df['label'])\n    return imgs, df\n\nimg_size = 200\ntrain_imgs, train_df = build_data(train_set, img_size)\nval_imgs, val_df = build_data(validation_set, img_size)\ntest_imgs, test_df = build_data(test_set, img_size)","5d432a05":"figure, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\nax[0].imshow(train_imgs[random.randint(0,train_imgs.shape[0]),:,:,:], interpolation='nearest')\nax[1].imshow(val_imgs[random.randint(0,val_imgs.shape[0]),:,:,:], interpolation='nearest')\nax[2].imshow(test_imgs[random.randint(0,test_imgs.shape[0]),:,:,:], interpolation='nearest')\nax[0].set_title('Train_set image sample')\nax[1].set_title('Validation_set image sample')\nax[2].set_title('Test_set image sample')\nplt.show()","c096b46d":"base_model = tf.keras.applications.MobileNetV2(input_shape=(200,200,3), include_top=False, weights='imagenet')","5d1e7d04":"base_model.trainable = False","43408c61":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()","24ab35ac":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","f7411030":"inputs = tf.keras.Input(shape=(200, 200, 3))\nx = inputs\nx = data_augmentation(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\n\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(32, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)","6ef8d582":"model.summary()","7be51a56":"model.compile(tf.keras.optimizers.Adam(lr=0.0001),\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])","31ec8a57":"hist = model.fit(train_imgs, train_df, epochs=10, validation_data=(val_imgs, val_df))","eb5e809f":"base_model.trainable = True","40f59dde":"fine_tune_at = 50\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","cfa0cf52":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])","64b84247":"hist_fine = model.fit(train_imgs, train_df, epochs=10+20, initial_epoch=hist.epoch[-1], validation_data=(val_imgs, val_df))","0c383470":"acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\n\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\n\nacc += hist_fine.history['accuracy']\nval_acc += hist_fine.history['val_accuracy']\n\nloss += hist_fine.history['loss']\nval_loss += hist_fine.history['val_loss']\n\ninitial_epochs=10\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","7dc2a34a":"model.evaluate(test_imgs, test_df)","33fc5ba2":"<h3>Learning curves","6c068514":"<h3>Model evaluation","31af30f1":"![image.png](attachment:image.png)","e3180adf":"<h3>Importing relevant libraries:","9287ff5e":"<h3>Fine tuning","4bb2c34a":"<h3>Training","4e4a719e":"<h3>Sample images","cfb96a59":"<h3>Create the base model from the pre-trained convnet","51a81a9d":"<h3>Adding custom top layers","80506bbd":"Main elements of this notebook:\n1. Transfer learning using **MobileNet V2** model developed at Google\n2. Data augmentation\n3. Fine tuning","6b433486":"<h3>Selecting only high quality images","39c29b46":"<h3>Dataset composition"}}