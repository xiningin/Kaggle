{"cell_type":{"a66fc32a":"code","536e7cb6":"code","924528b4":"code","62b1f5c1":"code","59a50f48":"code","3e5de247":"code","8b766ebb":"code","317ac053":"code","2f79f63b":"code","00786bc4":"code","fdfd9031":"code","07cb6e2a":"code","c7b67751":"code","f38680d0":"code","3aa406d4":"code","31bb8850":"code","b3f97eaa":"code","84394a4d":"code","bf3dc98e":"code","e41c8aec":"code","792e68b5":"code","cdc53091":"code","41f89971":"code","1ab7f0ff":"code","d5079bec":"code","2997b363":"code","af6bc9a9":"code","fe446c5a":"code","dfc08a39":"code","ec953223":"code","50723fa0":"code","823c2148":"code","7bd4cb05":"code","8d7df7ee":"code","c93966b8":"code","76ef656a":"code","5273cc65":"code","7172e859":"code","e1eacd00":"code","f3d31c80":"code","67f55091":"code","216a5384":"code","d10632b8":"code","29d855b4":"code","05811c9a":"code","81abbbea":"code","f921b0d1":"code","30a09dad":"code","dafbcb22":"code","4bb237cc":"code","6e68074c":"code","96302056":"code","2bd34553":"markdown","e4a94d43":"markdown","7318b9f2":"markdown","4b196305":"markdown","a6cd512d":"markdown","b1a9e7b9":"markdown","32c21d56":"markdown","06194da8":"markdown","6086ae6b":"markdown","d53b2a99":"markdown","ec988147":"markdown","aaf6c838":"markdown","dac0fe61":"markdown","eb276992":"markdown","ea41602f":"markdown"},"source":{"a66fc32a":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt","536e7cb6":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Trump.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# Store height and width of the image\nheight, width = image.shape[:2]\n\nquarter_height, quarter_width = height\/4, width\/4\n\n#       | 1 0 Tx |\n#  T  = | 0 1 Ty |\n\n# T is our translation matrix\nT = np.float32([[1, 0, quarter_width], [0, 1,quarter_height]])\n\n# We use warpAffine to transform the image using the matrix, T\nimg_translation = cv2.warpAffine(image, T, (width, height))\nplt.imshow(img_translation)","924528b4":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Trump.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nheight, width = image.shape[:2]\n\n# Divide by two to rototate the image around its centre\nrotation_matrix = cv2.getRotationMatrix2D((width\/2, height\/2), 90, .5)\n\nrotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n\nplt.imshow( rotated_image)","62b1f5c1":"rotated_image = cv2.transpose(image)\n\nplt.imshow( rotated_image)","59a50f48":"flipped = cv2.flip(image, 1)\nplt.imshow( flipped) ","3e5de247":"# load our input image\nimage = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Trump.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Let's make our image 3\/4 of it's original size\nimage_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\nplt.imshow(image_scaled)","8b766ebb":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1abraham.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nsmaller = cv2.pyrDown(image)\nlarger = cv2.pyrUp(smaller)\n\nplt.imshow(image )","317ac053":"plt.imshow(smaller )","2f79f63b":"plt.imshow(larger)","00786bc4":"import cv2\nimage = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Hillary.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nheight, width =image.shape[:2]\n\nstart_row, start_col = int(height * .25), int(width * .25)\n\nend_row, end_col = int(height * .75), int(width * .75)\n\ncropped = image[start_row:end_row , start_col:end_col]\n\n\nplt.imshow(image)\n","fdfd9031":"plt.imshow(cropped)\n","07cb6e2a":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1coffee.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#image = cv2.imread('\/kaggle\/input\/opencv-samples-images\/someshapes.jpg')\n\n# Create a matrix of ones, then multiply it by a scaler of 100 \n# This gives a matrix with same dimesions of our image with all values being 100\nM = np.ones(image.shape, dtype = \"uint8\") * 175 \nplt.imshow(image)","c7b67751":"# We use this to add this matrix M, to our image\n# Notice the increase in brightness\nadded = cv2.add(image, M)\nplt.imshow(added)","f38680d0":"# Likewise we can also subtract\n# Notice the decrease in brightness\nsubtracted = cv2.subtract(image, M)\nplt.imshow( subtracted)","3aa406d4":"# Making a sqare\nsquare = np.zeros((300, 300), np.uint8)\ncv2.rectangle(square, (50, 50), (250, 250), 255, -2)\nplt.imshow(square)","31bb8850":"# Making a ellipse\nellipse = np.zeros((300, 300), np.uint8)\ncv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\nplt.imshow(ellipse)","b3f97eaa":"# Shows only where they intersect\nAnd = cv2.bitwise_and(square, ellipse)\nplt.imshow(And)","84394a4d":"# Shows where either square or ellipse is \nbitwiseOr = cv2.bitwise_or(square, ellipse)\nplt.imshow(bitwiseOr)","bf3dc98e":"# Shows where either exist by itself\nbitwiseXor = cv2.bitwise_xor(square, ellipse)\nplt.imshow( bitwiseXor)","e41c8aec":"# Shows everything that isn't part of the square\nbitwiseNot_sq = cv2.bitwise_not(square)\nplt.imshow(bitwiseNot_sq)","792e68b5":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Sunflowers.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)\n\n# Creating our 3 x 3 kernel\nkernel_3x3 = np.ones((3, 3), np.float32) \/ 9\n","cdc53091":"# We use the cv2.fitler2D to conovlve the kernal with an image \nblurred = cv2.filter2D(image, -1, kernel_3x3)\nplt.imshow(blurred)\n","41f89971":"# Creating our 7 x 7 kernel\nkernel_7x7 = np.ones((7, 7), np.float32) \/ 49\n\nblurred2 = cv2.filter2D(image, -1, kernel_7x7)\nplt.imshow( blurred2)","1ab7f0ff":"blur = cv2.blur(image, (3,3))\nplt.imshow(blur)","d5079bec":"# Instead of box filter, gaussian kernel\nGaussian = cv2.GaussianBlur(image, (7,7), 0)\nplt.imshow(Gaussian)","2997b363":"# Takes median of all the pixels under kernel area and central \n# element is replaced with this median value\nmedian = cv2.medianBlur(image, 5)\nplt.imshow(median)","af6bc9a9":"# Bilateral is very effective in noise removal while keeping edges sharp\nbilateral = cv2.bilateralFilter(image, 9, 75, 75)\nplt.imshow( bilateral)","fe446c5a":"# Parameters, after None are - the filter strength 'h' (5-10 is a good range)\n# Next is hForColorComponents, set as same value as h again \ndst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n\nplt.imshow(dst)","dfc08a39":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1beatle.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","ec953223":"# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\nplt.imshow(sharpened)","50723fa0":"# Load our image\nimage = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1elephant.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","823c2148":"# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(thresh1)","7bd4cb05":"# Values below 127 go to 255 and values above 127 go to 0 (reverse of above)\nret,thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(thresh2)","8d7df7ee":"# Values above 127 are truncated (held) at 127 (the 255 argument is unused)\nret,thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\nplt.imshow(thresh3)","c93966b8":"# Values below 127 go to 0, above 127 are unchanged  \nret,thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\nplt.imshow(thresh4)","76ef656a":"# Resever of above, below 127 is unchanged, above 127 goes to 0\nret,thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\nplt.imshow(thresh5)","5273cc65":"# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(thresh1)\n\nimage = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1elephant.jpg')\n","7172e859":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1candy.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)","e1eacd00":"# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\nplt.imshow( erosion)","f3d31c80":"# Dilation\ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.imshow(dilation)","67f55091":"# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.imshow(opening)","216a5384":"# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.imshow(closing)","d10632b8":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1Trump.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)\n\n\nsobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\nsobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)","29d855b4":"plt.title(\"sobel_x\")\nplt.imshow(sobel_x)","05811c9a":"plt.title(\"sobel_y\")\nplt.imshow(sobel_y)","81abbbea":"sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\nplt.imshow(sobel_OR)","f921b0d1":"laplacian = cv2.Laplacian(image, cv2.CV_64F)\nplt.imshow(laplacian)","30a09dad":"# Canny Edge Detection uses gradient values as thresholds\n# The first threshold gradient\ncanny = cv2.Canny(image, 50, 120)\nplt.imshow(canny)","dafbcb22":"image = cv2.imread('\/kaggle\/input\/opencv-samples-images\/scan.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n","4bb237cc":"# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n \nwarped = cv2.warpPerspective(image, M, (420,594))\n \nplt.imshow(warped)","6e68074c":"image = cv2.imread('\/kaggle\/input\/operations-with-opencv\/1ex2.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nrows,cols,ch = image.shape\n\nplt.imshow(image)\ncv2.waitKey(0)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594]])\n ","96302056":"# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getAffineTransform(points_A, points_B)\n\nwarped = cv2.warpAffine(image, M, (cols, rows))\n \nplt.imshow(warped)","2bd34553":"## Sharpening \n\nBy altering our kernels we can implement sharpening, which has the effects of in strengthening or emphasizing edges in an image.","e4a94d43":"## Arithmetic Operations\n\nThese are simple operations that allow us to directly add or subract to the color intensity.\n\nCalculates the per-element operation of two arrays. The overall effect is increasing or decreasing brightness.","7318b9f2":"## In affine transforms you only need 3 coordiantes to obtain the correct transform","4b196305":"## Image Pyramids\n\nUseful when scaling images in object detection.","a6cd512d":"## Thresholding, Binarization & Adaptive Thresholding\nIn thresholding, we convert a grey scale image to it's binary form","b1a9e7b9":"## Scaling, re-sizing and interpolations\n\nRe-sizing is very easy using the cv2.resize function, it's arguments are:\n\n> cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)","32c21d56":"## Dilation, Erosion, Opening and Closing ","06194da8":"## Rotations\n\ncv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)","6086ae6b":"## Bitwise Operations and Masking\n\nTo demonstrate these operations let's create some simple images","d53b2a99":"### Other commonly used blurring methods in OpenCV","ec988147":"## Edge Detection & Image Gradients","aaf6c838":"## Translations\n\nThis an affine transform that simply shifts the position of an image.\n\nWe use cv2.warpAffine to implement these transformations.","dac0fe61":"## Convolutions and Blurring","eb276992":"## Image De-noising - Non-Local Means Denoising","ea41602f":"\n## Hi Everyone and Welcome My Notebook !\n### Nowadays I was eager to learn opencv. This is the second kernel about OpenCV.But more to come.\n### The topics are as follows\n\n\n\n* Translations\n* Rotations\n* Scaling, re-sizing and interpolations\n* Image Pyramids\n* Cropping\n* Arithmetic Operations\n* Bitwise Operations and Masking\n* Convolutions and Blurring\n* Sharpening \n* Thresholding, Binarization & Adaptive Thresholding\n* Dilation, Erosion, Opening and Closing \n* Edge Detection & Image Gradients\n* Perspective & Affine Transforms\n\n### If You like, Pls upvote ! Have a nice day!\n\n#### Let's start by importing the OpenCV libary\n"}}