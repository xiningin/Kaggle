{"cell_type":{"cb9bbc2e":"code","fa2d0d4c":"code","114e2edb":"code","daec5b5a":"code","31b4c699":"code","b6ff2ff8":"code","69eec5d5":"code","8d16380d":"code","592835ed":"code","7a9cd807":"code","15ebad64":"code","dfddc910":"code","48e93c03":"code","a00ff8e7":"code","210fa7a4":"code","3ec27b5b":"code","22347cde":"markdown","12398c37":"markdown","b0bb039b":"markdown","c02c69ff":"markdown","48f99c74":"markdown","b099f3ff":"markdown","50791637":"markdown","03aec970":"markdown","f3d33def":"markdown","c86e5416":"markdown","133ab9cf":"markdown"},"source":{"cb9bbc2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa2d0d4c":"import seaborn as sns\nimport matplotlib.pyplot as plt\ndata=pd.read_csv('..\/input\/sample-supermarket-dataset\/SampleSuperstore.csv')","114e2edb":"data.info()","daec5b5a":"# lets check if there are any duplicates in the data, if there are, we'll remove them.\ndata=data.drop(data[data.duplicated()].index)\ndata","31b4c699":"data.Country.value_counts()","b6ff2ff8":"# display only top 15 cities based on their frequency\ndata.City.value_counts().head(15)","69eec5d5":"print(f'The total number of unique city locations in the dataset is {len(data.City.value_counts())}')","8d16380d":"data.State.value_counts().head(15)","592835ed":"print(f'The total number of unique state locations in the dataset is {len(data.State.value_counts())}')","7a9cd807":"from ipywidgets import widgets,interact\ndrop_down_values=widgets.Dropdown(options=['Profit','Discount','Sales','Quantity'],value='Quantity')\ndrop_down_agg=widgets.Dropdown(options=['sum','mean','std'])\ndrop_down_var1=widgets.Dropdown(options=list(data.describe(include='object').columns),value='City')\ndrop_down_var2=widgets.Dropdown(options=list(data.describe(include='object').columns),value='Sub-Category')\n\n\ndef crosstab(var1,var2,values,agg):\n    return pd.crosstab(data[var1],data[var2],margins=True,values=data[values],aggfunc=agg)\n\ninteract(crosstab,var1=drop_down_var1,var2=drop_down_var2,values=drop_down_values,agg=drop_down_agg)","15ebad64":"# lets look at the value_counts() of each column present and get an overall idea\nfig,ax=plt.subplots(2,3,figsize=(16,8))\nax[0][0].bar(data['Ship Mode'].value_counts().index,data['Ship Mode'].value_counts().values,color='#ea4335')\nax[0][0].set_title('$Ship Mode$',fontweight='bold')\n\nax[0][1].bar(data['Segment'].value_counts().index,data['Segment'].value_counts().values,color='#4285f4')\nax[0][1].set_title('$Segment$',fontweight='bold')\n\nax[0][2].bar(data['Region'].value_counts().index,data['Region'].value_counts().values,color='#fbbc05')\nax[0][2].set_title('$Region$',fontweight='bold')\n\nax[1][0].bar(data['Category'].value_counts().index,data['Category'].value_counts().values,color='#34a853')\nax[1][0].set_title('$Category$',fontweight='bold')\n\nax[1][1].barh(data['Sub-Category'].value_counts().index,data['Sub-Category'].value_counts().values,color='#5F68C3')\nax[1][1].set_title('$Sub-Category$',fontweight='bold')\n\nax[1][2].bar(data['Quantity'].value_counts().index,data['Quantity'].value_counts().values,color='#747474')\nax[1][2].set_title('$Quantity$',fontweight='bold')\n\nplt.sca(ax[0][0])\nplt.xticks(rotation=10)\n\nplt.show()","dfddc910":"# lets compare each sub-categories Sales, Profits, Quantity and discount per order by plotting bar graphs\nfig,ax=plt.subplots(2,2,figsize=(18,8),sharex=True)\nlabels=data.groupby(by='Sub-Category').agg('sum').index\nsns.barplot(x=data.groupby(by='Sub-Category').agg('sum').index,y=data.groupby(by='Sub-Category').agg('sum').Profit,order=labels,ax=ax[0][0])\nsns.barplot(x=data.groupby(by='Sub-Category').agg('sum').index,y=data.groupby(by='Sub-Category').agg('sum').Quantity,order=labels,ax=ax[1][0])\nsns.barplot(x=data.groupby(by='Sub-Category').agg('sum').index,y=data.groupby(by='Sub-Category').agg('sum').Sales,order=labels,ax=ax[0][1])\nsns.barplot(x=data.groupby(by='Sub-Category').agg('sum').index,y=data.groupby(by='Sub-Category').agg('mean').Discount,order=labels,ax=ax[1][1])\nplt.sca(ax[1][1])\nplt.ylabel('Average discount per order')\nplt.xticks(rotation=60)\nplt.sca(ax[1][0])\nplt.xticks(rotation=60)\nplt.show()","48e93c03":"drop_down=widgets.Dropdown(options=['Sales','Discount','Quantity','Profit'],value='Profit',disabled=False)\ndrop_down1=widgets.Dropdown(options=['sum','mean'],value='sum',disabled=False)\n\ndef data_new(agg_parameter,variable):\n    new_data=data.groupby(by=['Region','Category']).agg(agg_parameter)\n    hue=[]\n    for i in range(len(new_data)):\n        hue.append(new_data.index[i][1])\n    region=[]\n    for i in range(len(new_data)):\n        region.append(new_data.index[i][0])\n    new_data['region']=region\n    new_data['hue']=hue\n    \n    graph=sns.barplot(data=new_data,y=variable,x='region',hue='hue',palette='viridis')\n    graph,plt.legend(bbox_to_anchor=(1,1.02))\n\n\ninteract(data_new,agg_parameter=drop_down1,variable=drop_down)\n# sum and Discount gives cumulative discount of all the items ordered (Category like Furniture etc)\n# mean gives 'per order' stat as we aggregated by 'mean'","a00ff8e7":"Furniture=list(data[data.Category=='Furniture']['Sub-Category'].unique())\nOffice_Supplies=list(data[data.Category=='Office Supplies']['Sub-Category'].unique())\nTechnology=list(data[data.Category=='Technology']['Sub-Category'].unique())\n\n\nfrom ipywidgets import widgets,interact\ndrop_down=widgets.Dropdown(description='Sub Category',\n                           options=[('furniture',Furniture),('office supplies',Office_Supplies),('technology',Technology)])\n# creating a dictionary of the sub-categories and their maximum sales values\nmax_sales={}\nsub=data['Sub-Category'].unique()\nfor i in sub:\n    max_sales[i]=data[data['Sub-Category']==i].Sales.max()\n    \ndef graph(sub_category):\n    fig,ax=plt.subplots(1,1,figsize=(16,8))\n    sns.kdeplot(data=data[data['Sub-Category'].isin(sub_category)],x='Sales',hue='Sub-Category',ax=ax)\n    n=0.0002\n    for i in sub_category:\n        ax.annotate(f'max {i} Sales ({max_sales[i]})',xy=(max_sales[i],0),xytext=(5000,n),arrowprops=dict(shrink=0.05))\n        n+=0.0001\n    \ninteract(graph,sub_category=drop_down)","210fa7a4":"drop_down=widgets.Dropdown(options=list(data['Sub-Category'].unique()))\n\ndef graph(sub_category):\n    sns.histplot(data[data['Sub-Category']==sub_category].Profit\/data[data['Sub-Category']==sub_category].Quantity)\n\ninteract(graph,sub_category=drop_down)","3ec27b5b":"#dividing the data into those orders that resulted in profits and those which resulted in a loss\nprofit=data[data.Profit>0]\nloss=data[data.Profit<0]\n\n# percentage share of total profit by each sub-category\nplt.pie(profit.groupby('Sub-Category').agg('sum').Profit,radius=3.12,labels=profit.groupby('Sub-Category').agg('sum').index,\n       autopct='%1.2f%%')\nplt.title('Profit pie',fontdict=dict(fontsize=36),pad=100,loc='center')\nplt.show()\n\n# percentage share of total loss by each sub-category\nplt.pie(np.abs(loss.groupby('Sub-Category').agg('sum').Profit),radius=3.12,labels=loss.groupby('Sub-Category').agg('sum').index,\n       autopct='%1.2f%%')\nplt.title('Loss pie',fontdict=dict(fontsize=36),pad=100,loc='center')\nplt.show()","22347cde":"# introduction\n* The sample superstore dataset consists data ranging from the type of product sold, where it is sold to and how they are shipped.\n* First lets look at the data and understand and its types and information it contains\n* Then we will make some vizualizations to compare all the columns and use interactive tools using widgets to look at different parameters. Using seaborn, we can visualize the distribution of the profits and loss incurred by different sub categories and how each of them compare to each other. There are many different column category combinations we can try to detemine areas of loss and profits.","12398c37":"\n# Vizualizations","b0bb039b":"* Lets look at the disrtibution of sales data according to the sub categories by using the interactive widget to select the category. ","c02c69ff":"* Dividing the profits of each order to the quantity of the product ordered gives us the unit profit made from the Product. Here we can see that each category, for example chairs, dont have the same unit profit, i.e. each chair order has different profit per unit alluding to the fact that there are probably different types of chairs. Hence the superstore should try to push sales of a type of sub-category (chair in our example) which gives high profits per unit.\n* From this distribution, we can also see which category is profitable.\n\n* Now lets look at the distribution of profit and loss among the sub-categories","48f99c74":"* We can use the crosstab function to group data by different categories and apply summary statistics on those grouped data. The variables to use in the contigency table are the categorical variables and we can use sum or mean to calculate summary characteristics on numerical values of the grouped counts where numerical columns are 'Quantity', 'Profits' etc","b099f3ff":"* From the pie chart, we can immediately see which sub-category takes majority portion of the total profit and loss. From the Profit pie, we can see that 'Binders' account for 15.54% of the total profits and 'Copiers' having the second best share of about 12.5%\n* The loss pie shows us that not only does binders account for the majority of the profits, but also account for almost 25% of the total loss. 'Tables' aslo cause quiet a bit of damage as they account for 20% of total loss.\n* We can see that not all sub-categories are included in the loss pie as some only make profits and dont account for the loss. For eg, 'Copiers' only make profits i.e. no loss is incurred by the sale of copiers.","50791637":"* One of uses of the crosstab are the 'Sub-Category' and 'City' combination. We can detemine which city ordered which product and what was mean or total profit from that city. This will help us detemine which cities to target to increase profits or reduce losses by discontinuing the sale of the product in that city. \n* We can also determine which city ordered what type of product. The NaNs indicate that, that city did not order that product.","03aec970":"* Above we can compare the different sub_categories with each other. We can determine which sub_category is helping the superstore and which category is causing loss.\n* lets look at the categories of products sold by region. We group the dataset by Region and Category and aggregate by two parameters, either by 'sum' so as to obtain total stats for each region and category or we use 'mean' parameter to obtain 'per order' statistics. Using the visualizations below, we can compare the types of products sold by region and their profits or sales.\n* Using the ipywidgets module, we can look at the visualizations one at a time and note down important takeaways or observaions\n* The main comparision here is the region where the sale occurred or where the shipment is off to, so we can compare the performance by region whereas in the previous visualizations, we compared the subcategories.","f3d33def":"* The distribution shows the sales on a per order basis, i.e. the maximum sales value for each sub-category shows the maximum sales out of all the orders.","c86e5416":"* assuming that no two orders can be exactly the same, we ignore the duplicates. But it is entirely possible that two orders can be same as we cannot distinguish them by order time data or order_id as this information is not provided. In our case lets assume no two orders are the same and continue.","133ab9cf":"If you are wondering why I used specific colors for individual plots,.....well I was bored and wanted to try something different. Interestingly enough, the colors of the first 4 subplots from the left are official colors of google, the 5th one is of TCS and the last one is one of the colors from the microdoft logo \n* I got them from here https:\/\/www.schemecolor.com\/tata-consultancy-services-tcs-logo-color.php, it has the color codes for the other companies too!\n* From the countplots, we can see some of the distribution of the different categories and how they compare to themsleves.\n* Lets look at the different locations preset in our dataset."}}