{"cell_type":{"ada879fe":"code","f2c27037":"code","2b706022":"code","97599f72":"code","c52f3119":"code","9d9e9791":"code","beac292a":"code","ff5bf897":"code","c608697c":"code","8d13c19c":"code","b9c5eb79":"code","90a34633":"markdown","10af114f":"markdown","5b13a0ba":"markdown","2de96580":"markdown","2b9723b1":"markdown","1275eb68":"markdown","433be87e":"markdown","a13feb04":"markdown","d4e641be":"markdown","87c429dc":"markdown","a7038cf7":"markdown","126aef9f":"markdown","d7780ea2":"markdown","65410aea":"markdown","ee927be4":"markdown"},"source":{"ada879fe":"#Import necessay libraries\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nimport seaborn as sns\n\n#Preprocessing\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import OrdinalEncoder,StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n#Model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error,roc_auc_score\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb","f2c27037":"#import the data and shape\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsample=pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\nprint(train.shape,test.shape,sample.shape)\nprint(train.isnull().sum())\ntrain.describe()","2b706022":"!pip install tensorflow_decision_forests --upgrade","97599f72":"import tensorflow_decision_forests as tfdf\n\ntrain_tfds = tfdf.keras.pd_dataframe_to_tf_dataset(train,label=\"target\")\ntest_tfds = tfdf.keras.pd_dataframe_to_tf_dataset(test)\n\n#Build the model\nmodel = tfdf.keras.RandomForestModel()\nmodel.fit(train_tfds)\n\n#Model summary\nmodel.summary()\n\npred = model.predict(test_tfds)\n\n#prediction output\nsample['target'] = pred\nsample.to_csv('submission.csv',index= False)\nprint('Success')\nsample.sample(1)","c52f3119":"model.make_inspector().evaluation()","9d9e9791":"model.make_inspector().training_logs()","beac292a":"logs = model.make_inspector().training_logs()\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Accuracy (out-of-bag)\")\n\nplt.subplot(1, 2, 2)\nplt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Logloss (out-of-bag)\")\n\nplt.show()\n","ff5bf897":"#features(categorical and numerical datas separate)\nuseful_features = [c for c in train.columns if c not in (\"id\",\"target\")]\nX = train[useful_features]\ny=train.target\ntest = test[useful_features]\n\nRs = preprocessing.RobustScaler()\nX = Rs.fit_transform(X)\ntest = Rs.transform(test)\n\nprint('Features and preprocessing process is succesfully completed.......')\nprint('********************************************************************************************')\n\nxtrain,xvalid,ytrain,yvalid = model_selection.train_test_split(X,y,test_size = 0.2,random_state=42)\nprint(xtrain.shape,xvalid.shape,ytrain.shape,yvalid.shape)","c608697c":"from sklearn.ensemble import RandomForestClassifier\n\nfinal_prediction1 = []\nscore = []\n\n#Initialize\nclf = RandomForestClassifier(max_depth=3, random_state=42)\n#Fit\nclf.fit(xtrain,ytrain)\n#predict\npred = clf.predict(xvalid)\ntest_pre = clf.predict(test)\nfinal_prediction1.append(test_pre)\n\n#ROC\nroc=roc_auc_score(yvalid,pred)\nscore.append(roc)\nprint(score)\nprint(final_prediction1)","8d13c19c":"\nsample.target = preds = np.column_stack(final_prediction1)\nsample.to_csv(\"submission_rfc.csv\",index=False)\nprint(\"success\")\nsample.sample(1)","b9c5eb79":"from sklearn.cross_decomposition import PLSRegression\n\nreg = PLSRegression(n_components=10)\nreg.fit(xtrain,ytrain)\npred1 = reg.predict(xvalid)\ntest_pred1 = reg.predict(test)\nroc1= roc_auc_score(yvalid,pred1)\nprint(roc1)\n\nsample.target = test_pred1\nsample.to_csv(\"submission_rr.csv\",index=False)\nprint(\"success\")\n","90a34633":"## **Tabular Playground Series_Nov_21**\n\n***I'm trying this time tensorflow_decision_forests, Previously KFold split_5 if you want refere my works (version_1)***\n\n**Lets, Start!**\n\n**STEPS:** \n1. Import necessary library\n2. Load Data\n3. Apply tensorflow_decision_forests\n4. Random forest Classifier\n5. PLSRegression\n6. Save CSV file","10af114f":"## **Identify Features,Preprocessing and split the data**","5b13a0ba":"## **Import necessary libraries** ","2de96580":"## ***Thankyou*** \ud83d\ude0a\n\n### ***I'm really excited to try random_forest_classifier&PLSRegression*** \n### ***Happy_Learning***\ud83d\ude0a","2b9723b1":"### **Random_forest_Classifier**","1275eb68":"### ***These TF-DF is useful for all, If you want increase the accuracy(keep try hyperparameter tunning in this model)***\n\n**Reference: https:\/\/www.tensorflow.org\/decision_forests\/tutorials**\n\n### **Keep learning**\n","433be87e":"## **Evaluating the model**","a13feb04":"## ***Plot the training_logs|Out_of_bags***","d4e641be":"### **Predict output and generate .CSV file**","87c429dc":"## **Install Tensorflow_decision_forests libraries**\n\n### **Reference: https:\/\/www.tensorflow.org\/decision_forests\/tutorials**","a7038cf7":"## **Random_Forest_Classifier**\n\n**Reference:** [https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html](http:\/\/)","126aef9f":"## **Inspecting training_logs**","d7780ea2":"## **Load,Shape,Describe,Identify null in data**","65410aea":"### **PLSRegression**","ee927be4":"#### ***Apply libraries in Data's and Predict output***"}}