{"cell_type":{"38d68277":"code","c26b1325":"code","58a9e9a1":"code","7fc0298a":"code","6d592246":"code","b0d97d97":"code","5a0258b8":"code","6faa9ec7":"code","6853cbe8":"code","0ca709fe":"code","1742f4c8":"markdown"},"source":{"38d68277":"# This Python 3 environment comes with many helpful analytics libraries installed\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport h5py\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import loadmat\nfrom skimage import color\nfrom skimage import io\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import classification_report\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras import regularizers\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import SGD, RMSprop, Adam, Nadam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD, Adadelta, Adagrad\nfrom keras.constraints import max_norm\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.layers import Activation, Flatten, Input, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D \nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\n# Any results you write to the current directory are saved as output.","c26b1325":"def load_data(path):\n    \"\"\" Helper function for loading a MAT-File\"\"\"\n    data = loadmat(path)\n    return data['X'], data['y']\n\npath = '..\/input\/svhntrain\/train_32x32.mat'\npathTest = '..\/input\/svhntest\/test_32x32.mat'\nX_train, y_train = load_data(path)\nX_test, y_test = load_data(pathTest)\n","58a9e9a1":"# Transposing the the train and test data\n# by converting it from  \n# (width, height, channels, size) -> (size, width, height, channels)\n\nX_train, y_train = X_train.transpose((3,0,1,2)), y_train[:,0]\nX_test, y_test = X_test.transpose((3,0,1,2)), y_test[:,0]\n\nprint(\"Training Set\", X_train.shape)\nprint('')\n\nprint(\"Test Set\", X_test.shape)\nprint('')\n\n# Calculate the total number of images\nnum_images = X_train.shape[0]\nnum_images2 = X_test.shape[0]\n\nprint(\"Total Number of Train Images\", num_images)\nprint(\"Total Number of Test Images\", num_images2)\n\n#Label from 10 to 0\ny_train[y_train == 10] = 0\ny_test[y_test == 10] = 0\nprint(np.unique(y_train))\n\n#Validation Set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.13, random_state=7)\n\ntrain_mean = np.mean(X_train, axis=0) #Shape (32,3)\ntrain_std = np.std(X_train, axis=0) #Shape (32,3)\nX_train_norm = (X_train - train_mean) \/ train_std\nX_train_255 = np.divide(X_train, 255)\nX_train_255 = np.array(X_train_255)\nprint(\"X_train_norm Shape: \", X_train_norm.shape)\nprint(\"X_train_255 Shape: \", X_train_255.shape)\n\n\n\nX_train_norm_array = np.array(X_train_norm)\ny_train_array = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\nX_val_array = np.array(X_val)\ny_val_array = np.array(y_val)\n\nprint(\"Y Train Shape: \", y_train_array.shape)\n\nX_test_255 = np.divide(X_test, 255)\n\ny_train_cnn = to_categorical(y_train_array, 10)\ny_val_cnn = to_categorical(y_val_array, 10)\ny_test_cnn = to_categorical(y_test, 10)\nprint(\"Y Train CNN Shape: \", y_train_cnn.shape)\nprint(\"Y Val CNN Shape: \", y_val_cnn.shape)\nprint(\"Y Test CNN Shape: \", y_test_cnn.shape)","7fc0298a":"def plot_images(img, labels, nrows, ncols):\n    \"\"\" Plot nrows x ncols images\n    \"\"\"\n    fig, axes = plt.subplots(nrows, ncols)\n    for i, ax in enumerate(axes.flat): \n        if img[i].shape == (32, 32, 3):\n            ax.imshow(img[i])\n        else:\n            ax.imshow(img[i,:,:,0])\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.set_title(labels[i])","6d592246":"plot_images(X_train, y_train, 1, 5)","b0d97d97":"fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\nfig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n\nax1.hist(y_train, bins=10)\nax1.set_title(\"Training set\")\nax1.set_xlim(1, 10)\n\nax2.hist(y_test, color='g', bins=10)\nax2.set_title(\"Test set\")\n\nfig.tight_layout()","5a0258b8":"def cnn_model_convAndMaxPool(): \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), strides=1, activation='relu',\n                            input_shape=(32, 32, 3), kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.90))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.75))\n#     model.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu', strides=1, kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.75))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.50))\n#     model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu', strides=1, kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.50))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.50))\n    model.add(Flatten())\n    model.add(Dense(10))\n#     model.add(Activation('relu'))\n#     #model.add(Dropout(0.50))\n#     model.add(Dense(10))\n    model.add(Activation('softmax'))\n#     model.add(Dense(10))\n#     model.add(Activation('softmax'))\n    \n    return model;\n\n\n    ","6faa9ec7":"X_test_255.shape, X_train_255.shape","6853cbe8":"#Accuracy = 0.9319683466502766\ndef cnn_model_convMaxPoolDropoutEveryLayer():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, input_shape=(32,32,3), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.50))\n\n    model.add(Conv2D(64, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.30))\n\n    model.add(Conv2D(128, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.30))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.10))\n\n    model.add(Dense(10, activation='softmax'))\n    return model","0ca709fe":"batch_size = 128\nnb_classes = 10\nnb_epoch = 20\n# X_train_array = np.array(X_train)\nmodel = cnn_model_convMaxPoolDropoutEveryLayer()\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n# model.fit(X_train_norm_array, y_train_cnn, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_val_array, y_val_cnn))\nmodel.fit(X_train_255, y_train_cnn, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_val_array, y_val_cnn))\n# score = model.evaluate(X_test, y_test_cnn, verbose=0)\nscore = model.evaluate(X_test_255, y_test_cnn, verbose=0)\nprint('loss:', score[0])\nprint('Test accuracy:', score[1])","1742f4c8":"Using Dropout in Convolution Neural Networks for the SVHN(Street View House Number) Dataset"}}