{"cell_type":{"392eee43":"code","86ba7f8b":"code","a015d550":"code","f1a2fd1d":"code","75848152":"code","6434b0bd":"code","5408ac4a":"code","948814cf":"code","fdc9b765":"code","8450d02d":"code","82ea5ae7":"code","91974df2":"code","7fc4fc31":"code","87afe78b":"code","23adf7be":"code","050fb372":"code","8a46c0e9":"code","578e36c5":"code","4deb10a9":"code","1f31b282":"code","d92adfa4":"code","ddf2377b":"code","0d8e2d22":"code","68ed7313":"code","d347559e":"code","51bcb423":"code","340f5b1a":"code","3b8cb53b":"code","ceda6578":"code","aa14311d":"code","bd0f1ed4":"code","e4877cbb":"code","66b2b9c9":"code","6d005a97":"code","d946cc34":"code","1bcf0c0c":"code","d2fe5514":"code","455623f3":"code","fe7d7d0e":"code","1340592f":"code","a5e41ef1":"code","278235b5":"code","5f054a01":"code","48f1e001":"code","af81a44b":"code","9a3128fa":"code","215d7e68":"markdown","51b84d34":"markdown","b1412804":"markdown","a5dc7050":"markdown","3bfe4530":"markdown","a57cc987":"markdown","a3d3f986":"markdown","875b88a7":"markdown","ef3d83b3":"markdown","cb401c23":"markdown","b1a91eee":"markdown","a4b79e24":"markdown","6d99af86":"markdown","e0199183":"markdown","214ede12":"markdown","1fa4c788":"markdown","36c48b26":"markdown","fbab0d6c":"markdown"},"source":{"392eee43":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","86ba7f8b":"data = pd.read_csv(\"..\/input\/adult-census-income\/adult.csv\")\ndata.head()","a015d550":"data.info()","f1a2fd1d":"data.hist(bins=20, figsize=(15,12), edgecolor='black',grid=True)\nplt.show()","75848152":"data.loc[data['native.country']==\"?\"]","6434b0bd":"data.isin(['?']).sum()","5408ac4a":"data = data.replace('?', np.NAN)","948814cf":"for col in ['workclass', 'occupation', 'native.country']:\n    data[col].fillna(data[col].mode()[0], inplace=True)","fdc9b765":"data.isnull().values.any()","8450d02d":"data.isnull().sum()","82ea5ae7":"data['income'].value_counts()","91974df2":"import seaborn as sns\nsns.countplot(x='income',data=data, palette=\"cool\")\nplt.title('Income Values')","7fc4fc31":"sns.boxplot(x='income', y='age', data=data, palette='hot')\nplt.title('Age vs Income')","87afe78b":"sns.boxplot(x='income',y='hours.per.week', data=data, palette='seismic')\nplt.title('hours vs Income')","23adf7be":"sns.countplot(data['sex'],hue=data['income'], palette='coolwarm')\nplt.title('Sex vs Income')","050fb372":"sns.countplot(data['occupation'],hue=data['income'], palette='winter')\nplt.xticks(rotation=90)\nplt.title('Occupation vs Income')","8a46c0e9":"data['income']=data['income'].map({'<=50K':0, '>50K': 1})","578e36c5":"sns.FacetGrid(data, col='income').map(sns.distplot, \"age\")","4deb10a9":"sns.barplot(x='education.num', y='income', data=data)\nplt.title('Education vs Income')","1f31b282":"sns.barplot(x=\"workclass\",y=\"income\",data=data)\nplt.xticks(rotation=90)\nplt.title('Workclass vs Income')","d92adfa4":"sns.barplot(x=\"education\",y=\"income\",data=data)\nplt.xticks(rotation=90)\nplt.title('Education vs Income')\n","ddf2377b":"sns.barplot(x='marital.status',y='income', data=data)\nplt.xticks(rotation=90)\nplt.title('Education vs Income')","0d8e2d22":"data['relationship'].unique()","68ed7313":"sns.barplot(x='relationship',y='income', data=data)\nplt.xticks(rotation=90)\nplt.title('Relationship vs Income')","d347559e":"sns.barplot(x='race', y='income', data=data)\nplt.xticks(rotation=90)\nplt.title('Race vs Income')","51bcb423":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()","340f5b1a":"for col in data.columns:\n    if data[col].dtypes == 'object':\n        data[col] = label_encoder.fit_transform(data[col])","3b8cb53b":"data.dtypes","ceda6578":"data.head()","aa14311d":"corr = data.corr()\nplt.figure(figsize=(20,12))\nsns.heatmap(corr, annot=True, cmap='coolwarm')","bd0f1ed4":"corr['income'].sort_values(ascending = False)","e4877cbb":"previsores = data.iloc[:,0:14]\nclasse = data.iloc[:,14]","66b2b9c9":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","6d005a97":"previsores = scaler.fit_transform(previsores)","d946cc34":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ncolumn_tranformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(),\n [1, 3, 5, 6, 7, 8, 9, 13])],remainder='passthrough')\n\nprevisores = column_tranformer.fit_transform(previsores).toarray()\n","1bcf0c0c":"previsores","d2fe5514":"from sklearn.model_selection import train_test_split\nprevisores_train, previsores_teste, classe_train, classe_test = train_test_split(previsores, classe, test_size=0.30, random_state=0)","455623f3":"#append results\nlista=[]","fe7d7d0e":"# best parameters for models:\n# Labelencoder (79.23%) \n# Labelencoder and Scaler (82.17%)\n# Labelencoder, Scaler and OneHotEncoder (84.58%)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nclassificador = LogisticRegression(random_state=1, solver='lbfgs')\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('Logistic Regression: ', precisao * 100)\nlista.append(precisao)","1340592f":"# best parameters for models:\n# Labelencoder (79.50%) \n# Labelencoder and Scaler (80.38%)\n# Labelencoder, Scaler and OneHotEncoder (54.50%)\n\nfrom sklearn.naive_bayes import GaussianNB\n\nclassificador = GaussianNB()\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('Naive Bayes: ', precisao * 100)\nlista.append(precisao)\n","a5e41ef1":"# best parameters for models:\n# Labelencoder (80.86%) \n# Labelencoder and Scaler (80.84%)\n# Labelencoder, Scaler and OneHotEncoder (81.28%)\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassificador = DecisionTreeClassifier()\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('Tree Classifier: ', precisao * 100)\nlista.append(precisao)\n","278235b5":"# best parameters for models:\n# Labelencoder (85.55%) \n# Labelencoder and Scaler (85.51%)\n# Labelencoder, Scaler and OneHotEncoder (85.33%)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassificador = RandomForestClassifier(n_estimators=350, criterion='entropy', random_state=0)\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('Random Forest: ', precisao * 100)\nlista.append(precisao)\n","5f054a01":"# best parameters for models:\n# Labelencoder (86.16%) \n# Labelencoder and Scaler (86.16%)\n# Labelencoder, Scaler and OneHotEncoder (86.22%)\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclassificador = GradientBoostingClassifier()\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('GBC: ', precisao * 100)\nlista.append(precisao)","48f1e001":"# best parameters for models:\n# Labelencoder (75.82%) \n# Labelencoder and Scaler (84.46%)\n# Labelencoder, Scaler and OneHotEncoder (84.68%)\n\nfrom sklearn.svm import SVC\n\nclassificador = SVC(kernel = 'rbf', random_state = 1, C = 2.0, gamma='auto')\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('SVM: ', precisao * 100)\nlista.append(precisao)","af81a44b":"# best parameters for models:\n# Labelencoder (80.53%) \n# Labelencoder and Scaler (84.78%)\n# Labelencoder, Scaler and OneHotEncoder (83.07%)\n\nfrom sklearn.neural_network import MLPClassifier\n\nclassificador = MLPClassifier(verbose = False,\n                              max_iter=1000,\n                              tol = 0.0000010,\n                              solver = 'adam',\n                              hidden_layer_sizes=(100),\n                              activation='relu')\nclassificador.fit(previsores_train, classe_train)\n\nprevisoes = classificador.predict(previsores_teste)\n\nprecisao = accuracy_score(classe_test, previsoes)\nmatriz = confusion_matrix(classe_test,previsoes)\n\nprint('MLP Classifier: ', precisao * 100)\nlista.append(precisao)","9a3128fa":"fig, ax = plt.subplots()\ny_grafico =['Logistic Regression',\n          'Naive Bayes',\n          'Tree Classifier',\n           'Random Forest',\n            'GBC',\n            'SVM',\n            'MLP Classifier'\n           ]\n\nx_grafico = lista \nsns.barplot(x=x_grafico,y=y_grafico)\nfor y,x in enumerate(x_grafico):\n    ax.annotate(\"{:.2f}%\".format(x * 100), xy=(x,y))\n    ax.set_xlim(0, 1)\nplt.xlabel('Accuracy')\nplt.title('List Best Models')","215d7e68":"**3. Decision Tree**","51b84d34":"**5. Gradient Boosting **","b1412804":"**#CREATING MODELS**","a5dc7050":"#**Divis\u00e3o do dataset**","3bfe4530":"**#Scaler**","a57cc987":"**2. Naive bayes**","a3d3f986":"**Import library**","875b88a7":"**1. Logistic Regression**","ef3d83b3":"**Label Encoder**","cb401c23":"**7. Neural Network - MLP **","b1a91eee":"**#Data split for Train and test**","a4b79e24":"*The best parameters for each models can be seen above *","6d99af86":"**4. Random Forest**","e0199183":"6. SVM","214ede12":"#create List Object","1fa4c788":"**#Result Models**","36c48b26":"**Preprocessing and Visualization**","fbab0d6c":"**#One Hot Encoder**"}}