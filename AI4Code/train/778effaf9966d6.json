{"cell_type":{"757dbeb4":"code","1e7a4359":"code","b65ce42f":"code","ed338d38":"code","0e4bcba8":"code","81236b0b":"code","8ec49b2c":"code","3fcc459f":"code","312f6da4":"code","7b486923":"code","4a29515f":"code","60e3bbc8":"code","ee51ff65":"code","43730ce4":"code","5bbee977":"code","f36373a7":"code","79540c07":"code","8ce65dfb":"code","10b13e29":"code","4f7f0aa8":"code","1b098a17":"code","92659470":"code","b24f3491":"code","9d1ce59b":"code","a1e1a1da":"code","6df309ab":"code","b24854da":"code","4c87306e":"code","be2c60fb":"code","c6e4085a":"code","c09c7026":"code","c9c8a2e9":"code","f986ce8a":"code","19afe317":"code","0da47411":"code","5698ac6e":"code","484f89f4":"code","cfac930b":"code","0528ef19":"code","54dc55e6":"code","e0b91cd2":"code","40ed4c5a":"code","7e6ab5b5":"code","81db07b5":"code","90c79f24":"code","8139f2f9":"code","360af661":"code","c32b32c9":"code","319ce3ff":"code","33fb2132":"code","2ecbe848":"code","73e79ef9":"code","0da373fc":"code","1e1296de":"markdown","06e1f1e6":"markdown","241ae801":"markdown","5a955d2c":"markdown","2f2a35c5":"markdown"},"source":{"757dbeb4":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\nfigure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport json\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score \nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder, Imputer\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom scipy.stats import skew, norm, boxcox_normmax\nfrom scipy import stats\nfrom scipy.special import boxcox1p \n# models\nfrom xgboost import XGBRegressor\nimport warnings\n\n# Ignore useless warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n\n# Avoid runtime error messages\npd.set_option('display.float_format', lambda x:'%f'%x)\n\n# make notebook's output stable across runs\nnp.random.seed(42)\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\nimport os\nprint(os.listdir(\"..\/input\"))","1e7a4359":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nprint(\"N\u00famero de linhas e colunas no train_df : \",train_df.shape)\nprint(\"N\u00famero de linhas e colunas no teste_df : \",test_df.shape)","b65ce42f":"train_df.head()","ed338d38":"train_df.shape","0e4bcba8":"train_df.dtypes.head(30)","81236b0b":"#column_names = train_df.columns","8ec49b2c":"#verifica valores nulos\ntrain_df.isnull().sum().sort_values(ascending=False)","3fcc459f":"train_df['SalePrice'].describe()","312f6da4":"#skewness and kurtosis\nprint(\"Skewness: %f\" % train_df['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_df['SalePrice'].kurt())","7b486923":"train_df.describe(include='O') #categorical features","4a29515f":"plt.figure(figsize=(12,8))\nsns.distplot(train_df['SalePrice'].values, bins=50, kde=False, color=\"blue\")\nplt.title(\"Histogram of SalePrice\")\nplt.xlabel('SalePrice', fontsize=12)","60e3bbc8":"train_df.hist(bins=50, figsize=(20,15))\nplt.tight_layout(pad=0.4)","ee51ff65":"#correlation matrix\ncorrmat = train_df.corr()\nplt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=1.0, square=True, cmap=\"Blues\");","43730ce4":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([train_df['SalePrice'], train_df[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","5bbee977":"# As 10 features que mais se correlacionam com SalePrice\ncorr_matrix = train_df.corr()\ncorr_matrix['SalePrice'].sort_values(ascending=False)[:10]","f36373a7":"#histogram and normal probability plot\nsns.distplot(train_df['SalePrice'], fit=norm);\nfig = plt.figure()\n#res = stats.probplot(train_df['SalePrice'], plot=plt)","79540c07":"#applying log transformation\ntrain_df['SalePrice'] = np.log(train_df['SalePrice'])","8ce65dfb":"#data transformation\ntrain_df['GrLivArea'] = np.log(train_df['GrLivArea'])\ntest_df['GrLivArea'] = np.log(test_df['GrLivArea'])","10b13e29":"#transformed histogram and normal probability plot\nsns.distplot(train_df['SalePrice'], fit=norm);\nfig = plt.figure()\n#res = stats.probplot(train_df['SalePrice'], plot=plt)","4f7f0aa8":"#transformed histogram and normal probability plot\nsns.distplot(train_df['GrLivArea'], fit=norm);\nfig = plt.figure()\n#res = stats.probplot(train_df['GrLivArea'], plot=plt)","1b098a17":"train_cp = train_df.copy()\ntest_cp = test_df.copy()\ntest_id = test_df[\"Id\"]","92659470":"train_cp = train_cp.drop(['SalePrice'], axis=1)","b24f3491":"all_df = pd.concat([train_cp,test_cp])\nprint(all_df.shape)\nall_df.head()","9d1ce59b":"conta_nulo2 = all_df.isnull().sum().sort_values(ascending=False)\nconta_nulo2.head(40)","a1e1a1da":"all_df.shape ","6df309ab":"#all_df['temGaragem'] = all_df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)","b24854da":"all_df['temLareira'] = all_df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","4c87306e":"all_df = all_df.drop(['Fireplaces'], axis=1) ","be2c60fb":"all_df['GarageCars'] = all_df['GarageCars'].fillna(2.0)\nall_df['GarageArea'] = all_df['GarageArea'].fillna(480.0)\nall_df['TotalBsmtSF'] = all_df['TotalBsmtSF'].fillna(989.5)","c6e4085a":"all_df_x = pd.DataFrame()","c09c7026":"all_df_x['Id'] = all_df['Id']\nall_df_x['OverallQual'] = all_df['OverallQual']\nall_df_x['GrLivArea'] = all_df['GrLivArea']\nall_df_x['GarageCars'] = all_df['GarageCars']\nall_df_x['GarageArea'] = all_df['GarageArea']\nall_df_x['TotalBsmtSF'] = all_df['TotalBsmtSF']\nall_df_x['1stFlrSF'] = all_df['1stFlrSF']\nall_df_x['FullBath'] = all_df['FullBath']\nall_df_x['TotRmsAbvGrd'] = all_df['TotRmsAbvGrd']\nall_df_x['YearBuilt'] = all_df['YearBuilt']\nall_df_x['Fence'] = all_df['Fence']\nall_df_x['temLareira'] = all_df['temLareira']","c9c8a2e9":"# Get_Dummies para transformar categoricos em Num\u00e9ricos\nall_dummy_df = pd.get_dummies(all_df_x)","f986ce8a":"all_dummy_df.shape","19afe317":"all_dummy_df.head()","0da47411":"train_dummy_df = all_dummy_df[:1460]","5698ac6e":"train_dummy_df.shape","484f89f4":"train_dummy_df.head()","cfac930b":"train_df_2 = train_dummy_df\ntrain_df_2[\"SalePrice\"] = train_df[\"SalePrice\"]","0528ef19":"train_df_2.to_csv(\"train_hprice.csv\", index=False)","54dc55e6":"test_dummy_df = all_dummy_df[1460:]","e0b91cd2":"test_dummy_df.shape","40ed4c5a":"test_dummy_df.to_csv(\"test_hprice.csv\", index=False)","7e6ab5b5":"train_dummy_df = train_dummy_df.drop(['Id'], axis=1)\ntest_dummy_df = test_dummy_df.drop(['Id'], axis=1)","81db07b5":"train_dummy_df = train_dummy_df.drop(['SalePrice'], axis=1)","90c79f24":"all_dummy_df = all_dummy_df.drop(['Id'], axis=1)","8139f2f9":"#train_X, test_X, train_y, test_y = train_test_split(train_dummy_df.as_matrix(), train_df['SalePrice'].as_matrix(), test_size=0.25)\n\ntrain_X = train_dummy_df\ntest_X = test_dummy_df\ntrain_y = train_df['SalePrice']\n\nprint(train_X.shape, test_X.shape)","360af661":"#test_y.shape #array sem colunas","c32b32c9":"#Training a Linear Regression Model\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n\n# Fitting the training data to our model\nregressor.fit(train_X,train_y)\n\n# Predicting price for the Validation set\ny_pred = regressor.predict(test_X)\n\n# Scoring the model\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# R2 score closer to 1 is a good model\n#print(f\"R2 score: {r2_score(test_y, y_pred)}\")\n\n# MSE score closer to zero is a good model\n#print(f\"MSE score: {mean_squared_error(test_y, y_pred)}\")\n\n#R2 score: 0.8405922641242736\n#MSE score: 0.02760294922349491\n#An R2 score closer to 1.0 means the model is a better one. Likewise, an MSE score closer to 0 means the model is good.\n\nprint(y_pred)","319ce3ff":"y_pred = np.exp(y_pred)","33fb2132":"y_pred","2ecbe848":"test_id = pd.DataFrame({\"Id\":test_id.values})","73e79ef9":"sub_df = pd.DataFrame({\"Id\":test_id[\"Id\"].values})\nsub_df[\"SalePrice\"] = y_pred\nprint(sub_df)","0da373fc":"sub_df.to_csv(\"linRegression.csv\", index=False)","1e1296de":"<b>Feature Engineering","06e1f1e6":"<b>Tirar Log para normalizar os campos SalePrice e GrLivArea","241ae801":"<b>Concatena treino e teste","5a955d2c":"Campo SalePrice apresenta Skewness > 1.0, logo o campo precisa ser normalizado (log transformation)","2f2a35c5":"<b>An\u00e1lise do arquivo train_df"}}