{"cell_type":{"1f9f23f4":"code","cdb676ec":"code","a7c417ff":"code","c111a1d0":"code","0348fed3":"code","67cb2a4e":"code","19fa4ee9":"code","1d3dd045":"code","98f7ccc9":"code","b49c41dd":"code","b1f7d824":"code","cc5b5bb2":"code","04406534":"code","c5fd6922":"code","5bd763d7":"code","f1014a80":"code","a56ecb9c":"code","9d21ba0b":"code","4ba1f0dd":"code","0b78556f":"code","a1112f3a":"code","0cc652eb":"code","d2e2455a":"code","9b7613e3":"code","266c8ee4":"code","6e28256e":"code","c757b941":"code","b80d1122":"code","2e2e3909":"code","61ff5a13":"code","6a440a73":"code","92da4332":"code","eb3412ef":"code","e583e871":"code","d5f71db5":"code","3a54b296":"code","fdafed18":"code","daa17473":"code","09400734":"code","4aeb8331":"code","123a78f6":"code","04552a49":"markdown","220a712f":"markdown","1cad464a":"markdown","615bb612":"markdown","736f529d":"markdown","6e1ac80c":"markdown","47a8ade2":"markdown","9ee10c28":"markdown","8ba26509":"markdown","6fc88fe0":"markdown","09567bc5":"markdown","d1449028":"markdown","c6677161":"markdown","100dcde9":"markdown","5a1b72db":"markdown","fa789e03":"markdown","db9f5fdb":"markdown","8d2f66ea":"markdown","1a7cbc90":"markdown","0dae48e1":"markdown","441e7466":"markdown","79485963":"markdown"},"source":{"1f9f23f4":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nimport sys\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport scikitplot as skplt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,precision_recall_curve","cdb676ec":"from keras.models import model_from_json","a7c417ff":"dataset = pd.read_csv('..\/input\/resized-2015-2019-blindness-detection-images\/labels\/trainLabels19.csv')\n\ndataset","c111a1d0":"names = ['Normal', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']\nprint(dataset['diagnosis'].value_counts())\nsns.barplot(x=names,y=dataset.diagnosis.value_counts().sort_index())","0348fed3":"dataset1 = pd.read_csv('..\/input\/resized-2015-2019-blindness-detection-images\/labels\/trainLabels15.csv')\ndataset1.columns = ['id_code','diagnosis']\ndataset1","67cb2a4e":"print(dataset1['diagnosis'].value_counts())\nsns.barplot(x=names,y=dataset1.diagnosis.value_counts().sort_index())","19fa4ee9":"#Now we will take 900 images in total for each class. So to complete the 900 images we will take majority of images from 'dataset' \n#and if necessary take the rest of the required images from 'dataset1'\n\n#index  Final_Img_count   Image taken from dataset 1\n# 0          900                   (0)\n# 1          900                 (530)\n# 2          900                   (0)\n# 3          900                 (707)\n# 4          900                 (605)\n\n\nlevel_1 = dataset1[dataset1.diagnosis == 1].sample(n=530)\n\nlevel_3 = dataset1[dataset1.diagnosis == 3].sample(n=707)\n\nlevel_4 = dataset1[dataset1.diagnosis == 4].sample(n=605)","1d3dd045":"level_1.shape , level_3.shape, level_4.shape","98f7ccc9":"level_0 = dataset[dataset.diagnosis == 0].sample(n=900)\nlevel_0","b49c41dd":"level_2 = dataset[dataset.diagnosis == 2].sample(n=900)\nlevel_2","b1f7d824":"dataset= dataset[dataset['diagnosis']>0]\ndataset= dataset[dataset['diagnosis'] != 2]\nprint(dataset['diagnosis'].value_counts())","cc5b5bb2":"dataset = pd.concat([level_0,level_2,dataset])\ndataset=dataset.sample(frac=1)\nprint(dataset['diagnosis'].value_counts())\ndataset","04406534":"dataset1 = pd.concat([level_1,level_3, level_4])\ndataset1=dataset1.sample(frac=1)\n\nprint(dataset1['diagnosis'].value_counts())\ndataset1","c5fd6922":"images = []\nfor i, image_id in enumerate(tqdm(dataset.id_code)):\n    im = cv2.imread(f'..\/input\/resized-2015-2019-blindness-detection-images\/resized train 19\/{image_id}.jpg')\n    #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = cv2.resize(im, (128, 128))\n    images.append(im)\n\nimages","5bd763d7":"for i, image_id in enumerate(tqdm(dataset1.id_code)):\n    im = cv2.imread(f'..\/input\/resized-2015-2019-blindness-detection-images\/resized train 15\/{image_id}.jpg')\n    #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = cv2.resize(im, (128, 128))\n    images.append(im)\n\nimages","f1014a80":"# random image from imported data\nplt.imshow(images[-30])\nplt.show()","a56ecb9c":"# This function will act as a filter for the image data\n\ndef load_colorfilter(image, sigmaX=10):\n    #image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #image = crop_image_from_gray(image)\n    #image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX),-4 ,128)\n    return image","9d21ba0b":"for i in range(len(images)):\n    output = load_colorfilter(images[i])\n    images[i] = output","4ba1f0dd":"# image after filtering\nplt.imshow(images[-30])\nplt.show()","0b78556f":"images = np.array(images)\nimages.shape","a1112f3a":"dataset = pd.concat([dataset,dataset1])\nprint(dataset['diagnosis'].value_counts())\n\nsns.barplot(x=names,y=dataset.diagnosis.value_counts().sort_index())","0cc652eb":"X = images\/255.0\ny = dataset.diagnosis.values\nX, y","d2e2455a":"# Cleaning some RAM memory space\ndel images,level_1,level_3, level_4, level_0, dataset1","9b7613e3":"# Applying image augmentation\nsys.stdout.flush()\naug = ImageDataGenerator(rotation_range=0.2, width_shift_range=0.2, \\\n    height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\\\n    horizontal_flip=True, fill_mode=\"nearest\")","266c8ee4":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)#\n#X_train.shape, X_valid.shape, y_train.shape, y_valid.shape\n#######################################################################################\n\nX, X_test, y, y_test = train_test_split(X,y,test_size=0.1, stratify = y)\nX.shape, X_test.shape, y.shape, y_test.shape","6e28256e":"# Function defined to plot the curves during training\n\ndef display_training_curves(training, validation, title, subplot):\n    \n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n    plt.show()","c757b941":"BS = 32       #Batch size\naccuracy = []\n\n############ USING STRATIFIED K-FOLD CROSS VALIDATION TECHNIQUE ##########\n\nskf = StratifiedKFold(n_splits=5)\nskf.get_n_splits(X,y)\n\nfor train, test in skf.split(X,y):\n    # Design of CNN Model\n    model=tf.keras.Sequential([\n        tf.keras.layers.Conv2D(16,(3,3),input_shape=(128,128,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n\n        tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n\n\n        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n\n        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        \n        tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        \n\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(1024,activation='relu'),\n        tf.keras.layers.Dense(5,activation='softmax')\n\n    ])\n    \n    # Compiling the model\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['acc'])\n    \n    # Training\n    history = model.fit_generator(aug.flow(X[train], y[train], batch_size=BS),\n    validation_data=(X[test], y[test]),\n    epochs=80, verbose = 1)\n\n    # Evaluate score\n    acc=model.evaluate(X[test], y[test])\n    accuracy.append(acc[1])\n    \n    # Plotting traning curves\n    display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss', 211)\n    \n    display_training_curves(\n    history.history['acc'], \n    history.history['val_acc'], \n    'accuracy', 212)","b80d1122":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n ","2e2e3909":"model.save(\"modelsave.h5\")\nprint(\"Saved model to disk\")","61ff5a13":"# we can see the minimum and maximum validation accuracy received after training on the training dataset\naccuracy","6a440a73":"# thus we can assume the mean accuracy of the model on the training set to be:\na=sum(accuracy)\/len(accuracy)\nprint(f'Mean evaluated accuracy of model : {a}')","92da4332":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","eb3412ef":"#predicting training labels\ny_train_pred = model.predict_classes(X)\n\n#Accuracy of train prediction\nprint('\\nAccuracy of training data prediction : {:.2f}\\n'.format(accuracy_score(y, y_train_pred)))\n\n#confusion matrix for training set\nconfusion = confusion_matrix(y, y_train_pred)\nprint('Confusion Matrix of training data prediction \\n')\nprint(confusion)","e583e871":"# Visualizing confusion matrix for train data\nskplt.metrics.plot_confusion_matrix(y, y_train_pred, figsize=(8, 8))\nplt.show()","d5f71db5":"#Classification report \nprint('\\nClassification Report of training set : \\n')\nprint(classification_report(y, y_train_pred, target_names=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']))","3a54b296":"y_pred = model.predict_classes(X_test)\ny_pred","fdafed18":"y_test","daa17473":"# Accuracy of test prediction\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))","09400734":"# Confusion matrix of the test data\nconfusion = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix\\n')\nprint(confusion)","4aeb8331":"# Visualizing confusion matrix for test data\nskplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(8, 8))\nplt.show()","123a78f6":"#Classification report\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred, target_names=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate DR']))","04552a49":"# SPLITTING OF DATASET IN TRAIN AND TEST DATA","220a712f":"**IMPORTING APTOS-2019 BLINDNESS DETECTION DATA CSV FILE**","1cad464a":"# ANALYSIS OF TRAINING MODEL","615bb612":"# PREDICTING TEST RESULTS","736f529d":"1. **DESIGNING THE CONVOLUTIONAL NEURAL NETWORK MODEL**\n2. **USING STRATIFIED K-FOLD CROSS VALIDATION TECHNIQUE TO SPLIT THE TRAINING DATA INTO TRAINING AND VALIDATION SETS**\n3. **COMPILE AND TRAIN THE MODEL FOR EACH SPLIT**\n4. **PLOT THE TRAINING CURVES FOR EACH SPLIT**","6e1ac80c":"**APPLYING GAUSSIAN BLUR NOISE FILTER**","47a8ade2":"**ANALYSIS OF TEST RESULTS**","9ee10c28":"# IMPORTING SELECTED IMAGES FROM THE DATASET","8ba26509":"# TRAINING OF MODEL","6fc88fe0":"**SCALING\/NORMALISING IMAGE DATASET**","09567bc5":"# IMPORTING DATA","d1449028":"**MODEL LAYER DIAGRAM**","c6677161":"**FORMING THE FINAL DATASET**","100dcde9":"# IMAGE AUGMENTATION","5a1b72db":"**VISUALIZING DATASET1**","fa789e03":"**RESIZING THE IMPORTING DATA**","db9f5fdb":"# PREPROCESSING OF IMAGE DATA","8d2f66ea":"**VISUALIZING DATASET**","1a7cbc90":"**VISUALIZING BALANCED DATASET**","0dae48e1":"**IMPORTING DIABETIC RETINOPATHY RESIZED DATA FROM THE KAGGLE COMPETITION 2015 CSV FILE**","441e7466":"# IMPORTING LIBRARIES","79485963":"# BALANCING THE DATASET"}}