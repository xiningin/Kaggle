{"cell_type":{"276d4fae":"code","9ef1150a":"code","f557bf5e":"code","95739018":"code","44f65a85":"code","1e0dfe07":"code","14facdaf":"code","72e09bcd":"code","3a63cd37":"code","39f8f38b":"code","92722dc2":"code","f63ed450":"code","76352a66":"code","7d28fb91":"code","648e1c21":"code","01042c22":"code","428b1cbf":"code","be9e558b":"code","6e8170ff":"code","6bddd71c":"code","1b3d76b8":"code","2167ebea":"code","958f0eee":"code","2f46bfc2":"code","cc6fc7fd":"code","e41656c2":"code","d3ae1978":"code","803c786d":"code","2b6b8a24":"code","296814ed":"code","7f67213b":"code","5aa3311c":"code","8c12bb23":"code","67760ab7":"code","cc496337":"code","a7f67b07":"code","95e4ced0":"markdown","c1168818":"markdown","aa2b50bb":"markdown","290dff71":"markdown","aa25aaac":"markdown","ae434569":"markdown","8de82520":"markdown","c8e5547f":"markdown","a02251be":"markdown","c7097b12":"markdown","7132fcb0":"markdown","56b7fee8":"markdown","669c5b9e":"markdown","a489c965":"markdown","0509e10f":"markdown","ca351b47":"markdown","b52d40b8":"markdown","af9bb20c":"markdown","c2d4d9ab":"markdown","66d9964e":"markdown","722c7f93":"markdown","e66876d3":"markdown","0d529e58":"markdown","fe4606ba":"markdown","d93e0aca":"markdown"},"source":{"276d4fae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9ef1150a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n","f557bf5e":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')","95739018":"train.head(5)","44f65a85":"train.describe()","1e0dfe07":"l1=pd.DataFrame(train.Age.fillna(int(train.Age.mean())))\nl2=pd.DataFrame(train.Embarked.fillna(\"S\"))\nl3=pd.DataFrame(train.Sex.map({\"male\":0,\"female\":1}))\nl4=pd.DataFrame(train.Fare)\nl5=pd.DataFrame(train.Pclass)\nl6=pd.DataFrame(train.SibSp)\nl7=pd.DataFrame(train.Parch)\nl8=pd.DataFrame(train.Cabin.fillna(train.Cabin.mode()))\nx1=pd.concat([l1,l2,l3,l4,l5,l6,l7,l8],axis=1)\n\nfrom sklearn import preprocessing\nle=preprocessing.LabelEncoder()\nx1.Embarked=le.fit_transform(x1.Embarked)","14facdaf":"x=x1[['Age','Embarked','Sex','Fare','Pclass','SibSp','Parch','Cabin']]\ny=train[['Survived']]","72e09bcd":"sns.boxplot(x=\"Survived\",y='Age',data=train)","3a63cd37":"sns.boxplot(x=\"Survived\",y='Fare',data=train)","39f8f38b":"sns.boxplot(x=\"Pclass\",y='Age',data=train)","92722dc2":"l=pd.concat([x,y],axis=1)\nvar=l[['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked','Survived']]\ncorre=var.corr()\nsns.heatmap(corre,annot=True)","f63ed450":"X=x[['Pclass','Sex','Fare','Embarked']]\nY=y[['Survived']]","76352a66":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=0)","7d28fb91":"from sklearn.tree import DecisionTreeClassifier\nmodel1=DecisionTreeClassifier()\nmodel1.fit(X_train,Y_train)","648e1c21":"pred1=model1.predict(X_test)","01042c22":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model1,X,Y,cv=5)\nscores\nimport numpy as np\nnp.mean(scores)","428b1cbf":"from sklearn.linear_model import LogisticRegression\nmodel2=LogisticRegression(max_iter=20000)\nmodel2.fit(X_train,np.ravel(Y_train))","be9e558b":"pred2=model2.predict(X_test)","6e8170ff":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model2,X,np.ravel(Y),cv=5)\nscores\nimport numpy as np\nnp.mean(scores)","6bddd71c":"from sklearn.naive_bayes import GaussianNB\nmodel3=GaussianNB()\nmodel3.fit(X_train,np.ravel(Y_train))","1b3d76b8":"pred3=model3.predict(X_test)","2167ebea":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model3,X,np.ravel(Y),cv=5)\nscores\nimport numpy as np\nnp.mean(scores)","958f0eee":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(Y_test,pred3)","2f46bfc2":"from sklearn.ensemble import RandomForestClassifier\nmodel4=RandomForestClassifier()\nmodel4.fit(X_train,np.ravel(Y_train))","cc6fc7fd":"pred4=model4.predict(X_test)","e41656c2":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model4,X,np.ravel(Y),cv=5)\nscores\nimport numpy as np\nnp.mean(scores)","d3ae1978":"model_parameters={\n    \"tree\":{\"model\":DecisionTreeClassifier(),\"params\":{}},\n    \"Naive Bayes\":{\"model\":GaussianNB(),\"params\":{}},\n    \"logistic regression\":{\"model\":LogisticRegression(),\"params\":{}},\n    \"Random forest classifier\":{\"model\":RandomForestClassifier(),\"params\":{}}\n}","803c786d":"from sklearn.model_selection import GridSearchCV\nimport pandas as pd\nscores=[]\nfor model_name, mp in model_parameters.items():\n    clf =  GridSearchCV(mp['model'],mp['params'], cv=10, return_train_score=False)\n    clf.fit(X, np.ravel(Y))\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        \n    })\ndf = pd.DataFrame(scores,columns=['model','best_score'])\ndf","2b6b8a24":"test.head(5)","296814ed":"test.describe()","7f67213b":"l1=pd.DataFrame(test.Age.fillna(int(test.Age.mean())))\nl2=pd.DataFrame(test.Embarked.fillna(\"S\"))\nl3=pd.DataFrame(test.Sex.fillna(test.Sex.mode()).map({\"male\":0,\"female\":1}))\nl4=pd.DataFrame(test.Fare)\nl5=pd.DataFrame(test.Pclass.fillna(test.Pclass.mode()))\nl6=pd.DataFrame(test.SibSp.fillna(test.SibSp.mode()))\nl7=pd.DataFrame(test.Parch)\nl8=pd.DataFrame(test.Cabin.fillna(test.Cabin.mode()))\nx1=pd.concat([l1,l2,l3,l4,l5,l6,l7,l8],axis=1)\n\nfrom sklearn import preprocessing\nle=preprocessing.LabelEncoder()\nx1.Embarked=le.fit_transform(x1.Embarked)","5aa3311c":"X=x[['Pclass','Sex','Fare','Embarked']]\nY=y[['Survived']]\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=0)\n\nfrom sklearn.tree import DecisionTreeClassifier\nmodel1=DecisionTreeClassifier()\nmodel1.fit(X_train,Y_train)","8c12bb23":"X1=x1[['Pclass','Sex','Fare','Embarked']]\nX2=np.nan_to_num(X1)","67760ab7":"x_1=test[['PassengerId']]\nx_1.columns=['passenger id']\npred=model1.predict(X2)\nvalue=pd.DataFrame(pred)\nvalue.columns=['survived']","cc496337":"submit=pd.concat([x_1,value],axis=1)\nsubmit","a7f67b07":"from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model1,X,np.ravel(Y),cv=5)\nscores\nimport numpy as np\nnp.mean(scores)","95e4ced0":"TESTING THE TEST DATA OF TITANIC:","c1168818":"IMPORTING THE DATASET","aa2b50bb":"THE PROCESS TO DECODE THE CATEGORICAL VARIABLE:","290dff71":"THEREFORE BELOW IS THE INDEPENDENT VARIBALE 'X' AND DEPENDENT VARIABLE 'Y'","aa25aaac":"TRAINING THE TRAIN DATA OF TITANIC:","ae434569":"LOGISTIC REGRESSION:","8de82520":"FROM THE CORREALTION MATRIX WE CAN SEE THAT 'PCLASS','SEX','FARE','EMBARKED' ARE HIGHLY CORRELATED WITH THE VARIABLE 'SURVIVED'.","c8e5547f":"RANDOM FOREST CLASSIFIER:","a02251be":"ACCURACY SCORE:","c7097b12":"GRAPHICAL REPRESENTATION","7132fcb0":"BEST _SCORE OF ALL THE ABOVE MODELS:","56b7fee8":"NAIVE BAYES CLASSIFIER:","669c5b9e":"IMPORTING ALL THE NECESSARY LIBARIES","a489c965":"AS FROM THE ABOVE SCORE WE CAN SEE THAT DECISION TREE CLASSIFIER WORKS THE BEST AMONG THEM.SO WE WILL USE THIS MODEL TO MAKE THE PREDICTIONS.","0509e10f":"DECISION TREE CLASSIFIER:","ca351b47":"TO CHECK THE FIRST FEW OBSERVATIONS:","b52d40b8":"SUMMARY OF THE TEST DATA","af9bb20c":"ACCURACY RATE COMES OUT TO BE 81.13%.","c2d4d9ab":"THE SUMMARY OF THE TRAINING DATASET OF TITANIC:","66d9964e":"BOXPLOT","722c7f93":"THE PROCESS TO DECODE THE CATEGORICAL VARIABLE:","e66876d3":"BELOW WE ARE APPLYING SOME MODELS ON THE TRAINING DATASET","0d529e58":"TO CHECK THE FIRST FEW OBSERVATIONS OF TEST DATA","fe4606ba":"SPLITTING THE DATASET INTO TRAINING AND TESTING DATASET:","d93e0aca":"CORRELATION MATRIX:"}}