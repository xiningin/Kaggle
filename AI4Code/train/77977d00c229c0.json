{"cell_type":{"b6109928":"code","fdf976b2":"code","7f75a01a":"code","712e2d8e":"code","2ff1ba13":"code","c338811e":"code","70dfdbdd":"code","c8f6278a":"code","c1a522df":"code","aa8848e6":"code","7b3434a3":"code","d90ac782":"code","a99e3365":"code","fd3df381":"code","53d2186a":"code","9557eca4":"code","a941fefc":"code","0fbbce05":"code","4972bc31":"code","d50c3654":"code","37c17212":"code","0444fc3c":"code","ff1ac42b":"code","fe08f98e":"code","41a19160":"code","433f8a39":"code","a7c0662e":"code","3d7da69e":"code","4b26a120":"code","a53d5a07":"code","7e37e861":"code","e109cd2f":"code","1bfed8d1":"code","68006cba":"code","1068fcd7":"code","6278c493":"code","4ce84819":"code","ae983add":"code","81a3620e":"code","b94ea264":"code","c243ad8d":"code","9cc7e60d":"code","6f0a9cd0":"markdown","b704217f":"markdown","4266ba9f":"markdown","e0129430":"markdown","0899ae0c":"markdown","7c07490a":"markdown","2e3b1568":"markdown","c5f69938":"markdown","9308e0e4":"markdown","26a81da1":"markdown","feaa8bcc":"markdown","070ea634":"markdown","3983814c":"markdown","18d6470a":"markdown"},"source":{"b6109928":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdf976b2":"import os, random, re, math, time\nrandom.seed(a=42)\nimport numpy as np\n\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport PIL\nfrom kaggle_datasets import KaggleDatasets\nfrom tqdm import tqdm","7f75a01a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n## import the dataset\ndftrain = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ndftest = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')","712e2d8e":"## Missing values in training data\ndftrain.isna().any()\ndftrain = dftrain.dropna()\n\n## Missing values in testing data\ndftest.isna().any()\ndftest = dftest.dropna()\n","2ff1ba13":"print(\"Count of male and female \", dftrain.sex.value_counts())\nprint(\"uniques in anatom_site_general_challenge column \", dftrain.anatom_site_general_challenge.unique())\nprint(\"uniques in diagnosis column \", dftrain.diagnosis.unique())\nprint(\"uniques in benign_malignant column \", dftrain.benign_malignant.unique())","c338811e":"sns.kdeplot(dftrain[(dftrain['target'] == 1)].age_approx, shade = True)","70dfdbdd":"dummy = dftrain[dftrain['target'] == 1]\n\nsns.barplot(x = \"sex\", y = \"target\", data = dummy, hue =\"sex\")\n\n","c8f6278a":"# viewing the distributions of data \n\nsns.barplot(x = \"target\", y = \"target\", data = dftrain, hue =\"target\")\n\n## hence the number of unaffected surpasses the affected, we need to normalise this data. But we need to understand \n# various other columns before normalising this data","c1a522df":"print(\"no of unaffected males  : \", len(dftrain[(dftrain['target'] == 0) & (dftrain['sex'] == 'male')]))\nprint(\"no of unaffected females  : \", len(dftrain[(dftrain['target'] == 0) & (dftrain['sex'] == 'female')]))\n\n## not. much of a difference in. the ratios","aa8848e6":"sns.barplot(x = \"anatom_site_general_challenge\", y = \"target\", data = dftrain, hue =\"anatom_site_general_challenge\")\n","7b3434a3":"## looking at the unique values of anatom_site_general_challenge column\n\ndftrain.anatom_site_general_challenge.unique()","d90ac782":"# looking at the number of unique values of anatom_site_general_challenge column\n\ndf = dftrain.copy()\nprint(\"no of head\/neck  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'head\/neck')]))\nprint(\"no of upper extremity  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'upper extremity')]))\nprint(\"no of lower extremity  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'lower extremity')]))\nprint(\"no of torso  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'torso')]))\nprint(\"no of palms\/soles'  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'palms\/soles')]))\nprint(\"no of oral\/genital'  : \", len(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'oral\/genital')]))","a99e3365":"## number of affected in the whole dataset\n\nprint(\"no of affected : \", len(dftrain[dftrain['target'] == 1]))","fd3df381":"temp = dftrain[dftrain['target'] == 1]\n\n## for training  (500 samples)\nfinal_df = temp[:500]\n\n## for testing (75 samples)\naffected_validationdata = temp[500:]","53d2186a":"def random_data_selector(data, n):\n    data =  data.sample(n = n)\n    return data\n\n\ndf = dftrain.copy()\n\n## selecting samples for testing (100 samples)\ntemp  = df[df['target'] == 0]\nunaffected_validationdata = temp[:100]\n\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'head\/neck')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'upper extremity')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'lower extremity')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'torso')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'palms\/soles')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\ndata = random_data_selector(df[(df['target'] == 0) & (df['anatom_site_general_challenge'] == 'oral\/genital')], 100)\nfinal_df = final_df.append(data, ignore_index = True)\n\n","9557eca4":"final_df.head()","a941fefc":"## finding the number of infected\nlen(final_df[final_df['target'] == 1])","0fbbce05":"## finding the number of infected\nlen(final_df[final_df['target'] == 0])","4972bc31":"## shuffle the dataset\n\nimport sklearn\n\nfinal_df  = sklearn.utils.shuffle(final_df)","d50c3654":"import cv2\nimport pathlib\nimport imageio\nfrom skimage.transform import resize\nimport numpy as np\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\n\n\n\n#converting normal images into numpy array\n\n\ntraining_paths = pathlib.Path('..\/input\/siim-isic-melanoma-classification\/jpeg').glob('train\/*.jpg')\ntraining_sorted = sorted([x for x in training_paths])\ndirectory_path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\n\n\n\nfor index in range(len(training_sorted)) : training_sorted[index] = str(training_sorted[index])    \n    \ntraining_images = np.zeros(150528)\ntraining_images = training_images.reshape(1,224,224,3)\n\nfor index in range(len(final_df)):\n    img_name = final_df.loc[index].image_name\n    img_name = str(directory_path +  img_name + '.jpg')\n    position_in_list = training_sorted.index(img_name)\n    img_path = training_sorted[position_in_list]\n    \n    img = image.load_img(img_path, target_size = (224,224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n    x = preprocess_input(x)    \n    training_images = np.vstack((training_images, x))\n\n    ","37c17212":"## making the xtrain data ready\n\nxtraindf = training_images.copy()\nxtraindf = xtraindf[1:]\nxtraindf.shape\n","0444fc3c":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(5,5, figsize=(8,8))\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(xtraindf[i])","ff1ac42b":"## making the ytrain data ready\n\nytraindf = final_df.target\nytraindf.head()","fe08f98e":"affected_validationdata = affected_validationdata.append(unaffected_validationdata)\ntestdata_copy = affected_validationdata.copy()","41a19160":"testdata_copy.head()","433f8a39":"print(\"affected : \", len(testdata_copy[testdata_copy['target'] == 1]))\nprint(\"unaffected : \", len(testdata_copy[testdata_copy['target'] == 0]))","a7c0662e":"## shuffle the df \nimport sklearn\n\ntestdata_copy  = sklearn.utils.shuffle(testdata_copy).reset_index(drop=True)","3d7da69e":"testdata_copy.tail()","4b26a120":"\n\n#converting normal images into numpy array\n\n\ntest_paths = pathlib.Path('..\/input\/siim-isic-melanoma-classification\/jpeg\/').glob('train\/*.jpg')\ntest_sorted = sorted([x for x in test_paths])\ndirectory_path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\n\n\n\nfor index in range(len(test_sorted)) : test_sorted[index] = str(test_sorted[index])    \n    \ntest_images = np.zeros(150528)\ntest_images = test_images.reshape(1,224,224,3)\n\nfor index in range(len(testdata_copy)):\n    img_name = testdata_copy.loc[index].image_name\n    img_name = str(directory_path +  img_name + '.jpg')\n    \n    position_in_list = test_sorted.index(img_name)\n    img_path = test_sorted[position_in_list]\n    \n    img = image.load_img(img_path, target_size = (224,224))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n    x = preprocess_input(x)    \n    test_images = np.vstack((test_images, x))\n        \n\n    ","a53d5a07":"## Making the xtest data ready\n\nxtestdf = test_images.copy()\nxtestdf = xtestdf[1:]\nxtestdf.shape\n","7e37e861":"## plotting the images\n\nimport matplotlib.pyplot as plt\nfig, axes = plt.subplots(5,5, figsize=(8,8))\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(xtestdf[i])","e109cd2f":"## making the ytest data ready\n\nytestdf = testdata_copy.target\nytestdf.head()","1bfed8d1":"from keras.applications.resnet50 import ResNet50\n\nimg_rows, img_cols = 224, 224\n\n\nresnet = ResNet50(weights = 'imagenet',\n                      include_top = False,\n                      input_shape  =  (img_rows,  img_cols, 3))\n\n## lets freeze the last  4 layers as they  are set to be trainable by  default\nfor layer in  resnet.layers:\n  layer.trainable = False\n\n## lets look at our layers\nfor (i, layer) in enumerate(resnet.layers):\n  print(str(i)  + \" \"  +  layer.__class__.__name__, layer.trainable)","68006cba":"\n## Let us  create a function to build our top layer\n\ndef addTopMobileNetLayer(bottom_model, num_classes):\n\n  top_model = bottom_model.output\n  top_model = GlobalAveragePooling2D()(top_model)\n  top_model = (Dense(2048, activation = 'relu'))(top_model)\n  top_model = (Dense(2048, activation = 'relu'))(top_model)\n  top_model = (Dense(1024, activation = 'relu'))(top_model)\n  top_model = (Dense(num_classes, activation  = 'softmax'))(top_model)\n\n  return top_model","1068fcd7":"from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Activation,  Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\n\nnum_classes = 2\n\nFC_head = addTopMobileNetLayer(resnet, num_classes)\n\nmodel  = Model(inputs =  resnet.input, outputs = FC_head)\n\nprint(model.summary())","6278c493":"\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 3,\n                          verbose = 1,\n                          restore_best_weights = True)\n\ncallbacks = [earlystop]\n\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 0.005), metrics = ['accuracy'])","4ce84819":"epochs = 10\n\n\nhistory = model.fit(xtraindf, \n          ytraindf,\n          batch_size = 8,\n          epochs = epochs,\n          verbose = 1,\n          callbacks = callbacks,\n          validation_data = (xtestdf, ytestdf)\n          )","ae983add":"\nimport tensorflow\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import TensorBoard","81a3620e":"model = Sequential()\nmodel.add(Conv2D(24,3,3, input_shape = (224,224,3), activation = 'relu'))\nmodel.add(Conv2D(36,3,3, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Conv2D(36,3,3, activation = 'relu'))\nmodel.add(Conv2D(36,3,3,  activation = 'relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units = 2028, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 1024, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 512, activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))","b94ea264":"model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr = 0.005), metrics = ['accuracy'])\nepochs = 10\n\n\nhistory = model.fit(xtraindf, \n          ytraindf,\n          batch_size = 64,\n          epochs = epochs,\n          verbose = 1,\n          validation_data = (xtestdf, ytestdf))","c243ad8d":"#plot of validation vs training accuracy over the epochs\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training', 'validation'])\nplt.title('Loss')\nplt.xlabel('Epoch')","9cc7e60d":"ypred = model.predict(xtestdf)\nevaluation = model.evaluate(xtestdf, ytestdf)\nprint('Test accuracy : {:.3f}'.format(evaluation[1]))","6f0a9cd0":"#### Below chart is the distribution of anatom site challenge","b704217f":"# ResNet50 model\n","4266ba9f":"### visualizations\n","e0129430":"#### convert test images to numpy arrays","0899ae0c":"### Test data analysis","7c07490a":"### check for missing values","2e3b1568":"### lets see the distributions of sex  in  unaffected before removing normalizing","c5f69938":"## Reading in the data","9308e0e4":"#### Below plot is the distribution of sex of those affected","26a81da1":"### check unique values in each column","feaa8bcc":"### My CNN","070ea634":"#### Below plot is the distribution of age of those affected","3983814c":"#### selecting few samples randomly from the unaffected to normalize  the data","18d6470a":"#### Comparision of affected (0 - blue) to unaffected (1 - orange)"}}