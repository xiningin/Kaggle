{"cell_type":{"dc36a725":"code","43a8e073":"code","87c484aa":"code","0a02abd5":"code","94976c08":"code","e9146471":"code","927d74fc":"code","017c41bf":"code","6738c424":"code","acd82e60":"code","a18f5de4":"code","4c568f3e":"code","0ae52227":"code","e8da1ffc":"code","63ea4418":"code","52fb5100":"code","292bcfe8":"code","294afa0d":"code","2f15f6e9":"code","f53ae5d6":"code","1bd0344d":"code","83d05ee0":"code","45514258":"code","bffd0b50":"code","c29a51c0":"code","4afc1b26":"code","1d15fbb5":"code","5029b465":"code","24306f54":"code","7ce6f077":"code","e36f731c":"code","e333ea16":"code","7520667b":"markdown","416c0733":"markdown","9303c33f":"markdown","5b733557":"markdown","16f6f9bd":"markdown","9b57b4f1":"markdown","b9a4ec2c":"markdown","6c7b6bd9":"markdown","bd394173":"markdown","327d1a36":"markdown","775afe26":"markdown","ee85aefa":"markdown","ac95160d":"markdown","35809a4c":"markdown","79f37397":"markdown","c1b7cb18":"markdown","f4510f9f":"markdown","48060a72":"markdown","090001d6":"markdown","f6f0fa2e":"markdown","d1dfbf21":"markdown"},"source":{"dc36a725":"import numpy as np\nimport pandas as pd\nimport cv2\nimport json\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns","43a8e073":"DATASET_DIR = '\/kaggle\/input\/pku-autonomous-driving\/'\nJSON_DIR = os.path.join(DATASET_DIR, 'car_models_json')\nNUM_IMG_SAMPLES = 10 # The number of image samples used for visualization","87c484aa":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","0a02abd5":"df.head()","94976c08":"image_ids = np.array(df['ImageId'])\nprediction_strings = np.array(df['PredictionString'])\nprediction_strings = [\n    np.array(prediction_string.split(' ')).astype(np.float32).reshape(-1, 7) \\\n    for prediction_string in prediction_strings\n]","e9146471":"print('Image ID:', image_ids[0])\nprint('Annotations:\\n', prediction_strings[0])","927d74fc":"# https:\/\/raw.githubusercontent.com\/ApolloScapeAuto\/dataset-api\/master\/car_instance\/car_models.py\nmodels = {\n    #           name                id\n         'baojun-310-2017':          0,\n            'biaozhi-3008':          1,\n      'biaozhi-liangxiang':          2,\n       'bieke-yinglang-XT':          3,\n            'biyadi-2x-F0':          4,\n           'changanbenben':          5,\n            'dongfeng-DS5':          6,\n                 'feiyate':          7,\n     'fengtian-liangxiang':          8,\n            'fengtian-MPV':          9,\n       'jilixiongmao-2015':         10,\n       'lingmu-aotuo-2009':         11,\n            'lingmu-swift':         12,\n         'lingmu-SX4-2012':         13,\n          'sikeda-jingrui':         14,\n    'fengtian-weichi-2006':         15,\n               '037-CAR02':         16,\n                 'aodi-a6':         17,\n               'baoma-330':         18,\n               'baoma-530':         19,\n        'baoshijie-paoche':         20,\n         'bentian-fengfan':         21,\n             'biaozhi-408':         22,\n             'biaozhi-508':         23,\n            'bieke-kaiyue':         24,\n                    'fute':         25,\n                 'haima-3':         26,\n           'kaidilake-CTS':         27,\n               'leikesasi':         28,\n           'mazida-6-2015':         29,\n              'MG-GT-2015':         30,\n                   'oubao':         31,\n                    'qiya':         32,\n             'rongwei-750':         33,\n              'supai-2016':         34,\n         'xiandai-suonata':         35,\n        'yiqi-benteng-b50':         36,\n                   'bieke':         37,\n               'biyadi-F3':         38,\n              'biyadi-qin':         39,\n                 'dazhong':         40,\n          'dazhongmaiteng':         41,\n                'dihao-EV':         42,\n  'dongfeng-xuetielong-C6':         43,\n 'dongnan-V3-lingyue-2011':         44,\n'dongfeng-yulong-naruijie':         45,\n                 '019-SUV':         46,\n               '036-CAR01':         47,\n             'aodi-Q7-SUV':         48,\n              'baojun-510':         49,\n                'baoma-X5':         50,\n         'baoshijie-kayan':         51,\n         'beiqi-huansu-H3':         52,\n          'benchi-GLK-300':         53,\n            'benchi-ML500':         54,\n     'fengtian-puladuo-06':         55,\n        'fengtian-SUV-gai':         56,\n'guangqi-chuanqi-GS4-2015':         57,\n    'jianghuai-ruifeng-S3':         58,\n              'jili-boyue':         59,\n                  'jipu-3':         60,\n              'linken-SUV':         61,\n               'lufeng-X8':         62,\n             'qirui-ruihu':         63,\n             'rongwei-RX5':         64,\n         'sanling-oulande':         65,\n              'sikeda-SUV':         66,\n        'Skoda_Fabia-2011':         67,\n        'xiandai-i25-2016':         68,\n        'yingfeinidi-qx80':         69,\n         'yingfeinidi-SUV':         70,\n              'benchi-SUR':         71,\n             'biyadi-tang':         72,\n       'changan-CS35-2012':         73,\n             'changan-cs5':         74,\n      'changcheng-H6-2016':         75,\n             'dazhong-SUV':         76,\n 'dongfeng-fengguang-S560':         77,\n   'dongfeng-fengxing-SX6':         78\n}","017c41bf":"models_map = dict((y, x) for x, y in models.items())","6738c424":"cars = []\nfor prediction_string in prediction_strings:\n    for car in prediction_string:\n        cars.append(car)\ncars = np.array(cars)","acd82e60":"unique, counts = np.unique(cars[..., 0].astype(np.uint8), return_counts=True)\nall_model_types = zip(unique, counts)\n\nfor i, model_type in enumerate(all_model_types):\n    print('{}.\\t Model type: {:<22} | {} cars'.format(i, models_map[model_type[0]], model_type[1]))","a18f5de4":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels,\n    explode,\n    colors=None,\n):\n    fig, ax = plt.subplots(figsize=(14, 14))\n\n    y_pos = np.arange(len(labels))\n    barlist = ax.bar(y_pos, sizes, align='center')\n    ax.set_xticks(y_pos, labels)\n    ax.set_ylabel(bar_ylabel)\n    ax.set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            ax.text(\n                rect.get_x() + rect.get_width()\/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    fig, ax = plt.subplots(figsize=(14, 14))\n    \n    pielist = ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=start_angle, counterclock=False)\n    ax.axis('equal')\n    ax.set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","4c568f3e":"plot_figures(\n    counts,\n    pie_title='The percentage of the number of cars of each model type',\n    start_angle=170,\n    bar_title='Distribution of cars of each model type',\n    bar_ylabel='Frequency',\n    labels=[label for label in unique],\n    explode=np.zeros(len(unique))\n)","0ae52227":"# Get all json files\nfiles = [file for file in os.listdir(JSON_DIR) if os.path.isfile(os.path.join(JSON_DIR, file))]\n\n# For each json file, plot figure\nfor file in files:\n    model_path = os.path.join(JSON_DIR, file)\n    with open(model_path) as src:\n        data = json.load(src)\n        car_type = data['car_type']\n        faces = data['faces']\n        vertices = np.array(data['vertices'])\n        triangles = np.array(faces) - 1\n\n        fig = plt.figure(figsize=(16, 5))\n        ax11 = fig.add_subplot(1, 2, 1, projection='3d')\n        ax11.set_title('Model: {} | Type: {}'.format(file.split('.')[0], car_type))\n        ax11.set_xlim([-2, 3])\n        ax11.set_ylim([-3, 2])\n        ax11.set_zlim([0, 3])\n        ax11.view_init(30, -50)\n        ax11.plot_trisurf(vertices[:,0], vertices[:,2], triangles, -vertices[:,1], shade=True, color='lime')\n        \n        ax12 = fig.add_subplot(1, 2, 2, projection='3d')\n        ax12.set_title('Model: {} | Type: {}'.format(file.split('.')[0], car_type))\n        ax12.set_xlim([-2, 3])\n        ax12.set_ylim([-3, 2])\n        ax12.set_zlim([0, 3])\n        ax12.view_init(30, 40)\n        ax12.plot_trisurf(vertices[:,0], vertices[:,2], triangles, -vertices[:,1], shade=True, color='lime')","e8da1ffc":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(18, 16))\n        \n        # Get image\n        img_path = os.path.join(DATASET_DIR, 'train_images', '{}.{}'.format(sample, 'jpg'))\n        img = cv2.imread(img_path, 1)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        # Get corresponding mask\n        mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(sample, 'jpg'))\n        mask = cv2.imread(mask_path, 0)\n\n        patches = []\n        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=2, edgecolor='r', facecolor='r', fill=True)\n            patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet, alpha=0.3)\n\n        ax.imshow(img\/255)\n        ax.set_title(sample)\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","63ea4418":"# Randomly select samples\nsamples = image_ids[np.random.choice(image_ids.shape[0], NUM_IMG_SAMPLES, replace=False)]\n\n# Show images and corresponding masks of too-far-away (not of interest) cars\nshow_samples(samples)","52fb5100":"import seaborn as sns\nimread = cv2.imread\nPATH = DATASET_DIR\ntrain = df\n\ndef imread(path, fast_mode=False):\n    img = cv2.imread(path)\n    if not fast_mode and img is not None and len(img.shape) == 3:\n        img = np.array(img[:, :, ::-1])\n    return img\n\n# From camera.zip\ncamera_matrix = np.array([[2304.5479, 0,  1686.2379],\n                          [0, 2305.8757, 1354.9849],\n                          [0, 0, 1]], dtype=np.float32)\ncamera_matrix_inv = np.linalg.inv(camera_matrix)\n\ndef str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n    '''\n    Input:\n        s: PredictionString (e.g. from train dataframe)\n        names: array of what to extract from the string\n    Output:\n        list of dicts with keys from `names`\n    '''\n    coords = []\n    for l in np.array(s.split()).reshape([-1, 7]):\n        coords.append(dict(zip(names, l.astype('float'))))\n        if 'id' in coords[-1]:\n            coords[-1]['id'] = int(coords[-1]['id'])\n    return coords","292bcfe8":"from math import sin, cos\n\n# convert euler angle to rotation matrix\ndef euler_to_Rot(yaw, pitch, roll):\n    Y = np.array([[cos(yaw), 0, sin(yaw)],\n                  [0, 1, 0],\n                  [-sin(yaw), 0, cos(yaw)]])\n    P = np.array([[1, 0, 0],\n                  [0, cos(pitch), -sin(pitch)],\n                  [0, sin(pitch), cos(pitch)]])\n    R = np.array([[cos(roll), -sin(roll), 0],\n                  [sin(roll), cos(roll), 0],\n                  [0, 0, 1]])\n    return np.dot(Y, np.dot(P, R))\n\ndef draw_line(image, points):\n    color = (255, 0, 0)\n    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n    return image\n\n\ndef draw_points(image, points):\n    for (p_x, p_y, p_z) in points:\n        cv2.circle(image, (p_x, p_y), int(1000 \/ p_z), (0, 255, 0), -1)\n#         if p_x > image.shape[1] or p_y > image.shape[0]:\n#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n    return image","294afa0d":"lens = [len(str2coords(s)) for s in train['PredictionString']]\n\nplt.figure(figsize=(15,6))\nsns.countplot(lens);\nplt.xlabel('Number of cars in image');","2f15f6e9":"points_df = pd.DataFrame()\nfor col in ['x', 'y', 'z', 'yaw', 'pitch', 'roll']:\n    arr = []\n    for ps in train['PredictionString']:\n        coords = str2coords(ps)\n        arr += [c[col] for c in coords]\n    points_df[col] = arr","f53ae5d6":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['x'], bins=500);\nplt.xlabel('x')\nplt.show()","1bd0344d":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['y'], bins=500);\nplt.xlabel('y')\nplt.show()","83d05ee0":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['z'], bins=500);\nplt.xlabel('z')\nplt.show()","45514258":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['yaw'], bins=500);\nplt.xlabel('yaw')\nplt.show()","bffd0b50":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['pitch'], bins=500);\nplt.xlabel('pitch')\nplt.show()","c29a51c0":"def rotate(x, angle):\n    x = x + angle\n    x = x - (x + np.pi) \/\/ (2 * np.pi) * 2 * np.pi\n    return x\n\nplt.figure(figsize=(15,6))\nsns.distplot(points_df['roll'].map(lambda x: rotate(x, np.pi)), bins=500);\nplt.xlabel('roll rotated by pi')\nplt.show()","4afc1b26":"def get_img_coords(input_item, input_type=str, output_z=False):\n    '''\n    Input is a PredictionString (e.g. from train dataframe)\n    Output is two arrays:\n        xs: x coordinates in the image (row)\n        ys: y coordinates in the image (column)\n    '''\n    if input_type == str:\n        coords = str2coords(input_item)\n    else:\n        coords = input_item\n    \n    xs = [c['x'] for c in coords]\n    ys = [c['y'] for c in coords]\n    zs = [c['z'] for c in coords]\n    P = np.array(list(zip(xs, ys, zs))).T\n    img_p = np.dot(camera_matrix, P).T\n    img_p[:, 0] \/= img_p[:, 2]\n    img_p[:, 1] \/= img_p[:, 2]\n    img_xs = img_p[:, 0]\n    img_ys = img_p[:, 1]\n    img_zs = img_p[:, 2] # z = Distance from the camera\n    if output_z:\n        return img_xs, img_ys, img_zs\n    return img_xs, img_ys\n\nplt.figure(figsize=(14,14))\nplt.imshow(imread(PATH + 'train_images\/' + train['ImageId'][2217] + '.jpg'))\nplt.scatter(*get_img_coords(train['PredictionString'][2217]), color='red', s=100);","1d15fbb5":"xs, ys = [], []\n\nfor ps in train['PredictionString']:\n    x, y = get_img_coords(ps)\n    xs += list(x)\n    ys += list(y)\n\nplt.figure(figsize=(18,18))\nplt.imshow(imread(PATH + 'train_images\/' + train['ImageId'][2217] + '.jpg'), alpha=0.3)\nplt.scatter(xs, ys, color='red', s=10, alpha=0.2);","5029b465":"def visualize(img, coords):\n    # You will also need functions from the previous cells\n    x_l = 1.02\n    y_l = 0.80\n    z_l = 2.31\n    \n    img = img.copy()\n    for point in coords:\n        # Get values\n        x, y, z = point['x'], point['y'], point['z']\n        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n        # Math\n        Rt = np.eye(4)\n        t = np.array([x, y, z])\n        Rt[:3, 3] = t\n        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n        Rt = Rt[:3, :]\n        P = np.array([[x_l, -y_l, -z_l, 1],\n                      [x_l, -y_l, z_l, 1],\n                      [-x_l, -y_l, z_l, 1],\n                      [-x_l, -y_l, -z_l, 1],\n                      [0, 0, 0, 1]]).T\n        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n        img_cor_points = img_cor_points.T\n        img_cor_points[:, 0] \/= img_cor_points[:, 2]\n        img_cor_points[:, 1] \/= img_cor_points[:, 2]\n        img_cor_points = img_cor_points.astype(int)\n        # Drawing\n        img = draw_line(img, img_cor_points)\n        img = draw_points(img, img_cor_points[-1:])\n    \n    return img","24306f54":"n_rows = 6\n\nfor idx in range(n_rows):\n    fig, axes = plt.subplots(1, 2, figsize=(20,20))\n    img = imread(PATH + 'train_images\/' + train['ImageId'].iloc[idx] + '.jpg')\n    axes[0].imshow(img)\n    img_vis = visualize(img, str2coords(train['PredictionString'].iloc[idx]))\n    axes[1].imshow(img_vis)\n    plt.show()","7ce6f077":"import random\nsample_index_list = random.sample(list(range(len(points_df))), 5000)\nv = np.vstack([points_df['x'][sample_index_list], points_df['y'][sample_index_list], \n               points_df['z'][sample_index_list], points_df['yaw'][sample_index_list], \n               points_df['pitch'][sample_index_list], points_df['roll'][sample_index_list]])\nCM = np.corrcoef(v)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nim = ax.imshow(CM)\nax.set_xticks(np.arange(6))\nax.set_yticks(np.arange(6))\nax.set_xticklabels(['x', 'y', 'z', 'yaw', 'pitch', 'roll'])\nax.set_yticklabels(['x', 'y', 'z', 'yaw', 'pitch', 'roll'])\nfor i in range(6):\n    for j in range(6):\n        text = ax.text(j, i, round(CM[i, j], 2),\n                       ha=\"center\", va=\"center\", color=\"w\")\nfig.tight_layout()\nplt.show()","e36f731c":"coords = []\nfor sample_index in sample_index_list:\n    coord = {}\n    coord['x'] = points_df['x'][sample_index] \n    coord['y'] = points_df['y'][sample_index] \n    coord['z'] = points_df['z'][sample_index]\n    coords.append(coord)\nimg_x_list, img_y_list, img_z_list = get_img_coords(coords, input_type=list, output_z=True)\n\nv = np.vstack([points_df['x'][sample_index_list], points_df['y'][sample_index_list], \n               points_df['z'][sample_index_list], img_x_list, img_y_list, img_z_list])\nCM = np.corrcoef(v)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nim = ax.imshow(CM)\nax.set_xticks(np.arange(6))\nax.set_yticks(np.arange(6))\nax.set_xticklabels(['x', 'y', 'z', 'img_x', 'img_y', 'img_z'])\nax.set_yticklabels(['x', 'y', 'z', 'img_x', 'img_y', 'img_z'])\nfor i in range(6):\n    for j in range(6):\n        text = ax.text(j, i, round(CM[i, j], 2),\n                       ha=\"center\", va=\"center\", color=\"w\")\nfig.tight_layout()\nplt.show()","e333ea16":"mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(image_ids[0], 'jpg'))\nmask_accru = cv2.imread(mask_path, 0).astype(np.int) \/ 255\nfor id in image_ids[1:]:\n    mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(id, 'jpg'))\n    try:\n        mask = cv2.imread(mask_path, 0).astype(np.int) \/ 255\n        mask_accru = np.add(mask_accru, mask)\n    except:\n        pass\n\nfig, ax = plt.subplots(figsize=(18, 16))\nax.set_title('mask distribution')\nim = ax.imshow(mask_accru)\nplt.show()","7520667b":"# Initial Data Exploration\n\nNote that this notebook is a changed version of https:\/\/www.kaggle.com\/phunghieu\/a-quick-simple-eda and https:\/\/www.kaggle.com\/hocop1\/centernet-baseline. Thank you guys!, Also I added two parts by myself.","416c0733":"and see the relations among coordinates.","9303c33f":"# Import modules","5b733557":"Let's get 5000 samples from the labels to see if some relations are among the dimensions of poses,","16f6f9bd":"# Configure parameters","9b57b4f1":"# 2D Visualization","b9a4ec2c":"The distribution of car types is imbalanced.\nThe distribution of each other dimension of labels is highly imbalanced.\nThe upper halfs of images are less useful or useless.\nThe dimensions y and z are extremely correlated.\nThe dimensions x and z are less correlated.\nMasks are distributed mostly at far ends.","6c7b6bd9":"# Plot all 3D car models\n### Plotting logic for car models is based on this awesome [kernel](https:\/\/www.kaggle.com\/ebouteillon\/load-a-3d-car-model) created by Eric Bouteillon (@ebouteillon)\n### Also, let's check out [3D Interactive Car with Plotly](https:\/\/www.kaggle.com\/subinium\/3d-interactive-car-with-plotly) created by Subin An (@subinium), the visualization of car models in this kernel is absolutely wonderful!!!","bd394173":"# Data distributions","327d1a36":"# Visualize some images","775afe26":"# Plot some figures","ee85aefa":"# Get annotations","ac95160d":"The following is my analysis.","35809a4c":"# 3D Visualization","79f37397":"# Conclusion","c1b7cb18":"Let's look at the distribution of all points. Image is here just for reference.","f4510f9f":"# Correlation Matrices","48060a72":"Start from Hieu Phung\u2018s notebook.","090001d6":"# Get all model-types","f6f0fa2e":"Then go to Ruslan Baynazarov's notebook.","d1dfbf21":"# Mask Distribution"}}