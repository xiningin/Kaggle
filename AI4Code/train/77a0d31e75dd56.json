{"cell_type":{"4b1e9f94":"code","fb304e1d":"code","b06ceebb":"code","53e38aa3":"code","25006fe9":"code","7e044557":"code","1aaf41bb":"code","908bc749":"code","1185b2ef":"code","a1f5388d":"markdown","1dfe219d":"markdown","8f0d0868":"markdown","728d7b54":"markdown"},"source":{"4b1e9f94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb304e1d":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","b06ceebb":"# Features Selection\nfeatures = ['Pclass','Sex','SibSp','Parch','Fare','Age']\n\n# from sklearn.preprocessing import StandardScaler\n# sc = StandardScaler()\n# sc.fit_transform(features[4,5])\n# x_test = sc.fit_transform()\n\nx = pd.get_dummies(train_data[features])\nx_test = pd.get_dummies(test_data[features])\ny = train_data[\"Survived\"]\n","53e38aa3":"# handlin NaN in Fare and Age\nx['Fare'].fillna(x['Fare'].mode()[0], inplace=True)\nx_test['Fare'].fillna(x_test['Fare'].mode()[0], inplace=True)\n\n# Handling NaN in Age\nx['Age'].fillna(x['Age'].mode()[0], inplace=True)\nx_test['Age'].fillna(x_test['Age'].mode()[0], inplace=True)\n","25006fe9":"# Algorithm Tuning\nfrom scipy.stats import uniform as sp_rand\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_grid = {'alpha': sp_rand()}\nmodel = Ridge()\nrsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\nrsearch.fit(x,y)\nprint(rsearch)","7e044557":"# the Model)\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=10,criterion='entropy',n_jobs=-1, random_state=42)\nrfc.fit(x,y)\ny_pred = rfc.predict(x_test)\ny_pred\nplt.hist(y_pred)\n# The accuracy score as shown by from kaggle report is 0.77511","1aaf41bb":"# # plotting a contour map with logreg using the Visualising the Training set results\n# from matplotlib.colors import ListedColormap\n# X_set, y_set = x, y\n# X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step =\n# 0.01),\n# np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n# plt.contourf(X1, X2, logreg.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n# alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n# plt.xlim(X1.min(), X1.max())\n# plt.ylim(X2.min(), X2.max())\n# for i, j in enumerate(np.unique(y_set)):\n#     plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n# c = ListedColormap(('red', 'green'))(i), label = j)\n# plt.title('Logistic Regression (Training set)')\n# plt.xlabel('Pclass and Parch')\n# plt.ylabel('Survived')\n# plt.legend()\n","908bc749":"# to save the output: i.e the prediction\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\noutput.to_csv('submission3.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1185b2ef":"# women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n# rate_women = sum(women)\/len(women)\n\n# print(\"% of women who survived:\", rate_women)","a1f5388d":"# Logistic Regression Model","1dfe219d":"# **Titanic Data**","8f0d0868":"# **Features' Selection and Engineering**","728d7b54":"# Ensemble Model"}}