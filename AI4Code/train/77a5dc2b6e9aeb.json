{"cell_type":{"3f107756":"code","95ce6027":"code","cf23fc2b":"code","ae25c70a":"code","384370b5":"code","7ff9456d":"code","4473f382":"code","dd924436":"code","fab5fae5":"code","54b92ef2":"code","03974670":"code","7711829c":"code","5c7b82d0":"code","3fe16ef2":"code","1194e25d":"code","5b58083c":"code","95041118":"code","fb338b5f":"code","515f7abf":"code","4010abfa":"code","7b2ae25a":"code","d35a6b7f":"code","e2303ea9":"code","1035a16b":"code","47a1ba67":"code","252beb53":"code","71585793":"code","4796c6d2":"code","9f1b889d":"code","e8b12d2d":"code","7f149f16":"code","4b080563":"code","ad4e71ae":"code","a240fac7":"code","0ca160dc":"code","e666bb1e":"code","f5db2201":"code","7c9e6235":"code","12bfea55":"code","ee2f235d":"code","d08b0095":"code","f20e0bed":"code","104aafe8":"code","d1e95dcb":"code","b421621e":"code","61a6c1b0":"code","02afe468":"code","f23674db":"code","333ade22":"code","f3a8d461":"code","b2f4d8ba":"code","f0daeb45":"code","be4a3ab0":"code","d9929bb0":"code","95ba5deb":"code","c20a1bdb":"code","de54b624":"code","b9e09b0a":"code","cb067bc0":"code","897b1db1":"code","73e01088":"code","fa0b305c":"code","b966bce7":"markdown","6e5832b4":"markdown","a42a679d":"markdown","8f34f950":"markdown","bb9d8cc5":"markdown","7e2640d6":"markdown","718fdb78":"markdown","655ebac4":"markdown","6b86ce48":"markdown","fdcc4dad":"markdown","d5bb2962":"markdown","b45cb840":"markdown","35138627":"markdown","0a3c03c9":"markdown","5db74fa4":"markdown","defd3f74":"markdown","94935959":"markdown","c1c72ea6":"markdown","ac78a0fe":"markdown"},"source":{"3f107756":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","95ce6027":"path = '..\/input\/Kannada-MNIST\/'","cf23fc2b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image","ae25c70a":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix","384370b5":"from keras.utils import to_categorical\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nfrom keras.callbacks import EarlyStopping","7ff9456d":"\"\"\"\nhelper function to show a number of randomly selected images \nbelonging either to a specified label or selected across all labels\n\"\"\"\n\ndef show_random_images(images, num=10, label=None):\n\n    # generating images' subsample if label specified\n    if label is not None:\n        images = images[images.label == label]\n    \n    fig, axs = plt.subplots(num, figsize=(1.25, num * 2.5))\n    \n    for i in range(num):\n    \n        rnd = np.random.randint(len(images))\n    \n        # getting image data and splitting between label and pixels' vector\n        img_data = np.array(images.iloc[rnd], dtype='uint8')    \n        img_label = img_data[0]\n        img_pixels = img_data[1:]\n        \n        # reshaping image to 2D array\n        img_shape = (int(np.sqrt(img_pixels.shape[0])), int(np.sqrt(img_pixels.shape[0])))\n        img_array = img_pixels.reshape(img_shape)\n        \n        title = 'Image {} \/ labelled {}'.format(rnd, img_label)\n        \n        axs[i].imshow(img_array, alpha=0.66, cmap='gray')\n        axs[i].set_title(title)","4473f382":"train_data = pd.read_csv(path + 'train.csv')\ntrain_data","dd924436":"# checking labels distribution\n\ntrain_data.label.value_counts()","fab5fae5":"show_random_images(train_data, num=5, label=5)","54b92ef2":"dig_data = pd.read_csv(path + 'Dig-MNIST.csv')\ndig_data","03974670":"# checking labels distribution\n\ndig_data.label.value_counts()","7711829c":"show_random_images(dig_data, num=5, label=5)","5c7b82d0":"# helper function to show randomly selected image from 2D images array\n\ndef show_random_image(imgset):\n    \n    rnd = np.random.randint(imgset.shape[0])\n    imgarray = imgset[rnd,:,:,0]\n    plt.figure(figsize=(1.5, 1.5))\n    plt.imshow(imgarray, cmap='gray')","3fe16ef2":"# preparing train image labels using 'one-hot' encoding\n\ntrain_labels = to_categorical(train_data.label)\ntrain_labels","1194e25d":"train_labels.shape","5b58083c":"# preparing train images array ('flat' image vectors)\n\ntrain_images = np.array(train_data.drop(columns='label'))\ntrain_images.shape","95041118":"# preparing 2D train images array (reshaping original 'flat' image vectors array)\n\nn_images = train_images.shape[0]\ndim = int(np.sqrt(train_images.shape[1]))\n\ntrain_images_2D = train_images.reshape(n_images, dim, dim, 1)\ntrain_images_2D.shape","fb338b5f":"show_random_image(train_images_2D)","515f7abf":"# normalizing \"train\" images\n\ntrain_images_2D = train_images_2D.astype('float')\ntrain_images_2D \/= 255","4010abfa":"# preparing dig-mnist image labels using 'one-hot' encoding\n\ndig_labels = to_categorical(dig_data.label)\ndig_labels","7b2ae25a":"dig_labels.shape","d35a6b7f":"# preparing train images array ('flat' image vectors)\n\ndig_images = np.array(dig_data.drop(columns='label'))\ndig_images.shape","e2303ea9":"# preparing 2D dig-mnist images array (reshaping original 'flat' image vectors array)\n\nn_images = dig_images.shape[0]\ndim = int(np.sqrt(dig_images.shape[1]))\n\ndig_images_2D = dig_images.reshape(n_images, dim, dim, 1)\ndig_images_2D.shape","1035a16b":"show_random_image(dig_images_2D)","47a1ba67":"# normalizing \"Dig-MNIST\" images\n\ndig_images_2D = dig_images_2D.astype('float')\ndig_images_2D \/= 255","252beb53":"images_train,imames_val,labels_train,labels_val = train_test_split(train_images_2D, train_labels, \n                                                                   random_state=42,test_size=0.15)","71585793":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(images_train)","4796c6d2":"test_data = pd.read_csv(path + 'test.csv', index_col='id')\ntest_data","9f1b889d":"submission = pd.read_csv(path + 'sample_submission.csv', index_col='id')\nsubmission","e8b12d2d":"# preparing test images array ('flat' image vectors)\n\ntest_images = np.array(test_data)\ntest_images.shape","7f149f16":"# preparing 2D test images array (reshaping original 'flat' image vectors array)\n\nn_images = test_images.shape[0]\ndim = int(np.sqrt(train_images.shape[1]))\n\ntest_images_2D = test_images.reshape(n_images, dim, dim, 1)\ntest_images_2D.shape","4b080563":"# normalizing \"test\" images\n\ntest_images_2D = test_images_2D.astype('float')\ntest_images_2D \/= 255","ad4e71ae":"# setting input dimensionality - 2D image arrays\ninput_shape = (dim, dim, 1)\nnum_classes = 10","a240fac7":"# setting optimization parameters\noptimizer = 'rmsprop'\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']","0ca160dc":"# setting training parameters\nepochs = 100\nbatch_size = 1024\n\nearly_stop = EarlyStopping(monitor='val_loss', \n                           min_delta=0, \n                           patience=3, \n                           verbose=True, \n                           mode='auto', \n                           baseline=None, \n                           restore_best_weights=False)\n\ncallbacks = [early_stop]","e666bb1e":"# defining model's architecture - version 1\n# source: https:\/\/keras.io\/examples\/mnist_cnn\/\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","f5db2201":"# defining model's architecture - version 2\n\nkernel_size = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size, activation='relu', \n                 input_shape=input_shape))\nmodel.add(Conv2D(64, kernel_size=kernel_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","7c9e6235":"# defining model's architecture - version 3\n\nkernel_size = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size, activation='relu', \n                 input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=kernel_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=kernel_size, activation='relu'))\nmodel.add(Conv2D(64, kernel_size=kernel_size, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","12bfea55":"# defining model's architecture - version 4\n\nkernel_size_1 = (7, 7)\nkernel_size_2 = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same', \n                 input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","ee2f235d":"# defining model's architecture - version 5\n\nkernel_size_1 = (7, 7)\nkernel_size_2 = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same', \n                 input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","d08b0095":"# defining model's architecture - version 7\n\nkernel_size_1 = (7, 7)\nkernel_size_2 = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same', \n                 input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","f20e0bed":"# defining model's architecture - version 8\n\nkernel_size_1 = (7, 7)\nkernel_size_2 = (5, 5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same', \n                 input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=kernel_size_1, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=kernel_size_2, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))","104aafe8":"model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","d1e95dcb":"model.summary()","b421621e":"model.fit_generator(datagen.flow(images_train, labels_train, \n                                 batch_size=batch_size), \n                    epochs=epochs, \n                    verbose=True, \n                    callbacks=callbacks, \n                    validation_data=(imames_val, labels_val))","61a6c1b0":"# showing history of 'accuracy'\n\nplt.figure()\nplt.plot(model.history.history['accuracy'], label='TRAIN ACC')\nplt.plot(model.history.history['val_accuracy'], label='VAL ACC')\nplt.legend()\nplt.show()","02afe468":"# showing history of 'loss'\n\nplt.figure()\nplt.plot(model.history.history['loss'], label='TRAIN LOSS')\nplt.plot(model.history.history['val_loss'], label='VAL LOSS')\nplt.legend()\nplt.show()","f23674db":"# making predictions for \"train\" data (in-sample check)\n\npred_train = model.predict_classes(train_images_2D)\npred_train.shape","333ade22":"hits = (pred_train == train_data.label)\nprint('Hits: {}, i.e. {:.2f}%'.format(hits.sum(), hits.sum() \/ pred_train.shape[0] * 100))","f3a8d461":"miss = (pred_train != train_data.label)\nprint('Misses: {}, i.e. {:.2f}%'.format(miss.sum(), miss.sum() \/ pred_train.shape[0] * 100))","b2f4d8ba":"cm = confusion_matrix(y_true=train_data.label, y_pred=pred_train)\ncm = pd.DataFrame(cm, index=range(num_classes), columns=range(num_classes))\ncm","f0daeb45":"plt.figure(figsize=(12,10))\nsns.heatmap(cm, annot=True,)","be4a3ab0":"# evaluating model on \"train\" data\n\neval_metrics = model.evaluate(x=train_images_2D, y=train_labels, \n                              batch_size=batch_size, verbose=True, callbacks=callbacks)\npd.DataFrame(eval_metrics, index=model.metrics_names, columns=['metric'])","d9929bb0":"# making predictions for \"Dig-MNIST\" data\n\npred_Dig = model.predict_classes(dig_images_2D)\npred_Dig.shape","95ba5deb":"hits = (pred_Dig == dig_data.label)\nprint('Hits: {}, i.e. {:.2f}%'.format(hits.sum(), hits.sum() \/ pred_Dig.shape[0] * 100))","c20a1bdb":"miss = (pred_Dig != dig_data.label)\nprint('Misses: {}, i.e. {:.2f}%'.format(miss.sum(), miss.sum() \/ pred_Dig.shape[0] * 100))","de54b624":"cm = confusion_matrix(y_true=dig_data.label, y_pred=pred_Dig)\ncm = pd.DataFrame(cm, index=range(num_classes), columns=range(num_classes))\ncm","b9e09b0a":"plt.figure(figsize=(12,10))\nsns.heatmap(cm, annot=True,)","cb067bc0":"# evaluating model on \"Dig-MNIST\" data\n\neval_metrics = model.evaluate(x=dig_images_2D, y=dig_labels, \n                              batch_size=batch_size, verbose=True, callbacks=callbacks)\npd.DataFrame(eval_metrics, index=model.metrics_names, columns=['metric'])","897b1db1":"# setting the optimal number of epochs\nepochs = early_stop.stopped_epoch + 1\n\n# re-training the model on full train dataset\nmodel.fit(train_images_2D, train_labels, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True)","73e01088":"# making predictions on \"test\" data\n\npred_test = model.predict_classes(test_images_2D)","fa0b305c":"submission.label = pred_test\nsubmission.to_csv('submission.csv')","b966bce7":"#### Preparing \"Dig-MNIST\" images","6e5832b4":"#### Learning history","a42a679d":"##### Helper functions","8f34f950":"### Data loading & inspection","bb9d8cc5":"#### splitting \"train_images_2D\" between train\/validation subsets","7e2640d6":"### Data preparation","718fdb78":"#### Making predictions","655ebac4":"#### Setting (hyper)parameters","6b86ce48":"### Setup & Imports","fdcc4dad":"#### Loading test images and sample submission","d5bb2962":"#### Model evaluation on \"train\" data","b45cb840":"#### Preparing test images","35138627":"#### \"Dig-MNIST.csv\"","0a3c03c9":"#### Preparing \"train\" images","5db74fa4":"##### helper functions","defd3f74":"### Modelling","94935959":"#### \"train.csv\"","c1c72ea6":"#### Train images augmentation\nsource: https:\/\/www.kaggle.com\/shahules\/indian-way-to-learn-cnn","ac78a0fe":"#### Model evaluation on \"Dig-MNIST\" data"}}