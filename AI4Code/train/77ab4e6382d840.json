{"cell_type":{"f5997b4a":"code","b4882107":"code","b65b68c6":"code","38fa491f":"code","d90023a0":"code","2d388e62":"code","2682f9b0":"code","9f469cac":"code","05b20806":"code","76dc8423":"code","ec180a34":"code","70cf8d5e":"code","269740e3":"code","ac8a1b86":"code","89a5e799":"code","9b6be93d":"code","f1807782":"code","f88501e4":"code","7ee883be":"code","a6d1c1fd":"markdown"},"source":{"f5997b4a":"import numpy as np \nimport pandas as pd\nimport os\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import fetch_openml","b4882107":"df_train = pd.read_csv('..\/input\/mnist-digit-recognizer\/train.csv')\n\n#Get data label\ntarget = df_train[[\"label\"]]\n\n#cut data label\nfeature = df_train.drop(columns=[\"label\"])\n\n#Separate in Train 75 % y Test 25%\nx_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)","b65b68c6":"x_train[:3]","38fa491f":"# normalizaci\u00f3n y split\nx_train, x_test, y_train, y_test = x_train \/ 255., x_test\/ 255., y_train.astype(np.int), y_test.astype(np.int)","d90023a0":"#Para usar matplotlib tengo que convertirlos a numpy\nx_train=x_train.to_numpy()\nx_test=x_test.to_numpy()\ny_train=y_train.to_numpy()\ny_test=y_test.to_numpy()","2d388e62":"x_train[:3]","2682f9b0":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport random \ni=0\nr, c = 3, 5\nfig = plt.figure(figsize=(2*c, 2*r))\nfor _r in range(r):\n    for _c in range(c):\n        i=i+1\n        plt.subplot(r, c, _r*c + _c + 1)\n        img = np.reshape(x_train[i], (28, 28))\n        plt.title(y_train[i])\n        plt.imshow(img, cmap='gray')\n        plt.axis(\"off\")\n        \nplt.tight_layout()\nplt.show()","9f469cac":"#Array on one dimension\ny_train = y_train.flatten()\ny_test = y_test.flatten()","05b20806":"y_train[:3]","76dc8423":"#Create Dataset\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, X, Y):\n        self.X = torch.from_numpy(X).float().cuda()\n        self.Y = torch.from_numpy(Y).long().cuda()\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, ix):\n        return self.X[ix], self.Y[ix]\n    \ndataset = Dataset(x_train, y_train)\n#Seaparate in batches\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)","ec180a34":"from sklearn.metrics import accuracy_score\n\ndef softmax(x):\n    return torch.exp(x) \/ torch.exp(x).sum(axis=-1,keepdims=True)\n\ndef evaluate(x):\n    model.eval()\n    y_pred = model(x)\n    y_probas = softmax(y_pred)\n    return torch.argmax(y_probas, axis=1)","70cf8d5e":"#D_in= 784 pixels h= 100 hidden layers D_out = 10 output classes\ndef build_model(D_in=784, H=100, D_out=10):\n    model = torch.nn.Sequential(\n        torch.nn.Linear(D_in, H),\n        torch.nn.ReLU(),\n        torch.nn.Linear(H, D_out),\n    ).to(\"cuda\")\n    return model\n\ndef fit(model, dataloader, epochs=10, log_each=1):\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n    model.train()\n    l, acc = [], []\n    for e in range(1, epochs+1): \n        _l, _acc = [], []\n        for x_b, y_b in dataloader:\n            y_pred = model(x_b)\n            loss = criterion(y_pred, y_b)\n            _l.append(loss.item())\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            y_probas = torch.argmax(softmax(y_pred), axis=1)            \n            _acc.append(accuracy_score(y_b.cpu().numpy(), y_probas.cpu().detach().numpy()))\n        l.append(np.mean(_l))\n        acc.append(np.mean(_acc))\n        if not e % log_each:\n            print(f\"Epoch {e}\/{epochs} loss {l[-1]:.5f} acc {acc[-1]:.5f}\")\n    return {'epoch': list(range(1, epochs+1)), 'loss': l, 'acc': acc}","269740e3":"model = build_model()\nhist = fit(model, dataloader)","ac8a1b86":"#Accuracy\ny_pred = evaluate(torch.from_numpy(x_train).float().cuda())\naccuracy_score(y_train, y_pred.cpu().numpy())","89a5e799":"fig = plt.figure(dpi=100)\nax = plt.subplot(111)\npd.DataFrame(hist).plot(x='epoch', grid=True, ax=ax)\nplt.show()","9b6be93d":"fig = plt.figure(dpi=200, figsize=(10,3))\nax = plt.subplot(121)\npd.DataFrame(hist).plot(x='epoch', y='loss', grid=True, ax=ax)\nax = plt.subplot(122)\npd.DataFrame(hist).plot(x='epoch', y='acc', grid=True, ax=ax)\nplt.show()","f1807782":"model = build_model()\nhist = fit(model, dataloader, epochs=30, log_each=10)","f88501e4":"fig = plt.figure(dpi=200, figsize=(10,3))\nax = plt.subplot(121)\npd.DataFrame(hist).plot(x='epoch', y='loss', grid=True, ax=ax)\nax = plt.subplot(122)\npd.DataFrame(hist).plot(x='epoch', y='acc', grid=True, ax=ax)\nplt.show()","7ee883be":"y_pred = evaluate(torch.from_numpy(x_test).float().cuda())\naccuracy_score(y_test, y_pred.cpu().numpy())","a6d1c1fd":"Code taken from https:\/\/www.youtube.com\/channel\/UCDhbl_RkuRF7WLZp9Q88FdQ\n\nArtificial intelligence from Juan sensio"}}