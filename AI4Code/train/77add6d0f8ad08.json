{"cell_type":{"52be77d8":"code","af56d6c6":"code","8dbdd39b":"code","9c19d022":"code","fe0e0ace":"code","4fc9f598":"code","9222e777":"code","6445b9b7":"code","195bc79e":"code","1c45f0cb":"code","87a3fc09":"code","edca57e4":"code","9efdbc53":"code","cfc76dc3":"code","089602ed":"code","f2320db3":"code","4468280d":"code","360a6974":"code","738c33ad":"markdown","eba54fe3":"markdown","0733d896":"markdown","7ae1daeb":"markdown","fb4fd52a":"markdown","aff29180":"markdown","b6991d12":"markdown","1940beed":"markdown","d854d2ef":"markdown","4090c774":"markdown"},"source":{"52be77d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","af56d6c6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n","8dbdd39b":"sample_submission = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv\")\nsample_submission.head()","9c19d022":"dtype = {}\nfor i in range(2000):\n    dtype[f\"d_{i}\"] = np.uint16\nsales_train_validation = pd.read_csv(\n    \"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\",\n    dtype = dtype\n).set_index([\"cat_id\",\"id\",\"item_id\",\"dept_id\",\"store_id\",\"state_id\"])\nsales_train_validation.columns = [int(col.split(\"_\")[-1]) for col in sales_train_validation.columns]\nsales_train_validation.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales\",i)for i in sales_train_validation.columns]\n)\nsales_train_validation.head()","fe0e0ace":"calendar = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")\nsell_prices = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\",dtype={\"sell_price\":float})\n\nsell_calendar = calendar[[\"wm_yr_wk\",\"d\"]].join(sell_prices.set_index(\"wm_yr_wk\"),on=\"wm_yr_wk\")\ncalendar[\"d\"] = calendar[\"d\"].apply(lambda x : int(x.split(\"_\")[-1]))\nsell_calendar.head()","4fc9f598":"sell_price_calendar = pd.pivot_table(sell_calendar, values='sell_price', index=['store_id', 'item_id'],\n                    columns=['d'], aggfunc=\"last\", fill_value=0)\nsell_price_calendar.columns = [int(col.split(\"_\")[-1]) for col in sell_price_calendar.columns]\nsell_price_calendar = sell_price_calendar.sort_index(axis=1)\nsell_price_calendar.columns = pd.MultiIndex.from_tuples(\n    [ (\"sell_prices\",i)for i in sell_price_calendar.columns]\n)\n\nsell_price_calendar.head()","9222e777":"sales_dataset = sales_train_validation.join(sell_price_calendar,on=[\"store_id\",\"item_id\"])\nrevenue = sales_dataset[\"sell_prices\"]*sales_dataset[\"n_sales\"]\nrevenue.columns = pd.MultiIndex.from_tuples(\n    [ (\"revenue\",i)for i in revenue.columns]\n)\nsales_dataset = sales_dataset.join(revenue)\nsales_dataset.head()","6445b9b7":"weekly = np.cos(np.array(range(2000))*2*np.pi\/7)\nmonthly = np.cos(np.array(range(2000))*2*np.pi\/(365.2425\/12))\nyearly = np.cos(np.array(range(2000))*2*np.pi\/365.2425)\nd = np.array(range(2000))\ncyclic_time = pd.DataFrame({\n    \"weekly\":weekly,\n    \"monthly\":monthly,\n    \"yearly\":yearly,\n    \"w_step\":np.array(range(2000))%7\/7,\n    \"m_step\":np.array(range(2000))%(365.2425\/12)\/(365.2425\/12),\n    \"y_step\":np.array(range(2000))%365.2425\/365.2425,\n    \"d\":d\n}).set_index(\"d\")\n# cyclic_time = (cyclic_time+1)\/2\ncyclic_time[\"mean\"] =cyclic_time.mean(axis=1)\ncyclic_time = cyclic_time.join(pd.get_dummies(calendar[[\"wday\",\"month\",\"d\"]].set_index(\"d\"),columns=[\"wday\",\"month\"])).fillna(0)\ncyclic_time.to_pickle(\"cyclic_time.zip.pkl\",compression=\"zip\")\ncyclic_time[[\"mean\",\"yearly\",\"monthly\"]].plot(figsize=(32\/2, 9\/2))\ncyclic_time.head()","195bc79e":"nsales_percata = sales_dataset[\"n_sales\"].groupby([\"cat_id\",\"state_id\"]).agg(np.mean).transpose()\n\nsales_dataset[\"n_sales\"].groupby([\"cat_id\"]).agg(np.mean).transpose().plot(figsize=(32\/2, 9\/2))\nplt.title(\"ALL mean n sales by cat_id\")\nfor cata in [\"FOODS\",\"HOBBIES\",\"HOUSEHOLD\"]:\n    nsales_percata[cata].plot(figsize=(32\/2, 9\/2))\n    plt.title(f\"{cata} mean n sales\")\n","1c45f0cb":"from sklearn.linear_model import LinearRegression\nfor cata in [\"FOODS\",\"HOBBIES\",\"HOUSEHOLD\"]:\n    \n    ser = nsales_percata[cata].transpose().mean()\n    reg = LinearRegression().fit(ser.index.values.reshape(-1, 1), ser.values)\n    trend = reg.predict(ser.index.values.reshape(-1, 1))\n    nsales_percata[(cata,\"trends\")] = trend\n    nsales_percata[cata].plot(figsize=(32\/2, 9\/2))\n    plt.title(f\"{cata} mean with trends\")\n\n    \nnsales_percata[[(\"FOODS\",\"trends\"),(\"HOBBIES\",\"trends\"),(\"HOUSEHOLD\",\"trends\")]].plot(figsize=(32\/2, 9\/2))\nplt.title(f\"trends for each catagoy\")\n","87a3fc09":"from tqdm.auto import tqdm\ntqdm.pandas()\ndef apply_trend(x):\n    reg = LinearRegression().fit(x.index.values.reshape(-1, 1), x.values)\n    trend = reg.predict(x.index.values.reshape(-1, 1))\n    return trend\n\n\nn_sales_trends = sales_dataset[\"n_sales\"].copy()\nn_sales_trends[n_sales_trends.columns] = np.stack(n_sales_trends.progress_apply(apply_trend,axis=1))\n\nn_sales_detrends = sales_dataset[\"n_sales\"].copy()\nn_sales_detrends = n_sales_detrends - n_sales_trends\n\nn_sales_detrends.groupby([\"cat_id\",\"state_id\"]).agg(np.mean).transpose().plot(figsize=(32\/2, 9\/2))\nplt.title(f\"detrended data\")","edca57e4":"n_sales_detrends.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales_detrends\",i)for i in n_sales_detrends.columns]\n)\nn_sales_trends.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales_trends\",i)for i in n_sales_trends.columns]\n)","9efdbc53":"plt.figure(figsize=(32\/2, 9\/2))\nplt.plot(n_sales_detrends[\"n_sales_detrends\"].agg(np.mean).transpose()[-365:-1])\nplt.plot(cyclic_time[[\"weekly\",\"monthly\"]][1914-365:1914],alpha=0.5)\nplt.legend([\"average detrended nsales\",\"weekly sin t=7\",\"monthly sin t=30\"])","cfc76dc3":"\nsales_dataset = sales_dataset.join(n_sales_detrends).join(n_sales_trends)\nsales_dataset.to_pickle(\"sales_dataset.zip.pkl\",compression=\"zip\")\nsales_dataset.columns.unique(0)","089602ed":"calendar.head()","f2320db3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nindex = 1\nY = sales_dataset[\"n_sales\"].iloc[index][-1000:-28]\nX = cyclic_time.loc[Y.index]\nreg = RandomForestRegressor(n_estimators=5).fit(X, Y)\n# reg = LinearRegression().fit(X, Y)\nprint(\"training\")\nprint(f\"R2 {reg.score(X, Y)}\")\nprint(f\"RMSE {np.sqrt(mean_squared_error(reg.predict(X),Y))}\")\nplt.scatter(reg.predict(X),Y.values)\n\nprint(\"validation\")\n\nY_val = sales_dataset[\"n_sales\"].iloc[index][-28:]\nX_val = cyclic_time.loc[Y_val.index]\nplt.scatter(reg.predict(X_val),Y_val.values)\nprint(f\"R2 {reg.score(X_val, Y_val)}\")\nprint(f\"RMSE {np.sqrt(mean_squared_error(reg.predict(X_val),Y_val))}\")","4468280d":"index_list = sales_dataset[\"n_sales\"].index\n\ndef get_score_from_idx(idx):\n    Y = sales_dataset[\"n_sales\"].loc[idx][-600:-28]\n    X = cyclic_time.loc[Y.index]\n    reg = RandomForestRegressor(n_estimators=5).fit(X, Y)\n    reg = LinearRegression().fit(X, Y)\n    \n    Y_val = sales_dataset[\"n_sales\"].iloc[index][-28:]\n    X_val = cyclic_time.loc[Y_val.index]\n    return {\n        \"index\":idx,\n        \"rmse\":np.sqrt(mean_squared_error(reg.predict(X_val),Y_val))\n    }\n\nret = []\nfor idx in tqdm(index_list[:10]):\n    ret.append(get_score_from_idx(idx))","360a6974":"SCORE = pd.DataFrame(ret).set_index(\"index\")\nSCORE.index = pd.MultiIndex.from_tuples(\n    SCORE.index \n)\nSCORE.hist()\nSCORE.describe()","738c33ad":"# Data prep","eba54fe3":"by plotting with previously create cyclic time it is certain that sales are heavily corelated to day of week and day of month","0733d896":"## Cyclic Time data","7ae1daeb":"# Join all preped data and save as pkl","fb4fd52a":"# Visualization\n## here we will visualize\n1. number of sales through time per catagory\/state\n2. price through time per catagory\/state\n3. revenue through time per catagory\/state\n4. detrending","aff29180":"## n_sales","b6991d12":"### Find trends by fitting to linear regression","1940beed":"# Models \n## Simple Regression using 1 model per item","d854d2ef":"## Number of Sales through time per catagory\/state","4090c774":"## sell price and calendar"}}