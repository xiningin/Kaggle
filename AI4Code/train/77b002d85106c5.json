{"cell_type":{"467f249c":"code","bbade91e":"code","456adad7":"code","8386850a":"code","610d843a":"code","3a03e39d":"code","4048f080":"code","9e2b21c2":"code","9017d53c":"code","baf48409":"code","88967916":"code","34099fcd":"code","a0486c37":"code","54cda763":"code","e139f39f":"code","7552392c":"code","45c961d6":"code","c6d7f683":"code","bfacd637":"code","5b237308":"code","f20f5cdb":"code","2d8de544":"code","3c852b97":"code","cf9d7315":"code","7f153bff":"code","9ad2351a":"code","bf4677b3":"code","e58b148b":"code","9a7742aa":"code","559adadb":"code","80d788f4":"code","732c4e75":"code","d630af75":"code","f81a1ce6":"code","777b652e":"code","6c99e213":"code","26c27e4a":"code","bb8a8d86":"code","0a27e944":"code","e169d978":"markdown","0228745f":"markdown","02bdfd9a":"markdown","c2702fd1":"markdown","abf91287":"markdown","e271d176":"markdown","668de697":"markdown","2e10ab9b":"markdown","d3839c69":"markdown","e7692c8d":"markdown","04bf3d7d":"markdown","185a8aed":"markdown","2fe74548":"markdown","1735358f":"markdown","baf27e62":"markdown","1ef806c3":"markdown","7c8c8164":"markdown","cf8a4e3b":"markdown","be4704a5":"markdown","99b73beb":"markdown","853b674c":"markdown","27b936d2":"markdown","6fea1670":"markdown","71fafffa":"markdown","67f336bf":"markdown","6db26fd8":"markdown","d47f6f9c":"markdown","328d0951":"markdown","0874bbeb":"markdown","5b9ce7b9":"markdown","9ce777ba":"markdown","caf235dd":"markdown","0b6a097c":"markdown","cf4ab4f9":"markdown","386788f8":"markdown","90ec6df1":"markdown","2cc5b255":"markdown","3e99ab3b":"markdown","15eef7d3":"markdown","dfe68b21":"markdown","c57193de":"markdown","5abf91d6":"markdown","c6c05f98":"markdown"},"source":{"467f249c":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom sklearn.model_selection import train_test_split\n\nprint(tf.__version__)","bbade91e":"batch_size = 128\nepochs = 35\nimage_size = (300,300)\ntest_size = 0.2","456adad7":"training_images = tf.io.gfile.glob('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/*\/*')\nvalidation_images = tf.io.gfile.glob('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/*\/*')\n\nprint(f'Before division of 80:20')\nprint(f'Total number of training images = {len(training_images)}')\nprint(f'Total number of validation images = {len(validation_images)}\\n')\n\n\ntotal_files = training_images\ntotal_files.extend(validation_images)\nprint(f'Total number of images : training_images + validation_images = {len(total_files)}\\n')\n\ntrain_images, val_images = train_test_split(total_files, test_size = test_size)\nprint(f'After division of 80:20')\nprint(f'Total number of training images = {len(train_images)}')\nprint(f'Total number of validation images = {len(val_images)}')\n","8386850a":"count_normal = len([x for x in train_images if \"NORMAL\" in x])\nprint(f'Normal images count in training set: {count_normal}')\n\ncount_pneumonia = len([x for x in train_images if \"PNEUMONIA\" in x])\nprint(f'Pneumonia images count in training set: {count_pneumonia}')\n\ncount_array = []\ncount_array += ['positive']*count_pneumonia\ncount_array += ['negative']*count_normal\n\nsns.set_style('ticks')\nsns.countplot(count_array)","610d843a":"tf.io.gfile.makedirs('\/kaggle\/working\/val_dataset\/negative\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/val_dataset\/positive\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/train_dataset\/negative\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/train_dataset\/positive\/')\n","3a03e39d":"for ele in train_images:\n    parts_of_path = ele.split('\/')\n\n    if 'PNEUMONIA' == parts_of_path[-2]:\n        tf.io.gfile.copy(src = ele, dst = '\/kaggle\/working\/train_dataset\/positive\/' +  parts_of_path[-1])\n    else:\n        tf.io.gfile.copy(src = ele, dst = '\/kaggle\/working\/train_dataset\/negative\/' +  parts_of_path[-1])","4048f080":"for ele in val_images:\n    parts_of_path = ele.split('\/')\n\n    if 'PNEUMONIA' == parts_of_path[-2]:\n        tf.io.gfile.copy(src = ele, dst = '\/kaggle\/working\/val_dataset\/positive\/' +  parts_of_path[-1])\n    else:\n        tf.io.gfile.copy(src = ele, dst = '\/kaggle\/working\/val_dataset\/negative\/' +  parts_of_path[-1])","9e2b21c2":"train_datagen = ImageDataGenerator(rescale = 1\/255,\n                                 rotation_range = 30,\n                                 zoom_range = 0.2,\n                                 width_shift_range = 0.1,\n                                 height_shift_range = 0.1)\nval_datagen = ImageDataGenerator(rescale = 1\/255)\n                                \n\ntrain_generator = train_datagen.flow_from_directory(\n    '\/kaggle\/working\/train_dataset\/',\n    target_size = image_size,\n    batch_size = batch_size ,\n    class_mode = 'binary'\n)\n\nvalidation_generator = val_datagen.flow_from_directory(\n    '\/kaggle\/working\/val_dataset\/',\n    target_size = image_size,\n    batch_size = batch_size ,\n    class_mode = 'binary'\n)\n","9017d53c":"eval_datagen = ImageDataGenerator(rescale = 1\/255)\n\ntest_generator = eval_datagen.flow_from_directory(\n    '..\/input\/chest-xray-pneumonia\/chest_xray\/test',\n    target_size = image_size,\n    batch_size = batch_size , \n    class_mode = 'binary'\n)\n","baf48409":"initial_bias = np.log([count_pneumonia\/count_normal])\ninitial_bias","88967916":"weight_for_0 = (1 \/ count_normal)*(len(train_images))\/2.0 \nweight_for_1 = (1 \/ count_pneumonia)*(len(train_images))\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","34099fcd":"base_model1 = tf.keras.applications.VGG16(input_shape=(300, 300, 3),include_top=False, weights='imagenet')\nbase_model1.trainable = False\n\n\nmodel1 = tf.keras.Sequential([\n        base_model1,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n        ])\n\nmodel1.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])\nmodel1.summary()","a0486c37":"print(len( base_model1.layers))","54cda763":"checkpoint_cb1 = tf.keras.callbacks.ModelCheckpoint(\"model1_vgg.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb1 = tf.keras.callbacks.EarlyStopping(monitor ='val_loss', patience=20, mode = 'min',restore_best_weights=True)","e139f39f":"history1 = model1.fit(\n    train_generator,\n    steps_per_epoch = 10,\n    epochs = epochs,\n    validation_data = validation_generator,\n    class_weight = class_weight,\n    callbacks = [checkpoint_cb1, early_stopping_cb1]\n)","7552392c":"figure, axis = plt.subplots(1, 2, figsize=(18,5))\naxis = axis.ravel()\n\nfor i,element in enumerate(['accuracy', 'loss']):\n    axis[i].plot(history1.history[element])\n    axis[i].plot(history1.history['val_' + element])\n    axis[i].set_title('Model {}'.format(element))\n    axis[i].set_xlabel('epochs')\n    axis[i].set_ylabel(element)\n    axis[i].legend(['train', 'val'])\n","45c961d6":"eval_result1 = model1.evaluate_generator(test_generator, 624)\nprint('loss rate at evaluation data :', eval_result1[0])\nprint('accuracy rate at evaluation data :', eval_result1[1])","c6d7f683":"vgg_model = tf.keras.models.load_model('\/kaggle\/working\/model1_vgg.h5')\n\nwrong_predicted_image = [[],[]]\ncorrect_predicted_image = [[],[]]\ni = 0\nwhile i< 5 and len(wrong_predicted_image[0]) < 6:\n    j = 0\n    while j < 128 and len(wrong_predicted_image[0]) < 6:\n        \n        image_array = (test_generator[i][0][j]).reshape(1,300,300,3)\n        \n        prediction = vgg_model.predict(image_array)\n        \n        if int(round(prediction[0][0])) != test_generator[i][1][j]:\n            wrong_predicted_image[0].append(image_array)\n            wrong_predicted_image[1].append(int(round(prediction[0][0])))\n            \n        elif len(correct_predicted_image[0]) < 6:\n            correct_predicted_image[0].append(image_array)\n            correct_predicted_image[1].append(int(round(prediction[0][0])))\n#         print(len(correct_predicted_image[0]),len(wrong_predicted_image[0]))  \n        j += 1\n        \n    i += 1","bfacd637":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 22 ,4\nfig, ax = plt.subplots(1,6)\n\ni = 0\nfor ele in wrong_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'wrong_prediction_by_model --- {wrong_predicted_image[1]}')","5b237308":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 22 ,4\nfig, ax = plt.subplots(1,6)\n\ni = 0\nfor ele in correct_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'correct_prediction_by_model --- {correct_predicted_image[1]}')","f20f5cdb":"base_model2 = tf.keras.applications.InceptionV3(input_shape=(300, 300, 3),include_top=False, weights='imagenet')\n\nfor layers in base_model2.layers[:200]:\n    layers.trainable = False\n\nmodel2 = tf.keras.Sequential([\n        base_model2,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(1,activation=tf.nn.sigmoid) \n        ])\n\nmodel2.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])\n\nmodel2.summary()","2d8de544":"len(base_model2.layers)","3c852b97":"checkpoint_cb2 = tf.keras.callbacks.ModelCheckpoint(\"model1_inceptionNet.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb2 = tf.keras.callbacks.EarlyStopping(monitor ='val_loss', patience=20, mode = 'min',restore_best_weights=True)\n                                                     ","cf9d7315":"history2 = model2.fit(\n    train_generator,\n    steps_per_epoch = 10,\n    epochs = epochs,\n    validation_data = validation_generator,\n    class_weight = class_weight,\n    callbacks = [checkpoint_cb2, early_stopping_cb2]    \n)","7f153bff":"figure, axis = plt.subplots(1, 2, figsize=(18,5))\naxis = axis.ravel()\n\nfor i,element in enumerate(['accuracy', 'loss']):\n    axis[i].plot(history2.history[element])\n    axis[i].plot(history2.history['val_' + element])\n    axis[i].set_title('Model {}'.format(element))\n    axis[i].set_xlabel('epochs')\n    axis[i].set_ylabel(element)\n    axis[i].legend(['train', 'val'])","9ad2351a":"eval_result2 = model2.evaluate_generator(test_generator, 624)\nprint('loss rate at evaluation data :', eval_result2[0])\nprint('accuracy rate at evaluation data :', eval_result2[1])","bf4677b3":"Inception_model = tf.keras.models.load_model('\/kaggle\/working\/model1_inceptionNet.h5')\n\nwrong_predicted_image = [[],[]]\ncorrect_predicted_image = [[],[]]\ni = 0\nwhile i< 5 and len(wrong_predicted_image[0]) < 6:\n    j = 0\n    while j < 128 and len(wrong_predicted_image[0]) < 6:\n        \n        image_array = (test_generator[i][0][j]).reshape(1,300,300,3)\n        \n        prediction = Inception_model.predict(image_array)\n        \n        if int(round(prediction[0][0])) != test_generator[i][1][j]:\n            wrong_predicted_image[0].append(image_array)\n            wrong_predicted_image[1].append(int(round(prediction[0][0])))\n            \n        elif len(correct_predicted_image[0]) < 6:\n            correct_predicted_image[0].append(image_array)\n            correct_predicted_image[1].append(int(round(prediction[0][0])))\n#         print(len(correct_predicted_image[0]),len(wrong_predicted_image[0]))\n        j += 1\n        \n    i += 1","e58b148b":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 22 ,4\nfig, ax = plt.subplots(1,6)\n\ni = 0\nfor ele in wrong_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'wrong_prediction_by_model --- {wrong_predicted_image[1]}')","9a7742aa":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 22 ,4\nfig, ax = plt.subplots(1,6)\n\ni = 0\nfor ele in correct_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'correct_prediction_by_model --- {correct_predicted_image[1]}')","559adadb":"base_model3 = tf.keras.applications.ResNet50(input_shape=(300, 300, 3),include_top=False, weights='imagenet')\n# base_model3.trainable = False\nfor layers in base_model3.layers[:100]:\n    layers.trainable = False\n\nmodel3 = tf.keras.Sequential([\n        base_model3,\n        tf.keras.layers.GlobalAveragePooling2D(),\n#          tf.keras.layers.Flatten(),\n#         tf.keras.layers.Dense(512, activation=tf.nn.relu),\n#          tf.keras.layers.Dropout(0.3),\n#         tf.keras.layers.Dense(512, activation=tf.nn.relu),\n#         tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1,activation=tf.nn.sigmoid),\n        ])\n\nmodel3.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])\nmodel3.summary()","80d788f4":"len(base_model3.layers)","732c4e75":"checkpoint_cb3= tf.keras.callbacks.ModelCheckpoint(\"model3_resnet.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb3 = tf.keras.callbacks.EarlyStopping(monitor ='val_loss', patience=20, mode = 'min',restore_best_weights=True)\n                                                     ","d630af75":"history3 = model3.fit(\n    train_generator,\n    steps_per_epoch = 10,\n    epochs = epochs,\n    validation_data = validation_generator,\n    class_weight = class_weight,\n    callbacks = [checkpoint_cb3, early_stopping_cb3] \n)","f81a1ce6":"figure, axis = plt.subplots(1, 2, figsize=(18,5))\naxis = axis.ravel()\n\nfor i,element in enumerate(['accuracy', 'loss']):\n    axis[i].plot(history3.history[element])\n    axis[i].plot(history3.history['val_' + element])\n    axis[i].set_title('Model {}'.format(element))\n    axis[i].set_xlabel('epochs')\n    axis[i].set_ylabel(element)\n    axis[i].legend(['train', 'val'])","777b652e":"eval_result3 = model3.evaluate_generator(test_generator, 624)\nprint('loss rate at evaluation data :', eval_result3[0])\nprint('accuracy rate at evaluation data :', eval_result3[1])","6c99e213":"Residual_model = tf.keras.models.load_model('\/kaggle\/working\/model3_resnet.h5')\n\nwrong_predicted_image = [[],[]]\ncorrect_predicted_image = [[],[]]\ni = 0\nwhile i< 5 and len(wrong_predicted_image[0]) < 6:\n    j = 0\n    while j < 128 and len(wrong_predicted_image[0]) < 6:\n        \n        image_array = (test_generator[i][0][j]).reshape(1,300,300,3)\n        \n        prediction = Residual_model.predict(image_array)\n        \n        if int(round(prediction[0][0])) != test_generator[i][1][j]:\n            wrong_predicted_image[0].append(image_array)\n            wrong_predicted_image[1].append(int(round(prediction[0][0])))\n            \n        elif len(correct_predicted_image[0]) < 6:\n            correct_predicted_image[0].append(image_array)\n            correct_predicted_image[1].append(int(round(prediction[0][0])))\n#         print(len(correct_predicted_image[0]),len(wrong_predicted_image[0]))\n        j += 1\n        \n    i += 1","26c27e4a":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 22 ,4\nfig, ax = plt.subplots(1,6)\n\ni = 0\nfor ele in wrong_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'wrong_prediction_by_model --- {wrong_predicted_image[1]}')","bb8a8d86":"import matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 11 ,4\nfig, ax = plt.subplots(1,2)\n\ni = 0\nfor ele in correct_predicted_image[0]:\n    image = tf.keras.preprocessing.image.array_to_img(ele.reshape(300,300,3))\n    ax[i].imshow(image)\n    i += 1\n\nprint(f'correct_prediction_by_model --- {correct_predicted_image[1]}')","0a27e944":"tf.io.gfile.rmtree('\/kaggle\/working\/val_dataset\/')\ntf.io.gfile.rmtree('\/kaggle\/working\/train_dataset\/')","e169d978":"All the below parameters are found by experimenting many times while fine-tuning the model.\ni.e for Dense layers, it was trained with different no. of neurons (4096, 1024, 512) but the best result found by taking 512 neurons for Dense layers and using Dropout (0.2 and 0.5 while fine-tuning) 0.2 gives us best result.","0228745f":"## f) Images on which output predicted correctly by model****","02bdfd9a":"## f) Images on which output predicted correctly by model","c2702fd1":"# 6. Residual Net Model","abf91287":"Below code helps us find the list of images on which prediction is wrong as well as list of images on which prediction is correct.","e271d176":"## e) Images on which output predicted incorrectly by model ","668de697":"Deleting all the directories created in the below cell as it is only created to divide the dataset.","2e10ab9b":"Below code block shows, number of layers for base model (Inception) which is 311. and out of 311 layers, I choose to freeze 200 layers while training it means we will not be training those 200 freezed layers.","d3839c69":"Below code block shows, number of layers for base model (vgg) which is 19 and out of 19 I choose to freeze all 19 layers while training it means we will not be training those 19 freezed layers.","e7692c8d":"#### Model_Name   and    Accuracy\n     VGG            91.18% \n     Inception      90.38%","04bf3d7d":"All the below parameters are found by experimenting many times while fine-tuning the model. i.e number of the layers that should not be trained,\n(so 200 layers out of 311 are freezed and will not trained while training), I also tried to add Dense layers but it was not giving good results on test dataset.","185a8aed":"## c) Visualise the model performance","2fe74548":"## 2. Load Data and division of Data","1735358f":"Below code helps us to save the best model while training and using earlystopping callbacks provided by tensorflow to keep monitoring the validation loss, and saving those model which had less validation loss while training and (patience = 20) while training for 20 more epochs if there is no improvement in validation loss, we will stop the training.","baf27e62":"## e) Images on which output predicted incorrectly by model","1ef806c3":"## b) Train the model","7c8c8164":"Below code helps us to save the best model while training and using earlystopping callbacks provided by tensorflow to keep monitoring the validation loss, and saving those model which had less validation loss while training and (patience = 20) while training for 20 more epochs if there is no improvement in validation loss, we will stop the training. ","cf8a4e3b":"## d) Predict and Evaluate on test dataset","be4704a5":"Below codes, helps us to visualise the model - loss parameter for training dataset as well as validation dataset while training and model - accuracy for training and validation dataset. all the graphs points recoreded at the end of every epoch.","99b73beb":"Below codes, helps us to visualise the model - loss parameter for training dataset as well as validation dataset while training and model - accuracy for training and validation dataset. all the graphs points recorded at the end of every epoch.","853b674c":"## c) Visualise the model performance","27b936d2":"## b) Train the model","6fea1670":"* Creating directory in Kaggle\/working directory for training dataset and validation dataset after division of 80:20.\n* In both directory there is more two directory i.e. negative and positive\n* The directory struture is same as the structure in Input directory.","71fafffa":"## 3. Correction for Data Imbalance","67f336bf":"Below code helps us find the list of images on which prediction is wrong as well as list of images on which prediction is correct.","6db26fd8":"## f) Images on which output predicted correctly by model","d47f6f9c":"* Total validation images = 16\n* Total training images = 5216\n* There is lot of training images compare to validation images and division between these two dataset not in 80:20 ratio.\n* In below cell, divsion of 80:20 performed after merging all the validation and training images in a list of files.","328d0951":"## d) Predict and Evaluate on test dataset","0874bbeb":"## c) Visualise the model performance","5b9ce7b9":"## e) Images on which output predicted incorrectly by model","9ce777ba":"# 4. VGG Net Model","caf235dd":"Below code helps us to save the best model while training and using earlystopping callbacks provided by tensorflow to keep monitoring the validation loss, and saving those model which had less validation loss while training and (patience = 20) while training for 20 more epochs if there is no improvement in validation loss, we will stop the training.  ","0b6a097c":"In the following two cell , copying all the files from input directory to custom directory. i.e\n* From the train_images list, transferring all the files to train_dataset directory.\n* From the val_images list, transferring all the files to val_dataset directory.\n","cf4ab4f9":"## a) VGG model after fine-tuning","386788f8":"After analysing the training dataset that has been created in above cell, there is lot of Pneumonia images(positive) in comparison to Normal images(negative). This shows that imbalance in data. Correction for imbalance in data performed in Correction for Data Imbalance Section.","90ec6df1":"## d) Predict and Evaluate on test dataset","2cc5b255":"Below codes, helps us to visualise the model - loss parameter for training dataset as well as validation dataset while training and model - accuracy for training and validation dataset. all the graphs points recorded at the end of every epoch.","3e99ab3b":"## b) Train the model","15eef7d3":"## a) Inception model after fine-tuning","dfe68b21":"Using ImageDataGenerator, we are augmenting the dataset to makes the learning difficult for a given model, so that model can learn differnet and difficult features from training dataset which helps us to get good accuracy on test_dataset. ","c57193de":"Below code helps us find the list of images on which prediction is wrong as well as list of images on which prediction is correct.","5abf91d6":"# 5. Inception Net Model","c6c05f98":"## a) Residual model after fine-tuning"}}