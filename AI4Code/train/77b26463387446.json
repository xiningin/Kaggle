{"cell_type":{"04f238e6":"code","6c89dee4":"code","8f5c6f5d":"code","057e9df4":"code","1a0c5879":"code","4967e91c":"code","33c7a6d3":"code","9248547c":"code","da52d35a":"code","d5911004":"markdown","420b2af7":"markdown","7ef99897":"markdown"},"source":{"04f238e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c89dee4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler,PowerTransformer,RobustScaler,OrdinalEncoder\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.feature_selection import SelectKBest,f_classif,SelectKBest,mutual_info_regression,f_regression\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor","8f5c6f5d":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv',index_col='Id')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmit=pd.DataFrame(test['Id'])","057e9df4":"#------------------------------Deleting columns with null value more than 500 -------------------------------------\n\nnull=train.loc[:,train.isnull().sum()>500]\ntrain.drop(null,inplace=True,axis=1)\n\n\nnull=test.loc[:,test.isnull().sum()>500]\ntest.drop(null,inplace=True,axis=1)\n\n\n\n#----------------------------------- Categorical value-----------------------------------------------------------------\n\nencode=LabelEncoder()\nfor i in train.select_dtypes(include='object').columns:\n    train[i]=encode.fit_transform(train[i])\n    test[i]=encode.fit_transform(test[i])\n\n\n    \n\n\ny=np.log(train['SalePrice'])\n\ntest=test.drop('Id',axis=1)\n","1a0c5879":"model=XGBRegressor(base_score=0.4, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.4603, gamma=0.05,\n             gpu_id=-1, importance_type='gain', interaction_constraints='',\n             learning_rate=0.05, max_delta_step=0, max_depth=3,\n             min_child_weight=1.7817, monotone_constraints='()',\n             n_estimators=2200, n_jobs=4, nthread=-1, num_parallel_tree=1,\n             random_state=7, reg_alpha=0.464, reg_lambda=0.8571,\n             scale_pos_weight=1, subsample=0.5213,silent = True,tree_method='exact',\n             validate_parameters=1, verbosity=0)","4967e91c":"for i in range(1,2):\n    pipeline=Pipeline(steps=[('impute',IterativeImputer(max_iter=4)),('model',model)])\n\n    xtrain,xvalid,ytrain,yvalid=train_test_split(train.drop('SalePrice',axis=1),y,test_size=0.2)\n\n    pipeline.fit(xtrain,ytrain)\n\n    yhat=pipeline.predict(xvalid)\n    print(np.sqrt(mean_squared_error(yvalid,yhat)),i)","33c7a6d3":"yhat=pipeline.predict(test)\nyhat=np.exp(yhat)\n\nsubmit['SalePrice']=yhat*0.55+yhat\nsubmit.to_csv('index.csv',index=False)","9248547c":"submit","da52d35a":"train","d5911004":"# Modelling and submitting","420b2af7":"# ->  Loading Module and Datasets","7ef99897":"# If u found notebook please help by voting it"}}