{"cell_type":{"b4a667e2":"code","04e98d1f":"code","ea9b6fec":"code","994a6824":"code","c31db306":"code","118b5c69":"code","c57a9cf9":"code","bf7f05e9":"code","126427cc":"markdown","962ce90a":"markdown"},"source":{"b4a667e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04e98d1f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt","ea9b6fec":"train = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')\ntest = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/test.csv')\nss = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv')","994a6824":"train.shape, test.shape","c31db306":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (pixel_array, sample_prediction_df) in iter_test:\n    break\n    sample_prediction_df['annotations'] = '0.5 0 0 100 100'  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n\nfig, ax = plt.subplots(figsize=(15, 10))\nplt.imshow(pixel_array)\nplt.show()\n\n(train['image_id'] == train['video_id'].astype('str') + '-' + train['video_frame'].astype('str')).mean()","118b5c69":"plt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(15, 5))\nfor sequence, d in train.query('video_id == 0').groupby('sequence'):\n    d['sequence_frame'].plot(ax=ax, label=f'Sequence {sequence}')\nax.set_title('Video 0: Sequence Frame vs Video Frame')\nax.set_xlabel('Video Frame')\nax.set_ylabel('Sequence Frame')\nplt.legend()\nplt.show()","c57a9cf9":"train.head()","bf7f05e9":"train['n_annotations'] = train['annotations'].apply(lambda x: len(eval(x)))\n\ntrain.groupby(['video_id','sequence'])['sequence_frame'].max() \\\n    .sort_values().plot(kind='barh', figsize=(12, 5),\n                        title='Length of Sequences')","126427cc":"How many Annotations per Frame?\nIs it different in each video?\nIs it different in each sequence within a video?","962ce90a":"Example of using the submission package."}}