{"cell_type":{"e7aab3f0":"code","14bad1b7":"code","715a3f3c":"code","a403e911":"code","bd9ec9d5":"code","e950995e":"code","1efe82ee":"code","bfe70f55":"code","02f08d75":"code","3a4ad142":"code","32f8abba":"code","7d3c0485":"code","9455f0a3":"code","1eccb00a":"code","c607c303":"code","bd9e9ba0":"code","964290d7":"code","919631fe":"markdown","37fd0aa2":"markdown","12389fed":"markdown","4c1d0ad6":"markdown","75a8752d":"markdown","28b4952e":"markdown","606aa1fc":"markdown","f0d13b7b":"markdown","60eda905":"markdown","1a2cb673":"markdown","45cdf0e3":"markdown","f1dc2971":"markdown","31de697e":"markdown","eee44657":"markdown","660f97e6":"markdown","9061f84a":"markdown","dc953f35":"markdown"},"source":{"e7aab3f0":"import os\nimport re\nimport html as ihtml\n\nimport pandas as pd\nfrom bs4 import BeautifulSoup","14bad1b7":"input_dir = '..\/input'\n\nanswers = pd.read_csv(os.path.join(input_dir, 'answers.csv'))","715a3f3c":"def clean_text(text):\n    text = BeautifulSoup(ihtml.unescape(text)).text\n    text = re.sub(r\"http[s]?:\/\/\\S+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text)    \n    return text","a403e911":"sample_text = answers.loc[31425, \"answers_body\"]\nsample_text","bd9ec9d5":"sample_text = ihtml.unescape(sample_text)\nsample_text","e950995e":"sample_text = BeautifulSoup(sample_text, \"lxml\").text\nsample_text","1efe82ee":"sample_text = re.sub(r\"\\s+\", \" \", sample_text)\nsample_text","bfe70f55":"def clean_text(text):\n    text = BeautifulSoup(ihtml.unescape(text), \"lxml\").text\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text","02f08d75":"sample_text = answers.loc[13137, \"answers_body\"]\nsample_text","3a4ad142":"sample_text = clean_text(sample_text)\nsample_text","32f8abba":"re.sub(r\"http[s]?:\/\/\\S+\", \"\", sample_text)","7d3c0485":"def clean_text(text):\n    text = BeautifulSoup(ihtml.unescape(text), \"lxml\").text\n    text = re.sub(r\"http[s]?:\/\/\\S+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text\nclean_text(answers.loc[13137, \"answers_body\"])","9455f0a3":"import spacy\nnlp = spacy.load('en_core_web_sm')\nnlp.remove_pipe('parser')\nnlp.remove_pipe('ner')\nnlp.remove_pipe('tagger')\n\n\" \".join(\n    [token.lower_ for token in \n     list(nlp.pipe([clean_text(answers.loc[13137, \"answers_body\"])], n_threads=1))[0]]\n)","1eccb00a":"%timeit answers.loc[~answers[\"answers_body\"].isnull(), \"answers_body\"].apply(clean_text)","c607c303":"results = answers.loc[~answers[\"answers_body\"].isnull(), \"answers_body\"].apply(clean_text)","bd9e9ba0":"answers[\"answers_body\"][0]","964290d7":"results[0]","919631fe":"### Spacy","37fd0aa2":"We can also optionally remove hyperlinks as well:","12389fed":"Final function:","4c1d0ad6":"Double checking:","75a8752d":"### Hyperlinks","28b4952e":"## Contents\n\n1. [tl;dr](#tl;dr)\n2. [Development](#Development)\n  - [HTML entities](#HTML-entities)\n  - [BeautifulSoup](#BeautifulSoup)\n  - [Spacing](#Spacing)\n  - [Hyperlinks](#Hyperlinks)\n  - [Spacy](#Spacy)\n3. [Performance](#Performance)","606aa1fc":"## Development","f0d13b7b":"### Spacing\nRegularize spacing:","60eda905":"### HTML entities\nUnescape HTML entities:","1a2cb673":"Preview the tokenization results of Spacy:","45cdf0e3":"It's already fast enough. No need to do parallelization.","f1dc2971":"## Performance","31de697e":"### BeautifulSoup\nRemove HTML tags (note \"<apta.org>\" is also removed. That's an unfortunate false positive.):","eee44657":"Combining what we have so far:","660f97e6":"## tl;dr\n\nApply this function before spacy tokenization:","9061f84a":"# Remove HTML Tags using BeautifulSoup\n\nThis kernel assumes that you use Spacy to tokenize the texts. Spacy is not able to process HTML tags properly, so some preprocessing needs to be done. \n\nYou can choose to remove punctuations, certain types of words (e.g. adjectives, adverbs) after the tokenization. Here we just focus on getting the texts ready for Spacy.","dc953f35":"Pick a sample:"}}