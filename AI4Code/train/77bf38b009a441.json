{"cell_type":{"e874b312":"code","cbb862b8":"code","daedadef":"code","ebc3738c":"code","42f6b5e6":"code","1819d61e":"code","cc58cb4b":"code","3551e5a6":"code","1aafa6ba":"code","089fc382":"code","b05d1d1f":"code","cb497200":"markdown","fbf247b2":"markdown","d2ab3466":"markdown","c9f47e4f":"markdown","220a843b":"markdown","d960879c":"markdown","20b13b2c":"markdown","c20b2d09":"markdown","fe3b104b":"markdown","1a5aa1f1":"markdown","3ac1d9ac":"markdown"},"source":{"e874b312":"# Usados na importa\u00e7\u00e3o e tratamento dos dados\nimport math, re, os\nimport numpy as np\n\n# Biblioteca de redes neurais\nimport tensorflow as tf\n\n# Necess\u00e1rio para rodar em TPU\nfrom kaggle_datasets import KaggleDatasets","cbb862b8":"# Tenta se conectar em uma TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\n# Se consegui configura para rodar na TPU\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    \n# Sen\u00e3o define uma estrat\u00e9gia que funciona para CPU ou GPU\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","daedadef":"# Adquire o path do Google Cloud Storage para o dataset dessa competi\u00e7\u00e3o \nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_PATH)","ebc3738c":"IMAGE_SIZE = [192, 192]\nGCS_PATH = GCS_DS_PATH + '\/tfrecords-jpeg-192x192'\nAUTO = tf.data.experimental.AUTOTUNE\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/train\/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/val\/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/test\/*.tfrec') \n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","42f6b5e6":"def data_augment(image, label):\n    # Thanks to the dataset.prefetch(AUTO)\n    # statement in the next function (below), this happens essentially\n    # for free on TPU. Data pipeline code is executed on the \"CPU\"\n    # part of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","1819d61e":"# Define o tamanho do batch, baseando no n\u00famero de n\u00facleos de TPU dispon\u00edveis\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n# Gera os datasets separados em treino, valida\u00e7\u00e3o e teste\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()","cc58cb4b":"with strategy.scope():\n    # Importando o modelo j\u00e1 treinado\n    model = tf.keras.applications.xception.Xception(\n        weights='imagenet',\n        # Exclui a \u00faltima camada, vai ser trocada para ser espec\u00edfica para o problema \n        include_top=False ,\n        # Define o tamanho do dado de entrada\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    \n    # \"Congela\" os pesos da rede, assim s\u00f3 a \u00faltima camada nova vai ser treinada\n    model.trainable = False\n    \n    model = tf.keras.Sequential([\n        # O modelo base est\u00e1 treinado com ImageNet\n        model,\n        # O final da rede \u00e9 alterado para se adequar ao problema\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","3551e5a6":"# Definindo o otimizador, fun\u00e7\u00e3o perda e m\u00e9tricas\nmodel.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","1aafa6ba":"EPOCHS = 10\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","089fc382":"with strategy.scope():\n    model = tf.keras.applications.xception.Xception(\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    \n    \n    model = tf.keras.Sequential([\n        model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\nmodel.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","b05d1d1f":"with strategy.scope():\n    model = tf.keras.applications.xception.Xception(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    \n    \n    model = tf.keras.Sequential([\n        model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\nmodel.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","cb497200":"## 0 - Importa\u00e7\u00f5es","fbf247b2":"# Transfer Learning, GPUs e TPUs\nEsse notebook foi criado com base no tutorial de Ryan Holbrook, dispon\u00edvel no pr\u00f3prio Kaggle: https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission\n\nA competi\u00e7\u00e3o de Flower Classification on TPU foi criada para ensinar os usu\u00e1rios a utilizarem os recursos de aceleradores do Kaggle, pois treinar uma rede neural no dataset dessa competi\u00e7\u00e3o usando s\u00f3 a CPU seria extremamente demorado.","d2ab3466":"#### Transfer learning sem congelar as camadas iniciais:","c9f47e4f":"Em seguida, \u00e9 preciso importar os dados e transformar as imagens para elas ficarem em um formato adequado para serem utilizadas pela rede neural. Nesse notebook o c\u00f3digo para isso \u00e9 o mesmo apresentado por Ryan Holbrook em: https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission.\n\nRecomendo muito ler esse tutorial para ter mais detalhes essa etapa.","220a843b":"## 2 - Definindo e treinando o modelo\nEm geral \u00e9 dif\u00edcil decidir uma arquitetura de rede neural do zero, por isso, em muitos casos compensa adotar uma arquitetura j\u00e1 existente para o problema que queremos resolver. Essas redes podem ser encontradas pesquisando artigos recentes sobre alguma \u00e1rea espec\u00edfica, por exemplo, classifica\u00e7\u00e3o de imagens que \u00e9 o caso desse dataset.\n\n#### Transfer Learning\nPodemos usar peda\u00e7o de um modelo j\u00e1 treinado em algum dataset para come\u00e7ar na frente em algum dataset novo.\nIsso \u00e9 feito reutilizando os par\u00e2metros treinados como inicializa\u00e7\u00e3o para a rede inv\u00e9s de iniciar os pesos e vi\u00e9ses do zero. Tamb\u00e9m \u00e9 comum \"congelar\" camadas para que n\u00e3o sejam treinadas. Isso tamb\u00e9m ajuda a acelerar o treinamento.\n\nEsse procedimento funciona pois as features aprendidas pela rede s\u00e3o reutilizadas ao usar os pesos de uma rede j\u00e1 treinada em um problema parecido. \u00c9 comum achar redes de artigos j\u00e1 treinadas em datasets como o ImageNet para o problema de classifica\u00e7\u00e3o de imagens, inclusive v\u00e1rias est\u00e3o implementadas no pr\u00f3prio TensorFlow.\n\nAlgumas redes implementadas no Keras podem ser encontradas em tf.keras.applications: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications","d960879c":"Para executar o c\u00f3digo em uma TPU tamb\u00e9m \u00e9 necess\u00e1rio usar um dataset armazenado em um Google Cloud Storage Bucket. No caso de dados dispon\u00edveis no Kaggle, \u00e9 poss\u00edvel conseguir o path adequado usando a biblioteca kaggle_datasets.","20b13b2c":"Existem 3 modos de executar seus c\u00f3digos no Kaggle:\n* **CPU** (sem acelerador): Processador comum, \u00e9 suficiente para algumas aplica\u00e7\u00f5es, mas quase nunca d\u00e1 conta para redes neurais grandes, que usam muitos dados no treinamento.\n* **GPU**: Unidade de processamento especializada em processar blocos de dados em paralelo. Torna o treinamento das redes muito mais r\u00e1pido, pois as bibliotecas tomam proveito dessa propriedade para executar multiplas opera\u00e7\u00f5es simult\u00e2neamente (Vectorization).\n* **TPU**: Hardware especializado (ASIC) para executar c\u00f3digo do TensorFlow. Por ser especializado tende a ter a melhor performance, mas tamb\u00e9m tem v\u00e1rias particularidades.\n\nEnt\u00e3o, **como eu uso esses aceleradores?**\n\nNo caso do seu pr\u00f3prio PC o tensorflow a CPU j\u00e1 funciona sem mudar nada, mas se voc\u00ea quiser usar uma GPU voc\u00ea deve seguir a documenta\u00e7\u00e3o para garantir que a biblioteca consiga utilizar esse recurso:\nhttps:\/\/www.tensorflow.org\/install\/gpu\n\nObs: Por padr\u00e3o o tensorflow s\u00f3 funciona com placas de v\u00eddeo da Nvidia (inclusive pode funcionar s\u00f3 de ter os drivers instalados). Para placas da AMD existem meios alternativos, mas nenhum oficial do TensorFlow.\n\nNo Kaggle o procedimento \u00e9 mais simples: \u00e9 s\u00f3 clicar nos tr\u00eas pontos do canto superior direto, depois em \"Accelerator\" e escolher um acelerador. \n\n**Mas por qu\u00ea esses recursos aceleram o treinamento?**\n\n![diagrama_matrizes.png](attachment:ae5fca89-a8e3-4273-8e69-d88eac53eada.png)","c20b2d09":"#### Compara\u00e7\u00e3o de tempo para cada acelerador:\n* **CPU**: Aproximadamente 13 minutos por \u00e9poca\n* **GPU**: 33-34 segundos por \u00e9poca.\n* **TPU**: 5-6 segundos por \u00e9poca.\n\nSugiro rodar esse notebook mudando o acelerador do Kaggle para observar a diferen\u00e7a no tempo de treinamento. ","fe3b104b":"#### Sem transfer Learning:","1a5aa1f1":"\u00c9 poss\u00edvel ver que o modelo teve uma acur\u00e1cia maior sem aplicar transfer learning, isso provavelmente \u00e9 uma consequ\u00eancia de todos os pesos serem treinados para esse problema espec\u00edfico. Apesar disso, usar transfer learning fez com que o modelo tivesse uma acur\u00e1cia melhor nas primeiras \u00e9pocas. Tendo isso em vista, pode ser interessante treinar o modelo com pesos iniciais da ImageNet, mas todas as camadas trein\u00e1veis.","3ac1d9ac":"## 1 - Configura\u00e7\u00f5es iniciais e importa\u00e7\u00e3o dos dados\nPrimeiramente, como queremos ter a possibilidade de rodar o c\u00f3digo em uma TPU, precisamos definir uma estrat\u00e9gia de distribui\u00e7\u00e3o. Isso \u00e9 necess\u00e1rio, pois rodar algo em TPU \u00e9 como rodar em v\u00e1rias GPUs ou CPUs, e essa defini\u00e7\u00e3o distribui o treinamento nos v\u00e1rios n\u00facleos da TPU."}}