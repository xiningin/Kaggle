{"cell_type":{"796e9f9f":"code","0e69168d":"code","9216fa03":"code","43ae4cb6":"code","09345841":"code","d66e0c94":"code","b79259a6":"code","872f9770":"code","31c453cd":"code","7ba9e767":"code","3fba5de3":"code","c9f105e9":"code","941af48b":"code","193d8030":"code","59fe468f":"code","529ceab3":"code","3cb9b301":"code","897117df":"code","ef497f77":"code","9df61715":"code","fcdb17f1":"code","3d3843a0":"code","7f2b6321":"code","6bcc3d69":"code","fc770f5c":"code","cffdd9db":"code","c42d365e":"code","62a64e44":"code","7743aea9":"code","a7b5622c":"code","3d501cce":"code","9aa3f2d1":"code","c5c3099d":"code","8d723950":"code","f2dfbdc1":"code","555ba4bb":"code","abc14775":"code","a3a3863e":"code","f9c89378":"code","c65e33da":"code","2bb6fb44":"code","69d9bc53":"code","66f36a6e":"code","5e0e58f7":"code","82dcf387":"code","3c7297d7":"markdown","d8c7ea34":"markdown","ef9e8ef4":"markdown","8b0813b2":"markdown","239445e2":"markdown","c1378b88":"markdown","4252cf99":"markdown","60fc9704":"markdown","6ce48c4b":"markdown","1f1ae587":"markdown","ce801928":"markdown","d0c9d1b2":"markdown","a295f6cd":"markdown","f62195a0":"markdown","334013d2":"markdown","cd79ae83":"markdown","ebf392dd":"markdown","8f833b71":"markdown","0ce358a4":"markdown","0064e66c":"markdown","cafa3a40":"markdown","92799eb8":"markdown","2deaa32e":"markdown","3e19ab9e":"markdown","c8b9e01b":"markdown","92ab8806":"markdown","cb37cc81":"markdown","675c7f9d":"markdown","d3219559":"markdown","bb5bbc87":"markdown","fc3cd813":"markdown","26b12d12":"markdown","eaa374e8":"markdown","2a623ac9":"markdown","3863c4b4":"markdown","5b9dd720":"markdown","2504f9d8":"markdown","f989d700":"markdown","d2462713":"markdown","4d86c5cf":"markdown","706b2989":"markdown","0ad08966":"markdown","606fadab":"markdown","42a12381":"markdown","d3ad40f3":"markdown","39b0065a":"markdown","9cd50577":"markdown","43c4ae95":"markdown","dfe6bc8f":"markdown","878b92d2":"markdown","8e559207":"markdown","9fd5ad0a":"markdown","cca5ce82":"markdown","b88bc6c0":"markdown","14eff0ca":"markdown","12d7cc97":"markdown","cda3b265":"markdown","edd88caa":"markdown","83d571fb":"markdown","4c36079f":"markdown","39801bfb":"markdown","9aaa0025":"markdown"},"source":{"796e9f9f":"# import libraries\nimport pandas as pd # for data manupulation or analysis\nimport numpy as np # for numeric calculation\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for data visualization","0e69168d":"#Load breast cancer dataset\nfrom sklearn.datasets import load_breast_cancer\ncancer_dataset = load_breast_cancer()\n","9216fa03":"cancer_dataset","43ae4cb6":"type(cancer_dataset)","09345841":"# keys in dataset\ncancer_dataset.keys()","d66e0c94":"# features of each cells in numeric format\ncancer_dataset['data']","b79259a6":"# malignant or benign value\ncancer_dataset['target']","872f9770":"# target value name malignant or benign tumor\ncancer_dataset['target_names']","31c453cd":"# description of data\nprint(cancer_dataset['DESCR'])","7ba9e767":"#name of feature\nprint(cancer_dataset['feature_names'])","3fba5de3":"# location\/path of data file\nprint(cancer_dataset['filename'])","c9f105e9":"# create datafrmae\ncancer_df = pd.DataFrame(np.c_[cancer_dataset['data'],cancer_dataset['target']],\n             columns = np.append(cancer_dataset['feature_names'], ['target']))","941af48b":"#DataFrame to csv file\ncancer_df.to_csv(\"breast_cancer_dataFrame.csv\")","193d8030":"#Head of cancer DataFrame\ncancer_df.head(7)","59fe468f":"# Tail of cancer DataFrame\ncancer_df.tail(6) ","529ceab3":"# Information of cancer Dataframe\ncancer_df.info()","3cb9b301":"# Numerical distribution of data\ncancer_df.describe()","897117df":"cancer_df.isnull().sum()","ef497f77":"# pair plot of sample feature\nsns.pairplot(cancer_df, hue = 'target', \n             vars = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'] )","9df61715":"# Count the target class\nsns.countplot(cancer_df['target'])","fcdb17f1":"# counter plot of feature mean radius\nplt.figure(figsize = (20,8))\nsns.countplot(cancer_df['mean radius'])\n","3d3843a0":"# heatmap of DataFrame\nplt.figure(figsize=(16,9))\nsns.heatmap(cancer_df)","7f2b6321":"\n# Heatmap of Correlation matrix of breast cancer DataFrame\nplt.figure(figsize=(20,20))\nsns.heatmap(cancer_df.corr(), annot = True, cmap ='coolwarm', linewidths=2)","6bcc3d69":"# create second DataFrame by droping target\ncancer_df2 = cancer_df.drop(['target'], axis = 1)\nprint(\"The shape of 'cancer_df2' is : \", cancer_df2.shape)","fc770f5c":"# visualize correlation barplot\nplt.figure(figsize = (16,5))\nax = sns.barplot(cancer_df2.corrwith(cancer_df.target).index, cancer_df2.corrwith(cancer_df.target))\nax.tick_params(labelrotation = 90)","cffdd9db":"# input variable\nX = cancer_df.drop(['target'], axis = 1)\nX.head(6)","c42d365e":"# output variable\ny = cancer_df['target']\ny.head(6)","62a64e44":"# split dataset into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)\n","7743aea9":"# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","a7b5622c":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","3d501cce":"# Support vector classifier\nfrom sklearn.svm import SVC\nsvc_classifier = SVC()\nsvc_classifier.fit(X_train, y_train)\ny_pred_scv = svc_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_scv)","9aa3f2d1":"# Train with Standard scaled Data\nsvc_classifier2 = SVC()\nsvc_classifier2.fit(X_train_sc, y_train)\ny_pred_svc_sc = svc_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_svc_sc)","c5c3099d":"# XGBoost Classifier\nfrom xgboost import XGBClassifier\nxgb_classifier = XGBClassifier()\nxgb_classifier.fit(X_train, y_train)\ny_pred_xgb = xgb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_xgb)","8d723950":"# Train with Standard scaled Data\nxgb_classifier2 = XGBClassifier()\nxgb_classifier2.fit(X_train_sc, y_train)\ny_pred_xgb_sc = xgb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_xgb_sc)","f2dfbdc1":"# XGBoost classifier most required parameters\nparams={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] \n}","555ba4bb":"# Randomized Search\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_search = RandomizedSearchCV(xgb_classifier, param_distributions=params, scoring= 'roc_auc', n_jobs= -1, verbose= 3)\nrandom_search.fit(X_train, y_train)","abc14775":"random_search.best_params_","a3a3863e":"{'min_child_weight': 1,\n 'max_depth': 3,\n 'learning_rate': 0.3,\n 'gamma': 0.4,\n 'colsample_bytree': 0.3}","f9c89378":"random_search.best_estimator_","c65e33da":"# training XGBoost classifier with best parameters\nxgb_classifier_pt = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bynode=1, colsample_bytree=0.4, gamma=0.2,\n       learning_rate=0.1, max_delta_step=0, max_depth=15,\n       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n       nthread=None, objective='binary:logistic', random_state=0,\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n       silent=None, subsample=1, verbosity=1)\n \nxgb_classifier_pt.fit(X_train, y_train)\ny_pred_xgb_pt = xgb_classifier_pt.predict(X_test)\n","2bb6fb44":"accuracy_score(y_test, y_pred_xgb_pt)","69d9bc53":"cm = confusion_matrix(y_test, y_pred_xgb_pt)\nplt.title('Heatmap of Confusion Matrix', fontsize = 15)\nsns.heatmap(cm, annot = True)\nplt.show()","66f36a6e":"print(classification_report(y_test, y_pred_xgb_pt))","5e0e58f7":"# Cross validatio\nfrom sklearn.model_selection import cross_val_score\ncross_validation = cross_val_score(estimator = xgb_classifier_pt, X = X_train_sc,y = y_train, cv = 10)\nprint(\"Cross validation accuracy of XGBoost model = \", cross_validation)\nprint(\"\\nCross validation mean accuracy of XGBoost model = \", cross_validation.mean())","82dcf387":"## Pickle\nimport pickle\n \n# save model\npickle.dump(xgb_classifier_pt, open('breast_cancer_detector.pickle', 'wb'))\n \n# load model\nbreast_cancer_detector_model = pickle.load(open('breast_cancer_detector.pickle', 'rb'))\n \n# predict the output\ny_pred = breast_cancer_detector_model.predict(X_test)\n \n# confusion matrix\nprint('Confusion matrix of XGBoost model: \\n',confusion_matrix(y_test, y_pred),'\\n')\n \n# show the accuracy\nprint('Accuracy of XGBoost model = ',accuracy_score(y_test, y_pred))","3c7297d7":"# XGBoost Classifier","d8c7ea34":"# Breast Cancer Detection Machine Learning Model Building","ef9e8ef4":"# **Create DataFrame**","8b0813b2":"Breast cancer is a dangerous disease for women. If it does not identify in the early-stage then the result will be the death of the patient. It is a common cancer in women worldwide. Worldwide near about 12% of women affected by breast cancer and the number is still increasing.\n\nThe doctors do not identify each and every breast cancer patient. That\u2019s the reason Machine Learning Engineer \/ Data Scientist comes into the picture because they have knowledge of maths and computational power. ","239445e2":"Getting information of cancer DataFrame using \u2018.info()\u2018 method.","c1378b88":"# Split DataFrame in train and test","4252cf99":"To get more accuracy, we trained all supervised classification algorithms but you can try out a few of them which are always popular. After training all algorithms, we found that Logistic Regression, Random Forest and XGBoost classifiers are given high accuracy than remain but we have chosen XGBoost.\n\nAs ML Engineer, we always retrain the deployed model after some period of time to sustain the accuracy of the model. We hope our efforts will save the life of breast cancer patients.","60fc9704":"# Data Preprocessing","6ce48c4b":"# Data Visualization","1f1ae587":"Converting different units and magnitude data in one unit.","ce801928":"The scikit-learn store data in an object bunch ,like a dictionary. mean we have data in the form of dictionary which is called as bunch in sklearn","d0c9d1b2":"after extraction of cell tumor , we got this type of data\n\nWhen we call load_breast_cancer() class it downloads breast_cancer.csv file and you can see file location.","a295f6cd":"Here we can see that XGboost classifier is the best classifier for our dataset because it gives the 98.2% accuracy.Now we have to check whether our model is generalised or overfitted beacuse XGBoost classifier is very complex classifier.and when we use complex classifier then it probably becomes so much overfitted.and also we have very less data so we can identity it is overfitted or not. \n\nso here we check the confusion matrix ","f62195a0":"# XGBoost Parameter Tuning Randomized Search","334013d2":"In the below counterplot max samples mean radius is equal to 1","cd79ae83":"# We have completed the Machine learning Project successfully with 98.24% accuracy which is great for \u2018Breast Cancer Detection using Machine learning\u2019 project. Now, we are ready to deploy our ML model in the healthcare project.","ebf392dd":"The model is giving 0% type II error and it is best.it means it classify the best way to any patient whetere they have cancer or not.now the 2% of people , i have considered as a cancer patient. so that our model give best accuracy.\n","8f833b71":"# Heatmap of a correlation matrix","0ce358a4":"# Classification Report of Model","0064e66c":"**In seaborn, the hue parameter determines which column in the data frame should be used for colour encoding.Adding  hue=\"target\" \ntells seaborn you want to colour the data points for malignant and benign differently.**","cafa3a40":"here we can see that the mean area is from 800 to 2400 and worst area is also 800 to 200 and rest of them have nearly 0","92799eb8":"The target stores the values of malignant or benign tumors.","2deaa32e":"**0 means malignant tumor**\n\n**1 mean benign tumor**","3e19ab9e":"# Introduction","c8b9e01b":"Taking the correlation of each feature with the target and the visualize barplot.","92ab8806":"Showing the total count of malignant and benign tumor patients in counterplot.","cb37cc81":"Pair plot of breast cancer data","675c7f9d":" no. of patient have mailgnant tumor is 200\n \nno. of patient have benign tumor is 350","d3219559":"# Confusion Matrix","bb5bbc87":"In the below heatmap we can see the variety of different feature\u2019s value. The value of feature **\u2018mean area**\u2019 and **\u2018worst area\u2019** are greater than other and **\u2018mean perimeter\u2019**, **\u2018area error\u2019**, and **\u2018worst perimeter\u2019** value slightly less but greater than remaining features.","fc3cd813":"# Heatmap of breast cancer DataFrame","26b12d12":"#  Counterplot","eaa374e8":"# Pair plot of sample feature of DataFrame","2a623ac9":"The cancer_dataset[\u2018DESCR\u2019] store the description of breast cancer dataset.","3863c4b4":"# The mean accuracy value of cross-validation is 96.24% and XGBoost model accuracy is 98.24%. It showing XGBoost is slightly overfitted but when training data will more it will generalized model","5b9dd720":"After completion of the Machine Learning project or building the ML model need to deploy in an application. To deploy the ML model need to save it first. To save the Machine Learning project we can use the pickle or joblib package.\n\nHere, we will use pickle, Use anyone which is better for you.","2504f9d8":"# Heatmap","f989d700":"We have extracted features of breast cancer patient cells and normal person cells.we have to create a machine Learning Model and classify malignanat and benign tumor.\nFor this we are going to use the supervised machine learning classifier algorithm.","d2462713":"# Introduction","4d86c5cf":"# Save the Machine Learning model","706b2989":"# Data Manupulation","0ad08966":"Now, we are creating DataFrame by concate \u2018data\u2019 and \u2018target\u2019 together and give columns name","606fadab":"# Correlation barplot","42a12381":"We are loading breast cancer data using a scikit-learn load_brast_cancer class.","d3ad40f3":"# Cross-validation of the ML model","39b0065a":"**We have clean and well formated DataFrame, so DataFrame is ready to visualize.**","9cd50577":"**The pair plot showing malignant and benign tumor data distributed in two classes.\nIt is easy to differentiate in the pair plot.\n**","43c4ae95":"from this we can see the patient have breast cancer their mean radius>1 and who dont have breast cancer   their mean radius is 1","dfe6bc8f":"**In the above correlation barplot only feature \u2018smoothness error\u2019 is strongly positively correlated with the target than others. The features \u2018mean factor dimension\u2019, \u2018texture error\u2019, and \u2018symmetry error\u2019 are very less positive correlated and others remaining are strongly negatively correlated.**","878b92d2":" Here we have checked whether there is any  null value is there or not. and we got there is no null values.","8e559207":"![breastcancer.jpg](attachment:breastcancer.jpg)","9fd5ad0a":"# Support Vector Classifier","cca5ce82":"We have a total of non-null 569 patients\u2019 information with 31 features. All feature data types in the float. The size of the DataFrame is 137.9 KB.\n\n\nNumerical distribution of data. We can know to mean, standard deviation, min, max, 25%,50% and 75% value of each feature.","b88bc6c0":"We have clean data to build the Ml model. But which Machine learning algorithm is best for the data we have to find. The output is a categorical format so we will use supervised classification machine learning algorithms.\n\n\nTo build the best model, we have to train and test the dataset with multiple Machine Learning algorithms then we can find the best ML model. So let\u2019s try.\n\n\nFirst, we need to import the required packages","14eff0ca":"The tail of cancer DataFrame","12d7cc97":"To find a correlation between each feature and target we visualize heatmap using the correlation matrix.","cda3b265":"here we can see the correlation of dataset .most of the values are correlated","edd88caa":"To find the ML model is overfitted, under fitted or generalize doing cross-validation.","83d571fb":"# Load breast cancer dataset & explore it","4c36079f":"# Import essential libraries","39801bfb":"After looking this description we can see that total patients we have 569 and 30 numeric feature","9aaa0025":"These numeric values are extracted features of each cell."}}