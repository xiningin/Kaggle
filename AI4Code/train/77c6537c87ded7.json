{"cell_type":{"014055bb":"code","ca2c8d24":"code","57211376":"code","76a2ac6f":"code","30c22204":"code","542f65c9":"code","568ec4b9":"code","669bcee8":"code","6f1636aa":"code","43437eb6":"code","5c1d2ad7":"code","5c81e66d":"code","b266a67c":"code","1c58f5c6":"code","c81c2cf4":"code","77ef11b3":"code","5b421529":"code","e6a24fdb":"code","fa8e8b2c":"code","dad30181":"code","956a1e00":"code","c6dd2109":"code","f7a3bfab":"code","a353ccdf":"code","7416ae30":"code","09cf6492":"code","d6576d54":"code","df3b1780":"code","0ba4a178":"code","7aa48621":"code","1c07e6c9":"code","899a8a67":"code","7809d74b":"code","d5ff9120":"code","8f052288":"code","f89da022":"code","32a764c8":"code","7ec4cbab":"code","d17af35e":"code","6342c461":"code","3eb33207":"code","8f2cf2d7":"code","3b2a3e43":"code","ae1a5fe7":"markdown","b17207d7":"markdown","1e3fdb33":"markdown","9f24ab7a":"markdown","3dca0cef":"markdown","8ec80481":"markdown","686eee0a":"markdown","0d0cb84a":"markdown","5ca7b9f7":"markdown","64fac2df":"markdown","ccff716d":"markdown","099e067c":"markdown","010db5d5":"markdown","33686fd1":"markdown","034be57a":"markdown","a59cffd6":"markdown","c13aa0ac":"markdown","861e8c65":"markdown","5cbbaae1":"markdown","75b1f729":"markdown","75d334ac":"markdown"},"source":{"014055bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ca2c8d24":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","57211376":"avocado = pd.read_csv(\"..\/input\/avocado.csv\")","76a2ac6f":"print ('There are',len(avocado.columns),'columns:')\nfor x in avocado.columns:\n    print(x+' ',end=',')","30c22204":"avocado.head()","542f65c9":"avocado.tail()","568ec4b9":"avocado.info()","669bcee8":"avocado['type'].value_counts()","6f1636aa":"sns.heatmap(avocado.isnull(),yticklabels=False)","43437eb6":"avocado.columns.values","5c1d2ad7":"sns.jointplot(x='Large Bags',y='Small Bags',data=avocado)","5c81e66d":"sns.jointplot(x='XLarge Bags',y='Large Bags',data=avocado)","b266a67c":"sns.jointplot(x='Small Bags',y='XLarge Bags',data=avocado)","1c58f5c6":"sns.countplot(avocado['type'])","c81c2cf4":"avocado = avocado.drop(['Unnamed: 0','Date'],axis=1)","77ef11b3":"avocado.head()","5b421529":"from sklearn.feature_extraction import FeatureHasher\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.grid_search import GridSearchCV","e6a24fdb":"len(avocado['region'].value_counts())","fa8e8b2c":"fh = FeatureHasher(n_features=5,input_type='string')","dad30181":"hashed_features = fh.fit_transform(avocado['region']).toarray()","956a1e00":"avocado = pd.concat([avocado,pd.DataFrame(hashed_features)],axis=1)","c6dd2109":"avocado.head()","f7a3bfab":"avocado = avocado.drop('region',axis=1)","a353ccdf":"X = avocado.drop('type',axis=1)\ny = avocado['type']","7416ae30":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","09cf6492":"rfc = RandomForestClassifier(n_estimators=100)","d6576d54":"rfc.fit(X_train,y_train)","df3b1780":"pred1 = rfc.predict(X_test)","0ba4a178":"print(classification_report(y_test,pred1))","7aa48621":"print(confusion_matrix(y_test,pred1))","1c07e6c9":"knn = KNeighborsClassifier(n_neighbors=5)","899a8a67":"knn.fit(X_train,y_train)","7809d74b":"pred2 = knn.predict(X_test)","d5ff9120":"print(classification_report(y_test,pred2))","8f052288":"print(confusion_matrix(y_test,pred2))","f89da022":"params = {'C':[1,10,100,1000,10000],'gamma':[1,0.1,0.01,0.001,0.0001]}","32a764c8":"grid = GridSearchCV(SVC(),params,verbose=3)\n","7ec4cbab":"grid.fit(X_train,y_train)","d17af35e":"grid.best_params_","6342c461":"grid.best_estimator_","3eb33207":"pred3 = grid.predict(X_test)","8f2cf2d7":"print(classification_report(y_test,pred3))","3b2a3e43":"print(confusion_matrix(y_test,pred3))","ae1a5fe7":"# USING RANDOM FOREST CLASSIFIER.","b17207d7":"# DATA EXPLORATION ","1e3fdb33":"Best Parameters for C and gamma","9f24ab7a":"Dropping Region column as we have created hashed features out of them so this category is now of no use while training our model.","3dca0cef":"Our  trained model is giving 100% accuracy!!!","8ec80481":"# LOADING DATA SET ","686eee0a":"#  USING KNearestNeighbors","0d0cb84a":"# IMPORTING SOME MORE LIBRARIES TO PREDICT THE 'TYPE'","5ca7b9f7":"Head of new dataset.","64fac2df":"Our model is giving (false positive) + (false negatives) = 3.\nTotal 3 inaccurate predictions which is pretty awesome.","ccff716d":"# USING SVM","099e067c":"Dropping Unnamed: 0 and Date column from avocado dataset","010db5d5":"# Feature Hashing \nFrom feature_extraction we import Feature Hasher. Since region category contains 54 different regions so its not possible to direct pass this category while training the model, so Feature Hashing allows us to overcome this problem by letting us to encode them in a unique codes for each region, and then passing it to our model will increase our model's accuracy!","33686fd1":"# PREDICTION OF \"TYPE\" COLUMN","034be57a":"Dataset after dropping Unnamed: 0 and Date columns","a59cffd6":"So at last we have tried Random Forest Classifier, KNN and SVM but most efficient among them is Random Forest Classifier giving 100% accuracy, KNN is also not too bad as it has 98% accuracy but Support Vector Classifier(SVC) is not that much efficient in predicting the values having only 54% accuracy for conventional and 100% accuracy for organic type.\nRecommended Model for prediction of TYPE(coventional and organic categories) columns is Random Forest Classifier.","c13aa0ac":"Dataset is uniformly distributed as both categories conventional as well as organic type has approximately same entries","861e8c65":"# IMPORTING LIBRARIES","5cbbaae1":"Different types of region.","75b1f729":"no null values in the dataset.","75d334ac":"Manually sending list of parameters C and gamma so to get a best combination of parameters ."}}