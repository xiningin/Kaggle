{"cell_type":{"11dc7a78":"code","1a91cfef":"code","b9c3a133":"code","e06d521d":"code","7467f2f7":"code","cc9edb67":"code","52b0b0ba":"code","d7833268":"code","79054bd4":"code","79e3aaa0":"code","e9400f4d":"code","862f8a57":"code","e2192a6c":"code","e7b686cd":"code","7ab39db3":"code","a9cdfaf4":"code","63e5e38d":"code","c962feef":"code","45505b85":"code","14fc60b0":"code","d7828e37":"code","83c9d5b5":"code","65ed3405":"code","9d1aac3a":"code","7156d6c9":"code","5b30d93e":"code","76583661":"code","03b56588":"code","a2b58077":"code","b965e429":"code","17f28d32":"code","d63d78f2":"code","7f3704f2":"code","c834c802":"code","48b48aaf":"code","2913a9b4":"markdown","cca1ac83":"markdown","80ac8209":"markdown","2e1d3055":"markdown","4287a393":"markdown","cc1b6456":"markdown","34b1867e":"markdown","eae8e08b":"markdown","7566fd7d":"markdown","3dec744d":"markdown","5d77f805":"markdown","c95e549c":"markdown","5703826d":"markdown","072b277b":"markdown","3aceff4e":"markdown","aab73dc1":"markdown","d400c46f":"markdown","f376b3a1":"markdown"},"source":{"11dc7a78":"!pip install emoji","1a91cfef":"import re\nimport regex\nimport pandas as pd\nimport numpy as np\nimport emoji\nimport plotly.express as px\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","b9c3a133":"def startsWithDateAndTime(s):\n    pattern = '^([0-9]+)(\\\/)([0-9]+)(\\\/)([0-9]+), ([0-9]+):([0-9][0-9]):([0-9][0-9]) (AM|PM|am|pm)? -'\n    result = re.match(pattern, s)\n    if result:\n        return True\n    return False","e06d521d":"def FindAuthor(s):\n    patterns = [\n        '([\\w]+):',                        # First Name\n        '([\\w]+[\\s]+[\\w]+):',              # First Name + Last Name\n        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # First Name + Middle Name + Last Name\n        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number (India)\n        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Mobile Number (US)\n        '([\\w]+)[\\u263a-\\U0001f999]+:',    # Name and Emoji              \n    ]\n    pattern = '^' + '|'.join(patterns)\n    result = re.match(pattern, s)\n    if result:\n        return True\n    return False","7467f2f7":"def getDataPoint(line):   \n    splitLine = line.split(' - ') \n    dateTime = splitLine[0]\n    date, time = dateTime.split(', ') \n    message = ' '.join(splitLine[1:])\n    if FindAuthor(message): \n        splitMessage = message.split(': ') \n        author = splitMessage[0] \n        message = ' '.join(splitMessage[1:])\n    else:\n        author = None\n    return date, time, author, message","cc9edb67":"def getDayPart(x):\n    if (x > 4) and (x <= 8):\n        return 'Early Morning'\n    elif (x > 8) and (x <= 12 ):\n        return 'Morning'\n    elif (x > 12) and (x <= 16):\n        return'Noon'\n    elif (x > 16) and (x <= 20) :\n        return 'Evening'\n    elif (x > 20) and (x <= 24):\n        return'Night'\n    elif (x <= 4):\n        return'Late Night'","52b0b0ba":"parsedData = [] # List to keep track of data so it can be used by a Pandas dataframe\n\nconversationPath = '..\/input\/whatsappchat\/WhatsAppChat.txt'\n\n\nwith open(conversationPath, encoding=\"utf-8\") as fp:\n    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n    messageBuffer = [] \n    date, time, author = None, None, None\n    while True:\n         \n        line = fp.readline() \n        if not line: \n            break\n        line = line.strip()\n        if startsWithDateAndTime(line):            \n            if len(messageBuffer) > 0: \n                parsedData.append([date, time, author, ' '.join(messageBuffer)]) \n            messageBuffer.clear() \n            date, time, author, message = getDataPoint(line) \n            messageBuffer.append(message) \n        else:\n            messageBuffer.append(line)","d7833268":"df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])","79054bd4":"df.head()","79e3aaa0":"df.info()","e9400f4d":"df.Author.unique()","862f8a57":"df = df.dropna()\ndf.info()","e2192a6c":"df.Author.unique()","e7b686cd":"total_messages = df.shape[0]\nprint(total_messages)","7ab39db3":"media_messages = df[df['Message'] == '<\u200eimage omitted>'].shape[0]\nprint(media_messages)","a9cdfaf4":"import emoji\n\ndef extract_emojis(s):\n  return ''.join(c for c in s if c in emoji.UNICODE_EMOJI['en'])\n\ndf[\"emoji\"] = df[\"Message\"].apply(extract_emojis)\nemojis = sum(df['emoji'].str.len())\nprint(emojis)","63e5e38d":"URLPATTERN = r'(https?:\/\/\\S+)'\ndf['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\nlinks = np.sum(df.urlcount)","c962feef":"print(\"Group Wise Stats\")\nprint(\"Messages:\",total_messages)\nprint(\"Media:\",media_messages)\nprint(\"Emojis:\",emojis)\nprint(\"Links:\",links)","45505b85":"media_messages_df = df[df['Message'] == '<\u200eimage omitted>']","14fc60b0":"messages_df = df.drop(media_messages_df.index)\nmessages_df.info()","d7828e37":"messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\nmessages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\nmessages_df[\"MessageCount\"]=1","83c9d5b5":"messages_df.head()","65ed3405":"messages_df[\"emojicount\"]= df['emoji'].str.len()","9d1aac3a":"l = messages_df.Author.unique()\n\nfor i in range(len(l)):\n  # Filtering out messages of particular user\n  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n  # req_df will contain messages of only one particular user\n  print(f'Stats of {l[i]} -')\n  # shape will print number of rows which indirectly means the number of messages\n  print('Messages Sent', req_df.shape[0])\n  #Word_Count contains of total words in one message. Sum of all words\/ Total Messages will yield words per message\n  words_per_message = (np.sum(req_df['Word_Count']))\/req_df.shape[0]\n  print('Words per message', words_per_message)\n  #media conists of media messages\n  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n  print('Media Messages Sent', media)\n  # emojis conists of total emojis\n  emojis = sum(req_df['emoji'].str.len())\n  print('Emojis Sent', emojis)\n  #links consist of total links\n  links = sum(req_df[\"urlcount\"])   \n  print('Links Sent', links)   \n  print()","7156d6c9":"def f(i):\n  l = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n  return l[i];\nday_df=pd.DataFrame(messages_df[\"Message\"])\nday_df['day_of_date'] = messages_df['Date'].dt.weekday\nday_df['day_of_date'] = day_df[\"day_of_date\"].apply(f)\nday_df[\"messagecount\"] = 1\nday = day_df.groupby(\"day_of_date\").sum() \nday.plot.barh()\nplt.xlabel('Number of Messages')\nplt.ylabel('Day')","5b30d93e":"messages_df['Hours'] = pd.to_datetime(messages_df['Time']).dt.strftime('%H')","76583661":"dt = messages_df['Hours'].value_counts()\ndt.head(24).plot.barh()\nplt.xlabel('Number of messages')\nplt.ylabel('Hours')","03b56588":"messages_df['DayPart'] = messages_df['Hours'].astype(int).apply(getDayPart)\ndaypart = messages_df['DayPart'].value_counts()\ndaypart.head().plot.barh()\nplt.xlabel('Number of messages')\nplt.ylabel('Part of the Day')","a2b58077":"author_value_counts = df['Author'].value_counts() # Number of messages per author\n#top_author_value_counts = author_value_counts.head() # Number of messages per author for the top 10 most active authors\nauthor_value_counts.plot.barh() # Plot a bar chart using pandas built-in plotting apis\nplt.xlabel('Number of Messages')\nplt.ylabel('Author')","b965e429":"author_media_messages_value_counts = media_messages_df['Author'].value_counts()\ntop_author_media_messages_value_counts = author_media_messages_value_counts.head()\ntop_author_media_messages_value_counts.plot.barh()\nplt.xlabel('Number of Media Messages')\nplt.ylabel('Author')","17f28d32":"total_word_count_grouped_by_author = messages_df[['Author', 'Word_Count']].groupby('Author').sum()\nsorted_total_word_count_grouped_by_author = total_word_count_grouped_by_author.sort_values('Word_Count', ascending=False)\n#top_sorted_total_word_count_grouped_by_author = sorted_total_word_count_grouped_by_author.head()\nsorted_total_word_count_grouped_by_author.plot.barh()\nplt.xlabel('Number of Words')\nplt.ylabel('Authors')","d63d78f2":"plt.figure(figsize=(15, 2)) # To ensure that the bar plot fits in the output cell of a Jupyter notebook\nword_count_value_counts = messages_df['Word_Count'].value_counts()\ntop_20_word_count_value_counts = word_count_value_counts.head(20)\ntop_20_word_count_value_counts.plot.bar()\nplt.xlabel('Word Count')\nplt.ylabel('Frequency')","7f3704f2":"plt.figure(figsize=(15, 2))\nletter_count_value_counts = messages_df['Letter_Count'].value_counts()\ntop_20_letter_count_value_counts = letter_count_value_counts.head(20)\ntop_20_letter_count_value_counts.plot.bar()\nplt.xlabel('Letter count')\nplt.ylabel('Frequency')","c834c802":"from sklearn.feature_extraction.text import CountVectorizer\nword_vectorizer = CountVectorizer(ngram_range=(1,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(messages_df['Message'])\nfrequencies = sum(sparse_matrix).toarray()[0]\npd1 = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\npd1.sort_values('frequency',inplace=True,ascending=False)\npd2 = pd1.head(20)\npd2.plot.bar()\nplt.xlabel('Word')\nplt.ylabel('Total word Count')","48b48aaf":"plt.figure(figsize=(18, 2))\ntotal_emoji_by_author = messages_df[['Author', 'emojicount']].groupby('Author').sum()\ntotal_emoji_by_author = total_emoji_by_author.sort_values('emojicount', ascending=False)\ntotal_emoji_by_author.plot.barh()\nplt.xlabel('Number of Emoji')\nplt.ylabel('Authors')","2913a9b4":"Messages by time","cca1ac83":"We can say Preeti is emoji lover, while Shradha dont like emoji.","80ac8209":"**Media messages count by author**","2e1d3055":"Lets Drop all data with blank Author","4287a393":"**Messages count by author**","cc1b6456":"Author has few blank data, that can be when someone added\/left group, or security messages from WhatsApp itself. ","34b1867e":"**Most Frequently used word**","eae8e08b":"**Total word count by author**","7566fd7d":"As we see graph, we can say - People prefers small messages.","3dec744d":"Although we can say similar about letters, but people have prefered big letter meassages as well","5d77f805":"**Most common word count in a message**","c95e549c":"Count ","5703826d":"**Emoji Lover**","072b277b":"We need to check Media messages. We can have image, video, or Media. But my dataset has only images","3aceff4e":"**Most common letter count in a message**","aab73dc1":"Vishnu and Shahain are most active users, while Shradha and Shweta are least active users","d400c46f":"We have few hindi text messages exchanged, thats why you are seeing above warning and blank text in graph.","f376b3a1":"# Basic functions"}}