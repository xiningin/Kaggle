{"cell_type":{"3d390f20":"code","b19cd081":"code","d4283fc1":"code","b6c165e7":"code","2a9b2e67":"code","45250342":"code","412e4b7c":"code","fbe88245":"code","c8d9e291":"code","3b864530":"code","9c8d69ef":"code","752e40ad":"code","d0903f38":"code","524c817f":"code","78e03e89":"code","133bcc1b":"code","882e3bfe":"code","c7e72bb6":"code","4d8fc999":"code","abe3ab34":"code","bf558d07":"code","650ac626":"code","35f95c82":"code","a04309cf":"code","3f8176ce":"code","3cb6e0fc":"code","84734a1c":"markdown","1e9d191b":"markdown","919f027b":"markdown","18e0dde4":"markdown","2c5860fb":"markdown","dc4cb9d8":"markdown","655fa4b7":"markdown","71e954ee":"markdown","d5c1d62b":"markdown","4a8743bf":"markdown","5a05f13a":"markdown","09b6385e":"markdown","7a7cf9fb":"markdown","3a79f94c":"markdown","946a55f1":"markdown","b8fa5628":"markdown","8eabed00":"markdown","674cd7cc":"markdown"},"source":{"3d390f20":"'''Importing Data Manipulattion Moduls'''\nimport numpy as np\nimport pandas as pd\n\n'''Seaborn and Matplotlib Visualization'''\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n'''Importing preprocessing libraries'''\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n'''Display markdown formatted output like bold, italic bold etc.'''\nfrom IPython.display import Markdown\ndef bold(string):\n    display(Markdown(string))","b19cd081":"'''Installing tensorflow version 2.0'''\n!pip install tensorflow==2.0.0-rc1","d4283fc1":"'''Importing tensorflow libraries'''\nimport tensorflow as tf \nprint(tf.__version__)\n\nfrom tensorflow.keras import layers, models","b6c165e7":"'''Read in train and test data from csv files'''\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","2a9b2e67":"'''Train and test data at a glance.'''\nbold('**Preview of Train Data:**')\ndisplay(train.head(3))\nbold('**Preview of Test Data:**')\ndisplay(test.head(3))","45250342":"'''Ckecking for null and missing values'''\nbold('**Train Data**')\ndisplay(train.isnull().any(). describe())\nbold('**Test Data**')\ndisplay(test.isnull().any(). describe())","412e4b7c":"'''Seting X and Y'''\ny_train = train['label']\n\n# Drop 'label' column\nX_train = train.drop('label', axis = 1)\n\nX_test = test","fbe88245":"\"\"\"Let's have a final look at our data\"\"\"\nbold('**Data Dimension for Model Building:**')\nprint('Input matrix dimension:', X_train.shape)\nprint('Output vector dimension:',y_train.shape)\nprint('Test data dimension:', X_test.shape)","c8d9e291":"plt.figure(figsize = (8,8))\nsns.countplot(y_train, palette='Paired')\nplt.show()","3b864530":"images = train.iloc[:,1:].values\nimages = images.astype(np.float)\n\n# convert from [0:255] => [0.0:1.0]\nimages = np.multiply(images, 1.0 \/ 255.0)\n\nimage_size = images.shape[1]\nprint('image_size => {0}'.format(image_size))\n\n# in this case all images are square\nimage_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n\nprint('image_width => {0}\\nimage_height => {1}'.format(image_width, image_height))","9c8d69ef":"'''Displaying image'''\n# display image\ndef display(img):\n    \n    # (784) => (28,28)\n    one_image = img.reshape(image_width,image_height)\n    \n    plt.axis('off')\n    plt.imshow(one_image, cmap='binary')\n\n# output image     \ndisplay(images[11])","752e40ad":"'''Normalizing the data'''\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","d0903f38":"'''Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)'''\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)","524c817f":"'''convert class labels from scalars to one-hot vectors'''\n# 0 => [1 0 0 0 0 0 0 0 0 0]\n# 1 => [0 1 0 0 0 0 0 0 0 0]\n# ...\n# 9 => [0 0 0 0 0 0 0 0 0 1]\ny_train = tf.keras.utils.to_categorical(y_train, num_classes = 10, dtype='uint8')","78e03e89":"'''Set the random seed'''\nseed = 44\n'''Split the train and the validation set for the fitting'''\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=seed)","133bcc1b":"'''weight initialization'''\ninput_size = 784\noutput_size = 10\nhidden_layer_size = 250\n\nmodel = tf.keras.Sequential([\n                            tf.keras.layers.Flatten(input_shape = (28,28,1)),\n                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n                            tf.keras.layers.Dense(hidden_layer_size, activation= 'relu'),\n                            tf.keras.layers.Dense(hidden_layer_size, activation= 'relu'),\n                            tf.keras.layers.Dense(output_size, activation='softmax')\n                             ])","882e3bfe":"OPTIMIZER = tf.optimizers.Adam(\n                    learning_rate=0.001,\n                    beta_1=0.9,\n                    beta_2=0.999,\n                    epsilon=1e-07,\n                    amsgrad=False,\n                   )\n\nmodel.compile(optimizer=OPTIMIZER, loss='categorical_crossentropy', metrics=['accuracy'])","c7e72bb6":"NUM_EPOCHS = 5\nBATCH_SIZE = 100\n\nHistory = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = NUM_EPOCHS, validation_data = (X_val, y_val), verbose = 2)","4d8fc999":"'''Training and validation curves'''\nfig, ax = plt.subplots(2,1)\nax[0].plot(History.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(History.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(History.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(History.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","abe3ab34":"'''predict results'''\nresults = model.predict(X_test)\n\n'''select the indix with the maximum probability'''\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","bf558d07":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission_nn_mnist.csv\",index=False)","650ac626":"'''Set the CNN model'''\n# CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28,28,1)))\nmodel.add(layers.Conv2D(32, (5, 5), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n          \nmodel.add(layers.Conv2D(64, (5, 5), activation='relu'))\nmodel.add(layers.Conv2D(64, (5, 5), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n          \nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(10, activation='softmax'))","35f95c82":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = 10, validation_data = (X_val, y_val), verbose = 2)","a04309cf":"'''Training and validation curves'''\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","3f8176ce":"'''predict results'''\nresults = model.predict(X_test)\n\n'''select the indix with the maximum probability'''\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","3cb6e0fc":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission_cnn_mnist.csv\",index=False)","84734a1c":"# 4. Model ANN\n![](https:\/\/image.ibb.co\/jYevxc\/5.jpg)","1e9d191b":"## 4.4 Evaluate the model","919f027b":"# Prediction and Submission","18e0dde4":"## 5.4 Evaluate the model","2c5860fb":"## 4.3 Training","dc4cb9d8":"## 5.2 Compile and Train the model","655fa4b7":"## 3.2 One Hot Ecoding","71e954ee":"## 4.1 Outline the model ANN","d5c1d62b":"# 3. Data Preprocessing","4a8743bf":"## 4.2 Optimizer And Loss function","5a05f13a":"# 5. Model CNN\n![](https:\/\/image.ibb.co\/mGJWpp\/gec2.jpg)","09b6385e":"## 3.1 Normalize Images\nRescale pixel values from the range of 0-255 to the range 0-1 preferred for neural network models.\n\nScaling data to the range of 0-1 is traditionally referred to as normalization.\n\nThis can be achieved by setting the rescale argument to a ratio by which each pixel can be multiplied to achieve the desired range.\n\nIn this case, the ratio is 1\/255 or about 0.0039.","7a7cf9fb":"# 2. Variable Description and Identification","3a79f94c":"## 3.3 Split data into train and valdiation set\n","946a55f1":"# 1. Importing Packages and Collecting Data","b8fa5628":"### REFERENCES NOTE:\n1. https:\/\/www.kaggle.com\/kanncaa1\/convolutional-neural-network-cnn-tutorial\n2. https:\/\/www.kaggle.com\/kanncaa1\/deep-learning-tutorial-for-beginners\n3. https:\/\/www.tensorflow.org\n4. https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6","8eabed00":"## 5.1 Outline the model CNN","674cd7cc":"# Prediction and Submission"}}