{"cell_type":{"981ffb1d":"code","d59680fe":"code","d142c285":"code","67825c51":"code","6e1d0ca6":"code","6a17da56":"code","9e2ea074":"code","bb8c70eb":"code","872ac123":"code","2a6af0df":"code","f4586f4e":"code","807018d5":"code","65f2c0c4":"code","3071b1b9":"code","bbf7ad21":"code","1c679f89":"markdown","129fc97a":"markdown","73827cac":"markdown","ea7cefc2":"markdown","e92aabac":"markdown","f13e8650":"markdown"},"source":{"981ffb1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport shutil\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d59680fe":"os.listdir('\/kaggle\/working')","d142c285":"#shutil.rmtree('\/kaggle\/working\/intel-image-classification\/')","67825c51":"\n## run only once\n### move all images to working dir (change this code according to your needs)\n\nsrc_dir = '\/kaggle\/input\/'\noutput_dir = '\/kaggle\/working\/intel-image-classification'\n\ntry :\n    shutil.copytree(src_dir, output_dir)\nexcept : \n    pass\n","6e1d0ca6":"\nprint(os.listdir('\/kaggle\/working\/intel-image-classification\/intel-image-classification\/seg_test\/seg_test'))","6a17da56":"train_dir = '\/kaggle\/working\/intel-image-classification\/intel-image-classification\/seg_train\/seg_train'\nvalidation_dir = '\/kaggle\/working\/intel-image-classification\/intel-image-classification\/seg_test\/seg_test'\ntrain_dir","9e2ea074":"# get count of distinct class\n\nnum = []\nname = []\n\nfor d in os.listdir(train_dir):\n    name.append(d)\n    num.append(len(os.listdir(os.path.join(train_dir, d))))\n\n\nsns.barplot(name, num)\nplt.title('Class distribution')\nplt.xlabel('classes')\nplt.ylabel('number os samples')\nplt.show()","bb8c70eb":"\ntrain_gen = \ntf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                           rotation_range=30,\n                                                           width_shift_range=0.2,\n                                                           height_shift_range=0.2,\n                                                           shear_range=0.2,\n                                                           zoom_range=0.3,\n                                                           horizontal_flip=True,\n                                                           vertical_flip=True)\n\ntrain_data = \ntrain_gen.flow_from_directory(directory=train_dir,\n                                    target_size=(150,150),\n                                    batch_size=32,\n                                    class_mode='categorical')\n\n# remember - do not augment the validation set\nvalidation_gen = \ntf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.\/255)\n\nvalidation_data = \nvalidation_gen.flow_from_directory(directory=validation_dir,\n                                                    target_size=(150,150),\n                                                    batch_size=32,\n                                                    class_mode='categorical')","872ac123":"# we will use tranfer learning from an inceptionV3 network\n\n\npretrained_model = \ntf.keras.applications.InceptionV3(include_top=False,\n                                                    input_shape=(150,150,3),\n                                                    weights='imagenet')\n\n# set the layers to non-trainable since they already carry weights from ImageNet\n\nfor layer in pretrained_model.layers:\n    layer.trainable = False\n\n#print the original model structure -> very long\n#pretrained_model.summary()","2a6af0df":"last_layer = pretrained_model.get_layer('mixed5')\nlast_layer_output = last_layer.output\nprint(last_layer_output)","f4586f4e":"# add you own layers to the end\n\n# flatten the last layer to match the output \nx = tf.keras.layers.Flatten()(last_layer_output)\n# add your fully connected layer\nx = tf.keras.layers.Dense(1280, activation=tf.keras.activations.relu)(x)\n# add a dropout layer\nx = tf.keras.layers.Dropout(0.2)(x)\n# add a prediction layer\nx = tf.keras.layers.Dense(6, activation=tf.keras.activations.softmax)(x)\n\nmodel = tf.keras.Model(pretrained_model.input, x)\n\nmodel.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n\n# print summary of the model -> very long\n# model.summary()","807018d5":"threshold = .8\nclass mycallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('accuracy') > threshold :\n            self.model.stop_training = True\n            print('\\n Stopping training as the model reached ', str(threshold), '% accuracy ')\n            \nmycallback_func = mycallback()","65f2c0c4":"# train model\nhistory = model.fit(train_data, validation_data=validation_data, epochs=10, callbacks=[mycallback_func], batch_size=32, verbose=1)","3071b1b9":"# plot accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['Training accuracy', 'Validation accuracy'])\nplt.show()\n","bbf7ad21":"# plot loss\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Training accuracy', 'Validation accuracy'])\nplt.show()\n","1c679f89":"Ok! we dont really need such a huge network and hence we shall use only a 50% of its layers","129fc97a":"1. move all image to working dir\n2. use image generators scale and augment the data (training and validation)\n3. build an inception model","73827cac":"**use image generators for scaling and augmentation**","ea7cefc2":"**Author - Rahul Mishra**\n\nHere I will augment the images and use inception v3 model from tensorflow and demonstrate a transfer learning in practice","e92aabac":"here are the parameters Ill pass for image augmentation in my (ImageDataGenerator) functions below\n\n1. rescale -> to normalize images since larger values will dominate smaller values and cause loss of information\n2. rotation_range -> rotate the images randomly to 30 degrees\n3. width_shift_range -> randomly shift the images left <-> right uptp 20%\n4. heigth_shift_range -> randomly shift the image up <-> down by 20%\n5. shear_range -> tilt the image back <-> front bt 20%\n6. horizontal_flip -> flip the image hrizontally\n7. vertical_flip -> flip the image vertically","f13e8650":"**Build model**"}}