{"cell_type":{"e2555171":"code","96d35de1":"code","1411f05d":"code","fb328d42":"code","3848d463":"code","7b017a9e":"code","e9faf0c0":"code","e3e7138e":"code","0c084c77":"code","8cbb29b8":"code","5914bd4a":"code","d68bc021":"code","221352a1":"code","674485f9":"code","12bc11cb":"code","ea26fafd":"code","0806d186":"markdown","156183f1":"markdown","e611135f":"markdown","1f216cc2":"markdown","a4e42c40":"markdown","c4c1b359":"markdown","9d234c3f":"markdown","2af66a13":"markdown","8bce62e5":"markdown","1eba8446":"markdown"},"source":{"e2555171":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96d35de1":"%%time\n# datatable installation with internet\n!pip install datatable==0.11.0 > \/dev\/null","1411f05d":"import datatable as dt","fb328d42":"%%time\n\ndata = pd.read_csv(\"\/kaggle\/input\/g-research-crypto-forecasting\/train.csv\")\n\nprint(\"Train size:\", data.shape)","3848d463":"%%time\ncsvDT = dt.fread(\"\/kaggle\/input\/g-research-crypto-forecasting\/train.csv\")","7b017a9e":"%%time \n# Convert datatable to pandas\ndf = csvDT.to_pandas()","e9faf0c0":"%%time\n# Writing dataset as hdf5\ndata.to_hdf(\"gCryptoTrain.h5\", \"gCryptoTrain\")","e3e7138e":"%%time\n# Writing dataset as feather\ndata.to_feather(\"gCryptoTrain.feather\")","0c084c77":"%%time\n# Writing dataset as parquet\ndata.to_parquet(\"gCryptoTrain.parquet\")","8cbb29b8":"%%time\n# Writing dataset as pickle\ndata.to_pickle(\"gCryptoTrain.pkl.gzip\")","5914bd4a":"%%time\n# Writing dataset as jay\ndt.Frame(data).to_jay(\"gCryptoTrain.jay\")","d68bc021":"%%time\n\ndata = pd.read_hdf(\"gCryptoTrain.h5\", \"gCryptoTrain\")\n\nprint(\"Train size:\", data.shape)","221352a1":"%%time\n\ndata = pd.read_feather(\"gCryptoTrain.feather\")\n\nprint(\"Train size:\", data.shape)","674485f9":"%%time\n\ndata = pd.read_parquet(\"gCryptoTrain.parquet\")\n\nprint(\"Train size:\", data.shape)","12bc11cb":"%%time\n\ndata = pd.read_pickle(\"gCryptoTrain.pkl.gzip\")\n\nprint(\"Train size:\", data.shape)","ea26fafd":"%%time\n\ndata = dt.fread(\"gCryptoTrain.jay\")\n\nprint(\"Train size:\", data.shape)","0806d186":"This notebook was born from this discussion: https:\/\/www.kaggle.com\/c\/g-research-crypto-forecasting\/discussion\/285291\n\nI just followed the notebooks cited by:\n* [@faisalalsrheed](https:\/\/www.kaggle.com\/faisalalsrheed) : https:\/\/www.kaggle.com\/pedrocouto39\/fast-reading-w-pickle-feather-parquet-jay basic explanation\n* [@carlmcbrideellis](https:\/\/www.kaggle.com\/carlmcbrideellis) : https:\/\/www.kaggle.com\/rohanrao\/tutorial-on-reading-large-datasets more in-depth knowledge\n\nCheck those notebooks and upvote them as they are gems. ","156183f1":"# Format: pickle","e611135f":"# Format: hdf5","1f216cc2":"# Wrtiting data to diferent file formats","a4e42c40":"# Format: CSV","c4c1b359":"# Format: jay","9d234c3f":"# Format: feather","2af66a13":"# Format: parquet","8bce62e5":"I would like to point out what [@jpmiller](https:\/\/www.kaggle.com\/jpmiller) said about pickle. \n\n> Pickle is easy, versatile and fine for personal use. There may be issues though in more general applications.\n> \n> * https:\/\/www.benfrederickson.com\/dont-pickle-your-data\/\n> * https:\/\/nedbatchelder.com\/blog\/202006\/pickles_nine_flaws.html","1eba8446":"But as suggested by [@jpmiller](https:\/\/www.kaggle.com\/jpmiller) you could also try this:\n\n> You might try flipping the operations here.\n> * Use datatable to read in the csv and convert to pandas (much faster than a pd.read_csv())\n> * Do your thing with the data in pandas\n> * Save the file back as pd.to_parquet() or feather, hd5"}}