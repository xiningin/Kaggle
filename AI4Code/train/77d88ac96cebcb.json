{"cell_type":{"94c6d22a":"code","5669b620":"code","3fa58d37":"code","42274c56":"code","f5844ac0":"code","bc2a048a":"code","f01a3c21":"code","98d78186":"code","f75aaec5":"code","b3331d96":"code","2c94ea71":"code","fa5a08fd":"code","a87ad1fb":"code","a4d7427a":"code","4e7d38d1":"code","80ccb203":"code","e5ee5652":"code","3f06897a":"code","2dd8bc3c":"code","e58aae52":"code","fbbe384c":"code","2bde4425":"code","8c35d4cb":"code","e4e47494":"code","26f70862":"code","8375fca4":"code","5f8b5fd7":"code","e842512b":"code","da09f9d7":"code","b28b2c15":"code","8ff02760":"code","83cf8ba0":"code","2b9dc74d":"code","6088a156":"code","970c81d6":"code","2887f615":"code","8e2ff54c":"code","12a3be6f":"code","41c5924c":"code","5fc529a4":"code","1f56f538":"code","cea94c4c":"code","caf144db":"code","a474e0aa":"code","a9b35f43":"code","ffc3553f":"code","efcdcf52":"code","579ef685":"code","e49bce89":"code","15555e81":"code","bfd47cb9":"code","7b322221":"code","0da7d1ef":"code","227365f6":"code","8f3e4d0f":"code","fedc5dfb":"code","3c62b988":"code","7c9078bd":"code","93a41e3a":"code","f012b42c":"code","558e2257":"code","a0846bbd":"code","f1c5ae43":"code","55011130":"markdown","da55a458":"markdown","dec154d8":"markdown","c33dc65d":"markdown","d7f3756d":"markdown","b467480b":"markdown","26afb4ae":"markdown","ba2404c9":"markdown","2e190278":"markdown","cbafb852":"markdown","098f7d7e":"markdown","8dad8255":"markdown","2465d98f":"markdown","4e71d11c":"markdown"},"source":{"94c6d22a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","5669b620":"df = pd.read_csv('..\/input\/palantir-stock-data-latest-and-updated\/Palantir_stock_history.csv',index_col=\"Date\",parse_dates=True)","3fa58d37":"\ndf","42274c56":"df.describe()","f5844ac0":"df.info()","bc2a048a":"df.isna().sum()","f01a3c21":"import seaborn as sns\nsns.displot(df[\"Close\"]);","98d78186":"df.Close.plot(figsize=(20,5), title = \"Close Price\")\nplt.show()","f75aaec5":"import scipy.stats\n\nscipy.stats.probplot(df.Close,plot=plt)\nplt.title(\"QQ Plot Close Price\",size=14);","b3331d96":"df","2c94ea71":"df.drop([\"Open\",\"High\",\"Low\",\"Volume\",\"Dividends\",\"Stock Splits\"],axis=1,inplace=True)","fa5a08fd":"size=int(len(df)*0.75)\ndf_train=df.iloc[:size]\ndf_test=df.iloc[size:]","a87ad1fb":"df_train.tail()","a4d7427a":"df_test.head()","4e7d38d1":"import statsmodels.graphics.tsaplots as sgt\nimport statsmodels.tsa.stattools as sts\n","80ccb203":"p=sts.adfuller(df[\"Close\"])[1]\nif p<0.05:\n    print(\"Reject Null Hipothesis. Serie is Stationary : P value---> \",p)\nelse:\n    print(\"Not Reject Null Hipothesis. Serie is not Stationary : P value---> \",p)","e5ee5652":"from statsmodels.graphics.tsaplots import plot_acf\n\nsgt.plot_acf(df[\"Close\"], lags = 40)\nplt.title(\"ACF for Close Price\",size=24)\nplt.show()","3f06897a":"sgt.plot_pacf(df[\"Close\"], lags = 40)\nplt.title(\"PACF for Close Price\",size=24)\nplt.show()","2dd8bc3c":"df['returns'] = df.Close.pct_change(1)*100","e58aae52":"df.returns.plot(figsize=(20,5), title = \"Returns\")\nplt.show()","fbbe384c":"p=sts.adfuller(df[\"returns\"][1:])[1]\nif p<0.05:\n    print(\"Reject Null Hipothesis. Serie is Stationary : P value---> \",p)\nelse:\n    print(\"Not Reject Null Hipothesis. Serie is not Stationary : P value---> \",p)","2bde4425":"df[\"volatility\"]=df[\"returns\"]**2","8c35d4cb":"df[\"volatility\"].plot(figsize=(20,5))\nplt.title(\"Volatility\",size=24)\nplt.show()","e4e47494":"!pip install pmdarima\nfrom pmdarima.arima import auto_arima\n","26f70862":"model_auto2 = auto_arima(df_train.Close,m = 5,\n                       max_order = None, max_p = 7, max_q = 7, max_d = 2, max_P = 4, max_Q = 4, max_D = 2,\n                       maxiter = 50, alpha = 0.05, n_jobs = -1, trend = 'ct', information_criterion = 'aic')\n\n\n# exogenous -> outside factors (e.g other time series)\n# m -> seasonal cycle length\n# max_order -> maximum amount of variables to be used in the regression (p + q)\n# max_p -> maximum AR components\n# max_q -> maximum MA components\n# max_d -> maximum Integrations\n# maxiter -> maximum iterations we're giving the model to converge the coefficients (becomes harder as the order increases)\n# alpha -> level of significance, default is 5%, which we should be using most of the time\n# n_jobs -> how many models to fit at a time (-1 indicates \"as many as possible\")\n# trend -> \"ct\" usually\n# information_criterion -> 'aic', 'aicc', 'bic', 'hqic', 'oob' \n#        (Akaike Information Criterion, Corrected Akaike Information Criterion,\n#        Bayesian Information Criterion, Hannan-Quinn Information Criterion, or\n#        \"out of bag\"--for validation scoring--respectively)\n# out_of_smaple_size -> validates the model selection (pass the entire dataset, and set 20% to be the out_of_sample_size)","8375fca4":"model_auto2.summary()","5f8b5fd7":"df_test","e842512b":"start_date= \"2021-08-02\"\nend_date= \"2021-11-09\"\ndf_auto_pred = pd.DataFrame(model_auto2.predict(n_periods = len(df_test[start_date:end_date])))\ndf_auto_pred.index=df_test[start_date:end_date].index","da09f9d7":"df_auto_pred","b28b2c15":"predictions=pd.concat([df_test,df_auto_pred],axis=1)\npredictions.columns=[\"Price\",\"Prediction\"]","8ff02760":"\npredictions.plot(figsize=(16,8))\nplt.title(\"SARIMA (1,0,1)(1,0,1,5) Predictions\");","83cf8ba0":"from sklearn.metrics import mean_squared_error,mean_absolute_error","2b9dc74d":"print(\"MSE\",mean_squared_error(predictions[\"Price\"],predictions[\"Prediction\"]))\nprint(\"RMSE\",np.sqrt(mean_squared_error(predictions[\"Price\"],predictions[\"Prediction\"])))\nprint(\"MAE\",mean_absolute_error(predictions[\"Price\"],predictions[\"Prediction\"]))\n","6088a156":"df_train[\"returns\"]=df.iloc[:210][\"returns\"]\n\n\nmodel_auto2 = auto_arima(df_train.returns[1:],m = 5,\n                       max_order = None, max_p = 7, max_q = 7, max_d = 2, max_P = 4, max_Q = 4, max_D = 2,\n                       maxiter = 50, alpha = 0.05, n_jobs = -1, trend = 'ct', information_criterion = 'aic')","970c81d6":"model_auto2.summary()","2887f615":"df_test[\"returns\"]=df.iloc[210:][\"returns\"]\n\nstart_date= \"2021-08-02\"\nend_date= \"2021-11-09\"\ndf_auto_pred = pd.DataFrame(model_auto2.predict(n_periods = len(df_test.returns[start_date:end_date])))\ndf_auto_pred.index=df_test[start_date:end_date].index","8e2ff54c":"df_auto_pred","12a3be6f":"predictions=pd.concat([df_test,df_auto_pred],axis=1)\npredictions.columns=[\"Close\",\"Returns\",\"Returns Predictions\"]","41c5924c":"predictions[[\"Returns\",\"Returns Predictions\"]].plot(figsize=(16,8))","5fc529a4":"df = pd.read_csv('..\/input\/palantir-stock-data-latest-and-updated\/Palantir_stock_history.csv',index_col=\"Date\",parse_dates=True)\ndf.drop([\"Open\",\"High\",\"Low\",\"Volume\",\"Dividends\",\"Stock Splits\"],axis=1,inplace=True)\nsize=int(len(df)*0.75)\ndf_train=df.iloc[:size]\ndf_test=df.iloc[size:]\n","1f56f538":"from tensorflow import keras","cea94c4c":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(df_train)\n\nscaled_train = scaler.transform(df_train)\nscaled_test = scaler.transform(df_test)","caf144db":"len(scaled_train),len(scaled_test)","a474e0aa":"from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nn_input = 5\nn_features = 1\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)","a9b35f43":"X,y = generator[0]\nprint(f'Datos: \\n{X.flatten()}')\nprint(f'Predicci\u00f3n: \\n {y}')","ffc3553f":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","efcdcf52":"model = Sequential()\n\nmodel.add(LSTM(150,input_shape=(n_input, n_features),activation=\"relu\"))\n\nmodel.add(Dense(1))\n\nmodel.compile(loss='mse', optimizer='adam')","579ef685":"model.summary()","e49bce89":"model.fit_generator(generator,epochs=200)","15555e81":"loss_per_epoch = model.history.history['loss']\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch)","bfd47cb9":"first_eval_batch = scaled_train[-5:]","7b322221":"X.shape","0da7d1ef":"first_eval_batch.shape","227365f6":"first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))\nfirst_eval_batch.shape","8f3e4d0f":"first_eval_batch","fedc5dfb":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(len(df_test)):\n    \n    # obtener la predicci\u00f3n ([0] es para obtener solo el n\u00famero en lugar de [matriz])\n    current_pred = model.predict(current_batch)[0]\n    \n    # guardar la predicci\u00f3n\n    test_predictions.append(current_pred) \n    \n    # actualizar el lote para incluir ahora la predicci\u00f3n y soltar primer valor\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","3c62b988":"test_predictions","7c9078bd":"true_predictions = scaler.inverse_transform(test_predictions)\ntrue_predictions","93a41e3a":"df_test[\"predictions\"]=true_predictions","f012b42c":"df_test","558e2257":"df_test.plot(figsize=(12,8))","a0846bbd":"df_test","f1c5ae43":"print(\"MSE\",mean_squared_error(df_test[\"Close\"],df_test[\"predictions\"]))\nprint(\"RMSE\",np.sqrt(mean_squared_error(df_test[\"Close\"],df_test[\"predictions\"])))\nprint(\"MAE\",mean_absolute_error(df_test[\"Close\"],df_test[\"predictions\"]))","55011130":"##### We got a SAR(I)MA model (0,1,0) (1,0,1,5) as the best model","da55a458":"#### We see no clear stationality","dec154d8":"#### The distribution of the close price is indeed normal","c33dc65d":"##### Drop useless columns since we want to predict the Close price","d7f3756d":"##### Train and Test split","b467480b":"# LSTM","26afb4ae":"##### We see that the predictions are not very well","ba2404c9":"##### We have a high MSE for the data values we have","2e190278":"## I am super new to Time Series Analysis so i would be very grateful with every recommendation and correction of the many mistakes i probably did. Thx for watching","cbafb852":"##### If we want we could use an ARCH or GARCH model","098f7d7e":"##### Creating Returns","8dad8255":"#### The predictions are much better than before but it still a general bad forecast of the series","2465d98f":"##### With the Dickey - Fuller test we see that the serie is not stationary","4e71d11c":"##### For the returns the model also behaved in a bad way"}}