{"cell_type":{"2bc64d34":"code","e7180702":"code","25bc4a77":"code","7b6dde75":"code","78cc103d":"code","505948f2":"code","fd08dfd9":"code","d23a1c5f":"code","b6161629":"code","40c91229":"code","1aa8c9a3":"code","6698f08b":"code","668ad4e0":"code","d3b847dc":"code","a48c3908":"code","379a1a32":"code","32730a83":"code","8683eef0":"code","11b0cccb":"code","0eab432b":"code","66649447":"code","c225fa84":"code","59399f00":"code","d25ee2f5":"code","5835fc86":"code","c54feea5":"code","19d204a4":"markdown","87da0410":"markdown","a2ce3e2d":"markdown","9f69ee5e":"markdown","3dcf1615":"markdown","a9cc2e17":"markdown","b2223383":"markdown","3ba04f2f":"markdown"},"source":{"2bc64d34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7180702":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns","25bc4a77":"#importing nlp related libraries \nimport nltk\nfrom collections import Counter\nfrom nltk import ngrams\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))","7b6dde75":"recipes = pd.read_csv('\/kaggle\/input\/recipes-from-reddit\/Recipes.csv', encoding='latin')\nrecipes_2 = pd.read_csv('\/kaggle\/input\/recipes-from-reddit\/Recipes_2.csv',encoding='latin')\nprint(recipes.shape)\nrecipes.head()","78cc103d":"print(recipes_2.shape)\nrecipes_2.head()\n","505948f2":"recipes.append(recipes_2, ignore_index=True)","fd08dfd9":"# let's print details about the dataset \nprint('Details about the dataset')\nprint(recipes.shape, ':Shape of the dataset')\nprint('more information about the dataset\\n'+str(recipes.info))\nprint('Description about the dataset\\n'+str(recipes.describe()))\nprint('\\nColumns in dateset {}'.format(recipes.columns))","d23a1c5f":"# using value counts to see what are the occurence of number of comments here \nnum_comments =  recipes['num_comments'].value_counts()","b6161629":"num_comments","40c91229":"plt.figure(figsize=(20, 8))\nrecipes['num_comments'].hist(bins=80)\nplt.xlabel('Number of comments')\nplt.ylabel('Frequency')\nplt.title('Number of comments per recipes')\nplt.show()\n","1aa8c9a3":"# let's see first five results for title \nrecipes['title'][:5]","6698f08b":"title = recipes['title'] ","668ad4e0":"# it will use for ploting character length using histogram \n# This will give us the freq of number of characters len are used in creating the column\ndef plot_number_of_characters(text, bin_=100, text_=''):\n    text_len = text.str.len()\n    fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n    ax.hist(text_len, color='#341610', bins=bin_)\n    ax.set_title(text_, size=22)\n    plt.show()\n    ","d3b847dc":"# Number of words in a text column \n# we can examine how the number of words are used for the particular columns\ndef number_of_words(text, bin_=100, text_=''):\n    text_len = text.str.split().map(lambda x : len(x))\n    fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n    ax.hist(text_len, color='#341610', bins=bin_)\n    ax.set_title(text_, size=22)\n    plt.show()","a48c3908":"def avg_number_of_words(text, bin_=100, text_=''):\n    text_len = text.str.split().map(lambda x : len(x))\n    fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n    ax.hist(text_len.map(lambda x  : np.mean(x)), color='#341610', bins=bin_)\n    ax.set_title(text_, size=22)\n    plt.show()","379a1a32":"def clean_text(text):\n    \n    # Replacing @handle with the word USER\n    text_handle = text.str.replace(r'@[\\S]+', 'user')\n    \n    # Replacing the Hast tag with the word hASH\n    text_hash = text_handle.str.replace(r'#(\\S+)','hash')\n    \n    # Removing the all the Retweets\n    text_r = text_hash.str.replace(r'\\brt\\b',' ')\n    \n    # Replacing the URL or Web Address\n    text_url = text_r.str.replace(r'((www\\.[\\S]+)|(http?:\/\/[\\S]+))','URL')\n    \n    # Replacing Two or more dots with one\n    text_dot = text_url.str.replace(r'\\.{2,}', ' ')\n    \n    # Removing all the special Characters\n    text_special = text_dot.str.replace(r'[^\\w\\d\\s]',' ')\n    \n    # Removing all the non ASCII characters\n    text_ascii = text_special.str.replace(r'[^\\x00-\\x7F]+',' ')\n    \n    # Removing the leading and trailing Whitespaces\n    text_space = text_ascii.str.replace(r'^\\s+|\\s+?$','')\n    \n    # Replacing multiple Spaces with Single Space\n    Dataframe = text_space.str.replace(r'\\s+',' ')\n    \n\n    return Dataframe","32730a83":"# cleaning title \n# we have created cleaning tweet functions since these actually were created on redits it will have tweet like text too \n# so we applying it on the text to clean it.\ntitle = clean_text(title)\ntitle= title.apply(str)\n","8683eef0":"def n_grams_ploting(text, n=1, grams='unigrams'):\n    # Top 20 unigrams for the positive sentiment in the text in whole dataset\n\n    df_data_pos = \" \".join(text)\n    token_text_pos = word_tokenize(df_data_pos)\n    unigrams_pos = ngrams(token_text_pos, n)\n    frequency_pos = Counter(unigrams_pos)\n\n    df_pos = pd.DataFrame(frequency_pos.most_common(20))\n\n\n    # Barplot that shows the top 20 unigrams\n    plt.rcParams['figure.figsize'] = [13,9]\n    sns.set(font_scale = 1.5, style = 'whitegrid')\n\n    sns_pos_1 = sns.barplot(x = df_pos[1], y = df_pos[0], color = 'lightsteelblue')\n\n    # Setting axes labels\n    sns_pos_1.set(xlabel = 'Occurrence', ylabel = grams, title = 'Ngrams plot');\n    plt.show()","11b0cccb":"plot_number_of_characters(title, text_='Number of character vs Freq')\nnumber_of_words(title, text_='Number of Words vs Freq')\navg_number_of_words(title, text_='Avg Number of words vs Freq')\n","0eab432b":"n_grams_ploting(title, n=1, grams='unigrams')\nn_grams_ploting(title, n=2, grams='bigrams')\nn_grams_ploting(title, n=3, grams='trigrams')","66649447":"comment = recipes['comment']\ncomment = clean_text(comment)\ncomment= comment.apply(str)","c225fa84":"plot_number_of_characters(comment, text_='Number of character vs Freq')\nnumber_of_words(comment, text_='Number of Words vs Freq')\navg_number_of_words(comment, text_='Avg Number of words vs Freq')\nn_grams_ploting(comment, n=1, grams='unigrams')\nn_grams_ploting(comment, n=2, grams='bigrams')\nn_grams_ploting(comment, n=3, grams='trigrams')","59399f00":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib as mpl\nstop_words = set(stopwords.words(\"english\"))\n","d25ee2f5":"def wordcloud_text(data, column='title'):\n                 \n                mpl.rcParams['figure.figsize']=(15.0,7.0)    #(6.0,4.0)\n                mpl.rcParams['font.size']=12                #10 \n                mpl.rcParams['savefig.dpi']=100             #72 \n                mpl.rcParams['figure.subplot.bottom']=.1 \n\n\n                stopwords = set(STOPWORDS)\n                \n\n                wordcloud = WordCloud(\n                                          background_color='white',\n                                          stopwords=stopwords,\n                                          max_words=2000,\n                                          max_font_size=40, \n                                          random_state=42\n                                         ).generate(str(data[column]))\n\n                print(wordcloud)\n                fig = plt.figure(1)\n                plt.imshow(wordcloud)\n                plt.axis('off')\n                plt.show()\n                fig.savefig(\"word1.png\", dpi=900)","5835fc86":"wordcloud_text(recipes, column='comment')","c54feea5":"wordcloud_text(recipes, column='title')","19d204a4":"# Exploring Column: title","87da0410":"# WordCloud \n- Word clouds (also known as text clouds or tag clouds) work in a simple way: the more a specific word appears in a source of textual data (such as a speech, blog post, or database), the bigger and bolder it appears in the word cloud.\n\n- A word cloud is a collection, or cluster, of words depicted in different sizes. The bigger and bolder the word appears, the more often it\u2019s mentioned within a given text and the more important it is.\n\n- Also known as tag clouds or text clouds, these are ideal ways to pull out the most pertinent parts of textual data, from blog posts to databases. They can also help business users compare and contrast two different pieces of text to find the wording similarities between the two.","a2ce3e2d":"## Exploring column: num_comments","9f69ee5e":"# Exploring Column: comment","3dcf1615":"# LET'S COOK\n### **This notebook is data exploration notebook**\n- Here I will try to explore data and find the insight \n- also will apply some nlp basic \n- stemming and lemmatization and POS as well as NER will be research \n- more .. things might will do while literally exploring the data \n\n> Please do upvote if you found it helpful \n- Appreciation is a booster for sucess !","a9cc2e17":"- Here I will use some already built functions by me but used in different notebooks \n- these functions will give us the insight of lenght of the sentence \n- will also give number of word and avg number of word \n- and top n-grams plot too (it is fun though! and I really love the out results) :D","b2223383":"- from the graph it is clear that it is right skewed \n- most of the data comes form 1-25 bin and it was clear by value_counts() \n- max comments is 178 and while most of them have 1 comments only ","3ba04f2f":"\n### so here we have created the helper funtions \n- I will explain the helper functions below \n- n_grams_ploting : it is a helper function to plot top-20 n-grams \n- clean_text() : for cleaning text, its tweet cleaner but we will use it here too \n- number_of_character: to plot number of characters on the plot to see how text differs \n- number of words : to plot number words histo gram \n- avg number of words : histogram to plot avg number of words"}}