{"cell_type":{"77c18e37":"code","14a84f1f":"code","cce2e620":"code","e04a67c2":"code","30db39e2":"code","03245d1f":"code","481a544c":"code","151a605e":"code","d32e8a9f":"code","0ee848fe":"code","47194771":"code","1faf0618":"code","5f4d56cf":"code","476b551e":"code","350132dc":"code","e50ac86f":"code","19c3dc7c":"code","6e88e9c0":"code","2b017af4":"code","97468a83":"code","a420f9b3":"code","c6158019":"code","10f0aa7c":"code","a6a7d1bb":"code","9c7f7b8c":"markdown","bae17580":"markdown","87af269b":"markdown","4604f6a8":"markdown","e89ef220":"markdown","020c7f43":"markdown","1549802b":"markdown","622f7da3":"markdown","d2b1f78b":"markdown","14e94701":"markdown","ffc7a09c":"markdown","21239f2f":"markdown","eb4317ce":"markdown"},"source":{"77c18e37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14a84f1f":"import pandas as pd\nmovie=pd.read_csv(\"..\/input\/imdb-extensive-dataset\/IMDb movies.csv\")\nmovie.head()","cce2e620":"movie.shape","e04a67c2":"# Satir Sayisi\nprint(\"Sat\u0131r Say\u0131s\u0131:\\n\",movie.shape[0:])\n\n# Sutun Adlari\nprint(\"S\u00fctun Adlari:\\n\",movie.columns.tolist())\n\n# Veri Tipleri\nprint(\"Veri Tipleri:\\n\",movie.dtypes)","30db39e2":"# Eksik veri say\u0131lar\u0131 ve veri setindeki oranlar\u0131 \nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.concat([movie.isnull().sum(), 100 * movie.isnull().sum()\/len(movie)], \n              axis=1).rename(columns={0:'Missing Records', 1:'Percentage (%)'})","03245d1f":"#Dram t\u00fcr\u00fc i\u00e7in korelasyon grafi\u011fi\ndrama=movie.copy()\ndrama_values = (drama['genre'] == 'Drama').astype(int)\nfields = list(drama.columns[:-4])\ncorrelations = drama[fields].corrwith(drama_values)\ncorrelations.sort_values(inplace=True)\ncorrelations\nax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='Drama Correlation');","481a544c":"#Su\u00e7 t\u00fcr\u00fc i\u00e7in korelasyon grafi\u011fi\ncrime=movie.copy()\ncrime_values = (drama['genre'] == 'Crime').astype(int)\nfields = list(drama.columns[:-4])  \ncorrelations = drama[fields].corrwith(crime_values)\ncorrelations.sort_values(inplace=True)\ncorrelations\nax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='Crime Correlation');","151a605e":"# Veri seti i\u00e7erisinden belli alanlar se\u00e7ilerek yeni bir veriseti olu\u015fturuldu.\n\ndf1=pd.Series(movie['duration'],name=\"duration\")\ndf2=pd.Series(movie['votes'],name=\"votes\")\ndf_movie=pd.concat([df1,df2], axis=1)\ndf_movie.describe().T","d32e8a9f":"plt.figure()\ndf_movie.boxplot(column=['duration','votes'])\n\nfig,axs=plt.subplots(2,2) \naxs[0, 0].boxplot(df_movie['duration'])\naxs[0, 0].set_title('duration')\n\naxs[0, 1].boxplot(df_movie['votes'])\naxs[0, 1].set_title('votes')\n\n\n\n","0ee848fe":"# Histogram grafi\u011fi\nfrom matplotlib import pyplot\ndf_movie.hist()\npyplot.show()","47194771":"# Scatter Plot Matrix\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(df_movie)\npyplot.show()","1faf0618":"#Amerikada izlenen filmler i\u00e7in korelasyon grafi\u011fi\nus=movie.copy()\ny = (us['country'] == 'USA').astype(int)\nfields = list(us.columns[:-1])  # everything except \"country name\"\ncorrelations = us[fields].corrwith(y)\ncorrelations.sort_values(inplace=True)\ncorrelations\n","5f4d56cf":"ax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='USA Correlation');","476b551e":"plt.figure()\nmovie.boxplot(column=['year','duration','avg_vote','metascore','votes','reviews_from_users'])\n\nfig,axs=plt.subplots(2,3) \naxs[0, 0].boxplot(movie['year'])\naxs[0, 0].set_title('Film Y\u0131l\u0131')\n\naxs[0, 1].boxplot(movie['duration'])\naxs[0, 1].set_title('Film S\u00fcresi')\n\naxs[0, 2].boxplot(movie['avg_vote'])\naxs[0, 2].set_title('Film Hakk\u0131nda Yap\u0131lan Ortalama Oy Say\u0131s\u0131')\n\naxs[1, 0].boxplot(movie['metascore'])\naxs[1, 0].set_title('Metascore')\n\naxs[1, 1].boxplot(movie['votes'])\naxs[1, 1].set_title('Film Hakk\u0131nda Yap\u0131lan Oylama Say\u0131s\u0131')\n\naxs[1, 2].boxplot(movie['reviews_from_users'])\naxs[1, 2].set_title('Film Hakk\u0131nda Kullan\u0131c\u0131 Yorumlar\u0131')\n","350132dc":"# Film s\u00fcresine g\u00f6re oylaman\u0131n nas\u0131l oldu\u011fu hakk\u0131nda bilgi almak i\u00e7in veri e\u011fitildi.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX = df_movie\ny = df_movie['votes']\n\nmms = MinMaxScaler()\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, random_state=0)\nX_train = mms.fit_transform(X_train) \nX_test= mms.fit_transform(X_test)\n\nprint(\"Dataframe boyutu: \",df_movie.shape)\nprint(\"E\u011fitim verisi boyutu: \",X_train.shape, y_train.shape)\nprint(\"Test verisi boyutu: \",X_test.shape,y_test.shape)","e50ac86f":"# type error i\u00e7in target types\u0131 \"Label Encoder\" ile  multiclassa \u00e7evirdim.(Target=Y_train)\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(y_train.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))\n\nlab_enc = preprocessing.LabelEncoder()\nY_train = lab_enc.fit_transform(y_train)","19c3dc7c":"import numpy as np\nfrom sklearn    import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model","6e88e9c0":"# Her bir modelin do\u011fruluk de\u011feri ,s\u0131n\u0131fland\u0131rma raporu , kar\u0131\u015f\u0131kl\u0131k matrisi ve MSE(Ortalama Kare Hata Regresyon Oran\u0131) de\u011ferlerini hesaplamak i\u00e7in import edildi.\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error","2b017af4":"# Lineer Regresyon\nprint(\"\\nLineer Regresyon\")\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X_train, Y_train)\ny_true1 , y_pred1 =y_test,lm.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred1)\nplt.scatter(y_true1, y_pred1,c='blue')\nplt.scatter(y_true1, y_test,c='pink')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","97468a83":"#Lineer Regresyon\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v = lab_enc.fit_transform(y_true1)\nutils.multiclass.type_of_target(y_true1.astype('int'))\nypred1= lab_enc.fit_transform(y_pred1)\nutils.multiclass.type_of_target(ypred1.astype('int'))\nconf=confusion_matrix(encoded_v, ypred1)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v, ypred1))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v, ypred1))\nprint(\"MSE:\",mean_squared_error(encoded_v, ypred1))","a420f9b3":"# Decision Tree Classifier\nprint(\"Decision Tree Classifier\")\nclf = DecisionTreeClassifier()\nclf.fit(X_train, Y_train)\ny_true5 , y_pred5=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred5)\nplt.scatter(y_true5, y_pred5,c='orange')\nplt.scatter(y_true5, y_test,c='purple')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","c6158019":"#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v4 = lab_enc.fit_transform(y_true5)\nutils.multiclass.type_of_target(y_true5.astype('int'))\nypred5= lab_enc.fit_transform(y_pred5)\nutils.multiclass.type_of_target(ypred5.astype('int'))\nconf=confusion_matrix(encoded_v4, ypred5)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v4, ypred5))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v4, ypred5))\nprint(\"MSE:\",mean_squared_error(encoded_v4, ypred5))","10f0aa7c":"# GaussianNB\nprint(\"GaussianNB\")\nclf = GaussianNB()\nclf.fit(X_train, Y_train)\ny_true3 , y_pred3=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred3)\nplt.scatter(y_true3, y_pred3,c='pink')\nplt.scatter(y_true3, y_test,c='orange')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","a6a7d1bb":"# GaussianNB\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v2 = lab_enc.fit_transform(y_true3)\nutils.multiclass.type_of_target(y_true3.astype('int'))\nypred3= lab_enc.fit_transform(y_pred3)\nutils.multiclass.type_of_target(ypred3.astype('int'))\nconf=confusion_matrix(encoded_v2, ypred3)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v2, ypred3))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v2, ypred3))\nprint(\"MSE:\",mean_squared_error(encoded_v2, ypred3))","9c7f7b8c":"-> Veri setindeki sat\u0131r say\u0131s\u0131,veri tipi ve de\u011fi\u015fken isimleri \u00f6\u011frenilerek dataset hakk\u0131nda genel bilgiye sahip olundu.","bae17580":"-> Dataset \u00fczerinde analiz , modelleme yapabilmek i\u00e7in eksik veri say\u0131s\u0131 kontrol\u00fc yap\u0131ld\u0131.","87af269b":"-> Ayk\u0131r\u0131 de\u011fer g\u00f6zlemi yapabilmek ad\u0131na s\u00fcrekli de\u011fi\u015fkenler i\u00e7in boxplotlar olu\u015fturuldu. Ayk\u0131r\u0131 de\u011fer analizi ile de\u011fi\u015fkenler i\u00e7erisindeki de\u011ferlerin ortalama ile mi seyretti\u011fi yoksa b\u00fcy\u00fck farkl\u0131l\u0131klar\u0131n m\u0131 oldu\u011fu sonucuna var\u0131r\u0131z. Buradan de\u011ferler aras\u0131nda b\u00fcy\u00fck farkl\u0131l\u0131klar oldu\u011funu g\u00f6zlemliyoruz.","4604f6a8":"-> Su\u00e7 t\u00fcr\u00fc i\u00e7in \"Puanlama, Film S\u00fcresi, Film Y\u0131l\u0131 ve Ortalama Puan\" aras\u0131ndaki ili\u015fkiyi g\u00f6zlemleyebilmek ad\u0131na korelasyon grafi\u011fi olu\u015fturuldu.","e89ef220":"-> Olu\u015fturulan dataframe i\u00e7in 'votes ,duration' de\u011fi\u015fkenleri \u00fczerinden 'votes'(Film Puanlanmas\u0131) \u00fczerine tahminleme yap\u0131ld\u0131.\n\n-> Veri modellemeden \u00f6nce normalize edildi.Bunu yaparken MinMaxScaler kullan\u0131ld\u0131.\n\nBu y\u00f6ntemde, bir grup verinin i\u00e7erisindeki en b\u00fcy\u00fck ve en k\u00fc\u00e7\u00fck de\u011ferler ele al\u0131n\u0131r. Di\u011fer b\u00fct\u00fcn veriler, bu de\u011ferlere g\u00f6re normalle\u015ftirilir.\n\n-> Yap\u0131lan tahminleme sonucunda 3 algoritma kullan\u0131ld\u0131. Bunlar;\n* Lineer Regresyon\n* Decision Tree Classifier\n* Naive Bayes -Gaussian Y\u00f6ntemi\n\n-> Bunlardan do\u011fruluk de\u011feri y\u00fcksek olup MSE de\u011feri d\u00fc\u015f\u00fck olarak en iyi tahmini yap\u0131p en yak\u0131n sonucu veren algoritma Lineer Regresyon oldu.\n   \u0130kinci en yak\u0131n tahmini yapan ise, Decision Tree Classifier (Karar A\u011fa\u00e7lar\u0131 S\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131) oldu.\n   \n-> Veriler modellemeye haz\u0131r hale getirildikten sonra algoritmalar uyguland\u0131 ve tahmin sonu\u00e7lar\u0131 da birden farkl\u0131 ba\u015far\u0131 de\u011feri ile k\u0131yasland\u0131.\n    Ba\u015far\u0131 k\u0131yaslamalar\u0131 ise;\n* Kar\u0131\u015f\u0131kl\u0131k Matrisi (Confusion Matrix)   \n* S\u0131n\u0131fland\u0131rma Raporlamalar\u0131 (Classification Report)\n* Ortalama Kare Hatas\u0131 (MSE)  ile yap\u0131ld\u0131.\n\n->Modelleme yaparken denenen de\u011ferler aras\u0131nda test boyutu i\u00e7in 0.3, random state i\u00e7in 0 ile en iyi sonuca ula\u015f\u0131ld\u0131. Test boyutu ve random state b\u00fcy\u00fcd\u00fck\u00e7e do\u011fruluk de\u011feri d\u00fc\u015f\u00fcp hata oran\u0131 b\u00fcy\u00fcd\u00fc. Bunun yan\u0131nda, dataframe boyutu, e\u011fitim verisi boyutu ve test verisi boyutu g\u00f6sterildi.","020c7f43":"Bu veri seti yer alan film bilgileri hakk\u0131nda tahminleme yapmaktad\u0131r.","1549802b":"-> Olu\u015fturulan dataframe'in y\u0131la ve ald\u0131\u011f\u0131 puanlamaya g\u00f6re da\u011f\u0131l\u0131m grafi\u011fi matrisi elde edilmi\u015ftir.","622f7da3":"-> Olu\u015fturulan dataframe'in histogram grafi\u011fi incelenmi\u015ftir.","d2b1f78b":"-> Se\u00e7ilen veri seti import edildi ve i\u00e7indeki veriler okutuldu.","14e94701":"-> Amerikada izlenen filmler i\u00e7in \"Film Y\u0131l\u0131, Film S\u00fcresi, Ortalama Puan\u0131, Metascoru, Puan\u0131, Kullan\u0131c\u0131 Yorumlar\u0131\" bilgileri aras\u0131ndaki ili\u015fkiyi g\u00f6zlemleyebilmek ad\u0131na korelasyon grafi\u011fi olu\u015fturuldu.","ffc7a09c":"-> Dram t\u00fcr\u00fc i\u00e7in \"Puanlama, Film S\u00fcresi, Film Y\u0131l\u0131 ve Ortalama Puan\" bilgileri aras\u0131ndaki ili\u015fkiyi g\u00f6zlemleyebilmek ad\u0131na korelasyon grafi\u011fi olu\u015fturuldu.","21239f2f":"-> Ayk\u0131r\u0131 de\u011fer g\u00f6zlemi yapabilmek ad\u0131na s\u00fcrekli de\u011fi\u015fkenler i\u00e7in boxplotlar olu\u015fturuldu. Ayk\u0131r\u0131 de\u011fer analizi ile de\u011fi\u015fkenler i\u00e7erisindeki de\u011ferlerin ortalama ile mi seyretti\u011fi yoksa b\u00fcy\u00fck farkl\u0131l\u0131klar\u0131n m\u0131 oldu\u011fu sonucuna var\u0131r\u0131z. Burada Puan de\u011ferleri hari\u00e7 di\u011fer de\u011ferlerin ortalama seyretti\u011fini g\u00f6zlemliyoruz.","eb4317ce":"-> Veri setin i\u00e7erisinden belirli alanlar se\u00e7ilerek yeni bir veriseti olu\u015fturuldu. Sonra dataframedeki s\u00fcrekli de\u011fi\u015fkenler i\u00e7in describe metodu ile \"count,mean ,min ,max\" de\u011ferleri \u00f6\u011frenildi."}}