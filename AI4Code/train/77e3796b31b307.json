{"cell_type":{"7ce790d8":"code","4d5f6d34":"code","0fce99b1":"code","02a48978":"code","9d5db021":"code","7d3b69b0":"code","4b0d9421":"code","76652960":"code","a46f3e75":"code","38b22ab1":"code","09f1fe64":"code","92304b64":"code","cdbc37b9":"code","9c218e53":"code","ea369d00":"code","f08689ab":"code","5274bd71":"code","ef362818":"code","33b57123":"code","6746d1e3":"code","7ddb1a57":"code","97f970d8":"code","42be7f82":"code","1b09e824":"code","bdd424ea":"code","ee5ce1ee":"code","7d457581":"code","ede8b7ab":"code","240ce574":"code","3b8f2e47":"code","d1020e95":"code","bf916e96":"code","cf2c6bf0":"code","a6cd2f44":"code","f7d094e2":"code","ad40e967":"code","82300263":"code","4e638ba6":"code","702b3130":"code","a2c33450":"code","b99c5792":"code","044fc8e3":"code","09f529f0":"code","e0532c50":"code","a1f0fe1e":"code","10d49ef3":"markdown","07b5825e":"markdown","b49c0563":"markdown","0d67f74e":"markdown","8adac178":"markdown","84ea6e4b":"markdown","f1b4f924":"markdown","19ce2d5b":"markdown","ded07f49":"markdown","8fe3ebf1":"markdown","e2a08452":"markdown","7f713744":"markdown","935d1645":"markdown","154b49cc":"markdown","30f5f9aa":"markdown","1ce57846":"markdown","5a486d68":"markdown","7247d7b5":"markdown","a46849be":"markdown","5720d11a":"markdown","4db15a71":"markdown","f38d1146":"markdown","42a2b1aa":"markdown","9a94e7f5":"markdown","64939466":"markdown","e4ec7b91":"markdown","23aa4608":"markdown","96338d33":"markdown","ee25e815":"markdown","6b3868f3":"markdown","de912db3":"markdown","5cec26a6":"markdown","ddc2781a":"markdown"},"source":{"7ce790d8":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport re\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n\nfrom sklearn import set_config\nset_config(display='diagram')\n\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4d5f6d34":"# # Import the CSV file as a dataframe:\n\ndf = pd.read_csv('\/kaggle\/input\/san-francisco-airbnb-listings\/listings.csv')","0fce99b1":"# # Display basic dataframe info (number of columns\/rows & data types):\n\ndf.info()","02a48978":"# # Take a look at the first 5 rows:\n\npd.set_option('display.max_columns', None)\ndf.head()","9d5db021":"# # Create a new dataframe that omits all the unneeded columns:\n\nmldf = df[['city', 'neighbourhood_cleansed', 'property_type', 'room_type', 'price', 'amenities']]","7d3b69b0":"# # Show the number of null values in each column:\n\nmldf.isnull().sum()","4b0d9421":"# # Drop null values; check what datatype each column contains:\n\nmldf.dropna(inplace = True)\n\nmldf.info()","76652960":"# # Show summary stats for the dataframe:\n\nmldf.describe()","a46f3e75":"mldf['city'].value_counts()","38b22ab1":"# # Check whether the 'San Francisco' class with only 3 records contains an extra space in its name:\n\nmldf.loc[mldf['city'].str.contains('San Francisco ')]","09f1fe64":"# # Correct the 'San Francisco' name variants to read only 'San Francisco':\n\nmldf.loc[mldf['city'] == 'Noe Valley - San Francisco', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco, Hayes Valley', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == '\u65e7\u91d1\u5c71', 'city'] = 'San Francisco'\nmldf.loc[mldf['city'] == 'San Francisco ', 'city'] = 'San Francisco'","92304b64":"# # Confirm the corrections using value_counts method:\n\nmldf['city'].value_counts()","cdbc37b9":"# # Get the index names for non-SF records and compute the sum:\n\nindex_names = mldf[(mldf['city'] == 'Daly City') | (mldf['city'] == 'San Jose') | (mldf['city'] == 'Brisbane')].index \nlen(index_names)","9c218e53":"# # drop non-SF row indices from dataFrame and confirm their removal:\n\nmldf.drop(index_names, inplace = True)\n\nmldf['city'].value_counts()","ea369d00":"# # Convert the values in price column to floats:\n\nmldf['price'] = mldf['price'].replace('[\\$,]', '', regex=True).astype(float)","f08689ab":"# # Show summary stats for price column:\nmldf['price'].describe()","5274bd71":"mldf[mldf['price'] < 1]","ef362818":"# # Drop the row with index 3752 and confirm its removal:\n\nmldf.drop([3752], inplace = True)\nmldf[mldf['price'] <= 1]","33b57123":"# # We can now drop the city column from the dataframe:\n\nmldf = mldf[['neighbourhood_cleansed', 'property_type', 'room_type', 'amenities', 'price']]","6746d1e3":"mldf['room_type'].value_counts(normalize=True)","7ddb1a57":"# # Drop 'shared room' and 'hotel room' listings from the data frame:\n\nmldf = mldf[(mldf['room_type'] == 'Entire home\/apt') | (mldf['room_type'] == 'Private room')]\nmldf['room_type'].value_counts(normalize=True)","97f970d8":"mldf['amenities'] = mldf['amenities'].str.replace(' *', flags=re.I, repl='')","42be7f82":"# # Compute the proportion of listings that belong to each property type category:\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint(mldf['property_type'].describe())","1b09e824":"# # Add a column that shows the proportion of listings represented by each property type:\n\nmldf[\"property_type_freq\"] = 1\nmldf[\"property_type_freq\"] = mldf.groupby('property_type').transform('count').div(len(mldf))\nmldf.head()","bdd424ea":"# # Drop property types with normalized frequencies less than 5% and confirm the change:\n\nmldf = mldf[(mldf['property_type_freq'] >= 0.05)]\n\nprint(mldf['property_type'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['property_type'].describe())","ee5ce1ee":"# drop property_type_freq from dataframe and confirm its removal:\n\nmldf.drop('property_type_freq', axis=1, inplace=True)\nmldf.dtypes","7d457581":"# # Compute the normalized frequency of each neighborhood in the dataframe:\n\nprint(mldf['neighbourhood_cleansed'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['neighbourhood_cleansed'].describe())","ede8b7ab":"mldf[\"neigh_freq\"] = 1\nmldf[\"neigh_freq\"] = mldf.groupby('neighbourhood_cleansed').transform('count').div(len(mldf))\nmldf.head()","240ce574":"mldf = mldf[(mldf['neigh_freq'] >= 0.02)]\nprint(mldf['neighbourhood_cleansed'].value_counts(normalize=True))\nprint('\\n')\nprint(mldf['neighbourhood_cleansed'].describe())","3b8f2e47":"# drop neigh_freq from dataframe and confirm its removal:\n\nmldf.drop('neigh_freq', axis=1, inplace=True)\nmldf.dtypes","d1020e95":"fig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","bf916e96":"price_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(s=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(s=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","cf2c6bf0":"print('Top: price range of the bottom 98% of listings.')\nprint('Bottom: price range of the top 2% of listings.')\nprint('\\n')\n      \n# print(pd.qcut(cleandf['price'], q=[0, .98, 1]).value_counts(normalize=False))\n\nprint('Private room:')\nprint('\\n')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Private room\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))\nprint('\\n')\nprint('Entire home:')\nprint('\\n')\nprint(pd.qcut(mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], q=[0, .98, 1]).value_counts(normalize=False))","a6cd2f44":"mldf = mldf[((mldf['price'] <= 350) & (mldf[\"room_type\"] == \"Private room\")) | ((mldf['price'] <= 1000) & (mldf[\"room_type\"] == \"Entire home\/apt\"))]\nmldf.head()","f7d094e2":"fig = plt.figure(figsize=(11,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(2,1,1)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Entire home prices')\nplt.xticks(rotation=45, size=8, ha='right')\nplt.xlabel(\"\")\n\nplt.subplot(2,1,2)\nsns.stripplot(y=mldf[mldf[\"room_type\"] == \"Private room\"]['price'], \n              x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              alpha=.5)\nplt.title(label='Private room prices')\nplt.xticks(rotation=45, size=8, ha='right')\n\nplt.show()","ad40e967":"price_skew = mldf['price'].skew(axis = 0, skipna = True)\nlogprice_skew = (np.log(mldf.price)).skew(axis = 0, skipna = True)\n\nfig, ax =plt.subplots(1, 2, figsize=(16,4))\nchart1 = sns.distplot(mldf.price, ax=ax[0], color='b')\nchart1.set_xlabel('Price',fontsize=12)\nchart1.annotate(s=f'skew: {price_skew:.2f}', xy=(300, 200), xycoords='axes points')\nchart2 = sns.distplot(np.log(mldf.price), ax=ax[1], color='g')\nchart2.set_xlabel('log Price',fontsize=12)\nchart2.annotate(s=f'log price skew: {logprice_skew:.2f}', xy=(300, 200), xycoords='axes points')\n\nfig.show()","82300263":"y1 = mldf[mldf[\"room_type\"] == \"Entire home\/apt\"].groupby(['neighbourhood_cleansed']).median(['price'])\ny2 = mldf[mldf[\"room_type\"] == \"Private room\"].groupby(['neighbourhood_cleansed']).median(['price'])\n\n# get the counts as a dataframe\ny_df=pd.concat([y1,y2],axis=1)\ny_df.columns=['Entire Hm','Pvt Rm']\n\n\ny_df.index.name = 'index'\n\n# # melt the data frame so it has a \"tidy\" data format\ny_df=y_df.reset_index().melt(id_vars=['index'], var_name=\"room_type\",value_name=\"Median Price (US$)\")\ny_df.head()","4e638ba6":"y_df_rm = y_df[y_df['room_type'] == 'Pvt Rm']\n\nf, ax = plt.subplots(figsize=(12, 3))\nplt.xticks(rotation=50, size=10, ha='right')\n\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df, label=\"Total\", alpha = 0.5, color=\"darkorange\")\nplt.bar(height=\"Median Price (US$)\", x=\"index\", data=y_df_rm, label=\"Total\", alpha = 0.5, color=\"deepskyblue\")\n\nsns.despine(left=True, bottom=True)\nplt.legend(['Entire Home\/Apt', 'Private Room'], loc=1)\nplt.title(label='Median Listing Price x Neighborhood')\nplt.xlabel(\"Neighborhood\")\nplt.ylabel(\"Median Price in US$\")\nplt.show()","702b3130":"fig = plt.figure(figsize=(10,8))\nfig.subplots_adjust(hspace=1, wspace=0.75)\n\nplt.subplot(1,2,1)\nmldf[mldf[\"room_type\"] == \"Entire home\/apt\"].groupby([\"neighbourhood_cleansed\"])['price'].median().sort_values(ascending=True).plot.barh(color=\"skyblue\")\nplt.xticks(rotation=50, size=10, ha='right')\nplt.xlabel(\"Median Price in US$\")\nplt.title(label='Entire home\/apt Median Prices')\n\nplt.subplot(1,2,2)\nmldf[mldf[\"room_type\"] == \"Private room\"].groupby([\"neighbourhood_cleansed\"])['price'].median().sort_values(ascending=True).plot.barh()\nplt.xticks(rotation=50, size=10, ha='right')\nplt.xlabel(\"Median Price in US$\")\nplt.ylabel(\"\")\nplt.title(label='Private room Median Prices')\n\nplt.show()","a2c33450":"fig = plt.figure(figsize=(10,5))\nax = sns.countplot(x=mldf[mldf[\"room_type\"] == \"Entire home\/apt\"]['neighbourhood_cleansed'],\n             order = mldf['neighbourhood_cleansed'].value_counts().index, \n                   alpha=0.4, \n                   color='blue')\nplt.xticks(rotation=50, size=10, ha='right')\n\nsns.countplot(x=mldf[mldf[\"room_type\"] == \"Private room\"]['neighbourhood_cleansed'],\n              ax=ax, \n              alpha=0.3, \n              color='green')\n\nplt.legend(['Entire Home\/Apt', 'Private Room'], loc=1)\nplt.title(label='Number of listings per neighborhood')\nplt.show()","b99c5792":"# # Log transform the price data to reduce skew:\n\nmldf['price'] = np.log(mldf['price'])\ndisplay(mldf)","044fc8e3":"X = mldf.drop('price', axis=1)\ny = mldf['price']","09f529f0":"categorical_features = ['neighbourhood_cleansed', 'property_type', 'room_type']\ntext_features = ['amenities']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text', TfidfVectorizer(), 'amenities'), \n        ('category', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n\nrfr = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor', RandomForestRegressor())])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=0)\n\nrfr.fit(X_train, y_train)","e0532c50":"y_pred = rfr.predict(X_test)\n\nprint('First 10 predictions vs first 10 observations:')\n\nPrediction_Vs_Observation = {'pred': y_pred[0:10],\n                            'obs': y_test[0:10]}\n\nPvOdf = pd.DataFrame(Prediction_Vs_Observation).reset_index(drop=True)\ndisplay(PvOdf)","a1f0fe1e":"# # Compute the accuracy scores the model achieved for the training and test data sets:\n\nprint(f'The accuracy score of our Random Forest model on the training data: {rfr.score(X_train, y_train)}.')\nprint('\\n')\nprint(f'The accuracy score of our Random Forest model on the test data: {rfr.score(X_test, y_test)}.')","10d49ef3":"### Did you find this notebook instructive or helpful? Please upvote below.","07b5825e":"As we would expect, the median listing price for a private room is lower than for an entire home, regardless of neighbhorhood.\n\n\nNeighborhoods with high median listing prices include: Pacific Heights, Marina, Portrero Hill, Castro, South of Market, Western Addition, and Russian Hill.","b49c0563":"The change leaves us with 4 property types.","0d67f74e":"## Data Visualization\n\nGenerate a strip plot representation of the prices for each room type:","8adac178":"### Remarks\n#### The prediction accuracy for the test data is considerably lower than for the training data. This suggests the model overfit the training data.\n\n#### However, it's important to keep in mind that this model is attempting to make numerical price predictions based on numerous combinations of categorical variables:\n* 20 neighborhoods\n* 4 property types\n* 2 room types\n* many different amenities\n\n#### This makes for a very challenging prediction task. \n#### One possible strategy for improving the accuracy and usefulness of the model would be to make the target, price, a categorical variable. \n#### This could be accomplished by binning the price data into bands\/ranges. There would be a loss of resolution but a gain of accuracy.","84ea6e4b":"### Compare the first 10 predictions from the model to the first 10 observations in the test data:","f1b4f924":"* #### 10 of the 8111 records contain null values for ***city***. \n* #### City is a non-numerical value and cannot be imputed. \n* #### Therefore, we will drop the affected records.","19ce2d5b":"Let's graph the data a different way to show the rank of each neighborhood by median listing price:","ded07f49":"## Welcome! This notebook is divided into the following sections:\n\n1. Data importation, cleaning and preparation.\n2. Data visualization\/exploratory data analysis.\n3. Machine Learning\/Price Prediction using a Random forest model.\n\n### The goal is to create a model that can predict Airbnb listing prices in the San Francisco market.","8fe3ebf1":"#### There are 8 unique values for ***city***. Let's see what they are.","e2a08452":"#### With that done, let's check the proportion of listings that belong to each room type class:","7f713744":"The room_type variable specifies four classes:\n* 'Entire home\/apt' and 'Private room', which account for ~ 59% and ~ 36% of observations respectively. \n* 'Shared room' and 'Hotel room', which individually account for 3% or less.\n\nTo help simplify and optimize our model, we will discard the small number of records that correspond to the 'shared room' and 'hotel room' classes.","935d1645":"### Let's try to predict price:","154b49cc":"The data points are now more spread out along the price axis and cover it more evenly.\n\nRe-plot the distributions and re-calculate the skew values:","30f5f9aa":"## Data Cleaning and Preparation","1ce57846":"The amenities text must be *tokenized* before being fed into the ML model. This will occur later, at the pre-processing step.\n\nSpaces between words might be (incorrectly) interpreted as token separators by the vectorizer. We must remove these spaces so that words describing individual amenities are counted as single tokens:","5a486d68":"Eliminating extreme prices from the data set lowered the skew values considerably. \n\nThe log skew value is below 0.5, so we will apply a log transformation to the prices before running our ML algorithm.","7247d7b5":"In each plot, most of the data points are clustered toward the bottom; ***a few extreme values make the overall price range higher than it would otherwise be.***\n\nPlot the distribution of prices with and without log transformation to examine the skewness:","a46849be":"The change leaves us with 20 neighborhoods.","5720d11a":"The property_type variable specifies 26 unique values. Most of these occur with low frequency and are of little business interest or predictive value because they are so rare or peculiar e.g., 'Earth house' and 'Dome house.'\n\nMoreover, all these classes will have to be one-hot encoded for use in our predictive model. One-hot encoding is computationally demanding.\n\nTo simplify our model and improve its predictive utility, we will discard property types with freq < 5%.","4db15a71":"For both room types, the Marina district commands the highest median price.","f38d1146":"Next, graph number of listings per neighborhood, per room type:","42a2b1aa":"## ML\/Prediction - Random Forest","9a94e7f5":"There are 36 unique neighborhoods. This is a categorical variable, so all the values in this column will have to be one-hot encoded for the predictive model. This raises the same issue as was noted for the property type variable. \n\nTo help our model's performance and predictive utility, we will use freq = 2% as a cut-off.","64939466":"#### We want only listings located in San Francisco. \n\n#### Consolidate the SF name-variant classes into the 'San Francisco' class, and eliminate the non-SF entries:","e4ec7b91":"With the extreme high prices eliminated, let's graph the median prices by room type and neighborhood:","23aa4608":"Regenerate the strip plots:","96338d33":"#### The predictors must be preprocessed before they can be fed into the ML model:\n* The categorical features must be one-hot encoded.\n* The amenities text must be vectorized.\n\n#### To accomplish this, we will use two transformers:\n* #### One-hot encoder\n* #### Term-frequency times inverse document-frequency (Tfid) vectorizer\n\n#### **These will convert the categorical and text data to numerical representations that can be used by the algorithm.**","ee25e815":"We can see sharp disparities\/imbalances in terms of the number of listings per room type: \n* Inner Sunset has the highest number of entire home listings but comparatively few private room listings.\n* Mission has the third highest number of entire home listings but the highest number of private room listings.","6b3868f3":"**Left panel**: The prices are very positively skewed, with skewness = 12.02. Normally distributed data have skewness = 0.\n\n**Right panel**: Log transformation helps lower the skew value. But it's still considerably greater than 0.\n\nLet's see the price ranges for the bottom 98% and top 2% for each room class:","de912db3":"#### The dataframe contains 106 columns. For price prediction, we're going to utilize only these 4 features:\n* Property type\n* Room type\n* Amenities\n* Neighborhood","5cec26a6":"The min price value is zero. This make no sense. Let's check for prices < 1:","ddc2781a":"Extremely high price values are skewing the distribution. These rare\/extraordinary prices are of little predictive value. \n\nTrim away the top 2% to eliminate the high-price extremes:"}}