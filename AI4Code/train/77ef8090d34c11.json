{"cell_type":{"e0d47256":"code","6aa8a86c":"code","8c84a6e3":"code","8a0930b0":"code","6f8bfb68":"code","e41de4fb":"code","a19f81f2":"code","4a0f93f3":"code","9a1e6845":"code","3fdf052a":"code","6e2f8a81":"code","185badab":"code","378e5f0d":"code","8d51fde7":"markdown","c0f4ca06":"markdown"},"source":{"e0d47256":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","6aa8a86c":"x = np.arange(-6,6+0.01,0.01)\nf = np.exp(x)\/(1 + np.exp(x))\nplt.plot(x,f)\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.grid()\nplt.show()","8c84a6e3":"col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin',\n             'bmi', 'pedigree', 'age', 'label']\n# We read the table with column name change\ndiabetes = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\", header = 1, names = col_names)","8a0930b0":"# visualization of first row of the Data Frame\ndiabetes.head()","6f8bfb68":"# we choose in the dataset the explanatory variables (features)\n# we choose in the dataset the variable to be explained (target)\nfeature_cols = ['pregnant', 'insulin', 'bmi', 'age', 'glucose', 'bp', 'pedigree']\nX = diabetes [feature_cols] # explanatory variables\ny = diabetes.label # variable to explain","e41de4fb":"# 75% of the data is used for learning\n# 25% of the data is used for the test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","a19f81f2":"# import of the LogisticRegression class\nfrom sklearn.linear_model import LogisticRegression\n# creation of an instance of the LogisticRegression class\nlogistiquereg = LogisticRegression(solver = 'lbfgs', max_iter = 120)\n# estimation of model parameters\nlogistiquereg.fit(X_train,y_train)\n# Using the model to make a prediction\ny_pred=logistiquereg.predict(X_test)","4a0f93f3":"# evaluation of model performance using the confusion matrix\nfrom sklearn import metrics\nconfusionMatrix = metrics.confusion_matrix(y_test, y_pred)\nconfusionMatrix","9a1e6845":"nbPredictionExact = confusionMatrix [0, 0] + confusionMatrix [1, 1]\nprint('The number of exact prediction is ', nbPredictionExact)\nnbPredictionInexact = confusionMatrix [0, 1] + confusionMatrix [1, 0]\nprint('The number of inaccurate prediction is ', nbPredictionInexact)\nnbPredictionTotal = nbPredictionExact + nbPredictionInexact\nprint('Total number of prediction {0}, to be compared with the number of y_test items {1}'.\nformat(nbPredictionTotal, len(y_test)))","3fdf052a":"# visualization of the confusion matrix in the form of a heatmap\nimport seaborn as sns","6e2f8a81":"nomClasse = [0, 1]\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(nomClasse))\nplt.xticks(tick_marks, nomClasse)\nplt.yticks(tick_marks, nomClasse)\n# create heatmap\nsns.heatmap(pd.DataFrame(confusionMatrix), annot = True, cmap = \"YlGnBu\",fmt = 'g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matrice de confusion', y=1.1)\nplt.ylabel('Label r\u00e9el')\nplt.xlabel('Label pr\u00e9dit')\nplt.show()","185badab":"# model evaluation\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","378e5f0d":"# ROC curve (Receiver Operating Characteristic)\ny_pred_proba = logistiquereg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label = \"data 1, auc=\" + str(auc))\nplt.legend(loc = 4)\nplt.show()","8d51fde7":"The confusion matrix is here a 2\u00d72 table because we solve a binary classification problem (2 classes, one class 0 and one class 1).\n\nThe values on the main diagonal represent the exact predictions.\n\nThe values on the non-diagonal terms are inaccurate predictions.","c0f4ca06":"This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n\nSeveral constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U\/ml)\nBMI: Body mass index (weight in kg\/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1)"}}