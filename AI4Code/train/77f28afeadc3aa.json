{"cell_type":{"241367f8":"code","8e9eb777":"code","6296be1b":"code","c4237104":"code","c3696353":"code","043e8476":"code","ad46bbb9":"code","f3661d6d":"code","18bf6959":"code","17d83874":"code","95f465b9":"code","7d79b211":"code","df294a85":"code","140037bb":"code","59997899":"code","1bff6354":"code","a903c547":"code","b28393cc":"code","686281b5":"code","b35606e1":"code","5f0b1d94":"code","75c57569":"code","d05477c1":"code","9e76ff61":"code","2534b8b5":"code","c3e056ca":"markdown"},"source":{"241367f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e9eb777":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport re","6296be1b":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","c4237104":"train.info()","c3696353":"train.shape","043e8476":"train.describe().T\n","ad46bbb9":"train.head()","f3661d6d":"train[train[\"target\"] == 1][\"text\"].values[1]","18bf6959":"train[train[\"target\"] == 0][\"text\"].values[0]","17d83874":"df = pd.concat([train,test])","95f465b9":"# lower case\ntrain['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n# Punctional\ntrain['text'] = train['text'].str.replace('[^\\w\\s]','')\n\n# Removing URL\ndef remove_URL(text):    \n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ntrain['text']=train['text'].apply(lambda x : remove_URL(x))\n\n# Removing HTML Tags\ndef remove_html(text):    \n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ntrain['text']= train['text'].apply(lambda x : remove_html(x))\n\n# Removing Emojis\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\ntrain['text']= train['text'].apply(lambda x: remove_emoji(x))\n\n\n\n\n\n\n","7d79b211":"delete = pd.Series(' '.join(train['text']).split()).value_counts()[-1000:]\ntrain['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in delete))","df294a85":"train.head()","140037bb":"# StopWords\n\n\nimport nltk\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nsw = stopwords.words(\"english\")\ntrain[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n","59997899":"test.head()","1bff6354":"x = train[\"text\"]\ny = train[\"target\"]","a903c547":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=42)","b28393cc":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.fit_transform(y_test)","686281b5":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer()\ntrain_vectors = count_vectorizer.fit_transform(X_train)\ntest_vectors = count_vectorizer.transform(X_test)","b35606e1":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf_model = rf.fit(train_vectors,y_train)","5f0b1d94":"from sklearn import model_selection\naccuracy = model_selection.cross_val_score(rf_model, \n                                           train_vectors, \n                                           y_train, \n                                           cv = 10).mean()\n\nprint(\"Count Vectors Do\u011fruluk Oran\u0131:\", accuracy)","75c57569":"# Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb_model = nb.fit(train_vectors, y_train)","d05477c1":"accuracy = model_selection.cross_val_score(nb_model, \n                                           train_vectors, \n                                           y_train, \n                                           cv = 10).mean()\n\nprint(\"Count Vectors Do\u011fruluk Oran\u0131:\", accuracy)","9e76ff61":"test = count_vectorizer.transform(test[\"text\"])\n","2534b8b5":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = nb_model.predict(test)\nsample_submission.to_csv(\"submission.csv\", index=False)\n","c3e056ca":"# Cleaning the Data"}}