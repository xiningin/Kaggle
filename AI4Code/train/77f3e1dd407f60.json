{"cell_type":{"407dbd26":"code","2247a62b":"code","6c737347":"code","10626ef8":"code","4b268fee":"code","d194113b":"code","85e153ca":"code","b49576da":"code","79ab33a5":"code","3fa944d5":"code","94a7e75d":"code","d1ca9f2e":"code","f5afcb82":"code","740c9e99":"code","ffdb301a":"code","af3ae378":"code","7dfe19b2":"code","c9b4fffe":"code","84778652":"markdown","7f061b0d":"markdown","ee7a6e36":"markdown","afef7558":"markdown","37468595":"markdown","3751a174":"markdown","b2522f2b":"markdown","7d890630":"markdown","6d8d402b":"markdown","6a8d98a7":"markdown","3681ae16":"markdown"},"source":{"407dbd26":"pip install keras","2247a62b":"import pandas as pd\nimport numpy as np\nimport os.path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom PIL import Image\n\n%matplotlib inline\nfrom tensorflow import keras \nfrom tensorflow.keras.applications import ResNet50,ResNet101\nimport cv2\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing import image","6c737347":"from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","10626ef8":"train = pd.read_csv('\/kaggle\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train.csv')\ntrain.head()","4b268fee":"# As we are going to divide dataset\ndf = train.copy()","d194113b":"# Increasing the size of dataset without disturbing their corresponding ratios \n\nMisce = train[train[\"Class\"]=='Miscellaneous']\nChris_tree = train[train[\"Class\"]=='Christmas_Tree']\nJacket = train[train[\"Class\"]=='Jacket']\nCandle = train[train[\"Class\"]=='Candle']\nAirplane = train[train[\"Class\"]=='Airplane']\nSnowman = train[train[\"Class\"]=='Snowman']\n\ndf = pd.concat([df,Misce])\ndf = pd.concat([df,Chris_tree])\ndf = pd.concat([df,Jacket])\ndf = pd.concat([df,Candle])\ndf = pd.concat([df,Airplane])\ndf = pd.concat([df,Snowman])","85e153ca":"TRAIN_PATH = '..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train'","b49576da":"def get_model(IMG_SIZE):\n    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    add_model = Sequential()\n    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    add_model.add(Dropout(0.3))\n    add_model.add(Dense(64, activation='relu'))\n    add_model.add(Dropout(0.4))\n\n    add_model.add(Dense(6, activation='softmax'))\n\n    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n                  metrics=['accuracy'])\n    return model\n#     model.summary()","79ab33a5":"# Storing the average of all predictions\n\nmain_pred = []\nerror = []\ndata_kfold = pd.DataFrame()","3fa944d5":"# Creating X, Y for training \n\ntrain_y = df.Class\ntrain_x = df.drop(['Class'],axis=1)","94a7e75d":"IMG_SIZE = 128\nBATCH_SIZE = 16\nEPOCHS = 1\nN_SPLIT = 7","d1ca9f2e":"#Initializing Data Generators\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\n# k-fold\nkfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)\n\n# Variable for keeping count of split we are executing\nj = 0\n\n# K-fold Train and test for each split\nfor train_idx, val_idx in list(kfold.split(train_x,train_y)):\n    x_train_df = df.iloc[train_idx]\n    x_valid_df = df.iloc[val_idx]\n    j+=1\n\n\n    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n                                                 x_col=\"Image\", y_col=\"Class\",\n                                                 class_mode=\"categorical\",\n                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n    \n    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n                                                 x_col=\"Image\", y_col=\"Class\",\n                                                 class_mode=\"categorical\",\n                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n    \n    model_test = get_model(IMG_SIZE)\n    \n    \n    history = model_test.fit_generator( training_set,\n                                        validation_data=validation_set,\n                                        epochs = EPOCHS,\n                                        steps_per_epoch=x_train_df.shape[0] \/\/ BATCH_SIZE\n                                        )\n    \n    test_generator = ImageDataGenerator(rescale = 1.\/255)\n    \n    test_set = test_generator.flow_from_dataframe(dataframe=train, directory=TRAIN_PATH,\n                                                 x_col=\"Image\",y_col=None,\n                                                 class_mode=None,\n                                                 target_size=(IMG_SIZE,IMG_SIZE))\n    \n    pred= model_test.predict_generator(test_set, len(train) \/\/ BATCH_SIZE)\n    predicted_class_indices=np.argmax(pred,axis=1)\n                                       \n    data_kfold[j] = predicted_class_indices\n    gc.collect()","f5afcb82":"# holder\ndata_kfold","740c9e99":"# testing on single iteration of HoldOut\npredicted_class_indices = data_kfold[1]\nlabels=(training_set.class_indices)\nlabels2=dict((v,k) for k,v in labels.items())\npredictions=[labels2[k] for k in predicted_class_indices]","ffdb301a":"print(\"Accuracy of HandOut Method: \",accuracy_score(predictions,train.Class))","af3ae378":"ans = train.copy()","7dfe19b2":"# Taking The Label with Maximum Occurences\n\nlabels=(training_set.class_indices)\nlabels2=dict((v,k) for k,v in labels.items())\nimport collections \nfor i in range(len(data_kfold)):\n    co = collections.Counter(data_kfold.loc[i])\n    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n    ans.Class.loc[i] = labels2[co[0][0]]","c9b4fffe":"# Averaged K-Fold Output\nprint(\"Accuracy of K-Fold Method: \",accuracy_score(train.Class,ans.Class))","84778652":"## **Averaged Accuracy of K-Fold > Accuracy by HoldOut**","7f061b0d":"# Model","ee7a6e36":"# Please Upvote if it helped YOU ! \ud83d\udc4d\u270c","afef7558":"# Setting Path For Images Folder","37468595":"Increase EPOCHS variable if you are going for competition","3751a174":"# Initializing Libraries","b2522f2b":"# Training And Predition","7d890630":"**I took 7 splits as we have 6 labels and even for worst case at least 1 label will have 2 occurence**","6d8d402b":"# Another dataset","6a8d98a7":"# Preparation for kfolds","3681ae16":"# Getting the Data"}}