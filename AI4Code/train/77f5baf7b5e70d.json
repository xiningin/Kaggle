{"cell_type":{"f8870332":"code","2f727862":"code","18e0598a":"code","6e215246":"code","320b5bd7":"code","ae57d17d":"code","c676639c":"code","4aec83c8":"code","306d37df":"code","b77df4a2":"code","cee11522":"code","2d9a2ae4":"code","e8273693":"code","4e78d15f":"code","de818eab":"code","404d4c02":"code","354188de":"code","33de2bfc":"code","7e357af4":"code","8683df45":"code","2f024ded":"code","2c891246":"code","2a7b80af":"code","e3abe627":"code","ff582ebd":"code","4c4f51b4":"markdown","0bc6138c":"markdown","fbab3448":"markdown","275a4e83":"markdown","a4d6cdeb":"markdown","c842ce16":"markdown","0a492c69":"markdown","48efac2f":"markdown","3c098c8f":"markdown","18522d7f":"markdown","e46b6782":"markdown","9317e2d6":"markdown","20a88cb0":"markdown","c4523644":"markdown","46ddd47b":"markdown","e4e5be6b":"markdown"},"source":{"f8870332":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport matplotlib.pyplot as plt\n%matplotlib inline ","2f727862":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","18e0598a":"rows = 28\ncols = 28\nclasses = 10\n\ntest_size = 0.2\nrand = 2000","6e215246":"train_file = \"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\"\ntest_file  = \"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\"\n\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)","320b5bd7":"#Check The training set dimensions \ntrain_data.shape","ae57d17d":"#Check The test set dimensions \ntest_data.shape","c676639c":"# Create a dictionary for each type of label \nlabels = {0 : \"T-shirt\/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\ndef get_classes_distribution(data):\n    label_counts = data[\"label\"].value_counts()\n    total_samples = len(data)\n    for i in range(len(label_counts)):\n        label = labels[label_counts.index[i]]\n        count = label_counts.values[i]\n        percent = (count \/ total_samples) * 100\n        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))","4aec83c8":"#Train set\nget_classes_distribution(train_data)","306d37df":"#Test Set\nget_classes_distribution(test_data)","b77df4a2":"#To understand the dataset\ntrain_data","cee11522":"def sample_images_data(data):\n    # An empty list to collect some samples\n    sample_images = []\n    sample_labels = []\n\n    # Iterate over the keys of the labels dictionary defined in the above cell\n    for k in labels.keys():\n        # Get four samples for each category\n        samples = data[data[\"label\"] == k].head(4)\n        # Append the samples to the samples list\n        for j, s in enumerate(samples.values):\n            # First column contain labels, hence index should start from 1\n            img = np.array(samples.iloc[j, 1:]).reshape(rows,cols)\n            sample_images.append(img)\n            sample_labels.append(samples.iloc[j, 0])\n\n    print(\"Total number of sample images to plot: \", len(sample_images))\n    return sample_images, sample_labels\n\n#plot train sample images\ntrain_sample_images, train_sample_labels = sample_images_data(train_data)","2d9a2ae4":"def plot_sample_images(data_sample_images,data_sample_labels,cmap=\"Blues\"):\n    # Plot the sample images now\n    f, ax = plt.subplots(5,8, figsize=(16,10))\n\n    for i, img in enumerate(data_sample_images):\n        ax[i\/\/8, i%8].imshow(img, cmap=cmap)\n        ax[i\/\/8, i%8].axis('off')\n        ax[i\/\/8, i%8].set_title(labels[data_sample_labels[i]])\n    plt.show()    ","e8273693":"#plot the sample images from the train set\nplot_sample_images(train_sample_images,train_sample_labels)","4e78d15f":"#plot the sample images from the train set\ntest_sample_images, test_sample_labels = sample_images_data(test_data)\nplot_sample_images(test_sample_images,test_sample_labels)","de818eab":"def data_preprocessing(raw):\n    out_y = keras.utils.to_categorical(raw.label, classes)\n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    x_shaped_array = x_as_array.reshape(num_images, rows, cols, 1)\n    out_x = x_shaped_array \/ 255\n    return out_x, out_y","404d4c02":"# prepare the data\nX, y = data_preprocessing(train_data)\nX_test, y_test = data_preprocessing(test_data)","354188de":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=rand)\nprint(\"Fashion MNIST train -  rows:\",X_train.shape[0],\" columns:\", X_train.shape[1:4])\nprint(\"Fashion MNIST valid -  rows:\",X_val.shape[0],\" columns:\", X_val.shape[1:4])\nprint(\"Fashion MNIST test -  rows:\",X_test.shape[0],\" columns:\", X_test.shape[1:4])","33de2bfc":"def get_count_per_class(yd):\n    ydf = pd.DataFrame(yd)\n    # Get the count for each label\n    label_counts = ydf[0].value_counts()\n\n    # Get total number of samples\n    total_samples = len(yd)\n\n\n    # Count the number of items in each class\n    for i in range(len(label_counts)):\n        label = labels[label_counts.index[i]]\n        count = label_counts.values[i]\n        percent = (count \/ total_samples) * 100\n        print(\"{:<20s}:   {} or {}%\".format(label, count, percent))","7e357af4":"#For the Training set\nget_count_per_class(np.argmax(y_train,axis=1))","8683df45":"#For the validation set\nget_count_per_class(np.argmax(y_val,axis=1))","2f024ded":"epochs = 50\nbatch_size = 128\nis_local = False","2c891246":"# Model\nmodel = Sequential()\n# Add convolution 2D\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=(rows, cols, 1)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, \n                 kernel_size=(3, 3), \n                 activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(classes, activation='softmax'))\n\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","2a7b80af":"#To Inspect the model\nmodel.summary()","e3abe627":"train_model = model.fit(X_train, y_train,\n                  batch_size=batch_size,\n                  epochs=epochs,\n                  verbose=1,\n                  validation_data=(X_val, y_val))","ff582ebd":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","4c4f51b4":"The training set has equal distribution of 10% for all the classes","0bc6138c":"## Training the Model","fbab3448":"## Reading Data\n\nTraining set and Test set are two seperate datasets","275a4e83":"## Preparing the model\n### Data pre-processing\n\nReshape the columns from (784) to (28,28,1).<br>\nSave \"label\" as a seperate vector","a4d6cdeb":"The segmentation caused some class distribution imbalance in the training and validation datasets","c842ce16":"### Building the Model\nThe model built is a squential model with the following layers:\n* **Conv2D** which is a 2D CNN layer with the following parameters:\n    * filters: The number of Kernels used in this layer (32)\n    * kernel_size: The dimensions of the kernel (3x3)\n    * activation: the activation function used (relu)\n    * kernel_init: the function for initializing the kernel\n    * input_shape: the shape of input image (28x28) -> outputs 4D tensor.\n* **MaxPooling2D** is a Max pooling operation for spatial data. Parameters used are:\n    * pool_size, in this case (2,2), representing the factors by which to downscale in both directions;\n* **Conv2D** with the following parameters:\n    * filters: 64\n    * kernel_size : (3 x 3)\n    * activation : relu\n* **MaxPooling2D** :\n   * pool_size: (2,2)\n* **Conv2D** :\n    * filters: 128\n    * kernel_size : (3 x 3)\n    * activation : relu\n* **Flatten** to flaten the input\n* **Dense** a regular fully-connected NN layer,used without parameters.\n* **Dense** The final layer. USed with the following parameters:\n\n    * units: the number of classes (in our case 10);\n    * activation : softmax; for this final layer it is used softmax activation (standard for multiclass classification)\n","0a492c69":"## Parameters\nThere are 10 different classes of images, as following:\n\n    0: T-shirt\/top;\n    1: Trouser;\n    2: Pullover;\n    3: Dress;\n    4: Coat;\n    5: Sandal;\n    6: Shirt;\n    7: Sneaker;\n    8: Bag;\n    9: Ankle boot.\n\nImage dimmensions are 28x28.","48efac2f":"### Splitting the training set","3c098c8f":"## Data Exploration ","18522d7f":"## Check Accuracy","e46b6782":"## Run the model","9317e2d6":"### Plot sample images","20a88cb0":"#### Class distribution among the segments","c4523644":"The test set has equal class distribution as well","46ddd47b":"### Class distribution","e4e5be6b":"## Load Libraries"}}