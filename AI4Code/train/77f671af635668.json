{"cell_type":{"8d10de54":"code","ff60592c":"code","f760ebb1":"code","bd328abd":"code","e0792153":"code","21ce67d4":"code","c6a5cfd9":"code","31e9902b":"code","adb385eb":"code","b55e955b":"code","7757270c":"code","b0252279":"code","93e50bfc":"code","9a5047ee":"code","a4664025":"code","f0d86530":"code","4d981e70":"code","bcf8b6b6":"markdown","f751478c":"markdown","2a08d581":"markdown","92fa60c9":"markdown","fc929b0d":"markdown"},"source":{"8d10de54":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport keras\nimport keras.layers as L\nimport math\nfrom keras.utils import Sequence\nfrom keras.preprocessing import image\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nimport plotly.express as px\nimport seaborn as sns\nimport random as python_random\nfrom numba import cuda\nfrom keras.models import load_model\ncuda.select_device(0)\nnp.random.seed(42)\npython_random.seed(42)\ntf.random.set_seed(42)","ff60592c":"train_labels =pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nsample_submission = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ndef id_to_path(idx,train=True):\n    path = '..\/input\/seti-breakthrough-listen\/'\n    if train:\n        folder = 'train\/'\n    else:\n        folder = 'test\/'\n    path+=folder+idx[0]+'\/'+idx+'.npy'\n    return path","f760ebb1":"class Dataset(Sequence):\n    def __init__(self,idx,y=None,batch_size=16,shuffle=True):\n        self.idx = idx\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        if y is not None:\n            self.is_train=True\n        else:\n            self.is_train=False\n        self.y = y\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n    def __getitem__(self,ids):\n        batch_ids = self.idx[ids * self.batch_size:(ids + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x1 = np.array([np.load(id_to_path(x, self.is_train))[::2].reshape(3*273,256) for x in batch_ids]).transpose(1,2,0)\n        list_x2 = np.array([np.zeros((3,3*273,256)) for x in batch_ids]).transpose(1,2,3,0)\n        list_x2[0::] = list_x1\n        list_x2[1::] = list_x1\n        list_x2[2::] = list_x1\n        batch_x = np.transpose(list_x2,(3,1,2,0))\n        if self.is_train:\n            return batch_x, batch_y\n        else:\n            return batch_x\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","bd328abd":"!pip install -U efficientnet","e0792153":"import efficientnet.keras as efn","21ce67d4":"def make_model():\n    model = tf.keras.Sequential([efn.EfficientNetB0(input_shape=(3*273,256,3),weights='imagenet',include_top=False),\n        L.GlobalAveragePooling2D(),\n        L.Dense(32,activation='relu'),\n        L.Dense(1, activation='sigmoid')\n        ])\n\n    model.summary()\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n    return model","c6a5cfd9":"train_idx =  train_labels['id'].values\ny = train_labels['target'].values\ntest_idx = sample_submission['id'].values\nx_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42,stratify=y)\ntrain_dataset = Dataset(x_train,y_train)\nvalid_dataset = Dataset(x_valid,y_valid)\ntest_dataset = Dataset(test_idx)\n","31e9902b":"def auc_plot(auc,val_auc):\n    plt.plot(auc)\n    plt.plot(val_auc)\n    plt.xlabel('epochs')\n    plt.ylabel('auc')\n    plt.title('auc vs epochs')\n    plt.legend(['auc','val_auc'])\n    plt.show()\ndef loss_plot(loss,val_loss):\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.title('loss vs epochs')\n    plt.legend(['loss','val_loss'])\n    plt.show()","adb385eb":"model = make_model()\nhistory = model.fit(train_dataset,epochs=3,validation_data=valid_dataset)\nloss_plot(history.history['loss'],history.history['val_loss'])\npreds = model.predict(test_dataset)\npreds = preds.reshape(-1)\nsubmission = pd.DataFrame({'id':sample_submission['id'],'target':preds})\nsubmission.to_csv('new_submission.csv',index=False)","b55e955b":"old_train_labels = pd.read_csv('..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_labels_old.csv')\nold_test_labels = pd.read_csv('..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_labels_old.csv')","7757270c":"def old_train_path(idx):\n    old_train_path = '..\/input\/seti-breakthrough-listen\/old_leaky_data\/train_old\/'\n    return old_train_path+idx[0]+'\/'+idx+'.npy'\n\ndef old_test_path(idx):\n    old_test_path = '..\/input\/seti-breakthrough-listen\/old_leaky_data\/test_old\/'\n    return old_test_path+idx[0]+'\/'+idx+'.npy'\n\nold_test_labels['path'] = old_test_labels['id'].apply(old_test_path)\nold_train_labels['path'] = old_train_labels['id'].apply(old_train_path)\nold_labels = pd.concat([old_train_labels,old_test_labels],ignore_index=True)","b0252279":"def load_image(data_path):\n    data = np.load(data_path).astype(np.float32)\n    for i in range(data.shape[0]):\n        data[i] -= data[i].mean()\n        data[i] \/= data[i].std()\n    return data","93e50bfc":"class Old_dataset(Sequence):\n    def __init__(self,idx,y=None,batch_size=16,shuffle=True):\n        self.idx = idx\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        if y is not None:\n            self.is_train=True\n        else:\n            self.is_train=False\n        self.y = y\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n    def __getitem__(self,ids):\n        batch_ids = self.idx[ids * self.batch_size:(ids + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x1 = np.array([load_image(x)[::2].reshape(3*273,256) for x in batch_ids]).transpose(1,2,0)\n        list_x2 = np.array([np.zeros((3,3*273,256)) for x in batch_ids]).transpose(1,2,3,0)\n        list_x2[0::] = list_x1\n        list_x2[1::] = list_x1\n        list_x2[2::] = list_x1\n        batch_x = np.transpose(list_x2,(3,1,2,0))\n        if self.is_train:\n            return batch_x, batch_y\n        else:\n            return batch_x\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","9a5047ee":"train_idx =  old_labels['path'].values\ny = old_labels['target'].values","a4664025":"x_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42,stratify=y)\nold_train_dataset = Old_dataset(x_train,y_train)\nold_valid_dataset = Old_dataset(x_valid,y_valid)\nmodel = make_model()\nhistory = model.fit(old_train_dataset,epochs=3,validation_data=old_valid_dataset)\nloss_plot(history.history['loss'],history.history['val_loss'])\npreds = model.predict(test_dataset)\npreds = preds.reshape(-1)\nsubmission = pd.DataFrame({'id':sample_submission['id'],'target':preds})\nsubmission.to_csv('old_submission.csv',index=False)","f0d86530":"train_idx =  train_labels['id'].values\ny = train_labels['target'].values\ntest_idx = sample_submission['id'].values\nx_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.05,random_state=42,stratify=y)\ntrain_dataset = Dataset(x_train,y_train)\nvalid_dataset = Dataset(x_valid,y_valid)\ntest_dataset = Dataset(test_idx)\n","4d981e70":"\nmodel = load_model('..\/input\/fork-of-old-data-vs-new-data-c0a49b\/old_model.h5')\nhistory = model.fit(train_dataset,epochs=2,validation_data=valid_dataset)\nloss_plot(history.history['loss'],history.history['val_loss'])\npreds = model.predict(test_dataset)\npreds = preds.reshape(-1)\nsubmission = pd.DataFrame({'id':sample_submission['id'],'target':preds})\nsubmission.to_csv('submission.csv',index=False)","bcf8b6b6":"# Refrences","f751478c":"# Using both old and new data","2a08d581":"# New Data","92fa60c9":"https:\/\/www.kaggle.com\/awsaf49\/seti-bl-spatial-info-tf-tpu<br>\nhttps:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/239552","fc929b0d":"# Old Data"}}