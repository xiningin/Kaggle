{"cell_type":{"953fcc67":"code","ffa3cd15":"code","2f93a165":"code","dc31d396":"code","5f4aa1bb":"code","7a5b7a28":"code","997bd134":"code","39d7d207":"code","1b19b7eb":"code","0bc0e4fd":"code","29f881de":"code","e323151e":"code","d0ea775e":"code","1a33848b":"code","73e9de7d":"code","ca32e014":"code","38b72bb8":"code","e2264636":"code","1788ed26":"code","09783727":"code","99e568ce":"code","d3d3ba8a":"code","bd8fbbc5":"code","9e22fbb5":"code","6055dae8":"code","55f5b8a0":"code","e5010567":"code","10076b2c":"code","b596cdcc":"code","1c1e952f":"code","6e43ee8c":"code","c40477f0":"code","6da73eed":"code","8ea8e2fd":"markdown","af636bec":"markdown","3b088b52":"markdown","1b1f68d9":"markdown","5505538d":"markdown","b67f1631":"markdown","bef46700":"markdown","6761f05c":"markdown","1fbcf1d3":"markdown","c2a76885":"markdown","308faeb9":"markdown","7fe14ef0":"markdown","e9701705":"markdown","c1ef4eb1":"markdown","c527aafa":"markdown","a35aea56":"markdown","d25f143a":"markdown","8eadbba5":"markdown","8e24654b":"markdown","2cd9dc5d":"markdown"},"source":{"953fcc67":"import numpy as np\nimport pandas as pd","ffa3cd15":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","2f93a165":"data = pd.read_csv('..\/input\/online_ads_dummy_data.csv')","dc31d396":"data.head()","5f4aa1bb":"data.info()","7a5b7a28":"#Converting Timestamp column to 'datetime' Dtype\nimport datetime\ndata['Timestamp'] = pd.to_datetime(data['Timestamp'])\n#Converting Male column to 'int' Dtype\ndata['Male'] = data['Male'].apply(lambda x: int(x))\ndata.info()","997bd134":"data.isnull().sum()","39d7d207":"data.head()","1b19b7eb":"def get_hour(x):\n    return x.hour\n\ndays = dict(enumerate(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']))\n\ndef get_day(x):\n    return days[x.weekday()]\n\nmonths = dict(enumerate(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct','Nov','Dec']))\n\ndef get_month(x):\n    return months[x.month-1]","0bc0e4fd":"data['Month'] = data['Timestamp'].apply(lambda x:get_month(x))\ndata['Day'] = data['Timestamp'].apply(lambda x:get_day(x))\ndata['Hour'] = data['Timestamp'].apply(lambda x:get_hour(x))","29f881de":"data.head(4)","e323151e":"sns.pairplot(data, hue='Clicked on Ad')","d0ea775e":"data.corr()[data.corr()>0.3]","1a33848b":"sns.heatmap(data.corr(),cmap=sns.color_palette(\"BuGn_r\"))","73e9de7d":"data.groupby('Clicked on Ad').mean()","ca32e014":"import plotly.express as px\n\nfig = px.scatter(data, \n                y=\"Daily Time Spent on Site\", \n                x=\"Daily Internet Usage\", \n                title='How daily internet usage affects daily time spent on site.',\n                color='Clicked on Ad', \n                trendline='ols'\n                )\nfig.show()","38b72bb8":"px.scatter(data, \n              x = 'Area Income',\n              y = 'Daily Time Spent on Site',\n              color='Clicked on Ad', \n              trendline='ols',\n              title = 'How Area income effects the daily amount of time that someone spends on the site.'\n             )","e2264636":"px.scatter(data, \n              x = 'Area Income',\n              y = 'Daily Internet Usage',\n              color='Clicked on Ad', \n              trendline='ols',\n              title = 'How Area income effects the daily amount of time that someone spends on the site.'\n             )","1788ed26":"by_hour = data[['Age','Hour']].groupby('Hour').mean()\nsns.barplot(data = by_hour,\n            x = by_hour.index,\n            y='Age',\n            color='green',\n           ).set_title('Average age of site visitor per hour')","09783727":"px.scatter(data, x='Hour',\n           y='Age', \n           color='Clicked on Ad',\n           size_max=5, \n           trendline='lowess', \n           title = 'Age of visitors to the site during each hour of the day.')","99e568ce":"month_dummies = pd.get_dummies(data['Month'],drop_first=True)","d3d3ba8a":"day_dummies = pd.get_dummies(data['Day'],drop_first=True)","bd8fbbc5":"hour_dummies = pd.get_dummies(data['Hour'],drop_first=True)","9e22fbb5":"age_dummies = pd.get_dummies(data['Age']>30,drop_first=True,prefix='>30')","6055dae8":"data.head(3)","55f5b8a0":"categories = pd.concat([month_dummies,day_dummies,hour_dummies,age_dummies, data[['Male','Clicked on Ad']]],axis=1)\ncategories","e5010567":"from sklearn.model_selection import train_test_split","10076b2c":"X = categories.drop('Clicked on Ad',axis=1)\ny = data['Clicked on Ad']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","b596cdcc":"from sklearn.linear_model import LogisticRegression\nlm = LogisticRegression()\nlm.fit(X_train,y_train)","1c1e952f":"predictions = lm.predict(X_test)","6e43ee8c":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","c40477f0":"error = lm.predict(X_test)-y_test","6da73eed":"false_negative = 0\ncorrect = 1\nfalse_positive = 0\n\nfor i in error:\n    if i == -1:\n        false_negative+=1\n    elif i==0:\n        correct+=1\n    else:\n        false_positive+=1\n        \nprint(f'false negative predictions:\\t {false_negative} out of {len(error)} predictions.\\n'\n     +f'\\nfalse negative prediction percentage:  {\"{:.2f}\".format((100*false_negative)\/len(error))}%\\n')\nprint(f'\\ncorrect predictions:\\t {correct} out of {len(error)} predictions.\\n'\n     +f'\\ncorrect prediction percentage:  {\"{:.2f}\".format((100*correct)\/len(error))}%\\n')\nprint(f'\\nfalse positive predictions:\\t {false_positive} out of {len(error)} predictions.\\n'\n     +f'\\nfalse positive predictions:  {\"{:.2f}\".format((100*false_positive)\/len(error))}%')\n      ","8ea8e2fd":"#### Looking at the relationship between 'Daily Internet Usage' and 'Daily Time Spent on Site':\nWe can see that there is a positive correlation between someone's internet usage and the amount of time that they spend on the site. This makes sense because the two variables are likely dependent on each other.\nAdditionally, we can see that on average, those who spent less time on the site clicked the Ad.\nThis implies that the people who are clicking on the Ad are those that may already know what they want to buy and are not spending as much time browsing the site as others.\n\nThe regression line implies that, in a single day, for every extra minute spent on the internet results in approximately 10 more minutes spent on the site.\n    ","af636bec":"#### The data types of each column seem to be in the correct format except for the Timestamp column.\n - We must change the data type of the Timestamp column to DataTime in order to extract information efficiently.\n - We must change the Male column to data type 'int' in order to use it as binary in our Logistic Regression Model.","3b088b52":"### Instantiating, training and using the model","1b1f68d9":"#### Create columns for to add extra features for the time","5505538d":"#### Overall, we can see that there is quite a weak correlation between variables, but the most correlated variables are:\n    - 'Daily Internet Usage' and 'Daily Time Spent on Site'\n    - 'Area Income' and 'Daily Time Spent on Site'\n    - 'Area Income' and 'Daily Internet Usage'\n    - 'Age' and 'Clicked on Ad'","b67f1631":"#### Import the required libraries ","bef46700":"#### Average characteristics of those who click on the Ads\n - On average, we can see that for a person who clicks on an Ad:\n     - Clicks on the Ad at around midday.\n     - They are likely to be a middle-aged female.\n     - They are earning around $50,000.\n     - Daily, they spend 2-3 hours online and 53 minutes on the site.","6761f05c":"# Exploratory Data Analysis","1fbcf1d3":"#### Looking at the relationship between 'Hour' and 'Age':\nWe can see that as the day progresses, the average age stays approximately constant with a few decreases. Most of the decreases occur between the times 12:00 and 21:00. This may be because the visitors are at leisure points of the day such as: lunchtime, after-work, dinner, late-evening etc.\nAdditionally, we can see that on average, those that clicked on the Ad were older than those that didn't.\nThis implies that the Ad may have targeted the older age group and does not appeal to a younger audience.\n\nThe regression line indicates that on the average age of people using the site decreases very gradually throughout the day however this change is almost negligable.","c2a76885":"\n# Data Cleaning \n ","308faeb9":"#### Read the data into a pandas dataframe","7fe14ef0":"# Advertising data\nI will be using mock advertising data in order to demonstrate data cleaning, exploration and application. In order to complete the data wrangling stage, I will use the libraries numPy and pandas. For the data visualisations I will use the libraries seaborn, matplotlib and plotly. \nDuring the exploration stage, I will explore the relationships between features of each customer and infer meaning from the trends. I will then use this analylsis to build a clear picture and understanding of the context of the data.\nDuring the application stage, I will implement a logistic regression model to predict whether a customer clicked on an Ad or not based on the features of the customer.","e9701705":"#### Identifying initial trends.","c1ef4eb1":"#### We can also see that there are no empty values in this dataset.","c527aafa":"#### Looking at the relationship between 'Area Income' and 'Daily Internet Usage':\nWe can see that there is a positive correlation between the average person's income and the amount of time that they spend on the internet. This makes sense because, like outlined above, a person of higher income is likely to spend more time shopping online. \n\nThe regression line implies that an increase in average area income of $1000 results in an extra minute spent online.\n    ","a35aea56":"# Logistic Regression Analysis","d25f143a":"### Correctly formatting the categorical data","8eadbba5":"#### Looking at the relationship between 'Area Income' and 'Daily Time Spent on Site':\nWe can see that there is a positive correlation between the average person's income and the amount of time that they spend on the site.\nThis makes sense because it is likely that a person in an area with a higher average income, will have more money to spend on the site.\nAdditionally, we can see that on average the areas that earned less on average were more likely to have clicked the Ad.\nThis implies that the product in the Ad may not have been appealing to the higher end of the market.\n\nThe regression line implies that an increase of $1000 in the average area income results in an extra 20 seconds spent on the site.","8e24654b":"#### Dealing with categorical columns","2cd9dc5d":"## Graphical representation of relationships between variables"}}