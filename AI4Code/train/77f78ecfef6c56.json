{"cell_type":{"b5f1a0d1":"code","5b1d3c36":"code","1f3c51b5":"code","ab4aa9f7":"code","83f578d5":"code","89c8c516":"code","1dea87cd":"code","56933a55":"markdown"},"source":{"b5f1a0d1":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt","5b1d3c36":"#Load Yolo\nnet = cv2.dnn.readNet(\"..\/input\/gleasonyolo\/yolov3.weights\", \"..\/input\/gleasonyolo\/Detectx-Yolo-V3-master-manami\/Detectx-Yolo-V3-master-manami\/cfg\/yolov3.cfg\")\nclasses = []\nwith open(\"..\/input\/gleasonyolo\/Detectx-Yolo-V3-master-manami\/Detectx-Yolo-V3-master-manami\/data\/coco.names\", \"r\") as f:\n  classes = [line.strip() for line in f.readlines()]","1f3c51b5":"layer_names = net.getLayerNames()\noutput_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\ncolors = np.random.uniform(0, 255, size = (len(classes), 3))","ab4aa9f7":"#loading image\nimg = cv2.imread(\"..\/input\/the-room-image\/room_ser.jpg\")\nimg = cv2.resize(img, None, fx = 0.4, fy = 0.4)\nheight, width, channels = img.shape\nplt.imshow(img)","83f578d5":"#Detecting objects\nblob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0,0,0), True, crop = False)\nfig, axes = plt.subplots(ncols=3, figsize = (11,11))\nfor b in blob:\n    for n, img_blob in enumerate(b):\n        axes[n].imshow(img_blob)\nplt.show()","89c8c516":"net.setInput(blob)\nouts = net.forward(output_layers)","1dea87cd":"#Name of the object, showing informations on the screen\nconfidences = []\nclass_ids = []\nboxes = []\n\nfor out in outs:\n    for detection in out:\n        scores = detection[5: ]\n        class_id = np.argmax(scores)\n        confidence = scores[class_id]\n        if confidence > 0.5:\n            #object detected\n            center_x = int(detection[0] * width)\n            center_y = int(detection[1]* height)\n            w = int(detection[2] * width)\n            h = int(detection[3] * height)\n            \n            # Rectangle Co-ordinates\n            x = int(center_x - w \/ 2)\n            y = int(center_y - h \/ 2)\n            \n            cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n            \n            cv2.circle(img, (center_x, center_y), 10, (0, 255, 0),2)\n            \n            boxes.append([x, y, w, h])\n            confidences.append(float(confidence))\n            class_ids.append(class_id)\n\nindexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\nprint(indexes)\nnumber_objects_detected = len(boxes)\nfont = cv2.FONT_HERSHEY_PLAIN\nfor i in range (len(boxes)):\n    if i in indexes:\n        x, y, w, h = boxes[i]\n        label = str(classes[class_ids[i]])\n        color= colors[i]\n        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n        cv2.putText(img, label, (x, y + 30), font, 4, color, 3)\n        print(label)\n    \nmyPlt = plt.imshow(img)\n\nfig = myPlt.get_figure()\nfig.savefig(\"output_detection.png\")","56933a55":"Ref: https:\/\/www.youtube.com\/watch?v=h56M5iUVgGs&t=1933s\nhttps:\/\/www.kaggle.com\/tasnimnishatislam\/eda-and-basics"}}