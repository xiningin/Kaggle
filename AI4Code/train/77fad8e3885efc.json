{"cell_type":{"640dbc56":"code","43257423":"code","d4929af3":"code","73effbfe":"code","9cf2c785":"code","d75fee09":"code","a04eb1df":"code","9aa6cc7f":"code","f62658e4":"code","b425fb9a":"code","2be6bfa3":"code","712edf2f":"code","efb11026":"code","b9633502":"code","9636375b":"code","52d1639d":"code","1942cb7a":"code","637fc946":"code","792ed161":"code","33b8e32a":"code","46b03c27":"code","f2b8329a":"code","7b186596":"code","80797d5b":"code","00f41489":"code","a5a50788":"code","e586b7f7":"code","43cd03be":"code","810239a9":"code","585d6ce8":"code","bcaddf39":"code","47221a9f":"code","51eb2c0f":"code","56240452":"code","2ea4b7a9":"code","630d57b9":"code","3210fbd9":"code","56e9660d":"code","8c8d576e":"code","258522a7":"code","d22b30bb":"code","a09063dc":"code","f7e8db58":"code","493116ed":"code","35ab8d33":"code","eff95ef1":"code","21ad4ebf":"code","b54617f7":"code","1a44ca7c":"code","fd2c3f24":"code","4b38fb5a":"code","d1bd9596":"code","290f50c2":"code","d4b9a3ed":"code","c21b4474":"markdown","8343e1ac":"markdown","f4e4a82e":"markdown","a55e28d8":"markdown","9ca5bf4c":"markdown","a0558a3f":"markdown","b20ce7b6":"markdown","9cfff4be":"markdown","24e3f6fb":"markdown","b1c88307":"markdown","3e556b7a":"markdown","5ae1ae34":"markdown","2c556d5e":"markdown","de63f43c":"markdown","8993deb4":"markdown","f04de183":"markdown","95037478":"markdown","58f181da":"markdown","d9ca3626":"markdown","bf497f52":"markdown","7057a69e":"markdown","379fa061":"markdown","d37a700a":"markdown","0df7f939":"markdown","f45339e0":"markdown","d53ee3df":"markdown","fd6dff4b":"markdown","4ff3442d":"markdown","882ac50f":"markdown","a8068b6d":"markdown","2567dc7c":"markdown","ca416122":"markdown","c98a6313":"markdown","8ef2ab8a":"markdown","73771ac1":"markdown","55c01604":"markdown","faa3b3c0":"markdown","5a92bfa0":"markdown","9d5f9c48":"markdown","4b0eabdb":"markdown","77aff07c":"markdown"},"source":{"640dbc56":"import pandas as pd \nimport numpy as np\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('dark')\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","43257423":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","d4929af3":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","73effbfe":"train_data.info()","9cf2c785":"test_data.info()","d75fee09":"train_data.shape, test_data.shape","a04eb1df":"train_data.duplicated().sum()","9aa6cc7f":"test_data.duplicated().sum()","f62658e4":"train_data['Survived'].value_counts(normalize=True)","b425fb9a":"plt.figure(figsize=(10,5))\nplt.title('Survivors and Deads Count', fontsize=14)\nsns.countplot(x=train_data['Survived'], palette=('#C52219', '#23C552'))\nplt.xlabel(\"Survival & Dead Rate\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","2be6bfa3":"train_data['Sex'].value_counts().to_frame()","712edf2f":"train_data.groupby('Sex').Survived.mean()","efb11026":"fig, axarr = plt.subplots(1, 2, figsize=(10,5))\na = sns.countplot(train_data['Sex'], ax=axarr[0], palette=('#003f7f','#ff007f')).set_title('Passengers count by sex')\naxarr[1].set_title('Survival rate by sex')\nb = sns.barplot(x='Sex', y='Survived', data=train_data, palette=('#003f7f','#ff007f'), ci=None, ax=axarr[1]).set_ylabel('Survival rate')","b9633502":"train_data['Pclass'].value_counts().to_frame()","9636375b":"train_data.groupby('Pclass').Survived.mean()","52d1639d":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\na = sns.barplot(x='Pclass', y='Survived', data=train_data, palette=\"Greens\", ci=None, ax=axarr[0]).set_ylabel('Survival rate')\naxarr[0].set_title('Survival rate by class')\nb = sns.countplot(x='Pclass', hue='Survived', data=train_data, palette=('#C52219', '#23C552'), ax=axarr[1]).set_title('Survivors and deads count by class')","1942cb7a":"train_data.groupby(['Pclass', 'Sex']).Survived.mean().to_frame()","637fc946":"plt.figure(figsize = [10,5])\nplt.title('Survival rate by sex and class')\ng = sns.barplot(x='Pclass', y='Survived', hue='Sex', palette=('#003f7f','#ff007f'), ci=None, data=train_data).set_ylabel('Survival rate')","792ed161":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\naxarr[0].set_title('Age distribution')\nf = sns.distplot(train_data['Age'], color='g', bins=40, ax=axarr[0])\naxarr[1].set_title('Age distribution for the two subpopulations')\ng = sns.kdeplot(train_data['Age'].loc[train_data['Survived'] == 1], color='#C52219',\n                shade= True, ax=axarr[1], label='Survived').set_xlabel('Age')\ng = sns.kdeplot(train_data['Age'].loc[train_data['Survived'] == 0], color='#23C552',\n                shade=True, ax=axarr[1], label='Not Survived')","33b8e32a":"plt.figure(figsize=(10,5))\ng = sns.swarmplot(y='Sex', x='Age', hue='Survived', palette=('#C52219', '#23C552'), data=train_data).set_title('Survived by age and sex')","46b03c27":"plt.figure(figsize=(10,5))\nh = sns.barplot(x='Pclass', y='Age', hue='Survived', palette=('#C52219', '#23C552'), ci=None, data=train_data).set_title('Survived by age and class')","f2b8329a":"train_data.Fare.describe().to_frame()","7b186596":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\nf = sns.distplot(train_data.Fare, color='g', ax=axarr[0]).set_title('Fare distribution')\nfare_ranges = pd.qcut(train_data.Fare, 4, labels = ['Low', 'Mid', 'High', 'Very high'])\naxarr[1].set_title('Survival rate by fare category')\ng = sns.barplot(x=fare_ranges, y=train_data.Survived, palette='mako', ci=None, ax=axarr[1]).set_ylabel('Survival rate')","80797d5b":"plt.figure(figsize=(10,5))\na = sns.swarmplot(x='Sex', y='Fare', hue='Survived', palette=('#C52219', '#23C552'), data=train_data).set_title('Survived by fare and sex')","00f41489":"train_data.loc[train_data.Fare==0]","a5a50788":"def remove_zero_fares(row):\n    if row.Fare == 0:\n        row.Fare = np.NaN\n    return row\n# Apply the function\ntrain_data = train_data.apply(remove_zero_fares, axis=1)\ntest_data = test_data.apply(remove_zero_fares, axis=1)\n# Check if it did the job\nprint('Number of zero-Fares: {:d}'.format(train_data.loc[train_data.Fare==0].shape[0]))","e586b7f7":"train_data['Embarked'].value_counts().to_frame()","43cd03be":"train_data.groupby('Embarked').Survived.mean().to_frame()","810239a9":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\nsns.countplot(train_data['Embarked'], palette='magma', ax=axarr[0]).set_title('Passengers count by boarding point')\np = sns.countplot(x = 'Embarked', hue = 'Survived', data = train_data, palette=('#C52219', '#23C552'),\n                  ax=axarr[1]).set_title('Survivors and deads count by boarding point')","585d6ce8":"train_data.groupby(['Embarked', 'Pclass']).Survived.sum().to_frame()","bcaddf39":"plt.figure(figsize=(10,5))\ng = sns.countplot(data=train_data, x='Embarked', hue='Pclass', palette=\"twilight\").set_title('Pclass count by embarking point')","47221a9f":"train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","51eb2c0f":"train_data['Title'].value_counts().to_frame()","56240452":"test_data['Title'].value_counts().to_frame()","2ea4b7a9":"train_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntrain_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)","630d57b9":"train_data.groupby('Title').Survived.mean()","3210fbd9":"plt.figure(figsize=(10,5))\nplt.title('Survival rate by Title')\ng = sns.barplot(x='Title', y='Survived', palette=\"magma\", ci=None, data=train_data).set_ylabel('Survival rate')","56e9660d":"train_data['Ticket_lett'] = train_data.Ticket.apply(lambda x: x[:2])\ntest_data['Ticket_lett'] = test_data.Ticket.apply(lambda x: x[:2])","8c8d576e":"train_data['Ticket_len'] = train_data.Ticket.apply(lambda x: len(x))\ntest_data['Ticket_len'] = test_data.Ticket.apply(lambda x: len(x))","258522a7":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\na = sns.countplot(train_data['SibSp'], palette=\"magma\", ax=axarr[0]).set_title('Passengers count by SibSp')\naxarr[1].set_title('Survival rate by SibSp')\nb = sns.barplot(x='SibSp', y='Survived', data=train_data, palette=\"mako\", ci=None, ax=axarr[1]).set_ylabel('Survival rate')","d22b30bb":"plt.figure(figsize = [10,5])\nplt.title('Survival rate by SibSp')\nsns.countplot(x='SibSp', hue='Survived', palette=('#C52219', '#23C552'), data=train_data)","a09063dc":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\na = sns.countplot(train_data['Parch'], palette=\"magma\", ax=axarr[0]).set_title('Passengers count by Parch')\naxarr[1].set_title('Survival rate by Parch')\nb = sns.barplot(x='Parch', y='Survived', data=train_data, palette=\"mako\", ci=None, ax=axarr[1]).set_ylabel('Survival rate')","f7e8db58":"plt.figure(figsize = [10,5])\nplt.title('Survival rate by Parch')\nsns.countplot(x='Parch', hue='Survived', palette=('#C52219', '#23C552'), data=train_data)","493116ed":"train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] + 1","35ab8d33":"plt.figure(figsize=(10,5))\nplt.title('Survival rate by family size')\ng = sns.barplot(x='Fam_size', y='Survived', palette=\"magma\", ci=None, data=train_data).set_ylabel('Survival rate')","eff95ef1":"plt.figure(figsize=(10,5))\nplt.title('Survival rate by family size')\nsns.countplot(x='Fam_size', hue='Survived', data=train_data, palette=('#C52219', '#23C552'))","21ad4ebf":"# Creation of four groups\ntrain_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])","b54617f7":"plt.figure(figsize=(10,5))\nplt.title('Survival rate by family type')\ng = sns.barplot(x=train_data.Fam_type, y=train_data.Survived, palette='twilight', ci=None).set_ylabel('Survival rate')","1a44ca7c":"plt.figure(figsize=(10,5))\nplt.title('Survival rate by family type')\nsns.countplot(x='Fam_type', hue='Survived', data=train_data, palette=('#C52219', '#23C552'))","fd2c3f24":"y = train_data['Survived']\nfeatures = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_lett']\nX = train_data[features]\nX.head()","4b38fb5a":"numerical_cols = ['Fare']\ncategorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_lett']\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='median')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Bundle preprocessing and modeling code \ntitanic_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))\n])\n\n# Preprocessing of training data, fit model \ntitanic_pipeline.fit(X,y)\n\nprint('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))","d1bd9596":"X_test = test_data[features]\nX_test.head()","290f50c2":"# Preprocessing of test data, get predictions\npredictions = titanic_pipeline.predict(X_test)","d4b9a3ed":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint('Your submission was successfully saved!')","c21b4474":"* **Looking at the distribution of the titles, it might be convenient to move the really low-frequency ones into bigger groups.**  \n* **After analyzing them, we can substitute all rare female titles with Miss and all rare male titles with Mr.**","8343e1ac":"**Since from the EDA I remember that we have missing values in both train and test data and multiple categorical variables to deal with, we can usepipelines to simplify all the work.**","f4e4a82e":"## Age & Sex\n* **At a first look, the relationship between `Age` and `Survived` appears not to be very clear, we notice for sure that there is a peak corresponding to young passengers for those who survived, but apart from that the rest is not very informative.**  \n* **We can appreciate this feature more if we consider `Sex` too: now it is clearer that a good number of male survivors had less than 12 years, while the female group has no particular properties.**","a55e28d8":"## Sex\n* **We see that around 65% of the passengers were male while the remaining 35% were female.** \n* **The important thing to notice here is that the survival rate for women was four times the survival rate for men and this makes `Sex` one of the most informative features.**","9ca5bf4c":"## Age, Pclass & Sex\n* **Another interesting thing to look at is the relation between `Age`, `Pclass` and `Survived`.**  \n* **We see the influence of `Pclass` is the important one as there are no super clear horizontal patterns.** \n* **Also, we note that there were not many children in the first class.**","a0558a3f":"## Parch\n* **Similar to the `SibSp` column, this feature contains the number of parents or children each passenger was traveling with.** \n* **Here we draw the same conclusions as `SibSp`; we see again that small families had more chances to survive than bigger ones and passengers who traveled alone.**","b20ce7b6":"**From above tables, we can say that `Age`, `Cabin` and `Embarked` are missing in the train data set, while values in `Age`, `Fare` and `Cabin` are missing in the test data.**","9cfff4be":"**Calculate ticket length**","24e3f6fb":"**All we have to do now is convert them into the submission file!**","b1c88307":"# Modeling\n* **We start by selecting the features we will use and isolating the target.**  \n* **We will not consider `Cabin` and in the end, we also excluded `Age` as the relevant information which is being a young man is encoded in the Master title.**  \n* **We also did not use `Sex` as it is not useful given the `Title` column: adult males and young children have the same sex but are really different categories as we saw before, so we don't want to confuse our algorithm.**  \n\n***If you don't extract the `Title` column, remember to put `Sex` in your models as it is pretty important!***","3e556b7a":"**Extract the first two letters**","5ae1ae34":"## Importing Required Packages","2c556d5e":"## Fare\n* **From the description, we see that the `Fare` distribution is positively skewed, with 75% of data under 31 and a maximum of 512.**  \n* **Just to understand better this feature, the simplest idea here could be creating fare ranges using quartiles.** \n* **At a first look, we notice that the higher the fare, the higher the possibility of surviving.**","de63f43c":"## Embarked \n* **`Embarked` tells us where a passenger boarded from.**\n* **There are three possible values for it: Southampton, Cherbourg and Queenstown.**  \n* **In the training data, more than 70% of the people boarded from Southampton, slightly under 20% from Cherbourg and the rest from Queenstown.**\n* **Counting survivors by boarding point, we see that more people who embarked from Cherbourg survived than those who died.**\n* **People who Embarked from Southampton, most of them couldn't survive the disaster.**","8993deb4":"![](https:\/\/preview.redd.it\/0izq0428pe661.jpg?width=960&format=pjpg&auto=webp&s=15022053715fc50198a17c401be035445592fee2)","f04de183":"**I ran this file On 4th Mar, and as a result i got in to top 4%**","95037478":"## Pclass\n* **There were three classes on the ship and from the plot we see that the number of passengers in the third class was higher than the number of passengers in the first and second classes combined.**\n* **However, the survival rate by class is not the same, more than 60% of first-class passengers and around half of the second class passengers were rescued, whereas 75% of third class passengers were not able to survive the disaster.**  \n* **For this reason, this is definitely an important aspect to consider.**","58f181da":"## Cabin and Ticket\n* **The `Cabin` feature is somewhat problematic as there are many missing values.**  \n* **We can not expect it to help our model too much.**  \n* **On the other side, a correctly engineered `Ticket` column is the best way to find family groups.** \n* **Since it is a pity to delete it knowing its full potential, we can create two new columns; one for the ticket first two letters and the second one for the ticket length.**","d9ca3626":"## Family Type\n**To further summarize the previous trend, as our final feature,  Let's create four groups for family size.**","bf497f52":"**Here is the final result, we discovered a nice pattern.**","7057a69e":"**Load and display train data**","379fa061":"## Pclass & Sex\n\n* **We can also see the survival rate by `Sex` and `Pclass`, which is quite impressive. First class and second class women who were rescued were respectively 97% and 92%, while the percentage drops to 50% for third-class women.**  \n* **Despite that, this is still more than the 37% survival rate for first-class men.** ","d37a700a":"* **The claim is correct and hopefully justifies why that survival rate is so high at Cherbourg** \n* **Again this feature might be useful in detecting groups at a deeper level of a tree and this is the only reason why I keep it.**\n* **Also, most of the 3rd class people have Embarked from Southampton and died.**\n* **And there is only 1 person from 1st class and 2 person from 2nd class Embarked from Queenstown.**","0df7f939":"**There are almost 15 such passengers are present.\nSince some of them are 1st or 2nd class passengers, we should remove zero-Fares that might confuse our model.  \nWith the help of this function, we are going to set null values every time we encounter a zero value for `Fare`.**","f45339e0":"## Embarked & Pclass\n* **Since we don't expect that a passenger's boarding point could change the chance of surviving, we guess this is probably due to the higher proportion of first and second class passengers for those who came from Cherbourg rather than Queenstown and Southampton.** \n* **To check this, we see the class distribution for the different embarking points.**","d53ee3df":"**Also after looking describe function, we noticed that the minimum value for `Fare` is zero and that is a bit strange.  \nLet's see who these passengers are.**","fd6dff4b":"## SibSp\n* **`SibSp` is the number of siblings or spouses of a person aboard the Titanic.**  \n* **We see that more than 90% of people traveled alone or with one sibling or spouse.** \n* **The survival rate between the different categories is a bit confusing but we see that the chances of surviving are lower for those who traveled alone or with more than 2 siblings.**  \n* **Furthermore, we notice that no one from a big family with 5 or 8 siblings was able to survive.**","4ff3442d":"**Let's check for missing values in both training and test data.**","882ac50f":"**Plotting the survival rate by family size it is clear that people who were alone had a lower chance of surviving than families up to 4 components, while the survival rate drops for bigger families and ultimately becomes zero for very large ones.**","a8068b6d":"# Introduction\nThe sinking of the **Titanic** is one of the most infamous shipwrecks in history. On **April 15, 1912**, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing **1502** out of **2224** passengers and crew. This is a very unforgetable disaster that no one in the world can forget.\n\nIt took about $7.5 million to build the Titanic and it sunk under the ocean due to collision. The Titanic Dataset is a very good dataset for begineers to start a journey in data science and participate in competitions in Kaggle.\n\nThe Objective of this notebook is to give an idea how is the workflow in any predictive modeling problem. How do we check features, how do we add new features and some Machine Learning Concepts. I have tried to keep the notebook as basic as possible so that even newbies can understand every phase of it.","2567dc7c":"**Here is the final result. We have relatively high hopes for this new feature since the survival rate in most cases appears to be either significantly above or below the average survival rate, which should help our model.**","ca416122":"**We see that in the training data only around 38.4% of the passengers managed to survive the disaster.**","c98a6313":"**Load and display test data**","8ef2ab8a":"## Name\n* **The `Name` column contains useful information as for example we could identify family groups using surnames.**  \n* **In this notebook, however, we extracted only the passengers' title from it, creating a new feature for both train and test data.**","73771ac1":"# Feature Analysis","55c01604":"* **Here we'll see how our data used to perform a more precise feature selection in the modeling part.** \n* **We will thus explore one feature at a time in order to determine its importance in predicting if a passenger survived or not.**","faa3b3c0":"## Fare & Sex\n* **Looking at the more detailed plot below, we also see for example that all males with fare between 200 and 300 died.**  \n* **For this reason, we can left the `Fare` feature as it is in order to prevent losing too much information; at deeper levels of a tree, a more discriminant relationship might open up and it could become a good group detector.**","5a92bfa0":"**We are now ready to make our predictions by simply calling the predict method on the test data.**","9d5f9c48":"## Age\n* **Despite this column contains a lot of missing values, we see that in the training data the average age was just under 30 years.**  \n* **Here is the plot of the age distribution in general compared to the one for the survivors and the deads.**","4b0eabdb":"## Family Size\n* **Since we have two seemingly weak predictors, one thing we can do is combine them to get a stronger one.** \n* **In the case of `SibSp` and `Parch`, we can join the two variables to get a family size feature, which is the sum of `SibSp`, `Parch` and 1 (who is the passenger himself).** \n* **Creation of a new Fam_size column**","77aff07c":"**Let's focus on the target(survival) and see how many passengers survived.**"}}