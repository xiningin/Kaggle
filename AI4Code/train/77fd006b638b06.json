{"cell_type":{"1a1bd78d":"code","d7354668":"code","58bc8925":"code","5beb00a5":"code","227eb70b":"code","02e5abb8":"code","6670f2fd":"code","061a8850":"code","5befb3dd":"code","ad74ac0e":"code","085cf1f6":"code","dbf56d87":"code","092ee00d":"markdown","8af4bbb5":"markdown"},"source":{"1a1bd78d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans \nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d7354668":"df=pd.read_csv(\"..\/input\/College.csv\", index_col = 0)","58bc8925":"df.head()","5beb00a5":"df_corr = df.corr() > 0.5\n#df_corr\ndf_corr[\"corr_sum\"] = df_corr.sum()\ndf_corr = df_corr[df_corr[\"corr_sum\"] >= 5]\nprint(df_corr)\nprint(df_corr.index.values)\nsns.heatmap(df.corr())","227eb70b":"# df1 = df[df_corr.index.values]\n# df1.head()\n# df.columns\ndf1 = df.drop(['Private'], axis =1)\ndf1.columns","02e5abb8":"# kmeans=KMeans(n_clusters=2)","6670f2fd":"# kmeans.fit(df1)","061a8850":"# kmeans.cluster_centers_","5befb3dd":"# kmeans.labels_","ad74ac0e":"#df[\"Grad\"] = df[\"Grad.Rate\"].apply(lambda x: 1 if x > 75 else(2 if x > 50 else(3 if x > 25 else 4)))\n# df[\"cluster\"] = kmeans.labels_\n# df.head(50)","085cf1f6":"from sklearn.metrics import silhouette_samples, silhouette_score\nfor i,k in enumerate([2,3,4]):\n    fig,(ax1,ax2) = plt.subplots(1,2)\n    fig.set_size_inches(18,7)\n\n    #Run the kmeans algorithm\n    km = KMeans(n_clusters = k)\n    labels = km.fit_predict(df1)\n    centroids = km.cluster_centers_\n    #take silhouette samples\n    silhouette_vals = silhouette_samples(df1, labels)\n    #silhouette plots\n    y_ticks = []\n    y_lower, y_upper = 0, 0\n    for i, cluster in enumerate(np.unique(labels)):\n        cluster_silhouette_vals = silhouette_vals[labels == cluster]\n        cluster_silhouette_vals.sort()\n        y_upper += len(cluster_silhouette_vals)\n        ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n        ax1.text(-0.03, (y_lower + y_upper) \/ 2, str(i + 1))\n        y_lower += len(cluster_silhouette_vals)\n    # Get the average silhouette score and plot it\n    avg_score = np.mean(silhouette_vals)\n    ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n    ax1.set_yticks([])\n    ax1.set_xlim([-0.1, 1])\n    ax1.set_xlabel('Silhouette coefficient values')\n    ax1.set_ylabel('Cluster labels')\n    ax1.set_title('Silhouette plot for the various clusters', y=1.02);\n    \n    # Scatter plot of data colored with labels\n    ax2.scatter(df1.values[:, 0], df1.values[:, 1], c=labels)\n    ax2.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='r', s=250)\n    ax2.set_xlim([-2, 2])\n    ax2.set_xlim([-2, 2])\n    ax2.set_xlabel('Eruption time in mins')\n    ax2.set_ylabel('Waiting time to next eruption')\n    ax2.set_title('Visualization of clustered data', y=1.02)\n    ax2.set_aspect('equal')\n    plt.tight_layout()\n    plt.suptitle(f'Silhouette analysis using k = {k}',\n                 fontsize=16, fontweight='semibold', y=1.05);","dbf56d87":"# Run the algorithm and find the index of cluster data points\nsse = []\nlist_k = list(range(1,10))\n\nfor k in list_k:\n    km = KMeans(n_clusters =k)\n    km.fit(df1)\n    sse.append(km.inertia_)\nprint(sse)\n#plot sse against k\n\nplt.figure(figsize = (6,6))\nplt.plot(list_k, sse, '-o')\nplt.xlabel(r'Number of clusters *k*')\nplt.ylabel('Sum of squared distance');","092ee00d":"## Elbow Method","8af4bbb5":"# Modelling and Evaluation\n## Silhouette Analysis"}}