{"cell_type":{"61c1c991":"code","2ea5972b":"code","1be08a21":"code","af5f1a41":"code","c3535927":"code","1579a147":"code","1f997fd2":"code","c0532e42":"code","fc7e21d0":"code","0298005c":"code","1b22b15f":"code","17961dcc":"code","7faa0b53":"code","c50cdb61":"code","fa1eac53":"code","cdf18d5b":"markdown"},"source":{"61c1c991":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, runni\u0403ng this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2ea5972b":"from tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization,Dropout\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.utils import to_categorical\nimport cv2\nfrom tqdm import tqdm\nimport random as rn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","1be08a21":"#\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\nX=[]\nZ=[]\nIMG_SIZE=150\nFLOWER_DAISY_DIR='..\/input\/flowers-recognition\/flowers\/flowers\/daisy'\nFLOWER_SUNFLOWER_DIR='..\/input\/flowers-recognition\/flowers\/flowers\/sunflower'\nFLOWER_TULIP_DIR='..\/input\/flowers-recognition\/flowers\/flowers\/tulip'\nFLOWER_DANDI_DIR='..\/input\/flowers-recognition\/flowers\/flowers\/dandelion'\nFLOWER_ROSE_DIR='..\/input\/flowers-recognition\/flowers\/flowers\/rose'\n\ndef assign_label(img,flower_type):\n    return flower_type\n\ndef make_train_data(flower_type,DIR):\n    for img in tqdm(os.listdir(DIR)):\n        label=assign_label(img,flower_type)\n        path = os.path.join(DIR,img)\n        _, ftype = os.path.splitext(path)\n        if ftype == \".jpg\":\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n            X.append(np.array(img))\n            Z.append(str(label))\n\n","af5f1a41":"make_train_data('Daisy',FLOWER_DAISY_DIR)\nmake_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\nmake_train_data('Tulip',FLOWER_TULIP_DIR)\nmake_train_data('Dandelion',FLOWER_DANDI_DIR)\nmake_train_data('Rose',FLOWER_ROSE_DIR)","c3535927":"#-------------------------------------------------------\nle=LabelEncoder()\nY=le.fit_transform(Z)\nY=to_categorical(Y,5)\nX=np.array(X)\nX=X\/255\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n\nnp.random.seed(42)","1579a147":"batch_size=32\nepochs=100\n\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau\nred_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5)","1f997fd2":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","c0532e42":"# del model","fc7e21d0":"model = Sequential()\n\nmodel.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.layers[0].trainable = False","0298005c":"from tensorflow.python.keras.optimizers import Adam\nmodel.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","1b22b15f":"# count = sum([len(files) for r, d, files in os.walk(\"..\/input\/flowers-recognition\/flowers\/flowers\/\")])\n\nHistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, \n                              validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size,callbacks=[red_lr])","17961dcc":"import matplotlib.pyplot as plt\nplt.plot(History.history['acc'])\nplt.plot(History.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","7faa0b53":"# getting predictions on val set.\npred=model.predict(x_test)\npred_digits=np.argmax(pred,axis=1)","c50cdb61":"\n# now storing some properly as well as misclassified indexes'.\ni=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==pred_digits[i]):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(y_test)):\n    if(not np.argmax(y_test[i])==pred_digits[i]):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break","fa1eac53":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_test[mis_class[count]])\n        ax[i,j].set_title(\"Predicted Flower :\"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n        plt.tight_layout()\n        count+=1","cdf18d5b":"# Shameless copy from [Stefan Petrushevski](https:\/\/www.kaggle.com\/cokastefan) and [Raj Mehrotra](https:\/\/www.kaggle.com\/rajmehra03)"}}