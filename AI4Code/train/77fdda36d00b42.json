{"cell_type":{"5813a1a3":"code","49b5be2d":"code","6af1731c":"code","0f209a76":"code","06fde6af":"code","cb9d1949":"code","33fa4216":"code","dd779bd5":"code","8e5908aa":"code","b8dab7d8":"code","ece9b0e8":"code","6a49d326":"code","6942b116":"code","9b82b8b6":"code","e4fe9806":"code","a0adde0d":"code","5172ca28":"code","8ee5630d":"code","27640d44":"code","5100b4e2":"markdown","237e985b":"markdown","274dcef9":"markdown","8b90b89e":"markdown","d4d3760a":"markdown","bb7e06e3":"markdown","458ff22f":"markdown","06818c50":"markdown","37be9e32":"markdown","56339576":"markdown","afd40885":"markdown"},"source":{"5813a1a3":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport itertools    \nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import confusion_matrix","49b5be2d":"import pathlib\n\ndata_dir = pathlib.Path('..\/input\/handwritten-math-symbols\/dataset')","6af1731c":"image_count = len(list(data_dir.glob('*\/*.*')))\nprint(\"Total no of images =\",image_count)","0f209a76":"digits = list(data_dir.glob('6\/*'))\nPIL.Image.open(str(digits[0]))","06fde6af":"batch_size = 32\nimg_height = 100\nimg_width = 100","cb9d1949":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  #color_mode=\"grayscale\",\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","33fa4216":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  #color_mode=\"grayscale\",\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","dd779bd5":"class_names = train_ds.class_names\nprint(class_names)","8e5908aa":"plt.figure(figsize=(10, 10))\nfor images, labels in val_ds.take(1):\n  for i in range(1):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")\n   ","b8dab7d8":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","ece9b0e8":"num_classes = 16\nimg_channels = 3\n\nmodel = Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu',input_shape=(img_height, img_width, img_channels)),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes),\n  #keras.layers.Dense(num_classes, activation='softmax')\n])","6a49d326":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","6942b116":"model.summary()","9b82b8b6":"epochs = 5\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","e4fe9806":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n","a0adde0d":"def plot_confusion_matrix(cm, class_names):\n  \"\"\"\n  Returns a matplotlib figure containing the plotted confusion matrix.\n\n  Args:\n    cm (array, shape = [n, n]): a confusion matrix of integer classes\n    class_names (array, shape = [n]): String names of the integer classes\n  \"\"\"\n  figure = plt.figure(figsize=(8, 8))\n  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n  plt.title(\"Confusion matrix\")\n  plt.colorbar()\n  tick_marks = np.arange(len(class_names))\n  plt.xticks(tick_marks, class_names, rotation=45)\n  plt.yticks(tick_marks, class_names)\n\n  # Compute the labels from the normalized confusion matrix.\n  labels = np.around(cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis], decimals=2)\n\n  # Use white text if squares are dark; otherwise black.\n  threshold = cm.max() \/ 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    color = \"white\" if cm[i, j] > threshold else \"black\"\n    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  return figure\n\ny_pred = model.predict(val_ds)\ny_pred = tf.nn.softmax(y_pred)\npredicted_categories = tf.argmax(y_pred, axis=1)\ntrue_categories = tf.concat([y for x, y in val_ds], axis=0)\ncm = confusion_matrix(predicted_categories, true_categories)\nfigure = plot_confusion_matrix(cm, class_names)","5172ca28":"# test_image_path = \"\/content\/\"\n# test_image = PIL.Image.open(test_image_path)\n\n# img = keras.preprocessing.image.load_img(\n#     test_image_path, target_size=(img_height, img_width)\n# )\n# img_array = keras.preprocessing.image.img_to_array(img)\n# img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n# predictions = model.predict(img_array)\n# score = tf.nn.softmax(predictions[0])\n\n# print(\n#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n#     .format(class_names[np.argmax(score)], 100 * np.max(score))\n# )","8ee5630d":"!pip install tensorflowjs[wizard]","27640d44":"!tensorflowjs_converter --input_format=keras \/kaggle\/working\/CNN-16-cats.h5 \/kaggle\/working\/CNN-16-cats","5100b4e2":"# Visualize training results","237e985b":"# Building the Model","274dcef9":"**> Ignore this confusion matrix its due to absence of logits**","8b90b89e":"# Read the dataset","d4d3760a":"## Confusion Matrix","bb7e06e3":"# Convert model to Web suitable format","458ff22f":"# Check the split dataset","06818c50":"# Split data into train test","37be9e32":"# Basic Imports","56339576":"# Predict on new data","afd40885":"# Check some images"}}