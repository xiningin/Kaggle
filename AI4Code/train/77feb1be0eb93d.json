{"cell_type":{"a3d2f7cc":"code","4c3ff45d":"code","76cf3573":"code","acdbf3f0":"code","f72850f4":"code","45998d63":"code","7c27ebee":"code","ac99fcb7":"code","9afb89af":"code","a37887f5":"code","8b769818":"code","55584103":"code","00af5a11":"code","4ad942b0":"code","13620ba0":"code","23326ac7":"code","bba909e4":"code","0624beb4":"code","5eb28b3d":"code","a0d203ce":"code","b4eef7cd":"code","bcc1cbaf":"code","80e61d6e":"code","ea26f9af":"code","8f1deb91":"code","30ff1ecd":"code","5e95d2b5":"code","c40e32c8":"markdown","32115bc3":"markdown","04515fe0":"markdown","d0ed8af4":"markdown","a7ac7fc7":"markdown","8a6dfea4":"markdown","f98a1160":"markdown","7683e324":"markdown","2632c0e2":"markdown","005c438f":"markdown","464713f3":"markdown","5594b330":"markdown","edc9cbdd":"markdown"},"source":{"a3d2f7cc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc,os,sys\n\nsns.set_style('darkgrid')\npd.options.display.float_format = '{:,.3f}'.format\n\nprint(os.listdir(\"..\/input\"))","4c3ff45d":"%%time\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint(train.shape, test.shape)","76cf3573":"for c in train.columns:\n    if c not in test.columns: print(c)","acdbf3f0":"train.head()","f72850f4":"null_cnt = train.isnull().sum().sort_values()\nprint('null count:', null_cnt[null_cnt > 0])","45998d63":"train['target'].value_counts().to_frame().plot.bar()","7c27ebee":"_='''\n'''\nfrom sklearn.datasets import load_boston\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\n\nX = train.drop(['id','target'], axis=1)\ny = train['target']\ntr_ids = train['id']\nte_ids = test['id']\n\nrfc = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_depth=5, random_state=42)\nselector = RFE(rfc, n_features_to_select=200)\nselector.fit(X, y)\n\nselected = train.drop(['id','target'], axis=1).columns[selector.get_support()]\ntrain = train[selected]\ntrain['id'] = tr_ids\ntrain['target'] = y\ntest = test[selected]\ntest['id'] = te_ids","ac99fcb7":"all_data = train.append(test, sort=False).reset_index(drop=True)\ndel train, test\ngc.collect()\n\nall_data.head()","9afb89af":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","a37887f5":"corr_matrix = all_data.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.95)]\ndel upper\n\ndrop_column = all_data.columns[to_drop]\nprint('drop columns:', drop_column)\n#all_data.drop(drop_column, axis=1, inplace=True)","8b769818":"cols = [col for col in all_data.columns if col not in ['id','target']]\nfor i, t in all_data.loc[:, cols].dtypes.iteritems():\n    if t == object:\n        print(i)\n        all_data[i] = pd.factorize(all_data[i])[0]","55584103":"from sklearn import preprocessing\n\nnumcols = all_data.drop(['id','target'],axis=1).select_dtypes(include='number').columns.values\n#scaler = preprocessing.StandardScaler()\nscaler = preprocessing.RobustScaler()\nall_data.loc[:,numcols] = scaler.fit_transform(all_data[numcols])","00af5a11":"from sklearn.decomposition import PCA\n\npca = PCA()\npca.fit(all_data[numcols])\nev_ratio = pca.explained_variance_ratio_\nev_ratio = np.hstack([0,ev_ratio.cumsum()])\n\nplt.xlabel('components')\nplt.plot(ev_ratio)\nplt.show()","4ad942b0":"X_train = all_data[all_data['target'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['target'].isnull()].drop(['target'], axis=1).reset_index(drop=True)\ndel all_data\ngc.collect()\n\n# drop ID_code\nX_train.drop(['id'], axis=1, inplace=True)\nX_test_ID = X_test.pop('id')\n\nY_train = X_train.pop('target')\n\nprint(X_train.shape, X_test.shape)","13620ba0":"_='''\nfrom imblearn.over_sampling import SMOTE,ADASYN\n\n#sm = SMOTE(random_state=42)\n#sm = SMOTE(kind='svm',random_state=42)\n#sm = SMOTE(kind='borderline1',random_state=42)\nsm = ADASYN(random_state=42)\nX_train, Y_train = sm.fit_sample(X_train, Y_train)\nX_train = pd.DataFrame(X_train, columns=X_test.columns)\nprint(X_train.shape)\n'''","23326ac7":"from sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=2, random_state=42)\nkm.fit(X_train, Y_train)\n\nX_train_km = km.predict(X_train)\nX_test_km = km.predict(X_test)\n\nkm_data = pd.DataFrame({'KM':X_train_km, 'target':Y_train})\nsns.countplot(x='KM', hue='target', palette='Set1', data=km_data)\nplt.title('KMeans visualization')\nplt.show()\n\nprint(pd.Series(X_test_km).value_counts())","bba909e4":"X_train = pd.concat([X_train, pd.get_dummies(X_train_km, prefix='_km')], axis=1)\nX_test = pd.concat([X_test, pd.get_dummies(X_test_km, prefix='_km')], axis=1)","0624beb4":"_='''\nfrom sklearn.mixture import GaussianMixture\n\ngm = GaussianMixture(n_components=2, covariance_type='tied', random_state=42)\ngm.fit(X_train, Y_train)\n\nX_train_gm = gm.predict(X_train)\nX_test_gm = gm.predict(X_test)\n\ngm_data = pd.DataFrame({'GM':X_train_gm, 'target':Y_train})\nsns.countplot(x='GM', hue='target', palette='Set1', data=gm_data)\nplt.title('GaussianMixture visualization')\nplt.show()\n\nprint(pd.Series(X_test_gm).value_counts())\n'''","5eb28b3d":"#X_train = pd.concat([X_train, pd.get_dummies(X_train_gm, prefix='_gm')], axis=1)\n#X_test = pd.concat([X_test, pd.get_dummies(X_test_gm, prefix='_gm')], axis=1)","a0d203ce":"from sklearn.neighbors import KNeighborsClassifier\n\n_='''\nfor k in range(2, 10):\n    knc = KNeighborsClassifier(n_neighbors=k)\n    knc.fit(X_train, Y_train)\n    score = knc.score(X_train, Y_train)\n    print(\"[%d] score: {:.2f}\".format(score) % k)\n\nknc = KNeighborsClassifier(n_neighbors=5)\nknc.fit(X_train, Y_train)\nX_train_knc = knc.predict(X_train)\nX_test_knc = knc.predict(X_test)\nknc_data = pd.DataFrame({'KNC':X_train_knc, 'target':Y_train})\nsns.countplot(x='KNC', hue='target', palette='Set1', data=knc_data)\nplt.title('KNeighborsClassifier visualization')\n'''","b4eef7cd":"#X_train['_knc'] = knc.predict_proba(X_train)[:,1]\n#X_test['_knc'] = knc.predict_proba(X_test)[:,1]","bcc1cbaf":"from sklearn.linear_model import LogisticRegression, Lasso\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFE, RFECV","80e61d6e":"splits = 10\nfolds = RepeatedStratifiedKFold(n_splits=splits, n_repeats=20, random_state=42)\noof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nfor fold_, (trn_, val_) in enumerate(folds.split(X_train, Y_train)):\n    trn_x, trn_y = X_train.iloc[trn_], Y_train[trn_]\n    val_x, val_y = X_train.iloc[val_], Y_train[val_]\n\n    # add noise\n    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n\n    '''\n    clf = LogisticRegression(C=1, max_iter=3000, class_weight='balanced', \n            penalty='l1', solver='liblinear', random_state=42)\n    model = RFECV(clf, step=1, cv=(splits - 1))\n    model.fit(trn_x, trn_y)\n    oof_preds[val_] = model.predict_proba(val_x)[:,1]\n    sub_preds += model.predict_proba(X_test)[:,1] \/ splits \/ 20 #folds.n_splits\n    '''\n    clf = Lasso(alpha=0.03, tol=0.01, selection='random', random_state=42)\n    model = RFECV(clf, step=1, cv=(splits - 1))\n    model.fit(trn_x, trn_y)\n    oof_preds[val_] = model.predict(val_x).clip(0, 1)\n    sub_preds += model.predict(X_test).clip(0, 1) \/ splits \/ 20 #folds.n_splits\n    #print('features:%d' % model.n_features_)","ea26f9af":"from sklearn import metrics\n\nfpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","8f1deb91":"submission = pd.DataFrame({\n    'id': X_test_ID,\n    'target': sub_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","30ff1ecd":"print(submission['target'].sum() \/ len(submission))\nsubmission['target'].hist(bins=25, alpha=0.6)","5e95d2b5":"submission.head()","c40e32c8":"# Predict","32115bc3":"# Submit","04515fe0":"# Load data","d0ed8af4":"# Prepare","a7ac7fc7":"### GaussianMixture","8a6dfea4":"## scaling","f98a1160":"### KNeighborsClassifier","7683e324":"# Data analysis","2632c0e2":"### over sampling","005c438f":"### KMeans","464713f3":"## PCA","5594b330":"# Feature engineering","edc9cbdd":"## feature selection"}}