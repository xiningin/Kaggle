{"cell_type":{"3b63f033":"code","276e049e":"code","d067b18d":"code","3009ecd3":"code","1fefd30c":"code","e4057fbd":"code","5e73dc78":"code","74bb901d":"code","a255d902":"code","42fd8486":"code","2824fc50":"code","bbfd14f8":"code","54a09bb9":"code","1f44d488":"code","b51c9dfd":"code","76929afe":"code","9f8fe351":"code","0c7facd1":"code","b5f9865f":"code","c2be2144":"code","29935b6b":"code","cccea113":"code","cf0433a7":"code","0f3943b9":"code","00f8f5f2":"code","1ac7b047":"code","53656ea8":"code","bc94f588":"code","69268872":"code","720fdc25":"code","acac82f4":"code","04d9b77e":"code","d64d438b":"code","bc4ec8ff":"code","8dd51108":"code","d9dd4a54":"code","23542ab8":"code","2e83643b":"code","58d6f529":"code","a1b8e778":"code","7283cf0a":"code","1ad576b8":"markdown","313d007a":"markdown","818e219a":"markdown","74058805":"markdown","63b478cd":"markdown","a3fdb284":"markdown","e9f116fb":"markdown","f79ab42a":"markdown","c9450d8e":"markdown","3e70d5d2":"markdown"},"source":{"3b63f033":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","276e049e":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","d067b18d":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","3009ecd3":"# Rate of women survived\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nrate_women","1fefd30c":"# Rate of men survived\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nrate_men","e4057fbd":"X = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']","5e73dc78":"X","74bb901d":"features = [\"Sex\"]\nX_dummies = pd.get_dummies(X[features])\nX_dummies","a255d902":"X_dummied = pd.concat([X, X_dummies], axis=1)\nX_dummied","42fd8486":"X_processed = X_dummied.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked', 'Sex'], axis=1)\nX_processed","2824fc50":"X_processed['Sex_female'].mean()","bbfd14f8":"values = {\n    'Pclass': X_processed['Pclass'].mean(),\n    'Age': X_processed['Age'].mean(),\n    'SibSp': X_processed['SibSp'].mean(),\n    'Parch': X_processed['Parch'].mean(),\n    'Parch': X_processed['Fare'].mean(),\n    'Sex_female': X_processed['Sex_female'].mean(),\n    'Sex_male': X_processed['Sex_male'].mean(),\n}\n\nX_processed_final = X_processed.fillna(value=values)\nX_processed_final","54a09bb9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_processed_final, y, test_size=0.2, random_state=33)","1f44d488":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\npred = tree.predict(X_test)","b51c9dfd":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","76929afe":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nforest.fit(X_train, y_train)\npred = forest.predict(X_test)","9f8fe351":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","0c7facd1":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)","b5f9865f":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","c2be2144":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nbagging = BaggingClassifier(\n    KNeighborsClassifier()\n)\nbagging.fit(X_train, y_train)\npred = bagging.predict(X_test)","29935b6b":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","cccea113":"from sklearn.ensemble import AdaBoostClassifier\nboosting = AdaBoostClassifier(n_estimators=100)\n# Train\nboosting.fit(X_train, y_train)\npred = boosting.predict(X_test)","cf0433a7":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","0f3943b9":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nbagging = BaggingClassifier(\n    KNeighborsClassifier(n_neighbors=1),\n    max_samples=0.5,\n    max_features=0.5)\n\nfrom sklearn.ensemble import AdaBoostClassifier\nboosting = AdaBoostClassifier(n_estimators=100)\n\nfrom sklearn.ensemble import VotingClassifier\nvoting = VotingClassifier(\n    estimators=[('bagging', bagging),\n               ('boosting', boosting)])\n# Train\nvoting.fit(X_train, y_train)\npred = voting.predict(X_test)","00f8f5f2":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","1ac7b047":"X_train","53656ea8":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_test)","bc94f588":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","69268872":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train, y_train)\npred = svm.predict(X_test)","720fdc25":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, pred)","acac82f4":"from xgboost import XGBClassifier\nxgbc = XGBClassifier()\nxgbc.fit(X_train, y_train)","04d9b77e":"xgbc.score(X_test, y_test)","d64d438b":"test_data","bc4ec8ff":"features = [\"Sex\"]\nX_dummies_test = pd.get_dummies(test_data[features])\nX_dummies_test","8dd51108":"X_dummied_test = pd.concat([test_data, X_dummies_test], axis=1)\nX_dummied_test","d9dd4a54":"X_processed_test = X_dummied_test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked', 'Sex'], axis=1)\nX_processed_test","23542ab8":"values = {\n    'Pclass': X_processed_test['Pclass'].mean(),\n    'Age': X_processed_test['Age'].mean(),\n    'SibSp': X_processed_test['SibSp'].mean(),\n    'Parch': X_processed_test['Parch'].mean(),\n    'Fare': X_processed_test['Fare'].mean(),\n    'Sex_female': X_processed_test['Sex_female'].mean(),\n    'Sex_male': X_processed_test['Sex_male'].mean(),\n}\n\nX_processed_final_test = X_processed_test.fillna(value=values)","2e83643b":"X_processed_final_test","58d6f529":"predictions = tree.predict(X_processed_final_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_tree.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a1b8e778":"predictions = forest.predict(X_processed_final_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_forest.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7283cf0a":"predictions = xgbc.predict(X_processed_final_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_xgbc.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1ad576b8":"### Decision Tree","313d007a":"### Bagging + KNN","818e219a":"### Make prediction","74058805":"### SVM","63b478cd":"### XGBoost","a3fdb284":"### RandomForest","e9f116fb":"### Voting","f79ab42a":"### Boosting","c9450d8e":"### Logistic Regression","3e70d5d2":"### KNN"}}