{"cell_type":{"a31d10be":"code","51ddf977":"code","d33fa759":"code","56a3d828":"code","ac16d59a":"code","6b35701a":"code","d6bac62e":"code","788356aa":"code","5b63239f":"code","f1417b45":"code","2d44eb2d":"code","79726a9f":"code","e60c34cb":"code","048e7d62":"code","3c933967":"code","4117acf4":"code","419b52ae":"code","c60aaaf7":"code","e0e45e06":"code","b0aafda5":"code","42e52c31":"code","9d48a5e3":"code","3a5592a3":"code","9a96768e":"code","a453be6a":"code","5be60721":"code","ed58c04e":"code","32a7f902":"code","57b6b1e9":"code","27723fa5":"code","94774b2e":"code","f053ed07":"code","49f59777":"code","66c677f4":"code","65489cfd":"code","17f03043":"code","a95f1764":"code","ee2f95dc":"code","ab77b205":"code","bf307771":"code","040e7459":"code","7ea00732":"code","27577e51":"code","fc1d197e":"code","52efb283":"code","d416109d":"code","2d30a5f9":"code","56752eba":"code","04fbc503":"code","4815871a":"code","c1fb69e2":"code","037cb6a8":"code","6b78d808":"code","061a3c5f":"code","80c11ac2":"markdown","b1c524ae":"markdown","dc3fdec6":"markdown","6ecb9688":"markdown","89bd47a0":"markdown","7310543d":"markdown","130cd3f2":"markdown","6d73fb31":"markdown","43eb8cd4":"markdown","7089a646":"markdown","87e27877":"markdown","ce971bae":"markdown","3b9543c7":"markdown","c836b3b8":"markdown","f1dbe87b":"markdown","1592ae45":"markdown","9d93012c":"markdown","3b268a0a":"markdown","0157e1a3":"markdown","82db29df":"markdown","b54f1592":"markdown","6489d9e1":"markdown","6d03f247":"markdown","dd4a9d28":"markdown","bdd7fb2e":"markdown","a312aaca":"markdown","9a2d65eb":"markdown","ef993f64":"markdown","2ed2856d":"markdown","5c26dd90":"markdown","446ca330":"markdown","f23446ce":"markdown","5cb15b0a":"markdown","a3686705":"markdown","095acb01":"markdown","f9cc7270":"markdown","362c3393":"markdown","7f811429":"markdown","836c8a93":"markdown","d2aa89a2":"markdown","d7903f99":"markdown","012a35f0":"markdown","270428fb":"markdown","20c4a85e":"markdown","ad0bb83c":"markdown","09a24c9d":"markdown","adcd42da":"markdown","43178723":"markdown","6a130ae3":"markdown","3a801730":"markdown","8ccab787":"markdown","a30b8b6b":"markdown","ae6604f7":"markdown","08927ad7":"markdown","82efa0cb":"markdown","0afe36f1":"markdown","20f173c4":"markdown","f9579900":"markdown","5e5c6190":"markdown","bc05842a":"markdown","fcf43f48":"markdown","d8e6e81f":"markdown","a6db95d5":"markdown","b79046b0":"markdown","9b86b74a":"markdown","f7ccf1b7":"markdown","a76d01dc":"markdown","896d525e":"markdown","38abcac5":"markdown","f3bf502f":"markdown","184d35da":"markdown"},"source":{"a31d10be":"!pip install pydotplus","51ddf977":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# linear algebra\nimport numpy as np \n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd \n\n#Visualization libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\n#decision tree visualization\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n\n#Data split\nfrom sklearn.model_selection import train_test_split\n\n#ML Algorithms \nfrom sklearn import tree\nimport pydotplus\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\n\n\n\n#Model evaluation metrics\nfrom sklearn import metrics\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d33fa759":"df = pd.read_csv('\/kaggle\/input\/drug-classification\/drug200.csv')","56a3d828":"df.head()","ac16d59a":"df.shape","6b35701a":"df.describe(include = 'all')","d6bac62e":"df.info()","788356aa":"sns.catplot('Drug', 'Age', data = df)","5b63239f":"plt.figure(figsize = (8,6))\nax = sns.boxplot('Sex', 'Age', data = df).set(ylim = (0, 80))","f1417b45":"df.Sex.value_counts()","2d44eb2d":"sex_drug = df.groupby('Sex').Drug.value_counts()\nsex_drug","79726a9f":"sex_drug.unstack(level=0).plot(kind='bar', subplots=False)","e60c34cb":"df.BP.value_counts()","048e7d62":"tab = pd.crosstab(df['BP'], df['Drug'])\nprint (tab)\n\ntab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False)\nplt.xlabel('BP')\nplt.ylabel('Percentage')","3c933967":"df.Cholesterol.value_counts()","4117acf4":"tab = pd.crosstab(df['Cholesterol'], df['Drug'])\n\ntab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False)\nplt.xlabel('Cholesterol')\nplt.ylabel('Percentage')","419b52ae":"sns.catplot('Drug', 'Na_to_K', data=df)","c60aaaf7":"for col in df:\n    print(col)\n    print(df[col].unique())\n    print()","e0e45e06":"df[\"Sex\"] = df[\"Sex\"].map({\"M\": 0, \"F\":1})\ndf[\"BP\"] = df[\"BP\"].map({\"HIGH\" : 3, \"NORMAL\" : 2, \"LOW\": 1})\ndf[\"Cholesterol\"] = df[\"Cholesterol\"].map({\"HIGH\": 1, \"NORMAL\" : 0})\ndf[\"Drug\"] = df[\"Drug\"].map({\"DrugY\": 0, \"drugC\": 1, \"drugX\": 2, \"drugA\":3, \"drugB\":4})","b0aafda5":"df.head()","42e52c31":"df.dtypes","9d48a5e3":"sns.boxplot(x=df['Age'])","3a5592a3":"sns.boxplot(x=df['Na_to_K'])","9a96768e":"df.drop(df[df.Na_to_K > 30].index, inplace=True)","a453be6a":"sns.boxplot(x=df['Na_to_K'])","5be60721":"plt.figure(figsize=(15,6))\nsns.heatmap(df.corr(), vmax=0.6, square=True, annot=True)","ed58c04e":"df.drop('Sex', axis=1, inplace=True)","32a7f902":"df.head()","57b6b1e9":"values=df.values\nX, y = values[:, :-1], values[:, -1]\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 2)","27723fa5":"print(\"X_train shape:\",X_train.shape)\nprint(\"X_test shape:\",X_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","94774b2e":"rfc = RandomForestClassifier(n_estimators = 9, criterion = 'entropy', random_state=22)\n\nrfc.fit(X_train,y_train)","f053ed07":"rf_pred = rfc.predict(X_test)","49f59777":"print(\"Accuracy score : \", metrics.accuracy_score(y_test, rf_pred))\n\nprint(\"F1 score: \", metrics.f1_score(y_test, rf_pred, average='weighted') )\n\nprint(\"Jaccard score: \", metrics.jaccard_score(y_test, rf_pred, average='weighted'))\n\nprint(\"recall score: \", metrics.recall_score(y_test, rf_pred, average='weighted'))\n\nprint(\"precision score: \", metrics.precision_score(y_test, rf_pred, average='weighted'))","66c677f4":"rfc_score = {\n            'accuracy': metrics.accuracy_score(y_test, rf_pred),\n            'f1': metrics.f1_score(y_test, rf_pred, average='weighted'),\n            'jaccard': metrics.jaccard_score(y_test, rf_pred, average='weighted'),\n            'recall': metrics.recall_score(y_test, rf_pred, average='weighted'),\n            'precision': metrics.precision_score(y_test, rf_pred, average='weighted')\n        }","65489cfd":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)","17f03043":"dt_pred = dtc.predict(X_test)","a95f1764":"print(\"Accuracy score : \", metrics.accuracy_score(y_test, dt_pred))\n\nprint(\"F1 score: \", metrics.f1_score(y_test, dt_pred, average='weighted') )\n\nprint(\"Jaccard score: \", metrics.jaccard_score(y_test, dt_pred, average='weighted'))\n\nprint(\"recall score: \", metrics.recall_score(y_test, dt_pred, average='weighted'))\n\nprint(\"precision score: \", metrics.precision_score(y_test, dt_pred, average='weighted'))","ee2f95dc":"dt_score = {\n            'accuracy': metrics.accuracy_score(y_test, dt_pred),\n            'f1': metrics.f1_score(y_test, dt_pred, average='weighted'),\n            'jaccard': metrics.jaccard_score(y_test, dt_pred, average='weighted'),\n            'recall': metrics.recall_score(y_test, dt_pred, average='weighted'),\n            'precision': metrics.precision_score(y_test, dt_pred, average='weighted')\n        }","ab77b205":"featureNames = ['Age', 'BP', 'Cholesterol','Na_to_K']","bf307771":"dot_data = tree.export_graphviz(dtc,\n                                feature_names=featureNames,\n                                out_file=None,\n                                special_characters=True,\n                                filled=True,\n                                rounded=True)\ngraph = pydotplus.graph_from_dot_data(dot_data)\n\nfilename = \"drugTree.png\"\ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(50,100))\nplt.imshow(img,interpolation = 'nearest')\nplt.show()","040e7459":"Ks = 15\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n\nmean_acc","7ea00732":"plt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","27577e51":"k = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k)\nneigh.fit(X_train,y_train)","fc1d197e":"predKNN = neigh.predict(X_test)","52efb283":"print(\"Accuracy score : \", metrics.accuracy_score(y_test, predKNN))\n\nprint(\"F1 score: \", metrics.f1_score(y_test, predKNN, average='weighted') )\n\nprint(\"Jaccard score: \", metrics.jaccard_score(y_test, predKNN, average='weighted'))\n\nprint(\"recall score: \", metrics.recall_score(y_test, predKNN, average='weighted'))\n\nprint(\"precision score: \", metrics.precision_score(y_test, predKNN, average='weighted'))","d416109d":"knn_score = {\n            'accuracy': metrics.accuracy_score(y_test, predKNN),\n            'f1': metrics.f1_score(y_test, predKNN, average='weighted'),\n            'jaccard': metrics.jaccard_score(y_test, predKNN, average='weighted'),\n            'recall': metrics.recall_score(y_test, predKNN, average='weighted'),\n            'precision': metrics.precision_score(y_test, predKNN, average='weighted')\n        }","2d30a5f9":"svc = svm.SVC(kernel='rbf', random_state = 22)\nsvc.fit(X_train, y_train)","56752eba":"predSVC = svc.predict(X_test)","04fbc503":"print(\"Accuracy score : \", metrics.accuracy_score(y_test, predSVC))\n\nprint(\"F1 score: \", metrics.f1_score(y_test, predSVC, average='weighted') )\n\nprint(\"Jaccard score: \", metrics.jaccard_score(y_test, predSVC, average='weighted'))\n\nprint(\"recall score: \", metrics.recall_score(y_test, predSVC, average='weighted'))\n\nprint(\"precision score: \", metrics.precision_score(y_test, predSVC, average='weighted', zero_division=1))","4815871a":"svm_score = {\n            'accuracy': metrics.accuracy_score(y_test, predSVC),\n            'f1': metrics.f1_score(y_test, predSVC, average='weighted'),\n            'jaccard': metrics.jaccard_score(y_test, predSVC, average='weighted'),\n            'recall': metrics.recall_score(y_test, predSVC, average='weighted'),\n            'precision': metrics.precision_score(y_test, predSVC, average='weighted', zero_division=1)\n        }","c1fb69e2":"print(pd.DataFrame.from_dict(rfc_score, orient = \"index\",columns=[\"Score\"]))","037cb6a8":"print(pd.DataFrame.from_dict(dt_score, orient = \"index\",columns=[\"Score\"]))","6b78d808":"print(pd.DataFrame.from_dict(knn_score, orient = \"index\",columns=[\"Score\"]))","061a3c5f":"print(pd.DataFrame.from_dict(svm_score, orient = \"index\",columns=[\"Score\"]))","80c11ac2":"### Evaluation","b1c524ae":"### Check outliers for column Na_to_K","dc3fdec6":"KNN and SVM algorithms appears to be much worse compared to the rest. Random forest and decision tree scores are the same and since random forest complexity time is higher than decision tree that would be my choice for this data.","6ecb9688":"### <a id='93'> KNearest Neighboor <\/a>","89bd47a0":"There is few data points looking like outliers with values above 30, we can remove these rows.","7310543d":"### Decision tree score","130cd3f2":"Drop of column Sex, since in EDA we saw it didin't had any affect on target feature.","6d73fb31":"## Summary\n\n Age, Na_to_k, BP and Cholesterol have correlation with Drug type","43eb8cd4":"Distribution between genders of patients is almos equivalent.","7089a646":"* DrugX is used for BP low and normal.\n* DrugC is used only for BP low.\n* drugB and drugA are used only for BP high.\n* DrugY is used for every BP level.\n\nAbove barplot clearly show that, there is a correlation between BP level and type of drug.","87e27877":"# <a id='7'>Feature Engineering<a>","ce971bae":"Check data type of each column","3b9543c7":"### <a id='44'>Info about dataset<\/a>","c836b3b8":"### SVM score","f1dbe87b":"# <a id='9'> ML Algorithms <\/a>","1592ae45":"### <a id='91'> Random Forest <\/a>","9d93012c":"Check boxplot again","3b268a0a":"### Modeling","0157e1a3":"### <a id='94'> SVM <\/a>","82db29df":"### <a id='41'>Header of dataset<\/a>","b54f1592":"* For na_to_k higher than 15, only drugY is used.\n* Rest drugs are used in 5 to 15 Na_to_k value range.","6489d9e1":"# <a id='10'> Conclusion <\/a>","6d03f247":"### Evaluation","dd4a9d28":"### 2) Sex with Drug type","bdd7fb2e":"### <a id='51'> Correct format of columns <a>","a312aaca":"### <a id='43'>Describe of dataset<\/a>","9a2d65eb":"### Evaluation","ef993f64":"Now our dataset contains only numeric dTypes, so we can use it with ML algorithms","2ed2856d":"1. Firstly i'm gonna check distribution of gender and  age of patients","5c26dd90":"### Prediction","446ca330":"* BP is positively correlated with Drug type.\n* Na_to_K is highly negatively correlated with drug type.","f23446ce":"### 1) Age with Drug type","5cb15b0a":"### 5) Na_to_K with Drug type","a3686705":"### KNN score","095acb01":"4 is our number, i'm not using k=1 due to overfitting issues.","f9cc7270":"# <a id='2'>Include Libraries<\/a> ","362c3393":"### <a id='42'>Shape of dataset<\/a>","7f811429":"## Summary","836c8a93":"Distribution of patients age compared to gender is pretty simillar.","d2aa89a2":"Check head of dataframe again","d7903f99":"### Modeling","012a35f0":"**Info function provide us with confirmation about which columns are object Dtype and the fact that all entries are filled.**|","270428fb":"# <a id='5'>Data Cleaning<a>","20c4a85e":"### <a id='54'>Correlation heatmap<a>","ad0bb83c":"# <a id='3'>Import data<\/a>","09a24c9d":"Since BP and Cholesterol has been converted from Categorical type, there is no need to check outliers for them.","adcd42da":"### Modeling","43178723":"### <a id='45'>Finding relations between features and target feature<\/a>","6a130ae3":"Let's visualise it","3a801730":"# <a id='4'>Exploratory data analysis<\/a>","8ccab787":"# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Import Libraries<\/a>  \n- <a href='#3'>Import Data<\/a>   \n- <a href='#4'>Exploratory Data Analysis<\/a>   \n - <a href='#41'>Data header<\/a>   \n - <a href='#42'>Data shape<\/a>   \n - <a href='#43'>Describing dataset<\/a>   \n - <a href='#44'>Dataset info<\/a>   \n - <a href='#45'>Finding relations between features and target feature<\/a>    \n- <a href='#5'>Data Cleaning<\/a>   \n - <a href='#51'>Correct format of columns<\/a>   \n - <a href='#52'>Handle Outliers<\/a>   \n - <a href='#53'>Handle missing values<\/a>\n - <a href='#54'>Correlation heatmap<\/a> \n- <a href='#7'>Feature Engineering<\/a> \n- <a href='#8'>Data split<\/a>\n- <a href='#9'>Modeling and Evaluation<\/a>\n - <a href='#91'>Random Forest<\/a>\n - <a href='#92'>Decision tree<\/a>\n - <a href='#93'>KNN<\/a>\n - <a href='#94'>SVM<\/a>\n- <a href='#10'>Conclusion<\/a>","a30b8b6b":"### Random forest score","ae6604f7":"### <a id='53'> Handle Outliers <a>","08927ad7":"# <a id='1'>Introduction<\/a> \n\n### Data set source:\nhttps:\/\/www.kaggle.com\/prathamtripathi\/drug-classification\n\n### Business problem: \nClassification problem where we have to predict which of drug will fit requirements of a patient.\n\n### Target feature:\n* Drug type\n\n### The feature sets are:\n* Age\n* Sex\n* Blood Pressure Level (BP)\n* Cholesterol Level\n* sodium to Potassium Ratio (na_to_k)","82efa0cb":"* Sex column has 2 unique values, male and female proportions are almost equivalent.\n* BP most frequent value is HIGH, 77 out of 200 entries with 3 unique values.\n* Cholesterol has 2 unique values, both of them are almost equivalent.\n* Drug most frequent value is DrugY, 91 of 200 entries with 5 unique values.\n* Distribution of Na_to_K seems a bit odd, 38 as max might be outlier.\n* Dataset does not contain any missing values since count for each column is 200.","0afe36f1":"### Visualisation of decision tree","20f173c4":"Gender of patients is not correlated with their drug type.","f9579900":"### <a id='92'> Decision Tree <\/a>","5e5c6190":"### Prediction","bc05842a":"**Dataframe has 200 entries and 6 columns**","fcf43f48":"### Prediction","d8e6e81f":"### Modeling","a6db95d5":"### Check outliers for column Age","b79046b0":"* DrugY is most used for all ages.\n* DrugC frequency is low and is used for all ages.\n* DrugX is second highest frequency and is used for all ages.\n* Drug A appears only for people age 50 or lower.\n* Drug B appears only for people age 50 or higher.","9b86b74a":"Search for best K","f7ccf1b7":"### Evaluation","a76d01dc":"# <a id='8'>Data split<a>","896d525e":"### 3) BP with Drug type","38abcac5":"### 4) Cholesterol with Drug type","f3bf502f":"### Prediction","184d35da":"All drugs are used in both levels of Cholesterol except **DrugC** which is only used at High level of Cholesterol."}}