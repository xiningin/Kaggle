{"cell_type":{"28410dc6":"code","63b3dfb5":"code","126ef5ef":"code","cc89ce2f":"code","bc1e56c5":"code","574bb04f":"code","8b762b60":"code","e2465706":"code","dc7b3402":"code","02e86639":"code","2fcb9359":"code","fd5fc8a4":"code","32618033":"code","b3ea957e":"code","dc88f529":"code","9c8e3b44":"markdown","4ae09729":"markdown","01919aa0":"markdown","b0a2d604":"markdown","9f96a1fe":"markdown","073c5c10":"markdown","c9c270cf":"markdown","f247fa51":"markdown","93f19914":"markdown","f88d1eb9":"markdown","395edb32":"markdown","3a168520":"markdown","b7911504":"markdown","f0342561":"markdown","c3dee7a3":"markdown"},"source":{"28410dc6":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns \nsns.set(style = 'whitegrid',palette = 'Set3',context = 'talk')\n        \n        \nimport warnings\nwarnings.filterwarnings('ignore')\n","63b3dfb5":"#load data\ndf = pd.read_csv('..\/input\/application_train.csv')\n#POS_CASH_balance = pd.read_csv('..\/input\/POS_CASH_balance.csv')\n#bureau_balance = pd.read_csv('..\/input\/bureau_balance.csv')\n#previous_application = pd.read_csv('..\/input\/previous_application.csv')\n#installments_payments = pd.read_csv('..\/input\/installments_payments.csv')\n#credit_card_balance = pd.read_csv('..\/input\/credit_card_balance.csv')\n#bureau = pd.read_csv('..\/input\/bureau.csv')\n#application_test = pd.read_csv('..\/input\/application_test.csv')","126ef5ef":"# check column dtypes\nprint(df.dtypes.value_counts())\n\n# Number of unique classes in each object column\ndf.select_dtypes('object').apply(pd.Series.nunique, axis = 0)\n# they are category columns","cc89ce2f":"# manually number the cat-columns (just in case )\n# of course we could also use (le) Lable Encoding or one-hot encoding \n# we will do this in next kernel : feature engineering\n\ndf['NAME_CONTRACT_TYPE'] = df['NAME_CONTRACT_TYPE'].replace({'Cash loans':0,\n                                                         'Revolving loans':1})\ndf['CODE_GENDER'] = df['CODE_GENDER'].replace({'M':1,'F':0})\ndf['CODE_GENDER'] = df[df['CODE_GENDER'] != 'XNA']  # just 4 rows, and we remove them\ndf['FLAG_OWN_CAR'] = df['FLAG_OWN_CAR'].replace({'Y':1,'N':0})\ndf['FLAG_OWN_REALTY'] = df['FLAG_OWN_REALTY'].replace({'Y':1,'N':0})                                                         \n","bc1e56c5":"# missing value check\ndef mis_check(x):\n    total = x.isnull().sum().sort_values(ascending = False)\n    percentage = (x.isnull().sum()\/x.isnull().count()*100).sort_values(ascending = False)\n    tb = pd.concat([total, percentage], axis=1, keys=['Total', 'Percentage'])\n    \n    display(tb.head(20)) # just show the top 20 rows\n","574bb04f":"mis_check(df)","8b762b60":"tmp = df['NAME_CONTRACT_TYPE'].value_counts()\ntmp1 = df['TARGET'].value_counts()\nplt.subplots(1,2,figsize = (12,6))\nplt.subplots_adjust(left = 0.1,wspace = 0.4)\ncolors = ['lightcoral', 'lightskyblue']\n\nplt.subplot(121)\ntmp.plot.pie(autopct='%1.1f%%', shadow=True, startangle=45,explode = (0.2,0),colors = colors)\nplt.title('Gender Distribution')\nplt.subplot(122)\ntmp1.plot.pie(autopct='%1.1f%%', shadow=True, startangle=45,explode = (0.2,0),colors = colors)\nplt.title('Default Distribution')\n\n","e2465706":"\ncols = ['FLAG_OWN_CAR','FLAG_OWN_REALTY','CNT_CHILDREN']\nplt.figure(2 , figsize = ( 24, 6))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(1 , 3 , n)\n    plt.subplots_adjust(wspace =0.4)\n    sns.countplot(df[c] )\n    plt.title('Countplot of {}'.format(c))\n","dc7b3402":"cols = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']\nplt.figure(4 , figsize = ( 24, 12))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(2 , 2 , n)\n    plt.subplots_adjust(wspace =0.2, hspace =0.4,)\n    sns.boxenplot(df[c] )\n    plt.title('boxplot of {}'.format(c))","02e86639":"cols =['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE']\nplt.figure(4 , figsize = ( 24, 16))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(3 , 2 , n)\n    plt.subplots_adjust(wspace =0.5, hspace =0.4,)\n    sns.countplot(y = df[c], )\n    plt.title('countplot of {}'.format(c))","2fcb9359":"corr = df.corr()['TARGET'].sort_values()\n# Display correlations\nprint('Top 10 strong Positive Correlations:\\n', corr.tail(10))\nprint('\\nTop 10 strong Negative Correlations:\\n', corr.head(10))","fd5fc8a4":"df['AGE'] = round(abs(df['DAYS_BIRTH'])\/365,0)\n\nplt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf['AGE'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightblue')\nplt.title('Distribution of Age')\nplt.subplot(212)\nsns.kdeplot(df.loc[df['TARGET'] == 0, 'AGE'], label = 'Not-Default')\nsns.kdeplot(df.loc[df['TARGET'] == 1, 'AGE'], label = 'Default')\n","32618033":"df['EMPLOYED_YEAR'] = round(abs(df['DAYS_EMPLOYED'])\/365,1)\ndf['EMPLOYED_YEAR'].corr(df['TARGET'])","b3ea957e":"plt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf['EMPLOYED_YEAR'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightcoral')\nplt.subplot(212)\nsns.kdeplot(df.loc[df['TARGET'] == 0, 'EMPLOYED_YEAR'], label = 'Not-Default')\nsns.kdeplot(df.loc[df['TARGET'] == 1, 'EMPLOYED_YEAR'], label = 'Default')","dc88f529":"df0 = df[df['EMPLOYED_YEAR'] < 50]\n\nplt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf0['EMPLOYED_YEAR'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightcoral')\nplt.title('Distribution of working year')\nplt.subplot(212)\nsns.kdeplot(df0.loc[df0['TARGET'] == 0, 'EMPLOYED_YEAR'], label = 'Not-Default')\nsns.kdeplot(df0.loc[df0['TARGET'] == 1, 'EMPLOYED_YEAR'], label = 'Default')\n","9c8e3b44":"**Employed year more than 1000 is total insane, after all it is not easy to stay alive 100 years.**","4ae09729":"**Shortcut:**\n* Users ages are between 20 -70\n* Most of uers' working year is under 10 years\n* Most of the default happens the first couple of working years.\n","01919aa0":"**Shortcut:**\n* Most of AMT_Income_total is under 1 million, let's assume and define outilers,which are more than 1 million;\n* AMT_CREDIT outliers: value more than 2000K;\n* AMT_ANNUITY outliers: value more than 80k;\n* GOODS_PRICE outliers: value more than 2000k;\n","b0a2d604":"**We can see expect 'target' itself, the most strong factor is DAY_BIRTH. **\n\nGenerally young people have more possibility to default,it might due to the less income and stability.\n\n**Except the EXT_SOURCE factors, the most strong negtive factor is DAYS_EMPLOYED**\n","9f96a1fe":"## 1.Split out categorical columns and numerical columns","073c5c10":"## 3.Have a look on our data","c9c270cf":"![](https:\/\/i.redd.it\/22uasph7vxvy.png)","f247fa51":"* [1.Split out categorical columns and numerical columns](#1)\n* [Data Cleaning](#2)\n    * Deal with cat-columns\n    * Dheck missing values\n* [Find the impact factors](#3)\n* [Deep look impact factors](#4)\n* [Deal with outliers]\n","93f19914":"**Shortcut**\n* 90% loans are Revolving loans and the others are cash loans;\n* Most of users are in rules, 8.1% users have problem in repaying loan;\n* 30% loan applications are for car, the others are for realty;\n* Most of users have no kid,only a few have more than 2 kids","f88d1eb9":"## 2. Data Cleaning","395edb32":"## 5.Look Deeper","3a168520":"## 4.Find the impact factors","b7911504":"### Deal with cat-columns","f0342561":"### Check missing value","c3dee7a3":"## Next Chapter: Feature Engineering\n* Imputing missing data\n* Remove outliers\n* Deal with extremely skewed data\n* Find features and create more features\n* Modeling and Predicting\n* Optimise results\n\n"}}