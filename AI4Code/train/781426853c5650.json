{"cell_type":{"422bd8fc":"code","066f7248":"code","15d91c56":"code","126d9377":"code","e31f13cd":"code","2e41aad8":"code","cb41770b":"code","b3efb7c4":"code","32cff8d8":"code","9578b044":"code","251c42c9":"code","2ce7a1c0":"code","696e6d62":"code","fb2c8dbb":"code","78930471":"code","cbda951b":"code","0bbe9550":"code","da129a99":"code","2f1a370a":"code","685a97a9":"code","5c53c9b3":"code","138b483f":"code","98fa99e3":"code","32e3348e":"code","72632fcd":"code","2233804c":"code","79802fc7":"code","c02b52c3":"code","b18f5b41":"code","0662b898":"code","74b09f1a":"code","3f268b91":"code","66c8e239":"code","bd7129a3":"code","94bcce48":"code","13d52ca3":"code","c212c26b":"code","3e3fd2ae":"code","03e0745d":"code","a83638e2":"code","237ceacf":"code","7a2b0a9d":"code","5f6884f5":"code","0d193bcc":"code","353f6fac":"code","feb8ab5b":"code","4eb2a9ee":"code","cc8f2d5b":"code","8336cb05":"code","f73a87cd":"code","ffd161c1":"code","282a93f2":"code","4d999c74":"code","467d5ee8":"code","71dc7f32":"code","0a15e4cd":"code","18d57cc2":"code","95d17115":"code","679709b5":"code","d1a61fb8":"code","af41156b":"code","309e675c":"code","20003e23":"code","1c867c2e":"code","1a8e73fe":"code","259d465f":"code","aecbcaac":"code","12dd8d66":"code","96b58548":"code","d4b71fd4":"code","dc6627d8":"code","efe81165":"code","9f13210d":"code","3b8c6959":"code","f3964b5a":"code","8b643de3":"code","0c22d679":"code","51892e48":"code","cbd4caf0":"code","a4b49c57":"code","8eedba2c":"code","b2fc6bd7":"code","bec9d84c":"code","b787399f":"code","bfe6cfcb":"code","9caa932f":"code","d10c8b54":"code","9c00b618":"code","0e28ca79":"code","44606b85":"code","185aa5f9":"code","5ce8521f":"code","9bf19af5":"code","5e9dd6e5":"code","b5c24b1a":"code","96f70110":"code","48366dca":"code","51f36e08":"markdown","7ba63588":"markdown","9f8b778c":"markdown","17e587d5":"markdown","6f879ef2":"markdown","a3377968":"markdown","f726203d":"markdown","6267c75a":"markdown","7ad74398":"markdown","3927614d":"markdown","77270d39":"markdown","aee539a7":"markdown","54d45f03":"markdown","685a77c7":"markdown","1c5052d8":"markdown","4b713e50":"markdown","9511cab5":"markdown","946be4a2":"markdown","1a9054f5":"markdown","86043fb0":"markdown","d9e1b416":"markdown","a8ce5dab":"markdown","6946ce8f":"markdown","6f64f84a":"markdown","9490240f":"markdown","0e22aa71":"markdown","d4006717":"markdown","f93e469a":"markdown","4a7aaedd":"markdown","1be875c6":"markdown","30e0e81f":"markdown","dcdccb2a":"markdown","16c235bd":"markdown","41562290":"markdown","23b85a49":"markdown","b562c076":"markdown","d3ee6eb5":"markdown","d1d08647":"markdown","1ffcd3ed":"markdown","9eaa4a13":"markdown","db97fb1d":"markdown","743f0ffb":"markdown","e0758d4f":"markdown","15d94c64":"markdown","275248f4":"markdown","47100b1c":"markdown","00ca0253":"markdown","942010f6":"markdown","cb352ea2":"markdown","2c537640":"markdown","f1100b01":"markdown","fda23766":"markdown","2cf70f2a":"markdown","7105e9dc":"markdown","85dc25b6":"markdown","4e73ef5f":"markdown","83cdf52a":"markdown","c782872c":"markdown","c1ab02a0":"markdown","5aa19061":"markdown","13b74dc8":"markdown","aa87304d":"markdown","3d3ff70f":"markdown","dcdb0a2a":"markdown","a40ac7ae":"markdown","e8fdd988":"markdown","7dc720a7":"markdown","9c3c27d5":"markdown","6ec49dcf":"markdown","eefc2dd9":"markdown","81d03a82":"markdown","44a72cf7":"markdown","d2b6651a":"markdown","0142294a":"markdown","c774e1ff":"markdown","26edd4e1":"markdown","f0cd5e48":"markdown","cfa49953":"markdown","41e186fe":"markdown","f730ef5a":"markdown","c456632b":"markdown","df0a7f91":"markdown","3610d2b2":"markdown","7b27a9b3":"markdown","2a87b1fd":"markdown","3e3dbcf0":"markdown","9a05a611":"markdown","70128bbf":"markdown","d24cbc7f":"markdown","c8370b2c":"markdown","b20f0e28":"markdown","12d78785":"markdown","c06c257e":"markdown","07535e43":"markdown","2ab292a1":"markdown","f6629388":"markdown","a473a67f":"markdown","b21b319a":"markdown","1b5b6fc3":"markdown","3de9df8f":"markdown","dd9f38d1":"markdown","ec6df97a":"markdown","54a7cf3d":"markdown","3fa3c4f7":"markdown","5f633da7":"markdown","ae701bda":"markdown","b87328e1":"markdown","61837319":"markdown","a5e0fd43":"markdown","8e09618f":"markdown","2fbafb96":"markdown","b87e4b20":"markdown","35cbb34d":"markdown","1655e9ef":"markdown","f126a733":"markdown","23565fa3":"markdown","2179efcf":"markdown","1c74f058":"markdown","eb1c16a0":"markdown","6c98c0d7":"markdown"},"source":{"422bd8fc":"!pip install python-highcharts pycountry-convert","066f7248":"# standard libs\nimport os\nimport pandas as pd\nimport numpy as np\nimport json\nimport string\nimport pickle\nimport math\nfrom collections import Counter\nfrom collections import defaultdict\nfrom collections.abc import Iterable\nfrom itertools import compress\n\n# Graphic libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom highcharts import Highchart\nimport pydot\nfrom scipy import stats\n#import altair as alt # https:\/\/altair-viz.github.io\/ \n# to install: conda install -c conda-forge altair vega_datasets\n\n# Maps \nimport geopandas as gpd\nimport pycountry_convert as pc\n# import basemap as bm\n\n# Natural Language Toolkit\nimport re\nimport spacy\nimport nltk\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n# Topics modeling\nfrom gensim import corpora\nfrom gensim import models\nfrom gensim.models import Phrases\n# LDA visualisation\nimport pyLDAvis\nimport pyLDAvis.gensim\n\n# Min max scaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Machine learning \nfrom sklearn import tree\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom itertools import chain # to flatten list of sentences of tokens into list of tokens","15d91c56":"CDP_cities_correctly_located  = pd.read_excel('..\/input\/cdp-inputs-final\/Cities_Disclosing_to_CDP_corrected.xlsx')\n\ngdf = gpd.GeoDataFrame(\n    CDP_cities_correctly_located, \n    geometry=gpd.points_from_xy(CDP_cities_correctly_located.Longitude,\n                                CDP_cities_correctly_located.Latitude))\n\nfig = px.scatter_geo(gdf,\n                    lat=gdf.geometry.y,\n                    lon=gdf.geometry.x,\n                    hover_name='Organization')\nfig.show()","126d9377":"df = pd.read_excel('..\/input\/cdp-inputs-final\/Country_indicators.xlsx')\n\nfig = go.Figure(data=go.Choropleth(\n    locations = df['iso3'],\n    z = df['7.2.1 Renewable energy share in the total final energy consumption (%)'],\n    text = df['Country'],\n    colorscale = 'Reds',\n    autocolorscale=False,\n    reversescale=True,\n    marker_line_color='darkgray',\n    marker_line_width=0.5,\n    colorbar_title = 'Renewable energy share (%)',\n))\nfig.show()","e31f13cd":"Proba_magnitude_aggreg = pd.read_excel('..\/input\/cdp-inputs-final\/Proba_Magn_agg_risk.xlsx')\nfig = px.scatter(Proba_magnitude_aggreg, \n                 x=\"Magnitude\", \n                 y=\"Probability\",\n                 size=\"n\", color=\"Risk\",\n                 hover_name=\"Climate Hazard\", log_x=False, size_max=30)\nfig.update_layout({\n'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n})\nfig.show()","2e41aad8":"CDP_cities_scores = pd.read_excel('..\/input\/cdp-inputs-final\/final_risk_scores.xlsx')\nscores  = [\"biodiv_Z\",\n           \"water_Z\",\n           \"energy_Z\",\n           \"physical_Z\"]\nCDP_cities_scores = CDP_cities_scores.loc[:, scores]\ng = sn.pairplot(CDP_cities_scores)","cb41770b":"def hc_gaussianKDE(x, bounds = [0,1], title = '', dataType = ''):\n    \n    # Generates a Highchart with the Gaussian kernel density estimators of the data \n    \n    # Highchart options\n    H = Highchart(width=750, height=600)\n    \n    options = {\n        'title': {\n            'text': title\n        },\n        'xAxis': {\n            'title': { 'text': dataType}\n        },\n        'tooltip': {\n            'shared': True,  \n        },\n        'colors': [\"#df5353\",\"#434348\", \"#7cb5ec\", \"#90ed7d\", \"#f7a35c\", \"#8085e9\", \"#f15c80\", \"#e4d354\", \"#2b908f\", \"#f45b5b\", \"#91e8e1\"]\n    }\n\n    H.set_dict_options(options)\n    \n    # Kernel Density Estimation\n    for i in x.columns:\n        kde = stats.gaussian_kde(x.loc[:,i].values)\n        data = [[float(j),float(np.round(kde(j)[0],3))] for j in np.array(range(int(100*bounds[0]),int(100*bounds[1])+1))\/100]\n\n        H.add_data_set(data, 'area', i, tooltip={'headerFormat': '<b>{series.name}<\/b><br>'})#, color='rgba(223, 83, 83, .5)')\n    \n    return H","b3efb7c4":"CDP_cities_scores = pd.read_excel('..\/input\/cdp-inputs-final\/final_risk_scores.xlsx')\nscores  = [\"Social Risk\", # To call prosperity\n           \"Prosperity Risk\",\n           \"Planet Risk\"]\nCDP_cities_scores = CDP_cities_scores.loc[:, scores] \n\nH_risks = hc_gaussianKDE(CDP_cities_scores, [0,1], title = 'Density estimation of the Risk scores', dataType = 'Score')\nH_risks","32cff8d8":"cities_2020 = pd.read_pickle('..\/input\/cdp-inputs-final\/2020_Full_Cities_Dataset_Expended.pkl')\ncities_2020.rename(columns={'Account Number': 'Account'}, inplace = True)","9578b044":"geo_cities_2020 = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Disclosing\/2020_Cities_Disclosing_to_CDP.csv', usecols=[\"Account Number\",\"City Location\"])\ngeo_cities_2020.rename(columns={'Account Number': 'Account'}, inplace = True)","251c42c9":"cities_Will_2020 = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020.pkl')\ncities_Stat_2020 = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_Stat_2020.pkl')","2ce7a1c0":"with open('..\/input\/cdp-inputs-final\/cities_Will_2020_vWide.pkl', 'rb') as handle:\n    cities_Will_2020_vWide = pickle.load(handle)","696e6d62":"extra_info = pd.read_pickle('..\/input\/cdp-inputs-final\/extra_info_2020.pkl')","fb2c8dbb":"unique_answer = pd.read_pickle('..\/input\/cdp-inputs-final\/positive_dict.pkl')\nunique_answer = dict(zip(unique_answer.Category, unique_answer.Label))","78930471":"cities_Will_2020_CatAnalysis = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_CatAnalysis.pkl')\n\nwith open('..\/input\/cdp-inputs-final\/cities_Will_2020_CatCount.pkl', 'rb') as handle:\n    cities_Will_2020_CatCount = pickle.load(handle)","cbda951b":"cities_Will_2020_CatScore = cities_Will_2020_CatAnalysis.mean(axis=1)\ntop_10_CatAnalysis = cities_Will_2020_CatScore.sort_values(ascending=False).iloc[0:10]\nbottom_10_CatAnalysis = cities_Will_2020_CatScore.sort_values(ascending=True).iloc[0:10]\nTopbottom_Cities_CatAnalysis = pd.DataFrame([[cities_Will_2020.loc[cities_Will_2020.Account == x, 'Organization'].values[0] for x in list(top_10_CatAnalysis.index)],\n                           [cities_Will_2020.loc[cities_Will_2020.Account == x, 'Organization'].values[0] for x in list(bottom_10_CatAnalysis.index)]],\n                         index = ['Top', 'Bottom'], columns = range(1,11)).T\n\n\nTopbottom_Cities_CatAnalysis = Topbottom_Cities_CatAnalysis.applymap(lambda x: x.encode('iso-8859-1', 'ignore').decode('utf8','ignore'))\nTopbottom_Cities_CatAnalysis","0bbe9550":"data = pd.DataFrame(cities_Will_2020_CatScore, columns = ['Score'])\nH_risks = hc_gaussianKDE(data, [0,1], title = 'Density estimation of the Quantitative and Categorical answers', dataType = 'Score')\nH_risks","da129a99":"with open('..\/input\/cdp-inputs-final\/cities_Will_2020_SentimentAnalysis.pkl', 'rb') as handle:\n    cities_Will_2020_SentimentAnalysis = pickle.load(handle)","2f1a370a":"with open('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_models.pkl', 'rb') as handle:\n    cities_Will_2020_LDA_models = pickle.load(handle)\n\nwith open('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_topics.pkl', 'rb') as handle:\n    cities_Will_2020_LDA_topics = pickle.load(handle)","685a97a9":"cities_Will_2020_LDA_topics_Avg = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_topics_Avg.pkl')\ncities_Will_2020_SentimentAnalysis_Avg = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_SentimentAnalysis_Avg.pkl')","5c53c9b3":"Scores_All_Questions = pd.read_pickle('..\/input\/cdp-inputs-final\/cities_2020_Scores_All_Questions.pkl')","138b483f":"Question_Quality = pd.read_pickle('..\/input\/cdp-inputs-final\/Questions_Quality.pkl')","98fa99e3":"# Subset data per SDGs macro-theme\nPlanet_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'Planet' in x if isinstance(x, list) else False)])\nPlanet_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Planet_questions].copy()\n\nProsperity_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'Prosperity' in x if isinstance(x, list) else False)])\nProsperity_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Prosperity_questions].copy()\n\nSocial_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'SocialJustice' in x if isinstance(x, list) else False)])\nSocial_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Social_questions].copy()","32e3348e":"def weighted_nan_average(x, w):\n    indices = np.array(x.apply(lambda y: ~np.isnan(y)))\n    if sum(indices)>0:\n        out = np.average(np.array(x[indices], dtype='float'), weights = w[indices])\n    else:\n        out = np.nan\n    return out","72632fcd":"# Compute average score per macro-theme\nweights_Planet = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Planet_Scores.columns[2:]]])\nPlanet_Scores['KPI'] = Planet_Scores.apply(lambda x: weighted_nan_average(x[2:], weights_Planet), axis = 1)\n\nweights_Prosperity = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Prosperity_Scores.columns[2:]]])\nProsperity_Scores['KPI'] = Prosperity_Scores.apply(lambda x: weighted_nan_average(x[2:], w = weights_Prosperity), axis = 1)\n\nweights_Social = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Social_Scores.columns[2:]]])\nSocial_Scores['KPI'] = Social_Scores.apply(lambda x: weighted_nan_average(x[2:], w = weights_Social), axis = 1)","2233804c":"KPIs = pd.DataFrame([Planet_Scores.KPI, Prosperity_Scores.KPI, Social_Scores.KPI]).T\nKPIs.columns = ['Planet', 'Prosperity', 'Social']\nKPIs.insert(loc=0, column='Account Number', value=Planet_Scores.Account)\nKPIs.set_index('Account Number', inplace = True)","79802fc7":"H_scores = hc_gaussianKDE(pd.concat([Social_Scores['KPI'].rename('Social'),Prosperity_Scores['KPI'].rename('Prosperity'),Planet_Scores['KPI'].rename('Planet')],axis=1), [0,1], title = 'Density estimation of the Ambition scores', dataType = 'Score')\nH_scores","c02b52c3":"CDP_cities_scores_ambitions      = pd.read_excel('..\/input\/cdp-inputs-final\/Ambition_KPIs.xlsx')\nCDP_cities_scores_risk_exposures = pd.read_excel('..\/input\/cdp-inputs-final\/final_risk_scores.xlsx')\nloc  = [\"Account Number\",\n        \"Prosperity Risk\", \n        \"Planet Risk\",\n        \"Social Risk\"]\nCDP_cities_scores_risk_exposures= CDP_cities_scores_risk_exposures.loc[:, loc] \n\nCDP_cities_scores = pd.merge(CDP_cities_scores_ambitions,CDP_cities_scores_risk_exposures, on='Account Number')\n\nKPIs_corr = CDP_cities_scores.iloc[:,1:].corr()\nax = sn.heatmap(KPIs_corr, annot=True, fmt='.2%', cmap = 'Blues') #cmap='Blues' pour changer la couleur\n# bottom, top = ax.get_ylim()\n# ax.set_ylim(bottom + 0.5, top - 0.5)","b18f5b41":"CDP_cities_correctly_located  = pd.read_excel('..\/input\/cdp-inputs-final\/Cities_Disclosing_to_CDP_corrected.xlsx')\n\ngdf = gpd.GeoDataFrame(\n    CDP_cities_correctly_located, \n    geometry=gpd.points_from_xy(CDP_cities_correctly_located.Longitude,\n                                CDP_cities_correctly_located.Latitude))\n\ngdf['Social Ambition Score'] = [Social_Scores.loc[Social_Scores.Account==c, 'KPI'].values[0] for c in gdf['Account.Number'] if c in Social_Scores.Account.values]\ngdf['Planet Ambition Score'] = [Planet_Scores.loc[Social_Scores.Account==c, 'KPI'].values[0] for c in gdf['Account.Number'] if c in Social_Scores.Account.values]\ngdf['Prosperity Ambition Score'] = [Prosperity_Scores.loc[Social_Scores.Account==c, 'KPI'].values[0] for c in gdf['Account.Number'] if c in Social_Scores.Account.values]","0662b898":"country_code = [pc.country_alpha3_to_country_alpha2(c) for c in gdf.iso3.unique()]\ngdf['Continent'] = [pc.country_alpha2_to_continent_code(pc.country_alpha3_to_country_alpha2(c)) for c in gdf.iso3] \n\nCDP_cities_scores = pd.read_excel('..\/input\/cdp-inputs-final\/final_risk_scores.xlsx')\nscores  = [\"Planet Risk\", # To call prosperity\n           \"Prosperity Risk\",\n           \"Social Risk\"]\nCDP_cities_scores = CDP_cities_scores.loc[:, scores] \nCDP_cities_scores['Account'] = geo_cities_2020.loc[:,'Account']\n\nrisk_env = CDP_cities_scores.copy().loc[:,['Account','Planet Risk']].dropna()\nrisk_env['iso3']=np.nan\nrisk_env.loc[[x in gdf.loc[:,'Account.Number'].values for x in risk_env.Account],'iso3'] = [gdf.loc[gdf['Account.Number']==x,'iso3'].values for x in risk_env.Account if x in gdf['Account.Number'].values]\n\nEUR = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='EU','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='EU','iso3'].unique()]\nNA = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='NA','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='NA','iso3'].unique()]\nSA = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='SA','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='SA','iso3'].unique()]\nAS = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='AS','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='AS','iso3'].unique()]\nAF = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='AF','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='AF','iso3'].unique()]\nOC = [{'x':np.round(gdf.loc[gdf.iso3==x,'Planet Ambition Score'].mean(),2),'y':np.round(risk_env.loc[risk_env.iso3==x, 'Planet Risk'].mean(),2), 'z':float(gdf.loc[gdf.Continent=='OC','iso3'].value_counts().loc[x]), 'country':x} for x in gdf.loc[gdf.Continent=='OC','iso3'].unique()]\n\nH = Highchart(width=900, height=600)\n\noptions = {\n    'chart': {\n        'type': 'bubble',\n        'zoomType': 'xy'\n    },\n\n    'title': {\n        'text': 'Risk exposure\/Ambition for Planet related issues aggregated at the country level'\n    },\n    'xAxis': {\n        'title': { 'text': 'Average Ambition Score amongst cities'}\n    },\n    'yAxis': {\n        'title': { 'text': 'Average Risk Score amongst cities'}\n    },\n    'tooltip': {\n        'useHTML': True,\n        'headerFormat': '<table>',\n        'pointFormat': '<tr><th colspan=\"2\"><h3>{point.country}<\/h3><\/th><\/tr>' +\n            '<tr><th>Risk Score:<\/th><td>{point.y}<\/td><\/tr>' +\n            '<tr><th>Ambition Score:<\/th><td>{point.x}<\/td><\/tr>' +\n            '<tr><th>Number of cities:<\/th><td>{point.z}<\/td><\/tr>',\n        'footerFormat': '<\/table>',\n        'followPointer': True\n    },\n    'colors': [\"#df5353\",\"#434348\", \"#7cb5ec\", \"#90ed7d\", \"#f7a35c\", \"#8085e9\", \"#f15c80\", \"#e4d354\", \"#2b908f\", \"#f45b5b\", \"#91e8e1\"]\n\n}\n\nH.set_dict_options(options)\n\nH.add_data_set(EUR, 'bubble', 'Europe')\nH.add_data_set(NA, 'bubble', 'North America')\nH.add_data_set(SA, 'bubble', 'South America')\nH.add_data_set(AS, 'bubble', 'Asia')\nH.add_data_set(AF, 'bubble', 'Africa')\nH.add_data_set(OC, 'bubble', 'Oceania')\n\nH","74b09f1a":"top_10_Planet = Planet_Scores.sort_values('KPI', ascending=False).iloc[0:10,0].values\nbottom_10_Planet = Planet_Scores.sort_values('KPI', ascending=True).iloc[0:10,0].values\n\ntop_10_Social = Social_Scores.sort_values('KPI', ascending=False).iloc[0:10,0].values\nbottom_10_Social = Social_Scores.sort_values('KPI', ascending=True).iloc[0:10,0].values\n\ntop_10_Prosperity = Prosperity_Scores.sort_values('KPI', ascending=False).iloc[0:10,0].values\nbottom_10_Prosperity = Prosperity_Scores.sort_values('KPI', ascending=True).iloc[0:10,0].values","3f268b91":"fig = px.scatter_geo(gdf,\n                    lat=gdf.geometry.y,\n                    lon=gdf.geometry.x,\n                    hover_name='Organization',\n                    color ='Planet Ambition Score',\n                    width = 1200,\n                    height = 600, \n                    title = 'Planet Ambition Score')\nfig.show()","66c8e239":"Top_Cities = pd.DataFrame([[cities_Will_2020.loc[cities_Will_2020.Account == x, 'Organization'].values[0] for x in top_10_Planet],\n                           [cities_Will_2020.loc[cities_Will_2020.Account == x, 'Organization'].values[0] for x in top_10_Prosperity],\n                           [cities_Will_2020.loc[cities_Will_2020.Account == x, 'Organization'].values[0] for x in top_10_Social]],\n                         index = ['Planet', 'Prosperity', 'Social'], columns = range(1,11)).T\n\nTop_Cities = Top_Cities.applymap(lambda x: x.encode('iso-8859-1','ignore').decode('utf8','ignore'))\nTop_Cities","bd7129a3":"Planet_data = {k: cities_Will_2020_vWide[k] for k in Planet_questions}\nPlanet_data_dummies = geo_cities_2020.copy()\nlabel = {'1.0':'Sust Plan', '5.5':'GHG Plan', '10.7':'Zero Emission Zone', '12.3':'Food Policies', '14.4':'Public Water Management',\n         '2.0':'Climate Assesment', '3.2':'Climate Change Plan', '4.0':'Emissions Invetory', '4.8':'Emission Growth', '6.2':'Business Partnership',\n         '8.0':'Renewable Target'}\ncol = {'1.0':1, '5.5':1, '10.7':1,  '12.3':1, '14.4':1, '2.0':1, '3.2':1, '4.0':1, '4.8':1, '6.2':1, '8.0':1}\nfor q in ['1.0', '5.5', '10.7', '12.3', '14.4', '2.0', '3.2', '4.0', '4.8', '6.2', '8.0']:\n    df = pd.DataFrame(Planet_data[q].iloc[:,(1+col[q])].apply(lambda x: list(x.keys())[0] if isinstance(x, dict) else x))\n    df.columns = [label[q]]\n    df.dropna(inplace=True)\n    df = pd.DataFrame(df[label[q]].tolist(), index= df.index)\n    df = pd.get_dummies(df.stack(), prefix = label[q]).sum(level=0)\n    df.drop([col for col, val in df.sum().iteritems() if val < 10], axis=1, inplace=True)\n    Planet_data_dummies = pd.merge(Planet_data_dummies, df, left_index=True, right_index=True, how = 'outer')\nPlanet_data_dummies.fillna(0, inplace = True)\nPlanet_data_dummies.drop([c for c in Planet_data_dummies.keys() if re.search(r'_No$', c)],axis=1,inplace=True)","94bcce48":"Y = pd.qcut(Planet_Scores.KPI,5, labels = False)\nX_train, X_test, Y_train, Y_test = train_test_split(Planet_data_dummies.iloc[:,2:], Y, test_size=0.2, stratify=Y, random_state=10)","13d52ca3":"clf = tree.DecisionTreeClassifier(min_samples_leaf=40, max_depth=3,random_state=10)\nclf = clf.fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\n# print(classification_report(Y_test, Y_pred))","c212c26b":"from sklearn.tree import export_graphviz\nexport_graphviz(clf, \n                out_file='tree.dot', \n                feature_names = list(Planet_data_dummies.columns[2:]),\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\nimport pydot\n(graph,) = pydot.graph_from_dot_file('tree.dot')\ngraph.write_png('tree.png')\nplt.figure(figsize = (18, 20))\nplt.imshow(plt.imread('tree.png'))\nplt.axis('off');\nplt.show();","3e3fd2ae":"# Generates a Highchart with the values of the pertinence score and coverage for every questions\n\nH = Highchart(width=900, height=400)\n\noptions = {\n    'chart': {\n        'type': 'column'\n    },\n    'title': {\n        'text': 'Questions quality'\n    },\n    'xAxis': {\n        'title': { 'text': 'Question Number'},\n        'categories' : [q for q in Question_Quality.index.values]\n    },\n    'yAxis': {\n        'title': {'text': 'Score'},\n        'max' : 1.0\n    },\n    'tooltip': {\n        'headerFormat': '<span style=\"font-size:10px\"><b>Question {point.key}<\/b><\/span><table>',\n        'pointFormat': '<tr><td style=\"color:{series.color};padding:0\">{series.name}: <\/td>' +\n            '<td style=\"padding:0\">{point.y}<\/td><\/tr>',\n        'footerFormat': '<\/table>',\n        'shared': True,\n        'useHTML': True\n    }\n}\n\nH.set_dict_options(options)\n\npertinence = [x for x in Question_Quality.loc[:, 'Pertinence'].apply(lambda x: np.round(x,2)).values]\ncoverage = [x for x in Question_Quality.loc[:, 'Coverage'].apply(lambda x: np.round(x,2)).values]\n\nH.add_data_set(pertinence, 'scatter', 'Pertinence')\nH.add_data_set(coverage, 'scatter', 'Coverage', color='rgba(223, 83, 83, .5)')\n\nH","03e0745d":"CDP_cities_correctly_located  = pd.read_excel('..\/input\/cdp-inputs-final\/Cities_Disclosing_to_CDP_corrected.xlsx')\n\ngdf = gpd.GeoDataFrame(\n    CDP_cities_correctly_located, \n    geometry=gpd.points_from_xy(CDP_cities_correctly_located.Longitude,\n                                CDP_cities_correctly_located.Latitude))\n\nfig = px.scatter_geo(gdf,\n                    lat=gdf.geometry.y,\n                    lon=gdf.geometry.x,\n                    hover_name='Organization',\n                    color ='fit.classification')\nfig.show()","a83638e2":"def remove_dictKey(d, key):\n    # Removes a key in a dictionary if the key is present\n    r = dict(d)\n    if key in d.keys():\n        del r[key]\n    return r\n\ndef get_Recommendation(SDG, comparableCities = []):\n    \n    # if comparableCities is empty, we use the top 5 of all cities\n    # if comparableCities is not empty, we retain only the 5 top cities in the list\n    if len(comparableCities)==0:\n        comparableCities = pd.DataFrame([top_10_Planet[0:5], top_10_Social[0:5], top_10_Prosperity[0:5]], index = ['Planet', 'Social', 'Prosperity']).transpose()\n        comparableCities = comparableCities.loc[:,SDG].values\n    \n    elif len(comparableCities)>5:\n        comparableCities = pd.concat([Planet_Scores.loc[[Planet_Scores.loc[c,'Account'] in comparableCities for c in Planet_Scores.index], 'Account'].rename('Account'),Planet_Scores.loc[[Planet_Scores.loc[c,'Account'] in comparableCities for c in Planet_Scores.index], 'KPI'].rename('Planet'), Social_Scores.loc[[Social_Scores.loc[c,'Account'] in comparableCities  for c  in Social_Scores.index], 'KPI'].rename('Social'), Prosperity_Scores.loc[[Prosperity_Scores.loc[c,'Account'] in comparableCities  for c  in Prosperity_Scores.index], 'KPI'].rename('Prosperity')], axis=1)\n        comparableCities = comparableCities.sort_values(SDG,ascending=False).Account.values[:5]\n    \n    # Gets the answers related to this SDG and that can be used to generate recommendations\n    reco_info = extra_info.loc[extra_info['Political Recommandation'].isna()==False]\n    reco_info = reco_info.loc[[q for q in reco_info.loc[reco_info['SDGs'].isna()==False,'Question Number'].index if SDG in reco_info.loc[q,'SDGs']]]\n    #reco_q = reco_info.loc[:,'Question Number'].values\n    reco_q = ['3.0','6.2a']\n    reco_cols = [[9],[2,3]]\n    reco_dict = {q:[] for q in reco_q}\n    \n    for i,q in enumerate(reco_q):\n        # Gets the column of interests\n        cols_study = reco_cols[i]\n        reco_ans = cities_Will_2020_vWide[q].loc[[cities_Will_2020_vWide[q].loc[c,'Account'] in comparableCities for c in cities_Will_2020_vWide[q].index]]\n        \n        if q == '3.0':\n            reco_dict[q].append(reco_ans)\n        else:\n            reco_ans = reco_ans.iloc[:,cols_study]\n            t0 = [list(item.keys()) for item in reco_ans.iloc[:,0] if isinstance(item, dict)]\n            t0 = [item for sublist in t0 for item in sublist]\n            t1 = [list(item.keys()) for item in reco_ans.iloc[:,1] if isinstance(item, dict)]\n            t1 = [item for sublist in t1 for item in sublist]\n            c0 = remove_dictKey(dict(Counter(t0)), 'Question not applicable')\n            c1 = remove_dictKey(dict(Counter(t1)), 'Question not applicable')\n            counters = {reco_ans.columns[0] : {sect : c0[sect] for sect in list(c0)}, reco_ans.columns[1]:{sect:{col:0 for col in list(c1)} for sect in list(c0)}}\n\n            for i in reco_ans.index:\n                for j in list(reco_ans.loc[i,reco_ans.columns[1]]):\n                    if j!='Question not applicable':\n                        for k in reco_ans.loc[i,reco_ans.columns[1]][j]:\n                            z = [x for x in list(reco_ans.loc[i,reco_ans.columns[0]]) if k in reco_ans.loc[i,reco_ans.columns[0]][x]][0]\n                            counters[reco_ans.columns[1]][z][j]=counters[reco_ans.columns[1]][z][j]+1\n             \n            reco_dict[q].append(counters)\n    \n    return reco_dict","237ceacf":"SDG='Planet'\ncomparableCities = pd.read_excel('..\/input\/cdp-inputs-final\/Cities_Disclosing_to_CDP_corrected.xlsx')\ncomparableCities = comparableCities.iloc[:,[0,-1]]\ncomparableCities = comparableCities.loc[comparableCities['fit.classification']==2,'Account.Number'].values\n\nreco_dict = get_Recommendation(SDG,comparableCities)\nprint('Cities used to generate recommendations:')\nreco_cities = pd.DataFrame([reco_dict['3.0'][0].loc[:,'Account'].values, [cities_Will_2020.loc[cities_Will_2020['Account']==c, 'Organization'].values[0] for c in reco_dict['3.0'][0].loc[:,'Account'].values]], index = ['Account','Organisation']).transpose()\nreco_cities.iloc[:,1] = reco_cities.iloc[:,1].apply(lambda x: x.encode('iso-8859-1','ignore').decode('utf8','ignore'))\nreco_cities","7a2b0a9d":"# Exemple 1:\nprint(cities_Will_2020.loc[cities_Will_2020['Question Number']=='3.0', 'Question Name'].values[0]+'\\n')\nprint('Respondent: ' +cities_Will_2020.loc[cities_Will_2020['Account']==reco_dict['3.0'][0].loc[351,'Account'], 'Organization'].values[0]+'\\n')\nprint('Action: '+list(reco_dict['3.0'][0].loc[351,'Action'])[8])\nprint('Action description: '+list(reco_dict['3.0'][0].loc[351,'Action description and implementation progress'])[8])","5f6884f5":"#Exemple 2\nprint(cities_Will_2020.loc[cities_Will_2020['Question Number']=='6.2a', 'Question Name'].values[0]+'\\n')\nd = reco_dict['6.2a'][0]\nH_pie = Highchart(width = 850, height = 600)\n\ncolors = [\"#df5353\",\"#434348\", \"#7cb5ec\", \"#90ed7d\", \"#f7a35c\", \"#8085e9\", \"#f15c80\", \"#e4d354\", \"#2b908f\", \"#f45b5b\", \"#91e8e1\"]\ncolors = [tuple(int(c.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) for c in colors]\ncolors = ['rgba('+str(c[0])+','+str(c[1])+','+str(c[2])+',1)' for c in colors]\n\n\ndata = [{\n            'y': np.round(100*float(d[list(d)[0]][x]\/sum(d[list(d)[0]][xx] for xx in d[list(d)[0]])),2),\n            'color': colors[c],\n            'drilldown': {\n                'name': x,\n                'categories': [xx for xx in list(d[list(d)[1]][x]) if d[list(d)[1]][x][xx]>0],\n                'data': [np.round(100*float(d[list(d)[1]][x][k]*d[list(d)[0]][x]\/(sum(d[list(d)[1]][x][xx] for xx in d[list(d)[1]][x])*sum(d[list(d)[0]][xx] for xx in d[list(d)[0]]))),2) for k in list(d[list(d)[1]][x]) if d[list(d)[1]][x][k]>0],\n                'color': colors[c]\n            } \n        } for c,x in enumerate(list(d[list(d)[0]]))]\n\n\noptions = {\n    'chart': {\n        'type': 'pie'\n    },\n    'title': {\n        'text': 'Share of collaboration areas and the corresponding type of collaborations provided by the 5 top cities'\n    },\n    'plotOptions': {\n        'pie': {\n            'shadow': False,\n            'center': ['50%', '50%']\n        }\n    },\n    'tooltip': {\n        'valueSuffix': '%'\n    }\n}\n\n\ncategories = list(d[list(d)[0]])\nbrowserData = []\nversionsData = []\n\nfor i in range(len(data)):\n\n    browserData.append({\n        'name': categories[i],\n        'y': data[i]['y'],\n        'color': data[i]['color']\n        })\n\n    drillDataLen = len(data[i]['drilldown']['data'])\n    for j in range(drillDataLen): \n\n        brightness = 0.2 - (j \/ drillDataLen) \/ 5;\n        versionsData.append({\n            'name': data[i]['drilldown']['categories'][j],\n            'y': data[i]['drilldown']['data'][j],\n            'color': data[i]['color'][:-2]+ '0.5)'\n        })\n\nH_pie.set_dict_options(options)\n\nH_pie.add_data_set(browserData, 'pie', cities_Will_2020_vWide['6.2a'].columns[2], size='60%',\n            dataLabels={\n                'formatter': 'function () { \\\n                                    return this.y > 5 ? this.point.name : null;\\\n                                }',\n                'color': 'white',\n                'distance': -30\n            })\n\nH_pie.add_data_set(versionsData, 'pie', cities_Will_2020_vWide['6.2a'].columns[3], size='80%',\n            innerSize='60%',\n            dataLabels={\n                'formatter': \"function () {\\\n                                    return this.y > 5 ? '<b>' + this.point.name + ':<\/b> ' + this.y + '%'  : null;\\\n                                }\"\n            })\nH_pie","0d193bcc":"# cities_2020 = pd.read_excel('..\/input\/cdp-inputs-final\/2020_Full_Cities_Dataset_Expended.xlsx', sheet_name = '2020_Full_Cities_Dataset')\n# cities_2020.to_pickle('..\/input\/cdp-inputs-final\/2020_Full_Cities_Dataset_Expended.pkl')\n# cities_2020.rename(columns={'Account Number': 'Account'}, inplace = True)","353f6fac":"cities_2020.drop(['Questionnaire', 'Country', 'CDP Region', 'Parent Section', 'Section', 'File Name', 'Last update', 'Row Name', 'Comments'], axis = 1, inplace = True)\ncities_2020.keys()","feb8ab5b":"# First we clean our personal variables\ncities_2020.loc[cities_2020['SDGs']==0, 'SDGs'] = np.nan\ncities_2020.loc[cities_2020['Type of Answer']==0, 'Type of Answer'] = np.nan\ncities_2020.loc[cities_2020['Max Column Number']==0, 'Max Column Number'] = np.nan\ncities_2020.loc[cities_2020['Which Is Text to Analyse']==0, 'Which Is Text to Analyse'] = np.nan\ncities_2020.loc[cities_2020['Which else to Analyse']==0, 'Which else to Analyse'] = np.nan\ncities_2020.loc[cities_2020['Political Recommandation']==0, 'Political Recommandation'] = np.nan\ncities_2020.loc[cities_2020['Is Positive']==0, 'Is Positive'] = np.nan\ncities_2020.loc[cities_2020['Text Ref Col']==0, 'Text Ref Col'] = np.nan\ncities_2020.loc[cities_2020['2019 OK']==0, '2019 OK'] = np.nan","4eb2a9ee":"cities_2020.shape","cc8f2d5b":"isEnglish = {'Account':np.array(cities_2020.Account[cities_2020['Question Name'] == 'What language are you submitting your response in?']), \n             'isEnglish':np.array(cities_2020[cities_2020['Question Name'] == 'What language are you submitting your response in?']['Response Answer']=='English')}\n\nisEnglish_df = pd.DataFrame(isEnglish)\nisEnglish_df = isEnglish_df[isEnglish_df.isEnglish==True]\n\n# with open('..\/input\/cdp-inputs-final\/isEnglish_df.pkl', 'wb') as handle:\n#     pickle.dump(isEnglish_df, handle, protocol=pickle.HIGHEST_PROTOCOL)","8336cb05":"import en_core_web_sm\nnlp = en_core_web_sm.load()\n\ndef cleanData(text, to_list=False):\n\n    if isinstance(text, str):\n        \n        if text: # empty string is False\n            \n            # Liens https\n            pattern = re.compile(r'http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n            text = pattern.sub('', text)\n\n            # Tweet account et emails\n            pattern = re.compile(r'\\S*@\\S*\\s?')\n            text = pattern.sub('', text)\n            \n            # Suppressions de symboles sp\u00e9cifiques\n            pattern = re.compile(r'[$\u20ac\u00a3\u00a5\\+%]{1}')\n            text = pattern.sub('', text)\n            \n            # Remove multiple whitespace\n            text = ' '.join(text.split())\n            \n            if to_list: \n                \n                # Remove dates\n                pattern = re.compile(r'([0-9]{2}[:\\\/,.]){1,2}[:\\\/,.]?[0-9]{0,4}|am|pm|(\\s[0-9]{1,2}[a-zA-Z]{1,3})')\n                text = pattern.sub('', text)\n\n                # Remove months\n                months = ['january', 'february', 'march', 'april', 'mai', 'june', 'july', 'august', 'september', 'october', \n                          'november', 'december']\n                text = ' '.join([word for word in text.split() if word.lower() not in months])\n                \n                # Remove remaining numbers and whats surround them\n                pattern = re.compile(r'\\s[a-zA-Z]{0,3}[0-9]+[.,]?[0-9]*[a-zA-Z]{0,3}')\n                text = pattern.sub(' ', text)\n                \n                # Remove multiple whitespace\n                text = ' '.join(text.split())\n                \n                CLEAN_words = {word.lemma_.strip().lower(): word.pos_ for word in nlp(text) \n                               if (not word.is_stop and not word.is_punct and not word.is_space and not word.pos_ in ['NUM'])}  \n                \n            else:\n                CLEAN_words = text\n        else:\n            CLEAN_words = np.nan\n    \n    elif (isinstance(text, float) or isinstance(text, int)):\n        CLEAN_words = float(text)\n            \n    else:\n        CLEAN_words = np.nan\n    \n    return CLEAN_words","f73a87cd":"cities_Risk_2020 = cities_2020[['Risk Exposure' in k for k in \n                                   cities_2020['Type of Answer'].map(lambda x: x.split(', ') if isinstance(x, str) else [])]].copy()\ncities_Will_2020 = cities_2020[['Willingness' in k for k in \n                                   cities_2020['Type of Answer'].map(lambda x: x.split(', ') if isinstance(x, str) else [])]].copy()\ncities_Stat_2020 = cities_2020[['Statistics' in k for k in \n                                   cities_2020['Type of Answer'].map(lambda x: x.split(', ') if isinstance(x, str) else [])]].copy()","ffd161c1":"# We reset the index of each subset.\ncities_Risk_2020.reset_index(drop=True, inplace=True)\ncities_Will_2020.reset_index(drop=True, inplace=True)\ncities_Stat_2020.reset_index(drop=True, inplace=True)\n\n# cities_Stat_2020.to_pickle('..\/input\/cdp-inputs-final\/cities_Stat_2020.pkl')\n# cities_Will_2020.to_pickle('..\/input\/cdp-inputs-final\/cities_Stat_2020.pkl')","282a93f2":"def replace_other_spec(s):\n    out = s\n    try:\n        if s[:21]=='Other, please specify':\n            out = 'Other'\n        return out\n    except:\n        return out","4d999c74":"def extract_answer_perCol(df,question=\"\"):\n    \n    # Possible to run for one question or multiple\n    if question:\n        df = df[df['Question Number']==question]\n    else:\n        out_list = []\n        q_nb_list = []\n    \n    # Run over all questions in df\n    for q in df['Question Number'].unique():\n        # Add geographic data. In case it might be usefull for matching with other data sources.\n        out = geo_cities_2020.copy()\n        #Subset data to question q\n        df_small = df[df['Question Number']==q].copy()\n        # Apply transformation to \"Other, please specify\"\n        df_small['Response Answer'] = df_small['Response Answer'].apply(replace_other_spec)\n        # Dropp nan answers\n        df_small = df_small[df_small['Response Answer'].notna()]\n    \n        # Run over each sub-question (given by the column number)\n        for cn in np.sort(df_small['Column Number'].unique()):\n            # subset again \n            res = df_small[df_small['Column Number']==cn][['Account', 'Response Answer', 'Row Number']].copy()\n            \n            # define output dataset\n            res_ok = pd.DataFrame()\n            res_ok['Account'] = res.Account.unique()\n            \n            # For each column number we get all answers and the corrsponding row\n            resp_list = []\n            for i in res.Account.unique():\n                h = defaultdict(list)\n                for k, v in zip(list(res[res.Account==i].iloc[:,1]), list(res[res.Account==i].iloc[:,2])):\n                    h[k].append(v)\n                resp_list.append(dict(h))\n            res_ok['Response Answer'] = pd.Series(resp_list, dtype='object')\n            \n            res_ok.rename(columns = {'Response Answer': df_small[df_small['Column Number']==cn]['Column Name'].unique()[0]}, \n                          inplace=True)\n            out = pd.merge(out, res_ok, on='Account', how='outer')\n        \n            if not question:               \n                out_list.append(out)\n                q_nb_list.append(q)\n    \n    # output change if there is one question or multiple.\n    if question:\n        return out\n    else:\n        return dict(zip(q_nb_list, out_list))","467d5ee8":"cities_Will_2020_vWide = extract_answer_perCol(cities_Will_2020)\n\n# with open('..\/input\/cdp-inputs-final\/cities_Will_2020_vWide.pkl', 'wb') as handle:\n#     pickle.dump(cities_Will_2020_vWide, handle, protocol=pickle.HIGHEST_PROTOCOL)","71dc7f32":"print(cities_Will_2020[cities_Will_2020['Question Number']=='6.0'].iloc[0,4])\ndf_6_0 = cities_Will_2020_vWide['6.0']\ndf_6_0.head(5)","0a15e4cd":"def transform_ToL(data, split_arg = ','):\n    \n    x = data.copy()\n    \n    isStr = x.apply(lambda y: isinstance(y, str))\n    \n#     x[isStr] = pd.Series(x[isStr].apply(lambda y: [int(i) if len(i)<3 else i for i in list(y.split(split_arg))]), dtype = 'object')\n    x[isStr] = pd.Series(x[isStr].apply(lambda y: [int(i) if len(i)<3 else i.replace(' ', '') for i in list(y.split(split_arg))]), dtype = 'object')\n    \n    return x","18d57cc2":"##### This step can't be run because it requires a manual input.\n\n# We build extra_info from the main dataset. Some reshaping is required.\n\n# extra_info = []\n# for q in cities_Will_2020['Question Number'].unique():\n#     d = pd.DataFrame(cities_Will_2020[cities_Will_2020['Question Number']==q].iloc[0,10:])\n#     d.columns = [q]\n#     extra_info.append(d)\n# extra_info = pd.concat(extra_info, axis = 1).T\n# extra_info.reset_index(inplace = True, drop = False)\n# extra_info.rename(columns={'index':'Question Number'}, inplace = True)\n# extra_info['SDGs'] = transform_ToL(extra_info['SDGs'],',')\n# extra_info['Which else to Analyse'] = transform_ToL(extra_info['Which else to Analyse'],';')\n# extra_info['Is Positive'] = transform_ToL(extra_info['Is Positive'],';')\n# extra_info['2019 OK'] = extra_info['2019 OK'].astype('str')\n\n####################################################################################\n\n# # We manually update some questions.\n\n# # question\n# q = '10.1'\n\n# # Question Name\n# cities_Will_2020['Question Name'][cities_Will_2020['Question Number']==q].unique()\n\n# # Exemple of possible answers\n# boo = cities_Will_2020_vWide[q].iloc[:,2].apply(lambda x: list(x.keys())[0] if isinstance(x, dict) else x) != 'Question not applicable'\n# boo2 = cities_Will_2020_vWide[q].iloc[:,2].notna()\n# cities_Will_2020_vWide[q][boo & boo2].iloc[0:7,2:]\n\n# # Current data in  extra_info\n# extra_info[extra_info['Question Number'] ==q]\n\n# # Update extra_info\n# # # Text\n# # extra_info.loc[extra_info['Question Number'] ==q, 'Which Is Text to Analyse'] = 2\n\n# # # Esle\n# extra_info.loc[extra_info['Question Number'] ==q, 'Which else to Analyse'] = [[2,3,5,6]]\n\n# # # Positive\n# extra_info.loc[extra_info['Question Number'] ==q, 'Is Positive'] = [[1,1,1,1]]\n\n# # Ref Text\n# # extra_info.loc[extra_info['Question Number'] ==q, 'Text Ref Col'] = np.nan\n\n# ###################################################################################\n\n# extra_info.to_pickle('..\/input\/cdp-inputs\/extra_info_2020.pkl')","95d17115":"def flatten_LoloS(coll):\n    # Flattent list of list of string to a single list of string \n    for i in coll:\n            if isinstance(i, Iterable) and not isinstance(i, str):\n                for subc in flatten_LoloS(i):\n                    yield subc\n            else:\n                yield i","679709b5":"####### READ ME ####### \n\n# This chunk will not lead to the donloaded dictionary because some steps were manually made in Excel.\n\n# #  We indentify all positive questions\n# pos_question = list()\n# for q in extra_info['Question Number'][extra_info['Is Positive'].notna() & extra_info['Is Positive']!=0]:\n#     pos_question.append(q)\n\n# #  We subset all non-numeric answers to those questions\n# cat_Pos = []\n# for q in pos_question:\n#     df = cities_Will_2020_vWide[q]\n#     # Categories to analyse per question\n#     cat_to_analyse = extra_info.loc[extra_info['Question Number']==q, 'Which else to Analyse'].values[0]\n#     is_to_analyse = extra_info.loc[extra_info['Question Number']==q, 'Is Positive'].values[0] \n    \n#     # Filter to positve catagories only\n#     if isinstance(cat_to_analyse, list):\n#         cat_to_analyse = [i[1] for i in enumerate(cat_to_analyse) if is_to_analyse[i[0]]==1]\n    \n#     # Get text\n#     if isinstance(cat_to_analyse, int):\n#         cat_to_analyse = [cat_to_analyse]\n\n#     output = []\n#     for c in cat_to_analyse:\n#         text = list(df.iloc[:,(2+c-1)]) \n#         # Only keep unique variable\n#         for n in range(len(df.Account)):\n#             d = text[n]\n#             if isinstance(d, dict):\n#                 isSTR = [isinstance(x, str) for x in list(d.keys())]\n#                 kSTR = list(d.keys())\n#                 kSTR = list(compress(kSTR, isSTR))\n#                 output.append(kSTR)\n\n#     # Flattent list of list of string to a single list of string                \n#     output = list(set(list(flatten_LoloS(output))))\n#     if 'Question not applicable' in output:\n#         output.remove('Question not applicable')\n\n#     # delete numbers entered as strings\n#     output = [i for i in output if any(map(str.isalpha, i))]\n\n#     cat_Pos.append(output)\n    \n# # Assign unique answers to a dictionary as usual\n# Dict_POS = dict(zip(pos_question, cat_Pos))\n# # Delete empty strings\n# Dict_POS = {k:v for k,v in Dict_POS.items() if v}\n\n# # Reshape to dataframe format\n# unique_answer = pd.DataFrame(list(set(list(flatten_LoloS(list(Dict_POS.values()))))))\n\n# # Export to Excel to mannually assign quantitative label\n# unique_answer.to_excel('Positive_dict.xlsx', engine='xlsxwriter')\n\n# # Load and save up-to-date dataset\n# unique_answer = pd.read_excel('Positive_dict.xlsx', sheet_name='Feuil1')\n# unique_answer.to_pickle('..\/inputcdp-inputs-final\/positive_dict.pkl')","d1a61fb8":"def remove_dictKey(d, key):\n    # Removes a key in a dictionary if the key is present\n    r = dict(d)\n    if key in d.keys():\n        del r[key]\n    return r","af41156b":"def isRepartition(df, threshold=0.5):\n    # Check if the answers in the dataframe correspond to a question about a repartition\n    # that is when the number of answers whose sum are either 1 or 100 are above the threshold\n    # If yes, we compute the rescaled data to correct cities that didn't use decimal (e.g. 50 rather than 0.5).\n    \n    out = df.copy()\n    vals = pd.DataFrame(index = df.index, columns = df.columns[2:])\n    for i,ct in enumerate(vals.index):\n        for j,c in enumerate(vals.columns):\n            if type(df.iloc[i,j+2])!=dict:\n                vals.loc[ct,c] = 0\n            else:\n                try:\n                    vals.loc[ct,c] = float(list(df.iloc[i,j+2])[0])\n                except:\n                    vals.loc[ct,c] = np.nan\n    \n    vals_drop = vals[vals.sum(axis=1)!=0].dropna()\n    if vals_drop.empty:\n        return False, pd.DataFrame()\n    else:\n        if (vals_drop.sum(axis=1).round(0)==100).mean()>threshold:\n            if vals_drop.shape[1]>1:\n                vals_drop = vals_drop.divide(vals_drop.sum(axis=1), axis=0)\n                out.loc[vals_drop.index, df.columns[2:]] = vals_drop.values\n            else:\n                vals_drop[vals_drop>1] = vals_drop[vals_drop>1]\/100\n                vals_drop[vals_drop>1] = 1.0\n                out.loc[vals_drop.index, df.columns[2]] = vals_drop.loc[:,df.columns[2]].values\n            \n            return True, out\n        else:\n            return False, pd.DataFrame()","309e675c":"def questionType(df, columns = [], colPos = []):\n    # Determine the type of answers for each columns of interest in the specified question\n    # The possible types are: ['quant', 'cat_Rank', 'cat_noRank', 'cat_noRank_noPos']\n    \n    # Check the columns of interest are in the good format\n    if type(columns)==int:\n        columns = [columns + 1]\n    else:\n        columns = [x+1 for x in columns]\n     \n    # Check the orientation the columns of interest are in the good format\n    if type(colPos)!=list:\n        if math.isnan(colPos):\n            colPos = ['9999' for x in columns]\n        else:\n            colPos = [colPos]\n    \n    # Determination of the types  \n    questionType = []\n    for k,n in enumerate(columns):\n        data = df.iloc[:,n]\n        t = [list(item.keys()) for item in data if isinstance(item, dict)]\n        t = [item for sublist in t for item in sublist]\n        t_drop = [x for x in t if x!='Question not applicable']\n        \n        try:\n            # Quantitative answers\n            pd.Series(t_drop).astype(float).dropna()\n            questionType.append('quant')\n        except:\n            # Categorial answers\n            isRank = np.sum([(x in unique_answer) for x in t_drop])==len(t_drop)\n            if isRank:\n                # Gradable categories\n                questionType.append('cat_Rank')\n            else:\n                if type(colPos[k])==str:\n                    # Ungradable categories with different orientations\n                    questionType.append('cat_noRank_noPos')\n                else:\n                    # Ungradable categories with similar orientation\n                    questionType.append('cat_noRank')\n            \n    return list(questionType)","20003e23":"def Explore_AnalyticData(df, columns = [], colPos = [], models = [], weights = {}):\n    \n    # Computes the score for each columns of interest based on the column type\n    \n    # Check the columns of interest are in the good format\n    if type(columns)==int:\n        columns = [columns + 1]\n    else:\n        columns = [x+1 for x in columns]\n        \n    if type(colPos)!=list:\n        if math.isnan(colPos):\n            colPos = ['9999' for x in columns]\n        else:\n            colPos = [colPos]\n            \n    # Check if the columns corresponds to a repartition\n    isRep, rescaledData = isRepartition(df)\n    if isRep:\n        df = rescaledData.copy()\n        \n    # Determination of the column type\n    # If quantitative, computation of the deciles distribution \n    # If categorial, computation of the categories frequencies\n    Count = []\n    colType = []\n    colDec = []\n    for n in columns:\n        data = df.iloc[:,n]\n        if isRep:\n            t = [item for item in data if isinstance(item, float)]\n            t = [item for item in t if not math.isnan(item)]\n            \n        else:\n            t = [list(item.keys()) for item in data if isinstance(item, dict)]\n            t = [item for sublist in t for item in sublist]\n        c = remove_dictKey(dict(Counter(t)), 'Question not applicable')\n        Count.append(c)\n        \n        try:\n            # The data are quantitative if we can convert all the answers to float\n            val = pd.Series([x for x in t if x!='Question not applicable']).astype(float).dropna()\n            dec = pd.Series(index = val.index, data = pd.qcut(val.values, 10, labels=False, duplicates='drop'))\n            colType.append('quant')\n            colDec.append(pd.concat([val.rename(0),dec.rename(1)], axis=1))\n            \n        except:\n            # If at least one of the answers cannot be convert to numeric type, then the type is categorial\n            colType.append('cat')\n            colDec.append(pd.DataFrame())\n    \n    # For each column of interest, we compute the score of every respondent\n    df_city = pd.DataFrame(index = df['Account'].unique(), columns = df.columns[columns])\n    \n    for k,n in enumerate(columns):\n        \n        # If we entered model cities, we compute the particular frequencies amongst their answer only\n        if len(models)>0:\n            model_idx = [df.index[i] for i in df.index if df.loc[i,'Account'] in models]\n            model_data = df.loc[model_idx, df.columns[n]]\n            \n            t_model = [list(item.keys()) for item in model_data if isinstance(item, dict)]\n            t_model = [item for sublist in t_model for item in sublist]\n            c_model = remove_dictKey(dict(Counter(t_model)), 'Question not applicable')\n            \n        for ct in df_city.index:\n            \n            # Quantitative Data\n            # We get the decile corresponding to the city answer\n            # If the orientation of the question is negative, we inverse the decile in order \n            # to give a higher score to the cities with the lowest answers\n            if colType[k]=='quant':\n                decs = colDec[k]\n                try: \n                    if isRep:\n                        val = float(df.loc[df['Account']==ct, df.columns[n]].values[0])\n                    else:\n                        val = float(list(df.loc[df['Account']==ct, df.columns[n]].values[0])[0])\n                    df_city.loc[ct, df.columns[n]] = decs[decs[0]==val].iloc[0,1]\n                    if colPos[k]==0:\n                        df_city.loc[ct, df.columns[n]] = 9-df_city.loc[ct, df.columns[n]]\n                except:\n                    df_city.loc[ct, df.columns[n]] = np.nan\n                    \n            # Categorial Data\n            # We determine the sub-type of the column to compute the score\n            else:\n                # set the weighting scheme\n                w = np.ones(len(Count[k]))\/np.sum([x for x in Count[k].values()])\n                if n in weights.keys():\n                    if len(weights[n])==len(Count[k]):\n                        w = weights[n]\n\n                try: \n                    # The answer is not empty\n                    if type(df.loc[df.index[df['Account']==ct].values[0], df.columns[n]])==dict:\n                        # The city was eligible for the question\n                        if len(remove_dictKey(df.loc[df.index[df['Account']==ct].values[0], df.columns[n]],'Question not applicable'))>0:\n                            \n                            isRank = np.sum([(x in unique_answer) for x in list(Count[k])])==len(list(Count[k]))\n                            \n                            # Gradable categories\n                            # We weight the number of answers by their relative scores in unique_value\n                            if isRank:\n                                df_city.loc[ct, df.columns[n]] = np.sum([unique_answer[x] for x in df.loc[df['Account']==ct, df.columns[n]].values[0]])\/np.sqrt(len(Count[k]))\n                            else:\n                            \n                                # Ungradable categories with similar orientation\n                                # We count the number of chosen categories\n                                if type(colPos[k])==int:\n                                    df_city.loc[ct, df.columns[n]] = len(df.loc[df['Account']==ct, df.columns[n]].values[0])\/len(Count[k])\n                                    if colPos[k]==0:\n                                        df_city.loc[ct, df.columns[n]]=1-df_city.loc[ct, df.columns[n]]\n                                \n                                else:\n                                # Ungradable categories with different orientations\n                                # If the list of model cities is empty, we weight the number of categories \n                                # by their relative frequency in the whole set of answers\n                                # If the list of model cities is not empty, we weight the number of of categories \n                                # by their relative frequency in the set of answers from the model cities\n                                    if len(models) == 0:\n                                        df_city.loc[ct, df.columns[n]] = np.sum([Count[k][x]*w[i]  for i,x in enumerate(df.loc[df.index[df['Account']==ct].values[0], df.columns[n]].keys())])\n\n                                    else:\n                                        df_city.loc[ct, df.columns[n]] = np.sum([c_model[x]*w[i]  for i,x in enumerate(df.loc[df.index[df['Account']==ct].values[0], df.columns[n]].keys()) if x in list(c_model)])\n\n\n                    # Empty answer         \n                    else:\n                        df_city.loc[ct, df.columns[n]] = 0\n                    \n                                \n                        \n                except Exception as exception:\n                    print(exception.__str__())\n                    df_city.loc[ct, df.columns[n]] = 0\n                    \n                    \n        # We scale our scores to make them comparable  \n        z = (df_city.loc[:, df.columns[n]].max()-df_city.loc[:, df.columns[n]].min())\n        df_city.loc[:, df.columns[n]] = (df_city.loc[:, df.columns[n]]-df_city.loc[:, df.columns[n]].min())\/z\n    \n    return Count, df_city","1c867c2e":"questions = extra_info['Question Number'][extra_info['Which else to Analyse'].notna()]\nquestionsTypes = pd.DataFrame(index = questions, columns = ['questionsType'])\n\ncities_Will_2020_CatAnalysis = pd.DataFrame(index = cities_Will_2020.Account.unique(), columns = questions)\ncities_Will_2020_CatCount = {q:{} for q in questions}\n\nfor q in questions:\n    \n    if type(extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0])==list:\n        cols_study = [int(c) for c in extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    else:\n        cols_study = [extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    \n    colsPos = extra_info[extra_info['Question Number']==q].loc[:,'Is Positive'].values[0] \n    questionsTypes.loc[q, 'questionsType'] = questionType(cities_Will_2020_vWide[q], columns = cols_study, colPos = colsPos)\n\nq_secondAnalysis = questionsTypes.applymap(lambda x: np.sum([i=='cat_noRank_noPos' for i in x])>0)\nq_secondAnalysis = q_secondAnalysis[q_secondAnalysis].dropna().index.values\nq_firstAnalysis = [x for x in questions if x not in q_secondAnalysis]\nq_secondAnalysis","1a8e73fe":"for q in q_firstAnalysis:\n    \n    if type(extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0])==list:\n        cols_study = [int(c) for c in extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    else:\n        cols_study = [extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    \n    colsPos = extra_info[extra_info['Question Number']==q].loc[:,'Is Positive'].values[0] \n    \n    try:\n        catCounter, catAnalysis = Explore_AnalyticData(cities_Will_2020_vWide[q], columns = cols_study, colPos = colsPos)\n        catAnalysis = catAnalysis.mean(axis=1)\n        cities_Will_2020_CatAnalysis.loc[catAnalysis.index, q] = catAnalysis.values\n        cities_Will_2020_CatCount[q] = catCounter\n    except Exception as exception:\n        print(exception.__str__())","259d465f":"cities_Will_2020_CatScore = cities_Will_2020_CatAnalysis.loc[:,q_firstAnalysis].mean(axis=1)\ncities_Will_2020_CatModel = pd.Series(index = cities_Will_2020_CatScore.index, data = pd.qcut(cities_Will_2020_CatScore.values, 10, labels=False, duplicates='drop'))\ncities_Will_2020_CatModel = cities_Will_2020_CatModel[cities_Will_2020_CatModel==9].index.values","aecbcaac":"cities_2020.Organization[cities_2020.Account.isin(list(cities_Will_2020_CatModel))].unique()","12dd8d66":"for q in q_secondAnalysis:\n    if type(extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0])==list:\n        cols_study = [int(c) for c in extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    else:\n        cols_study = [extra_info[extra_info['Question Number']==q].loc[:,'Which else to Analyse'].values[0]]\n    \n    colsPos = extra_info[extra_info['Question Number']==q].loc[:,'Is Positive'].values[0] \n    \n    try:\n        catCounter, catAnalysis = Explore_AnalyticData(cities_Will_2020_vWide[q], columns = cols_study, colPos = colsPos, models = cities_Will_2020_CatModel)\n        catAnalysis = catAnalysis.mean(axis=1)\n        cities_Will_2020_CatAnalysis.loc[catAnalysis.index, q] = catAnalysis.values\n        cities_Will_2020_CatCount[q] = catCounter\n    except Exception as exception:\n        print(exception.__str__())\n        \n# cities_Will_2020_CatAnalysis.to_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_CatAnalysis.pkl')\n\n# with open('..\/input\/cdp-inputs-final\/cities_Will_2020_CatCount.pkl', 'wb') as handle:\n#     pickle.dump(cities_Will_2020_CatCount, handle, protocol=pickle.HIGHEST_PROTOCOL)","96b58548":"def Explore_Textdata(df, niv_ref=np.nan, niv_text=np.nan):\n    \n    # We build a fonction that reshape for a given question all free text answers into a single string. It is possible \n    # to specify a reference sub-question to analyse free text answers based on the sub-question topics.\n    \n    # the output is a dictionary of dataframes with either 'All' as the single key if no sub-question has been given as \n    # reference or sub-question topics as keys.\n\n    #\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"args:\n    # niv_ref=np.nan # Column number from the main dataset to define as reference\n    # niv_text=np.nan # Column number from the main dataset to define as free text answers\n    # ATTENTION: We define the column numbers as the one in the original CDP questionnaire. It is easy to find when reading \n    # the .pdf file.    \n    \n    # Cas o\u00f9 il n'y a pas de colonne de r\u00e9f\u00e9rence. ie. on souhaite r\u00e9cup\u00e9rer tout le texte disponible dans une grande matrice.\n    if np.isnan(niv_ref):\n        \n        # On r\u00e9cup\u00e8re l'ensemble du texte associ\u00e9 \u00e0 la question\n        if np.isnan(niv_text):\n            text = list(df.iloc[:,(df.shape[1]-1)]) \n        else:\n            text = list(df.iloc[:,(2+niv_text)])\n        \n        # On transforme en dataframe\n        output = []\n        for n in range(len(df.Account)):\n            d = text[n]\n            if isinstance(d, dict):\n                # Ici on met toutes les r\u00e9ponses d'une ville sur une th\u00e9matique dans un grand string.\n                output.append(' '.join(list(d.keys())) if (len(list(d.keys()))>1) else list(d.keys())[0])\n            else:\n                output.append('')\n        # On transforme output vers un dataframe        \n        output_d = {'Account': df.Account, 'Response Answer': output}\n        output_d = pd.DataFrame(output_d)\n        output_d.dropna(inplace=True) # drop na\n\n        # On ne conserve que les donn\u00e9es en anglais.\n        output_d = pd.merge(output_d, isEnglish_df, on='Account', how='inner')\n        del output_d['isEnglish']\n        output_d = output_d[output_d['Response Answer'].apply(lambda x: isinstance(x, str) and \n                                                              len(x)>1 and x!='Question not applicable')]\n\n        # On nettoie le texte\n        output_d['Response Answer'] = output_d['Response Answer'].map(lambda x: cleanData(x))\n        output_d['Response Answer ToL'] = output_d['Response Answer'].map(lambda x: cleanData(x, to_list=True))\n        # On reset l'index\n        output_d.reset_index(drop=True, inplace=True)\n\n        text_per_category = output_d   \n    \n    # Cas o\u00f9 il y a une colonne de r\u00e9f\u00e9rence, permettant de filtrer les r\u00e9ponses textuelles dans diff\u00e9rentes cat\u00e9gories.\n    else:\n        \n        # On r\u00e9cup\u00e8re la fr\u00e9quence d'appartition des cat\u00e9gories\n        Count = []\n        for n in range(2,(df.shape[1]-1)):\n            data = df.iloc[:,n]\n            t = [list(item.keys()) for item in data if isinstance(item, dict)]\n            t = [item for sublist in t for item in sublist]\n            Count.append(dict(Counter(t)))\n\n        # On r\u00e9cup\u00e8re les textes par cat\u00e9gories les plus g\u00e9n\u00e9rales\n        # liste des catg\u00e9ories\n        all_refs = list(Count[niv_ref].keys()) \n        if 'Question not applicable' in all_refs:\n            all_refs.remove('Question not applicable')\n        ref_vect = list(df.iloc[:,2+niv_ref])\n\n        all_refs_text = []\n\n        for item_ref in all_refs:\n            \n            print('Category for text selection :', item_ref)\n            \n            # On r\u00e9cup\u00e8re l'indice des lignes par entreprise qui traitent de item_ref\n            idx = []\n            for i in ref_vect:\n                if isinstance(i, dict):\n                    idx.append([i[k] for k in list(i.keys()) if k == item_ref])\n                else:\n                    idx.append([])\n\n            idx_notEmpty = [i for i, x in enumerate(idx) if x]\n            Account_With_Text = list(df.Account[idx_notEmpty])\n            idx = [idx[i] for i in idx_notEmpty] \n\n            # On r\u00e9cup\u00e8re l'ensemble du texte associ\u00e9 \u00e0 la question\n            if np.isnan(niv_text):\n                text = list(df.iloc[:,(df.shape[1]-1)]) \n            else:\n                text = list(df.iloc[:,(2+niv_text)])\n\n            # On filtre sur les entreprises qui traitent d'item_ref\n            res_list = [text[i] for i in idx_notEmpty] \n\n            # On filtre sur les textes qui traitent d'item_ref et on raccroche aux entreprises\n            output = []\n            for n in range(len(Account_With_Text)):\n                d = res_list[n]\n                if isinstance(d, dict):\n                    # Ici on met toutes les r\u00e9ponses d'une ville sur une th\u00e9matique dans un grand string en ne conservant \n                    # que ce qui est du texte (format str).\n                    output.append(' '.join([list(d.keys())[k] for k in range(len(d)) if \n                                            (list(d.values())[k][0] in idx[n][0]) and isinstance(list(d.keys())[k], str)]))\n                else:\n                    output.append('')\n            # On transforme output vers un dataframe        \n            output_d = {'Account': Account_With_Text, 'Response Answer': output}\n            output_d = pd.DataFrame(output_d)\n            output_d.dropna(inplace=True) # drop na\n\n            # On ne conserve que les donn\u00e9es en anglais.\n            output_d = pd.merge(output_d, isEnglish_df, on='Account', how='inner')\n            del output_d['isEnglish']\n            output_d = output_d[output_d['Response Answer'].apply(lambda x: isinstance(x, str) and \n                                                                  len(x)>1 and x!='Question not applicable')]\n            if not output_d.empty:\n                # On nettoie le texte\n                output_d['Response Answer'] = output_d['Response Answer'].apply(lambda x: cleanData(x))\n                output_d['Response Answer ToL'] = output_d['Response Answer'].apply(lambda x: cleanData(x, to_list=True))\n                # On reset l'index\n                output_d.reset_index(drop=True, inplace=True)\n\n            all_refs_text.append(output_d)\n\n        text_per_category = dict(zip(all_refs, all_refs_text))\n        \n    return text_per_category","d4b71fd4":"# Exemple for question '6.0'\nExplore_Td_6_0 = Explore_Textdata(df_6_0,niv_ref=0, niv_text=1)\nExplore_Td_6_0['Development of energy efficiency measures and technologies'].head(5)","dc6627d8":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndef Compute_weights(corpus, type = \"tf_idf\"):\n    \n    if not ((isinstance(corpus, list) and isinstance(corpus[0], str)) \n            or (isinstance(corpus,  pd.Series) and isinstance(corpus[0],  dict))):\n        print(\"Corpus must be either a list of strings or a series of dict with words as keys.\")\n        return\n    \n    def dict_to_string(x):\n        if isinstance(x,dict):\n            res = ' '.join(x.keys())\n        else:\n            res = ''\n        return res\n        \n    if (isinstance(corpus,  pd.Series) and isinstance(corpus[0],  dict)):\n        corpus = list(corpus.map(lambda x: dict_to_string(x)))\n    \n    if type==\"tf_idf\":\n        # Tf-Idf\n        vectorizer = TfidfVectorizer()\n        got_tfidf = vectorizer.fit_transform(corpus)\n        tfidf = pd.DataFrame(got_tfidf.toarray())\n        tfidf.columns = vectorizer.get_feature_names()\n\n        weights = dict(zip(tfidf.columns, tfidf.mean(axis = 0)))\n    else:\n        print(\"type : corpus frequency\")  \n        # Corpus freq\n        bow = CountVectorizer()\n        BOW = bow.fit_transform(corpus)\n        bagOFwords = pd.DataFrame(BOW.toarray())\n        bagOFwords.columns = bow.get_feature_names()\n\n        weights = dict(zip(bagOFwords.columns, bagOFwords.mean(axis = 0)))\n\n    return weights","efe81165":"from nltk.corpus import wordnet as wn\nnltk.download('sentiwordnet')\nfrom nltk.corpus import sentiwordnet as swn","9f13210d":"def spacy_to_wn(tag):\n    \"\"\"\n    Convert between the Spacy tags to simple Wordnet tags\n    \"\"\"\n    if tag.startswith('ADJ'):\n        return wn.ADJ\n    elif tag.startswith('N'):\n        return wn.NOUN\n    elif tag.startswith('ADV'):\n        return wn.ADV\n    elif tag.startswith('V'):\n        return wn.VERB\n    else:\n        return None","3b8c6959":"def Wordnet_sentiment(sentence, weights=np.nan):\n        \n    if not isinstance(sentence, dict):\n        print(\"Sentence must be cleaned in a dict format with pos tags\")\n        return np.nan\n    \n    if not isinstance(weights,dict):\n#         print(\"Equal weights will be given to words\")\n        weights = dict(zip(list(sentence.keys()), np.ones(len(sentence))))\n    \n    if not sentence:\n        # Dans le cas o\u00f9 le texte est vide\n        score = np.nan\n        \n    else:\n\n        # 1) On r\u00e9cup\u00e8re le sentiment de chaque mot.\n        sentiment = []\n\n        for word, pos_tag in sentence.items():\n            synsets = wn.synsets(word, pos=spacy_to_wn(pos_tag))\n            if synsets:\n                # Take the first sense, the most common\n                synset = synsets[0]\n                swn_synset = swn.senti_synset(synset.name())\n#                 sentiment.append([swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()])\n                sentiment.append(swn_synset.pos_score() - swn_synset.neg_score())\n            else:\n#                 sentiment.append([])\n                sentiment.append(0)\n\n        # 2) On pond\u00e8re les mots par un vecteur donn\u00e9 en argument\n        score = 0\n        tokens_count = 0\n        for i in range(len(sentiment)):\n            if list(sentence.keys())[i] in weights.keys():\n                score += sentiment[i]*weights[list(sentence.keys())[i]]               \n            if sentiment[i]!=0:\n                tokens_count +=1\n\n        # 3) On normalise le score par la taille de la phrase. En ne comptant que les mots ayant un impact.\n        if tokens_count!=0:\n            score = score\/tokens_count\n            \n    return score","f3964b5a":"!pip install twython","8b643de3":"nltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","0c22d679":"def Vader_sentiment(sentence, weights=np.nan):\n    sid = SentimentIntensityAnalyzer()\n    \n    if isinstance(sentence,dict) and bool(sentence):\n        sentence = list(sentence.keys())\n    \n    if isinstance(sentence, list):\n        \n        if not isinstance(weights,dict):\n            weights = dict(zip(sentence, np.ones(len(sentence))))  \n        \n        # 1) On r\u00e9cup\u00e8re le sentiment de chaque mot.\n        sentiment = []\n        for word in sentence:\n            sentiment.append(sid.polarity_scores(word)['compound'])\n\n        # 2) On pond\u00e8re les mots par un vecteur donn\u00e9 en argument\n        score = 0\n        tokens_count = 0\n        for i in range(len(sentiment)):\n            if sentence[i] in weights.keys():\n                score += sentiment[i]*weights[sentence[i]]               \n            if sentiment[i]!=0:\n                tokens_count +=1\n    \n        # 3) On normalise le score par la taille de la phrase. En ne comptant que les mots ayant un impact.\n        if tokens_count!=0:\n            score = score\/tokens_count\n            \n    elif (isinstance(sentence, str) and len(list(sentence.split(\" \")))>1):\n        score = sid.polarity_scores(sentence)['compound']\n    \n    else:\n        score = np.nan\n            \n    return score   ","51892e48":"def Score2Label(scores,*tau):\n    q = []\n    for t in tau:\n        q.append(np.nanquantile(scores,t))\n    \n    q.sort()\n    \n    label = np.empty(len(scores))\n    label[:] = np.nan\n    \n    label[scores<q[0]] = 0\n    for i in range(len(q)-1):\n        label[(q[i]<=scores) & (scores<q[i+1])] = (i+1)  \n    label[scores>q[-1]] = len(q)\n    \n    return label.astype(float)","cbd4caf0":"def Apply_Sentiment_Analysis(df):\n    \n    df_new = {}\n    \n    if not isinstance(df, dict):\n        df = {'All': df}\n        \n    # On travaille th\u00e9matiques par th\u00e9matiques\n    for thematic in df.keys():\n        \n        if not df[thematic].empty:\n        \n            df_small = df[thematic].copy()\n\n            # On cr\u00e9er une s\u00e9rie des r\u00e9ponses sous forme de dict pour le calcul du vecteur tf-idf. Pour cela on reset \n            # l'idx de cette s\u00e9rie\n            answer_dict = df_small['Response Answer ToL']            \n            answer_dict.reset_index(drop=True, inplace=True)\n            answer_dict = pd.Series([i for i in answer_dict.dropna() if i])\n            # On calcule le vecteur tf-idf sur l'ensemble des r\u00e9ponses \u00e0 la question.\n            tfidf_weights = Compute_weights(answer_dict)\n            # On calcule les sentiments \u00e0 partir de ces poids\n            WordNet_EQ = df_small['Response Answer ToL'].map(lambda x: Wordnet_sentiment(x, weights=\"EQ\"))\n            WordNet_TFIDF = df_small['Response Answer ToL'].map(lambda x: Wordnet_sentiment(x, weights=tfidf_weights))\n            Vader_TFIDF = df_small['Response Answer ToL'].map(lambda x: Vader_sentiment(x, weights=tfidf_weights))\n            Vader = df_small['Response Answer'].map(lambda x: Vader_sentiment(x))\n            # On transforme les scores en labels.\n            WordNet_EQ = Score2Label(WordNet_EQ, 0.2, 0.4, 0.6, 0.8)\n            WordNet_TFIDF = Score2Label(WordNet_TFIDF, 0.2, 0.4, 0.6, 0.8)\n            Vader_TFIDF = Score2Label(Vader_TFIDF, 0.2, 0.4, 0.6, 0.8)\n            Vader = Score2Label(Vader, 0.2, 0.4, 0.6, 0.8)\n            # On applique le vote \u00e0 mojorit\u00e9 pour le choix du label\n            Sentiment_df = pd.DataFrame({'Wordnet_EQ': WordNet_EQ, 'Wordnet_TFIDF':WordNet_TFIDF, \n                                             'Vader_TFIDF':Vader_TFIDF, 'Vader': Vader})\n            df_small['Sentiment'] = Sentiment_df.apply(lambda x: Counter(x).most_common()[0][0], axis = 1)\n\n            df_new[thematic] = df_small\n        \n        else:\n            df_new[thematic] = pd.DataFrame()\n\n    return df_new","a4b49c57":"cities_Will_2020_SentimentAnalysis = []\nquestions = []\n# Question to analyse\nfor q in extra_info['Question Number'][extra_info['Which Is Text to Analyse'].notna()]:\n    \n    if q not in []:\n    \n        print('Question number', q)\n\n       # Col number for reference categories\n        l_r = extra_info.loc[extra_info['Question Number']==q, 'Text Ref Col'].iloc[0]\n        if isinstance(l_r, list):\n            l_r = int(l_r[0])\n        if not np.isnan(l_r):\n            l_r = int(l_r-1) # to be good with python indexing starting at 0\n\n        # Col number of text\n        l_t = int(extra_info.loc[extra_info['Question Number']==q, 'Which Is Text to Analyse'].iloc[0])-1\n\n        print('Column number ref :', l_r, 'and Column text:', l_t)\n\n        # Get text for the given categories into a dictionary\n        df = Explore_Textdata(cities_Will_2020_vWide[q],niv_ref=l_r, niv_text=l_t)\n\n        # Run sentiment analysis\n        df = Apply_Sentiment_Analysis(df)\n        \n        # Reshape to size of all unique respondent\n        df_new={}\n        for k in df.keys():\n            d = df[k].copy()\n            if not d.empty:\n                df_new[k] = pd.merge(geo_cities_2020, d, on='Account', how='outer')\n                \n        cities_Will_2020_SentimentAnalysis.append(df_new)\n        questions.append(q)\n\ncities_Will_2020_SentimentAnalysis = dict(zip(questions, cities_Will_2020_SentimentAnalysis))   \n\n# with open('..\/input\/cdp-inputs-final\/cities_Will_2020_SentimentAnalysis.pkl', 'wb') as handle:\n#     pickle.dump(cities_Will_2020_SentimentAnalysis, handle, protocol=pickle.HIGHEST_PROTOCOL)","8eedba2c":"from nltk.corpus import stopwords","b2fc6bd7":"def get_wordnet_pos(treebank_tag):\n\n    if treebank_tag.startswith('J'):\n        return wn.ADJ\n    elif treebank_tag.startswith('V'):\n        return wn.VERB\n    elif treebank_tag.startswith('N'):\n        return wn.NOUN\n    elif treebank_tag.startswith('R'):\n        return wn.ADV\n    else:\n        return ''\n    \ndef topics_document_to_dataframe(topics_document, num_topics):\n    res = pd.DataFrame(columns=['Topic ' + str(t) for t in range(num_topics)])\n    for topic_weight in topics_document:\n        res.loc[0, 'Topic ' + str(topic_weight[0])] = topic_weight[1]\n    return res\n\ndef LDA_Analysis(df_source, nb_topics):\n    \n    # We check if there are enough answers to run a LDA\n    if df_source['Response Answer'].value_counts().shape[0]<20:\n        df_source = df_source.loc[:,['Account', 'Response Answer']].dropna().reset_index(drop=True)\n        df_topics = pd.DataFrame(data = np.nan, index = df_source.index, columns = np.append(['Account', 'Response Answer'],['Topic ' + str(x) for x in range(nb_topics)]))\n        df_topics.loc[:, ['Account', 'Response Answer']] = df_source.loc[:, ['Account', 'Response Answer']] \n        lda = {}\n    \n    else:\n    \n        df = df_source.loc[:,['Account', 'Response Answer']].dropna().reset_index(drop=True)\n        df.columns = ['account', 'answer']\n    \n        # Tokenization\n        df['sentences'] = df.answer.map(sent_tokenize)\n        df['tokens_sentences'] = df['sentences'].map(lambda sentences: [word_tokenize(sentence) for sentence in sentences])\n\n        # Lemmatization with POS tagging\n        df['POS_tokens'] = df['tokens_sentences'].map(lambda tokens_sentences: [pos_tag(tokens) for tokens in tokens_sentences])\n\n        # Lemmatizing each word with its POS tag, in each sentence\n        lemmatizer = WordNetLemmatizer()\n        df['tokens_sentences_lemmatized'] = df['POS_tokens'].map(\n            lambda list_tokens_POS: [\n                [\n                    lemmatizer.lemmatize(el[0], get_wordnet_pos(el[1])) \n                    if get_wordnet_pos(el[1]) != '' else el[0] for el in tokens_POS\n                ] \n                for tokens_POS in list_tokens_POS\n            ]\n        )\n\n        # Regrouping tokens and removing stop words\n        stopwords_verbs = ['say', 'get', 'go', 'know', 'may', 'need', 'like', 'make', 'see', 'want', 'come', 'take', 'use', 'would', 'can']\n        stopwords_other = ['one', 'mr', 'bbc', 'image', 'getty', 'de', 'en', 'caption', 'also', 'copyright', 'something']\n#         my_stopwords = stopwords.words('English') + stopwords_verbs + stopwords_other\n        my_stopwords = stopwords.words('english') + stopwords_verbs + stopwords_other\n\n        df['tokens'] = df['tokens_sentences_lemmatized'].map(lambda sentences: list(chain.from_iterable(sentences)))\n        df['tokens'] = df['tokens'].map(lambda tokens: [token.lower() for token in tokens if token.isalpha() and token.lower() not in my_stopwords and len(token)>1])\n\n        # Data preparation - Bi-gram and Tri-gram models\n        tokens = df['tokens'].tolist()\n        bigram_model = Phrases(tokens)\n        trigram_model = Phrases(bigram_model[tokens], min_count=1)\n        tokens = list(trigram_model[bigram_model[tokens]])\n\n        # LDA\n        dictionary_LDA = corpora.Dictionary(tokens)\n        dictionary_LDA.filter_extremes(no_below=3)\n        corpus = [dictionary_LDA.doc2bow(tok) for tok in tokens]\n\n        np.random.seed(2020)\n        lda_model = models.LdaModel(corpus, num_topics=nb_topics, id2word=dictionary_LDA, passes=4, alpha=[0.01]*nb_topics, eta=[0.01]*len(dictionary_LDA.keys()))\n\n\n        # Like TF-IDF, create a matrix of topic weighting, with documents as rows and topics as columns\n        topics = [lda_model[corpus[i]] for i in range(len(df))]\n        document_topic = pd.concat([topics_document_to_dataframe(topics_document, num_topics=nb_topics) for topics_document in topics]).reset_index(drop=True).fillna(0)\n        \n        df_topics = df_source.loc[:,['Account', 'Response Answer']].dropna().reset_index(drop=True)\n        df_topics[['Topic ' + str(x) for x in range(nb_topics)]] = document_topic\n\n        # LDA results\n        lda = {'model': lda_model, 'corpus': corpus, 'dictionary': dictionary_LDA}\n    \n    return df_topics, lda","bec9d84c":"def Apply_LDA_Analysis(df, nb_topics):\n    \n    d_topics = {}\n    d_lda = {}\n    \n    if not isinstance(df, dict):\n        df = {'All': df}\n        \n    # We work thematic by thematic\n    for thematic in df.keys():\n        \n        if not df[thematic].empty:\n            df_small = df[thematic].copy()\n            df_topics, lda = LDA_Analysis(df_small, nb_topics)\n            d_topics[thematic] = df_topics\n            d_lda[thematic] = lda\n            \n        else:\n            d_topics[thematic] = pd.DataFrame()\n            d_lda[thematic] = {}\n\n    return d_topics, d_lda","b787399f":"def LDA_heatmap(lda_df, n_topics):\n    if lda_df.dropna().empty:\n        print('The LDA was not computed')\n    else:\n        document_topic = lda_df.dropna().iloc[:,-n_topics:]\n        sn.set(rc={'figure.figsize':(10,20)})\n        sn.heatmap(document_topic.loc[document_topic.idxmax(axis=1).sort_values().index])\n    \ndef LDA_printTopics(lda_model, n_topics, n_words = 10):\n    if len(lda_model)==0:\n        print('The LDA was not computed')\n    else:\n        lda_model = lda_model['model']\n        for i,topic in lda_model.show_topics(formatted=True, num_topics=n_topics, num_words=n_words):\n            print('Topic ' + str(i)+\": \"+ topic)\n            print()\n        \ndef LDA_visual(lda_model):\n    \n    vis = pyLDAvis.gensim.prepare(topic_model=lda_model['model'], corpus=lda_model['corpus'], dictionary=lda_model['dictionary'])\n    pyLDAvis.enable_notebook()\n    return vis","bfe6cfcb":"nb_topics=3","9caa932f":"cities_Will_2020_LDA_topics = []\ncities_Will_2020_LDA_models = []\nquestions = []\n\n# Question to analyse\nfor q in extra_info['Question Number'][extra_info['Which Is Text to Analyse'].notna()]:\n    \n    if q not in []:\n    \n        print('Question number', q)\n\n        # Col number for reference categories\n        l_r = extra_info.loc[extra_info['Question Number']==q, 'Text Ref Col'].iloc[0]\n        if isinstance(l_r, list):\n            l_r = int(l_r[0])\n        if not np.isnan(l_r):\n            l_r = int(l_r-1) # On se met en phase avec python\n\n        # Col number of text\n        l_t = int(extra_info.loc[extra_info['Question Number']==q, 'Which Is Text to Analyse'].iloc[0])-1\n\n        print('Column number ref :', l_r, 'and Column text:', l_t)\n\n        # Get text for the given categories into a dictionary\n        df = Explore_Textdata(cities_Will_2020_vWide[q],niv_ref=l_r, niv_text=l_t)\n        \n        # Run LDA\n        d_topics, d_lda = Apply_LDA_Analysis(df, nb_topics)\n\n        # Reshape dataframe to size of all unique respondent\n        d_topics_new={}\n        for k in d_topics.keys():\n            d = d_topics[k].copy()\n            if not d.empty:\n                d_topics_new[k] = pd.merge(geo_cities_2020, d, on='Account', how='outer')  \n        cities_Will_2020_LDA_topics.append(d_topics_new)\n        \n        cities_Will_2020_LDA_models.append(d_lda)\n        \n        questions.append(q)\n\ncities_Will_2020_LDA_topics = dict(zip(questions, cities_Will_2020_LDA_topics)) \ncities_Will_2020_LDA_models = dict(zip(questions, cities_Will_2020_LDA_models))  \n\n# with open('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_models.pkl', 'wb') as handle:\n#     pickle.dump(cities_Will_2020_LDA_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n# with open('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_topics.pkl', 'wb') as handle:\n#     pickle.dump(cities_Will_2020_LDA_topics, handle, protocol=pickle.HIGHEST_PROTOCOL)","d10c8b54":"def Question_Pertinence(q, threshold=0.8):\n    \n    sent = []\n    # Check if the answer is categorielle\n    isCat = q in extra_info.loc[extra_info['Which else to Analyse'].notna(), 'Question Number'].values\n    \n    # Check if the answers are text\n    isText = q in extra_info.loc[extra_info['Which Is Text to Analyse'].notna(), 'Question Number'].values\n    \n    # Check if the free text answer has to be separated by categories\n    isFreeText = extra_info.loc[extra_info['Question Number']==q, 'Text Ref Col'].isna().values[0]\n    \n    # Check if the answers are well distributed amongst the potential categories\n    if isCat:\n        max_freq = []\n        cat_count = cities_Will_2020_CatCount[q]\n                    \n        for i in range(len(cat_count)):\n            freq = np.array([x for x in cat_count[i].values()])\/np.sum([x for x in cat_count[i].values()])\n            max_freq.append(max(freq))\n            \n            if min(max_freq)<threshold:\n                question_score = 1.0\n            else: \n                # If the answers are concentrated on one answer, check if the text answers are different\n                if isText:\n                    if max(cat_count[0], key=lambda key: cat_count[0][key])=='Question not applicable':\n                        question_score = 0\n                    else:\n                        if isFreeText:\n                            sent = cities_Will_2020_SentimentAnalysis[q]['All']\n                            sent_freq = (sent.iloc[:, -1].value_counts())\/sum(sent['Sentiment'].notna())\n                            if sent_freq.empty:\n                                sent_freq = pd.Series([0.0, 0.0])\n\n                            # Check topics distribution in the answers\n                            lda_topics = cities_Will_2020_LDA_topics[q]['All']\n                            lda_freq = (lda_topics.iloc[:, -nb_topics:].idxmax(axis=1).value_counts())\/lda_topics.iloc[:, -nb_topics:].dropna(axis=0, how='all').shape[0]\n                            \n                        else:\n                            # Check sentiment distribution in the answers\n                            sent = cities_Will_2020_SentimentAnalysis[q][max(cat_count[0], key=lambda key: cat_count[0][key])]\n    #                         sent_freq = (sent.iloc[:, -1].value_counts())\/sent.shape[0]\n                            sent_freq = (sent.iloc[:, -1].value_counts())\/sum(sent['Sentiment'].notna())\n                            if sent_freq.empty:\n                                sent_freq = pd.Series([0.0, 0.0])\n\n                            # Check topics distribution in the answers\n                            lda_topics = cities_Will_2020_LDA_topics[q][max(cat_count[0], key=lambda key: cat_count[0][key])]\n    #                         lda_freq = (lda_topics.iloc[:, -nb_topics:].idxmax(axis=1).value_counts())\/lda_topics.shape[0]\n                            lda_freq = (lda_topics.iloc[:, -nb_topics:].idxmax(axis=1).value_counts())\/lda_topics.iloc[:, -nb_topics:].dropna(axis=0, how='all').shape[0]\n                        if lda_freq.empty:\n                            lda_freq = pd.Series([0.0, 0.0])\n\n                        if max(max(lda_freq), max(sent_freq))<threshold:\n                            question_score = 1.0\n                        else:\n                            question_score = 1.0 - max(max(lda_freq), max(sent_freq))\n                    \n                else:\n                    question_score = (1.0 - max(max_freq))\n            \n    else:\n        if isText:\n            # Check sentiment distribution in the answers\n            sent = cities_Will_2020_SentimentAnalysis[q]['All']\n#             sent_freq = (sent.iloc[:, -1].value_counts())\/sent.shape[0]\n            sent_freq = (sent.iloc[:, -1].value_counts())\/sum(sent['Sentiment'].notna())\n            if sent_freq.empty:\n                sent_freq = pd.Series([0.0, 0.0])\n                \n            # Check topics distribution in the answers\n            lda_topics = cities_Will_2020_LDA_topics[q]['All']\n#             lda_freq = (lda_topics.iloc[:, -nb_topics:].idxmax(axis=1).value_counts())\/lda_topics.shape[0]\n            lda_freq = (lda_topics.iloc[:, -nb_topics:].idxmax(axis=1).value_counts())\/lda_topics.iloc[:, -nb_topics:].dropna(axis=0, how='all').shape[0]\n            if lda_freq.empty:\n                lda_freq = pd.Series([0.0, 0.0])\n            \n            if max(max(lda_freq), max(sent_freq))<threshold:\n                question_score = 1.0\n            else:\n                question_score = 1.0 - max(max(lda_freq), max(sent_freq))\n    \n        else:\n            question_score = 1.0\n            \n    return question_score","9c00b618":"def Question_Coverage(q):\n    \n    # Determines the number of cities that were eligible to the question\n    # and computes the actual % number of answers (not left blanks)\n    \n    df = cities_Will_2020_vWide[q].iloc[:,2]\n    coverage = (df.shape[0]-np.sum(['Question not applicable' in list(x) for x in df if type(x)==dict]))\n    not_empty_answers = 1-(df.shape[0] - df.dropna().shape[0])\/coverage\n            \n    return coverage\/df.shape[0], not_empty_answers","0e28ca79":"Question_Quality = pd.DataFrame(index = extra_info['Question Number'].unique(), columns = ['Pertinence','Coverage'])\nfor q in extra_info['Question Number'].unique():\n        Question_Quality.loc[q, 'Pertinence'] = Question_Pertinence(q, 0.6)\n        Question_Quality.loc[q, 'Coverage'] = Question_Coverage(q)[0]\n        \n# Question_Quality.to_pickle('..\/input\/cdp-inputs-final\/Questions_Quality.pkl')","44606b85":"def Average_Score_Per_Question(data, nb_col_to_analyse):\n    if not isinstance(data, dict):\n        print('Data do not seem to require any reshape')\n        return\n    # We create an empty dataframe for each question's score\n    All_Scores = geo_cities_2020.copy()\n    \n    # We iterate through each question of the dict\n    for q in data.keys():\n#     for q in ['1.0a', '1.3', '10.7a', '12.3']:\n        # We create an empty dataframe for scores\n        q_scores = data[q][list(data[q].keys())[0]].iloc[:,:1].copy()\n        \n        # We iterate through each category of a given question\n        for cat in data[q].keys():\n            df = data[q][cat].copy()\n            if nb_col_to_analyse>1:\n                qutile = df.iloc[:,-nb_col_to_analyse:].apply(lambda x: np.nanquantile(x,0.5), axis = 0)\n                # If multiple scores per category, we are considering topics analysis. Hence the agregate score is the \n                # sum of topics present in the answer depreciated by the difference between the largest topics and the smallest.\n                df['Score'] = df.iloc[:,-nb_col_to_analyse:].apply(lambda x: sum(x>qutile)*(1-(np.max(x)-np.min(x))) \n                                                                   if not np.isnan(x).any() else np.nan, axis = 1)\n            else:\n                df['Score'] = df.iloc[:,-nb_col_to_analyse:]\n            \n            # Save the data to the question level\n            q_scores = pd.merge(q_scores, df.iloc[:,[0, -1]], on='Account', how='outer')\n        \n        # Average all categories scores to compute a single score per question\n        q_scores['Avg'] = q_scores.iloc[:,1:].apply(lambda x: np.nanmean(x), axis = 1)\n        All_Scores = pd.merge(All_Scores, q_scores.iloc[:,[0, -1]], on='Account', how='outer')\n        All_Scores.rename(columns={'Avg': q}, inplace=True)  \n        \n        del q_scores\n    \n    return All_Scores","185aa5f9":"ities_Will_2020_LDA_topics_Avg = Average_Score_Per_Question(cities_Will_2020_LDA_topics, 3)\ncities_Will_2020_SentimentAnalysis_Avg = Average_Score_Per_Question(cities_Will_2020_SentimentAnalysis, 1)\n# cities_Will_2020_LDA_topics_Avg.to_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_LDA_topics_Avg.pkl')\n# cities_Will_2020_SentimentAnalysis_Avg.to_pickle('..\/input\/cdp-inputs-final\/cities_Will_2020_SentimentAnalysis_Avg.pkl')","5ce8521f":"def weighted_nan_average(x, w):\n    indices = np.array(x.apply(lambda y: ~np.isnan(y)))\n    if sum(indices)>0:\n        out = np.average(np.array(x[indices], dtype='float'), weights = w[indices])\n    else:\n        out = np.nan\n    return out","9bf19af5":"def Compute_Aggregate_Score(X_o,Y_o,Z_o, Approach_weights):\n    # Create output with account informations\n    res = geo_cities_2020.copy()\n    \n    # Rank scores per approach\n    X = X_o.copy()\n    Y = Y_o.copy()\n    Z = Z_o.copy()\n    X.iloc[:,2:] = X.iloc[:,2:].apply(lambda x: x.rank(ascending = True, method = 'dense'))\n    Y.iloc[:,2:] = Y.iloc[:,2:].apply(lambda x: x.rank(ascending = True, method = 'dense'))\n    Z.iloc[:,2:] = Z.iloc[:,2:].apply(lambda x: x.rank(ascending = True, method = 'dense'))\n    \n    # We define a scaler to range oaal rankings between 0 and 1.\n    scaler = MinMaxScaler()\n    \n    # For each question, average ranking over the available approaches\n    for q in extra_info['Question Number'][extra_info.loc[:,['Which Is Text to Analyse' , 'Which else to Analyse']].isna().apply(lambda x: sum(x)<2, axis = 1)]:\n#     for q in ['1.0a']:\n        if q in X.columns:\n            id_X = list(X.columns).index(q)\n            r_X = X.iloc[:,id_X].copy()\n        else:\n            r_X = np.empty([X.shape[0],1])\n            r_X[:]=np.nan\n            r_X = r_X[0]\n        if q in Y.columns:\n            id_Y = list(Y.columns).index(q)\n            r_Y = Y.iloc[:,id_Y].copy()\n        else:\n            r_Y = np.empty([Y.shape[0],1])\n            r_Y[:]=np.nan\n            r_Y = r_Y[0]\n        if q in Z.columns:\n            id_Z = list(Z.columns).index(q)\n            r_Z = Z.iloc[:,id_Z].copy()\n        else:\n            r_Z = np.empty([Z.shape[0],1])\n            r_Z[:]=np.nan\n            r_Z = r_Z[0]\n\n        r_inter = pd.DataFrame([r_X, r_Y, r_Z])        \n        # we Scale all rankings between 0 and 1 for meaningfull averaging\n        r_inter = pd.DataFrame(scaler.fit_transform(r_inter.T)).T\n        \n        # We avreage each approach with specified weights\n#         r_mean = r_inter.apply(lambda x: np.nanmean(x), axis = 0)\n        r_mean = r_inter.apply(lambda x: weighted_nan_average(x, Approach_weights), axis = 0)\n        res[q] = r_mean\n\n    return res","5e9dd6e5":"# Utile pour remettre au m\u00eame niveau que les autres bases\ncities_Will_2020_CatAnalysis.reset_index(drop = False, inplace = True)\ncities_Will_2020_CatAnalysis.rename(columns={'index':'Account'}, inplace=True)\ncities_Will_2020_CatAnalysis = pd.merge(geo_cities_2020, cities_Will_2020_CatAnalysis, on='Account', how='outer')","b5c24b1a":"Scores_All_Questions = Compute_Aggregate_Score(cities_Will_2020_CatAnalysis, cities_Will_2020_LDA_topics_Avg, cities_Will_2020_SentimentAnalysis_Avg, Approach_weights=np.array([0.8, 0.1, 0.1]))\n# Scores_All_Questions.to_pickle('..\/input\/cdp-inputs-final\/cities_2020_Scores_All_Questions.pkl')","96f70110":"# Subset data per SDGs macro-theme\nPlanet_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'Planet' in x if isinstance(x, list) else False)])\nPlanet_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Planet_questions].copy()\n\nProsperity_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'Prosperity' in x if isinstance(x, list) else False)])\nProsperity_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Prosperity_questions].copy()\n\nSocial_questions = list(extra_info['Question Number'][extra_info['SDGs'].apply(lambda x: 'SocialJustice' in x if isinstance(x, list) else False)])\nSocial_Scores = Scores_All_Questions.loc[:, ['Account', 'City Location'] + Social_questions].copy()","48366dca":"# Compute average score per macro-theme\nweights_Planet = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Planet_Scores.columns[2:]]])\nPlanet_Scores['KPI'] = Planet_Scores.apply(lambda x: weighted_nan_average(x[2:], weights_Planet), axis = 1)\n\nweights_Prosperity = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Prosperity_Scores.columns[2:]]])\nProsperity_Scores['KPI'] = Prosperity_Scores.apply(lambda x: weighted_nan_average(x[2:], w = weights_Prosperity), axis = 1)\n\nweights_Social = np.array([float(Question_Quality.Pertinence.iloc[w]) for w in [list(Question_Quality.index).index(q) for q in Social_Scores.columns[2:]]])\nSocial_Scores['KPI'] = Social_Scores.apply(lambda x: weighted_nan_average(x[2:], w = weights_Social), axis = 1)","51f36e08":"<p style=\"text-align:justify;\">We can see that coverage and pertinence are not much related. It is consistent with our definition because some questions apply to very specific cases. Hence, our pertinence score appears more able to capture the question's quality than only the proportion of answers. <\/p>\n\n<p style=\"text-align:justify;\">In particular, we can read on this chart that questions 2.1a, 2.1b, and 2.1b have the same coverage because the same cities were asked these questions,but they do not all have the same relevance score because the answers differ. Precisely what we are showing is that the coverage is not a good measure of relevance: we can have weak coverage with few cities responding but a wide variety of responses conveying informations, whence a relevance of 1 for 2.1b and 2.1c even with low coverage.<\/p>","7ba63588":"We articulate these three goals in the following methodology:","9f8b778c":"<a id=\"Free-text\"><\/a>\n### 2.2.2 Free text answers: Unsupervised Sentiment and Topics Scoring","17e587d5":"To sum things up, we have the following data sources to exploit from our automated data mining process:\n\n* ***cities_Will_2020_CatAnalysis*** : categorical and quantitative questions scores\n\n* <p style=\"text-align:justify;\"><em><b>cities_Will_2020_SentimentAnalysis<\/b><\/em> : sentiment on qualitative questions. For each respondent, we still have to combine the sentiment of each sub-question to create a final sentiment per question. Each sentiment being between 0 and 2 we can average them to the question level and still compare sentiment between questions.<\/p>\n\n* <p style=\"text-align:justify;\"><em><b>cities_Will_2020_LDA_topics<\/b><\/em> : topics raised in qualitative questions. For each sub-question we have a distribution of topics among each answer. We set the score as the product between the number of captured topics in the answer and the difference between the maximum and the difference in the probaility distribution. Hence this foster answers which captures the maximum of topics equally. Of course the final score per question is comparable between questions.\n\n<p style=\"text-align:justify;\">We first combine the score for the <b>sentiment and topics analyses<\/b> to the question level. Each sub-questions' score is comparable to others since they are either class or density. Hence we simply average scores per sub-question to come up with quesions' scores.","6f879ef2":"For each question, we aim at creating an ambition score per respondent. \n\n<p style=\"text-align:justify;\">We first distinguish between data that are directly analyzable (<em>analytical answers<\/em>) and data that will require particular processing (<em>free text answers<\/em>). For the free text answers we apply:<\/p>\n\n* <p style=\"text-align:justify;\"><b>Sentiment analysis:<\/b> It aims to capture the mindset of the respondent. Does he emphasise its actions to mitigate risk, promote new policies and projects or simply gives a list of what is being done, with no real beliefs on the matter?<\/p>\n\n* <p style=\"text-align:justify;\"><b>Topics analysis:<\/b> It aims to assess the respondent ability to fully capture the scope of the question. For a given, specific question, did the respondent write about the main topics that other respondent mentioned in their answers to the same question?<\/p>\n\nEach type of answers is then treated differently following the process presented hereafter.","a3377968":"### 1.2.2 From SDG to macro-theme KPIs","f726203d":"##### C) Vader sentiment analysis","6267c75a":"We then computes the scores for the questions that do not require model cities","7ad74398":"<a id=\"Political\"><\/a>\n## 3.4 Solutions recommendations","3927614d":"<p style=\"text-align:justify;\">To illustrate the pertinence of our approach next, we present an exemple of the topics identified in the corpus of question 6.0 about the \"<em>Development of sustainable transport sector<\/em>\".<\/p>\n\n<p style=\"text-align:justify;\">Althoug the first topic seems to be predominant in the answers, all three are clearly identified and justified. Indeed, by looking at the most relevant terms for each topics, we can conclude that their meanings are as follow:<\/p>\n\n* Topic 1: Personal vehicule and electric transportation\n* Topic 2: Active transportation \/ clean transportation\n* Topic 3: Public transport and infrastructure","77270d39":"<p style=\"text-align:justify;\">We propose to use our risk and ambition scores to generate political recommendations cities given a set of property. To make these solutions accessible to any cities, we chose to construct cluster on external bases only (answering the CDP is not a requirement to be assigned a cluster). <\/p>\n\n<p style=\"text-align:justify;\">We performed a clustering on the climate and geological conditions using a Gaussian finite mixture model fitted by EM algorithm and based on a principal component analysis on climate and geological conditions of respondents (see Appendix). We use one year of the following average monthly informations:<\/p>\n\n* Soil moisture (0-10, 10-40 and 40-100cm)\n* Total precipitation rate\n* Surface and air temperature\n* Snow precipitation rate\n* Wind speed\n* Surface albedo (sunlight reflection)\n* Specific Humidity\n* Total available water capacity (mm water per 1 m soil depth)\n* Soil organic carbon density (kg C\/m2 for 0-30cm depth range)\n* Soil organic carbon density (kg C\/m2 for 0-100cm depth range)\n* Soil carbonate carbon density (kg C\/m2 for 0-100cm depth range)\n* Soil pH (0-30 cm depth range)\n* Soil pH (30-100 cm depth range)\n\n<p style=\"text-align:justify;\">Based on this information set, we retrieved the principal components and define clusters that can be used for non-responding cities as well. For instance, a city could be interested in insights into what ambitious cities facing similar challenges are doing. <\/p>\n\n<p style=\"text-align:justify;\">We can see on the following map that clusters are grouped per latitude which is an indicator of quality for the climate clusters. Note that we could easily encompass Risk KPIs in the clustering process if we wanted to restrict the analysis on respondents only.<\/p>","aee539a7":"##### B) Wordnet sentiment analysis","54d45f03":"We check the coherence of the results before going forward with the process.","685a77c7":"#### 2.2.2.1 Unsupervised Sentiment Analysis","1c5052d8":"#### 2.2.2.2. Unsupervised Topics analysis\n\nAs explain previously, the idea is to obtain the addressed topics in a specific sub-question and then identify if a given answer captures them all by retrieving each topic's density in the answer.\n\n<a id=\"Utils-top\"><\/a>\n##### Utils\n\n[Back to the main section](#U-Top)","4b713e50":"<p style=\"text-align:justify;\">In this section we present the methodology for constructing risk exposure KPIs. We illustrate this methodology through the example of the KPI of the macro-theme \"Planet\". Within each macro-theme, we have defined sub-components around the relevant SDGs. For example, for the macro-theme \"Planet\", we built the scores for the following SDGs: water (6), energy (7), climate change (13), biodiversity (14 and 15). Each SDG score is built from relevant variables from CDP and external databases.<\/p>","9511cab5":"<a id=\"Quality\"><\/a>\n### 2.2.3. Questions' pertinence","946be4a2":"We further build a function for text cleaning.","1a9054f5":"<p style=\"text-align:justify;\">We then use the five top cities in this sample and look at their answers for some questions that could be of interests for cities wanting to change their adaptation strategies.<\/p>\n    \n<p style=\"text-align:justify;\">The example proposed below focuses on Planet Risk and Ambitions to tackle related issues. We illustrate our results on two questions for city that would be placed in the second group of our clustering. These cities mostly are located around or below the Tropic of Capricorne.<\/p>","86043fb0":"### 2.3.2. Combine scores to SDGs macro-themes level","d9e1b416":"### 1.1.2 External databases","a8ce5dab":"<p style=\"text-align:justify;\">We build a fonction that reshapes and cleans for a given question all free text answers into a single string. It is possible to specify a reference sub-question to analyse free text answers based on the sub-question topics.<\/p>\n\n<p style=\"text-align:justify;\">This approach is relevant for topics and sentiment analysis as we can compare answers between cities while filtering on topics. For topics analysis, using LDA for instance, it avoids finding the sub-question topics and rather allows to truly identify common topics among responses.<\/p>\n\nAll details are given in the dedicated [section](#Text-explore) of the appendix.","6946ce8f":"<a id=\"Utils-cat\"><\/a>\n#### Utils\nWe now adds some functions that are going to help us determine the type of answers and computes the scores.","6f64f84a":"The macro-theme scores are based on the following variables:\n\n| Prosperity  | Planet| Social|\n| :---        | :---- | :---- |\n|- (CDP.2.2.) Budgetary capacity <br>- (CDP.2.2.) Cost of living<br> - (CDP.2.2.) Economic diversity <br>- (CDP.2.2.) Economic health <br>- (CDP.2.2.) Infrastructure capacity <br>- (CDP.2.2.) Infrastructure conditions \/ maintenance<br> - (CDP.2.2.) Underemployment<br>- (CDP.2.2.) Unemployment<br>- Population<br>- (UN8.1.1) Annual growth rate of <br>real GDP per capita (%)<br>- (UN9.2.1) Manufacturing value added as a <br>proportion of GDP (%)| Equally weighted <br>construction based on the <br>- biodiversity ,<br> - water,<br>- energy and<br>- physical score<br> detailed above| - (NDG) Food <br>- (NDG) Health  <br> - (UN3.9.1) Mortality  Age-standardized mortality rate<br> attributed to household and ambient air pollution <br>(deaths per 100,000 population)<br>- (UN3.9.2) Mortality rate attributed to unsafe <br>water, unsafe sanitation and lack of<br> hygiene <br>(deaths per 100,000 population) <br>- (UN14.2a) Higher water prices <br> - (CDP2.2) Unemployment <br> - (UN7.1.1) Proportion of population with access<br> to electricity, by urban\/rural (%)|","9490240f":"[Back to Table of Contents](#ToC)\n\n<a id=\"Conclusion\"><\/a>\n# Conclusion","0e22aa71":"The score of city *i* on a specific macro-theme is then :\n\\begin{equation}\n    KPI_{s,i} = \\sum_{q=1}^{Q} Pertinence_q * Score_{q,i}\n\\end{equation}\n\nWith **Q** the number of relevant questions for specific macro-theme and $Pertinence_q$ corresponding to quesion q assessed quality.","d4006717":"<a id=\"Ambition-score-by-question\"><\/a>\n## 2.2. Ambition Scores by question","f93e469a":"Hence, some of the questions that these KPIs may help to answer could be:\n\n- <p style=\"text-align:justify;\">How do you help cities adapt to a rapidly changing climate amidst a global pandemic, but do it in a way that is socially equitable?<\/p>\n\n- <p style=\"text-align:justify;\">What are the projects that can be invested in that will help pull cities out of a recession, mitigate climate issues, but not perpetuate racial\/social inequities?<\/p>\n\n- <p style=\"text-align:justify;\">What are the practical and actionable points where city and corporate ambition join, i.e. where do cities have problems that corporations affected by those problems could solve, and vice versa?<\/p>\n\n- <p style=\"text-align:justify;\">How can we measure the intersection between environmental risks and social equity, as a contributor to resiliency?<\/p>","4a7aaedd":"<p style=\"text-align:justify;\">Next is an exemple of question 6.0 output for the sub-question on opportunities regarding the Development of energy efficiency measures and technologies. <\/p>\n\n<p style=\"text-align:justify;\">Question 6.0 asks: \"<em>Please indicate the opportunities your city has identified as a result of addressing climate change and describe how the city is positioning itself to take advantage of these opportunities.<\/em>\"<\/p>\n\n<p style=\"text-align:justify;\">We give three examples of free text answers with their sentiment score. One clearly see a difference in the way repondents answer the question:<\/p>\n\n* \"*LED lighting upgrades - Municipal buildings and street lights*\" : **Sentiment Score = 0** (index 23);\n\n* <p style=\"text-align:justify;\">\"<em>The City is looking for new opportunities within the clean technology business like implementing electrical vehicle chargers and enrolling all the residents and municipal accounts into East Bay Community Energy's 100 Renewable plan.<\/em>\" : <b>Sentiment Score = 2<\/b> (index 38);<\/p>\n\n* <p style=\"text-align:justify;\">\"<em>The Regional Energy System Operator (RESO) project delivers a smart local energy system design for Coventry and a viable business model using an approach that can be replicated across the wider region. The cost effective project will assist Coventry in decarbonising to align with West Midlands 2041 targets. Coventry won a national competition as the location of a new Battery Industrialisation Centre which hopes to be the centre of excellence in battery technologies, aimed specifically at electric car energy storage.<\/em>\" : <b>Sentiment Score = 4<\/b> (index = 33)<\/p>","1be875c6":"##### D) From Score to Label","30e0e81f":"<a id=\"KPIs-compilation\"><\/a>\n## 2.3. Ambition KPIs by macro-theme","dcdccb2a":"<p style=\"text-align:justify;\">The map above conveys the same conclusions that different trends appear in the ambition on the Planet macro-theme. However there are some exceptions, based on several factors, the geographic situation for instance.","16c235bd":"<p style=\"text-align:justify;\">We quickly control the final output of this process. Since we have one score per question for all cities who answered, a quick way is to average all score to the city level and then visualise the top 10 and bottom 10 cities and the distribution of all scores.<\/p>","41562290":"## Appendices 1. Risk Scores","23b85a49":"### Contextualizing the challenge\n\n#### Topics: the need for an holistic approach to tackle *grand challenges*\n\n<p style=\"text-align:justify;\">Although the CDP has historically focused on climate issues, its questionnaires have regularly evolved to incorporate social and economic issues. This development is part of an overall trend of changing issues facing decision-makers in cities and companies. Formerly confronted with <em>local<\/em> problems, mainly related to the direct consequences of their activities, they are now involved in global and interconnected issues such as climate change, pandemics. This new type of societal issues has been conceptualised under the terms of <em>grand challenges<\/em>. Grand challenges differ from tame problems in three ways: they are complex, uncertain and evaluative <a href=\"https:\/\/www.researchgate.net\/publication\/272788893_Tackling_Grand_Challenges_Pragmatically_Robust_Action_Revisited\">(Ferraro et al., 2015)<\/a>. They can be defined as <em>\u2019specific critical barriers that, if removed, would help solve an important societal problem with a high likelihood of global impact through widespread implementation\u2019<\/em> <a href=\"https:\/\/journals.aom.org\/doi\/10.5465\/amj.2016.4007\">(George et al., 2016)<\/a>. Being complex means that they are inseparable, such as the holistic vision proposed by the 17 sustainable development goals from the United Nations (see below). <\/p>\n\n<p style=\"text-align:justify;\">The case of 'yellow vests' (2018) - opposed to an increase in the French carbon tax - illustrates the need to integrate social issues into the energy transition plans. More recently, the COVID-19  crisis has shown one of the underestimated impacts of climate change and the importance of health system resilience. On this specific concer, the only real performance indicator -or at least one that facilitates the management of this crisis - seems to be hospital capacity. We do not have enough hindsight on these situations and local management to draw relevant indicators and, more generally, we have too little data on this subject to properly address the risk of an infectious wave. However, it is noteworthy that this risk is now fully identified by respondents as early as the 2020 questionnaires. Although we focus on climate issues, we have therefore tried throughout our study to integrate these social and economic issues. <\/p>","b562c076":"<p style=\"text-align:justify;\">From a risk exposure perspective, the question we considered most relevant to the CDP questionnaire is the question 2.1. where respondents are asked to list <em>the most significant climate hazards faced by [their] city<\/em>. For each potential hazard, cities must report the probability of occurrence and the magnitude of the impact. The SDG 13 risk exposure score, for each City $j$, is therefore built as follow:<\/p>\n\n$$Expo_{j,SDG13} = \\sum_{i=1}^{N}Probability_{i} \\times Magnitude_{i}$$\n\n<p style=\"text-align:justify;\">where $N$ is the total number of climate hazards, $Probability$ and $ Magnitude$ their respective probability of occurence and the magnitude of the impact. <\/p>\n\n<p style=\"text-align:justify;\">Below are the most frequent climate hazards. The size provide the number of respondent considering the hazard in their analysis and the coordinates are the average probability and magnitude over respondents.<\/p>","d3ee6eb5":"From our analysis of the questionnaire, we saw that questions regard different topics. Hence we create three different datasets based on the underlying topic give in **Type of Answer**:\n\n* **Cities_Stat_2020**: with all descriptive questions of the cities.\n\n* **Cities_Risk_2020**: with all questions regarding risk exposures.\n\n* **Cities_Will_2020**: with all questions regarding ambition of cities to fight risks.","d1d08647":"<p style=\"text-align:justify;\">As one of the specificities of the project is to study the interactions between the social, environmental and economic components of climate change, we have chosen to organise our study according to the 17 Sustainable Development Goals (SDGs) of the United Nations. Adopted in 2015, the SDGs are an extension of the eight Millennium Development Goals (MDGs) defined in 2000 with a horizon of 2015. However, they differ on two points: whereas the MDGs focused on humanitarian issues, the SDGs cover social, environmental and economic issues on the one hand, and are the result of negotiations involving all stakeholders (local authorities, civil society and the private sector) on the other.<\/p>","1ffcd3ed":"Depending on the broad range of variable we used, KPIS are more or less normally distributed. However the scope of variables is large enough to we prevent skewed distributions. We analyse later on the empirical meaning of our KPIs.","9eaa4a13":"<a id=\"Kpi-validation\"><\/a>\n## 3.2 KPIs validation \n\n<p style=\"text-align:justify;\">Assessing the quality of our KPIs is not straightforward. Indeed, there are no clear target scores for our macro-themes and environmental and social assessments are often controversial <a href=\"https:\/\/papers.ssrn.com\/sol3\/papers.cfm?abstract_id=3438533\">(Berg, K\u00f6lbel and Rigobon, 2020)<\/a>. In our case, the alignment of cities to SDGs are by no means evaluated or referenced. One way to tackle this issue is to directly challenge some of the output, like the top 10 cities of each macro-theme. Another one is to use <em>machine-learning<\/em> algorithms to build classification rules to explain the deciding factors of our KPIs and challenge the rules. The next sections go through these two approaches.<\/p>","db97fb1d":"<p style=\"text-align:justify;\">We wish to assess the pertinence of the questions to determine their value-added in our analysis and more broadly in the CDP's questionnaire.<\/p>\n\n<p style=\"text-align:justify;\">A naive metric would be to consider the question's coverage, ie the percentage of cities that were eligible to the question. Although it is important to measure such quantity, it is not sufficient to assess the pertinence of a question. Indeed, even if all the cities are involved, if all respondents give the same answer, the question will not be useful to discriminate between ambitious and non-ambitious cities. We thus propose a finer approach of pertinence where we examine the answers distributions. <\/p>\n\n<p style=\"text-align:justify;\"> <b>Hence, we define Pertinence as a measures of the diversity in the answers provided to a given question.<\/b> The higher the diversificationm the closer to 1 the score will be. Conversely, the highest the concentration on a particular answer, the closer the score will be to 0. To measure this concentration, we consider the following cases:<\/p>\n\n* <p style=\"text-align:justify;\">The answer is a free range text: we check that the frequency of topics appearances amongst answers are not concentrated on a single topic, and that the sentiments are well distributed amongst all answers. <\/p>\n* <p style=\"text-align:justify;\">The answer is quantitative: we verify that the answers are not concentrated on single values (usually the bounds of the distribution). <\/p>\n* <p style=\"text-align:justify;\">The answers are categorials: we check that no single categorie accounts for the majority of the cities answers.<\/p>\n\nAll functions are detailed in the dedicated [appendix section](#Quality).","743f0ffb":"<a id=\"Pertinence\"><\/a>\n## 3.3 Questions' pertinence\n\n[Back to section 2.3](#KPIs-compilation)","e0758d4f":"We obtain well distributed KPIs on our three macro-themes: **Planet**, **Prosperity** and **Social**.","15d94c64":"For global climate conditions we used:\n- [Climate conditions (GLDAS NOAH)](https:\/\/disc.gsfc.nasa.gov\/datasets?keywords=GLDAS): We use a model from NASA web service.\n- [Soils properties from Global Data Set of Derived Soil Properties, 0.5-Degree Grid (ISRIC-WISE)](https:\/\/daac.ornl.gov\/cgi-bin\/dsviewer.pl?ds_id=546)","275248f4":"### 2.2.2 Free text answers: Unsupervised Sentiment and Topics Scoring\n[Back to main section](#Free-text)\n\n<a id=\"Text-explore\"><\/a>\nNext is an exemple of the output of *Explore_Textdata*, the function which reshape and clean text to make answers ready to use for sentiment and topics analysis.","47100b1c":"<p style=\"text-align:justify;\">After analysing the 17 goals and 169 targets, we propose to select and group the following goals into three macro-themes:<\/p>","00ca0253":"<a id=\"Risk-Effort\"><\/a>\n## 3.1 Studying the intersection of KPIs","942010f6":"### Extracting the main goals\n\nWe propose to synthesize the request as follows:\n\n| Type of output | Topics | Specificities |\n| ----------- | ----------- | ----------- | \n| - Methodology <br> - KPIs | - Climate change <br> - Water security <br> - Deforestation <br> - Racial\/social inequities <br> - Pull out of a recession <br> - Global pandemic <br> - Mitigate and Adapt to climate change | - Intersection between env. and soc. issues <br> - Ambitions to take factors into account <br> - Projects can be invested <br> - That corporations could solve <br> - External data sources <br> - Automated process |","cb352ea2":"## 2.3. Ambition KPIs by macro-theme\n\n<a id=\"Question-level-app\"><\/a>\n### 2.3.1. Combine scores to questions' level\n\n[Back to the main section](#Score-bq)","2c537640":"<a id=\"U-Top\"><\/a>\n#### 2.2.2.2. Unsupervised Topics analysis","f1100b01":"<a id=\"Dataset-preparation\"><\/a>\n## 2.1. Dataset preparation","fda23766":"### Problem original statement","2cf70f2a":"<p style=\"text-align:justify;\">We built:\n\n* Risk KPIs, based on a selection of external data consolidated by some relevant question from the CDP. \n* Ambition KPIs, derived from the unsupervised numeration of the questions answers.\n    \n<p style=\"text-align:justify;\">It is thus natural to ask ourselves how the two KPIs' types are related. A correlation study provides an answer to the question of the intersection between the environmental, economic and social components raised in the initial problem statement.<\/p>","7105e9dc":"#### Sentiment Analysis in Practice\n\nWe apply the sentiment analysis to every question marked on the ***Which is text to Analyse*** column from the ***extra_info*** database. We also set the reference sub-question from the ***Text Ref Col*** column.","85dc25b6":"<p style=\"text-align:justify;\">As explain previously, we capture the addressed topics in a specific sub-question and then identify if a given answer captures them all by retrieving each topic's density in the answer.<\/p>\n\n<p style=\"text-align:justify;\">Similar to the sentiment analysis section, we define all functions in a <a href=\"#Utils-top\">Utils section<\/a> which may be seen as a reporistory for unsupervised topics analysis.<\/p>\n\n<p style=\"text-align:justify;\">In practice, we set an a-priori number of optimal topics to three. It seems enough to capture the complexity of the answers' structure since we get homogeneous set of answers by filtering on referencce sub-questions. <\/p>","4e73ef5f":"![schema_AmbitionScore.jpg](attachment:schema_AmbitionScore.jpg)","83cdf52a":"Out of the 73 questions we spotted as relevant for the analysis of **cities' ambition** to protect the ***Planet** take care of ***Social*** inequalities and ensure ***Prosperity*** through sustainable development, only four of them do not have either quantitative of categorcial answers to analyse. It emphasises how important this part is to build *Key Performance Indicators* on the previous issues based on the cities answers.\n\nWe follow the process explained [above](#Ambition-score-by-question) to score each cities' answers.\n\nWe first define a dictionary that scores all catagories that may be ranked. These questions are identified from the **extra_information** dataset based on the **Is Positive** column.","c782872c":"#### Libraries","c1ab02a0":"[Back to Table of Contents](#ToC)\n\n<a id=\"Appendices\"><\/a>\n# Appendices","5aa19061":"Average all thre approaches base on cities ranking in each approach.","13b74dc8":"### Transform database to wide format for a given question\n\nEach question in the original dataset may lead to several answers and hence multiple rows. To ease our analysis of the data we decided to reshape the data into a \"*dict\/wide format*\" where for each question all answers are stored in a panda dataframe. These dataframes are in a \"*wide format*\" with one row per respondent and every sub-question as column. \n\nHence, for a given question, each cell of the dataframe is a dictionnary where keys are the answers to a sub-question and values are their identifier.","aa87304d":"<p style=\"text-align:justify;\">We define all functions in a <a href=\"#Utils-sent\">Utils section<\/a> which may be seen as a reporistory for unsupervised sentiment analysis. It consolidates Wordnet and Vader sentiment analysis with multiple possible word weighting schemes, including term frequency-inverse document frequency (<em>TF-IDF<\/em>). \nEach score is then discretized to quintile and the final sentiment score is computed by a majority vote between the different models.<\/p>\n\n<p style=\"text-align:justify;\">We apply the sentiment analysis to every question marked on the <em><b>Which is text to Analyse<\/b><\/em> column from the <em><b>extra_info<\/b><\/em> database. It makes 21 questions. We also set the reference sub-question from the <em><b>Text Ref Col<\/b><\/em> column.","3d3ff70f":"<p style=\"text-align:justify;\">This section aims to develop ambition key performance indicators for each city and macro-theme, based on the analysis of all types of responses addressed to the CDP: quantitative, categorical and free text.<\/p>\n\n<p style=\"text-align:justify;\">We differentiate the creation of scores per question from the computation of KPIs by macro-themes of SDGs.<\/p>","dcdb0a2a":"For each indicator, we use a simple scaling process to obtain a normalized signal:\n\n$$ Score = \\frac{Score - mean(Score)}{sd(Score)} $$\n\nThe other SDGs' scores within the macro theme planet are based on the following score:","a40ac7ae":"### The United Nations Sustainable Development Goals framework","e8fdd988":"No city have grasped the three identified topics, but some answers cover two out of three topics.\n\n<p style=\"text-align:justify;\">For example, the answer with index 168 is \"<em>The City has recently received funds to complete two trails - the Clippership Connector and the South Medford Connector - that will expand options for active transportation throughout the region.<\/em>\"<\/p>\n\n<p style=\"text-align:justify;\">We can clearly identify the Topic 3 that corresponds to public infrastructure development and the Topic 2 on active transportation.<\/p>\n\n<p style=\"text-align:justify;\">Another example is the answer with index 9: \"<em>Expansion and promotion of E-mobility by grants for appropriate investments such as vehicle procurement or charging infrastructure. Impulse investments in hydrogen technology through charging station, vehicle and bus procurement.Testing new types of E-vehicles and exemplary use in new areas (e.g. city logistics).<\/em>\"<\/p>\n\n<p style=\"text-align:justify;\">One can easily identifies the Topic 1 on electric transportation as well as Topic 2 on clean transportation.<\/p>","7dc720a7":"![schema1.3.jpg](attachment:schema1.3.jpg)","9c3c27d5":"<p style=\"text-align:justify;\">From our first analysis of the questionnaire, we created three different datasets based on the underlying <b>type of Answer<\/b>:<\/p>\n\n* **Cities_Stat_2020**: with all descriptive questions of the cities.\n\n* **Cities_Risk_2020**: with all questions regarding risk exposures.\n\n* **Cities_Will_2020**: with all questions regarding ambition of cities to fight risks.","6ec49dcf":"[Back to Table of Contents](#ToC)\n\n<a id=\"Risk-exposure\"><\/a>\n# 1. Risk exposure KPIs\n\n<a id=\"Dataset-description\"><\/a>\n## 1.1 Dataset description\n\n### 1.1.1 CDP survey","eefc2dd9":"Given the CDP's request, our study has three main objectives:\n\n- **Risks**:  develop a risk KPI for each city and macro-theme, based on CDP and external data;\n\n- <p style=\"text-align:justify;\"><b>Ambitions<\/b>: develop ambition KPI for each city and macro-theme, based on the analysis of all the responses to the CDP: quantitatives, categorical and free text;<\/p>\n\n- <p style=\"text-align:justify;\"><b>Solutions<\/b>: propose solutions for each city based on the responses provided by other cities with similar risks.<\/p>","81d03a82":"Here is an exemple for question **6.0**: *Please indicate the opportunities your city has identified as a result of addressing climate change and describe how the city is positioning itself to take advantage of these opportunities.*","44a72cf7":"Main function to compute the scores on analytical data","d2b6651a":"#### In order to meet these three objectives in the most relevant and rigorous way possible, we propose:\n\n* <p style=\"text-align:justify;\">KPIs per city built from the CDP database, supplemented by external data;<\/p>\n* <p style=\"text-align:justify;\">KPIs based on the SDGs' framework;<\/p>\n* <p style=\"text-align:justify;\">A method for automatically extracting and processing the qualitative content of the CDP responses;<\/p>\n* <p style=\"text-align:justify;\">An analysis of the intersections between environmental, economic and social issues based on correlation analysis;<\/p>\n* <p style=\"text-align:justify;\">A method for checking and explaining the relevance of scores based on decision trees;<\/p>\n* <p style=\"text-align:justify;\">An assessment of the questions'pertinence to give the Carbon Disclosure Project insights on the questionnaire's possible changes;<\/p>\n* <p style=\"text-align:justify;\">A tool to provide solutions\/recommendations to cities even if they are not in the database.","0142294a":"<p style=\"text-align:justify;\">Each question in the original dataset may lead to several answers and hence multiple rows. To ease our analysis of the data, we reshape the data into a \"<em>dict\/wide format<\/em>\" where each question's answers are stored in a panda dataframe. These dataframes are in a \"<em>wide format<\/em>\" with one row per respondent and every sub-question as column. For a given question, each cell of the dataframe is a dictionary where keys are the answers to a sub-question and values are their identifier.<\/p>","c774e1ff":"<p style=\"text-align:justify;\">Let us start by analyzing the terms of the request, as formulated by the Carbon Disclosure Project.<\/p>\n\n> <p style=\"text-align:justify;\">\"Data scientists will scour environmental information provided to CDP by disclosing companies and cities, searching for <b>solutions<\/b> to our most pressing problems related to <b>climate change, water security, deforestation, and social inequity\"<\/b>.''<\/p>\n\n> <p style=\"text-align:justify;\">\"Develop a <b>methodology<\/b> for calculating <b>key performance indicators (KPIs)<\/b> that relate to the <b>environmental<\/b> and <b>social<\/b> issues that are discussed in the CDP survey data. Leverage external data sources and thoroughly discuss the intersection between environmental issues and social issues. Mine information to create automated insight generation demonstrating whether city and corporate <b>ambitions<\/b> take these factors into account. \"<\/p>\n\n<p style=\"text-align:justify;\">We propose to focus our analysis on the \"cities\", as companies have already been the subject of numerous studies on environmental, social and governance (ESG) issues.<\/p>","26edd4e1":"<a id=\"Quantitative-and-Categorical\"><\/a>\n### 2.2.1. Quantitative and Categorical answers: Frequentist and Automated Scoring","f0cd5e48":"<p style=\"text-align:justify;\">We construct Planet and Social componant based on the aggregation of the metrics in the table hereunder. We use an equally weighting scheme because of the large number of components. For the prosperity risk exposure we propose a more advanced method. Following the <a href=\"http:\/\/www.oecd.org\/sdd\/42495745.pdf\">OECD methodology<\/a>, we build a new score using Principal Component Analysis. More specificaly, we use factor loadings, i.e. the correlation between the original variables and the factors. Squared factor loadings indicate what percentage of the variance in an original variable is explained by a factor and are retained as the weight for each variable.<\/p>","cfa49953":"Everything regarding data generation in this section is available in the R notebook *SDG_quant_database_construction* attached in the dataset cdp-inputs-final.","41e186fe":"<p style=\"text-align:justify;\">To complete the CDP database, we rely on the following open-source databases: <\/p>\n\n- <a href=\"https:\/\/unstats.un.org\/sdgs\/indicators\/database\/\">United Nation database<\/a>\n- <p style=\"text-align:justify;\"><a href=\"http:\/\/sedac.ciesin.columbia.edu\/es\/compendium.html\">Compendium of Environmental Sustainability Indicator Collections: 2004 Environmental Vulnerability Index (EVI) (July 2006) Center for International Earth Science Information Network (CIESIN) Columbia University<\/a><\/p>\n- [Notre-Dame Gain](https:\/\/gain.nd.edu\/our-work\/country-index\/)\n- City 500 census (for health issues scores)\n\n<p style=\"text-align:justify;\">We give an example of an indicator corresponding to the renewable energy share in the total final energy consumption (%), accessible on the UN database hereunder. <\/p>","f730ef5a":"<a id=\"Score-bq\"><\/a>\n### 2.2.3. Scores aggregation to questions' level","c456632b":"<p style=\"text-align:justify;\">We then aggregate each approach' score to compute a final one per respondent per question answered. To do so, we rank each respondent on a given approach and then compute their average scaled rank.<\/p>\n\n<p style=\"text-align:justify;\">It is important to note that we give the opporunity for the user to balance each approach importance in the final score by weighting them. In this case, we decided to assign <b>80%<\/b> to the <b>Quantitative\/Qualitative<\/b> analysis and <b>10%<\/b> to both <b>Free Text<\/b> analyses. Depending on the evolution of the questionnaire one might want to change the weights.<\/p>\n\n\\begin{equation}\n    Score_{q,i} = Score_{q,i,QCat}*W_{QCat} + Score_{q,i,Senti}*W_{Senti} + Score_{q,i,Topics}*W_{Topics}\n\\end{equation}\n\n<p style=\"text-align:justify;\">With <b>QCat<\/b> being the quantitative\/categorical analysis, <b>Senti<\/b> the sentiment analysis and <b>Topics<\/b> the output of the LDA analysis.<\/p>\n\nAll details are presented in the dedicated [appendix section](#Question-level-app).","df0a7f91":"### 3.2.2 Validation by classification tree","3610d2b2":"![tableau_Sdgs_macro_themes.png](attachment:tableau_Sdgs_macro_themes.png)","7b27a9b3":"[Back to Table of Contents](#ToC)\n\n<a id=\"Discussion\"><\/a>\n# 3. Discussion\n\n<p style=\"text-align:justify;\">In this section, we discuss the methodology used to generate our KPIs and propose some potential extensions to leverage our results.\u00a0First, we study the intersections of the Ambitions and Risks KPIs of the Planet, Prosperity and Social macro themes.\u00a0Next, in order to make sure that our Ambition KPIs are coherent measures, we propose a systematic process for validation.\u00a0In addition, we introduce metrics to measure the pertinence and coverage of the information extracted from the CDP questions.\u00a0Finally, we propose an extension of our work where we generate solution recommendations from model cities facing similar climate risks.<\/p>","2a87b1fd":"<a id=\"Risk-exposure-methodology\"><\/a>\n## 1.2 Risk exposure scoring methodology","3e3dbcf0":"It seems coherent with our beliefs. There are expected major cities but also some smaller cities who might have a strong amibition to tackle our macro-themes for many reasons such as geographic exposure, country's plan is spreading...\n\nHence we run the second step of the analysis.","9a05a611":"We build a dictionary referencing which cities answered in english. This will be usefull later for free text analysis.","70128bbf":"# Risk, Ambition and Solution KPIs for cities","d24cbc7f":"### 1.2.1 From CDP and external database to SDGs scores","c8370b2c":"<p style=\"text-align:justify;\">Out of the 73 questions we spotted as relevant for the analysis of <b>cities' ambition<\/b> to protect the <b><em>Planet<\/em><\/b>, take care of <b><em>Social<\/em><\/b> issues and ensure <b><em>Prosperity<\/em><\/b> through sustainable development, only four of them do not have either quantitative or categorcial answers to analyse. It emphasises how important this part is to build KPIs.<\/p>\n\nWe follow the process explained above to score each cities' answers.","b20f0e28":"We then build a new dataset from the extra columns we added to the main dataset w called ***extra_info***. ","12d78785":"|Water (6)  | Energy  (7) |  Biodiversity (14-15)| \n| :----- | :-----------   | :-----               |\n|- (CDP2.1) Water Scarcity > Drought <br> - (CDP14.1) pct pop potable water <br> - (CDP4.2a) Change in land-use <br> - (CDP14.2a) Declining water quality <br> - (CDP14.2a) Drought<br>- (CDP14.2a) Ecosystem vulnerability <br>- (CDP14.2a) Energy supply issues<br>- (CDP14.2a) Environmental regulations<br>- (CDP14.2a) Higher water prices<br>- (CDP14.2a) Inadequate or ageing water supply infrastructure<br>- (CDP14.2a) Increased levels of plastic in freshwater bodies<br>- (CDP14.2a) Increased water demand<br>- (CDP14.2a) Increased water scarcity<br> - (CDP14.2a) Increased water stress<br>- (CDP14.2a) Pollution incidents<br>- (CDP14.2a) Rationing of municipal water supply<br>- (CDP14.2a) Severe weather events<br>- (CDP14.2a) Unauthorised\/unregistered water connections<br>- (CDP14.2a) Water infestation\/disease<br>- (CDP6.2.1) Proportion of population practicing open defecation by urban\/rural (%)<br>- (CDP6.6.1) Water body extent (permanent and maybe permanent) (%) of total land area)<br>- (CDP6.6.1) Water body extent (permanent and maybe permanent) (square kilometres)<br>- (CDP6.6.1) Water body extent (permanent) (% of total land area)<br>- (CDP6.6.1) Water body extent (permanent) (square kilometres)<br>- (SEDAC) DRYEVI<br> - (SEDAC) WATEVI<br>- (SEDAC) WATEREVI<br>- (NDG) water Index| - (UN8.1) Biomass (+) <br> - (UN8.1) Coal (-) <br>- (UN8.1) Gas (-) <br>- (UN8.1) Geothermal (+) <br>- (UN8.1) Hydro (+) <br> - (UN8.1) Nuclear (+) <br>- (UN8.1) Oil (-)<br> - (UN8.1) Solar (+)<br>- (UN8.1) Wind (+)<br> - (UN7.1.1) Proportion of population with access to electricity, by urban\/rural (%) (+) <br> - (UN7.2.1) Renewable energy share in the total final energy consumption (%) (+) <br> - (UN7.3.1) Energy intensity level of primary energy (megajoules per constant 2011 purchasing power parity GDP)|- (NDG) habitat<br> - (UN14.1.1) Chlorophyll-a deviations, remote sensing (%)<br> - (UN15.1.1) Forest area (thousands of hectares) <br>- (UN15.1.1) Forest area as a proportion of total land area (%)<br>- (UN15.1.2) Average proportion of Terrestrial Key Biodiversity Areas (KBAs)<br> covered by protected areas (%)<br>- (UN15.2.1) Above-ground biomass stock in forest (tonnes per hectare)<br>- (UN15.2.1) Forest area annual net change rate (%)<br>- (UN15.2.1) Forest area under an independently verified forest management <br>certification scheme (thousands of hectares)<br>- (UN15.4.1) Average proportion of Mountain Key Biodiversity Areas (KBAs) <br>covered by protected areas (%)<br>15.5.1 Red List Index<br>- (UN15.6.1) Countries that are contracting Parties to the International Treaty <br>on Plant Genetic Resources for Food and Agriculture (PGRFA) (1 = YES; 0 = NO)<br>- (UN15.6.1) Countries that are parties to the Nagoya Protocol (1 = YES; 0 = NO)<br>- (UN15.6.1) Countries that have legislative, administrative and policy framework or<br> measures reported through the Online Reporting System on Compliance  of the International Treaty on Plant Genetic Resources for Food and Agriculture (PGRFA) (1 = YES; 0 = NO)<br>- (UN15.6.1) Countries that have legislative, administrative and <br>policy framework or measures reported to the Access and Benefit-Sharing Clearing-House (1 = YES; 0 = NO)<br>15.6.1 Total reported number of Standard Material Transfer Agreements (SMTAs) transferring plant genetic resources for food and agriculture to the country (number)<br> - (UN15.8.1) Legislation, Regulation, Act related to the prevention of introduction<br> and management of Invasive Alien Species (1 = YES, 0 = NO)<br>- (UN15.8.1) National Biodiversity Strategy and Action Plan (NBSAP)<br> targets alignment to Aichi Biodiversity target 9 set out in the Strategic Plan for Biodiversity 2011-2020 (1 = YES, 0 = NO))|","c06c257e":"\n<p style=\"text-align:justify;\">Based on the classification tree results, the <b>Planet KPI<\/b> is very consistent. Indeed, cities with the highest scores are ones with : a food policy to fight againt wastes AND a public water management agency AND a decrese in GHG emissions OR Renewable Targets OR Colaborate with Business on climate issues, while the cities with the lowest scores have none of the above.<\/p>\n\n<p style=\"text-align:justify;\">This classification tree has not been design for prediction but rather to explain our KPIs results. Hence it works particularly well for the extremes and could be used as an independent sparse scoring system.<\/p> \n\n<p style=\"text-align:justify;\">This approach may of course also be applied to the other macro-themes.\n","07535e43":"##### E) Apply sentiment analysis","2ab292a1":"### 2.2. Ambition Scores by question\n\n### Extra information from questionnaire analysis\n\nFrom the extra columns we added to the main dataset we build a new dataset called ***extra_info***. \n\nWe could have done it automatically from the added columns but there are some questions in the main dataset who don't appear in the questionnaire. Therefore we had to update manually the extra_info dataframe.","f6629388":"<p style=\"text-align:justify;\">Our top 10 on the three macro-themes look very convincing. Indeed, on the Planet side, we can compare our resultst to the A list of the CDP since cities from the A list are <em>\"setting and meeting ambitious climate goals\"<\/em>. <b>Out of our ten cities with the highest Planet Ambition score, 7 are in the 2020 CDP A list<\/b>. However the match is not perfect because we did not use the CDP's methodology to build our Planet KPI and therefore the scope of questions may differ. We believe we can be confident on the other macro-theme since our approach is mostly unsupervised and automated.","a473a67f":"#### Data: the (climate) data gap\n\n<p style=\"text-align:justify;\">One of the issues <a href=\"https:\/\/2degrees-investing.org\/resource\/asset-level-data-and-climate-relate-financial-analysis-a-market-survey\/\">regularly raised<\/a> in studies on the integration of climate issues in finance is the lack of data on the exposure of the various actors regarding their climate risks. In this study we rely on the definition of the <a href=\"https:\/\/assets.bbhub.io\/company\/sites\/60\/2020\/10\/FINAL-2017-TCFD-Report-11052018.pdf\">TCFD (2017)<\/a> to distinguish:<\/p>\n\n-  <p style=\"text-align:justify;\">transition risk: risks related to the <em>transition<\/em> to a lower-carbon economy <\/p>\n- <p style=\"text-align:justify;\">physical risks: risks related to the <em>physical<\/em> impacts of climate change.<\/p>\n\n<p style=\"text-align:justify;\">The question of physical risks and the necessary adaptations in the face of changing conditions requires particularly precise data.  Cities and companies that are very close to each other may face very different climate hazards. Once again, putting these physical risk indicators into perspective with the state of the art of the market clearly shows us the added value of the CDP databases. Its questionnaires make it possible to locate risks by typology, probability and intensity, which in the end can easily allow a mapping of these risks and trace them back to the different forms of economic activity. This question is particularly relevant for enriching the offer made to the financial organization.<\/p>\n\n<p style=\"text-align:justify;\">Although climate data is still fragmented, we can notice that a large amount of information is made available on open data platforms, from the <a href=\"https:\/\/datatopics.worldbank.org\/esg\/\">World Bank<\/a> or the <a href=\"https:\/\/unstats.un.org\/sdgs\/indicators\/database\">United Nations<\/a>.We will therefore complement the CDP database with these external resources. <\/p>","b21b319a":"##### 2.2.2.1. Sentiment Analysis\n\nWe define all functions in a Utils section which may be seen as a reporistory for sentiment analysis.\n\n<a id=\"Utils-sent\"><\/a>\n#### Utils\n\n[Back to the main section](#Free-text)\n\n##### A) Word weights","1b5b6fc3":"<p style=\"text-align:justify;\">Here is an exemple for the Planet macro-theme. We rank the scores in 5 groups (quintiles) and run a classic classification tree based on trivial categorical variables that are included in the Planet KPI's construction. <\/p>\n\n<p style=\"text-align:justify;\">The main goal is to use the abilities of classification trees to come up with simple rules that make sense to justify our KPIs on the ambition of cities to protect the environment. <\/p>","3de9df8f":"### Risks, Ambitions, Solutions","dd9f38d1":"<a id=\"ToC\"><\/a>\n## Table of Contents\n\n* [Introduction](#intro)\n* [1. Risk exposure KPIs](#Risk-exposure)\n    - [1.1. Dataset description](#Dataset-description)\n    - [1.2. Risk exposure scoring methodology](#Risk-exposure-methodology)\n* [2. Ambition KPIs](#Ambition)\n    - [2.1. Dataset preparation](#IDataset-preparation)\n    - [2.2. Ambition Scores by question](#Ambition-score-by-question)\n    - [2.3. Ambition KPIs by macro-theme](#KPIs-compilation)\n* [3. Discussions](#Discussion)\n    - [3.1. Studying the intersection of KPIs](#Risk-Effort)\n    - [3.2. KPIs validation](#Kpi-validation)\n    - [3.3. Questions' Pertinence](#Pertinence)\n    - [3.4. Solutions recommendations](#Political)\n* [Conclusion](#Conclusion)\n* [Appendices](#Appendices)","ec6df97a":"## Appendices 2. Ambition Scores","54a7cf3d":"### 3.2.1 Validation by vizualisation","3fa3c4f7":"<a id=\"intro\"><\/a>\n## Introduction","5f633da7":"<p style=\"text-align:justify;\">To summarize in a few words, we capitalize on the CDP databases and questionnaires to analyze both the cities risk exposures and their demonstrated ambitions to tackle such issues. Our methodology exploits the data synergies between the UN Sustainable Development Goals and CDP questionnaires to construct relevant Key Performance Indicators. The quality of the obtained KPIs is then assessed empirically and using machine learning techniques. In addition we investigate which questions seems to be more pertinent in the CDP questionnaires. Finally, we develop a tool for cities, inside or outside of the CDP database to gain insights into which directions ambitious cities facing similar climate risks are pursuing.<\/p>\n\n<p style=\"text-align:justify;\">Our mainly unsupervised approach yields very satisfactory results. Most of the cities with the highest KPIs are publicly known for their leading efforts in the three macro-themes we studied: Planet, Prosperity and Social. In that sense, our KPIs seem to be reliable. <\/p>\n\n<p style=\"text-align:justify;\">In addition to that, our methodology may be applied in a systematic and dynamic way to follow the evolution of the actors over time. Also, while this notebook focuses on cities - because they have been the subject of less study than corporates - the approach is generalizable, especially the unsupervised assessment of ambition detailed in Section 2.<\/p> \n\n<p style=\"text-align:justify;\">Finally, we believe the small number of final KPIs we retained make these measures easily understandable and compatible with many processes, such as portfolio management and can help stakeholders to include climate change, sustainable development and social issues into account.","ae701bda":"### 2.2.1. Quantitative and Categorical answers: Frequentist and Automated Scoring","b87328e1":"<p style=\"text-align:justify;\">We observe high correlation between the ambition KPIs. This result is characteristic of the ambitions expressed in terms of social and responsible development, and it seems that the two dimensions are intrinsically linked in the general discourse. Depending on the scores' objectives, correlations may be reduced by not taking into account the same question in multiple macro-themes. On the other hand risk KPIs are mostly uncorrelated with eachothers and with the ambition KPIs. This is becaused we used a non-exhaustive proposal of indicators, selected to be representative and independent.<\/p>\n    \n<p style=\"text-align:justify;\">This second result is important. It suggests that cities that are highly exposed to certain risks have not systematically developed a specific action plan on these issues. It is therefore essential to come up with solutions for these cities. This second result is also found at the country level:","61837319":"#### Outputs: evaluation and values\n\n<p style=\"text-align:justify;\">One of the objectives of the Kaggle challenge is to build KPIs for each city. This methodological challenge is part of a global logic of evaluation of environmental, social and governance (ESG) performance, which has taken several names: corporate social responsibility (CSR) for companies and actors of the real economy or ESG on the financial side. While financial performance is measured in a relatively universal way (thanks to the homogeneity of accounting frameworks and financial markets), environmental and social performance leaves room for many, sometimes divergent approaches. For the same counterpart, the themes selected, the way of calculating the scores on these themes and the weighting of these themes differ according to the observers and their values <a href=\"https:\/\/papers.ssrn.com\/sol3\/papers.cfm?abstract_id=3438533\">(Berg, K\u00f6lbel and Rigobon, 2020)<\/a>. In order to limit the bias induced by <em>our<\/em> values, we have tried to refer as much as possible to a widely shared international reference framework - the Sustainable Development Goals - in particular in the choice of macro-themes and variables used to build our KPIs. <\/p>","a5e0fd43":"### 2.1. Dataset preparation\n\nWe clean raw data from CDP of the data and define functions for further text cleaning.","8e09618f":"![sdgs.PNG](attachment:sdgs.PNG)","2fbafb96":"<a id=\"Practice-cat\"><\/a>\n##### Explore_AnalyticData In Practice\n\nWe first determine the questions that are categorial with ungradable categories and different orientations. Indeed, we need to identify model cities to compute the scores on such questions.","b87e4b20":"<p style=\"text-align:justify;\">We use the CDP 2020 Cities database as a reference to build our KPIs. This database contains responses to questionnaires from 566 cities. After a slight processing of the coordinates, we selected the cities located as follows:<\/p>","35cbb34d":"We then aggregate scores by the macro-themes to create so called **KPIs**.\n\n<p style=\"text-align:justify;\">We compute a weighted average of each question' score using a <b>questions' quality metric<\/b> that we built and discuss further in the <a href=\"#Pertinence\">Section 3.3<\/a>.<\/p>","1655e9ef":"In addition to the absence of correlation between risk exposure and ambition exposure, we can see from this figure that:\n* There are no clear clusters of Planet risk exposure per region. It seems fair since climate differ within a region;\n* On the contrary, there are different trends on the Ambition side between regions. Europe seems clearly ahead from its counterparts.","f126a733":"#### LDA in Practice","23565fa3":"[Back to Table of Contents](#ToC)\n\n<a id=\"Ambition\"><\/a>\n# 2. Ambition KPIs","2179efcf":"We select the cities with the highest scores as model cities and use them to compute the scores on the remaining questions.","1c74f058":"We added supplementary variables coming from our analysis of the 2020 cities' questionnaire:\n* <p style=\"text-align:justify;\"><b>Type of Answer<\/b> takes four possible values depending on the type of the question: Descriptive Statistics, Risk Exposure, Willingness to fight risks, also referred as Ambition to fight risks, and Investment. <\/p>\n* <p style=\"text-align:justify;\"><b>SDGs<\/b> takes three possible values depending on which macro-theme it relates to (<em>Prosperity<\/em>, <em>Social<\/em> and <em>Planet<\/em>).<\/p>\n* <p style=\"text-align:justify;\"><b>Which is text to analyse<\/b> gives information to which columns of the question are suitable for text analysis while <b>Which else to analyse<\/b> tells which other columns must be analysed based on other approaches. <\/p>\n* <p style=\"text-align:justify;\"><b>Political Recommendation<\/b> is marked for a given question if we can use the answers of some cities to give political recommendations to others.<\/p>\n* <p style=\"text-align:justify;\"><b>Is Positive<\/b> tells if the possible answers are positive. We define <em>Positive<\/em> as a three-dimensional object either quantitative, ranked categories or all positive categories. It helps us apply a specific approach for answers' evaluation to build our KPIs. <\/p>\n* <p style=\"text-align:justify;\"><b>Text Ref Col<\/b> tells which column may be used to define reference categories to analyse free text answers. <\/p>","eb1c16a0":"<p style=\"text-align:justify;\">The output is consistant with our expectations: most of the top cities are well known for their efforts in favor of all three SDGs macro-themes and the scores are relatively normally distributed.<\/p>","6c98c0d7":"We therefore believe that this framework is relevant to structure our work: \n\n- It enables us to address the interactions between social, environmental and economic issues.\n\n- It is recognised by the organisations we are studying: cities and companies (72% of the companies surveyed by PwC worldwide included SDOs in their communications in 2018)."}}