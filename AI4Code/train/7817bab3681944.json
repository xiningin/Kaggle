{"cell_type":{"4514fba2":"code","32db5d0c":"code","77c7d08b":"code","54ff06ad":"code","4aaf474f":"code","0c4f900c":"code","e0374b63":"code","e0ac9e20":"code","342ac1c5":"code","f12a2658":"code","b1ba9546":"code","d9ffac16":"code","e7ceec73":"code","d3ce994a":"code","8afed3b6":"code","35f7bd04":"code","1a294daf":"code","cac407fb":"code","3a936f3f":"code","5b306fbe":"code","5558efec":"code","5397d9e1":"code","4b5e36c1":"code","59395561":"code","696796cc":"code","638e9bcf":"code","43f23c10":"code","8e7568f2":"code","03ebb95b":"code","9da06636":"code","47b1d42e":"code","55c9647e":"code","e9a09575":"code","88b36a14":"code","fb330d5e":"code","386d4bf6":"code","e4e55a85":"code","fed3f61e":"code","88d9852a":"code","6766de5c":"code","d6f27318":"code","84cab1d1":"code","d74e937c":"code","6a82a424":"code","1afac568":"code","052c713e":"code","03263ad0":"code","a6bd035e":"code","ce65a339":"code","3a5480c9":"code","202cd2e7":"code","8e44cf76":"code","728281eb":"code","73cf6c82":"markdown","932ce95f":"markdown","59fc6006":"markdown","e5d8b5ae":"markdown","d7ebd291":"markdown","056ff627":"markdown","19ecf4a3":"markdown","e15f49a0":"markdown","04a6f030":"markdown","95186b6a":"markdown","13be996c":"markdown","3b2959b1":"markdown","53f8ce55":"markdown","538a590f":"markdown","228d673e":"markdown","e012ead5":"markdown","ad92262e":"markdown","f39e4436":"markdown","d436426a":"markdown"},"source":{"4514fba2":"#IMPORTING REQUIRED LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom lightgbm.sklearn import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nimport gc\ngc.enable()\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n","32db5d0c":"#DATASET VIEW\npath1=\"..\/input\/\"\ndata_files=list(os.listdir(path1))\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(path1+x).st_size\/(1024*1024),2))\ndf_files","77c7d08b":"#DATASET VIEW\npath1=\"..\/input\/ga-customer-revenue-prediction\/\"\npath2='..\/input\/gstore-prepared-dataset\/'\ndata_files=['..\/input\/gstore-prepared-dataset\/prepared_train\/prepared_train',\n            '..\/input\/gstore-prepared-dataset\/prepared_test\/prepared_test']\ndf_files=pd.DataFrame(data_files,columns=['File_Name'])\ndf_files['Size_in_MB']=df_files.File_Name.apply(lambda x:round(os.stat(x).st_size\/(1024*1024),2))\ndf_files","54ff06ad":"#All functions\n\n#FUNCTION FOR PROVIDING FEATURE SUMMARY\ndef feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))\n\n#FUNCTION FOR READING DICTIONARY ITEMS AND HANDLING KEYERROR\ndef get_val(x,col):\n    try:\n        y=x[col]\n    except:\n        y=np.nan\n    return(y)\n\n#FUNCTION FOR CALCULATING RSME\ndef rsme(y,pred):\n    return(mean_squared_error(y,pred)**0.5)","4aaf474f":"%%time\n#READING TRAINING AND TEST DATASET\nprint('reading train dataset...')\ndf_train=pd.read_csv(data_files[0],dtype={'fullVisitorId':str})\nprint('reading test dataset...')\ndf_test=pd.read_csv(data_files[1],dtype={'fullVisitorId':str})\nprint('data reading complete')","0c4f900c":"#CHECKING TOP FIVE TRAIN OBSERVATIONS OR ROWS\ndf_train.head()","e0374b63":"#FEATURE SUMMARY FOR TRAIN DATASET\nfeature_summary(df_train)","e0ac9e20":"#CHECKING TOP 5 TEST OBSERVATIONS OR ROWS\ndf_test.head()","342ac1c5":"#FEATURE SUMMARY FOR TEST DATASET\nfeature_summary(df_test)","f12a2658":"#CREATING COPY OF TRAIN DATA SET\ntrain_cpy=df_train.copy()","b1ba9546":"#ADDING ANOTHER FEATURE revenue_status TO INDICATE PRESENCE\/ABSENCE OF REVENUE FOR EACH OBSERVATION\ndf_train['revenue_status']=df_train.totals_transactionRevenue.apply(lambda x: 0 if x==0 else 1)","d9ffac16":"#VISUALIZATION FUNCTIONS\ndef revenue_transaction_visualization(df_t,col,col_name):\n    df_con=df_t[[col,'totals_transactionRevenue','revenue_status']].groupby(col).aggregate(\n        {'totals_transactionRevenue':['mean'],'revenue_status':['count']}).reset_index()\n    df_con.columns=[col,'totals_transactionRevenue_mean','revenue_status_count']\n    df=df_con.sort_values(by='totals_transactionRevenue_mean',ascending=False)[:20]\n    df1=df_con.sort_values(by='revenue_status_count',ascending=False)[:20]\n    display('SORTED BY Mean Revenue')\n    display(df.style.format(formatter))\n\n\n    plt.subplots(figsize=(20,5))\n    plt.subplot(1,2,1)\n    plt.title('REVENUE MEAN BY '+col_name,color='b',fontsize=12)\n    plt.xlabel(col_name,color='b',fontsize=12)\n    plt.ylabel('Mean Revenue',color='b',fontsize=12)\n    plt.bar(range(len(df)),df.totals_transactionRevenue_mean,color='grey')\n    plt.xticks(range(len(df)),df[col],rotation=90,fontsize=12)\n    plt.yticks(fontsize=12)\n\n\n    plt.subplot(1,2,2)\n    plt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY '+col_name,color='b',fontsize=12)\n    plt.xlabel(col_name,color='b',fontsize=12)\n    plt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\n    plt.bar(range(len(df)),df.revenue_status_count,color='orange')\n    plt.yticks(fontsize=12)\n    plt.xticks(range(len(df)),df[col],rotation=90,fontsize=12)\n    plt.show()\n\n    display('SORTED BY Count of Transactions with Revenue')\n    display(df1.style.format(formatter))\n\n    plt.subplots(figsize=(20,5))\n    plt.subplot(1,2,1)\n    plt.title('REVENUE MEAN BY '+col_name,color='b',fontsize=12)\n    plt.xlabel(col_name,color='b',fontsize=12)\n    plt.ylabel('Mean Revenue',color='b',fontsize=12)\n    plt.bar(range(len(df1)),df1.totals_transactionRevenue_mean,color='grey')\n    plt.xticks(range(len(df1)),df1[col],rotation=90,fontsize=12)\n    plt.yticks(fontsize=12)\n\n\n    plt.subplot(1,2,2)\n    plt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY '+col_name,color='b',fontsize=12)\n    plt.xlabel(col_name,color='b',fontsize=12)\n    plt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\n    plt.bar(range(len(df1)),df1.revenue_status_count,color='orange')\n    plt.yticks(fontsize=12)\n    plt.xticks(range(len(df1)),df1[col],rotation=90,fontsize=12)\n    plt.show()","e7ceec73":"#UNDERSTANDING NUMBER OF TRANSACTIONS GENERATING REVENUE\npie_labels=['Revenue Generated -'+str(df_train['revenue_status'][df_train.revenue_status==1].count()),'No Revenue Generated-'+\n            str(df_train['revenue_status'][df_train.revenue_status==0].count())]\npie_share=[df_train['revenue_status'][df_train.revenue_status==1].count()\/df_train['revenue_status'].count(),\n           df_train['revenue_status'][df_train.revenue_status==0].count()\/df_train['revenue_status'].count()]\nfigureObject, axesObject = plt.subplots(figsize=(6,6))\npie_colors=('green','orange')\npie_explode=(.30,.15)\naxesObject.pie(pie_share,labels=pie_labels,explode=pie_explode,autopct='%.2f%%',colors=pie_colors,startangle=45,shadow=True)\naxesObject.axis('equal')\nplt.title('Percentage of Transactions Generating Revenue and Not Generating Revenue',color='blue',fontsize=12)\nplt.show()","d3ce994a":"#REVENUE GENERATED BY BROWSERS\ndf_browser=df_train[['device_browser','totals_transactionRevenue','revenue_status']].groupby(df_train.device_browser).aggregate({'totals_transactionRevenue':['mean'],\n                                                                                                              'revenue_status':['count']}).reset_index()\ndf_browser.columns=['device_browser','totals_transactionRevenue_mean','revenue_status_count']\ndf=df_browser.sort_values(by='totals_transactionRevenue_mean',ascending=False)[df_browser.totals_transactionRevenue_mean>0]\nformatter = {'totals_transactionRevenue_mean':'{:4.2f}'}\ndisplay(df.style.format(formatter))\n\nplt.subplots(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.title('REVENUE MEAN BY BROWSER',color='b',fontsize=12)\nplt.xlabel('Browsers',color='b',fontsize=12)\nplt.ylabel('Mean Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.totals_transactionRevenue_mean,color='grey')\nplt.xticks(range(len(df)),df.device_browser,rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\n\n\nplt.subplot(1,2,2)\nplt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY BROWSER',color='b',fontsize=12)\nplt.xlabel('Browsers',color='b',fontsize=12)\nplt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.revenue_status_count,color='orange')\nplt.xticks(range(len(df)),df.device_browser,rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","8afed3b6":"#REVENUE GENERATED BY OPERATING SYSTEM\ndf_OS=df_train[['device_operatingSystem','totals_transactionRevenue','revenue_status']].groupby(df_train.device_operatingSystem).aggregate({'totals_transactionRevenue':['mean'],\n                                                                                                              'revenue_status':['count']}).reset_index()\ndf_OS.columns=['device_operatingSystem','totals_transactionRevenue_mean','revenue_status_count']\ndf=df_OS.sort_values(by='totals_transactionRevenue_mean',ascending=False)[df_OS.totals_transactionRevenue_mean>0]\ndisplay(df.style.format(formatter))\n\nplt.subplots(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.title('REVENUE MEAN BY OPERATING SYSTEM',color='b',fontsize=12)\nplt.xlabel('Operating Systems',color='b',fontsize=12)\nplt.ylabel('Mean Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.totals_transactionRevenue_mean,color='grey')\nplt.xticks(range(len(df)),df.device_operatingSystem,rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\n\n\nplt.subplot(1,2,2)\nplt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY OPERATING SYSTEM',color='b',fontsize=12)\nplt.xlabel('Operating Systems',color='b',fontsize=12)\nplt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.revenue_status_count,color='orange')\nplt.yticks(fontsize=12)\nplt.xticks(range(len(df)),df.device_operatingSystem,rotation=90,fontsize=12)\nplt.show()","35f7bd04":"#UNDERSTANDING REVENUE, TRANSACTIONS WITH REVENUE AND TOTAL TRANSACTIONS BY DATE\ndf=df_train[['date','revenue_status','totals_transactionRevenue']]\ndf['date']=pd.to_datetime(df['date'],format=\"%Y%m%d\")\ndf=df.groupby('date').aggregate({'revenue_status':['sum','count'],'totals_transactionRevenue':['sum']}).reset_index()\ndf.columns=['date','transactions_withRevenue','total_transactions','total_revenue']\n\n\n#PLOT FOR REVENUE BY DATES\nplt.figure(figsize=(40,10))\nplt.title(\"REVENUE BY DATES\",fontsize=30,color='b')\nplt.xlabel(\"Dates\",fontsize=30,color='b')\nplt.ylabel(\"Total Revenue\",fontsize=30,color='b')\nplt.xticks(fontsize=30)\nplt.yticks(fontsize=30)\nplt.plot(df['date'],df['total_revenue'],color='orange',linewidth=3)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.mean(df['total_revenue']),color='r',linestyle='dashed')\nplt.text('2017-01-10',np.mean(df['total_revenue'])+2,str('Mean: '+str(round(np.mean(df['total_revenue'])\/(10**10),4))),\n         color='r',fontsize=25)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.max(df['total_revenue']),color='r',linestyle='dashed')\nplt.text('2017-01-10',np.max(df['total_revenue'])+2,str('Max: '+str(round(np.max(df['total_revenue'])\/(10**10),4))),\n         color='r',fontsize=25)\nplt.show()\n\n#PLOT FOR TRANSACTIONS WITH REVENUE BY DATES\nplt.figure(figsize=(40,10))\nplt.title(\"TRANSACTIONS WITH REVENUE BY DATES\",fontsize=30,color='b')\nplt.xlabel(\"Dates\",fontsize=30,color='b')\nplt.ylabel(\"Transactions with Revenue\",fontsize=30,color='b')\nplt.xticks(fontsize=30)\nplt.yticks(fontsize=30)\nplt.plot(df['date'],df['transactions_withRevenue'],color='g',linewidth=3)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.mean(df['transactions_withRevenue']),color='r',linestyle='dashed')\nplt.text('2017-01-10',np.mean(df['transactions_withRevenue'])+2,str('Mean: '+str(round(np.mean(df['transactions_withRevenue']),4))),\n         color='r',fontsize=25)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.max(df['transactions_withRevenue']),color='r',linestyle='dashed')\nplt.text('2017-01-10',np.max(df['transactions_withRevenue'])+1,str('Max: '+str(round(np.max(df['transactions_withRevenue']),4))),\n         color='r',fontsize=25)\nplt.show()\n\n\n#PLOT FOR TOTAL TRANSACTIONS BY DATES\nplt.figure(figsize=(40,10))\nplt.title(\"TOTAL TRANSACTIONS BY DATES\",fontsize=30,color='b')\nplt.xlabel(\"Dates\",fontsize=30,color='b')\nplt.ylabel(\"Total Transactions\",fontsize=30,color='b')\nplt.xticks(fontsize=30)\nplt.yticks(fontsize=30)\nplt.plot(df['date'],df['total_transactions'],color='r',linewidth=3)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.mean(df['total_transactions']),color='g',linestyle='dashed')\nplt.text('2017-01-10',np.mean(df['total_transactions'])+2,str('Mean: '+str(round(np.mean(df['total_transactions']),0))),\n         color='g',fontsize=25)\nplt.hlines(xmin='2016-07-20',xmax='2017-08-10',y=np.max(df['total_transactions']),color='g',linestyle='dashed')\nplt.text('2017-01-10',np.max(df['total_transactions'])+2,str('Max: '+str(round(np.max(df['total_transactions']),0))),\n         color='g',fontsize=25)\nplt.show()\n\n\n\n","1a294daf":"#REVENUE GENERATED BY OPERATING SYSTEM\ndf_isM=df_train[['device_isMobile','totals_transactionRevenue','revenue_status']].groupby(df_train.device_isMobile).aggregate({'totals_transactionRevenue':['mean'],\n                                                                                                              'revenue_status':['count']}).reset_index()\ndf_isM.columns=['device_isMobile','totals_transactionRevenue_mean','revenue_status_count']\ndf=df_isM.sort_values(by='totals_transactionRevenue_mean',ascending=False)[df_isM.totals_transactionRevenue_mean>0]\ndisplay(df.style.format(formatter))\n\nplt.subplots(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.title('REVENUE MEAN BY MOBILE',color='b',fontsize=12)\nplt.xlabel('Mobile',color='b',fontsize=12)\nplt.ylabel('Mean Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.totals_transactionRevenue_mean,color='grey')\nplt.xticks(range(len(df)),df.device_isMobile,rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\n\n\nplt.subplot(1,2,2)\nplt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY MOBILE',color='b',fontsize=12)\nplt.xlabel('Mobile',color='b',fontsize=12)\nplt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.revenue_status_count,color='orange')\nplt.yticks(fontsize=12)\nplt.xticks(range(len(df)),df.device_isMobile,rotation=90,fontsize=12)\nplt.show()","cac407fb":"#REVENUE GENERATED BY COUNTRY\nrevenue_transaction_visualization(df_train,'geoNetwork_country','COUNTRY')","3a936f3f":"#REVENUE GENERATED BY CITY\nrevenue_transaction_visualization(df_train,'geoNetwork_city','CITY')","5b306fbe":"#REVENUE GENERATED BY NETWORKDOMAIN\nrevenue_transaction_visualization(df_train,'geoNetwork_networkDomain','NETWORKDOMAIN')","5558efec":"#REVENUE GENERATED BY SUBCONTINENT\nrevenue_transaction_visualization(df_train,'geoNetwork_subContinent','SUBCONTINENT')","5397d9e1":"#REVENUE GENERATED BY REGION\nrevenue_transaction_visualization(df_train,'geoNetwork_region','REGION')","4b5e36c1":"#REVENUE GENERATED BY CONTINENT\nrevenue_transaction_visualization(df_train,'geoNetwork_continent','CONTINENT')","59395561":"#REVENUE GENERATED BY METRO\nrevenue_transaction_visualization(df_train,'geoNetwork_metro','METRO')","696796cc":"#REVENUE GENERATED BY AdCONTENT with Train dataset\nrevenue_transaction_visualization(df_train,'trafficSource_adContent','AdCONTENT')","638e9bcf":"#ANALYZING AdContent in train and test dataset\nprint('Train data: Unique AdContent value count')\ndisplay(df_train['trafficSource_adContent'].groupby(df_train.trafficSource_adContent).count())\nprint('Test data: Unique AdContent value count')\ndisplay(df_test['trafficSource_adContent'].groupby(df_test.trafficSource_adContent).count())\n","43f23c10":"#REVENUE GENERATED BY isTrueDirect\ndf_train['trafficSource_isTrueDirect'].replace({np.nan:'False'},inplace=True)\ndf_isTD=df_train[['trafficSource_isTrueDirect','totals_transactionRevenue','revenue_status']].groupby(df_train.trafficSource_isTrueDirect).aggregate({'totals_transactionRevenue':['mean'],\n                                                                                                              'revenue_status':['count']}).reset_index()\ndf_isTD.columns=['trafficSource_isTrueDirect','totals_transactionRevenue_mean','revenue_status_count']\ndf=df_isTD.sort_values(by='totals_transactionRevenue_mean',ascending=False)[df_isTD.totals_transactionRevenue_mean>0]\ndisplay(df.style.format(formatter))\n\nplt.subplots(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.title('REVENUE MEAN BY isTrueDirect',color='b',fontsize=12)\nplt.xlabel('isTrueDirect',color='b',fontsize=12)\nplt.ylabel('Mean Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.totals_transactionRevenue_mean,color='grey')\nplt.xticks(range(len(df)),df.trafficSource_isTrueDirect,rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\n\n\nplt.subplot(1,2,2)\nplt.title('NUMBER OF TRANSACTIONS WITH REVENUE BY isTrueDirect',color='b',fontsize=12)\nplt.xlabel('isTrueDirect',color='b',fontsize=12)\nplt.ylabel('Count of Transactions with Revenue',color='b',fontsize=12)\nplt.bar(range(len(df)),df.revenue_status_count,color='orange')\nplt.yticks(fontsize=12)\nplt.xticks(range(len(df)),df.trafficSource_isTrueDirect,rotation=90,fontsize=12)\nplt.show()","8e7568f2":"#REVENUE GENERATED BY MEDIUM\nrevenue_transaction_visualization(df_train,'trafficSource_medium','MEDIUM')","03ebb95b":"#REVENUE GENERATED BY MEDIUM\nrevenue_transaction_visualization(df_train,'trafficSource_referralPath','referralPath')","9da06636":"#AS IDENTIFIED IN EDA COUNTRY Anguilla HAS A VERY HIGH VALUE SINGLE VISIT TRANSACTION\nprint('Dropping following observation:')\ndisplay(train_cpy[train_cpy.geoNetwork_country=='Anguilla'])\n\n#DROPING THIS OUTLIER\ntrain_cpy.drop(train_cpy[train_cpy.geoNetwork_country=='Anguilla'].index,axis=0,inplace=True)\n\n#RESETING INDEX\ntrain_cpy.reset_index(drop=True,inplace=True)\n\n#COMBINING TRAIN AND TEST DATASET\ndf_combi=pd.concat([train_cpy,df_test],ignore_index=True)\n\n#FEATURE SUMMARY FOR COMBINED DATASET\ndf_combi_fs=feature_summary(df_combi)\ndisplay(df_combi_fs)","47b1d42e":"#EXTRACTING DAY_OF_WEEK, HOUR, DAY, MONTH FROM DATE \ndf_combi['date'] = pd.to_datetime(df_combi['visitStartTime'], unit='s')\ndf_combi['day_of_week'] = df_combi['date'].dt.dayofweek\ndf_combi['hour'] = df_combi['date'].dt.hour\ndf_combi['day'] = df_combi['date'].dt.day\ndf_combi['month'] = df_combi['date'].dt.month\n\n#ADDING ANOTHER FEATURE revenue_status TO INDICATE PRESENCE\/ABSENCE OF REVENUE FOR EACH OBSERVATION\ndf_combi['revenue_status']=df_combi.totals_transactionRevenue.apply(lambda x: 0 if x==0 else 1)","55c9647e":"%%time\n#CONVERTING ALL THE STRINGS IN CATEGORICAL FEATURES TO LOWER CASE\nfor col in df_combi.columns:\n    if ((df_combi[col].dtype=='object') & (col!='fullVisitorId')):\n        df_combi[col]=df_combi[col].apply(lambda x:str(x).lower())\n        \n#REPLACING STRING 'nan' WITH np.nan\ndf_combi.replace('nan',np.nan,inplace=True)","e9a09575":"%%time\n#CONVERTING CATEGORICAL FEATURES (LESS THAN 10 UNIQUE VALUES) TO DUMMIES\ndf_combi.drop(['device_isMobile'],axis=1,inplace=True)\n\ncat_col=['channelGrouping','device_deviceCategory','tsadclick_slot','tsadclick_adNetworkType','tsadclick_isVideoAd','trafficSource_medium',\n        'geoNetwork_continent']\n\nfor col in cat_col:\n    df_combi[col]=df_combi[col].apply(lambda x: str(x).replace(\" \",\"_\"))\n    \ndummy=pd.DataFrame()\n\nfor col in cat_col:\n    if col.find('_')!=-1:\n        col_name=col.split('_')[1]\n    else:\n        col_name=col\n    dummy=pd.concat([dummy,pd.get_dummies(df_combi[col],prefix=col_name)],axis=1)\n    \nprint('Newly created dummy cols:',len(dummy.columns))\ndf_combi=pd.concat([df_combi,dummy],axis=1)\n\ndf_combi.drop(cat_col,axis=1,inplace=True)","88b36a14":"df_combi.head()","fb330d5e":"#SOME BASIC DATA CLEANUP\ndf_combi['totals_newVisits'].fillna(0,inplace=True) \ndf_combi['totals_bounces'].fillna(0,inplace=True)\ndf_combi['tsadclick_page'].fillna(0,inplace=True)\ndf_combi['trafficSource_isTrueDirect'].replace({np.nan:0,'true':1},inplace=True)","386d4bf6":"%%time\n#GENERATING RANKS FOR CATEGORICAL FEATURES WITH UNIQUE VALUES GREATER THAN 10\n#RANKS ARE GENERATED USING REVENUE PERCENTAGE\ncols=[x for x in df_combi.columns if x not in ['fullVisitorId','sessionId','geoNetwork_networkDomain','tsadclick_gclId']]\n\nfor col in cols:\n    if df_combi[col].dtype=='object':\n        df_combi[col].fillna('others',inplace=True)\n        col_list=['revenue_status','totals_transactionRevenue']\n        col_list.append(col)\n        print(col_list)\n        df=df_combi[col_list].groupby(col).aggregate({col:['count'],'revenue_status':['sum'],'totals_transactionRevenue':['sum']}).reset_index()\n        df.columns=[col,col+\"_count\",'revenue_status_sum','totals_transactionRevenue_sum']\n        df['revenue_perc']=df['totals_transactionRevenue_sum']\/df[col+\"_count\"]\n        df['rank']=df['revenue_perc'].rank(ascending=1)\n        \n        replace_dict={}\n        final_dict={}\n        for k,col_val in enumerate(df[col].values):\n            replace_dict[col_val]=df.iloc[k,5]\n        final_dict[col]=replace_dict\n        df_combi.replace(final_dict,inplace=True)\n        del df,replace_dict,final_dict\n        gc.collect()","e4e55a85":"#SPLITING COMBINED DATASET BACK TO TRAIN AND TEST SETS\ntrain=df_combi[:len(train_cpy)]\ntest=df_combi[len(train_cpy):]","fed3f61e":"train.head()","88d9852a":"test.head()","6766de5c":"%%time\n#REPLACING DOT WITH SPACE IN FEATURE geoNetwork_networkDomain\n#THIS IS DONE TO TREAT IT AS TEXT AND WE WILL USE TfidfVectorizer TO EXTRACT FEATURES\ntrain['geoNetwork_networkDomain'].fillna('unknown.unknown',inplace=True)\ntest['geoNetwork_networkDomain'].fillna('unknown.unknown',inplace=True)\n\ntrain['geoNetwork_networkDomain']=train.geoNetwork_networkDomain.apply(lambda x: x.replace('.',' '))\ntest['geoNetwork_networkDomain']=test.geoNetwork_networkDomain.apply(lambda x: x.replace('.',' '))","d6f27318":"%%time\n#USING TfidfVectorizer TO EXTRACT FEATURES FROM geoNetwork_networkDomain\nTvect=TfidfVectorizer(ngram_range=(1,2),max_features=20000)\nvect=Tvect.fit(train['geoNetwork_networkDomain'])\ntrain_vect=vect.transform(train['geoNetwork_networkDomain'])\ntest_vect=vect.transform(test['geoNetwork_networkDomain'])\n\n#DIMENSIONALITY REDUCTION ON EXTRACTED FEATURES\nsvd=TruncatedSVD(n_components=10)\n\n#CREATING DATAFRAMES AFTER FEATURE EXTRACTION AND REDUCTION\nvect_cols=['vect'+str(x) for x in range(1,11)]\ndf_train_vect=pd.DataFrame(svd.fit_transform(train_vect),columns=vect_cols)\ndf_test_vect=pd.DataFrame(svd.fit_transform(test_vect),columns=vect_cols)","84cab1d1":"#VIEW OF EXTRACTED AND REDUCED FEATURES\nprint(train_vect.shape,test_vect.shape)\ndisplay(df_train_vect.head())\ndisplay(df_test_vect.head())\nprint('Shape of vector dataframes:',df_train_vect.shape,df_test_vect.shape)","d74e937c":"X=train.drop(['sessionId','visitId','date','geoNetwork_networkDomain','tsadclick_gclId'],axis=1)\nX_test=test.drop(['sessionId','visitId','date','geoNetwork_networkDomain','tsadclick_gclId'],axis=1)   ","6a82a424":"#REORDERING INDEX FOR TEST DATASET\n#THIS IS REQUIRED BEFORE CONCATENATING DATAFRAMES\nX_test.reset_index(drop=True,inplace=True)\nX_test.head()","1afac568":"#CONCATENATING WITH TEXT FEATURES \nX=pd.concat([X,df_train_vect],axis=1)\nX_test=pd.concat([X_test,df_test_vect],axis=1)","052c713e":"#VIEW OF TRAIN AND TEST DATASET SHAPE\nprint('Before creating aggregated features')\nprint('Train shape:',X.shape,' Test shape:',X_test.shape)","03263ad0":"%%time\nagg_func={}\nagg_col=['fullVisitorId']\nfor col in [x for x in X.columns if x not in ['fullVisitorId']]:\n    if col=='totals_transactionRevenue':\n        agg_func[col]=['sum']\n        agg_col.append(str(col)+'_sum')\n    elif col=='revenue_status':\n        agg_func[col]=['sum']\n        agg_col.append(str(col)+'_sum')\n    else:\n        agg_func[col]=['sum','max','min','mean','var','std']\n        agg_col.append(str(col)+'_sum')\n        agg_col.append(str(col)+'_max')\n        agg_col.append(str(col)+'_min')\n        agg_col.append(str(col)+'_mean')\n        agg_col.append(str(col)+'_var')\n        agg_col.append(str(col)+'_std')\n    \nX=X.groupby(X.fullVisitorId).aggregate(agg_func).reset_index()\nX.columns=agg_col\n\nX_test=X_test.groupby(X_test.fullVisitorId).aggregate(agg_func).reset_index()\nX_test.columns=agg_col","a6bd035e":"%%time\n\n#CREATING y_dummy FOR USING STRATIFIED KFOLD\ny_dummy=X.revenue_status_sum.apply(lambda x: 0 if x==0 else 1)\n\n#TARGET FEATURE CONVERTED TO NATURAL LOG\n# y=pd.Series(X['totals_transactionRevenue_sum'])\ny=X.totals_transactionRevenue_sum.apply(lambda x: np.log1p(x))\n\n#PEPARING DATA FOR TRAINING LGBM MODEL\nX=X.drop(['totals_transactionRevenue_sum','fullVisitorId','revenue_status_sum'],axis=1)\n\n#FINAL DATAFRAME FOR SUBMISSION\ncol=['fullVisitorId','totals_transactionRevenue_sum']\nfinal=X_test[col] \nfinal.columns=['fullVisitorId','PredictedLogRevenue']\n\n#FINAL TEST FEATURES USED FOR PREDICTING SUBMISSION\nX_test=X_test.drop(['fullVisitorId','totals_transactionRevenue_sum','revenue_status_sum'],axis=1)","ce65a339":"print('After creating aggregated features')\nprint('Train shape:',X.shape,' Test shape:',X_test.shape)","3a5480c9":"%%time\n#LGBMRegressor. THIS REQUIRES FURTHER PARAMETER TUNINIG\nmodel=LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=-1,learning_rate=0.01,n_estimators=1000,max_bin=255,subsample_for_bin=50000,\n              objective=None,min_split_gain=0,min_child_weight=3,min_child_samples=10,subsample=1,subsample_freq=1,colsample_bytree=1,\n              reg_alpha=0.1,reg_lambda=0,seed=17,silent=False,nthread=-1,n_jobs=-1)\n\n\nk=1\nsplits=5\navg_score=0\n\n\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\nprint('\\nStarting KFold iterations...')\nfor train_index,test_index in skf.split(X,y_dummy):\n    df_X=X.iloc[train_index,:]\n    df_y=y.iloc[train_index]\n    val_X=X.iloc[test_index,:]\n    val_y=y.iloc[test_index]\n\n    model.fit(df_X,df_y)\n\n    preds_x=pd.Series(model.predict(val_X))\n    acc=rsme(val_y,preds_x)\n    print('Iteration:',k,'  rmse:',acc)\n    \n    if k==1:\n        score=acc\n        model1=model\n        preds=pd.Series(model.predict(X_test))\n        \n    else:\n        preds1=pd.Series(model.predict(X_test))\n        preds=preds+preds1\n        if score>acc:\n            score=acc\n            model1=model\n    avg_score=avg_score+acc        \n    k=k+1\nprint('\\n Best score:',score,' Avg Score:',avg_score\/splits)\npreds=preds\/splits","202cd2e7":"#PREPARING PREDICTED DATA\nfinal['PredictedLogRevenue']=pd.Series(preds)\n#GROUPING PREDICTED DATA ON fullVisitorId\nfinal = final.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\nfinal.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\n","8e44cf76":"final","728281eb":"#READING SUMISSION FILE\nsubmission=pd.read_csv(path1+'sample_submission.csv')\n\n#CREATING JOIN BETWEEN PREDICTED DATA WITH SUBMISSION FILE\nsubmission=submission.join(final.set_index('fullVisitorId'),on='fullVisitorId',lsuffix='_sub')\nsubmission.drop('PredictedLogRevenue_sub',axis=1,inplace=True)\n\n#HANDLING NaN IN CASE OF MISSING fullVisitorId\nsubmission.fillna(0,inplace=True)\n\n#SUBMITING FILE\nsubmission.to_csv('LGBM_submission.csv',index=False)","73cf6c82":"<h2>Understanding Revenue generated by Region<\/h2>\n<ul>\n <li>Maximum Mean Revenue 23045564.85 is for <b>Zulia<\/b> and Count of Transactions with Revenue is 239\n <li>Maximum Count of Transactions with Revenue 107495 for <b>California<\/b> \n <li>Maximum mean revenue is for Zulia. Although Zulia have very few transactions with revenue.\n <li><b>California<\/b> has maximum count for transactions with Revenue and also generating good revenue 3493169.36\n<\/ul>","932ce95f":"<h2>Understanding Revenue generated by Device (mobile\/non mobile)<\/h2>\n<ul>\n <li>More revenue is generated by non mobile devices\n <li>More transactions with revenue are done from non mobile devices\n \n<\/ul>","59fc6006":"<h2>Analyzing Each Feature one by one<\/h2>\nWill try to understand following points\n<ul>\n<li>Number of transactions generating revenue\n<li>'Revenue mean' and 'Transactions with revenue count' by browser\n<li>'Revenue mean' and 'Transactions with revenue count' by operating system\n<li>Revenue, Transactions with Reveune and Total Transactions by date\n <li>Maximum Mean Revenue is for country <b>Anguilla<\/b> and Count of Transactions with Revenue is just one\n <li>Maximum Count of Transactions with Revenue for country <b>United States<\/b> and Mean Revenue is 3982082.36\n <li>This gives opportunity for discarding observations which can cause baised model,e.g. observations covering country <b>Anguilla<\/b>\n  <li>Maximum Mean Revenue is for city <b>Fort Collins<\/b> and Count of Transactions with Revenue is 7\n <li>Maximum Count of Transactions with Revenue for city <b>Mountain View<\/b> and Mean Revenue is 3084426.18\n <li>For number of cities high Revenue is generated by very few transactions.\n <li>Many cities have zero revenue although there are number of non zero transactions. There requires a bit for further analysis.\n  <li>Maximum Mean Revenue 536500000.00 is for domain <b>dialpad.com<\/b> and Count of Transactions with Revenue is 2\n <li>Maximum Count of Transactions with Revenue for domain <b>unknown.unknown<\/b> and Mean Revenue is 238995.99\n <li>Domain generating Maximum revenue have very few transactions\n <li>Whereas Maximum transactions with revenue is done by unknown domains.\n <li>Maximum Mean Revenue 3801967.43 is for subcontinent <b>Northern America<\/b> and Count of Transactions with Revenue is 390657\n <li>Maximum Count of Transactions with Revenue for subcontinent <b>Northern America<\/b> \n <li>Maximum mean revenue and maximum transactions with revenue is from same subcontinent\n <li>Maximum Mean Revenue 23045564.85 is for region <b>Zulia<\/b> and Count of Transactions with Revenue is 239\n <li>Maximum Count of Transactions with Revenue 107495 for region <b>California<\/b> \n <li>Maximum mean revenue is for region Zulia. Although Zulia have very few transactions with revenue.\n <li><b>California<\/b> region has maximum count for transactions with Revenue and also generating good revenue 3493169.36\n <li>Maximum Mean Revenue 3340915.72 is for continent <b>Americas<\/b> and Count of Transactions with Revenue is 450377\n <li>Maximum Count of Transactions with Revenue 450377 for continent <b>Americas<\/b> \n <li><b>Americas<\/b> continent has maximum count for transactions with Revenue and also maximum mean revenue\n <li>Maximum Mean Revenue 30035000.00 is for metro <b>Providence-New Bedford,MA<\/b> and Count of Transactions with Revenue is 6\n <li>Maximum Count of Transactions with Revenue\t95913 for metro <b>San Francisco-Oakland-San Jose CA<\/b> \n <li>Only 6 transactions with revenue are generation maximum mean revenue for <b>Providence-New Bedford,MA<\/b> metro. This need to analyzed further for improving model.\n<\/ul>\n<font color='red'>work in progress...<\/font>","e5d8b5ae":"<h2>Understanding Revenue generated by adContent<\/h2>\n<ul>\n <li>Maximum Mean Revenue 3346865.67 is for <b>KeyWord:Google Branded Gear<\/b> and Count of Transactions with Revenue is 67\n <li>Maximum Count of Transactions with Revenue\t5122 for <b>Google Merchandise Collection<\/b> and mean revenue is 2920404.14 \n <li>Similar analysis on Test data will help in understanding AdContent better. This may require futher data cleaning or preparation. As data is appearing bit unstructured.\n <li>After comparing train and test data for AdContent it is clear we don't need any data cleaning or preparation. As values in train and test set are similar.\n<\/ul>","d7ebd291":"<h2>Preparing Submission<\/h2>\nWhile preparing submission we have to keep few points in mind\n<ul>\n<li>Number of observations in test set 804684\n<li>Number of entries in submission file 617242\n<li>Therefore after predicting will be will grouping predicted value on <i>fullVisitorId<\/i>, and \n<li>Then creating a join with submission dataframe to get final submission file\n<li>I was missing this trick in first go and LB score was 2.005 :). Now it is 1.4431\n<\/ul>\n<h2>Score log<\/h2>\n<ol>\n<li>Score improved from 2.005 to 1.4431 by preparing predicted data\n<li>By further data preparation score improved from 1.4431 to 1.4389\n<li>Grouped data by <b>fullVisitorId<\/b> and applied aggregates score improved from 1.4389 to 1.4281 \n<li>Score further improved from 1.4281 to 1.470 by converting feature <b>geoNetwork_networkDomain<\/b> into text and using TfidfVectorizer for text feature extraction\n<li>Score is improved from 1.4270 to 1.4260 by dropping observation for country <b>Anguilla<\/b>. This improvement is direct outcome of EDA\n <\/ol>","056ff627":"<h2>Understanding Revenue generated by Country<\/h2>\n<ul>\n <li>Maximum Mean Revenue is for <b>Anguilla<\/b> and Count of Transactions with Revenue is just one\n <li>Maximum Count of Transactions with Revenue for <b>United States<\/b> and Mean Revenue is 3982082.36\n <li>This gives opportunity for discarding observations which can cause baised model \n<\/ul>","19ecf4a3":"<h2>Understanding Revenue generated by isTrueDirect<\/h2>\n<ul>\n <li>Mean Revenue is 4169993.21 for <b>True Direct<\/b> and 631261.04 for false\n <li>Transactions with revenue is 274005 for <b>True Direct<\/b> and 629648 for false\n<\/ul>","e15f49a0":"<h2>Understanding Revenue generated by subContinent<\/h2>\n<ul>\n <li>Maximum Mean Revenue 3801967.43 is for <b>Northern America<\/b> and Count of Transactions with Revenue is 390657\n <li>Maximum Count of Transactions with Revenue for <b>Northern America<\/b> \n <li>Maximum mean revenue and maximum transactions with revenue is from same subcontinent\n<\/ul>","04a6f030":"<h2>Understanding Revenue generated by City<\/h2>\n<ul>\n <li>Maximum Mean Revenue is for <b>Fort Collins<\/b> and Count of Transactions with Revenue is 7\n <li>Maximum Count of Transactions with Revenue for <b>Mountain View<\/b> and Mean Revenue is 3084426.18\n <li>For number of cities high Revenue is generated by very few transactions.\n <li>Many cities have zero revenue although there are number of non zero transactions. There requires a bit for further analysis.\n<\/ul>","95186b6a":"<font color='blue'><i>Please upvote if you find notebook useful<\/i><\/font><br>\n\n<h2>Key Machine Learning Techniques used in this Notebook<\/h2>\n<ul>\n    <li>Creating Dummy features out of categorical features\n    <li>Generating aggregated features with groupby\n    <li>Replacing categorical features with Ranks\n    <li>Dimensionality Reduction on sparse matrix (TruncatedSVD)\n    <li>Feature extraction from text features (TfidfVectorizer)\n    <li>StratifiedKFold for creating cross validation sets\n<\/ul>\n<font color='red'><i>Note: This is not a tutorial to above mentioned techniques. But their implementation on a complex dataset<\/i><\/font>","13be996c":"<h2>Understanding Revenue generated by networkDomain<\/h2>\n<ul>\n <li>Maximum Mean Revenue 536500000.00 is for <b>dialpad.com<\/b> and Count of Transactions with Revenue is 2\n <li>Maximum Count of Transactions with Revenue for <b>unknown.unknown<\/b> and Mean Revenue is 238995.99\n <li>Domain generating Maximum revenue have very few transactions\n <li>Whereas Maximum transactions with revenue is done by unknown domains.\n<\/ul>","3b2959b1":"\n<h2>Problem Statement<\/h2>\n\nIn this competition, you\u2019re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to <b>predict revenue per customer.<\/b> \n\n<br><br>\nSubmissions are scored on the <b>root mean squared error<\/b>. RMSE or RMSD is defined as:\n\n![RSME or RSMD](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/eeb88fa0f90448e9d1a67cd7a70164f674aeb300)\n\n<br><br>\n Final submission deadline: <b>November 15, 2018<\/b>\n<h2>GStore EDA<\/h2>\n<ol>\n    <li>Data Preparation\n        <ul>\n            <li>Moved Json Feature extraction to another [notebook ](https:\/\/www.kaggle.com\/rahullalu\/gstore-datapreparation)\n            <li>Will be reading files generated by above notebook\n        <\/ul>\n  <li>Further Data Preparation\n          <ul>\n           <li>Converting a set of categorical features to dummy features. Where categories are less than 10\n           <li>Replacing categorical features with categories greater than 10 with ranked values calculated on Revenue per Transaction\n              <li>Factorize <b>tsadclick_gclId<\/b> and <b>geoNetwork_networkDomain<\/b>\n          <\/ul>\n      <li>Exploratory Analysis Summary<font color=\"red\">(work in progress)<\/font>\n<ul>\n    <li>Number of transactions generating revenue\n    <li><b>Revenue mean<\/b> and <b>Transactions with revenue count<\/b> by browser\n    <li><b>Revenue mean<\/b> and <b>transactions with revenue count<\/b> by operating system\n    <li><b>Revenue, Transactions with Reveune<\/b> and <b>Total Transactions<\/b> by date    \n<li>Maximum Mean Revenue is for country <b>Anguilla<\/b> and Count of Transactions with Revenue is just one\n <li>Maximum Count of Transactions with Revenue for country <b>United States<\/b> and Mean Revenue is 3982082.36\n <li>This gives opportunity for discarding observations which can cause baised model,e.g. observations covering country <b>Anguilla<\/b>\n  <li>Maximum Mean Revenue is for city <b>Fort Collins<\/b> and Count of Transactions with Revenue is 7\n <li>Maximum Count of Transactions with Revenue for city <b>Mountain View<\/b> and Mean Revenue is 3084426.18\n <li>For number of cities high Revenue is generated by very few transactions.\n <li>Many cities have zero revenue although there are number of non zero transactions. There requires a bit for further analysis.\n  <li>Maximum Mean Revenue 536500000.00 is for domain <b>dialpad.com<\/b> and Count of Transactions with Revenue is 2\n <li>Maximum Count of Transactions with Revenue for domain <b>unknown.unknown<\/b> and Mean Revenue is 238995.99\n <li>Domain generating Maximum revenue have very few transactions\n <li>Whereas Maximum transactions with revenue is done by unknown domains.\n <li>Maximum Mean Revenue 3801967.43 is for subcontinent <b>Northern America<\/b> and Count of Transactions with Revenue is 390657\n <li>Maximum Count of Transactions with Revenue for subcontinent <b>Northern America<\/b> \n <li>Maximum mean revenue and maximum transactions with revenue is from same subcontinent\n <li>Maximum Mean Revenue 23045564.85 is for region <b>Zulia<\/b> and Count of Transactions with Revenue is 239\n <li>Maximum Count of Transactions with Revenue 107495 for region <b>California<\/b> \n <li>Maximum mean revenue is for region Zulia. Although Zulia have very few transactions with revenue.\n <li><b>California<\/b> region has maximum count for transactions with Revenue and also generating good revenue 3493169.36\n <li>Maximum Mean Revenue 3340915.72 is for continent <b>Americas<\/b> and Count of Transactions with Revenue is 450377\n <li>Maximum Count of Transactions with Revenue 450377 for continent <b>Americas<\/b> \n <li><b>Americas<\/b> continent has maximum count for transactions with Revenue and also maximum mean revenue\n <li>Maximum Mean Revenue 30035000.00 is for metro <b>Providence-New Bedford,MA<\/b> and Count of Transactions with Revenue is 6\n <li>Maximum Count of Transactions with Revenue\t95913 for metro <b>San Francisco-Oakland-San Jose CA<\/b> \n <li>Only 6 transactions with revenue are generation maximum mean revenue for <b>Providence-New Bedford,MA<\/b> metro. This need to analyzed further for improving model.\n <\/ul>\n    <li>Developing baseline model\n        <ul>\n            <li>Grouped data by <b>fullVisitorId<\/b> and applied aggregates\n            <li>Converting <b>totals_transactionRevenue<\/b> to natual log\n             <li>Creating a dummy traget category feature giving revenue or no revenue. This feature will be used for StratifiedKfold  \n            <li>Developing LGBMRegressor model\n            <li>Basic idea is to achieve best score by data preparation using  single model \n        <\/ul>\n     <li>While preparing submission we have to keep few points in mind\n<ul>\n<li>Number of observations in test set 804684\n<li>Number of entries in submission file 617242\n<li>Read train and test file with following data type setup <i><b>dtype={'fullVisitorId':str,'date':str,'sessionId':str,'visitId':str,'visitStartTime':str}<\/b><\/i>\n<li>Therefore after predicting group predicted values on <i>fullVisitorId<\/i>, and \n<li>Then creating a join with submission dataframe to get final submission file\n<li>I was missing this trick in first go and LB score was 2.005 :). Now it is 1.4431\n<li>By further data preparation score improved from 1.4431 to 1.4389\n<li>Grouped data by <b>fullVisitorId<\/b> and applied aggregates score improved from 1.4389 to 1.4281 \n<li>Score further improved from 1.4281 to 1.470 by converting feature <b>geoNetwork_networkDomain<\/b> into text and using TfidfVectorizer for text feature extraction\n<li>Score is improved from 1.4270 to 1.4260 by dropping observation for country <b>Anguilla<\/b>. This improvement is direct outcome of EDA\n    \n<\/ul>\n\n<\/ol>\n","53f8ce55":"<h2>Understanding Revenue generated by Medium<\/h2>\n<ul>\n <li>Maximum Mean Revenue 12509974.45 is for <b>cpm<\/b> and Count of Transactions with Revenue is 6262\n <li>Maximum Count of Transactions with Revenue\t381561 for <b>organic<\/b> and mean revenue is 855382.26 \n <li>Medium has only 6 unique values. Medium <b>cpm<\/b> has maximum mean revenue generated by least transactions with revenue\n<\/ul>","538a590f":"<h2>Understanding Number Of Transations Generating Revenue by Operating System<\/h2>\n<ul>\n <li>There are total 24 unique values for operating systems\n <li>But revenue is generated using only 7 operating systems\n <li>Maximum mean revenue is generated using chrome os\n <li>Maximum transactions with revenue are done using windows\n <li>This shows few operating systems are more important for predicting revenue.\n<\/ul>","228d673e":"<h2>Understanding Number Of Transations Generating Revenue by Browser<\/h2>\n<ul>\n <li>There are total 128 unique values for browser\n <li>But revenue is generated using only 9 browsers\n <li>Maximum mean revenue is generated using firefox\n <li>Maximum transactions with revenue are done using chrome\n <li>This shows few browsers are more important for predicting revenue.\n<\/ul>","e012ead5":"<h2>Understanding Revenue generated by Metro<\/h2>\n<ul>\n <li>Maximum Mean Revenue 30035000.00 is for <b>Providence-New Bedford,MA<\/b> and Count of Transactions with Revenue is 6\n <li>Maximum Count of Transactions with Revenue\t95913 for <b>San Francisco-Oakland-San Jose CA<\/b> \n <li>Only 6 transactions with revenue are generation maximum mean revenue. This need to analyzed further for improving model.\n<\/ul>","ad92262e":"<h2>Understanding Revenue, Transactions with Revenue and Total Transactions by Date<\/h2>\n<ul>\n <li>Revenue mean by date 0.4208 (scaling 1e10) and Revenue by date max value  2.7181 (scaling 1e10)\n <li>Transactions with Revenue by date mean 31.4617 and Transactions with Revenue by date max value 87\n <li>Total Transactions by date mean 2489 and Total Transactions by date max value 4807  \n<\/ul>","f39e4436":"<h2>Understanding Number Of Transations Generating Revenue<\/h2>\n<ul>\n <li>Only 1.27% Transactions generate revenue\n<\/ul>","d436426a":"<h2>Understanding Revenue generated by Continent<\/h2>\n<ul>\n <li>Maximum Mean Revenue 3340915.72 is for <b>Americas<\/b> and Count of Transactions with Revenue is 450377\n <li>Maximum Count of Transactions with Revenue 450377 for <b>Americas<\/b> \n <li><b>Americas<\/b> has maximum count for transactions with Revenue and also maximum mean revenue\n<\/ul>"}}