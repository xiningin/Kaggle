{"cell_type":{"fb69cf68":"code","fbeae48b":"code","550db270":"code","b41e067d":"code","98577abe":"code","8351f1eb":"code","f506fa52":"code","d5d3be7e":"code","6b799c1b":"code","c6384868":"code","599cf79a":"code","112657ce":"code","c590389c":"code","91650b88":"code","627543db":"code","038157a3":"code","846f34c4":"markdown"},"source":{"fb69cf68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fbeae48b":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","550db270":"datasets = [train,test]\n\nfor df in datasets:\n    df['Title'] = df.Name.str.extract('([A-Za-z]+)\\.', expand=False)","b41e067d":"for df in datasets:\n    df['hasCabin'] = np.where(pd.isnull(df['Cabin']),0,1)\n    df.loc[pd.isnull(df['Embarked']),'Embarked'] = 'None'\n    df.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n    \ntrain.head()","98577abe":"from sklearn.preprocessing import LabelEncoder\n\nSEED = 1\nnp.random.seed(SEED)\nle = dict()\nle['Sex'] = LabelEncoder()\nle['Sex'].fit(train.Sex)\nle['Embarked'] = LabelEncoder()\nle['Embarked'].fit(train.Embarked)\nle['Title'] = LabelEncoder()\nle['Title'].fit(pd.concat([train.Title, test.Title], axis=0))\n\nfor df in datasets:\n    df['Sex'] = le['Sex'].transform(df['Sex'])\n    df['Embarked'] = le['Embarked'].transform(df['Embarked'])\n    df['Title'] = le['Title'].transform(df['Title'])\n    \ntrain.head()\n","8351f1eb":"for df in datasets:\n    df.loc[pd.isnull(df['Age']), 'Age'] = df['Age'].mean()\n\nfor df in datasets:\n    df.loc[:,'Age'] = np.round(df['Age'])","f506fa52":"for df in datasets:\n    df.loc[pd.isnull(df['Fare']),'Fare'] = df['Fare'].mean()\n","d5d3be7e":"train.describe()","6b799c1b":"\nx_train0 = train.drop(['PassengerId','Survived'],axis=1)\ny_train0 = train['Survived']\n\nx_test0 = test.drop(['PassengerId'],axis=1)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train0)\nx_test = sc.fit_transform(x_test0)\n\ny_train = y_train0.values.astype('float32')\n","c6384868":"from keras import models\nfrom keras import layers\nfrom keras import optimizers","599cf79a":"epochs_num = 100\nbatch_size = 20\ninput_dim = len(x_train[0])","112657ce":"def get_model(input_dim):\n    model = models.Sequential()\n    model.add(layers.Dense(units = 7, kernel_initializer = 'lecun_uniform', activation = 'relu', input_dim = input_dim))\n    model.add(layers.Dense(units = 5, kernel_initializer = 'lecun_uniform', activation = 'relu'))\n    model.add(layers.Dense(units = 1, kernel_initializer = 'lecun_uniform', activation = 'sigmoid'))\n    model.compile(optimizer=optimizers.Adam(learning_rate=0.01),\n        loss='binary_crossentropy', metrics=['accuracy']) \n    return model","c590389c":"model = get_model(input_dim)\n\nhistory = model.fit(x_train, y_train, epochs=epochs_num, batch_size=batch_size, verbose=1)\n","91650b88":"predict = model.predict(x_test)","627543db":"my_submission = pd.DataFrame({\n\t'PassengerId': test.PassengerId, \n\t'Survived': pd.Series(predict.reshape((1,-1))[0]).round().astype(int)\n})\n\nmy_submission.head()","038157a3":"my_submission.to_csv('submission.csv', index=False)","846f34c4":"Use keras and simple relu to training."}}