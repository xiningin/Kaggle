{"cell_type":{"f7348437":"code","f9831e82":"code","76ca6847":"code","92f22620":"code","7248509b":"code","dba3ab61":"code","67752ed4":"code","3449c656":"code","d49592af":"code","89686ba0":"code","d2e5fa41":"code","43ceb8d5":"code","e4b38060":"markdown","1529c388":"markdown","f2066874":"markdown","00ddba68":"markdown","35e5aae8":"markdown","c40fb5b2":"markdown","a50ee2fd":"markdown"},"source":{"f7348437":"import tweepy as tw\nimport pandas as pd\nfrom collections import Counter","f9831e82":"with open(\"twitter-tokens.txt\", \"r\") as tfile:\n    consumer_key = tfile.readline().strip(\"\\n\")\n    consumer_secret = tfile.readline().strip(\"\\n\")\n    access_token = tfile.readline().strip(\"\\n\")\n    access_token_secret = tfile.readline().strip(\"\\n\")","76ca6847":"auth = tw.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\n\napi = tw.API(auth)\napi = tw.API(auth, wait_on_rate_limit=True)\n","92f22620":"list_friends = []\nlist_nr_followers = []\ndf_links = pd.DataFrame(columns=['from', 'to'])","7248509b":"user = api.get_user(\"\")\nscreen_name = \"\"\nc = tw.Cursor(api.friends, screen_name)  \nprint(user.screen_name)\nprint(user.followers_count)\n","dba3ab61":"for friend in tw.Cursor(api.friends, screen_name).items():\n    list_friends.append(friend.screen_name)\n    list_nr_followers.append(friend.followers_count)\n    df_links = df_links.append({\"from\": screen_name, \"to\": friend.screen_name}, ignore_index=True)\n    print(friend.screen_name) ","67752ed4":"for person in df_links[\"to\"]:\n    screen_name = person\n    c = tw.Cursor(api.friends, screen_name) \n    \n    for friend in tw.Cursor(api.friends, screen_name).items(50):\n        df_links = df_links.append({\"from\": screen_name, \"to\": friend.screen_name}, ignore_index=True)\n        print(friend.screen_name) ","3449c656":"df_fri = pd.DataFrame(list_friends)\ndf_foll = pd.DataFrame(list_nr_followers)\n\ndf_friends = pd.concat([df_fri, df_foll], axis = 1)\ndf_friends.head()","d49592af":"tweets = api.user_timeline(screen_name=\"\", \n                           include_rts = False,\n                           # NecWessary to keep full_text \n                           # otherwise only the first 140 words are extracted\n                           tweet_mode = 'extended'\n                          )\n    ","89686ba0":"all_tweets = []\nall_tweets.extend(tweets)\noldest_id = tweets[-1].id\nwhile True:\n    tweets = api.user_timeline(screen_name=\"\", \n                           # 200 is the maximum allowed count\n                           count=200,\n                           include_rts = False,\n                           max_id = oldest_id - 1,\n                           # Necessary to keep full_text \n                           # otherwise only the first 140 words are extracted\n                           tweet_mode = 'extended'\n                           )\n    if len(tweets) == 0:\n        break\n    oldest_id = tweets[-1].id\n    all_tweets.extend(tweets)\n    print('N of tweets downloaded till now {}'.format(len(all_tweets)))","d2e5fa41":"list_of_mentions = []\nfor info in all_tweets:\n    info = str(\"ID: {}\".format(info.id)) + str(info.created_at) + str(info.full_text) + \"\\n\"\n    tweet = info.split()\n    for i in tweet:\n        if i[0] == \"@\":\n            #Esta parte do c\u00f3digo serve para corrigir as men\u00e7\u00f5es. Muitas vezes quando usu\u00e1rio menciona algu\u00e9m ele termina com uma pontua\u00e7\u00e3o, v\u00edrgula ou dois pontos isso leva nosso iterador a contar uma \"@randolfeap.\" como uma men\u00e7\u00e3o nova e n\u00e3o como mais uma men\u00e7\u00e3o em \"@randolfeap\"\n            if not i[-1].isalpha() or i[-1].isnumeric():\n                list_of_mentions.append(i[:-1])\n            else:\n                list_of_mentions.append(i)\n            \n            \ndict_mentions = Counter(list_of_mentions) \ndf_mentions = pd.DataFrame.from_dict(dict_mentions, orient='index').reset_index()           ","43ceb8d5":"df_friends.to_csv(\"friends\",sep=\",\", encoding='utf-8', index=False)\ndf_mentions.to_csv(\"mentions\",sep=\",\", encoding='utf-8', index=False)\ndf_links.to_csv(\"links\",sep=\",\", encoding='utf-8', index=False)","e4b38060":"### here we download the 3.lins dataset. on the items parameters we are choosing the number \"friends of our friends\" we are downloading.","1529c388":"### Bellow here between \"\" you will put the name of the user you want to download the datasets.","f2066874":"### Bellow here between \"\" you will put the name of the user you want to download the datasets:","00ddba68":"### Passing twitter api keys. This is made reading a txt file with one key in each line","35e5aae8":"### Libraries","c40fb5b2":"### Extracting Data:\n\nIn this notebook we will be creating 3 dataset:\n\n1.List of friends(twitter call people you follow as friend)\n\n2.Number of times an @ is mentioned on a tweet. When a tweet is replyed it calls as an mention too.\n\n3.Connections. This is dataset created by the friends of our friends. This dataset is created with the intention of building a network graph\n\nTwitter api has a limit of how much data you can download so be aware of the number of friends and tweets you will download.","a50ee2fd":"### Bellow here between \"\" you will put the name of the user you want to download the datasets:"}}