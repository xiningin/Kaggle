{"cell_type":{"215989de":"code","f1258160":"code","fc8a5ec1":"code","d51a79f2":"code","15c109db":"code","7b9ab18b":"code","9c029700":"code","957ccbec":"code","04b3728d":"code","9855399d":"code","031dbac2":"code","8ee3560f":"code","272346d1":"code","d629ae10":"code","c01bfe1b":"code","5a80e01e":"code","63036cc9":"code","c24470d3":"code","aa61da9b":"code","0ac580c3":"code","373eea49":"code","f2c50776":"code","1a67e732":"code","a7c87cb2":"code","f0e0ac50":"code","f9f7cb4a":"code","7718aa8b":"markdown","028da770":"markdown","3081c8e9":"markdown","9e1cae87":"markdown","aa48777b":"markdown","01ceda0a":"markdown"},"source":{"215989de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1258160":"df=pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf","fc8a5ec1":"df['diagnosis']=df['diagnosis'].map({'M':1,'B':0})\ndf","d51a79f2":"df=df.drop(columns=['id','Unnamed: 32'])\ndf","15c109db":"df.isna().sum()","7b9ab18b":"X=df.drop(columns=['diagnosis'])\ny=df['diagnosis']","9c029700":"from sklearn.preprocessing import StandardScaler","957ccbec":"s=StandardScaler()","04b3728d":"new=s.fit_transform(X)\nnew","9855399d":"new.shape","031dbac2":"transformed_X=pd.DataFrame(new)\ntransformed_X","8ee3560f":"transformed_X.columns=X.columns\ntransformed_X","272346d1":"from sklearn.model_selection import train_test_split","d629ae10":"X_train,X_test,y_train,y_test=train_test_split(transformed_X,y,test_size=0.2)","c01bfe1b":"import sklearn\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","5a80e01e":"linear=LinearRegression()\nlinear.fit(X_train,y_train)","63036cc9":"linear.score(X_test,y_test)","c24470d3":"lg=LogisticRegression()\nlg.fit(X_train,y_train)","aa61da9b":"lg.score(X_test,y_test)","0ac580c3":"svc=SVC()\nsvc.fit(X_train,y_train)","373eea49":"svc.score(X_test,y_test)","f2c50776":"tree=DecisionTreeClassifier(criterion='entropy')\ntree.fit(X_train,y_train)","1a67e732":"tree.score(X_test,y_test)","a7c87cb2":"rf=RandomForestClassifier()","f0e0ac50":"rf.fit(X_train,y_train)","f9f7cb4a":"rf.score(X_test,y_test)","7718aa8b":"# Based on testing through different classifiers so far, Support Vector Classifier performed the best among them with an accuracy of 96.49%","028da770":"# Support Vector Classifier","3081c8e9":"# Linear Regression","9e1cae87":"# Decision Tree","aa48777b":"# Logistic Regression","01ceda0a":"# Random Forest"}}