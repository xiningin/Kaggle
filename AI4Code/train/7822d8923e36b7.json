{"cell_type":{"29e80fea":"code","627f98ab":"code","71499e05":"code","17b5247f":"code","5e8e35ea":"code","cd6ce728":"code","c2f5a40e":"code","f2608f0c":"code","577e3064":"code","c70e97ed":"code","7f01cd47":"code","02944651":"code","b715d875":"code","ea4340ea":"code","166a1e81":"code","9a0b6ff2":"code","ca3ba189":"code","2719f806":"code","2f1e37e7":"code","43d35610":"code","4df4ced0":"code","e5411674":"code","dedd5154":"code","f6177ce9":"code","bd3a0cb8":"code","8b333614":"code","00c0953e":"code","d81ebbff":"code","27c888b0":"code","a8eec5a5":"code","bc0db5e5":"code","719efa45":"code","f65e11d2":"code","d8cca2a1":"code","935a32da":"code","41698ed7":"code","a0f88956":"code","ae7dbf75":"code","4c238980":"code","e7f93bef":"code","9e490cd6":"code","9b662739":"code","6374b857":"code","9290c8e4":"code","9aefcb54":"code","aed0a5c3":"code","0c9836d5":"code","8e4b4967":"code","99ae6a42":"code","7161dfd8":"code","e872ca56":"code","13275072":"code","35e92a8b":"code","6986b386":"code","82bbf37a":"code","1ab95a68":"markdown","9513fbdc":"markdown","fa51da16":"markdown","ce7a4216":"markdown","c49a90c7":"markdown","1a49fa4b":"markdown","22e9d502":"markdown","5b54f913":"markdown","8323539f":"markdown","d21ecd12":"markdown","a8267cfc":"markdown","f5a5e2a2":"markdown","900a7559":"markdown"},"source":{"29e80fea":"import pandas as pd\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","627f98ab":"df_train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", index_col=\"Id\")\ndf_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\", index_col=\"Id\")","71499e05":"msno.matrix(df_train, figsize=(75, 30), labels=True) # so much null (white space)","17b5247f":"df = pd.concat([df_train, df_test], axis=0)\ndf.head()","5e8e35ea":"drop_col = [\"Neighborhood\", \"BsmtFinSF2\", \"MiscFeature\"]\nval_col = [\"LotFrontage\", \"MasVnrArea\", \"GarageYrBlt\", \"LotFrontage\", \"BsmtFinSF1\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\", \"GarageCars\", \"GarageArea\"]\ncat_col = [\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"Electrical\", \"GarageType\", \"GarageFinish\", \n           \"GarageQual\", \"GarageCond\", \"MasVnrType\", \"FireplaceQu\", \"Alley\"]\nbinary_col = [\"PoolQC\", \"Fence\"]\n# Add: Alley, FireplaceQu","cd6ce728":"df = df.drop(columns=drop_col)","c2f5a40e":"for i in val_col: \n    df[i].fillna(0, inplace=True)","f2608f0c":"for i in cat_col: \n    df[i] = df[i].fillna(\"No\")","577e3064":"for i in binary_col: \n    df[i].fillna(0, inplace=True)\n    df[i] = df[i].apply(lambda x: 0 if x == 0 else 1)","c70e97ed":"cor_df = df.select_dtypes(np.number).corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(cor_df)","7f01cd47":"df = pd.get_dummies(df.iloc[:, df.columns != \"SalePrice\"])\nX = df.iloc[:df_train.shape[0], :]\ny = df_train[\"SalePrice\"]\nX_test = df.iloc[df_train.shape[0] :, :]","02944651":"msno.matrix(X, figsize=(75, 30), labels=True) #NA checked","b715d875":"msno.matrix(X_test, figsize=(75, 30), labels=True)","ea4340ea":"sns.distplot(y)","166a1e81":"fig = plt.figure(figsize=(12, 5))\nfig.add_subplot(121)\nsns.boxplot(x=X[\"PoolQC\"], y=y)\nfig.add_subplot(122)\nsns.boxplot(x=X[\"Fence\"], y=y)","9a0b6ff2":"from sklearn.model_selection import train_test_split","ca3ba189":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.1, random_state=101)","2719f806":"print(X_train.shape, X_val.shape, X_test.shape)","2f1e37e7":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge","43d35610":"alpha_L2 = [15, 20, 30, 35, 40, 45, 50, 55]\nparameters = {'alpha':alpha_L2, 'solver':('svd', 'saga')}\nclf = GridSearchCV(Ridge(random_state=101), parameters)\nclf.fit(X_train.select_dtypes(np.number), y_train)","4df4ced0":"clf.best_params_","e5411674":"print(f'train score: {clf.best_score_}')\nprint(f'validation score: {clf.score(X_val, y_val)}')","dedd5154":"y_pred_ridge = clf.predict(X_test)\n\nsub_1 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred_ridge)], axis=1).rename(columns={0:\"SalePrice\"})\nsub_1.head()","f6177ce9":"# sub_1.to_csv(\"submission_Ridge.csv\", index=False)","bd3a0cb8":"from sklearn.linear_model import Lasso","8b333614":"alpha_L1 = [200, 220, 250, 280, 300]\nparameters = {'alpha':alpha_L1}\nclf = GridSearchCV(Lasso(random_state=101), parameters)\nclf.fit(X_train.select_dtypes(np.number), y_train)","00c0953e":"clf.best_params_","d81ebbff":"print(f'train score: {clf.best_score_}')\nprint(f'validation score: {clf.score(X_val, y_val)}')","27c888b0":"y_pred_lasso = clf.predict(X_test)\n\nsub_2 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred_lasso)], axis=1).rename(columns={0:\"SalePrice\"})\nsub_2.head()","a8eec5a5":"# sub_2.to_csv(\"submission_Lasso.csv\", index=False)","bc0db5e5":"from xgboost import XGBRegressor","719efa45":"xgboost = XGBRegressor(learning_rate=0.005,n_estimators=4500,\n                                     max_depth=5, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.005)","f65e11d2":"xgboost.fit(X_train, y_train)","d8cca2a1":"print(f'train score: {xgboost.score(X_train, y_train)}')\nprint(f'validation score: {xgboost.score(X_val, y_val)}')","935a32da":"y_pred_xgboost = xgboost.predict(X_test)\n\nsub_3 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred_xgboost)], axis=1).rename(columns={0:\"SalePrice\"})\nsub_3.head()","41698ed7":"# sub_3.to_csv(\"submission_XGBoost.csv\", index=False)","a0f88956":"# parameters = {'learning_rate': [0.005], 'n_estimators':[4500], 'max_depth':[5], 'reg_alpha':[0.005]}\n# clf = GridSearchCV(XGBRegressor(min_child_weight=0, gamma=0, \n#                                         colsample_bytree=0.7, objective='reg:linear', nthread=-1,\n#                                         scale_pos_weight=1, subsample=.7, seed=27), parameters)\n# clf.fit(X_train.select_dtypes(np.number), y_train)","ae7dbf75":"# clf.best_params_\n\n# # {'learning_rate': 0.005,\n# #  'max_depth': 5,\n# #  'n_estimators': 4500,\n# #  'reg_alpha': 0.005}","4c238980":"# print(f'train score: {clf.best_score_}')\n# print(f'validation score: {clf.score(X_val, y_val)}')\n\n# # train score: 0.8856452700799474\n# # validation score: 0.9125119162731631","e7f93bef":"# y_pred = clf.predict(X_test)\n\n# sub_3 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred)], axis=1).rename(columns={0:\"SalePrice\"})\n# sub_3.head()","9e490cd6":"# sub_3.to_csv(\"submission_XGBoost_Optimized.csv\", index=False)","9b662739":"from lightgbm import LGBMRegressor","6374b857":"lightgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=5,\n                                       learning_rate=0.01, \n                                       n_estimators=5500,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       )","9290c8e4":"lightgbm.fit(X_train, y_train)","9aefcb54":"print(f'train score: {lightgbm.score(X_train, y_train)}')\nprint(f'validation score: {lightgbm.score(X_val, y_val)}')","aed0a5c3":"y_pred_lgbm = lightgbm.predict(X_test)\n\nsub_4 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred_lgbm)], axis=1).rename(columns={0:\"SalePrice\"})\nsub_4.head()","0c9836d5":"# sub_4.to_csv(\"submission_LightGBM.csv\", index=False)","8e4b4967":"# parameters = {'learning_rate': [0.01], 'n_estimators':[5500, 6000, 7500], 'num_leaves':[3, 4, 5]}\n# clf = GridSearchCV(LGBMRegressor(objective='regression', \n#                                        max_bin=200, \n#                                        bagging_fraction=0.75,\n#                                        bagging_freq=5, \n#                                        bagging_seed=7,\n#                                        feature_fraction=0.2,\n#                                        feature_fraction_seed=7,\n#                                        verbose=-1,), parameters)\n# clf.fit(X_train.select_dtypes(np.number), y_train)","99ae6a42":"# clf.best_params_\n\n# #{'learning_rate': 0.01, 'n_estimators': 5500, 'num_leaves': 5}","7161dfd8":"# print(f'train score: {clf.best_score_}')\n# print(f'validation score: {clf.score(X_val, y_val)}')\n\n# #train score: 0.8856209897695116\n# # validation score: 0.9069389402737372","e872ca56":"# y_pred = clf.predict(X_test)\n\n# sub_5 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred)], axis=1).rename(columns={0:\"SalePrice\"})\n# sub_5.head()","13275072":"# sub_5.to_csv(\"submission_LightGBM_Optimized.csv\", index=False)","35e92a8b":"mul_lgbm = 0.30\nmul_xgboost = 0.47\nmul_ridge = 0.03\nmul_lasso = 0.2\nprint(mul_lgbm + mul_xgboost + mul_ridge + mul_lasso)","6986b386":"y_pred_final_1 = (y_pred_lgbm * mul_lgbm) + (y_pred_xgboost * mul_xgboost) + (y_pred_ridge * mul_ridge) + (y_pred_lasso * mul_lasso)\n\nsub_6 = pd.concat([pd.Series(X_test.index), pd.Series(y_pred_final_1)], axis=1).rename(columns={0:\"SalePrice\"})\nsub_6.tail()","82bbf37a":"sub_6.to_csv(\".\/submission_Merge_1.csv\", index=False) #0.12077","1ab95a68":"### Lasso Regression","9513fbdc":"## 4. training\/validation split","fa51da16":"## 2. Data Preprocessing (Feature Engineering)","ce7a4216":"### XGBoost","c49a90c7":"### LightGBM","1a49fa4b":"## Stacked Regressor (Merge the models together)","22e9d502":"### -- optional XGBoost with gridsearch (find best parameters)","5b54f913":"### -- optional LightGBM with gridsearch (find best parameters)","8323539f":"### Ridge Regression","d21ecd12":"## 3. Data Visualization & EDA","a8267cfc":"## 1. importing libraries&dataset","f5a5e2a2":"# House Prices: Advanced Regression Techniques\n## Predict sales prices and practice feature engineering, RFs, and gradient boosting\n\n### Competition Description\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n### Practice Skills\n- Creative feature engineering \n- Advanced regression techniques like random forest and gradient boosting","900a7559":"## 5. Modeling\n- Linear Regression\n    - [Ridge Regression (L2)](#Ridge-Regression)\n    - [Lasso Regression (L1)](#Lasso-Regression)\n- [XGBoost](#XGBoost)\n- [LightGBM](#LightGBM)"}}