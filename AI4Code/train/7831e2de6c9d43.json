{"cell_type":{"ddca2dc1":"code","fd8ee8f0":"code","a195bcc9":"code","4d8c8a67":"code","1fed7c07":"code","15dfcfa5":"code","8e08d377":"code","95463a5c":"code","fd0ca94f":"code","108bbef1":"code","5f3c31b9":"code","b63431c8":"code","ccd8c667":"code","95921df7":"code","cd297064":"code","5a0a02e2":"code","64b488f5":"markdown"},"source":{"ddca2dc1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd8ee8f0":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","a195bcc9":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.info()","4d8c8a67":"women = train_data.loc[train_data.Sex == 'female']['Survived']\n#print(women)\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","1fed7c07":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","15dfcfa5":"train_data.info()","8e08d377":"train_data=train_data.drop(['Name','Ticket'],axis=1)\ntest_data=test_data.drop(['Name','Ticket'],axis=1)\n","95463a5c":"#age = train_data.loc[train_data.Age== 'nan'][\"Survived\"]\n#sum(age)\/len(age)\n#print(age)\n\n\ntrain_data_age_test=train_data[train_data['Age'].isnull()]\na=train_data_age_test.index\na=list(a)\nb=[]\nfor i in range(0,891):\n    if i not in a:\n        b.append(i)\ntrain_data_age_train=train_data.loc[b,:]\ntrain_data_age_train=train_data_age_train.drop(['Cabin'],axis=1)\ntrain_data_age_test=train_data_age_test.drop(['Cabin'],axis=1)\n\ntrain_data_age_train['Embarked'].fillna(train_data_age_train['Embarked'].value_counts().index[0],inplace=True)\ntrain_data_age_test['Embarked'].fillna(train_data_age_test['Embarked'].value_counts().index[0],inplace=True)\n\ntrain_data_age_train=pd.get_dummies(train_data_age_train,drop_first=True)\ntrain_data_age_test=pd.get_dummies(train_data_age_test,drop_first=True)\n\ntrain_data_age_test=train_data_age_test.drop(['Age'],axis=1)\ntarget_age=train_data_age_train['Age']\ntrain_data_age_train=train_data_age_train.drop(['Age'],axis=1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf.fit(train_data_age_train,target_age)\npredit=rf.predict(train_data_age_test)\n\ntrain_data_age_test['Age']=predit\ntrain_data_age_train['Age']=target_age\n\ntrain_data=pd.concat([train_data_age_train,train_data_age_test])","fd0ca94f":"#age = train_data.loc[train_data.Age== 'nan'][\"Survived\"]\n#sum(age)\/len(age)\n#print(age)\n\n\ntest_data_age_test=test_data[test_data['Age'].isnull()]\na=test_data_age_test.index\na=list(a)\nb=[]\nfor i in range(0,418):\n    if i not in a:\n        b.append(i)\ntest_data_age_train=test_data.loc[b,:]\n\n#delete unneccesary column as it cotain too much of Nan Vlue \ntest_data_age_train=test_data_age_train.drop(['Cabin'],axis=1)\ntest_data_age_test=test_data_age_test.drop(['Cabin'],axis=1)\n\n#fill the embarked column\ntest_data_age_train['Embarked'].fillna(test_data_age_train['Embarked'].value_counts().index[0],inplace=True)\ntest_data_age_test['Embarked'].fillna(test_data_age_test['Embarked'].value_counts().index[0],inplace=True)\n\ntest_data_age_train['Fare'].fillna(test_data_age_train['Fare'].value_counts().index[0],inplace=True)\ntest_data_age_test['Fare'].fillna(test_data_age_test['Fare'].value_counts().index[0],inplace=True)\n\n#handle the categorical value \ntest_data_age_train=pd.get_dummies(test_data_age_train,drop_first=True)\ntest_data_age_test=pd.get_dummies(test_data_age_test,drop_first=True)\n\n#separtating taret value and input variable \ntest_data_age_test=test_data_age_test.drop(['Age'],axis=1)\ntarget_age=test_data_age_train['Age']\ntest_data_age_train=test_data_age_train.drop(['Age'],axis=1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\n\nrf.fit(test_data_age_train,target_age)\npredicct=rf.predict(test_data_age_test)\n\ntest_data_age_test['Age']=predicct\ntest_data_age_train['Age']=target_age\n\ntest_data=pd.concat([test_data_age_train,test_data_age_test])","108bbef1":"#train_data.info()","5f3c31b9":"#train_data_age_test.info()\n#train_data_age_train.info()\n\ntarget=train_data['Survived']\ntrain_data=train_data.drop(['Survived'],axis=1)","b63431c8":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\n\n\n\n\n\n","ccd8c667":"#y = train_data[\"Survived\"]\n#features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Fare\"]\n#X= pd.get_dummies(train_data[features])\n#from sklearn.preprocessing import MinMaxScaler\n\n\n\n#X_train = scaler.transform(X_train)\n#X_test = scaler.transform(X_test)\n\nX_train,X_test,y_train,y_test=train_test_split(train_data,target,test_size=0.2)\n\n#scaler = MinMaxScaler(feature_range = (0,40)).fit(X_train)\n\n#X_train = scaler.transform(X_train)\n#X_test = scaler.transform(X_test)\n\n#X1_test = pd.get_dummies(test_data[features])\n\n#from sklearn.impute import SimpleImputer\n#my_imputer = SimpleImputer()\n#X1_test = my_imputer.fit_transform(X1_test)\n\n#scaler1=MinMaxScaler(feature_range=(0,40)).fit(X1_test)\n#X1_test=scaler1.transform(X1_test)\n","95921df7":"param_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']},\n    {'classifier' : [RandomForestClassifier()],\n    'classifier__n_estimators' : list(range(10,101,10)),\n    'classifier__max_features' : list(range(6,32,5))}\n]\n\npipe = Pipeline([('classifier' , RandomForestClassifier())])\n\nmodel = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n","cd297064":"test_data","5a0a02e2":"model.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\npredict1=model.predict(X_test)\nprint(accuracy_score(predict1,y_test))\npredictions=model.predict(test_data)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission1.csv', index=False)\nprint(\"Your submission was successfully saved!\")","64b488f5":"First we have to predict the age(for better result ) using random forest regressor so I have done neccessary cleaning "}}