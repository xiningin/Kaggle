{"cell_type":{"42238d21":"code","d9d75a4c":"code","d7c59c2f":"code","a2ccc24c":"code","24980ebc":"code","0456d045":"code","4f245169":"code","0d072281":"code","956c7e5f":"code","6f89535f":"code","b934ee91":"code","c3573086":"code","2e1a6465":"code","f1c1d8e3":"code","a7305af7":"code","87d53071":"code","f813864e":"code","daa0931f":"code","156015ed":"code","189c8d50":"code","9a30a871":"code","b73c3971":"code","187fc858":"code","e4d5191e":"markdown","228d51f9":"markdown","f0be792d":"markdown","1507b065":"markdown","4e579426":"markdown","3b119f6f":"markdown","07f7bf00":"markdown","3587264b":"markdown","514312d2":"markdown","e7c84de4":"markdown","ea8ddc1e":"markdown","d561ff4e":"markdown","47432250":"markdown","a097a6a9":"markdown","3f5b852e":"markdown","d347d91f":"markdown","fc937c5b":"markdown","b24b3596":"markdown","4033da53":"markdown","4118388b":"markdown","2fa52361":"markdown","35d01c76":"markdown","cfd22c76":"markdown","df26388f":"markdown","3084ae2c":"markdown","a25bf3c5":"markdown"},"source":{"42238d21":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom collections import Counter\nfrom nltk import ngrams\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))","d9d75a4c":"df_train=pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ndf_test=pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')","d7c59c2f":"df_train.head()","a2ccc24c":"df_test.tail()","24980ebc":"df_data = df_train.append(df_test, sort = False)\ndf_data.head()","0456d045":"df_data.tail()","4f245169":"def clean_text(tweets):\n    \n    # Replacing @handle with the word USER\n    tweets_handle = tweets.str.replace(r'@[\\S]+', 'user')\n    \n    # Replacing the Hast tag with the word hASH\n    tweets_hash = tweets_handle.str.replace(r'#(\\S+)','hash')\n    \n    # Removing the all the Retweets\n    tweets_r = tweets_hash.str.replace(r'\\brt\\b',' ')\n    \n    # Replacing the URL or Web Address\n    tweets_url = tweets_r.str.replace(r'((www\\.[\\S]+)|(http?:\/\/[\\S]+))','URL')\n    \n    # Replacing Two or more dots with one\n    tweets_dot = tweets_url.str.replace(r'\\.{2,}', ' ')\n    \n    # Removing all the special Characters\n    tweets_special = tweets_dot.str.replace(r'[^\\w\\d\\s]',' ')\n    \n    # Removing all the non ASCII characters\n    tweets_ascii = tweets_special.str.replace(r'[^\\x00-\\x7F]+',' ')\n    \n    # Removing the leading and trailing Whitespaces\n    tweets_space = tweets_ascii.str.replace(r'^\\s+|\\s+?$','')\n    \n    # Replacing multiple Spaces with Single Space\n    Dataframe = tweets_space.str.replace(r'\\s+',' ')\n    \n    return Dataframe","0d072281":"df_data['text'] = clean_text(df_data['text'])\ndf_data['text'] = df_data['text'].apply(str)","956c7e5f":"df_data.head()","6f89535f":"plt.rcParams['figure.figsize'] = [8, 10]\nsns_count = sns.countplot(df_train['sentiment'], data = df_train, order = df_train['sentiment'].value_counts().index)","b934ee91":"# Top 20 unigrams for the positive sentiment in the text in whole dataset\n\ndf_data_pos = \" \".join(df_data.loc[df_data.sentiment == 'positive', 'text'])\ntoken_text_pos = word_tokenize(df_data_pos)\nunigrams_pos = ngrams(token_text_pos, 1)\nfrequency_pos = Counter(unigrams_pos)\n\ndf_pos = pd.DataFrame(frequency_pos.most_common(20))\n\n\n# Barplot that shows the top 20 unigrams\nplt.rcParams['figure.figsize'] = [13,9]\nsns.set(font_scale = 1.5, style = 'whitegrid')\n\nsns_pos_1 = sns.barplot(x = df_pos[1], y = df_pos[0], color = 'lightsteelblue')\n\n# Setting axes labels\nsns_pos_1.set(xlabel = 'Occurrence', ylabel = 'Unigrams', title = 'Top 20 Unigrams for the Positive Sentiment');","c3573086":"# Top 20 Bigrams for the positive sentiment in the text in whole dataset\nbigrams_pos = ngrams(token_text_pos, 2)\nfrequency_pos = Counter(bigrams_pos)\ndf_pos = pd.DataFrame(frequency_pos.most_common(20))\n\n# Barplot that shows the top 20 Bigrams\nsns_pos_2 = sns.barplot(x = df_pos[1], y = df_pos[0], color = 'mediumpurple')\n\n# Setting axes labels\nsns_pos_2.set(xlabel = 'Occurrence', ylabel = 'Bigrams', title = 'Top 20 Bigrams for the Positive Sentiment');","2e1a6465":"# Top 20 Trigrams for the positive sentiment in the text in whole dataset\ntrigrams_pos = ngrams(token_text_pos, 3)\nfrequency_pos = Counter(trigrams_pos)\ndf_pos = pd.DataFrame(frequency_pos.most_common(20))\n\n# Barplot that shows the top 20 Trigrams\nsns_pos_3 = sns.barplot(x = df_pos[1], y = df_pos[0], color = 'darkcyan')\n\n# Setting axes labels\nsns_pos_3.set(xlabel = 'Occurrence', ylabel = 'Trigrams', title = 'Top 20 Trigrams for the Positive Sentiment');","f1c1d8e3":"# Top 20 Unigrams for the negative sentiment in text for the whole dataset\ndf_data_neg = \" \".join(df_data.loc[df_data.sentiment == 'negative', 'text'])\ntoken_text_neg = word_tokenize(df_data_neg)\nunigrams_neg = ngrams(token_text_neg, 1)\nfrequency_neg = Counter(unigrams_neg)\n\ndf_neg = pd.DataFrame(frequency_neg.most_common(20))\n\n# Barplot that shows the top 20 unigrams\nsns_neg_1 = sns.barplot(x = df_neg[1], y = df_neg[0], color = 'lightsteelblue')\n\n# Setting axes labels\nsns_neg_1.set(xlabel = 'Occurrence', ylabel = 'Unigrams', title = 'Top 20 Unigrams for the Negative Sentiment');","a7305af7":"# Top 20 Bigrams for the negative sentiment in text for the whole dataset\nBigrams_neg = ngrams(token_text_neg, 2)\nfrequency_neg = Counter(Bigrams_neg)\n\ndf_neg = pd.DataFrame(frequency_neg.most_common(20))\n\n# Barplot that shows the top 20 Bigrams\nsns_neg_2 = sns.barplot(x = df_neg[1], y = df_neg[0], color = 'mediumpurple')\n\n# Setting axes labels\nsns_neg_2.set(xlabel = 'Occurrence', ylabel = 'Bigrams', title = 'Top 20 Bigrams for the Negative Sentiment');","87d53071":"# Top 20 Trigrams for the negative sentiment in text for the whole dataset\nTrigrams_neg = ngrams(token_text_neg, 3)\nfrequency_neg = Counter(Trigrams_neg)\n\ndf_neg = pd.DataFrame(frequency_neg.most_common(20))\n\n# Barplot that shows the top 20 Trigrams\nsns_neg_3 = sns.barplot(x = df_neg[1], y = df_neg[0], color = 'darkcyan')\n\n# Setting axes labels\nsns_neg_3.set(xlabel = 'Occurrence', ylabel = 'Trigrams', title = 'Top 20 Trigrams for the Negative Sentiment');","f813864e":"# Top 20 unigrams for the neutral sentiment in the text in whole dataset\n\ndf_data_neu = \" \".join(df_data.loc[df_data.sentiment == 'neutral', 'text'])\ntoken_text_neu = word_tokenize(df_data_neu)\nunigrams_neu = ngrams(token_text_neu, 1)\nfrequency_neu = Counter(unigrams_neu)\n\ndf_neu = pd.DataFrame(frequency_neu.most_common(20))\n\n# Barplot that shows the top 20 unigrams\nsns_neu_1 = sns.barplot(x = df_neu[1], y = df_neu[0], color = 'lightsteelblue')\n\n# Setting axes labels\nsns_neu_1.set(xlabel = 'Occurrence', ylabel = 'Unigrams', title = 'Top 20 Unigrams for the Neutral Sentiment');","daa0931f":"# Top 20 Bigrams for the neutral sentiment in the text in whole dataset\nBigrams_neu = ngrams(token_text_neu, 2)\nfrequency_neu = Counter(Bigrams_neu)\n\ndf_neu = pd.DataFrame(frequency_neu.most_common(20))\n\n# Barplot that shows the top 20 Bigrams\nsns_neu_2 = sns.barplot(x = df_neu[1], y = df_neu[0], color = 'mediumpurple')\n\n# Setting axes labels\nsns_neu_2.set(xlabel = 'Occurrence', ylabel = 'Bigrams', title = 'Top 20 Bigrams for the Neutral Sentiment');","156015ed":"# Top 20 Trigrams for the neutral sentiment in the text in whole dataset\nTrigrams_neu = ngrams(token_text_neu, 3)\nfrequency_neu = Counter(Trigrams_neu)\n\ndf_neu = pd.DataFrame(frequency_neu.most_common(20))\n\n# Barplot that shows the top 20 Trigrams\nsns_neu_3 = sns.barplot(x = df_neu[1], y = df_neu[0], color = 'darkcyan')\n\n# Setting axes labels\nsns_neu_3.set(xlabel = 'Occurrence', ylabel = 'Trigrams', title = 'Top 20 Trigrams for the Neutral Sentiment');","189c8d50":"# Removing the stop words before plotting\n\ndf_data['text'] = df_data['text'].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\njoined = \" \".join(df_data['text'])\ntokenize = word_tokenize(joined)\nfrequency = Counter(tokenize)\ndf = pd.DataFrame(frequency.most_common(30))\n\nplt.rcParams['figure.figsize'] = [12, 15]\nsns.set(font_scale = 1.3, style = 'whitegrid')\n\n# plotting\nword_count = sns.barplot(x = df[1], y = df[0], color = 'orange')\nword_count.set_title(\"Word Count Plot\")\nword_count.set_ylabel(\"Words\")\nword_count.set_xlabel(\"Count\");","9a30a871":"# Word cloud of the text with the positive sentiment\ndf_pos = df_data.loc[df_data.sentiment == 'positive', 'text']\nk = (' '.join(df_pos))\n\nwordcloud = WordCloud(width = 1000, height = 500, background_color = 'white').generate(k)\nplt.figure(figsize=(15, 10))\nplt.imshow(wordcloud)\nplt.axis('off');","b73c3971":"# Word cloud of the text with the negative sentiment\ndf_neg = df_data.loc[df_data.sentiment == 'negative', 'text']\nk = (' '.join(df_neg))\n\nwordcloud = WordCloud(width = 1000, height = 500, background_color = 'white').generate(k)\nplt.figure(figsize=(15, 10))\nplt.imshow(wordcloud)\nplt.axis('off');","187fc858":"# Word cloud of the text with the Neutral sentiment\ndf_neu = df_data.loc[df_data.sentiment == 'neutral', 'text']\nk = (' '.join(df_neu))\n\nwordcloud = WordCloud(width = 1000, height = 500, background_color = 'white').generate(k)\nplt.figure(figsize=(15, 10))\nplt.imshow(wordcloud)\nplt.axis('off');","e4d5191e":"Word Clouds (also known as wordle, word collage or tag cloud) are visual representations of words that give greater prominence to words that appear more frequently.","228d51f9":"#### Trigrams","f0be792d":"## NGrams","1507b065":"#### Unigrams","4e579426":"Merging the Datasets","3b119f6f":"### Importing the Datasets","07f7bf00":"#### Bigrams","3587264b":"#### Trigrams","514312d2":"#### Unigrams","e7c84de4":"#### Negative Sentiment","ea8ddc1e":"# Exploratory Data Analysis","d561ff4e":"### Importing the Required Libraries","47432250":"#### Neutral Sentiment","a097a6a9":"### Neutral Sentiment","3f5b852e":"#### Bigrams","d347d91f":"#### Unigrams","fc937c5b":"### Negative Sentiment","b24b3596":"### Positive Sentiment","4033da53":"## Preprocessing","4118388b":"#### Trigrams","2fa52361":"### Word Count Plot","35d01c76":"In the fields of computational linguistics and probability, an n-gram is a contiguous sequence of n items from a given sample of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus. ","cfd22c76":"#### Positive Sentiment","df26388f":"Plotting the distribution of the sentiment in the dataset","3084ae2c":"#### Bigrams","a25bf3c5":"## Word Clouds"}}