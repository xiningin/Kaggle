{"cell_type":{"3c02c8a3":"code","6acd7617":"code","fe0e09ac":"code","d0c8a353":"code","f92dbdb7":"code","639df533":"code","c5e3f816":"code","b67218b6":"code","cfe6efbc":"code","289e53f5":"code","9215f3da":"code","6b7d21e1":"code","c21a1901":"markdown","a65f8444":"markdown"},"source":{"3c02c8a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport warnings \n\nfrom ipywidgets import interact\npd.options.display.max_colwidth = 200\nwarnings.filterwarnings('ignore')","6acd7617":"# Load Data\ncoordinates = pd.read_csv(\"..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv\")\ncountry_coordinates = coordinates[['country_code','latitude','longitude','country']]\nstate_coordinates = coordinates[['usa_state_code','usa_state_latitude','usa_state_longitude','usa_state']]\ndf = pd.read_csv(\"..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\ndf['Country\/Region'].replace(['Mainland China'], 'China',inplace=True)\ndf['Country\/Region'].replace(['US'], 'United States',inplace=True)\ndf['Country'] = df['Country\/Region']\ndf = df[df.ObservationDate==np.max(df.ObservationDate)]\ntodays_date = '3\/15\/2020'\n\n# Mortality rate for every country in the dataset\ndf_deaths = pd.DataFrame(df.groupby('Country')['Deaths'].sum())\ndf_confirmed = pd.DataFrame(df.groupby('Country')['Confirmed'].sum())\ndf_confirmed['Deaths'] = df_deaths['Deaths']\ndf_global = df_confirmed\ndf_global['Mortality Rate'] = np.round((df_global.Deaths.values\/df_global.Confirmed.values)*100,2)\ndf_global = df_global.reset_index()\ndf_global = df_global.merge(country_coordinates, left_on='Country', right_on='country')\ndf_global = df_global[['Country','Confirmed','Deaths','Mortality Rate','latitude','longitude','country_code']]\ndf_global.columns = ['Country','Confirmed','Deaths','Mortality Rate','Latitude','Longitude','Country_Code']\ndf_global.to_csv('\/kaggle\/working\/global_covid19_mortality_rates.csv')\n\n# Mortality rate for every state in the USA\ndf_usa = df[df['Country\/Region']=='United States']\ndf_usa = df_usa[df_usa.ObservationDate==np.max(df_usa.ObservationDate)]\ndf_usa['State'] = df_usa['Province\/State']\ndf_usa['Mortality Rate'] = np.round((df_usa.Deaths.values\/df_usa.Confirmed.values)*100,2)\ndf_usa.sort_values('Mortality Rate', ascending= False).head(10)\ndf_usa = df_usa.merge(state_coordinates, left_on='State', right_on='usa_state')\ndf_usa['Latitude'] = df_usa['usa_state_latitude']\ndf_usa['Longitude'] = df_usa['usa_state_longitude']\ndf_usa = df_usa[['State','Confirmed','Deaths','Recovered','Mortality Rate','Latitude','Longitude','usa_state_code']]\ndf_usa.columns = ['State','Confirmed','Deaths','Recovered','Mortality Rate','Latitude','Longitude','USA_State_Code']\ndf_usa.to_csv('\/kaggle\/working\/usa_covid19_mortality_rates.csv')","fe0e09ac":"fig = px.choropleth(df_global, \n                    locations=\"Country\", \n                    color=\"Confirmed\", \n                    locationmode = 'country names', \n                    hover_name=\"Country\",\n                    range_color=[0,10000],\n                    title='Global COVID-19 Infections as of '+todays_date)\nfig.show()\n\nfig = px.choropleth(df_global, \n                    locations=\"Country\", \n                    color=\"Deaths\", \n                    locationmode = 'country names', \n                    hover_name=\"Country\",\n                    range_color=[0,100],\n                    title='Global COVID-19 Deaths as of '+todays_date)\nfig.show()\n\nfig = px.choropleth(df_global, \n                    locations=\"Country\", \n                    color=\"Mortality Rate\", \n                    locationmode = 'country names', \n                    hover_name=\"Country\",\n                    range_color=[0,10],\n                    title='Global COVID-19 Mortality Rates as of '+todays_date)\nfig.show()","d0c8a353":"fig = px.bar(df_global.sort_values('Confirmed',ascending=False)[0:10], \n             x=\"Country\", \n             y=\"Confirmed\",\n             title='Global COVID-19 Infections as of '+todays_date)\nfig.show()\n\nfig = px.bar(df_global.sort_values('Deaths',ascending=False)[0:10], \n             x=\"Country\", \n             y=\"Deaths\",\n             title='Global COVID-19 Deaths as of '+todays_date)\nfig.show()\n\nfig = px.bar(df_global.sort_values('Confirmed',ascending=False)[0:10], \n             x=\"Country\", \n             y=\"Mortality Rate\",\n             title='Global COVID-19 Mortality Rates as of '+todays_date+' for Countries with Top 10 Most Confirmed')\nfig.show()","f92dbdb7":"##input_dir = PurePath('..\/input\/CORD-19-research-challenge\/2020-03-13')\n\nsources = pd.read_csv('..\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')  \ndef doi_url(d): return d if d.startswith('doi.org') else f'doi.org\/{d}'\n\nsources.doi = sources.doi.fillna('').apply(doi_url)\nSOURCES_COLS = ['title', 'abstract', 'doi', 'pubmed_id', 'publish_time', 'authors', 'journal', 'has_full_text']\nsources[SOURCES_COLS]\n\ndef show_sources(ShowAllColumns=False):\n    return sources if ShowAllColumns else sources[SOURCES_COLS]\n\ninteract(show_sources);","639df533":"class ResearchPapers:\n    \n    def __init__(self, sources: pd.DataFrame):\n        self.sources = sources\n        \n    def __getitem__(self, item):\n        df = self.sources.iloc[item].to_frame().fillna('')\n        df.columns = ['Value']\n        return df\n    \n    def _repr_html_(self):\n        return self.sources._repr_html_()\n\npapers = ResearchPapers(sources)","c5e3f816":"papers[10000]","b67218b6":"def count_ngrams(dataframe,column,begin_ngram,end_ngram):\n    # adapted from https:\/\/stackoverflow.com\/questions\/36572221\/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n    word_vectorizer = CountVectorizer(ngram_range=(begin_ngram,end_ngram), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(dataframe['title'].dropna())\n    frequencies = sum(sparse_matrix).toarray()[0]\n    most_common = pd.DataFrame(frequencies, \n                               index=word_vectorizer.get_feature_names(), \n                               columns=['frequency']).sort_values('frequency',ascending=False)\n    most_common['ngram'] = most_common.index\n    most_common.reset_index()\n    return most_common\n\ndef word_cloud_function(df,column,number_of_words):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=number_of_words,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef word_bar_graph_function(df,column,title,nvals):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(nvals), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:nvals])])\n    plt.yticks([x + 0.5 for x in range(nvals)], reversed(popular_words_nonstop[0:nvals]))\n    plt.title(title)\n    plt.show()\n    \n    \nthree_gram = count_ngrams(sources,'title',3,3)\nwords_to_exclude = [\"my\",\"to\",\"at\",\"for\",\"it\",\"the\",\"with\",\"from\",\"would\",\"there\",\"or\",\"if\",\"it\",\"but\",\"of\",\"in\",\"as\",\"and\",'NaN','dtype']","cfe6efbc":"# show most frequent words in titles\nplt.figure(figsize=(10,10))\nword_bar_graph_function(sources,column='title', \n                        title='Most common words in the TITLES of the papers in the CORD-19 dataset',\n                        nvals=40)","289e53f5":"fig = px.bar(three_gram.sort_values('frequency',ascending=False)[0:10], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Most Common 3-Words in Titles of Papers in CORD-19 Dataset',\n             orientation='h')\nfig.show()","9215f3da":"plt.figure(figsize=(10,10))\nword_cloud_function(sources,'title',5000)","6b7d21e1":"# show most frequent words in titles\nplt.figure(figsize=(10,10))\nword_bar_graph_function(sources,column='abstract', \n                        title='Most common words in the Abstract of the papers in the CORD-19 dataset',\n                        nvals=40)","c21a1901":"****Map of coronavirus****","a65f8444":"**Look at paper**"}}