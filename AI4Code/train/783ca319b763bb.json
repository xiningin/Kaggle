{"cell_type":{"73fd01f1":"code","5c1da519":"code","65f0026f":"code","b3bd1f6a":"code","d17f775a":"code","d02f9d29":"code","84cab6ca":"code","2b90fb92":"code","0ecbe382":"code","56df43ae":"code","b51b8b19":"code","7859e0b8":"code","671f6fa1":"code","9196f35d":"code","8f065e08":"code","05720dee":"code","455c9adb":"markdown","09e146f3":"markdown","f55cd44d":"markdown","f582ae28":"markdown","0e05c3f1":"markdown","c17ac96f":"markdown","21b07b5c":"markdown","6aa8a6fe":"markdown","dc469b4f":"markdown","52f3019a":"markdown","2ae489fa":"markdown","f5443370":"markdown"},"source":{"73fd01f1":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nTEST_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/test'","5c1da519":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    seed=35\n    trn_fold=[[0, 1, 2, 3, 4]] # [0, 1, 2, 3, 4]\n#     model_path = ['..\/input\/ranzcr3stepsmodelweightsv0fold0\/fold0\/resnet200d_fold0_best_loss_cpu.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold1\/resnet200d_fold1_best_loss.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold2\/resnet200d_fold2_best_loss.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold3\/fold3\/resnet200d_fold3_best_loss.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold34\/fold4\/resnet200d_fold4_best_loss.pth',\n#                  ]\n#     model_path = ['..\/input\/ranzcr3stepsmodelweightsv0fold0\/fold0\/resnet200d_fold0_best_score_cpu.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold1\/resnet200d_fold1_best_score.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold2\/resnet200d_fold2_best_score.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold3\/fold3\/resnet200d_fold3_best_score.pth',\n#                   '..\/input\/ranzcr3stepsmodelweightsv0fold34\/fold4\/resnet200d_fold4_best_score.pth',\n#                  ]\n    model_path = ['..\/input\/ranzcrresnet200dfocalmctrmodelf0\/fold0resnet200d_fold0_best_score.pth',\n                  '..\/input\/ranzcrresnet200dfocalmctrmodelf1\/fold1resnet200d_fold1_best_score.pth',\n                  '..\/input\/ranzcrresnet200dfocalmctrmodelf2\/fold2resnet200d_fold2_best_score.pth',\n                  '..\/input\/ranzcrresnet200dfocalmctrmodelf3\/fold3resnet200d_fold3_best_score.pth',\n                  '..\/input\/ranzcrresnet200dfocalmctrmodelf4\/fold4resnet200d_fold4_best_score.pth',\n                 ]\n#     oof_path = ['..\/input\/ranzcr3stepsmodelweightsv0fold0\/fold0\/oof_df.csv',\n#                '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold1\/oof_df.csv',\n#                '..\/input\/ranzcr3stepsmodelweightsv0fold12\/fold2\/oof_df.csv',\n#                '..\/input\/ranzcr3stepsmodelweightsv0fold3\/fold3\/oof_df.csv',\n#                '..\/input\/ranzcr3stepsmodelweightsv0fold34\/fold4\/oof_df.csv',\n#                ]\n        \n    debug=False\n    num_workers=4\n    model_name='resnet200d'\n    size=512\n    batch_size=128\n    \n    target_size=11\n    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n                 'Swan Ganz Catheter Present']\n    n_fold=5\n   ","65f0026f":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nsys.path.insert(0,'..\/input\/timm-nfnet')\nimport timm\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","b3bd1f6a":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","d17f775a":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    scores = []\n    for i in range(y_true.shape[1]):\n        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n        scores.append(score)\n    avg_score = np.mean(scores)\n    return avg_score, scores\n\n\ndef get_result(result_df):\n    preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n    labels = result_df[CFG.target_cols].values\n    score, scores = get_score(labels, preds)\n    LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","d02f9d29":"# oof_df=pd.DataFrame()\n# for single_oof_path in CFG.oof_path:\n#     temp_oof_df = pd.read_csv(single_oof_path)\n#     oof_df = pd.concat([temp_oof_df,oof_df])\n\n# oof_df.columns","84cab6ca":"# oof_folds_score = 0\n# for fold in range(5):\n#     fold_oof_df = oof_df[oof_df['fold']==fold].reset_index(drop=True)\n#     LOGGER.info(f\"========== fold: {fold} result ==========\")\n#     get_result(fold_oof_df)\n        \n#     preds = fold_oof_df[[f'pred_{c}' for c in CFG.target_cols]].values\n#     labels = fold_oof_df[CFG.target_cols].values\n#     score,_= get_score(labels, preds)\n#     oof_folds_score+=score\/5\n# print('CV score of 5folds avg = {}',(oof_folds_score))","2b90fb92":"if CFG.debug:\n    test = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv', nrows=10)\nelse:\n    test = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\n\nprint(test.shape)\ntest.head()","0ecbe382":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            #Resize(CFG.size, CFG.size),\n            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n            HorizontalFlip(p=0.5),\n            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n            CoarseDropout(p=0.2),\n            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","56df43ae":"# ====================================================\n# Dataset\n# ====================================================\nclass mctrTestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['StudyInstanceUID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}.jpg'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n           \n            \n        return image\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['StudyInstanceUID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}.jpg'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","b51b8b19":"train_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n\nfor i in range(1):\n    image = train_dataset[i]\n    plt.imshow(image[0])\n    plt.show()\n    plt.imshow(image[0].flip(-1))\n    plt.show()","7859e0b8":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d_320', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        if pretrained:\n            pretrained_path = '..\/input\/resnet200d-pretrained-weight\/resnet200d_ra2-bdba9bf9.pth'\n            self.model.load_state_dict(torch.load(pretrained_path))\n            print(f'load {model_name} pretrained model')\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","671f6fa1":"# ====================================================\n# Helper functions\n# ====================================================\ndef mctrinference(models, test_loader, device):\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for model in models:\n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) \/ 2\n            avg_preds.append(y_preds)\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs\n\n\ndef inference(models, test_loader, device):\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for model in models:\n#             print('finish one model')\n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) \/ 2\n            avg_preds.append(y_preds)\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs\n\n# def inference(models, test_loader, device):\n#     tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n#     probs = []\n#     weights=[0.9504,0.9522,0.9486,0.9520,0.9464] \n    \n#     for i, (images) in tk0:\n#         images = images.to(device)\n#         avg_preds = []\n#         for j,model in enumerate(models):\n#             with torch.no_grad():\n#                 y_preds1 = model(images)\n#                 y_preds2 = model(images.flip(-1))\n#             y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) \/ 2\n            \n#             y_preds = y_preds * weights[j]\n            \n#             avg_preds.append(y_preds)            \n#         avg_preds = np.sum(avg_preds, axis=0) \/ (0.9504+0.9522+0.9486+0.9520+0.9464)\n#         probs.append(avg_preds)\n#     probs = np.concatenate(probs)\n#     return probs","9196f35d":"%%time\nmodels = []\nfor fold in range(5):#CFG.trn_fold:\n    model = CustomResNet200D(CFG.model_name, pretrained=False)\n    model_path = CFG.model_path[fold] # '..\/input\/ranzcr-resnet200d-3-stage-training-step3\/resnet200d_fold0_best_loss_cpu.pth'\n    model.load_state_dict(torch.load(model_path,map_location=device)['model'])\n    model.eval()\n    models.append(model.to(device))","8f065e08":"%%time\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(models, test_loader, device)","05720dee":"# submission\ntest[CFG.target_cols] = predictions\ntest[['StudyInstanceUID'] + CFG.target_cols].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","455c9adb":"# Utils","09e146f3":"# Directory settings","f55cd44d":"# Helper functions","f582ae28":"# Data Loading","0e05c3f1":"# inference","c17ac96f":"# Library","21b07b5c":"# CFG","6aa8a6fe":"Train Kernel Version Info:\n* V1: fold0 {CV=0.9504 LB=0.957}\n* V4: fold1 {CV=0.9522 LB=0.955}      \n* V6: fold2 {CV=0.9486 LB=0.955}\n* V7: fold3 {CV=0.9520 LB=0.960}      \n* V8: fold4 {CV=0.9464 LB=0.956}","dc469b4f":"# Dataset","52f3019a":"# Transforms","2ae489fa":"# Submit Info\n* V1: mean of 5 folds results      \n    LB=0.962         \n* V2: res^0.5 mean from:[https:\/\/www.kaggle.com\/c\/ranzcr-clip-catheter-line-classification\/discussion\/211194](http:\/\/)      \n    LB=0.961\n* V3: weighted mean(CV scores)       \n    LB=0.962\n* V6: best_score_model       \n    LB=0.962\n* V7: focal+mctr model; test without mctr                 \n    LB=","f5443370":"# MODEL"}}