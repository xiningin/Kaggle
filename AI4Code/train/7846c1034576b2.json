{"cell_type":{"4931972f":"code","0269b2fb":"code","d2747eeb":"code","2560801c":"code","df1aa059":"code","fd80355e":"code","8fafb34c":"code","b648f7fc":"code","010fad7f":"code","3f507253":"code","ccebe4ee":"code","ed643b74":"code","02e441d0":"code","02fb73ad":"code","2db14695":"code","fde3460a":"code","44d1871e":"code","a46c7a66":"code","c47f0b3b":"code","dd0b482c":"code","6d68efa6":"code","29374a76":"code","82b4e677":"code","487d79ae":"code","98439cd5":"code","a761bc60":"code","4f49266f":"code","20a111cc":"code","63798119":"code","73376c53":"code","405bc99c":"code","62baf211":"code","26de03d4":"code","b54a310b":"code","a4857849":"code","a2c62c80":"code","2d275d04":"code","8e2436fe":"code","a99d5337":"code","48f37b39":"code","ac89a280":"code","79d6afb8":"code","76ff999f":"code","ab3a24d0":"code","d330e005":"code","cb09debb":"code","6cf06c1d":"code","6ded4284":"code","b0beee7b":"code","21c6173f":"code","d4bb4afa":"code","363bedc5":"code","47ce3c94":"markdown","2dad0204":"markdown","13551db9":"markdown","fe9146f6":"markdown","31ac3494":"markdown","84ef2487":"markdown","d0ce6f86":"markdown","81ccfa30":"markdown","80a22898":"markdown","ecaa0d7b":"markdown","18b1c427":"markdown","dd1d7c30":"markdown","b93944f6":"markdown","58368f6b":"markdown","502d9895":"markdown","3f83ab67":"markdown","12b3029f":"markdown","f00c7aa9":"markdown","c1e4c832":"markdown","b952f9dd":"markdown","77d8d7f0":"markdown","2d8746d3":"markdown","5ccede5b":"markdown","4e988912":"markdown","e3b5db4a":"markdown","dffb454f":"markdown","ae9ec85a":"markdown","6ed95a53":"markdown","785f16bd":"markdown","2ea939ac":"markdown","31600d5c":"markdown","045fac30":"markdown","ff281167":"markdown","473dead0":"markdown","a8b6ed45":"markdown","358d50fe":"markdown","04c5f3c3":"markdown","4e00af34":"markdown","a4d12f14":"markdown","c7828a7c":"markdown","d71c85e7":"markdown","d9d25d38":"markdown","a7af50f4":"markdown"},"source":{"4931972f":"project_name = \"EDA on Medium blogs\" ","0269b2fb":"pip install --upgrade pip","d2747eeb":"!pip install jovian --upgrade -q","2560801c":"import jovian","df1aa059":"jovian.commit(project=project_name)","fd80355e":"import pandas as pd\nimport numpy as np","8fafb34c":"medium_df=pd.read_csv('..\/input\/medium-articles-dataset\/medium_data.csv')","b648f7fc":"medium_df","010fad7f":"medium_df.info()","3f507253":"medium_df.columns","ccebe4ee":"required_columns = ['title','subtitle', 'image', 'claps', 'responses',\n       'reading_time', 'publication', 'date']","ed643b74":"medium_df_eda = medium_df[required_columns].copy()","02e441d0":"medium_df.info()\nmedium_df_eda.info()","02fb73ad":"medium_df_eda.date = pd.to_datetime(medium_df_eda.date)\nmedium_df_eda.info()\n","2db14695":"print(medium_df_eda.date[0])\nprint(medium_df_eda.date[0].day)\nprint(medium_df_eda.date[0].month)\nprint(medium_df_eda.date[0].year)","fde3460a":"medium_df_eda.image = medium_df_eda.image.str.replace('[0-9.]','',regex=True)","44d1871e":"medium_df_eda.image.value_counts()","a46c7a66":"medium_df_eda.image.replace('',np.nan, inplace=True)\nmedium_df_eda.dropna(subset=['image'], inplace=True)","c47f0b3b":"medium_df_eda.image.value_counts()","dd0b482c":"medium_df_eda.image = medium_df_eda.image.str.lower()","6d68efa6":"medium_df_eda.image.value_counts()","29374a76":"import jovian","82b4e677":"jovian.commit(project=project_name)","487d79ae":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","98439cd5":"publication_articles_count = medium_df_eda.publication.value_counts().rename_axis('publications').reset_index(name='counts')\npublication_articles_count","a761bc60":"plt.figure(figsize=(12,6))\nplt.xlabel(\"number of articles\")\nplt.title(\"Number of articles by publications\")\nsns.barplot(y=publication_articles_count.publications,x=publication_articles_count.counts);","4f49266f":"articles_df = medium_df_eda.date.value_counts().rename_axis('dates').reset_index(name='counts')","20a111cc":"articles_df.info()","63798119":"articles_df['month'] = articles_df.dates.dt.month_name()\narticles_df['day_of_week'] = articles_df.dates.dt.day_name()\narticles_df","73376c53":"rest_data = articles_df.pivot_table(index='month', columns='day_of_week', values='counts',  aggfunc='sum', fill_value=0)\nrest_data = rest_data[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']]","405bc99c":"rest_data","62baf211":"plt.figure(figsize=(12,6))\nplt.title(\"when were the blogs posted?\")\nsns.heatmap(rest_data, cmap=\"Greens\", linewidths=.5)","26de03d4":"plt.figure(figsize=(12,6))\nplt.xlabel(\"Reading time in minutes\")\nplt.ylabel(\"number of claps\")\nsns.scatterplot(medium_df_eda.reading_time,medium_df_eda.claps)","b54a310b":"plt.figure(figsize=(19,6))\nplt.xlabel(\"Reading time in minutes\")\nplt.ylabel(\"number of claps\")\nsns.scatterplot(medium_df_eda.responses, medium_df_eda.reading_time)","a4857849":"medium_df_eda['image'].value_counts().plot(kind='pie', figsize=(10, 9),  autopct='%1.1f%%')\nplt.legend(medium_df_eda.image.unique())\nplt.title(\"Type of images used\")","a2c62c80":"import jovian","2d275d04":"jovian.commit(project=project_name)","8e2436fe":"medium_df_eda","a99d5337":"percentage = medium_df_eda.subtitle.count()\/len(medium_df_eda) * 100\nprint(\"About {} percent of articles have subtitles\".format(percentage))","48f37b39":"print(\"The data of blogs we have is from {} to {}\".format(medium_df_eda.date.min(), medium_df_eda.date.max()))","ac89a280":"avg_reading_time_df = medium_df_eda[[\"publication\",\"reading_time\"]].groupby(\"publication\").mean() ","79d6afb8":"print(avg_reading_time_df)\nprint(\"--------------------------------------\")\nprint(medium_df_eda.publication.value_counts())","76ff999f":"indexes = medium_df_eda.groupby(['publication'], sort=False)['claps'].transform(max) == medium_df_eda['claps']","ab3a24d0":"best_articles = medium_df_eda[indexes]\nbest_articles","d330e005":"for index, row in best_articles.iterrows():\n    print(\"The article '{}' from '{}' publication has highest number of claps i.e. '{}'\".format(row.title, row.publication, row.claps))\n    print(\"\\n\")","cb09debb":"for index, row in best_articles.iterrows():\n    print(\"The best article from {} has reading time of {} minutes\".format(row.publication, row.reading_time))\n    print(\"\\n\")\n","6cf06c1d":"best_articles.reading_time.mean()","6ded4284":"percentage = best_articles.subtitle.count()\/len(best_articles) * 100\nprint(\"About {} percent of articles have subtitles\".format(percentage))","b0beee7b":"import jovian","21c6173f":"jovian.commit(project=project_name)","d4bb4afa":"import jovian","363bedc5":"jovian.commit(project=project_name)","47ce3c94":"And there yo go, we got it. Before we plot the heatmap for this analysis we have to convert it into pivot table. More about the pivot table can be found [here](https:\/\/en.wikipedia.org\/wiki\/Pivot_table) and we will be using `pivot_table` method in python","2dad0204":"Images make the articles engaging and attractive and hence they are necessary part of the blog, well atleast the cover image because it can decide wether user will click the link and look at the blog or not. And due to this using the right image extension is also necessary because it will affect the performance of the blog. Because if the webpage takes a long time to load because of it's resources i.e image in this case, people are just going to move on.\n\nso, lets check what image extentions are uses in thes 60k articles dataframe.  Pie chart with percentages will be useful for this analysis so lets plot that by using `value_counts` method","13551db9":"From the above scatterplots we can say that\n\n#### The articles with reading time of 5 - around 10 minutes have huge number of claps and have some responses\n\nFor these claps we can assume that a person has read and understood the article hence he\/she gave a clap to it.  So we can say that ideal reading time for an article should be 5 - 10 minutes. And if the article is too long there is a possibility that the user may not read it as it will take lot of their time and hence will not comment or clap to it.","fe9146f6":"### Q: What is the avarage reading time for the article with highest claps among the publications","31ac3494":"## Data Preparation and Cleaning\n\nTODO","84ef2487":"### Q: Which articles among the publications have maximum number of claps?","d0ce6f86":"## Refrences and Future work\n\nFuture Work:\n\nThe same analysis can be done on the dataset which has information of all the blogs over a year and not only the blogs specfic to the publications. This will help to do a strong analysis which may backup our current facts and may also generate new facts. similarly some kewords can be taken from the titles of the blog and we can possibily get the hot topics to write the blogs. \n\nRefrences:\n\n- Dataset: https:\/\/www.kaggle.com\/dorianlazar\/medium-articles-dataset?select=medium_data.csv\n- Pandas user guide: https:\/\/pandas.pydata.org\/docs\/user_guide\/index.html\n- Matplotlib user guide: https:\/\/matplotlib.org\/3.3.1\/users\/index.html\n- Seaborn user guide & tutorial: https:\/\/seaborn.pydata.org\/tutorial.html\n","81ccfa30":"`replace('[0-9.]','',regex=True)` this peice of code is a regular expression with replace function. The regular expression is used to identify the the digits starting with any digits between 0 to 9 along with `.` and replace it with empty string so we get the desired result. Let's check the number of unique image extensions using `value_counts` function.","80a22898":"* **\"The Startup\"** publication posted highest number of articles in year 2019 where as **\"Better Humans\"** published least number of articles. For this analysis to help in our blogging we can further look at the articles published by The Starup and analyze on what topics do they write or whats the nature of their alticles so that we get the topics which are in high demand.\n\n* Mondays and Thursdays can be best days to publish your article so that It gets more visibility and likes. Note that this is only one factor, for an article to become successful the content, heading, etc factors matter.\n\n* The ideal reading time for an article should be around 5 - 10 minutes i.e the article you write should not be verbose and should be up to the point so the user won't get bored and get the information he\/she needs quickly.\n\n* JPEG\/JPG: This is an ideal image format for all types of photographs. PNG: This format is perfect for screenshots and other types of imagery where there\u2019s not a lot of color data.\n\n* Writing the subtitle to your article may be helpful, because it will help audience to understand more about your post before they click on it. It can also be a deciding factor wether a person will click the link or not.","ecaa0d7b":"### Q: what percent of articles have subtitle after heading, is it necessary? \n\nTitles play an essential role in determining whether a reader clicks on your story. Medium titles that are not formatted properly can render an article ineligible for curation. This is also true for the article subtitle if you choose to add these elements to your article.","18b1c427":"## Asking and Answering Questions\n\nwe have gained some insights about the blogs in the dataset and it also helped to understand how your next article should be. Let's ask some specific questions, and try to answer them using data frame operations and interesting visualizations if required.","dd1d7c30":"From the above graph we can see that\n\n#### *The Startup* publication has most number of articles i.e. around 3000 and *Better Humans* has the least number of articles published on medium i.e. around 10.\n\nWe can also Infer that most of the people read articles from The Startup, Towards Data Science and Data Driven Investor assuming they have posted huge number of articles based on the demand\/response fron audience.\n\n(Note: we cannot be completly sure about this Inference because the dataset we have might not be the complete data) ","b93944f6":"And its removed :)\nBut we also have some upper extensions in upper case let's turn them into lower case","58368f6b":"Now it's confirmed that we have new dataset to explore and play with. We can see that the date column has datatype object, let's convert it into date so that It can be used into analysis.","502d9895":"## Exploratory Analysis and Visualization\n\nVisualizations are interesting isn't it? Lets Do some visualizations now","3f83ab67":"So, these are the articles from specfic publications with maximum number of claps","12b3029f":"This tells us that we have information for 6508 blog posts written on medium for responses,\treading_time,\tpublication, etc. Lets have a look at some more information about this dataset using `.info()` method","f00c7aa9":"### Q: What is the reading time for the article with highest claps among the publications","c1e4c832":"Wow thats the huge number, so we can say that writing subtitle is an import part for sucessful blog.\n\nNow that we got answers to out questions let's move to the conclusion.","b952f9dd":"so from this we can see that most of the articles are written by The Startup publication and their avarage reading time is around 6 minutes and this also backs up our analysis i.e. ideal reading time is 5 - 10 minutes from the scatterplots.","77d8d7f0":"So we have data for 2019 starting from 26th january to 30th December","2d8746d3":"Now that we got the basic info we can say that the columns ID and URL will not be necessary for the analysis. Lets proceed to remove these columns but before that we will make a copy(using `.copy()` method) because it's no recommended to play with original dataset.","5ccede5b":"Wow here is our heatmap, amazing, isn't it? \nFrom this heatmap we can say that most of the blogs were posted on monday and among all the months around 500 articles were published on monday in the month of october. If we consider two week days where number of  articles published highest we get\n\n* Monday\n* Thursday\n\nSo the next time when you publish your article try to do it on Monday or Thursday hopefully it will get seen by more number of audience.","4e988912":"Now that we made a copy let's see if it's copied properly","e3b5db4a":"Ohh as we see that most of the images are of of type **jpeg** i.e about 50% and then jpg and png. There is gonna be some reason behind this, let's see what it is\n\n* JPEG - JPEG is a lossy compression method used to ensure the digital images being used are as small as possible and load quickly when someone wants to view them. Here are some important points about it\n    * The file size of the image being compressed is permanently reduced by eliminating unnecessary (redundant) information from the image.\n    * Image quality does suffer, though it\u2019s often so slight the average site visitor can\u2019t tell.\n    \n    \n* JPG - Well, when it comes to .jpeg vs .jpg, the truth is there is no difference between the two except the number of characters.\n    * The term JPG exists because the earlier versions of Windows operating systems. Specifically, the MS-DOS 8.3 and FAT-16 file systems had a maximum 3-letter limit when it came to file names, unlike the UNIX-like operating systems like Mac or Linux, which didn\u2019t have this limit.\n    \nI read these points in [this article](https:\/\/kinsta.com\/blog\/jpg-vs-jpeg\/), you can check it out if you want to learn more about it\n\nwell coming to png's\n\n* PNG - Portable Network Graphics (PNGs) are just as popular as JPEGs on websites. They also support millions of colors, although you\u2019re much better off using PNGs for images that contain less color data. Otherwise, your image is going to be \u2018heavier\u2019 than the same image saved as a JPEG.\n\nso we can conclude that\n\n1. JPEG\/JPG: This is an ideal image format for all types of photographs.\n2. PNG: This format is perfect for screenshots and other types of imagery where there\u2019s not a lot of color data.\n3. GIF: If you want to show off animated graphics on your site, this is the best image format for you.\n","dffb454f":"In the code above `rename_axis('publications').reset_index(name='counts')` is used to represent the `value_counts()` output as a dataframe so that we should be able to plot the graphs with it. Lets proceed by plotting bargraph on the data. ","ae9ec85a":"The code above will give us indexes of the rows with maximum number of claps and then we can select those rows from out dataset","6ed95a53":"Now we are good let's proceed to visualization","785f16bd":"Wonderful, now that we have converted the datatype we can access the day, month. Lets modify the image column of the data as we only need image type and not the name for analysis.","2ea939ac":"### Publications \nNow that we imported the required libraries lets get started with the visualizations. We can check the check the number of articles that a publications published using the `value_counts()` function in python ","31600d5c":"`medium_df_eda.image.replace('',np.nan, inplace=True)` This line replaces the empty with NaN and `medium_df_eda.dropna(subset=['image'], inplace=True)` drops column with NaN\nLet's check if they are removed now.","045fac30":"Now lets try to plot the graph which will tell the day on which maximum\/minimum number of articles are published. For this we can plot graph for month vs day_of_week for the number of articles published. Let's create a new dataframe with all the dates and the counts of it.","ff281167":"The second line of the code is used to get weeks in order i.e. mon, tue, etc. Otherwise it will be sorted alphabetically.","473dead0":"# EDA on Medium blogs\n\nI am blogging for some time on [dev.to](https:\/\/dev.to\/kedark) and [medium](https:\/\/medium.com\/@kedarkodgire.kk) and I thought that it would be great to  to analyze some data based on blogs like, what should be the reading time, on what day to post a blog, which image extensions are used in the blogs, etc. I found an interesting dataset on kaggle for medium blogs, this dataset contains information about randomly chosen medium articles published in 2019 from these 7 publications:\n\nTowards Data Science\nUX Collective\nThe Startup\nThe Writing Cooperative\nData Driven Investor\nBetter Humans\nBetter Marketing\n\nI will be using some python libraries like pandas, numpy, etc for this analysis.","a8b6ed45":"Yay, we got our graph!!\nalong with the claps the comments\/responses are also the important factor in the article writing because they they help us to understand quality of blog i.e is it well-written \/ it's plagarised \/ it is helpful \/ conversation starter, etc. and you can also do further sentimental analysis on it to understand if it's good or bad. let's plot another scatterplot for it.","358d50fe":"### Q: The dataset that we are using is in which time span\n\nWe can answer this using min and max functions","04c5f3c3":"This number again backs up two of our analysis which we did previously i.e. 5 - 10 minutes. Hence we can say that reading time plays an effective role in success of the article.","4e00af34":"## Inferences and Conclusion\n\nHere is the summary of analysis that we did from this dataset","a4d12f14":"Cool, as you see we have got the required columns from mail dataframe i.e dates and counts, let's take day of week and month out of it using `dt` and make two new columns for these as we are going to use these for out graph.","c7828a7c":"Now that we understood what is the best day to post an article, let's try to get understand how long should the article be.\n\nwe are going to plot the graph with number of claps vs reading time of the article. Assumtion is that a person will give a clap to article only when he reads it completly and finds it useful\/entertaining.","d71c85e7":"what? we have 2 rows with no image. let's remove these two rows to make this dataset cleaner.","d9d25d38":"### Q: what percent of best blogs have subtitles?","a7af50f4":"### Q: what is the avarage reading time of articles according to the publications"}}