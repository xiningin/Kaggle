{"cell_type":{"8df82a45":"code","5d0006f6":"code","3c349111":"code","c6f65e28":"code","bf0522f0":"code","8bf6d818":"code","45ffa5a1":"code","f58814d4":"code","384f555f":"code","fa5440a3":"code","021fd63b":"code","73507d32":"code","51f8c788":"code","f614576e":"code","d8a1d0bb":"code","9dc95fcd":"code","973c9557":"code","43f432ec":"code","74877d66":"code","ffa09241":"code","41173846":"code","8c093a20":"code","940a908c":"code","c16cf204":"code","f88837a5":"code","52eb4362":"code","ce753b2e":"code","dd2457cd":"code","ad98705a":"code","48f74a37":"code","3a0b61f7":"code","01234fdc":"markdown"},"source":{"8df82a45":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport shutil\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\nfrom tensorflow.keras.layers import Input, Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint","5d0006f6":"FAST_RUN = False\nIMAGE_WIDTH = 128\nIMAGE_HEIGHT = 128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\ntf.random.set_seed(42)","3c349111":"image_dir = '..\/input\/zndmasks\/images'\ntrain = pd.read_csv('..\/input\/zndmasks\/train_labels.csv')\nsub = pd.read_csv('..\/input\/zndmasks\/sample_sub_v2.csv')","c6f65e28":"train","bf0522f0":"sub","8bf6d818":"def create_dir(names: [str], path: str):\n    \"\"\"\n    Creates the directories passed in the names arg list\n    in the specified path within the current working directory.\n    Args:\n        `names`: A list of directory names to be created.\n        `path`: The path where to create the directories.\n    \"\"\"\n    for dir_name in names:\n        new_dir = os.path.join(path, dir_name)\n        img_path = os.path.join(new_dir)\n        if not os.path.exists(img_path):\n            os.mkdir(img_path)\n        else:\n            print(f'{img_path}: Exists!') \n\n\ndef move_images(image_list: [str], source_dir: str, dest_dir: str):\n    \"\"\"\n    Move images in image_list from source path to dest path.\n    Args:\n        `image_list`: A list of image files to be moved between directories.\n        `source_dir`: The source\/current directory holding the files.\n        `dest_dir`: The new directory where the files will be transfered.\n    \"\"\"\n    for img in image_list:\n        shutil.move(source_dir+img, dest_dir)","45ffa5a1":"dirs = ['train', 'test']\n#create_dir(dirs, '\/kaggle\/working\/')\ncreate_dir(dirs, '\/tmp\/')","f58814d4":"img_names = os.listdir('..\/input\/zndmasks\/images')\ntrain_img_names = train.image.tolist()\ntest_img_names = []\n\nfor img in img_names:\n    if img not in train_img_names:\n        test_img_names.append(img)\n        \ntrain_img_names\ntest_img_names","384f555f":"print(len(train_img_names))\nprint(len(test_img_names))","fa5440a3":"from distutils.dir_util import copy_tree\n\nfromDirectory='..\/input\/zndmasks\/images'\ntoDirectory='\/tmp\/images'\n\ncopy_tree(fromDirectory,toDirectory)","021fd63b":"# Move train images to the train dir\nmove_images(train_img_names, '\/tmp\/images\/', '\/tmp\/train\/')\n\n# Move test images to the test dir\nmove_images(test_img_names, '\/tmp\/images\/', '\/tmp\/test\/')","73507d32":"# Plotting the image class distributions in the train set\ntrain['target'].value_counts().plot.bar()\nplt.title('Image class distributions')\nplt.xlabel('Classes (0: No mask) (1: Mask)')\nplt.ylabel('Number of images in train set')","51f8c788":"# Further splitting the train images into train and validation images.\ntrain['target'] = train['target'].replace({0: 'No_mask', 1: 'Mask'})\n\ntr_data, val_data = train_test_split(train, test_size=0.20, random_state=42)\ntr_data = tr_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)","f614576e":"tr_data","d8a1d0bb":"total_train = tr_data.shape[0]  #total train images\ntotal_validate = val_data.shape[0] #total images on validation set\nbatch_size = 8","9dc95fcd":"# Train generator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    tr_data, \n    '\/tmp\/train\/', \n    x_col = 'image',\n    y_col = 'target',\n    target_size = IMAGE_SIZE,\n    class_mode = 'categorical',\n    batch_size = batch_size\n)\n\n# Validation generator\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    val_data, \n    '\/tmp\/train\/', \n    x_col='image',\n    y_col='target',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","973c9557":"plt.figure(figsize=(12, 12))\nfor i in range(0, 8):\n    plt.subplot(2, 4, i+1)\n    for X_batch, Y_batch in train_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","43f432ec":"base_model = tf.keras.applications.MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n                                               include_top=False,\n                                               weights='imagenet')\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx =  Dense(1024,activation='relu')(x) # complex for better results.\nx = Dropout(0.8)(x) \nx = Dense(1024,activation='relu')(x) \nx = Dropout(0.8)(x) \nx = Dense(512,activation='relu')(x) \nx = Dropout(0.8)(x) \npreds = Dense(2,activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input,outputs=preds) #specify the inputs and outputs\n\nmodel.summary()","74877d66":"earlystop = EarlyStopping(patience=5) # Stop if validation loss doesn't improve after 5 epochs\n\n# Gradually reduce the learning rate if validation loss doesn't improve after 5 steps\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=5, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001\n                                           )\nmodelcheckpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n\ncallbacks = [earlystop, modelcheckpoint,learning_rate_reduction]\n\nbase_learning_rate = 0.0001\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","ffa09241":"# Training the model\nepochs = 10 if FAST_RUN else 200\n\nhistory = model.fit_generator(\n    train_generator, \n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = total_validate\/\/batch_size,\n    steps_per_epoch = total_train\/\/batch_size,\n    callbacks = callbacks\n)","41173846":"model.save_weights(\"mobilenet.h5\")","8c093a20":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","940a908c":"test_filenames = os.listdir('\/tmp\/test\/')\ntest_df = pd.DataFrame({\n    'image': test_filenames\n})\nnb_samples = test_df.shape[0]","c16cf204":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    '\/tmp\/test\/', \n    x_col='image',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","f88837a5":"predictions = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","52eb4362":"from keras.models import load_model\nsaved_model = load_model('best_model.h5')\npred_new = saved_model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))\npred_probabilities = pred_new.max(1)","ce753b2e":"test_df['target'] = pred_probabilities\nsub2 = test_df.copy()\nsub2.to_csv('submission2.csv', index=False)","dd2457cd":"predicted_probabilities = predictions.max(1)","ad98705a":"test_df['target'] = predicted_probabilities","48f74a37":"test_df","3a0b61f7":"sub = test_df.copy()\nsub.to_csv('submission.csv', index=False)","01234fdc":"Creating train and test directories to store the respective images:"}}