{"cell_type":{"e1261aec":"code","8b9ef4d2":"code","fb03194d":"code","271d11e6":"code","71a529d2":"code","ca67d453":"code","ef3c0cab":"code","1f69f714":"code","ccba08f6":"code","3fba6130":"code","67a51411":"code","f16ca48b":"code","00fc9270":"code","6e758387":"code","f1ccdd9a":"code","49636894":"code","5fb3ec49":"code","2cbb157e":"code","c7740e74":"code","32e203fc":"code","328904be":"code","b132b30a":"code","5c4c5d63":"code","b5b822fd":"code","a8d2595d":"markdown","d5023e2e":"markdown","1d680554":"markdown","37c369b0":"markdown","1f00fb98":"markdown","c4a68998":"markdown","5b2ed9e7":"markdown","d349aff8":"markdown","d85e6e4c":"markdown"},"source":{"e1261aec":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm","8b9ef4d2":"!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","fb03194d":"!apt-get install -y -qq libboost-all-dev","271d11e6":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","71a529d2":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile","ca67d453":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","ef3c0cab":"# Latest Pandas version\n!pip install -q 'pandas==0.25' --force-reinstall","1f69f714":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","ccba08f6":"print(\"Pandas version:\", pd.__version__)","3fba6130":"import warnings\nwarnings.filterwarnings(\"ignore\")","67a51411":"import gc\ngc.enable()","f16ca48b":"import lightgbm as lgb\nprint(\"LightGBM version:\", lgb.__version__)","00fc9270":"from sklearn.preprocessing import LabelEncoder","6e758387":"train_transaction = pd.read_csv('..\/input\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\n\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='TransactionID')","f1ccdd9a":"train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)","49636894":"y_train = train['isFraud'].copy()\ndel train_transaction, train_identity, test_transaction, test_identity\ngc.collect()","5fb3ec49":"# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\ndel train, test\ngc.collect()","2cbb157e":"X_train = X_train.fillna(-999)\nX_test = X_test.fillna(-999)","c7740e74":"# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values))","32e203fc":"# LGBMClassifier with GPU\nclf = lgb.LGBMClassifier(\n    max_bin = 63,\n    num_leaves = 255,\n    num_iterations = 500,\n    learning_rate = 0.01,\n    tree_learner = 'serial',\n    task = 'train',\n    is_training_metric = False,\n    min_data_in_leaf = 1,\n    min_sum_hessian_in_leaf = 100,\n    sparse_threshold=1.0,\n    device = 'gpu',\n    num_thread = -1,\n    save_binary= True,\n    seed= 42,\n    feature_fraction_seed = 42,\n    bagging_seed = 42,\n    drop_seed = 42,\n    data_random_seed = 42,\n    objective = 'binary',\n    boosting_type = 'gbdt',\n    verbose = 1,\n    metric = 'auc',\n    is_unbalance = True,\n    boost_from_average = False,\n)","328904be":"%time clf.fit(X_train, y_train)","b132b30a":"gc.collect()","5c4c5d63":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X_train.columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:20])\nplt.title('LightGBM Feature Importance - Top 20')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances.png')","b5b822fd":"sample_submission['isFraud'] = clf.predict_proba(X_test)[:,1]\nsample_submission.to_csv('simple_lightgbm_gpu.csv')","a8d2595d":"### Build and re-install LightGBM with GPU support","d5023e2e":"## Submission","1d680554":"## Feature Importances","37c369b0":"This kernel demonstrates a way of using LightGBM with GPU support in Kaggle kernels.\n\nBasically to avoid the following error which we get when we give `device='gpu'` in LightGBM parameters.\n\n`LightGBMError: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1`\n\nThe code & idea are heavily inspired from the following:\n* https:\/\/www.kaggle.com\/inversion\/ieee-simple-xgboost\n* https:\/\/www.kaggle.com\/xhlulu\/ieee-fraud-xgboost-with-gpu-fit-in-40s\n* https:\/\/www.kaggle.com\/vinhnguyen\/gpu-acceleration-for-lightgbm\n* https:\/\/lightgbm.readthedocs.io\/en\/latest\/GPU-Tutorial.html\n* https:\/\/lightgbm.readthedocs.io\/en\/latest\/GPU-Performance.html","1f00fb98":"With `device='gpu'` parameter commented, it takes ~ 22 minutes to fit on CPU.\n\n`CPU times: user 42min 4s, sys: 13 s, total: 42min 17s\nWall time: 21min 47s`\n\nWith `device='gpu'`, it takes ~ 3 minutes to fit on GPU.\n\n`CPU times: user 3min 59s, sys: 46 s, total: 4min 45s\nWall time: 2min 34s`\n\n*Note: The CPU provided in Kaggle GPU kernel is 2 core, so the time to fit with above parameters might take half the time(~11 minutes) on a CPU only kernel(4 core CPU), which is still slower than LightGBM GPU implementation.*","c4a68998":"## Preprocessing","5b2ed9e7":"## LightGBM GPU Installation","d349aff8":"## Imports","d85e6e4c":"## Modeling"}}