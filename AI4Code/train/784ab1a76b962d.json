{"cell_type":{"32baf1ae":"code","275b5a12":"code","5f2d0e1c":"code","e430e811":"code","e988ac62":"code","eebd46e2":"code","ddf5ab99":"code","238c112f":"code","41009d6b":"code","461de828":"code","d26f57d7":"code","62e8c41a":"markdown","e9a051be":"markdown"},"source":{"32baf1ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","275b5a12":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [20,8]\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nfrom sklearn.metrics import log_loss","5f2d0e1c":"df=pd.read_csv('..\/input\/prostatecsv\/prostate.csv')\ndf.drop(['ID'],axis=1,inplace=True)\ndf.sample(2)","e430e811":"df.describe()","e988ac62":"sns.heatmap(df.corr(),annot=True,vmin=0.2,vmax=0.5,cmap='Dark2')","eebd46e2":"X=df.drop('GLEASON',axis=1)\ny=df[['GLEASON']]\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test","ddf5ab99":"df['GLEASON'].unique()","238c112f":"# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()  #criterion{\u201cgini\u201d, \u201centropy\u201d}, default=\u201dgini\u201d\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n\n#Predict the response for test dataset\ny_pred1 = clf.predict(X_test)\nt_score1=clf.score(X_train,y_train)\nscore1=clf.score(X_test,y_test)\n\n##log loss\nprob_y=clf.predict_proba(X_test)\nlog_loss1=log_loss(y_test,prob_y,labels=clf.classes_)\n\n# Model Accuracy, how often is the classifier correct?\naccuracy1=metrics.accuracy_score(y_test, y_pred1)\nprint(\"Accuracy:\",accuracy1)","41009d6b":"# Create Decision Tree classifer object\nclf1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3) #criterion{\u201cgini\u201d, \u201centropy\u201d}, default=\u201dgini\u201d\n# Train Decision Tree Classifer\nclf1 = clf1.fit(X_train,y_train)\n#Predict the response for test dataset\ny_pred = clf1.predict(X_test)\nt_score2=clf1.score(X_train,y_train)\nscore2=clf1.score(X_test,y_test)\n\n##log loss\nprob_y1=clf1.predict_proba(X_test)\nlog_loss2=log_loss(y_test,prob_y1,labels=clf.classes_)\n\n# Model Accuracy, how often is the classifier correct?\naccuracy2=metrics.accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\",accuracy2)","461de828":"data={'model':[clf,clf1],'train_score':[t_score1,t_score2],'test_score':[score1,score2],'log_loss':[log_loss1,log_loss2],'Accuracy':[accuracy1,accuracy2]}\ndf1=pd.DataFrame(data)\ndf1","d26f57d7":"X=df.drop('GLEASON',axis=1)\ny=df['GLEASON']\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n\n# ##\nfrom sklearn.ensemble import RandomForestRegressor\nclf3 = RandomForestRegressor(max_depth=3, random_state=0).fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf3.predict(X_test)\nt_score3=clf3.score(X_train,y_train)\nscore3=clf3.score(X_test,y_test)\nprint('Score',score3)","62e8c41a":"# RandomForestRegressor","e9a051be":"# DecisionTreeClassifier\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html"}}