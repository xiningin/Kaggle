{"cell_type":{"1ff590b0":"code","9fd27186":"code","7be42ee4":"code","0b9ad848":"code","4e5ec94e":"code","9b66d4ff":"code","b8b5dd9e":"code","0ad87da2":"code","9561edc7":"code","1b7dfc19":"code","0800e9bc":"code","829d6edb":"code","c8edead8":"code","d7dfcc08":"code","87eff3b9":"code","5d0d3550":"code","e3f9b90b":"markdown","15d0892e":"markdown","b38cf6a7":"markdown","57425ca1":"markdown","ae4f364e":"markdown","6be3fe79":"markdown","88ee2d9f":"markdown","afe150e7":"markdown","b1c9408b":"markdown","db2c9d1f":"markdown","d1eb5adc":"markdown","5ac3de9c":"markdown","65b2ee90":"markdown","083ffa19":"markdown","b7e4e8eb":"markdown"},"source":{"1ff590b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9fd27186":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","7be42ee4":"df = pd.read_csv('\/kaggle\/input\/montcoalert\/911.csv')\ndf.info()","0b9ad848":"plt.figure(1,(15,5))\nsns.heatmap(df.isnull(), yticklabels=False, cbar=False)\nplt.show()","4e5ec94e":"df.head()","9b66d4ff":"df['desc'][0]","b8b5dd9e":"df['reason'] = df['title'].apply(lambda x: x.split(':')[0])","0ad87da2":"df.head()","9561edc7":"print('Reason:' ,df['reason'].unique())\n\nsns.countplot(x = 'reason', data = df, palette='hot')\nplt.show()","1b7dfc19":"df['timeStamp'] = pd.to_datetime(df['timeStamp'])\n\ndf['month'] = df['timeStamp'].apply(lambda time: time.month)\ndf['day'] = df['timeStamp'].apply(lambda time: time.dayofweek)\ndf['hour'] = df['timeStamp'].apply(lambda time: time.hour)\ndf['date'] = df['timeStamp'].apply(lambda time: time.date())","0800e9bc":"dmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\ndorder = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n\ndf['day'] = df['day'].map(dmap)\ndf.head()","829d6edb":"reason_list = ['EMS', 'Fire', 'Traffic']\n\nplt.figure(1,(25,5))\nfor n,i in enumerate(reason_list):\n    plt.subplot(1,3,n+1)\n    df[df['reason']==i].groupby('date').count()['e'].plot()\n    plt.xticks(rotation=90)\n    plt.title(i)","c8edead8":"sns.countplot(x='day', order = dorder, data = df, hue = 'reason', palette='hot')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","d7dfcc08":"dayHour = df.groupby(by=['day','hour']).count()['reason'].unstack().reindex(dorder)\ndayHour.head()","87eff3b9":"plt.figure(1,(20,10))\nsns.heatmap(dayHour)\nplt.show()","5d0d3550":"sns.clustermap(dayHour)\nplt.show()","e3f9b90b":"Let's check if there are any missing values. In this case, a simple representation is sufficient. (Bright lines represent missing values.)","15d0892e":"And add them up per weekday.","b38cf6a7":"For better readability, we present the days as strings.","57425ca1":"With the grouped DataFrame we can create a heatmap.","ae4f364e":"Three major categories can be identified (EMS, Fire, Traffic). Plotting them over time could be interesting. Unfortunately, the timeStamp is a string and it would be better to have separate columns. So, we convert the string to a DateTime datatype and create 4 new columns for \"month\", \"day\", \"hour\" and \"date\".","6be3fe79":"This representation is not clear. Therefore, we want to examine this more closely and use a heatmap. First we restructure the data frame and group the reason column by day and hour. We will also put the days of the week in the correct order.","88ee2d9f":"How many reasons are there? And how often do they occur?","afe150e7":"The column \"desc\" seems to be composed of entries from other columns.","b1c9408b":"# Emergency 911 Calls - my first EDA\n\nWith this notebook, I want to gain experience in exploratory data analysis. And I hope the code examples will be useful to others who, like me, are just getting started with Data Science.\n\nFirst, we import the Packages, the data and get an overview.","db2c9d1f":"After all, this was a fun EDA that covered many important areas.\n\nSuggestions for improvement? I'm happy to hear from you!","d1eb5adc":"And check the new DataFrame.","5ac3de9c":"Now we can plot each reason over time.","65b2ee90":"Only zip-codes are missing. However, this column isn\u2019t interesting for our analysis and can be ignored. Let\u2019s have a closer look at the Dataset.","083ffa19":"The number of emergency calls in the morning hours and late at night are comparatively low. There are also slightly fewer emergency calls at the weekend. They are more frequent from Monday to Friday between 8 a.m. and 6 p.m., with a peak between 3 p.m. and 5 p.m.\n\nWe can show the relationships even more precisely with a cluster map.","b7e4e8eb":"and is rather uninteresting. More interesting is the \"title\" column. The entries follow the structure \"General reason: specification\". Capturing the general reason as a separate column could be interesting. So, we generate a new column \"reason\" from the data of the title column."}}