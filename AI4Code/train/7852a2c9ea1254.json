{"cell_type":{"3568c70d":"code","2bd15612":"code","4c6ad2e0":"code","6613e3df":"markdown"},"source":{"3568c70d":"!cp ..\/input\/nlpp-text2code\/eval_utils.py .\/\nfrom numpy.random import default_rng\nfrom eval_utils import(\n    load_model_and_data,\n    length_of_test_dataset,\n    eval_test_data,\n    eval_user_input,\n    eval_done\n)\n\nload_model_and_data()","2bd15612":"rng = default_rng()\nresults = []\nfor i in range(10):\n    results += eval_test_data(rng.integers(length_of_test_dataset()), i)\nfor i in range(5):\n    results += eval_user_input(i) \n    \neval_done()","4c6ad2e0":"print(results)","6613e3df":"# Python code generation\n\nThe goal of our project is to have a docstring in code out translation model. In our case we want to go from English to Python. Specifically, our model learned the association between a function's docstring and code. For this we limited ourselves to only short functions. \n\nThis evaluation has two parts:\n1. Rate the given examples (chosen from our test data).\n2. Give your own docstrings to the model.\n\nIn both parts, please rate:\n1. The quality of the generated code.\n2. How well the generated code fits the given docstring.\n\nRate on a scale from 1 to 5:  \n1 = no part of the code is worth keeping (ignoring \"def\", \"return\", or other keywords).  \n2 = I could change the code to a correct solution, but would not save time doing so.  \n3 = fixing the changes and writing a correct version would be equally complex.  \n4 = changing the given code to a correct version would still save me time.  \n5 = no changes needed.  \n\nFor example if the code quality is good but doesn't fit the docstring at all, you may rate it (5,1).\n"}}