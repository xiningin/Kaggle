{"cell_type":{"6935828e":"code","4fd72099":"code","f1a76648":"code","0fd7f3c8":"code","30a7f59b":"code","fac7d4dc":"code","d5c7c8d4":"code","92289f76":"code","6808297b":"code","43848604":"code","a90e8640":"code","1ef0e1a6":"code","8acc8918":"code","88659866":"code","5668de5b":"code","f6cac2bd":"code","40d545b6":"code","159dd266":"code","7b68d869":"code","609171c7":"code","e5db794f":"code","f8b49a69":"code","f1515019":"code","b49290e6":"code","df7cd197":"code","53215921":"code","bd5b521d":"code","bab68970":"code","ac51ee52":"code","6af57973":"code","3f358fb3":"code","6b70baf1":"code","4c3032c0":"code","82ff1587":"code","a5aff672":"code","2f6ed2a2":"code","4132bb03":"code","d6febef2":"code","b168b10d":"code","21432ae3":"code","fe90af15":"code","b0ba18e7":"code","691f4079":"code","845260b5":"code","3f8c8125":"code","be0087bc":"code","544a6a62":"code","af683204":"code","24c7a475":"code","ecba469d":"code","68d6ff31":"code","0857010a":"code","0d5d55b4":"code","91bd98d9":"code","98089e69":"code","8345308b":"code","1dcc23e1":"code","2a743663":"code","d150eefa":"code","a5817894":"code","854332dc":"code","f6f6db94":"code","947cb608":"code","3d7e63ad":"code","70a2eee9":"code","252dd528":"code","83cf1a8b":"code","adcba0b7":"markdown","863430b3":"markdown","6b8bd8d6":"markdown","1248d77e":"markdown","d43d94cc":"markdown","9fa3eebf":"markdown","2b7e5d3e":"markdown","36a94f9b":"markdown","fe2e890b":"markdown","46045c1e":"markdown","04b54836":"markdown"},"source":{"6935828e":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","4fd72099":"import os\nimport pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nimport sklearn\nfrom datetime import date","f1a76648":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0fd7f3c8":"train_data = pd.read_csv(f'\/kaggle\/input\/train.csv')\ntrain_label = pd.read_csv(f'\/kaggle\/input\/train_label.csv',header=None)\ntest_data = pd.read_csv(f'\/kaggle\/input\/test.csv')\ntest_label = pd.read_csv(f'\/kaggle\/input\/test_label.csv', header=None)","30a7f59b":"train_data.head()","fac7d4dc":"train_label.shape, train_data.shape, test_data.shape,test_label.shape","d5c7c8d4":"train_data['Total Booking'] = train_label","92289f76":"train_data.head()","6808297b":"date_data = pd.DataFrame(pd.to_datetime(train_data['datetime']))\ndate_data['Total Booking'] = train_label\ndate_data = date_data.set_index('datetime')\ndate_data.plot()\nplt.ylabel('Total Bookings')","43848604":" weekly = date_data.resample('W').sum()        \n weekly.plot()        \n plt.ylabel('Weekly total bookings'); ","a90e8640":" by_weekday = date_data.groupby(date_data.index.dayofweek).mean()        \n by_weekday.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']        \n by_weekday.plot();\n","1ef0e1a6":"weekend = np.where(date_data.index.weekday < 5, 'Weekday', 'Weekend')        \nby_time = date_data.groupby([weekend, date_data.index.time]).mean() \nhourly_ticks = 4 * 60 * 60 * np.arange(6)\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))        \nby_time.loc['Weekday'].plot(ax=ax[0], title='Weekdays', xticks=hourly_ticks, style=[':', '--', '-'])        \nby_time.loc['Weekend'].plot(ax=ax[1], title='Weekends',  xticks=hourly_ticks,style=[':', '--', '-'])\n","8acc8918":"g = sns.FacetGrid(train_data, col='workingday')\ng.map(plt.hist, 'Total Booking', bins=20)","88659866":"grid = sns.FacetGrid(train_data, col='workingday', row='season', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Total Booking', bins=20)\ngrid.add_legend();","5668de5b":"g = sns.FacetGrid(train_data, col='holiday')\ng.map(plt.hist, 'Total Booking', bins=20)","f6cac2bd":"grid = sns.FacetGrid(train_data, col='holiday', row='season', height=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Total Booking', bins=20)\ngrid.add_legend();","40d545b6":"train_data.isnull().sum()","159dd266":"train_data.info()","7b68d869":"sns.countplot(x=\"season\", data=train_data)","609171c7":"sns.countplot(y=\"weather\", data=train_data)","e5db794f":"train_data.describe()","f8b49a69":"attributes = ['temp',\t'atemp',\t'humidity',\t'windspeed',\t'Total Booking']","f1515019":"train_data[attributes].hist(bins=50, figsize=(20,15))","b49290e6":"#sns.boxplot(x='windspeed',data=train_data)\nplt.figure(figsize = (10,5))\nax = sns.boxplot(data = train_data, orient = \"h\", color = \"violet\", palette = \"Set1\")\nplt.show()","df7cd197":"corr_matrix = train_data.corr()","53215921":"corr_matrix[\"Total Booking\"].sort_values(ascending=False)","bd5b521d":"sns.pairplot(train_data[attributes])","bab68970":"sns.jointplot(x=\"Total Booking\", y=\"temp\", data=train_data);","ac51ee52":"def preprocessing(data):\n  \n  date_data = pd.DataFrame(pd.to_datetime(data['datetime']))\n\n  #Extracting Year from Date\n  data['Year'] = date_data['datetime'].dt.year\n\n  #Extracting Month from Date\n  data['Month'] = date_data['datetime'].dt.month\n\n  #Extracting the weekday name of the date\n  data['day_name'] = date_data['datetime'].dt.day_name()\n\n  final_data = data.drop(columns=['datetime'])\n\n  def truncate(n):\n    return round(n)\n\n  final_data['temp'] = final_data['temp'].apply(truncate)\n  final_data['atemp'] = final_data['atemp'].apply(truncate)\n  final_data['windspeed'] = final_data['windspeed'].apply(truncate)\n\n  attributes = ['season','weather','day_name']\n  one_hot_df = pd.get_dummies(final_data[attributes])\n\n  final_data = pd.concat([final_data,one_hot_df],axis=1)\n  final_data = final_data.drop(columns=attributes)\n    \n  return final_data","6af57973":"final_data = preprocessing(train_data)\nfinal_data.columns","3f358fb3":"attrib = ['Total Booking','weather_ Heavy Rain + Thunderstorm ']\nfinal_data = final_data.drop(columns=attrib)","6b70baf1":"final_data.head()","4c3032c0":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ntrain_data_final = scaler.fit_transform(final_data)\nX_train, X_test, y_train, y_test = train_test_split(train_data_final, train_label, test_size=0.2, random_state=200)","82ff1587":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression(normalize=True)","a5aff672":"lm.fit(X_train,y_train)","2f6ed2a2":"predictions = lm.predict(X_test)","4132bb03":"plt.scatter(y_test,predictions)","d6febef2":"from sklearn.metrics import r2_score","b168b10d":"print('R2-Score',r2_score(y_test,predictions))","21432ae3":"from sklearn.svm import LinearSVR","fe90af15":"svm_reg = LinearSVR(epsilon=1.5,max_iter=1000,random_state=200)\nsvm_reg.fit(X_train,y_train.values.ravel())","b0ba18e7":"preds = svm_reg.predict(X_test)","691f4079":"print('R2-Score',r2_score(y_test,preds))","845260b5":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()","3f8c8125":"forest_reg.fit(X_train,y_train.values.ravel())","be0087bc":"preds = forest_reg.predict(X_test)","544a6a62":"print('R2-Score',r2_score(y_test,preds))","af683204":"from sklearn.model_selection import GridSearchCV","24c7a475":"param_grid = [{'n_estimators':[20,30], 'max_features': [2,4,6,8]},\n              {'bootstrap':[False],'n_estimators':[3,10], 'max_features':[2,3,4]}]","ecba469d":"forest_reg = RandomForestRegressor()","68d6ff31":"grid_search = GridSearchCV(forest_reg, param_grid,cv=5,scoring='r2',return_train_score=True)","0857010a":"grid_search.fit(X_train, y_train.values.ravel())","0d5d55b4":"grid_search.best_params_","91bd98d9":"grid_search.best_estimator_","98089e69":"forest_reg1 = RandomForestRegressor(max_features=6,n_estimators=30)","8345308b":"forest_reg1.fit(X_train,y_train.values.ravel())","1dcc23e1":"preds = forest_reg1.predict(X_test)","2a743663":"print('R2-Score after Grid Search best Parameters',r2_score(y_test,preds))","d150eefa":"from sklearn.ensemble import VotingRegressor","a5817894":"voting_clf = VotingRegressor(estimators=[('lr', lm),('rf', forest_reg1),('svm', svm_reg)])\nvoting_clf.fit(X_train, y_train.values.ravel()).predict(X_test)","854332dc":"X_train.shape, y_train.shape, X_test.shape,y_test.shape","f6f6db94":"from sklearn.metrics import r2_score\nfor clf in (lm,forest_reg1,svm_reg,voting_clf):\n  clf.fit(X_train,y_train.values.ravel())\n  y_pred = clf.predict(X_test)\n  print(clf.__class__.__name__,r2_score(y_test,y_pred))","947cb608":"test_data = preprocessing(test_data)","3d7e63ad":"test_data.head()","70a2eee9":"test_data = scaler.fit_transform(test_data)","252dd528":"final_preds = forest_reg1.predict(test_data)","83cf1a8b":"print('R2-Score of test data',r2_score(test_label, final_preds))","adcba0b7":"Regression Models:","863430b3":"Random Forest","6b8bd8d6":"Linear Regression:","1248d77e":"Grid Search:","d43d94cc":"Testing:","9fa3eebf":"Often when dealing with continuous numeric attributes like proportions or percentages, we may not need the raw values having a high amount of precision. Hence it often makes sense to round off these high precision percentages into numeric integers. ","2b7e5d3e":"Ensemble Methods:","36a94f9b":"Outlier Analysis using Boxplots:","fe2e890b":"**Preprocessing and Feature Engineering**\n1. Convert the categorical variables in the train_data to one-hot encoding\n2. Extract Date Features\n3. Round decimal data\n4. Normalize data for training","46045c1e":"The info() method is useful to get a quick description of data, in particular the total number of rows, and each attribute's type and number of non-null values.","04b54836":"From the above info() method we can understand- \n1. 7 attributes are numerical.\n2. No null values in the data.\n3. 3 Columns are of object type datetime, season and weather.\n\nLet's explore further:\n"}}