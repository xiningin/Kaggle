{"cell_type":{"ea5b2681":"code","bd8859ee":"code","e66216d3":"code","86ba50d9":"code","4a22bb80":"code","620fa81c":"code","416e25a5":"code","b8211c68":"code","ab5b8e4a":"code","0b35d5c1":"code","63d782fb":"code","fe5ade15":"code","6b3b26d1":"code","85e09739":"code","e5574a2d":"code","c769825e":"code","d091bc36":"code","825b9a84":"code","689b3205":"code","9bab6738":"code","6d67a855":"code","3b18b2b8":"code","72edb367":"code","15a220ea":"code","0e708acd":"code","80459d4a":"code","7047e3ed":"code","86b404ee":"code","6c43f0e5":"code","82a780f2":"code","7b2b6075":"code","5249d172":"code","f7c473de":"code","2e5c1fb8":"code","3549491d":"markdown","a0beb36c":"markdown","11c8a213":"markdown"},"source":{"ea5b2681":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bd8859ee":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","e66216d3":"train.head()","86ba50d9":"test.info()","4a22bb80":"train.isnull().sum()","620fa81c":"test.isnull().sum()","416e25a5":"#Treat Age\ntrain['Age'] = train['Age'].fillna(value=train['Age'].median())\ntest['Age'] = test['Age'].fillna(value=test['Age'].median())","b8211c68":"#Treat Fare\ntrain['Fare'] = train['Fare'].fillna(value=train['Fare'].median())\ntest['Fare'] = test['Fare'].fillna(value=test['Fare'].median())","ab5b8e4a":"train['Embarked'].mode()[0]","0b35d5c1":"#Treat Embarked\ntrain['Embarked'] = train['Embarked'].fillna(value=train['Embarked'].mode()[0])\ntest['Embarked'] = test['Embarked'].fillna(value=test['Embarked'].mode()[0])","63d782fb":"#Treat Cabin\ntrain['Cabin'] = train['Cabin'].fillna('Missing')\ntrain['Cabin'] = train['Cabin'].str[0]\ntrain['Cabin'].value_counts()","fe5ade15":"#Treat Cabin\ntest['Cabin'] = test['Cabin'].fillna('Missing')\ntest['Cabin'] = test['Cabin'].str[0]\ntest['Cabin'].value_counts()","6b3b26d1":"#Extract Title from Name\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","85e09739":"#We will combine a few categories, since few of them are unique \ntrain['Title'] = train['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\ntrain['Title'] = train['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\ntrain['Title'] = train['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntrain['Title'] = train['Title'].replace(['Mme'], 'Mrs')\ntrain['Title'].value_counts()","e5574a2d":"#We will combine a few categories, since few of them are unique \ntest['Title'] = test['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\ntest['Title'] = test['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\ntest['Title'] = test['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntest['Title'] = test['Title'].replace(['Mme'], 'Mrs')\ntest['Title'].value_counts()","c769825e":"#Family Size & Alone \ntrain['Family_Size'] = train['SibSp'] + train['Parch'] + 1\ntrain['IsAlone'] = 0\ntrain.loc[train['Family_Size']==1, 'IsAlone'] = 1","d091bc36":"#Family Size & Alone \ntest['Family_Size'] = test['SibSp'] + test['Parch'] + 1\ntest['IsAlone'] = 0\ntest.loc[train['Family_Size']==1, 'IsAlone'] = 1","825b9a84":"train.head()","689b3205":"all = pd.concat([train, test], sort = False)\nall.info()","9bab6738":"all_dummies = pd.get_dummies(all.drop(['Name', 'Ticket'], axis = 1), drop_first = True)\nall_dummies.head()","6d67a855":"all_train = all_dummies[all_dummies['Survived'].notna()]","3b18b2b8":"all_test = all_dummies[all_dummies['Survived'].isna()]","72edb367":"y = all_train['Survived']\nX = all_train.drop(['Survived', 'PassengerId'], axis = 1)","15a220ea":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=101)","0e708acd":"from sklearn.linear_model import LogisticRegression","80459d4a":"logModel = LogisticRegression(max_iter = 5000)\nlogModel.fit(X_train, y_train)","7047e3ed":"predictions = logModel.predict(X_test)\npredictions","86b404ee":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","6c43f0e5":"logModel.score(X_train, y_train)","82a780f2":"logModel.score(X_test, y_test)","7b2b6075":"X_Submission = all_test.drop(['PassengerId', 'Survived'], axis = 1)","5249d172":"pred_for_submission = logModel.predict(X_Submission).astype(int)","f7c473de":"logSub = pd.DataFrame({'PassengerId': all_test['PassengerId'], 'Survived':pred_for_submission })\nlogSub.head(1)","2e5c1fb8":"logSub.to_csv(\"1_Logistics_Regression_Submission.csv\", index = False)","3549491d":"# Process Data for Modelling","a0beb36c":"# Make Submission","11c8a213":"# Log Model"}}