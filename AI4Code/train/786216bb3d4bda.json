{"cell_type":{"d26315c7":"code","a5097a20":"code","265293ea":"code","2f4a273b":"code","d978ec14":"code","c33057cd":"code","617be95e":"code","38062e44":"code","6f23f771":"code","b9ff17f6":"code","789326da":"code","d0b98048":"code","26d9b9e4":"code","0326119c":"code","698e5ece":"code","dbbef2fa":"code","f3bb5e12":"code","ba1b92a7":"code","15e454c1":"code","4934f0a9":"code","133d0f25":"code","6d2fe881":"code","84698d38":"code","d03fc9f1":"code","57de22aa":"code","b6215da1":"code","c69739b4":"markdown","1530155d":"markdown","3d4ace24":"markdown","348aaae6":"markdown","eea9efc7":"markdown","e846a8b0":"markdown","2bf29115":"markdown"},"source":{"d26315c7":"import cv2\nimport os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport codecs\nfrom tqdm import tqdm","a5097a20":"train_labels = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/train_labels.csv\")\ntrain_labels.head(5)","265293ea":"ddt = train_labels[\"target\"].value_counts().to_frame()\nfig, ax = plt.subplots(1,1,figsize=(12,4))\nsns.countplot(data = train_labels, x = \"target\", orient = \"v\", palette = \"pastel\", ax=ax)\nplt.suptitle(\"Train target distribution\")","2f4a273b":"train_files = glob.glob(\"..\/input\/seti-breakthrough-listen\/train\" + \"\/*\/*.npy\")\nprint(\"Number of train files:{}\".format(len(train_files)))","d978ec14":"test_files = glob.glob(\"..\/input\/seti-breakthrough-listen\/test\" + \"\/*\/*.npy\")\nprint(\"Number of test files:{}\".format(len(test_files)))","c33057cd":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"..\/input\/seti-breakthrough-listen\/train\/{_id[0]}\/{_id}.npy\"\n\ndef show_cadence(filename: str, label: int) -> None:\n    fig, axes = plt.subplots(6, 1, figsize = (16, 10))\n    ax = axes.ravel()\n    arr = np.load(filename)\n    for i in range(6):\n        \n        ax[i].imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        ax[i].text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        if i != 5:\n            ax[i].set_xticks([])\n            \n    fig.text(0.5, -0.02, 'Frequency Range', ha='center', fontsize=18)\n    fig.text(-0.02, 0.5, 'Seconds', va='center', rotation='vertical', fontsize=18)\n\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    fig.tight_layout()\n    plt.show()","617be95e":"positive_target=train_labels.query(\"target==1\").sample().id.item()\nnegative_target=train_labels.query(\"target==0\").sample().id.item()\nshow_cadence(get_train_filename_by_id(positive_target), 1)\nshow_cadence(get_train_filename_by_id(negative_target), 0)","38062e44":"!pip install efficientnet_pytorch","6f23f771":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\nimport sys\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.model_selection import StratifiedKFold\nfrom efficientnet_pytorch import model as enet\nfrom torch.utils.data import Dataset, DataLoader","b9ff17f6":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(2021)","789326da":"DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","d0b98048":"sample_train_id = train_labels.query(\"target==1\").sample().id.item()\nsample = np.load(f\"..\/input\/seti-breakthrough-listen\/train\/{sample_train_id[0]}\/{sample_train_id}.npy\")\nsample.shape\nnp.array([np.abs(sample).max() for i in range(sample.shape[0])]).reshape(sample.shape[0],1,1)","26d9b9e4":"class ETDataSet(Dataset):\n    def __init__(self, image_paths, targets):\n        self.image_paths = image_paths\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, item):\n        image = np.load(self.image_paths[item]).astype(\"float\")\n        targets = self.targets[item]\n        image = image \/ np.array([np.abs(image).max() for i in range(6)]).reshape(6,1,1)\n        \n        return torch.tensor(image,dtype=torch.float), torch.tensor(targets,dtype=torch.float)","0326119c":"df_train = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/train_labels.csv\")\ndf_train.head(5)","698e5ece":"df_train[\"image_path\"] = df_train[\"id\"].apply(lambda x:f\"..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy\")\ndf_train.head(5)","dbbef2fa":"# enet.EfficientNet.from_pretrained(\"efficientnet-b3\")","f3bb5e12":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    \"Returns mixed inputs, pairs of targets and lambda\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    \n    batch_size = x.size()[0]\n    \n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n        \n    mixed_x = lam  * x + (1-lam) * x[index,:]\n    y, y_shuffle = y, y[index]\n    return mixed_x, y, y_shuffle, lam\n\ndef mixup_criterion(criterion, pred, y, y_shuffle, lam):\n    return lam * criterion(pred, y.view(-1,1)) + (1 - lam) * criterion(pred, y_shuffle.view(-1,1))","ba1b92a7":"class backbone(nn.Module):\n    def __init__(self, pretrain, out_dim):\n        super(backbone, self).__init__()\n        self.enet = enet.EfficientNet.from_pretrained(pretrain)\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv = nn.Conv2d(6, 3, kernel_size = 3, padding = 3, bias = False)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.enet(x)\n        x = self.myfc(x)\n        return x","15e454c1":"def focal_loss(outputs, targets):\n    gamma = 2\n    log_outs = F.log_softmax(outputs, -1)\n    log_outs = log_outs.gather(1, targets.view(-1,1))\n    outs = log_outs.exp()\n    \n    loss = - ((1 - outs) ** gamma) * log_outs\n    loss = loss.mean()\n    return loss","4934f0a9":"criterion = nn.BCEWithLogitsLoss()\n\ndef train(train_loader, val_loader, model, optimizer, device, fold_idx, epoch):\n    model.train()\n    with codecs.open('log.out','a') as f:\n        f.write(\"\\n\\n\")\n    best_roc_auc  = 0\n    check_point = 1\n    loss = -1\n    \n    for epoch_idx in range(epoch):\n        process_bar = tqdm(train_loader, position=0, leave=True, desc=\"Training\")\n        for datas,labels in process_bar:\n            datas = datas.to(device).float()\n            labels = labels.to(device)\n\n            if np.random.randint(1, 10) >= 6:\n                mixed_x, y, y_shuffle, lam = mixup_data(datas, labels,use_cuda = False)\n                outputs = model(mixed_x)\n                loss_now = mixup_criterion(criterion, outputs, y, y_shuffle, lam)\n                \n            else:\n                outputs = model(datas)\n                loss_now = focal_loss(outputs, labels)\n                \n            \n            if loss == -1:\n                loss = loss_now.data.item()\n            else:\n                loss = 0.8 * loss + 0.2 * loss_now.data.item()\n            \n            process_bar.set_postfix(loss = loss)\n            process_bar.update()\n            \n            optimizer.zero_grad()\n            loss_now.backward()\n            optimizer.step()\n\n\n        preds, valid_targets = evaluate(val_loader, model, device=DEVICE)\n        roc_auc = roc_auc_score(valid_targets, preds)\n        print(f\"valid auc is:{roc_auc}\")\n\n        with codecs.open(\"log.out\",\"a\") as f:\n            f.write(f\"Fold{fold_idx}, Epoch={epoch_idx}, Check_point={check_point}, Valid_ROC_AUC={roc_auc}\\n\")\n\n        if roc_auc > best_roc_auc:\n            torch.save(model.state_dict(), \".\/efnet-\" + str(fold_idx) + \".pth\")\n            best_roc_auc = roc_auc\n\n            \ndef evaluate(data_loader, model, device):\n    model.eval()\n    total_labels = []\n    total_outputs = []\n    \n    for datas, labels in tqdm(data_loader, position=0, leave=True, desc=\"Evaluating\"):\n        datas = datas.to(device).float()\n        \n        outputs = model(datas)\n        outputs = outputs.detach().cpu().numpy().tolist()\n        labels = labels.detach().cpu().numpy().tolist()\n        \n        total_labels.extend(labels)\n        total_outputs.extend(outputs)\n    \n    return total_outputs, total_labels","133d0f25":"backbone_name = \"efficientnet-b3\"\n\nepochs = 2\nbatch_size = 32","6d2fe881":"X = df_train.image_path.values\nY = df_train.target.values\nprint(X)\nprint(Y)","84698d38":"skf = StratifiedKFold(n_splits = 5)\nfold = 0\n\nfor train_idx, val_idx in skf.split(X,Y):\n    model = backbone(backbone_name, out_dim=1)\n    model.to(DEVICE)\n    model = nn.DataParallel(model)\n    \n    train_images, valid_images = X[train_idx], X[val_idx]\n    train_targets, valid_targets = Y[train_idx], Y[val_idx]\n    \n    train_dataset = ETDataSet(image_paths = train_images, targets = train_targets)\n    valid_dataset = ETDataSet(image_paths = valid_images, targets = valid_targets)\n    \n    train_loader = DataLoader(dataset = train_dataset,\n                             batch_size = batch_size,\n                             shuffle = True,\n                             num_workers=1)\n    valid_loader = DataLoader(dataset = valid_dataset,\n                             batch_size = batch_size,\n                             shuffle = False,\n                             num_workers=1)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    train(train_loader, valid_loader, model, optimizer, DEVICE, fold, epochs)\n    \n    fold += 1\n    print(\"\")","d03fc9f1":"import pandas as pd\nsubmission = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/sample_submission.csv\")\nsubmission[\"img_path\"] = submission[\"id\"].apply(lambda x:f\"..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy\")\n\ntest_dataset = ETDataSet(image_paths = submission.img_path.values, targets = submission.target.values)\ntest_loader = DataLoader(dataset = test_dataset,\n                        batch_size = 16,\n                        shuffle = False,\n                        num_workers = 1)\n","57de22aa":"models = []\nfor path in glob.glob(\"efnet-*\"):\n    model = backbone(backbone_name, out_dim = 1)\n    model.to(DEVICE)\n    model = nn.DataParallel(model)\n    model.load_state_dict(torch.load(path))\n    models.append(model)\n    \nsigmoid = torch.nn.Sigmoid()\nouts = []\nfor model in models:\n    predictions, valid_targets = evaluate(test_loader,model, DEVICE)\n    predictions = np.array(predictions)[:,0]\n    out = sigmoid(torch.from_numpy(predictions))\n    out = out.detach().numpy()\n    outs.append(out)\n\npred = np.mean(np.array(outs), axis=0)","b6215da1":"submission.target = pred\nsubmission.drop([\"img_path\"], axis=1 ,inplace = True)\nsubmission.to_csv('.\/submission.csv', index = False)","c69739b4":"># focal loss\n","1530155d":"># Criterion and train","3d4ace24":"> # DATASET","348aaae6":"># Test set","eea9efc7":"># BackBone","e846a8b0":"># Mixup Data","2bf29115":"> # Train set"}}