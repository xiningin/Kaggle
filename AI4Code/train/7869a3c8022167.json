{"cell_type":{"d72f2744":"code","a136f537":"code","55197d3a":"code","8dc18888":"code","5736d7b1":"code","9b91c9be":"code","5cb95ba9":"code","a6515c35":"code","b2869b47":"code","08dce4f7":"code","ddbb26bb":"code","f88a458e":"code","1102e923":"code","88527a67":"code","146123e1":"code","2b4b39ef":"code","79041b53":"code","8a7dc9e9":"code","51e17fb1":"markdown"},"source":{"d72f2744":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a136f537":"#Importing important modules\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport numpy as np\n#Installing Tensorboard\n!pip install Tensorboard","55197d3a":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')","8dc18888":"x = train.drop(['label'], axis =1)\ny = train['label']","5736d7b1":"\nfrom sklearn.model_selection import train_test_split\n(x_train,x_test, y_train, y_test) = train_test_split(x, y, test_size=0.3,random_state = 101, shuffle=True)","9b91c9be":"#Verify the shape\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","5cb95ba9":"#Reshape the data\nx_train = x_train.values.reshape(x_train.shape[0],28,28,1)\n\nx_test = x_test.values.reshape(x_test.shape[0],28,28,1)\n\n#Change into float32 datatype and Normalize x_train and x_test by dividing it by 255.0\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n#Normalizing the input\nx_train \/= 255.0\nx_test \/= 255.0\n","a6515c35":"#Verify the shape of x_train and x_test\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint('X_test shape:', x_test.shape)\nprint(x_test.shape[0], 'test samples')","b2869b47":"#Using One-hot encoding to divide y_train and y_test into required no of output classes\n\nnum_classes = 10\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","08dce4f7":"#Verify shape of y_train\nprint('y_train shape:', y_train.shape)","ddbb26bb":"#Initialize the model\nmodel = Sequential()\n\n#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu'))\n\n#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n\n#Add a MaxPooling Layer of size 2X2 \nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#Apply Dropout with 0.25 probability \nmodel.add(Dropout(0.25))\n\n#Flatten the layer\nmodel.add(Flatten())\n\n#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\nmodel.add(Dense(128, activation='relu'))\n\n#Apply Dropout with 0.5 probability \nmodel.add(Dropout(0.5))\n\n#Add Fully Connected Layer with 10 units and activation function as 'softmax'\nmodel.add(Dense(num_classes, activation='softmax'))","f88a458e":"from keras.optimizers import Adam\nfrom keras.losses import categorical_crossentropy\n\n#To use adam optimizer for learning weights with learning rate = 0.001\noptimizer = Adam(lr=0.000003)\n#Set the loss function and optimizer for the model training\nmodel.compile(loss=categorical_crossentropy,\n              optimizer=optimizer,\n              metrics=['accuracy'])","1102e923":"model.fit(x_train, y_train,\n          batch_size=64,\n          epochs=120,validation_data=(x_test, y_test))#Testing the model on test set\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","88527a67":"#Loading test File\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","146123e1":"test = test.values.reshape(test.shape[0],28,28,1)\ntest = test.astype('float32')\ntest \/= 255.0","2b4b39ef":"predictions = model.predict_classes(test, verbose=1)\ndf = pd.DataFrame({\"ImageId\":list(range(1,len(predictions)+1)),\n              \"Label\":predictions})\ndf","79041b53":"df.to_csv('sample_submission_1.csv', index=False,header=True)","8a7dc9e9":"for layers in model.layers:\n    print(layers.name)\n    if('dense' not in layers.name):\n        layers.trainable = False\n        print(layers.name + 'is not trainable\\n')\n    if('dense' in layers.name):\n        print(layers.name + ' is trainable\\n')","51e17fb1":"Validate model on fresh set of data"}}