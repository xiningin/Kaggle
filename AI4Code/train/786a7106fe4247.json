{"cell_type":{"c3a3a8a1":"code","cb8efd8c":"code","3681f86e":"code","c8fc18de":"code","cb10d59b":"code","4db56831":"code","8e1b40db":"code","bab5dd1a":"code","0eb3929c":"markdown","a7d5ed70":"markdown","355b1e5b":"markdown","a6de0630":"markdown","1f2ef769":"markdown","b3cf1207":"markdown","bf9bb632":"markdown","44291202":"markdown"},"source":{"c3a3a8a1":"import cv2\nimport os\nimport subprocess\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np \nimport pandas as pd \nimport csv\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","cb8efd8c":"# 2 datasets\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n# Combine the 2 datasets together\n\ntrain_data1 = np.concatenate([x_train, x_test], axis=0)\nlabels1 = np.concatenate([y_train, y_test], axis=0)\nlabels2 = train_data.label\nlabels = np.concatenate([labels1, labels2], axis=0)\ntrain_data2 = train_data.drop(columns='label')\nimages = np.concatenate([train_data1.reshape([-1,28*28]), train_data2.values], axis=0)\nprint(images.shape)\nprint(labels.shape)\n# Now we have the amount of picture in 2 datasets (112000 pictures), but just a picture of 1 digit\n# 784 = 28x28 it is the 1-D array of 28x28 pixels picture","3681f86e":"digits_per_sequence = 7 #The number of digits in a picture\nnumber_of_sequences = 100 # the number of pictures you want to generate\ndataset_sequences = []\ndataset_labels = []\n\nfor i in range(number_of_sequences):\n    random_indices = np.random.randint(len(images), size=(digits_per_sequence,)) #L\u1ea5y random 7 c\u00e1i \u0111\u1ecba ch\u1ec9 \u1ea3nh\n    random_digits_images = images[random_indices] #L\u1ea5y 7 \u1ea3nh t\u1eeb 7 \u0111\u1ecba ch\u1ec9 \u0111\u00f3\n    transformed_random_digits_images = []\n    # L\u1eadt h\u00ecnh cho d\u1ec5 nh\u00ecn\n    for img in random_digits_images:\n        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n        img = cv2.flip(img, 1)\n        transformed_random_digits_images.append(img)\n\n    random_digits_images = np.array(transformed_random_digits_images) #ma tran anh chuoi ki tu: ahgdasjdg\n    random_digits_labels = labels[random_indices] #[9 9 9 2 9 8 6]\n\n    random_sequence = np.hstack(random_digits_images.reshape((digits_per_sequence, 28, 28))) #\u1ea3nh chu\u1ed7i k\u00ed t\u1ef1 \u0111ang x\u00e9t\n    random_labels = np.hstack(random_digits_labels.reshape(digits_per_sequence, 1)) #label c\u1ee7a \u1ea3nh chu\u1ed7i k\u00ed t\u1ef1 \u0111ang x\u00e9t\n    \n    dataset_sequences.append(random_sequence) # chu\u1ed7i c\u00e1c \u1ea3nh ahdjagj\n    dataset_labels.append(random_labels) # chu\u1ed7i c\u00e1c label c\u1ee7a \u1ea3nh 9,1,2,7,4,6,7\n\n\nlabels = np.array(dataset_labels)\nimages = np.array(dataset_sequences).reshape([-1, 28,28*digits_per_sequence,1])\n#print('\\n labels',labels)","c8fc18de":"from zipfile import ZipFile\nimport os\nfor i in range(10000):\n    label = ( \"\".join( str(e) for e in labels[i] ) ) # remove brackets [] of array\n    images[i] = 255 - images[i]\n    name  = str(label +\".png\")\n    cv2.imwrite(name,images[i])\n\nzipObj = ZipFile('multi_digit_images_10k.zip', 'w')\nfor filename in os.listdir(\"\/kaggle\/working\"):\n    if filename.endswith(\".png\"):\n        zipObj.write(filename)\nzipObj.close()","cb10d59b":"# Data augmentation\ndef augmentation(image):\n    ''' The dataset is so clean, so it's not fit with out real input images with blobs, noise, ugly characters '''\n    height, width = image.shape \n    num_blob= int(random.gauss(20, 20))\n    for i in range (num_blob):\n        x = random.randint(0,width)\n        y = int (random.gauss(0,height))\n        radius = random.randint(0,3)\n        # add noise\n        image = cv2.circle(image, (x,y), radius = radius, color = ((0, 0, 0) ), thickness = -1) \n        # erode or dilate\n    return image","4db56831":"# Resize, transpose and normalize image\ndef preprocess(img, imgSize ):\n    ''' resize, transpose and standardization grayscale images '''\n    # create target image and copy sample image into it\n    widthTarget, heightTarget = imgSize \n    height, width = img.shape \n    factor_x = width \/ widthTarget\n    factor_y = height \/ heightTarget\n\n    factor = max(factor_x, factor_y)\n    # scale according to factor\n    newSize = (min(widthTarget, int(width \/ factor)), min(heightTarget, int(height \/ factor)))\n\n    img = cv2.resize(img, newSize)\n    target = np.ones(shape=(heightTarget, widthTarget), dtype='uint8') * 255\n    target[0:newSize[1], 0:newSize[0]] = img\n    # transpose\n    img = cv2.transpose(target)\n    # standardization\n    mean, stddev = cv2.meanStdDev(img)\n    mean = mean[0][0]\n    stddev = stddev[0][0]\n    img = img - mean\n    img = img \/\/ stddev if stddev > 0 else img\n    return img","8e1b40db":"header = 'label image'\nheader = header.split()\nwith open('.\/aug_digit_data.csv', \"w\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerow(header)\n\nfor i,image in enumerate(images):\n    label = \"'\" + ( \"\".join( str(e) for e in labels[i] ) ) # b\u1ecf ngo\u1eb7c, th\u00eam d\u1ea5u '\n    # I have to add \"'\" bcuz csv will change label 0345 into 345\n    image = 255 - image\n    image = image[:,:,0].astype('uint8')\n\n    image = augmentation(image)\n    image = preprocess(image, imgSize = (128, 32))\n\n    image = image.flatten()\n    #print ('len image',len(image))\n    image = ( \" \".join( str(e) for e in image ) )\n    value = [label, image]\n\n    with open('.\/aug_digit_data.csv', \"a\", encoding=\"utf-8\") as f:\n        writer = csv.writer(f)\n        writer.writerow(value)\n\nprint('done')","bab5dd1a":"data = pd.read_csv('.\/aug_digit_data.csv')\n\nlabels = data.iloc[: ,0].to_list()\nimages = data.iloc[: ,1].to_list()\nt = []\nfor image in images:\n    image = image.split(' ')\n    image = np.array(image, dtype = float)\n    t.append(image)\nimages = t\nt = []\nimages = np.array(images).reshape(-1, 128, 32, 1)\n\nfor label in labels:\n    label = label.split(\"'\")[1] #remove ' comma\n    t.append(label)\nlabels = t\nt = []\n\nplt.figure(num='multi digit',figsize=(9,18))\nfor i in range(6):\n\n    plt.subplot(3,3,i+1) \n    plt.title(labels[i])\n    plt.imshow(np.squeeze(images[i,:,:,]))\n    plt.axis('off')\nplt.show()","0eb3929c":"Let's see how to work with csv file and what inside","a7d5ed70":"<a href=\"multi_digit_images_10k.zip\"> Download File <\/a>","355b1e5b":"Write image to `csv` file","a6de0630":"# LOAD MNIST DATASET","1f2ef769":"# PROCESSING THE DATASET\nThe code bellow is from [this repo](https:\/\/github.com\/dredwardhyde\/crnn-ctc-loss-pytorch\/blob\/main\/mnist_sequence_recognition.py)\n\nIt's really hard to understand the original code, the author wanted to feed all of the array of picture into the model, but not me, for some reason. \n\nMay be you tooo. I guess.\n","b3cf1207":"I will use Vietnamese for this project so feel free to use google translate :))\n\nThe code bellow is [here](https:\/\/www.kaggle.com\/duansm\/crnn-for-mnist\/data?fbclid=IwAR1EHvegm9lcSLubJcroL5aZ_nLuDVN02ufqu3erc-pL27F_oa_bjouByo0&select=train.csv)\n\nI guess the author wanted to combine the 2 datasets to get more data\n","bf9bb632":"## .CSV file\nHere is updated code for my project\n1. Data augmentation (add noise)\n2. Resize, transpose and normalize image\n3. Saving picture into `.csv` file","44291202":"# SAVING NEW DATASET\n## .PNG file\nNow we will save the images. I wil add all the image into zip file to download instead of png file"}}