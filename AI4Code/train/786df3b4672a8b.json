{"cell_type":{"d1e674ca":"code","c4162827":"code","c614e0f7":"code","83c60fa4":"code","71449751":"code","3eff507a":"code","60a5501b":"code","04c18dcc":"code","d0fcca20":"code","d95de59d":"code","3e6d06b0":"code","53409737":"code","5d1d2b56":"code","c65b962c":"code","889f3f53":"code","a07a6937":"code","eac743e1":"code","6c9c417b":"code","db85a7ac":"code","830a2a80":"code","3417f39e":"code","22085af4":"code","28d5367a":"code","7bc9d631":"code","514d5264":"code","136fbe46":"code","006a4232":"code","6bbc657c":"code","93797e26":"markdown","41a65f2b":"markdown","853313b9":"markdown","2b5d7791":"markdown","40de6024":"markdown","7bccb49d":"markdown","c30552d0":"markdown","82915e4b":"markdown","2735c3ca":"markdown","02a4c92a":"markdown","7f1649e9":"markdown","6a7b77ab":"markdown","9ec93e38":"markdown","dcd34e1d":"markdown","e2822b10":"markdown","3cbd7da6":"markdown","b667bac5":"markdown","bc9d8069":"markdown","9606d8e6":"markdown"},"source":{"d1e674ca":"\"\"\"reading training data\"\"\"\nimport pandas as pd\nimport plotly.express as px\n\ntrain_data= pd.read_csv(\"..\/input\/ashrae-energy-prediction\/train.csv\")\nweather = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/weather_train.csv\")\nmetadata = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/building_metadata.csv\")\n","c4162827":"## Function to reduce the DF size\nimport numpy as np\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\n\ntrain_data = reduce_mem_usage(train_data)\n\nweather = reduce_mem_usage(weather)\n\nmetadata = reduce_mem_usage(metadata)\n","c614e0f7":"\"\"\"getting description\"\"\"\ntrain_data.describe()","83c60fa4":"\"\"\"EDA for each variable\"\"\"\nimport plotly.express as px\nout = train_data.meter.value_counts().reset_index()\n\nfig = px.bar(out, x='index' ,  y='meter')\nfig.show()","71449751":"temp = train_data.groupby(['meter']).mean().reset_index()\nfig = px.bar(temp, x=\"meter\" ,  y='meter_reading')\nfig.show()","3eff507a":"\"\"\"histogram for skewed meter_reading\"\"\"\nimport matplotlib.pyplot as plt\ntrain_data['meter_reading'].hist(bins = 100)\n","60a5501b":"import numpy as np\ntrain_data['log_meter_reading'] = np.log1p(train_data['meter_reading']) \ntrain_data['log_meter_reading'].hist(bins = 100)\n","04c18dcc":"\"\"\"conevrting time stamp into timeseries type\"\"\"\ntrain_data['timestamp'] = pd.to_datetime(train_data['timestamp'] )\n\n","d0fcca20":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=2, cols=2)\n\n\"\"\"for meter type 0\"\"\"\ntemp = train_data.loc[train_data['meter'] == 0].groupby(['timestamp']).sum().reset_index()\nfig.add_trace(\n    go.Scatter(x=temp['timestamp'], y=temp['meter_reading']),\n    row=1, col=1\n)\n\n\"\"\"for meter type 1\"\"\"\ntemp = train_data.loc[train_data['meter'] == 1].groupby(['timestamp']).sum().reset_index()\nfig.add_trace(\n    go.Scatter(x=temp['timestamp'], y=temp['meter_reading']),\n    row=1, col=2\n)\n\n\n\"\"\"for meter type 2\"\"\"\ntemp = train_data.loc[train_data['meter'] == 2].groupby(['timestamp']).sum().reset_index()\nfig.add_trace(\n    go.Scatter(x=temp['timestamp'], y=temp['meter_reading']),\n    row=2, col=1\n)\n\n\"\"\"for meter type 3\"\"\"\ntemp = train_data.loc[train_data['meter'] == 3].groupby(['timestamp']).sum().reset_index()\nfig.add_trace(\n    go.Scatter(x=temp['timestamp'], y=temp['meter_reading']),\n    row=2, col=2\n)\n\nfig.show()","d95de59d":"\"\"\"getting missing data\"\"\"\nmetadata.isnull().sum()","3e6d06b0":"fig = px.box(metadata, y=\"year_built\")\nfig.show()","53409737":"fig = px.box(metadata, y=\"floor_count\")\nfig.show()","5d1d2b56":"merged_data = pd.merge(train_data, metadata, on=\"building_id\")\n","c65b962c":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=4, cols=4)\nusage = list(merged_data.primary_use.unique())\ncount = 0\n\n\nfor rows in [1,2,3,4]:\n  for cols in [1,2,3,4]:\n\n    temp = merged_data.loc[merged_data.primary_use == usage[count]].groupby(['timestamp']).sum().reset_index()\n    count += 1\n    fig.add_trace(\n        go.Scatter(x=temp['timestamp'], y=temp['meter_reading']),\n        row=rows, col=cols\n    )\n\n\nfig.update_layout(height=1200, width=1600, title_text=\"Subplots\")\ncount = 0\nfor rows in [1,2,3,4]:\n  for cols in [1,2,3,4]:\n    fig.update_xaxes(title_text=usage[count], row=rows, col=cols)\n    count += 1\n\nfig.show()","889f3f53":"\ntemp = merged_data.groupby([\"primary_use\"]).mean()['meter_reading'].reset_index()\nfig = px.bar(temp, x=\"primary_use\" ,  y='meter_reading')\nfig.show()\n","a07a6937":"temp = merged_data.groupby([\"primary_use\"]).sum()['meter_reading'].reset_index()\nfig = px.bar(temp, x=\"primary_use\" ,  y='meter_reading')\nfig.show()","eac743e1":"weather.describe()","6c9c417b":"#weather.air_temperature.nunique()\nfig = px.box(weather, y=\"air_temperature\")\nfig.show()","db85a7ac":"\"\"\"converting timestamp data to timestamp type\"\"\"\nweather['timestamp'] = pd.to_datetime(weather['timestamp'] )","830a2a80":"weather.head(5)","3417f39e":"merged_data.head(4)\n\n\n","22085af4":"\"\"\"merging dataframes on site_id and timestamp\"\"\"\n\nnew_merges = pd.merge(merged_data, weather, on=['timestamp','site_id'])\n\n\"\"\"verifying length \"\"\"\nprint(len(new_merges))","28d5367a":"\"\"\"counting the number of missing timestamp and site combination data from weather file\"\"\"\nprint('missing' ,  len(set(merged_data.timestamp.apply(str) + \"_\" + merged_data.site_id.apply(str)) - set(weather.timestamp.apply(str) + \"_\" + weather.site_id.apply(str)) ))","7bc9d631":"print(\"data lost due to missing of wether data\" , len(merged_data)- len(new_merges))","514d5264":"\"\"\"checking missing values\"\"\"\nnew_merges.isnull().sum().plot(kind= \"bar\")\nprint(new_merges.isnull().sum())","136fbe46":"import plotly.express as px\ntemp = new_merges.groupby(['air_temperature']).sum()['meter_reading'].reset_index()\nfig = px.bar(temp, x=\"air_temperature\" ,  y='meter_reading')\nfig.show()\n","006a4232":"import plotly.express as px\ntemp = new_merges.groupby(['wind_speed']).sum()['meter_reading'].reset_index()\nfig = px.bar(temp, x=\"wind_speed\" ,  y='meter_reading')\nfig.show()\n","6bbc657c":"import plotly.express as px\ntemp = new_merges.groupby(['dew_temperature']).sum()['meter_reading'].reset_index()\nfig = px.bar(temp, x=\"dew_temperature\" ,  y='meter_reading')\nfig.show()\n","93797e26":"**COnclusion**\n\nHere length of merged data is not equal to original data hence there are some sets of timestamp and site_id combination whch are not present in weather data.","41a65f2b":"Grouping different meter according to their tyep and then plotting with date time ","853313b9":"Taking pictorial look over the data","2b5d7791":"**Cnclusion**\nFrom the description we can conclude following\n* there is no missing value present \n* meter_reading is right skewed\n","40de6024":"**Conclusion**\n\n\n1.   Only meter type 0 follows the seasonality pattern\n2.   Bills for meter type 1,2 are preety high\n","7bccb49d":"**Average meter readin for each meter**","c30552d0":"**merging weather data with prevous merged data data**","82915e4b":"**Conclusion**\n\n\n1.   Year Built column: since 774 columns are empty, this may be becaue either building is under construction or building is before 1900 which is the min year present in data\n\n\n\n2.   List item\n\n\n\n","2735c3ca":"**Moving on next metadatfile i.e. Weather**","02a4c92a":"**EDA for training data**","7f1649e9":"**moving on with Building Metadata**","6a7b77ab":"**Getting overall usage of each building type**","9ec93e38":"Hence 50% of houses bult between 1949-1995 as here q1 starts and q3 stops","dcd34e1d":"**dealing with time series expansion**","e2822b10":"**Merging Building metadata with training data** ","3cbd7da6":"Reducing memory size","b667bac5":"But this occurs for multiple buildings and hence total count rose to following","bc9d8069":"**Getting average usage of each building type**","9606d8e6":"**Getting energy usage of various building types**"}}