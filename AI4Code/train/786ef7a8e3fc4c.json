{"cell_type":{"aa6efbe4":"code","e6919ad4":"code","b225debb":"code","ff1507b4":"code","d122d331":"code","9212f410":"code","f134df8e":"code","1b7355dc":"code","0b544f47":"code","19efb039":"code","9d545a34":"code","0a396e1a":"code","68bc02f3":"code","81b30635":"code","05cce444":"code","c07a163b":"code","9cb6418b":"code","eb40f689":"code","0239f713":"code","6806fb1e":"code","71653df4":"code","fff24ae7":"code","317cbf59":"code","ee005e4b":"code","e78370de":"code","1d0512d6":"code","adcce3a2":"code","c3f8a87f":"code","5ec7f450":"code","6c8473d8":"code","a37156a5":"code","3e4469b7":"code","138749ed":"code","3212464e":"code","d2852387":"markdown"},"source":{"aa6efbe4":"import numpy as np \nimport pandas as pd\nimport os\nfrom PIL import Image\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport time\n\nfrom subprocess import check_output\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50,MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\n\nprint(os.listdir(\"..\/input\"))","e6919ad4":"def read_and_resize(filepath):\n    im = image.load_img(filepath, \n                        color_mode = \"grayscale\", \n                        target_size=(resize, resize))\n    x = image.img_to_array(im)\n    x = preprocess_input(x)\n    return x","b225debb":"train_dir = \"..\/input\/train\"\ntest_dir = \"..\/input\/test\"\nresize = 124 ## size images will be resized to \nsample_to = 15\nbatch_size = 32","ff1507b4":"train = pd.read_csv(\"..\/input\/train.csv\")","d122d331":"print((train.Id=='new_whale').mean())\nprint((train.Id.value_counts()==1).mean())","9212f410":"im_count = train[train.Id != 'new_whale'].Id.value_counts()","f134df8e":"im_count.name = 'sighting_count'\ntrain = train.join(im_count, on='Id')","1b7355dc":"train.shape","0b544f47":"val_fns = set(train.sample(frac=1)[(train.Id != 'new_whale') & (train.sighting_count > 1)].groupby('Id').first().Image)","19efb039":"train_xnw = train.loc[train['Id'] != 'new_whale'].reset_index(drop=True) #xnw = exclude new whale\ntrain_nw = train.loc[train['Id'] == 'new_whale'].reset_index(drop=True) #nw = incude new whale\nnum_classes = len(train_xnw['Id'].unique())","9d545a34":"del train\ngc.collect()","0a396e1a":"train_xnw_val = train_xnw[train_xnw.Image.isin(val_fns)].reset_index(drop=True)\ntrain_xnw_train = train_xnw[~train_xnw.Image.isin(val_fns)]","68bc02f3":"print(train_xnw_train.sighting_count.min())\nprint(train_xnw_train.sighting_count.max())","81b30635":"res = None\n\nfor grp in tqdm(train_xnw_train.groupby('Id')):\n    n = grp[1].shape[0]\n    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n    rows = pd.concat((grp[1], additional_rows))\n    \n    if res is None: res = rows\n    else: res = pd.concat((res, rows))\n        \nres = res.reset_index(drop = True).drop(columns=['sighting_count'])","05cce444":"len(res)","c07a163b":"del train_xnw_train\ngc.collect()","9cb6418b":"res.shape","eb40f689":"im_count_new = res.Id.value_counts()\nim_count_new.name = 'sighting_count'\nres = res.join(im_count_new, on='Id')","0239f713":"print(res.sighting_count.max()) ## took 1 image for the validation set, therefore its 72 instead of 73\nprint(res.sighting_count.min())","6806fb1e":"df = pd.DataFrame(train_xnw.Id.value_counts().sort_values(ascending=True))\ndf = df.reset_index()\ndf = df.rename(index=str, columns={\"index\": \"Id\", \"Id\": \"Count\"})\ndf.tail()","71653df4":"d = {cat: k for k,cat in enumerate(df['Id'])}","fff24ae7":"x_train = np.zeros((res.shape[0],resize,resize,1))\nfor index, row in tqdm(res.iterrows()):  \n    im = read_and_resize(os.path.join(train_dir,row['Image']))\n    x_train[index,:,:,:] = im","317cbf59":"train_labels = []\nfor index, row in tqdm(res.iterrows()):  \n        train_labels.append(d[row['Id']])\ntrain_labels = np.array(train_labels)\ny_train = keras.utils.to_categorical(train_labels)","ee005e4b":"del res, train_xnw\ngc.collect()","e78370de":"x_val = np.zeros((train_xnw_val.shape[0],resize,resize,1))\nfor index, row in tqdm(train_xnw_val.iterrows()):  \n    im = read_and_resize(os.path.join(train_dir,row['Image']))\n    x_val[index,:,:,:] = im","1d0512d6":"val_labels = []\nfor index, row in tqdm(train_xnw_val.iterrows()):  \n        val_labels.append(d[row['Id']])\nval_labels = np.array(val_labels)\ny_val = keras.utils.to_categorical(val_labels)","adcce3a2":"del train_xnw_val, val_labels\ngc.collect()","c3f8a87f":"print(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","5ec7f450":"gen =ImageDataGenerator( )","6c8473d8":"model = ResNet50(input_shape=(resize, resize, 1),\n                      weights=None, \n                      classes=num_classes)","a37156a5":"model.compile(optimizer=Adam(lr = 0.0001), \n              loss='categorical_crossentropy',\n              metrics=['accuracy', 'top_k_categorical_accuracy'])\nprint(model.summary())","3e4469b7":"batches = gen.flow(x_train, y_train, batch_size=batch_size)\nval_batches = gen.flow(x_val,y_val, batch_size=batch_size )","138749ed":"epochs = 1\nhistory=model.fit_generator(generator=batches, \n                            steps_per_epoch= batches.n\/\/batch_size, \n                            validation_data = val_batches,\n                            validation_steps =  val_batches.n\/\/batch_size,\n                            epochs=epochs)","3212464e":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['top_k_categorical_accuracy'], color='b', label=\"Training Top 5 Accuracy\")\nax[1].plot(history.history['val_top_k_categorical_accuracy'], color='r',label=\"Validation Top 5 accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","d2852387":"#### Classifier to identify whales that have been seen before"}}