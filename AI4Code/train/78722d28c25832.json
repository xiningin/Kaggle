{"cell_type":{"f75d08e2":"code","28d5278c":"code","a5c38a9d":"code","8cce6003":"code","6e8008f3":"code","674eddc5":"code","1564b063":"code","f171ba5f":"code","4b851457":"code","7057b230":"markdown","35f43cf2":"markdown"},"source":{"f75d08e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport pyarrow.parquet as pq\nimport matplotlib.pyplot as plt\n\n\n# Any results you write to the current directory are saved as output.","28d5278c":"def random_crop(data,meta_data = None,length = 50000,n_samples = 100,targets = None,mode = 'uniform',sigma = 400000):\n    if meta_data is None:\n        meta_data = pd.read_csv('..\/input\/metadata_train.csv')\n    if length is None:\n        length = np.random.randint(1,len(data))\n    if mode != 'uniform':\n        start = np.random.randn() * sigma + len(data) \/\/ 2\n    else:\n        start = np.random.randint(1,len(data))\n    if isinstance(targets,int):\n        meta_data = meta_data[meta_data['target'] == targets]\n    indices = range(len(meta_data))\n    #selected_data = data[:,indices]\n    if n_samples > meta_data.shape[0]:\n        n_samples = meta_data.shape[0]\n    inds = np.random.choice(indices,n_samples,replace = False)\n    targets = meta_data.iloc[inds].target.values\n    pair = (data[start:start + length,inds],targets)\n    return  pair\n     ","a5c38a9d":"# assumes random crop is done\ndef synthesize_waves(pair_a,pair_b,alpha = .5):\n    assert np.all(pair_a[1] == pair_b[1]), 'class does not match'\n    assert len(pair_a[0]) == len(pair_b[0]), 'wave length does not match'\n    np.random.shuffle(pair_b[0].T)\n    return alpha * pair_a[0] + (1 - alpha) * pair_b[0]\n","8cce6003":"#test and show some results here\ndata  = pq.read_pandas('..\/input\/train.parquet', columns=[str(i) for i in range(510)]).to_pandas().values\nmeta_data = pd.read_csv('..\/input\/metadata_train.csv')[:510]","6e8008f3":"pair_a = random_crop(data,meta_data) ","674eddc5":"plt.plot(pair_a[0][:,3])","1564b063":"pair_b = random_crop(data,meta_data)","f171ba5f":"plt.plot(pair_b[0][:,3])","4b851457":"#synthesize the waves\npair_a = random_crop(data,meta_data,targets = 0)\npair_b = random_crop(data,meta_data,targets = 0)\nsynthesized = synthesize_waves(pair_a,pair_b)\nplt.plot(synthesized[:,3])","7057b230":"# About\nThis section is to intoduce lot of data augmentation techniques inspried by sound analysis techniques.\nStating from the basic cropping, we would include some more advanced stuffs, such as wave synthesize and pitch shifting etc.  ","35f43cf2":" ## Augmentors \nThese augmentors are inspired by https:\/\/arxiv.org\/pdf\/1711.10282.pdf , https:\/\/arxiv.org\/pdf\/1604.07160.pdf and http:\/\/karol.piczak.com\/papers\/Piczak2015-ESC-ConvNet.pdf. \n\nAlso, some of the techniques mentioned in https:\/\/arxiv.org\/pdf\/1608.04363.pdf can be useful, so I am looking to add these, too.\n\nFor the random cropping, I set the default length to be 50k.\nIn 2D CNN(images), in many applications,  the input size is $(224, 256)^2$,  which makes 45~ 65k data points.\n\nAlso, it is mentioned that 1s~2s of sound wave is large enough in https:\/\/arxiv.org\/pdf\/1711.10282.pdf. Considering the sampling rate of CD is 44.1 kHZ, that is equivalent to 44.1 ~ 88.2k data points. "}}