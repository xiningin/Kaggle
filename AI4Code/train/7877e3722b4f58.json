{"cell_type":{"d8d71e7b":"code","b8868fac":"code","e873726f":"code","22500aac":"code","51ed7945":"code","56345640":"code","41cf68ff":"code","beaa839d":"code","e6b31ac7":"code","5f6b1b83":"code","408e1481":"code","6f038fa6":"code","2dca09e7":"code","d8ee8f81":"markdown","52b7b817":"markdown","b8bfcf6d":"markdown","825db5df":"markdown","acf94c1d":"markdown","eff04636":"markdown","52f64c43":"markdown","f2963444":"markdown"},"source":{"d8d71e7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b8868fac":"data = pd.read_csv(\"..\/input\/logistics-shopee-code-league\/delivery_orders_march.csv\")\nSLA_data = pd.read_excel(\"..\/input\/logistics-shopee-code-league\/SLA_matrix.xlsx\")","e873726f":"data[['1st_deliver_attempt','2nd_deliver_attempt','pick']] = data[['1st_deliver_attempt','2nd_deliver_attempt','pick']].astype('datetime64[s]')+pd.Timedelta('08:00:00')\ndata","22500aac":"#Remove unnecessary columns\/rows\n#SLA_data.drop(SLA_data.index[0], axis = 0, inplace=True)#This line is needed when using google colab\nSLA_data.drop(SLA_data.columns[0], axis = 1, inplace=True)\nSLA_data.dropna(how='all', inplace=True)\n\n#Make 1st row into DataFrame header\nSLA_data.columns = SLA_data.iloc[0]\n#Rename seller origin column header (1st column) (NA --> 'origin')\nSLA_data.rename(columns={SLA_data.columns[0]: 'origin'}, inplace = True)\n#Drop 1st row\nSLA_data.drop(SLA_data.index[0], inplace = True)\n\n#Make 1st column into DataFrame index\nLocation_List =SLA_data['origin'].values.tolist()\nSLA_data.index = Location_List\nSLA_data.drop(columns=['origin'], inplace=True)\n\n#Extract number\nfor i in SLA_data.columns:\n  SLA_data[i] = SLA_data[i].str.extract('(\\d+)').astype('int64')\n\n#Unstack into series\nSLA_data = SLA_data.stack()\n\n#Convert multi-index into single index\nnew_idx = []\n\nfor i in range(0, len(SLA_data)):\n    new_idx.append(\" to \".join(SLA_data.index[i]))\n    \nSLA_data.index = new_idx\n\nSLA_data","51ed7945":"#List all location from SLA_data\npatList = '('+'|'.join(Location_List)+')'\n\n#Convert string to title case and extract location matched with the list\ndata.buyeraddress = data.buyeraddress.str.title()\ndata.buyeraddress = data.buyeraddress.str.findall(patList).str[-1]\n\ndata.selleraddress = data.selleraddress.str.title()\ndata.selleraddress = data.selleraddress.str.findall(patList).str[-1]","56345640":"data","41cf68ff":"#define custom holidays\nholid = ['2020-03-08', '2020-03-25', '2020-03-30', '2020-03-31']\nfor i in range(0, len(holid)):\n  holid[i] = np.datetime64(holid[i], 'D')","beaa839d":"#Add new column and calculate the value\ndata['1st_interval'] = np.busday_count(begindates=data['pick'].values.astype('datetime64[D]'),\n                    enddates=data['1st_deliver_attempt'].values.astype('datetime64[D]'), \n                    weekmask='Mon Tue Wed Thu Fri Sat', holidays=holid)","e6b31ac7":"#Add new column with initiate value -1\ndata['2nd_interval'] = -1\n\n#Get boolean index of rows with 2nd attempt available\nidx_2nd_attempt = pd.notna(data['2nd_deliver_attempt'])\n\n\ndata.loc[idx_2nd_attempt,'2nd_interval'] = np.busday_count(begindates=data.loc[idx_2nd_attempt,'1st_deliver_attempt'].values.astype('datetime64[D]'),\n                    enddates=data.loc[idx_2nd_attempt,'2nd_deliver_attempt'].values.astype('datetime64[D]'), \n                    weekmask='Mon Tue Wed Thu Fri Sat', holidays=holid)","5f6b1b83":"data","408e1481":"data['SLA'] = data['selleraddress'] + \" to \" + data['buyeraddress']\ndata['SLA'] = data['SLA'].map(SLA_data)","6f038fa6":"#Evaluate first attempt\ndata['is_late'] = data['1st_interval'] > data['SLA']\n\n#Extract order failed 1st attempt but isn't late on that attempt\nidx_failed_1st = (data['is_late'] == 0) & (idx_2nd_attempt)\n\n#Evaluate 2nd attempt\ndata.loc[idx_failed_1st, 'is_late'] = data.loc[idx_failed_1st,'2nd_interval'] > 3\n\n#Convert boolean to int\ndata['is_late'] = data['is_late'].astype('int64')\n\ndata","2dca09e7":"data[['orderid', 'is_late']].to_csv('submission.csv', header = True, index = False)","d8ee8f81":"Data after pre-processed","52b7b817":"Process SLA data","b8bfcf6d":"# Evaluation","825db5df":"Determine SLA for each orderid base on location","acf94c1d":"# SLA Calculation","eff04636":"Define custom holidays","52f64c43":"# Pre-processing data","f2963444":"Using busday_count from numpy to count the number of business day between 2 dates (must use astype('datetime64[D]') to extract only the date because we don't include time in our calculation)"}}