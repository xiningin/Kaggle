{"cell_type":{"878c66d8":"code","94229798":"code","a0620f94":"code","0ff45ff0":"code","857c358b":"code","90f1c0c2":"code","322e03b9":"code","644f4bb7":"code","d456e011":"code","f4a26ce3":"code","f880a559":"code","53e0a272":"code","8d8b4f41":"code","09ce6d15":"code","8804201c":"code","40bc1c72":"code","82876992":"code","b969213c":"code","e3bd330e":"code","cc979e2b":"code","b67ff300":"code","1fc4d462":"code","a7bce4d1":"code","63f596f3":"code","344b174d":"code","ab320084":"code","0346d8d1":"code","7c2fd523":"code","1319f322":"code","2347da74":"code","31528dd2":"code","38fa9502":"code","c138a78a":"code","41cdde85":"code","3a47d651":"code","b0c2c218":"code","54ca40dd":"code","0b0b1ff9":"code","a8c87ddc":"code","58b464b1":"code","79fe3881":"code","f2c8962a":"code","23318bb6":"code","af03255d":"code","f7527a24":"code","3f45a9c7":"code","0ec8e03b":"code","2465d243":"code","3e89a033":"code","7e39c6b5":"code","847b00b9":"code","57ae640e":"code","4e8e9c7a":"code","566526cc":"code","5f847071":"code","7a6e884a":"code","f6e999a0":"code","73176822":"code","a0589756":"markdown","f79b3ab6":"markdown","5efaf75c":"markdown","d0fe135d":"markdown","34133297":"markdown","bfe239cf":"markdown","216218ee":"markdown","dd033e23":"markdown","9de8baf5":"markdown","a67d5621":"markdown","8cb68318":"markdown","660692f6":"markdown","d55243bd":"markdown","d4b4d37d":"markdown","633d4e58":"markdown","d68042e4":"markdown","bcabc135":"markdown","6eebee5f":"markdown","c5eb0ab0":"markdown","b10d6ebe":"markdown","58f1735f":"markdown","77ca1cd4":"markdown","dba76bc2":"markdown","16b4e5f4":"markdown","511a0915":"markdown","8e380514":"markdown","9fdde793":"markdown","da51e3a1":"markdown","cabd3fc2":"markdown","c5feb272":"markdown","ec443d2a":"markdown","5c5b8ec0":"markdown","6600ab13":"markdown","a45c7552":"markdown","2693da82":"markdown","352bffdb":"markdown"},"source":{"878c66d8":"# pip install plotly","94229798":"# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.express as px\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom catboost import CatBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\n\nfrom scipy.stats import chi2_contingency\n\nfrom sklearn.inspection import permutation_importance","a0620f94":"def configure_plotly_browser_state():\n    import IPython\n    display(IPython.core.display.HTML('''\n        <script src=\"\/static\/components\/requirejs\/require.js\"><\/script>\n        <script>\n          requirejs.config({\n            paths: {\n              base: '\/static\/base',\n              plotly: 'https:\/\/cdn.plot.ly\/plotly-1.5.1.min.js?noext',\n            },\n          });\n        <\/script>\n      '''))","0ff45ff0":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","857c358b":"PassengerId = test['PassengerId']\n\n#\ud2b8\ub808\uc778 \ub370\uc774\ud130 \uc77c\ubd80 \ud655\uc778\ntrain.head(3)","90f1c0c2":"#\ub450 \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \ud55c\ubc88\uc5d0 \uc804\ucc98\ub9ac\ud558\uae30 \uc704\ud574 \ub9ac\uc2a4\ud2b8\ud654\nfull_data = [train,test]\n\n# \uc774\ub984\uae38\uc774 \ubcc0\uc218 \uc0dd\uc131\ntrain['Name_length'] = train['Name'].apply(len) # Name \uceec\ub7fc\uc5d0 len \ud568\uc218 \uc801\uc6a9\ntest['Name_length'] = test['Name'].apply(len)\n\n# \uc2b9\uac1d\uc774 Cabin\uc774 \uc788\uc5c8\ub294\uc9c0 \uc720\ubb34 \ud655\uc778\ntrain['Has_Cabin'] = train['Cabin'].apply(lambda x: 0 if type(x) == float else 1 ) # Nan\uc758 \uacbd\uc6b0 type\uc774 float\uc774\uae30 \ub54c\ubb38\uc5d0 Cabin\uc774 \uc5c6\uc744\uc2dc 0 \ubd80\uc5ec\ntest['Has_Cabin'] = test['Cabin'].apply(lambda x: 0 if type(x) == float else 1)","322e03b9":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 #\uac00\uc871 \uc218 \uacc4\uc0b0, Parch\uc758 \uacbd\uc6b0 \ud568\uaed8 \ud0d1\uc2b9\ud55c \ubd80\ubaa8 \ub610\ub294 \uc790\ub140\uc218\uc9c0\ub9cc \ubcf8\uc778\uc744 \ud3ec\ud568\ud558\uc9c0 \uc54a\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 +1\uc744 \ud574\uc900\ub2e4\n\nfor dataset in full_data:\n    dataset['IsAlone'] = 0 \n    dataset.loc[dataset['FamilySize']==1,'IsAlone'] = 1 #IsAlone\uc774\ub77c\ub294 \ubcc0\uc218\ub97c Family Size\ub97c \ud1b5\ud574 \ub9cc\ub4e4\uc5b4 \uc900\ub2e4\n\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S') #Embarked \uc911 \uac00\uc7a5 \ub9ce\uc740 \ub370\uc774\ud130\uc778 S\ub85c \ube48\uac12 \ucc44\uc6cc\uc900\ub2e4\n\nfor dataset in full_data:\n    dataset['Fare'].fillna(train['Fare'].median(),inplace=True) # Fare\uc758 \ube48\uac12\uc740 \uc911\uc559\uac12\uc73c\ub85c \ucc44\uc6cc\uc900\ub2e4\n\n#train['CategoricalFare'] = pd.qcut(train['Fare'],4) #Fare\uc744 4\uac1c\uc758 \ub3d9\uc77c \uad6c\uac04\uc73c\ub85c \ub098\ub208\ub2e4\n\n# pd.cut\uc758 \uacbd\uc6b0 \ub3d9\uc77c \uae38\uc774\ub85c \ub098\ub204\uae30 \/ pd.qcut\uc758 \uacbd\uc6b0 \ub3d9\uc77c \uac2f\uc218\ub85c \ub098\ub204\uae30\n\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean() #\ud3c9\uade0\n    age_std = dataset['Age'].std() #\ud45c\uc900\ud3b8\ucc28\n    age_null_count = dataset['Age'].isnull().sum() #age \uc5f4\uc758 \ube48\uac12\uc758 \uac2f\uc218 \uce74\uc6b4\ud2b8\n    #age\uc5f4\uc5d0 \ube48\uac12\uc774 \ub9ce\uae30 \ub54c\ubb38\uc5d0 \ud3c9\uade0 - \ud45c\uc900\ud3b8\ucc28, \ud3c9\uade0+\ud45c\uc900\ud3b8\ucc28\uac12\uc73c\ub85c \uc0dd\uc131\ud55c \ub79c\ub364\uac12\uc744 \uc0dd\uc131\ud558\uc5ec \ucc44\uc6cc\uc900\ub2e4\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size = age_null_count)\n\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain['CategoricalAge'] = pd.cut(train['Age'],5) #Age\ub97c pd.cut\uc744 \uc774\uc6a9\ud558\uc5ec \uce74\ud14c\uace0\ub9ac\uceec \ub370\uc774\ud130\ub85c \ubcc0\ud658","644f4bb7":"def get_title(name):\n      title_search = re.search(' ([A-Za-z]+)\\.', name) #\uc815\uaddc\ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud574\uc11c Mr,Mrs\uc640 \uac19\uc740 \ud0c0\uc774\ud2c0 \ucd94\ucd9c\n      # \ud0c0\uc774\ud2c0\uc774 \uc874\uc7ac\ud55c\ub2e4\uba74 \uadf8 \ud0c0\uc774\ud2c0\uc744 \ucd94\ucd9c\ud558\uace0 \ub9ac\ud134 \uc2dc\ud0b4\n      if title_search:\n            return title_search.group(1)\n    \n      return \"\"\n\n# passenger\uc758 \uc774\ub984\uc5d0\uc11c \ud0c0\uc774\ud2c0\uc744 \ucd94\ucd9c\ud55c title\uc774\ub780 \uc0c8\ub85c\uc6b4 \ud53c\ucc98 \uc0dd\uc131\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\n#Title\uc744 \uadf8\ub8f9\ud654 \uc2dc\ud0b4(\ub4dc\ubb3c\uac8c \ubc1c\uc0dd\ud558\ub294 \ud0c0\uc774\ud2c0\uc740 Rare\ub85c \ub098\uba38\uc9c0\ub294 Miss\uc640 Mrs,Master\ub85c\ub9cc \uad6c\ubd84)\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace((['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare'))\n\n    dataset['Title'] = dataset['Title'].replace('Mlle','Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms','Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n# \uc131\uc744 \uc22b\uc790\ub85c \uce58\ud658 female\uc758 \uacbd\uc6b0 0\uc73c\ub85c male\uc758 \uacbd\uc6b0 1\ub85c\nfor dataset in full_data:\n    # Mapping Sex\n\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # \ud0c0\uc774\ud2c0\ub3c4 \uc22b\uc790\ub85c \uce58\ud658 Mr\ub294 1, Miss\ub294 2,Mrs\ub294 3, Master\ub294 4, Rare\ub294 5 \n    title_mapping = {'Mr':1, 'Miss': 2, 'Mrs':3, 'Master': 4, 'Rare': 5}\n\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n    # Embarked \uc218\uce58\ud654\n    dataset['Embarked'] = dataset['Embarked'].map( {'S' : 0, 'C': 1, 'Q': 2}).astype(int)\n\n    # Fare\ub3c4 \uc815\uc758\ud55c \uad6c\uac04\uc73c\ub85c \ub098\ub220 \uce74\ud14c\uace0\ub9ac\uceec \ub370\uc774\ud130\ub85c \ubcc0\ud658(4\uad6c\uac04)\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n   \n    # Age \uce74\ud14c\uace0\ub9ac\uceec \ub370\uc774\ud130\ub85c \ubcc0\ud658(5\uac1c)\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age']>16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2 \n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ","d456e011":"drop_elements = ['PassengerId','Name','Ticket','Cabin','SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge'],axis = 1)\ntest = test.drop(drop_elements, axis = 1)","f4a26ce3":"train['Title'] = train['Title'].astype('int')","f880a559":"train.head(3)","53e0a272":"train[\"Parch\"].value_counts()","8d8b4f41":"col_for_pearson = [\"Survived\", \"Sex\", \"Name_length\", \"FamilySize\", \"Has_Cabin\", \"Parch\"]\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y= 1.05, size = 15)\nsns.heatmap(train[col_for_pearson].corr(),linewidths=0.1,vmax=1.0,\n            square = True, cmap = colormap, linecolor='white',annot=True)","09ce6d15":"col_for_cramer = ['Survived', 'Sex', 'Pclass', 'Age', 'Fare', 'Embarked', 'Has_Cabin', 'IsAlone', 'Title']","8804201c":"def cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))","40bc1c72":"df_lst = []\n\nfor col1 in col_for_cramer:\n    for_df_lst = []\n    for col2 in col_for_cramer:\n        cramer = cramers_v(train[col1], train[col2])\n        for_df = pd.DataFrame(cramer, index = [col1], columns=[col2])\n        for_df_lst.append(for_df)\n    \n    cramer_df = pd.concat(for_df_lst, axis=1)\n    df_lst.append(cramer_df)","82876992":"cramer_df = pd.concat(df_lst)","b969213c":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Cramer\\'s V of Features', y= 1.05, size = 15)\nsns.heatmap(cramer_df,linewidths=0.1,vmax=1.0,\n            square = True, cmap = colormap, linecolor='white',annot=True)","e3bd330e":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.scatter(train, x= 'Fare',y= 'Age', color = 'Survived', size = 'Fare')\nfig.show()","cc979e2b":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.pie(train, names = 'Survived', title = 'Passenger Survival')\nfig.show()\n#\ub3c4\ub11b \ud50c\ub78f\uc744 \uadf8\ub9ac\uae30 \uc704\ud574\uc120 hole argument\uc5d0 float\uc744 \ub123\ub294\ub2e4","b67ff300":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig= px.pie(train, names = 'Survived', title = 'Passenger Survival',hole = 0.4)\nfig.show()","1fc4d462":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = go.Figure(data = [go.Pie(labels=train['Embarked'], pull =[.1,.15,0])])\nfig.show()","a7bce4d1":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = make_subplots(rows=1, cols=3, specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}, {\"type\": \"pie\"}]])\nfig.add_trace(\n            go.Pie(labels=train.loc[train['Embarked'] == 'C']['Survived'], pull = [.1, .1],\n                   title = 'Embarked C vs. Survived'), row=1, col=1)\n\nfig.add_trace(\n            go.Pie(labels=train.loc[train['Embarked'] == 'S']['Survived'], pull = [.07, .07],\n                   title = 'Embarked S vs. Survived'),row=1, col=2)\n\nfig.add_trace(\n            go.Pie(labels=train.loc[train['Embarked'] == 'Q']['Survived'], pull = [.1, .1],\n                   title = 'Embarked Q vs. Survived'), row=1, col=3)\n\n\nfig.update_layout(height=500, width=800, title_text=\"Gene Expression Features\")\nfig.show()","63f596f3":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.histogram(train, x='Age', nbins=30, marginal='box')\nfig.show()","344b174d":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.histogram(train, x='Age', nbins=50, histnorm='probability density')\nfig.show()","ab320084":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.box(train, x='Pclass', y=\"Age\")\nfig.show()","0346d8d1":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.box(train, x='Pclass', y=\"Age\", points=\"all\")\nfig.show()","7c2fd523":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\nfig = px.box(train, x='Pclass', y=\"Age\", notched=True, color=\"Survived\")\nfig.show()","1319f322":"test.drop([\"Title\", \"Fare\", \"Name_length\", \"FamilySize\"], axis = 1, inplace = True)\ntrain.drop([\"Title\", \"Fare\", \"Name_length\", \"FamilySize\"], axis = 1, inplace = True)","2347da74":"print(train.shape[0],test.shape[0])","31528dd2":"test.columns","38fa9502":"ntrain = train.shape[0] #\ud589 \uac2f\uc218\nntest = test.shape[0] \nSEED = 0\nNFOLDS = 5 #out-of-fold predictions\uc744 \uc704\ud574 folds \uc124\uc815\nkf = KFold(n_splits= NFOLDS, random_state=SEED, shuffle=True)","c138a78a":"class SklearnHelper(object): # class \uc0dd\uc131\n    def __init__(self, clf, seed = 0, params = None): #__init__=> \ucd08\uae30\ud654\ub97c \uc704\ud55c \ud568\uc218, \ub370\uc774\ud130\uc758 \ucd08\uae30\ub97c \uc2e4\uc2dc\ud558\ub294 \ud568\uc218\n        params['random_state'] = seed # \uc218\ud589\uc2dc\ub9c8\ub2e4 \ub3d9\uc77c\ud55c \uacb0\uacfc\ub97c \uc5bb\uae30 \uc704\ud574 \uc801\uc6a9\ud569\ub2c8\ub2e4.\n        self.clf = clf(**params) #parameter\ub97c \uba87\uac1c\uc77c\uc9c0 \ubaa8\ub974\uae30 \ub54c\ubb38\uc5d0 **params \uc124\uc815(?)\n  \n    def train(self, x_train,y_train):\n          self.clf.fit(x_train, y_train) #\ubaa8\ub378\uc744 train\uc5d0 \uc801\uc6a9\n  \n    def predict(self, x):\n          return self.clf.predict(x) #model\uc744 \ud1b5\ud574 test \uc608\uce21\n  \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n  \n    def feature_importances(self,x,y):\n        print(self.clf.fit(x,y).feature_importances_) #feature importance \ubcf4\uae30","41cdde85":"def get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,)) #train\uc758 \ud589\uc758 \uac2f\uc218\ub9cc\ud07c\uc758 0\uc0dd\uc131\n    oof_test = np.zeros((ntest,)) #test\uc758 \ud589\uc758 \uac2f\uc218\ub9cc\ud07c\uc758 0 \uc0dd\uc131\n    oof_test_skf = np.empty((NFOLDS,ntest)) #\n\n    for i, (train_index, test_index) in enumerate(kf.split(train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr,y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i,:] = clf.predict(x_test)\n    \n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1,1)","3a47d651":"#from sklearn.model_selection import train_test_split, GridSearchCV\n#from sklearn.metrics import accuracy_score","b0c2c218":"#rf_params = {\n#    'n_jobs': [-1],\n#    'n_estimators': [300,400,500],\n#    'warm_start': [True],  #True\ub85c \uc124\uc815\uc2dc \uc0ac\uc774\ud0b7\ub7f0\uc758 fit() \uba54\uc2a4\ub2e4\uac00 \ud638\ucd9c\ub420\ub54c \uae30\uc874\ud2b8\ub9ac\ub97c \uc720\uc9c0\ud558\uace0 \ud6c8\ub828\uc744 \ucd94\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 \uae30\ub2a5\n#    'max_depth' : [2,4,6],\n#    'min_samples_leaf' : [1,2,3,4],\n#    'max_features' : ['sqrt'], # sqaure root\n#    'verbose':[0]\n#}","54ca40dd":"#cross_valid_scores = {}","0b0b1ff9":"#model_random_forest = GridSearchCV(\n#    RandomForestClassifier(\n#    random_state=SEED,\n#    class_weight='balanced',\n#), \n#    rf_params, \n#    cv=5,\n#    scoring='accuracy',\n#)\n\n#model_random_forest.fit(x_train, y_train)\n\n#print('-----')\n#print(f'Best parameters {model_random_forest.best_params_}')\n#print(\n#    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n#    f'{model_random_forest.best_score_:.3f}'\n#)\n#cross_valid_scores['random_forest'] = model_random_forest.best_score_\n#print('-----')","a8c87ddc":"rf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n    'warm_start': True, #True\ub85c \uc124\uc815\uc2dc \uc0ac\uc774\ud0b7\ub7f0\uc758 fit() \uba54\uc2a4\ub2e4\uac00 \ud638\ucd9c\ub420\ub54c \uae30\uc874\ud2b8\ub9ac\ub97c \uc720\uc9c0\ud558\uace0 \ud6c8\ub828\uc744 \ucd94\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 \uae30\ub2a5\n    'max_depth' : 6,\n    'min_samples_leaf' : 4,\n    'max_features' : 'sqrt', # sqaure root\n    'verbose':0\n}\n\ncat_params = {\n    'iterations':1000,\n    'learning_rate':0.3,\n    'verbose':100    \n}","58b464b1":"rf = SklearnHelper(clf = RandomForestClassifier, seed= SEED, params=rf_params)\ncat = SklearnHelper(clf=CatBoostClassifier,seed=SEED,params=cat_params)","79fe3881":"y_train = train['Survived'].ravel() #\ub2e4\ucc28\uc6d0 \ubc30\uc5f4\uc744 1\ucc28\uc6d0 \ubc30\uc5f4\ub85c \ud3c9\ud3c9\ud558\uac8c \ud3b4\uc8fc\ub294 \ud558\uc218 -> \ubcf5\uc0ac\ubcf8\uc744 \uc0dd\uc131\ud558\uc9c0\uc54a\uae30 \ub54c\ubb38\uc5d0 ravel()\uc774 \ub9ac\ud134\ud55c \ubc30\uc5f4\uc744 \uc218\uc815\ud558\uba74 \uc6d0\ubcf8 \ubc30\uc5f4\ub3c4 \uc218\uc815\ub428\ntrain = train.drop(['Survived'],axis = 1)\nx_train = train.values\nx_test = test.values","f2c8962a":"rf_oof_train, rf_oof_test = get_oof(rf,x_train,y_train,x_test)\ncat_oof_train, cat_oof_test = get_oof(cat,x_train, y_train, x_test) # CatBoost Classifier\nprint(\"Training is complete\")","23318bb6":"rf_feature = rf.feature_importances(x_train,y_train)\ncat_feature = cat.feature_importances(x_train,y_train)","af03255d":"cat_feature = cat.feature_importances(x_train,y_train)","f7527a24":"rf_features = [0.17447914, 0.53011952, 0.07505842, 0.04552526, 0.05206962, 0.08728321, 0.03546483]\ncat_features = [17.53038179, 34.58138065, 16.2788412,   8.96514553, 10.85993632,  6.0965102,  5.68780431]","3f45a9c7":"cols = train.columns.values\nfeature_dataframe = pd.DataFrame( {'features': cols,\n  'Random Forest feature importances': rf_features,\n  'CatBoost feature importances':cat_features\n  })","0ec8e03b":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\ntrace = go.Scatter(\n    y = feature_dataframe['Random Forest feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode = 'markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n        color = feature_dataframe['Random Forest feature importances'].values,\n        colorscale = 'Portland',\n        showscale = True\n    ),\n    text = feature_dataframe['features'].values\n)\n\ndata = [trace]\n\nlayout = go.Layout(\n    autosize = True,\n    title = 'Ramdp, Fprest Feature Importance',\n    hovermode = 'closest', # \ud558\ub098\uc758 hoverlabel\uc774 hover distance\uc0c1\uc758 \uac00\uc7a5 \uac00\uae4c\uc6b4 \ud3ec\uc778\ud2b8\ub97c \ubcf4\uc5ec\uc900\ub2e4\n  yaxis = dict(\n      title = 'Feature Importance',\n      ticklen = 5,\n      gridwidth = 2\n    ),\n    showlegend = False\n)\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig,filename='scatter2010')\n\ntrace = go.Scatter(\n    y = feature_dataframe['CatBoost feature importances'].values,\n    x = feature_dataframe['features'].values,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = feature_dataframe['CatBoost feature importances'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = feature_dataframe['features'].values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'CatBoost feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')\n\n","2465d243":"feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\nfeature_dataframe.head(3)","3e89a033":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\ny = feature_dataframe['mean'].values\nx = feature_dataframe['features'].values\ndata = [go.Bar(\n            x= x,\n             y= y,\n            width = 0.5,\n            marker=dict(\n               color = feature_dataframe['mean'].values,\n            colorscale='Portland',\n            showscale=True,\n            reversescale = False\n            ),\n            opacity=0.6\n        )]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Barplots of Mean Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='bar-direct-labels')\n","7e39c6b5":"from eli5.sklearn import PermutationImportance\nimport eli5","847b00b9":"cb = CatBoostClassifier(iterations=1000,\n    learning_rate= 0.3,\n    verbose= 100,\n    random_state = SEED).fit(train,y_train)","57ae640e":"perm = PermutationImportance(cb, random_state = SEED).fit(train,y_train)","4e8e9c7a":"eli5.show_weights(perm, feature_names = train.columns.tolist())","566526cc":"base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n      'CatBoost': cat_oof_train.ravel()\n    })\nbase_predictions_train.head()","5f847071":"configure_plotly_browser_state()\npy.init_notebook_mode(connected=False)\n\ndata = [\n    go.Heatmap(\n        z= base_predictions_train.astype(float).corr().values ,\n        x=base_predictions_train.columns.values,\n        y= base_predictions_train.columns.values,\n          colorscale='Viridis',\n            showscale=True,\n            reversescale = True\n    )\n]\npy.iplot(data, filename='labelled-heatmap')","7a6e884a":"x_train = np.concatenate(( rf_oof_train, cat_oof_train), axis=1)\nx_test = np.concatenate(( rf_oof_test, cat_oof_test), axis=1)","f6e999a0":"cat = CatBoostClassifier(\n    learning_rate = 0.02,\n    iterations= 2000,\n     max_depth= 4,verbose=100).fit(x_train, y_train)\npredictions = cat.predict(x_test)","73176822":"StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n                            'Survived': predictions })\nStackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)","a0589756":"#### Interactive feature importances via Plotly scatterplots","f79b3ab6":"### Out-of-Fold Predictions","5efaf75c":"2\ubc88\uc9f8 \uc608\uce21\uc744 \uc704\ud574\uc11c \uc0c8\ub85c\uc6b4 feauters\ub97c \ub9cc\ub4e4\uc5b4 \uc801\uc6a9\uc2dc\ud0a4\ub294 \uacfc\uc815.","d0fe135d":"### Second-Level Predictions from the First-level Output","34133297":"\uccab\ubc88\uc9f8 \ub808\ubca8\uc758 \ubca0\uc774\uc2a4 \ubaa8\ub378\uc744 \uc900\ube44\ud558\uc600\uae30 \ub54c\ubb38\uc5d0 training\uacfc test data\ub97c \uc6d0 \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0\uc11c numpy arry\ub97c \uc0dd\uc131\ud558\uc5ec classifier\uc5d0 \uc801\uc6a9\uc2dc\ud0ac \uc900\ube44\ub97c \ud55c\ub2e4.","bfe239cf":"##### Permutation Importance","216218ee":"## Visualizations(coreelations)\n- \ubc94\uc8fc\ud615 \ubcc0\uc218\n    - Survived(\uc0dd\uc874\uc5ec\ubd80), Pclass(\ud2f0\ucf13 \ub4f1\uae09), Sex(\uc131\ubcc4), Age(\ub098\uc774 \uadf8\ub8f9),\n    Fare(\uc694\uae08), Embarked(\ud0d1\uc2b9 \ud56d\uad6c), Has_Cabin(\uac1d\uc2e4 \uc5ec\ubd80), IsAlone(\ud63c\uc790 \ud0d1\uc2b9 \uc5ec\ubd80), Title(\ud638\uce6d)\n    \n    \n- \uc5f0\uc18d\ud615 \ubcc0\uc218\n    - Name_length(\uc774\ub984 \uae38\uc774), FamilySize(\uac00\uc871 \uc218), Parch(\ud568\uaed8 \ud0d1\uc2b9\ud55c \ubd80\ubaa8, \uc544\uc774\uc758 \uc218)","dd033e23":"## Feature Exploration, Engineering and Cleaning","9de8baf5":"### Cramer's V Heatmap(\ud788\ud2b8\ub9f5\uc744 \ud1b5\ud574 \ud06c\ub808\uc774\uba38 V \uacc4\uc218 \ubcf4\uae30)","a67d5621":"#### Parameters <br\/>\n**n_jobs**: cpu \ucf54\uc5b4\ub97c \uba87\uac1c\ub85c \ud65c\uc6a9\ud560\uc9c0 \uc120\ud0dd <br\/>\n**n_estimators**: : \uc0ac\uc6a9\ud560 tree \uc218 <br\/>\n**max_depth**: \ud2b8\ub9ac\uc758 \uae4a\uc774 \uc81c\ud55c <br\/>\n**verbose**: \uc0c1\uc138\ud55c \ub85c\uae45\uc744 \ucd9c\ub825\ud560\uc9c0 \ub9d0\uc9c0\ub97c \uc870\uc815\ud558\ub294 parameter\n","8cb68318":"#### Output of the First level Predictions","660692f6":"Below code is function to display plotly visualization.  \n\nThis function must be run simultaneously with plotly code to display the visualization.  ","d55243bd":"## Concept of this notebook\nThere is no correct answer when dealing with data, but I think an accurate method is needed for statistical verification. Pearson's correlation analysis is used to determine the correlation of variables through correlation analysis in the actual EDA process, but an appropriate correlation analysis is required for each characteristic of the variables.\n\nSo, the purpose of this notebook is to find correlation coefficients according to variables and use them for EDA.\n\nTitanic datasets have continuous and discrete variables. For the degree of correlation of continuous variables, the degree of correlation can be checked with Pearson's coefficient, and for discontinuous fractions, the degree of correlation can be checked with the Cram\u00e9r\u2019s V coefficient.\n\n- continuous variable\n    - Peasron's Correlation \n        - continuous variables and discrete vraibles(There are two categories. (0, 1))\n        \n- discrete variable\n    - Cram\u00e9r\u2019s V\n        - discrete variables(There are more than 3 categories)\n        \nOf course, it is also necessary to check the significance level after checking the correlation coefficient.\nDiscrete variables use chi-square verification.\n\ncorrelations : [https:\/\/www.notion.so\/2d1f82f31f604af594273e6ee57d9df7]  \nCram\u00e9r\u2019s V reference : [https:\/\/towardsdatascience.com\/the-search-for-categorical-correlation-a1cf7f1888c9]","d4b4d37d":"#### Second level learning model CatBoost","633d4e58":"Kaggle: [https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python]\n\n\uc774\uc720\ud55c_\uce90\uae00\ud544\uc0ac: [https:\/\/kaggle-kr.tistory.com\/32]","d68042e4":"#### Creaating Numpy arrays out of our train and test sets","bcabc135":"\ucd9c\ucc98:[https:\/\/blog.naver.com\/wjsduwls703\/222164661392]<br\/>\n**Random Forest**: Decision Tree \uc54c\uace0\ub9ac\uc998\uc744 \ud65c\uc6a9\ud55c bagging \uae30\ubc95\uc758 \uc559\uc0c1\ube14 \ubaa8\ub378\ub85c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec\uac1c\uc758 decision tree\ub97c \uc0dd\uc131 \ud6c4 \ucd5c\uc885 \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc774\ub2e4. Decision tree\ub294 \uc785\ub825 \ubcc0\uc218\ub4e4\uc5d0 \ub530\ub77c \ubcc0\uc218\uc758 \uac12\uc744 \uc608\uce21\ud558\ub294 \ubaa8\ub378\uc778\ub370 \ub79c\ub364\ud3ec\ub808\uc2a4\ud2b8\ub294 \uc774 decision Tree\ub97c \ub2e4\uc218 \uc0dd\uc131\ud558\uc5ec \uc9d1\ub2e8 \ud559\uc2b5\uc2dc\ucf1c \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud55c\ub2e4.\n","6eebee5f":"#### Producing the Submission file","c5eb0ab0":"### \uccab\ubc88\uc9f8 \ub808\ubca8\uc758 \ubca0\uc774\uc2a4 \ubaa8\ub378 \uc0dd\uc131","b10d6ebe":"#### Feature importances generated from the different classifiers","58f1735f":"##### K Fold\ub780?\n![\ub2e4\uc6b4\ub85c\ub4dc (1)](https:\/\/user-images.githubusercontent.com\/57039464\/136370223-25fe8580-d727-44a2-873b-4677fe2d8bd5.png)\n\ubaa8\ub378\uc758 \uc624\ubc84\ud53c\ud305\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud55c \ubc29\uc2dd\uc73c\ub85c \ud3f4\ub4dc\ub97c \uc124\uc815\ud6c4 (\uc704 \uc774\ubbf8\uc9c0\uc758 \uacbd\uc6b0\ub294 4\ubc88)\n\uac01 \uad50\ucc28\uac80\uc99d \ub370\uc774\ud130\ub85c \ub9cc\ub4e4\uc5b4\ub0b8 \ubaa8\ub378\ub4e4\ub85c \uc608\uce21\uc744 \ud55c \ud6c4 \uadf8 \uc608\uce21\uac12\ub4e4\uc758 \ud3c9\uade0\uc73c\ub85c \ucd5c\uc885 \uc608\uce21\uac12\uc744 \ub3c4\ucd9c\ud55c\ub2e4\n","77ca1cd4":"### Ensembling & Stacking models","dba76bc2":"\uccab\ubc88\uc9f8 \ub808\ubca8 \ud504\ub9ac\ub515\uc158\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud574 \uc0dd\uc131\ud588\ub358 5\uac1c\uc758 base classifiers\ub97c Out-of-Fold prediction function\uc5d0 \uc9d1\uc5b4 \ub123\ub294\ub2e4.","16b4e5f4":"\ucd9c\ucc98: [https:\/\/wooono.tistory.com\/102]\n\n#### **\ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd**:\n\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uae30 \uc704\ud574 \uc0ac\uc804 \uc124\uc815\ud574\uc57c \ud558\ub294 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uc758 \ucd5c\uc801\uac12\uc744 \ud0d0\uc0c9\ud558\ub294 \ubc29\ubc95 <br\/>\n**1. Manual Search**: \uc9c1\uad00 \ub610\ub294 \ub300\uc911\uc801\uc73c\ub85c \uc798 \uc54c\ub824\uc9c4 \ubc29\uc2dd\uc73c\ub85c \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c \uc124\uc815\ud558\uace0 \uc774\ub4e4\uc744 \ud65c\uc6a9\ud558\uc5ec \ud559\uc2b5\uc744 \uc218\ud589\ud55c \ud6c4 \uac80\uc99d \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud558\uc5ec \uce21\uc815\ud55c \uc131\ub2a5 \uacb0\uacfc\ub97c \uae30\ub85d. \uc774\uc640 \uac19\uc774 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c \uc9c1\uc811 \ud0d0\uc0c9\ud558\ub294 \ubc29\uc2dd\n\n**2. Grid Search**: \ud0d0\uc0c9 \ub300\uc0c1\uc774 \ub418\ub294 \ud2b9\uc815 \uad6c\uac04 \ub0b4\uc758 \ud6c4\ubcf4 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \uc77c\uc815\ud55c \uac04\uaca9\uc744 \ub450\uace0 \uc120\uc815 \ud6c4 \uac01 \uacb0\uacfc\ub97c \uae30\ub85d \ud6c4 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc778 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \uc120\uc815\n\n**3. Random Search**: Grid Search\uc640 \ud070 \ud2c0\uc740 \uc720\uc0ac\ud558\ub098 \ud0d0\uc0c9 \ub300\uac15 \uad6c\uac04 \ub0b4\uc758 \ud6c4\ubcf4 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \uac12\ub4e4\uc744 \ub79c\ub364 \uc0d8\ud50c\ub9c1\uc744 \ud1b5\ud574 \uc120\uc815\ud55c\ub2e4. \ubaa8\ub4e0 grid\ub97c \uc804\ubd80 \ucc3e\ub294 \ub300\uc2e0 random\ud558\uae30 \uc77c\ubd80 parameter\ub4e4\ub9cc \uad00\uce21\ud55c \ud6c4 \uadf8 \uc911\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 parameter\ub97c \uace0\ub978\ub2e4.\n\n**4. Bayesian Optimization**: \uc5b4\ub290 \uc785\ub825\uac12(x)\ub97c \ubc1b\ub294 \ubbf8\uc9c0\uc758 \ubaa9\uc801 \ud568\uc218(f(x))\ub97c \uc0c1\uc815 \ud6c4 \ud568\uc22b\uac12(f(x))\uc744 \ucd5c\ub300\ub85c \ub9cc\ub4dc\ub294 \ucd5c\uc801\ud574\ub97c \ucc3e\ub294 \uac83\uc744 \ubaa9\uc801\uc73c\ub85c \ud568<br\/>\n  - \ubaa9\uc801 \ud56b\ubb34\uc640 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \uc30d\uc744 \ub300\uc0c1\uc73c\ub85c Surrogate Model\uc744 \ub9cc\ub4e0 \ud6c4\n  - \uc21c\ucc28\uc801\uc73c\ub85c \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c \uc5c5\ub370\uc774\ud2b8\ud574 \uac00\uba74\uc11c \ud3c9\uac00\ub97c \ud1b5\ud574 \ucd5c\uc801\uc758 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \uc870\ud569\uc744 \ud0d0\uc0c9\n  - \ubaa9\uc810 \ud568\uc218\ub97c black-box function \uc774\ub77c\uace0 \ud55c\ub2e4.","511a0915":"\ucd9c\ucc98:[https:\/\/blog.naver.com\/sjy5448\/222480078727] <br\/>\n**\uc559\uc0c1\ube14 \ud559\uc2b5**: \uc5ec\ub7ec\uac1c\uc758 \ubaa8\ub378\uc744 \ud1b5\ud574 \uc5bb\uc740 \uc608\uce21\uac12\uc744 \uacb0\ud569\ud558\uc5ec \ubcf4\ub2e4 \uc815\ud655\ud55c \ucd5c\uc885 \uc608\uce21\uc744 \ub3c4\ucd9c\ud558\ub294 \uae30\ubc95 <br\/>\n**\uc559\uc0c1\ube14 \ud559\uc2b5 \uc720\ud615**: \ubcf4\ud305,\ubc30\uae45,\ubd80\uc2a4\ud305 <br\/>\n- \ubcf4\ud305: \ub2e4\ub978 \uc54c\uace0\ub9ac\uc998\uc758 \ubaa8\ub378\ub4e4\uc774 \ud22c\ud45c\ub97c \ud1b5\ud574 \uc608\uce21 \ubc29\uc2dd \uacb0\uc815\n- \ubc30\uae45: \uac01\uac01\uc758 \ubaa8\ub378\ub4e4\uc774 \ub3d9\uc77c\ud55c \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud558\uc9c0\ub9cc \ub370\uc774\ud130 \uc0d8\ud50c\ub9c1\uc744 \ub2e4\ub974\uac8c \ud558\uba74\uc11c \ud559\uc2b5\uc744 \ud1b5\ud574 \ub3d9\uc77c\ud558\uac8c \ud22c\ud45c\ub97c \ud1b5\ud574 \uc608\uce21 \ubc29\uc2dd \uacb0\uc815 <br\/>\n     - \uad50\ucc28\uac80\uc99d\uacfc\ub294 \ub2e4\ub974\uac8c \ub370\uc774\ud130 \uc138\ud2b8 \uac04\uc5d0 \uc911\ucca9 \ud5c8\uc6a9\n     - \ubd80\ud2b8\uc2a4\ud2b8\ub798\ud551: \uac1c\ubcc4 \ubaa8\ub378\uc5d0\uac8c \ub370\uc774\ud130\ub97c \uc77c\ubd80 \uc911\ucca9\ub418\uac8c \uc0d8\ud50c\ub9c1\ud574\uc11c \ucd94\ucd9c\ud558\ub294 \ubc29\uc2dd\n     - \uac1c\ubcc4 \ubaa8\ub378\uc774 \ubd80\ud2b8\uc2a4\ud2b8\ub798\ud551 \ubc29\uc2dd\uc73c\ub85c \uc0d8\ud50c\ub9c1\ub41c \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud574\uc11c \ud559\uc2b5\uc744 \ud1b5\ud574 \uac1c\ubcc4\uc801\uc778 \uc608\uce21\uc744 \uc218\ud589\ud55c \uacb0\uacfc\ub97c \ubcf4\ud305 \ubc29\uc2dd\uc744 \ud1b5\ud574 \uc608\uce21 \uacb0\uacfc\ub97c \uc120\uc815 \n- \ubd80\uc2a4\ud305: \uc5ec\ub7ec\uac1c\uc758 \ubaa8\ub378\uc744 \uc21c\ucc28\uc801\uc73c\ub85c \ud559\uc2b5\ud558\uc9c0\ub9cc \uc55e \uc21c\uc11c\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uc608\uce21\uc774 \ud2c0\ub9b0 \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c\ub294 \uc62c\ubc14\ub978 \uc608\uce21\uc744 \ud560 \uc218 \uc788\ub3c4\ub85d \ub2e4\uc74c \ubaa8\ub378\uc5d0 \uac00\uc911\uce58\ub97c \ubd80\uc5ec\ud558\uba74\uc11c \ud559\uc2b5\uacfc \uc608\uce21\uc744 \uc9c4\ud589\ud558\ub294 \ubc29\uc2dd\n    - \ub300\ud45c\uc801\uc73c\ub85c \uadf8\ub798\ub514\uc5b8\ud2b8 \ubd80\uc2a4\ud2b8,XGBoost(eXtra Gradient Boost), LightGBM(Light Gradient Boost)\uac00 \uc788\ub2e4. ","8e380514":"#### First-level ouput as new features","9fdde793":"- \ub300\uccb4\ub85c \uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc9c0 \uc54a\uc73c\ub098 Family Size\uc640 Parch\ub294 \uc0c1\uad00\uad00\uacc4\uac00 \ub192\ub2e4(Parch\ub85c Family Size\ub97c \ub9cc\ub4e0\uac70\uae30 \ub54c\ubb38),\n- Survived, Sex\ub294 \uc0c1\uad00\uad00\uacc4\uac00 \ub192\ub2e4(\uc989, \uc5ec\uc131\uc758 \uc0dd\uc874\uac00\ub2a5\uc131\uc774 \ub192\ub2e4.)","da51e3a1":"1. Random Forest Classifier\n2. CatBoost Boosting classifier","cabd3fc2":"feature importance\uc744 \ubcf4\uae30 \uc704\ud574 plotly\uc758 scatter plot\uc744 \ud65c\uc6a9\ud55c\ub4dc","c5feb272":"\uce90\uae00\uc5d0\uc11c \uc11c\ub85c \uc0c1\uad00\uad00\uacc4\uac00 \uc801\uc740 \ubaa8\ub378\ub4e4\ub07c\ub9ac \ud568\uaed8 train\uc744 \uc2dc\ud0a4\uba74 \ub354 \uacb0\uacfc\uac00 \uc798 \ub098\uc624\ub294 \uba87\uba87\uc758 \ucf00\uc774\uc2a4\ub4e4\uc774 \uc788\uc5b4 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589","ec443d2a":"#### Correlation Heatmap of the Second Level Training set\n\n","5c5b8ec0":"\ucd9c\ucc98:[https:\/\/pro-jy.tistory.com\/25] <br\/>\n**Adaboost**: Adaptive + Boosting\ub85c \ub9cc\ub4e4\uc5b4\uc9c4 \ub2e8\uc5b4. \uc57d\ud55c \ubd84\ub958\uae30(weak classifier)\ub4e4\uc774 \uc0c1\ud638\ubcf4\uc644 \ud558\ub3c4\ub85d \uc21c\ucc28\uc801\uc73c\ub85c \ud559\uc2b5\ud558\uace0, \uc774\ub4e4\uc744 \uc870\ud569\ud558\uc5ec \ucd5c\uc885\uc801\uc73c\ub85c \uac15\ud55c \ubd84\ub958\uae30\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83 <br\/>\n\uc57d\ud55c \ubd84\ub958\uae30\ub4e4\uc740 \ud55c\ubc88\uc5d0 \ud558\ub098\uc529 \uc21c\ucc28\uc801\uc73c\ub85c \ud559\uc2b5\uc744 \uc9c4\ud589\uc2dc \uba3c\uc800 \ud559\uc2b5\ub41c \ubd84\ub958\uae30\ub294 \uc81c\ub300\ub85c \ubd84\ub958\ub97c \ud574\ub0b4\ub294 \ub370\uc774\ud130\uc640 \uc81c\ub300\ub85c \ubd84\ub958\ud574\ub0b4\uc9c0 \ubabb\ud558\ub294 \ub370\uc774\ud130\ub4e4\uc774 \ubc1c\uc0dd\ud558\uac8c\ub41c\ub2e4. \uc774 \uc815\ubcf4\ub4e4\uc744 \ubd84\ub958\ud558\uc5ec \ub2e4\uc74c \ubd84\ub958\uae30\ub294 \uc798 \ubd84\ub958\ud558\uc9c0 \ubabb\ud55c \ub370\uc774\ud130\ub4e4\uc758 \uac00\uc911\uce58\ub97c \ub192\uc778\ub2e4.\uc774\uc804 \ubd84\ub958\uae30\uac00 \uc798\ubabb \ubd84\ub958\ud55c \uc0d8\ud50c\uc758 \uac00\uc911\uce58\ub97c adaptive\ud558\uac8c \ubc14\uafd4\uac00\uba70 \uc798 \ubabb \ubd84\ub958\ub418\ub294 \ub370\uc774\ud130\uc5d0 \ub354 \uc9d1\uc911\ud558\uc5ec \ud559\uc2b5\ud558\uac8c \ub41c\ub2e4. \n\n\ucd9c\ucc98:[https:\/\/bkshin.tistory.com\/entry\/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-14-AdaBoost?category=1057680] <br\/>\n![stump](https:\/\/user-images.githubusercontent.com\/57039464\/135722654-e8b2c19b-6150-4d2e-8a25-7abacb31653a.png) <br\/>\n\n\uc57d\ud55c \ubd84\ub958\uae30\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \uc704\ud574 Adaboost\ub294 \uc704\uc640 \uac19\uc774 \ud558\ub098\uc5d0 \ub450\uac1c\uc758 \ub9ac\ud504\ub97c \uc9c0\ub2cc stump\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ud2b8\ub9ac\uc640 \ub2e4\ub974\uac8c stump\ub294 \uc815\ud655\ud55c \ubd84\ub958\ub97c \ud558\uc9c0 \ubabb\ud558\ub294\ub370 \uadf8 \uc774\uc720\ub294 \uc5ec\ub7ec \uc9c8\ubb38\uc744 \ud1b5\ud574 \ub370\uc774\ud130\ub97c \ubd84\ub958\ud558\ub294 \ud2b8\ub9ac\uc640 \ub2e4\ub974\uac8c, stump\ub294 \ub2e8 \ud558\ub098\uc758 \uc9c8\ubb38\uc73c\ub85c \ub370\uc774\ud130\ub97c \ubd84\ub958\ud574\uc57c\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c stump\ub294 \uc57d\ud55c \ud559\uc2b5\uae30(weak learner)\uc785\ub2c8\ub2e4.\n<br\/>\n\n**Gradient Boost**: Gradient Boost\ub294 stump\ub098 tree\uac00 \uc544\ub2cc \ud558\ub098\uc758 leaf (single leaf) \ubd80\ud130 \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc774 leaf\ub294 \ud0c0\uac8c\uac12\uc5d0 \ub300\ud55c \ucd08\uae30 \ucd94\uc815\uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucd08\uae30 \ucd94\uc815\uac12\uc744 \uc815\ud55c \ud6c4 \uadf8 \ud6c4\uc5d0\ub294 AdaBoost\uc640 \ub3d9\uc77c\ud558\uac8c \uc774\uc804 tree\uc758 error\ub294 \ub2e4\uc74c tree\uc5d0 \uc601\ud5a5\uc744 \uc90d\ub2c8\ub2e4. Adaboost\uc640 \ub2e4\ub974\uac8c stump\uac00 \uc544\ub2cc tree\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc73c\uba70 \ubcf4\ud1b5\uc740 leaf\uac00 8\uac1c~32\uac1c\ub418\ub294 tree\ub85c \uad6c\uc131\ud569\ub2c8\ub2e4.\n\n**ExtraTrees Classifier**: https:\/\/wyatt37.tistory.com\/6","6600ab13":"- \uac15\ud55c \uc0c1\uad00(0.8 ~ 1)\n    - Sex & Title : Title(\ud638\uce6d)\uc740 \uc131\ubcc4\uc5d0 \ub530\ub77c \ub2e4\ub974\ubbc0\ub85c \uc0c1\uad00\uc774 \ub192\ub2e4. (\ub458 \uc911 \ud558\ub098 \uc81c\uac70 \ud574\ub3c4 \ub420\ub4ef?)\n    - Pclass & Has_Cabin : Pclass(\uac1d\uc2e4\ub4f1\uae09)\uc5d0 \ub530\ub77c \uac1d\uc2e4 \uc5ec\ubd80\uc758 \uc0c1\uad00\uc774 \ub192\uc74c. (\ub458 \uc911 \ud558\ub098 \uc81c\uac70 \ud574\ub3c4 \ub420\ub4ef?)\n    \n    \n- \uc0c1\uad00(0.4 ~ 0.6)\n    - Sex & Survived : \ud53c\uc5b4\uc2a8\uc758 \uc0c1\uad00\uacc4\uc218\ub791 \uac19\uc74c\n    - Title & Survived : \ud53c\uc5b4\uc2a8\uc758 \uc0c1\uad00\uacc4\uc218\ub791 \uac19\uc74c\n    - Pclass & Fare : \uac1d\uc2e4 \ub4f1\uae09\uacfc \uc694\uae08\n    - Fare & Has_Cabin : \uc694\uae08\uacfc \uac1d\uc2e4 \uc5ec\ubd80\n    - Fare & IsAlone : \uc694\uae08\uacfc \ud63c\uc790 \uc5ec\ubd80\n    \n- \ubcc0\uc218 \uc120\ud0dd\n    - Title \uc81c\uac70 : Sex\uc640\uc758 \uc0c1\uad00\uc774 \ub192\uace0 \ud578\ub4e4\ub9c1 \uc694\uc18c\uac00 \ub9ce\uc740 title\uc81c\uac70\n    - Fare \uc81c\uac70 : Pclass, Has_Cabin, IsAlone\uc640 \uacf5\ud1b5\uc801\uc73c\ub85c \uc0c1\uad00\uc774 \ub192\uc544 \uc81c\uac70\n    - Name_length : Title\uc5d0\uc11c \ud30c\uc0dd \ubc0f \ud578\ub4e4\ub9c1 \uc694\uc18c\uc640 \ubaa8\ub378\ub9c1 catboost\ub97c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc5f0\uc18d\ud615 \ubcc0\uc218 \uc81c\uac70\n    - FamilySize : Name_length\uc640 \uac19\uc740 \uc774\uc720\ub85c \uc81c\uac70","a45c7552":"#### Plotly Barplot of Average Feature Importances","2693da82":"#### Pairplots","352bffdb":"### Pearson Correlation Heatmap(\ud788\ud2b8\ub9f5\uc744 \ud1b5\ud574 \ud53c\uc5b4\uc2a8 \uc0c1\uad00\uacc4\uc218 \ubcf4\uae30)"}}