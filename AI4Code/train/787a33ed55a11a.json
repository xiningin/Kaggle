{"cell_type":{"8f3e0e38":"code","98072a38":"code","e694e456":"code","0ee6226a":"code","a26c175f":"code","f62fd956":"code","1c0017dd":"code","0a1bd2b4":"code","4ffeec42":"code","001a996c":"code","61caaba8":"code","d1aae72d":"code","b4a0565b":"code","0982fa48":"code","6147ba06":"code","54f43408":"code","a017694d":"code","ec884f0b":"code","ed7f9575":"markdown","f2bb312a":"markdown","2ac310d2":"markdown","cf28a3f3":"markdown","ecf91330":"markdown","c20cfac8":"markdown","4bbc967a":"markdown","02f51045":"markdown","d1b7e52a":"markdown","ec691c26":"markdown","1c62e9b2":"markdown","482c5576":"markdown","e3d51022":"markdown","caedd261":"markdown","2a848828":"markdown","12b8b239":"markdown","88517820":"markdown"},"source":{"8f3e0e38":"import numpy as np\nfrom tensorflow.keras.datasets.mnist import load_data\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import BatchNormalization\nfrom matplotlib import pyplot\nimport time\nimport os\nfrom IPython.display import display, clear_output","98072a38":"def define_discriminator(in_shape=(28,28,1)):\n    model = Sequential()\n    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","e694e456":"model = define_discriminator()\nmodel.summary()","0ee6226a":"def define_generator(input_dim):\n    model = Sequential()\n    \n    # foundation for 7x7 image\n    n_nodes = 128 * 7 * 7\n    model.add(Dense(n_nodes, input_dim=input_dim))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((7, 7, 128)))\n    model.add(Dropout(0.2))\n    \n    # upsample to 14x14\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.2))\n    \n    # upsample to 28x28\n    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n    return model","a26c175f":"noise_dim = 100\ng_model = define_generator(noise_dim)\ng_model.summary()","f62fd956":"# use for generate random noise to generate random image\ndef generate_noise(noise_dim, n_samples):\n    x_input = np.random.randn(noise_dim * n_samples) # generate random noise \n    x_input = x_input.reshape(n_samples, noise_dim)\n    return x_input","1c0017dd":"def generate_fake_samples(noise_dim, n_samples):\n  x_input = generate_noise(noise_dim, n_samples) # generate by random noise\n  X = g_model.predict(x_input) # generate image from our model\n  y = np.zeros((n_samples, 1)) # mark label to 'fake' as 0\n  return X, y","0a1bd2b4":"fig = pyplot.figure(figsize=(12, 12))\nn_samples = 25\nX, _ = generate_fake_samples(100, n_samples)\nfor i in range(n_samples):\n    pyplot.subplot(5, 5, 1 + i)\n    pyplot.axis('off')\n    pyplot.imshow(X[i, :, :, 0])\n    pyplot.draw()","4ffeec42":"def load_real_samples():\n    (trainX, _), (_, _) = load_data() # load mnist dataset\n    X = np.expand_dims(trainX, axis=-1) # add gray scale channel to image\n    X = X.astype('float32') # convert pixel from ints to floats\n    X = X \/ 255.0 # pixel to between\n    return X","001a996c":"def get_real_samples(dataset, idx):\n    n_sample = len(idx)\n    X = dataset[idx]\n    y = np.ones((n_sample, 1)) # mark label to 'real' as 1 \n    return X, y","61caaba8":"def define_gan(g_model, d_model):\n    d_model.trainable = False # don't want to update the decriminator model\n  \n    # connects discriminator and generator\n    model = Sequential()\n    model.add(g_model)\n    model.add(d_model)\n  \n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n    return model","d1aae72d":"noise_dim = 100\nd_model = define_discriminator()\ng_model = define_generator(noise_dim)\ngan_model = define_gan(g_model, d_model)\ngan_model.summary()","b4a0565b":"d_history = []","0982fa48":"def train_gan(dataset, noise_dim, epochs, batch_size):\n    steps = int(dataset.shape[0] \/ batch_size)\n    half_batch = int(batch_size \/ 2)\n\n    # generate plot slot for real time plot\n    fig = pyplot.figure(figsize=(12, 12))\n    axs = []\n    for i in range(25):\n        axs.append(pyplot.subplot(5, 5, 1 + i))\n\n    for epoch in range(epochs):\n        for step in range(steps):\n            # train our discriminator base from our generator result\n            sample_idx = range(step, step+half_batch)\n            X_real, y_real = get_real_samples(dataset, sample_idx)\n            X_fake, y_fake = generate_fake_samples(noise_dim, half_batch)\n            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n            d_loss, _ = d_model.train_on_batch(X, y)\n\n            # train our GAN to improve our generator\n            x_gan = generate_noise(noise_dim, batch_size)\n            y_gan = np.ones((batch_size, 1))\n            gan_model.train_on_batch(x_gan, y_gan)\n        if epoch % 100 == 0: # evaluate every 100 epochs\n            # evaluate model test only with 100 output\n            evaluate_sample_idx = np.random.randint(0, dataset.shape[0], 50)\n            X_real_test, y_real_test = get_real_samples(dataset, evaluate_sample_idx)\n            x_fake_test, y_fake_test = generate_fake_samples(noise_dim, 50)\n            x_test, y_test = np.vstack((X_real_test, x_fake_test)), np.vstack((y_real_test, y_fake_test))\n            _, acc = d_model.evaluate(x_fake_test, y_fake_test, verbose=0)\n            d_history.append([acc, epoch])\n\n            fig.suptitle('Discriminal Accuracy: {} at epoch {}'.format(acc, epoch), fontsize=16) # display accuracy and epoch on title\n\n            # plot result in real time\n            for i in range(25):\n              ax = axs[i]\n              ax.cla()\n              ax.axis('off')\n              ax.imshow(x_fake_test[i, :, :, 0])\n            fig.savefig(\"result_at_epoch_{}.png\".format(epoch))\n            display(fig)\n            clear_output(wait = True) \n\n  ","6147ba06":"dataset = load_real_samples()\ntrain_gan(dataset, noise_dim, epochs=1500, batch_size=256)","54f43408":"g_model.save(\"model.h5\")","a017694d":"d_history = np.array(d_history)\npyplot.figure(figsize=(12, 6))\npyplot.plot(d_history[:, 1], d_history[:, 0]) # plot history accuracy\npyplot.show()","ec884f0b":"x_fake, _ = generate_fake_samples(noise_dim, 25)\nfig = pyplot.figure(figsize=(12, 12))\nfor i in range(25):\n    pyplot.subplot(5, 5, 1 + i)\n    pyplot.axis('off')\n    pyplot.imshow(x_fake[i, :, :, 0])","ed7f9575":"The result is not look good yet as our generator is not well trained yet","f2bb312a":"# See our descrimator performances","2ac310d2":"### Get real sample by index","cf28a3f3":"# Try on GAN\n\nThis notebook is my first try on GAN. We wil use MNIST data to train our GAN. At the end we will use the result to generate the random digit images. \n\n\nAssume that you already read: \n* [Get Start Image Classification](https:\/\/www.kaggle.com\/uysimty\/get-start-image-classification)\n* [Understand Image Classification](https:\/\/www.kaggle.com\/uysimty\/keras-cnn-dog-or-cat-classification)\n\nThese Kernels let's you understand CNN.\n\n    ","ecf91330":"What we are doing here are:\n* We get the image from dataset and generate the fake images to train our discriminator.\n* The discriminator will predict the generator output in probability between 0.0 and 1.0.\n* While training the GAN we label all the generation from our generator to be real (1).\n* The discriminator can calculate the errors and improve the generator model.\n* Every 100 epochs we will push the accuracy to `d_history` to virtualize it later","c20cfac8":"Save our generator","4bbc967a":"# Create GAN Model\n\n* GAN model is created from combined of generator model and discriminal model.\n* The generator responsible for generate fake image.\n* And dicriminator responible to evaluate the output of the generator by doing binary classication how look real is it for the output image. \n* From the prediction of discriminator, GAN will get the errors to update the weight of generator to improve the generator model. \n* The weights in the generator model are updated based on the performance of the discriminator model.","02f51045":"# Plot the final result","d1b7e52a":"### Load samples","ec691c26":"# Require library","1c62e9b2":"# Discriminator Model\n\nThe model to prodict that image is fake or real. It will take image as input and predict whether it is real or fake. \n\nThe discriminator model \n* Has two convolutional layers with 64 filters each, \n* A small kernel size of 3, and larger than normal stride of 2.\n* Has no pooling layers and a single node in the output layer with the sigmoid activation function to predict whether the input sample is real or fake. \n* Is trained to minimize the binary cross entropy loss function, appropriate for binary classification.","482c5576":"# Generator Model\n\u200b\nGenerator model is reponsible for generate our fake image with machine learning algorithm (not randomly).\nIt will take random noise as input and generate image output. \n\u200b\nSo we going to rake 100 random element and generate it to output image with 28x28 = 784 pixels\n\u200b\n* The first is a Dense layer as the first hidden layer that has enough nodes to represent a low-resolution version of the output image. Specifically, an image half the size (one quarter the area) of the output image would be 14\u00d714 or 196 nodes, and an image one quarter the size (one eighth the area) would be 7\u00d77 or 49 nodes.\n* Reshape image to 128 different 7\u00d77 feature maps\n* Upsampling the low-resolution image to a higher resolution version of the image. The Conv2DTranspose layer can be configured with a stride of (2\u00d72) to double their width and height \n* The output layer of the model is a Conv2D with one filter and a kernel size of 7\u00d77. Designed to create a single feature map and preserve its dimensions at 28\u00d728 \n* We will use best practice with BatchNormalization and Dropout to improve our model","e3d51022":"See how our generator perform","caedd261":"# Train model ","2a848828":"By this number of epochs it is not perfect yet. But we start to see shape of the digit","12b8b239":"### Generate fake samples","88517820":"# GAN over simplify \n\nImagine the criminal and police works. The criminal have their method to create the fake money. And the police have their method to detect it. While police keep detecting it, the criminal will try to improve their method which is harder to detect the fake money. Also while the criminal method keep improving, police also keep improving their method to detecting it. In the mean time, both of them keep improving on their work base on the other work. So at the end, both side will have perfect methodology of their result. \n\nIn this notebook:\n*   The criminal will be the **generator model** who responsible for generate fake image\n*   The police will be the **discriminator model** who responsible for detecting the result of generator\n*   They both will keep improving base on each other results. \n"}}