{"cell_type":{"e547fbf3":"code","758006b2":"code","438572b2":"code","4b8a5c22":"code","256e6eea":"code","650c2f1a":"code","3f4f4c9a":"code","b7019e06":"code","e398d712":"code","171a1c1a":"code","e31928ca":"code","fac35de1":"code","9d060cca":"code","7b443be3":"code","a6905410":"code","3c816dd9":"code","c7e526af":"code","68848a2e":"code","eb03ec55":"code","8b1d3bf8":"code","2a909be3":"code","14b16785":"code","16a0d308":"code","443f0ce6":"code","7d0d9fe5":"code","e6506164":"code","1551e2db":"code","b8e22529":"code","6033564e":"code","f45a7816":"code","96598cdd":"code","3962b11c":"code","beb5359c":"code","7a2ba95e":"code","09efdceb":"code","3a6f6363":"code","b7cf1106":"code","48a8f4d0":"code","7f21ced9":"markdown","da6d21d5":"markdown","f3dcbd6b":"markdown","9b4bb5c2":"markdown","31352bce":"markdown","f69ebedb":"markdown","e36778e7":"markdown","9edc3cd4":"markdown","dc810263":"markdown","3e02d29c":"markdown","91ddcfe7":"markdown"},"source":{"e547fbf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport featuretools as ft\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport pickle\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","758006b2":"new = pd.read_csv('..\/input\/new_merchant_transactions.csv',parse_dates =[\"purchase_date\"])\nhis = pd.read_csv('..\/input\/historical_transactions.csv',parse_dates =[\"purchase_date\"])\ntrain = pd.read_csv( '..\/input\/train.csv',parse_dates =[\"first_active_month\"])\ntest = pd.read_csv( '..\/input\/test.csv',parse_dates =[\"first_active_month\"])\nmerchants = pd.read_csv( '..\/input\/merchants.csv')","438572b2":"train.shape","4b8a5c22":"train_sub = train.loc[np.random.choice(train.index, 10000, replace=False)]","256e6eea":"merchants = merchants.drop_duplicates(subset=\"merchant_id\",keep=\"first\")\nprint(train.shape[0]==train[\"card_id\"].nunique())\nprint(merchants.shape[0]==merchants[\"merchant_id\"].nunique())\n#print(merchants[merchants[\"merchant_id\"].duplicated()])","650c2f1a":"new_drop=new.drop(['purchase_date',\"merchant_category_id\",\n                                                   \"subsector_id\",\"city_id\",\n                                                   \"state_id\"], axis=1)\nhis_drop=his.drop(['purchase_date',\"merchant_category_id\",\n                                                   \"subsector_id\",\"city_id\",\n                                                   \"state_id\"], axis=1)","3f4f4c9a":"mer_drop = merchants.drop(['merchant_group_id',\"merchant_category_id\",\n                                                   \"subsector_id\",\"most_recent_sales_range\",\n                                                   \"most_recent_purchases_range\",\n                           'city_id','state_id'], axis=1)","b7019e06":"train_his=train_sub[[\"card_id\"]].merge(his_drop, how='left', on=\"card_id\")","e398d712":"print(train_his.shape)\ntrain_his.head()","171a1c1a":"#train_his_transactions=train_his_transactions.dropna()\ntrain_his_sub=train_his\n#train_his_sub=train_his.loc[np.random.choice(train_his.index, 1000000, replace=False)]","e31928ca":"print(train_his_sub.shape)\ntrain_his_sub.head()","fac35de1":"authorized_flag = pd.get_dummies(train_his_sub['authorized_flag'])\nauthorized_flag.columns = ['authorized_flag_N', 'authorized_flag_Y']\ntrain_his_sub=train_his_sub.drop(['authorized_flag'], axis=1)\ntrain_his_sub=pd.concat([train_his_sub, authorized_flag], axis=1)","9d060cca":"train_his_sub.head()","7b443be3":"category_1 = pd.get_dummies(train_his_sub['category_1'])\ncategory_1.head()\ncategory_1.columns = ['category_1_N', 'category_1_Y']\ntrain_his_sub=train_his_sub.drop(['category_1'], axis=1)\ntrain_his_sub=pd.concat([train_his_sub, category_1], axis=1)\ntrain_his_sub.head()","a6905410":"category_2 = pd.get_dummies(train_his_sub['category_2'])\n#category_2.head()\ncategory_2.columns = ['category_2_1', 'category_2_2',\"category_2_3\",\"category_2_4\",\"category_2_5\"]\ntrain_his_sub=train_his_sub.drop(['category_2'], axis=1)\ntrain_his_sub=pd.concat([train_his_sub, category_2], axis=1)\ntrain_his_sub.head()","3c816dd9":"category_3 = pd.get_dummies(train_his_sub['category_3'])\n#category_3.head()\ncategory_3.columns = ['category_3_A', 'category_3_B',\"category_3_C\"]\ntrain_his_sub=train_his_sub.drop(['category_3'], axis=1)\ntrain_his_sub=pd.concat([train_his_sub, category_3], axis=1)\ntrain_his_sub.head()","c7e526af":"train_his_sub.columns","68848a2e":"train_his_sub.columns.values[1:]=[\"his_trans_\" + str(col) for col in list(train_his_sub)[1:]]\n","eb03ec55":"train_his_sub.columns.values[2] = \"merchant_id\"","8b1d3bf8":"train_his_sub.columns.values","2a909be3":"mer_drop = merchants.drop(['merchant_group_id',\"merchant_category_id\",\n                                                   \"subsector_id\",\"most_recent_sales_range\",\n                                                   \"most_recent_purchases_range\",\n                           'city_id','state_id'], axis=1)\nmer_drop.columns.values[1:]=[\"his_mer_\" + str(col) for col in mer_drop.columns.values[1:]] \nmer_drop.columns","14b16785":"train_his_sub_mer = train_his_sub.merge(mer_drop,how=\"left\",on='merchant_id')\ntrain_his_sub_mer.shape","16a0d308":"train_his_sub_mer.head()","443f0ce6":"category_1 = pd.get_dummies(train_his_sub_mer['his_mer_category_1'])\ncategory_1.head()\ncategory_1.columns = ['his_mer_category_1_N', 'his_mer_category_1_Y']\ntrain_his_sub_mer=train_his_sub_mer.drop(['his_mer_category_1'], axis=1)\ntrain_his_sub_mer=pd.concat([train_his_sub_mer, category_1], axis=1)\ntrain_his_sub_mer.head()","7d0d9fe5":"category_2 = pd.get_dummies(train_his_sub_mer['his_mer_category_2'])\n#category_2.head()\ncategory_2.columns = ['his_mer_category_2_1', 'his_mer_category_2_2',\"his_mer_category_2_3\",\"his_mer_category_2_4\",\"his_mer_category_2_5\"]\ntrain_his_sub_mer=train_his_sub_mer.drop(['his_mer_category_2'], axis=1)\ntrain_his_sub_mer=pd.concat([train_his_sub_mer, category_2], axis=1)\ntrain_his_sub_mer.head()","e6506164":"category_4 = pd.get_dummies(train_his_sub_mer['his_mer_category_4'])\n#category_1.head()\ncategory_4.columns = ['his_mer_category_4_N', 'his_mer_category_4_Y']\ntrain_his_sub_mer=train_his_sub_mer.drop(['his_mer_category_4'], axis=1)\ntrain_his_sub_mer=pd.concat([train_his_sub_mer, category_4], axis=1)\ntrain_his_sub_mer.head()","1551e2db":"with open('train_his_sub_mer.pickle', 'wb') as f:\n    pickle.dump(train_his_sub_mer, f)","b8e22529":"with open('train_his_sub_mer.pickle', 'rb') as f:\n    train_his_sub_mer = pickle.load(f)","6033564e":"## extract history transactions record for training data\n\ntrain_new=train_sub[[\"card_id\"]].merge(new_drop, how='left', on=\"card_id\")\n\nprint(train_new.shape)\ntrain_new.head()\n\n## **one hot encode** for train_his_sub : authorized_flag; category_1; category_2; category_3\ntrain_new['authorized_flag']=train_new['authorized_flag'].fillna(\"N\")\nauthorized_flag = pd.get_dummies(train_new['authorized_flag'])\n#print(train_new['authorized_flag'].value_counts())\n#print(train_new['authorized_flag'].isna().sum())\nauthorized_flag.columns = ['authorized_flag_N', 'authorized_flag_Y']\ntrain_new=train_new.drop(['authorized_flag'], axis=1)\ntrain_new=pd.concat([train_new, authorized_flag], axis=1)\n\ntrain_new.head()\n\ncategory_1 = pd.get_dummies(train_new['category_1'])\ncategory_1.head()\ncategory_1.columns = ['category_1_N', 'category_1_Y']\ntrain_new=train_new.drop(['category_1'], axis=1)\ntrain_new=pd.concat([train_new, category_1], axis=1)\ntrain_new.head()\n\ncategory_2 = pd.get_dummies(train_new['category_2'])\n#category_2.head()\ncategory_2.columns = ['category_2_1', 'category_2_2',\"category_2_3\",\"category_2_4\",\"category_2_5\"]\ntrain_new=train_new.drop(['category_2'], axis=1)\ntrain_new=pd.concat([train_new, category_2], axis=1)\ntrain_new.head()\n\ncategory_3 = pd.get_dummies(train_new['category_3'])\n#category_3.head()\ncategory_3.columns = ['category_3_A', 'category_3_B',\"category_3_C\"]\ntrain_new=train_new.drop(['category_3'], axis=1)\ntrain_new=pd.concat([train_new, category_3], axis=1)\ntrain_new.head()\n\n## rename column for merging simplicity\n\nprint(train_new.columns)\n\ntrain_new.columns.values[1:]=[\"new_trans_\" + str(col) for col in list(train_new)[1:]]\n\n\ntrain_new.columns.values[2] = \"merchant_id\"\n\nprint(train_new.columns.values)\n\n","f45a7816":"mer_drop = merchants.drop(['merchant_group_id',\"merchant_category_id\",\n                                                   \"subsector_id\",\"most_recent_sales_range\",\n                                                   \"most_recent_purchases_range\",\n                           'city_id','state_id'], axis=1)\nmer_drop.columns.values[1:]=[\"new_mer_\" + str(col) for col in mer_drop.columns.values[1:]] \nprint(mer_drop.columns)\n\n## merge with merchants (X : his transaction, Y : merchant)\n\ntrain_new_mer = train_new.merge(mer_drop,how=\"left\",on='merchant_id')\ntrain_new_mer.shape\n\ntrain_new_mer.head()\n\n## **one hot encode** for train_his_sub_mer(merchants part) : category_1; category_2; category_3\n\ncategory_1 = pd.get_dummies(train_new_mer['new_mer_category_1'])\n#category_1.head()\ncategory_1.columns = ['new_mer_category_1_N', 'new_mer_category_1_Y']\ntrain_new_mer=train_new_mer.drop(['new_mer_category_1'], axis=1)\ntrain_new_mer=pd.concat([train_new_mer, category_1], axis=1)\ntrain_new_mer.head()\n\ncategory_2 = pd.get_dummies(train_new_mer['new_mer_category_2'])\n#category_2.head()\ncategory_2.columns = ['new_mer_category_2_1', 'new_mer_category_2_2',\"new_mer_category_2_3\",\"new_mer_category_2_4\",\"new_mer_category_2_5\"]\ntrain_new_mer=train_new_mer.drop(['new_mer_category_2'], axis=1)\ntrain_new_mer=pd.concat([train_new_mer, category_2], axis=1)\ntrain_new_mer.head()\n\ncategory_4 = pd.get_dummies(train_new_mer['new_mer_category_4'])\n#category_1.head()\ncategory_4.columns = ['new_mer_category_4_N', 'new_mer_category_4_Y']\ntrain_new_mer=train_new_mer.drop(['new_mer_category_4'], axis=1)\ntrain_new_mer=pd.concat([train_new_mer, category_4], axis=1)\ntrain_new_mer.head()\n\nwith open('train_new_mer.pickle', 'wb') as f:\n    pickle.dump(train_new_mer, f)\n\nwith open('train_new_mer.pickle', 'rb') as f:\n    train_new_mer = pickle.load(f)\n\ntrain_new_mer.head()","96598cdd":"train_new_mer.columns.values","3962b11c":"train_new_mer.shape","beb5359c":"def aggregate_new_trans(data):  \n    agg_func = {\n        'card_id': ['size'], #num_trans\n        'new_trans_installments': ['sum', 'mean','median', 'max', 'min', 'std', 'nunique'],\n        'merchant_id': ['nunique'],\n        'new_trans_month_lag': ['mean', 'max', 'min', 'std', 'nunique'],\n        'new_trans_purchase_amount': ['sum', 'mean', 'max', 'min', 'std', 'nunique'],\n        'new_trans_authorized_flag_Y': ['mean'],\n        'new_trans_category_1_Y': ['mean'],\n        'new_trans_category_2_1': ['mean'],\n        'new_trans_category_2_2': ['mean'],\n        'new_trans_category_2_3': ['mean'],\n        'new_trans_category_2_4': ['mean'],\n        'new_trans_category_2_5': ['mean'],\n        'new_trans_category_3_A': ['mean'],\n        'new_trans_category_3_B': ['mean'],\n        'new_trans_category_3_C': ['mean'],\n        'new_mer_numerical_1':['mean'],\n        'new_mer_numerical_2':['mean'],\n        'new_mer_avg_sales_lag3':['mean'],\n        'new_mer_avg_purchases_lag3':['mean'],\n        'new_mer_active_months_lag3':['mean'], \n        'new_mer_avg_sales_lag6':['mean'],\n        'new_mer_avg_purchases_lag6':['mean'],\n        'new_mer_active_months_lag6':['mean'],\n        'new_mer_avg_sales_lag12':['mean'],\n        'new_mer_avg_purchases_lag12':['mean'],\n        'new_mer_active_months_lag12':['mean'],\n        'new_mer_category_1_Y':['mean'], \n        'new_mer_category_2_1':['mean'],\n        'new_mer_category_2_2':['mean'], \n        'new_mer_category_2_3':['mean'],\n        'new_mer_category_2_4':['mean'], \n        'new_mer_category_2_5':['mean'],\n        'new_mer_category_4_Y':['mean']\n    }    \n    agg_trans = data.groupby(['card_id']).agg(agg_func)\n    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n    agg_trans.reset_index(inplace=True)\n    \n    return agg_trans\n\n#hist_sum = aggregate_trans(histdata, 'hist_')\nnew_sum = aggregate_new_trans(train_new_mer)","7a2ba95e":"new_sum.head()","09efdceb":"new_sum.shape","3a6f6363":"def aggregate_his_trans(data):  \n    agg_func = {\n        'card_id': ['size'], #num_trans\n        'his_trans_installments': ['sum', 'mean','median', 'max', 'min', 'std', 'nunique'],\n        'merchant_id': ['nunique'],\n        'his_trans_month_lag': ['mean', 'max', 'min', 'std', 'nunique'],\n        'his_trans_purchase_amount': ['sum', 'mean', 'max', 'min', 'std', 'nunique'],\n        'his_trans_authorized_flag_Y': ['mean'],\n        'his_trans_category_1_Y': ['mean'],\n        'his_trans_category_2_1': ['mean'],\n        'his_trans_category_2_2': ['mean'],\n        'his_trans_category_2_3': ['mean'],\n        'his_trans_category_2_4': ['mean'],\n        'his_trans_category_2_5': ['mean'],\n        'his_trans_category_3_A': ['mean'],\n        'his_trans_category_3_B': ['mean'],\n        'his_trans_category_3_C': ['mean'],\n        'his_mer_numerical_1':['mean'],\n        'his_mer_numerical_2':['mean'],\n        'his_mer_avg_sales_lag3':['mean'],\n        'his_mer_avg_purchases_lag3':['mean'],\n        'his_mer_active_months_lag3':['mean'], \n        'his_mer_avg_sales_lag6':['mean'],\n        'his_mer_avg_purchases_lag6':['mean'],\n        'his_mer_active_months_lag6':['mean'],\n        'his_mer_avg_sales_lag12':['mean'],\n        'his_mer_avg_purchases_lag12':['mean'],\n        'his_mer_active_months_lag12':['mean'],\n        'his_mer_category_1_Y':['mean'], \n        'his_mer_category_2_1':['mean'],\n        'his_mer_category_2_2':['mean'], \n        'his_mer_category_2_3':['mean'],\n        'his_mer_category_2_4':['mean'], \n        'his_mer_category_2_5':['mean'],\n        'his_mer_category_4_Y':['mean']\n    }    \n    agg_trans = data.groupby(['card_id']).agg(agg_func)\n    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n    agg_trans.reset_index(inplace=True)\n    \n    return agg_trans\n\n#hist_sum = aggregate_trans(histdata, 'hist_')\nhis_sum = aggregate_his_trans(train_his_sub_mer)","b7cf1106":"with open('new_sum.pickle', 'wb') as f:\n    pickle.dump(new_sum, f)\nwith open('his_sum.pickle', 'wb') as f:\n    pickle.dump(his_sum, f)","48a8f4d0":"his_sum.shape","7f21ced9":"## Feature Engineering","da6d21d5":"## **one hot encode** for train_his_sub_mer(merchants part) : category_1; category_2; category_3","f3dcbd6b":"## rename column for merging simplicity","9b4bb5c2":"## extract history transactions record for training data","31352bce":"## check duplicates in merchants and train datasets, remove any duplicates","f69ebedb":"## merge with merchants (X : his transaction, Y : merchant)","e36778e7":"## drop non-important column for his, new and merchant","9edc3cd4":"## **subsample his transactions**","dc810263":"## **one hot encode** for train_his_sub : authorized_flag; category_1; category_2; category_3","3e02d29c":"## same for new transaction","91ddcfe7":"## import dataset"}}