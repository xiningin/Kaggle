{"cell_type":{"e922818b":"code","e8661648":"code","fe84b66c":"code","1e618636":"code","eccd057a":"code","e0d454a8":"code","325e2583":"code","b7c8d15a":"code","ddc7b43b":"code","08f0d95e":"code","3ae6cbd6":"code","6ce5ad6f":"code","f193dcbb":"code","f9ec31a9":"code","08e8bf3c":"code","fd4d4c9a":"code","fbf61f12":"code","d59fa9ab":"code","0fc6de20":"code","a3f3ff31":"code","09e66981":"code","aa67df3b":"code","614e267e":"code","95ae9433":"code","022d6294":"code","1894af82":"code","e69d06ce":"code","72ea6fef":"code","33c03b88":"code","7edf6a8e":"code","70b137fe":"code","04b381f0":"code","4d75bd4a":"code","3017e135":"code","f9407410":"code","7b0fcee2":"code","cf0cb985":"code","a77c545b":"code","e76c6774":"code","13bd3f54":"code","66cd5867":"code","da940c64":"code","14d98dc2":"code","b61d524c":"code","f3946915":"code","eaaa16d6":"code","7570c092":"code","aa325872":"code","79d1a5ef":"code","69a629c6":"code","f793ff4f":"code","1922c057":"code","9eb2f522":"code","64457032":"code","4cf52892":"code","b791ab7d":"code","8c99e7e3":"code","48edd6e4":"code","51f6c92e":"code","677b5951":"code","6f4a3124":"code","f2de95f9":"code","0703fefa":"code","bcce1246":"code","0b69829e":"code","b740b228":"code","e60eb97b":"code","d8d1d9fa":"code","af89f80a":"code","49459121":"code","ac296f67":"code","5422e1dc":"code","e32f9b43":"code","d7587d47":"code","502c959e":"code","cf883e8c":"code","e592e68f":"code","54906fb2":"code","e458c91e":"code","4d2b7ebe":"code","7db997a6":"code","e362d18f":"code","3b1e4e7a":"code","b40acb6e":"code","8e68c20d":"code","f003adcb":"code","85a5d28d":"code","31c232a0":"code","4257ddb4":"code","a7b6e9d3":"code","2d6e983b":"code","7e32dbcb":"code","15749c7c":"code","f5b8a56c":"code","d598d2f5":"code","c6dfb3a9":"code","a0b26112":"code","4586d51b":"code","d22a75ae":"code","1123f709":"code","d996e9b0":"code","bc6d96c4":"code","6fe8bd60":"code","1c69fbe6":"code","ffdc804d":"code","335a9c0d":"markdown","634efea7":"markdown","02b35f4e":"markdown","c6cf7ea9":"markdown","3f4ccce7":"markdown","744b56c2":"markdown","0599c404":"markdown","9f358f6b":"markdown","bd3b818c":"markdown","439717f4":"markdown","58935ac0":"markdown","5eeb0175":"markdown","a9dc6244":"markdown","9e64b5ec":"markdown","057fa08a":"markdown","e5d3c8c7":"markdown","56a76d17":"markdown","8f14fc24":"markdown","f7ff8d2d":"markdown","9224437f":"markdown","93603b8c":"markdown","ce82e1b3":"markdown","970d4c09":"markdown","2bc2cd9d":"markdown","3a423191":"markdown","00a934c5":"markdown","d46bd0aa":"markdown","ce1314f4":"markdown","e84002de":"markdown","a1953f5f":"markdown","cd85301e":"markdown","0b76946d":"markdown","d4fc2a75":"markdown","49914f6a":"markdown","c57ed016":"markdown","ff3dbb96":"markdown","0d2c2524":"markdown","62d613e8":"markdown","9c207241":"markdown","050d61ed":"markdown","e8a0c718":"markdown","bc963e1b":"markdown","3d553958":"markdown","71037f59":"markdown","770c8af8":"markdown","111beacc":"markdown","64e44d50":"markdown","6cbc26cd":"markdown","f565d17a":"markdown","c5a3dd95":"markdown"},"source":{"e922818b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset,Dataset\n\nimport gc\n\nimport random\n\nimport transformers\nimport warnings\nwarnings.simplefilter('ignore')\n\n#scaler = torch.cuda.amp.GradScaler() # GPU\u3067\u306e\u9ad8\u901f\u5316\u3002\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpu\u304cgpu\u304b\u3092\u81ea\u52d5\u5224\u65ad\ndevice","e8661648":"SEED = 508\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","fe84b66c":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf","1e618636":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest","eccd057a":"df.info()","e0d454a8":"df.columns","325e2583":"for col in df.columns:\n    print(str(col) + \":\" + str(len(df[col].unique())))","b7c8d15a":"df[\"Age\"]","ddc7b43b":"# In order to get the average value, dropna is used to remove all but Nan data.\n# \u5e73\u5747\u5024\u3092\u51fa\u3059\u305f\u3081\u306b\u3001dropna\u3067Nan\u30c7\u30fc\u30bf\u4ee5\u5916\u3092\u629c\u304d\u307e\u3059\u3002\ndf[\"Age\"].dropna()","08f0d95e":"dmean = df[\"Age\"].dropna().mean()\ndmean","3ae6cbd6":"# filling an mean value. : \u5e73\u5747\u5024\u3067\u57cb\u3081\u308b\n\ndf[\"Age\"] = df[\"Age\"].fillna(dmean)","6ce5ad6f":"df","f193dcbb":"test[\"Age\"] = test[\"Age\"].fillna(dmean)","f9ec31a9":"from sklearn.preprocessing import LabelEncoder","08e8bf3c":"le=LabelEncoder()\nle.fit(df[\"Sex\"])\ndf[\"Sex\"] = le.transform(df[\"Sex\"])\ntest[\"Sex\"] = le.transform(test[\"Sex\"])","fd4d4c9a":"df","fbf61f12":"# firstly, combining df and test. Combine vertically with axis = 0.\n# \u30c8\u30ec\u30a4\u30f3\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u307e\u3059\u3002axis = 0 \u3067\u7e26\u306b\u7d50\u5408\u3002\n\ndfall = pd.concat([df,test],axis=0)\ndfall","d59fa9ab":"# one-hot encoding using pd.get_dummies. NaN can also be separated by dummy_na = True.\n# get_dummies\u3092\u4f7f\u3063\u3066\u3001one-hot encoding\u3057\u307e\u3059\u3002dummy_na=True\u3067NaN\u3082\u5206\u3051\u308b\u3053\u3068\u304c\u53ef\u80fd\u3002\n\ndfall2 = pd.get_dummies(dfall[\"Embarked\"],dummy_na=True)\ndfall2","0fc6de20":"# Combine horizontally with axis = 1.\n# axis = 1 \u3067\u6a2a\u306b\u7d50\u5408\u3002\n\ndfall = pd.concat([dfall,dfall2],axis=1)\ndfall","a3f3ff31":"# Separate the train data and test data and restore them.\n# \u30c8\u30ec\u30a4\u30f3\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u96e2\u3057\u3066\u5143\u306b\u623b\u3057\u307e\u3059\u3002\n\ntrain = dfall.iloc[:len(df),:]\ntest = dfall.iloc[len(df):,:]","09e66981":"train","aa67df3b":"test","614e267e":"from sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","95ae9433":"folds = train.copy()\nFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"Survived\"])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.groupby(['fold', \"Survived\"]).size())","022d6294":"folds","1894af82":"p_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]","e69d06ce":"p_train","72ea6fef":"# An error will occur later, so reassign the index.\n# \u5f8c\u307b\u3069\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\u3001index\u3092\u632f\u308a\u306a\u304a\u3059\u3002\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)","33c03b88":"p_train","7edf6a8e":"# defining the feature columns and the target\n\nFEATURES = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"C\",\"Q\",\"S\",np.nan]\nTARGET = \"Survived\"","70b137fe":"p_train[FEATURES]","04b381f0":"p_train[FEATURES]","4d75bd4a":"p_train[TARGET]","3017e135":"train_X = np.array(p_train[FEATURES])\ntrain_Y = np.array(p_train[TARGET])\n\nval_X = np.array(p_val[FEATURES])\nval_Y = np.array(p_val[TARGET])","f9407410":"train_X[:3]","7b0fcee2":"from sklearn.preprocessing import StandardScaler\nNormarizescaler = StandardScaler()\nNormarizescaler.fit(np.array(train[FEATURES]))","cf0cb985":"train_X = Normarizescaler.transform(train_X)\nval_X = Normarizescaler.transform(val_X)","a77c545b":"train_X[:3]","e76c6774":"train_X = torch.from_numpy(train_X).float()\ntrain_Y = torch.from_numpy(train_Y).long() # long : int64\n\nval_X = torch.from_numpy(val_X).float()\nval_Y = torch.from_numpy(val_Y).long() # long : int64","13bd3f54":"train_X[:3]","66cd5867":"train_dataset = TensorDataset(train_X,train_Y)\nval_dataset = TensorDataset(val_X,val_Y)","da940c64":"train_dataset[0]","14d98dc2":"class PytorchDataSet(Dataset):\n    \n    def __init__(self,df):\n        \n        # for test data, In test data, it's easier to fill it with something on purpose.\n        # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3082\u8aad\u307f\u8fbc\u3081\u308b\u3088\u3046\u306b\u308f\u3056\u30689999\u3067\u57cb\u3081\u3066\u3044\u307e\u3059\u3002\n        \n        if \"Survived\" not in df.columns:\n            df[\"Survived\"] = 9999\n        \n        self.df = df\n        \n        self.train_X = np.array(self.df[FEATURES])\n        self.train_Y = np.array(self.df[TARGET])\n        \n        self.train_X = Normarizescaler.transform(self.train_X)\n        \n        self.train_X = torch.from_numpy(self.train_X).float()\n        self.train_Y = torch.from_numpy(self.train_Y).long() # long : int64\n\n    def __len__(self):\n        \n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        \n        return {\"X\":self.train_X[idx],\"Y\":self.train_Y[idx]}","b61d524c":"train_dataset = PytorchDataSet(p_train)\nval_dataset = PytorchDataSet(p_val)\ntest_dataset = PytorchDataSet(test)","f3946915":"train[FEATURES].head(3)","eaaa16d6":"train_dataloader = DataLoader(train_dataset,batch_size=256,shuffle = True)\nval_dataloader = DataLoader(val_dataset,batch_size=256*2,shuffle = False)\ntest_dataloader = DataLoader(test_dataset,batch_size=256*2,shuffle = False)","7570c092":"for a in train_dataloader:\n    print(a)\n    break","aa325872":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__() \n        self.fc1 = nn.Linear(len(FEATURES),512) #input number and middle layer fc1\n        self.fc2 = nn.Linear(512,256) # middle layer fc2\n        self.fc3 = nn.Linear(256,2) # output\n        \n    \n    def forward(self,x): \n        x= F.relu(self.fc1(x)) # Put the relu function after fc1\n        x= F.relu(self.fc2(x)) # Put the relu function after fc2\n        x = self.fc3(x) # fc3\n        return x ","79d1a5ef":"model=Net() # model instance\n\nmodel.to(device) # if GPU is using, this must be needed. cpu is also OK in this sentence.\n\ncriterion = nn.CrossEntropyLoss() # how to calculate loss function\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Algo for optimizing weight","69a629c6":"model","f793ff4f":"total_loss = 0 # Initializing total loss\n\nmodel.train()\n\nfor a in train_dataloader:\n\n        train_x= a[\"X\"].to(device)\n        train_y = a[\"Y\"].to(device)\n        \n        \n        optimizer.zero_grad() # Set the gradient of optimizer to 0\n\n        output = model(train_x) # prediction\n        \n        loss = criterion(output,train_y) # calculationg loss between predictions and answers\n        \n        loss.backward() # backward\n\n        optimizer.step() # optimizing weight\n\n        total_loss += loss.item() # integration of loss\n        \n        break","1922c057":"output[:3]","9eb2f522":"torch.max(output.data,1)","64457032":"torch.max(output.data,1)[1]","4cf52892":"output_numpy = output.detach().cpu().numpy() # torch to numpy","b791ab7d":"out2 = [s.argmax() for s in output_numpy] ","8c99e7e3":"out2[:20]","48edd6e4":"total_loss","51f6c92e":"def training(train_dataloader,model):\n\n    total_loss = 0 # Initializing total loss\n    \n    model.train()\n\n    for a in train_dataloader:\n\n            train_x= a[\"X\"].to(device)\n            train_y = a[\"Y\"].to(device)\n            \n            optimizer.zero_grad() # Set the gradient of optimizer to 0\n\n            output = model(train_x) # prediction\n\n            loss = criterion(output,train_y) # calculationg loss between predictions and answers\n\n            loss.backward() # backward\n\n            optimizer.step() # optimizing weight\n\n            total_loss += loss.item() # integration of loss\n            \n    total_loss = total_loss\/len(train_dataloader)\n            \n    return model,total_loss\n        ","677b5951":"model,total_loss = training(train_dataloader,model)","6f4a3124":"total_loss","f2de95f9":"total_loss = 0 # Initializing total loss\n\nmodel.eval()\n\nfor a in val_dataloader:\n    \n    with torch.no_grad():\n        \n\n        val_x= a[\"X\"].to(device)\n        val_y = a[\"Y\"].to(device)\n        \n        output = model(val_x) # prediction\n        \n        loss = criterion(output,val_y) # calculationg loss between predictions and answers\n        \n     \n        total_loss += loss.item() # integration of loss\n        \n        break","0703fefa":"output[:3]","bcce1246":"def valeval(val_dataloader,model):\n    \n    allpreds=[]\n\n    total_loss = 0 # Initializing total loss\n\n    model.eval()\n\n    for a in val_dataloader:\n\n        with torch.no_grad():\n\n\n            val_x= a[\"X\"].to(device)\n            val_y = a[\"Y\"].to(device)\n\n            output = model(val_x) # prediction\n            \n            allpreds.append(output.detach().cpu().numpy())\n            \n            loss = criterion(output,val_y) # calculationg loss between predictions and answers\n\n\n            total_loss += loss.item() # integration of loss\n            \n\n    total_loss=total_loss\/len(val_dataloader)\n    allpreds = np.concatenate(allpreds)\n    \n    \n    return allpreds, total_loss\n","0b69829e":"allpreds,valloss = valeval(val_dataloader,model)","b740b228":"model=Net() # model instance\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss() # how to calculate loss function\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Algo for optimizing weight","e60eb97b":"all_res = []\n\nfor epoch in tqdm(range(1000)):\n    \n    model,trainloss = training(train_dataloader,model)\n    allpreds,valloss = valeval(val_dataloader,model)\n    all_res.append([epoch,trainloss,valloss])\n ","d8d1d9fa":"alldf = pd.DataFrame(all_res)\nalldf.columns = [\"epoch\",\"trainloss\",\"valloss\"]\nalldf","af89f80a":"alldf.head(10)","49459121":"plt.plot(alldf[\"epoch\"],alldf[\"trainloss\"])\nplt.plot(alldf[\"epoch\"],alldf[\"valloss\"])","ac296f67":"train_X","5422e1dc":"train_preds = model(train_X)\ntrain_preds","e32f9b43":"train_preds2 = torch.max(train_preds.data,1)[1]\ntrain_preds2[:3]","d7587d47":"accuracy_score(train_Y,train_preds2)","502c959e":"# functionalize\n\ndef calc_accuracy(x,y,model):\n    preds = model(x)\n    preds2 = torch.max(preds.data,1)[1]\n    return accuracy_score(y,preds2)\n    \n    ","cf883e8c":"calc_accuracy(train_X,train_Y,model)","e592e68f":"calc_accuracy(val_X,val_Y,model)","54906fb2":"len(train_X)","e458c91e":"all_trainloss = []\nall_valloss = []\n\nall_trainscore = []\nall_valscore = []\n\nallres=[]\n\nbestscore = 0\n\nmodel=Net() # model instance\n\ncriterion = nn.CrossEntropyLoss() # how to calculate loss function\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Algo for optimizing weight\n\nfor epoch in tqdm(range(1000)):\n    \n    model,trainloss = training(train_dataloader,model)\n    \n    preds,valloss = valeval(val_dataloader,model)\n    \n    trainscore = calc_accuracy(train_X,train_Y,model)\n    \n    valscore = calc_accuracy(val_X,val_Y,model)\n    \n    allres.append([epoch,trainloss,valloss,trainscore,valscore])\n    \n    if bestscore <valscore:\n        \n        bestscore = valscore\n        state = {\n                    'state_dict': model.state_dict(),\n                    'optimizer_dict': optimizer.state_dict(),\n                    \"bestscore\":bestscore\n                }\n        \n\n        torch.save(state, \"model1.pth\")\n        \n    else:\n        pass\n        \n    \n    ","4d2b7ebe":"bestscore","7db997a6":"resdf = pd.DataFrame(allres)\nresdf.columns=[\"epoch\",\"trainloss\",\"valloss\",\"trainscore\",\"valscore\"]","e362d18f":"resdf","3b1e4e7a":"plt.plot(resdf[\"epoch\"],resdf[\"trainloss\"])\nplt.plot(resdf[\"epoch\"],resdf[\"valloss\"])","b40acb6e":"plt.plot(resdf[\"epoch\"],resdf[\"trainscore\"])\nplt.plot(resdf[\"epoch\"],resdf[\"valscore\"])","8e68c20d":"state = torch.load(\".\/model1.pth\")","f003adcb":"model.load_state_dict(state[\"state_dict\"])","85a5d28d":"# confirming submission file","31c232a0":"submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission","4257ddb4":"for a in test_dataloader:\n    print(a)\n    break","a7b6e9d3":"def inference(test_dataloader,model):\n    \n    allpreds=[]\n\n    total_loss = 0 # Initializing total loss\n\n    model.eval()\n\n    for a in test_dataloader:\n\n        with torch.no_grad():\n            val_x= a[\"X\"].to(device)\n            val_y = a[\"Y\"].to(device)\n\n            output = model(val_x) # prediction\n            \n            allpreds.append(output.detach().cpu().numpy())\n            \n            \n\n    allpreds = np.concatenate(allpreds)\n    \n    \n    return allpreds\n","2d6e983b":"allpreds = inference(test_dataloader,model)","7e32dbcb":"allpreds[:3]","15749c7c":"allpreds2 = [s.argmax() for s in allpreds]","f5b8a56c":"submission.head(3)","d598d2f5":"submission[\"Survived\"] = allpreds2","c6dfb3a9":"submission.to_csv(\"submission1.csv\",index = False)","a0b26112":"kall_preds = []\nbestscores=[]\n\nfor fold in range(5):\n    \n    print(f\"----fold={fold}---start\")\n\n\n    p_train = folds[folds[\"fold\"] != fold]\n    p_val = folds[folds[\"fold\"] == fold]\n\n    # An error will occur later, so reassign the index.\n    # \u5f8c\u307b\u3069\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\u3001index\u3092\u632f\u308a\u306a\u304a\u3059\u3002\n\n    p_train = p_train.reset_index(drop=True)\n    p_val = p_val.reset_index(drop=True)\n\n    train_dataset = PytorchDataSet(p_train)\n    val_dataset = PytorchDataSet(p_val)\n    test_dataset = PytorchDataSet(test)\n\n    train_dataloader = DataLoader(train_dataset,batch_size=256,shuffle = True)\n    val_dataloader = DataLoader(val_dataset,batch_size=256*2,shuffle = False)\n    test_dataloader = DataLoader(test_dataset,batch_size=256*2,shuffle = False)\n\n    model=Net() # model instance\n\n    model.to(device) # if GPU is using, this must be needed. cpu is also OK in this sentence.\n\n    criterion = nn.CrossEntropyLoss() # how to calculate loss function\n\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Algo for optimizing weight\n\n    all_trainloss = []\n    all_valloss = []\n\n    all_trainscore = []\n    all_valscore = []\n\n    allres=[]\n\n    bestscore = 0\n\n    model=Net() # model instance\n\n    criterion = nn.CrossEntropyLoss() # how to calculate loss function\n\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Algo for optimizing weight\n\n    for epoch in tqdm(range(1000)):\n        \n        model,trainloss = training(train_dataloader,model)\n        \n        preds,valloss = valeval(val_dataloader,model)\n        \n        trainscore = calc_accuracy(train_X,train_Y,model)\n        \n        valscore = calc_accuracy(val_X,val_Y,model)\n        \n        allres.append([epoch,trainloss,valloss,trainscore,valscore])\n        \n        if bestscore <valscore:\n            \n            bestscore = valscore\n            state = {\n                        'state_dict': model.state_dict(),\n                        'optimizer_dict': optimizer.state_dict(),\n                        \"bestscore\":bestscore\n                    }\n            \n\n            torch.save(state, f\"model{fold}.pth\")\n            \n        else:\n            pass\n            \n    bestscores.append(bestscore)","4586d51b":"kall_preds = []\n\nfor fold in range(5):\n    \n    state = torch.load(f\".\/model{fold}.pth\")\n\n    model.load_state_dict(state[\"state_dict\"])\n\n    allpreds = inference(test_dataloader,model)\n    \n    kall_preds.append(allpreds)\n    \n    ","d22a75ae":"bestscores","1123f709":"np.mean(bestscores)","d996e9b0":"len(kall_preds)","bc6d96c4":"kall_preds = np.mean(kall_preds,axis=0)\nkall_preds = [s.argmax() for s in kall_preds]","6fe8bd60":"submission[\"Survived\"] = kall_preds","1c69fbe6":"submission.to_csv(\"submission2.csv\",index=False)","ffdc804d":"submission","335a9c0d":"# 4. Kfold\n#### Prepare training data and verification data in 5 combinations.\n#### \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u30925\u3064\u306e\u7d44\u307f\u5408\u308f\u305b\u3067\u6e96\u5099\u3059\u308b\u3002","634efea7":"#### There are 891 rows. There are NaN data in Age, Cabin, Embarked.\n#### \u5168\u90e8\u3067891\u884c\u3042\u3063\u3066\u3001Age,Cabin,Embarked\u306b\u306fnull\u30c7\u30fc\u30bf\u306f\u306a\u3044\u304c\u3001NaN\u30c7\u30fc\u30bf\u304c\u3042\u308a\u305d\u3046\u3002","02b35f4e":"![image.png](attachment:a82168a7-f857-41f3-8134-6299c5ff1924.png)","c6cf7ea9":"## 5.4.4 validation","3f4ccce7":"![image.png](attachment:da5e624e-1e46-4dfd-b29f-6e9a8a74e772.png)","744b56c2":"## 5.4.3 Functionalized for 1epoch","0599c404":"#### 5.2.1.1 DataFrame \u2192 Numpy","9f358f6b":"![image.png](attachment:7d246e9d-d007-4f9f-8bf7-bc709443a53b.png)","bd3b818c":"# Fixing Random seed in order to get reproducability. \u518d\u73fe\u6027\u78ba\u4fdd\u306e\u305f\u3081\u306e\u30e9\u30f3\u30c0\u30e0\u30b7\u30fc\u30c9\u56fa\u5b9a","439717f4":"![image.png](attachment:fcab6a0d-7d12-421a-923d-cbd5509975e3.png)","58935ac0":"# 5.3 Making class : In Pytorch, when creating a Dataset, it is often created as a class as shown below. Therefore, I will explain how to do this.\n\nPytorch\u3067\u306f\u3001\u3088\u304fDataset\u3092\u4f5c\u308b\u3068\u304d\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001class\u306b\u3057\u3066\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u591a\u3044\u3067\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u3053\u306e\u3084\u308a\u65b9\u3092\u8aac\u660e\u3057\u307e\u3059\u3002","5eeb0175":"## point : early stopping is needed in order to avoid overfitting \n\n### Accuracy score","a9dc6244":"## About data\nsurvival\tSurvival\t0 = No, 1 = Yes\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\tSex\t\nAge\tAge in years\t\nsibsp\t# of siblings \/ spouses aboard the Titanic\t\nparch\t# of parents \/ children aboard the Titanic\t\nticket\tTicket number\t\nfare\tPassenger fare\t\ncabin\tCabin number\t\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n#########\u65e5\u672c\u8a9e#################\n\nsurvival\t\u751f\u6b7b\t0 = \u6b7b\u4ea1, 1 = \u751f\u5b58\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\t\u6027\u5225\t\nAge\t\u5e74\u9f62\t\nsibsp\t# of siblings \/ \u89aa\u65cf\u306e\u6570\t\nparch\t# of parents \/ \u5b50\u4f9b\u306e\u6570\t\nticket\tTicket number\u3000\u30c1\u30b1\u30c3\u30c8\u30ca\u30f3\u30d0\u30fc\t\nfare\tPassenger fare\t\u904b\u8cc3\ncabin\tCabin number\t\u90e8\u5c4b\u306e\u756a\u53f7\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\u3000\u4e57\u8239\u3057\u305f\u5834\u6240\n","9e64b5ec":"## 7.1 Kfold inference ( this part can be included in #7 )","057fa08a":"## Strategy: Save model on best validation score update using calc_accuracy","e5d3c8c7":"Initialize model condition","56a76d17":"# 5.4 Modeling","8f14fc24":"#### 5.2.1.2 Numpy \u2192 Normalization","f7ff8d2d":"# 2 label encoding\n#### Automatically convert strings to numbers. Since there is a significant difference such as 0 and 1, Sex is divided in this way.\n#### \u6587\u5b57\u5217\u3092\u6570\u5b57\u306b\u81ea\u52d5\u5909\u63db. 0\u30681\u306a\u3069\u6709\u610f\u5dee\u304c\u3042\u308b\u305f\u3081\u3001\u3053\u306e\u3084\u308a\u65b9\u3067\u6027\u5225\u3092\u5206\u3051\u3066\u3044\u307e\u3059\u3002","9224437f":"![image.png](attachment:aea4a051-cd09-454c-8cab-51f01327657b.png)","93603b8c":"## python has already Accuracy function","ce82e1b3":"# 7. Application : Kfold","970d4c09":"## for practice, fold0 is defined as validation, fold1-4 are defined as train\n## \u7df4\u7fd2\u306e\u305f\u3081\u306b\u3001\u307e\u305a\u3001fold0\u3092\u691c\u8a3c\u30c7\u30fc\u30bf\u3001fold1-4\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u3057\u307e\u3059\u3002","2bc2cd9d":"# 5.Neural Network using pytorch","3a423191":"#### 5.2.1.5 Tensor Dataset","00a934c5":"![image.png](attachment:86cbcb8d-bab8-493a-b8bf-1672810567ba.png)","d46bd0aa":"# 5.1 Defining features and target\n##     \u7279\u5fb4\u91cf\u3068\u30e9\u30d9\u30eb(\u30bf\u30fc\u30b2\u30c3\u30c8)\u3092\u5b9a\u7fa9\u3057\u307e\u3059","ce1314f4":"## 6.1 loading model","e84002de":"## Dataloader : Change the Dataset to a batch processing (multiple processing) format.\n#### \u2192 Dataset\u3092\u30d0\u30c3\u30c1\u51e6\u7406(\u8907\u6570\u51e6\u7406)\u3059\u308b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u5909\u3048\u307e\u3059\u3002Dataloader\u306f\u3001Dataset\u3067\u4f5c\u3063\u305f1\u3064\u306e\u888b\u3092\u5927\u304d\u306a\u7d19\u888b\u306b\u5165\u308c\u3066\u3001\u7d19\u888b\u3054\u3068\u51e6\u7406\u3059\u308b\u30a4\u30e1\u30fc\u30b8\u3002\u3053\u306e\u5834\u5408\u30011\u3064\u306e\u7d19\u888b(Dataloader)\u306b\u306f\u3001training\u3067\u306f256\u500b\u306e\u30d3\u30cb\u30fc\u30eb\u888b\u3092\u8a70\u3081\u8fbc\u3080\u30a4\u30e1\u30fc\u30b8\u3002","a1953f5f":"#### 5.2.1.4 Normalization \u2192 torch","cd85301e":"# 6.inference for test data","0b76946d":"![image.png](attachment:ad7baa01-f679-481c-bc46-4dd1c8649137.png)","d4fc2a75":"# 3. One-hot encoding\n#### Automatically convert strings to numbers line by line. \n#### There are four Embarked places including NaN, but since no significant difference can be considered, divide them in parallel.\n#### \u6587\u5b57\u5217\u3092\u884c\u3054\u3068\u306b\u6570\u5b57\u306b\u81ea\u52d5\u5909\u63db\u3002Embarked\u306fNaN\u3092\u5165\u308c\u30664\u3064\u3042\u308b\u304c\u3001\u6709\u610f\u5dee\u304c\u8003\u3048\u3089\u308c\u306a\u3044\u306e\u3067\u3001\u4e26\u5217\u306b\u5206\u3051\u307e\u3059\u3002","49914f6a":"## 5.4.1 Definition of Criterion, optimizer","c57ed016":"![image.png](attachment:ef42746a-7eb2-467e-a91c-5fa76bf8c6cd.png)","ff3dbb96":"## In numpy case, I use this method. \u203b This is different in torch \u21d4 numpy","0d2c2524":"![image.png](attachment:09e034ba-3b5e-4b8d-a3fc-cb86ea40a018.png)","62d613e8":"# Pytorch Neural Network Starter\n## About this notebook\n*  This notebook is basic code for neural network starter using pytorch including Kfold, label encoding, one-hot encoding and so on.\n*  This notebook is detail version in order to understand easily. Short version will be made.\n*  If this is helpful for you, please upvote.\n\n\n\n*  \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306f\u3001NaN\u306e\u51e6\u7406\u3001Kfold, \u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3001\u30ef\u30f3\u30db\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306a\u3069\u306e\u69d8\u3005\u306a\u5834\u9762\u3067\u4f7f\u3046\u30b3\u30fc\u30c9\u3092\u542b\u3080\u3001pytorch\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u57fa\u790e\u30b3\u30fc\u30c9\u3067\u3059\u3002\n*  \u7406\u89e3\u3092\u6df1\u3081\u308b\u305f\u3081\u306b\u3001\u9577\u304f\u66f8\u3044\u3066\u3044\u307e\u3059\u3002\u30b7\u30e7\u30fc\u30c8\u30d0\u30fc\u30b8\u30e7\u30f3\u3082\u4f5c\u308a\u307e\u3059\u3002\n*  \u3082\u3057\u3001\u304a\u5f79\u306b\u7acb\u3061\u307e\u3057\u305f\u3089\u3001upvote\u3057\u3066\u304f\u308c\u308b\u3068\u5b09\u3057\u3044\u3067\u3059\u3002\n\n","9c207241":"# 1. Handling of NaN values : \u6b20\u640d\u5024\u306e\u51e6\u7406\n### 1.1 filling an mean value. : \u5e73\u5747\u5024\u3067\u57cb\u3081\u308b","050d61ed":"![image.png](attachment:dc37d308-233a-4831-b289-b4bbe1810709.png)","e8a0c718":"# 5.2 Dataset\/DataLoader\n## Dataset : Set the combination of features and correct answers.\u3000\n#### \u2192 \u7279\u5fb4\u91cf\u3068\u6b63\u89e3\u306e\u7d44\u307f\u5408\u308f\u305b\u3092\u30bb\u30c3\u30c8\u3057\u307e\u3059\u3002\u30a4\u30e1\u30fc\u30b8\u3067\u3044\u3046\u3068\u30011\u3064\u306e\u30d3\u30cb\u30fc\u30eb\u888b\u306e\u4e2d\u306b\u7279\u5fb4\u91cf1\u500b\u3068\u6b63\u89e31\u500b\u3092\u5165\u308c\u308b\u30a4\u30e1\u30fc\u30b8\uff08\u3053\u308c\u304c1\u884c\u5206)\u3002\n","bc963e1b":"## 5.2.1 \u307e\u305a\u306f1\u3064\u3084\u3063\u3066\u307f\u308b ","3d553958":"## 5.4.2 Training one epoch","71037f59":"# 0. Confirming the train\/test data : \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\n","770c8af8":"## 5.4.5 Functionalized for 1epoch","111beacc":"![image.png](attachment:ab3252e6-9f52-4389-9adc-c5e19dc1d4d6.png)","64e44d50":"# 5.5     (test) 1000 epoch training and confirm","6cbc26cd":"You can see that the feature amount on the 0th line and the label are combined.\n\n\n0\u884c\u76ee\u306e\u7279\u5fb4\u91cf\u3068label\u306e\u7d44\u307f\u5408\u308f\u305b\u304c\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b","f565d17a":"![image.png](attachment:cd563819-fd4d-49b5-8098-893b10a186ca.png)","c5a3dd95":"![image.png](attachment:ca855327-bec4-4383-8489-a591b4f805ce.png)"}}