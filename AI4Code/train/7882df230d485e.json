{"cell_type":{"387996fd":"code","108c839c":"code","699ff674":"code","bfec13ce":"code","9fe2c012":"code","4f6aad84":"code","d10b3459":"code","f5cb4f32":"code","d89761ea":"code","01ac96a6":"code","40b8d457":"code","009ae7b5":"code","2a2b3676":"code","4b063731":"code","6b6d1988":"code","36084bd5":"code","1c25a986":"code","9042308b":"code","23f1f89f":"code","8a142436":"code","490f56fc":"code","82698a67":"code","466cef8b":"code","7ef63584":"code","5ad3da8f":"code","684d81d6":"code","2120739e":"code","c76c88ca":"code","0416586e":"code","ca6c330d":"code","de3c78a7":"code","7bd2cb36":"code","59488b7e":"code","b6e519b9":"code","bba3e50a":"code","6e1bebc7":"code","567792d1":"code","24513ba2":"code","1aa0be41":"code","1abb056a":"code","8f7296f3":"code","f949f192":"code","83ea1121":"code","3eed18a7":"markdown","95589c83":"markdown","d0a96f91":"markdown","25397d9b":"markdown","8debff6f":"markdown","0744bdc2":"markdown","9e898739":"markdown","01f12bab":"markdown","c5275c67":"markdown","09f2b77b":"markdown","87fe578f":"markdown","e7a161cf":"markdown","9df7a49d":"markdown","f7095006":"markdown","52b375d3":"markdown","0a7b79f4":"markdown"},"source":{"387996fd":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_test_copy = df_test.copy()\ndf_train.head()\n\n","108c839c":"df_train.describe().transpose()","699ff674":"df_train.isnull().sum()","bfec13ce":"df_train.shape","9fe2c012":"df_train.Survived.value_counts(normalize=True)","4f6aad84":"sns.countplot(x=\"Survived\", data = df_train)","d10b3459":"sns.countplot(x=\"Sex\", hue=\"Survived\", data = df_train)","f5cb4f32":"sns.countplot(x=\"Pclass\", hue=\"Survived\", data= df_train)","d89761ea":"sns.catplot(x=\"Sex\", y=\"Age\", data = df_train, hue=\"Survived\", palette=[\"y\", \"r\"], kind=\"violin\", split=True)","01ac96a6":"def mappy(df_train):\n    df_train[\"Sex\"] = df_train.Sex.map({ \"female\" : 1, \"male\" : 0}).astype(int)","40b8d457":"mappy(df_train)\ndf_train.head()","009ae7b5":"mappy(df_test)\ndf_test.head()","2a2b3676":"sns.catplot(x=\"Pclass\", y=\"Age\", data=df_train, hue=\"Survived\", kind=\"violin\", split=True)","4b063731":"df_train.groupby(\"Pclass\").median()","6b6d1988":"def fill_age(cols):\n\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 37\n        \n        elif Pclass == 2:\n            return 29\n        \n        else:\n            return 24\n        \n    else:\n        \n        return Age","36084bd5":"df_train[\"Age\"] = df_train[[\"Age\", \"Pclass\"]].apply(fill_age, axis=1)","1c25a986":"sns.catplot(x=\"Sex\", y=\"Age\", col=\"Pclass\", data = df_train, hue= \"Survived\", kind=\"box\", palette=['r', 'g'])","9042308b":"df_train[\"Embarked\"] = df_train.Embarked.fillna(df_train.Embarked.mode()[0])","23f1f89f":"df_train.Embarked.isnull().sum()","8a142436":"df_test.isnull().sum()","490f56fc":"df_train.drop(\"Cabin\", axis=1, inplace=True)\ndf_test.drop(\"Cabin\", axis=1, inplace=True)","82698a67":"df_test.groupby(\"Pclass\").median()","466cef8b":"def fill_age_test(cols):\n\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 42\n        \n        elif Pclass == 2:\n            return 26.5\n        \n        \n        else:\n            return 24\n        \n    else:\n        \n        return Age","7ef63584":"df_test[\"Age\"] = df_train[[\"Age\", \"Pclass\"]].apply(fill_age, axis=1)","5ad3da8f":"df_test.isnull().sum()","684d81d6":"df_test[\"Fare\"]= df_test.Fare.fillna(df_test.Fare.median())","2120739e":"sns.countplot(x=\"SibSp\", hue=\"Survived\", data=df_train)","c76c88ca":"df_train[[\"SibSp\", \"Survived\"]].groupby(\"SibSp\").mean()","0416586e":"df_train[[\"Parch\", \"Survived\"]].groupby(\"Parch\").mean()","ca6c330d":"for dataset in [df_train, df_test]:\n    dataset[\"Title\"] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)\npd.crosstab(df_train[\"Sex\"], df_train[\"Title\"]).transpose()","de3c78a7":"for dataset in [df_train, df_test]:\n    dataset[\"Title\"]= dataset.Title.replace(['Lady', 'Countess', 'Capt', 'Col', \n                                             'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ndf_train[['Title', 'Survived']].groupby('Title').mean()","7bd2cb36":"title_mapping = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5}\nfor dataset in [df_train, df_test]:\n    dataset['Title'] = dataset.Title.map(title_mapping)\n    dataset['Title'] = dataset.Title.fillna(0)\ndf_train.head()","59488b7e":"df_train[\"Alone\"]=0\ndf_train.loc[(df_train[\"SibSp\"]==0) & (df_train[\"Parch\"]==0), \"Alone\"]=1\n\ndf_test[\"Alone\"]=0\ndf_test.loc[(df_test[\"SibSp\"]==0) & (df_test[\"Parch\"]==0), \"Alone\"]=1","b6e519b9":"for dataset in [df_train, df_test]:\n    dataset.drop(['Name', 'Ticket', 'SibSp', 'Parch'], axis=1, inplace=True)","bba3e50a":"df_train.head()","6e1bebc7":"def mapping(frame):\n    \n    \n    \n    frame['Embarked'] = frame.Embarked.map({'S' : 0 , 'C': 1 , 'Q':2}).astype(int)\n    \n    \n    \n    frame.loc[frame.Age <= 16 , 'Age'] = 0\n    frame.loc[(frame.Age >16) & (frame.Age<=32) , 'Age'] = 1\n    frame.loc[(frame.Age >32) & (frame.Age<=48) , 'Age'] = 2\n    frame.loc[(frame.Age >48) & (frame.Age<=64) , 'Age'] = 3\n    frame.loc[(frame.Age >64) & (frame.Age<=80) , 'Age'] = 4\n    \n    \n    frame.loc[(frame.Fare <= 7.91) , 'Fare'] = 0\n    frame.loc[(frame.Fare > 7.91) & (frame.Fare <= 14.454) , 'Fare'] = 1\n    frame.loc[(frame.Fare > 14.454) & (frame.Fare <= 31) , 'Fare'] = 2\n    frame.loc[(frame.Fare > 31) , 'Fare'] = 3","567792d1":"mapping(df_train)\ndf_train.head()","24513ba2":"mapping(df_test)\ndf_test.head()","1aa0be41":"for dataset in [df_train, df_test]:\n    dataset[\"age*pclass\"]= dataset.Age * dataset.Pclass\ndf_train.head()","1abb056a":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler","8f7296f3":"x_train = df_train.drop(\"Survived\", axis=1)\ny_train = df_train[\"Survived\"]\nx_test = df_test.copy()\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","f949f192":"models = [DecisionTreeClassifier(), LogisticRegression(), SVC(), RandomForestClassifier()]\nmodels_names = ['DecisionTreeClassifier', 'LogisticRegression', 'SVC', 'RandomForestClassifier']\n\naccuracy =[]\nfor model in models:\n    clf = model\n    clf.fit(x_train, y_train)\n    accuracy.append(round(clf.score(x_train, y_train)*100, 2))\ncompare = pd.DataFrame({\"algorithm\": models_names, \"accuracy\": accuracy})\ncompare","83ea1121":"params_dict={'criterion':['gini','entropy'],'max_depth':[5.21,5.22,5.23,5.24,5.25,5.26,5.27,5.28,5.29,5.3]}\n\nclf_dt=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=params_dict,scoring='accuracy', cv=5)\n\nclf_dt.fit(x_train,y_train)\n\npred=clf_dt.predict(x_test)\n\nd = {\"PassengerId\": df_test_copy.PassengerId, \"Survived\": pred}\nanswer = pd.DataFrame(d)\nanswer.to_csv(\"submission_4.csv\", index=False)\n    ","3eed18a7":"finding median not mean there are many outliers so median is proper selection \nnow we will feel the age according to the pclass \nso that our model will more accurately recognise the pattern in dataset","95589c83":"analyse the graph carefully \nthis graph shows the different age groups according to pclass who have survived \nthis will help us in filling the null values of age ","d0a96f91":"this graph shows the people who have no siblings have died more \nthat is people who were travelling alone have died more as compared to family with more no of members ","25397d9b":"analysing survived with respect to gender\nthis shows that female survived are more than man ","8debff6f":"now we will use name column to analyse \nby doing this we want to find pattern of survival with respect to name ","0744bdc2":"the age scenario is the key feature as it will help us in filling the null value of age column\nas there are 177 null value so we will fill the age group with respect to corresponding pclass","9e898739":"now we will focus on the siblings and parch section ","01f12bab":"### finding out the nullvalues","c5275c67":"importing some important library ","09f2b77b":"count of people who died are more the survived","87fe578f":"analysing survived with respect to passenger class\nwe found that passenger of third class have died more","e7a161cf":"This is my first notebook so please forgive my mistakes I will correct those mistakes \nplease **upvote** if it helped you a little.\nThank you :)","9df7a49d":"# titanic\n* this is for the beginners who have just started.\n* this basics problem will make you understand the following:\n    1.  how to analyse the data\n    2. visualization and outcome of plotting the graph \n    3. how visualization help in feature engineering part.\nlets get started...........","f7095006":"This is the overfitting condition and this can be removed through proper cross validation technique so \nthis is your task to do..","52b375d3":"this shows that name whic","0a7b79f4":"people having siblings 1 or 2 have more chances of survival"}}