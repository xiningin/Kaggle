{"cell_type":{"dbc8b815":"code","10bef3d2":"code","676e9bdd":"code","73fb9cf9":"code","0508c61f":"code","16fbd0a4":"code","fd85678b":"code","1559bb90":"code","0fe0d3dc":"code","84f3f576":"code","30dfe859":"code","cc952ae0":"code","b3f76793":"code","8cf39cac":"code","73d6c05f":"markdown","2cd05851":"markdown","55ce74da":"markdown","f7117d7d":"markdown","afc667b0":"markdown","0250440a":"markdown"},"source":{"dbc8b815":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n!mkdir \"\/kaggle\/working\/labels\"\n!cp -r \"\/kaggle\/input\/car-plate-detection\/images\" \"\/kaggle\/working\/images\"","10bef3d2":"imgs = os.listdir('\/kaggle\/working\/images')\nimgs_train, imgs_val = train_test_split(imgs, test_size=0.05)\n\ndf = pd.read_csv('..\/input\/car-plate-get-annotation-info-from-xml\/annotation.csv')","676e9bdd":"import yaml\ncwd = '\/kaggle\/working\/'\ndata = dict(\n    train =  cwd + 'train.txt',\n    val   =  cwd + 'val.txt',\n    nc    = 1,\n    names = ['licence'],\n)\n\nwith open(cwd + 'bgr.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\nwith open(cwd + 'train.txt', 'w') as f:\n    for path in imgs_train:\n        f.write(cwd+'images\/'+path+'\\n')\nwith open(cwd + 'val.txt', 'w') as f:\n    for path in imgs_val:\n        f.write(cwd+'images\/'+path+'\\n')","73fb9cf9":"for file in imgs:\n    file = file.split('.')[0]\n    bboxs = []\n    for _,row in df[df['file'] == file].iterrows():\n        bbox = [str(0), str(row['Xcent']), str(row['Ycent']), str(row['boxW']), str(row['boxH'])]\n        bbox = ' '.join(bbox)\n        bboxs.append(bbox)\n    with open(cwd+'labels\/'+file+'.txt', 'w') as f:\n        bboxs = '\\n'.join(bboxs)\n        f.write(bboxs)","0508c61f":"!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd yolov5\n%pip install -qr requirements.txt\n\nfrom yolov5 import utils\ndisplay = utils.notebook_init()","16fbd0a4":"!pip install -q wandb --upgrade\n\nimport wandb\nwandb.login(anonymous='must')","fd85678b":"!python train.py --img 1280\\\n--batch 10\\\n--epochs 50\\\n--data \/kaggle\/working\/bgr.yaml\\\n--weights yolov5m6.pt","1559bb90":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/yolov5\/runs\/train\/exp\/results.png'))","0fe0d3dc":"fig, ax = plt.subplots(2, 2, figsize = (2*8,2*5), constrained_layout = True)\nfor row in range(2):\n    ax[row][0].imshow(plt.imread(f'\/kaggle\/working\/yolov5\/runs\/train\/exp\/val_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'\/kaggle\/working\/yolov5\/runs\/train\/exp\/val_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'\/kaggle\/working\/yolov5\/runs\/train\/exp\/val_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'\/kaggle\/working\/yolov5\/runs\/train\/exp\/val_batch{row}_pred.jpg', fontsize = 12)\nplt.show()","84f3f576":"import torch\nfrom PIL import Image\n\nCKPT_PATH = '\/kaggle\/working\/yolov5\/runs\/train\/exp\/weights\/best.pt'\nyolov5 = torch.hub.load('\/kaggle\/working\/yolov5',\n                        'custom',\n                        path=CKPT_PATH,\n                        source='local',\n                        force_reload=True)\n\n'confidence: ' + str(yolov5.conf)","30dfe859":"imgs = os.listdir('\/kaggle\/input\/car-plate-detection\/images')\n\npred_df = pd.DataFrame()\nfor pth in imgs:\n    img = Image.open('\/kaggle\/input\/car-plate-detection\/images\/' + pth).convert('RGB')\n    img = np.asarray(img)\n    pred = yolov5(img, size=1280, augment=False)\n    for i, row in pred.pandas().xyxy[0].iterrows():\n        if row['confidence'] < yolov5.conf: break\n        row['path'] = pth\n        pred_df = pred_df.append(row)\npred_df = pred_df.reset_index()","cc952ae0":"pred_df","b3f76793":"import pytesseract\n\nfor i, row in pred_df.iterrows():\n    img = '\/kaggle\/input\/car-plate-detection\/images\/' + row['path']\n    img = Image.open(img).convert('RGB')\n    img = np.asarray(img)\n    img_cropped = img[int(row['ymin']):int(row['ymax']), int(row['xmin']):int(row['xmax'])]\n    text = pytesseract.image_to_string(img_cropped)\n    pred_df.loc[i, 'text_detected'] = text","8cf39cac":"pred_df","73d6c05f":"# Predict","2cd05851":"# OCR with pyTesseRACt","55ce74da":"# YOLOv5","f7117d7d":"# Dataset","afc667b0":"# Train","0250440a":"# Visualize"}}