{"cell_type":{"7e3b2fae":"code","d3b4eecf":"code","c2da8df7":"code","787ee99e":"code","6a210155":"code","9bc863a4":"code","a22ad238":"code","7855104d":"code","c445a10c":"code","39c09f84":"code","2d84e961":"code","ab89513e":"code","6d58ae05":"code","ef102b95":"code","3cd0e588":"code","2737e553":"code","8a35a4d3":"code","c91a2cab":"code","7abe76ba":"code","1484370b":"code","2e4d25ca":"code","034fd3b6":"code","c8634823":"markdown","bec9ebd1":"markdown","1f81899c":"markdown","a2b2586c":"markdown","cae0ccf3":"markdown","14447adc":"markdown","00a1487c":"markdown","7d51905c":"markdown","f0083c9a":"markdown","18b01c78":"markdown","dddfae55":"markdown","39ad7227":"markdown","1871eb7b":"markdown","3c667f5c":"markdown","8a3fb8ea":"markdown","0a3f7284":"markdown"},"source":{"7e3b2fae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # advance data visualization\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3b4eecf":"# we will create 4 seperate data-frame for each company and load our csv file in that.\ndf1=pd.read_csv('\/kaggle\/input\/wind-power-generation\/TenneTTSO.csv')\ndf2=pd.read_csv('\/kaggle\/input\/wind-power-generation\/50Hertz.csv')\ndf3=pd.read_csv('\/kaggle\/input\/wind-power-generation\/TransnetBW.csv')\ndf4=pd.read_csv('\/kaggle\/input\/wind-power-generation\/Amprion.csv')\n","c2da8df7":"# Now we will see the shape of our data\nprint(\"columns in dataframe1=\",df1.shape[1],\" And rows are=\",df1.shape[0])\nprint(\"columns in dataframe2=\",df2.shape[1],\" And rows are=\",df2.shape[0])\nprint(\"columns in dataframe3=\",df3.shape[1],\" And rows are=\",df3.shape[0])\nprint(\"columns in dataframe4=\",df4.shape[1],\" And rows are=\",df4.shape[0])","787ee99e":"#lets print some of the rows to check data\ndf1.head(2)\n# we will not print the head part of all the 3 left data frame as it will same as first only values are different.","6a210155":"# lets check for the Total No of Numerical and categorical variable\nprint(\"Total No of Cat Features=\",sum(df1.dtypes=='object'))\nprint(\"Total No of Numr Features=\",sum(df1.dtypes=='float'))","9bc863a4":"# Lets check if our data contains any null values or not if any than we will do further analysis\ncount=0\nfor i in df1.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df1\")\n    \ncount=0\nfor i in df2.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df2\")\ncount=0   \nfor i in df3.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df3\")\ncount=0   \nfor i in df4.isnull().sum():\n    if i==1 :\n        count=1\nif(count==0):\n    print(\"No NUll Value in Df4\")","a22ad238":"# here these are the features we will extract from single dataframe\n#FOR DATA-FRAME 1\ndf1['total energy generated\/day']=df1.sum(axis=1,numeric_only=True)\ndf1['mean energy generated\/15 min']=df1.mean(axis=1,numeric_only=True)\ndf1['min energy during 15 min']=df1.min(axis=1,numeric_only=True)\ndf1['max energy during 15 minute']=df1.max(axis=1,numeric_only=True)\ndf1['0 to 6 energy generated Total']=df1.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf1['0 to 6 mean energy generated']=df1.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf1['6 to 12 energy generated Total']=df1.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf1['6 to 12 mean energy generated']=df1.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf1['12 to 18 energy generated Total']=df1.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf1['12 to 18 mean energy generated']=df1.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf1['18 to 24 energy generated Total']=df1.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf1['18 to 24 mean energy generated']=df1.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 2\ndf2['total energy generated\/day']=df2.sum(axis=1,numeric_only=True)\ndf2['mean energy generated\/15 min']=df2.mean(axis=1,numeric_only=True)\ndf2['min energy during 15 min']=df2.min(axis=1,numeric_only=True)\ndf2['max energy during 15 minute']=df2.max(axis=1,numeric_only=True)\ndf2['0 to 6 energy generated Total']=df2.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf2['0 to 6 mean energy generated']=df2.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf2['6 to 12 energy generated Total']=df2.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf2['6 to 12 mean energy generated']=df2.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf2['12 to 18 energy generated Total']=df2.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf2['12 to 18 mean energy generated']=df2.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf2['18 to 24 energy generated Total']=df2.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf2['18 to 24 mean energy generated']=df2.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 3\ndf3['total energy generated\/day']=df3.sum(axis=1,numeric_only=True)\ndf3['mean energy generated\/15 min']=df3.mean(axis=1,numeric_only=True)\ndf3['min energy during 15 min']=df3.min(axis=1,numeric_only=True)\ndf3['max energy during 15 minute']=df3.max(axis=1,numeric_only=True)\ndf3['0 to 6 energy generated Total']=df3.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf3['0 to 6 mean energy generated']=df3.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf3['6 to 12 energy generated Total']=df3.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf3['6 to 12 mean energy generated']=df3.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf3['12 to 18 energy generated Total']=df3.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf3['12 to 18 mean energy generated']=df3.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf3['18 to 24 energy generated Total']=df3.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf3['18 to 24 mean energy generated']=df3.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n#FOR DATA-FRAME 4\ndf4['total energy generated\/day']=df4.sum(axis=1,numeric_only=True)\ndf4['mean energy generated\/15 min']=df4.mean(axis=1,numeric_only=True)\ndf4['min energy during 15 min']=df4.min(axis=1,numeric_only=True)\ndf4['max energy during 15 minute']=df4.max(axis=1,numeric_only=True)\ndf4['0 to 6 energy generated Total']=df4.loc[:,'00:00:00':'05:45:00'].sum(axis=1,numeric_only=True)\ndf4['0 to 6 mean energy generated']=df4.loc[:,'00:00:00':'05:45:00'].mean(axis=1,numeric_only=True)\ndf4['6 to 12 energy generated Total']=df4.loc[:,'06:00:00':'11:45:00'].sum(axis=1,numeric_only=True)\ndf4['6 to 12 mean energy generated']=df4.loc[:,'06:00:00':'11:45:00'].mean(axis=1,numeric_only=True)\ndf4['12 to 18 energy generated Total']=df4.loc[:,'12:00:00':'17:45:00'].sum(axis=1,numeric_only=True)\ndf4['12 to 18 mean energy generated']=df4.loc[:,'12:00:00':'17:45:00'].mean(axis=1,numeric_only=True)\ndf4['18 to 24 energy generated Total']=df4.loc[:,'18:00:00':'23:45:00'].sum(axis=1,numeric_only=True)\ndf4['18 to 24 mean energy generated']=df4.loc[:,'18:00:00':'23:45:00'].mean(axis=1,numeric_only=True)\n\n# so we have extracted all these feature as i have mentioned earlier. now we will drop the 96 columns which are now not useful.","7855104d":"#lets look now howour dataframe looks\nprint(df1.shape)\ndf1.head(3)\n\n# take a look on how we have added different columns so now we will drop the earlier columns except date.","c445a10c":"# as from the above code we have extracted useful info from the data now what we will do is drop all the columns from 00:00:00 to 23:45:00\ndf1.drop(df1.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf2.drop(df2.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf3.drop(df3.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\ndf4.drop(df4.loc[:,'00:00:00':'23:45:00'],axis=1,inplace=True)\n\ndf1.head() #lets look at our table NOW.\n# we are going in a good direction as now we are done with data preprocessing and created a table \n#which will have useful info and reduced original table","39c09f84":"#one more thing left to do i.e converting our date to datetime object\ndf1['Date']=pd.to_datetime(df1['Date'])\ndf2['Date']=pd.to_datetime(df2['Date'])\ndf3['Date']=pd.to_datetime(df3['Date'])\ndf4['Date']=pd.to_datetime(df4['Date'])","2d84e961":"import plotly.express as px\n\n# first lets describe about data\ny=[df1['total energy generated\/day'].sum(),df2['total energy generated\/day'].sum(),df3['total energy generated\/day'].sum(),df4['total energy generated\/day'].sum()]\nfig,ax=plt.subplots(1,2,figsize=(15,4))\n#fig-1\nsns.barplot(y=y,x=[\"TenneTTSO\",\"50Hertz\",\"TransnetBW\",\"Amprion\"],palette=\"Blues\",ax=ax[0])\nax[0].set_ylabel(\"energy in 10^6\")\nax[0].set_title(\"Total Energy generation in 397 Days\")\n#fig-2\ny=[df1['mean energy generated\/15 min'].mean(),df2['mean energy generated\/15 min'].mean(),df3['mean energy generated\/15 min'].mean(),df4['mean energy generated\/15 min'].mean()]\nsns.barplot(y=y,x=[\"TenneTTSO\",\"50Hertz\",\"TransnetBW\",\"Amprion\"],palette=\"Reds\",ax=ax[1])\nax[1].set_ylabel(\"energy unit\")\nax[1].set_title(\"Mean Energy generation in each 15 min\")\n","ab89513e":"sns.set(rc={'axes.facecolor':'#000000', 'figure.facecolor':'white'})\nfig,ax=plt.subplots(4,1,figsize=(20,12))\n#fig-1\nsns.lineplot(x=df1['Date'],y=df1['total energy generated\/day'],color='#33ffad',ax=ax[0])\nplt.grid(False)\nax[0].set_xticks([])\nax[0].set_xlabel(\"TenneTTSO\")\nax[0].set_ylabel(\"\")\n#fig-2\nsns.lineplot(x=df2['Date'],y=df2['total energy generated\/day'],color='#80ccff',ax=ax[1])\nplt.grid(False)\nax[1].set_xticks([])\nax[1].set_ylabel(\"TOTAL ENERGY Generated\")\nax[1].set_xlabel(\"50Hertz\")\n#fig-1\nsns.lineplot(x=df3['Date'],y=df3['total energy generated\/day'],color='#ff944d',ax=ax[2])\nplt.grid(False)\nax[2].set_xticks([])\nax[2].set_xlabel(\"TransnetBW\")\nax[2].set_ylabel(\"\")\n#fig-1\nsns.lineplot(x=df4['Date'],y=df4['total energy generated\/day'],color='#ccff66',ax=ax[3])\nplt.grid(False)\nax[3].set_ylabel(\"\")\nax[3].set_xlabel(\"Amprion\")\n\n","6d58ae05":"#before moving ahead lets cut our dataset only to Total Energy generation\ndf1=df1[['Date','total energy generated\/day']]\ndf2=df2[['Date','total energy generated\/day']]\ndf3=df3[['Date','total energy generated\/day']]\ndf4=df4[['Date','total energy generated\/day']]","ef102b95":"#lets see if our data is stationery or not.\nfrom statsmodels.tsa.stattools import adfuller\ntest_result=adfuller(df1['total energy generated\/day'])","3cd0e588":"#Ho: It is non stationary\n#H1: It is stationary\n\ndef adfuller_test(sales):\n    result=adfuller(sales)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n    if result[1] <= 0.05:\n        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n    else:\n        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")","2737e553":"print(\"for df1\")\nadfuller_test(df1['total energy generated\/day'])\n","8a35a4d3":"#lets plot the autocorrelation graph\nfrom pandas.plotting import autocorrelation_plot\nautocorrelation_plot(df1['total energy generated\/day'])\nplt.show()","c91a2cab":"#lets plot the graph to find the suitable value of P and Q\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(df1['total energy generated\/day'],lags=40,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df1['total energy generated\/day'],lags=40,ax=ax2)","7abe76ba":"# p=4,d=0(as difference =0),q=1\nfrom statsmodels.tsa.arima_model import ARIMA\n#lets fit our model\nmodel=ARIMA(df1['total energy generated\/day'],order=(4,0,1))\nmodel_fit=model.fit()\nmodel_fit.summary()","1484370b":"#lets see how our model is fitted on training data\ndf1['forecast']=model_fit.predict(start=100,end=397,dynamic=True)\ndf1[['total energy generated\/day','forecast']].plot(figsize=(12,8))","2e4d25ca":"#lets give seasonal difference of one month\nmodel=sm.tsa.statespace.SARIMAX(df1['total energy generated\/day'],order=(2, 0, 1),seasonal_order=(2,0,1,30))\nresults=model.fit()","034fd3b6":"df1['forecast']=results.predict(start=178,end=250,dynamic=True)\ndf1[['total energy generated\/day','forecast']].plot(figsize=(12,8))","c8634823":"## <font color='#1f4d40'>Data Collection\ud83d\udd2c<\/font>\n<font color='#001a33'>AS we can see from the above table that our data has 4 CSV files One for each company\ud83c\udfed<\/font>\n* <font color='#001a33'>\/kaggle\/input\/wind-power-generation\/TenneTTSO.csv<\/font>\n* <font color='#001a33'>\/kaggle\/input\/wind-power-generation\/50Hertz.csv<\/font>\n* <font color='#001a33'>\/kaggle\/input\/wind-power-generation\/TransnetBW.csv<\/font>\n* <font color='#001a33'>\/kaggle\/input\/wind-power-generation\/Amprion.csv<\/font>","bec9ebd1":"### <font color='#001a33'>AS You can see that our Simple Arima Does not work well It just draw the straight line\ud83d\udd87. i.e orange line....we will fit it with Seasonal Arima\ud83c\udf25<\/font>\n","1f81899c":"<h1 align=\"center\"><font color='#1f4d40'>Time Series Modelling\u23f0<\/font><\/h1>","a2b2586c":"#### <font color='#1f4d40'>SO WE ARE DONE WITH INFO ABOUT DATA AND DATA COLLECTION PROCESS\u2139. BEFORE MOVING AHEAD LETS CONCLUDE SOME POINTS.\ud83d\udc46<\/font>\n* <font color='#001a33'>We have created 4 Data frame.<\/font>\n* <font color='#001a33'>There are 397 rows and 97 columns in each data.<\/font>\n* <font color='#001a33'>There is one Category Feature i.e-Date AND Rest all 96 features Are Date.<\/font>\n* <font color='#001a33'>If we look At features we found that Except date columns there are reading realeted to every 15 minutes starting from 00:00:00 to 23:45:00<\/font>\n* <font color='#001a33'>DataSet Has No Null Values.<\/font>\n","cae0ccf3":"### <font color='#001a33'>Hello\ud83d\ude4c everyone, Before moving ahead let me clear Some Steps we Gonna Follow. If You Follow step by step It will be very easy To understand.<\/font>\n* <font color='#001a33'>Introduction To Problem \ud83e\udde7<\/font>\n* <font color='#001a33'>DATA Collection And Info\ud83d\udee0 <\/font>\n* <font color='#001a33'>Data  Preprocessing\u2139<\/font>\n* <font color='#001a33'>Data Analysis\ud83d\udcca<\/font>\n* <font color='#001a33'>Model building \ud83c\udfd7<\/font>","14447adc":"## <font color='#1f4d40'>DATA PREPROCESSING AND CLEANING\ud83d\udcfd<\/font>\n### <font color='#001a33'>How we will Preprocess our DAta?\u2753<\/font>\n\n* <font color='#001a33'>We will extract only some useful info from the data. i.e. we will find total energy in a day.<\/font>\n* <font color='#001a33'>Mean Energy in a day.<\/font>\n* <font color='#001a33'>Total  energy in Each 6 hours.<\/font>\n* <font color='#001a33'>Mean  energy in Each 6 hours.<\/font>\n* <font color='#001a33'>Max  energy generation in 15 min.<\/font>\n* <font color='#001a33'>Min  energy generation in 15 min.<\/font>\n\n#### <font color='#ff4d4d'>Data Preprocessing is one of the time consuming task. SO Look each step carefully.\u26a0<\/font>\n\n","00a1487c":"### <font color='#001a33'>Why we need to check It if data is stationary or not?<\/font>\n* <font color='#001a33'>Stationary data means its mean,variance and auto correlation does not change over time<\/font>\n* <font color='#001a33'>If data is not stationary we have to bring it by doing differencing.<\/font>\n\n\n### <font color='#001a33'>How can we test if data is stationary or not?<\/font>\n* <font color='#001a33'>we can test it by adfuller test.<\/font>","7d51905c":"## <font color='#1f4d40'>Exploratory Data Analysis\ud83d\udcca<\/font>","f0083c9a":"## <font color='#1f4d40'>Introduction To Problem\ud83e\udde7<\/font>\n<font color='#001a33'>Wind power\ud83c\udf43 or wind energy is the use of wind to provide mechanical\ud83d\udee0 power through wind turbines to turn electric generators for electrical power. Wind power is a popular sustainable, renewable source of power that has a much smaller impact on the environment compared to burning fossil fuels.<\/font>\n<br>\n<font color='#001a33'>In this Notebook we will look into the wind energy generation Data of 4 company From Date-23\/09\/2019 to 18\/09\/2020.<\/font>\n<br>\n#### <font color='#1f4d40'>WHAT WE HAVE TO DO?\u2753<\/font>\n* <font color='#001a33'> Finding insights from data.\ud83d\udcc8<\/font>\n* <font color='#001a33'> Total Wind energy generation.<\/font>\n* <font color='#001a33'> Building Model to Predict future Generation<\/font>\n\n<br>\n\n#### <font color='#1f4d40'>WHAT ARE WE WAITING FOR. LETS GET STARTED.\ud83e\uddbe<\/font>\n\n\n\n","18b01c78":"<font color='#001a33'>SO We are done with it. I know this is not the best Model and i have not tuned this model. THis notebook is just to give you idea on how to deal with time series data.<\/font>\n\n### <font color='#001a33'> IF You Like This NOtebook Please give it a upvote\u2b06\ud83d\udc4d...and for comment any feedback or suggestion on how i can improve.<\/font>","dddfae55":"# <font color='#1f4d40'>MODEL BUILDING - ARIMA\ud83c\udfd7<\/font>\n<font color='#001a33'>ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data.<\/font>\n* <font color='#001a33'>About the ARIMA model the parameters used and assumptions made by the model.<\/font>\n* <font color='#001a33'>How to fit an ARIMA model to data and use it to make forecasts<\/font>\n* <font color='#001a33'>How to configure the ARIMA model on your time series problem.<\/font>\n\n","39ad7227":"* What is tell Us\n* it gives us a p value which is exponential decrease till at what point=4,so p=4\n* we will select q value as 1 as there is suddent decrese in 1","1871eb7b":"## <font color='#001a33'>Lets Conclude Some points<\/font>\n* <font color='#001a33'>As we found out that our data is stationery..lets move to further step<\/font>\n* <font color='#001a33'>If the data is non Stationery then we have to find differencing.<\/font>","3c667f5c":"### <font color='#001a33'>Lets Conclude Some Points Now.\ud83c\udff4\u200d\u2620\ufe0f<\/font>\n\n* <font color='#001a33'>We have plotted our date and the total energy genaration in that particular day<\/font>\n* <font color='#001a33'>AS we can see that is is time series data so Fitting linear regression is noyt good for its Future prediction<\/font>\n","8a3fb8ea":"### <font color='#001a33'>Fitting simple Arima Model<\/font>","0a3f7284":"### Final Thoughts on Autocorrelation and Partial Autocorrelation\n* Identification of an AR model is often best done with the PACF.\n* For an AR model, the theoretical PACF \u201cshuts off\u201d past the order of the model. The phrase \u201cshuts off\u201d means that in theory the partial autocorrelations are equal to 0 beyond that point. Put another way, the number of non-zero partial autocorrelations gives the order of the AR model. By the \u201corder of the model\u201d we mean the most extreme lag of x that is used as a predictor.\n* Identification of an MA model is often best done with the ACF rather than the PACF.\n\n* For an MA model, the theoretical PACF does not shut off, but instead tapers toward 0 in some manner. A clearer pattern for an MA model is in the ACF. The ACF will have non-zero autocorrelations only at lags involved in the model.\n\n* p,d,q p AR model lags d differencing q MA lags"}}