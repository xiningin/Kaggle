{"cell_type":{"e2511173":"code","d1ee00bb":"code","c609a3e9":"code","504c8f27":"code","b5e0251c":"code","18bf86c0":"code","ef6f371a":"code","89d6d29f":"code","88271b99":"code","07927baa":"markdown","76014f78":"markdown","8be57be3":"markdown","fa8319f0":"markdown","ac3086f8":"markdown","315e6ef6":"markdown","9e554496":"markdown","dca3dca5":"markdown","532485b6":"markdown","d4df5d92":"markdown","a5012300":"markdown","e71ee67f":"markdown","90308b49":"markdown","b525af4d":"markdown","edd55b02":"markdown","2e975362":"markdown","b07029d2":"markdown"},"source":{"e2511173":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport math\nimport matplotlib.pyplot as plt","d1ee00bb":"def get_hash(fpath, hash_length):\n    dim = int(math.sqrt(hash_length))+1    \n    r_str=''    \n    img=cv2.imread(fpath,0)        # read image as gray scale image\n    img=cv2.resize(img, (dim,dim), interpolation = cv2.INTER_NEAREST)\n    img=img.flatten()\n    list2=list(img) \n    for col in range (0,len(list2)-1):\n        if(list2[col]>list2[col+1]):\n            value=str(1)\n        else:\n            value=str(0)\n        r_str=r_str + value   \n    return r_str","c609a3e9":"def match(value1, value2, difference):\n    length=len(value1)\n    mismatch=0\n    for i in range(0, length):\n        if value1[i] !=value2[i]:\n            mismatch = mismatch  + 1\n            if mismatch>difference:\n                return False\n    return True","504c8f27":"def find_duplicates(hash_dict, difference):\n    dup_dict={}\n    key_list=[]\n    for key,value in tqdm(hash_dict.items()):\n        dup_list=[]\n        for key2,value2 in hash_dict.items():\n            if key != key2 and key not in key_list and key2 not in key_list:\n                if match(value,value2,difference):\n                    dup_list.append(key2)\n                    dup_dict[key]=dup_list\n                    if key2 not in key_list:\n                        key_list.append(key2)                    \n        if key not in key_list:\n            key_list.append(key)\n        \n        #print('key= {0}  key2= {1} match= {2} key list = {3}'.format(key,key2,m,key_list))\n    return dup_dict","b5e0251c":"def find_duplicate(source_dir,distance):\n    sense_list=[0, 3,6,9,12,21,27,32,45,64] \n    difference=sense_list[sensitivity] # hash length is 256 if there are less than distance differences in the hash\n    # then images are considered duplicates\n    hash_length= 256\n    f_list=[] # will be a list of files ( full path) that are not duplicates of each other\n    duplicate_files_list = [] # will contain a list of duplicate filepaths\n    dup_list =[] # list of files that are duplicates of files in f_list\n    class_list= os.listdir(source_dir)    \n    for klass in class_list: # iterate through classes \n        class_path=os.path.join (source_dir, klass)\n        if os.path.isdir(class_path):\n            flist=os.listdir(class_path)\n            for f in flist:\n                fpath=os.path.join(class_path,f)\n                f_list.append(fpath) # list of all filepaths in the source_dir\n        else:\n            for f in class_list:\n                fpath=os.path.join(source_dir,f)\n                f_list.append(fpath)\n            break\n    hash_dict={}\n    for fpath in tqdm(f_list): # iterate through the list of filepaths\n        hash_dict[fpath]=get_hash(fpath,hash_length)  # store the hash in a dictionary with key-filepath and value=hash\n    # now go the dictionary and create a new dictionary of duplicate files\n    # dup_dict the key is a fileppath and the values are filepaths of images that are duplicates of the key filepath\n    dup_dict=find_duplicates(hash_dict, difference)\n    if len(dup_dict)<1:\n        print('No duplicate images were found in ', source_dir, '\\n')            \n    else:\n        dup_count = 0\n        for key, values in dup_dict.items():\n            dup_count += len(values) \n            for fpath in values:\n                f_list.remove(fpath)\n                duplicate_files_list.append(fpath)\n                \n        print('\\n', dup_count, ' duplicate images were detected and removed from the list of good_files')\n        #print (dup_dict)\n    return f_list, duplicate_files_list  ","18bf86c0":"display_list=[]\nplt.figure(figsize=(20,8))\nbaseball_dir=r'..\/input\/duplicate-image-detection\/dup\/baseball'\nbaseball_list=sorted(os.listdir(baseball_dir))\nbasketball_dir=r'..\/input\/duplicate-image-detection\/dup\/basketball'\nbasketball_list=sorted(os.listdir(basketball_dir))\nfor directory in [baseball_dir, basketball_dir]:\n    flist= sorted(os.listdir(directory))    \n    for f in flist:\n        fpath=os.path.join(directory,f)\n        img=plt.imread(fpath)\/255\n        display_list.append(img)\nfor i in range(len(display_list)):    \n    plt.axis('off')\n    img=display_list[i]\n    plt.subplot(2,6,i+1)\n    plt.imshow(img)\n    if i <=5:\n        plt.title('baseball-' +baseball_list[i], color='yellow', fontsize=12)        \n    else:\n        plt.title('basketball-' +basketball_list[i-6], color='yellow', fontsize=12)         \nplt.show()","ef6f371a":"source_dir=r'..\/input\/duplicate-image-detection\/dup'\nsensitivity = 0 # level 0 will require duplicate to be an EXACT copy of each other\n# ranges from 0 to 9 determines how close in similarity the images have to be to be\n# considered duplicate images.\nhash_length=256\ngood_files, duplicate_files=find_duplicate(source_dir,sensitivity)\nfor i in range(len(duplicate_files)):\n    print (duplicate_files[i])","89d6d29f":"sensitivity = 5 # at level of 5 should detect images as duplicate if they are very similar to each other\ngood_files, duplicate_files=find_duplicate(source_dir,sensitivity)\nfor i in range(len(duplicate_files)):\n    print (duplicate_files[i])","88271b99":"sensitivity = 8 # at level of 8 should detect images as duplicate if they are somewhat similar to each other\ngood_files, duplicate_files=find_duplicate(source_dir,sensitivity)\nfor i in range(len(duplicate_files)):\n    print (duplicate_files[i])","07927baa":"<a id=\"demo1\"><\/a>\n# <center>Run detector with sensivity=0 (Detect Exact Duplicates)<\/center>","76014f78":"### This program searches through a dirctory- Source_dir and uses a difference hash to find similar images.\n#### author: Gerry Piosenka\n#### First it goes through all the files in the directory and appends the file to a list called f_list. \n#### Then for the files in the f_list it reads in the image defined by the file path in\n#### gray scale, and resizes it into a vector of length  257. It then performs a difference hash on the vector.\n#### The file name along with the hash is stored in a dictionary  hash_dict, with the key=file path and the value = the hash.\n#### Once the dictionary is made the dictionary is then processed to compare the hash values of each image to the hash values\n#### of all the other images. The results are stored in a dictionary called dup_dict\n#### The comparison calculates the number of bit differences between the two hashes. If the number of differences is less than an\n#### an integer value called difference than the images are flagged as being duplicates. The value of difference is determine by the\n#### function parameter distance. The smaller the value of distance the closer (on a pixel by pixel basis) the two images have to be\n#### in order to be flagged as duplicates. A distance level 0 requires images to be exact duplicate (pixel by pixel) of each other.\n","8be57be3":"<a id=\"example\"><\/a>\n# <center>Show use of find_duplicate on example data set<\/center>","fa8319f0":"Notice with sensitivity of 5 image 5.jpg was detected as a duplicate of baseball 5.bmp","ac3086f8":"<a id=\"display\"><\/a>\n# <center>Display the baseball and basketball images<\/center>","315e6ef6":"<a id=\"distance\"><\/a>\n# <center>Define Function to find distance between hash code<\/center>","9e554496":"<a id=\"dup\"><\/a>\n# <center>Define Function to create dictionary of duplicate images<\/center>","dca3dca5":"Example dataseet dup contains 2 classes,  baseballs and basketballs. Baseball set has no duplicate images\nbasketbal class has 4 images 1,2,3 and 4 which are exact copies (exact because BMP format is used)\nof images 1,2,3 and 4 in the baseball class. Image 5.bmp in basketball is image 5 from baseball but it has been resized to 1\/2\nits original size. Also in basketball image 5.jpg is a copy of image 5.bmp from baseball. While they 'LOOK' identical visually\nthey will have a different due to effects of jpg compression.\nWe will run the duplicate detection with different levels of sensitivity to demonstrate the results.","532485b6":"## [1. Import Needed Modules](#import) ##\n## [2. Create code for Generation of Hash code](#hash) ## \n## [3. Define Function to find distance between hash codes](#distance) ##\n## [4. Define Function to create dictionary of duplicate images](#dup) ## \n## [5. Define main function to detect duplicate images](#main) ## \n## [6. Display baseball and basketball images](#display) ## \n## [7. Run detector with sensivity=0 (Detect Exact Duplicates)](#demo1) ## \n## [8. Run detector with sensivity=5 (Detect Almost Duplicates)](#demo2) ## \n## [9. Run detector with sensivity=8 (Detect Similar)](#demo3) ## ","d4df5d92":"One of the problems in doing classification on a data set is to insure there are no duplicate images between  \nthe train data set and either the test data set or the validation data set. If there are duplicates then the  \nvalues you get for valiidation accuracy or test set accuracy are not valid because the images have already  \nbeen processed as part of the training set. So you want to compare images in the validation set to images in  \nthe training set and do the same for images in the test set. Alternatively if you start out with a single data set  \nthat you will later split into a training set, a test set and a validation set you want to eliminate all  \nduplicate images in the single data set before you split it. The function below detects any duplicate images within  \na source_dir (including it's subdirectories) and returns a list of filepaths in which there are no duplicate images.  \nThe duplicate detection process is NOT flawless. For example is you take an image and resize it they are no longer  \nexact duplicates but from the standpoint of an AI network they essentially are duplicates. So the function has a  \nparameter called sensitivity. By setting the value to a level like 5 resized images will be flagged as duplicates.  \nA note about image identity: Many images that visually appear identical are not EXACTLY identical. For example if  \nyou have and image 1.jpg and copy it as 2.jpg they in general are not EXACTLY identical due to artifacts of  \ncompression. If you use a non compression format like BMP however they will be identical in the sense they have  \nthe same hash value.","a5012300":"<a id=\"main\"><\/a>\n# <center>Define  main function to Detect Duplicate Images<\/center>","e71ee67f":"<a id=\"hash\"><\/a>\n# <center>Define Function to generate hash code for the Image File<\/center>","90308b49":"Notice at level 8 basketball image 5.bmp( a 50% size image of baseball 5.bmp) was detected as a duplicate. ","b525af4d":"<a id=\"demo2\"><\/a>\n# <center>Run detector with sensivity=5 (Detect 'Similar' images)<\/center>","edd55b02":"<a id=\"demo3\"><\/a>\n# <center>Run detector with sensivity=8 (Detect 'Similar' images)<\/center>","2e975362":"notice at sensitivity level=0 images must be EXACT duplicates, so the 4 exact copies in basketball were\ndetected as duplicate. NOTE: 5.bmp in basketball was not detected as it is baseball 5.bmp at half size.\nAlso NOTE 5.jpg was not detected even though they look visually identical they are in different formats\nand therefore have a different hash value","b07029d2":"<a id=\"import\"><\/a>\n# <center>Import required modules<\/center>"}}