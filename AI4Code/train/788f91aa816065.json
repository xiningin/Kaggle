{"cell_type":{"815602ed":"code","b1b58da0":"code","a214aa6d":"code","66a0fe9e":"code","52534c10":"code","6f1217a3":"markdown","bcafbd30":"markdown","2ccd065b":"markdown","58e21c1f":"markdown","af73fd2c":"markdown","d1726ce3":"markdown","4ae79989":"markdown","d0996d4d":"markdown","bf3576bc":"markdown","9f3759da":"markdown","840d8c6f":"markdown","c0b75a55":"markdown","842dc142":"markdown","10a7b1b3":"markdown","3985afb2":"markdown","e1133760":"markdown","ad9299fd":"markdown","1aa363b5":"markdown","0667789e":"markdown","5cc5d342":"markdown","66a1c07c":"markdown","b420a0b0":"markdown","2b6278be":"markdown","74002dfd":"markdown"},"source":{"815602ed":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\ntrain = pd.read_csv(\"..\/input\/random-linear-regression\/train.csv\") \ntest = pd.read_csv(\"..\/input\/random-linear-regression\/test.csv\") \ntrain = train.dropna()\ntest = test.dropna()\ntrain.head()\n\n# Model PLot and Accuracy\nX_train = np.array(train.iloc[:, :-1].values)\ny_train = np.array(train.iloc[:, 1].values)\nX_test = np.array(test.iloc[:, :-1].values)\ny_test = np.array(test.iloc[:, 1].values)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = model.score(X_test, y_test)\n\nplt.plot(X_train, model.predict(X_train), color='green')\nplt.show()\nprint(accuracy)","b1b58da0":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n#Data is used the same as LGB\nX = train.drop(columns=['item_price', 'item_id']) \ny = train['item_price']\nX.head()\n\n# Model & Accuracy\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nlasso.fit(X, y)\nr2_score(lasso.predict(X), y)","a214aa6d":"import sklearn\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import r2_score\nfrom statistics import mode\n\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest  = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain.head()\n\n\nports = pd.get_dummies(train.Embarked , prefix='Embarked')\ntrain = train.join(ports)\ntrain.drop(['Embarked'], axis=1, inplace=True)\ntrain.Sex = train.Sex.map({'male':0, 'female':1})\ny = train.Survived.copy()\nX = train.drop(['Survived'], axis=1) \nX.drop(['Cabin'], axis=1, inplace=True) \nX.drop(['Ticket'], axis=1, inplace=True) \nX.drop(['Name'], axis=1, inplace=True) \nX.drop(['PassengerId'], axis=1, inplace=True)\nX.Age.fillna(X.Age.median(), inplace=True)\n\n#Model and Accuracy\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(max_iter = 500000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\naccuracy = model.score(X_test, y_test)\nprint(accuracy)","66a0fe9e":"# Support Vector Machine","52534c10":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\ndata_svm = pd.read_csv(\"..\/input\/svm-classification\/UniversalBank.csv\")\ndata_svm.head()\n\n\n\n#model & accuuracy\n\nX = data_svm.iloc[:,1:13].values\ny = data_svm.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\naccuracies.mean()","6f1217a3":"### Applications:\nLasso regression algorithms have been widely used in financial networks and economics. In finance, its application is seen in forecasting probabilities of default and Lasso-based forecasting models are used in assessing enterprise wide risk framework. Lasso-type regressions are also used to perform stress test platforms to analyze multiple stress scenarios.  ","bcafbd30":"![image.png](attachment:image.png)","2ccd065b":"# What is Machine Learning ?\n\n### The capability of Artificial Intelligence systems to learn by extracting patterns from data is known as Machine Learning. It is a kind of AI that enables computers to think and learn on their own.\n![image.png](attachment:image.png)\n","58e21c1f":"### Applications:\n* Studying engine performance from test data in automobiles\n* Least squares regression is used to model causal relationships between parameters in biological systems\n* OLS regression can be used in weather data analysis\n* Linear regression can be used in market research studies and customer survey results analysis\n* Linear regression is used in observational astronomy commonly enough. A number of statistical tools and methods are used in astronomical data analysis, and there are entire libraries in languages like Python meant to do data analysis in astrophysics.","af73fd2c":"![image.png](attachment:image.png)","d1726ce3":"# Supervised Machine Learning\nSupervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output.\n\nY = f(X)\n\nThe goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (Y) for that data.\nIt is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the training data and is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of performance.\n\nSupervised learning problems can be further grouped into **regression ** and **classification** problems.\n\n#### Classification: A classification problem is when the output variable is a category, such as \u201cred\u201d or \u201cblue\u201d or \u201cdisease\u201d and \u201cno disease\u201d.\n\n#### Regression: A regression problem is when the output variable is a real value, such as \u201cdollars\u201d or \u201cweight\u201d.\n\nSome common types of problems built on top of classification and regression include recommendation and time series prediction respectively.\n\nSome popular examples of supervised machine learning algorithms are:\n\nLinear regression for regression problems.\nRandom forest for classification and regression problems.\nSupport vector machines for classification problems.","4ae79989":"# Type of Machine Learning\n\n\n1. Supervised Machine Learning\n2. Unsupervised Machine Learning\n3. Reinforcement Machine Learning ","d0996d4d":"2. **Lasso Regression**: *LASSO stands for Least Absolute Selection Shrinkage Operator wherein shrinkage is defined as a constraint on parameters. The goal of lasso regression is to obtain the subset of predictors that minimize prediction error for a quantitative response variable. The algorithm operates by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward a zero.*\n\n      *Variables with a regression coefficient equal to zero after the shrinkage process are excluded from the model. Variables with non-zero regression coefficients variables are most strongly associated with the response variable. Explanatory variables can be either quantitative, categorical or both. This lasso regression analysis is basically a shrinkage and variable selection method and it helps analysts to determine which of the predictors are most important.*","bf3576bc":"# Difference between Traditional Programming and Machine learning\n\n![image.png](attachment:image.png)","9f3759da":"## I will discuss all technique in details in another notebook to understand everything more efficiently.","840d8c6f":"# Table of Content\n1. Introduction to Machine Learning\n2. Real life relation with Machine learning\n3. Supervised Learning: Regression\n4. Feature Engineering\n5. Supervised Learning: Classification\n\n        ","c0b75a55":"Please note : Obviously I am collecting the best part to understand ML from various sources.","842dc142":"# Features of Machine Learning\n* Machine Learning is computing-intensive and generally requires a large amount of training data.\n* It involves repetitive training to improve the learning and decision making of algorithms.\n* As more data gets added, Machine Learning training can be automated for learning new data patterns and adapting its algorithm.","10a7b1b3":"## Supervised learning uses regression techniques and classification algorithms to develop predictive models.","3985afb2":"![image.png](attachment:image.png)","e1133760":"# 3.**Logistic regression:** \n*One of the most commonly used regression techniques in the industry which is extensively applied across fraud detection, credit card scoring and clinical trials, wherever the response is binary has a major advantage. One of the major upsides is of this popular algorithm is that one can include more than one dependent variable which can be continuous or dichotomous. The other major advantage of this supervised machine learning algorithm is that it provides a quantified value to measure the strength of association according to the rest of variables. Despite its popularity, researchers have drawn out its limitations, citing a lack of robust technique and also a great model dependency.*\n\n\n\n\n### Applications: \nToday enterprises deploy Logistic Regression to predict house values in real estate business, customer lifetime value in the insurance sector and are leveraged to produce a continuous outcome such as whether a customer can buy\/will buy scenario.","ad9299fd":"# Unsupervised Machine Learning\nUnsupervised learning is where you only have input data (X) and no corresponding output variables.\n\nThe goal for unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data.\n\nThese are called unsupervised learning because unlike supervised learning above there is no correct answers and there is no teacher. Algorithms are left to their own devises to discover and present the interesting structure in the data.\n\nUnsupervised learning problems can be further grouped into clustering and association problems.\n\n#### Clustering: A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior.\n#### Association:  An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy X also tend to buy Y.\nSome popular examples of unsupervised learning algorithms are:\n\nk-means for clustering problems.\nApriori algorithm for association rule learning problems.","1aa363b5":"# Reinforcement Machine Learning\nReinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.\n\n![image.png](attachment:image.png)","0667789e":"# Work in Progress :-)","5cc5d342":"# Application of Supervised Machine Learning\n* Bioinformatics\n* Quantitative structure\n* Database marketing\n* Handwriting recognition\n* Information retrieval\n* Learning to rank\n* Information extraction\n* Object recognition in computer vision\n* Optical character recognition\n* Spam detection\n* Pattern recognition","66a1c07c":"# Machine learning performance Steps\n1. * Problem Definition\n1. * Analyse Data\n1. * Prepare Data\n1. * Evaluate Algorithm\n1. * Improve Results\n1. * Present Results","b420a0b0":"# Support Vector Machine:\nSupport Vector Machines are perhaps one of the most popular and talked about machine learning algorithms.It is primarily a classier method that performs classification tasks by constructing hyperplanes in a multidimensional space that separates cases of different class labels. SVM supports both regression and classification tasks and can handle multiple continuous and categorical variables\n\nExample: One class is linearly separable from the others like if we only had two features like Height and Hair length of an individual, we\u2019d first plot these two variables in two dimensional space where each point has two co-ordinates","2b6278be":"# Machine Learning Technique\n\n![image.png](attachment:image.png)","74002dfd":"1. **Simple Linear Regression model:** *Simple linear regression is a statistical method that enables users to summarise and study relationships between two continuous (quantitative) variables. Linear regression is a linear model wherein a model that assumes a linear relationship between the input variables (x) and the single output variable (y). Here the y can be calculated from a linear combination of the input variables (x). When there is a single input variable (x), the method is called a simple linear regression. When there are multiple input variables, the procedure is referred as multiple linear regression.*\n\n![image.png](attachment:image.png)"}}