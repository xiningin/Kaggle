{"cell_type":{"028ff7e9":"code","5b3f6da9":"code","43adcd47":"code","80efa5f1":"code","1ffc3715":"code","7c637e74":"code","9bef3a22":"code","2b436fae":"code","f609a0b0":"code","8a0a39f8":"code","2b59450d":"code","e818ba91":"code","fbc80487":"code","e7087810":"code","1f81d0d1":"code","2b80c6e3":"code","e62186c7":"code","6203542c":"code","13b893db":"code","c66b45a1":"code","5ace3089":"code","50ceead8":"code","55e3c756":"code","fe7f6699":"code","146185ef":"code","36ce823b":"code","775b6092":"code","45fc86c8":"code","c345ce29":"code","a1bf07b5":"code","09c54d32":"code","4755ae22":"code","f79f9ed2":"code","bd8f7379":"code","12eff14f":"code","500fd1d3":"code","bba9aa82":"code","0fd17642":"code","88147ba6":"code","b0ebbfe1":"code","24a579f2":"code","e37c22bd":"code","f9f0342c":"code","65551fc9":"code","052b4b7f":"code","8b01e59d":"code","2fd414fc":"code","c18d45a9":"code","d7b5cc20":"code","afba705d":"code","54d60b6c":"code","1d9f2652":"code","c45e7a8d":"code","26adee2d":"code","08628b88":"code","59bad422":"code","36f1ea08":"code","227c7b01":"code","2ab0f467":"code","b17ef06d":"code","6bd80b1c":"code","7fffebdc":"code","6544a9ed":"code","276ae577":"code","33543946":"code","216a31df":"code","a34054a9":"code","f03a2f26":"code","842663eb":"code","a2b5e507":"code","ae62df3e":"code","27198f30":"code","2d149d3a":"code","2f78c9a1":"code","6852e4b7":"code","49428a84":"code","add15f4e":"code","0687e6e8":"markdown","79876052":"markdown","e0ad3135":"markdown","9f18e0f4":"markdown","cf671613":"markdown","1db86316":"markdown","a64906ed":"markdown","d599b386":"markdown","1aec2a07":"markdown","c171ec8b":"markdown","1e07de0a":"markdown","be34c178":"markdown","0058dd3a":"markdown","3ba9741b":"markdown","8f242be8":"markdown","2b6bae92":"markdown","0f192394":"markdown","f2722dee":"markdown","a898445b":"markdown","30248642":"markdown","88ecc69e":"markdown","8b9314f9":"markdown","f41b4e55":"markdown","262de850":"markdown","bbb59027":"markdown","88ee290c":"markdown","3d1a6a22":"markdown","8cc668c8":"markdown","dced45fd":"markdown"},"source":{"028ff7e9":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","5b3f6da9":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","43adcd47":"# Importing Pandas and NumPy\nimport pandas as pd, numpy as np, seaborn as sns,matplotlib.pyplot as plt","80efa5f1":"pd.set_option('display.max_columns', None)","1ffc3715":"# Importing all datasets\nchurn_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/churn_data.csv\")\nchurn_data.head()","7c637e74":"customer_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/customer_data.csv\")\ncustomer_data.head()","9bef3a22":"internet_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/internet_data.csv\")\ninternet_data.head()","2b436fae":"# Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')","f609a0b0":"# Final dataframe with all predictor variables\ntelecom = pd.merge(df_1, internet_data, how='inner', on='customerID')","8a0a39f8":"# Let's see the head of our master dataset\ntelecom.head()","2b59450d":"# Let's check the dimensions of the dataframe\ntelecom.shape","e818ba91":"# let's look at the statistical aspects of the dataframe\ntelecom.describe()","fbc80487":"# Let's see the type of each column\ntelecom.info()","e7087810":"#The varaible was imported as a string we need to convert it to float\n# telecom['TotalCharges'] = telecom['TotalCharges'].astype(float) \ntelecom.TotalCharges = pd.to_numeric(telecom.TotalCharges, errors='coerce')","1f81d0d1":"telecom.info()","2b80c6e3":"\nplt.figure(figsize=(20,40))\nplt.subplot(10,2,1)\nax = sns.distplot(telecom['tenure'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nplt.subplot(10,2,2)\nax = sns.countplot(x='PhoneService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,4)\nax =sns.countplot(x='PaperlessBilling', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,5)\nax =sns.countplot(x='PaymentMethod', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,6)\nax =sns.countplot(x='Churn', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,7)\nax =sns.countplot(x='gender', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,8)\nax =sns.countplot(x='SeniorCitizen', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,9)\nax =sns.countplot(x='Partner', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,10)\nax =sns.countplot(x='Dependents', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,11)\nax =sns.countplot(x='MultipleLines', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,12)\nax =sns.countplot(x='InternetService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,13)\nax =sns.countplot(x='OnlineSecurity', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,14)\nax =sns.countplot(x='OnlineBackup', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,15)\nax =sns.countplot(x='DeviceProtection', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,16)\nax =sns.countplot(x='TechSupport', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,17)\nax =sns.countplot(x='StreamingTV', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,18)\nax =sns.countplot(x='StreamingMovies', data=telecom)\nax.set_ylabel('# of Customers')\nplt.subplot(10,2,19)\nax = sns.distplot(telecom['MonthlyCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('MonthlyCharges')\nplt.subplot(10,2,20)\nax = sns.distplot(telecom['TotalCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('TotalCharges');","e62186c7":"sns.pairplot(telecom)\nplt.show()","6203542c":"plt.figure(figsize=(25, 10))\nplt.subplot(1,3,1)\nsns.boxplot(x = 'tenure', y = 'Churn', data=telecom)\nplt.subplot(1,3,2)\nsns.boxplot(x = 'MonthlyCharges', y = 'Churn', data=telecom)\nplt.subplot(1,3,3)\nsns.boxplot(x = 'TotalCharges', y = 'Churn', data=telecom)\nplt.show()","13b893db":"# List of variables to map\n\nvarlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\ntelecom[varlist] = telecom[varlist].apply(binary_map)","c66b45a1":"telecom.head()","5ace3089":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(telecom[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom, dummy1], axis=1)","50ceead8":"telecom.head()","55e3c756":"# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n\n# Creating dummy variables for the variable 'MultipleLines'\nml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')\n# Dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'], 1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ml1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineSecurity'.\nos = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')\nos1 = os.drop(['OnlineSecurity_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,os1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineBackup'.\nob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')\nob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ob1], axis=1)\n\n# Creating dummy variables for the variable 'DeviceProtection'. \ndp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,dp1], axis=1)\n\n# Creating dummy variables for the variable 'TechSupport'. \nts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ts1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingTV'.\nst =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,st1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingMovies'. \nsm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,sm1], axis=1)","fe7f6699":"telecom.head()","146185ef":"# We have created dummies for the below variables, so we can drop them\ntelecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)","36ce823b":"# Checking for outliers in the continuous variables\nnum_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]","775b6092":"# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])","45fc86c8":"# Adding up the missing values (column-wise)\ntelecom.isnull().sum()","c345ce29":"print('No. of Null Records for TotalCharges:',telecom.TotalCharges.isnull().sum())","a1bf07b5":"print('No. of Records for TotalCharges:',len(telecom))","09c54d32":"print('No. of non Records for TotalCharges:',len(telecom)-telecom.TotalCharges.isnull().sum())","4755ae22":"# Checking the percentage of missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","f79f9ed2":"telecom = telecom.dropna()\ntelecom = telecom.reset_index(drop=True)\n\n","bd8f7379":"# Checking percentage of missing values after removing the missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","12eff14f":"from sklearn.model_selection import train_test_split","500fd1d3":"# Putting feature variable to X\nX = telecom.drop(['Churn','customerID'], axis=1)\n\nX.head()","bba9aa82":"# Putting response variable to y\ny = telecom['Churn']\n\ny.head()","0fd17642":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","88147ba6":"from sklearn.preprocessing import StandardScaler","b0ebbfe1":"scaler = StandardScaler()\n\nX_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n\nX_train.head()","24a579f2":"X_test[['tenure','MonthlyCharges','TotalCharges']] = scaler.transform(X_test[['tenure','MonthlyCharges','TotalCharges']])\n\nX_test.head()","e37c22bd":"### Checking the Churn Rate\nchurn = (sum(telecom['Churn'])\/len(telecom['Churn'].index))*100\nchurn","f9f0342c":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","65551fc9":"# Let's see the correlation matrix \nplt.figure(figsize = (25,25))        # Size of the figure\nsns.heatmap(telecom.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","052b4b7f":"plt.figure(figsize=(10,8))\ntelecom.corr()['Churn'].sort_values(ascending = False).plot(kind='bar');","8b01e59d":"X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                       'StreamingTV_No','StreamingMovies_No'], 1)\nX_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                         'StreamingTV_No','StreamingMovies_No'], 1)","2fd414fc":"plt.figure(figsize = (25,25))\nsns.heatmap(X_train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","c18d45a9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nmodel = RandomForestClassifier()\n","d7b5cc20":"# number of trees used\nprint('Number of Trees used : ', model.n_estimators)","afba705d":"# fit the model with the training data\nmodel.fit(X_train,y_train)","54d60b6c":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","1d9f2652":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","c45e7a8d":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif.tail()","26adee2d":"features_to_remove = vif.loc[vif['VIF'] >= 4.99,'Features'].values\nfeatures_to_remove = list(features_to_remove)\nprint(features_to_remove)","08628b88":"X_train = X_train.drop(columns=features_to_remove, axis = 1)\nX_train.head()","59bad422":"X_test = X_test.drop(columns=features_to_remove, axis = 1)\nX_test.head()","36f1ea08":"# fit the model with the training data\nmodel.fit(X_train,y_train)","227c7b01":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","2ab0f467":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","b17ef06d":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6bd80b1c":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train, predict_train )\nprint(confusion)\n","7fffebdc":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","6544a9ed":"# Let's see the sensitivity of our model\ntrainsensitivity= TP \/ float(TP+FN)\ntrainsensitivity","276ae577":"# Let us calculate specificity\ntrainspecificity= TN \/ float(TN+FP)\ntrainspecificity","33543946":"# Calculate false postive rate - predicting churn when customer does not have churned\nprint(FP\/ float(TN+FP))","216a31df":"# Positive predictive value \nprint (TP \/ float(TP+FP))","a34054a9":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","f03a2f26":"draw_roc(y_train,predict_train)","842663eb":"#Looking at the confusion matrix again","a2b5e507":"from sklearn.metrics import precision_score, recall_score\nprecision_score(y_train,predict_train)","ae62df3e":"recall_score(y_train,predict_train)","27198f30":"# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data\\n\\n',predict_test)","2d149d3a":"confusion2 = metrics.confusion_matrix(y_test, predict_test )\nprint(confusion2)","2f78c9a1":"# Let's check the overall accuracy.\ntestaccuracy= accuracy_score(y_test,predict_test)\ntestaccuracy","6852e4b7":"# Let's see the sensitivity of our lmodel\ntestsensitivity=TP \/ float(TP+FN)\ntestsensitivity","49428a84":"# Let us calculate specificity\ntestspecificity= TN \/ float(TN+FP)\ntestspecificity","add15f4e":"# Let us compare the values obtained for Train & Test:\nprint(\"Train Data Accuracy    :{} %\".format(round((trainaccuracy*100),2)))\nprint(\"Train Data Sensitivity :{} %\".format(round((trainsensitivity*100),2)))\nprint(\"Train Data Specificity :{} %\".format(round((trainspecificity*100),2)))\nprint(\"Test Data Accuracy     :{} %\".format(round((testaccuracy*100),2)))\nprint(\"Test Data Sensitivity  :{} %\".format(round((testsensitivity*100),2)))\nprint(\"Test Data Specificity  :{} %\".format(round((testspecificity*100),2)))","0687e6e8":"### Step 4: Test-Train Split","79876052":"# VIF","e0ad3135":"#### Converting some binary variables (Yes\/No) to 0\/1","9f18e0f4":"### Step 1: Importing and Merging Data","cf671613":"### Step 6: Looking at Correlations","1db86316":"Now we don't have any missing values","a64906ed":"## Precision and Recall","d599b386":"#### Dropping highly correlated dummy variables","1aec2a07":"#### Checking for Missing Values and Inputing Them","c171ec8b":"### Step 2: Inspecting the Dataframe","1e07de0a":"#### Checking for Outliers","be34c178":"### Step 11: Making predictions on the test set","0058dd3a":"# Plotting the ROC Curve","3ba9741b":"## Telecom Churn Case Study\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.","8f242be8":"#### Combining all data files into one consolidated dataframe","2b6bae92":"From the distribution shown above, you can see that there no outliers in your data. The numbers are gradually increasing.","0f192394":"#### Dropping the repeated variables","f2722dee":"#### Checking the Correlation Matrix","a898445b":"# Final Observation:","30248642":"# VIF","88ecc69e":"After dropping highly correlated variables now let's check the correlation matrix again.","8b9314f9":"It means that 11 * 100\/7043 = 0.1561834%, best is to remove these observations from the analysis","f41b4e55":"### Step 5: Feature Scaling","262de850":"We have almost 27% churn rate","bbb59027":"Now you can see that you have all variables as numeric.","88ee290c":"# EDA","3d1a6a22":"#### For categorical variables with multiple levels, create dummy features (one-hot encoded)","8cc668c8":"# Random Forest","dced45fd":"### Step 7: Model Building\nLet's start by splitting our data into a training set and a test set."}}