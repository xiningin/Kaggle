{"cell_type":{"67c24af6":"code","479093a6":"code","bab2f7f7":"code","86c31339":"code","53fa2ab4":"code","fb35cbae":"code","cc94055b":"code","f2884a79":"code","9381da2c":"code","3510ef4d":"code","1f4af2bf":"code","e7561f56":"code","4ed8825e":"code","cf2e0477":"code","648db3ea":"code","9475f550":"code","3fc93fa4":"code","c4f27cd8":"markdown","723a3350":"markdown","df76c27f":"markdown","cc0a16d9":"markdown","dd5c0033":"markdown","1ef88633":"markdown","066eb62f":"markdown"},"source":{"67c24af6":"! apt-get install -y libsndfile-dev","479093a6":"import glob\nimport os\n\n# For manipulating audio\nimport librosa\nimport librosa.display as disp\nimport soundfile\nimport numpy as np\nimport pandas as pd\n\n# For machine learning models\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.multiclass import unique_labels\nimport optuna\n\n# For displaying\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nimport seaborn as sns\nimport tqdm\n\ninput_folder = \"\/kaggle\/input\/\"","bab2f7f7":"sample_audio_path = input_folder + 'Actor_01\/03-01-03-02-02-02-01.wav'\n\n# play a sample audio\nipd.Audio(sample_audio_path)","86c31339":"# Load the audio file as an array without resampling\naudio, sr = librosa.load(sample_audio_path, sr=None)\n\n####### Visualizing Waveform #######\nplt.figure(figsize=(14, 5))\nplt.title(\"Waveform\")\ndisp.waveplot(audio, sr=sr)\n\n\n####### Zooming in in the Waveform #######\nplt.figure(figsize=(14, 5))\nplt.title(\"Zoomed in Waveform\")\nplt.plot(audio[30000:30050])\n\n\n####### Visualizing Spectogram #######\nX = librosa.stft(audio)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 5))\nplt.title(\"Spectogram\")\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","53fa2ab4":"# Extract features (mfcc, chroma, mel) from a sound file\ndef extract_feature(file_name, mfcc, chroma, mel):\n    with soundfile.SoundFile(file_name) as sound_file:\n        X = sound_file.read(dtype=\"float32\")\n        sample_rate = sound_file.samplerate\n        if chroma:\n            stft = np.abs(librosa.stft(X))\n        result = np.array([])\n        if mfcc:\n            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n            result = np.hstack((result, mfccs))\n        if chroma:\n            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n            result = np.hstack((result, chroma))\n        if mel:\n            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n            result = np.hstack((result, mel))\n            \n    return result","fb35cbae":"emotions={\n  '01':'neutral',\n  '02':'calm',\n  '03':'happy',\n  '04':'sad',\n  '05':'angry',\n  '06':'fearful',\n  '07':'disgust',\n  '08':'surprised'\n}","cc94055b":"def load_data(test_size=0.2):\n    x,y=[],[]\n    for file in glob.glob(input_folder + \"Actor_*\/*.wav\"):\n        file_name = os.path.basename(file)\n        emotion = emotions[file_name.split(\"-\")[2]]\n        feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n        x.append(feature)\n        y.append(emotion)\n    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)","f2884a79":"x_train, x_test, y_train, y_test = load_data(test_size=0.25)","9381da2c":"print(f'Number of training data: {x_train.shape[0]}')\nprint(f'Number of testing data: {x_test.shape[0]}')\nprint(f'Number of features extracted: {x_train.shape[1]}')","3510ef4d":"# Scale data\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","1f4af2bf":"mlp_model = MLPClassifier(activation='relu',\n                         solver='sgd',\n                         hidden_layer_sizes=100,\n                         alpha=0.839903176695813,\n                         batch_size=150,\n                         learning_rate='adaptive',\n                         max_iter=100000)","e7561f56":"# Fit mlp model\nmlp_model.fit(x_train,y_train)","4ed8825e":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14, model='clf'):\n    \"\"\"\n    Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix,\n    as a seaborn heatmap. \n    \"\"\"\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, ax=ax, fmt=\"d\", cmap=plt.cm.Oranges)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n        \n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    # fix for mpl bug that cuts off top\/bottom of seaborn viz\n    b, t = plt.ylim() \n    b += 0.5 \n    t -= 0.5 \n    plt.ylim(b, t) \n    plt.show()","cf2e0477":"def get_model_performance(model):\n    y_pred = model.predict(x_test)\n    accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n    # Print the accuracy\n    print(\"\\nModel:{}    Accuracy: {:.2f}%\".\n          format(type(model).__name__ , accuracy*100))\n    \n    # Print Confusion Matrix\n    print_confusion_matrix(confusion_matrix(y_test, y_pred), unique_labels(y_test, y_pred), model=model)","648db3ea":"# Get Accuracy of individual models\nget_model_performance(mlp_model)","9475f550":"# def objective_mlp(trial):\n\n#     params = {\n#         'activation': trial.suggest_categorical('activation', ['logistic', 'tanh', 'relu']),\n#         'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n#         'hidden_layer_sizes':trial.suggest_int('hidden_layer_sizes', 100, 300, 1500),\n#         'alpha': trial.suggest_uniform('alpha', 0.001, 0.99),\n#         'batch_size':trial.suggest_int('batch_size', 150, 256, 300), \n#         'learning_rate': trial.suggest_categorical('learning_rate', ['adaptive', 'constant', 'invscaling']),\n#         'max_iter': 1000\n#         }\n  \n#     model = MLPClassifier(**params, random_state = 22) \n    \n#     model.set_params(**params)\n\n#     return np.mean(cross_val_score(model, x_train, y_train, cv=5, scoring='accuracy'))","3fc93fa4":"# study = optuna.create_study(direction='maximize')\n# study.optimize(objective_mlp, n_trials=10)","c4f27cd8":"## Make Necessary Installation and Imports","723a3350":"## Evaluate Model","df76c27f":"## Extract Features","cc0a16d9":"## Visualize Data","dd5c0033":"## Hyperparameter Tuning\n\n> To be done","1ef88633":"## Prepare and load data","066eb62f":"## Define and Train Model"}}