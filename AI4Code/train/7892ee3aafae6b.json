{"cell_type":{"20e2d741":"code","603d367c":"code","f871a2f0":"code","5e13ebd8":"code","0cf30bd8":"code","f2f236b8":"code","3d78478a":"code","a58283c0":"code","c9f639b3":"markdown","c7942a35":"markdown","38fda694":"markdown","92df59ce":"markdown","3efc4c4d":"markdown","c62774c9":"markdown","4ea9bce9":"markdown","2da32324":"markdown"},"source":{"20e2d741":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import tensor\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrSheduler\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport pandas as pd\nimport torch as th\n%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport scipy as sci","603d367c":"dataRawTrain = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ndataRawTest = pd.read_csv('..\/input\/fashion-mnist_test.csv')\n\ndataTrain = np.array(dataRawTrain.iloc[:,1:]).astype('uint8')\ndataTrain = dataTrain.reshape(-1, 1, 28, 28)\n","f871a2f0":"targetTrain = np.array(dataRawTrain.iloc[:,:1])\nzz = np.zeros([len(targetTrain), 10])\nfor i, d in enumerate(targetTrain):\n    zz[i][d.squeeze()] = 0.66\ntargetTrain = zz\n\ndataTest = np.array(dataRawTest.iloc[:,1:])\ndataTest = dataTest.reshape(-1, 1, 28, 28)\n\ntargetTest = np.array(dataRawTest.iloc[:,:1])\nzz = np.zeros([len(targetTest), 10])\nfor i, d in enumerate(targetTest):\n    zz[i][d.squeeze()] = 0.66\ntargetTest = zz\n\n","5e13ebd8":"for i in range(3):\n    plt.matshow(dataTrain[i][0], cmap='rainbow')\n    plt.colorbar()\n    plt.suptitle('class: {}'.format(targetTrain[i]))\n    \nfor i in range(3):    \n    plt.matshow(dataTest[i][0], cmap='rainbow')\n    plt.colorbar()\n    plt.suptitle('class: {}'.format(targetTest[i]))\nplt.show()","0cf30bd8":"from torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torchvision import transforms\n\ndataTrainT = torch.from_numpy(dataTrain).float() \/ np.std(dataTrain) - np.mean(dataTrain)\n# dataTrainT = torch.from_numpy(dataTrain).float() \/ 255.0 - 0.5\ntargetTrainT = torch.from_numpy(targetTrain).float()\nprint('train data size: {}'.format(dataTrainT.shape))\n\ndataTestT = torch.from_numpy(dataTest).float() \/ np.std(dataTest) - np.mean(dataTest)\n# dataTestT = torch.from_numpy(dataTest).float() \/  255.0 - 0.5\ntargetTestT = torch.from_numpy(targetTest).float()\nprint('test data size: {}'.format(dataTestT.shape))\n\n# processing function for trained data\ndef processImgBatch(batch):\n    outBatchData = []\n    outBatchTarget = []\n    for i, (img, target) in enumerate(batch):\n        outBatchData.append(img)\n        outBatchTarget.append(target)\n    outTensorData = th.stack(outBatchData)\n    outTensorTarget = th.stack(outBatchTarget)\n    return [outTensorData, outTensorTarget]\n\ndataTrainArch = TensorDataset(dataTrainT, targetTrainT)\nloaderTrain = DataLoader(dataTrainArch, shuffle=True, batch_size=64, pin_memory=True, collate_fn=processImgBatch)\n\ndataTestArch = TensorDataset(dataTestT, targetTestT)\nloaderTest = DataLoader(dataTestArch, shuffle=False, batch_size=1000, pin_memory=True, collate_fn=processImgBatch)\n","f2f236b8":"class NetMNIST2(nn.Module):\n    flag = False\n\n    def __init__(self):\n        super(NetMNIST2, self).__init__()\n        \n        # convolution 1\n        self.bn0 = nn.BatchNorm2d(1)\n        self.conv00 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu00 = nn.PReLU()\n        self.conv0 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu0 = nn.PReLU()\n        self.pool0 = nn.MaxPool2d(2)\n        self.drop0 = nn.Dropout2d()\n        \n        # convolution 2\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv10 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu10 = nn.PReLU()\n        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu1 = nn.PReLU()\n        self.pool1 = nn.MaxPool2d(2)\n        self.drop1 = nn.Dropout2d()\n\n        # convolution 3\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv20 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu20 = nn.PReLU()\n        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu2 = nn.PReLU()\n        self.pool2 = nn.MaxPool2d(2)\n        self.drop2 = nn.Dropout2d()\n\n        # full connection layer 1\n        self.bn3 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(32*6*6, 10)\n        self.fc1Prelu = nn.PReLU()\n        \n        # full connection layer 2\n        self.fc2 = nn.Linear(10, 10)\n        \n    # direct computation\n    def forward(self, x):\n        x = self.bn0(x)\n        x = self.conv00(x)\n        x = self.relu00(x)\n        x = self.conv0(x)\n        x = self.relu0(x)\n        x = self.pool0(x)\n        x = self.drop0(x)\n\n        x = self.bn1(x)\n        x = self.conv10(x)\n        x = self.relu10(x)\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n        x = self.drop1(x)\n\n        x = self.bn2(x)\n        x = self.conv20(x)\n        x = self.relu20(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.pool2(x)\n        x = self.drop2(x)\n        \n#         show input parameter\n#         print(x.shape)\n        x = self.bn3(x)\n        x = self.fc1(x.view(x.size(0), -1))\n        x = self.fc1Prelu(x)\n        x = torch.nn.functional.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x\n\n# network initialization\nnet = NetMNIST2().cuda()\n# show network\nprint(net)","3d78478a":"optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-5)\ncriterion = F.kl_div\n\ndef train(model, optimizer, criterion, dataLoader):\n    model.train()\n    for i, (data, target) in enumerate(dataLoader):\n        dataCUDA, targetCUDA = Variable(data).cuda(), Variable(target.float()).cuda()\n        optimizer.zero_grad()\n        outModel = model(dataCUDA)\n        loss = criterion(outModel, targetCUDA)\n        loss.backward()\n        optimizer.step()\n    return loss\n\n\ndef test(model, dataLoader):\n    model.eval()\n    fit = 0.0\n\n    for i, (data, target) in enumerate(dataLoader):\n        dataCUDA, targetCUDA = Variable(data).cuda(), Variable(target).cuda()\n        outModel = model(dataCUDA)\n        pred = outModel.data.max(1)[1]\n        targetMaxIndex = targetCUDA.data.max(1)[1]     \n        fit += pred.eq(targetMaxIndex).cpu().sum()\n#     calculation accuracy\n    acc = float(fit.cpu().numpy() \/ float(len(dataLoader.dataset)))\n    return acc\n\n\nlossProgress = []\nfor e in range(50):\n    lossTrain = train(net, optimizer, criterion, loaderTrain)\n    accTest = test(net, loaderTest)\n    lossProgress.append(accTest)\n    print('Epoch: {}   acc: {}   loss: {}'.format(e, accTest, lossTrain))\n    \nplt.plot(lossProgress)","a58283c0":"from sklearn.metrics import confusion_matrix\nX = np.empty([0], dtype=np.int16)\nY = np.empty([0], dtype=np.int16)\nfor i, (data, target) in enumerate(loaderTest):\n    dataCUDA, targetCUDA = Variable(data).cuda(), Variable(target).cuda()\n    outModel = net(dataCUDA)\n    Y = np.append(Y, outModel.data.max(1)[1].cpu().numpy())\n    X = np.append(X, targetCUDA.data.max(1)[1].cpu().numpy())\n    \nfrom matplotlib.ticker import MultipleLocator\nlabels = [str(x) for x in range(10)]\nconfMatrix = confusion_matrix(X.reshape(-1), Y.reshape(-1))\n\nimport seaborn as sns\nax= plt.subplot()\nsns.heatmap(confMatrix, annot=True, fmt='d', ax = ax, cmap='plasma')\n\nax.set_xlabel('Predicted')\nax.set_ylabel('Target')\nax.set_title('Confusion Matrix')\nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)\n\n\n","c9f639b3":"Show database","c7942a35":"## Confusion matrix calulate","38fda694":"Train network","92df59ce":"Network","3efc4c4d":"Load data from csv","c62774c9":"Data normalisation and create pyTorch data loader","4ea9bce9":"**Generate target output**\n\n2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n\n6 -> [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n\n...","2da32324":"Import library"}}