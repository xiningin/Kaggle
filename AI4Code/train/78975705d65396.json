{"cell_type":{"d1a7026d":"code","adb09da2":"code","6801c2b8":"code","6042f507":"code","12b423d3":"code","20924676":"code","7a28f2fd":"code","1946871e":"code","ed3b8f2d":"code","35f4b30a":"code","70f80c88":"code","0b74708b":"code","eaff7f08":"code","9d6a44f9":"code","509da92c":"code","f6637916":"code","6197ffd4":"markdown","f4566125":"markdown","2bc9432a":"markdown","304d4ed7":"markdown","ddc69f83":"markdown"},"source":{"d1a7026d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","adb09da2":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport math\nimport random\nimport albumentations as A\n\nimport tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt","6801c2b8":"!pip install keras","6042f507":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\" in Gray Scale\",\"..\/input\/facelandmark-for-fer\/content\/data_2_extract\/surprise\/**\")","12b423d3":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[25:50]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Drooping in Gray Scale\",\"..\/input\/facelandmark-for-fer\/content\/data_2_extract\/angry\/**\")","20924676":"from tqdm import tqdm\nfrom PIL import Image as Img","7a28f2fd":"#Code by Nagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/generate-realistic-human-face-using-gan\n\nPIC_DIR = f'..\/input\/facelandmark-for-fer\/content\/data_2_extract\/angry\/'\n\nIMAGES_COUNT = 1125\n\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) \/\/ 2\n\nWIDTH = 128\nHEIGHT = 128\n\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic))","1946871e":"#Code by Nagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/generate-realistic-human-face-using-gan\n\n#Display first 25 images\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","ed3b8f2d":"#Codes by Yaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/monet-eda-and-visualization-techniques\n\ndef visualize_images(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    image_names = all_names[:n_images]   \n    if is_random:\n        image_names = random.sample(all_names, n_images)\n            \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    \n    plt.show()","35f4b30a":"neutral_PNG_PATH = '..\/input\/facelandmark-for-fer\/content\/data_2_extract\/neutral\/'","70f80c88":"visualize_images(neutral_PNG_PATH, 9)","0b74708b":"def batch_visualization(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    \n    image_names = all_names[:n_images]\n    if is_random:\n        image_names = random.sample(all_names, n_images)\n    \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.axis(\"off\")\n        \n    plt.show()","eaff7f08":"batch_visualization(neutral_PNG_PATH, 1, is_random=True, figsize=(5, 5))","9d6a44f9":"batch_visualization(neutral_PNG_PATH, 4, is_random=True, figsize=(10, 10))","509da92c":"batch_visualization(neutral_PNG_PATH, 9, is_random=True)","f6637916":"batch_visualization(neutral_PNG_PATH, 16, is_random=True)","6197ffd4":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:orange;\">FER: Facial Expression Recognition<\/b><\/h1><\/center>","f4566125":"Large datasets for model training, GPU is too slow. It requires TPU for model training. Since my CPU is awful, don't expect any FER. Just enjoy the cool images.\n\nThe data was collected and extracted by https:\/\/github.com\/GiangVu0912 a student at Coderschool.","2bc9432a":"It was suppose to make Facial expression recognition. Though the many Notebooks I found had csv files to apply the angry, surprise, sad, contempt,disgust,fear,happy. And that Dataset has only that Super cool images. Therefore, I'll wait to see any other kaggler making the expected FER (Facial Expression Recognition)  I tried to use pip install FER however the images resulted in empty brackets.","304d4ed7":"To view more techniques go to:\n\nCodes by Yaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/monet-eda-and-visualization-techniques\n\nNagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/generate-realistic-human-face-using-gan\n\nAnd https:\/\/www.kaggle.com\/mpwolke\/rijksmuseum-augmentation\n\n\n#I'll try that FER (Facial Expression Recognition) when I got a decent wi-fi\nhttps:\/\/www.kaggle.com\/shawon10\/ck-facial-expression-detection","ddc69f83":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcR4_h3U75aiyoC_nncvIOs_P2JAySmiOxs44A&usqp=CAU)ic.unicamp.br"}}