{"cell_type":{"87f5c8aa":"code","e8fbd783":"code","2f22581f":"code","25dd1263":"code","7937fb37":"code","d0422209":"code","bdb164f8":"code","36a7431c":"code","731e3a9c":"code","4a2044b2":"code","4ebdd050":"code","18321ebf":"code","a7b82f15":"code","32f09af2":"code","c8deb723":"code","f5ad7167":"code","ee60034a":"code","21d7617e":"code","937e7bf2":"code","86a7f841":"code","e8295a8c":"code","56f3b338":"code","35b50c71":"code","00152e40":"code","5e01a4bc":"code","9e72fd8b":"code","2a76c155":"code","aa082b6e":"code","6bea6e41":"code","051439db":"code","5e91aeda":"code","86dc7286":"code","e5063ff9":"code","005b622f":"code","cbb96c0a":"code","dcfdccf4":"code","80e25f05":"code","130edbd8":"code","3c7a5f6e":"code","5f77df92":"code","bc3b4b60":"code","2f7d080f":"code","1683bdf7":"code","41cb35ba":"code","7e666dfb":"code","848c450a":"code","36c92d38":"code","c2c30bb9":"code","6872f8d1":"code","5591f633":"code","d6e504e3":"code","9e1614cc":"code","54e3ca34":"code","d695a06d":"code","698cb32e":"code","c86637ce":"code","665a5a5c":"code","424884af":"code","32687cf0":"code","746e787f":"code","cdc9cfec":"code","f2f8359e":"code","87a7e7ed":"code","5b6078be":"code","1f22f64a":"code","c3baf824":"code","608c8325":"code","ec96fc04":"code","9ad6e7d8":"code","dc8b1650":"markdown","e98cc28f":"markdown","23dc86a0":"markdown","878c1a48":"markdown","1db0265d":"markdown","cf6533c9":"markdown","3f73da93":"markdown","27156548":"markdown","337e6fd2":"markdown","710487f0":"markdown","e78a6b77":"markdown","9bf07b97":"markdown","80569b9f":"markdown","c6992ed1":"markdown","5d0dfc9b":"markdown","8fa97889":"markdown","eb576e75":"markdown","f8044c82":"markdown","c2cef2c1":"markdown","944c3638":"markdown","d578b0f3":"markdown","da40985a":"markdown","ad347f59":"markdown","85c0ad21":"markdown","494cdea4":"markdown","67acad17":"markdown","08f315ad":"markdown","ee4227f3":"markdown","7c59c929":"markdown","5426e17a":"markdown","c96f80be":"markdown","dd66e702":"markdown","da9ba52a":"markdown","34b81ab1":"markdown","2aab4a4a":"markdown","31d8efc8":"markdown","52c813af":"markdown","d9a1d32f":"markdown","da9da5dc":"markdown"},"source":{"87f5c8aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8fbd783":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\n\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix,log_loss,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier,StackingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nnp.random.seed(0)\nsns.set_palette('pastel')","2f22581f":"train = pd.read_csv(r'\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv(r'\/kaggle\/input\/titanic\/test.csv')\ntrain.tail()","25dd1263":"test.head()","7937fb37":"train.head()","d0422209":"print(train.shape)\nprint(test.shape)","bdb164f8":"train.info()","36a7431c":"test.info()","731e3a9c":"train.describe()","4a2044b2":"test.describe()","4ebdd050":"train.dtypes","18321ebf":"train.isnull().sum()","a7b82f15":"test.isnull().sum()","32f09af2":"avg_age_train = (train.groupby(\"Sex\")['Age']).mean()\nprint(avg_age_train)\navg_age_test = (test.groupby(\"Sex\")['Age']).mean()\nprint(avg_age_test)","c8deb723":"for i in range(len(train['Age'])):\n    if train['Age'].isnull()[i] == True and train['Sex'][i] == 'male':\n        train['Age'][i] = np.round(avg_age_train['male'],decimals=1)\n    elif train['Age'].isnull()[i] == True and train['Sex'][i] == 'female':\n        train['Age'][i] = np.round(avg_age_train['female'],decimals=1)\n        \nfor i in range(len(test['Age'])):\n    if test['Age'].isnull()[i] == True and test['Sex'][i] == 'male':\n        test['Age'][i] = np.round(avg_age_test['male'],decimals=1)\n    elif test['Age'].isnull()[i] == True and test['Sex'][i] == 'female':\n        test['Age'][i] = np.round(avg_age_test['female'],decimals=1)","f5ad7167":"train = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)","ee60034a":"print(train.shape)\nprint(test.shape)","21d7617e":"train.isnull().sum()","937e7bf2":"test.isnull().sum()","86a7f841":"Y = train['Survived']\ntrain = train.drop('Survived',axis=1)\ndata = pd.concat([train,test],axis=0)\ndata.head()","e8295a8c":"avg_fare = data.groupby(\"Sex\")['Fare'].mean()\navg_fare","56f3b338":"print(\"Index of the null value is: \",test[test['Fare'].isnull()].index.tolist())\nprint(test['Sex'][152])","35b50c71":"data['Fare'][152] = avg_fare['male']","00152e40":"data.isnull().sum()","5e01a4bc":"print(\"Number of duplicate rows in the train dataset :\",train.duplicated().sum())\nprint(\"Number of duplicate rows in the test dataset :\",test.duplicated().sum())","9e72fd8b":"Name_title_data = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint(Name_title_data)\ndata['Name_title'] = Name_title_data\ndata = data.reset_index(drop=True)\ndata.head()","2a76c155":"age_group_data = [None] * len(data['Age'])\nfor i in range(len(data['Age'])):\n    if data['Age'][i] <= 3:\n        age_group_data[i] = 'Baby'\n    elif data['Age'][i] >3 and data['Age'][i] <= 13:\n        age_group_data[i] = 'Child'\n    elif data['Age'][i] >13 and data['Age'][i] <= 19:\n        age_group_data[i] = 'Teenager'\n    elif data['Age'][i] >19 and data['Age'][i] <= 30:\n        age_group_data[i] = 'Young Adult'\n    elif data['Age'][i] >30 and data['Age'][i] <= 45:\n        age_group_data[i] = 'Middle Aged Adult'\n    elif data['Age'][i] >45 and data['Age'][i] <65:\n        age_group_data[i] = 'Adult'\n    else:\n        age_group_data[i] = 'Old'\n\ndata['age_group'] = age_group_data","aa082b6e":"np.unique(data['Name_title'])","6bea6e41":"data['Is_Married'] = 0\ndata['Is_Married'].loc[data['Name_title'] == 'Mrs'] = 1\ndata['FamSize'] = data['SibSp'] + data['Parch'] + 1\ndata['Single'] = data['FamSize'].map(lambda s: 1 if s == 1 else 0)","051439db":"data.head()","5e91aeda":"np.unique(data['Ticket'])\ntic = data.groupby('Ticket',sort=True,group_keys=True)\ngroups = list(tic.groups)\ntogther = [None] * len(data['Ticket'])\nk=0\nfor i in range(len(groups)):\n    for j in range(len(data['Ticket'])):\n        if data['Ticket'][j] == groups[i]:\n            togther[j] = i\ndata['Togther'] = togther","86dc7286":"data.head()","e5063ff9":"np.unique(data['Fare'])","005b622f":"rates = [None]*len(data['Fare'])\nfor i in range(len(data['Fare'])):\n    if data['Fare'][i]<=10:\n        rates[i] = 1\n    elif data['Fare'][i] >10 and data['Fare'][i]<=30:\n        rates[i] = 2\n    elif data['Fare'][i] >30 and data['Fare'][i]<=70:\n        rates[i] = 3\n    elif data['Fare'][i] >70 and data['Fare'][i]<=100:\n        rates[i] = 4 \n    else:\n        rates[i] = 5\ndata['Rates'] = rates","cbb96c0a":"data['Cabin_present'] = 1\ndata['Cabin_present'].loc[data['Cabin'].isnull()] = 0","dcfdccf4":"data.shape","80e25f05":"data = data.drop('Cabin',axis=1)\ndata = data.drop('Ticket',axis=1)\ndata = data.drop('Name',axis=1)\ndata = data.drop('PassengerId',axis=1)","130edbd8":"data_ohe = pd.get_dummies(data,drop_first=True)\ndata_ohe.head()","3c7a5f6e":"plt.figure(figsize=(20,20))\nsns.heatmap(train.corr(),annot=True,fmt=\"0.3f\",cmap='GnBu',linewidth=1.2,linecolor='black',square=True)\nplt.show()","5f77df92":"plt.figure(figsize=(20,20))\nsns.heatmap(test.corr(),annot=True,fmt=\"0.3f\",cmap='YlOrBr',linewidth=1.2,linecolor='black',square=True)\nplt.show()","bc3b4b60":"train['Survived'] = Y","2f7d080f":"plt.figure(figsize=(20,12))\n\nplt.subplot(2,2,1)\nsns.countplot('Sex',data=train,palette=['darkblue','red'])\nplt.title(\"Train data Sex Count\")\nplt.grid()\n\nplt.subplot(2,2,2)\nsns.countplot('Sex',data=test,palette=['teal','purple'])\nplt.title(\"Test data Sex Count\")\nplt.grid()\n\nplt.show()","1683bdf7":"plt.figure(figsize=(20,12))\nplt.subplot(2,2,1)\nsns.countplot('Survived',data=train,palette=['black','yellow'],hue='Sex')\nplt.grid()\nplt.title(\"Survival Graph\")\n\nplt.subplot(2,2,2)\nsns.countplot('SibSp',data=train,palette=['green','pink'],hue='Sex')\nplt.grid()\nplt.title(\"No of siblings \/ spouses aboard the Titanic\")\n\nplt.subplot(2,2,3)\nsns.countplot('Parch',data=train,palette=['orange','greenyellow'],hue='Sex')\nplt.grid()\nplt.title(\"No of parents \/ children aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.subplot(2,2,4)\nsns.countplot('Pclass',data=train,palette=['brown','magenta'],hue='Sex')\nplt.grid()\nplt.title(\"Passenger Class with sex\")\nplt.legend(loc='upper right')\n\nplt.show()","41cb35ba":"plt.figure(figsize=(20,20))\nsns.countplot(y='Age',data=train)\nplt.grid()\nplt.title(\"Train data Age ranges\")\nplt.show()","7e666dfb":"plt.figure(figsize=(20,20))\nsns.countplot(y='Age',data=test)\nplt.grid()\nplt.title(\"Test data Age ranges\")\nplt.show()","848c450a":"plt.figure(figsize=(20,12))\n\nplt.subplot(2,2,1)\nsns.countplot('Embarked',data=train,hue='Survived',palette=['red','purple'])\nplt.grid()\nplt.title(\"Embarked plotted\")\n\nplt.subplot(2,2,2)\nsns.countplot('Pclass',data=train,hue='Survived',palette=['teal','darkblue'])\nplt.grid()\nplt.title(\"Types of Passenger Classes\")\n\nplt.subplot(2,2,3)\nsns.countplot('Parch',data=train,palette=['orange','greenyellow'],hue='Survived')\nplt.grid()\nplt.title(\"No of parents \/ children aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.subplot(2,2,4)\nsns.countplot('SibSp',data=train,palette=['brown','magenta'],hue='Survived')\nplt.grid()\nplt.title(\"No of siblings \/ spouses aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.show()","36c92d38":"fig = px.pie(train,names='Sex',color='Survived')\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","c2c30bb9":"fig = px.pie(train,names='Embarked',color='Survived',color_discrete_sequence=px.colors.sequential.RdBu)\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","6872f8d1":"fig = px.pie(train,names='Pclass',color='Survived',color_discrete_sequence=px.colors.sequential.GnBu)\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","5591f633":"fig = px.pie(train,names='SibSp',color='Survived',template='seaborn')\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","d6e504e3":"fig = px.violin(train,x='Sex',y='Age',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Sex',y='Pclass',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Sex',y='SibSp',points='all',box=True)\nfig.show()","9e1614cc":"fig = px.violin(train,x='Survived',y='Age',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Survived',y='Pclass',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Survived',y='SibSp',points='all',box=True)\nfig.show()","54e3ca34":"fig = px.scatter(train,x='Age',y='Fare',color='Survived',size='Age')\nfig.show()\n\nfig = px.scatter(train,x='Age',y='Fare',color='Sex',size='Age')\nfig.show()","d695a06d":"train = train.drop('Survived',axis=1)","698cb32e":"train_ohe = data_ohe[:train.shape[0]]\ntest_ohe = data_ohe[train.shape[0]:]","c86637ce":"len(data)","665a5a5c":"X_train,X_test,Y_train,Y_test = train_test_split(train_ohe,Y,test_size=0.2)","424884af":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","32687cf0":"def plot_conf_matrix(Y_test,Y_pred):\n    conf = confusion_matrix(Y_test,Y_pred)\n    recall =(((conf.T)\/(conf.sum(axis=1))).T)\n    precision =(conf\/conf.sum(axis=0))\n\n    print(\"Confusion Matrix : \")\n    class_labels = [0,1]\n    plt.figure(figsize=(10,8))\n    sns.heatmap(conf,annot=True,fmt=\".3f\",cmap=\"GnBu\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n\n    print(\"Precision Matrix ; \")\n    plt.figure(figsize=(10,8))\n    sns.heatmap(precision,annot=True,fmt=\".3f\",cmap=\"YlOrBr\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n\n    print(\"Recall Matrix ; \")\n    plt.figure(figsize=(10,8))\n    sns.heatmap(recall,annot=True,fmt=\".3f\",cmap=\"Blues\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()","746e787f":"# params = dict(\n#     n_estimators = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     criterion = ['gini','entropy'],\n#     max_depth = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n# )\n# rf = RandomForestClassifier()\n# clf = RandomizedSearchCV(rf,params,random_state=0,verbose=0,n_jobs=-1,n_iter=20,cv=10)\n# rsc = clf.fit(X_train,Y_train)\n# rsc.best_params_","cdc9cfec":"rf = RandomForestClassifier(n_estimators=15,min_samples_leaf=6,max_depth=400,criterion='gini')\nrf.fit(X_train,Y_train)\npred = rf.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","f2f8359e":"# params = dict(\n#     learning_rate = [0.001,0.01,0.1,1,10,100,1000],\n#     n_estimators = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     criterion = ['friedman_mse','mse','mae'],\n#     max_depth = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n# )\n# gbdt = GradientBoostingClassifier()\n# clf = RandomizedSearchCV(gbdt,params,random_state=0,verbose=0,n_jobs=-1,n_iter=20,cv=10)\n# gb = clf.fit(X_train,Y_train)\n# gb.best_params_","87a7e7ed":"gbdt = GradientBoostingClassifier(n_estimators=700,min_samples_leaf=8,max_depth=1000,criterion='mse',learning_rate=0.01)\ngbdt.fit(X_train,Y_train)\npred = gbdt.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","5b6078be":"vc = VotingClassifier(estimators=[('rf', rf), ('gbdt', gbdt)],voting='soft')\nvc = vc.fit(X_train,Y_train)\n\npred = vc.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","1f22f64a":"X_train.shape","c3baf824":"test['PassengerId']","608c8325":"predictions = gbdt.predict(test_ohe)\npredictions.shape","ec96fc04":"submit = pd.DataFrame(test['PassengerId'],columns=['PassengerId'])\nsubmit['Survived'] = predictions\nsubmit.head()","9ad6e7d8":"submit.to_csv(\"Submissions.csv\",index=False)\nprint(\"Finished saving the file\")","dc8b1650":"**<p style=\"color:purple\">There are no duplicate rows present in the dataset .**","e98cc28f":"**<p style=\"color:purple;\">I will handle the remaining missing values in the Cabin column after some feature engineering.<\/p>**","23dc86a0":"**<p style=\"color:purple;\">The missing values in the cabin column will be handled after some feature engineering.<\/p>**","878c1a48":"# **<h1 style=\"color:skyblue;\">Random Forest :**","1db0265d":"# **<h1 style=\"color:skyblue;\">Feature Engineering :**","cf6533c9":"<h1 style=\"color:red\">Hello folks, in case you like this notebook dont forget to <span style=\"color:purple\">UPVOTE<\/span> it and thanks for viewing :)<\/h1>","3f73da93":"2. **<p style=\"color:green;\">Creating the category of the age section.**","27156548":"**<p style=\"color:green;\">Scatter Plots :**","337e6fd2":"**<p style=\"color:purple;\">The age feature consists of many missing values.<\/p>**","710487f0":"**<p style=\"color:green;\">Violin Plots :**","e78a6b77":"**<p style=\"color:orange\">Thanks for viewing.**","9bf07b97":"**<p style=\"color:green;\">Combining the dataset :<\/p>**","80569b9f":"# **<h1 style=\"color:skyblue;\">Data Visualisation :**","c6992ed1":"**<p style=\"color:purple;\">I am going to replace the missing value in the Fare column by the average fare of according to the Sex<\/p>**","5d0dfc9b":"**<p style=\"color:green;\">Hetamaps :**","8fa97889":"**<p style=\"color:red;\">And we are done with the predictions.<\/p>**","eb576e75":"3. **<p style=\"color:green;\">Creating features that the person is married or not,and the family size with SibSp and parch column**","f8044c82":"**<p style=\"color:purple;\">Therefore the missing age values are handled.<\/p>**","c2cef2c1":"# **<h1 style=\"color:skyblue;\">Importing Libraries :<\/h1>**","944c3638":"5. **<p style=\"color:green;\">A feature which categorizes the fare rates of the person.**","d578b0f3":"# **<h1 style=\"color:skyblue;\">One-Hot Encoding of features :**","da40985a":"**<p style=\"color:green;\">Pie Charts :**","ad347f59":"# **<h1 style=\"color:skyblue;\">Train-Test Split :**","85c0ad21":"**<p style=\"color:purple;\">Hence the missing value in the Fare column in the data is handled<\/p>**","494cdea4":"# **<h1 style=\"color:skyblue;\">Data Modeling :**","67acad17":"# **<h1 style=\"color:skyblue;\">Duplicate Values :**","08f315ad":"#  **<h1 style=\"color:skyblue;\">Voting Classifier :**","ee4227f3":"# **<h1 style=\"color:skyblue;\">ML Models :**","7c59c929":"**<p style=\"color:purple;\">Now removing the useless columns.**","5426e17a":"1. **<p style=\"color:green;\">Creating a feature with the titles of the name.<\/p>**","c96f80be":"# **<h1 style=\"color:skyblue;\">Null Values :<\/h1>**","dd66e702":"**<p style=\"color:purple;\">Bar graphs and CountPlots :**","da9ba52a":"# **<h1 style=\"color:skyblue;\">Loading the dataset :<\/h1>**","34b81ab1":"6. **<p style=\"color:green;\">A feature which tells us the the cabin value is present or not since the cabin feature has so many null values.**","2aab4a4a":"# **<h1 style=\"color:green;\">Variable Notes :<\/h1>**\n<p style=\"color:purple;\">pclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n<\/p>\n<p style=\"color:purple;\">\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n<\/p>  \n<p style=\"color:purple;\">\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n<\/p>\n<p style=\"color:purple;\">\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n<\/p>","31d8efc8":"4. **<p style=\"color:green;\">Creating a feature which tells us that the person is travelling with someone or not according to the similar number on the tickets.**","52c813af":"# **<h1 style=\"color:skyblue;\">GBDT :**","d9a1d32f":"# **<h1 style=\"color:skyblue;\">Predictions :**","da9da5dc":"**<p style=\"color:purple;\">To handle the missing values in the age column of the dataset I have calculated the average age of the males and the females in the dataset and replaced the missing values accoring to their sex.<\/p>**"}}