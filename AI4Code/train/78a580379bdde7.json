{"cell_type":{"49e9a5ad":"code","68c65c7e":"code","769f5720":"code","fa820534":"code","9c659228":"code","5f5fdc6e":"code","7d9f75e7":"code","64efcdc4":"code","0f6996d6":"code","563963e9":"code","0ef93612":"code","a31b2ddd":"code","de4a8e32":"code","c52afb7f":"code","f2873c2d":"markdown","badfca9d":"markdown","39402141":"markdown","69159d28":"markdown","fc8c789d":"markdown","70fda04b":"markdown","4149b457":"markdown"},"source":{"49e9a5ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","68c65c7e":"!pip install face_recognition","769f5720":"!pip install imageio-ffmpeg","fa820534":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nimport glob\nimport cv2\nfrom albumentations import *\nfrom tqdm import tqdm_notebook as tqdm\nimport gc\n\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\nfrom keras.optimizers import Adam\nimport face_recognition\nimport imageio\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')\nPATH = '..\/input\/deepfake-detection-challenge\/'\nprint(os.listdir(PATH))","9c659228":"for dirname, _, filenames in os.walk('\/kaggle\/input\/testmodel'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5f5fdc6e":"TRAIN_PATH = 'train_sample_videos\/*.mp4'\nTEST_PATH = 'test_videos\/*.mp4'\ntrain_img = glob.glob(os.path.join(PATH, TRAIN_PATH))\ntest_img = glob.glob(os.path.join(PATH, TEST_PATH))","7d9f75e7":"from IPython.display import HTML\nfrom base64 import b64encode\nvid1 = open('\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/ytddugrwph.mp4','rb').read()\ndata_url = \"data:video\/mp4;base64,\" + b64encode(vid1).decode()\nHTML(\"\"\"\n<video width=600 controls>\n      <source src=\"%s\" type=\"video\/mp4\">\n<\/video>\n\"\"\" % data_url)","64efcdc4":"class Video:\n    def __init__(self, path):\n        self.path = path\n        self.container = imageio.get_reader(path, 'ffmpeg')\n        self.length = self.container.count_frames()\n#         self.length = self.container.get_meta_data()['nframes']\n        self.fps = self.container.get_meta_data()['fps']\n    \n    def init_head(self):\n        self.container.set_image_index(0)\n    \n    def next_frame(self):\n        self.container.get_next_data()\n    \n    def get(self, key):\n        return self.container.get_data(key)\n    \n    def __call__(self, key):\n        return self.get(key)\n    \n    def __len__(self):\n        return self.length","0f6996d6":"IMGWIDTH = 256\n\nclass Classifier:\n    def __init__():\n        self.model = 0\n    \n    def predict(self, x):\n        return self.model.predict(x)\n    \n    def fit(self, x, y):\n        return self.model.train_on_batch(x, y)\n    \n    def get_accuracy(self, x, y):\n        return self.model.test_on_batch(x, y)\n    \n    def load(self, path):\n        self.model.load_weights(path)\n\n\nclass Meso4(Classifier):\n    def __init__(self, learning_rate = 0.001):\n        self.model = self.init_model()\n        optimizer = Adam(lr = learning_rate)\n        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n    \n    def init_model(self): \n        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n        \n        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n        x1 = BatchNormalization()(x1)\n        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n        \n        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n        x2 = BatchNormalization()(x2)\n        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n        \n        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n        x3 = BatchNormalization()(x3)\n        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n        \n        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n        x4 = BatchNormalization()(x4)\n        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n        \n        y = Flatten()(x4)\n        y = Dropout(0.5)(y)\n        y = Dense(16)(y)\n        y = LeakyReLU(alpha=0.1)(y)\n        y = Dropout(0.5)(y)\n        y = Dense(1, activation = 'sigmoid')(y)\n\n        return KerasModel(inputs = x, outputs = y)\n\n","563963e9":"tf.test.is_gpu_available(\n    cuda_only=False,\n    min_cuda_compute_capability=None\n)","0ef93612":"classifier = Meso4()\nclassifier.load('\/kaggle\/input\/testmodel\/Meso4_DF')","a31b2ddd":"submit = []","de4a8e32":"save_interval = 150 # perform face detection every {save_interval} frames\nmargin = 0.2\nfor vi in os.listdir('\/kaggle\/input\/deepfake-detection-challenge\/test_videos'):\n#     print(os.path.join(\"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\", vi))\n    re_video = 0.5\n    try:\n        video = Video(os.path.join(\"\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/\", vi))\n        re_imgs = []\n        for i in range(0,video.__len__(),save_interval):\n            img = video.get(i)\n            face_positions = face_recognition.face_locations(img)\n            for face_position in face_positions:\n                offset = round(margin * (face_position[2] - face_position[0]))\n                y0 = max(face_position[0] - offset, 0)\n                x1 = min(face_position[1] + offset, img.shape[1])\n                y1 = min(face_position[2] + offset, img.shape[0])\n                x0 = max(face_position[3] - offset, 0)\n                face = img[y0:y1,x0:x1]\n\n                inp = cv2.resize(face,(256,256))\/255.\n                re_img = classifier.predict(np.array([inp]))\n    #             print(vi,\": \",i , \"  :  \",classifier.predict(np.array([inp])))\n                re_imgs.append(re_img[0][0])\n        re_video = np.average(re_imgs)\n        if np.isnan(re_video):\n            re_video = 0.5\n    except:\n        re_video = 0.5\n#     submit.append([vi,1.0-re_video])\n    submit.append([vi,re_video])","c52afb7f":"submission = pd.DataFrame(submit, columns=['filename', 'label']).fillna(0.5)\nsubmission.sort_values('filename').to_csv('submission.csv', index=False)\nsubmission","f2873c2d":"# Read video","badfca9d":"# Load model","39402141":"## MesoNet results","69159d28":"# Model Meso4","fc8c789d":" predict video by combie image","70fda04b":"# Predict","4149b457":"read video and extract frame from video"}}