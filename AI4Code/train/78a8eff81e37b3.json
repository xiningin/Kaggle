{"cell_type":{"3b27fd3a":"code","b35f67af":"code","8bed0d1e":"code","9ef0fe91":"code","b374148c":"code","ae85d720":"code","6224fba6":"code","d7066d01":"code","98bfe991":"code","ef6f0284":"code","248f51de":"code","d647ccfd":"code","71863a8c":"code","d685d1f6":"code","80747bf9":"code","7cfca772":"code","6ddae8d4":"code","8561f111":"code","d4c6d639":"code","3a603cb9":"code","b1e8a231":"code","af389176":"code","154c1b18":"code","de1c2fc4":"code","04ab9240":"code","744585aa":"code","a31d67cb":"code","8f69d9ea":"markdown","0f2cf88a":"markdown","711556b7":"markdown","8e1a107d":"markdown","b1e304ff":"markdown","a303c3ef":"markdown","099dc509":"markdown","930800c0":"markdown","343c268e":"markdown","91ed7a6c":"markdown","ed0f0160":"markdown","a6c8064c":"markdown","d94fb75d":"markdown","6375a343":"markdown","6715c81b":"markdown","b315b4bb":"markdown","e5721638":"markdown"},"source":{"3b27fd3a":"import numpy as np\nimport pandas as pd\nimport os\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","b35f67af":"print(os.listdir(\"..\/input\/bisindotest\/bisindo_test\"))","8bed0d1e":"train_dir = \"..\/input\/bisindo2\/Bisindo\"","9ef0fe91":"def load_unique():\n    size_img = 64,64 \n    images_for_plot = []\n    labels_for_plot = []\n    for folder in os.listdir(train_dir):\n        for file in os.listdir(train_dir + '\/' + folder):\n            filepath = train_dir + '\/' + folder + '\/' + file\n            image = cv2.imread(filepath)\n            final_img = cv2.resize(image, size_img)\n            final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2GRAY)\n            images_for_plot.append(final_img)\n            labels_for_plot.append(folder)\n            break\n    return images_for_plot, labels_for_plot\n\nimages_for_plot, labels_for_plot = load_unique()\nprint(\"unique_labels = \", labels_for_plot)\n\nfig = plt.figure(figsize = (15,15))\ndef plot_images(fig, image, label, row, col, index):\n    fig.add_subplot(row, col, index)\n    plt.axis('off')\n    plt.imshow(image,cmap='Greys')\n    plt.title(label)\n    return\n\nimage_index = 0\nrow = 5\ncol = 5\nfor i in range(1,(row*col+1)):\n    plot_images(fig, images_for_plot[image_index], labels_for_plot[image_index], row, col, i)\n    image_index = image_index + 1\nplt.show()","b374148c":"labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n                   'Z':25}\n\ndef load_data():\n    \"\"\"\n    Loads data and preprocess. Returns train and test data along with labels.\n    \"\"\"\n    images = []\n    labels = []\n    size = 64,64\n    print(\"LOADING DATA FROM : \",end = \"\")\n    for folder in os.listdir(train_dir):\n        print(folder, end = ' | ')\n        for image in os.listdir(train_dir + \"\/\" + folder):\n            temp_img = cv2.imread(train_dir + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(labels_dict[folder])\n    \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    \n    labels = keras.utils.to_categorical(labels)\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.12)\n    \n    print()\n    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n    \n    return X_train, X_test, Y_train, Y_test","ae85d720":"X_train, X_test, Y_train, Y_test = load_data()","6224fba6":"model = Sequential()\n    \nmodel.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))\nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n    \nmodel.add(BatchNormalization())\n    \nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\nmodel.add(Dense(26, activation = 'softmax'))\n    \nmodel.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n    \nprint(\"MODEL CREATED\")\nmodel.summary()\n    \n","d7066d01":"es = EarlyStopping(monitor='val_loss', verbose=1, patience=2)\n    ","98bfe991":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n#kf= StratifiedKFold(n_splits=3)\nkf = KFold(n_splits=3)","ef6f0284":"def get_score (model, x_train, x_test, y_train, y_test):\n    curr_model_hist= model.fit(x_train,y_train, batch_size = 64, callbacks=[es],validation_data=(x_test,y_test),epochs=5) \n    test_score = model.evaluate(x_test,y_test)\n    train_score = model.evaluate(x_train,y_train)\n    plotHistory(curr_model_hist)\n    return train_score,test_score","248f51de":"def plotHistory(curr_model_hist):\n    plt.plot(curr_model_hist.history['accuracy'])\n    plt.plot(curr_model_hist.history['val_accuracy'])\n    plt.legend(['train', 'test'], loc='lower right')\n    plt.title('accuracy plot - train vs test')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.show()\n\n    plt.plot(curr_model_hist.history['loss'])\n    plt.plot(curr_model_hist.history['val_loss'])\n    plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n    plt.title('loss plot - training vs vaidation')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()","d647ccfd":"scores = []\n\nfor train_index, test_index in kf.split(X_train):\n    x_train, x_test, y_train, y_test = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    scores.append(get_score(model,x_train,x_test,y_train,y_test))","71863a8c":"scores","d685d1f6":"total_train_loss = 0\ntotal_train_acc = 0\ntotal_test_loss = 0\ntotal_test_acc = 0\nfor i in range (3):\n    total_train_loss = total_train_loss+scores[i][0][0]\n    total_train_acc =total_train_acc+scores[i][0][1]\n    total_test_loss =total_test_loss+scores[i][1][0]\n    total_test_acc =total_test_acc+scores[i][1][1]\nprint(total_train_acc\/3)\nprint(total_train_loss\/3)\nprint(total_test_acc\/3)\nprint(total_test_loss\/3)","80747bf9":"evaluate_metrics = model.evaluate(X_test, Y_test)\nprint(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))","7cfca772":"def evaluate_F1(model,Y_test,X_test):\n    from sklearn.metrics import f1_score\n    y_true = [np.where(r==1)[0][0] for r in Y_test]\n    classes = model.predict_classes(X_test)\n    return f1_score(y_true,classes,average=None)","6ddae8d4":"evaluate_F1(model,Y_test,X_test)","8561f111":"model.save('MODEL A.h5')","d4c6d639":"from keras.models import load_model","3a603cb9":"source_model = load_model(\"..\/input\/asl-classifier-using-keras\/ASL3\")\nsource_model.summary()","b1e8a231":"new_model = Sequential()\nnew_model = source_model\nnew_model.pop()\nnew_model.add(Dense(26))","af389176":"for i in range (8):\n    new_model.layers[i+1].trainable = False\nnew_model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\nnew_model.summary()","154c1b18":"scores = []\n\nfor train_index, test_index in kf.split(X_train):\n    x_train, x_test, y_train, y_test = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    scores.append(get_score(new_model,x_train,x_test,y_train,y_test))","de1c2fc4":"total_train_loss = 0\ntotal_train_acc = 0\ntotal_test_loss = 0\ntotal_test_acc = 0\nfor i in range (3):\n    total_train_loss = total_train_loss+scores[i][0][0]\n    total_train_acc =total_train_acc+scores[i][0][1]\n    total_test_loss =total_test_loss+scores[i][1][0]\n    total_test_acc =total_test_acc+scores[i][1][1]\nprint(total_train_acc\/3)\nprint(total_train_loss\/3)\nprint(total_test_acc\/3)\nprint(total_test_loss\/3)","04ab9240":"evaluate_metrics = new_model.evaluate(X_test, Y_test)\nprint(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))","744585aa":"evaluate_F1(new_model,Y_test,X_test)","a31d67cb":"new_model.save( 'MODEL B.h5')","8f69d9ea":"## Testing the model with test data","0f2cf88a":"## define the training directory","711556b7":"## Test the new_model with test data","8e1a107d":"create a new_model that keeps all the layers and params from ASL, then replace the last layer with Dense(26)","b1e304ff":"## Evaluate the model with F1 score","a303c3ef":"## Construct the A model ","099dc509":"Model training using stratified kfold","930800c0":"plot the training history","343c268e":"## plot the sample images","91ed7a6c":"calculating the average loss and accuracy","ed0f0160":"## Data Preprocessing","a6c8064c":"## define the early stopping callback","d94fb75d":"## GREAT! We're moving to Model B","6375a343":"## Train the new_model","6715c81b":"##  KFold","b315b4bb":"## load the ASL Model","e5721638":"## Import the supporting libraries"}}