{"cell_type":{"6cd2970a":"code","fb5c3264":"code","c38543b8":"code","4d494428":"code","687d74b2":"code","0b58026a":"code","f6ee049e":"code","10372fe1":"code","028e0c51":"code","cb8491e4":"code","2f4f8631":"code","3cda5817":"code","64d9872f":"code","41b662ba":"code","c956e5b3":"markdown","68a0c3fc":"markdown","e4a1d482":"markdown","14031e37":"markdown","b8db7cbd":"markdown","350d81a9":"markdown","69a9e0c1":"markdown","35e2b02a":"markdown","1b2c66a7":"markdown"},"source":{"6cd2970a":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage import io\nimport os\n%matplotlib inline\n\n\n# Import the Convolutional Autoencoder utility script\nfrom convolutionalautoencoder import CNAutoEnc\nfrom tensorflow.keras.optimizers import Adam\n        ","fb5c3264":"from keras.preprocessing.image import load_img, img_to_array, array_to_img\n\ndef arrReshape(arr):\n    arr = arr.astype(\"float32\")\/255.0\n    return arr\n\ndef arrShape(arr):\n    arr = (arr.astype(\"float32\")*255.0).astype(\"uint8\")\n    return arr\n\ndef getImageArray(folderPath):\n    for dirname, _, filenames in os.walk('\/kaggle\/input\/denoise\/denoising-dirty-documents\/train\/train'):\n        images = np.ndarray(shape=(len(filenames), 320, 320, 1),dtype=np.float32)\n        i=0\n        for filename in filenames:\n            # reference Tensorflow : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/load_img\n            img = img_to_array(load_img(os.path.join(dirname,filename),color_mode=\"grayscale\",target_size=(320,320), interpolation=\"nearest\"))\n            img= img.reshape((320,320,1))\n            images[i] = img\n            i+=1\n    return images\n","c38543b8":"trainNoise = arrReshape(getImageArray('\/kaggle\/input\/denoise\/denoising-dirty-documents\/train\/train'))\ntrainCleaned = arrReshape(getImageArray('\/kaggle\/input\/denoise\/denoising-dirty-documents\/train_cleaned\/train_cleaned'))\ntestNoise = arrReshape(getImageArray('\/kaggle\/input\/denoise\/denoising-dirty-documents\/test\/test'))","4d494428":"array_to_img(np.hstack([trainNoise[5],trainCleaned[5]]))","687d74b2":"EPOCH=50\nbatchsize=5\n(encoder,decoder, autoencoder) = CNAutoEnc.create((320,320,1))\nautoencoder.compile(loss=\"mse\",optimizer=Adam(lr=5e-4) )","0b58026a":"history = autoencoder.fit(trainNoise,trainCleaned,epochs=EPOCH,batch_size=batchsize)","f6ee049e":"decodedImages = autoencoder.predict(testNoise)","10372fe1":"sampleshow = None\nfor i in range(5):\n    if sampleshow is None:\n        sampleshow = np.hstack([decodedImages[i],testNoise[i]])\n    else:\n        sampleshow = np.vstack([sampleshow,np.hstack([decodedImages[i],testNoise[i]])])","028e0c51":"array_to_img(sampleshow)","cb8491e4":"from tensorflow.keras.preprocessing.image import random_rotation\norigImage = trainNoise[0]\njunkImage  = random_rotation(origImage, rg=20, row_axis=0, col_axis=12, channel_axis=2, fill_mode='nearest', cval=0.0, interpolation_order=1)\njunkImage = arrReshape(junkImage.reshape((320, 320, 1)))","2f4f8631":"array_to_img(junkImage)","3cda5817":"anamolyPredict = autoencoder.predict(junkImage.reshape((1,320, 320, 1)))","64d9872f":"mse = np.mean((origImage-anamolyPredict[0])**2)\nprint(mse)","41b662ba":"array_to_img(anamolyPredict[0])","c956e5b3":"#### Reconstruct the anamoly Image\nIn this step I am reconstructing the image from the autoencoder. By this reconstructed image we will see how far the autoencoder is able to reconstruct this image successfully; by looking into the MSE from the original anamoly (rotated) image.","68a0c3fc":"# Denoising Autoencoder\nThis example will use the already published script: [Convolutional Autoencoder](https:\/\/www.kaggle.com\/pankaj1234\/convolutionalautoencoder)\nThe main idea behind this example is to demonstrate the powerful concept of image denosing by using application of AutoEncoders.\n\n> A, section here will also cover the aspect that how Autoencoder can be used to detect Anomaly w.r.t. to computer vision (images). ","e4a1d482":"### Noise Image and Original Image ","14031e37":"# Anomaly Detection\nIn this section we can look into how the Autoencoder can be used to detect the Anamoly for input images.<\/br> The overall idea behind this concept is to use compress the image to is latent dimension and then reconstruct the Image from there itself.<\/br> The difference in MSE of the orignalimage on which the Autoencoder is trained and the image with the anomaly will help decide if the image is and detected anomaly.\n### Theory behind this concept\nWe would expect the autoencoder to do a really good job at reconstructing the images from the domain on which its trained upon, as that is exactly what the autoencoder was trained to do \u2014 and if we were to look at the MSE between the input image and the reconstructed image, we would find that it\u2019s quite low.\n\nBut now instead of that - if we feed an image from the different domain to the autoencoder (anamoly) then thit will generate the output (reconstructed) which is no where near that image (because autoencoder is not trained on this domain of images) - Hence the MSE is going to be very high - thus the anamoly can be detected.","b8db7cbd":"### Display the results after denoising\nLeft Image is decoded from the Noise and Right side image is the Original Image. ","350d81a9":"#### Sample Image for Anamoly detection\nIn this step I am extracting a sample image from the TrainNoise set and then by doiong random rotation a sample image is derived  - this image is treated as an anamoly for this original dataset. This is because this image is not trained on this network.","69a9e0c1":"### Helper Functions<br\/>Load and reshape the data","35e2b02a":"### Load the data","1b2c66a7":"### Anamoly Detection Output\nNot to surprise the Autoencoder model is unable to construct the Anamoly image perfectly. Hence this is daignosed as an anamoly for the dataset on which the Autoancoder is trained originally."}}