{"cell_type":{"a4055c6d":"code","427eb632":"code","19a36315":"code","b9163c8d":"code","6e34c5f0":"code","dc531192":"code","46d54150":"code","6463ace6":"code","e824b8a0":"code","8594c3d3":"code","5811e4bb":"code","3c2a65a4":"code","2304713b":"code","decd0535":"code","466c192a":"code","675f7300":"code","01d49767":"code","08e00cb2":"code","3ab3483b":"code","2c769bf4":"code","6b951153":"code","a588178e":"code","ecfc28c8":"code","b558b0a9":"code","d3fefdae":"code","5b6deb58":"code","0b46aa42":"code","d565aa70":"code","75fe9e88":"code","553b347a":"code","9bf1321d":"code","284ef659":"code","e35ecdd5":"code","34ec635b":"code","3614bb72":"code","213127de":"code","f450f624":"code","37863d96":"code","e153531a":"code","7e0ac53f":"code","2fe9020a":"code","9705e47b":"code","6b5ae4f2":"code","06b83b25":"code","d55f59af":"code","19a2643c":"code","c8941a2a":"code","9f30735a":"code","236fd09a":"code","b3f4dcaa":"code","1e7b3762":"code","b1293f00":"code","944446fe":"code","da6d50de":"code","b7b107ba":"code","33e01f7f":"code","40eddee8":"code","63702836":"code","4a7e642a":"code","4f1ec4b5":"code","e6eafddf":"code","8302f272":"code","14c44000":"code","db1cbcb4":"code","624b8de3":"code","07fea37c":"code","7002acb6":"code","80859478":"code","9c1f6650":"code","e5bd7d86":"code","b3d2467b":"code","2b09f4b8":"code","779580e1":"code","ed921a98":"code","edf7a1e4":"code","afbad448":"code","03a9a58c":"code","c6fe274e":"code","376a2058":"code","663089b7":"code","c5787679":"code","9247e77a":"code","216e4c11":"code","00f42035":"markdown","87b3fe7b":"markdown","071c48cc":"markdown","c9e4423f":"markdown","c98c7325":"markdown","24d1ac15":"markdown","80077c4e":"markdown","e64506e7":"markdown","3c3f2e80":"markdown","7ff1aea1":"markdown","9c9fab73":"markdown","c6e337a4":"markdown","165ab5bf":"markdown","7df9b0e6":"markdown","118a5a31":"markdown","155bc782":"markdown","cfc5a6ca":"markdown","5c6befb5":"markdown","3439ef40":"markdown","ca0cf941":"markdown","6ef3adaf":"markdown","3a770b72":"markdown","8a5a609a":"markdown","64a91848":"markdown","49cb7b48":"markdown","a4083393":"markdown","d90ae901":"markdown","0a45a2ed":"markdown","d2067318":"markdown","b8f3223b":"markdown","5f84cfec":"markdown","bbc133ba":"markdown","4db59b9a":"markdown","61ff7060":"markdown","145cceb4":"markdown","0b3fcf88":"markdown","0e035f24":"markdown","6856ae41":"markdown","8df89ea7":"markdown","797fdc58":"markdown","b1c4c8bd":"markdown","7010b992":"markdown","eb84f5c4":"markdown","a878f693":"markdown","0de6d99e":"markdown","c09cce9d":"markdown","b3db6f2e":"markdown","13f86f96":"markdown","a07fa91d":"markdown","045120b4":"markdown"},"source":{"a4055c6d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix","427eb632":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","19a36315":"train_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")","b9163c8d":"class FashionDataset(Dataset):\n    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n    \n    def __init__(self, data, transform = None):\n        \"\"\"Method to initilaize variables.\"\"\" \n        self.fashion_MNIST = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion_MNIST:\n             # first column is of labels.\n            label.append(i[0])\n            image.append(i[1:])\n        self.labels = np.asarray(label)\n        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n\n    def __getitem__(self, index):\n        label = self.labels[index]\n        image = self.images[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.images)","6e34c5f0":"# Transform data into Tensor that has a range from 0 to 1\ntrain_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\ntest_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n\ntrain_loader = DataLoader(train_set, batch_size=100)\ntest_loader = DataLoader(train_set, batch_size=100)","dc531192":"def output_label(label):\n    output_mapping = {\n                 0: \"T-shirt\/Top\",\n                 1: \"Trouser\",\n                 2: \"Pullover\",\n                 3: \"Dress\",\n                 4: \"Coat\", \n                 5: \"Sandal\", \n                 6: \"Shirt\",\n                 7: \"Sneaker\",\n                 8: \"Bag\",\n                 9: \"Ankle Boot\"\n                 }\n    input = (label.item() if type(label) == torch.Tensor else label)\n    return output_mapping[input]","46d54150":"a = next(iter(train_loader))\na[0].size()","6463ace6":"len(train_set)","e824b8a0":"image, label = next(iter(train_set))\nplt.imshow(image.squeeze())\nprint(output_label(label))","8594c3d3":"demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n\nbatch = next(iter(demo_loader))\nimages, labels = batch\nprint(type(images), type(labels))\nprint(images.shape, labels.shape)","5811e4bb":"grid = torchvision.utils.make_grid(images, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)))\nprint(\"labels: \", end=\" \")\nfor i, label in enumerate(labels):\n    print(output_label(label), end=\", \")\n","3c2a65a4":"import torch.nn.functional as F\n# function to count number of parameters\ndef get_n_params(model):\n    np=0\n    for p in list(model.parameters()):\n        np += p.nelement()\n    return np\n\naccuracy_list = []\n# we pass a model object to this trainer, and it trains this model for one epoch\ndef train(epoch, model):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            \ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        output = model(data)\n        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n\n    test_loss \/= len(test_loader.dataset)\n    accuracy = 100. * correct \/ len(test_loader.dataset)\n    accuracy_list.append(accuracy)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        accuracy))","2304713b":"class FC2Layer(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(FC2Layer, self).__init__()\n        self.input_size = input_size\n        self.network = nn.Sequential(\n            nn.Linear(input_size, 200), \n            nn.ReLU(), \n            nn.Linear(200,200),\n            nn.ReLU(),\n            nn.Linear(200,100),\n            nn.ReLU(),\n            nn.Linear(100,80),\n            nn.ReLU(),\n            nn.Linear(80,60),\n            nn.ReLU(), \n            nn.Linear(60, output_size), \n            nn.LogSoftmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = x.view(-1, self.input_size)\n        return self.network(x)","decd0535":"import torch.optim as optim\ninput_size  = 28*28   # images are 28x28 pixels\noutput_size = 10\nprint(\"Training on \", device)\nmodel_fnn = FC2Layer(input_size, output_size)\nmodel_fnn.to(device)\noptimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5,)\nprint('Number of parameters: {}'.format(get_n_params(model_fnn)))\n\nfor epoch in range(0, 10):\n    train(epoch, model_fnn)\n    test(model_fnn)","466c192a":"fixed_perm = torch.randperm(784) # Fix a permutation of the image pixels; We apply the same permutation to all images\n\n# show some training images\nplt.figure(figsize=(8, 8))\n\n# fetch a batch of train images; RANDOM\nimage_batch, label_batch = next(iter(train_loader))\n\nfor i in range(6):\n    image = image_batch[i]\n    image_perm = image.view(-1, 28*28).clone()\n    image_perm = image_perm[:, fixed_perm]\n    image_perm = image_perm.view(-1, 1, 28, 28)\n    \n    label = label_batch[i].item()\n    plt.subplot(3,4 , 2*i + 1)\n    #image, label = train_loader.dataset.__getitem__(i)\n    plt.imshow(image.squeeze().numpy())\n    plt.axis('off')\n    plt.title(output_label(label))\n    plt.subplot(3, 4, 2*i+2)\n    plt.imshow(image_perm.squeeze().numpy())\n    plt.axis('off')\n    plt.title(output_label(label))","675f7300":"accuracy_list = []\n\ndef scramble_train(epoch, model, perm=torch.arange(0, 784).long()):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        # permute pixels\n        data = data.view(-1, 28*28)\n        data = data[:, perm]\n        data = data.view(-1, 1, 28, 28)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            \ndef scramble_test(model, perm=torch.arange(0, 784).long()):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        # permute pixels\n        data = data.view(-1, 28*28)\n        data = data[:, perm]\n        data = data.view(-1, 1, 28, 28)\n        \n        output = model(data)\n        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n\n    test_loss \/= len(test_loader.dataset)\n    accuracy = 100. * correct \/ len(test_loader.dataset)\n    accuracy_list.append(accuracy)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        accuracy))","01d49767":"print(\"Training on \", device)\nmodel_fnn_2 = FC2Layer(input_size, output_size)\nmodel_fnn_2.to(device)\noptimizer = optim.SGD(model_fnn_2.parameters(), lr=0.01, momentum=0.5)\nprint('Number of parameters: {}'.format(get_n_params(model_fnn_2)))\n\nfor epoch in range(0, 10):\n    scramble_train(epoch, model_fnn_2, fixed_perm)\n    scramble_test(model_fnn_2, fixed_perm)","08e00cb2":"def visualize_pred(img, pred_prob, real_label):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    #pred_prob = pred_prob.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.numpy().squeeze())\n    ax1.axis('off')\n    pred_label = numpy.argmax(pred_prob)\n    ax1.set_title([real_label, pred_label])\n    \n    ax2.barh(numpy.arange(10), pred_prob)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(numpy.arange(10))\n    ax2.set_yticklabels(numpy.arange(10))\n    ax2.set_title('Prediction Probability')\n    ax2.set_xlim(0, 1.1)\n    plt.tight_layout()","3ab3483b":"import numpy\nmodel_fnn_2.to('cpu') \n\n# fetch a batch of test images\nimage_batch, label_batch = next(iter(test_loader))\nimage_batch_scramble = image_batch.view(-1, 28*28)\nimage_batch_scramble = image_batch_scramble[:, fixed_perm]\nimage_batch_scramble = image_batch_scramble.view(-1, 1, 28, 28)\n# Turn off gradients to speed up this part\nwith torch.no_grad():\n    log_pred_prob_batch = model_fnn_2(image_batch_scramble)\nfor i in range(10):\n    img = image_batch[i]\n    img_perm = image_batch_scramble[i]\n    real_label = output_label(label_batch[i].item())\n    log_pred_prob = log_pred_prob_batch[i]\n    # Output of the network are log-probabilities, need to take exponential for probabilities\n    pred_prob = torch.exp(log_pred_prob).data.numpy().squeeze()\n    visualize_pred(img_perm, pred_prob, real_label)","2c769bf4":"class FashionCNN(nn.Module):\n    \n    def __init__(self):\n        super(FashionCNN, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n    \n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(in_features=600, out_features=120)\n        self.fc3 = nn.Linear(in_features=120, out_features=10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n       \n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        \n        return out","6b951153":"model = FashionCNN()\nmodel.to(device)\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","a588178e":"num_epochs = 5\ncount = 0\n# Lists for visualization of loss and accuracy \nloss_list = []\niteration_list = []\naccuracy_list = []\n\n# Lists for knowing classwise accuracy\npredictions_list = []\nlabels_list = []\n\nfor epoch in range(num_epochs):\n    for images, labels in train_loader:\n        # Transfering images and labels to GPU if available\n        images, labels = images.to(device), labels.to(device)\n    \n        train = Variable(images.view(100, 1, 28, 28))\n        labels = Variable(labels)\n        \n        # Forward pass \n        outputs = model(train)\n        loss = error(outputs, labels)\n        \n        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n        optimizer.zero_grad()\n        \n        #Propagating the error backward\n        loss.backward()\n        \n        # Optimizing the parameters\n        optimizer.step()\n    \n        count += 1\n    \n    # Testing the model\n    \n        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n            total = 0\n            correct = 0\n        \n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                labels_list.append(labels)\n            \n                test = Variable(images.view(100, 1, 28, 28))\n            \n                outputs = model(test)\n            \n                predictions = torch.max(outputs, 1)[1].to(device)\n                predictions_list.append(predictions)\n                correct += (predictions == labels).sum()\n            \n                total += len(labels)\n            \n            accuracy = correct * 100 \/ total\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        \n        if not (count % 500):\n            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n","ecfc28c8":"plt.plot(iteration_list, loss_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Iterations vs Loss\")\nplt.show()","b558b0a9":"plt.plot(iteration_list, accuracy_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Iterations vs Accuracy\")\nplt.show()","d3fefdae":"class_correct = [0. for _ in range(10)]\ntotal_correct = [0. for _ in range(10)]\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        test = Variable(images)\n        outputs = model(test)\n        predicted = torch.max(outputs, 1)[1]\n        c = (predicted == labels).squeeze()\n        \n        for i in range(100):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            total_correct[label] += 1\n        \nfor i in range(10):\n    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 \/ total_correct[i]))","5b6deb58":"from itertools import chain \n\npredictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\nlabels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\npredictions_l = list(chain.from_iterable(predictions_l))\nlabels_l = list(chain.from_iterable(labels_l))","0b46aa42":"import sklearn.metrics as metrics\n\nconfusion_matrix(labels_l, predictions_l)\nprint(\"Classification report for CNN :\\n%s\\n\"\n      % (metrics.classification_report(labels_l, predictions_l)))","d565aa70":"fixed_perm = torch.randperm(784) # Fix a permutation of the image pixels; We apply the same permutation to all images\n\n# show some training images\nplt.figure(figsize=(8, 8))\n\n# fetch a batch of train images; RANDOM\nimage_batch, label_batch = next(iter(train_loader))\n\nfor i in range(6):\n    image = image_batch[i]\n    image_perm = image.view(-1, 28*28).clone()\n    image_perm = image_perm[:, fixed_perm]\n    image_perm = image_perm.view(-1, 1, 28, 28)\n    \n    label = label_batch[i].item()\n    plt.subplot(3,4 , 2*i + 1)\n    #image, label = train_loader.dataset.__getitem__(i)\n    plt.imshow(image.squeeze().numpy())\n    plt.axis('off')\n    plt.title(output_label(label))\n    plt.subplot(3, 4, 2*i+2)\n    plt.imshow(image_perm.squeeze().numpy())\n    plt.axis('off')\n    plt.title(output_label(label))","75fe9e88":"accuracy_list = []\n\ndef scramble_train(epoch, model, perm=torch.arange(0, 784).long()):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        # permute pixels\n        data = data.view(-1, 28*28)\n        data = data[:, perm]\n        data = data.view(-1, 1, 28, 28)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            \ndef scramble_test(model, perm=torch.arange(0, 784).long()):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        # send to device\n        data, target = data.to(device), target.to(device)\n        \n        # permute pixels\n        data = data.view(-1, 28*28)\n        data = data[:, perm]\n        data = data.view(-1, 1, 28, 28)\n        \n        output = model(data)\n        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n\n    test_loss \/= len(test_loader.dataset)\n    accuracy = 100. * correct \/ len(test_loader.dataset)\n    accuracy_list.append(accuracy)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        accuracy))","553b347a":"print(\"Training on \", device)\nmodel_fnn_2 = FashionCNN()\nmodel_fnn_2.to(device)\noptimizer = optim.SGD(model_fnn_2.parameters(), lr=0.00005, momentum=0.0006)\nprint('Number of parameters: {}'.format(get_n_params(model_fnn_2)))\n\nfor epoch in range(0, 5):\n    scramble_train(epoch, model_fnn_2, fixed_perm)\n    scramble_test(model_fnn_2, fixed_perm)\n","9bf1321d":"# load data set\nx_l = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY_l = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')\nimg_size = 64\nplt.subplot(1, 2, 1)\nplt.imshow(x_l[260].reshape(img_size, img_size))\nplt.axis('on')\nplt.subplot(1, 2, 2)\nplt.imshow(x_l[900].reshape(img_size, img_size))\nplt.axis('on')","284ef659":"x_l = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY_l = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')\n# Join a sequence of arrays along an row axis.\nX = np.concatenate((x_l[204:409], x_l[822:1027] ), axis=0) # from 0 to 204 is zero sign and from 205 to 410 is one sign \nz = np.zeros(205)\no = np.ones(205)\nY = np.concatenate((z, o), axis=0).reshape(X.shape[0],1)\nprint(\"X shape: \" , X.shape)\nprint(\"Y shape: \" , Y.shape)\n# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]","e35ecdd5":"# Join a sequence of arrays along an row axis.\nX = np.concatenate((x_l[204:409], x_l[822:1027] ), axis=0) # from 0 to 204 is zero sign and from 205 to 410 is one sign \nz = np.zeros(205)\no = np.ones(205)\nY = np.concatenate((z, o), axis=0).reshape(X.shape[0],1)\nprint(\"X shape: \" , X.shape)\nprint(\"Y shape: \" , Y.shape)","34ec635b":"# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]","3614bb72":"X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\nX_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\nprint(\"X train flatten\",X_train_flatten.shape)\nprint(\"X test flatten\",X_test_flatten.shape)","213127de":"x_train = X_train_flatten.T\nx_test = X_test_flatten.T\ny_train = Y_train.T\ny_test = Y_test.T\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","f450f624":"# intialize parameters and layer sizes\ndef initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n                  \"bias1\": np.zeros((3,1)),\n                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n                  \"bias2\": np.zeros((y_train.shape[0],1))}\n    return parameters","37863d96":"def forward_propagation_NN(x_train, parameters):\n\n    Z1 = np.dot(parameters[\"weight1\"],x_train) +parameters[\"bias1\"]\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n    A2 = sigmoid(Z2)\n\n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n    \n    return A2, cache","e153531a":"# Compute cost\ndef compute_cost_NN(A2, Y, parameters):\n    logprobs = np.multiply(np.log(A2),Y)\n    cost = -np.sum(logprobs)\/Y.shape[1]\n    return cost","7e0ac53f":"# Backward Propagation\ndef backward_propagation_NN(parameters, cache, X, Y):\n\n    dZ2 = cache[\"A2\"]-Y\n    dW2 = np.dot(dZ2,cache[\"A1\"].T)\/X.shape[1]\n    db2 = np.sum(dZ2,axis =1,keepdims=True)\/X.shape[1]\n    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n    dW1 = np.dot(dZ1,X.T)\/X.shape[1]\n    db1 = np.sum(dZ1,axis =1,keepdims=True)\/X.shape[1]\n    grads = {\"dweight1\": dW1,\n             \"dbias1\": db1,\n             \"dweight2\": dW2,\n             \"dbias2\": db2}\n    return grads","2fe9020a":"# update parameters\ndef update_parameters_NN(parameters, grads, learning_rate = 0.01):\n    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n    \n    return parameters","9705e47b":"# prediction\ndef predict_NN(parameters,x_test):\n    # x_test is a input for forward propagation\n    A2, cache = forward_propagation_NN(x_test,parameters)\n    Y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(A2.shape[1]):\n        if A2[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction","6b5ae4f2":"import math\n\ndef sigmoid(x):\n    return 1 \/ (1 + math.e ** -x)","06b83b25":"# 2 - Layer neural network\ndef two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n    cost_list = []\n    index_list = []\n    #initialize parameters and layer sizes\n    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n\n    for i in range(0, num_iterations):\n         # forward propagation\n        A2, cache = forward_propagation_NN(x_train,parameters)\n        # compute cost\n        cost = compute_cost_NN(A2, y_train, parameters)\n         # backward propagation\n        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n         # update parameters\n        parameters = update_parameters_NN(parameters, grads)\n        \n        if i % 100 == 0:\n            cost_list.append(cost)\n            index_list.append(i)\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n    plt.plot(index_list,cost_list)\n    plt.xticks(index_list,rotation='vertical')\n    plt.xlabel(\"Number of Iterarion\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    \n    # predict\n    y_prediction_test = predict_NN(parameters,x_test)\n    y_prediction_train = predict_NN(parameters,x_train)\n\n    # Print train\/test Errors\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n    return parameters\n\nparameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=2500)","d55f59af":"x_l = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY_l = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')\n# Join a sequence of arrays along an row axis.\nX = np.concatenate((x_l[204:409], x_l[822:1027] ), axis=0) # from 0 to 204 is zero sign and from 205 to 410 is one sign \nz = np.zeros(205)\no = np.ones(205)\nY = np.concatenate((z, o), axis=0).reshape(X.shape[0],1)\nprint(\"X shape: \" , X.shape)\nprint(\"Y shape: \" , Y.shape)\n# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]","19a2643c":"def shuffel_pixels(idx, data):\n    data_new=np.zeros((data.shape))\n    for i,img in enumerate(data):\n        data_new[i] = img.flatten()[idx].reshape((64,64))\n    return data_new\n\nnp.random.seed(64)\nshuffel_idx = np.random.permutation(np.arange(64*64))\nX_train_shuffle = shuffel_pixels(shuffel_idx, X_train)\nX_test_shuffle = shuffel_pixels(shuffel_idx, X_test)","c8941a2a":"plt.figure(figsize=(12,12))\nfor i in range(0,4):\n    plt.subplot(1,4,(i+1))\n    plt.imshow((X_train_shuffle[i,:,:]),cmap=\"gray\")\n    plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i]))","9f30735a":"X_train_flatten_shuffle = X_train_shuffle.reshape(number_of_train,X_train_shuffle.shape[1]*X_train_shuffle.shape[2])\nX_test_flatten_shuffle = X_test_shuffle.reshape(number_of_test,X_test_shuffle.shape[1]*X_test_shuffle.shape[2])\nprint(\"X train flatten shuffled\",X_train_flatten_shuffle.shape)\nprint(\"X test flatten shuffled\",X_test_flatten_shuffle.shape)","236fd09a":"x_train = X_train_flatten_shuffle.T\nx_test = X_test_flatten_shuffle.T\ny_train = Y_train.T\ny_test = Y_test.T\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","b3f4dcaa":"# intialize parameters and layer sizes\ndef initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n                  \"bias1\": np.zeros((3,1)),\n                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n                  \"bias2\": np.zeros((y_train.shape[0],1))}\n    return parameters","1e7b3762":"def forward_propagation_NN(x_train, parameters):\n\n    Z1 = np.dot(parameters[\"weight1\"],x_train) +parameters[\"bias1\"]\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n    A2 = sigmoid(Z2)\n\n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n    \n    return A2, cache","b1293f00":"# Compute cost\ndef compute_cost_NN(A2, Y, parameters):\n    logprobs = np.multiply(np.log(A2),Y)\n    cost = -np.sum(logprobs)\/Y.shape[1]\n    return cost","944446fe":"# Backward Propagation\ndef backward_propagation_NN(parameters, cache, X, Y):\n\n    dZ2 = cache[\"A2\"]-Y\n    dW2 = np.dot(dZ2,cache[\"A1\"].T)\/X.shape[1]\n    db2 = np.sum(dZ2,axis =1,keepdims=True)\/X.shape[1]\n    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n    dW1 = np.dot(dZ1,X.T)\/X.shape[1]\n    db1 = np.sum(dZ1,axis =1,keepdims=True)\/X.shape[1]\n    grads = {\"dweight1\": dW1,\n             \"dbias1\": db1,\n             \"dweight2\": dW2,\n             \"dbias2\": db2}\n    return grads","da6d50de":"# update parameters\ndef update_parameters_NN(parameters, grads, learning_rate = 0.01):\n    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n    \n    return parameters","b7b107ba":"# prediction\ndef predict_NN(parameters,x_test):\n    # x_test is a input for forward propagation\n    A2, cache = forward_propagation_NN(x_test,parameters)\n    Y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(A2.shape[1]):\n        if A2[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction","33e01f7f":"import math\n\ndef sigmoid(x):\n    return 1 \/ (1 + math.e ** -x)","40eddee8":"# 2 - Layer neural network\ndef two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n    cost_list = []\n    index_list = []\n    #initialize parameters and layer sizes\n    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n\n    for i in range(0, num_iterations):\n         # forward propagation\n        A2, cache = forward_propagation_NN(x_train,parameters)\n        # compute cost\n        cost = compute_cost_NN(A2, y_train, parameters)\n         # backward propagation\n        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n         # update parameters\n        parameters = update_parameters_NN(parameters, grads)\n        \n        if i % 100 == 0:\n            cost_list.append(cost)\n            index_list.append(i)\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n    plt.plot(index_list,cost_list)\n    plt.xticks(index_list,rotation='vertical')\n    plt.xlabel(\"Number of Iterarion\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    \n    # predict\n    y_prediction_test = predict_NN(parameters,x_test)\n    y_prediction_train = predict_NN(parameters,x_train)\n\n    # Print train\/test Errors\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n    return parameters\n\nparameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=2500)","63702836":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n","4a7e642a":"X = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')","4f1ec4b5":"img_size = 64\nplt.subplot(1, 2, 1)\nplt.imshow(X[260].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(X[900].reshape(img_size, img_size))\nplt.axis('off')","e6eafddf":"# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n\nxTrain = xTrain.reshape(-1,64,64,1)\nxTest = xTest.reshape(-1,64,64,1)\n\nprint(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","8302f272":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu', input_shape = (64,64,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","14c44000":"optimizer = Adam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999)","db1cbcb4":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","624b8de3":"epochs = 15 #1 epoch means 1 forward and 1 backward pass.\nbatch_size = 20 # Number of training samples for one forward\/backward pass.","07fea37c":"datagen = ImageDataGenerator(\n        featurewise_center = False,  # set input mean to 0 over the dataset\n        samplewise_center = False,  # set each sample mean to 0\n        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n        samplewise_std_normalization = False,  # divide each input by its std\n        zca_whitening = False,  # dimesion reduction\n        rotation_range = 10,  # randomly rotate images in the range 10 degrees\n        zoom_range = 0.1, # Randomly zoom image 1%\n        width_shift_range = 0.1,  # randomly shift images horizontally 1%\n        height_shift_range = 0.1,  # randomly shift images vertically 1%\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip = False)  # randomly flip images\n\ndatagen.fit(xTrain)","7002acb6":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","80859478":"# fit the model\nhistory = model.fit_generator(datagen.flow(xTrain,\n                                           yTrain, \n                                           batch_size = batch_size), \n                              epochs = epochs, \n                              validation_data = (xTest, yTest), \n                              steps_per_epoch = xTrain.shape[0] \/\/ batch_size,\n                              callbacks = [annealer])","9c1f6650":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color = 'b', label = \"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","e5bd7d86":"# Predict the values from the validation dataset\nY_pred = model.predict(xTest)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(yTest,axis = 1) \nl=len(Y_true)\nk=0\nfor i in range(l):\n    if Y_true[i]==Y_pred_classes[i]:\n        k=k+1\nacc=(k*100)\/l\nprint(\"Test Accuracy = \",acc)\n# Y_true, Y_pred_classes","b3d2467b":"X = np.load('..\/input\/sign-language-digits-dataset\/X.npy')\nY = np.load('..\/input\/sign-language-digits-dataset\/Y.npy')\n\n# Join a sequence of arrays along an row axis.\nprint(\"X shape: \" , X.shape)\nprint(\"Y shape: \" , Y.shape)\n# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]","2b09f4b8":"def shuffel_pixels(idx, data):\n    data_new=np.zeros((data.shape))\n    for i,img in enumerate(data):\n        data_new[i] = img.flatten()[idx].reshape((64,64))\n    return data_new\n\nnp.random.seed(64)\nshuffel_idx = np.random.permutation(np.arange(64*64))\nX_train_shuffle = shuffel_pixels(shuffel_idx, X_train)\nX_test_shuffle = shuffel_pixels(shuffel_idx, X_test)\n","779580e1":"plt.figure(figsize=(12,12))\nfor i in range(0,4):\n    plt.subplot(1,4,(i+1))\n    plt.imshow((X_train_shuffle[i,:,:]),cmap=\"gray\")\n    plt.title('true label: '+np.str(np.argmax(Y_train,axis=1)[i]))","ed921a98":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu', input_shape = (64,64,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","edf7a1e4":"optimizer = Adam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999)","afbad448":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","03a9a58c":"epochs = 15 #1 epoch means 1 forward and 1 backward pass.\nbatch_size = 20 # Number of training samples for one forward\/backward pass.","c6fe274e":"X_train_shuffle = X_train_shuffle.reshape(-1,64,64,1)\nX_test_shuffle = X_test_shuffle.reshape(-1,64,64,1)","376a2058":"datagen = ImageDataGenerator(\n        featurewise_center = False,  # set input mean to 0 over the dataset\n        samplewise_center = False,  # set each sample mean to 0\n        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n        samplewise_std_normalization = False,  # divide each input by its std\n        zca_whitening = False,  # dimesion reduction\n        rotation_range = 10,  # randomly rotate images in the range 10 degrees\n        zoom_range = 0.1, # Randomly zoom image 1%\n        width_shift_range = 0.1,  # randomly shift images horizontally 1%\n        height_shift_range = 0.1,  # randomly shift images vertically 1%\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip = False)  # randomly flip images\n\ndatagen.fit(X_train_shuffle)","663089b7":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","c5787679":"# fit the model\nhistory = model.fit_generator(datagen.flow(X_train_shuffle,\n                                           Y_train, \n                                           batch_size = batch_size), \n                              epochs = epochs, \n                              validation_data = (X_test_shuffle, Y_test), \n                              steps_per_epoch = X_train_shuffle.shape[0] \/\/ batch_size,\n                              callbacks = [annealer])\n#X_train_shuffle, X_test_shuffle, Y_train, Y_test","9247e77a":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color = 'b', label = \"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","216e4c11":"# Predict the values from the validation dataset\nY_pred = model.predict(X_test_shuffle)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_test,axis = 1) \nl=len(Y_true)\nk=0\nfor i in range(l):\n    if Y_true[i]==Y_pred_classes[i]:\n        k=k+1\nacc=(k*100)\/l\nprint(\"Test Accuracy = \",acc)\n# Y_true, Y_pred_classes","00f42035":"### Playing with data and displaying some images using matplotlib imshow() method.\n\n\n\n","87b3fe7b":"**On scrambled dataset, CNNs fail to give proper accuracy, which means CNNs fails on scrambled dataset.**","071c48cc":"**We got a good accuracy on training a DNN on Sign Language Digits Dataset.**","c9e4423f":"**Import important libraries.**","c98c7325":"**If the GPU is available use it for the computation otherwise use the CPU.**","24d1ac15":"**Load train and test dataset.**","80077c4e":"### 2. Train a DNN on Scrambled Fashion MNIST dataset.","e64506e7":"**CNN**","3c3f2e80":"##  Fashion MNIST Dataset","7ff1aea1":"**Defining a class to build dataset using Pytorch.**","9c9fab73":"**Scramble**","c6e337a4":"**Plot of Accuracy vs Iterations**","165ab5bf":"**Defining a fully connected layered DNN.**","7df9b0e6":"**Defining a train and test function.**","118a5a31":"### 8. Train a CNN on Sign Language Digits Dataset. ","155bc782":"**We got a good accuracy on training a DNN on Fashion MNIST dataset.**","cfc5a6ca":"### 4. Train a CNN on Scrambled Fashion MNIST dataset.","5c6befb5":"## b. Sign Language Digits Dataset","3439ef40":"**Making permutations to see if DNNs use visual informations.**","ca0cf941":"**Accuracy still remains similar, on scrambled data for DNN.**","6ef3adaf":"**Training**","3a770b72":"### Observation: Model still gives good accuracy, so doesn't use visual information.","8a5a609a":"**Still got a similar accuracy again, on training a DNN on Scrambled Fashion MNIST dataset.**","64a91848":"**We got a good accuracy on training a CNN on Fashion MNIST dataset.**","49cb7b48":"**Lets visualize the outputs.**","a4083393":"**Defining a method to scramble the images.**","d90ae901":"### 3. Train a CNN on Fashion MNIST dataset.","0a45a2ed":"**Plot of Loss vs No of Iterations.**","d2067318":"**DNN**","b8f3223b":"**Transforming data into Tensor that has a range from 0 to 1.**","5f84cfec":"**Plot confusion matrix.**","bbc133ba":"### 7. Train a DNN on Scrambled Sign Language Digits Dataset .\n","4db59b9a":"**Re-train**","61ff7060":"### 1. Train a DNN on Fashion MNIST dataset.","145cceb4":"**DNN on scrambled**","0b3fcf88":"**Train**","0e035f24":"### 5. Conclusions.\n\n**1. DNN's dont use Visual Information**\n\n**2. CNN's uses Visual Information.** ","6856ae41":"### 6. Train a DNN on Sign Language Digits Dataset .","8df89ea7":"**Define a class for CNN model.**","797fdc58":"**CNN on scrambled data**","b1c4c8bd":"# **AML Assignment 1**","7010b992":"**CNN**","eb84f5c4":"### 9. Train a CNN on Scrambled Sign Language Digits Dataset .\n","a878f693":"### We have 10 types of clothes in FashionMNIST dataset.\n\n\n> Making a method that return the name of class for the label number.\nex. if the label is 5, we return Sandal.\n\n","0de6d99e":"## Table of Contents:\n**1. Train a DNN on Fashion MNIST dataset.**\n\n**2. Train a DNN on Scrambled Fashion MNIST dataset.**\n\n**3. Train a CNN on Fashion MNIST dataset.**\n\n**4. Train a CNN on Scrambled Fashion MNIST dataset.**\n\n**5. Conclusions.**\n\n**6. Train a DNN on Sign Language Digits Dataset .**\n\n**7. Train a DNN on Scrambled Sign Language Digits Dataset .**\n\n**8. Train a CNN on Sign Language Digits Dataset .**\n\n**9. Train a CNN on Scrambled Sign Language Digits Dataset .**\n\n**10. Conclusions.**\n","c09cce9d":"**We have got a good accuracy by training a CNN on Sign Language Digits Dataset.**","b3db6f2e":"**Scramble**","13f86f96":"### 10. Conclusions.\n\n**1. DNNs dont use Visual Information, as they are giving good accuracy even on scrambled dataset, where human's won't be able to recognize the images.**\n\n**2. CNNs use Visual Information as they are performing good on normal images, but their accuracy falls down a lot on the scrambled dataset.**","a07fa91d":"**Accuracy drops down badly for training a CNN on Scrambled Sign Language Digits Dataset.**","045120b4":"## Task 1:\n**DNN vs CNN experiments for the Fashion MNIST and Sign Language Digits datasets.**"}}