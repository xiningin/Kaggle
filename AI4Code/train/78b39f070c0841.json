{"cell_type":{"6048742b":"code","151e7531":"code","8795ac20":"code","60460817":"code","4693c0de":"code","8b6bb216":"code","89e8db3d":"code","9a5a436d":"code","c46e556c":"code","468ab0cd":"code","d7a77a52":"code","cdf1bb58":"code","a31bda35":"code","148b46d7":"code","d3a60d1c":"code","da197aa5":"code","4415247b":"code","33be7048":"code","c6f8d339":"code","2ccb9379":"code","8f520816":"code","d13eb24a":"code","684b065a":"code","764e49a9":"code","af5ca309":"code","4e3e8a90":"code","7014297a":"code","8ae64409":"markdown","b91233a8":"markdown","24dd3786":"markdown","a0051c93":"markdown","fff5d0c7":"markdown","88112499":"markdown","c16c0dc1":"markdown","dccfd318":"markdown","48310434":"markdown","1a07465c":"markdown","69bc3ae4":"markdown","9dd31374":"markdown","18817f53":"markdown","05a32623":"markdown","639dcaa5":"markdown","d223aca5":"markdown","60ca765c":"markdown","e2b224a6":"markdown","7f8530fe":"markdown","14903eab":"markdown","5c46ab4d":"markdown","ec57760e":"markdown","2c3c7f3c":"markdown","884ebf85":"markdown","d81cc055":"markdown"},"source":{"6048742b":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\n\nfrom numpy.random import seed\nseed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom keras.models import Model\n\nfrom tensorflow.random import set_seed\nset_seed(42)","151e7531":"df_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndf_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","8795ac20":"df_train","60460817":"df_test","4693c0de":"#https:\/\/www.kaggle.com\/gpreda\/cnn-with-tensorflow-keras-for-fashion-mnist\n\n#784 pixels(columns) -> 28x28 (height and width in pixels)\nIMG_ROWS = 28\nIMG_COLS = 28\nNUM_CLASSES = 10\n\ndef data_preprocessing(raw):\n    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES) \n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    \n    # Reshaping to (num_images, Width, Height, Colour Channels)\n    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n    \n    #Normalizing the values (pixel-value is an integer between 0 and 255)\n    out_x = x_shaped_array \/ 255\n    return out_x, out_y","8b6bb216":"X, Y = data_preprocessing(df_train)\nX_test, Y_test = data_preprocessing(df_test)","89e8db3d":"print('X_train shape: ', X.shape)\nprint('X_test shape: ', X_test.shape)","9a5a436d":"labels_list = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal'\n              ,'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nplt.figure(figsize=(12,12))\n\nfor i in range(0, 36):\n    plt.subplot(6,6,i + 1)\n    plt.imshow(X[i], cmap=plt.get_cmap('gray'))\n    plt.title(labels_list[df_train.iloc[i, 0]])\n    plt.axis(\"off\")\n\nplt.tight_layout()\n\nplt.show()","c46e556c":"plt.figure(figsize=(12,12))\n\nfor i in range(0, 36):\n    plt.subplot(6,6,i + 1)\n    plt.imshow(X_test[i], cmap=plt.get_cmap('gray'))\n    plt.title(labels_list[df_test.iloc[i, 0]])\n    plt.axis(\"off\")\n\nplt.tight_layout()\n\nplt.show()","468ab0cd":"print('Train Set Class Distribution:\\n')\nprint(df_train['label'].value_counts())\n\nprint('\\nTest Set Class Distribution:\\n')\nprint(df_test['label'].value_counts())","d7a77a52":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 42\n                                                    , stratify = Y)","cdf1bb58":"def get_model():\n    \n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_ROWS, IMG_COLS, 1))\n    \n    # Block One\n    x = layers.BatchNormalization()(inputs)\n    x = layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPool2D()(x)\n\n    # Block Two\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPool2D()(x)\n\n    # Head\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(64, activation='relu')(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","a31bda35":"#Setting early_stopping callback\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=15,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)","148b46d7":"keras.backend.clear_session()\n\nmodel_1 = get_model()\nmodel_1.compile(loss='categorical_crossentropy'\n              , optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics='accuracy')\n\nmodel_1.summary()","d3a60d1c":"history = model_1.fit(X_train, Y_train,\n          batch_size = 128, epochs = 100,\n          validation_data=(X_val, Y_val),\n          callbacks=[early_stopping]);","da197aa5":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'val'], loc='best')\nplt.show()","4415247b":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['accuracy'])\nsns.lineplot(x = history.epoch, y = history.history['val_accuracy'])\nax.set_title('Learning Curve (Accuracy)')\nax.set_ylabel('Accuracy')\nax.set_xlabel('Epoch')\nax.legend(['train', 'val'], loc='best')\nplt.show()","33be7048":"score = model_1.evaluate(X_val, Y_val, verbose = 0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","c6f8d339":"def get_model2():\n    \n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_ROWS, IMG_COLS, 1))\n    \n    # Block One\n    x = layers.BatchNormalization()(inputs)\n    x = layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.3)(x)\n\n    # Block Two\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.3)(x)\n\n    # Block Three\n    x = layers.BatchNormalization()(x)\n    x = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.3)(x)\n\n    # Head\n    x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(64, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","2ccb9379":"keras.backend.clear_session()\n\nmodel_2 = get_model2()\nmodel_2.compile(loss='categorical_crossentropy'\n              , optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics='accuracy')\n\nmodel_2.summary()","8f520816":"history = model_2.fit(X_train, Y_train,\n          batch_size = 128, epochs = 100,\n          validation_data=(X_val, Y_val),\n          callbacks=[early_stopping]);","d13eb24a":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","684b065a":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['accuracy'])\nsns.lineplot(x = history.epoch, y = history.history['val_accuracy'])\nax.set_title('Learning Curve (Accuracy)')\nax.set_ylabel('Accuracy')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","764e49a9":"score = model_2.evaluate(X_val, Y_val, verbose = 0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","af5ca309":"predictions = model_2.predict(X_test)\npred_labels = predictions.argmax(axis=-1) #From probabilities to class labels\nprint(\"Test Accuracy: \", accuracy_score(df_test['label'], pred_labels))","4e3e8a90":"print(metrics.classification_report(df_test['label'], pred_labels, target_names=labels_list))","7014297a":"prob_confusion_matrix = metrics.confusion_matrix(df_test['label'], pred_labels)\n\nplt.figure(figsize=(16,16))\n\nsns.heatmap(prob_confusion_matrix, annot=True, fmt=\"d\", cmap = 'viridis'\n           , xticklabels = labels_list, yticklabels = labels_list, annot_kws={'size': 13})\n            \nplt.xlabel(\"Predicted Label\", fontsize= 13)\nplt.ylabel(\"True Label\", fontsize= 13)\n\nplt.show()","8ae64409":"# <a id=\"4\">Improved Model<\/a> ","b91233a8":"### Context\nFashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\n### Content\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels, and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\n#### Labels\nEach training and test example is assigned to one of the following labels:\n\n- 0: T-shirt\/top\n- 1: Trouser\n- 2: Pullover\n- 3: Dress\n- 4: Coat\n- 5: Sandal\n- 6: Shirt\n- 7: Sneaker\n- 8: Bag\n- 9: Ankle boot","24dd3786":"First, we will split the train dataset into train\/validation.","a0051c93":"Let\u2019s train our baseline model and use the validation set for a first assessment of its performance.","fff5d0c7":"Both datasets have 785 columns. The first column presents the class labels for each article of clothing, while the remaining columns contains the pixel values. As described in the dataset information, each image is 28 pixels in height and 28 pixels in width (for a total of 784 pixels).\n\nWe will separate the labels from each dataset and reshape their columns from 784 columns to a 28x28x1 format (Height, Width and Number of Channels) using the preprocessing function found in Preda\u2019s notebook.  ","88112499":"## Overview\n\nThis is my first notebook on image classification using Convolutional Neural Networks. My motivation to create this notebook was to put in practice what I\u2019ve learned in Kaggle\u2019s Computer Vision course.\n\nI\u2019ve built two CNN models, one simpler to serve as a baseline and one improved version, with more convolutional layers and the addition of dropouts for regularization.\n\nValidation Accuracy (20% of train data):\n\n- Baseline CNN: 91.86%\n- Improved CNN: 93.58%\n\nTest Accuracy:\n\n- Improved CNN: 93.94%\n\nTo prepare the data, I used the preprocessing function found in [Gabriel Preda\u2019s](https:\/\/www.kaggle.com\/gpreda) notebook [\u2018CNN with Tensorflow|Keras for Fashion MNIST\u2019](https:\/\/www.kaggle.com\/gpreda\/cnn-with-tensorflow-keras-for-fashion-mnist). \n","c16c0dc1":"Now, let\u2019s build a new, better model. As previously stated, the solely addition of dropout layers could improve the validation accuracy. I\u2019ve tested this and found a validation accuracy of 93,36% (not shown in this notebook). There is still room to build a more robust CNN. After a few tests, I\u2019ve decided to include a third Conv Block, with 2 convolutional layers. Let\u2019s check the performance of this new model.","dccfd318":"## <center>If you find this notebook useful, support with an upvote!<center>","48310434":"Both datasets are perfectly balanced, with the samples equally distributed among the classes.","1a07465c":"# <a id=\"3\">Baseline Model<\/a> ","69bc3ae4":"Now, let\u2019s use our model to make predictions on the test set and check our results.","9dd31374":"Before we move on to the modelling stage, we will check the how many samples each class has.","18817f53":"The effect of the dropout layers can be observed by looking at the learning curves. The validation loss decreases for a longer period, reaching lower values than the one found in our baseline model, and it stabilizes at a certain point. The new model reached a validation accuracy of 93,58%, beating the baseline model.","05a32623":"# <a id='0'>Content<\/a>\n\n- <a href='#1'>Dataset Information<\/a>  \n- <a href='#2'>Importing Packages and Exploring the Data<\/a>  \n- <a href='#3'>Baseline Model<\/a>  \n- <a href='#4'>Improved Model<\/a>\n- <a href='#5'>Predictions on the Test Set<\/a>","639dcaa5":"# <a id=\"2\">Importing Packages and Exploring the Data<\/a> ","d223aca5":"Our baseline model reached a validation accuracy of 91.86%, which seems to be good. However, when we look at the learning curves (specifically the loss curves), we can see that the model is overfitting right after the first 5 epochs. This shows us that the addition of regularization methods, such as dropout layers, can probably improve our model\u2019s performance.","60ca765c":"## <center>If you find this notebook useful, support with an upvote!<center>","e2b224a6":"As we can see, the most difficult task for our model was to distinguish between shirts and T-shirts\/tops. 108 shirts were classified as T-shirts, while 58 T-shirts were assigned to the \u2018shirt\u2019 class. There is also a reasonable number of mispredictions involving Shirts and Coats as well.\n\nIt\u2019s interesting to notice that, if we consider the similarity between objects (e.g: Sandals, sneakers and ankle boots are somewhat similar and can be grouped as \u2018Footwear\u2019), there were only just a few cases of \u2018odd\u2019 misclassifications.","7f8530fe":"# <a id=\"5\">Predictions on the Test Set<\/a> ","14903eab":"Let\u2019s plot a few samples from each dataset to see what kind of images we have.","5c46ab4d":"<img src=\"https:\/\/raw.githubusercontent.com\/zalandoresearch\/fashion-mnist\/master\/doc\/img\/fashion-mnist-sprite.png\" width=\"500\" height=\"250\" align=\"center\"\/>","ec57760e":"Now, let's create our baseline model with two convolutional layers.","2c3c7f3c":"# <a id=\"1\">Dataset Information<\/a> ","884ebf85":"<br>\n<h1 style = \"font-size:30px; font-weight : bold; color : blue; text-align: center; border-radius: 10px 15px;\"> Fashion MNIST: Image Classification with Convolutional Neural Networks <\/h1>\n<br>\n\n---","d81cc055":"We were able to reach a test accuracy of 93.94% with the new model. As seen in the classification report, our model was almost perfect at predicting Trousers. The performance in predicting Sandals and Bags are also noticeable, with a 99% F1-Score. On the other hand, the model had some difficulties in predicting Shirts, with a Recall around 80% and less than 85% in Precision.\n\nLet\u2019s take a look at the confusion matrix to better understand these results."}}