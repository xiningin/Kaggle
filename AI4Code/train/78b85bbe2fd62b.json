{"cell_type":{"0d46a388":"code","4c5b6bd4":"code","e8a9ac9e":"code","ccf0f2cf":"code","226670a4":"code","88c84054":"code","a176b4dd":"code","abefe735":"code","1f98f51c":"code","41352c7d":"code","82fce2a2":"code","3e1c16c4":"code","b33b5a3c":"code","7d6a774e":"code","9efec3a5":"code","c4d93aee":"code","f3dbf353":"code","8c0def2e":"code","2cf436bd":"markdown","5064aec9":"markdown","6c28fc45":"markdown","64e224ea":"markdown","ff9d0d02":"markdown","b4597f36":"markdown","560f0ea1":"markdown","06927cc0":"markdown","af09d376":"markdown","8f67033a":"markdown","5cc42c5f":"markdown","9c67df23":"markdown","16106573":"markdown","8bc899dc":"markdown","3e3cd9cf":"markdown"},"source":{"0d46a388":"!pip install -q git+git:\/\/github.com\/oke-aditya\/pytorch_cnn_trainer.git","4c5b6bd4":"from pytorch_cnn_trainer import dataset\nfrom pytorch_cnn_trainer import model_factory\nfrom pytorch_cnn_trainer import utils\nfrom pytorch_cnn_trainer import engine","e8a9ac9e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport os\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n","ccf0f2cf":"# PyTorch Image model from Ross Wightman\nimport timm\n# All these models can be used with this code.\nprint(timm.list_models())","226670a4":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\",dtype = np.float32)\ntrain.head()","88c84054":"targets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values\/255 # normalization\n","a176b4dd":"features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,targets_numpy,test_size = 0.2,random_state = 2) ","abefe735":"X_train=torch.from_numpy(features_train)\ny_train=torch.from_numpy(targets_train).type(torch.LongTensor)\n\nX_test = torch.from_numpy(features_test)\ny_test = torch.from_numpy(targets_test).type(torch.LongTensor)","1f98f51c":"print(X_train.shape)","41352c7d":"X_train = X_train.reshape(-1, 1, 28, 28)\nX_test = X_test.reshape(-1, 1, 28, 28)","82fce2a2":"print(X_train.shape)\nprint(X_test.shape)","3e1c16c4":"batch_size = 32\n\ntrain=torch.utils.data.TensorDataset(X_train,y_train)\ntest=torch.utils.data.TensorDataset(X_test,y_test)\n\n\n# data loader\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n\n# visualize one of the images in data set\nplt.imshow(features_numpy[8].reshape(28,28))\nplt.axis(\"off\")\nplt.title(str(targets_numpy[8]))\nplt.savefig('graph.png')\nplt.show()\n","b33b5a3c":"MODEL_NAME = \"efficientnet_b3\"\nNUM_ClASSES = 10\nIN_CHANNELS = 1\nPRETRAINED = True  # If True -> Fine Tuning else Scratch Training\nEPOCHS = 3\nEARLY_STOPPING = True  # If you need early stoppoing for validation loss\nSAVE_PATH = \"{}.pt\".format(MODEL_NAME)\nSEED = 42","7d6a774e":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","9efec3a5":"print(\"Creating Model\")\nmodel = model_factory.create_timm_model(MODEL_NAME, num_classes=NUM_ClASSES, in_channels=IN_CHANNELS, pretrained=True)\nif torch.cuda.is_available():\n    print(\"Model Created. Moving it to CUDA\")\nelse:\n    print(\"Model Created. Training on CPU only\")\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","c4d93aee":"criterion = nn.CrossEntropyLoss()  # All classification problems usually need Cross entropy loss\nearly_stopper = utils.EarlyStopping(patience=7, verbose=True, path=SAVE_PATH)","f3dbf353":"history = engine.fit(\n    epochs=EPOCHS,\n    model=model,\n    train_loader=train_loader,\n    valid_loader=test_loader,\n    criterion=criterion,\n    device=device,\n    optimizer=optimizer,\n    early_stopper=early_stopper,\n)\nprint(\"Done !!\")","8c0def2e":"for epoch in tqdm(range(EPOCHS)):\n    print()\n    print(\"Training Epoch = {}\".format(epoch))\n    train_metrics = engine.train_step(model, train_loader, criterion, device, optimizer)\n    print()\n    print(\"Validating Epoch = {}\".format(epoch))\n    valid_metrics = engine.val_step(model, test_loader, criterion, device)\n    validation_loss = valid_metrics[\"loss\"]\n    early_stopper(validation_loss, model=model)\n\n    if early_stopper.early_stop:\n        print(\"Saving Model and Early Stopping\")\n        print(\"Early Stopping. Ran out of Patience for validation loss\")\n        break\n\n    print(\"Done Training, Model Saved to Disk\")","2cf436bd":"## Features of This trainer.\n\n1. Early stopping.\n2. Gradient Penalty.\n3. Works for both torchvision and Ross Wightman's models [timm](https:\/\/github.com\/rwightman\/pytorch-image-models)\n4. Supports .fit() like method to train\n5. Supports Quantizatoin training as well.\n\nYou can find source code, examples and all features here on GitHub https:\/\/github.com\/oke-aditya\/pytorch_cnn_trainer","5064aec9":"- The best part. We can simply do a .fit() method as in tf 2.x or Keras. It trains the model !!!","6c28fc45":"- I leave the submission to competition part as an exercise to the reader.\n- Trainer properly and submitting from this kernel will give you a very good LB Score.\n- You can a variety of models, all those in torchvision and timm. It is a generic trainer for all of these.\n- Check more about this package here on GitHub https:\/\/github.com\/oke-aditya\/pytorch_cnn_trainer\n- Do check the package and let me know in the comments below.","64e224ea":"\n## Install it\n","ff9d0d02":"\n\n- For hacky people, you simply use train_step and val_step to do it and customize the training too !!\n\n","b4597f36":"\n\nThat's it !!! Training done.\n\n- It automates the stuff that you shouldn't worry about. Written in Pure PyTorch it has no extra library requirements too.\n\n- Train_step is useful for experienced people who want to do something hacky in their loop.\n\n- The library has only 4 Files !!!. Model Factory, Engine, dataset and utils.\n\n- I will add more features and support soon.\n\n- If you like this kernel or package please do upvote and share with others.\n- Also checkout on Github as well and let me know what you think in comments !!\n\nPackage Link\nhttps:\/\/github.com\/oke-aditya\/pytorch_cnn_trainer\n","560f0ea1":"Thanks to user [Manav Kapadnis](https:\/\/www.kaggle.com\/manavkapadnis). I used his boiler plate to load the data !!!\nIt became much easier for me to complete the script","06927cc0":"# Make CNN Training Simple in Torch","af09d376":"## Final Word","8f67033a":"## Lets Train our Model","5cc42c5f":"# Loading The Dataset","9c67df23":"# Getting the Train and Test sets for model to operate on","16106573":"- Introducing PyTorch CNN Trainer.\n- A simple yet powerful trainer, which allows you to easily train over datasets.\n\n- It is very annoying to write training loop and training code for CNN training. Also to support all the training features it takes massive time.","8bc899dc":"## Creating Train and test dataset","3e3cd9cf":"\n## Split data into features(pixels) and labels(numbers from 0 to 9)\n- we normalize the values of feature so that it becomes easier for processing"}}