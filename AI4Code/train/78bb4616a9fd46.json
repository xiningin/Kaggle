{"cell_type":{"5fc953c8":"code","11f551d5":"code","323980a1":"code","57dbb24c":"code","44e4bf44":"code","dd503d54":"code","6cef4c72":"code","39b93bf7":"code","88ae1fa5":"code","775219cf":"code","3242d3e6":"code","9b96e3cc":"code","7caf9920":"code","d7e41586":"code","b3759662":"code","722e7906":"code","d663d31c":"code","41d39260":"code","adf0a100":"code","2bed76f8":"markdown","2029df05":"markdown","1b5adb1d":"markdown","93b086af":"markdown","6fed0c4c":"markdown","d1acee44":"markdown","a0c7ef36":"markdown","5407f121":"markdown","f7551c01":"markdown","1357ef2c":"markdown"},"source":{"5fc953c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11f551d5":"dataset = pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\", index_col = 0 , na_values = \"NA\")","323980a1":"dataset.head()","57dbb24c":"dataset.info()","44e4bf44":"dataset.isnull().sum()","dd503d54":"import seaborn as sns\n\nsns.countplot(x='RainTomorrow', data=dataset)\n","6cef4c72":"sns.countplot(x ='RainToday', data=dataset )","39b93bf7":"dataset.dropna(axis=0, subset = [\"RainTomorrow\",\"RainToday\"], inplace = True)","88ae1fa5":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","775219cf":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 1:6])\nX[:, 1:6] = imputer.transform(X[:, 1:6])\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 7:8])\nX[:, 7:8] = imputer.transform(X[:, 7:8])\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X[:, 10:-1])\nX[:, 10:-1] = imputer.transform(X[:, 10:-1])","3242d3e6":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='constant')\nimputer.fit(X[:, 6:7])\nX[:, 6:7] = imputer.transform(X[:, 6:7])\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='constant')\nimputer.fit(X[:, 8:10])\nX[:, 8:10] = imputer.transform(X[:, 8:10])","9b96e3cc":"x_check =pd.DataFrame(X)\nx_check.isnull().sum()","7caf9920":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\nprint(X)\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [54,56,57])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\nprint(X)\n# Encoding the independent Variable(Numeric)\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[:,-1] = le.fit_transform(X[:,-1])\nprint(X)","d7e41586":"\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)","b3759662":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","722e7906":"from sklearn.ensemble import RandomForestClassifier\nrandomforset = RandomForestClassifier(n_estimators = 10, random_state = 0)\nrandomforset.fit(X_train, y_train)","d663d31c":"prediction = randomforset.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nprint(confusion_matrix(y_test,prediction))\naccuracy_score(y_test, prediction)","41d39260":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)","adf0a100":"prediction = xgb.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nprint(confusion_matrix(y_test,prediction))\naccuracy_score(y_test, prediction)","2bed76f8":"# Encoding categorical data","2029df05":"# Dependant variable ","1b5adb1d":"# Import the data","93b086af":"Check our dataset","6fed0c4c":"# Splitting the dataset into the Training set and Test set","d1acee44":"Random Forest Classifier","a0c7ef36":"taking care of missing data (categorical)","5407f121":"Creat X and Y","f7551c01":"Taking care of missing data (numeric)","1357ef2c":"# Encoding the Dependent Variable"}}