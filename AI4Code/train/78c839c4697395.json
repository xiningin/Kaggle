{"cell_type":{"b1b031ec":"code","c0617209":"code","f58fcee3":"code","13a9744b":"code","2ad1378a":"code","983c059d":"code","78bcf210":"code","9f24beaf":"code","87b6489b":"code","25ac463c":"code","a62d4a6d":"code","7ee766c0":"code","90c0726b":"code","a8de1348":"code","11811010":"code","c9d6813a":"code","6853245d":"code","3ed997ec":"code","2cbf4f89":"code","2ba4ffb7":"code","bf46778e":"code","c16f6431":"code","6394da8f":"code","d53e70e5":"code","5d51f15e":"code","4a430efc":"code","f90769f2":"code","a7850741":"code","ee1fe150":"code","635558e3":"code","37759a58":"code","bc71b7ed":"code","b6596f9a":"code","effe7a74":"markdown","a315bc51":"markdown","f697cf92":"markdown","e988c156":"markdown","6675fa82":"markdown","7b2e8be5":"markdown","874b6005":"markdown","97e3f189":"markdown","57d5082d":"markdown"},"source":{"b1b031ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0617209":"!pip install calplot\n!pip install statsmodels","f58fcee3":"from pylab import rcParams\nimport calplot\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom math import sqrt\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n\nimport matplotlib.pyplot as plt","13a9744b":"train_df = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv')","2ad1378a":"print('Train data shape:', train_df.shape)\nprint('Test data shape:', test_df.shape)","983c059d":"train_df.head()","78bcf210":"# convert date to datetime\ntrain_df['date'] = pd.to_datetime(train_df['date'])\ntest_df['date'] = pd.to_datetime(test_df['date'])","9f24beaf":"#set date as index\ntrain_df = train_df.set_index('date')\ntest_df = test_df.set_index('date')","87b6489b":"train_df['meantemp'].plot(figsize=(12,4))","25ac463c":"ets_result = seasonal_decompose(train_df['meantemp'], model='additive')\nrcParams['figure.figsize'] = (12,5)\nets_result.plot();","a62d4a6d":"calplot.calplot(train_df['meantemp'], suptitle='Average delhi temperature in Yearly')","7ee766c0":"dd= np.asarray(train_df.meantemp)\ntest_df['naive'] = dd[len(dd)-1]","90c0726b":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['naive'], label='Naive Forecast')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\")\nplt.show()","a8de1348":"rms = sqrt(mean_squared_error(test_df.meantemp, test_df.naive))\nprint(rms)","11811010":"test_df['SA'] = train_df['meantemp'].mean()","c9d6813a":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['SA'], label='SA Forecast')\nplt.legend(loc='best')\nplt.title(\"Simple Average Forecast\")\nplt.show()","6853245d":"rms = sqrt(mean_squared_error(test_df.meantemp, test_df.SA))\nprint(rms)","3ed997ec":"train_df['7-SMA'] = train_df['meantemp'].rolling(window=7).mean()","2cbf4f89":"train_df[['meantemp','7-SMA']].plot(figsize=(15,5))","2ba4ffb7":"test_df['SMA'] = train_df['meantemp'].rolling(window=7).mean().iloc[-1]","bf46778e":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['SMA'], label='SMA Forecast')\nplt.legend(loc='best')\nplt.title(\"Simple Moving Average Forecast\")\nplt.show()","c16f6431":"span=7\nalpha = 2\/(span+1)","6394da8f":"freq = pd.infer_freq(train_df.index)\ntrain_df.index.freq = freq\ntest_df.index.freq = freq","d53e70e5":"model = SimpleExpSmoothing(train_df['meantemp'])\nfitted_model = model.fit(smoothing_level=alpha, optimized=False)\ntrain_df['SES7'] = fitted_model.fittedvalues","5d51f15e":"test_df['SES7'] = list(fitted_model.forecast(len(test_df)))","4a430efc":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['SES7'], label='SES7 Forecast')\nplt.legend(loc='best')\nplt.title(\"SES7 Forecast\")\nplt.show()","f90769f2":"# double exponential smoothing additive model\ndes_model = ExponentialSmoothing(train_df['meantemp'], trend='add')\nfitted_des_model = des_model.fit()\ntrain_df['DES_add_7'] = fitted_des_model.fittedvalues","a7850741":"test_df['DESAdd7'] = list(fitted_des_model.forecast(len(test_df)))","ee1fe150":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['DESAdd7'], label='DESAdd7')\nplt.legend(loc='best')\nplt.title(\"DES_add_7 Forecast\")\nplt.show()","635558e3":"test_df.head()","37759a58":"tes_mul_model = ExponentialSmoothing(train_df['meantemp'], trend='add',seasonal='add',seasonal_periods=7)\nfitted_tes_mul_model = tes_mul_model.fit()\ntrain_df['TES_add_7'] = fitted_tes_mul_model.fittedvalues","bc71b7ed":"test_df['TES_add_7'] = list(fitted_tes_mul_model.forecast(len(test_df)))","b6596f9a":"plt.figure(figsize=(12,5))\nplt.plot(train_df.index, train_df['meantemp'], label='Train')\nplt.plot(test_df.index,test_df['meantemp'], label='Test')\nplt.plot(test_df.index,test_df['TES_add_7'], label='TES_add_7')\nplt.legend(loc='best')\nplt.title(\"TES_add_7 Forecast\")\nplt.show()","effe7a74":"## Simple Exponential Smoothing\n\nIn this, forecast are calculated using weighted average where weights decreases exponentially as observation come from further in past. The smallest weight associated with the oldest observation.\n\n$$y_{t+1} = \\alpha y_{t}+\\alpha(1-\\alpha)y_{t-1}+\\alpha(1-\\alpha)^2y_{t-2}$$\n\nwhere:\n$0<=\\alpha<=1$ is a smoothing paramter\n\nThe above equation can be rewritten as :\n\n$$y_{t+1|t} = \\alpha*y_{t}+(1-\\alpha)*y_{t|t-1}$$ ","a315bc51":"As we can see from heatmap, May and June month have high temperature because it's the summer time in India.","f697cf92":"## triple Exponential Smoothing\n\nWith Triple Exponential Smoothing, we introduce a smoothing factor $\\gamma$ that addresses seasonality.\n\n$$l_{t} = (1-\\alpha)l_{t-1}+\\alpha x_{t}$$\n$$b_{t} = (1-\\beta)b_{t-1}+\\beta(l_{t}-l_{t-1})$$\n$$c_{t} = (1-\\gamma)c_{t-L}+\\gamma(x_{t}-l_{t-1}-b_{t-1})$$\n$$y_{t} = (l_{t}+b_{t})c_t$$\n$$y_{t+m} = (l_{t}+mb_{t})c_{t-L}+1+(m-1)modL$$\n\nwhere:\n\nL-> number of division\/cycle\nm-> number of periods in future","e988c156":"There's seasonality present in the data yearly. Every year pattern is repeating.\nNow let's plot ETS decomposition of the data.","6675fa82":"In this notebook, we will explore various smoothing techniques which we can perform on time series data.\n\nMethods Cover:\n1. Naive approach\n2. Simple Average\n3. Moving Average\n4. Simple Exponential Smoothing\n5. Holt's Method\n5. Holt's Winter Method","7b2e8be5":"## 1. Naive Approach\n\nNaive approach simply take previous day value to forecast future dates.\n\n$$y_{t+1}=y_{t}$$\n\nThis approach is helpful when the past target values are stable. ","874b6005":"## Double Exponential Smoothing\n\nPrevious methods fails to capture other contributing factors like Trend and Seasonality.\n\nHolt Winter's method able to capture seasonality. Holt Winter method comprises of the forecast equation and three smoothing equations:\n\n|             | Component   | Smoothing Parameter|\n| ----------- | ----------- |----------------------\n| $l_{t}$     | Level       | $\\alpha$           |\n| $b_{t}$     | Trend       | $\\beta$            |\n| $s_{t}$     | Seasonality | $\\gamma$           |\n\n\nhere equation will be:\n\n$$l_{t} = (1-\\alpha)l_{t-1}+\\alpha x_{t}$$\n$$b_{t} = (1-\\beta)b_{t-1}+\\beta(l_{t}-l_{t-1})$$\n$$y_{t} = l_{t}+b_{t}$$\n$$y_{t+1} = l_{t}+hb_{t}$$\n\nwhere:\nh-> number of periods in future\n\nHere name is double exponential because we are using two parameters $\\alpha$ and $\\beta$","97e3f189":"## Simple Averaging\n\nIt takes average of all the past target values and that average will be use to forecast the future dates.\n\n$$y_{t+1}=\\frac{1}{x}\\sum_{i=1}^{x}y_{i}$$","57d5082d":"## Moving Average\n\nIn previous method, we have to take mean of all previous data but using all previous data doesn't sound right when there's sudden change in behavious in  previous data. Therefore for improvement we will take average of the target variable for last few time periods.\n\n$$y_{t+1}=\\frac{1}{p}(y_{t-1}+y_{t-2}+y_{t-3}+.....+y_{t-p})$$"}}