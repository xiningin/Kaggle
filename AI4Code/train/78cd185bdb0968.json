{"cell_type":{"7c335c98":"code","a957df6c":"code","7716eb71":"code","9af5df7d":"code","f8f2c367":"code","6e5f2537":"code","b34daf08":"code","fea30e29":"markdown","e2fb63f1":"markdown","4eb0b39b":"markdown","3e8f9136":"markdown"},"source":{"7c335c98":"# encoding: utf-8\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport spacy\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a957df6c":"posFilePath = \"\/kaggle\/input\/humor-detection\/Short-Text-Corpus-For-Humor-Detection-master\/datasets\/humorous_oneliners.pickle\"\nnegFilePath = \"\/kaggle\/input\/humor-detection\/Short-Text-Corpus-For-Humor-Detection-master\/datasets\/wiki_sentences.pickle\"\nposData = pickle.load(open(posFilePath,'rb'))\nnegData = pickle.load(open(negFilePath,'rb'),encoding='utf-8')\nprint(\"The positive examples data contains {} sentences and the first one is: {}\".format(len(posData),posData[0]))\nprint(\"The negative examples data contains {} sentences and the first one is: {}\".format(len(negData),negData[0]))","7716eb71":"print(posData[:10])\nprint(negData[:10])","9af5df7d":"reuFilePath = \"\/kaggle\/input\/humor-detection\/Short-Text-Corpus-For-Humor-Detection-master\/datasets\/reuters_headlines.pickle\"\nreuData = pickle.load(open(reuFilePath,'rb'),encoding='utf-8')\nprint(\"The Reuters examples data contains {} sentences and the first one is: {}\".format(len(reuData),reuData[0]))\nprint(reuData[:10])","f8f2c367":"proFilePath = \"\/kaggle\/input\/humor-detection\/Short-Text-Corpus-For-Humor-Detection-master\/datasets\/proverbs.pickle\"\nproData = pickle.load(open(proFilePath,'rb'),encoding='utf-8')\nprint(\"The proverb example data contains {} sentences and the first one is: {}\".format(len(proData),proData[0]))\nprint(proData[:10])","6e5f2537":"from sklearn.feature_extraction.text import TfidfVectorizer\ndata = [' '.join(posData),' '.join(negData), ' '.join(reuData),' '.join(proData)]\nvectorizer = TfidfVectorizer(min_df=1, stop_words='english')\ntfidf = vectorizer.fit_transform(data)\nprint((tfidf*tfidf.T).toarray())","b34daf08":"\"\"\"\nnlp = spacy.load('en')\nposSpacy = nlp(' '.join(posData))\nnegSpacy = nlp(' '.join(negData))\nreuSpacy = nlp(' '.join(reuData))\nproSpacy = nlp(' '.join(proData))\nprint(\"The positive dataset similarity to the negative one is:{}\".format(posSpacy.similarity(negData)))\nprint(\"The positive dataset similarity to the reuters one is:{}\".format(posSpacy.similarity(reuData)))\nprint(\"The positive dataset similarity to the proverb one is:{}\".format(posSpacy.similarity(proData)))\n\"\"\"","fea30e29":"We want to create a positive\/negative set of data.\nAt first, we can check the datasets **humorous_oneliners.pickle** and **wiki_sentences.pickle** .","e2fb63f1":"We see in the above that the closest dataset (in terms of words) to the  positive one is the one we tagged as negative at the start.\nThere is still a huge bias in this selection but this will do for a first training set.","4eb0b39b":"Now we compare all those datasets to find the closest to the positive one","3e8f9136":"The negative data might be too random, let's see if some other data are useable."}}