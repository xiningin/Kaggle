{"cell_type":{"a2f64610":"code","695f5544":"code","45e87b7d":"code","e8f0c6d3":"code","76ac09c0":"code","09d94476":"code","8f380837":"code","93debbf8":"code","ebb9afcf":"code","9924607e":"code","a83a1237":"code","e1ae441d":"code","90fd1a79":"code","7604ea42":"code","a26948f4":"code","06fbd166":"code","de50d8cb":"code","0c0c0c97":"code","43b892e2":"code","076b2ed9":"code","cdb3034f":"code","0eb6ff8c":"code","b55f3305":"code","eb8c9bbf":"code","ef9d3a6d":"code","c85a8287":"code","5782b285":"code","d04d9635":"code","60aa615e":"code","e3aabef9":"code","c251a59f":"code","4f40356a":"code","8abac6a2":"code","1bca0909":"code","c9615aa0":"code","7f4685dc":"code","2545bbea":"markdown","db5c7bd5":"markdown","3ec8e90c":"markdown","b809d74a":"markdown","e69c67df":"markdown","b776a263":"markdown","0ac50246":"markdown","73152b2d":"markdown","d04877ac":"markdown","459300f5":"markdown","547ee933":"markdown","13832f22":"markdown","a049e090":"markdown","9cecb88b":"markdown","7a65b8e7":"markdown","1a785bb5":"markdown","9c387371":"markdown","f288bbbd":"markdown","b3951f67":"markdown","32e2a08f":"markdown"},"source":{"a2f64610":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","695f5544":"train=pd.read_csv(\"\/kaggle\/input\/uci-turkiye-student-evaluation-data-set\/turkiye-student-evaluation_generic.csv\")","45e87b7d":"train.head()","e8f0c6d3":"sns.countplot(x=\"class\",data=train)","76ac09c0":"sns.countplot(x=\"class\",hue=\"nb.repeat\",data=train)","09d94476":"sns.countplot(x=\"nb.repeat\",hue=\"difficulty\",data=train)","8f380837":"sns.countplot(x=\"difficulty\",hue=\"nb.repeat\",data=train)","93debbf8":"sns.countplot(x=\"difficulty\",hue=\"attendance\",data=train)","ebb9afcf":"sns.countplot(x=\"class\",hue=\"instr\",data=train)","9924607e":"sns.countplot(x=\"class\",hue=\"difficulty\",data=train)","a83a1237":"for i in train.columns:\n    train.hist(i)\n    plt.show()","e1ae441d":"X_res=train.values","90fd1a79":"X_res","7604ea42":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nfeatures=scaler.fit_transform(X_res)","a26948f4":"features","06fbd166":"from sklearn.cluster import KMeans\nk = 5\nkmeans = KMeans(n_clusters=k, random_state=42)\ny_pred = kmeans.fit_predict(features)","de50d8cb":"kmeans.labels_","0c0c0c97":"kmeans.inertia_","43b892e2":"m=[]\nfor k in range(1,80):\n    km=KMeans(n_clusters=k, random_state=42).fit(features)\n    m.append(km.inertia_)\n","076b2ed9":"m","cdb3034f":"plt.figure(figsize=(20,10))\nplt.plot(range(1, 80),m, \"bo-\")\nplt.xlabel(\"$k$\", fontsize=14)\nplt.ylabel(\"Inertia\", fontsize=14)\nplt.show()","0eb6ff8c":"l=[]\np=[]\nfor k in range(1,10):\n    km=KMeans(n_clusters=k, random_state=42).fit(features)\n    l.append(km.inertia_)\n    p.append(km)\nplt.figure(figsize=(20,10))\nplt.plot(range(1, 10),l, \"bo-\")\nplt.xlabel(\"$k$\", fontsize=14)\nplt.ylabel(\"Inertia\", fontsize=14)\nplt.show()","b55f3305":"from sklearn.metrics import silhouette_score\nsilhouette_scores =[]\nfor model in p[1:]:\n    s=silhouette_score(features, model.labels_)\n    silhouette_scores.append(s)\n    ","eb8c9bbf":"plt.figure(figsize=(20, 10))\nplt.plot(range(1, 9),silhouette_scores, \"bo-\")\nplt.xlabel(\"$k$\", fontsize=14)\nplt.ylabel(\"Silhouette score\", fontsize=14)\n\nplt.show()\n","ef9d3a6d":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\n","c85a8287":"f=pca.fit_transform(features)","5782b285":"f","d04d9635":"l=[]\np=[]\nfor k in range(1,10):\n    km=KMeans(n_clusters=k, random_state=42).fit(features)\n    l.append(km.inertia_)\n    p.append(km)\nplt.figure(figsize=(20,10))\nplt.plot(range(1, 10),l, \"bo-\")\nplt.xlabel(\"$k$\", fontsize=14)\nplt.ylabel(\"Inertia\", fontsize=14)\nplt.show()","60aa615e":"silhouette_scores =[]\nfor model in p[1:]:\n    s=silhouette_score(f, model.labels_)\n    silhouette_scores.append(s)\nplt.figure(figsize=(20, 10))\nplt.plot(range(1, 9),silhouette_scores, \"bo-\")\nplt.xlabel(\"$k$\", fontsize=14)\nplt.ylabel(\"Silhouette score\", fontsize=14)\nplt.show()  ","e3aabef9":"kmeans = KMeans(n_clusters=4, random_state=42)\ny_pred = kmeans.fit_predict(f)","c251a59f":"t=kmeans.labels_","4f40356a":"plt.figure(figsize=(8, 6))\nplt.scatter(f[:,0], f[:,1], c=kmeans.labels_.astype(float))\nplt.show()","8abac6a2":"from sklearn.model_selection import train_test_split\n\nnp.random.seed(1234)\n\nx_train,x_test,y_train,y_test = train_test_split(f,t, train_size=0.80, random_state=42)","1bca0909":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrnd_clf = RandomForestClassifier(n_estimators=200, max_leaf_nodes=8, random_state=42)\ncv_scores = cross_val_score(rnd_clf, x_train, y_train, cv=10)\ncv_scores.mean()","c9615aa0":"rnd_clf.fit(x_train,y_train)\nrnd_clf.score(x_test,y_test)","7f4685dc":"n_estimator=[10,100,400,500,600,700,800,2000]\nmax_leaf_nodes=[2,4,6,8,16]\nfor i in n_estimator:\n    for k in max_leaf_nodes:\n       rnd_clf = RandomForestClassifier(n_estimators=i, max_leaf_nodes=k, random_state=42)\n       rnd_clf.fit(x_train, y_train)\n       t=rnd_clf.score(x_test,y_test)\n       print(i,k,t)\n    print(\"-\"*40)","2545bbea":"Easy courses are also repeated by students","db5c7bd5":"Our Random Forest Classifier is giving as 99% accuracy (min hyperparameter value for best score n_estimator=500,max_leaf_nodes=6)","3ec8e90c":"k=4 is the best value for number of cluster(Elbow method is giving k=3,4 silhoutte scores is giving k=4 so intersection will be k=4)","b809d74a":"value of k will be between 0 to 10","e69c67df":"Number of course taken by Student(course No. 3 is student favourite,Course No. 12 is mostly disliked by them)","b776a263":"\nSilhoutte curve is not as we want(their might be some error)","0ac50246":"Lets find suitable value for k using elbow method and silhoutte score","73152b2d":"# CLUSTERING","d04877ac":"# CLASSIFICATION ALGORITHM(MULTICLASS CLASSIFICATION)","459300f5":"Clustering after PCA in this case produce better silhoutte scores graph","547ee933":"we are getting 99% accuracy","13832f22":"# RANDOM FOREST CLASSIFIER IS THE BEST ALGORITHM TO SOLVE MULTICLASS CLASSIFICATION PROBLEMS","a049e090":"value of k  may be 3 lets cross check using silhoutte score (l stores model inertia,p stores all model","9cecb88b":"# DATA PREPROCESSING","7a65b8e7":"Lets try various n_estimators and max_leaf_nodes value","1a785bb5":"Instructor1:Course No.-2,7,10 Instructor2:Course No.-1,6,11,13 Instructor3:Course No.-3,4,5,8,9,12,13 Course No. 13 is jointly taken by Intructor1,Instructor2 Instructor1 is least popular May be","9c387371":"Elbow method again giving value of k to be 3 or 4","f288bbbd":"Course no. 13 is mostly repeated by students","b3951f67":"# DATA VISULIZATION","32e2a08f":"# May be we should try reducing dimensions before clustering "}}