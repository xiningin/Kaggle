{"cell_type":{"fe49ef9d":"code","9a5fa748":"code","828a71c4":"code","334abe20":"code","c63296cd":"code","7100623a":"code","4371cf04":"code","b3e324d6":"code","2240a327":"code","2d390d90":"code","9143ca9a":"code","6bb868c7":"code","d29b725d":"markdown","c4046507":"markdown","339a74a8":"markdown","ca6474f1":"markdown","87285df1":"markdown","88dfd4c0":"markdown","b102bf64":"markdown","de80994a":"markdown","be71caa8":"markdown","fab0d8da":"markdown","76a7b2f4":"markdown","8ab769fc":"markdown","a9e6949c":"markdown","e69f8687":"markdown","fc06397c":"markdown","010a14c1":"markdown","33c84487":"markdown","ed08e0d6":"markdown"},"source":{"fe49ef9d":"import pandas as pd\nfrom pathlib import Path\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt, image as img\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Conv2DTranspose,\n    MaxPool2D,\n    ReLU,\n    Flatten,\n    Dense,\n    UpSampling2D,\n)\nfrom tensorflow.keras.models import Model, Sequential\nfrom skimage.transform import resize\nfrom tensorflow import Tensor\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Input\nfrom tensorflow import Tensor\nfrom scipy.stats import mannwhitneyu\nfrom tabulate import tabulate\n\n# random seed generator\nnp.random.seed(3)\ntf.random.set_seed(7)\n\n","9a5fa748":"# To run independently in PC\n# # To get the path of root folder\n# def get_path():\n#     ROOT = Path(__file__).resolve().parent\n#     return ROOT\n\n\n# To load raw .png data\ndef load_raw_data():\n# Independent version\n#     covid_path = get_path() \/ \"data\/COVID\"\n#     non_covid_path = get_path() \/ \"data\/non-COVID\"\n\n    covid_path = \"..\/input\/sarscov2-ctscan-dataset\/COVID\"\n    non_covid_path = \"..\/input\/sarscov2-ctscan-dataset\/non-COVID\"\n\n    covid_images = list(Path(covid_path).glob(\"*.png\"))\n    non_covid_images = list(Path(non_covid_path).glob(\"*.png\"))\n\n    # To visualize the dataset\n    fig = plt.figure(figsize=(10, 10))\n    fig.add_subplot(1, 2, 1)\n    image = img.imread(covid_images[1])\n    plt.imshow(image)\n    plt.title(\"CT Scan of Covid Affected Lungs\")\n\n    fig.add_subplot(1, 2, 2)\n    image = img.imread(non_covid_images[1])\n    plt.imshow(image)\n    plt.title(\"CT Scan of Healthy Lungs\")\n    plt.savefig(get_path() \/ \"figs\/Dataset_example.png\")\n    return covid_images, non_covid_images","828a71c4":"# To convert .png image files to .npy numpy arrays\ndef convert_to_npy():\n    covid_images, non_covid_images = load_raw_data()\n    IMG_SIZE = 128\n\n    # https:\/\/www.kaggle.com\/travishong\/covid-19-lung-ct-segmentation-classification\/?select=CT_COVID\n    # Two empty numpy arrays to store coverted images\n    positive_npy = np.empty((len(covid_images), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n    negative_npy = np.empty((len(non_covid_images), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n\n    # Converting COVID dataset to .npy format\n    for i, _file in enumerate(covid_images):\n        image_npy = img.imread(_file)\n\n        # https:\/\/stackoverflow.com\/questions\/48121916\/numpy-resize-rescale-image\n        positive = resize(image_npy, (IMG_SIZE, IMG_SIZE, 1), anti_aliasing=True)\n        positive_npy[i] = positive\n    np.save(\n        \"..\/input\/processed-input\/positive.npy\",\n        positive_npy,\n        allow_pickle=False,\n        fix_imports=False,\n    )\n\n    # Converting non-COVID dataset to .npy format\n    for i, _file in enumerate(non_covid_images):\n        image_npy = img.imread(_file)\n\n        # https:\/\/stackoverflow.com\/questions\/48121916\/numpy-resize-rescale-image\n        negative = resize(image_npy, (IMG_SIZE, IMG_SIZE, 1), anti_aliasing=True)\n        negative_npy[i] = negative\n    np.save(\n        \"..\/input\/processed-input\/negative.npy\",\n        negative_npy,\n        allow_pickle=False,\n        fix_imports=False,\n    )","334abe20":"# To load .npy datasets\ndef load_data():\n    positive = np.load(\"..\/input\/processed-input\/positive.npy\")\n    positive_labels = [\"1\" for i in positive]\n    negative = np.load(\"..\/input\/processed-input\/negative.npy\")\n    negative_labels = [\"0\" for i in negative]\n\n    # Joining both datasets and labels\n    X = np.concatenate([positive, negative])\n    y = np.array((positive_labels + negative_labels), dtype=np.float32)\n    return X, y","c63296cd":"# Code to calculate AUC of each pixel after converting images to 3x3\n# def AUC():\npositive = np.load(\"..\/input\/processed-input\/positive.npy\")\nnegative = np.load(\"..\/input\/processed-input\/negative.npy\")\npositive = positive.squeeze()\nnegative = negative.squeeze()\nIMG_SHAPE = (1252, 3, 3)\npositive = np.resize(positive, IMG_SHAPE)\nnegative = resize(negative, IMG_SHAPE)\n# Group seperations\ng1 = positive\ng2 = negative\n# Feature names\nFEAT_NAMES = [\n    \"top-right\",\n    \"top-middle\",\n    \"top-left\",\n    \"middle-right\",\n    \"middle-middle\",\n    \"middle-left\",\n    \"bottom-right\",\n    \"bottom-middle\",\n    \"bottom-left\",\n]\n\n# An array to store pixelwise AUC\npixel_auc = []\n# An array to store aggregate AUC\nauc_array = []\n\n# To plot converted 3x3 images\nfig, ax = plt.subplots(4, 2, figsize=(10, 10))\nfor i, seg in enumerate(positive):\n    if i == 4:\n        break\n    ax[i, 0].imshow(positive[i].squeeze(), cmap=\"gray\")\n    ax[i, 1].imshow(negative[i].squeeze(), cmap=\"gray\")\nfig.suptitle(\n    \"Converted 3x3 images\",\n    fontsize=16,\n)\n# plt.savefig(get_path() \/ \"figs\/auc.png\")\n# plt.show()\n\n# To loop over each pixels in all images\nfor j in [0, 1, 2]:\n    for k in [0, 1, 2]:\n        for i in range(positive.shape[0]):\n            g1 = positive[: positive.shape[0], j, k]\n            g2 = negative[: negative.shape[0], j, k]\n            # print(g1, g2)\n            auc = mannwhitneyu(g1, g2).statistic \/ (len(g1) * len(g2))\n\n            pixel_auc.append(auc)\n        auc_array.append(np.nanmean(pixel_auc))\n\n# TO make a pandas dataframe of auc values with feature and AUC as columns\naucs = pd.DataFrame({\"Feature\": FEAT_NAMES, \"AUC\": auc_array})\nprint(tabulate(aucs, tablefmt=\"pipe\", headers=\"keys\"))","7100623a":"# Dice loss\ndef dice_loss(y_true: Tensor, y_pred: Tensor) -> Tensor:\n    y_true = tf.cast(y_true, tf.float32)\n    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n    denominator = tf.reduce_sum(y_true + y_pred)\n    return 1 - numerator \/ denominator\n\n\ndef dice(y_true: Tensor, y_pred: Tensor) -> Tensor:\n    return 1 - dice_loss(y_true, y_pred)","4371cf04":"# Unet Model\ndef unet():\n    input_shape = (128, 128, 1)\n\n    data = Input(shape=input_shape)\n\n    conv1 = Conv2D(padding=\"same\", filters=32, kernel_size=2)(data)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPool2D(2)(conv1)\n    conv2 = Conv2D(padding=\"same\", filters=64, kernel_size=2)(pool1)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPool2D(2)(conv2)\n    conv3 = Conv2D(padding=\"same\", filters=128, kernel_size=2)(pool2)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPool2D(2)(conv3)\n\n    bottleneck = Conv2D(padding=\"same\", filters=256, kernel_size=3)(pool3)\n\n    up1 = Conv2DTranspose(128, kernel_size=2, strides=2)(bottleneck)\n    r1 = tf.concat([conv3, up1], axis=-1)\n    conv9 = BatchNormalization()(r1)\n    up2 = Conv2DTranspose(64, kernel_size=2, strides=2)(conv9)\n    r2 = tf.concat([conv2, up2], axis=-1)\n    conv10 = BatchNormalization()(r2)\n    up3 = Conv2DTranspose(32, kernel_size=2, strides=2)(conv10)\n    r3 = tf.concat([conv1, up3], axis=-1)\n    conv11 = BatchNormalization()(r3)\n    output = Conv2D(1, kernel_size=1, activation=\"sigmoid\")(conv11)\n\n    model = Model(data, output)\n    return model","b3e324d6":"# CNN model\ndef cnn():\n    model = Sequential()\n    # First convulutional layer\n    model.add(\n        Conv2D(\n            32,\n            kernel_size=5,\n            activation=\"relu\",\n            input_shape=(128, 128, 1),\n        )\n    )\n    # Normalising after activation\n    model.add(BatchNormalization())\n    # Maxpooling to make features more distinct\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    # Second convulutional layer\n    model.add(Conv2D(64, kernel_size=5, activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    # fully connected layer\n    model.add(Dense(200, activation=\"relu\"))\n    # output\n    model.add(Dense(2, activation=\"softmax\"))\n    model.compile(\n        loss=keras.losses.sparse_categorical_crossentropy,\n        optimizer=keras.optimizers.SGD(lr=0.01),\n        metrics=[\"accuracy\"],\n    )\n    return model\n","2240a327":"# def test_unet():\nX, y = load_data()\nModel = unet()\n\nModel.compile(optimizer=\"rmsprop\", loss=dice_loss, metrics=dice)\n# Model.summary()\n\n# Model.save(get_path() \/ \"weights.h5\")     #To save the model as my computer is superslow\n\n# To load the saved model\nModel = load_model(\n    \"..\/input\/processed-input\/weights.h5\",\n    custom_objects={\"dice_loss\": dice_loss, \"dice\": dice},\n)\n\n# Model.fit(X, X, epochs=15)\n\nsegmented_images = Model.predict(X)\n\n# Plot segmented CT scans\nfig, ax = plt.subplots(3, 2, figsize=(10, 10))\nfor i, seg in enumerate(segmented_images):\n    if i == 3:\n        break\n    ax[i, 0].imshow(X[i].squeeze(), cmap=\"gray\")\n    ax[i, 1].imshow(seg.squeeze(), cmap=\"gray\")\nfig.suptitle(\n    \"Segmented images using Unet\\n Original CT Scan(Left) Segmented images(Right)\",\n    fontsize=16,\n)\n# plt.savefig(\"output\/figs\/segmented_images\")\nplt.show()\n# return segmented_images, y","2d390d90":"# To implement the CNN\n# def test_cnn(segemented):\n# X, y = test_unet()\n\nX_train, X_test, y_train, y_test = train_test_split(segmented_images, y, test_size=0.2, random_state=42)\nmodel = cnn()\n\nhistory_cnn = model.fit(\n    X_train,\n    y_train,\n    epochs=20,\n    workers=4,\n    validation_data=(X_test, y_test),\n)\n\ny_pred = model.predict(X_test)\npredicted = np.argmax(y_pred, axis=-1)\naccuracy = np.equal(y_test, predicted).mean()\nprint(\"Accuracy:\", accuracy)\n# learning_curve(history_cnn, segemented)  # To plot learning curve\n# if segemented == \"no\":\n#     Final_report(X_test, y_pred)  # To generate final report","9143ca9a":"\n# To plot learning curves\n# def learning_curve(history_cnn, segmented):\nfig, ax = plt.subplots(1, 2, figsize=(10, 10))\nax[0].set_title(\"Loss vs Epochs\")\nax[0].plot(history_cnn.history[\"loss\"])\nax[0].plot(history_cnn.history[\"val_loss\"])\nax[0].legend([\"train\", \"test\"])\nax[0].set_xlabel(\"epoch\")\nax[0].set_ylabel(\"loss\")\nax[0].set_xlim(1, 20)\nax[0].set_xticks(range(1, 21))\n\nax[1].set_title(\"Accuracy vs Epochs\")\nax[1].plot(history_cnn.history[\"accuracy\"])\nax[1].plot(history_cnn.history[\"val_accuracy\"])\nax[1].legend([\"train\", \"test\"])\nax[1].set_xlabel(\"epoch\")\nax[1].set_ylabel(\"accuracy\")\nax[1].set_xlim(1, 20)\nax[1].set_xticks(range(1, 21))\n\n# learning curve\nplt.show()\n#plt.savefig(\"output\/figs\/learningcurve_with_seg.png\")","6bb868c7":"# To print the final report\n# def Final_report(X_test, y_pred):\nj = 0\nk = 0\nfor i, label in enumerate(y_pred):\n\n    # Report for positive predicted cases\n    if (np.argmax(y_pred[i]) == 1.0) and (j < 1):\n        plt.title(\"Predicted Report\")\n        plt.imshow(X_test[i].squeeze(), cmap=\"gray\")\n        plt.xlabel(\n            \"Model predicted the result as POSITIVE with \"\n            + str(round((np.max(label) * 100), 2))\n            + \"% chance of Covid Infection\",\n            fontweight=\"bold\",\n        )\n\n        plt.show()\n        #plt.savefig(\"output\/figs\/positive_predicted_report.png\")\n        j = j + 1\n\n    # Report for negative predicted cases\n    if (np.argmax(y_pred[i]) == 0.0) and (k < 1):\n        plt.title(\"Predicted Report\")\n        plt.imshow(X_test[i].squeeze(), cmap=\"gray\")\n        plt.xlabel(\n            \"Model predicted the result as NEGATIVE with \"\n            + str(round((np.min(label) * 100), 2))\n            + \"% chance of Covid Infection\",\n            fontweight=\"bold\",\n        )\n        #plt.savefig(\"output\/figs\/negative_predicted_report.png\")\n        plt.show()\n        k = k + 1\n\n# if __name__ == \"__main__\":\n#     # convert_to_npy()  #To convert image dataset into numpy arrays\n#     AUC()  # To calculate AUC\n#     test_cnn(\"no\")  # CNN using Unsegmented CT scans\n#     test_cnn(\"yes\")  # CNN using segmented CT scans","d29b725d":"# Summary\nFrom the findings, a Convolutional Neural Network, trained using CT scans segmented by a pre-trained Unet, will be the best option for automating covid detetction. Although, the model is not perfectly reliable it can be used as a preliminary diagnosis method, for quick and easy detection of the virus infection.","c4046507":"A final report is generated based on the results predicted. For accurate and reliable diagnosis the confidence level of the model is also given. This report can be used as a preliminary way to detect the virus infection.","339a74a8":"**Loading the raw image datasets in to the environment.**","ca6474f1":"# References\n\n1. \u201cImaging Features of COVID-19.\u201d YouTube, YouTube, 19 Mar. 2020, www.youtube.com\/watch?v=g9jEk_gi__g. \n2. Soares, Eduardo, et al. \u201cSARS-CoV-2 CT-Scan Dataset: A Large Dataset of Real Patients CT Scans for SARS-CoV-2 Identification.\u201d MedRxiv, Cold Spring Harbor Laboratory Press, 1 Jan. 2020, www.medrxiv.org\/content\/10.1101\/2020.04.24.20078584v3. \n3. PlamenEduardo. \u201cSARS-COV-2 Ct-Scan Dataset.\u201d Kaggle, 30 May 2020, www.kaggle.com\/plameneduardo\/sarscov2-ctscan-dataset?select=non-COVID. ","87285df1":"Unet implementation","88dfd4c0":"Unet model\nskip connections adapted adapted https:\/\/www.programcreek.com\/python\/example\/89658\/keras.layers.Conv2D\n","b102bf64":"# To generate final report whether the patient is positive or negative.","de80994a":"CNN implementation","be71caa8":"Plotting learning curves to diagnose an underfit or overfit","fab0d8da":"CNN Model","76a7b2f4":"**Dice loss function and dice coefficient to calcualte loss in each epoch**\n\nThe `dice_loss` function below is an adaptation (and correction) of\nNieradzik, L. (2018, September 27). \nLoss Functions For Segmentation. Lars76.Github.Io.\nhttps:\/\/lars76.github.io\/2018\/09\/27\/loss-functions-for-segmentation.html","8ab769fc":"**Converting the raw data in to .npy files to train the CNN.**","a9e6949c":"**Calculating the AUC values**","e69f8687":"# Future work\nThe \"Ground glass opacities\" are also seen in normal pneumonia affected lungs. So, the model must also be trained to classify  covid pneumonia and normal pneumonia from the CT scans to make the automation more accurate and reliable.\n","fc06397c":"The pre-trained Unet is used to segment the scans. A CNN is then trained using these segmented images. It reached overfitting around 9-10 epochs with an accuracy of 96%.","010a14c1":"**Loading the converted dataset into the environment.**","33c84487":"# Covid-19 detection from lung CT-scan using Unet and CNN.\nCovid is an ongoing pandemic and the major concern is fast and reliable detection of the virus infection. This project aims in finding the best automation method for most accurate detection of the virus using lung CT scans.\n\nThe project concluded by finding that, Convolutional Neural Network trained using segmented CT scans, is the best automation method that can be implemented for faster and reliable detection of the virus infection.","ed08e0d6":"When both CT scans were compared, the Covid infected lungs has some grey markings scattered throughout the lungs. This is called \"Ground glass opacities\"(\u201cImaging Features of COVID-19\u201dwww.youtube.com\/watch?v=g9jEk_gi__g). This grey shades in CT scan is due to the accumulation of fluid in the alveoli, in covid infected lungs. This is the main and common feature that distinguishes infected and non-infected lungs."}}