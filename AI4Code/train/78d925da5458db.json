{"cell_type":{"44bd0b4a":"code","4e74342b":"code","367664d6":"code","76e4a27c":"code","abb691d4":"code","2ebd083c":"code","d122e887":"code","a22bb45e":"code","b92d54a3":"code","14fe42d0":"code","8684d8a1":"code","1c281694":"code","24d3e951":"code","38c7d87a":"code","90fa8204":"code","eff0165f":"code","630486fe":"code","c3bc1bb6":"code","4a002eec":"code","dcb53dbd":"code","9615437c":"code","37527a73":"code","4b5e4926":"code","e3ca0a4a":"markdown","13102c32":"markdown","91a8b5e2":"markdown","24742c85":"markdown","d9b5b58c":"markdown","4ee37d1f":"markdown","685ee8a6":"markdown"},"source":{"44bd0b4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e74342b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","367664d6":"df =  pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","76e4a27c":"df.describe().transpose()","abb691d4":"df.info()","2ebd083c":"df['Class'].value_counts()","d122e887":"df.corr()['Class']","a22bb45e":"df= df.drop('Time', axis =1)","b92d54a3":"fraud = df[df['Class'] == 1]\nnon_fraud = df[df['Class'] == 0]","14fe42d0":"non_fraud = non_fraud.sample(n = 1000)\nnon_fraud.shape","8684d8a1":"df = fraud.append(non_fraud)","1c281694":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","24d3e951":"X = df.drop('Class', axis = 1).values\ny = df['Class'].values","38c7d87a":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","90fa8204":"scaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","eff0165f":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","630486fe":"model = Sequential()\nmodel.add(Dense(29,activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(15,activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(8,activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(units=1,activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","c3bc1bb6":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=5, patience=35)","4a002eec":"model.fit(x=X_train, \n          y=y_train, \n          epochs=600,\n          batch_size= 128,\n          validation_data=(X_test, y_test), verbose=1,\n          callbacks=[early_stop]\n          )","dcb53dbd":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","9615437c":"predictions = model.predict_classes(X_test)","37527a73":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test,predictions))","4b5e4926":"print(confusion_matrix(y_test,predictions))","e3ca0a4a":"## Model creatation","13102c32":"## Scaling the Data","91a8b5e2":"Due to imbalanced dataset we can reduce the split to train the model","24742c85":"## Prediction and Evaluation","d9b5b58c":"## Quick EDA","4ee37d1f":"## Import of Libaries and data","685ee8a6":"# Credit Card Fraud Detection using Tensorflow"}}