{"cell_type":{"ba8e3816":"code","90a01d57":"code","5a4798f4":"code","21ea2441":"code","3c3d8420":"code","d2b9c3c1":"markdown","8d4ea4b9":"markdown","984b4ac3":"markdown","f57d8a8b":"markdown","49cac51d":"markdown","48dcac0c":"markdown","a72d24ca":"markdown","c4149b55":"markdown","7d69e135":"markdown","f18e28e2":"markdown","672d7bd5":"markdown","b853ad53":"markdown","2667d164":"markdown","571aa053":"markdown","accd0406":"markdown","63365ef8":"markdown"},"source":{"ba8e3816":"from IPython.display import Video\n\nVideo('..\/input\/big-data-bowl-play-examples\/prediction_close_to_true.mp4', width=1000, embed=True)","90a01d57":"Video('..\/input\/big-data-bowl-play-examples\/true_close_to_true.mp4', width=1000, embed=True)","5a4798f4":"Video('..\/input\/big-data-bowl-play-examples\/prediction_far_to_true.mp4', width=1000, embed=True)","21ea2441":"Video('..\/input\/big-data-bowl-play-examples\/true_far_to_true.mp4', width=1000, embed=True)","3c3d8420":"import pickle\n\nwith open('..\/input\/yoe-data\/goe_best_df.pkl', 'rb') as file:\n    best_df = pickle.load(file)\n\nfirst_last_20 = best_df.head(15).append(best_df.tail(15))\nfirst_last_20 = first_last_20.style.set_properties(**{'background-color':'yellow'}, subset=['yoe\/play'])\ndisplay(first_last_20)","d2b9c3c1":"## True Play","8d4ea4b9":"# Introduction\n\nLike in all areas in football, decision making in special teams is very important. The smallest decisions to take a step one way or another can have cascading effects on the outcome of the play. How can we quantify this though? How do we determine how optimal the true outcome was out of the infinite unrealized possibilities?\n\nThe idea is simple - if we can figure out how an \"average\" NFL player would perform in a given situation, we can compare it with the true play and capture something insightful. Thus we had two main objectives in this notebook. First we build a model that can predict the next state of an NFL play given the current state. Second, we use this model to evaluate special teams returners by calculating Yards Over Expected (YOE) yards.","984b4ac3":"# Data Preprocessing\n\nIn order to develop the model, we needed to filter and augment the data to suit our needs. We only considered plays where the special teams result was a return, with a few other additional parameters to keep the plays simple. For instance, we only considered plays where there were no penalties taken, so we can predict returns that do not result in a penalty. We also exclude plays where there were passes or fumbles to simplify the modeling process.\n\nThe input to our model is a 184 dimensional feature vector, representing 23 players each modeled by an eight dimensional feature vector. From the given data we aimed to use a player's x-position, y-position, speed, acceleration, orientation, and direction. The eight dimensional feature vector was comprised of adjusted x-position, adjusted y-position, speed, acceleration, sin orientation angle, cosine orientation angle, sin direction angle, and cosine direction angle.\n\nAdjusted (x,y) position - Instead of using the raw x,y coordinates and player directions, we adjust the spatial coordinates to account for the direction the team insteads to move. The adjusted x-coordinate denotes how many yards away from the ball-carrier's target endzone the player is while the adjusted y-coordinate denotes how far the player is from the middle of the field. Positive values denote the left side of the field when viewed as facing the target endzone.\n\nWe also adjust the angle measurements based on play direction, similarly to the x,y positions.\n\nSin and Cosine angles - Instead of directly predicting the orientation and direction angle, we decided to predict the sin and cosine of the angle. This is motivated by the fact that target angles are circular - a 0 degree angle and 359 degree angle are much closer together than indicated by simple loss functions such as MSE. Decomposing the angle into its sin and cosine components alleviates this issue, and allows us to easily reconstruct the original angle with the arctan function.\n\nWe also construct our input feature vector with a specific structure. The first eight-dimensional vector represents the ball-carrier and the second represents the football. The next 11 vectors represent the 10 opponent players, and they are sorted by closest to the ball-carrier. The final 10 vectors represent the 10 teammates, and they are sorted by closest to the ball-carrier.\n\nThe final remark we note is that we determined the start of the play when the 'event' variable equals either kick_received or punt_received. We determine the end of the play when 'event' equals tackle, out_of_bounds, touchdown, or fumble.","f57d8a8b":"This begs the question, when does the model produce a very different output than the true result? As we have shown the model simulates \"average\" plays, it usually diverges from the true result when there are atypical results. This could indicate a unique decision(s) being made by the ball carrier. In this case for example, the ball carrier's decision to change direction towards the middle of the field gains him an extra five yards.","49cac51d":"## True Play","48dcac0c":"# Simulated Examples","a72d24ca":"As an example of the model closely predicting the true outcome of a kickoff, we look at a 2018 game between the Atlanta Falcons vs Cleveland Browns. At the beginning of the second quarter, Jabrill Peppers returned Matt Bosher's kick for 21 yards in a seemingly conventional manner - upon receiving the ball he runs up and towards the sideline before being tackled around the touchback mark. The only slight difference is the model predicted the ball carrier to run closer to the middle of the field. But generally the model is close to the true play in situations such as these - when the true play could be thought of as an \"average\" return.","c4149b55":"## Model prediction","7d69e135":"# Future Work\n\nThere are two main areas we see that we could improve on. \n\n1) Building a better model\n\nThe model itself has several limitations that could be improved on. First, adding additional engineered features could improve the model loss. Effectively our entire input focuses on each player individually; i.e. we have eight features for every player and include every player (including the ball). There are no explicit features modeling any of the interactions between the players or the geometry of the current state. Directly creating these features could help the model learn better. Additionally, the model does not take into account differences between players - every player is effectively assumed to be equal. This is obviously not a true assumption and a model that could take into account the specific features of each player could be more accurate. \n\n2) Deeper applications\n\nWith a more complex model such as stated above, this could open the door for more complex analysis. For example, if the model accounted for specific players, then one could directly compare the difference between swapping different players in and out of a play. For example, what would be the difference if Chris Moore was returning the ball instead of Trent Taylor in a given play? ","f18e28e2":"## Takeaways\n\nOur work accomplishes its two primary goals. First, it shows that we can build a model that can do a more than reasonable job of simulating punt returns and kickoffs. Second, we provide one direct application of such a model by ranking special teams returners. YOE aims to quantify a special teams returner's talent by comparing each players performance to the simulated expected action. Done for each player as above, one can compare players based on their YOE.\n\nThis approach has many potential applications to NFL teams. Being able to simulate plays in general provides opportunity to compare actual events against hypothetical simulated situations. While we focused on the ball carrier, there is no reason one could not generalize this to any player on the field and see how their actions compare against simulated actions. Additionally, there is potential to analyze different structures and formations during these types of plays. For example, say a kickoff team is uncertain how they want to press the returning team. At the beginning of the play, one could pass as input into the model different starting formations and see which starting defensive position performs best. As another example, the returning team could try to determine which is the most effective positional structure to return the kickoff. How many teammates should be lined up how far from the ball receiver? Where should they start, where should they go? Simluating these different hypotheticals could provide this type of insight.","672d7bd5":"## Model Prediction","b853ad53":"![Basic neural net](https:\/\/www.tibco.com\/sites\/tibco\/files\/media_entity\/2021-05\/neutral-network-diagram.svg)","2667d164":"# Model\n\nMuch needs not to be said about the increasing prevalence of neural networks, as they are a powerful model architecture that have shown to be able to predict complex phenominom. We tried more powerful models such as multi-layered Convolutional Neural Networks but found that a simple two-layer neural network produced comparable outputs. The hidden layer size was 230 followed by a LeakyReLU activation function.","571aa053":"# Analysis\n\nThis motivates a way to measure punt\/kickoff return skill. With the model we can simulate what an \"average\" NFL player would do in the given situation. Thus we can calculate the expected number of yards an average player would gain. We can compare this to the actual number of yards gain to measure how well a player does at returning the ball.\n\nWe define Yards Over Expected (YOE) as precisely this. Below is a table of all the ball carriers from our test set (with at least five carries) and their given YOE per play. We see Chris Moore perform by far the highest with 8.43 yards over expected per play while Trent Taylor ranked last with -11.697 yards over expected per play.","accd0406":"# Appendix \n\n[github repo](https:\/\/github.com\/scottmaran\/big_data_bowl)","63365ef8":"We experimented with a couple different loss functions and settled on Mean Squared Error (MSE). A baseline model that predicts the next state as the current state achieves a loss of 0.5202. Our model achieves a loss of 0.279."}}