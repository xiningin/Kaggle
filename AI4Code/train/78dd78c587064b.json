{"cell_type":{"09a5822f":"code","906df8d3":"code","6ef2a4d3":"code","39f1eae3":"code","d6b429a0":"code","21f655e8":"code","eb95fd14":"code","fe98488f":"code","a155ee13":"code","3c53cf35":"code","54b2e3a8":"code","6ee9d034":"code","92c26cc0":"code","5051dacf":"code","8c927c45":"code","cef03993":"code","7e64f97d":"code","75d7139d":"code","17017903":"code","1f424a41":"code","489f2c81":"code","f9eafcdb":"code","4377bf0f":"code","919be312":"code","ab934c9a":"code","eb983202":"markdown","18e1223a":"markdown","a36b79f6":"markdown","fe74f518":"markdown","8df513a0":"markdown","9ebe0060":"markdown","efc52dd8":"markdown","2e178a14":"markdown","76f6972d":"markdown","58392c70":"markdown","f192874c":"markdown","a663534f":"markdown","1c408de2":"markdown","5c6eb448":"markdown","5410a7b1":"markdown","31cdf586":"markdown"},"source":{"09a5822f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os, random, torch, time, copy\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset\nfrom PIL import Image, ImageOps, ImageFilter\nfrom skimage.filters import threshold_local\n\nfrom torch.autograd import Variable","906df8d3":"# dataset_path = '.\/dataset'\ncovid_dataset_path = '..\/input\/covid-chest-xray'","6ef2a4d3":"classes = ['no-covid', 'covid']","39f1eae3":"class image_dataset(Dataset):\n    \"\"\"Class creator for the x-ray dataset.\"\"\"\n\n    def __init__(self, csv_path, root_dir, transform=None, phase=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.df = pd.read_csv(csv_path)\n        self.root_dir = root_dir\n        self.transform = transform\n        # If not a PA view, drop the line \n        self.df.drop(self.df[self.df.view != 'PA'].index, inplace=True)\n        self.phase = phase\n\n    def __len__(self):\n        \n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        if self.df['finding'].iloc[idx] != 'COVID-19':\n            finding = 0\n            img_path = os.path.sep.join([covid_dataset_path, 'images', self.df['filename'].iloc[idx]])\n            image = Image.open(img_path)\n            sample = {'image': image, 'finding': finding}\n            \n            if self.transform:\n                sample = {'image': self.transform[self.phase](sample['image']), 'finding': finding}\n\n        else:\n            finding = 1\n            img_path = os.path.sep.join([covid_dataset_path, 'images', self.df['filename'].iloc[idx]])\n            image = Image.open(img_path)\n            sample = {'image': image, 'finding': finding}\n\n            if self.transform:\n                sample = {'image': self.transform[self.phase](sample['image']), 'finding': finding}\n\n        return sample","d6b429a0":"xray_dataset = image_dataset(csv_path=os.path.sep.join([covid_dataset_path, 'metadata.csv']), root_dir=covid_dataset_path)","21f655e8":"class HistEqualization(object):\n    \"\"\"Image pre-processing.\n\n    Equalize the image historgram\n    \"\"\"\n    \n    def __call__(self,image):\n        \n        return ImageOps.equalize(image, mask = None) ","eb95fd14":"class ContrastBrightness(object):\n    \"\"\"Image pre-processing.\n\n    alpha = 1.0 # Simple contrast control [1.0-3.0]\n    beta = 0    # Simple brightness control [0-100]\n    \"\"\"\n    \n    def __init__(self, alpha, beta):\n        self.alpha = alpha\n        self.beta = beta\n    \n    def __call__(self,image,):\n        image = np.array(image)\n        for y in range(image.shape[0]):\n            for x in range(image.shape[1]):\n                image[y,x] = np.clip(self.alpha*image[y,x] + self.beta, 0, 255)\n\n                return Image.fromarray(np.uint8(image)*255)","fe98488f":"class SmothImage(object):\n    \"\"\"Image pre-processing.\n\n    Smooth the image\n    \"\"\"\n    def __call__(self,image):\n        \n        return image.filter(ImageFilter.SMOOTH_MORE)","a155ee13":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Grayscale(1),\n        transforms.RandomRotation(30, fill=(0,)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        ContrastBrightness(1.2,25),\n        HistEqualization(),\n        SmothImage(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5],\n                             [0.25])\n    ]),\n    'test': transforms.Compose([\n        transforms.Grayscale(1),\n        transforms.Resize(240),\n        transforms.CenterCrop(224),\n        ContrastBrightness(1.2,25),\n        HistEqualization(),\n        SmothImage(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5],\n                             [0.25])\n    ]),\n}","3c53cf35":"Nr = 4\nNc = 3\n\nfig, axs = plt.subplots(Nr, Nc,figsize=(20,10))\nfor i in range(Nr*Nc):\n    sample = xray_dataset[\n        i + random.randrange(\n            0, len(xray_dataset)-(Nr*Nc)\n        )]\n    \n    plt.subplot(Nr, Nc, i+1, aspect='auto')\n    plt.tight_layout()\n    plt.title('Finding: '+classes[sample['finding']])\n    plt.axis('off')\n    plt.imshow(sample['image'], cmap='gray')\n\nplt.show()","54b2e3a8":"scale = transforms.Resize(256)\ncrop = transforms.CenterCrop(400)\ncomposed = transforms.Compose([\n    transforms.Grayscale(1),\n    HistEqualization(),\n    transforms.RandomRotation(30, fill=(0,)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomResizedCrop(224),    \n])\n\n# Apply each of the above transforms on sample.\nfig = plt.figure(figsize=(18, 12))\nsample = xray_dataset[random.randrange(0, len(xray_dataset))]\nfor i, tsfrm in enumerate([scale, crop, composed]):\n    transformed_sample = tsfrm(sample['image'])\n\n    ax = plt.subplot(1, 3, i + 1)\n    plt.tight_layout()\n    plt.axis('off')\n    ax.set_title(type(tsfrm).__name__)\n    plt.imshow(transformed_sample, cmap='gray')\n\nplt.show()","6ee9d034":"xray_transform = image_dataset(\n    csv_path=os.path.sep.join([covid_dataset_path, 'metadata.csv']),\n    root_dir=covid_dataset_path,\n    transform=data_transforms,\n    phase='train'\n)","92c26cc0":"Nr = 4\nNc = 3\n\nfig, axs = plt.subplots(Nr, Nc,figsize=(20,10))\nfor i in range(Nr*Nc):\n    sample = xray_transform[\n        i + random.randrange(\n            0, len(xray_transform)-(Nr*Nc)\n        )]\n    \n    plt.subplot(Nr, Nc, i+1, aspect='auto')\n    plt.tight_layout()\n    plt.title('Finding: '+classes[sample['finding']])\n    plt.axis('off')\n    plt.imshow(sample['image'].numpy().transpose(1, 2, 0).reshape(224,224),cmap='gray') #tensor is (ch, w, h)\n\nplt.show()","5051dacf":"image_datasets = {\n    x: image_dataset(\n        csv_path=os.path.sep.join([covid_dataset_path, 'metadata.csv']),\n        root_dir=covid_dataset_path,\n        transform=data_transforms,\n        phase=x)\n    for x in ['train', 'test']\n}\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n                                              shuffle=True, num_workers=8)\n              for x in ['train', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","8c927c45":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25, device='cpu'):\n    \"\"\"\n    Support function for model training.\n\n    Args:\n      model: Model to be trained\n      criterion: Optimization criterion (loss)\n      optimizer: Optimizer to use for training\n      scheduler: Instance of ``torch.optim.lr_scheduler``\n      num_epochs: Number of epochs\n      device: Device to run the training on. Must be 'cpu' or 'cuda'\n    \"\"\"\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for data in dataloaders[phase]:\n                inputs = data['image']\n                labels = data['finding']\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            # deep copy the model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n      time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best validation Acc: {:4f}'.format(best_acc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","cef03993":"model = models.resnet18(\n    pretrained=True,\n    progress=True\n)","7e64f97d":"model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)","75d7139d":"num_ftrs = model.fc.in_features\n\nmodel.classifier = nn.Sequential(\n    nn.Dropout(p=0.5),\n    nn.Linear(num_ftrs, num_ftrs),\n    nn.Dropout(p=0.5),\n    nn.Linear(num_ftrs, 2),\n)\n\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = True","17017903":"criterion = nn.CrossEntropyLoss()\n\n# Note that we are only training the head.\noptimizer_ft = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.1)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.3)","1f424a41":"model_ft = train_model(model.to(device), criterion, optimizer_ft, exp_lr_scheduler,\n                        num_epochs=50, device=device)","489f2c81":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in dataloaders['test']:\n        inputs = data['image']\n        labels = data['finding']\n        outputs = model_ft(inputs.float().to(device))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.to(device)).sum().item()\n\nprint('Accuracy of the network: %d %%' % (\n    100 * correct \/ total))","f9eafcdb":"class_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\n\nwith torch.no_grad():\n    for data in dataloaders['test']:\n        images = data['image']\n        labels = data['finding']\n        outputs = model_ft(images.to(device))\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels.to(device)).squeeze()\n        for i in range(images.shape[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(2):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","4377bf0f":"dataloader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=(len(image_datasets['test'])), num_workers=8)\n\ndataiter = iter(dataloader)\ndata = dataiter.next()\nimages = data['image']\nlabels = data['finding']\n\nmodel_ft.to('cpu')\n\noutput = torch.tensor(model_ft(images).detach().numpy())","919be312":"from sklearn.metrics import classification_report\n# show a nicely formatted classification report\nprint(classification_report(labels, np.argmax(output,1), target_names=classes))","ab934c9a":"from sklearn.metrics import confusion_matrix\n\n# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(labels, np.argmax(output,1))\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) \/ total\nsensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n# show the confusion matrix, accuracy, sensitivity, and specificity\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","eb983202":"## Exemple of transform application\n#### tsfm = Transform(params)\n#### transformed_sample = tsfm(sample)","18e1223a":"## Load the pre-trained model","a36b79f6":"## Sampling the training images\n\n### Each iteration will give different images","fe74f518":"## Create paths","8df513a0":"## Create a train and test dataset and the dataloaders","9ebe0060":"## Add a front layer to receive the black and white images from the X-Ray","efc52dd8":"## CNN for classification\n\n### Transfer learning with Resnet18","2e178a14":"## Add a classification layer","76f6972d":"## Create a train method","58392c70":"## Fine tuning the model","f192874c":"## Creating the data transformations","a663534f":"## Evaluation","1c408de2":"## Import Libraries","5c6eb448":"## Ploting some X-Rays samples","5410a7b1":"## Creating a Dataset","31cdf586":"## Applying transformations"}}