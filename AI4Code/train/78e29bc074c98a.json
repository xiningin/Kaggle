{"cell_type":{"7394ef44":"code","cf7bc589":"code","81b62b25":"code","8f1d8851":"code","fd208dc5":"code","85c02094":"code","20ce8d23":"code","9625101e":"code","74d1bc37":"code","5cc8c189":"code","efe6202e":"code","602b97de":"code","f5ad140d":"code","67935342":"code","9262e9ac":"code","f8517e93":"code","f36ad6c8":"code","6aedc548":"code","284c9bef":"code","6d2e421f":"code","b23a006f":"code","462a2b00":"code","6c284d46":"code","8a82f6bf":"code","0e4238d9":"code","8bbef2a7":"code","157762a7":"code","7d400a59":"code","082c2706":"code","31f7dcc8":"code","e768d765":"code","ecbb3c7d":"code","02535428":"code","6edfa974":"code","04c08787":"code","7eafa3f2":"code","8f2f579c":"code","0d25e9f7":"code","4a374747":"code","9c836c4d":"code","fa577027":"code","7cfce415":"code","f9a16fa6":"code","033c9afe":"code","29502f65":"code","c849fa04":"code","210530ed":"markdown","4b862e43":"markdown","663f0948":"markdown","9182e268":"markdown"},"source":{"7394ef44":"import pandas as pd\nimport math\nimport re\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np","cf7bc589":"df=pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")","81b62b25":"df","8f1d8851":"df.isnull().sum()","fd208dc5":"ls=list()\nls=round(100*(df.isnull().sum()\/len(df.index)),4)\nls","85c02094":"df=df.drop(\"society\",axis=1)","20ce8d23":"df[\"location\"].value_counts()","9625101e":"df[\"location\"].fillna(\"Whitefield\",inplace=True)","74d1bc37":"df['size'].value_counts()","5cc8c189":"df[\"size\"].fillna(\"2 BHK\",inplace=True)","efe6202e":"df.isnull().sum()","602b97de":"df.describe()","f5ad140d":"df[\"bath\"].fillna(2.692610,inplace=True)","67935342":"df[\"balcony\"].fillna(1.584376,inplace=True)","9262e9ac":"df.isnull().sum()","f8517e93":"df['size'] = df['size'].str[0:2]\ndf['size']=df['size'].astype('int')\ndf","f36ad6c8":"df.info()\n","6aedc548":"df.total_sqft.unique()","284c9bef":"def convert_total_sqft(my_list):\n    if len(my_list) == 1:\n        \n        try:\n            return float(my_list[0])\n        except:\n            ls = ['Sq. Meter', 'Sq. Yards', 'Perch', 'Acres', 'Cents', 'Guntha', 'Grounds']\n            split_list = re.split('(\\d*.*\\d)', my_list[0])[1:]\n            area = float(split_list[0])\n            type_of_area = split_list[1]\n            if type_of_area == 'Sq. Meter':\n                area_in_sqft = area * 10.7639\n            elif type_of_area == 'Sq. Yards':\n                area_in_sqft = area * 9.0\n            elif type_of_area == 'Perch':\n                area_in_sqft = area * 272.25\n            elif type_of_area == 'Acres':\n                area_in_sqft = area * 43560.0\n            elif type_of_area == 'Cents':\n                area_in_sqft = area * 435.61545\n            elif type_of_area == 'Guntha':\n                area_in_sqft = area * 1089.0\n            elif type_of_area == 'Grounds':\n                area_in_sqft = area * 2400.0\n            return float(area_in_sqft)\n        \n    else:\n        return (float(my_list[0]) + float(my_list[1]))\/2.0","6d2e421f":"df['total_sqft'] = df.total_sqft.str.split('-').apply(convert_total_sqft)","b23a006f":"df = df.drop(df[df['bath']>5].index)\ndf = df.drop(df[df['size']>6].index)","462a2b00":"df['price_per_sqft'] = df['price']*100000\/df['total_sqft']","6c284d46":"df","8a82f6bf":"def remove_outlier(df1):\n    new_dataframe = pd.DataFrame()\n    for key, df2 in df1.groupby('location'):\n        m = np.mean(df2.price_per_sqft)\n        st = np.std(df2.price_per_sqft)\n        reduced_df = df2[(df2.price_per_sqft>(m-st)) & (df2.price_per_sqft<=(m+st))]\n        new_dataframe = pd.concat([new_dataframe,reduced_df],ignore_index=True)\n    return new_dataframe\n    ","0e4238d9":"df = remove_outlier(df)\ndf.shape","8bbef2a7":"df = remove_outlier(df)","157762a7":"df.drop(columns=['availability','area_type'],inplace = True)","7d400a59":"df.location = df.location.str.strip()\nlocation_count = df['location'].value_counts(ascending=False)","082c2706":"location_stats_less_than_8 = location_count[location_count<=8]","31f7dcc8":"df.location = df.location.apply(lambda x: 'other' if x in location_stats_less_than_8 else x)","e768d765":"df = df[df.location != 'other']","ecbb3c7d":"df.shape","02535428":"location = pd.get_dummies(df.location)","6edfa974":"df = pd.concat([df,location],axis='columns')","04c08787":"df.shape","7eafa3f2":"df1 = df.drop('location',axis = 1)\ndf1 = df1.drop(columns=['balcony','price_per_sqft'])\ndf1","8f2f579c":"x=df1.drop(\"price\",axis=1)\ny=df1[\"price\"]","0d25e9f7":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.4)\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nxtrain=sc.fit_transform(xtrain)\nxtest=sc.transform(xtest)","4a374747":"xtrain","9c836c4d":"!pip install lazypredict","fa577027":"from lazypredict.Supervised import LazyRegressor\nreg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\nmodels,predictions = reg.fit(xtrain, xtest, ytrain, ytest)","7cfce415":"models","f9a16fa6":"from sklearn.neural_network import MLPRegressor\nregr = MLPRegressor(random_state=1, max_iter=1000).fit(xtrain, ytrain)\nprint(\"Train Accuracy \",regr.score(xtrain,ytrain)*100)\nprint(\"Test Accuracy \",regr.score(xtest, ytest)*100)","033c9afe":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import GridSearchCV\nmodel_params = {\n    'MLP': {\n        'model': MLPRegressor(),\n        'params' : {\n            'max_iter':[1000],\n            'random_state':[1]\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestRegressor(),\n        'params' : {\n            'n_estimators': [1,5,10,20,25]\n        }\n    },\n    'GradientBoosting':{\n        'model':GradientBoostingRegressor(random_state=0),\n        'params':{\n            'n_estimators':[1500]\n        }\n    }\n}","29502f65":"scores=[]\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(xtrain,ytrain)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })","c849fa04":"df2 = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf2","210530ed":"****When we process the bath and size attribute we came across some conclusion that size of a flat can't be greator than 5 bhk or washroom's can't be greater than 6****","4b862e43":"****Now we can see that total_sqrt is of object datatype we have to convert it into int but their is some range in the column so we have to deal with it also and map the total_sqrt with area_type****","663f0948":"****Now we have earlier study in our 12th class that if we have a couple of data and if the value if greator than sum of mean and deviation or less than the difference between mean and standard deviation then the data point is invalid , in our case it's a outlier so we have to remove that Outlier****","9182e268":"****Now from above list we can conclude that society has 41% null values and Their is no sense to take that feature****"}}