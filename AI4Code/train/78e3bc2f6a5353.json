{"cell_type":{"a9e7c7ff":"code","a3ff01e5":"code","1e814f59":"code","8cf0093c":"code","640ae202":"code","ab407f7a":"code","0ed50b89":"code","e737fbb7":"code","0d621f56":"code","b3bfe34a":"code","7e4eaf76":"code","33ead83f":"code","3cddd8a3":"code","f8048da3":"code","3754fe75":"code","0d4dafbf":"code","a75ee76a":"code","4dd1d656":"code","3c991086":"code","4ea8c3b0":"code","44de8f1a":"code","f1b5ee13":"code","41079810":"code","d88029fa":"code","50711e5c":"code","3b5d0e22":"code","0a4f5c18":"code","6da8a1e7":"code","8f3d6aff":"code","03f443d4":"code","c8fac38f":"code","0c5c919d":"code","91b180a1":"code","de407814":"code","e49de5e9":"code","cb5aa2ba":"code","e984ff0a":"code","1392b688":"code","6c0a2072":"code","04635eef":"code","27d3da38":"code","82f24865":"code","b01b3c26":"code","00d46c37":"code","d87889f8":"code","276e0a29":"code","6be46f8b":"code","67f3f788":"code","77c3019c":"code","c2d1e0af":"code","82e4a13e":"code","18186219":"code","c38b7ba4":"code","ce16614d":"code","e8a26dd4":"code","fbb6eebf":"code","244bfdea":"code","4b65060a":"code","7f8bf3fb":"code","810879b1":"markdown","8509184f":"markdown","014b4db4":"markdown","539eb2db":"markdown","b7c15791":"markdown","6a033e60":"markdown","1da1f5ae":"markdown","2ba2c85a":"markdown","9cb658e3":"markdown","2029acf1":"markdown","7595427b":"markdown","8c7cb768":"markdown","4be4c7ff":"markdown","2b205084":"markdown","04b25cae":"markdown","b822efa3":"markdown","05e06751":"markdown","53e40d60":"markdown","30d87ab9":"markdown","2e662645":"markdown","ca92348b":"markdown","d2d3d18b":"markdown","fcdafdd8":"markdown","7a9667b9":"markdown","133c9f5d":"markdown","fdeb5cea":"markdown","d7bc397a":"markdown","79c87d68":"markdown","c80fa974":"markdown","ef44c919":"markdown","26652f8a":"markdown","29f503ff":"markdown","1d7456ed":"markdown","fbf86ed0":"markdown","0202d6b6":"markdown","f7d22623":"markdown","0b989633":"markdown","eda45693":"markdown","c177fd4a":"markdown","b6aa7279":"markdown","eaafceac":"markdown","5278c8f0":"markdown","75b5a00f":"markdown","294b3059":"markdown","d3592237":"markdown","5b95fca6":"markdown","3504ed5f":"markdown","8fb3d145":"markdown","fde71ce0":"markdown","b8d12409":"markdown","cb495f5a":"markdown","43fbbd88":"markdown","44b8974d":"markdown","8ed433d7":"markdown","d9ad22ff":"markdown","9c8cb6b7":"markdown","62b263b4":"markdown","832d1fff":"markdown","6c059e13":"markdown","95cdfe9b":"markdown","9e5821eb":"markdown","a494c0e6":"markdown","b6595d77":"markdown","d6f5fae1":"markdown","cea47498":"markdown","6059409d":"markdown","8b00a14b":"markdown","a1d013b8":"markdown","7d7e233b":"markdown","3bc94918":"markdown","11e6bee5":"markdown","d454d33a":"markdown","e8e5a29b":"markdown"},"source":{"a9e7c7ff":"# comandos m\u00e1gicos que n\u00e3o se comunicam com a linguagem Python e sim diretamente com o kernel do Jupyter\n# come\u00e7am com %\n\n%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","a3ff01e5":"# importando os principais m\u00f3dulos que usaremos ao longo da aula\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\n\nimport sklearn.neural_network\nimport sklearn.model_selection\nimport sklearn.metrics\n\nfrom tensorflow import keras","1e814f59":"print(np.__version__)\nprint(pd.__version__)\nprint(matplotlib.__version__)\nprint(sns.__version__)\nprint(sklearn.__version__)\nprint(keras.__version__)","8cf0093c":"from IPython.display import YouTubeVideo\nYouTubeVideo(\"EhXT_uWNuCg\")","640ae202":"YouTubeVideo(\"e65Ix1T1N2U\")","ab407f7a":"YouTubeVideo(\"cd-VSQeiPSM\")","0ed50b89":"mnist_PATH = '\/kaggle\/input\/digit-recognizer\/'\n\nmnist_train = pd.read_csv(mnist_PATH+'train.csv')\nmnist_test = pd.read_csv(mnist_PATH+'test.csv')","e737fbb7":"mnist_train","0d621f56":"X, y = mnist_train.iloc[:,1:].values\/255, mnist_train.iloc[:,0].values\n\nX.shape, y.shape","b3bfe34a":"# localiza\u00e7\u00e3o dos exemplos na matriz de dados \nloc = [0,1,20,34,54,659,541,5200,11200,16721,23000,24010,29050,30000,32000,34990,36000,37000,39000,41000]\n\n# selecionando os d\u00edgitos, j\u00e1 no formato de matriz\ndigitos = [X[i].reshape(28,28) for i in loc]\n\n# criando figura do matplotlib\nfig, ax = plt.subplots(1,len(loc),figsize=(18,0.5))\n\n# plotando!\n[ax[i].imshow(digitos[i], cmap = matplotlib.cm.binary, interpolation=\"nearest\") for i in range(len(loc))]\n\n# desligando os eixos de todos os d\u00edgitos\n[ax[i].axis('off') for i in range(len(loc))];","7e4eaf76":"X_treino, X_validacao, y_treino, y_validacao = sklearn.model_selection.train_test_split(X, y, \n                                                                                        test_size=0.1, \n                                                                                        random_state=0)\n\ny_treino.shape, y_validacao.shape","33ead83f":"fig, ax = plt.subplots(1,2,figsize=(13,4))\n\nsns.countplot(y_treino,ax=ax[0])\nsns.countplot(y_validacao,ax=ax[1])\n\nax[0].set_title('Treino')\nax[1].set_title('Valida\u00e7\u00e3o')\n\nfig.suptitle('Propor\u00e7\u00e3o de classes (d\u00edgitos)');","3cddd8a3":"m = sklearn.neural_network.MLPClassifier(random_state=0)\n\n%time m.fit(X_treino, y_treino)","f8048da3":"y_validacao_pred = m.predict(X_validacao)","3754fe75":"print(y_validacao)\nprint(y_validacao_pred)","0d4dafbf":"acc_tr = sklearn.metrics.accuracy_score(y_treino, m.predict(X_treino))\nacc_val = sklearn.metrics.accuracy_score(y_validacao, y_validacao_pred)\n\nprint(f'Acur\u00e1cia do treino: {acc_tr}')\nprint(f'Acur\u00e1cia da valida\u00e7\u00e3o: {acc_val}')","a75ee76a":"confusao = sklearn.metrics.confusion_matrix(y_validacao, y_validacao_pred)\nconfusao","4dd1d656":"def display_score(m):\n        \n    X = [X_treino, X_validacao]\n    y = [y_treino, y_validacao]\n\n    labels = ['Treino', 'Valida\u00e7\u00e3o']\n    \n    if isinstance(m, keras.models.Sequential):\n        if any([isinstance(l,keras.layers.Conv2D) for l in m.layers]):\n            X = [X[i].reshape(-1,28,28,1) for i in (0,1)]\n    \n    y_pred = [m.predict(X[i]) for i in (0,1)]\n    \n    if isinstance(m, keras.models.Sequential):\n        y_pred = [np.argmax(y_pred[i], axis=1) for i in (0,1)]\n\n    confusao = [sklearn.metrics.confusion_matrix(y[i], y_pred[i]) for i in (0,1)]\n\n    fig, ax = plt.subplots(1,2,figsize=(13,6.5))\n    \n    for i in (0,1):\n        \n        # dividindo cada valor da matriz pelo n\u00famero total de imagens em cada classe\n        row_sums = confusao[i].sum(axis=0, keepdims=True)\n        confusao_normalizada = confusao[i] \/ row_sums\n\n        # sumindo com a diagonal, pra podermos analizar s\u00f3 os erros:\n        np.fill_diagonal(confusao_normalizada, 0)\n        \n        # plotando a matriz!\n        ax[i].matshow(confusao_normalizada, cmap=plt.cm.Blues);\n        \n        # plotando os valores num\u00e9ricos\n        for j in range(len(confusao[i])):\n            for k in range(len(confusao[i])):\n                text = ax[i].text(k, j, confusao[i][j, k],\n                               ha=\"center\", va=\"center\", color=\"w\" if j!=k else \"dodgerblue\")\n                \n        # para exibir todos os n\u00fameros\n        ax[i].xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n        ax[i].yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n        \n        # t\u00edtulo\n        ax[i].set_title(f'{labels[i]}\\nAcur\u00e1cia: {sklearn.metrics.accuracy_score(y[i], y_pred[i]).round(4)}');","3c991086":"display_score(m)","4ea8c3b0":"def logistic(u): return 1\/(1 + np.exp(-u))\n\nx = np.linspace(-6,6)\nplt.plot(x,x>0,'--',label='heaviside')\nplt.plot(x,logistic(x), label='log\u00edstica')\nplt.axis('off')\nplt.legend();","44de8f1a":"m = keras.models.Sequential()\n\nm.add(keras.layers.Dense(200, input_shape = (784,), activation=\"relu\"))\nm.add(keras.layers.Dense(10, activation=\"softmax\"))","f1b5ee13":"m.summary()","41079810":"m.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","d88029fa":"%%time \n\nH = m.fit(X_treino, y_treino, \n          batch_size = 200, epochs = 10, \n          validation_data = (X_validacao, y_validacao));","50711e5c":"pd.DataFrame(H.history).plot();\nplt.xlabel('epoch');","3b5d0e22":"m.evaluate(X_validacao, y_validacao);","0a4f5c18":"display_score(m)","6da8a1e7":"def logistic(u): \n    return 1\/(1 + np.exp(-u))\ndef relu(u): \n    return np.where(u > 0, u, 0)\ndef leaky_relu(u, a = 0.1): \n    return np.where(u > 0, u, a*u)\ndef elu(u, a=1): \n    return np.where(u > 0, u, a*(np.exp(u)-1))\n          \nfuncs = [logistic, relu, leaky_relu, elu]\n\nformulas = [\"$f(u) = (1+e^{-u})^{-1}$\",\n            \"$f(u)=\\max(0,u)$\",\n            \"$f(u,a)=\\max(au,u)$\",\n            \"$f(u,a)=\\max(ae^{u-1},u)$\"]\n    \nfig, ax = plt.subplots(1,len(funcs), figsize=(15,3), sharey=True)\nx = np.linspace(-4,4)\n    \nfor i in range(len(funcs)):\n    ax[i].plot(x,funcs[i](x));\n    ax[i].grid('on');\n    ax[i].set_title(funcs[i].__name__+'\\n'+formulas[i])","8f3d6aff":"m = keras.models.Sequential([\n    \nkeras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=(28, 28, 1)),\nkeras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n    \nkeras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"),\nkeras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n    \nkeras.layers.Flatten(),\nkeras.layers.Dense(units=64, activation=\"relu\"),\n    \nkeras.layers.Dropout(0.2),\n    \nkeras.layers.Dense(units=10, activation=\"softmax\")\n    \n])\n\nm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","03f443d4":"m.summary()","c8fac38f":"%%time\nH = m.fit(X_treino.reshape(-1,28,28,1), y_treino,\n          batch_size=64, epochs=10,\n          validation_data = (X_validacao.reshape(-1,28,28,1), \n                             y_validacao))","0c5c919d":"pd.DataFrame(H.history).plot();\nplt.xlabel('epoch');","91b180a1":"display_score(m)","de407814":"# localiza\u00e7\u00e3o dos exemplos na matriz de dados \ny_validacao_pred = np.argmax(m.predict(X_validacao.reshape(-1,28,28,1)), axis=1)\nloc = np.where(y_validacao!=y_validacao_pred)[0]\n\n# selecionando os d\u00edgitos, j\u00e1 no formato de matriz\ndigitos = [X_validacao[i].reshape(28,28) for i in loc]\n\n# criando figura do matplotlib\nfig, ax = plt.subplots(max(1,len(loc)\/\/20+1),20,figsize=(18,1.7))\n\n# plotando!\n[ax.ravel()[i].imshow(digitos[i], cmap = matplotlib.cm.binary, interpolation=\"nearest\") for i in range(len(loc))]\n\n# desligando os eixos de todos os d\u00edgitos\n[ax.ravel()[i].axis('off') for i in range(len(ax.ravel()))];","e49de5e9":"from IPython.display import YouTubeVideo\nYouTubeVideo(\"4Lo3tcrz8U0\")","cb5aa2ba":"YouTubeVideo(\"mIpc2TaiZv0\")","e984ff0a":"YouTubeVideo(\"UC1RVfG2AfA\")","1392b688":"YouTubeVideo(\"L0Q6cboXyLY\")","6c0a2072":"technocast_PATH = '\/kaggle\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/'\n\ntechnocast_train_path = technocast_PATH + 'train\/'\ntechnocast_test_path = technocast_PATH + 'test\/'","04635eef":"dir1 = technocast_train_path+'\/ok_front\/'\ndir2 = technocast_train_path+'\/def_front\/'\n\nimg1 = plt.imread(dir1+random.choice(os.listdir(dir1)))\nimg2 = plt.imread(dir2+random.choice(os.listdir(dir2)))\n\nfig, ax = plt.subplots(1,2)\n\nax[0].imshow(img1)\nax[0].axis('off')\nax[0].set_title('ok')\n\nax[1].imshow(img2)\nax[1].axis('off');\nax[1].set_title('defeituosa');","27d3da38":"def make_generators():\n\n    datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255,\n                                                           validation_split = 0.1)\n    \n    train_generator = datagen.flow_from_directory(directory = technocast_train_path, \n                                                  batch_size = 32,\n                                                  target_size = (300, 300),\n                                                  color_mode = \"grayscale\",\n                                                  class_mode = \"binary\",\n                                                  classes = {\"ok_front\": 0, \"def_front\": 1},\n                                                  shuffle = True,\n                                                  #seed = 0,\n                                                  subset = \"training\")\n\n    validation_generator = datagen.flow_from_directory(directory = technocast_train_path,\n                                                       batch_size = 32,\n                                                       target_size = (300, 300),\n                                                       color_mode = \"grayscale\",\n                                                       class_mode = \"binary\",\n                                                       classes = {\"ok_front\": 0, \"def_front\": 1},\n                                                       shuffle = True,\n                                                       #seed = 0,\n                                                       subset = \"validation\")\n    \n    return train_generator, validation_generator","82f24865":"def visualizeImageBatch(datagen, title):\n    \n    '''\n    Adaptado de:\n    https:\/\/www.kaggle.com\/tomythoven\/casting-inspection-with-data-augmentation-cnn\n    '''\n    \n    mapping_class = {0: \"0 (ok)\", 1: \"1 (defeituosa)\"}\n    \n    images, labels = next(iter(datagen))\n    images = images.reshape(32, *(300,300))\n    \n    fig, axes = plt.subplots(4, 8, figsize=(13,6.5))\n\n    for ax, img, label in zip(axes.flat, images, labels):\n        ax.imshow(img, cmap = \"gray\")\n        ax.axis(\"off\")\n        ax.set_title(mapping_class[label], size = 12)\n\n    fig.tight_layout()\n    fig.suptitle(title, size = 16, y = 1.05)","b01b3c26":"train_generator, validation_generator = make_generators()\n\nvisualizeImageBatch(train_generator, 'Exemplo de minilote de treino')","00d46c37":"test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255)\n\nn_test = sum([len(files) for r, d, files in os.walk(technocast_test_path)])\n\ntest_generator = test_datagen.flow_from_directory(directory = technocast_test_path,\n                                                  batch_size = n_test,\n                                                  target_size = (300, 300),\n                                                  color_mode = \"grayscale\",\n                                                  class_mode = \"binary\",\n                                                  classes = {\"ok_front\": 0, \"def_front\": 1},\n                                                  shuffle = False)","d87889f8":"fig, ax = plt.subplots(1,3,figsize=(10,3))\n\nsns.countplot(train_generator.classes,ax=ax[0])\nsns.countplot(validation_generator.classes,ax=ax[1])\nsns.countplot(test_generator.classes,ax=ax[2])\n\nax[0].set_title('Treino')\nax[1].set_title('Valida\u00e7\u00e3o')\nax[2].set_title('Teste')\n\nfig.suptitle('Propor\u00e7\u00e3o de classes (normais\/defeituosas)')\nfig.tight_layout(rect=[0, 0.03, 1, 0.92]);","276e0a29":"def make_cnn():\n\n    m = keras.models.Sequential([\n\n    keras.layers.Conv2D(filters=16, kernel_size=(7,7), strides = 2, activation=\"relu\", \n                        padding=\"same\", input_shape=(300, 300, 1)),\n    keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n        \n    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n                \n    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n                \n    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n        \n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2),\n                \n    keras.layers.Flatten(),\n    keras.layers.Dense(units=64, activation=\"relu\"),\n\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Dense(units=1, activation=\"sigmoid\")\n\n    ])\n\n    m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return m","6be46f8b":"make_cnn().summary()","67f3f788":"early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5)","77c3019c":"%%time\n\n# n\u00famero de redes no ensemble\nn_models = 10\n\n# listas que armazenar\u00e3o os modelos e os hist\u00f3ricos de resultados\nm = [0]*n_models\nH = [0]*n_models\n\nfor i in range(n_models):\n\n    print(f'Rede {i+1}')\n    print('----------------------------------------')\n    \n    # gerando conjuntos de treino\/valida\u00e7ao diferentes a cada treinamento\n    train_generator, validation_generator = make_generators()\n    \n    # gerando o modelo\n    m[i] = make_cnn()\n    \n    # checkpoint para salvar o melhor modelo para a rede em quest\u00e3o\n    checkpoint = keras.callbacks.ModelCheckpoint(f\"technocast_cnn_{i+1}.hdf5\",\n                                                 save_best_only = True,\n                                                 monitor = \"val_loss\")\n    \n    print('Treinando...')\n    \n    # treinando a rede em quest\u00e3o\n    H[i] = m[i].fit(train_generator, validation_data = validation_generator, \n                    epochs = 30, callbacks=[early_stop,checkpoint], verbose=0)\n    \n    # imprimindo resultados ap\u00f3s o t\u00e9rmino do treino da rede em quest\u00e3o\n    epoch_min = pd.DataFrame(H[i].history).idxmin(axis=0)['val_loss']\n    print(f\"\u00c9pocas: {len(H[i].history['loss'])}\") \n    print(f\"loss: {H[i].history['loss'][epoch_min]:.4}, accuracy: {H[i].history['accuracy'][epoch_min]:.4}\")\n    print(f\"val_loss: {H[i].history['val_loss'][epoch_min]:.4}, val_accuracy: {H[i].history['val_accuracy'][epoch_min]:.4}\")\n    print('----------------------------------------\\n')","c2d1e0af":"fig, ax = plt.subplots(2,5, figsize=(20,5))\n\nfor i in range(n_models):\n    \n    pd.DataFrame(H[i].history).plot(ax=ax.ravel()[i], legend = True if i==0 else False);\n    plt.xlabel('epoch');","82e4a13e":"best_models = [keras.models.load_model(f\"technocast_cnn_{i+1}.hdf5\") for i in range(n_models)]","18186219":"def ensemble_prediction(generator):\n    \n    y_probs = [best_models[i].predict(generator).squeeze() for i in range(len(best_models))]\n    return np.mean(np.array(y_probs), axis=0)","c38b7ba4":"y_probs = ensemble_prediction(test_generator)","ce16614d":"y = test_generator.classes\ny_pred = y_probs>0.5\n\nprint(f'Acur\u00e1cia:{sklearn.metrics.accuracy_score(y, y_pred):.4}')\nprint('------------------------------')\nprint('Matriz de confus\u00e3o:')\nprint(sklearn.metrics.confusion_matrix(y, y_pred))","e8a26dd4":"print(f'Precis\u00e3o: {sklearn.metrics.precision_score(y, y_pred):.4}')\nprint(f'Revoca\u00e7\u00e3o: {sklearn.metrics.recall_score(y, y_pred):.4}')\nprint(f'F1: {sklearn.metrics.f1_score(y, y_pred):.4}')","fbb6eebf":"prob_x = np.linspace(0.01,0.99)\n\nrecall = [0]*len(prob_x)\nf1 = [0]*len(prob_x)\nprecision = [0]*len(prob_x)\n\nfor i in range(len(prob_x)):\n    y_pred_rp_curve = y_probs>prob_x[i]\n    recall[i] = sklearn.metrics.recall_score(y, y_pred_rp_curve)\n    f1[i] = sklearn.metrics.f1_score(y, y_pred_rp_curve)\n    precision[i] = sklearn.metrics.precision_score(y, y_pred_rp_curve)\n\nplt.plot(prob_x, recall,'.--')\nplt.plot(prob_x, f1,'*-')\nplt.plot(prob_x, precision,'.-')\n\nplt.xlabel('Probabilidade de corte')\nplt.legend(['revoca\u00e7\u00e3o','$F_1$','precis\u00e3o']);","244bfdea":"direc = technocast_test_path\nimgs = [plt.imread(direc+file) for file in test_generator.filenames]\n\nfig, ax = plt.subplots(715\/\/13,13, figsize=(18,100))\n\nfor i in range(715):\n    \n    ax.ravel()[i].imshow(imgs[i])\n    ax.ravel()[i].axis('off');\n    \n    color = ('black' if ((test_generator.labels[i]==0 and y_probs[i]<0.5)) or \n                        (test_generator.labels[i]==1 and y_probs[i]>=0.5) \n             else 'red')\n    \n    ax.ravel()[i].set_title(f'{test_generator.labels[i]}\\n {y_probs[i]:.2}', color=color)","4b65060a":"'''\nNo caso de o modelo atingir acur\u00e1cia de 100%, esta c\u00e9lula n\u00e3o rodar\u00e1\n'''\nif sklearn.metrics.accuracy_score(y, y_pred)<1:\n\n    direc = technocast_test_path\n\n    # selecionando as imagens com predi\u00e7\u00f5es erradas\n\n    wrong_positions = np.where(y!=y_pred)[0]\n    wrong_files = [test_generator.filenames[i] for i in wrong_positions]\n\n    imgs = [plt.imread(direc+file) for file in wrong_files]\n\n    # probabilidades para as imagens com predi\u00e7\u00f5es erradas\n    y_probs_wrong = ensemble_prediction((next(test_generator)[0][wrong_positions]))\n\n    fig, ax = plt.subplots(1,len(wrong_positions), figsize = (20,5))\n\n    # transformando objetos ax, y_probs_wrong e wrong_positions em containers caso nao sejam\n    # para podermos entrar no loop abaixo mesmo quando h\u00e1 apenas uma posi\u00e7\u00e3o errada\n    ax = np.array([ax]) if not hasattr(type(ax), '__iter__') else ax\n    y_probs_wrong = [y_probs_wrong] if not hasattr(type(y_probs_wrong), '__iter__') else y_probs_wrong\n    wrong_positions = [wrong_positions] if not hasattr(type(wrong_positions), '__iter__')  else wrong_positions\n\n    # plotando!\n\n    for i in range(len(wrong_positions)):\n\n        ax[i].imshow(imgs[i])\n        ax[i].axis('off');\n        ax[i].set_title(f'{test_generator.labels[wrong_positions[i]]}\\n {y_probs_wrong[i]:.2}')\n        ax[i].text(2, 15, str(wrong_positions[i]))\n\n    fig.suptitle('Amostra(s) classificada(s) incorretamente', fontsize=18)\n    fig.tight_layout(rect=[0, 0.03, 1, 0.9]);","7f8bf3fb":"'''\nNo caso de o modelo atingir acur\u00e1cia de 100%, esta c\u00e9lula n\u00e3o rodar\u00e1\n'''\nif sklearn.metrics.accuracy_score(y, y_pred)<1:\n    \n    direc = technocast_test_path\n\n    # selecionando as imagens com predi\u00e7\u00f5es longe de 0 e 1\n\n    mask = np.logical_and(y_probs > 0.2, y_probs < 0.8)\n\n    unusual_prob_positions = np.where(mask)[0]\n    unusual_prob_files = [test_generator.filenames[i] for i in unusual_prob_positions]\n\n    imgs = [plt.imread(direc+file) for file in unusual_prob_files]\n\n    # predi\u00e7\u00f5es propriamente ditas\n    y_probs_unusual = ensemble_prediction(next(test_generator)[0][unusual_prob_positions])\n\n    # gerando a janela do gr\u00e1fico\n\n    n_columns = 5\n    n_lines = max(1,max(1,len(unusual_prob_positions)\/\/n_columns+1))\n\n    fig, ax = plt.subplots(n_lines,n_columns, \n                           figsize = (20,4*n_lines))\n\n    # zerando todos os eixos antes de entrarmos no loop\n    [ax.ravel()[i].axis('off') for i in range(len(ax.ravel()))]\n\n    # plotando!\n\n    for i in range(len(unusual_prob_positions)):\n\n        ax.ravel()[i].imshow(imgs[i])\n\n        color = ('black' if ((test_generator.labels[unusual_prob_positions[i]]==0 and y_probs_unusual[i]<0.5)) or \n                            (test_generator.labels[unusual_prob_positions[i]]==1 and y_probs_unusual[i]>=0.5) \n                 else 'red')\n\n        ax.ravel()[i].set_title(f'{test_generator.labels[unusual_prob_positions[i]]}\\n {y_probs_unusual[i]:.2}',\n                               color = color)\n\n        ax.ravel()[i].text(2, 15, str(unusual_prob_positions[i]))\n\n    suptitle1 = f'{len(unusual_prob_positions)} amostras a serem encaminhadas para revis\u00e3o humana ({(len(unusual_prob_positions)\/715*100):.2}% do total)'\n    suptitle2 = f'das quais {np.in1d(unusual_prob_positions, wrong_positions).sum()} classificada(s) incorretamente.'\n\n    fig.suptitle(suptitle1+'\\n'+suptitle2,fontsize=18);\n\n    fig.tight_layout(rect=[0, 0.03, 1, 0.9])","810879b1":"# Rede convolucional no Keras\n\nComo no exemplo anterior, utilizaremos a classe [keras.models.Sequential()](https:\/\/keras.io\/api\/models\/sequential\/), mas, ao inv\u00e9s de usar a fun\u00e7\u00e3o `add`, dessa vez forneceremos as camadas como uma lista \u00e0 inicializa\u00e7\u00e3o do modelo:","8509184f":"# Detec\u00e7\u00e3o de falhas em um processo de fundi\u00e7\u00e3o\n\nNa aula passada, estudamos o problema de detec\u00e7\u00e3o de falhas no contexto do controle estat\u00edstico multivariado de processos, utilizando o modelo n\u00e3o-supervisionado PCA. \n\nNesta se\u00e7\u00e3o retomaremos o tema, abordando-o no contexto da vis\u00e3o computacional como um problema de classifica\u00e7\u00e3o bin\u00e1ria utilizando modelos supervisionados de redes convolucionais.","014b4db4":"Na matriz de confus\u00e3o, o elemento $C_{ij}$ corresponde \u00e0 quantidade de observa\u00e7\u00f5es da classe $i$ que foi confundida com a classe $j$. O elemento da diagonal principal $C_{ii}$ corresponde \u00e0 quantidade de predi\u00e7\u00f5es corretas da classe $i$.\n\nNota-se que as maiores fontes de confus\u00e3o s\u00e3o: \n\n* 9 sendo classificado como 4 (oito vezes);\n* 3 sendo classificado como 8 (sete vezes);\n* 8 sendo classificado como 6 (cinco vezes);\n* 9 sendo classificado como 7 (cinco vezes).\n\nA partir de agora, utilizaremos a fun\u00e7\u00e3o `display_score` para verificar o desempenho dos modelos:","539eb2db":"Percebe-se que apenas uma pequena fra\u00e7\u00e3o das amostras encontra-se na faixa considerada suspeita (no caso acima, 0,2<p<0,8).\n\nO uso de um ensemble de redes aumenta a acur\u00e1cia geral (reduzindo as amostras nessa faixa) e ajuda tamb\u00e9m a trazer as m\u00e9dias das predi\u00e7\u00f5es incertas para perto de 0,5 (o que tende a trazer as imagens com classifica\u00e7\u00f5es incorretas para dentro dessa faixa). \u00c9 um cen\u00e1rio favor\u00e1vel para a implementa\u00e7\u00e3o de uma estrat\u00e9gia de revis\u00e3o das predi\u00e7\u00f5es, resultando em um sistema de detec\u00e7\u00e3o que pode atingir acur\u00e1cia de 100% com baixo custo adicional de [HH (humano\/hora)](https:\/\/en.wikipedia.org\/wiki\/Man-hour).\n\nA estrat\u00e9gia de revis\u00e3o \u00e9 particularmente importante nesse processo porque mesmo baixas taxas de erro (de menos de 1%) podem resultar em consider\u00e1veis perdas econ\u00f4micas, j\u00e1 que o custo de um \u00fanico falso positivo ou negativo pode ser alto (como discutido [aqui](https:\/\/www.kaggle.com\/ravirajsinh45\/real-life-industrial-dataset-of-casting-product\/discussion\/129717)).\n\nSe voc\u00ea executar este notebook, provavelmente vai obter resultados diferentes dos apresentados aqui, principalmente quanto ao n\u00famero de classifica\u00e7\u00f5es incorretas no conjunto de teste (que varia de 0 a 4, em geral). Mas, particularmente, verifiquei dois pontos consistentes ao longo de todas as execu\u00e7\u00f5es que efetuei:\n\n* a precis\u00e3o \u00e9 mais alta que a revoca\u00e7\u00e3o na maior parte da faixa de probabilidades de corte;\n* as probabilidades das amostras classificadas incorretamente encontram-se perto de 0,5 (em geral abaixo, devido \u00e0 revoca\u00e7\u00e3o ser menor que precis\u00e3o).\n\nTalvez outra estrat\u00e9gia ou arquitetura leve a resultados mais est\u00e1veis. Voc\u00ea pode tentar :)\n\nPara concluir, \u00e9 importante fazer uma ressalva quanto \u00e0 natureza dos dados de teste. Muito provavelmente, nesse conjunto, eles n\u00e3o refletem o ambiente de produ\u00e7\u00e3o (em que, espera-se, a propor\u00e7\u00e3o de pe\u00e7as defeituosas seja bem menor que as normais). Portanto, na pr\u00e1tica, todos os resultados e conclus\u00f5es deveriam ser reobtidos com dados que reflitam a opera\u00e7\u00e3o da planta industrial, que infelizmente n\u00e3o est\u00e3o dispon\u00edveis para este estudo de caso.","b7c15791":"Os resultados j\u00e1 s\u00e3o bons mesmo na primeira \u00e9poca e v\u00e3o melhorando lenta e continuamente conforme o treinamento evolui. As curvas de treino e valida\u00e7\u00e3o est\u00e3o pr\u00f3ximas, um indicativo de que n\u00e3o h\u00e1 muito sobreajuste.\n\nPodemos usar o m\u00e9todo `evaluate` para avaliar rapidamente o desempenho final do modelo:","6a033e60":"## Escola Piloto Virtual - PEQ\/COPPE\/UFRJ\n## Data Science e Machine Learning na Pr\u00e1tica - Introdu\u00e7\u00e3o e Aplica\u00e7\u00f5es na Ind\u00fastria de Processos\n\nEste notebook \u00e9 referente \u00e0 Aula 3 do curso, que trata do problema de classifica\u00e7\u00e3o utilizando modelos de [redes neurais](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network).\n\nSer\u00e3o dois estudos de caso, ambos constituindo aplica\u00e7\u00f5es do tipo [vis\u00e3o computacional](https:\/\/pt.wikipedia.org\/wiki\/Vis%C3%A3o_computacional):\n\n* o [conjunto de dados MNIST](https:\/\/en.wikipedia.org\/wiki\/MNIST_database), talvez o exemplo mais famoso da \u00e1rea de aprendizado de m\u00e1quina;\n* um [conjunto de dados industrial](https:\/\/www.kaggle.com\/ravirajsinh45\/real-life-industrial-dataset-of-casting-product) com imagens de pe\u00e7as regulares e defeituosas resultantes de um [processo de fundi\u00e7\u00e3o](https:\/\/pt.wikipedia.org\/wiki\/Fundi%C3%A7%C3%A3o).","1da1f5ae":"Pronto! J\u00e1 podemos treinar. Na c\u00e9lula abaixo, as v\u00e1rias redes s\u00e3o treinadas em sequ\u00eancia. Repare na presen\u00e7a de outro callback, o `checkpoint`, instanciado da classe [ModelCheckpoint](https:\/\/keras.io\/api\/callbacks\/model_checkpoint\/) e respons\u00e1vel por salvar o modelo com melhor desempenho (medido em rela\u00e7\u00e3o \u00e0 perda da valida\u00e7\u00e3o). Isso \u00e9 \u00fatil porque n\u00e3o necessariamente o resultado da \u00faltima \u00e9poca \u00e9 o melhor.","2ba2c85a":"Como de costume, os tamanhos dos mapas de caracter\u00edsticas diminuem e o n\u00famero de filtros aumenta conforme se avan\u00e7a na profundidade. Perceba que o primeiro campo receptivo \u00e9 maior que os demais (7x7), o que pode ser conveniente para reduzir o tamanho da imagem sem perder muita informa\u00e7\u00e3o (e como s\u00f3 h\u00e1 em geral no m\u00e1ximo 3 canais na terceira dimens\u00e3o da entrada, a opera\u00e7\u00e3o n\u00e3o \u00e9 muito custosa).\n\nAbaixo definimos um [callback](https:\/\/keras.io\/api\/callbacks\/) para parada antecipada. *Callbacks* s\u00e3o objetos que efetuam a\u00e7\u00f5es durante o treinamento. No caso abaixo, o callback `early_stop`, definido a partir da classe [EarlyStopping](https:\/\/keras.io\/api\/callbacks\/early_stopping\/), ir\u00e1 monitorar a perda da valida\u00e7\u00e3o a cada \u00e9poca e, caso a diminui\u00e7\u00e3o nas \u00faltimas 5 \u00e9pocas n\u00e3o seja maior que $10^{-6}$, o treinamento ser\u00e1 finalizado.","9cb658e3":"## O processo\n\nO [conjunto de dados](https:\/\/www.kaggle.com\/ravirajsinh45\/real-life-industrial-dataset-of-casting-product), proveniente da companhia indiana [Pilot Technocast](http:\/\/www.pilottechnocast.com\/), \u00e9 composto por imagens de pe\u00e7as regulares e defeituosas resultantes de um processo de [fundi\u00e7\u00e3o](https:\/\/pt.wikipedia.org\/wiki\/Fundi%C3%A7%C3%A3o). Nesse processo, o material met\u00e1lico fundido \u00e9 alimentado a um molde e, durante o resfriamento, solidifica-se na forma desejada, como ilustrado a seguir:","2029acf1":"***M\u00e3o na massa 4!***\n\n* Tente aprimorar os desempenhos dos modelos deste notebook. H\u00e1 margem para melhorias nos resultados e nas efici\u00eancias computacionais. Algumas sugest\u00f5es:\n\n    * Varie as arquiteturas das redes e os demais hiperpar\u00e2metros (n\u00fameros de filtros, taxas de dropout, etc.).\n    * Crie ensembles nos casos em que usamos apenas um modelo (MNIST e Fashion MNIST). Teste v\u00e1rias estruturas para os ensembles (n\u00famero de modelos, arquitetura de cada modelo individual, maneira de agregar os resultados, etc.).\n    * Use a estrat\u00e9gia de [aumento de dados](https:\/\/en.wikipedia.org\/wiki\/Data_augmentation), que consiste em alimentar aos modelos n\u00e3o apenas as imagens originais e sim um conjunto potencialmente muito maior, composto por imagens com pequenas varia\u00e7\u00f5es das originais. Voc\u00ea pode implementar o aumento de dados facilmente fornecendo hiperpar\u00e2metros descrevendo as varia\u00e7\u00f5es das imagens \u00e0 classe `ImageDataGenerator` (cheque a [refer\u00eancia](https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class) para mais detalhes).\n    * Use modelos pr\u00e9-treinados para introduzir par\u00e2metros n\u00e3o-trein\u00e1veis nas primeiras camadas (transfer\u00eancia de aprendizado).\n    * etc, etc.\n    \nDurante seus testes, \u00e9 instrutivo verificar tamb\u00e9m quais modifica\u00e7\u00f5es n\u00e3o ajudam ou mesmo pioram o desempenho.\n    \nNa Internet, em particular no Kaggle e principalmente para o MNIST, voc\u00ea pode encontrar implementa\u00e7\u00f5es das ideias citadas acima ou de outras ideias. H\u00e1 material de sobra para estudo e explora\u00e7\u00e3o. Boa jornada!","7595427b":"Conferindo a acur\u00e1cia e as matrizes de confus\u00e3o:","8c7cb768":"O desempenho \u00e9 parecido com o que obtivemos com a rede MLP do `scikit-learn`, com a diferen\u00e7a de que parece haver menos sobreajuste. \n\nPara melhorar o resultado, utilizaremos redes com m\u00faltiplas camadas, que constituem o principal objeto de estudo do [aprendizado profundo (*deep learning*)](https:\/\/pt.wikipedia.org\/wiki\/Aprendizagem_profunda). Em particular, utilizaremos uma arquitetura especialmente apropriada para aplica\u00e7\u00f5es de vis\u00e3o computacional, as chamadas [redes convolucionais](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network).","4be4c7ff":"# Rede MLP no scikit-learn\n\nAntes de entrarmos nos belos detalhes matem\u00e1ticos dos modelos de redes neurais, vamos utilizar o [modelo dispon\u00edvel no scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html), conhecido como  [MLP (Multilayer perceptron)](https:\/\/en.wikipedia.org\/wiki\/Multilayer_perceptron), para implementar uma solu\u00e7\u00e3o inicial utilizando a API que j\u00e1 nos \u00e9 familiar:","2b205084":"A divis\u00e3o por 255 \u00e9 uma normaliza\u00e7\u00e3o que converte os pixels da faixa 0-255 para a faixa 0-1, o que melhora o desempenho das redes neurais.\n\nUsando o `matplotlib` para dar uma olhada nas imagens:","04b25cae":"# O que s\u00e3o redes neurais?\n\n[Redes neurais artificiais](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network) s\u00e3o uma classe de modelos de aprendizado inspirados vagamente no funcionamento do c\u00e9rebro humano.\n\nEsta \u00e9 a estrutura de um [neur\u00f4nio biol\u00f3gico](https:\/\/pt.wikipedia.org\/wiki\/Neur%C3%B3nio):\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/4\/44\/Neuron3.png\" width=\"350\" height=\"350\"\/>\n\n* O corpo celular \u00e9 o local dos componentes mais complexos da c\u00e9lula (n\u00facleo, etc).\n\n* Os [dendritos](https:\/\/pt.wikipedia.org\/wiki\/Dendrito) s\u00e3o pequenas e m\u00faltiplas ramifica\u00e7\u00f5es do corpo celular.\n\n* O [ax\u00f4nio](https:\/\/pt.wikipedia.org\/wiki\/Ax%C3%B3nio) \u00e9 uma longa extens\u00e3o (pode ser algumas ou milhares de vezes maior do que o corpo celular) em cujos terminais encontram-se as [sinapses](https:\/\/pt.wikipedia.org\/wiki\/Sinapse), que por sua vez se conectam aos dendritos ou corpos celulares de outros neur\u00f4nios.\n\nCada neur\u00f4nio individual apresenta um funcionamento bem simples. As caracter\u00edsticas complexas dos sistemas nervosos biol\u00f3gicos emergem da auto-organiza\u00e7\u00e3o dos neur\u00f4nios em vastas e complexas redes contendo bilh\u00f5es de c\u00e9lulas, cada uma podendo efetuar milhares de conex\u00f5es. A informa\u00e7\u00e3o \u00e9 processada nas redes por meio de sinais el\u00e9tricos que cada neur\u00f4nio recebe e transmite atrav\u00e9s das sinapses nervosas. As for\u00e7as entre as conex\u00f5es s\u00e3o ajustadas de acordo com est\u00edmulos externos. Esses ajustes s\u00e3o o mecanismo por meio do qual ocorre o processo de aprendizado em seres vivos.\n\nO [neur\u00f4nio matem\u00e1tico](https:\/\/en.wikipedia.org\/wiki\/Artificial_neuron) mimetiza o funcionamento do neur\u00f4nio biol\u00f3gico:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/65\/Artificial_neuron_2.gif\" width=\"400\" height=\"400\"\/>\n\n* Cada neur\u00f4nio $k$ em uma rede artificial \u00e9 uma unidade de processamento local, que aceita $m$ conex\u00f5es por meio das entradas $x_1$, $x_2$, ..., $x_m$ e fornece uma sa\u00edda $y_k$.\n\n* Cada conex\u00e3o $i$ tem um peso associado, denotado por $w_{ki}$. O *aprendizado* da rede \u00e9 efetuado por meio do ajuste desses pesos.\n\n* A entrada $0$ n\u00e3o \u00e9 uma conex\u00e3o com um neur\u00f4nio anterior, j\u00e1 que fornece sempre o mesmo valor $x_0=1$. Seu peso \u00e9 denotado por $w_0 = b_k$ e chamado de vi\u00e9s (*bias*) do neur\u00f4nio $k$. Fazendo analogia com o modelo linear, o vi\u00e9s \u00e9 como se fosse o intercepto da reta.\n\n* A sa\u00edda $y_k$ do neur\u00f4nio \u00e9 expressa por:\n\n$$ y_k = \\varphi(v_k) = \\varphi\\left(\\sum_{i=0}^m w_{ki} x_i\\right)$$\n\n* A fun\u00e7\u00e3o n\u00e3o-linear $\\varphi$ \u00e9 chamada de [fun\u00e7\u00e3o de ativa\u00e7\u00e3o](https:\/\/en.wikipedia.org\/wiki\/Activation_function) e \u00e9 respons\u00e1vel por introduzir n\u00e3o-linearidade nas redes. Se n\u00e3o houvesse uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o em cada neur\u00f4nio, as redes s\u00f3 seriam capazes de aprender padr\u00f5es lineares, j\u00e1 que o termo $v_k = \\sum_{i=0}^m w_{ki} x_i$ \u00e9 uma combina\u00e7\u00e3o linear dos sinais de entrada (cujos coeficientes s\u00e3o os pesos). Como veremos a seguir, existem v\u00e1rias possibilidades para a escolha da fun\u00e7\u00e3o de ativa\u00e7\u00e3o.\n\n* Nas redes neurais, os neur\u00f4nios s\u00e3o dispostos em camadas, organizadas de acordo com a *arquitetura da rede*. Um exemplo de rede com tr\u00eas camadas (uma camada de entrada, uma camada oculta e uma camada de sa\u00edda):\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/c\/c2\/MultiLayerNeuralNetworkBigger_english.png\" width=\"450\" height=\"450\"\/>\n\n* A camada de entrada n\u00e3o efetua nenhum c\u00e1lculo e \u00e9 respons\u00e1vel apenas por distribuir os sinais de entrada para as camadas internas.\n\n* No treinamento das redes, os pesos $w$ das v\u00e1rias conex\u00f5es s\u00e3o ajustados de modo que, para uma dada entrada, uma sa\u00edda especificada seja gerada (lembre-se de que no aprendizado supervisionado, tanto entrada quanto sa\u00edda est\u00e3o dispon\u00edveis na etapa de treinamento).\n\n* Ap\u00f3s o treinamento, na etapa de predi\u00e7\u00e3o, novos dados de entrada s\u00e3o alimentados e, caso o aprendizado tenha sido efetivo, sa\u00eddas com baixo erro (ou seja, pr\u00f3ximas das corretas) ser\u00e3o geradas pela rede.\n\n* Quanto \u00e0 arquitetura, as duas grandes classes de redes s\u00e3o as redes a) [recorrentes](https:\/\/en.wikipedia.org\/wiki\/Recurrent_neural_network) e b) de [alimenta\u00e7\u00e3o direta](https:\/\/en.wikipedia.org\/wiki\/Feedforward_neural_network):\n\n<img src=\"https:\/\/www.researchgate.net\/publication\/338672883\/figure\/fig1\/AS:864764884422656@1583187423806\/The-comparison-between-Recurrent-Neural-Network-RNN-and-Feed-Forward-Neural-Network.jpg\n\" width=\"400\" height=\"400\"\/>\n\n* Nas redes recorrentes, o sinal pode ser propagado para tr\u00e1s, enquanto nas redes de alimenta\u00e7\u00e3o direta, o sinal s\u00f3 se propaga em um sentido. \n\n* As redes recorrentes s\u00e3o \u00fateis para modelar dados em que h\u00e1 depend\u00eancia entre as observa\u00e7\u00f5es, como processos din\u00e2micos, textos ou sequ\u00eancias.\n\n* Neste notebook, s\u00f3 ser\u00e3o estudadas redes de alimenta\u00e7\u00e3o direta.\n\n## Perc\u00e9ptron\n\nO [perc\u00e9ptron](https:\/\/en.wikipedia.org\/wiki\/Perceptron), inventado por [Frank Rosenblatt](https:\/\/en.wikipedia.org\/wiki\/Frank_Rosenblatt) em 1957, foi uma das primeiras redes neurais propostas. Em sua forma original, consiste de uma camada de neur\u00f4nios (ou mesmo apenas um neur\u00f4nio) com a seguinte fun\u00e7\u00e3o de ativa\u00e7\u00e3o:\n\n$$   \\varphi(u)= \n\\begin{cases}\n    0, & \\text{se } u\\leq 0\\\\\n    1,          &    \\text{se } u> 0.\n\\end{cases}\n$$\n\n$\\varphi(u)$ \u00e9 chamada de [fun\u00e7\u00e3o degrau de Heaviside](https:\/\/en.wikipedia.org\/wiki\/Heaviside_step_function). O uso dessa ativa\u00e7\u00e3o resulta em um comportamento an\u00e1logo ao do neur\u00f4nio biol\u00f3gico (que dispara ou n\u00e3o um sinal de sa\u00edda para os pr\u00f3ximos neur\u00f4nios a depender das intensidades dos sinais de entrada).\n\nApesar da grande simplicidade, a empolga\u00e7\u00e3o com o perc\u00e9ptron foi grande, j\u00e1 que era a \u00e9poca do surgimento da Intelig\u00eancia Artificial! A m\u00e1quina [Mark I Perceptron](https:\/\/apps.dtic.mil\/dtic\/tr\/fulltext\/u2\/236965.pdf) foi constru\u00edda para implementar o modelo:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/en\/5\/52\/Mark_I_perceptron.jpeg\n\" width=\"250\" height=\"250\"\/>\n\nAp\u00f3s a empolga\u00e7\u00e3o inicial, logo percebeu-se que os perc\u00e9ptrons tinham muitas limita\u00e7\u00f5es, uma delas de natureza te\u00f3rica: n\u00e3o era poss\u00edvel fazer com que o modelo representasse algumas fun\u00e7\u00f5es simples. \n\nA solu\u00e7\u00e3o para esse problema veio de um resultado muito importante chamado de [Teorema da Aproxima\u00e7\u00e3o Universal](https:\/\/en.wikipedia.org\/wiki\/Universal_approximation_theorem), cujo enunciado afirma que:\n\n* redes com uma camada oculta conseguem aproximar qualquer fun\u00e7\u00e3o cont\u00ednua;\n* redes com mais de uma camada oculta conseguem aproximar qualquer fun\u00e7\u00e3o.\n\nUau! Est\u00e1 garantido que, em tese, o uso de mais camadas nas redes neurais possibilita a resolu\u00e7\u00e3o de uma enorme classe de problemas! No entanto, apesar de encorajador, o teorema n\u00e3o diz nada sobre os procedimentos necess\u00e1rios para fazer isso acontecer. Ou seja: como treinar redes com m\u00faltiplas camadas??\n\nObs: para uma visualiza\u00e7\u00e3o bem interessante do teorema da aproxima\u00e7\u00e3o universal, recomendo [esta leitura](http:\/\/neuralnetworksanddeeplearning.com\/chap4.html).\n\n## Treinamento das redes\n\nPor muito tempo lutou-se para encontrar um algoritmo de treinamento eficaz para redes com v\u00e1rias camadas.\n\nAt\u00e9 que [RUMERHALT *et al.* (1986)](http:\/\/www.cs.toronto.edu\/~hinton\/absps\/pdp8.pdf) propuseram o revolucion\u00e1rio [algoritmo da retropropaga\u00e7\u00e3o do erro](https:\/\/en.wikipedia.org\/wiki\/Backpropagation). Cada itera\u00e7\u00e3o desse algoritmo \u00e9 dividida em duas etapas: \n\n* Na primeira etapa , chamada de passe direto, calcula-se a sa\u00edda da rede. \n* Na segunda, o passe reverso, calcula-se o quanto cada camada contribui para o erro da camada anterior. Isso \u00e9 efetuado de tr\u00e1s para frente, ou seja, da sa\u00edda para a entrada, por meio da aplica\u00e7\u00e3o da [regra da cadeia](https:\/\/pt.wikipedia.org\/wiki\/Regra_da_cadeia) (isso mesmo, aquela do C\u00e1lculo 1!). \n\nO resultado da segunda etapa \u00e9 uma medida eficiente do gradiente do erro ao longo de toda a rede, o que torna poss\u00edvel a aplica\u00e7\u00e3o do algoritmo do [gradiente descendente](https:\/\/en.wikipedia.org\/wiki\/Gradient_descent) para a minimiza\u00e7\u00e3o do erro. O algoritmo do gradiente descendente \u00e9 um m\u00e9todo de [minimiza\u00e7\u00e3o de fun\u00e7\u00f5es](https:\/\/en.wikipedia.org\/wiki\/Mathematical_optimization) que, a cada passo (itera\u00e7\u00e3o), busca o m\u00ednimo na dire\u00e7\u00e3o de maior inclina\u00e7\u00e3o da fun\u00e7\u00e3o. A figura a seguir ilustra a aplica\u00e7\u00e3o do algoritmo a uma superf\u00edcie, partindo de tr\u00eas pontos distintos:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a3\/Gradient_descent.gif\" width=\"250\" height=\"250\"\/>\n\nUm dos pontos iniciais levou a um m\u00ednimo local, enquanto os outros dois chegaram ao que parece ser o m\u00ednimo global no dom\u00ednio apresentado. N\u00e3o h\u00e1 garantia de que o algoritmo convirja para o m\u00ednimo global.\n\nA fun\u00e7\u00e3o objetivo a ser minimizada \u00e9 chamada de [perda (*loss*)](https:\/\/en.wikipedia.org\/wiki\/Loss_function). O tamanho do passo que o algoritmo de minimiza\u00e7\u00e3o efetua na descida, a cada itera\u00e7\u00e3o, \u00e9 chamado de [taxa de aprendizado](https:\/\/en.wikipedia.org\/wiki\/Learning_rate) e constitui talvez o hiperpar\u00e2metro mais importante do modelo.\n\nPara que o algoritmo da retropropaga\u00e7\u00e3o do erro funcionasse, os autores precisaram propor uma nova fun\u00e7\u00e3o de ativa\u00e7\u00e3o:\n\n$$\\varphi(u) = \\frac{1}{1+\\exp(-u)},$$\n\na fun\u00e7\u00e3o de ativa\u00e7\u00e3o [log\u00edstica](https:\/\/en.wikipedia.org\/wiki\/Logistic_function). Isso foi necess\u00e1rio porque a fun\u00e7\u00e3o de Heaviside, muito utilizada at\u00e9 ent\u00e3o, \u00e9 composta de segmentos planos, n\u00e3o apresentando gradientes.\n\nPodemos encarar a fun\u00e7\u00e3o log\u00edstica como uma esp\u00e9cie de suaviza\u00e7\u00e3o da fun\u00e7\u00e3o de Heaviside:","b822efa3":"### Detalhes sobre a minimiza\u00e7\u00e3o\n\n#### V\u00e1rios algoritmos\n\nExistem v\u00e1rias t\u00e9cnicas pertencentes \u00e0 fam\u00edlia de algoritmos de gradiente descendente. Uma variante muito usada nas redes neurais \u00e9 o [gradiente descendente estoc\u00e1stico (SGD)](https:\/\/en.wikipedia.org\/wiki\/Stochastic_gradient_descent), em que as derivadas s\u00e3o estimadas a partir de por\u00e7\u00f5es aleat\u00f3rias dos dados, o que reduz problemas como m\u00ednimos locais e pontos de sela. \n\nA [estrat\u00e9gia de momentos](https:\/\/www.sciencedirect.com\/science\/article\/abs\/pii\/S0893608098001166?via%3Dihub) consiste em adicionar a cada passo da itera\u00e7\u00e3o uma fra\u00e7\u00e3o do passo anterior, o que pode amortecer oscila\u00e7\u00f5es e acelerar a descida em dire\u00e7\u00f5es promissoras. Levar em conta essa fra\u00e7\u00e3o do passo anterior tamb\u00e9m no c\u00e1lculo do gradiente resulta na [estrat\u00e9gia de momentos de Nesterov](http:\/\/mpawankumar.info\/teaching\/cdt-big-data\/nesterov83.pdf). O termo \"momento\" vem da analogia com a F\u00edsica. \n\nUma tend\u00eancia recente \u00e9 a utiliza\u00e7\u00e3o de taxas de aprendizado adaptativas, ou seja, atualizadas conforme a minimiza\u00e7\u00e3o evolui. O m\u00e9todo Adam ([KINGMA e BA, 2014](https:\/\/arxiv.org\/abs\/1412.6980)), um dos mais usados atualmente, estende a estrat\u00e9gia de momentos descrita no par\u00e1grafo anterior adicionando um segundo momento, respons\u00e1vel por controlar a taxa de aprendizado. Esse segundo momento rastreia as vari\u00e2ncias dos gradientes de cada par\u00e2metro ao longo dos passos anteriores. Quanto maior a vari\u00e2ncia dos gradientes passados de um dado par\u00e2metro, mais o m\u00e9todo diminui a taxa de aprendizado correspondente. O objetivo \u00e9 atualizar mais os par\u00e2metros que ainda n\u00e3o foram muito atualizados.\n\nPara mais detalhes sobre algoritmos de gradiente descendente em redes neurais, confira [esta](https:\/\/ruder.io\/optimizing-gradient-descent\/) ou [esta](https:\/\/towardsdatascience.com\/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c) p\u00e1ginas.\n\nObs: pode-se ir al\u00e9m do gradiente descendente e utilizar outras t\u00e9cnicas, como as de segunda ordem (que utilizam informa\u00e7\u00f5es de derivada segunda; exemplos s\u00e3o os m\u00e9todos de [Newton](https:\/\/en.wikipedia.org\/wiki\/Newton%27s_method_in_optimization) e [Quase-Newton](https:\/\/en.wikipedia.org\/wiki\/Quasi-Newton_method)) ou [meta-heur\u00edsticas](https:\/\/en.wikipedia.org\/wiki\/Metaheuristic). No entanto, tais aplica\u00e7\u00f5es s\u00e3o bem menos comuns.\n\n#### Minilotes e \u00e9pocas\n\nComo vimos, nas variantes SGD do m\u00e9todo de gradiente descendente, os dados s\u00e3o divididos aleatoriamente em pequenas por\u00e7\u00f5es. Cada por\u00e7\u00e3o \u00e9 chamada de minilote (*minibatch*). \n\nUma itera\u00e7\u00e3o do algoritmo de minimiza\u00e7\u00e3o \u00e9 efetuada para cada minilote (ou seja, os erros s\u00e3o calculados e os pesos s\u00e3o atualizados a cada minilote processado).\n\nUma \u00e9poca (*epoch*) \u00e9 marcada quando todos os minilotes foram processados (quando todo o conjunto de dados passou pela rede). Em outras palavras, o n\u00famero de \u00e9pocas \u00e9 a quantidade de vezes em que cada dado \u00e9 processado pela rede durante o treinamento. Geralmente, algumas \u00e9pocas s\u00e3o necess\u00e1rias para que se atinja um erro baixo.\n\n#### Regulariza\u00e7\u00e3o\n\nUma cr\u00edtica recorrente a modelos de redes neurais (e a modelos de aprendizado, de forma geral) \u00e9 a grande quantidade de par\u00e2metros de sua estrutura matem\u00e1tica. No mundo acad\u00eamico, construiu-se um certo consenso de que modelos com muitos par\u00e2metros s\u00e3o inerentemente ruins, por conta da complexidade matem\u00e1tica e da excessiva capacidade de adapta\u00e7\u00e3o resultantes. [Enrico Fermi](https:\/\/en.wikipedia.org\/wiki\/Enrico_Fermi), em 1953, ao criticar a complexidade de um modelo em espec\u00edfico, cunhou uma frase cl\u00e1ssica sobre o assunto: \n\n\"*With four parameters I can fit an elephant, and with five I can make him wiggle his trunk*\". \n\n[MAYER *et al.* (2009)](https:\/\/publications.mpi-cbg.de\/Mayer_2010_4314.pdf), em um artigo muito divertido, foram os primeiros a implementar de fato o elefante com quatro par\u00e2metros (e a fazer a tromba balan\u00e7ar com um par\u00e2metro adicional).\n\nNo entanto, os tempos mudam. Modelos de aprendizado profundo, que s\u00e3o incontestavelmente \u00fateis (reconhecem rostos em imagens, traduzem textos, etc.), possuem milhares (ou milh\u00f5es, ou mesmo [bilh\u00f5es!!](https:\/\/www.microsoft.com\/en-us\/research\/blog\/turing-nlg-a-17-billion-parameter-language-model-by-microsoft\/)) de par\u00e2metros. Isso \u00e9 poss\u00edvel porque existem estrat\u00e9gias desenvolvidas justamente para lidar com essa quest\u00e3o.\n\nUma das estrat\u00e9gias \u00e9 a [regulariza\u00e7\u00e3o](https:\/\/en.wikipedia.org\/wiki\/Regularization_(mathematics)). Do ponto de vista matem\u00e1tico, a regulariza\u00e7\u00e3o \u00e9 qualquer procedimento que adiciona informa\u00e7\u00e3o a um problema com muitos graus de liberdade. No caso espec\u00edfico do aprendizado de m\u00e1quina, a regulariza\u00e7\u00e3o \u00e9 qualquer procedimento que tem como objetivo reduzir o erro de predi\u00e7\u00e3o sem reduzir o erro do treinamento. \n\nNas redes neurais, uma regulariza\u00e7\u00e3o muito usada \u00e9 a regulariza\u00e7\u00e3o $L_2$, que adiciona \u00e0 fun\u00e7\u00e3o perda um termo de penaliza\u00e7\u00e3o dos pesos $w$, na forma:\n\n$$\n\\lambda \\sum_i w_i^2\n$$\n\nLembre-se de que o treinamento consiste na minimiza\u00e7\u00e3o da fun\u00e7\u00e3o perda por meio do ajuste dos pesos $w$. Quando a fun\u00e7\u00e3o perda possui um termo de regulariza\u00e7\u00e3o, o algoritmo tentar\u00e1 minimizar esse termo, se poss\u00edvel levando-o a zero. Para um par\u00e2metro $w_i$ n\u00e3o resultar em zero, ele precisa ser muito importante, ou seja, *seu efeito na diminui\u00e7\u00e3o do erro tem de ser mais importante do que o efeito no aumento do erro causado pelo termo de regulariza\u00e7\u00e3o*. \n\nMoral da hist\u00f3ria: mesmo que o modelo tenha muitos par\u00e2metros, nem todos s\u00e3o utilizados efetivamente no aprendizado, j\u00e1 que a regulariza\u00e7\u00e3o far\u00e1 com que uma parte deles tenda a zero.\n\nObserva\u00e7\u00f5es:\n\n* $\\lambda$ \u00e9 um hiperpar\u00e2metro que controla a intensidade da regulariza\u00e7\u00e3o. Valores t\u00edpicos v\u00e3o de $10^{-6}$ a $10^{-4}$.\n* A regulariza\u00e7\u00e3o $L_1$ \u00e9 an\u00e1loga \u00e0 $L_2$, no entanto usando valores absolutos no lugar dos quadrados.\n* A regulariza\u00e7\u00e3o \u00e9 utilizada em muitos modelos, n\u00e3o apenas em redes neurais. A regress\u00e3o linear utilizando regulariza\u00e7\u00e3o $L_1$ \u00e9 chamada de [regress\u00e3o lasso](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Lasso.html), enquanto a regulariza\u00e7\u00e3o $L_2$ d\u00e1 origem \u00e0 [regress\u00e3o ridge](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Ridge.html).\n\n## TensorFlow Playground\n\nO [TensorFlow Playground](https:\/\/playground.tensorflow.org\/) \u00e9 uma p\u00e1gina muito interessante para ganhar sentimento em rela\u00e7\u00e3o ao funcionamento das redes neurais. Recomendo que voc\u00ea brinque um pouquinho com os diversos recursos e possibilidades oferecidas, em especial antes de fazer a atividade que vem a seguir.","05e06751":"# Conclus\u00e3o\n\nNesta aula aprendemos o que h\u00e1 de mais moderno e vibrante no campo de aprendizado de m\u00e1quina, os modelos de [redes neurais](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network), em particular de [aprendizado profundo](https:\/\/en.wikipedia.org\/wiki\/Deep_learning). Estudamos dois tipos de redes, [MLP](https:\/\/en.wikipedia.org\/wiki\/Multilayer_perceptron) e [convolucionais](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network), e entendemos porque este \u00faltimo \u00e9 adequado para aplica\u00e7\u00f5es do tipo [vis\u00e3o computacional](https:\/\/pt.wikipedia.org\/wiki\/Vis%C3%A3o_computacional).\n\nUtilizamos tr\u00eas conjuntos de dados: [MNIST](https:\/\/www.kaggle.com\/c\/digit-recognizer), [Fashion MNIST](https:\/\/www.kaggle.com\/zalando-research\/fashionmnist) e [Pilot Technocast](https:\/\/www.kaggle.com\/ravirajsinh45\/real-life-industrial-dataset-of-casting-product\/). Incentivo voc\u00ea a testar suas novas habilidades com outros dados. Voc\u00ea pode inclusive criar o seu pr\u00f3prio conjunto, baixando imagens do Google (para tentar diferenciar gatos de cachorros, etc). A partir de agora, o c\u00e9u \u00e9 o limite para voc\u00ea!\n\nAt\u00e9 a pr\u00f3xima ;)","53e40d60":"## Importando os dados\n\nOs dados est\u00e3o organizados em duas pastas, de acordo com a estrutura:\n\n    casting_data\n    \u251c\u2500\u2500\u2500test\n    \u2502   \u251c\u2500\u2500\u2500def_front\n    \u2502   \u2514\u2500\u2500\u2500ok_front\n    \u2514\u2500\u2500\u2500train\n        \u251c\u2500\u2500\u2500def_front\n        \u2514\u2500\u2500\u2500ok_front\n\nEssa estrutura \u00e9 conveniente porque, no momento da leitura pelo `keras`, h\u00e1 o reconhecimento das classes `def_front` e `ok_front` de acordo com os nomes das pastas.\n\nArmazenando os caminhos:","30d87ab9":"# Aprendizado Profundo\n\n[GOODFELLOW *et al.* (2016)](https:\/\/www.deeplearningbook.org\/) propuseram uma excelente defini\u00e7\u00e3o de aprendizado profundo:\n\n\"*O aprendizado profundo \u00e9 um tipo espec\u00edfico de aprendizado de m\u00e1quina que alcan\u00e7a grande poder e flexibilidade ao representar o mundo como uma hierarquia aninhada de conceitos, sendo i) cada conceito definido por meio de sua rela\u00e7\u00e3o com conceitos mais simples e ii) representa\u00e7\u00f5es mais abstratas calculadas em termos de outras menos abstratas.*\"\n\nOu seja, em um modelo de aprendizado profundo, os padr\u00f5es reconhecidos a partir dos dados s\u00e3o organizados em m\u00faltiplas camadas. Quanto mais fundo se avan\u00e7a nas camadas do modelo, mais os padr\u00f5es v\u00e3o se tornando complexos e abstratos. As redes neurais, justamente por conta de sua organiza\u00e7\u00e3o natural em camadas, s\u00e3o o tipo de modelo de escolha para tais aplica\u00e7\u00f5es. Para uma leitura sobre aprendizado profundo complementar a este notebook, recomendo o artigo de [LECUN *et al.* (2015)](https:\/\/www.nature.com\/articles\/nature14539).\n\nApesar de a ideia ser antiga, o treinamento de redes com muitas camadas sempre se mostrou bem dif\u00edcil, mesmo com o advento do algoritmo da retropropaga\u00e7\u00e3o do erro em 1986. Historicamente, os grandes problemas foram:\n\n1. treinamentos excessivamente lentos;\n2. gradientes que desaparecem ou explodem ao serem retropropagados pela rede;\n3. escassez de dados para treinamento;\n4. risco de sobreajuste por conta do excesso de par\u00e2metros.\n\n[HINTON *et al.* (2006)](https:\/\/www.mitpressjournals.org\/doi\/10.1162\/neco.2006.18.7.1527) foram os primeiros a demonstrar a possibilidade de atenua\u00e7\u00e3o dos problemas 1 e 3 para treinamento de redes profundas, utilizando uma metodologia de pr\u00e9-treinamento n\u00e3o supervisionado. Este trabalho reviveu o interesse da comunidade cient\u00edfica e tecnol\u00f3gica nas redes neurais. A estrat\u00e9gia proposta foi muito popular, mas caiu em desuso na d\u00e9cada de 2010, quando novas solu\u00e7\u00f5es para os problemas foram surgindo. A seguir, abordaremos as mais influentes e utilizadas hoje em dia.\n\n### Problema 1: treinamentos excessivamente lentos\n\n[RAINA *et al.* (2009)](http:\/\/www.robotics.stanford.edu\/~ang\/papers\/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf) propuseram o uso de [GPU's (Unidades Gr\u00e1ficas de Processamento)](https:\/\/en.wikipedia.org\/wiki\/Graphics_processing_unit) para efetuar o treinamento das redes profundas de forma massivamente paralela, o que se mostrou essencial para aplica\u00e7\u00f5es em larga escala. Um dos motivos para tal aplica\u00e7\u00e3o ter sido t\u00e3o bem-sucedida \u00e9 que j\u00e1 havia press\u00e3o econ\u00f4mica para desenvolvimento de GPU's antes do uso pela comunidade cient\u00edfica, vinda principalmente da ind\u00fastria de videogames. Voc\u00ea pode verificar a relev\u00e2ncia da metodologia rodando os pr\u00f3ximos c\u00f3digos deste notebook com GPU's ativadas e depois somente com CPU's e comparando os desempenhos.\n\nOutro fator que vem contribuindo para a melhoria de desempenho dos treinamentos \u00e9 o surgimento de novas metodologias de minimiza\u00e7\u00e3o por gradiente descendente, como a [Adam](https:\/\/arxiv.org\/abs\/1412.6980), j\u00e1 citada.\n\n### Problema 2: desaparecimento\/explos\u00e3o de gradientes\n\nMesmo com o grande ganho de efici\u00eancia introduzido pelas GPU's, s\u00e9rias dificuldades num\u00e9ricas relativas ao treinamento de redes profundas persistiram. Em particular, durante a etapa de retropropaga\u00e7\u00e3o do erro, era inevit\u00e1vel que [os gradientes zerassem](https:\/\/en.wikipedia.org\/wiki\/Vanishing_gradient_problem), impedindo a converg\u00eancia do treinamento. Em redes recorrentes \u00e9 comum o problema inverso, a explos\u00e3o dos gradientes.\n\n[GLOROT e BENGIO (2010)](http:\/\/proceedings.mlr.press\/v9\/glorot10a\/glorot10a.pdf), em um trabalho muito influente, identificaram os principais culpados para o fen\u00f4meno do desaparecimento dos gradientes:\n\n* a at\u00e9 ent\u00e3o popular fun\u00e7\u00e3o de ativa\u00e7\u00e3o log\u00edstica;\n* a at\u00e9 ent\u00e3o popular estrat\u00e9gia de inicializa\u00e7\u00e3o dos pesos com uma distribui\u00e7\u00e3o gaussiana de m\u00e9dia $0$ e desvio-padr\u00e3o $1$.\n\nCom essa combina\u00e7\u00e3o, a cada camada, a vari\u00e2ncia da sa\u00edda resulta maior que da entrada, fazendo os sinais crescerem (positiva ou negativamente) at\u00e9 saturarem nas extremidades da fun\u00e7\u00e3o de ativa\u00e7\u00e3o log\u00edstica. Com a propaga\u00e7\u00e3o de um sinal praticamente constante ao longo da rede, o gradiente na etapa de retropropaga\u00e7\u00e3o (o sinal reverso) resulta praticamente nulo.\n\nDesde ent\u00e3o, v\u00e1rias boas pr\u00e1ticas v\u00eam sendo propostas para garantir que haja uma efetiva propaga\u00e7\u00e3o dos sinais pela rede (tanto as predi\u00e7\u00f5es, no sentido direto; quanto os gradientes, no sentido reverso), dentre as quais citamos:\n\n* novas fun\u00e7\u00f5es de ativa\u00e7\u00e3o;\n* novas estrat\u00e9gias de inicializa\u00e7\u00e3o dos pesos;\n* normaliza\u00e7\u00e3o por lote.\n\n#### Novas fun\u00e7\u00f5es de ativa\u00e7\u00e3o\n\nAs fun\u00e7\u00f5es de ativa\u00e7\u00e3o mais usadas atualmente s\u00e3o da classe de [retificadores lineares](https:\/\/en.wikipedia.org\/wiki\/Rectifier_(neural_networks)). Abaixo apresentamos alguns exemplos, junto \u00e0 fun\u00e7\u00e3o log\u00edstica:","2e662645":"***M\u00e3o na massa 1!***\n\n* Adicione ao kernel o conjunto de dados [Fashion MNIST](https:\/\/github.com\/zalandoresearch\/fashion-mnist) (no menu superior, clique em `File` e depois `Add or Upload Data`). Pesquise e entenda a natureza do conjunto. Quais classes est\u00e3o presentes? Repita todo o procedimento que efetuamos acima para o conjunto MNIST:\n    * separe em X e y;\n    * separe em treino e valida\u00e7\u00e3o;\n    * visualize algumas amostras;\n    * aplique uma rede MLP e me\u00e7a o desempenho com a acur\u00e1cia simples e a matriz de confus\u00e3o.","ca92348b":"# Redes convolucionais\n\n[Redes convolucionais](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network) s\u00e3o redes esparsamente conectadas, em que cada neur\u00f4nio *n\u00e3o* se conecta a todos os neur\u00f4nios da camada anterior. \u00c9 o contr\u00e1rio das redes densamente conectadas, como a MLP, que estudamos at\u00e9 agora.\n\nAs redes densamente conectadas s\u00f3 podem aprender padr\u00f5es globais, ou seja, padr\u00f5es que envolvem todos os pontos presentes em dada amostra ou observa\u00e7\u00e3o. J\u00e1 as redes convolucionais, como veremos, s\u00e3o capazes de aprender *padr\u00f5es locais* e reconhecer esses padr\u00f5es em *qualquer posi\u00e7\u00e3o* de alguma outra amostra. No caso de imagens, esses padr\u00f5es locais podem corresponder a bordas, curvas etc.\n\nAo longo da estrutura da rede, conforme se avan\u00e7a nas camadas mais profundas, os padr\u00f5es locais simples v\u00e3o sendo agregados e tornando-se cada vez mais complexos. \u00c9 uma estrutura de aprendizado an\u00e1loga a que se observa no [c\u00f3rtex visual](https:\/\/en.wikipedia.org\/wiki\/Visual_cortex), estrutura do c\u00e9rebro respons\u00e1vel pelo processamento da informa\u00e7\u00e3o visual. Por isso as redes convolucionais s\u00e3o t\u00e3o utilizadas para processar imagens.\n\nMatematicamente, a rede efetua o aprendizado desses padr\u00f5es locais por meio da opera\u00e7\u00e3o de [convolu\u00e7\u00e3o](https:\/\/en.wikipedia.org\/wiki\/Convolution), explicada a seguir.\n\n## Funcionamento da rede convolucional\n\n* Para alimentar uma imagem \u00e0 rede, \u00e9 necess\u00e1rio represent\u00e1-la como um tensor. Por exemplo, a seguir \u00e9 ilustrada a representa\u00e7\u00e3o da imagem de um c\u00e3ozinho como um tensor tridimensional de pixels:\n\n<img src=\"https:\/\/media.springernature.com\/original\/springer-static\/image\/chp%3A10.1007%2F978-3-030-47994-7_16\/MediaObjects\/472738_1_En_16_Fig2_HTML.png\" width=\"600\" height=\"600\"\/>\n\n* No caso, o tensor resultante possui formato 15x20x3 (ou seja, s\u00e3o 15 linhas, 20 colunas e 3 canais de cores).\n\n* Em seguida, a imagem passa por uma *camada convolucional*. Nessa camada, aplica-se a opera\u00e7\u00e3o de convolu\u00e7\u00e3o:\n\n<img src=\"https:\/\/media.springernature.com\/original\/springer-static\/image\/chp%3A10.1007%2F978-3-030-47994-7_16\/MediaObjects\/472738_1_En_16_Fig3_HTML.png\" width=\"500\" height=\"500\"\/>\n\n* Na opera\u00e7\u00e3o de convolu\u00e7\u00e3o, um *filtro* (tamb\u00e9m chamado de *kernel*), em geral de dimens\u00e3o 3x3 (a mais comum), 5x5 ou 7x7, percorre os pixels de uma imagem calculando o produto escalar a cada passo e armazenando os resultados em uma matriz chamada de *mapa de caracter\u00edsticas*.\n\n* O mapa de caracter\u00edsticas recebe esse nome porque \u00e9 a estrutura respons\u00e1vel por reconhecer os v\u00e1rios padr\u00f5es (caracter\u00edsticas) relativos \u00e0 imagem. A natureza do padr\u00e3o reconhecido depende da estrutura do filtro.\n\n* Quando a imagem possui v\u00e1rios canais, o mapa de caracter\u00edsticas resultante do filtro \u00e9 a soma dos mapas de caracter\u00edsticas correspondentes a cada canal.\n\n* A camada convolucional pode ter v\u00e1rios filtros, cada um dando origem a um mapa de caracter\u00edsticas.\n\n* Cada elemento de um mapa de caracter\u00edsticas corresponde a um neur\u00f4nio. Os neur\u00f4nios em um mesmo mapa de caracter\u00edsticas compartilham os mesmos par\u00e2metros (pesos).\n\n* Em geral, a matriz de n\u00fameros que constitui cada filtro de dada camada \u00e9 um par\u00e2metro da rede, ou seja, \u00e9 ajustada junto com os pesos de modo a resultar no aprendizado \u00f3timo. O n\u00famero de filtros de dada camada \u00e9 um hiperpar\u00e2metro (deve ser determinado a priori).\n\n* Os m\u00faltiplos mapas de caracter\u00edsticas podem ser alimentados a uma nova camada convolucional, resultando em novos mapas, como ilustrado:\n\n<img src=\"https:\/\/www.mdpi.com\/sensors\/sensors-19-01693\/article_deploy\/html\/images\/sensors-19-01693-g002-550.jpg\" width=\"400\" height=\"400\"\/>\n\n* Cada neur\u00f4nio de um mapa de caracter\u00edsticas da sa\u00edda conecta-se a apenas uma por\u00e7\u00e3o dos neur\u00f4nios dos mapas da entrada. A por\u00e7\u00e3o da camada anterior que se conecta a um neur\u00f4nio \u00e9 chamada de seu *campo receptivo*. A figura a seguir ilustra bem o conceito de campo receptivo de um neur\u00f4nio:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/8\/85\/Convolution_arithmetic_-_Full_padding_no_strides_transposed.gif\" width=\"200\" height=\"200\"\/>\n\n* A opera\u00e7\u00e3o de convolu\u00e7\u00e3o faz com que o mapa de sa\u00edda tenha formato menor do que o mapa de entrada. De modo a fazer com que o formato seja o mesmo, pode-se utilizar estrat\u00e9gias de preenchimento (*padding*). Na estrat\u00e9gia a seguir, conhecida como *zero padding* ou *same padding*, adicionam-se zeros \u00e0s bordas do mapa de entrada de modo que o mapa de sa\u00edda possua o mesmo formato da entrada. \u00c9 uma maneira de preservar as informa\u00e7\u00f5es das bordas ao longo da rede.\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/8\/80\/Convolution_arithmetic_-_Same_padding_no_strides_transposed.gif\" width=\"200\" height=\"200\"\/>\n\n* Caso deseje-se gerar mapas de sa\u00edda menores do que os de entrada, podem ser utilizados passos largos (*strides*). Na figura a seguir, o mapa \u00e9 calculado com um stride de 2:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/b\/b9\/Convolution_arithmetic_-_No_padding_strides.gif\n\" width=\"200\" height=\"200\"\/>\n\n* Outra estrat\u00e9gia para gerar mapas de sa\u00edda menores que os da entrada \u00e9 a *dilata\u00e7\u00e3o*, proposta por [YU e KOLTUN (2015)](https:\/\/arxiv.org\/abs\/1511.07122) e ilustrada na figura a seguir. A vantagem da dilata\u00e7\u00e3o em rela\u00e7\u00e3o \u00e0 estrat\u00e9gia de passos largos \u00e9 a abrang\u00eancia maior do campo receptivo de cada neur\u00f4nio.\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/c\/c1\/Convolution_arithmetic_-_Dilation.gif\" width=\"200\" height=\"200\"\/>\n\n* Al\u00e9m da camada convolucional, \u00e9 comum adicionar \u00e0s redes camadas de *pooling*. Assim como as camadas convolucionais, os neur\u00f4nios das camadas de pooling tamb\u00e9m possuem campos receptivos, mas n\u00e3o h\u00e1 pesos e a opera\u00e7\u00e3o efetuada n\u00e3o \u00e9 a convolu\u00e7\u00e3o e sim alguma opera\u00e7\u00e3o de agrega\u00e7\u00e3o, como a m\u00e9dia ou a escolha do valor m\u00e1ximo (sendo essa \u00faltima a mais usada):\n\n<img src=\"https:\/\/www.researchgate.net\/publication\/333593451\/figure\/fig2\/AS:765890261966848@1559613876098\/Illustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max.png\n\" width=\"350\" height=\"350\"\/>\n\n* Em geral, os campos receptivos de pooling t\u00eam tamanho 2x2 e stride 2, como mostrado acima.\n\n* As camadas de pooling diminuem a quantidade de par\u00e2metros da rede, atenuando o sobreajuste e o custo computacional. Al\u00e9m do mais, como h\u00e1 agrega\u00e7\u00e3o da informa\u00e7\u00e3o de janelas maiores em janelas menores, os campos receptivos das camadas mais profundas da rede, mesmo sendo pequenos, possuem informa\u00e7\u00f5es relativas \u00e0 toda a imagem original. Isso possibilita a cria\u00e7\u00e3o de padr\u00f5es globais e mais complexos\/abstratos nas camadas profundas.\n\n* A figura a seguir ilustra a arquitetura t\u00edpica de uma rede convolucional:\n\n<img src=\"https:\/\/www.researchgate.net\/publication\/336805909\/figure\/fig1\/AS:817888827023360@1572011300751\/Schematic-diagram-of-a-basic-convolutional-neural-network-CNN-architecture-26.ppm\" width=\"500\" height=\"500\"\/>\n\n* A primeira parte da rede efetua a *extra\u00e7\u00e3o de caracter\u00edsticas*, ou seja, identifica os diversos padr\u00f5es presentes na imagem. Tipicamente, utilizam-se v\u00e1rios pares de camadas convolu\u00e7\u00e3o\/pooling, o que define a profundidade da rede.\n\n* A segunda parte consiste de uma camada densa (totalmente conectada, como as da rede MLP) e \u00e9 respons\u00e1vel por efetuar a classifica\u00e7\u00e3o.\n\n* Algumas excelentes p\u00e1ginas para visualiza\u00e7\u00f5es interativas de redes convolucionais s\u00e3o [esta](https:\/\/www.cs.ryerson.ca\/~aharley\/vis\/conv\/) e [esta](https:\/\/poloclub.github.io\/cnn-explainer\/).\n\nAgora vamos implementar uma rede convolucional no Keras.","d2d3d18b":"## Modelagem\n\nA estrat\u00e9gia aqui ser\u00e1 criar m\u00faltiplas redes e juntar os v\u00e1rios resultados em uma \u00fanica predi\u00e7\u00e3o. \u00c9 uma abordagem semelhante \u00e0 que utilizamos na Aula 1 com modelos de florestas aleat\u00f3rias. De maneira geral, o procedimento de criar um modelo composto por m\u00faltiplos submodelos \u00e9 conhecido como [ensembling](https:\/\/en.wikipedia.org\/wiki\/Ensemble_learning).\n\nA motiva\u00e7\u00e3o para usar ensembling \u00e9 a mesma da aula de florestas: a redu\u00e7\u00e3o do erro de generaliza\u00e7\u00e3o. Lembre-se de que quanto maior for a independ\u00eancia entre os modelos, maior ser\u00e1 a redu\u00e7\u00e3o do erro. As diferen\u00e7as entre as redes neste caso surgem das aleatoriedades da i) separa\u00e7\u00e3o entre treino\/valida\u00e7\u00e3o e ii) inicializa\u00e7\u00e3o dos pesos.\n\nA fun\u00e7\u00e3o a seguir retorna uma rede convolucional compilada:","fcdafdd8":"Lembre-se de que a rede fornece como sa\u00edda, para cada imagem, uma probabilidade (ou seja, um n\u00famero entre 0 e 1). Quanto mais perto de 0 est\u00e1 a probabilidade, mais a rede acredita que a imagem pertence \u00e0 classe 0; quanto mais perto de 1, mais ela acredita que a classe \u00e9 a 1. \n\nNa fun\u00e7\u00e3o acima, a probabilidade do ensemble \u00e9 calculada como a m\u00e9dia das probabilidades fornecidas por cada rede.\n\nNa pr\u00f3xima c\u00e9lula, aplicamos a fun\u00e7\u00e3o para calcular as probabilidades relativas ao conjunto de teste:","7a9667b9":"* A classe [keras.layers.conv2D](https:\/\/keras.io\/api\/layers\/convolution_layers\/convolution2d\/) implementa uma camada convolucional. Repare que a entrada da primeira camada \u00e9 um tensor de formato largura x altura x canais (ao contr\u00e1rio da rede MLP, em que a entrada era um vetor).\n\n* A classe [keras.layers.MaxPooling2D](https:\/\/keras.io\/api\/layers\/pooling_layers\/max_pooling2d\/) implementa uma camada de pooling.\n\n* A entrada de uma camada densa deve ser um vetor; portanto, antes dessa camada, \u00e9 preciso achatar o tensor de entrada para apenas uma dimens\u00e3o, o que \u00e9 efetuado com a classe [keras.layers.Flatten](https:\/\/keras.io\/api\/layers\/reshaping_layers\/flatten\/).\n\n* A classe [keras.layers.Dropout](https:\/\/keras.io\/api\/layers\/regularization_layers\/dropout\/) implementa uma camada de dropout que, no caso, desliga 20% dos neur\u00f4nios antes de fornec\u00ea-los \u00e0 camada de sa\u00edda. \n\nVisualizando a estrutura do modelo:","133c9f5d":"As pe\u00e7as em quest\u00e3o s\u00e3o impulsores de [bombas submers\u00edveis](https:\/\/en.wikipedia.org\/wiki\/Submersible_pump), cujo funcionamento \u00e9 ilustrado nos seguintes v\u00eddeos:","fdeb5cea":"Definindo uma fun\u00e7\u00e3o para retornar a predi\u00e7\u00e3o do ensemble:","d7bc397a":"Para calcular as m\u00e9tricas de classifica\u00e7\u00e3o, \u00e9 necess\u00e1rio definir qual faixa de probabilidades est\u00e1 associada a cada classe. Em outras palavras, \u00e9 preciso escolher o valor de corte que separa cada uma das duas classes. A maneira mais intuitiva de efetuar esse procedimento \u00e9:\n\n* Classe $0$: $p\\leq0{,}5$\n* Classe $1$: $p>0,5$.\n\nApesar de $0{,}5$ ser o corte mais comum, podemos variar esse valor de modo a manipular as propor\u00e7\u00f5es entre erros do [tipo I](https:\/\/pt.wikipedia.org\/wiki\/Erro_do_tipo_I) e do [tipo II](https:\/\/pt.wikipedia.org\/wiki\/Erro_do_tipo_II), como discutido mais adiante.\n\nCalculando as m\u00e9tricas:","79c87d68":"S\u00e3o esses dois tipos de imagens que nossos modelos precisar\u00e3o distinguir!","c80fa974":"No primeiro gr\u00e1fico, da fun\u00e7\u00e3o log\u00edstica, fica evidente como, para valores de $u$ afastados de $0$, os valores de $f(u)$ saturam.\n\nNo segundo gr\u00e1fico, temos a fun\u00e7\u00e3o `ReLU`, a mais popular hoje em dia por dois motivos: n\u00e3o satura no sentido positivo e \u00e9 r\u00e1pida de calcular. \u00c9 incr\u00edvel como essa fun\u00e7\u00e3o, bem mais simples do que a log\u00edstica, funciona t\u00e3o melhor nas redes neurais e precisou esperar tantas d\u00e9cadas at\u00e9 ter seu uso disseminado! O prov\u00e1vel motivo \u00e9 a analogia que se pode fazer entre a fun\u00e7\u00e3o log\u00edstica e os mecanismos de disparo do neur\u00f4nio biol\u00f3gico (analogias s\u00e3o legais, mas n\u00e3o ajudam em nada os algoritmos matem\u00e1ticos).\n\nNo terceiro gr\u00e1fico, temos a fun\u00e7\u00e3o `Leaky ReLU`, que introduz uma inclina\u00e7\u00e3o na regi\u00e3o negativa da `ReLU`. \u00c9 uma estrat\u00e9gia para impedir a morte de neur\u00f4nios (ou seja, quando a sa\u00edda do neur\u00f4nio \u00e9 nula para todas as amostras de treinamento), situa\u00e7\u00e3o comum em redes com ativa\u00e7\u00e3o `ReLU`. Quando $a$ se torna um par\u00e2metro a ser aprendido pela rede, como sugerido por [HE *et al.* (2015)](https:\/\/arxiv.org\/abs\/1502.01852), a fun\u00e7\u00e3o recebe o nome de `PReLU` (Parametric ReLU).\n\nNo quarto gr\u00e1fico, temos a fun\u00e7\u00e3o `ELU`, proposta por [CLEVERT *et al.* (2015)](https:\/\/arxiv.org\/abs\/1511.07289). Sua maior vantagem \u00e9 tornar a m\u00e9dia das ativa\u00e7\u00f5es mais pr\u00f3xima de $0$, o que acelera o aprendizado por proporcionar maior flexibilidade \u00e0 minimiza\u00e7\u00e3o por gradiente descendente (detalhes [aqui](https:\/\/stats.stackexchange.com\/questions\/237169\/)). Outra vantagem: quando $a=1$, a fun\u00e7\u00e3o \u00e9 [suave](https:\/\/pt.wikipedia.org\/wiki\/Fun%C3%A7%C3%A3o_suave), uma conveni\u00eancia num\u00e9rica tamb\u00e9m \u00fatil na minimiza\u00e7\u00e3o. A desvantagem \u00e9 que ela \u00e9 mais lenta para calcular (compensada \u00e0s vezes pela maior velocidade de converg\u00eancia do treinamento).\n\nAl\u00e9m dessas, h\u00e1 v\u00e1rias outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o ([SELU](https:\/\/arxiv.org\/abs\/1706.02515), [GELU](https:\/\/arxiv.org\/abs\/1606.08415), etc.). Para uma discuss\u00e3o mais profunda, recomendo [esta leitura](https:\/\/mlfromscratch.com\/activation-functions-explained\/#\/).\n\n#### Novas estrat\u00e9gias de inicializa\u00e7\u00e3o dos pesos\n\nLembre-se de que a maior dificuldade para o bom funcionamento de uma rede profunda \u00e9 garantir a efetiva propaga\u00e7\u00e3o dos sinais pela rede. Para esse objetivo, o ideal seria que a vari\u00e2ncia de um sinal (direto ou reverso) se mantivesse constante antes e depois de passar por uma camada. Isso n\u00e3o \u00e9 poss\u00edvel quando a camada apresenta um n\u00famero diferente de entradas em rela\u00e7\u00e3o ao de neur\u00f4nios, mas pode-se chegar pr\u00f3ximo o suficiente dessa situa\u00e7\u00e3o ideal por meio de estrat\u00e9gias inteligentes de inicializa\u00e7\u00e3o de pesos.\n\n[GLOROT e BENGIO (2010)](http:\/\/proceedings.mlr.press\/v9\/glorot10a\/glorot10a.pdf) propuseram uma nova inicializa\u00e7\u00e3o conhecida como *inicializa\u00e7\u00e3o de Glorot* (ou *de Xavier*), [usada como default no keras](https:\/\/keras.io\/api\/layers\/initializers\/#glorotuniform-class) e ideal para [fun\u00e7\u00f5es sigm\u00f3ides](https:\/\/en.wikipedia.org\/wiki\/Sigmoid_function) (como a log\u00edstica). [HE *et al.* (2015)](https:\/\/arxiv.org\/abs\/1502.01852) propuseram uma modifica\u00e7\u00e3o na inicializa\u00e7\u00e3o de Glorot para que funcionasse melhor com fun\u00e7\u00f5es de ativa\u00e7\u00e3o baseadas em retificadores lineares (`ReLU`, etc.), dando origem \u00e0 *inicializa\u00e7\u00e3o de He*. Ambas as estrat\u00e9gias envolvem amostragens aleat\u00f3rias a partir de distribui\u00e7\u00f5es estat\u00edsticas com caracter\u00edsticas espec\u00edficas. Para detalhes, consulte [esta p\u00e1gina](https:\/\/www.deeplearning.ai\/ai-notes\/initialization\/).\n\n#### Normaliza\u00e7\u00e3o por lote\n\nA [normaliza\u00e7\u00e3o por lote](https:\/\/en.wikipedia.org\/wiki\/Batch_normalization) foi proposta por [IOFFE e SZEGEDY (2015)](https:\/\/arxiv.org\/abs\/1502.03167) e desde ent\u00e3o aparece com frequ\u00eancia nas arquiteturas das redes neurais modernas. \n\nUma [camada de normaliza\u00e7\u00e3o por lote](https:\/\/keras.io\/api\/layers\/normalization_layers\/batch_normalization\/) aceita um vetor de entradas $\\mathbf{x}$ e retorna uma sa\u00edda $\\mathbf{y}$ de mesmo comprimento, cujos elementos resultam da seguinte opera\u00e7\u00e3o:\n\n$$ y_i = \\left(\\frac{x_i-\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}\\right)\\gamma +\\beta, $$\n\nem que:\n\n* $\\mu_B$ e $\\sigma_B^2$ s\u00e3o a m\u00e9dia e a vari\u00e2ncia do minilote utilizado no momento;\n* $\\gamma$ e $\\beta$ s\u00e3o par\u00e2metros a serem aprendidos pela rede;\n* $\\epsilon$ \u00e9 um n\u00famero fixo pequeno que ajuda a evitar problemas num\u00e9ricos.\n\nO termo dentro do par\u00eanteses \u00e9 a simples normaliza\u00e7\u00e3o do sinal utilizando as estat\u00edsticas do minilote. O sucesso da proposta veio da introdu\u00e7\u00e3o dos par\u00e2metros $\\gamma$ e $\\beta$, que possibilitam que as sa\u00eddas $y_i$ tenham *qualquer* m\u00e9dia e vari\u00e2ncia (na verdade, esses valores s\u00e3o determinados de maneira \u00f3tima pela rede).\n\nA normaliza\u00e7\u00e3o por lote possibilita que se utilize maiores taxas de aprendizado, diminui a sensibilidade da rede em rela\u00e7\u00e3o \u00e0 inicializa\u00e7\u00e3o e atua como um regularizador, aumentando a capacidade de generaliza\u00e7\u00e3o do modelo. O porqu\u00ea de ela funcionar t\u00e3o bem ainda \u00e9 uma quest\u00e3o em aberto. A explica\u00e7\u00e3o mais fact\u00edvel parece ser uma diminui\u00e7\u00e3o das influ\u00eancias dos pesos uns sobre os outros ao longo das v\u00e1rias camadas, o que suaviza a fun\u00e7\u00e3o objetivo e facilita a tarefa dos m\u00e9todos de minimiza\u00e7\u00e3o. Para discuss\u00f5es interessantes a respeito, consulte [SANTUNKAR *et al.* (2019)](https:\/\/arxiv.org\/abs\/1805.11604) ou [esta](https:\/\/blog.paperspace.com\/busting-the-myths-about-batch-normalization\/), [esta](https:\/\/mlexplained.com\/2018\/01\/10\/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1\/) e [esta](https:\/\/www.reddit.com\/r\/MachineLearning\/comments\/67mjuw\/d_alternative_interpretation_of\/) p\u00e1ginas.\n\n### Problema 3: escassez de dados para treinamento\n\nEste problema vem sendo aliviado principalmente por conta do cen\u00e1rio *big data*, com a cada vez maior quantidade de dados sendo gerada a partir das mais diversas fontes.\n\nNos casos em que h\u00e1 poucos dados para um problema em espec\u00edfico, podem ser utilizadas t\u00e9cnicas de [transfer\u00eancia de aprendizado](https:\/\/en.wikipedia.org\/wiki\/Transfer_learning), em que modelos treinados em uma situa\u00e7\u00e3o (com muitos dados) podem ser aplicados a cen\u00e1rios similares (com menor disponibilidade de dados). No aprendizado profundo, por exemplo, podemos usar camadas gen\u00e9ricas pr\u00e9-treinadas e treinar apenas as \u00faltimas camadas para uma situa\u00e7\u00e3o em espec\u00edfico, usando poucos dados, como demonstrado [aqui](https:\/\/keras.io\/guides\/transfer_learning\/). Essa \u00e9 uma linha de pesquisa ainda pouco explorada e potencialmente muito frut\u00edfera.\n\n### Problema 4: risco de sobreajuste por conta do excesso de par\u00e2metros\n\nPara esse problema, as velhas regulariza\u00e7\u00f5es $L_1$ e $L_2$ podem ser boas solu\u00e7\u00f5es. Al\u00e9m delas, uma estrat\u00e9gia de regulariza\u00e7\u00e3o muito usada \u00e9 a [dropout](https:\/\/en.wikipedia.org\/wiki\/Dilution_(neural_networks)), proposta por [HINTON *et al.* (2012)](https:\/\/arxiv.org\/abs\/1207.0580), que consiste na desativa\u00e7\u00e3o de uma certa parcela aleat\u00f3ria dos neur\u00f4nios a cada passo do treinamento. \u00c9 uma ideia simples, mas surpreendentemente efetiva para melhorar a capacidade de generaliza\u00e7\u00e3o das redes.","ef44c919":"Os [defeitos](https:\/\/en.wikipedia.org\/wiki\/Casting_defect) podem ser de [diferentes naturezas](http:\/\/www.jmmsassessoria.com.br\/upload\/files\/defeitos-em-pecas-fabricadas-pelo-processo-de-fundicao.pdf): rebarbas, porosidades, trincas, defeitos na superf\u00edcie, dimens\u00f5es ou forma incorretas, etc. O v\u00eddeo a seguir, por exemplo, fornece dicas para que se evite o problema da porosidade:","26652f8a":"Duas outras m\u00e9tricas adequadas para esse problema s\u00e3o a [precis\u00e3o $P$ e a revoca\u00e7\u00e3o $R$](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall). Denotando a classe negativa como sendo das amostras normais (sem defeitos) e a classe positiva como sendo das amostras com defeitos, definimos:\n\n$$\nP=\\frac{VP}{VP+FP}\n$$\n\n$$\nR=\\frac{VP}{VP+FN}\n$$\n\nem que $VP$ \u00e9 o n\u00famero de verdadeiros positivos, $FP$ \u00e9 o n\u00famero de falsos positivos e $FN$ \u00e9 o n\u00famero de falsos negativos. Em ess\u00eancia:\n\n* A precis\u00e3o diz respeito \u00e0 propor\u00e7\u00e3o de pe\u00e7as detectadas como defeituosas que est\u00e1 correta.\n* A revoca\u00e7\u00e3o diz respeito \u00e0 propor\u00e7\u00e3o de pe\u00e7as defeituosas que s\u00e3o corretamente detectadas.\n\nA precis\u00e3o \u00e9 uma medida de exatid\u00e3o das detec\u00e7\u00f5es e tem a ver com qualidade; a revoca\u00e7\u00e3o \u00e9 uma medida de completude das detec\u00e7\u00f5es e tem a ver com quantidade. Do ponto de vista da teoria estat\u00edstica de [testes de hip\u00f3teses](https:\/\/pt.wikipedia.org\/wiki\/Testes_de_hip%C3%B3teses), a precis\u00e3o est\u00e1 associada a [erros do tipo I](https:\/\/pt.wikipedia.org\/wiki\/Erro_do_tipo_I) e a revoca\u00e7\u00e3o est\u00e1 associada a [erros do tipo II](https:\/\/pt.wikipedia.org\/wiki\/Erro_do_tipo_II).\n\nUma m\u00e9trica tamb\u00e9m muito usada \u00e9 a [$F_1$](https:\/\/en.wikipedia.org\/wiki\/F1_score), a m\u00e9dia harm\u00f4nica entre precis\u00e3o e revoca\u00e7\u00e3o:\n\n$$\nF_1 = \\frac{2}{1\/P+1\/R} $$\n\nNa pr\u00f3xima c\u00e9lula, calculamos a precis\u00e3o, a revoca\u00e7\u00e3o e o $F_1$ de nosso modelo:","29f503ff":"Percebe-se que alguns d\u00edgitos foram escritos de maneira bem inusual. Um exerc\u00edcio interessante \u00e9 predizer voc\u00ea mesma os d\u00edgitos de cada uma dessas imagens e calcular sua \"acur\u00e1cia humana\". Tenta a\u00ed, duvido acertar todas xD\n\n\u00c9 poss\u00edvel melhorar ainda mais os resultados no conjunto MNIST (esse ser\u00e1 o tema do m\u00e3o-na-massa do final da aula). Agora, vamos dar uma olhada em um estudo de caso de natureza industrial.","1d7456ed":"Comparando valores verdadeiros e predi\u00e7\u00f5es:","fbf86ed0":"Especificamos o tamanho do lote como o tamanho total do conjunto de teste, j\u00e1 que a predi\u00e7\u00e3o de teste ser\u00e1 efetuada com todos os dados de uma vez, ap\u00f3s o t\u00e9rmino do treinamento.\n\nComo fizemos no caso MNIST, \u00e9 \u00fatil verificar as propor\u00e7\u00f5es das classes nos diferentes conjuntos:","0202d6b6":"## An\u00e1lise dos resultados","f7d22623":"Usando o `matplotlib` para dar uma olhada em duas pe\u00e7as aleat\u00f3rias (normal e defeituosa):","0b989633":"# Rede MLP no Keras\n\nNosso primeiro contato com as redes foi por meio do `scikit-learn`, uma abordagem conveniente pois j\u00e1 t\u00ednhamos familiaridade com sua interface. Mas, na verdade, existem bibliotecas muito mais poderosas para utiliza\u00e7\u00e3o de redes neurais, que possibilitam a cria\u00e7\u00e3o de modelos com diferentes arquiteturas e m\u00faltiplas camadas. S\u00e3o as chamadas bibliotecas de [aprendizado profundo (*deep learning*)](https:\/\/pt.wikipedia.org\/wiki\/Aprendizagem_profunda).\n\nEm particular, aqui utilizaremos a biblioteca [keras](https:\/\/keras.io\/), que oferece uma interface intuitiva para implementa\u00e7\u00e3o de modelos de redes neurais com a possibilidade de utiliza\u00e7\u00e3o de diversos motores de c\u00e1lculo (o motor utilizado aqui ser\u00e1 o [TensorFlow](https:\/\/www.tensorflow.org\/)).\n\nAntes de entrarmos nos detalhes do aprendizado profundo, \u00e9 interessante implementarmos no `keras` um modelo MLP semelhante ao que usamos no `scikit-learn`.\n\nPara criar uma rede neural no `keras`, podemos inicializar o modelo utilizando a classe [keras.models.Sequential()](https:\/\/keras.io\/api\/models\/sequential\/) e ir adicionando as camadas sequencialmente com o m\u00e9todo `add`:","eda45693":"Agora vamos criar o gerador das imagens de teste, definido de maneira um pouco diferente:","c177fd4a":"Para a playlist do curso completo, clique [aqui](https:\/\/www.youtube.com\/playlist?list=PLvr45Arc0UpzsRhzq3q4_KmZcm0utwvvB).","b6aa7279":"Dos seis valores mostrados, percebemos que o modelo tomou um 3 por um 8 (deve ser um erro recorrente, dada a semelhan\u00e7a entre os d\u00edgitos).\n\nUma m\u00e9trica de desempenho bastante usada em problemas de classifica\u00e7\u00e3o \u00e9 a acur\u00e1cia, ou seja, a simples propor\u00e7\u00e3o de predi\u00e7\u00f5es verdadeiras. Ela est\u00e1 dispon\u00edvel em [sklearn.metrics.accuracy_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.accuracy_score.html):","eaafceac":"Percebe-se que a quase totalidade das predi\u00e7\u00f5es est\u00e1 pr\u00f3xima de 0 ou 1, o que indica grande certeza do modelo quanto \u00e0s classes da maioria das imagens.\n\nObservando apenas as imagens classificadas incorretamente:","5278c8f0":"Os argumentos do m\u00e9todo `flow_from_directory` especificam que ser\u00e3o gerados minilotes contendo 32 imagens de tamanho 300x300 na escala de cinza (ou seja, com apenas 1 canal de cores). O problema \u00e9 bin\u00e1rio e \u00e0s classes normal (`ok_front`) e defeituosa (`def_front`) foram atribu\u00eddos os r\u00f3tulos 0 e 1, respectivamente. Os dados ser\u00e3o embaralhados e a semente da aleatoriedade foi especificada como 0.\n\nNesse momento, \u00e9 conveniente dar uma olhada em um exemplo de minilote. Para tal, utilizaremos a fun\u00e7\u00e3o `visualizeImageBatch`:","75b5a00f":"Parece um bom desempenho! Com um pequeno grau de sobreajuste, mas nada grave.\n\nPara maior detalhamento do resultado, podemos usar a [matriz de confus\u00e3o](https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix), dispon\u00edvel em [sklearn.metrics.confusion_matrix](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix):","294b3059":"Cada linha do DataFrame corresponde a uma imagem e cada coluna, a um pixel da imagem (com exce\u00e7\u00e3o da primeira coluna, `label`, que identifica o d\u00edgito). S\u00e3o 784 pixels, j\u00e1 que as imagens t\u00eam tamanho 28x28.\n\nSeparando os conjuntos `X` e `y`:","d3592237":"***M\u00e3o na massa 2!***\n\n* Analise a API da fun\u00e7\u00e3o [sklearn.neural_network.MLPClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html). Com os conceitos apresentados acima, voc\u00ea deve ser capaz de entender a natureza da maior parte dos hiperpar\u00e2metros. Treine a rede nos conjuntos MNIST e Fashion MNIST mais vezes, variando alguns hiperpar\u00e2metros e observando os efeitos nos resultados.\n\nObs: h\u00e1 algumas refer\u00eancias, ([SMITH, 2018](https:\/\/arxiv.org\/abs\/1803.09820), por exemplo), em que voc\u00ea pode conferir dicas e boas pr\u00e1ticas para essa tarefa.","5b95fca6":"As amostras com classifica\u00e7\u00f5es incorretas apresentam majoritariamente predi\u00e7\u00f5es pr\u00f3ximas de 0,5. Esse fato pode ser usado para montar uma estrat\u00e9gia de revis\u00e3o dos resultados do modelo. Predi\u00e7\u00f5es cujas probabilidades estejam muito distantes de 0 ou 1 (ou seja, em que o modelo n\u00e3o est\u00e1 muito confiante quanto ao pertencimento a alguma das classes) podem ser encaminhadas para verifica\u00e7\u00e3o humana.\n\nNa c\u00e9lula abaixo, selecionamos as amostras que resultam em probabilidades distantes de 0 ou 1 (o qu\u00e3o distantes podem ser par\u00e2metros ajust\u00e1veis):","3504ed5f":"As propor\u00e7\u00f5es parecem consistentes entre os conjuntos. Poder\u00edamos tentar corrigir a preval\u00eancia de imagens de pe\u00e7as defeituosas em rela\u00e7\u00e3o \u00e0s normais, mas como a diferen\u00e7a n\u00e3o \u00e9 t\u00e3o grande, isso n\u00e3o ser\u00e1 feito.\n\nPronto! J\u00e1 temos os objetos respons\u00e1veis por gerar nossos dados de treino, valida\u00e7\u00e3o e teste. Podemos proceder para a etapa de modelagem.","8fb3d145":"Como os dados s\u00e3o provenientes da [competi\u00e7\u00e3o Digit Recognizer](https:\/\/www.kaggle.com\/c\/digit-recognizer), apenas 42000 imagens est\u00e3o dispon\u00edveis no conjunto (as outras 28000 s\u00e3o reservadas para teste). Incentivo que voc\u00ea se inscreva na competi\u00e7\u00e3o e submeta os resultados dos v\u00e1rios modelos que criaremos ao longo da aula, de modo a verificar os respectivos desempenhos no conjunto de teste. Antes de submeter, n\u00e3o esque\u00e7a de retreinar os modelos no conjunto de treino completo (sem a separa\u00e7\u00e3o treino\/valida\u00e7\u00e3o).","fde71ce0":"A probabilidade de corte, portanto, pode ser um par\u00e2metro definido de acordo com o interesse da companhia:\n\n* Se deseja-se diminuir ao m\u00e1ximo o preju\u00edzo causado pelo desperd\u00edcio de pe\u00e7as boas (ou seja, diminuir o risco de falsos positivos), deve-se selecionar um corte que resulte em m\u00e1xima precis\u00e3o.\n* Se deseja-se evitar ao m\u00e1ximo o envio de pe\u00e7as defeituosas ao cliente (ou seja, diminuir o risco de falsos negativos), deve-se selecionar um corte que resulte em m\u00e1xima revoca\u00e7\u00e3o.\n* Se deseja-se um bom compromisso entre os dois cen\u00e1rios descritos, pode-se selecionar um corte que resulte em m\u00e1ximo $F_1$.\n\nNo caso de ajuste desse par\u00e2metro, \u00e9 bom que a escolha seja feita com base nos dados de valida\u00e7\u00e3o e n\u00e3o de teste, de modo que possamos usar os dados de teste para verifica\u00e7\u00e3o da adequa\u00e7\u00e3o da escolha.\n\nAcabamos de entender a import\u00e2ncia da probabilidade de sa\u00edda da rede para o processo de classifica\u00e7\u00e3o. Nas pr\u00f3ximas c\u00e9lulas, essa import\u00e2ncia ficar\u00e1 ainda mais clara por meio de uma an\u00e1lise detalhada do conjunto de teste.\n\nNa figura a seguir, visualizamos todas as 715 amostras do conjunto de teste junto com, respectivamente, a classe verdadeira e a probabilidade predita pelo modelo. No caso de predi\u00e7\u00f5es equivocadas, os t\u00edtulos est\u00e3o em vermelho.","b8d12409":"## Gerando dados com Keras\n\n* Aqui utilizaremos a classe [ImageDataGenerator](https:\/\/keras.io\/api\/preprocessing\/image\/#imagedatagenerator-class) (dispon\u00edvel no m\u00f3dulo [keras.preprocessing.image](https:\/\/keras.io\/api\/preprocessing\/image\/)) para gerar os tensores de entrada do modelo a partir dos arquivos dispon\u00edveis nas pastas `technocast_train_path` e `technocast_test_path`. \n\n* Essa gera\u00e7\u00e3o acontece em tempo real durante o treinamento: a cada itera\u00e7\u00e3o, um minilote de tensores \u00e9 fornecido ao modelo para que um passo da minimiza\u00e7\u00e3o seja efetuado.\n\nNa fun\u00e7\u00e3o abaixo, definimos um objeto de nome `datagen`a partir da classe `ImageDataGenerator`, especificando que os pixels ser\u00e3o normalizados para a faixa 0-1 (por meio da divis\u00e3o por 255) e 10% dos dados ser\u00e3o reservados para valida\u00e7\u00e3o. Ap\u00f3s isso, utilizamos o m\u00e9todo `flow_from_directory` para criar efetivamente os objetos que gerar\u00e3o os minilotes de treino e de valida\u00e7\u00e3o.","cb495f5a":"Perceba a grande quantidade de par\u00e2metros, mesmo em uma rede com apenas uma camada oculta!\n\nAntes de treinar o modelo, \u00e9 preciso compil\u00e1-lo, definindo a fun\u00e7\u00e3o perda, o otimizador e as m\u00e9tricas de avalia\u00e7\u00e3o:","43fbbd88":"Utilizando a fun\u00e7\u00e3o:","44b8974d":"Ufa! Deu bem mais trabalho do que o modelo do `scikit-learn`, pois foi preciso definir muito mais detalhes. Em compensa\u00e7\u00e3o, o desempenho computacional foi bem melhor.\n\nO atributo `history` do objeto `H` possibilita que analisemos a evolu\u00e7\u00e3o das m\u00e9tricas e valores da fun\u00e7\u00e3o perda para os dados de treino e valida\u00e7\u00e3o:","8ed433d7":"Observe a necessidade de reformata\u00e7\u00e3o dos dados de entrada para o formato largura x altura x canais de cores.\n\nVisualizando a curva de aprendizado:","d9ad22ff":"* S\u00e3o bem mais camadas do que o modelo MLP, mas a quantidade de par\u00e2metros \u00e9 menor.\n\n* A arquitetura \u00e9 t\u00edpica de uma rede convolucional: pares consecutivos de camadas convolucionais\/pooling, com os tamanhos dos mapas de caracter\u00edsticas diminuindo e o n\u00famero de filtros aumentando conforme se avan\u00e7a na profundidade. \u00c9 conveniente ter um n\u00famero maior de filtros nas camadas mais profundas porque em geral h\u00e1 muito mais possibilidades de padr\u00f5es complexos do que padr\u00f5es simples (lembre-se de que a identifica\u00e7\u00e3o de padr\u00f5es complexos se d\u00e1 por meio da combina\u00e7\u00e3o dos padr\u00f5es simples).\n\nNa pr\u00f3xima c\u00e9lula \u00e9 efetuado o treino da rede:","9c8cb6b7":"A fun\u00e7\u00e3o [entropia cruzada](https:\/\/pt.wikipedia.org\/wiki\/Entropia_cruzada) vem da [teoria da informa\u00e7\u00e3o](https:\/\/pt.wikipedia.org\/wiki\/Teoria_da_informa%C3%A7%C3%A3o) e mede a dist\u00e2ncia entre duas distribui\u00e7\u00f5es de probabilidade. Para duas distribui\u00e7\u00f5es $y$ e $p$, a entropia cruzada \u00e9 escrita como:\n\n$$ - \\sum_{j} y_{j} \\log \\, p_{j} $$\n\nNas aplica\u00e7\u00f5es de redes neurais para classifica\u00e7\u00e3o, as distribui\u00e7\u00f5es $y$ e $p$ s\u00e3o substitu\u00eddas pelos vetores $\\mathbf{y}$ (o vetor verdadeiro de probabilidades de cada classe) e $\\mathbf{p}$ (o vetor de probabilidades de cada classe predito pela rede).\n\nComo temos certeza sobre a classe verdadeira nas amostras de treinamento, na verdade os vetores verdadeiros de probabilidades $\\mathbf{y}$ tem a forma: $[0,0,..1,..0]$ (representa\u00e7\u00e3o *one-hot encoding*). \n\nPor exemplo, em certa aplica\u00e7\u00e3o o vetor $\\mathbf{y}$ poderia ser:\n\n$$\n\\mathbf{y} = [0,0,0,1,0,0,0,0,0,0],\n$$\n\no que significa dizer que temos certeza de que o valor verdadeiro \u00e9 3. \n\nO vetor $\\mathbf{p}$ poderia ser:\n\n$$\n\\mathbf{p} = [0,0,0,0.98,0,0.02,0,0,0,0],\n$$\n\no que significa dizer que a rede prev\u00ea que 98% de certeza que o valor \u00e9 3.\n\nA entropia cruzada entre $\\mathbf{y}$ e $\\mathbf{p}$ seria:\n\n$$-1\\cdot\\log(0.98) = -0.00877$$\n\nA fun\u00e7\u00e3o perda \u00e9 definida como a m\u00e9dia das v\u00e1rias entropias cruzadas das $M$ classes para todas as amostras $N$ do conjunto (ou do minilote):\n\n$$ - \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^M y_{ij} \\log \\, p_{ij} $$\n\n\u00c9 a fun\u00e7\u00e3o acima que a rede tenta minimizar durante o treinamento, manipulando os pesos das conex\u00f5es.\n\nPronto! J\u00e1 implementamos o modelo e entendemos os detalhes matem\u00e1ticos. Podemos enfim treinar:","62b263b4":"# O conjunto de dados MNIST\n\nO [conjunto de dados MNIST](https:\/\/en.wikipedia.org\/wiki\/MNIST_database) \u00e9 composto de 70000 imagens de d\u00edgitos escritos por funcion\u00e1rios do [United States Census Bureau](https:\/\/en.wikipedia.org\/wiki\/United_States_Census_Bureau) e estudantes do ensino m\u00e9dio estadunidenses. Nossa miss\u00e3o aqui ser\u00e1 criar modelos capazes de identificar o d\u00edgito de cada imagem.\n\n## Importando dados\n\nOs dados MNIST podem ser importados facilmente do `scikit-learn` ou do `keras`. No entanto, utilizaremos os dados dispon\u00edveis na [competi\u00e7\u00e3o Digit Recognizer](https:\/\/www.kaggle.com\/c\/digit-recognizer) do Kaggle:","832d1fff":"Adicionamos na rede acima duas camadas (al\u00e9m da camada de entrada, que n\u00e3o precisa ser explicitamente adicionada), ambas definidas com a classe [keras.layers.Dense](https:\/\/keras.io\/api\/layers\/core_layers\/dense\/). Uma camada densa \u00e9 aquela em que os neur\u00f4nios est\u00e3o conectados a todos os neur\u00f4nios da camada anterior.\n\nS\u00e3o 200 neur\u00f4nios na camada oculta. A entrada reflete a dimensionalidade das imagens (784 pixels). A fun\u00e7\u00e3o de ativa\u00e7\u00e3o [relu](https:\/\/en.wikipedia.org\/wiki\/Rectifier_(neural_networks)) (hoje mais prestigiada do que a velha log\u00edstica) \u00e9 usada tamb\u00e9m no default do MLP do `scikit-learn` e ser\u00e1 explicada mais adiante. \n\nS\u00e3o 10 neur\u00f4nios na camada de sa\u00edda, correspondentes \u00e0s 10 classes (aos 10 poss\u00edveis d\u00edgitos). A fun\u00e7\u00e3o [softmax](https:\/\/en.wikipedia.org\/wiki\/Softmax_function), a \u00faltima etapa da rede, \u00e9 a respons\u00e1vel por transformar a sa\u00edda em um vetor de probabilidades (um vetor de soma 1 composto por n\u00fameros entre 0 e 1):\n\n$$\\sigma(\\mathbf{u})_i = \\frac{e^{u_i}}{\\sum_{j=1}^K e^{u_j}} $$\n\nDessa maneira, a entrada da rede \u00e9 uma imagem de 784 pixels e a sa\u00edda \u00e9 um vetor de 10 elementos, cada um deles descrevendo a probabilidade da imagem corresponder a um dos d\u00edgitos entre 0 e 9.\n\n\u00c9 poss\u00edvel verificar a qualquer momento a estrutura do modelo com a fun\u00e7\u00e3o [summary()](https:\/\/keras.io\/api\/models\/model\/#summary-method):","6c059e13":"O desempenho \u00e9 melhor em rela\u00e7\u00e3o \u00e0 rede MLP!\n\nQue tal darmos uma olhada nas imagens que a rede classificou incorretamente?","95cdfe9b":"Carregando as melhores configura\u00e7\u00f5es de cada um dos modelos (salvas pelo callback `model_checkpoint`):","9e5821eb":"Analisando as matrizes de confus\u00e3o utilizando nossa fun\u00e7\u00e3o `display_score`:","a494c0e6":"\u00c9 \u00fatil verificar se as propor\u00e7\u00f5es de d\u00edgitos no treino e na valida\u00e7\u00e3o s\u00e3o parecidas:","b6595d77":"Efetuando a predi\u00e7\u00e3o nos dados de valida\u00e7\u00e3o:","d6f5fae1":"Visualizando um minilote:","cea47498":"# Videoaulas\n\nEste notebook \u00e9 explicado em detalhes ao longo das seguintes videoaulas:","6059409d":"Plotando as curvas de aprendizado:","8b00a14b":"Visualizando a estrutura da rede:","a1d013b8":"## Separando treino-valida\u00e7\u00e3o\n\nPara separar treino\/valida\u00e7\u00e3o, usaremos a fun\u00e7\u00e3o `train_test_split`:","7d7e233b":"***M\u00e3o na massa 3!***\n\n* Explore a [API do Keras](https:\/\/keras.io\/api\/) e aprenda como utilizar os recursos explicados aqui: fun\u00e7\u00f5es de ativa\u00e7\u00e3o, inicializa\u00e7\u00e3o de pesos, normaliza\u00e7\u00e3o por lote e *dropout*. Aplique em alguns modelos MLP para os conjuntos MNIST e Fashion MNIST. N\u00e3o fique preso ao que foi mencionado na aula: pesquise sobre e utilize outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o, inicializa\u00e7\u00f5es, etc.  O objetivo \u00e9 que voc\u00ea ganhe familiaridade com a biblioteca e autonomia para navegar na API e implementar os recursos em seus modelos.","3bc94918":"As propor\u00e7\u00f5es entre classes parecem bem balanceadas em ambos os conjuntos.","11e6bee5":"Existe um balan\u00e7o entre precis\u00e3o e revoca\u00e7\u00e3o: quando aumentamos uma, a outra tende a diminuir. Podemos verificar esse balan\u00e7o plotando as curvas de precis\u00e3o e revoca\u00e7\u00e3o em fun\u00e7\u00e3o da probabilidade de corte da sa\u00edda do modelo:","d454d33a":"Inspecionando os dados:","e8e5a29b":"Nas figuras acimas, para melhor visualiza\u00e7\u00e3o dos erros, as cores da diagonal foram zeradas e as cores de fora da diagonal foram normalizadas. Fica evidente o alto grau de sobreajuste, o que indica margem para melhoria do desempenho."}}