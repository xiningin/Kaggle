{"cell_type":{"311e0d51":"code","f95dcf37":"code","63d911d4":"code","80b4bb5d":"code","50f5876a":"code","d91ed55b":"code","4d6fc0cf":"code","01c5b57d":"code","1ed46e57":"code","7812894a":"code","199fc4a1":"code","535fb268":"code","af323e10":"code","b23a44cc":"code","97f57609":"code","d79c3c85":"code","8aa65f53":"code","44a0a06b":"code","adf0c212":"code","bc76583d":"code","63edf610":"code","eadfab37":"code","7ed48f1b":"code","1fcc52d1":"code","7ec242ce":"code","19df4812":"code","4d2c2ac8":"code","cbf11a65":"code","a1de8ec0":"code","1e902730":"code","9587152d":"code","42841648":"code","6ba3abcd":"code","ddbd9204":"code","182d0f35":"code","6bc7311c":"markdown","b4d9b356":"markdown","c4928550":"markdown","7c8e71bb":"markdown","c418e75d":"markdown","92714160":"markdown","e124b409":"markdown","781f435e":"markdown","4d7aea9a":"markdown"},"source":{"311e0d51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f95dcf37":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport unidecode\nimport nltk\n\nfrom tensorflow import keras\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom gensim.parsing.preprocessing import remove_stopwords\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import svm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom wordcloud import WordCloud","63d911d4":"#read dataset\ntrain_set = pd.read_csv(\"..\/input\/sentiment-analysis-on-movie-reviews\/train.tsv.zip\",sep = '\\t')\ntest_set= pd.read_csv(\"..\/input\/sentiment-analysis-on-movie-reviews\/test.tsv.zip\",sep = '\\t')\n\ntrain_set.head()","80b4bb5d":"print(len(train_set))\nprint(len(test_set))","50f5876a":"train_set.info()","d91ed55b":"train_set.describe()","4d6fc0cf":"train_set.columns","01c5b57d":"target_category = train_set['Sentiment'].unique()\ntarget_category=list(map(str,target_category))\nprint(target_category)","1ed46e57":"train_set = train_set[['Phrase','Sentiment']]\ntrain_set.head()","7812894a":"train_set.groupby(\"Sentiment\").Sentiment.count().plot.bar(ylim=0)","199fc4a1":"category = train_set.groupby('Sentiment').size()\n\ncategory.plot(kind='pie', subplots=True, figsize=(10, 8), autopct = \"%.2f%%\", colors=['purple','orange','blue','green','red'])\nplt.title(\"Pie chart for Sentiments\",fontsize=17)\nplt.legend()\nplt.show()","535fb268":"phrase = train_set['Phrase']\nphrase.head(10)","af323e10":"sentiment = train_set[\"Sentiment\"]\nsentiment.head(10)","b23a44cc":"def preprocessDataset(text): \n        \n    text = str(text)\n    \n    #remove single quotes \n    text = text.replace(\"'\", \"\")\n    \n    \n    #word tokenization using text-to-word-sequence\n    tokenized_train_set = text_to_word_sequence(text,filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n',split=\" \")\n\n\n    #stop word removal\n    stop_words = set(stopwords.words('english'))\n    stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n    #print (stop_words)\n     \n    #join words into sentence\n    stopwordremove_text = ' '.join(stopwordremove)\n    #print(stopwordremove_text)\n        \n    #remove numbers\n    numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n    #print(output)\n        \n    #Stemming\n    stemmer= PorterStemmer()\n\n    stem_input=nltk.word_tokenize(numberremove_text)\n    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n    #print(stem_text)\n    \n    #lemmatization\n    lemmatizer = WordNetLemmatizer()\n\n    def get_wordnet_pos(word):\n        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n        tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n        return tag_dict.get(tag, wordnet.NOUN)\n\n    lem_input = nltk.word_tokenize(stem_text)\n    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n    #print(lem_text)\n    \n\n    return lem_text","97f57609":"train_set['Phrase'] = train_set['Phrase'].apply(preprocessDataset)\nphrase = train_set['Phrase']\nsentiment = train_set['Sentiment']\nphrase.head()","d79c3c85":"def wordCollection(phrase, sentiment):\n    words = []\n    for i in phrase[phrase['Sentiment'] == sentiment]['Phrase'].str.split():\n        for j in i:\n            words.append(j)\n    return words","8aa65f53":"negative = wordCollection(train_set,0)\nsomewhat_negative = wordCollection(train_set,1)\nneutral = wordCollection(train_set,2)\nsomewhat_positive = wordCollection(train_set,3)\npositive = wordCollection(train_set,4)","44a0a06b":"wordCloud = WordCloud(background_color=\"white\", width=1600, height=800).generate(' '.join(negative))\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordCloud)","adf0c212":"wordCloud = WordCloud(background_color=\"white\", width=1600, height=800).generate(' '.join(somewhat_negative))\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordCloud)","bc76583d":"wordCloud = WordCloud(background_color=\"white\", width=1600, height=800).generate(' '.join(neutral))\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordCloud)","63edf610":"wordCloud = WordCloud(background_color=\"white\", width=1600, height=800).generate(' '.join(somewhat_positive))\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordCloud)","eadfab37":"wordCloud = WordCloud(background_color=\"white\", width=1600, height=800).generate(' '.join(positive))\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordCloud)","7ed48f1b":"list_data = list(zip(phrase, sentiment))\n   \ntrain_set = pd.DataFrame(list_data,columns = ['Phrase', 'Sentiment'])\ntrain_set.head(20)","1fcc52d1":"#remove empty rows \ntrain_set['Phrase'].replace('', np.nan, inplace=True)\ntrain_set.dropna(subset = [\"Phrase\"], inplace=True)\ntrain_set.head(20)","7ec242ce":"#after removing empty rows\nprint(len(train_set))","19df4812":"phrase = train_set['Phrase']\nsentiment = train_set['Sentiment']\n\nphrase.head()","4d2c2ac8":"X_train, X_test, Y_train, Y_test = train_test_split(phrase,sentiment, test_size = 0.3, random_state = 60,shuffle=True, stratify=sentiment)\n\nprint(len(X_train))\nprint(len(X_test))","cbf11a65":"vectorizer = TfidfVectorizer()\ntfidf_text = vectorizer.fit_transform(X_train)\n#print(tfidf_text)\n\n\n#--Training the classifier with  Naive Bayes--\n\nnb = Pipeline([('tfidf', TfidfVectorizer()),\n               ('clf', MultinomialNB()),\n              ])\n\nnb.fit(X_train,Y_train)\n\ntest_predict = nb.predict(X_test)\n\ntrain_accuracy = round(nb.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\n\nprint(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","a1de8ec0":"sgd = Pipeline([('tfidf', TfidfVectorizer()),\n                ('clf', SGDClassifier()),\n               ])\n\nsgd.fit(X_train, Y_train)\n\ntest_predict = sgd.predict(X_test)\n\ntrain_accuracy = round(sgd.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"SVM Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"SVM Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))","1e902730":"dt = Pipeline([('tfidf', TfidfVectorizer()),\n                ('dt', DecisionTreeClassifier()),\n               ])\n\ndt.fit(X_train, Y_train)\n\ntest_predict = dt.predict(X_test)\n\ntrain_accuracy = round(dt.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"Decision Tree Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Decision Tree Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))","9587152d":"knn = Pipeline([('tfidf', TfidfVectorizer()),\n                ('knn', KNeighborsClassifier(n_neighbors=5, metric='euclidean')),\n               ])\n\nknn.fit(X_train, Y_train)\n\ntest_predict = knn.predict(X_test)\n\ntrain_accuracy = round(knn.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"K-Nearest Neighbour Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"K-Nearest Neighbour Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","42841648":"test_set.head()","6ba3abcd":"test_set['Phrase'] = test_set['Phrase'].apply(preprocessDataset)\n\ntest_id = test_set['PhraseId']\ntest_text = test_set['Phrase']\ny_prdict = dt.predict(test_text)","ddbd9204":"submission = pd.DataFrame(list(zip(test_id, y_prdict)),\n               columns =['PhraseId', 'Sentiment'])\nsubmission.head(20)","182d0f35":"submission.to_csv('submission.csv', index=False)","6bc7311c":"after removing stop words some rows of the phrase colums has missing data. So we have to remove those rows ","b4d9b356":"**Most used words under positive lable**","c4928550":"**Most used words under somewhat postive lable**","7c8e71bb":"**Naive Bayes Classifier**","c418e75d":"**Most used words under negative lable**","92714160":"**Split dataset for train\/test**","e124b409":"**Most used words under neutral lable**","781f435e":"**Most used words under somewhat negative lable**","4d7aea9a":"**Train the test set with the Decison Tree model**"}}