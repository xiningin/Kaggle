{"cell_type":{"fd15c987":"code","2275f1a2":"code","de1e8e1a":"code","57674466":"code","7f6f29b3":"code","3e3c0804":"code","edde8951":"code","658b2b32":"code","c2fb6f0e":"code","81358c3c":"code","ff427794":"code","c7378c98":"code","2fc5d59b":"code","6b2d0e0f":"code","442b2315":"code","404510c6":"code","df568c55":"code","f158c0eb":"code","90329d30":"code","bf5891d9":"code","c66e5662":"code","b408c244":"code","ba12a561":"code","d47916be":"code","eaeb608d":"code","5a07f5c5":"code","9925c7e6":"code","aa9b8e33":"code","55583169":"code","736ccb35":"code","dd4b5cae":"code","0a45470c":"code","c567e1c3":"code","7c79e563":"code","64acc550":"code","ed3cee15":"code","a236f6ee":"code","f932f7d0":"code","b9215ca5":"code","9f5a969d":"code","8f4dcd36":"code","99813412":"code","ae6c3426":"code","585d8b9a":"code","bee136ea":"code","c39b1543":"code","89c17359":"code","c06f2c77":"code","91ea5c68":"code","a9b587ae":"code","da6c00c3":"code","27203641":"code","a129d992":"code","a2bd84dc":"code","d983ad30":"code","c8ee87fe":"code","483fc915":"code","0c8910c0":"code","937b50df":"code","2d4ff565":"code","e394c853":"code","f9cd5837":"code","97be285b":"code","82e58f84":"code","6d70d0a7":"code","87845f95":"code","213c39f6":"code","98329750":"code","ba2ce7f1":"code","64006b43":"code","cdcba9e3":"code","e7c2c17d":"code","8cf75e67":"code","0579e06c":"code","a7079db6":"code","e42a77b7":"code","bab7214e":"code","33e55ee4":"code","aa043ee5":"code","18041724":"code","9793bff4":"code","6d270e23":"code","c9918ad3":"code","4fa1168e":"markdown","c4534ad1":"markdown","f50a19a0":"markdown","6510330e":"markdown","b568fcf5":"markdown","5d29b984":"markdown","caf1f632":"markdown","6681655b":"markdown","f0726363":"markdown","619d8827":"markdown","ce5a0ec5":"markdown","edf8d216":"markdown","d6c34f4f":"markdown","68d02ebd":"markdown","be1531d2":"markdown","6f29c6eb":"markdown","55a8d7b6":"markdown","8e1b1e53":"markdown","4fe664e3":"markdown","46367fea":"markdown","fbd0afcc":"markdown","b6c848e0":"markdown","3c982b79":"markdown","86e3b416":"markdown","509602a8":"markdown","bde81eb0":"markdown","13dc1b45":"markdown","88ae778a":"markdown","4bdc26d5":"markdown"},"source":{"fd15c987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2275f1a2":"import pandas as pd # data analytical library\nimport numpy as np # fast linear algebra\nimport matplotlib.pyplot as plt # visulaization\nimport seaborn as sns # statictical viz","de1e8e1a":"data = pd.read_csv('..\/input\/machine-learning-24-hrs-hackathon\/train_SJC.csv')\ndata.head()","57674466":"new_header = data.iloc[0] #grab the first row for the header\ndata = data[1:] #take the data less the header row\ndata.columns = new_header #set the header row as the df header","7f6f29b3":"data.columns","3e3c0804":"# changing header name for three rows, DateReported, DependentsOther, DaysWorkedPerWeek\n\ndata.columns = ['ClaimNumber','DateTimeOfAccident','DateReported','Age', 'Gender','MaritalStatus', \n                'DependentChildren', 'DependentsOther','WeeklyWages', 'PartTimeFullTime',\n                'HoursWorkedPerWeek', 'DaysWorkedPerWeek','ClaimDescription', 'InitialIncurredCalimsCost',\n                'UltimateIncurredClaimCost']\n# data.head()","edde8951":"data.info()","658b2b32":"data.isnull().sum()","c2fb6f0e":"data[\"MaritalStatus\"].fillna(\"U\", inplace = True)\ndata[\"WeeklyWages\"].fillna(0, inplace = True)\ndata[\"HoursWorkedPerWeek\"].fillna(0, inplace = True)","81358c3c":"data.isnull().sum()","ff427794":"data.info()","c7378c98":"data['DateTimeOfAccident']=pd.to_datetime(data['DateTimeOfAccident'])\ndata['DateReported']=pd.to_datetime(data['DateReported'])","2fc5d59b":"data['Age']=pd.to_numeric(data['Age'])\ndata['DependentChildren']=pd.to_numeric(data['DependentChildren'])\ndata['DependentsOther']=pd.to_numeric(data['DependentsOther'])\ndata['WeeklyWages']=pd.to_numeric(data['WeeklyWages'])\ndata['HoursWorkedPerWeek']=pd.to_numeric(data['HoursWorkedPerWeek'])\ndata['DaysWorkedPerWeek']=pd.to_numeric(data['DaysWorkedPerWeek'])\ndata['InitialIncurredCalimsCost']=pd.to_numeric(data['InitialIncurredCalimsCost'])\ndata['UltimateIncurredClaimCost']=pd.to_numeric(data['UltimateIncurredClaimCost'])","6b2d0e0f":"data.info()","442b2315":"data.describe()","404510c6":"data.HoursWorkedPerWeek.max()","df568c55":"data.loc[data.HoursWorkedPerWeek.max(),:]","f158c0eb":"data['UltimateIncurredClaimCost'].describe()","90329d30":"plt.boxplot(data['UltimateIncurredClaimCost'])","bf5891d9":"plt.figure(figsize = (15,10))\nplt.subplot(1, 2, 1)\nsns.distplot(data['UltimateIncurredClaimCost'])\nplt.subplot(1, 2, 2)\nplt.title('Log Scale')\nsns.distplot(np.log1p(data['UltimateIncurredClaimCost']))","c66e5662":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\n\ntext = \" \".join(data.ClaimDescription)\nword_cloud = WordCloud(width=1600, height=800,collocations = False, background_color = 'white').generate(text)\nplt.figure( figsize=(10,20) ) \nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","b408c244":"words = ['RIGHT','LEFT','BACK','EYE','BODY','SHOULDER','FINGER',\n        'TOE','FOREARM','HAND','WRIST','KNEE','ELBOW','FOOT', \n        'LEG','NOSE','FACE','NECK','HEAD','LIGAMENT','MUSCLE'\n        'TENDON','THUMB','ANKLE','RIB','TISSUE','CALF','LIP','CORNEA',\n        'PAIN','SPRAIN','TWISTED','CUT','STRUCK','FELL',\n        'SPRAINED','STRAIN','LACERATION','LACERATED',\n        'LACERATE','UNKNOWN','TORN','JAMMED','KNIFE','FRACTURED',\n        'BURN','BRUISED','SPIDER','BRUISING', 'SLIP','CRUSHED',\n        'TRIPPED','INFECTED', 'INJURY', 'CHEMICAL']","ba12a561":"import nltk\nfrom nltk.corpus import stopwords\n\nstop_words = stopwords.words('english')\n\ndef get_keywords(column):\n    some_text = column['ClaimDescription']\n    tokens = nltk.tokenize.word_tokenize(some_text)\n    keywords = [keyword for keyword in tokens if keyword.isalpha() and not keyword in stop_words]\n    keywords_string = ' '.join(keywords)\n    return keywords_string\n\n#replaces all occurring digits in the strings with nothing\ndata['ClaimDescription'] = data['ClaimDescription'].str.replace('\\d+', '')\n#if you need the whole row to be passed inside the function\ndata['Keywords'] = data.apply(lambda row:get_keywords(row), axis=1) ","d47916be":"data['Keywords'].head()","eaeb608d":"del data[\"ClaimDescription\"]","5a07f5c5":"data['year_Acc'] = pd.DatetimeIndex(data['DateTimeOfAccident']).year\ndata['month_Acc'] = pd.DatetimeIndex(data['DateTimeOfAccident']).month\ndata['day_Acc'] = pd.DatetimeIndex(data['DateTimeOfAccident']).day\ndata['hour_Acc'] = pd.DatetimeIndex(data['DateTimeOfAccident']).hour\n\ndata['year_report'] = pd.DatetimeIndex(data['DateReported']).year\ndata['month_report'] = pd.DatetimeIndex(data['DateReported']).month\ndata['day_report'] = pd.DatetimeIndex(data['DateReported']).day\ndata['hour_report'] = pd.DatetimeIndex(data['DateReported']).hour\n\ndata['day_Lag'] = (data['DateReported'] - data['DateTimeOfAccident']) \/ np.timedelta64(1, 'D')\n\ndata['hour_Lag'] = (data['DateReported'] - data['DateTimeOfAccident'])","9925c7e6":"plt.figure(figsize = (10,5))\nplt.subplot(1, 2, 1)\nsns.distplot(data['HoursWorkedPerWeek'])\nplt.subplot(1, 2, 2)\nsns.distplot(data['DaysWorkedPerWeek'])","aa9b8e33":"plt.hist(data['Age'], color = 'cyan', edgecolor = 'black')","55583169":"sns.pairplot(data)","736ccb35":"sns.catplot(data=data, kind=\"bar\", x=\"DependentsOther\", y=\"UltimateIncurredClaimCost\", hue=\"Gender\", ci=None, height=6, aspect=11\/6)","dd4b5cae":"sns.catplot(data=data, kind=\"bar\", x=\"DependentChildren\", y=\"UltimateIncurredClaimCost\", hue=\"Gender\", ci=None, height=6, aspect=11\/6)","0a45470c":"sns.catplot(data=data, kind=\"bar\", x=\"year_Acc\", y=\"UltimateIncurredClaimCost\", ci=None, height=5, aspect=11\/5)","c567e1c3":"sns.catplot(data=data, kind=\"bar\", x=\"year_report\", y=\"UltimateIncurredClaimCost\", ci=None, height=6, aspect=11\/6)","7c79e563":"sns.catplot(data=data, kind=\"bar\", x=\"month_Acc\", y=\"UltimateIncurredClaimCost\", ci=None, height=6, aspect=11\/6)","64acc550":"sns.catplot(data=data, kind=\"bar\", x=\"month_report\", y=\"UltimateIncurredClaimCost\", ci=None, height=6, aspect=11\/6)","ed3cee15":"sns.catplot(data=data, kind=\"bar\", x=\"day_Acc\", y=\"UltimateIncurredClaimCost\", ci=None, height=6, aspect=11\/6)","a236f6ee":"sns.distplot(data['day_Lag'])","f932f7d0":"sns.distplot(data['hour_Lag'])","b9215ca5":"data['WeeklyWages'].describe()","9f5a969d":"ABin = pd.cut(data['WeeklyWages'], bins=[0,180,360,540,720,900], labels=['lowest','low','medium','high','highest'])\nABin.hist()\n# plt.hist(data['Age'], color = 'cyan', edgecolor = 'black')","8f4dcd36":"sns.distplot(data['WeeklyWages'],bins=30)","99813412":"small_weeklywages = (data['WeeklyWages'] < 1000)\nsns.distplot(small_weeklywages,bins=30)","ae6c3426":" del data['DateTimeOfAccident'] ","585d8b9a":"del data['DateReported']","bee136ea":"sns.catplot(data=data, kind=\"bar\", x='DaysWorkedPerWeek', y='HoursWorkedPerWeek', ci=None, height=6, aspect=11\/6)","c39b1543":"sns.catplot(data=data, kind=\"bar\", x='DaysWorkedPerWeek', y=\"UltimateIncurredClaimCost\", ci=None, height=6, aspect=11\/6)","89c17359":"data['InitialIncurredCalimsCost'].describe()\n","c06f2c77":"data[\"UltimateIncurredClaimCost\"].describe()","91ea5c68":"data.shape\ndata.columns","a9b587ae":"data.info()","da6c00c3":"data['hour_Lag']=pd.to_numeric(data['hour_Lag'])","27203641":"plt.figure(figsize = (10,5))\nplt.subplot(1, 2, 1)\nsns.distplot(data[\"UltimateIncurredClaimCost\"])\nsns.distplot(data['InitialIncurredCalimsCost'])\nplt.subplot(1, 2, 2)\nplt.title('Log Scale')\nsns.distplot(np.log1p(data['UltimateIncurredClaimCost']))\nsns.distplot(np.log1p(data['InitialIncurredCalimsCost']))\n# sns.catplot(data=data, x=\"UltimateIncurredClaimCost\", col=\"UltimateIncurredClaimCost\", kind='violin')","a129d992":"Cat_vars = ['Gender', 'MaritalStatus', 'PartTimeFullTime']","a2bd84dc":"data[Cat_vars].describe()","d983ad30":"data.info()","c8ee87fe":"data.columns","483fc915":"data.shape","0c8910c0":"del data['Keywords']","937b50df":"data.info()","2d4ff565":"del data['ClaimNumber']","e394c853":"data.drop(['Gender', 'MaritalStatus', 'PartTimeFullTime'], axis=1, inplace=True)","f9cd5837":"data.shape","97be285b":"data = pd.get_dummies(data)","82e58f84":"import sklearn.model_selection as ms\nimport sklearn.preprocessing as pre\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","6d70d0a7":"le = pre.LabelEncoder()","87845f95":"train , test = train_test_split(data, test_size = 0.3)\n\nx_train = train.drop('UltimateIncurredClaimCost', axis=1)\ny_train = train['UltimateIncurredClaimCost']\n\nx_test = test.drop('UltimateIncurredClaimCost', axis = 1)\ny_test = test['UltimateIncurredClaimCost']","213c39f6":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_train = pd.DataFrame(x_train_scaled)\n\nx_test_scaled = scaler.fit_transform(x_test)\nx_test = pd.DataFrame(x_test_scaled)","98329750":"from sklearn import neighbors\nfrom sklearn.metrics import mean_squared_error \nfrom math import sqrt\nimport matplotlib.pyplot as plt\n%matplotlib inline","ba2ce7f1":"rmse_val = [] #to store rmse values for different k\nfor K in range(20):\n    K = K+1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n\n    model.fit(x_train, y_train)  #fit the model\n    pred=model.predict(x_test) #make prediction on test set\n    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n    rmse_val.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)","64006b43":"curve = pd.DataFrame(rmse_val) #elbow curve \ncurve.plot()","cdcba9e3":"import sklearn.linear_model as lm","e7c2c17d":"glm=lm.LinearRegression()\nglm.fit(x_train,y_train)\nprint('The test score is', glm.score(x_test,y_test))\nprint('The train score is', glm.score(x_train,y_train))  ","8cf75e67":"#reading test and submission files\ntest = pd.read_csv('..\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv')\nsubmission = pd.read_csv('..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv')\nsubmission['ClaimNumber'] = test['ClaimNumber']\nsubmission['UltimateIncurredClaimCost'] = test['InitialIncurredCalimsCost']","0579e06c":"test.columns","a7079db6":"test.shape","e42a77b7":"test[\"MaritalStatus\"].fillna(\"U\", inplace = True)","bab7214e":"test['Age']=pd.to_numeric(test['Age'])\ntest['DependentChildren']=pd.to_numeric(test['DependentChildren'])\ntest['DependentsOther']=pd.to_numeric(test['DependentsOther'])\ntest['WeeklyWages']=pd.to_numeric(test['WeeklyWages'])\ntest['HoursWorkedPerWeek']=pd.to_numeric(test['HoursWorkedPerWeek'])\ntest['DaysWorkedPerWeek']=pd.to_numeric(test['DaysWorkedPerWeek'])\ntest['InitialIncurredCalimsCost']=pd.to_numeric(test['InitialIncurredCalimsCost'])\ntest['DateTimeOfAccident']=pd.to_datetime(test['DateTimeOfAccident'])\ntest['DateReported']=pd.to_datetime(test['DateReported'])","33e55ee4":"test['year_Acc'] = pd.DatetimeIndex(test['DateTimeOfAccident']).year\ntest['month_Acc'] = pd.DatetimeIndex(test['DateTimeOfAccident']).month\ntest['day_Acc'] = pd.DatetimeIndex(test['DateTimeOfAccident']).day\ntest['hour_Acc'] = pd.DatetimeIndex(test['DateTimeOfAccident']).hour\ntest['year_report'] = pd.DatetimeIndex(test['DateReported']).year\ntest['month_report'] = pd.DatetimeIndex(test['DateReported']).month\ntest['day_report'] = pd.DatetimeIndex(test['DateReported']).day\ntest['hour_report'] = pd.DatetimeIndex(test['DateReported']).hour\ntest['day_Lag'] = (test['DateReported'] - test['DateTimeOfAccident']) \/ np.timedelta64(1, 'D')\ntest['hour_Lag'] = (test['DateReported'] - test['DateTimeOfAccident'])","aa043ee5":"test.shape","18041724":"test = test.drop(['DateTimeOfAccident', 'DateReported', 'Gender','MaritalStatus',\n                  'ClaimDescription','PartTimeFullTime',], axis=1)","9793bff4":"test = test.drop(['ClaimNumber',], axis=1)","6d270e23":"test['hour_Lag']=pd.to_numeric(test['hour_Lag'])","c9918ad3":"#predicting on the test set and creating submission file\n\npredict = model.predict(test)\nsubmission['UltimateIncurredClaimCost'] = predict\nsubmission.to_csv('submit_file.csv',index=False)","4fa1168e":"We have removed the columns mentioned above as the relevent data had been extracted","c4534ad1":"From the above graph we can say that majority of the claims were incured by 20 to 25 year olds","f50a19a0":"## EDA\nEDA objective here: to understand how the num_var in this dataset relate to the UltimateIncurredClaimCost.","6510330e":"We can note from the above observations that Majority of the weekly wages in this populus is in between 350 to 600. with an extreme in 7000s.","b568fcf5":"The training and testing datasets were first loaded onto the kernel.  \nAfter which the null values were replaced with 0 or U (unmarried).  \nThe keywords in the Claim description were then extracted (using nlptk) based on the wordcloud made.  \nThen KNN was used to predict the UltimateIncurredClaimCost in the test dataset ","5d29b984":"## Reason this model was selected   \nThe KNN algorithm can be used for both classification and regression problems. \nThe KNN algorithm uses \u2018feature similarity\u2019 to predict the values of any new data points. A new point is assigned a value based on how closely it resembles the points in the training set.","caf1f632":"#### About the Target","6681655b":"The code( jupyter notebook) need to have the following code sections Data loading, Data processing, EDA, feature engineering, Machine Learning model and Reason to select the algorithm and how its better than other models","f0726363":"## Aim: to predict the Actuarial loss","619d8827":"### ClaimDescription to keywords","ce5a0ec5":"From the top two graphs we can say that:  \n- There is a gradual increase in accidents (therefore also, claims)\n- year 2005 had seen the most number of accidents (therefore also, claims)\n- there is no delay in the year of accident occuring and reporting ","edf8d216":"## Data processing","d6c34f4f":"In this plot we see that the workers\/people who have dependents (not thier children) Have ultimately claimed a lot more than the rest of the populus. These claims were made by Females more than males.","68d02ebd":"In the above plot we can see that the ultimate claims for 9 children were the most. these claim was done by Males.","be1531d2":"Above shows the accidents reported before they took place ","6f29c6eb":"There were some cases where the hours worked per week show null (replaced to 0) but the days worked per week show not null.  \nthis contradicts both columns.","55a8d7b6":"## Machine Learning model ","8e1b1e53":"## Feature Engineering\nthe process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning and is both difficult and expensive. (source: Wikipedia)","4fe664e3":"#### Analyzing categorical Variables  ","46367fea":"Things to deal with:  \n- there are null values\n- changing the data types of date time columns, some it cols\n- contraditicions of the wages and working columns","fbd0afcc":"From the top two graphs we can say that:  \n- there seems to be some delay in the day of accident occuring and reporting. ","b6c848e0":"From the top two graphs we can say that:  \n- The number of accidents (therefore also, claims) seem to be almost evenly distributed throughout the year.  \n  But there is a small increase in December\/January.\n- there seems to be some delay in the month of accident occuring and reporting.  \n  as the most number of accident occuring seem to be in december and reporting seem to be in January.\n- We can attribute them to New years accidents ??","3c982b79":"We can see that majority of the injuries occur on the right side (Majority of the populus is right handed), and are particularly strains.","86e3b416":"We can infer that there is some lag in the day the accident occur and reported","509602a8":"#### We can infer:  \nBased on the dependencies, more the number of dependencies then more would be the Ultimaate incurred claim cost. ","bde81eb0":"#### Changing data types of cols","13dc1b45":"#### Null values","88ae778a":"## Data loading","4bdc26d5":"In the above graph we see that, Most of the claims incurred were of people who worked 6 days of the week."}}