{"cell_type":{"6e9d4988":"code","ea14118d":"code","d8084a8b":"code","ad254991":"code","339e72b0":"code","ef9ec1c8":"code","1d1e6766":"code","50af72e5":"code","790e2066":"code","d1360d01":"code","280933ff":"code","91345275":"code","65f82c77":"code","ad59700e":"code","cab2500b":"code","99c70dac":"code","95f4d232":"code","21675020":"code","2fdbfe03":"markdown","d43c107d":"markdown","7562fd2a":"markdown","70c81816":"markdown","ffc4542b":"markdown","7a20db7e":"markdown","1a17e327":"markdown","793be133":"markdown","2b0b3dfe":"markdown"},"source":{"6e9d4988":"import numpy as np \nimport pandas as pd\nimport cv2\nfrom scipy.spatial import distance\nimport os\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","ea14118d":"#loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","d8084a8b":"import matplotlib.pyplot as plt\n#trying it out on a sample image\nimg = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss244.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4) #returns a list of (x,y,w,h) tuples\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n\n#plotting\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","ad254991":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        if label[i]==1:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),1)\n        else:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No. of faces detected is less than 2\")","339e72b0":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator","ef9ec1c8":"#Load train and test set\ntrain_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","1d1e6766":"# Data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\ntrain_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\nval_datagen = ImageDataGenerator(rescale=1.0\/255)\nval_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)","50af72e5":"# Load model from kaggle data\nvgg19_weights = \"..\/input\/vgg19\/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg19 = VGG19(weights=vgg19_weights, include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='sigmoid'))\nmodel.summary()","790e2066":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")","d1360d01":"history = model.fit(\n    generator=train_generator,\n    steps_per_epoch=len(train_generator)\/\/32,\n    epochs=20,validation_data=val_generator,\n    validation_steps=len(val_generator)\/\/32\n)","280933ff":"model.evaluate(test_generator)","91345275":"sample_mask_img = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\/1560.png')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nplt.imshow(sample_mask_img)\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0","65f82c77":"model.predict(sample_mask_img)","ad59700e":"model.save('masknet.h5')\n!ls","cab2500b":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)}","99c70dac":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No. of faces detected is less than 2\")","95f4d232":"# TFLite \ubcc0\ud658 - .h5 -> .pb\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nmodel = keras.models.load_model(\"masknet.h5\", compile=False)\n \nsaved_model_dir = '.\/output_pb'\nmodel.save(saved_model_dir, save_format=\"tf\")","21675020":"# TFLite \ubcc0\ud658 - .pb -> .tflite \nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\ntflite_model = converter.convert()\nwith open('.\/model.tflite', 'wb') as f:\n    f.write(tflite_model)\nwith open('.\/labels.txt', 'wt') as f:\n    f.write(\"\\n\".join(mask_label.values()))","2fdbfe03":"#### Red box shows violation of social distancing.","d43c107d":"## TFLite \ubcc0\ud658\ud558\uae30","7562fd2a":"### haar cascade\uc640 \ud568\uaed8 \uc0ac\uc6a9\ud558\uae30\n1. haar cascade\ub85c \uc5bc\uad74 crop\n2. crop\ud55c \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ubaa8\ub378\uc5d0 \ub123\uace0 \uc608\uce21","70c81816":"### \ubaa8\ub378 \uc800\uc7a5\ud558\uae30","ffc4542b":"### haar cascade\uc744 \ud65c\uc6a9\ud55c Face detection\n\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","7a20db7e":"### \ubaa8\ub378 \ud14c\uc2a4\ud2b8\ud558\uae30","1a17e327":"### VGG19 \uc804\uc774\ud559\uc2b5 \ubaa8\ub378","793be133":"### VGG19\ub97c \ud65c\uc6a9\ud55c Mask detection\n","2b0b3dfe":"# Mask and Social distancing Detection\n### Original notebook : [Mask and social distancing detection using VGG19](https:\/\/www.kaggle.com\/nageshsingh\/mask-and-social-distancing-detection-using-vgg19)\n\n### Additional conents\n+ Loading vgg19 model from downloaded file\n+ Converting to tflite model\n"}}