{"cell_type":{"5e8fd9cc":"code","f91ab604":"code","bfbaeb35":"code","cf2f54c8":"code","ff0916c0":"code","7a7a3542":"code","5b2a7c31":"code","61c8da1a":"code","def52f59":"code","2ae28114":"code","732f804b":"code","8bb026e3":"code","2283ab90":"code","dbfd665c":"code","7c1a8484":"code","e7138cee":"code","f537716b":"code","1a024eda":"code","2c98e7fc":"code","031f1470":"code","0a9b5db8":"code","7835b057":"code","7e1dc227":"code","47f57db6":"code","8cfd029a":"code","6bd8c425":"code","e4998ed3":"code","d00c3282":"code","a4056911":"code","7bdff34c":"code","f309d1bb":"code","dd5bbd41":"code","6c244312":"code","80e34599":"code","d036c7aa":"code","8d041b5b":"code","6edfe556":"code","2505ce12":"code","1db1aa44":"code","d6c93d93":"code","20d55065":"code","18710d30":"code","7c3493dc":"code","798d2775":"code","650e89a5":"code","4fa3c20b":"code","ca42371f":"code","5fcff1db":"code","e501a4ff":"code","6b8afe2f":"code","c4144758":"code","7468ef78":"code","dfbee8b5":"code","8fc2e67d":"code","a7db075a":"code","8358b260":"code","8ce3e5a9":"code","81f315c4":"code","d0fbe01d":"code","408766d0":"code","babdd601":"code","6bc77af6":"code","125e6ca0":"code","5b0c539a":"code","d5ef6606":"code","490583d4":"code","b3941477":"code","023168a7":"code","99dbc4d0":"code","25a81d71":"code","27453337":"code","73403a80":"code","a3c9ac73":"code","ebac643f":"code","30b6bd30":"code","f94b8be7":"code","26f8af66":"code","bf0a6c04":"code","ddfa7b5e":"code","1b679ff7":"code","2e9232e4":"code","bc03f7ef":"code","0e446978":"code","9ef10218":"code","aee05f38":"code","20856b5b":"code","de603791":"code","c4df4e8e":"code","18ac41dc":"code","4b7f8d09":"code","200bd360":"code","64ad8c91":"code","22d74f3d":"code","dd4355ab":"code","a63f80ed":"code","e2c3c5aa":"code","d20ceb2d":"code","bf837cf4":"code","a2b4b9b5":"code","98d3820a":"code","42a174c8":"code","bf72f2b3":"code","fa4d7c87":"code","a516fed0":"markdown","ae124f9e":"markdown","49966cd4":"markdown","8ce7dbcd":"markdown","6649a7c2":"markdown","ffb7b511":"markdown","91007b0c":"markdown","67d54253":"markdown","98be7d44":"markdown","82203e88":"markdown","10e2e336":"markdown","a4195224":"markdown","2859053b":"markdown","6226b9b9":"markdown","65077751":"markdown","89b443e6":"markdown","fced9ef3":"markdown","366b3853":"markdown","973416f6":"markdown","3b2eeec7":"markdown","a67988b2":"markdown","50495729":"markdown","15175b95":"markdown","941e2a9f":"markdown","35e5d856":"markdown","d3fa6268":"markdown","194c02e1":"markdown","6053e168":"markdown","bc40a871":"markdown","13be05bd":"markdown","697bd2ef":"markdown","3acc59cf":"markdown","eb3186e7":"markdown","bacd6184":"markdown","5f746ccf":"markdown","85bcd31c":"markdown","bb6af084":"markdown","42ac22bd":"markdown","7340e54b":"markdown","c8dc70db":"markdown","49ecbaf2":"markdown","e89b7cf1":"markdown","225ace78":"markdown","ade98265":"markdown","387b8f17":"markdown","85b3b256":"markdown","09638554":"markdown","96a5d032":"markdown","12029d9c":"markdown","c07efa3a":"markdown","a4faa057":"markdown","b34489a1":"markdown","e1c1b90a":"markdown","16196c50":"markdown"},"source":{"5e8fd9cc":"#importing necessary Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.decomposition import PCA\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sn\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom scipy.stats import pearsonr\nfrom scipy.stats import spearmanr\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import display\nsn.set()","f91ab604":"# Loading the dataset\nfor (root,dirs,files) in os.walk('\/kaggle\/input\/pamap-data'):\n  pass\n\n\n\nfiles_protocol_id = []\nfor i in range(len(files)):\n  files_protocol_id.append(root+'\/'+files[i])\n\n","bfbaeb35":"#files_optional_id","cf2f54c8":"files_protocol_id","ff0916c0":"# activity id dictonary is created according to the dataset\nactivity_id = {0: 'transient', 1:'lying', 2:'sitting', 3:'standing',\n              4:'walking', 5:'running', 6:'cycling', 7:'Nordic walking',\n              9:'watching TV', 10:'computer work', 11:'car driving',\n              12:'ascending stairs', 13:'descending stairs', 16:'vacuum cleaning',\n              17:'ironing', 18:'folding laundry', 19:'house cleaning',\n              20:'playing soccer', 24:'rope jumping'}\n","7a7a3542":"#just in case we want to capture the activity name from the numeric id\nactivity_id_reverse = {}\nfor key in activity_id.keys():\n  value = activity_id.get(key)\n  activity_id_reverse[value] = key","5b2a7c31":"activity_id_reverse","61c8da1a":"col_names = []","def52f59":"#developing the column name for the data\ncol_names=['timestamp', 'activity_id', 'heart_rate']\n\nIMU_locations = ['hand', 'chest', 'ankle']\nIMU_data = ['tmp', 'acc_16_01', 'acc_16_02', 'acc_16_03',\n            'acc_06_01', 'acc_06_02', 'acc_06_03',\n            'gyr_01', 'gyr_02', 'gyr_03',\n            'mag_01', 'mag_02', 'mag_03',\n            'ori_01', 'ori_02', 'ori_03', 'ori_04']\n","2ae28114":"colnames = col_names+ [j+'_'+i  for i in IMU_locations for j in IMU_data]\ncolnames\n","732f804b":"#Loading all the seperate files into a single dataframe\ndf_raw = pd.DataFrame() \nfor i in files_protocol_id : \n  int_data = pd.read_table(i , names = colnames, sep = '\\s+')\n  int_data['SubjectID'] = int(i[-5])\n  df_raw = df_raw.append(int_data, ignore_index = True)\n  \n\n","8bb026e3":"#The initial raw dataframe\npd.set_option('display.max_columns',None)\ndf_raw\n","2283ab90":"drop_columns = ['acc_06_01_hand','acc_06_02_hand','acc_06_03_hand','ori_01_hand','ori_02_hand','ori_03_hand','ori_04_hand','acc_06_01_chest','acc_06_02_chest','acc_06_03_chest','ori_01_chest','ori_02_chest','ori_03_chest','ori_04_chest','acc_06_01_ankle','acc_06_02_ankle','acc_06_03_ankle','ori_01_ankle','ori_02_ankle','ori_03_ankle','ori_04_ankle']","dbfd665c":"df_raw1 = df_raw.drop(drop_columns, axis = 1)","7c1a8484":"df_raw1.isnull().sum()","e7138cee":"df_raw1 = df_raw1.dropna(subset = ['heart_rate'])\ndf_raw1","f537716b":"df_raw1.isnull().sum()","1a024eda":"drop_index = []\n\n#Getting indexes of activity 0\ndrop_index += list(df_raw1.index[df_raw1['activity_id']==0])\n\n#Keep only activities as documented on file \"PerformedActivitiesSummary.pdf\"\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==1) & (df_raw1['activity_id'].isin([10,20]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==2) & (df_raw1['activity_id'].isin([9,10,11,18,19,20]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==3) & (df_raw1['activity_id'].isin([5,6,7,9,10,11,18,19,20,24]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==4) & (df_raw1['activity_id'].isin([5,9,10,11,18,19,20,24]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==5) & (df_raw1['activity_id'].isin([9,11,18,20]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==6) & (df_raw1['activity_id'].isin([9,11,20]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==7) & (df_raw1['activity_id'].isin([9,10,11,18,19,20,24]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==8) & (df_raw1['activity_id'].isin([9,11]))])\ndrop_index += list(df_raw1.index[(df_raw1['SubjectID']==9) & (df_raw1['activity_id'].isin([1,2,3,4,5,6,7,9,11,12,13,16,17]))])\n\ndf_raw1 = df_raw1.drop(drop_index)","2c98e7fc":"#interpolating the data \ndf_raw1 =df_raw1.interpolate(limit_direction = 'both')","031f1470":"df_raw1.head(6)","0a9b5db8":"#finding resultant acceleration, and angular velocity for hand, chest and ankle\ndf_raw1['acc_hand'] = ((df_raw1.acc_16_01_hand**2)+(df_raw1.acc_16_02_hand**2)+(df_raw1.acc_16_03_hand**2))**0.5\ndf_raw1['acc_chest'] = ((df_raw1.acc_16_01_chest**2)+(df_raw1.acc_16_02_chest**2)+(df_raw1.acc_16_03_chest**2))**0.5\ndf_raw1['acc_ankle'] = ((df_raw1.acc_16_01_ankle**2)+(df_raw1.acc_16_02_ankle**2)+(df_raw1.acc_16_03_ankle**2))**0.5\ndf_raw1['gyr_hand'] = ((df_raw1.gyr_01_hand**2)+(df_raw1.gyr_02_hand**2)+(df_raw1.gyr_03_hand**2))**0.5\ndf_raw1['gyr_chest'] = ((df_raw1.gyr_01_chest**2)+(df_raw1.gyr_02_chest**2)+(df_raw1.gyr_03_chest**2))**0.5\ndf_raw1['gyr_ankle'] = ((df_raw1.gyr_01_ankle**2)+(df_raw1.gyr_02_ankle**2)+(df_raw1.gyr_03_ankle**2))**0.5\n","7835b057":"#removing all of the individual acceleration,angularvelocity and magneticfield measurements and\nto_drop = ['acc_16_01_hand','acc_16_02_hand','acc_16_03_hand','acc_16_01_ankle','acc_16_02_ankle','acc_16_03_ankle','acc_16_01_chest','acc_16_02_chest','acc_16_03_chest','gyr_01_hand','gyr_02_hand','gyr_03_hand','gyr_01_chest','gyr_02_chest','gyr_03_chest','gyr_01_ankle','gyr_02_ankle','gyr_03_ankle','mag_01_hand','mag_02_hand','mag_03_hand','mag_01_chest','mag_02_chest','mag_03_chest','mag_01_ankle','mag_02_ankle','mag_03_ankle']\ndf_raw2 = df_raw1.drop(to_drop, axis = 1)\ndf_raw2","7e1dc227":"freq = 5\ndf_raw2['activity_block'] = ((df_raw2['activity_id'].shift(1) != df_raw2['activity_id']) | (df_raw2['SubjectID'].shift(1) != df_raw2['SubjectID'])).astype(int).cumsum() #will count each change either when acitvity or the subject changes and make cumilative sum and saved as a row in the data frame\ndrop_index = []\nnumblocks = df_raw2['activity_block'].max() #for the total number of change\nfor block in range(1, numblocks+1):# for each place in the data frame where activity or subject changes, 50 rows are added (corresponding to five seconds) to the droplist\n    drop_index += list(df_raw2[df_raw2['activity_block']==block].head(10 * freq).index)\n    drop_index += list(df_raw2[df_raw2['activity_block']==block].tail(10 * freq).index)\n    \ndf_raw3 = df_raw2.drop(drop_index)# the rows in the droplist is droped, ie, 5 seconds in each shift of activities is removed\ndf_raw3.drop(['activity_block'], axis = 1, inplace  = True)\ndf_raw3.reset_index(drop = True, inplace = True)\ndf_raw3\n","47f57db6":"# the cleaned data is shuffled and split into test and train data\ndf_train = df_raw3.sample(frac=0.8, random_state=1)\ndf_test = df_raw3.drop(df_train.index)","8cfd029a":"df_train","6bd8c425":"df_train.describe()","e4998ed3":"df_final = df_raw3.drop(['activity_id','SubjectID','timestamp'],axis = 1)","d00c3282":"df_final.hist(figsize = (25,25), bins = 50)\nplt.show()","a4056911":"sn.set()\ndf_HR_mean =df_train['heart_rate'].groupby(df_train['activity_id']).mean()#grouping heart rate data wrt activity id and finds the mean of heart rate for each activity\ndf_HR_mean.index = df_HR_mean.index.map(activity_id)# to get the real activity id as index\ndf_HR_mean.plot(kind = 'bar')\nplt.ylabel(\"Mean Heart Rate (bpm)\")\nplt.title('Hear rate average for different activities')\nplt.show()","7bdff34c":"# To find the hand,chest and ankle average accelaration\ndf_Acc_hand_mean = df_train['acc_hand'].groupby(df_train['activity_id']).mean() - 9.81 # 9.81(accelartion due to gravity) is reduced so that while plotting it will give better idea of vigour of the movement of the body part\ndf_Acc_chest_mean = df_train['acc_chest'].groupby(df_train['activity_id']).mean() - 9.81\ndf_Acc_ankle_mean = df_train['acc_ankle'].groupby(df_train['activity_id']).mean() - 9.81\n\ndf_Acc_hand_mean.index = df_Acc_hand_mean.index.map(activity_id)\ndf_Acc_chest_mean.index = df_Acc_chest_mean.index.map(activity_id)\ndf_Acc_ankle_mean.index = df_Acc_ankle_mean.index.map(activity_id)","f309d1bb":"df_acc_mean = pd.concat([df_Acc_hand_mean,df_Acc_chest_mean,df_Acc_ankle_mean],axis = 1)# concating the different means togather so that it can be plotted in the same plot as a tripple bar graph\ndf_acc_mean.plot(kind = 'bar', figsize = (15,8))\nplt.ylabel('Mean Acceleration m\/s^2')\nplt.title('Mean Accelerations of Hand, Chest and Ankle for different activities')\nplt.show()","dd5bbd41":"# To find the hand,chest and ankle average angular velocity\ndf_gyr_hand_max = df_train['gyr_hand'].groupby(df_train['activity_id']).mean()\ndf_gyr_chest_max = df_train['gyr_chest'].groupby(df_train['activity_id']).mean()\ndf_gyr_ankle_max = df_train['gyr_ankle'].groupby(df_train['activity_id']).mean()\n\ndf_gyr_hand_max.index = df_gyr_hand_max.index.map(activity_id)\ndf_gyr_chest_max.index = df_gyr_chest_max.index.map(activity_id)\ndf_gyr_ankle_max.index = df_gyr_ankle_max.index.map(activity_id)","6c244312":"df_angular_vel_max = pd.concat([df_gyr_hand_max,df_gyr_chest_max,df_gyr_ankle_max],axis =1)# concating the different means togather so that it can be plotted in the same plot as a tripple bar graph\ndf_angular_vel_max.plot(kind = 'bar', figsize = (15,8))\nplt.ylabel('Radian\/sec')\nplt.title('Mean angular velocity of Hand, chest and Ankle for different activities')\nplt.show()","80e34599":"list_activities = list(df_gyr_hand_max.index)# just to get the list of 12 activities which are protocol activities\nlist_activities","d036c7aa":"#To see how the temperature data description of the hand for different activitites\ndf_tmp_hand = df_train[['tmp_hand']].groupby(df_train['activity_id'])\nk = df_tmp_hand.describe()\nk.index = df_tmp_hand.describe().index.map(activity_id)# To change the index to the real index","8d041b5b":"k","6edfe556":"#Box plot for temperature variation of the hand for different activities\ndf_tmp_hand.boxplot(figsize = (25,25))\nplt.show()","2505ce12":"#average values of all the sensor data for different subject ID\ndf_average =df_train.pivot_table(index = 'SubjectID')# pivoting the table wrt the subject ID\ndf_average1 =df_average.drop([\"activity_id\",\"timestamp\"],axis = 1)\ndf_average1","1db1aa44":"#average value of sensor data for different activities\ndf_average_activity = df_train.pivot_table(index = 'activity_id')#pivoting table wrt the activity id\ndf_average_activity.index  = df_average_activity.index.map(activity_id)\ndf_average_activity_new=df_average_activity.drop(['SubjectID'],axis = 1)\ndf_average_activity_new","d6c93d93":"#removing unsuitable columns for correlation\ndf_train1 = df_train.drop(['SubjectID','activity_id','timestamp'],axis =1)","20d55065":"df_train1.corr(method = 'spearman').style.background_gradient()\n","18710d30":"#heatmap using seaborn for representing the same correlation data frame we saw before\n\nsn.set(font = 'monospace')\ndf_train1_corr_matrix = df_train1.corr(method='spearman')\n\nfig, axe = plt.subplots(figsize=(12,12))\ncmap = sn.diverging_palette(220,10,center = \"light\", as_cmap=True)\n\nsn.heatmap(df_train1_corr_matrix,vmax=1,square =True, cmap=cmap,annot=True );","7c3493dc":"#My correlation Hypothesis testing function\ndef hypothesis_testing_corr(data1,data2):\n  correlation,p_value = spearmanr(data1,data2)#spearmanr gives correlation and p_value as output\n  print('correlation between the parameters = {}'.format(correlation))#prints the correlation\n  print('p_value = {}'.format(p_value))#prints the p-value\n  for i in [0.01 , 0.05, 0.1]:\n      if p_value < i:\n        print('The null Hypothesis H0 is rejected at a confidence interval of {}%'.format(100 -i*100))\n        break\n\n      else:\n        print('Failed to reject the null Hypothesis at {}% of confidence interval'.format(100-i*100))","798d2775":"hypothesis_testing_corr(df_test['gyr_ankle'],df_test['heart_rate']) #calling hypothesis function on the angular velocity and heart rate data","650e89a5":"hypothesis_testing_corr(df_test['gyr_hand'],df_test['heart_rate'])#calling hypothesis function ","4fa3c20b":"from sklearn.metrics import precision_score,recall_score, f1_score, confusion_matrix, accuracy_score,ConfusionMatrixDisplay\nfrom sklearn.svm import SVC #importig svm model\n","ca42371f":"#Shuffling the data set\ndf_final2 = df_raw3.sample(frac = 1, random_state = 33)","5fcff1db":"#Dropping timestamp and subject id\ndf_final3 = df_final2.drop(['timestamp','SubjectID'],axis = 1)","e501a4ff":"df_features = df_final3.drop(['activity_id'],axis = 1)#features dataframe\ndf_target = df_final3['activity_id']#target\n","6b8afe2f":"scaler = RobustScaler()#Robust scaler is used since the data is skewed and not normally distributed\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)#test train split\nX_train = scaler.fit_transform(X_train)#scaling the train data\nX_test = scaler.transform(X_test)#scaling the train data using the same scalar object","c4144758":"def get_metrics (y_true,y_pred):# function to get accuracy,precision,Recall and F1 score of the data\n    acc = accuracy_score(y_true, y_pred)\n    \n    p = precision_score(y_true, y_pred,average=None).mean()#average precision \n    r = recall_score(y_true, y_pred, average=None).mean()#average recall\n    f1 = f1_score(y_true, y_pred, average=None).mean()#average f1 score\n   \n    print(\"Accuracy:  \",acc)\n    \n    print(\"Precision: \", p)\n    print(\"Recall:    \", r)\n    print(\"F1:        \", f1)","7468ef78":"#function to show the confusion matrix\ndef show_Confusion_matrix(y_true,y_predicted):  \n  cm = confusion_matrix(y_true,y_predicted)\n  plt.rcParams['figure.figsize'] = (18,10)#setting the scale to get bigger display\n  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels = list_activities)\n  disp.plot(xticks_rotation= 'vertical',cmap = 'binary' )\n  plt.show()\n","dfbee8b5":"from sklearn.decomposition import PCA #importing PCA from Sklearn\npca = PCA()\npca.fit(X_train)#fitting the train data\nvar= pca.explained_variance_ratio_ # explains how much variance is captured by the number of components\nvar1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n\nplt.title(\"PCA Variance against num of Componmnets\")\nplt.ylabel(\"Variance %\")\nplt.xlabel(\"Number of componments\")\nl = plt.axhline(94, color=\"red\")# the meeting point between the line and the curve will give how many components we have to consider for capturing 94% variance\n\nplt.plot(var1)\nplt.grid()","8fc2e67d":"pca = PCA(n_components=3)# creating PCA object for 3 features\nX_train=pca.fit_transform(X_train)#fitting X_train\nX_test=pca.transform(X_test)#using the same pca object to transform X_test","a7db075a":"X_train_df = pd.DataFrame(X_train,columns=['PCA_1','PCA_2','PCA_3' ])#the columns show the 3 columns created by the PCA object\nX_train_df","8358b260":"from sklearn.svm import SVC","8ce3e5a9":"%%time\nSVCmodel = SVC(kernel = 'rbf')\nSVCmodel.fit(X_train, y_train)","81f315c4":"%%time\nSVCmodel_y_pred = SVCmodel.predict(X_test)\nprint(len(SVCmodel_y_pred))\nprint(len(y_test))\nprint(SVCmodel_y_pred[0:5])\nprint(y_test[0:5])","d0fbe01d":"#shows the confusion matrix\nshow_Confusion_matrix(y_test,SVCmodel_y_pred)","408766d0":"get_metrics(y_test,SVCmodel_y_pred)","babdd601":"#shuffling \ndf_final2 = df_raw3.sample(frac = 1, random_state = 33)","6bc77af6":"df_final3 = df_final2.drop(['timestamp','SubjectID'],axis = 1)#dropping ","125e6ca0":"df_features = df_final3.drop(['activity_id'],axis = 1)#feature\ndf_target = df_final3['activity_id']#target\n","5b0c539a":"scaler = RobustScaler()#since data is not normal and skewed\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","d5ef6606":"%%time\nSVCmodel = SVC(kernel = 'rbf')#Eusing svm model\nSVCmodel.fit(X_train, y_train)","490583d4":"%%time\nSVCmodel_y_pred = SVCmodel.predict(X_test)\nprint(len(SVCmodel_y_pred))\nprint(len(y_test))\nprint(SVCmodel_y_pred[0:5])\nprint(y_test[0:5])","b3941477":"show_Confusion_matrix(y_test,SVCmodel_y_pred)","023168a7":"get_metrics(y_test,SVCmodel_y_pred)# to get the score","99dbc4d0":"from sklearn.ensemble import RandomForestClassifier #Using RandomForest model for classification ","25a81d71":"%%time\nRFmodel = RandomForestClassifier()#creating the model object\nRFmodel.fit(X_train,y_train)","27453337":"RFmodel_y_pred = RFmodel.predict(X_test)#predictions\nprint(len(RFmodel_y_pred))\nprint(len(y_test))\nprint(RFmodel_y_pred[0:5])#to compare the first 5 predictions\nprint(y_test[0:5])","73403a80":"#showing the confusion matrix\nshow_Confusion_matrix(y_test, RFmodel_y_pred)","a3c9ac73":"get_metrics(y_test,RFmodel_y_pred)","ebac643f":"df_final3= df_final2.drop(['SubjectID','timestamp','gyr_hand','gyr_chest','gyr_ankle'],axis = 1)#dropping gyroscope data","30b6bd30":"df_features = df_final3.drop(['activity_id'],axis = 1)#features\ndf_target = df_final3['activity_id']#target\n","f94b8be7":"scaler = RobustScaler()#standardizing non normal data\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","26f8af66":"RFmodel = RandomForestClassifier()#creating model object\nRFmodel.fit(X_train,y_train)#training the data","bf0a6c04":"RFmodel_y_pred = RFmodel.predict(X_test)#making prediction\nprint(len(RFmodel_y_pred))\nprint(len(y_test))\nprint(RFmodel_y_pred[0:5])#compare the first five results\nprint(y_test[0:5])","ddfa7b5e":"show_Confusion_matrix(y_test, RFmodel_y_pred)","1b679ff7":"get_metrics(y_test,RFmodel_y_pred)#gt the scores","2e9232e4":"df_final3= df_final2.drop(['SubjectID','timestamp','tmp_hand','tmp_chest','tmp_ankle'],axis = 1)#removing temperature data","bc03f7ef":"df_features = df_final3.drop(['activity_id'],axis = 1)#features\ndf_target = df_final3['activity_id']#target\n","0e446978":"scaler = RobustScaler()# for standardizing\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","9ef10218":"RFmodel = RandomForestClassifier()#creating model object\nRFmodel.fit(X_train,y_train)#training the model","aee05f38":"RFmodel_y_pred = RFmodel.predict(X_test)#Making the prediction\nprint(len(RFmodel_y_pred))\nprint(len(y_test))\nprint(RFmodel_y_pred[0:5])#comparing the first 5 predictions with original classification\nprint(y_test[0:5])","20856b5b":"show_Confusion_matrix(y_test, RFmodel_y_pred)#to show the confusion matrix","de603791":"get_metrics(y_test,RFmodel_y_pred)#get score","c4df4e8e":"#shuffling \ndf_final2 = df_raw3.sample(frac = 1, random_state = 33)","18ac41dc":"df_final3 = df_final2.drop(['timestamp','SubjectID','acc_chest','acc_ankle','tmp_chest','tmp_ankle','gyr_chest','gyr_ankle'],axis = 1)#dropping sensor datas from chest and ankle","4b7f8d09":"df_features = df_final3.drop(['activity_id'],axis = 1)#feature\ndf_target = df_final3['activity_id']#target\n","200bd360":"scaler = RobustScaler()#since data is not normal and skewed\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","64ad8c91":"RFmodel = RandomForestClassifier()#creating model object\nRFmodel.fit(X_train,y_train)#training the model","22d74f3d":"RFmodel_y_pred = RFmodel.predict(X_test)#Making the prediction\nprint(len(RFmodel_y_pred))\nprint(len(y_test))\nprint(RFmodel_y_pred[0:5])#comparing the first 5 predictions with original classification\nprint(y_test[0:5])","dd4355ab":"show_Confusion_matrix(y_test, RFmodel_y_pred)#to show the confusion matrix","a63f80ed":"get_metrics(y_test,RFmodel_y_pred)#get score","e2c3c5aa":"#shuffling \ndf_final2 = df_raw3.sample(frac = 1, random_state = 33)","d20ceb2d":"df_final3 = df_final2.drop(['timestamp','SubjectID','acc_chest','acc_hand','tmp_chest','tmp_hand','gyr_chest','gyr_hand'],axis = 1)#dropping sensor data from chest and hand","bf837cf4":"df_features = df_final3.drop(['activity_id'],axis = 1)#feature\ndf_target = df_final3['activity_id']#target\n","a2b4b9b5":"scaler = RobustScaler()#since data is not normal and skewed\nX_train,X_test,y_train,y_test = train_test_split(df_features,df_target,test_size = 0.2,random_state = 42)\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","98d3820a":"RFmodel = RandomForestClassifier()#creating model object\nRFmodel.fit(X_train,y_train)#training the model","42a174c8":"RFmodel_y_pred = RFmodel.predict(X_test)#Making the prediction\nprint(len(RFmodel_y_pred))\nprint(len(y_test))\nprint(RFmodel_y_pred[0:5])#comparing the first 5 predictions with original classification\nprint(y_test[0:5])","bf72f2b3":"show_Confusion_matrix(y_test, RFmodel_y_pred)#to show the confusion matrix","fa4d7c87":"get_metrics(y_test,RFmodel_y_pred)#get score","a516fed0":"RandomForestClassifier only takes 45second to trian our model where as SVM model took almost 8 mins","ae124f9e":"# Conclusion\n\nThe PAMAP2 Physical Activity Monitoring dataset has been analyzed and various insights has been gained.Different sensor data is manipulated in such away that the sensor data all togather can be used as features for help in developing a Hardware\/software which can predict the activity performed by the person out of the 12 protocol activities.\n\nHypothesis testing is done on the test data set to make sure that our findings in explortory data analysis is statistically significant\n\nFinally found a very good model RandomForestClassifier, which takes very low time to calculate the accuracy and very high accuracy while classifying the activities in test data set compared to SVM(support vector machine model).\n\nMy final conclusion is that if the commercial hardaware has to be made to classify the activities, the classifier to use is RandomForestClassifier and the Hardware should be designed to wear in hand.","49966cd4":"### SVC model without using PCA","8ce7dbcd":"It can be observed that the SVC model takes 12 mins to train the data with PCA approach","6649a7c2":"From the description of the train data, The mean Heart Rate is nearly $107\/min$ and the maximum is around $201\/min$. The maximum temperature is recorded in the chest at $38.5 ^\\circ C$ among hand chest and ankle. The mean acceleration is maximum in the ankle at $12.5 \\, m^2\/sec$ and mean angular velocity is maximum in hand at $1.56 \\, rad\/sec$.\n\n\nNow let's remove the `activity_id` , `SubjectID` and `timestamp` columns to visualize the distribution of the Heart rate and IMU sensor data.","ffb7b511":"The RandomForestModel has nearly perfect scores(accuracy = 99.87% ) by using all the sensor data as the input","91007b0c":"Now let's analyze different attributes individually","67d54253":"Again, the main take away from this table is that the all the sensor data except temperature is maximum for the activity rope jumping. Except acceleration of the ankle and temperature, all the sensor data is the least for the activity lying.","98be7d44":"Here I am doing the hypothesis on correlation, Hence i am using `spearmanr` method from `scipy.stats` module since the data is not normally distributed\n\n","82203e88":"We can find the resultant acceleration, angular velocity for hand, chest and ankle separately and make new columns and drop the individual acceleration and the angular velocity measurements in each axis. Also, the magnetic field measurement is not much useful if our aim is just to detect which activity the person is performing, because there are no activities which tampers with the magnetic field in the given set of activities, which means the magnetic field measurement just depends on the place which the person is performing the activity(Earth's Magnetic field) but not depended on the activity itself.\n\nThe resultant acceleration is given by\n\n* $a_{(res)} = \\sqrt {a_x^2 \\, +\\, a_y^2 \\,+\\, a_z^2}$\n\nand the resultant angular velocity is given by\n\n* $\\omega_{(res)} = \\sqrt {\\omega_x^2 \\, +\\, \\omega_y^2 \\,+\\, \\omega_z^2}$","10e2e336":"From the above hypothesis testing it is evident that the correlation between  angular velocity of the hand and the heart rate is +ve and is statistically significant.","a4195224":"From the above modelling using random forest model, we can say that if we place the hardware in the ankle it will have an accuracy of $89.61%$. Which is less than when hardware is placed at hand($92.18%$)","2859053b":"* From the above bar chart it is observed that physically non challenging activites have low angular velocity for each body part,except ironing, which has considerable mean angular acceleration in hand.\n\n* Running have high mean angular acceleration $\\approx 4.2\\, rad\/sec$ for both hand and ankle. Rope jumping has the highest mean hand angular acceleration $\\approx 4.5 \\, rad\/sec$ but with low ankle acceleration compared to the hand.\n\n* Descending stairs have much higher mean ankle acceleration than ascending","6226b9b9":"# Exploratory Data Analysis (EDA)","65077751":"From the above graph, we can see that both the lines meet for x = 3, which means that for our data we need 3 features to capture 94% of the variation","89b443e6":"After modelling we understood that we can have a good accuracy($92.18%$) for the model if the hardware is supposed to design to wear in hand using random forest model.","fced9ef3":"Also it takes 5 mins to test the data with PCA","366b3853":"With out doing dimensionality reduction with PCA, we get an accuracy of 80.72 percent, which is a very significant difference. \n\nThere for I am further not goint to use the PCA since PCA in this scenario is slowing down the model as well ans make the model give very poor result","973416f6":"# References\n\n1. Archive.ics.uci.edu. (2012). UCI Machine Learning Repository: PAMAP2 Physical Activity Monitoring Data Set. [online] Available at: http:\/\/archive.ics.uci.edu\/ml\/datasets\/pamap2+physical+activity+monitoring\n\n1. poseMethod Technique:Analysis of usain bolt's running technique Available at: https:\/\/posemethod.com\/usain-bolts-running-technique\/ \n\n1. world Jump Rope records Avalilable at:https:\/\/jumpropehub.com\/world-jump-rope-record\/\n\n1. Talk accelerometer Available at:https:\/\/en.wikipedia.org\/wiki\/Talk%3AAccelerometer.","3b2eeec7":"After removing the rows with missing HR values still we have some missing values in the other columns. This missing values can be dealt by interpolating the data with either 'nearest' or 'linear' method. Since frequency in which data is collected are high compared to the possible complex harmonic oscillation frequency of the body part during the vigourous body movements, either of the above method will be good for interpolating.\n\nAlso, I have kept the activities as it is documented on the 'performedActivitiesSummary.pdf' provided along with data source","a67988b2":"As expected, physically non challenging activities (lying,sitting,standing,ironing) have very low mean acceleration of different body parts. However physically challenging activities like running and rope jumping has considerably high mean acceleration value for ankle and hand. Also, activities with considerable leg movements like walking, Nordic walking,ascending and discending stairs have high ankle, cycling being an exception.\n\nThe chest acceleration is low for almost all activities except for rope jumping.","50495729":"#### Hypothesis testing 1)b\n\nIf angular velocity of the hand is higher for higher heart rate, then for higher angular velocity of the hand, the Heart rate will be higher.\n\nNull Hypothesis\n* $H0$: correlation = 0\n\nAlternative Hypothesis\n* $H1$: correlation > 0\n\n\nHere also I am using `spearmanr` method for the hypothesis testing since the data are not normally distributed","15175b95":"From both this hypothesis testing we can come to a conclusion that, generally for higher angualr velocity of the limbs of a person (ie  more  the vigour  of hand and the leg movement),The heart rate of the person will be higher.","941e2a9f":"For gaining insights from the data, Let us further analyze the data. For that, the data is further split into test and train data. We will do the EDA on train data and will do the hypothesis testing on the test data.","35e5d856":"So from the above observation, we can say that removing the temperature sensor decreases the efficiency of the model to correctly classify the activities.\n\nSo, I the use of temperature sensor is mandatory in the hardware.","d3fa6268":"Now since we are trying to develope a hardware which can classify the activities, wearing sensors in every part of the body is not practical.So we should fit the device either in the hand or the ankle.If we are only looking at the convenience between these two positions,it should be placed in the hand.\n\nHowever, we should still check if there is much difference in accuracy between both the positons.","194c02e1":"Hence I recommend the hardwear to be designed in such a way that it can be wear in the hand of the person","6053e168":"## Modelling\n\nOur aim is to help develop a hardware\/software for detecting the activity performed by a person. For that we have to develop and test some model, which can be used to predict the activity performed by the person given the sensor data\n","bc40a871":"From the abouve boxplot, it can be observed that, the varience of the temperature is maximum for the rope jumping(activity 24)and the least for vaccum cleaning(activity 16). The temperature variation is less for ironing also(activity 17)","13be05bd":"It should be noted that all the sensory data mean values are highest for subject ID 9 except temperature data, with a very high mean heart rate of $148.46 \\,  bpm$. But this information is highly biased since the subject 9 has only done one protocol activity which is rope jumping. If we consider only rope jumping other candidates also have similar heart rates.","697bd2ef":"Now we can see that the SVC model has taken only 8 mins to fit and train the model.And it is 33% faster than when we applied the PCA! This is an unexpected observation.","3acc59cf":"While doing the training and testing, it might take lot of time for the model to perform it since the number of features is high. However we can get the help of PCA(principle component analysis) to project and reduce the dimetion of the features and hence the train and test time might be reduced.\n\n","eb3186e7":"From the above bar chart it is evident that for physically easy activities (for a normal human) like sitting, lying, standing and ironing, the heart rates average is on the lower spectrum, close to the normal heart rate of $72 \\,bpm$. However, for slightly physically challenging activities like cylcing, Nordic Walking, ascending and descending stairs have an average heart rate over $120 \\, bpm$. For heavy activities indulging in vigourous movement of body parts like running and rope jumping the average heart rate is over $150 \\,bpm$. \n\nAmong all the 12 activities, rope jumping has the highest heart rate($160 \\, bpm$) and lying has the least average heart rate ($75 \\, bpm$).","bacd6184":"From the above data Frame, it is evident that the temperature mean is maximum for vaccum cleaning, may be beacuse of the hot air emitted by the machine. All the other activities which are physically not challenging has similar mean temperature.\n\nIt is interesting to note that for activities including vigourous movement of the hand, the hand temperature is much lesser compared to other activities.\n\n1. Rope jumping : $29.75^\\circ C$\n1. Running: $30.79^\\circ C$\n1. Cycling: $30.99^\\circ C$\n\n\nThe possible reason for this observation might be because of the high air(normal temperature,unlike in vaccum cleaning)movement wrt the hand while doing these activities and that might have caused high heat carrying rate from the hand by the air","5f746ccf":"To find the correlation we have to use the **Spearman** correlation method as most of the sensor data distribution is not following normal distribution.","85bcd31c":"Now let us find out the correleation between all the sensor data.","bb6af084":"* From the above correlation data frame it can be observed that, there is a high correlation between the all the  angular velocity measurements(hand,chest and the ankle) is highly correlated with the heart rate.\n\n* Also another interesting obesrvation is that the Heart rate  is negatively correlelated wth the hand temperature($-0.35$).\n\n* All the temperature measurements are highly positively correlated with each other.\n\n* All the angular velocity measurements are hightly positively correlerated with each other\n\n* However, even though the acceleration values are positively correlated to each other, it is not significant positive correlations.\n","42ac22bd":"Most of the attributes have non - normal distribution. However since the sample size is high(for test data also), we can confidently perform a t-test later. There appears to be outliers in the hand temperature data set, however since the data is entered by the sensors, there might be chance that it is related to some specific activity, because of which I am not removing those outliers. The mean of the acceleration values is around $9.81$ , which accounts to the fact that  accelerometer measures the value of accelertion due to gravity at rest, which is around $9.81$ https:\/\/en.wikipedia.org\/wiki\/Talk%3AAccelerometer.\n\nAlso the mode of gyroscope data is around $0$, indicating that the angular acceleration of the body parts are close to zero majority of the time.","7340e54b":"## Hypothesis testing\n\n#### Hypothesis testing 1a)\n\nIf angular velocity of the ankle is higher for higher Heart Rate, then for higher angular velocity of the ankle the Heart Rate should be Higher\n\nNull Hypothesis\n* $H0$: Correlation = 0\n\nAlternate Hypothesis\n* $H1$: Correleation> 0","c8dc70db":"As mentioned in the data source, the Heart Rate monitor has a frequency of $\\approx$ 9hz and the IMU(Inertial Measuring Devices) has a frequency of $\\approx$ 100Hz. Which means that $\\approx$ 90% of the data we collected wont have the Heart Rate measurement in it. However, do we really require this 90% data in which the Heart rate is not measured?, no we don't! Because among the 12 activities given, running and rope jumping are the most vigorous activities and 9Hz is still enough to capture all the variation of IMU data(acceleration oscillations and the angular velocity oscillations) since the fastest runner in the world uses less than 4 oscillations of his hands and ankles per second https:\/\/posemethod.com\/usain-bolts-running-technique\/ and the fastest skipper in the world uses less than 7 oscillations per second https:\/\/jumpropehub.com\/world-jump-rope-record\/ and also still we have enough data even with 9hz frequency.\n\nSo we can safely disregard the data without the heart rate measurement, ie making the time step to almost 0.1 second instead of time step 0.01. There might be only very small amount of other possible missing of Heart Rate measurement because the missing values are almost 90% of the data $(\\frac{2610265}{2872533})\\times100$, which indicates that we can again safely disregard the missing data.\n\n","49ecbaf2":"Since there is  chance of mislabelling of data during the period of transitioning between one activity to other activity, and also since it takes some time to increase the body temperature and Heart rate to rise, let us remove \u00b1 5 seconds in the data during the transition from one activity to another","e89b7cf1":"Still we have very high score (accuracy = 99.82%) very slightly less than using all the sensors. But we can observe from the confusion matrix that many of the rope jumping activity is now being classified as running without the presence of gyroscope sensor data.\n\nSo if a person is much more physically active then it is not a good idea to avoid the gyroscope sensor as it will mislabel the heavy activities\n\nHowever if the person doesnt do much of heavy activities which involves rigourous limb movements, We dont have to implement the gyroscope in the hardware","225ace78":"### Hardware placed on Hand","ade98265":"By using Accelerometer, Heart Rate measuring device and Gyroscope and temperature measurement","387b8f17":"### Without using temperature sensor","85b3b256":"### Hardware placed on ankle","09638554":"Here now I am removing the data from accelerometer with scale: \u00b16g, because due to high impacts caused\nby certain movements (e.g. during running) with acceleration over 6g, it gets saturated sometimes. Instead we can use  data from accelerometer with the scale: \u00b116g. Also I am removing the orientation data as it is not useful to predict the activities.","96a5d032":"As we have done significant Exploratory data anlaysis, let us now test our hypothesis.","12029d9c":"# Introduction\n\nThe goal of this project is to help develop hardware and\/or software which can determine the type of physical activity carried out by an individual and to get actionable insights by using PAMAP2 Physical Activity Monitoring dataset http:\/\/archive.ics.uci.edu\/ml\/datasets\/pamap2+physical+activity+monitoring  \n\nIt contains data of 18 different physical activities (such as walking, cycling, playing soccer etc) performed by 9 subjects wearing 3 inertial measurement units (IMU) and a heart rate monitor. This data is stored in individual text files per subject. Each row in each file represents one reading and contains 54 attributes (including timestamp, activity ID, heart rate and IMU sensory data). Among 18 phyiscal activities only 12 activities are protocol activities and we will be focusing only on this 12 activities and our final aim will be to find a suitable machine learning model to predict which type of physical activity a person is doing among this 12 activities\n\nThe whole project is classified into 3 major sections\n\n1. Data Loading, Cleaning and performing Exploritory Data Analysis.\n1. Hypothesis testing for relationship between attributes.\n1. Supervised machine learning modelling to predict the activity performed by the person.","c07efa3a":"From the above hypothesis testing it is evident that the correlation between the parameters heart rate and angular velocity of the ankle is +vely correlated and the correlation is statistically significant.","a4faa057":"#### Angular velocity analysis","b34489a1":"By using Heart Rate monitor and Accelerometer and temperature measurement \n\n","e1c1b90a":"#### Acceleration analysis","16196c50":"Here by using SVM model with PCA we get very low scores. Let us check if it is because of the implementation of the PCA"}}