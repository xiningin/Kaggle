{"cell_type":{"17cdf578":"code","3c1124ff":"code","a9cd22e0":"code","253657ae":"code","75c05f94":"code","a9964a22":"code","0b11f7a0":"code","2df351b1":"code","eb7ccd82":"code","853e64d1":"code","9d93948e":"code","5562b8b4":"code","5ffa710d":"code","986b3297":"code","a0a50e85":"code","a2e77aef":"code","31bac7b8":"code","dc4e91c6":"code","d9a76f8d":"code","42142a01":"code","d2e5449d":"code","f2b24a52":"code","ef479f52":"code","32afbcec":"markdown","1d29897a":"markdown","d8f20682":"markdown","5579ae53":"markdown","56a41ed1":"markdown"},"source":{"17cdf578":"import pandas as pd\n\ngl = pd.read_csv('..\/input\/game_logs.csv', low_memory=False)\ngl.head()","3c1124ff":"# set the memory_usage parameter to 'deep' to get an accurate number\n\ngl.info(memory_usage='deep')","a9cd22e0":"# the average memory usage for data type\nfor dtype in ['float','int','object']:\n    selected_dtype = gl.select_dtypes(include=[dtype])\n    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n    mean_usage_mb = mean_usage_b \/ 1024 ** 2\n    print(\"Average memory usage for {} columns: {:03.2f} MB\".format(dtype,mean_usage_mb))","253657ae":"# the minimum and maximum values for each integer subtype\n\nimport numpy as np\nint_types = [\"uint8\", \"int8\", \"int16\"]\nfor it in int_types:\n    print(np.iinfo(it))","75c05f94":"\n# select only the integer columns\n# optimize the types \n# compare the memory usage\n\n\ndef mem_usage(pandas_obj):\n    if isinstance(pandas_obj,pd.DataFrame):\n        usage_b = pandas_obj.memory_usage(deep=True).sum()\n    else: # \u0438\u0441\u0445\u043e\u0434\u0438\u043c \u0438\u0437 \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u043e \u0442\u043e\u043c, \u0447\u0442\u043e \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435 DataFrame, \u0442\u043e \u044d\u0442\u043e Series\n        usage_b = pandas_obj.memory_usage(deep=True)\n    usage_mb = usage_b \/ 1024 ** 2 # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0431\u0430\u0439\u0442\u044b \u0432 \u043c\u0435\u0433\u0430\u0431\u0430\u0439\u0442\u044b\n    return \"{:03.2f} MB\".format(usage_mb)\n\ngl_int = gl.select_dtypes(include=['int'])\nconverted_int = gl_int.apply(pd.to_numeric,downcast='unsigned')\n\nprint(mem_usage(gl_int))\nprint(mem_usage(converted_int))\n\ncompare_ints = pd.concat([gl_int.dtypes,converted_int.dtypes],axis=1)\ncompare_ints.columns = ['before','after']\ncompare_ints.apply(pd.Series.value_counts)","a9964a22":"# with float columns\n\ngl_float = gl.select_dtypes(include=['float'])\nconverted_float = gl_float.apply(pd.to_numeric,downcast='float')\n\nprint(mem_usage(gl_float))\nprint(mem_usage(converted_float))\n\ncompare_floats = pd.concat([gl_float.dtypes,converted_float.dtypes],axis=1)\ncompare_floats.columns = ['before','after']\ncompare_floats.apply(pd.Series.value_counts)","0b11f7a0":"# create a copy of original dataframe\n# assign optimized numeric columns in place of the originals\n# see what overall memory usage is now\n\noptimized_gl = gl.copy()\n\noptimized_gl[converted_int.columns] = converted_int\noptimized_gl[converted_float.columns] = converted_float\n\nprint(mem_usage(gl))\nprint(mem_usage(optimized_gl))","2df351b1":"# looking at individual strings\n# looking items in a pandas series\n\nfrom sys import getsizeof\n\ns1 = 'working out'\ns2 = 'memory usage for'\ns3 = 'strings in python is fun!'\ns4 = 'strings in python is fun!'\n\nfor s in [s1, s2, s3, s4]:\n    print(getsizeof(s))","eb7ccd82":"obj_series = pd.Series(['working out',\n                          'memory usage for',\n                          'strings in python is fun!',\n                          'strings in python is fun!'])\nobj_series.apply(getsizeof)","853e64d1":"# the number of unique values of each of object types\n\ngl_obj = gl.select_dtypes(include=['object']).copy()\ngl_obj.describe()","9d93948e":"# convert to categorical\n\ndow = gl_obj.day_of_week\nprint(dow.head())\n\ndow_cat = dow.astype('category')\nprint(dow_cat.head())","5562b8b4":"# return the integer values the category type uses to represent each value\n\ndow_cat.head().cat.codes","5ffa710d":"# memory usage for this column before and after converting\n\nprint(mem_usage(dow))\nprint(mem_usage(dow_cat))","986b3297":"# iterate over each object column\n# if the number of unique values is less than 50% - convert it to the category type\n\nconverted_obj = pd.DataFrame()\n\nfor col in gl_obj.columns:\n    num_unique_values = len(gl_obj[col].unique())\n    num_total_values = len(gl_obj[col])\n    if num_unique_values \/ num_total_values < 0.5:\n        converted_obj.loc[:,col] = gl_obj[col].astype('category')\n    else:\n        converted_obj.loc[:,col] = gl_obj[col]","a0a50e85":"print(mem_usage(gl_obj))\nprint(mem_usage(converted_obj))\n\ncompare_obj = pd.concat([gl_obj.dtypes,converted_obj.dtypes],axis=1)\ncompare_obj.columns = ['before','after']\ncompare_obj.apply(pd.Series.value_counts)","a2e77aef":"# combine this with the rest \n\noptimized_gl[converted_obj.columns] = converted_obj\n\nmem_usage(optimized_gl)","31bac7b8":"# use datetime for the first column of data set\n\ndate = optimized_gl.date\nprint(mem_usage(date))\ndate.head()","dc4e91c6":"# convert \n\noptimized_gl['date'] = pd.to_datetime(date,format='%Y%m%d')\n\nprint(mem_usage(optimized_gl))\noptimized_gl.date.head()","d9a76f8d":"# apply memory-saving techniques when can't even create the dataframe in the first place\n# specify the optimal column types when read the data set in\n\n\ndtypes = optimized_gl.drop('date',axis=1).dtypes\n\ndtypes_col = dtypes.index\ndtypes_type = [i.name for i in dtypes.values]\n\ncolumn_types = dict(zip(dtypes_col, dtypes_type))\n\n# rather than print all 161 items, we'll\n# sample 10 key\/value pairs from the dict\n# and print it nicely using prettyprint\n\npreview = first2pairs = {key:value for key,value in list(column_types.items())[:10]}\nimport pprint\npp = pp = pprint.PrettyPrinter(indent=4)\npp.pprint(preview)\n","42142a01":"#  to read in the data with the correct types in a few lines\n\nread_and_optimized = pd.read_csv('..\/input\/game_logs.csv',dtype=column_types,parse_dates=['date'],infer_datetime_format=True)\n\nprint(mem_usage(read_and_optimized))\nread_and_optimized.head()","d2e5449d":"import matplotlib.pyplot as plt","f2b24a52":"# the distribution of game days.\n\noptimized_gl['year'] = optimized_gl.date.dt.year\ngames_per_day = optimized_gl.pivot_table(index='year',columns='day_of_week',values='date',aggfunc=len)\ngames_per_day = games_per_day.divide(games_per_day.sum(axis=1),axis=0)\n\nax = games_per_day.plot(kind='area',stacked='true')\nax.legend(loc='upper right')\nax.set_ylim(0,1)\nplt.show()","ef479f52":"# how game length has varied over the years\n\ngame_lengths = optimized_gl.pivot_table(index='year', values='length_minutes')\ngame_lengths.reset_index().plot.scatter('year','length_minutes')\nplt.show()","32afbcec":"I created this kernal while I was reading the article \"[Tutorial: Using pandas with Large Data Sets](https:\/\/www.dataquest.io\/blog\/pandas-big-data\/)\"","1d29897a":"### 98% reduction","d8f20682":"- date \u2014 Date of the game.\n- v_name \u2014 Visiting team name.\n- v_league \u2014 Visiting team league.\n- h_name \u2014 Home team name.\n- h_league \u2014 Home team league.\n- v_score \u2014 Visiting team score.\n- h_score \u2014 Home team score.\n- v_line_score \u2014 Visiting team line score, eg 010000(10)00.\n- h_line_score \u2014 Home team line score, eg 010000(10)0X.\n- park_id \u2014 ID of the park where the game was held.\n- attendance\u2014 Game attendance","5579ae53":"### reduced the memory usage of the dataframe by 7%","56a41ed1":"### reduction of 93%"}}