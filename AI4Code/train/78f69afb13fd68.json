{"cell_type":{"932f20de":"code","f5968100":"code","3d7a73dc":"code","ff5cf6e5":"code","fdc394af":"code","10c778d2":"code","6871ad27":"code","e3874b1e":"code","1950f673":"code","d6f2bda3":"code","0ce5039e":"code","9866c873":"code","ddc9a64d":"code","cf9bd2b5":"code","b70c0a6d":"code","4227d4e7":"code","d217ea42":"code","4e415e08":"code","da0bdf9a":"code","0ecb88d9":"code","9b1ac5b5":"code","d80e3d7b":"code","6570a46c":"code","607f3d5a":"code","ae2f490a":"code","efd6fd7c":"code","d6de176b":"code","1cf321fe":"code","ee79ebbc":"code","aa6db993":"code","27b827c8":"code","292a0d41":"code","fb0455cb":"code","3d30d0f6":"code","6164cb08":"code","3d63736c":"code","d3505756":"code","a8d14752":"code","95b17339":"code","49ddb908":"code","523e14ca":"code","ea4df94c":"code","661475c7":"code","d1cd6049":"code","7584437b":"code","1349bf60":"code","0c225c82":"code","80b7ebaa":"code","f36dcf16":"markdown","bb747ce1":"markdown","c17e5348":"markdown","040b17fe":"markdown","41840827":"markdown","1fdd2e56":"markdown","1b10f5da":"markdown","0699857d":"markdown","f3277cd2":"markdown","6b358f9e":"markdown","d0cc1cb9":"markdown","b9c0e5e0":"markdown","8df3523f":"markdown","89641387":"markdown","8df69107":"markdown","8de42396":"markdown","9aaa20b8":"markdown","2394f75f":"markdown","2e8476c9":"markdown","349a1664":"markdown","4ff62e3d":"markdown","7f39f6e3":"markdown","aa972e39":"markdown","81bb36ad":"markdown","7fb04697":"markdown","a5485af5":"markdown","08103b25":"markdown","f5e2a422":"markdown","2f7ef880":"markdown","2419c4a5":"markdown","bb434f5c":"markdown","3333bf74":"markdown","5de24686":"markdown","281591e3":"markdown","3c435a87":"markdown"},"source":{"932f20de":"# Libraries used\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nfrom numpy.random import seed\n\nseed(11111)","f5968100":"# Reading\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n# Putting on index to each dataset before split it\ntrain = train.set_index(\"PassengerId\")\ntest = test.set_index(\"PassengerId\")\n\n# dataframe \ndf = pd.concat([train, test], axis=0, sort=False)\n\ndf","3d7a73dc":"df.info()","ff5cf6e5":"df.isna().sum()","fdc394af":"# Sex\nchange = {'female':0,'male':1}\ndf.Sex = df.Sex.map(change)\n\n# Embarked\nchange = {'S':0,'C':1,'Q':2}\ndf.Embarked = df.Embarked.map(change)","10c778d2":"columns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=df, x=feature, hue='Survived', palette='Paired')\n    \nsns.despine()","6871ad27":"columns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=df, x=feature, hue='Sex', palette='BrBG')\n    \nsns.despine()","e3874b1e":"corr_df = df.corr()\nfig, axs = plt.subplots(figsize=(8, 6))\nsns.heatmap(corr_df).set_title(\"Correlation Map\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});","1950f673":"df.groupby(['Pclass','Sex','Survived'])['Age'].median()","d6f2bda3":"#Filling the missing values with mean of Pclass and Sex.\ndf[\"Age\"].fillna(df.groupby(['Pclass','Sex'])['Age'].transform(\"mean\"), inplace=True)","0ce5039e":"fig, axs = plt.subplots(figsize=(10, 5))\nsns.histplot(data=df, x='Age').set_title(\"Age distribution\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","9866c873":"auxage = pd.cut(df['Age'], 4)\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x=auxage, hue='Survived', data=df).set_title(\"Age Bins\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","ddc9a64d":"# converting to categorical\ndf['Age'] = LabelEncoder().fit_transform(auxage) ","cf9bd2b5":"pd.crosstab(df['Age'], df['Survived'])","b70c0a6d":"df[\"Fare\"].fillna(df.groupby(['Pclass', 'Sex'])['Fare'].transform(\"median\"), inplace=True)","4227d4e7":"auxfare = pd.cut(df['Fare'],5)\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x=auxfare, hue='Survived', data=df).set_title(\"Fare Bins\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","d217ea42":"df['Fare'] = LabelEncoder().fit_transform(auxfare) ","4e415e08":"pd.crosstab(df['Fare'], df['Survived'])","da0bdf9a":"print(\"mean of embarked\",df.Embarked.median())\n\ndf.Embarked.fillna(df.Embarked.median(), inplace = True)","0ecb88d9":"print(\"Percentage of missing values in the Cabin column :\" ,round(df.Cabin.isna().sum()\/ len(df.Cabin)*100,2))","9b1ac5b5":"df.drop(['Cabin'], axis = 1, inplace = True)","d80e3d7b":"df['Title'] = df.Name.str.extract('([A-Za-z]+)\\.', expand = False)","6570a46c":"df.Title.value_counts()","607f3d5a":"least_occuring = ['Rev','Dr','Major', 'Col', 'Capt','Jonkheer','Countess']\n\ndf.Title = df.Title.replace(['Ms', 'Mlle','Mme','Lady'], 'Miss')\ndf.Title = df.Title.replace(['Countess','Dona'], 'Mrs')\ndf.Title = df.Title.replace(['Don','Sir'], 'Mr')\n\ndf.Title = df.Title.replace(least_occuring,'Rare')\n\ndf.Title.unique()","ae2f490a":"pd.crosstab(df['Title'], df['Survived'])","efd6fd7c":"df['Title'] = LabelEncoder().fit_transform(df['Title']) ","d6de176b":"# I got the total number of each family adding SibSp and Parch. (1) is the same passenger.\ndf['FamilySize'] = df['SibSp'] + df['Parch']+1\ndf.drop(['SibSp','Parch'], axis = 1, inplace = True)","1cf321fe":"fig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x='FamilySize', hue='Survived', data=df).set_title(\"Raw Column\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","ee79ebbc":"# Binning FamilySize column\ndf.loc[ df['FamilySize'] == 1, 'FamilySize'] = 0                            # Alone\ndf.loc[(df['FamilySize'] > 1) & (df['FamilySize'] <= 4), 'FamilySize'] = 1  # Small Family \ndf.loc[(df['FamilySize'] > 4) & (df['FamilySize'] <= 6), 'FamilySize'] = 2  # Medium Family\ndf.loc[df['FamilySize']  > 6, 'FamilySize'] = 3                             # Large Family ","aa6db993":"fig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x='FamilySize', hue='Survived', data=df).set_title(\"Variable Bined\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nsns.despine()","27b827c8":"df['Ticket'] = df.Ticket.str.split().apply(lambda x : 0 if x[:][-1] == 'LINE' else x[:][-1])","292a0d41":"df.Ticket = df.Ticket.values.astype('int64')","fb0455cb":"df['LastName'] = last= df.Name.str.extract('^(.+?),', expand = False)","3d30d0f6":"df['WomChi'] = ((df.Title == 0) | (df.Sex == 0))","6164cb08":"family = df.groupby([df.LastName, df.Pclass, df.Ticket]).Survived\n\ndf['FTotalCount'] = family.transform(lambda s: s[df.WomChi].fillna(0).count())\ndf['FTotalCount'] = df.mask(df.WomChi, (df.FTotalCount - 1), axis=0)\n\ndf['FSurvivedCount'] = family.transform(lambda s: s[df.WomChi].fillna(0).sum())\ndf['FSurvivedCount'] = df.mask(df.WomChi, df.FSurvivedCount - df.Survived.fillna(0), axis=0)\n\ndf['FSurvivalRate'] = (df.FSurvivedCount \/ df.FTotalCount.replace(0, np.nan))","3d63736c":"df.isna().sum()","d3505756":"# filling the missing values\ndf.FSurvivalRate.fillna(0, inplace = True)\ndf.FTotalCount.fillna(0, inplace = True)\ndf.FSurvivedCount.fillna(0, inplace = True)","a8d14752":"# You can review the result Family Survival Rate with these Families Heikkinen, Braund, Rice, Andersson,\n# Fortune, Asplund, Spector,Ryerson, Allison, Carter, Vander, Planke\n\ndf[df['LastName'] == \"Dean\"]","95b17339":"df['PassengerId'] = df.index","49ddb908":"df = pd.get_dummies(df, columns=['Sex','Fare','Pclass'])","523e14ca":"df.drop(['Name','LastName','WomChi','FTotalCount','FSurvivedCount','Embarked','Title'], axis = 1, inplace = True)","ea4df94c":"df.columns","661475c7":"# I splitted df to train and test\ntrain, test = df.loc[train.index], df.loc[test.index]\n\nX_train = train.drop(['PassengerId','Survived'], axis = 1)\nY_train = train[\"Survived\"]\ntrain_names = X_train.columns\n\nX_test = test.drop(['PassengerId','Survived'], axis = 1)","d1cd6049":"corr_train = X_train.corr()\nfig, axs = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr_train).set_title(\"Correlation Map\",fontdict= { 'fontsize': 20, 'fontweight':'bold'});\nplt.show()","7584437b":"# Scaler\nX_train = StandardScaler().fit_transform(X_train)\nX_test = StandardScaler().fit_transform(X_test)","1349bf60":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_predDT = decision_tree.predict(X_test)\n\nprint(\"Accuracy of the model: \",round(decision_tree.score(X_train, Y_train) * 100, 2))","0c225c82":"importances = pd.DataFrame(decision_tree.feature_importances_, index = train_names)\nimportances.sort_values(by = 0, inplace=True, ascending = False)\nimportances = importances.iloc[0:6,:] \n\nplt.figure(figsize=(8, 5)) \nsns.barplot(x=0, y=importances.index, data=importances,palette=\"deep\").set_title(\"Feature Importances\",\n                                                                                 fontdict= { 'fontsize': 20,\n                                                                                            'fontweight':'bold'});\nsns.despine()","80b7ebaa":"submit = pd.DataFrame({\"PassengerId\":test.PassengerId, 'Survived':Y_predDT.astype(int).ravel()})\nsubmit.to_csv(\"submissionJavier_Vallejos.csv\",index = False)","f36dcf16":"Let's binning the columns to process it the best way.","bb747ce1":"### 1.1. Missing Values","c17e5348":"### 1.5. Cabin column","040b17fe":"The following figure show us numeric columns vs Survived column to know the behavior. In the last fig (3,3) you can see that we are working with unbalanced dataset. ","41840827":"# 5. References","1fdd2e56":"This column has many missing values and thats the reason I dropped it.","1b10f5da":"The easy way to impute the missing values is with mean or median on base its correlation with other columns. Below you can see the correlation beetwen variables, Pclass has a good correlation with Age, but I also added Sex column to impute missing values.","0699857d":"# 2. Feature Extraction","f3277cd2":"To visualize better the columns we will transform the Sex and Embarked columns to numeric. Sex column only has two categories Female and Male, Embarked column has tree labels S, C and Q.","6b358f9e":"### 1.2. Age column","d0cc1cb9":"The four titles most ocurring are Mr, Miss, Mrs and Master. ","b9c0e5e0":"Here, I reviewed the variables, impute missing values, found patterns and watched relationship between columns.","8df3523f":"### 2.4. Woman or Child column","89641387":"# Titanic Disaster\n## Improve your score to 82.78% (Top 3%) \n\nIn this work I have used some basic techniques to process of the easy way Titanic dataset. ","8df69107":"Here, I created a new column to know if the passenger is woman a child, I selected the Title parameter because most of children less than 16 years have the master title.","8de42396":"## 2.1. SibSp and Parch column","9aaa20b8":"To get a better model,I got the Last Name of each passenger.","2394f75f":"# 4. Conclutions","2e8476c9":"### 2.3. Name Column","349a1664":"* [Advanced Feature Engineering Tutorial](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)\n* [Top 5% Titanic: Machine Learning from Disaster](https:\/\/www.kaggle.com\/kpacocha\/top-5-titanic-machine-learning-from-disaster)\n* [Titanic - Top score : one line of the prediction](https:\/\/www.kaggle.com\/vbmokin\/titanic-top-score-one-line-of-the-prediction?scriptVersionId=42197143&select=survived.csv)\n* [Titanic survival prediction from Name and Sex](https:\/\/www.kaggle.com\/mauricef\/titanic)\n* [Titanic Dive Through: Feature scaling and outliers](https:\/\/www.kaggle.com\/allunia\/titanic-dive-through-feature-scaling-and-outliers)\n* [Titanic (Top 20%) with ensemble VotingClassifier](https:\/\/www.kaggle.com\/amiiiney\/titanic-top-20-with-ensemble-votingclassifier#5--Machine-Learning)\n* [Titanic Survival Rate](https:\/\/www.kaggle.com\/prakharrathi25\/titanic-survival-rate#Titanic-Survival-Prediction)\n","4ff62e3d":"### 2.2. Ticket column","7f39f6e3":"There are three columns with missing values (Age, Fare and Cabin) and Survived column has NaNs because the Test dataset doesn't have that information.   ","aa972e39":"### 1.4. Embarked column","81bb36ad":"Has two missing values.","7fb04697":"# 3. Modeling","a5485af5":"# 1. Preprocessing and EDA","08103b25":"### 2.4 Family Survived Rate column","f5e2a422":"### 1.3. Fare column","2f7ef880":"In this part I have used the Name column to extract the Title of each person.","2419c4a5":"Reading the dataset and merging Train and Test to get better results.","bb434f5c":"Fare has only one missing value and I imputed with the median or moda","3333bf74":"With the following lambda function I got the ticket's number and I changed the LINE ticket to zero.","5de24686":"In this part I created three new columns FTotalCount, FSurviviedCount and FSurvivalRate, the F is of Family.  FTotalCount uses a lambda function to count of the WomChi column on base of LastName, PClass and Ticked  detect families and then subtract the same passanger with a boolean process the passenger is woman or child. FSurvivedCount also uses a lambda function to sum WomChi column and then with mask function filters if the passenger is woman o child subtract the state of survival, and the last FSurvivalRate only divide FSurvivedCount and FTotalCount.\n","281591e3":"As you can see Name, Sex, Ticket, Cabin, and Embarked column are objects, before processing each column we should know if there are NAs or missing values.","3c435a87":"This report is part of a bootcamp of Data Science, and as you can see I achieved to be on the Top 3%. In the fist part I did an analysis to visualize each column and impute their missing values. After that I applied feature engineering to extract the title, last name of the Name column and Family Size is the adding of SibSp and Parch plus one that means the same passenger. Age and Fare columns have been Binning to get better results. To get Family Survival Rate is base on two rules:\n\n1. All males die except boys in families where all females and boys live.\n2. All females live except those in families where all females and boys die.\n\nWith rules above you can get an score near to 81% but if you add the ticket number and other changes that I did you can improve it to 82.78% on Kaggle leaderboard.\n\nTo the model part I used only Desicion tree because is the easy way to getting this score.\n\nFinally, if you want to increase your score, then I suggest you read this [work](https:\/\/www.kaggle.com\/cdeotte\/titanic-wcg-xgboost-0-84688). and like Chris Deotte said in his [post](https:\/\/www.kaggle.com\/c\/titanic\/discussion\/57447) this is the fist step to improve your score. \n\n"}}