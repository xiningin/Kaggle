{"cell_type":{"58160407":"code","153ffa79":"code","bd7a1383":"code","13c0a865":"code","84711f91":"code","5868b40f":"code","9a276164":"code","04ef46e4":"code","36efa76f":"code","81934b56":"code","19062987":"code","0987a0bd":"code","db08cc7a":"code","86e5e068":"code","b9d4f782":"code","426d1d26":"code","a787cb7c":"code","e5e15136":"code","bc3df115":"code","df62dd57":"code","45fe74e0":"code","c3293908":"code","5a5c50ba":"code","75360d69":"code","08ffb514":"code","9446c032":"code","2fb7822e":"code","a98725f2":"markdown","0ff48327":"markdown","c664cde1":"markdown","23c91b9b":"markdown","bd368114":"markdown","8c82e6a4":"markdown","39ef2b1b":"markdown","df910a67":"markdown","cb677b3c":"markdown","75a4ed35":"markdown","d8d1e746":"markdown","e1b6e2ee":"markdown","0cf5171f":"markdown","91be8fa6":"markdown","2a454417":"markdown","2bf606e3":"markdown","03afa4be":"markdown","f96f0fb3":"markdown","63baf241":"markdown"},"source":{"58160407":"\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport gc\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport missingno","153ffa79":"train=pd.read_csv('..\/input\/learn-together\/train.csv')\ntest=pd.read_csv('..\/input\/learn-together\/test.csv')\nsample_submission=pd.read_csv('..\/input\/learn-together\/sample_submission.csv')","bd7a1383":"X_train=train.copy()\nx_test=test.copy()","13c0a865":"X_train['Euclidean_distance_to_hydrology']=(X_train.Horizontal_Distance_To_Hydrology**2+X_train.Vertical_Distance_To_Hydrology**2)**(1\/2)\nx_test['Euclidean_distance_to_hydrology']=(x_test.Horizontal_Distance_To_Hydrology**2 + x_test.Vertical_Distance_To_Hydrology**2)**(1\/2)","84711f91":"X_train['interaction_9amnoon']=X_train.Hillshade_9am*X_train.Hillshade_Noon\nx_test['interaction_9amnoon']=x_test.Hillshade_9am*test.Hillshade_Noon","5868b40f":"X_train['Cosine_slope']=pd.DataFrame(np.cos(X_train.Slope))\nx_test['Cosine_slope']= pd.DataFrame(np.cos(x_test.Slope))","9a276164":"X_train['Canteral_family']=X_train['Soil_Type1']\nx_test['Canteral_family']=x_test['Soil_Type1']\n\nX_train['Ratake_family'] = np.where((X_train['Soil_Type2'] ==1) | (X_train['Soil_Type4'] == 1), 1, 0)\nx_test['Ratake_family'] = np.where((x_test['Soil_Type2'] ==1) | (x_test['Soil_Type4'] == 1), 1, 0)\n\nX_train['Vanet_family'] = np.where((X_train['Soil_Type5'] ==1) , 1, 0)\nx_test['Vanet_family'] = np.where((x_test['Soil_Type5'] ==1) , 1, 0)\n\nX_train['Wetmore_family'] = np.where((X_train['Soil_Type6'] ==1) , 1, 0)\nx_test['Wetmore_family'] = np.where((x_test['Soil_Type6'] ==1) , 1, 0)\n\nX_train['Limber_family'] = np.where((X_train['Soil_Type8'] ==1) , 1, 0)\nx_test['Limber_family'] = np.where((x_test['Soil_Type8'] ==1) , 1, 0)\n\nX_train['Troutwill_family'] = np.where((X_train['Soil_Type9'] ==1) , 1, 0)\nx_test['Troutwill_family'] = np.where((x_test['Soil_Type9'] ==1) , 1, 0)\n\nX_train['Catamount_family'] = np.where((X_train['Soil_Type10'] ==1) | (X_train['Soil_Type11'] == 1) | (X_train['Soil_Type13'] == 1) | (X_train['Soil_Type26'] == 1) |\n                                       (X_train['Soil_Type28'] == 1) | (X_train['Soil_Type31'] == 1) | (X_train['Soil_Type32'] == 1) | (X_train['Soil_Type33'] == 1), 1, 0)\nx_test['Catamount_family'] = np.where((x_test['Soil_Type10'] ==1) | (x_test['Soil_Type11'] == 1) | (x_test['Soil_Type13'] == 1) | (x_test['Soil_Type26'] == 1) |\n                                       (x_test['Soil_Type28'] == 1) | (x_test['Soil_Type31'] == 1) | (x_test['Soil_Type32'] == 1) | (x_test['Soil_Type33'] == 1), 1, 0)\n\nX_train['Legualt_family'] = np.where((X_train['Soil_Type12'] ==1) | (X_train['Soil_Type29'] == 1) | (X_train['Soil_Type30']), 1, 0)\nx_test['Legualt_family'] = np.where((x_test['Soil_Type12'] ==1) | (x_test['Soil_Type29'] == 1) | (x_test['Soil_Type30']), 1, 0)\n\nX_train['Gateview_family'] = np.where((X_train['Soil_Type17'] ==1) , 1, 0)\nx_test['Gateview_family'] = np.where((x_test['Soil_Type17'] ==1) , 1, 0)\n\nX_train['Rogert_family'] = np.where((X_train['Soil_Type18'] ==1) , 1, 0)\nx_test['Rogert_family'] = np.where((x_test['Soil_Type18'] ==1) , 1, 0)\n\nX_train['Leighcan_family'] = np.where((X_train['Soil_Type21'] ==1) | (X_train['Soil_Type22'] == 1) | (X_train['Soil_Type23'] == 1) | (X_train['Soil_Type24'] == 1) |\n                                       (X_train['Soil_Type25'] == 1) | (X_train['Soil_Type26'] == 1), 1, 0)\nx_test['Leighcan_family'] = np.where((x_test['Soil_Type21'] ==1) | (x_test['Soil_Type22'] == 1) | (x_test['Soil_Type23'] == 1) | (x_test['Soil_Type24'] == 1) |\n                                       (x_test['Soil_Type25'] == 1) | (x_test['Soil_Type27'] == 1), 1, 0)\n\nX_train['Bross_family'] = np.where((X_train['Soil_Type36'] ==1) , 1, 0)\nx_test['Bross_family'] = np.where((x_test['Soil_Type36'] ==1) , 1, 0)\n\nX_train['Ratake_family'] = np.where((X_train['Soil_Type38'] ==1) | (X_train['Soil_Type39'] == 1) | (X_train['Soil_Type40'] ), 1, 0)\nx_test['Ratake_family'] = np.where((x_test['Soil_Type38'] ==1) | (x_test['Soil_Type39'] == 1) | (X_train['Soil_Type40'] ), 1, 0)\n","04ef46e4":"X_train['Rubbly'] = np.where((X_train['Soil_Type3'] ==1) | (X_train['Soil_Type4'] == 1) | (X_train['Soil_Type5'] == 1) | (X_train['Soil_Type10'] == 1) |\n                                       (X_train['Soil_Type11'] == 1) | (X_train['Soil_Type13'] == 1), 1, 0)\nx_test['Rubbly'] = np.where((x_test['Soil_Type3'] ==1) | (x_test['Soil_Type4'] == 1) | (x_test['Soil_Type5'] == 1) | (x_test['Soil_Type10'] == 1) |\n                                       (x_test['Soil_Type13'] == 1) | (x_test['Soil_Type11'] == 1), 1, 0)\n\n\nX_train['stony'] = np.where((X_train['Soil_Type2'] ==1) | (X_train['Soil_Type6'] == 1) | (X_train['Soil_Type9'] == 1) | (X_train['Soil_Type12'] == 1), 1, 0)\nx_test['stony'] = np.where((x_test['Soil_Type2'] ==1) | (x_test['Soil_Type6'] == 1) | (x_test['Soil_Type9'] == 1) | (x_test['Soil_Type12'] == 1), 1, 0)\n\n\nX_train['extremely_stony'] = np.where((X_train['Soil_Type1'] ==1) | (X_train['Soil_Type24'] == 1) | (X_train['Soil_Type25'] == 1) | (X_train['Soil_Type27'] == 1) |\n                                       (X_train['Soil_Type28'] == 1) | (X_train['Soil_Type29'] == 1) | (X_train['Soil_Type30'] == 1) | (X_train['Soil_Type31'] == 1) | (X_train['Soil_Type32'] == 1) | (X_train['Soil_Type33'] == 1) |\n                                      (X_train['Soil_Type34'] == 1) | (X_train['Soil_Type36'] == 1) | (X_train['Soil_Type37'] == 1) | (X_train['Soil_Type38'] == 1) | (X_train['Soil_Type39'] == 1) | (X_train['Soil_Type40'] == 1), 1, 0)\nx_test['extremely_stony'] = np.where((x_test['Soil_Type1'] ==1) | (x_test['Soil_Type24'] == 1) | (x_test['Soil_Type25'] == 1) | (x_test['Soil_Type27'] == 1) |\n                                       (x_test['Soil_Type28'] == 1) | (x_test['Soil_Type29'] == 1) | (x_test['Soil_Type30'] == 1) | (x_test['Soil_Type31'] == 1) | (x_test['Soil_Type32'] == 1) | (x_test['Soil_Type33'] == 1) |\n                                      (x_test['Soil_Type34'] == 1) | (x_test['Soil_Type36'] == 1) | (x_test['Soil_Type37'] == 1) | (x_test['Soil_Type38'] == 1) | (x_test['Soil_Type39'] == 1) | (x_test['Soil_Type40'] == 1), 1, 0)\n","36efa76f":"X_train.shape","81934b56":"plt.figure(figsize=(20,30))\nplt.subplot(5, 2, 1)\nfig = train.boxplot(column='Elevation')\nfig.set_title('')\nfig.set_ylabel('Elevation')\n \nplt.subplot(5, 2, 2)\nfig = train.boxplot(column='Aspect')\nfig.set_title('')\nfig.set_ylabel('Aspect')\n\nplt.subplot(5, 2, 3)\nfig = train.boxplot(column='Slope')\nfig.set_title('')\nfig.set_ylabel('Slope')\n \nplt.subplot(5, 2, 4)\nfig = train.boxplot(column='Horizontal_Distance_To_Hydrology')\nfig.set_title('')\nfig.set_ylabel('Horizontal_Distance_To_Hydrology')\n\nplt.subplot(5, 2, 5)\nfig = train.boxplot(column='Vertical_Distance_To_Hydrology')\nfig.set_title('')\nfig.set_ylabel('Vertical_Distance_To_Hydrology')\n \nplt.subplot(5, 2, 6)\nfig = train.boxplot(column='Horizontal_Distance_To_Roadways')\nfig.set_title('')\nfig.set_ylabel('Horizontal_Distance_To_Roadways')\n\nplt.subplot(5, 2, 7)\nfig = train.boxplot(column='Hillshade_9am')\nfig.set_title('')\nfig.set_ylabel('Hillshade_9am')\n \nplt.subplot(5, 2, 8)\nfig = train.boxplot(column='Hillshade_Noon')\nfig.set_title('')\nfig.set_ylabel('Hillshade_Noon')\n\nplt.subplot(5, 2, 9)\nfig = train.boxplot(column='Hillshade_3pm')\nfig.set_title('')\nfig.set_ylabel('Hillshade_3pm')\n \nplt.subplot(5, 2, 10)\nfig = train.boxplot(column='Horizontal_Distance_To_Fire_Points')\nfig.set_title('')\nfig.set_ylabel('Horizontal_Distance_To_Fire_Points')","19062987":"IQR = X_train.Slope.quantile(0.75) - X_train.Slope.quantile(0.25) #finding interquantile range\nLower_fence = X_train.Slope.quantile(0.25) - (IQR * 1.5)          #lower value\nUpper_fence = X_train.Slope.quantile(0.75) + (IQR * 1.5)          #upper value\nprint('slope number outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\nSlope = len(X_train[X_train.Slope>Upper_fence]) \/ np.float(len(X_train))\nprint('Number of Slope with values higher than {upperboundary}: {slope}'.format(upperboundary=Upper_fence, slope=Slope))","0987a0bd":"def top_code(df, variable, top):                            #function to top_code values\n    return np.where(df[variable]>top, top, df[variable])\nX_train['Slope']= top_code(X_train, 'Slope', 40)            #train_set is top_coded\nx_test['Slope']= top_code(x_test,'Slope',40)  ","db08cc7a":"IQR2 = X_train.Hillshade_3pm.quantile(0.75) - X_train.Hillshade_3pm.quantile(0.25)\nLower_fence = X_train.Hillshade_3pm.quantile(0.25) - (IQR2 * 1.5)\nUpper_fence = X_train.Hillshade_3pm.quantile(0.75) + (IQR2 * 1.5)\nprint('Hillshade_3pm number outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\nHillshades_3pm = len(X_train[X_train.Hillshade_3pm<Lower_fence]) \/ np.float(len(X_train))\nprint('Number of Hillshade_3pm with values lower than {lowerboundary}: {Hillshade_3pm}'.format(lowerboundary=Lower_fence, Hillshade_3pm=Hillshades_3pm))","86e5e068":"def bottom_code(df, variable, bottom):                      #function to bottom values\n    return np.where(df[variable]<bottom, bottom, df[variable])\n\n#bottom coding Hillshade_3pm\nX_train['Hillshade_3pm']=bottom_code(X_train,'Hillshade_3pm',14)\nx_test['Hillshade_3pm']=bottom_code(x_test,'Hillshade_3pm',14)","b9d4f782":"def discretise(var,X_train,x_test):\n#     #ploting figure before discritisation\n#     fig = plt.figure()\n#     fig = X_train.groupby([var])['Cover_Type'].mean().plot(figsize=(12,6))\n#     fig.set_title('relationship between variable and target before discretisation')\n#     fig.set_ylabel('Cover_Type')\n    \n    # find quantiles and discretise train set\n    \n    X_train[var], bins = pd.qcut(x=X_train[var], q=8, retbins=True, precision=3, duplicates='raise')\n    x_test[var] = pd.cut(x = x_test[var], bins=bins, include_lowest=True)\n    \n    t1 = X_train.groupby([var])[var].count() \/ np.float(len(X_train))\n    t3 = x_test.groupby([var])[var].count() \/ np.float(len(x_test))\n    \n    \n    #plot to show distribution of values\n#     temp = pd.concat([t1,t3], axis=1)\n#     temp.columns = ['train', 'test']\n#     temp.plot.bar(figsize=(12,6))\n    \n    #plot after discretisation\n#     fig = plt.figure()\n#     fig = X_train.groupby([var])['Cover_Type'].mean().plot(figsize=(12,6))\n#     fig.set_title('Normal relationship between variable and target after discretisation')\n#     fig.set_ylabel('Cover_Type')","426d1d26":"try:\n    X_train,x_test=discretise('Horizontal_Distance_To_Hydrology',X_train,x_test)\nexcept TypeError:\n    pass\n\ntry:\n    X_train,x_test=discretise('Vertical_Distance_To_Hydrology',X_train,x_test)\nexcept TypeError:\n    pass\n\ntry:\n    X_train,x_test=discretise('Horizontal_Distance_To_Roadways',X_train,x_test)\nexcept TypeError:\n    pass\n\ntry:\n    X_train,x_test=discretise('Hillshade_9am',X_train,x_test)\nexcept TypeError:\n    pass\n\ntry:\n    X_train,x_test=discretise('Hillshade_Noon',X_train,x_test)\nexcept TypeError:\n    pass\n\ntry:\n    X_train,x_test=discretise('Horizontal_Distance_To_Fire_Points',X_train,x_test)\nexcept TypeError:\n    pass","a787cb7c":"def inpute(var,X_train,x_test):\n    if x_test[var].isnull().sum()>0:\n        x_test.loc[x_test[var].isnull(), var] = X_train[var].unique()[0]\n        print(\"inputed column :: \",var)","e5e15136":"for col in X_train.columns:\n    if col !='Cover_Type':\n        inpute(col,X_train,x_test)","bc3df115":"for df in [X_train, x_test]:\n    df.Horizontal_Distance_To_Hydrology = df.Horizontal_Distance_To_Hydrology.astype('O')\n    df.Vertical_Distance_To_Hydrology = df.Vertical_Distance_To_Hydrology.astype('O')\n    df.Horizontal_Distance_To_Roadways = df.Horizontal_Distance_To_Roadways.astype('O')\n    df.Hillshade_9am = df.Hillshade_9am.astype('O')\n    df.Hillshade_Noon = df.Hillshade_Noon.astype('O')\n    df.Horizontal_Distance_To_Fire_Points = df.Horizontal_Distance_To_Fire_Points.astype('O')","df62dd57":"def encode_categorical_variables(var, target):\n        # make label to risk dictionary\n        ordered_labels = X_train.groupby([var])[target].mean().to_dict()\n        \n        # encode variables\n        X_train[var] = X_train[var].map(ordered_labels)\n        x_test[var] = x_test[var].map(ordered_labels)","45fe74e0":"for var in ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Horizontal_Distance_To_Fire_Points']:\n    print(var)\n    encode_categorical_variables(var, 'Cover_Type')","c3293908":"y_train=train['Cover_Type']\nX_train.drop(['Cover_Type','Id'],axis=1,inplace=True) #removing target and id column from train set\nx_test.drop(['Id'],axis=1,inplace=True) ","5a5c50ba":"print(X_train.shape,x_test.shape)","75360d69":"import lightgbm as lgb\n\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, \n                              GradientBoostingClassifier, RandomForestClassifier)\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix","08ffb514":"random_state = 1\nrandom.seed(random_state)\nnp.random.seed(random_state)\nos.environ['PYTHONHASHSEED'] = str(random_state)\n\nprint('> Setting up classifiers...')\nn_jobs = -1  # Use all processor cores to speed things up\n\nab_clf = AdaBoostClassifier(n_estimators=200,\n                            base_estimator=DecisionTreeClassifier(\n                                min_samples_leaf=3,\n                                random_state=random_state),\n                            random_state=random_state)\n\nbg_clf = BaggingClassifier(n_estimators=200,\n                           random_state=random_state)\n\ngb_clf = GradientBoostingClassifier(n_estimators=400,\n                                    min_samples_leaf=3,\n                                    tol=0.1,\n                                    verbose=0,\n                                    random_state=random_state)\n\nlg_clf = LGBMClassifier(n_estimators=400,\n                        num_leaves=30,\n                        verbosity=0,\n                        random_state=random_state,\n                        n_jobs=n_jobs)\n\nrf_clf = RandomForestClassifier(n_estimators=885,\n                                min_samples_leaf=3,\n                                verbose=0,\n                                random_state=random_state,\n                                n_jobs=n_jobs)\n\nxg_clf = XGBClassifier(n_estimators=400,\n                       min_child_weight=3,\n                       verbosity=0,\n                       random_state=random_state,\n                       n_jobs=n_jobs)\n\nensemble = [('ab', ab_clf),\n            ('bg', bg_clf),\n            ('gb', gb_clf),\n            ('lg', lg_clf),\n            ('rf', rf_clf),\n            ('xg', xg_clf)]\n\nstack = StackingCVClassifier(classifiers=[clf for label, clf in ensemble],\n                             meta_classifier=rf_clf,\n                             cv=5,\n                             use_probas=True,\n                             use_features_in_secondary=True,\n                             verbose=1,\n                             random_state=random_state,\n                             n_jobs=n_jobs)\n\n# TODO: Find best parameters for each classifier\n\nprint('> Cross-validating classifiers...')\nX_train = X_train.to_numpy()  # Converting to numpy matrices because...\nx_test = x_test.to_numpy()  # ...XGBoost complains about dataframe columns\n\nscores = dict()\nfor label, clf in ensemble:\n    print('  -- Cross-validating {} classifier...'.format(label))\n    score = cross_val_score(clf, X_train, y_train,\n                            cv=5,\n                            scoring='accuracy',\n                            verbose=1,\n                            n_jobs=n_jobs)\n    scores[label] = score\n    print('  -- {} : {:.3f} : {}'.format(label, np.mean(score), np.around(score, 3)))\n    print()\n\nprint('> All cross-validation scores')\nfor label, score in scores.items():\n    print('  -- {} : {:.3f} : {}'.format(label, np.mean(score), np.around(score, 3)))","9446c032":"\nprint('> Fitting & predicting...')\nstack = stack.fit(X_train, y_train)\nprediction = stack.predict(x_test)\n","2fb7822e":"output = pd.DataFrame({'Id': test.Id,\n                      'Cover_Type': prediction})\noutput.to_csv('sample_submission.csv', index=False)","a98725f2":"### Models","0ff48327":"the lower value in inter quantile range is 14(approx)\n\nwe we have to cap the values lower than 14 to 14","c664cde1":"18 new features are added","23c91b9b":"Slope:\n\nnow i have to calculate the interquantile range(IQR) for the column","bd368114":"\nRock_type :: soil_type\n\nrubbly  : : 3,4,5,10,11,13\n\nstony : : 6,2,9,12\n\nextremely stony : : 1,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40","8c82e6a4":"cosine of slope :  used to partially model the relationships between hillshade","39ef2b1b":"interaction_9amnoon: Product of hillshades at 9AM and Noon\n","df910a67":"family                  : :                 soil_Type\n\nCantheral  : :  1                            \n\nRatake : : 2,4\n\nvanet : :5\n\nwetmore :: 6\n\nlimber : :8\n\ntroutville : :9\n\ncatamount :: 10,11,13,26,28,31,32,33\n\nlegault : :12,29,30\n\ngateview:: 17\n\nrogert :: 18\n\nleighcan : : 21,22,23,24,25,27\n\nbross : : 36\n\nmoran : : 38,39,40","cb677b3c":"feature:\n\nEuclidean_distance_to_hydrology: square root of the sum of square of vertical and horizontal distance","75a4ed35":"now we have top_coded and bottom coded respective columns\n\nnow i will use discretisation for the other columns which have outliers","d8d1e746":"Bottom_coding : Hillshade_3pm","e1b6e2ee":"**Importing Libraries**","0cf5171f":"### Stacking","91be8fa6":"Clearly the columns other than elevation and aspect have outliers in them\n\ni will be using 2 techniques for outliers handling\n\n1.top_coding and bottom_coding: in this the values which are out of the range are caped within it\n\n2.Discretisation: the intervals of all values are formed so that outliers could come in some interval\n\n1.Top_coding: Slope\n\n2.Bottom_coding:Hillshade_3pm\n\n3.Discretisation: all other columns","2a454417":"now thier are few missing values in the test set and we have to inpute them","2bf606e3":"**Rock Type**","03afa4be":"the uppervalue of the quantile in slope is 40\n\nnow we have to cap all the values which are above 40 to 40","f96f0fb3":"**soils families**","63baf241":"now the intervals are formed\n\nbefore encoding them we have change their data type to object"}}