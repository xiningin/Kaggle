{"cell_type":{"e48cb991":"code","a59fa7e7":"code","0bc1f071":"code","091420b5":"code","1da7d810":"code","a4f7c6c5":"code","f756eccf":"code","706d4ae9":"code","e3039558":"code","8478d00c":"code","902f900d":"code","5881af1e":"markdown","f7c9065d":"markdown","4e7346c6":"markdown","a65ca7c8":"markdown","e1d1fcde":"markdown","acc2c4fd":"markdown","5974507e":"markdown","f7f5baa7":"markdown","7cc439cc":"markdown","df65fab7":"markdown","8552eab4":"markdown"},"source":{"e48cb991":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a59fa7e7":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n","0bc1f071":"df = pd.read_csv('..\/input\/textdb3\/fake_or_real_news.csv') # Load data into DataFrame\n","091420b5":"# Pre-Processing\ndf['text'] = df['text'].apply(lambda x: x.lower())","1da7d810":"\nmax_features = 2000 # Vocabulary Size\n\ntokenizer = Tokenizer(num_words=max_features, split=' ')\ntokenizer.fit_on_texts(df['text'].values)\nX = tokenizer.texts_to_sequences(df['text'].values)","a4f7c6c5":"max_length = 1000\n# Padding\nX = pad_sequences(X,maxlen = max_length, padding = 'post')","f756eccf":"#y = df.label\ny = pd.get_dummies(df['label']).values","706d4ae9":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=53)\n\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","e3039558":"# define the model\nmodel = Sequential()\nmodel.add(Embedding(max_features, 24, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# summarize the model\nprint(model.summary())\n","8478d00c":"# fit the model\nmodel.fit(X_train, y_train, epochs=50, verbose=0)\n\n","902f900d":"# evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))\n","5881af1e":"# Processing Target","f7c9065d":"# Tokenization","4e7346c6":"# Train-Test Split","a65ca7c8":"# Pre-processing","e1d1fcde":"# Load Data","acc2c4fd":"# Padding","5974507e":"# Imports","f7f5baa7":"# Design Deep Neural Network with Embedding Layer","7cc439cc":"# Fake News Classifier with Deep Learning with Embedding Layer","df65fab7":"# Training","8552eab4":"# Evaluation"}}