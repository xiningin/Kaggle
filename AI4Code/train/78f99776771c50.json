{"cell_type":{"c5ba7a6a":"code","af0e024a":"code","a7deffba":"code","20ba9749":"code","6564d16a":"code","d03edad6":"code","698fce6c":"code","f078bc05":"code","bb8f9d68":"code","56327425":"code","4626619a":"code","5ca1da74":"code","1b4e379a":"code","a8e23caa":"code","af577761":"code","f8cf72ff":"code","9012d2a5":"code","3950af9b":"code","e4c83eda":"code","5810258a":"code","f32cb435":"code","efce65d4":"code","202fc8a1":"code","a695bdc2":"code","19b017ae":"code","29c819ad":"code","f0798908":"code","1029be43":"code","78247714":"code","1edd626e":"code","275768d7":"code","5d2e4eda":"code","cfd28146":"code","49783488":"code","f7959055":"code","6632eb1a":"code","3531471a":"code","2c669298":"code","d42ca6b9":"code","0d94cbcd":"code","5d46ece6":"code","42db56b3":"code","412ac020":"code","1c8ebc77":"markdown","7e970043":"markdown","77658fcb":"markdown","24e6f3db":"markdown","f71c28b5":"markdown","19413922":"markdown","7439b3a1":"markdown","d8587e62":"markdown","97f88e01":"markdown"},"source":{"c5ba7a6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af0e024a":"traindf = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntestdf = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","a7deffba":"print(traindf.info())\nmeanOfAge = int(round(traindf[[\"Age\"]].mean()))\nprint(meanOfAge)","20ba9749":"# as we can see the clumn Cabin has very few data so we will not consider it and will drop the cloumn cabin\n# PassengerId is a uniqe for each passenger and it is not a useful factor\n# Name is also a not useful factor for servival\n# Ticket is not useful as everyone has its own ticket number\n\n# putting the average of age where it is not there\ntraindf['Age'] = traindf['Age'].fillna(meanOfAge)\n\ntraindf = traindf.drop([\"Cabin\",\"Ticket\",\"Name\"], axis=1)\ntraindf[\"Embarked\"]","6564d16a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n","d03edad6":"sns.pairplot(traindf)","698fce6c":"traindf.Embarked.hist()\n#as we can see most of the embarked has the value of S","f078bc05":"traindf.Embarked = traindf.Embarked.fillna(\"S\")","bb8f9d68":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score","56327425":"traindf = pd.get_dummies(traindf, columns=[\"Sex\"], prefix=[\"Sex\"] )\ntraindf = pd.get_dummies(traindf, columns=[\"Embarked\"], prefix=[\"Embarked\"] )\ntraindf","4626619a":"traindfx = traindf[[\"Pclass\",\"Sex_male\",\"Sex_female\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]]\ntraindfy = traindf[[\"Survived\"]]","5ca1da74":"x_train, x_test, y_train, y_test = train_test_split(traindfx, traindfy)","1b4e379a":"\nmodel = RandomForestClassifier()\nmodel.fit(x_train,y_train)","a8e23caa":"ypredict = model.predict(x_test)\naccuracy_rfc = accuracy_score(ypredict,y_test.to_numpy().flatten())\nf1score_rfc = f1_score(y_test, ypredict, average=None)","af577761":"print(\"Accuracy of Random Forest tree is {}\".format(accuracy_rfc))\nprint(\"F1 score of Random Forest tree is {}\".format(f1score_rfc))","f8cf72ff":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(x_train,y_train.values.ravel())","9012d2a5":"ypredict_gnb = gnb.predict(x_test)\naccuracy_gnb = accuracy_score(ypredict_gnb,y_test.to_numpy().flatten())\nf1score_gnb = f1_score(y_test, ypredict_gnb, average=None)","3950af9b":"print(\"Accuracy of Naive Bayes Classifier is {}\".format(accuracy_gnb))\nprint(\"F1 score of Naive Bayes Classifier is {}\".format(f1score_gnb))","e4c83eda":"dtc = DecisionTreeClassifier()\ndtc.fit(x_train,y_train.values.ravel())","5810258a":"ypredict_dtc = dtc.predict(x_test)\naccuracy_dtc = accuracy_score(ypredict_dtc,y_test.to_numpy().flatten())\nf1score_dtc = f1_score(y_test, ypredict_dtc, average=None)","f32cb435":"print(\"Accuracy of Naive Bayes Classifier is {}\".format(accuracy_dtc))\nprint(\"F1 score of Naive Bayes Classifier is {}\".format(f1score_dtc))","efce65d4":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(x_train, y_train.values.ravel())","202fc8a1":"ypredict_svc = svc.predict(x_test)\naccuracy_svc = accuracy_score(ypredict_svc,y_test.to_numpy().flatten())\nf1score_svc = f1_score(y_test, ypredict_svc, average=None)","a695bdc2":"print(\"Accuracy of Naive Bayes Classifier is {}\".format(accuracy_svc))\nprint(\"F1 score of Naive Bayes Classifier is {}\".format(f1score_svc))","19b017ae":"from sklearn.linear_model import LogisticRegression\nlogR = LogisticRegression()\nlogR.fit(x_train, y_train.values.ravel())","29c819ad":"ypredict_logR = logR.predict(x_test)\naccuracy_logR = accuracy_score(ypredict_logR,y_test.to_numpy().flatten())\nf1score_logR = f1_score(y_test, ypredict_logR, average=None)","f0798908":"print(\"Accuracy of Naive Bayes Classifier is {}\".format(accuracy_logR))\nprint(\"F1 score of Naive Bayes Classifier is {}\".format(f1score_logR))","1029be43":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(x_train,y_train.values.ravel())","78247714":"ypredict_knn = knn.predict(x_test)\naccuracy_knn = accuracy_score(ypredict_knn,y_test.to_numpy().flatten())\nf1score_knn = f1_score(y_test, ypredict_knn, average=None)","1edd626e":"print(\"Accuracy of Naive Bayes Classifier is {}\".format(accuracy_knn))\nprint(\"F1 score of Naive Bayes Classifier is {}\".format(f1score_knn))","275768d7":"modelsLists = [\"RandomForest\",\"NaiveBayes\",\"DecisionTree\",\"SVM\",\"LogisticRegression\",\"KNN\"]\nf1scoreLists = [f1score_rfc,f1score_gnb,f1score_dtc,f1score_svc,f1score_logR,f1score_knn]\nf1score_df = pd.DataFrame({'Model Name' : modelsLists, 'F1 score_test' : f1scoreLists})\nf1score_df","5d2e4eda":"\nypredict_rfc_train = model.predict(x_train)\naccuracy_rfc_train = accuracy_score(ypredict_rfc_train,y_train.to_numpy().flatten())\nf1score_rfc_train = f1_score(y_train, ypredict_rfc_train, average=None)\n\nypredict_gnb_train = gnb.predict(x_train)\naccuracy_gnb_train = accuracy_score(ypredict_gnb_train,y_train.to_numpy().flatten())\nf1score_gnb_train = f1_score(y_train, ypredict_gnb_train, average=None)\n\nypredict_dtc_train = dtc.predict(x_train)\naccuracy_dtc_train = accuracy_score(ypredict_dtc_train,y_train.to_numpy().flatten())\nf1score_dtc_train = f1_score(y_train, ypredict_dtc_train, average=None)\n\nypredict_svc_train = svc.predict(x_train)\naccuracy_svc_train = accuracy_score(ypredict_svc_train,y_train.to_numpy().flatten())\nf1score_svc_train = f1_score(y_train, ypredict_svc_train, average=None)\n\nypredict_logR_train = logR.predict(x_train)\naccuracy_logR_train = accuracy_score(ypredict_logR_train,y_train.to_numpy().flatten())\nf1score_logR_train = f1_score(y_train, ypredict_logR_train, average=None)\n\nypredict_knn_train = knn.predict(x_train)\naccuracy_knn_train = accuracy_score(ypredict_knn_train,y_train.to_numpy().flatten())\nf1score_knn_train = f1_score(y_train, ypredict_knn_train, average=None)\n\n\nf1score_train = [f1score_rfc_train,f1score_gnb_train,f1score_dtc_train,f1score_svc_train,f1score_logR_train,f1score_knn_train ]\nf1score_df[\"F1 score_train\"] = f1score_train","cfd28146":"f1score_df.to_html()","49783488":"import smtplib, ssl\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\nimport datetime\ntoday = datetime.datetime.now()\n","f7959055":"\n\nsender_email = \"piyushkumargupta05@gmail.com\"\nreceiver_email = \"push0123456@gmail.com\"\npassword = input(\"Type your password and press enter:\")\n\nmessage = MIMEMultipart()\nmessage[\"Subject\"] = \"Status Update: \"+today.strftime(\"%d\")+\" \"+today.strftime(\"%B\")\nmessage[\"From\"] = sender_email\nmessage[\"To\"] = receiver_email\nmessage[\"Cc\"] = \"theairtelhacker@gmail.com\"\n\n# Create the plain-text and HTML version of your message\ntext = \"\"\"\\\nHi Pramodhini,\nAs discussed, I have tried to applied different different model and found the f1-score for them which is in the below table->\n\\nn\"\"\"\nhtml = f1score_df.to_html()\n\n# Turn these into plain\/html MIMEText objects\npart1 = MIMEText(text, \"plain\")\npart2 = MIMEText(html, \"html\")\npart1 = MIMEText(\"\\n\\n Thanks,\\nPiyush Gupta\", \"plain\")\n# Add HTML\/plain-text parts to MIMEMultipart message\n# The email client will try to render the last part first\nmessage.attach(part1)\nmessage.attach(part2)\n\n# Create secure connection with server and send email\ncontext = ssl.create_default_context()\nwith smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n    server.login(sender_email, password)\n    server.sendmail(\n        sender_email, receiver_email, message.as_string()\n    )","6632eb1a":"testdf['Age'] = testdf['Age'].fillna(meanOfAge)\n\ntestdf = testdf.drop([\"Cabin\",\"Ticket\",\"Name\"], axis=1)\ntestdf.Embarked = testdf.Embarked.fillna(\"S\")","3531471a":"testdf = pd.get_dummies(testdf, columns=[\"Sex\"], prefix=[\"Sex\"] )\ntestdf = pd.get_dummies(testdf, columns=[\"Embarked\"], prefix=[\"Embarked\"] )\ntestdf","2c669298":"\ntestdf_x = testdf[[\"Pclass\",\"Sex_male\",\"Sex_female\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]]","d42ca6b9":"testdf_x.info()\n","0d94cbcd":"testdf_x.Fare = testdf_x.Fare.fillna(testdf_x.Fare.median())","5d46ece6":"ypredict = model.predict(testdf_x)","42db56b3":"ypredict\n\noutput = pd.DataFrame({'PassengerId': testdf.PassengerId, 'Survived': ypredict})\noutput","412ac020":"output.to_csv('MyFirstSubmission.csv', index=False)\nprint(\"Successfully saved!\")","1c8ebc77":"# Sending the mail report","7e970043":"# SVM Classifier","77658fcb":"# Naive Bayes Classifier","24e6f3db":"# Calculating the f1 score train\n","f71c28b5":"# Logistic Regression","19413922":"# Random Forest Classifier","7439b3a1":"# KNN classifire","d8587e62":"# Saving Output","97f88e01":"# Decision Tree Classifier"}}