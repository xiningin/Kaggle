{"cell_type":{"8375cf58":"code","238eef46":"code","f5139e3f":"code","959bdf94":"code","ad457652":"code","5acff4bc":"code","b66346ad":"code","7bece510":"code","cfb54cb6":"code","a99c869a":"code","7df748a6":"code","165acad1":"code","1570f6fb":"code","63db90a1":"code","a604969b":"code","3239b403":"code","95d750ed":"code","b73aca29":"code","85edab41":"code","2ce28c96":"code","8ff21d97":"code","04207a58":"code","7150dd2b":"code","12c325b5":"code","6331fed5":"code","bb220eba":"code","a06506d9":"code","3efdedf7":"code","e21a8f3e":"code","b8996231":"code","badf474f":"markdown","01c9fab3":"markdown","984b9803":"markdown","8202d41b":"markdown","ab08a3e4":"markdown","6da29fda":"markdown","82de5f3c":"markdown","d6acb71d":"markdown","0c143623":"markdown","3af73250":"markdown","6f03aafe":"markdown","a0c9cc8f":"markdown","6e471a93":"markdown","c4977a2c":"markdown","e26d0fa7":"markdown","eed26b52":"markdown","728df23d":"markdown","41e64e5e":"markdown","af9c6a6d":"markdown","eaaad10b":"markdown","cc5f14b3":"markdown","d74a78bf":"markdown","48ef3db8":"markdown","7a2c55ce":"markdown","c1ce51c9":"markdown","0ba07cb4":"markdown","e840eeb7":"markdown","9c0cc8db":"markdown","7dae4524":"markdown","ca1c2e49":"markdown","44d1f4ff":"markdown","a0247c3d":"markdown","b377abd2":"markdown","25519538":"markdown","b61e6ce2":"markdown","261a4966":"markdown","40d09f6e":"markdown","bc36d4b4":"markdown","06c840a1":"markdown","59344bd3":"markdown","5faa5211":"markdown","e6ae4acc":"markdown","006608be":"markdown","eeff4f53":"markdown","e414b31e":"markdown"},"source":{"8375cf58":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\n# setting plots' configuration\nplt.rcParams[\"figure.figsize\"]= 50,30\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.patches as mpatches\nfrom matplotlib.patches import FancyArrowPatch\n\nimport scipy.special\nimport math\nimport random\nfrom scipy.stats import multivariate_normal\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplays = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/plays.csv')\ngames = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/games.csv')\n\nweek1 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week1.csv')\nweek2 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week2.csv')\nweek3 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week3.csv')\nweek4 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week4.csv')\nweek5 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week5.csv')\nweek6 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week6.csv')\nweek7 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week7.csv')\nweek8 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week8.csv')\nweek9 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week9.csv')\nweek10 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week10.csv')\nweek11 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week11.csv')\nweek12 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week12.csv')\nweek13 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week13.csv')\nweek14 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week14.csv')\nweek15 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week15.csv')\nweek16 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week16.csv')\nweek17 = pd.read_csv('..\/input\/nfl-big-data-bowl-2021\/week17.csv')\n\n# creating a unique dataset for all the tracking data\nframes = [week1,week2,week3,week4,week5,week6,week7,week8,week9,week10,week11,week12,week13,week14,week15,week16,week17]\nweeks = pd.concat(frames,axis=0).reset_index().drop('index',axis=1)","238eef46":"# setting plot's configuration\nfig, (ax1) = plt.subplots(1, 1)\n\n# specific playID of the passing play taken into consideration\nplayID = 75\n\n# tracking data of the passing play taken into consideration\npossible_track = week1[ week1['playId'] == playID]\n\n# names of the players involved + the ball\nnames = possible_track[\"displayName\"].unique()\n\n\ndef arrow(x,y,ax,color, alpha):\n    \"\"\"\n    Function to draw the arrow of the movement\n    :param x: position on x-axis\n    :param y: position on y-axis\n    :param ax: plot's configuration\n    :param color: color of the arrows\n    :param alpha: color's intensity of the arrows\n    :return: arrows on the specific positions\n    \"\"\"\n    # distance between the arrows\n    ind = np.arange(len(x)-14,len(x),13)\n    \n    # computing of the arrows\n    for i in ind:\n        ar = FancyArrowPatch ((x[i-1],y[i-1]),(x[i],y[i]), \n                              arrowstyle='fancy', mutation_scale=50, color = color, alpha = alpha)\n        ax.add_patch(ar)\n\n\ndef draw(player_df, colorr, alpha):\n    \"\"\"\n    Function to draw the movement\n    :param player_df: tracking data of the player\n    :param colorr: color of the movement\n    :param alpha: color's intensity of the movement\n    :return: plot (proportional to the field) of the movement\n    \"\"\"\n    \n    # removing variables of no interest \n    Y = player_df.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)  \n    \n    # converting into a matrix\n    Y = Y.to_numpy()\n    Y = Y.astype(float)\n    \n    # plot's dimension proportional to the field\n    plt.xlim([0, 120])\n    plt.ylim([0, 53.3])\n    \n    # plot of the movement\n    plt.plot(Y[:,0], Y[:,1] , '-ok', color = colorr, alpha = alpha)\n    \n    # line of scrimmage\n    plt.axvline(x= 90, color =  'black')\n    plt.text(90.5, 2, 'line of scrimmage ',fontsize=42, color = 'black',weight = 'bold')\n    \n    # line of endzone\n    plt.axvline(x= 10, color =  'black')\n    plt.text(3, 20, 'ENDZONE ',fontsize=100, color = 'black', weight = 'bold', rotation='vertical')\n    \n    # plot of the arrows on the movement\n    arrow(Y[:,0],Y[:,1],ax1,colorr, alpha = alpha)\n\n    \n# loop over each name involved in the passing play\nfor i in range(0,len(names)):\n    \n    # dataframe of tracking data of that \"name\"  \n    df = possible_track[possible_track['displayName'] == names[i]]\n\n    # plot of tracking data if \"name\" is the ball\n    if df[\"team\"][df.index[0]] == 'football':\n        colorr = 'brown'\n        draw(df, colorr,1)\n        \n    # plot of tracking data if \"name\" is a member of the offensive team\n    elif df[\"team\"][df.index[0]] == 'away':\n        colorr = 'blue'\n        draw(df, colorr,1)\n    \n    # legend\n    blue_patch = mpatches.Patch(color='blue', label= 'Offensive Team')\n    brawn_patch = mpatches.Patch(color='brown', label= 'Ball')\n    plt.legend(handles=[blue_patch,brawn_patch], loc='upper right',prop={'size': 30}) \n    \n    # arrow of the direction of the attack\n    plt.arrow(65, 10, -26, 0, length_includes_head=True, head_width=2, head_length=3)\n    plt.text(43.5, 10.4, 'direction of attack ',fontsize=42, color = 'black')\n    \n    # title\n    plt.title(\"Possible opponent's strategy during a passing play\",size=95)\n    \n    # caption\n    plt.text(60, -5, 'Figure 1', ha='center',size=70)","f5139e3f":"# setting plot's configuration\nfig, (ax1) = plt.subplots(1, 1)\n\n# loop over each name involved in the passing play\nfor i in range(0,len(names)):\n    \n    # dataframe of tracking data of that \"name\"\n    df = possible_track[possible_track['displayName'] == names[i]]\n\n    # plot of tracking data if \"name\" is the ball\n    if df[\"team\"][df.index[0]] == 'football':\n        colorr = 'brown'\n        draw(df, colorr,1)\n    \n    # plot of tracking data if \"name\" is a member of the offensive team\n    elif df[\"team\"][df.index[0]] == 'away':\n        colorr = 'blue'\n        draw(df, colorr,1)\n    \n    # plot of tracking data if \"name\" is a member of the defensive team\n    elif df[\"team\"][df.index[0]] == 'home':\n        colorr = 'red'\n        draw(df, colorr,1)\n    \n\n    # legend\n    red_patch = mpatches.Patch(color='red', label= 'Defensive Team')\n    blue_patch = mpatches.Patch(color='blue', label= 'Offensive Team')\n    brown_patch = mpatches.Patch(color='brown', label= 'Ball')\n    plt.legend(handles=[red_patch,blue_patch,brown_patch], loc='upper right',prop={'size': 30}) \n    \n    # arrow of the direction of the attack\n    plt.arrow(65, 10, -26, 0, length_includes_head=True, head_width=2, head_length=3)\n    plt.text(43.5, 10.4, 'direction of attack ',fontsize=42, color = 'black')\n    \n    # title\n    plt.title(\"Defensive strategy\", size=95)\n    \n    # caption\n    plt.text(60, -5, 'Figure 2', ha='center',size=70)","959bdf94":"plays","ad457652":"weeks","5acff4bc":"# setting plot's configuration\nfig, (ax1) = plt.subplots(1, 1)\n\n# dataframe of the tracking data of the player of interest\nY = possible_track[ possible_track['displayName'] == 'Nate Gerry']\n\n# removing variables of no interest\nY = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n\n# converting into a matrix \nY = Y.to_numpy()\nY = Y.astype(float)\n\n# loop over each name involved in the passing play  \nfor i in range(0,len(names)):\n    \n    # dataframe of tracking data of that \"name\"\n    df = possible_track[possible_track['displayName'] == names[i]]\n    \n    # plot of tracking data if \"name\" is the ball\n    if df[\"team\"][df.index[0]] == 'football':\n        colorr = 'brown'\n        draw(df, colorr,0.1)\n        \n    # plot of tracking data if \"name\" is a member of the offensive team    \n    elif df[\"team\"][df.index[0]] == 'away':\n        colorr = 'blue'\n        draw(df, colorr,0.1)\n        \n    # plot of tracking data if \"name\" is a member of the defensive team      \n    elif df[\"team\"][df.index[0]] == 'home':\n        colorr = 'red'\n        draw(df, colorr,0.1)\n    \n\n    # legend\n    red_patch = mpatches.Patch(color='red', label= 'Defensive Team')\n    blue_patch = mpatches.Patch(color='blue', label= 'Offensive Team')\n    brawn_patch = mpatches.Patch(color='brown', label= 'Ball')\n    orange_patch = mpatches.Patch(color='darkorange', label= 'Player of interest')\n    plt.legend(handles=[red_patch,blue_patch,brawn_patch,orange_patch], loc='upper right',prop={'size': 30}) \n    \n    # arrow of the direction of the attack\n    plt.arrow(65, 10, -26, 0, length_includes_head=True, head_width=2, head_length=3)\n    plt.text(43.5, 10.4, 'direction of attack ',fontsize=42, color = 'black')\n    \n    # plot of tracking data of the player of interest\n    plt.plot(Y[:,0], Y[:,1] , '-ok', color = 'darkorange', alpha = 4 )\n    arrow(Y[:,0],Y[:,1],ax1,color='orange', alpha = 4)\n    \n    # title\n    plt.title(\"Focus on one single player\",size=95)\n    \n    # caption\n    plt.text(60, -5, 'Figure 3', ha='center',size=70)","b66346ad":"# setting plot's configuration\nfig, (ax1) = plt.subplots(1, 1)\n\n\ndef b(t,d):\n    \"\"\"\n    This function is necessay to compute the general formulation of B\u00e9zier curves in matrix format.\n    :param t: scalar input of B\u00e9zier curve that takes a value between 0 and 1 \n    :param d: order B\u00e9zier curve\n    :return: scalar number\n    \"\"\"\n    a = (t**d) * ( (1-t)**(n-d) ) * scipy.special.binom(n, d)\n    return a\n\n# B\u00e9zier curve's order\nn = 4  \n\n# number of movement's observations\nm = Y.shape[0]\n\n# matrix T (more information look at chap. 2.1.3 \"Statistical Modeling of Trajectories with B\u00e9zier Curves\")\nT = []\nT.insert(0, np.zeros((m,n+1)))\nt  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\np = 0\nfor h in range(0, n+1):\n    for j in range(0,T[0].shape[0]):\n        T[0][j,p] = b(float(t[j]),h)\n    p = p + 1\n\n# estimated points\ntheta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n\n\ndef Bezier_function(t, degree):\n    \"\"\"\n    This function computes the output of Bezier curve of a given order with the fixed theta.\n    :param t: scalar input of B\u00e9zier curve that takes a value between 0 and 1 \n    :param degree: order B\u00e9zier curve\n    :return: two-dimensional vector\n    \"\"\"\n    n = degree\n\n    a = 0\n    for i in range(0,n+1):\n       a =  scipy.special.binom(n, i) * (1-t)**(n-i) * t**i * theta_hat[i,:] + a\n    return a\n\n# computation B\u00e9zier curve's output\nt = np.linspace(start=0, stop=1, num=1000)\nA = np.zeros((1000,2))\nfor i in range(0,1000):\n    A[i,:] = Bezier_function(t[i],n)\n\n# plot of tracking data of the player of interest\nplt.scatter(Y[:,0], Y[:,1] ,c= 'darkorange')\narrow(Y[:,0],Y[:,1], ax1,color='darkorange',alpha=1)\n\n# plot estimated points\nplt.scatter(theta_hat[:,0], theta_hat[:,1], c='blueviolet', s=300)\n\n# plot's dimension proportional to the field\nplt.xlim([0, 120])\nplt.ylim([0, 53.3])\n\n# line of scrimmage\nplt.axvline(x= 90, color =  'black')\nplt.text(90.5, 2, 'line of scrimmage ',fontsize=42, color = 'black',weight = 'bold')\n    \n# line of endzone\nplt.axvline(x= 10, color =  'black')\nplt.text(3, 20, 'ENDZONE ',fontsize=100, color = 'black', weight = 'bold', rotation='vertical')\n\n# legend\nred_patch = mpatches.Patch(color='blueviolet', label= 'Estimated points')\norange_patch = mpatches.Patch(color='darkorange', label= 'Player of interest')\nplt.legend(handles=[red_patch, orange_patch], loc='upper right',prop={'size': 30})\n\n# title\nplt.title(\"Estimated points of this specific movement\",size=95)\n\n# caption\nplt.text(60, -5, 'Figure 4', ha='center',size=70);","7bece510":"# setting plot's configuration\nfig, (ax1) = plt.subplots(1, 1)\n\n# plot of tracking data of the player of interest\nplt.scatter(Y[:,0], Y[:,1], c='darkorange')\n\n# plot estimated points\nplt.scatter(theta_hat[:,0], theta_hat[:,1], c='blueviolet', s=300)\n\n# plot's dimension proportional to the field\nplt.xlim([0, 120])\nplt.ylim([0, 53.3])\n\n# line of scrimmage\nplt.axvline(x= 90, color =  'black')\nplt.text(90.5, 2, 'line of scrimmage ',fontsize=42, color = 'black',weight = 'bold')\n    \n# line of endzone\nplt.axvline(x= 10, color =  'black')\nplt.text(3, 20, 'ENDZONE ',fontsize=100, color = 'black', weight = 'bold', rotation='vertical')\n\n# plot output B\u00e9zier curve\nplt.scatter(A[:,0], A[:,1], c='green')\narrow(A[:,0],A[:,1], ax1,color='green', alpha =1)\n\n# legend\nred_patch = mpatches.Patch(color='blueviolet', label= 'Estimated points')\norange_patch = mpatches.Patch(color='darkorange', label= 'Player of interest')\ngreen_patch = mpatches.Patch(color='green', label= 'Output B\u00e9zier Curve')\nplt.legend(handles=[red_patch, orange_patch, green_patch], loc='upper right',prop={'size': 30})\n\n# title\nplt.title(\"Output B\u00e9zier curve of fourth-order\",size=95)\n\n#caption\nplt.text(60, -5, 'Figure 5', ha='center',size=70);","cfb54cb6":"# Looking at the AIC values for each player is unthinkable, given the dimension of dataset. \n# Here we can compute the AIC values of 10 random defensive players.\n# Running this part of the code multiple times is possible in order to base our decision not only on one single sample of 10 elements!\n\n# random sampling of 10 passing plays\nsampled_list = random.sample(list(plays.index), 10)\n\n# looping over the 10 sampled passing plays\nfor fils in range(0,len(sampled_list)):\n\n    gameID = plays.iloc[fils,0]\n    playID = plays.iloc[fils,1]\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    focus7 = plays[ plays['gameId'] == gameID ]\n    focus6 = focus7 [ focus7 ['playId'] == playID ].reset_index().drop('index',axis=1)\n    \n    # team in possession of the ball\n    possTeam = focus6.iloc[0,6]\n\n    # checking which team is the defender\n    focus5 = games[ games['gameId'] == gameID ].reset_index().drop('index',axis=1)\n    if focus5.iloc[0,3] == possTeam:\n        defend = \"away\"\n    else:\n        defend = \"home\"\n    \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"defend\"\n    focus4 = weeks[ weeks['playId'] == playID ]\n    focus3 = focus4[ focus4['team'] == defend ]\n    focus2 = focus3[ focus3['gameId'] == gameID].reset_index().drop('index',axis=1)\n    \n    # names of the players involved in that specific defensive passing play\n    names = focus2['displayName'].unique().astype(str)\n    \n    # random sampling of one of the players in \"names\"\n    name = random.sample(list(names), 1)\n    \n    # dataframe of traking data of the \"name\" sampled\n    Y = focus2[focus2['displayName'] == name[0]]\n        \n    # checking if the direction of the attack is from left to right\n    if(focus2.iloc[0,17] == 'right'):\n        \n        # if it is, we flip the passing play in order to have the same direction of the attack for each different passing play (from right to left)\n        xli = []\n        for l in range(0,Y.shape[0]):\n        \n            OldMax = 120\n            OldMin = 0\n            NewMax = 0\n            NewMin = 120\n            OldValue = Y.iloc[l,1]\n        \n            OldRange = (OldMax - OldMin)  \n            NewRange = (NewMax - NewMin)  \n            NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n            xli.append(NewValue)\n        \n        \n        yli = []\n        for z in range(0,Y.shape[0]):\n        \n            OldMax = 53.3\n            OldMin = 0\n            NewMax = 0\n            NewMin = 53.3\n            OldValue = Y.iloc[z,2]\n        \n            OldRange = (OldMax - OldMin)  \n            NewRange = (NewMax - NewMin)  \n            NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n            yli.append(NewValue)\n    \n        # dataset flipped\n        frames = [pd.DataFrame(xli), pd.DataFrame(yli)]\n        Y = pd.concat(frames,axis=1).reset_index().drop('index',axis=1)\n            \n            \n    if(focus2.iloc[0,17] != 'right'):\n        # removing variables of no interest\n        Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n            \n    #converting into a matrix            \n    Y = Y.to_numpy()\n    Y = Y.astype(float)\n\n    def vector(Matrix):\n        \"\"\"\n        This function computes the vectorization, namely a linear transformation which converts the matrix into a column vector.\n        :param Matrix: a matrix\n        :return: a column vector\n        \"\"\"\n        n = Matrix.shape[0]\n        p = Matrix.shape[1]\n\n        vett = np.zeros(n*p)\n        o = 0\n        for i in range(p):\n            for k in range(n):\n                vett[o] = Matrix[k,i]\n                o = o + 1\n        return vett\n\n    #AKAIKE\n    def Akaike(Y,theta_hat,observations,variables,parameters):\n        \"\"\"\n        This function computes the AIC value in a multivariate linear regression context.\n        :param Y: response variable that is a two-dimensional matrix\n        :param theta_hat: it contains the estimated points\n        :param observations: number of observations\n        :param variables: number of variables (in this context two)\n        :param parameters: B\u00e9zier curve's order\n        \"\"\"\n        p = variables\n        k = parameters\n        n = observations\n\n        # T is the design matrix\n\n        # projection matrix\n        P = np.dot(T[0], np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])), np.transpose(T[0])))\n\n        # Estimate of the error variance\n        S = np.dot(np.dot(np.transpose(Y), (np.eye(Y.shape[0]) - P)), Y) \/ (Y.shape[0] - p - 1)\n\n        # Computation of the Multivariate Normal distribution's mean\n        Y_t = vector(Y)\n        mean = vector(np.dot(T[0],theta_hat))\n\n        # Computation of the Multivariate Normal distribution's covariance matrix\n        var = np.kron(S,np.eye(Y.shape[0]))\n\n        # Computational solution for the positive covariance\n        min_eig = np.min(np.real(np.linalg.eigvals(var)))\n        if min_eig < 0:\n            var -= 10 * min_eig * np.eye(*var.shape)\n        # Transpose of Y's log-likelihood\n        L = math.log(multivariate_normal.pdf(Y_t,mean,var))\n\n        # Akaike's formula\n        return -2*L + 2*n*(p*k + p*(p+1)\/2)\/(n-(k+p+1))\n\n\n    max_order = 10\n    akaike = np.zeros(max_order)\n    c = 0\n    \n    # loop over the possible orders of the B\u00e9zier curve\n    for i in range(0,max_order):\n        i = i + 2\n        n = int(i) # Number of parameters\n        m = Y.shape[0]\n\n        # MATRIX T\n        T = []\n        T.insert(0, np.zeros((m,n+1)))\n        t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n        p = 0\n        for h in range(0, n+1):\n            for j in range(0,T[0].shape[0]):\n                T[0][j,p] = b(float(t[j]),h)\n            p = p + 1\n        \n        # estimated points\n        theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n        \n        # computation of AIC value\n        akaike[c] = Akaike(Y,theta_hat,Y.shape[0],2,n)\n        c = c + 1\n\n    plt.plot(np.arange(1,max_order+1), akaike, '-o')\n    plt.title(\"AIC values for 10 defensive players chosen randomly\",size=75)\n    plt.xlabel(\"B\u00e9zier curve's order\",size=55)\n    plt.ylabel(\"AIC's values\",size=55)","a99c869a":"# dataframe of tracking data of all defensive players of the passing play that was taken into consideration\nalls = possible_track[possible_track['team']== 'home']\n\n# loop over all defensive players\nfor k in range(0, len(alls[\"displayName\"].unique())):\n    \n    # filtering tracking data of the passing play taken into consideration, with respect to unique 'displayName' of 'alls'\n    Y = possible_track[ possible_track['displayName'] == alls[\"displayName\"].unique()[k]]\n    # removing variables of no interest\n    Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n    \n    # converting into a matrix\n    Y = Y.to_numpy()\n    Y = Y.astype(float)\n    \n    # Bezier curve's order adopted\n    n = 4 \n    m = Y.shape[0]\n\n    # MATRIX T\n    T = []\n    T.insert(0, np.zeros((m,n+1)))\n    t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n    p = 0\n    for h in range(0, n+1):\n        for j in range(0,T[0].shape[0]):\n            T[0][j,p] = b(float(t[j]),h)\n        p = p + 1\n\n    # matrix of estimated points\n    theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n\n    # computation B\u00e9zier curve's output\n    t = np.linspace(start=0, stop=1, num=1000)\n    A = np.zeros((1000,2))\n    for i in range(0,1000):\n        A[i,:] = Bezier_function(t[i],n)\n\n    # plot each defensive movements \n    plt.scatter(Y[:,0], Y[:,1], c='red')\n    \n    # plot estimated points\n    plt.scatter(theta_hat[:,0], theta_hat[:,1], c='blueviolet', s = 200)\n    \n    # plot's dimension proportional to the field\n    plt.xlim([0, 120])\n    plt.ylim([0, 53.3])\n    \n    # line of scrimmage\n    plt.axvline(x= 90, color =  'black')\n    plt.text(90.5, 2, 'line of scrimmage ',fontsize=42, color = 'black',weight = 'bold')\n    \n    # line of endzone\n    plt.axvline(x= 10, color =  'black')\n    plt.text(3, 20, 'ENDZONE ',fontsize=100, color = 'black', weight = 'bold', rotation='vertical')\n    \n    # plot B\u00e9zier curve's output\n    plt.scatter(A[:,0], A[:,1], c='green')\n\n# legend\nviolet_patch = mpatches.Patch(color='blueviolet', label= 'Estimated points')\nred_patch = mpatches.Patch(color='red', label= 'Defensive Team')\ngreen_patch = mpatches.Patch(color='green', label= 'Output B\u00e9zier Curves')\nplt.legend(handles=[violet_patch,red_patch,green_patch], loc='upper right',prop={'size': 30}) \n    \n# plot arrow of the direction of the attack\nplt.arrow(65, 10, -26, 0, length_includes_head=True, head_width=2, head_length=3)\nplt.text(43.5, 10.4, 'direction of attack ',fontsize=42, color = 'black')\n\n# title\nplt.title(\"Estimated points for all defensive movements of this defensive strategy\",size=95)\n\n# caption\nplt.text(60, -5, 'Figure 6', ha='center',size=70);","7df748a6":"# dataframe of tracking data of all defensive players of the passing play that was taken into consideration\nalls = possible_track[possible_track['team']== 'home']\n\n# list of the estimated points for each different passing play\nthetas = []\n\n# loop over all defensive players\nfor k in range(0, len(alls[\"displayName\"].unique())):\n    \n    # filtering tracking data of the passing play taken into consideration, with respect to unique 'displayName' of 'alls'\n    Y = possible_track[ possible_track['displayName'] == alls[\"displayName\"].unique()[k]]\n    \n    # removing variables of no interest\n    Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n    \n    # converting into a matrix\n    Y = Y.to_numpy()\n    Y = Y.astype(float)\n        \n    # Bezier curve's order adopted\n    n = 4 \n    m = Y.shape[0]\n\n    # MATRIX T\n    T = []\n    T.insert(0, np.zeros((m,n+1)))\n    t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n    p = 0\n    for h in range(0, n+1):\n        for j in range(0,T[0].shape[0]):\n            T[0][j,p] = b(float(t[j]),h)\n        p = p + 1\n    \n    # matrix of estimated points\n    theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n    \n    thetas.append(theta_hat)\n            \n    # plot each defensive movements \n    plt.scatter(Y[:,0], Y[:,1], c='red')\n    \n    # plot estimated points of each movement\n    plt.scatter(theta_hat[:,0], theta_hat[:,1], c='blueviolet',s=300)\n    \n    # plot's dimension proportional to the field\n    plt.xlim([0, 120])\n    plt.ylim([0, 53.3])\n    \n    # line of scrimmage\n    plt.axvline(x= 90, color =  'black')\n    plt.text(90.5, 2, 'line of scrimmage ',fontsize=42, color = 'black',weight = 'bold')\n    \n    # line of endzone\n    plt.axvline(x= 10, color =  'black')\n    plt.text(3, 20, 'ENDZONE ',fontsize=100, color = 'black', weight = 'bold', rotation='vertical')\n        \nthetas = np.concatenate(thetas)\n\n# Applying K-means algorithm on the estimated points\nkmeans = KMeans(n_clusters=25)\nkmeans.fit_predict(thetas)\n\n# matrix of the centroids\ncentroids = kmeans.cluster_centers_\n    \n# plot centroids obtained\nplt.scatter(pd.DataFrame(centroids)[0], pd.DataFrame(centroids)[1], c='goldenrod', s = 100);\n\n# legend\nviolet_patch = mpatches.Patch(color='blueviolet', label= 'Estimated points')\nred_patch = mpatches.Patch(color='red', label= 'Defensive Team')\ngolden_patch = mpatches.Patch(color='goldenrod', label= 'Centroids')\nplt.legend(handles=[violet_patch,red_patch,golden_patch], loc='upper right',prop={'size': 30}) \n    \n# plot arrow of the direction of the attack\nplt.arrow(65, 10, -26, 0, length_includes_head=True, head_width=2, head_length=3)\nplt.text(43.5, 10.4, 'direction of attack ',fontsize=42, color = 'black')\n\n# title\nplt.title(\"Centroids obtained with K-Means for this passing play\",size=95)\n\n# caption\nplt.text(60, -5, 'Figure 7', ha='center',size=70);","165acad1":"pd.DataFrame(plays.groupby('personnelD').count()['isDefensivePI'])\n\n# I am going to drop out the only passing play with 4 defensive players in motion in the next cell.","1570f6fb":"# list of all clean passing plays\nkey = []\n\n# empty list for checking purpose\nempty = []\n\n# loop over each different passing play\nfor i in range(0,plays.shape[0]): \n\n    gameID = plays[\"gameId\"][i]\n    playID = plays[\"playId\"][i]\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    focus7 = plays[ plays['gameId'] == gameID ]\n    focus6 = focus7[ focus7['playId'] == playID ].reset_index().drop('index',axis=1)\n    \n    # team in possession of the ball\n    possTeam = focus6.iloc[0,6]\n    \n    # checking which team is the defender\n    focus5 = games[ games['gameId'] == gameID ].reset_index().drop('index',axis=1)\n    if focus5.iloc[0,3] == possTeam:\n        defend = \"away\"\n    else:\n        defend = \"home\"\n    \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"defend\"\n    focus4 = weeks[ weeks['gameId'] == gameID ]\n    focus3 = focus4[ focus4['playId'] == playID ]\n    focus2 = focus3[ focus3['team'] == defend].reset_index().drop('index',axis=1)\n    \n    # names of the players involved in that specific defensive passing play\n    names = focus2['displayName'].unique().astype(str)\n    \n    # checking if the passing play in plays is without a defensive strategy\n    if (names.tolist() != empty ):\n        \n        key.append([gameID,playID,defend])\n\n# converting into a dataframe        \nkey = pd.DataFrame(key)\nkey.columns = ['gameId','playId','Defender']\n\n# index of the passing play with only 4 players in motion\na = key[key['playId'] == int(plays[ plays['personnelD'] == '7 DL, 3 LB, 1 DB' ]['playId'])]\nidx = a[a['gameId'] == int(plays[ plays['personnelD'] == '7 DL, 3 LB, 1 DB' ]['gameId'])].index\n\n# Let's remove the only passing play with 4 defensive players in motion\nkey = key.drop([idx[0]]).reset_index().drop('index',axis=1)\nkey","63db90a1":"# list of centroids obtained from defensive strategy for each passing play, sorted by distance from the end zone (defensive)\nprotos =[]\n\n# loop over each clean passing play\nfor i in range(0,len(key)): \n\n    gameID = key.iloc[i,0]\n    playID = key.iloc[i,1]\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    focus7 = plays[ plays['gameId'] == gameID ]\n    focus6 = focus7[ focus7['playId'] == playID ].reset_index().drop('index',axis=1)\n    \n    # team in possession of the ball\n    possTeam = focus6.iloc[0,6]\n    \n    # checking which team is the defender\n    focus5 = games[ games['gameId'] == gameID ].reset_index().drop('index',axis=1)\n    if focus5.iloc[0,3] == possTeam:\n        defend = \"away\"\n    else:\n        defend = \"home\"\n    \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"defend\"\n    focus4 = weeks[ weeks['playId'] == playID ]\n    focus3 = focus4[ focus4['team'] == defend ]\n    focus2 = focus3[ focus3['gameId'] == gameID].reset_index().drop('index',axis=1)\n    \n    # names of the players involved in that specific defensive passing play\n    names = focus2['displayName'].unique().astype(str)\n    \n    # list of the estimated points for each different passing play    \n    thetas = []\n    \n    # loop over each defensive player's name involved in 'i' passing play\n    for u in range(0, len(names)):\n        \n        # dataframe of tracking data of the \"name\" \n        Y = focus2[focus2['displayName'] == names[u]]\n        \n        # checking if the direction of the attack is from left to right\n        if(focus2.iloc[0,17] == 'right'):\n            \n            # if it is, we flip the passing play in order to have the same direction of the attack for each different passing play (from right to left)\n            xli = []\n            for l in range(0,Y.shape[0]):\n        \n                OldMax = 120\n                OldMin = 0\n                NewMax = 0\n                NewMin = 120\n                OldValue = Y.iloc[l,1]\n        \n                OldRange = (OldMax - OldMin)  \n                NewRange = (NewMax - NewMin)  \n                NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                xli.append(NewValue)\n        \n        \n            yli = []\n            for z in range(0,Y.shape[0]):\n        \n                OldMax = 53.3\n                OldMin = 0\n                NewMax = 0\n                NewMin = 53.3\n                OldValue = Y.iloc[z,2]\n        \n                OldRange = (OldMax - OldMin)  \n                NewRange = (NewMax - NewMin)  \n                NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                yli.append(NewValue)\n    \n            # dataset flipped\n            frames = [pd.DataFrame(xli), pd.DataFrame(yli)]\n            Y = pd.concat(frames,axis=1).reset_index().drop('index',axis=1)\n            \n            \n        if(focus2.iloc[0,17] != 'right'):\n            # removing variables of no interest\n            Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n            \n        # converting into a matrix        \n        Y = Y.to_numpy()\n        Y = Y.astype(float)\n    \n        # Bezier curve's order adopted\n        n = 4 \n        m = Y.shape[0]\n\n        # MATRIX T\n        T = []\n        T.insert(0, np.zeros((m,n+1)))\n        t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n        p = 0\n        for h in range(0, n+1):\n            for j in range(0,T[0].shape[0]):\n                T[0][j,p] = b(float(t[j]),h)\n            p = p + 1\n        \n        # matrix estimated points\n        theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n    \n            \n        thetas.append(theta_hat)\n\n        \n    thetas = np.concatenate(thetas) \n    \n    # Applying K-means algorithm on the estimated points\n    kmeans = KMeans(n_clusters=25)\n    kmeans.fit_predict(thetas)\n    \n    # matrix of the centroids\n    centroids = kmeans.cluster_centers_ \n        \n    # computation of the distance from the end zone (defensive) for the centroids, in order to sort the centroids by distance\n    dist = []\n    for w in range(0,centroids.shape[0]):\n    \n            dist.append(abs( centroids[w][0] - 10 ))\n        \n    protos.append([centroids[qq] for qq in list(np.argsort(dist))])\n        \n        \n\n# PCA on the centroids obtained\n_dataset = []\nfor i in range(0,len(protos)):          \n    \n    pr = np.array(protos[i])\n            \n    pca = PCA(n_components=1, whiten= True)\n    X_pca = pca.fit_transform(pr)\n    \n    _dataset.append(X_pca.tolist())\n    \n\n# transforming into a dataframe \n_dataseT_dif = pd.DataFrame(_dataset)\n\nfor i in range(0,_dataseT_dif.shape[0]):\n    \n    for j in range(0,_dataseT_dif.shape[1]):\n        \n        if _dataseT_dif.iloc[i,j] != None:\n            _dataseT_dif.iloc[i,j] = float(_dataseT_dif.iloc[i,j][0])\n\n_dataseT_dif.columns = ['dif_1','dif_2','dif_3','dif_4','dif_5',\n                        'dif_6','dif_7','dif_8','dif_9','dif_10',\n                        'dif_11','dif_12','dif_13','dif_14','dif_15',\n                        'dif_16','dif_17','dif_18','dif_19','dif_20',\n                        'dif_21','dif_22','dif_23','dif_24','dif_25']\n\n_dataseT_dif","a604969b":"# empty list for checking purpose\nempty = []\n\n# list of all passing plays that do not have offensive strategy.\nnull = []\n\n# loop over each different passing play\nfor i in range(0,len(key)): \n\n    gameID = key.iloc[i,0]\n    playID = key.iloc[i,1]\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    focus7 = plays[ plays['gameId'] == gameID ]\n    focus6 = focus7[ focus7['playId'] == playID ].reset_index().drop('index',axis=1)\n    \n    # team in possession of the ball\n    possTeam = focus6.iloc[0,6]\n    \n    # checking which team is the attacker\n    focus5 = games[ games['gameId'] == gameID ].reset_index().drop('index',axis=1)\n    if focus5.iloc[0,3] == possTeam:\n        attack = \"home\"\n    else:\n        attack = \"away\"\n        \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"attack\"\n    focus4 = weeks[ weeks['playId'] == playID ]\n    focus3 = focus4[ focus4['team'] == attack ]\n    focus2 = focus3[ focus3['gameId'] == gameID].reset_index().drop('index',axis=1)\n        \n    # names of the players involved in that specific offensive passing play\n    names = focus2['displayName'].unique().astype(str)\n    \n    # checking if the passing play in key is without a offensive strategy\n    if (names.tolist() == empty ):\n           null.append(i)\n            \n# Dropping passing plays whitout no offensive strategies\nkey = key.drop(null).reset_index().drop('index',axis=1)\n_dataseT_dif = _dataseT_dif.drop(null).reset_index().drop('index',axis=1)\n\n# list of the passing plays with 4 offensive players in motion\nmin_4 = []\n\n# list of centroids obtained from offensive strategy for each passing play, sorted by distance from the end zone (defensive)\nprotos = []\n\n# loop over each passing play in key\nfor i in range(0,len(key)): \n\n    gameID = key.iloc[i,0]\n    playID = key.iloc[i,1]\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    focus7 = plays[ plays['gameId'] == gameID ]\n    focus6 = focus7[ focus7['playId'] == playID ].reset_index().drop('index',axis=1)\n    \n    # team in possession of the ball\n    possTeam = focus6.iloc[0,6]\n\n    # checking which team is the attacker\n    focus5 = games[ games['gameId'] == gameID ].reset_index().drop('index',axis=1)\n    if focus5.iloc[0,3] == possTeam:\n        attack = \"home\"\n    else:\n        attack = \"away\"\n        \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"attack\"\n    focus4 = weeks[ weeks['playId'] == playID ]\n    focus3 = focus4[ focus4['team'] == attack ]\n    focus2 = focus3[ focus3['gameId'] == gameID].reset_index().drop('index',axis=1)\n        \n    # names of the players involved in that specific offensive passing play\n    names = focus2['displayName'].unique().astype(str)\n    \n    # checking if the passing play has more than 4 offensive players in motion\n    if (len(names) != 4 ):\n        \n        # list of the estimated points for each different passing play  \n        thetas = []\n        \n        # loop over each offensive player's name involved in 'i' passing play\n        for u in range(0, len(names)):\n                     \n            # dataframe of tracking data of the \"name\"\n            Y = focus2[focus2['displayName'] == names[u]]\n            \n            # checking if the direction of the attack is from left to right\n            if(focus2.iloc[0,17] == 'right'):\n                \n                # if it is, we flip the passing play in order to have the same direction of the attack for each different passing play (from right to left)\n                xli = []\n                for l in range(0,Y.shape[0]):\n        \n                    OldMax = 120\n                    OldMin = 0\n                    NewMax = 0\n                    NewMin = 120\n                    OldValue = Y.iloc[l,1]\n        \n                    OldRange = (OldMax - OldMin)  \n                    NewRange = (NewMax - NewMin)  \n                    NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                    xli.append(NewValue)\n        \n        \n                yli = []\n                for z in range(0,Y.shape[0]):\n        \n                    OldMax = 53.3\n                    OldMin = 0\n                    NewMax = 0\n                    NewMin = 53.3\n                    OldValue = Y.iloc[z,2]\n        \n                    OldRange = (OldMax - OldMin)  \n                    NewRange = (NewMax - NewMin)  \n                    NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                    yli.append(NewValue)\n    \n                # dataset flipped\n                frames = [pd.DataFrame(xli), pd.DataFrame(yli)]\n                Y = pd.concat(frames,axis=1).reset_index().drop('index',axis=1)\n            \n            \n            if(focus2.iloc[0,17] != 'right'):\n                # removing variables of no interest\n                Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)\n            \n            # converting into a matrix      \n            Y = Y.to_numpy()\n            Y = Y.astype(float)\n    \n            # Bezier curve's order adopted\n            n = 4 \n            m = Y.shape[0]\n\n            # MATRIX T\n            T = []\n            T.insert(0, np.zeros((m,n+1)))\n            t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n            p = 0\n            for h in range(0, n+1):\n                for j in range(0,T[0].shape[0]):\n                    T[0][j,p] = b(float(t[j]),h)\n                p = p + 1\n\n            # matrix estimated points\n            theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n    \n            \n            thetas.append(theta_hat)\n\n        \n        thetas = np.concatenate(thetas)\n        \n        # Applying K-means algorithm on the estimated points\n        kmeans = KMeans(n_clusters = 25)\n        kmeans.fit_predict(thetas)\n        \n        # matrix of the centroids\n        centroids = kmeans.cluster_centers_ \n    \n        # computation of the distance from the end zone (defensive) for the centroids, in order to sort the centroids by distance\n        dist = []\n        for w in range(0,len(centroids)):\n    \n            dist.append(abs( centroids[w][0] - 10 ))\n        \n        protos.append([centroids[qq] for qq in list(np.argsort(dist))])\n    \n    else:\n        min_4.append(i)\n\n\n# Let's remove the passing plays with 4 offensive players in motion from key and _dataseT_dif\nkey = key.drop(min_4).reset_index().drop('index',axis=1)\n_dataseT_dif = _dataseT_dif.drop(min_4).reset_index().drop('index',axis=1)\n\n# PCA on the centroids obtained\n_dataset_off = []\nfor i in range(0,len(protos)):          \n    \n    pr = np.array(protos[i])\n            \n    pca = PCA(n_components=1, whiten= True)\n    X_pca = pca.fit_transform(pr)\n    \n    _dataset_off.append(X_pca.tolist())\n    \n# transforming into a dataframe \n_dataseT_off = pd.DataFrame(_dataset_off)\n\nfor i in range(0,_dataseT_off.shape[0]):\n    \n    for j in range(0,_dataseT_off.shape[1]):\n        \n        if _dataseT_off.iloc[i,j] != None:\n            _dataseT_off.iloc[i,j] = float(_dataseT_off.iloc[i,j][0])\n\n_dataseT_off.columns = ['att_1','att_2','att_3','att_4',\n                        'att_5','att_6','att_7','att_8','att_9',\n                        'att_10','att_11','att_12','att_13','att_14',\n                        'att_15','att_16','att_17','att_18','att_19',\n                        'att_20','att_21','att_22','att_23','att_24','att_25']\n_dataseT_off","3239b403":"# list of the estimated points for each different passing play\nthetas = []\n\n# empty list for checking purpose\nempty = []\n\n# loop over each clean passing play in key\nfor i in range(0,len(key)): \n\n    gameID = key.iloc[i,0]\n    playID = key.iloc[i,1]\n    \n    # filtering of weeks with that specific values of \"gameID\", \"playID\" and \"football\"\n    focus4 = weeks[ weeks['playId'] == playID ]\n    focus3 = focus4[ focus4['team'] == 'football' ]\n    focus2 = focus3[ focus3['gameId'] == gameID].reset_index().drop('index',axis=1)\n    \n    # names of the ball involved in that specific passing play \n    names = focus2['displayName'].unique().astype(str)\n    \n    # checking if the passing play in plays is without ball's movement\n    if (names.tolist() != empty ):\n        \n        # loop over each element in \"names\" for each 'i' passing play\n        for u in range(0, len(names)):\n            \n            # dataframe of tracking data of the ball \n            Y = focus2[focus2['displayName'] == names[u]]\n            \n            # checking if the direction of the attack is from left to right\n            if(focus2.iloc[0,17] == 'right'):\n                \n                # if it is, we flip the passing play in order to have the same direction of the attack for each different passing play (from right to left)\n                xli = []\n                for l in range(0,Y.shape[0]):\n        \n                    OldMax = 120\n                    OldMin = 0\n                    NewMax = 0\n                    NewMin = 120\n                    OldValue = Y.iloc[l,1]\n        \n                    OldRange = (OldMax - OldMin)  \n                    NewRange = (NewMax - NewMin)  \n                    NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                    xli.append(NewValue)\n        \n        \n                yli = []\n                for z in range(0,Y.shape[0]):\n        \n                    OldMax = 53.3\n                    OldMin = 0\n                    NewMax = 0\n                    NewMin = 53.3\n                    OldValue = Y.iloc[z,2]\n        \n                    OldRange = (OldMax - OldMin)  \n                    NewRange = (NewMax - NewMin)  \n                    NewValue = (((OldValue - OldMin) * NewRange) \/ OldRange) + NewMin\n    \n                    yli.append(NewValue)\n    \n                # dataset flipped\n                frames = [pd.DataFrame(xli), pd.DataFrame(yli)]\n                Y = pd.concat(frames,axis=1).reset_index().drop('index',axis=1)\n            \n            \n            if(focus2.iloc[0,17] != 'right'):\n                # removing variables of no interest\n                Y = Y.drop(['time','s','a','dis','o','dir','event','nflId','displayName','jerseyNumber','position','frameId','team','gameId','playId','playDirection','route'],axis=1)           \n            \n            # converting into a matrix     \n            Y = Y.to_numpy()\n            Y = Y.astype(float)\n    \n            # Bezier curve's order adopted\n            n = 4 \n            m = Y.shape[0]\n\n            # MATRIX T\n            T = []\n            T.insert(0, np.zeros((m,n+1)))\n            t  =  np.linspace(0, 1,T[0].shape[0], endpoint = True )\n\n            p = 0\n            for h in range(0, n+1):\n                for j in range(0,T[0].shape[0]):\n                    T[0][j,p] = b(float(t[j]),h)\n                p = p + 1\n            \n            # matrix estimated points\n            theta_hat = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(T[0]), T[0])),np.transpose(T[0])),Y)\n    \n         \n        thetas.append(theta_hat)\n            \n\n# PCA on the estimated points obtained        \n_dataset_ball = []\nfor i in range(0,len(thetas)):          \n    \n    pr = np.array(thetas[i])\n            \n    pca = PCA(n_components=1, whiten= True)\n    X_pca = pca.fit_transform(pr)\n    \n    _dataset_ball.append(X_pca.tolist())\n    \n# transforming into a dataframe \n_dataseT_ball = pd.DataFrame(_dataset_ball)\n\nfor i in range(0,_dataseT_ball.shape[0]):\n    \n    for j in range(0,_dataseT_ball.shape[1]):\n        \n        if _dataseT_ball.iloc[i,j] != None:\n            _dataseT_ball.iloc[i,j] = float(_dataseT_ball.iloc[i,j][0])\n\n_dataseT_ball.columns = ['ball_1','ball_2','ball_3','ball_4','ball_5']\n_dataseT_ball","95d750ed":"# Each average information is a nested list. Each average[i] has as the fist element the information regarding the defensive movements,\n# the second element regarding the information about the offensive movements, the third element regarding the information about \n# the ball's movement. This is done for each passing play.\naverage_s = []\naverage_a = []\naverage_dis = []\naverage_o = []\naverage_dir = []\n\n# loop over each passing play in key\nfor i in range(0,len(key)): \n    \n    # filtering of weeks with that specific values of \"playID\" \n    a = weeks[weeks['playId'] == key.iloc[i,1]]\n    \n    #Defender\n    b = a[a[\"team\"] == key.iloc[i,2]]\n    c = b[b[\"gameId\"] == key.iloc[i,0]]\n    average_s.append([np.mean(c['s'])])\n    average_a.append([np.mean(c['a'])])\n    average_dis.append([np.mean(c['dis'])])\n    average_o.append([np.mean(c['o'])])\n    average_dir.append([np.mean(c['dir'])])\n    \n    \n    if key.iloc[i,2] == 'away':\n        rr = 'home'\n    else:\n        rr = 'away'\n    #Attacker\n    b = a[a[\"team\"] == rr  ]\n    c = b[b[\"gameId\"] == key.iloc[i,0]]\n    average_s[i].append(np.mean(c['s']))\n    average_a[i].append(np.mean(c['a']))\n    average_dis[i].append(np.mean(c['dis']))\n    average_o[i].append(np.mean(c['o']))\n    average_dir[i].append(np.mean(c['dir']))\n    \n    \n    #Ball\n    b = a[a[\"team\"] == 'football' ]\n    c = b[b[\"gameId\"] == key.iloc[i,0]]\n    average_s[i].append(np.mean(c['s']))\n    average_a[i].append(np.mean(c['a']))\n    average_dis[i].append(np.mean(c['dis'])) \n    \n\n# converting into a dataframe\nspeed = pd.DataFrame(average_s)\nspeed.columns = ['speed_dif','speed_att','speed_ball']\n\nacc = pd.DataFrame(average_a)\nacc.columns = ['acc_dif','acc_att','acc_ball']\n\ndis = pd.DataFrame(average_dis)\ndis.columns = ['dis_dif','dis_att','dis_ball']\n\no = pd.DataFrame(average_o)\no.columns = ['o_dif','o_att']\n\ndire = pd.DataFrame(average_dir)\ndire.columns = ['dire_dif','dire_att']\n\n\n\nadd_info = []\n\n# loop over each passing play in 'key'\nfor i in range(0,len(key)):\n    \n    # filtering of plays with that specific values of \"playID\" and 'gameID'\n    a = plays[plays['playId'] == key.iloc[i,1]]\n    b = a[a[\"gameId\"] == key.iloc[i,0]]\n    \n    # adding 'epa' for the passing play 'i'\n    add_info.append(b['epa'].reset_index().drop('index',axis=1).iloc[0,0]) \n    \nadd_info = pd.DataFrame(add_info)\nadd_info.columns = ['epa'] \nadd_info","b73aca29":"frames = [_dataseT_dif,_dataseT_off,_dataseT_ball,speed,acc,dis,o,dire,add_info]\n__final_ = pd.concat(frames,axis=1)\n__final_","85edab41":"# response variable\n_y = []\n\n# loop over each passing play in key\nfor i in range(0,len(key)):\n    \n    # filtering of plays with that specific values of \"gameID\" and \"playID\"\n    a = plays[plays['playId'] == key.iloc[i,1]]\n    b = a[a[\"gameId\"] == key.iloc[i,0]]\n    \n    # value of 'isDefensivePI' \n    _y.append([b['isDefensivePI'].reset_index().drop('index',axis=1).iloc[0,0]])\n    \n_y = pd.DataFrame(_y)\n_y.columns = ['isDefensivePI']\n_y","2ce28c96":"from sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import precision_score,recall_score\nfrom sklearn.metrics import confusion_matrix","8ff21d97":"_y.isDefensivePI.value_counts()","04207a58":"from sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\ny_encoder = ordinal_encoder.fit_transform(_y)\ny_encoder = np.transpose(y_encoder)\ny_encoder = y_encoder[0].astype(np.float64)\ny_encoder\n\nX = np.array(__final_).astype(np.float64)\n\n# Splitting into train and test maintaing the Imbalance Ratio\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits= 1, test_size=0.25)\nfor train_index, test_index in split.split(_y,_y['isDefensivePI']):\n    y_train = y_encoder[train_index]\n    y_test = y_encoder[test_index]\n    \n    X_train = X[train_index]\n    X_test = X[test_index]","7150dd2b":"from imblearn.ensemble import BalancedRandomForestClassifier\n\n# fitting the model\nbrf = BalancedRandomForestClassifier()\nbrf.fit(X_train, y_train) \n\n# checking the scores\ny_pred = brf.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2)}')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","12c325b5":"from imblearn.ensemble import RUSBoostClassifier\n\n# fitting the model\nrusboost = RUSBoostClassifier(algorithm='SAMME.R')\nrusboost.fit(X_train, y_train)  \n\n# checking the scores\ny_pred = rusboost.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","6331fed5":"from imblearn.ensemble import EasyEnsembleClassifier\n\n# fitting the model\neec = EasyEnsembleClassifier()\neec.fit(X_train, y_train) \n\n# checking the scores\ny_pred = eec.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","bb220eba":"from imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# fitting the model\nbbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(), sampling_strategy='auto',replacement=False)\nbbc.fit(X_train, y_train) \n\n# checking the scores\ny_pred = bbc.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","a06506d9":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n\n# fitting the model\nsvm_clf = Pipeline([\n        (\"scaler\",StandardScaler()),\n        (\"linear_svc\",LinearSVC(C=10,loss=\"hinge\"))\n    ])\nsvm_clf.fit(X_train, y_train) \n\n# checking the scores\ny_pred = svm_clf.predict(X_test)\n\nprint(f'The balanced accuracy is: {balanced_accuracy_score(y_test, y_pred) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {precision_score(y_test,y_pred)}')\nprint(f'The recall is: {recall_score(y_test,y_pred)}')","3efdedf7":"from sklearn.ensemble import RandomForestClassifier\n\n# fitting the model\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train) \n\n# checking the scores\ny_pred = rfc.predict(X_test)\n\nprint(f'The balanced accuracy is: {balanced_accuracy_score(y_test, y_pred) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {precision_score(y_test,y_pred)}')\nprint(f'The recall is: {recall_score(y_test,y_pred)}')","e21a8f3e":"import xgboost\n\n# fitting the model\nxgb_clf = xgboost.XGBClassifier()\nxgb_clf.fit(X_train,y_train)\n\n# checking the scores\ny_pred = xgb_clf.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","b8996231":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# fitting the model\nada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), \n                             algorithm='SAMME.R', learning_rate=0.5, n_estimators=200)\nada_clf.fit(X_train, y_train)\n\n# checking the scores\ny_pred = ada_clf.predict(X_test)\n\nprint(f'The balanced accuracy is: {round(balanced_accuracy_score(y_test, y_pred),2) }')\nprint(f'The confusion matrix is: \\n {confusion_matrix(y_test,y_pred)}')\nprint(f'The precision is: {round(precision_score(y_test,y_pred),2)}')\nprint(f'The recall is: {round(recall_score(y_test,y_pred),2)}')","badf474f":"# Each passing play is different","01c9fab3":"- In the ball's movements, we do not need to use K-means technique since the ball's movement is not characterized by a personnel. We can incorporate the estimated points directly into our dataset (after transforming them into a feature vector by using PCA).","984b9803":"### Easy Ensemble classifier","8202d41b":"[Mattia Arsendi](https:\/\/mattia-arsendi.netlify.app\/)","ab08a3e4":"A different number of moving defensive players is involved in each passing play. This means that, depending on the personnel used into the defensive strategy, we have a **different number of estimated points.** So as observed before, we obtained a $35 \\times 2$ matrix because there were seven moving defensive players involved. But, if nine moving defensive players had been involved, you would have obtained a $45 \\times 2$ matrix.\n\nTo apply a classification algorithm, we need a dataset in which each observation has the same number of features. Once the dimensionality reduction is applied, the obtained feature vector might have a different dimension depending on the moving defensive players involved in that specific passing play. To avoid this problem, the [K-means](https:\/\/www.youtube.com\/watch?v=4b5d3muPQmA&t=85s) technique is applied. In essence, **each** passing play's estimated points are **replaced** by a **fixed number** of **centroids** which is the **same** for each passing play. Therefore, the PCA is applied to **the centroids**. \n\n*The advantage?* Every passing play has a defensive strategy defined by **the same number** of points (**centroids obtained**) even though a different personnel is used.\n\n*The disadvantage?* You can lose some information after using the K-means technique because we represent fewer centroids as replacements for the estimated points.\n\nThis heuristic method gives us a **good trade-off** between representation and classification's practicability. ","6da29fda":"# Modeling movements to predict Defensive Pass Interference","82de5f3c":"As you can imagine, each passing play has its defensive strategy in which a different number of moving defenders is involved. By restating what we implied before, we should define new variables that can accurately collect the relevant information from the tracking data (\u2705), **for each different passing play.**","d6acb71d":"The first step is to get a closer look at the two datasets that we are going to **manipulate** mainly in this analysis:\n- *plays*: containing the information about all passing plays during the 2018 regular season.","0c143623":"As you can imagine, we have more passing plays that do not have DPI fouls than the passing plays that do have them. Meaning, we are working with an extremely unbalanced dataset. Specifically, the Imbalance Ratio (IR) is equal to 0.01.","3af73250":"### RUSBoost","6f03aafe":"As we can observe, the curve obtained from the fourth-order B\u00e9zier curve is similar to the player's movement!\n\nIf we had chosen to adopt a higher number of estimated points, we would have obtained B\u00e9zier curves' output closer to that of actual movement. **The power** of seeing B\u00e9zier curves through a **statistical point of view** is that you can not only compute an estimate of points that uniquely describes the movement, [**but also identify the \u201dcorrect order\u201d of the B\u00e9zier curve.**](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHfghZG8) Namely, the order that can represent the movement **without losing the signal**, but at the same time, it can **avoid over-fitting.**\n\nIn this context, I decided to adopt the B\u00e9zier curve of **fourth-order** since it seemed a **good trade-off** by looking at the [AIC values](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHipHaLM). ","a0c9cc8f":"The \"standard\" classification algorithms, such as Random Forest or Linear SVC, do not work correctly with this type of dataset. Therefore, we will use algorithms that perform appropriately with an unbalanced dataset from the library [*imbalanced-learn*](https:\/\/github.com\/scikit-learn-contrib\/imbalanced-learn).\n\nWe will try to maintain this Imbalance Ratio when we split the dataset in train and test set, trying to keep the representativeness of the results.","6e471a93":"### Adaboost","c4977a2c":"# Offensive strategies and ball's movements","e26d0fa7":"Now, by extending the approach of the estimated points to each movement of this analyzed defensive strategy, we can obtain the following result:","eed26b52":"We have now obtained a *new* dataset that can effectively represent the **relevant information** from the tracking data, and in which a **classification algorithm** can be applied to predicting DPI penalties.\n\nIn other words, we can now **predict** whether a Defensive Pass Interference will be called on the analyzed passing play, based on the **tracking data**!","728df23d":"# Other useful features","41e64e5e":"Having seen how defining a set of **new variables** that can accurately **collect** the relevant information from the tracking data for the **defensive strategies**, let's apply the same approach to the **offensive strategies** and to the **ball's movements!**\n\nSomeone may wonder, why should we also consider these movements? On the other hand, the DPI is committed by the defensive team. \n\nTrue, the DPI is committed by the defensive team, but it is also affected by the offensive strategy and ball's movement. They are both parts of the passing play. Thus, to add this information on the dataset just obtained, the same approach is applied to offensive strategies and ball's movements. ","af9c6a6d":"### Balanced Random Forest","eaaad10b":"The only small differences from the method shown above are: \n\n- In the case of offensive strategies, we need to delete 4 passing plays to increase the representativeness's power by using 25 centroids. Namely, all the passing plays have a minimum of 5 moving offensive players except for 4 passing plays.","cc5f14b3":"### XGBoost","d74a78bf":"Before generalizing the method to each defensive strategy of each passing play, we need to clean the dataset *plays* since some passing plays may not have defensive strategy. The data frame obtained called *key* becomes the reference point since it collects *gameId*, *playId* and the *defender team* of each *clean* passing play.","48ef3db8":"After the generalization, we obtain a dataset in which each passing play is characterized by dif$_1$, ..., dif$_{25}$. These values result from the PCA's application on the 25 centroids, which were obtained from the estimated points of each different passing play.","7a2c55ce":"A $35 \\times 2$ matrix containing the estimated points has been obtained for this particular defensive strategy ( 5 estimated points for each of the seven moving players involved in this passing play).\n\nLet's see now how this matrix can be **effectively transformed** into a feature vector for this passing play.","c1ce51c9":"In this specific context, we do not want to lose too much information when using K-means to define fewer centroids as replacements for each passing play's estimated points. Thus, we should use the **largest possible number** of centroids. The largest possible number of centroids corresponds to the minimum number of moving defensive players involved in a passing play multiplied by five.\n\nBy looking at the variable *personnelD* in *plays*, that shows personnel used by the defensive team, we can spot that all the passing plays have a minimum of 5 defenders in motion except for one single passing play. Therefore, I have chosen to delete this observation to increase the number of centroids (used for **each** passing play) from 20 to 25, **by enhancing the power of the centroids' representativeness!**","0ba07cb4":"# How to gather information from tracking data","e840eeb7":"Given the impact that DPI might have on the match, I would prefer to recognize as many DPI as possible to provide the treatment they deserve. Therefore, I would pick the model that has the **highest recall**, and the Easy Ensemble classifier is the right option.\n\nIn any case, each coach has his\/her opinion. Someone may prefer to be sure about predicting that the passing play actually has a DPI foul, at the risk of not to detect all them. In this case, the XGboost can be adopted since it has the **highest precision**.\n\nThe results obtained can be improved by:\n- analyzing the optimal threshold\n- hyperparameter optimization\n- And ... **I am open to any suggestion!**","9c0cc8db":"The dataset *weeks* also contains information regarding each movement, such as speed and acceleration. Incorporating these into the new dataset is crucial in **enhancing** the data\u2019s **quality**.\n\nMoreover, to **contextualize** each passing play, adding the variable *epa* from *plays* is necessary. This variable estimates the average of the next scoring outcome given the **down**, **distance**, **yardline** and **time remaining**. By doing so, each passing play is also characterized by its **game characteristics**.","7dae4524":"# Datasets","ca1c2e49":"## What is the \"right\" number of centroids that you should adopt?","44d1f4ff":"Imagine being an **NFL coach** behind the desk of his\/her office. With our staff's help, we are analyzing a bunch of several passing plays shown in the huge monitor in front of us. The goal? *Studying the defensive strategies that can hinder the opponent's strength we will have to face.* \n\nIt is **right at this moment** that the approach shown in this notebook can be useful. Namely, can we **predict** whether a **Defensive Pass Interference will be called** on the analyzed passing play, based on **the players' movements?** \n\nIn other words, let's imagine that the monitor in front of us visualizes this particular scenario:","a0247c3d":"- *weeks*: containing all the passing plays' tracking data in *plays*.","b377abd2":"## Dimensionality reduction\n\nTo use the matrix of estimated points as the feature vector of this passing play, a technique of dimensionality reduction is necessary. In this context, the primary linear technique called Principal Component Analysis, is used. By applying PCA, the $35 \\times 2$ matrix can be **transformed** into a $35 \\times 1$ array. By doing so, the transformation can be applied as **the new feature vector of that specific passing play.**","25519538":"Using the dataset *weeks* as it is, is **unthinkable**. We need a method that can **model** the movement for each player **without losing too much information.** \n\nThe technique used in this notebook is based on [B\u00e9zier curves](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHfghZEE), which are parametric curves that can be seen from a statistical point of view. More information about this method's theory can be found in my [Final Bachelor\u2019s Project](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/view); in this notebook, the key concepts are shown.\n\nBy applying this method, we will **estimate a set of points** (in two-dimensional Euclidean space) which can **uniquely describe the movement of interest.** Let's see an example.","b61e6ce2":"# Predicting DPI","261a4966":"### Random Forest ","40d09f6e":"[**Defensive Pass Interference (DPI)**](https:\/\/operations.nfl.com\/the-rules\/nfl-video-rulebook\/defensive-pass-interference\/#:~:text=It%20is%20pass%20interference%20by,opportunity%20to%20catch%20the%20ball) is a crucial aspect that **can shift the balance of the match.** Therefore, we would like to keep it into consideration during the analysis of the defensive strategies. Namely, by moving in this way in response to this passing play, **will we commit a DPI?** \n\nOnce we answer this question, we will be able **to avoid defensive strategies that could lead the team into a DPI.**\n\nBy keeping in mind this goal, let's move towards how to build an answer to this question.","bc36d4b4":"In other words, instead of using all observations of the movement, **these five estimated points** (purple points) can **uniquely identify this particular movement!** \n\nWhether you would like to test if these estimated points actually refer uniquely to that specific movement, then let's observe that by computing the output of the B\u00e9zier curve of [fourth-order](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHhgt1Ek) for 1000 values of $ t \\in [0,1] $,  by fixing $ p_0, p_1, p_2, p_3, p_4 $ equal to the estimated points computed.","06c840a1":"### Balanced Bagging","59344bd3":"### Linear SVC","5faa5211":"The above graph shows the same passing play that was seen before (Figure 2), but our focus now is on the movement of the player coloured in orange. Given this smooth trajectory, we can [estimate](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHfghZGY) (exploiting B\u00e9zier curves [through a statistical point of view](https:\/\/drive.google.com\/file\/d\/1iNhRpEiCRHS9hBGmFIaWpwjpHlpKui5N\/edit?disco=AAAAHfghZDw)) a new set of points that **uniquely** describes this **movement.**","e6ae4acc":"# Defensive strategy of each passing play","006608be":"After a large number of intensive meetings with our staff, we have decided that the following strategy is the best way to countering this passing play.","eeff4f53":"As we can observe, **each passing play** in *plays* is uniquely identified by a **combination of two variables**: *playId* and *gameId*.\n\nTo answer whether a DPI will be called or not, the two datasets *weeks* and *plays* are manipulated, in order to obtain a **new dataset** in which **classification algorithms** can be applied.\n\nWe want to obtain a **new dataset** in which each row is a passing play characterized by a set of **new** features. These **new** features should **efficiently collect** compelling **information** from the dataset *weeks* and *plays*, for **each different** passing play. ","e414b31e":"# Problem"}}