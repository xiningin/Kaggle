{"cell_type":{"fac14343":"code","4bb7e8bb":"code","0eb1d789":"code","00b3baf8":"code","9cc0507a":"code","31719796":"code","a5f9e04e":"code","8007bfcd":"code","d4b6b3e3":"code","83ea110a":"code","d57abf7e":"code","2257481f":"code","b3347f73":"code","daf5546c":"code","d0f96f5e":"code","2ed9af54":"code","20890a3f":"code","1aac3d00":"code","6c35955d":"code","a8af34a8":"code","92a0fd1c":"code","28d7c22a":"code","07af9d47":"code","fc934b20":"code","388c2b53":"code","0c169efb":"code","6f47ea4c":"code","ef4a0849":"code","8a0b7518":"code","dd264f24":"code","49959a24":"code","d76315e0":"code","2871be95":"code","f5ecd698":"code","31b8235a":"code","1e188a26":"code","660e19f9":"code","0705f291":"code","cebf078f":"code","1e9b0b50":"code","09f566d8":"code","59c1997c":"code","20a3259d":"code","f98ede2d":"code","32930e9c":"code","e50f6f13":"code","00658de2":"code","90c4e634":"code","0cd20078":"code","59f7aec8":"code","d6b304e4":"code","c825683a":"code","f6f1d614":"code","50c2b0a5":"code","29f8efe5":"code","a80c4b60":"code","a124580f":"code","962cae8d":"code","a5114d7f":"code","62f52795":"code","0ff82652":"code","225a41c7":"code","61139e69":"code","f444b0c4":"code","b462e8fe":"code","3c3f6831":"code","8882ec48":"code","da230bcb":"code","3446fa71":"code","4d861f53":"code","baab1948":"code","0f222ba3":"code","20e09a8d":"code","8e6a630e":"code","7856fdc7":"code","7f78f21c":"code","bf7164c8":"code","976ccff2":"code","aa877d9a":"code","659b33b3":"code","e8d94087":"code","bf24946d":"code","4913c7eb":"code","b0577a32":"code","9a86dcd0":"code","b6bfb491":"code","fab29c4a":"code","f7cc94cb":"code","1bdc2482":"code","a7317a4d":"code","e49aea2f":"code","25667e59":"code","13f19df5":"code","44bc4eb7":"code","d9781d0e":"code","3e2ed9a7":"code","acbee0e4":"code","5997217c":"code","565fa8ae":"code","faff77d4":"code","466e97f1":"code","c2da4900":"code","a57d2714":"code","31a64905":"code","cd42a164":"code","72fc5dd4":"code","56b0563c":"code","9090f7f0":"code","80fb62df":"code","43b48ea7":"code","412819bc":"code","883de9a7":"code","a2e005a4":"code","18befbdb":"code","2970f9ad":"code","b360c8c3":"code","52fde8db":"code","37b42279":"code","a205bee3":"code","42423d82":"code","cffa48b4":"code","5c28c981":"code","eb685f27":"code","37e93667":"code","aef6b9ad":"markdown","87bb7dac":"markdown","65377589":"markdown","b47f562a":"markdown","b3ef003b":"markdown","18aa907c":"markdown","56a3393b":"markdown","7168e9d7":"markdown","976f7033":"markdown","b6bda267":"markdown","d406e52a":"markdown","764514ce":"markdown","26479d21":"markdown","d0c0423c":"markdown","a4f8854f":"markdown","46de7ca4":"markdown","35038279":"markdown"},"source":{"fac14343":"# suppress display of warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 'Pandas' is used for data manipulation and analysis\nimport pandas as pd \n\n# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\nimport numpy as np\n\n# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\n# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\nimport seaborn as sns\n\n# import 'is_string_dtype' to check if the type of input is string  \nfrom pandas.api.types import is_string_dtype\n\n# import various functions to perform classification\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.tree import export_graphviz\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import SVC\n\n# import various functions to perform regression\nfrom sklearn.linear_model import SGDClassifier\nimport statsmodels\nimport statsmodels.api as sm\nfrom sklearn import linear_model\n\n#importing library for scaling data\nfrom sklearn.preprocessing import MinMaxScaler\n\n# display all columns of the dataframe\npd.options.display.max_columns = None","4bb7e8bb":"#setting the plot size using rcParams\nplt.rcParams['figure.figsize'] = [15,8]","0eb1d789":"#importing data set for training the models\ndf=pd.read_csv(\"..\/input\/titanic\/train.csv\")","00b3baf8":"#printing the first 5 records from the training data set\ndf.head()","9cc0507a":"#checking the number of rows and columns in the training data set\ndf.shape","31719796":"#\"info\" gives us the column names and their data types along with null values if any in the columns\ndf.info()","a5f9e04e":"#understanding the data types with the unique values of each column\nfor i in df.columns:\n    print(i,\"----->\",df[i].nunique(),'----->',df[i].dtypes)","8007bfcd":"#converting the data types of the columns \n#As the columns mentioned in 'cols' list are of integer type whereas they have very less unique values\ncols=['Pclass','Survived','SibSp','Parch','Embarked']\nfor i in cols:\n    df[i]=df[i].astype('object')","d4b6b3e3":"#plotting the histogram of numerical variables\ndf.hist(figsize=(15,8))\nplt.tight_layout()\nplt.show()","83ea110a":"#using boxplot to see if there are outliers\nsns.boxplot(x=df['Age'])\nplt.show()","d57abf7e":"#Checking number of passengers died and survived in the mishap as per the dataset\nprint(\"Number of passengers died:\",(df['Survived']==0).sum())\nprint(\"Number of passengers survived:\",(df['Survived']==1).sum())","2257481f":"#plotting the column survived\nsns.countplot(df['Survived'])\nplt.title(\"Count of Number of passengers died and number of passengers survived\")\nplt.show()","b3347f73":"df.columns","daf5546c":"# create a list of all categorical variables\n# initiate an empty list to store the categorical variables\ncategorical=['Survived', 'Pclass','Sex','SibSp','Parch','Embarked']\n\n# plot the count plot for each categorical variable \nfig, ax = plt.subplots(nrows = 2, ncols = 3, figsize=(25, 30))\n\n# use for loop to plot the count plot for each variable\nfor variable, subplot in zip(categorical, ax.flatten()):\n    \n    # use countplot() to plot the graph\n    sns.countplot(df[variable], ax = subplot)\n\n# display the plot\nplt.show()","d0f96f5e":"#Checking passengers survived with respect to parents onboard\nsns.countplot(df.Survived,hue=df.Parch,order=df['Survived'].value_counts().iloc[1:2].index)\nplt.show()","2ed9af54":"#Checking passengers survived with respect to parents onboard\nsns.countplot(df.Survived,hue=df.Sex,order=df['Survived'].value_counts().iloc[1:2].index)\nplt.show()","20890a3f":"#Checking passengers survived with respect to parents onboard\nsns.countplot(df.Survived,hue=df.Embarked,order=df['Survived'].value_counts().iloc[1:2].index)\nplt.show()","1aac3d00":"#Checking passengers survived with respect to parents onboard\nsns.countplot(df.Survived,hue=df.SibSp,order=df['Survived'].value_counts().iloc[1:2].index)\nplt.show()","6c35955d":"#Checking passengers survived with respect to parents onboard\nsns.countplot(df.Survived,hue=df.Pclass,order=df['Survived'].value_counts().iloc[1:2].index)\nplt.show()","a8af34a8":"#checking the correlation between variables\n# use the corr() function to generate the correlation matrix of the numeric variables\ncorr = df.corr()\n\n# print the correlation matrix\ncorr","92a0fd1c":"#for visualisation plotting the heatmap of correlation\ncorrelation=df.corr()\nplt.figure(figsize=(10, 10))\nsns.heatmap(correlation[(correlation >= 0.5) | (correlation <= -0.5)],\n            annot=True,linewidths=.1,linecolor=\"blue\")\nplt.title('Correlation between features', fontsize=15)\nplt.show()","28d7c22a":"#Checking for null values\nTotal = df.isnull().sum().sort_values(ascending = False)          \n\n# calculate the percentage of missing values\n# 'ascending = False' sorts values in the descending order\n# the variable with highest percentage of missing values will appear first\nPercent = ((Total*100)\/df.isnull().count()).sort_values(ascending = False)   \n\n# concat the 'Total' and 'Percent' columns using 'concat' function\n# 'keys' is the list of column names\n# 'axis = 1' concats along the columns\nmissing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])    \nmissing_data","07af9d47":"# plot heatmap to check null values\n# 'cbar = False' does not show the color axis \nsns.heatmap(df.isnull(), cbar=False)\n\n# display the plot\nplt.show()","fc934b20":"#dropping the cabin column\ndf=df.drop('Cabin',axis=1)","388c2b53":"#checking different parameters of age,so that we can analyse with which we can replace the missing values\nprint(\"mean age:\",df['Age'].mean())\nprint(\"median age:\",df['Age'].median())\nprint(\"mode age:\",df['Age'].mode())","0c169efb":"df['Age']=df['Age'].fillna(df['Age'].median())\ndf=df.dropna(axis=0)","6f47ea4c":"# plot heatmap to check null values\n# 'cbar = False' does not show the color axis \nsns.heatmap(df.isnull(), cbar=False)\n\n# display the plot\nplt.show()","ef4a0849":"df['Sex']=df['Sex'].replace('male',0)\ndf['Sex']=df['Sex'].replace('female',1)\n\ndf['Embarked']=df['Embarked'].replace('S',0)\ndf['Embarked']=df['Embarked'].replace('C',1)\ndf['Embarked']=df['Embarked'].replace('Q',2)","8a0b7518":"#storing categorical features which are important for training the model in the variable categorical\n#then converting it into dataframe and storing it in \"df_cat\"\ncategorical=['Embarked','Sex','Parch','SibSp','Pclass']\ndf_cat =df[categorical]\n\n#storing the important numeric features in the variable num\n#then converting it into dataframe and storing it in \"df_num\"\nnum=['Age','Fare']\ndf_num1 = df[num]","dd264f24":"#Creating the finaldataframe\ndf_final=pd.concat([df_num1,df_cat],axis=1)","49959a24":"df_final.head()","d76315e0":"# select only the target variable 'target' and store it in dataframe 'y'\ndf['Survived']=df['Survived'].astype(int)\ny = df['Survived']","2871be95":"X=df_final","f5ecd698":"# create a generalized function to calculate the metrics values for test set\ndef get_test_report(model):\n    \n    # return the performace measures on test set\n    return(classification_report(y_test, y_pred))","31b8235a":"# create a generalized function to calculate the metrics values for test set\ndef kappa_score(model):\n    \n    # return the kappa score on test set\n    return(cohen_kappa_score(y_test, y_pred))","1e188a26":"# define a to plot a confusion matrix for the model\ndef plot_confusion_matrix(model):\n    \n    # create a confusion matrix\n    # pass the actual and predicted target values to the confusion_matrix()\n    cm = confusion_matrix(y_test, y_pred)\n\n\n    conf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n  \n    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = ListedColormap(['lightskyblue']), cbar = False, \n                linewidths = 0.1, annot_kws = {'size':25})\n\n    # set the font size of x-axis ticks using 'fontsize'\n    plt.xticks(fontsize = 20)\n\n    # set the font size of y-axis ticks using 'fontsize'\n    plt.yticks(fontsize = 20)\n\n    # display the plot\n    plt.show()","660e19f9":"# define a function to plot the ROC curve and print the ROC-AUC score\ndef plot_roc(model):\n    \n \n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    #y_pred or y_pred_prob check it and do it acc to different algorithms in DT it was y_pred_prob in SVM it is y_pred\n\n    # plot the ROC curve\n    plt.plot(fpr, tpr)\n\n    # set limits for x and y axes\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n\n    # plot the straight line showing worst prediction for the model\n    plt.plot([0, 1], [0, 1],'r--')\n\n    # add plot and axes labels\n    # set text size using 'fontsize'\n    plt.title('ROC Curve for Passengers survived', fontsize = 15)\n    plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\n    plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n\n\n    plt.text(x = 0.02, y = 0.9, s = ('AUC Score:',round(roc_auc_score(y_test, y_pred),4)))\n\n    # plot the grid\n    plt.grid(True)","0705f291":"# create an empty dataframe to store the scores for various classification algorithms\nscore_card = pd.DataFrame(columns=['Model', 'AUC Score', 'Precision Score', 'Recall Score', 'Accuracy Score',\n                                   'Kappa Score', 'f1-score'])\n\n\ndef update_score_card(model_name):\n    \n    # assign 'score_card' as global variable\n    global score_card\n\n    # append the results to the dataframe 'score_card'\n    # 'ignore_index = True' do not consider the index labels\n    score_card = score_card.append({'Model': model_name,\n                                    'AUC Score' : roc_auc_score(y_test, y_pred),\n                                    'Precision Score': metrics.precision_score(y_test, y_pred),\n                                    'Recall Score': metrics.recall_score(y_test, y_pred),\n                                    'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n                                    'Kappa Score': cohen_kappa_score(y_test, y_pred),\n                                    'f1-score': metrics.f1_score(y_test, y_pred)}, \n                                    ignore_index = True)\n    return(score_card)","cebf078f":"# split data into train subset and test subset\n# set 'random_state' to generate the same dataset each time you run the code \n# 'test_size' returns the proportion of data to be included in the test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 10)\n\n# check the dimensions of the train & test subset using 'shape'\n# print dimension of train set\nprint(\"X_train\",X_train.shape)\nprint(\"y_train\",y_train.shape)\n\n# print dimension of test set\nprint(\"X_test\",X_test.shape)\nprint(\"y_test\",y_test.shape)","1e9b0b50":"# build the model\nsvclassifier = SVC(kernel = 'linear')\n\n# fit the model\nsvc_model=svclassifier.fit(X_train, y_train)\n","09f566d8":"# predict the values\ny_pred = svclassifier.predict(X_test)","59c1997c":"# call the function to plot the confusion matrix\nplot_confusion_matrix(svc_model)","20a3259d":"# compute the performance measures on test data\ntest_report = get_test_report(svc_model)\n\n# print the performace measures\nprint(test_report)","f98ede2d":"# compute kappa score on test set\nkappa_value = kappa_score(svc_model)\n\n# print the kappa value\nprint(kappa_value)","32930e9c":"plot_roc(svc_model)","e50f6f13":"update_score_card(model_name='SVM')","00658de2":"# build the model\nsvclassifier = SVC(kernel='rbf')\n# fit the model\nsvm_rbf=svclassifier.fit(X_train, y_train)","90c4e634":"# predict the values\ny_pred= svclassifier.predict(X_test)\n","0cd20078":"plot_confusion_matrix(svm_rbf)","59f7aec8":"# compute kappa score on test set\nkappa_value = kappa_score(svm_rbf)\n\n# print the kappa value\nprint(kappa_value)","d6b304e4":"update_score_card(model_name='SVM with rbf')","c825683a":"# build the model\nsvclassifier = SVC(kernel='sigmoid')\n# fit the model\nsvm_sigmoid=svclassifier.fit(X_train, y_train)","f6f1d614":"# predict the values\ny_pred  = svclassifier.predict(X_test)","50c2b0a5":"# call the function to plot the confusion matrix\nplot_confusion_matrix(svm_sigmoid)","29f8efe5":"# compute the performance measures on test data\ntest_report = get_test_report(svm_sigmoid)\n\n# print the performace measures\nprint(test_report)","a80c4b60":"# compute kappa score on test set\nkappa_value = kappa_score(svm_sigmoid)\n\n# print the kappa value\nprint(kappa_value)","a124580f":"plot_roc(svm_sigmoid)","962cae8d":"update_score_card(model_name='SVM Sigmoid')","a5114d7f":"# build the model\nsvclassifier = SVC(kernel='poly')\n# fit the model\nsvm_poly=svclassifier.fit(X_train, y_train)\n","62f52795":"# predict the values\ny_pred  = svclassifier.predict(X_test)","0ff82652":"# call the function to plot the confusion matrix\nplot_confusion_matrix(svm_poly)","225a41c7":"# compute the performance measures on test data\ntest_report = get_test_report(svm_poly)\n\n# print the performace measures\nprint(test_report)","61139e69":"# compute kappa score on test set\nkappa_value = kappa_score(svm_poly)\n\n# print the kappa value\nprint(kappa_value)","f444b0c4":"plot_roc(svm_poly)","b462e8fe":"update_score_card(model_name='SVM using polynomial kernel')","3c3f6831":"# build the model\nsvclassifier_Poly = SVC(kernel='poly', degree = 2, gamma = 'auto')\n# fit the model\nsvm=svclassifier_Poly.fit(X_train, y_train)","8882ec48":"# predict the values\ny_pred  = svclassifier_Poly.predict(X_test)","da230bcb":"plot_confusion_matrix(svm)","3446fa71":"test_report=get_test_report(svm)\nprint(test_report)","4d861f53":"# compute kappa score on test set\nkappa_value = kappa_score(svm)\n\n# print the kappa value\nprint(kappa_value)","baab1948":"plot_roc(svm)","0f222ba3":"update_score_card(model_name='SVM with kernel(ploynomial) with degree 2')","20e09a8d":"# instantiate the 'DecisionTreeClassifier' object using 'entropy' criterion\ndecision_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 10)\n\n# fit the model using fit() on train data\ndecision_tree_model = decision_tree.fit(X_train, y_train)","8e6a630e":"labels=X_train.columns\n\n#plot the decisin tree\nfig=plt.figure(figsize=(30,30))\nz=tree.plot_tree(decision_tree_model,\n                feature_names=labels,\n                class_names=['0','1'],\n                filled=True)","7856fdc7":"y_pred=decision_tree_model.predict(X_test)","7f78f21c":"plot_confusion_matrix(decision_tree_model)","bf7164c8":"kappa_score(decision_tree_model)","976ccff2":"test_report=get_test_report(decision_tree_model)\nprint(test_report)","aa877d9a":"plot_roc(decision_tree)","659b33b3":"update_score_card(model_name='Decision Tree')","e8d94087":"prune=DecisionTreeClassifier(max_depth=5,max_leaf_nodes=25,random_state=10)\ndecision_tree_prune=prune.fit(X_train,y_train)","bf24946d":"labels=X_train.columns\nfig=plt.figure(figsize=(30,30))\nz=tree.plot_tree(decision_tree_prune,\n                feature_names=labels,\n                class_names=['0','1'],\n                filled=True)","4913c7eb":"y_pred=decision_tree_prune.predict(X_test)","b0577a32":"plot_confusion_matrix(decision_tree_prune)","9a86dcd0":"test_report=get_test_report(decision_tree_prune)\nprint(test_report)","b6bfb491":"plot_roc(decision_tree_prune)","fab29c4a":"update_score_card(model_name='Decision Tree Pruned')","f7cc94cb":"tuned_parameters=[{'criterion':['gini','entropy'],\n                  'min_samples_split':[10,20],\n                  'max_depth':[3,5],\n                  'min_samples_leaf':[15,20,25,30,35],\n                  'max_leaf_nodes':[5,10,15,20,25]\n                  }]","1bdc2482":"tree_classification=DecisionTreeClassifier(random_state=10)\ngrid=GridSearchCV(estimator=tree_classification,\n                 param_grid=tuned_parameters,\n                 cv=5)\n#change cv as per sample size,consider there are 1000 sample keep it 5\ndt_grid=grid.fit(X_train,y_train)\n\nprint(\"best parameters:\",dt_grid.best_params_,'\\n')","a7317a4d":"dt_grid_model=DecisionTreeClassifier(criterion=dt_grid.best_params_.get('criterion'),\n                                     max_depth=dt_grid.best_params_.get(\"max_depth\"),\n                                     max_leaf_nodes=dt_grid.best_params_.get(\"max_leaf_nodes\"),\n                                     min_samples_leaf=dt_grid.best_params_.get(\"max_leaf_nodes\"),\n                                     min_samples_split=dt_grid.best_params_.get(\"min_samples_split\"),\n                                     random_state=10)\ndt_grid_model=dt_grid_model.fit(X_train,y_train)","e49aea2f":"# save the column names in 'labels'\nlables = X_train.columns\n\n# plot the decision tree \nfig = plt.figure(figsize=(30,30))\n_ = tree.plot_tree(decision_tree_model, \n                   feature_names=lables,  \n                   class_names=[\"0\",\"1\"],\n                   filled=True)","25667e59":"y_pred=dt_grid_model.predict(X_test)","13f19df5":"# call the function to plot the confusion matrix\n# pass the decision tree model to the function\nplot_confusion_matrix(decision_tree_model)","44bc4eb7":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the decision tree model to the function\ntest_report = get_test_report(decision_tree_model)\n\n# print the performace measures\nprint(test_report)","d9781d0e":"# compute kappa score on test set\n# call the function 'kappa_score'\n# pass the decision tree model to the function\nkappa_value = kappa_score(decision_tree_model)\n\n# print the kappa value\nprint(kappa_value)","3e2ed9a7":"# call the function 'plot_roc' to plot the ROC curve\n# pass the decision tree model to the function\nplot_roc(decision_tree_model)","acbee0e4":"# use the function 'update_score_card' to store the performance measures\n# pass the 'Decision Tree' as model name to the function\nupdate_score_card(model_name = 'Decision Tree with hyperparameter tuning')","5997217c":"# instantiate the 'SGDClassifier' to build model using SGD\n# to perform logistic regression, consider the log-loss function \n# set 'random_state' to generate the same dataset each time you run the code \nSGD = SGDClassifier(loss = 'log', random_state = 10)\n\n# fit the model on scaled training data\nlogreg_with_SGD = SGD.fit(X_train, y_train)","565fa8ae":"# use predict() to predict the class labels of target variable\ny_pred = logreg_with_SGD.predict(X_test)","faff77d4":"# call the function to plot the confusion matrix\n# pass the logistic regression (SGD) model to the function\nplot_confusion_matrix(logreg_with_SGD)","466e97f1":"# compute the performance measures on test data\n# call the function 'get_test_report'\n# pass the logstic regression (SGD) model to the function\ntest_report = get_test_report(logreg_with_SGD)\n\n# print the performace measures\nprint(test_report)","c2da4900":"# compute kappa score on test set\n# call the function 'kappa_score'\n# pass the logstic regression (SGD) model to the function\nkappa_value = kappa_score(logreg_with_SGD)\n\n# print the kappa value\nprint(kappa_value)","a57d2714":"# call the function 'plot_roc' to plot the ROC curve\n# pass the logstic regression (SGD) model to the function\nplot_roc(logreg_with_SGD)","31a64905":"# use the function 'update_score_card' to store the performance measures\n# pass the 'Logistic Regression (SGD)' as model name to the function\nupdate_score_card(model_name = 'Logistic Regression (SGD)')","cd42a164":"df_test=pd.read_csv('..\/input\/titanic\/test.csv')","72fc5dd4":"df_test.shape","56b0563c":"df_test.info()","9090f7f0":"df_test.isnull().sum()","80fb62df":"df_test=df_test.drop('Cabin',axis=1)","43b48ea7":"df_test['Age']=df_test['Age'].fillna(df_test['Age'].median())","412819bc":"df_test['Fare']=df_test['Fare'].fillna(df_test['Fare'].median())","883de9a7":"df_test.isnull().sum()","a2e005a4":"df_test['Embarked'].value_counts()","18befbdb":"df_test['Sex']=df_test['Sex'].replace('male',0)\ndf_test['Sex']=df_test['Sex'].replace('female',1)","2970f9ad":"df_test['Embarked']=df_test['Embarked'].replace('S',0)\ndf_test['Embarked']=df_test['Embarked'].replace('C',1)\ndf_test['Embarked']=df_test['Embarked'].replace('Q',2)","b360c8c3":"#storing categorical features which are important for training the model in the variable categorical\n#then converting it into dataframe and storing it in \"df_cat\"\ncategorical=['Embarked','Sex','Parch','SibSp','Pclass']\ndf_cat =df_test[categorical]\n\n#storing the important numeric features in the variable num\n#then converting it into dataframe and storing it in \"df_num\"\nnum=['Age','Fare']\ndf_num1 = df_test[num]","52fde8db":"df_test_cat1=df_test[['Parch','SibSp','Pclass']]","37b42279":"#Creating the finaldataframe\ndf_final=pd.concat([df_num1,df_cat],axis=1)","a205bee3":"#predicting the test data using the best model\npredict=svclassifier_Poly.predict(df_final)","42423d82":"#converting the predicted values into list\nv=np.array(predict).tolist()","cffa48b4":"#inserting the predicted values in the dataframe under the column name treatment\ndf_test.insert(2,column=\"Survived\",value=v)\ndf_test.head()","5c28c981":"upload=df_test.drop(['Pclass','Name','Age','SibSp','Parch','Ticket','Fare','Embarked','Sex'],axis=1)","eb685f27":"upload.head()","37e93667":"upload.to_csv(\"predicted_titanic.csv\",index=False)","aef6b9ad":"Replacing misisng age with median age as the median and mean age is close by.","87bb7dac":"From the plots following points can be deducted:\n1.There were more male members onboard than the female members\n\n2.More passengers died than survived\n\n3.Maximum passengers were from Pclass 3 i.e. lower class\n\n4.Maximum passengers did not had siblings onboard\n\n5.Maximum passengers did not have parents or children onboard\n\n6.Maximum passengers embarked from Southampton","65377589":"# Exploratory data analysis","b47f562a":"we can see that there are outliers in the age column.","b3ef003b":"# Dealing with the missing values","18aa907c":"We see that all the missing data have been handled.","56a3393b":"Segregated categorical data and numeric data for performing one hot encoding.","7168e9d7":"Training data set is mostly balanced","976f7033":"We had seen from the plot above that maximum passengers were from lower class, but maximum passengers who survived the tragic incident were from higher class.So it can be concluded that higher class passengers were saved more during the incident.","b6bda267":"Though there were more male passengers onboard than female passengers, we can see from the plot that more female passengers survived than male passengers","d406e52a":"Maximum survivers were from Southampton.It is obvious because maximum passenger who did board the ship were from Southampton.","764514ce":"It can be seen that the age column and the cabin column has got many missing values.Sincce the cabin column has got many missing values we drop the column, as there are more than 50%  missing values.","26479d21":"The age column is normally distributed whereas if we see the fare column,it is positively skewed.","d0c0423c":"# Creating generalised functions","a4f8854f":"We can see that maximum passengers who survived did not had parents or children onboard","46de7ca4":"Maximum passengers who survived did not had siblings onboard","35038279":"There are no variables that are highly correlated"}}