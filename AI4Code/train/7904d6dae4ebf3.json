{"cell_type":{"f9b3b34d":"code","41d47431":"code","15a3812b":"code","2af9db55":"code","41fe59f1":"code","0f66bf66":"code","93d2197b":"code","3d25431d":"code","4a726c7a":"code","2ad0fa85":"code","ff93a262":"code","59d95d22":"code","f10991d7":"code","e6344bb9":"code","f7fbd2ae":"code","51831c75":"code","077e848b":"code","85e63b15":"markdown","b01aa9cb":"markdown","2871bc26":"markdown","075a9645":"markdown","b06e2cd2":"markdown","6177df54":"markdown"},"source":{"f9b3b34d":"import pandas as pd \nimport numpy as np\npd.set_option('display.max_columns', 50)\nfrom sklearn.metrics import mean_squared_error\nimport math","41d47431":"train = pd.read_csv('..\/input\/30-days-of-ml\/train.csv')\ntest = pd.read_csv('..\/input\/30-days-of-ml\/test.csv')\nsubmission = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')","15a3812b":"# define the features for convenience.\nCAT_FEATS = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\nNUM_FEATS = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\n\nTARGET = 'target'","2af9db55":"data = pd.concat([train, test])","41fe59f1":"from sklearn.preprocessing import LabelEncoder\n\nLE_FEATS = []\nfor feat in CAT_FEATS:\n    le = LabelEncoder()\n    data[f'le_{feat}'] = le.fit_transform(data[feat])\n    LE_FEATS.append(f'le_{feat}')","0f66bf66":"for feat in NUM_FEATS:\n    data[feat] = np.log1p(data[feat])","93d2197b":"ALL_FEATS = LE_FEATS + NUM_FEATS","3d25431d":"train_size = train.shape[0]\ntrain = data[:train_size]\ntest = data[train_size:]","4a726c7a":"xgb_params = {\n    'n_estimators': 10000,\n    'learning_rate': 0.35,\n    'subsample': 0.926,\n    'colsample_bytree': 0.84,\n    'max_depth': 2,\n    'booster': 'gbtree', \n    'reg_lambda': 35.1,\n    'reg_alpha': 34.9,\n    'random_state': 42,\n    'n_jobs': 4\n}\n\nlgbm_params = {\n     'max_bin': 500,\n    'feature_fraction': 0.78,\n    'bagging_fraction': 0.78,\n    'objective': 'regression',\n    'max_depth': -1,\n    'learning_rate': 0.01,\n    \"bagging_seed\": 42,\n    'random_state': 42,\n    \"metric\": 'mse',\n    \"verbosity\": -1,\n}","2ad0fa85":"# I put 2 just to make the notebooks fast.\nN_FOLDS = 2","ff93a262":"CATBOOST = True\nXGB = True\nLGBM = True\n\nseed = 42","59d95d22":"from sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor, Pool\n\ndef learn_and_pred(train, test):\n\n    # create a dataframe to keep the validation result of each models\n    val_pred = train[TARGET].copy()\n    val_pred.iloc[:] = 0\n    val_pred = pd.DataFrame([val_pred.values, val_pred.values, val_pred.values]).T\n    val_pred.columns=['cb', 'xgb', 'lgbm']\n\n    # create a dataframe to keep the prediction for the test set of each models. \n    pred = submission['target'].copy()\n    pred.iloc[:] = 0\n    pred = pd.DataFrame([pred.values, pred.values, pred.values]).T\n    pred.columns=['cb', 'xgb', 'lgbm']\n\n    for fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=N_FOLDS, random_state=seed, shuffle=True).split(train)):\n        print(f'fold - {fold}')\n\n        X_train = train.loc[train_idx, :]\n        X_valid = train.loc[valid_idx, :]\n        y_train = train.loc[train_idx, TARGET]\n        y_valid = train.loc[valid_idx, TARGET]\n\n        if CATBOOST: # building Catboost model part\n            X_train_cb = X_train.loc[:,ALL_FEATS]\n            X_valid_cb = X_valid.loc[:,ALL_FEATS]\n            \n            model = CatBoostRegressor(\n                iterations=6800,\n                learning_rate=0.93,\n                loss_function=\"RMSE\",\n                random_state=seed,\n                early_stopping_rounds=100,\n                depth=1,\n                l2_leaf_reg=3.28,\n                thread_count=4,\n                verbose=100,\n            )\n            model.fit(X_train_cb, y_train, eval_set=Pool(X_valid_cb, y_valid))\n            cb_pred = model.predict(X_valid_cb)\n\n            print(f'Fold {fold} - RMSE:{math.sqrt(mean_squared_error(cb_pred, y_valid))}')\n\n            val_pred.loc[valid_idx, 'cb'] += cb_pred \n            pred.loc[:, 'cb'] += model.predict(test[ALL_FEATS]) \n\n        if XGB: # building XGBoost model part\n            X_train_xgb = X_train.loc[:,ALL_FEATS]\n            X_valid_xgb = X_valid.loc[:,ALL_FEATS]\n\n            xgb_params['random_state'] = seed\n\n            model = XGBRegressor(**xgb_params)\n            model.fit(\n                X_train_xgb, y_train,\n                verbose=False,\n                eval_set=[(X_train_xgb, y_train), (X_valid_xgb, y_valid)],\n                eval_metric=\"rmse\",\n                early_stopping_rounds=100,\n            )\n\n            xgb_pred = model.predict(X_valid_xgb)\n\n            print(f'Fold {fold} - RMSE:{math.sqrt(mean_squared_error(xgb_pred, y_valid))}')\n\n            val_pred.loc[valid_idx, 'xgb'] += xgb_pred \n            pred.loc[:, 'xgb'] += model.predict(test[ALL_FEATS]) \n\n        if LGBM: # building LightGBM model part\n            tr_data = lgb.Dataset(X_train[ALL_FEATS].values.astype(np.float32), label=y_train)\n            va_data = lgb.Dataset(X_valid[ALL_FEATS].values.astype(np.float32), label=y_valid)\n\n            lgbm_params['random_state'] = seed\n            lgbm_params['bagging_seed'] = seed\n\n            model = lgb.train(\n                lgbm_params, \n                tr_data,\n                num_boost_round=100000,\n                valid_sets=[tr_data, va_data],\n                early_stopping_rounds=100,\n                feature_name=ALL_FEATS,\n                categorical_feature=LE_FEATS, \n                verbose_eval=100\n            )\n            val_pred.loc[valid_idx, 'lgbm'] += model.predict(X_valid[ALL_FEATS]) \n            pred.loc[:, 'lgbm'] += model.predict(test[ALL_FEATS]) \n\n    pred \/= N_FOLDS\n\n    return val_pred, pred","f10991d7":"val_pred, pred = learn_and_pred(train, test)","e6344bb9":"val_pred.to_csv('validation.csv', index=False)\npred.to_csv('prediction.csv', index=False)","f7fbd2ae":"val_pred.head()","51831c75":"%%time\n# cb, xgb, lgbm\nRATIO = [0.3, 0.3, 0.4] #the ratio is just an example\n\n#val_pred['ensembled'] = val_pred.apply(lambda x: x['cb'] * RATIO[0] + x['xgb'] * RATIO[1] + x['lgbm'] * RATIO[2], axis=1)\n# the code below is much faster\nval_pred['ensembled'] = val_pred['cb'] * RATIO[0] + val_pred['xgb'] * RATIO[1] + val_pred['lgbm'] * RATIO[2]\n\nrmse = math.sqrt(mean_squared_error(train['target'], val_pred['ensembled']))\nprint(f'RMSE:{rmse}  with CB:XGB:LGBM = {RATIO[0]}:{RATIO[1]}:{RATIO[2]}')","077e848b":"# submit\npred['ensembled'] = pred.apply(lambda x: x['cb'] * RATIO[0] + x['xgb'] * RATIO[1] + x['lgbm'] * RATIO[2], axis=1)\nsubmission['target'] = pred['ensembled']\nsubmission.to_csv('submission.csv', index=False)","85e63b15":"Let's check the kept validation result in the variable, **val_pred**.\n\nNow we got validation results for each models.","b01aa9cb":"## How can we find optimum weights for ensemble?\nWhen you take a look at some ensembling notebooks, you might be wondering, how do they find the weights? \n\nSometimes we just take average or put random numbers. \n\nAlternatively, the weights can be determined based on the CV of each model.\n\nAs I see many ensemble public notebooks, I propose a way to find a good weights. \n\nIn this notebook, I will explain how to determine how well the model is performing with the selected weights by measuring the CV.\n\n** CV stands for Cross Validation. Sometimes we use the term CV to mean the score measured by CrossValidation.","2871bc26":"## Build models\n\nWe build 3 models. \n\nTo assess the CV for ensemble, we need to keep the validation result of each models. <- This is the important part.\n\nSo keep an eye on the variable **val_pred** in the following cell.\n\nIt keeps the validation result of each models. ","075a9645":"## Determine the weights\n\nHere comes the best part. \n\nWhat we are going to do is, perform wighted averaging with validation result. \n\nSo we can calculate CV(in this competition, we use RMSE).\n\nWhat we should do is minimize the RMSE tweeking the weights. \n\nSince now we have the criteria, it is possible to find the best weights as an optimization problem.\n\n** We can optimize the weights using CV because CV is trustworthy in this competition. Establishing a trustworthy CV is not always easy. ","b06e2cd2":"## The models for ensemble\n\nFor the starter, we need models to ensemble. Let's build some models. \n\nWe will build three models in this notebook. \n\n* Catboost\n* XGBoost\n* LightGBM\n\nI took paramters from the following noteboooks.\n* [30dML - EDA + Simple CatBoost](https:\/\/www.kaggle.com\/maximkazantsev\/30dml-eda-simple-catboost)\n* [30dML - EDA + XGBoost with Folds](https:\/\/www.kaggle.com\/maximkazantsev\/30dml-eda-xgboost)\n* [LightGBM Starter - 30 Days of ML](https:\/\/www.kaggle.com\/kokitanisaka\/lightgbm-starter-30-days-of-ml)","6177df54":"## Preprocess\nThis part is not important in this notebook. Just do some necessary preprocess."}}