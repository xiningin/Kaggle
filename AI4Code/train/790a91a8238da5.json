{"cell_type":{"e2ec558a":"code","e25c74d2":"code","5e07122f":"code","ba9e6012":"code","34955cfe":"code","151bc611":"code","174a1098":"code","023ae241":"code","30887bac":"code","a90ae8c6":"code","cada97cb":"code","f922845b":"code","4878fbc8":"code","9abfec33":"code","9e4a9089":"markdown","20018aa9":"markdown","bd960cfd":"markdown"},"source":{"e2ec558a":"import tensorflow as tf\nimport keras \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport sys\nimport random","e25c74d2":"image_size = 1024\ninput_size = 331","5e07122f":"def img_transf(imgs):\n    if len(imgs.shape) == 4:\n        for i in range(imgs.shape[0]):\n            for j in range(imgs.shape[-1]):\n                imgs[i,...,j] \/= imgs[i,...,j].max()\n    elif len(imgs.shape) == 3 or 2:\n        for j in range(imgs.shape[-1]):\n            imgs[...,j] \/= imgs[...,j].max()\n    else:\n        print('Input shape not recognised')\n    return imgs","ba9e6012":"def rand_crop(img):\n    h = random.randint(input_size, image_size) \n    cx = random.randint(0, image_size-h)\n    cy = random.randint(0, image_size-h)\n    cropped_img = img[cx:cx+h,cy:cy+h,:]\n    return cv2.resize(cropped_img, (input_size,input_size))","34955cfe":"from keras.preprocessing.image import ImageDataGenerator\ndata_dir = '..\/input\/neuron cy5 full\/Neuron Cy5 Full'\n\ndata_gen = ImageDataGenerator(horizontal_flip=True, #augmentation turned off for now\n                              vertical_flip=True,\n                              validation_split=0.2,\n                              preprocessing_function = img_transf)\n\nanchor_train_gen = data_gen.flow_from_directory(data_dir, \n                                                target_size=(input_size, input_size),\n                                                color_mode='grayscale',\n                                                class_mode='categorical',\n                                                batch_size=16, \n                                                shuffle=True, \n                                                subset='training')\nanchor_test_gen = data_gen.flow_from_directory(data_dir, \n                                               target_size=(input_size, input_size),\n                                               color_mode='grayscale',\n                                               class_mode='categorical',\n                                               batch_size=16, \n                                               shuffle=True, \n                                               subset='validation')\n\ntrain_gen = data_gen.flow_from_directory(data_dir, \n                                         target_size=(input_size, input_size),\n                                         color_mode='grayscale',\n                                         class_mode='categorical',\n                                         batch_size=1, \n                                         shuffle=True, \n                                         subset='training')\ntest_gen = data_gen.flow_from_directory(data_dir, \n                                        target_size=(input_size, input_size),\n                                        color_mode='grayscale',\n                                        class_mode='categorical',\n                                        batch_size=1, \n                                        shuffle=True, \n                                        subset='validation')\n\nclasses = dict((v, k) for k, v in anchor_train_gen.class_indices.items())\nnum_classes = len(classes)","151bc611":"\ndef lossless_triplet_loss(y_true, y_pred, N = 2, beta=2, epsilon=1e-10):\n    \"\"\"\n    Implementation of the triplet loss function\n    \n    Arguments:\n    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n    y_pred -- python list containing three objects:\n            anchor -- the encodings for the anchor data\n            positive -- the encodings for the positive data (similar to anchor)\n            negative -- the encodings for the negative data (different from anchor)\n    N  --  The number of dimension \n    beta -- The scaling factor, N is recommended\n    epsilon -- The Epsilon value to prevent ln(0)\n    \n    \n    Returns:\n    loss -- real number, value of the loss\n    \"\"\"\n    anchor = tf.convert_to_tensor(y_pred[:,0:N])\n    positive = tf.convert_to_tensor(y_pred[:,N:N*2]) \n    negative = tf.convert_to_tensor(y_pred[:,N*2:N*3])\n    \n    # distance between the anchor and the positive\n    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),1)\n    # distance between the anchor and the negative\n    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),1)\n    \n    #Non Linear Values  \n    \n    # -ln(-x\/N+1)\n    pos_dist = -tf.log(-tf.divide((pos_dist),beta)+1+epsilon)\n    neg_dist = -tf.log(-tf.divide((N-neg_dist),beta)+1+epsilon)\n    \n    # compute loss\n    loss = neg_dist + pos_dist\n    \n    return loss","174a1098":"from tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.applications import VGG16\nfrom tensorflow.python.keras.layers import Input, Concatenate, Dense\nfrom tensorflow.python.keras.optimizers import Adam\n\ndef create_model():\n    vgg16_model = VGG16(include_top=False,\n                         pooling='max',\n                         input_shape=(input_size, input_size, 3),\n                         weights='imagenet')\n    outp = Dense(2, activation='sigmoid')(vgg16_model.output)\n    pretrained_model = Model(vgg16_model.input, outp)\n    cfg = pretrained_model.get_config()\n    cfg['layers'][0]['config']['batch_input_shape'] = (None, input_size, input_size, 1)\n    model = Model.from_config(cfg)\n    for i, layer in enumerate(model.layers):\n        if len(model.layers)-i < 7:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    return model\n\nanc_inp = Input(shape=(input_size, input_size,1))\npos_inp = Input(shape=(input_size, input_size,1))\nneg_inp = Input(shape=(input_size, input_size,1))\n\nvgg16_model = create_model()\nanc_outp = vgg16_model(anc_inp)\npos_outp = vgg16_model(pos_inp)\nneg_outp = vgg16_model(neg_inp)\n\nmerged_outp = Concatenate(axis=-1)([anc_outp, pos_outp, neg_outp])\n\nmodel = Model(inputs=[anc_inp, pos_inp, neg_inp], outputs=merged_outp)\nadam_fine = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #10x smaller than standard\nmodel.compile(optimizer='adam', loss=lossless_triplet_loss)\nmodel.summary()","023ae241":"def triplet_gen(anchor_gen, gen):\n    while True:\n        anchors, y_anc = next(anchor_gen)\n        pos = np.empty(anchors.shape)\n        neg = np.empty(anchors.shape)\n        for sample_idx in range(anchors.shape[0]):\n            while pos[sample_idx].any() == None or neg[sample_idx].any() == None:\n                img, y = next(gen)\n                if y == y_anc[sample_idx]:\n                    pos[sample_idx,...] = img\n                else:\n                    neg[sample_idx,...] = img\n        yield [anchors, pos, neg], y_anc","30887bac":"def crop_gen(batches): #not used\n    while True:\n        batch_x, batch_y = next(batches)\n        batch_crops = np.zeros((batch_x.shape[0], input_size, input_size, 1))\n        for i in range(batch_x.shape[0]):\n            batch_crops[i,...,0] = rand_crop(batch_x[i])\n        yield (batch_crops, batch_y)","a90ae8c6":"history = model.fit_generator(triplet_gen(anchor_train_gen, train_gen), #inefficient, will change \n                              epochs=5,\n                              steps_per_epoch=4*len(anchor_train_gen),\n                              validation_data=triplet_gen(anchor_test_gen, test_gen),\n                              validation_steps=len(anchor_test_gen), \n                              verbose=1)","cada97cb":"X ,y = next(triplet_gen(anchor_test_gen, test_gen))\npoints = model.predict(X, verbose=1)[:,0:2]\nplt.scatter(points[:,0], points[:,1], c=y[:,0])","f922845b":"for layer in model.layers:\n    layer.trainable = True\nmodel.compile(optimizer=adam_fine, loss=lossless_triplet_loss)","4878fbc8":"history2 = model.fit_generator(triplet_gen(anchor_train_gen, train_gen), #inefficient, will change \n                              epochs=10,\n                              steps_per_epoch=4*len(anchor_train_gen),\n                              validation_data=triplet_gen(anchor_test_gen, test_gen),\n                              validation_steps=len(anchor_test_gen), \n                              verbose=1)","9abfec33":"X ,y = next(triplet_gen(anchor_test_gen, test_gen))\npoints = model.predict(X, verbose=1)[:,0:2]\nplt.scatter(points[:,0], points[:,1], c=y[:,0])","9e4a9089":"As the model needs to be fed 3 images at a time, an Anchor, Positive and Negative image, three data generators are needed for training and test sets.","20018aa9":"Standard imports","bd960cfd":"Now to create the model. First the convolution layers of VGG16 are loaded into a model and then that model is three times in parallel to give the siamese network.\n\nThe triplet-loss required to train a Siamese network isn't contained within Keras so it must be defined seperately. The lossless triplet loss described in [this article](https:\/\/towardsdatascience.com\/lossless-triplet-loss-7e932f990b24) is used."}}