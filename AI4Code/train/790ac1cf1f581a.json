{"cell_type":{"4bb7d7de":"code","26954bfe":"code","5bb04dc6":"code","b179afbc":"code","f5f71d6f":"code","bfd22393":"code","27879bc1":"code","3e83d97c":"code","7725b91c":"code","6c1196c8":"code","8ab6998f":"code","c22a895e":"code","441712c7":"code","1fd58e0d":"code","42306399":"code","e69e044b":"code","d7f69652":"code","5c17e9fc":"code","77cda301":"code","58cd8182":"code","aad7e68d":"markdown","c93404f2":"markdown","2da60cd3":"markdown","4bbb18b4":"markdown","a3d041d5":"markdown","dfb9ea35":"markdown"},"source":{"4bb7d7de":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","26954bfe":"base_dir = \"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\"\nimage_size = 224","5bb04dc6":"train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0,\n                                                            shear_range = 0.2,\n                                                            zoom_range = 0.2,\n                                                            width_shift_range = 0.2,\n                                                            height_shift_range = 0.2,\n                                                            fill_mode=\"nearest\")\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0)","b179afbc":"train_data = train_datagen.flow_from_directory(os.path.join(base_dir,\"train\"),\n                                               target_size=(image_size,image_size),\n                                               batch_size=32,\n                                               class_mode=\"categorical\"                                               \n                                              )","f5f71d6f":"test_data = test_datagen.flow_from_directory(os.path.join(base_dir,\"valid\"),\n                                               target_size=(image_size,image_size),\n                                               batch_size=32,\n                                               class_mode=\"categorical\"                                               \n                                              )","bfd22393":"train_data.class_indices","27879bc1":"train_data.image_shape","3e83d97c":"# weights=\"imagenet\"(load weights pretrained on the ImageNet)\n# include_top=False (Do not include the ImageNet classifier at the top)\n\nbase_model = keras.applications.MobileNet(weights=\"imagenet\",\n                                          input_shape=(224,224,3),\n                                          include_top=False,)","7725b91c":"base_model.summary()","6c1196c8":"# Freeze the base_model\nbase_model.trainable = False\n\n# Create new model on top\ninputs = keras.Input(shape=(224, 224, 3))\nx = base_model(inputs, training=False)\nx = keras.layers.GlobalAveragePooling2D()(x)\nx = keras.layers.Dropout(0.2)(x)  \noutputs = keras.layers.Dense((38),activation=\"softmax\")(x)\n\nmobilenet_model = keras.Model(inputs, outputs, name='leaf_disease_model_mobilenet')\nmobilenet_model.summary()","8ab6998f":"mobilenet_model.compile(optimizer=keras.optimizers.Adam(),\n                        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n                        metrics=[keras.metrics.CategoricalAccuracy()])","c22a895e":"#Add Callbacks, e.g. ModelCheckpoints, earlystopping, csvlogger.\nfrom keras.callbacks import EarlyStopping\n\n# EarlyStopping callback.\nearly_stop = EarlyStopping(monitor='val_loss', \n                           patience=3, \n                           verbose=1)\n\ncallbacks_list = [early_stop]\n\nhistory = mobilenet_model.fit(train_data,\n                              steps_per_epoch=300,  \n                              validation_data=test_data,\n                              epochs=20,\n                              validation_steps=300,\n                              callbacks=callbacks_list)\n","441712c7":"mobilenet_model.evaluate(test_data)","1fd58e0d":"# Learning Curves.\n# Plot Loss vs Accuracy graphs.\n\nplt.figure(figsize=(18,7))\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label = 'Training Loss')\nplt.plot(history.history['val_loss'], label = 'Validation Loss')\nplt.grid(False)\nplt.xlabel('Epochs')\nplt.ylabel('Loss Magnitude')\nplt.title('Training Loss')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(history.history['categorical_accuracy'], label = 'Training Accuracy')\nplt.plot(history.history['val_categorical_accuracy'], label = 'validation Accuracy')\nplt.grid(False)\nplt.xlabel('Epochs')\nplt.ylabel('Loss Magnitude')\nplt.title('Training Accuracy')\nplt.legend(loc='lower right')\nplt.show()","42306399":"def get_class_string_from_index(index):\n   for class_string, class_index in test_data.class_indices.items():\n      if class_index == index:\n         return class_string\n\nx, y = next(test_data)\nimage = x[0, :, :, :]\ntrue_index = np.argmax(y[0])\nplt.imshow(image)\nplt.axis('off')\nplt.show()\n\n# Expand the validation image to (1, 224, 224, 3) before predicting the label\nprediction_scores = mobilenet_model.predict(np.expand_dims(image, axis=0))\npredicted_index = np.argmax(prediction_scores)\nprint(\"True label: \" + get_class_string_from_index(true_index))\nprint(\"Predicted label: \" + get_class_string_from_index(predicted_index))","e69e044b":"!pip install tensorflowjs","d7f69652":"import tensorflowjs as tfjs\ntfjs.converters.save_keras_model(mobilenet_model,\"\/kaggle\/working\")","5c17e9fc":"# Save Model. as h5\nmobilenet_model.save('leaf_disease_diagnosis_MobileNet3.h5')","77cda301":"# saved_model format.\nsaved_model_path = \"\/kaggle\/working\"\ntf.saved_model.save(mobilenet_model, saved_model_path)","58cd8182":"# save .js format.\nimport tensorflowjs as tfjs\n!tensorflowjs_converter --input_format=keras '\/kaggle\/working\/leaf_disease_diagnosis_MobileNet3.h5' \"\/kaggle\/working\"","aad7e68d":"# **Predictions.**","c93404f2":"#  **Using MobileNet**","2da60cd3":"# **Evaluate Model.**","4bbb18b4":"# **Import Libraries.**","a3d041d5":"# **Save Models.**","dfb9ea35":"# **Compile and train the model.**"}}