{"cell_type":{"a3a9870c":"code","1f8ccf44":"code","c0cc1afb":"code","ae807480":"code","427b85d7":"code","51b7baa8":"code","248188ff":"code","b25b1ca5":"code","7c55f74e":"code","8ea03e0b":"code","ab3df9e3":"code","b0757734":"code","d74adefc":"code","db4a97b1":"code","34448830":"code","3af58024":"code","049cca66":"code","51a1fa2f":"code","e6f73486":"code","f13f50a0":"code","5da85c47":"code","6f0dc679":"code","f01180ff":"code","a275a771":"code","b2fd18a9":"code","50ebd48b":"code","843e2308":"code","2cd9de5f":"code","a06e3d5b":"code","86ad3b0f":"code","e600cfe2":"code","f5676023":"code","8b8a6d47":"code","184e567f":"code","2a4dc3dd":"code","9d038925":"code","6fe69f96":"code","cb677c0e":"markdown","13b5387c":"markdown","3478cbd7":"markdown","dec37de2":"markdown","7e348c8e":"markdown","d1cf14c3":"markdown","489fa723":"markdown","c8578782":"markdown","6f83d40a":"markdown","202dec05":"markdown","12aa51f8":"markdown","b2805662":"markdown","e999ed02":"markdown","0b871775":"markdown","7641ca92":"markdown","a3c3ac46":"markdown","c7e456a5":"markdown","78ce1d19":"markdown","69ee20e0":"markdown"},"source":{"a3a9870c":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","1f8ccf44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c0cc1afb":"pd.set_option('display.max_rows', None)","ae807480":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","427b85d7":"train_data.info()","51b7baa8":"train_data['Name'] = train_data['Name'].apply(lambda x : x.split(',')[1].split('.')[0].strip())\ntrain_data.groupby('Name')['PassengerId'].nunique()","248188ff":"titles = {\n    'Capt' : 'Officer',\n    'Col'  : 'Officer',\n    'Dr'   : 'Officer',\n    'Major': 'Officer',\n    'Rev'  : 'Officer',\n    'Jonkheer': 'Royalty',\n    'Don'     : 'Royalty',\n    'Dona'    : 'Royalty',\n    'Lady'    : 'Royalty',\n    'Sir'     : 'Royalty',\n    'the Countess': 'Royalty',\n    'Mr'  : 'Mr',\n    'Mrs' : 'Mrs',\n    'Ms'  : 'Mrs',\n    'Mme' : 'Mrs',\n    'Miss': 'Miss',\n    'Mlle': 'Miss',\n    'Master': 'Master'\n}\n\ntrain_data['Name'] = train_data['Name'].map(titles)","b25b1ca5":"room_occupant = train_data.groupby('Ticket')['PassengerId'].nunique()\ntrain_data = train_data.assign(Occupancy=train_data['Ticket'].map(room_occupant))\ntrain_data.drop(['Ticket'], axis=1, inplace=True)","7c55f74e":"train_data['Cabin'].fillna('M', inplace=True)\ntrain_data['Cabin'] = train_data['Cabin'].apply(lambda x: x[0])\n\ntrain_data['Cabin'].value_counts()","8ea03e0b":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nsurvivor_count = train_data.groupby('Cabin')['Survived'].apply(lambda x: x[x==1].count())\ntuples = list(zip(['A','B','C','D','E','F','G','M','T'], survivor_count))\nbar_df = pd.DataFrame(tuples, columns = ['Cabin', 'SurvivorCount'])\n\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\nf.set_figheight(5)\nf.set_figwidth(10)\nsns.barplot(x='Cabin', y='SurvivorCount', data=bar_df, palette='husl', ax=ax1)\n\ndeath_count = train_data.groupby('Cabin')['Survived'].apply(lambda x: x[x==0].count())\ntuples = list(zip(['A','B','C','D','E','F','G','M','T'], death_count))\nbar_df = pd.DataFrame(tuples, columns = ['Cabin', 'DeathCount'])\n\nsns.barplot(x='Cabin', y='DeathCount', data=bar_df, palette='husl', ax=ax2)","ab3df9e3":"train_data.groupby(['Cabin','Pclass'])['PassengerId'].count()","b0757734":"train_data['Cabin'] = train_data['Cabin'].map({'A':'ABC', 'B':'ABC', 'C':'ABC', 'D':'DE', 'E':'DE', 'F':'FG', 'G':'FG', 'M':'M', 'T':'ABC'})\n\ndummy = pd.get_dummies(train_data['Cabin'])\ntrain_data.drop('Cabin', axis=1, inplace=True)\ntrain_data = pd.concat([train_data, dummy], axis = 1)","d74adefc":"train_data.loc[train_data['Embarked'].isnull()]","db4a97b1":"mode = train_data['Embarked'].mode()[0]\ntrain_data['Embarked'].fillna(mode, inplace=True)\n\ndummy = pd.get_dummies(train_data['Embarked'])\ntrain_data.drop('Embarked', axis=1, inplace=True)\ntrain_data = pd.concat([train_data, dummy], axis = 1)","34448830":"train_data.groupby(['Pclass','Name','Sex'])['Age'].median()","3af58024":"median_df = train_data.groupby(['Pclass','Name','Sex'])['Age'].median().to_frame()\ntrain_data['Age'] = train_data.groupby(['Pclass', 'Name', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","049cca66":"dummy = pd.get_dummies(train_data['Sex'])\ntrain_data = pd.concat([train_data, dummy], axis = 1)\ntrain_data.drop('Sex', axis=1, inplace=True)","51a1fa2f":"dummy = pd.get_dummies(train_data['Name'])\ntrain_data = pd.concat([train_data, dummy], axis = 1)\ntrain_data.drop('Name', axis=1, inplace=True)","e6f73486":"data = train_data[train_data.columns.difference(['PassengerId'])]\nplt.figure(figsize=(30,15))\nax = sns.heatmap(data.corr(), annot=True)","f13f50a0":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","5da85c47":"test_data.info()","6f0dc679":"test_data.loc[test_data['Fare'].isnull()]","f01180ff":"third_class = test_data.loc[test_data['Pclass'] == 3]\nmean_fare = third_class['Fare'].mean()\ntest_data['Fare'].fillna(mean_fare, inplace=True)","a275a771":"test_data['Name'] = test_data['Name'].apply(lambda x : x.split(',')[1].split('.')[0].strip())\ntest_data.groupby('Name')['PassengerId'].nunique()","b2fd18a9":"test_data['Name'] = test_data['Name'].map(titles)\n\ndummy = pd.get_dummies(test_data['Name'])\ntest_data = pd.concat([test_data, dummy], axis = 1)","50ebd48b":"test_data['Cabin'].fillna('M', inplace=True)\ntest_data['Cabin'] = test_data['Cabin'].apply(lambda x: x[0])\n\ntest_data['Cabin'] = test_data['Cabin'].map({'A':'ABC', 'B':'ABC', 'C':'ABC', 'D':'DE', 'E':'DE', 'F':'FG', 'G':'FG', 'M':'M', 'T':'ABC'})\n\ndummy = pd.get_dummies(test_data['Cabin'])\ntest_data.drop('Cabin', axis=1, inplace=True)\ntest_data = pd.concat([test_data, dummy], axis = 1)","843e2308":"age_is_null = test_data.loc[test_data['Age'].isnull(), ['Pclass','Name','Sex']]\nfilled_age = age_is_null.reset_index().merge(median_df, on=['Pclass','Name','Sex'], how='left').set_index('index')\npredicted_age = dict(zip(filled_age.index, filled_age['Age']))\ntest_data['Age'].fillna(predicted_age, inplace=True)","2cd9de5f":"dummy = pd.get_dummies(test_data['Sex'])\ntest_data.drop('Sex', axis=1, inplace=True)\ntest_data = pd.concat([test_data, dummy], axis = 1)","a06e3d5b":"room_occupant = test_data.groupby('Ticket')['PassengerId'].nunique()\ntest_data = test_data.assign(Occupancy=test_data['Ticket'].map(room_occupant))\ntest_data.drop(['Ticket', 'Name'], axis=1, inplace=True)","86ad3b0f":"dummy = pd.get_dummies(test_data['Embarked'])\ntest_data.drop('Embarked', axis=1, inplace=True)\ntest_data = pd.concat([test_data, dummy], axis = 1)","e600cfe2":"target = train_data['Survived'].to_numpy()\ntrain_predictor = train_data[train_data.columns.difference(['PassengerId', 'Survived'])].to_numpy()\ntest_predictor = test_data[test_data.columns.difference(['PassengerId'])].to_numpy()","f5676023":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\nscaled_train = scaler.fit_transform(train_predictor)\nscaled_test = scaler.fit_transform(test_predictor)","8b8a6d47":"from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import confusion_matrix\n\nskf = StratifiedKFold(n_splits=10, random_state=42)","184e567f":"from sklearn.ensemble import RandomForestClassifier\n\nestimator = RandomForestClassifier(random_state=42, max_depth=10, min_samples_leaf=2, min_samples_split=4)\nn_estimators = [n for n in range(100, 1000, 100)]\nparam_grid = {'n_estimators': n_estimators}\nrfc = GridSearchCV(estimator, param_grid, cv=3)\n\nscores = cross_val_score(rfc, train_predictor, target, cv=skf)\nprint(scores)\nprint('Average score :', np.mean(scores))\ny_pred = cross_val_predict(rfc, train_predictor, target, cv=10)\nsns.heatmap(confusion_matrix(target, y_pred),annot=True,fmt='3.0f')\nplt.title('Confusion_matrix', y=1.05, size=15)","2a4dc3dd":"from sklearn.linear_model import LogisticRegression\n\nestimator = LogisticRegression(max_iter=10000, random_state=42)\npenalty = ['l1', 'l2']\nC = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\nparam_grid = {'C': C, 'penalty': penalty}\nlr = GridSearchCV(estimator, param_grid, cv=3)\n\nscores = cross_val_score(lr, scaled_train, target, cv=skf)\nprint(scores)\nprint('Average score :', np.mean(scores))\ny_pred = cross_val_predict(lr, scaled_train, target, cv=10)\nsns.heatmap(confusion_matrix(target, y_pred),annot=True,fmt='3.0f')\nplt.title('Confusion_matrix', y=1.05, size=15)","9d038925":"from sklearn.svm import SVC\n\nestimator = SVC(random_state=42)\nCs = [0.001, 0.01, 0.1, 1, 10]\ngammas = [0.001, 0.01, 0.1, 1]\nparam_grid = {'C': Cs, 'gamma' : gammas}\nsvm = GridSearchCV(estimator, param_grid, cv=3)\n\nscores = cross_val_score(svm, scaled_train, target, cv=skf)\nprint(scores)\nprint('Average score :', np.mean(scores))\ny_pred = cross_val_predict(svm, scaled_train, target, cv=10)\nsns.heatmap(confusion_matrix(target, y_pred),annot=True,fmt='3.0f')\nplt.title('Confusion_matrix', y=1.05, size=15)","6fe69f96":"svm.fit(scaled_train, target)\npredictions = svm.predict(scaled_test)","cb677c0e":"**4. Make predictions using the best model**","13b5387c":"* Sex","3478cbd7":"**2. Preprocessing test data**","dec37de2":"* Fare","7e348c8e":"* Cabin","d1cf14c3":"* Sex","489fa723":"* Name","c8578782":"We can fill the missing values with the most frequently occuring port.","6f83d40a":"* Name and Ticket","202dec05":"* Age","12aa51f8":"* Title","b2805662":"**1. Preprocessing train data**","e999ed02":"* Ticket","0b871775":"* Title","7641ca92":"* Cabin<br>","a3c3ac46":"* Age<br>","c7e456a5":"* Embarked","78ce1d19":"* Embarked","69ee20e0":"**3. Train model**"}}