{"cell_type":{"19c6c8e4":"code","e70688af":"code","52d846b9":"code","a2023a7a":"code","29781443":"code","bbe9fd3e":"code","418a622a":"code","24a54fef":"code","d5450630":"code","6bb26a41":"code","66e96d1f":"code","e63d6f21":"code","823dce36":"code","5df54c99":"code","ff6ab8e4":"code","30aca19e":"code","d93e9de5":"code","30a481bd":"code","3670eb5a":"code","06b94318":"code","98c65584":"code","6b9818fa":"code","39e81c0f":"code","0f9229f0":"code","451888ba":"code","e242c19b":"code","97862174":"code","7e6a4773":"code","bd371bf6":"code","3b00a9dd":"code","42f9fae4":"code","5e96e127":"markdown","2d1e4df8":"markdown","c9b9f980":"markdown","d35ddbb0":"markdown","9a8d3163":"markdown","ed2c9798":"markdown","4a09c66e":"markdown","9983f423":"markdown","b54ef94a":"markdown","da178d94":"markdown","5bbc7242":"markdown","07a1d69b":"markdown","52b74e87":"markdown"},"source":{"19c6c8e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e70688af":"import torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport torchvision.transforms as tt\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n%matplotlib inline\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nfrom tqdm.notebook import tqdm","52d846b9":"data_path = \"..\/input\/stanford-cars-dataset\/cars_train\"\nimage_size = 256\nbatch_size = 64\nnormstats = (0.,0.,0.),(1.,1.,1.)\ntransforms = tt.Compose([tt.Resize(image_size),#resize to make things uniform\n                        tt.CenterCrop(image_size),#cropping to the center to avoid distortion\n                        tt.ToTensor(),#to a tensor\n                        tt.Normalize(*normstats)#normalizing in order to increase effectiveness of our GAN\n                        ])\ndataset = ImageFolder(data_path, transform = transforms)\nimg, _ = dataset[0]\nplt.imshow(img.permute((1,2,0)))","a2023a7a":"def denorm(img_tensors):\n    return img_tensors * normstats[1][0] + normstats[0][0]\n\ndef show_batch(dl):#just to show one batch of our data\n    for img, _ in dl:\n        fig, ax = plt.subplots(figsize=(8,8))\n        ax.set_xticks([]);ax.set_yticks([])\n        ax.imshow(torchvision.utils.make_grid(img[:64],nrow = 8).permute(1,2,0))\n        break\n\ndef show_images(images):\n    fig, ax = plt.subplots(figsize=(8,8))\n    ax.set_xticks([]),ax.set_yticks([])\n    ax.imshow(torchvision.utils.make_grid(denorm(images.detach()[:64]),nrow = 8).permute(1,2,0))\n\ndataload = DataLoader(dataset,batch_size,num_workers = 4,shuffle = True, pin_memory=True)#makes our data into batches\nshow_batch(dataload)","29781443":"def find_default_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    else:\n        return torch.device('cpu')","bbe9fd3e":"device = find_default_device()","418a622a":"device","24a54fef":"def to_device(data,device):\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    else:\n        return data.to(device, non_blocking=True)","d5450630":"class DataloaderDeviced():\n    def __init__(self,data,device):\n        self.data = data\n        self.device = device\n    def __iter__(self):\n        for b in self.data:\n            yield to_device(b,self.device)\n    def __len__(self):\n        return len(self.data)","6bb26a41":"dataload = DataloaderDeviced(dataload,device)","66e96d1f":"descriminator = nn.Sequential(\n    #input size being of 3 channels, 256x256\n    nn.Conv2d(3, 32 ,kernel_size = 3, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(32),\n    nn.LeakyReLU(0.1, inplace=True),\n    #output size being of 32 channels, 128x128\n    \n    nn.Conv2d(32,64,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 64x64x64\n    \n    nn.Conv2d(64,128,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.1, inplace = True),\n    #out 128x32x32\n    \n    nn.Conv2d(128,256,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.1,inplace = True),\n    #out 256x16x16\n    \n    nn.Conv2d(256,512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.1, inplace = True),\n    #out 512x8x8\n    \n    nn.Conv2d(512,1024, kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(1024),\n    nn.LeakyReLU(0.1,inplace = True),\n    #out 1024x4x4\n    \n    nn.Conv2d(1024,1,kernel_size = 4,stride = 1, padding = 0, bias = False),\n    #out 1x1x1\n    \n    nn.Flatten(),\n    nn.Sigmoid(),\n    #final activation for T\/F\n)\n\n#descriminator.load_state_dict(torch.load(\"..\/input\/weights\/discweights4.pth\"))\ndescriminator = to_device(descriminator,device)\ndescriminator","e63d6f21":"latent_sz = 128","823dce36":"generator = nn.Sequential(\n    #latent in 128x1x1\n    nn.ConvTranspose2d(128,1024,kernel_size = 4, stride = 1, padding = 0, bias = False),\n    nn.BatchNorm2d(1024),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 1024x4x4\n    \n    nn.ConvTranspose2d(1024,512,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 512x8x8\n    \n    nn.ConvTranspose2d(512,256,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 256x16x16\n    \n    nn.ConvTranspose2d(256,128,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 128x32x32\n    \n    nn.ConvTranspose2d(128,64,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 64x64x64\n    \n    nn.ConvTranspose2d(64,32,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.BatchNorm2d(32),\n    nn.LeakyReLU(0.1, inplace=True),\n    #out 32x128x128\n    \n    nn.ConvTranspose2d(32,3,kernel_size = 4, stride = 2, padding = 1, bias = False),\n    nn.Tanh()\n    #out 3x256x256\n    \n)\n#generator.load_state_dict(torch.load(\"..\/input\/weights\/genweights4.pth\"))\ngenerator","5df54c99":"xb = torch.randn(batch_size,latent_sz,1,1,)\nfake_images = generator(xb)\nshow_images(fake_images)\ngenerator = to_device(generator,device)","ff6ab8e4":"def train_discriminator(real_images,opt_d):\n    \n    opt_d.zero_grad()\n    real_preds = descriminator(real_images)\n    real_targets = torch.ones(real_images.size(0),1,device = device)\n    real_loss = F.binary_cross_entropy(real_preds,real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    latent = torch.randn(batch_size,latent_sz,1,1, device = device)\n    fake_images = generator(latent)\n    \n    fake_preds = descriminator(fake_images)\n    fake_targets = torch.zeros(fake_images.size(0),1,device = device)\n    fake_loss = F.binary_cross_entropy(fake_preds,fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n    \n    loss = fake_loss+real_loss\n    loss.backward()\n    opt_d.step()\n    \n    return loss.item(),real_score,fake_score","30aca19e":"def train_generator(opt_g):\n    opt_g.zero_grad()\n    latent = torch.randn(batch_size,latent_sz, 1,1, device = device)\n    images = generator(latent)\n    \n    targets = torch.ones(batch_size,1,device = device)\n    score = descriminator(images)\n    loss = F.binary_cross_entropy(score,targets)\n    \n    loss.backward()\n    opt_g.step()\n    \n    return loss.item()","d93e9de5":"savedir = \"gen\"\nos.makedirs(savedir, exist_ok = True)\n","30a481bd":"def save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors)\n    fake_fname = 'generated-images-{0:0=4d}e1.png'.format(index+90)\n    save_image(denorm(fake_images), os.path.join(savedir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","3670eb5a":"torch.manual_seed(64)\nfixed_latent = torch.randn(batch_size, latent_sz, 1, 1, device=device)","06b94318":"save_samples(0,fixed_latent)","98c65584":"def fit(epochs, lr, start_idx = 1):\n    loss_d =[]\n    loss_g = []\n    real_scores = []\n    fake_scores = []\n    \n    opt_d = torch.optim.Adam(descriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for img, _ in tqdm(dataload):\n            \n            loss, real_score, fake_score = train_discriminator(img, opt_d)\n            lossg = train_generator(opt_g)\n            \n        loss_d.append(loss)\n        loss_g.append(lossg)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        print(\"Epoch [{}\/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n            epoch+1, epochs, loss, lossg, real_score, fake_score))\n        \n        save_samples(epoch+start_idx, fixed_latent, show=False)\n        \n    return loss_g,loss_d,real_scores,fake_scores","6b9818fa":"lr = 5e-4\nepochs = 2\nhistory = fit(epochs,lr)","39e81c0f":"torch.save(generator.state_dict(),\"genweights4.pth\")","0f9229f0":"torch.save(descriminator.state_dict(),\"discweights4.pth\")","451888ba":"torch.manual_seed(94)\nlatent_test = torch.randn(1,latent_sz,1,1,device=device)\nimage = generator(latent_test)","e242c19b":"image=to_device(image, torch.device(\"cpu\"))\nb=image[0].permute(1,2,0).detach().numpy()\nb.shape","97862174":"plt.imshow(b)","7e6a4773":"!pip install jovian","bd371bf6":"prjname=\"cars_generator\"","3b00a9dd":"import jovian","42f9fae4":"jovian.commit(project=prjname,environment = None)","5e96e127":"# The Fit function\nhere we fit our images to the training dataset.","2d1e4df8":"# Testing Our function\nwe generate a single image and then display it.\n<br>\nwe can inspect it ourselves to see how real this image can get","c9b9f980":"### training our generator\nSo we know that, given an input random tensor we recive an image from our generator, so we essentially generate a batch of images from our generator and give them to the discriminator, who then returns 1 or 0 depending if the image is real or not, Ideally we ****should**** be able to fool our discirminator, so the fake images we generate should return a value of 1(real).\n<br>\nbased off what our discriminator returns, we then backpropogate and update the weights accordingly.","d35ddbb0":"# GPU Time!\nhere we define classes that load stuff to our accelerator that would help us achieve faster epochs","9a8d3163":"# Importing The Right Modules\njust the importing stuff, if you're familiar with torch, you'll know what these are for","ed2c9798":"# Making our Generator\ntaking in a latent vector of size 128, we're going to generate an image of size 256x256.<br>\nthis is our generator, here, we take in a random tensor(a random value for imagining our random image), and then by the magic of transposed convolutions, we generate images.\n","4a09c66e":"# Making our Discirminator\nwe have input images of size 3x256x256\nwe are now trying to define a discriminator network that would differentiate between fake and real images acting as the loss function to our generator.\n<br>essentially:\n<br>this guy is the guy who tells our generator how wrong his generated image is, based off which changes to the generated images are made","9983f423":"# Getting our Data Ready\nhere we define our, path, image size, batch size and normalization stats for getting our data ready for processing","b54ef94a":"# Training functions\n### training our discriminator\nHere's how we train a GAN, we first feed real images form our dataset to the discriminator(whose job is basically to tell if the generated image is fake or real),<br>\nIdeally for images from our dataset, our discrimiator should return 'real'(1), so our target is sessentially 1<br>\n<br>\nWe also generate fake images from our generator so that our discriminator knows what a 'fake' image is aswell, so here, our target is 'fake'(0).\n<br>\nBased off the outputs we recive, we backpropogate and updates the weights accordingly to recive the ideal outputs.","da178d94":"# Helper Functions to Save images\n\nhere we have helper functions that help us save images we generated in each training epoch","5bbc7242":"# That's it\nHope this experiment was informative and we could gain a few insights on how this dataset would work on our GAN","07a1d69b":"I just made a GAN for cars from this dataset, cause I was bored. The dataset isn't meant for it, But I did it anyways :D\n<br>\nCode uses pytorch for making a GAN","52b74e87":"# Saving our Weights\nYeah kaggle disconnects interactive sessions after a while,so we save and download the weights to see how the progress goes for the number of epochs we ran\n<br>\nwe save the weights into .pth files"}}