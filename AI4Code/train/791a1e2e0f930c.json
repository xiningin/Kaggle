{"cell_type":{"2af027a6":"code","acb0c87b":"code","bb31c0c4":"code","2c79e542":"code","0dec46c7":"code","d9b48a3d":"code","eae6733f":"code","9b3c4eef":"code","4fedc4a7":"code","6f6136c5":"code","95bf45ca":"code","c96413ae":"code","6aba4e73":"code","560e3868":"code","2fa9d878":"code","301b244f":"code","c79df061":"code","474947c6":"code","9ed6ce5c":"code","c2346b6d":"code","2e716f48":"code","7e29f887":"code","52332a90":"code","a697867e":"code","a12336fe":"code","b54f4d2e":"code","2753441c":"code","90ff8097":"code","7f20ea96":"code","f7f98fd9":"code","8bf3af46":"code","5bd4d339":"code","2663fd46":"code","e1372d7a":"code","ba76148e":"code","5c51f8ed":"code","5567f399":"code","8bd22f9f":"code","fca03de4":"code","c6924d8b":"code","d28cf19a":"code","f2d94de8":"code","5c963853":"code","d55da47c":"code","a7415a1f":"code","69dac213":"code","3a9781ab":"code","af6ed546":"code","764d59da":"code","84140313":"code","9643e3a9":"code","f06ed336":"code","d009df7a":"code","500d064b":"code","71105d16":"code","35767344":"code","70cb889b":"code","dca21d25":"code","cb6de8a4":"code","b844b337":"code","0eea19ce":"code","e697112d":"code","194a518d":"code","b969b255":"code","3ffe1d56":"code","64b6507c":"code","e633d633":"code","24302b8f":"code","de775e05":"code","6093948c":"code","d420d24e":"code","552fd505":"code","dc0d2454":"code","47da84c3":"code","afc985e9":"code","071e2293":"code","61da9f09":"code","87b62c5b":"code","5dd766d4":"code","5d359e56":"code","a8685fce":"code","488a6fdd":"code","f0c6904b":"code","32813821":"markdown","8cee463e":"markdown","84caff08":"markdown","262588df":"markdown","7e6fdf1b":"markdown","5c5e65bf":"markdown","0f5cb9c9":"markdown","1333df6c":"markdown","adfa9952":"markdown","89becbce":"markdown","52c2fcfa":"markdown","7bc081da":"markdown","bbb618aa":"markdown","b995e670":"markdown","c7f49a82":"markdown","e4dd4749":"markdown","f4b014d6":"markdown","92870f1f":"markdown","a36baa24":"markdown","76222129":"markdown","6230e749":"markdown","1971ac64":"markdown","40f7d196":"markdown","e7b7090d":"markdown","4b597038":"markdown","7bef014d":"markdown","ca5303a4":"markdown","f0ef0677":"markdown","3499a173":"markdown","1901ca4c":"markdown","0025c1ff":"markdown","05d776c8":"markdown","97fd3193":"markdown","67e083e7":"markdown","15e88bdd":"markdown","a27489ae":"markdown","2e2ffdf5":"markdown","268dd697":"markdown","556962ce":"markdown","3764b6af":"markdown","4e0be657":"markdown","ea404c2c":"markdown","f522d442":"markdown","a3c69e14":"markdown","c088dc62":"markdown","51d3905b":"markdown","8381bc2d":"markdown","430a1404":"markdown","dd4d0ba0":"markdown","be0da8fc":"markdown","5d3dc4a3":"markdown","b2a8f321":"markdown","fcbc7d19":"markdown","03f18778":"markdown","5f22fe9e":"markdown","28dcea94":"markdown","9236fd7f":"markdown","10ba1ec7":"markdown","946eec49":"markdown","32629aca":"markdown","4ca69a82":"markdown"},"source":{"2af027a6":"#import the warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","acb0c87b":"#import the useful libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","bb31c0c4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2c79e542":"#read the data set of \"bank telemarketing campaign\" in inp0.\ninp0= pd.read_csv(r'\/kaggle\/input\/bank_marketing_updated_v1.csv')\ninp0","0dec46c7":"#Print the head of the data frame.\ninp0.head()","d9b48a3d":"#read the file in inp0 without first two rows as it is of no use.\ninp0= pd.read_csv(r'\/kaggle\/input\/bank_marketing_updated_v1.csv',skiprows=2)\ninp0","eae6733f":"#print the head of the data frame.\ninp0.head()","9b3c4eef":"#print the information of variables to check their data types.\nprint(type(inp0.info()))","4fedc4a7":"#convert the age variable data type from float to integer.\n\ninp0['age']=inp0['age'].astype('Int64')\ninp0","6f6136c5":"#print the average age of customers.\navg=np.mean(inp0['age'])\nprint(round(avg,2))","95bf45ca":"#drop the customer id as it is of no use.\ninp0=inp0.drop(['customerid'],axis=1)\ninp0","c96413ae":"#Extract job in newly created 'job' column from \"jobedu\" column.\njobedu=inp0['jobedu'].apply(lambda x: pd.Series(x.split(',')))\ninp0['job']=jobedu[0]\ninp0","6aba4e73":"#Extract education in newly created 'education' column from \"jobedu\" column.\ninp0['education']= jobedu[1]\ninp0","560e3868":"#drop the \"jobedu\" column from the dataframe.\ninp0=inp0.drop(['jobedu'],axis=1)\ninp0","2fa9d878":"#count the missing values in age column.\ninp0.age.isnull().sum(axis=0)","301b244f":"#pring the shape of dataframe inp0\ninp0.shape","c79df061":"#calculate the percentage of missing values in age column.\nround(100*(inp0.age.isnull().sum(axis=0)\/len(inp0.index)),2)","474947c6":"#drop the records with age missing in inp0 and copy in inp1 dataframe.\ninp1= inp0[~inp0.age.isnull()].copy()\ninp1","9ed6ce5c":"#count the missing values in month column in inp1.\ninp1.month.isnull().sum(axis=0)","c2346b6d":"#print the percentage of each month in the data frame inp1.\ninp1.month.value_counts(normalize=True) *100","2e716f48":"#find the mode of month in inp1\nmode_month=inp1.month.mode()[0]\nmode_month","7e29f887":"# fill the missing values with mode value of month in inp1.\ninp1.month.fillna(mode_month,inplace=True)","52332a90":"#let's see the null values in the month column.\ninp1.month.isna().sum()","a697867e":"#count the missing values in response column in inp1.\ninp1.response.isna().sum()","a12336fe":"#calculate the percentage of missing values in response column. \nround(100*(inp1.response.isna().sum())\/len(inp1.index),3)","b54f4d2e":"#drop the records with response missings in inp1.\ninp1=inp1[~inp1.response.isna()]\ninp1","2753441c":"#calculate the missing values in each column of data frame: inp1.\ninp1.isna().sum()","90ff8097":"#describe the pdays column of inp1.\ninp1.pdays.describe()","7f20ea96":"#describe the pdays column with considering the -1 values.\ninp1.loc[inp1.pdays<0,\"pdays\"]= np.NaN\ninp1.pdays.describe()","f7f98fd9":"#describe the age variable in inp1.\ninp1.age.describe()","8bf3af46":"#plot the histogram of age variable.\nimport matplotlib.pyplot as plt\ninp1.age.plot.hist()\nplt.show()","5bd4d339":"#plot the boxplot of age variable.\nimport seaborn as sns\nsns.boxplot(inp1.age)\nplt.show()","2663fd46":"#describe the salary variable of inp1.\ninp0.salary.describe()","e1372d7a":"#plot the boxplot of salary variable.\nsns.boxplot(inp0.salary)","ba76148e":"#describe the balance variable of inp1.\ninp0.balance.describe()","5c51f8ed":"#plot the boxplot of balance variable.\nsns.boxplot(inp0.balance)","5567f399":"#plot the boxplot of balance variable after scaling in 8:2.\nplt.figure(figsize=(8,2))\nsns.boxplot(inp0.balance)","8bd22f9f":"#print the quantile (0.5, 0.7, 0.9, 0.95 and 0.99) of balance variable\ninp1.balance.quantile([0.5, 0.7, 0.9, 0.95,0.99])\n","fca03de4":"#describe the duration variable of inp1\ninp1.duration.describe()\n","c6924d8b":"#convert the duration variable into single unit i.e. minutes. and remove the sec or min prefix.\ninp1.duration=inp1.duration.apply(lambda x: float(x.split()[0])\/60 if x.find(\"sec\")>0 else float(x.split()[0]))\n","d28cf19a":"#describe the duration variable\ninp1.duration.describe()","f2d94de8":"#calculate the percentage of each marital status category. \nmarital=inp1.marital.value_counts(normalize=True)*100\nmarital","5c963853":"#plot the bar graph of percentage marital status categories\nmarital.plot.barh(color='r')\nplt.show()","d55da47c":"#calculate the percentage of each job status category.\njob=inp1.job.value_counts(normalize=True)*100\njob","a7415a1f":"#plot the bar graph of percentage job categories\njob.plot.barh(color='g')\nplt.show()","69dac213":"#calculate the percentage of each education category.\neducation=inp1.education.value_counts(normalize=True)*100\neducation","3a9781ab":"#plot the pie chart of education categories\neducation.plot.pie()\nplt.show()\n","af6ed546":"#calculate the percentage of each poutcome category.\npoutcome=inp1.poutcome.value_counts(normalize=True)*100\npoutcome                                                                               ","764d59da":"poutcome.plot.pie()\nplt.show()","84140313":"poutcometarget=inp1[~(inp1.poutcome=='unknown')].poutcome.value_counts(normalize=True)*100\npoutcometarget","9643e3a9":"poutcometarget.plot.bar()\nplt.show()","f06ed336":"#calculate the percentage of each response category.\nresponse=inp1.response.value_counts(normalize=True)*100\nresponse","d009df7a":"#plot the pie chart of response categories\nresponse.plot.pie()\nplt.show()","500d064b":"#plot the scatter plot of balance and salary variable in inp0\ninp0.plot.scatter(x='salary',y='balance')\nplt.show()","71105d16":"#plot the scatter plot of balance and age variable in inp1\nplt.scatter(inp1.age,inp1.balance)\nplt.show()","35767344":"#plot the pair plot of salary, balance and age in inp1 dataframe.\nsns.pairplot(data=inp1,vars=['salary','balance','age'])\nplt.show()","70cb889b":"#plot the correlation matrix of salary, balance and age in inp1 dataframe.\ninp1[['salary','balance','age']].corr()","dca21d25":"sns.heatmap(inp1[['salary','balance','age']].corr(),annot=True,cmap='Reds')\n\nplt.show()","cb6de8a4":"#groupby the response to find the mean of the salary with response no & yes seperatly.\ninp1.groupby(\"response\")[\"salary\"].mean()","b844b337":"#groupby the response to find the median of the salary with response no & yes seperatly.\ninp1.groupby(\"response\")[\"salary\"].median()","0eea19ce":"#plot the box plot of salary for yes & no responses.\nsns.boxplot(data=inp1,x='response',y='salary')\nplt.show()","e697112d":"#plot the box plot of balance for yes & no responses.\nsns.boxplot(data=inp1,x='response',y='balance')\nplt.show()","194a518d":"#groupby the response to find the mean of the balance with response no & yes seperatly.\ninp1.groupby(\"response\")['balance'].mean()","b969b255":"#groupby the response to find the median of the balance with response no & yes seperatly.\ninp1.groupby(\"response\")['balance'].median()","3ffe1d56":"#function to find the 75th percentile.\ndef p75(x):\n    return np.quantile(x, 0.75)","64b6507c":"#calculate the mean, median and 75th percentile of balance with response\ninp1.groupby(\"response\")['balance'].aggregate([\"mean\",\"median\",p75])","e633d633":"#plot the bar graph of balance's mean an median with response.\ninp1.groupby(\"response\")['balance'].aggregate([\"mean\",\"median\"]).plot.bar()\nplt.show()","24302b8f":"#groupby the education to find the mean of the salary education category.\ninp1.groupby(\"education\")[\"salary\"].mean()","de775e05":"#groupby the education to find the median of the salary for each education category.\ninp1.groupby(\"education\")[\"salary\"].median()","6093948c":"#groupby the job to find the mean of the salary for each job category.\ninp1.groupby(\"job\")[\"salary\"].mean()","d420d24e":"#create response_flag of numerical data type where response \"yes\"= 1, \"no\"= 0\ninp1['response_flag']=np.where(inp1.response=='yes',1,0)\ninp1.response_flag.value_counts()","552fd505":"#calculate the mean of response_flag with different education categories.\ninp1.groupby(\"education\")[\"response_flag\"].mean()","dc0d2454":"#calculate the mean of response_flag with different marital status categories.\ninp1.groupby(\"marital\")[\"response_flag\"].mean()","47da84c3":"#plot the bar graph of marital status with average value of response_flag\n(inp1.groupby(\"marital\")[\"response_flag\"].mean()).plot.barh()","afc985e9":"#plot the bar graph of personal loan status with average value of response_flag\n(inp1.groupby(\"loan\")[\"response_flag\"].mean()*100).plot.bar()\nplt.show()","071e2293":"#plot the bar graph of housing loan status with average value of response_flag\n(inp1.groupby(\"housing\")[\"response_flag\"].mean()*100).plot.bar()\n","61da9f09":"#plot the boxplot of age with response_flag\nsns.boxplot(data=inp1,x='response_flag',y='age')","87b62c5b":"#create the buckets of <30, 30-40, 40-50 50-60 and 60+ from age column.\ninp1[\"age_group\"]= pd.cut(inp1.age,[0,30,40,50,60,120],labels=[\"<30\", \"30-40\", \"40-50\",\"50-60\",\"60+\"])","5dd766d4":"#plot the percentage of each buckets and average values of response_flag in each buckets. plot in subplots.\nplt.figure(figsize=[10,4])\nplt.subplot(1,2,1)\n(inp1.age_group.value_counts(normalize=True)*100).plot.bar()\nplt.subplot(1,2,2)\n(inp1.groupby(['age_group'])['response_flag'].mean()*100).plot.bar()\nplt.show()","5d359e56":"#plot the bar graph of job categories with response_flag mean value.\n(inp1.groupby(['job'])['response_flag'].mean()*100).plot.barh()\nplt.show()","a8685fce":"#create heat map of education vs marital vs response_flag\n\nax=pd.pivot_table(data=inp1,index=\"education\",columns='marital',values='response_flag')\nsns.heatmap(ax,annot=True,cmap='PiYG')\nplt.show()\n","488a6fdd":"#create the heat map of Job vs marital vs response_flag.\nax=pd.pivot_table(data=inp1,index='job',columns='marital',values='response_flag')\nsns.heatmap(ax,annot=True,cmap='rainbow')\nplt.show()","f0c6904b":"#create the heat map of education vs poutcome vs response_flag.\nax=pd.pivot_table(data=inp1,index='education',columns='poutcome',values='response_flag')\nsns.heatmap(ax,annot=True,cmap='plasma_r')\nplt.show()","32813821":"### Segment-2, Numeric- numeric analysis ","8cee463e":"Checklist for data standardization exercises:\n- **Standardise units**: Ensure all observations under one variable are expressed in a common and consistent unit, e.g., convert lbs to kg, miles\/hr to km\/hr, etc.\n- **Scale values if required**: Make sure all the observations under one variable have a common scale.\n- **Standardise precision** for better presentation of data, e.g., change 4.5312341 kg to 4.53 kg.\n- **Remove extra characters** such as common prefixes\/suffixes, leading\/trailing\/multiple spaces, etc. These are irrelevant to analysis.\n- **Standardise case**: String variables may take various casing styles, e.g., UPPERCASE, lowercase, Title Case, Sentence case, etc.\n- **Standardise format**: It is important to standardise the format of other elements such as date, name, etce.g., change 23\/10\/16 to 2016\/10\/23, \u201cModi, Narendra\u201d to \u201cNarendra Modi\", etc.","84caff08":"#### handling missing values in response column ","262588df":"#### Dropping customer id column. ","7e6fdf1b":"#### Balance vs response ","5c5e65bf":"### Segment- 5, Categorical categorical variable ","0f5cb9c9":"## Session- 2, Data Cleaning ","1333df6c":"#### Education vs marital vs response ","adfa9952":"### Segment- 6, Standardising values ","89becbce":"#### Age variable ","52c2fcfa":"### Segment- 5, Handling Outliers ","7bc081da":"### Segment- 3, Categorical ordered univariate analysis ","bbb618aa":"Take aways from the lecture on missing values:\n\n- **Set values as missing values**: Identify values that indicate missing data, for example, treat blank strings, \"NA\", \"XX\", \"999\", etc., as missing.\n- **Adding is good, exaggerating is bad**: You should try to get information from reliable external sources as much as possible, but if you can\u2019t, then it is better to retain missing values rather than exaggerating the existing rows\/columns.\n- **Delete rows and columns**: Rows can be deleted if the number of missing values is insignificant, as this would not impact the overall analysis results. Columns can be removed if the missing values are quite significant in number.\n- **Fill partial missing values using business judgement**: Such values include missing time zone, century, etc. These values can be identified easily.\n\nTypes of missing values:\n- **MCAR**: It stands for Missing completely at random (the reason behind the missing value is not dependent on any other feature).\n- **MAR**: It stands for Missing at random (the reason behind the missing value may be associated with some other features).\n- **MNAR**: It stands for Missing not at random (there is a specific reason behind the missing value).\n","b995e670":"#### Housing loans vs response rate ","c7f49a82":"#### Education vs response rate","e4dd4749":"#### Education vs salary ","f4b014d6":"#### Marital status ","92870f1f":"There are three ways to analyse the numeric- numeric data types simultaneously.\n- **Scatter plot**: describes the pattern that how one variable is varying with other variable.\n- **Correlation matrix**: to describe the linearity of two numeric variables.\n- **Pair plot**: group of scatter plots of all numeric variables in the data frame.","a36baa24":"#### Education","76222129":"#### handling pdays column. ","6230e749":"#### Balance variable ","1971ac64":"#### Importing the libraries.","40f7d196":"#### Education vs poutcome vs response","e7b7090d":"#### handling missing values in age column.","4b597038":"There are multiple types of data types available in the data set. some of them are numerical type and some of categorical type. You are required to get the idea about the data types after reading the data frame. \n\nFollowing are the some of the types of variables:\n- **Numeric data type**: banking dataset: salary, balance, duration and age.\n- **Categorical data type**: banking dataset: education, job, marital, poutcome and month etc.\n- **Ordinal data type**: banking dataset: Age group.\n- **Time and date type** \n- **Coordinates type of data**: latitude and longitude type.\n","7bef014d":"### Segment- 2, Data Types ","ca5303a4":"#### Problem Statement:","f0ef0677":"Major approaches to the treat outliers:\n \t\t\n- **Imputation**\n- **Deletion of outliers**\n- **Binning of values**\n- **Cap the outlier**\n","3499a173":"#### Correlation heat map ","1901ca4c":"Target variable is better of not imputed.\n- Drop the records with missing values.","0025c1ff":"### Segment- 2, Categorical unordered univariate analysis ","05d776c8":"### Segment- 4, Numerical categorical variable","97fd3193":"-1 indicates the missing values.\nMissing value does not always be present as null.\nHow to handle it:\n\nObjective is:\n- you should ignore the missing values in the calculations\n- simply make it missing - replace -1 with NaN.\n- all summary statistics- mean, median etc. we will ignore the missing values of pdays.","67e083e7":"#### handling missing values in month column","15e88bdd":"#### Salary variable ","a27489ae":"##### making buckets from age columns ","2e2ffdf5":"## Session- 3, Univariate Analysis ","268dd697":"Ordered variables have some kind of ordering. Some examples of bank marketing dataset are:\n- Age group= <30, 30-40, 40-50 and so on.\n- Month = Jan-Feb-Mar etc.\n- Education = primary, secondary and so on.","556962ce":"#### Duration variable","3764b6af":"Checklist for fixing rows:\n- **Delete summary rows**: Total and Subtotal rows\n- **Delete incorrect rows**: Header row and footer row\n- **Delete extra rows**: Column number, indicators, Blank rows, Page No.\n\nChecklist for fixing columns:\n- **Merge columns for creating unique identifiers**, if needed, for example, merge the columns State and City into the column Full address.\n- **Split columns to get more data**: Split the Address column to get State and City columns to analyse each separately. \n- **Add column names**: Add column names if missing.\n- **Rename columns consistently**: Abbreviations, encoded columns.\n- **Delete columns**: Delete unnecessary columns.\n- **Align misaligned columns**: The data set may have shifted columns, which you need to align correctly.\n","4e0be657":"Unordered data do not have the notion of high-low, more-less etc. Example:\n- Type of loan taken by a person = home, personal, auto etc.\n- Organisation of a person = Sales, marketing, HR etc.\n- Job category of persone.\n- Marital status of any one.\n","ea404c2c":"Drop the records with age missing. ","f522d442":"#### Job vs salary","a3c69e14":"## Session- 4, Bivariate and Multivariate Analysis","c088dc62":"#### Read the file without unnecessary headers.","51d3905b":"#### poutcome ","8381bc2d":"#### Loans vs response rate ","430a1404":"### Segment-6, Multivariate analysis ","dd4d0ba0":"#### Response the target variable ","be0da8fc":"#### Marital vs response rate ","5d3dc4a3":"#### Dividing \"jobedu\" column into job and education categories. ","b2a8f321":"#### Job  ","fcbc7d19":"### Segment- 3, Fixing the Rows and Columns ","03f18778":"\u00a0\n\nThe bank provides financial services\/products such as savings accounts, current accounts, debit cards, etc. to its customers. In order to increase its overall revenue, the bank conducts various marketing campaigns for its financial products such as credit cards, term deposits, loans, etc. These campaigns are intended for the bank\u2019s existing customers. However, the marketing campaigns need to be cost-efficient so that the bank not only increases their overall revenues but also the total profit. You need to apply your knowledge of EDA on the given dataset to analyse the patterns and provide inferences\/solutions for the future marketing campaign.\n\nThe bank conducted a telemarketing campaign for one of its financial products \u2018Term Deposits\u2019 to help foster long-term relationships with existing customers. The dataset contains information about all the customers who were contacted during a particular year to open term deposit accounts.\n\n\n**What is the term Deposit?**\n\nTerm deposits also called fixed deposits, are the cash investments made for a specific time period ranging from 1 month to 5 years for predetermined fixed interest rates. The fixed interest rates offered for term deposits are higher than the regular interest rates for savings accounts. The customers receive the total amount (investment plus the interest) at the end of the maturity period. Also, the money can only be withdrawn at the end of the maturity period. Withdrawing money before that will result in an added penalty associated, and the customer will not receive any interest returns.\n\nYour target is to do end to end EDA on this bank telemarketing campaign data set to infer knowledge that where bank has to put more effort to improve it's positive response rate. ","5f22fe9e":"##### 75th percentile ","28dcea94":"#### Job vs marital vs response ","9236fd7f":"### Segment- 4, Impute\/Remove missing values ","10ba1ec7":"#### Salary vs response ","946eec49":"#### Read in the Data set. ","32629aca":"#### Age vs response ","4ca69a82":"## Bank Telemarketing Campaign Case Study."}}