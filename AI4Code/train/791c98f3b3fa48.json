{"cell_type":{"8af2ba1e":"code","b5c4038f":"code","8943c346":"code","e2b61bda":"code","027f408a":"code","e719eeda":"code","92848b51":"code","393e4094":"code","855be9ba":"code","31fa06d5":"code","fc94a910":"code","5acd1f34":"code","a4ebf18e":"code","9304d90a":"code","a38ba6c8":"code","a6b40059":"code","d769be62":"code","9cfb1dbb":"code","a9056f5a":"code","a651ee8b":"code","00f4620a":"code","d2b10f2b":"code","10d7e511":"code","2a2cdf93":"code","3a13d064":"code","139324d2":"code","ef25d241":"code","18340fe3":"code","4fbadda6":"code","d7fc8d23":"code","d5199255":"code","c7703f8f":"markdown","b9ad06d7":"markdown","776f66db":"markdown","38fb4e7c":"markdown","5301c685":"markdown","a406d3ed":"markdown","081deeac":"markdown","d359b4f0":"markdown","91198e59":"markdown","49dbb0c4":"markdown","3c2a3396":"markdown","27177830":"markdown","4f5e380f":"markdown","8083f94c":"markdown","e13fed85":"markdown","3693afc1":"markdown","cfdd91a5":"markdown","63d8d0c7":"markdown"},"source":{"8af2ba1e":"#importing packages for data Analysis\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n#importing wordcloud for visual\n\nfrom wordcloud import WordCloud, STOPWORDS","b5c4038f":"#importing packages for data visuals\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#importing packages for interactive data visuals\n\nfrom plotly import __version__\n\nimport cufflinks as cf\n\nfrom plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\ninit_notebook_mode(connected=True)\ncf.go_offline()\n\n\nfrom IPython.display import HTML","8943c346":"#importing data\n\ndf = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv',index_col = 0)","e2b61bda":"df.info()","027f408a":"df.tail(3)","e719eeda":"# we can see in above tail of the data columns nun value is filled with -1,-1.0 and \"-1\" so we can replace with np.nun\n\ndf.replace(to_replace =-1,  value = np.nan,inplace=True)\n\ndf.replace(to_replace =-1.0,value = np.nan,inplace=True)\n\ndf.replace(to_replace ='-1',value = np.nan,inplace=True)","92848b51":"#let us look at Missing data\n\nmissing_data = df.isnull().sum()\/len(df)*100\n\nmissing_data.iplot(kind='bar',color='#F52D5E',  title='Missing values in each column', yTitle='In percentage')\n","393e4094":"# since competitors and Easy Apply columns are almost 70% of data is missing so it is not required for analysis\n \ndf.drop(['Easy Apply','Competitors'],1,inplace = True)\n\n\n# we can continue cleaning for Salary, Company Rating and Location\n                 ","855be9ba":"# cleaning Salary Estimate column\n# let us remove the unwanted 'strings'\n\ndf['Salary Estimate'] = df['Salary Estimate'].str.replace('Glassdoor est.','')\ndf['Salary Estimate'] = df['Salary Estimate'].str.replace('$', '')\ndf['Salary Estimate'] = df['Salary Estimate'].str.replace('K','')\ndf['Salary Estimate'] = df['Salary Estimate'].str.strip('()')\n\n#let us split the Salary Estimate into two parts Min and Max\n\nSalary_min_max = df['Salary Estimate'].str.split('-',expand=True)","31fa06d5":"# join the columns\ndf['Salary_Min'] = Salary_min_max[0]\ndf['Salary_Max'] = Salary_min_max[1]\n\n# convert the column into float64\ndf['Salary_Min'] = pd.to_numeric(df['Salary_Min'])\ndf['Salary_Max'] = pd.to_numeric(df['Salary_Max'])","fc94a910":"# cleaning company name column\n\ndf['Company Name'] = df['Company Name'].str.replace(r'\\W',\" \")\ndf['Company Name'] = df['Company Name'].str.replace('\\d+', '')","5acd1f34":"# cleaning location column\n\ndf['Location'] = df['Location'].str.replace(r'\\W',\" \")\ndf['Location'] = df['Location'].str.replace('\\d+', '')","a4ebf18e":"# cleaning Job Title column\n\ndf['Job Title'] = df['Job Title'].str.replace(r'\\W',\" \")\ndf['Job Title'] = df['Job Title'].str.replace('\\d+', '')","9304d90a":"#df['Job Description']\n\n\ndf['Job Description'] = df['Job Description'].str.replace(r'\\W',\" \")\ndf['Job Description'] = df['Job Description'].str.replace('\\d+', '')","a38ba6c8":"df.info()","a6b40059":"# ploting data \n\nplt.figure(figsize=(10,6))\nsns.set_context(context='notebook', font_scale=1)\nsns.set_style('whitegrid')\nsns.pairplot(df)","d769be62":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in df['Job Title']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 1200, height = 1200, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = '#9CC9AD') \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('Job Title')  \nplt.show() ","9cfb1dbb":"comment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in df['Job Description']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for text in range(len(tokens)): \n        tokens[text] = tokens[text].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 1200, height = 1200, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 20).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = '#6897BB') \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('Job Description')  \nplt.show() ","a9056f5a":"\n\n# data for plot\n\ndf[df['Job Title']== 'Data Analyst']['Location'].value_counts()[0:10].iplot(kind='bar',color='#FFC300',title='Top 10 location with Data Analyst job')\n    ","a651ee8b":"# ploting the rating\n\nplt.figure(figsize=(14,6))\nsns.countplot(df['Rating'])\nplt.title('Rating')","00f4620a":"# top 10 rated company \n\ndf[df['Rating'] >= 4 ]['Company Name'].dropna().value_counts()[0:10].iplot(kind='bar',color='green',title='Top 10 company with greater than 4 rating')","d2b10f2b":"print('*******************************************')\nprint('The Average rating is Data Analyst',round(df[df['Job Title'] == 'Data Analyst']['Rating'].mean(),2)) \nprint('*******************************************')","10d7e511":"print('*****************************************************')\nprint('Minimum mean salary for Data Analyst role is',round(df[df['Job Title'] == 'Data Analyst']['Salary_Min'].mean()*1000,2))\nprint('*****************************************************')\nprint('Maximum mean salary for Data Analyst role is',round(df[df['Job Title'] == 'Data Analyst']['Salary_Max'].mean()*1000,2))\nprint('*****************************************************')","2a2cdf93":"# let us plot the distribution of salary\n\nx = df['Salary_Min']\ny = df['Salary_Max']\n\n\nfig, ax = plt.subplots(1,2,figsize=(15, 6))\n\nplt.figure(figsize=(10,6))\n\nsns.set_style('dark')\nsns.set_context(context = 'notebook',font_scale=1)\nsns.distplot(x, ax = ax[0],color='red',bins=5,kde=False)\nsns.distplot(y, ax = ax[1],color='blue',bins=5,kde=False)\n\nax[0].title.set_text('Minimum Salary')\nax[1].title.set_text('Maximum Salary')\n\nplt.tight_layout()\n\n","3a13d064":"# plotting location where above mean salary of Data Analyst''\n\n\ndf[(df['Salary_Max'] >= 95)]['Location'].value_counts()[0:10].iplot(kind='bar',color='#52E2FE',title='Top 10 location where salary of Data Analyst above mean salary')\n","139324d2":"df[(df['Rating'] == 4.5)]['Job Title'].value_counts()[0:10].iplot(kind='bar',color='#61E6A8',title='Top rated Job title')","ef25d241":"rating_job_title = df[(df['Rating'] == 4.5)]['Job Title']\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in rating_job_title: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for text in range(len(tokens)): \n        tokens[text] = tokens[text].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 1200, height = 1200, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 20).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = '#52E2FE') \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('Top Rated job title')  \nplt.show() ","18340fe3":"# top 10 Industry\n\njob_industry = df['Industry'].value_counts()[0:10]\n\n\njob_industry.iplot(kind='bar',color='#61E6A8',title='Top 10 Industry')","4fbadda6":"# let us compare top 10 Industry in jobs with wordcloud\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in df['Industry']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for text in range(len(tokens)): \n        tokens[text] = tokens[text].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 1200, height = 1200, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 5).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = '#61E6A8') \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('Industry')  \nplt.show() ","d7fc8d23":"#top 10 Company with Data analyst role\n\ndf['Company Name'].value_counts()[0:10].iplot(kind='bar',color='purple',title='top 10 Company with Data analyst role') ","d5199255":"# what is mean salary of Data Analyst which is posted.\n\nprint('what is mean salary of Data Analyst which is posted ?')\nprint('******************************')\nprint('Minimum mean salary is',round(df[df['Job Title'] == 'Data Analyst']['Salary_Min'].mean()*1000,2))\nprint('******************************')\nprint('Maximum mean salary is',round(df[df['Job Title'] == 'Data Analyst']['Salary_Max'].mean()*1000,2))\nprint('******************************')\n\nprint('\\n')\n\nprint('what is average rating for the job title Data Analyst ?')\nprint('******************************')\nprint('The Average rating is',round(df[df['Job Title'] == 'Data Analyst']['Rating'].mean(),2)) ","c7703f8f":"# Industry","b9ad06d7":"# Objective of the Study:\n\n**To Find best jobs by Salary, Company Rating and Location**\n\n","776f66db":"# Job Description","38fb4e7c":"**let us see the most popular job title using wordcloud**","5301c685":"# Salary","a406d3ed":"# Data Analyst\n\n","081deeac":"let us answer some question\n\n1. what is mean salary of Data Analyst which is posted.\n\n2. what is average rating for the job title Data Analyst.\n\n3. what is best role to be and the answer is now we all know Data Analyst.\n\n\n","d359b4f0":"# Locations","91198e59":"if it is found useful do upvote **thanks!!!** ","49dbb0c4":" **let us compare top 10 Industry in jobs with wordcloud below**","3c2a3396":"**Top rated Job title**\n\n* as an assumption that top rated job title is above 4.5 rating","27177830":"Top 10 locations with Data Analyst role","4f5e380f":"# Rating","8083f94c":"# Company","e13fed85":"# Job Title","3693afc1":"# Data Exploratory Analysis","cfdd91a5":"**let use wordcloud to double check the above plot**","63d8d0c7":"# Data cleaning"}}