{"cell_type":{"1a7a54b7":"code","73893fde":"code","8a1389da":"code","201720d3":"code","d8bd5038":"code","edb8bdf2":"code","15a4e405":"code","46a9826f":"code","43d3fb69":"code","9af7d14c":"code","31a41b2f":"code","acb53031":"code","3c486fd3":"code","51ce2250":"code","0d81d406":"code","79564980":"code","530e50ee":"code","59ef028d":"code","bf329b46":"code","10fa9bdd":"code","ceabd87c":"code","55fefb1c":"code","c1068235":"code","59662042":"code","1ee1d0ff":"code","7604b8ea":"code","1c12f8c4":"code","8dada955":"code","c0baf51f":"code","ddeab1f6":"code","2011de0d":"code","7b16abb5":"code","4e31fc4a":"code","18c84b37":"code","8fa5ea7a":"code","f053cb5f":"code","6353bbcb":"code","78118178":"code","6e8e39cf":"code","13b2573e":"code","c27c49d7":"code","d319f755":"markdown"},"source":{"1a7a54b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt; \nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n# Importing sklearn libraries\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport pickle\n# Importing Keras libraries\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.applications import VGG16\nfrom keras.applications import imagenet_utils\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.layers import Dense, Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n \nimport warnings\nwarnings.filterwarnings('ignore')\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","73893fde":"%cd \/kaggle\/working\/\n!ls","8a1389da":"!wget https:\/\/www.dropbox.com\/s\/sh5yt160xzqjkk0\/Food-11.zip?dl=1","201720d3":"!mv Food-11.zip?dl=1 Food_11.zip","d8bd5038":"!unzip Food_11.zip","edb8bdf2":"!ls","15a4e405":"!rm -rf Food_11.zip","46a9826f":"train = [os.path.join(\"training\",img) for img in os.listdir(\"training\")]\nval = [os.path.join(\"validation\",img) for img in os.listdir(\"validation\")]\ntest = [os.path.join(\"evaluation\",img) for img in os.listdir(\"evaluation\")]\nlen(train),len(val),len(test)\n# len(test)","43d3fb69":"train_y = [int(img.split(\"\/\")[-1].split(\"_\")[0]) for img in train]\nval_y = [int(img.split(\"\/\")[-1].split(\"_\")[0]) for img in val]\ntest_y = [int(img.split(\"\/\")[-1].split(\"_\")[0]) for img in test]\nnum_classes = 11\n# Convert class labels in one hot encoded vector\ny_train = []\nfor x in train_y:\n    a = np.array([0]*num_classes)\n    a[x] = 1\n    y_train.append(a)\ny_val = []\nfor x in val_y:\n    a = np.array([0]*num_classes)\n    a[x] = 1\n    y_val.append(a)\ny_test = []\nfor x in test_y:\n    a = np.array([0]*num_classes)\n    a[x] = 1\n    y_test.append(a)\n    \n#len(y_train),len(y_val),len(y_test)\ny_train = np.array(y_train)\ny_val = np.array(y_val)\ny_test = np.array(y_test)\ny_train.shape,y_val.shape,y_test.shape","9af7d14c":"import pickle\nwith open(\"test_op.pkl\",\"wb\") as file:\n    pickle.dump(y_test,file)\nwith open(\"train_op.pkl\",\"wb\") as file:\n    pickle.dump(y_train,file)\nwith open(\"val_op.pkl\",\"wb\") as file:\n    pickle.dump(y_val,file)","31a41b2f":"print(\"Reading train images..\")\nX_train = [cv2.resize(cv2.imread(x), dsize=(224,224), interpolation=cv2.INTER_AREA) for x in train]\nprint(\"Done.\")\nlen(X_train)","acb53031":"model = VGG16(weights=\"imagenet\", include_top=False)\nouts = []\nfor img in X_train:\n    x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))\n    outs.append(model.predict(x)[0])\n    if len(outs) % 100 == 0:\n        print(len(outs))\nouts = np.array(outs)\nouts.shape\n# print(\"creating train features..\")\n# train_x, train_features, train_features_flatten = create_features(train, model)\n# print(\"creating val features..\")\n# val_x, val_features, val_features_flatten = create_features(val, model)\n# test_x, test_features, test_features_flatten = create_features(test, model)\n\n# print(train_x.shape, train_features.shape, train_features_flatten.shape)\n# print(val_x.shape, val_features.shape, val_features_flatten.shape)\n# print(test_x.shape, test_features.shape, test_features_flatten.shape)","3c486fd3":"print(outs.shape)\nwith open(\"train_features.pkl\",\"wb\") as file:\n    pickle.dump(outs,file)","51ce2250":"print(\"Reading val images..\")\nouts = []\nX_train = []\nX_val = [cv2.resize(cv2.imread(x), dsize=(224,224), interpolation = cv2.INTER_AREA) for x in val]\nprint(\"Done.\")\nlen(X_val)","0d81d406":"model = VGG16(weights=\"imagenet\", include_top=False)\nfor img in X_val:\n    x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))\n    outs.append(model.predict(x)[0])\n    if len(outs) % 100 == 0:\n        print(len(outs))\nouts = np.array(outs)\nouts.shape","79564980":"print(outs.shape)\nwith open(\"val_features.pkl\",\"wb\") as file:\n    pickle.dump(outs,file)","530e50ee":"outs = []\nX_val = []\nprint(\"Reading test images..\")\nX_test = [cv2.resize(cv2.imread(x), dsize=(224,224), interpolation = cv2.INTER_AREA) for x in test]\nprint(\"Done.\")\nlen(X_test)","59ef028d":"model = VGG16(weights=\"imagenet\", include_top=False)\nfor img in X_test:\n    x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))\n    outs.append(model.predict(x)[0])\n    if len(outs) % 100 == 0:\n        print(len(outs))\nouts = np.array(outs)\nouts.shape","bf329b46":"print(outs.shape)\nwith open(\"test_features.pkl\",\"wb\") as file:\n    pickle.dump(outs,file)","10fa9bdd":"outs = []\nX_train = []\nX_val = []\nX_test = []\n\n# val_features = []\n# train_features = []\nval_features = pickle.load(open(\"val_features.pkl\",\"rb\"))\ntrain_features = pickle.load(open(\"train_features.pkl\",\"rb\"))\ntest_features = pickle.load(open(\"test_features.pkl\",\"rb\"))","ceabd87c":"y_test = []\nwith open(\"test_op.pkl\",\"rb\") as file:\n    y_test = pickle.load(file)\ny_train = []\nwith open(\"train_op.pkl\",\"rb\") as file:\n    y_train = pickle.load(file)\ny_val = []\nwith open(\"val_op.pkl\",\"rb\") as file:\n    y_val = pickle.load(file)","55fefb1c":"print(train_features.shape, y_train.shape)\nprint(val_features.shape, y_val.shape)\nprint(test_features.shape,y_test.shape)","c1068235":"checkpointer = ModelCheckpoint(filepath='transfermodel_best.hdf5',\n                               verbose=1,save_best_only=True)\nmodel_transfer = Sequential()\nmodel_transfer.add(GlobalAveragePooling2D(input_shape=train_features.shape[1:]))\nmodel_transfer.add(Dropout(0.2))\nmodel_transfer.add(Dense(120, activation='relu'))\nmodel_transfer.add(Dense(256, activation='relu'))\nmodel_transfer.add(Dense(11, activation='softmax'))\nmodel_transfer.compile(loss='categorical_crossentropy', optimizer='adam',\n              metrics=['accuracy'])\nhistory = model_transfer.fit(train_features, y_train, batch_size=64, epochs=30,\n          validation_data=(val_features, y_val), callbacks=[checkpointer],\n          verbose=1, shuffle=True)","59662042":"def plot_acc_loss(history):\n    fig = plt.figure(figsize=(10,5))\n    plt.subplot(1, 2, 1)\n#     plt.plot(history.history['acc'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper right')\n    plt.show()\n \nplot_acc_loss(history)\n","1ee1d0ff":"model_transfer.summary()","7604b8ea":"from keras.models import Model\nintermediate_layer_model = Model(inputs=model_transfer.input,\n                                 outputs=model_transfer.get_layer(\"dense_2\").output)\n","1c12f8c4":"train_feats = intermediate_layer_model.predict(train_features)\ntrain_features = []\nval_feats = intermediate_layer_model.predict(val_features)\n# val_features = []\ntest_feats = intermediate_layer_model.predict(test_features)\n# test_features = []","8dada955":"train_feats.shape,val_feats.shape,test_feats.shape","c0baf51f":"len(train_y), len(val_y), len(test_y)","ddeab1f6":"from sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=0) --> 78.83 val acc\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=170) # --> 78.65\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=180) # --> 78.74\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=190) # --> 78.77\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=200) # --> 78.86\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=210) # --> 78.54\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=220) # --> 78.51\n# clf = RandomForestClassifier(max_depth=28,n_estimators=150,random_state=230) # --> 78.89\n# clf = RandomForestClassifier(max_depth=28,n_estimators=200,random_state=230) # --> 78.92\n# clf = RandomForestClassifier(max_depth=28,n_estimators=220,random_state=230) # --> 78.95\n# clf = RandomForestClassifier(max_depth=30,n_estimators=220,random_state=230) # --> 78.97\n# clf = RandomForestClassifier(max_depth=45,n_estimators=220,random_state=230) # --> 79.06\nclf = RandomForestClassifier(max_depth=45,n_estimators=220,random_state=230)\nclf.fit(train_feats,np.array(train_y))","2011de0d":"from sklearn.svm import SVC\nsvc = SVC(kernel='rbf',gamma='scale',decision_function_shape='ovo',probability=True)\nsvc.fit(train_feats,np.array(train_y))","7b16abb5":"SVM_val_outputs = svc.predict(val_feats)\nSVM_test_outputs = svc.predict(test_feats)\nSVM_val_outputs.shape, SVM_test_outputs.shape\nprint(\"SVM accuracies:\")\nprint(\"val:\",accuracy_score(val_y,SVM_val_outputs))\nprint(\"test:\",accuracy_score(test_y,SVM_test_outputs))","4e31fc4a":"RF_val_outputs = clf.predict(val_feats)\nRF_test_outputs = clf.predict(test_feats)\nRF_val_outputs.shape, RF_test_outputs.shape\nprint(\"RF accuracies:\")\nprint(\"val:\",accuracy_score(val_y,RF_val_outputs))\nprint(\"test:\",accuracy_score(test_y,RF_test_outputs))","18c84b37":"tm_val = model_transfer.predict(val_features)\ntm_test = model_transfer.predict(test_features)\npreds = np.argmax(tm_val, axis=1)\nprint(\"Transfer model accuracies:\")\nprint(\"val\", accuracy_score(val_y, preds))\npreds2 = np.argmax(tm_test, axis=1)\nprint(\"test\", accuracy_score(test_y, preds2))","8fa5ea7a":"SVM_val_outputs = svc.predict_proba(val_feats)\nSVM_test_outputs = svc.predict_proba(test_feats)\nSVM_val_outputs.shape, SVM_test_outputs.shape","f053cb5f":"RF_val_outputs = clf.predict_proba(val_feats)\nRF_test_outputs = clf.predict_proba(test_feats)\nRF_val_outputs.shape, RF_test_outputs.shape","6353bbcb":"len(val_y)","78118178":"# SVM accuracies:\n# val: 0.7880466472303207\n# test: 0.8037048102778608\n# RF accuracies:\n# val: 0.79067055393586\n# test: 0.8099790857484315\n# Transfer model accuracies:\n# val 0.7740524781341108\n# test 0.7842844338213325\n# w1 = 2; w2 = 2; w3 = 1.05 --> 79.09 val acc.","6e8e39cf":"w1 = 2; w2 = 2; w3 = 1.05# 79\nfinprobs = []\nfor i in range(3430):\n    p1 = SVM_val_outputs[i].argsort()[-5:][::-1]\n    p2 = RF_val_outputs[i].argsort()[-5:][::-1]\n    p3 = tm_val[i].argsort()[-5:][::-1]\n    p1_scores = sorted(SVM_val_outputs[i])[-5:][::-1]\n    p2_scores = sorted(RF_val_outputs[i])[-5:][::-1]\n    p3_scores = sorted(tm_val[i])[-5:][::-1]\n    probs = [0]*11\n    for k in range(5):\n        if p1[k]==p2[k] and p1[k] == p3[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n        elif p1[k]==p2[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n            probs[p3[k]] += (w3*p3_scores[k])\n        elif p2[k]==p3[k]:\n            probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n            probs[p1[k]] += (w1*p1_scores[k])\n        elif p1[k]==p3[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n            probs[p2[k]] += (w2*p2_scores[k])\n        else:\n            probs[p1[k]] += (w1*p1_scores[k])\n            probs[p2[k]] += (w2*p2_scores[k])\n            probs[p3[k]] += (w3*p3_scores[k])\n\n    probs = np.array(probs).argsort()[-5:][::-1]\n    finprobs.append(probs[0])\n# print(\"ensembled!\",len(finprobs),len(val_y))\nprint(\"val:\",accuracy_score(val_y,finprobs))","13b2573e":"print(len(test_features))\npreds = np.argmax(model_transfer.predict(test_features), axis=1)\nprint(\"\\nAccuracy on Test Data: \", accuracy_score(test_y, preds))\nprint(\"\\nNumber of correctly identified imgaes: \",\n      accuracy_score(test_y, preds, normalize=False),\"\\n\")\nconfusion_matrix(test_y, preds, labels=range(0,11))","c27c49d7":"w1 = 2; w2 = 2; w3 = 1.05# 79\nfinprobs = []\nfor i in range(3347):\n    p1 = SVM_test_outputs[i].argsort()[-5:][::-1]\n    p2 = RF_test_outputs[i].argsort()[-5:][::-1]\n    p3 = tm_test[i].argsort()[-5:][::-1]\n    p1_scores = sorted(SVM_test_outputs[i])[-5:][::-1]\n    p2_scores = sorted(RF_test_outputs[i])[-5:][::-1]\n    p3_scores = sorted(tm_test[i])[-5:][::-1]\n    probs = [0]*11\n    for k in range(5):\n        if p1[k]==p2[k] and p1[k] == p3[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n        elif p1[k]==p2[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n            probs[p3[k]] += (w3*p3_scores[k])\n        elif p2[k]==p3[k]:\n            probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n            probs[p1[k]] += (w1*p1_scores[k])\n        elif p1[k]==p3[k]:\n            probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n            probs[p2[k]] += (w2*p2_scores[k])\n        else:\n            probs[p1[k]] += (w1*p1_scores[k])\n            probs[p2[k]] += (w2*p2_scores[k])\n            probs[p3[k]] += (w3*p3_scores[k])\n\n    probs = np.array(probs).argsort()[-5:][::-1]\n    finprobs.append(probs[0])\nprint(\"ensembled!\",len(finprobs),len(test_y))\nprint(\"val:\",accuracy_score(test_y,finprobs))","d319f755":"## Accuracies\n### SVM val: 0.7880466472303207\n### RF val: 0.79067055393586\n### Transfer model val: 0.7740524781341108\n### Ensemble model val: 0.7909620991253644\nw1 = 2; w2 = 2; w3 = 1.05 --> test: 0.8096803107260233"}}