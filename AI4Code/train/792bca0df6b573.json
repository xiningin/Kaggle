{"cell_type":{"fdaa253d":"code","eac625e8":"code","59133fba":"code","5d323a0b":"code","5a5680b7":"code","31b15b34":"code","697fc3a6":"code","e66bf823":"code","f6b74e48":"code","e0290a65":"code","dc09674f":"code","4d4450b9":"code","3af2dca0":"code","6bcf3c8e":"code","e2883723":"code","c4c0bb63":"code","d11278bd":"code","5eb92ddc":"markdown","10970b04":"markdown","69b54174":"markdown","768bc5dd":"markdown","d7551b78":"markdown","9c0209f1":"markdown","22470e31":"markdown","86d0cd7a":"markdown","57c0e56a":"markdown"},"source":{"fdaa253d":"import numpy as np\nimport pandas as pd\nimport gc\nimport sys\n\naisles = pd.read_csv('..\/input\/aisles.csv')\ndepartments = pd.read_csv('..\/input\/departments.csv')\norder_products_prior = pd.read_csv('..\/input\/order_products__prior.csv')\norder_products_train = pd.read_csv('..\/input\/order_products__train.csv')\norders = pd.read_csv('..\/input\/orders.csv')\nproducts = pd.read_csv('..\/input\/products.csv')\n\nshopping_cart = pd.concat(\n    [\n        order_products_prior,\n        order_products_train\n    ]\n)\n\nt = pd.merge(\n    orders,\n    shopping_cart,\n    on = 'order_id',\n    how = 'inner'\n)\n\ndel shopping_cart\ndel order_products_prior\ndel order_products_train\n\norder_id_and_number = t[['user_id', 'order_id', 'order_number','days_since_prior_order','order_dow', 'order_hour_of_day']].drop_duplicates()\norder_id_and_number['days_since_prior_order'][order_id_and_number.days_since_prior_order.isnull()] = 0\norder_id_and_number = order_id_and_number.sort_values(by = ['user_id', 'order_number'])\norder_id_and_number.head()\n\nunique_users = order_id_and_number['user_id'].drop_duplicates().reset_index()\nunique_users = unique_users.drop('index', axis = 1)\n\nunique_users_sample = unique_users.sample(n = 1000)\n\norder_id_and_number = pd.merge(\n    order_id_and_number,\n    unique_users_sample,\n    on = 'user_id',\n    how = 'inner'\n)\n\no = pd.merge(\n    order_id_and_number,\n    t,\n    on = [\n        'order_id',\n        'user_id',\n        'order_number',\n        'order_dow',\n        'order_hour_of_day'\n    ],\n    how = 'inner'\n)\n\no = o.drop('days_since_prior_order_y', axis = 1)\no = o.rename({'days_since_prior_order_x':'days_since_prior_order'}, axis = 'columns')\n\no.head()","eac625e8":"# COUNTS - HOUR \/ DAY\nproduct_rank = t[['product_id', 'order_dow', 'order_hour_of_day']] \\\n    .groupby(['product_id', 'order_dow', 'order_hour_of_day']) \\\n    .size() \\\n    .reset_index(name = 'count')\n\nproducts0 = products['product_id'].to_frame()\nproducts0['key'] = 1\n\ntime = t[['order_dow', 'order_hour_of_day']].drop_duplicates().reset_index().drop('index', axis = 1)\ntime['key'] = 1\n\nproducts1 = pd.merge(\n    products0,\n    time,\n    on = 'key',\n    how = 'inner'\n).drop('key', axis = 1)\n\nproduct_rank = pd.merge(\n    products1,\n    product_rank,\n    on = ['product_id', 'order_dow', 'order_hour_of_day'],\n    how = 'left'\n)\n\nproduct_rank['count'][product_rank['count'].isnull()] = 0\n\nproduct_rank['sum_help'] = 1\n\n# RANKS - HOUR \/ DAY - MACRO LEVEL\nproduct_rank = product_rank.sort_values(by = ['order_dow', 'order_hour_of_day','count'], ascending = [True, True, False])\n\nproduct_rank['rank_macro_day_hour'] = product_rank \\\n    .groupby(['order_dow', 'order_hour_of_day']) \\\n    .cumsum()['sum_help']\n\n# RANKS - HOUR \/ DAY - PRODUCT LEVEL\nproduct_rank = product_rank.sort_values(by = ['product_id','count'], ascending = [True, False])\n\nproduct_rank['rank_product_day_hour'] = product_rank \\\n    .groupby(['product_id']) \\\n    .cumsum()['sum_help']\n\nproduct_rank = product_rank.drop('sum_help', axis = 1)\nproduct_rank = product_rank.rename({'count' : 'count_day_hour'}, axis = 'columns')\n\n# COUNTS - DAY LEVEL\ntime0 = t[['order_dow']].drop_duplicates().reset_index().drop('index', axis = 1)\ntime0['key'] = 1\n\nproducts2 = pd.merge(\n    products0,\n    time0,\n    on = 'key',\n    how = 'inner'\n).drop('key', axis = 1)\n\nproduct_rank_day = t[['product_id', 'order_dow']] \\\n    .groupby(['product_id', 'order_dow']) \\\n    .size() \\\n    .reset_index(name = 'count')\n\nproduct_rank_day = pd.merge(\n    products2,\n    product_rank_day,\n    on = ['product_id', 'order_dow'],\n    how = 'left'\n)\n\nproduct_rank_day['count'][product_rank_day['count'].isnull()] = 0\nproduct_rank_day['sum_help'] = 1\n\n# RANKS - DAY LEVEL - MACRO LEVEL\nproduct_rank_day = product_rank_day.sort_values(by = ['order_dow','count'], ascending = [True, False])\n\nproduct_rank_day['rank_macro_day'] = product_rank_day \\\n    .groupby(['order_dow']) \\\n    .cumsum()['sum_help']\n\n# RANKS - DAY LEVEL - PRODUCT LEVEL\nproduct_rank_day = product_rank_day.sort_values(by = ['product_id','count'], ascending = [True, False])\n\nproduct_rank_day['rank_product_day'] = product_rank_day \\\n    .groupby(['product_id']) \\\n    .cumsum()['sum_help']\n\nproduct_rank_day = product_rank_day.drop('sum_help', axis = 1)\nproduct_rank_day = product_rank_day.rename({'count' : 'count_day'}, axis = 'columns')\n\n# COUNTS - HOUR LEVEL\ntime1 = t[['order_hour_of_day']].drop_duplicates().reset_index().drop('index', axis = 1)\ntime1['key'] = 1\n\nproducts3 = pd.merge(\n    products0,\n    time1,\n    on = 'key',\n    how = 'inner'\n).drop('key', axis = 1)\n\nproduct_rank_hour = t[['product_id', 'order_hour_of_day']] \\\n    .groupby(['product_id', 'order_hour_of_day']) \\\n    .size() \\\n    .reset_index(name = 'count')\n\nproduct_rank_hour = pd.merge(\n    products3,\n    product_rank_hour,\n    on = ['product_id', 'order_hour_of_day'],\n    how = 'left'\n)\n\nproduct_rank_hour['count'][product_rank_hour['count'].isnull()] = 0\nproduct_rank_hour['sum_help'] = 1\n\n# RANKS - HOUR LEVEL - MACRO LEVEL\nproduct_rank_hour = product_rank_hour.sort_values(by = ['order_hour_of_day','count'], ascending = [True, False])\n\nproduct_rank_hour['rank_macro_hour'] = product_rank_hour \\\n    .groupby(['order_hour_of_day']) \\\n    .cumsum()['sum_help']\n\n# RANKS - HOUR LEVEL - PRODUCT LEVEL\nproduct_rank_hour = product_rank_hour.sort_values(by = ['product_id','count'], ascending = [True, False])\n\nproduct_rank_hour['rank_product_hour'] = product_rank_hour \\\n    .groupby(['product_id']) \\\n    .cumsum()['sum_help']\n\nproduct_rank_hour = product_rank_hour.drop('sum_help', axis = 1)\nproduct_rank_hour = product_rank_hour.rename({'count' : 'count_hour'}, axis = 'columns')\n\n# COUNTS - HOUR LEVEL\nproduct_rank_overall = t[['product_id']] \\\n    .groupby(['product_id']) \\\n    .size() \\\n    .reset_index(name = 'count')\n\nproduct_rank_overall = pd.merge(\n    products0,\n    product_rank_overall,\n    on = ['product_id'],\n    how = 'left'\n)\n\nproduct_rank_overall['count'][product_rank_overall['count'].isnull()] = 0\nproduct_rank_overall['sum_help'] = 1\n\n# RANKS - OVERALL\nproduct_rank_overall = product_rank_overall.sort_values(by = ['count'], ascending = [False])\n\nproduct_rank_overall['rank_macro_overall'] = product_rank_overall \\\n    .cumsum()['sum_help']\n\nproduct_rank_overall = product_rank_overall.drop(['sum_help', 'key'], axis = 1)\nproduct_rank_overall = product_rank_overall.rename({'count' : 'count_overall'}, axis = 'columns')","59133fba":"first_order = o[['user_id', 'order_number', 'product_id']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .min()['order_number'] \\\n    .reset_index(name = 'first_order')\n\n# next: user_products\nuser_products = o[['user_id', 'product_id']].drop_duplicates().reset_index().drop('index', axis = 1)\n\n# next: user_orders\nuser_orders = o[['user_id', 'order_number', 'order_dow', 'order_hour_of_day']].drop_duplicates().reset_index().drop('index', axis = 1)\n\n# then join on user_id, filter out when order_number < first_order.order_number\ncross_join = pd.merge(\n    pd.merge(\n        user_products,\n        user_orders,\n        on = 'user_id',\n        how = 'inner'\n    ),\n    first_order,\n    on = ['user_id', 'product_id'],\n    how = 'inner'\n)\n\norder_days = o[['user_id', 'order_number', 'days_since_prior_order']].drop_duplicates().reset_index().drop('index', axis = 1)\n\norder_days['days_agg'] = order_days \\\n    .groupby('user_id') \\\n    .cumsum()['days_since_prior_order']\n\ncross_join = pd.merge(\n    cross_join,\n    order_days,\n    on = ['user_id', 'order_number'],\n    how = 'inner'\n)\n\nproduct_orders = o[['user_id', 'order_number', 'product_id']]\nproduct_orders['ordered'] = 1\n\ncross_join = pd.merge(\n    cross_join,\n    product_orders,\n    on = ['user_id', 'order_number', 'product_id'],\n    how = 'left'\n)\n\ncross_join.loc[cross_join.ordered.isnull(), 'ordered'] = 0\n\ncross_join = cross_join.sort_values(by = ['user_id', 'order_number'], ascending = True)\n\ncross_join['count_previous_orders'] = cross_join \\\n    .groupby(['user_id', 'product_id']) \\\n    .cumsum()['ordered'] - cross_join['ordered']\n\ncross_join['shift_indicator'] = cross_join \\\n    .groupby(['user_id', 'product_id'])['ordered'] \\\n    .shift(1) \\\n    .fillna(0)\n\ncross_join['last_order_number'] = 0\n\ncross_join['prev_order_number'] = cross_join \\\n    .groupby(['user_id', 'product_id'])['order_number'] \\\n    .shift(1)\n\ncross_join.loc[cross_join.shift_indicator == 1, 'last_order_number'] = cross_join['prev_order_number']\n\ncross_join['last_order_switch'] = 0\ncross_join.loc[cross_join.last_order_number != 0, 'last_order_switch'] = 1\ncross_join['bloc_party'] = cross_join \\\n    .groupby(['user_id', 'product_id']) \\\n    .cumsum()['last_order_switch']\n\ncross_join = pd.merge(\n    cross_join,\n    cross_join[['user_id', 'product_id', 'bloc_party', 'last_order_number']][cross_join.last_order_number != 0] \\\n        .drop_duplicates() \\\n        .reset_index(drop = True) \\\n        .rename({'last_order_number' : 'bloc_last_order_number'}, axis = 'columns'),\n    on = ['user_id', 'product_id', 'bloc_party'],\n    how = 'inner'\n) \\\n    .drop('last_order_number', axis = 1) \\\n    .rename({'bloc_last_order_number' : 'last_order_number'}, axis = 'columns')\n\ncross_join = pd.merge(\n    cross_join,\n    order_days[['user_id', 'order_number', 'days_agg']].rename({'order_number' : 'last_order_number', 'days_agg' : 'days_agg_last'}, axis = 1),\n    on = ['user_id', 'last_order_number'],\n    how = 'inner'\n)\n\ncross_join['days_since_last_order'] = cross_join['days_agg'] - cross_join['days_agg_last']\n\nuser_add_to_cart = o[['user_id', 'product_id', 'order_number', 'add_to_cart_order']]\n\ntotal_orders = user_add_to_cart \\\n    .groupby(['user_id', 'order_number']) \\\n    .size() \\\n    .reset_index(name = 'num_products_in_order')\n\nuser_add_to_cart = pd.merge(\n    user_add_to_cart,\n    total_orders,\n    on = ['user_id', 'order_number'],\n    how = 'inner'\n)\n\nuser_add_to_cart['pct_add_to_cart'] = user_add_to_cart['add_to_cart_order'] \/ user_add_to_cart['num_products_in_order']\n\nuser_add_to_cart['total_cart_order'] = user_add_to_cart \\\n    .groupby(['user_id', 'product_id']) \\\n    .cumsum()['pct_add_to_cart']\n\nuser_add_to_cart['order_count'] = 1\n\nuser_add_to_cart['num_orders'] = user_add_to_cart \\\n    .groupby(['user_id', 'product_id']) \\\n    .cumsum()['order_count']\n\n# denominator: replace order_number with number orders so far\nuser_add_to_cart['avg_add_to_cart_order'] = user_add_to_cart['total_cart_order'] \/ user_add_to_cart['num_orders']\ncross_join = pd.merge(\n    cross_join,\n    user_add_to_cart.rename({'order_number' : 'last_order_number'}, axis = 1),\n    on = ['user_id', 'product_id', 'last_order_number'],\n    how = 'inner'\n)\n\ncross_join = cross_join.sort_values(by = ['user_id', 'order_number'])\n\ncross_join['num_orders_three_ago'] = cross_join \\\n    .groupby(['user_id', 'product_id'])['num_orders'] \\\n    .shift(3) \\\n    .fillna(0)\n\ncross_join['num_orders_last_three'] =  cross_join['num_orders'] - cross_join['num_orders_three_ago']\n\nproduct_rank['product_id'] = product_rank['product_id'].astype(int)\nproduct_rank['order_dow'] = product_rank['order_dow'].astype(int)\nproduct_rank['order_hour_of_day'] = product_rank['order_hour_of_day'].astype(int)\n\nproduct_rank_day['product_id'] = product_rank_day['product_id'].astype(int)\nproduct_rank_day['order_dow'] = product_rank_day['order_dow'].astype(int)\n\nproduct_rank_hour['product_id'] = product_rank_hour['product_id'].astype(int)\nproduct_rank_hour['order_hour_of_day'] = product_rank_hour['order_hour_of_day'].astype(int)\n\nproduct_rank_overall['product_id'] = product_rank_overall['product_id'].astype(int)\n\ncross_join = pd.merge(\n    cross_join,\n    products,\n    on = 'product_id',\n    how = 'inner'\n).drop('product_name', axis = 1)\n\ncross_join = pd.merge(\n    cross_join,\n    product_rank,\n    on = ['product_id', 'order_dow', 'order_hour_of_day'],\n    how = 'inner'\n)\n\ncross_join = pd.merge(\n    cross_join,\n    product_rank_day,\n    on = ['product_id', 'order_dow'],\n    how = 'inner'\n)\n\ncross_join = pd.merge(\n    cross_join,\n    product_rank_hour,\n    on = ['product_id', 'order_hour_of_day'],\n    how = 'inner'\n)\n\ncross_join = pd.merge(\n    cross_join,\n    product_rank_overall,\n    on = ['product_id'],\n    how = 'inner'\n)\n\ncross_join['order_number'] = cross_join['order_number'].astype(int)\ncross_join['product_id'] = cross_join['product_id'].astype(int)\ncross_join['user_id'] = cross_join['user_id'].astype(int)\n\ndel o","5d323a0b":"from sklearn.preprocessing import PolynomialFeatures\n\npoly = cross_join[\n    [\n        'num_orders_last_three',\n        'count_previous_orders',\n        'total_cart_order',\n        'days_since_last_order'\n    ]\n]\n\np = PolynomialFeatures(degree = 2).fit(poly)\n\npoly = pd.DataFrame(\n    data = p.transform(poly),\n    columns = p.get_feature_names(poly.columns)\n)\n\npoly['user_id'] = cross_join['user_id']\npoly['order_number'] = cross_join['order_number']\npoly['product_id'] = cross_join['product_id']\n\ncross_join = pd.merge(\n    cross_join,\n    poly,\n    on = [\n        'user_id', \n        'order_number', \n        'product_id',\n        'num_orders_last_three',\n        'count_previous_orders',\n        'total_cart_order',\n        'days_since_last_order'\n    ],\n    how = 'inner'\n).drop('1', axis = 1)\n\ncross_join.shape","5a5680b7":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import f1_score\n\nx = cross_join.copy().drop(\n    [\n        'ordered',\n        'shift_indicator',\n        'last_order_number',\n        'add_to_cart_order',\n        'first_order',\n        'num_products_in_order',\n        'bloc_party',\n        'last_order_switch',\n        'prev_order_number',\n        'num_orders',\n        'order_count',\n        'num_orders_three_ago'\n    ],\n    axis = 1\n)\ny = cross_join['ordered']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 0)\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train, y_train)\npredictions = model.predict(x_test)\n\npredictions = pd.DataFrame(\n    data = predictions,\n    columns = ['prediction']\n)\n\ny_test = y_test.reset_index()\ny_test = y_test.drop('index', axis = 1)\npredictions['actual'] = y_test\n\nauc = roc_auc_score(y_test, predictions['prediction'])\nprint('AUC: ', auc)\n\nf1 = f1_score(predictions['actual'], predictions['prediction'], average = 'binary')\nprint('f1: ', f1)\n\ncorr = cross_join.corr()\ncorr = corr['ordered'].to_frame().reset_index()\ncorr.columns = ['column', 'corr']\n\nimportances = model.feature_importances_\ncols = x.columns\nimportances = pd.DataFrame(\n    data = {'column' : cols, 'importance': importances}\n)\n\nimportances = pd.merge(\n    importances,\n    corr,\n    on = 'column',\n    how = 'inner'\n).sort_values(by = 'corr', ascending = False)\nprint(importances)","31b15b34":"import lightgbm as lgb\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 0)\n\nlgb_model = lgb.LGBMClassifier(\n    n_estimators = 1000, \n    objective = 'binary', \n    class_weight = 'balanced', \n    learning_rate = 0.05, \n    reg_alpha = 0.1, \n    reg_lambda = 0.1, \n    subsample = 0.8, \n    n_jobs = -1, \n    random_state = 50\n)\n\nlgb_model.fit(\n    x_train,\n    y_train,\n    eval_metric = 'auc'\n)\n\np = lgb_model.predict_proba(x_test)\np_binary = lgb_model.predict(x_test)\n\nlightGBM = roc_auc_score(y_test, p[:,1])\nprint('LGBM proba:', lightGBM)\n\nlightGBM_binary = roc_auc_score(y_test, p_binary)\nprint('LGBM binary:', lightGBM_binary)\n\nf1_lgbm = f1_score(y_test, p_binary, average = 'binary')\nprint('f1 binary: ', f1_lgbm)\n\nlgbm_importances = lgb_model.feature_importances_\ncols = x.columns\nlgbm_importances = pd.DataFrame(\n    data = {'column' : cols, 'importance': lgbm_importances}\n).sort_values(by = 'importance', ascending = False)\n\nprint(lgbm_importances)","697fc3a6":"p = pd.DataFrame(\n    data = p\n)\n\np['actual'] = y_test\n\np['.1'] = 0\np.loc[p[1] >= .1, '.1'] = 1\nlightGBM = roc_auc_score(y_test, p['.1'])\nf1_lgbm = f1_score(y_test, p['.1'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .1:', lightGBM)\n\np['.2'] = 0\np.loc[p[1] >= .2, '.2'] = 1\nlightGBM = roc_auc_score(y_test, p['.2'])\nf1_lgbm = f1_score(y_test, p['.2'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .2:', lightGBM)\n\np['.3'] = 0\np.loc[p[1] >= .3, '.3'] = 1\nlightGBM = roc_auc_score(y_test, p['.3'])\nf1_lgbm = f1_score(y_test, p['.3'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .3:', lightGBM)\n\np['.4'] = 0\np.loc[p[1] >= .4, '.4'] = 1\nlightGBM = roc_auc_score(y_test, p['.4'])\nf1_lgbm = f1_score(y_test, p['.4'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .4:', lightGBM)\n\np['.5'] = 0\np.loc[p[1] >= .5, '.5'] = 1\nlightGBM = roc_auc_score(y_test, p['.5'])\nf1_lgbm = f1_score(y_test, p['.5'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .5:', lightGBM)\n\np['.6'] = 0\np.loc[p[1] >= .6, '.6'] = 1\nlightGBM = roc_auc_score(y_test, p['.6'])\nf1_lgbm = f1_score(y_test, p['.6'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .6:', lightGBM)\n\np['.7'] = 0\np.loc[p[1] >= .7, '.7'] = 1\nlightGBM = roc_auc_score(y_test, p['.7'])\nf1_lgbm = f1_score(y_test, p['.7'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .7:', lightGBM)\n\np['.8'] = 0\np.loc[p[1] >= .8, '.8'] = 1\nlightGBM = roc_auc_score(y_test, p['.8'])\nf1_lgbm = f1_score(y_test, p['.8'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .8:', lightGBM)\n\np['.9'] = 0\np.loc[p[1] >= .9, '.9'] = 1\nlightGBM = roc_auc_score(y_test, p['.9'])\nf1_lgbm = f1_score(y_test, p['.9'], average = 'binary')\nprint('f1: ', f1_lgbm)\nprint('LGBM: .9:', lightGBM)","e66bf823":"test = orders[orders.eval_set == 'test']\ntest_unique = test['user_id'].drop_duplicates().reset_index().drop('index', axis = 1)\ntest_unique_orders = pd.merge(\n    test_unique,\n    orders,\n    on = 'user_id',\n    how = 'inner'\n)\ntest_unique_orders['days_since_prior_order'][test_unique_orders.days_since_prior_order.isnull()] = 0\n\ntest_unique_orders['days'] = test_unique_orders \\\n    .groupby('user_id') \\\n    .cumsum()['days_since_prior_order']\n\ntest_driver = pd.merge(\n    test_unique,\n    t,\n    on = 'user_id',\n    how = 'inner'\n)","f6b74e48":"test_counts = test_driver[['user_id', 'product_id']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .size() \\\n    .reset_index(name = 'count_previous_orders')\n\ntest_counts.head()","e0290a65":"test_last_order = test_driver[['user_id', 'product_id', 'order_number']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .max()['order_number'] \\\n    .reset_index()\n\ntest_last_order = pd.merge(\n    test[['user_id','order_number']],\n    test_last_order,\n    on = 'user_id',\n    how = 'inner'\n).rename({'order_number_x' : 'order_number_current', 'order_number_y' : 'order_number_last'}, axis = 'columns')\n\ntest_last_order = pd.merge(\n    test_last_order,\n    test_unique_orders[['user_id', 'order_number', 'days']],\n    left_on = [\n        'user_id',\n        'order_number_current'\n    ],\n    right_on = [\n        'user_id',\n        'order_number'\n    ],\n    how = 'inner'\n) \\\n    .rename({'days' : 'days_agg'}, axis = 'columns') \\\n    .drop('order_number', axis = 1)\n\ntest_last_order = pd.merge(\n    test_last_order,\n    test_unique_orders[['user_id', 'order_number', 'days']],\n    left_on = [\n        'user_id',\n        'order_number_last'\n    ],\n    right_on = [\n        'user_id',\n        'order_number'\n    ],\n    how = 'inner'\n) \\\n    .rename({'days' : 'days_agg_last'}, axis = 'columns') \\\n    .drop('order_number', axis = 1)\n\ntest_last_order['days_since_last_order'] = test_last_order['days_agg'] - test_last_order['days_agg_last']\n\ntest_last_order.head()","dc09674f":"add_to_cart_counts = test_driver[['user_id', 'order_number']] \\\n    .groupby(['user_id', 'order_number']) \\\n    .size() \\\n    .reset_index(name = 'total_cart_order')\n\nadd_to_cart = pd.merge(\n    test_driver[['user_id', 'order_number', 'product_id','add_to_cart_order']],\n    add_to_cart_counts,\n    on = ['user_id', 'order_number'],\n    how = 'inner'\n)\n\nadd_to_cart['pct_add_to_cart'] = add_to_cart['add_to_cart_order'] \/ add_to_cart['total_cart_order']\nlast_order = add_to_cart.copy()\n\nadd_to_cart = add_to_cart[['user_id', 'product_id', 'pct_add_to_cart']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .sum()['pct_add_to_cart'] \\\n    .reset_index(name = 'total_cart_order')\n\nadd_to_cart = pd.merge(\n    add_to_cart,\n    test_counts,\n    on = ['user_id', 'product_id'],\n    how = 'inner'\n)\n\nadd_to_cart['avg_add_to_cart_order'] = add_to_cart['total_cart_order'] \/ add_to_cart['count_previous_orders']\n\n# add most recent order's pct_add_to_cart\nlast_order_driver = last_order[['user_id', 'product_id', 'order_number']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .max()['order_number'] \\\n    .reset_index(name = 'order_number')\n\nlast_order = pd.merge(\n    last_order,\n    last_order_driver,\n    on = ['user_id', 'product_id', 'order_number'],\n    how = 'inner'\n)\n\nadd_to_cart = pd.merge(\n    add_to_cart,\n    last_order[['user_id', 'product_id', 'pct_add_to_cart']],\n    on = ['user_id', 'product_id'],\n    how = 'inner'\n).drop('count_previous_orders', axis = 1)\n\nadd_to_cart.head()","4d4450b9":"last_user_order = test_driver[['user_id', 'order_number']] \\\n    .groupby(['user_id']) \\\n    .max()['order_number'] \\\n    .reset_index(name = 'order_number_end')\n\nlast_user_order['order_number_start'] = last_user_order['order_number_end'] - 2\n\nlast_user_order.loc[last_user_order.order_number_start < 0, 'order_number_start'] = 0\n\nrecent_three_orders = pd.merge(\n    test_driver,\n    last_user_order,\n    on = 'user_id',\n    how = 'inner'\n)\n\nrecent_three_orders = recent_three_orders[\n    (recent_three_orders.order_number >= recent_three_orders.order_number_start) & \n    (recent_three_orders.order_number <= recent_three_orders.order_number_end)\n]\n\nrecent_three_orders = recent_three_orders[['user_id', 'product_id']] \\\n    .groupby(['user_id', 'product_id']) \\\n    .size() \\\n    .reset_index(name = 'num_orders_last_three')\n\nrecent_three_orders","3af2dca0":"test = pd.merge(\n    test,\n    test_counts,\n    on = ['user_id'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    test_last_order,\n    left_on = ['user_id', 'product_id', 'order_number'],\n    right_on = ['user_id', 'product_id', 'order_number_current'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    products,\n    on = 'product_id',\n    how = 'inner'\n).drop('product_name', axis = 'columns')\n\ntest = pd.merge(\n    test,\n    add_to_cart,\n    on = ['user_id', 'product_id'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    product_rank,\n    on = ['product_id', 'order_dow', 'order_hour_of_day'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    product_rank_day,\n    on = ['product_id', 'order_dow'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    product_rank_hour,\n    on = ['product_id', 'order_hour_of_day'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    product_rank_overall,\n    on = ['product_id'],\n    how = 'inner'\n)\n\ntest = pd.merge(\n    test,\n    recent_three_orders,\n    on = ['user_id', 'product_id'],\n    how = 'left'\n)\n\ntest['num_orders_last_three'][test.num_orders_last_three.isnull()] = 0\n\ntest = test.drop(\n    [\n        'eval_set',\n        'order_number_current',\n        'order_number_last',\n        'order_id'\n    ],\n    axis = 1\n)","6bcf3c8e":"x.dtypes","e2883723":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_test = test[\n    [\n        'num_orders_last_three',\n        'count_previous_orders',\n        'total_cart_order',\n        'days_since_last_order'\n    ]\n]\n\np_test = PolynomialFeatures(degree = 2).fit(poly_test)\n\npoly_test = pd.DataFrame(\n    data = p_test.transform(poly_test),\n    columns = p_test.get_feature_names(poly_test.columns)\n)\n\npoly_test['user_id'] = test['user_id']\npoly_test['order_number'] = test['order_number']\npoly_test['product_id'] = test['product_id']\n\ntest = pd.merge(\n    test,\n    poly_test,\n    on = [\n        'user_id', \n        'order_number', \n        'product_id',\n        'num_orders_last_three',\n        'count_previous_orders',\n        'total_cart_order',\n        'days_since_last_order'\n    ],\n    how = 'inner'\n).drop('1', axis = 1)\n\ntest.shape","c4c0bb63":"test = test[\n    [\n        'user_id',\n        'product_id',\n        'order_number',\n        'order_dow',\n        'order_hour_of_day',\n        'days_since_prior_order',\n        'days_agg',\n        'count_previous_orders',\n        'days_agg_last',\n        'days_since_last_order',\n        'pct_add_to_cart',\n        'total_cart_order',\n        'avg_add_to_cart_order',\n        'num_orders_last_three',\n        'aisle_id',\n        'department_id',\n        'count_day_hour',\n        'rank_macro_day_hour',\n        'rank_product_day_hour',\n        'count_day',\n        'rank_macro_day',\n        'rank_product_day',\n        'count_hour',\n        'rank_macro_hour',\n        'rank_product_hour',\n        'count_overall',\n        'rank_macro_overall',\n        'num_orders_last_three^2',\n        'num_orders_last_three count_previous_orders',\n        'num_orders_last_three total_cart_order',\n        'num_orders_last_three days_since_last_order',\n        'count_previous_orders^2',\n        'count_previous_orders total_cart_order',\n        'count_previous_orders days_since_last_order',\n        'total_cart_order^2',\n        'total_cart_order days_since_last_order',\n        'days_since_last_order^2'\n    ]\n]","d11278bd":"test['prediction'] = lgb_model.predict_proba(test)[:,1]\n\nsubmit_staging = test[['user_id', 'product_id', 'order_number']][test.prediction >= .7]\n\nsubmit_staging = pd.merge(\n    submit_staging,\n    orders[['user_id', 'order_number', 'order_id']],\n    on = ['user_id', 'order_number'],\n    how = 'inner'\n)\n\ntest_left_side = orders[orders.eval_set == 'test']\nsubmit_staging2 = pd.merge(\n    test_left_side[['user_id', 'order_id']],\n    submit_staging,\n    on = ['user_id', 'order_id'],\n    how = 'left'\n)\n\nsubmit_staging3 = submit_staging2[['order_id', 'product_id']]\nsubmit_staging3['product_id'][submit_staging3.product_id.isnull()] = 0\nsubmit_staging3 = submit_staging3.astype(int)\nsubmit_staging3 = submit_staging3.astype(str)\n\nsubmit = submit_staging3 \\\n    .groupby('order_id')['product_id'] \\\n    .apply(' '.join) \\\n    .reset_index(name = 'products')\n\nsubmit.loc[submit.products == '0', 'products'] = 'None'\n\nsubmit.to_csv('submit.csv', index = False)","5eb92ddc":"# Put it all together\n## Features:\n1. Count of times ordered per product (test_counts)\n2. Days since product ordered (test_last_order)\n3. days since original order (test_unique_orders)\n4. days_since_prior_order\n5. order_number\n6. product_id\n7. user_id\n8. order_dow\n9. order_hour_of_day","10970b04":"# cross_join = TRAIN dataset","69b54174":"# SET UP TEST DF","768bc5dd":"# Create submission file!","d7551b78":"## Initial driver DataFrame\n\n## Discovered cumsum() -> VERY useful tool!","9c0209f1":"# Add to cart order","22470e31":"# Polynomial Features","86d0cd7a":"## Days since last ordered","57c0e56a":"## Count of times product ordered previously per user"}}