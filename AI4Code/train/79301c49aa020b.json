{"cell_type":{"470f96ef":"code","c73ffa1d":"code","005ac9e5":"code","706c5a5e":"code","bcb6bf0a":"code","13495cb5":"code","1a5d228b":"code","3c0bca2b":"code","948719f6":"code","41709cb2":"code","821164dc":"code","b626c484":"code","46e45659":"code","194383a0":"code","7fb9cf65":"code","123bd3b8":"code","40daa5a2":"code","129dca92":"markdown"},"source":{"470f96ef":"#importing pakages\n%matplotlib inline\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","c73ffa1d":"import pandas as pd\ndiabetes = pd.read_csv(\"..\/input\/diabetes.csv\")\ndiabetes.head()","005ac9e5":"diabetes.shape","706c5a5e":"diabetes.info()","bcb6bf0a":"sns.heatmap(diabetes.isnull())","13495cb5":"diabetes.groupby('Outcome').hist(figsize=(10,9))\n# from below graphs we can visualize details like\n#for non diabetes age is lies mostly 20 to 40\n#for diabetes age is lies mostly 20 to 60 for\n#for non diabetes and diabetes there is no change in BMI,Blood Pressure,Diabetes PedigreeFunction \n#for diabetes Glucose is more towards 200 compared to non diabetes etc","1a5d228b":"print(diabetes.groupby('Outcome').size()) #1 means diabetes. Of these 768 data points, 500 are labeled as 0 and 268 as 1:\n#counting the outcome of the diabetes study.\nsns.countplot(diabetes['Outcome'],label='Count')","3c0bca2b":"from sklearn.model_selection import train_test_split\nX_train ,X_test ,y_train , y_test = train_test_split( diabetes.loc[:,diabetes.columns !='Outcome'], diabetes['Outcome'],\n                                                     stratify=diabetes['Outcome'],random_state=66)","948719f6":"#importing KNN classifier\nfrom sklearn.neighbors import KNeighborsClassifier\ntraining_accuracy = []\ntest_accuracy = []\nneighbors_settings = range(1,100)\nfor n_neighbors in neighbors_settings:\n    knn = KNeighborsClassifier(n_neighbors= n_neighbors)\n    knn.fit(X_train, y_train)\n    training_accuracy.append(knn.score(X_train,y_train))\n    test_accuracy.append(knn.score(X_test,y_test))\nplt.plot(neighbors_settings, training_accuracy, label='training accuracy')\nplt.plot(neighbors_settings, test_accuracy, label='test accuracy')\nplt.xlabel('Accuracy')\nplt.ylabel('n_neighbors')\nplt.legend()\nplt.show()","41709cb2":"#k value can be taken as 19 as seen from the above graph\nknn = KNeighborsClassifier(n_neighbors=19)\nknn.fit(X_train, y_train)\nprint('Accuracy of KNN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))\nprint('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))","821164dc":"#importing the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nactual =y_test\npredicted =knn.predict(X_test)\nresults = confusion_matrix(actual, predicted)\nprint('Confusion Matrix')\nprint(results)\nprint('Accuracy Score :', accuracy_score(actual, predicted))\nprint('Report')\nprint(classification_report(actual,predicted))","b626c484":"#importing roc curve and roc curve score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","46e45659":"def plot_roc_curve(fpr,tpr):\n  plt.plot(fpr, tpr, color = 'orange', label = 'ROC')\n  plt.plot([0,1], [0,1],color='darkblue',linestyle='--')\n  plt.title('Receiver Operating Charactersticks (ROC) Curve')\n  plt.xlabel('False Positive Value')\n  plt.ylabel('True Positive Rate')\n  plt.legend()\n  plt.show()","194383a0":"#predicting the probablity by KNN classifier\nprobs = knn.predict_proba(X_test)\nprobs[0:10]\n","7fb9cf65":"probs = probs[:,1]\nprobs[0:10]","123bd3b8":"auc = roc_auc_score(y_test,probs)\nprint('AUC: %.2f' %auc)","40daa5a2":"fpr, tpr, thresholds = roc_curve(y_test, probs)\n#plotting the roc curve\nplot_roc_curve(fpr, tpr)","129dca92":"k-Nearest Neighbors The k-NN algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training data set. To make a prediction for a new data point, the algorithm finds the closest data points in the training data set\u200a\u2014\u200aits \u201cnearest neighbors.\u201d\n\nFirst, Let\u2019s investigate whether we can confirm the connection between model complexity and accuracy:"}}