{"cell_type":{"d72af3f7":"code","50690ba0":"code","8880763e":"code","63822781":"code","c89a1d0d":"code","16375021":"code","2860b5b2":"code","1185feab":"code","e2343570":"code","84aafa80":"code","ae8443c7":"code","f214a8c5":"code","5c727dbb":"markdown","98610f97":"markdown","e2c81907":"markdown","5530f40e":"markdown","336c9d71":"markdown","c1cba58a":"markdown","8c479a4a":"markdown","64112448":"markdown","03edab36":"markdown","a6b919a0":"markdown","0e446f40":"markdown"},"source":{"d72af3f7":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt","50690ba0":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n        #lambda x: imagehash.whash(x, mode='db4'),\n    ]\n\n    petids = []\n    hashes = []\n    for path in tqdm(glob.glob('..\/input\/*_images\/*-1.jpg')):\n\n        image = Image.open(path)\n        imageid = path.split('\/')[-1].split('.')[0][:-2]\n\n        petids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return petids, np.array(hashes)\n\n%time petids, hashes_all = run()","8880763e":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","63822781":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_all.shape[0])])","c89a1d0d":"indices1 = np.where(sims > 0.9)\nindices2 = np.where(indices1[0] != indices1[1])\npetids1 = [petids[i] for i in indices1[0][indices2]]\npetids2 = [petids[i] for i in indices1[1][indices2]]\ndups = {tuple(sorted([petid1,petid2])):True for petid1, petid2 in zip(petids1, petids2)}\nprint('found %d duplicates' % len(dups))","16375021":"train = pd.read_csv('..\/input\/train\/train.csv')\ntest = pd.read_csv('..\/input\/test\/test.csv')\n\ntrain.loc[:,'Category'] = 'train'\ntest.loc[:,'Category'] = 'test'\ntest.loc[:,'AdoptionSpeed'] = np.nan\n\ndf = pd.concat([train, test], sort=False)","2860b5b2":"detail = {petid:df[df.PetID == petid].iloc[0] for petid in itertools.chain.from_iterable(list(dups))}","1185feab":"def show(row1, row2):\n\n    print('PetID: %s \/ %s' % (row1.PetID, row2.PetID))\n    print('Name: %s \/ %s' % (row1.Name, row2.Name))\n    print('Category: %s \/ %s' % (row1.Category, row2.Category))\n    print('AdoptionSpeed: %s \/ %s' % (row1.AdoptionSpeed, row2.AdoptionSpeed))\n    print('Breed1: %d \/ %d' % (row1.Breed1, row2.Breed1))\n    print('Age: %d \/ %d' % (row1.Age, row2.Age))\n    print('RescuerID:\\n%s\\n%s' % (row1.RescuerID, row2.RescuerID))\n    \n    image1 = cv2.imread('..\/input\/%s_images\/%s-1.jpg' % (row1.Category, row1.PetID))\n    image2 = cv2.imread('..\/input\/%s_images\/%s-1.jpg' % (row2.Category, row2.PetID))\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n    \n    fig = plt.figure(figsize=(10, 20))\n    fig.add_subplot(1,2,1)\n    plt.imshow(image1)\n    fig.add_subplot(1,2, 2)\n    plt.imshow(image2)\n    plt.show()","e2343570":"for petid1, petid2 in sorted(list(dups)):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    if row1.Category != row2.Category:\n        show(row1, row2)","84aafa80":"counter = collections.Counter()\nfor petid1, petid2 in list(dups):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    \n    for attr in train.columns:\n        if getattr(row1, attr) != getattr(row2, attr):\n            counter[attr] += 1\n            \ncounter","ae8443c7":"for petid1, petid2 in list(dups)[:20]:\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    if row1.Description != row2.Description:\n        print(row1.Description)\n        print('-'*5)\n        print(row2.Description)\n        print('\\n')","f214a8c5":"import json\nout = [[petid1,petid2] for petid1,petid2 in dups.keys()]\nwith open('dups.json', 'w') as fp:\n    fp.write(json.dumps(out))","5c727dbb":"## Example of duplicates","98610f97":"Convert numpy array into torch tensor to speed up similarity calculation.","e2c81907":"- Some pets change their info (such as Name, Breed, Age).\n- Some pets are adopted more than once even twice.","5530f40e":"## Which column info is inconsistent on duplicate pairs?","336c9d71":"## Associate petid with csv info","c1cba58a":"- Version6: Fixed order of RGB when plotting. Added json output.\n- Version2: Description added.","8c479a4a":"- Duplicate pets change their name often.\n- 1\/3 of duplicate pets with different RescuerID","64112448":"Calculate similarities among all image pairs. Divide the value by 256 to normalize (0-1).","03edab36":"## Thresholding","a6b919a0":"## Let's see how their description changes","0e446f40":"## Calc similalities between all image pairs\nI use imagehash library to calculate hash value of image. \nhttps:\/\/github.com\/JohannesBuchner\/imagehash\n\nThere are several hash functions provided and I used 4 of them and combined the calculated hash values.\n\n  - average hashing (aHash)\n  - perception hashing (pHash)\n  - difference hashing (dHash)\n  - wavelet hashing (wHash)\n  \nI used profile image(1st image) of pet images to calculate hash values. "}}