{"cell_type":{"4ba5f413":"code","557768ab":"code","b75f453c":"code","5b99bbcd":"code","76f1c790":"code","150fe05e":"code","60f0d75b":"code","51daff54":"code","d81ffe22":"code","5e97a50c":"code","581c7048":"code","dbcedf25":"code","08f194fa":"code","34d348a2":"code","d22aa4e1":"code","c01b2fa9":"code","e927789f":"code","0ece082c":"code","695b080f":"code","ab529ce7":"code","aa1c4bde":"code","55bec987":"code","927ac1b1":"code","0b3a1c1d":"code","285741d6":"code","74aabab4":"code","13963d00":"code","c8b51302":"code","753fda39":"code","1e7db850":"code","e2a8148e":"code","6ce558c0":"code","b7502513":"code","e62a5392":"code","786797e3":"code","f9a07b1d":"code","6fa14a92":"code","5a614d77":"code","8c6df521":"code","426a1502":"code","ead7e8ac":"code","d1b2aed1":"code","e9a87fb6":"code","5192fbb3":"code","882c91a9":"code","1a624a50":"code","8fb63224":"code","52b06bce":"code","504c55e2":"code","d6ce7bd2":"code","c036338b":"code","60a943ee":"code","cd7c8405":"code","cf47eaa6":"code","7607b121":"markdown","1fb11cd2":"markdown","057adfec":"markdown","d9d1c052":"markdown","a1aedcf2":"markdown","dad8286d":"markdown","4b5c24f9":"markdown"},"source":{"4ba5f413":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","557768ab":"import seaborn as sns\nimport matplotlib.pyplot as plt","b75f453c":"df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","5b99bbcd":"df.head()","76f1c790":"df.shape","150fe05e":"df_test.shape","60f0d75b":"df.dtypes.value_counts()","51daff54":"df_test_id = df_test['Id']","d81ffe22":"df.drop(['Id'], axis=1, inplace=True)\ndf_test.drop(['Id'], axis=1, inplace=True)","5e97a50c":"df_train = df","581c7048":"print(f\"Number of rows and number of columns in the train dataset are {df_train.shape[0]} and {df_train.shape[1]}\")\nprint(f\"Number of rows and number of columns in the test dataset are {df_test.shape[0]} and {df_test.shape[1]}\")","dbcedf25":"def null_data_table(data):\n    \"\"\"\n    A function which gives the number and percentage of null values in the given dataset.\n    \"\"\"\n    indices = data.isnull().sum().index\n    values = data.isnull().sum().values\n    percentages = []\n    for i in indices:\n        percentages.append((data[i].isnull().sum() \/ data[i].shape[0]) * 100)\n    dataframe = {'Columns' : indices, 'Count of Null Values' : values, 'Percentage of Null Values' : percentages}\n    # data = dict(zip(indices, percentages))\n    null_data_frame = pd.DataFrame(data = dataframe)\n    return null_data_frame","08f194fa":"null_frame_train = null_data_table(df_train)\nnull_frame_train.sort_values(by = 'Percentage of Null Values').tail(10)","34d348a2":"null_frame_test = null_data_table(df_test)\nnull_frame_test.sort_values(by = 'Percentage of Null Values').tail(10)","d22aa4e1":"# Combine train and test sets\ntotal = pd.concat((df_train, df_test), sort = False).reset_index(drop = True)\n# Drop the target \"SalePrice\" and Id columns\ntotal.drop(['SalePrice'], axis = 1, inplace = True)\nprint(f\"Total size is {total.shape}\")","c01b2fa9":"numeric = df_train.select_dtypes(exclude=['object'])\nprint(numeric.shape)\ncategorical = df_train.select_dtypes(include= ['object'])\nprint(categorical.shape)","e927789f":"numeric.corr()['SalePrice'][:-1].sort_values().plot(kind='bar')","0ece082c":"sns.distplot(numeric['SalePrice'])","695b080f":"plt.subplots(figsize = (12,8))\n\nplt.scatter(df_train['GrLivArea'],df_train['SalePrice'])\nplt.xlabel('General Living Area')\nplt.ylabel('Sale Price')","ab529ce7":"train = df_train[df_train['GrLivArea'] < 4500]","aa1c4bde":"# looking at the histogram, the sales price is highly skewed\n#from sklearn.preprocessing import PowerTransformer","55bec987":"#log = PowerTransformer() \n#log.fit(df_train[['SalePrice']])\n#df_train['SalePrice'] = log.transform(df_train[['SalePrice']])","927ac1b1":"#sns.distplot(df_train['SalePrice'])","0b3a1c1d":"train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])","285741d6":"sns.distplot(train['SalePrice'])","74aabab4":"y = train['SalePrice'].reset_index(drop = True)\ntrain_features = train.drop('SalePrice', axis = 1)\ntest_features = df_test.copy()\n\nfeatures = pd.concat((train_features, test_features)).reset_index(drop = True)","13963d00":"features.shape","c8b51302":"features['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\nfeatures['YrSold'] = features['YrSold'].astype(str)","753fda39":"def vertical_plot(data, threshold = 20, color = 'black',edgecolor='black', height = 3, width = 15):\n    \n    plt.figure(figsize = (width, height))\n    percent = (data.isnull().mean()) * 100\n    percent.sort_values(ascending = False).plot.bar(color = color, edgecolor = edgecolor)\n    plt.axhline(y = threshold, color = 'r', linestyle = '-')\n    \n    plt.title('Missing values percentage per column', fontsize=20, weight='bold' )\n    \n    plt.text(len(data.isnull().sum()\/len(data)), threshold+12.5, f'Columns with more than {threshold}% missing values', fontsize=12, color='red',\n         ha='left' ,va='top')\n    plt.text(len(data.isnull().sum()\/len(data)), threshold - 5, f'Columns with less than {threshold}% missing values', fontsize=12, color='blue',\n         ha='left' ,va='top')\n    plt.xlabel('Columns', size=15, weight='bold')\n    plt.ylabel('Missing values percentage')\n    plt.yticks(weight ='bold')\n    \n    return plt.show()","1e7db850":"vertical_plot(features, 50, color = sns.color_palette('Blues',15))","e2a8148e":"features = features.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence'], axis = 1)\nfeatures.shape","6ce558c0":"vertical_plot(features, 50, color = sns.color_palette('Blues',15))","b7502513":"description = open(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/data_description.txt\", \"r\")\nprint(description.read())","e62a5392":"print(\"Correlation with the mort_acc column\")\nfeatures.corr()['LotFrontage'].sort_values()","786797e3":"LotArea_avg = features.groupby('LotArea').mean()['LotFrontage']","f9a07b1d":"def fill_lotfrontage(lotarea,lotfrontage):\n    '''\n    Accepts the total_acc and mort_acc values for the row.\n    Checks if the mort_acc is NaN , if so, it returns the avg mort_acc value\n    for the corresponding total_acc value for that row.\n    \n    total_acc_avg here should be a Series or dictionary containing the mapping of the\n    groupby averages of mort_acc per total_acc values.\n    '''\n    if np.isnan(lotfrontage):\n        return LotArea_avg[lotarea]\n    else:\n        return lotfrontage","6fa14a92":"def filling_null(features):\n    \n    # In the description for 'Functional Feature', it is given that Typ refers to the Typical Functionality\n    # We will replace null values in the 'Functional' feature with 'Typ'\n    \n    features['Functional'] = features['Functional'].fillna('Typ')\n    \n    # Replace the null values in the below columns with their mode(words that occur most). We are replacing with mode because\n    # we cant take the mean and median since they are categorical variables.\n    \n    features['Electrical'] = features['Electrical'].fillna(features['Electrical'].mode()[0])\n    \n    features['KitchenQual'] = features['KitchenQual'].fillna(features['KitchenQual'].mode()[0])\n    \n    features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\n    \n    features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n\n    features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n     \n    # In order to fill the null values for MSZoing, we will take into account the MSSubClass featue.\n    # We are doing so because the type of dwelling in a given area largely affects the zone of the area.\n    \n    features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n    \n    # In order to fill the null values for LotFrontage(Linear feet of street connected to property) \n    # we will fill it with mean of the values grouped by the LotArea since it has a higher correlation with LotArea.\n    LotArea_avg = features.groupby('LotArea').mean()['LotFrontage']\n    \n    features['LotArea'] = features.apply(lambda x: fill_lotfrontage(x['LotArea'], x['LotFrontage']), axis=1)\n    \n    # the 'NA' value in many columns signifies the absence of that feature for\n    # a particular house, we will replace those null values with None.\n    # 'None' for categorical feature and 0 for numerical feature.\n    \n    cat_features = features.select_dtypes(include = 'object').columns\n    num_features = features.select_dtypes(exclude = 'object').columns\n    \n    features[cat_features] = features[cat_features].fillna('None')\n    features[num_features] = features[num_features].fillna(0)\n        \n    return features","5a614d77":"features = filling_null(features)\nfeatures.isnull().sum().sum()","8c6df521":"def new_features(features):\n    \n    features['HasPool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    features['Has2ndFloor'] = features['2ndFlrSF'].apply(lambda x : 1 if x > 0 else 0)\n    features['HasGarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n    features['HasBsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n    features['HasFireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n    \n    # Adding total sqfootage features \n    # In order to get the total area of the house we have to add the basement area, 1st floor area and 2nd floor area.\n    \n    features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n    \n    # Total number of bathrooms = number of full bathrooms + 0.5 * number of half bathrooms\n    # + number of bathrooms in basement + 0.5 * number of half bathrooms in the basement.\n    \n    features['Total_Bathrooms'] = (features['FullBath'] + features['HalfBath'] +\n                                   features['BsmtFullBath'] + features['BsmtHalfBath'])\n    \n    features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n                                  features['EnclosedPorch'] + features['ScreenPorch'])\n\n    # Add years since age\n    features['Age'] = features['YrSold'].astype(int) - features['YearRemodAdd'].astype(int)\n\n    return features","426a1502":"features = new_features(features)\nfeatures.shape","ead7e8ac":"from scipy.stats import skew","d1b2aed1":"def remove_skew(features):\n    \n    from scipy.special import boxcox1p\n    from scipy.stats import boxcox_normmax\n    \n    ## Getting all the data that are not of \"object\" type. \n    numerical_columns = features.select_dtypes(exclude = 'object').columns\n\n    # Check the skew of all numerical features\n    skewed_features = features[numerical_columns].apply(lambda x: x.skew()).sort_values(ascending=False)\n    \n    high_skew = skewed_features[abs(skewed_features) > 0.5]\n    skewed_features = high_skew.index\n\n    # Perform the Box-Cox transformation\n    for column in skewed_features:\n        features[column] = boxcox1p(features[column], boxcox_normmax(features[column] + 1))\n        \n    return features","e9a87fb6":"features = remove_skew(features)\nfeatures.head()","5192fbb3":"features = pd.get_dummies(features).reset_index(drop=True)\nfeatures.head()","882c91a9":"X = features.iloc[:len(y), :]\ntest = features.iloc[len(y):, :]","1a624a50":"X.shape, test.shape, y.shape","8fb63224":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score\nfrom sklearn.svm import LinearSVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import HuberRegressor","52b06bce":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","504c55e2":" def evaluation(model, x_train, y_train, x_test, y_test, train = True):\n    if train == True:\n        pred = model.predict(x_train)\n        \n        print(\"Train Result:\\n================================================\")\n        print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_train, pred))}\")\n        print(\"_______________________________________________\")\n        print(f\"Mean Squared Error: {mean_squared_error(y_train, pred)}\")\n        print(\"_______________________________________________\")\n        print(f\"Mean Absolute Error: \\n{mean_absolute_error(y_train, pred)}\")\n        print(\"_______________________________________________\")\n        \n    print()\n    \n    if train == False:\n        pred = model.predict(x_test)\n        \n        print(\"Test Result:\\n================================================\")\n        print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_test, pred))}\")\n        print(\"_______________________________________________\")\n        print(f\"Mean Squared Error: {mean_squared_error(y_test, pred)}\")\n        print(\"_______________________________________________\")\n        print(f\"Mean Absolute Error: \\n{mean_absolute_error(y_test, pred)}\")\n        print(\"_______________________________________________\")","d6ce7bd2":"from sklearn.linear_model import Lasso\nls = Lasso(alpha = 0.1)\nls.fit(X_train, y_train)\n\nevaluation(ls, X_train, y_train, X_test, y_test, True)\nevaluation(ls, X_train, y_train, X_test, y_test, False)","c036338b":"from sklearn.linear_model import Ridge\nridge = Ridge(alpha = 10)\nridge.fit(X_train, y_train)\n\nevaluation(ridge, X_train, y_train, X_test, y_test, True)\nevaluation(ridge, X_train, y_train, X_test, y_test, False)","60a943ee":"test_pred = ridge.predict(test)\nprediction = pd.DataFrame(df_test_id, columns = ['Id'])\ntest_pred = np.expm1(test_pred)\nprediction['SalePrice'] = test_pred \nprediction.head()","cd7c8405":"prediction.shape[0]","cf47eaa6":"filename = 'house prices prediction.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)\n","7607b121":"# FEATURE ENGINEERING","1fb11cd2":"check correlation between target variable and numerical features","057adfec":"- the lotfrontage has cant be absent so we cant fill its missing values with zero\n- we fill in the missing values with that of a numeric column with the strongest correlation ","d9d1c052":"checking for outliers\n- outliers can negatively affect our model so we need to take care of them\n- there are several ways of dealing with outliers:\n    1. one of which involves cutting values within a selected range. this has some disadvantage:\n        - removes from all features within that range even if there are no ouliers \n    2. removing outliers above a certain standard deviation from the mean    \n","a1aedcf2":"# Defining a function that returns the percentage of null values per feature","dad8286d":"# selecting specific datatypes","4b5c24f9":"- the target variable assumes a normal distribution but it is positively skewed \n- this will affect our model.\n- hence we need to remove the skewness before developing our model"}}