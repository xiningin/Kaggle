{"cell_type":{"cd4c1bb4":"code","e50a101f":"code","fa373415":"code","d8c472e2":"code","9d287967":"code","5bd414db":"code","c13308e8":"code","7837e6b3":"code","dca3e82b":"code","92d6bcb6":"code","c302d138":"code","c4ae65bc":"code","cf81237b":"code","c1a21ff5":"code","3cb607f0":"code","b1379fec":"code","08523d9c":"code","7b3cf6cd":"code","0c884f9f":"code","2cd5a123":"markdown","e1537c70":"markdown","2fe9c811":"markdown","cd50fdf9":"markdown","b41f852a":"markdown","38869afd":"markdown"},"source":{"cd4c1bb4":"import numpy as np # linear algebr\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA \nfrom sklearn.cluster import KMeans \nfrom sklearn.manifold import TSNE\nimport warnings \nwarnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e50a101f":"train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\ntrain.head()","fa373415":"print(train.shape)\nprint(test.shape)\nprint(train.columns)\nprint(test.columns)\nprint(train.info())\nprint(train.describe().transpose())\nprint(\"\\n\",train.isnull().sum())","d8c472e2":"def time_step(x):\n    if x < 1.0:\n        return 0\n    elif x < 1.5:\n        return 1\n    else:\n        return 2\ntrain[\"log_u_in\"] = np.log1p(train.u_in)\ntest[\"log_u_in\"] = np.log1p(test.u_in)\n\ntrain[\"time_step_class\"] = train.time_step.apply(time_step)\ntest[\"time_step_class\"] = test.time_step.apply(time_step)\n\npivot = train.pivot_table(index=\"breath_id\", columns=\"time_step_class\", values=\"log_u_in\", fill_value=0, aggfunc=\"mean\")\npivot_test = test.pivot_table(index=\"breath_id\", columns=\"time_step_class\", values=\"log_u_in\", fill_value=0, aggfunc=\"mean\")\n\npivot.head()","9d287967":"pca = PCA(n_components=2, random_state=42)\npca.fit(pivot)\nplt.figure(figsize=(12,8),dpi=60)\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.grid()\nplt.xlabel(\"n_components\")\nplt.ylabel(\"explained_variance_ratio_\")\nplt.xticks([0, 1])\nplt.show()","5bd414db":"train_pca = pca.transform(pivot)\ntest_pca = pca.transform(pivot_test)\n\ntrain_pca = pd.DataFrame(train_pca, columns=[\"c\"+str(c) for c in range(2)], index=pivot.index)\ntest_pca = pd.DataFrame(test_pca, columns=[\"c\"+str(c) for c in range(2)], index=pivot_test.index)\n\ntrain_pca.head()","c13308e8":"plt.figure(figsize=(12,8),dpi=60)\nsns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\")\nplt.show()","7837e6b3":"km = KMeans(n_clusters=3, \n            random_state=42,\n            max_iter=100,\n            init=\"k-means++\", \n            tol=0.0001)\ny_km = km.fit_predict(train_pca)\ny_km_test = km.predict(test_pca)","dca3e82b":"from sklearn.metrics import silhouette_samples\nfrom matplotlib import cm\n\ncluster_labels = np.unique(y_km)\nn_clusters=cluster_labels.shape[0]    \n\nsilhouette_vals = silhouette_samples(train_pca, y_km, metric='euclidean')  \ny_ax_lower, y_ax_upper= 0,0\nyticks = []\n\nfor i,c in enumerate(cluster_labels):\n        c_silhouette_vals = silhouette_vals[y_km==c]   \n        c_silhouette_vals.sort()\n        y_ax_upper += len(c_silhouette_vals)              \n        color = cm.jet(float(i)\/n_clusters)              \n        plt.barh(range(y_ax_lower,y_ax_upper),            \n                         c_silhouette_vals,               \n                         height=1.0,                      \n                         edgecolor='none',                \n                         color=color)                     \n        yticks.append((y_ax_lower+y_ax_upper)\/2)          \n        y_ax_lower += len(c_silhouette_vals)              \n\nsilhouette_avg = np.mean(silhouette_vals)                 \nplt.axvline(silhouette_avg,color=\"red\",linestyle=\"--\")     \nplt.yticks(yticks,cluster_labels + 1)                     \nplt.ylabel('Cluster')\nplt.xlabel('silhouette coefficient')\nplt.show()","92d6bcb6":"\ntrain_pca[\"cluster\"] = y_km\ntest_pca[\"cluster\"] = y_km_test\n\ncenter = km.cluster_centers_\nplt.figure(figsize=(12,8),dpi=60)\nsns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\", hue=\"cluster\")\nplt.plot(center[0, 0], center[0, 1], \"bo\", c=\"r\")\nplt.plot(center[1, 0], center[1, 1], \"bo\", c=\"r\")\nplt.plot(center[2, 0], center[2, 1], \"bo\", c=\"r\")\nplt.show()","c302d138":"train_pca[\"cluster\"] = train_pca.cluster.apply(lambda x: 0 if x == 2 else 1)\ntest_pca[\"cluster\"] = test_pca.cluster.apply(lambda x: 0 if x == 2 else 1)\nplt.figure(figsize=(12,8),dpi=60)\nsns.scatterplot(data=train_pca, x=\"c0\", y=\"c1\", hue=\"cluster\")\nplt.show()","c4ae65bc":"train_pca[\"breath_id\"] = train_pca.index \ntrain_pca.drop([\"c0\", \"c1\"], axis=1, inplace=True)\ntrain_pca = train_pca.reset_index(drop=True)\ntrain = pd.merge(train, train_pca, how=\"left\", on=\"breath_id\")\n\ntest_pca[\"breath_id\"] = test_pca.index \ntest_pca.drop([\"c0\", \"c1\"], axis=1, inplace=True)\ntest_pca = test_pca.reset_index(drop=True)\ntest = pd.merge(test, test_pca, how=\"left\", on=\"breath_id\")\n\n# helper \ndef find_cluster_r_c(df):\n    fig, ax = plt.subplots(2, 2, figsize=(15, 6))\n    for c in range(2):\n        for r_c in range(2):\n            x = df.loc[df.cluster == c, \"R\" if r_c == 0 else \"C\" ]\n            sns.countplot(x, ax=ax[c][r_c])\n            ax[c][r_c].set_title(f\"Cluster={c}\")\n    plt.tight_layout()\n\ndef find_cluster_transition(df, is_train=True):\n    fig, ax = plt.subplots(2, 5, figsize=(15, 6))\n    for c in range(2):\n        x = df.loc[df.cluster == c]\n        breath = x.breath_id.unique()\n        for n in range(5):\n            if is_train:\n                xx = x.loc[x.breath_id == breath[n], [\"time_step\", \"u_in\", \"u_out\", \"pressure\"]]\n            else:\n                xx = x.loc[x.breath_id == breath[n], [\"time_step\", \"u_in\", \"u_out\"]]\n            xx.set_index(\"time_step\").plot(ax=ax[c][n])\n            ax[c][n].set_title(f\"breath_id={breath[n]}\")\n            ax[c][n].set_xticks([])\n            \n            if n == 0:\n                ax[c][n].set_ylabel(f\"Cluster={c}\")\n    plt.tight_layout()\n            ","cf81237b":"sns.countplot(train.cluster)","c1a21ff5":"sns.countplot(test.cluster)\n","3cb607f0":"find_cluster_r_c(train)\n","b1379fec":"find_cluster_r_c(test)","08523d9c":"find_cluster_transition(train)","7b3cf6cd":"find_cluster_transition(test, False)","0c884f9f":"train.drop([\"time_step_class\", \"log_u_in\"], axis=1, inplace=True)\ntest.drop([\"time_step_class\", \"log_u_in\"], axis=1, inplace=True)\n\ntrain.to_csv(\"train.csv\", index=False)\ntest.to_csv(\"test.csv\", index=False)","2cd5a123":"# Applying dimensionality reduction algorithm to reduce the number of dimensions,which can be done by using PCA which is termed as a unsupervised machine level algorithm \n\n**Process includes \n\n1.Standardise the data(scales should be similar)\n\n2.Build a Correclation matrix(To find the relationship among the variables)\n\n3.Obtain Eigen Values and Eigen Vectors\n\n4.Break into directions(Eigen Vectors) and Magnitude(Eigen Values)\n\n5.Sort Eigen values in descending order.\n\n6.Dropping less informative pairs.\n\n7.Tranforming data into KK dimentional features.**","e1537c70":"# Data Preprocessing","2fe9c811":"# Visualising with Scatterplot","cd50fdf9":"# Performing Clustering on the above dataset and perform silhouette method to get the number of clusters","b41f852a":"# Please Upvote if you like the notebook","38869afd":"# Import both train and test data"}}