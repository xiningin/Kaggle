{"cell_type":{"bdd794e3":"code","e06675cc":"code","9d1693a4":"code","3ced100b":"code","62711841":"code","a28d381a":"code","7b1571c6":"code","5f1597eb":"code","c2bcceda":"code","6fef707a":"code","4ac1b0f0":"code","c2e7e967":"code","f1401731":"code","9777aff7":"code","4571b397":"code","8c879ee9":"code","163e2dcf":"code","c5015834":"code","1f422b92":"code","092f6b11":"code","7ad489dc":"code","20d10f6b":"markdown","f1e209a4":"markdown","a3bb9a8d":"markdown"},"source":{"bdd794e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e06675cc":"!pip install segmentation_models -q\n%env SM_FRAMEWORK=tf.keras","9d1693a4":"import tensorflow as tf\nimport segmentation_models as sm\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom zipfile import ZipFile\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nimport gc","3ced100b":"# import data tiles (iafoss 512x512)\n\nimage_zip = '..\/input\/iafoss-512x512\/train.zip'\nmask_zip = '..\/input\/iafoss-512x512\/masks.zip'\n\nimage_store = '..\/kaggle\/working\/train\/'\nmask_store = '..\/kaggle\/working\/masks\/'\n\nwith ZipFile(image_zip, 'r') as imgs:\n    imgs.extractall(image_store)\n\nwith ZipFile(mask_zip, 'r') as masks:\n    masks.extractall(mask_store)","62711841":"TRAIN_TILES = []\nTRAIN_MASKS = []\n\nfor tile in os.listdir(image_store):\n    TRAIN_TILES.append(np.asarray(Image.open(image_store + tile)))\n\nfor mask in os.listdir(mask_store):\n    TRAIN_MASKS.append(np.asarray(Image.open(mask_store + mask)))","a28d381a":"# define image augmentation steps\naug = A.Compose([# A.Normalize(mean=(0.6627, 0.5120, 0.6972), std=(0.1804, 0.2560, 0.1648),\n                 #             max_pixel_value=255.0, always_apply=False, p=1.0),\n                 A.OneOf([A.RandomRotate90(),\n                          A.HorizontalFlip(),\n                          A.VerticalFlip()], p=0.8),\n                 A.OneOf([A.RandomBrightnessContrast(),\n                          A.HueSaturationValue()], p=0.3)])","7b1571c6":"aug = [aug(image=img, mask=mask) for (img, mask) in list(zip(TRAIN_TILES, TRAIN_MASKS))]","5f1597eb":"X = [img['image'] for img in aug]\nY = [mask['mask'] for mask in aug]","c2bcceda":"X = np.asarray(X)\nY = np.asarray(Y)","6fef707a":"del TRAIN_TILES, TRAIN_MASKS, aug\ngc.collect()","4ac1b0f0":"BACKBONE = 'resnet34'\nBATCH_SIZE = 16\nEPOCHS = 30","c2e7e967":"preprocess_input = sm.get_preprocessing(BACKBONE)","f1401731":"X_TRAIN, X_VAL, Y_TRAIN, Y_VAL = train_test_split(X, Y, test_size=0.2, random_state=15)","9777aff7":"del X, Y\ngc.collect()","4571b397":"X_TRAIN = preprocess_input(X_TRAIN)\nX_VAL = preprocess_input(X_VAL)","8c879ee9":"def dice_coe(output, target, axis = None, smooth=1e-10):\n    output = tf.dtypes.cast( tf.math.greater(output, 0.5), tf. float32 )\n    target = tf.dtypes.cast( tf.math.greater(target, 0.5), tf. float32 )\n    inse = tf.reduce_sum(output * target, axis=axis)\n    l = tf.reduce_sum(output, axis=axis)\n    r = tf.reduce_sum(target, axis=axis)\n\n    dice = (2. * inse + smooth) \/ (l + r + smooth)\n    dice = tf.reduce_mean(dice, name='dice_coe')\n    return dice","163e2dcf":"model = sm.Unet(BACKBONE, encoder_weights='imagenet')\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coe])\nmodel.summary()","c5015834":"check = tf.keras.callbacks.ModelCheckpoint(filepath='\/kaggle\/working\/alina_resnet34.h5', verbose=1,\n                                           save_best_only=True)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=7, monitor='val_dice_coe', mode='max',\n                                              restore_best_weights=True)","1f422b92":"history = model.fit(X_TRAIN, Y_TRAIN, batch_size=BATCH_SIZE, epochs=EPOCHS,\n                    callbacks=[check, early_stop], validation_data=(X_VAL, Y_VAL))","092f6b11":"# plot training and validation loss\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'y', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","7ad489dc":"model.save('alina_resnet34.h5')","20d10f6b":"# Build Model","f1e209a4":"# Data augmentation","a3bb9a8d":"# Import tiled images"}}