{"cell_type":{"d21b4ed3":"code","d9c26748":"code","c53d1d12":"code","c5c18d62":"code","fce3acb0":"code","8b4f06ed":"code","22b99e62":"code","ea8623e2":"code","0b064610":"code","04997f73":"code","89bfc35e":"code","3e857ac4":"code","653a144c":"code","ab608139":"code","cf452cad":"code","6121e1ea":"code","41561fc3":"code","83f4290b":"code","8dffe2db":"code","c03d1269":"code","7f9fcd81":"code","55856011":"code","052a42af":"code","22d748ef":"code","dfe2ce27":"code","d2016d14":"code","4b8964d7":"code","e51f0559":"code","dca7ce99":"code","c126052a":"code","2caef649":"code","03d639b6":"code","35e96c66":"markdown","2efca0dc":"markdown","02643b7e":"markdown","617fe12c":"markdown","3c88bf8e":"markdown","0b2d5622":"markdown","d0f5dec0":"markdown","6f828774":"markdown","bdb753ba":"markdown","17645d93":"markdown","e62ac847":"markdown","770dd4ce":"markdown","65e08a4f":"markdown","5583443c":"markdown","5f96781d":"markdown","f269c6d1":"markdown","3eada1e9":"markdown"},"source":{"d21b4ed3":"# Packages used within the scope of this analysis\n!pip install rank_bm25\n!pip install pyLDAvis\n!pip install nltk \n!pip install scispacy\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_md-0.2.4.tar.gz\n!pip install spacy\n\n!pip install scispacy\n!pip install wordcloud\n!pip install kneed\n!pip install torch\n!pip install sentence_transformers\n!pip install https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.2.0\/en_core_web_sm-2.2.0.tar.gz\n!pip install scattertext\n!pip install gensim\n!pip install yattag\n!pip install bokeh\n!pip install interact","d9c26748":"# Modules that need to be imported for this analysis\n\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download(\"punkt\")\nimport pandas as pd\nfrom pandas import ExcelWriter\nfrom pandas import ExcelFile\nimport string\nimport re\nimport numpy as np\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom gensim.models.ldamodel import LdaModel\nfrom gensim.corpora.dictionary import Dictionary\n#Create Biagram & Trigram Models \nfrom gensim.models import Phrases\n\n# spacy for lemmatization\nimport spacy\n\n#sklearn\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n#bm25 imports\nfrom rank_bm25 import BM25Okapi\n\n#nltk\nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import Word\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.tokenize import word_tokenize, sent_tokenize , RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\nfrom nltk.corpus import wordnet \nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom difflib import SequenceMatcher , get_close_matches, Differ\nfrom sentence_transformers import SentenceTransformer\nimport scipy\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom kneed import KneeLocator\nimport matplotlib.colors as mcolors\nimport seaborn as sns\n\nfrom pandas import Panel\nfrom tqdm import tqdm_notebook as tqdm\n\n# Enable logging for gensim - optional\nimport logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n\nfrom pprint import pprint\n\nimport en_core_sci_md\nimport scattertext as st\nimport en_core_web_sm\nfrom IPython.display import IFrame\n# from kaggle.api.kaggle_api_extended import KaggleApi\nimport glob\nimport json\n\nfrom IPython.display import HTML\nfrom yattag import Doc, indent\n\nfrom sklearn.manifold import TSNE\nfrom bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, CustomJS\nfrom bokeh.palettes import Category20\nfrom bokeh.transform import linear_cmap\nfrom bokeh.io import output_file, show\nfrom bokeh.transform import transform\nfrom bokeh.io import output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.layouts import column\nfrom bokeh.models import RadioButtonGroup\nfrom bokeh.models import TextInput\nfrom bokeh.layouts import gridplot\nfrom bokeh.models import Div\nfrom bokeh.models import Paragraph\nfrom bokeh.layouts import column, widgetbox\nfrom gensim import corpora, models\nfrom bokeh.io import output_notebook\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import HoverTool, CustomJS, ColumnDataSource, Slider\nfrom bokeh.layouts import column\nfrom bokeh.palettes import all_palettes\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport gc\nimport os\nimport pickle","c53d1d12":"# The files pulled from different directories \n# ## Metadatafile\nmeta_file = '\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv'\nmeta_df = pd.read_csv(meta_file)\n\n# ## 4 json files\nbio_path =  '\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/'\ncomm_path = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/'\nnon_comm_path = '\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/'\ncustom_path = '\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/'","c5c18d62":"# Categories of journals\njournals = {\"BIORXIV_MEDRXIV\": bio_path,\n              \"COMMON_USE_SUB\" : comm_path,\n              \"NON_COMMON_USE_SUB\" : non_comm_path,\n              \"CUSTOM_LICENSE\" : custom_path}","fce3acb0":"# Function to parse each json file and merge abstract and body text into a new column 'full_text'\n\ndef parse_each_json_file(file_path,journal):\n    inp = None\n    with open(file_path) as f:\n        inp = json.load(f)\n    rec = {}\n    rec['document_id'] = inp['paper_id'] or None\n    rec['title'] = inp['metadata']['title'] or None\n    if inp.get('abstract'):\n        abstract = \"\\n \".join([inp['abstract'][_]['text'] for _ in range(len(inp['abstract']) - 1)])\n        rec['abstract'] = abstract or None\n    else:\n        rec['abstract'] = None\n    full_text = []\n    for _ in range(len(inp['body_text'])):\n        try:\n            full_text.append(inp['body_text'][_]['text'])\n        except:\n            pass\n\n    rec['full_text'] = \"\\n \".join(full_text) or None\n    rec['source'] =  journal     or None    \n    return rec","8b4f06ed":"# Function to merge extracted data from json files into a pandas dataframe \n\ndef parse_json_and_create_csv(journals):\n    journal_dfs = []\n    cnt = 0\n    for journal, path in journals.items():\n        print(journal,path)\n        parsed_rcds = []  \n        json_files = glob.glob('{}\/**\/*.json'.format(path), recursive=True)\n        for file_name in json_files:\n            cnt = cnt + 1\n            #print('processing {} file {}'.format(cnt,file_name))\n            rec = parse_each_json_file(file_name,journal)\n            parsed_rcds.append(rec)\n        print(\"Total Records in list = {}\".format(len(parsed_rcds)))\n        df = pd.DataFrame(parsed_rcds)\n        journal_dfs.append(df)\n        #print(journal_dfs)\n    return pd.concat(journal_dfs)","22b99e62":"# Create a csv file with extracted data from json files\n\nall_df = parse_json_and_create_csv(journals=journals)\n\n# Save the dataframe into a csv:\n#all_df.to_csv(\"covid19_latest.csv\",index=False)","ea8623e2":"# Drop Duplicates for the df from 4 json files based on document id and title keys and from metadata file\nall_df = all_df.drop_duplicates(subset=['document_id', 'title'])\n\n# Drop Duplicates for the meta data df based on sha key\nmeta_df = meta_df.drop_duplicates(subset=['sha'])","0b064610":"# Display dimensions of text and metadata dataframes\nprint('all_df:',all_df.shape)\nprint('meta_df:',meta_df.shape)","04997f73":"# Merging the useful columns from metadata file with the final_all_df file\n\ncovid_df = pd.merge(left=all_df, right=meta_df, how='left', left_on='document_id', right_on='sha')\ncovid_df['publish_time'] = covid_df['publish_time'].fillna('1900')\ncovid_df['publish_time'] = covid_df['publish_time'].str[:4]\ncovid_df['publish_time'] = covid_df['publish_time'].astype(int)\ncovid_df.fillna(\"\",inplace=True)\n\n### Saving this final merged dataframe into csv:covid10_final\n#merged_df.to_csv(\"covid19_final.csv\",index=False)","89bfc35e":"%%time\n# Duplicate columns between the json files and meta data are dropped and column headers renamed\n\ncovid_df=covid_df.drop(columns=[ 'title_y', 'abstract_y','source_x','sha', 'Microsoft Academic Paper ID','license', 'WHO #Covidence', 'has_pdf_parse', 'has_pmc_xml_parse', 'full_text_file'])\ncovid_df=covid_df.rename(columns={\"title_x\":'title',\"abstract_x\":\"abstract\",'full_text':'body','document_id':'paper_id','source':'dataset'})\n\nprint('Dataset for before BM25 Scoring ',covid_df.shape)","3e857ac4":"print(covid_df.columns)\nprint('\\n covid_df Shape:', covid_df.shape)\n\ncovid_df = covid_df[covid_df['body'].str.lower().str.contains('corona|sars|ncov|covid|ncovid|novel')]\nprint('\\n covid_df after filtering Shape:', covid_df.shape)\n\ncovid_df= covid_df.drop_duplicates(subset=['title'])\nprint('\\n covid_df after Title duplicate drop Shape:', covid_df.shape)\n\ncovid_df = covid_df.drop(['dataset', 'cord_uid', 'doi','pmcid', 'pubmed_id','journal'], axis = 1)\nprint('\\n covid_df after columns drop Shape:', covid_df.columns)\n\ncovid_df = covid_df.reset_index(drop=True)","653a144c":"del [[meta_df,all_df]]\ngc.collect()","ab608139":"# Pre-processing functions for cleaning text \n\nexclude_list = string.digits + string.punctuation\ntable = str.maketrans(exclude_list, len(exclude_list)*\" \")\nstop = stopwords.words('english')\nenglish_stopwords = list(set(stop))\nSEARCH_DISPLAY_COLUMNS = ['paper_id', 'title', 'body', 'publish_time', 'url', 'all_text']\n\nnlp_x = en_core_web_sm.load()   \n\ndef clean_text(txt):    \n    t = txt.replace(\"\\\\n\",'')\n    t = re.sub('\\(|\\)|:|,|;|\\|\u2019|\u201d|\u201c|\\?|%|>|<', '', t )\n    t = re.sub('\/', ' ', t)\n    t = t.replace('\\n','')\n    t = t.replace('  ','')\n    t = t.replace(\"[\",'')\n    t = t.replace(\"]\",'')\n    t = ' '.join([word for word in t.split() if len(word)>1 ])\n    t = sent_tokenize(t)\n    return t\n\ndef preprocess_with_ngrams(docs):\n    # Add bigrams and trigrams to docs,minimum count 10 means only that appear 10 times or more.\n    bigram = Phrases(docs, min_count=5)\n    trigram = Phrases(bigram[docs])\n\n    for idx in range(len(docs)):\n        for token in bigram[docs[idx]]:\n            if '_' in token:\n                # Token is a bigram, add to document.\n                docs[idx].append(token)\n        for token in trigram[docs[idx]]:\n            if '_' in token:\n                # Token is a trigram, add to document.\n                docs[idx].append(token)\n    return docs\n\nclass SearchResults:\n    \n    def __init__(self, \n                 data: pd.DataFrame,\n                 columns = None):\n        self.results = data\n        if columns:\n            self.results = self.results[columns]\n            \n    def __getitem__(self, item):\n        return Paper(self.results.loc[item])\n    \n    def __len__(self):\n        return len(self.results)\n        \n    def _repr_html_(self):\n        return self.results._repr_html_()\n    \n    def getDf(self):        \n        return self.results \n    \ndef strip_characters(text):\n    t = re.sub('\\(|\\)|:|,|;|\\.|\u2019|\u201d|\u201c|\\?|%|>|<', '', text)\n    t = re.sub('\/', ' ', t)\n    t = t.replace(\"'\",'')\n    return t\n\ndef clean(text):\n    t = text.lower()\n    t = strip_characters(t)\n    t = str(t).translate(table)\n    return t\n\ndef tokenize(text):\n    words = nltk.word_tokenize(text)\n    return list(set([word for word in words \n                     if len(word) > 1\n                     and not word in english_stopwords\n                     and not (word.isnumeric() and len(word) is not 4)\n                     and (not word.isnumeric() or word.isalpha())] )\n               )\n\ndef preprocess(text):\n    t = clean(text)    \n    tokens = tokenize(t)\n    \n    return tokens\n\n","cf452cad":"# Functions defining the BM25 Algorithm\n\nclass WordTokenIndex:\n    \n    def __init__(self, \n                 corpus: pd.DataFrame, \n                 columns=SEARCH_DISPLAY_COLUMNS):\n        self.corpus = corpus\n        raw_search_str =self.corpus.title.fillna('') +' ' + self.corpus.body.fillna('')\n        self.corpus['all_text'] = raw_search_str.apply(preprocess).to_frame()\n        self.index = raw_search_str.apply(preprocess).to_frame()\n        self.index.columns = ['terms']\n        self.index.index = self.corpus.index\n        self.columns = columns\n       \n    def search(self, search_string):\n        search_terms = preprocess(search_string)\n        result_index = self.index.terms.apply(lambda terms: any(i in terms for i in search_terms))\n        results = self.corpus[result_index].copy().reset_index().rename(columns={'index':'paper'})\n        return SearchResults(results, self.columns + ['paper'])\n    \nclass RankBM25Index(WordTokenIndex):\n    \n    def __init__(self, corpus: pd.DataFrame, columns=SEARCH_DISPLAY_COLUMNS):\n        super().__init__(corpus, columns)\n        #self.bm25 = BM25Okapi(self.index.terms.tolist())\n        self.bm25 = BM25Okapi(self.index.terms.tolist(),k1=3,b=0.001)\n        \n    def search(self, search_string, n=4):\n        search_terms = preprocess(search_string)\n        doc_scores = self.bm25.get_scores(search_terms)\n        ind = np.argsort(doc_scores)[::-1][:n]\n        results = self.corpus.iloc[ind][self.columns]\n        results['BM25_Score'] = doc_scores[ind]\n        results = results[results.BM25_Score > 0]\n        return SearchResults(results.reset_index(), self.columns + ['BM25_Score'])\n    \ndef show_task(taskTemp,taskId):\n    #print(Task)\n    keywords = taskTemp#tasks[tasks.Task == Task].Keywords.values[0]\n    print(keywords)\n    search_results = bm25_index.search(keywords, n=200)    \n    return search_results","6121e1ea":"# Functions defining the BM25 Algorithm\n\nclass WordTokenIndex:\n    \n    def __init__(self, \n                 corpus: pd.DataFrame, \n                 columns=SEARCH_DISPLAY_COLUMNS):\n        self.corpus = corpus\n        raw_search_str =self.corpus.title.fillna('') +' ' + self.corpus.body.fillna('')\n        self.corpus['all_text'] = raw_search_str.apply(preprocess).to_frame()\n        self.index = raw_search_str.apply(preprocess).to_frame()\n        self.index.columns = ['terms']\n        self.index.index = self.corpus.index\n        self.columns = columns\n       \n    def search(self, search_string):\n        search_terms = preprocess(search_string)\n        result_index = self.index.terms.apply(lambda terms: any(i in terms for i in search_terms))\n        results = self.corpus[result_index].copy().reset_index().rename(columns={'index':'paper'})\n        return SearchResults(results, self.columns + ['paper'])\n    \nclass RankBM25Index(WordTokenIndex):\n    \n    def __init__(self, corpus: pd.DataFrame, columns=SEARCH_DISPLAY_COLUMNS):\n        super().__init__(corpus, columns)\n        #self.bm25 = BM25Okapi(self.index.terms.tolist())\n        self.bm25 = BM25Okapi(self.index.terms.tolist(),k1=3,b=0.001)\n        \n    def search(self, search_string, n=4):\n        search_terms = preprocess(search_string)\n        doc_scores = self.bm25.get_scores(search_terms)\n        ind = np.argsort(doc_scores)[::-1][:n]\n        results = self.corpus.iloc[ind][self.columns]\n        results['BM25_Score'] = doc_scores[ind]\n        results = results[results.BM25_Score > 0]\n        return SearchResults(results.reset_index(), self.columns + ['BM25_Score'])\n    \ndef show_task(taskTemp,taskId):\n    #print(Task)\n    keywords = taskTemp#tasks[tasks.Task == Task].Keywords.values[0]\n    print(keywords)\n    search_results = bm25_index.search(keywords, n=200)    \n    return search_results","41561fc3":"%%time\n\nrebuild_index = False\n\n#BM25 algorithm getting trained on the text from the dataset\n\nbm25index_file_create = '\/kaggle\/working\/covid_task9_bm25index.pkl'\nbm25index_file_load = '\/kaggle\/input\/cord-19-bm25index\/covid_task9_bm25index.pkl'\nif rebuild_index:\n        print(\"Running the BM25 index...\")\n        bm25_index = RankBM25Index(covid_df)\n        print(\"Creating pickle file for the bm25 index...\")\n        with open(bm25index_file_create, 'wb') as file:\n            pickle.dump(bm25_index, file)\n        with open(bm25index_file_create, 'rb') as corpus_pt:\n            bm25_index = pickle.load(corpus_pt)\n        print(\"Completed load of the BM25 index from\", bm25index_file_create, '...')\nelse:\n    with open(bm25index_file_load, 'rb') as corpus_pt:\n        bm25_index = pickle.load(corpus_pt)\n    print(\"Completed load of the BM25 index from\", bm25index_file_load, '...')\n\n\nprint(\"Shape of BM25: \", bm25_index.corpus.shape)","83f4290b":"# LDA & Coherence functions\n\n# Find the optimal topic model\ndef findOptimalTopicModel(start_num_topics, noOfMaxTopics, step_num_topics,model_list, coherence_values): \n    temp_coherenace = 0\n    best_model_idx = 0\n    idx = 0\n    number_of_topics = 0\n    x = range(start_num_topics, noOfMaxTopics, step_num_topics)\n    for m, cv in zip(x, coherence_values):\n        #print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))    \n        if(temp_coherenace<cv):\n            temp_coherenace = cv\n            best_model_idx = idx\n            number_of_topics = m\n        idx += 1\n \n    # Select the model and print the topics\n    optimal_model = model_list[best_model_idx]\n    model_topics = optimal_model.show_topics(num_topics=number_of_topics,formatted=False)\n    return (optimal_model, model_topics, number_of_topics, temp_coherenace)\n\ndef compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())        \n    return model_list, coherence_values\n\ndef format_topics_sentences(df,ldamodel=None, corpus=None, texts=None):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n    \n    # Get main topic in each documentp\n    for i, row_list in enumerate(ldamodel[corpus]):\n        row = row_list[0] if ldamodel.per_word_topics else row_list            \n        \n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        \n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic                \n                wp = ldamodel.show_topic(topic_num)\n                \n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic_num', 'Topic_Perc_Contrib', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    #contents = pd.Series(texts)\n    sent_topics_df = pd.concat([df,sent_topics_df], axis=1)\n    return(sent_topics_df)","8dffe2db":"%%time\n# BERT Sentence Transformer model based on bert-base-nli-mean-tokens\n\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')\nembedder = SentenceTransformer('bert-base-nli-mean-tokens')\ntop_N_sentence = 20\n","c03d1269":"# BERT Functions for sentence embeddings\n\ndef sentenceEmbed(corpus_sentence, tcount):\n    task = [task9_keywords[tcount]]\n    corpus_sentence_embeddings = model.encode(corpus_sentence)\n    query_embeddings = model.encode(task)\n\n    for query, query_embedding in zip(task, query_embeddings):\n        distances = scipy.spatial.distance.cdist([query_embedding], corpus_sentence_embeddings, \"cosine\")[0]\n\n        results = zip(range(len(distances)), distances)\n        results = sorted(results, key=lambda x: x[1])\n\n        #print(\"\\n\\n======================\\n\\n\")\n        #print(\"Query:\", task)\n        #print(\"\\nTop 5 most similar sentences in corpus:\")\n        all_sentence =''\n        top_3_sentence=''\n        score = 0\n        top3 = 1\n        #print(results[0:top_N_sentence])\n        #print(\"\\n\\n======================\\n\\n\")\n        for idx, distance in results[0:top_N_sentence]:\n            #print(\"\\n\\n\",corpus_sentence[idx].strip(), \"(Score: %.4f)\" % (1-distance),\"***END***\")\n            if(top3<4):                \n                top_3_sentence += corpus_sentence[idx].strip().capitalize() +\"--- \\n\\n\"\n                top3 += 1\n            \n            all_sentence += corpus_sentence[idx].strip()\n            score += (1-distance)   \n        score = score\/top_N_sentence\n        scoreStr =''\n        if(score<=0.3):\n            scoreStr = 'Low'\n        elif(score>0.31 and score<0.7):\n            scoreStr = 'Medium'\n        else:\n            scoreStr = 'High'\n    return top_3_sentence,all_sentence,scoreStr;\n","7f9fcd81":"# Function to determine Cut-off point for identifying optimum value\n\ndef kneeLocator(x,y):\n    kn = KneeLocator(x, y,curve='concave',direction='decreasing',online=True)\n    return y[kn.knee-1],kn;","55856011":"# Plot of the curve that shows optimum cut-off value\n\ndef plotKnee(kn,x,y,minval,maxval,x_label,y_label,axes,idx):\n    #plt.xlabel(x_label)\n    #plt.ylabel(y_label)\n    #plt.plot(x, y, 'bx-')\n    #plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    \n    axes[idx].plot(x, y,'bx-')    \n    axes[idx].vlines(kn.knee, minval,maxval, linestyles='dashed')\n    axes[idx].set(xlabel =x_label, ylabel = y_label, title = 'Knee Scoring')\n\n    #plt.show()\n    ","052a42af":"# Visualization Functions used to show Topic coherence and word cloud formed from dominant topics\n\ndef plotCoherence(start_num_topics, noOfMaxTopics, step_num_topics,coherence_values,axes,idx):\n    x = range(start_num_topics, noOfMaxTopics, step_num_topics)\n    axes[idx].plot(x, coherence_values)\n    #plt.plot(x, coherence_values)\n    #plt.xlabel(\"Num Of Topics\")\n    #plt.ylabel(\"Coherence score\")\n    #plt.legend((\"coherence_values\"), loc='best')\n    axes[idx].set(xlabel =\"Num Of Topics\", ylabel = \"Coherence score\", title = 'Coherence Scoring')\n    #plt.show()\n    #return plt;\n\ndef plotWordCloud(number_of_topics,model_topics):\n    if(number_of_topics>10):\n        number_of_topics = 10\n    N_rows = int(number_of_topics\/2)\n    N_cols = int(2)\n    i = 0\n    #Word cloud\n    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n\n    cloud = WordCloud(background_color='white',\n                  width=2500,\n                  height=1800,\n                  max_words=10,\n                  colormap='tab10',\n                  color_func=lambda *args, **kwargs: cols[i],\n                  prefer_horizontal=1.0)\n\n    fig, axes = plt.subplots(N_rows,N_cols, figsize=(10,10), sharex=True, sharey=True)    \n    for i, ax in enumerate(axes.flatten()):\n        fig.add_subplot(ax)\n        topic_words = dict(model_topics[i][1])    \n        cloud.generate_from_frequencies(topic_words, max_font_size=300)\n        plt.gca().imshow(cloud)\n        plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n        plt.gca().axis('off')\n\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.axis('off')\n    plt.margins(x=0, y=0)\n    plt.tight_layout()\n    plt.show()\n    return plt;","22d748ef":"# Interactive visualizations including Scatterplot and TSNE \n\ndef scatterPlot(df,fileName,topNStr):\n    categoryName = ''\n   \n    if((df[df['SentenceScore'] == 'High']).shape[0] >0):\n        categoryName = 'High'\n    elif((df[df['SentenceScore'] == 'Medium']).shape[0] >0):\n        categoryName = 'Medium'\n    else:\n        categoryName = 'Low'\n    \n    if(len(df.SentenceScore.unique()) >1):\n        corpusOfNsentence = st.CorpusFromPandas(df,category_col=\"SentenceScore\",text_col=topNStr,nlp=nlp_x).build()\n        html = st.produce_scattertext_explorer(corpusOfNsentence,\n                                        category=categoryName,\n                                        category_name=\"Research Papers with \"+categoryName+\" Score\",\n                                        not_category_name='Others',\n                                        width_in_pixels=1000,\n                                        minimum_term_frequency=2,\n                                        transform=st.Scalers.percentile)\n\n        open(fileName, 'wb').write(html.encode('utf-8'))\n        display(IFrame(src=fileName, width = 1800, height=700))\n    else:\n        print('No more than one category to produce scatter plot')\n\ndef tsneplot(df,topNStr):\n    print(topNStr)\n\n    tsne = TSNE(verbose=1, perplexity=5)\n    np.random.seed(2017)\n    texts = df['all_text'].values\n    dictionary2 = corpora.Dictionary(texts)\n    corpus2 = [dictionary2.doc2bow(text) for text in texts]\n\n    ldamodel2 = models.ldamodel.LdaModel(corpus2, id2word=dictionary2, \n                                    num_topics=15, passes=20, minimum_probability=0)\n\n    hm = np.array([[y for (x,y) in ldamodel2[corpus2[i]]] for i in range(len(corpus2))])\n    tsne = TSNE(n_components=2)\n    embedding = tsne.fit_transform(hm)\n    embedding = pd.DataFrame(embedding, columns=['x','y'])\n    embedding['hue'] = hm.argmax(axis=1)\n    \n    output_notebook()\n\n    source = ColumnDataSource(\n            data=dict(\n            x = embedding.x,\n            y = embedding.y,\n            colors = [all_palettes['Category20'][15][i] for i in embedding.hue],\n            title = df.title,\n            year = df.publish_time,\n            Top_Sentences = df[topNStr],\n            SubTask = df.SubTask,\n            url=df.url,\n            alpha = [0.9] * embedding.shape[0],\n            size = [14] * embedding.shape[0]\n        )\n    )\n    hover_tsne = HoverTool(names=[\"final_results\"], tooltips=\"\"\"\n        <div style=\"margin: 10\">\n            <div style=\"margin: 0 auto; width:300px;\">\n                <span style=\"font-size: 12px; font-weight: bold;\">Title:<\/span>\n                <span style=\"font-size: 12px\">@title<\/span>\n                <span style=\"font-size: 12px; font-weight: bold;\">Year:<\/span>\n                <span style=\"font-size: 12px\">@year<\/span>\n                <span style=\"font-size: 12px; font-weight: bold;\">SubTask:<\/span>\n                <span style=\"font-size: 12px\">@SubTask<\/span>\n                <span style=\"font-size: 12px; font-weight: bold;\">URL:<\/span>\n                <span style=\"font-size: 12px\">@url<\/span>\n            <\/div>\n        <\/div>\n        \"\"\")\n    tools_tsne = [hover_tsne, 'pan', 'wheel_zoom', 'reset']\n    plot_tsne = figure(plot_width=700, plot_height=700, tools=tools_tsne, title='Papers')\n    plot_tsne.circle('x', 'y', size='size', fill_color='colors', \n                 alpha='alpha', line_alpha=0, line_width=0.01, source=source, name=\"final_results\")\n\n\n    callback = CustomJS(args=dict(source=source), code=\n    \"\"\"\n    var data = source.data;\n    var f = cb_obj.value\n    x = data['x']\n    y = data['y']\n    colors = data['colors']\n    alpha = data['alpha']\n    title = data['title']\n    year = data['year']\n    size = data['size']\n    for (i = 0; i < x.length; i++) {\n        if (year[i] <= f) {\n            alpha[i] = 0.9\n            size[i] = 7\n        } else {\n            alpha[i] = 0.05\n            size[i] = 4\n        }\n    }\n    source.change.emit();\n    \"\"\")\n\n    layout = column(plot_tsne)\n    show(layout)","dfe2ce27":"# HTML version of scatterplot\n\ndef generate_html_table(df):\n\n    css_style = \"\"\"table.paleBlueRows {\n      font-family: \"Trebuchet MS\", Helvetica, sans-serif;\n      border: 1px solid #FFFFFF;\n      width: 100%;\n      height: 150px;\n      text-align: center;\n      border-collapse: collapse;\n    }\n    table.paleBlueRows td, table.paleBlueRows th {\n      text-align: center;\n      border: 1px solid #FFFFFF;\n      padding: 3px 2px;\n      \n    }\n    table.paleBlueRows tbody td {\n      text-align: center;\n      font-size: 11px;\n      \n    }\n    table.paleBlueRows tr:nth-child(even) {\n      background: #D0E4F5;\n    }\n    table.paleBlueRows thead {\n      background: #0B6FA4;\n      border-bottom: 5px solid #FFFFFF;\n    }\n    table.paleBlueRows thead th {\n      font-size: 17px;\n      font-weight: bold;\n      color: #FFFFFF;\n      border-left: 2px solid #FFFFFF;\n    }\n    table.paleBlueRows thead th:first-child {\n      border-left: none;\n    }\n\n    table.paleBlueRows tfoot {\n      font-size: 14px;\n      font-weight: bold;\n      color: #333333;\n      background: #D0E4F5;\n      border-top: 3px solid #444444;\n    }\n    table.paleBlueRows tfoot td {\n      font-size: 14px;\n    }\n    div.scrollable {width:100%; max-height:150px; overflow:auto; text-align: center;}\n    \"\"\"\n    urlColIdx = df.columns.get_loc('url') \n    titleColIdx = df.columns.get_loc('title')\n    pubColIdx = df.columns.get_loc('publish_time')\n    \n    doc, tag, text, line = Doc().ttl()\n\n    with tag(\"head\"):\n        with tag(\"style\"):\n            text(css_style)\n\n\n    with tag('table', klass='paleBlueRows'):\n        with tag(\"tr\"):\n            for col in list(df.columns):\n                if(col not in ('url')):\n                    with tag(\"th\"):\n                         with tag(\"div\", klass = \"scrollable\"):\n                            text(col)\n                        \n        for idx, row in df.iterrows():\n            with tag('tr'):\n                for i in range(len(row)):\n                    if(i==titleColIdx):                       \n                        with tag('td'):\n                            with tag(\"div\", klass = \"scrollable\"):                            \n                                if \"http\" in row[urlColIdx]:\n                                    with tag(\"a\", href = str(row[urlColIdx])):\n                                        text(str(row[i]))\n                                else:\n                                    text(str(row[i]))\n                    elif(i==pubColIdx):\n                        with tag('td'):\n                            with tag(\"div\", klass = \"scrollable\"):                           \n                                if(row[i]==\"1900\"):\n                                    text(\"Not Available\")\n                                else:\n                                    text(str(row[i]))\n                    elif(i==urlColIdx):\n                        None\n                    else:\n                        with tag('td'):\n                            with tag(\"div\", klass = \"scrollable\"):                            \n                                text(str(row[i]))\n\n    display(HTML(doc.getvalue()))","d2016d14":"# This section is where we list text from the questions related to Task 9 of the COVID-19 challenge.\n# Since Task 9 has multiple sub-questions, each is comma delimited so we can identify best responses for each individually.\n\ntask9_keywords = [\"testing covid-19 sars-cov-2 coronavirus studies lab testing pandemic research data collection data standards nomenclature data gathering 2019-nCov SARS MERS\",\n\"coronavirus insurance companies hospitals emergency room schools nursing homes workplaces covid-19 sars-cov-2 state officials local officials mitigation strategies telehealth colleges universities 2019-nCov MERS\",\n\"coronavirus COVID19 COVID-19 SARS-CoV-2 at-risk  Understanding mitigating barriers information-sharing information sharing   information source insight discernment recognition shackles constraints hindrances impediments obstacles\",\n\"coronavirus COVID19 COVID-19 SARS-CoV-2 recruit support coordinate local non-Federal expertise capacity relevant public health emergency response public private commercial non-profit academic\",\n\"2020 2019 SARS-CoV-2 surveillance trace contact transmission public state interview evaluation monitor address interview symptoms\",\n\"2020 2019 SARS-CoV-2 capacity interventions actionable prevent prepare funding investments financing public government future potential\",\n\"aging population COVID19 Novel 2019 COVID-19 SARS-CoV-2 at-risk communication medical professionals critical workers relaying information social media\",\n\"COVID19 Novel 2019 COVID-19 SARS-CoV-2 at-risk conveying information mitigation measures child care advice parents families children communications transparent protocol measures mitigation\",\n\"risk disease population communications Coronavirus SARS-CoV-2 2019-nCov COVID-19 COVID19 COVID messaging notification contagion\",\n\"misunderstanding containment mitigation misinterpretation regulation COVID-19 SARS-CoV-2 pathogens epidemiology coronavirus disease COVID19 2019\",\n\"Action plan mitigate gaps problems inequity public health capability capacity funding citizens needs access surveillance treatment COVID19  2109 COVID-19 SARS-CoV-2\",\n\"2020 2019 COVID-19 traditional approaches community-based interventions digital Inclusion develop local response ensuring communications marginalized disadvantaged populations research priorities\",\n\"2020 2019 COVID-19 prison correctional federal state local inmate jail sheriff officer facility non-violent offenders guards deputy penal authorities locked incarcerated security custody\",\n\"2020 2019 COVID-19 benefit patient client rejection insurance coverage care consultation eligibility plan risk factors policy therapy treatment payment in-network out-of-network deductible\"]","4b8964d7":"task9 = [\"1. Methods for coordinating data-gathering with standardized nomenclature.\",\n\"2. Sharing response information among planners, providers, and others.\",\n\"3. Understanding and mitigating barriers to information-sharing.\",\n\"4. How to recruit, support, and coordinate local (non-Federal) expertise and capacity relevant to public health emergency response (public, private, commercial and non-profit, including academic).\",\n\"5. Integration of federal\/state\/local public health surveillance systems.\",\n\"6. Value of investments in baseline public health response infrastructure preparedness\",\n\"7. Modes of communicating with target high-risk populations (elderly, health care workers).\",\n\"8. Risk communication and guidelines that are easy to understand and follow (include targeting at risk populations\u2019 families too).\",\n\"9. Communication that indicates potential risk of disease to all population groups.\",\n\"10. Misunderstanding around containment and mitigation.\",\n\"11. Action plan to mitigate gaps and problems of inequity in the Nation\u2019s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment.\",\n\"12. Measures to reach marginalized and disadvantaged populations. Data systems and research priorities and agendas incorporate attention to the needs and circumstances of disadvantaged populations and underrepresented minorities.\",\n\"13. Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment.\",\n\"14. Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care\"]","e51f0559":"dict_task=dict(zip(task9,task9_keywords))","dca7ce99":"final_dict = {}\n#header_dict = {'': '','All': 'All'}\nheader_dict = {'All': 'All'}\nfinal_dict = dict(header_dict, **dict_task)","c126052a":"# Function that finds most relevent articles and sentences for a given input text. \n\ndef bm25res(tcount,visualization):\n    print('\\033[1m' + '*********************************Start*****************************************')\n    print('\\033[1m' + 'Subtask: ' + task9[tcount] + '\\n') \n    \n    bm25_results = bm25_index.search(task9_keywords[tcount],n=covid_df.shape[0])\n    bm25_df = bm25_results.getDf()\n    \n    bm25_score = bm25_df['BM25_Score'].sort_values(ascending=False).tolist()\n    #print('Max BM25 Score = ',bm25_df['BM25_Score'].max())\n    print('\\033[1m' + 'BM25 Score Selection')\n    bm25_x_idx = range(1, len(bm25_score)+1)    \n    bm25_kn = KneeLocator(bm25_x_idx, bm25_score,curve='concave',direction='decreasing',online=True)\n    #optimal_bm25_score ,kn_bm25= kneeLocator(bm25_x_idx,bm25_score)\n    optimal_bm25_score = bm25_score[bm25_kn.knee-1]\n    \n    covid_df_bm25_filter =bm25_df[bm25_df['BM25_Score'] >=optimal_bm25_score]\n    \n    if (covid_df_bm25_filter.shape[0] <10):\n        covid_df_bm25_filter= bm25_df.iloc[:25,:]\n\n    print('\\033[1m' + 'Number of Papers Selected after BM25 Scoring = ', covid_df_bm25_filter.shape[0])        \n    docs = covid_df_bm25_filter.all_text\n    dictionary = Dictionary(docs)\n    if(len(docs)<10):\n        dictionary.filter_extremes(no_below=1)\n    else:\n        dictionary.filter_extremes()\n    #Create dictionary and corpus required for Topic Modeling\n    corpus = [dictionary.doc2bow(doc) for doc in docs]\n    noOfDocs = len(corpus)\n    start_num_topics = 0\n    step_num_topics = 2\n    if(noOfDocs>=200):\n        noOfMaxTopics = int(noOfDocs*0.1)\n        if(noOfMaxTopics>100):\n            noOfMaxTopics = 100\n        start_num_topics = 5\n        step_num_topics = 5\n    elif(noOfDocs>=50 and noOfDocs<200):\n        noOfMaxTopics = 20\n        start_num_topics = 2\n        step_num_topics = 2\n    else:\n        noOfMaxTopics = 10\n        start_num_topics = 2\n        step_num_topics = 2\n    #print('Number of unique tokens: %d' % len(dictionary))\n    #print('Number of documents: %d' % noOfDocs)\n    #print('Number of max topics: %d' % noOfMaxTopics)\n    print('\\033[1m' + 'Finding Optimal of topics is in progress = ',noOfMaxTopics)\n    model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=docs, start=start_num_topics, limit=noOfMaxTopics, step=step_num_topics)\n    optimal_model, model_topics, number_of_topics, temp_coherenace= findOptimalTopicModel(start_num_topics, noOfMaxTopics, step_num_topics, model_list, coherence_values)\n    print('\\033[1m' + 'Optimal Number of Topics = ',number_of_topics)\n    print('\\033[1m' + 'Coherence Score = ', temp_coherenace)\n    \n    df_topic_sents_keywords = format_topics_sentences(covid_df_bm25_filter,ldamodel=optimal_model, corpus=corpus, texts=docs)\n    df_dominant_topic = df_topic_sents_keywords.reset_index()\n    \n\n    topicPercContrib = df_dominant_topic.Topic_Perc_Contrib.sort_values(ascending=False).tolist()    \n    print('\\033[1m' + 'Dominant Score Selection')\n    topic_contrib_x_idx = range(1, len(topicPercContrib)+1)    \n    topic_kn = KneeLocator(topic_contrib_x_idx, topicPercContrib,curve='concave',direction='decreasing',online=True)\n    \n    #optimal_topic_score,kn_topic = kneeLocator(topic_contrib_x_idx ,topicPercContrib)\n    \n    \n    #optimal_bm25_score = bm25_score[bm25_kn.knee-1]\n    optimal_topic_score = topicPercContrib[topic_kn.knee-1]\n    \n    dominant_topic_filtered_df = df_dominant_topic[df_dominant_topic['Topic_Perc_Contrib']>=optimal_topic_score]\n    \n    print('\\033[1m' + 'Number of Papers Selected after Dominant Topic Scoring = ', dominant_topic_filtered_df.shape[0])    \n    \n    topNStr = 'Top_'+str(top_N_sentence)+'_Sentence'\n        \n    title_body_str = dominant_topic_filtered_df.title.fillna('') +' ' + dominant_topic_filtered_df.body.fillna('')\n    dominant_topic_filtered_df['title_body_clean'] = title_body_str.apply(clean_text).to_frame()\n\n    sentence_embed_df = dominant_topic_filtered_df.title_body_clean.apply(sentenceEmbed,args=[tcount])\n    dominant_topic_filtered_df[['Top_3_Sentence',topNStr,'SentenceScore']] = pd.DataFrame(sentence_embed_df.to_list(), columns=['Top_3_Sentence',topNStr,'SentenceScore'], index=sentence_embed_df.index)    \n    dominant_topic_filtered_df = dominant_topic_filtered_df.sort_values(by=['SentenceScore'], ascending=False)      \n    \n    results = dominant_topic_filtered_df[['paper_id','title',topNStr,'Top_3_Sentence','SentenceScore','publish_time','url','all_text']]    \n    \n    if(visualization):\n        finalfig, finalaxis = plt.subplots(1,3,figsize=(20,5))\n        plotKnee(bm25_kn,bm25_x_idx,bm25_score,min(bm25_score),max(bm25_score),'BM25 Doc#','BM25 Score',finalaxis,0)\n        plotCoherence(start_num_topics, noOfMaxTopics, step_num_topics,coherence_values,finalaxis,1)\n        plotKnee(topic_kn,topic_contrib_x_idx,topicPercContrib,min(topicPercContrib),max(topicPercContrib),'Topic Doc ID','Topic % Contribution',finalaxis,2)\n        plt.show()\n        print('\\033[1m' + '\\nTop N Topics Word Cloud' + '\\033[0m')\n        plotWordCloud(number_of_topics,model_topics)\n\n    print('\\033[1m' + 'Final Number of Papers Selected = ', results.shape[0])\n    print('\\033[1m' + 'Subtask: ' + task9[tcount] + '\\n')\n    print('\\033[1m' + '*********************************Completed*****************************************')\n    return results;","2caef649":"def run_task(val):\n    tcount = list(dict_task.values()).index(val)\n    #taskscount=len(task9)\n    # taskscount=1\n    # tcount = 0\n    visualization=False\n    taskResults = pd.DataFrame(columns=[])\n    #for tcount in range(taskscount):\n    fileName = task9[tcount]\n    results = bm25res(tcount, visualization)\n        #results.to_csv(fileName + '.csv', index=False)   \n        #scatterPlot(results,fileName+'.html','Top_'+str(top_N_sentence)+'_Sentence')\n    temp = results\n    temp['SubTask'] = fileName\n    temp['SubTask'] = temp.SubTask.fillna(fileName)\n    taskResults = taskResults.append(temp)\n    taskResults =taskResults.reset_index(drop=True)\n    final_visualization(taskResults)\n    \ndef run_task_all():\n    taskscount=len(task9)\n    # taskscount=1\n    # tcount = 0\n    visualization=False\n    taskResults = pd.DataFrame(columns=[])\n    for tcount in range(taskscount):\n        #fileName = 'task9_subtask_' + str(tcount)\n        fileName = task9[tcount]\n        results = bm25res(tcount, visualization)\n            #results.to_csv(fileName + '.csv', index=False)    \n            #scatterPlot(results,fileName+'.html','Top_'+str(top_N_sentence)+'_Sentence')\n        temp = results\n        temp['SubTask'] = fileName\n        temp['SubTask'] = temp.SubTask.fillna(fileName)\n        taskResults = taskResults.append(temp)\n    taskResults =taskResults.reset_index(drop=True)\n    final_visualization(taskResults)\n\ndef final_visualization(taskResults):\n    topNColumnName = 'Top_'+str(top_N_sentence)+'_Sentence'\n    taskResults.fillna('',inplace=True)\n    #taskResults.to_csv('all_task_final_output.csv', index=False)\n    scatterPlot(taskResults,'Task9_Scatterplot.html',topNColumnName)\n    tsneplot(taskResults,topNColumnName)\n    taskResults['publish_time'] = taskResults['publish_time'].astype(str)\n    generate_html_table(taskResults[['SubTask','title','Top_3_Sentence','publish_time','url']])","03d639b6":"#Runs all the sub tasks for the task 9\nrun_task_all()","35e96c66":"#Enable the below code to run using drop down menu\n\n@interact\ndef drop_down(x=final_dict):\n    dropdown=list(final_dict.keys())[list(final_dict.values()).index(x)]\n    '''if x == '':\n        print ('')\n    elif x == \"All\":'''\n    if x == \"All\":\n        run_task_all()\n    else: \n        run_task(x)\n    return dropdown","2efca0dc":"# <center> CORD-19 Challenge\n# <center> TASK 9\n    \n![Task%209%20banner.JPG](attachment:Task%209%20banner.JPG)\n    \n## The Critical Challenge\nThe 2019 novel coronavirus (COVID-19) has caused a public health crisis across the U.S. and around the world. The number of related research publications is increasing at a rapid pace and consequently, the best practices on how to address the COVID-19 crisis are quickly evolving. \nHow do medical communities, researchers, and health care policy makers quickly and easily find the most current and accurate research related to intersectoral collaboration and information sharing regarding COVID-19, so that they can focus their valuable time on developing protocols, policies, and vaccines to address the crisis?\n\n## Summary of our Solution\nThis notebook provides an AI-powered literature review of CORD-19 (COVID-19 Open Research Dataset) focused on the question of \u201cwhat has been published about information sharing and intersectoral collaboration?\u201d We have developed an Intelligent Publication Retrieval Engine (IPRE) using NLP text and data mining methods to generate four interactive ways for users to quickly and easily locate the most relevant articles that address intersectoral collaboration and information regarding COVID-19. The results are dynamic to provide the most current publications from the current contents of CORD-19 with regard to these sub tasks:\n    \n* Methods for coordinating data-gathering with standardized nomenclature.\n* Sharing response information among planners, providers, and others.\n* Understanding and mitigating barriers to information-sharing.\n* How to recruit, support, and coordinate local (non-Federal) expertise and capacity relevant to public health emergency response (public, private, commercial and non-profit, including academic).\n* Integration of federal\/state\/local public health surveillance systems.\n* Value of investments in baseline public health response infrastructure preparedness\n* Modes of communicating with target high-risk populations (elderly, health care workers).\n* Risk communication and guidelines that are easy to understand and follow (include targeting at risk populations\u2019 families too).\n* Communication that indicates potential risk of disease to all population groups.\n* Misunderstanding around containment and mitigation.\n* Action plan to mitigate gaps and problems of inequity in the Nation\u2019s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment.\n* Measures to reach marginalized and disadvantaged populations.\n* Data systems and research priorities and agendas incorporate attention to the needs and circumstances of disadvantaged populations and underrepresented minorities.\n* Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment.\n* Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care\nWe have developed an Intelligent Publication Retrieval Engine (IPRE) using NLP text and data mining methods to generate four interactive ways for users to quickly and easily locate the most relevant articles that address intersectoral collaboration and information regarding COVID-19. The results are dynamic to provide the most current publications from the current contents of CORD-19.\n\n## Summary of Key Insights from Our Solution\n\nAs part of our validation process, each team member reviewed the responses to each of the subtasks. Here are some of the insights we gleaned from our validation of the most relevant articles on intersectoral collaboration and information. These are key sentences from the highest ranking articles resulting from our Intelligent Publication Retrieval Engine (IPRE):\n    \n_WeChat Chinese social network platform is used by IMWs in Hong Kong and Macau  for sharing key health messages and    official information to the community and providing one another with emotional support_\n     \n_However the power of community might prove to be crucial during this epidemic. Family elders and religious leaders have major role as health-care providers for both adult and adolescent members of the African NORP community.\nAfrican NORP migrants residing in Wuhan Hubei GPE province-the epicenter of the outbreak-might be more worried than ever. Community unity is the primary strategy in coping with barriers to health care-eg the Ghanaian NORP community in Guangzhou GPE Guangdong GPE province made monetary donations and arranged health care for their community. \nAfrican NORP community organisations also compile and manage information about visits of health-care providers from Africa LOC for their members and encourage these visiting specialists to informally consult on voluntary basis_\n\n## Notebook Contents\nThe remainder of this notebook includes:\n* **Our Overall Approach**\n* **Pros and Cons of Our Approach**\n* **Our Solution: Code and Results**\n* **Acknowledgement and Licenses**\n\n## Our Overall Approach\nBecause the volume of text available in the COVID-19 dataset is so large and spans such a wide scope of topics, we used a multi-step, iterative approach to find the most relevant articles and make them available in an easy way to quickly bring current and critical information to serve the needs of our healthcare and research communities.\nThe picture below shows the overall process we used to develop our solution. A detailed description of each step follows the picture.\n\n![Overall%20Process%20Updated.jpg](attachment:Overall%20Process%20Updated.jpg)\n\n### Summary of Approach\n1. We started by preparing the COVID-19 dataset for efficient processing and analysis. This included consolidating data sources, keeping the most relevant columns of data, and then cleansing the data for easier analysis and input to the data models.\n2. Next, we minimized the number of articles to analyze by eliminating those that were not relevant to the subtasks on which we were focused. \n3. From there, we identified the dominant topics across the subtasks and used them to identify the most relevant articles for each sub task\n4. Lastly, we identified the top three sentences across the top ranked articles to provide an important and quick glimpse into the relevancy of the articles relative to the sub tasks.\n5. We display the responses to the sub tasks in four interactive ways. Two are shown here:\n\n    **Scatter Plot** -- A scatter plot is an interactive way to find top sentences from relevant articles that are responses to the subtasks.\n    We show the results in three categories 'High', 'Medium' and 'Low' based on their scores. We then compare the resulting text between the 'High' category of articles to the rest. \n   * The ScatterTextPlot shows the frequency of words between these two categories within four quadrants on the plot. \n   * The upper left corner are words that were found frequently in 'High' scoring articles, but not so much in others i.e. 'Medium' and 'Low'. \n   * In the lower right corner are words occurring frequently in lower scoring articles. \n   * The bottom left corner are words infrequent in both sets of articles.\n   * You can also use the Scatter Plot to get responses based on key word searches. You can search for any word or simply click a word on the plot and immediately see the exact sentences where those words are part of the articles. For example, in the Search bar, you could search for the text 'Information' and it would auto complete with any further words it found in the articles, like ' Information sharing'. \n   * The search results will show all sentences where 'Information sharing' is mentioned. \n     Here is an actual result related to \"Geographic Location\" in the context of the overall sub task about information sharing:\n                                          \n![Scatter2_1.gif](attachment:Scatter2_1.gif)\n   \n    \n    \n*    **t-SNE Plot** (T-distributed Stochastic Neighbor Embedding) \u2013 The dominant topics related to the subtasks are clustered together. You can click on a topic to see related articles. If you find one article to be relevant to a topic, you can then choose to see other articles that address that topic. \n        Here is an actual result that shows a cluster of articles on the same search text. Hovering above any of the dots displays the information about that article.\n\n        \n![TSNE1.JPG](attachment:TSNE1.JPG)\n        \n    \n    \n\n### 1. Prepare the Dataset for Processing\nAs with any data analysis project, the first step is to clean the data to eliminate unnecessary words and punctuation and remove any data not needed for the final solution for more efficient and accurate processing and model input, which included:\n* **Reducing the size of source datasets** to include only the data needed for final output\n     * Integrating directly with Kaggle APIs to download latest available dataset and parse it to import it to our processes so that we have one csv dataset that includes all of what we need to make the most relevant articles available for each sub task.\n     * Bringing together all of the json files, which contain the articles, with meta data from downloaded datasets and convert it to one csv file.\n     * Opening each JSON file (containing one article) and extract the valuable text from it so we have all of the data in one place, including:\n        *   Dropping duplicate rows based on title, author, etc. \n        *   Dropping duplicate columns \u2013 keeping 22 columns containing the most needed data for the final solution to save on processing time \n        *   Merging all files with meta data (publish date, author, etc.) based on selected unique fields \n* **Eliminating unneeded data from dataset**\n     *   Removing punctuation, digits, whitespace, stop words (library of words in English that are common words and not relevant to the article) \n     *   Making all words lowercase for exact matching of words\n     *   Tokenizing words so that each word can be used as an independent entity; each word is a token and additional preprocessing can be done; for example, bigrams and trigrams to breakdown words to be passed into subsequent algorithms\n\n### 2.\tTrain the Model\nOur next step was to find those articles most relevant to the subtasks within Task 9. To do this, we used BM25 (BM=Best Match 25=25th iteration of the computations used within it). BM25 processes all of the text in all of the articles in the source dataset and creates an index of keywords and related articles. This is how BM25 is trained on the COVID-19 data. BM25 ranks the keywords based on the occurrences of keywords found in each article to create a ranked index.\n\n### 3.\tTopic Modeling\nWith a ranked index of articles based on keywords, the next step is to match the most relevant articles to the subtasks. The relevant articles are passed to the LDA Topic Modeling algorithm (latent Dirichlet allocation model). LDA identifies the dominant topics found in those articles. A coherency score is calculated to indicate the degree to which the topic is related to the article.  The higher the score, the greater the relevance. This output is used to create the cluster of articles by dominant topics shown in the t-SNE plot as one of the four responses to the subtasks. \n\n### 4. Sentence Smoothing\nTo provide deeper insight into the top ranked articles for each subtask, we used a trained lanuguage model, BERT (Bidirectional Encoder Representations from Transformers), to provide the top three sentences from among the short list of most relevant articles to give the user more specific information about the contents of the most relevant articles for each subtask.\n\n# Pros and Cons of the Approach\n**Pros**\n* Our approach provides visual and interactive ways to quickly see key information about relevant publications and articles for multiple subtasks and provides the opportunity to go directly to the source, when the user wants to see more detailed information.\n* The use of t-SNE plots and Wall charts provide two different ways to quickly see clusters of keywords and their relationships among other high value and low frequency topics again, with the opportunity to go directly to the source for more detail.\n* Providing the top three sentences of the top ranked articles for each sub task gives a quick glimpse to see if the publication is releant for the users' need\n\n**Cons**\n* Our approach uses a fixed set of keywords to identify key insights from the articles in relation to a sub task. This method could possibly exclude other relevant insights.\n* We chose to start our approach by using the TF-ID word frequency model to create clusters of articles to find those related to our task 9 subtasks so we could then focus on that cluster of articles.\n* We quickly saw that no clear clusters were formed. With 35,000 plus articles, there were not enough relationships among the keywords from the articles to form clear clusters.\n* Our new focus was on how to filter or shrink the number of articles to work with to just those relevant to our subtasks. \n* With a reduced number of articles to work with, it became easier to focus on getting unique topics and sentences to provide relevant responses to the subtasks. However, this could also exclude relevant insights from articles filtered out.\n","02643b7e":"# Step 5: Identify articles based on dominant topics\nNow that we have retrieved a smaller set of articles related to our sub task, we further analyze the text in these articles to find dominant topics.\nWe use LDA as a topic modeling technique to identify topics from each article and then measure the dominant effect of the topic using coherence measures. \nThis enables the ranking of articles based on the highly dominant topics. The ones that score high are then extracted for the next stage of analysis.\n\n## LDA technique for topic modelling\n\nWe use LDA to obtain a list of topics for each article. \nLDA is an unsupervised technique, meaning that we don\u2019t know prior to running the model how many topics exist in our corpus.\n\n![LDA.JPG](attachment:LDA.JPG)\n\n## Coherence score\nTopic coherence is a technique used to estimate the number of topics. \nTopic coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. \nThese measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.  \n\nWe use c_v measure to see the coherence score of our LDA model. \nC_v measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity.\nC_V measure typically has values 0 < x < 1\n\n\n## Rank articles with dominant topics\nThe last step is to find the optimal number of topics. We run the LDA model with different values of the number of topics (k) and pick the one that gives the highest coherence value. Choosing a \u2018k\u2019 that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics. If you see the same keywords being repeated in multiple topics, it\u2019s probably a sign that the \u2018k\u2019 is too large.\n\n![Coherence_score.JPG](attachment:Coherence_score.JPG)","617fe12c":"# Step 2: Extract text from each article\n\nWe will use the text in the abstract and body of each research article to perform our analysis.\n\n## Steps performed on each article.\n- The extracted text is appended as a column to the original dataset that is loaded using standard pandas functions.\n- The updated dataset is then saved as a csv file.\n- Duplicate articles are removed, if the Document ID and title match between two or more articles.\n- Valuable information from the meta data file is added to the dataframe eg. Publish date of the article.\n- Duplicate columns between the JSON files and meta data are dropped and column headers renamed.","3c88bf8e":"The text is specific to each sub task in Task 9.\n\nIf you are not much of a visual person, then this section may help. \n\nWe put together the top three senteces found in the top articles related to each sub task. \n\nThese sentences are derived from the various algorithms and calculations performed in the code and is our best match effort to answer the sub tasks.","0b2d5622":"# Step 4: Identify relevant articles based on the BM25 algorithm\n\n![BM25_1.JPG](attachment:BM25_1.JPG)","d0f5dec0":"In this step, the covid_task9_bm25index.pkl, which contains the BM25 index file, is run.\nIt uses the BM25 index created on April 15th so that you can use the solution without rebuilding the BM25 index from the latest covid-19 dataset.\nIf the latest dataset needs to be analyzed, set rebuild_index = True","6f828774":"%%time\nbm25_index = RankBM25Index(covid_df)\nprint(\"Shape of BM25: \", bm25_index.corpus.shape)","bdb753ba":"We display the results in multiple ways.\n\n## ScatterTextPlot\n\n**What is a ScatterTextPlot?**\n\nIt is an interactive tool to visually represent high frequency words found in the most relevent articles.\n\n**What does it do?**\n\nWe split the results into three categories 'High', 'Medium' and 'Low' based on their scores. We then compare the resulting text between the 'High' category of articles versus the rest.\n\nThe ScatterTextPlot shows the frequency of words between these two categories within four quadrants on the plot. The upper left corner are words that were found frequently in 'High' scoring articles, but not so much in others i.e. 'Medium' and 'Low'. They are likely to be rare and unique finds of high value text. The vice versa holds true for the lower right corner. These are words occuring frequently in lower scoring articles. They also are unique but probably not so rare as they occur in many lower ranked articles.\n\nThe bottom left corner are words infrequent in both sets of articles and may not be worth looking into. We say that, but you never know what you might find, so do check them out. The top right corner are words found frequently in both sets. As you may imagine, a lot of common English words may show up. If you skip past them, you may find words that are highly relevant and have a high frequency of occurrences in all articles.\n\n**How do I use the ScatterTextPlot?**\n\nYou can search for any word or simply click a word on the plot and immediately see the exact sentences where those words were part of in the articles. For example, in the Search bar, you could search for the text 'Public' and it would auto complete with any further words it found in the articles, like ' Public health'. The search results will show all sentences where 'Public health' is mentioned.\n\nSimilarly, you could find patterns in the words displayed on the plot. The closeness of words is based on how frequently they are mentioned in articles. Simply clicking any of the words will show all sentences found in both category of articles.\n\nThis method can be used to get answers based on key word searches.\n\n## t-SNE Plot\nWe group together articles that are talking about the same topics. These are topics we extracted based on relevance of the words found in the articles.\n\nThe t-SNE plot shows these clusters of articles in different colors. Hovering above any of the circles shows information about that article.\n\nThese clusters can be used to find a group of articles that may be related and have relevent information about a given sub task in Task 9.\nHow far (or close) each cluster is from the other also shows the relative similarity between the different topics.","17645d93":"**Ericsson, the world\u2019s leading telecommunications company, cares about doing good. This task was completed as part of our Ericsson for Good program, which allows our 90,000+ employees to contribute to their communities.**\n\n\u00a9 This Notebook has been released under the OSI-approved GNU LGPLv2.1 license; Google BERT is under Apache License 2.0 (https:\/\/github.com\/google-research\/bert\/blob\/master\/LICENSE); Facebook\u2019s fairseq is under MIT license: https:\/\/github.com\/pytorch\/fairseq\/blob\/master\/LICENSE","e62ac847":"# Step 1: Collect COVID-19 articles from Kaggle\n\nThe latest allen-institute-for-ai\/CORD-19-research-challenge dataset from Kaggle is pulled using the Kaggle API. \nTo perform this, a Kaggle account is required.\nThe process involves building a data extraction pipeline, where data is pulled from four source directories and a metadata file.\nHere are the files:\n- BIORXIV_MEDRXIV\n- COMMON_USE_SUB\n- NON_COMMON_USE_SUB\n- CUSTOM_LICENSE\n- metadata.csv","770dd4ce":"# Step 3: Pre-process the data\nBefore we start our analysis on the dataset, we perform steps to prepare the data in the ALL_TEXT column so that it is better suited for text analysis. \n\n## Data cleasing steps\n- Remove digits and punctuations\n- Remove common English stop words eg. The, at, on etc\n- Remove words that are 3 characters or less in length\n- Replace white space characters\n- Replace special characters eg. |,:,> etc.\n- Make all text Lower case\n- Tokenize each sentence into a list of words.\n- Capture Bi-grams and Tri-grams:\n    Bigrams are two words frequently occurring together in the document. Trigrams are three words frequently occurring. \n    Some examples in our example are: \u2018back_bumper\u2019, \u2018oil_leakage\u2019, \u2018maryland_college_park\u2019 etc.","65e08a4f":"# Step 6: Find top N sentences from relevant articles\n\nWe use the BERT Sentence_Transformer, which has been pre-trained on Natural Language Inference (NLI) data to extract the top N sentences that have the most relevence. \n\nWe feed BERT with the sub task text and the articles filtered from the previous step, to find relevant responses.\n\nThe result is a ranked set of articles with the top scores and the top sentences found within the article relevant to the sub task.\n\n![BERT3.JPG](attachment:BERT3.JPG)\n\n\n\n## Steps in our approach\n- Pass the ALL_TEXT data from each of the filtered articles \n- Get contextualized embedding from a pretrained BERT which was fine-tuned on Natural Language Inference (NLI) data \n- Apply contextualized embedding on the text of the sub task\n- Apply cosine similarity on both the ALL_TEXT and the sub task text, to get the most similar sentences along with the articles of these sentences\n","5583443c":"# Step 7: Optimize results based on Elbow and Knee cut-off methods\n\nWe added steps to measure the effectiveness of the results and further trim the results based on certain cut-off criteria. \n\nThese methods are used to trim the resulting articles from BM25 and LDA to further optimize the results.\n\n## BM25 optimization using elbow cut-off\n\nThe results from BM25 are further optimized by plotting the BM25 score against each article ranked in descending order. \n\n![BM25_elbow.JPG](attachment:BM25_elbow.JPG)\n\nThe resulting plot has an elbow shape. The elbow joint shows the cut-off where articles having a lower score than the cut-off can be ignored.\n\nWe use this method to further trim the results of BM25\n\n## LDA optimization using knee cut-off\nThe topic modeling scores for each article are plotted in order to determine the optimum number of topics to consider. \n\n![Dominant_Topic.JPG](attachment:Dominant_Topic.JPG)\n\nThe results has a knee shape where the relevance of topics drops off after a certain number of topics within an article.\n\nThis drop-off point is used to determine the optimum number of topics to consider.","5f96781d":"# Step 9: Execute\n\nThis is where the magic happens. For those who want to use our code, this is the section where you choose the sub task for which you want responses, and let the code run. You could either choose the \"All\" option, which will identify answers for all 15 sub tasks that are part of Task 9, or specify a single sub task.\n\nThe results are provided in four different ways:\n- Relevant sentences from relevant articles that best answer each question\n- A scattertextplot which is an interactive way to view and search for key words and sentences from the resulting articles\n- A t-SNE plot that shows how articles are clustered together based on the topics found relevent for a sub task\n- A Word wall that highlights the most frequent words showing in the resulting articles.\n","f269c6d1":"# Packages used within the scope of this analysis","3eada1e9":"# Step 8: Call all functions \n\nThis is where all the ingredients are brought together for execution. \n\n1. We list text from the sub tasks related to Task 9 of the COVID-19 challenge. Since Task 9 has multiple sub tasks, each is comma delimited so we can identify best responses for each one separately.\n\n2. We define a function that can be called by providing the text of a sub task. It returns a list of articles and sentences that are found to have the most relevant answers."}}