{"cell_type":{"ef4f8112":"code","c8315e7d":"code","6fb46880":"code","599e4cdb":"code","69fd7b42":"code","7898a522":"code","452243ee":"code","30a5ef6c":"code","0e83fe6e":"code","ccd09142":"code","d28cb8a3":"code","2e59c0e2":"code","3dfb351c":"code","1739be8b":"code","0744a162":"code","530fe2ab":"code","db4c06d4":"code","32525e6a":"code","b11cf08f":"code","e796bf95":"code","63dc7ccc":"code","37bde80a":"code","6366f604":"code","9cd0e4f3":"code","82b5c422":"code","13f2c91d":"code","ceae4703":"code","3323bb0f":"code","4766bfbb":"code","d13c7e1b":"code","b7b2901d":"code","5bf7252c":"code","23fe9e93":"code","c0b471cd":"markdown","71a01fa6":"markdown","73c975ac":"markdown"},"source":{"ef4f8112":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8315e7d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\nfrom xgboost import XGBRegressor\n\nfrom catboost import CatBoostRegressor\nfrom catboost import Pool\n\nimport datetime\nfrom datetime import datetime","6fb46880":"def parser(x):\n    return datetime.strptime(x, '%d\/%m\/%y')","599e4cdb":"train = pd.read_csv('\/kaggle\/input\/train.csv', parse_dates = [1], date_parser = parser)\ntrain = train.drop('record_ID', axis = 1)\ntest = pd.read_csv('\/kaggle\/input\/test.csv', parse_dates = [1], date_parser = parser)\ntest_ID = test.record_ID\ntest = test.drop('record_ID', axis = 1)\n\ntrain.loc[(train['total_price'].isnull()), 'total_price'] = train.loc[(train['total_price'].isnull()), 'base_price'].values[0].astype(float)\n\ntrain['quarter'] = train['week'].dt.quarter\ntrain['year'] = train['week'].dt.year\ntrain['month'] = train['week'].dt.month\ntrain['date'] = train['week'].dt.day\ntrain['week_day'] = train['week'].dt.dayofweek\ntrain['is_weekend'] = np.where(train['week'].isin([5, 6]), 1, 0)\ntrain['is_weekday'] = np.where(train['week'].isin([0, 1, 2, 3, 4]), 1, 0)\n\ntest['quarter'] = test['week'].dt.quarter\ntest['year'] = test['week'].dt.year\ntest['month'] = test['week'].dt.month\ntest['date'] = test['week'].dt.day\ntest['week_day'] = test['week'].dt.dayofweek\ntest['is_weekend'] = np.where(test['week'].isin([5, 6]), 1, 0)\ntest['is_weekday'] = np.where(test['week'].isin([0, 1, 2, 3, 4]), 1, 0)","69fd7b42":"train.head()","7898a522":"train.info()","452243ee":"test.info()","30a5ef6c":"train.head()","0e83fe6e":"plt.figure(figsize = (16, 7))\nsns.lineplot(train['week'], train['units_sold'])","ccd09142":"plt.figure(figsize = (16, 7))\nsns.barplot(train['store_id'], train['units_sold'])\nplt.xticks(rotation = 90)\nplt.show()","d28cb8a3":"train.loc[(train['total_price'].isnull()), 'total_price'] = train.loc[(train['total_price'].isnull()), 'base_price'].values[0].astype(float)\nplt.figure(figsize = (16, 7))\nsns.lineplot(train['total_price'], train['units_sold'])\nsns.despine()","2e59c0e2":"plt.figure(figsize = (16, 7))\nsns.barplot(train['sku_id'], train['units_sold'])\nplt.xticks(rotation = '90')\nplt.show()","3dfb351c":"plt.figure(figsize = (16, 7))\nsns.lineplot(train['store_id'], train['units_sold'])\nplt.xticks(rotation = '90')","1739be8b":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'units_sold', data = train)\nsns.despine()","0744a162":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'total_price', y = 'units_sold', data = train)\nplt.show()","530fe2ab":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'base_price', y = 'units_sold', data = train)\nplt.show()","db4c06d4":"plt.figure(figsize = (16, 7))\nsns.jointplot(x = 'store_id', y = 'units_sold', data = train)","32525e6a":"plt.figure(figsize = (16, 7))\nsns.boxplot(x = 'sku_id', y = 'units_sold', data = train)\nplt.xticks(rotation = 90)\nplt.show()","b11cf08f":"print(\"Total number of stores : \", train['store_id'].nunique())","e796bf95":"store_sku_train = (train['store_id'].astype(str) + \"_\" + train['sku_id'].astype(str)).unique()\nprint(\"There are\", len(store_sku_train), \"store-product pairs in train data\")","63dc7ccc":"store_sku_test = (test['store_id'].astype(str) + \"_\" + test['sku_id'].astype(str)).unique()\nprint(\"There are\", len(store_sku_test), \"store-product pairs in test data\")","37bde80a":"# check if test set has any new center-mean pair or not\nprint(\"There are\",len(set(store_sku_test) - set(store_sku_train)), \"New center-meal pairs in test dataset which are not present in train dataset\")\nprint(set(store_sku_test) - set(store_sku_train))","6366f604":"outlier_index = train[(train['units_sold'] > 1500)].index\ntrain.drop(outlier_index, inplace = True)","9cd0e4f3":"plt.figure(figsize = (12, 10))\nsns.heatmap(train.corr())\nsns.despine","82b5c422":"avg_sku_bp = train[['sku_id', 'base_price']].append(test[['sku_id', 'base_price']])\navg_sku_bp.columns = ['sku_id', 'avg_bp']\navg_sku_bp = avg_sku_bp.groupby(['sku_id'])['avg_bp'].mean()\n\ntrain = pd.merge(train, avg_sku_bp, on = [\"sku_id\"], how = \"left\")\ntrain['bp_fraction'] = train['base_price']\/train['avg_bp']\n\ntest = pd.merge(test, avg_sku_bp, on = [\"sku_id\"], how = \"left\")\ntest['bp_fraction'] = test['base_price']\/test['avg_bp']","13f2c91d":"train['discount'] = train['base_price'] - train['total_price']\ntrain['discount_per'] = (train['discount']\/train['base_price'])*100\ntrain['promo_homepage'] = train['is_display_sku'] + train['is_featured_sku']\ntrain['store_id'] = train['store_id'].astype(np.object)\ntrain['sku_id'] = train['sku_id'].astype(np.object)\n\ntrain = pd.get_dummies(train, drop_first = True)\ntrain = train.drop('week', axis = 1)\n\ntest['discount'] = test['base_price'] - test['total_price']\ntest['discount_per'] = (test['discount']\/test['base_price'])*100\ntest['promo_homepage'] = test['is_display_sku'] + test['is_featured_sku']\ntest['store_id'] = test['store_id'].astype(np.object)\ntest['sku_id'] = test['sku_id'].astype(np.object)\n\ntest = pd.get_dummies(test, drop_first = True)\ntest = test.drop('week', axis = 1)","ceae4703":"train.head()","3323bb0f":"X, y = train.drop(['units_sold'],axis = 1), train.units_sold\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)","4766bfbb":"rf = RandomForestRegressor(n_estimators = 200)\nrf.fit(X_train, y_train)\ntest_pred = rf.predict(X_test)\nprint(100*np.sqrt(mean_squared_log_error(y_test, test_pred)))\n\nprint('RMSLE score is', 100*(np.sqrt(np.mean(np.power(np.log1p(y_test)-np.log1p(test_pred), 2)))))","d13c7e1b":"sorted(zip(rf.feature_importances_, X_train), reverse = True)","b7b2901d":"y_pred = rf.predict(test)","5bf7252c":"submission = pd.read_csv('\/kaggle\/input\/sample_submission.csv')\nsubmission.head()","23fe9e93":"submission = pd.DataFrame({'record_ID': test_ID, 'units_sold': y_pred})\nsubmission.to_csv('RandomForest_final.csv',index = False)\nsubmission.head()","c0b471cd":"#### AV Score: 475.75, Rank: 123  (Jupyter Notebook: 42.80849288634156 - without Quarter and Avg. Base Price,  fraction) - RandomForest_v2.csv","71a01fa6":"#### Feature Engineering","73c975ac":"#### Remove outlier"}}