{"cell_type":{"36e932bd":"code","c727fa47":"code","234e6ccf":"code","2c42e709":"code","72d14f21":"code","96b49f69":"code","bda97fdd":"code","ce4b6285":"code","78268ce8":"code","ed4c21f8":"code","77bbce4f":"code","d4ff806d":"code","036add85":"code","cc543abf":"code","716d85b2":"code","e88600ac":"code","17f0b66c":"code","ddcc5d33":"code","41908e77":"code","c4033ea3":"code","2c2c73ce":"code","31e2cd77":"code","5028e6e9":"code","30991644":"code","45e84ad4":"code","83a9eac7":"code","ae6b2ded":"markdown","f755968d":"markdown","6bc61600":"markdown","14011eb8":"markdown","e54dea14":"markdown","c20eaa5f":"markdown","49434e54":"markdown","cfa9e1ce":"markdown","2dd57b5e":"markdown","becd54be":"markdown","bac35620":"markdown","d2e9f7a0":"markdown"},"source":{"36e932bd":"# Import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport pandas as pd\nimport os\nimport time\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\nimport ipywidgets as widgets\nfrom IPython.display import display","c727fa47":"t_Start = time.time()","234e6ccf":"t1_Start = time.time()","2c42e709":"# Created dataframes from input files\ntrain_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntest_id = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ntrain_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\ntest_trans = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv')\n\nprint('Data imported')","72d14f21":"t1_End = time.time()\nif (t1_End - t1_Start) < 60:\n    print('Step 1 completed - Time taken %3.1f seconds' % (t1_End - t1_Start))\nelse:\n    print('Step 1 completed - Time taken %i minutes and %i seconds' % ((t1_End - t1_Start)\/\/60,(t1_End - t1_Start)%60))","96b49f69":"t2_Start = time.time()","bda97fdd":"avg_fraud_rate = train_trans.isFraud.sum()\/train_trans.shape[0]","ce4b6285":"# Merge the ID data and the transaction data\n\ntrain_merged = pd.merge(train_trans, train_id, how='outer', on='TransactionID')","78268ce8":"w = widgets.Dropdown(options=train_merged.columns.drop(['TransactionID','isFraud']), value='card6', description='column:', disabled=False)","ed4c21f8":"# Function to create variables based on selected column\n\ndef Display_Features(column):\n    ''' (str) --> None\n    \n    For the selected column, displays various features\n    '''\n    # Data type\n    data_type = train_merged[column].dtype\n\n    # Proportion of missing values\n    missing_proportion = train_merged[column].isna().sum()\/train_merged[column].count()\n    \n    # Dataframe of most common values and total other values \n    top_9 = train_merged.groupby(column).count()['TransactionID'].sort_values(ascending=False).head(9)\n    top_10 = top_9.copy()\n    top_10.loc['other'] = train_merged.groupby(column).count()['TransactionID'].sum()-top_9.sum()\n    \n    print('The data type is %s' % str(data_type))\n    print('%3.1f%% of the data is missing' % (missing_proportion*100))\n    display(top_10.to_frame())\n# Bar chart of frequencies\n\ndef Display_Chart(column):\n    ''' (str) --> None\n    \n    For the selected column, displays a plot of frequencies and fraud rate\n    '''\n    fig, ax = plt.subplots(1, 1, figsize=(8, 5));\n\n    # bar chart of frequencies\n    train_merged.groupby(column).count()['TransactionID'].plot.bar(color='blue',alpha=0.5,ax=ax);\n    bx = ax.twinx()\n    ax.set_title('Frequency of values (fraud % overlaid)');\n    ax.set_xlabel('Value');\n    ax.set_ylabel('Frequency');\n    ax.set_xticks(range(len(train_merged.groupby(column).count())))\n    ax.set_xticklabels(train_merged.groupby(column).count()['TransactionID'].index)\n    # line chart of fraud rate\n    (1-train_merged[train_merged['isFraud']==0].groupby(column).count()\/train_merged.groupby(column).count())['TransactionID'].plot.line(ax=bx,color='red')\n    bx.set_ylabel('Fraud %');\n    \n    plt.show()\n    ","77bbce4f":"selection = widgets.Output()\n\ndef Widger_Event_Handler(change):\n    ''' None --> None\n    Function to automatically display dashboard when widget changed\n    '''\n    selection.clear_output()\n    with selection:\n        Display_Features(change.new)\n        Display_Chart(change.new)\n    \nw.observe(Widger_Event_Handler, names='value')\n\ndisplay(w)","d4ff806d":"display(selection)","036add85":"t2_End = time.time()\nif (t2_End - t2_Start) < 60:\n    print('Step 2 completed - Time taken %3.1f seconds' % (t2_End - t2_Start))\nelse:\n    print('Step 2 completed - Time taken %i minutes and %i seconds' % ((t2_End - t2_Start)\/\/60,(t2_End - t2_Start)%60))","cc543abf":"t3_Start = time.time()","716d85b2":"# Set up target variable\n\ntrain_trans = train_trans.set_index('TransactionID')\ny_train = train_trans.isFraud\n","e88600ac":"# Define a function to manipulate the data for input into the model\n# At this stage, just cut the data down to fully populated, numeric columns\n\ndef DataForInput(trans_data,ID_data):\n    ''' (df, df) --> df\n    \n    Takes the transaction and ID dataframes and combines them to create a single dataframe suitable for input into the model.\n    \n    Set up as a function so can be repeated for training and test dataset\n    '''\n    \n    return trans_data['TransactionAmt'] ","17f0b66c":"# Set up the training data ready for model training\n\nX_train = DataForInput(train_trans,train_id)","ddcc5d33":"# Fit a model\n\n#xgboost = xgb.XGBClassifier().fit(X_train,y_train)","41908e77":"# Work out some performance statistics using cross-validation\n'''\nxgb_accuracy = cross_val_score(xgboost, X_train, y_train, cv=5).mean()\nxgb_auc = cross_val_score(xgboost, X_train, y_train, scoring='roc_auc', cv=5).mean()\n\nprint('The CV model accuracy score is %3.1f%%' % (xgb_accuracy*100))\nprint('The CV model AUC score is %3.5f' % (xgb_auc))\n'''","c4033ea3":"t3_End = time.time()\nif (t3_End - t3_Start) < 60:\n    print('Step 3 completed - Time taken %3.1f seconds' % (t3_End - t3_Start))\nelse:\n    print('Step 3 completed - Time taken %i minutes and %i seconds' % ((t3_End - t3_Start)\/\/60,(t3_End - t3_Start)%60))","2c2c73ce":"t4_Start = time.time()","31e2cd77":"# Create predictions\n\ntest_trans = test_trans.set_index('TransactionID')\nX_test = DataForInput(test_trans,test_id)\n#X_test.preds = xgboost.predict_proba(X_test)\nX_test.preds = 0.5\nsample_sub.isFraud = 1 - X_test.preds\nsample_sub.to_csv('submission.csv',index=False)","5028e6e9":"plt.figure(figsize=(12, 5))\nplt.hist(sample_sub.isFraud,bins=100);\nplt.title('Distribution of prediction probabilities in submission');\nplt.xlabel('Probability');\nplt.ylabel('Count');","30991644":"mean = sample_sub.isFraud.mean()\n\nprint('The predicted fraud rate is %3.2f%%' % (mean*100))","45e84ad4":"t4_End = time.time()\nif (t4_End - t4_Start) < 60:\n    print('Step 4 completed - Time taken %3.1f seconds' % (t4_End - t4_Start))\nelse:\n    print('Step 4 completed - Time taken %i minutes and %i seconds' % ((t4_End - t4_Start)\/\/60,(t4_End - t4_Start)%60))","83a9eac7":"t_End = time.time()\nprint('Notebook finished - Total run time = %i minutes and %i seconds' % ((t_End - t_Start)\/\/60,(t_End - t_Start)%60))","ae6b2ded":"The test data contain 506,691 rows, with around 28% also having ID features. All columns are consistent between the training and the test data (other than the target variable).","f755968d":"The predictions are distributed at the lower end of the distribution. The predicted fraud rate of 4.24% is possibly a little high but appears reasonable.","6bc61600":"# Fraud Detection\n### August 2019","14011eb8":"The training data contains 590,540 rows, with features split across two dataframes:\n- train_trans contains 392 features (plus an identifier and a fraud flag) which appear to relate to the transaction details (e.g. amount, card type)\n- train_id contains a further 40 features (plus an identifier) for around 25% of transactions. The features appear to relate to the online route of the transaction (e.g. browser, device)","e54dea14":"## 4) Create Submission File","c20eaa5f":"## 2) Analysis of the Data","49434e54":"Use the dropdown box to look at a basic dashboard for each feature","cfa9e1ce":"## 3) Fit ML Model","2dd57b5e":"This is the second kernel created within the competition and was started on 28 August 2019. My aims are:\n1. Cut out some of the initial data checks, as these were completed in a previous kernel\n2. Analyse each feature to understand the type of data, the one-way relationship to target and key correlations with other features\n3. Propose how to bring each feature through to the model (or whether to remove)\n4. Consider possible engineered features and profile as in Step 2\n\nI hope to reach this stage by 8 September 2019. This kernel will then inform a kernel where a more complex model is fitted.","becd54be":"In the training dataset, 3.5% of transactions are fraudulent","bac35620":"## 1) Import, check and prepare data","d2e9f7a0":"Most of the columns are numeric (although not clear if the numbers may represent categories). There are a lot of missing values with some columns very sparsely populated."}}