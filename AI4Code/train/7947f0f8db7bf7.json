{"cell_type":{"7256353f":"code","3a87b53d":"code","505d7163":"code","1cca567b":"code","8e67211b":"code","d892dc38":"code","d92fae9f":"code","115b189e":"code","0fd65a85":"code","4ad320f8":"code","d4fdb019":"code","243171e8":"code","b442a4fb":"code","aece653e":"code","8d587c69":"code","c05c41c3":"code","e7e5cf79":"code","cd1a7b80":"code","ae0fffec":"code","adc2442f":"code","3371b9de":"code","dcc02871":"code","6920c2fc":"code","d3d628f6":"code","768b0f10":"code","127ef90b":"code","9b6a5e09":"code","9eb23ddf":"code","32ccdb6c":"code","2fda9094":"code","690a5ee4":"code","8d417547":"code","d1384bb2":"code","18d5f698":"code","c3423a6a":"code","1f89aa74":"code","77ccd539":"code","279165db":"code","a32de068":"code","3867d9ed":"code","69e996fb":"code","f6fd0ac7":"code","00965195":"code","08f4a5f8":"code","2452d284":"code","5b6d3dd4":"code","b973b463":"code","d5cd665e":"code","ef1953b0":"code","dcaaf16c":"code","efee8c66":"code","e6882ce4":"code","9f684c9f":"code","5e0105d8":"code","ab8600fc":"code","6243e955":"code","1dcca778":"code","7b089b0d":"code","25d55ce3":"code","69a3e57c":"code","d8ae3848":"code","f0abb6d4":"code","00267fb5":"code","6ea0c357":"code","e65a958c":"code","c95ced64":"code","a142a7ea":"code","0502aef7":"code","e5e8cd6a":"code","5db7a34b":"code","f6d5c766":"code","b7a3d647":"code","e41617b7":"code","dd4e26eb":"code","86f48868":"code","e7e6d8d4":"code","b7fa2a5e":"code","2bd85e05":"code","dbd9ee77":"code","6026e7c6":"code","382b3627":"code","efad69b5":"code","734a69b8":"code","ba0a48e5":"code","dfa478d7":"markdown","d6d323a4":"markdown","7d13cb04":"markdown","3a109551":"markdown","7ec97692":"markdown","d5bd809d":"markdown","3e4c450e":"markdown","874f139b":"markdown","9600b196":"markdown","1b3cd632":"markdown","a531cb3a":"markdown","9c99ba74":"markdown","5aad7beb":"markdown","818d909f":"markdown","ede073be":"markdown","93a7b356":"markdown","d44c1b65":"markdown","82a2dce1":"markdown","aa754dd0":"markdown","5b3b9e58":"markdown","cf02b04b":"markdown","9d307ddd":"markdown","ff5285c8":"markdown","f0b84792":"markdown","a95e1264":"markdown","11d62a5b":"markdown","4b2c32d2":"markdown","2b7bc965":"markdown","bbf98a26":"markdown","995e50c9":"markdown","519455d0":"markdown","33696f22":"markdown","439f5e18":"markdown","4290340b":"markdown","843366b1":"markdown","be0a1743":"markdown","d1775b0a":"markdown","6f27a445":"markdown","e8587cf3":"markdown","3b7d9db7":"markdown","9eebc75e":"markdown","21b1609a":"markdown","442eda27":"markdown","cf537c27":"markdown","8aeba08a":"markdown","0f003299":"markdown"},"source":{"7256353f":"## Libraries Needed:\nimport numpy as np                        ## Matrix functions\nimport matplotlib.pyplot as plt           ## PLotting\nimport pandas as pd                       ## To Work WIth Dataframes \nimport plotly.express as px               ## For Interactive Visualization\nimport plotly.graph_objects as go         ## For Detailed visual plots\nfrom collections import Counter         \nfrom plotly.subplots import make_subplots ## To Plot Subplots\nfrom wordcloud import WordCloud           ## To Generate Wordcloud\nfrom datetime import datetime             ## Work with timeseries data\n\nimport warnings\nwarnings.filterwarnings('ignore')","3a87b53d":"metadata = pd.read_csv(\"..\/input\/zomato-restaurants-hyderabad\/Restaurant names and Metadata.csv\")\nprint(\"MetaData Shape:\", metadata.shape)","505d7163":"metadata.head()","1cca567b":"metadata.isnull().sum()","8e67211b":"metadata.info()","d892dc38":"metadata.drop(['Links'], axis=1, inplace=True)\nmetadata['Cost'] = metadata['Cost'].apply(lambda x : float(x.replace(',', '')))","d92fae9f":"cost = metadata[['Name', 'Cost']]\n\nbins = pd.DataFrame(pd.cut(cost['Cost'], bins= 10))\nbins.columns = ['bins']\nbins['bins'] = bins['bins'].astype(str)\n\nbins = bins['bins'].value_counts().reset_index()\nbins.columns = ['Bin', 'Count']\nbins[\"Cumsum\"] = bins['Count'].cumsum()","115b189e":"fig = go.Figure()\nfig.add_trace(go.Bar(name = \"Restaurants in Range\", x = bins['Bin'], y=bins['Count']))\nfig.add_trace(go.Scatter(name = \"Restaurants below or in Range\", x = bins['Bin'], y=bins['Cumsum']))\nfig.update_layout(title=\"No Of Restaurents by Price Range\",\n                 xaxis_title = \"Price Range\",\n                 yaxis_title = \"No Of Restaurants\")","0fd65a85":"fig = go.Figure()\n\ntemp = cost.sort_values(by='Cost')\n\nfig.add_trace(go.Bar(name = \"Cheapest Restaurant\", x = temp.head()['Name'], y=temp.head()['Cost']))\nfig.add_trace(go.Bar(name=\"Expensive Restaurent\", x = temp.tail()['Name'], y=temp.tail()['Cost']))\nfig.update_layout(title = \"Least and Most Expensive Restaurants:\",\n                 xaxis_title = \"Restaurant Name\",\n                 yaxis_title = \"Cost\")\nfig.show()\ndel temp","4ad320f8":"cuisines = metadata['Cuisines']\ncuisines = cuisines.apply(lambda x : x.lower())","d4fdb019":"all_cuisines = ', '.join(i for i in cuisines.tolist())\nall_cuisines = Counter(all_cuisines.split(', '))\nall_cuisines = pd.DataFrame.from_dict(all_cuisines, orient='index', dtype='int')\nall_cuisines.columns = ['No Of Restaurents']\nall_cuisines.sort_values(by='No Of Restaurents', ascending=False, inplace=True)","243171e8":"cuisines = cuisines.apply(lambda x : x.split(', '))\ncuisines = pd.DataFrame(cuisines)\n\nfor i in all_cuisines.index.tolist():\n    cuisines['{}'.format(i)] = cuisines['Cuisines'].apply(lambda x : i in x)\n\ncuisines.drop('Cuisines', axis=1, inplace=True)\ncuisines = pd.concat([metadata, cuisines], axis=1)\ncuisines.drop(['Collections', 'Cuisines', 'Timings'], axis=1, inplace=True)\ncuisines = pd.melt(cuisines, id_vars=['Name', 'Cost'], var_name='Cuisine')\ncuisines = cuisines[cuisines['value']]\ncuisines.drop(['value'], axis=1, inplace=True)\ndel all_cuisines","b442a4fb":"temp = cuisines['Cuisine'].value_counts().reset_index()\n\nfig = px.bar(x = temp['index'], y=temp['Cuisine'])\nfig.update_layout(title = \"Cuisines availability\",\n                 xaxis_title = \"Cusisine\",\n                 yaxis_title = \"No of restaurants cuisine available at\")\nfig.show()\ndel temp","aece653e":"## Value_counts() functions returns in descending order. So we don't need to sort expliitly.\ntop_cuisines = cuisines['Cuisine'].value_counts().reset_index()\ntop_cuisines = top_cuisines['index'].tolist()[:8]","8d587c69":"temp = cuisines[cuisines['Cuisine'].isin(top_cuisines)]\n\nfig = px.histogram(data_frame=temp, x='Cost',\n            facet_col = 'Cuisine', facet_col_wrap=4,\n            title = \"Price Distribution amongst most popular cuisines:\")\nfig.show()\ndel temp","c05c41c3":"mean_cost = cuisines.groupby(by='Cuisine')['Cost'].mean().reset_index()\nmean_cost.sort_values(by='Cost', ascending=False, inplace=True)\n\nfig = px.bar(mean_cost, x='Cuisine', y='Cost')\nfig.update_layout(title = \"Average Cost by Cuisine\",\n                 xaxis_title = \"Cuisine (Most to Least Expensive)\",\n                 yaxis_title = \"Avg Cost of Cuisine\")\nfig.show()\ndel mean_cost","e7e5cf79":"cuisine_offered = cuisines.groupby(by='Name')['Cuisine'].count().reset_index()\ncuisine_offered.columns = ['Name', 'Cuisine_Offered']\n\nmetadata = pd.merge(metadata, cuisine_offered, left_on='Name', right_on = 'Name')\n\ndel cuisine_offered","cd1a7b80":"collections = metadata['Collections'].dropna().tolist()\ncollections = ', '.join(i for i in collections)\n\nwc = WordCloud(background_color=\"white\", max_words=200, \n               width=800, height=600, random_state=1).generate(collections)\nprint(\"Most Common Taggs:\")\nplt.imshow(wc)\ndel collections","ae0fffec":"reviews = pd.read_csv(\"..\/input\/zomato-restaurants-hyderabad\/Restaurant reviews.csv\")\nprint(\"Reviews Shape:\", reviews.shape)","adc2442f":"reviews.head()","3371b9de":"reviews.isnull().sum()","dcc02871":"reviews.info()","6920c2fc":"temp = reviews[reviews.Reviewer.isnull()].Restaurant.unique()\nprint(\"These are the restaurants where we have missing values:\", temp, sep = '\\n')\ndel temp","d3d628f6":"reviews.drop('Pictures', axis = 1, inplace=True)\nreviews.dropna(inplace=True)","768b0f10":"reviews['Rating'].unique()","127ef90b":"reviews.loc[reviews['Rating']=='Like', 'Rating'] = 3.5\nreviews['Rating'] = reviews['Rating'].astype('float')","9b6a5e09":"def get_followers(x):\n    x = x.split(\", \")\n    try :\n        x = x[1].split()[0]\n    except:\n        x = 0\n    return x","9eb23ddf":"reviews['Thread Review'] = reviews['Metadata'].apply(lambda x : x.split(\", \")[0].split()[0])\nreviews['Followers'] = reviews['Metadata'].apply(get_followers)\n\nreviews['Thread Review'] = reviews['Thread Review'].astype('int')\nreviews['Followers'] = reviews['Followers'].astype('int')\n\nreviews.drop('Metadata', axis=1, inplace=True)","32ccdb6c":"reviews['Time'] = reviews['Time'].apply(lambda x : datetime.strptime(x, '%m\/%d\/%Y %H:%M'))","2fda9094":"reviews['Restaurant'].value_counts().nunique()","690a5ee4":"## 100 reviews for each restaurant, Which restaurants have not been reviewd?\n\ntemp = set(metadata['Name'].tolist()) - set(reviews['Restaurant'].tolist())\n\nprint(\"Restaurants which have no reviews.\", temp, sep = '\\n')","8d417547":"print(\"Details of the restaurants that have not been reviewd.\")\nmetadata[metadata['Name'].isin(temp)]","d1384bb2":"reviewers = reviews['Reviewer'].value_counts().reset_index()\nreviewers.columns = ['Reviewer', 'Reviews']\n\nfig = px.histogram(reviewers, 'Reviews')\nfig.update_layout(title = \"Distribution in no of reviews:\",\n                 xaxis_title = \"No of Reviews\",\n                 yaxis_title = \"Given By users\")\nfig.show()","18d5f698":"temp = reviewers.head()['Reviewer'].tolist()\nprint(\"People who have posted most reviews are :\", temp)\n\ndel temp, reviewers","c3423a6a":"mean_ratings = reviews.groupby('Restaurant')['Rating'].mean().reset_index()\nmean_ratings.columns = ['Restaurant', 'Avg. Rating']\nreviews = pd.merge(reviews, mean_ratings, left_on = 'Restaurant', right_on = 'Restaurant')\nmean_ratings.sort_values(by='Avg. Rating', ascending = False, inplace=True)","1f89aa74":"fig = go.Figure()\nfig.add_trace(go.Bar(name = \"Highest Avg. Ratings\",\n                     x = mean_ratings.head()['Restaurant'], y = mean_ratings.head()['Avg. Rating']))\nfig.add_trace(go.Bar(name = \"Lowest Avg. Ratings\",\n                     x = mean_ratings.tail()['Restaurant'], y = mean_ratings.tail()['Avg. Rating']))\n\nfig.update_layout(title = \"Restaurents with highest and lowest avg. ratings:\",\n                 xaxis_title = \"Restaurant Name\",\n                 yaxis_title = \"Avg. Rating\")\nfig.show()","77ccd539":"reviews['Hour'] = reviews['Time'].dt.hour\nreviews['Month'] = reviews['Time'].dt.month","279165db":"hour_counts = reviews['Hour'].value_counts().reset_index()\nhour_counts.columns = ['Hour', 'Count']\nhour_counts.sort_values(by = 'Hour')\nfig = px.bar(hour_counts, 'Hour', 'Count')\nfig.update_layout(title = \"Reviews submissions by day Hours:\",\n                 xaxis_title = \"Day Hour\",\n                 yaxis_title = \"No Of Reviews\")\nfig.show()\ndel hour_counts","a32de068":"month_counts = reviews['Month'].value_counts().reset_index()\nmonth_counts.columns = ['month', 'Count']\nmonth_counts.sort_values(by = 'month')\nfig = px.bar(month_counts, 'month', 'Count')\nfig.update_layout(title = \"Reviews submissions by months:\",\n                 xaxis_title = \"Month\",\n                 yaxis_title = \"No Of Reviews\")\nfig.show()\ndel month_counts","3867d9ed":"temp = reviews.groupby(by='Hour')['Rating'].mean().reset_index()\nprint(temp)","69e996fb":"reviews['Weekday'] = reviews['Time'].dt.weekday\nday_map = dict(zip(range(7), [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]))\nreviews['Weekday'] = reviews['Weekday'].map(day_map)\ndel day_map","f6fd0ac7":"weekday_count = reviews.groupby(by='Weekday')['Review'].count().reset_index()\n\nfig = go.Figure(data=[\n    go.Pie(labels = weekday_count['Weekday'],\n           values = weekday_count['Review'],\n          )\n])\n\nfig.update_traces(hoverinfo='label+value', textinfo='percent', textfont_size=20,\n                  marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title = \"No of Reviews by Week-Day:\")\nfig.show()","00965195":"fig = px.histogram(data_frame=reviews, x='Rating',\n            facet_col = 'Weekday', facet_col_wrap=4,\n            title = \"Rating Distribution amongst weekdays:\")\nfig.show()","08f4a5f8":"fig = px.scatter(reviews, x = 'Thread Review', y='Followers')\nfig.update_layout(title = \"Relationship b\/w Threads and Followers\",\n                 xaxis_title = \"No Of Threads\",\n                 yaxis_title = \"No Of Followers\")","2452d284":"reviewers = reviews.groupby(by='Reviewer')['Followers', 'Thread Review'].sum().reset_index()\nreviewers.sort_values(by = ['Followers'], ascending = False, inplace=True)\n\nmost_followers = reviewers.head()\n\nreviewers.sort_values(by = ['Thread Review'], ascending = False, inplace=True)\n\nmost_threads = reviewers.head()","5b6d3dd4":"fig = make_subplots(rows = 1, cols = 2, subplot_titles = ['Most Followers', 'Most Threads'])\n\nfig.add_trace(go.Bar(name=\"Followers\", x = most_followers['Reviewer'], y = most_followers['Followers']), 1,1)\nfig.add_trace(go.Bar(name=\"Threads\", x = most_followers['Reviewer'], y = most_followers['Thread Review']), 1,1)\n\nfig.add_trace(go.Bar(name=\"Followers\", x = most_threads['Reviewer'], y = most_threads['Followers']), 1,2)\nfig.add_trace(go.Bar(name=\"Threads\", x = most_threads['Reviewer'], y = most_threads['Thread Review']), 1,2)\n\n\nfig.update_xaxes(title_text=\"Reviewer\", row=1, col=1)\nfig.update_xaxes(title_text=\"Reviewer\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Sum\", row=1, col=1)\nfig.update_yaxes(title_text=\"Sum\", row=1, col=2)\n\nfig.update_layout(title = \"Reviewers with:\")","b973b463":"df = pd.merge(cuisines, reviews, left_on = 'Name', right_on = 'Restaurant')\ndf.drop(['Name', 'Time', 'Hour', 'Month'], axis = 1, inplace = True)","d5cd665e":"fig = px.scatter(df, 'Cost', 'Avg. Rating', trendline = 'ols')\nfig.update_layout(title = \"Relationship between Cost and Avg. Raing of the restaurant\")\nfig.show()","ef1953b0":"del metadata, reviews, cuisines","dcaaf16c":"review = pd.read_csv(\"..\/input\/zomato-restaurants-hyderabad\/Restaurant reviews.csv\")\nreview = review[['Review', 'Rating']]","efee8c66":"review.isnull().sum()","e6882ce4":"review.dropna(inplace=True)","9f684c9f":"review.head()","5e0105d8":"review['Review']= review['Review'].apply(lambda x : x.replace('\\n', ' '))\nreview['Review']= review['Review'].apply(lambda x : x.lower())","ab8600fc":"review.groupby(by='Rating')['Review'].count()","6243e955":"review = review[review['Rating']!='Like']\nreview['Rating']= review['Rating'].astype('float')\nreview['Rating'] = review['Rating'].apply(lambda x : int(x))","1dcca778":"review.groupby(by='Rating')['Review'].count()","7b089b0d":"import nltk\nfrom nltk.tokenize import word_tokenize\n\nreview['Words'] = review['Review'].apply(word_tokenize)\n\nfrom nltk.corpus import stopwords \n\nStopWords = set(stopwords.words('english'))\n\ndef clean_words(x):\n    words = []\n    for i in x:\n        if i.isalnum() and i not in StopWords:\n            words.append(i)\n    return words\n\nreview['Words'] = review['Words'].apply(clean_words)\nreview['Word Count'] = review['Words'].apply(lambda x : len(x))\ndel StopWords","25d55ce3":"review.groupby(by='Rating')['Word Count'].mean()","69a3e57c":"fig = px.histogram(review, x='Word Count', color='Rating',\n            barmode = 'overlay', nbins=50, marginal = 'box')\nfig.update_layout(title = \"Word Count Distribution in Reviews by Ratings.\",\n                 xaxis_title = \"Word Count\",\n                 yaxis_title = \"No of Reviews\")\nfig.show()","d8ae3848":"review.drop('Word Count', axis = 1, inplace=True)","f0abb6d4":"most_common = dict()\n\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Words by ratings and their word-counts:\")\npd.DataFrame(most_common)","00267fb5":"review['POS'] = review['Words'].apply(nltk.pos_tag)","6ea0c357":"def get_adjective(x):\n    adj = set(['JJ', 'JJR', 'JJS'])\n    word = []\n    for i in x:\n        if i[1] in adj:\n            word.append(i[0])\n    return word\n\nreview['ADJ'] = review['POS'].apply(get_adjective)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['ADJ'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Adjectives by ratings:\")\npd.DataFrame(most_common)","e65a958c":"def get_noun(x):\n    noun = set(['NN', 'NNS', 'NNP', 'NNPS'])\n    word = []\n    for i in x:\n        if i[1] in noun:\n            word.append(i[0])\n    return word\n\nreview['Noun'] = review['POS'].apply(get_noun)\n\nreview.drop('POS', axis = 1, inplace = True)\n\nmost_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Noun'].tolist():\n        words.extend(i)\n    words = nltk.FreqDist(words)\n    words = words.most_common(10)\n    most_common['{}'.format(group)] = words\nprint(\"Most Common Nouns by ratings:\")\npd.DataFrame(most_common)","c95ced64":"most_common = dict()\nfor group, data in review.groupby(by='Rating'):\n    words = []\n    for i in data['Words'].tolist():\n        words.extend(i)\n    bigram = list(nltk.bigrams(words))\n    bigram = nltk.FreqDist(bigram)\n    bigram = bigram.most_common(10)\n    most_common['{}'.format(group)] = bigram\n\nprint(\"Most Common Bi-grams by Ratings:\")\npd.DataFrame(most_common)","a142a7ea":"del most_common","0502aef7":"from textblob import TextBlob\n\nreview['Subjectivity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.subjectivity)\nreview['Polarity'] = review['Review'].apply(lambda x : TextBlob(x).sentiment.polarity)","e5e8cd6a":"fig = px.histogram(review, x='Subjectivity', barmode='overlay', color='Rating')\nfig.update_layout(title = \"Subjectivity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","5db7a34b":"fig = px.histogram(review, x='Polarity', barmode='overlay', color='Rating')\n\nfig.update_layout(title = \"Polarity distribution in reviews of different ratings.\",\n                 xaxis_title = \"Subjectivity\",\n                 yaxis_title = \"Number of Reviews\")\nfig.show()","f6d5c766":"from sklearn.feature_extraction.text  import TfidfVectorizer\ntf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2),\n                    min_df = 1)","b7a3d647":"from sklearn.model_selection import train_test_split\n\nX = review['Review']\ny = review['Rating']\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 1)\n\ntf_x_train = tf.fit_transform(x_train)\ntf_x_test = tf.transform(x_test)","e41617b7":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nperformance = {'Model' : [],\n              'Accuracy Score' : [],\n              'Precision Score' : [],\n              'Recall Score' : [],\n              'f1 Score' : []}","dd4e26eb":"from sklearn.linear_model import LogisticRegression\n\nlr= LogisticRegression()\nlr.fit(tf_x_train, y_train)\npred = lr.predict(tf_x_test)\n\nperformance['Model'].append('LogisticRegression')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","86f48868":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(tf_x_train, y_train)\npred = sgd.predict(tf_x_test)\n\nperformance['Model'].append('SGD')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","e7e6d8d4":"from sklearn.naive_bayes import MultinomialNB\n\nmnb = MultinomialNB()\nmnb.fit(tf_x_train, y_train)\npred = mnb.predict(tf_x_test)\n\nperformance['Model'].append('Multinomial NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","b7fa2a5e":"from sklearn.naive_bayes import BernoulliNB\n\nbnb = BernoulliNB()\nbnb.fit(tf_x_train, y_train)\npred = bnb.predict(tf_x_test)\n\nperformance['Model'].append('Bernoulli NB')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","2bd85e05":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(tf_x_train, y_train)\npred = svc.predict(tf_x_test)\n\nperformance['Model'].append('SVC')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","dbd9ee77":"from sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(tf_x_train, y_train)\npred = linear_svc.predict(tf_x_test)\n\nperformance['Model'].append('Linear SVC')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","6026e7c6":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nrfc.fit(tf_x_train, y_train)\npred = rfc.predict(tf_x_test)\n\nperformance['Model'].append('Random Forest')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","382b3627":"pd.DataFrame(performance)","efad69b5":"from statistics import mode\n\nclass voted_classifier():\n    def __init__(self):\n        self.classifiers = [lr, sgd, mnb, bnb, svc, linear_svc, rfc]\n        \n    def classify(self, features):\n        names = ['lr', 'sgd', 'mnb', 'bnb', 'svc', 'linear_svc', 'rfc']\n        i = 0 \n        votes = pd.DataFrame()\n        for classifier in self.classifiers:\n            pred = classifier.predict(features)\n            votes[names[i]] = pred\n            i+=1\n        return votes.mode(axis = 1)[0]","734a69b8":"vc = voted_classifier()\npred = vc.classify(tf_x_test)\n\nperformance['Model'].append('Voted Classifier')\nperformance['Accuracy Score'].append(accuracy_score(y_test, pred))\nperformance['Precision Score'].append(precision_score(y_test, pred, average='macro'))\nperformance['Recall Score'].append(recall_score(y_test, pred, average='macro'))\nperformance['f1 Score'].append(f1_score(y_test, pred, average='macro'))","ba0a48e5":"pd.DataFrame(performance)","dfa478d7":"### Reviewers","d6d323a4":"## Combining Datasets","7d13cb04":"## Analyzing Reviews (Text)","3a109551":"### Restaurants and Ratings","7ec97692":"#### Linked attribute will be of no use in our analysis. Also, Cost attribute should be of float type.","d5bd809d":"#### Now, these bigrams have started making proper sense. Like, \"Worst Experiance\" is th most common bigram for rating 1, whereas \"Must Try\" is the most common bigram for rating 5. These bigram mean the same as their ratings.","3e4c450e":"#### Very few reviews have rating like, 1.5, 2.5, 3.5 and 4.5. (We have lesser data for some categories and more data for other categories). This will make classification process difficult.\n- We should merge them to get better performance. \n- For Analysis as well, this will be more helpful as this few records are similar to outliers.\n- 'Like' is a data redunduncy, better drop this.","874f139b":"### Data Cleaning","9600b196":"## Predictions","1b3cd632":"### Common Bigrams","a531cb3a":"### Models","9c99ba74":"#### Did you notice something? 'Parijat Ray' in the list of Reviewer with most threads is from our list of people who posted most reviews.","5aad7beb":"### Reviews Distribution","818d909f":"#### Time is in the form of string, for better analysis we can convert this to datetime object.","ede073be":"### Followers and Thread Reviews","93a7b356":"### Voted Classifier","d44c1b65":"#### We can see a positive correlation between cost and Avg. Rating of a Cuisine.","82a2dce1":"### Time and Reviews","aa754dd0":"### Nouns","5b3b9e58":"### Ratings distribution","cf02b04b":"### Extracting meaningful words from reviews","9d307ddd":"#### Metadada attribute consistes of followers and reviews. It is better to extract these differently and use in out analysis. We'll rename the reviews as thread review as we already have an attribute named as reviews that are Original Review. Also, After extracting these differently, we'll have no use of the \"Metadata\" attribute itself. So, we'll drop that.","ff5285c8":"#### Thank you. Do share your thoughts and suggestions in the comments. (Work on progress to ahieve better accuracy.)","f0b84792":"### Cuisins","a95e1264":"### Tf-idf","11d62a5b":"### Collections","4b2c32d2":"### Review length by Rating","2b7bc965":"#### We do see difference in polarity distribution of reviews of different ratings. Which is how this should be. ","bbf98a26":"### Cost vs Rating","995e50c9":"### Data Cleaning","519455d0":"## Reviews","33696f22":"### Cost Distribution","439f5e18":"#### Let's see if we'll encounter these names again in our analysis.","4290340b":"### Adjectives","843366b1":"#### Picture attribute will not be used in our analysis, we better get rid of it. Also, number of null values is ignorable considering size of the dataset. We're gonna drop null values too.","be0a1743":"### No Review Restaurant","d1775b0a":"#### We can see a useual pattern here. People tend to go out on weekends more than on weekdays, this is why we have more reviews on weekends than on weekdays.","6f27a445":"#### We can see an obvious pattern in day-hour and no of reviews recorded during that hour. No one just reviews a restaurant as soon as they wake up.","e8587cf3":"#### A bigram (group of two words) better describes feelings than a single word. Let's see the bigrams","3b7d9db7":"## MetaData","9eebc75e":"### Polarity And Subjectivity","21b1609a":"### Most common words by rating","442eda27":"#### We have an unusual pattern here, Recorded reviews are extremely less in the month of June as compared to other months. What chould be the reason?","cf537c27":"#### We can see that most users have only given reviews once.","8aeba08a":"### Parts Of Speech","0f003299":"#### We found No Significance difference here, So there is no point plotting it and going deep in it."}}