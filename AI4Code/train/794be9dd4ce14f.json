{"cell_type":{"5e54b768":"code","d6eb3464":"code","e81d2fdd":"code","d68e437a":"code","9f27bc81":"code","c51032cb":"code","61e7dbee":"code","902afd80":"code","7e21e51b":"code","98a90a0a":"code","8fc1ac91":"code","5c28eaf6":"code","9a819112":"code","337dc557":"code","9e0ef25c":"code","1eb36ce8":"markdown","5a26be3c":"markdown","f24ece84":"markdown","5ed3d3c8":"markdown","a34125c8":"markdown","d0d63746":"markdown"},"source":{"5e54b768":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestClassifier","d6eb3464":"data = pd.read_csv('..\/input\/hepatitis-data\/hepatitis_csv.csv')","e81d2fdd":"data","d68e437a":"data.info()","9f27bc81":"def preprocess_inputs(df, drop_protime=False):\n    df = df.copy()\n    \n    # Identify the continuous numeric features\n    continuous_features = ['age', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin', 'protime']\n    \n    # Fill missing values\n    for column in continuous_features:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    for column in df.columns.drop(continuous_features):\n        df[column] = df[column].fillna(df[column].mode().sample(1, random_state=1).values[0])\n    \n    # Convert the booleans columns into integer columns\n        for column in df.select_dtypes('bool'):\n            df[column] = df[column].astype(np.int)\n    \n    # Encode the sex column as a binary feature\n    df['sex'] = df['sex'].replace({\n        'female': 0,\n        'male': 1\n    })\n    \n    # Shuffle the data\n    df = df.sample(frac=1.0, random_state=1).reset_index(drop=True)\n    \n    # Change label name\n    df = df.rename(columns={'class': 'label'})\n    \n    # Drop protime\n    if drop_protime == True:\n        df = df.drop('protime', axis=1)\n    \n    # Split df into X and y\n    y = df['label']\n    X = df.drop('label', axis=1)\n    \n    return X, y","c51032cb":"X, y = preprocess_inputs(data, drop_protime=True)","61e7dbee":"X","902afd80":"y","7e21e51b":"kmeans = KMeans(n_clusters=2)\nkmeans.fit(X)\n\ncluster_labels = kmeans.labels_\ncluster_labels","98a90a0a":"pca = PCA(n_components=2)\n\nX_reduced = pd.DataFrame(pca.fit_transform(X), index=X.index, columns=[\"PC1\", \"PC2\"])\nX_reduced = pd.concat([X_reduced, y, pd.Series(cluster_labels, name='cluster')], axis=1)\n\ncentroids = pca.transform(kmeans.cluster_centers_)","8fc1ac91":"X_reduced","5c28eaf6":"cluster_0_examples = X_reduced.query(\"cluster == 0\")\ncluster_1_examples = X_reduced.query(\"cluster == 1\")\n\nplt.figure(figsize=(16, 10))\nplt.scatter(cluster_0_examples['PC1'], cluster_0_examples['PC2'], label=\"Cluster A\")\nplt.scatter(cluster_1_examples['PC1'], cluster_1_examples['PC2'], label=\"Cluster B\")\nplt.scatter(centroids[:, 0], centroids[:, 1], c='lightgreen', s=200, label=\"Cluster Centers\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"K-Means Clustering\")\nplt.legend()\nplt.show()","9a819112":"live_examples = X_reduced.query(\"label == 'live'\")\ndie_examples = X_reduced.query(\"label == 'die'\")\n\n\nplt.figure(figsize=(16, 10))\nplt.scatter(live_examples['PC1'], live_examples['PC2'], c='pink', label=\"Live\")\nplt.scatter(die_examples['PC1'], die_examples['PC2'], c='purple', label=\"Die\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"Class Visualization\")\nplt.legend()\nplt.show()","337dc557":"# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n\n# Scale X\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)","9e0ef25c":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {:.2f}%\".format(model.score(X_test, y_test) * 100))","1eb36ce8":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/rWZo8FrIlUQ","5a26be3c":"# Training","f24ece84":"# Preprocessing","5ed3d3c8":"# Getting Started","a34125c8":"# Clustering","d0d63746":"# Task for Today  \n\n***\n\n## Hepatitis Survival Classification  \n\nGiven *medical hepatitis patient data*, let's try to predict whether a given patient will **survive** or not.\n\nWe will cluster the data using k-means and use a random forest classification model to make our predictions."}}