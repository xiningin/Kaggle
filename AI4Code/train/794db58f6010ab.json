{"cell_type":{"27657ef6":"code","42cf2c2d":"code","4be31ebd":"code","4a236039":"code","ec779610":"code","aca7f373":"code","f559388b":"code","5f1ee772":"code","2dd991f8":"code","504117e4":"code","4653ec0a":"code","e759ef9d":"code","e39da9ac":"code","4f5a8851":"code","13397b7d":"markdown","6300c2bc":"markdown","8e7c5d6b":"markdown","89ad7fd8":"markdown","5c4c2209":"markdown","e7c6babb":"markdown","9c99fabb":"markdown","90712f18":"markdown","5e2882a6":"markdown","4e4a0a1b":"markdown","9beaeccf":"markdown","e92da5de":"markdown"},"source":{"27657ef6":"#%tensorflow_version 2.x #only exists in Colab.","42cf2c2d":"# import libraries\nimport math, re, os\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport IPython.display as display\n#from kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","4be31ebd":"# In this notebook, We have only considered image data so, two image files are used.\ncat_in_snow  = tf.keras.utils.get_file('320px-Felis_catus-cat_on_snow.jpg', 'https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/320px-Felis_catus-cat_on_snow.jpg')\nwilliamsburg_bridge = tf.keras.utils.get_file('194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg','https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')","4a236039":"# checking the image file\ndisplay.display(display.Image(filename=cat_in_snow))\ndisplay.display(display.HTML('Image cc-by: <a \"href=https:\/\/commons.wikimedia.org\/wiki\/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka<\/a>'))","ec779610":"# checking the image file\ndisplay.display(display.Image(filename=williamsburg_bridge))\ndisplay.display(display.HTML('<a \"href=https:\/\/commons.wikimedia.org\/wiki\/File:New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\">From Wikimedia<\/a>'))","aca7f373":"# The following functions can be used to convert a value to a type compatible\n# with tf.Example.\n\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","f559388b":"# create a dictionary to map classes to images, \n# this will be helpful when we use image classification algorithm on dataset\nimage_labels = {\n    cat_in_snow : 0,\n    williamsburg_bridge : 1,\n}\n\n# Create a function to apply entire process to each element of dataset.\n# process the two images into 'tf.Example' messages.\ndef image_example(image_string, label):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n  # Create a dictionary mapping the feature name to the tf.Example-compatible\n  # data type.\n  image_feature_description = {\n      \"image\": _bytes_feature(image_string),\n      \"class\": _int64_feature(label),\n      }\n  # Create a Features message using tf.train.Example.\n  return tf.train.Example(features=tf.train.Features(feature=image_feature_description))","5f1ee772":"# define a filename to store preprocessed image data:\nrecord_file = 'images.tfrecords'\n# Write the `tf.Example` observations to the file.\nwith tf.io.TFRecordWriter(record_file) as writer:\n  for filename, label in image_labels.items():\n    image_string = open(filename, 'rb').read()\n    # storing all the features in the tf.Example message.\n    tf_example = image_example(image_string, label)\n    # write the example messages to a file named images.tfrecords\n    writer.write(tf_example.SerializeToString())","2dd991f8":"# checking if file is written\n!du -sh {record_file}","504117e4":"# to read TFRecord file use TFRecordDataset\nraw_image_dataset = tf.data.TFRecordDataset(record_file)\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n\n# create a function to apply image feature description to each observation\ndef _parse_image_function(example_proto):\n  # parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\n# use map to apply this operation to each element of dataset\nparsed_image_dataset = raw_image_dataset.map(_parse_image_function)","4653ec0a":"# Use the .take method to only pull one example from the dataset.\nfor image_features in parsed_image_dataset.take(1):\n  image = image_features['image'].numpy()\n  display.display(display.Image(data=image))\n  classes = image_features['class'].numpy()\n  print('The label of image is', classes)","e759ef9d":"file = '..\/input\/flower-classification-with-tpus\/tfrecords-jpeg-192x192\/train\/00-192x192-798.tfrec'","e39da9ac":"# on \n# to read TFRecord file use TFRecordDataset\nraw_image_dataset = tf.data.TFRecordDataset(file)\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n\n# create a function to apply image feature description to each observation\ndef _parse_image_function(example_proto):\n  # parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\n# use map to apply this operation to each element of dataset\nparsed_image_dataset = raw_image_dataset.map(_parse_image_function)","4f5a8851":"# Use the .take method to only pull one example from the dataset.\nfor image_features in parsed_image_dataset.take(1):\n  image = image_features['image'].numpy()\n  display.display(display.Image(data=image))\n  classes = image_features['class'].numpy()\n  print('The label of image is', classes)","13397b7d":"TFRecord Format:\n===\nIn this competition we're classifying 104 types of flowers based on their images drawn from five different public datasets. This competition is different in that images are provided in TFRecord format.\n\nTo make things easier, it will be better if we have basic understanding of dataset and how to experiment with different methods faster even on Google Colab without limiting yourself.","6300c2bc":"Faster training on TPU:\n===\nAccoring to Google's team behind Colab's free TPU:\n>\"Artificial neural networks based on the AI applications used to train the TPUs are 15 and 30 times faster than CPUs and GPUs!\"\n\nSo, how can we do that; As per my experimentation, when you use CPU and GPU static shape is not that important, but incase of XLA\/TPU static shape and batch size makes a very big difference.\n\nHence, if you use static input batch_size i.e., train the TPU model with static batch_size*8 (number of TPU cores). The epoch time reduced to 20%-50% as compared to training model on GPU. Since colab TPU has 8 TPU cores which operates as independent processing units.","8e7c5d6b":"Hence, The process of serializing data into TFRecord format will be: \n**Data -> FeatureSet (a dictionary of features)-> Example -> Serialized Example -> TFRecord.**\n\nand to read it back, the process is reversed.\n**TFRecord -> SerializedExample -> Example -> FeatureSet -> Data**","89ad7fd8":"## Setup","5c4c2209":"Writing and Reading a TFRecord file\n===\nIn practice, There are different types of input data but the process of creating a TFRecord file will be the same for each type of dataset:\n\n1. Within each observation, each value needs to be converted to a `tf.train.Feature` containing one of the 3 compatible types, BytesList, FloaList,and Int64List. These are not python data types but tf.train.Feature types, that are used to store python data in compatible formats for TensorFlow operations.\n\n1. You create a map (dictionary) from the feature name string to the encoded feature value produced in #1.\n\n1. The map produced in step 2 is converted to a [`Features` message](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/core\/example\/feature.proto#L85).\n\n1. Write the `tf.Example` observations to the TFRecord file","e7c6babb":">**Aknowledgement**  \nTensorFlow core team did a great job sharing tutorials on TFRecord.  \nhttps:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord  \nhttps:\/\/codelabs.developers.google.com\/codelabs\/keras-flowers-data","9c99fabb":"### On Flower Classification with TPUs\n","90712f18":"References:\n===\n1. https:\/\/www.dlology.com\/blog\/how-to-train-keras-model-x20-times-faster-with-tpu-for-free\/\n\n1. https:\/\/codelabs.developers.google.com\/codelabs\/keras-flowers-data\/#4\n\n1. https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord\n\n1. https:\/\/www.skcript.com\/svr\/why-every-tensorflow-developer-should-know-about-tfrecord\/","5e2882a6":"# Overview\nThis notebook describes all the different elements of TFRecord format. Obviously, to cover everything, it has to be fairly long. I have only covered the basics on using TFRecord on image data. I will be updating it in few weeks and I encourage everyone to read Tensorflow core tutorials as it has covered all the concpets thoroughly.","4e4a0a1b":"In order to convert python data type to a standard TensorFlow type tf.train.Feature, we will use the functions below. Each of these functions takes scalar input value and returns a tf.train.Feature","9beaeccf":"# What is TFRecord?\n> As per Tensorflow's documentation, \" ... approach is to convert whatever data you have into a supported format. This approach makes it easier to mix and match data sets and network architectures. The recommended format for TensorFlow is a TFRecords file containing tf.train.Example protocol buffers (which contain Features as a field).\"\n\nIn Layman's terms, The TFRecord format is a simple format for storing a sequence of binary records.\n\nSo, why we even need a container for our image dataset we can simply extract our image into folder, read them into ram and then run, any image classification techniques. Well, There are plenty of reasons:\n1.  Suppose you are experimenting with different image classification algorithms it is beneficial to do basic preprocessing and convert data into format that is faster to load. TFRecord makes that job easier. You can preprocess data and then convert it into TFRecord file. It will save your time and all you need to do read TFRecord file without any preprocessing and then, you can test your ideas on that dataset much faster without going to same step every time.\ne.g., for pandas it is hdf5 files and for numpy it is npy, similarly for tensorflow, it is tfrecord files.\n\n2. To dynamically shuffle at random places and also change the ratio of train:test:validate from the whole dataset. When you are working with an image dataset, what is the first thing you do? Split into Train, Test, Vaildate, sets, and then shuffle to not have any biased data distribution. In case of TFRecord, everything is in a single file and we can use that file to shuffle our dataset.\n","e92da5de":"Conclusion\n===\nThis is just a first cut notebook on using tfrecord format. Also more rigorous experiment can be done and heuristics can be explored for faster preprocessing and training. I hope this helped you in understanding of using TensorFlow's TFRecords.\n\nComments, suggestions, criticism are welcomed. Thanks\n\n### To be continued ................\n"}}