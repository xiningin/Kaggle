{"cell_type":{"e7ab9850":"code","e094fd78":"code","e5e9f2e3":"code","5110b968":"code","e47d3e05":"code","03095f9f":"code","168cde5f":"code","91582542":"code","126d70f3":"code","41628397":"code","31d8a462":"code","361dca57":"code","92d5f043":"code","ea33ab8f":"code","140c3f5b":"code","06218016":"code","654562f4":"code","b23988a5":"code","febd6ca4":"code","5e375bba":"code","d0611b13":"code","9f9c4c0d":"code","7a051fe0":"code","eefad77e":"code","b6bf3c58":"code","e31ca8e7":"code","9a05fcd6":"code","290b1144":"code","b5f0958a":"code","90fabee9":"code","12218fb6":"code","3b7b2d78":"code","1991d863":"code","c4e857bf":"code","c52c6bcc":"code","8c8cdfc4":"code","0c92c3d1":"code","172b6e63":"code","8f984268":"code","44b15e57":"code","582bf389":"code","6c40ddba":"code","a6ca6e5d":"code","80836418":"code","484a3331":"code","c9b44c29":"code","9442d90f":"code","e4e39d43":"code","71eaa6d7":"code","d8e62e46":"code","34292e64":"code","150545ec":"code","4b7294e3":"code","eccb627d":"code","befa7839":"code","360944ef":"code","cc2f7bfb":"code","fd863bcc":"code","67edb44f":"code","f15ee2c2":"code","e1c0bacf":"code","c6d10381":"code","b5ec911f":"code","201f7f92":"code","e6ea525d":"code","4625fc37":"code","38b92697":"code","12697d50":"code","07299961":"code","4edcc8f7":"code","032fb3d3":"code","59edd2e4":"code","4f4faefd":"code","78f1998e":"code","25011750":"code","de4b5f5d":"code","77505569":"code","540e3560":"code","b20d45a9":"code","471a220e":"code","43362d2c":"code","eeb28a2a":"code","72bf930c":"code","f763f9ce":"code","7430697e":"code","40bb275d":"code","3b9b220e":"code","604e8dbd":"code","a794b35f":"code","da3ef7c2":"code","c9686bc1":"code","003fa6f2":"code","003f8221":"code","ca63cbb8":"code","4e9916e6":"code","055e2ba6":"code","d6ee71b5":"code","33b935c4":"code","c0b890f0":"code","1e6c8f4b":"code","94653fba":"code","35a1aac5":"code","516ca69a":"code","5d3ce380":"code","24443b2e":"code","9829be80":"code","82accd8e":"code","7826958f":"code","f645ffa7":"code","bbf56a48":"code","1188cf3c":"code","a55fb24c":"code","198293b9":"code","9829559b":"code","ada29ca5":"code","70458d70":"code","0e620c89":"code","e499de1d":"code","019d6bf1":"markdown","492693ee":"markdown","141104ad":"markdown","9df8dae0":"markdown","946efc9f":"markdown","1eaef25a":"markdown","72ba7a4f":"markdown","73549b17":"markdown","7043e736":"markdown","c5a62389":"markdown","9a25e136":"markdown","3f37b787":"markdown","56e94d5d":"markdown","edcc56aa":"markdown","40080ed7":"markdown","6cd532e7":"markdown","4a9c98ad":"markdown","5a493df6":"markdown","164c0c29":"markdown","1704ba7e":"markdown","66ecd06e":"markdown","2f298704":"markdown","461b6715":"markdown","8eb539a1":"markdown","b64c18f2":"markdown","ebe6651c":"markdown","4a91037e":"markdown","ee66ab72":"markdown","ac4e1e28":"markdown","3b2f31c2":"markdown","3c7e40de":"markdown","3f641ca9":"markdown","6ac797a6":"markdown","c4849aca":"markdown","3785c009":"markdown","2017fb1f":"markdown","400f477f":"markdown","c3392d22":"markdown","e29bd3eb":"markdown","4b169f4f":"markdown","b19198b0":"markdown","a17df39f":"markdown","f73944ff":"markdown","741a7f05":"markdown","6a94c7ba":"markdown","61c67d9c":"markdown","76f4459f":"markdown","d47934cd":"markdown","39ccc338":"markdown","743bc4ee":"markdown"},"source":{"e7ab9850":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\nfrom datetime import datetime #datetime module\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e094fd78":"df = pd.read_csv(\"\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\ndf.head(10) # first 10 rows","e5e9f2e3":"df.info() # information about datas","5110b968":"df.tail() # default -> last 5 rows","e47d3e05":"df.columns # names of data columns","03095f9f":"df.count() # data count in columns","168cde5f":"df['Province\/State'].value_counts(sort=True,ascending=True) # sort Province\/State value in ascending order ","91582542":"df.size # returns size of dataframe which is equivalent to total number of elements. That is rows x columns.","126d70f3":"f,ax=plt.subplots(figsize=(12,12))\nsns.heatmap(df.corr(),annot=True,linewidth=.5,fmt='.1f',cbar=True,ax=ax)\nplt.show()","41628397":"df.Deaths.plot(kind = 'line', color = 'red',label ='Deaths',linewidth=1,alpha = 0.5,grid = True,linestyle = '--')\nplt.legend(loc='upper right') # puts label into plot\nplt.xlabel('x axis')    # name of xlabel\nplt.ylabel('y axis')    # name of xlabel\nplt.title('Line Plot')  # title of plot\nplt.show()","31d8a462":"df.plot(kind='scatter', x=\"Deaths\", y='Recovered', alpha=0.4, color='blue')\nplt.xlabel('Deaths') # name of xlabel\nplt.ylabel('Recovered') # name of ylabel\nplt.title('Deaths Recovered Scatter Plot') #title of plot\nplt.show()\n\n","361dca57":"df.Deaths.plot(kind = 'hist',bins = 100,figsize = (15,15))\nplt.title(\"Histogram\")\nplt.show()","92d5f043":"df.plot(x='ObservationDate',y='Recovered',color = 'green',label ='Recovered',linewidth=1,alpha = 0.5,grid = True,linestyle = '--')\nplt.title('', color='black')\nplt.xticks(rotation = 90) # rotates the labels 90 degrees.\n#plt.tight_layout() \nplt._show()","ea33ab8f":"#Other date plot\n'''df['ObservationDate'] = df['ObservationDate'].map(lambda x: datetime.strptime(str(x), '%m\/%d\/%Y'))\nx = df['ObservationDate']\ny = df['Recovered']\n\nplt.plot(x,y,color='pink')# plot\nplt.gcf().autofmt_xdate()# beautify the x-labels\nplt.show()'''","140c3f5b":"currency = {\n    \"Dolar\" : \"USD\",\n    \"T\u00fcrk Liras\u0131\" : \"TR\",\n    \"Euro\" : \"EUR\",\n    \"Sterlin\" : \"GBP\"\n}\nprint('My dictionary :',currency)\nprint(currency.keys())\nprint(currency.values())","06218016":"x = currency.get('Euro') # get 'Euro''s value\nprint(x)","654562f4":"for k,v in currency.items(): # print key and value in dictionary\n    print(k+' : '+v)","b23988a5":"if \"Sterlin\" in currency: # check 'Sterlin' in dictionary\n  print(\"Yes, 'Sterlin' is one of the keys in the currency dictionary\")","febd6ca4":"currency['Kanada Dolar\u0131']='CAD' # adding item\nprint(currency)","5e375bba":"#currency.clear() #remove dictionary\n#del currency # delete dictionary ","d0611b13":"df[:8] # 0-8 rows","9f9c4c0d":"#Filtering\nx = df['Deaths']>5000 \ndf[x]","7a051fe0":"df[(df['Recovered']>5000) & (df['Deaths']<500)]","eefad77e":"(df.groupby(['ObservationDate','Country\/Region']).sum().loc[lambda df: df['Deaths'] > 4000]) # data selection (date format -> %m %d %Y)","b6bf3c58":"df.sample(n=6, weights='Deaths') # selecting random samples","e31ca8e7":"i=0\n\nwhile True:\n    print(i,\"Data Science\")\n    i +=1\n    if i==6:\n        break    #break the loop","9a05fcd6":"#print columns names with while loop\ni=0\nwhile i<len(df.columns):\n    print(\"Column\",i, ':' ,df.columns[i])\n    i +=1\n","290b1144":"#print columns names with for loop\nfor col in df.columns:\n    print(col)","b5f0958a":"#For pandas we can achieve index and value\nfor index,value in df[['Province\/State']][0:5].iterrows():\n    print(index,\" : \",value)","90fabee9":"# iterate over rows with iterrows()\nfor index, row in df.head(6).iterrows():\n     # access data using column names\n     print(index+1, row['Province\/State'], row['Country\/Region'])","12218fb6":"#Create Tuple\nx = (\"C\",\"Java\",\"Python\")\n\nprint(x)","3b7b2d78":"x = (\"C\",\"Java\",\"Python\")\ny = list(x)\ny[0] = \"C++\"\nx = tuple(y)\n\nprint(x)","1991d863":"#Values of tuple with for loop\nfor i in x:\n    print(i)\n\nprint(\"\\n\")\n(l1,l2,l3)=x\nprint(\"Values:\",l1,l2,l3)","c4e857bf":"x = 2 #Global scope\n\ndef f(y):\n    result = y**x \n    return result\n\nprint(f(5))","c52c6bcc":"count = 1\n\ndef func():\n    for count in range(6):\n        count +=1\n    return count\n\nprint(count) # count = 1 global scope\nprint(func()) # count = 6 local scope\n","8c8cdfc4":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","0c92c3d1":"def function1(): # outer function\n    print (\"Hello from outer function\")\n    def function2(): # inner function\n        print (\"Hello from inner function\")\n    function2()\n\nfunction1()","172b6e63":"# example finding number's square with nested function\ndef func1(x):\n    def func2():\n        result = x**2\n        return result\n    return func2()\n\n#number = int(input(\"Please enter a number \")) with input value -> func1(number)\nprint(f\"{5}'s square =\",func1(5))","8f984268":"# default argument\ndef func(lang='Python'):\n    return lang\n\nprint(\"Programing language:\" ,func())\nprint(\"Programing language:\", func('C++'))","44b15e57":"# flexible arguments *args\ndef func(*args):\n    for i in args:\n        print(i)\n\nfunc(3,5,8,11)\nlist1=[1,2,3,4,5,6]\nfunc(list1)\nlist2=[1,2,3,4,5,6],[2,5,7,8,9,10]\nfunc(list2)","582bf389":"# flexible arguments **kwargs that is dictionary\ndef func(**kwargs):\n    for key, value in kwargs.items():\n        print(f\"{key} -> {value}\")\n        \nfunc(Class = 'Data Science', Part = '2')\n        ","6c40ddba":"# lambda function\nnegative = lambda x : -x\nprint(negative(5))\n\nresult = lambda a,b,c : a*b*c\nprint(result(2,5,10))","a6ca6e5d":"import math # for sqrt function\n\nnum_list=[0,4,16,36]\nfunc = map(lambda x:math.sqrt(x),num_list)\nprint(tuple(func))","80836418":"# iteration example\nsubject = \"DataScience\"\nit=iter(subject)\nprint(next(it))\nprint(next(it))\nprint(next(it))\nprint(next(it))\nprint(*it)","484a3331":"# zip example zip() -> zip lists\nlist1=[\"Dolar\",\"T\u00fcrk Liras\u0131\",\"Euro\",\"Sterlin\"]\nlist2=[\"USD\",\"TR\",\"EUR\",\"GBP\"]\nz = tuple(zip(list1,list2))\nprint(z)","c9b44c29":"un_zip = zip(*z)\nun_list1,un_list2 = tuple(un_zip)\nprint(un_list1)\nprint(un_list2)","9442d90f":"list1 = [1,2,5,8,14,21]\nlist2 = [print(f\"{i}: Odd\") if i%2!=0 else print(f\"{i}: Even\") for i in list1]","e4e39d43":"# list comprehension for covid_19_data dataset\nthreshold = sum(df.Deaths)\/len(df.Deaths) # average Deaths\nprint(\"Average Deaths:\",threshold) \n# List values between 60000 and 80000 according to deaths level(high or low)\ndf[\"Deaths_Level\"] = [\"High\" if i > threshold else \"Low\" for i in df.Deaths] \ndf.loc[60000:80000,[\"Deaths_Level\",\"Deaths\",\"Country\/Region\"]] ","71eaa6d7":"df.head(15) #first 15 data","d8e62e46":"df.tail(15) #last 15 data","34292e64":"df.shape # (row,column)","150545ec":"df.info() # information about datas","4b7294e3":"# For example lets look frequency of countries\nprint(df['Country\/Region'].value_counts(dropna =False))","eccb627d":"df.describe() # There may be problems with statistics account because there are too many 0 values.","befa7839":"df.mask(df == 0).describe() # 0 values are masked.","360944ef":"# For example: compare deaths covid-19 that are deaths_level high or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndf.boxplot(figsize=(15,15),column='Deaths',by = 'Deaths_Level') # There may be problems because there are too many 0 values and data.","cc2f7bfb":"# Firstly I create new data from covid_19 data to explain melt more easily.\ndata_new = df.loc[55591:55601]    # I only take 10 rows into new data\ndata_new","fd863bcc":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Country\/Region', value_vars= ['Deaths','Recovered'])\nmelted","67edb44f":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot_table(index = 'Country\/Region', columns = 'variable',values='value')","f15ee2c2":"data1 = df.head()\ndata2= df.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row # Concatenating data1 and data2 ","e1c0bacf":"data1 = df['Country\/Region'].tail()\ndata2= df['Deaths'].tail()\ndata3= df['Recovered'].tail()\nconc_data_col = pd.concat([data1,data2,data3],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col","c6d10381":"df.dtypes","b5ec911f":"# lets convert object(str) to categorical and float to int.\ndf['Deaths_Level'] = df['Deaths_Level'].astype('category')\ndf['Confirmed'] = df['Confirmed'].astype('int')\n\ndf.dtypes","201f7f92":"# Lets look at does covid_19 data have nan value\n# As you can see there are 68558 entries. However Province\/State has 44125 non-null object so it has 24433 null object.\ndf.info()","e6ea525d":"# Lets chech Province\/State\ndf[\"Province\/State\"].value_counts(dropna =False)\n# As you can see, there are 24433 NAN value","4625fc37":"# Lets drop nan values\ndata1=df   # also we will use df to fill missing value so I assign it to data1 variable\ndata1[\"Province\/State\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","38b92697":"# Lets check with assert statement\n# Assert statement:\nassert  df[\"Province\/State\"].notnull().all() # returns nothing because we drop nan values","12697d50":"df[\"Province\/State\"].fillna('empty',inplace = True)","07299961":"assert  df[\"Province\/State\"].notnull().all() # returns nothing because we do not have nan values","4edcc8f7":"# # With assert statement we can check a lot of thing. For example\nassert df.columns[0] == 'SNo' #True\n#assert df.Deaths_Level.dtypes == np.int #False","032fb3d3":"df[\"Province\/State\"].value_counts(dropna = False) # now there isn't nan value in table","59edd2e4":"# data frames from dictionary\nlanguage = [\"English\",\"German\",\"Turkish\"]\nlevel = [\"B2\",\"B1\",\"C2\"]\nlist_label = [\"language\",\"level\"]\nlist_col = [language,level]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\nprint(data_dict)\ndata = pd.DataFrame(data_dict)\ndata","4f4faefd":"# Add new columns with list comprehension \ndata[\"completed\"]=[\"Yes\" if i == \"C2\"  else \"No\" for i in data.level]\ndata","78f1998e":"# Broadcasting\ndata[\"necessary\"] = \"Yes\" #Broadcasting entire column\ndata","25011750":"# Plotting all data \ndata1 = df.loc[:,[\"Confirmed\",\"Deaths\",\"Recovered\"]]\ndata1.plot()\n# it is confusing","de4b5f5d":"# subplots\ndata1.plot(subplots = True)\nplt.show()","77505569":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Confirmed\",y = \"Deaths\",alpha=0.4,color=\"red\")\nplt.show()","540e3560":"# histogram plot  \ndata1.plot(kind = \"hist\",y = \"Deaths\",bins = 30,range= (0,500),density = True) # density was used instead of normed","b20d45a9":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Deaths\",bins = 50,range= (0,500),density = True,ax = axes[0],color=\"yellow\")\ndata1.plot(kind = \"hist\",y = \"Deaths\",bins = 50,range= (0,500),density = True,ax = axes[1],color=\"yellow\",cumulative = True) #cumulative total\nplt.savefig('graph.png')\nplt","471a220e":"df.describe()","43362d2c":"time_list = [\"2020-11-29\",\"2020-07-30\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","eeb28a2a":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# In order to practice lets take covid-19 data and add it a time list\ndata2 = df\ndatetime_object = pd.to_datetime(data2.ObservationDate) # convert ObservationDate that is object to pandas time series\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2.head(10)","72bf930c":"# Now we can select according to our date index\nprint(data2.loc[\"2020-06-11\"])\nprint(data2.loc[\"2020-06-11\":\"2020-07-30\"])","f763f9ce":"data2.resample(\"M\").mean() # average covid-19 results by months","7430697e":"#data2.resample(\"M\").first().interpolate(\"linear\")\n#data2.resample(\"M\").mean().interpolate(\"linear\")\n# we didn't use interpolate because data already include all months","40bb275d":"# read data\ndata = pd.read_csv(\"\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\ndata= data.set_index(\"SNo\")\ndata.head()","3b9b220e":"# indexing using square brackets\ndata[\"Country\/Region\"][55543]","604e8dbd":"# using column attribute and row label\ndata.Deaths[55543]","a794b35f":"# using loc accessor\ndata.loc[1,[\"Country\/Region\"]]","da3ef7c2":"# selecting only some columns\ndata[[\"Country\/Region\",\"Deaths\",\"Recovered\"]]","c9686bc1":"# difference between selecting columns: series and dataframes\nprint(type(data[\"Confirmed\"]))     # series\nprint(type(data[[\"Confirmed\"]]))   # data frames","003fa6f2":"# slicing and indexing series\ndata.loc[55000:55010,\"Country\/Region\":\"Deaths\"]   # 10 and \"Deaths\" are inclusive","003f8221":"# reverse slicing \ndata.loc[55010:55000:-1,\"Country\/Region\":\"Deaths\"]","ca63cbb8":"# from something to end\ndata.loc[55000:55010,\"Deaths\":] ","4e9916e6":"# creating boolean series\nboolean = data.Deaths > 40000\ndata[boolean]","055e2ba6":"# combining filters\nfirst_filter = data.Deaths < 5000\nsecond_filter = data.Recovered > 50000\ndata[first_filter & second_filter]","d6ee71b5":"# filtering column based others\ndata.Deaths[data.Recovered>20000]","33b935c4":"# plain python functions\ndef square(n):\n    return n**2\ndata.Confirmed.apply(square)","c0b890f0":"# or we can use lambda function\ndata.Confirmed.apply(lambda n : n**2)","1e6c8f4b":"# defining column using other columns\ndata[\"gap\"] = data.Recovered - data.Deaths\ndata.loc[55000:55010]","94653fba":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"Index\"\ndata.head()","35a1aac5":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,233710,2)\ndata3.head()","516ca69a":"# data= data.set_index(\"#\") or  data.index = data[\"#\"]","5d3ce380":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv(\"\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","24443b2e":"# Setting index : Country\/Region is outer Province\/State is inner index\ndata1 = data.set_index([\"Country\/Region\",\"Province\/State\"]) \ndata1.head(10000)","9829be80":"dic = {\"job\":[\"Engineer\",\"Engineer\",\"Chef\",\"Chef\"],\"gender\":[\"M\",\"F\",\"M\",\"F\",],\"experience\":[0,5,12,8],\"age\":[22,28,40,32]}\ndf = pd.DataFrame(dic)\ndf","82accd8e":"# pivoting\ndf.pivot(index=\"job\",columns = \"gender\",values=\"age\")","7826958f":"df1 = df.set_index([\"job\",\"gender\"])\ndf1","f645ffa7":"# level determines indexes\ndf1.unstack(level=0)","bbf56a48":"df1.unstack(level=1)","1188cf3c":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","a55fb24c":"df","198293b9":"pd.melt(df,id_vars=\"job\",value_vars=[\"age\",\"experience\"])","9829559b":"df","ada29ca5":"# according to job take means of other features\ndf.groupby(\"job\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","70458d70":"# we can only choose one of the feature\ndf.groupby(\"job\").age.max() ","0e620c89":"# Or we can choose multiple features\ndf.groupby(\"job\")[[\"age\",\"experience\"]].min() ","e499de1d":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"job\"] = df[\"job\"].astype(\"category\")\n#df.info()","019d6bf1":"## Default and Flexible Arguments","492693ee":"## Lambda Function","141104ad":"## User Defined Function","9df8dae0":"## Scope","946efc9f":"## Slicing Data Frame","1eaef25a":"In this output, we can see results 11.06.2020 and between 11.06.2020-30.07.2020","72ba7a4f":"# 3.Cleaning Data","73549b17":"## Categoricals and GroupBy","7043e736":"## Correlation Map","c5a62389":"## Pivoting Data","9a25e136":"**LINE PLOT**\n\nLine plot is better when x axis is time.","3f37b787":"## Diagnose Data for Cleaning ","56e94d5d":"## Concatenating Data","edcc56aa":"## Pivoting Data Frames","40080ed7":"# 1.Introduction to Python","6cd532e7":"## Statistical Exploratory Data Analysis","4a9c98ad":"## Melting Data Frames","5a493df6":"## Missing Data and Testing With Assert ","164c0c29":"## Matplotlib","1704ba7e":"## Resampling Pandas Time Series ","66ecd06e":"## Anonymous Function","2f298704":"**SCATTER PLOT**\n\nScatter is better when there is correlation between two variables.","461b6715":"## Stacking and Unstacking DataFrame","8eb539a1":"## Building Data Frames From Scratch","b64c18f2":"## Iterators","ebe6651c":"## Indexing Pandas Time Series","4a91037e":"## Tidy Data","ee66ab72":"## List Comprehension","ac4e1e28":"## Filtering Data Frames","3b2f31c2":"**HISTOGRAM**\n\nHistogram is better when we need to see distribution of numerical data.","3c7e40de":"## **Result**<br>\nAs a result, in this table we can see high deaths level in the US, UK and Italy compared to other countries. (because of Covid-19)","3f641ca9":"# 2.Python Data Science Toolbox","6ac797a6":"In these tables, we can see original data and the deaths level column we added in part 2.","c4849aca":"## Index Objects and Labeled Data","3785c009":"## Indexing Data Frames ","2017fb1f":"## Pandas","400f477f":"In this table, we can see deaths and recovered numbers by country\/region.","c3392d22":"## Nested Function","e29bd3eb":"## Data Types ","4b169f4f":"## Visual Exploratory Data Analysis","b19198b0":"## Hierarchical Indexing ","a17df39f":"## While and For Loops","f73944ff":"## Transforming Data","741a7f05":"# 4.Pandas Foundation","6a94c7ba":"# 5.Manipulating Data Frames with Pandas ","61c67d9c":"## Dictionary","76f4459f":"## Visual Exploratory Data Analysis","d47934cd":"## Reading Data\n","39ccc338":"## Exploratory Data Analysis (EDA)","743bc4ee":"**DATE PLOT**"}}