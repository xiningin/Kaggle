{"cell_type":{"d1572b21":"code","5e0261ac":"code","afe361d4":"code","0b398002":"code","8dbdb4f5":"code","450d356a":"code","7e77dfa8":"code","1cd7eb34":"code","d3abddb4":"code","cf3491e7":"code","4f724a3d":"code","63a1675f":"code","37f75dd8":"code","921ca18a":"code","49c4e091":"code","4e9aaf95":"code","80d40aa2":"code","236796d1":"code","d96362fa":"code","2868cd06":"code","d29c96c1":"code","2085d4ed":"code","0d7166c4":"code","e68a8a3b":"code","8f9c3932":"code","5e4911be":"code","1def8110":"code","1072dc5d":"code","13f61b87":"code","12f86700":"code","f5b1c340":"code","c0c6da25":"code","f952d4e7":"code","7d7a4004":"code","5a0aec88":"code","15bdd685":"code","582b1a93":"code","48d181f2":"code","04de5631":"code","2bc11191":"code","bdbdfcc6":"code","d8e42ce0":"code","3d257298":"code","91304587":"code","fb4d2d05":"code","85bd1771":"code","68351bda":"code","90c3dff1":"code","04283fa1":"code","7490fee8":"code","d30c4468":"markdown","60e11129":"markdown","98eb5e5e":"markdown","cf9d3cfb":"markdown","0d83e9f4":"markdown","2dd0e37a":"markdown","5624981b":"markdown","70e707a4":"markdown","18a89720":"markdown","d904e658":"markdown","dda36244":"markdown","e42d00ad":"markdown","858be721":"markdown","64ea530c":"markdown","5417bed1":"markdown","256cac4c":"markdown","c9a645df":"markdown","e2bfb534":"markdown","e4399aae":"markdown","af9e38cd":"markdown","0653d685":"markdown","f2f74402":"markdown","0b37cde2":"markdown"},"source":{"d1572b21":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\n\nmatplotlib.rcParams['figure.figsize'] = (12,8) # Default size of plot\nwarnings.filterwarnings('ignore') # Ignore all warnings sign\nsns.set_style('darkgrid') # Choose darkgrid theme","5e0261ac":"df = pd.read_csv('\/kaggle\/input\/student-grade-prediction\/student-mat.csv')","afe361d4":"df.head()","0b398002":"print(\"Row:\", df.shape[0])\nprint(\"Column:\", df.shape[1])","8dbdb4f5":"df.info()","450d356a":"df['age'].unique()","7e77dfa8":"df['sex'].unique()","1cd7eb34":"sns.kdeplot(df.groupby('sex').get_group('M')['age'], shade = True, label='male')\nsns.kdeplot(df.groupby('sex').get_group('F')['age'], shade = True, label='female')\nplt.xlabel('age range')\nplt.ylabel(\"% data distribution\")\nplt.legend()\nplt.show()","d3abddb4":"def create_sex_corr_plot(params):\n    sns.kdeplot(df.groupby('sex').get_group('M')[params], shade = True, label='male')\n    sns.kdeplot(df.groupby('sex').get_group('F')[params], shade = True, label='female')\n    plt.xlabel(f'{params} range')\n    plt.ylabel(\"% data distribution\")\n    plt.legend()\n    plt.show()","cf3491e7":"create_sex_corr_plot(\"studytime\")","4f724a3d":"create_sex_corr_plot(\"traveltime\")","63a1675f":"objects = df.dtypes=='object'\nobjects_col = objects[objects].index\nobj_col = list(objects_col)\nobj_col","37f75dd8":"plt.figure(figsize=(20,50))\nfor idx, name in enumerate(obj_col):\n    plt.subplot(9, 2, idx+1)\n    sns.countplot(df[name])\n    plt.title(name.title())\n    \nplt.show()","921ca18a":"# Father job\ndf.groupby(\"Fjob\")['G1'].median()","49c4e091":"# Mother job\ndf.groupby(\"Mjob\")['G1'].median()","4e9aaf95":"def common_comparison(params, grade='G1'):\n    order_by = df.groupby(params)[grade].median().sort_values(ascending = False).index\n    sns.boxplot(x = df[params], y = df[grade], order = order_by)\n    plt.xticks(rotation=90)\n    plt.title(f\"{params} v\/s {grade}\")","80d40aa2":"parents_job = ['Fjob', 'Mjob']\n\nplt.figure(figsize=(15,10))\n\nfor idx, name in enumerate(parents_job):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name)\n\nplt.show()\n\nplt.figure(figsize=(15,10))\n    \nfor idx, name in enumerate(parents_job):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name, 'G2')\n    \nplt.show()\n\nplt.figure(figsize=(15,10))\n    \nfor idx, name in enumerate(parents_job):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name, 'G3')\n    \nplt.show()","236796d1":"parents_edu = ['Fedu', 'Medu']\n\nplt.figure(figsize=(15,10))\n\nfor idx, name in enumerate(parents_edu):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name)\n    plt.xticks(rotation=0)\n\nplt.show()\n\nplt.figure(figsize=(15,10))\n\nfor idx, name in enumerate(parents_edu):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name, 'G2')\n    plt.xticks(rotation=0)\n\nplt.show()\n\nplt.figure(figsize=(15,10))\n\nfor idx, name in enumerate(parents_edu):\n    plt.subplot(1, 2, idx+1)\n    common_comparison(name, 'G3')\n    plt.xticks(rotation=0)\n\nplt.show()","d96362fa":"obj_col_2 = ['schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']","2868cd06":"plt.figure(figsize=(15,15))\n\nfor idx, name in enumerate(obj_col_2):\n    plt.subplot(2,4,idx+1)\n    common_comparison(name)\n\nplt.show()","d29c96c1":"# Data split\nfrom sklearn.model_selection import train_test_split\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n# Support Vector Regression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\n\n# Polynomial Regression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Metrics Accuracy\nfrom sklearn.metrics import r2_score","2085d4ed":"df_ml = df[['studytime', 'failures', 'Dalc', 'Walc', \n            'health', 'absences', 'traveltime', \n            'G1', 'G2', 'G3']]","0d7166c4":"X_rf = df_ml.iloc[:, :-1].values\ny_rf = df_ml.iloc[:, -1].values","e68a8a3b":"X_train, X_test, y_train, y_test = train_test_split(X_rf, y_rf, test_size = 0.3, random_state = 0)","8f9c3932":"rf_model = RandomForestRegressor(n_estimators=10, random_state=0)\nrf_model.fit(X_train, y_train)","5e4911be":"y_rf_pred = rf_model.predict(X_test)","1def8110":"rf_score = (r2_score(y_test, y_rf_pred))","1072dc5d":"print(\"Random Forest Score:\", rf_score)","13f61b87":"X_lr = df_ml.iloc[:, :-1].values\ny_lr = df_ml.iloc[:, -1].values","12f86700":"X_train, X_test, y_train, y_test = train_test_split(X_lr, y_lr, test_size=0.3, random_state=0)\n\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\n\ny_lr_pred = lr_model.predict(X_test)","f5b1c340":"lr_score = (r2_score(y_test, y_lr_pred))","c0c6da25":"print(\"Linear Regression Score:\", lr_score)","f952d4e7":"X_svr = df_ml.iloc[:, :-1].values\ny_svr = df_ml.iloc[:, -1].values\ny_svr = y_svr.reshape(len(y_svr), 1)","7d7a4004":"X_train, X_test, y_train, y_test = train_test_split(X_svr, y_svr, test_size=0.30, random_state=0)","5a0aec88":"# There must be two scaler, because it contains different value\nscaler_x = StandardScaler()\nscaler_y = StandardScaler()\n\nX_train = scaler_x.fit_transform(X_train)\ny_train = scaler_y.fit_transform(y_train)","15bdd685":"svr_model = SVR(kernel = 'rbf')\nsvr_model.fit(X_train, y_train.ravel()) ","582b1a93":"y_svr_pred = scaler_y.inverse_transform(svr_model.predict(scaler_x.transform(X_test)))","48d181f2":"svr_score = (r2_score(y_test, y_svr_pred))","04de5631":"print(\"Support Vector Regression Score:\", svr_score)","2bc11191":"X_train, X_test, y_train, y_test = train_test_split(X_lr, y_lr, test_size=0.3, random_state=0)","bdbdfcc6":"pr_models = PolynomialFeatures(degree=2)\nX_poly = pr_models.fit_transform(X_lr)\npr_model = LinearRegression()\npr_model.fit(X_poly, y_lr)","d8e42ce0":"y_pr_pred = pr_model.predict(pr_models.fit_transform(X_test))","3d257298":"pr_score = (r2_score(y_test, y_pr_pred))","91304587":"print(\"Polynomial Regression Score:\", pr_score)","fb4d2d05":"model_data = [['Random Forest', rf_score], ['Linear Regression', lr_score], \n             ['Support Vector Regression', svr_score], ['Polynomial Regression', pr_score]]","85bd1771":"df_model = pd.DataFrame(model_data, columns=['Algorithm', 'Score'])","68351bda":"df_model","90c3dff1":"df_model['Score'] = df_model.Score.round(2)","04283fa1":"df_model.sort_values(by='Score', ascending=False)","7490fee8":"algorithm = list(df_model.Algorithm)\nscore = list(df_model.Score)\n\nx = np.arange(len(algorithm))\nwidth = 0.5\n\nfig, ax = plt.subplots()\nfig.set_figheight(10)\nfig.set_figwidth(12)\nax.set_title(\"Algorithm Comparison In Grade Predictions\")\nax.set_xlabel(\"Algorithm\")\nax.set_ylabel(\"Score\")\nax.set_xticks(x)\nax.set_xticklabels(algorithm)\n\nalgo_frame = ax.bar(x, score, width, label='Algorithm')\nfor algo in algo_frame:\n    height = algo.get_height()\n    ax.annotate(\"{}\".format(height),\n                xy = (algo.get_x() + algo.get_width() \/ 2, height),\n                xytext = (0,3),\n                textcoords=\"offset points\",\n                ha='center', va='bottom')\n    \nplt.show()","d30c4468":"### Explicit: Finding sex correlation function\n\nCreating Function to make ploting easier","60e11129":"### 1.4 Sex & Study Time Correlation","98eb5e5e":"### 2.4 Support Vector Regression","cf9d3cfb":"As we can see together, the best algorithm to predict grade score in this case is Random Forest with 0.87 in the predictions","0d83e9f4":"### 1.8 Medain ","2dd0e37a":"### 1.5 Sex & Travel Time Correlation","5624981b":"Thanks and happy learning!!!\n\nHave a Nice Code :)","70e707a4":"### 2.6 Model Comparison","18a89720":"### Explicit: Comparing common function","d904e658":"### 2.5 Polynomial Regression","dda36244":"## 2. Machine Learning Comparison","e42d00ad":"### 1.7 Parents & Grade Correlation","858be721":"From the graph we can understand that student range is around 14 until 22. \n\nIn average, female student is more than male student","64ea530c":"It will reuse the linear regression data","5417bed1":"# ML Starter in Grade Prediction\n\nI was newbie and data science and still like to follow along tutorial.\n\nThis notebook is combination from two person:\n\n1. [yashtiwari1906](https:\/\/www.kaggle.com\/yashtiwari1906)\n2. [Raphael Blaise](https:\/\/www.kaggle.com\/koalablaize)\n\nThanks!!!","256cac4c":"### 1.3 Sex & Age Correlation","c9a645df":"### 1.2 Explore dataset","e2bfb534":"### 2.3 Linear Regression","e4399aae":"## 1. Analyzing the Data","af9e38cd":"### 1.1 Import module & dataset","0653d685":"### 1.6 Comparing object data","f2f74402":"### 2.2 Random Forst Regression","0b37cde2":"### 2.1 Import Important Module"}}