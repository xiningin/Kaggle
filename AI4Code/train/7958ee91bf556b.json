{"cell_type":{"e07c102d":"code","2f321889":"code","7966787d":"code","e2e67aed":"code","7c7951e2":"code","f3498d03":"code","8b2ce33c":"code","432a81f0":"code","07575073":"code","b8ea9411":"code","69af36c7":"code","d27622f5":"code","c7c22fef":"code","eec60b7a":"code","54df00f8":"code","20ca998b":"code","be8fc4b7":"code","af1029e6":"code","5392cd9d":"code","2f277f72":"code","f0cf6003":"code","75fbf8fc":"code","7a669fed":"code","558cdb4e":"code","b656f9c1":"code","42a72f77":"code","17c6f515":"code","9bd3d227":"code","22998bc5":"code","8243156c":"code","a8e7c105":"code","b2d7f74a":"code","681e63c9":"code","ea5bd253":"code","e7b19a47":"code","2235cfdd":"code","d25c92e2":"code","6a1294ae":"code","810e91b0":"code","c1234747":"code","ccaa2e5a":"code","7e32cfa9":"code","990e1e23":"code","b5d808b0":"code","9ccb46a3":"code","480ea81e":"code","f7f0c2af":"code","17bb6658":"markdown","c21abf05":"markdown","a82635fd":"markdown","f26940eb":"markdown","cbc7a0ae":"markdown","265ff341":"markdown","ab80c988":"markdown","ea6fdc42":"markdown","f9d237ca":"markdown","b7e92327":"markdown","2812de17":"markdown","39097fc6":"markdown","e236c86b":"markdown","bf10d17d":"markdown","bf946f11":"markdown","7d232ca6":"markdown","ecbaf22a":"markdown","9fb468c9":"markdown","e255e9a6":"markdown","3c62357b":"markdown","473e1bc1":"markdown","c7d7f398":"markdown","45248e20":"markdown","d3b1f933":"markdown","f4b545c9":"markdown","95868530":"markdown","1eeaef7e":"markdown","d57540b0":"markdown","1fdb5dce":"markdown"},"source":{"e07c102d":"import numpy as np\nimport pandas as pd\nimport matplotlib as mt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n# plt.style.use('seaborn-notebook')\nsns.set_style(\"darkgrid\")\nimport re\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport warnings \nwarnings.filterwarnings('ignore')\n","2f321889":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n# gender = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n","7966787d":"display(train_data.head())","e2e67aed":"test_data.head()","7c7951e2":"train_data.info()","f3498d03":"train_data.isnull().sum()","8b2ce33c":"test_data.isnull().sum()","432a81f0":"corr = train_data.corr()\ncorr['Age']","07575073":"age_by_pclass_sex = train_data.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(train_data['Age'].median()))\n\n# Filling the missing values in Age with the medians of Sex and Pclass groups\ntrain_data['Age'] = train_data.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","b8ea9411":"age_by_pclass = test_data.groupby(['Pclass','Sex']).median()['Age']\n\nfor i in range(1,4):\n    for j in ['female','male']:\n        print(f\"Median of Passenger class {i} {j} : {age_by_pclass[i][j]}\")\n\ntest_data['Age'] = test_data.groupby(['Pclass','Sex'])['Age'].apply(lambda x: x.fillna(x.median()))","69af36c7":"train_data['Embarked'] = train_data['Embarked'].fillna(np.array(train_data.Embarked.mode())[0])","d27622f5":"corr['Fare']","c7c22fef":"test_data['Fare'] = test_data.groupby(['Pclass'])['Fare'].apply(lambda x: x.fillna(x.median()))","eec60b7a":"# df_new['HasCabin'] = df_complete[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n# Replace missing values with 'U' for Cabin\ntrain_data['Cabin'] = train_data['Cabin'].fillna('U')\ntest_data['Cabin'] = test_data['Cabin'].fillna('U')\n# Extract first letter\ntrain_data['Cabin'] = train_data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntest_data['Cabin'] = test_data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ncabin_category = {'A':9, 'B':8, 'C':7, 'D':6, 'E':5, 'F':4, 'G':3, 'T':2, 'U':1}\n# Mapping 'Cabin' to group\ntrain_data['Cabin'] = train_data['Cabin'].map(cabin_category)\ntest_data['Cabin'] = test_data['Cabin'].map(cabin_category)","54df00f8":"df_train = train_data\ndf_test = test_data","20ca998b":"# color palette for visualizations\ncolors = ['#EEEEEE','#F8485E','#00C1D4','#512D6D','black']\npalette = sns.color_palette( palette = colors)\n\nsns.palplot(palette,size=3)\nplt.text(-0.75,-0.75,'Color Palette for this Visualization', {'fontname':'serif', 'size':25, 'weight':'bold'})\nplt.text(-0.75,-0.64,'Mostly same colors will be used for throughout this notebook.', {'fontname':'serif', 'size':18, 'weight':'normal'}, alpha = 0.8)\nplt.show()","be8fc4b7":"\nx = pd.DataFrame( df_train.groupby(['Survived'])['Survived'].count())\n\n# plot\nfig, ax = plt.subplots(figsize = (7,6), dpi=70 )\nax.barh([0], x.Survived[0], height = 0.7, color = colors[1])\nplt.text(-210,-0.08, 'Not Survived',{'fontname': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':colors[1]})\nplt.text(590,-0.08, '62%',{'fontname':'Serif','weight':'bold' ,'size':'16','color': colors[1]})\nax.barh([1], x.Survived[1], height = 0.7, color = colors[3])\nplt.text(-210,1, 'Survived', {'fontname': 'Serif','weight':'bold','Size': '16','style':'normal', 'color': colors[3]})\nplt.text(390,1, '38%',{'fontname':'Serif', 'weight':'bold','size':'16','color':colors[3]})\n\nfig.patch.set_facecolor('white')\nax.set_facecolor('white')\n\nplt.text(-150,1.77, 'Percentage of People surviving' ,{'fontname': 'Serif', 'Size': '25','weight':'bold', 'color':'black'})\nplt.text(450,1.55, 'Not Survived ', {'fontname': 'Serif','weight':'bold','Size': '14','weight':'bold','style':'normal', 'color':colors[1]})\nplt.text(610,1.55, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nplt.text(630,1.55, 'Survived', {'fontname': 'Serif','weight':'bold', 'Size': '14','style':'normal', 'weight':'bold','color':colors[3]})\n\nax.axes.get_xaxis().set_visible(False)\nax.axes.get_yaxis().set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(True)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)","af1029e6":"df_train.isnull().sum()","5392cd9d":"data_vis = df_train.drop(['PassengerId'],axis=1)\ndied = data_vis[data_vis.Survived == 0]\nsurvived = data_vis[data_vis.Survived == 1]","2f277f72":"fig = plt.figure(figsize = (24,10))\n\nspec = fig.add_gridspec(10,24)\n\nax1 = fig.add_subplot(spec[1:4,:8])\nax2 = fig.add_subplot(spec[6:9,:8 ])\nax3 = fig.add_subplot(spec[1:10,13:])\n\n# axes list\naxes = [ ax1,ax2, ax3]\n\n# setting of axes; visibility of axes and spines turn off\nfor ax in axes:\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_facecolor(colors[0])\n    \n    for loc in ['left', 'right', 'top', 'bottom']:\n        ax.spines[loc].set_visible(False)\n\nfig.patch.set_facecolor(colors[0])\n        \nax3.axes.get_xaxis().set_visible(True)\nax3.axes.get_yaxis().set_visible(True)\n\n\n# kdeplot for Age feature\n\nsns.kdeplot(data_vis[\"Age\"], shade = True,ax = ax1,color = colors[3],alpha =1,legend=False)\nax1.set_xlabel('Age of a person', fontdict = {'fontname':'Serif', 'color': 'black', 'size': 16,'weight':'bold' })\nax1.text(-17,0.075,'Overall Age Distribution - How skewed is it?', {'fontname':'Serif', 'color': 'black','weight':'bold','size':24}, alpha = 0.9)\nax1.text(-17,0.055, 'Based on Age we have data from infants to elderly people.\\nYoung Adult population is the median group.', \n        {'fontname':'Serif', 'size':'16','color': 'black'})\n\n# # distribution of Age with respect to Survived feature\n\nsns.kdeplot(died.Age,ax = ax2, shade = True,  alpha = 1, color = colors[3],legend=False)\nsns.kdeplot(survived.Age,ax = ax2, shade = True,  alpha = 0.8, color = colors[1],legend=False)\nax2.set_xlabel('Age of a person', fontdict = {'fontname':'Serif', 'color': 'black', 'weight':'bold','size': 16})\n\nax2.text(-17,0.0525,'Who is more safe - Young or Old?', {'fontname':'Serif', 'weight':'bold','color': 'black', 'size':24}, alpha= 0.9)\nax2.text(80,0.043, 'Not Survived', {'fontname': 'Serif','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':colors[3]})\nax2.text(112,0.043, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nax2.text(115,0.043, 'Survived', {'fontname': 'Serif','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':colors[1]})\n\n# distplot\nsns.distplot(died['Age'], label='Not Survived', hist=True, color = colors[3], ax=ax3)\nsns.distplot(survived['Age'], label='Survived', hist=True, color = colors[1], ax=ax3)\nax3.text(-10,0.08, 'Data is not skewed and young adults have highest \\nchacnes of surviving ', {'fontname': 'Serif','weight':'bold','Size': '25','weight':'bold','style':'normal', 'color': 'black'})\nax3.text(80,0.07, 'Not Survived', {'fontname': 'Serif','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':colors[3]})\nax3.text(105,0.07, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nax3.text(110,0.07, 'Survived', {'fontname': 'Serif','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':colors[1]})\n\nfig.text(0.5,1,'Survival of the Youngest ?? True or False?',{'fontname':'Serif', 'weight':'bold','color': 'black', 'size':35})\nfig.show()\n","f0cf6003":"fig = plt.figure(figsize = (24,10))\n\nspec = fig.add_gridspec(10,24)\n\nax1 = fig.add_subplot(spec[1:4,:8])\nax2 = fig.add_subplot(spec[6:9,:8 ])\nax3 = fig.add_subplot(spec[1:10,13:])\n\n# axes list\naxes = [ ax1,ax2, ax3]\n\n# setting of axes; visibility of axes and spines turn off\nfor ax in axes:\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_facecolor(colors[0])\n    \n    for loc in ['left', 'right', 'top', 'bottom']:\n        ax.spines[loc].set_visible(False)\n\nfig.patch.set_facecolor(colors[0])\n        \nax3.axes.get_xaxis().set_visible(True)\nax3.axes.get_yaxis().set_visible(True)\n\n\n# kdeplot for Age feature\n\nsns.kdeplot(data_vis['Fare'] , shade = True,ax = ax1,color = colors[3],alpha =1,legend=False)\nax1.set_xlabel('Fare', fontdict = {'fontname':'Serif', 'color': 'black', 'size': 16,'weight':'bold' })\nax1.text(-17,0.045,'Overall Fare Distribution - How skewed is it?', {'fontname':'Serif', 'color': 'black','weight':'bold','size':24}, alpha = 0.9)\n\n# distribution of Age with respect to Survived feature\n\nsns.kdeplot(died['Fare'],ax = ax2, shade = True,  alpha = 1, color = colors[3],legend=False )\nsns.kdeplot(survived['Fare'],ax = ax2, shade = True,  alpha = 0.8, color = colors[1],legend=False)\nax2.set_xlabel('Fare of a Person', fontdict = {'fontname':'Serif', 'color': 'black', 'weight':'bold','size': 16})\n\nax2.text(-17,0.0555,'High Fare or Low Fare?', {'fontname':'Serif', 'weight':'bold','color': 'black', 'size':24}, alpha= 0.9)\nax2.text(150,0.033, 'Not Survived', {'fontname': 'Serif','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':colors[3]})\nax2.text(340,0.033, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nax2.text(370,0.033, 'Survived', {'fontname': 'Serif','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':colors[1]})\n\n# distplot\nsns.distplot(died['Fare'], label='Not Survived', hist=True ,color = colors[3], ax=ax3)\nsns.distplot(survived['Fare'], label='Survived', hist=True,color = colors[1], ax=ax3)\nax3.text(-10,0.099, 'Highly skewed left ', {'fontname': 'Serif','weight':'bold','Size': '25','weight':'bold','style':'normal', 'color': 'black'})\nax3.text(190,0.088, 'Not Survived', {'fontname': 'Serif','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':colors[3]})\nax3.text(330,0.088, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nax3.text(350,0.088, 'Survived', {'fontname': 'Serif','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':colors[1]})\n\nfig.text(0.13,1,'Suvival of the Richest',{'fontname':'Serif', 'weight':'bold','color': 'black', 'size':35})\nfig.show()","75fbf8fc":"fig,axes = plt.subplots(5,2,figsize=(24,40))\ndied.Embarked.value_counts().plot(kind='pie',colors = colors ,ax=axes[0][0], fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Not Surviving based on Embarking place\")\nsurvived.Embarked.value_counts().plot(kind='pie',ax=axes[0][1],colors = colors, fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Surviving based on Embarking place\")\ndied.Pclass.value_counts().plot(kind='pie',ax=axes[1][0],colors = colors, fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Not Surviving based on Passenger Class\")\nsurvived.Pclass.value_counts().plot(kind='pie',ax=axes[1][1], colors= colors , fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Surviving based on Passenger Class\")\ndied.Parch.value_counts().plot(kind='pie',ax=axes[2][0], colors = colors ,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Not Surviving based on How many ParentChild boarded\")\nsurvived.Parch.value_counts().plot(kind='pie',ax=axes[2][1], colors = colors ,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Surviving based on How many ParentChild boarded\")\ndied.Sex.value_counts().plot(kind='pie',ax=axes[3][0], colors=colors,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Not Surviving based on Gender\")\nsurvived.Sex.value_counts().plot(kind='pie',ax=axes[3][1], colors=colors,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Surviving based on Gender\")\ndied.SibSp.value_counts().plot(kind='pie',ax=axes[4][0], colors=colors,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Not Surviving based on How many Siblings boarded\")\nsurvived.SibSp.value_counts().plot(kind='pie',ax=axes[4][1], colors=colors,fontsize=10, autopct='%1.0f%%',title=\"Pie Chart of People Surviving based on How many Siblings boarded\")\nfig.show()","7a669fed":"fig = plt.figure(figsize=(16,16))\nsns.heatmap(df_train.drop(['PassengerId'], axis=1).corr(), annot=True,square=True,cmap = mt.colors.LinearSegmentedColormap.from_list(\"\",colors) , annot_kws={'size': 14})\nplt.title(\"Correlation\")","558cdb4e":"df_comp = pd.concat([df_train,df_test])","b656f9c1":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\ndf_comp['Title'] = df_comp['Name'].apply(get_title)\ndf_comp['Title'] = df_comp['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndf_comp['Title'] = df_comp['Title'].replace('Mlle', 'Miss')\ndf_comp['Title'] = df_comp['Title'].replace('Ms', 'Miss')\ndf_comp['Title'] = df_comp['Title'].replace('Mme', 'Mrs')\ndf_comp['Title'] = LabelEncoder().fit_transform(df_comp['Title'])","42a72f77":"df_comp['Last_Name'] = df_comp['Name'].apply(lambda x: str.split(x, \",\")[0])\ndf_comp['Fare'].fillna(df_comp['Fare'].mean(), inplace=True)\n\nDEFAULT_SURVIVAL_VALUE = 0.5\ndf_comp['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in df_comp[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n                           'SibSp', 'Parch', 'Age']].groupby(['Last_Name', 'Fare']):\n    \n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                df_comp.loc[df_comp['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                df_comp.loc[df_comp['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      df_comp.loc[df_comp['Family_Survival']!=0.5].shape[0])","17c6f515":"for _, grp_df in df_comp.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    df_comp.loc[df_comp['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    df_comp.loc[df_comp['PassengerId'] == passID, 'Family_Survival'] = 0\n                        \nprint(\"Number of passenger with family\/group survival information: \" \n      +str(df_comp[df_comp['Family_Survival']!=0.5].shape[0]))","9bd3d227":"df_comp['Senior'] = df_comp['Age'].map(lambda s:1 if s>70 else 0)","22998bc5":"# Binning to deal with outliers and also to categorise the feature?\nbins_i = [-1, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550]\nlabels_i = [1,2,3,4,5,6,7,8,9,10,11]\n\ndf_train['stage'] = 0\ndf_train['stage'] = pd.cut(df_train.Fare, bins=bins_i, labels=labels_i)\n\ndf_test['stage'] = 0\ndf_test['stage'] = pd.cut(df_test.Fare, bins=bins_i, labels=labels_i)\n\ndf_train.stage.unique()\n","8243156c":"df_train.Fare = df_train.stage.astype(\"int64\")\ndf_test.Fare = df_test.stage.astype(\"int64\")\ndf_train.drop(\"stage\", axis=1, inplace=True)\ndf_test.drop(\"stage\", axis=1, inplace=True)","a8e7c105":"\ndf_train['Age'] = pd.qcut(df_train['Age'],4)\ndf_test['Age'] = pd.qcut(df_test['Age'],4)","b2d7f74a":"# Encoding the categorical features\ndf_comp['Fare'] = LabelEncoder().fit_transform(df_comp['Fare'])\ndf_comp['Age'] = LabelEncoder().fit_transform(df_comp['Age'])\ndf_comp['Sex'] = LabelEncoder().fit_transform(df_comp['Sex'])\n# Using highly correlated features to get new features\ndf_comp['P_fare'] = df_comp['Pclass'] * df_comp['Fare']\ndf_comp['P_Age'] = df_comp['Pclass'] * df_comp['Age']\ndf_comp['Fam'] = df_comp['Parch'] + df_comp['SibSp'] + 1\ndf_comp['Alone'] = [1 if i == 1 else 0 for i in df_comp['Fam']]\n# df_comp['SmallF'] = df_comp['Fam'].map(lambda s: 1 if  s == 2  else 0)\n# df_comp['MedF']   = df_comp['Fam'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# df_comp['LargeF'] = df_comp['Fam'].map(lambda s: 1 if s >= 5 else 0)\n# df_comp['FareCat_Sex'] = df_comp['Fare']*df_comp['Sex']\n# df_comp['Pcl_Sex'] = df_comp['Pclass']*df_comp['Sex']\n# df_comp['Pcl_Title'] = df_comp['Pclass']*df_comp['Title']\n# df_comp['Title_Sex'] = df_comp['Title']*df_comp['Sex']\ndf_comp['Fam'] = OneHotEncoder().fit_transform(df_comp['Fam'].values.reshape(-1,1)).toarray()\ndf_comp['Embarked'] = OneHotEncoder().fit_transform(df_comp['Embarked'].values.reshape(-1,1)).toarray()\ndf_comp['Pclass'] = OneHotEncoder().fit_transform(df_comp['Pclass'].values.reshape(-1,1)).toarray()\ndf_comp['Age'] = OneHotEncoder().fit_transform(df_comp['Age'].values.reshape(-1,1)).toarray()\ndf_comp['Fare'] = OneHotEncoder().fit_transform(df_comp['Fare'].values.reshape(-1,1)).toarray()","681e63c9":"df = df_comp.drop('Name',axis=1)\ndf.drop('Ticket',axis=1,inplace=True)\ndf.drop('Last_Name',axis=1,inplace=True)\nd_passenger_id = df.PassengerId.values\ndf.drop('PassengerId',axis=1,inplace=True)\n","ea5bd253":"df_train_f = df.iloc[:891,:]\ndf_test_f = df.iloc[891:,:]\ndf_test_f.drop(\"Survived\",axis=1,inplace=True)","e7b19a47":"\nc = {}\nfor i in df_train_f.columns:\n    c[i] = df_train_f.Survived.corr(df_train_f[i])","2235cfdd":"selected_features = [x for x in c.keys() if abs(c[x]) > 0.15 and x != 'Survived']","d25c92e2":"columns = selected_features\nX = df_train_f[columns]\nX_t = StandardScaler().fit_transform(X)\nY_t = df_train_f['Survived'].values\nX_train,X_val,Y_train,Y_val = train_test_split(X_t,Y_t,test_size = 0.1,random_state =42)\n","6a1294ae":"model_rf = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=42,\n                                           n_jobs=-1,\n                                           verbose=1)\nmodel_rf.fit(X_train, Y_train)\npredictions_rf = model_rf.predict(X_val)\nprint(accuracy_score(Y_val,predictions_rf))\nprint(classification_report(Y_val,predictions_rf))","810e91b0":"model_ab = AdaBoostClassifier(random_state=42)\nmodel_ab.fit(X_train, Y_train)\npredictions_ab = model_ab.predict(X_val)\nprint(accuracy_score(Y_val,predictions_ab))\nprint(classification_report(Y_val,predictions_ab))","c1234747":"model_xgb = XGBClassifier(random_state=42)\nmodel_xgb.fit(X_train, Y_train)\npredictions_xgb = model_xgb.predict(X_val)\nprint(accuracy_score(Y_val,predictions_xgb))\nprint(classification_report(Y_val,predictions_xgb))","ccaa2e5a":"model_lgb = LGBMClassifier(random_state=42)\nmodel_lgb.fit(X_train, Y_train)\npredictions_lgb = model_lgb.predict(X_val)\nprint(accuracy_score(Y_val,predictions_lgb))\nprint(classification_report(Y_val,predictions_lgb))","7e32cfa9":"model_gb = GradientBoostingClassifier(random_state=42)\nmodel_gb.fit(X_train, Y_train)\npredictions_gb = model_gb.predict(X_val)\nprint(accuracy_score(Y_val,predictions_gb))\nprint(classification_report(Y_val,predictions_gb))","990e1e23":"from sklearn.svm import SVC\nmodel_svc = SVC(random_state=42)\nmodel_svc.fit(X_train, Y_train)\npredictions_svc = model_svc.predict(X_val)\nprint(accuracy_score(Y_val,predictions_svc))\nprint(classification_report(Y_val,predictions_svc))","b5d808b0":"from sklearn.neighbors import KNeighborsClassifier\nmodel_knn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n                           metric_params=None, n_jobs=1, n_neighbors=6, p=2, \n                           weights='uniform')\nmodel_knn.fit(X_train, Y_train)\npredictions_knn = model_knn.predict(X_val)\nprint(accuracy_score(Y_val,predictions_knn))\nprint(classification_report(Y_val,predictions_knn))","9ccb46a3":"X_test = df_test_f[columns]\nX_test = StandardScaler().fit_transform(X_test)\nmmo = {897:1,899:1,930:1,1143:1,1152:1,1153:1,1171:1,972:0,1130:0,1138:0,1173:0,1284:0}\npredictions = model_gb.predict(X_test)\n","480ea81e":"sub = pd.DataFrame()\nsub['PassengerId'] = d_passenger_id[891:]\nsub['Survived'] = predictions.astype('int')\nfor i in mmo.keys():\n    sub[sub['PassengerId'] == i].Survived = mmo[i]\nsub['Survived'] = sub['Survived'].apply(lambda x: 1 if x>0.8 else 0)\nsub.head()","f7f0c2af":"sub.to_csv('submission.csv',index=False)","17bb6658":"# Feature Selection","c21abf05":"# Missing Values","a82635fd":"## ","f26940eb":"### Embarked","cbc7a0ae":"### Categorical features","265ff341":"# Model","ab80c988":"<h1 style=\"color:#00C1D4; \">Let's set sail to our journey through this data.<\/h1>","ea6fdc42":"### Please Check out my other notebooks also :\n- [Heart Attack prediction](https:\/\/www.kaggle.com\/govindsrathore\/heart-attack-analysis-prediction-91-acc)\n- [Pneumonia Detection Using Chest Xrays](https:\/\/www.kaggle.com\/govindsrathore\/vgg-transfer-learning-data-augmentation-94-acc)","f9d237ca":"### In case of Age , \n* We want to replace the values with median of the value so the outliers may not play a major role.\n* Also we can use Pclass and Sex features to get stratified medians according to these features.","b7e92327":"### Fare","2812de17":"#### In case of Fare , we use the same idea that Pclass which has highest (negative) correlation with the fare which implies that as Pclass decreases the Fare increases ","39097fc6":"<h2 style=\"color:#555273; \">Features:<\/h2>\n<ol>\n    <li><h4>Pclass -> Passenger class.<\/h4><\/li>\n    <li><h4>SibSp -> Number of siblings on board.<\/h4><\/li>\n    <li><h4>Parch -> Number of Parent or child on board.<\/h4><\/li>\n    <li><h4>Cabin -> Cabin where the seat of the passenger was located.<\/h4><\/li>\n    <li><h4>Embarked -> Boarding Location.<\/h4><\/li>\n    <li><h4>Fare -> Amount paid for the ticket<\/h4><\/li>\n    <li><h4>Ticket -> Ticket number.<\/h4><\/li>\n    <li><h4>Name ,Sex, Age are self-explanatory<\/h4><\/li>\n <\/ol>","e236c86b":"# Feature Engineering","bf10d17d":"# Data Visualization ","bf946f11":"## Questions to wonder\n### 1. Does being young increase survivalibility?\ud83e\uddd2\ud83e\uddd2\n### 2. Being in different passenger class changes the chances of surviving?\n### 3. Being alone is better or being with family helps ?\ud83d\udc6a\ud83d\udc6a\n### 4. Paying more for the ticket affect the survival?\ud83e\udd11\ud83e\udd11\n### 5. Being a female increases survivability \ud83e\udd2f\n### 6. Boarding location also matters in the game of survival?","7d232ca6":"### Cabin","ecbaf22a":"#### In case of Embarked , we will use mode of the feature to fill the missing values. As this a categorical data and no other information is given to us using mode seems like a plausible solution.","9fb468c9":"### Age","e255e9a6":"# Conclusion","3c62357b":"\n####  - From Parch and SibSp ,people who boarded alone are more than not likely to survive.\n#### - From Sex , females had more chances of surviving.\n#### - From Passenger Class , class 3 are more prone to not surviving.\n#### - From Alone , being alone decreases the survivalibility\n#### - From Fare , we can see that people who paid less are more likely to survive.\n#### - From Embarked , people boarding from Southampton had lower chances of surviving","473e1bc1":"# Importing Libraries","c7d7f398":"Since there are missing values in both test and train dataset , we will combine both dataset into one to deal with the missing values in the both without tampering both dataset. ","45248e20":"<h2 style=\"color:#555273; \">Titanic:<\/h2>\n<ul>\n    <li> <a href= \"#Importing-Libraries\"><h3>Import Libraries<\/h3><\/a><\/li>\n    <li><a href= \"#Missing-Values\"><h3>Missing Value<\/h3><\/a><\/li>\n    <li><a href = \"#Imputing-Data\"><h3>Impute data<\/h3><\/a><\/li>\n    <li><a href = \"#Data-Visualization\"><h3>Data Visualisation<\/h3><\/a><\/li>\n    <li><a href = \"#Feature-Engineering\"><h3>Feature Engineer<\/h3><\/a><\/li>\n    <li><a href = \"#Feature-Selection\"><h3>Features Selection<\/h3><\/a><\/li>\n    <li><a href = \"#Model\"><h3>Models<\/h3><\/a><\/li>\n    <li><a href = \"#Conclusion\"><h3> In Conclusion<\/h3><\/a><\/li>\n<\/ul>\n\n","d3b1f933":"#### In case of Cabin , we will fill the missing values with U for unidentified ","f4b545c9":"### Fare","95868530":"### Age","1eeaef7e":"![](https:\/\/faithmag.com\/sites\/default\/files\/styles\/article_full\/public\/2018-09\/titanic2.jpg?h=6521bd5e&itok=H8td6QVv)","d57540b0":"# Imputing Data ","1fdb5dce":"##### Select the features highly correlated with target feature"}}