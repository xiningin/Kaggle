{"cell_type":{"23641488":"code","b79208ba":"code","e1feec48":"code","f8267d5c":"code","0d0b881f":"code","1677bf8d":"code","2ab7208d":"code","d9a90b2e":"code","7cb5fee4":"code","3fa43b4d":"code","02db46ba":"code","2ec96a0b":"code","6fa6537e":"code","8a8e2a17":"code","92b4867c":"markdown"},"source":{"23641488":"# Os comandos presentes nesse notebook foram retirados do notebook de Jonas Paluci Barbosa e .\n# usados como framework para projeto 3 de Introducao a Inteligencia Artificial. O link para o notebook\n# dele: https:\/\/www.kaggle.com\/jonaspalucibarbosa\/chest-x-ray-pneumonia-cnn-transfer-learning\/notebook\n#\n# Pro projeto foi solicitado que fosse implementado o modelo CNN de Gaobo Liang e Lixin Zheng usando o\n# notebook de Jonas como framework, a parte do c\u00f3digo onde esse modelo foi implementado trata-se \n# da funcao get_model encontrada mais adiante.\n\nimport pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n\npd.options.display.max_colwidth = 100\n\nimport random\nimport os\n\nfrom numpy.random import seed\nseed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport glob\nimport cv2\n\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')","b79208ba":"# Inicia algumas constante como a SEED para permitir a reproducao e o tamanho da imagem\n\nIMG_SIZE = 150\nBATCH = 20\nSEED = 42","e1feec48":"main_path = \"..\/input\/labeled-chest-xray-images\/chest_xray\"\n\ntrain_path = os.path.join(main_path,\"train\")\ntest_path=os.path.join(main_path,\"test\")\n\ntrain_normal = glob.glob(train_path+\"\/NORMAL\/*.jpeg\")\ntrain_pneumonia = glob.glob(train_path+\"\/PNEUMONIA\/*.jpeg\")\n\ntest_normal = glob.glob(test_path+\"\/NORMAL\/*.jpeg\")\ntest_pneumonia = glob.glob(test_path+\"\/PNEUMONIA\/*.jpeg\")","f8267d5c":"train_list = [x for x in train_normal]\ntrain_list.extend([x for x in train_pneumonia])\n\ndf_train = pd.DataFrame(np.concatenate([['Normal']*len(train_normal) , ['Pneumonia']*len(train_pneumonia)]), columns = ['class'])\ndf_train['image'] = [x for x in train_list]\n\ntest_list = [x for x in test_normal]\ntest_list.extend([x for x in test_pneumonia])\n\ndf_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*len(test_pneumonia)]), columns = ['class'])\ndf_test['image'] = [x for x in test_list]","0d0b881f":"# Criando o conjunto de valida\u00e7\u00e3o. 80% do dataset eh usado para treino e 20% para validacao\n\ntrain_df, val_df = train_test_split(df_train, test_size = 0.20, random_state = SEED, stratify = df_train['class'])","1677bf8d":"train_datagen = ImageDataGenerator(rescale=1\/255.,\n                                  zoom_range = 0.1,\n                                  #rotation_range = 0.1,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1)\n\nval_datagen = ImageDataGenerator(rescale=1\/255.)\n\nds_train = train_datagen.flow_from_dataframe(train_df,\n                                             #directory=train_path, #dataframe contains the full paths\n                                             x_col = 'image',\n                                             y_col = 'class',\n                                             target_size = (IMG_SIZE, IMG_SIZE),\n                                             class_mode = 'binary',\n                                             batch_size = BATCH,\n                                             seed = SEED)\n\nds_val = val_datagen.flow_from_dataframe(val_df,\n                                            #directory=train_path,\n                                            x_col = 'image',\n                                            y_col = 'class',\n                                            target_size = (IMG_SIZE, IMG_SIZE),\n                                            class_mode = 'binary',\n                                            batch_size = BATCH,\n                                            seed = SEED)\n\nds_test = val_datagen.flow_from_dataframe(df_test,\n                                            #directory=test_path,\n                                            x_col = 'image',\n                                            y_col = 'class',\n                                            target_size = (IMG_SIZE, IMG_SIZE),\n                                            class_mode = 'binary',\n                                            batch_size = 1,\n                                            shuffle = False)","2ab7208d":"#Setting callbakcs\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\nplateau = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor = 0.2,                                     \n    patience = 2,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n) ","d9a90b2e":"# A funcao a seguir foi feita baseada no modelo proposto por Liang e Zheng que utilizam 49 camadas de\n# convolucao, com um dropout de 0.5 e um Global Average Pooling depois dessas camadas, se encerrando\n# com duas Camadas densas, a primeira utilizando como Ativacao ReLu e a ultima usando Ativacao Sigmoid\n\n# Para implementar as 49 camadas, me inspirei num modelo de ResNet com 34 camadas de convolucao que \n# pode ser visto no seguinte link: https:\/\/towardsdatascience.com\/introduction-to-resnets-c0a830a288a4\n# A ideia principal desse modelo, eh dividir as 34 camadas em 4 blocos com filtros diferentes, como\n# sera visto a seguir\n\ndef get_model():\n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Primeira camada de convolucao, usamos filtro 64 e tamanho do kernel igual a 5x5. Alem disso,\n    # como sugerido no modelo de Liang e Zheng, foi tambem usado dilatacao para as camadas, no caso\n    # todas as 49 camadas sao dilatadas com uma taxa de 2x2 e utilizam Ativacao ReLu\n    x = layers.Conv2D(filters=64, kernel_size=(5,5), padding='valid', dilation_rate=(2,2))(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    # A seguir temos os blocos de camadas de convolucao, cada bloco possui 12 camadas\n\n    # Primeiro dos 4 blocos de camadas de convolucao, o kernel diminui para 3x3, mas o filtro permanece\n    # sendo 64.\n    for i in range(12):\n        x = layers.Conv2D(filters=64, kernel_size=(3,3), padding='valid', dilation_rate=(2,2))(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n\n    # Segundo bloco, o kernel continua em 3x3, mas o filtro dobra para 128.\n    for i in range(12):\n        x = layers.Conv2D(filters=128, kernel_size=(3,3), padding='valid', dilation_rate=(2,2))(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n    \n    # Terceiro bloco, o kernel diminui para 1x1 e o filtro dobra para 256.\n    for i in range(12):\n        x = layers.Conv2D(filters=256, kernel_size=(1,1), padding='valid', dilation_rate=(2,2))(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n    \n    # Quarto bloco, o kernel continua em 1x1, mas o filtro dobra para 512.\n    for i in range(12):\n        x = layers.Conv2D(filters=512, kernel_size=(1,1), padding='valid', dilation_rate=(2,2))(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n    \n    # Ao final das camadas de convolucao, eh feito um dropout de 0.5 e depois fazemos um Global Average\n    # Pooling\n    x = layers.Dropout(0.5)(x)\n    x = layers.GlobalAvgPool2D()(x)\n    \n    # Seguimos para a primeira camada densa, que usa Ativacao ReLu\n    x = layers.Flatten()(x)\n    x = layers.Dense(64, activation='relu')(x)\n\n    # Por fim, realizamos a ultima camada densa que usa Ativacao Sigmoid e retornamos o modelo criado\n    # para o programa.\n    output = layers.Dense(1, activation='sigmoid')(x)\n\n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","7cb5fee4":"keras.backend.clear_session()\n\nmodel = get_model()\nmodel.compile(loss='binary_crossentropy'\n              , optimizer = keras.optimizers.Adam(learning_rate=0.00003), metrics='binary_accuracy')\n\nmodel.summary()","3fa43b4d":"# Treina o modelo criado usando 100 epochs\n\nhistory = model.fit(ds_train,\n          batch_size = BATCH, epochs = 100,\n          validation_data=ds_val,\n          callbacks=[early_stopping, plateau],\n          steps_per_epoch=(len(train_df)\/BATCH),\n          validation_steps=(len(val_df)\/BATCH))","02db46ba":"# Faz a predicao dos resultados para que seja possivel calcular as metricas\n\nnum_label = {'Normal': 0, 'Pneumonia' : 1}\nY_test = df_test['class'].copy().map(num_label).astype('int')\n\nds_test.reset()\npredictions = model.predict(ds_test, steps=len(ds_test), verbose=0)\npred_labels= np.where(predictions>0.5, 1, 0)","2ec96a0b":"# Mostra a matriz de confunsao\n\nconfusion_matrix = metrics.confusion_matrix(Y_test, pred_labels)\nsns.heatmap(confusion_matrix, annot=True, fmt=\"d\")\n\nplt.xlabel(\"Predicted Label\", fontsize= 12)\nplt.ylabel(\"True Label\", fontsize= 12)\n\nplt.show()","6fa6537e":"# Mostra o resultado das metricas do modelo\n\nprint(\"Accuracy: \", metrics.accuracy_score(Y_test, pred_labels))\nprint(\"Precision: \", metrics.precision_score(Y_test, pred_labels))\nprint(\"F1: \", metrics.f1_score(Y_test, pred_labels))\nprint(\"Recall: \", metrics.recall_score(Y_test, pred_labels))","8a8e2a17":"# Mostra o resultado da Curva ROC\n\nroc_auc = metrics.roc_auc_score(Y_test, predictions)\nprint('ROC_AUC: ', roc_auc)\n\nfpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions)\n\nplt.plot(fpr, tpr, label = 'ROC_AUC = %0.3f' % roc_auc)\n\nplt.xlabel(\"False Positive Rate\", fontsize= 12)\nplt.ylabel(\"True Positive Rate\", fontsize= 12)\nplt.legend(loc=\"lower right\")\n\nplt.show()","92b4867c":"Universidade de Brasilia\n\nAluno: Joao Victor Siqueira de Araujo\n\nMatricula: 19\/0031026\n\nDisciplina: Introducao a Inteligencia Artificial - CIC0135\n\nTurma A\n\nProfessor: Dibio Leandro Borges"}}