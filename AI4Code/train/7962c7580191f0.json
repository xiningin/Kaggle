{"cell_type":{"ce2b1bb4":"code","ae07875e":"code","1d58670a":"code","7bddfd26":"code","44a9ed7d":"code","79e2977e":"code","87c2a5aa":"code","8367071f":"code","576c7271":"code","e8109fe9":"code","97ec97b9":"code","d39d67c3":"code","c5dfcc33":"code","f0bd8b06":"markdown","8e5c5db7":"markdown","2127283a":"markdown","e11bdff9":"markdown","ff71edc0":"markdown","d0660d4f":"markdown","4aaad9c6":"markdown","727fdf9a":"markdown","387f09f6":"markdown","97fe13e5":"markdown","4c2eab27":"markdown"},"source":{"ce2b1bb4":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport statistics\nimport nltk\nimport spacy\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler","ae07875e":"class MODEL_EVAL_METRIC:\n    accuracy = \"accuracy\"\n    f1_score = \"f1_score\"\n\nclass Config:    \n    EMB_SIZE = 300    \n    NUM_FOLDS = 5\n    NUM_EPOCHS = 20\n    NUM_CV_RUN = 1\n    MODEL_EVAL_METRIC = MODEL_EVAL_METRIC.accuracy\n\nDATA_PATH = \"\/kaggle\/input\/nlp-getting-started\/\"","1d58670a":"df_train = pd.read_csv(DATA_PATH + 'train.csv')\ndf_test = pd.read_csv(DATA_PATH + 'test.csv')\nprint(f\"Rows in train.csv = {len(df_train)}\")\nprint(f\"Rows in test.csv = {len(df_test)}\")\npd.set_option('display.max_colwidth', None)\ndf_train.head()","7bddfd26":"df_train_pos = df_train[df_train.target == 1]\ndf_train_neg = df_train[df_train.target == 0]\nprint(f\"No. of positive training examples = {len(df_train_pos)}\")\nprint(f\"No. of negative training examples = {len(df_train_neg)}\")\ntrain_keywords_unique = df_train.keyword.unique()\nprint(f\"No. of unique keywords = {len(train_keywords_unique)}\")\ndf_train_notnull_keywords = df_train[~df_train.keyword.isnull()]\nprint(f\"No of train examples with keyword not null = {len(df_train_notnull_keywords)}\")","44a9ed7d":"train_tweet_vectors = None\ntest_tweet_vectors = None\nnlp = spacy.load(\"en_core_web_lg\")\nwith nlp.disable_pipes():\n    train_tweet_vectors = np.array([nlp(row.text).vector for id, row in df_train.iterrows()])\n    test_tweet_vectors = np.array([nlp(row.text).vector for id, row in df_test.iterrows()])\nprint(train_tweet_vectors.shape)    ","79e2977e":"train_targets = df_train[\"target\"]\nvec_mean = train_tweet_vectors.mean(axis=0)\nvec_std = train_tweet_vectors.std(axis=0)\nprint(vec_mean.shape, vec_std.shape)","87c2a5aa":"# for a training and label data in form of numpy arrays, return a fold_index array whose elements\n# represent the fold index. The length of this fold_index array is same as length of input dataset\n# and the items for which fold_index array value == cv iteration count are to be used for validation \n# in the corresponding cross validation iteration with rest of the items ( for which fold_index \n# array value != cv iteration count ) being used for training (typical ration being 80:20)\ndef get_skf_index(num_folds, X, y):\n    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = 42)\n    train_fold_index = np.zeros(len(y))\n    for fold, (train_index, val_index) in enumerate(skf.split(X=X, y=y)):\n        train_fold_index[val_index] = [fold + 1] * len(val_index)\n    return train_fold_index\n\nk_folds = get_skf_index(num_folds=Config.NUM_FOLDS, X=train_tweet_vectors, y=train_targets)","8367071f":"# Get the train and validation data for a specific fold. \n# X: numpy array of input features\n# y: numpy array of target labels\n# fold: fold index for which to create data loaders                                     \n# kfolds: Array that marks each of the data items as belonging to a specific fold\ndef get_fold_data(fold, kfolds, X, y):\n    fold += 1                         \n    train_X = X[kfolds != fold]        \n    train_y = y[kfolds != fold]    \n    val_X = X[kfolds == fold]\n    val_y = y[kfolds == fold]    \n    return train_X, train_y, val_X, val_y","576c7271":"from sklearn.metrics import f1_score, accuracy_score\n\ndef run_training(train_X, train_y, val_X, val_y, params):\n    # Create the SVC model\n    model = SVC(gamma='scale', C=params[\"C\"], kernel=params[\"kernel\"])\n    # normalize the train and validation data \n    scaler = StandardScaler()\n    train_X_scaled = scaler.fit_transform(train_X.astype(np.float32))\n    val_X_scaled = scaler.fit_transform(val_X.astype(np.float32))\n    model.fit(train_X_scaled, train_y.ravel())\n    val_y_pred = model.predict(val_X_scaled)\n    val_score = None\n    if Config.MODEL_EVAL_METRIC == MODEL_EVAL_METRIC.accuracy:\n        val_score = accuracy_score(val_y, val_y_pred)\n    elif Config.MODEL_EVAL_METRIC == MODEL_EVAL_METRIC.f1_score:\n        val_score = f1_score(val_y, val_y_pred)\n    return round(val_score, 4), model","e8109fe9":"import tqdm\n\ndef cv_run(run, train_tweet_vectors, train_targets):\n    fold_metrics_model = []\n    params = {\"C\": 1.0, \"kernel\": \"rbf\"}\n    for fold in tqdm.tqdm(range(Config.NUM_FOLDS)):        \n        train_X, train_y, val_X, val_y = get_fold_data(fold, k_folds, train_tweet_vectors, train_targets)    \n        fold_val_metric, fold_model = run_training(train_X, train_y, val_X, val_y, params)\n        fold_metrics_model.append((fold_val_metric, fold_model))\n    fold_metrics = [item[0] for item in fold_metrics_model]\n    cv_metric_mean = statistics.mean(fold_metrics)\n    cv_metric_std = statistics.stdev(fold_metrics)\n    print(f\"For cv run {run} fold_metrics = {fold_metrics}\")\n    print(f\"mean val metric across folds = {cv_metric_mean}, val metric stdev across folds = {cv_metric_std}\")\n    return fold_metrics_model","97ec97b9":"run_fold_metrics_model = []\ntrain_tweet_vectors = train_tweet_vectors - vec_mean\nfor run in tqdm.tqdm(range(Config.NUM_CV_RUN)):\n    fold_metrics_model = cv_run(run+1, train_tweet_vectors, train_targets)    \n    run_fold_metrics_model.append(fold_metrics_model)    ","d39d67c3":"fold_metrics_model = run_fold_metrics_model[0]\nfold_metrics_model_sorted = sorted(fold_metrics_model, key=lambda x:x[0], reverse=True)    \nbest_cv_model = fold_metrics_model_sorted[0][1]\n\ndef test_predictions(model, test_tweet_vectors):\n    scaler = StandardScaler()\n    test_tweet_vectors_scaled = scaler.fit_transform(test_tweet_vectors.astype(np.float32))\n    predictions = model.predict(test_tweet_vectors_scaled)\n    print(f\"Completed prediction for {len(predictions)} test rows\")\n    df_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n    df_submission['target']= predictions\n    df_submission.to_csv('submission_svc.csv',index=False)\n    \n#test_predictions(best_cv_model, test_tweet_vectors)    ","c5dfcc33":"\nparams = {\"C\": 1.0, \"kernel\": \"rbf\"}\nfull_model = SVC(gamma='scale', C=params[\"C\"], kernel=params[\"kernel\"])\n# normalize the train and validation data \nscaler = StandardScaler()\ntrain_X_scaled = scaler.fit_transform(train_tweet_vectors.astype(np.float32))\nfull_model.fit(train_X_scaled, train_targets.ravel())\ntest_predictions(full_model, test_tweet_vectors)","f0bd8b06":"## This is where the entire magic is. \nLoad spacy's awesome language model and convert your tweets into vector embeddings","8e5c5db7":"### K Fold CV","2127283a":"## Train the model on entire training data and predict on test","e11bdff9":"### Text classification using spacy and support vector machine\n","ff71edc0":"### Load the data","d0660d4f":"## The training loop","4aaad9c6":"### Get train and validation data for a fold","727fdf9a":"Our cross validation is able to mimic the public leaderboard and the mean cv metric score will be very close to the public leaderboard score if we use the best cross validation model. However we want to do even better.","387f09f6":"## Prediction using the best model","97fe13e5":"### Some EDA","4c2eab27":"### Configuration for training"}}