{"cell_type":{"4777fca8":"code","69808b75":"code","206df2e8":"code","a78b6efb":"code","dbf03cc9":"code","89cf0718":"code","91bb4108":"code","33875896":"code","aaf7c521":"code","cf165ee0":"code","5e3d1d59":"code","09e91958":"code","c3c99b2d":"code","833ed6ad":"code","888fac62":"code","ea8dde5d":"code","84dc36d1":"code","ddee344e":"code","577cbda0":"code","ba830f83":"markdown","e40b9b9b":"markdown","d854e3f7":"markdown","bc5e778d":"markdown"},"source":{"4777fca8":"#Meghdoot31 - Kernel 01 - Iris Species Dataset\n#Import packages that might be useful in this Kernel\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats\nfrom sklearn import preprocessing\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nimport os","69808b75":"iris = pd.read_csv(\"..\/input\/Iris.csv\")","206df2e8":"iris = iris.drop('Id',1)\nprint(iris.head())\nprint(iris.info())\nprint(iris.shape)","a78b6efb":"matcorr = iris.corr()\nmask = np.zeros_like(matcorr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(matcorr, mask=mask, cmap=\"Purples\", vmin=-1, vmax=1, center=0, square=True,annot = True);\nplt.show()","dbf03cc9":"sns.pairplot(iris,diag_kind = \"kde\",hue = \"Species\",height = 5, vars = [\"SepalLengthCm\",\"SepalWidthCm\"])","89cf0718":"sns.pairplot(iris,hue = \"Species\",height = 5, vars = [\"PetalLengthCm\",\"PetalWidthCm\"])","91bb4108":"iris[\"Species\"].value_counts().plot(kind = \"bar\")","33875896":"## Dimension of the data set\n\nprint(\"The dimension of the Iris dataset are:\",iris.shape)\nprint(\" \")\nprint(\"The number elements in the Iris dataset is:\",iris.size)\nprint(\" \")\nprint(iris.isnull().sum())\nprint(\" \")\niris = iris.dropna()\nprint(\" \")\nprint(iris.info())\nprint(\" \")\nprint(\"The Unique Species of Iris Flowers and the count are:\") \nprint(iris[\"Species\"].value_counts())\n","aaf7c521":"iris.head()","cf165ee0":"iris.tail()","5e3d1d59":"iris.describe()","09e91958":"cols = iris.columns\nfeature1 = cols[0:3]\nprint(feature1)\nlabel = cols[3]\nprint(label)\n","c3c99b2d":"#Shuffle The data\nindices = data_norm.index.tolist()\nindices = np.array(indices)\nnp.random.shuffle(indices)","833ed6ad":"from pandas import get_dummies","888fac62":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","ea8dde5d":"# One Hot Encode as a dataframe\nfrom sklearn.model_selection import train_test_split\ny = get_dummies(y)\n\n# Generate Training and Validation Sets\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2)\n\n# Convert to np arrays so that we can use with TensorFlow\nX_train = np.array(X_train).astype(np.float32)\nX_test  = np.array(X_test).astype(np.float32)\ny_train = np.array(y_train).astype(np.float32)\ny_test  = np.array(y_test).astype(np.float32)","84dc36d1":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","ddee344e":"# K-Nearest Neighbours\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nModel = KNeighborsClassifier(n_neighbors=8)\nModel.fit(X_train, y_train)\n\ny_pred = Model.predict(X_test)","577cbda0":"# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test.argmax(0), y_pred.argmax(0)))\nprint('Accuracy is',accuracy_score(y_pred,y_test))","ba830f83":"In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor. ","e40b9b9b":"### Dataset Exploration","d854e3f7":"# K-Nearest Neighbours","bc5e778d":"## Data Preprocessing "}}