{"cell_type":{"2458b14d":"code","3955971d":"code","4e277184":"code","eb936942":"code","628d8fcf":"code","f57d527f":"code","fa569dfb":"code","54b270cd":"code","d6098cfa":"code","023a9846":"code","a47195cd":"code","ad9b5d54":"code","73526f6a":"code","2d1619bd":"code","6c15ca8e":"markdown","24c05b39":"markdown","c5a51f18":"markdown","f5ed2909":"markdown","973e2fe1":"markdown","9ac3e6ec":"markdown","5b284bb4":"markdown","f4b7af6d":"markdown","48735ee7":"markdown","8d7c778e":"markdown","8f20d1bb":"markdown"},"source":{"2458b14d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3955971d":"pip install openpyxl","4e277184":"pip install xlrd","eb936942":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport math\nimport scipy.stats as st\n\npd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', 10)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\n\ndef score_up_down_diff(up, down):\n    return up - down\n\n\ndef score_average_rating(up, down):\n    if up + down == 0:\n        return 0\n    return up \/ (up + down)\n\ndef wilson_lower_bound(up, down, confidence=0.95):\n    \"\"\"\n    Wilson Lower Bound Score hesapla\n\n    - Bernoulli parametresi p i\u00e7in hesaplanacak g\u00fcven aral\u0131\u011f\u0131n\u0131n alt s\u0131n\u0131r\u0131 WLB skoru olarak kabul edilir.\n    - Hesaplanacak skor \u00fcr\u00fcn s\u0131ralamas\u0131 i\u00e7in kullan\u0131l\u0131r.\n    - Not:\n    E\u011fer skorlar 1-5 aras\u0131daysa 1-3 negatif, 4-5 pozitif olarak i\u015faretlenir ve bernoulli'ye uygun hale getirilebilir.\n    Bu beraberinde baz\u0131 problemleri de getirir. Bu sebeple bayesian average rating yapmak gerekir.\n\n    Parameters\n    ----------\n    up: int\n        up count\n    down: int\n        down count\n    confidence: float\n        confidence\n\n    Returns\n    -------\n    wilson score: float\n\n    \"\"\"\n    n = up + down\n    if n == 0:\n        return 0\n    z = st.norm.ppf(1 - (1 - confidence) \/ 2)\n    phat = 1.0 * up \/ n\n    return (phat + z * z \/ (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z \/ (4 * n)) \/ n)) \/ (1 + z * z \/ n)","628d8fcf":"df = pd.read_csv(\"..\/input\/amazon-reviews\/amazon_reviews.csv\")\ndf[\"overall\"].mean()","f57d527f":"df.info()","fa569dfb":"# day_diff: yorum sonras\u0131 ne kadar g\u00fcn ge\u00e7mi\u015f\ndf['reviewTime'] = pd.to_datetime(df['reviewTime'], dayfirst=True)\ncurrent_date = pd.to_datetime(str(df['reviewTime'].max()))\ndf[\"day_diff\"] = (current_date - df['reviewTime']).dt.days","54b270cd":"# day_diff de\u011fi\u015fkeninin \u00e7eyrek de\u011ferlerini elde etme:\na = df[\"day_diff\"].quantile(0.25)\nb = df[\"day_diff\"].quantile(0.50)\nc = df[\"day_diff\"].quantile(0.75)","d6098cfa":"# a,b,c de\u011ferlerine g\u00f6re a\u011f\u0131rl\u0131kl\u0131 puan\u0131 hesaplama:\ndf.loc[df[\"day_diff\"] <= a, \"overall\"].mean() * 28 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > a) & (df[\"day_diff\"] <= b), \"overall\"].mean() * 26 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > b) & (df[\"day_diff\"] <= c), \"overall\"].mean() * 24 \/ 100 + \\\ndf.loc[(df[\"day_diff\"] > c), \"overall\"].mean() * 22 \/ 100\n","023a9846":"def time_based_weighted_average(dataframe,a, w1=28, w2=26, w3=24, w4=22):\n    # day_diff de\u011fi\u015fkeninin \u00e7eyrek de\u011ferlerini elde etme:\n    a = dataframe[\"day_diff\"].quantile(0.25)\n    b = dataframe[\"day_diff\"].quantile(0.50)\n    c = dataframe[\"day_diff\"].quantile(0.75)\n\n    return dataframe.loc[dataframe[\"day_diff\"] <= a, \"overall\"].mean() * w1 \/ 100 + \\\n           dataframe.loc[(dataframe[\"day_diff\"] > a) & (dataframe[\"day_diff\"] <= b), \"overall\"].mean() * w2 \/ 100 + \\\n           dataframe.loc[(dataframe[\"day_diff\"] > b) & (dataframe[\"day_diff\"] <= c), \"overall\"].mean() * w3 \/ 100 + \\\n           dataframe.loc[(dataframe[\"day_diff\"] > c), \"overall\"].mean() * w4 \/ 100","a47195cd":"df.head(50)\n\ndf[\"helpful_no\"] = df[\"total_vote\"] - df[\"helpful_yes\"]\n\ndf = df[[\"reviewerName\", \"overall\", \"summary\", \"helpful_yes\", \"helpful_no\", \"total_vote\", \"reviewTime\"]]","ad9b5d54":"def score_up_down_diff(up, down):\n    return up - down\n\n# score_pos_neg_diff\ndf[\"score_pos_neg_diff\"] = df.apply(lambda x: score_up_down_diff(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)\n\ndf.sort_values(\"score_pos_neg_diff\", ascending=False).head(20)\n\n\n# 1500 1000 -> 500\n# 500 0 -> 500\n\n\n\n\ndef score_average_rating(up, down):\n    if up + down == 0:\n        return 0\n    return up \/ (up + down)\n\n\n# score_average_rating\ndf[\"score_average_rating\"] = df.apply(lambda x: score_average_rating(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)\n\ndf.sort_values(\"score_average_rating\", ascending=False).head(20)\n\n# 1500 1000 -> 500  1500\/2500\n# 500 0 -> 500    500 \/ 500 1\n# 1 0 -> 1\/1 1\n\n\n\n\ndef wilson_lower_bound(up, down, confidence=0.95):\n    \"\"\"\n    Wilson Lower Bound Score hesapla\n\n    - Bernoulli parametresi p i\u00e7in hesaplanacak g\u00fcven aral\u0131\u011f\u0131n\u0131n alt s\u0131n\u0131r\u0131 WLB skoru olarak kabul edilir.\n    - Hesaplanacak skor \u00fcr\u00fcn s\u0131ralamas\u0131 i\u00e7in kullan\u0131l\u0131r.\n    - Not:\n    E\u011fer skorlar 1-5 aras\u0131daysa 1-3 negatif, 4-5 pozitif olarak i\u015faretlenir ve bernoulli'ye uygun hale getirilebilir.\n    Bu beraberinde baz\u0131 problemleri de getirir. Bu sebeple bayesian average rating yapmak gerekir.\n\n    Parameters\n    ----------\n    up: int\n        up count\n    down: int\n        down count\n    confidence: float\n        confidence\n\n    Returns\n    -------\n    wilson score: float\n\n    \"\"\"\n    n = up + down\n    if n == 0:\n        return 0\n    z = st.norm.ppf(1 - (1 - confidence) \/ 2)\n    phat = 1.0 * up \/ n\n    return (phat + z * z \/ (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z \/ (4 * n)) \/ n)) \/ (1 + z * z \/ n)","73526f6a":"# wilson_lower_bound\n# G\u00fcven aral\u0131\u011f\u0131 hesaplan\u0131r. 100 ki\u015fiden 95'i bu yorumla iligili bir etikile\u015fim sa\u011flad\u0131\u011f\u0131nda y\u00fczde 5'lik bir hata pay\u0131 ile bu yorumun\n# up oran\u0131 bu aral\u0131k olacakt\u0131r diyebiliyoruz. Alt skor al\u0131n\u0131r.\ndf[\"wilson_lower_bound\"] = df.apply(lambda x: wilson_lower_bound(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)\n\n\n##################################################\n# Ad\u0131m 3. 20 Yorumu Belirleyiniz ve Sonu\u00e7lar\u0131 Yorumlay\u0131n\u0131z.\n###################################################\n\ndf.sort_values(\"wilson_lower_bound\", ascending=False).head(20)\n","2d1619bd":"df_top_comments = df.sort_values(\"wilson_lower_bound\",ascending=False).head(20)\ndf_top_comments[[\"overall\", \"summary\", \"helpful_yes\", \"helpful_no\", \"wilson_lower_bound\"]]","6c15ca8e":"# \u0130\u015f Problemi\n**\u00dcr\u00fcn ratinglerini daha do\u011fru hesaplamaya \n\u00e7al\u0131\u015fmak ve \u00fcr\u00fcn yorumlar\u0131n\u0131 daha do\u011fru \ns\u0131ralamak.**\n","24c05b39":"Veri Setini Okutal\u0131m ve \u00dcr\u00fcn\u00fcn Ortalama Puan\u0131n\u0131 Hesaplayal\u0131m.","c5a51f18":"**Average Rating\u2019i g\u00fcncel yorumlara g\u00f6re \nhesaplay\u0131n\u0131z ve var olan average rating ile \nk\u0131yaslayal\u0131m.**\n\n* Payla\u015f\u0131lan veri setinde kullan\u0131c\u0131lar bir \u00fcr\u00fcne puanlar vermi\u015f ve yorumlar yapm\u0131\u015ft\u0131r.\n* Bu g\u00f6revde amac\u0131m\u0131z verilen puanlar\u0131 tarihe g\u00f6re a\u011f\u0131rl\u0131kland\u0131rarak de\u011ferlendirmek.\n* \u0130lk ortalama puan ile elde edilecek tarihe g\u00f6re a\u011f\u0131rl\u0131kl\u0131 puan\u0131n kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131 gerekmektedir.","f5ed2909":"# De\u011fi\u015fkenler\n\n* reviewerID \u2013 Kullan\u0131c\u0131 ID\u2019si\n* asin \u2013 \u00dcr\u00fcn ID\u2019si.\n* reviewerName \u2013 Kullan\u0131c\u0131 Ad\u0131\n* helpful \u2013 Faydal\u0131 de\u011ferlendirme derecesi\n* reviewText \u2013 De\u011ferlendirme\n* overall \u2013 \u00dcr\u00fcn rating\u2019i\n* summary \u2013 De\u011ferlendirme \u00f6zeti\n* unixReviewTime \u2013 De\u011ferlendirme zaman\u0131\n* unixReviewTime \u2013 De\u011ferlendirme zaman\u0131\n* day_diff \u2013 De\u011ferlendirmeden itibaren ge\u00e7en g\u00fcn say\u0131s\u0131\n* helpful_yes \u2013 De\u011ferlendirmenin faydal\u0131 bulunma say\u0131s\u0131\n* total_vote \u2013 De\u011ferlendirmeye verilen oy say\u0131s\u0131","973e2fe1":"score_pos_neg_diff, score_average_rating ve wilson_lower_bound Skorlar\u0131n\u0131 Hesaplay\u0131p Veriye Ekleyelim.","9ac3e6ec":"**** \u00dcr\u00fcn i\u00e7in \u00dcr\u00fcn Detay Sayfas\u0131nda G\u00f6r\u00fcnt\u00fclenecek 20 Review'i Belirleyelim.****\n\nhelpful_no De\u011fi\u015fkenini \u00dcretelim\n\n Not:\n total_vote bir yoruma verilen toplam up-down say\u0131s\u0131d\u0131r.\n up, helpful demektir.\n veri setinde helpful_no de\u011fi\u015fkeni yoktur, var olan de\u011fi\u015fkenler \u00fczerinden \u00fcretilmesi gerekmektedir.","5b284bb4":"**BONUS**","f4b7af6d":"*  Son zamanlardaki trendin ka\u00e7\u0131r\u0131lma durumu var. \u00d6rne\u011fin \u00dcr\u00fcnle iligili kullan\u0131ld\u0131ktan sonra \u00e7e\u015fitli arzalar\u0131n ortaya \u00e7\u0131kmas\u0131 gibi.\n*  Bu durumda tarihe g\u00f6re bir a\u011f\u0131rl\u0131kland\u0131rma yap\u0131p yeni bir rating hesaplanabilir. B\u00f6ylece son zamanlardaki pozitif trend veya\n negatif trend durumu yakalanabilir duruma geliyor olacakat\u0131r.","48735ee7":"Tarihe G\u00f6re A\u011f\u0131rl\u0131kl\u0131 Puan Ortalamas\u0131n\u0131 Hesaplayal\u0131m.\n\n   - reviewTime de\u011fi\u015fkenini tarih de\u011fi\u015fkeni olarak tan\u0131tman\u0131z\n   - reviewTime'\u0131n max de\u011ferini current_date olarak kabul etmeniz\n   - her bir puan-yorum tarihi ile current_date'in fark\u0131n\u0131 g\u00fcn cinsinden ifade ederek yeni de\u011fi\u015fken olu\u015fturman\u0131z\n   - ve g\u00fcn cinsinden ifade edilen de\u011fi\u015fkeni quantile fonksiyonu ile 4'e b\u00f6l\u00fcp (3 \u00e7eyrek verilirse 4 par\u00e7a \u00e7\u0131kar)\n   - \u00e7eyrekliklerden gelen de\u011ferlere g\u00f6re a\u011f\u0131rl\u0131kland\u0131rma yapman\u0131z gerekir.\n   - \u00f6rne\u011fin q1 = 12 ise a\u011f\u0131rl\u0131kland\u0131r\u0131rken 12 g\u00fcnden az s\u00fcre \u00f6nce yap\u0131lan yorumlar\u0131n ortalamas\u0131n\u0131 al\u0131p bunlara\n   - y\u00fcksek a\u011f\u0131rl\u0131k vermek gibi.","8d7c778e":"# Veri Seti Hikayesi\n**Amazon \u00fcr\u00fcn verilerini i\u00e7eren bu veri seti \u00fcr\u00fcn kategorileri ile \n\u00e7e\u015fitli metadatalar\u0131 i\u00e7ermektedir.\nElektronik kategorisindeki en fazla yorum alan \u00fcr\u00fcn\u00fcn kullan\u0131c\u0131 \npuanlar\u0131 ve yorumlar\u0131 vard\u0131r.**","8f20d1bb":" wilson lower bound de\u011ferine g\u00f6re de\u011ferlendirmeleri s\u0131ralad\u0131k. Helpful olarak i\u015faretlenme say\u0131s\u0131n\u0131n y\u00fcksek olmas\u0131\n yap\u0131lan yorumun iyi oldu\u011funu g\u00f6stermez. Yorumlar\u0131 belirlerken hangi yorumlar\u0131n olumlu, olumsuz ve n\u00f6tr oldu\u011funu da g\u00f6rmek\n bizlere fayda sa\u011flayacakt\u0131r. Bu nedenle yap\u0131lan yorumlara sentiment analizi yani duygu analizi yaparak positive, negatif, n\u00f6tr\n s\u0131n\u0131fland\u0131rmas\u0131 yapabiliriz. Bunun i\u00e7in Natural Language Toolkit k\u00fct\u00fcphanesi kullanaca\u011f\u0131z.\n\n NLTK -> Do\u011fal dil i\u015fleme k\u00fct\u00fcphanesi (https:\/\/www.nltk.org\/)\n Sentiment analysis (Duygu analizi), metindeki olumlu veya olumsuz duyguyu tespit etme s\u00fcrecidir.\n Genellikle \u015firketler veya markalar taraf\u0131ndan sosyal verilerdeki duyarl\u0131l\u0131\u011f\u0131 tespit etmek, marka itibar\u0131n\u0131 \u00f6l\u00e7mek ve m\u00fc\u015fterileri anlamak i\u00e7in kullan\u0131l\u0131r.\n\n\n Gerekli k\u00fct\u00fcphanelerin y\u00fcklenmesi\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer #nltk k\u00fct\u00fcphanesinde haz\u0131r bir sentiment Intensity Analizi var\nimport nltk\nimport re\nfrom textblob import TextBlob # metnin olumlu-olumsuz durumuna g\u00f6re size 0-1 aral\u0131\u011f\u0131nda bir de\u011fer d\u00f6nmektedir. TextBlob ile amac\u0131m\u0131z yaz\u0131n\u0131n olumlu mu olumsuz mu i\u00e7erik i\u00e7erdi\u011fini anlamakt\u0131r.\nnltk.downloader.download('vader_lexicon')\n VADER (Valence Aware Dictionary for Sentiment Reasoning), duygunun hem polaritesine (pozitif\/negatif) hem de\n yo\u011funlu\u011funa (g\u00fcc\u00fcne) duyarl\u0131 olan metin duygu analizi i\u00e7in kullan\u0131lan bir modeldir.\n NLTK paketinde mevcuttur ve do\u011frudan etiketlenmemi\u015f metin verilerine uygulanabilir.\n\n\n Daha iyi sonu\u00e7lar i\u00e7in summary de\u011fi\u015fkenimizin i\u00e7erisindeki text'leri temizlenmesi gerekiyor. (Noktalama i\u015faretlerinden kurtulmak, k\u00fc\u00e7\u00fck harfe \u00e7evirmek..)\nrt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)\",\" \",x)\ndf[\"summary\"] = df[\"summary\"].map(rt)\ndf[\"summary\"] = df[\"summary\"].str.lower()\ndf.head(10)\n\n\n Sentiment analysis\n TextBlob \u00c7\u0131kt\u0131 olarak polarity ve subjectivity de\u011ferlerini d\u00f6nd\u00fcrecektir.\n Polarity  duygu durumunu yani olumlu mu olumsuz mu oldu\u011funu belirtir.\n Bize 0 ile 1 aras\u0131nda de\u011fer d\u00f6ner. 1' e ne kadar yak\u0131nsa o kadar olumlu, 0'a ne kadar yak\u0131nsa o kadar olumsuzdur.\ndf[['polarity', 'subjectivity']] = df['summary'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\nfor index, row in df['summary'].iteritems():\n    print(index,row)\n    score = SentimentIntensityAnalyzer().polarity_scores(row)\n    neg = score['neg']\n    neu = score['neu']\n    pos = score['pos']\n    if neg > pos:\n        df.loc[index, 'sentiment'] = \"negative\"\n    elif pos > neg:\n        df.loc[index, 'sentiment'] = \"positive\"\n    else:\n        df.loc[index, 'sentiment'] = \"neutral\"\n    df.loc[index, 'neg'] = neg\n    df.loc[index, 'neu'] = neu\n    df.loc[index, 'pos'] = pos\n\ndf.head(10)\n\n\n Duygu analizlerinin da\u011f\u0131l\u0131m\u0131\ndef count_values_in_column(data,feature):\n    total=data.loc[:,feature].value_counts(dropna=False)\n    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n\ncount_values_in_column(df,\"sentiment\")\n           Total  Percentage\n positive   2691    54.75000\n neutral    1856    37.76000\n negative    368     7.49000\n\n\n Worldcloud -> Daha fazla g\u00f6r\u00fcnen kelimelere daha fazla \u00f6nem vererek olu\u015fturulan g\u00f6rsel\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\ndef create_wordcloud(text):\n    stopwords = set(STOPWORDS)\n    wc = WordCloud(background_color=\"white\",\n                  max_words=3000,\n                  stopwords=stopwords,\n                  repeat=True)\n    wc.generate(str(text))\n    plt.figure()\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n\n\n Pozitif yorumlar i\u00e7in kelime bulutu\ncreate_wordcloud(df[df[\"sentiment\"]==\"positive\"][\"summary\"].values)\n\n Negatif yorumlar i\u00e7in kelime bulutu\ncreate_wordcloud(df[df[\"sentiment\"]==\"negative\"][\"summary\"].values)\n\n N\u00f6tr yorumlar i\u00e7in kelime bulutu\ncreate_wordcloud(df[df[\"sentiment\"]==\"neutral\"][\"summary\"].values)\n\n\n 20 Yorumu Belirlerken, art\u0131k yorumlar\u0131n olumlu, olumsuz ve notr olma durumlar\u0131n\u0131 da katabiliriz.\ndf[df[\"sentiment\"]==\"positive\"].sort_values(\"wilson_lower_bound\", ascending=False).head(20)"}}