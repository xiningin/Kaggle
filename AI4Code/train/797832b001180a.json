{"cell_type":{"057ce453":"code","10501954":"code","bd80aad2":"code","d4627652":"code","3b4ba491":"code","b2f30465":"code","f03f8fbd":"code","3f9a6402":"code","6ba359b4":"code","e8844a76":"code","efb09c35":"code","742d4c5b":"code","3a262b88":"code","d7ebe438":"code","f1b802ac":"code","92a01a41":"code","ef67bb7f":"code","6c097da5":"markdown","cf9654d1":"markdown","2cc420f6":"markdown","8cfcdc4c":"markdown","9bcd4005":"markdown","bc096385":"markdown","cb338397":"markdown","70635eb4":"markdown"},"source":{"057ce453":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10501954":"train_data = pd.read_csv('..\/input\/neolen-house-price-prediction\/train.csv', index_col = 'Id')\ntest_data = pd.read_csv('..\/input\/neolen-house-price-prediction\/test.csv', index_col = 'Id')","bd80aad2":"train_data.head()","d4627652":"test_data.head()","3b4ba491":"train_data.shape, test_data.shape","b2f30465":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n#correlation matrix\ncorrmat = train_data.corr()\nf, ax = plt.subplots(figsize=(20, 9))\nsns.heatmap(corrmat, vmax=.8, annot=True)","f03f8fbd":"# most correlated features\ncorrmat = train_data.corr()\ntop_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\nplt.figure(figsize=(10,10))\ng = sns.heatmap(train_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","3f9a6402":"# relation between overallQual feature and salePrice \nsns.barplot(train_data.OverallQual,train_data.SalePrice)","6ba359b4":"sns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train_data[cols], size = 2.5)\nplt.show();","e8844a76":"fig, ax = plt.subplots()\nax.scatter(x = train_data['GrLivArea'], y = train_data['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()\n\n\nfig, ax = plt.subplots()\nax.scatter(x = train_data['TotalBsmtSF'], y = train_data['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('TotalBsmtSF', fontsize=13)\nplt.show()","efb09c35":"#Deleting outliers\ntrain_data = train_data.drop(train_data[(train_data['GrLivArea']>4000) & (train_data['SalePrice']<300000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(train_data['GrLivArea'], train_data['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()\n\n\n#Deleting outliers\ntrain_data = train_data.drop(train_data[(train_data['TotalBsmtSF']>6000) & (train_data['SalePrice']<200000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(train_data['TotalBsmtSF'], train_data['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('TotalBsmtSF', fontsize=13)\nplt.show()","742d4c5b":"from sklearn.model_selection import train_test_split\n\nX = train_data.copy()\ny = X.pop(\"SalePrice\")\n\n# making training and validation set\nx_train, x_valid, y_train, y_valid = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0)\n\nX.head()","3a262b88":"cat_col = [c for c in X.columns if X[c].dtype == 'object']\nnum_col = [c for c in X.columns if X[c].dtype in ['int64', 'float64']]\n\ncol = cat_col + num_col\n\ntrainingX = x_train[col].copy()\nvalidationX = x_valid[col].copy()\ntestingX = test_data[col].copy()","d7ebe438":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_transformer = SimpleImputer(strategy = 'mean')\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown = 'ignore'))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', num_transformer, num_col),\n    ('cat', cat_transformer, cat_col)\n])","f1b802ac":"\n\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n\n\nLRPipeline = Pipeline(steps =[\n    ('preprocess', preprocessor),\n    ('model',LinearRegression())\n])\n\n","92a01a41":"from sklearn.metrics import mean_absolute_error\n\nLRPipeline.fit(trainingX,y_train)\ny_pred = LRPipeline.predict(validationX)\nprint('LR MAE: ',mean_absolute_error(y_pred,y_valid))\nplt.scatter(y_valid, y_pred)\n\n","ef67bb7f":"# Save test predictions to file\ny_pred = LRPipeline.predict(testingX)\n\noutput = pd.DataFrame({'Id': testingX.index,\n                       'SalePrice': y_pred})\noutput.to_csv('submission.csv', index=False)\n\n\n#dataFrame = pd.read_csv('submission.csv')\n#dataFrame.head()","6c097da5":"From the last row, it is evident that some of feature has stronger correlation with the SalePrice than the others.\n\nso let see the feature having correlation of more than 0.5 with the SalePrice ","cf9654d1":"This heatmap shows the 0.79 correlation value between SalePrice and OverallQual. Lets plot them to look what the meaning of having a high correlation value.","2cc420f6":"# Making model","8cfcdc4c":"# Understanding Data","9bcd4005":"As the total area in the house plays big role in deciding the house price, hence we are going to add a new feature called TotalSF","bc096385":"Removing the above outliers: for very high GrLiveArea and TotalBsmtSF there is low price","cb338397":"dropping ID column since it deos'nt play role in prediction process","70635eb4":"It seems from the above figure that there are outliers in GrLiveArea and TotalBsmtSF\n\nlet us examine them closely."}}