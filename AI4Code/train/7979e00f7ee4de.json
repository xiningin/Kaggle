{"cell_type":{"838726ef":"code","5d7fc6d1":"code","a8c206fe":"code","418e9f0f":"code","cde42c21":"code","0bcc4599":"code","de9c1a37":"code","6a43b5df":"code","581d36cf":"code","3fff2f1a":"code","8a976148":"code","bbd99dd1":"code","85d4f3cc":"code","53b682b1":"code","288a3630":"code","ddfc5874":"code","e315f279":"code","4372c328":"code","719e41db":"code","5e9cd0c3":"code","7a360a44":"code","09d37ef7":"code","76185163":"code","a393a9c7":"code","f493489f":"code","c284e352":"code","fb9068cb":"code","608fa7ac":"code","e8c9d9ff":"code","8cdee44c":"code","74ffe221":"code","8b0db386":"code","6f648e38":"code","0da1d4e8":"code","75efe08d":"code","cc5caae9":"code","97e7a3c3":"code","a326fc6a":"markdown","087809c6":"markdown"},"source":{"838726ef":"import numpy as np\nimport pandas as pd","5d7fc6d1":"data = pd.read_csv('..\/input\/news-articles\/NewsArticles.csv',encoding = 'unicode_escape')\ndata.drop_duplicates(keep='first')\ndf = data[['article_id','text','title']]","a8c206fe":"df = df.rename(columns={'article_id':'id', 'text':'document', 'title':'summary'})\ndf = df.dropna()","418e9f0f":"df['document']= df['document'].apply(lambda x: x.lower())\ndf['summary'] = df['summary'].apply(lambda x: x.lower())","cde42c21":"df.info()","0bcc4599":"pd.set_option('display.max_colwidth',None)\ndf.head(1)","de9c1a37":"!pip install datasets transformers rouge-score nltk -q","6a43b5df":"!pip install torch==1.7.1 -q","581d36cf":"import torch\nimport datasets\nfrom datasets import Dataset\nfrom datasets import load_metric","3fff2f1a":"import transformers\nprint(transformers.__version__)","8a976148":"from transformers import AutoTokenizer\n\nmodel_checkpoint ='t5-small'\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\npad_on_right = tokenizer.padding_side == \"right\"","bbd99dd1":"tokenizer(\"Hello, this one sentence!\")","85d4f3cc":"max_input_length = 1024\nmax_target_length = 128","53b682b1":"df = df.sample(frac=1).reset_index(drop=True)\ntrain = df[:3350]\nvalid = df[3350:3690]\ntest = df[3690:]\ntrain.shape, valid.shape,test.shape","288a3630":"def preprocess_function(examples):\n    inputs = ['summarize:' + doc for doc in examples[\"document\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding='max_length')\n\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","ddfc5874":"import torch\nimport datasets\nfrom datasets import Dataset\n\ntrain = Dataset.from_pandas(train)\nvalid = Dataset.from_pandas(valid)","e315f279":"tokenized_train = train.map(preprocess_function, batched=True)\ntokenized_valid = valid.map(preprocess_function, batched=True)","4372c328":"import transformers\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)","719e41db":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","5e9cd0c3":"batch_size = 16\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","7a360a44":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n    \n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    # Extract a few results\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n    \n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    \n    return {k: round(v, 4) for k, v in result.items()}","09d37ef7":"import gc\ngc.collect()","76185163":"# determine the device we will be using for training\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"[INFO] training using {}\".format(torch.cuda.get_device_name(0)))\n#print('There are %d GPU(s) available.' % torch.cuda.device_count())","a393a9c7":"torch.cuda.empty_cache()","f493489f":"%env WANDB_DISABLED=True","c284e352":"model_name = model_checkpoint.split(\"\/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-newsarticles\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True\n)","fb9068cb":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","608fa7ac":"metric = load_metric(\"rouge\")","e8c9d9ff":"trainer.train()","8cdee44c":"eval_dataset = Dataset.from_pandas(test)","74ffe221":"eval_dataset = eval_dataset.map(\n                preprocess_function,\n                batched=True)","8b0db386":"predict_results = trainer.predict(\n            eval_dataset,max_length=128, num_beams=3)","6f648e38":"metrics = predict_results.metrics","0da1d4e8":"metrics","75efe08d":"if args.predict_with_generate:\n    predictions = tokenizer.batch_decode(predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n    predictions = [pred.strip() for pred in predictions]","cc5caae9":"predictions[:2]","97e7a3c3":"test['summary'][:2]","a326fc6a":"### NewsArticles\n\nThis is a reusable publicly-available dataset for \u201cmedia bias\u201d studies. The content of this dataset is publish date, title, subtitle and text for 3824 news articles. These articles are collected by a project within 3 months from December of 2016 to march 2017. The source of these news articles are from ABC News, CNN news, The Huffington Post, BBC News, DW News, TASS News, Al Jazeera News, China Daily and RTE News. All of them are collected by using RSS feeds of each news sites. (2017-3-31)","087809c6":"## Fine tuning "}}