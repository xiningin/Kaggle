{"cell_type":{"84e10c9d":"code","f0bfca91":"code","73515b02":"code","4368a600":"code","a28b1f97":"code","77874a1c":"code","737fe7a0":"code","ca2a973f":"code","a1cb1f7d":"code","b35bbacc":"code","42a57548":"code","f213aa48":"code","4acc41b7":"code","a1b01c1d":"code","ac7e75dd":"code","d9fd9f11":"code","96920b2d":"code","28792ead":"code","86967652":"code","aa66e537":"code","7ed30d8c":"code","9ed988df":"code","205483d1":"code","add1b755":"code","21d93e86":"code","e2a5588d":"code","b9bc8d32":"code","9d48f7a6":"code","b440e75d":"code","07f63b12":"code","7dae2966":"code","971c2132":"code","78aa81bf":"code","2e056dcd":"code","a329b86a":"code","8369d08b":"code","72f80201":"code","328e45c6":"code","5d9df521":"code","49b4a52d":"code","03132c53":"code","00b0fefb":"code","b181b17e":"code","e1146901":"code","23b6058b":"code","2545a215":"code","45e99aae":"code","21c16a67":"code","65506deb":"code","cd290239":"code","51991928":"code","43cb8604":"code","49e6094c":"code","e36e76e1":"code","743a5d7c":"code","280a9cef":"code","a7a1f779":"markdown","bb971ced":"markdown","ef062f2b":"markdown","f7d2f13e":"markdown","020e5f99":"markdown","b68c11f5":"markdown","235de60b":"markdown","010a15b1":"markdown","6c6b1b77":"markdown","6838be8b":"markdown","44f0c223":"markdown","ef9474cd":"markdown","4d9a5206":"markdown","21f4eea6":"markdown","350211f4":"markdown","f247dad3":"markdown"},"source":{"84e10c9d":"pip install pretrainedmodels","f0bfca91":"pip install torchsummary","73515b02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4368a600":"# create data directory\n!rm -rf data\n!mkdir data\n\n# copy data\n!cp -r \/kaggle\/input\/plant-pathology-2020-fgvc7\/images data\n!cp \/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv data\n!cp \/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv data\n!cp \/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv data\n\n# lists data\n!ls data","a28b1f97":"# copy resume files\n!cp \/kaggle\/input\/plant-pathology-resume-files\/distilled_labels.csv .\n#!cp \/kaggle\/input\/plant-pathology-resume-files\/fold_idx.pkl .\n#!cp \/kaggle\/input\/plant-pathology-resume-files\/pred2.pkl .\n#!cp \/kaggle\/input\/plant-pathology-resume-files\/true2.pkl .\n!cp \/kaggle\/input\/plant-pathology-resume-files\/fold_idx_sl.pkl .\n!cp \/kaggle\/input\/plant-pathology-resume-files\/pred_sl2.pkl .\n!cp \/kaggle\/input\/plant-pathology-resume-files\/true_sl2.pkl .\n\n# list current working directory\n!ls","77874a1c":"import platform\nimport fastai\nfrom fastai.vision.all import *\nimport torch\nimport torchvision\nfrom torchsummary import summary\nimport pretrainedmodels\nimport albumentations\nfrom albumentations import (\n    Compose,GaussianBlur,HorizontalFlip,MedianBlur,MotionBlur,OneOf,\n    RandomBrightness,RandomContrast,Resize,ShiftScaleRotate,VerticalFlip\n)\nimport sklearn\nfrom sklearn.model_selection import StratifiedKFold\nimport os\nimport cv2\nimport pandas as pd\nimport pickle\n\nprint('python version:           {}'.format(platform.python_version()))\nprint('fastai version:           {}'.format(fastai.__version__))\nprint('torch version:            {}'.format(torch.__version__))\nprint('torchvision version:      {}'.format(torchvision.__version__))\nprint('pretrainedmodels version: {}'.format(pretrainedmodels.__version__))\nprint('albumentations version:   {}'.format(albumentations.__version__))\nprint('sklearn version:          {}'.format(sklearn.__version__))\nprint('opencv version:           {}'.format(cv2.__version__))\nprint('pandas version:           {}'.format(pd.__version__))\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\") \nprint('CUDA available:           {}'.format(use_cuda))\nprint('cuDNN enabled:            {}'.format(torch.backends.cudnn.enabled))\nprint('num gpus:                 {}'.format(torch.cuda.device_count()))\n\nif use_cuda:\n    print('gpu:                      {}'.format(torch.cuda.get_device_name(0)))\n\n    print()\n    print('------------------------- CUDA -------------------------')\n    ! nvcc --version","737fe7a0":"seed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)","ca2a973f":"data_dir = Path('.\/data')\nimg_dir = data_dir\/'images'\nlabels = ['healthy', 'multiple_diseases', 'rust', 'scab']\nimage_size = [480, 768]","a1cb1f7d":"def load_data(path):\n    df = pd.read_csv(path)\n    df['image_id'] = 'data\/images\/' + df.image_id + '.jpg'\n    df['label'] = df[labels].idxmax(1)\n    return df","b35bbacc":"train_df = load_data(data_dir\/'train.csv')\nprint('dataset size: {}'.format(len(train_df.index)))\ntrain_df.sample(n=5)","42a57548":"train_df[labels].sum().plot(kind='bar');","f213aa48":"train_df['label'].value_counts()","4acc41b7":"for img in train_df.image_id:\n    img_loaded= Image.open(img)\n    if img_loaded.shape == (1365, 2048): continue\n    print(img,img_loaded.shape)","a1b01c1d":"img = Image.open(img_dir\/'Train_245.jpg'); img.size","ac7e75dd":"img = Image.open(img_dir\/'Train_1156.jpg'); img.size","d9fd9f11":"for img in train_df.image_id:\n    img_loaded= Image.open(img)\n    if img_loaded.shape == (1365, 2048): continue\n    img_loaded.transpose(Image.TRANSPOSE).save(img)","96920b2d":"img = Image.open(img_dir\/'Train_245.jpg'); img.size","28792ead":"img = Image.open(img_dir\/'Train_1156.jpg'); img.size","86967652":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n\n        return PILImage.create(aug_img)","aa66e537":"def get_train_aug(image_size): return Compose(\n    [\n        Resize(height=image_size[0], width=image_size[1]),\n        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=1)]), #fastai has\n        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3)], p=0.5),\n        VerticalFlip(p=0.5),#Dihedral\n        HorizontalFlip(p=0.5),\n        ShiftScaleRotate(\n            shift_limit=0.2,\n            scale_limit=0.2,\n            rotate_limit=20,\n            interpolation=cv2.INTER_LINEAR,\n            border_mode=cv2.BORDER_REFLECT_101,\n            p=1,\n        ),\n    ]\n)\n\ndef get_valid_aug(image_size): return  Compose(\n    [\n        Resize(height=image_size[0], width=image_size[1]),\n    ]\n)","7ed30d8c":"item_tfms = [AlbumentationsTransform(get_train_aug(image_size), get_valid_aug(image_size))]\nbatch_tfms = [Normalize.from_stats(*imagenet_stats)]","9ed988df":"dls = ImageDataLoaders.from_df(\n    train_df, bs=16, seed=2020, item_tfms=item_tfms, batch_tfms=batch_tfms, label_col=5\n)","205483d1":"dls.show_batch(max_n=16)","add1b755":"def l2_norm(input, axis=1):\n    norm = torch.norm(input, 2, axis, True)\n    output = torch.div(input, norm)\n    return output\n\n\nclass BinaryHead(nn.Module):\n    def __init__(self, num_class=4, emb_size=2048, s=16.0):\n        super(BinaryHead, self).__init__()\n        self.s = s\n        self.fc = nn.Sequential(nn.Linear(emb_size, num_class))\n\n    def forward(self, fea):\n        fea = l2_norm(fea)\n        logit = self.fc(fea) * self.s\n        return logit\n\n\nclass se_resnext50_32x4d(nn.Module):\n    def __init__(self):\n        super(se_resnext50_32x4d, self).__init__()\n\n        self.model_ft = nn.Sequential(\n            *list(pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](num_classes=1000, pretrained=\"imagenet\").children())[\n                :-2\n            ]\n        )\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.model_ft.last_linear = None\n        self.fea_bn = nn.BatchNorm1d(2048)\n        self.fea_bn.bias.requires_grad_(False)\n        self.binary_head = BinaryHead(4, emb_size=2048, s=1)\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n\n        img_feature = self.model_ft(x)\n        img_feature = self.avg_pool(img_feature)\n        img_feature = img_feature.view(img_feature.size(0), -1)\n        fea = self.fea_bn(img_feature)\n        # fea = self.dropout(fea)\n        output = self.binary_head(fea)\n\n        return output","21d93e86":"model = se_resnext50_32x4d()","e2a5588d":"model","b9bc8d32":"summary(model.to(device), (3, 224, 224))","9d48f7a6":"class CrossEntropyLossOneHot(nn.Module):\n    def __init__(self):\n        super(CrossEntropyLossOneHot, self).__init__()\n        self.log_softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, preds, labels):\n        return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1))","b440e75d":"class OneHotLabelCB(Callback):\n    \n    def before_train(self):\n        self.imgs_list = L(o for o in self.dl.items.iloc[:,0].values) # get list of images in the order they are drawn this epoch\n        self.df = self.dl.items.set_index('image_id')\n    \n    def before_validate(self):\n        self.imgs_list = L(o for o in self.dl.items.iloc[:,0].values) # get list of images in the order they are drawn this epoch\n        self.df = self.dl.items.set_index('image_id')\n\n    def before_batch(self):\n        df = self.df\n        imgs = self.imgs_list[self.dl._DataLoader__idxs[self.iter*self.dl.bs:self.iter*self.dl.bs+self.dl.bs]]\n        one_hot_yb = df.loc[imgs,df.columns[:-1]].values\n        self.learn.yb = (Tensor(one_hot_yb).cuda(),)","07f63b12":"def accuracy(inp, targ, axis=-1):\n    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n    pred,targ = flatten_check(inp.argmax(dim=axis), targ.argmax(dim=axis))\n    return (pred == targ).float().mean()","7dae2966":"def test_predict(cnt,msg):\n    # Create Test Dataloaders\n    test = load_data('data\/sample_submission.csv')\n    test_dl = dls.test_dl(test) \n\n    # predict with test time augmentation\n    preds, _ = learn.tta(dl=test_dl) \n    p = preds.softmax(axis=1) \n\n    # format submission file\n    test = pd.read_csv('data\/sample_submission.csv')['image_id']\n    out_a = pd.concat([test,pd.DataFrame(p,columns = learn.dls.vocab)],axis=1)[['image_id','healthy','multiple_diseases','rust','scab']]\n\n    # write to csv and submit to kaggle\n    out_a.to_csv(f'submission{cnt}.csv',index=False)","971c2132":"#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n#fold_idx = list(skf.split(train_df.image_id,train_df.label))\n#\n#with open('fold_idx.pkl', 'wb') as f:\n#    pickle.dump(fold_idx, f)","78aa81bf":"#with open('fold_idx.pkl', 'rb') as f:\n#    fold_idx = pickle.load(f)\n#    \n#fold_idx = fold_idx[3:]; len(fold_idx)","2e056dcd":"#true = pd.DataFrame(columns = L(o for o in train_df.columns))\n#pred = pd.DataFrame(columns = L(o for o in train_df.columns))","a329b86a":"#with open('true2.pkl', 'rb') as f:\n#    true = pickle.load(f)\n#    \n#with open('pred2.pkl', 'rb') as f:\n#    pred = pickle.load(f)","8369d08b":"#splits, preds, targs, preds_c,  = [],[],[],[]\n##i = 0\n#i = 3\n#\n#for _, val_idx in fold_idx:\n#    splitter = IndexSplitter(val_idx)\n#\n#    # Create dataloaders splittin on indexes defined by StratifiedKFold\n#    db = DataBlock(\n#        blocks=(ImageBlock,CategoryBlock),\n#        get_x=ColReader(0),get_y=ColReader(5),\n#        item_tfms=item_tfms,batch_tfms=batch_tfms,\n#        splitter=splitter\n#    )\n#    dls = db.dataloaders(train_df, bs=24)\n#\n#    #train model with fastai dataloaders, pytorch model, pytorch loss function, fastai gradient clipping, custom callback, on fp16 precision \n#    learn = Learner(dls,se_resnext50_32x4d(),loss_func=CrossEntropyLossOneHot(),cbs=[GradientClip,OneHotLabelCB()], metrics=[accuracy]).to_fp16()\n#    learn.fine_tune(80,reset_opt=True) # Train freeze epoch then unfreeze for 80 epochs   \n#\n#    p, _ = learn.tta() # test time augmentation\n#    p = p.softmax(axis=1) # Convert to probabilities\n#\n#    # Format dataframe to save\n#    items_pred = pd.DataFrame(p, columns=dls.vocab)\n#    items_pred['label'] = [dls.vocab[int(o)] for o in p.argmax(dim=1)]\n#    items_pred['image_id'] = dls.valid.items.image_id.values\n#    items_pred = items_pred[train_df.columns]\n#    \n#    true = pd.concat([true,dls.valid.items])\n#    with open(f'true{i}.pkl', 'wb') as f:\n#        pickle.dump(true, f)\n#    \n#    pred = pd.concat([pred,items_pred])\n#    with open(f'pred{i}.pkl', 'wb') as f:\n#        pickle.dump(pred, f)\n#    \n#    # predict and submit to kaggle\n#    test_predict(i,f'distilling labels fold count {i}') \n#    i += 1","72f80201":"#pred.to_csv('distilled_labels.csv',index=False)","328e45c6":"train_df = load_data(data_dir\/'train.csv')\ntrain_df = train_df.sort_values('image_id')","5d9df521":"distilled_labels = pd.read_csv('distilled_labels.csv')\ndistilled_labels = distilled_labels.sort_values('image_id');\n\n# Get one hot encoded labels (zeros and ones)\ndistilled_labels.iloc[:,1:-1] = pd.get_dummies(distilled_labels.label)","49b4a52d":"assert (train_df.image_id.values==distilled_labels.image_id.values).all()\ndistilled_labels.reset_index(drop=True,inplace=True); train_df.reset_index(drop=True,inplace=True); \n\n# get soft labels\ntrain_df.iloc[:,1:-1] = distilled_labels.iloc[:,1:-1] * .3 + train_df.iloc[:,1:-1] * .7\ntrain_df.loc[train_df.healthy == 0.3][:5]","03132c53":"train_df.head()","00b0fefb":"#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n#fold_idx = list(skf.split(train_df.image_id,train_df.label))\n#\n#with open('fold_idx_sl.pkl', 'wb') as f:\n#    pickle.dump(fold_idx, f)","b181b17e":"with open('fold_idx_sl.pkl', 'rb') as f:\n    fold_idx = pickle.load(f)\n    \nfold_idx = fold_idx[3:]; len(fold_idx)","e1146901":"#true = pd.DataFrame(columns = L(o for o in train_df.columns))\n#pred = pd.DataFrame(columns = L(o for o in train_df.columns))","23b6058b":"with open('true_sl2.pkl', 'rb') as f:\n    true = pickle.load(f)\n    \nwith open('pred_sl2.pkl', 'rb') as f:\n    pred = pickle.load(f)","2545a215":"splits, preds, targs, preds_c,  = [],[],[],[]\n#i = 0\ni = 3\n\nfor _, val_idx in fold_idx:\n    splitter = IndexSplitter(val_idx)\n\n    # Create dataloaders splittin on indexes defined by StratifiedKFold\n    db = DataBlock(\n        blocks=(ImageBlock,CategoryBlock),\n        get_x=ColReader(0),get_y=ColReader(5),\n        item_tfms=item_tfms,batch_tfms=batch_tfms,\n        splitter=splitter\n    )\n    dls = db.dataloaders(train_df, bs=24)\n\n    #train model with fastai dataloaders, pytorch model, pytorch loss function, fastai gradient clipping, custom callback, on fp16 precision \n    learn = Learner(dls,se_resnext50_32x4d(),loss_func=CrossEntropyLossOneHot(),cbs=[GradientClip,OneHotLabelCB()], metrics=[accuracy]).to_fp16()\n    learn.fine_tune(80,reset_opt=True) # Train freeze epoch then unfreeze for 80 epochs   \n\n    p, _ = learn.tta() # test time augmentation\n    p = p.softmax(axis=1) # Convert to probabilities\n\n    # Format dataframe to save\n    items_pred = pd.DataFrame(p, columns=dls.vocab)\n    items_pred['label'] = [dls.vocab[int(o)] for o in p.argmax(dim=1)]\n    items_pred['image_id'] = dls.valid.items.image_id.values\n    items_pred = items_pred[train_df.columns]\n    \n    true = pd.concat([true,dls.valid.items])\n    with open(f'true_sl{i}.pkl', 'wb') as f:\n        pickle.dump(true, f)\n    \n    pred = pd.concat([pred,items_pred])\n    with open(f'pred_sl{i}.pkl', 'wb') as f:\n        pickle.dump(pred, f)\n    \n    # predict and submit to kaggle\n    test_predict(i,f'distilling labels fold count {i}') \n    i += 1","45e99aae":"test = pd.read_csv('data\/sample_submission.csv')['image_id']\nout = pd.concat([test,pred],axis=1)[['image_id','healthy','multiple_diseases','rust','scab']]","21c16a67":"pred.to_csv('submission_final.csv',index=False)","65506deb":"pred","cd290239":"test.shape","51991928":"pred2 = pred.copy()","43cb8604":"pred2['image_id'] = test","49e6094c":"pred2[['image_id','healthy','multiple_diseases','rust','scab']].to_csv('submission_final_real.csv',index=False)","e36e76e1":"distilled_labels = pd.read_csv('distilled_labels.csv'); distilled_labels","743a5d7c":"distilled_labels['image_id'] = test","280a9cef":"distilled_labels[['image_id','healthy','multiple_diseases','rust','scab']].to_csv('submission_distilled_real.csv',index=False)","a7a1f779":"### Inference","bb971ced":"# Plant Pathology\n- Dataset: https:\/\/arxiv.org\/abs\/2004.11958\n- Approach from: https:\/\/isaac-flath.github.io\/fastblog\/deep%20learning\/2021\/02\/15\/PlantPathology.html (author: [Isaac Flath](https:\/\/github.com\/Isaac-Flath))\n- General Hints: https:\/\/twitter.com\/abhi1thakur\/status\/1360954451104829441\n- Alternative Approach: https:\/\/hamonk.github.io\/2020\/12\/05\/plant_pathology.html#what-worked (not implemted here)\n- you need accuracy with variance attached to it, https:\/\/www.youtube.com\/watch?v=0LIACHcxpHU","ef062f2b":"## Train (Soft Labeling)","f7d2f13e":"### Train (5 Folds)","020e5f99":"### Define Transforms","b68c11f5":"### Metric","235de60b":"### Clean Data","010a15b1":"## Data","6c6b1b77":"## Model","6838be8b":"Stratified K-Fold: https:\/\/towardsdatascience.com\/stratified-k-fold-what-it-is-how-to-use-it-cf3d107d3ea2","44f0c223":"### Load Data","ef9474cd":"### One-Hot-Label Callback","4d9a5206":"### Create Dataloader","21f4eea6":"### EDA","350211f4":"## Train","f247dad3":"### Loss Function"}}