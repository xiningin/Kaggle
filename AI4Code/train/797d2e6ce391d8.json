{"cell_type":{"d9028879":"code","0e4278c7":"code","c318d909":"code","24995c6e":"code","36e8e02e":"code","74d511cb":"code","a64e59c2":"code","a268eead":"code","356f087b":"code","ac45a268":"code","2bddd28c":"code","da2db29e":"code","540bb1c8":"code","b776f1ab":"code","357d8ee4":"code","8a8bd020":"code","ee1c3c4b":"code","15d428f1":"code","c192d936":"code","35e2809d":"code","ddd355bd":"code","f32b97d8":"code","6cee7ea6":"code","ba33a5cf":"code","0e45a07e":"code","efead934":"code","3f5f9c32":"code","ca15a7ab":"code","84c65c1a":"code","1f9912c3":"code","0bd59a98":"code","32cd2ee4":"code","4770b210":"code","5f199a5f":"code","f67e7c86":"code","6244dc47":"code","4cf6f99a":"code","f94929a8":"code","f708af9f":"code","bea8e271":"code","bb184f33":"code","72221750":"code","d1771e0b":"code","9f2881e2":"code","0151b4b6":"code","cb351eb1":"code","0bb9b580":"code","7cb0c896":"code","b1082e75":"code","4fa7ac94":"markdown","dc9e5883":"markdown","bb96005e":"markdown","e0ea360b":"markdown","81e80f78":"markdown","6434ce18":"markdown","e7957728":"markdown","a2e8e6d0":"markdown","76ed7c72":"markdown"},"source":{"d9028879":"import os \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname,filename))","0e4278c7":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nimport warnings #  for avoid unwanted warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.core.display import display, HTML # for HTMl tag use in python","c318d909":"pd.set_option('display.max_columns',None) # to show maximum number of columns","24995c6e":"dataset=pd.read_csv('\/kaggle\/input\/walmart-dataretail-analysis\/Walmart_Store_sales.csv')","36e8e02e":"dataset.head()","74d511cb":"dataset.shape ","a64e59c2":"dataset.describe().T ","a268eead":"stores_all=dataset['Store'].value_counts()\nstores_all","356f087b":"dataset['Holiday_Flag'].value_counts() # holidays and non-holidays ","ac45a268":"dataset.info()","2bddd28c":"dataset.isnull().sum() # no missing data","da2db29e":"dataset.duplicated().sum()","540bb1c8":"dataset.head()","b776f1ab":"store_by_sale=dataset.groupby('Store')['Weekly_Sales']","357d8ee4":"stores_all\nstore_sale=dataset.groupby('Store')['Weekly_Sales'].sum()\nstore_sale_max=store_sale.sort_values(ascending=False) # show all store with their sale in highest to lowest\nprint(f'Maximum Sale is ${store_sale_max.values[0]} from store_{store_sale_max.keys()[0]}') ","8a8bd020":"#All Store Sales \nplt.figure(figsize=(20,5))\ny=list(store_sale_max.values[0:10])\nx=list(store_sale_max.keys()[0:10])\n# sns.barplot(data=store_sale_max,y=y,x=x) \n# plt.bar(x,y) \nplt.pie(y,labels=x,autopct='%0.2f%%')\nplt.show()","ee1c3c4b":"#Top 10 Sales \ntop=10\nfor i in range(top): \n    print(f'Maximum Sale is ${store_sale_max.values[i]} from store_{store_sale_max.keys()[i]}')   ","15d428f1":"store_by_sale.std()\nx=store_by_sale.std().sort_values(ascending=False).values[0]\ny=store_by_sale.std().sort_values(ascending=False).keys()[0] \nprint(f'Maximum Standard Deviation is {x} of Store_{y}')","c192d936":"dataset.head()","35e2809d":"dataset['Holiday_Flag'].value_counts()","ddd355bd":"dataset['Date'].value_counts()","f32b97d8":"a=dataset[dataset['Date']== '12-02-2010']['Weekly_Sales'].sum()\nb=dataset[dataset['Date']== '11-02-2011']['Weekly_Sales'].sum()\nc=dataset[dataset['Date']== '10-02-2012']['Weekly_Sales'].sum()\nd=dataset[dataset['Date']== '08-02-2013']['Weekly_Sales'].sum() \nsuper_bowl_sale = a+b+c+d\n\na1=dataset[dataset['Date']== '10-09-2010']['Weekly_Sales'].sum()\nb1=dataset[dataset['Date']== '09-09-2011']['Weekly_Sales'].sum()\nc1=dataset[dataset['Date']== '07-09-2012']['Weekly_Sales'].sum()\nd1=dataset[dataset['Date']== '06-09-2013']['Weekly_Sales'].sum() \nlabour_day_sale = a1+b1+c1+d1\n\na2=dataset[dataset['Date']== '26-11-2010']['Weekly_Sales'].sum()\nb2=dataset[dataset['Date']== '25-11-2011']['Weekly_Sales'].sum()\nc2=dataset[dataset['Date']== '23-11-2012']['Weekly_Sales'].sum()\nd2=dataset[dataset['Date']== '29-11-2013']['Weekly_Sales'].sum() \nthanks_giving_sale = a2+b2+c2+d2\n\na3=dataset[dataset['Date']== '31-12-2010']['Weekly_Sales'].sum()\nb3=dataset[dataset['Date']== '30-12-2011']['Weekly_Sales'].sum()\nc3=dataset[dataset['Date']== '28-12-2012']['Weekly_Sales'].sum()\nd3=dataset[dataset['Date']== '27-12-2013']['Weekly_Sales'].sum() \nchristmas = a3+b3+c3+d3\n\nprint('super_bowl_sale : ',super_bowl_sale)\nprint('labour_day_sale : ',labour_day_sale)\nprint('thanks_giving_sale : ',thanks_giving_sale)\nprint('christmas : ',christmas)","6cee7ea6":"plt.figure(figsize=(10,5))\nsns.barplot(x=list(['super_bowl_sale','labour_day_sale','thanks_giving_sale','christmas']),y=list([super_bowl_sale,labour_day_sale,thanks_giving_sale,christmas]))\nplt.show()","ba33a5cf":"#Quater_3 = Q3 = july-sept","0e45a07e":"# Date format seperated into year,month and quater\ndataset['Date']=pd.to_datetime(dataset['Date'])\nmonthlysale=dataset.groupby([dataset['Date'],dataset['Store']])['Weekly_Sales'].agg(sum).reset_index()\n\nmonthlysale['Year']=monthlysale['Date'].dt.year\nmonthlysale['Month'] = monthlysale['Date'].dt.month\nmonthlysale['Quarter'] = monthlysale['Date'].dt.quarter\nmonthlysale['Date_wise']=monthlysale['Date'].dt.day\nmonthlysale","efead934":"monthlysale.head()","3f5f9c32":"Q3_Sale_2012=monthlysale[(monthlysale['Quarter'] == 3) & ((monthlysale['Month']<=9) & (monthlysale['Month']>=7)) & (monthlysale['Year']==2012) ]\na=Q3_Sale_2012['Weekly_Sales'].sum()\nb=Q3_Sale_2012['Weekly_Sales'].mean()\nc=Q3_Sale_2012['Weekly_Sales'].std()\ndisplay(HTML(f'<b>Total<\/b> 3rd-Quaterly Sale in 2012 : <b>$ {round(a,2)}<\/b>'))\ndisplay(HTML(f'<b>Average<\/b> 3rd-Quaterly Sale in 2012 : <b>$ {round(b,2)}<\/b>'))\ndisplay(HTML(f'<b>Standrd Deviation<\/b> 3rd-Quaterly Sale in 2012 : <b>$ {round(c,2)}<\/b>'))","ca15a7ab":"display(HTML(\"<h6>Which store's has good quarterly growth rate in Q3\u20192012?<\/h6>\"))\na=Q3_Sale_2012.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False).keys()[0]\nb=Q3_Sale_2012.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False).values[0]\ndisplay(HTML(f'<b>Store_{a}<\/b> , because it have maximum sale in quarter3 2012 which is <b>$ {b}<\/b>'))","84c65c1a":"#heatmap\nplt.figure(figsize=(15,10))\nsns.heatmap(dataset.corr(),cmap='RdYlBu',annot=True)\nplt.show()","1f9912c3":"dataset","0bd59a98":"dataset.info()","32cd2ee4":"# dataset=pd.get_dummies(dataset)\ndataset","4770b210":"dataset.dtypes","5f199a5f":"y = pd.get_dummies(dataset[\"Store\"]) #One hot encoding the store \ndataset = dataset.drop('Store',axis = 1)\n# Join the encoded df\ndataset = dataset.join(y)","f67e7c86":"from sklearn.preprocessing import StandardScaler # for normilization data https:\/\/i.stack.imgur.com\/obywE.png\n\nscaler = StandardScaler()\nscale_temp = scaler.fit_transform(dataset[['Temperature']]) \ndataset['Temperature'] = scale_temp\nscale_fuel = scaler.fit_transform(dataset[['Fuel_Price']]) \ndataset['Fuel_Price'] = scale_fuel\nscale_unemployment = scaler.fit_transform(dataset[['Unemployment']]) \ndataset['Unemployment'] = scale_unemployment","6244dc47":"x=dataset.drop(columns=['Weekly_Sales','Date'],axis=1)\ny=dataset['Weekly_Sales']","4cf6f99a":"from sklearn.model_selection import train_test_split\nx_train, x_test,y_train, y_test=train_test_split(x,y,train_size=0.75,random_state=1)","f94929a8":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","f708af9f":"from sklearn.linear_model import LinearRegression","bea8e271":"model=LinearRegression()","bb184f33":"model.fit(x_train,y_train)","72221750":"y_predict=model.predict(x_test)","d1771e0b":"from sklearn.metrics import r2_score,mean_squared_error","9f2881e2":"r2=r2_score(y_test,y_predict)\nMSE=mean_squared_error(y_test,y_predict)\ndisplay(HTML(f'<h2>Accurecy is : {round(r2*100,2)} %<\/h2>'))# It's R square value\nprint('Mean Square Error :',MSE)","0151b4b6":"plt.figure(figsize=(15,6))\nsns.regplot(x=y_test, y=y_predict) \nplt.show()","cb351eb1":"y_error=y_test-y_predict\n# accurcy=round((y_predict-y_test)*100\/y_test,2)\n\nerror_data=pd.DataFrame(np.array([y_test,y_predict,y_error\n                                 ])).T\nerror_data=error_data.rename(columns={0:'Actual',1:'Predicted',2:'Error',3:'Accurcy%'})\nerror_data\n","0bb9b580":"plt.figure(figsize=(17,5))\nno_of_data_show =20 # type here how many data you want to show\npredicted = list(error_data['Predicted'])[0:no_of_data_show] \nactual = list(error_data['Actual'])[0:no_of_data_show]\n\nn=len(predicted) \nr = np.arange(n)\nwidth = 0.25\n\n  \nplt.bar(r, predicted, color = 'y',width = width, edgecolor = 'black',label='Predicted')\nplt.bar(r + width, actual, color = 'g',width = width, edgecolor = 'black',label='Actual')\n  \nplt.xlabel(\"No of Datas\",fontsize=12,weight=\"bold\")\nplt.ylabel(\"Data Range\",fontsize=12,weight=\"bold\")\nplt.title(\"Data Accuracy\\n\",fontsize=20,weight=\"bold\")\nplt.legend(fontsize=15)\nplt.grid(color='b', linestyle='-', linewidth=0.9)\nplt.xticks(np.arange(0, no_of_data_show, step=1)) \nplt.show()","7cb0c896":"# For Show statistics\nimport statsmodels.api as si\nmod=si.OLS(y_train,x_train)\nresult=mod.fit()\n\nprint(result.summary())","b1082e75":"# we will give them whole data y and x\n# For Show statistics\nimport statsmodels.api as si\nmod=si.OLS(y,x)\nresult=mod.fit()\n\nprint(result.summary())","4fa7ac94":"<h3>Holiday Events Sale<\/h3>\n<p><b>Super Bowl<\/b>:12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13<\/p>\n<p><b>Labour Day<\/b>: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13<\/p>\n<p><b>Thanksgiving<\/b>: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13<\/p>\n<p><b>Christmas<\/b>: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13<\/p>","dc9e5883":"import opendatasets as od<br>\nod.download(\"https:\/\/www.kaggle.com\/vik2012kvs\/walmart-dataretail-analysis\")","bb96005e":"<h1>How to download kaggle dataset<\/h1>","e0ea360b":"<h1>Problem Statement<\/h1>\n\nOne of the leading retail stores in the US, Walmart, would like to predict the sales and demand accurately. There are certain events and holidays which impact sales on each day. There are sales data available for 45 stores of Walmart. The business is facing a challenge due to unforeseen demands and runs out of stock some times, due to the inappropriate machine learning algorithm. An ideal ML algorithm will predict demand accurately and ingest factors like economic conditions including CPI, Unemployment Index, etc.\n\nWalmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of all, which are the Super Bowl, Labour Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge presented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of complete\/ideal historical data. Historical sales data for 45 Walmart stores located in different regions are available.\n<h1>Dataset Description<\/h1>\n\nThis is the historical data that covers sales from 2010-02-05 to 2012-11-01, in the file WalmartStoresales. Within this file you will find the following fields:\n\nStore - the store number\n\nDate - the week of sales\n\nWeekly_Sales - sales for the given store\n\nHoliday_Flag - whether the week is a special holiday week 1 \u2013 Holiday week 0 \u2013 Non-holiday week\n\nTemperature - Temperature on the day of sale\n\nFuel_Price - Cost of fuel in the region\n\nCPI \u2013 Prevailing consumer price index\n\nUnemployment - Prevailing unemployment rate\n\nHoliday Events\n\nSuper Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\nLabour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\nThanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\nChristmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n\nAnalysis Tasks\n\nBasic Statistics tasks\n\nWhich store has maximum sales\n\nWhich store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation\n\nWhich store\/s has good quarterly growth rate in Q3\u20192012\n\nSome holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together\n\nProvide a monthly and semester view of sales in units and give insights\n\nStatistical Model\n\nFor Store 1 \u2013 Build prediction models to forecast demand\n\nLinear Regression \u2013 Utilize variables like date and restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order). Hypothesize if CPI, unemployment, and fuel price have any impact on sales.\n\nChange dates into days by creating new variable.","81e80f78":"# Multiple Linear Regression","6434ce18":"<h5>Which store's has good quarterly growth rate in Q3\u20192012<\/h5>","e7957728":"<h5>Which store has maximum standard deviation<\/h5>","a2e8e6d0":"# Data Accurecy Check with comparing ACTUAL vs PREDICTED","76ed7c72":"<h5>which store has maximum sale?<\/h5>"}}