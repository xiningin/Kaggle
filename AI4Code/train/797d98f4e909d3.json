{"cell_type":{"fad16776":"code","8e134735":"code","fa00cd18":"code","75dd4cd3":"code","81635da3":"code","4ecbcdaf":"code","9e633fa9":"code","f8b76bd9":"code","d1df450c":"code","f3abe12f":"code","2311bfa1":"code","ab4fa70b":"code","29a04197":"code","2d955de4":"markdown","af1aa8fe":"markdown","55bb4b46":"markdown","902e95a4":"markdown","c0595b1b":"markdown","fd6b66ff":"markdown","f00da392":"markdown","90c0c330":"markdown","096c3aa1":"markdown","3a6d2213":"markdown","74d2a489":"markdown","05869e53":"markdown"},"source":{"fad16776":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e134735":"from sklearn.datasets import make_classification\nx,y=make_classification(n_samples=2000,n_features=20,n_classes=2,weights=[1,1],random_state=1)","fa00cd18":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=1)","75dd4cd3":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","81635da3":"from sklearn.ensemble import RandomForestClassifier\nrfmod=RandomForestClassifier()\nrfmod.fit(xtrain,ytrain)\nytrainpred=rfmod.predict_proba(xtrain)\nprint(\"Random Forest train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=rfmod.predict_proba(xtest)\nprint(\"Random Forest train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","4ecbcdaf":"from sklearn.linear_model import LogisticRegression\nlogmod=LogisticRegression()\nlogmod.fit(xtrain,ytrain)\nytrainpred=logmod.predict_proba(xtrain)\nprint(\"Logistic regression train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=logmod.predict_proba(xtest)\nprint(\"Logistic regression train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","9e633fa9":"from sklearn.ensemble import AdaBoostClassifier\nadamod=AdaBoostClassifier()\nadamod.fit(xtrain,ytrain)\nytrainpred=adamod.predict_proba(xtrain)\nprint(\"Ada Boost train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=adamod.predict_proba(xtest)\nprint(\"Ada Boost train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","f8b76bd9":"from sklearn.neighbors import KNeighborsClassifier\nknnmod=KNeighborsClassifier()\nknnmod.fit(xtrain,ytrain)\nytrainpred=knnmod.predict_proba(xtrain)\nprint(\"K Nearest Neighbor Classifier  train roc-auc score {}\".format(roc_auc_score(ytrain,ytrainpred[:,1])))\nytestpred=knnmod.predict_proba(xtest)\nprint(\"K Nearest Neighbor Classifier train roc-auc score {}\".format(roc_auc_score(ytest,ytestpred[:,1])))","d1df450c":"pred=[]\nfor model in [rfmod,logmod,adamod,knnmod]:\n    pred.append(pd.Series(model.predict_proba(xtest)[:,1]))\nfinalpred=pd.concat(pred,axis=1).mean(axis=1)\nprint(\"Ensemble models test roc-auc score {}\".format(roc_auc_score(ytest,finalpred)))","f3abe12f":"fpr,tpr,threshold= roc_curve(ytest,finalpred)\nthreshold","2311bfa1":"from sklearn.metrics import accuracy_score\nacc=[]\nfor thres in threshold:\n    ypred=np.where(finalpred>thres,1,0)\n    acc.append(accuracy_score(ytest,ypred,normalize=True))\nacc=pd.concat([pd.Series(acc),pd.Series(threshold)],axis=1)\nacc.columns=['Accuracy','Threshold']\nacc.sort_values(by='Accuracy',ascending=False,inplace=True)\nacc.head()","ab4fa70b":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='red', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","29a04197":"plot_roc_curve(fpr,tpr)","2d955de4":"# **Ada Boost Classifier**","af1aa8fe":"**Now we are going to calculate the mean of all predictions of the  x test data to make a final prediction data**","55bb4b46":"**Lets make a dataset to create a model for binary classification**","902e95a4":"**Thus we can say that the threshold of value 0.44 will give high model accuracy**","c0595b1b":"# **Random Forest**","fd6b66ff":"**The roc curve gives some threshold values. We have to select the correct threshold value which gives more model accuracy.**","f00da392":"# **K Nearest Neighbor Classifier**","90c0c330":"**Thus we can say that the roc curve is well structured.**","096c3aa1":"# **Logistic Regression**","3a6d2213":"# **Train test split**","74d2a489":"**We are going to create models using some algorithms**","05869e53":"# **ROC-AUC CURVE**\n**ROC stands for Receiver Operating Characteristic, AUC stands for area under curve. ROC-AUC  is used as a metrics for classification problems. It is used to pick the correct threshold for the classification problem. The area under curve varies between 0-1. AUC-1 is the model with high accuracy and with 0 is the worst model. 0.5 is not a good model as it will not correctly predict the classes. The higher the area under the curve, the higher the model performance**"}}