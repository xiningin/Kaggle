{"cell_type":{"49b191a4":"code","b2f1327d":"code","19c9a06c":"code","5c0d2957":"code","4168cfd2":"code","063b6d83":"code","0c189e52":"code","9e87a4a0":"code","fa08d5b6":"code","0415e672":"code","9c216eac":"code","45f33364":"code","4a424e3e":"code","460fc253":"code","1d5bd076":"code","0a9d4e97":"code","d0f59328":"code","641d0ad6":"markdown"},"source":{"49b191a4":"import warnings\n\n#ignore Warnings\n\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n\n#Manipulasi data\nimport numpy as np\nimport pandas as pd\n\n#Visualisasi Data\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n#Model Selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.preprocessing import LabelEncoder\n\n#preprocess\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#dl libraries \nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom keras.utils import to_categorical\n\n#specially for CNN\nfrom keras.layers import Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization\n\nimport tensorflow as tf\nimport random as rn\n\n#soepecially for manipulating Zipped image and getting numpy arrays\nimport cv2\nimport os\nfrom PIL import Image\n\n#save train data and model\nimport joblib","b2f1327d":"data = pd.read_csv('\/kaggle\/input\/fer2013-dataset\/fer2013.csv')\ndata.head()","19c9a06c":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nwidth, height = 48, 48\n\ndatapoints = data['pixels'].tolist()\n\n#getting features for training\nX = []\nfor xseq in datapoints:\n    xx = [int(xp) for xp in xseq.split(' ')]\n    xx = np.asarray(xx).reshape(width, height)\n    X.append(xx.astype('float32'))\n\nX = np.asarray(X)\nX = np.expand_dims(X, -1)\n\n#getting labels for training\ny = data['emotion']\n\nprint(\"Preprocessing Done\")\nprint(\"Number of Features: \"+str(len(X[0])))\nprint(\"Number of Labels: \"+ str(len(y)))\nprint(\"Number of examples in dataset:\"+str(len(X)))\nprint(\"X,y stored in fdataX.npy and flabels.npy respectively\")","5c0d2957":"labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\nimport random as rn\nw=10\nh=10\nfig=plt.figure(figsize=(10, 15))\ncolumns = 4\nrows = 5\nfor i in range(1, columns*rows +1):\n#     img = np.random.randint(10, size=(h,w))\n    fig.add_subplot(rows, columns, i)\n    angka_random = rn.randint(1,len(X))\n    plt.imshow(X[angka_random].reshape(48,48), cmap = 'gray')\n    plt.title(labels[y[angka_random]])\nplt.show()","4168cfd2":"# storing them using numpy\nnp.save('fdataX', X)\nnp.save('flabels', y)","063b6d83":"Y = to_categorical(y,len(labels))\nX = np.array(X)\nX = X\/255 #proses normalisasi","0c189e52":"X_new = []\nfor i in range(len(X)):\n    stacked_img = np.stack((X[i].reshape(48,48),)*3, axis=-1)\n    X_new.append(stacked_img)\n\nX_new = np.array(X_new)","9e87a4a0":"x_train, x_test, y_train, y_test = train_test_split(X_new, Y, test_size = 0.2)\nprint(\"Data Train Shape\")\nprint(\"X_TRAIN : \", x_train.shape)\nprint(\"Y_TRAIN : \", y_train.shape)\n\nprint(\"Data Test Shape\")\nprint(\"X_TRAIN : \", x_test.shape)\nprint(\"Y_TRAIN : \", y_test.shape)","fa08d5b6":"from keras.applications.xception import Xception\nfrom keras.layers import Activation, Dense,GlobalAveragePooling2D, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n\nbase_model = Xception(weights='imagenet', include_top=False )\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(512, activation='relu')(x)\n\nx = Dropout(0.3)(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(7, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nmodel.summary()","0415e672":"batch_size= 64\nepochs= 50\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=epochs,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=5,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,reduce_lr]","9c216eac":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","45f33364":"# Compile the model\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nHistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, \n                              callbacks=callbacks,\n                              validation_data = (x_test,y_test),\n                              verbose = 1)","4a424e3e":"plt.figure(figsize=(15, 3))\nplt.subplot(121)\n\nplt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\n\n\nplt.subplot(122)\nplt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\n\nplt.savefig('Xception.png')\nplt.show()","460fc253":"#saving the  model to be used later\nfer_json = model.to_json()\nwith open(\"mymodel.json\", \"w\") as json_file:\n    json_file.write(fer_json)\nmodel.save_weights(\"model_weight.h5\")\nprint(\"Saved model to disk\")\n\njoblib.dump(History, 'history.h5')","1d5bd076":"def confusion_matrix_img(y_pred, y_true, savename):\n    cm = confusion_matrix(y_true, y_pred)\n    labels = ['Angry','Sad', 'Happy','Fear','Surprise']\n    title='Confusion matrix'\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45)\n    plt.yticks(tick_marks, labels)\n    fmt = 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.savefig(savename)\n    plt.show()","0a9d4e97":"truey=[]\npredy=[]\nx = x_test\ny = y_test\n\nyhat= model.predict(x)\nyh = yhat.tolist()\nyt = y.tolist()\ncount = 0\n\nfor i in range(len(y)):\n    yy = max(yh[i])\n    yyt = max(yt[i])\n    predy.append(yh[i].index(yy))\n    truey.append(yt[i].index(yyt))\n    if(yh[i].index(yy)== yt[i].index(yyt)):\n        count+=1\n\nacc = (count\/len(y))*100\n\n#saving values for confusion matrix and analysis\nnp.save('truey', truey)\nnp.save('predy', predy)\nprint(\"Predicted and true label values saved\")\nprint(\"Accuracy on test set :\"+str(acc)+\"%\")","d0f59328":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n\nconfusion_matrix_img(truey, predy, savename='Confusion Matrix')","641d0ad6":"# Preprocessing\ni got preprocessing code from https:\/\/github.com\/gitshanks\/fer2013"}}