{"cell_type":{"eb7a85c2":"code","04ae55ca":"code","4b33ae74":"code","4ffe0073":"code","5eccc0a6":"code","4c879b2c":"code","4c9205f4":"code","6e7ef8bc":"code","72967b9d":"code","6765e0c0":"code","3db1cbdb":"code","6be87e11":"code","8c773c0c":"code","25d120bc":"code","e264f1bc":"code","d17c412c":"code","c8a18b7a":"code","ac4fa394":"code","fbf74543":"code","7c1938bd":"code","0b59028a":"code","09495589":"code","5d2ec520":"code","9832dc69":"code","cad469f1":"code","1917a59f":"code","08117f59":"code","7eac2548":"code","65977aaa":"code","1840ba11":"code","56f3567d":"code","5e7fba9e":"code","930f1de8":"code","b8344b57":"code","5aa134ef":"code","67506fcb":"code","e3f90600":"code","1f054f1f":"code","5a5e1521":"code","7806e1b8":"code","74df5d5d":"code","43addcd9":"code","e1b66d10":"code","51edacac":"code","514f47d4":"code","ddc8e93b":"code","755b729b":"code","8957077c":"code","de73d6dc":"code","8ee3f243":"code","2fa7a218":"code","a7031383":"code","8afc01d4":"code","dbc7b57c":"code","98cbe3a1":"code","fb0e2d9c":"code","26ed58bf":"code","21880816":"code","23454f64":"code","a85a0caa":"code","596f2058":"code","94e72b69":"code","b4a18211":"code","854da4fb":"code","9915c5cc":"code","494cbf3d":"code","8c48cc6e":"code","7a1bd853":"code","0cefce9f":"code","a26616e4":"code","17e52f08":"code","1416dce2":"code","8f19aeb2":"code","c9053088":"code","08ec05a9":"code","e8a4cc8d":"code","66f1bab1":"code","f2866d8b":"code","498fd953":"code","a45ae308":"code","db6b3e6a":"code","e57bb1e1":"code","2b354a14":"code","9d7c4eec":"code","1de7010f":"code","7efab1d6":"code","454e4747":"markdown","27b1ff12":"markdown","bf5dad74":"markdown","25578e51":"markdown","f63b52cf":"markdown","51a12f67":"markdown","547a51bc":"markdown","41fb40c7":"markdown","03b3032b":"markdown","ef3da391":"markdown","abac5c3f":"markdown","5557887d":"markdown","fea4bb86":"markdown","0069d4f3":"markdown","d97bb865":"markdown","37250042":"markdown","f51add5c":"markdown","dd8f642a":"markdown","76782b4c":"markdown","260ab1f6":"markdown","b512ccac":"markdown","05225445":"markdown","f85e3151":"markdown"},"source":{"eb7a85c2":"import pandas as pd\nimport numpy as np\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n","04ae55ca":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","4b33ae74":"# first look to head of traind data\ndf_train.head()\n","4ffe0073":"# first look to head of test data\ndf_test.head()\n","5eccc0a6":"#informT\u0130ON bout trainata\ndf_train.info();","4c879b2c":"#column datatypes and counts\ndf_train.dtypes.value_counts()","4c9205f4":"# Number of unique classes in each object column\ndf_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","6e7ef8bc":"df_numericVariables = df_train.select_dtypes(include = ['float64', 'int64']) \ndf_numericVariables.head()","72967b9d":"df_train.shape","6765e0c0":"#check for any missing values\ndf_train.isnull().sum()","3db1cbdb":"df_train['Cabin'].isnull().sum() ","6be87e11":"# Percentage of missing values, method-1\n    print(\"Missing Value % of Cabin: \"+str(100 * df_train['Cabin'].isnull().sum() \/ len(df_train)))\n    print(\"Missing Value % of Age: \"+str(100 * df_train['Age'].isnull().sum() \/ len(df_train)))\n    print(\"Missing Value % of Embarked: \"+str(100 * df_train['Embarked'].isnull().sum() \/ len(df_train)))","8c773c0c":"# Percentage of missing values, method-2\n\ndef missingValues_table(df):\n    \n    # Total missing values\n    mis_val = df.isnull().sum()\n    \n    # Percentage of missing values\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n                                mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n                                '% of Total Values', ascending=False).round(1)\n        \n    # Print some summary information\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n            \" columns that have missing values.\")\n        \n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns","25d120bc":"# method-2 for finding missing values\n\nmissingValues = missingValues_table(df_train)\nmissingValues","e264f1bc":"columNames = df_train.columns\nprint(columNames)","d17c412c":"df_train.describe(include=\"all\")","c8a18b7a":"df_train.describe().T","ac4fa394":"df_train.groupby([\"Sex\"])[[\"Age\",\"Survived\"]].aggregate(\"mean\")","fbf74543":"df_train.groupby([\"Sex\",\"Pclass\",\"Survived\"])[[\"Age\"]].aggregate(\"mean\")","7c1938bd":"df_train.isnull().sum()","0b59028a":"df_train['Embarked'].value_counts()","09495589":"df_train['Survived'].value_counts()","5d2ec520":"df_train['Pclass'].value_counts()","9832dc69":"df_train['SibSp'].value_counts()","cad469f1":"df_train['Parch'].value_counts()","1917a59f":"df_train['Cabin'].value_counts()","08117f59":"df_train['Cabin'].describe()","7eac2548":"sns.barplot(x = 'Pclass', y = 'Survived', hue='Sex',  data = df_train);","65977aaa":"#Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\nsns.barplot(x = 'Embarked', y = 'Survived',   data = df_train);\n","1840ba11":"sns.barplot(x = 'Sex', y = 'Survived', data = df_train);","56f3567d":"sns.barplot(x = 'SibSp', y = 'Survived', data = df_train);","5e7fba9e":"sns.barplot(x = 'Parch', y = 'Survived', data = df_train);","930f1de8":"df_yeni=df_train[['Survived', 'Pclass', 'Sex','Age','SibSp','Parch']] \nsns.pairplot(df_yeni);","b8344b57":"df_numericVariables.head()","5aa134ef":"\nsns.boxplot(x = df_numericVariables['Age']);","67506fcb":"# We can drop the Ticket feature since it is unlikely to have useful information\ndf_train.head()","e3f90600":"df_train = df_train.drop(['Ticket'], axis = 1)\ndf_test = df_test.drop(['Ticket'], axis = 1)\n","1f054f1f":"#we'can  dropp the Cabin feature since \ndf_train = df_train.drop(['Cabin'], axis = 1)\ndf_test = df_test.drop(['Cabin'], axis = 1)","5a5e1521":"df_train.describe().T","7806e1b8":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = df_train['Fare']);","74df5d5d":"\nQ1 = df_train['Fare'].quantile(0.25)\nQ3 = df_train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nupper_limit = Q3 + 1.5*IQR","43addcd9":"print(\"Fare lower Limit: \"+str(lower_limit))","e1b66d10":"print(\"Fare upper Limit: \"+str(upper_limit))","51edacac":"df_train.sort_values(\"Fare\", ascending=False).head(10)","514f47d4":"# observations with Fare data higher than the upper limit:\n\ndf_OutlierValues = df_train['Fare'] > (upper_limit)","ddc8e93b":"# There are too many data higher than upper limit so  we can not change all. But we can Just repress the highest value \ndf_train['Fare'] = df_train['Fare'].replace(512.3292, 300)\ndf_train.sort_values(\"Fare\", ascending=False).head(10)","755b729b":"df_test.sort_values(\"Fare\", ascending=False).head(10)","8957077c":"df_test['Fare'] = df_test['Fare'].replace(512.3292, 300)\ndf_test.sort_values(\"Fare\", ascending=False).head(10)","de73d6dc":"df_train['Embarked'].value_counts()","8ee3f243":"df_train['Embarked'].isnull().sum()","2fa7a218":"#replacing the missing values in the Embarked feature with S\ndf_train = df_train.fillna({\"Embarked\": \"S\"})\ndf_train['Embarked'].isnull().sum()","a7031383":"#check for any missing values\ndf_train.isnull().sum()","8afc01d4":"df_test.isnull().sum()","dbc7b57c":"df_train[\"Age\"] = df_train[\"Age\"].fillna(df_train[\"Age\"].mean())\ndf_test[\"Age\"] = df_test[\"Age\"].fillna(df_test[\"Age\"].mean())","98cbe3a1":"df_test[df_test[\"Fare\"].isnull()]","fb0e2d9c":"df_test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","26ed58bf":"df_test[\"Fare\"] = df_test[\"Fare\"].fillna(12)","21880816":"df_test.isnull().sum()","23454f64":"df_train.isnull().sum()","a85a0caa":"embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ndf_train['Embarked'] = df_train['Embarked'].map(embarked_mapping)\ndf_test['Embarked'] = df_test['Embarked'].map(embarked_mapping)","596f2058":"df_train['Embarked'].value_counts()","94e72b69":"df_test['Embarked'].value_counts()","b4a18211":"# Convert Sex values into 1-0:\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ndf_train[\"Sex\"] = lbe.fit_transform(df_train[\"Sex\"])\ndf_test[\"Sex\"] = lbe.fit_transform(df_test[\"Sex\"])","854da4fb":"df_train[\"Sex\"].value_counts()","9915c5cc":"df_test[\"Sex\"].value_counts()","494cbf3d":"#we can drop Names\ndf_train = df_train.drop(['Name'], axis = 1)\ndf_test = df_test.drop(['Name'], axis = 1)","8c48cc6e":"df_train.head()","7a1bd853":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n\ndf_train['AgeGroup'] = pd.cut(df_train[\"Age\"], bins, labels = mylabels)\ndf_test['AgeGroup'] = pd.cut(df_test[\"Age\"], bins, labels = mylabels)\n\n# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n\ndf_train['AgeGroup'] = df_train['AgeGroup'].map(age_mapping)\ndf_test['AgeGroup'] = df_test['AgeGroup'].map(age_mapping)\n","0cefce9f":"df_train","a26616e4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\npredictors = df_train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = df_train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","17e52f08":"x_train.shape","1416dce2":"x_test.shape","8f19aeb2":"target","c9053088":"predictors","08ec05a9":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","e8a4cc8d":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","66f1bab1":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","f2866d8b":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}\n\n\nxgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","498fd953":"xgb_cv_model.fit(x_train, y_train)","a45ae308":"xgb_cv_model.best_params_","db6b3e6a":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","e57bb1e1":"xgb_tuned =  xgb.fit(x_train,y_train)","2b354a14":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","9d7c4eec":"#set ids as PassengerId and predict survival \nids = df_test['PassengerId']\npredictions = xgb_tuned.predict(df_test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","1de7010f":"output.head()","7efab1d6":"output[\"Survived\"].value_counts()","454e4747":"## **4.Data Visualization****","27b1ff12":"> ## Contents\n1.  Information about Dataset\n2.  Read the Data\n3.  Data Analysis\n4.  Data Visualization\n5.  Data Manupilation\n6.  Choosing the Best Model\n7.  Creating Submission File\n\nAny and all feedback is welcome","bf5dad74":"* There are a total of 891 passengers in training set.\n* The Age feature is missing approximately 19.8% of its values. pretty important to survival, so we should probably attempt to fill these gaps.\n* The Cabin feature is missing approximately 77.1% of its values. Since so much of the feature is missing, it would be hard to fill in the missing values. We'll probably drop these values from our dataset.\n* The Embarked feature is missing 0.22% of its values, which should be relatively harmless.","25578e51":"missing values problem has solved","f63b52cf":"**Random Forest**","51a12f67":"**We can drop the Ticket Variable**","547a51bc":"## 1.Information about Dataset\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\n\nThe `test.csv` dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.","41fb40c7":"**Cabin Variable**","03b3032b":"**Gradient Boosting Classifier**","ef3da391":"**Variable Transformation**","abac5c3f":"## **2.Read Data**","5557887d":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","fea4bb86":"## **5.Data Manupulation**","0069d4f3":"**Fare Variable**","d97bb865":"# Titanic Survival Prediction Exercise-1\n\nGoals, build a predictive model that answers the question: \n    \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).","37250042":"**Outlier Treatments**","f51add5c":"## **6.Choosing the Best Model**\n","dd8f642a":"## information about fields\nVariables and Their Types:\n* Numerical Features: Age (Continuous), Fare (Continuous), SibSp (Discrete), Parch (Discrete)\n* Categorical Features: Survived, Sex, Embarked, Pclass\n* Alphanumeric Features: Ticket, Cabin\n\nData types for each feature?\n* Survived: int\n* Pclass: int\n* Name: string\n* Sex: string\n* Age: float\n* SibSp: int\n* Parch: int\n* Ticket: string\n* Fare: float\n* Cabin: string\n* Embarked: string\n\n\nSurvival:             ,  0 = No, 1 = Yes\n\nPclass: Ticket class  ,  1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation,              C = Cherbourg, Q = Queenstown, S = Southampton\n\n\n** Variable Notes: **\n\nPclass: A proxy for socio-economic status (SES)\n\n1st = Upper\n2nd = Middle\n3rd = Lower\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\nParch: The dataset defines family relations in this way...\n\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them.\n\n\n","76782b4c":"**Time to clean  data **\n* missing values and \n* unnecessary informations \n* outlier values","260ab1f6":"**Embarked Value**","b512ccac":"**Logistic Regression**","05225445":"7.Creating Submission File","f85e3151":"## 3.Data Analysis"}}