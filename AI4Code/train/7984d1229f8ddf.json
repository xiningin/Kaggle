{"cell_type":{"22083d1d":"code","6ca9ca33":"code","8ed6d095":"code","e0261f8f":"code","60136eb3":"code","f29d5668":"code","d90682bb":"code","200438f2":"code","482b596d":"code","29174f72":"code","54de578b":"code","43504ed6":"code","1d5d51f5":"code","a4c179ee":"code","e8c7a359":"code","c1815a4a":"code","fd385455":"code","69dfbdbe":"code","93f717d8":"code","39fa0347":"code","f7e5df75":"markdown","5e07e4c2":"markdown","b53671cf":"markdown","0e135513":"markdown","4364de99":"markdown","d3e23ca7":"markdown","a2caf72b":"markdown","a5d35d39":"markdown","816348ba":"markdown","2f9b2150":"markdown"},"source":{"22083d1d":"import os\nimport sys\nimport shutil\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport itertools\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn, utils, optim\nfrom torchvision import transforms, models\nsys.path.append(\"..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\")\nfrom efficientnet_pytorch import model as enet","6ca9ca33":"# Be deterministic \ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Since it is learned multiple times when tuning parameters,\n# make it a function so that it can be initialized with the same seed each time. \ndef init_seed():\n    np.random.seed(0)\n    torch.manual_seed(0)","8ed6d095":"# Initial settings\nUSE_DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 16\nBATCH_SIZE_VALID = 4\nNUM_WORKERS = 2\nNUM_EPOCHS = 3 # epochs for test to find parameter\nLR_TESTS = [5e-3,1e-4,5e-4] # Find the best parameter while changing the learning rate\nWEIGHT_TESTS = [0.5,0.7,0.9] # Try weighted classification weights-unbalanced dataset with more than 1 than 0 \nUSE_TRAIN_SUBSET = True # for test run","e0261f8f":"df_origin = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/train_labels.csv\")\ndf_test = pd.concat([df_origin[df_origin.target==1][:500], df_origin[df_origin.target==0][:500]])\ndf_train = pd.concat([df_origin[df_origin.target==1][500:], df_origin[df_origin.target==0][500:]])\ndf_valid = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/sample_submission.csv\")","60136eb3":"class MyDataset:\n    def __init__(self, test=False, valid=False):\n        # Read Training file\n        df = df_valid if valid else (df_test if test else df_train)\n        if (not valid) and USE_TRAIN_SUBSET:\n            _, df = train_test_split(df, test_size=0.1, random_state=0)\n        self.df = df\n        self.valid = valid # is prediction?\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, pos):\n        loc = self.df.iloc[pos]\n        _id = loc[\"id\"]\n        # read signal data\n        if self.valid:\n            fn = f\"..\/input\/seti-breakthrough-listen\/test\/{_id[0]}\/{_id}.npy\"\n        else:\n            fn = f\"..\/input\/seti-breakthrough-listen\/train\/{_id[0]}\/{_id}.npy\"\n        # target value\n        lb = int(loc[\"target\"])\n        arr = np.load(fn) # read signal\n        if not self.valid:\n            if np.random.random() < 0.2: # DA\n                # Since the horizontal direction is the time axis, rotate the time and shift the position. \n                pos = np.random.randint(arr.shape[2]-50)+50\n                X = arr.copy()\n                p = np.array([[np.linspace(0,arr[i,j,-1]-arr[i,j,-pos],pos) for j in range(arr.shape[1])] for i in range(arr.shape[0])])\n                q = np.array([[np.linspace(0,arr[i,j,pos]-arr[i,j,0],arr.shape[2]-pos) for j in range(arr.shape[1])] for i in range(arr.shape[0])])\n                X[:,:,0:pos] = arr[:,:,-pos:] - p\n                X[:,:,pos:] = arr[:,:,:-pos] - q\n                arr = X\n        return torch.tensor(arr, dtype=torch.float32), torch.tensor(lb, dtype=torch.int64)","f29d5668":"def get_model():\n    # modify output classes=2\n    model = enet.EfficientNet.from_name('efficientnet-b0')\n    model.load_state_dict(torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth'))\n    model._conv_stem = nn.Conv2d(6, 32, kernel_size=3, bias=False)\n    model._fc = nn.Linear(1280, 2)\n    model = model.to(USE_DEVICE)\n    return model\n\ndef get_optim(model, lr):\n    params = model.parameters()\n    optimizer = optim.Adam(params, lr=lr)\n    return optimizer\n\ndef get_loss(weight):\n    # Loss function for classification with weights for unbalanced datasets \n    weight = torch.tensor([1.0-weight,weight], dtype=torch.float)\n    weight = weight.to(USE_DEVICE)\n    loss = nn.CrossEntropyLoss(weight=weight)\n    return loss\n\ndef get_score(true_valid, pred_valid):\n    # RocAUC Score\n    return roc_auc_score(true_valid, pred_valid)","d90682bb":"train_ds = MyDataset(test=False)\ntest_ds = MyDataset(test=True)\ndata_loader = utils.data.DataLoader(\n    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\ndata_loader_v = utils.data.DataLoader(\n    test_ds, batch_size=BATCH_SIZE_VALID, shuffle=False, num_workers=NUM_WORKERS)","200438f2":"best_scores = [] # score of best epoch in each parameter set\n\nif not os.path.isdir('tmp'):\n    os.mkdir('tmp')\n\nfor t, (lr, weight) in enumerate(itertools.product(LR_TESTS, WEIGHT_TESTS)):\n    init_seed() # initialized with the same seed each time. \n    model = get_model() # get model\n\n    optimizer = get_optim(model, lr)\n    loss = get_loss(weight) # get weighted loss function\n\n    print(f'test #{t} lr={lr} weight={weight}') # try train&test\n    scores = []\n\n    for epoch in tqdm(range(NUM_EPOCHS)):\n        total_loss = []\n        model.train() # make model for train\n        \n        # train\n        for X, y in data_loader:\n            X = X.to(USE_DEVICE)\n            y = y.to(USE_DEVICE)\n\n            losses = loss(model(X), y)\n\n            optimizer.zero_grad()\n            losses.backward()\n            optimizer.step()\n\n            total_loss.append(losses.detach().cpu().numpy())\n\n        # test\n        with torch.no_grad():\n            total_loss_v = []\n            true_valid = []\n            pred_valid = []\n\n            model.eval() # make model for test\n            for i, (X, y) in enumerate(data_loader_v):\n                X = X.to(USE_DEVICE)\n                y = y.to(USE_DEVICE)\n\n                res = model(X)\n                losses = loss(res, y)\n\n                y = y.detach().cpu().numpy()\n                true_valid.extend(y.tolist())\n\n                res = torch.softmax(res, axis=1)\n                res = res.detach().cpu().numpy()\n                pred_valid.extend(res[:,1].tolist())\n\n                total_loss_v.append(losses.detach().cpu().numpy())\n\n        # Run tests for every epoch and use the one with the best epoch \n        total_loss = np.mean(total_loss)\n        total_loss_v = np.mean(total_loss_v)\n        score = get_score(true_valid, pred_valid)\n        scores.append(score) # scores in this parameter set\n        print(f'epoch #{epoch}: train_loss:{total_loss} valid_loss:{total_loss_v} score:{score}')\n        torch.save(model.state_dict(), f'tmp\/checkpoint{epoch}.pth') # save model\n\n    # The best epoch for this parameter \n    best_epoch = np.argmax(scores)\n    shutil.copyfile(f'tmp\/checkpoint{best_epoch}.pth',f'tmp\/test{t}_best.pth')\n    best_scores.append(scores[best_epoch])\n\n    del model, optimizer, loss, X, y, res, losses\n    torch.cuda.empty_cache()","482b596d":"del train_ds, test_ds, data_loader, data_loader_v","29174f72":"best_of_best = np.argmax(best_scores) # best epoch in best parameter\nmodel_name = f'tmp\/test{best_of_best}_best.pth'","54de578b":"validmodel = get_model()\nvalidmodel.load_state_dict(torch.load(model_name, map_location=torch.device(USE_DEVICE)))","43504ed6":"# Make test data\nvalid_ds = MyDataset(test=False, valid=True)\ndata_loader_v = utils.data.DataLoader(\n    valid_ds, batch_size=BATCH_SIZE_VALID, shuffle=False, num_workers=NUM_WORKERS)","1d5d51f5":"# Prediction\nwith torch.no_grad():\n    pred_valid = []\n\n    validmodel.eval()\n    for i, (X, y) in tqdm(enumerate(data_loader_v), total=len(data_loader_v)):\n        X = X.to(USE_DEVICE)\n        y = y.to(USE_DEVICE)\n\n        res = validmodel(X)\n        res = torch.softmax(res, axis=1)\n        res = res.detach().cpu().numpy()\n        pred_valid.extend(res[:,1].tolist())","a4c179ee":"csv = \"..\/input\/seti-breakthrough-listen\/sample_submission.csv\"\ndf = pd.read_csv(csv)\ndf[\"target\"] = pred_valid\ndf.to_csv(\"submission.csv\", index=False)","e8c7a359":"df_train = df_origin # train all data\nUSE_TRAIN_SUBSET = False # train all data","c1815a4a":"train_ds = MyDataset(test=False)\ndata_loader = utils.data.DataLoader(\n    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)","fd385455":"lr = 0.0005 # find parameter\nweight = 0.5 # find parameter\nNUM_EPOCHS = 3 # find parameter\n\ninit_seed() # initialized with the same seed each time. \nmodel = get_model() # get model\n\noptimizer = get_optim(model, lr)\nloss = get_loss(weight) # get weighted loss function\n\nprint(f'train again lr={lr} weight={weight}') # train in find parameters\nscores = []\n\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    total_loss = []\n    model.train() # make model for train\n\n    # train\n    for X, y in data_loader:\n        X = X.to(USE_DEVICE)\n        y = y.to(USE_DEVICE)\n\n        losses = loss(model(X), y)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()","69dfbdbe":"validmodel = model","93f717d8":"# Prediction\nwith torch.no_grad():\n    pred_valid = []\n\n    validmodel.eval()\n    for i, (X, y) in tqdm(enumerate(data_loader_v), total=len(data_loader_v)):\n        X = X.to(USE_DEVICE)\n        y = y.to(USE_DEVICE)\n\n        res = validmodel(X)\n        res = torch.softmax(res, axis=1)\n        res = res.detach().cpu().numpy()\n        pred_valid.extend(res[:,1].tolist())","39fa0347":"csv = \"..\/input\/seti-breakthrough-listen\/sample_submission.csv\"\ndf = pd.read_csv(csv)\ndf[\"target\"] = pred_valid\ndf.to_csv(\"submission2.csv\", index=False)","f7e5df75":"# Save Submission file","5e07e4c2":"# Load best parameter-trained model","b53671cf":"# Make dataset","0e135513":"# Initial settings","4364de99":"# Make Submission file","d3e23ca7":"# Training with find best parameter","a2caf72b":"# Deta model with DA","a5d35d39":"# Training All Data in find parameters","816348ba":"# Pytorch model","2f9b2150":"# Make Submission"}}