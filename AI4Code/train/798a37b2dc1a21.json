{"cell_type":{"551bcc41":"code","3133b925":"code","41fc6491":"code","da30e6ce":"code","4335b96c":"code","750b554a":"code","7e137f4e":"code","91f8353e":"code","6ae853e7":"code","2b1e5887":"code","81cc0bb7":"code","367c9cee":"code","e5524c22":"code","f5173637":"code","c82af0b2":"code","90fd356a":"code","efdaddd1":"code","e61f8ceb":"code","6036771e":"code","d8f0e467":"code","72f32ed0":"code","1cbef2f2":"code","c7ed9dd2":"code","d2a3e47e":"code","1d83025b":"code","c8635d20":"code","0eba0f27":"code","4a2e86c7":"code","3843ba57":"code","7dac4e80":"code","1ffdae8f":"code","a777d797":"code","4cb88ae1":"code","867076d3":"code","e2a01d05":"code","29c5abdd":"code","49fd0ad1":"code","d9f464ea":"code","56489742":"code","01a4575f":"code","784c0662":"code","704260bf":"code","04fa43a5":"code","6e0bec9e":"code","afaa3bbd":"code","b2d569bd":"code","a723fff2":"code","e81f5e42":"code","7ccfbe32":"code","a9ab5658":"code","a47933c2":"code","6b50baa0":"code","e55f7e20":"code","090e0d7c":"code","714d66dd":"code","0bda020f":"code","78d937fb":"code","049cf7c6":"code","1b759cd4":"code","e5b6f8a7":"code","adeefc3c":"code","06ceebe7":"code","c05c0281":"code","0b9a2d18":"code","a724ec1d":"code","3af90546":"code","cdf56c08":"code","44b939f6":"markdown","84378b8b":"markdown","b1d77a78":"markdown","5b6bbf1f":"markdown","af8058e0":"markdown","85930889":"markdown","2cc654c0":"markdown","3c3e5aa8":"markdown","4fc3887a":"markdown","910533ed":"markdown","bee4d159":"markdown","473e643b":"markdown","2a541435":"markdown","d65d6a57":"markdown","612b1562":"markdown","65f8ca3c":"markdown","e477e031":"markdown","9f86f382":"markdown","628639a3":"markdown","7dacc23f":"markdown","68eedf0e":"markdown","934981ef":"markdown","69f343b7":"markdown","253ab391":"markdown","c1a84ce0":"markdown","130edf1c":"markdown","ed1453f5":"markdown","a96dc549":"markdown","e479d6ed":"markdown","eb7ff5fd":"markdown","a62df2ac":"markdown","c5e5d52e":"markdown","fa303493":"markdown","86e8f398":"markdown"},"source":{"551bcc41":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntrain = pd.read_csv('..\/input\/a-fine-windy-day-hackerearth-ml-challenge\/train_data.csv')\ntest = pd.read_csv('..\/input\/a-fine-windy-day-hackerearth-ml-challenge\/test_data.csv')","3133b925":"train['datetime'] = train['datetime'].astype('datetime64[ns]')\ntest['datetime'] = test['datetime'].astype('datetime64[ns]')","41fc6491":"train.shape","da30e6ce":"#Few rows had the target value as NaN and are hence dropped!\ntrain.dropna(axis=0, subset=['windmill_generated_power(kW\/h)'], inplace=True)","4335b96c":"train['wind_direction(\u00b0)'] = (((train['wind_direction(\u00b0)']-120)%360)-180)\ntest['wind_direction(\u00b0)'] = (((test['wind_direction(\u00b0)']-120)%360)-180)","750b554a":"train['windmill_height(m)'] = (train['windmill_height(m)'] + 31.0)\ntest['windmill_height(m)'] = (test['windmill_height(m)'] + 31.0)","7e137f4e":"plt.figure(figsize=(15,4))\nplt.tight_layout()\n\nplt.subplot(1,3,1)\nplt.hist(train['blades_angle(\u00b0)'], bins = 10)\nplt.title('-99 as missing value in Blade Angle')\n\n\nplt.subplot(1,3,2)\nplt.hist(train['shaft_temperature(\u00b0C)'], bins = 10)\nplt.title('-99 as missing value in Shaft Temperature')\n\n\nplt.subplot(1,3,3)\nplt.hist(train['atmospheric_temperature(\u00b0C)'], bins = 10)\nplt.title('-99 as missing value in Atmospheric Temperature')\n\nplt.show()","91f8353e":"def extract_nan(col, value):\n    test[col].replace(value, np.nan, inplace=True)\n    train[col].replace(value, np.nan, inplace=True)","6ae853e7":"columns = ['blade_length(m)','rotor_torque(N-m)', 'resistance(ohm)', 'blades_angle(\u00b0)', 'shaft_temperature(\u00b0C)' , \n           'gearbox_temperature(\u00b0C)', 'windmill_body_temperature(\u00b0C)', 'atmospheric_temperature(\u00b0C)' ]\nfor i in columns:\n    extract_nan(i, -99)\n    \n    \nextract_nan('windmill_body_temperature(\u00b0C)', -999)\nextract_nan('area_temperature(\u00b0C)', -30)","2b1e5887":"def clip_temp(col, upper, lower):\n    train[col].clip(lower=lower, upper=upper, inplace = True)\n    test[col].clip(lower=lower, upper=upper, inplace = True)","81cc0bb7":"columns = ['shaft_temperature(\u00b0C)', 'engine_temperature(\u00b0C)', \n           'atmospheric_temperature(\u00b0C)', 'area_temperature(\u00b0C)']\nfor i in columns:\n    clip_temp(i, 60, -25)\nclip_temp('gearbox_temperature(\u00b0C)', 100, -25)\nclip_temp('windmill_body_temperature(\u00b0C)', 100, -25)","367c9cee":"def cel_to_fah(col):\n    train[col] = (train[col]+17.778)\/0.556\n    test[col] = (test[col]+17.778)\/0.556\n    return None","e5524c22":"columns = ['shaft_temperature(\u00b0C)' , 'gearbox_temperature(\u00b0C)',\n           'windmill_body_temperature(\u00b0C)', 'engine_temperature(\u00b0C)', \n           'generator_temperature(\u00b0C)', 'atmospheric_temperature(\u00b0C)', \n           'area_temperature(\u00b0C)']\nfor i in columns:\n    cel_to_fah(i)","f5173637":"#Pascal to Bar\ntrain['atmospheric_pressure(Pascal)'] = (train['atmospheric_pressure(Pascal)']\/1e5)\ntest['atmospheric_pressure(Pascal)'] = (test['atmospheric_pressure(Pascal)']\/1e5)","c82af0b2":"train['wind_speed(m\/s)'] = (train['wind_speed(m\/s)']\/10)\ntest['wind_speed(m\/s)'] = (test['wind_speed(m\/s)']\/10)","90fd356a":"plt.hist(train['wind_speed(m\/s)'], bins = 10)\nplt.title('Distribution of wind speed')","efdaddd1":"train = train.round(2)\ntest = test.round(2)","e61f8ceb":"# import dtale\n# dtale.show(train)","6036771e":"corr= abs(train.corr())\ncore = abs(corr['windmill_generated_power(kW\/h)'].sort_values(ascending = False))\nprint(core.sort_values(ascending = False))\nplt.figure(figsize = (20,10))\n\nax = sns.heatmap(corr, vmax = 0.65, annot=True, linewidths=.5)","d8f0e467":"train['air_density'] = (train['atmospheric_pressure(Pascal)']*1e5)\/(287.058*(273.3+(train['area_temperature(\u00b0C)']*.556-17.778)))\ntest['air_density'] = (test['atmospheric_pressure(Pascal)']*1e5)\/(287.058*(273.3+(test['area_temperature(\u00b0C)']*.556-17.778)))","72f32ed0":"chart_data = pd.concat([\n    train['motor_torque(N-m)'],\n    train['generator_temperature(\u00b0C)'],\n], axis=1)\nchart_data = chart_data.sort_values(['motor_torque(N-m)'])\nchart_data = chart_data.rename(columns={'motor_torque(N-m)': 'x'})\nchart_data = chart_data.dropna()\n\nimport plotly.graph_objs as go\n\nchart = go.Scattergl(\n    x=chart_data['x'], y=chart_data['generator_temperature(\u00b0C)'], mode='markers', opacity=0.7, name='all',\n    marker={'size': 15, 'line': {'width': 0.5, 'color': 'white'}}\n)\n\nfigure = go.Figure(data=[chart], layout=go.Layout({\n    'legend': {'orientation': 'h'},\n    'title': {'text': 'generator_temperature(\u00b0C) by motor_torque(N-m)'},\n    'xaxis': {'title': {'text': 'motor_torque(N-m)'}},\n    'yaxis': {'title': {'text': 'generator_temperature(\u00b0C)'}, 'type': 'linear'}\n}))\nfigure","1cbef2f2":"train['generator_on'] = (train['motor_torque(N-m)']>1000).astype('int64')\ntest['generator_on'] = (test['motor_torque(N-m)']>1000).astype('int64')","c7ed9dd2":"df_turb = pd.concat([train,test])\ndf_turb = df_turb.sort_values('datetime')\nidx = [*range(0,df_turb.shape[0])]\ndf_turb['index'] = idx\ndf_turb = df_turb.set_index('index')","d2a3e47e":"turbulence = []\n\n\nfirst = []\nfirst.append(train['wind_speed(m\/s)'][0])\nfirst.append(train['wind_speed(m\/s)'][1])\nt = np.std(first)\/np.mean(first)\nturbulence.append(t)\n\nfor i in range(1,df_turb.shape[0]):\n    if (i==(df_turb.shape[0]-1)):\n        continue\n    turb = []\n    turb.append(df_turb['wind_speed(m\/s)'][i])\n    if ((df_turb.datetime[i]-df_turb.datetime[i-1]).total_seconds()==600):\n        turb.append(df_turb['wind_speed(m\/s)'][i-1])\n    if ((df_turb.datetime[i+1]-df_turb.datetime[i]).total_seconds()==600):\n        turb.append(df_turb['wind_speed(m\/s)'][i+1])\n    if (np.mean(turb)==0):\n        t = 0\n        turbulence.append(t)\n        continue\n    t = np.std(turb)\/np.mean(turb)\n    turbulence.append(t)\n\nlast = []\nlast.append(df_turb['wind_speed(m\/s)'][40077])\nlast.append(df_turb['wind_speed(m\/s)'][40078])\nt = np.std(last)\/np.mean(last)\nturbulence.append(t)\ndf_turb['turbulence'] = turbulence\n#df_turb['turbulence'] = abs(df_turb['turbulence'])\n#df_turb['turbulence'].clip(lower=0, upper=1, inplace = True)\ndel turbulence","1d83025b":"df_turb = df_turb.set_index('tracking_id')\ndict_turb = df_turb[['turbulence']].to_dict()\ndict_turb = dict_turb['turbulence']","c8635d20":"train[\"turbulence\"] = train[\"tracking_id\"].map(dict_turb)\ntest[\"turbulence\"] = test[\"tracking_id\"].map(dict_turb)","0eba0f27":"train['wind_speed(m\/s)'] = abs(train['wind_speed(m\/s)'])\ntest['wind_speed(m\/s)'] = abs(test['wind_speed(m\/s)'])","4a2e86c7":"train['hour'] = train['datetime'].dt.hour\ntest['hour'] = test['datetime'].dt.hour\ntrain['month'] = train['datetime'].dt.month\ntest['month'] = test['datetime'].dt.month","3843ba57":"#train['expected_output'] = train['air_density']*((train['blade_length(m)']**2)*3.14)*(train['wind_speed(m\/s)']**3)\n#test['expected_output'] = test['air_density']*((test['blade_length(m)']**2)*3.14)*(test['wind_speed(m\/s)']**3)\n#train['expected_output'] = abs(train['expected_output'])\n#test['expected_output'] = abs(test['expected_output'])","7dac4e80":"train['air_density'] = abs(train['air_density'])\ntest['air_density'] = abs(test['air_density'])\n\ntrain['blade_length(m)'] = abs(train['blade_length(m)'])\ntest['blade_length(m)'] = abs(test['blade_length(m)'])\ntrain['unique'] = (train.tracking_id).str[3:]\ntest['unique'] = (test.tracking_id).str[3:]\ntrain.unique = train.unique.astype('int64')\ntest.unique = test.unique.astype('int64')","1ffdae8f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import KNNImputer","a777d797":"train.isnull().sum()","4cb88ae1":"#train['gearbox_temperature(\u00b0C)'].fillna(train['gearbox_temperature(\u00b0C)'].mean(), inplace = True)\n#test['gearbox_temperature(\u00b0C)'].fillna(test['gearbox_temperature(\u00b0C)'].mean(), inplace = True)\n\n#train['blade_length(m)'].fillna(train['blade_length(m)'].mean(), inplace = True)\n#test['blade_length(m)'].fillna(test['blade_length(m)'].mean(), inplace = True)","867076d3":"train['atmospheric_pressure(Pascal)'].fillna(train['atmospheric_pressure(Pascal)'].mean(), inplace = True)\ntest['atmospheric_pressure(Pascal)'].fillna(test['atmospheric_pressure(Pascal)'].mean(), inplace = True)","e2a01d05":"pd.options.mode.chained_assignment = None \n\n\nindex = train.loc[((train['motor_torque(N-m)']).isnull()) & (train['generator_temperature(\u00b0C)'].notnull())].index.to_list()\nfor i in index:\n    upper = (train['generator_temperature(\u00b0C)'][i])+2\n    lower = (train['generator_temperature(\u00b0C)'][i])-2\n    A = (train['generator_temperature(\u00b0C)']>lower)\n    B = (train['generator_temperature(\u00b0C)']<upper)\n    val = train.loc[A & B,'motor_torque(N-m)'].mean()\n    train['motor_torque(N-m)'][i] = val\n    \nindex = test.loc[((test['motor_torque(N-m)']).isnull()) & (test['generator_temperature(\u00b0C)'].notnull())].index.to_list()\nfor i in index:\n    upper = (test['generator_temperature(\u00b0C)'][i])+2\n    lower = (test['generator_temperature(\u00b0C)'][i])-2\n    A = (test['generator_temperature(\u00b0C)']>lower)\n    B = (test['generator_temperature(\u00b0C)']<upper)\n    val = test.loc[A & B, 'motor_torque(N-m)'].mean()\n    test['motor_torque(N-m)'][i] = val","29c5abdd":"#train.drop(labels='generator_temperature(\u00b0C)', axis=1, inplace=True)\n#test.drop(labels='generator_temperature(\u00b0C)', axis=1, inplace=True)","49fd0ad1":"train['cloud_level'] = train['cloud_level'].replace({'Extremely Low':0, 'Low':2, 'Medium':3})\ntest['cloud_level'] = test['cloud_level'].replace({'Extremely Low':0, 'Low':2, 'Medium':3})","d9f464ea":"print(train.groupby('cloud_level')['windmill_generated_power(kW\/h)'].describe())\ntrain.loc[(train['windmill_generated_power(kW\/h)']<2.000001) & train.cloud_level.isnull(), 'cloud_level'] = 0","56489742":"print(test.groupby('cloud_level')['motor_torque(N-m)'].describe())\ntest.loc[(test['motor_torque(N-m)']<1070) & (test.cloud_level.isnull()), 'cloud_level'] = 0","01a4575f":"train['cloud_level'].fillna(3, inplace = True)\ntest['cloud_level'].fillna(3, inplace = True)","784c0662":"train = train.join(pd.get_dummies(train.cloud_level, prefix = 'cloud'))\ntrain.drop(['cloud_level', 'cloud_2.0', 'cloud_3.0'], axis=1, inplace = True)\n\ntest = test.join(pd.get_dummies(test.cloud_level, prefix='cloud'))\ntest.drop(['cloud_level', 'cloud_2.0', 'cloud_3.0'], axis=1, inplace = True)","704260bf":"print(train.groupby('turbine_status')['windmill_generated_power(kW\/h)'].mean(),\n      train.groupby('turbine_status')['motor_torque(N-m)'].mean())\n#train.drop(labels='turbine_status', axis=1, inplace=True)\n#test.drop(labels='turbine_status', axis=1, inplace=True)","04fa43a5":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(train.turbine_status.astype('str'))\n\n\nnan_index_train = train.loc[train.turbine_status.isnull()].index.to_list()[0]\nnan_index_test = test.loc[test.turbine_status.isnull()].index.to_list()[0]\n\n\ntrain.turbine_status = le.transform(train.turbine_status.astype('str'))\ntest.turbine_status = le.transform(test.turbine_status.astype('str'))\n\n\nnan_value_train = train.turbine_status[nan_index_train]\nnan_value_test = train.turbine_status[nan_index_test]\n\n\ntrain['turbine_status'] = train['turbine_status'].replace({nan_value_train : np.nan})\ntest['turbine_status'] = test['turbine_status'].replace({nan_value_test : np.nan})","6e0bec9e":"#for col in train.columns.to_list():\n#    if train[col].dtype == 'float64':\n#            print(col)\n#            print(np.var(train[col]),'\\n')","afaa3bbd":"#train.drop(labels='blade_breadth(m)', axis=1, inplace=True)\n#test.drop(labels='blade_breadth(m)', axis=1, inplace=True)","b2d569bd":"train.set_index('tracking_id', inplace = True)\ntest.set_index('tracking_id', inplace = True)","a723fff2":"from xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport sklearn.metrics as metrics \nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom sklearn.metrics import r2_score","e81f5e42":"xtrain=train.copy()\nxtrain.drop('datetime', axis = 1, inplace = True)\nxtest=test.copy()\nxtest.drop('datetime', axis = 1, inplace = True)\n\n\ny = xtrain['windmill_generated_power(kW\/h)'].values\nX = xtrain.drop('windmill_generated_power(kW\/h)', axis =1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","7ccfbe32":"space = {\n    'learning_rate':     hp.loguniform('learning_rate',np.log(0.01), np.log(0.2)),\n    'max_depth':         hp.quniform(\"max_depth\", 5, 16, 1),\n    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5,1),\n    'n_estimators':      500,\n    'eval_metric':       'RMSE',\n    'reg_lambda' :       hp.uniform('reg_lambda', 0,1)\n}","a9ab5658":"def objective(space):\n    clf=CatBoostRegressor(\n                    n_estimators =space['n_estimators'], \n                    max_depth = space['max_depth'],\n                    colsample_bylevel= space['colsample_bylevel'],\n                    eval_metric = space['eval_metric'],\n                    reg_lambda = space['reg_lambda'], \n                    learning_rate = space['learning_rate']\n    )\n    \n    evaluation = [( X_train, y_train), ( X_test, y_test)]\n    \n    clf.fit(X_train, y_train,\n            eval_set=evaluation,\n            #early_stopping_rounds=10,\n            verbose=False)\n    \n\n    pred = clf.predict(X_test)\n    r2 = max(0,100*r2_score(y_test, pred))\n    print (\"SCORE:\", r2)\n    return {'loss': -r2, 'status': STATUS_OK, 'model' : clf }","a47933c2":"trials = Trials()\n\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 200,\n                        trials = trials)","6b50baa0":"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)","e55f7e20":"best_param_list = []\nsorted_trial_losses = sorted(trials.losses())\nt = trials.trials\n#print(\"Best params for the top losses\")\n#print(best_hyperparams)\nfor i in range(len(t)):\n    if ((t[i]['result']['loss']== sorted_trial_losses[0]) | (t[i]['result']['loss']== sorted_trial_losses[9]) |\n        (t[i]['result']['loss']== sorted_trial_losses[1]) | (t[i]['result']['loss']== sorted_trial_losses[2]) |\n        (t[i]['result']['loss']== sorted_trial_losses[3]) | (t[i]['result']['loss']== sorted_trial_losses[4]) |\n        (t[i]['result']['loss']== sorted_trial_losses[5]) | (t[i]['result']['loss']== sorted_trial_losses[6]) |\n        (t[i]['result']['loss']== sorted_trial_losses[7]) | (t[i]['result']['loss']== sorted_trial_losses[8])):\n        print(t[i]['result']['loss'], '\\t', i)\n        print(t[i]['misc']['vals'])\n        best_param_list.append(t[i]['misc']['vals'])","090e0d7c":"best_param_list =[ \n                 {'colsample_bylevel': [0.7840776236431249],\n  'learning_rate': [0.06646758913213958],\n  'max_depth': [7.0],\n  'reg_lambda': [0.781094012645824],\n  'n_estimators' : [900],\n  'early_stopping_rounds' : [10]},   #900 WES 97.112 ---> n_estimators = 900, WES = With Early stopping, 97.112 = Public test score\n                   {'colsample_bylevel': [0.9514227590176606],\n  'learning_rate': [0.04847664475604065],\n  'max_depth': [8.0],\n  'reg_lambda': [0.28689172062837387],\n  'n_estimators' : [900],\n  'early_stopping_rounds' : [10]},  #900 WES 97.116\n                   \n        \n                  \n                  \n             \n                 {'colsample_bylevel': [0.7714687677253086],\n  'learning_rate': [0.1026578686058806],\n  'max_depth': [7.0],\n  'reg_lambda': [0.9403115684587895],\n  'n_estimators' : [850],\n  'early_stopping_rounds' : [10]}, #850 WES 97.1079 \n                   \n                  \n                  \n                  \n                  {'colsample_bylevel': [0.9018718841848762],\n  'learning_rate': [0.08907308842612886],\n  'max_depth': [7.0],\n  'reg_lambda': [0.2788033754905464],\n  'n_estimators' : [850],\n  'early_stopping_rounds' : [None]}, #850 NES 97.12736\n                   {'colsample_bylevel': [0.9927906240334108],\n  'learning_rate': [0.08354190505569654],\n  'max_depth': [7.0],\n  'reg_lambda': [0.23944221880461342],\n  'n_estimators' : [850],\n  'early_stopping_rounds' : [None]},  #850 NES 97.106\n                  {'colsample_bylevel': [0.9531240033491211],\n  'learning_rate': [0.07887402371682703],\n  'max_depth': [8.0],\n  'reg_lambda': [0.1528264376777892],\n  'n_estimators' : [850],\n  'early_stopping_rounds' : [None]}, #850 NES 97.113\n                  \n                  \n                  \n\n\n                   {'colsample_bylevel': [0.8165270016931238],\n  'learning_rate': [0.1074426160195262],\n  'max_depth': [7.0],\n  'reg_lambda': [0.8709247833299882],\n  'n_estimators' : [600],\n  'early_stopping_rounds' : [None]},  #600 NES 97.101\n                  {'colsample_bylevel': [0.9036631000437778],\n  'learning_rate': [0.11934909736210365],\n  'max_depth': [7.0],\n  'reg_lambda': [0.15195405997837974],\n  'n_estimators' : [600],\n  'early_stopping_rounds' : [None]},  #600 NES 97.15204\n    \n    \n    \n    \n    \n    {'colsample_bylevel': [0.9713918522977533],\n 'learning_rate': [0.06172263631910841],\n 'max_depth': [8.0],\n 'reg_lambda': [0.28629630830807196],\n  'n_estimators' : [900],\n  'early_stopping_rounds' : [None]},  #900 NES 97.15198\n    {'colsample_bylevel': [0.7965427860702724],\n 'learning_rate': [0.05817673067609091],\n 'max_depth': [7.0],\n 'reg_lambda': [0.030299421668642385],\n  'n_estimators' : [900],\n  'early_stopping_rounds' : [None]}, #900 NES 97.14199\n    \n    \n    \n    \n    {'colsample_bylevel': [0.9936898562667233],\n 'learning_rate': [0.10448908377830841],\n 'max_depth': [7.0],\n 'reg_lambda': [0.7821509420549156],\n  'n_estimators' : [1000],\n  'early_stopping_rounds' : [None]}, #1000 NES 97.13968\n] \n","714d66dd":"subs = {}\nfor i in range(0,11):\n    cat = CatBoostRegressor(loss_function = 'RMSE',\n                            eval_metric='R2', \n                            random_seed=14,\n                            colsample_bylevel = best_param_list[i]['colsample_bylevel'][0],\n                            learning_rate = best_param_list[i]['learning_rate'][0], \n                            max_depth = best_param_list[i]['max_depth'][0],\n                            reg_lambda = best_param_list[i]['reg_lambda'][0],\n                            n_estimators = best_param_list[i]['n_estimators'][0],\n                            early_stopping_rounds = best_param_list[i]['early_stopping_rounds'][0]\n                           )\n    cat.fit(X, y, verbose = 0)\n    p_y = cat.predict(X)\n    print(100*metrics.r2_score(y, p_y))\n    p_y = cat.predict(X_test)\n    print(100*metrics.r2_score(y_test, p_y), '\\n')\n    p_y = cat.predict(xtest)\n    subs[i] = p_y","0bda020f":"p_y = 0\nfor i in range(0,11):\n    p_y = p_y + subs[i]\np_y = p_y\/11\nprint(p_y, '\\n', p_y.shape)","78d937fb":"sample = test[['datetime']]\nsample = pd.DataFrame(sample)\nsample['datetime'] = sample['datetime'].astype('datetime64[ns]')\nsample['windmill_generated_power(kW\/h)'] = p_y\nsample.to_csv('Predictions.csv')","049cf7c6":"import seaborn as sns\nfeature_imp = pd.DataFrame(sorted(zip(cat.feature_importances_, X_train.columns), reverse=True)[:50], \n                           columns=['Value','Feature'])\nplt.figure(figsize=(15,15))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('Catboost Features')\nplt.tight_layout()\nplt.show()\n","1b759cd4":"xtrain=train.copy()\nxtrain.drop('datetime', axis = 1, inplace = True)\nxtest=test.copy()\nxtest.drop('datetime', axis = 1, inplace = True)\n\n\ny = xtrain['windmill_generated_power(kW\/h)'].values\nX = xtrain.drop('windmill_generated_power(kW\/h)', axis =1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","e5b6f8a7":"space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n       'learning_rate':    hp.loguniform('learning_rate',np.log(0.01), np.log(0.2)),\n       'gamma': hp.uniform ('gamma', 1,9),\n       'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n       'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n       'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n       'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n       'n_estimators': 500,\n       'seed': 14,\n    }","adeefc3c":"def objective(space):\n    clf=XGBRegressor(\n                    n_estimators =space['n_estimators'], \n                    max_depth = int(space['max_depth']),\n                    gamma = space['gamma'],\n                    reg_alpha = space['reg_alpha'],\n                    min_child_weight=space['min_child_weight'], \n                    reg_lambda = space['reg_lambda'],\n                    colsample_bytree= space['colsample_bytree'], \n                    learning_rate = space['learning_rate'],\n                    seed = space['seed']\n    \n    )\n    \n    evaluation = [( X_train, y_train), ( X_test, y_test)]\n    \n    clf.fit(X_train, y_train,\n            eval_set=evaluation, eval_metric=\"rmse\",\n            early_stopping_rounds=10,verbose=False)\n    \n\n    pred = clf.predict(X_test)\n    r2 = max(0,100*r2_score(y_test, pred))\n    print (\"SCORE:\", r2)\n    return {'loss': -r2, 'status': STATUS_OK, 'model' : clf }","06ceebe7":"trials = Trials()\n\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 200,\n                        trials = trials)","c05c0281":"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)","0b9a2d18":"hyper_param_list_xgb = []\nsorted_trial_losses = sorted(trials.losses())\nt = trials.trials\nprint(\"Best params for the top losses\")\nprint(best_hyperparams)\nfor i in range(len(t)):\n    if ((t[i]['result']['loss']== sorted_trial_losses[0]) |\n       (t[i]['result']['loss']== sorted_trial_losses[1]) | (t[i]['result']['loss']== sorted_trial_losses[2]) |\n       (t[i]['result']['loss']== sorted_trial_losses[3]) | (t[i]['result']['loss']== sorted_trial_losses[4])):\n        print(t[i]['result']['loss'])\n        print(t[i]['misc']['vals'])\n        hyper_param_list_xgb.append(t[i]['misc']['vals'])","a724ec1d":"hyper_param_list_xgb = [{'colsample_bytree': [0.9892149956637211],\n  'gamma': [4.151339507172721],\n  'max_depth': [14.0],\n  'reg_alpha': [115.0],\n  'reg_lambda':[ 0.7803914410527434]},\n {'colsample_bytree': [0.9371155535338993],\n  'gamma': [3.35490402669362],\n  'max_depth': [16.0],\n  'reg_alpha': [117.0],\n  'reg_lambda': [0.8993500199753666]},\n {'colsample_bytree': [0.9463180516464882],\n  'gamma': [4.644028461064384],\n  'max_depth': [15.0],\n  'reg_alpha': [70.0],\n  'reg_lambda': [0.7966394133180845]},\n {'colsample_bytree': [0.9296947166702829],\n  'gamma': [2.5828440605645158],\n  'max_depth': [15.0],\n  'reg_alpha': [114.0],\n  'reg_lambda': [0.7577023363874883]},\n {'colsample_bytree': [0.9590719842000492],\n  'gamma': [2.362607579231714],\n  'max_depth': [17.0],\n  'reg_alpha': [111.0],\n  'reg_lambda': [0.8373380626534839]}]","3af90546":"import warnings\nwarnings.filterwarnings(action='ignore', category=UserWarning)\nsubs_xgb = {}\nfor i in range(0,5):\n    model = XGBRegressor(   objective = 'reg:squarederror',\n                            gamma = hyper_param_list_xgb[i]['gamma'][0],\n                            colsample_bytree = hyper_param_list_xgb[i]['colsample_bytree'][0],\n                            max_depth =int(hyper_param_list_xgb[i]['max_depth'][0]),\n                            reg_lambda = hyper_param_list_xgb[i]['reg_lambda'][0],\n                            reg_alpha = hyper_param_list_xgb[i]['reg_alpha'][0], \n                            n_estimators = 500\n                           )\n    model.fit(X_train, y_train, verbose = 0, \n              eval_metric='rmse', early_stopping_rounds = 10,\n            eval_set = [(X_train, y_train),(X_test, y_test)])\n        \n    p_y = model.predict(X)\n    print(100*metrics.r2_score(y, p_y))\n    p_y = model.predict(X_test)\n    print(100*metrics.r2_score(y_test, p_y), '\\n')\n    p_y = model.predict(xtest)\n    subs_xgb[i] = p_y","cdf56c08":"p_y = 0\nfor i in range(0,5):\n    p_y = p_y + subs_xgb[i]\np_y = p_y\/5\nprint(p_y, '\\n', p_y.shape)\n\nsample = test[['datetime']]\nsample = pd.DataFrame(sample)\nsample['datetime'] = sample['datetime'].astype('datetime64[ns]')\nsample['windmill_generated_power(kW\/h)'] = p_y\nsample.to_csv('Predictions1.csv')","44b939f6":"## The below process of getting the best parameter for a particular \"n_estimators\" with and without early stopping was done several time with \"n_estimator\" being 500, 600, 750, 850, 900 and 1000. This is an extremely time consuming and computationally expensive process, therefore I have not run it again.\n## However, 3 cells below is the list (best_param_list) of some of the best parameters obtained by the above process.","84378b8b":"## As now, after tweaking the wind direction feature, the sign of wind direction is representative of its direction, wind speeds can be taken as their absolute value without the worry of any loss information due to its sign. ","b1d77a78":"## This was a competition hosted on [HackerEarth](https:\/\/www.hackerearth.com\/), named [A Fine Windy Day](https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-machine-learning-challenge-predict-windmill-power\/instructions\/).\n## Every step is explained in detail, from feature engineering to data pre-processing, knowing how tricky and extremely off-putting at first glance the dataset was.\n#### *If this helps you in learning, an upvote would be huge!*","5b6bbf1f":"### Multiple columns had hidden values under the masquerade of values like \"-999\" or \"-99\"\n","af8058e0":"# ---------------------------------------------------------------------------------------------------------------","85930889":"### We can see how threshold for generator is 1001 Nm of motor torque (Hover over the graph!).\n### This signifies the threshold value of motor torque after which power generation starts in the windmill.\n### This can be seen as a reflection of \"cut-in speed\" of windmill.  ","2cc654c0":"# XGBoost Regressor with HyperOpt","3c3e5aa8":"### For this we sort the dataset using *datetime* as index. To our advantage, the time difference between 2 observations are more often than not 10 minutes.","4fc3887a":"### Pressure is converted from Pascals to Bar as the feature of interest is *atmospheric pressure*. This also helps in scaling the feature for future use. ","910533ed":"### NOTE : The negative value can be a representation of wind flowing in opposite direction to the reference direction!","bee4d159":"### Converting \"datetime\" column to datetime64 datatype of python.","473e643b":"### Processing *cloud_level* to analyze and impute it's missing values.","2a541435":"### After analysing the relation of *cloud level* with various feature, we see that there is a distinct demarcation of \"extremely low\" cloud type with other cloud types from the huge difference in distribution of the power generated by the windmill. \n### Also, since there is not real difference in distribution of the target variable, or any other variable, with respect to the cloud types of \"Low\" and \"Medium\", therefore, they are treated the same. This helps in generalizing and better training of the model.","d65d6a57":"### Columns having unscientific values have been clipped to their nearest naturally possible values. This maintains the integrity of the data while making sense out of the data.","612b1562":"# Generator Status","65f8ca3c":"## Air Density\n### Air density directly accounts to power generation of windmill as it is used in the *ideal* formula for the same.\n#### Pressure is first converted to Pascals from bar. \n#### 287.058 accounts for gas constant\n#### Temperature is converted from Fahrenheit to Kelvin. ","e477e031":"# Filling NaNs\n### Values are imputed while prioritizing the distribution of features across train and test data, and correlations amongst features. ","9f86f382":"### We can see that the correlation are really strong for some pairs of features!\n### Moreover, motor_torque(N-m), generator_temperature(\u00b0C), blades_angle(\u00b0), wind_direction(\u00b0), resistance(ohmengine_temperature(\u00b0C) and rotor_torque(N-m) are *highly* correlated with the *target variable*.\n### These features would play particularly important role in making predictions!","628639a3":"# Feature Generation\n## All the attempts of feature generations are taken after extensive research on how power is generated using windmills. This included the working of windmills, components required to build a windmill, factors affecting power generation, geographical, environmental and technical limitations for the process, physics related to drag friction in air, wind movement, temperature changes and humidity. \n## Tons of websites, blogs and research papers were scanned to achieve this and make educated and informed decisions. ","7dacc23f":"# Models ","68eedf0e":"### Labels which do not contribute to the model\/dataset or do not have any significance with respect to the region of interest have been dropped.  \n### This will be done throughout the process.","934981ef":"# Theoretical power output\n## Tried to include a column which represents the theoretical power generated by the windmill. This feature however, did not contribute anything to the model and was thus commented out. \n#### Formula used :- \n#### power = [(air density) * (swept area of blades) * (wind speed cubed)] \/ 2. \n#### The area is in meters squared, air density is in kilograms per meters cubed and wind speed is in meters per second.","69f343b7":"### Wind speed is touched up to make the values more natural. The values went as high as 600m\/s which is not recorded ever. ","253ab391":"# CatBoostRegressor  with HyperOpt","c1a84ce0":"### Wind direction is tweaked so that wind moving *against* the *designed* direction of windmill is *negative* , and for is *positive*.\n### This is done by carefully examing the distribution of wind direction and understanding the reference point of direction measurement. ","130edf1c":"### All temperatures related columns have been converted from Celsius to Fahrenheit. ","ed1453f5":"### Used the *DTale* python library for charts, correlations and complete description of each feature present in the dataset. \n### This is arguably the most useful and efficient way of *exploratory data analysis*!","a96dc549":"## The below process of getting the best parameter for a particular \"n_estimators\" with and without early stopping was done several time with \"n_estimator\" being 500, 600, 750, 850, 900 and 1000. This is an extremely time consuming and computationally expensive process, therefore I have not run it again.\n## However, 3 cells below is the list (hyper_param_list_xgb) of some of the best parameters obtained by the above process.","e479d6ed":"### Similarly it was found that turbine status does not influence the power generated by the windmill. ","eb7ff5fd":"# Turbulence\n### Atmospheric turbulence is the set of seemingly random and continuously changing air motions that are superimposed on the wind\u2019s average motion and impacts wind energy. \n###  Turbulence is quantified with a metric called turbulence intensity which is calculated by the standard deviation of the horizontal wind speed divided by the average wind speed over some time period, typically 10 minutes.\n","a62df2ac":"### Motor torque and generator temperature have a correlation value of 0.94, therefore generator temperature is used to impute missing values of motor torque. \n### This is done by keeping in mind the importance of motor torque value with the target of the task, after properly comprehending the task in hand and reading multiple articles related to the domain. ","c5e5d52e":"### Turbulence is calculated only if the observations are 10 minutes apart. if-statements for this condition to be met are coded accordingly. ","fa303493":"# Hour and Month\n## Hour of the day and months of a year can be decisive of winds speed(sunsets and rise cause significant change in temperature which in turn causes change in flow of wind. Similarly, Winds in monsoon are more intense than in summers.)\n#### NOTE : As the geographical location of the establishments of windmill are unknown, it is difficult to group months to represent seasons, which vary across the globe. ","86e8f398":"### Dataset has quite a number of missing values. "}}