{"cell_type":{"b4d065f4":"code","5b63327a":"code","1c1e7f40":"code","dac78ca9":"code","8856a15a":"code","67cfd55f":"code","07d0c40a":"code","e47fbf93":"code","38ade6be":"code","ee222a3e":"code","3b9e7310":"code","21e3a0b2":"code","6aaa2bd7":"code","a241908a":"code","b0816a0f":"code","f2c73ca2":"code","3ff56482":"code","1d2dbdc8":"code","70ec4f01":"code","3247e440":"markdown"},"source":{"b4d065f4":"\nimport matplotlib.pyplot as plt\nimport random\nimport time\nimport os\n\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\n# Binary Relevance\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Performance metric\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import hamming_loss\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom sklearn.model_selection import cross_val_score","5b63327a":"ACTIONS = [\"kiri\", \"maju\",\"idle\",\"kanan\"]\nreshape = (-1,8, 60)\n","1c1e7f40":"def create_data(starting_dir=\"..\/input\/eeg8chanel\/data8\"):\n    training_data = {}\n    for action in ACTIONS:\n        if action not in training_data:\n            training_data[action] = []\n        data_dir = os.path.join(starting_dir,action)\n        for item in os.listdir(data_dir):\n            data = np.load(os.path.join(data_dir, item))\n            for item in data:\n                training_data[action].append(item)\n\n    lengths = [len(training_data[action]) for action in ACTIONS]\n    print(lengths)\n\n    for action in ACTIONS:\n        np.random.shuffle(training_data[action])  \n        training_data[action] = training_data[action][:min(lengths)]\n\n    lengths = [len(training_data[action]) for action in ACTIONS]\n    print(lengths)\n    combined_data = []\n    for action in ACTIONS:\n        for data in training_data[action]:\n            if action == \"kiri\":\n                combined_data.append([data, [1, 0, 0,0]])\n            elif action == \"maju\":\n                combined_data.append([data, [0, 1, 0, 0]])\n            elif action == \"idle\":\n                combined_data.append([data, [0, 0, 1, 0]])\n            elif action == \"kanan\":\n                combined_data.append([data, [0, 0, 0, 1]])\n\n    np.random.shuffle(combined_data)\n    print(\"length:\",len(combined_data))\n    return combined_data\n","dac78ca9":"print(\"creating training data\")\ntraindata = create_data(starting_dir=\"..\/input\/eeg8chanel\/data8\")\ntrain_X = []\ntrain_y = []\n\nfor X, y in traindata:\n    train_X.append(X)\n    train_y.append(y)\n    \n\n","8856a15a":"train_X = np.array(train_X).reshape(1000,480)\ntrain_y = np.array(train_y)\ntrain_X.shape,train_y.shape\n","67cfd55f":"x_train,x_test,y_train,y_test=train_test_split(train_X,train_y,test_size=0.2 )\nx_train.shape,y_train.shape, x_test.shape , y_test.shape","07d0c40a":"y_tn=np.argmax(y_train, axis=1)\ny_tt=np.argmax(y_test, axis=1)\ny_tn.shape,y_tt.shape","e47fbf93":"\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.decomposition import FastICA\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","38ade6be":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\n\npipeline_rf=Pipeline([('scalar1',StandardScaler()),\n                     #('pca1',PCA(n_components=60)), \n                      #('pca1',IncrementalPCA(n_components=62, batch_size=64)),\n                     #('lr_classifier',RandomForestClassifier())\n                     ('lr_classifier',OneVsRestClassifier(RandomForestClassifier(n_estimators=50, random_state=1)))\n                     ])\n\npipeline_lr=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=8)), \n                     ('lr_classifier',LogisticRegression())])\n\npipeline_dt=Pipeline([('scalar2',StandardScaler()),\n                     ('pca2',PCA(n_components=8)),\n                     ('dt_classifier',DecisionTreeClassifier())])\n\npipeline_svm = Pipeline([('scalar3', StandardScaler()),\n                      ('pca3', PCA(n_components=8)),\n                      ('clf', svm.SVC())])\n\npipeline_knn=Pipeline([('scalar4',StandardScaler()),\n                     #('pca4',PCA(n_components=60)),\n                     #('pca1',IncrementalPCA(n_components=62, batch_size=64)),\n                       ('fia3',FastICA(n_components=62,random_state=0)),\n                     ('knn_classifier',OneVsRestClassifier(KNeighborsClassifier(n_neighbors=1)))])\n\npipeline_sgd=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=8)), \n                     ('lr_classifier',SGDClassifier())])\n\npipeline_lda=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=8)), \n                     ('lr_classifier',LinearDiscriminantAnalysis())])\n\npipeline_ada=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=8)), \n                     ('lr_classifier',AdaBoostClassifier())])\n\npipeline_gb=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=8)), \n                     ('lr_classifier',GaussianNB())])\n\n\n\npipelines = [pipeline_lr, pipeline_dt,pipeline_svm, pipeline_knn,pipeline_rf,\n             pipeline_sgd,pipeline_lda,pipeline_ada,pipeline_gb]\n\npipe_dict = {0: 'Logistic Regression',\n             1: 'Decision Tree',\n             2: 'Support Vector Machine',\n             3:'K Nearest Neighbor',\n             4:'RandomForestr',\n             5:'SGDClassifier',\n             6:'LinearDiscriminantAnalysis',\n             7:'AdaBoostClassifier',\n             8:'GaussianNB',\n            }\nfor pipe in pipelines:\n  pipe.fit(x_train, y_tn)\nfor i,model in enumerate(pipelines):\n    print(\"{} Test Accuracy:{}\".format(pipe_dict[i],model.score(x_test,y_tt)))","ee222a3e":"pipeline_knn.fit(x_train, y_tn)\n","3b9e7310":"prediksi = pipeline_knn.predict(x_test)\nprint(classification_report(y_tt,prediksi))","21e3a0b2":"#defining various steps required for the genetic algorithm\ndef initilization_of_population(size,n_feat):\n    population = []\n    for i in range(size):\n        chromosome = np.ones(n_feat,dtype=np.bool)\n        chromosome[:int(0.3*n_feat)]=False\n        np.random.shuffle(chromosome)\n        population.append(chromosome)\n    return population\n\ndef fitness_score(population):\n    scores = []\n    for chromosome in population:\n        pipeline_knn.fit(x_train[:,chromosome],y_tn)\n        predictions = pipeline_knn.predict(x_test[:,chromosome])\n        scores.append(accuracy_score(y_tt,predictions))\n    scores, population = np.array(scores), np.array(population) \n    inds = np.argsort(scores)\n    return list(scores[inds][::-1]), list(population[inds,:][::-1])","6aaa2bd7":"def selection(pop_after_fit,n_parents):\n    population_nextgen = []\n    for i in range(n_parents):\n        population_nextgen.append(pop_after_fit[i])\n    return population_nextgen\n\ndef crossover(pop_after_sel):\n    population_nextgen=pop_after_sel\n    for i in range(len(pop_after_sel)):\n        child=pop_after_sel[i]\n        child[3:7]=pop_after_sel[(i+1)%len(pop_after_sel)][3:7]\n        population_nextgen.append(child)\n    return population_nextgen","a241908a":"def mutation(pop_after_cross,mutation_rate):\n    population_nextgen = []\n    for i in range(0,len(pop_after_cross)):\n        chromosome = pop_after_cross[i]\n        for j in range(len(chromosome)):\n            if random.random() < mutation_rate:\n                chromosome[j]= not chromosome[j]\n        population_nextgen.append(chromosome)\n    return population_nextgen\n\ndef generations(size,n_feat,n_parents,\n                mutation_rate,n_gen,x_train,\n                x_test, y_tn, y_tt):\n    best_chromo= []\n    best_score= []\n\n    population_nextgen=initilization_of_population(size,n_feat)\n    for i in range(n_gen):\n        scores, pop_after_fit = fitness_score(population_nextgen)\n        print(scores[:2])\n        pop_after_sel = selection(pop_after_fit,n_parents)\n        pop_after_cross = crossover(pop_after_sel)\n        population_nextgen = mutation(pop_after_cross,mutation_rate)\n        best_chromo.append(pop_after_fit[0])\n        best_score.append(scores[0])\n    return best_chromo,best_score","b0816a0f":"chromo,score=generations(#size=200,\n                         size=3,\n                         n_feat=480,\n                         #n_parents=100,\n                         n_parents=3,\n                         mutation_rate=0.010,\n                         n_gen=40,\n                         x_train=x_train,x_test=x_test,y_tn=y_train,y_tt=y_test)\npipeline_knn.fit(x_train[:,chromo[-1]],y_tn)\n","f2c73ca2":"predictions = pipeline_knn.predict(x_test[:,chromo[-1]])\nprint(\"Accuracy score after genetic algorithm is= \"+str(accuracy_score(y_tt,predictions)))\nprint(classification_report(y_tt,predictions))","3ff56482":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_tt,predictions)\ncm","1d2dbdc8":"pipeline_knn.fit(x_train[:,chromo[-1]],y_tn)\nscores = cross_val_score( pipeline_knn, x_train,y_tn, cv=5, scoring='f1_macro')\nscores","70ec4f01":"plt.figure(figsize = (10,10))\nimport seaborn as sns\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='')","3247e440":"# DATA"}}