{"cell_type":{"2a3f9971":"code","4ae6303e":"code","11b8a635":"code","45c79a72":"code","d4479c5d":"code","a848cdc1":"code","d8653d0b":"code","243ea717":"code","db873caf":"code","dffa8636":"code","2abefff1":"code","8967e38c":"code","18ff7e56":"code","0f7fda4f":"code","431fd6ad":"code","2a117d9b":"code","a2c3d650":"code","c0aedb64":"code","1e95364e":"code","23b99498":"code","a3a9ac9e":"code","0f9b02c7":"code","729217f6":"code","92883b21":"code","420df50b":"code","075a2a0d":"code","8ab24ccd":"code","938cd907":"code","fe3f8e24":"code","e8318a3a":"code","5b36f936":"code","a50722d4":"code","e394b39b":"code","c3123c3e":"code","c43cdce0":"code","ce17bc63":"code","8db595b9":"code","f528f953":"code","a0899b94":"code","7c873f50":"code","c79a34a8":"code","3683e6d3":"code","50dea875":"code","9471e526":"markdown","24f1a591":"markdown","a577543c":"markdown","2ae047d7":"markdown","15160839":"markdown","1c7ebea4":"markdown","7fe0f34b":"markdown","44939f10":"markdown","9a3bcbe2":"markdown","27c9589f":"markdown","910ef18a":"markdown","c623e3f5":"markdown","f809df4e":"markdown","3b8036de":"markdown","8180d01b":"markdown","01f3a419":"markdown","e70a1842":"markdown","e3e65528":"markdown","d2fe0610":"markdown","f6f2fc15":"markdown","1a491c04":"markdown","d11e593b":"markdown","a1d73534":"markdown","ad215eaa":"markdown","b17a50d1":"markdown","ec53004a":"markdown","bb364f18":"markdown","fb8d0e7b":"markdown","82585325":"markdown","68e825c3":"markdown","fe9a34b3":"markdown","e33efb01":"markdown","4458a99b":"markdown","38a70ddd":"markdown","31a7a7ce":"markdown","10c32177":"markdown","eedeefec":"markdown","5fbe52a8":"markdown","6be40a52":"markdown","a0c041f6":"markdown","0992f70e":"markdown","65a46afa":"markdown","07ac4b3c":"markdown","569262fb":"markdown","2c6ede69":"markdown","0b64d895":"markdown","4c48f271":"markdown","1e0a0e80":"markdown","15658485":"markdown","ec00c8b4":"markdown","6629b6db":"markdown","1836c13a":"markdown","1deb41d6":"markdown","e4888a1d":"markdown","97981a54":"markdown","4018a6b9":"markdown","ec66192f":"markdown","1823aab9":"markdown","826ac3af":"markdown","01a0f7d6":"markdown","bb1af54b":"markdown","8d004db4":"markdown","6ba99db0":"markdown","0a75900e":"markdown","e23cb7fa":"markdown","32cb495b":"markdown","8bccf692":"markdown","2ff06b08":"markdown","fc3cf2d7":"markdown","9a8e252a":"markdown"},"source":{"2a3f9971":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","4ae6303e":"bpi_challenge_2017_data = pd.read_csv('..\/input\/bpichallenge2017\/BPI_Challenge_2017.csv') ","11b8a635":"bpi_challenge_2017_data.head()","45c79a72":"bpi_challenge_2017_data.describe(include='all')","d4479c5d":"bpi_challenge_2017_data.info()","a848cdc1":"bpi_challenge_2017_data.isnull().sum().sort_values(ascending=False)","d8653d0b":"bpi_challenge_2017_data[bpi_challenge_2017_data['EventOrigin'] == 'Offer'].isnull().sum().sort_values(ascending=False)","243ea717":"bpi_challenge_2017_data[bpi_challenge_2017_data['EventOrigin'] == 'Workflow'].isnull().sum().sort_values(ascending=False)","db873caf":"bpi_challenge_2017_data['Accepted'].unique()","dffa8636":"bpi_challenge_2017_data['Accepted'].value_counts()","2abefff1":"plt.figure(figsize=[10,8])\naccepted = bpi_challenge_2017_data[bpi_challenge_2017_data['Accepted'] == True]['Selected']\nax = sns.countplot(accepted)\nfor p in ax.patches:\n    (ax.annotate('{:.2f}%'.format(p.get_height()\/len(accepted.dropna())*100), \n                 (p.get_x()+0.3, p.get_height()+1), fontsize=14))\nax.set_title(\"Accepted Distribution\")\nax.set(xlabel=\"Accepted\", ylabel=\"Frequence\")\nplt.show()","8967e38c":"plt.figure(figsize=[10,8])\nax = sns.distplot(bpi_challenge_2017_data['case:RequestedAmount'])\nax.set_title(\"Requested Amount Distribution\")\nax.set(xLabel=\"Requested Amount\", yLabel=\"Density\")\nplt.show()","18ff7e56":"plt.figure(figsize=[10,8])\nax = sns.distplot(bpi_challenge_2017_data['OfferedAmount'])\nax.set_title(\"Offered Amount Distribution\")\nax.set(xLabel=\"Offered Amount\", yLabel=\"Density\")\nplt.show()","0f7fda4f":"offered_less = (bpi_challenge_2017_data[(bpi_challenge_2017_data['OfferedAmount']) \n                                        < (bpi_challenge_2017_data['case:RequestedAmount'])])\noffered_more = (bpi_challenge_2017_data[(bpi_challenge_2017_data['OfferedAmount']) \n                                        > (bpi_challenge_2017_data['case:RequestedAmount'])])\noffered_eq = (bpi_challenge_2017_data[(bpi_challenge_2017_data['OfferedAmount']) \n                                     == (bpi_challenge_2017_data['case:RequestedAmount'])])\nless_acc = offered_less[offered_less['Accepted'] == True]\nmore_acc = offered_more[offered_more['Accepted'] == True]\nequal_acc = offered_eq[offered_eq['Accepted'] == True]\n\nplt.figure(figsize=[10,8])\nax = sns.countplot(less_acc['Selected'])\nfor p in ax.patches:\n    (ax.annotate('{:.2f}%'.format(p.get_height()\/len(less_acc)), \n                 (p.get_x()+0.3, p.get_height()+1), fontsize=14))\nax.set_title(\"Accepted Distribution - (OfferedAmount < RequestedAmount)\")\nax.set(xLabel=\"Accepted\", yLabel='Frequence')\n\nplt.figure(figsize=[10,8])\nax = sns.countplot(more_acc['Selected'])\nfor p in ax.patches:\n    (ax.annotate('{:.2f}%'.format(p.get_height()\/len(more_acc)), \n                 (p.get_x()+0.3, p.get_height()+1),fontsize=14))\nax.set_title(\"Accepted Distribution - (OfferedAmount > RequestedAmount)\")\nax.set(xLabel=\"Accepted\", yLabel='Frequence')\n\nplt.figure(figsize=[10,8])\nax = sns.countplot(equal_acc['Selected'])\nfor p in ax.patches:\n    (ax.annotate('{:.2f}%'.format(p.get_height()\/len(equal_acc)), \n                 (p.get_x()+0.3, p.get_height()+1), fontsize=14))\nax.set_title(\"Accepted Distribution (OfferedAmount = RequestedAmount)\")\nax.set(xLabel=\"Accepted\", yLabel='Frequence')\nplt.show()\n","431fd6ad":"plt.figure(figsize=[10,8])\nloan_goals_occ = bpi_challenge_2017_data['case:LoanGoal'].value_counts()\nax = sns.barplot( x=loan_goals_occ.index, y=loan_goals_occ)\nax.set(ylabel=\"Frequence\", xlabel = \"Loan Goal\")\nax.set_title(\"Loan Goal Distribution\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","2a117d9b":"offer_refused = (bpi_challenge_2017_data[(bpi_challenge_2017_data['Accepted'] == True) \n                                         & (bpi_challenge_2017_data['Selected'] == False)])\ngrouped_by_lg = (offer_refused.groupby(['case:LoanGoal'])['Selected'].count()\n                 .sort_values(ascending=False))\n\nplt.figure(figsize=[10,8])\nax = sns.barplot(y=grouped_by_lg.values, x=grouped_by_lg.index)\nax.set(ylabel=\"Offer Refused\", xlabel = \"Loan Goal\")\nax.set_title(\"Offer Refused by Loan Goal\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","a2c3d650":"plt.figure(figsize=[10,8])\nax = sns.boxplot(data=bpi_challenge_2017_data, x='case:LoanGoal', y='case:RequestedAmount')\nax.set(xlabel=\"Loan Goal\", ylabel = \"Requested Amount\")\nax.set_title(\"Loan Goal Variation (Requested Amount)\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=30)\nplt.show()","c0aedb64":"plt.figure(figsize=[10,8])\nax = sns.boxplot(data=bpi_challenge_2017_data, x='case:LoanGoal', y='OfferedAmount')\nax.set(xlabel=\"Loan Goal\", ylabel = \"Offered Amount\")\nax.set_title(\"Loan Goal Variation (Offered Amount)\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=30)\nplt.show()","1e95364e":"mean_per_loan_goal = (bpi_challenge_2017_data.groupby(['case:LoanGoal'])['case:RequestedAmount']\n                      .mean().sort_values(ascending=False))\nplt.figure(figsize=[10,8])\nax = sns.barplot(y=mean_per_loan_goal.values, x=mean_per_loan_goal.index)\nax.set(ylabel=\"Mean of Requested Amount\", xlabel = \"Loan Goal\")\nax.set_title(\"Mean of Requested Amount by Loan Goal\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","23b99498":"mean_per_loan_goal = (bpi_challenge_2017_data.groupby(['case:LoanGoal'])['OfferedAmount']\n                      .mean().sort_values(ascending=False))\nplt.figure(figsize=[10,8])\nax = sns.barplot(y=mean_per_loan_goal.values, x=mean_per_loan_goal.index)\nax.set(ylabel=\"Mean Offered Amount\", xlabel = \"Loan Goal\")\nax.set_title(\"Mean of Offered Amount by Loan Goal\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","a3a9ac9e":"offer_refused = (bpi_challenge_2017_data[(bpi_challenge_2017_data['Accepted'] == True) \n                                         & (bpi_challenge_2017_data['Selected'] == False) ])\ngrouped_by_lg = (offer_refused.groupby(['case:LoanGoal'])['Selected'].count()\n                 .sort_values(ascending=False))\n\nplt.figure(figsize=[10,8])\nax = sns.barplot(y=grouped_by_lg.values, x=grouped_by_lg.index)\nax.set(ylabel=\"Offer Refused\", xlabel = \"Loan Goal\")\nax.set_title(\"Mean Offer Refused by Loan Goal\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nplt.show()","0f9b02c7":"df_model = (bpi_challenge_2017_data[['concept:name', 'case:concept:name', 'EventOrigin',\n                                     'case:RequestedAmount', 'CreditScore', 'OfferedAmount']])\ndf_model.head()","729217f6":"df_model = df_model[df_model['EventOrigin'] != 'Workflow']\ndf_model.head()","92883b21":"# Aplications ok\napp_ok = (df_model[(df_model['concept:name'] == 'A_Pending')]['case:concept:name']\n          .drop_duplicates())\ndf_1 = df_model.merge(app_ok, on='case:concept:name')\ndf_1['label'] = df_1.apply(lambda x: 1, axis=1)\ndf_1.head()","420df50b":"# Aplications not ok\napp_not_ok = (df_model[(~df_model['case:concept:name'].isin(app_ok.tolist()))]['case:concept:name']\n              .drop_duplicates())\ndf_2 = df_model.merge(app_not_ok, on='case:concept:name')\ndf_2['label'] = df_2.apply(lambda x: 0, axis=1)\ndf_2.head()","075a2a0d":"df_model = (pd.concat([df_1, df_2])[['case:concept:name', 'case:RequestedAmount', \n                                     'CreditScore', 'OfferedAmount', 'label']]\n            .drop_duplicates())\ndf_model.sample(10)","8ab24ccd":"df_model.isnull().sum().sort_values(ascending=False)","938cd907":"df_model = df_model.dropna(axis=0)\ndf_model.isnull().sum().sort_values(ascending=False)","fe3f8e24":"plt.figure(figsize=[10,8])\nlabels_occ = df_model['label']\nax = sns.barplot(data=df_model, x=labels_occ.value_counts().index, y=labels_occ.value_counts(), orient='v')\nfor p in ax.patches:\n    (ax.annotate('{:.2f}%'.format(p.get_height()\/len(labels_occ)*100), \n                 (p.get_x()+0.3, p.get_height()+1), fontsize=14))\nax.set(xlabel=\"Label\", ylabel = \"Frequence\")\nax.set_title(\"Label Distribution\")\nplt.show()","e8318a3a":"X_train, X_test = train_test_split(df_model['case:concept:name'].drop_duplicates(), test_size=0.3)\nX_train = df_model.merge(X_train, on=\"case:concept:name\")\nX_test = df_model.merge(X_test, on=\"case:concept:name\")\n\ny_test = X_test['label']\ny_train = X_train['label']\nX_train = X_train.drop(['case:concept:name', 'label'], axis=1)\nX_test = X_test.drop(['case:concept:name', 'label'], axis=1)","5b36f936":"classifier_dt = DecisionTreeClassifier()\nclassifier_dt = classifier_dt.fit(X_train,y_train)\ny_pred = classifier_dt.predict(X_test)","a50722d4":"accuracy = metrics.accuracy_score(y_test, y_pred)\nrecall = metrics.recall_score(y_test, y_pred)\nprecision = metrics.precision_score(y_test, y_pred)\n\nprint(\"Accuracy: \", accuracy)\nprint(\"Recall: \", recall)\nprint(\"Precision: \", precision)","e394b39b":"plt.figure(figsize=(10,8))\nax = (sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, annot_kws={\"size\": 20}, \n                 linewidths=.1, fmt='d', cmap=sns.cubehelix_palette(as_cmap=True)))\nplt.yticks([0.5,1.5,2], [ 'Loan ok', 'Loan Not ok'], va='center', fontsize=14)\nplt.xticks([0.5,1.5,2], [ 'Loan ok', 'Loan Not ok'], va='center', fontsize=14)\nax.set_title(\"Confusion Matrix\")\nax.set(xlabel=\"Predicted\", ylabel=\"Actual\");\nplt.show()\n","c3123c3e":"features = X_train.columns\n\nfeatures_importances = pd.Series(classifier_dt.feature_importances_, index=features)\n\nplt.figure(figsize=[10,8])\nax = sns.barplot(x=features_importances.values, y=features_importances)\nax.set_title(\"Feature importances\")\nplt.xticks(list(range(len(features_importances))), features)\nplt.show()","c43cdce0":"df_model_reg = (bpi_challenge_2017_data[['case:LoanGoal','case:RequestedAmount', \n                                         'CreditScore', 'OfferedAmount']])\ndf_model_reg.head()","ce17bc63":"df_model_reg.isnull().sum().sort_values(ascending=False)","8db595b9":"df_model_reg = df_model_reg.dropna(axis=0)\ndf_model_reg.isnull().sum().sort_values(ascending=False)","f528f953":"df_model_reg.columns.str.strip()","a0899b94":"x = df_model_reg[['case:LoanGoal', 'case:RequestedAmount', 'CreditScore']]\ny = df_model_reg[['OfferedAmount']]","7c873f50":"x = pd.get_dummies(x, columns=['case:LoanGoal'])\nx.head()","c79a34a8":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)","3683e6d3":"linear_regressor = LinearRegression()  \nlinear_regressor.fit(x_train, y_train)\ny_pred = linear_regressor.predict(x_test)","50dea875":"mae = metrics.mean_absolute_error(y_test, y_pred)\nmse =  metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n\nprint(\"Mean Absolute Error (MAE): \", mae)\nprint(\"Mean Squared Error (MSE)\", mse)\nprint(\"Root Mean Squared Error (RMSE): \", rmse)","9471e526":"For this model the Workflow data is not very interesting, so we can get it out.","24f1a591":"We use *get_dummies* from the * pandas * library to convert categorical variables into numeric values. In this case only the column 'case: LoanGoal' is categorical.","a577543c":"\nThis visualization is important because it shows the amount of data, columns and their types and the amount of non-null values, that is, you can see that there are columns with many missing values, and that it is important to deal with them before making specific analyzes.","2ae047d7":"# **Loading Data**","15160839":"# **Evaluating the model**","1c7ebea4":"# **Importing Libraries**","7fe0f34b":"# **Classification**","44939f10":"# **Building a model with Decision Tree**","9a3bcbe2":"1. We created a classifier using DecisionTreeClassifier from the *sklearn* library.\n2. We perform the classifier training using the *fit* function.\n3. We perform the prediction with the test data.","27c9589f":"For a better visualization of the prediction results of each class, we can create a confusion matrix. Confusion matrix is precisely a table that shows the frequency of classification for each class of the model.\n\nIn the confusion matrix:\n\n* First quadrant is the *true positive* (TP): it occurs when in the real set, the class that is to be predicted was correctly predicted.\n* Second quadrant is the *false positive* (FP): it occurs when in the real set, the class to be predicted was predicted incorrectly.\n* Third quadrant is the *false negative* (FN): it occurs when in the real set, the class that is not intended to be predicted was incorrectly predicted.\n* Fourth quadrant is the *true negative* (TN): it occurs when in the real set, the class that is not wanted to be predicted that was correctly predicted.","910ef18a":"The last two bar graphs show the average amount requested per loan objective and the average amount offered per loan objective, respectively.","c623e3f5":"To answer this question we can calculate and graphically display the number of offers grouped by loan objective.","f809df4e":"We use the *sklearn* library's *train_test_split* function to separate the data for training and testing. Usually 30% of the data is an ideal size for the test set and this is passed as a function parameter.","3b8036de":"Since we already have a trained model and perform a prediction, we can evaluate the model using several metrics:\n\n* **Accuracy**: It is the number of data correctly predicted in all data sets. It tells you how accurate the model is.\n* **Recall**: It is the proportion of positive observations correctly predicted in relation to the total of predicted observations.\n* **Precision**: It is the proportion of positive observations correctly predicted in relation to the total of positive predicted observations. It's how accurate the model is.","8180d01b":"# **Conclusions**","01f3a419":"# **Checking and handling missing values**","e70a1842":"# **Separating resources**","e3e65528":"To answer this question, we can view the distribution of the values of the responses of Accepeted offers (True or False). For that we built a bar graph.","d2fe0610":"# **Question 4: Predict whether the loan will be successful at the end of the process.**","f6f2fc15":"# **Checking and handling missing values**","1a491c04":"# **Evaluating the model**","d11e593b":"\nChecking the amount of missing values \u200b\u200bin a candidate column for the variable of interest is very important. For some cases, considering these values \u200b\u200bcan lead to weak or biased analysis. Missing values \u200b\u200bcan be filled in or even removed.","a1d73534":"To predict the value the value of the offer, we already know that the dependent variable (output) is the value of the offer (OfferedAmount) and as they are continuous values the best to use is Regression. There are several types of regression, we will use multiple regression to make this prediction.","ad215eaa":"# **Regression**","b17a50d1":"# **Selecting features**","ec53004a":"In the bar graph above, we can see the distribution of the variable (LoanGoal) that shows the frequency of loan objectives.","bb364f18":"# **Viewing the data**","fb8d0e7b":"The bar graph shows the distribution of labels (1 and 0) that represent the loan logs that worked and those that did not, respectively.","82585325":"The last graph shows the average of offers declined for loan objectives.","68e825c3":"Since we already have a trained model and perform a prediction, we can evaluate the model using several metrics:\n\n* Mean Absolute Error (MAE): Is the mean of the absolute value of the erro.\n* Mean Squared Error (MSE) Is the mean of the squared errors.\n* Root Mean Squared Error (RMSE): Is the square root of the mean of the squared errors.","fe9a34b3":"# **Checking missing value**","e33efb01":"The following input variables (features) were chosen:\n\n* case: RequestedAmount: Amount requested on the loan\n* CreditScore: Customer credit score\n* OfferedAmount: Amount offered","4458a99b":"The following input variables (features) were chosen:\n\n* case: LoanGoal: The goal of the loan\n* case: RequestedAmount: Amount requested on the loan\n* CreditScore: Customer credit score\n* OfferedAmount: Amount offered","38a70ddd":"# **Separating resources**","31a7a7ce":"We now join the two sets into a single dataframe, overwriting it only with the columns that will be used in the model.","10c32177":"# **Analyzes and predictions**\n\n\nSome questions that can answer possible problems in the process:\n\n*Question 1: What is the frequency of accepted offers?*\n\n*Question 2: Offers with less than requested value are more likely to be rejected?*\n\n*Question 3: Which loan goal had the highest number of declined offers?*\n\n*Question 4: Predict whether the loan will be successful at the end of the process.*\n\n*Question 5: Predict the value of the offer to be received by an application.*","eedeefec":"We can perform other analyzes:","5fbe52a8":"We can view the columns and the number of rows that have missing values. As the initial process of the company did not register offers, it is acceptable that a lot of data have these columns with null values, but the question is: Are there only missing values \u200b\u200bfor applications that did not have offers?\n\n\nTo answer this question, we can check for missing values \u200b\u200bwhen the event type (EventOrigin) is different from 'Aplication', in the case 'Offer' and 'Workflow'.","6be40a52":"The *countplot* chart is a type of bar chart from the *seaborn* library that aims to show the frequency of each categorical class.","a0c041f6":"With the bar graph above we can see that the purpose of the loan application that had the most declined offers was 'Car' followed by 'Home improvement' and 'Existing loan takeover'.","0992f70e":"We can calculate the importance of resources for the model, using the feature_importances_ attribute of the sklearn library classifier. And for the best visualization we can use a bar graph.","65a46afa":"We use str.strip () to \"trim\" the data in all columns, if needed.","07ac4b3c":"# **Question 5:**","569262fb":"The data of applications that gave ok were labeled with a value of 1 (Label column), while data that failed with a value of 0.","2c6ede69":"# **Question 1: What is the frequency of accepted offers?**","0b64d895":"# **Exploratory Analyzes**","4c48f271":"# **About Dataset**\n\nThe dataset was found on the [website](https:\/\/www.win.tue.nl\/bpi\/doku.php?id=2017:challenge) of the 13th International Business Process Intelligence Workshop 2017.\n\nThe logs refer to a loan application process of a Dutch financial institute. The data includes all the loan process logs including offers made by the company for accepted loan applications.\n\nFor more information about the data, you can consult the [event page](https:\/\/www.win.tue.nl\/bpi\/doku.php?id=2017:challenge) in the 'The Data' section or directly in the [page](https:\/\/data.4tu.nl\/articles\/BPI_Challenge_2017\/12696884) of the dataset.","1e0a0e80":"To answer this question, we can see the frequency of accepted and rejected offers when the amount offered was less than the amount requested.","15658485":"1.  We created a regressor using LinearRegressor from the *sklearn* library.\n2.  We perform regressor training using the *fit* function.\n3.  We perform a prediction with the test data.\n","ec00c8b4":"Initially we can create a new set with just the columns of interest to get the data we need.","6629b6db":"In this case, we can remove the lines with missing values.","1836c13a":"Initially we can create a new set with just the columns of interest to get the data we need.","1deb41d6":"Similarly, we can calculate and visualize the distribution for other individual variables.","e4888a1d":"# **Building a model with Linear Regression**","97981a54":"We separate the data set into two variables, it depends (Y) that the output is independent (X) that are like inputs.","4018a6b9":"Neste caso podemos remover as linhas com valores ausentes.","ec66192f":"I used the *sklearn* library's *train_test_split* function to separate the data for training and testing. Usually 30% of the data is an ideal size for the test set and this is passed as a function parameter.","1823aab9":"\nThis view allows showing a statistical summary of the numerical variables. With the parameter \"include = all\" we can view categorical data information as well.","826ac3af":"# **Extracting the data**","01a0f7d6":"# **Main Objective**\n\nThe main objective is to practice knowledge of Data Analysis, Machine Learning and Statistics. For this, a Business Process Intelligence (BPI) data set was selected.","bb1af54b":"# **Question 3: Which loan goal had the highest number of declined offers?**","8d004db4":"For this model offered Amount is a feature of high importance.","6ba99db0":"# **Selecting features**","0a75900e":"In this notebook we explore the data made available by BPI Challenge 2017 in order to practice knowledge of data analysis, exploratory data analysis, machine learning, among others.\n\nWe analyzed the distribution of some variables in order to view accepted \/ rejected offers and what could influence an offer to be refused. We also created models to predict when a loan would be successful and also to know the value offered for an application.\n\nThe analyzes were carried out during studies to practice the knowledge of the acquired area, for more interpretations and decisions, more in-depth analyzes should be carried out.","e23cb7fa":"We noticed that there are missing values \u200b\u200bin the offer fields when the logs are from all sources - 'Application', 'Offer' and 'Workflow'.","32cb495b":"The *distplot* charts are density graphs with histogram showing the distribution and the probability of the values of the variables *RequestedAmount* and *OfferedAmount*, respectively.","8bccf692":"To perform this classification, we need to select the data for the two classes, the class of loans that worked and the class of those that did not.","2ff06b08":"To better answer the question, we can make comparisons with other analyzes. Compare with the frequency of declined offers when the offered value is greater than requested, and also when the offered value is equal to the requested value. We can say that more than half of the offers with less than the requested value can be refused.","fc3cf2d7":"# **Question 2: Offers with less than requested value are more likely to be rejected?**","9a8e252a":"The last two plotted graphs are bloxplots of the amount requested for loan objectives and the amount offered for loan objectives, respectively. The bloxplot represents the variation of the observed data, and we can make several analyzes, including visualizing outliers."}}