{"cell_type":{"29627531":"code","ece0c956":"code","0ca76413":"code","364a6b55":"code","9fba6211":"code","b47ad2b3":"code","bdaae15c":"code","1d8abceb":"code","45aa7714":"code","220e4512":"code","ce734d8a":"code","260b3540":"code","8267decd":"code","e0698a0c":"code","f7d30990":"code","a01ab5ca":"code","6ff36384":"code","c79376ab":"code","a9009a2e":"code","b7032260":"code","cc4c86d0":"code","bea2e78f":"code","75ffa919":"code","d856f4ba":"code","cdf82981":"code","c8d5d6d9":"code","a5a2a812":"code","322cd6a6":"code","3442a368":"code","72e44a7d":"code","f0fbe452":"code","6a9b9cd8":"code","01c707b1":"code","96a6535e":"code","6897c49c":"code","14351342":"code","038b2344":"code","7015a86a":"code","ac40bd8d":"code","79431fcd":"code","b0f01c37":"code","e5c85acf":"code","f6eaa9b1":"code","e7fd1580":"code","56de1cb7":"code","0cbf92c0":"code","a4510780":"code","d531a21c":"code","e61d20cf":"code","5222b6d3":"code","6ff56939":"code","81abd532":"code","ff5c2e54":"code","ca0c8693":"markdown","ede95cfb":"markdown","9281fd49":"markdown","d71198f3":"markdown","5dc2314b":"markdown","72ffb87e":"markdown","54f26711":"markdown","0d22e245":"markdown","a64b36a1":"markdown","86dbd839":"markdown","a9313336":"markdown","89648901":"markdown","463ddbd2":"markdown","da8f1f61":"markdown","5729cb56":"markdown","260202db":"markdown","8c8f0284":"markdown","ad46bba0":"markdown","02528375":"markdown","b1d5fe15":"markdown","96b620d7":"markdown","eff3dea7":"markdown"},"source":{"29627531":"import pandas as pd\nimport numpy as np\nfrom collections import OrderedDict\n\nfrom PIL import Image\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\nplt.style.use('seaborn')\n%matplotlib inline","ece0c956":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split","0ca76413":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain_df.head()","364a6b55":"print(\"train data shape : {}\".format(train_df.shape))\nprint(\"test data shape : {}\".format(test_df.shape))","9fba6211":"train_df.describe()","b47ad2b3":"print(\"Check train data values : \\n{}\".format(np.unique(train_df)))","bdaae15c":"sns.color_palette(\"Greys\", as_cmap=True)","1d8abceb":"Greys_palette = sns.color_palette(\"Greys\",10)\nsns.palplot(Greys_palette)","45aa7714":"pd.DataFrame(train_df.isnull().sum().sort_values(ascending=False), columns=[\"Null Count\"]).head().style.background_gradient(cmap='Greys')","220e4512":"msno.matrix(df=train_df.iloc[:,:],figsize=(20,5),color=Greys_palette[8])","ce734d8a":"fig, ax = plt.subplots(1,1, figsize=(10,7))\nsns.countplot(x='label', data=train_df, palette=Greys_palette[::-1], ax=ax)\nax.patch.set_alpha(0)\n\nfig.text(0.1,0.92,\"distribution by Label in Mnist dataset\", fontweight=\"bold\", fontfamily='serif', fontsize=17)","260b3540":"x = train_df.iloc[:,1:].values\ny = train_df.iloc[:,0].values","8267decd":"print(\"X shape : {}\".format(x.shape))\nprint(\"Y shape : {}\".format(y.shape))","e0698a0c":"fig , axes = plt.subplots(5, 5, figsize=(15,15))\n\nx_idx = 0\ny_idx = 0\n\nfor i in range(5*5):\n    if x_idx == 5:\n        x_idx = 0\n        y_idx += 1\n        \n    axes[y_idx][x_idx].imshow(x[i].reshape(28,28), 'gray')\n    axes[y_idx][x_idx].axis(\"off\")\n    axes[y_idx][x_idx].set_title(\"Target : \" + str(y[i]))\n    x_idx += 1\n\nplt.show()","f7d30990":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15)","a01ab5ca":"print(\"x_train shape : {}\".format(x_train.shape))\nprint(\"y_train shape : {}\".format(y_train.shape))\nprint(\"x_val shape : {}\".format(x_val.shape))\nprint(\"y_val shape : {}\".format(y_val.shape))","6ff36384":"class BasicDataset(torch.utils.data.Dataset):\n    def __init__(self,x_data, y_data, is_labeled=False):\n        self.x = self.get_float_type(x_data)\n        self.is_labeled = is_labeled\n        \n        if self.is_labeled:\n            self.y = self.get_long_type(y_data)\n        else:\n            self.y = None\n        \n        \n    def __len__(self):\n        return len(self.x)\n    \n    \n    def __getitem__(self, index):\n        global data\n        data = {}\n        \n        x_row = self.x[index]\n        data['data'] = x_row\n    \n        if self.is_labeled == True: \n            y_row = self.y[index]\n            data['target'] = y_row\n        return data\n    \n        \n    def get_float_type(self, data):\n        data = data.astype('float32')\n        data \/= 255\n        data = data.reshape(-1, 1, 28, 28)\n        return data\n    \n    \n    def get_long_type(self, target):\n        target = target.astype(torch.LongTensor)\n        return target","c79376ab":"train_dataset = BasicDataset(x_train, y_train, is_labeled=True)\nval_dataset = BasicDataset(x_val, y_val, is_labeled=True)","a9009a2e":"print(\"Data of train dataset : {}\\n\\n\\n\\n\".format(train_dataset[0]['data']))\nprint(\"Target of train dataset : {}\".format(train_dataset[0]['target']))","b7032260":"BATCH_SIZE = 256","cc4c86d0":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle = False)","bea2e78f":"dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}","75ffa919":"INPUT_DIM = 1\nHIDDEN_DIM_1 = 32\nHIDDEN_DIM_2 = 64\nOUTPUT = 10","d856f4ba":"class BasicCNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output):\n        super(BasicCNN, self).__init__()\n        \n        self.convolution_layer = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(input_dim, hidden_dim_1, 3, 1, 0)),\n            ('relu1', nn.ReLU()),\n            ('pool1', nn.MaxPool2d(2,2)),\n            ('conv2', nn.Conv2d(hidden_dim_1, hidden_dim_2, 3, 1, 0)),\n            ('relu2', nn.ReLU()),\n            ('pool2', nn.MaxPool2d(2,2))    \n        ]))\n        self.fc_layer = nn.Sequential(OrderedDict([\n            ('Dense1', nn.Linear(1600, output)),\n            ('softmax', nn.Softmax())\n        ]))\n    \n    def forward(self,x):\n        out = self.convolution_layer(x)\n        out = out.view(out.size(0),-1)\n        out = self.fc_layer(out)\n        return out","cdf82981":"cnn_model = BasicCNN(INPUT_DIM, HIDDEN_DIM_1, HIDDEN_DIM_2, OUTPUT)\nprint(cnn_model)","c8d5d6d9":"class ResidualBlock(nn.Module):\n    def __init__(self, data_dim, layer_name, is_last_layer=False):\n        super(ResidualBlock, self).__init__()\n        self.is_last_layer = is_last_layer\n        \n        self.resblock_1 = nn.Sequential(OrderedDict([\n            ('{}_conv1'.format(layer_name), nn.Conv2d(data_dim, data_dim, kernel_size=3, stride=1, padding=1, bias=False)),\n            ('{}_batchnorm1'.format(layer_name), nn.BatchNorm2d(data_dim)),\n            ('{}_relu1'.format(layer_name), nn.ReLU()),\n            \n            ('{}_conv2'.format(layer_name), nn.Conv2d(data_dim, data_dim, kernel_size=3, stride=1, padding=1, bias=False)),\n            ('{}_batchnorm2'.format(layer_name), nn.BatchNorm2d(data_dim)),\n            ('{}_relu2'.format(layer_name), nn.ReLU())\n        ]))\n        self.resblock_2 = nn.Sequential(OrderedDict([\n            ('{}_conv1'.format(layer_name), nn.Conv2d(data_dim, data_dim, kernel_size=3, stride=1, padding=1, bias=False)),\n            ('{}_batchnorm1'.format(layer_name), nn.BatchNorm2d(data_dim)),\n            ('{}_relu1'.format(layer_name), nn.ReLU()),\n            \n            ('{}_conv2'.format(layer_name), nn.Conv2d(data_dim, data_dim, kernel_size=3, stride=1, padding=0, bias=False)),\n            ('{}_batchnorm2'.format(layer_name), nn.BatchNorm2d(data_dim)),\n            ('{}_relu2'.format(layer_name), nn.ReLU())\n        ]))\n        \n        # Adjustment layer because height and width values are different\n        self.set_shortcut = nn.Conv2d(data_dim, data_dim, kernel_size=3, stride=1, padding=0, bias=False)\n        \n        \n    def forward(self, x):\n        shortcut = x\n        out = self.resblock_1(x)\n        out = out + shortcut\n        \n        shortcut = self.set_shortcut(out)\n        out = self.resblock_2(out)\n        out = out + shortcut\n\n        return out","a5a2a812":"class ResNet_mini(nn.Module):\n    def __init__(self, input_dim, output):\n        super(ResNet_mini, self).__init__()\n        self.FirstBlock = nn.Sequential(OrderedDict([\n            ('FirstBlock_conv1', nn.Conv2d(input_dim, 64, kernel_size=4, stride=2, padding=4, bias=False)),\n            ('FirstBlock_batchnorm1', nn.BatchNorm2d(64)),\n            ('FirstBlock_relu1', nn.ReLU()),\n            ('FirstBlock_maxpool2d1', nn.MaxPool2d(kernel_size=2, stride=2, padding=1)),\n        ]))\n        self.SecondBlock = ResidualBlock(64,'SecondBlock')\n        self.ChangeChannel_1 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0)\n        \n        self.ThridBlock = ResidualBlock(128,'ThridBlock')\n        self.ChangeChannel_2 = nn.Conv2d(128, 256, kernel_size=1, stride=1, padding=0)\n        \n        self.FourthBlock = ResidualBlock(256,'FourthBlock')  \n        \n        self.AveragePool2d = nn.AdaptiveAvgPool2d((1,1))\n        \n        self.FC = nn.Sequential(OrderedDict([\n            ('FC_linear', nn.Linear(256, output)),\n            ('FC_softmax', nn.Softmax(dim=1))\n        ]))\n    \n    def forward(self, x):\n        out = self.FirstBlock(x)\n\n        out = self.SecondBlock(out)\n        out = self.ChangeChannel_1(out)\n\n        out = self.ThridBlock(out)\n        out = self.ChangeChannel_2(out)\n\n        out = self.FourthBlock(out)\n\n        out = self.AveragePool2d(out)\n        out = out.view(out.size(0), -1)\n        out = self.FC(out)\n        \n        return out","322cd6a6":"resnet_model = ResNet_mini(INPUT_DIM, OUTPUT)\nprint(resnet_model)","3442a368":"class DenseBlock(nn.Module):\n    def __init__(self,input_dim, layer_name):\n        super(DenseBlock, self).__init__()\n        \n        hidden_dim = input_dim * 2\n        \n        self.denseblock1 = nn.Sequential(OrderedDict([\n            ('{}_batchnorm1'.format(layer_name), nn.BatchNorm2d(input_dim)),\n            ('{}_relu1'.format(layer_name), nn.ReLU()),\n            ('{}_conv1'.format(layer_name), nn.Conv2d(input_dim, hidden_dim, kernel_size=3, stride=1, padding=1, bias=False)),\n        ]))\n        \n        self.denseblock2 = nn.Sequential(OrderedDict([\n            ('{}_batchnorm2'.format(layer_name), nn.BatchNorm2d(hidden_dim)),\n            ('{}_relu2'.format(layer_name), nn.ReLU()),\n            ('{}_conv2'.format(layer_name), nn.Conv2d(hidden_dim, 32, kernel_size=3, stride=1, padding=1, bias=False)),\n        ]))\n        \n    def forward(self, x):\n        shortcut = x\n        out = self.denseblock1(x)\n        out = self.denseblock2(out)\n        out = torch.cat([out, shortcut], 1)\n        return out","72e44a7d":"class DenseNet_mini(nn.Module):\n    def __init__(self, input_dim, output):\n        super(DenseNet_mini, self).__init__()\n        self.FirstBlock = nn.Sequential(OrderedDict([\n            ('FirstBlock_conv1', nn.Conv2d(input_dim, 32, kernel_size=4, stride=2, padding=4, bias=False)),\n            ('FirstBlock_batchnorm1', nn.BatchNorm2d(32)),\n            ('FirstBlock_relu1', nn.ReLU()),\n            ('FirstBlock_maxpool2d1', nn.MaxPool2d(kernel_size=2, stride=2, padding=1)),\n        ]))\n        self.SecondBlock = DenseBlock(32,'SecondBlock')\n        self.ThridBlock = DenseBlock(32+32,'ThridBlock')\n        self.FourthBlock = DenseBlock(64+32,'FourthBlock')\n        self.FifthBlock = DenseBlock(96+32,'FifthBlock')\n        \n        self.AveragePool2d = nn.AdaptiveAvgPool2d((1,1))\n        \n        self.FC = nn.Sequential(OrderedDict([\n            ('FC_linear', nn.Linear(128, output)),\n            ('FC_softmax', nn.Softmax(dim=1))\n        ]))\n    \n    def forward(self, x):\n        out = self.FirstBlock(x)\n        out = self.SecondBlock(out)\n        out = self.ThridBlock(out)\n        out = self.FourthBlock(out)\n\n        out = self.AveragePool2d(out)\n        out = out.view(out.size(0), -1)\n        out = self.FC(out)\n        \n        return out","f0fbe452":"densenet_model = DenseNet_mini(INPUT_DIM, OUTPUT)\nprint(densenet_model)","6a9b9cd8":"def train_model(model, dataloaders_dict, loss_fn, optimizer, num_epochs, filename):\n    model.to(device)\n\n    history ={'train_loss' : [],\n             'train_acc' : [],\n              'val_loss' : [],\n              'val_acc' : []\n             }\n    \n    for epoch in range(num_epochs):\n        for i, phase in enumerate(['train','val']):\n            if phase=='train':\n                model.train()\n            else:\n                model.eval()\n                \n            correct = 0\n            epoch_loss = 0\n            epoch_acc = 0 \n\n            for data in dataloaders_dict[phase]:\n                x_data = data['data'].to(device)\n                y_data = data['target'].to(device)\n\n                optimizer.zero_grad()\n\n                predict = model(x_data)\n                target = y_data\n                loss = loss_fn(predict, target)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                epoch_loss += loss.item() * len(x_data)\n                correct += (target==predict.argmax(axis=1)).sum()\n                    \n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = 100 * (correct \/ len(dataloaders_dict[phase].dataset))\n            print(\"{} : [{} \/ {}] Loss : {:.4f}  | Accuracy : {:.2f}%\".format(phase.upper(), epoch+1, num_epochs, epoch_loss, epoch_acc))\n            \n            history['{}_loss'.format(phase)].append(epoch_loss)\n            history['{}_acc'.format(phase)].append(epoch_acc)\n            \n        torch.save(model.state_dict(), filename)\n        print(\" \")\n    return history","01c707b1":"USE_CUDA = torch.cuda.is_available()\nprint(USE_CUDA)\ndevice = torch.device('cuda:0' if USE_CUDA else 'cpu')\nprint('A device that proceeds with : ',device)","96a6535e":"loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(cnn_model.parameters(), lr=0.01)","6897c49c":"NUM_EPOCHS = 30\nSAVE_MODEL_PATH = f'cnn.pth'\n\nhistory = train_model(\n    cnn_model,\n    dataloaders_dict,\n    loss_fn, \n    optimizer,\n    NUM_EPOCHS,\n    SAVE_MODEL_PATH\n    )","14351342":"fig, axes = plt.subplots(1,2, figsize=(18,8))\naxes[0].plot(history['train_loss'],label='train_loss')\naxes[0].plot(history['val_loss'], label='val_loss')\naxes[0].set_xticks(np.arange(0,NUM_EPOCHS,5))\naxes[0].legend()\n\n\naxes[1].plot(history['train_acc'], label='train_acc')\naxes[1].plot(history['val_acc'], label='val_acc')\naxes[1].set_xticks(np.arange(0,NUM_EPOCHS,5))\naxes[1].legend()\n\nplt.show()","038b2344":"# Clear cache\nimport gc\ngc.collect()\n\ntorch.cuda.empty_cache()","7015a86a":"resnet_model = ResNet_mini(INPUT_DIM, OUTPUT)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet_model.parameters(), lr=0.0001)","ac40bd8d":"NUM_EPOCHS = 15\nSAVE_MODEL_PATH = f'resnet.pth'\n\nhistory = train_model(\n    resnet_model,\n    dataloaders_dict,\n    loss_fn, \n    optimizer,\n    NUM_EPOCHS,\n    SAVE_MODEL_PATH\n    )","79431fcd":"fig, axes = plt.subplots(1,2, figsize=(18,8))\naxes[0].plot(history['train_loss'],label='train_loss')\naxes[0].plot(history['val_loss'], label='val_loss')\naxes[0].set_xticks(np.arange(0,NUM_EPOCHS))\naxes[0].legend()\n\n\naxes[1].plot(history['train_acc'], label='train_acc')\naxes[1].plot(history['val_acc'], label='val_acc')\naxes[1].set_xticks(np.arange(0,NUM_EPOCHS))\naxes[1].legend()\n\nplt.show()","b0f01c37":"# Clear cache\nimport gc\ngc.collect()\n\ntorch.cuda.empty_cache()","e5c85acf":"densenet_model = DenseNet_mini(INPUT_DIM, OUTPUT)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(densenet_model.parameters(), lr=0.0001)","f6eaa9b1":"NUM_EPOCHS = 20\nSAVE_MODEL_PATH = f'densenet.pth'\n\nhistory = train_model(\n    densenet_model,\n    dataloaders_dict,\n    loss_fn, \n    optimizer,\n    NUM_EPOCHS,\n    SAVE_MODEL_PATH\n    )","e7fd1580":"fig, axes = plt.subplots(1,2, figsize=(18,8))\naxes[0].plot(history['train_loss'],label='train_loss')\naxes[0].plot(history['val_loss'], label='val_loss')\naxes[0].set_xticks(np.arange(0,NUM_EPOCHS,5))\naxes[0].legend()\n\n\naxes[1].plot(history['train_acc'], label='train_acc')\naxes[1].plot(history['val_acc'], label='val_acc')\naxes[1].set_xticks(np.arange(0,NUM_EPOCHS,5))\naxes[1].legend()\n\nplt.show()","56de1cb7":"def evalueate_model(model, test_loader):\n    predictions = []\n\n    #model = BasicCNN()\n    #model.to(device)\n    #model.load_state_dict(torch.load(f'cnn.pth'))\n    \n    model.eval()\n\n    for data in test_loader:\n        x_data = data['data'].to(device)\n        \n        with torch.no_grad():\n            predicts = model(x_data)\n            predicts = predicts.argmax(axis=1)\n            predicts = predicts.cpu().numpy()\n            \n            # Put the batch size data into the list one by one.\n            for pred in predicts:\n                predictions.append(pred)\n        \n    return(predictions)","0cbf92c0":"test_df.head()","a4510780":"test_dataset = BasicDataset(test_df.values, y_data=None, is_labeled=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle = False)","d531a21c":"cnn_pred = evalueate_model(cnn_model, test_loader)\nresnet_pred = evalueate_model(resnet_model, test_loader)\ndensenet_pred = evalueate_model(densenet_model, test_loader)","e61d20cf":"cnn_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\ncnn_submission['Label'] = cnn_pred\n\nresnet_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nresnet_submission['Label'] = resnet_pred\n\n\ndensenet_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\ndensenet_submission['Label'] = densenet_pred\ncnn_submission.head()","5222b6d3":"fig, axes = plt.subplots(1,5, figsize=(20,5))\n\nfor i in range(5):\n    axes[i].imshow(test_df.iloc[i].values.reshape(28,28), 'gray')\n    axes[i].axis('off')\n    axes[i].set_title(\"CNN Predict Label :\" + str(cnn_pred[i]))\nplt.show()","6ff56939":"fig, axes = plt.subplots(1,5, figsize=(20,5))\n\nfor i in range(5):\n    axes[i].imshow(test_df.iloc[i].values.reshape(28,28), 'gray')\n    axes[i].axis('off')\n    axes[i].set_title(\"RESNET Predict Label :\" + str(resnet_pred[i]))\nplt.show()","81abd532":"fig, axes = plt.subplots(1,5, figsize=(20,5))\n\nfor i in range(5):\n    axes[i].imshow(test_df.iloc[i].values.reshape(28,28), 'gray')\n    axes[i].axis('off')\n    axes[i].set_title(\"DENSENET Predict Label :\" + str(densenet_pred[i]))\nplt.show()","ff5c2e54":"cnn_submission.to_csv('cnn_submission.csv', index=False)\nresnet_submission.to_csv('resnet_submission.csv', index=False)\ndensenet_submission.to_csv('densenet_submission.csv', index=False)","ca0c8693":"### 5-5) Evaluating","ede95cfb":"# 4. Feature Enginnering\n* Split Train set \/ Validation set\n* Convert to data suitable for CNN model (Dataset \/ Dataloader)","9281fd49":"### 5-2) ResNet Modeling","d71198f3":"* CNN Model","5dc2314b":"# 3. Exploratory Data Analysis(EDA) with Visualization [Before Preprocessing]\n* Plot the null values\n* Plot the label Percent\n* Plot the image Data","72ffb87e":"# 1. Import & Install libray\n* Import Basic libray\n* Import Enginnering libray","54f26711":"# 2. Check out my data\n* Check Shape \/ Info \/ Describe","0d22e245":"![68222222101258.jpg](attachment:033ef31e-d3ff-4c86-9408-39d539b36845.jpg)\n# Digit Recognizer\n\n## Overview\nThis competition uses the most basic mnist data in deep learning. We need to create a model to classify the numbers in the image. <br\/>\nYou can use other techniques instead of deep learning. However, this notebook will be written based on deep learning. <br\/>\nIn addition, we will use \"Pytorch\" among the frameworks that enable deep learning.\n\n#### My opinion :\n* 1) I think it is important to use various techniques and get used to deep learning through this competition.\n* 2) This book will model **Basic CNN \/ ResNet \/ DenseNet** :)","a64b36a1":"* Mini DenseNet Model","86dbd839":"# 5.Modeling\n* CNN Modeling\n* ResNet Modeling\n* DenseNet Modeling\n* Training\n* Evaluating","a9313336":"# 6. Submission\n* Submit the predictions.","89648901":"### 3-3) * Plot the image Data","463ddbd2":"##### reference \n* https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers\n\n###  If this notebook is useful for your kaggling, \"UPVOTE\" for it \ud83d\udc40\n#### THX to Reading My Notebook\ud83c\udf08","da8f1f61":"### 4-2) Convert to data suitable for CNN model (Dataset \/ Dataloader)","5729cb56":"### 5-3) DenseNet Modeling","260202db":"### 3-2) Plot the label Percent","8c8f0284":"### 5-1) CNN Modeling","ad46bba0":"***\n## My Workflow\n\n#### 1. Import & Install libray\n* Import Basic libray\n* Import Enginnering libray\n\n#### 2. Check out my data\n* Check Shape \/ Info \/ Describe\n\n#### 3. Exploratory Data Analysis(EDA) with Visualization [Before Preprocessing]\n* Plot the null values\n* Plot the label Percent\n* Plot the image Data\n\n#### 4. Feature Enginnering\n* Split Train set \/ Validation set\n* Convert to data suitable for CNN model (Dataset \/ Dataloader)\n\n#### 5.Modeling\n* CNN Modeling\n* ResNet Modeling\n* DenseNet Modeling\n* Training\n* Evaluating\n\n#### 6. Submission\n* Submit the predictions.\n<br\/><br\/>\n***","02528375":"### 3-1) Plot the null values","b1d5fe15":"* Mini ResNet Model","96b620d7":"### 5-4) Training","eff3dea7":"### 4-1) Split Train set \/ Validation set"}}