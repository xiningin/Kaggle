{"cell_type":{"d96a0605":"code","b3ec02c3":"code","464362dd":"code","e2b9fdb8":"code","b187842f":"code","319a3f38":"code","e603677f":"code","a641d6f5":"code","25ff7726":"code","84b6c2a4":"code","093058f6":"code","c0a8383a":"code","c12ff916":"code","55467ec5":"code","182821c0":"code","3bd35fde":"code","72d44ca9":"code","5921fec8":"code","a0adde19":"code","ae6de28a":"code","e81733df":"code","a03ae06d":"code","5a1591e0":"code","35bd2078":"code","17de571e":"code","f05f68e9":"code","b2dfdce4":"code","f0d7f4b7":"code","642191b3":"code","ba20128f":"code","ee2a7275":"code","11992ef2":"code","a36b697e":"code","0de0cc7a":"code","d0da809d":"code","b7464ad8":"code","6c0fb1a6":"code","568d3e99":"code","eb3e2aea":"code","823653ac":"code","bd84d7b5":"code","a40e3626":"markdown","bd4db3ed":"markdown","3d6b3d4e":"markdown","b08355fc":"markdown","091cf4fc":"markdown","cf577b6b":"markdown","b31cc4a7":"markdown","573d6350":"markdown","e80414a9":"markdown","4565d086":"markdown","46fa97f1":"markdown","aa1fb324":"markdown","75b2ef0e":"markdown","f9127632":"markdown","21738fa9":"markdown","f73f6bb3":"markdown","b0b94172":"markdown","e1cd7066":"markdown","18b22942":"markdown","2652774e":"markdown","33c69885":"markdown","843db61d":"markdown","2c674931":"markdown","2ea5d483":"markdown","1382b783":"markdown","1e0c9497":"markdown","2536ad22":"markdown","dbf8c8b2":"markdown","ee477264":"markdown","6de18110":"markdown","2f1591be":"markdown","9aa9de39":"markdown","164398dc":"markdown","7778006d":"markdown","c6f174f3":"markdown","8fbd2057":"markdown","dd3e449d":"markdown","a7f191bd":"markdown","df1ffce5":"markdown","8a2156d0":"markdown","61a092d2":"markdown","83befff1":"markdown","1a1a5942":"markdown","c8044653":"markdown","5b7fdaf1":"markdown","c629b94e":"markdown","231155dc":"markdown"},"source":{"d96a0605":"#importing useful libararies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sea\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score","b3ec02c3":"#read the Sales Records excel file\ndf = pd.read_csv(r'..\/input\/income-classification\/income_evaluation.csv')","464362dd":"df.head(5)","e2b9fdb8":"df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']","b187842f":"df.isna().sum()","319a3f38":"df.dtypes","e603677f":"num = [i for i in df.columns if df[i].dtype!='O']\ncat = [i for i in df.columns if df[i].dtype=='O']","a641d6f5":"df[cat].nunique().plot(kind='bar')","25ff7726":"for i in df[cat]:\n    print(df[i].value_counts())","84b6c2a4":"df.replace(' ?', np.nan, inplace= True)","093058f6":"df.isna().sum()","c0a8383a":"df.fillna(method = 'bfill', inplace=True)","c12ff916":"df.isna().sum().sum()","55467ec5":"df.income.value_counts()","182821c0":"sea.countplot(x= 'income' ,data =df)","3bd35fde":"df.income.value_counts().plot(kind='pie')","72d44ca9":"sea.countplot(x=\"income\", hue=\"sex\", data=df)","5921fec8":"plt.subplots(figsize=(12, 8))\nsea.countplot(x=\"income\", hue=\"workclass\", data=df)","a0adde19":"plt.subplots(figsize=(12, 8))\nsea.countplot(hue=\"sex\", x=\"workclass\", data=df)","ae6de28a":"for i in cat:\n    \n    print(i, ' contains ', len(df[i].unique()), ' labels')","e81733df":"y = df.income","a03ae06d":"y = pd.get_dummies(y,drop_first=True)\ndf.drop(['income'],axis =1, inplace=True)","5a1591e0":"x = pd.get_dummies(df[cat])","35bd2078":"df.drop(df[cat],axis = 1,inplace = True)","17de571e":"df[num].head()","f05f68e9":"sea.distplot(df.age, bins=10)","b2dfdce4":"sea.boxplot(df.age)","f0d7f4b7":"df.corr()","642191b3":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ndf = scaler.fit_transform(df)","ba20128f":"df = pd.DataFrame(df)\nx = pd.concat([x,df],axis=1)","ee2a7275":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","11992ef2":"X_train.head(2)","a36b697e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","0de0cc7a":"y_pred = logreg.predict(X_test)\naccuracy_score(y_test, y_pred)","d0da809d":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=10)\nrfc.fit(X_train, y_train)","b7464ad8":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","6c0fb1a6":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=100)\nrfc.fit(X_train, y_train)","568d3e99":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","eb3e2aea":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nmodel = BaggingClassifier(random_state=0)\nmodel.fit(X_train, y_train)","823653ac":"y_pred = model.predict(X_test)\naccuracy_score(y_test, y_pred)","bd84d7b5":"import xgboost as xgb\nmodel=xgb.XGBClassifier(base_estimator = rfc,random_state=1,learning_rate=0.1)\nmodel.fit(X_train, y_train)\nmodel.score(X_test,y_test)","a40e3626":"### plotting the workclass w.r.t gender.","bd4db3ed":"**Observation**\n- there is no correlation beween the variables.","3d6b3d4e":"**Observation**\n- There are more people who employed with private sector, in both categories of income. ","b08355fc":"### Our target variable income, lets visualize it, with repect to others variables","091cf4fc":"#### Remove the target variable income ","cf577b6b":"**Observation**\n- In workclass the highest number of people doing work in private. And in all workclass males are highest. ","b31cc4a7":"# EDA on Numerical Variables","573d6350":"**Observation**\n- most number of people are belong to 20 to 50 age group.","e80414a9":"###  Testing the logistic model by predicting the test data and calculate the accuracy score ","4565d086":"### Fitting the Random forest Model with only 100 decision trees","46fa97f1":"**Summary**\n- This income prediction classification problem, the logistic regerssion achieved 85.13%.\n- The simple baggging with no base model gives accuracy 84.39%\n- Ensemble learning bagging technique with base model Random forest with 10 decision tress, gives accuracy is 84.95%\n- Ensemble learning bagging technique with base model Random Forest with 100 decision trees, gives accuracy is 85.40%\n- In Ensemble learning Boosting technique with base model random forest, gives accuracy 86.94%","aa1fb324":"### Checking the outliers in Numerical variables.","75b2ef0e":"### EDA on Categorical variables","f9127632":"#### Checking the data Types of the variables","21738fa9":"**Observation**\n- There are more than 75% number of people making less than 50k.","f73f6bb3":"### Income distribution w.r.t workclass","b0b94172":"Now, there is no null or invalid values left in our data","e1cd7066":"### Seperating categorical and numerical variables apart","18b22942":"### Testing the bagging model and calculate accuracy","2652774e":"### Splitting the data into test and train","33c69885":"## Fitting the Extream gradient boosting method with keeping hyperparamerter(learning rate is 0.1 ) then calculate accuracy.","843db61d":"### Correcting the columns names","2c674931":"### Testing the random forest model by predicting the test data and calculate the accuracy score with100 decision tress. ","2ea5d483":"**Obseravation**\n\n -There are some outliers present in Age variables.","1382b783":"### Fitting the Logistic Regression model","1e0c9497":"There are no missing values","2536ad22":"### lets encode the categorical varibles with one hot encoding","dbf8c8b2":"Lets have a look to our data","ee477264":"**Observation**\n- Only two categories in income variable","6de18110":"## Bagging method of ensemble learning ","2f1591be":"### ****Replacing all invalid values to NaN values, so we can easily fill that****","9aa9de39":"### See the income distribution with respect to gender","164398dc":"**Observation**\n- There are some '?' values instead of null values are present in some variables. we need to remove these values.\n- You can see all different classes of categorical variables with their share or get the count of distribution of values.","7778006d":"**Observation**\n- people who are earning less than 50K are high in numbers also Male are high in numbers","c6f174f3":"### Scalling the Numerical varibales ","8fbd2057":"### Checking the correlation between numerical variables.","dd3e449d":"**This Data Set Name is Income Classification**\n**Shape of the data set (32561,15)**\n**NuLL values:** Not Present\n\n**Variables:** 'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income'.\n\nThere are **9 categorical variables** and **6 Numerical variables.** \n\n**Income is the Target Variable**\n\n\nBy using this dataset, I try to make prediction whether the person is making over 50K or less than 50K. \nI have implemeted the Random Forest Classification with python. Also, I have also using ensemble learnig to increase the accuracy of our Model.\n","a7f191bd":"### Checking missing values","df1ffce5":"### Fitting the Random forest Model with only 10 decision trees ","8a2156d0":"##### here you can see the counts of null values in the variables. \n\n### Now using fillna() function we need to replace the the null the previous column value ","61a092d2":"##### Accuracy increase by 0.1 by increasing the number of decision tress.","83befff1":"See we can easily get the count of NaN values","1a1a5942":"#### view the Distribution of Age variable","c8044653":"### Testing the random forest model by predicting the test data and calculate the accuracy score ","5b7fdaf1":"Checking the different categories in each categorical variables","c629b94e":"** Observation**\n- This graph sows no of different categories in the categorical variables","231155dc":"### visualize trainig data"}}