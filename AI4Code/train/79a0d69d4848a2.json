{"cell_type":{"a44d5b4d":"code","d301b5bd":"code","2aefe084":"code","b614bff0":"code","647812c6":"code","96d659dc":"code","a0600929":"code","92c97160":"code","358e01b9":"code","a7982b1f":"code","66fd4c73":"code","1d5efe21":"code","40d96373":"code","30798a3a":"markdown","b92bf12e":"markdown","8d21edaf":"markdown","8cb4c7a9":"markdown","e3406154":"markdown","a3bcd1a4":"markdown","89fcb348":"markdown","e0ea82c0":"markdown","ea915558":"markdown","76fffa06":"markdown","e84b03ad":"markdown","fdb2ebb8":"markdown"},"source":{"a44d5b4d":"# file operations\nimport os\n# to list files\nimport glob\n\n# for numerical analysis\nimport numpy as np \n# to store and process in a dataframe\nimport pandas as pd \n\n# for ploting graphs\nimport matplotlib.pyplot as plt\n# advancec ploting\nimport seaborn as sns\n\n# image processing\nimport matplotlib.image as mpimg\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n# model performance metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# utility functions\nfrom tensorflow.keras.utils import to_categorical, plot_model\n# process image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n# sequential model\nfrom tensorflow.keras.models import Sequential\n# layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n# callback functions\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler","d301b5bd":"# list of files in the dataset\nos.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images')","2aefe084":"# list all the images in the directory Parasitized\nparasitized = glob.glob('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/*.png')\n\n# no. of files in the directory Parasitized\nprint('No. of files in the directory Parasitized', len(parasitized))\n\n# first few images\nparasitized[:5]","b614bff0":"# list all the images in the directory Uninfected\nuninfected = glob.glob('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/*.png')\n\n# no. of files in the directory Uninfected\nprint('No. of files in the directory Uninfected', len(uninfected))\n\n# first few images\nuninfected[:5]","647812c6":"fig, ax = plt.subplots(figsize=(18, 8))\nfig.suptitle('Parasitized cells', fontsize=24)\n\nfor ind, img_src in enumerate(parasitized[:30]):\n    plt.subplot(3, 10, ind+1)\n    img = plt.imread(img_src)\n    plt.axis('off')\n    plt.imshow(img)","96d659dc":"fig, ax = plt.subplots(figsize=(18, 8))\nfig.suptitle('Uninfected cells', fontsize=24)\n\nfor ind, img_src in enumerate(uninfected[:30]):\n    plt.subplot(3, 10, ind+1)\n    img = plt.imread(img_src)\n    plt.axis('off')\n    plt.imshow(img)","a0600929":"BATCH_SIZE = 100  # Number of training examples to process before updating our models variables\nIMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\nTARGET_SIZE = 64\nEPOCHS = 10","92c97160":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Flatten())\n\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","358e01b9":"plt.figure(figsize=(5, 10))\nplot_model(model, to_file=\"model.png\")","a7982b1f":"datagen = ImageDataGenerator(rescale=1.\/255,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             validation_split=0.3)\n\ntrain_data = datagen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                         target_size=(IMG_SHAPE,IMG_SHAPE),\n                                         batch_size=BATCH_SIZE,\n                                         shuffle=True,\n                                         class_mode='binary',\n                                         subset='training')\n\nvalidation_data = datagen.flow_from_directory('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images',\n                                              target_size=(IMG_SHAPE,IMG_SHAPE),\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True,\n                                              class_mode='binary',\n                                              subset='validation')","66fd4c73":"# Instantiate an early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', \n                               min_delta = 0.01,\n                               patience=5)\n\n# Instantiate a model checkpoint callback\nmodel_save = ModelCheckpoint('best_model.hdf5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True)","1d5efe21":"history = model.fit(train_data,\n                    validation_data=validation_data,\n                    epochs=EPOCHS,\n                    verbose=1, \n                    callbacks=[early_stopping, model_save])","40d96373":"plt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.show()","30798a3a":"# Model","b92bf12e":"### List files","8d21edaf":"### Callback functions","8cb4c7a9":"### Model parameters","e3406154":"# Data","a3bcd1a4":"# Libraries","89fcb348":"### Data generator","e0ea82c0":"### Plot metrics","ea915558":"# Images","76fffa06":"## About the Dataset\n\n> The dataset contains 2 folders\n  \n> * Infected\n> * Uninfected  \n  \n> And a total of 27,558 images.\n\n## Task\n> To come up with a model that can predict label for each image","e84b03ad":"### Model initialization","fdb2ebb8":"### Fit model"}}