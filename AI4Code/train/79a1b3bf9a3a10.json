{"cell_type":{"32b7ff5f":"code","98bdf8c4":"code","d5f0c5de":"code","19c67eb1":"code","94a38671":"code","32bdb224":"code","4c9b7d5f":"code","9a1118e4":"code","0cbe7b41":"code","73c6d5ca":"code","bdf10bbb":"code","1be26e16":"markdown","9c264060":"markdown","de908d90":"markdown","afc96611":"markdown","0a3e060e":"markdown","dfd540f1":"markdown","fec49963":"markdown","7e295ca4":"markdown","58d0e6b2":"markdown","322edae9":"markdown","f0961c28":"markdown","7932d464":"markdown","ca1b3619":"markdown"},"source":{"32b7ff5f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","98bdf8c4":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPool2D","d5f0c5de":"model = Sequential()\n\nmodel.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(32,kernel_size=3,activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","19c67eb1":"model.load_weights('\/kaggle\/input\/kannada-mnist-model-weights\/BWeight.md5')","94a38671":"data = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')","32bdb224":"X = data.drop(['id'],axis=1)","4c9b7d5f":"X = X.values.reshape(X.shape[0],28,28,1)","9a1118e4":"layer_outputs = [layer.output for layer in model.layers]\n# Storing layers of model in a list\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\n# A simple model that takes its input as input of previously trained model and produces output based on provided \n# list of layers","0cbe7b41":"activations = activation_model.predict(X[0:10])","73c6d5ca":"plt.matshow(activations[0][9, :, :, 10], cmap='viridis')","bdf10bbb":"layer_names = []\nfor layer in model.layers[:6]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 16\n\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features \/\/ images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1 \/ size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto')","1be26e16":"# Visualization","9c264060":"Link to original notebook with model and full prediction process - [Kannada MNIST](https:\/\/www.kaggle.com\/rohan9889\/kannada-mnist-cnn-keras)","de908d90":"Loading the weights on which the model was previously trained (.984 accuracy)","afc96611":"# Weight Loading","0a3e060e":"The visualization code use is taken from [Link to repository](https:\/\/github.com\/gabrielpierobon\/cnnshapes\/blob\/master\/README.md)","dfd540f1":"Making model from same architecture as previous notebook","fec49963":"**It is clear that as we move to higher layers low level information is being filtered and only high level info remains**","7e295ca4":"Using the imported data to predict the activations of all present layers","58d0e6b2":"**In this kernel intermediate layers of model trained for kannada MNIST challenge will be visualized to understand inner workings of the CNN**","322edae9":"Visualzing for all activations","f0961c28":"Visualizing 10th channel of first activation","7932d464":"**Low layers are looking for edges and other suck info but as we move forward in the layers it becomes clear that these features are not important for high level features, high level features only look for semantics of the image**","ca1b3619":"# Model"}}