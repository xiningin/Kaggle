{"cell_type":{"74e0c4c5":"code","dca51754":"code","2d6044fc":"code","fe0f329f":"code","38062bc8":"code","ab5e8be7":"code","553e4792":"code","36d77892":"code","057ba4e9":"code","b8d02159":"code","cf700513":"code","77de0444":"code","15794ba1":"code","c15a3c12":"code","113ca8fe":"code","407908d0":"code","013b7b46":"code","de759789":"code","d9904303":"code","10e60e97":"code","f5f21ee9":"code","bfa4111c":"code","74d2a10e":"markdown","620be5e6":"markdown","91ecbcbd":"markdown","26920595":"markdown","2b9606d5":"markdown","b6c850c4":"markdown","5dff6f8e":"markdown","9c549ece":"markdown","6d0f94a1":"markdown","8ed4425c":"markdown","6f93734c":"markdown","fe14057b":"markdown","5bc771d0":"markdown","0c7a9217":"markdown","69cc1049":"markdown","d949af99":"markdown","57cd22dd":"markdown","7ebff45a":"markdown","23cfbd3d":"markdown"},"source":{"74e0c4c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import scale\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dca51754":"# Import CSV File\ndf = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\", sep = \",\")\n# Show dataframe, first 5 rows\nprint(df.head(5))\n# All columns are numerical\nprint(df.info())\n# Shape of data, 303 rows and 14 columns\nprint(df.shape)","2d6044fc":"# 1. function for identifying missing values\nprint(df.isnull().sum())\n\n# 2. function for identifying missing values\ndf.info()","fe0f329f":"X = df.drop(\"target\", axis=1).values\ny = df[\"target\"].values\nfeature_names = df.drop(\"target\", axis=1).columns","38062bc8":"df[(df[\"cp\"] != 0) & (df[\"target\"] == 1)].count()","ab5e8be7":"print(df.describe())","553e4792":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,cmap=\"magma\",fmt='.2f') # look for other color theme","36d77892":"\nsns_dataframe = df.copy()[[\"sex\",\"target\",\"cp\",\"age\"]]\n\ndef diagnosis(infected):\n    if infected == 1:\n        return \"Heart Disease\"\n    else:\n        return \"No Heart Disease\"\nsns_dataframe['target'] = sns_dataframe['target'].apply(diagnosis)\n\ndef gender(sex):\n    if sex == 0:\n        return \"female\"\n    else:\n        return \"male\"\nsns_dataframe[\"sex\"] = sns_dataframe[\"sex\"].apply(gender)\n\nsns.countplot(data= sns_dataframe, x=\"sex\",hue=\"target\", palette=[\"#c1121f\", \"#60d394\"])\nplt.title(\"Deseased per Sex v\/s target\\n\")\n","057ba4e9":"sns.countplot(data= sns_dataframe, x='cp',hue='target', palette=[\"#c1121f\", \"#60d394\"])\nplt.xticks([0,1,2,3],[\"asymptomatic\", \"atypical angina\", \"non-anginal pain\", \"typical angina\"])\nplt.title('Chest Pain Type v\/s target\\n')","b8d02159":"plt.hist(df[df[\"target\"] == 1][\"age\"], density = True, bins = 15)","cf700513":"df[df[\"target\"] == 1][\"age\"].value_counts().sort_values().plot.barh()","77de0444":"plt.figure(figsize=(20,7))\nsns.set()\nsns.countplot(x = df.age);","15794ba1":"plt.figure(figsize=(20,7))\nplt.hist(x = df[df.sex==1][\"age\"], bins=30, color = \"#60d394\")\nplt.hist(x = df[df.sex==0][\"age\"], bins=30, color = \"#c1121f\")\nplt.title(\"Heart disease per age and sex\", fontsize=20)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count of Diseased\")\nplt.xticks([20,25,30,35,40,45,50,55,60,65,70,75])\nplt.legend([\"Male\", \"Female\"])\n#help(plt.hist)","c15a3c12":"from yellowbrick.model_selection import FeatureImportances\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=19, random_state=42)\nviz = FeatureImportances(model, labels = column_names)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nviz.fit(X_test, y_test)\nviz.show()","113ca8fe":"# How many results do we get for chest pain type 0 and target 0?\nprint(\"Values for chest pain type 0 and target 0:\", len(df[(df[\"cp\"] == 0) & (df[\"target\"] == 0)]))\n\n# How many results do we get for chest pain type 0 and target 1?\nprint(\"Values for chest pain type 0 and target 1:\", len(df[(df[\"cp\"] == 0) & (df[\"target\"] == 1)]))\n\n# How many results do we get for chest pain type 1 and target 0?\nprint(\"Values for chest pain type 1 and target 0:\", len(df[(df[\"cp\"] == 1) & (df[\"target\"] == 0)]))\n\n# How many results do we get for chest pain type 1 and target 1?\nprint(\"Values for chest pain type 1 and target 1:\", len(df[(df[\"cp\"] == 1) & (df[\"target\"] == 1)]))\n\n# How many results do we get for chest pain type 2 and target 0?\nprint(\"Values for chest pain type 2 and target 0:\", len(df[(df[\"cp\"] == 2) & (df[\"target\"] == 0)]))\n\n# How many results do we get for chest pain type 2 and target 1?\nprint(\"Values for chest pain type 2 and target 1:\", len(df[(df[\"cp\"] == 2) & (df[\"target\"] == 1)]))\n\n# How many results do we get for chest pain type 3 and target 0?\nprint(\"Values for chest pain type 3 and target 0:\", len(df[(df[\"cp\"] == 3) & (df[\"target\"] == 0)]))\n\n# How many results do we get for chest pain type 3 and target 1?\nprint(\"Values for chest pain type 3 and target 1:\", len(df[(df[\"cp\"] == 3) & (df[\"target\"] == 1)]))","407908d0":"# Results\nresults = {}","013b7b46":"pipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"knn\", KNeighborsClassifier())\n])\n\nparameters = {\"knn__n_neighbors\": np.arange(1,50)}\ncv = GridSearchCV(pipeline, parameters, cv = 5, scoring = \"f1_weighted\")\ncv.fit(X, y)\ny_pred = cv.predict(X)\n\nbest_n_neighbors = cv.best_params_[\"knn__n_neighbors\"]\n# Save model results in dictionary\nresults[\"KNeighborsClassifier\"] = {\n    \"Accuracy\" : cv.score(X, y),\n    \"F1-Score\" : cv.cv_results_[\"mean_test_score\"][best_n_neighbors - 1]\n}\nprint(\"Best value for n_neighbors\", best_n_neighbors)\nprint(\"Classification Report: \\n\", classification_report(y, y_pred))\nprint(pd.DataFrame(results))\n\n\nConfusionMatrixDisplay(confusion_matrix(y,y_pred), display_labels = [\"Not diseased\", \"Diseased\"]).plot()\n","de759789":"pipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"logreg\", LogisticRegression(random_state=0))\n])\n\nparameters = {}\ncv = GridSearchCV(pipeline, parameters, cv = 5, scoring = \"f1_weighted\")\ncv.fit(X, y)\nprint(\"Classification Report: \\n\", classification_report(y, cv.predict(X)))\n\n# Save model results in dictionary\nresults[\"LogisticRegression\"] = {\n    \"Accuracy\" : cv.score(X, y),\n    \"F1-Score\" : cv.cv_results_[\"mean_test_score\"][0]\n}\n\nprint(pd.DataFrame(results))\nConfusionMatrixDisplay(confusion_matrix(y,y_pred), display_labels = [\"Not diseased\", \"Diseased\"]).plot()","d9904303":"# Tune hyperparameter max_depth\ncv = GridSearchCV(\n    Pipeline(\n        steps = [\n        (\"clf\", DecisionTreeClassifier(random_state=42))]\n    ), \n    {\"clf__max_depth\": np.arange(1,50)}, \n    cv = 5, \n    scoring = \"f1_weighted\"\n)\ncv.fit(X, y)\ny_pred = cv.predict(X)\nbest_max_depth = cv.best_params_[\"clf__max_depth\"]\nprint(\"Best max_depth value:\", best_max_depth)\nprint(\"Classification Report: \\n\", classification_report(y, y_pred))\n\n# Save model results in dictionary\nresults[\"DecisionTreeClassifier\"] = {\n    \"Accuracy\" : cv.score(X, y),\n    \"F1-Score\" : cv.cv_results_[\"mean_test_score\"][best_max_depth - 1]\n}\nprint(pd.DataFrame(results))\nConfusionMatrixDisplay(confusion_matrix(y,y_pred), display_labels = [\"Not diseased\", \"Diseased\"]).plot()","10e60e97":"clf = DecisionTreeClassifier(max_depth = best_max_depth)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=40)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nscore = clf.score(X_test, y_test)\ncv_scores = cross_val_score(clf, X, y, cv = 5, scoring = \"roc_auc\")\nprint(\"Average:\", np.mean(cv_scores), \"Scores: \", cv_scores)\n\n# Plot Tree\nplt.figure(figsize=(20,7))\nplot_tree(clf, filled = True, feature_names = list(feature_names), class_names = [\"Diseased\", \"Healthy\"])\nplt.show()","f5f21ee9":"# Tune hyperparameter max_depth\ncv = GridSearchCV(\n    Pipeline(\n        steps = [\n        (\"clf\", RandomForestClassifier(random_state=42))]\n    ), \n    {\"clf__n_estimators\": np.arange(1,50)}, \n    cv = 5, \n    scoring = \"f1_weighted\"\n)\ncv.fit(X, y)\ny_pred = cv.predict(X)\nbest_n_estimators = cv.best_params_[\"clf__n_estimators\"]\nprint(\"Best n_estimators value:\", best_n_estimators)\nprint(\"Classification Report: \\n\", classification_report(y, y_pred))\n\n# Save model results in dictionary\nresults[\"RandomForestClassifier\"] = {\n    \"Accuracy\" : cv.score(X, y),\n    \"F1-Score\" : cv.cv_results_[\"mean_test_score\"][best_n_estimators - 1]\n}\nprint(pd.DataFrame(results))\n","bfa4111c":"print(pd.DataFrame(results))","74d2a10e":"### Use the best parameter in the model","620be5e6":"## 3.3 DecisionTreeClassifier","91ecbcbd":"# 2.0 Data Preparation\nChest Pain (cp) is the most important predictor of heart disease","26920595":"# Important data characteristics","2b9606d5":"## 2.3 Results\nPatients with chest pain show a higher tendendency for the target variable 1. As chest pain is also an indicator for heart disease, one can be assume that 1 equals heart diseased.","b6c850c4":"## 1.4 Heatmap","5dff6f8e":"## 1.3 Descriptive Statistics\nDescriptive statistics can reveil instristing instights of the dataset","9c549ece":"## 1.2 Assign Variables","6d0f94a1":"# Notes\nmore description","8ed4425c":"# Marketing Analytics\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to\nthis date. The \"goal\" field refers to the presence of heart disease in the patient.\n\n## Variables\nAs critical information was not provided on the data set, external sources were used for explanation for variables:\nSource: https:\/\/towardsdatascience.com\/heart-disease-uci-diagnosis-prediction-b1943ee835a7\n\nage = age in years\n\nsex = (1 = male; 0 = female)\n\ncp = chest pain type\n\u2014 Value 0: asymptomatic\n\u2014 Value 1: atypical angina\n\u2014 Value 2: non-anginal pain\n\u2014 Value 3: typical angina\n\ntrestbps = resting blood pressure (in mm Hg on admission to the hospital)\n\nchol = serum cholestoral in mg\/dl\n\nfbs = fasting blood sugar > 120 mg\/dl\n\nrestecg = resting electrocardiographic results (values 0,1,2)\n\nthalach = maximum heart rate achieved\n\nexang = exercise induced angina\n\noldpeak = ST depression induced by exercise relative to rest\n\nslope = the slope of the peak exercise ST segment\n\nca = number of major vessels (0-3) colored by flourosopy\n\nthal = thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n\ntarget = (0 = no heart disease), (1 = heart disease)","6f93734c":"## 3.1 KNeighborsClassifier","fe14057b":"# 3.0 Model building\nThe results will be stored in the variable results.","5bc771d0":"## 1.6 Heart diseased with respect to different chest pain types","0c7a9217":"# 4.0 Model Evaluation","69cc1049":"# 1. Exploratory Data Analysis","d949af99":"## 1.1 Check for Missing Values\nEvery dataset needs to be checked for empty variables. If empty variables exists, they should be replaced by averages or in the worst cased dropped.\nEmpty variables can be identified by the following two function:","57cd22dd":"## 3.2 LogisticRegression","7ebff45a":"## 2.2 Assessment of our target variable by chest type","23cfbd3d":"## 1.5 Gender characteristics"}}