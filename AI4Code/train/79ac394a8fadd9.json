{"cell_type":{"f964926d":"code","8aac1e52":"code","2d1f297b":"code","c3dbf6de":"code","ff5c3160":"code","da5daa14":"code","8f5dcb24":"code","9a5bceb4":"code","d4cad7a8":"code","9c920c9e":"code","893cf463":"code","2257117c":"code","4bfe80b3":"code","30b307b8":"code","03767af5":"code","ccd89c68":"code","df855380":"code","5a05838b":"code","4ee5cd30":"code","32dfdf84":"markdown","d8935cb3":"markdown","40c4525e":"markdown","000d04c3":"markdown","fcdf86f7":"markdown","0c09fc7d":"markdown","9c44e453":"markdown","129c23a8":"markdown","038234d0":"markdown","a6eec611":"markdown","d9ad6d33":"markdown","ac16bfdd":"markdown","3425e97b":"markdown","680ba04e":"markdown","ba0326a1":"markdown","89e2e5fa":"markdown","1692a82b":"markdown","3ddce4f7":"markdown","6a9bdbb6":"markdown"},"source":{"f964926d":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json","8aac1e52":"count = 0\nfile_exts = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        count += 1\n        file_ext = filename.split(\".\")[-1]\n        file_exts.append(file_ext)\n\nfile_ext_set = set(file_exts)\n\nprint(f\"Files: {count}\")\nprint(f\"Files extensions: {file_ext_set}\\n\\n=====================\\nFiles extension count:\\n=====================\")\nfile_ext_list = list(file_ext_set)\nfor fe in file_ext_list:\n    fe_count = file_exts.count(fe)\n    print(f\"{fe}: {fe_count}\")","2d1f297b":"count = 0\nfor root, folders, filenames in os.walk('\/kaggle\/input'):\n    print(root, folders)","c3dbf6de":"print(f\"pdf json: {len(os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/document_parses\/pdf_json'))}\")\nprint(f\"pmc json: {len(os.listdir('\/kaggle\/input\/CORD-19-research-challenge\/document_parses\/pmc_json'))}\")","ff5c3160":"json_folder_path = \"\/kaggle\/input\/CORD-19-research-challenge\/document_parses\/pdf_json\"\njson_file_name = os.listdir(json_folder_path)[0]\nprint(json_file_name)\njson_path = os.path.join(json_folder_path, json_file_name)\n\nwith open(json_path) as json_file:\n    json_data = json.load(json_file)","da5daa14":"json_data_df = pd.io.json.json_normalize(json_data)","8f5dcb24":"json_data_df","9a5bceb4":"print(f\"Files in folder: {len(os.listdir(json_folder_path))}\")","d4cad7a8":"from tqdm import tqdm\n\n# to process all files, uncomment the next line and comment the line below\n# list_of_files = list(os.listdir(json_folder_path))\nlist_of_files = list(os.listdir(json_folder_path))[0:1000]\npmc_custom_license_df = pd.DataFrame()\n\nfor file in tqdm(list_of_files):\n    json_path = os.path.join(json_folder_path, file)\n    with open(json_path) as json_file:\n        json_data = json.load(json_file)\n    json_data_df = pd.io.json.json_normalize(json_data)\n    pmc_custom_license_df = pmc_custom_license_df.append(json_data_df)","9c920c9e":"pmc_custom_license_df.head()","893cf463":"pmc_custom_license_df['abstract_text'] = pmc_custom_license_df['abstract'].apply(lambda x: x[0]['text'] if x else \"\")","2257117c":"pd.set_option('display.max_colwidth', 500)\npmc_custom_license_df[['abstract', 'abstract_text']].head()","4bfe80b3":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n%matplotlib inline \nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=200,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15,15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=14)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15,15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    ","30b307b8":"show_wordcloud(pmc_custom_license_df['abstract_text'], title = 'Comm use subset - papers abstract - frequent words  (500 samples)')","03767af5":"show_wordcloud(pmc_custom_license_df['bib_entries.BIBREF0.title'], title = 'Comm use subset - papers title - frequent words (500 samples)')\n","ccd89c68":"pmc_custom_license_df.loc[((pmc_custom_license_df['bib_entries.BIBREF0.venue']==\"\") | ((pmc_custom_license_df['bib_entries.BIBREF0.venue'].isna()))), 'bib_entries.BIBREF0.venue'] = \"Not identified\"\n","df855380":"import seaborn as sns\ndef plot_count(feature, title, df, size=1, show_percents=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[0:20], palette='Set3')\n    g.set_title(\"Number of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=10)\n    if(show_percents):\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100*height\/total),\n                    ha=\"center\") \n    ax.set_xticklabels(ax.get_xticklabels());\n    plt.show()    \n","5a05838b":"plot_count('bib_entries.BIBREF0.venue', 'Comm use subset - Top 20 Journals (500 samples)', pmc_custom_license_df, 3.5)","4ee5cd30":"plot_count('bib_entries.BIBREF0.venue', 'Comm use subset - Top 20 Journals (500 samples)', \n           pmc_custom_license_df.loc[pmc_custom_license_df['bib_entries.BIBREF0.venue']!='Not identified'], 3.5)","32dfdf84":"We eliminate \"Not identified\"","d8935cb3":"<a href=\"#0\"><small>Go to top<\/small><\/a>","40c4525e":"<h1 style='background:#13E3E1; border:0; color:black'><center>Load packages<\/center><\/h1>\n\nWe just load the minimum packages for now.","000d04c3":"<a id=\"6\"><\/a><h1 style='background:#13E3E1; border:0; color:black'><center>Visualize most frequent items in categorical features<\/center><\/h1>\n","fcdf86f7":"<a id=\"5\"><\/a><h1 style='background:#13E3E1; border:0; color:black'><center>Visualize text content<\/center><\/h1>\n\nLet's present here few useful techniques for data visualization:\n\n* Worldclouds for text fields;\n\n* Countplot for category-type features.\n","0c09fc7d":"<a href=\"#0\"><small>Go to top<\/small><\/a>","9c44e453":"<h1 style='background:#13E3E1; border:0; color:black'><center>Explore the data<\/center><\/h1>","129c23a8":"<a href=\"#0\"><small>Go to top<\/small><\/a>","038234d0":"<a id=\"4\"><\/a><h1 style='background:#13E3E1; border:0; color:black'><center>Extract abstract text<\/center><\/h1>\n\nLet's extract now abstract text from abstract column.  \n\nSimilar approach can be used to extract other parts from a dictionary-type field.\n","a6eec611":"\nWe provide some tools to explore the jsons.\n\n<a id=\"2\"><\/a><h1 style='background:#13E3E1; border:0; color:black'><center>Read a JSON File<\/center><\/h1>\n\n","d9ad6d33":"Let's also look to the structure of directories, to see how the data is structured high-level:","ac16bfdd":"<a href=\"#0\"><small>Go to top<\/small><\/a>","3425e97b":"To use more easy, we can normalize the json. Here is the code.","680ba04e":"<h1> CORD-19 Solution Toolbox<\/h1>\n\n\nWe give here a minimal toolset to explore the dataset and start performing an EDA.  \n\n<a id=\"0\"><\/a>\nWe will provide the tools to:\n\n* <a href='#1'>Browse through the files in the collections;<\/a>  \n* <a href='#2'>Read content from JSON files;<\/a>  \n* <a href='#3'>Bulk process JSON files to extract content in a DataFrame;<\/a>  \n* <a href='#4'>Extract abstract content;<\/a>  \n* <a href='#5'>Visualize text content;<\/a>  \n* <a href='#6'>Visualize most frequent items in categorical features<\/a>  \n\n","ba0326a1":"Majority of files are in json format. The files are grouped in 3 main folders and multiple subfolders.\n","89e2e5fa":"<a id=\"3\"><\/a><h1 style='background:#13E3E1; border:0; color:black'><center>Convert the folder in a dataframe<\/center><\/h1>\n\nLet's process now the folder. We will create a dataset with the data from the folder. We just take a subset of data (1000 samples).  For your work, just comment the line of code where the subset is declared and uncomment the line of code above, to process entire dataset.","1692a82b":"The json was transformed in a row in a dataframe, with the column names resulted by aggregating the succesive levels of the json structure.   Let's check the result.","3ddce4f7":"<a href=\"#0\"><small>Go to top<\/small><\/a>","6a9bdbb6":"<a href=\"#0\"><small>Go to top<\/small><\/a>"}}