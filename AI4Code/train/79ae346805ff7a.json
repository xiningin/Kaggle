{"cell_type":{"3c700838":"code","306b098d":"code","b1e6a8b0":"code","842eb97e":"code","9fff71dd":"code","e56e0aa7":"code","9c23f8cd":"code","ada7ecf7":"code","2fce4074":"code","49bf59b7":"code","4ca05a39":"code","5bd7cc58":"code","fad7617b":"code","476e6b91":"code","bf14f378":"code","5fd703de":"code","422cacb1":"code","11e4c7cc":"code","830a1630":"code","ce378017":"code","9704625c":"code","115b16e7":"code","6709f3cc":"code","ef767ee6":"code","32265888":"code","de99f5bf":"code","515e6fa5":"code","4fd10ddb":"code","fcfabd4b":"code","3c169db3":"code","e9c00716":"code","8216b9f9":"code","df1feaa0":"code","961f661b":"code","06627067":"code","7feeed7f":"code","8f0f6037":"code","63bc362e":"code","03cd8867":"code","d8ad182f":"code","c35ebd57":"code","97d58ab5":"code","48338ae0":"code","10dc555e":"code","5e705817":"code","a6dcf62c":"code","f6673c09":"code","4ba5a951":"code","0b78e13a":"code","509ea5dd":"markdown","2fe6f3f5":"markdown","dac838e2":"markdown"},"source":{"3c700838":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","306b098d":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nimport re\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud, STOPWORDS ","b1e6a8b0":"TweetData =  pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\",index_col=0)","842eb97e":"TweetData.head()","9fff71dd":"TweetData.info()","e56e0aa7":"TweetData['tweet_length']= TweetData['text'].apply(lambda x: len(x.split()))","9c23f8cd":"TweetData.head()","ada7ecf7":"# Number of Sentence in a tweet\nTweetData['Sent_count'] = TweetData['text'].apply(lambda x : len(sent_tokenize(x))) ","2fce4074":"TweetData.head()","49bf59b7":"# punchuation mark count per text\nTweetData['punch_count'] = TweetData['text'].apply(lambda x : len(word_tokenize(x))-len(x.split()))  ","4ca05a39":"# hastags in a tweets\nTweetData['hashtags'] = TweetData['text'].apply(lambda x :  word_tokenize(x).count('#'))","5bd7cc58":"from nltk.corpus import stopwords","fad7617b":"stop_words = set(stopwords.words('english')) \ntokenizer = RegexpTokenizer(r'\\w+')","476e6b91":"# without stopwords text length\nTweetData['text_no_stop'] = TweetData['text'].apply(lambda x : len([w for w in tokenizer.tokenize(x) if not w in stop_words]))","bf14f378":"def clean_tweets(x):\n    clean1 = re.sub('https?:\/\/[A-Za-z0-9.\/]+','',x)\n    clean2 = re.sub(r'[^\\w\\s]','',clean1).lower()\n    return clean2","5fd703de":"TweetData['Clean_text'] = TweetData['text'].apply(lambda x: clean_tweets(x))","422cacb1":"TweetData['Sentiment_Score'] = TweetData['Clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)","11e4c7cc":"TweetData['Sentiment']=\"A\"\nCondition = [(TweetData['Sentiment_Score']>0),(TweetData['Sentiment_Score'] ==0)]\nchoices = ['Positive','Neutral']\nTweetData['Sentiment'] = np.select(Condition,choices,default='Negative')","830a1630":"TweetData.head()","ce378017":"sns.set()\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(12,4), dpi=100)\nsns.distplot(TweetData['tweet_length'],ax=axes[0][0],kde=False)\nsns.distplot(TweetData['text_no_stop'],ax=axes[0][1],kde=False)\nsns.distplot(TweetData['Sentiment_Score'],ax=axes[1][0],kde=False)\nsns.distplot(TweetData['punch_count'],ax=axes[1][1],kde=False)","9704625c":"sns.set(style='whitegrid', rc={\"grid.linewidth\": 0.2})\nsns.set_context(\"paper\", font_scale=0.9)\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(10,6), dpi=100)\n# sns.set_context('notebook',font_scale=1)\n# sns.set_style('whitegrid')\nsns.countplot(x='target',data=TweetData,ax=axes[0][0])\nsns.countplot(x='Sent_count',data=TweetData,ax=axes[0][1])\nsns.countplot(x='hashtags',data=TweetData,ax=axes[1][0])\nsns.countplot(x='Sentiment',data=TweetData,ax=axes[1][1])","115b16e7":"comment_words = ' '\nstopwords = set(STOPWORDS) ","6709f3cc":"for text in TweetData['Clean_text']:\n    tokens = word_tokenize(text)\n    for words in tokens: \n        comment_words = comment_words + words + ' ' ","ef767ee6":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)\nsns.set()\nplt.figure(figsize = (8, 8), facecolor = None,dpi=100) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)","32265888":"sns.set(style='whitegrid', rc={\"grid.linewidth\": 0.2})\nsns.set_context(\"paper\", font_scale=0.9)\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(10,6), dpi=100)\n# sns.set_context('notebook',font_scale=1)\n# sns.set_style('whitegrid')\nsns.countplot(x='target',data=TweetData,ax=axes[0][0])\nsns.countplot(x='Sent_count',data=TweetData,ax=axes[0][1],hue='target')\nsns.countplot(x='hashtags',data=TweetData,ax=axes[1][0],hue='target')\nsns.countplot(x='Sentiment',data=TweetData,ax=axes[1][1],hue ='target')","de99f5bf":"fig =plt.figure(figsize=(15,15),dpi=100)\nsns.set_context('notebook',font_scale=1.3)\nsns.set_style('whitegrid')\ng=sns.pairplot(TweetData[['tweet_length','text_no_stop','Sentiment_Score','punch_count','target']],hue='target')","515e6fa5":"Tweettrain = TweetData[['target','tweet_length','Sent_count','punch_count','hashtags','text_no_stop','Sentiment_Score','Sentiment']]","4fd10ddb":"X = Tweettrain.iloc[:,1:].values\nY = Tweettrain.iloc[:,0].values","fcfabd4b":"from sklearn.preprocessing import LabelEncoder","3c169db3":"LabelX = LabelEncoder()\nX[:,6]=LabelX.fit_transform(X[:,6])","e9c00716":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","8216b9f9":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","df1feaa0":"from sklearn.linear_model import LogisticRegression","961f661b":"def plot_roc_curve(fpr, tpr,col,lab):\n    plt.plot(fpr, tpr, color=col, label=lab)\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","06627067":"X_train,X_test,Y_Train,Y_Test = train_test_split(X,Y,test_size= 0.20)","7feeed7f":"classifierRF = RandomForestClassifier(n_estimators=150,max_depth=12,criterion='gini')\nclassifierRF.fit(X_train,Y_Train)\ny_pred_RF = classifierRF.predict(X_test)\n\ncm_RF = confusion_matrix(Y_Test, y_pred_RF)\nprint('Confusion matrix Random Forest',cm_RF)\n\naccuracy_RF = accuracy_score(Y_Test, y_pred_RF)\nprecision_RF =precision_score(Y_Test, y_pred_RF)\nrecall_RF =  recall_score(Y_Test, y_pred_RF)\nf1_RF = f1_score(Y_Test, y_pred_RF)\nprint('accuracy random forest :',accuracy_RF)\nprint('precision random forest :',precision_RF)\nprint('recall random forest :',recall_RF)\nprint('f1-score random forest :',f1_RF)\nauc_RF = roc_auc_score(Y_Test, y_pred_RF)\nprint('AUC: %.2f' % auc_RF)","8f0f6037":"xgb =  XGBClassifier(max_depth=4)\nxgb.fit(X_train,Y_Train)\ny_pred_xgb = xgb.predict(X_test)\n\ncm_xgb = confusion_matrix(Y_Test, y_pred_xgb)\nprint('Confusion matrix Random Forest',cm_xgb)\n\naccuracy_xgb = accuracy_score(Y_Test, y_pred_xgb)\nprecision_xgb =precision_score(Y_Test, y_pred_xgb)\nrecall_xgb =  recall_score(Y_Test, y_pred_xgb)\nf1_xgb = f1_score(Y_Test, y_pred_xgb)\nprint('XGBOOST accuracy :',accuracy_xgb)\nprint('precision XGBOOST :',precision_xgb)\nprint('recall XGBOOST :',recall_xgb)\nprint('f1-score XGBOOST :',f1_xgb)\nauc_xgb = roc_auc_score(Y_Test, y_pred_xgb)\nprint('AUC: %.2f' % auc_xgb)","63bc362e":"classifierLogistic = LogisticRegression()\nclassifierLogistic.fit(X_train,Y_Train)\ny_pred_logit = classifierLogistic.predict(X_test)\n\ncm_logit = confusion_matrix(Y_Test, y_pred_logit)\nprint('Confusion matrix for Logistic',cm_logit)\n\naccuracy_logit = accuracy_score(Y_Test, y_pred_logit)\nprecision_logit =precision_score(Y_Test, y_pred_logit)\nrecall_logit =  recall_score(Y_Test, y_pred_logit)\nf1_logit = f1_score(Y_Test, y_pred_logit)\nprint('accuracy_logistic :',accuracy_logit)\nprint('precision_logistic :',precision_logit)\nprint('recall_logistic :',recall_logit)\nprint('f1-score_logistic :',f1_logit)\nauc_logit = roc_auc_score(Y_Test, y_pred_logit)\nprint('AUC_logistic : %.2f' % auc_logit)","03cd8867":"a=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\nb=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\nfig =plt.figure(figsize=(15,15),dpi=50)\nfpr, tpr, thresholds = roc_curve(Y_Test,y_pred_logit )\nplt.plot(fpr, tpr,color ='orange',label ='Logistic' )\nfpr, tpr, thresholds = roc_curve(Y_Test,y_pred_RF )\nplt.plot(fpr, tpr,color ='blue',label ='random Forest' )\nfpr, tpr, thresholds = roc_curve(Y_Test,y_pred_RF )\nplt.plot(fpr, tpr,color ='red',label ='XGB' )\nplt.plot(a,b,color='black',linestyle ='dashed')\nplt.legend(fontsize=15)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.ylabel('True Positive Rate',fontsize=15)","d8ad182f":"test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\",index_col=0)","c35ebd57":"test.head()","97d58ab5":"test['tweet_length']= test['text'].apply(lambda x: len(x.split()))\ntest['Sent_count'] = test['text'].apply(lambda x : len(sent_tokenize(x))) \ntest['punch_count'] = test['text'].apply(lambda x : len(word_tokenize(x))-len(x.split()))\ntest['hashtags'] = test['text'].apply(lambda x :  word_tokenize(x).count('#'))\ntest['text_no_stop'] = test['text'].apply(lambda x : len([w for w in tokenizer.tokenize(x) if not w in stop_words]))\ntest['Clean_text'] = test['text'].apply(lambda x: clean_tweets(x))\ntest['Sentiment_Score'] = test['Clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\ntest['Sentiment']=\"A\"\nCondition = [(test['Sentiment_Score']>0),(test['Sentiment_Score'] ==0)]\nchoices = ['Positive','Neutral']\ntest['Sentiment'] = np.select(Condition,choices,default='Negative')","48338ae0":"test.head()","10dc555e":"Test = test[['tweet_length','Sent_count','punch_count','hashtags','text_no_stop','Sentiment_Score','Sentiment']]","5e705817":"Test.head()","a6dcf62c":"T = Test.iloc[:,:].values","f6673c09":"T[:,6]=LabelX.transform(T[:,6])","4ba5a951":"output = classifierRF.predict(T)","0b78e13a":"outputS =  pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\noutputS['target'] = output\noutputS.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","509ea5dd":"Comparision with Target column","2fe6f3f5":"EDA","dac838e2":"Will  apply classification models using Features created... work in progress :P"}}