{"cell_type":{"0404044e":"code","530838e9":"code","4bdb3633":"code","adecf7ed":"code","5fa7ce46":"code","ecdb32c3":"code","f964abe0":"code","ed6db285":"code","f809f24c":"code","b5a3a20d":"code","93ffb338":"code","3dc8b2e6":"markdown"},"source":{"0404044e":"!pip install -U torch==1.5 torchvision==0.6 -f https:\/\/download.pytorch.org\/whl\/cu101\/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n!gcc --version\n\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","530838e9":"!pip install detectron2==0.1.3 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu101\/index.html","4bdb3633":"import os, sys\n\n!git clone https:\/\/github.com\/aim-uofa\/AdelaiDet.git\nos.chdir('AdelaiDet')","adecf7ed":"DATA_DIR = '\/kaggle\/input'\nROOT_DIR = '\/kaggle\/working'\n\nsys.path.append(os.path.join(ROOT_DIR, 'AdelaiDet')) ","5fa7ce46":"!python setup.py build develop","ecdb32c3":"!wget -O tt_attn_R_50.pth https:\/\/cloudstor.aarnet.edu.au\/plus\/s\/t2EFYGxNpKPUqhc\/download\n!ls -lh tt_attn_R_50.pth","f964abe0":"import cv2\nimport glob\nimport matplotlib.pyplot as plt\n\ndef process(filename):\n    plt.figure(figsize=(25,15))\n    plt.imshow(filename)","ed6db285":"images = [cv2.imread(file) for file in glob.glob('\/kaggle\/input\/totaltextstr\/Total-Text\/Train\/*.jpg')]\nprint(len(images))\n    \ni = 0\nfor file in images:\n    process(file)\n    i += 1\n    if i > 10: break","f809f24c":"!mkdir 'output'\n!python demo\/demo.py \\\n    --config-file configs\/BAText\/TotalText\/attn_R_50.yaml \\\n    --input \/kaggle\/input\/totaltextstr\/Total-Text\/Train\/* \\\n    --output \/kaggle\/working\/AdelaiDet\/output\/ \\\n    --opts MODEL.WEIGHTS tt_attn_R_50.pth","b5a3a20d":"images = [cv2.imread(file) for file in glob.glob('\/\/kaggle\/working\/AdelaiDet\/output\/*.jpg')]\n\nprint(len(images))\n    \ni = 0\nfor file in images:\n    process(file)\n    i += 1\n    if i > 20: break","93ffb338":"!rm -rf \/kaggle\/working\/AdelaiDet","3dc8b2e6":"# ABCNet\n\n[ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network](https:\/\/arxiv.org\/abs\/2002.10200)\n\n\n> Scene text detection and recognition has received increasing research attention. Existing methods can be roughly categorized into two groups: character-based and segmentation-based. These methods either are costly for character annotation or need to maintain a complex pipeline, which is often not suitable for real-time applications. Here we address the problem by proposing the Adaptive Bezier-Curve Network (ABCNet). Our contributions are three-fold: 1) For the first time, we adaptively fit arbitrarily-shaped text by a parameterized Bezier curve. 2) We design a novel BezierAlign layer for extracting accurate convolution features of a text instance with arbitrary shapes, significantly improving the precision compared with previous methods. 3) Compared with standard bounding box detection, our Bezier curve detection introduces negligible computation overhead, resulting in superiority of our method in both efficiency and accuracy. Experiments on arbitrarily-shaped benchmark datasets, namely Total-Text and CTW1500, demonstrate that ABCNet achieves state-of-the-art accuracy, meanwhile significantly improving the speed. In particular, on Total-Text, our realtime version is over 10 times faster than recent state-of-the-art methods with a competitive recognition accuracy. \n\n\n# Quick Inference on Total-Text Data"}}