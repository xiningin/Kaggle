{"cell_type":{"9336dfa8":"code","079c446d":"code","1f906f32":"code","d1ae6695":"code","d75d3420":"code","6b48fd96":"code","0e9bdb4f":"code","1fa64ee2":"code","a5f3522d":"code","fdbd3c7e":"code","3a736340":"code","a7e84d19":"code","db61559f":"code","4b7ed122":"code","ac61b39d":"code","a92df7d8":"code","99a0bb0c":"code","5bf73197":"code","d0403201":"code","72fa70c6":"code","ee8f5a69":"code","d02aa40f":"code","5f933897":"code","9cbdf455":"code","10fa99bb":"code","75423c59":"code","06b760a6":"code","ff470d0b":"code","2946bb1e":"code","3ac769a8":"code","2b97d5d0":"code","866d86d2":"code","c7b242c4":"code","00a54dce":"code","44c56a20":"code","884d56ec":"code","3a82dc30":"code","408a1bd6":"code","7f4547d8":"code","41d22f2b":"code","08c56aeb":"code","e7accc35":"code","4b6d31a3":"code","857d8963":"code","e89fe11d":"code","6c792cec":"code","4e57b60d":"code","b72dc391":"code","470600a3":"code","ba52a66d":"code","0ab104d6":"code","c42e9437":"code","1ea60c88":"code","5101003f":"code","81912eb1":"code","cb388fa9":"markdown","d015bca3":"markdown","4b715975":"markdown","4eb1bef8":"markdown","c612cfb4":"markdown","a5e56653":"markdown","13e7bf33":"markdown","9a461602":"markdown","6e73f79e":"markdown","a2b8a65f":"markdown","11ddba70":"markdown","daa5bc7a":"markdown","27072dc5":"markdown","39f36d61":"markdown","bb6100cb":"markdown","379560f1":"markdown","a512bd0c":"markdown","78e9a9d3":"markdown","26c5f37b":"markdown","f7a2d573":"markdown","6fd619c1":"markdown","c2c96705":"markdown","a621d989":"markdown","4caa55ff":"markdown","8240153a":"markdown","3dd9fc62":"markdown","e489ce5b":"markdown","76340631":"markdown","7e15a940":"markdown","884182ea":"markdown","de5dcc43":"markdown","9934ace7":"markdown"},"source":{"9336dfa8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","079c446d":"import seaborn as sns\nimport matplotlib.pyplot as plt","1f906f32":"health = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","d1ae6695":"health.head(10)","d75d3420":"health.isnull().sum()","6b48fd96":"np.mean(health.bmi)","0e9bdb4f":"health.bmi.fillna(np.mean(health.bmi), inplace=True)","1fa64ee2":"health.smoking_status.value_counts()","a5f3522d":"health.drop(['id'] , axis=1 , inplace=True)","fdbd3c7e":"health.work_type.value_counts()","3a736340":"#health.smoking_status.replace({'Unknown':'smokes'} , inplace=True)","a7e84d19":"health.age.min()","db61559f":"def remove_outliers(df , col , k):\n    mean= df[col].mean()\n    sd=df[col].std()\n    global df1\n    final_list = [x for x in df[col] if (x>mean-k*sd)]\n    final_list = [x for x in final_list if (x<mean+k*sd)]\n    df1 = df.loc[df[col].isin(final_list)];\n    return df1\nhealth = pd.concat([remove_outliers(health[health.stroke==1] , 'age' ,2.0) , health[health.stroke == 0]] , axis=0)","4b7ed122":"\ndist = [health.stroke[health.stroke == 1 ].count() , health.stroke[health.stroke == 0 ].count()]\ndist\nplt.pie(dist, autopct='%1.1f%%');","ac61b39d":"sns.histplot(x='age' , data=health , hue='stroke' , element='poly')\nplt.title(\"Age Vs Stroke Histogram\")","a92df7d8":"sns.boxplot(y='age' , x='stroke', data=health )\nplt.title(\"Age Vs Stroke Boxplot \")","99a0bb0c":"data = health[health.stroke == 1].smoking_status.value_counts()\npie_data = []\nfor i in data:\n    pie_data.append(i)\nlabel = ('never smoked' , 'formerly smoked' , 'unknown'  ,'smokes');\nplt.pie(pie_data , labels=label , autopct='%1.0f%%' );\nplt.title(\"Somking status of people with stoke\");","5bf73197":"sns.countplot(x='gender' , hue='stroke' , data=health )\nplt.title(\"Gender vs Stroke\");","d0403201":"plt.figure(figsize=(10,5))\nsns.histplot(x='bmi' , hue='stroke' , data=health , element='poly')\nplt.title(\"Bmi vs Stroke\")\nplt.grid()","72fa70c6":"plt.figure(figsize=(10 , 5))\nsns.countplot(x='heart_disease' , hue='stroke' , data=health)\nplt.title(\"Histogram of Heart Disease vs Stoke\");","ee8f5a69":"plt.figure(figsize=(10,5))\nsns.countplot(x='hypertension' , hue='stroke' , data=health)\nplt.grid()","d02aa40f":"plt.figure(figsize=(10 , 5))\nsns.histplot(x='avg_glucose_level' , data=health , hue='stroke' , element='poly');\nplt.title(\"AVg_glucose_level count and stroke\");","5f933897":"sns.catplot(y=\"work_type\", hue=\"stroke\", kind=\"count\", edgecolor=\".6\",\n            data=health)","9cbdf455":"plt.figure(figsize=(16,8))\nsns.heatmap(health.corr(),cmap=\"Blues\");","10fa99bb":"from sklearn.preprocessing import LabelEncoder","75423c59":"le = LabelEncoder()","06b760a6":"health[health.select_dtypes(include=['object']).columns] = health[health.select_dtypes(include=['object']).columns].apply(le.fit_transform)","ff470d0b":"health.head()","2946bb1e":"from boruta import BorutaPy\nfrom sklearn.ensemble import RandomForestClassifier","3ac769a8":"health_x = health.drop(['stroke'] , axis=1)\nhealth_y = health.stroke\n\nhealth_x\n\nhealth_x = np.array(health_x)\nhealth_y = np.array(health_y)\n\nrf = RandomForestClassifier()\nboruta = BorutaPy(rf, max_iter=25 )\nboruta.fit(health_x, health_y)","2b97d5d0":"features = pd.DataFrame({\"Features\":health.drop(['stroke'], axis=1).columns , \"Score\":boruta.support_})","866d86d2":"features","c7b242c4":"health_x = health.drop(['stroke'] , axis=1)\nhealth_y = health.stroke","00a54dce":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\ntest = SelectKBest(score_func=chi2 , k='all')\n\nfitted = test.fit(health_x , health_y)\nprint(fitted.scores_)","44c56a20":"Feature_imp = pd.DataFrame({\"Features\":health_x.columns , \"Importance\":fitted.scores_ })","884d56ec":"sns.catplot(y='Importance' , x='Features' , data=Feature_imp.sort_values(['Importance'], ascending=False) , kind='bar')\nplt.xticks(rotation = 90);","3a82dc30":"from sklearn.model_selection import train_test_split\ntrain  , test  = train_test_split(health , test_size = 0.2 , random_state=555)","408a1bd6":"train_x = train.drop(['stroke'] , axis=1)\ntrain_y = train.stroke","7f4547d8":"test_x = test.drop(['stroke'] , axis=1)\ntest_y = test.stroke\n","41d22f2b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix , accuracy_score , classification_report\nfrom sklearn.ensemble import AdaBoostClassifier","08c56aeb":"rfc = RandomForestClassifier(criterion='entropy' , max_depth=6 ,class_weight='balanced')\nrfc.fit(train_x , train_y)\npred_rfc = rfc.predict(test_x)\nconfution_rfc = confusion_matrix(pred_rfc , test_y)\nprint(confution_rfc)\nrepo = classification_report(test_y , pred_rfc)\nprint(repo)\nAccuracy_rfc = accuracy_score(test_y , pred_rfc)\nprint(Accuracy_rfc)\nplt.figure(figsize=(5,2))\nsns.heatmap(confution_rfc, annot=True ,fmt='' );","e7accc35":"rfc_feature = pd.DataFrame({\"Feature\":train_x.columns , \"Importance\":rfc.feature_importances_})\nrfc_feature.sort_values('Importance' , ascending=False)","4b6d31a3":"df2 = train[train.stroke == 1]\ntrain = pd.concat([train , df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2] , axis=0)\ntrain_x = train.drop(['stroke'] , axis=1)\ntrain_y = train.stroke","857d8963":"df2 = train[train.stroke == 1]\ndf2.shape\ntrain.shape","e89fe11d":"lr = LogisticRegression()\nadb= AdaBoostClassifier(lr)\nadb.fit(train_x , train_y)\npred_lr = adb.predict(test_x)\nconfution_lr = confusion_matrix(pred_lr , test_y)\nprint(confution_lr)\nrepo = classification_report(test_y , pred_lr)\nprint(repo)\nAccuracy_rfc = accuracy_score(test_y , pred_lr)\nprint(Accuracy_rfc)\nplt.figure(figsize=(5,2))\nsns.heatmap(confution_lr , annot=True ,fmt='' );\n\n","6c792cec":"rfc = RandomForestClassifier(max_depth=6 , criterion='entropy' , class_weight='balanced')\nadb = AdaBoostClassifier(rfc)\nadb.fit(train_x , train_y)\npred_adb = adb.predict(test_x)\nconfution_adb = confusion_matrix(pred_adb , test_y)\nprint(confution_adb)\nrepo = classification_report(test_y , pred_adb)\nprint(repo)\nAccuracy_rfc = accuracy_score(test_y , pred_adb)\nprint(Accuracy_rfc)\nplt.figure(figsize=(5,2))\nsns.heatmap(confution_adb, annot=True ,fmt='' );","4e57b60d":"from sklearn.tree import DecisionTreeClassifier\n","b72dc391":"dt = DecisionTreeClassifier(min_samples_split=3 , criterion='entropy' , max_depth=6  )\ndt.fit(train_x  , train_y)\npred_dt = dt.predict(test_x)\nconf_dt = confusion_matrix(pred_dt , test_y)\nprint(conf_dt)\nrepo = classification_report(test_y , pred_dt)\nprint(repo)\nAccuracy_rfc = accuracy_score(test_y , pred_dt)\nprint(Accuracy_rfc)\nplt.figure(figsize=(5,2))\nsns.heatmap(conf_dt, annot=True ,fmt='' );","470600a3":"from sklearn.ensemble import ExtraTreesClassifier\net = ExtraTreesClassifier(class_weight='balanced')","ba52a66d":"et.fit(train_x , train_y )\nadb = AdaBoostClassifier(et , learning_rate=2 )\nadb.fit(train_x , train_y)\npred_et = adb.predict(test_x)\nconf_et = confusion_matrix(pred_et , test_y)\nprint(conf_et)","0ab104d6":"from sklearn.ensemble import GradientBoostingClassifier","c42e9437":"grd = GradientBoostingClassifier()\ngrd.fit(train_x , train_y)\npred_grd = grd.predict(test_x)\nconf_grd = confusion_matrix(pred_grd , test_y)\nrepo_grd = classification_report(test_y , pred_grd)\nacc_grd = accuracy_score(test_y , pred_grd)\nprint(conf_grd)\nprint(repo_grd)\nprint(acc_grd)\nplt.figure(figsize=(5,2))\nsns.heatmap(conf_grd, annot=True ,fmt='' );","1ea60c88":"from sklearn.naive_bayes import MultinomialNB","5101003f":"NB = MultinomialNB()\nNB.fit(train_x , train_y)\npred_NB = NB.predict(test_x)\nconf_NB =confusion_matrix(pred_NB , test_y)\nprint(conf_NB)\nacc_grd = accuracy_score(test_y , pred_NB)\nprint(acc_grd)\nrepo_NB= classification_report(test_y , pred_NB)\nprint(repo_NB)\nplt.figure(figsize=(5,2))\nsns.heatmap(conf_NB, annot=True ,fmt='' );","81912eb1":"import xgboost as xg\nxgboost=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\nxgboost.fit(train_x , train_y)\n\npredictions = xgboost.predict(test_x)\nconf_tab = confusion_matrix(predictions , test_y)\nconf_tab","cb388fa9":"### Extra Tree Classifier","d015bca3":"### Gradient Boosting","4b715975":"## Relation between hearth disease and Stroke","4eb1bef8":" <i>Here we can see that age , avg_gloucose_level , bmi  , work_type are most important columns <\/i>","c612cfb4":"## Boruta","a5e56653":"## Removing Outliers in age who has stroke","13e7bf33":"# Model and Prediction","9a461602":"<i>The Number of Rows after upsampling in train data are 8018<\/i>","6e73f79e":"#### people of Bmi group (20 , 40 ) is more prone to stroke","a2b8a65f":"## Naive Bayes ","11ddba70":"### Percent of data in both catagory ","daa5bc7a":"### upsampling class 1","27072dc5":"#### Here we can see that female count in stroke bar is more than that of Male ","39f36d61":"# Feature Selection ","bb6100cb":"#### Here people without hypertention is more prone to stroke","379560f1":"####  Here we can see that the age of people having stroke is left skewed distribution 55 and above aged people are much more prone to stroke","a512bd0c":"### Random Forest  with AdaBoost","78e9a9d3":"## Chi 2 test ","26c5f37b":"## Hypertension VS stroke","f7a2d573":"### Decision Tree","6fd619c1":"### Logistic Regression ","c2c96705":"## Plot between smoking status in people that had stroke","a621d989":"### Relation between stroke and age ","4caa55ff":"## Plot between stroke and Gender Count","8240153a":"## Work Type and Stroke","3dd9fc62":"# Test train Split","e489ce5b":"## Stroke and BMI relation ship ","76340631":"### Random forest ","7e15a940":"#  EDA ","884182ea":"# Converting Labeled Data to Numerical Data","de5dcc43":"## Avg_glucose_level count and stroke","9934ace7":"#### Here people without heart disease much prone to stroke "}}