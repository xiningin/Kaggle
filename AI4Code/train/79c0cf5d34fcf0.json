{"cell_type":{"75eeff1b":"code","005a58b0":"code","03fcef74":"code","2042195b":"code","95a621d4":"code","1ca1a6f1":"code","9b44415c":"code","165c0d48":"code","08275c3f":"code","91851d15":"code","80aa573a":"code","a2ea323e":"code","449df2cf":"code","06d0b3ef":"code","52f6aa83":"code","8af3e8ad":"markdown","aaecd279":"markdown","7c97e45e":"markdown","85125ea0":"markdown","2d563717":"markdown"},"source":{"75eeff1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","005a58b0":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n!pip install tensorflow_decision_forests\n!pip install wurlitzer\nimport tensorflow_decision_forests as tfdf\nfrom wurlitzer import sys_pipes","03fcef74":"train_df = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nprint('train shape:',train_df.shape)\nprint('test shape:',test_df.shape)","2042195b":"feat = train_df.drop(columns = ['id','loss'])\nfeat.head()","95a621d4":"col_names = list(feat.columns)","1ca1a6f1":"scaler = StandardScaler()\ntrain_df[col_names] = scaler.fit_transform(train_df[col_names])\ntest_df[col_names] = scaler.transform(test_df[col_names])","9b44415c":"label = 'loss'\ndef split_dataset(dataset, test_ratio=0.30):\n    \"\"\"Splits a panda dataframe in two.\"\"\"\n    test_indices = np.random.rand(len(dataset)) < test_ratio\n    return dataset[~test_indices], dataset[test_indices]","165c0d48":"train_ds_pd, test_ds_pd = split_dataset(train_df.drop(columns=['id']))\n# train_ds_pd = train_ds_pd.drop(columns = ['loss'])\n# train_ds_pd.head()\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)","08275c3f":"model = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nmodel.compile(metrics=[\"mse\"])\n\n# Train the model.\nwith sys_pipes():\n    model.fit(x=train_ds,validation_data=test_ds)","91851d15":"import math\nevaluation = model.evaluate(test_ds, return_dict=True)\n\nprint(evaluation)\nprint()\nprint(f\"MSE: {evaluation['mse']}\")\nprint(f\"RMSE: {math.sqrt(evaluation['mse'])}\")","80aa573a":"test_1 = test_df.drop(columns=['id'])","a2ea323e":"test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_1, task=tfdf.keras.Task.REGRESSION)\npredictions = model.predict(test_ds)","449df2cf":"predictions.reshape((150000))","06d0b3ef":"output = pd.DataFrame({'id': test_df.id, 'loss': predictions.reshape((150000))})","52f6aa83":"output.to_csv('tfdf_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8af3e8ad":"# Scale the Data","aaecd279":"# Load Data","7c97e45e":"# Prediction using the trained model","85125ea0":"# Train the Model","2d563717":"# Splitting the Train Data"}}