{"cell_type":{"861ffca5":"code","13579c53":"code","a4c7fa35":"code","c151c3eb":"code","3565e369":"code","dc1ae61a":"code","65eabc26":"code","d6a78824":"code","4e4a9adc":"code","9945dfb9":"code","80f27f1b":"markdown","fc7ed630":"markdown","915d6e3f":"markdown","277f6e1e":"markdown","92c6228b":"markdown","6aa4391d":"markdown","b531fd4e":"markdown","8e82fc8a":"markdown","584409ce":"markdown","7e8af11c":"markdown"},"source":{"861ffca5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\n\n\nfrom PIL import Image\nimport cv2 \nfrom tqdm import tqdm \n# Last three are for import and tidying data\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","13579c53":"validation_horses = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/horses\"\nvalidation_humans = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/humans\"\ntrain_horses = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/horses\"\ntrain_humans = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/humans\"\n\nimage_size = 64\n\nX1 = []\nX2 = []\nX3 = []\nX4 = []\n\nfor image in tqdm(os.listdir(validation_horses)):\n    p = os.path.join(validation_horses, image)\n    img = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img = cv2.resize(img, (image_size, image_size)).flatten() \n    X1.append(img) # list of images\n    imgshow1 = np.asarray(img) # just taking one image for visualize\n    \nfor image in tqdm(os.listdir(validation_humans)):\n    p = os.path.join(validation_humans, image)\n    img2 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img2 = cv2.resize(img2, (image_size, image_size)).flatten() \n    X2.append(img2)\n    imgshow2 = np.asarray(img2)\n    \nfor image in tqdm(os.listdir(train_horses)):\n    p = os.path.join(train_horses, image)\n    img3 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img3 = cv2.resize(img3, (image_size, image_size)).flatten() \n    X3.append(img3)\n    imgshow3 = np.asarray(img3)\n    \nfor image in tqdm(os.listdir(train_humans)):\n    p = os.path.join(train_humans, image)\n    img4 = cv2.imread(p, cv2.IMREAD_GRAYSCALE) \n    img4 = cv2.resize(img4, (image_size, image_size)).flatten() \n    X4.append(img4)\n    imgshow4 = np.asarray(img4)\n    \n# Convert to array    \nX1 = np.asarray(X1)    \nX2 = np.asarray(X2)\nX3 = np.asarray(X3)    \nX4 = np.asarray(X4)    \n","a4c7fa35":"plt.figure(figsize=(6, 6))\nplt.subplot(2, 2, 1)\nplt.imshow(imgshow1.reshape(image_size, image_size))\nplt.axis('off')\nplt.subplot(2, 2, 2)\nplt.imshow(imgshow2.reshape(image_size, image_size))\nplt.axis('off')\nplt.subplot(2, 2, 3)\nplt.imshow(imgshow3.reshape(image_size, image_size))\nplt.axis('off')\nplt.subplot(2, 2, 4)\nplt.imshow(imgshow4.reshape(image_size, image_size))\nplt.axis('off')\nplt.show()","c151c3eb":"x = np.concatenate((X1,X3,X2,X4), axis = 0)\n\nzero = np.zeros(X1.shape[0] + X3.shape[0])\none = np.ones(X2.shape[0] + X4.shape[0])\n\ny = np.concatenate((zero,one), axis = 0).reshape(-1,1)\nprint(\"x shape :\", x.shape)\nprint(\"y shape :\", y.shape)","3565e369":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"x_train shape :\",x_train.shape)\nprint(\"x_test shape :\",x_test.shape)\nprint(\"y_train shape :\",y_train.shape)\nprint(\"y_test shape :\",y_test.shape)","dc1ae61a":"def initializeParameters(x_train, y_train):\n    parameters = {\"weight1\" : np.random.randn(4, x_train.shape[1]) * 0.1, \n                  \"bias1\" : np.zeros((4,1)) ,\n                  \"weight2\" : np.random.randn(1, 4) * 0.1,\n                  \"bias2\" : np.zeros((1,1))}\n    return parameters\n\ndef sigmoid(z):\n    y_head = 1\/(1+np.exp(-z))\n    return y_head\n\ndef forwardPropagation(x_train, parameters):\n    z1 = np.dot(parameters[\"weight1\"], x_train.T) + parameters[\"bias1\"]\n    a1 = np.tanh(z1)\n    z2 = np.dot(parameters[\"weight2\"], a1) + parameters[\"bias2\"]\n    a2 = sigmoid(z2)\n    \n    spinoff = {\"z1\" : z1,\n               \"a1\" : a1,\n               \"z2\" : z2,\n               \"a2\" : a2}\n    return a2, spinoff\n\ndef calculateCost(a2, y_train):\n    k = np.multiply(np.log(a2), y_train.T)\n    cost = -np.sum(k) \/ y_train.shape[0]\n    \n    return cost\n\ndef backwardPropagation(parameters, spinoff, x, y):\n    \n    dz2 = spinoff[\"a2\"].T-y\n    dw2 = np.dot(dz2.T,spinoff[\"a1\"].T)\/x.shape[0]\n    db2 = np.sum(dz2.T,axis =1,keepdims=True)\/x.shape[0]\n    dz1 = np.dot(parameters[\"weight2\"].T,dz2.T)*(1 - np.power(spinoff[\"a1\"], 2))\n    dw1 = np.dot(dz1,x)\/x.shape[0]\n    db1 = np.sum(dz1,axis =1,keepdims=True)\/x.shape[0]\n    \n    gradients = {\"dWeight1\": dw1,\n                 \"dBias1\": db1,\n                 \"dWeight2\": dw2,\n                 \"dBias2\": db2}\n    return gradients\n\ndef update(param, grad, lr):\n    param = {\"weight1\" : param[\"weight1\"] - lr * grad[\"dWeight1\"],\n             \"bias1\"   : param[\"bias1\"]   - lr * grad[\"dBias1\"],\n             \"weight2\" : param[\"weight2\"] - lr * grad[\"dWeight2\"],                             \n             \"bias2\"   : param[\"bias2\"]   - lr * grad[\"dBias2\"]}  \n                                         \n    return param\n\ndef predict(parameters, x_test):\n    a2, spinoff = forwardPropagation(x_test, parameters)\n    predicted = np.zeros((x_test.shape[0], 1))\n    \n    for i in range(a2.shape[1]):\n        if a2[0, i] < 0.5 :\n            predicted[i, 0] = 0\n        else:\n            predicted[i, 0] = 1\n            \n    return predicted    ","65eabc26":"def annModel(x_train, x_test, y_train, y_test, iterationNumber, learningRate):\n    \n    costList = []\n    iterationList = []\n    \n    parameters = initializeParameters(x_train, y_train)\n    \n    for i in range(iterationNumber):\n        a2, spinoff = forwardPropagation(x_train, parameters)\n        cost = calculateCost(a2, y_train)\n        gradients = backwardPropagation(parameters, spinoff, x_train, y_train)\n        parameters = update(parameters, gradients, learningRate)\n        \n        if i % 500 == 0:\n            costList.append(cost)\n            iterationList.append(i)\n            print(\"Cost after {}. iteration : {}\".format(i, cost))\n            \n        \n    plt.plot(iterationList, costList)\n    plt.xticks(iterationList, rotation='vertical')\n    plt.xlabel(\"Number of iteration\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n       \n    trainPrediction = predict(parameters, x_train)\n    testPrediction  = predict(parameters, x_test)\n    \n    print(\"Train accuracy : {}%\".format(100 - np.mean(np.abs(trainPrediction - y_train)) * 100))\n    print(\"Test accuracy : {}%\".format(100 - np.mean(np.abs(testPrediction - y_test)) * 100))     \n    \n    return parameters   ","d6a78824":"parameters = annModel(x_train, x_test, y_train, y_test, iterationNumber = 2500, learningRate = 0.008) ","4e4a9adc":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\nearlyStop = EarlyStopping(patience = 3)\n\nn_cols = x_train.shape[1]\n\nann = Sequential()\nann.add(Dense(units = 50, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = (n_cols)))\nann.add(Dense(units = 20, kernel_initializer = \"uniform\", activation = \"relu\"))\nann.add(Dense(units = 20, kernel_initializer = \"uniform\", activation = \"relu\"))\nann.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\nann.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n\nann.fit(x_train, y_train, epochs = 100, callbacks = [earlyStop])","9945dfb9":"trainPrediction2 = ann.predict(x_train)\ntestPrediction2 = ann.predict(x_test)\n\nprint(\"Train accuracy : {}%\".format(100 - np.mean(np.abs(trainPrediction2 - y_train)) * 100))\nprint(\"Test accuracy : {}%\".format(100 - np.mean(np.abs(testPrediction2 - y_test)) * 100))     ","80f27f1b":"With keras as you can see above, we can reach very good rates rapidly.","fc7ed630":"* Artificial Neural Network Model without Keras.","915d6e3f":"* Importing image data, converting grayscale mode, resizing and generally tidying data for ANN algorithm.","277f6e1e":"* We created an artificial neural network model with 2 layer and our model contains just 4 neurons(node). So, probably in this data, our model will not work very well because it is very simple and the model will not be able to learn this data, therefore it cannot distinguish horse and human images. Well, let's see how it works.","92c6228b":"Training lasted too long and accuracies are not so good as we expected. Now let's try it with Keras with more layers and neurons.","6aa4391d":"# Introduction\n\nIn this kernel we will try to create an artificial neural network model that can separate horse and human images and predict correctly. First, we will write the model without using any deep learning library. Then create it again using keras which is very useful library for deep learning. ","b531fd4e":"* Artificial Neural Network Model with Keras","8e82fc8a":"* Creating functions that are essential for our model.\n","584409ce":"* Let's see what do these images look like","7e8af11c":"# Conclusion\n\nThis was my first artificial neural network model and first deep learning work. If you like the kernel you can upvote. Feedbacks would be greatly appreciated. Leave a comment."}}