{"cell_type":{"ae3f4161":"code","b169f549":"code","8149e6d4":"code","18fc4493":"code","cf9dd44d":"code","0215894f":"code","ad869037":"code","4d046140":"code","54177191":"code","f4655c50":"code","217173a6":"code","e2cfa52b":"code","ac6b7b82":"code","a0664559":"code","0b2f739d":"code","b0a51cd8":"code","f92dae6e":"code","caec78c9":"code","2d6b1591":"code","5bfd97f3":"code","bf563ee4":"code","6309e53e":"code","6a596ad0":"code","10d68a2e":"code","48cfd722":"code","3d9fa863":"code","408ecb49":"code","cb63eaca":"code","a28c4a55":"code","319b79f3":"code","6b82d7fc":"code","f91e724d":"code","2d4ee58e":"code","321d7d6d":"code","bc6f1739":"code","0b2002a2":"code","2f67688e":"code","94a0eafb":"code","eac9d593":"markdown","7ffa0f9f":"markdown"},"source":{"ae3f4161":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b169f549":"emp=pd.read_csv(\"..\/input\/HR-Employee-Attrition.csv\")","8149e6d4":"emp.shape","18fc4493":"emp.info()","cf9dd44d":"emp.describe().T","0215894f":"emp.Attrition.value_counts()","ad869037":"emp.isna().sum()","4d046140":"emp.columns","54177191":"emp.duplicated().sum()","f4655c50":"emp.head(5)","217173a6":"emp['Attrition'] = emp['Attrition'].map(lambda x: 1 if x== 'Yes' else 0)","e2cfa52b":"emp.head(5)","ac6b7b82":"cat_col = emp.select_dtypes(exclude=np.number)    ### to select all category types\ncat_col\nnum_col = emp.select_dtypes(include=np.number)\nnum_col","a0664559":"for i in cat_col:\n    print(emp[i].value_counts())","0b2f739d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","b0a51cd8":"one_hot = pd.get_dummies(cat_col)\none_hot.head(5)","f92dae6e":"emp = pd.concat([num_col,one_hot],sort=False,axis=1)\nemp.head()","caec78c9":"x = emp.drop(columns='Attrition')","2d6b1591":"y = emp['Attrition']","5bfd97f3":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\ntrain_pred = logreg.predict(x_train)","bf563ee4":"metrics.confusion_matrix(y_train,train_pred)","6309e53e":"metrics.accuracy_score(y_train,train_pred)","6a596ad0":"test_Pred = logreg.predict(x_test)","10d68a2e":"metrics.confusion_matrix(y_test,test_Pred)","48cfd722":"metrics.accuracy_score(y_test,test_Pred)","3d9fa863":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, test_Pred))","408ecb49":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","cb63eaca":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom math import sqrt","a28c4a55":"x_train, x_test, y_train, y_test = train_test_split(\nx, y, test_size = 0.3, random_state = 100)\ny_train=np.ravel(y_train)\ny_test=np.ravel(y_test)\n#y_train = y_train.ravel()\n#y_test = y_test.ravel()","319b79f3":"accuracy_train_dict={}\naccuracy_test_dict={}\ndf_len=round(sqrt(len(emp)))\nfor k in range(3,df_len):\n    K_value = k+1\n    neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n    neigh.fit(x_train, y_train) \n    y_pred_train = neigh.predict(x_train)\n    y_pred_test = neigh.predict(x_test)    \n    train_accuracy=accuracy_score(y_train,y_pred_train)*100\n    test_accuracy=accuracy_score(y_test,y_pred_test)*100\n    accuracy_train_dict.update(({k:train_accuracy}))\n    accuracy_test_dict.update(({k:test_accuracy}))\n    print (\"Accuracy for train :\",train_accuracy ,\" and test :\",test_accuracy,\"% for K-Value:\",K_value)","6b82d7fc":"elbow_curve_train = pd.Series(accuracy_train_dict,index=accuracy_train_dict.keys())\nelbow_curve_test = pd.Series(accuracy_test_dict,index=accuracy_test_dict.keys())\nelbow_curve_train.head(10)","f91e724d":"ax=elbow_curve_train.plot(title=\"Accuracy of train VS Value of K \")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"Accuracy of train\")","2d4ee58e":"ax=elbow_curve_test.plot(title=\"Accuracy of test VS Value of K \")\nax.set_xlabel(\"K\")\nax.set_ylabel(\"Accuracy of test\")","321d7d6d":"from sklearn.naive_bayes import GaussianNB","bc6f1739":"NB=GaussianNB()\nNB.fit(x_train, y_train)","0b2002a2":"GaussianNB(priors=None,var_smoothing=1e-09)","2f67688e":"train_pred=NB.predict(x_train)\naccuracy_score(train_pred,y_train)","94a0eafb":"test_pred=NB.predict(x_test)\naccuracy_score(test_pred,y_test)","eac9d593":"will try to implement KNN for this problem to see accuracy is better than logistic regression","7ffa0f9f":"From the above iteration we see K=12 had better accuracy"}}