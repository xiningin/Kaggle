{"cell_type":{"57e31fb3":"code","e5ee0d3d":"code","9729173f":"code","1c8e5cb2":"code","595ef233":"code","42323a54":"code","f597e344":"code","12c9b2a8":"code","d1484de8":"code","d2fc674d":"code","61d846c0":"code","6e97d50d":"code","23e41579":"code","9005b3f6":"code","89e618ee":"code","72e7d84b":"code","d500e881":"code","0eae2b70":"code","3b3b242b":"code","792f53f3":"code","67099d05":"code","13e7abbf":"code","0fbd5f31":"code","fcdf6303":"code","30406d60":"code","661be1e7":"markdown","58cfbeef":"markdown","d367b04f":"markdown","a36188a5":"markdown","ece88166":"markdown","4059804a":"markdown","6d8e04e8":"markdown","392ed664":"markdown","64621f2d":"markdown","79faf24b":"markdown","5bacb0d4":"markdown","055338d2":"markdown","913e5244":"markdown","364c9e71":"markdown","f6b82d30":"markdown"},"source":{"57e31fb3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as ex\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport re\nimport string\nfrom wordcloud import STOPWORDS,WordCloud\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\ndef rmse(y,y_hat):\n    return np.sqrt(mean_squared_error(y,y_hat))\n\nplt.rc('figure',figsize=(20,11))\nplt.rc('font',size=12)","e5ee0d3d":"a_data =pd.read_csv('\/kaggle\/input\/amazon-top-50-bestselling-books-2009-2019\/bestsellers with categories.csv')\na_data.head(3)\n","9729173f":"a_data.info()","1c8e5cb2":"#text Preprocessing\na_data['Name'] = a_data['Name'].apply(lambda x: x.lower())\na_data['Name'] = a_data['Name'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\nsid = SentimentIntensityAnalyzer()\na_data['Sentiment'] = a_data.Name.apply(lambda x:sid.polarity_scores(x))\na_data['Positive Sentiment'] = a_data.Sentiment.apply(lambda x: x['pos'])\na_data['Neutral Sentiment'] = a_data.Sentiment.apply(lambda x: x['neu'])\na_data['Negative Sentiment'] = a_data.Sentiment.apply(lambda x: x['neg'])\na_data['Compound Sentiment'] = a_data.Sentiment.apply(lambda x: x['compound'])\na_data.drop(columns=['Sentiment'],inplace=True)","595ef233":"info = a_data.iloc[:,:-5].describe()\ninfo.loc['median'] = a_data.median()\ninfo.loc['skew'] = a_data.skew()\ninfo.loc['kurtosis'] = a_data.kurt()\n\ninfo","42323a54":"ax =sns.distplot(a_data['User Rating'],bins=15)\nax.set_title('Distribution of ratings across the dataset',fontsize=19)\nplt.show()","f597e344":"plt.subplot(2,1,1)\nax =sns.distplot(a_data['Price'],color='red')\nax.set_title('Distribution of prices across the dataset',fontsize=19)\nplt.show()\nplt.subplot(2,1,2)\n#remove outliers\na_data = a_data.query('Price < 60')\nax =sns.distplot(a_data['Price'],color='red')\nax.set_title('Distribution of prices across the dataset (After Outlier Removal)',fontsize=19)\nplt.show()","12c9b2a8":"plt.subplot(2,1,1)\nax =sns.distplot(a_data['Reviews'],color='teal')\nax.set_title('Distribution of review counts across the dataset',fontsize=19)\nplt.show()\nplt.subplot(2,1,2)\na_data['Reviews'] =np.log(a_data['Reviews'])\nax =sns.distplot((a_data['Reviews']),color='teal')\nax.set_title('Distribution of review counts across the dataset',fontsize=19)\nplt.show()","d1484de8":"fig = ex.pie(a_data,names='Genre',title='Proportion Of Different Geners in Our Dataset',hover_data=['Genre'])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","d2fc674d":"pivot = a_data.pivot_table(values='Price',columns='Year',index='Genre')\nplt.title('Prices Of Each Genre Over The Years')\nsns.heatmap(pivot,annot=True)","61d846c0":"gby_year = a_data.groupby('Year').mean()\ngby_year_median = a_data.groupby('Year').median()\n\ntr1 = go.Scatter(x=gby_year.index,y=gby_year['Price'],name='Mean')\ntr2 = go.Scatter(x=gby_year_median.index,y=gby_year_median['Price'],name='Median')\n\n\nlayout = dict(title='Average Book Price Over The Years',yaxis_title='Mean Price',xaxis_title='Year')\nfig = go.Figure(data=[tr1,tr2],layout=layout)\n\n\nfig.show()","6e97d50d":"tr1 = go.Scatter(x=gby_year.index,y=gby_year['Reviews'],name='Mean')\ntr2 = go.Scatter(x=gby_year_median.index,y=gby_year_median['Reviews'],name='Median')\n\nlayout = dict(title='Average Book Review Count Over The Years',yaxis_title='Mean Number Of Reviews',xaxis_title='Year')\ngo.Figure(data=[tr1,tr2],layout=layout)","23e41579":"tr1 = go.Scatter(x=gby_year.index,y=gby_year['User Rating'],name='Mean')\ntr2 = go.Scatter(x=gby_year_median.index,y=gby_year_median['User Rating'],name='Median')\n\nlayout = dict(title='Average Book User Rating Over The Years',yaxis_title='Mean Rating',xaxis_title='Year')\ngo.Figure(data=[tr1,tr2],layout=layout)","9005b3f6":"print('There are -{}- unique number of authors in our dataset!'.format(len(a_data['Author'].unique())))","89e618ee":"ax = sns.barplot(y=a_data['Author'].value_counts()[:10].index,x=a_data['Author'].value_counts()[:10].values,palette='mako')\nax.set_title('Top 10 Authors',fontsize=16)\nax.set_xlabel('Number Of Books in Our Dataset',fontsize=14)\nplt.show()","72e7d84b":"plt.subplot(3,1,1)\nsns.scatterplot(x=a_data['Compound Sentiment'],y=a_data['Price'])\nplt.subplot(3,1,2)\nsns.scatterplot(x=a_data['Compound Sentiment'],y=a_data['Reviews'])\nplt.subplot(3,1,3)\nsns.scatterplot(x=a_data['Compound Sentiment'],y=a_data['User Rating'])\nplt.show()","d500e881":"plt.subplot(3,1,1)\nax =sns.distplot((a_data[a_data['Compound Sentiment']>0]['Price']),label='Positive Compound')\nax =sns.distplot((a_data[a_data['Compound Sentiment']<0]['Price']),label='Negative Compound')\nplt.legend()\nplt.show()\nplt.subplot(3,1,2)\nax =sns.distplot((a_data[a_data['Compound Sentiment']>0]['Reviews']),label='Positive Compound')\nax =sns.distplot((a_data[a_data['Compound Sentiment']<0]['Reviews']),label='Negative Compound')\nplt.legend()\nplt.show()\nplt.subplot(3,1,3)\nax =sns.distplot((a_data[a_data['Compound Sentiment']>0]['User Rating']),label='Positive Compound')\nax =sns.distplot((a_data[a_data['Compound Sentiment']<0]['User Rating']),label='Negative Compound')\nplt.legend()\nplt.show()","0eae2b70":"plt.imshow(WordCloud(width=900,height=600,stopwords=STOPWORDS).generate(' '.join(a_data.Name.values)))\nplt.axis('off')\nplt.title('Most Frequent Words In Our Book Names',fontsize=16)\nplt.show()","3b3b242b":"NUMBER_OF_COMPONENTS = 180\n\nvectorizer = TfidfVectorizer()\nsp_matrix = vectorizer.fit_transform(a_data['Name'])\n\nsvd_truncer = TruncatedSVD(n_components=NUMBER_OF_COMPONENTS)\ndec_mat = svd_truncer.fit_transform(sp_matrix)","792f53f3":"cu_sum = np.cumsum(svd_truncer.explained_variance_ratio_)\ntr1 = go.Scatter(x=np.arange(0,len(cu_sum)),y=cu_sum)\nlayout=dict(yaxis_title='Explained Variance',xaxis_title='# Of Components',title='Explained Variance Of Name Tfidf Matrix Using {} Components'.format(NUMBER_OF_COMPONENTS))\ngo.Figure(data=[tr1],layout=layout)","67099d05":"train_x,test_x,train_y,test_y = train_test_split(dec_mat,a_data['Price'],random_state=42)\n\n\nLR_Pipe = Pipeline(steps = [('model',LinearRegression())])\nLR_Pipe.fit(train_x,train_y)    \nRF_Pipe = Pipeline(steps = [('model',RandomForestRegressor(random_state=42))])\nRF_Pipe.fit(train_x,train_y)    \n\n\nlr_predictions = LR_Pipe.predict(test_x)\nrf_predictions = RF_Pipe.predict(test_x)\n\nplt.subplot(2,1,1)\nplt.title('Linear Regression Residual Plot')\nsns.residplot(lr_predictions,test_y)\n\nplt.subplot(2,1,2)\nplt.title('Random Forest Residual Plot')\nsns.residplot(rf_predictions,test_y)\nplt.show()","13e7abbf":"L_Encoder = LabelEncoder()\nLR_Pipe.fit(dec_mat,a_data['Price'])\na_data['LR_Pred']  = RF_Pipe.predict(dec_mat)\na_data['Genre'] = L_Encoder.fit_transform(a_data['Genre'] )\n","0fbd5f31":"X = a_data[['Year','Genre','Compound Sentiment','LR_Pred']]\nY = a_data['Price']\nRF_Pipe.fit(X,Y)\n\nplt.title('Final Price Prediction Residuals sing Random Forest')\nax = sns.residplot(RF_Pipe.predict(X),Y)\ntextstr = f'RMSE: {np.round(rmse(RF_Pipe.predict(X),Y),2)}'\nprops = dict(boxstyle='round', facecolor='tab:blue', alpha=0.5)\nax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=29,\n        verticalalignment='top', bbox=props)\nplt.show()","fcdf6303":"output = pd.DataFrame({\"Actual\":Y,'Prediction':RF_Pipe.predict(X)})\n\nfig = make_subplots(\n    rows=3, cols=2,subplot_titles=('','Actual','Predictions','Residuals'),\n    vertical_spacing=0.09,\n    specs=[[{\"type\": \"table\",\"rowspan\": 3}     ,{\"type\": \"scatter\"}] ,\n           [None                               ,{\"type\": \"scatter\"}]            ,           \n           [None                               ,{\"type\": \"scatter\"}]                           \n          ]\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=np.arange(0,len(output[\"Actual\"])),\n        y=output[\"Actual\"],\n        mode=\"markers\",\n    ),\n    row=1, col=2\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=np.arange(0,len(output[\"Prediction\"])),\n        y=output[\"Prediction\"],\n        mode=\"markers\",\n    ),\n    row=2, col=2\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=np.arange(0,len(output[\"Prediction\"])),\n        y=output[\"Prediction\"]-output[\"Actual\"],\n        mode=\"markers\",\n    ),\n    row=3, col=2\n)\n\nfig.add_trace(\n    go.Table(\n        header=dict(\n            values=['Prediction','Actual'],\n            font=dict(size=10),\n            align=\"left\"\n        ),\n        cells=dict(\n            values=[output[k].tolist() for k in output.columns],\n            align = \"left\")\n    ),\n    row=1, col=1\n)\n\n\n\nfig.add_shape(type=\"line\",\n    x0=0, y0=(output[\"Prediction\"]-output[\"Actual\"]).mean(), x1=len(output[\"Prediction\"]), y1=(output[\"Prediction\"]-output[\"Actual\"]).mean(),\n    line=dict(\n        color=\"Red\",\n        width=2,\n        dash=\"dashdot\",\n    ),\n        name='Mean',\n        xref='x3', \n        yref='y3'\n)\n\nfig.update_layout(\n    height=800,\n    showlegend=False,\n    title_text=\"Prediction Evaluation\",\n)\n\nfig.show()","30406d60":"output = pd.DataFrame({'Book Name':a_data['Name'],'Year':a_data[\"Year\"],'Actual Price':a_data['Price'],'Predicted Price':RF_Pipe.predict(X)})\noutput.to_csv('Price_Prediction.csv',index=False)","661be1e7":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Year Based Analysis<\/h3>\n","58cfbeef":"### We will use the linear regression model for our meta feature, we see that in comparison to the random forest model it looks like the linear regression tends to show less heteroskedasticity.\n","d367b04f":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Price Prediction Using Stacking And Random Forest Model<\/h3>\n","a36188a5":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Text Based Analysis<\/h3>\n","ece88166":"### There is a clear trend, we can see that the average rating score increase with each year","4059804a":"### There is a clear trend, we can see that the average book price is decreasing with each year","6d8e04e8":"### We can see that both genres even though they are in different price ranges they are similarly experiencing a decrease in their price over the years.","392ed664":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Using The Book Name Feature as A Predictor For Price<\/h3>\n","64621f2d":"### We can clearly see that there is no significant change between the sentiment compounds and our numeric features (price, review counts, and rating) distribution","79faf24b":"### We can clearly see that there is no significant correaltion between the sentiment compounds and our numeric features (price, review counts, and rating)","5bacb0d4":"<a id=\"2\"><\/a>\n<h1 style=\"background-color:orange;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 15px 50px;\">Exploratory Data Analysis<\/h1>\n","055338d2":"### There is a clear trend, we can see that the average review count increases with each year","913e5244":"<a id=\"1.2\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Data Importation And Missing Value Assessment<\/h3>\n","364c9e71":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Libraries And Utilities<\/h3>\n","f6b82d30":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Numeric Variables Distributions<\/h3>\n"}}