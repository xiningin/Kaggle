{"cell_type":{"92199565":"code","70006bbe":"code","5fdc7baa":"code","7b82b6fa":"code","a5babe56":"code","8f337367":"code","c659c65e":"code","d43a394f":"code","38b7bc8b":"code","a1f940d1":"code","62122ad6":"code","7adc7d81":"code","c93181bb":"code","ff095ed3":"code","eda842cf":"code","0ef60aa1":"code","2cb84d72":"code","ee9b68b8":"code","7f7c4213":"code","d4abbc00":"code","8224b91f":"markdown","729ac746":"markdown","2576c222":"markdown","7f109c2d":"markdown"},"source":{"92199565":"!pip install livelossplot","70006bbe":"import os\nimport math\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom livelossplot import PlotLossesKerasTF\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.applications import VGG16, Xception\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, Activation\n\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\n\nfrom PIL import Image\nfrom PIL import ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n%matplotlib inline","5fdc7baa":"for dirname, _, filenames in os.walk('\/kaggle\/input\/yoga-pose-classification\/dataset'):\n    print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname))","7b82b6fa":"basedir = \"\/kaggle\/input\/yoga-pose-classification\/dataset\" # here below the train and validation data","a5babe56":"def removeCorruptedImages(path):\n    for filename in os.listdir(path):\n        try:\n            img = Image.open(os.path.join(path,filename))\n            img.verify() \n        except (IOError, SyntaxError) as e:\n            print('Bad file:', filename)\n            os.remove(os.path.join(path,filename))","8f337367":"# Yoga Set 1\nyoga_train_path = os.path.join(\"yoga_set1\",\"train\") # root for training\nyoga_test_path = os.path.join(\"yoga_set1\",\"test\") # root for testing\n\n# Yoga Set 2\n# yoga_train_path = os.path.join(\"yoga_set2\",\"train\") # root for training\n# yoga_test_path = os.path.join(\"yoga_set2\",\"test\") # root for testing\n\ntraindir = os.path.join(basedir,yoga_train_path) \nvaliddir = os.path.join(basedir,yoga_test_path) ","c659c65e":"\n# Yoga Set 1\nremoveCorruptedImages(os.path.join(traindir,'tree'))\nremoveCorruptedImages(os.path.join(traindir,'downdog'))\nremoveCorruptedImages(os.path.join(traindir,'warrior1'))\n\nremoveCorruptedImages(os.path.join(validdir,'tree'))\nremoveCorruptedImages(os.path.join(validdir,'downdog'))\nremoveCorruptedImages(os.path.join(validdir,'warrior1'))\n\n\n# Yoga Set 2\n# removeCorruptedImages(os.path.join(traindir,'goddess'))\n# removeCorruptedImages(os.path.join(traindir,'mountain'))\n# removeCorruptedImages(os.path.join(traindir,'warrior2'))\n\n# removeCorruptedImages(os.path.join(validdir,'goddess'))\n# removeCorruptedImages(os.path.join(validdir,'mountain'))\n# removeCorruptedImages(os.path.join(validdir,'warrior2'))\n","d43a394f":"train_datagen=ImageDataGenerator(rescale=1.\/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\ntest_datagen=ImageDataGenerator(rescale=1.\/255)","38b7bc8b":"batch_size=8\nprint(\"For Training: \")\ntrain_datagen = train_datagen.flow_from_directory(\n                  directory = traindir,\n                  target_size=(300,300),\n                  batch_size=batch_size,\n                  shuffle=True,\n                  color_mode=\"rgb\",\n                  class_mode='categorical')\n\nprint(\"\\nFor Testing: \")\nval_datagen = test_datagen.flow_from_directory(\n                directory = validdir,\n                target_size=(300,300),\n                batch_size=batch_size,\n                shuffle=False,\n                color_mode=\"rgb\",\n                class_mode='categorical')","a1f940d1":"# Loading Pretrained Model\n\n# base_model_path2 = \".\/pretrained_models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n# base_model =  Xception(weights=base_model_path1, include_top=False, input_shape=(300, 300, 3))\n\nbase_model_path1 = \".\/pretrained_models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbase_model = VGG16(weights=base_model_path1, include_top=False, input_shape=(300, 300, 3))","62122ad6":"output_neurons = 3\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=base_model.output_shape[1:]))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_neurons))\nmodel.add(Activation('softmax'))\n\n\nmodel = Model(inputs=base_model.input, outputs=model(base_model.output))\n\n\noptimizers = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9, nesterov=True)\nlosss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\nmodel.compile(loss=losss,\n             optimizer=optimizers,\n              metrics=['accuracy'])\n\nmodel.summary()","7adc7d81":"# Callbacks\n\nclass ConvolutionCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self,epoch,logs={}):\n            if(logs.get('accuracy')>=0.97 and logs.get('val_accuracy') >=0.92):\n                print(\"Reached greater than 97.0% accuracy so cancelling training!\")\n                self.model.stop_training = True\n                \nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.001, mode='auto')\ncheckpoint = keras.callbacks.ModelCheckpoint(\".\/checkpoints_models\/pose_classification_model_weights2.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\n\nconvolutionCallback = ConvolutionCallback()\ncallbacks = [PlotLossesKerasTF(), checkpoint,reduce_lr, convolutionCallback]","c93181bb":"# epoch_for_model2 = 5\nBATCH_SIZE = 16\n\nhistory = model.fit(train_datagen,\n                    epochs=4,\n                    validation_data = val_datagen,\n                    callbacks=callbacks\n                    )","ff095ed3":"plt.figure(0)\nplt.plot(history.history['loss'],'g', label=\"Loss\")\nplt.plot(history.history['val_loss'],'b',label=\"Validation Loss\")\nplt.plot(history.history['accuracy'],'r', label=\"Accuracy\")\nplt.plot(history.history['val_accuracy'],'black', label=\"Validation Accuracy\")\nplt.legend()\nplt.show()","eda842cf":"yoga_set1_model_save_path = \".\/final_models\/H5_Models\/Yoga_Set1.h5\"\n# yoga_set2_model_save_path = \".\/final_models\/H5_Models\/Yoga_Set2.h5\"\nmodel.save(yoga_set1_model_save_path)","0ef60aa1":"loaded_model = tf.keras.models.load_model('.\/final_models\/H5_Models\/Yoga_Set1.h5')\nloaded_model.summary()","2cb84d72":"## TFLite Import\n\ntf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = tf_lite_converter.convert()\n\nyoga_final_model_name = \"Yoga_Set1_TFLite_Model.tflite\"\n# yoga_final_model_name = \"Yoga_Set2_TFLite_Model.tflite\"\n\ntflite_model_name = yoga_final_model_name\nopen(tflite_model_name,\"wb\").write(tflite_model)\n\ndef get_file_size(file_path):\n    size = os.path.getsize(file_path)\n    return size\n\ndef convert_bytes(size, unit=None):\n    if unit == \"KB\":\n        return print('File size: ' + str(round(size \/ 1024, 3)) + ' Kilobytes')\n    elif unit == \"MB\":\n        return print('File size: ' + str(round(size \/ (1024 * 1024), 3)) + ' Megabytes')\n    else:\n        return print('File size: ' + str(size) + ' bytes')\n    \nconvert_bytes(get_file_size(tflite_model_name),\"MB\")","ee9b68b8":"model.evaluate(val_datagen)","7f7c4213":"yoga_labels = {0:\"downdog\",1:\"tree\",2:\"warrior1\"}\n# yoga_labels = {0:\"goddess\",1:\"mountain\",2:\"warrior2\"}","d4abbc00":"import numpy as np\nfrom keras.preprocessing import image\nimport matplotlib.image as mpimg\n\n# predicting images\npath = input(\"Enter Image Name (from 1-15) : \")\npath = \".\/dataset\/final_test\/yoga_set1\/\" + path + \".jpg\"\n\nimg = image.load_img(path, target_size=(300, 300))\nx = image.img_to_array(img)\n# print(x\/255)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = loaded_model.predict(images, batch_size=10)\n\nplt.axis(\"Off\")\nimg = mpimg.imread(path)\nplt.imshow(img)\nplt.show()\n\nprint(\"Class Predictions: \",classes)\npred_index = np.argmax(classes[0])\nprint(\"\\nPrediction is: \", yoga_labels[pred_index])","8224b91f":"## Testing ","729ac746":"## Saving Model","2576c222":"## Training","7f109c2d":"## Image Data Generator"}}