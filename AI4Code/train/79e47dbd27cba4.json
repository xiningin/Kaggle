{"cell_type":{"9e2eed48":"code","492a3126":"code","3a796129":"code","b71dc1fa":"code","22dc126c":"code","b86ef52f":"code","b107f732":"code","00db1f1a":"code","b10f09d5":"code","9a05df7f":"code","9d73eb57":"code","e2918302":"code","3e9c03c9":"code","660172f9":"code","98009a9e":"code","30e04302":"code","7fda90d4":"code","d6bbd83e":"code","075fb91e":"code","8d95db18":"code","39134bda":"code","90279960":"code","c141454d":"code","47492df6":"code","1306c1d7":"markdown","4362ccf6":"markdown","b348b873":"markdown","a4ba1f02":"markdown","7ddc1d86":"markdown","d52efb32":"markdown","4b24d6fb":"markdown","bc337ad8":"markdown","f2554307":"markdown","19a6fc86":"markdown","2176b958":"markdown","4ed92599":"markdown","6c75d48a":"markdown","d8adf88a":"markdown","ea53809d":"markdown","08bb63a3":"markdown","29a4beac":"markdown","fcc1023b":"markdown","707c2246":"markdown","f2436809":"markdown"},"source":{"9e2eed48":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","492a3126":"dataset= pd.read_csv('..\/input\/diabetes\/diabetes.csv')\nX=dataset.iloc[:,:-1].values\ny=dataset.iloc[:,-1].values","3a796129":"dataset.head()","b71dc1fa":"dataset.info()","22dc126c":"dataset.describe()","b86ef52f":"dataset.corr()","b107f732":"dataset.hist(figsize = (20,20))","00db1f1a":"# 0 - pink color scatter indicates No Diabetes\n# 1 - blue color scatter indicates Has Diabetes\nplt.rcParams['figure.figsize'] = (40, 41)\nplt.style.use('dark_background')\n\nsns.pairplot(dataset, hue = 'Outcome', palette = 'husl')\nplt.title('Pair plot for the data', fontsize = 40)\nplt.show()","b10f09d5":"dataset_copy = dataset.copy(deep = True)\ndataset_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = dataset_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(dataset_copy.isnull().sum())","9a05df7f":"dataset_copy['Glucose'].fillna(dataset_copy['Glucose'].mean(), inplace = True)\ndataset_copy['BloodPressure'].fillna(dataset_copy['BloodPressure'].mean(), inplace = True)\ndataset_copy['SkinThickness'].fillna(dataset_copy['SkinThickness'].median(), inplace = True)\ndataset_copy['Insulin'].fillna(dataset_copy['Insulin'].median(), inplace = True)\ndataset_copy['BMI'].fillna(dataset_copy['BMI'].median(), inplace = True)","9d73eb57":"dataset_copy.hist(figsize = (20,20))","e2918302":"# 0 - pink color scatter indicates No Diabetes\n# 1 - blue color scatter indicates Has Diabetes\nplt.rcParams['figure.figsize'] = (40, 41)\nplt.style.use('dark_background')\n\nsns.pairplot(dataset_copy, hue = 'Outcome', palette = 'husl')\nplt.title('Pair plot for the data', fontsize = 40)\nplt.show()","3e9c03c9":"plt.figure(figsize=(12,10))  \np=sns.heatmap(dataset.corr(), annot=True,cmap ='RdYlGn') ","660172f9":"plt.figure(figsize=(12,10))  \np=sns.heatmap(dataset_copy.corr(), annot=True,cmap ='RdYlGn') ","98009a9e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX= sc.fit_transform(dataset_copy.drop([\"Outcome\"],axis = 1))","30e04302":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1\/3,random_state=42, stratify=y)","7fda90d4":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0,C=1.0,max_iter=200)\nclassifier.fit(X_train,y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n#calculate the details Logistic Regression\nprint('train_score classifier',classifier.score(X_train,y_train))\nprint('test_score classifier',classifier.score(X_test,y_test))\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)\n","d6bbd83e":"from sklearn.svm import SVC\nsvcmodel = SVC(kernel='rbf',degree=3)\nsvcmodel.fit(X_train,y_train)\n\n# Predicting the Test set results SVM\ny_pred = svcmodel.predict(X_test)\n\n#calculate the details SVM\nprint('train_score svcmodel', svcmodel.score(X_train,y_train))\nprint('test_score svcmodel',svcmodel.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)\n","075fb91e":"from sklearn.neural_network import MLPClassifier\n\nmlp_model = MLPClassifier(hidden_layer_sizes=100 ,activation='relu',alpha=0.01,epsilon=1E-08)\nmlp_model.fit(X_train,y_train)\n\n# Predicting the Test set results NNClassifier Model\ny_pred = mlp_model.predict(X_test)\n\n#calculate the details NNClassifier Model\nprint('train_score mlp_model', mlp_model.score(X_train,y_train))\nprint('test_score mlp_model',mlp_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","8d95db18":"from sklearn.neighbors import KNeighborsClassifier\nKnnclassifier_model = KNeighborsClassifier(n_neighbors=11)\nKnnclassifier_model.fit(X_train,y_train)\n\n# Predicting the Test set results KNeighborsClassifier\ny_pred = Knnclassifier_model.predict(X_test)\n\n#calculate the details KNeighborsClassifier\nprint('train_score Knnclassifier_model', Knnclassifier_model.score(X_train,y_train))\nprint('test_score Knnclassifier_model',Knnclassifier_model.score(X_test,y_test))\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","39134bda":"from sklearn.tree import DecisionTreeClassifier\nDT_model=DecisionTreeClassifier(criterion='entropy')\nDT_model.fit(X_train,y_train)\n\n# Predicting the Test set results DecisionTreeClassifier Model\ny_pred = DT_model.predict(X_test)\n\n#calculate the details DecisionTreeClassifier Model\nprint('train_score DT_model', DT_model.score(X_train,y_train))\nprint('test_score DT_model',DT_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","90279960":"from sklearn.naive_bayes import GaussianNB\ngussian_model = GaussianNB(priors=None, var_smoothing=1e-09)\ngussian_model.fit(X_train,y_train)\n\n# Predicting the Test set results Naive Bayes\ny_pred = gussian_model.predict(X_test)\n\n#calculate the details Naive Bayes\nprint('train_score gussian_model', gussian_model.score(X_train,y_train))\nprint('test_score gussian_model',gussian_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","c141454d":"from sklearn.ensemble import RandomForestClassifier\n\nrfc= RandomForestClassifier(criterion='gini',n_estimators=200,max_depth=3)\nrfc.fit(X_train,y_train)\n\n# Predicting the Test set results RandomForestClassifier Model\ny_pred = rfc.predict(X_test)\n\n#calculate the details RandomForestClassifier Model\nprint('train_score rfc', rfc.score(X_train,y_train))\nprint('test_score rfc',rfc.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","47492df6":"r=[[classifier.score(X_train,y_train),svcmodel.score(X_train,y_train),Knnclassifier_model.score(X_train,y_train),gussian_model.score(X_train,y_train)\n   ,DT_model.score(X_train,y_train),mlp_model.score(X_train,y_train),rfc.score(X_train,y_train)],\n   [classifier.score(X_test,y_test),svcmodel.score(X_test,y_test),Knnclassifier_model.score(X_test,y_test),gussian_model.score(X_test,y_test)\n    ,DT_model.score(X_test,y_test),mlp_model.score(X_test,y_test),rfc.score(X_test,y_test)]]\n\n\nX = np.arange(7)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nplt.style.use('seaborn-notebook')\nax.bar(X+ 0.00,r[0], color = 'blue', width = 0.30,label = 'train score')\nax.bar(X+ 0.40, r[1], color = 'red', width = 0.30,label = 'test score')\nfor i,m in list(zip(X,r[0])):\n  plt.text(x = i ,y = m,s = m)\nfor i,m in list(zip(X,r[1])):\n  plt.text(x = i + 0.45 ,y = m,s = m)\nax.set_xlabel('Models')\nax.set_ylabel('score')\nax.set_xticklabels(('','classifier', 'SVC', 'KNN', 'Gussian', 'DT','MLP','RFC'))\nplt.legend()\nplt.show(10,10)","1306c1d7":"# Decision Tree Classification ","4362ccf6":"# Logistic Regression","b348b873":"# KNN","a4ba1f02":"# **Train The Model**","7ddc1d86":"# Heatmap for clean data","d52efb32":"# Heatmap for unclean data","4b24d6fb":"# **Importing Libraries**","bc337ad8":"# **Splitting Data**","f2554307":"# **It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values**\n","19a6fc86":"# PLOTS for Visualization and Insights","2176b958":"# Random Forest","4ed92599":"# **bar chart with labels For Models**","6c75d48a":"# SVM","d8adf88a":"# **Exploratory Data Analysis**","ea53809d":"# NN","08bb63a3":"# **Importing The Dataset**","29a4beac":"# **Plotting after Nan removal**","fcc1023b":"# **Feature Scaling**","707c2246":"# Naive Bayes","f2436809":"# Aiming to impute nan values for the columns in accordance with their distribution"}}