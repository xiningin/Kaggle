{"cell_type":{"f7a9853e":"code","fd0a47fb":"code","774456cc":"code","8a57ed80":"code","999cb14b":"code","c68b6954":"code","8818dc49":"code","aebfbabe":"code","5405bbbe":"code","4a5e1e1c":"code","b72a3bef":"code","fbafd60a":"code","fd8ba5d8":"code","a2e41924":"code","28d6d2b3":"code","2dd2cdd5":"code","81e5ed58":"code","1b6a4ed4":"code","6f708ee8":"code","18feaf0d":"code","3e89f163":"code","3f3cbef0":"code","c7925965":"code","304fd820":"code","d23eca93":"code","6b6f4808":"code","33db9a73":"code","11c3c3c7":"code","50978026":"code","c7cc4024":"code","a97ec5ab":"code","b5e19d87":"code","cb989121":"code","35022833":"code","7f003e13":"code","b2ae5fa2":"code","b06221bc":"code","f7bafe5c":"code","7727132a":"code","92cc36a4":"code","b94c5e7a":"code","91b7f769":"code","83aca0c2":"code","7ae743ba":"code","7de56240":"code","e193aa2d":"code","59e7ec00":"code","c4fc689d":"code","31e015cc":"code","c1637fce":"code","8539d878":"code","8c789780":"code","652b6166":"code","67655da2":"code","906079ce":"code","53bba646":"code","02704fb0":"code","7655d402":"code","e6d75d9f":"code","90ae0e2e":"code","1cb15207":"code","21c2e0cf":"code","c9905470":"code","108fdd4b":"code","b3c5f920":"code","ee5188ea":"code","3a5be67e":"code","4dced5e2":"code","8e8430de":"code","e5352825":"code","a469395c":"code","4a1ee923":"code","f44f23c4":"code","0e77c6bb":"code","69404382":"code","502ae601":"code","a8e59be7":"code","62319519":"code","f8c71791":"code","dad7c4f6":"markdown","a57e1a09":"markdown","d11d4c6c":"markdown","91cde7d9":"markdown","a1027f7e":"markdown","7b816de4":"markdown","173f74d2":"markdown","826f6dd0":"markdown","89e8ab52":"markdown","10093eb5":"markdown","ad14f389":"markdown","e42c0fbd":"markdown","b133e6d6":"markdown","709b1db9":"markdown","ccab8930":"markdown","e3094473":"markdown","c3da97e9":"markdown","f3d11257":"markdown","4c748450":"markdown","0512327d":"markdown","4a9d1cc2":"markdown","72ab0980":"markdown","67188572":"markdown","036d139a":"markdown","7406698f":"markdown","8acf9462":"markdown","c4b67c69":"markdown","d54a3a4a":"markdown","cc43f863":"markdown","d926a074":"markdown","de507d26":"markdown","5bfe5512":"markdown","ec1c3f64":"markdown","4b37307f":"markdown","c63d9946":"markdown","34ef6322":"markdown","a183938d":"markdown","2d99596d":"markdown","108547df":"markdown"},"source":{"f7a9853e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport missingno as msno\n#models \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n# ensamble\nfrom sklearn.ensemble import BaggingClassifier\n#Scale\nfrom sklearn.preprocessing import StandardScaler\n# To ignore unwanted warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.pipeline import Pipeline","fd0a47fb":"train = pd.read_csv('..\/input\/titanic\/train.csv')","774456cc":"test = pd.read_csv('..\/input\/titanic\/train.csv')","8a57ed80":"train.isna().sum()","999cb14b":"test.isna().sum()","c68b6954":"train.drop('Cabin',axis=1,inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)","8818dc49":"train.shape , test.shape","aebfbabe":"train.info()","5405bbbe":"test.info()","4a5e1e1c":"train.describe()","b72a3bef":"test.describe()","fbafd60a":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (18, 6))\n\n# train data \nsns.heatmap(train.isnull(), yticklabels=False, ax = ax[0], cbar=False, cmap='viridis')\nax[0].set_title('Train data')\n\n# test data\nsns.heatmap(test.isnull(), yticklabels=False, ax = ax[1], cbar=False, cmap='viridis')\nax[1].set_title('Test data');","fd8ba5d8":"# combined the both dataset to do  more EDA and cleaning to both of them at the same time\ncombind_data = pd.concat([train, test]).reset_index(drop=True)\ncombind_data.head()","a2e41924":"#Heatmap for numrical features correlation \ncmap = sns.cubehelix_palette(light = 0.95, as_cmap = True)\nsns.set(font_scale=1.2)\nplt.figure(figsize = (16,8))\nmask = np.zeros_like(combind_data.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(combind_data.corr(), vmin = 0, vmax = 1, square = True, cmap = cmap,mask=mask ,annot=True)\nplt.show();","28d6d2b3":"Fetures = ['Pclass' , 'SibSp' , 'Parch' ,'Sex','Embarked']","2dd2cdd5":"def bar_plt(f1 , f2 , title ):\n    fig, ax = plt.subplots(figsize=(16,8))\n    ax= sns.barplot(x=f1, y=f2, data=combind_data , ax=ax, palette='Set3' , hue=f2);\n    ax.set_title(title , fontsize =20);","81e5ed58":"for i in Fetures:\n    title= \"The relation between \"+ i + ' Survived'\n    bar_plt('Survived', i , title )","1b6a4ed4":"#### creat a box plot with swarm plot of the columns ####\nfig = plt.figure(figsize=(10,5))\nsns.boxplot(x='Survived', y='Fare', data=combind_data, whis=np.inf);\nsns.swarmplot(x='Survived', y='Fare', data=combind_data, color=\".2\");\nplt.xticks(rotation=70);\nplt.title('Survived & Fare');\nplt.show()","6f708ee8":"def outlier(df,col): \n ##### Check the outliers  #####\n        #get the value of Q1 using describe()\n        q1 = df.describe()[col]['25%']\n        #get the value of Q2 using describe()\n        q3 = df.describe()[col]['75%']\n        #calculate the IQR\n        iqr = q3-q1 \n        #calculate the distance \n        distance = 1.5*iqr\n        #caluclate the lower limit \n        lower_limit = q1-distance \n        #caluclate the upper limit \n        higher_limit = q3+ distance \n\n        outlier_num=0\n        #itrate through list of total \n        for t in df[col] : \n            #check if the total < lower limit or t>higher limit \n            if t < lower_limit or t > higher_limit  :\n                #increase the counter \n                outlier_num +=1 \n        #print the number of outlires \n        print ( f\"There are :\" , outlier_num , \" outliers data \")","18feaf0d":"def check_distribution(df,col):\n    \n    ##### get the descriptive Statistics (median, mean, mode) #####\n    skwe_ = df[col].skew()\n    median=df[col].median()\n    mean=df[col].mean()\n    mode=df[col].mode()[0]\n\n    ##### Check the disrubtion #####\n    if median < mean :\n         print (\"It Has a positive skew and it's distribution is not normal based on the skewness which is = \" , skwe_ ,\"\\n\"  )\n    elif  median> mean:\n          print (\"It has a negative skew and it's distribution is normal based on the skewness which is = \" , skwe_  ,\"\\n\" )\n    else : \n          print (\"It has a normal disribution \\n\")","3e89f163":"numerical = pd.DataFrame(combind_data.select_dtypes(exclude=['object']))\nnumerical.drop(['PassengerId','Survived'],axis=1,inplace=True)","3f3cbef0":"ss=StandardScaler()\n# Scale all numeric feature\nnumeric_scale=ss.fit_transform(numerical)\nnumeric_scale","c7925965":"scaled_df=pd.DataFrame(numeric_scale)\nscaled_df.columns=['Pclass','Age','SibSp','Parch','Fare']\nfig, ax6 = plt.subplots(figsize=(16,8))\nsns.boxplot(data=scaled_df,ax=ax6)\nplt.title('Boxplots of numerical features');","304fd820":"for i in scaled_df:\n    print(i,'feature:')\n    outlier(numerical,i)\n    check_distribution(numerical,i)","d23eca93":"msno.matrix(combind_data,labels=True);","6b6f4808":"train.Embarked.value_counts()","33db9a73":"train=train.fillna({'Embarked' : 'S'})","11c3c3c7":"train.Embarked.isna().sum()","50978026":"test[test['Fare'].isnull()]","c7cc4024":"test[test.Pclass == 3]","a97ec5ab":"print(f\"The mean fare for the Pclass (for missing fare data) is:  {test.Fare[test.Pclass == 3].mean()}\")","b5e19d87":"test.Fare[test.Pclass == 3] = test.Fare[test.Pclass == 3].fillna(test.Fare[test.Pclass == 3].mean())","cb989121":"test.Fare.isna().sum()","35022833":"train.groupby([ 'Pclass'])[['Age']].mean()","7f003e13":"#defining a function 'impute_age'\ndef impute_age(age_pclass): # passing age_pclass as ['Age', 'Pclass']\n    \n    # Passing age_pclass[0] which is 'Age' to variable 'Age'\n    Age = age_pclass[0]\n    \n    # Passing age_pclass[2] which is 'Pclass' to variable 'Pclass'\n    Pclass = age_pclass[1]\n    \n    #applying condition based on the Age and filling the missing data respectively \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 38\n\n        elif Pclass == 2:\n            return 30\n\n        else:\n            return 25\n\n    else:\n        return Age","b2ae5fa2":"# (for train) grab age and apply the impute_age, our custom function \ntrain['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)\n# (for test) grab age and apply the impute_age, our custom function \ntest['Age'] = test[['Age','Pclass']].apply(impute_age,axis=1)\nprint(f'train part \\n{train.isna().sum()}')","b06221bc":"# CODE HERE PLEASE\nprint(f'test part \\n{test.isna().sum()}')","f7bafe5c":"# re-check the missing values\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (18, 6))\n\n# train data \nsns.heatmap(train.isnull(), yticklabels=False, ax = ax[0], cbar=False, cmap='viridis')\nax[0].set_title('Train data')\n\n# test data\nsns.heatmap(test.isnull(), yticklabels=False, ax = ax[1], cbar=False, cmap='viridis')\nax[1].set_title('Test data');","7727132a":"# drop hopless features\ntrain.drop('PassengerId',axis=1, inplace=True)\ntest.drop('PassengerId',axis=1, inplace=True)\ntrain.drop('Name',axis=1, inplace=True)\ntest.drop('Name',axis=1, inplace=True)\ntrain.drop('Ticket',axis=1, inplace=True)\ntest.drop('Ticket',axis=1, inplace=True)","92cc36a4":"train[['Sex','Embarked','Pclass' , 'Survived']]= train[['Sex','Embarked' ,'Pclass' ,'Survived']].astype('category')\ntrain.dtypes        ","b94c5e7a":"train = pd.get_dummies(train, columns=['Sex','Embarked' ,'Pclass' , 'Survived'],drop_first=True)\ntrain.head(3)","91b7f769":"test[['Sex','Embarked','Pclass']]= test[['Sex','Embarked' ,'Pclass']].astype('category')\ntest.dtypes  ","83aca0c2":"test = pd.get_dummies(test, columns=['Sex','Embarked' ,'Pclass' ],drop_first=True)\ntest.head(3)","7ae743ba":"#Target and X\ny = train.pop('Survived_1')\nX = train.copy(deep=True)","7de56240":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True, random_state=42)","e193aa2d":"baseline_acc= 1.-train[y==1].shape[0]\/train.shape[0]\nbaseline_acc","59e7ec00":"baseline_acc= 1.-train[y==0].shape[0]\/train.shape[0]\nbaseline_acc","c4fc689d":"rf_params = {\n     'n_estimators': [10, 50, 100],\n     'max_features':[2, 3, 5, 7, 8,None],\n     'max_depth': [1, 2, 3, 4, 5, 8,None],\n     'criterion':['gini', 'entropy']\n}","31e015cc":"rf = RandomForestClassifier() \nrf_gs = GridSearchCV(rf, param_grid=rf_params, cv=5, verbose = 1)\nrf_gs.fit(X_train, y_train)","c1637fce":"pred_rf_gs = rf_gs.predict(X_test)\npred_rf_gs[:10]","8539d878":"rf_gs.score(X_train, y_train)","8c789780":"rf_gs.score(X_test, y_test)","652b6166":"cross_val_score(rf_gs , X_train, y_train, cv=5).mean()","67655da2":"et_params = {\n    'n_estimators': [10, 50, 100],\n    'max_features':[2, 3, 5, 7, 8,None],\n    'max_depth': [1, 2, 3, 4, 5, 8,None],\n    'criterion':['gini', 'entropy']\n}","906079ce":"et = ExtraTreesClassifier()\net_gs  = GridSearchCV(et, param_grid=et_params, cv=5, verbose = 1)\net_gs.fit(X_train, y_train)","53bba646":"pred_et_gs = et_gs.predict(X_test)\npred_et_gs[:10]","02704fb0":"et_gs.score(X_train, y_train)","7655d402":"et_gs.score(X_test, y_test)","e6d75d9f":"cross_val_score(et_gs , X_train, y_train, cv=5).mean()","90ae0e2e":"param_grid = {\n    'n_neighbors': [3, 5, 7, 9, 11, 20, 50, 100],\n    'weights': ['uniform', 'distance'],\n    'metric': ['manhattan', 'euclidean','minkowski']\n    \n}\nknn2 = KNeighborsClassifier()\nknn_gs = GridSearchCV(knn2, \n                  param_grid, \n                  cv=5,\n                  scoring='roc_auc',\n                  verbose=1)\nknn_gs.fit(X_train, y_train)","1cb15207":"pred_knn_gs = knn_gs.predict(X_test)\npred_knn_gs[:10]","21c2e0cf":"knn_gs.score(X_train, y_train)","c9905470":"knn_gs.score(X_test, y_test)","108fdd4b":"cross_val_score(knn_gs , X_train, y_train, cv=5).mean()","b3c5f920":"param_grid2 = {\n    'base_estimator__n_neighbors': [ 5, 10, 50, 100],\n    'base_estimator__weights': ['uniform', 'distance'],\n    'base_estimator__metric': ['manhattan', 'euclidean','minkowski'],\n    'max_features': [0.6,0.8,None],\n    'n_estimators': [50, 200], \n    'max_samples':[0.5,0.8]\n}\n    \nmodel = BaggingClassifier(base_estimator=KNeighborsClassifier())\nmodel_gs = GridSearchCV(model,param_grid2, cv=5,scoring='roc_auc', verbose=1, n_jobs=-1 )\nmodel_gs.fit(X_train, y_train)","ee5188ea":"pred_model_gs=model_gs.predict(X_test)\npred_model_gs[:10]","3a5be67e":"model_gs.score(X_train, y_train)","4dced5e2":"model_gs.score(X_test, y_test)","8e8430de":"cross_val_score(model_gs,X_train, y_train, cv=5).mean()","e5352825":"logreg_params = {'C': [0.1, 0.2,0.3], \n                 'fit_intercept': [True, False],\n                 'penalty': ['l1', 'l2']}","a469395c":"logreg=LogisticRegression()\nlogreg_gs = GridSearchCV(logreg, logreg_params,cv=5, verbose=1)\nlogreg_gs.fit(X_train, y_train)","4a1ee923":"logreg_prediction=logreg_gs.predict(X_test)\nlogreg_prediction[:10]","f44f23c4":"logreg_gs.score(X_train, y_train)","0e77c6bb":"logreg_gs.score(X_test, y_test)","69404382":"cross_val_score(logreg_gs,X_train, y_train, cv=5).mean()","502ae601":"features_drop = ['PassengerId','Name', 'Ticket', 'Survived']\n\nselected_features = [i for i in train.columns if i not in features_drop]","a8e59be7":"# RandomForestClassifier\npred_rf= rf_gs.predict(test[selected_features])\n# ExtraTreeClassifier\npred_et = et_gs.predict(test[selected_features])\n# KNN\npred_knn = knn_gs.predict(test[selected_features])\n# KNN with BaggingClassifier\npred_knn_bag = model_gs.predict(test[selected_features])\n# LogesticRegression\npred_logreg = logreg_gs.predict(test[selected_features])","62319519":"# # RandomForestClassifier\n# test['Survived'] = pred_rf\n# ExtraTreeClassifier\n# test['Survived'] = pred_et\n# # LogesticRegression\n# test['Survived'] = pred_logreg\n# test['Survived'] = pred_knn\n# KNN with BaggingClassifier\ntest['Survived'] = pred_knn_bag","f8c71791":"test[['PassengerId', 'Survived']].to_csv('submissionRF.csv',index=False)\n\ntest[['PassengerId', 'Survived']].to_csv('submissionET.csv',index=False)\n\ntest[['PassengerId', 'Survived']].to_csv('submissionKNN.csv',index=False)\n\ntest[['PassengerId', 'Survived']].to_csv('submissionKNN_bag.csv',index=False)","dad7c4f6":"## Modeling\n---","a57e1a09":"**check the `Pclass` of missing fare in test dataset**","d11d4c6c":"- There are alot of features affect on the Survived ,which are Pclass, SibSp , Parch ,Sex, Embarked . \n- Using clasification models to predit the Survived pasengers . \n- The best model for predict the Survived pasengers was RandomForestClassifier .\n- The RandomForestClassifier model has 0.9002808988764045 train score .\n- Based on our investagition we found the pasengers, which have many of their family members in the ship has dead.\n- Also we found the female Survived pasengers more than the meale Survived pasengers. \n- We recommend to do more future resaerch to use advanced models for clasification predictions .\n- Also we recommend to use more other information to get best predictions.","91cde7d9":"## Import libraries\n---\n\nWe'll need the following libraries in this project :\n- `pandas`\n- `numpy`\n- `GridSearchCV`, `train_test_split` and `cross_val_score` from `sklearn`'s `model_selection` module \n- `RandomForestClassifier` and `ExtraTreesClassifier` from `sklearn`'s `ensemble` module ","a1027f7e":"# Problem Statement","7b816de4":"### Age feature","173f74d2":"**Now we'll impute the missing values of `Fare` with its mean**","826f6dd0":"**Compute the average of `Fare` of the missing `Pclass` when Pclass == 3**","89e8ab52":"## Impute the missing values ","10093eb5":"Everyone knows about the accident that happened in Titanic ships on the end at the night of 15th April 1912, which led to the loss of many lives, so this project aims to investigate the Titanic ships by using classification models to predict whether a passenger would survive or not survive with a lot of given features. <br> \nThese models are able to accurately estimate the survived passengers based on given features , we will evaluate our models using Cross validation Score and R^2 Score .","ad14f389":"<img src=\"https:\/\/image.freepik.com\/free-vector\/shipwreck-accident-ship-run-aground-sink-ocean_33099-2210.jpg\" style=\" height: 80px , width: 80px\">","e42c0fbd":"## Detecting missing values","b133e6d6":"# Save Submission file\n\n---\n","709b1db9":"## KNN with BaggingClassifier","ccab8930":"# Bi-variate analysis","e3094473":"\n\n<h1 style ='text-align: center;' >  Project 2 - Titanic <h1\/> \n","c3da97e9":"## ExtraTreesClassifier","f3d11257":"**Convert `Sex` , `Embarked`, `Pclass`, and `Survived` columns in train and test datasets**","4c748450":"### Fare feature","0512327d":"### One Hot Encoding","4a9d1cc2":"**Use the above function to both of datasets (train and test) and fill the missing data in `Age` column accordingly**","72ab0980":"**Create these heatmaps, yellow are the missing data**. ","67188572":"we found these features that have a missing values : \n* In train: `Age`, `Cabin` and `Embarked`\n* In test: `Age`, `Fare` and `Cabin`\n<br>So depend on this observation we decide to drop Cabin feature because it has more than half of its data as missing values. ","036d139a":"**we will fill them with the port of highest embarkation**","7406698f":"Here we'll focus on the meaningfull features such as Pclass, SibSp, Parch, Sex, and Embarked","8acf9462":"# LogesticRegression","c4b67c69":"## KNN","d54a3a4a":"### Embarked feature","cc43f863":"## Data Preprocessing And Feature Engineering ","d926a074":"**we will find how many ports are in Embarked feature**","de507d26":"## RandomForestClassifier","5bfe5512":"# Univariate analysis & detecting outliers  ","ec1c3f64":"**Now we'll get the baseline accuracy**","4b37307f":"**What is the mean age of each Pclass in the train data.**","c63d9946":"# Team members : \n**Group 5** <br> \n\n**Reem Alruqi - kholoud Alowis - Waad Alotaibi**","34ef6322":"## EDA phase","a183938d":"## Load Data\n---\n\nLoad titanic `train.csv` and `test.csv` from Kaggle into `DataFrames`.","2d99596d":"# Conclusion and Recommendations\n---","108547df":"**Calculate the mean `age` with respect to each `Pclass`**"}}