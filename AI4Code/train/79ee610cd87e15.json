{"cell_type":{"14b25e35":"code","0fbbca02":"code","f149ad0e":"code","6187bf95":"code","e70a32da":"code","2360c1d7":"code","0dd885dc":"code","d89a8e77":"code","d44d5779":"code","366a024e":"code","e5cd9d15":"code","0bd684b0":"code","246018ea":"code","0e6e1420":"code","13750dc0":"code","1dcd013e":"code","e5b172c1":"code","bfc5b23c":"code","bea704d3":"code","04e879d3":"code","0c6dd4a5":"code","b946ac1e":"code","0f8003f6":"code","1ffa3bbc":"code","f0d69bba":"code","b4c9d0a5":"code","4da92751":"code","10484cd7":"code","2213c37e":"code","8ac7ca37":"code","4ccdad98":"code","b911450b":"code","6cbed0fb":"code","3a20fa5a":"code","fe5870d7":"code","9ad4a845":"code","dbaea443":"code","a28bddb6":"code","399d6e07":"code","513d09a0":"code","517912d7":"code","3b32d1d9":"code","f5cdde8d":"code","09d90e49":"code","c356c2eb":"code","c3c4ca32":"code","a674c3f0":"code","643662a7":"code","b08aa39c":"code","7fdd597a":"code","36ee2519":"code","1d4bc8bd":"code","b455433f":"code","5147d11b":"code","f4abc074":"code","06da722f":"code","bb149145":"code","e0a9ecfd":"code","1647b925":"code","46507c9a":"code","59ebd50f":"code","5277b6d3":"code","05c8a38d":"code","fa2bd350":"code","627ba8e9":"code","a24ff3e0":"code","deb2d07b":"code","5696f854":"code","71ef0ff4":"code","09441ffb":"code","61374257":"code","d8fa55ac":"code","7dfffa76":"code","707a7602":"code","cf6b62dd":"markdown","d2dfb498":"markdown","9eff0458":"markdown","42cfe360":"markdown","3cd039ee":"markdown","29184a57":"markdown","66e7a9b5":"markdown","f88e34ac":"markdown","1859ab3c":"markdown","2ee66f3d":"markdown","4ae8254a":"markdown","afb13fa1":"markdown","88da56e3":"markdown","6f2eb696":"markdown","361ad6ae":"markdown","0f52a169":"markdown"},"source":{"14b25e35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fbbca02":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom sklearn.feature_selection import SelectFromModel","f149ad0e":"pd.set_option('display.max_rows', None)","6187bf95":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv', sep=',')\nsub_sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv', sep=',')\ntest= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv', sep=',')","e70a32da":"test.info()","2360c1d7":"print(train.shape, test.shape, sub_sample.shape)","0dd885dc":"sub_sample.head()","d89a8e77":"train.info()","d44d5779":"train.head()","366a024e":"train.isna().sum()","e5cd9d15":"train.describe()","0bd684b0":"train = train.set_index('PassengerId')","246018ea":"train.groupby(by=['Pclass'])['Fare'].median()","0e6e1420":"train.loc[(train['Fare'].isna()) & (train['Pclass']==1), 'Fare']=63.58\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2), 'Fare']=22.72\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3), 'Fare']=10.96","13750dc0":"train['Age'] = train['Age'].replace(np.nan, train['Age'].median())","1dcd013e":"train['Cabin'] =train['Cabin'].str[0]","e5b172c1":"#train[train['Cabin'].isna()].groupby(by=['Pclass', 'Fare'])['Survived'].sum()","bfc5b23c":"train['Cabin'] = train['Cabin'].fillna('Z')","bea704d3":"train.groupby(by=['Cabin'])['Survived'].mean()","04e879d3":"df_cabin = pd.get_dummies(train['Cabin'], prefix='Cabin')","0c6dd4a5":"train.groupby(by=['Embarked'])[['Fare','Survived']].mean()","b946ac1e":"train[train['Embarked'].isna()].groupby(by=['Pclass'])['Survived'].mean()","0f8003f6":"#train.loc[(train['Embarked'].isna()) & (train['Pclass']==1), 'Embarked']='Z1'\n#train.loc[(train['Embarked'].isna()) & (train['Pclass']==2), 'Embarked']='Z2'\n#train.loc[(train['Embarked'].isna()) & (train['Pclass']==3), 'Embarked']='Z3'\ntrain['Embarked'] = train['Embarked'].fillna('S')","1ffa3bbc":"df_embarked = pd.get_dummies(train['Embarked'], prefix='Embark')","f0d69bba":"train['Ticket'] = train['Ticket'].str.replace('[^a-zA-Z]', '').str[:2]\ntrain['Ticket'] = train['Ticket'].str.strip()","b4c9d0a5":"train['Ticket'] = train['Ticket'].fillna('ZZ')","4da92751":"train.loc[train['Ticket']=='', 'Ticket']='NN'","10484cd7":"train.groupby(by=['Ticket'])['Survived'].mean()","2213c37e":"df_tiket = pd.get_dummies(train['Ticket'], prefix='ticket')","8ac7ca37":"#train['Name'] = train['Name'].str.split(',',1).str[0]","4ccdad98":"#test['Survived'] =2\n#df_name = pd.concat([train, test], axis=0)","b911450b":"#df_name.groupby(by=['Name','Pclass','Sex','Age','Survived'])['Fare'].mean()","6cbed0fb":"df_name = pd.concat([train['Name'], test['Name']], axis=0)","3a20fa5a":"le = LabelEncoder()\ndf_name = le.fit_transform(df_name)","fe5870d7":"train['Name'] = le.transform(train['Name'])","9ad4a845":"train['Name'].head()","dbaea443":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x=='female' else 0)","a28bddb6":"train['Sex'].value_counts()","399d6e07":"train['Pclass'] = train['Pclass'].astype('str')\ndf_pclass = pd.get_dummies(train['Pclass'], prefix='class')","513d09a0":"df_pclass.head()","517912d7":"# introducing a new feature : the size of families (including the passenger)\ntrain['FamilySize'] = train['Parch'] + train['SibSp'] + 1","3b32d1d9":"# introducing other features based on the family size\ntrain['Singleton'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFamily'] = train['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntrain['LargeFamily'] = train['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","f5cdde8d":"df = pd.concat([train['Fare'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'], train['Sex'], df_cabin, df_tiket, df_pclass, df_embarked ,train['Name'],train['Survived']], axis=1)","09d90e49":"#incuding the Name encoder\ndf1 = pd.concat([train['Fare'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'], train['Sex'],df_cabin, df_tiket, df_pclass, df_embarked], axis=1)","c356c2eb":"df.columns","c3c4ca32":"plt.figure(figsize=(15,10))\nsns.heatmap(data=df.corr())","a674c3f0":"df = df.drop(columns='Survived')","643662a7":"df.head()","b08aa39c":"km = KMeans(n_clusters=3, random_state=22, n_init=20)\ndf_km = km.fit_predict(df)\ndf_km = pd.DataFrame(df_km, index=df.index)\ndf_km = df_km.astype('str')\ndf_km = pd.get_dummies(df_km)","7fdd597a":"df_km.head()","36ee2519":"df = pd.concat([df, df_km], axis=1)","1d4bc8bd":"df_target = train['Survived']","b455433f":"clf = RandomForestClassifier(n_estimators=200, max_features='sqrt')\nclf = clf.fit(df, df_target)","5147d11b":"features = pd.DataFrame()\nfeatures['feature'] = df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","f4abc074":"import optuna","06da722f":"def objective(trial , data = df , target = df_target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.028059109276941666 , random_state = 22)\n\n    #test_size = 0.028059109276941666\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 10),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 1e-5 , 10),\n        'num_leaves' : trial.suggest_int('num_leaves' , 11 , 800),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.0000001 , 0.1),\n        'max_depth' : trial.suggest_int('max_depth' , 5 , 400),\n        'n_estimators' : trial.suggest_int('n_estimators' , 1 , 9999),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 110),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'subsample' : trial.suggest_uniform('subsample' , 1e-5 , 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree' , 1e-5 , 1),\n        'random_state' : trial.suggest_categorical('random_state' , [1,22,2022,1509]),\n        'metric' : 'accuracy',\n        'device_type' : 'cpu',\n    }\n    model = lightgbm.LGBMClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] ,eval_metric='logloss', early_stopping_rounds = 2000 , \\\n             verbose = False)\n    preds = model.predict(test_x)\n    acc = accuracy_score(test_y , preds)\n    return acc","bb149145":"study = optuna.create_study(direction = 'maximize' , study_name = 'lgbm')\nstudy.optimize(objective , n_trials = 1)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","e0a9ecfd":"#the best value: 0.7808267997148967\nparams= {'reg_alpha': 0.000493095633250276, 'reg_lambda': 0.2799468729577344, 'num_leaves': 220, 'learning_rate': 0.058683299033376934, 'max_depth': 97, 'n_estimators': 9161, 'min_child_samples': 108, 'min_child_weight': 1.7359084365325016e-05, 'subsample': 0.7381682823837273, 'colsample_bytree': 0.29845810314125426, 'random_state': 1509}","1647b925":"#the best value: 0.7811831789023521\nparams2 = {'reg_alpha': 0.02242367265240423, 'reg_lambda': 0.0006085533155144086, 'num_leaves': 238, 'learning_rate': 0.03240605916351265, 'max_depth': 65, 'n_estimators': 5361, 'min_child_samples': 27, 'min_child_weight': 0.00011308353926700071, 'subsample': 0.5688435861948473, 'colsample_bytree': 0.06746586089945723, 'random_state': 22}","46507c9a":"#the best value: 0.7804704205274412\nparams1= {'reg_alpha': 0.009415444471348289, 'reg_lambda': 1.2556528225033043, 'num_leaves': 25, 'learning_rate': 0.00835886426230468, 'max_depth': 230, 'n_estimators': 3653, 'min_child_samples': 9, 'min_child_weight': 0.0002224399318225647, 'subsample': 0.9780174338845454, 'colsample_bytree': 0.7969641118752326, 'random_state': 1}","59ebd50f":"test = test.set_index('PassengerId')\n\n#Fare\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1), 'Fare']=63.58\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2), 'Fare']=22.72\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3), 'Fare']=10.96\n\n#Age\ntest['Age'] = test['Age'].replace(np.nan, test['Age'].median())\n\n#Cabin\ntest['Cabin'] =test['Cabin'].str[0]\ntest['Cabin'] = test['Cabin'].fillna('Z')\ndft_cabin = pd.get_dummies(test['Cabin'], prefix='Cabin')\n\n#Embarked\n#test.loc[(test['Embarked'].isna()) & (test['Pclass']==1), 'Embarked']='Z1'\n#test.loc[(test['Embarked'].isna()) & (test['Pclass']==2), 'Embarked']='Z2'\n#test.loc[(test['Embarked'].isna()) & (test['Pclass']==3), 'Embarked']='Z3'\ntest['Embarked'] = test['Embarked'].fillna('S')\ndft_embarked = pd.get_dummies(test['Embarked'], prefix='Embark')\n\n#Ticket\ntest['Ticket'] = test['Ticket'].str.replace('[^a-zA-Z]', '').str[:2]\ntest['Ticket'] = test['Ticket'].str.strip()\ntest['Ticket'] = test['Ticket'].fillna('ZZ')\ntest.loc[test['Ticket']=='', 'Ticket']='NN'\ndft_tiket = pd.get_dummies(test['Ticket'], prefix='ticket')\n\n#Name\n#test['Name'] = test['Name'].str.split(',',1).str[0]\ntest['Name'] = le.transform(test['Name'])\n\n#Sex\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x=='female' else 0)\n\n#Pclass\ntest['Pclass'] = test['Pclass'].astype('str')\ndft_pclass = pd.get_dummies(test['Pclass'], prefix='class')\n\n#Family Size\ntest['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n\ntest['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntest['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","5277b6d3":"dft = pd.concat([test['Fare'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'],dft_cabin,dft_tiket, dft_pclass, dft_embarked, test['Name']], axis=1)","05c8a38d":"dft1 = pd.concat([test['Fare'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'], dft_cabin, dft_tiket, dft_pclass, dft_embarked], axis=1)","fa2bd350":"dft.head()","627ba8e9":"dft_km = km.predict(dft)\ndft_km = pd.DataFrame(dft_km, index=dft.index)\ndft_km = dft_km.astype('str')\ndft_km = pd.get_dummies(dft_km)","a24ff3e0":"dft = pd.concat([dft, dft_km], axis=1)","deb2d07b":"dft.columns","5696f854":"list(set(df.columns)-set(dft.columns))","71ef0ff4":"df_target.head()","09441ffb":"params1['metric'] = 'accuracy'\nparams1['device'] = 'cpu'\npreds = np.zeros(dft.shape[0])\noof_preds = np.zeros(df.shape[0])\nkf = StratifiedKFold(n_splits = 15 , random_state = 22 , shuffle = True)\nroc = []\nn = 0\nfor trn_idx , val_idx in kf.split(df , df_target):\n    train_x = df.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model = lightgbm.LGBMClassifier(**params1)\n    model.fit(train_x , train_y , eval_set = [(val_x , val_y)] ,eval_metric='logloss', early_stopping_rounds = 8000 , verbose = False)\n    clf = CalibratedClassifierCV(model, cv='prefit', method='sigmoid')\n    clf.fit(train_x , train_y)\n    preds += clf.predict_proba(dft)[:,1]\/kf.n_splits\n    oof_preds += clf.predict_proba(df)[:,1]\/kf.n_splits\n    roc.append(accuracy_score(val_y , clf.predict(val_x)))\n    fpr, tpr, thresholds = roc_curve(val_y , clf.predict_proba(val_x)[:,1])\n    gmeans = np.sqrt(tpr * (1-fpr))\n    ix = np.argmax(gmeans)\n    print(n+1 , roc[n], 'Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n    n+=1","61374257":"sub_sample.head()","d8fa55ac":"sub_sample['Survived'] = preds","7dfffa76":"#simple threshold\nsub_sample['Survived'] = sub_sample['Survived'].apply(lambda x: 1 if x>0.405749 else 0)","707a7602":"sub_sample.to_csv('submission.csv',index=False)","cf6b62dd":"Keep only the first 2 letter for ticket and replace space with N and nan wi1th ZZ","d2dfb498":"# Using Optuna with Lgbm","9eff0458":"### Data Preprocessing","42cfe360":"Convert NAN to ZZ","3cd039ee":"One Hot encoder for Pclass","29184a57":"Convert '' with NN","66e7a9b5":"## Preprocessing the Test_set","f88e34ac":"## Load Data","1859ab3c":"For Cabin Feature, estract only the first letter, then fillna with Z","2ee66f3d":"Analysis of possible strategy to fillna for Embarked field.\nSince the Passenger Class seems to be correlated to the possibility to Survive. 3 different embark classes will be created to fillna","4ae8254a":"Using Only the Surname from the \"Name\" field","afb13fa1":"### Utils","88da56e3":"Strategy to fillna for Fare will be based on the median value of Passenger Class","6f2eb696":"Get the Fatures related to Family size. An idea taken from:\nhttps:\/\/medium.datadriveninvestor.com\/start-with-kaggle-a-comprehensive-guide-to-solve-the-titanic-challenge-8ac5815b0473","361ad6ae":"using the Median to fill all the NAN for Age","0f52a169":"Encoding the sex feature"}}