{"cell_type":{"c640ac95":"code","e47620fb":"code","da4ee5a3":"code","ae377a99":"code","61c23f07":"code","f73d50f9":"code","2218843e":"code","a22ac434":"code","e43c45e3":"code","74df7e72":"code","8e7a99e3":"code","a97779a2":"code","48a7476a":"code","5062435c":"code","d68bddaa":"code","072865a8":"code","3c7e6bec":"code","98140a0c":"code","8afe23cd":"code","648c8f2c":"code","afcdc94f":"code","7dc95b83":"code","8914488b":"code","8db1aa1e":"code","64978a4f":"code","6bf4ed30":"code","35c3df48":"code","ceeae6c8":"code","b2715a4d":"code","d579b6c3":"code","4cb0336c":"code","35912ecd":"code","61294a7f":"code","dee7118a":"code","54703273":"code","240aa3d3":"code","388788fb":"code","4fcf569a":"code","02cd50a8":"code","65ad26d3":"markdown","d1598108":"markdown","d91c900a":"markdown","1b4e9c62":"markdown","c084d2c8":"markdown","b4ec6dc1":"markdown","07c51d13":"markdown","ccad39d2":"markdown","d7ea3b6d":"markdown","d5e7c4ed":"markdown"},"source":{"c640ac95":"# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e47620fb":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","da4ee5a3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ae377a99":"df_items = pd.read_csv(dirname + '\/items.csv') \ndf_item_categories = pd.read_csv(dirname + '\/item_categories.csv') \ndf_sales_train = pd.read_csv(dirname + '\/sales_train.csv') \ndf_shops = pd.read_csv(dirname + '\/shops.csv') \ndf_test = pd.read_csv(dirname + '\/test.csv') ","61c23f07":"df_items.info()","f73d50f9":"df_item_categories.info()","2218843e":"df_test.info()","a22ac434":"df_shops.info()","e43c45e3":"df_sales_train.info()","74df7e72":"df_sales_train.describe().T","8e7a99e3":"df_items.head()","a97779a2":"df_item_categories.head()","48a7476a":"df_shops.head()","5062435c":"df_test.head()","d68bddaa":"df_sales_train","072865a8":"# We use the shop_id and item_id as index and the value of date_block_num as columns with item_cnt_day as values\ndf_sales = df_sales_train.pivot_table(index = ['shop_id', 'item_id'],\n                                values = 'item_cnt_day',\n                                columns = 'date_block_num',\n                                fill_value = 0,\n                                aggfunc = np.sum)\ndf_sales.reset_index(inplace=True)","3c7e6bec":"df_sales","98140a0c":"dataset = df_test.merge(df_sales, on=['shop_id', 'item_id'], how='left')\ndataset.fillna(0, inplace=True)","8afe23cd":"dataset","648c8f2c":"df = dataset.drop(columns=['ID', 'shop_id', 'item_id'])","afcdc94f":"X = df.values[:, :-1]\ny = df.values[:, -1:]\nprint(y)","7dc95b83":"print(X.shape, y.shape)","8914488b":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state = 42)","8db1aa1e":"X_test = df.values[:, 1:]\nprint(X_test.shape)","64978a4f":"scaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\nprint(X_test.shape)","6bf4ed30":"X_train.shape, y_train.shape ","35c3df48":"X_val.shape, y_val.shape","ceeae6c8":"# Liner Regression model\nmodel_LR = linear_model.LinearRegression()","b2715a4d":"# Decision Tree Regressor model\nmodel_DTR = DecisionTreeRegressor(random_state = 101)","d579b6c3":"# Random Forest\nmodel_RF = RandomForestRegressor(random_state = 101)","4cb0336c":"# Function to find Mean Squared Error\ndef MSE(model, X_train, y_train, X_val, y_val):\n    \n    model.fit(X_train, y_train)\n    y_predict = model.predict(X_val)\n    \n    return mean_squared_error(y_val, y_predict)","35912ecd":"# Getting the Mean Square error for various models\nbest_mse = MSE(model_LR, X_train, y_train, X_val, y_val)\nmodel = model_LR\nprint(\"MSE with Linear Regression \\t:\", best_mse)","61294a7f":"mse_dtr = MSE(model_DTR, X_train, y_train, X_val, y_val)\nprint(\"MSE with Decision Tree Regressor:\", mse_dtr)\n\nif mse_dtr < best_mse:\n    best_mse = mse_dtr\n    model = model_DTR","dee7118a":"mse_rf = MSE (model_RF, X_train, y_train.ravel(), X_val, y_val)\nprint(\"MSE with Random Forest:\", mse_rf)\n\nif mse_rf < best_mse:\n    best_mse = mse_rf\n    model = model_RF","54703273":"# Make predictions using the validation set\ny_predict = model.predict(X_val)\ny_predict.shape","240aa3d3":"predictions = model.predict(X_test)\n\n# Let's eliminate the negative numbers\npredictions = predictions.clip(min = 0)","388788fb":"print(predictions)","4fcf569a":"submission = pd.DataFrame({'ID': dataset['ID'], 'item_cnt_month': np.round(predictions)})\nsubmission","02cd50a8":"submission.to_csv('submission.csv',index=False)","65ad26d3":"We leave the last column of the dataframe for label (y) and the other columns for the features (X)","d1598108":"### Data Description\nAs we can see the info() method show us that there are no null values. This is part of our Data Quality Verification","d91c900a":"We perform 90\/10 data split train and validation set","1b4e9c62":"### Data Exploration","c084d2c8":"### Prediction results\nLet's check how well our model predict","b4ec6dc1":"### Collect initial data\nWe import the datasets to be use in this project. Those can be obtained from [Kaggle](https:\/\/www.kaggle.com\/c\/competitive-data-science-predict-future-sales\/data)","07c51d13":"We are going to focus on the df_sales_train, which is dataframe we are going to use mainly.","ccad39d2":"We use various models to test which one has better performance","d7ea3b6d":"### Model training","d5e7c4ed":"## Predict Future Sales\n\n### Objective\nWe are asking you to predict total sales for every product and store in the next month. You are provided with daily historical sales data. Note that the list of shops and products slightly changes every month."}}