{"cell_type":{"5fe252ce":"code","aae46c52":"code","86e3e24c":"code","96fbb05c":"code","214e81db":"code","71202f26":"code","33e5570f":"code","d74d2fc7":"code","952f0f49":"code","bfe5d247":"code","6cd32020":"code","60e1e69b":"code","947be713":"code","010d1ea6":"code","2fd1166d":"code","44536d0c":"code","4e0eae72":"code","98dc5d19":"code","c60cd619":"code","fbf2a89c":"code","31af4cb8":"code","27a22caa":"code","114b7f69":"code","d2fdd283":"code","2ddae782":"code","74b87516":"code","99b9f62b":"code","35a1d6fc":"code","8cd393b1":"code","0095c962":"code","7d0d84b1":"code","4a93355f":"code","69fd7d47":"code","dba8ef13":"code","f52f2495":"code","43eff15b":"code","da97c210":"code","1c04ec89":"code","fab3db84":"code","8f9c9cea":"code","98cb5fdd":"code","859fd847":"code","98a06313":"code","49157c7b":"code","d2b81a02":"code","df9f6ec3":"code","24431ab5":"code","0645e784":"code","4e06e36f":"code","e0560fa3":"code","ac6a5905":"code","66b5e92d":"code","13745589":"code","a21a6a3a":"code","bc79a2cd":"code","f1549ffc":"code","3fb318ee":"code","1ffcf72a":"code","f0cfbc29":"markdown","b6c7e5b7":"markdown","939f2085":"markdown","2354c87b":"markdown","b25a6288":"markdown","47401d51":"markdown","e1c5f589":"markdown","e10b226b":"markdown","420f37c4":"markdown","9632ca72":"markdown","2c4317a7":"markdown","48bf7437":"markdown","6709a394":"markdown","65856201":"markdown","fefb136a":"markdown","57520dd9":"markdown","4db87f8c":"markdown","330e154a":"markdown","bd551344":"markdown","f1881868":"markdown","2ca276d8":"markdown","5c9e526d":"markdown","17238c89":"markdown","5ddb2d78":"markdown"},"source":{"5fe252ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aae46c52":"# Load user, ratings, and movie data\nusers_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\nusers = pd.read_csv(\n    '..\/input\/movielens-data\/ml-100k\/u.user', sep='|', names=users_cols, encoding='latin-1')\n\nratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\nratings = pd.read_csv(\n    '..\/input\/movielens-data\/ml-100k\/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n\n# The movies file contains a binary feature for each genre.\ngenre_cols = [\n    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n]\nmovies_cols = [\n    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n] + genre_cols\nmovies = pd.read_csv('..\/input\/movielens-data\/ml-100k\/u.item', sep='|', names=movies_cols, encoding='latin-1')","86e3e24c":"ratings.head","96fbb05c":"ratings.dtypes","214e81db":"input_query_df = pd.read_csv(\"..\/input\/inquery\/Movielens (Responses) - Form Responses 1.csv\")\nquery_len = len(input_query_df)\n\n# Only get the latest response\ninput_query_df = input_query_df[-1:]","71202f26":"# Only keep movies and ratings in dataframe\ninput_genres_df = input_query_df['Out of all of the genres below, what are your top 3 favorites?']\ninput_query_df = input_query_df.drop(['Out of all of the genres below, what are your top 3 favorites?', 'Timestamp'], axis = 1)\ninput_query = input_query_df.to_dict()\nprint(input_query)","33e5570f":"# Turn into dict{movie_id: rating}\ninput_ratings = {}\npossible_ratings = ['1', '2', '3', '4', '5']\nfor movie in input_query:\n    rating = input_query[movie][query_len-1]\n    title_row = movies.loc[movies['title'] == movie]\n    title_row\n    movie_id = title_row.iloc[0]['movie_id']\n    if rating[0] in possible_ratings:\n        input_ratings[movie_id] = int(rating[0])\n    \n\nprint(input_ratings)","d74d2fc7":"# Get user input's top 3 favorite genres\ninput_genres = input_genres_df.values.tolist()[0].split(',')\nprint(input_genres)","952f0f49":"# Add to ratings\n\nnew_user = '944'\n\nuser = ['944'] * 10\ninput_movies = []\ninput_ratings = [5] * 10\ninput_time = [0] * 10\n\n# Sample: all children's movies\ninput_movies.append(\"1\")\ninput_movies.append(\"8\")\ninput_movies.append(\"63\")\ninput_movies.append(\"71\")\ninput_movies.append(\"35\")\ninput_movies.append(\"1531\")\ninput_movies.append(\"1540\")\ninput_movies.append(\"91\")\ninput_movies.append(\"94\")\ninput_movies.append(\"95\")\n\n# # Append to ratings\nnew_ratings = {'user_id':user, 'movie_id': input_movies, 'rating': input_ratings, 'unix_timestamp': input_time}\nadd_ratings = pd.DataFrame(data = new_ratings)\nadd_ratings['user_id'] = add_ratings['user_id'].astype(int)\nadd_ratings['movie_id'] = add_ratings['movie_id'].astype(int)\n# ratings = ratings.append(add_ratings, ignore_index = True)\nratings = pd.concat([add_ratings, ratings]).reset_index(drop = True)\nratings.head(20)\n","bfe5d247":"#ratings.drop(ratings.tail(10).index,inplace=True)\nratings.shape","6cd32020":"# Look up title row for children's\nfor movie in input_movies:\n    kids_row = movies.loc[movies['movie_id'] == int(movie)]\n    print(kids_row)","60e1e69b":"# Look up kid's movies\nkids_row = movies.loc[movies['Children'] == 1]\nkids_row.head(20)","947be713":"users.dtypes","010d1ea6":"# Create new user\n\nnew_person = pd.DataFrame(data = {'user_id': 944, 'age': 21}, index = [0])\nusers = users.append(new_person, ignore_index = True)\nusers.tail","2fd1166d":"users.dtypes","44536d0c":"# 0-index data\nusers[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\nmovies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\nmovies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\nratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: str(x-1))\nratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: str(x-1))\nratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))","4e0eae72":"print(users)","98dc5d19":"print(ratings)","c60cd619":"print(movies)","fbf2a89c":"print(type(movies['movie_id'].values[0]))","31af4cb8":"# Look at how top 15 users rated top 15 movies \n# top = highest counts\ng1 = ratings.groupby('user_id')['rating'].count()\ntop_users = g1.sort_values(ascending=False)[:15]\ng2 = ratings.groupby('movie_id')['rating'].count()\ntop_movies = g2.sort_values(ascending=False)[:15]\ntop_r = ratings.join(top_users, rsuffix='_r', how='inner', on='user_id')\ntop_r = top_r.join(top_movies, rsuffix='_r', how='inner', on='movie_id')\npd.crosstab(top_r.user_id, top_r.movie_id, top_r.rating, aggfunc=np.sum)","27a22caa":"# Remove users with low amount of ratings","114b7f69":"# List of all genres\nmovies.columns\nprint(top_movies.index)\ntop_movies_list = top_movies.index.values.tolist()\ntop_movies_list = [str(movie) for movie in top_movies_list]\nprint(top_movies_list)","d2fdd283":"top15_movies = movies.loc[movies['movie_id'].isin(top_movies_list)]\nprint(top15_movies)\nprint(top15_movies['title'])","2ddae782":"# Create combined ratings + titles\n\n# Get titles and genre only\n# labels = ['release_date', 'video_release_date', 'imdb_url', 'year']\n# titles = movies.drop(columns = labels)\n# print(titles)\n# combined_ratings = ratings.join(titles.set_index('movie_id'), on = 'movie_id')\n# print(type(titles))","74b87516":"# Remove movies that have very little ratings\n\nmovie_counts = g2.sort_values(ascending=True)\nmovie_counts = movie_counts.to_frame()\nprint(movie_counts)","99b9f62b":"counts = movie_counts.value_counts()\nprint(counts)\n\n#from matplotlib.pyplot import plot\ncounts[:20].plot.bar()\n","35a1d6fc":"print(movie_counts.index)","8cd393b1":"# Remove ratings of movies with less than 10 ratings\n\nten = [i for i in range(11)]\n\n#for i in range(11):\n    ","0095c962":"from sklearn.preprocessing import LabelEncoder\n\n# user_enc = LabelEncoder()\n# ratings['user'] = user_enc.fit_transform(ratings['user_id'].values)\n# item_enc = LabelEncoder()\n# ratings['movie'] = item_enc.fit_transform(ratings['movie_id'].values)\n# min_rating = min(ratings['rating'])\n# max_rating = max(ratings['rating'])\n\n# Get unique users, movies\nnum_users = ratings['user_id'].nunique()+1\nnum_movies = ratings['movie_id'].nunique()\n\nratings['movie_id'] = ratings['movie_id'].values.astype(int)\nratings['user_id'] = ratings['user_id'].values.astype(int)\n\nprint(ratings)\nnum_users, num_movies","7d0d84b1":"ratings.sample(frac = 1)","4a93355f":"from sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\n\nX = ratings[['user_id', 'movie_id']].values # Input = user and movie\n#X = ratings[['user', 'movie']].values # Input = user and movie\ny = ratings[['rating']].values # Output = rating\n\n# One hot encode output (ratings)\nratings_enc = LabelEncoder()\nratings_enc.fit(y)\nencoded_ratings = ratings_enc.transform(y)\nencoded_ratings = np_utils.to_categorical(encoded_ratings)\nprint(encoded_ratings)\n\n# Train\/test split\nX_train, X_test, y_train, y_test = train_test_split(X, encoded_ratings, test_size = 0.2, random_state = 42)\n\n# Put user and movies into their own arrays (for Keras)\nX_train_arrs = [X_train[:, 0], X_train[:, 1]]\nX_test_arrs = [X_test[:, 0], X_test[:, 1]]\n\nprint(X_train)","69fd7d47":"from tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Embedding, Dot, Input, Reshape, Lambda, Concatenate, Add, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\n\nnum_factors = 50\n","dba8ef13":"# User embedding\nuser_input = Input(shape = (1,))\n#layer_embed_users = embed_layer(user_input, num_users, num_factors)\nlayer_embed_users = Embedding(\n    name = 'user_embedding',\n    input_dim = num_users, \n    output_dim = num_factors, \n    embeddings_initializer = 'he_normal', \n    embeddings_regularizer = l2(1e-6))(user_input)\nlayer_embed_users = Reshape(target_shape = ((num_factors),))(layer_embed_users) # why is target_shape = 50??\n\n# Movie embedding\nmovie_input = Input(shape = (1,))\n#layer_embed_movies = embed_layer(user_input, num_movies, num_factors)\nlayer_embed_movies = Embedding(\n    name = 'movie_embedding',\n    input_dim = num_movies, \n    output_dim = num_factors, \n    embeddings_initializer = 'he_normal', \n    embeddings_regularizer = l2(1e-6))(movie_input)\nlayer_embed_movies = Reshape(target_shape = ((num_factors),))(layer_embed_movies)\n","f52f2495":"layer_embed_users = Dropout(0.5)(layer_embed_users)\nlayer_embed_movies = Dropout(0.5)(layer_embed_movies)","43eff15b":"layer = Concatenate()([layer_embed_users, layer_embed_movies])\nlayer = Dropout(0.5)(layer)","da97c210":"print(layer)","1c04ec89":"layer = Dense(128, activation='relu', kernel_initializer='he_normal')(layer)\nlayer = Dropout(0.5)(layer)\n# layer = Dense(10, activation='relu', kernel_initializer='he_normal')(layer)\n# layer = Dropout(0.5)(layer)","fab3db84":"final_layer = Dense(5, activation = 'softmax')(layer)\n#final_layer = Lambda(lambda final_layer: final_layer * (max_rating - min_rating) + min_rating)(final_layer)\n","8f9c9cea":"# Make neural net model using layers\nnn_model = Model(inputs = [user_input, movie_input], outputs = final_layer)\n\nfrom tensorflow.keras.metrics import CategoricalCrossentropy\n\n# Compile model\nnn_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) # LOSS ONLY FOR SOFTMAX (NOT WORKING)\n#nn_model.compile(optimizer = Adam(lr = 0.001), loss = 'mean_squared_error', metrics = ['accuracy'])","98cb5fdd":"nn_model.summary()","859fd847":"nn_model.fit(X_train_arrs, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test_arrs, y_test))","98a06313":"from matplotlib.pyplot import plot\n\n#plot(nn_model_fit.history['loss'])\n#plot(nn_model_fit.history['val_loss'])","49157c7b":"# use ints for both inputs\nnewuser = np.array([[942]]) \nnewmovies = np.array([[5]])\nto_predict = np.array(X_test_arrs)\nynew = nn_model.predict([[newuser, newmovies]]) # for this user, predict output for this movie\nprint(\"X=%s, Predicted=%s\" % (newuser[0], ynew))","d2b81a02":"print(type(newmovies))","df9f6ec3":"# see if correct\nrow = movies.loc[movies['movie_id'] == '1']\nrow2 = ratings.loc[ratings['user_id'] == 1]\nmovie1 = row2.loc[row2['movie_id'] == 291]\nrow3 = row2.sort_values('rating', ascending = False)\nprint(row3)\nprint(row2)\nprint(movie1)","24431ab5":"# Find unranked movies for user 1\nuser_id = 12\nunranked_movies = []\nnum_total_movies = 1682\nuser_ratings = ratings.loc[ratings['user_id'] == user_id]\nprint(f\"User {user_id} has only watched\/ranked {len(user_ratings.index)} out of {num_total_movies} movies total.\")    \nprint(f\"Therefore, we can predict how he will rate {num_total_movies - len(user_ratings.index)} other movies.\")","0645e784":"print(user_ratings)","4e06e36f":"import random\n\nuser_values = user_ratings['movie_id'].values \nprint(user_values)\nfor i in range(num_total_movies):\n    if i not in user_values:\n        unranked_movies.append(i)\n#random.shuffle(unranked_movies)\n#random.shuffle(unranked_movies)\n#random.shuffle(unranked_movies)\nprint(unranked_movies)","e0560fa3":"def get_genres(row):\n    genres = []\n    \n    labels = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url', 'year']\n    genres_df = row.drop(columns = labels)\n    \n    for genre in genres_df.columns:\n        if genres_df[genre].iat[0] == 1:\n            genres.append(genre)\n            \n    return genres","ac6a5905":"title_row = movies.loc[movies['movie_id'] == str(0)]\nprint(title_row)\ngenres = get_genres(title_row)\nprint(genres)","66b5e92d":"# Predict only the first 15 movies\ndef find_movie_recs(movies_to_rec, movies_df, curr_user):\n    to_predict = movies_to_rec[:100]\n    titles = []\n    enjoyment = []\n    genres = []\n\n    for movie in to_predict:\n        prediction = nn_model.predict([[np.array([[curr_user]]), np.array([[movie]])]])\n        rating = prediction[0][4]\n        enjoyment.append(rating)\n        title_row = movies_df.loc[movies_df['movie_id'] == str(movie)]\n        title = title_row.iloc[0]['title']\n        titles.append(title)\n        genres.append(get_genres(title_row))\n        \n    d = {'title': titles, 'enjoyment': enjoyment, 'genres': genres}\n    recs = pd.DataFrame(data = d)\n    return recs\n\ndef raw_ratings(movies_to_rec, movies_df, user_id):\n    to_predict = movies_to_rec[:15]\n    print(to_predict)\n    titles = []\n    enjoyment = []\n    raw_preds = []\n\n    for movie in to_predict:\n        prediction = nn_model.predict([[np.array([[user_id]]), np.array([[movie]])]])\n        preds = prediction[0].tolist()\n        raw_preds.append(preds)\n        print(raw_preds)\n        \n        #find actual rating class\n        rating = preds.index(max(preds)) + 1\n        \n        enjoyment.append(rating)\n        title_row = movies_df.loc[movies_df['movie_id'] == str(movie)]\n        title = title_row.iloc[0]['title']\n        titles.append(title)\n        \n    d = {'movie_id': to_predict, 'title': titles, 'raw': raw_preds, 'rating': enjoyment}\n    recs = pd.DataFrame(data = d)\n    return recs","13745589":"movies.sample(frac = 1)","a21a6a3a":"# Check and see if model matches user's previous ratings\nrated_movies = []\nfor i in range(num_total_movies):\n    if i in user_ratings['movie_id'].values:\n        rated_movies.append(i)\nprint(rated_movies[:15])","bc79a2cd":"#already_watched = raw_ratings(rated_movies, movies)\n","f1549ffc":"row3.head(15)","3fb318ee":"recs = find_movie_recs(unranked_movies, movies, user_id)\nrecs = recs.sort_values('enjoyment', ascending = False)\nprint(recs)","1ffcf72a":"# recs['genres'].value_counts().plot.bar()","f0cfbc29":"Train\/test split","b6c7e5b7":"Feature engineering ? lol","939f2085":"^^ tried loss = binary_crossentropy but very, very low accuracy lol (< 0.07)","2354c87b":"# Predicting - test","b25a6288":"An embedding allows for categorical values (movie titles) to be mapped to numerical representations.","47401d51":"^^ this model is insanely overfitted ?\n\noutput: predicted ratings","e1c5f589":"# Post-processing data ","e10b226b":"## Cleaning up ","420f37c4":"# Begin here","9632ca72":"### Softmax (final layer)","2c4317a7":"### Create model","48bf7437":"### For user_id = 1","6709a394":"Merge the two embedding spaces together into a single layer","65856201":"# Preprocessing","fefb136a":"### Other layers ???","57520dd9":"Fit the model\n\nWant loss --> 0, accuracy --> 1","4db87f8c":"# Recommending a movie\n\nFor only one movie a user would like recs for. ","330e154a":"# Add new user to dataset","bd551344":"# Get user input query","f1881868":"There are only 5 ratings: 1, 2, 3, 4, 5","2ca276d8":"# Neural Net model","5c9e526d":"These work but have to re-run script b\/c if ran once, then df saves with new changes already","17238c89":"### The top 15 movies we recommend:","5ddb2d78":"### Embedding layers"}}