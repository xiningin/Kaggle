{"cell_type":{"643e7f1e":"code","1590c43b":"code","39be7201":"code","5f2e8388":"code","8b4af96a":"code","60fce4bb":"code","130cebf6":"code","b7da5005":"code","091fb32b":"code","6714a07d":"code","7ded5395":"code","c7f9af9f":"code","c93a1ce1":"code","d7830098":"code","78f0715a":"code","eb1f3800":"code","94c66d7d":"code","4cb71491":"code","3362e2c1":"code","c34b2bbe":"code","c15c8a48":"code","99ae443f":"code","3c393bcb":"code","2cb04c6c":"code","4977ddb8":"code","6d6144d8":"code","532da7b4":"code","1ac2a14f":"code","5b592fe8":"code","ccab871d":"code","c7e5de39":"code","6ce98579":"code","588541a9":"code","47ce2d18":"markdown"},"source":{"643e7f1e":"!pip install -q efficientnet","1590c43b":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nfrom tqdm import tqdm\nfrom glob import glob\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12,8)\nplt.rcParams['axes.titlesize'] = 16\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\nimport efficientnet.tfkeras as efn\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\n\nimport os\nprint(os.listdir('..\/input\/alaska2-image-steganalysis'))","39be7201":"path = '\/kaggle\/input\/alaska2-image-steganalysis\/'\nfolders = ['JUNIWARD', 'JMiPOD', 'UERD', 'Cover']","5f2e8388":"sub = pd.read_csv('..\/input\/alaska2-image-steganalysis\/sample_submission.csv')\nprint(sub.shape)\nsub.head()","8b4af96a":"plt.suptitle('Images from Cover', fontsize = 16)\nfor i, img in enumerate(os.listdir('..\/input\/alaska2-image-steganalysis\/Cover')[:12]):\n    plt.subplot(3, 4, i + 1)\n    img = mpimg.imread('..\/input\/alaska2-image-steganalysis\/Cover\/' + img)\n    plt.imshow(img)","60fce4bb":"plt.suptitle('Images from JMiPOD', fontsize = 16)\nfor i, img in enumerate(os.listdir('..\/input\/alaska2-image-steganalysis\/JMiPOD')[:12]):\n    plt.subplot(3, 4, i + 1)\n    img = mpimg.imread('..\/input\/alaska2-image-steganalysis\/JMiPOD\/' + img)\n    plt.imshow(img)","130cebf6":"plt.suptitle('Images from JUNIWARD', fontsize = 16)\nfor i, img in enumerate(os.listdir('..\/input\/alaska2-image-steganalysis\/JUNIWARD')[:12]):\n    plt.subplot(3, 4, i + 1)\n    img = mpimg.imread('..\/input\/alaska2-image-steganalysis\/JUNIWARD\/' + img)\n    plt.imshow(img)","b7da5005":"plt.suptitle('Images from UERD', fontsize = 16)\nfor i, img in enumerate(os.listdir('..\/input\/alaska2-image-steganalysis\/UERD')[:12]):\n    plt.subplot(3, 4, i + 1)\n    img = mpimg.imread('..\/input\/alaska2-image-steganalysis\/UERD\/' + img)\n    plt.imshow(img)","091fb32b":"train_files = np.array(os.listdir(path + 'Cover\/'))\nprint(len(train_files))\ndisplay(train_files[:5])","6714a07d":"train_df = pd.DataFrame(columns = ['tag', 'file_path', 'target'])","7ded5395":"np.random.seed(0)\nnp.random.shuffle(train_files)","c7f9af9f":"start = 0\nend = 10000\nsteg_paths = []\nfor tag in folders[:3]:\n    for file in train_files[start: end]:\n        full = tag + '\/' + file\n        steg_paths.append(full)\n    start += 10000\n    end += 10000\nsteg_paths[:5], len(steg_paths)","c93a1ce1":"np.random.shuffle(train_files)\ncover_paths = []\nfor file in train_files[:30000]:\n    full = 'Cover' + '\/' + file\n    cover_paths.append(full)\ncover_paths[-5:], len(cover_paths)","d7830098":"img_files = steg_paths + cover_paths\nlen(img_files)","78f0715a":"train_df['file_path'] = img_files\ntrain_df['tag'] = train_df['file_path'].apply(lambda x: x.split('\/')[0])\nflag = {'JUNIWARD': 1, 'JMiPOD': 1, 'UERD': 1, 'Cover': 0}\ntrain_df['target'] = train_df['tag'].map(flag)\ntrain_df = train_df.sample(frac = 1).reset_index(drop = True)\ntrain_df","eb1f3800":"sns.countplot(train_df['tag'])","94c66d7d":"test_df = pd.DataFrame(columns = ['file_path', 'label'])\n\ntest_paths = []\n\nfor file in sub['Id']:\n    full = 'Test' + '\/' + file\n    test_paths.append(full)\n\ntest_df['file_path'] = test_paths\ntest_df","4cb71491":"print(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","3362e2c1":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nprint(BATCH_SIZE)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_DS_PATH)","c34b2bbe":"#Format path for TPU\n\ndef format_path(pt):\n    return os.path.join(GCS_DS_PATH, pt)","c15c8a48":"train_paths = train_df['file_path'].apply(format_path).values\ntest_paths = test_df['file_path'].apply(format_path).values\n\ntrain_targets = train_df['target'].values","99ae443f":"train_paths[:5], train_targets[:5]","3c393bcb":"train_path, valid_path, train_label, valid_label = train_test_split(train_paths, train_targets, test_size = 0.2, random_state = 2019)\nprint(train_path.shape, train_label.shape, valid_path.shape, valid_label.shape)","2cb04c6c":"def decode_image(filename, label = None, image_size = (512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels = 3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label = None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","4977ddb8":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_path, train_label))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .cache()\n    .repeat()\n    .shuffle(1024)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_path, valid_label))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls = AUTO)\n    .batch(BATCH_SIZE)\n)","6d6144d8":"with strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB7(\n            input_shape = (512, 512, 3),\n            weights = 'imagenet',\n            include_top = False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1, activation = 'sigmoid')\n    ])\n        \n    model.compile(\n        optimizer = 'adam',\n        loss = 'binary_crossentropy',\n        metrics = ['accuracy']\n    )\n    model.summary()","532da7b4":"STEPS_PER_EPOCH = train_label.shape[0] \/\/ BATCH_SIZE\n\ncheckpoint = ModelCheckpoint('model_tpu.h5',monitor = 'val_loss', save_best_only = True, verbose = 1, period = 1)\n\nreduceLR = ReduceLROnPlateau(monitor = 'val_loss', min_lr = 0.00001, patience = 3, mode = 'min', verbose = 1)","1ac2a14f":"for l in model.layers:\n    print(l)\n    l.trainable = False\n    \nhist = model.fit(train_dataset, epochs = 3, steps_per_epoch = STEPS_PER_EPOCH, validation_data = valid_dataset,\n                 callbacks = [checkpoint, reduceLR])\n\ndel hist\ngc.collect()","5b592fe8":"EPOCHS = 10\n\nhistory = model.fit(train_dataset, epochs = EPOCHS, steps_per_epoch = STEPS_PER_EPOCH, validation_data = valid_dataset,\n                 callbacks = [checkpoint, reduceLR])","ccab871d":"def display_training_curves(training, validation, title, subplot):\n    \"\"\"\n    Source: https:\/\/www.kaggle.com\/mgornergoogle\/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot%10 == 1: # set up the subplots on the first call\n        plt.subplots(figsize = (10,10), facecolor = '#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","c7e5de39":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'Loss', 211)\ndisplay_training_curves(\n    history.history['accuracy'], \n    history.history['val_accuracy'], \n    'Accuracy', 212)","6ce98579":"preds = model.predict(test_dataset, verbose = 1)\nsub.iloc[:, 1:] = preds\nprint(sub.shape)\ndisplay(sub.head())","588541a9":"sub.to_csv('.\/submission.csv', index = False)","47ce2d18":"__Preparing Train and Test paths for training__"}}