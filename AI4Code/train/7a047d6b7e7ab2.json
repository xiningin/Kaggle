{"cell_type":{"07860bfa":"code","f2c7c038":"code","802c0533":"code","96237262":"code","9bc54b7a":"code","293dbe70":"code","f66a6d78":"code","95dcd463":"code","44ccd42d":"code","9227ebcf":"code","a801e146":"markdown","565d5ef6":"markdown","58614d58":"markdown","532b0897":"markdown","293418bf":"markdown","90256c70":"markdown"},"source":{"07860bfa":"import tensorflow as tf  \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras import Input, Model, Sequential\nfrom tensorflow.keras import layers\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\nfrom skimage import io\nfrom skimage.transform import resize\n\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport random\nimport os\nfrom tqdm import tqdm\n\nfrom random import randrange","f2c7c038":"class CustomDataGen(tf.keras.utils.Sequence):\n    \n    def __init__(self, path = \"..\/input\/mvtecad-mvtec-anomaly-detection\/mvtec_anomaly_detection\/screw\/\",\n                 batch_size = 2,\n                 input_size=(224, 224),\n                 shuffle=True, seed = None, subset = 'training'):\n        \n        self.image_data_generator = ImageDataGenerator(rescale=1. \/ 255, data_format='channels_last',     \n            #zoom_range = 0.1,\n            #width_shift_range = 0.05,\n            #height_shift_range = 0.05,\n            #brightness_range=(0.95,1.05)\n        )\n        \n        if seed is None:\n            random.randint(0, 2**32)\n            \n        self.batch_size = batch_size\n        self.input_size = input_size\n        \n        self.X_paths = [os.fsdecode(file) for file in os.scandir(f\"{path}\/train\/good\")]\n        self.X_train, self.X_val = train_test_split(self.X_paths, test_size=0.2, random_state = seed, shuffle = True)\n        \n        if subset == 'training':            \n            self.X = self.X_train\n        elif subset == 'validation':\n            self.X = self.X_val\n            \n        self.n = len(self.X)\n    \n    \n    def __getitem__(self, index):\n        \n        data_x = []\n        \n        for i in range(self.batch_size):\n            image = cv2.imread(self.X[self.batch_size * index + i])\n            \n            image = self.image_data_generator.random_transform(image)\n            \n            image = image \/ 255\n            \n            image = tf.image.resize(image, self.input_size)\n            data_x.append(image)\n            \n        data_x = np.array(data_x)\n        \n        return data_x, data_x\n    \n    def __len__(self):            \n        return self.n \/\/ self.batch_size","802c0533":"INPUT_SIZE = (400,400)\nseed = random.randint(0, 2**32)\ntrain_datagen = CustomDataGen(input_size = INPUT_SIZE, batch_size = 2, seed = seed)\nvalidation_datagen = CustomDataGen(input_size = INPUT_SIZE, batch_size = 2, subset = \"validation\", seed = seed) ","96237262":"#Check we dont have the same images in train and validation sets\nany([value in train_datagen.X for value in validation_datagen.X])","9bc54b7a":"x, y = train_datagen[0]\nio.imshow(x[0])\nio.show()","293dbe70":"input_model_filepath = \"..\/input\/anomalysegmentation-weights\/anomaly-segmentation-model_vgg19.h5\"\noutput_model_filepath = \".\/anomaly-segmentation-model.h5\"\n#model class\n#Implementation of DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation https:\/\/arxiv.org\/abs\/2012.07122\nclass AnomalySegmentator(tf.keras.Model):\n    def __init__(self, init_layer = 0, end_layer = None):\n        super(AnomalySegmentator, self).__init__()\n        #self.L2_weight = 1e-6\n        self.init_layer = init_layer\n        self.end_layer = end_layer\n        \n    def build_autoencoder(self, c0, cd):\n        self.autoencoder = Sequential([\n            layers.InputLayer((self.map_shape[0]\/\/4, self.map_shape[1]\/\/4, c0)),\n            layers.Conv2D((c0 + cd) \/\/ 2,(1,1), padding='same', activation = tf.keras.layers.LeakyReLU(alpha=0.1)),\n            layers.Conv2D(2*cd,(1,1), padding='same', activation = tf.keras.layers.LeakyReLU(alpha=0.1)),\n            layers.Conv2D(cd,(1,1), padding='same'),\n            layers.Conv2D(2*cd,(1,1), padding='same', activation = tf.keras.layers.LeakyReLU(alpha=0.1)),\n            layers.Conv2D((c0 + cd) \/\/ 2,(1,1), padding='same', activation = tf.keras.layers.LeakyReLU(alpha=0.1)),\n            layers.Conv2D(c0,(1,1), padding='same')            \n            \n        ])\n        \n    def build(self, input_shape):\n        \n        self.vgg = VGG19(include_top = False, weights = 'imagenet', input_shape=input_shape[1:])\n        self.features_list = [layer.output for layer in self.vgg.layers if 'conv' in layer.name][self.init_layer:self.end_layer]\n        \n        self.feature_extractor = Model(inputs = self.vgg.input, \n                                       outputs = self.features_list)\n        self.feature_extractor.trainable = False   \n        \n        self.threshold = tf.Variable(0, trainable = False, dtype = tf.float32)\n\n        self.map_shape = self.features_list[0].shape[1:-1]\n        \n        self.average_pooling = layers.AveragePooling2D(pool_size=(4, 4), strides=(4,4))       \n        \n        \n        \n        self.c0 = sum([feature.shape[-1] for feature in self.features_list])        \n        self.cd = 40        \n        self.build_autoencoder(self.c0, self.cd)\n        \n    @tf.function      \n    def call(self, inputs):\n        features = self.feature_extractor(inputs)\n        resized_features = [tf.image.resize(feature, self.map_shape) for feature in features]\n        resized_features = tf.concat(resized_features, axis = -1)\n        \n        resized_features = self.average_pooling(resized_features)\n\n        autoencoder_output = self.autoencoder(resized_features)\n        return tf.reduce_mean((autoencoder_output - resized_features)**2, axis = -1)\n        \n    def reconstruction_loss(self):\n        @tf.function\n        def _loss(y_true, y_pred):\n            loss = tf.reduce_mean(y_pred, axis = (1,2)) \/ tf.cast(tf.shape(y_pred)[0], tf.float32)\n            return loss\n                    \n        return _loss\n\n    def compute_threshold(self, data_loader, fpr = 0.05):\n      error = []\n      for i in tqdm(range(len(data_loader))):\n        x, y = data_loader[i]\n        error.append(self(x))\n\n      threshold = np.percentile(error, 100 - fpr)\n      self.threshold = tf.Variable(threshold, trainable = False, dtype = tf.float32)\n        \n    def compute_pca(self, data_loader):\n        extraction_per_sample = 20\n        \n        extractions = []        \n        for i in tqdm(range(len(data_loader))):\n            x, _ = data_loader[i]     \n            \n            features = self.feature_extractor(x)\n            resized_features = [tf.image.resize(feature, self.map_shape) for feature in features]\n            resized_features = tf.concat(resized_features, axis = -1)\n\n            resized_features = self.average_pooling(resized_features)\n            \n            for feature in resized_features:\n                \n                for _ in range(extraction_per_sample):                    \n                \n                    row, col = randrange(feature.shape[0]), randrange(feature.shape[1])\n                    extraction = feature[row, col]\n                    extractions.append(extraction)\n            \n        extractions = np.array(extractions)\n        print(f\"Extractions Shape: {extractions.shape}\")\n        pca = PCA(0.9, svd_solver = \"full\")\n        pca.fit(extractions)\n        self.cd = pca.n_components_\n        self.build_autoencoder(self.c0, self.cd)\n        print(f\"Components with explainable variance 0.9 -> {self.cd}\")\n        \nas_model = AnomalySegmentator()\nas_model.compile(Adam(1e-4), loss = as_model.reconstruction_loss())","f66a6d78":"as_model.build((None, *INPUT_SIZE,3))\nas_model.compute_pca(train_datagen)","95dcd463":"#True if we want to train the model\nif True:\n    # Training the model\n    plateau = tf.keras.callbacks.ReduceLROnPlateau(\n      monitor='val_loss', factor=0.5, patience=5, verbose = 1\n    )\n    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n                                          patience=15)  # Early stopping (stops training when validation doesn't improve for {patience} epochs)\n    save_best = tf.keras.callbacks.ModelCheckpoint(output_model_filepath, monitor='val_loss', save_best_only=True,\n                                                mode='min', save_weights_only = True)  # Saves the best version of the model to disk (as measured on the validation data set)\n    remote_monitor_callback = tf.keras.callbacks.RemoteMonitor(\n        root='https:\/\/dweet.io', path='\/dweet\/for\/semantic-segmentation-training',\n        send_as_json=False, field = 'data'\n    )      \n    history = as_model.fit(train_datagen,\n        epochs=500,\n        validation_data=validation_datagen,\n        shuffle=True,\n        callbacks=[es, save_best, plateau, remote_monitor_callback])\n    #Training history\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    as_model.load_weights(output_model_filepath)\n    as_model.compute_threshold(train_datagen)\n    as_model.save_weights(output_model_filepath)\nelse:\n    \n    as_model.build((None, *INPUT_SIZE,3))\n    as_model.load_weights(input_model_filepath)\n    as_model.compute_threshold(train_datagen)\n    as_model.summary()\n    as_model.autoencoder.summary()","44ccd42d":"classes = ['good', 'manipulated_front', 'scratch_head', 'scratch_neck', 'thread_side', 'thread_top'] #only 0 index is GOOD\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255, data_format='channels_last')\ntest_generator = test_datagen.flow_from_directory(\"..\/input\/mvtecad-mvtec-anomaly-detection\/mvtec_anomaly_detection\/screw\/test\", \n                                                  target_size = INPUT_SIZE,\n                                                  batch_size = 1,\n                                                  class_mode = 'sparse')","9227ebcf":"for i in range(10):\n    x_batch, y_batch = next(test_generator)    \n    hotmaps = as_model(x_batch)\n    for x, y, hotmap in zip(x_batch, y_batch, hotmaps):\n\n        prediction = np.any(hotmap > as_model.threshold)\n\n        hotmap = resize(hotmap, x.shape[:-1], anti_aliasing = True)\n        mask = np.where(hotmap > as_model.threshold, 1, 0)\n        \n\n        f, axarr = plt.subplots(1,2, figsize=(15,15))\n        axarr[0].imshow(x)\n        axarr[1].imshow(mask)\n        axarr[1].imshow(x, alpha = 0.75)\n        plt.show()\n\n        print(f\"Threshold: {as_model.threshold.numpy()} MaxValue: {hotmap.max()}\")\n        print(f\"GT: {classes[int(y)]}, anomaly detected: {prediction}\")\n    ","a801e146":"# TESTING","565d5ef6":"## Model","58614d58":"## Training","532b0897":"## IMPORTS","293418bf":"# UNSUPERVISED ANOMALY SEGMENTATION\n### This is a implementation of **DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation** https:\/\/arxiv.org\/abs\/2012.07122\n#### We train only with OK images, and then we predict a hotmap, where high areas are presumably anomalous\n#### The pretrained weights provided by me (input anomalysegmentation-weights) are not very good because Kaggle limits training time to 9hrs","90256c70":"## Custom Data Generator"}}