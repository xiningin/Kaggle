{"cell_type":{"9ddf327f":"code","a6c216c0":"code","27dfb02f":"code","b477c905":"code","c5a0ac01":"code","297bec54":"code","60342daa":"code","c53382bf":"code","aaeee418":"code","914a4fa2":"code","3b160a17":"code","359d6827":"code","7e6ac71a":"code","8c2a78e8":"code","fe65bd08":"code","4033a2a9":"code","fe372edc":"code","c4adc613":"code","757ed33f":"markdown","8ac19c56":"markdown","7ce98fc8":"markdown","ed82ade6":"markdown","805ba827":"markdown","3a1fd676":"markdown","4671ad2a":"markdown","cc74e12f":"markdown","934530fa":"markdown","a77b7cd8":"markdown"},"source":{"9ddf327f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix,plot_confusion_matrix\n%matplotlib inline\nml.style.use('ggplot')\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6c216c0":"data = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv',encoding='latin-1')\nprint(data.shape)\ndata.head()","27dfb02f":"data.info()","b477c905":"cols = {'v1':'Label','v2':'Text'}\ndata = data.rename(columns=cols)\ndata","c5a0ac01":"col3 = data['Unnamed: 2'].isnull().sum()\/data.shape[0]\ncol4 = data['Unnamed: 3'].isnull().sum()\/data.shape[0]\ncol5 = data['Unnamed: 4'].isnull().sum()\/data.shape[0]\n\nprint(\"Portion of NaN values in the 3rd column : \",(col3*100),\"%\")\nprint(\"Portion of NaN values in the 4th column : \",(col4*100),\"%\")\nprint(\"Portion of NaN values in the 5th column : \",(col5*100),\"%\")","297bec54":"data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\ndata.head(10)","60342daa":"# Getting all words in all 5572 SMS's\ntexts = list(data.Text.values)\nwords = []\nfor i in texts:\n    words.extend(i.split(\" \"))\nlen(words)","c53382bf":"# Replacing non-alphabetical instances\nfor i in range(len(words)):\n    if not words[i].isalpha():\n        words[i] = \"\"\n\n# Create a Counter dictionary to maintain ('word':count) tuples.\nword_dict = Counter(words)\nword_dict.most_common(1)     # Get the 1st most common word.","aaeee418":"del word_dict['']\n# Check\nword_dict.most_common(1)","914a4fa2":"# Getting the 3000 most common words in text messages (Why 3000 ? Hit and trial)\nw_new = word_dict.most_common(3000)\nw_new","3b160a17":"features,columns = [],[]\n\n# Creating the columns(features)\nfor word in w_new:\n    columns.append(word[0])\n\n# Creating data\nfor s in texts:\n    d = []\n    for wrd in w_new:\n        d.append(s.count(wrd[0]))\n    features.append(d)\n\n# Create dataframe\ndf = pd.DataFrame(features,columns=columns)\ndf","359d6827":"df['label'] = 0\ndf","7e6ac71a":"labels = {'spam':1,'ham':0}             # Spam = 1, Not spam = 0\nfor i in range(df.shape[0]):\n    df.iloc[i,3000] = int(labels[data.iloc[i,0]])\ndf","8c2a78e8":"# X = df.iloc[:,:3000].values\nX = np.array(features)\n# Y = df['label'].values\nY = np.array(df.label)\n\ntrain_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.7,random_state=10)\nprint(\"Train X size = \",train_x.shape,\", Test X size = \",test_x.shape)\nprint(\"Train Y size = \",train_y.shape,\", Test Y size = \",test_y.shape)","fe65bd08":"# Defining the Naive Bayes classifier\nmnb = MultinomialNB(alpha = 1.9, fit_prior = True)\n# Training the model\nmnb.fit(train_x,train_y)","4033a2a9":"y_pred = mnb.predict(test_x)\nprint(confusion_matrix(test_y,y_pred,labels=[1,0],normalize=None))\ntn,fp,fn,tp = confusion_matrix(test_y,y_pred).ravel()\nprint(\"\\nTP = \",tp,\", FP = \",fp,\", FN = \",fn,\", TN = \",tn)\nprint(\"Confirmation : TP + FP + FN + TN = \",tp+fp+fn+tn)\nprint(\"Equal to test_y size(3901)\")\n# Accuracy\nprint(\"\\nAccuracy of Naive Bayes = \",(tp+tn)*100\/(tp+tn+fp+fn),\"%\")","fe372edc":"svc = SVC(C=1.0,kernel='rbf',gamma='auto')         \nsvc.fit(train_x,train_y)\ny_pred2 = svc.predict(test_x)\nprint(\"Accuracy Score for SVM : \", accuracy_score(y_pred2,test_y)*100, \"%\")","c4adc613":"rfc = RandomForestClassifier(n_estimators=100,criterion='gini')\nrfc.fit(train_x,train_y)\ny_pred3 = rfc.predict(test_x)\nprint(\"Accuracy Score of Random Forest Classifier : \", accuracy_score(y_pred3,test_y)*100, \"%\")","757ed33f":"**Random Forest Classifier**","8ac19c56":"**RENAMING COLUMNS**","7ce98fc8":"**FILTERING OUT THE COMMON WORDS AND FORMING A FREQUENCY DATASET**","ed82ade6":"**SVM**","805ba827":"**TRAINING THE MODEL**","3a1fd676":"**FIND RATIO OF NULL VALUES IN LAST 3 COLUMNS TO DECIDE WHETHER TO KEEP OR DROP**","4671ad2a":"This shouldn't be the case. The most common word can't be a ' '. So we remmove the occurrence of ' '(unwanted character) in the word_dict","cc74e12f":"**PREDICTIONS AND CONFUSION MATRIX**\nConfusion matrix to get an idea of the accuracy of the model. X-axis = Predicted label. Y-axis = True label.","934530fa":"**DROPPING 'TEXT' AND ASSIGNING LABELS MANUALLY**\n","a77b7cd8":"**FEATURE ENGINEERING**"}}