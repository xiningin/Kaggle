{"cell_type":{"c7b5f4b5":"code","0096f34f":"code","4f524435":"code","cfb78161":"code","94b3f1e4":"code","483820f5":"code","6b345922":"code","94699ca3":"code","1d121fed":"code","215b9000":"code","9428588b":"code","b8a7e647":"code","76225936":"code","71df29b3":"code","b9f3e2d0":"code","c1bfd753":"markdown"},"source":{"c7b5f4b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0096f34f":"import json\ndatastore = []\nfor line in open('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset.json','r'):\n    datastore.append(json.loads(line))","4f524435":"sentences = []\nlabels = []\nfor item in datastore:\n    sentences.append(item['headline'])\n    labels.append(item['is_sarcastic'])","cfb78161":"print(sentences[0])\nprint(labels[0])","94b3f1e4":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import  Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n","483820f5":"vocab_size = 10000\nmax_length = 50\nembedding_dim = 200 \npadd_type = 'post'\ntrunc_type = 'post'\n\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(sentences)\nword_index = tokenizer.word_index\nprint(len(word_index))","6b345922":"sequences = tokenizer.texts_to_sequences(sentences)\npadded = pad_sequences(sequences,maxlen = max_length,padding = padd_type, truncating = trunc_type )","94699ca3":"print(type(padded))","1d121fed":"labels = np.array(labels)\nprint(type(labels))","215b9000":"from keras.layers import *","9428588b":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n    tf.keras.layers.MaxPooling1D(pool_size=4),\n    tf.keras.layers.LSTM(128,return_sequences = True),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(24,activation = 'relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n","b8a7e647":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","76225936":"num_epochs = 10\nhistory = model.fit(padded, labels,epochs = num_epochs, verbose = 1,validation_split = 0.2)","71df29b3":"print(history.history['val_accuracy'][9])\nprint(history.history['val_loss'][9])","b9f3e2d0":"import matplotlib.pyplot as plt\n\nfig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))\nfig.suptitle(\"Performance of Model without pretrained embeddings\")\nax1.plot(history.history['accuracy'])\nax1.plot(history.history['val_accuracy'])\nvline_cut = np.where(history.history['val_accuracy'] == np.max(history.history['val_accuracy']))[0][0]\nax1.axvline(x=vline_cut, color='k', linestyle='--')\nax1.set_title(\"Model Accuracy\")\nax1.legend(['train', 'test'])\n\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'])\nvline_cut = np.where(history.history['val_loss'] == np.min(history.history['val_loss']))[0][0]\nax2.axvline(x=vline_cut, color='k', linestyle='--')\nax2.set_title(\"Model Loss\")\nax2.legend(['train', 'test'])\nplt.show()","c1bfd753":"### Author : Sanjoy Biswas \n### Project : Sarcasm Detection of News Headlines \n### Email : sanjoy.eee32@gmail.com"}}