{"cell_type":{"6a153ebd":"code","b47454ff":"code","416965ff":"code","7bb06842":"code","26258f12":"code","f14fe420":"code","87e7daf9":"code","92c6ac09":"code","83eb0c2e":"code","9ada69ac":"code","0cccd570":"code","d4c6f22c":"code","e06e9852":"code","ad6e6112":"code","57e1eee5":"code","f71e81e0":"code","dda3ea70":"code","62a62d7d":"code","609f31bf":"code","0d3855fa":"markdown","0bec7c8d":"markdown","23edd58f":"markdown","4f558438":"markdown","c7956e88":"markdown","f7470eb2":"markdown","59f1c6ed":"markdown","27c611e8":"markdown","45915d4c":"markdown","e87fbf5b":"markdown","570e02d5":"markdown","b3609877":"markdown","9b4ba4f9":"markdown","a6bb6f8e":"markdown","88e4e4bc":"markdown","55c684f9":"markdown"},"source":{"6a153ebd":"import numpy as np \nimport pandas as pd \nimport random as rn\n\nimport os\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","b47454ff":"from __future__ import absolute_import # caution : it must be in the front \nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport keras.backend as K\n\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers import MaxPool2D, Flatten, Dense, Dropout\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\nprint(tf.__version__)\nprint(keras.__version__)","416965ff":"def dataload(src):\n    temp = []\n    files = os.listdir(src)\n    for i in range(len(os.listdir(src))):\n        if files[i][-4:] == '.jpg':\n            temp.append(files[i])\n    print(len(temp))\n    \n    return temp\n\nsrc = '..\/input\/car-wheel-design-in-engineering\/data_3000\/'\nfilenames = dataload(src)","7bb06842":"# read image and print \n\ndef img_plot(img):\n    plt.imshow(img)\n    plt.show()\n    \ndef img_read(src, file):\n    img = cv.imread(src + file, cv.COLOR_BGR2GRAY)\n    return img\n\nX, y = [],[]\ncount = 0\n\nfor name in filenames:\n    # Divide the data into 255 and normalize it between 0 and 1 and put it in the X list.\n    X.append(img_read(src, name) \/ 255.)\n    y.append(float(name[:-4]))\n    \nX = np.asarray(X)\ny = np.asarray(y)\n\nfor i in range(5):        \n    img = X[i]\n    img_plot(img)\n\nplt.tight_layout()\n\nprint(f\"==========================================\")\nprint('X shape: ', np.shape(X), 'y shape: ', np.shape(y))","26258f12":"learning_rate = 0.003\ntraining_epochs = 500\nbatch_size = 64","f14fe420":"x_train,x_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n\nx_train = np.expand_dims(x_train, axis=-1) # (x, 56, 56, 1)\nx_test = np.expand_dims(x_test, axis=-1) # (x, 56, 56, 1)\n\nprint(np.shape(x_train), np.shape(x_test)) # images\nprint(np.shape(y_train), np.shape(y_test)) # numbers","87e7daf9":"y_train","92c6ac09":"# linear \ndef linear(x):\n    return x\n\ninputs = [x for x in range(-10, 10)]\noutputs = [linear(x) for x in inputs]\npyplot.plot(inputs, outputs)\npyplot.show()\n\n# target values used to train a model with a linear activation function in the output layer are typically scaled \n# prior to modeling using normalization or standardizatin transforms.","83eb0c2e":"# Relu (most common function used for hidden layers)\n\ndef rectified(x):\n    return max(0.0, x)\n\ninputs = [x for x in range(-10, 10)]\noutputs = [rectified(x) for x in inputs]\npyplot.plot(inputs, outputs)\npyplot.show()\n\n# When using the ReLU function for hidden layers, it is a good practice to use a \u201cHe Normal\u201d or \u201cHe Uniform\u201d \n# weight initialization and scale input data to the range 0-1 (normalize) prior to training.","9ada69ac":"# sigmoid \n\ndef sigmoid(z):\n    y_head = 1 \/ (1 + np.exp(-z))\n    return y_head\n\ninputs = [x for x in range(-10, 10)]\noutputs = [sigmoid(x) for x in inputs]\npyplot.plot(inputs, outputs)\npyplot.show()\n\n# when using the sigmoid function for hidden layers, it's a good practice to use a \"Xavier Normal\" or \"Xavier Uniform\" weight initialization\n# also referred to Glorot initialization, named for Xavier Glorot) and scale input data to the range 0 ~ 1 (e.g. the range of the activation\n# function) prior to training.","0cccd570":"# tanh \nfrom math import exp\n\ndef tanh(x):\n    return (exp(x) - exp(-x)) \/ (exp(x) + exp(-x))\n\ninputs = [x for x in range(-10, 10)]\noutputs = [tanh(x) for x in inputs]\npyplot.plot(inputs, outputs)\npyplot.show()\n\n# When using the TanH function for hidden layers, it is a good practice to use a \u201cXavier Normal\u201d or \u201cXavier Uniform\u201d weight initialization \n# (also referred to Glorot initialization, named for Xavier Glorot) and scale input data to the range -1 to 1 \n# (e.g. the range of the activation function) prior to training.","d4c6f22c":"# softmax \n\ndef softmax(x):\n    return np.exp(x) \/ np.exp(x).sum()\n\ninputs = [2.0, 1.0, 0.1]\noutputs = softmax(inputs)\nprint(outputs)\nprint(outputs.sum())","e06e9852":"# Input : (3000, 56, 56, 1)\n\ndef CNN_model():\n    model = keras.Sequential()\n    \n    # filters : int, the dimensionality of the output space \n    # kernel_size : int or tuple\/list of 2 integers, An integer or tuple\/list of 2 integers, specifying the height and width of the 2D convolution window\n    # activation : Refer to the function\n    # padding : \"valid\" means no padding, \"SAME\" results in padding with zeros evenly to the left\/right or up\/down of the input\n    # when padding='same' & strides=1, the outputs has the same size as the input\n    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu,\n                                    padding='SAME', input_shape=(56, 56, 1)))\n    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(1))\n    \n    return model","ad6e6112":"model = CNN_model()\nmodel.summary()","57e1eee5":"keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","f71e81e0":"def rmse (y_true, y_pred):\n    '''\n    params : RMSE (Root Mean Square Error)\n    '''\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))","dda3ea70":"# CNN model compile\nmodel.compile(loss='MSE',                 # MSE : mean square error\n              optimizer='adam',                \n              metrics=[rmse, 'mape'])     # MAPE : mean absolute percentage error     \n\n# training \nhistory = model.fit(x_train, y_train,     # input \n          batch_size=batch_size,          # We already define Hyper parameters (100 processes per batch) \n          epochs=training_epochs,         # 1000 training\n          verbose=1,                         # Verbose is to set phrases that are printed during learning \n          validation_data=(x_test, y_test))  # validation sets\n\n# Check the test result\nscore = model.evaluate(x_test, y_test, verbose=1) \nprint('Test loss(mse) :', score[0])\nprint('Test RMSE :', score[1])\nprint('Test MAPE :', score[2])","62a62d7d":"def plot_rmse(history, title=None):  \n    '''\n    summarize history for RMSE\n    '''\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['rmse'])        \n    plt.plot(history['val_rmse'])    \n    \n    if title is not None:\n        plt.title(title)\n    \n    plt.ylabel('RMSE')\n    plt.xlabel('Epoch')\n    plt.legend(['Training data', 'Validation data'], loc=0)\n    # plt.show()\n\ndef plot_mape(history, title=None):        \n    '''\n    summarize history for MAPE\n    '''\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['mape'])        \n    plt.plot(history['val_mape'])    \n    \n    if title is not None:\n        plt.title(title)\n        \n    plt.ylabel('MAPE')\n    plt.xlabel('Epoch')\n    plt.legend(['Training data', 'Validation data'], loc=0)\n    # plt.show()\n\ndef plot_loss(history, title=None):     # Loss Visualization\n    '''\n    summarize history for loss\n    '''\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['loss'])           # loss\n    plt.plot(history['val_loss'])       # validation\n    \n    if title is not None:\n        plt.title(title)\n    \n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Training data', 'Validation data'], loc=0)\n    # plt.show()","609f31bf":"plot_loss(history, '(a) Loss') \nplt.show()\nplot_rmse(history, '(b) RMSE')  \nplt.show()\nplot_mape(history, '(c) MAPE')\nplt.show()","0d3855fa":"* relu","0bec7c8d":"### Hyper Parameters","23edd58f":"#### Traning ","4f558438":"#### Visualization","c7956e88":"* Linear","f7470eb2":"* metric : https:\/\/www.kaggle.com\/kimalpha\/summary-of-metric  \n* Adam : https:\/\/keras.io\/api\/optimizers\/adam\/  ","59f1c6ed":"tf.keras.layers\n* Conv2D : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Conv2D#args  \n* MaxPool2D : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/MaxPool2D  \n* Flatten : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Flatten  \n* Dense : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Dense  \n* Dropiut : https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Dropout  ","27c611e8":"#### How to Choose an Output Activation Function  \n\nhttps:\/\/machinelearningmastery.com\/  \n![](https:\/\/machinelearningmastery.com\/wp-content\/uploads\/2020\/12\/How-to-Choose-an-Output-Layer-Activation-Function.png)","45915d4c":"* tanh (hyperbolic tangent)","e87fbf5b":"**[Datasets]**\n\nPlease refer to the site below for a description of the dataset.  \nhttps:\/\/www.kaggle.com\/kimalpha\/car-wheel-design-in-engineering  \n(The name at the end of the address is invalid. It's not a car wheel design, but a structural design.)\n  \n    \n**[Definition of variables]**  \n* **X** is thousands of images.\n* **y** is the stiffness value of the structure (see file name)\n\n**[Reference]**  \nhttp:\/\/www.smartdesignlab.org\/DL\/jupyter\/HMC_CNN(%EB%B8%8C%EB%9D%BC%EC%BC%93)_model_fit.html","570e02d5":"### CNN Model","b3609877":"### Splitting into Traning and Validation Sets","9b4ba4f9":"* softmax","a6bb6f8e":"#### Activation function graphs","88e4e4bc":"* sigmoid","55c684f9":"Please turn on GPU Mode"}}