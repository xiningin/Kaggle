{"cell_type":{"cc7f461f":"code","708211d9":"code","f1b0db5c":"code","15e3b378":"code","8429593d":"code","5887a284":"code","87044786":"code","e269c98e":"code","a14023f3":"code","13c16743":"code","d7fa025a":"code","d58271d9":"code","e5e61682":"code","06ab0d9a":"code","b0b7a058":"code","8ac04672":"code","14750efa":"code","f0b49b90":"code","962ea2e6":"code","3ff9a5a5":"code","5ac490b3":"code","fa20b021":"code","a4527762":"code","7af16599":"code","d50d2754":"code","7b4c3697":"code","97c6d11e":"code","c185e02c":"code","9ba4d9bc":"code","b64b3755":"code","99d11b1a":"code","5c9a6ef3":"code","1429c7a4":"code","572bf1a6":"code","4b95411f":"code","76a0ab08":"code","4ab4ee08":"code","fdb6f175":"code","8dd9bc99":"code","04e05cc4":"code","21b1929b":"code","5632f186":"code","5157f9ff":"code","d0dd9730":"code","34d0b869":"code","e0b14ed7":"code","a67c09da":"code","73259418":"code","a9f201d1":"code","7c44772f":"code","122e9eb9":"code","61e12e9a":"code","409cc0cf":"code","4150cf85":"code","cb44ede6":"code","b8376adb":"code","7700df04":"code","189cc169":"code","03f2a671":"code","5d726d78":"code","a6d4527a":"markdown","49218403":"markdown","c9e0d93f":"markdown","21e6c212":"markdown","2473b598":"markdown"},"source":{"cc7f461f":"import pandas as pd\nimport pandas_profiling\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\nimport re\nimport math\nimport copy\nfrom IPython.display import display\npd.options.mode.chained_assignment = None","708211d9":"RANDOM_SEED = 42\n!pip freeze > requirements.txt\nCURRENT_DATE = pd.to_datetime('25\/06\/2020')","f1b0db5c":"path_to_file = '\/kaggle\/input\/sf-dst-restaurant-rating\/'\ndf_train = pd.read_csv(path_to_file+'main_task.csv')\ndf_test = pd.read_csv(path_to_file+'kaggle_task.csv')\npd.set_option('display.max_columns', 200)\ndisplay(df_train.head(2))\ndisplay(df_test.head(2))","15e3b378":"# \u0412\u0410\u0416\u041d\u041e! \u0434\u0440\u044f \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442 \u0432 \u043e\u0434\u0438\u043d \u0434\u0430\u0442\u0430\u0441\u0435\u0442\ndf_train['Sample'] = 1 # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0440\u0435\u0439\u043d\ndf_test['Sample'] = 0 # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0435\u0441\u0442\ndf_test['Rating'] = 0 # \u0432 \u0442\u0435\u0441\u0442\u0435 \u0443 \u043d\u0430\u0441 \u043d\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f Rating, \u043c\u044b \u0435\u0433\u043e \u0434\u043e\u043b\u0436\u043d\u044b \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043a\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438\n\nrest = df_test.append(df_train, sort=False).reset_index(drop=True) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c","8429593d":"rest.head()","5887a284":"# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0430 \u043f\u0443\u0441\u0442\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\ndef missing_values_table(df):\n        # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\n        mis_val = df.isnull().sum()\n        \n        # \u041f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        #\u0422\u0430\u0431\u043b\u0438\u0446\u0430 \u0441 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c\u0438\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # \u041f\u0435\u0440\u0435\u0438\u043c\u0435\u043d\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0438\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # \u0421\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u0443\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # \u041f\u0435\u0447\u0430\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n       \n        return mis_val_table_ren_columns","87044786":"missing_values_table(rest)","e269c98e":"plt.subplots(figsize=(15, 15))\nsns.heatmap(rest.isnull())","a14023f3":"rest['code_Restaurant_id'] = rest['Restaurant_id'].apply(lambda x: float(x[3:]))","13c16743":"sns.heatmap(rest.corr(),annot=True)","d7fa025a":"rest.drop(['code_Restaurant_id'], axis=1, inplace=True)","d58271d9":"# \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 9283 (23.2%) \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \n# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u044d\u0442\u0443 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e\nrest['NAN_Cuisine Style'] = pd.isna(rest['Cuisine Style']).astype('float64') \n\n# \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c 'Other'\nrest['Cuisine Style'] = rest['Cuisine Style'].fillna(\"['Other']\")","e5e61682":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0443 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\nrest['Cuisine Style'] = rest['Cuisine Style'].str.findall(r\"'(\\b.*?\\b)'\") \n\ntemp_list = rest['Cuisine Style'].tolist()\n\ndef list_unrar(list_of_lists):\n    result=[]\n    for lst in list_of_lists:\n        result.extend(lst)\n    return result\n\ntemp_counter=Counter(list_unrar(temp_list))","06ab0d9a":"# \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u043a\u0443\u0445\u043e\u043d\u044c \u0438 \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u043d\u0430 \u0435\u0433\u043e \u043e\u0441\u043d\u043e\u0432\u0435 \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\nlist_of_unique_Cuisine = [x[0] for x in temp_counter.most_common()[-16:]]\nrest['unique_Cuisine_Style'] = rest['Cuisine Style'].apply(lambda x: 1 if len(set(x) & set(list_of_unique_Cuisine))>0  else 0).astype('float64')","b0b7a058":"for cuisine in temp_counter:\n    rest[cuisine] = rest['Cuisine Style'].apply(lambda x: 1 if cuisine in x else 0 ).astype('float64')\n\n# \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043a\u043e\u043b-\u0432\u043e \u043a\u0443\u0445\u043e\u043d\u044c \u0432 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0435\nrest['count_Cuisine_Style'] = rest['Cuisine Style'].apply(lambda x: len(x)).astype('float64')","8ac04672":"# \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043e\u0447\u0435\u043d\u044c \u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 13886 (34.7%)\n# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u0445 \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u043f\u043e\u0442\u0435\u0440\u044f\u0442\u044c\nrest['NaN_Price Range'] = pd.isna(rest['Price Range']).astype('float64') \n\n# \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043f\u043e \u0441\u043b\u043e\u0432\u0430\u0440\u044e\ndic_value_Price = {'$':1,'$$ - $$$':2,'$$$$':3}\nrest['Price_Range']=rest['Price Range'].map(lambda x: dic_value_Price.get(x,x))\n\n# 18412 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u044d\u0442\u043e \u0431\u043e\u043b\u0435\u0435 70% \u0438\u0437 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u0438\u043c\u0435\u044e\u0442 \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0446\u0435\u043d\u044b\n# \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0434\u0432\u043e\u0439\u043a\u043e\u0439 (2)\nrest['Price_Range'] = rest['Price_Range'].fillna(2)","14750efa":"# \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 2543 (6.4%) \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \n# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u044d\u0442\u0443 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e\nrest['NAN_Number of Reviews'] = pd.isna(rest['Number of Reviews']).astype('float64')\n\n# \u0434\u043b\u044f \u0443\u0434\u043e\u0431\u0441\u0442\u0432\u0430 \u0438\u0437\u043c\u0435\u043d\u0438\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u0430\nrest.rename(columns={'Number of Reviews': 'Number_of_Reviews'}, inplace=True)","f0b49b90":"rest['Reviews'] = rest['Reviews'].fillna('[[], []]')\nrest['empty_Reviews'] = (rest['Reviews']=='[[], []]').astype('float64')","962ea2e6":"rest['date_of_Review'] = rest['Reviews'].str.findall('\\d+\/\\d+\/\\d+')\nrest['len_date'] = rest['date_of_Review'].apply(lambda x: len(x))","3ff9a5a5":"print(\"\u043a\u043e\u043b-\u0432\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 Reviews \u0441 \u0442\u0440\u0435\u043c\u044f \u0434\u0430\u0442\u0430\u043c\u0438 :=\" , len(rest[rest['len_date']==3]))\nprint(\"\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f Reviews \u0441 \u0442\u0440\u0435\u043c\u044f \u0434\u0430\u0442\u0430\u043c\u0438 :=\")\ntemp_list = rest[rest['len_date']==3].Reviews.to_list()\ndisplay(rest[rest['len_date']==3].Reviews.to_list())\nprint(\"\u0434\u0430\u0442\u044b \u043f\u043e\u0441\u043b\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u043c\u0438 \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438:\")\ndisplay([re.findall('\\d+\/\\d+\/\\d+', x) for x in temp_list])","5ac490b3":"rest['len_date'].date_of_Review = rest[rest['len_date']==3].date_of_Review.apply(lambda x: x.pop(0))","fa20b021":"print(\"\u043a\u043e\u043b-\u0432\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 Reviews \u0441 \u043e\u0434\u043d\u043e\u0439 \u0434\u0430\u0442\u043e\u0439 :=\" , len(rest[rest['len_date']==1]))\ndisplay(rest[rest['len_date']==1].Reviews[:4])","a4527762":"rest['one_Review'] = (rest['len_date']==1).astype('float64')\n\n# \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0435\u0440\u0435\u0440\u044b\u0432 \u043c\u0435\u0436\u0434\u0443 \u043e\u0442\u0437\u044b\u0432\u0430\u043c\u0438 (\u043f\u043e \u043e\u0442\u0437\u044b\u0432\u0430\u043c \u0433\u0434\u0435 len = 2) \u0438 \u043d\u0430\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u0432\u043d\u043e \u0431\u044b\u043b \u0441\u0434\u0435\u043b\u0430\u043d \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0441\u0430\u043c\u044b\u0439 \u0441\u0432\u0435\u0436\u0438\u0439 \u043e\u0442\u0437\u044b\u0432\n# \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0444\u0443\u043d\u043a\u0446\u0438\u0438:\ndef time_to_now(row):\n    if row['date_of_Review'] == []:\n        return None\n    return datetime.datetime.now() - pd.to_datetime(row['date_of_Review']).max()\n\ndef time_between_Reviews(row):\n    if row['date_of_Review'] == []:\n        return None\n    return pd.to_datetime(row['date_of_Review']).max() - pd.to_datetime(row['date_of_Review']).min()\n\nrest['day_to_now'] = rest.apply(time_to_now, axis = 1).dt.days\nrest['day_between_Reviews'] = rest[rest['len_date']==2].apply(time_between_Reviews, axis = 1).dt.days","7af16599":"rest['out_day_between_Reviews'] = (rest['day_between_Reviews']==0).astype('float64')\n\n# \u0438 \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b\nrest.loc[rest['day_between_Reviews']==0, 'day_between_Reviews'] = None","d50d2754":"rest['day_to_now'].isna().sum()","7b4c3697":"rest['day_between_Reviews'].isna().sum()","97c6d11e":"rest['code_ID_TA'] = rest['ID_TA'].apply(lambda x: float(x[1:]))","c185e02c":"rest['code_after_g_URL_TA'] = rest['URL_TA'].str.split('-').apply(lambda x: x[1][1:]).astype('float64')","9ba4d9bc":"City_dummies = pd.get_dummies(rest['City'], dummy_na=False).astype('float64')\nrest = pd.concat([rest,City_dummies], axis=1)","b64b3755":"le = LabelEncoder()\nle.fit(rest['City'])\nrest['code_City'] = le.transform(rest['City'])","99d11b1a":"NotCapitalCity = ['Barcelona', 'Milan', 'Hamburg', 'Munich', \n                          'Lyon', 'Zurich', 'Oporto', 'Geneva', 'Krakow']\nrest['Capital_City'] = rest['City'].apply(lambda x: 0.0 if x in NotCapitalCity else 1.0)","5c9a6ef3":"countries = {'London' : 'England', 'Paris' : 'France', 'Madrid' : 'Spain', \n                  'Barcelona' : 'Spain', 'Berlin' : 'Germany', 'Milan' : 'Italy', \n                  'Rome' : 'Italy', 'Prague' : 'Czech_c', 'Lisbon' : 'Portugal', \n                  'Vienna' : 'Austria', 'Amsterdam' : 'Holland', \n                  'Brussels' : 'Belgium', 'Hamburg' : 'Germany', 'Munich' : 'Germany', \n                  'Lyon' : 'France', 'Stockholm' : 'Sweden', 'Budapest' : 'Romania', \n                  'Warsaw' : 'Poland', 'Dublin' : 'Ireland', 'Copenhagen' : 'Denmark', \n                  'Athens' : 'Greece', 'Edinburgh' : 'Scotland', 'Zurich' : 'Switzerland', \n                  'Oporto' : 'Portugal', 'Geneva' : 'Switzerland', 'Krakow' : 'Poland', \n                  'Oslo' : 'Norway', 'Helsinki' : 'Finland', 'Bratislava' : 'Slovakia', \n                  'Luxembourg' : 'Luxembourg_c', 'Ljubljana' : 'Slovenia'}\nrest['\u0421ountry'] = rest.apply(lambda row: countries[row['City']], axis = 1)\n\nle = LabelEncoder()\nle.fit(rest['\u0421ountry'])\nrest['code_\u0421ountry'] = le.transform(rest['\u0421ountry'])","1429c7a4":"city_population= {'London' : 8908, 'Paris' : 2206, 'Madrid' : 3223, 'Barcelona' : 1620, \n                        'Berlin' : 6010, 'Milan' : 1366, 'Rome' : 2872, 'Prague' : 1308, \n                        'Lisbon' : 506, 'Vienna' : 1888, 'Amsterdam' : 860, 'Brussels' : 179, \n                        'Hamburg' : 1841, 'Munich' : 1457, 'Lyon' : 506, 'Stockholm' : 961, \n                        'Budapest' : 1752, 'Warsaw' : 1764, 'Dublin' : 553, \n                        'Copenhagen' : 616, 'Athens' : 665, 'Edinburgh' : 513, \n                        'Zurich' : 415, 'Oporto' : 240, 'Geneva' : 201, 'Krakow' : 769, \n                        'Oslo' : 681, 'Helsinki' : 643, 'Bratislava' : 426, \n                        'Luxembourg' : 119, 'Ljubljana' : 284}\nrest['\u0421ity_population'] = rest.apply(lambda row: city_population[row['City']], axis = 1)","572bf1a6":"rest.Ranking.hist()","4b95411f":"# \u0423 \u043d\u0430\u0441 \u043c\u043d\u043e\u0433\u043e \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0434\u043e\u0442\u044f\u0433\u0438\u0432\u0430\u044e\u0442 \u0438 \u0434\u043e 2500 \u043c\u0435\u0441\u0442\u0430 \u0432 \u0441\u0432\u043e\u0435\u043c \u0433\u043e\u0440\u043e\u0434\u0435, \u0430 \u0447\u0442\u043e \u0442\u0430\u043c \u043f\u043e \u0433\u043e\u0440\u043e\u0434\u0430\u043c?\nplt.rcParams['figure.figsize'] = (12,6)\ndf_train['City'].value_counts(ascending=True).plot(kind='barh')","76a0ab08":"for x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","4ab4ee08":"mean_Ranking= rest.groupby(['City'])['Ranking'].mean()\ncount_Restorant_in_City = rest['City'].value_counts(ascending=False)\nrest['mean_Ranking'] = rest['City'].apply(lambda x: mean_Ranking[x])\nrest['count_Restorant_in_City'] = rest['City'].apply(lambda x: count_Restorant_in_City[x])\nrest['norm_Ranking'] = (rest['Ranking'] - rest['mean_Ranking']) \/ rest['count_Restorant_in_City']","fdb6f175":"for x in (rest['City'].value_counts())[0:10].index:\n    rest['norm_Ranking'][rest['City'] == x].hist(bins=100)\nplt.show()","8dd9bc99":"rest['norm_Population'] = rest['\u0421ity_population']\/rest['count_Restorant_in_City']","04e05cc4":"rest.drop(['Restaurant_id','City', 'Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA', 'date_of_Review', 'len_date', '\u0421ountry', '\u0421ity_population', 'mean_Ranking', 'count_Restorant_in_City', ], axis=1, inplace=True, errors='ignore')","21b1929b":"display(rest.head())","5632f186":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0430\u0446\u0438\u0438\ndef StandardScaler_column(d_col):\n    scaler = StandardScaler()\n    scaler.fit(rest[[d_col]])\n    return scaler.transform(rest[[d_col]])\n# \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0432\u0441\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b \u043a\u0440\u043e\u043c\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u0438 Sample\nfor i  in list(rest.columns):\n    if i not in ['Rating','Sample']:\n        rest[i] = StandardScaler_column(i)\n        if len(rest[rest[i].isna()]) < len(rest):\n            rest[i] = rest[i].fillna(0)","5157f9ff":"display(rest.describe().head(1))","d0dd9730":"train_data = rest.query('Sample == 1').drop(['Sample'], axis=1)\ntest_data = rest.query('Sample == 0').drop(['Sample'], axis=1)\n\ny = train_data.Rating.values            # \u043d\u0430\u0448 \u0442\u0430\u0440\u0433\u0435\u0442\nX = train_data.drop(['Rating'], axis=1)","34d0b869":"# \u0412\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0435 train_test_split \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n# \u0432\u044b\u0434\u0435\u043b\u0438\u043c 20% \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e (\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","e0b14ed7":"# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","a67c09da":"# \u0421\u043e\u0437\u0434\u0430\u0451\u043c \u043c\u043e\u0434\u0435\u043b\u044c (\u041d\u0410\u0421\u0422\u0420\u041e\u0419\u041a\u0418 \u041d\u0415 \u0422\u0420\u041e\u0413\u0410\u0415\u041c)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","73259418":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nmodel.fit(X_train, y_train)\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0430 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u0432 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e y_pred\ny_pred = model.predict(X_test)","a9f201d1":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u043e\u0433\u043e \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043e\u043a\u0440\u0443\u0433\u043b\u0435\u043d\u0438\u044f\ndef classic_round(d_num):\n    return int(d_num + (0.5 if d_num > 0 else -0.5))\n\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u043a\u0440\u0443\u0433\u043b\u0435\u043d\u0438\u044f \u043a\u0440\u0430\u0442\u043d\u043e 0.5\ndef my_round(d_pred):\n    result = classic_round(d_pred*2)\/2\n    if result <=5:\n        return result\n    else:\n        return 5\n    \n# \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432 np\nmy_vec_round = np.vectorize(my_round)","7c44772f":"y_pred = my_vec_round(y_pred)","122e9eb9":"# \u0421\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f (y_pred) \u0441 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u043c\u0438 (y_test), \u0438 \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u043d\u0438 \u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c \u043e\u0442\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f\n# \u041c\u0435\u0442\u0440\u0438\u043a\u0430 \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f Mean Absolute Error (MAE) \u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043e\u0442 \u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445.\nMAE = metrics.mean_absolute_error(y_test, y_pred)\nprint('MAE:', MAE)","61e12e9a":"plt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(25).plot(kind='barh')","409cc0cf":"train_data = rest.query('Sample == 1').drop(['Sample'], axis=1)\ntest_data = rest.query('Sample == 0').drop(['Sample','Rating'], axis=1)\ny = train_data.Rating.values            # \u043d\u0430\u0448 \u0442\u0430\u0440\u0433\u0435\u0442\nX = train_data.drop(['Rating'], axis=1)","4150cf85":"sample_submission = pd.read_csv(path_to_file+'sample_submission.csv')\nsample_submission.head()","cb44ede6":"sample_submission.shape, test_data.shape, X.shape, y.shape","b8376adb":"model.fit(X, y)","7700df04":"predict_submission = model.predict(test_data)","189cc169":"predict_submission=my_vec_round(predict_submission)\npredict_submission","03f2a671":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","5d726d78":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","a6d4527a":"Price Range","49218403":"Number of Reviews","c9e0d93f":"Cuisine Style","21e6c212":"Reviews","2473b598":"Ranking"}}