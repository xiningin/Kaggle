{"cell_type":{"2b81d2c2":"code","b090dfc0":"code","62aa3f56":"code","36cb2931":"code","49132c5b":"code","caaa889e":"code","7525a5c3":"code","6915996f":"code","d3f6d868":"code","2ebbc602":"code","624bb9b4":"code","6b527532":"code","a457a9d9":"code","453040cf":"code","89d814fb":"code","31f0c64f":"code","5bd75e09":"code","66987a14":"code","b8e1cfb4":"code","5920fa79":"code","7307f983":"code","bb5d0a89":"code","380d41ef":"code","8c8bb2ba":"code","bdd8a8b8":"code","c704b456":"markdown","e994dab5":"markdown","00884568":"markdown","57c11161":"markdown","b553b292":"markdown","25103f32":"markdown","4e01937d":"markdown","c18d527e":"markdown","8b14ddfc":"markdown","2be3c002":"markdown","8f3f7cf9":"markdown","0290fbd4":"markdown","7765edd7":"markdown","0aefc3b9":"markdown","8b58529f":"markdown","e6953b68":"markdown","3dd72866":"markdown","b004366e":"markdown","057ad20c":"markdown","5c9f1660":"markdown","aa972b34":"markdown","4e7cb5d6":"markdown","75d25ec0":"markdown","e945a003":"markdown","c0e6d3e3":"markdown","bd5f25be":"markdown","69315b55":"markdown","a9ab9e3f":"markdown"},"source":{"2b81d2c2":"import pandas as pd\nimport numpy as np\n\nfrom datetime import datetime, timedelta\nfrom dateutil import parser\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom IPython.display import display, HTML, Markdown\n\nimport seaborn as sns\nimport altair as alt","b090dfc0":"# old url that stopped working as of 3-26-20\n# url = 'https:\/\/raw.githubusercontent.com\/datasets\/covid-19\/master\/data\/time-series-19-covid-combined.csv'","62aa3f56":"#url = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports\/01-22-2020.csv'\n\nurl = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports\/{date}.csv'","36cb2931":"dflist = []\nyesterday = datetime.today() - timedelta(days=1)\n\nfor d in pd.date_range('2020-01-22', yesterday.strftime(\"%Y-%m-%d\")):\n    try:\n        _df=pd.read_csv(url.format(date=d.strftime(\"%m-%d-%Y\")))\n        _df.columns = [ n.lower() for n in _df.columns ]\n        _df.rename(columns={\n                'country\/region': 'country',\n                'country_region':'country',\n                'province\/state': 'state',\n                'province_state': 'state',\n                'last_update' : 'ts',\n                'last update' : 'ts',\n                'long_' : 'lag',\n                'longitude': 'lag',\n                'latitude': 'lat'\n        }, inplace=True)\n        _df['ts'] = pd.to_datetime(_df.ts)\n        _df['date'] = _df.ts.apply(lambda x : x.date())\n        dflist.append(_df)\n    except Exception as e:\n        print(f\"missing:{d} - {str(e)}\")\ndfn = pd.concat(dflist, sort=True)\ndisplay(dfn.shape)\ndfn.head()","49132c5b":"# drop rows that dont have confrimed cases\n#dfn = dfn.drop(index=dfn[dfn.confirmed == 0].index)\ndfn.confirmed.fillna(method='ffill', inplace=True)\n\n# replace active, deaths, recovered with 0\n[dfn[c].fillna(0, inplace=True) for c in ['confirmed','deaths','recovered'] ];","caaa889e":"# making sure there isnt any discrepency between active cases\n\n#dfn['active'] = dfn['confirmed'] - (dfn['recovered'] + dfn['deaths'])\n\n# they stopped sending active numbers\n#dfn['active-off']= dfn.apply( lambda x : (x['comp-active'] - x['active']) != 0, axis=1)\n\n# print(f\"\"\"\n#     turns out we have {dfn['active-off'].sum()} discrepencies out of {dfn.shape[0]}  ( {round(dfn['active-off'].sum()\/ dfn.shape[0]*100,2)}% )\n# \"\"\")\n# dfn['active'] = dfn['comp-active']\n# dfn.drop(columns=['active-off'], inplace=True)","7525a5c3":"# get list of official country names \n# results here should alwasy should be empty\n\ndf_country_code_mapping = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/lukes\/ISO-3166-Countries-with-Regional-Codes\/master\/all\/all.csv\")\n_false_countries = dfn[['country']].merge(df_country_code_mapping, left_on=['country'], right_on=['name'], how='outer')","6915996f":"# process country names for accuracy\n\ndef preprocess_country(val):\n    mapping = {\n        'Mainland China':'China',\n        'Vietnam' : 'Vietnam',\n        'Taiwan*' : 'Taiwan',\n        'Gambia, The' : 'The Gambia',\n        'Bahamas, The' : 'The Bahamas',\n        'Korea, South' : 'South Korea',\n        'Macao SAR' : 'Macao',\n        'Macau' : 'Macao',\n        'Hong Kong SAR' : 'Hong Kong',\n        'Republic of Korea':'South Korea',\n        'Republic of Ireland' : 'Ireland',\n        'Republic of Moldova' : 'Moldova',\n        'Congo (Brazzaville)' : 'Republic of Congo',\n        'West Bank and Gaza' : 'Palestinian territory',\n        'occupied Palestinian territory' : 'Palestinian territory',\n        'United Kingdom' : 'UK',\n        'Iran (Islamic Republic of)' : 'Iran',\n        'Viet Nam' : 'Vietnam',\n        'Cruise Ship' : 'Others'\n    }\n    return mapping[val] if val in mapping.keys() else val.strip()\n\ndfn['country'] = dfn.country.apply(preprocess_country)\ndfn['country'] = dfn.apply(lambda x : 'Others' if x['country'] == 'Israel' and x['state'] == 'From Diamond Princess' else x['country'], axis=1)\ndfn['state'  ] = dfn.state.apply(lambda x : 'Diamond Princess' if x == 'Diamond Princess cruise ship'  else x)\ndfn['state'  ] = dfn.apply(lambda x : 'Diamond Princess' if x['country'] == 'Diamond Princess' else x['state'], axis=1)\ndfn['country'] = dfn.apply(lambda x : 'Others' if x['state'] == 'Diamond Princess' else x['country'], axis=1)\n\n# save original\ndforig = dfn.copy()\n","d3f6d868":"dfn.head()","2ebbc602":"dfn.state.fillna('unknown',inplace=True)\n_d = dfn.groupby(['country','state','date']).agg({'confirmed':'sum', 'recovered':'sum', 'deaths':'sum', 'active':'sum'})\n_d = _d.merge( _d.groupby(['country','state']).diff() , left_index=True, right_index=True, suffixes=('','_diff'))\n\n# fill na for 1 record \n_d['confirmed_diff'] = _d.apply(lambda x : x['confirmed'] if pd.isnull(x['confirmed_diff']) else x['confirmed_diff'], axis=1)\n_d['active_diff'   ] = _d.apply(lambda x : x['active'   ] if pd.isnull(x['active_diff'])    else x['active_diff'],    axis=1)\n_d['recovered_diff'] = _d.apply(lambda x : x['recovered'] if pd.isnull(x['recovered_diff']) else x['recovered_diff'], axis=1)\n_d['deaths_diff'] = _d.apply(lambda x : x['deaths'] if pd.isnull(x['deaths_diff']) else x['deaths_diff'], axis=1)\n\ndfn = _d.rename(columns={'confirmed':'confirmed_rep', \n                   'recovered':'recovered_rep',\n                   'deaths': 'deaths_rep',\n                   'active' : 'active_rep'})\\\n  .rename(columns={'confirmed_diff':'confirmed',\n                   'recovered_diff':'recovered',\n                   'deaths_diff':'deaths',\n                   'active_diff':'active'})\\\n  .reset_index()","624bb9b4":"_d = dfn.groupby(['country','date']).agg({'confirmed':'sum', 'recovered':'sum', 'deaths':'sum', 'active':'sum'})\n_d = _d.merge( _d.groupby(['country']).diff() , left_index=True, right_index=True, suffixes=('','_diff'))\n\n# fill na for 1 record \n_d['confirmed_diff'] = _d.apply(lambda x : x['confirmed'] if pd.isnull(x['confirmed_diff']) else x['confirmed_diff'], axis=1)\n\ndfc = _d.rename(columns={'confirmed':'confirmed_rep', \n                   'recovered':'recovered_rep',\n                   'deaths': 'deaths_rep',\n                   'active' : 'active_rep'})\\\n  .rename(columns={'confirmed_diff':'confirmed',\n                   'recovered_diff':'recovered',\n                   'deaths_diff':'deaths',\n                   'active_diff':'active'})\\\n  .reset_index()","6b527532":"_df = dfc.copy()\n\n# filter data with the last update date seen.\n#_df['last_update_date'] = _df.ts.apply(lambda x : x.date())\n_df = _df[_df.date == _df.date.max()]\n\n# aggreagate and melt the columns. this will make it easier to split the data in the charts\ndata = _df.groupby(['country']).agg({'confirmed': 'sum',\n                              'deaths'   : 'sum',\n                              'active'   : 'sum',\n                              'recovered': 'sum'})\\\n    .reset_index()\\\n    .sort_values(by='confirmed', ascending=False)\\\n    .melt(id_vars=['country'], value_vars=['confirmed','deaths','active','recovered'], var_name='status', value_name ='count')\n\nconfirmed = alt.Chart( data[data.status == 'confirmed'].sort_values(by=['count'], ascending=False).head(10) )\\\n    .mark_bar()\\\n    .encode(y=alt.Y('country',sort='-x'), x='count')\\\n    .properties(title='confirmed')\nconfirmed_text = confirmed.mark_text(dx = 15).encode(text='count')\n\nrecovered = alt.Chart( data[data.status == 'recovered'].sort_values(by=['count'], ascending=False).head(10) )\\\n    .mark_bar()\\\n    .encode(y=alt.Y('country',sort='-x'), x='count')\\\n    .properties(title='recovered')\nrecovered_text = recovered.mark_text(dx = 15).encode(text='count')\n\ndeaths = alt.Chart( data[data.status == 'deaths'].sort_values(by=['count'], ascending=False).head(10) )\\\n    .mark_bar()\\\n    .encode(y=alt.Y('country',sort='-x'), x='count')\\\n    .properties(title='deaths')\ndeaths_text = deaths.mark_text(dx = 15).encode(text='count')\n\nactive = alt.Chart( data[data.status == 'active'].sort_values(by=['count'], ascending=False).head(10) )\\\n    .mark_bar()\\\n    .encode(y=alt.Y('country',sort='-x'), x='count')\\\n    .properties(title='active')\nactive_text = active.mark_text(dx = 15).encode(text='count')\n\n(\n    ( (confirmed + confirmed_text) | (recovered + recovered_text) )\n  & ( (deaths + deaths_text) | (active + active_text) )\n).properties(title='last 24 hr stats')","a457a9d9":"# dfg = dfcountry.reset_index().groupby(['country'])\\\n#          .agg({'confirmed_diff':'sum', 'recovered_diff':'sum', 'deaths_diff':'sum'})\\\n#          .rename(columns={'confirmed_diff':'confirmed','recovered_diff':'recovered', 'deaths_diff':'deaths'})\\\n#          .reset_index()\n\ndfg = dfn.copy()\ndfg = dfg.groupby(['country'])\\\n         .agg({'confirmed':'sum', 'recovered':'sum', 'deaths':'sum', 'active':'sum'})\\\n         .reset_index()\n\n# calculate active counts\n# calculate x-rates for each of confirmed, recovered , deaths and active counts\n\n# dfg['active']         = dfg['confirmed'] - dfg['deaths'] - dfg['recovered']\ndfg['death-rate']     = round(dfg['deaths']   \/dfg['confirmed'] *100,2)\ndfg['recovery-rate']  = round(dfg['recovered']\/dfg['confirmed'] *100,2)\ndfg['active-rate']    = round(dfg['active']   \/dfg['confirmed'] *100,2)\n\n# chart the heatmap table sorted by confirmed cases on a cumulative basis\n\ndisplay(\ndfg.sort_values(by=['confirmed','active-rate'], ascending=False)\\\n    .head(20)\\\n    .set_index(pd.Index([i for i in range(1,21)]),'rank')\\\n    .style\\\n    .format(dict([(c,'{:.0f}')  for c in ['confirmed','deaths','recovered','active']]))\\\n    .format(dict([(c,'{:.0f}%') for c in ['death-rate','recovery-rate','active-rate']]))\\\n    .background_gradient( subset=['active-rate', 'death-rate', 'recovery-rate', 'deaths']\n                         ,cmap=ListedColormap(sns.color_palette('Reds', desat=0.7)))\\\n    .background_gradient(subset=['recovery-rate', 'recovered']\n                         ,cmap='Greens')\\\n    .background_gradient(subset=['active', 'confirmed']\n                         ,cmap='Blues')\\\n    .set_caption(f\"cumulative numbers from (date:{dfn.date.min()} to {dfn.date.max()}) for to 20 countries by confirmed cases\")\n)","453040cf":"_df = dfn.copy()\n_df['date'] = pd.to_datetime(_df.date)\n\n# generate data by grouping and filtering top 10 countries\n# plot area chart , this will show % share by country of the cumulative count\n# plot line chart on the same data on the side , this will clearly show the rate over time for each country in top 10 \n\nbase = alt.Chart(\n    data = _df.groupby(['date','country'], as_index=False).agg({'confirmed':'sum'})\\\n    .merge(\n        # only look at top 10 countries\n        dfg.sort_values(by=['confirmed'], ascending=False)\\\n           .head(10)\\\n           .country \n        , on='country')\n    )\n\narea = base.mark_area(opacity=.8)\\\n           .encode(  x='date:T'\n                   , y='confirmed'\n                   , tooltip=['confirmed']\n                   , color=alt.Color('country'\n                                     , sort=alt.EncodingSortField('confirmed'\n                                                                  , op=\"sum\"\n                                                                  , order=\"descending\")))\\\n        .properties(width=600, title='confirmed cases by country')\\\n        .interactive()\n\nline = base.mark_line(opacity=.8, point=True)\\\n           .encode(  x='date:T'\n                   , y='confirmed'\n                   , tooltip=['confirmed']\n                   , color=alt.Color('country'\n                                     , sort=alt.EncodingSortField('confirmed'\n                                                                  , op=\"sum\"\n                                                                  , order=\"descending\")))\\\n        .properties(width=600, title='confirmed cases by country')\\\n        .interactive()\n(area & line)","89d814fb":"_df = dfn.copy()\n_df['date'] = pd.to_datetime(_df.date)\n\ndfg = dfn.groupby(['country'], as_index=False)\\\n         .agg({  'confirmed':'sum'\n               , 'recovered':'sum'\n               , 'deaths':'sum'})\n\n# create a base df with to 10 countries by confirmed cases\n# this will be later used to build rest of the thesis\n\n_top_10_countries = dfg.sort_values(by=['confirmed'], ascending=False).head(10).country\n_top_20_countries = dfg.sort_values(by=['confirmed'], ascending=False).head(20).country\n\n_df_base = _df.groupby(['date'\n                        ,'country'], as_index=False)\\\n              .agg({ 'confirmed':'sum'\n                    ,'deaths'   :'sum'\n                    ,'recovered':'sum'\n                    , 'active':'sum'})\\\n              .merge( _top_10_countries , on='country') # filter for top 10 countries\n\n_df_base_20 = _df.groupby(['date'\n                           ,'country'], as_index=False)\\\n              .agg({  'confirmed':'sum'\n                    , 'deaths'   :'sum'\n                    , 'recovered':'sum'\n                    , 'active'   :'sum'})\\\n              .merge( _top_20_countries , on='country') # filter for top 20 countries\n\n_df_base_with_states = _df.groupby(['date'\n                                    ,'country'\n                                    ,'state'], as_index=False)\\\n              .agg({  'confirmed':'sum'\n                    , 'deaths'   :'sum'\n                    , 'recovered':'sum'\n                    , 'active'   :'sum'})\\\n              .merge( _top_10_countries , on='country')","31f0c64f":"_df = dfn.copy()\n_df['date'] = pd.to_datetime(_df.date)\n\n# create a grouper obj\n# agg on confirmed cases and collect start date (min date)\n# grp = _df.groupby(['country']).agg({'confirmed':'sum', 'date':'min'})\\\n#          .sort_values(by=['confirmed'], ascending=False)\\\n#          .head(20)\\\n#          .groupby(['country'])\n\ngrp = _df.groupby(['country']).agg({'confirmed':'sum', 'date':'min'})\\\n         .sort_values(by=['confirmed'], ascending=False)\\\n         .groupby(['country'])\n\n# calculate start date for reach country, the date when first confirmed case was reported\nstart_date_by_country = grp.agg({'date':min})\\\n                           .rename(columns={'date':'start_date'})\n\n# calculate the date when first covid-19 case was seen in each of the top 10 countries\n_dfsd = _df_base.merge(start_date_by_country, on=['country'])\n_dfsd['days'] = _dfsd.apply(lambda x : (x['date'] - x['start_date']).days, axis=1)","5bd75e09":"# create start date by country data frame  to show the order in the chart\n# `p` : assign a column to count ( like select start_date , 1 as p from ... )\n_dfsc = start_date_by_country\\\n            .sort_values(by=['start_date'])\\\n            .assign(p=True)\\\n            .reset_index()\n\n# store the order of countries, useful to order country label on axis\n_country_order = _dfsc.country\n\n_df = _dfsc.pivot('start_date','country','p')[_country_order]\n\n# ----------------------------------------------------------------- #\n# (1) Start date of COVID-19 in top 20 countries by confirmed cases #\n# ----------------------------------------------------------------- #\n\nchart_1 = alt.Chart(_dfsc.iloc[200:])\\\n    .mark_point(stroke='red', filled=True, opacity=.6)\\\n    .encode(  x='yearmonthdate(start_date):T'\n            , y=alt.Y('country', sort='-x')\n            , tooltip=['country', 'start_date']\n            , size='p')\\\n    .properties( title='(1) Start date of COVID-19 in top 20 countries by confirmed cases',\n                 width=600)\n\n# ----------------------------------------------- #\n# (3) No. of new countries affected by start date #\n# ----------------------------------------------- #\n\n_df = dfn.copy()\n_df['date'] = pd.to_datetime(_df.date)\nbase = alt.Chart(\n        _df.groupby(['country'])\\\n           .agg({'date'     :'min'})\\\n           .assign(c = 1)\\\n           .reset_index()\\\n           .rename(columns={'date':'start_date'})\n        )\n\nflattened = base.mark_point(color='firebrick', opacity=0.7, thickness=2, filled=True)\\\n        .encode(  x='start_date:T'\n                , size='sum(c)'\n                , tooltip=['start_date', 'sum(c)'])\\\n        .properties(title=\"(3) No. of new countries affected by start date\",\n                    width=600)\nbreakdown = base.mark_bar(color='firebrick', opacity=.7)\\\n        .encode(  x='start_date:T'\n                , y='sum(c)'\n                , tooltip=['start_date', 'sum(c)'])\\\n        .properties(title=\"(3) No. of new countries infected\",\n                    width=600)\n\n# --------------------------------------------- #\n# (2) confirmed cases on start date for country #\n# --------------------------------------------- #\n\n_df20 = _df_base_20.merge(start_date_by_country, on=['country'])\n_df20['days'] = _df20.apply(lambda x : (x['date'] - x['start_date']).days, axis=1)\n\nbase = alt.Chart( _df20[_df20['date'] == _df20['start_date']].reset_index(drop=True) )\n\nchart20china = base.mark_bar()\\\n              .encode( x=alt.X('country')\n                     , y='confirmed'\n                     , tooltip=['country', 'confirmed']\n                     , color='country')\\\n              .transform_filter( alt.datum.country == 'China' )\\\n\ntext20china  = chart20china.mark_text(dx=15,angle=90).encode(text='confirmed')\n\nchart20 = base.mark_bar()\\\n              .encode( y=alt.Y('country'\n                               , sort=alt.EncodingSortField('start_date:T', order='ascending'))\n                     , x='confirmed'\n                     , tooltip=['country', 'confirmed']\n                     , color='country')\\\n              .transform_filter( alt.datum.country != 'China' )\\\n              .properties(title='(2) No. of confirmed cases on start date for country',\n                          width=450)\\\n\ntext20  = chart20.mark_text(dx=15).encode(text='confirmed')\n\n# ----------------------------------------- #\n# (4) No. of new countries affected by week #\n# ----------------------------------------- #\n\n__df=_df.groupby(['country'])\\\n        .agg({'confirmed':'sum'\n              , 'date':'min'})\\\n        .sort_values(by=['confirmed'], ascending=False)\\\n        .reset_index()\\\n        .groupby(['date'])\\\n            .agg({'country':'count'})\\\n            .reset_index()\\\n            .rename(columns={  'date':'start_date'\n                             , 'country': 'country_count'})\n\n__df['week-of-year'] = __df.start_date.apply(lambda x : f\"{x.year} - {x.strftime('%U')}\")\n__df['grand_total']  = __df.country_count.sum()\n__df['growth_rate']  = __df.apply(lambda x : round(x['country_count']\/x['grand_total']*100,2), axis=1)\n\nweekly_chart = alt.Chart(__df.groupby(['week-of-year']).agg({'country_count':'sum'}).reset_index())\\\n           .mark_bar(color='firebrick', opacity=.6)\\\n           .encode(  x=alt.X('week-of-year')\n                   , y='country_count')\\\n           .properties(  title='(4) No. of new countries infected by week'\n                       , width=600)\n\nweeklytext = weekly_chart.mark_text(angle=0, dy=10).encode(text='country_count')\n\n(     \n chart_1 \n & ( (chart20china + chart20china) | chart20+text20 ) \n & ( flattened & breakdown )\n & (weekly_chart + weeklytext) \n)","66987a14":"_dfsd['confirmed-rolling-sum'] = _dfsd.groupby(['country']).confirmed.transform(lambda x : x.rolling(7).sum())\n_dfsd['recovered-rolling-sum'] = _dfsd.groupby(['country']).recovered.transform(lambda x : x.rolling(7).sum())\n\nconfirmed = alt.Chart(_dfsd[['days','country','confirmed-rolling-sum']])\\\n    .mark_line(strokeOpacity=.7)\\\n    .encode(x='days:O', \n            y='confirmed-rolling-sum',\n            tooltip=['days','confirmed-rolling-sum','country'],\n            color=alt.Color('country', \n                            sort=alt.EncodingSortField('confirmed-rolling-sum', \n                                                       op=\"sum\", \n                                                       order=\"descending\")))\\\n    .properties(title=\"7 day sum of confirmed cases by days since reported\",\n                width=600)\n\nrecovered = alt.Chart(_dfsd[['days',\n                             'country',\n                             'recovered-rolling-sum']])\\\n    .mark_line(strokeOpacity=.7)\\\n    .encode(x='days', \n            y='recovered-rolling-sum',\n            tooltip=['days','recovered-rolling-sum','country'],\n            color='country')\\\n    .properties(title='7 day sum of recovered cases by day since reported',\n                width=600)\n\n(confirmed & recovered)\nrecovered","b8e1cfb4":"df_by_day = _df_base.copy()\ndf_by_day['dow']= df_by_day.date.apply(lambda x : x.strftime(\"%w-%a\"))","5920fa79":"cols_of_interest = ['confirmed','deaths','recovered','active']\n\n_df = df_by_day.groupby(['dow', \n                         'country'])\\\n               .sum()\\\n               .reset_index()\\\n        .merge(\n            df_by_day.groupby(['country'])\\\n                .sum()\\\n                .rename(columns=dict([(c,f\"{c}-max\") for c in cols_of_interest]))\\\n                .reset_index()\n            , on='country'\n            )\\\n        .set_index(['dow','country'])\n\n\nfor c in cols_of_interest:\n    _df[f'{c}_pct'] = round(_df[c]\/_df[f'{c}-max'], 2 )\n","7307f983":"dfc = _df.groupby(['country'])\n\ndf_by_pct = \\\n    dfc.apply(lambda x : x.nlargest(1,'confirmed_pct')\n                          .reset_index()\n                          .confirmed_pct)\\\n        .rename(columns={0:'confirmed'})\\\n        .assign(active=dfc.apply(lambda x : x.nlargest(1,'active_pct')\n                                             .reset_index()\n                                             .active_pct)\\\n                            .rename(columns={0:'active'}))\\\n        .assign(deaths=dfc.apply(lambda x : x.nlargest(1,'deaths_pct')\n                                             .reset_index()\n                                             .deaths_pct)\\\n                            .rename(columns={0:'deaths'}))\\\n        .assign(recovered=dfc.apply(lambda x : x.nlargest(1,'recovered_pct')\n                                                .reset_index()\n                                                .recovered_pct)\\\n                            .rename(columns={0:'recovered'}))\\\n        .unstack()\\\n        .to_frame()\\\n        .reset_index()\\\n        .rename(columns={0:'pct', 'confirmed_pct':'state'})\n\ndf_by_dow = \\\n    dfc.apply(lambda x : x.nlargest(1,'confirmed_pct')\n                          .reset_index()\n                          .dow)\\\n        .rename(columns={0:'confirmed'})\\\n        .assign(active=dfc.apply(lambda x : x.nlargest(1,'active_pct')\n                                             .reset_index()\n                                             .dow)\\\n                        .rename(columns={0:'active'}))\\\n        .assign(deaths=dfc.apply(lambda x : x.nlargest(1,'deaths_pct')\n                                             .reset_index()\n                                             .dow)\\\n                        .rename(columns={0:'deaths'}))\\\n        .assign(recovered=dfc.apply(lambda x : x.nlargest(1,'recovered_pct')\n                                                .reset_index()\n                                                .dow)\\\n                            .rename(columns={0:'recovered'}))\\\n        .unstack()\\\n        .to_frame()\\\n        .reset_index()\\\n        .rename(columns={0:'day', 'dow':'state'})\n\n# Charts #\n# chart the prefered day by state\n\nprefered_dow_pct_breakdown = \\\n    alt.Chart( \n        df_by_dow.groupby(['day','state'], as_index=False)\\\n                .agg({'country':'count'})\\\n                .query('state != \"active\"') \n        )\\\n        .mark_bar()\\\n        .encode(y='day',\n                x='country', \n                color='state', \n                column='state')\n\n#display(prefered_dow_pct_breakdown)\n\ncpct = alt.Chart(_df.reset_index())\\\n        .mark_bar()\\\n        .encode(y='dow', \n                x=alt.X('confirmed_pct', axis=alt.Axis(format=\".0%\")), \n                color='country',\n                tooltip=['country','confirmed_pct','dow'])\ncpct_txt = alt.Chart(_df.reset_index())\\\n              .mark_text(dx=-20)\\\n              .encode(\n                y='dow',\n                x=alt.X('confirmed_pct', stack='zero', axis=alt.Axis(format=\".0%\")),\n                detail='country',\n                text=alt.Text('confirmed_pct', format=\".1%\"))\n\ndpct = alt.Chart(_df.reset_index())\\\n        .mark_bar()\\\n        .encode(y='dow', \n                x=alt.X('deaths_pct', axis=alt.Axis(format=\".0%\")), \n                color='country')\ndpct_txt = alt.Chart(_df.reset_index())\\\n              .mark_text(dx=-20)\\\n              .encode(\n                y='dow',\n                x=alt.X('deaths_pct', stack='zero', axis=alt.Axis(format=\".0%\")),\n                detail='country',\n                text=alt.Text('deaths_pct', format=\".1%\"))\n\nrpct = alt.Chart(_df.reset_index())\\\n        .mark_bar()\\\n        .encode(y='dow', \n                x=alt.X('recovered_pct', axis=alt.Axis(format=\".0%\")), \n                color='country')\n\nrpct_txt = alt.Chart(_df.reset_index())\\\n              .mark_text(dx=-20)\\\n              .encode(\n                y='dow',\n                x=alt.X('recovered_pct', stack='zero', axis=alt.Axis(format=\".0%\")),\n                detail='country',\n                text=alt.Text('recovered_pct', format=\".1%\"))\ndisplay(\n(    (cpct + cpct_txt).properties(width=600)\n   & (dpct + dpct_txt).properties(width=600)\n   & (rpct + rpct_txt).properties(width=600)\n))\n\n\n\ndisplay(\n    df_by_dow.merge( df_by_pct, on=['state','country'])\\\n             .pivot_table(index='country', \n                          columns=['state','day'], \n                          values=['pct'])\\\n             .fillna(0)\\\n             .style\\\n             .background_gradient(cmap='Blues')\\\n             .format(\"{:.0%}\")\n)\n\n","bb5d0a89":"cols_of_interest = ['confirmed','deaths','recovered','active']\n\n_df = dfn.copy()\n_df = _df[_df.state != 'unknown']\n\nall_countries_with_state = _df.groupby(['date'\n                                    ,'country'\n                                    ,'state'], as_index=False)\\\n              .agg({  'confirmed':'sum'\n                    , 'deaths'   :'sum'\n                    , 'recovered':'sum'\n                    , 'active'   :'sum'})\\\n\n# calculate aggreate by country and state\n# _df_cs = _df_base_with_states.groupby(['country'\n#                                        ,'state'])\\\n#                              .agg(dict([ (c,'sum') for c in cols_of_interest ]))\n\n_df_cs = all_countries_with_state.groupby(['country'\n                                       ,'state'])\\\n                             .agg(dict([ (c,'sum') for c in cols_of_interest ]))\n\n\n# calculate agg. by country\n_dfc = _df.groupby(['date'\n              ,'country'], as_index=False)\\\n              .agg({ 'confirmed':'sum'\n                    ,'deaths'   :'sum'\n                    ,'recovered':'sum'\n                    , 'active':'sum'})\\\n                .groupby(['country'])\\\n                     .agg(dict([ (c,'sum') for c in cols_of_interest ]))\n\n\n# filtere top 10 countries\n# assign agg at country level to state level \n\n_dfm = _df_cs.reset_index()\\\n    .merge(_dfc, on='country')\\\n    .rename(columns={'confirmed_x':'confirmed',\n                     'deaths_x'   : 'deaths',\n                     'recovered_x': 'recovered',\n                     'active_x'   : 'active',\n                     \n                     'confirmed_y': 'confirmed_total',\n                     'deaths_y'   : 'deaths_total',\n                     'recovered_y': 'recovered_total',\n                     'active_y'   : 'active_total'})\n\n# calculate percent change at country level for each of the matrics for each of the states\nfor c in cols_of_interest:\n    _dfm[f'{c}_pct'] = round(_dfm[c]\/_dfm[f'{c}_total'],2)\n\n_dfg = _dfm.groupby('country')\n\n# filter top 5 states in each country by % change\ndata = _dfg.apply(lambda x : x.nlargest(5,'confirmed').reset_index(drop=True))\\\n           .sort_values(by=['confirmed_total',\n                            'confirmed_pct'], ascending=False)\\\n           .drop(columns=['country'])\n\nchart_data = data.reset_index()\n#chart_data = chart_data[chart_data.country != 'Germany']\n\nchart = alt.Chart(chart_data)\\\n           .mark_bar(opacity=0.8, width=20)\\\n           .encode(x=alt.X('state',sort='-y'), \n                   y='confirmed', \n                   color='country')\\\n           .properties(width=150, height=150)\n\ntext = chart.mark_text(angle=90, \n                       align='right', \n                       dx=-1)\\\n            .encode(text=alt.Text('confirmed_pct', format='.1%'))\n\n# display(\n# data.style\\\n#     .format( dict((c,'{:.0f}')for c in ['confirmed','deaths','recovered','active','confirmed_total','deaths_total','recovered_total','active_total'] ))\\\n#     .bar(subset=['confirmed_pct','deths_pct','recovered_pct','active_pct'], axis=0)\n# )\n\nalt.layer(chart,\n          text, \n          data=chart_data)\\\n.facet(facet='country',\n       bounds='full', \n       columns=5)\\\n.resolve_scale(y='independent', \n               x='independent')\\\n.properties(title=\"top 5 states affected by COVID-19 across countries ( labels in %) (cumulative confirmed cases)\")","380d41ef":"_df = dfn.copy()\n\n_df = _df.groupby(['date','country'], as_index=False).agg({'confirmed':'sum'})\n_df = _df\\\n        .merge(_df\\\n                   .groupby(['country'], as_index=False)\\\n                   .sum(),\n              on=['country'])\\\n        .rename(columns={'confirmed_x':'confirmed',\n                         'confirmed_y':'total_confirmed'})\n_df['confirmed_pct'] = round(_df['confirmed']\/_df['total_confirmed'],2)\n\ndef bucket_confirmed_pct(val):\n    if val <  0.05 : return '0-5'\n    if val >= 0.06 and val <=.10 : return '6-10'\n    if val >=.11 and val <=.20 : return '11-20'\n    if val >=.21 and val <=.50 : return '21-50'\n    if val >=.51 and val <=.75 : return '51-75'\n    if val >=.76 and val <=.100 : return '76-100'\n\n_df['bucket'] = pd.Categorical( _df.confirmed_pct.apply(bucket_confirmed_pct),\n                              ['0-5','6-10','11-20','21-50','51-75','76-100'])","8c8bb2ba":"_d = _df.groupby(['date','bucket'], as_index=True).agg({'country':pd.Series.nunique}).reset_index()\n_d['date'] = pd.to_datetime(_d['date'])\nalt.Chart(_d)\\\n    .mark_bar()\\\n    .encode(x='date:T', y='country', facet=alt.Facet('bucket', columns=1, sort=alt.EncodingSortField('bucket')), color='bucket')\\\n    .resolve_scale( y='independent')\\\n    .properties(height=100,width=600, title=\"No.of countries in the confirmed_pct bucket over time\")","bdd8a8b8":"\n_d['date'] = _df['date'].apply(lambda x : x.strftime(\"%Y-%m-%d\"))\n_d['ym'] = _df['date'].apply(lambda x : x.strftime(\"%Y-%m\"))\n_d['d']   = _df['date'].apply(lambda x : x.strftime(\"%d\"))\n\n_dd = _d.sort_values(by=['date'])\\\n              .tail(80)\\\n              .groupby(['bucket','date'], as_index=False)\\\n              .sum()\\\n              .pivot('bucket','date','country')\\\n              .replace(0, np.nan)\n\nplt.figure(figsize=(25,3))\nplt.title(\"No. of countries by buckets of growth rate of confirmed_pct (% change) over time\")\ndisplay(\n    sns.heatmap(_dd\n            , annot=True\n            , linewidths=1\n            , square=False\n            , cbar=None\n            , cmap='Reds'\n            , fmt='.0f')\n)\n\n\n_dym_d = _d.sort_values(by=['date'])\\\n              .groupby(['bucket','ym','d'], as_index=False)\\\n              .sum()\ndisplay(\n    pd.pivot_table(data=_dym_d, \n                   index=['bucket','ym'], \n                   columns=['d'], \n                   values=['country'])\\\n        .fillna(0)\\\n        .style\\\n        .background_gradient(cmap='Reds')\\\n        .format(lambda x : \"\" if x == 0 else x)\\\n        .set_caption('No. of countries by buckets of growth rate of confirmed_pct (% change) split by day and month matrix')\n)","c704b456":"# Conclusion\n1. from the chart (4) we can see that there are less newer countries that are being infected.\n2. from chart above , we can see that although fewer new countries are being infected. infection is spreading among those countries.\n3. infection rate is started to curve for US based on w\/w comparision.","e994dab5":"- if you plot the day of the week by aggregated sum of various measures , we can see some interesting observation\n    - confirmed and deaths cases peak on wed!\n    - recoveries peak on Mon!","00884568":"\n3. although we do get reported active cases , we will calculate active to see if there is any discrepencies. (in case of discrepencies. we will fall back to calculated number for active cases)","57c11161":"- interesting to see that most deaths, recoveries and confirmed cases are reported on monday for 8 out of top 10 countries.","b553b292":"1. get the largest `pct` percent change for all confirmed, active, recovered & deaths over country\n    - this is later used to display heat map\n2. calculate prefered day of the week by metrics for the largest percent change\n3. finally calculate break down by prefered day of the week across top 20 countries excluding `active`","25103f32":"1. aggregate metrics across state and country\n2. calculate % change across all metrics for each of the states in a country\n3. filter top 5 states by % change in each of the countries.\n4. chart","4e01937d":"* chart based on start date of infection in top 20 countries","c18d527e":"* from above heat map and bar charts we can see that\n    * the infection is spread more recently across the world\n    * comparision ov m\/m shows more countries are movign in the 2nd bucket of (5-10) from (0-5) % . which means the infections is actually spreading. instead of being contained.","8b14ddfc":"- we can see the COVID-19 impact on `US` from the breakout curves. rolling 7 day difference in confirmed cases has spiked to 200K.\n- it has started to weaken for `Germany` by `65`th day.\n- `Spain`, `Italy` and `UK` has started recovering. they have reported fewer cases on a w\/w basis.\n- `China` has already moved to -ve difference compared to previous weekly numbers.\n- finally , `US` has started to tip off on rolling 7 day diff.","2be3c002":"# Day of the week analysis","8f3f7cf9":"- first we will create base data frames. so we dont have to calculate the same layer again\n    - `_top_10_countries` : aggregate of top 10 countries by date\n    - `_top_20_countries` : agg. of top 20 countries by date\n    - `_df_base` : original df filtered for top 10 countries\n    - `_df_base_20` : original df filterd for top 20 countries\n    - `_df_base_with_states` : original df filtere for top 10 countries and includes states info","0290fbd4":"- as you can see. `US`, `China`, 'South Korea` and 'Brazil` has the first cases as per the data (us started collecging data from 01-22-20)\n    - interesting to me was `Brazil` had the cases at the same time as `US`\n- then it started spreading in Europe starting with `France`, `Germany`, `Italy`.. `UK`\n- at the start of the data set i.e. 01-22-02 there were 8 countries already affected \n- if we look at spread across world, we see that it really started spreading between 02-22-02 and 03-22-02.\n- even as of 04-05-20 we are seeing it spread across countries. which is alarming..","7765edd7":"1. calculate sum of all metrics by dow and country\n2. calculate agg. of all metrics by country \n3. merge both dfs together\n4. calculate % change on day of week over agg of country","0aefc3b9":"- as you can clearly see `Hubei` has `82`% of the cases reported in `China`.\n- and about `39`% of the cases reported in `US` are in `New York`. \n- also about `41`% of the active cases in `US` are in `New York`.\n\n***NOTE***\n* ***`Germany` has only one city reported. so we can ignore that one from the table ***\n* ***some preprocessing need to be done for UK.***","8b58529f":"4. certain country name need preprocessing \n    - we will compare the reported country names with ISO database, and update the discrepencies when needed\n    - eg: `china` and `Mainland china`  or our analysis we will count both as `chaina`","e6953b68":"# preprocessing\n\nfor our analysis here we will assume that any particular case either falls under `active`, `confirmed`, `recovered` or `death` state\n1. fill missing values for confirmed cases. since we can assule that previously reported numbers for a missing day.\n2. fill missing values for confirmed, deaths, recoreved","3dd72866":"# COVID-19 by Numbers & Charts\n\nIn this Notebook, we will try to understand the present state of the world as it is being affected by COVID-19.\n\n* we will be using the dataset for covid-19 available [here...](https:\/\/github.com\/CSSEGISandData\/COVID-19)\n* this is a live notebook. Every time we run the notebook, we will be pulling in the latest data from the repository.\n ","b004366e":"# Start of Infection across Countries\n- look at how COVID-19 spread across the work in different countries\n- rate of spread and if it is still spreading..","057ad20c":"# COVID-19 State across reporting countries in past 24 hr.","5c9f1660":"* generate a list of dates from `2020-01-22` till `yesterday`\n* download the file corresponding to the date\n* create a final data frame by concating data frames for each day","aa972b34":"# Breakout curves\n","4e7cb5d6":"* converting cululative numbers to daily numbers ","75d25ec0":"- `grp` : create a grouper obj for top 20 countries aggregated over countries for confirmed cases and start date ","e945a003":"# Rate of infection over time around the world\n* calcualte growth rate of confirmed cases by country to its total\n* bucket growth rate into 10 bins\n* calculate number of countries that all into each bucket ( hist gram ) over date\n\n* we can see that infection rate around the world and the rate of infaction over time","c0e6d3e3":"# Cumulative numbers across countries \n- comparing countries by their reported confirmed cases on a cumulative basis\n- rank countries based on the number of cumulative reported numbers\n- last reported numbers is the cumulative number for each countries \n    - we will try to find the daily numbers for each metric ","bd5f25be":"# Major cities affected across top 10 countries","69315b55":"# download data and prep\n- data is availabe in 2 different formats. I find it easier to work this csv instead of excell format also called time seried format ( which is a pivot of the csv format )\n- there is a daily file with data under .\/csse_covid_19_daily_reports directory for each day.\n- we will iterate over all the files and build a dataframe, then preprocess some columns.","a9ab9e3f":"# Time Series of top 10 most affected countries\n- US has an exponential increase in confirmed cases. \n- China's confirmed cases has started to decline.\n"}}