{"cell_type":{"68cf034a":"code","6371ff35":"code","ca47e74b":"code","23670a69":"code","42293c82":"code","b9def50a":"code","54279f77":"code","f3e83a85":"code","1ac10f9f":"code","634a4fd5":"code","ff068293":"code","aee27694":"code","d56f163a":"code","e21d0c5f":"code","e78917fb":"code","e5920122":"code","7a9df7f7":"code","bb5384b7":"code","454ead3f":"code","368fa22c":"code","7ff2b844":"code","5040e9ff":"code","832071c4":"code","0249b07f":"code","04c71705":"markdown","7a7a9bcf":"markdown","f16bae9b":"markdown","1d09ae05":"markdown","cc650cd5":"markdown","c4414458":"markdown","07618b45":"markdown","9ed31393":"markdown"},"source":{"68cf034a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6371ff35":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","ca47e74b":"df = pd.read_csv(\"\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv\")","23670a69":"df.head()","42293c82":"df.drop(['Id','idhogar','r4t3','tamhog','tamviv','hogar_total', 'SQBmeaned', 'SQBhogar_total',\n            'SQBage','SQBescolari','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency',\n            'SQBmeaned','agesq'], inplace = True, axis=1)","b9def50a":"df.columns[df.isnull().sum()!=0]","54279f77":"df['v2a1'] = df['v2a1'].fillna((df['v2a1'].mean()))\ndf['v18q1'] = df['v18q1'].fillna((df['v18q1'].mean()))\ndf['rez_esc'] = df['rez_esc'].fillna((df['rez_esc'].mean()))\ndf['meaneduc'] = df['meaneduc'].fillna((df['meaneduc'].mean()))\n\ndf.columns[df.isnull().sum()!=0]","f3e83a85":"df.select_dtypes('object').head()","1ac10f9f":"yes_ou_no = {'no':0,'yes':1}\ndf['dependency'] = df['dependency'].replace(yes_ou_no).astype(np.float32)\ndf['edjefe'] = df['edjefe'].replace(yes_ou_no).astype(np.float32)\ndf['edjefa'] = df['edjefa'].replace(yes_ou_no).astype(np.float32)","634a4fd5":"df.select_dtypes('object').head()","ff068293":"X = df.drop('Target', axis = 1)\n\ny = df.Target","aee27694":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)","d56f163a":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, max_features=2, oob_score=True, random_state=42)\nmodel.fit(X_train,y_train)\n","e21d0c5f":"predicted = model.predict(X_test)\nprint('Classifcation report:\\n', classification_report(y_test, predicted))\nprint('Confusion matrix:\\n', confusion_matrix(y_test, predicted))","e78917fb":"df['Target'].value_counts()","e5920122":"df_1 = df[df['Target']== 1]\ndf_2 = df[df['Target']==2]\ndf_3 = df[df['Target']==3]\ndf_4 = df[df['Target']== 4]\ndf_1.shape,df_2.shape,df_3.shape,df_4.shape","7a9df7f7":"from sklearn.utils import resample\n\ndf_1_over = resample(df_1,\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)\ndf_2_over = resample(df_2,\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)\ndf_3_over = resample(df_3,\n                       replace=True, # sample com replacement\n                       n_samples=len(df_4), # igualando a maior classe\n                       random_state=42)","bb5384b7":"df_over = pd.concat([df_1_over,df_2_over,df_3_over,df_4])","454ead3f":"df_over['Target'].value_counts()\n","368fa22c":"X = df_over.drop('Target', axis = 1)\n\ny = df_over.Target","7ff2b844":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=42)","5040e9ff":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, max_features=2, oob_score=True, random_state=42)\nmodel.fit(X_train,y_train)\n","832071c4":"predicted = model.predict(X_test)\nprint('Classifcation report:\\n', classification_report(y_test, predicted))\nprint('Confusion matrix:\\n', confusion_matrix(y_test, predicted))","0249b07f":"df_test = pd.read_csv(\"\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv\")\nz = pd.Series(predicted,name=\"Target\")\ndf_entrega = pd.concat([df_test.Id,z], axis=1)\ndf_entrega.to_csv(\"\/kaggle\/working\/submission.csv\",index=False)","04c71705":"# Predi\u00e7\u00e3o do n\u00edvel de pobreza dom\u00e9stica na Costa Rica.","7a7a9bcf":"# Refazendo o modelo","f16bae9b":"## Pr\u00e9 processamento","1d09ae05":"Utilizando a matriz de confus\u00e3o podemos ter as seguintes informa\u00e7\u00f5es:\n- O modelo explicou 85% dos dados.\n- 96% dos que o modelo classificou como 1 (extrema pobreza) realmente era. 90% dos que o modelo classificou como 2 realmente era, 95% dos que o modelo classificou como 3 realmente era e 83% dos que o modelo classificou como 4 realmente era.\n- O recall explica a frequ\u00eancia que o modelo classifica os dados na classe certa. Podemos ver que na extrema pobreza, o modelo classificaria 66% dos dados que s\u00e3o extrema pobreza como sendo extrema pobreza. \u00c9 poss\u00edvel ver que a melhor classifica\u00e7\u00e3o \u00e9 no 4, pois depois classifica 99% dos dados da classe 4 como sendo classe 4. \n- O F1 score \u00e9 o equilibrio entre o precision e o recall, o melhor entre as classes 1 a 4, foi a classe 4, que chegou a 91%, isso pode ter acontecido porque a classe 4 \u00e9 mais frequente no data frame, com 1799 linhas. ","cc650cd5":"Refazendo o modelo com os dados balanceados, \u00e9 possivel ver uma melhora significativa, pois agora o modelo explica 99% dos dados e houve uma melhora do precision, recall e f1 score nas classes 1 a 3","c4414458":"## Criando o modelo e usando o Random Forest Classifier","07618b45":"# Tratando os dados desbalanceados","9ed31393":"Foi utilizado o conjunto de dados DF, com 9557 linhas e 128 colunas. Cada linha representa uma pessoa e cada coluna um recurso, exclusivo para a fam\u00edlia do pessoa ou para a pr\u00f3pria pessoa. O conjunto de dados tem a coluna target, que representa o n\u00edvel de pobreza em uma escala de 1 a 4, sendo que o n\u00edvel 1 \u00e9 a pobreza mais extrema. O objetivo desse trabalho \u00e9 prever o n\u00edvel de pobreza."}}