{"cell_type":{"97206eb3":"code","3e18f176":"code","93f8e863":"code","2a3ab5ba":"code","c37547a8":"code","261e251a":"code","f6b87eef":"code","02ac757e":"code","dbbb9a5b":"code","6b343c8c":"code","ace64b9c":"markdown","d8985a64":"markdown","b3a4642f":"markdown","cccd69a1":"markdown","611f7497":"markdown","1838745a":"markdown","09e77c3d":"markdown","db62dc8f":"markdown"},"source":{"97206eb3":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\n","3e18f176":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","93f8e863":"Y_train = train[\"label\"]\n# Dropeamos la columna 'label' del set de entrenamiento \nX_train = train.drop(labels = [\"label\"],axis = 1)\n\n# liberamos espacio\ndel train \n\n#Graficamos la cantidad de veces que se repite un n\u00famero.\ng = sb.countplot(Y_train)\nY_train.value_counts()\n\nprint(X_train.shape)\nprint(test.shape)","2a3ab5ba":"print(X_train.isnull().any().describe())\nprint(\"___________________________\")\nprint(test.isnull().any().describe())\n","c37547a8":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n#Reshape de las im\u00e1genes, utilizando \"channel last\" \nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\n#One hot encoding\nY_train = to_categorical(Y_train, num_classes = 10)\n\n#Dividimos el set de entrenamiento\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 1)\n\n","261e251a":"# [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\n\n#Conv - Conv - Maxpool2D\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#Conv - Conv - Maxpool2D\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10, activation = \"softmax\"))","f6b87eef":"#Definimos el optimizador\noptimizer = Adam()  #lr=0.001\n\n#Compilamos\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","02ac757e":"datagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False, \n        rotation_range=10,  #rota la imagen de 0 a 180 grados\n        zoom_range = 0.1, #Hace zoom a la im\u00e1gen \n        width_shift_range=0.1,  # randomly shift images horizontally \n        height_shift_range=0.1,  # randomly shift images vertically\n        horizontal_flip=False,  \n        vertical_flip=False)  \n\ndatagen.fit(X_train)","dbbb9a5b":"epochs = 30 \nbatch_size = 86\n\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size)\n","6b343c8c":"predictions = model.predict_classes(test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"vvcp2.csv\", index=False, header=True)","ace64b9c":"**Revisamos la data**\n\nSabiendo que:\n    * El set de prueba cuenta con 784 pixeles.\n    * El set de entrenamiento cuenta con 785 pixeles, ya que cuenta con una columna de m\u00e1s llamada \"label\", pero       sin embargo esta se dropeo.\n    \n","d8985a64":"**Normalizando los Datos**","b3a4642f":"**Importaci\u00f3n de librer\u00edas**","cccd69a1":"**Carga de la data**","611f7497":"   Luego de realizar la revisi\u00f3n se observ\u00f3 que no existen null o nan en los sets, y por tanto no es necesario realizar modificaciones a los mismos.","1838745a":"**Entrenamiento del modelo**","09e77c3d":"Proyecto 2:\n* Victor Madureri\n* Carlos Mart\u00ednez\n* Viviana Tepedino","db62dc8f":"**Red Convolucional**"}}