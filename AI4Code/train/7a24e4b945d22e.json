{"cell_type":{"8e9b9f2e":"code","0c4cd218":"code","66c2d6e1":"code","1f86f01d":"code","0a9c04b6":"code","d7c2dc85":"code","051a1b83":"code","88f658d9":"code","9b62c2e8":"code","bdafbd20":"code","a9f5434a":"code","d2e0ba53":"code","bc333e15":"code","7af7918e":"code","250faaae":"code","f27a81db":"code","e78cf6be":"code","a34c15e1":"code","e6e22755":"code","2759d054":"code","38cfbaac":"code","eea5e7a8":"code","c1f68b9c":"code","9485ced7":"code","81b673cd":"code","b097c13e":"code","b54a7cab":"code","9bddab7c":"code","20aa26d3":"code","0ee2bf01":"code","f8aa2ba6":"code","7b92ef0e":"code","6c112482":"code","d3b402a7":"code","a36897ef":"code","14a67651":"code","13022105":"code","3391f08c":"code","c28bac1e":"code","2df3d354":"code","54a85864":"code","bc540ac9":"code","83f5e7d6":"code","16477808":"code","4f1f8c01":"code","12aa0cfb":"code","5a522bd3":"code","b1c7d693":"code","8c33b72b":"code","24d374e8":"code","f4569433":"code","3c2fc0f7":"code","91a86c15":"code","b308f79e":"code","a06c61ae":"code","99abe74e":"code","6f026638":"code","360db0b7":"code","97a8f6f5":"code","ef27b502":"code","83ed4862":"code","21a8820d":"code","4cb476c6":"code","1b43149c":"code","ddece80c":"code","912af885":"code","39ec7317":"code","4cb40ae7":"code","225831fc":"code","ef6a839c":"code","b56295f4":"code","f1ea1c86":"code","00059524":"code","a34a8841":"code","c60f81d8":"code","8e6a2e21":"code","437152a4":"code","648f6ee0":"code","57c6e59b":"code","683dcb44":"code","ffeff710":"code","5fe579dc":"markdown","f2dfc8ec":"markdown","94c0001c":"markdown","7e1eb12c":"markdown","815099c5":"markdown"},"source":{"8e9b9f2e":"#!pip3 install fastai==1.0.42","0c4cd218":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","66c2d6e1":"from fastai import *\nfrom fastai.text import * \nfrom fastai.gen_doc.nbdoc import *\nfrom fastai.datasets import * \nfrom fastai.datasets import Config\nfrom pathlib import Path\nimport pandas as pd","1f86f01d":"#import fastai; \n#fastai.show_install(1)","0a9c04b6":"path = Path('..\/input\/')","d7c2dc85":"df = pd.read_csv(path\/'train.tsv', sep=\"\\t\")\ndf.head()","051a1b83":"df.shape","88f658d9":"df['Sentiment'].value_counts()","9b62c2e8":"df_test = pd.read_csv(path\/'test.tsv', sep=\"\\t\")\ndf_test.head()","bdafbd20":"df = pd.DataFrame({'label':df.Sentiment, 'text':df.Phrase})\ndf.head()","a9f5434a":"test_df = pd.DataFrame({'PhraseId':df_test.PhraseId, 'text':df_test.Phrase})\ntest_df.head()","d2e0ba53":"df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")\ndf_test['text'] = test_df['text'].str.replace(\"[^a-zA-Z]\", \" \")","bc333e15":"import nltk\nnltk.download('stopwords') \nfrom nltk.corpus import stopwords ","7af7918e":"stop_words = stopwords.words('english')","250faaae":"# tokenization \ntokenized_doc = df['text'].apply(lambda x: x.split()) ","f27a81db":"# remove stop-words \ntokenized_doc = tokenized_doc.apply(lambda x:[item for item in x if \n                                    item not in stop_words]) ","e78cf6be":"# de-tokenization \ndetokenized_doc = [] ","a34c15e1":"for i in range(len(df)):\n    t =' '.join(tokenized_doc[i]) \n    detokenized_doc.append(t) ","e6e22755":"df['text'] = detokenized_doc\ndf.head()","2759d054":"# de-tokenization \ndetokenized_doc = [] ","38cfbaac":"df_test.head()","eea5e7a8":"# tokenization \ntokenized_doc = df_test['text'].apply(lambda x: x.split()) ","c1f68b9c":"# remove stop-words \ntokenized_doc = tokenized_doc.apply(lambda x:[item for item in x if \n                                    item not in stop_words]) ","9485ced7":"for i in range(len(df_test)):\n    t =' '.join(tokenized_doc[i]) \n    detokenized_doc.append(t) ","81b673cd":"test_df.head()","b097c13e":"test_df['text'] = detokenized_doc\ntest_df.head()","b54a7cab":"from sklearn.model_selection import train_test_split \n# split data into training and validation set \ndf_trn, df_val = train_test_split(df, stratify = df['label'],  test_size = 0.2, random_state = 12)\ndf_trn.shape, df_val.shape, test_df.shape","9bddab7c":"#data_lm = (TextList.from_csv(path, '\/kaggle\/working\/train.csv', cols='text') \n#                   .random_split_by_pct(0.1)\n#                   .label_for_lm()\n#                   .add_test(TextList.from_csv(path, '\/kaggle\/working\/test.csv', cols='text'))\n#                   .databunch())","20aa26d3":"# Language model data \ndata_lm = TextLMDataBunch.from_df(train_df = df_trn, \n                                  valid_df = df_val,\n                                  test_df = test_df,\n                                  text_cols=['text'],\n                                  path = \"\") ","0ee2bf01":"# Classifier model data \ndata_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, \n                                      valid_df = df_val,\n                                      test_df = test_df,\n                                      vocab=data_lm.train_ds.vocab, \n                                      bs=32)","f8aa2ba6":"learn = language_model_learner(data_lm, pretrained=True,arch=AWD_LSTM, drop_mult=0.7) #pretrained_model=URLs.WT103\n#learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)","7b92ef0e":"#learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, model_dir=\"\/tmp\/model\/\", drop_mult=0.3)\nlearn.model","6c112482":"learn.lr_find()\nlearn.recorder.plot()","d3b402a7":"#learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n#learn.fit_one_cycle(1, 1e-1)\n#learn.save('mini_train_lm')\n#learn.save_encoder('mini_train_encoder')","a36897ef":"# train the learner object with learning rate = 1e-2 \nlearn.fit_one_cycle(3, 1e-2)","14a67651":"#learn.unfreeze()\n#learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))","13022105":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(2e-3\/100, 2e-3))","3391f08c":"learn.predict(\"This is a review about\", n_words=10)","c28bac1e":"#learn.show_results()","2df3d354":"learn.save_encoder('ft_enc')","54a85864":"learn = text_classifier_learner(data_clas, drop_mult=0.7) \nlearn.load_encoder('ft_enc')","bc540ac9":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduction='elementwise_mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        #print(\"inputs\",inputs.shape)\n        #print(\"target\",targets.shape)\n        if self.logits:\n            BCE_loss = F.cross_entropy_with_logits(inputs, targets, reduction='none')\n            #BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        else:\n            #BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n            BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduction is None:\n            return F_loss\n        else:\n            return torch.mean(F_loss)","83f5e7d6":"learn.loss_func = FocalLoss()","16477808":"learn.lr_find()\nlearn.recorder.plot()","4f1f8c01":"learn.fit_one_cycle(3, 1e-3)","12aa0cfb":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(2e-3\/100, 2e-3))","5a522bd3":"# and plot the losses of the first cycle\nlearn.recorder.plot_losses()","b1c7d693":"# get predictions \npreds, targets = learn.get_preds(DatasetType.Valid) \npredictions = np.argmax(preds, axis = 1) ","8c33b72b":"%matplotlib inline\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=2)\n#predictions = model.predict(X_test, batch_size=1000)\n\nLABELS = ['negative','somewhat negative','neutral','somewhat positive','positive'] \n\nconfusion_matrix = metrics.confusion_matrix(targets, predictions)\n\nplt.figure(figsize=(10, 10))\nsns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\nplt.title(\"Confusion matrix\", fontsize=20)\nplt.ylabel('True label', fontsize=20)\nplt.xlabel('Predicted label', fontsize=20)\nplt.show()","24d374e8":"#??TextList.from_csv","f4569433":"#data_clas = (TextList.from_csv(path, '\/kaggle\/working\/train.csv',cols='text', vocab=data_lm.vocab) #test='test'\n#    .split_from_df(col='is_valid') #is_valid\n#    .label_from_df(cols='target')\n#    .add_test(TextList.from_csv(path, '\/kaggle\/working\/test.csv', cols='text'))\n#    .databunch(bs=42))","3c2fc0f7":"#type(data_clas.test_dl)","91a86c15":"#data_clas.show_batch()","b308f79e":"#??text_classifier_learner()","a06c61ae":"#data_clas.c","99abe74e":"#len(data_clas.vocab.itos)","6f026638":"#learn = text_classifier_learner(data_clas, drop_mult=0.5) #metrics=[accuracy_thresh]\n#learn.load_encoder('mini_train_encoder')\n#learn.freeze()\n#learn.model","360db0b7":"#learn.lr_find()","97a8f6f5":"#learn.recorder.plot()","ef27b502":"#learn.crit = F.binary_cross_entropy\n#learn.crit = F.binary_cross_entropy_with_logits","83ed4862":"#learn.metrics = [accuracy, fbeta] #r2_score, top_k_accuracy","21a8820d":"#learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n#learn.fit_one_cycle(1, slice(1e-3,1e-2))\n#learn.save('mini_train_clas')","4cb476c6":"#learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))","1b43149c":"#learn.freeze_to(-2)\n#learn.fit_one_cycle(1, slice(5e-3\/2., 5e-3))\n\n#learn.fit_one_cycle(1, slice(1e-2\/(2.6**4),1e-2), moms=(0.8,0.7))","ddece80c":"#learn.freeze_to(-3)\n#learn.fit_one_cycle(1, slice(5e-3\/(2.6**4),5e-3), moms=(0.8,0.7))","912af885":"#learn.unfreeze()\n#learn.fit_one_cycle(15, slice(2e-3\/100, 2e-3))\n\n#learn.fit_one_cycle(2, slice(1e-3\/(2.6**4),1e-3), moms=(0.8,0.7))","39ec7317":"# get predictions\n#preds, targets = learn.get_preds()\n\n#predictions = np.argmax(preds, axis = 1)\n#pd.crosstab(predictions, targets)","4cb40ae7":"#learn.show_results(rows=20)","225831fc":"# Language model data\n#data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n\n# Classifier model data\n#data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)","ef6a839c":"#type(learn.data.test_dl)","b56295f4":"probs, _ = learn.get_preds(DatasetType.Test)","f1ea1c86":"probs.shape","00059524":"probs[0]","a34a8841":"preds = probs.argmax(dim=1)","c60f81d8":"#preds = np.argmax(probs, axis=1)","8e6a2e21":"ids = df_test[\"PhraseId\"].copy()","437152a4":"submission = pd.DataFrame(data={\n    \"PhraseId\": ids,\n    \"Sentiment\": preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head(n=10)","648f6ee0":"#df.head()","57c6e59b":"#from sklearn.model_selection import train_test_split\n\n# split data into training and validation set\n#df_trn, df_val = train_test_split(df, stratify = df['target'], test_size = 0.4, random_state = 12)","683dcb44":"# Language model data\n#data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"..\/input\")","ffeff710":"# Classifier model data\n#data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)","5fe579dc":"https:\/\/github.com\/fastai\/course-v3\/blob\/master\/nbs\/dl1\/lesson3-imdb.ipynb","f2dfc8ec":"# Validation Set","94c0001c":"# Classifier","7e1eb12c":"# Predict Test","815099c5":"https:\/\/docs.fast.ai\/text.html"}}