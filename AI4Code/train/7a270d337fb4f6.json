{"cell_type":{"14699c64":"code","e18c54df":"code","5635d865":"code","007793be":"code","727bdbe8":"code","74f4bf80":"code","75fc443c":"markdown","8b6747c8":"markdown","87daefcf":"markdown","67ba1477":"markdown"},"source":{"14699c64":"import random\nimport pandas as pd\nimport itertools\nimport numpy as np\nimport torch\nimport datetime\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm","e18c54df":"# Return three list containing all the combinations that each map must use\ndef clean(permus, fraq_1=1\/3, fraq_2=1\/2):\n    start = permus[permus.Permutation.str[:2] =='\ud83c\udf85\ud83e\udd36']\n    other = permus[permus.Permutation.str[:2] !='\ud83c\udf85\ud83e\udd36'].reset_index(drop=True)\n\n    # Fais 3 liste qui contient les differentes permutations\n    permus4str_1 = start.copy()\n    permus4str_2 = start.copy()\n    permus4str_3 = start.copy()\n\n    add_to_1 = other.sample(frac=fraq_1)\n    other = other.drop(add_to_1['Permutation'].index.tolist())\n    add_to_2 = other.sample(frac=fraq_2)\n    other = other.drop(add_to_2['Permutation'].index.tolist())\n    add_to_3 = other.copy()\n\n    permus4str_1 = pd.concat([permus4str_1, add_to_1])\n    permus4str_1 = permus4str_1.sort_index()\n    permus4str_2 = pd.concat([permus4str_2, add_to_2])\n    permus4str_2 = permus4str_2.sort_index()\n    permus4str_3 = pd.concat([permus4str_3, add_to_3])\n\n    city_1, city_2, city_3 = [], [], []\n\n    for string in permus4str_1['Permutation'].tolist():\n        city_1.append(change(string))\n\n    for string in permus4str_2['Permutation'].tolist():\n        city_2.append(change(string))\n\n    for string in permus4str_3['Permutation'].tolist():\n        city_3.append(change(string))\n\n    return city_1, city_2, city_3\n\n# Return the distance matrix with only the distances of the cities in the list city\ndef get_dist_mat(dist_mat, city):\n    to_export = pd.DataFrame(columns=city, index=city)\n    for c in city:\n        to_export.loc[c] = dist_mat.loc[c]\n\n    to_export = to_export.to_numpy()\n    to_export[to_export==0] = 99999\n\n    return to_export\n\n# Check if the submission the good\ndef check_if_good(a):\n    is_false = False\n    error_count_start = 0\n    error_count_other = 0\n    # Check if the submission is valid\n    wildcard = pd.read_csv('..\/input\/santa-2021\/wildcards.csv')\n    permus = pd.read_csv('..\/input\/santa-2021\/permutations.csv')\n    start = permus[permus.Permutation.str[:2] =='\ud83c\udf85\ud83e\udd36']\n    other = permus[permus.Permutation.str[:2] !='\ud83c\udf85\ud83e\udd36'].reset_index(drop=True)\n\n    # If all the combinations beginning with \ud83c\udf85\ud83e\udd36 are in the three submissions\n    for permu in start['Permutation'].tolist():\n        if permu in a[0]:\n            if permu in a[1]:\n                if permu in a[2]:\n                    continue\n        # For wildcards\n        permus_for_wild = wildcard[wildcard['Permutation']==permu].index.values\n        in_string = False\n        for p in permus_for_wild:\n            if wildcard.at[p, 'Factor'] in a[0]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[1]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[2]: in_string = True\n        if in_string: continue\n        is_false = True\n        #print(\"Not all \ud83c\udf85\ud83e\udd36, missing:\", permu)\n        error_count_start += 1\n\n    # If all the combinations are in the submissions\n    for permu in other['Permutation'].tolist():\n        if permu in a[0]: continue\n        if permu in a[1]: continue\n        if permu in a[2]: continue\n\n        # For wildcards\n        permus_for_wild = wildcard[wildcard['Permutation']==permu].index.values\n        in_string = False\n        for p in permus_for_wild:\n            if wildcard.at[p, 'Factor'] in a[0]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[1]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[2]: in_string = True\n        if not in_string:\n            is_false = True\n            #print(\"Not all the combinaison, missing:\", permu)\n            error_count_other += 1\n\n    # If there are 2 stars or less\n    if a[0].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 0\")\n        return False\n    if a[1].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 1\")\n        return False\n    if a[2].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 2\")\n        return False\n\n    if is_false:\n        print(\"Nombre d'erreur start:\", error_count_start, ', other', error_count_other)\n        return False\n    return True\n\n# Turn icons into numbers\ndef change(a):\n    a = a.replace(\"\ud83c\udf85\", \"1\")\n    a = a.replace('\ud83e\udd36', \"2\")\n    a = a.replace('\ud83e\udd8c', \"3\")\n    a = a.replace('\ud83e\udddd', \"4\")\n    a = a.replace('\ud83c\udf84', \"5\")\n    a = a.replace('\ud83c\udf81', \"6\")\n    a = a.replace('\ud83c\udf80', \"7\")\n    return a\n\n\ndef rechange(a):\n    a = a.replace(\"1\", \"\ud83c\udf85\")\n    a = a.replace(\"2\", '\ud83e\udd36')\n    a = a.replace(\"3\", '\ud83e\udd8c')\n    a = a.replace(\"4\", '\ud83e\udddd')\n    a = a.replace(\"5\", '\ud83c\udf84')\n    a = a.replace(\"6\", '\ud83c\udf81')\n    a = a.replace(\"7\", '\ud83c\udf80')\n    return a\n\n# Save the solution\ndef save_schedule(sub, permus):\n    if check_if_good(sub):\n        print(\"Submission valid!\")\n        print('Final score:', max([len(sub[0]), len(sub[1]), len(sub[2])]))\n        sub_df = pd.DataFrame()\n        sub_df['schedule'] = sub\n        sub_df.to_csv('submission.csv', index=False)\n        print(sub_df.head())\n\n# Removes cities already used by chance by a previous map\ndef clear_already_in(a, b, permus):\n    in_b = []\n    for p in permus['Permutation'].tolist():\n        p = change(p)\n        if p in b:\n            in_b.append(p)\n\n    for p in in_b:\n        if p in a:\n            a.remove(p)\n    return a","5635d865":"# Optimisation stuff, thx YOSSHI999\ndef find_strings_perms(strings, verbose=False):\n    found_perms = []\n    perms = list(map(lambda p: \"\".join(p), itertools.permutations(\"1234567\")))\n    for s in strings:\n        found_perms.append([])\n        for i in range(len(s)-6):\n            p = s[i:i+7]\n            if p in perms:\n                found_perms[-1].append(p)\n    if verbose:\n        lens = [len(_) for _ in  found_perms]\n        print(f'There are {lens} permutations in strings, {sum(lens)} in total.')\n        lens = [len(set(_)) for _ in  found_perms]\n        print(f'There are {lens} unique permutations in strings, {sum(lens)} in total.')\n    return found_perms\n\n\ndef rebalance_perms(strings_perms, verbose=False):\n    # convert to dicts for fast lookup and to keep permutations order\n    strings_perms = [dict.fromkeys(_) for _ in strings_perms]\n    for p in strings_perms[0].copy():  # iterate over the copy to allow modification during iteration\n        if p[:2] != \"12\" and (p in strings_perms[1] or p in strings_perms[2]):\n            strings_perms[0].pop(p)\n    for p in strings_perms[1].copy():\n        if p[:2] != \"12\" and p in strings_perms[2]:\n            strings_perms[1].pop(p)\n    if verbose:\n        lens = [len(_) for _ in  strings_perms]\n        print(f'There are {lens} permutations left in strings after rebalancing, {sum(lens)} in total.')\n    return [list(_) for _ in strings_perms]\n\n\ndef star_optimization(a):\n    symbols = \"\ud83c\udf85\ud83e\udd36\ud83e\udd8c\ud83e\udddd\ud83c\udf84\ud83c\udf81\ud83c\udf80\"\n    words = a\n\n    schedules = []\n    schedules.append(change(a[0]))\n    schedules.append(change(a[1]))\n    schedules.append(change(a[2]))\n\n    perms = list(map(lambda p: \"\".join(p), itertools.permutations(\"1234567\")))\n    found_perms = find_strings_perms(schedules)\n    balanced_perms = rebalance_perms(found_perms)\n    perm2id = {p: i for i, p in enumerate(perms)}\n    perms_arr = np.array([list(map(int, p)) for p in perms])\n\n    perms_onehot = np.eye(7)[perms_arr-1, :].transpose(0, 2, 1)\n    assert np.allclose(perms_onehot[:,0,:].astype(np.int64), (perms_arr == 1).astype(np.int64))\n\n    left = perms_onehot[perm2id[\"1234567\"]]\n    right = perms_onehot[perm2id[\"5671234\"]]\n    matches = F.conv2d(\n        F.pad(torch.Tensor(left[None, None, :, :]), (7, 7)),\n        torch.Tensor(right[None, None, :, :]),\n        padding=\"valid\"\n    ).numpy().reshape(-1)\n    must_match_left2right = np.array([-1, -1, -1, -1, -1, -1, -1, 7, 6, 5, 4, 3, 2, 1, 0])\n    must_match_right2left = np.array([0, 1, 2, 3, 4, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1])\n    cost_ifmatch = np.array([7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7])\n\n    M = F.conv2d(\n        F.pad(torch.Tensor(perms_onehot[:, None, :, :]), (7, 7)),\n        torch.Tensor(perms_onehot[:, None, :, :]),\n        padding=\"valid\"\n    ).squeeze().numpy()\n\n    must_match_left2right = np.array([-1, -1, -1, -1, -1, -1, -1, 7, 6, 5, 4, 3, 2, 1, 0])\n    must_match_left2right_wild = np.array([-1, -1, -1, -1, -1, -1, -1, 6, 5, 4, 3, 2, 1, 0, 0])\n\n    cost_ifmatch = np.array([7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7])\n\n    costMat = np.where(M == must_match_left2right, cost_ifmatch, np.inf).min(axis=-1).astype(np.int8)\n    costMatWild = np.minimum(costMat, np.where(M == must_match_left2right_wild, cost_ifmatch, np.inf).min(axis=-1)).astype(np.int8)\n\n    nodes_list = []\n    table_list = []\n\n    for i in range(3):\n        word = words[i]\n        nodes = [perm2id[p] for p in balanced_perms[i]]\n\n        table = np.zeros((len(nodes), 10), np.int64)\n        table[0, :] = 7\n        for i in range(1, len(nodes)):\n            e = costMat[nodes[i-1], nodes[i]]\n            ew = costMatWild[nodes[i-1], nodes[i]]\n            table[i,0] = table[i-1,0] + e\n            table[i,1] = min(table[i-1,1] + e, table[i-1,0] + ew)\n            table[i,2] = min(table[i-1,2], table[i-1,1]) + e\n            table[i,3] = min(table[i-1,3], table[i-1,2]) + e\n            table[i,4] = min(table[i-1,4], table[i-1,3]) + e\n            table[i,5] = min(table[i-1,5], table[i-1,4]) + e\n            table[i,6] = min(table[i-1,6], table[i-1,5]) + e\n            table[i,7] = min(table[i-1,7], table[i-1,6]) + e\n            table[i,8] = min(table[i-1,8], table[i-1,7]) + e\n            table[i,9] = min(table[i-1,9] + e, table[i-1,8] + ew)\n        nodes_list.append(nodes)\n        table_list.append(table)\n\n    # backtrack\n    new_words = []\n    wilds = []\n    for nodes, table in zip(nodes_list, table_list):\n        ns = [perms[nodes[-1]]]\n        track = np.argmin(table[-1])\n        wild = []\n        for i in range(len(nodes)-2, -1, -1):\n            e = costMat[nodes[i], nodes[i+1]]\n            ew = costMatWild[nodes[i], nodes[i+1]]\n            if track == 0:\n                ns.append(perms[nodes[i]][:e])\n            elif track == 1:\n                if table[i, 1] + e < table[i, 0] + ew:\n                    ns.append(perms[nodes[i]][:e])\n                else:\n                    left = np.array(list(map(int, perms[nodes[i]][ew:])))\n                    right = np.array(list(map(int, perms[nodes[i+1]][:-ew])))\n                    mis = np.where(left != right)[0][0]\n                    wild.append(table[i, track-1]-7+ew+mis)\n                    ns.append(perms[nodes[i]][:ew])\n                    track = track - 1\n            elif 2 <= track <= 8:\n                if table[i, track] >= table[i, track-1]:\n                    track = track - 1\n                ns.append(perms[nodes[i]][:e])\n            elif track == 9:\n                if table[i, 9] + e < table[i, 8] + ew:\n                    ns.append(perms[nodes[i]][:e])\n                else:\n                    ns.append(perms[nodes[i]][:ew])\n                    left = np.array(list(map(int, perms[nodes[i]][ew:])))\n                    right = np.array(list(map(int, perms[nodes[i+1]][:-ew])))\n                    mis = np.where(left != right)[0][0]\n                    wild.append(table[i, track-1]-7+ew+mis)\n                    track = track - 1\n            else:\n                assert False\n        assert track == 0\n        wilds.append(wild)\n        nsw = list(\"\".join(ns[::-1]))\n        for w in wild:\n            nsw[w] = \"*\"\n        new_words.append(\"\".join(nsw))\n\n    print(\"Optimisation done\")\n    print(\"score: \", max(map(len, words)), \"->\", max(map(len, new_words)))\n    sub = [a.translate(str.maketrans(\"1234567*\", symbols+\"\ud83c\udf1f\")) for a in new_words]\n    if check_if_good(sub): print(\"Optimization validated\")\n\n    return sub","007793be":"# The ant class\nclass Ant:\n    def __init__(self, map):\n        self.map = map\n        self.visited = np.ones((self.map.nb_city,), dtype=bool)  # Boolean of if the city has been visited\n        self.position_id = self.map.city.index(random.choice(self.map.city))  # Id of current position\n        self.visited[self.position_id] = 0\n        self.dist_trav = 7  # Distance traveled\n        self.path = self.map.city[self.position_id] # What we are looking for\n        self.path_id = [0] * self.map.nb_city # History of the path for pheromones\n        self.path_id[0] = self.position_id\n        self.path_act_id = 1\n\n    def update(self):\n        dis, phero = self.map.dist_mat[self.position_id, :], self.map.pheros[self.position_id, :]\n        dis[dis < 0] = self.map.inf_dist\n\n        weight = (self.visited * phero) \/ ((dis * 2) ** self.map.coef_dist_puiss)\n\n        next_city_id = random.choices(range(self.map.nb_city), weights=weight, k=1)[0]\n\n        self.path += self.map.city[next_city_id][(7-int(dis[next_city_id])):]\n        self.path_id[self.path_act_id] = next_city_id\n        self.path_act_id += 1\n\n        self.dist_trav += self.map.dist_mat[self.position_id, next_city_id]\n        self.position_id = next_city_id\n        self.visited[self.position_id] = 0\n\n    def find_path(self):\n        for i in range(self.map.nb_city-1):\n            self.update()\n\n    def update_pheros(self):\n        x = 100\n        coef = -50\n        for i in range(x):\n            if self.dist_trav <= (self.map.dist_min + self.map.dist_delta * (i \/ x)):\n                coef += 1\n        for i in range(len(self.path_id)-1):\n            self.map.pheros[self.path_id[i], self.path_id[i+1]] += coef","727bdbe8":"# The map class\nclass Map:\n    # Settings\n    phero_start_fact = 1000\n    inf_dist = 9999\n\n    def __init__(self, city, dist_mat, name, coef_dist_puiss=20,\n                 nb_ant=20, nb_turn=100, do_print=True):\n        self.city = city # List of city to travel\n        self.name = name # Name of the map\n        self.nb_ant = nb_ant # Number of ants\n        self.nb_turn = nb_turn # Number of turn to do\n        self.dist_mat = dist_mat # Distance matrix\n\n        self.pheros = np.ones(self.dist_mat.shape) * self.phero_start_fact # Pheromones matrix\n\n        self.shortest_path = \"\"\n        self.shortest_dist = 9999999999999\n        self.dist_min = 0\n        self.dist_max = 0\n        self.dist_delta = 0\n        self.nb_city = len(city)\n\n        self.coef_dist_puiss = coef_dist_puiss # Coef to use in ant.update, 5-10 is good\n        self.ants = [] # List of ant\n        for i in range(self.nb_ant):\n            self.ants.append(Ant(self))\n\n        self.pbar = None # The progress bar\n\n    def update(self):\n        ants_dist = [0] * len(self.ants)\n        i = 0\n        for ant in self.ants:\n            ant.find_path()\n            dis = ant.dist_trav\n            ants_dist[i] = dis\n            if dis < self.shortest_dist:\n                self.shortest_dist = dis\n                self.shortest_path = ant.path\n            i+=1\n            self.pbar.update(1)\n        self.dist_min = min(ants_dist)\n        self.dist_max = max(ants_dist)\n        self.dist_delta = self.dist_max - self.dist_min\n        for ant in self.ants:\n            ant.update_pheros()\n            ant.__init__(self)\n\n    def start(self):\n        # Start the simulation\n        with tqdm(total=self.nb_turn*self.nb_ant, desc=self.name,unit=\"ant\") as pbar:\n            self.pbar = pbar\n            for i in range(self.nb_turn):\n                self.update()\n","74f4bf80":"#-------------------------------------------------------------------------------------------------\nprint(\"Init...\")\nnp.seterr(divide='ignore', invalid='ignore')\n\n#-------------------------------------------------------------------------------------------------\nprint(\"Import...\")\n\npermus = pd.read_csv(\"..\/input\/santa-2021\/permutations.csv\")\ndist_mat = pd.read_csv(\"..\/input\/santa-2021\/distance_matrix.csv\")\ndist_mat.set_index('Permutation', inplace=True)\ndic = {}\nfor c in dist_mat.columns:\n    dic[c] = change(c)\ndist_mat.rename(dic, axis=1, inplace=True)\ndist_mat.rename(dic, axis=0, inplace=True)\nother = permus[permus.Permutation.str[:2] !='\ud83c\udf85\ud83e\udd36'].reset_index(drop=True)\n\n#-------------------------------------------------------------------------------------------------\nprint(\"Clean...\")\n\ncity_1, city_2, city_3 = clean(permus, fraq_1=0.28, fraq_2=0.42)\n\n#-------------------------------------------------------------------------------------------------\nprint(\"Calcul...\")\nnb_ant = 2\nnb_turn = 5\ncoef_dist_puiss = 10\n\nprint(\"The calculation will take approximately \" + str(datetime.timedelta(seconds=(1.2 * 3 * nb_ant * nb_turn))))\nprint('Start for nb_ant:', nb_ant, ', nb_turn', nb_turn, )\n\ndist_mat_map_1 = get_dist_mat(dist_mat, city_1)\nmap_1 = Map(city_1, dist_mat_map_1, \"map_1\", nb_ant=nb_ant, nb_turn=nb_turn,\n            coef_dist_puiss=coef_dist_puiss, do_print=False)\nmap_1.start()\nprint(\"map_1 Done, score:\", map_1.shortest_dist, 'Nb_city:', len(city_1))\n\ncity_2 = clear_already_in(city_2, map_1.shortest_path, other)\ncity_3 = clear_already_in(city_3, map_1.shortest_path, other)\n\ndist_mat_map_2 = get_dist_mat(dist_mat, city_2)\nmap_2 = Map(city_2, dist_mat_map_2, \"map_2\", nb_ant=nb_ant, nb_turn=nb_turn,\n            coef_dist_puiss=coef_dist_puiss, do_print=False)\nmap_2.start()\nprint(\"map_2 Done, score:\", map_2.shortest_dist, 'Nb_city:', len(city_2))\n\ncity_3 = clear_already_in(city_3, map_2.shortest_path, other)\n\ndist_mat_map_3 = get_dist_mat(dist_mat, city_3)\nmap_3 = Map(city_3, dist_mat_map_3, \"map_3\", nb_ant=nb_ant, nb_turn=nb_turn,\n            coef_dist_puiss=coef_dist_puiss, do_print=False)\nmap_3.start()\nprint(\"map_3 Done, score:\", map_3.shortest_dist, 'Nb_city:', len(city_3))\n\n#-------------------------------------------------------------------------------------------------\nprint(\"Optimise...\")\n\npaths = [rechange(map_1.shortest_path), rechange(map_2.shortest_path), rechange(map_3.shortest_path)]\npaths = star_optimization(paths)\n\n#-------------------------------------------------------------------------------------------------\nprint(\"Check...\")\n\nsave_schedule(paths, permus)\n\n#-------------------------------------------------------------------------------------------------\nprint('Done!')","75fc443c":"# Functions","8b6747c8":"# Introduction\nHi I tried to find a solution using the ant method I saw in a Sebastian Lague video (https:\/\/www.youtube.com\/watch?v=X-iSQQgOd1A&t=207s).\n\nIt consists in taking a pack of ants, making them start in a random city (or here permutation), each of which looks at the distance that separates it from the next cities. They then randomly choose a city with greater luck if the city is closer. They continue like this until they get a path. The path then obtains a score which depends on the length of the path, the shorter the path the better, which allows to increase or reduce the power of the pheromones. Each possible movement between two cities has a pheromone level. The higher the level, the more likely the ants have to take this route.\n\nThis way the ants remember the most efficient paths and try to optimize them. But it is, of course, a local minimum.\n\nThere are two class in my code, ant which represents an ants and map which represents the land on which the ants are.\n\nIt's more or less my first data project so I hope it's okay. It is far from being optimized. I had ideas to use numba cuda, it can be done quite easily with an incredible performance improvement I think. Since all the ants would work in parallel. But I'll leave it there for now. I also had ideas to optimize the stars and many other things but I have to focus on my google data analytics certification. To give an idea this gives me a score of about 4000 for 30s of computation time.","87daefcf":"# Main","67ba1477":"# Class"}}