{"cell_type":{"8399b426":"code","c8961649":"code","d98b5d38":"code","d638b1c0":"code","4780c469":"code","051cf434":"code","8aa2060d":"code","460f2acd":"code","85183a72":"code","912e965a":"code","629f9e2c":"code","f9987973":"code","6728477f":"code","6dfca0d7":"code","686cdde7":"code","abd4c6e8":"code","22734908":"code","2a22b166":"code","108b8f92":"code","91311b5a":"code","9276a485":"code","503594ff":"code","b78a9d21":"code","7ed3cdbe":"code","c14621e0":"code","111b42c2":"code","7bb3b5ff":"code","fed8616b":"code","fa2ad6f6":"code","cf96ef01":"code","421c0c7b":"code","5aebdc2d":"code","580298fa":"code","8793155d":"code","2bdc1474":"code","3161b69c":"code","7360cd8e":"code","703ea85b":"code","b56b298a":"code","c863eee4":"code","7f80c45b":"code","96b08441":"code","6d52090b":"code","f5377ae9":"code","4b9bbbd8":"code","4e78d5f7":"code","b4582c09":"code","e7ec9a55":"code","67a56004":"code","4af3f5d9":"code","b19dfd4f":"code","f7d6e1d6":"code","2793b636":"code","0c99123a":"code","bd1829dc":"code","2b699c88":"code","ee7955f5":"code","791fe943":"code","43b0bc36":"code","56115940":"code","7b4f86c1":"code","8c305f89":"code","0c56101a":"code","52c2c579":"code","edc4b44c":"code","2cc11bfb":"code","1accad1d":"code","e07ed1be":"code","5a27ee68":"code","90820ed5":"markdown","48eea49c":"markdown","05323d12":"markdown","7db5f8e9":"markdown","5ca5151f":"markdown","e20a62ce":"markdown","a79d8fad":"markdown","b26dba4f":"markdown","27549802":"markdown","d4b10a0f":"markdown","bc4bb885":"markdown","42426830":"markdown","c97009a9":"markdown","af941528":"markdown","788b64b4":"markdown","2866dc3d":"markdown","a4cdc78f":"markdown","157d5741":"markdown","74e9ca32":"markdown","9016f582":"markdown"},"source":{"8399b426":"import numpy as np\nimport pandas as pd\nimport seaborn \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report","c8961649":"%config Completer.use_jedi = False # for autocompletion to work","d98b5d38":"df = pd.read_csv('\/kaggle\/input\/confused-eeg\/EEG_data.csv')","d638b1c0":"df.head()","4780c469":"df.info()","051cf434":"demo_df = pd.read_csv('\/kaggle\/input\/confused-eeg\/demographic_info.csv')","8aa2060d":"demo_df.head()","460f2acd":"## Renaming columns for easy merging\ndemo_df = demo_df.rename(columns = {'subject ID': 'SubjectID'})","85183a72":"demo_df.head()","912e965a":"df.head()","629f9e2c":"df = df.merge(demo_df,how = 'inner',on = 'SubjectID')","f9987973":"df.head()","6728477f":"df = pd.get_dummies(df)","6dfca0d7":"df.head()","686cdde7":"df.columns","abd4c6e8":"## Missing value check\nprint(\"Missing values count : \" + str(df.isna().sum().sum()))","22734908":"df[' gender_F'].value_counts()","2a22b166":"df['user-definedlabeln'].value_counts()","108b8f92":"df.drop(['SubjectID','VideoID','predefinedlabel', ' gender_F'],axis = 1,inplace=True)","91311b5a":"df = df[df['Attention']> 0.0]","9276a485":"df.hist(figsize = (15,15))\nplt.show()","503594ff":"df = df[df['Mediation']> 0.0]\ndf.hist(figsize = (15,15))\nplt.show()","b78a9d21":"plt.figure(figsize = (15,15))\ncorr_matrix = df.corr()\nseaborn.heatmap(corr_matrix,vmin = -1.0, square=True, annot = True)","7ed3cdbe":"df['user-definedlabeln'].unique()","c14621e0":"df['user-definedlabeln'].value_counts()","111b42c2":"X = np.array(df.drop(['user-definedlabeln'],axis = 1))","7bb3b5ff":"y = np.array(df['user-definedlabeln'])","fed8616b":"X.min(), X.max()","fa2ad6f6":"from sklearn.preprocessing import StandardScaler","cf96ef01":"# Transforming data to have mean 0 and std 1","421c0c7b":"X = StandardScaler().fit_transform(X)","5aebdc2d":"X.min(), X.max()","580298fa":"# from sklearn.model_selection import train_test_split\n\n# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25)\n\n# X_train.shape, y_train.shape\n\n# X_test.shape, y_test.shape\n\n# X_train= np.reshape(X_train,(X_train.shape[0], X_train.shape[1],1))\n\n# X_train.shape\n\n# X_test= np.reshape(X_test,(X_test.shape[0], X_test.shape[1],1))\n\n# X_test.shape\n\n# X_train[0]","8793155d":"import tensorflow as tf","2bdc1474":"dataset = tf.data.Dataset.from_tensor_slices((X,y))","3161b69c":"dataset_size = X.shape[0]\ndataset_size","7360cd8e":"train_size = int(0.75 * dataset_size)\ntrain_size","703ea85b":"X_train = dataset.take(train_size)\nX_test = dataset.skip(train_size)","b56b298a":"# for i in X_train :\n#     print(np.array(i[0]).shape,np.array(i[1]).shape)","c863eee4":"X_train = X_train.shuffle(len(X_train))","7f80c45b":"# Making batches of 32 \nX_train = X_train.batch(32)\nX_train","96b08441":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\n\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Attention, Lambda, Dot, Concatenate,Dropout, Activation\n\nfrom tensorflow.keras import backend as K\n\ntf.keras.backend.clear_session()","6d52090b":"from tensorflow.keras.layers import Layer\nfrom tensorflow.keras import backend as K\n\n# Bahdanau et al. implementation of Attention Layer\n\n# attention weights are softmax of (v*(w*s<t-1> + u*h))\n# s<t-1> is hidden state at <t-1> of decoder and h is hidden state outputs of the encoder\n\nclass Attention(Layer):\n    \n    def __init__(self, return_sequences=True):\n        self.return_sequences = return_sequences\n        super(Attention,self).__init__()\n        \n    def build(self, input_shape):\n        \n        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n                               initializer=\"normal\")\n        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n                               initializer=\"zeros\")\n        \n        super(Attention,self).build(input_shape)\n        \n    def call(self, x):\n        \n        e = K.tanh(K.dot(x,self.W)+self.b)\n        a = K.softmax(e, axis=1)\n        output = x*a\n        \n        if self.return_sequences:\n            return output\n        \n        return K.sum(output, axis=1)","f5377ae9":"\n# model = Sequential([\n#     LSTM(256,activation = 'relu',input_shape = (X_train.shape[1:]),return_sequences = True),\n#     Dropout(0.2),\n#     LSTM(256,activation = 'sigmoid',return_sequences=True),\n#     Dropout(0.2),\n#     LSTM(128,return_sequences=True,activation = 'sigmoid'),\n#     Dropout(0.2),\n#     LSTM(64),\n#     Dropout(0.2),\n#     Dense(1,activation = 'sigmoid')\n# ])","4b9bbbd8":"type(X_train)","4e78d5f7":"inputs = tf.keras.Input(shape=(16, 1))#lstm takes 3d input of the shape [batch_size, timesteps, feature]\n#time steps is the number of the input feature and the features is the number corresponding output value we want to predict\nDense1 = Dense(64, activation = 'relu')(inputs)\nDense2 = Dense(128, activation = 'relu')(Dense1)\nlstm_1=  LSTM(256, return_sequences = True)(Dense2)\ndrop = Dropout(0.2)(lstm_1)\nlstm_3=  LSTM(256, return_sequences = True)(drop)\ndrop2 = Dropout(0.2)(lstm_3)\natt_ = Attention(256)(drop2)\nDense_1 = Dense(128, activation = 'relu')(att_)\noutputs = Dense(1, activation='sigmoid')(Dense_1)\n\nmodel = tf.keras.Model(inputs, outputs)\n","b4582c09":"model.summary()","e7ec9a55":"model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])","67a56004":"bs = 32\nepochs = 100","4af3f5d9":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='\/tmp\/model.png', show_shapes=True,)","b19dfd4f":"#spliting it into the train and testing\nfrom sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.25)","f7d6e1d6":"#A sample for predicting output while training each epoch\nx = np.expand_dims(train_X[0], axis = 0)\nx.shape","2793b636":"x.shape","0c99123a":"class CallBacks(tf.keras.callbacks.Callback):\n    \n    def __init__(self,filepath):\n        super(CallBacks,self).__init__()\n        self.model_name = filepath\n        \n    def on_train_begin(self, logs = {}):\n        self.losses = []\n        self.acc = []\n        self.logs = []\n        keys = list(logs.keys())\n        print(\"Starting epoch {} , got keys {}\".format(len(self.losses)+1,keys))\n    \n    def on_epoch_end(self,epoch,logs = {}):\n        current = logs.get('loss')\n        # Appending logs, losses and accuracies to lists\n        self.logs.append(logs)\n        self.losses.append(logs.get(\"loss\"))\n        self.acc.append(logs.get(\"accuracy\"))\n        keys = list(logs.keys())\n        print(\"End of epoch {} , got keys {} and accuracy is {}\".format(len(self.losses), keys, logs['accuracy']))\n        \n        # Clear the previous plots\n        N = np.arange(0,len(self.losses))\n        print(N)\n        # prediction over the sample x \n        prediction = self.model.predict(x)\n        y_pred = np.array(prediction >= 0.5, dtype = np.int)\n        print(\"Predicted : {}\".format(y_pred[0][0][0]))\n        print(\"Actual : {}\".format(train_y[0]))\n        \n        # Plot the losses\n        fig, axes = plt.subplots(1)\n        plt.figure()\n        \n        axes.plot(N,self.losses, label = 'train_loss')\n        axes.plot(N,self.acc, label = 'train_acc')\n        fig.suptitle(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n        axes.legend()\n        plt.show()\nplot_losses = CallBacks(filepath = '.')","bd1829dc":"x.reshape(-1,1).shape","2b699c88":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n                              patience=5, min_lr=0.001)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n                            monitor = 'accuracy',\n                            patience = 5,\n                            restore_best_weights=True\n                )","ee7955f5":"# No callbacks\nhistory = history1 = model.fit(X_train,batch_size=bs,\n                   epochs = epochs,\n                callbacks = [reduce_lr,plot_losses,early_stop])","791fe943":"!mkdir 'weights'","43b0bc36":"!ls","56115940":"model.save_weights('.\/weights\/model__eeg2.h5')","7b4f86c1":"model.load_weights('.\/weights\/model__eeg2.h5')","8c305f89":"plt.figure(figsize = (16,10))\nplt.plot(range(len(history1.history['loss'])),history1.history['loss'],label = 'Train loss')\nplt.plot(range(len(history1.history['accuracy'])),history1.history['accuracy'],label = 'Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(\"Loss vs Time \")\nplt.legend()\nplt.show()\n","0c56101a":"train_X= np.reshape(train_X,(train_X.shape[0], train_X.shape[1],1))\n\nprint(train_X.shape)\n\ntest_X= np.reshape(test_X,(test_X.shape[0], test_X.shape[1],1))\n\nprint(test_X.shape)\nprint(test_y.shape)","52c2c579":"best_acc,epoch_at = max(history1.history['accuracy']),history1.history['accuracy'].index(max(history1.history['accuracy']))\nbest_acc *= 100\nprint(\"Best Accuracy : {:.2f} % at epoch : {}\".format(best_acc,epoch_at))","edc4b44c":"model.evaluate(test_X,test_y)","2cc11bfb":"y_true = np.array(test_y)\ny_pred = np.squeeze(model.predict(test_X))\ny_pred","1accad1d":"y_pred = np.array(y_pred >= 0.5, dtype = np.int)","e07ed1be":"y_pred","5a27ee68":"np.expand_dims(test_X[0],axis = 0)\nmodel.predict(np.expand_dims(test_X[0],axis = 0))","90820ed5":"# Model Definition","48eea49c":"## Let's clean the data\n\nThe SubjectID and VideoID will provide hinderance while model training as there are 10 clips for 10 students and these 1-2 min clips are divided ino parts of 0.5 sec samples. So Model will most probably learn based on IDs but we want it to learn on based of ethinicity and gender and age parameters","05323d12":"# About the Dataset","7db5f8e9":"### The callbacks \nWe will use reduce_lr callback and early stopping thus made their instances","5ca5151f":"### Having one hot encoding for categorical variables like gender and stuff","e20a62ce":"## Getting the demographic data","a79d8fad":"**EEG signal Data gathered from 10 college students collected when they were watching MOOC Videos. There were 20 total videos out of which 10 were confusing (like Quantum Mechanics) and 10 were non-confusing (simple algebra, geometry)**","b26dba4f":"The students wore a **single channel wireless headset (MindSet)** to caputre their  eeg signals and reported their confusion on a scale of one to seven.\n\nThe **MindSet** measures the voltage between the electrode resting on forehead and two electrodes (one ground and one reference) each in contact with each ear.","27549802":"### Using tf.data.Dataset ","d4b10a0f":"## Data Preprocessing","bc4bb885":"Output is labels as confused or not indicated as 0-Confused and 1-Not confused","42426830":"# Custom Attention Layer","c97009a9":"# Custom Callback for each epoch outputs","af941528":"### Merging both the dataframes based on SubjectId","788b64b4":"### Splitting the dataset based on user-defined labels","2866dc3d":"As from the heatmap, We see there is a good correlation between **Gamma1 and Beta2**","a4cdc78f":"## Data Split","157d5741":"### Let's have a Correlation Matrix","74e9ca32":"## Getting the EEG Data","9016f582":"# Plots and evaluation "}}