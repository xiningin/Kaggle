{"cell_type":{"1c9bd049":"code","56fd410a":"code","61a530e0":"code","5b702bf0":"code","25e07d48":"markdown","b62484d1":"markdown"},"source":{"1c9bd049":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","56fd410a":"### LGB\nm15 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m15.csv')\nm17 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m17.csv')\nm18 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m18.csv')\nm19 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m19.csv')\nm20 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m20.csv')\n### Catboost\nm16 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m16.csv')\n### NN\nm0 = pd.read_csv('\/kaggle\/input\/ieee-top-models-blend\/m0.csv')\n\nsubmission = pd.read_csv(\"\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv\")\nsubmission.head()","61a530e0":"m18.head()","5b702bf0":"submission['isFraud'] = (0.20*m15.isFraud) + \\\n                        (0.20*m17.isFraud) + \\\n                        (0.20*m18.isFraud) + \\\n                        (0.20*m19.isFraud) + \\\n                        (0.10)*m20.isFraud + \\\n                        (0.10*m16.isFraud) + \\\n                        (0.0*m0.isFraud)       \n                        \nsubmission.to_csv('my_blend_5.csv', index=False)","25e07d48":"### LGB \/ XGB \n* m1 = k-fold xgb [0.9383] : https:\/\/www.kaggle.com\/artkulak\/ieee-fraud-simple-baseline-0-9383-lb\n* m2 = h20 automl [0.9395] : https:\/\/www.kaggle.com\/tunguz\/ieee-with-h2o-automl\n* m3 = lgb + fe [0.9408] : https:\/\/www.kaggle.com\/kyakovlev\/ieee-ground-baseline\/output\n* m4 = lgb + bayesian tuning [ ] : [https:\/\/www.kaggle.com\/vincentlugat\/ieee-lgb-bayesian-opt\/output]\n* m5 = lgb + feature selection [.9419]: [https:\/\/www.kaggle.com\/nroman\/lgb-single-model-lb-0-9419\/output]\n* m6 = lgb + fe [0.9429] : [https:\/\/www.kaggle.com\/timon88\/lgbm-baseline-small-fe-no-blend\/notebook]\n* m7 = lgb + fe : [0.9415] https:\/\/www.kaggle.com\/plasticgrammer\/ieee-cis-fraud-detection-playground\/output\n* m8 = xgb + fe [] : https:\/\/www.kaggle.com\/iasnobmatsu\/xgb-model-with-feature-engineering\n* m9 = lgbm + gpu + bayesian hyperparameter opt [0.9430] : https:\/\/www.kaggle.com\/nicapotato\/gpyopt-hyperparameter-optimisation-gpu-lgbm\/output\n* m10 = lgb in R [0.9437] : https:\/\/www.kaggle.com\/andrew60909\/lgb-starter-r\/output\n* m11 = lgb + fe [0.9441] : https:\/\/www.kaggle.com\/kyakovlev\/ieee-ground-baseline-make-amount-useful-again\n* m12 = xgb + fe [0.9442] : https:\/\/www.kaggle.com\/krishonaveen\/xtreme-boost-and-feature-engineering\/output\n* m13 = lgb + fe [0.9449] : https:\/\/www.kaggle.com\/davidcairuz\/feature-engineering-lightgbm-corrected\/output\n* m14 = hst lgb + fe in R [0.94551] : https:\/\/www.kaggle.com\/duykhanh99\/hust-lgb-feature-engineering-with-r\n* m15 = lgbm + fe in R [0.9452] : https:\/\/www.kaggle.com\/duykhanh99\/lightgbm-fe-with-r\n* m17 = lgb [0.9463]: https:\/\/www.kaggle.com\/roydatascience\/light-gbm-with-complete-eda\/output\n* m18 = lgb + new features [0.9467] : https:\/\/www.kaggle.com\/gunesevitan\/lightgbm-some-new-features\n* m19 = lgb + fe in R [0.9469] : https:\/\/www.kaggle.com\/abednadir\/best-r-score\n* m20 = lgb + group kfold cv [0.9483] : https:\/\/www.kaggle.com\/kyakovlev\/ieee-lgbm-with-groupkfold-cv\n\n### Catboost\n* m16 = catboost [0.9454] : https:\/\/www.kaggle.com\/pipboyguy\/catboost-and-eda\/output\n\n\n### NN\n* m0 = nn + focal loss expt [0.92] : https:\/\/www.kaggle.com\/abazdyrev\/keras-nn-focal-loss-experiments","b62484d1":"### Listing down useful single models"}}