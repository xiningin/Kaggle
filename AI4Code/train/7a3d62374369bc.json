{"cell_type":{"b784a8c6":"code","48bf04bf":"code","7ca7abdf":"code","699cab8b":"code","e0f3ccf8":"code","9ceb9c13":"code","1e958740":"code","a2640a93":"code","7319baaf":"code","142d9d9a":"code","07b9ae95":"code","3dde7459":"code","d316549c":"code","e5c74179":"code","26aa48e9":"code","64faeccd":"code","ae2ea1e9":"code","b5e93645":"code","4eb4dca6":"code","755038dd":"code","1be4d1fc":"code","74055247":"code","7a7165f8":"code","4f060755":"code","061486ce":"code","f2869a2b":"code","6b06b011":"code","9557d3b9":"code","a1d3b7e5":"code","375d8948":"code","a7137b9e":"code","3cd5b738":"code","21dd4ebd":"code","afe0f142":"code","3495d754":"code","39d5c123":"code","09233dba":"code","9660709c":"code","f908e796":"markdown"},"source":{"b784a8c6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","48bf04bf":"df = pd.read_csv('\/kaggle\/input\/vehicle-dataset-from-cardekho\/car data.csv')","7ca7abdf":"df.head()","699cab8b":"df.shape","e0f3ccf8":"df.info()","9ceb9c13":"cat_features = ['Car_Name', 'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']\nfor col in cat_features:\n    print('{} : {}'.format(col, df[col].unique()))","1e958740":"# Checking for null values\ndf.isnull().sum()","a2640a93":"df.describe()","7319baaf":"# Dropping the carName\nfinal_data = df.drop('Car_Name', axis=1)","142d9d9a":"final_data.head()","07b9ae95":"final_data['Car_Age'] = 2020 - final_data['Year']","3dde7459":"final_data.head()","d316549c":"# Dropping `Year` from the dataset\nfinal_data.drop('Year', axis=1, inplace=True)","e5c74179":"# Creating dummy variables\nfinal_data = pd.get_dummies(final_data, drop_first=True)","26aa48e9":"final_data.head()","64faeccd":"final_data.corr()","ae2ea1e9":"sns.pairplot(final_data)","b5e93645":"plt.figure(figsize=(10,10))\nsns.heatmap(final_data.corr(), annot=True, cmap='RdYlGn')","4eb4dca6":"X = final_data.iloc[:,1:]\ny = final_data.iloc[:,0]","755038dd":"X.head()","1be4d1fc":"y.head()","74055247":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesRegressor","7a7165f8":"model = ExtraTreesRegressor()\nmodel.fit(X, y)","4f060755":"print(model.feature_importances_)","061486ce":"# Plotting graph for Feature Importance\nfeat_importance = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importance.nlargest(5).plot(kind='barh')\nplt.title('Feature Importance')\nplt.show()","f2869a2b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","6b06b011":"X_train.shape","9557d3b9":"from sklearn.ensemble import RandomForestRegressor","a1d3b7e5":"rf = RandomForestRegressor()","375d8948":"import numpy as np\n\n# Number of random forest estimators\nn_estimators = [int(x) for x in np.linspace(100, 1200, 12)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in trees\nmax_depth = [int(x) for x in np.linspace(5, 30, num=6)]\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","a7137b9e":"from sklearn.model_selection import RandomizedSearchCV","3cd5b738":"# Creation of Random Grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\nprint(random_grid)","21dd4ebd":"rf_random = RandomizedSearchCV(estimator=rf, \n                               param_distributions=random_grid, \n                               scoring='neg_mean_squared_error',\n                               n_iter=10,\n                               cv=5,\n                               verbose=2,\n                               random_state=43,\n                               n_jobs=1)","afe0f142":"rf_random.fit(X_train, y_train)","3495d754":"predictions = rf_random.predict(X_test)","39d5c123":"sns.distplot(y_test-predictions)","09233dba":"plt.scatter(y_test, predictions)","9660709c":"import pickle\n\nfile = open('random_forest_regression_model.pkl', 'wb')\n\n# writing information in the file\npickle.dump(rf_random, file)","f908e796":"Aim of this notebook is, to predict car price."}}