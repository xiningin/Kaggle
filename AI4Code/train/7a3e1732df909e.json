{"cell_type":{"bf8008d5":"code","5bb650b9":"code","8b02dfea":"code","6877af01":"code","732d0ece":"code","53111abd":"code","86b4c46a":"code","96bd31ef":"code","e15fcd2a":"code","07333057":"code","f169f2bf":"code","35639bfc":"code","ad21aee6":"code","1601cf81":"code","91cd84a2":"code","0a323188":"code","3379bb86":"code","e29e0ca2":"code","57187368":"code","507825a7":"code","1952ee14":"code","9c8b4cbc":"code","3eb60c81":"code","d6eef5fb":"markdown","f9314268":"markdown","aeff14f1":"markdown","d3c8570b":"markdown","b78cb56e":"markdown","5019e9e1":"markdown","644a2c6b":"markdown","8529fb52":"markdown","440e2dc2":"markdown","cc104dec":"markdown","237f7556":"markdown"},"source":{"bf8008d5":"import numpy as np \nimport pandas as pd \nimport sklearn \nimport seaborn as sns\nimport matplotlib.pyplot as plt","5bb650b9":"test=pd.read_csv('..\/input\/test.csv')\ntrain=pd.read_csv('..\/input\/train.csv')","8b02dfea":"train.head()","6877af01":"for df in [train,test]:\n    df.set_index('Id',inplace=True)","732d0ece":"test.head()","53111abd":"train.head()","86b4c46a":"X_test=test\nX_train=train.drop(columns='target')\ny_train=train['target']","96bd31ef":"sns.countplot(train['sex'])","e15fcd2a":"sns.countplot(train['race'])","07333057":"sns.countplot(train['workclass'])","f169f2bf":"from scipy import stats #mecanismo para descobrir a moda\n\nfor A in X_train.columns:\n    for data in [X_train,X_test]:\n        data[A]=data[A].replace(' ?',stats.mode(data[A])[0][0])\n        ","35639bfc":"One_Hot_Xtrain = pd.get_dummies(X_train)\nOne_Hot_Xtest = pd.get_dummies(X_test)\nX_train, X_test = One_Hot_Xtrain.align(One_Hot_Xtest,join='left',axis=1)","ad21aee6":"from sklearn.preprocessing import StandardScaler\nsc_X=StandardScaler()\nX_train=sc_X.fit_transform(X_train)\nX_test=sc_X.transform(X_test)","1601cf81":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nX_train = my_imputer.fit_transform(X_train)\nX_test = my_imputer.transform(X_test)","91cd84a2":"from sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier ","0a323188":"clf=RandomForestClassifier(random_state=100,min_samples_leaf=5,min_samples_split=3,max_features=None)","3379bb86":"clf.fit(X_train,y_train)","e29e0ca2":"y_predict=clf.predict(X_test)","57187368":"y_predict","507825a7":"Submission=pd.DataFrame()","1952ee14":"Submission['Id']=test.index\nSubmission['target']=y_predict","9c8b4cbc":"Submission.head()","3eb60c81":"Submission.to_csv('submission2.csv',index=False)","d6eef5fb":"Podemos ver que h\u00e1 uma coluna \"Id\" que, bem provavelmente, n\u00e3o afeta o resultado do nosso target, e portanto, \u00e9 interessante usarmos ela como index","f9314268":"### Manipulando o Data Frame e o salvando em csv","aeff14f1":"### Data Cleaning\nAo analizar o data-set, percebemos que os dados faltantes foram representados pela string \" ?\", sabendo que estamos lidando com dados categ\u00f3ricos, uma maneira poss\u00edvel de lidar com essa falta sem excluir os dados seria substituindo-os pela moda dos fatores que mais aparecem, haja vista que, como visto nos gr\u00e1ficos, a maioria das categorias apresentam uma caracter\u00edstica que se destaca expressivamente.","d3c8570b":"Em seguida, buscamos padronizar ao m\u00e1ximo nossos dados, utilizando ferramentas de padroniza\u00e7\u00e3o e de preenchimento. ","b78cb56e":"### Predizendo o resultado da base de teste ","5019e9e1":"## Pegando os dados ","644a2c6b":"### Agora, separamos a base de treino e de teste","8529fb52":"### Transforma\u00e7\u00e3o de dados categ\u00f3ricos\nPara que seja poss\u00edvel treinar o algoritmo RandomForest, \u00e9 necess\u00e1rio transformar os dados categ\u00f3ricos em dados n\u00famericos. Utilizaremos o comando \"get_dummies\" dispon\u00edvel no pr\u00f3prio pandas  ","440e2dc2":"### Aplicando o Modelo","cc104dec":"---------------------------------------------------------------------------------------------------------------------------","237f7556":"## Importando Bibliotecas\n"}}