{"cell_type":{"8313a6c9":"code","ea6e773b":"code","f71578a3":"code","d22b5f74":"code","e7c00acf":"code","98b63ddd":"code","1556973e":"code","f7994d9b":"code","6df15529":"code","5c54016c":"code","024f3041":"code","dbaa2782":"code","31074fa8":"code","05c9c07f":"code","1b4ffcbd":"markdown","b8e1719a":"markdown","ea4286a2":"markdown","a5998e1e":"markdown","74657c28":"markdown","946538ba":"markdown","68f1a195":"markdown","8d4a7005":"markdown","248edc5d":"markdown","14820a39":"markdown","ba684632":"markdown","4df409fc":"markdown","af293b86":"markdown","d662d719":"markdown"},"source":{"8313a6c9":"!pip install tensorflow==2.0.0-alpha0","ea6e773b":"import tensorflow as tf\nfrom tensorflow.keras import Model","f71578a3":"tf.__version__\n","d22b5f74":"dataset = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = dataset.load_data()","e7c00acf":"x_train = x_train\/255.0\nx_train = x_train[..., tf.newaxis]  # adding a channel dimension\n\nx_test = x_test\/255.0\nx_test = x_test[..., tf.newaxis]  # adding a channel dimension","98b63ddd":"traindataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(5000).batch(128)\ntestdataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)","1556973e":"class ConvNet(Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')\n        self.pool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')\n        self.flatten = tf.keras.layers.Flatten()\n        self.d1 = tf.keras.layers.Dense(256, activation='relu')\n        self.d2 = tf.keras.layers.Dense(128, activation='relu')\n        self.d3 = tf.keras.layers.Dense(10, activation='softmax')\n\n    def call(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.flatten(x)\n        x = self.d1(x)\n        x = self.d2(x)\n        x = self.d3(x)\n        return x","f7994d9b":"model = ConvNet()","6df15529":"epochs = 5\nlearningrate = 0.003","5c54016c":"optimizer = tf.optimizers.Adam(learningrate)\nlossf = tf.losses.SparseCategoricalCrossentropy()","024f3041":"train_loss = tf.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.metrics.SparseCategoricalAccuracy()\n\ntest_loss = tf.metrics.Mean(name='test_loss')\ntest_accuracy = tf.metrics.SparseCategoricalAccuracy()","dbaa2782":"@tf.function\ndef train(trainimages, trainlabels):\n    with tf.GradientTape() as tape:\n        trainpredictions = model(trainimages)\n        trainloss = lossf(trainlabels, trainpredictions)\n    gradients = tape.gradient(trainloss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss(trainloss)\n    train_accuracy(trainlabels, trainpredictions)","31074fa8":"@tf.function\ndef test(testimages, testlabels):\n    testpredictions = model(testimages)\n    testloss = lossf(testlabels, testpredictions)\n\n    test_loss(testloss)\n    test_accuracy(testlabels, testpredictions)","05c9c07f":"for e in range(epochs):\n\n    for images, labels in traindataset:\n        train(images, labels)\n\n    for timages, tlabels in testdataset:\n        test(timages, tlabels)\n\n    print(f\"Epoch {e+1}\", end='  ')\n    print(f\"Train loss: {train_loss.result()}, Test loss: {test_loss.result()}\", end=',  ')\n    print(f\"Train accuracy: {100*train_accuracy.result()}, Test accuracy: {100*test_accuracy.result()}\", end='\\n')","1b4ffcbd":"Importing libraries","b8e1719a":"Defining hyperparameters\n\n","ea4286a2":"Testing the model\n\n","a5998e1e":"Installing Tensorflow 2.0.0\n\n","74657c28":"Train the model\n\n","946538ba":"Normalization and adding a channel dimension","68f1a195":"Defining metrics","8d4a7005":"Checking the version of tensorflow","248edc5d":"Creating a model","14820a39":"Batching and shuffling.","ba684632":"All about loops\n\n","4df409fc":"We got almost %99 test and train accuracy! Looks great! Thank you for reading this!","af293b86":"Optimizer and loss function\n\n","d662d719":"Loading dataset"}}