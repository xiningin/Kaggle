{"cell_type":{"99f242cf":"code","97c045ef":"code","b46bba14":"code","05d6f60d":"code","ee5ac77a":"code","a4e3d075":"code","60030d54":"code","d38e37ad":"code","e3ed9e82":"code","9a8aa1be":"code","660eb18a":"code","be209a24":"code","a1018951":"code","2e261919":"markdown","3e1a42d5":"markdown","5f40c0e6":"markdown","9245a7c4":"markdown","ccdcfd8f":"markdown","bb81901b":"markdown","2e9809af":"markdown","23003d5f":"markdown","c295c91c":"markdown","b5448eb3":"markdown","22decb4f":"markdown","07b622fe":"markdown","00ad0c05":"markdown"},"source":{"99f242cf":"# Importing all necessary libraries\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport gc\nimport requests\n\nfrom PIL import Image\nfrom io import BytesIO\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\n\nwarnings.filterwarnings('ignore')","97c045ef":"# A little bit of data exploration\npath = '..\/input\/pokemon-generation-one\/dataset\/dataset' # Path to directory which contains classes\nclasses = os.listdir(path) # List of all classes\nprint(f'Total number of categories: {len(classes)}')\n\n# A dictionary which contains class and number of images in that class\ncounts = {}\nfor c in classes:\n    counts[c] = len(os.listdir(os.path.join(path, c)))\n    \nprint(f'Total number of images in dataset: {sum(list(counts.values()))}')\n\n# Number of images in each clsss plot\nfig = plt.figure(figsize = (25, 5))\nsns.lineplot(x = list(counts.keys()), y = list(counts.values())).set_title('Number of images in each class')\nplt.xticks(rotation = 90)\nplt.margins(x=0)\nplt.show()","b46bba14":"# Sort our \"counts\" dictionary and selecting 5 classes with most number of images\nimbalanced = sorted(counts.items(), key = lambda x: x[1], reverse = True)[:5]\nprint(imbalanced)\n\n# Taking only labels, it will come in handy in future\nimbalanced = [i[0] for i in imbalanced]\nprint(imbalanced)","05d6f60d":"X = [] # List for images\nY = [] # List for labels\n\n# Loop through all classes\nfor c in classes:\n    # We take only classes that we defined in 'imbalanced' list\n    if c in imbalanced:\n        dir_path = os.path.join(path, c)\n        label = imbalanced.index(c) # Our label is an index of class in 'imbalanced' list\n        \n        # Reading, resizing and adding image and label to lists\n        for i in os.listdir(dir_path):\n            image = cv.imread(os.path.join(dir_path, i))\n            \n            try:\n                resized = cv.resize(image, (96, 96)) # Resizing images to (96, 96)\n                X.append(resized)\n                Y.append(label)\n            \n            # If we can't read image - we skip it\n            except:\n                print(os.path.join(dir_path, i), '[ERROR] can\\'t read the file')\n                continue       \n            \nprint('DONE')","ee5ac77a":"# Counting appearances of each label in labels list\nobj = Counter(Y)\n\n# Plotting number of images in each class\nfig = plt.figure(figsize = (15, 5))\nsns.barplot(x = [imbalanced[i] for i in obj.keys()], y = list(obj.values())).set_title('Number of images in each class')\nplt.margins(x=0)\nplt.show()","a4e3d075":"# Convert list with images to numpy array and reshape it \nX = np.array(X).reshape(-1, 96, 96, 3)\n\n# Scaling data in array\nX = X \/ 255.0\n\n# Convert labels to categorical format\ny = to_categorical(Y, num_classes = len(imbalanced))\n\n# Splitting data to train and test datasets\n# I'll use these datasets only for training, for final predictions I'll use random pictures from internet\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, shuffle = True, random_state = 666)","60030d54":"# Defining ImageDataGenerator Iinstance\ndatagen = ImageDataGenerator(rotation_range = 45, # Degree range for random rotations\n                            zoom_range = 0.2, # Range for random zoom \n                            horizontal_flip = True, # Randomly flip inputs horizontally\n                            width_shift_range = 0.15, # Range for horizontal shift \n                            height_shift_range = 0.15, # Range for vertical shift \n                            shear_range = 0.2) # Shear Intensity\n\ndatagen.fit(X_train)\n\n# This piece of code can be used if you eant to look what your datagen doing with your images\n# img = X[600]\n# img = img.reshape([-1, 96, 96, 3])\n\n# i = 0\n# fig = plt.figure(figsize = (18, 8))\n\n# for i, flow in enumerate(datagen.flow(img, batch_size = 1)):\n#     fig.add_subplot(2, 5, i+1)\n#     plt.imshow(np.squeeze(flow[:, :, ::-1]))\n#     plt.axis('off')\n#     i += 1\n#     if i >= 10:\n#         break","d38e37ad":"model = Sequential()\nmodel.add(Conv2D(32, 3, padding = 'same', activation = 'relu', input_shape =(96, 96, 3), kernel_initializer = 'he_normal'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal', activation = 'relu'))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(imbalanced), activation = 'softmax'))\n\n# model.summary()\n\ncheckpoint = ModelCheckpoint('..\/working\/best_model.hdf5', verbose = 1, monitor = 'val_accuracy', save_best_only = True)\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 32), epochs = 100, validation_data = [X_test, y_test],\n                             steps_per_epoch=len(X_train) \/\/ 32, callbacks = [checkpoint])","e3ed9e82":"# Plot learning curves\nfig = plt.figure(figsize = (17, 4))\n    \nplt.subplot(121)\nplt.plot(history.history['accuracy'], label = 'acc')\nplt.plot(history.history['val_accuracy'], label = 'val_acc')\nplt.legend()\nplt.grid()\nplt.title(f'accuracy')\n\nplt.subplot(122)\nplt.plot(history.history['loss'], label = 'loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.legend()\nplt.grid()\nplt.title(f'loss')","9a8aa1be":"# Loading weights from best model\nmodel.load_weights('..\/working\/best_model.hdf5')\n\n# Saving all model\nmodel.save('..\/working\/model.hdf5')","660eb18a":"mewtwo = ['https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRwBFdoShdDVdPuANqaigTAAWaySb_gm_SCIw&usqp=CAU',\n         'https:\/\/cdn.vox-cdn.com\/thumbor\/sZPPvUyKyF97UEU-nNtVnC3LpF8=\/0x0:1750x941\/1200x800\/filters:focal(878x316:1158x596)\/cdn.vox-cdn.com\/uploads\/chorus_image\/image\/63823444\/original.0.jpg',\n         'https:\/\/images-na.ssl-images-amazon.com\/images\/I\/61j5ozFjJ0L._SL1024_.jpg']\n\npikachu = ['https:\/\/cdn03.ciceksepeti.com\/cicek\/kcx1653893\/XL\/kisiye-ozel-pokemon-pikachu-beyaz-kupa-bardak.jpeg',\n          'https:\/\/giantbomb1.cbsistatic.com\/uploads\/scale_medium\/0\/6087\/2437349-pikachu.png',\n          'https:\/\/johnlewis.scene7.com\/is\/image\/JohnLewis\/237525467']\n\ncharmander = ['https:\/\/i.ytimg.com\/vi\/H_wwEdpBo_Y\/maxresdefault.jpg',\n             'https:\/\/www.pokemoncenter.com\/wcsstore\/PokemonCatalogAssetStore\/images\/catalog\/products\/P5073\/701-03990\/P5073_701-03990_01.jpg',\n             'https:\/\/static.posters.cz\/image\/750\/%D0%A7%D0%B0%D1%88%D0%BA%D0%B0\/pokemon-charmander-glow-i72513.jpg']\n\nbulbasaur = ['https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTQ8gOthPVM0SR5qJioaLuAHREBhMWvdIgt-g&usqp=CAU',\n            'https:\/\/ae01.alicdn.com\/kf\/HTB1aWullxSYBuNjSsphq6zGvVXaR\/Big-Size-55-CM-Plush-Toy-Squirtle-Bulbasaur-Charmander-Toy-Sleeping-Pillow-Doll-For-Kid-Birthday.jpg',\n            'https:\/\/cdn.bulbagarden.net\/upload\/thumb\/f\/f7\/Bulbasaur_Detective_Pikachu.jpg\/250px-Bulbasaur_Detective_Pikachu.jpg']\n\nsquirtle = ['https:\/\/i.ytimg.com\/vi\/SuaJHkIwKlQ\/maxresdefault.jpg',\n           'https:\/\/cdn.vox-cdn.com\/thumbor\/l4cKX7ZWargjs-zlxOSW2WZVgfI=\/0x0:2040x1360\/1200x800\/filters:focal(857x517:1183x843)\/cdn.vox-cdn.com\/uploads\/chorus_image\/image\/61498573\/jbareham_180925_ply0802_0030.1537570476.jpg',\n           'https:\/\/thumbor.forbes.com\/thumbor\/960x0\/https%3A%2F%2Fblogs-images.forbes.com%2Fdavidthier%2Ffiles%2F2018%2F07%2FSquirtle_Squad.jpg']\n\ntest_df = [mewtwo, pikachu, charmander, bulbasaur, squirtle]","be209a24":"# Lists to store our future data\nval_x = []\nval_y = []\n\nfor i, urls in enumerate(test_df):\n    for url in urls:        \n        r = requests.get(url, stream = True).raw\n        image = np.asarray(bytearray(r.read()), dtype=\"uint8\")\n        image = cv.imdecode(image, cv.IMREAD_COLOR)\n        val_x.append(image)\n        val_y.append(i)\n\n# plt.imshow(image[:, :, ::-1])","a1018951":"rows = 5\ncols = 3\n\nfig = plt.figure(figsize = (25, 25))\n\nfor i, j in enumerate(zip(val_x, val_y)): # i - for subplots\n    orig = j[0] # Original, not resized image\n    label = j[1] # Label for that image\n    \n    image = cv.resize(orig, (96, 96)) # Resizing image to (96, 96)\n    image = image.reshape(-1, 96, 96, 3) \/ 255.0 # Reshape and scale resized image\n    preds = model.predict(image) # Predicting image\n    pred_class = np.argmax(preds) # Defining predicted class\n    \n    true_label = f'True class: {imbalanced[label]}'\n    pred_label = f'Predicted: {imbalanced[pred_class]} {round(preds[0][pred_class] * 100, 2)}%'\n    \n    fig.add_subplot(rows, cols, i+1)\n    plt.imshow(orig[:, :, ::-1])\n    plt.title(f'{true_label}\\n{pred_label}')\n    plt.axis('off')\n    \nplt.tight_layout()","2e261919":"Now we can predict some unseen data. In this kernel I want to stick to a little bit unusual approach - I want to take some random pictures for each class from internet and try to predict them, so I quikly grabbed some urls from Google images and put them in lists:","3e1a42d5":"First of all - let's look at our data, epecially how mach images belong to each class:","5f40c0e6":"Now I need to transform these urls to arrays of numbers:","9245a7c4":"Well, looks like we have a best accuracy on 66th epoch - 94.558%.","ccdcfd8f":"Now we can create our model, I'll use VGG-like architecture here:","bb81901b":"Now I want to read all images and add them to list:","2e9809af":"Well, we have 2 mistakes - Pikachu from Detective Pikachu movie was incorectly classified as Charmander and Bulbasaur (again from same move) was incorrectly classified as Mewtwo, in all other cases we got pretty good results and I think that it's not bad for such small dataset.\n","23003d5f":"Because we do not have too much data - we need to use data augmentation using ImageDataGenerator, which will apply random transformations to our images.","c295c91c":"This kernel is my second attempt on this dataset. On my first attempt I tried to train model that can predict all 149 classes, but I failed because of lack of data - yes, this dataset is imbalanced and almost all classes don't have enough data for training. So, in this case I tried another approach and let's see, what we can do here:","b5448eb3":"Well, as we can see, we have a deal with imbalanced dataset - 9 classes have a lot of pictures, another classes - very few. Moreover, as I said earlier, I tried to train model on all 149 classes, but my best results were 67% accuracy on train data and 54% on test data, we definetly need more data to train such model.\n\nSo, in this case I decided to use another approach - I'll use only 5 classes with most number of pictures to train model:","22decb4f":"Now we have 5 classes, each with about 300 images.","07b622fe":"Let's look what we have now:","00ad0c05":"And now we can finaly make our predictions:"}}