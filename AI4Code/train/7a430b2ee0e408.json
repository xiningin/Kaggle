{"cell_type":{"29bbad11":"code","9560d75c":"code","23dda57e":"code","30387943":"code","aa1cd526":"code","dae35fb5":"code","953b7627":"code","15525413":"code","50e8c559":"code","3c12baec":"code","46c02e4b":"code","513c8be9":"code","4797f4d8":"code","8b20f7b0":"code","4da1e625":"code","02ff5aa7":"code","b025259a":"code","3f9908aa":"code","af3caa10":"code","6954bc90":"code","e52822b7":"code","50042bb2":"code","78f7ca89":"code","0f8441c6":"code","a220fc87":"code","ff58208d":"markdown","113f08a7":"markdown","424dc21e":"markdown","f9ce2880":"markdown","ba943f65":"markdown","6b0e02f1":"markdown","8b100dae":"markdown","a544a46e":"markdown"},"source":{"29bbad11":"import numpy as np\nimport pandas as pd\nimport os\nimport shutil","9560d75c":"original_dataset_dir = '..\/input\/dogs-vs-cats\/train\/train\/'","23dda57e":"print('total training images:', len(os.listdir(original_dataset_dir)))","30387943":"base_dir = '\/' # Current directory","aa1cd526":"# Directories for our training,\n# validation and test splits\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\n\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\n\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# Directory with our training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats_dir)\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs_dir)\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nos.mkdir(validation_cats_dir)\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_dogs_dir)\n\n# Directory with our validation cat pictures\ntest_cats_dir = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats_dir)\n\n# Directory with our validation dog pictures\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs_dir)\n\n# Copy first 8000 cat images to train_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(8000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\n# Copy next 2000 cat images to validation_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(8000, 10000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 1000 cat images to test_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(10000, 11000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy first 8000 dog images to train_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(8000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 2000 dog images to validation_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(8000, 10000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 1000 dog images to test_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(10000, 11000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)","dae35fb5":"print('total training cat images:', len(os.listdir(train_cats_dir)))\nprint('total training dog images:', len(os.listdir(train_dogs_dir)))\n\nprint('\\ntotal validation cat images:', len(os.listdir(validation_cats_dir)))\nprint('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n\nprint('\\ntotal test cat images:', len(os.listdir(test_cats_dir)))\nprint('total test dog images:', len(os.listdir(test_dogs_dir)))","953b7627":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (3, 3),\n                        activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","15525413":"model.summary()","50e8c559":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=0.0001),\n              metrics=['acc'])","3c12baec":"from keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1\/255\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')","46c02e4b":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","513c8be9":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)","4797f4d8":"model.save('CvD_Model_01.h5')","8b20f7b0":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","4da1e625":"datagen = ImageDataGenerator(\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.4,\n      horizontal_flip=True,\n      fill_mode='nearest')","02ff5aa7":"# This is module with image preprocessing utilities\nfrom keras.preprocessing import image\n\nfnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n\n# We pick one image to \"augment\"\nimg_path = fnames[3]\n\n# Read the image and resize it\nimg = image.load_img(img_path, target_size=(150, 150))\n\n# Convert it to a Numpy array with shape (150, 150, 3)\nx = image.img_to_array(img)\n\n# Reshape it to (1, 150, 150, 3)\nx = x.reshape((1,) + x.shape)\n\n# The .flow() command below generates batches of randomly transformed images.\n# It will loop indefinitely, so we need to `break` the loop at some point!\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\n\nplt.show()","b025259a":"model = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3),\n                        activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(1500, activation='relu'))\nmodel.add(layers.Dense(700, activation='relu'))\nmodel.add(layers.Dense(350, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=0.00005),\n              metrics=['acc'])","3f9908aa":"model.summary()","af3caa10":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.4,\n    horizontal_flip=True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=160,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=80,\n        class_mode='binary')","6954bc90":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)","e52822b7":"model.save('CvD_Model_02.h5')","50042bb2":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure()\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","78f7ca89":"test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(150, 150),\n        batch_size=40,\n        class_mode='binary',\n        shuffle=False)\n\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('Test Accuracy:', test_acc)","0f8441c6":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\n# load model\n# from tensorflow.keras.models import load_model\n# model = load_model('\/kaggle\/working\/cats_and_dogs_small_1.h5')\n# preds = model.predict_generator(test_generator, steps=len(test_generator))\n# preds = model.predict(test_generator)\npreds = model.predict_generator(test_generator,steps = len(test_generator.labels\/\/50))\n\ny=test_generator.classes # shape=(2500,)\ny_test =y.reshape(2000,1)\n\nacc = accuracy_score(test_generator.labels, np.round(preds))*100\ncm = confusion_matrix(test_generator.labels, np.round(preds))\n\ntn, fp, fn, tp = cm.ravel()\n\nprint('============TEST METRICS=============')\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nprint('Accuracy: {}%'.format(acc))\nprint('Precision: {}%'.format(precision))\nprint('Recall: {}%'.format(recall))\nprint('F1-score: {}'.format(2*precision*recall\/(precision+recall)))","a220fc87":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_cm(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots()\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n    \nplot_cm(test_generator.labels, np.round(preds))","ff58208d":"# Results","113f08a7":"## CNN model with dropout","424dc21e":"## Exmple of data augmentation","f9ce2880":"### Thanks! :)","ba943f65":"# Using data augmentation\n\nOverfitting is caused by having too few samples to learn from, rendering us unable to train a model able to generalize to new data. \nGiven infinite data, our model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data \naugmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number \nof random transformations that yield believable-looking images. The goal is that at training time, our model would never see the exact same picture twice. This helps the model get exposed to more aspects of the data and generalize better.","6b0e02f1":"### We'll use CNNs to classify cats and dogs\n### Data augmentation and dropout layers will prevent overfitting.","8b100dae":"# Without Data Augmentation","a544a46e":"## Now, let's split these images into training, validation and test sets.\n### Note: next code block might need 5 minutes to complete."}}