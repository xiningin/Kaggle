{"cell_type":{"88890879":"code","45fe8213":"code","2bf89a04":"code","0d9ab8fd":"code","947f86dd":"code","2afa4cbb":"code","7d0d3842":"code","5df7f94e":"markdown","7b8e5d27":"markdown","0f1bdf62":"markdown","1787eba9":"markdown","baa5cfc3":"markdown","515e133b":"markdown","0cb8bbe1":"markdown","3b3f933e":"markdown","4fa4c6d0":"markdown","d112c896":"markdown"},"source":{"88890879":"pip install numpy requests nlpaug","45fe8213":"pip install torch>=1.6.0 transformers>=4.0.0","2bf89a04":"import nlpaug.augmenter.word as naw","0d9ab8fd":"aug = naw.ContextualWordEmbsAug(model_path='HooshvareLab\/bert-fa-base-uncased', action=\"substitute\")\nsentence = '\u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f'\naugmented_text = aug.augment(sentence)\nprint(augmented_text)","947f86dd":"aug = naw.ContextualWordEmbsAug(model_path='HooshvareLab\/bert-fa-base-uncased', action=\"insert\")\nsentence = '\u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f'\naugmented_text = aug.augment(sentence)\nprint(augmented_text)","2afa4cbb":"aug = naw.RandomWordAug(action='swap')\nsentence = '\u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f'\naugmented_text = aug.augment(sentence)\nprint(augmented_text)","7d0d3842":"aug = naw.RandomWordAug(action='delete')\nsentence = '\u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f'\naugmented_text = aug.augment(sentence)\nprint(augmented_text)","5df7f94e":"### Random Deletion\nThis is another basic operation that can easily be accomplished by using a random augmentation:","7b8e5d27":"## Easy Data Augmentation\nEDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. Such basic techniques do a remarkably good job of resisting overfitting and helping to train stronger models. Let's familiarize ourselveswith these four operations: \n\n1. **Synonym Replacement:**\nRandomly choose n words from the sentence that are notstop words.  Replace each of these words withone of its synonyms chosen at random.\n\nLet me show you with an example in Persian Language. Consider following Sentence:\n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\nThe procedure randomly chooses n words (assume two, `\u062e\u0627\u0646\u0647` and `\u0631\u0633\u062a\u0648\u0631\u0627\u0646`) and substitutes them with `\u0645\u0646\u0632\u0644` and `\u063a\u0630\u0627\u062e\u0648\u0631\u06cc` respectively:\n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 *\u0645\u0646\u0632\u0644* \u062a\u0627 *\u063a\u0630\u0627\u062e\u0648\u0631\u06cc* \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\n2. **Random Insertion:**\nFind a random synonym of a random word in the sentence that is not a stop word. Insert that synonym into a random position in the sentence. Do this n times.\n\nUsing the same Persian example:\n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\nthe new augmented sentence can be:\n> \u0634\u0647\u0627\u0628 *\u0645\u0646\u0632\u0644* \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 *\u063a\u0630\u0627\u062e\u0648\u0631\u06cc* \u0628\u062e\u0648\u0631\u062f\n\n3. **Random Swap:**\nRandomly choose twowords in the sentence and swap their positions. Do this n times.\n\nUsing the following words, if we were to construct an augmented text: \n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\nwe would have:\n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 *\u0631\u0633\u062a\u0648\u0631\u0627\u0646* \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 *\u0627\u062a\u0648\u0628\u0648\u0633* \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\n4. **Random  Deletion:**\nRandomly remove each word in the sentence with probability p.\n\nConsidering the same sentence as example:\n> \u0634\u0647\u0627\u0628 \u0627\u0645\u0631\u0648\u0632 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0686\u0644\u0648\u06a9\u0628\u0627\u0628 \u0628\u062e\u0648\u0631\u062f\n\nFourth operation will simply remove some words from the sentence:\n> \u0634\u0647\u0627\u0628 \u0628\u0627 \u0627\u062a\u0648\u0628\u0648\u0633 \u0627\u0632 \u062e\u0627\u0646\u0647 \u062a\u0627 \u0631\u0633\u062a\u0648\u0631\u0627\u0646 \u0631\u0641\u062a \u062a\u0627 \u0628\u062e\u0648\u0631\u062f","0f1bdf62":"## Conclusion\nhere we discussed EDA text augmentation and learned to try EDA on persian sentences using ParsBERT and NLPAug library. \n\nEDA methods are most useful where there are 500 samples in the learning set. On bigger subassemblies, the distinction is less apparent. A small change is, nevertheless, inevitable.\n\nI hope this notebook help you with your NLP projects in persian language.","1787eba9":"## Using NLPAug Library to implement EDA techniques\n\nAlthough EDA operations are easy, Yet applying these strategies from scratch successfully is a lot of effort. Fortunately, as always, there is a python package for that! \n\n[NLPAug](https:\/\/github.com\/makcedward\/nlpaug) is a very useful package which assists you with your NLP projects. \n\nThis library supports python 3.5+ in linux and windows platforms. To install the library:\n`pip install numpy requests nlpaug`\n\nSince we want to use ContextualWordEmbsAug, we should install the following dependencies as well:\n`pip install torch>=1.6.0 transformers>=4.0.0`","baa5cfc3":"# Persian Text Augmentation using ParsBERT and NLPAug\nLack of enough Data is always a big problem for natural language processing tasks in persian language. Data augmentation is a very good way to tackle this issue. Image can be augmented easily by flipping, rotating, using filters, adding noise, etc. but in the field of natural language processing (NLP), given the high language complexity, it is difficult to augment text. here I want to Introduce you to [EDA (Easy Data Augmentation)](https:\/\/arxiv.org\/abs\/1901.11196) Method for augmenting Text.","515e133b":"We can finally begin learning to implement EDA text augmentation using this library now that all is set.","0cb8bbe1":"### Synonym Replacement\nIn order to obtain a sentence of the same meaning but with distinct terms, we substitute n number words with their synonyms (word embeddings that are similar to these words). to do so, we may choose which pre-trained word embedding we should use. since we are trying to augment a persian text, [ParsBERT](https:\/\/github.com\/hooshvare\/parsbert) is the Best choice. here is how we can do this:","3b3f933e":"### Random Swap\nWe no longer need ParsBERT, because Random Swapping is not a Contextual Word Embedding Augmentation. here we Apply augmentation randomly, so we should use `RandomWordAug`:","4fa4c6d0":"### Random Insertion\nHere, we want to choose some random words from the sentence and insert their synonyms in some random point in our sentence. again, we use ParsBERT pre-trained word embedding to achieve a good quality outcome:","d112c896":"\nNow, in order to use NLPAug we should first Import it:"}}