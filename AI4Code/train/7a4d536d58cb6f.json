{"cell_type":{"939e42e1":"code","8045aae9":"code","25fdde80":"code","1618c9a0":"code","8219938b":"code","0b902f38":"code","8131f499":"code","744a2a09":"code","5f3b62e8":"code","b2e0b622":"code","2425bc06":"code","7545a6d1":"code","8f8bd5d4":"code","da1d3fab":"code","1db8802c":"code","fac766f3":"code","818493c9":"code","a45362d1":"code","3ecf2768":"code","fcaf782f":"code","5d421cc8":"code","5b5c7885":"code","6e03c9e0":"code","887a1666":"code","9ac79863":"code","7c1287b1":"code","dc142e83":"code","5f222559":"code","29247401":"code","843b70d3":"code","54be7faa":"markdown","afc5f1a3":"markdown","537b98ea":"markdown","f1f752ca":"markdown","647b5d13":"markdown","1bf8fa09":"markdown","142f64a6":"markdown","9e2c0f90":"markdown","46aacdde":"markdown","d3e64acd":"markdown","58bbed3d":"markdown","9c9341c5":"markdown","c3fffef5":"markdown","df3c7111":"markdown","2f0b7fc3":"markdown","3197801b":"markdown","0fa77f46":"markdown","a93336e2":"markdown","ae75eca6":"markdown","f9f9bf80":"markdown","62768389":"markdown","738238c4":"markdown","777e0f9c":"markdown","4cebd146":"markdown","21b844eb":"markdown"},"source":{"939e42e1":"import tensorflow as tf \nimport numpy as np\nimport os\nfrom keras.layers import Conv2D, Activation, AveragePooling2D, MaxPooling2D, ZeroPadding2D, Input, concatenate\nfrom keras.layers.core import Lambda, Dense, Flatten\nfrom numpy import genfromtxt\nimport cv2\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import backend as K\nfrom keras.layers import *\nfrom keras.models import Model\nfrom sklearn.preprocessing import normalize\nK.set_image_data_format('channels_first')\nimport random\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.utils import plot_model\nimport sys","8045aae9":"path_haar='..\/input\/haar-cascade\/haarcascade_frontalface_default.xml'\nPATH='..\/input\/face-match\/trainset'","25fdde80":"reference_images=[]\nselfies=[]\nn_sub=0","1618c9a0":"for folder in os.listdir(PATH):\n    subfolder=os.path.join(PATH,folder)\n    for sub in os.listdir(subfolder):\n        n_sub=n_sub+1\n        img_dir=os.path.join(subfolder,sub)\n        for img_raw in os.listdir(img_dir):\n            if 'script' in img_raw:\n                reference_images.append(img_raw)\n            else :\n                selfies.append(img_raw)","8219938b":"print(\"The total number of Folders in dataset : \",len(os.listdir(PATH)))\nprint(\"The total number of Employee in dataset : \",n_sub)\nprint(\"The total number of selfies are : \",len(selfies))\nprint(\"The total number of script images are : \",len(reference_images))","0b902f38":"image=cv2.imread('..\/input\/face-match\/trainset\/0003\/0003_0000345\/0000002.jpg')","8131f499":"plt.imshow(image)\nplt.show()","744a2a09":"image=cv2.imread('..\/input\/face-match\/trainset\/0003\/0003_0000345\/0003_0000345_script.jpg')","5f3b62e8":"plt.imshow(image)\nplt.show()","b2e0b622":"def inception_block_1a(X):\n    X_3=Conv2D(96,(1,1),data_format='channels_first',name='inception_3a_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3a_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(128,(3,3),data_format='channels_first',name='inception_3a_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3a_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    X_5=Conv2D(16,(1,1),data_format='channels_first',name='inception_3a_5x5_conv1')(X)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3a_5x5_bn1')(X_5)\n    X_5=Activation('relu')(X_5)\n    X_5=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_5)\n    X_5=Conv2D(32,(5,5),data_format='channels_first',name='inception_3a_5x5_conv2')(X_5)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3a_5x5_bn2')(X_5)\n    X_5=Activation('relu')(X_5)\n    \n    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n    X_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(X_pool)\n    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(X_pool)\n    X_pool = Activation('relu')(X_pool)\n    X_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(X_pool)\n    \n    X_1=Conv2D(64,(1,1),data_format='channels_first',name='inception_3a_1x1_conv')(X)\n    X_1=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3a_1x1_bn')(X_1)\n    X_1=Activation('relu')(X_1)\n    \n    inception=concatenate([X_3,X_5,X_pool,X_1],axis=1)\n    return inception\n\ndef inception_block_1b(X):\n    X_3=Conv2D(96,(1,1),data_format='channels_first',name='inception_3b_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(128,(3,3),data_format='channels_first',name='inception_3b_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    X_5=Conv2D(32,(1,1),data_format='channels_first',name='inception_3b_5x5_conv1')(X)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_5x5_bn1')(X_5)\n    X_5=Activation('relu')(X_5)\n    X_5=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_5)\n    X_5=Conv2D(64,(5,5),data_format='channels_first',name='inception_3b_5x5_conv2')(X_5)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_5x5_bn2')(X_5)\n    X_5=Activation('relu')(X_5)\n    \n    X_P=AveragePooling2D(pool_size=(3,3),strides=(3,3),data_format='channels_first')(X)\n    X_P=Conv2D(64,(1,1),data_format='channels_first',name='inception_3b_pool_conv')(X_P)\n    X_P=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_pool_bn')(X_P)\n    X_P=Activation('relu')(X_P)\n    X_P=ZeroPadding2D(padding=(4,4),data_format='channels_first')(X_P)\n    \n    X_1=Conv2D(64,(1,1),data_format='channels_first',name='inception_3b_1x1_conv')(X)\n    X_1=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3b_1x1_bn')(X_1)\n    X_1=Activation('relu')(X_1)\n    \n    inception=concatenate([X_3,X_5,X_P,X_1],axis=1)\n    return inception\n\ndef inception_block_1c(X):\n    X_3=Conv2D(128,(1,1),data_format='channels_first',name='inception_3c_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3c_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(256,(3,3),strides=(2,2),data_format='channels_first',name='inception_3c_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3c_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    X_5=Conv2D(32,(1,1),data_format='channels_first',name='inception_3c_5x5_conv1')(X)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3c_5x5_bn1')(X_5)\n    X_5=Activation('relu')(X_5)\n    X_5=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_5)\n    X_5=Conv2D(64,(5,5),strides=(2,2),data_format='channels_first',name='inception_3c_5x5_conv2')(X_5)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_3c_5x5_bn2')(X_5)\n    X_5=Activation('relu')(X_5)\n    \n    X_P=MaxPooling2D(pool_size=3,strides=2,data_format='channels_first')(X)\n    X_P=ZeroPadding2D(padding=((0,1),(0,1)),data_format='channels_first')(X_P)\n    \n\n    inception=concatenate([X_3,X_5,X_P],axis=1)\n    return inception\n\ndef inception_block_2a(X):\n    X_3=Conv2D(96,(1,1),data_format='channels_first',name='inception_4a_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(192,(3,3),data_format='channels_first',name='inception_4a_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    X_5=Conv2D(32,(1,1),data_format='channels_first',name='inception_4a_5x5_conv1')(X)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_5x5_bn1')(X_5)\n    X_5=Activation('relu')(X_5)\n    X_5=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_5)\n    X_5=Conv2D(64,(5,5),data_format='channels_first',name='inception_4a_5x5_conv2')(X_5)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_5x5_bn2')(X_5)\n    X_5=Activation('relu')(X_5)\n    \n    X_P=AveragePooling2D(pool_size=(3,3),strides=(3,3),data_format='channels_first')(X)\n    X_P=Conv2D(128,(1,1),data_format='channels_first',name='inception_4a_pool_conv')(X_P)\n    X_P=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_pool_bn')(X_P)\n    X_P=Activation('relu')(X_P)\n    X_P=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_P)\n    \n    X_1=Conv2D(256,(1,1),data_format='channels_first',name='inception_4a_1x1_conv')(X)\n    X_1=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4a_1x1_bn')(X_1)\n    X_1=Activation('relu')(X_1)\n    \n    inception=concatenate([X_3,X_5,X_P,X_1],axis=1)\n    return inception\n\ndef inception_block_2b(X):\n    X_3=Conv2D(160,(1,1),data_format='channels_first',name='inception_4e_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4e_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(256,(3,3),strides=(2,2),data_format='channels_first',name='inception_4e_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4e_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    X_5=Conv2D(64,(1,1),data_format='channels_first',name='inception_4e_5x5_conv1')(X)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4e_5x5_bn1')(X_5)\n    X_5=Activation('relu')(X_5)\n    X_5=ZeroPadding2D(padding=(2,2),data_format='channels_first')(X_5)\n    X_5=Conv2D(128,(5,5),strides=(2,2),data_format='channels_first',name='inception_4e_5x5_conv2')(X_5)\n    X_5=BatchNormalization(axis=1,epsilon=0.00001,name='inception_4e_5x5_bn2')(X_5)\n    X_5=Activation('relu')(X_5)\n    \n    X_P=MaxPooling2D(pool_size=3,strides=2,data_format='channels_first')(X)\n    X_P=ZeroPadding2D(padding=((0,1),(0,1)),data_format='channels_first')(X_P)\n\n    inception=concatenate([X_3,X_5,X_P],axis=1)\n    return inception\n\ndef inception_block_3a(X):\n    X_3=Conv2D(96,(1,1),data_format='channels_first',name='inception_5a_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5a_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(384,(3,3),data_format='channels_first',name='inception_5a_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5a_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n\n    \n    X_P=AveragePooling2D(pool_size=(3,3),strides=(3,3),data_format='channels_first')(X)\n    X_P=Conv2D(96,(1,1),data_format='channels_first',name='inception_5a_pool_conv')(X_P)\n    X_P=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5a_pool_bn')(X_P)\n    X_P=Activation('relu')(X_P)\n    X_P=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_P)\n    \n    X_1=Conv2D(256,(1,1),data_format='channels_first',name='inception_5a_1x1_conv')(X)\n    X_1=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5a_1x1_bn')(X_1)\n    X_1=Activation('relu')(X_1)\n    \n    inception=concatenate([X_3,X_P,X_1],axis=1)\n    return inception\ndef inception_block_3b(X):\n    X_3=Conv2D(96,(1,1),data_format='channels_first',name='inception_5b_3x3_conv1')(X)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5b_3x3_bn1')(X_3)\n    X_3=Activation('relu')(X_3)\n    X_3=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_3)\n    X_3=Conv2D(384,(3,3),data_format='channels_first',name='inception_5b_3x3_conv2')(X_3)\n    X_3=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5b_3x3_bn2')(X_3)\n    X_3=Activation('relu')(X_3)\n    \n    \n    X_P=MaxPooling2D(pool_size=(3,3),strides=2,data_format='channels_first')(X)\n    X_P=Conv2D(96,(1,1),data_format='channels_first',name='inception_5b_pool_conv')(X_P)\n    X_P=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5b_pool_bn')(X_P)\n    X_P=Activation('relu')(X_P)\n    X_P=ZeroPadding2D(padding=(1,1),data_format='channels_first')(X_P)\n    \n    X_1=Conv2D(256,(1,1),data_format='channels_first',name='inception_5b_1x1_conv')(X)\n    X_1=BatchNormalization(axis=1,epsilon=0.00001,name='inception_5b_1x1_bn')(X_1)\n    X_1=Activation('relu')(X_1)\n    \n    inception=concatenate([X_3,X_P,X_1],axis=1)\n    return inception\n\n\ndef FinalModel(input_shape):\n    \n    X_input=Input(input_shape)\n    \n    X=ZeroPadding2D(padding=(3,3))(X_input)\n    X=Conv2D(64,(7,7),strides=(2,2),name='conv1')(X)\n    X=BatchNormalization(axis=1,name='bn1')(X)\n    X=Activation('relu')(X)\n    \n    X=ZeroPadding2D((1,1))(X)\n    X=MaxPooling2D((3,3),strides=2)(X)\n    \n    X=Conv2D(64,(1,1),strides=(1,1),name='conv2')(X)\n    X=BatchNormalization(axis=1,epsilon=0.00001,name='bn2')(X)\n    X=Activation('relu')(X) \n    \n    X=ZeroPadding2D(padding=(1,1))(X)\n    \n    X=Conv2D(192,(3,3),strides=(1,1),name='conv3')(X)\n    X=BatchNormalization(axis=1,epsilon=0.00001,name='bn3')(X)\n    X=Activation('relu')(X)\n    \n    X=ZeroPadding2D(padding=(1,1))(X)\n    X=MaxPooling2D(pool_size=(3,3),strides=(2,2))(X)\n    \n    X=inception_block_1a(X)\n    X=inception_block_1b(X)\n    X=inception_block_1c(X)\n    \n    X=inception_block_2a(X)\n    X=inception_block_2b(X)\n    \n    X=inception_block_3a(X)\n    X=inception_block_3b(X)\n    \n    X=AveragePooling2D(pool_size=(3,3),strides=(1,1),data_format='channels_first')(X)\n    X=Flatten()(X)\n    X=Dense(128,activation='relu',kernel_initializer='glorot_normal',name='dense_layer')(X)\n    X=Lambda(lambda x:K.l2_normalize(x,axis=1),name='lambda_1')(X)\n    \n    model=Model(inputs=X_input,outputs=X,name='FaceRecognotionModel')\n    return model    \n","2425bc06":"model=FinalModel(input_shape=(3,96,96))","7545a6d1":"model.summary()","8f8bd5d4":"plot_model(model,to_file='Inception_one_shot.png')","da1d3fab":"def triplet_loss_t(y_true,y_pred):\n    #print(y_pred)\n    anchor=y_pred[:,0:128]\n    pos=y_pred[:,128:256]\n    neg=y_pred[:,256:384]\n    \n    positive_distance = K.sum(K.abs(anchor-pos), axis=1)\n    negative_distance = K.sum(K.abs(anchor-neg), axis=1)\n    probs=K.softmax([positive_distance,negative_distance],axis=0)\n    #loss = positive_distance - negative_distance+alpha\n    loss=K.mean(K.abs(probs[0])+K.abs(1.0-probs[1]))\n    return loss","1db8802c":"def localize_resize(path_image,path_haar='..\/input\/haar-cascade\/haarcascade_frontalface_default.xml'):\n    image=cv2.imread(path_image)\n    \n    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    classifier=cv2.CascadeClassifier(path_haar)\n    faces=classifier.detectMultiScale(gray,1.1,6)\n    if len(faces) != 1:#condition if we dont have any faces or cant be detected y haar cascade we will skip those\n        return -1\n    \n    x,y,w,h=faces.squeeze()\n    crop=image[y:y+h,x:x+w]\n    image=cv2.resize(crop,(96,96))\n    image=np.transpose(image,(2,0,1))\n    image=image.astype('float32')\/255.0\n    return image","fac766f3":"def data_gen(batch_size=32):\n    while True:\n        i=0\n        positive=[]\n        anchor=[]\n        negative=[]    \n        \n\n        while(i<batch_size):\n            r=random.choice(os.listdir(PATH))\n            p=PATH+'\/'+ r\n            id=os.listdir(p)\n            ra=random.sample(id,2)\n            pos_dir=p+'\/'+ra[0]\n            neg_dir=p+'\/'+ra[1]\n            pos=pos_dir+'\/'+random.choice(os.listdir(pos_dir))\n            anc=pos_dir+'\/'+random.choice([x for x in os.listdir(pos_dir) if 'script' in x])\n            neg=neg_dir+'\/'+random.choice(os.listdir(neg_dir))\n            pos_img=localize_resize(pos,path_haar)\n                    #print(pos+anc+neg)\n            if pos_img is -1:\n                continue\n            neg_img=localize_resize(neg,path_haar)\n            if neg_img is -1:\n                continue\n            anc_img=localize_resize(anc,path_haar)\n            if anc_img is -1:\n                continue\n            positive.append(list(pos_img))\n                #print('positive{0}'.format(i))\n            negative.append(list(neg_img))\n                #print('negative{0}'.format(i))\n            anchor.append(list(anc_img))\n                #print('anchor{0}'.format(i))\n            i=i+1\n        #return anchor,positive,negative\n        yield ([np.array(anchor),np.array(positive),np.array(negative)],np.zeros((batch_size,1)).astype(\"float32\"))","818493c9":"triplet_model_a=Input((3,96,96))\ntriplet_model_n=Input((3,96,96))\ntriplet_model_p=Input((3,96,96))\ntriplet_model_out=Concatenate()([model(triplet_model_a),model(triplet_model_p),model(triplet_model_n)])\ntriplet_model=Model([triplet_model_a,triplet_model_p,triplet_model_n],triplet_model_out)","a45362d1":"triplet_model.compile(optimizer='adam',loss=triplet_loss_t)","3ecf2768":"triplet_model.summary()","fcaf782f":"plot_model(triplet_model)","5d421cc8":"triplet_model.fit(data_gen(),steps_per_epoch=100,epochs=5)","5b5c7885":"triplet_model.save('triplet_model.h5')","6e03c9e0":"triplet_model=keras.models.load_model('..\/input\/trained-model-from-version-1\/triplet_model.h5',custom_objects={'triplet_loss_t':triplet_loss_t})","887a1666":"#To loacaloze the face and resize the image\ndef image_resizing(image,path_haar):\n\n    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    classifier=cv2.CascadeClassifier(path_haar)\n    faces=classifier.detectMultiScale(gray,1.1,6)\n\n    if len(faces)!=1:\n        print('More than one Image in the selfie')\n        sys.exit(0)\n    x,y,w,h=faces.squeeze()\n    crop=image[y:y+h,x:x+w]\n    image=cv2.resize(crop,(96,96))\n\n    return image","9ac79863":"def encode_img(img1,triplet_model):\n    #img1=cv2.imread(path,1)\n    img=img1[...,::-1]\n    img=np.around(np.transpose(img,(2,0,1))\/255,decimals=12)\n    x_train=np.array([img])\n    emb=triplet_model.layers[3].predict_on_batch(x_train)\n    return emb","7c1287b1":"threshold=0.65\ninterval=0.3\ndef confidence_value(ref_encode,img_encode,thres=threshold):\n    #diff=np.max(img_encode-ref_encode)\n    dist=np.linalg.norm((img_encode-ref_encode))\n    #confidence=(1-K.eval(tf.minimum(dist,1)))\n    confidence=(threshold-max([dist,interval]))\/(threshold-interval)\n    return dist,confidence","dc142e83":"rimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0006_0000557_script.jpg')\nimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0000000.jpg')\n\nfig=plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(2,2,1)\nax1.imshow(rimage)\nax2 = fig.add_subplot(2,2,2)\nax2.imshow(image)","5f222559":"rimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0006_0000557_script.jpg')\nimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0000000.jpg')\nrimg=image_resizing(rimage,path_haar)\nimg=image_resizing(image,path_haar)\nr_encode=encode_img(rimg,triplet_model)\nimg_encode=encode_img(img,triplet_model)\ndist,conf=confidence_value(r_encode,img_encode)\nif dist<threshold:\n    print(\"Match with a confidence of \",conf*100)\n    #print(\"Distance \",dist)\nelse:\n    print(\"No Match with a confidence of \",abs(conf*100))","29247401":"rimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0006_0000557_script.jpg')\nimage=cv2.imread('..\/input\/face-match\/trainset\/0002\/0002_0000308\/0000001.jpg')\n\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(2,2,1)\nax1.imshow(rimage)\nax2 = fig.add_subplot(2,2,2)\nax2.imshow(image)","843b70d3":"rimage=cv2.imread('..\/input\/face-match\/trainset\/0006\/0006_0000557\/0006_0000557_script.jpg')\nimage=cv2.imread('..\/input\/face-match\/trainset\/0002\/0002_0000308\/0000001.jpg')\nrimg=image_resizing(rimage,path_haar)\nimg=image_resizing(image,path_haar)\nr_encode=encode_img(rimg,triplet_model)\nimg_encode=encode_img(img,triplet_model)\ndist,conf=confidence_value(r_encode,img_encode)\nif dist<threshold:\n    print(\"Match with a confidence of \",conf*100)\n    #print(\"Distance \",dist)\nelse:\n    print(\"No Match with a confidence of \",abs(conf*100))","54be7faa":"# **Implementation of the model**","afc5f1a3":"### Function to resize the image to match the input shape of the model","537b98ea":">  Selecting the threshold value as 0.65 and intervals means that +\/- 0.3 the model confidence score will be 100%.","f1f752ca":"# Defining the Model","647b5d13":"# Defining the Triplet Loss Function","1bf8fa09":"> It uses haar cascade to detect the face and crops the face to remove the unwanted noise from the image and then resize it to (96,96).","142f64a6":"# Defining the path of dataset and haar cascade","9e2c0f90":"## Defining model for triplet loss","46aacdde":"## Function to calculate the distance between the embeddings and confidence score","d3e64acd":"### For images of different persons","58bbed3d":"## Training the model\n> We will be training the model for 5 epoch and with steps_per_epoch as 100  .These hyperparameters can be changed as per the availablity of computional power","9c9341c5":"### For images of same person","c3fffef5":"1. Florian Schroff, Dmitry Kalenichenko, James Philbin (2015).[ FaceNet: A Unified Embedding for Face Recognition and Clustering](https:\/\/arxiv.org\/pdf\/1503.03832.pdf)\n2. Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014).[ DeepFace: Closing the gap to human-level performance in face verification](https:\/\/research.fb.com\/wp-content\/uploads\/2016\/11\/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf)\n3. Deeplearning.ai [Deep Learning Specialization](https:\/\/www.coursera.org\/specializations\/deep-learning)","df3c7111":"# Analysing the dataset","2f0b7fc3":"## Acknowledgements","3197801b":"### Using the model trained in version 1. For details please refer version 1.","0fa77f46":"# Importing Libraries","a93336e2":"> The dataset consist of images of 1012 persons and with one reference image of each person and rest other images in different popse","ae75eca6":"## Definig the generator","f9f9bf80":"## Function to preprocess the image according to the model requirements. ","62768389":">  Since batch size is 32 and total number of samples is almost 3200 so steps_per_epoch=100","738238c4":">It normalizes the image matrix and transpose it since here we are using the 'Channels First' data format. Then it uses the base model to predict the embedding for the provided image","777e0f9c":"## Function to convert the image to embeddings.","4cebd146":" Face verification is the task of comparing a candidate face to another and verifying whether it is a match. It is different from face recognition. This model can be used for Facial Recognition also my making another minor change in the code. So this model uses the technique of One-Shot Learning, which means, to learn information about object categories from one, or only a few, training samples\/images. So this model needs only one image of a person in order to learn information and can be used for face verification and face recognition tasks. The base model is an inception network. Various detail about the models and their plots can be found in the notebook.\n","21b844eb":"# Face Verification Using One Shot Learning"}}