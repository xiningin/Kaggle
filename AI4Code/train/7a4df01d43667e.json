{"cell_type":{"06ae2e6f":"code","71ddd729":"code","3348aef5":"code","cb4ec625":"code","653241e3":"code","5b0f9fb7":"code","433421a6":"code","b4ea9d87":"code","d1d6850c":"code","1726f366":"code","dd35fb25":"code","90050989":"code","40b8e8c0":"code","8447ef51":"code","c8e841ce":"code","a4e73de1":"code","de61ef17":"code","70dc6d1d":"code","a75edc34":"code","e2b44e1f":"code","40a22a99":"code","a696231d":"code","f8e14a13":"code","ab102781":"code","f8f58f64":"code","7d53e522":"code","6f32df4f":"code","f8d3fdb4":"code","c23bed4a":"code","f9b719a7":"code","51a51daf":"markdown","b0ffa9ff":"markdown","88ae3fa8":"markdown","4c71f25d":"markdown","a374e459":"markdown","0cfd556f":"markdown","9c5c073d":"markdown","9a64608e":"markdown","7ba69aa8":"markdown","1f551f03":"markdown","0a555a78":"markdown","4574b1f1":"markdown","5be24d89":"markdown","5362f360":"markdown","2a263986":"markdown","b5e1cdb8":"markdown","067094cb":"markdown","3ea70ab3":"markdown","1fded7e0":"markdown","97c2221c":"markdown","bfa30e0b":"markdown"},"source":{"06ae2e6f":"# libraries\nimport numpy as np\nimport pandas as pd\nimport pylab as pl\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","71ddd729":"df = pd.read_excel('\/kaggle\/input\/movies_collection.xlsx')","3348aef5":"df.head()","cb4ec625":"# transform categorical data\ncols_to_transform = ['Seen']\n \ndf = pd.get_dummies( columns = cols_to_transform , data = df)\n# Seen --- 2 value 0 or 1 \n# we gonna remove one column\ndf = df.drop(columns=['Seen_False'])","653241e3":"df_numeric = df[['Orginal Name','Seen_True',\n                 'Budget','Year','Duration',\n                 'Votes','Rating' ,\n                 'Personal Rating']]","5b0f9fb7":"df_numeric.head()","433421a6":"df_numeric.isnull().sum()","b4ea9d87":"df_numeric.dropna(inplace=True)","d1d6850c":"df_numeric['Budget'].describe()","1726f366":"df_numeric['Duration'].describe()","dd35fb25":"df_numeric['Votes'].describe()","90050989":"df_numeric['Rating'].describe()","40b8e8c0":"df_numeric['Personal Rating'].describe()","8447ef51":"from sklearn import preprocessing\nminmax_processed = preprocessing.MinMaxScaler().fit_transform(df_numeric.drop('Orginal Name',axis=1))\ndf_numeric_scaled = pd.DataFrame(minmax_processed, index=df_numeric.index, columns=df_numeric.columns[:-1])\ndf_numeric_scaled.head()","c8e841ce":"Nc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in Nc]","a4e73de1":"score = [kmeans[i].fit(df_numeric_scaled).score(df_numeric_scaled) for i in range(len(kmeans))]","de61ef17":"pl.plot(Nc,score)\npl.xlabel('Number of Clusters')\npl.ylabel('Score')\npl.title('Elbow Curve')\npl.show()","70dc6d1d":"kmeans = KMeans(n_clusters=5)\nkmeans.fit(df_numeric_scaled)","a75edc34":"len(kmeans.labels_)","e2b44e1f":"df_numeric['cluster'] = kmeans.labels_","40a22a99":"df_numeric.head()","a696231d":"plt.figure(figsize=(12,7))\naxis = sns.barplot(x=np.arange(0,5,1),y=df_numeric.groupby(['cluster']).count()['Budget'].values)\nx=axis.set_xlabel(\"Cluster Number\")\nx=axis.set_ylabel(\"Number of movies\")","f8e14a13":"df_numeric.groupby(['cluster']).mean()","ab102781":"size_array = list(df_numeric.groupby(['cluster']).count()['Budget'].values)","f8f58f64":"size_array","7d53e522":"df_numeric[df_numeric['cluster']==size_array.index(sorted(size_array)[0])].sample(5)","6f32df4f":"df_numeric[df_numeric['cluster']==size_array.index(sorted(size_array)[1])].sample(5)","f8d3fdb4":"df_numeric[df_numeric['cluster']==size_array.index(sorted(size_array)[-1])].sample(5)\n","c23bed4a":"y_kmeans = kmeans.fit_predict(df_numeric_scaled)\n\nX = df_numeric_scaled.as_matrix(columns=None)\n\n# Plot the 5 clusters\n\nfrom sklearn.datasets.samples_generator import make_blobs\nX, y_true = make_blobs(n_samples=300, centers=5,\n                       cluster_std=0.60, random_state=0)\nplt.scatter(X[:, 0], X[:, 1], s=50)","f9b719a7":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","51a51daf":"# Apply K-Means Clustering","b0ffa9ff":"As a result of clustering, we have the clustering label. Let's put these labels back into the original numeric data frame.","88ae3fa8":"Only keep the numeric columns for our analysis. However, we'll keep Original Name also to interpret the results at the end of clustering. Note that this Original Name column will not be used in the analysis.","4c71f25d":"We see that one cluster which is also the smallest, is the cluster of movies that received maximum number of votes(in terms of counts) and also have very high rating and duration . Let's see some of the movies that belong to this cluster.","a374e459":"# Summary\nIn this entry we have learned about the k-means algorithm, including the data normalization before we execute it, the choice of the optimal number of clusters (elbow criterion) and the visualization of the clustering.\n\nIt has been a pleasure to make this post, I have learned a lot! Thank you for reading and if you like it, please upvote it.","0cfd556f":"Drop all the rows with null values","9c5c073d":"# Normalize data","9a64608e":"Let's see the statistics for the movies data","7ba69aa8":"**What k to choose?**                                                                    \nLet's fit cluster size 1 to 20 on our data and take a look at the corresponding score value.","1f551f03":"# Visualising Clusters ","0a555a78":"These score values signify how far our observations are from the cluster center. We want to keep this score value around 0. A large positive or a large negative value would indicate that the cluster center is far from the observations.\n\nBased on these scores value, we plot an Elbow curve to decide which cluster size is optimal. Note that we are dealing with tradeoff between cluster size(hence the computation required) and the relative accuracy.","4574b1f1":"First, let's generate a two-dimensional dataset containing five distinct blobs. To emphasize that this is an unsupervised algorithm, we will leave the labels out of the visualization","5be24d89":"Check if rows contain any null values","5362f360":"# Importing Dataset","2a263986":"Normalize the data with MinMax scaling provided by sklearn","b5e1cdb8":"We clearly see that one cluster is the largest and one cluster has the fewest number of movies.\n\nLet's look at the cluster statistics.","067094cb":"For this tutorial, we will use the **My Movie Collection** data set available on the kaggle datasets :\n\n[**My Movie Collection**](https:\/\/www.kaggle.com\/fazilbtopal\/my-movie-collection)","3ea70ab3":"By eye, it is relatively easy to pick out the five clusters. The k-means algorithm does this automatically, and in Scikit-Learn uses the typical estimator API.","1fded7e0":"**Fit K-Means clustering for k=5**","97c2221c":"Our Elbow point is around cluster size of 5. We will use k=5 to further interpret our clustering result. I'm prefering this number for ease of interpretation in this demo. We can also pick a higher number like 9.","bfa30e0b":"# Interpret clustering results                             \nLet's see cluster sizes first."}}