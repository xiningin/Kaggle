{"cell_type":{"284b25ec":"code","f2c8b50f":"code","82d0ba40":"code","d3c9c553":"code","12cdb4ef":"code","bd119ab8":"code","1f12da88":"code","59029d60":"code","8faea331":"code","c775a829":"code","106d72d9":"code","24fdb7e9":"code","6f0419f0":"code","5a194333":"code","3290bf41":"code","d26aa541":"code","085ca549":"code","e547d2ad":"code","e544ac48":"code","b0916f10":"code","b8d5fe09":"code","9a56b5ed":"code","7881dc7a":"code","b0b1c511":"code","4c447427":"markdown","bd2a692d":"markdown","403beeb5":"markdown","0d2709e4":"markdown","caea108e":"markdown","d54a8d3d":"markdown","97cf13c7":"markdown","26c4e623":"markdown","5b3aaacc":"markdown","01ea05de":"markdown","67d114ae":"markdown","92d3321c":"markdown","0bacaf58":"markdown","200de4b6":"markdown","5a0bb97e":"markdown","aca66202":"markdown","6e6b4ab6":"markdown","852099a6":"markdown","b46a06a4":"markdown","fda49a40":"markdown","0cd1befd":"markdown","3a1f7a97":"markdown","15431c7f":"markdown","5cb55314":"markdown","291929e5":"markdown"},"source":{"284b25ec":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport math\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, recall_score\nimport itertools\nimport cv2\nfrom tqdm import tqdm\nfrom keras.utils.vis_utils import plot_model\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom skimage import io\nfrom keras.preprocessing import image as imageK\nfrom sklearn.metrics import confusion_matrix\n\nimport glob\nimport random\nimport base64\nimport pandas as pd\n\nfrom PIL import Image\nfrom io import BytesIO\nfrom IPython.display import HTML\n\nfrom random import randint\n\n\nsns.set(style='white', context='notebook', palette='deep')","f2c8b50f":"clases = ['non-COVID', 'COVID']\ndata_dir = '..\/input\/sarscov2-ctscan-dataset\/'\ntrain_data = []\n\nfor id_clase, clase in enumerate(clases):\n    for file in os.listdir(os.path.join(data_dir, clase)):\n        train_data.append(['{}\/{}'.format(clase, file), id_clase, clase])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head()","82d0ba40":"IMAGE_SIZE = 100\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath), cv2.IMREAD_GRAYSCALE)\n\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","d3c9c553":"train = train.iloc[np.random.permutation(train.index)].reset_index(drop=True)","12cdb4ef":"x = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    if image is not None:\n        x[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))","bd119ab8":"disease_types=['COVID', 'non-COVID']\nfig, ax = plt.subplots(1, 3, figsize=(15, 15))\nfor i in range(3):\n    random = randint(0,len(x)-1)\n    ax[i].imshow(x[random], cmap='gray')\n    ax[i].set_title(train['Disease Type'].values[random])","1f12da88":"pd.set_option('display.max_colwidth', None)\n\ndef get_thumbnail(path):\n    i = Image.open(path)\n    i.thumbnail((200, 200), Image.LANCZOS)\n    return i\n\ndef image_base64(im):\n    if isinstance(im, str):\n        im = get_thumbnail(im)\n    with BytesIO() as buffer:\n        im.save(buffer, 'png')\n        return base64.b64encode(buffer.getvalue()).decode()\n\ndef image_formatter(im):\n    return f'<img src=\"data:image\/png;base64,{image_base64(im)}\">'\n\nfrom IPython.display import display_html\nfrom itertools import chain,cycle\n\ndef display_side_by_side(*args,titles=cycle([''])):\n    html_str=''\n    for df,title in zip(args, chain(titles,cycle(['<\/br>'])) ):\n        html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n        html_str+=f'<h2>{title}<\/h2>'\n        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n        html_str+='<\/td><\/th>'\n    display_html(html_str,raw=True)","59029d60":"covid_images = train\ncovid_images = covid_images.sample(6)\ncovid_images['file'] = covid_images.File.map(lambda File: f'..\/input\/sarscov2-ctscan-dataset\/{File}')\ncovid_images['image'] = covid_images.file.map(lambda f: get_thumbnail(f))\nHTML(covid_images[['Disease Type', 'image']].to_html(formatters={'image': image_formatter}, escape=False))","8faea331":"x = x \/ 255.","c775a829":"y = train['DiseaseID'].values","106d72d9":"X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=1)","24fdb7e9":"X_train = X_train.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\nX_val = X_val.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)","6f0419f0":"def entrenarModelos(num_redes, modelos, nombres, X_train, y_train, X_val, y_val, epochs=20,):\n    history = [0] * num_redes\n    #Cambia la tasa de aprendizaje en cada epoch, actualizandola a partir del epoch actual y la funci\u00f3n lambda creada.\n    planificador = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x+epochs))\n    earlyStopping = EarlyStopping(\n        monitor=\"val_recall\",\n        min_delta=0.001,\n        patience=20,\n        verbose=0,\n        restore_best_weights=True,)\n    \n    for i in range(num_redes):\n        history[i] = modelos[i].fit(X_train,y_train, batch_size=80, epochs = epochs, validation_data = (X_val,y_val), callbacks=[planificador, earlyStopping], verbose=0)\n        #a = history[i].history['val_recall'].index(max(history[i].history['val_recall']))\n        print(\"RED {0}: Epochs={1:d}, Train recall={2:.5f}, Validation recall={3:.5f}, Train acc={2:.5f}, Validation acc={3:.5f}\".format(\n        nombres[i],epochs,history[i].history['recall'][-1],history[i].history['val_recall'][-1], history[i].history['accuracy'][-1],history[i].history['val_accuracy'][-1] ))","5a194333":"from keras.callbacks import LearningRateScheduler, EarlyStopping\nfrom keras.metrics import Recall\n\nredes = 3\nmodelo = [0]*redes\n\nfor i in range(redes):\n    modelo[i] = Sequential()\n    modelo[i].add(Conv2D(32, kernel_size=5, padding='same', activation='relu',  input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n    modelo[i].add(MaxPool2D(pool_size = 2))\n    modelo[i].add(Dropout(0.25))\n    \n    if i >= 1:\n        modelo[i].add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\n        modelo[i].add(MaxPool2D(pool_size = 2))\n        modelo[i].add(Dropout(0.25))\n    \n    if i == 2:\n        modelo[i].add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\n        modelo[i].add(MaxPool2D(pool_size = 2))\n        modelo[i].add(Dropout(0.25))\n        \n    modelo[i].add(Flatten())\n    modelo[i].add(Dense(256, activation='relu'))\n    modelo[i].add(Dropout(0.25))\n    modelo[i].add(Dense(1, activation='sigmoid'))\n    modelo[i].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Recall\"])\n\nnombres = [\"1-Capa\",\"2-Capas\",\"3-Capas\"]\nentrenarModelos(redes, modelo, nombres, X_train, y_train, X_val, y_val, epochs=20,)","3290bf41":"from keras.callbacks import LearningRateScheduler, EarlyStopping\nfrom keras.metrics import Recall\n\nredes = 3\nmodelo = [0]*redes\n\nfor i in range(redes):\n    if i == 0:\n        modelo[i] = Sequential()\n        modelo[i].add(Conv2D(32, kernel_size=5, padding='same', activation='relu',  input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n        modelo[i].add(MaxPool2D(pool_size = 2))\n        modelo[i].add(Dropout(0.25))\n    \n    if i == 1:\n        modelo[i] = Sequential()\n        modelo[i].add(Conv2D(32, kernel_size=3, padding='same', activation='relu',  input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n        modelo[i].add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n        modelo[i].add(MaxPool2D(pool_size = 2))\n        modelo[i].add(Dropout(0.25))\n        \n    if i == 2:\n        modelo[i] = Sequential()\n        modelo[i].add(Conv2D(32, kernel_size=3, padding='same', activation='relu',  input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n        modelo[i].add(MaxPool2D(pool_size = 2))\n        modelo[i].add(Dropout(0.25))\n    \n    modelo[i].add(Flatten())\n    modelo[i].add(Dense(256, activation='relu'))\n    modelo[i].add(Dropout(0.25))\n    modelo[i].add(Dense(1, activation='sigmoid'))\n    modelo[i].compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Recall\"])\n\nnombres = [\"5x5\",\"2-3x3\",\"3x3\"]\nentrenarModelos(redes, modelo, nombres, X_train, y_train, X_val, y_val, epochs=30,)","d26aa541":"def create_model(dropout=0.25, neurons_dense=256, neurons_conv=32, pool_size=2):\n    \n    modelo = Sequential()\n    modelo.add(Conv2D(neurons_conv, kernel_size=3, padding='same', activation='relu', input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n    modelo.add(Conv2D(neurons_conv, kernel_size=3, padding='same', activation='relu'))\n    modelo.add(MaxPool2D(pool_size = pool_size))\n    modelo.add(Dropout(dropout))\n\n    #La capa flatten transforma los datos en una dimensi\u00f3n para poder ser procesados por las capas densas.\n    modelo.add(Flatten())\n    modelo.add(Dense(neurons_dense, activation='relu'))\n    modelo.add(Dropout(dropout))\n    modelo.add(Dense(1, activation='sigmoid'))\n    modelo.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Recall\"])\n    \n    return modelo","085ca549":"# from sklearn.model_selection import GridSearchCV\n# from keras.wrappers.scikit_learn import KerasClassifier\n\n# modelo = KerasClassifier(build_fn=create_model, epochs=20, verbose=0)\n\n# params = {'neurons_dense': [64, 128, 256], \n#           'neurons_conv':[16, 32, 64],\n#           'dropout': [0.25, 0.15, 0.35],\n#           'pool_size':[2,3],\n#           'batch_size':[64]}\n\n# grid = GridSearchCV(estimator=modelo, param_grid=params, cv=2, scoring='recall')\n# grid_result = grid.fit(X_train, y_train)\n# # summarize results\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']","e547d2ad":"modelo = Sequential()\nmodelo.add(Conv2D(16, kernel_size=3, padding='same', activation='relu', input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\nmodelo.add(Conv2D(16, kernel_size=3, padding='same', activation='relu'))\nmodelo.add(MaxPool2D(pool_size = 2))\nmodelo.add(Dropout(0.35))\n\n#La capa flatten transforma los datos en una dimensi\u00f3n para poder ser procesados por las capas densas.\nmodelo.add(Flatten())\nmodelo.add(Dense(64, activation='relu'))\nmodelo.add(Dropout(0.35))\nmodelo.add(Dense(1, activation='sigmoid'))\nmodelo.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"Recall\"])","e544ac48":"plot_model(modelo, \n           show_shapes = True, \n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 60)","b0916f10":"datagen = ImageDataGenerator(rotation_range=8, \n                        width_shift_range=0.05, \n                        height_shift_range=0.05, \n                        zoom_range=0.05,\n                        shear_range=0.1) \ndatagen.fit(X_train)","b8d5fe09":"earlyStopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    min_delta=0.001,\n    patience=20,\n    verbose=0,\n    restore_best_weights=True,)\n#history = modelo.fit(X_train,y_train, batch_size=64, epochs = 100, validation_data = (X_val,y_val), callbacks=[earlyStopping], verbose=1)\n\nhistory = modelo.fit_generator(datagen.flow(X_train, y_train, batch_size=64),\n            steps_per_epoch=X_train.shape[0] \/\/ 64,\n            epochs=100,\n            verbose=1,\n            callbacks=[earlyStopping],\n            validation_data = (X_val,y_val))","9a56b5ed":"\nplt.plot(history.history['accuracy'], 'bo')\nplt.plot(history.history['val_accuracy'], 'rx')\nplt.title('Precision del modelo')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.grid()\nplt.show()\n\nplt.plot(history.history['loss'], 'bo')\nplt.plot(history.history['val_loss'], 'rX')\nplt.title('Perdida del modelo')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.grid()\nplt.show()\n\nplt.plot(history.history['recall'], 'bo')\nplt.plot(history.history['val_recall'], 'rX')\nplt.title('Recall del modelo')\nplt.ylabel('recall')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.grid()\nplt.show()","7881dc7a":"print(\"Evaluar datos de test\")\nresults = modelo.evaluate(X_val, y_val, batch_size=16)\nprint(\"test loss, test acc, test recall:\", results)","b0b1c511":"random = randint(0,X_val.shape[0]-1)\n\nx_covid = X_val[random]\nx_covid = x_covid.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\ny = y_val[random]\n# x_covid = imageK.img_to_array(img_covid)\n# x_covid = np.expand_dims(x_covid, axis = 0)\n# x_covid = x_covid.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n# x_covid \/= 255\nprediccon = modelo.predict(x_covid)\nclase = np.round(prediccon)\n        \nprint('Predicci\u00f3n:',disease_types[int(clase)], \" Clase Real : \",disease_types[int(y)])","4c447427":"## 1.4 Muestra de im\u00e1genes del dataset","bd2a692d":"### 4.1 Predicci\u00f3n de la red\nVeremos como se predicen varias imagenes del conjunto de validaci\u00f3n","403beeb5":"Vemos que apartir de la epoch 30, el recall se mantiene la gran mayoria de las veces por encima del 90%, y la precisi\u00f3n se mantiene estable por encima del 90%. Esta falta de inconsistencia se puede deber en parte a la escasez de datos en el entrenamiento.","0d2709e4":"Probaremos distintas arquitecturas de la red para comprobar cual de ella nos da unos mejores resultados para nuestros datos. En primer lugar elegiremos el n\u00famero de capas.\n\n## 2.1 Elecci\u00f3n de capas\n\nRealizaremos pruebas con redes de 1 capa, 2 capas y 3 capas. Cada capa formada por una capa convoluci\u00f3n y otra de maxpooling.","caea108e":"En base a los resultados observamos, que la mejor arquitectura es la de dos capas convolucionales con dos kernels 3x3  la cual obtuvo las majores puntuaciones en validaci\u00f3n tanto recall como precisi\u00f3n.","d54a8d3d":"## 1.7 Divisi\u00f3n conjunto de datos\nDividimos el conjunto de datos en validaci\u00f3n y entrenamiento","97cf13c7":"Los resultados tras le ejecuci\u00f3n han sido Best: 0.948637 using {'batch_size': 64, 'dropout': 0.35, 'neurons_conv': 16, 'neurons_dense': 64, 'pool_size': 2}\ncomentaremos el c\u00f3digo para que no se vuelva a ejecutar ya que es muy costoso computacionalmente. Observamos que ha encontrado la mejor convinaci\u00f3n de estos par\u00e1metros.","26c4e623":"## 1.3 Cargar las im\u00e1genes en blanco y negro\nCargamos las imagenes en blanco y negro y las almacenamos en un vector","5b3aaacc":"## 1.2 Reordenar las im\u00e1genes\nReordenamos aleatoriamente las imagenes ya que se encuentran agrupadas por covid y no covid al cargarlas.","01ea05de":"Los mejores resultados han sido obtenidos con una sola capa, por lo que solamente usaremos una. Como vemos son los resultados m\u00e1s completos ya que tienen un mejor recall y una mejor precisi\u00f3n que el resto.","67d114ae":"# 2. Definici\u00f3n de la red","92d3321c":"Vemos como son las im\u00e1genes de los diferentes casos: *COVID* y *non-COVID*","0bacaf58":"## 2.2 Elecci\u00f3n de capas maxPool\n\nVamos a realizar una prueba para comprobar si es mejor utilizar una sola capa con un kernel de 5x5 o dos capas con dos kernels de 3x3 los cuales realizan la misma operaci\u00f3n pero utilizan menos recursos, son m\u00e1s r\u00e1pidos y tienen una mayor no linealidad. Tambi\u00e9n probaremos con una sola capa 3x3 para tener m\u00e1s datos.","200de4b6":"## 2.3 GridSearchCV para optimizar par\u00e1metros\n\nUtilizamores GridSearchCV para realizar una busqueda de los mejores par\u00e1metros. Intentando optimizar el numero de neuronas tanto de las capas convolutivas como de la capa densa, junto con el dropout y el pool size.","5a0bb97e":"# 1. Tratamiendo de las im\u00e1genes\n## 1.1 Cargar las rutas y clases\nCargaremos las im\u00e1genes en escala de grises ya que simplifica el computo y el color no aporta nada especial en este caso ya que las tomograf\u00edas no tienen color. Cargamos las clases asignado a cada una un valor num\u00e9rico, el 1 sera para la clase COVID y 0 para las No COVID.","aca66202":"## 2.3 Estructura en capas de la red","6e6b4ab6":"## 1.8 Formatear dimensiones dataset\nCambiaremos las dimensiones del dataset para que pueda utilizarse en el modelo ya que se necesitan 4 dimensiones. Para ello a\u00f1adiremos una dimension con -1 sin cambiar los datos.","852099a6":"## 4. Predicci\u00f3n","b46a06a4":"## 2.4 Representaci\u00f3n gr\u00e1fica de precisi\u00f3n, p\u00e9rdida y recall ","fda49a40":"## 1.6 Separar el target\nSacamos la variable target del dataset y las imagenes en x para dividir el dataset","0cd1befd":"## 3. Evaluaci\u00f3n de la red","3a1f7a97":"# Detecci\u00f3n Covid en Tomograf\u00edas - Pr\u00e1cticas Xeridia\n## Autores: Alejandro P\u00e9rez, Rub\u00e9n Gonz\u00e1lez, Santiago Valbuena\n* **1. Tratamiento de las im\u00e1genes**\n    * 1.1 Cargar las rutas y clases\n    * 1.2 Reordenar las im\u00e1genes\n    * 1.3 Cargar las im\u00e1genes\n    * 1.4 Muestra de im\u00e1genes del dataset\n    * 1.5 Normalizar las im\u00e1genes\n    * 1.6 Separar el target\n    * 1.7 Divisi\u00f3n conjunto de datos\n    * 1.8 Formatear dimensiones dataset\n* **2. Definici\u00f3n de la red**\n    * 2.1 Elecci\u00f3n de las capas\n    * 2.2 Elecci\u00f3n del n\u00famero de filtros\n    * 2.3 Otros par\u00e1metros - GridsearchCV\n    * 2.4 Red definitiva\n    * 2.5 Aumento de datos\n    * Entrenamiento del modelo\n* **3. Evaluaci\u00f3n del modelo**\n* **4. Predicci\u00f3n y entrega**","15431c7f":"Vemos que el Recall es superior al accuracy tal como quer","5cb55314":"## 1.5 Normalizar los im\u00e1genes\nNormalizamos los datos","291929e5":"## 2.4 Modelo definitivo"}}