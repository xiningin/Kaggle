{"cell_type":{"763c852e":"code","86af5d5c":"code","039c33d4":"code","75d16798":"code","3dab7bd4":"code","71a8f03c":"code","8629374b":"code","754559b6":"code","ec334759":"code","c20ec0be":"code","98aceb5c":"code","c1f3d319":"code","e757688e":"code","72843512":"code","ff52a2e3":"code","9b1aa33d":"code","459fdf89":"markdown","cb3da909":"markdown","90ce8b52":"markdown","c79b82bc":"markdown","500c5246":"markdown","ba49d482":"markdown","49095168":"markdown","1b02524c":"markdown","11e58baa":"markdown","02ba475c":"markdown","e8e42403":"markdown"},"source":{"763c852e":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeRegressor\nimport numpy as np","86af5d5c":"exemplo=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ndata=pd.read_csv('\/kaggle\/input\/titanic\/train.csv',index_col='PassengerId')\ndataTest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv',index_col='PassengerId')\ndata=data.dropna(axis=0)\ndata.head()","039c33d4":"#Prediction Target\ny=data.Survived\n#Features choose\ncolumnas=['Pclass','Sex','Age']\nX=data[columnas]\nX.head()","75d16798":"#data must be numerical\nX['Sex']=X.Sex.map(lambda x: 1 if x=='male' else 0)\nX","3dab7bd4":"data_model=DecisionTreeRegressor(random_state=1)\ndata_model.fit(X,y)\n","71a8f03c":"prediccions=data_model.predict(X)","8629374b":"z=[x1-x2 for (x1,x2) in zip(prediccions,list(y))]\n#Success ratio \nz.count(0)\/len(z)","754559b6":"Xtest=dataTest[columnas]\nXtest['Sex']=Xtest.Sex.map(lambda x: 1 if x=='male' else 0)\nXtest\n#po\u00f1emos\n#dataTest.loc[np.isnan(dataTest.Age)]","ec334759":"# Temos que po\u00f1er a idade dos NaN -> media\nageM=data.Age.mean()\nXtest=Xtest.fillna(ageM)","c20ec0be":"pred=data_model.predict(Xtest)","98aceb5c":"predR=[int(round(x)) for x in pred]\nlen(predR), predR.count(1)","c1f3d319":"submit=pd.DataFrame({'Survived':predR}, index=dataTest.index)\n#submit.to_csv('\/home\/manu\/Programacion\/kaggle\/titanic\/TreeSKlearn1.csv')","e757688e":"from sklearn.model_selection import train_test_split\ntrain_X,val_X,train_y, val_y=train_test_split(X,y,random_state=1)\n","72843512":"for mln in [2,5,8,10,20,100]:\n    train_X_model=DecisionTreeRegressor(max_leaf_nodes=mln,random_state=2)\n    train_X_model.fit(train_X,train_y)\n    pred=train_X_model.predict(val_X)\n    predR=[int(round(x)) for x in pred]\n    z=[x1-x2 for (x1,x2) in zip(predR,list(val_y))]\n    #Success ratio \n    sR=z.count(0)\/len(z)\n    print(\"Max Leaf Nodes \"+str(mln)+\"\\t\\t Success Ratio: \"+\"{0:.0%}\".format(sR))\n    ","ff52a2e3":"mln=10\ndata_model=DecisionTreeRegressor(max_leaf_nodes=mln,random_state=2)\ndata_model.fit(X,y)\npred=train_X_model.predict(Xtest)\npredR=[int(round(x)) for x in pred]\nlen(predR), predR.count(1)","9b1aa33d":"submit=pd.DataFrame({'Survived':predR}, index=dataTest.index)\n#submit.to_csv('\/home\/manu\/Programacion\/kaggle\/titanic\/TreeSKlearnMLN.csv')","459fdf89":"#### Result -> 66%","cb3da909":"## Set max_leaf_nodes=10 and testing","90ce8b52":"#### Result not relevant","c79b82bc":"### Split the train data for evaluate de best max_leaf_nodes","500c5246":"## Building the model","ba49d482":"# Titanic Competition - Using sklearn","49095168":"#### Result -> 72%","1b02524c":"## Validating model in data Test","11e58baa":"## Info: https:\/\/www.kaggle.com\/c\/titanic","02ba475c":"### Write csv file","e8e42403":"## Improve the model using max_leaf_nodes"}}