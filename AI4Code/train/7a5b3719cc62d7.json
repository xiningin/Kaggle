{"cell_type":{"900f30cd":"code","3e9d854c":"code","e19c1b8a":"code","954f5a36":"code","84683e56":"code","34e23388":"code","8ba2704c":"code","63dcf104":"code","23edb593":"code","6ded17e2":"code","a8a826f4":"code","badee644":"markdown","5fa736b0":"markdown"},"source":{"900f30cd":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\n# --- setup ---\npd.set_option('max_columns', 50)\n","3e9d854c":"import pickle\nfrom pathlib import Path\n\nimport cv2\nimport pandas as pd\nfrom detectron2.structures import BoxMode\nfrom tqdm import tqdm\n\n\ndef get_vinbigdata_dicts(\n    imgdir: Path, train: pd.DataFrame, use_cache: bool = True, debug: bool = True,\n):\n    debug_str = f\"_debug{int(debug)}\"\n    cache_path = Path(\".\") \/ f\"dataset_dicts_cache{debug_str}.pkl\"\n    if not use_cache or not cache_path.exists():\n        print(\"Creating data...\")\n        train_meta = pd.read_csv(imgdir \/ \"train_meta.csv\")\n        if debug:\n            train_meta = train_meta.iloc[:500]  # For debug....\n\n        # Load 1 image to get image size.\n        image_id = train_meta.loc[0, \"image_id\"]\n        image_path = str(imgdir \/ \"train\" \/ f\"{image_id}.png\")\n        image = cv2.imread(image_path)\n        resized_height, resized_width, ch = image.shape\n        print(f\"image shape: {image.shape}\")\n\n        dataset_dicts = []\n        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n            record = {}\n\n            image_id, height, width = train_meta_row.values\n            filename = str(imgdir \/ \"train\" \/ f\"{image_id}.png\")\n            record[\"file_name\"] = filename\n            record[\"image_id\"] = index\n            record[\"height\"] = resized_height\n            record[\"width\"] = resized_width\n            objs = []\n            for index2, row in train.query(\"image_id == @image_id\").iterrows():\n                # print(row)\n                # print(row[\"class_name\"])\n                # class_name = row[\"class_name\"]\n                class_id = row[\"class_id\"]\n                if class_id == 14:\n                    # It is \"No finding\"\n                    # This annotator does not find anything, skip.\n                    pass\n                else:\n                    # bbox_original = [int(row[\"x_min\"]), int(row[\"y_min\"]), int(row[\"x_max\"]), int(row[\"y_max\"])]\n                    h_ratio = resized_height \/ height\n                    w_ratio = resized_width \/ width\n                    bbox_resized = [\n                        int(row[\"x_min\"]) * w_ratio,\n                        int(row[\"y_min\"]) * h_ratio,\n                        int(row[\"x_max\"]) * w_ratio,\n                        int(row[\"y_max\"]) * h_ratio,\n                    ]\n                    obj = {\n                        \"bbox\": bbox_resized,\n                        \"bbox_mode\": BoxMode.XYXY_ABS,\n                        \"category_id\": class_id,\n                    }\n                    objs.append(obj)\n            record[\"annotations\"] = objs\n            dataset_dicts.append(record)\n        with open(cache_path, mode=\"wb\") as f:\n            pickle.dump(dataset_dicts, f)\n\n    print(f\"Load from cache {cache_path}\")\n    with open(cache_path, mode=\"rb\") as f:\n        dataset_dicts = pickle.load(f)\n    return dataset_dicts\n\n\ndef get_vinbigdata_dicts_test(\n    imgdir: Path, test_meta: pd.DataFrame, use_cache: bool = True, debug: bool = True,\n):\n    debug_str = f\"_debug{int(debug)}\"\n    cache_path = Path(\".\") \/ f\"dataset_dicts_cache_test{debug_str}.pkl\"\n    if not use_cache or not cache_path.exists():\n        print(\"Creating data...\")\n        # test_meta = pd.read_csv(imgdir \/ \"test_meta.csv\")\n        if debug:\n            test_meta = test_meta.iloc[:500]  # For debug....\n\n        # Load 1 image to get image size.\n        image_id = test_meta.loc[0, \"image_id\"]\n        image_path = str(imgdir \/ \"test\" \/ f\"{image_id}.png\")\n        image = cv2.imread(image_path)\n        resized_height, resized_width, ch = image.shape\n        print(f\"image shape: {image.shape}\")\n\n        dataset_dicts = []\n        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n            record = {}\n\n            image_id, height, width = test_meta_row.values\n            filename = str(imgdir \/ \"test\" \/ f\"{image_id}.png\")\n            record[\"file_name\"] = filename\n            record[\"image_id\"] = index\n            record[\"height\"] = resized_height\n            record[\"width\"] = resized_width\n            # objs = []\n            # record[\"annotations\"] = objs\n            dataset_dicts.append(record)\n        with open(cache_path, mode=\"wb\") as f:\n            pickle.dump(dataset_dicts, f)\n\n    print(f\"Load from cache {cache_path}\")\n    with open(cache_path, mode=\"rb\") as f:\n        dataset_dicts = pickle.load(f)\n    return dataset_dicts\n","e19c1b8a":"# Methods for prediction for this competition\nfrom math import ceil\nfrom typing import Any, Dict, List\n\nimport cv2\nimport detectron2\nimport numpy as np\nfrom numpy import ndarray\nimport pandas as pd\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import ColorMode, Visualizer\nfrom tqdm import tqdm\n\n\ndef format_pred(labels: ndarray, boxes: ndarray, scores: ndarray) -> str:\n    pred_strings = []\n    for label, score, bbox in zip(labels, scores, boxes):\n        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n        pred_strings.append(f\"{label} {score} {xmin} {ymin} {xmax} {ymax}\")\n    return \" \".join(pred_strings)\n\n\ndef predict_batch(predictor: DefaultPredictor, im_list: List[ndarray]) -> List:\n    with torch.no_grad():  # https:\/\/github.com\/sphinx-doc\/sphinx\/issues\/4258\n        inputs_list = []\n        for original_image in im_list:\n            # Apply pre-processing to image.\n            if predictor.input_format == \"RGB\":\n                # whether the model expects BGR inputs or RGB\n                original_image = original_image[:, :, ::-1]\n            height, width = original_image.shape[:2]\n            image = predictor.aug.get_transform(original_image).apply_image(original_image)\n            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n            inputs = {\"image\": image, \"height\": height, \"width\": width}\n            inputs_list.append(inputs)\n        predictions = predictor.model(inputs_list)\n        return predictions\n","954f5a36":"# --- utils ---\nfrom pathlib import Path\nfrom typing import Any, Union\n\nimport yaml\n\n\ndef save_yaml(filepath: Union[str, Path], content: Any, width: int = 120):\n    with open(filepath, \"w\") as f:\n        yaml.dump(content, f, width=width)\n\n\ndef load_yaml(filepath: Union[str, Path]) -> Any:\n    with open(filepath, \"r\") as f:\n        content = yaml.full_load(f)\n    return content\n","84683e56":"# --- configs ---\nthing_classes = [\n    \"Aortic enlargement\",\n    \"Atelectasis\",\n    \"Calcification\",\n    \"Cardiomegaly\",\n    \"Consolidation\",\n    \"ILD\",\n    \"Infiltration\",\n    \"Lung Opacity\",\n    \"Nodule\/Mass\",\n    \"Other lesion\",\n    \"Pleural effusion\",\n    \"Pleural thickening\",\n    \"Pneumothorax\",\n    \"Pulmonary fibrosis\"\n]\ncategory_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}\n","34e23388":"# --- flags ---\nfrom dataclasses import dataclass\nfrom typing import Dict\n\n\n@dataclass\nclass Flags:\n    # General\n    debug: bool = True\n    outdir: str = \"results\/det\"\n\n    # Data config\n    imgdir_name: str = \"vinbigdata-chest-xray-resized-png-256x256\"\n    # Training config\n    iter: int = 10000\n    ims_per_batch: int = 2  # images per batch, this corresponds to \"total batch size\"\n    num_workers: int = 4\n    base_lr: float = 0.00025\n    roi_batch_size_per_image: int = 512\n\n    def update(self, param_dict: Dict) -> \"Flags\":\n        # Overwrite by `param_dict`\n        for key, value in param_dict.items():\n            if not hasattr(self, key):\n                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n            setattr(self, key, value)\n        return self\n","8ba2704c":"flags_dict = {\n    \"debug\": True,\n    \"outdir\": \"results\/debug\", \n    \"imgdir_name\": \"vinbigdata-chest-xray-resized-png-256x256\",\n    \"iter\": 100,  # debug, small value should be set.\n    \"roi_batch_size_per_image\": 128  # faster, and good enough for this toy dataset (default: 512)\n}","63dcf104":"inputdir = Path(\"\/kaggle\/input\")\ntraineddir = inputdir \/ \"vinbigdata-r50fpn3x-512px\"\n\n# flags = Flags()\nflags: Flags = Flags().update(load_yaml(str(traineddir\/\"flags.yaml\")))\nprint(\"flags\", flags)\ndebug = flags.debug\n# flags_dict = dataclasses.asdict(flags)\noutdir = Path(flags.outdir)\nos.makedirs(str(outdir), exist_ok=True)\n\n# --- Read data ---\ndatadir = inputdir \/ \"vinbigdata-chest-xray-abnormalities-detection\"\nimgdir = inputdir \/ flags.imgdir_name\n\n# Read in the data CSV files\n# train = pd.read_csv(datadir \/ \"train.csv\")\ntest_meta = pd.read_csv(inputdir \/ \"vinbigdata-testmeta\" \/ \"test_meta.csv\")\nsample_submission = pd.read_csv(datadir \/ \"sample_submission.csv\")\n\ncfg = get_cfg()\noriginal_output_dir = cfg.OUTPUT_DIR\ncfg.OUTPUT_DIR = str(outdir)\nprint(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"vinbigdata_train\",)\ncfg.DATASETS.TEST = ()\n# cfg.DATASETS.TEST = (\"vinbigdata_train\",)\n# cfg.TEST.EVAL_PERIOD = 50\ncfg.DATALOADER.NUM_WORKERS = 2\n# Let training initialize from model zoo\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = flags.base_lr  # pick a good LR\ncfg.SOLVER.MAX_ITER = flags.iter\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = flags.roi_batch_size_per_image\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\n### --- Inference & Evaluation ---\n# Inference should use the config with parameters that are used in training\n# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n# path to the model we just trained\n# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.WEIGHTS = str(traineddir \/ \"model_final.pth\")\nprint(\"Original thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)  # 0.05\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0   # set a custom testing threshold\nprint(\"Changed  thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)  # 0.0\npredictor = DefaultPredictor(cfg)\n\nDatasetCatalog.register(\n    \"vinbigdata_test\", lambda: get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n)\nMetadataCatalog.get(\"vinbigdata_test\").set(thing_classes=thing_classes)\nmetadata = MetadataCatalog.get(\"vinbigdata_test\")\ndataset_dicts = get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n\nif debug:\n    dataset_dicts = dataset_dicts[:100]\n\nresults_list = []\nindex = 0\nbatch_size = 4\n\nfor i in tqdm(range(ceil(len(dataset_dicts) \/ batch_size))):\n    inds = list(range(batch_size * i, min(batch_size * (i + 1), len(dataset_dicts))))\n    dataset_dicts_batch = [dataset_dicts[i] for i in inds]\n    im_list = [cv2.imread(d[\"file_name\"]) for d in dataset_dicts_batch]\n    outputs_list = predict_batch(predictor, im_list)\n\n    for im, outputs, d in zip(im_list, outputs_list, dataset_dicts_batch):\n        resized_height, resized_width, ch = im.shape\n        # outputs = predictor(im)\n        if index < 5:\n            # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\n            v = Visualizer(\n                im[:, :, ::-1],\n                metadata=metadata,\n                scale=0.5,\n                instance_mode=ColorMode.IMAGE_BW\n                # remove the colors of unsegmented pixels. This option is only available for segmentation models\n            )\n            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n            cv2.imwrite(str(outdir \/ f\"pred_{index}.jpg\"), out.get_image()[:, :, ::-1])\n            plt.title(f\"index {index}\")\n            plt.imshow(out.get_image()[:, :, ::-1])\n\n        assert d[\"image_id\"] == index\n        image_id, dim0, dim1 = test_meta.iloc[index].values\n\n        instances = outputs[\"instances\"]\n        if len(instances) == 0:\n            # No finding, let's set 14 0 0 0 0.\n            result = {\"image_id\": image_id, \"PredictionString\": \"14 1.0 0 0 1 1\"}\n        else:\n            # Find some bbox...\n            # print(f\"index={index}, find {len(instances)} bbox.\")\n            fields: Dict[str, Any] = instances.get_fields()\n            pred_classes = fields[\"pred_classes\"]  # (n_boxes,)\n            pred_scores = fields[\"scores\"]\n            # shape (n_boxes, 4). (xmin, ymin, xmax, ymax)\n            pred_boxes = fields[\"pred_boxes\"].tensor\n\n            h_ratio = dim0 \/ resized_height\n            w_ratio = dim1 \/ resized_width\n            pred_boxes[:, [0, 2]] *= w_ratio\n            pred_boxes[:, [1, 3]] *= h_ratio\n\n            pred_classes_array = pred_classes.cpu().numpy()\n            pred_boxes_array = pred_boxes.cpu().numpy()\n            pred_scores_array = pred_scores.cpu().numpy()\n\n            result = {\n                \"image_id\": image_id,\n                \"PredictionString\": format_pred(\n                    pred_classes_array, pred_boxes_array, pred_scores_array\n                ),\n            }\n        results_list.append(result)\n        index += 1","23edb593":"# This submission includes only detection model's predictions\nsubmission_det = pd.DataFrame(results_list, columns=['image_id', 'PredictionString'])\nsubmission_det.to_csv(outdir\/\"submission_det.csv\", index=False)\nsubmission_det","6ded17e2":"thr = 0.8\npred_2class = pd.read_csv(inputdir\/\"vinbigdata-2class-prediction\/2-cls test pred.csv\")\n\npred_cl1 = pd.read_csv('..\/input\/vinbigdata-cxr-ad-yolov5-14-class-infer\/submission.csv')\npred_cl2 = pd.read_csv('..\/input\/vinbigdata-2class-prediction\/2-cls test pred.csv')\n\npred = pd.merge(pred_cl1, pred_cl2, on = 'image_id', how = 'left')\n\npred['PredictionString'].value_counts().iloc[[0]]\n\ndef filter_2cls(row, thr=thr):\n    if row['target']<thr:\n        row['PredictionString'] = '14 1 0 0 1 1'\n    return row\n\nsub = pred.apply(filter_2cls, axis=1)\n\nsub['PredictionString'].value_counts().iloc[[0]]\n\n\nsub[['image_id', 'PredictionString']].to_csv('vinbigdata_chest_submission_v10.csv',index = False)","a8a826f4":"NORMAL = \"14 1 0 0 1 1\"\nthreshold = 0.8\n\npred_det_df = submission_det  # You can load from another submission.csv here too.\nn_normal_before = len(pred_det_df.query(\"PredictionString == @NORMAL\"))\nmerged_df = pd.merge(pred_det_df, pred_2class, on=\"image_id\", how=\"left\")\nif \"class0\" in merged_df.columns:\n    merged_df.loc[merged_df[\"class0\"] >= threshold, \"PredictionString\"] = NORMAL\nelse:\n    merged_df.loc[merged_df[\"target\"] < 1 - threshold, \"PredictionString\"] = NORMAL\nn_normal_after = len(merged_df.query(\"PredictionString == @NORMAL\"))\nprint(f\"n_normal: {n_normal_before} -> {n_normal_after} with threshold {threshold}\")\nsubmission_filepath = str(outdir \/ \"submission.csv\")\nsubmission_df = merged_df[[\"image_id\", \"PredictionString\"]]\nsubmission_df.to_csv(submission_filepath, index=False)\nprint(f\"Saved to {submission_filepath}\")\n","badee644":"<a id=\"ref\"><\/a>\n# Other kernels\n\n[\ud83d\udcf8VinBigData detectron2 train](https:\/\/www.kaggle.com\/corochann\/vinbigdata-detectron2-train) kernel explains how to run object detection training, using `detectron2` library.\n\n[\ud83d\udcf8VinBigData 2-class classifier complete pipeline](https:\/\/www.kaggle.com\/corochann\/vinbigdata-2-class-classifier-complete-pipeline) kernel explains how to train 2 class classifier model for the prediction and submisssion for this competition.","5fa736b0":"That's all!\nObject deteaction is rather complicated task among deep learning tasks, but it's easy to train SoTA models & predict using `detectron2`!!!\n\n<h3 style=\"color:red\">If this kernel helps you, please upvote to keep me motivated \ud83d\ude01<br>Thanks!<\/h3>"}}