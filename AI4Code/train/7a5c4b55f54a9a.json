{"cell_type":{"cc4fc4d9":"code","6a0703ff":"code","cbb9879b":"code","e50a9b90":"code","64721a52":"code","95378eb4":"code","d80d86ed":"code","79183786":"code","cf84d48f":"code","03ab6e8b":"code","7d6d20cc":"code","6bc06a51":"code","4fa72de9":"code","710a2b99":"code","63273a02":"code","36ee0610":"code","f9c712d3":"code","1c21ec60":"code","ce46d8d5":"code","63d0be33":"code","7c8ce3b2":"code","48cd0999":"code","cc99b07d":"code","a3a22d9c":"code","e5e1011e":"code","e09e31d0":"code","6105f68d":"code","76178788":"code","c683f8de":"code","0d71c98d":"code","27436224":"code","1c7c7166":"code","6ce3ae08":"code","f5feff50":"code","13679110":"code","e04e02d1":"code","050da6b4":"code","1a6301f3":"code","d869c637":"code","8f146b46":"code","c3df266e":"code","de2a4ed4":"code","f967238e":"code","794c7879":"code","130c187f":"code","a62832d1":"code","826bda11":"code","842cfdd8":"code","eb8a8c78":"code","7893f78b":"code","e9b161a9":"code","2803749d":"code","f7d67371":"code","e0ff0674":"markdown","0baeccfc":"markdown","62b5cc0e":"markdown","8723c775":"markdown","76887bb8":"markdown","4b63892b":"markdown","8d90b684":"markdown","f13b5d01":"markdown","c80c341e":"markdown","02178b41":"markdown","c562f5dd":"markdown","228ded37":"markdown","bffb05db":"markdown","b1ae9310":"markdown","d494b06d":"markdown","f882997c":"markdown","648b8158":"markdown","1c61a829":"markdown","bf94d9ec":"markdown","6dd18750":"markdown","4a5541cc":"markdown","68d739e1":"markdown","25156f7f":"markdown","0afa9d0c":"markdown","628ef899":"markdown","59df323e":"markdown"},"source":{"cc4fc4d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a0703ff":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport email\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n","cbb9879b":"pip install beautifulsoup4","e50a9b90":"from bs4 import BeautifulSoup","64721a52":"Non_SM=os.listdir(\"..\/input\/ham-and-spam-dataset\/ham\/\")\nprint(f\"The Number of Non-Spam Mails are {len(Non_SM)}\")\nSM=os.listdir(\"..\/input\/ham-and-spam-dataset\/spam\/\")\nprint(f\"The Number of Spam Mails are {len(SM)}\")","95378eb4":"percent_spam=len(SM)\/(len(SM)+len(Non_SM))\npercent_spam\npercent_Non_Spam=1-percent_spam\nplt.pie([percent_spam,percent_Non_Spam],labels =[\"Spam Mails\",\"Ham Mails\"])\nplt.show()","d80d86ed":"\nwith open(f\"..\/input\/ham-and-spam-dataset\/ham\/{Non_SM[252]}\", 'rb') as file:\n    email_ham = email.parser.BytesParser(policy=email.policy.default).parse(file) \nprint(email_ham)","79183786":"print(f\"From :{email_ham.get_all('From')[0]}\")\n\nprint(f\"The contents are :{email_ham.get_content()}\")","cf84d48f":"all_spam_mails=[]\nall_ham_mails=[]\nfor file1 in SM:\n    with open(f\"..\/input\/ham-and-spam-dataset\/spam\/{file1}\", 'rb') as file:\n        all_spam_mails.append(email.parser.BytesParser(policy=email.policy.default).parse(file))\nfor file1 in Non_SM:\n    with open(f\"..\/input\/ham-and-spam-dataset\/ham\/{file1}\", 'rb') as file:\n        all_ham_mails.append(email.parser.BytesParser(policy=email.policy.default).parse(file))","03ab6e8b":"print(f'From: {all_ham_mails[15].get_all(\"From\")[0]}')\nprint(f'To: {all_ham_mails[14].get_all(\"To\")[0]}')\nprint(f'Sub: {all_ham_mails[15].get_all(\"Subject\")[0]}')\nprint(\"~~~~~~~~~~Non_Spam Mails~~~~~~~~~~~~~~~\")\nprint(f'{all_ham_mails[15].get_content()}')\nprint(\"~~~~~~~~~~Spam Mails~~~~~~~~~~~~~~~\")\nprint(all_spam_mails[12].get_content())","7d6d20cc":"def email_content_type(email):\n    payload = email.get_payload()\n    if isinstance(payload, list):\n        return \"multipart({})\".format(\", \".join([email_content_type(sub_email) for sub_email in payload]))\n    else:\n        return email.get_content_type()","6bc06a51":"email_content_type(all_spam_mails[131])","4fa72de9":"def Removal_Html_Tags(mail):\n    try:\n        soup = BeautifulSoup(mail.get_content(), 'html.parser')#This will have the clean text file without the HTML tags but contains the escape s\n        return (soup.text.replace('\\n\\n',''))\n    except:\n        return None","710a2b99":"print(Removal_Html_Tags(all_spam_mails[129]))","63273a02":"def Convertion_Mails(mail):\n    for section in mail.walk():\n        content_type=section.get_content_type()\n#         print(content_type)\n        if(content_type in ['text\/plain','text\/html']):\n            try: \n                content = section.get_content()\n            except:\n                content = str(section.get_payload())\n            if(content_type=='text\/plain'):\n                return(content)\n            else:\n                return (Removal_Html_Tags(section))\n        else:\n            continue\n                \n#     print(content_type)","36ee0610":"converted_Email=Convertion_Mails(all_spam_mails[129])\nprint(converted_Email)","f9c712d3":"def Create_Dataframe(emails,spam):\n    converted_mails=[]\n    for mail in range(len(emails)):\n        converted_mails.append(Convertion_Mails(emails[mail]))\n    dataframe=pd.DataFrame(converted_mails,columns=['Mail'])\n    dataframe['Spam or Not']=spam\n    return (dataframe)","1c21ec60":"\nham_df=Create_Dataframe(all_ham_mails,0)\nspam_df=Create_Dataframe(all_spam_mails,1)","ce46d8d5":"ham_df.head()","63d0be33":"spam_df['Mail'][23]","7c8ce3b2":"cleaned_data=pd.concat([ham_df,spam_df],axis=0)\nprint(len(cleaned_data))","48cd0999":"cleaned_data = cleaned_data.dropna()\ncleaned_data = cleaned_data.sample(frac=1).reset_index(drop=True)\n# cleaned_data.head(10)\nprint(len(cleaned_data))","cc99b07d":"cleaned_data","a3a22d9c":"for i in range(len(cleaned_data)):\n    cleaned_data['Mail'][i] = re.sub(r\"[^a-zA-Z0-9]+\", ' ', cleaned_data['Mail'][i])\n(cleaned_data)","e5e1011e":"sns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"Spam or Not\", data=cleaned_data,hue='Spam or Not') # 0-Ham Mail 1-Spam Mail\n# ax = sns.countplot(x=\"Spam or Not\", hue=\"Spam or No\", data=cleaned_data)","e09e31d0":"cleaned_spam_mail=[]\ncleaned_ham_mail=[]\nfor index,row in cleaned_data.iterrows():\n    if(row[1]==1):\n        cleaned_spam_mail.append(row[0])\n    else:\n        cleaned_ham_mail.append(row[0])","6105f68d":"cleaned_ham_mail","76178788":"# X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","c683f8de":"# cv=CountVectorizer()\ncv=TfidfVectorizer()","0d71c98d":"accuracy_dict={}","27436224":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_Multi_Count=CountVectorizer()\nx_Multi_Count=cv_Multi_Count.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_Multi_Count,y,test_size=0.2)\nmodel_Multi_Count=MultinomialNB()\ny_predict_Multi_Count=model_Multi_Count.fit(X_train,y_train)\nAccuracy=model_Multi_Count.score(X_test,y_test)\naccuracy_dict[\"Multinomial Naive Bayes with Countvectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_Multi_Count).__name__} using {type(cv_Multi_Count).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_Multi_Count.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","1c7c7166":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_Multi_tfidf=TfidfVectorizer()\nx_Multi_tfidf=cv_Multi_tfidf.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_Multi_tfidf,y,test_size=0.2)\nmodel_Multi_tfidf=MultinomialNB()\ny_predict_Multi_Count=model_Multi_tfidf.fit(X_train,y_train)\nAccuracy=model_Multi_tfidf.score(X_test,y_test)\naccuracy_dict[\"Multinomial Naive Bayes with TfidfVectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_Multi_tfidf).__name__} using {type(cv_Multi_tfidf).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_Multi_Count.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","6ce3ae08":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_Gauss_Count=CountVectorizer()\nx_Gauss_Count=cv_Gauss_Count.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_Gauss_Count,y,test_size=0.2)\nmodel_Gauss_Count=GaussianNB()\ny_predict_Gauss_Count=model_Gauss_Count.fit(X_train.toarray(),y_train)\nAccuracy=model_Gauss_Count.score(X_test.toarray(),y_test)\naccuracy_dict[\"Guassian Naive Bayes with Countvectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_Gauss_Count).__name__} using {type(cv_Gauss_Count).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_Gauss_Count.predict(X_test.toarray())\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(f\"The Confusion Matrix is {cn_matrix}\")\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","f5feff50":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_Gauss_tfidf=TfidfVectorizer()\nx_Gauss_tfidf=cv_Gauss_tfidf.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_Gauss_tfidf,y,test_size=0.2)\nmodel_Gauss_tfidf=GaussianNB()\ny_predict_Gauss_tfidf=model_Gauss_tfidf.fit(X_train.toarray(),y_train)\nAccuracy=model_Gauss_tfidf.score(X_test.toarray(),y_test)\naccuracy_dict[\"Guassian Naive Bayes with TfidfVectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_Gauss_tfidf).__name__} using {type(cv_Gauss_tfidf).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_Gauss_tfidf.predict(X_test.toarray())\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(f\"The Confusion Matrix is {cn_matrix}\")\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","13679110":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_SVC_Count=CountVectorizer()\nx_SVC_Count=cv_SVC_Count.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_SVC_Count,y,test_size=0.2)\nmodel_SVC_Count=LinearSVC(C=1000, dual=False)\ny_predict_SVC_Count=model_SVC_Count.fit(X_train,y_train)\nAccuracy=model_SVC_Count.score(X_test,y_test)\naccuracy_dict[\"SVC with Countvectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_SVC_Count).__name__} using {type(cv_SVC_Count).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_SVC_Count.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()\n","e04e02d1":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_SVC_tfidf=TfidfVectorizer()\nx_SVC_tfidf=cv_SVC_tfidf.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_SVC_tfidf,y,test_size=0.2)\nmodel_SVC_tfidf=LinearSVC(C=1000, dual=False)\ny_predict_SVC_tfidf=model_SVC_tfidf.fit(X_train,y_train)\nAccuracy=model_SVC_tfidf.score(X_test,y_test)\naccuracy_dict[\"SVC with TfidfVectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_SVC_tfidf).__name__} using {type(cv_SVC_tfidf).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_SVC_tfidf.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()\n","050da6b4":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_random_Count=CountVectorizer()\nx_random_Count=cv_random_Count.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_random_Count,y,test_size=0.2)\nmodel_random_Count=RandomForestClassifier(max_depth=100, n_estimators=20, max_features=1)\ny_predict_random_Count=model_random_Count.fit(X_train,y_train)\nAccuracy=model_random_Count.score(X_test,y_test)\naccuracy_dict[\"RandomForrest with Countvectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_random_Count).__name__} using {type(cv_random_Count).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_random_Count.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","1a6301f3":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv_random_tfidf=TfidfVectorizer()\nx_random_tfidf=cv_random_tfidf.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x_random_tfidf,y,test_size=0.2)\nmodel_random_tfidf=RandomForestClassifier(max_depth=100, n_estimators=20, max_features=1)\ny_predict_random_tfidf=model_random_tfidf.fit(X_train,y_train)\nAccuracy=model_random_tfidf.score(X_test,y_test)\naccuracy_dict[\"RandomForrest with TfidfVectorizer\"]=(Accuracy*100)\nprint(f\"The Acuracy of the model {type(model_random_tfidf).__name__} using {type(cv_random_tfidf).__name__} is  {Accuracy*100}%\")\npredict_y_test=y_predict_random_tfidf.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\nprint(cn_matrix)\nmatrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","d869c637":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']","8f146b46":"cv=CountVectorizer()\nx=cv.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\nmodel=MultinomialNB()\ny_predict=model.fit(X_train,y_train)\nAccuracy=model.score(X_test,y_test)\nprint(f\"The Acuracy of the model {type(model).__name__} using {type(cv).__name__} is  {Accuracy*100}%\")","c3df266e":"predict_y_test=y_predict.predict(X_test)\ncn_matrix = confusion_matrix(y_test, predict_y_test)\ncn_matrix","de2a4ed4":"matrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","f967238e":"#For Testeing Try to give full spam mail then it is predicting accurately\nmails=\"I got the resarch paper from professor.Thanks :)\"\n# mails=\"Please stop mailing me\"\n# mails=\"Dear Sir or Madam In the past you have requested information on discounted products We hope that you find this of interest If you are not a smoker and find this email offensive we sincerely apologise We will be only too happy to take you off our mailing list If you are a smoker however and are fed up with paying high prices for your cigarettes and tobacco take a look at what we have to offer by clicking on this link http www smokersassociation co uk S 15 ID 2 We can send you legally by registered air mail direct to your door 4 cartons of cigarettes or 40 pouches of rolling tobacco all brands are available from only 170 Euros about 105 pounds fully inclusive of postage and packing Why pay more To remove yourself from our mailing list please click below mailto smokersclub terra es Yours faithfully Smokers Association http www smokersassociation co uk S 15 ID 2 xay3171011y Irish Linux Users Group Social Events social linux ie http www linux ie mailman listinfo social for un subscription information List maintainer listmaster linux ie\"\n# mails=\"A security advisory on ssri affects at least one of your repositories\"\n# mails=\"Domino's Piece of the Pie Rewards\u00ae is open only to US residents 13+ with a Pizza Profile account who order from participating Domino's locations. Status as of 05\/01\/2021. Point redemption only valid online at participating locations in the US. Limit: one order of $10 or more (excludes tip and donations) per calendar day can earn points. For complete details visit\"\n# mails=\"This email was sent to you by Yocket because you are a registered user on Yocket.in or you participated in one of the online or offline events conducted by us or our associates and your communication preferences indicate that you wish to receive emails from us. Such emails are sent from time to time for updates regarding events, offers or communication from any of our associated partners. To ensure that you are able to receive our emails, please add\"\ndata=[mails]\nvector=cv_Multi_Count.transform(data).toarray()\nprediction=model_Multi_Count.predict(vector)\nprint(prediction)","794c7879":"if prediction[0]==1:\n    message=\"This is a spam mail\"\nelse:\n    message=\"This is not a spam mail\"\nprint(message)","130c187f":"x=cleaned_data['Mail']\ny=cleaned_data['Spam or Not']\ncv=CountVectorizer()\nx=cv.fit_transform(x)\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.1)\nmodel_overfit=MultinomialNB()\ny_predict=model_overfit.fit(X_train,y_train)\nAccuracy=model_overfit.score(X_test,y_test)\nprint(f\"The Acuracy of the model {type(model_overfit).__name__} using {type(cv).__name__} is  {Accuracy*100}%\")","a62832d1":"predict_y_test=y_predict.predict(x)\ncn_matrix = confusion_matrix(y, predict_y_test)\ncn_matrix","826bda11":"matrix_df = pd.DataFrame(cn_matrix, index=[\"Ham\", \"Spam\"], columns=[\"Ham\", \"Spam\"])\ndf = matrix_df.astype('float')\/matrix_df.sum(axis=1)[:, np.newaxis]\nsns.heatmap(df, annot=True)\nplt.show()","842cfdd8":"import pickle","eb8a8c78":"pickle.dump(model_Multi_Count,open(\"spam.pkl\",\"wb\"))","7893f78b":"pickle.dump(cv_Multi_Count,open(\"vectorizer.pkl\",\"wb\"))","e9b161a9":"accuracy_dict","2803749d":"minY = 0;\nmaxY = max(accuracy_dict.values())\nkeys=[]\nvalues=[]\nfor keys1 in accuracy_dict.keys():\n    keys.append(keys1)\nfor values1 in accuracy_dict.values():\n    values.append(values1)\n\ndf=pd.DataFrame(values,keys,columns=['Accuracy'])\n\nax=df.plot(figsize=(7,5), kind='bar', stacked=True)\n\nax.set(ylim=[minY, maxY+2])","f7d67371":"predict=y_predict.predict(x)\npredict_df=pd.DataFrame(predict,columns=['Prediction'])\noutput_df=pd.concat([cleaned_data,predict_df],axis=1)\noutput_df.to_csv(\"Submission.csv\",index=False)","e0ff0674":"## Output CSV File","0baeccfc":"Now I need to get the contents of the mail only as it is needed the most.I tried finidng ways to get the contents of the mail but at the end in the email library there is a  function for geting the contents of the mail and I found it as get_content()","62b5cc0e":"## **Multinomial Naive Bayes with TfidfVectorizer**","8723c775":"## Testing the model with Sample Inputs","76887bb8":"## **Guassian Naive Bayes with TfidfVectorizer**","4b63892b":"Getting each information of the mail like \n* Subject\n* From\n* To \n\nThis is possible by means of function called get_all() from the email library.If one gives get_all('To') it would return the value of 'To:' as a list as an output","8d90b684":"## **LinearSVC(C=1000) with TfidfVectorizer**","f13b5d01":"All the accuracies are good and we cannot choose the model only based on the accuracy.Thus the heatmap helps us to choose the model wisely.For RandomForrest with Countvectorizer even though the accuracy is 84% its accuarcy is bad when finding the Spam mail.From the heatmap it is seen that it predicts only 14% of the spam mail correctly.Similarly Gaussian NB with Countvectorizer also predicts only 78% of the spam mails correctly.Between SVC with Countvectorizer and Multinomial Naive Bayes with Countvectorizer need to choose one.I have chosen Multinomial Naive Bayes with Countvectorizer as of now.But seeing the heatmaps also the Multinominal Naive Bayes with the CountVectorizer performs well thus I take Multinominal Naive Bayes as a classifer and Countvectorizer as my Vectorizer","c80c341e":"**Just For displaying purpouse**","02178b41":"## **SVC with Countvectorizer**","c562f5dd":"## Model Selection","228ded37":"## **Guassian Naive Bayes with Countvectorizer**","bffb05db":"Experimentation with the data has been don now need to implement the same with the data in the input dataset","b1ae9310":"**1.Reading the Filenames of Ham folder and Spam Folder and storing in a variable**","d494b06d":"## **RandomForrest with Countvectorizer**","f882997c":"## **RandomForrest with TfidfVectorizer**","648b8158":"## Removing the Escape sequences in the cleaned data","1c61a829":"# Getting the file from all the paths of respective mails","bf94d9ec":"## GUI Building using Pickle and Streamlit","6dd18750":"# Refrences\n1.[For OS filename reading](https:\/\/stackoverflow.com\/questions\/3207219\/how-do-i-list-all-files-of-a-directory)\n\n2.[Parsing an email](https:\/\/docs.python.org\/3\/library\/email.parser.html)","4a5541cc":"Removal of HTML tags needs to be done in emails as it would be tough to vectorize the words.","68d739e1":"# OverFitting Experiment","25156f7f":"## **Multinomial Naive Bayes with Countvectorizer**","0afa9d0c":"**Getting Different parts of the email found above**","628ef899":"**2.Opening a file using the file names extracted from the above code and analyzing how the data in a file is**","59df323e":"**Final Model**"}}