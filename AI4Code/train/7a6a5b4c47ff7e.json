{"cell_type":{"2a2d3dd0":"code","6d2041f7":"code","ed2f5208":"code","7012bd77":"code","a233e397":"code","1590ed19":"code","b0ff5b87":"code","a82ade72":"code","2420da29":"code","0c1b55ec":"code","d1d41e61":"code","99bd8da1":"code","94f3e748":"code","9503da89":"code","8c4effeb":"code","fe4df0fe":"code","4bc7abc8":"code","b0699dce":"code","f94d9aa1":"code","e4be694f":"markdown","0942a57c":"markdown","e7367bfb":"markdown","be0045b0":"markdown","d3c4991b":"markdown"},"source":{"2a2d3dd0":"import numpy as np\nfrom itertools import product\n\n\n# By Kaggle Course Contributor For Computer Vision.\ndef show_kernel(kernel, label=True, digits=None, text_size=28):\n    # Format kernel\n    kernel = np.array(kernel)\n    if digits is not None:\n        kernel = kernel.round(digits)\n\n    # Plot kernel\n    cmap = plt.get_cmap('Blues_r')\n    plt.imshow(kernel, cmap=cmap)\n    plt.title(\"Filter\")\n    rows, cols = kernel.shape\n    thresh = (kernel.max()+kernel.min())\/2\n    # Optionally, add value labels\n    if label:\n        for i, j in product(range(rows), range(cols)):\n            val = kernel[i, j]\n            color = cmap(0) if val > thresh else cmap(255)\n            plt.text(j, i, val, \n                     color=color, size=text_size,\n                     horizontalalignment='center', verticalalignment='center')\n    plt.xticks([])\n    plt.yticks([])","6d2041f7":"from keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nimport tensorflow as tf","ed2f5208":"# Let's have a look at an image of one of the classes.\n\nimport matplotlib.pyplot as plt\nplt.rc('figure',autolayout=True)\nplt.rc('axes' , labelweight='bold' , labelsize='large' , \n       titleweight='bold',titlesize=18,titlepad=10)\nplt.rc('image',cmap='magma')\n\n\nimage_path = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train\/cars\/cars203.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\nplt.figure(figsize=(5, 5))\nplt.imshow(tf.squeeze(image),cmap='gray')\nplt.axis('off')\nplt.show()","7012bd77":"kernel = tf.constant([\n    [-1, -1, -1],\n    [-1,  8, -1],\n    [-1, -1, -1],\n])\n\n\nplt.figure(figsize=(3,3))\nshow_kernel(kernel)                                           #Code For show_kernel contributed by Kaggle Course Creator.","a233e397":"image = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\nkernel = tf.cast(kernel, dtype=tf.float32)\n\nimage_filter = tf.nn.conv2d(\n    input=image,\n    filters=kernel,\n    strides=1,\n    padding='SAME'\n)\n\nplt.figure(figsize=(5, 5))\nplt.imshow(tf.squeeze(image_filter))\nplt.axis('off')\nplt.show()","1590ed19":"# You can also impport kernels from computer_vision tools\n\nimport learntools.computer_vision.visiontools as visiontools\nfrom learntools.computer_vision.visiontools import edge, bottom_sobel, emboss, sharpen\n\nkernels = [edge, bottom_sobel, emboss, sharpen]\nnames = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n\nplt.figure(figsize=(12, 12))\nfor i, (kernel, name) in enumerate(zip(kernels, names)):\n    plt.subplot(1, 4, i+1)\n    visiontools.show_kernel(kernel)\n    plt.title(name)\nplt.tight_layout()","b0ff5b87":"images = []\nfor i in range(len(kernels)):\n    k1 = kernels[i]\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.expand_dims(image, axis=0)\n    k1 = tf.reshape(k1, [*k1.shape, 1, 1])\n    k1 = tf.cast(k1, dtype=tf.float32)\n    image_filter = tf.nn.conv2d(\n        input=image,\n        filters=k1,\n        strides=1,\n        padding='SAME'\n    )\n    images.append(tf.squeeze(image_filter))","a82ade72":"plt.figure(figsize=(15, 15))\nfor i, (image, name) in enumerate(zip(images, names)):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\n    plt.title(name)","2420da29":"relu_images = []\nfor i in range(len(kernels)):\n    k1 = kernels[i]\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.expand_dims(image, axis=0)\n    k1 = tf.reshape(k1, [*k1.shape, 1, 1])\n    k1 = tf.cast(k1, dtype=tf.float32)\n    image_filter = tf.nn.conv2d(\n        input=image,\n        filters=k1,\n        strides=1,\n        padding='SAME'\n    )\n    relu_fn = tf.nn.relu\n    image_detect = relu_fn(image_filter)\n    relu_images.append(tf.squeeze(image_detect))\n    \nplt.figure(figsize=(15, 15))\nfor i, (image, name) in enumerate(zip(relu_images, names)):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(relu_images[i])\n    plt.axis('off')\n    plt.title(name)","0c1b55ec":"kernel = kernels[0]  #Edge Detect\n\n\nimage_path = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train\/cars\/cars203.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\nimage = tf.image.convert_image_dtype(image , dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape,1,1])\nkernel = tf.cast(kernel,dtype = tf.float32)\n\nimage_filter = tf.nn.conv2d(\n    input = image,\n    filters = kernel,\n    strides = 1,\n    padding = \"VALID\"\n)\n\nimage_detect = tf.nn.relu(image_filter)\n\nimage_condense = tf.nn.pool(\n    input = image_detect,\n    window_shape = (2,2),\n    pooling_type = \"MAX\",\n    strides = (2,2),\n    padding = \"SAME\"\n)\n\nplt.figure(figsize=(12,7))\nplt.subplot(151)\nplt.imshow(tf.squeeze(image),cmap='gray')\nplt.axis(\"off\")\nplt.title(\"Input\")\n\nkernel = kernels[0]\nplt.subplot(1,5,2)\nvisiontools.show_kernel(kernel)\nplt.axis(\"off\")\nplt.title(\"Edge Detect\")\n\nplt.subplot(153)\nplt.imshow(tf.squeeze(image_filter))\nplt.axis(\"off\")\nplt.title(\"Filtered\")\n\nplt.subplot(154)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis(\"off\")\nplt.title(\"Detect\")\n\nplt.subplot(155)\nplt.imshow(tf.squeeze(image_condense))\nplt.axis(\"off\")\nplt.title(\"Pooling\")\nplt.show();\n\n","d1d41e61":"kernel = kernels[2]  #Emboss\n\n\nimage_path = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train\/cars\/cars203.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\nimage = tf.image.convert_image_dtype(image , dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape,1,1])\nkernel = tf.cast(kernel,dtype = tf.float32)\n\nimage_filter = tf.nn.conv2d(\n    input = image,\n    filters = kernel,\n    strides = 1,\n    padding = \"VALID\"\n)\n\nimage_detect = tf.nn.relu(image_filter)\n\nimage_condense = tf.nn.pool(\n    input = image_detect,\n    window_shape = (2,2),\n    pooling_type = \"MAX\",\n    strides = (2,2),\n    padding = \"SAME\"\n)\n\nplt.figure(figsize=(12,7))\nplt.subplot(151)\nplt.imshow(tf.squeeze(image),cmap='gray')\nplt.axis(\"off\")\nplt.title(\"Input\")\n\nkernel = kernels[2]\nplt.subplot(1,5,2)\nvisiontools.show_kernel(kernel)\nplt.axis(\"off\")\nplt.title(\"Emboss\")\n\nplt.subplot(153)\nplt.imshow(tf.squeeze(image_filter))\nplt.axis(\"off\")\nplt.title(\"Filtered\")\n\nplt.subplot(154)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis(\"off\")\nplt.title(\"Detect\")\n\nplt.subplot(155)\nplt.imshow(tf.squeeze(image_condense))\nplt.axis(\"off\")\nplt.title(\"Pooling\")\nplt.show();\n\n","99bd8da1":"import tensorflow as tf\nfrom keras.preprocessing import image_dataset_from_directory\n\ndata_train = image_dataset_from_directory(\n    '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train',\n    labels = \"inferred\",\n    label_mode = \"categorical\",\n    image_size = [128 , 128],\n    interpolation = 'nearest',\n    batch_size = 64,\n    shuffle = True\n)\n\ndata_valid = image_dataset_from_directory(\n    '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/test',\n    labels = \"inferred\",\n    label_mode = \"categorical\",\n    image_size = [128 , 128],\n    interpolation = 'nearest',\n    batch_size = 64,\n    shuffle = False\n)\n\ndef convert_to_float(image , label):\n    image = tf.image.convert_image_dtype(image,dtype=tf.float32)\n    return image,label\n    ","94f3e748":"from keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense","9503da89":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,        \n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255\n)\n\ntrain_set = train_datagen.flow_from_directory(\n    '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train',\n    target_size = (128,128),\n    batch_size = 32,\n    class_mode = \"categorical\"\n    \n\n)\n\ntest_set = test_datagen.flow_from_directory(\n    '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/test',\n    target_size = (128,128),\n    batch_size = 32,\n    class_mode = \"categorical\"\n    \n\n)","8c4effeb":"import keras.layers.experimental.preprocessing as preprocessing\nimport tensorflow as tf\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=32 , kernel_size=5 ,input_shape=[128,128,3] ,activation=\"relu\" ,padding=\"SAME\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(filters=64 , kernel_size=3 ,activation=\"relu\" ,padding=\"SAME\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(filters=128 , kernel_size=3 ,activation=\"relu\" ,padding=\"SAME\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(units=6 , activation=\"relu\"))\nmodel.add(Dense(units=3 , activation=\"softmax\"))\n\nmodel.summary()","fe4df0fe":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy'],\n)\n\nhistory = model.fit(\n    train_set,\n    validation_data = test_set,\n    epochs = 30\n)","4bc7abc8":"model.save('Scratch1.h5')","b0699dce":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:,['loss','val_loss']].plot()\nhistory_frame.loc[:,['accuracy','val_accuracy']].plot()\n","f94d9aa1":"from tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimg = image.load_img('..\/input\/multiclassimagedatasetairplanecar\/Dataset\/test\/cars\/cars1.jpg' , target_size=(128,128))\nplt.imshow(img)\nplt.axis('off')\nplt.plot()\nimg = np.reshape(img,[1,128,128,3])\nimg_f = tf.cast(img,tf.float32)\ncl = model.predict(img_f)\nprint(cl)\ncl = (cl>0.5).astype(\"int32\")\nif cl[0][0]>0.5:\n    print(\"AIRPLANE\")\nelif cl[0][1]>0.5:\n    print(\"CAR\")\nelse:\n    print(\"SHIP\")\nprint(cl)\n","e4be694f":"## 1.Detailed CNN","0942a57c":"# 2.Building A Model","e7367bfb":"*** > NOTE : the sum of the numbers in the kernel determines how bright the final image is**","be0045b0":"## **CONVOLUTION AND RELU(Detecting Features)**","d3c4991b":"## MAX-POOLING | Full Process"}}