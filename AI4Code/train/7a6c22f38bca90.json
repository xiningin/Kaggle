{"cell_type":{"969fbba1":"code","15b6f348":"code","8bce1a9b":"code","f03cbcf6":"code","d8181a31":"code","3d12dbc6":"code","eebe0c2f":"code","d87789f0":"code","833f90cd":"code","d377ef7d":"code","32be1ac1":"code","12eb7bba":"code","463c861c":"code","05852e18":"markdown","ae966de6":"markdown"},"source":{"969fbba1":"import numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns","15b6f348":"# Read to train dataset.\ntrain = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain.head()","8bce1a9b":"test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntest = test.drop(labels=['label'],axis=1) # I drop label column\ntest.head()","f03cbcf6":"# Y_train and X_train seperate\nY_train = train['label']\nX_train = train.drop(labels=['label'],axis=1)","d8181a31":"# Visualize Labels count\nplt.figure(figsize=(15,7))\ng = sns.countplot(Y_train, palette=\"RdBu\")\nplt.title(\"Number Of Labels\")\nY_train.value_counts()","3d12dbc6":"# Plot some samples\nplt.subplot(2,2,1)\nimg = X_train.iloc[0].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img)\nplt.title('Samples 1')\nplt.axis('off')\n# -----------------------\nplt.subplot(2,2,2)\nimg1 = X_train.iloc[8].to_numpy()\nimg1 = img1.reshape((28,28))\nplt.imshow(img1)\nplt.title('Sample 2')\nplt.axis('off')\n# -----------------------\nplt.subplot(2,2,3)\nimg2 = X_train.iloc[12].to_numpy()\nimg2 = img2.reshape((28,28))\nplt.imshow(img2)\nplt.title('Sample 3')\nplt.axis('off')\n# -----------------------\nplt.subplot(2,2,4)\nimg3 = X_train.iloc[67].to_numpy()\nimg3 = img3.reshape((28,28))\nplt.imshow(img3)\nplt.title('Sample 4')\nplt.axis('off')\nplt.show()","eebe0c2f":"# Normalization\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n#----------------------------------\nprint('X_train SHAPE:',X_train.shape)\nprint('Test SHAPE:',test.shape)","d87789f0":"from keras.utils.np_utils import to_categorical\nY_train = to_categorical(Y_train,num_classes=10)","833f90cd":"# Seperate train and val.\nfrom sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.1,random_state=42)\n# - - - - - - - - - - - - - - - - - - - - -\nprint('x_train SHAPE:',x_train.shape)\nprint('x_val SHAPE:',x_val.shape)\nprint('y_train SHAPE:',y_train.shape)\nprint('y_val SHAPE:',y_val.shape)","d377ef7d":"# Dics for CNN\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","32be1ac1":"# Create Model\nmodel = Sequential()\nmodel.add(Conv2D(filters=8,kernel_size=(7,7),padding='same',activation='relu',input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters=16,kernel_size=(5,5),padding='same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters=64,kernel_size=(2,2),padding='same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Fully Connection\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation='softmax'))\n\n# Optimizer\noptimizer = Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\nepochs = 10\nbatch_size = 250\n\n# Datagen\ndatagen = ImageDataGenerator(featurewise_center=False,\n                            samplewise_center=False,\n                            featurewise_std_normalization=False,\n                            samplewise_std_normalization=False,\n                            zca_whitening=False,\n                            rotation_range=0.5,\n                            zoom_range=0.5,\n                            width_shift_range=0.5,\n                            height_shift_range=0.5,\n                            horizontal_flip=False,\n                            vertical_flip=False)\ndatagen.fit(x_train)\n\n# Fit model\nhistory = model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                             epochs=epochs,validation_data=(x_val,y_val),steps_per_epoch=x_train.shape[0]\/\/batch_size)","12eb7bba":"# Loss Graph\nplt.plot(history.history['val_loss'], color='Lime', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","463c861c":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\ny_pred = model.predict(x_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Reds\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","05852e18":"# Convolutional Neural Network\n\nConvolutional neural networks are a sub-branch of deep learning and are often used in analyzing visual information.\n\n\n![](https:\/\/miro.medium.com\/max\/3288\/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)\n\n\n\n### *We will do all the steps shown one by one*","ae966de6":"# AND DONE, THANKS FOR READING"}}