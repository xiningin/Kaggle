{"cell_type":{"ebffb813":"code","5ecd753e":"code","5c0ec958":"code","6412652a":"code","6aa6bb0b":"code","2fd5d474":"code","1f15536d":"code","ff5b744c":"code","fa2f18a6":"code","54345af9":"code","d717920a":"code","64fba3ac":"code","e107ac48":"code","ddab1eac":"code","6e97e55c":"code","d912e903":"code","7b34d421":"code","f647fe61":"code","fe72bb89":"code","0474be7d":"code","b661f5b5":"code","4fb16200":"code","4e4199e6":"code","6fb1e075":"code","a7885ae1":"code","59f52c2a":"code","87cc7e05":"code","a7f70c5b":"code","94f7f0fd":"markdown","e968fc60":"markdown","3cfad9bc":"markdown","726b373b":"markdown","2f87e3a0":"markdown","cabf37ea":"markdown","14ff7d35":"markdown","52ef6ae2":"markdown","d82b529c":"markdown","662c4825":"markdown","16a677a2":"markdown","6eca269a":"markdown","41e958e2":"markdown","d10e9bbc":"markdown","d1711d62":"markdown","702648ea":"markdown"},"source":{"ebffb813":"from collections import Counter\nfrom pathlib import Path\n\nfrom tqdm import tqdm\nfrom PIL import Image\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision import transforms as T\nfrom torchvision.utils import make_grid\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.neighbors import NearestNeighbors\n\n\n%matplotlib inline","5ecd753e":"def show_cluster(cluster, labels, dataset, limit=32):\n    images = []\n    labels = np.array(labels)\n    indices = np.where(labels==cluster)[0]\n    \n    if not indices.size:\n        print(f'cluster: {cluster} is empty.')\n        return None\n    \n    for i in indices[:limit]:\n        image, _ = dataset[i]\n        images.append(image)\n        \n    gridded = make_grid(images)\n    plt.figure(figsize=(15, 10))\n    plt.title(f'cluster: {cluster}')\n    plt.imshow(gridded.permute(1, 2, 0))\n    plt.axis('off')\n    \n    \ndef show_neighbors(neighbors, dataset):\n    images = []\n    for n in neighbors:\n        images.append(dataset[n][0])\n\n    gridded = make_grid(images)\n    plt.figure(figsize=(15, 10))\n    plt.title(f'image and nearest neighbors')\n    plt.imshow(gridded.permute(1, 2, 0))\n    \n    \ndef extract_features(model, dataset, batch_size=32):\n    \"\"\"\n    Gets the output of a pytorch model given a dataset.\n    \"\"\"\n    loader = DataLoader(dataset, batch_size=batch_size)\n    features = []\n    for image, _ in tqdm(loader, desc='extracting features'):\n        output = model(Variable(image).cuda())\n        features.append(output.data.cpu())\n    return torch.cat(features).numpy() ","5c0ec958":"class FoodDataset(Dataset):\n    def __init__(self, root, transforms=None, labels=[], limit=None):\n        self.root = Path(root)\n        self.image_paths = list(Path(root).glob('*\/*.jpg'))\n        if limit:\n            self.image_paths = self.image_paths[:limit]\n        self.labels = labels\n        self.transforms = transforms\n        self.classes = set([path.parts[-2] for path in self.image_paths])\n        \n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        label = self.labels[index] if self.labels else 0\n        image = Image.open(image_path)\n        if self.transforms:\n            return self.transforms(image), label\n        return image, label\n            \n    def __len__(self):\n        return len(self.image_paths)    \n    \ntransforms = T.Compose([T.Resize(224),\n                        T.CenterCrop(224),\n                        T.ToTensor()])","6412652a":"# data\nroot = '..\/input\/images'\nlimit_images = 10000\n\n# clustering\npca_dim = 50\nkmeans_clusters = 100\n\n# convnet\nbatch_size = 64\nnum_classes = 100\nnum_epochs = 2\n","6aa6bb0b":"dataset = FoodDataset(root=root, limit=limit_images)","2fd5d474":"dataset.classes","1f15536d":"image, _ = dataset[9000]\nimage","ff5b744c":"# load resnet and alter last layer\nmodel = resnet18()\nmodel.fc = nn.Linear(512, num_classes)\nmodel.cuda();\n\npca = IncrementalPCA(n_components=pca_dim, batch_size=512, whiten=True)\nkmeans = MiniBatchKMeans(n_clusters=kmeans_clusters, batch_size=512, init_size=3*kmeans_clusters)\noptimizer = Adam(model.parameters())","fa2f18a6":"def cluster(pca, kmeans, model, dataset, batch_size, return_features=False):\n    features = extract_features(model, dataset, batch_size)  \n    reduced = pca.fit_transform(features)\n    pseudo_labels = list(kmeans.fit_predict(reduced))\n    if return_features:\n        return pseudo_labels, features\n    return pseudo_labels","54345af9":"def train_epoch(model, optimizer, train_dataset, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    total_loss = 0\n    pbar = tqdm(train_loader)\n    for batch, (images, labels) in enumerate(pbar):\n        optimizer.zero_grad()\n        images = Variable(images).cuda()\n        labels = Variable(labels).cuda().long()\n        out = model(images)\n        loss = F.cross_entropy(out, labels)\n        total_loss += loss.data[0]\n        pbar.set_description(f'training - loss: {total_loss \/ (batch + 1)}')\n        loss.backward()\n        optimizer.step()","d717920a":"raw_dataset = FoodDataset(root=root, transforms=transforms, limit=limit_images)\npseudo_labels, features = cluster(pca, kmeans, model, raw_dataset, batch_size, return_features=True)","64fba3ac":"plt.hist(pseudo_labels, bins=kmeans_clusters)\nplt.title('cluster membership counts');","e107ac48":"raw_dataset.classes ## all food types we have sampled","ddab1eac":"counts = Counter(pseudo_labels)\nshow_cluster(counts.most_common()[0][0], pseudo_labels, raw_dataset)","6e97e55c":"show_cluster(counts.most_common()[1][0], pseudo_labels, raw_dataset)","d912e903":"knn = NearestNeighbors(metric='cosine')\nknn.fit(features)","7b34d421":"anchor_image = 0\nneighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\nshow_neighbors(neighbors, raw_dataset)","f647fe61":"for i in range(num_epochs):\n    pseudo_labels = cluster(pca, kmeans, model, raw_dataset, batch_size) # generate labels\n    labeled_dataset = FoodDataset(root=root, labels=pseudo_labels, transforms=transforms, limit=limit_images) # make new dataset with labels matched to images\n    train_epoch(model, optimizer, labeled_dataset, batch_size) # train for one epoch","fe72bb89":"pseudo_labels, features = cluster(pca, kmeans, model, raw_dataset, batch_size, return_features=True)\n","0474be7d":"plt.hist(pseudo_labels, bins=kmeans_clusters)\nplt.title('cluster membership counts');","b661f5b5":"counts = Counter(pseudo_labels)","4fb16200":"show_cluster(counts.most_common()[0][0], pseudo_labels, raw_dataset)","4e4199e6":"show_cluster(counts.most_common()[1][0], pseudo_labels, raw_dataset)","6fb1e075":"knn = NearestNeighbors(metric='cosine')\nknn.fit(features)","a7885ae1":"anchor_image = 0\nneighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\nshow_neighbors(neighbors, raw_dataset)","59f52c2a":"for i in range(4):\n    pseudo_labels = cluster(pca, kmeans, model, raw_dataset, batch_size) # generate labels\n    labeled_dataset = FoodDataset(root=root, labels=pseudo_labels, transforms=transforms, limit=limit_images) # make new dataset with labels matched to images\n    train_epoch(model, optimizer, labeled_dataset, batch_size) # train for one epoch","87cc7e05":"features = extract_features(model, raw_dataset, batch_size)  \nknn = NearestNeighbors(metric='cosine')\nknn.fit(features)","a7f70c5b":"anchor_image = 0\nneighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\nshow_neighbors(neighbors, raw_dataset)","94f7f0fd":"## Data\nFood Dataset, 101 different foods, 1000 samples each.\n\nWe will use then first 10 classes to test this method.","e968fc60":"## Train some more","3cfad9bc":"## Models","726b373b":"## Check how images are clustered with random convnet","2f87e3a0":"## Config","cabf37ea":"## Training loop","14ff7d35":"## Utils","52ef6ae2":"### largest clusters","d82b529c":"### Cluster distributions","662c4825":"## Check new clusters","16a677a2":"# Deep Clustering for Unsupervised Learning 0f Visual Features\nhttps:\/\/arxiv.org\/pdf\/1807.05520.pdf","6eca269a":"## Image retrieval","41e958e2":"## image retrieval on with random model","d10e9bbc":"## Dataset and transforms","d1711d62":"# clustering loop","702648ea":"## Full Cycle"}}