{"cell_type":{"1d8e0312":"code","9a734304":"code","b81175ba":"code","89fd5615":"code","dabafcfa":"code","65c36dfd":"code","4f6944ed":"code","90575ad5":"code","8219d3b3":"code","abab160d":"code","81bda67a":"code","58659261":"code","1bcca4ac":"code","21c86763":"code","b92457ca":"code","97739f9a":"code","025180e9":"markdown","5bf99d2d":"markdown","f89f3edf":"markdown","e1115071":"markdown","5693097e":"markdown","88724e4b":"markdown","71878528":"markdown","3c81593c":"markdown","0245f973":"markdown","3c00d2e2":"markdown"},"source":{"1d8e0312":"!pip install -q efficientnet","9a734304":"from efficientnet.tfkeras import EfficientNetB3\nfrom efficientnet.tfkeras import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom matplotlib import pyplot\nfrom numpy import expand_dims\nimport tensorflow as tf\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter\n\nimport cv2\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec","b81175ba":"np.random.seed(0)\ntf.random.set_seed(0)","89fd5615":"model = EfficientNetB3(include_top=False, weights=\"imagenet\")","dabafcfa":"len(model.layers)","65c36dfd":"# we will take outputs of last 3 blocks\noutputs = [model.get_layer(\"block5e_add\").output,\n           model.get_layer(\"block6f_add\").output,\n           model.get_layer(\"block7b_add\").output]\n\nmodel = Model(inputs=model.inputs, outputs=outputs)","4f6944ed":"names = [\"Flamingo\", \"Barn Owl\",\n         \"Vincent van Gogh - Wheat Field with Cypresses\",\n         \"Vincent van Gogh - The White Orchard\"]\npaths = [\"\/kaggle\/input\/100-bird-species\/consolidated\/FLAMINGO\/012.jpg\",         \n         \"\/kaggle\/input\/100-bird-species\/consolidated\/BARN OWL\/029.jpg\",\n         \"\/kaggle\/input\/best-artworks-of-all-time\/images\/images\/\"\n           \"Vincent_van_Gogh\/Vincent_van_Gogh_109.jpg\",\n         \"\/kaggle\/input\/best-artworks-of-all-time\/images\/images\/\"\n           \"Vincent_van_Gogh\/Vincent_van_Gogh_132.jpg\"]\n\ndef read_images(path):\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = image[...,::-1]\n    return image\n    \ndef plot_images(images):\n    fig = plt.figure(constrained_layout = True, figsize=(10, 10))\n    gs = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)\n    for i in range(4):\n        y, x = i\/\/2, i%2 \n        ax = fig.add_subplot(gs[y,x]) \n        ax.imshow(np.uint8(images[i]))\n        ax.axis(\"off\")\n        ax.title.set_text(names[i])","90575ad5":"images = []\nfor path in paths:\n    images.append(read_images(path))\nplot_images(images)","8219d3b3":"learning_rate = 0.01\niterations = 150\ndef gradient_ascent(image, block_id):  \n    image = tf.expand_dims(image, axis=0)\n    for d in range(iterations):\n        with tf.GradientTape() as tape:\n            tape.watch(image)\n            # get block activation maps\n            maps = model(image)  \n            strength = tf.reduce_mean(tf.abs(maps[block_id]))\n\n        # get gradients stored in tape\n        gradients = tape.gradient(strength, image)\n\n        # normalize gradients\n        gradients \/= (tf.math.reduce_std(gradients) + 1e-10)\n\n        # modify input image\n        image += learning_rate * gradients\n\n    return image[0]","abab160d":"def deprocess(image):\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    \n    image[..., 0] *= std[0]\n    image[..., 1] *= std[1]\n    image[..., 2] *= std[2]\n    \n    image[..., 0] += mean[0]\n    image[..., 1] += mean[1]\n    image[..., 2] += mean[2]\n       \n    image *= 255.0\n    image = np.clip(image, 0, 255) \n\n    return image","81bda67a":"img_size = tf.convert_to_tensor([(140, 140), (170, 170), (205, 205),\n                     (245, 245), (300, 300), (355, 355), (425, 425),\n                     (512, 512), (614, 614), (740, 740)])\n\ndef deepdream(image_in):\n    results = []\n    for block_id in range(len(outputs)):\n        image = preprocess_input(image_in)\n        image = tf.convert_to_tensor(image)\n        for s in img_size:\n            image = tf.image.resize(image, s) \n            image = gradient_ascent(image, block_id)\n            \n        results.append(deprocess(image.numpy()))\n    return results","58659261":"titles = [\"Original Image\",\n          \"After maximizing the output of Block 5\",\n          \"After maximizing the output of Block 6\",\n          \"After maximizing the output of Block 7\"]\n\ndef plot_results(image, results):\n    image = cv2.resize(image, (448, 448), interpolation = cv2.INTER_CUBIC)\n    fig = plt.figure(constrained_layout = True, figsize=(9, 32))\n    gs = gridspec.GridSpec(nrows=4, ncols=1, figure=fig, height_ratios = [1,2,2,2])\n    for i in range(4):\n        y, x = i\/\/1, i%1 \n        ax = fig.add_subplot(gs[y,x])\n        if i > 0:\n            image = results[i-1]\n        ax.imshow(np.uint8(image))\n        ax.axis(\"off\")\n        ax.title.set_text(titles[i])","1bcca4ac":"results = deepdream(images[0])\nplot_results(images[0], results)","21c86763":"results = deepdream(images[1])\nplot_results(images[1], results)","b92457ca":"results = deepdream(images[2])\nplot_results(images[2], results)","97739f9a":"results = deepdream(images[3])\nplot_results(images[3], results)","025180e9":"![b3_blocks_2.png](attachment:b3_blocks_2.png)","5bf99d2d":"## Go with Gradient\n\nWhen creating DeepDream images, the idea is to modify input image so as to maximize the activation of a specific feature map or maps. It's like asking the neural network what it wants to see as input. Neural network itself guides the input modification process.\n\nWhile training neural networks, we aim to decrease loss and use gradient descent for this purpose. To maximize an activation, we use gradient ascent. \n\nThe gradient of the activation with respect to input image is computed. Then we go along the gradient direction with a stepsize of learning_rate. This way, input image is modified iteratively. To handle this, we define gradient_ascent function below.","f89f3edf":"Gradient ascent is applied to input image at different resolutions sequentially.","e1115071":"After modifying input image, it needs to be deprocessed. When inputting an image into a neural network, image is preprocessed. This stage changes from model to model. In deprocessing, the steps of preprocessing are reversed.\n\nefficientnet.tfkeras library uses preprocess_input function from keras.applications.imagenet_utils with mode=\"torch\".","5693097e":"## Load Model\n\nEfficientNetB3 block diagram is shown below. After input and stem layers, there are 7 blocks which are shown as gray boxes. Start and end layers of each block are shown. Dashed arrows inside boxes indicate that there are some layers not shown between start and end layers of each block.  ","88724e4b":"We load EfficientNetB3 excluding top with imagenet weights. avg_poll, top_dropout and probs layers are excluded.","71878528":"## Load Input Images","3c81593c":"## Get Outputs\n\nWe create another model in order to get the outputs of blocks 5, 6 and 7. ","0245f973":"In this kernel, we will use **EfficientNetB3** to produce **DeepDream** images. We will use **225 Bird Species** and **Best Artworks of All Time** datasets.","3c00d2e2":"Without top layers, it has\n\n* Total params: 10,783,528\n* Trainable params: 10,696,232\n* Non-trainable params: 87,296\n\nLet's look at number of layers."}}