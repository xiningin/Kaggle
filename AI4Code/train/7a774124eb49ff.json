{"cell_type":{"14fe5cda":"code","ebd8951a":"code","f1c0aec7":"code","677699ee":"code","cf959a34":"code","84423684":"code","f70e5633":"code","165d95b3":"code","30410fca":"code","d8a13e4e":"code","6139a27c":"code","16d1a886":"code","68a7a8fc":"code","8c5da8e8":"code","79248a91":"code","d44da696":"code","b9181120":"code","a683eb7a":"code","63f80ebd":"code","903c4bc5":"code","1c4a5fea":"code","aa0836fa":"code","fbb2d8bc":"code","8e9adbdf":"code","b1c6795b":"code","ce56df87":"code","e75166fd":"code","6a37a1ab":"code","5a4fef74":"code","154ac245":"code","210a69e0":"code","fe1a212c":"code","eb4e7469":"code","8e5dfa9e":"code","5a86d7c7":"code","5f018c09":"code","3e6c6e2a":"code","2b5e56d6":"code","7919d0d3":"code","5e97529f":"code","95fe9e62":"code","09de048c":"code","29133a72":"code","a1fb6a02":"code","4b4ad2c2":"code","0a29d08e":"code","a5f69348":"code","bd800ca0":"code","744ef9ff":"code","100838ec":"code","72b0a70e":"code","5fb316cd":"code","944e8a35":"code","a3559e9a":"code","7c8a712e":"code","5e43d669":"code","f80661a9":"code","84af0573":"code","16580cd4":"code","5c9993b0":"code","18566bc3":"code","5bae5030":"code","4c4015a1":"code","548d9141":"code","f9973293":"markdown","a7d04789":"markdown","fc16829f":"markdown","68723580":"markdown","eb4ba695":"markdown","6d1eb650":"markdown","09229310":"markdown","8aa2e18a":"markdown","19b13fe8":"markdown","a6b4266f":"markdown","8121a2ad":"markdown","116a02f9":"markdown","5c9da801":"markdown","28666f0d":"markdown","b397df8e":"markdown","d7883b3f":"markdown","29e37d33":"markdown","821f6538":"markdown","e24ecf54":"markdown","51f0a347":"markdown","658808fa":"markdown","e8e43ee9":"markdown","8647497c":"markdown","450c4c50":"markdown","f9cbbd41":"markdown","3021af84":"markdown","6da3195a":"markdown"},"source":{"14fe5cda":"import numpy as np # Linear Algebra\nimport pandas as pd # Data Processing\nimport matplotlib.pyplot as plt # Visualisation\nimport seaborn as sns # Statistical Data Visualisation\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ebd8951a":"# Importing the training dataset\n\ndf_train = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/train_SJC.csv\",header=1)","f1c0aec7":"# Renaming a few columns\n\ndf_train = df_train.rename(columns={'Unnamed: 2': 'DateReported', \n                                    'Unnamed: 7': 'DependentsOther', \n                                    'Unnamed: 11': 'DaysWorkedPerWeek'})\n\ndf_train.head() # returns the first few rows of the dataframe","677699ee":"df_train.shape # total number of rows and columns ","cf959a34":"# Importing the testing dataset\n\ndf_test = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv\")\n\ndf_test.head() # returns the first few rows of the dataframe","84423684":"df_test.shape # total number of rows and columns ","f70e5633":"df_sample = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")","165d95b3":"# DataFrame Summary\n\ndf_train.info()","30410fca":"# Data Summary\n\ndf_train.describe().T","d8a13e4e":"# Checking for missing values\n\ndf_train.isnull().sum()","6139a27c":"df_test.isnull().sum()","16d1a886":"# Replacing all the missing values in Marital status with 'U': Unknown\n\ndf_train['MaritalStatus'] = df_train['MaritalStatus'].fillna('U')\ndf_test['MaritalStatus'] = df_test['MaritalStatus'].fillna('U')","68a7a8fc":"df_train['WeeklyWages'].describe()","8c5da8e8":"df_train['HoursWorkedPerWeek'].describe()","79248a91":"# WeeklyWages and HoursWorkedPerWeek are highly skewed with values ranging between (Rs 1, Rs 7497) and (0 hrs,640 hrs).\n\n# If there are several outliers in a distribution it will often result in skewed shape of the distribution.\n\n# Hence we replace missing values in 'WeeklyWages' and 'HoursWorkedPerWeek' columns with median instead of mean.\n\ndf_train['WeeklyWages'] = df_train['WeeklyWages'].fillna(df_train['WeeklyWages'].median())\ndf_train['HoursWorkedPerWeek'] = df_train['HoursWorkedPerWeek'].fillna(df_train['HoursWorkedPerWeek'].median())","d44da696":"df_train.isnull().sum()","b9181120":"df_test.isnull().sum()","a683eb7a":"# Type casting : Converting the dtype of 'DateTimeofAccident' and 'Datereported' from object to datetime64\n\ndf_train['DateTimeOfAccident']=pd.to_datetime(df_train['DateTimeOfAccident'])\ndf_train['DateReported']=pd.to_datetime(df_train['DateReported'])\n\ndf_test['DateTimeOfAccident']=pd.to_datetime(df_test['DateTimeOfAccident'])\ndf_test['DateReported']=pd.to_datetime(df_test['DateReported'])","63f80ebd":"df_train.info()","903c4bc5":"df_test.info()","1c4a5fea":"# Dropping unimportant features from the train and test dataframes\n\ndf_train = df_train.drop(['ClaimNumber', 'DateTimeOfAccident', 'DateReported', 'ClaimDescription'], axis=1)\ndf_train","aa0836fa":"df_test = df_test.drop(['ClaimNumber', 'DateTimeOfAccident', 'DateReported', 'ClaimDescription'], axis=1)\ndf_test","fbb2d8bc":"df_train.columns","8e9adbdf":"# Count Plot for Gender\n\ndf_train['Gender'].replace(0,'F',inplace=True)\ndf_train['Gender'].replace(1,'M',inplace=True)\ndf_train['Gender'].replace(2,'U',inplace=True)\np1 = sns.countplot(df_train['Gender'],palette ='Set3')","b1c6795b":"# Count plot for Marital Status\n\np1 = sns.countplot(df_train['MaritalStatus'],palette ='pastel')","ce56df87":"# Boxplots and Distribution plots\n\nfeatures = { 'Age', 'DependentChildren', 'DependentsOther', 'WeeklyWages',\n             'HoursWorkedPerWeek', 'DaysWorkedPerWeek',\n             'InitialIncurredCalimsCost',\n             'UltimateIncurredClaimCost' }\n\nfor i in features:\n    ax,fig = plt.subplots(1,2,figsize=(25,5))\n    box = sns.boxplot(x=df_train[i], ax = fig[0], color='purple') # boxplot using seaborn library\n    box_title = box.set_title('Box Plot') # title for the boxplot\n    dist = sns.distplot(df_train[i], ax = fig[1], color='turquoise') # distribution plot using seaborn library\n    distplot_title = dist.set_title('Distribution plot') # title for distribution plot","e75166fd":"# Binning the ages\n\nbins = [0,20,40,60,80]\nlabels = [20,40,60,80]\ndf_train['Age'] = pd.cut(df_train['Age'],bins = bins , labels= labels, include_lowest = True).astype('int64')\nsns.distplot(df_train['Age'], color='orange')","6a37a1ab":"bins = [0,20,40,60,81]\nlabels = [20,40,60,81]\ndf_test['Age'] = pd.cut(df_test['Age'],bins = bins , labels= labels, include_lowest = True).astype('int64')","5a4fef74":"# Correlation matrix\n\nnum_df_train=df_train.select_dtypes(include=[float,int])\ncorr_matrix = num_df_train.corr()\ncorr_matrix","154ac245":"# Heatmap \n\nf, ax = plt.subplots(figsize=(30, 15))\nsns.heatmap(corr_matrix, annot=True, square=True,  cmap=\"YlGnBu\")\nplt.show()","210a69e0":"# Applying log transformation on 'InitialIncurredCalimsCost' and 'UltimateIncurredClaimCost' to transform their skewed distributions to approximately normal\n#df_train['InitialIncurredCalimsCost'] = np.log(df_train['InitialIncurredCalimsCost'])\n#df_train['UltimateIncurredClaimCost'] = np.log(df_train['UltimateIncurredClaimCost'])\n#plt.subplots(figsize=(10, 6))\n#sns.distplot(df_train.InitialIncurredCalimsCost, kde=False, label='Ultimate',bins=100, color = 'turquoise')\n#sns.distplot(df_train.InitialIncurredCalimsCost, kde=False, label='Initial', bins=100, color = 'yellow')\n#plt.xlabel('Claim costs (log)')\n#plt.legend()\n#plt.show()\n# There are some spikes in the initial incurred claim cost distribution.","fe1a212c":"#df_test['InitialIncurredCalimsCost'] = np.log(df_test['InitialIncurredCalimsCost'])","eb4e7469":"# Scatter plot\n\nplt.subplots(figsize=(10, 7))\nsns.scatterplot(data=df_train, x=\"InitialIncurredCalimsCost\",y=\"UltimateIncurredClaimCost\", color='pink')\nplt.show()","8e5dfa9e":" # Scatter plot after the log transformation\n    \nplt.subplots(figsize=(10, 7))\nsns.scatterplot(x=np.log(df_train['InitialIncurredCalimsCost']),y=np.log(df_train['UltimateIncurredClaimCost']), color='pink')\nplt.show()","5a86d7c7":"import sklearn.preprocessing as pre","5f018c09":"# Label Encoding the categorical variables\n\nle=pre.LabelEncoder()","3e6c6e2a":"df_train_list = ['Gender','MaritalStatus', 'PartTimeFullTime']","2b5e56d6":"for x in df_train[df_train_list]:\n    df_train[x]=le.fit_transform(df_train[x])\n    (df_train[x]-df_train[x].min())\/(df_train[x].max()-df_train[x])\n    le.fit(df_train[x])\n    le.transform(df_train[x])","7919d0d3":"df_train","5e97529f":"# Min-Max Scalar\n\nfor x in df_test[df_train_list]:\n    df_test[x]=le.fit_transform(df_test[x])\n    (df_test[x]-df_test[x].min())\/(df_test[x].max()-df_test[x])\n    le.fit(df_test[x])\n    le.transform(df_test[x])","95fe9e62":"df_train.info()","09de048c":"df_test.info()","29133a72":"import sklearn.model_selection as ms","a1fb6a02":"Features, outcomes = df_train.drop(['UltimateIncurredClaimCost'],axis=1),df_train['UltimateIncurredClaimCost']","4b4ad2c2":"# Train and test split\n\nx_train,x_test,y_train,y_test=ms.train_test_split(Features, outcomes, test_size=0.3,random_state=123456)","0a29d08e":"import sklearn.linear_model as lm","a5f69348":"glm = lm.LinearRegression()","bd800ca0":"# Fitting the linear regression model\n\nglm.fit(x_train,y_train)","744ef9ff":"# Test Score\n\nglm.score(x_test,y_test)","100838ec":"# Train Score\n\nglm.score(x_train,y_train)","72b0a70e":"# Predicted Value\n\ny_pred = glm.predict(x_test)","5fb316cd":"from sklearn.ensemble import RandomForestRegressor","944e8a35":"rf_model = RandomForestRegressor()\nrf_model.fit(x_train,y_train)","a3559e9a":"y_pred_rf = rf_model.predict(x_test)\ny_pred_rf","7c8a712e":"from sklearn.metrics import mean_squared_error\nimport math ","5e43d669":"# Linear Regression\nMSE = mean_squared_error(y_test, y_pred)\nMSE","f80661a9":"RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error for Linear Regression:\")\nprint(RMSE)","84af0573":"# Random Forest Regression\nMSE = mean_squared_error(y_test, y_pred_rf)\nMSE","16580cd4":"RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error for Random Forest Regressor:\")\nprint(RMSE)","5c9993b0":"Y_Pred = glm.predict(df_test)","18566bc3":"print(Y_Pred)\ndf_sample_reg = df_sample\ndf_sample_reg['UltimateIncurredClaimCost'] = Y_Pred","5bae5030":"Y_Pred.shape","4c4015a1":"df_sample_reg.to_csv(\"SampleSubmission.csv\",index=False)","548d9141":"df_sample_reg.head()","f9973293":"## Data loading","a7d04789":"### *Lower RMSE values indicate a better fit. The RMSE value for Linear Regression model is lower as compared to Random Forest Regression. Hence, we go with Linear Regression model to predict our Target Variable.*","fc16829f":"## Importing the libraries","68723580":"### *There are many outliers present in each column of the dataset which can be seen through the boxplots plotted above.* \n### *Several outliers lead to a skewed shape of the distribution which can be seen through the distribution plot plotted above.* ","eb4ba695":"### *(I) <u>Linear Regression<\/u>*","6d1eb650":"## Missing Value Treatment","09229310":"## Data Normalisation","8aa2e18a":"## Data Pre Processing","19b13fe8":"### *Majority of the workers whose claims are to be predicted are around 40 years.*","a6b4266f":"### *The Target variable 'Ultimate Incurred Claim Cost' is a continuous variable which accounts for the total claim payment by the insurance company.*\n\n### *Hence,it is a Regression problem and the models I have chosen for predicting 'Ultimate Incurred Claim Cost' is Linear Regression and Random Forest Regression.*\n\n### *Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Through linear regression we can find out the linear relationship between the target and the explanatory variables.*\n\n### *Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model.*\n\n### *Lower RMSE values indicate a better fit. The RMSE value obtained for Linear Regression model is lower as compared to Random Forest Regressor. Hence, I have chosen Linear Regression model to predict our Target Variable.*","8121a2ad":"### *There is a high correlation existing between 'InitialIncurredCalimsCost' and 'UltimateIncurredClaimCost'.*","116a02f9":"### *The above scatter plot after the log transformation can now be easily understood and interpreted. As the Initial estimate by the insurer of the claim cost increases the total claim payments to be made by the insurance company rises.*","5c9da801":"### *Though the two claim amounts are highly correlated not much can be interpreted from the above scatter plot.*\n### *Log transformation is applied on 'InitialIncurredCalimsCost' and 'UltimateIncurredClaimCost' to transform their skewed distributions to approximately normal. This makes the interpretation much easier.*","28666f0d":"### *Root Mean Squared Error (RMSE) is a metric used to evaluate a Regression Model. It tells us how accurate our predictions are and what is the amount of deviation from the actual values.*","b397df8e":"## Exploratory Data Analysis","d7883b3f":"### *Majority of the workers whose compensations are to be predicted are Single.*","29e37d33":"## Data Transformation","821f6538":"### *Every decision tree has high variance, but when we combine all of them together in parallel then the resultant variance is low as each decision tree gets perfectly trained on that particular sample data and hence the output doesn\u2019t depend on one decision tree but multiple decision trees.* \n### *Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.*","e24ecf54":"## Model Selection","51f0a347":"### *(II)<u> Random Forest Regression<\/u>*","658808fa":"# <u>Problem Statement : To predict Workers Compensation Claims<\/u>","e8e43ee9":"### *All the missing value columns have been treated*","8647497c":"## Independent\/Predictor Variables\n\n* ClaimNumber: Unique policy identifier \n* DateTimeOfAccident: Date and time of accident\n* DateReported: Date that accident was reported\n* Age: Age of worker\n* Gender: Gender of worker\n* MaritalStatus: Martial status of worker. (M)arried, (S)ingle, (U)unknown.\n* DependentChildren: The number of dependent children\n* DependentsOther: The number of dependants excluding children\n* WeeklyWages: Total weekly wage\n* PartTimeFullTime: Binary (P) or (F)\n* HoursWorkedPerWeek: Total hours worked per week\n* DaysWorkedPerWeek: Number of days worked per week\n* ClaimDescription: Free text description of the claim\n* InitialIncurredClaimCost: Initial estimate by the insurer of the claim cost\n\n## Dependent\/Target Variable\n\n* UltimateIncurredClaimCost: Total claims payments by the insurance company. ","450c4c50":"## Model Performance","f9cbbd41":"## Machine Learning Modelling Pipeline\n\n* Data Loading\n* Data Pre Processing :\n   - Data Cleaning\n   - Data Transformation\n* Exploratory Data Analysis\n* Data Normalisation\n* Model Selection\n* Model Evaluation\n","3021af84":"### *Majority of the workers whose compensations are to be predicted are male.*","6da3195a":"### *It is a machine learning algorithm based on supervised learning. It performs a regression task. Through linear regression we can find out the linear relationship between the target and the explanatory variables.*\n"}}