{"cell_type":{"8ded992e":"code","6cfa19d0":"code","6ca27cb7":"code","ac4a98d8":"code","e6159d98":"code","e012f73d":"code","6e126075":"code","76bc81cc":"code","f0b1293d":"code","95428651":"code","03d85ab8":"code","66fa1261":"code","047c686b":"code","8c51b9df":"code","d18dcce0":"code","b4e1b3a5":"code","8ddbb338":"code","8bddcbfb":"code","2f3d6b69":"code","7ffff934":"code","0ed399c8":"markdown","bbc9a85f":"markdown","3d7c4148":"markdown","4359fbee":"markdown","19029726":"markdown","ea57fa61":"markdown","2425c4be":"markdown","3e18afe5":"markdown","d4fabb07":"markdown","2b356b75":"markdown","a713e504":"markdown","ba616796":"markdown","9fc79dea":"markdown","e18c9fef":"markdown"},"source":{"8ded992e":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, Input, MaxPooling2D\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.applications.vgg16 import VGG16,  preprocess_input\nfrom tensorflow.keras.applications import VGG19\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","6cfa19d0":"BASE_PATH = '..\/input\/yoga-poses-dataset\/DATASET\/'","6ca27cb7":"filenames,labels = [],[]\n\nfor dirname in os.listdir(f'{BASE_PATH}TRAIN'):\n    for file in os.listdir(f'{BASE_PATH}TRAIN\/{dirname}'):\n        filenames.append(file)\n        labels.append(dirname)\n\ndf_train = pd.DataFrame(data={\n    'filename': filenames,\n    'labels': labels\n})","ac4a98d8":"df_train.head()","e6159d98":"df_train.labels.value_counts()","e012f73d":"rows = 5\ncols = 5\nfig, axs = plt.subplots(rows, cols, figsize=(16, 16))\nfor i, row in enumerate(list(df_train.labels.unique())):\n    for j, filename in enumerate(df_train[df_train.labels == row]['filename'].tolist()[:cols]):\n        img = load_img(os.path.join(BASE_PATH,'TRAIN',row, filename))\n        axs[i,j].matshow(img)\n        axs[i,j].axis('off')\n        axs[i,j].set_title(row.upper(), fontsize=24)\nfig.tight_layout()","6e126075":"num_classes = list(df_train.labels.unique())\nprint(num_classes)\nlen(num_classes)","76bc81cc":"IMG_H = 200\nIMG_W = 200\nIMG_C = 3\n\nBATCH_SIZE = 32\nEPOCHS = 30","f0b1293d":"train_gen = ImageDataGenerator(rescale=1.\/255,\n                               shear_range=0.2,\n                               zoom_range=0.2,\n                               width_shift_range=0.12,\n                               height_shift_range=0.12,\n                               horizontal_flip=True)\n\ntest_gen = ImageDataGenerator(rescale=1.\/255)","95428651":"train_set = train_gen.flow_from_directory(f'{BASE_PATH}TRAIN',\n                                          target_size=(IMG_W,IMG_H),\n                                          batch_size=BATCH_SIZE,\n                                          class_mode='categorical')\n\ntest_set = test_gen.flow_from_directory(f'{BASE_PATH}TEST',\n                                          target_size=(IMG_W,IMG_H),\n                                          batch_size=BATCH_SIZE,\n                                          class_mode='categorical')","03d85ab8":"def create_model():\n    tf.keras.backend.clear_session()\n    \n    cmodel = VGG19(input_shape = (IMG_W, IMG_H, IMG_C), \n                         weights='imagenet', \n                         include_top=False,)\n    \n    # there is no need to train existing weights\n    for layer in cmodel.layers:\n        layer.trainable = False\n        \n    x = Flatten()(cmodel.output)\n    #x = cmodel.output\n \n    prediction = Dense(len(num_classes), activation='softmax')(x)\n\n    # create model object\n    model = Model(inputs = cmodel.input, outputs = prediction)\n    \n    return model","66fa1261":"model = create_model()\nmodel.summary()","047c686b":"lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nes = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              verbose=0, mode='auto')","8c51b9df":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\ncallbacks_list = [es, lr_reduction]\n\nhistory = model.fit(train_set,\n                    validation_data=test_set,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks_list,\n                    shuffle=True\n                    )","d18dcce0":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","b4e1b3a5":"model.evaluate(train_set), model.evaluate(test_set)","8ddbb338":"y_val_org = []\nfor i in range( test_set.__len__() ):\n    y_val_org.extend(\n        test_set.__getitem__( i )[1] \n    )\ny_val_org = np.array(y_val_org)\ny_val_org = np.argmax(y_val_org, axis=1)","8bddcbfb":"y_val_org","2f3d6b69":"ypreds = model.predict(test_set)\nypreds = np.argmax(ypreds, axis=1)\nypreds","7ffff934":"cf_matrix = confusion_matrix(y_val_org, ypreds)\n\nplt.figure(figsize=(20,8))\nax = sns.heatmap(cf_matrix, annot=True, fmt='g')\nplt.show()\n\nprint(\"\\n\\n\")\nprint(classification_report(y_val_org, ypreds))","0ed399c8":"### Extract label from test_set","bbc9a85f":"### Number of classes","3d7c4148":"#### Set base path","4359fbee":"**Loading Data**","19029726":"### Predict Test data","ea57fa61":"### There are 5 different classes","2425c4be":"### Data Augumentation using ImageDataGenerator","3e18afe5":"### Create Model","d4fabb07":"# Yoga\n\n<img src = \"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRAKXxG7yXe7pKloc8Gwf87aNc6UrLZi71MvQ&usqp=CAU\" \/>\n\n<br\/>\n<br\/>\n\n**Yoga** is a group of physical, mental, and spiritual practices or disciplines which originated in ancient India.\n\nThere is a broad variety of yoga schools, practices, and goals in Hinduism, Buddhism, and Jainism. The term \"Yoga\" in the Western world often denotes a modern form of hatha yoga and yoga as exercise, consisting largely of the postures or asanas.\n\nThe practice of yoga has been thought to date back to pre-vedic Indian traditions, possibly in the Indus valley civilization around 3000 BCE. Yoga is mentioned in the Rigveda, and also referenced in the Upanishads, though it most likely developed as a systematic study around the 5th and 6th centuries BCE, in ancient India's ascetic and \u015arama\u1e47a movements. The chronology of earliest texts describing yoga-practices is unclear, varyingly credited to the Upanishads. The Yoga Sutras of Patanjali date from the 2nd century BCE, and gained prominence in the west in the 20th century after being first introduced by Swami Vivekananda. Hatha yoga texts began to emerge sometime between the 9th and 11th century with origins in tantra.\n\n\n**5 classes of yoga within datsset:**\n    - Downdog\n    - Goddess\n    - Plank\n    - Tree\n    - Warrior2\n\n\n\n## Downdog\n<hr\/>\n\n<img src = 'https:\/\/yogadigest.com\/wp-content\/uploads\/2014\/09\/madelyn-downdog.jpg' \/>\n\n<br\/>\n<br\/>\n\n## Goddess\n<hr>\n\n<img src = 'https:\/\/833487.smushcdn.com\/1695928\/wp-content\/uploads\/2018\/08\/inner_goddess-01.jpg?lossy=1&strip=1&webp=1' \/>\n\n<br\/>\n<br\/>\n\n## Plank\n<hr>\n\n<img src = 'https:\/\/www.theglobeandmail.com\/resizer\/e2P0Eu9t1YgOlW-T_cRMkdXELp8=\/2048x0\/filters:quality(80)\/arc-anglerfish-tgam-prod-tgam.s3.amazonaws.com\/public\/TFNCQAP3PRCCDAPGBVTDQAACJE' \/>\n\n<br\/>\n<br\/>\n\n## Tree\n<hr>\n\n<img src = 'https:\/\/images.vexels.com\/media\/users\/3\/153373\/isolated\/preview\/71641356ed1e72233efb7513b357508c-tree-yoga-pose-silhouette-by-vexels.png' \/>\n\n<br\/>\n<br\/>\n\n## Warrior\n<hr>\n\n<img src = 'https:\/\/purewows3.imgix.net\/images\/articles\/2019_09\/yoga-poses-for-kids-warrior-2.jpg?auto=format,compress&cs=strip' \/>\n\n<br\/>\n<br\/>","2b356b75":"### Displaying 5 images from each category","a713e504":"### Creating train, test set","ba616796":"### Confusion matrix and Classification Report","9fc79dea":"### Evaluate Model","e18c9fef":"### Config params"}}