{"cell_type":{"c1fe7248":"code","5782a24f":"code","f1369e85":"code","b5deb98c":"code","49ad9c83":"code","f643bf38":"code","ff99c595":"code","0ea7e513":"code","f6c26de2":"code","ca14d933":"code","3122455a":"code","6dd71b41":"code","881ff7a3":"code","5a57d101":"code","76308e3f":"code","0b78b11e":"code","6ae851d6":"code","5a1f4bcd":"markdown","4574eefd":"markdown","6dc4b2cc":"markdown","67accb01":"markdown","7202caf8":"markdown","5632d6aa":"markdown","da60968b":"markdown","aae99df7":"markdown","da40f791":"markdown"},"source":{"c1fe7248":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5782a24f":"data = pd.read_csv('..\/input\/anime.csv')\ndata.info()","f1369e85":"print(data['type'].value_counts(dropna=True))","b5deb98c":"data.describe()","49ad9c83":"data.boxplot(column = 'rating', by='type', figsize = (13,13))","f643bf38":"#id_vars is what we don't want to wish to melt\n#value_vars is what we want to wish to melt\ndata_new = data.head()\nmelted = pd.melt(frame=data_new, id_vars = 'name', value_vars =['genre', 'type'])\nmelted","ff99c595":"melted.pivot(index = 'name', columns = 'variable', values = 'value')","0ea7e513":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2], axis = 0, ignore_index=True)#axis=0 is meaning, vertical concat.\nconc_data_row","f6c26de2":"data_conc_cols = pd.concat([data1,data2], axis = 1 , ignore_index=True)#axis = 1 is meaning, horizontal cocnat.\ndata_conc_cols","ca14d933":"data.dtypes","3122455a":"data['type'] = data['type'].astype('category')\ndata['anime_id'] = data['anime_id'].astype('float')\ndata.dtypes","6dd71b41":"data.info()\n#there are 12294 object in out dataframe.\n#but as we can see, there are 12064 rating value at dataframe","881ff7a3":"data['rating'].value_counts(dropna=False)\n#there are 230 NaN value.","5a57d101":"dataNew = data\ndataNew['rating'].dropna(inplace =True)","76308e3f":"assert 1 == 1 # returns nothing.","0b78b11e":"assert 1 == 2 # returns error.","6ae851d6":"assert dataNew['rating'].dropna().all()#returns nothing because of we dropped all NaN values already.","5a1f4bcd":"### Melting & Pivoting Dataset\n\nWhen we would see especially the result of relation between different columns, we using melting function.\nPivoting function is reverse of melting.****","4574eefd":"### Concatenating Dataframes\nWe will concatenate two dataframes. We will do it from two different ways : \n* Vertical concatenate\n* Horizontal concatenate","6dc4b2cc":"### Data Types \n\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)","67accb01":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","7202caf8":"Lets check frequency value of the 'Type ' column.","5632d6aa":"Hello.\nI have changed the dataset because of the old dataset(World Happiness Report) had no value 'NaN'.\n\nThis homerwork kernel is about these issues :\n* Diagnose data for cleaning\n* Explotanory data analysis \n* Visual explotanory data analysis\n* Tidy Data\n* Pivoting Data\n* Concatenating Dataframes\n* DataTypes\n* Missing Data and Test with Asserts\n","da60968b":"### How can we use ' Assert ' ?\nAssert statement works like ' if statement. If assert gets boolean 1, returns nothing. But if assert gets boolean 0, returns error.","aae99df7":"### EXPLORATORY DATA ANALYSIS\n\n\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","da40f791":"### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles"}}