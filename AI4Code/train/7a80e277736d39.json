{"cell_type":{"5c56003d":"code","4a8125aa":"code","20110ea2":"code","56501a1a":"code","97395e22":"code","2f44562f":"code","740bcc94":"code","e8475859":"code","8a32ee83":"code","5cb5ae53":"code","ecb0f90e":"code","dd011440":"code","eeeaa13a":"markdown","43487025":"markdown","a1f321a2":"markdown","34b8153b":"markdown"},"source":{"5c56003d":"#import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nfrom numpy import asarray\nimport tensorflow as tf\nimport json\nimport pandas as pd\nimport os\nimport cv2   #import comp vision library\nimport math","4a8125aa":"#preprocessing annotation from json file (contains bounding box information)\n\nlist_name = []                   #contains list of json filenames\nlist_json =[]                    #contains bounding box values \n\nfolder=\"..\/input\/all-training-with-mask\/All_training_with_mask\/ann\"       #location for annotated json files\n\nfor filename in os.listdir(folder):                #looping through all the files present in the json folder                     \n    f = open(os.path.join(folder,filename))\n    data = json.load(f)                            #loading json file\n    list_name.append(filename)                                #extrating file name\n    list_json.append(data['objects'][0]['points']['exterior'])        #extracting bounding box values\n    f.close()\n    \ndf_training = pd.DataFrame(list_json, columns=['x_min,y_min', 'x_max,y_max'])    #creating dataframe containg bbox values\ndf_training['filename'] = list_name  #adding a column for filenames in the dataframe\n\n#preprocessing for dataframe\ndf_training['image_id'] = df_training.apply(lambda x: x['filename'].split('.')[0]+'.'+x['filename'].split('.')[1], axis=1)  \ndf_training['xmin'] = df_training.apply(lambda x: x['x_min,y_min'][0], axis=1)\ndf_training['ymin'] = df_training.apply(lambda x: x['x_min,y_min'][0], axis=1)\ndf_training['width'] = df_training.apply(lambda x: x['x_max,y_max'][0]-x['x_min,y_min'][0], axis=1)\ndf_training['height'] = df_training.apply(lambda x: x['x_max,y_max'][1]-x['x_min,y_min'][1], axis=1)\ndf_training","20110ea2":"#loading libraries \nimport cv2   #import comp vision library\nimport os    #import directory and related lib\nimport math\n\n#function to load images, indices, and file_names\ndef load_images_from_folder(folder, start, end):\n    \n    i = 0\n    ht_max, wd_max, cc_max = 0, 0, 0\n    ht_min, wd_min, cc_min = 0, 0, 0\n    images = []\n    files = []\n    index = []\n    \n    for filename in os.listdir(folder):    #loop for each file present in the folder\n        \n        img = cv2.imread(os.path.join(folder,filename))\n        \n        if img is not None and i <= end and i >= start:\n            \n            img = asarray(img)\n            \n            files.append(str(filename))\n            index.append(i)\n            \n            if (i == math.floor(start + (end-start)\/4)):\n                print(\"--------> (25%) Processing for record:\", i)\n            if (i == math.floor(start + (end-start)\/2)):\n                print(\"--------> (50%) Processing for record:\", i)\n                \n            ht, wd, cc= img.shape\n            top_pad, bottom_pad, left_pad, right_pad = 256-ht, 0, 256-wd, 0\n            img_padded = cv2.copyMakeBorder(img, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_DEFAULT)\n    \n            if i == 0:     #base case    \n                images.append(img_padded)\n                print('-------> Staring collecting images')\n\n            else:          #other cases\n                if ht > ht_max :\n                    ht_max = ht\n                if wd > wd_max :\n                    wd_max = wd\n                if cc > cc_max :\n                    cc_max = cc\n                if ht < ht_min :\n                    ht_min = ht\n                if wd < wd_min :\n                    wd_max = wd\n                if cc < cc_min :\n                    cc_min = cc\n\n                images.append(img_padded)\n                \n        i = i + 1\n        \n        if i == end:        #breaking condition\n            break\n    print('------> Loading images ..........  Done')\n    return images, files, index","56501a1a":"#loading images and other variables\nfolder=\"..\/input\/all-training-with-mask\/All_training_with_mask\/img\/\"\n\nimages, files, index = load_images_from_folder(folder, 0, 100)\nimages = asarray(images)\ndf_metadata = pd.DataFrame(list(zip(files, index)))\ndf_metadata.columns=['FileName', 'Index']\ndel files, index\n\nprint(images.shape)\n\n#preprocessing: mapping files with labels\ndf_y = df_training\ndf_metadata = pd.merge(df_metadata, df_y, left_on='FileName', right_on='image_id')\n#del df_y\ndf_metadata","97395e22":"#setting up input to the model, and test set\nX = asarray(images)\n\ny = (df_metadata[['xmin','ymin','width', 'height']]).to_numpy()","2f44562f":"# import keras libraries  \nimport sys\nfrom numpy import load\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import BatchNormalization\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.constraints import unit_norm\nfrom keras import metrics\nfrom keras.layers import Dropout\n\n\n\nin_shape=(X.shape[1], X.shape[2], 3)\nout_shape = y.shape[1]\n\nmodel = Sequential()\n    \n    \n#filter size is 3*3*volume; number of filters = 32; activation=relu;  (convolution layer)\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=in_shape, kernel_initializer='he_normal', kernel_constraint=unit_norm(), kernel_regularizer=regularizers.l2(l=0.001))) \nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_constraint=unit_norm(), kernel_regularizer=regularizers.l2(l=0.001))) \nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\n\n#fully connected layer\nmodel.add(Flatten())\nmodel.add(Dropout(0.1))\n# model.add(Dense(128, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(out_shape))\n \n# compile model\nopt = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt, loss='mean_squared_error', metrics=[metrics.mse])","740bcc94":"model.summary()","e8475859":"trainX, valX, trainY, valY = train_test_split(X, y, test_size=0.2)    #spliting between training and testing \n\nhistory = model.fit(trainX, trainY, epochs=90, validation_data=(valX, valY), verbose=2)\n\n#plotting training vs validation error\npyplot.subplot(211)\npyplot.title('mean_squared_error')\npyplot.plot(history.history['mean_squared_error'], color='blue', label='train')\npyplot.plot(history.history['val_mean_squared_error'], color='orange', label='test')\n# Function add a legend  \npyplot.legend([\"training\", \"validation\"], loc =\"lower right\")","8a32ee83":"#loading images and other variables for testing\ntest_folder=\"..\/input\/all-test\/All_testing\/\"\n\ntest_images, test_files, test_index = load_images_from_folder(test_folder, 0, 100)\ntest_images = asarray(test_images)\ntest_df_metadata = pd.DataFrame(list(zip(test_files, test_index)))\ntest_df_metadata.columns=['FileName', 'Index']\ndel test_files, test_index\n\n\n#setting up input to the model, and test set\ntest_X_all = asarray(test_images)\n\nnew_y = model.predict(test_X_all)","5cb5ae53":"new_y","ecb0f90e":"#writing into dataframe\n\ntest_df_pred = pd.DataFrame(new_y, columns=['pred_xmin', 'pred_ymin', 'pred_width', 'pred_height']).reset_index()\ntest_df_pred['pred_xmax'] = test_df_pred['pred_xmin'] + test_df_pred['pred_width']\ntest_df_pred['pred_ymax'] = test_df_pred['pred_ymin'] + test_df_pred['pred_height']\ntest_df_pred.drop(columns=['pred_width', 'pred_height'], inplace=True)\ntest_df_pred['imageid']=test_df_metadata['FileName']\ntest_df_pred.to_csv('.\/mask_csv.csv',index=False)","dd011440":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport os\n\nsave_maske_images_dir = 'masks'\nos.mkdir(save_maske_images_dir)\n\n\n\nprint(test_folder)\n\n#writing the mask into the file\n\nfor filename in os.listdir(test_folder):    #loop for each file present in the folder\n    \n    im = Image.open(os.path.join(test_folder,filename))\n    \n    #Create figure and axes\n    fig, ax = plt.subplots()\n    \n    # Display the image\n    ax.imshow(im)\n    \n    bbox = (test_df_metadata.loc[test_df_metadata.FileName == filename]).iloc[0,1]\n    \n    rect = patches.Rectangle((new_y[bbox][0], new_y[bbox][1]), new_y[bbox][2], new_y[bbox][3], linewidth=2, edgecolor='r', facecolor='none')\n\n    # Add the patch to the Axes\n    ax.add_patch(rect)\n\n    \n    \n    plt.savefig(save_maske_images_dir+'\/'+filename)\n    \n    plt.show()\n    \n ","eeeaa13a":"### Preprocessing","43487025":"### Predicting over test set using trained model","a1f321a2":"### Setting up X and y for training","34b8153b":"### Training using Keras"}}