{"cell_type":{"45750ac1":"code","6130d981":"code","fe2d8629":"code","9a3ebc67":"code","2c4c7c5f":"code","052840cc":"code","fee227d6":"code","384979ac":"code","691b8971":"code","d6f601e2":"code","6472b382":"code","dadb8254":"code","407f9311":"code","1783e3c8":"code","093b3993":"code","bf2034b0":"code","8f56fc48":"code","7df27cd2":"code","54a26111":"code","d4f6845f":"code","71f34d6e":"code","0d91cd23":"code","a402067d":"code","b8d7f6a5":"code","eeed8cf5":"code","0ba68549":"code","344caf08":"code","52d56875":"code","24590a45":"markdown","e8677ae7":"markdown","5a9139d7":"markdown","ed8f9722":"markdown","90e90768":"markdown","d5a8a1fc":"markdown","643e5dbc":"markdown","c6348e83":"markdown","866de766":"markdown","e1398da5":"markdown","57f77d4f":"markdown","7af3463d":"markdown","b9e60362":"markdown","6d4bad4c":"markdown","b61fee67":"markdown","9751356f":"markdown","0bf06ac5":"markdown"},"source":{"45750ac1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6130d981":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\n\nSeed = 42\nnp.random.seed(Seed)\n\n# import sklearn libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost","fe2d8629":"def calculate_time(s_time):\n    seconds = np.round(time.time() - s_time, 0)\n    minutes = hours = 0\n\n    # claculate minutes\n    while seconds > 60:\n        minutes += 1\n        seconds -= 60\n    \n    # calculate hours\n    while minutes > 60:\n        hours += 1\n        minutes -= 60\n\n    print(f'Cell Executed in {hours}h {minutes}m {seconds}s')","9a3ebc67":"def save_data(data, labels, file_name, path='.\/'):\n    df = pd.DataFrame(data, columns=labels)\n    df.to_csv(f'{path}\/{file_name}.csv', index=False )","2c4c7c5f":"\ndef save_data(data, labels, file_name, path='.\/'):\n    df = pd.DataFrame(data, columns=labels)\n    df.to_csv(f'{path}\/{file_name}.csv', index=False )\t\t","052840cc":"def remove_nulls(df, cols):\n    for col in cols:\n        df[col] = df[col].fillna(df[col].mean())\n\n","fee227d6":"# split the target and drop key and fare_amount from tain data\ndef drop_features(df, features= ['fare_amount', 'key']):\n    df.drop(features, axis = 1, inplace=True)","384979ac":"# split datetime feature in dummy feature with [year, month, day, hour, minute, seconds]\ndef split_date_time(df, feature_name = 'pickup_datetime'):\n    print('convert feature into datetime')\n    date_feature = pd.to_datetime( df[feature_name])\n\n    print('get year from feature:')\n    year = date_feature.dt.year\n\n    print('get Month from feature:')\n    month = date_feature.dt.month\n\n    print('get day from feature:')\n    day = date_feature.dt.day\n\n    print('get hour from feature:')\n    hour = date_feature.dt.hour\n\n    print('get minute from feature:')\n    minute = date_feature.dt.minute\n\n    print('get second from feature:')\n    second = date_feature.dt.second\n\n    print('add these cols as new features:')\n    df['year'] = year\n    df['month'] = month\n    df['day'] = day\n    df['hour'] = hour\n    df['minute'] = minute\n    df['second'] = second\n","691b8971":"dir_path = '\/kaggle\/input\/new-york-city-taxi-fare-prediction\/'\n\n# Load the dataset\ntrain = pd.read_csv(f'{dir_path}train.csv', nrows=30_000_000)\ntest = pd.read_csv(f'{dir_path}test.csv')","d6f601e2":"features = ['pickup_datetime', 'pickup_longitude',\n       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n       'passenger_count']","6472b382":"train.head()","dadb8254":"test.head()","407f9311":"# Split the target from train\ntarget = train['fare_amount']\ntarget.head()","1783e3c8":"# remove key, fare_amount features\ndrop_features(train)\ntrain.head()","093b3993":"# detect Null values\ntrain.isna().sum()","bf2034b0":"# fill null values using the mean of the rest of the feature samples\nnull_features = ['dropoff_longitude', 'dropoff_latitude']\nremove_nulls(train, null_features)\ntrain.isnull().sum()","8f56fc48":"s_time = time.time()\n# split datetime feature\nsplit_date_time(train, feature_name='pickup_datetime')\n\ndrop_features(train, ['pickup_datetime'])\n\ncalculate_time(s_time)\n\ntrain.head()","7df27cd2":"s_time = time.time()\n\n# Split datetime feature in test set\nsplit_date_time(test)\n\n# remove key and pickup_datetime features\ndrop_features(test, ['key', 'pickup_datetime'])\n\ncalculate_time(s_time)\n\ntest.head()","54a26111":"s_time = time.time()\n\nsc = StandardScaler()\n\nprint('Scale Training set')\ntrain_scaled = sc.fit_transform(train)\n\nprint('Scale Testing set')\ntest_scaled = sc.transform(test)\n\ncalculate_time(s_time)\n\ntrain_scaled[:5], test_scaled[:5]\n","d4f6845f":"labels = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'year', 'month', 'day', 'hour', 'minute', 'second']\n\n# Save Train data\nprint('Saving Train File....')\nsave_data(train_scaled, labels, 'scaled_train')\n\nprint('Saving Test File....')\n# save Test data\nsave_data(test_scaled, labels, 'scaled_test')","71f34d6e":"\nx_train, x_valid , y_train, y_valid = train_test_split(train_scaled, target, test_size=.2)\n\nx_train.shape, y_train.shape, x_valid.shape, y_valid.shape\n","0d91cd23":"s_time = time.time()\nsvr_reg = SVR()\nprint('Fitting the model...')\nsvr_reg.fit(x_train, y_train)\n\nprint('Predicting the model...')\ny_pred = svr_reg.predict(x_valid)\n\nprint('Calculating RMSE....')\nsvr_reg = mean_squared_error(y_valid, y_pred, squared=False)\n\nprint(f'RMSE = {svr_reg}')\n\ncalculate_time(s_time)","a402067d":"s_time = time.time()\n\nxg_reg = xgboost.XGBRegressor(n_estimators = 100, random_state = Seed)   \n\nprint('Fitting the model...')\nxg_reg.fit(x_train, y_train)     \n\nprint('Predicting the model...')\ny_pred = xg_reg.predict(x_valid)\n\nprint('Calculating RMSE....')\nxg_mse = mean_squared_error(y_valid, y_pred, squared=False)\n\nprint(f'RMSE = {xg_mse}')\n\ncalculate_time(s_time)","b8d7f6a5":"# save predicted test data for submission\ny_test_pred = xg_reg.predict(test_scaled)\n\nsubmit = pd.read_csv('sample_submission.csv')\n\nsubmit['fare_amount'] = y_test_pred\n\nsubmit.to_csv('submission_xgboost.csv', index=False)","eeed8cf5":"rnd_reg = RandomForestRegressor(n_estimators=200, max_depth=4, n_jobs=-1, random_state=Seed)\n\nprint('Fitting the model...')\nrnd_reg.fit(x_train, y_train)\n\nprint('Predicting the model...')\ny_pred_rnd = rnd_reg.predict(x_valid)\n\nprint('Calculating RMSE....')\nmse = mean_squared_error(y_valid, y_pred_rnd, squared=False)\n\nprint(f'RMSE = {xg_mse}')\n\ncalculate_time(s_time)","0ba68549":"# save predicted test data for submission\ny_test_pred = rnd_reg.predict(test_scaled)\n\nsubmit = pd.read_csv('sample_submission.csv')\n\nsubmit['fare_amount'] = y_test_pred\n\nsubmit.to_csv('submission_randomForest.csv', index=False)","344caf08":"y_test_pred","52d56875":"y_pred_rnd[:5], y_valid[:5]","24590a45":"##### Save Train and Test dataset to import directly in future without recleaning","e8677ae7":"##### RandomForest Regressor","5a9139d7":"##### Scale the features","ed8f9722":"##### xgboost Regressor","90e90768":"#### Build Functions","d5a8a1fc":"#####  split datetime feature","643e5dbc":"#### Build the Models","c6348e83":"#### Load the dataset","866de766":"##### Calculate Time","e1398da5":"##### Split valid data from train with 20%","57f77d4f":"##### Remove Nulls","7af3463d":"##### Save Scaled Data\nsave numpy arrays as csv file for future use","b9e60362":"#### Cleaning the Data","6d4bad4c":"##### Drop Features","b61fee67":"##### SVM Regressor","9751356f":"##### Save scaled dataset \nwe use it in the future rather than recleaning and saling the data","0bf06ac5":"### data Exploratory"}}