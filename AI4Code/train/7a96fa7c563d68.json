{"cell_type":{"89cd6e00":"code","d78a9bae":"code","f1f2daf5":"code","fe5052a3":"code","2a9b33bf":"code","f279abf6":"code","bb7c2f41":"code","e5a1fd3e":"code","16df7034":"code","ff68f22d":"code","a924dcc6":"code","910f0d05":"code","28a4195d":"code","f68c8970":"code","90577898":"code","95d4ef4f":"code","82b66487":"code","14cf333d":"code","d0eb9b0c":"code","4f1fc450":"code","f5a34f8b":"code","ce781a2d":"code","2f983b96":"code","2f7f6d8b":"markdown","f58bd7b3":"markdown","2de8a654":"markdown","1eec8011":"markdown","8a832c41":"markdown","f2feef84":"markdown","7022a043":"markdown","ed2a2b79":"markdown","8ddbb9f1":"markdown"},"source":{"89cd6e00":"!pip install pretrainedmodels\n!pip install albumentations\n!pip install --upgrade efficientnet-pytorch","d78a9bae":"import os\nimport numpy as np\nimport pandas as pd\n\nimport albumentations as A\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom efficientnet_pytorch import EfficientNet\n\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import Rotate \n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nimport warnings  \nwarnings.filterwarnings('ignore')","f1f2daf5":"DIR_INPUT = '\/kaggle\/input\/plant-pathology-2020-fgvc7'\n\nSEED = 42\nN_FOLDS = 5\nN_EPOCHS = 3\nBATCH_SIZE = 16\nSIZE = 224","fe5052a3":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    # random.seed(seed)\n    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nseed_everything(SEED)","2a9b33bf":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","f279abf6":"class PlantDataset(Dataset):\n    \n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms=transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_src = DIR_INPUT + '\/images\/' + self.df.loc[idx, 'image_id'] + '.jpg'\n        # print(image_src)\n        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        labels = self.df.loc[idx, ['healthy', 'multiple_diseases', 'rust', 'scab']].values\n        labels = torch.from_numpy(labels.astype(np.int8))\n        labels = labels.unsqueeze(-1)\n        \n        if self.transforms:\n            transformed = self.transforms(image=image)\n            image = transformed['image']\n\n        return image, labels","bb7c2f41":"transforms_train = A.Compose([\n        A.RandomResizedCrop(height=SIZE, width=SIZE, p=1.0),\n        A.Rotate(20),\n        A.Flip(),\n        A.Transpose(),\n    A.Resize(height=SIZE, width=SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n    ], p=1.0)\n\ntransforms_valid = A.Compose([\n    A.Resize(height=SIZE, width=SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])","e5a1fd3e":"train_df = pd.read_csv(DIR_INPUT + '\/train.csv')\ntrain_labels = train_df.iloc[:, 1:].values\n\n# Need for the StratifiedKFold split\ntrain_y = train_labels[:, 2] + train_labels[:, 3] * 2 + train_labels[:, 1] * 3","16df7034":"train_df.head()","ff68f22d":"folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof_preds = np.zeros((train_df.shape[0], 4))","a924dcc6":"model_name = 'efficientnet-b7'\nmodel = EfficientNet.from_pretrained(model_name, num_classes=4) ","910f0d05":"class DenseCrossEntropy(nn.Module):\n\n    def __init__(self):\n        super(DenseCrossEntropy, self).__init__()\n        \n        \n    def forward(self, logits, labels):\n        logits = logits.float()\n        labels = labels.float()\n        \n        logprobs = F.log_softmax(logits, dim=-1)\n        \n        loss = -labels * logprobs\n        loss = loss.sum(-1)\n\n        return loss.mean()","28a4195d":"def train_one_fold(i_fold, model, criterion, optimizer, lr_scheduler, dataloader_train, dataloader_valid):\n    \n    train_fold_results = []\n\n    for epoch in range(N_EPOCHS):\n\n        print('  Epoch {}\/{}'.format(epoch + 1, N_EPOCHS))\n        print('  ' + ('-' * 20))\n\n        model.train()\n        tr_loss = 0\n\n        for step, batch in enumerate(dataloader_train):\n\n            images = batch[0]\n            labels = batch[1]\n\n            images = images.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.float)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels.squeeze(-1))                \n            loss.backward()\n\n            tr_loss += loss.item()\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n        # Validate\n        model.eval()\n        \n        val_loss = 0\n        val_preds = None\n        val_labels = None\n\n        for step, batch in enumerate(dataloader_valid):\n\n            images = batch[0]\n            labels = batch[1]\n\n            if val_labels is None:\n                val_labels = labels.clone().squeeze(-1)\n            else:\n                val_labels = torch.cat((val_labels, labels.squeeze(-1)), dim=0)\n\n            images = images.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.float)\n\n            with torch.no_grad():\n                outputs = model(images)\n\n                loss = criterion(outputs, labels.squeeze(-1))\n                val_loss += loss.item()\n\n                preds = torch.softmax(outputs, dim=1).data.cpu()\n\n                if val_preds is None:\n                    val_preds = preds\n                else:\n                    val_preds = torch.cat((val_preds, preds), dim=0)\n       \n        # if train mode\n        lr_scheduler.step(tr_loss)\n\n        train_fold_results.append({\n            'fold': i_fold,\n            'epoch': epoch,\n            'train_loss': tr_loss \/ len(dataloader_train),\n            'valid_loss': val_loss \/ len(dataloader_valid),\n            'valid_score': roc_auc_score(val_labels, val_preds, average='macro'),\n        })\n\n    return val_preds, train_fold_results","f68c8970":"submission_df = pd.read_csv(DIR_INPUT + '\/sample_submission.csv')\nsubmission_df.iloc[:, 1:] = 0","90577898":"dataset_test = PlantDataset(df=submission_df, transforms=transforms_valid)\ndataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)","95d4ef4f":"submissions = None\ntrain_results = []\n\nfor i_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_y)):\n    print(\"Fold {}\/{}\".format(i_fold + 1, N_FOLDS))\n\n    valid = train_df.iloc[valid_idx]\n    valid.reset_index(drop=True, inplace=True)\n\n    train = train_df.iloc[train_idx]\n    train.reset_index(drop=True, inplace=True)    \n\n    dataset_train = PlantDataset(df=train, transforms=transforms_train)\n    dataset_valid = PlantDataset(df=valid, transforms=transforms_valid)\n\n    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n    dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n\n    model = model.to(device)\n\n    criterion = DenseCrossEntropy()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[int(N_EPOCHS * 0.5), int(N_EPOCHS * 0.75)], gamma=0.1, last_epoch=-1)\n    \n    val_preds, train_fold_results = train_one_fold(i_fold, model, criterion, optimizer, lr_scheduler, dataloader_train, dataloader_valid)\n    oof_preds[valid_idx, :] = val_preds.numpy()\n    \n    train_results = train_results + train_fold_results\n\n    model.eval()\n    test_preds = None\n\n    for step, batch in enumerate(dataloader_test):\n\n        images = batch[0].to(device, dtype=torch.float)\n\n        with torch.no_grad():\n            outputs = model(images)\n\n            if test_preds is None:\n                test_preds = outputs.data.cpu()\n            else:\n                test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n    \n    \n    # Save predictions per fold\n    submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(test_preds, dim=1)\n    submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n\n    # logits avg\n    if submissions is None:\n        submissions = test_preds \/ N_FOLDS\n    else:\n        submissions += test_preds \/ N_FOLDS\n\nprint(\"5-Folds CV score: {:.4f}\".format(roc_auc_score(train_labels, oof_preds, average='macro')))\n\ntorch.save(model.state_dict(), 'model.pth')","82b66487":"import matplotlib.pyplot as plt","14cf333d":"def show_training_loss(train_result):\n    plt.figure(figsize=(15,10))\n    plt.subplot(311)\n    train_loss = train_result['train_loss']\n    plt.plot(train_loss.index, train_loss, label = 'train_loss')\n    plt.legend()\n\n    val_loss = train_result['valid_loss']\n    plt.plot(val_loss.index, val_loss, label = 'val_loss')\n    plt.legend()","d0eb9b0c":"def show_valid_score(train_result):\n    plt.figure(figsize=(15,10))\n    plt.subplot(311)\n    valid_score = train_result['valid_score']\n    plt.plot(valid_score.index, valid_score, label = 'valid_score')\n    plt.legend()","4f1fc450":"train_results = pd.DataFrame(train_results)\ntrain_results.head(10)","f5a34f8b":"show_training_loss(train_results[train_results['fold'] == 0])","ce781a2d":"show_valid_score(train_results[train_results['fold'] == 0])","2f983b96":"submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(submissions, dim=1)\nsubmission_df.to_csv('submission.csv', index=False)","2f7f6d8b":"# Generate submission file","f58bd7b3":"# Train for StratifiedKFold","2de8a654":"# Agumentations","1eec8011":"# PretrainedModels","8a832c41":"# Settings","f2feef84":"# Show Train History","7022a043":"# StratifiedKFold","ed2a2b79":"# Define Dataset","8ddbb9f1":"# Version - 0.4\n - Using GPU\n - EfficientNet b7"}}