{"cell_type":{"650ca16d":"code","a34218c6":"code","bdcc9a16":"code","fcfbb67b":"code","50c42d89":"code","7a28781a":"code","f7bc4876":"code","9aadae4e":"code","3d042d23":"code","59c20503":"code","7aef66e4":"code","c1c90b1c":"code","773a2172":"code","cc6e7811":"code","8040df1e":"code","9c756c07":"code","e50ea837":"code","0cb4c3be":"code","83964d94":"code","696c8f62":"code","e16ad8a3":"code","a45fb89f":"code","a942386e":"code","9f32e559":"code","f3b3491b":"code","c151ec09":"code","73f8e432":"code","45befb28":"code","8435e5f9":"code","c60539ab":"code","e1d66966":"code","36e6a5aa":"code","49897f35":"code","b821535e":"code","9287900f":"code","68f584e6":"code","d4f40b0a":"code","d9f68340":"code","2ea2625c":"code","9acdb97d":"code","d962477d":"markdown","de861e79":"markdown","17252458":"markdown","5bca6d24":"markdown","09231742":"markdown","9920519a":"markdown","edb4e8d2":"markdown","9ed0308b":"markdown"},"source":{"650ca16d":"!pip install comet_ml","a34218c6":"import comet_ml #at the top of your file\nfrom comet_ml import Experiment\n\n# Create an experiment with your api key:\nexperiment = Experiment(\n    api_key=\"cjZUHKCBKcrudJIeYuUe1zaBT\",\n    project_name=\"species-audio-detection\",\n    workspace=\"kaggle\",\n    log_code=True,\n)","bdcc9a16":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport librosa\nimport librosa.display\nimport soundfile\nimport pathlib as pt\nimport os\nimport matplotlib.pyplot as plt\nimport multiprocessing as mp\nfrom itertools import repeat\nimport signal\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom fastai.vision.all import *\nfrom fastai.data.core import DataLoaders\n\nfrom tqdm import tqdm\n\nimport torch.cuda\nif torch.cuda.is_available():\n    print('PyTorch found cuda')\nelse:\n    print('PyTorch could not find cuda')","fcfbb67b":"ROOT = pt.Path('\/kaggle\/input\/rfcx-species-audio-detection')\nTRAIN_TP_CSV = ROOT\/\"train_tp.csv\"\nTRAIN_FP_CSV = ROOT\/\"train_fp.csv\"\nTRAIN_DIR    = ROOT\/\"train\"\nTEST_DIR     = ROOT\/\"test\"\n\nprint(list(TRAIN_DIR.glob(\"*\"))[:5])","50c42d89":"def create_path(row):\n    return TRAIN_DIR\/\"{}.flac\".format(row)","7a28781a":"train_audio_tp_df = pd.read_csv(TRAIN_TP_CSV)\ntrain_audio_tp_df[\"tp\"] = True\ntrain_audio_tp_df['audio_path'] = train_audio_tp_df['recording_id'].apply(create_path)\ntrain_audio_tp_df.head(3)","f7bc4876":"train_audio_fp_df = pd.read_csv(TRAIN_FP_CSV)\ntrain_audio_fp_df[\"tp\"] = False\ntrain_audio_fp_df['audio_path'] = train_audio_fp_df['recording_id'].apply(create_path)\ntrain_audio_fp_df.head(3)","9aadae4e":"print(\"TP: # {} FP: # {}\".format(len(train_audio_tp_df), len(train_audio_fp_df)))","3d042d23":"all_train_audio_df = pd.concat([train_audio_tp_df, train_audio_fp_df]).reset_index()\nall_train_audio_df.head(3)","59c20503":"species_ids = sorted(all_train_audio_df['species_id'].unique())\nprint(species_ids)","7aef66e4":"_df = all_train_audio_df['species_id'].value_counts().sort_index()\nax = _df.plot(kind='bar')\nax.set_xlabel(\"Species ID\")\nax.set_ylabel(\"Frequency\")\nax.set_title(\"Nr of samples \/ species\")\nplt.close('all')","c1c90b1c":"test_audio_paths = list(TEST_DIR.glob(\"*.flac\"))\ntest_audio_df = pd.DataFrame()\ntest_audio_df['recording_id'] = [p.stem for p in test_audio_paths]\ntest_audio_df['audio_path']   = [p for p in test_audio_paths]\ntest_audio_df.head(3)","773a2172":"print(\"Total training: # {}\".format(len(all_train_audio_df)))\nprint(\"Test: # {}\".format(len(test_audio_df)))","cc6e7811":"# train_df, valid_df = train_test_split(all_train_df, test_size=0.2, random_state=42)\n# train_df.reset_index(drop=True, inplace=True)\n# valid_df.reset_index(drop=True, inplace=True)\n\n# print(\"Train: # {} Validation: # {}\".format(len(train_df), len(valid_df)))","8040df1e":"# idx = 256\n# y, sr = librosa.load(all_train_audio_df.iloc[idx]['audio_path'])\n# fig, ax = plt.subplots(1, 1)\n# ax.plot(y);\n# ax.set_title('Signal - recording id {}'.format(all_train_audio_df.iloc[idx]['recording_id']));\n# ax.set_xlabel('Time (samples)');\n# ax.set_ylabel('Amplitude');","9c756c07":"# spec = np.abs(librosa.stft(y, hop_length=512))\n# spec = librosa.amplitude_to_db(spec, ref=np.max)\n# fig, ax = plt.subplots(1, 1)\n# img = librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='log', ax=ax);\n# ax.set_title('Spectrogram');\n# fig.colorbar(img, ax=ax, format='%+2.0f dB');","e50ea837":"# mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n# fig, ax = plt.subplots(1, 1)\n# img = librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max), y_axis='mel', x_axis='time')\n# ax.set_title('Melspectogram');\n# fig.colorbar(img, ax=ax, format='%+2.0f dB');\n\n# plt.close('all')","0cb4c3be":"def fig2img(fig):\n    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n    import io\n    buf = io.BytesIO()\n    fig.savefig(buf)\n    buf.seek(0)\n    img = Image.open(buf).convert('RGB')\n \n    return img","83964d94":"# %matplotlib\n# %matplotlib\n\n# fig, ax = plt.subplots(1, 1, figsize=(0.72, 0.72))\n# img = librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max), y_axis='mel', x_axis='time')\n# ax.set_axis_off()\n# ax.axis('tight')\n# # Set whitespace to 0\n# fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n# # img = fig2img(fig)\n# # img.save(\"pic_melspectogram_example_3.png\")\n# fig.savefig('melspectogram_example.png', dpi=400)#, bbox_inches='tight', pad_inches=0)\n# experiment.log_image('melspectogram_example.png')","696c8f62":"def save_melspectograms(data_df, output_dir, dim_inches=(0.72, 0.72)):\n    for _, row in data_df.iterrows():\n        if 'species_id' in data_df.columns:\n            image_filename = \"s{}_{}_train.png\".format(row['species_id'], row['recording_id'])\n        else:\n            image_filename = \"{}_test.png\".format(row['recording_id'])\n        melspec_path = output_dir\/image_filename\n        \n        if melspec_path.exists():\n            continue\n        y, sr = librosa.load(row['audio_path'])\n\n        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n\n        fig, ax = plt.subplots(1, 1, figsize=dim_inches)\n        _ = librosa.display.specshow(mel_spec, y_axis='mel', x_axis='time')\n        ax.set_axis_off()\n        ax.axis('tight')\n        # Set whitespace to 0\n        fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n        fig.savefig(melspec_path, dpi=400)#, bbox_inches='tight', pad_inches=0)\n        plt.close(fig)\n        plt.close('all')\n        del y\n        del mel_spec\n\n    print(\"Done saving from idx {}.\".format(data_df.index[0]))","e16ad8a3":"TRAIN_SPEC_DIR = pt.Path('\/kaggle\/working\/train_specs\/')\nTEST_SPEC_DIR = pt.Path('\/kaggle\/working\/test_specs\/')\nos.makedirs(TRAIN_SPEC_DIR, exist_ok=True)\nos.makedirs(TEST_SPEC_DIR, exist_ok=True)\n\nprint(\"TRAIN_SPEC_DIR: {} TEST_SPEC_DIR: {}\".format(TRAIN_SPEC_DIR.exists(), TEST_SPEC_DIR.exists()))","a45fb89f":"def signal_handler(signal, frame):\n    global interrupted\n    interrupted = True\n    \ndef parallelised_saving(data_df, output_dir, batch_nr=2):\n    master_list = []\n    num_proc = mp.cpu_count()\n\n    n_iter = int(np.ceil(len(data_df) \/ batch_nr))\n    for i in range(n_iter):\n        batch_df = data_df.iloc[i * batch_nr: (i+1) * batch_nr]\n        master_list.append(batch_df)\n\n    print(\"to be saved dfs #\", len(master_list))\n    print(\"CPU cores #\", num_proc)\n\n    signal.signal(signal.SIGINT, signal_handler)\n\n    processes = [None] * num_proc\n    processed_idx = []\n    local_current_index = 0\n\n    interrupted = False\n    finished = False\n    exit_main_loop = False\n\n    while(not interrupted and not exit_main_loop):\n\n        for i in range(num_proc):\n\n            if processes[i] is None and not finished:\n                batch_idx = local_current_index\n#                 print(\"Process number {} is free. Assigning new task.\".format(i))\n                if batch_idx >= len(master_list):\n                    finished = True\n                else:\n                    processed_idx.append(batch_idx)\n#                     print(\"\\tStarting processing of batch nr {}\".format(batch_idx))\n                    processes[i] = mp.Process(target=save_melspectograms, \n                                              args=([master_list[batch_idx], output_dir]))\n                    processes[i].start()\n                    local_current_index = local_current_index + 1\n\n            if(finished and all(v is None for v in processes)):\n                print(\">>> Finished processing!\")\n                exit_main_loop = True\n                break\n\n            if processes[i] is None:\n                continue\n\n            if processes[i].exitcode is not None:\n\n                processes[i].join()\n                processes[i] = None\n\n        time.sleep(0.1)","a942386e":"parallelised_saving(train_audio_tp_df, output_dir=TRAIN_SPEC_DIR, batch_nr=64)","9f32e559":"parallelised_saving(test_audio_df, output_dir=TEST_SPEC_DIR, batch_nr=64)","f3b3491b":"train_melspectograms = list(TRAIN_SPEC_DIR.glob(\"*.png\"))\nprint(\"Train total: #\", len(train_melspectograms))\n\ntest_melspectograms = list(TEST_SPEC_DIR.glob(\"*.png\"))\nprint(\"Test: #\", len(test_melspectograms))","c151ec09":"# _i = Image.open(train_melspectograms[0])\n# print(_i.shape)\n# plt.imshow(_i)","73f8e432":"train_specs_df = pd.DataFrame()\ntrain_specs_df['spec_path']    = train_melspectograms\ntrain_specs_df['recording_id'] = [p.name.split(\"_\")[1] for p in train_melspectograms]\ntrain_specs_df['species_id']   = [p.name.split(\"_\")[0] for p in train_melspectograms]\ntrain_specs_df.head(2)","45befb28":"test_specs_df = pd.DataFrame()\ntest_specs_df['spec_path']    = test_melspectograms\ntest_specs_df['recording_id'] = [p.name.split(\"_\")[0] for p in test_melspectograms]\ntest_specs_df.head(2)","8435e5f9":"help(ImageDataLoaders.from_df)","c60539ab":"data_loaders = ImageDataLoaders.from_df(train_specs_df, path=\"\/\", seed=42, fn_col='spec_path', label_col='species_id', item_tfms=[Resize(224)])","e1d66966":"learn = cnn_learner(data_loaders, resnet34, metrics=error_rate)\n# learn.model = learn.model.cuda()\n# learn.lr_find()","36e6a5aa":"learn.fine_tune(2)\n# learn.fit_one_cycle(n_epoch=2, lr_max=0.01)\nlearn.export(\"resnet34_model.pkl\")","49897f35":"experiment.log_model(name=\"resnet34_model_v0\", file_or_folder=\"\/resnet34_model.pkl\")","b821535e":"learn.show_results()","9287900f":"interp = Interpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,10))","68f584e6":"test_dl = data_loaders.test_dl(test_specs_df)\nres_preds = learn.get_preds(dl=test_dl, with_decoded=True) # returns (predictions, _, predicted label)","d4f40b0a":"preds_values = res_preds[0]\npreds_labels = res_preds[2]","d9f68340":"submission_data = {'recording_id': []}\nfor _id in species_ids:\n    submission_data.update({'s{}'.format(_id): []})\n\nfor idx, preds in enumerate(preds_values):\n\n    submission_data['recording_id'].append(test_specs_df.iloc[idx]['recording_id'])\n    for i, p in enumerate(preds):\n        submission_data[\"s{}\".format(i)].append(p.item())\n\nsubmission_df = pd.DataFrame(data=submission_data)\nsubmission_df.to_csv(\"submission_data.csv\", index=False)\nexperiment.log_table(\"submission_data.csv\")","2ea2625c":"submission_df.head()","9acdb97d":"experiment.end()","d962477d":"### Audio to spectogram","de861e79":"## Look at some predictions","17252458":"## Create submission file","5bca6d24":"## Train\n### Prepare data loaders","09231742":"## Prepare data","9920519a":"### Split train data into train and validation","edb4e8d2":"### Save spectograms","9ed0308b":"### Setup resnet34 architecture"}}