{"cell_type":{"8c25abbf":"code","890e755d":"code","19ea4ee7":"code","34e71820":"code","29af93b1":"code","c20a6ee9":"code","2ffec9a1":"code","200220ff":"code","3af04e4a":"code","c0188913":"code","939869cf":"code","45cb87db":"code","9d4fe052":"code","50b7067c":"code","b084de39":"code","6597f7ca":"code","408d4e5d":"code","a4d50d41":"code","d6324954":"code","89f5d396":"code","3692c2a7":"code","8456daa7":"code","f1117279":"code","c38a9022":"code","07f4593d":"code","0935e0de":"code","7c36eb6f":"code","cbf9149a":"code","b581d412":"code","bc478914":"code","91705344":"code","03fa7709":"code","df6522c2":"code","2bbbf4a2":"code","3b4c0808":"code","ef4a79f1":"code","5d7fa5a1":"code","10cab41e":"code","775e6951":"code","de4ca157":"code","a0952169":"code","c8cbfbb1":"code","e6115f68":"code","778420a6":"code","decf3df6":"code","4cdb1ce8":"code","4b44bdfc":"code","24aca423":"code","6cb62095":"code","c02bd107":"code","45802867":"code","1d013991":"code","89462a81":"code","678ddde1":"code","a800dca0":"code","1269931a":"code","f6fc2a53":"code","88446ef4":"code","66442a1b":"code","83bf41bf":"code","8fbd4d38":"code","82cc55d3":"code","f1ddeb7c":"code","6a545050":"code","47e756c8":"code","c5063d5e":"code","d8c4d31e":"code","e3c9353c":"code","5e221096":"code","3288a14d":"code","33f185b6":"code","7a1b5c6f":"code","8a04d9be":"code","df08a499":"code","2f4cfee7":"code","b74df1d2":"code","31ff2d06":"code","bb756097":"code","f00bbf6b":"code","fa5c0310":"code","c50cc641":"code","c9567a72":"markdown","5b307a24":"markdown","95b8993b":"markdown","bc6f06fc":"markdown","9ba85c25":"markdown","c9cc049a":"markdown","b068c9af":"markdown","d3606c73":"markdown","abd010a8":"markdown","67e6c538":"markdown","7028eced":"markdown","47b75849":"markdown","7fe041dd":"markdown","b05edb44":"markdown","4b898669":"markdown","9e6d8ebb":"markdown","03fecbeb":"markdown","95370ec2":"markdown","2cc48bc3":"markdown","bfe54446":"markdown","77957f34":"markdown","9205dd40":"markdown","b53b0020":"markdown","9ca0bd71":"markdown","c2398915":"markdown","4a8a4228":"markdown","bb6559c6":"markdown","adbc67a7":"markdown","a70eae86":"markdown","07594cc3":"markdown","6676f421":"markdown","0d8ebaec":"markdown","c5649572":"markdown","22f69a53":"markdown","7b608a0a":"markdown","ca3895ba":"markdown","1b690178":"markdown","e57fe209":"markdown","a7a343cf":"markdown","74f7e400":"markdown","d9fa8391":"markdown","c4caec27":"markdown","8760badc":"markdown","0fbce6c4":"markdown","8d87098f":"markdown","cc80d4cc":"markdown","e3c164ed":"markdown","9e4f664a":"markdown"},"source":{"8c25abbf":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","890e755d":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import plot_confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder","19ea4ee7":"sns.set_style('darkgrid')","34e71820":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\").set_index('PassengerId')","29af93b1":"data.head()","c20a6ee9":"sns.countplot(x='Survived', data=data)","2ffec9a1":"data.Sex.value_counts()","200220ff":"sns.countplot(x='Sex', data=data)","3af04e4a":"data.groupby('Sex')['Survived'].value_counts()","c0188913":"sns.countplot(x='Survived', hue='Sex', data=data)","939869cf":"sns.histplot(data['Age'])","45cb87db":"data.query('Survived == 0')['Age'].median()","9d4fe052":"data.query('Survived == 0')['Age'].mean()","50b7067c":"data.query('Survived == 1')['Age'].median()","b084de39":"data.query('Survived == 1')['Age'].mean()","6597f7ca":"sns.histplot(data.query('Survived == 1')['Age'])","408d4e5d":"sns.histplot(data.query('Survived == 0')['Age'])","a4d50d41":"sns.boxplot(data=data, x='Survived', y='Age')","d6324954":"p = sns.violinplot(data = data, x = 'Survived', y = 'Age')\np.set(title = 'Age Distribution by Survival', \n        xlabel = 'Survival', \n        ylabel = 'Age Distribution', \n        xticklabels = ['Died', 'Survived']);","89f5d396":"sns.countplot(x='Pclass',hue='Survived',data=data)","3692c2a7":"sns.countplot(x='Survived',hue='Embarked',data=data)","8456daa7":"sns.barplot(x='Embarked',y='Survived',data=data)","f1117279":"data.isnull().mean()*100","c38a9022":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","07f4593d":"y_train = train_data['Survived']","0935e0de":"train_data.head()","7c36eb6f":"X_train = train_data.drop(['Survived', 'PassengerId', 'Cabin', 'Name', 'Ticket'], axis=1)","cbf9149a":"X_train['Sex'] = X_train['Sex'].map({'female': 1, 'male': 0}).astype(int)","b581d412":"X_train['Embarked'] = X_train['Embarked'].fillna('C')","bc478914":"X_train['Embarked'] = X_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","91705344":"X_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())","03fa7709":"X_train.isnull().sum()","df6522c2":"X_train.head()","2bbbf4a2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","3b4c0808":"from sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline","ef4a79f1":"lr = LogisticRegression(max_iter=1000,random_state=42)\nknn = KNeighborsClassifier()\nscaler = StandardScaler()","5d7fa5a1":"models_accuracy = []\n\n# Without feature scaling, logistic regression\nmodels_accuracy.append(cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=5).mean())\n\n# Without feature scaling, knn\nmodels_accuracy.append(cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=5).mean())\n\n#With scaling StandardScaler + LogisticRegression\nmodel_scaling = make_pipeline(StandardScaler(), lr)\nmodels_accuracy.append(cross_val_score(model_scaling, X_train, y_train, scoring='accuracy', cv=5).mean())\n\n#With scaling StandardScaler + Knn\nmodel_scaling_knn = make_pipeline(StandardScaler(), knn)\nmodels_accuracy.append(cross_val_score(model_scaling_knn, X_train, y_train, scoring='accuracy', cv=5).mean())","10cab41e":"accuracy_df = pd.DataFrame({'Accuracy': models_accuracy}, index = ['LogisticRegression', 'KNN', \n                                                             'StandardScaler + LogisticRegression',\n                                                             'StandardScaler + KNN'\n                                                            ])\naccuracy_df","775e6951":"def make_submission(df, pred, n):\n    '''\n    Create submission file\n    :param df: test dataframe\n    :param pred: predictions\n    :n: number of the file\n    :returns: submission file in the appropriate format\n    '''\n    submission = pd.DataFrame({\n            \"PassengerId\": df[\"PassengerId\"],\n            \"Survived\": pred\n        })\n\n    submission.to_csv('submission_titanic_{}.csv'.format(n), index=False)","de4ca157":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","a0952169":"test_data.head()","c8cbfbb1":"X_test = test_data.drop(['PassengerId', 'Cabin', 'Name', 'Ticket'], axis=1)\nX_test['Sex'] = X_test['Sex'].map({'female': 1, 'male': 0}).astype(int)\nX_test['Embarked'] = X_test['Embarked'].fillna('C')\nX_test['Embarked'] = X_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\nX_test['Age'] = X_test['Age'].fillna(X_test['Age'].median())\nX_test['Fare'] = X_test['Fare'].fillna(0)","e6115f68":"X_test.isnull().sum()","778420a6":"model_scaling_knn.fit(X_train, y_train)\ny_pred_knn = model_scaling_knn.predict(X_test)\n#make_submission(test_data, y_pred_knn, '03')","decf3df6":"plt.figure(figsize=(15,6))\nsns.heatmap(data.corr(), vmax=0.6, square=True, annot=True)","4cdb1ce8":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","4b44bdfc":"train_test_data = [train_data, test_data]","24aca423":"for data in train_test_data:\n    data['Sex'] = data['Sex'].map({'female': 1, 'male': 0}).astype(int)","6cb62095":"for data in train_test_data:    \n    data['Age'] = data['Age'].fillna(data['Age'].median())\n    data.loc[data['Age'] <= 11, 'Age'] = 0\n    data.loc[(data['Age'] > 11) & (data['Age'] <= 18), 'Age'] = 1\n    data.loc[(data['Age'] > 18) & (data['Age'] <= 22), 'Age'] = 2\n    data.loc[(data['Age'] > 22) & (data['Age'] <= 27), 'Age'] = 3\n    data.loc[(data['Age'] > 27) & (data['Age'] <= 33), 'Age'] = 4\n    data.loc[(data['Age'] > 33) & (data['Age'] <= 40), 'Age'] = 5\n    data.loc[(data['Age'] > 40) & (data['Age'] <= 66), 'Age'] = 6\n    data.loc[ data['Age'] > 66, 'Age'] = 7","c02bd107":"for data in train_test_data:\n    data['Embarked'] = data['Embarked'].fillna('S')\n    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","45802867":"for data in train_test_data:\n    data['Fare'] = data['Fare'].fillna(train_data['Fare'].mean())","1d013991":"for data in train_test_data:\n    data['Family'] = data['SibSp'] + data['Parch']","89462a81":"pd.crosstab(train_data['Family'], train_data['Survived'])","678ddde1":"sns.barplot(x='Family',y='Survived',data=train_data)","a800dca0":"for data in train_test_data:\n    data['Alone'] = 0\n    data.loc[data['Family'] == 1, 'Alone'] = 1","1269931a":"train_test_data = [train_data, test_data]\nfor dataset in train_test_data:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.')","f6fc2a53":"pd.crosstab(train_data['Title'], train_data['Sex'])","88446ef4":"for data in train_test_data: \n        data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n        data['Title'] = data['Title'].replace('Mlle', 'Miss')\n        data['Title'] = data['Title'].replace('Ms', 'Miss')\n        data['Title'] = data['Title'].replace('Mme', 'Mrs')   ","66442a1b":"pd.crosstab(train_data['Title'], train_data['Sex'])","83bf41bf":"pd.crosstab(train_data['Title'], train_data['Survived'])","8fbd4d38":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\nfor data in train_test_data:\n    data['Title'] = data['Title'].map(title_mapping)","82cc55d3":"for data in train_test_data:\n    data['NameLength'] = data[\"Name\"].apply(lambda x: len(x))","f1ddeb7c":"pd.crosstab(train_data['NameLength'], train_data['Survived'])","6a545050":"for data in train_test_data:\n    data.loc[data[\"NameLength\"] <= 20, \"NameLength\"] = 0\n    data.loc[(data[\"NameLength\"] > 20)  &  (data[\"NameLength\"] <= 40) , \"NameLength\"] = 1\n    data.loc[(data[\"NameLength\"] > 40)  &  (data[\"NameLength\"] <= 55) , \"NameLength\"] = 2\n    data.loc[data[\"NameLength\"] > 55, \"NameLength\"] = 3","47e756c8":"for data in train_test_data:\n    data[\"Deck\"]=data.Cabin.str[0]","c5063d5e":"train_data['Deck'].unique()","d8c4d31e":"test_data['Deck'].unique()","e3c9353c":"for data in train_test_data:\n    data['Deck'] = data['Deck'].fillna('Z')","5e221096":"pd.crosstab(train_data['Deck'], train_data['Survived'])","3288a14d":"deck = {'Z':0, 'T':0, 'G':0, 'F':0, 'E':0, 'D':1, 'C':1, 'B':1, 'A':1}\nfor data in train_test_data:\n    data['Deck'] = data['Deck'].map(deck).astype(int)","33f185b6":"plt.figure(figsize=(20,8))\nsns.heatmap(train_data.drop(['PassengerId'], axis=1).corr(), vmax=0.6, square=True, annot=True)","7a1b5c6f":"X_train = train_data.drop(['Survived',\n                           'PassengerId',\n                           'Name', \n                           'Ticket', \n                           'Cabin', \n                           'SibSp', \n                           'Parch', \n                           'Family'\n                          ], axis=1)\ny_train = train_data['Survived']\nX_test = test_data.drop(['PassengerId', \n                         'Name',\n                         'Ticket', \n                         'Cabin',\n                         'SibSp', \n                         'Parch', \n                         'Family'\n                        ], axis=1)","8a04d9be":"X_train.head(3)","df08a499":"X_test.head(3)","2f4cfee7":"X_train.shape, X_test.shape","b74df1d2":"from sklearn.model_selection import KFold\nk_fold = KFold(n_splits=5, shuffle=True, random_state=42)","31ff2d06":"lr = LogisticRegression(C=0.05, max_iter=10000, random_state=42)\nknn = KNeighborsClassifier(n_neighbors=13)\nscaler = StandardScaler()","bb756097":"models_accuracy = []\n\n# Without feature scaling, original model\nmodels_accuracy.append(cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=k_fold).mean())\n\n#With scaling StandardScaler + LogisticRegression\nmodel_scaling = make_pipeline(StandardScaler(), lr)\nmodels_accuracy.append(cross_val_score(model_scaling, X_train, y_train, scoring='accuracy', cv=k_fold).mean())\n\n# Without feature scaling, original model\nmodels_accuracy.append(cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=k_fold).mean())\n\n#With scaling StandardScaler + Knn\nmodel_scaling_knn = make_pipeline(StandardScaler(), knn)\nmodels_accuracy.append(cross_val_score(model_scaling_knn, X_train, y_train, scoring='accuracy', cv=k_fold).mean())\n\nmodels_accuracy","f00bbf6b":"accuracy_df = pd.DataFrame({'Accuracy': models_accuracy}, \n                           index = ['LogisticRegression', 'StandardScaler+LogisticRegression',\n                                    'KNN', 'StandardScaler+KNN'])\naccuracy_df","fa5c0310":"model_scaling_knn.fit(X_train, y_train)\ny_pred_scale_knn = model_scaling_knn.predict(X_test)","c50cc641":"make_submission(test_data, y_pred_scale_knn, '29')","c9567a72":"It shows that median is 28 year old, and mean is 29 year old. We can also tell that the distribution is normal when you have similar median and mean.","5b307a24":"The next one is 'Embarked'. Let's fill the empty value with 'S' and convert the feature to numeric format.","95b8993b":"Let's merge some titles","bc6f06fc":"I read that persons with long names survived more than with short. I think it's connected with the social status - rich people have longer names.  \nLet's create a separate feature for the length of name.","9ba85c25":"let's merge values of this feature","c9cc049a":"Now let's look on 'Name' feature. All names have a title. Let's get it from names and create a separate feature. We are going to merge persons by 'Title', so we can say who was more likely to survive.","b068c9af":"**Summary:**  \nOn Kaggle the result is not great. It's about 0.74. KNN was overfitted on the train data.","d3606c73":"We can see on correlation matrix that 'Fare' has a positive correlation with target. So let's use it in our calculations.  \nLet's fill empty values with 'mean' value","abd010a8":"So StandardScaler+KNN gives us the better accuracy. Let's try to make prediction and submit it","67e6c538":"### Dataset\n\nRead the description here: https:\/\/www.kaggle.com\/c\/titanic\/data. Download the dataset and place it in the *data\/titanic\/* folder in your working directory.\nYou will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https:\/\/www.kaggle.com\/c\/titanic\/overview\/evaluation.  \n","7028eced":"Then let's work with 'Age' feature.  \nWe saw on plots that there is a correlation between person's age and survival, not great but it could help.  \nLet's fill empty values with median and split persons due to some ages:","47b75849":"Persons on decks 'A', 'B', 'C', 'D', 'E' were more likely to survive. Let's convert this feature to the numeric format according to this knowledge.  \nHonestly, we don't know about test data. And we can't say for 100% that it's the same for test_data.  \nBut I think that it's true for 'A', 'B', 'C', 'D' decks.  ","7fe041dd":"Overall plots tell us that the passengers' age is distributed around mid-end 20's. ","b05edb44":"Load the test set and make the predictions. Submit them to kaggle and see the results :)\nSelect the best model, load the test set and make the predictions. Submit them to kaggle.\n\n**Note**. X points will depend on your kaggle leaderboard score.\n$$ f(score) = 0.5, \\ \\ 0.79 \\leq score < 0.81,$$\n$$ f(score) = 1.0, \\ \\ 0.81 \\leq score < 0.83,$$ \n$$ f(score) = 2.5, \\ \\ 0.83 \\leq score $$ \nYour code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible.","4b898669":"As we can see, single persons and large families were far less likely to survive than passengers with not large family. let's transform this feature to another one - 'Alone'. ","9e6d8ebb":"Transform test data in the same way as train data","03fecbeb":"Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?","95370ec2":"Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations.","2cc48bc3":"From the plot above, there seems to be no clear correlation between survival and the age of a person on the Titanic.  \nLet's have a look on another one plot.","bfe54446":"There were more men than women. I think we have relationship between gender and survival. Men tried to survive women and allowed them to sit into boats. One more reason - workers (or sailors) on Titanic were men. As we know a lot of workers were died. So, women survived more than men.","77957f34":"I think it's not bad. Let's try to learn it, but after deleting some features","9205dd40":"Initially, let's look on correlation matrix","b53b0020":"Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!","9ca0bd71":"Read test data from the file","c2398915":"Let's look on correlation matrix","4a8a4228":"For the first attempt let's drop Survived (it's the target), PassengerId (no useful information for us), Cabin (a lot of missing values), PassengerID, Name and Ticket columns.  \nBoth Sex and Embarked columns let's convert to numeric.","bb6559c6":"Some features are categorical, so we can't see them into correlation matrix.  \nLet's upload datasets one more time and start our work from scratch","adbc67a7":"Now we can see that KNN is still better, but accuracy is less than in the first attempt. So, maybe it won't be so overfitted and is more stable now.  \nLet's make prediction on test_data and create submission file","a70eae86":"There were a lot of different researches and attempts. I leave the last one with the highest score on Kaggle LB.  \nAll feature transformations I'm going to do on the both datasets.  \nInitially, let's transform 'Sex' feature from categorical to numeric cause we saw that women survived more than men previously on plots. So, this feature could be important for the model.","07594cc3":"Make prediction and create submission file","6676f421":"I can see from this histogram that many children is below 5 years old. Some of them are babies which we see that there's a peak around 1 year. This histogram will have an almost normal distribution if there isn't a peak around 1 year old.","0d8ebaec":"How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?","c5649572":"Find the percentage of missing values for each feature. ","22f69a53":"Let's fill empty values with some char, e.g. 'Z'. And as we can see test_data doesn't include 'T' value. ","7b608a0a":"From the plots above, we can see that passengers in the third class were far less likely to survive than passengers in the first and second class.  \nAnd we can see that people from Port of Embarkation = \"C\" (Cherbourg) were far more likely to survive.","ca3895ba":"So from the above plot we can understand that, some of the older people died (between 50-70) and some of the younger people (between 20-40) survived more.  \nThe distribution of the age shows bimodal distribution of people who survived. Many old people died, though we see 1 80 year-old man survived. ","1b690178":"### Modelling","e57fe209":"Both 'Sibsp' and 'Parch' features a low correlation with target feature. Let's try to combine them into something more powerfull by creating a new feature and analyze it.","a7a343cf":"Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both).","74f7e400":"## Part 1: Titanic survival prediction","d9fa8391":"# Classification. Linear models and KNN","c4caec27":"Initially we deleted 'Cabin' feature. Now we can try to interpret it. Cabin includes Deck number. Let's get it.","8760badc":"### EDA","0fbce6c4":"Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n\n- Cabin attribute has too much missing values, so I'll drop it in the first attempt.  \n- Embarked attribute I can analyze due to values balance. And maybe put the value of attribute with the lowest total value. Or maybe analyze the target values due to rows with missing values and put the value according to probability of survation for the Embarked values. E.g., if Embarked value \"C\" has the most probability of survation and rows with missing values equals to Survived = 1, so put value \"C\" for all missing values.  \n- I don't know how to fill Age missing values. Initially, I think I'll put median value due to no clear correlation between survival and the age of a person on the Titanic and that median value for survived and not survived is the same. So, if we put median value we won't increase significance of some class.","8d87098f":"As we can see in correlation matrix, 'Pclass' feature has a negative strong correlation with target, but as we saw on plots, this feature will influence on target.   \nSo, let's put it as is.","cc80d4cc":"So, let's convert 'Title' feature to numeric format.","e3c164ed":"Let's drop both target and Cabin attribute from the dataset","9e4f664a":"We can now visualize the variable \u2018Embarked\u2019 with \u2018Survived.\u2019"}}