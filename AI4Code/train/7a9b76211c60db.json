{"cell_type":{"979d615b":"code","d10591f7":"code","45d998f9":"code","a55fbbaa":"code","39d2dd00":"code","05db7a4e":"code","025c1c65":"code","52ec91f0":"code","b0677e45":"code","4fe5a3df":"code","2d9266ca":"code","764d3df6":"code","f5b12815":"code","82347ee1":"code","7783e001":"code","e8f64a37":"code","c44064ad":"markdown","a6b4f0bb":"markdown","0045f62f":"markdown","578e5318":"markdown","2db081a1":"markdown","880c6fe1":"markdown","1ba413ea":"markdown","2ed5bd38":"markdown","04ef1b34":"markdown","d91c6576":"markdown","edbeb524":"markdown","04cd03e3":"markdown","0afc317e":"markdown","6077ff1f":"markdown"},"source":{"979d615b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re # for pattern matching, like grep in r\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","d10591f7":"data_entry = pd.read_csv('..\/input\/nihdata\/Data_Entry_2017.csv')\ndata_entry.head()","45d998f9":"data_entry_subset = data_entry.loc[:, 'Image Index':'Finding Labels']\ndata_entry_subset.head()","a55fbbaa":"split = pd.DataFrame(data_entry_subset['Finding Labels'].str.split('|').tolist())\n\ntemp = []\nfor i in split:\n    temp.append(split[i].unique())\n\nflatten = pd.DataFrame(temp).values.flatten()\n\nunique = []\nfor x in flatten:\n    if x not in unique:\n        unique.append(x)\n\nlabels = list(filter(None, unique))\nlabels","39d2dd00":"data_entry_subset[\"Finding Labels\"] = data_entry_subset[\"Finding Labels\"].apply(lambda x:x.split(\"|\"))\ndata_entry_subset.head()","05db7a4e":"from collections import Counter\nlabels_count = Counter(label for lbs in data_entry_subset[\"Finding Labels\"] for label in lbs)\n\nlabels_count","025c1c65":"total_count = sum(labels_count.values())\nclass_weights = {cls: total_count \/ count for cls, count in labels_count.items()}\n\nclass_weights","52ec91f0":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in data_entry_subset[:9].values:\n    img = cv2.imread('..\/input\/nihdata\/images_001\/images\/{}'.format(f))\n    ax[i \/\/ 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i \/\/ 3, i % 3].set_title('{} - {}'.format(f, l))\n    i += 1\n    \nplt.show()","b0677e45":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True,\n    validation_split=0.2) \n\ndef get_flow_from_dataframe(generator, \n                            dataframe, \n                            subset,\n                            image_shape=(150, 150),\n                            batch_size=32):\n    \n    train_generator_1 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '..\/input\/nihdata\/images_001\/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n\n    train_generator_2 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '..\/input\/nihdata\/images_002\/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n    \n    train_generator_3 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '..\/input\/nihdata\/images_003\/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n    \n    train_generator_4 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '..\/input\/nihdata\/images_004\/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n    \n    while True:\n        x_1 = train_generator_1.next()\n        x_2 = train_generator_2.next()\n        x_3 = train_generator_3.next()\n        x_4 = train_generator_4.next()\n\n        yield np.concatenate((x_1[0], x_2[0], x_3[0], x_4[0]), axis = 0), np.concatenate((x_1[1], x_2[1], x_3[1], x_4[1]), axis = 0)","4fe5a3df":"train_gen = get_flow_from_dataframe(generator=datagen, \n                                    dataframe=data_entry_subset, \n                                    subset = 'training',\n                                    image_shape=(150, 150),\n                                    batch_size=32)\n\nval_gen = get_flow_from_dataframe(generator=datagen, \n                                    dataframe=data_entry_subset, \n                                    subset = 'validation',\n                                    image_shape=(150, 150),\n                                    batch_size=32)","2d9266ca":"generator = datagen.flow_from_dataframe(data_entry_subset, target_size=(150,150),\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '..\/input\/nihdata\/images_001\/images',\n                                                      batch_size=32,\n                                                      classes = labels)\n\ngenerator.class_indices","764d3df6":"class_weights_index = {\n 1: 50.985951008645536,\n 5: 56.25476947535771,\n 4: 10.628294660959675,\n 10: 2.3448418680936367,\n 7: 623.5110132158591,\n 8: 7.114557152910425,\n 9: 24.478900034590108,\n 11: 22.356183857210553,\n 0: 12.244744355048015,\n 14: 26.695020746887966,\n 12: 41.81299852289513,\n 13: 98.9077568134172,\n 6: 83.94839857651246,\n 3: 61.45766391663048,\n 2: 30.327190914934647\n}","f5b12815":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), padding = 'same',\n                        activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(15, activation='sigmoid'))","82347ee1":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","7783e001":"step_per_train = 28000\/\/32\nstep_per_val = 6999\/\/32\n\nhistory = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = step_per_train, \n    validation_data  = val_gen,\n    validation_steps = step_per_val,\n    class_weight = class_weights_index,\n    use_multiprocessing = True,\n    epochs = 5)","e8f64a37":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nfig = plt.figure(figsize=(16,9))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()","c44064ad":"# Import required packages\n\nThis session is to import basic packages required for upcoming data manipulation, visualization and analysis.","a6b4f0bb":"# Model Optimization\nThis is to instruct the model to improve its performance by learning from its own mistake.","0045f62f":"**Remark:** From `Finding Labels`, we can tell this is a multi-labelled classification instead of binary (Yes\/No). Spliting the column and getting the unique values are required.","578e5318":"# To read data\n\n## Data_Entry_2017.csv","2db081a1":"**Remark:** To understand the data structure, lets take *Image Index* 00000001_001.png as example, that particular patient has two disease conditions that are Cardiomegaly and Emphysema. The classification later on will need to be managed to predict these two conditions for that patient instead of one condition (either Cardiomegaly or Emphysema) only.\n\nNow, we look at the count distribution of each disease.","880c6fe1":"# Data frame pre-processing\n\nThis session is to process the images (unstructed data) to machine learnable format (to let the computer understands the images in its way).\n\nWe will also split the entire dataset into training set and validation set for model developement and model validation respectively.","1ba413ea":"# Model Development\nThis session is to build a convolutional neural network based deep learning model that can perform a multi-label classification. Since this is just a mini-project and due to the limitation on computation power, I designed a much \"shallow\" and \"simple\" model's architecture instead of a complex one.","2ed5bd38":"**Remark:** We first look at the first five rows of the *Data_Entry_2017.csv* file and there is 12 columns consisting patient IDs, findings on disease condition and other information. For the upcoming classification, we only need the patient IDs and corresponding findings. Hence, a subset with interested columns is created.","04ef1b34":"## Images\n\n**Programing Note: ** `f, l` are dummy variables representing two columns of *data_entry_subset*.\n\nThe following section will show the images of first 9 patients with their labelled conditions.","d91c6576":"# Model Training\nThis session is to fit the data into the model.","edbeb524":"**Remark:** There are 15 disease condition including *No Finding*. Note that *Cardiomegaly* etc are not our sole interested point of prediction. Hence, it's necessasry to manipulate `Finding Labels` to split all the different disease tags.","04cd03e3":"# Performance Visualization","0afc317e":"## Derive class weights\nAs per the previous remarks, due to the imbalance class, we will define `class_weights_index` based on `class_weights` derived. ","6077ff1f":"**Remark:**\n\nFrom the frequency table, we found out that there are two types of imbalances:\n1. Imbalance across different classes, i.e. some disease like *Effusion* and *Infiltration* have high frequencies wheares others have extreme low frquencies.\n2. Imbalance between positive and negative in some classes, i.e. if we look at each disease one by one, more than 90% of patients don't have that condition and there will a risk of giving us a model with high false negative.\n\nWe will have to derive a `class_weights` to adjust the imbalance distribution later which will be used to fit into the `fit` function."}}