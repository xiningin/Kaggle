{"cell_type":{"fd50d85c":"code","ffc307be":"code","9f908529":"code","ffe30949":"code","19677255":"code","67a50ac4":"code","5866175d":"code","ee8de24b":"code","e71d0dc7":"code","f1c65e5e":"code","43d5650b":"code","f5ad4c36":"code","1edc73b8":"code","b79b3d40":"code","d531abae":"code","a92f092e":"code","e0a7b4d9":"code","b1be7c98":"code","a1407fb9":"code","9951a25b":"code","8f982f6e":"code","50973d5a":"code","a9a0a90a":"code","ad468621":"code","99f0d7ac":"code","ae12b9e5":"code","3d8287bc":"code","98a7572b":"code","3fb01f60":"code","d2d784d0":"code","212de42f":"code","2801d191":"code","9ac45978":"code","d42b0d1e":"code","c5caaa58":"code","eb97132b":"code","abd7e27a":"code","0ff70a59":"code","1c5a1746":"code","fc55ae5f":"code","3aa2e21d":"code","35db00c2":"code","38785f80":"code","703a7fd9":"code","8aecb4a1":"code","3badaeef":"code","b06ef9f9":"code","225de5d9":"code","1a0c2931":"code","60fbfcba":"code","0dbf57f4":"code","7afbc9b6":"code","443c9db2":"code","cd412f69":"markdown","f18e5670":"markdown","5b9a8a1d":"markdown","da478d2e":"markdown","60291f15":"markdown","896cc062":"markdown","8eb37e56":"markdown","02098e9d":"markdown","ab351389":"markdown","06f97ba3":"markdown","7860a128":"markdown","de813285":"markdown","a4d10598":"markdown","551ac715":"markdown","8bfd4efb":"markdown","bd104798":"markdown","7c31cbd1":"markdown","4bf5247e":"markdown","7156b67f":"markdown","41b44ff3":"markdown","076f77f6":"markdown","38384e49":"markdown","bcd27696":"markdown","c9ec9947":"markdown","e8c619d0":"markdown","b87573e6":"markdown","5da5bc4d":"markdown","66f73e68":"markdown","5aea2911":"markdown","1524f04e":"markdown","a1d573e4":"markdown"},"source":{"fd50d85c":"import pandas as pd\nimport numpy as np\n\nimport random , os \nfrom tqdm.notebook import tqdm","ffc307be":"from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVR, SVC\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom sklearn.linear_model import SGDRegressor, BayesianRidge\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport warnings \nwarnings.simplefilter('ignore')","9f908529":"!pip install catboost\nfrom catboost import CatBoostClassifier","ffe30949":"train = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntest = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\nsub = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","19677255":"train.isnull().sum()","67a50ac4":"train['age_approx'].fillna(train['age_approx'].mean(),inplace = True)\ntrain['sex'].fillna('unknown_sex',inplace = True)\n\ntrain['anatom_site_general_challenge'].fillna('unknown_anatom',inplace = True)\ntest['anatom_site_general_challenge'].fillna('unknown_anatom',inplace = True)","5866175d":"one_hot_anatom = pd.get_dummies(train.anatom_site_general_challenge ,prefix = 'anatom')\ntrain = train.join(one_hot_anatom)\n\none_hot_anatom = pd.get_dummies(test.anatom_site_general_challenge ,prefix = 'anatom')\ntest = test.join(one_hot_anatom)","ee8de24b":"'''\none_hot_sex = pd.get_dummies(train.sex, prefix='sex')\n#one_hot_diagnosis = pd.get_dummies(train.diagnosis , prefix = 'disgnosis')\n\ntrain = train.join(one_hot_sex)\n#train = train.join(one_hot_diagnosis)\n\ntrain['id'] = train['patient_id'].map(lambda x : int(x[3:]))'''","e71d0dc7":"'''\none_hot_sex = pd.get_dummies(test.sex, prefix='sex')\ntest = test.join(one_hot_sex)\ntest['id'] = test['patient_id'].map(lambda x : int(x[3:]))'''","f1c65e5e":"'''train.drop(['sex','diagnosis','anatom_site_general_challenge','benign_malignant','image_name','patient_id'],axis = 1,inplace = True)\ntest.drop(['sex','anatom_site_general_challenge','image_name','patient_id'],axis = 1,inplace = True)\ntrain.drop(['sex_unknown_sex','anatom_unknown_anatom'],axis=1, inplace = True)'''","43d5650b":"from sklearn.preprocessing import LabelEncoder \n\nle = LabelEncoder()\n\ntrain['sex_encoding'] = le.fit_transform(train['sex'].astype(str))\ntest['sex_encoding'] = le.transform(test['sex'].astype(str))\n\ntrain['anatom_site_general_challenge_encoding'] = le.fit_transform(train['anatom_site_general_challenge'].astype(str))\ntest['anatom_site_general_challenge_encoding'] = le.transform(test['anatom_site_general_challenge'].astype(str))","f5ad4c36":"train['n_images'] = train['patient_id'].map(train.groupby(['patient_id']).image_name.count())\ntest['n_images'] = test['patient_id'].map(test.groupby(['patient_id']).image_name.count())","1edc73b8":"from sklearn.preprocessing import KBinsDiscretizer\n\ncategorize = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\ntrain['n_images_encoding'] = categorize.fit_transform(train['n_images'].values.reshape(-1,1)).astype(int).squeeze()\ntest['n_images_encoding'] = categorize.transform(test['n_images'].values.reshape(-1,1)).astype(int).squeeze()","b79b3d40":"from sklearn.preprocessing import LabelEncoder \n\nenc = LabelEncoder()\n\ntrain['age_enc'] = enc.fit_transform(train['age_approx'].astype('str'))\ntest['age_enc'] = enc.fit_transform(test['age_approx'].astype('str'))","d531abae":"train_images = train['image_name'].values\ntrain_sizes = np.zeros(train.shape[0])\n\nfor i, img_path in enumerate(tqdm(train_images)) :\n    train_sizes[i] = os.path.getsize(os.path.join('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/',f'{img_path}.jpg'))\n    \ntrain['image_size'] = train_sizes\n\ntest_images = test['image_name'].values\ntest_sizes = np.zeros(test.shape[0])\n\nfor i, img_path in enumerate(tqdm(test_images)) :\n    test_sizes[i] = os.path.getsize(os.path.join('..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/',f'{img_path}.jpg'))\n\ntest['image_size'] = test_sizes","a92f092e":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\ntrain['image_size_scaled'] = scaler.fit_transform(train['image_size'].values.reshape(-1,1))\ntest['image_size_scaled'] = scaler.transform(test['image_size'].values.reshape(-1,1))","e0a7b4d9":"from sklearn.preprocessing import KBinsDiscretizer \n\ncategorize = KBinsDiscretizer(n_bins = 10,encode = 'ordinal' , strategy = 'uniform')\n\ntrain['image_size_encoding'] = categorize.fit_transform(train.image_size_scaled.values.reshape(-1,1)).astype(int).squeeze()\ntest['image_size_encoding'] = categorize.fit_transform(test.image_size_scaled.values.reshape(-1,1)).astype(int).squeeze()","b1be7c98":"train_color = pd.read_csv('..\/input\/mean-color-isic2020\/train_color.csv')\ntest_color = pd.read_csv('..\/input\/mean-color-isic2020\/test_color.csv')","a1407fb9":"train['mean_color'] = train_color.values\ntest['mean_color'] = test_color.values","9951a25b":"from sklearn.preprocessing import KBinsDiscretizer \n\ncategorize  = KBinsDiscretizer(n_bins = 10 , encode = 'ordinal' , strategy = 'uniform')\n\ntrain['mean_color_encoding'] = categorize.fit_transform(train['mean_color'].values.reshape(-1,1)).astype(int).squeeze()\ntest['mean_color_encoding'] = categorize.transform(test['mean_color'].values.reshape(-1,1)).astype(int).squeeze()","8f982f6e":"train['age_id_min'] = train['patient_id'].map(train.groupby(['patient_id']).age_approx.min())\ntrain['age_id_max'] = train['patient_id'].map(train.groupby(['patient_id']).age_approx.max())\n\ntest['age_id_min'] = test['patient_id'].map(test.groupby(['patient_id']).age_approx.min())\ntest['age_id_max'] = test['patient_id'].map(test.groupby(['patient_id']).age_approx.max())","50973d5a":"train['age_approx_mean'] = train['age_approx'].map(train.groupby(['age_approx'])['target'].mean())\ntest['age_approx_mean'] = test['age_approx'].map(train.groupby(['age_approx'])['target'].mean())","a9a0a90a":"train['sex_encoding_mean'] = train['sex_encoding'].map(train.groupby(['sex_encoding'])['target'].mean())\ntest['sex_encoding_mean'] = test['sex_encoding'].map(train.groupby(['sex_encoding'])['target'].mean())","ad468621":"train['anatom_site_general_challenge_encoding_mean'] = train['anatom_site_general_challenge_encoding'].map(train.groupby(['anatom_site_general_challenge_encoding'])['target'].mean())\ntest['anatom_site_general_challenge_encoding_mean'] = test['anatom_site_general_challenge_encoding'].map(train.groupby(['anatom_site_general_challenge_encoding'])['target'].mean())","99f0d7ac":"train['n_images_encoding_mean'] = train['n_images_encoding'].map(train.groupby(['n_images_encoding'])['target'].mean())\ntest['n_images_encoding_mean'] = test['n_images_encoding'].map(train.groupby(['n_images_encoding'])['target'].mean())","ae12b9e5":"train['image_size_encoding_mean'] = train['image_size_encoding'].map(train.groupby(['image_size_encoding'])['target'].mean())\ntest['image_size_encoding_mean'] = test['image_size_encoding'].map(train.groupby(['image_size_encoding'])['target'].mean())","3d8287bc":"corr = train.corr(method = 'pearson')\ncorr = corr.abs()\ncorr.style.background_gradient(cmap='inferno')","98a7572b":"corr = test.corr(method = 'pearson')\ncorr = corr.abs()\ncorr.style.background_gradient(cmap='inferno')","3fb01f60":"test.columns","d2d784d0":"test.columns","212de42f":"features = [\n    \n    #'image_name',\n    #'patient_id',\n    #'sex', \n    'age_approx',\n    #'anatom_site_general_challenge', \n    'sex_encoding',\n    'anatom_site_general_challenge_encoding',\n    'n_images',\n    #'n_images_encoding',\n    # 'age_enc',\n   # 'image_size',\n    'image_size_scaled',\n   # 'image_size_encoding',\n    'mean_color',\n    #'mean_color_encoding',\n    'age_id_min',\n    'age_id_max',\n   # 'age_approx_mean',\n    #'sex_encoding_mean',\n    #'anatom_site_general_challenge_encoding_mean',\n   # 'n_images_encoding_mean',\n   # 'image_size_encoding_mean',\n       # 'anatom_head\/neck',\n       # 'anatom_lower extremity',\n       #'anatom_oral\/genital',\n       # 'anatom_palms\/soles', \n      #  'anatom_torso',\n     #  'anatom_unknown_anatom', \n    #'anatom_upper extremity'\n    \n]","2801d191":"X = train[features]\ny = train['target']","9ac45978":"xgb = XGBRegressor()\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['binary:logistic'],\n              'learning_rate': [0.04], #so called `eta` value\n              'max_depth': [9],\n              'min_child_weight': [5],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n           'n_estimators': [500]}\n\nxgb_grid = GridSearchCV(xgb,\n                        parameters,\n                        cv = 4,\n                        n_jobs = 5,\n                        verbose=True\n                       )\n\nxgb_grid.fit(X,\n         y)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","d42b0d1e":"xgb = XGBRegressor(\n                nthread=4, #when use hyperthread, xgboost may become slower\n              objective='binary:logistic',\n              learning_rate= 0.04, #so called `eta` value\n              max_depth = 11,\n              min_child_weight = 5,\n              silent = 1,\n              subsample= 0.7,\n              colsample_bytree = 0.7,\n           n_estimators =  500\n\n)\n\nfolds = StratifiedKFold(n_splits = 5 , shuffle = True, random_state = 42 )\ncv_results = cross_val_score(xgb ,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","c5caaa58":"xgb.fit(X,y)\npredictions = xgb.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('xgb_anatom_ohe.csv',index = False)\nsub.head()","eb97132b":"model = CatBoostClassifier()\nparameters = {'depth'         : [6],\n                  'learning_rate' : [0.03],\n                  'iterations'    : [600]\n                 }\ngrid1 = GridSearchCV(estimator=model, param_grid = parameters, cv = 3, n_jobs=-1)\ngrid1.fit(X, y)    \n    # Results from Grid Search\nprint(\"\\n========================================================\")\nprint(\" Results from Grid Search \" )\nprint(\"========================================================\")       \nprint(\"\\n The best estimator across ALL searched params:\\n\",\n          grid1.best_estimator_)    \nprint(\"\\n The best score across ALL searched params:\\n\",\n          grid1.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",\n          grid1.best_params_)  \nprint(\"\\n ========================================================\")","abd7e27a":"cat = CatBoostClassifier(\n    depth = 6,\n    iterations = 600,\n    learning_rate = 0.03,\n    verbose = 0\n)\n\ncv_results = cross_val_score(cat ,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","0ff70a59":"cat.fit(X,y)\npredictions = cat.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('cat_sub.csv',index = False)\nsub.head()","1c5a1746":"model  = GaussianNB()\n\ncv_results = cross_val_score(model,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","fc55ae5f":"model.fit(X,y)\npredictions = model.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('gaussian_sub.csv',index = False)\nsub.head()","3aa2e21d":"model  = MultinomialNB()\n\ncv_results = cross_val_score(model,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","35db00c2":"model = AdaBoostClassifier()\nparameters = {'n_estimators' : [25],\n                  'learning_rate' : [0.015],\n                 }\ngrid1 = GridSearchCV(estimator=model, param_grid = parameters, cv = 3, n_jobs=-1)\ngrid1.fit(X, y)    \n    # Results from Grid Search\nprint(\"\\n========================================================\")\nprint(\" Results from Grid Search \" )\nprint(\"========================================================\")       \nprint(\"\\n The best estimator across ALL searched params:\\n\",\n          grid1.best_estimator_)    \nprint(\"\\n The best score across ALL searched params:\\n\",\n          grid1.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",\n          grid1.best_params_)  \nprint(\"\\n ========================================================\")","38785f80":"model  = AdaBoostClassifier(\n)\n\ncv_results = cross_val_score(model,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","703a7fd9":"model.fit(X,y)\npredictions = model.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('ada_sub.csv',index = False)\nsub.head()","8aecb4a1":"model = LGBMClassifier()\nparameters = {'n_estimators' : [50,100,150],\n                  'learning_rate' : [0.015,0.01,0.005],\n                 }\ngrid1 = GridSearchCV(estimator=model, param_grid = parameters, cv = 3, n_jobs=-1)\ngrid1.fit(X, y)    \n    # Results from Grid Search\nprint(\"\\n========================================================\")\nprint(\" Results from Grid Search \" )\nprint(\"========================================================\")       \nprint(\"\\n The best estimator across ALL searched params:\\n\",\n          grid1.best_estimator_)    \nprint(\"\\n The best score across ALL searched params:\\n\",\n          grid1.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",\n          grid1.best_params_)  \nprint(\"\\n ========================================================\")","3badaeef":"from lightgbm import LGBMClassifier","b06ef9f9":"model  = LGBMClassifier()\n\ncv_results = cross_val_score(model,X , y, cv = folds, scoring = 'roc_auc', verbose = 3 ) \nprint(cv_results.mean())","225de5d9":"model.fit(X,y)\npredictions = model.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('lgbm_sub.csv',index = False)\nsub.head()","1a0c2931":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout ,BatchNormalization\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf","60fbfcba":"!pip install tensorflow-addons=='0.9.1'\nimport tensorflow_addons as tfa","0dbf57f4":"from sklearn.utils import class_weight \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train.target),\n                                                 train.target)\n\nclass_weights = { 0 :  0.50897302 , 1 : 28.36130137 }\n\nclassweights =[item for k in class_weights for item in (k, class_weights[k])]\nprint(classweights)","7afbc9b6":"model = Sequential()\nmodel.add(Dense(512, activation='relu', input_dim=(8),\n                kernel_regularizer=regularizers.l2(0.01),\n                activity_regularizer=regularizers.l1(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation='sigmoid'))\n\nadam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=10**-8, decay=0.0001, amsgrad=False)\nmodel.compile(optimizer= adam,\n              loss ='binary_crossentropy', # tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO)\n              metrics=['accuracy',tf.keras.metrics.AUC()])\nhist = model.fit(X, y,\n                    batch_size=32,\n                    epochs=100,\n                    verbose=1,\n                    class_weight = class_weights\n                )","443c9db2":"model.fit(X,y)\npredictions = model.predict(test[features])\nsub['target'] = predictions\nsub.to_csv('nn_sub.csv',index = False)\nsub.head()","cd412f69":"## Categorize Image size :","f18e5670":"# Preprocessing \/ Feature Engineering :","5b9a8a1d":"## Adding mean color (using extra data) :","da478d2e":"## Image Size :","60291f15":"Special Thanks to : @awsaf49 \n\nplease check and upvote his kernel : https:\/\/www.kaggle.com\/awsaf49\/xgboost-tabular-data-ml-cv-85-lb-787","896cc062":"## AdaBoost : ","8eb37e56":"## Mean Encoding of Image size :","02098e9d":"## Mean Encoding of Number of Images :","ab351389":"## Mean Encoding of anatom :","06f97ba3":"## Train Correlation Map :","7860a128":"## Label Encoding Sex , Anatom : ","de813285":"## Label Encoding Age : ","a4d10598":"## Ensembling best results :","551ac715":"## XGBoost : (0.744 on LB) ","8bfd4efb":"## Scaling Image sizes : ","bd104798":"If you like my kernel, don't forget to upvote, you can also check my work on image data :\n\nhttps:\/\/www.kaggle.com\/aziz69\/efficientnets-augs-0-925","7c31cbd1":"## LightGBM :","4bf5247e":"## Multinomial NB, Gaussian NB :","7156b67f":"xgb with these features seems good => 0.744 on LB\n\ncatboost => 0.5 (seems bad)\n\ntry lgbm\n\ntry adaboost\n\ntry Neural Nets\n\ntry more tuning ","41b44ff3":"## Categorize number of images per patient :","076f77f6":"Play around with these feature ( you can get up to 0.8 LB)","38384e49":"# Modeling : ","bcd27696":"## Mean Encoding of sex :","c9ec9947":"## Neural Nets :","e8c619d0":"# One Hot Encoding Anatom site challenge : ","b87573e6":"## Mean Encoding of age :","5da5bc4d":"working on it ... stay tuned ! ","66f73e68":"## Test Correlation Map :","5aea2911":"## Min-Max age of patient :","1524f04e":"## CatBoost (0.5 on LB) :","a1d573e4":"## Images per Patient :"}}