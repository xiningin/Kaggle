{"cell_type":{"5a05c90d":"code","4a61f3ed":"code","a0b12a23":"code","fb889192":"code","0f19dfe1":"code","6751e930":"code","49ead875":"code","5d26320e":"code","cc2e89f1":"code","dfca04a0":"code","132b98db":"code","502870e3":"code","7d4ab5d2":"code","67a62494":"code","8b2b9652":"code","b6a73439":"code","252647ab":"code","7a35199f":"code","616c1473":"code","29933bf4":"code","fa149a71":"code","30188959":"code","c2c2a17c":"code","da01434e":"code","011d0c68":"code","47eff972":"code","a5ff576a":"code","b55aa577":"code","c486be0e":"code","25262f43":"code","e3e35739":"code","144b3483":"code","81cb7763":"code","6c149e9b":"code","e503b7f3":"code","bbf8aeea":"code","dfa2ed6e":"code","f446a661":"markdown","cb07e8a6":"markdown","c8bb0afe":"markdown","24cad436":"markdown","92e9e7a7":"markdown","5baa45cf":"markdown","b937501c":"markdown"},"source":{"5a05c90d":"import sys\n!git clone --quiet https:\/\/github.com\/yabhi0807\/libml1.git \/kaggle\/tmp\/fastai # This is my repo with all the fastai(updated) libraries \nsys.path.append('\/kaggle\/tmp\/fastai')\n!mkdir \/kaggle\/tmp\/data\/\n!ln -s \/kaggle\/tmp\/* \/kaggle\/working\/","4a61f3ed":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","a0b12a23":"from fastai.conv_learner import *","fb889192":"PATH = '\/kaggle\/tmp\/data\/planet\/'","0f19dfe1":"os.makedirs('\/kaggle\/tmp\/data\/planet\/models', exist_ok=True)\nos.makedirs('\/kaggle\/tmp\/cache\/planet\/tmp', exist_ok=True)","6751e930":"!cp -r ..\/input\/planets-dataset\/planet\/planet\/train-jpg \/kaggle\/tmp\/data\/planet\/train-jpg\n!cp -r ..\/input\/planets-dataset\/planet\/planet\/test-jpg \/kaggle\/tmp\/data\/planet\/test-jpg\n!cp -r ..\/input\/planets-dataset\/planet\/planet\/train_classes.csv \/kaggle\/tmp\/data\/planet\/","49ead875":"ls {PATH}","5d26320e":"from fastai.plots import *","cc2e89f1":"list_paths = [f\"{PATH}train-jpg\/train_0.jpg\", f\"{PATH}train-jpg\/train_1.jpg\"]\ntitles=[\"haze primary\", \"agriculture clear primary water\"]\nplots_from_files(list_paths, titles=titles, maintitle=\"Multi-label classification\")","dfca04a0":"from sklearn.metrics import fbeta_score\nimport warnings\n    \ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs.cpu(), (preds>th).cpu(), 2, average='samples')\n                    for th in np.arange(start,end,step)])","132b98db":"metrics=[f2]\nf_model = resnet34","502870e3":"label_csv = f'{PATH}train_classes.csv'\nn = len(list(open(label_csv)))-1\nval_idxs = get_cv_idxs(n)","7d4ab5d2":"def get_data(sz):\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    return ImageClassifierData.from_csv(PATH, 'train-jpg', label_csv, tfms=tfms,\n                    suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg')","67a62494":"data = get_data(256)","8b2b9652":"x,y = next(iter(data.val_dl))","b6a73439":"y","252647ab":"list(zip(data.classes, y[0]))","7a35199f":"plt.imshow(data.val_ds.denorm(to_np(x))[0]*1.4); # multiplying by 1.4 to make it visible","616c1473":"sz=64","29933bf4":"data = get_data(sz)","fa149a71":"data = data.resize(int(sz*1.3), 'tmp')","30188959":"learn = ConvLearner.pretrained(f_model, data, metrics=metrics)","c2c2a17c":"lrf=learn.lr_find()\nlearn.sched.plot()","da01434e":"lr = 0.2","011d0c68":"learn.fit(lr, 3, cycle_len=1, cycle_mult=2)","47eff972":"lrs = np.array([lr\/9,lr\/3,lr])","a5ff576a":"learn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)","b55aa577":"learn.save(f'{sz}')","c486be0e":"learn.sched.plot_loss()","25262f43":"sz=128","e3e35739":"learn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","144b3483":"# learn.unfreeze()\n# learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n# learn.save(f'{sz}')","81cb7763":"# Uncomment for better accuracy\n\n# sz=256\n\n# learn.set_data(get_data(sz))\n# learn.freeze()\n# learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n\n# learn.unfreeze()\n# learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n# learn.save(f'{sz}')","6c149e9b":"multi_preds, y = learn.TTA()\npreds = np.mean(multi_preds, 0)","e503b7f3":"preds.shape, y.shape","bbf8aeea":"def f2_(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n                    for th in np.arange(start,end,step)])\nf2_(preds,y)","dfa2ed6e":"# learn.summary() # Uncomment for whole model summary","f446a661":"## Multi-label classification","cb07e8a6":"## Multi-label models for Planet dataset","c8bb0afe":"In single-label classification each sample belongs to one class. In the previous example, each image is either a *dog* or a *cat*.","24cad436":"## Model Summary","92e9e7a7":"We use a different set of data augmentations for this dataset - we also allow vertical flips, since we don't expect vertical orientation of satellite images to change our classifications.","5baa45cf":"In multi-label classification each sample can belong to one or more classes. In the previous example, the first image belongs to two classes: *haze* and *primary*. The second image belongs to four classes: *agriculture*, *clear*, *primary* and  *water*.","b937501c":"## Multi-label versus single-label classification"}}