{"cell_type":{"31ac29e3":"code","3a478f8e":"code","1eae4a9f":"code","a2196ab7":"code","29c81320":"code","2d09f7d1":"code","67cb1660":"code","c2381e85":"code","ba93c51a":"code","8afe0351":"code","f20ac09d":"code","8404bd67":"code","d5e19db3":"code","435440a7":"code","2ca65ea7":"code","fe275787":"code","e417a925":"code","f29bc687":"code","79a3e4ff":"code","d9f75cf8":"code","f14cdabc":"code","d61c4d53":"code","274da3d5":"code","fa696479":"code","a5d993ce":"code","05fa0472":"code","c8d4767a":"code","d098a547":"code","ccda071e":"code","7800cc1a":"code","004f3116":"code","0a855463":"code","1dc3b650":"code","8de80a9e":"code","557ae040":"code","47a244f6":"code","f9d2ea71":"code","fae1e179":"code","415e64c7":"code","885a5a10":"code","75c822ce":"code","a7de3ae7":"code","a32b6bf6":"code","03fae71d":"code","d30c622a":"code","4b238be4":"code","7ce42e26":"code","5dc83ffb":"code","17abb75b":"code","f6d8b772":"code","beebac4f":"code","ec31e94f":"code","1537e987":"code","5ff2a1a0":"code","1b5ff275":"code","93659bdb":"code","e6f75a56":"code","245f210b":"code","89357def":"code","659906f4":"code","b00d853e":"code","53fea44b":"code","498ff671":"code","dce052cf":"code","9c1638a7":"code","f00adbac":"code","ddd21d79":"code","a6b99949":"code","be4c2639":"code","e04a9afc":"markdown","bd045e15":"markdown","5d6f8fdb":"markdown","8d9159f9":"markdown","741a58c6":"markdown","874478ca":"markdown","dcfb3f9a":"markdown","db0270fe":"markdown","00b25273":"markdown","7d6a2622":"markdown","92ee5781":"markdown","4a185c22":"markdown","14cbf1de":"markdown","d6c6a606":"markdown","bb4b0560":"markdown","ff4311e1":"markdown","15eed8ea":"markdown","d491572a":"markdown","e88dcfe0":"markdown","de4ee3ce":"markdown","2c323524":"markdown","9caf781a":"markdown","7d4593ed":"markdown"},"source":{"31ac29e3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import cohen_kappa_score,make_scorer\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport nltk\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import OneHotEncoder,MinMaxScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score, KFold, cross_validate,RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nRANDOM_STATE = 0","3a478f8e":"def evaluation_metric(model, actual, predicted):\n    '''\n        Compute quadratic weighted kappa score of predicted values\n    '''\n    return cohen_kappa_score(actual, predicted, weights = \"quadratic\")\n\ndef get_cross_breed(breed1, breed2) -> str:\n    '''\n        Compute whether the\n    '''\n    if (breed2 != 0) & (breed1 != breed2):\n        return 'Yes'\n    else:\n        return 'No'\n    \ndef clean_text(data):\n    data['text_char_count'] = data['Description'].apply(len)\n    data['text_word_count'] = data['Description'].apply(lambda x: len(x.split()))\n    data['text_density'] = data['text_char_count'] \/ (data['text_word_count']+1)\n    data['text_punctuation_count'] = data['Description'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation)))\n    data['title_word_count'] = data['Description'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n    data['text_upper_case'] = data['Description'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n    data['Description'] = data['Description'].apply(lambda x: x.translate(str.maketrans('', '', punctuation)))\n    data['Description'] = data['Description'].str.lower()\n    return data\n\ndef remove_stopwords(text):\n    \"\"\"\n    Removing stopwords belonging to english language\n    \n    \"\"\"\n    words = [w for w in text if w not in stopwords.words('english')]\n    return words\n\ndef combine_text(list_of_text):\n    '''Takes a list of text and combines them into one large chunk of text.'''\n    combined_text = ' '.join(list_of_text)\n    return combined_text\n\ndef determine_sentiments(score, magnitude):\n    '''\n        Determine the sentiment - https:\/\/cloud.google.com\/natural-language\/docs\/basics\n    '''\n    if score >=0.1:\n        if magnitude < 3:\n            return 'Weak Postive'\n        elif magnitude < 6 and magnitude>= 3:\n            return 'Medium Postive'\n        elif magnitude >= 6:\n            return 'Clearly Postive'\n            \n    elif score <=-0.1 :\n        if magnitude < 3:\n            return 'Weak Negative'\n        elif magnitude < 6 and magnitude>= 3:\n            return 'Medium Negative'\n        elif magnitude >=6:\n            return 'Clearly Negative'\n            \n    else:\n        return 'Netural'\n\nmapping_maturity = {1: 'Small', 2:'Medium', 3:'Large', 4: 'Extra Large', 0: 'Not Specified'}\nmapping_fur = {1: 'Short', 2:'Medium', 3:'Long', 0:'Not Specified'}\nmapping_vet = {1:'Yes', 2:'No', 3:'Not Sure'}\nmapping_health = {1:'Healthy', 2:'Minor Injury', 3:'Serious Injury', 0:'Not Specified'}\n\nkappa_scorer = make_scorer(cohen_kappa_score,weights = \"quadratic\")","1eae4a9f":"states = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/state_labels.csv')\ncolors = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/color_labels.csv')\nbreeds = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/breed_labels.csv')\n\ntrain = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/train\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/petfinder-adoption-prediction\/test\/test.csv')\n\npalette = {\"Dog\": \"C0\", \"Cat\": \"C1\"}","a2196ab7":"train.isnull().values.any()","29c81320":"train.isnull().sum()","2d09f7d1":"train.duplicated().sum()","67cb1660":"breeds.isnull().values.any()","c2381e85":"breeds['Type'].value_counts()","ba93c51a":"breeds['animal'] = breeds['Type'].apply(lambda x: \"Dog\" if x == 1 else \"Cat\")","8afe0351":"mapping = dict(breeds[['BreedID', \"BreedName\"]].values)\ntrain[\"Main_Breed\"]=train.Breed1.map(mapping)\ntest[\"Main_Breed\"] = test.Breed1.map(mapping)\n\nmap_animal = dict(breeds[['BreedID', 'animal']].values)\ntrain['Main_Breed_animal'] = train.Breed1.map(map_animal)\ntest['Main_Breed_animal'] = test.Breed1.map(map_animal)\ntrain['Sec_Breed_animal'] = train.Breed2.map(map_animal)\ntest['Sec_Breed_animal'] = test.Breed2.map(map_animal)","f20ac09d":"train['MaturitySize'] = train['MaturitySize'].map(mapping_maturity)\ntest['MaturitySize'] = test['MaturitySize'].map(mapping_maturity)\n\ntrain['FurLength'] = train['FurLength'].map(mapping_fur)\ntest['FurLength'] = test['FurLength'].map(mapping_fur)\n\ntrain['Vaccinated'] = train['Vaccinated'].map(mapping_vet)\ntest['Vaccinated'] = test['Vaccinated'].map(mapping_vet)\n\ntrain['Dewormed'] = train['Dewormed'].map(mapping_vet)\ntest['Dewormed'] = test['Dewormed'].map(mapping_vet)\n\ntrain['Sterilized'] = train['Sterilized'].map(mapping_vet)\ntest['Sterilized'] = test['Sterilized'].map(mapping_vet)\n\ntrain['Health'] = train['Health'].map(mapping_health)\ntest['Health'] = test['Health'].map(mapping_health)","8404bd67":"train.drop(train[train['Sec_Breed_animal'].notna() & (train['Main_Breed_animal'] != train['Sec_Breed_animal'])].index, inplace = True)","d5e19db3":"g = sns.countplot(train['Main_Breed_animal'],palette=palette)\ng.set_title(\"Distribution of Animals in Train set\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train['Main_Breed_animal'])), (x.mean(), y), ha='center', va='bottom');","435440a7":"g = sns.countplot(test['Main_Breed_animal'],palette=palette)\ng.set_title(\"Distribution of Animals in Test set\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(test['Main_Breed_animal'])), (x.mean(), y), ha='center', va='bottom');","2ca65ea7":"train['Cross_Breed'] = train.apply(lambda x: get_cross_breed(x['Breed1'], x['Breed2']), axis = 1 )\ntest['Cross_Breed'] = test.apply(lambda x: get_cross_breed(x['Breed1'], x['Breed2']), axis = 1)","fe275787":"train.Cross_Breed.value_counts()","e417a925":"g = sns.countplot(x='Cross_Breed', hue = \"Main_Breed_animal\", data = train,palette=palette)\ng.set_title(\"Distribution of Cross Breed in the Animals\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');","f29bc687":"train['AdoptionSpeed'].value_counts()","79a3e4ff":"plt.figure(figsize=(15, 8))\ng = sns.countplot(train['AdoptionSpeed'])\ng.set_title(\"Adoption Speed of Animals\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train['AdoptionSpeed'])), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])","d9f75cf8":"plt.figure(figsize=(15, 8))\ng = sns.countplot(x='AdoptionSpeed', hue = \"Main_Breed_animal\", data = train ,palette=palette)\ng.set_title(\"Adoption Speed per Animal\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])","f14cdabc":"cats = train[train['Main_Breed_animal'] == 'Cat']","d61c4d53":"pd.crosstab(cats['Main_Breed'], cats['AdoptionSpeed'])","274da3d5":"fig, axes = plt.subplots(1, 2, figsize = (20,8))\nnot_mixed = train[train['Cross_Breed'] == 'No']\npure = train[train['Cross_Breed'] == 'Yes']\nplt.figure(figsize=(15, 8));\n\n\ng = sns.countplot(x='AdoptionSpeed', hue = \"Main_Breed_animal\", data = not_mixed,palette=palette, ax=axes[0])\ng.set_title(\"Adoption Speed for Non-mixed Breed Animals (Pure Breed)\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    \n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(not_mixed)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])\n\ng = sns.countplot(x='AdoptionSpeed', hue = \"Main_Breed_animal\",palette=palette, data = pure, ax=axes[1])\ng.set_title(\"Adoption Speed per Mixed Breed Animal\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    \n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(pure)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days']);","fa696479":"train.Health.value_counts()","a5d993ce":"fig, axes = plt.subplots(1, 3, figsize = (25,8))\naxes[0].set_title('Distribution of Animal Ages')\nsns.histplot(data=train, x=\"Age\", kde=True, ax = axes[0]);\naxes[1].set_title(\"Scatterplot of Age and AdoptionSpeed\")\nsns.scatterplot(data=train, x=\"Age\", y=\"AdoptionSpeed\", hue=\"Main_Breed_animal\",palette=palette, ax = axes[1]);\naxes[2].set_title('AdoptionSpeed by Animal Specie and age')\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Main_Breed_animal\", data=train,palette=palette, ax = axes[2]);\n","05fa0472":"data = []\nfor a in range(5):\n    df = train.loc[train['AdoptionSpeed'] == a]\n\n    data.append(go.Scatter(\n        x = df['Age'].value_counts().sort_index().index,\n        y = df['Age'].value_counts().sort_index().values,\n        name = str(a)\n    ))\n    \nlayout = go.Layout(dict(title = \"AdoptionSpeed trends by Age\",\n                  xaxis = dict(title = 'Age (months)'),\n                  yaxis = dict(title = 'Counts'),\n                  )\n                  )\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","c8d4767a":"plt.figure(figsize=(30, 8))\ng = sns.countplot(x='PhotoAmt', hue = \"AdoptionSpeed\", data = train )\ng.set_title(\"Adoption Speed per PhotoAmt\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');\n","d098a547":"fig, axes = plt.subplots(1, 3, figsize = (25,8))\naxes[0].set_title('Distribution of Animal Photos')\nsns.histplot(data=train, x=\"PhotoAmt\", kde=True, ax = axes[0]);\naxes[1].set_title(\"Scatterplot of PhotoAmt and AdoptionSpeed\")\nsns.scatterplot(data=train, x=\"PhotoAmt\", y=\"AdoptionSpeed\", hue=\"Main_Breed_animal\",palette=palette, ax = axes[1]);\naxes[2].set_title('AdoptionSpeed by Animal Photos and Type')\nsns.violinplot(x=\"AdoptionSpeed\", y=\"PhotoAmt\", hue=\"Main_Breed_animal\", data=train,palette=palette, ax = axes[2]);","ccda071e":"palette_vet ={'Yes': \"#FF0B04\", 'No' : \"#4374B3\", 'Not Sure': \"#4d4d4d\"}\n##  'Vaccinated', 'Dewormed','Sterilized'\nfig, axes = plt.subplots(1, 3, figsize = (20,8));\nnot_mixed = train[train['Cross_Breed'] == 'No']\npure = train[train['Cross_Breed'] == 'Yes']\nplt.figure(figsize=(15, 8));\n\n\ng = sns.countplot(x='AdoptionSpeed', hue = \"Vaccinated\", palette = palette_vet, data = train,  ax=axes[0])\ng.set_title(\"Adoption Speed for Vaccinated Animals\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])\n\ng = sns.countplot(x='AdoptionSpeed', hue = \"Dewormed\", data = train,  palette = palette_vet, ax=axes[1])\ng.set_title(\"Adoption Speed per Dewormed Animals\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])\n    \ng = sns.countplot(x='AdoptionSpeed', hue = \"Sterilized\", data = train, palette = palette_vet, ax=axes[2])\ng.set_title(\"Adoption Speed per Sterilized Animals\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');\ng=g.set_xticklabels(['Same Day', '1-7days','8-30 days','31-90 days','> 100 days'])","7800cc1a":"train['Description'].nunique()","004f3116":"test['Description'] = test['Description'].fillna('')\ntrain['Description'] = train['Description'].fillna('')","0a855463":"train = clean_text(train)\ntest = clean_text(test)","1dc3b650":"from wordcloud import WordCloud\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=[26, 8])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(train[(train['AdoptionSpeed'] <=1) & (train['Main_Breed_animal'] == 'Dog') ]['Description']))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Early Adoption for Dogs (0 and 1)',fontsize=15);\n\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(train[(train['AdoptionSpeed'] <=1) & (train['Main_Breed_animal'] == 'Cat') ]['Description']))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Early Adoption for Cats (0 and 1)',fontsize=15);","8de80a9e":"fig, (ax3, ax4) = plt.subplots(1, 2, figsize=[26, 8])\n\n\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(train[(train['AdoptionSpeed'] >= 3) & (train['Main_Breed_animal'] == 'Dog') ]['Description']))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('Late Adoption for Dogs (3 and 4)',fontsize=15);\n\nwordcloud4 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(train[(train['AdoptionSpeed'] >= 3) & (train['Main_Breed_animal'] == 'Cat') ]['Description']))\nax4.imshow(wordcloud4)\nax4.axis('off')\nax4.set_title('Late Adoption for Cats (3 and 4)',fontsize=15);","557ae040":"import glob, json\ntrain_sentiment_files = sorted(glob.glob('\/kaggle\/input\/petfinder-adoption-prediction\/train_sentiment\/*.json'))\ndata = []\nfor i in range (len(train_sentiment_files)):\n    with open(train_sentiment_files[i]) as jsonFile:\n        jsonObject = json.load(jsonFile)\n        jsonFile.close()\n    score=jsonObject['documentSentiment']['score']\n    magnitude=jsonObject['documentSentiment']['magnitude']\n    path=train_sentiment_files[i]\n    firstpos=path.rfind(\"\/\")\n    lastpos=path.rfind(\".\")\n    PetID=path[firstpos+1:lastpos]\n    data.append([PetID,score,magnitude,score*magnitude])\nsentiment_train = pd.DataFrame(data, columns=['PetID','Score', 'Magnitude','Sentiment'])\n","47a244f6":"sentiment_train.fillna(0, inplace = True)","f9d2ea71":"train = pd.merge(train, sentiment_train, how = \"left\", left_on =\"PetID\", right_on = 'PetID' )","fae1e179":"train['description_sentiment'] = train.apply(lambda x: determine_sentiments(x['Score'], x['Magnitude']), axis = 1)","415e64c7":"plt.figure(figsize=(30, 8))\ng = sns.countplot(x='description_sentiment', hue = \"AdoptionSpeed\", data = train )\ng.set_title(\"Adoption Speed per Description Sentiment\")\nfor p in g.patches:\n    x = p.get_bbox().get_points()[:,0]\n    y = p.get_bbox().get_points()[1,1]\n    g.annotate('{:.2g}%'.format(100.*y\/len(train)), (x.mean(), y), ha='center', va='bottom');","885a5a10":"test_sentiment_files = sorted(glob.glob('\/kaggle\/input\/petfinder-adoption-prediction\/test_sentiment\/*.json'))\ndata_test = []\nfor i in range (len(test_sentiment_files)):\n    with open(test_sentiment_files[i]) as jsonFile:\n        jsonObject = json.load(jsonFile)\n        jsonFile.close()\n    score=jsonObject['documentSentiment']['score']\n    magnitude=jsonObject['documentSentiment']['magnitude']\n    path=train_sentiment_files[i]\n    firstpos=path.rfind(\"\/\")\n    lastpos=path.rfind(\".\")\n    PetID=path[firstpos+1:lastpos]\n    data_test.append([PetID,score,magnitude,score*magnitude])\nsentiment_test = pd.DataFrame(data_test, columns=['PetID','Score', 'Magnitude','Sentiment'])\nsentiment_test.fillna(0, inplace = True)","75c822ce":"test = pd.merge(test, sentiment_test, how = \"left\", left_on=\"PetID\", right_on = 'PetID')","a7de3ae7":"test['description_sentiment'] = test.apply(lambda x: determine_sentiments(x['Score'], x['Magnitude']), axis = 1)","a32b6bf6":"target = train['AdoptionSpeed']\ntest_petID = test['PetID']\ntrain = train.drop(columns=['AdoptionSpeed', 'Name', 'State','RescuerID','PetID','Breed1', 'Breed2','Sec_Breed_animal', 'Description','text_char_count',\n                            'text_word_count', 'text_density', 'text_punctuation_count','title_word_count','text_char_count',  'text_upper_case'])\ntest = test.drop(columns=['Name', 'State','RescuerID','PetID','Breed1', 'Breed2','Sec_Breed_animal', 'Description','text_char_count', \n                          'text_word_count','text_density', 'text_punctuation_count','title_word_count','text_char_count',  'text_upper_case'])\ncat_cols = ['Type','Gender', 'Color1', 'Color2','Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health','Main_Breed','Main_Breed_animal', 'Cross_Breed','description_sentiment' ]\nfloat_cols = ['Age','Quantity', 'Fee', 'VideoAmt','PhotoAmt','Score', 'Magnitude','Sentiment']","03fae71d":"ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\nohe.fit(train[cat_cols])\nohe_train_x = pd.DataFrame(ohe.transform(train[cat_cols]), columns=ohe.get_feature_names(cat_cols),index=train.index)\nohe_test_x = pd.DataFrame(ohe.transform(test[cat_cols]), columns=ohe.get_feature_names(cat_cols),index=test.index)","d30c622a":"test = test.drop(cat_cols, axis=1)\ntrain = train.drop(cat_cols, axis=1)\ntrain = pd.concat([train, ohe_train_x], axis=1)\ntest = pd.concat([test, ohe_test_x], axis=1)","4b238be4":"mm_scalar = MinMaxScaler()\nfor col in float_cols:\n    mm_scalar.fit(train[col].values.reshape(-1, 1))\n    test[col] = mm_scalar.transform(test[col].values.reshape(-1,1))\n    train[col] = mm_scalar.transform(train[col].values.reshape(-1,1))","7ce42e26":"train.columns[train.isnull().any()]","5dc83ffb":"test.columns[test.isnull().any()]","17abb75b":"train.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)","f6d8b772":"pca = PCA(0.95, random_state =RANDOM_STATE )\npca.fit(train)\ntrain_pca = pca.transform(train)\ntest_pca = pca.transform(test)","beebac4f":"train_pca.shape","ec31e94f":"test_pca.shape","1537e987":"plt.figure(figsize = (10,7))\nplt.plot(train_pca)\nplt.xlabel('Observation')\nplt.ylabel('Transformed Train Data')\nplt.title('Transformed data by 95% PCA');","5ff2a1a0":"pca_features = pd.DataFrame(pca.components_,columns=train.columns)","1b5ff275":"models = [\n          ('RF', RandomForestClassifier()),\n          ('GB', GradientBoostingClassifier()),\n          ('DT', DecisionTreeClassifier()),\n        ('Xgb', XGBClassifier())\n        ]\ndfs = []\nresults = []\nnames = []\nscoring = {\"F1\": \"f1_weighted\", \"kappa\": kappa_scorer}\n\nfor name, model in models:\n    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n    cv_results = cross_validate(model, train, target, cv=kfold, scoring=scoring, return_train_score=True)\n    results.append(cv_results)\n    names.append(name)\n    \n    this_df = pd.DataFrame(cv_results)\n    this_df['model'] = name\n    dfs.append(this_df)\n    final = pd.concat(dfs, ignore_index=True)","93659bdb":"final.groupby(['model']).agg({'fit_time':'mean', 'score_time':'mean', 'test_F1':'mean',  'train_F1':'mean', 'test_kappa':'mean', 'train_kappa':'mean'}).reset_index().sort_values(by=\"test_kappa\", ascending = False)\n","e6f75a56":"dfs = []\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n    cv_results = cross_validate(model, train_pca, target, cv=kfold, scoring=scoring, return_train_score=True)\n    results.append(cv_results)\n    names.append(name)\n    \n    this_df = pd.DataFrame(cv_results)\n    this_df['model'] = name\n    dfs.append(this_df)\n    final_pca = pd.concat(dfs, ignore_index=True)\n    \n","245f210b":"final_pca.groupby(['model']).agg({'fit_time':'mean', 'score_time':'mean', 'test_F1':'mean',  'train_F1':'mean', 'test_kappa':'mean', 'train_kappa':'mean'}).reset_index().sort_values(by=\"test_kappa\", ascending = False)\n","89357def":" models = [\n           ('RF', RandomForestClassifier(class_weight='balanced', n_estimators=200,max_features = 0.3,max_depth = 50, criterion ='entropy'  )),\n         ('Xgb', XGBClassifier(n_estimators = 200)),\n          ('GB', GradientBoostingClassifier(n_estimators = 200, max_depth=25, loss = 'deviance', learning_rate =0.5)),\n          ('DT', DecisionTreeClassifier(class_weight=\"balanced\", max_features=0.3, max_depth=5, criterion ='entropy'))\n        ]\ndfs = []\nresults = []\nnames = []\nscoring = {\"F1\": \"f1_weighted\", \"kappa\": kappa_scorer}\n\nfor name, model in models:\n    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n    cv_results = cross_validate(model, train, target, cv=kfold, scoring=scoring, return_train_score=True)\n    results.append(cv_results)\n    names.append(name)\n    \n    this_df = pd.DataFrame(cv_results)\n    this_df['model'] = name\n    dfs.append(this_df)\n    final = pd.concat(dfs, ignore_index=True)","659906f4":"final.groupby(['model']).agg({'fit_time':'mean', 'score_time':'mean', 'test_F1':'mean',  'train_F1':'mean', 'test_kappa':'mean', 'train_kappa':'mean'}).reset_index().sort_values(by=\"test_kappa\", ascending = False)\n","b00d853e":"gb = GradientBoostingClassifier()\ngb.fit(train, target)","53fea44b":"importance_gb_features = pd.DataFrame(data={\n    'Attribute': train.columns,\n    'Importance': gb.feature_importances_\n})\nimportance_gb_features = importance_gb_features.sort_values(by='Importance', ascending=False)","498ff671":"importance_gb_features","dce052cf":"inportant_features = importance_gb_features[importance_gb_features['Importance'] > 0]['Attribute'].values","9c1638a7":"cv_results = cross_validate(gb, train[inportant_features], target, cv=kfold, scoring=scoring, return_train_score=True)","f00adbac":"cv_results['test_kappa'].mean()","ddd21d79":"cv_results['train_kappa'].mean()","a6b99949":"gb = GradientBoostingClassifier()\ngb.fit(train[inportant_features], target)","be4c2639":"db_test_pred = gb.predict(test[inportant_features])\noutput_rf = pd.DataFrame(\n    {\n        'PetID': test_petID,\n        'AdoptionSpeed': db_test_pred\n    })\noutput_rf.to_csv('submission.csv', index=False)","e04a9afc":"## Sentiments\n\nThis section is analyzing the sentiments of pet description already run through Google's Natural Language API. PetID with missing sentiment magnitude and score will be filled with 0, translating to Neutral \n\nAnalysing description sentiments shows that:\n* Most of the description sentiments for the pet are positive\n* Positive sentiments doesnt translate to early adoption\n","bd045e15":"## Health\n\nHealth Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified). Most of the animals were healthy","5d6f8fdb":"# PetFinder.my Adoption Prediction\nMillions of stray animals suffer on the streets or are euthanized in shelters every day around the world. If homes can be found for them, many precious lives can be saved \u2014 and more happy families created.\n\nPetFinder.my has been Malaysia\u2019s leading animal welfare platform since 2008, with a database of more than 150,000 animals. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n\nAnimal adoption rates are strongly correlated to the metadata associated with their online profiles, such as descriptive text and photo characteristics. As one example, PetFinder is currently experimenting with a simple AI tool called the Cuteness Meter, which ranks how cute a pet is based on qualities present in their photos.\n\nThe goal of this project is to predict the adoptability of pets - specifically, how quickly is a pet adopted? If successful, they will be adapted into AI tools that will guide shelters and rescuers around the world on improving their pet profiles' appeal, reducing animal suffering and euthanization.\n\n## Evaluation\nResults are evaluated using the quadratic weighted kappa, which measures the agreement between two ratings. This metric typically varies from 0 (random agreement between raters) to 1 (complete agreement between raters). In the event that there is less agreement between the raters than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated between the scores which are expected\/known and the predicted scores.","8d9159f9":"# Data Exploration and Evaluation\n\n","741a58c6":"# Modeling\n\nFirstly in the modelinf section, simple models will be used with the train dataset and PCA dataset","874478ca":"## Breeds\nBreeds dataset holds the breed of the animal in the shelter and has no missing value. \n\nThere are 241 breeds of Dogs and 66 breeds of cat. The breeds information is merged with the train and test dataset\n\nThere is no mixed species in the dataset, i.e dog mixed with cats. \n\nThere are 5 animals without main breed details in the trainset and none in test. the 5 observations will be deleted\n\nDog population in train and test dataset is 54% and 53% respectively","dcfb3f9a":"cross breed are animals mixed with another breed. ie where Breed2 isnt zero and breed1 != breed2\n\nDogs are more cross bred than cats. There are more pure breeds in the train dataset","db0270fe":"# Feature Engineering","00b25273":"## Using Important Features of Xgboost","7d6a2622":"## Vetenary Treatment\n\n1. Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n1. Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n1. Sterilized - Pet has been spayed \/ neutered (1 = Yes, 2 = No, 3 = Not Sure)\n\nVaccination is not a factor to early adoption, as people prefer non-vacinated pets\nDewormed pets and healthy pets are favorites for adoption and people generally prefer non-sterilized pets\n","92ee5781":"## Age\n\nMost of the animals are young(new borns to few weeks old). \n\nYounger animals are speedily adopted than older ones","4a185c22":"## Randomized Search\n\nRandomized search was done to determine the best hyperparameters for the models. ","14cbf1de":"## Scaling\n\nScaling the float columns using MinMaxScaler to have consistency of 0-1 values","d6c6a606":"## One Hot Encoding\nConverting categorical values to numeric correspondence","bb4b0560":"The result of simple model showed that PCA train data performed worse than all the features. Gradient Booster performed better with lower train and test kappa difference","ff4311e1":"Overfitting was observed in the results of hypertuning. \nThe important features of Gradient Booster will be used to run the model to observe the results and reduce overfitting","15eed8ea":"### PCA\nTo reduce the dimension of the data, 95% n_components PCA is used. This resulted in 35 columns","d491572a":"## Adoption Speed\n\n* 0 - Pet was adopted on the same day as it was listed.\n* 1 - Pet was adopted between 1 and 7 days (1st week) after being listed.\n* 2 - Pet was adopted between 8 and 30 days (1st month) after being listed.\n* 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\n* 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n\n2.7% of pets were adopted immediately\n\nCats are more adopted within 7 days than dogs (i.e adoption speed 0 and 1).\nDomestic Hair cats are more likely to be adopted earlier than others\n\nMixed Breeds are adopted faster than pure breeds, especially cats","e88dcfe0":"## PhotoAmt\n\nThe maximum number of photos is 30. There is no sufficient evidence that the number of photos influences the Adoption Speed","de4ee3ce":"## Train Dataset\nThe train dataset has no duplicate record. The dataset has missing records in feature `Name` and `Description`","2c323524":"# Conclusion\n\nGradient Boosters result was more favourable and didnt overfit. Therefore gradientbooster with important features will be used for submission","9caf781a":"From the result table, XGBoost performed better but has a wide difference in test and train kappa result. Next the simple models will be used with PCA","7d4593ed":"## Description\n\nNull Description were filled with `Unknown_description`\n\nTaking a first look at the descriptions of the animals in wordcloud for early and late adoptions, the most common words are generic.\n\n"}}