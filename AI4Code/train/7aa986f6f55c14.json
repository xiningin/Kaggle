{"cell_type":{"09ed05a1":"code","cce0efbb":"code","dcb14c8d":"code","c90a06f0":"code","e851cc2a":"code","4ada869a":"code","fe271e33":"code","093d4731":"code","c792eb75":"markdown","2b5529a8":"markdown","b7cb7fb7":"markdown","2256eacb":"markdown","486019a6":"markdown","f4193699":"markdown","1e76cbc7":"markdown","2621b775":"markdown"},"source":{"09ed05a1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, roc_curve, precision_score, roc_auc_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\n","cce0efbb":"data = pd.read_csv(\"..\/input\/mushrooms.csv\")","dcb14c8d":"data.head()","c90a06f0":"def graph(name, u):\n    data[name].value_counts().plot(kind=\"bar\",ax=u, color=colors)\n    \n    plt.setp(u.get_xticklabels(), rotation=0)\n    u.grid(True)\n    u.set_title(name.replace(\"-\",\" \"), fontsize=11, fontdict={\"fontweight\": \"bold\"})\n    \n    for p in u.patches:\n        text = str(int(p.get_height()))\n        u.annotate(text, (p.get_x()+p.get_width()\/2, p.get_height()+100),\n                   ha=\"center\", va='center', fontsize=7, fontweight=\"bold\")\n\n###############################################################################\n# EXPLORATORY DATA ANALYSIS\n\nfig2, ax2 = plt.subplots(3,2, figsize=(11, 10), gridspec_kw={\"wspace\" : 0.4, \"hspace\" : 0.3, \"top\": 0.95})\n\ncolors=[\"#0019ff\",\"#f44809\",\"#af00af\",\"#00af23\",\"#00af23\"]\n\ngraph(\"stalk-shape\",ax2[0,0])\ngraph(\"stalk-root\",ax2[0,1])\ngraph(\"stalk-surface-above-ring\",ax2[1,0])\ngraph(\"stalk-surface-below-ring\",ax2[1,1])\ngraph(\"stalk-color-above-ring\",ax2[2,0])\ngraph(\"stalk-color-below-ring\",ax2[2,1])\nplt.rcParams['axes.axisbelow'] = True","e851cc2a":"X = data.drop([\"class\"], axis=1)\ny = data[\"class\"]\nX = pd.get_dummies(X)\n\nle = LabelEncoder()\ny = le.fit_transform(y)","4ada869a":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\nclf = LogisticRegression(solver=\"lbfgs\").fit(X_train,y_train)\npredicted = clf.predict(X_test)\npredicted_proba = clf.predict(X_test)\n\nprint(\"Accuracy is: \"+ str(clf.score(X_test,y_test)))\nprint(\"Recall score is: \" + str(round(recall_score(y_test, predicted),3)))\nprint(\"Precision score is: \" + str(round(precision_score(y_test, predicted),3)))\nprint(\"F1 score is: \" + str(round(f1_score(y_test, predicted),3)))\nprint(\"\\nConfusion matrix:\")\nprint(confusion_matrix(y_test, predicted))","fe271e33":"values = clf.coef_[0]\nnames = X_train.columns\n\nimportance = pd.DataFrame({\"value\": values, \"name\": names}).sort_values(\"value\")\nimportance = importance.set_index(\"name\")\n\n# TOP20 FACTORS\ntop20 = pd.concat([importance[\"value\"].head(10),importance[\"value\"].tail(10)])\n\nfig, ax = plt.subplots(figsize=(12,5), gridspec_kw={\"top\": 0.90, \"bottom\":0.05, \"left\":0.2})\n\ntop20.plot.barh(ax=ax)\n\nplt.rcParams['axes.axisbelow'] = True\nplt.ylabel(\"variable name\")\nplt.grid(True)\nplt.title(\"Classification - TOP20 features (importance)\")","093d4731":"# small experiment - arbitrary selected variables\nX2 = data[[\"bruises\",\"stalk-root\",\"stalk-shape\",\"habitat\"]]\nX2 = pd.get_dummies(X2)\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nX2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=0.2)\n\nclf2 = LogisticRegression(solver=\"lbfgs\").fit(X2_train, y_train)\n\npredicted = clf2.predict(X2_test)\n\npredicted_proba = clf2.predict_proba(X2_test)\npredicted_proba = pd.DataFrame(predicted_proba)[1]\n\nroc_auc=roc_auc_score(y_test, predicted)\n\nfpr, tpr, thresholds = roc_curve(y_test, predicted_proba, drop_intermediate=False)\n\nfig2, ax2 = plt.subplots(figsize=(10, 5), gridspec_kw={\"wspace\" : 0.4, \"hspace\" : 0.3, \"top\": 0.95})\nplt.plot(fpr,tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.grid(True)\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.xticks([i for i in np.arange(0,1.1,0.1)])\nplt.yticks([i for i in np.arange(0,1.1,0.1)])\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for 4 variables only')\nplt.legend(loc=\"lower right\")","c792eb75":"**Reading raw data from .csv file.**","2b5529a8":"**Classification and metrics for logistic regression classifier**","b7cb7fb7":"**MORE TO COME**","2256eacb":"**All columns are categorical. Let's explore them by looking at bar charts.**","486019a6":"**Data have to be encoded for classification. One-hot-encoding with pandas_get_dummies() will be performed. Binary labels will be encoded using sklearn LabelEncoder().**","f4193699":"**Very good result! Let's check what are the most influential variables. Let's select TOP20 of them.**","1e76cbc7":"**SMALL EXPERIMENT - let's choose only 4 ARBITRARY variables and see classificator performance **","2621b775":"**MUSHROOMS CLASSIFICATION**\n\n<a title=\"MichaelMaggs [CC BY-SA 2.5 (https:\/\/creativecommons.org\/licenses\/by-sa\/2.5)], from Wikimedia Commons\" href=\"https:\/\/commons.wikimedia.org\/wiki\/File:Amanita_muscaria_(fly_agaric).JPG\"><img width=\"128\" alt=\"Amanita muscaria (fly agaric)\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/c\/c2\/Amanita_muscaria_%28fly_agaric%29.JPG\/128px-Amanita_muscaria_%28fly_agaric%29.JPG\"><\/a>\n\n\nIn this kernel we will investigate the mushrooms classification database.\nSimple EDA and classification with logistic regression will be performed. Data for classification will be one-hot-encoded. Based on the analysis results features importance will be revealed. At the end we will see how the classfier will behave if we select few arbitrary selected variables (ROC will be plotted)\n\nReading necesary libraries. We will use [sklearn](https:\/\/scikit-learn.org\/stable\/), [pandas](https:\/\/pandas.pydata.org\/), [numpy](http:\/\/www.numpy.org\/) and [matplotlib](https:\/\/matplotlib.org\/)."}}