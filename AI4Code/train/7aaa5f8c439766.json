{"cell_type":{"1fc8d202":"code","435c2b4d":"code","db45457f":"code","e85365fa":"code","fe88be48":"code","fdbefb50":"code","b030fd7a":"code","c8140418":"code","f381c441":"code","ccac57df":"code","134ee474":"code","c2548a4c":"code","5fcf3898":"code","e869f392":"code","c5dd2df5":"code","86a9ca69":"code","1a3bbd71":"code","6cd2ad79":"code","ea8c8392":"code","8dab6592":"code","3f251dad":"code","ddad6436":"code","e3cd6c9c":"code","91a0f0e7":"code","130ebcb8":"code","18feaa7e":"code","7b89e39b":"code","e0976582":"markdown","4652c9d1":"markdown","b3f14a43":"markdown","e8b4295f":"markdown","ad66e51c":"markdown","7203783c":"markdown","f1acec6c":"markdown","05aeabd7":"markdown","2eb4364d":"markdown","4d5ced2a":"markdown","a4bcc170":"markdown","9937dba7":"markdown","be4a1949":"markdown","5b44c49b":"markdown","f542d493":"markdown","0ca50027":"markdown","5ee3ecbf":"markdown","36eb753e":"markdown"},"source":{"1fc8d202":"# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n\n#model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\n#dl libraraies\nimport tensorflow as tf\nimport random as rn\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.utils import to_categorical\n\n# specifically for cnn\nfrom tensorflow.keras.layers import Dropout, Flatten,Activation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\nfrom random import shuffle  \nfrom zipfile import ZipFile\nfrom PIL import Image\n\n%matplotlib inline  \n\n\n\n#preprocess.\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# To define maximum number of columns to be displayed in a dataframe\npd.set_option(\"display.max_columns\", None)\n\n# To supress scientific notations for a dataframe\npd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n\nimport os\nprint(os.listdir('\/kaggle\/input\/'))\n","435c2b4d":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","db45457f":"image_data = np.load('\/kaggle\/input\/plantseed\/images.npy' )\nlabel_data = pd.read_csv('\/kaggle\/input\/plantseed\/Labels.csv' )","e85365fa":"print(image_data.shape)\nprint(label_data.shape)","fe88be48":"# label_data.info()\nZ=label_data.Label.tolist()\n# print(Z)\nfig,axarr=plt.subplots(5,3)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range(3):\n        l=rn.randint(0,4750)\n        axarr[i,j].imshow(image_data[l])\n        axarr[i,j].set_title('Seed: '+Z[l])\n        \nplt.tight_layout();       ","fdbefb50":"# To see the count of classifications values\nlabel_data.Label.value_counts()","b030fd7a":"# Function to create barplots that indicate percentage for each category.\n\n\ndef perc_on_bar(z):\n    total = len(label_data[z])  # length of the column\n    plt.figure(figsize=(15, 5))\n    # plt.xticks(rotation=45)\n    ax = sns.countplot(label_data[z], palette=\"Paired\")\n    for p in ax.patches:\n        percentage = \"{:.1f}%\".format(\n            100 * p.get_height() \/ total\n        )  # percentage of each class of the category\n        x = p.get_x() + p.get_width() \/ 2 - 0.05  # width of the plot\n        y = p.get_y() + p.get_height()  # hieght of the plot\n\n        ax.annotate(percentage, (x, y), size=12)  # annotate the percantage\n    plt.show()  # show the plot","c8140418":"perc_on_bar(\"Label\")","f381c441":"#gaussian blurring\n\nimport cv2\n\nfig,axarr=plt.subplots(5,3)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range(3):\n        l=rn.randint(0,4750)\n        blurImg = cv2.GaussianBlur(image_data[l], (5, 5), 0) \n        axarr[i,j].imshow(blurImg)\n        axarr[i,j].set_title('Seed: '+Z[l])\n        \nplt.tight_layout(); ","ccac57df":"from skimage.filters import gaussian\n\nblurImg1=np.empty_like(image_data)\n\nfor i in range(4750):\n    blurImg1[i] = cv2.GaussianBlur(image_data[i], (5, 5), 0)\n#       blurImg1[i] = gaussian(image_data[i], multichannel=True) \n\n# print(blurImg1)","134ee474":"def convert_labels(y):\n    enc = LabelEncoder()                        \n    P = enc.fit_transform(y)                ## convert string labels to numbers \n    Y = to_categorical(P)                        ## convert number to one-hot-encode form \n    return Y\n\nX = np.array(blurImg1)\/255.0 \nY = convert_labels(label_data)\n\n#print(X)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\nX_train = X_train.astype('float32')    #chang integer -> float\nX_test = X_test.astype('float32')\nX_train \/= 255\nX_test \/= 255\n\nprint(\"Shape of training data:\")\nprint(X_train.shape)    #50,000 \u0e20\u0e32\u0e1e \u0e02\u0e19\u0e32\u0e14 32*32  3npg\nprint(Y_train.shape)\nprint(\"Shape of test data:\")\nprint(X_test.shape)\nprint(Y_test.shape)","c2548a4c":"# Initialising the CNN classifier\nmodel = Sequential()\n\n\n# Add a Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),activation ='relu', input_shape = (128,128,3)))\n\n# Add a Max Pooling layer of size 2X2\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\n\n# Add another Convolution layer with 64 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n \n\n# Add another Convolution layer with 96 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# Flattening the layer before fully connected layers\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(144, activation='relu'))\nmodel.add(Dense(12, activation='softmax'))","5fcf3898":"model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","e869f392":"batchSize=256\nep=20\nhistory=model.fit(X_train,Y_train,batch_size=batchSize,epochs=ep,validation_split=.15)","c5dd2df5":"model.evaluate(X_test,Y_test)","86a9ca69":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('CNN model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","1a3bbd71":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ndatagen = ImageDataGenerator(\n        rotation_range=20,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n\n \nx = blurImg1.copy() \nx = x.reshape((1,) + x.shape)  \n\nprint(x.shape)\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview\/` directory\ni = 0\nfor batch in datagen.flow(blurImg1, batch_size=1,save_to_dir='\/kaggle\/working', save_prefix='seed', save_format='jpeg'):\n    i += 1\n    if i > 19:\n        break  # otherwise the generator would loop indefinitely","6cd2ad79":"# # modelling starts using a CNN.\n\n\n# Initialising the CNN classifier\nmodel = Sequential()\n\n# Add a Convolution layer with 32 kernels of 5X5 shape with activation function ReLU\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),activation ='relu', input_shape = (128,128,3)))\n\n# Add a Max Pooling layer of size 2X2\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Add another Convolution layer with 64 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n \n\n# Add another Convolution layer with 96 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# Flattening the layer before fully connected layers\nmodel.add(Flatten())\n\n# Adding a fully connected layer with 512 neurons\nmodel.add(Dense(512,activation='relu'))\n\n# The final output layer with 12 neuron to predict the categorical classifcation\nmodel.add(Dense(12, activation = \"softmax\"))\n\nmodel.summary()","ea8c8392":"model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","8dab6592":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n#datagen.fit(X_train)\ndtAug=datagen.flow(X_train,Y_train)\nprint(dtAug)","3f251dad":"ep=50\n\nHistory = model.fit_generator(dtAug,epochs = ep,verbose = 1,use_multiprocessing=True, steps_per_epoch=X_train.shape[0] \/\/ batchSize,validation_data=(X_test,Y_test))","ddad6436":"model.evaluate(X_test,Y_test)","e3cd6c9c":"# modelling starts using a CNN.\n\n\n# Initialising the CNN classifier\nmodel = Sequential()\n\n# Add a Convolution layer with 64 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),activation ='selu', kernel_initializer = 'lecun_normal', input_shape = (128,128,3)),)\n\n# Add a Max Pooling layer of size 2X2\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Add another Convolution layer with 64 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='selu', kernel_initializer = 'lecun_normal'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n \n\n# Add another Convolution layer with 96 kernels of 3X3 shape with activation function ReLU\nmodel.add(Conv2D(filters =128, kernel_size = (3,3),padding = 'Same',activation ='selu', kernel_initializer = 'lecun_normal'))\n\n# Adding another pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# Flattening the layer before fully connected layers\nmodel.add(Flatten())\n\n# Adding a fully connected layer with 512 neurons\nmodel.add(Dense(512,activation='selu'))\n\n# The final output layer with 12 neuron to predict the categorical classifcation\nmodel.add(Dense(12, activation = \"softmax\"))\n\nmodel.summary()","91a0f0e7":"model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])","130ebcb8":"History = model.fit_generator(dtAug,epochs = 100,verbose = 1,use_multiprocessing=True, steps_per_epoch=X_train.shape[0] \/\/ batchSize,validation_data=(X_test,Y_test))","18feaa7e":"model.evaluate(X_test,Y_test)","7b89e39b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('CNN model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","e0976582":"## Model Building","4652c9d1":"## Data Augmentation","b3f14a43":"**All categories have at least 5% of all the values**","e8b4295f":"## Compiling the Model","ad66e51c":"### Objective:  \n**To create a classifier capable of determining a plant's species from a photo**\n\n### Dataset:\nThe data file names are:\n\n**\u2022 images.npy**\n\n**\u2022 Label.csv**\n\nDue to the large volume of data, the images were converted to images.npy file and the labels are also put into the Labels.csv.","7203783c":"## Data Preparation","f1acec6c":"**Significant improvement seen in performance**","05aeabd7":"## Model Performance Evaluation","2eb4364d":"## Conclusion","4d5ced2a":"## Fitting the model","a4bcc170":"**Data Accuracy is very low**\n\n**Trying Data Augmentation**","9937dba7":"### Loading Image File and Labels","be4a1949":"**There are 4750 color(RGB) images of size 128x128**","5b44c49b":"## Visualizing some random images","f542d493":"**Accuracy is still very low**","0ca50027":"**Few Images are blurry and some seem very similar. This can make it a little difficult to get high accuracy**\n\n**Will use Gaussian Filter to remove noise from the image**","5ee3ecbf":"### Loading Libraries","36eb753e":"**The source images have too much noise to be correctly classified using simple CNN**\n\n**We see some improvement post data augmentation**"}}