{"cell_type":{"507a7e09":"code","e0faced5":"code","d17b1826":"code","52a3ae01":"code","abb3e1a3":"code","5a694394":"code","95bb2a33":"code","dfcffcce":"code","cd4855ea":"markdown","66cb374e":"markdown","55f24051":"markdown","1302ec37":"markdown","583aeaa9":"markdown","c6870896":"markdown","92f95eff":"markdown","c3abc105":"markdown","41f6bdb6":"markdown","d807359c":"markdown","ec8a7141":"markdown","0124af25":"markdown","2e147edf":"markdown","e120b239":"markdown","5c8c27b4":"markdown","2d5df4e1":"markdown"},"source":{"507a7e09":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom collections import deque\nfrom sklearn.decomposition import FastICA","e0faced5":"eeg = pd.read_csv('..\/input\/eegsample\/eeg.csv')\n# convert from V to uV\neeg *= 10**6 ","d17b1826":"eeg.iloc[500:2500].plot(figsize=(15,5), legend=False)\nplt.xlabel('Time [samples]', fontsize=14, labelpad=10)\nplt.ylabel('Voltage [\\u03BCV]', fontsize=14)\nplt.title('Resting state EEG (63 channels)', fontsize=14)\nplt.show()","52a3ae01":"fig, axs = plt.subplots(2,1, figsize=(15, 7), sharex=True, sharey=True)\naxs = axs.ravel()\nplt.margins(x=0.001)\nfig.add_subplot(111, frameon=False)\nplt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\naxs[0].plot(eeg['Fp1'].iloc[500:2500], label='Fp1', color='rosybrown')\naxs[0].legend(loc=\"upper right\", fontsize=12)\naxs[1].plot(eeg['Fp2'].iloc[500:2500], label='Fp2', color='silver')\naxs[1].legend(loc=\"upper right\", fontsize=12)\nplt.xlabel('Time [samples]', fontsize=14, labelpad=15)\nplt.ylabel('Voltage [\\u03BCV]', fontsize=14, labelpad=15)\nplt.show()","abb3e1a3":"ica = FastICA(n_components=63, random_state=0, tol=0.05)\ncomps = ica.fit_transform(eeg)","5a694394":"fig, axs = plt.subplots(8,8, figsize=(18, 13), sharex=True, sharey=True)\nfig.subplots_adjust(hspace = .4, wspace=0)\naxs = axs.ravel()\n\nfig.add_subplot(111, frameon=False)\nplt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\nplt.xlabel('Time [samples]', fontsize=14, labelpad=15)\n\nfor i in range(63):\n    axs[i].plot(comps[1200:1600, i], color='slategrey')\n    axs[i].set_title(str(i))","95bb2a33":"# set artefact components to zero\ncomps[:,[29,42]] = 0 \nrestored = ica.inverse_transform(comps)","dfcffcce":"fig, axs = plt.subplots(2,1, figsize=(15, 7), sharex=True, sharey=True)\naxs = axs.ravel()\nplt.margins(x=0.001)\nfig.add_subplot(111, frameon=False)\nplt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\naxs[0].plot(eeg['Fp1'].iloc[500:2500], label='Fp1_pre', color='rosybrown')\naxs[0].plot(np.arange(500,2500), restored[500:2500, 34], label='Fp1_post', color='maroon')\naxs[0].legend(loc=\"upper right\", fontsize=12)\naxs[1].plot(eeg['Fp2'].iloc[500:2500], label='Fp2_pre', color='silver')\naxs[1].plot(np.arange(500,2500), restored[500:2500, 35], label='Fp2_post', color='dimgray')\naxs[1].legend(loc=\"upper right\", fontsize=12)\nplt.xlabel('Time [samples]', fontsize=14, labelpad=15)\nplt.ylabel('Voltage [\\u03BCV]', fontsize=14, labelpad=15)\nplt.show()","cd4855ea":"ICA is a **signal processing method** capable of separating a multivariate signal into its additive subcomponents, or sources. It is based on the assumptions that the sources are statistically independent and that the values in each source underlie non-Gaussian distributions. A classic example of source separation is the cocktail party problem, where multiple people in a room are talking simultaneously and their voices are recorded by microphones positioned at different spatial locations. ICA can then be applied to separate the mixed source data into various information sources representing maximally temporally independent signals. In other words, the individual voices of each person in the room can be restored with a fairly high degree of accuracy.","66cb374e":"## Visualizing all 63 channels","55f24051":"The scientific community has been using various ICA algorithms, such as Infomax, JADE, and FastICA, with the latter being arguably the most popular one. Additionally, scikit-learn provides the FastICA algorithm in its decomposition module, which further prompted me to use it for this demonstration.\nThe data used here was acquired from an approximately 8min resting-state EEG session. Let\u2019s start by taking a look at a slice of the EEG time-series.","1302ec37":"## ICA","583aeaa9":"It worked! The restored signals (Fp1_post and Fp2_post, darker colors) no longer contain the eye blink and eye movement artefacts present in the raw signals (Fp1_pre and Fp2_pre, faint colors).","c6870896":"<p align=\"center\">\n  <img src=\"https:\/\/hiveofactivities.files.wordpress.com\/2013\/10\/cocktail-party-_2502341b.jpg\" height=\"460\" width=\"800\">\n<\/p>","92f95eff":"Time-series data is often contaminated with unwanted signal artefacts that have the potential to considerably distort any further analysis. Independent component analysis, or ICA, is a powerful method to get around this very problem. Here, I will give a brief introduction to ICA followed by a demonstration of how to implement it to remove signal artefacts. In this notebook, I will be using time-series data obtained through electroencephalography (EEG)\u2014 a technique from the neurosciences that measures electrical activity of the cerebral cortex of the brain.\n","c3abc105":"## Application in EEG","41f6bdb6":"The sampling rate here was 500 Hz, so the above figure shows 4 seconds of data. An eye blink can be seen between samples 1250 and 1500. Eye blinks are typically most pronounced in channels Fp1 and Fp2, so let\u2019s plot them individually.","d807359c":"For the sake of simplicity, I have only plotted the components over 400 samples, from 1200 to 1600, hoping to spot that eye blink visible in Fp1 and Fp2. Upon close inspection, it appears as though component 29 contains horizontal eye movements and component 42 contains eye blink artefacts. To confirm this, I had a look at longer slices of data (not shown here) and found that the artefacts in these components in fact co-occur with the eye blink and eye movement artefacts in various frontal channels.","ec8a7141":"In the context of EEG, ICA can identify components that include artefacts such as eye blinks or eye movements. These components can then be removed before the data is transformed back from source space (individual sources as computed by ICA) to sensor space (original EEG data).","0124af25":"Looking at Fp1, a slight box shape can be detected just before the start of the eye blink. This represents horizontal eye movement and should ideally be removed as well. Now, let\u2019s run scikit-learn\u2019s FastICA and plot all 63 ICA components to see if we can identify the sources of any artefacts.","2e147edf":"**Note:** ICA separates signals into their subcomponents based on statistical measures, meaning that there is no specific component order. If you don\u2019t specify random_state, you will find that the components containing the artefacts can vary.","e120b239":"Let\u2019s now remove components 29 and 42 and transform our source data back into the original sensor space, using the inverse transform.","5c8c27b4":"**Cautionary note:** ICA has been shown to work really well with stereotyped artefacts such as eye blinks and eye movements. However, non-stereotyped artefacts that produce noise in various spatial locations, i.e. when subjects are scratching their head, defy the workings of ICA and should be treated with caution.","2d5df4e1":"Eye blinks and eye movements can usually be detected fairly easily by inspecting the time-series data. They are picked up particularly by frontal channels sitting either right above or in close proximity to the eyes."}}