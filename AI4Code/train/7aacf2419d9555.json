{"cell_type":{"630e2c40":"code","a368fe87":"code","49814ec9":"code","9944143b":"code","7af6af2c":"code","9fb0a205":"code","21356868":"code","11f42d1a":"code","33e1f7ff":"code","893a048e":"code","665b8848":"code","8bd21cff":"code","5da77e4a":"code","7a6ea330":"code","972b9181":"code","8760f8cd":"code","7418efd7":"code","2df13ff7":"code","ce1f2b6a":"code","7f014576":"code","a60f285d":"code","fd02550d":"markdown","d4e532cc":"markdown","4d43e418":"markdown","41539f83":"markdown","69626ba7":"markdown","87a0b78e":"markdown","e8b565de":"markdown"},"source":{"630e2c40":"# clone YOLOv5 repository\n!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n%cd yolov5\n!git reset --hard 886f1c03d839575afecb059accf74296fad395b6","a368fe87":"# install dependencies as necessary\n!pip install -qr requirements.txt  # install dependencies (ignore errors)\nimport torch\n\nfrom IPython.display import Image, clear_output  # to display images\nfrom utils.google_utils import gdrive_download  # to download models\/datasets\n\n# clear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","49814ec9":"#follow the link below to get your download code from from Roboflow\n!pip install -q roboflow\nfrom roboflow import Roboflow\nrf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")","9944143b":"# %cd \/content\/yolov5\n#after following the link above, recieve python code with these fields filled in\n#from roboflow import Roboflow\n#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n#project = rf.workspace().project(\"YOUR PROJECT\")\n#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n!pip install roboflow\nfrom roboflow import Roboflow\nroboflowapi = user_secrets.get_secret(\"RoboflowAPI\") \nrf = Roboflow(api_key=roboflowapi)\nproject = rf.workspace().project(\"counting_cars_cv_zone_drone\")\ndataset = project.version(1).download(\"yolov5\")","7af6af2c":"# Install W&B \n!pip install -q --upgrade wandb\n\n# Login \nimport wandb\nwandb_api = user_secrets.get_secret(\"wandb-apikey\") \nwandb.login(key=wandb_api)","9fb0a205":"# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n%cat {dataset.location}\/data.yaml","21356868":"# define number of classes based on YAML\nimport yaml\nwith open(dataset.location + \"\/data.yaml\", 'r') as stream:\n    num_classes = str(yaml.safe_load(stream)['nc'])","11f42d1a":"#this is the model configuration we will use for our tutorial \n%cat models\/yolov5s.yaml","33e1f7ff":"#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","893a048e":"%%writetemplate models\/custom_yolov5s.yaml\n\n# parameters\nnc: {num_classes}  # number of classes\ndepth_multiple: 0.33  # model depth multiple\nwidth_multiple: 0.50  # layer channel multiple\n\n# anchors\nanchors:\n    - [10,13, 16,30, 33,23]  # P3\/8\n    - [30,61, 62,45, 59,119]  # P4\/16\n    - [116,90, 156,198, 373,326]  # P5\/32\n\n# YOLOv5 backbone\nbackbone:\n  # [from, number, module, args]\n  [[-1, 1, Focus, [64, 3]],  # 0-P1\/2\n   [-1, 1, Conv, [128, 3, 2]],  # 1-P2\/4\n   [-1, 3, BottleneckCSP, [128]],\n   [-1, 1, Conv, [256, 3, 2]],  # 3-P3\/8\n   [-1, 9, BottleneckCSP, [256]],\n   [-1, 1, Conv, [512, 3, 2]],  # 5-P4\/16\n   [-1, 9, BottleneckCSP, [512]],\n   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5\/32\n   [-1, 1, SPP, [1024, [5, 9, 13]]],\n   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n  ]\n\n# YOLOv5 head\nhead:\n    [[-1, 1, Conv, [512, 1, 1]],\n   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n   [-1, 3, BottleneckCSP, [512, False]],  # 13\n\n   [-1, 1, Conv, [256, 1, 1]],\n   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3\/8-small)\n\n   [-1, 1, Conv, [256, 3, 2]],\n   [[-1, 14], 1, Concat, [1]],  # cat head P4\n   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4\/16-medium)\n\n   [-1, 1, Conv, [512, 3, 2]],\n   [[-1, 10], 1, Concat, [1]],  # cat head P5\n   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5\/32-large)\n\n   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n  ]","665b8848":"## train yolov5s on custom data for 100 epochs\n# time its performance\n#%%time\n%cd \/kaggle\/working\/yolov5\/\n!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}\/data.yaml --cfg .\/models\/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache","8bd21cff":"# we can also output some older school graphs if the tensor board isn't working for whatever reason... \nfrom utils.plots import plot_results  # plot results.txt as results.png\nImage(filename='runs\/train\/yolov5s_results\/results.png', width=1000)  # view results.png","5da77e4a":"# first, display our ground truth data\nprint(\"GROUND TRUTH TRAINING DATA:\")\nImage(filename='runs\/train\/yolov5s_results\/test_batch0_labels.jpg', width=900)","7a6ea330":"# print out an augmented training example\nprint(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\nImage(filename='runs\/train\/yolov5s_results\/train_batch0.jpg', width=900)","972b9181":"# trained weights are saved by default in our weights folder\n%ls runs\/","8760f8cd":"%ls runs\/train\/yolov5s_results\/weights","7418efd7":"ls","2df13ff7":"# use the best weights!\n%cd \/kaggle\/working\/yolov5\/\n!python detect.py --weights runs\/train\/yolov5s_results\/weights\/best.pt --img 416 --conf 0.4 --source \/kaggle\/working\/yolov5\/Counting_Cars_CV_Zone_Drone-1\/test\/images","ce1f2b6a":"#display inference on ALL test images\n#this looks much better with longer training above\n\nimport glob\nfrom IPython.display import Image, display\n\nfor imageName in glob.glob('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/*.jpg'): #assuming JPG\n    display(Image(filename=imageName))\n    print(\"\\n\")","7f014576":"%cp \/kaggle\/working\/yolov5\/runs\/train\/yolov5s_results\/weights\/best.pt \/kaggle\/working\/","a60f285d":"#just for keeping the notebook on \ud83d\ude01\n# while(True):\n#     pass","fd02550d":"# Export Trained Weights for Future Inference\n\nNow that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere","d4e532cc":"#Run Inference  With Trained Weights\nRun inference with a pretrained checkpoint on contents of `test\/images` folder downloaded from Roboflow.","4d43e418":"# Define Model Configuration and Architecture\n\nWe will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n\nYou do not need to edit these cells, but you may.","41539f83":"# Train Custom YOLOv5 Detector\n\n### Next, we'll fire off training!\n\n\nHere, we are able to pass a number of arguments:\n- **img:** define input image size\n- **batch:** determine batch size\n- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n- **data:** set the path to our yaml file\n- **cfg:** specify our model configuration\n- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https:\/\/drive.google.com\/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n- **name:** result names\n- **nosave:** only save the final checkpoint\n- **cache:** cache images for faster training","69626ba7":"# Evaluate Custom YOLOv5 Detector Performance","87a0b78e":"# Download Correctly Formatted Custom Dataset \n\nWe'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n\nTo get your data into Roboflow, follow the [Getting Started Guide](https:\/\/blog.roboflow.ai\/getting-started-with-roboflow\/).","e8b565de":"\n\n![YOLOv5 PyTorch export](https:\/\/i.imgur.com\/5vr9G2u.png)\n"}}