{"cell_type":{"690895e3":"code","89c92967":"code","dc473c7d":"code","fe73b1b6":"code","1d4af969":"code","377273dd":"code","777c9a54":"code","072ab6a2":"code","eb7e6afb":"code","64064abe":"code","c6c704f8":"code","9ec8468e":"code","73759780":"code","df084889":"code","17971743":"code","c2c43aae":"code","7a7446c0":"code","1e83c8a5":"code","bf0fd6e5":"code","4348bbf8":"code","b253577e":"code","8c5153d9":"code","b7d2530c":"code","d0f02016":"code","19aa7206":"code","2229dda1":"code","2ca7b567":"code","6fd4fe78":"code","fe61c0af":"code","53b24c58":"code","2171aedf":"code","350c985b":"code","f9d1e62e":"code","5234fd58":"code","e52d1fbb":"code","b58a0207":"code","8c324421":"code","d6f622f0":"code","0ad35a22":"code","96ac656a":"code","7aeeba2c":"code","9077c247":"code","1a6ddc14":"code","2363291d":"code","b5028111":"code","b756afb8":"code","a3135806":"code","a6e7a0c4":"code","5fe497f4":"code","b65dd749":"code","6be9866f":"code","fbc1b111":"code","5dfcd3c0":"code","ea7fbf6d":"code","556689db":"code","5dbc7b1d":"code","41989db7":"code","d9a24c6e":"code","0605f0df":"code","109c0b6e":"code","f3c4ef58":"code","616a9d4f":"code","ac2f7628":"code","6d430e18":"code","a45ef134":"code","3c8ccec4":"code","7fed5657":"code","1026650c":"code","eefaff2d":"code","be0a729a":"code","6e38379d":"code","ab88622b":"code","7e3c92cd":"code","9e1a46aa":"code","393470d8":"code","f280a917":"code","f8b89e6f":"code","9f95a8dc":"code","1435c8ff":"code","f76466f5":"code","7cf5e80d":"code","613dc01a":"code","aa3338bc":"code","1e6ba94a":"code","2cc29a12":"code","b31aa645":"code","4b8eda53":"code","51f2c6a4":"code","aea782c2":"code","efff0ace":"code","6b0aad10":"code","b6f170a2":"code","c1acdad0":"code","1e5534a9":"code","c2eaac29":"code","789fd380":"code","866723ec":"code","5f37d100":"code","8021e01f":"code","e22f6e66":"code","6b2ad87a":"code","24d7d97d":"code","87fa5330":"code","9ca2d2ce":"code","e17d68a3":"code","3b020f96":"code","01d16b0b":"code","069b4ed5":"code","ef3d5930":"code","ba1bf4ab":"code","25463740":"code","99795568":"code","d756beae":"code","69bc6ccf":"code","bb144bc8":"code","27b3c57e":"code","9fc15fcd":"code","23144e9a":"code","5b335fec":"code","69e96cd2":"code","cffc083e":"code","a0bec774":"code","b2e55c4e":"code","2bab4fbd":"code","f7811e38":"code","86ffbb1a":"code","4f5eb1b7":"code","e8e6ac65":"code","6f972125":"code","4b7ced28":"code","e49a2b8d":"code","ccd41f95":"code","89abc83e":"code","666c2674":"code","02439483":"code","a3ac1d6b":"code","59fe1890":"code","7e9d51f6":"code","ca0ca336":"code","7a04a060":"code","a309af2a":"code","267a5806":"code","a7439cd0":"code","ccef6ede":"code","05ea70f3":"code","48779e45":"code","ae2a9599":"code","0bba6fd7":"code","2eea95e9":"code","f4d0832e":"code","fcf40afd":"code","99d5af6f":"code","a19d597e":"code","af3ab79e":"code","d817ad4f":"code","31274e4a":"code","b78fded4":"code","6fadb644":"code","988f8d84":"code","ff0a27cc":"code","fd9eeddf":"code","548a45c1":"code","a68cf513":"code","4c7cfdbb":"code","ffaa642a":"code","b79eabce":"code","cb473216":"code","2c925e24":"code","a49a3000":"code","8fb88e57":"code","ac6a38b9":"code","273212e5":"code","a7af5024":"code","d516d57f":"code","03609df5":"code","5b6d9dfc":"code","5b729437":"code","7812ed09":"markdown","cc0423da":"markdown","54839ee6":"markdown","9a1d1e3d":"markdown","e68a073e":"markdown","7ce02ebe":"markdown","22849528":"markdown","22dd3e5b":"markdown","6ed6e1a6":"markdown","90dc6cb0":"markdown","f94b060f":"markdown","b0a14eab":"markdown","fbe6dd70":"markdown","79c9c6db":"markdown","1e32339f":"markdown","57de29df":"markdown","89202f52":"markdown","ccc78736":"markdown","89032021":"markdown","bf9ea233":"markdown","348c1f88":"markdown","0cd9e449":"markdown","f611bf90":"markdown","5e00afef":"markdown","fbb7b0f2":"markdown","3ae457e3":"markdown","dfaa9a81":"markdown","b93f1816":"markdown","2b96726f":"markdown","4379ba88":"markdown","12c491ab":"markdown","e0c03e4d":"markdown","8282e2f1":"markdown"},"source":{"690895e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport sys\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","89c92967":"print(os.listdir(\"..\/input\"))","dc473c7d":"import glob\n\nfrom os.path import join as path_join\nfrom scipy.stats import spearmanr, rankdata","fe73b1b6":"os.system('pip install ..\/input\/sacremoses\/sacremoses-master\/ > \/dev\/null')\nos.system('pip install ..\/input\/transformers\/transformers-master\/ > \/dev\/null')","1d4af969":"package_path = '..\/input\/radam-pytorch\/RAdam' \nsys.path.append(package_path)","377273dd":"folder = '..\/input\/google-quest-challenge\/'\npretrained_bert = \"..\/input\/pretrainedbertpytorch\/pretrained-bert-pytorch\/bert-base-uncased\/\"\nmodel_weight_path1 = '..\/input\/quest-003-55-bert-07-3-training-1\/'\nmodel_weight_path2 = '..\/input\/quest-003-55-bert-07-3-training-2\/'\nmodel_weight_path3 = '..\/input\/quest-003-55-bert-07-3-training-3\/'","777c9a54":"import os\nimport re\nimport gc\n\nimport pickle  \nimport numpy as np\nimport pandas as pd\nimport random\nimport copy\nimport string\nimport time\n\nimport nltk\nfrom nltk.tag import pos_tag\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelBinarizer\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom urllib.parse import urlparse\nimport math\nfrom tqdm import tqdm\n\nfrom spacy.lang.en import English\nfrom scipy.stats import spearmanr\n\nimport warnings\nwarnings.simplefilter('ignore')","072ab6a2":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nfrom torch.nn.utils.weight_norm import weight_norm","eb7e6afb":"import transformers\nprint(\"transformers:\", transformers.__version__)","64064abe":"SEED = 12345","c6c704f8":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(SEED)","9ec8468e":"import pickle\n\ndef read_pickle_from_file(pickle_file):\n    with open(pickle_file,'rb') as f:\n        x = pickle.load(f)\n    return x\n\ndef write_pickle_to_file(pickle_file, x):\n    with open(pickle_file, 'wb') as f:\n        pickle.dump(x, f, pickle.HIGHEST_PROTOCOL)","73759780":"train_df = pd.read_csv( f\"{folder}train.csv\" )\ntrain_df.shape","df084889":"test_df = pd.read_csv( f\"{folder}test.csv\" )\ntest_df.shape","17971743":"target_table = [\n    ['question_asker_intent_understanding',   'question'],\n    ['question_body_critical',                'question'],\n    ['question_conversational',               'question'],\n    ['question_expect_short_answer',          'question'],\n    ['question_fact_seeking',                 'question'],\n    ['question_has_commonly_accepted_answer', 'question'],\n    ['question_interestingness_others',       'question'],\n    ['question_interestingness_self',         'question'],\n    ['question_multi_intent',                 'question'],\n    ['question_not_really_a_question',        'question'],\n    ['question_opinion_seeking',              'question'],\n    ['question_type_choice',                  'question'],\n    ['question_type_compare',                 'question'],\n    ['question_type_consequence',             'question'],\n    ['question_type_definition',              'question'],\n    ['question_type_entity',                  'question'],\n    ['question_type_instructions',            'question'],\n    ['question_type_procedure',               'question'],\n    ['question_type_reason_explanation',      'question'],\n    ['question_type_spelling',                'question'],\n    ['question_well_written',                 'question'],\n    ['answer_helpful',                        'answer'],\n    ['answer_level_of_information',           'answer'],\n    ['answer_plausible',                      'answer'],\n    ['answer_relevance',                      'answer'],\n    ['answer_satisfaction',                   'answer'],\n    ['answer_type_instructions',              'answer'],\n    ['answer_type_procedure',                 'answer'],\n    ['answer_type_reason_explanation',        'answer'],\n    ['answer_well_written',                   'answer'],    \n]\n\ninput_columns = [\n    'question_title', \n    'question_body',    \n    'answer'\n]","c2c43aae":"target_question_columns = []\ntarget_answer_columns = []\n\nfor table in target_table:\n    if table[1] == 'question':\n        target_question_columns.append( table[0] )\n    elif table[1] == 'answer':\n        target_answer_columns.append( table[0] )   \n        \ntarget_columns = target_question_columns + target_answer_columns\n\nprint( 'question:', len(target_question_columns) )\nprint( 'answer:', len(target_answer_columns) )\nprint( 'total:', len(target_columns) )","7a7446c0":"for df in [train_df, test_df]:\n\n    ## domain components\n    df['domcom'] = df['url'].apply(lambda s: s.split(':\/\/')[1].split('\/')[0].split('.'))\n\n    # count components\n    df['dom_cnt'] = df['domcom'].apply(lambda s: len(s))\n\n    # extend length\n    df['domcom'] = df['domcom'].apply(lambda s: s + ['none', 'none'])\n\n    # components\n    for ii in range(0,4):\n        df['url_'+str(ii)] = df['domcom'].apply(lambda s: s[ii])\n\n    # clean up\n    df.drop('domcom', axis = 1, inplace = True)","1e83c8a5":"train_feature = pd.DataFrame()\ntest_feature = pd.DataFrame()","bf0fd6e5":"import nltk\nfrom nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))","4348bbf8":"for df, feature in [[train_df, train_feature], [test_df, test_feature]]:\n    for column in input_columns:\n        feature[column+'_total_length'] = df[column].apply(len)\n        feature[column+'_capitals'] = df[column].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n        feature[column+'_caps_vs_length'] = feature.apply(lambda row: float(row[column+'_capitals'])\/float(row[column+'_total_length']),axis=1)\n        feature[column+'_num_exclamation_marks'] = df[column].apply(lambda comment: comment.count('!'))\n        feature[column+'_num_question_marks'] = df[column].apply(lambda comment: comment.count('?'))\n        feature[column+'_num_punctuation'] = df[column].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n        feature[column+'_num_symbols'] = df[column].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n        feature[column+\"_num_chars\"] = df[column].apply(lambda x: len(str(x)))\n        feature[column+'_num_words'] = df[column].apply(lambda comment: len(comment.split()))\n        feature[column+'_num_unique_words'] = df[column].apply(lambda comment: len(set(w for w in comment.split())))\n        feature[column+'_words_vs_unique'] = feature[column+'_num_unique_words'] \/ feature[column+'_num_words']\n        feature[column+'_num_smilies'] = df[column].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n        \n        ## Number of stopwords in the text ##\n        feature[column+\"_num_stopwords\"] = df[column].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n        \n        ## Number of punctuations in the text ##\n        feature[column+\"_num_punctuations\"] =df[column].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n        \n        ## Number of title case words in the text ##\n        feature[column+\"_num_words_upper\"] = df[column].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))","b253577e":"nlp = English()\nsentencizer = nlp.create_pipe('sentencizer')\nnlp.add_pipe(sentencizer)\n\nans_user_and_category=train_df[train_df[['answer_user_name', 'category']].duplicated()][['answer_user_name', 'category']].values\nans_user_and_category.shape","8c5153d9":"def add_question_metadata_features(text):\n    doc=nlp(text)\n    indirect = 0\n    choice_words=0\n    reason_explanation_words = 0\n    question_count = 0\n    \n    for sent in doc.sents:\n        if '?' in sent.text and '?' == sent.text[-1]:\n            question_count += 1\n            for token in sent:\n                if token.text.lower()=='why':\n                    reason_explanation_words+=1\n                elif token.text.lower()=='or':\n                    choice_words+=1\n    if question_count==0:\n        indirect+=1\n    \n    return np.array([indirect, question_count, reason_explanation_words, choice_words])\n\n\ndef question_answer_author_same(df):\n    q_username = df['question_user_name']\n    a_username = df['answer_user_name']\n    author_same=[]\n    \n    for i in range(len(df)):\n        if q_username[i] == a_username[i]:\n            author_same.append(int(1))\n        else:\n            author_same.append(int(0))\n    return author_same\n\n\ndef add_external_features( df, feature ):\n    feature['question_vs_answer_length'] = feature['question_body_num_words']\/feature['answer_num_words']\n    feature['q_a_author_same'] = question_answer_author_same(df)\n    \n    answer_user_cat = []\n    for i in df[['answer_user_name', 'category']].values:\n        if i in ans_user_and_category:\n            answer_user_cat.append(int(1))\n        else:\n            answer_user_cat.append(int(0))\n    feature['answer_user_cat'] = answer_user_cat\n    \n    handmade_features=[]\n    for text in df['question_body'].values:\n        handmade_features.append(add_question_metadata_features(text))\n\n    feature = pd.concat( [ feature, pd.DataFrame( handmade_features, columns=['indirect', 'question_count', 'reason_explanation_words', 'choice_words'])], axis=1 )\n    \n    return feature","b7d2530c":"train_feature = add_external_features( train_df, train_feature )\ntest_feature  = add_external_features( test_df, test_feature )","d0f02016":"for column in input_columns:\n    print( \"{} | Min: {}, Max: {}\".format( column, train_feature[column+'_total_length'].min(), train_feature[column+'_total_length'].max() ) )\n    \nprint( '=====' )\n\nfor column in input_columns:\n    print( \"{} | Min: {}, Max: {}\".format( column, test_feature[column+'_total_length'].min(), test_feature[column+'_total_length'].max() ) )","19aa7206":"stop_words = nltk.corpus.stopwords.words('english')\nsymbol = [\"'\", '\"', ':', ';', '.', ',', '-', '!', '?', \"'s\", \")\", \"(\", \"...\", '``', \"''\", \"\/\", \"$\", \"%\", \"*\", \"&\", \"{\", \"}\", \"[\", \"]\"]\n\ndef get_prevalent( texts, top_count=15 ):    \n    tokenized_sents = [nltk.word_tokenize(i) for i in texts]\n    tokenized_sents = [flatten for inner in tokenized_sents for flatten in inner]   \n    \n    #fdist = nltk.FreqDist(w for w in tokenized_sents if w not in stop_words + symbol)\n    fdist = nltk.FreqDist(w.lower() for w in tokenized_sents if w.lower() not in stop_words + symbol)\n    comments = fdist.most_common(top_count)\n    \n    return [word[0] for word in comments]\n\nfor column in input_columns:\n    words = get_prevalent( train_df[column])\n    print( column, words )\n    \n    for word in words:\n        for df, feature in [[train_df, train_feature], [test_df, test_feature]]:\n            feature[column+'_num'+word] = df[column].apply(lambda comment: comment.count(word))","2229dda1":"find = re.compile(r\"^[^.]*\")\n\ntrain_df['netloc'] = train_df['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest_df['netloc'] = test_df['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n\ncount_columns = ['question_title', 'question_user_name', 'answer_user_name', 'category', 'netloc']\n\nfor col in count_columns:\n    value = train_df[col].value_counts()\n    train_feature[col+'_count'] = train_df[col].map( value )\n    test_feature[col+'_count']  = test_df[col].map( value ).fillna( 1 )","2ca7b567":"for col in train_feature.columns: \n    train_mean = np.nanmean( train_feature[col].values )\n    train_feature[col].fillna( train_mean, inplace=True )\n    test_feature[col].fillna( train_mean, inplace=True ) \n    \nprint( \"train: nan=\", np.sum( np.sum( pd.isnull( train_feature ) ) ) )\nprint( \"test : nan=\", np.sum( np.sum( pd.isnull( test_feature  ) ) ) )","6fd4fe78":"scaler = MinMaxScaler()\nscaler.fit(train_feature)\n\ntrain_feature = pd.DataFrame(scaler.transform(train_feature), columns=train_feature.columns)\ntest_feature = pd.DataFrame(scaler.transform(test_feature), columns=test_feature.columns)\n\ndel scaler\ngc.collect()","fe61c0af":"def convert_label( df, result_df, column, count=10 ):\n    labels = [ ( df[column].values>=(rate\/count) ).astype(np.int) for rate in range( 1, count+1 ) ]\n\n    columns = ['{}_{}'.format(column, i) for i in range(count)]\n    labels = np.array( labels ).T\n    \n    label_df = pd.DataFrame( labels, columns=columns )\n    result_df = pd.concat((result_df, label_df), axis=1)\n    \n    return result_df","53b24c58":"label_convert_count = 12\ntrain_feature2 = pd.DataFrame()\ntest_feature2 = pd.DataFrame()\n\nfor column in train_feature.columns:\n    train_feature2 = convert_label( train_feature, train_feature2, column, label_convert_count )\n    test_feature2 = convert_label( test_feature, test_feature2, column, label_convert_count )   \n    \ntrain_feature = train_feature2.copy()\ntest_feature = test_feature2.copy()\n\ndel train_feature2, test_feature2","2171aedf":"features = ['question_title', 'question_user_name', 'answer_user_name']\nlimits = [6, 8, 8]\n\nfor col, limit in zip( features, limits ):\n    value = train_df[col].value_counts()\n    train_df['item_count'] = train_df[col].map( value )    \n    train_df['item_value'] = train_df[col].copy()\n    train_df.loc[train_df.item_count < limit, 'item_value'] = \"___###___\"\n    \n    test_df['item_count'] = test_df[col].map( value ).fillna( 1 )    \n    test_df['item_value'] = test_df[col].copy()\n    test_df.loc[test_df.item_count < limit, 'item_value'] = \"___###___\"    \n    \n    lb = LabelBinarizer()\n    lb.fit( train_df['item_value'] )\n    \n    encode_train = lb.transform(train_df['item_value'])\n    encode_test = lb.transform(test_df['item_value'])\n    \n    columns = ['LabelBinarizer_{}'.format(i) for i in range(encode_train.shape[1])]\n    print( \"{}: {}\". format( col, len( train_df['item_value'].value_counts() ) ) )\n    \n    encode_train = pd.DataFrame( encode_train, columns=columns )\n    train_feature = pd.concat((train_feature, encode_train), axis=1)\n\n    encode_test = pd.DataFrame( encode_test, columns=columns )\n    test_feature = pd.concat((test_feature, encode_test), axis=1)      \n    \n    del lb\n    \ntrain_df.drop( ['item_count', 'item_count'], axis=1, inplace=True )\ntest_df.drop( ['item_count', 'item_count'], axis=1, inplace=True )","350c985b":"features = ['url_0', 'category']\nenc = OneHotEncoder( handle_unknown='ignore' )\nenc.fit( train_df[features] )\n\nencode_train = enc.transform(train_df[features]).toarray()\nencode_test = enc.transform(test_df[features]).toarray()\n\ncolumns = ['encode_{}'.format(i) for i in range(encode_train.shape[1])]\n\nencode_train = pd.DataFrame( encode_train, columns=columns )\ntrain_feature = pd.concat((train_feature, encode_train), axis=1)\n\nencode_test = pd.DataFrame( encode_test, columns=columns )\ntest_feature = pd.concat((test_feature, encode_test), axis=1)   \n\ndel encode_train, encode_test, enc","f9d1e62e":"for col in train_feature.columns: \n    train_mean = np.nanmean( train_feature[col].values )\n    train_feature[col].fillna( train_mean, inplace=True )\n    test_feature[col].fillna( train_mean, inplace=True ) \n    \nprint( \"train: nan=\", np.sum( np.sum( pd.isnull( train_feature ) ) ) )\nprint( \"test : nan=\", np.sum( np.sum( pd.isnull( test_feature  ) ) ) )","5234fd58":"# https:\/\/www.kaggle.com\/chenshengabc\/from-quest-encoding-ensemble-a-little-bit-differen\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '\/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '\u2022',  '~', '@', '\u00a3',\n '\u00b7', '_', '{', '}', '\u00a9', '^', '\u00ae', '`',  '<', '\u2192', '\u00b0', '\u20ac', '\u2122', '\u203a',  '\u2665', '\u2190', '\u00d7', '\u00a7', '\u2033', '\u2032', '\u00c2', '\u2588', '\u00bd', '\u00e0', '\u2026', '\\xa0', '\\t',\n '\u201c', '\u2605', '\u201d', '\u2013', '\u25cf', '\u00e2', '\u25ba', '\u2212', '\u00a2', '\u00b2', '\u00ac', '\u2591', '\u00b6', '\u2191', '\u00b1', '\u00bf', '\u25be', '\u2550', '\u00a6', '\u2551', '\u2015', '\u00a5', '\u2593', '\u2014', '\u2039', '\u2500', '\\u3000', '\\u202f',\n '\u2592', '\uff1a', '\u00bc', '\u2295', '\u25bc', '\u25aa', '\u2020', '\u25a0', '\u2019', '\u2580', '\u00a8', '\u2584', '\u266b', '\u2606', '\u00e9', '\u00af', '\u2666', '\u00a4', '\u25b2', '\u00e8', '\u00b8', '\u00be', '\u00c3', '\u22c5', '\u2018', '\u221e', '\u00ab',\n '\u2219', '\uff09', '\u2193', '\u3001', '\u2502', '\uff08', '\u00bb', '\uff0c', '\u266a', '\u2569', '\u255a', '\u00b3', '\u30fb', '\u2566', '\u2563', '\u2554', '\u2557', '\u25ac', '\u2764', '\u00ef', '\u00d8', '\u00b9', '\u2264', '\u2021', '\u221a', ]\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"couldnt\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"doesnt\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"havent\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"shouldnt\" : \"should not\",\n\"that's\" : \"that is\",\n\"thats\" : \"that is\",\n\"there's\" : \"there is\",\n\"theres\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"theyre\":  \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\n\ndef clean_text(x):\n    x = str(x).replace(\"\\n\",\"\")\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x","e52d1fbb":"from nltk.tokenize.treebank import TreebankWordTokenizer\ntokenizer = TreebankWordTokenizer()\n\ndef handle_contractions(x):\n    x = tokenizer.tokenize(x)\n    return x\n\ndef fix_quote(x):\n    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n    x = ' '.join(x)\n    return x\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\ndef replace_typical_misspell(text):\n    mispellings, mispellings_re = _get_mispell(mispell_dict)\n\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\n\ndef clean_data(df, columns: list):\n    for col in columns:\n#         df[col] = df[col].apply(lambda x: clean_numbers(x))\n        df[col] = df[col].apply(lambda x: clean_text(x.lower()))\n        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n        df[col] = df[col].apply(lambda x: handle_contractions(x))  \n        df[col] = df[col].apply(lambda x: fix_quote(x))   \n    \n    return df\n\n\ntrain_df = clean_data( train_df, input_columns )\ntest_df = clean_data( test_df, input_columns )\n\ndel tokenizer","b58a0207":"class SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x\n\nclass NeuralNet(nn.Module):\n    def __init__(self, num_features, num_labels, pretrained_bert ):\n        super(NeuralNet, self).__init__()\n        \n        self.bert = transformers.BertModel.from_pretrained( pretrained_bert )\n        self.num_features = num_features\n        self.num_labels = num_labels\n        \n        self.encoded_dropout = SpatialDropout( 0.2 )\n        self.pooled_dropout = nn.Dropout( 0.2 )        \n        \n        self.feature_linear = nn.Sequential(\n            nn.Linear( self.num_features, self.num_features ),\n            nn.ReLU( inplace=True ),\n            nn.Dropout( 0.2 ),            \n        )\n        \n        dense_hidden_units = self.bert.config.hidden_size * 3 + self.num_features\n        \n        self.linear1 = nn.Linear( dense_hidden_units, dense_hidden_units )\n        self.linear2 = nn.Linear( dense_hidden_units, dense_hidden_units )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear( dense_hidden_units, num_labels ),\n        )\n        \n    def forward( self, ids, masks, segments, feature ):  \n        \n        feature_output = self.feature_linear( feature )\n        \n        sequence_output, pooled_output = self.bert( input_ids=ids, attention_mask=masks, token_type_ids=segments )\n        sequence_output = self.encoded_dropout(sequence_output)\n        pooled_output = self.pooled_dropout(pooled_output)        \n        \n        avg_pool = torch.mean( sequence_output, 1 )\n        max_pool, _ = torch.max( sequence_output, 1 )\n        \n        h_conc = torch.cat( ( avg_pool, max_pool, pooled_output, feature_output ), 1 )\n        \n        h_conc_linear  = F.relu(self.linear1(h_conc))\n        hidden = h_conc + h_conc_linear \n            \n        h_conc_linear  = F.relu(self.linear2(hidden))\n        hidden = hidden + h_conc_linear      \n        \n        return self.classifier( hidden )","8c324421":"def compute_input_title_question( df, tokenizer, max_sequence_length=512 ):\n    \n    input_ids, input_masks, input_segments = [], [], []\n    \n    for _, instance in df.iterrows():\n         \n        title    = tokenizer.tokenize(instance.question_title)\n        question = tokenizer.tokenize(instance.question_body)\n\n        if (len(title)+len(question)+3) > max_sequence_length:\n            if len(title) > 30:\n                title = title[:30]\n                \n            question_len = max_sequence_length - len(title) - 3\n            question = question[:question_len]\n        \n        #token = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] \n        #token_ids = tokenizer.convert_tokens_to_ids(token)\n        \n        title_ids    = tokenizer.convert_tokens_to_ids(title)\n        question_ids = tokenizer.convert_tokens_to_ids(question)\n        cls_ids      = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids      = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        token_ids = cls_ids + title_ids + sep_ids + question_ids + sep_ids\n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        segments = [0]*(len(title_ids)+2) + [1]*(len(question_ids)+1) + padding\n        \n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),   \n    ]","d6f622f0":"def compute_input_arrays( df, tokenizer, max_sequence_length=512 ):\n    \n    input_ids, input_masks, input_segments = [], [], []    \n    t_max_len = 35     \n    \n    for _, instance in df.iterrows():\n        \n        title    = tokenizer.tokenize(instance.question_title)\n        question = tokenizer.tokenize(instance.question_body)\n        answer   = tokenizer.tokenize(instance.answer)\n\n        if (len(title)+len(question)+len(answer)+4) > max_sequence_length:\n            if len(title) > t_max_len:\n                title = title[:t_max_len]\n                \n            question_len = ( max_sequence_length - len(title) - 4 ) \/\/ 2\n            question = question[:question_len]\n            \n            answer_len = max_sequence_length - len(title) - len(question) - 4\n            answer = answer[:answer_len]\n        \n        #token = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n        #token_ids = tokenizer.convert_tokens_to_ids(token)\n        \n        title_ids    = tokenizer.convert_tokens_to_ids(title)\n        question_ids = tokenizer.convert_tokens_to_ids(question)\n        answer_ids   = tokenizer.convert_tokens_to_ids(answer) \n        cls_ids      = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids      = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        token_ids = cls_ids + title_ids + sep_ids + question_ids + sep_ids + answer_ids + sep_ids\n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        segments = [0]*(len(title_ids)+len(question_ids)+3) + [1]*(len(answer_ids)+1) + padding\n        \n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),   \n    ]","0ad35a22":"n_splits = 6\n\n'''\nx_train = train_feature.values\ny_train = train_df[target_columns].values\n\ncv = KFold( n_splits=n_splits, random_state=SEED )\nkfold_split = list( cv.split( x_train, y_train ) )\n\nwrite_pickle_to_file( 'kfold_split_index.pkl', kfold_split )\n'''\n\nkfold_split = read_pickle_from_file( model_weight_path1 + 'kfold_split_index.pkl' )","96ac656a":"test_pred_datas = {}\ntest_pred_weights = {}\n\nfor column in target_columns:\n    test_pred_datas[column] = np.zeros( len(test_df) )\n    test_pred_weights[column] = 0.0\n    \ndef add_test_pred_data( prediction, columns, weight ):\n    for column_idx, column in enumerate( columns ):\n        test_pred_datas[column] += weight * prediction[:, column_idx]  \n        test_pred_weights[column] += weight    ","7aeeba2c":"validation_datas = {}\nvalidation_counts = {}\n\nfor column in target_columns:\n    validation_datas[column] = np.zeros( len(train_df) )\n    validation_counts[column] = np.zeros( len(train_df) )\n\ndef add_validation_data( prediction, columns, idx ):\n    for column_idx, column in enumerate( columns ):\n        validation_datas[column][idx] += prediction[:, column_idx]  \n        validation_counts[column][idx] += 1.0    ","9077c247":"def mean_spearmanr_correlation_score( y_true, y_pred ):\n    num_labels = y_pred.shape[1]\n    score = np.nanmean( [ spearmanr( y_pred[:, idx], y_true[:, idx] ).correlation for idx in range(num_labels) ] )\n    return score ","1a6ddc14":"class QuestDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, features, labels = None):\n        \n        self.inputs   = inputs\n        self.features = features\n        \n        if labels is not None:\n            self.labels = labels\n        else:\n            self.labels = None\n\n    def __getitem__(self, idx):\n        \n        input_ids       = self.inputs[0][idx]\n        input_masks     = self.inputs[1][idx]\n        input_segments  = self.inputs[2][idx]\n        input_features  = self.features[idx]\n        \n        if self.labels is not None: # targets\n            input_labels = self.labels[idx]\n            return input_ids, input_masks, input_segments, input_features, input_labels\n        \n        return input_ids, input_masks, input_segments, input_features\n\n    def __len__(self):\n        return len(self.inputs[0])","2363291d":"def model_test_validation( label_columns, train_inputs, test_inputs, x_train, x_test, weight_files ):\n    \n    if len(kfold_split) != len(weight_files):\n        return\n    \n    batch_size   = 6    \n    num_features = x_test.shape[1]\n    num_labels   = len(label_columns)\n\n    test_dataset = QuestDataset( test_inputs, x_test, None )\n    test_loader = torch.utils.data.DataLoader( test_dataset, batch_size=batch_size, shuffle=False )   \n    \n    for k, (train_idx, valid_idx) in enumerate(kfold_split):\n        \n        fname = weight_files[k]\n        print( k+1, fname )\n        \n        x_train_valid = x_train[valid_idx]\n        train_inputs_valid = [x[valid_idx] for x in train_inputs]\n\n        valid_dataset = QuestDataset( train_inputs_valid, x_train_valid, None )\n        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False )\n        \n        model = NeuralNet( num_features, num_labels, pretrained_bert )\n        model.to('cuda:0')\n\n        model.load_state_dict( torch.load( fname ) )      \n        model.eval()\n     \n        #====================\n        #validation\n        valid_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in valid_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                valid_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            valid_preds_fold = np.array( valid_preds_fold )\n            add_validation_data( valid_preds_fold, label_columns, valid_idx )\n            \n        #====================\n        #test\n        test_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in test_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                test_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            test_preds_fold = np.array( test_preds_fold )\n            add_test_pred_data( test_preds_fold, label_columns, 1.0 )            \n\n        del model, valid_dataset, valid_loader\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    del test_dataset, test_loader","b5028111":"tokenizer = transformers.BertTokenizer.from_pretrained( pretrained_bert )","b756afb8":"train_inputs = compute_input_title_question( train_df, tokenizer, max_sequence_length=512 )\ntest_inputs = compute_input_title_question( test_df, tokenizer, max_sequence_length=512 )\n\nx_train = train_feature.values\nx_test  = test_feature.values\n\nprint( x_train.shape )\nprint( x_test.shape )\nprint( len( target_question_columns ) )\n\nweight_files = [\n    model_weight_path1 + 'best_weights_003_55_7_3_question_1.pth',\n    model_weight_path1 + 'best_weights_003_55_7_3_question_2.pth',\n    model_weight_path2 + 'best_weights_003_55_7_3_question_3.pth',\n    model_weight_path2 + 'best_weights_003_55_7_3_question_4.pth',\n    model_weight_path3 + 'best_weights_003_55_7_3_question_5.pth',\n    model_weight_path3 + 'best_weights_003_55_7_3_question_6.pth',\n]\n\nmodel_test_validation( target_question_columns, train_inputs, test_inputs, x_train, x_test, weight_files )\n\ndel x_train, x_test\ndel train_inputs, test_inputs","a3135806":"train_inputs = compute_input_arrays( train_df, tokenizer, max_sequence_length=512 )\ntest_inputs = compute_input_arrays( test_df, tokenizer, max_sequence_length=512 )\n\nx_train = train_feature.values\nx_test  = test_feature.values\n\nprint( x_train.shape )\nprint( x_test.shape )\nprint( len( target_answer_columns ) )\n\nweight_files = [\n    model_weight_path1 + 'best_weights_003_55_7_3_answer_1.pth',\n    model_weight_path1 + 'best_weights_003_55_7_3_answer_2.pth',\n    model_weight_path2 + 'best_weights_003_55_7_3_answer_3.pth',\n    model_weight_path2 + 'best_weights_003_55_7_3_answer_4.pth',\n    model_weight_path3 + 'best_weights_003_55_7_3_answer_5.pth',\n    model_weight_path3 + 'best_weights_003_55_7_3_answer_6.pth',\n]\n\nmodel_test_validation( target_answer_columns, train_inputs, test_inputs, x_train, x_test, weight_files )\n\ndel x_train, x_test\ndel train_inputs, test_inputs\n","a6e7a0c4":"del train_feature, test_feature\ndel target_question_columns, target_answer_columns ","5fe497f4":"validationT = pd.DataFrame()\n\nfor column in target_columns:\n    preds = validation_datas[column]\n    count = validation_counts[column]\n    count = np.where( count < 0.5, 1.0, count )\n    \n    validationT[column] = preds \/ count","b65dd749":"mean_spearmanr_correlation_score( validationT.values, train_df[target_columns].values )","6be9866f":"validationT.head()","fbc1b111":"test_pred_weights","5dfcd3c0":"test_predsT = pd.read_csv( f\"{folder}sample_submission.csv\" )\n\nfor column in target_columns:\n    preds = test_pred_datas[column]\n    weight = test_pred_weights[column]\n    \n    test_predsT[column] = preds \/ weight","ea7fbf6d":"test_predsT.head()","556689db":"del target_columns, input_columns\ndel test_pred_datas, test_pred_weights\ndel validation_datas, validation_counts","5dbc7b1d":"torch.cuda.empty_cache()\ngc.collect()","41989db7":"blabla","d9a24c6e":"!ls ..\/input\/photostage1\/","0605f0df":"folder = '..\/input\/google-quest-challenge\/'\npretrained_bert = \"..\/input\/pretrainedbertpytorch\/pretrained-bert-pytorch\/gpt2\/\"\nmodel_weight_path1 = '..\/input\/photostage1\/best_weights_006-55-gpt2-01_question_1.pth'\nmodel_weight_path2 = '..\/input\/photostage2\/best_weights_006-55-gpt2-01_question_2.pth'\nmodel_weight_path3 = '..\/input\/photostage3\/best_weights_006-55-gpt2-01_question_3.pth'\nmodel_weight_path4 = '..\/input\/photostage4\/best_weights_006-55-gpt2-01_question_4.pth'\nmodel_weight_path5 = '..\/input\/photostage5\/best_weights_006-55-gpt2-01_question_5.pth'\nmodel_weight_path6 = '..\/input\/photostage6\/best_weights_006-55-gpt2-01_question_6.pth'\nmodel_weight_path7 = '..\/input\/photostagea1\/best_weights_006-55-gpt2-01_answer_1.pth'\nmodel_weight_path8 = '..\/input\/photostagea2\/best_weights_006-55-gpt2-01_answer_2.pth'\nmodel_weight_path9 = '..\/input\/photostagea3\/best_weights_006-55-gpt2-01_answer_3.pth'\nmodel_weight_path10 = '..\/input\/photostagea4\/best_weights_006-55-gpt2-01_answer_4.pth'\nmodel_weight_path11 = '..\/input\/photostagea5\/best_weights_006-55-gpt2-01_answer_5.pth'\nmodel_weight_path12 = '..\/input\/photostagea6\/best_weights_006-55-gpt2-01_answer_6.pth'\n\n","109c0b6e":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nfrom torch.nn.utils.weight_norm import weight_norm\nfrom transformers import (\n    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n    get_cosine_schedule_with_warmup,    GPT2Config,GPT2Model,\n    GPT2LMHeadModel,\n    GPT2Tokenizer,\n)\nfrom transformers.modeling_gpt2 import GPT2PreTrainedModel","f3c4ef58":"import transformers\nprint(\"transformers:\", transformers.__version__)","616a9d4f":"SEED = 12345\n\nstart_time_all = time.time()","ac2f7628":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(SEED)","6d430e18":"import pickle\n\ndef read_pickle_from_file(pickle_file):\n    with open(pickle_file,'rb') as f:\n        x = pickle.load(f)\n    return x\n\ndef write_pickle_to_file(pickle_file, x):\n    with open(pickle_file, 'wb') as f:\n        pickle.dump(x, f, pickle.HIGHEST_PROTOCOL)\n        \n        \ndef time_to_str(t, mode='min'):\n    if mode=='min':\n        t  = int(t)\/60\n        hr = t\/\/60\n        min = t%60\n        return '%2d hr %02d min'%(hr,min)\n\n    elif mode=='sec':\n        t   = int(t)\n        min = t\/\/60\n        sec = t%60\n        return '%2d min %02d sec'%(min,sec)\n\n    else:\n        raise NotImplementedError","a45ef134":"train_df = pd.read_csv( f\"{folder}train.csv\" )\ntrain_df.shape\ntest_df = pd.read_csv( f\"{folder}test.csv\" )\ntest_df.shape","3c8ccec4":"target_table = [\n    ['question_asker_intent_understanding',   'question'],\n    ['question_body_critical',                'question'],\n    ['question_conversational',               'question'],\n    ['question_expect_short_answer',          'question'],\n    ['question_fact_seeking',                 'question'],\n    ['question_has_commonly_accepted_answer', 'question'],\n    ['question_interestingness_others',       'question'],\n    ['question_interestingness_self',         'question'],\n    ['question_multi_intent',                 'question'],\n    ['question_not_really_a_question',        'question'],\n    ['question_opinion_seeking',              'question'],\n    ['question_type_choice',                  'question'],\n    ['question_type_compare',                 'question'],\n    ['question_type_consequence',             'question'],\n    ['question_type_definition',              'question'],\n    ['question_type_entity',                  'question'],\n    ['question_type_instructions',            'question'],\n    ['question_type_procedure',               'question'],\n    ['question_type_reason_explanation',      'question'],\n    ['question_type_spelling',                'question'],\n    ['question_well_written',                 'question'],\n    ['answer_helpful',                        'answer'],\n    ['answer_level_of_information',           'answer'],\n    ['answer_plausible',                      'answer'],\n    ['answer_relevance',                      'answer'],\n    ['answer_satisfaction',                   'answer'],\n    ['answer_type_instructions',              'answer'],\n    ['answer_type_procedure',                 'answer'],\n    ['answer_type_reason_explanation',        'answer'],\n    ['answer_well_written',                   'answer'],    \n]\n\ninput_columns = [\n    'question_title', \n    'question_body',    \n    'answer'\n]","7fed5657":"target_question_columns = []\ntarget_answer_columns = []\n\nfor table in target_table:\n    if table[1] == 'question':\n        target_question_columns.append( table[0] )\n    elif table[1] == 'answer':\n        target_answer_columns.append( table[0] )   \n        \ntarget_columns = target_question_columns + target_answer_columns\n\nprint( 'question:', len(target_question_columns) )\nprint( 'answer:', len(target_answer_columns) )\nprint( 'total:', len(target_columns) )","1026650c":"import html\nfor df in [train_df, test_df]:\n\n    ## domain components\n    df['domcom'] = df['url'].apply(lambda s: s.split(':\/\/')[1].split('\/')[0].split('.'))\n\n    # count components\n    df['dom_cnt'] = df['domcom'].apply(lambda s: len(s))\n\n    # extend length\n    df['domcom'] = df['domcom'].apply(lambda s: s + ['none', 'none'])\n\n    # components\n    for ii in range(0,4):\n        df['url_'+str(ii)] = df['domcom'].apply(lambda s: s[ii])\n\n    # clean up\n    df.drop('domcom', axis = 1, inplace = True)\n    \n    df.question_body = df.question_body.apply(html.unescape)\n    df.answer        = df.answer.apply(html.unescape)\n    \n    df['question_body'] = df['question_body'].apply(lambda s: s.replace(\"\\&gt\",\">\"))\n    df['question_body'] = df['question_body'].apply(lambda s: s.replace(\"\\&lt\",\"<\"))\n    df['question_body'] = df['question_body'].apply(lambda s: s.replace(\"\\&amp\",\"&\"))\n    df['question_body'] = df['question_body'].apply(lambda s: s.replace(\"\\&quot;\",\"\\\"\"))    ","eefaff2d":"train_feature = pd.DataFrame()\ntest_feature = pd.DataFrame()\nimport nltk\nfrom nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))\nfor df, feature in [[train_df, train_feature], [test_df, test_feature]]:\n    for column in input_columns:\n        feature[column+'_total_length'] = df[column].apply(len)\n        feature[column+'_capitals'] = df[column].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n        feature[column+'_caps_vs_length'] = feature.apply(lambda row: float(row[column+'_capitals'])\/float(row[column+'_total_length']),axis=1)\n        feature[column+'_num_exclamation_marks'] = df[column].apply(lambda comment: comment.count('!'))\n        feature[column+'_num_question_marks'] = df[column].apply(lambda comment: comment.count('?'))\n        feature[column+'_num_punctuation'] = df[column].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n        feature[column+'_num_symbols'] = df[column].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n        feature[column+\"_num_chars\"] = df[column].apply(lambda x: len(str(x)))\n        feature[column+'_num_words'] = df[column].apply(lambda comment: len(comment.split()))\n        feature[column+'_num_unique_words'] = df[column].apply(lambda comment: len(set(w for w in comment.split())))\n        feature[column+'_words_vs_unique'] = feature[column+'_num_unique_words'] \/ feature[column+'_num_words']\n        feature[column+'_num_smilies'] = df[column].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n        feature[column+'_num_doubt'] = df[column].apply(lambda comment: comment.count('not sure'))\n        feature[column+'_num_think'] = df[column].apply(lambda comment: sum(comment.count(w) for w in ['thinking','think','thought']))        \n        ## Number of stopwords in the text ##\n        feature[column+\"_num_stopwords\"] = df[column].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n        \n        ## Number of punctuations in the text ##\n        feature[column+\"_num_punctuations\"] =df[column].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n        \n        ## Number of title case words in the text ##\n        feature[column+\"_num_words_upper\"] = df[column].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n        \nnlp = English()\nsentencizer = nlp.create_pipe('sentencizer')\nnlp.add_pipe(sentencizer)\n\nans_user_and_category=train_df[train_df[['answer_user_name', 'category']].duplicated()][['answer_user_name', 'category']].values\nans_user_and_category.shape        ","be0a729a":"def add_question_metadata_features(text):\n    doc=nlp(text)\n    indirect = 0\n    choice_words=0\n    reason_explanation_words = 0\n    question_count = 0\n    \n    for sent in doc.sents:\n        if '?' in sent.text and '?' == sent.text[-1]:\n            question_count += 1\n            for token in sent:\n                if token.text.lower()=='why':\n                    reason_explanation_words+=1\n                elif token.text.lower()=='or':\n                    choice_words+=1\n    if question_count==0:\n        indirect+=1\n    \n    return np.array([indirect, question_count, reason_explanation_words, choice_words])\n\n\ndef question_answer_author_same(df):\n    q_username = df['question_user_name']\n    a_username = df['answer_user_name']\n    author_same=[]\n    \n    for i in range(len(df)):\n        if q_username[i] == a_username[i]:\n            author_same.append(int(1))\n        else:\n            author_same.append(int(0))\n    return author_same\n\n\ndef add_external_features( df, feature ):\n    feature['question_vs_answer_length'] = feature['question_body_num_words']\/feature['answer_num_words']\n    feature['q_a_author_same'] = question_answer_author_same(df)\n    \n    answer_user_cat = []\n    for i in df[['answer_user_name', 'category']].values:\n        if i in ans_user_and_category:\n            answer_user_cat.append(int(1))\n        else:\n            answer_user_cat.append(int(0))\n    feature['answer_user_cat'] = answer_user_cat\n    \n    handmade_features=[]\n    for text in df['question_body'].values:\n        handmade_features.append(add_question_metadata_features(text))\n\n    feature = pd.concat( [ feature, pd.DataFrame( handmade_features, columns=['indirect', 'question_count', 'reason_explanation_words', 'choice_words'])], axis=1 )\n    \n    return feature","6e38379d":"train_feature = add_external_features( train_df, train_feature )\ntest_feature  = add_external_features( test_df, test_feature )","ab88622b":"for column in input_columns:\n    print( \"{} | Min: {}, Max: {}\".format( column, train_feature[column+'_total_length'].min(), train_feature[column+'_total_length'].max() ) )\n    \nprint( '=====' )\n\nfor column in input_columns:\n    print( \"{} | Min: {}, Max: {}\".format( column, test_feature[column+'_total_length'].min(), test_feature[column+'_total_length'].max() ) )","7e3c92cd":"stop_words = nltk.corpus.stopwords.words('english')\nsymbol = [\"'\", '\"', ':', ';', '.', ',', '-', '!', '?', \"'s\", \")\", \"(\", \"...\", '``', \"''\", \"\/\", \"$\", \"%\", \"*\", \"&\", \"{\", \"}\", \"[\", \"]\"]\n\ndef get_prevalent( texts, top_count=15 ):    \n    tokenized_sents = [nltk.word_tokenize(i) for i in texts]\n    tokenized_sents = [flatten for inner in tokenized_sents for flatten in inner]   \n    \n    #fdist = nltk.FreqDist(w for w in tokenized_sents if w not in stop_words + symbol)\n    fdist = nltk.FreqDist(w.lower() for w in tokenized_sents if w.lower() not in stop_words + symbol)\n    comments = fdist.most_common(top_count)\n    \n    return [word[0] for word in comments]\n\nfor column in input_columns:\n    words = get_prevalent( train_df[column])\n    print( column, words )\n    \n    for word in words:\n        for df, feature in [[train_df, train_feature], [test_df, test_feature]]:\n            feature[column+'_num'+word] = df[column].apply(lambda comment: comment.count(word))","9e1a46aa":"find = re.compile(r\"^[^.]*\")\n\ntrain_df['netloc'] = train_df['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest_df['netloc'] = test_df['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n\ncount_columns = ['question_title', 'question_user_name', 'answer_user_name', 'category', 'netloc']\n\nfor col in count_columns:\n    value = train_df[col].value_counts()\n    train_feature[col+'_count'] = train_df[col].map( value )\n    test_feature[col+'_count']  = test_df[col].map( value ).fillna( 1 )\n    \nfor col in train_feature.columns: \n    train_mean = np.nanmean( train_feature[col].values )\n    train_feature[col].fillna( train_mean, inplace=True )\n    test_feature[col].fillna( train_mean, inplace=True ) \n    \nprint( \"train: nan=\", np.sum( np.sum( pd.isnull( train_feature ) ) ) )\nprint( \"test : nan=\", np.sum( np.sum( pd.isnull( test_feature  ) ) ) )\n\nscaler = MinMaxScaler()\nscaler.fit(train_feature)\n\ntrain_feature = pd.DataFrame(scaler.transform(train_feature), columns=train_feature.columns)\ntest_feature = pd.DataFrame(scaler.transform(test_feature), columns=test_feature.columns)\n\ndel scaler\ngc.collect()","393470d8":"print( train_feature.shape )\nprint( test_feature.shape )\nprint( 'time: {}'.format( time_to_str((time.time()-start_time_all),'min') ) )","f280a917":"def convert_label( df, result_df, column, count=10 ):\n    labels = [ ( df[column].values>=(rate\/count) ).astype(np.int) for rate in range( 1, count+1 ) ]\n\n    columns = ['{}_{}'.format(column, i) for i in range(count)]\n    labels = np.array( labels ).T\n    \n    label_df = pd.DataFrame( labels, columns=columns )\n    result_df = pd.concat((result_df, label_df), axis=1)\n    \n    return result_df\n\n\ndef convert_label_origin( df, result_df, column, count=10 ):\n    \n    columns = ['{}_{}'.format(column, i) for i in range(count)]\n    labels = df[columns].values\n    values = []\n    \n    for i in range( len(labels ) ):\n        value = 0.0\n                   \n        for j in range(count):\n            if labels[i][j] > 0.5:\n                value = (j+1) \/ count\n    \n        values.append( value )\n                   \n    label_df = pd.DataFrame( values, columns=[column] )\n    result_df = pd.concat((result_df, label_df), axis=1)\n    \n    return result_df","f8b89e6f":"label_convert_count = 12\ntrain_feature2 = pd.DataFrame()\ntest_feature2 = pd.DataFrame()\n\nfor column in train_feature.columns:\n    train_feature2 = convert_label( train_feature, train_feature2, column, label_convert_count )\n    test_feature2 = convert_label( test_feature, test_feature2, column, label_convert_count )   \n    \ntrain_feature = train_feature2.copy()\ntest_feature = test_feature2.copy()\n\ndel train_feature2, test_feature2","9f95a8dc":"print( train_feature.shape )\nprint( test_feature.shape )","1435c8ff":"features = ['question_title', 'question_user_name', 'answer_user_name']\nlimits = [6, 8, 8]\n\n#features = ['question_title', 'question_user_name', 'answer_user_name', 'category', 'url_0', 'url_1']\n#limits = [6, 8, 8, 1, 60, 1]\n\nfor col, limit in zip( features, limits ):\n    value = train_df[col].value_counts()\n    train_df['item_count'] = train_df[col].map( value )    \n    train_df['item_value'] = train_df[col].copy()\n    train_df.loc[train_df.item_count < limit, 'item_value'] = \"limit_abcdefg123456789\"\n    \n    test_df['item_count'] = test_df[col].map( value ).fillna( 1 )    \n    test_df['item_value'] = test_df[col].copy()\n    test_df.loc[test_df.item_count < limit, 'item_value'] = \"limit_abcdefg123456789\"    \n    \n    lb = LabelBinarizer()\n    lb.fit( train_df['item_value'] )\n    \n    encode_train = lb.transform(train_df['item_value'])\n    encode_test = lb.transform(test_df['item_value'])\n    \n    columns = ['LabelBinarizer_{}'.format(i) for i in range(encode_train.shape[1])]\n    print( \"{}: {}\". format( col, len( train_df['item_value'].value_counts() ) ) )\n    \n    encode_train = pd.DataFrame( encode_train, columns=columns )\n    train_feature = pd.concat((train_feature, encode_train), axis=1)\n\n    encode_test = pd.DataFrame( encode_test, columns=columns )\n    test_feature = pd.concat((test_feature, encode_test), axis=1)      \n    \n    del lb\n    \ntrain_df.drop( ['item_count', 'item_count'], axis=1, inplace=True )\ntest_df.drop( ['item_count', 'item_count'], axis=1, inplace=True )","f76466f5":"features = ['url_0', 'category']\nenc = OneHotEncoder( handle_unknown='ignore' )\nenc.fit( train_df[features] )\n\nencode_train = enc.transform(train_df[features]).toarray()\nencode_test = enc.transform(test_df[features]).toarray()\n\ncolumns = ['encode_{}'.format(i) for i in range(encode_train.shape[1])]\n\nencode_train = pd.DataFrame( encode_train, columns=columns )\ntrain_feature = pd.concat((train_feature, encode_train), axis=1)\n\nencode_test = pd.DataFrame( encode_test, columns=columns )\ntest_feature = pd.concat((test_feature, encode_test), axis=1)   \n\ndel encode_train, encode_test, enc\nprint( train_feature.shape )\nprint( test_feature.shape )\nprint( 'time: {}'.format( time_to_str((time.time()-start_time_all),'min') ) )","7cf5e80d":"for col in train_feature.columns: \n    train_mean = np.nanmean( train_feature[col].values )\n    train_feature[col].fillna( train_mean, inplace=True )\n    test_feature[col].fillna( train_mean, inplace=True ) \n    \nprint( \"train: nan=\", np.sum( np.sum( pd.isnull( train_feature ) ) ) )\nprint( \"test : nan=\", np.sum( np.sum( pd.isnull( test_feature  ) ) ) )\n","613dc01a":"# https:\/\/www.kaggle.com\/chenshengabc\/from-quest-encoding-ensemble-a-little-bit-differen\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '\/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '\u2022',  '~', '@', '\u00a3',\n '\u00b7', '_', '{', '}', '\u00a9', '^', '\u00ae', '`',  '<', '\u2192', '\u00b0', '\u20ac', '\u2122', '\u203a',  '\u2665', '\u2190', '\u00d7', '\u00a7', '\u2033', '\u2032', '\u00c2', '\u2588', '\u00bd', '\u00e0', '\u2026', '\\xa0', '\\t',\n '\u201c', '\u2605', '\u201d', '\u2013', '\u25cf', '\u00e2', '\u25ba', '\u2212', '\u00a2', '\u00b2', '\u00ac', '\u2591', '\u00b6', '\u2191', '\u00b1', '\u00bf', '\u25be', '\u2550', '\u00a6', '\u2551', '\u2015', '\u00a5', '\u2593', '\u2014', '\u2039', '\u2500', '\\u3000', '\\u202f',\n '\u2592', '\uff1a', '\u00bc', '\u2295', '\u25bc', '\u25aa', '\u2020', '\u25a0', '\u2019', '\u2580', '\u00a8', '\u2584', '\u266b', '\u2606', '\u00e9', '\u00af', '\u2666', '\u00a4', '\u25b2', '\u00e8', '\u00b8', '\u00be', '\u00c3', '\u22c5', '\u2018', '\u221e', '\u00ab',\n '\u2219', '\uff09', '\u2193', '\u3001', '\u2502', '\uff08', '\u00bb', '\uff0c', '\u266a', '\u2569', '\u255a', '\u00b3', '\u30fb', '\u2566', '\u2563', '\u2554', '\u2557', '\u25ac', '\u2764', '\u00ef', '\u00d8', '\u00b9', '\u2264', '\u2021', '\u221a', ]\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"couldnt\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"doesnt\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"havent\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"shouldnt\" : \"should not\",\n\"that's\" : \"that is\",\n\"thats\" : \"that is\",\n\"there's\" : \"there is\",\n\"theres\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"theyre\":  \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\n\ndef clean_text(x):\n    x = str(x).replace(\"\\n\",\"\")\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x","aa3338bc":"from nltk.tokenize.treebank import TreebankWordTokenizer\ntokenizer = TreebankWordTokenizer()\n\ndef handle_contractions(x):\n    x = tokenizer.tokenize(x)\n    return x\n\ndef fix_quote(x):\n    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n    x = ' '.join(x)\n    return x\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\ndef replace_typical_misspell(text):\n    mispellings, mispellings_re = _get_mispell(mispell_dict)\n\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\n\ndef clean_data(df, columns: list):\n    for col in columns:\n#         df[col] = df[col].apply(lambda x: clean_numbers(x))\n        df[col] = df[col].apply(lambda x: clean_text(x.lower()))\n        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n        df[col] = df[col].apply(lambda x: handle_contractions(x))  \n        df[col] = df[col].apply(lambda x: fix_quote(x))   \n    \n    return df\n\n\ntrain_df = clean_data( train_df, input_columns )\ntest_df = clean_data( test_df, input_columns )\n\ndel tokenizer","1e6ba94a":"# 'Cyclical Learning Rates for Training Neural Networks'- Leslie N. Smith, arxiv 2017\n#       https:\/\/arxiv.org\/abs\/1506.01186\n#       https:\/\/github.com\/bckenstler\/CLR\n\nclass CyclicScheduler1():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10 ):\n        super(CyclicScheduler1, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n\n    def __call__(self, time):\n\n        #sawtooth\n        #r = (1-(time%self.period)\/self.period)\n\n        #cosine\n        time= time%self.period\n        r = (np.cos(time\/self.period *np.pi)+1)\/2\n\n        lr = self.min_lr + r*(self.max_lr-self.min_lr)\n        return lr\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.3f, max_lr=%0.3f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\nclass CyclicScheduler2():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10, max_decay=1.0, warm_start=0 ):\n        super(CyclicScheduler2, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n        self.max_decay = max_decay\n        self.warm_start = warm_start\n        self.cycle = -1\n\n    def __call__(self, time):\n        if time<self.warm_start: return self.max_lr\n\n        #cosine\n        self.cycle = (time-self.warm_start)\/\/self.period\n        time = (time-self.warm_start)%self.period\n\n        period = self.period\n        min_lr = self.min_lr\n        max_lr = self.max_lr *(self.max_decay**self.cycle)\n\n\n        r   = (np.cos(time\/period *np.pi)+1)\/2\n        lr = min_lr + r*(max_lr-min_lr)\n\n        return lr\n\n\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.4f, max_lr=%0.4f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\n#tanh curve\nclass CyclicScheduler3():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10, max_decay=1.0, warm_start=0 ):\n        super(CyclicScheduler3, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n        self.max_decay = max_decay\n        self.warm_start = warm_start\n        self.cycle = -1\n\n    def __call__(self, time):\n        if time<self.warm_start: return self.max_lr\n\n        #cosine\n        self.cycle = (time-self.warm_start)\/\/self.period\n        time = (time-self.warm_start)%self.period\n\n        period = self.period\n        min_lr = self.min_lr\n        max_lr = self.max_lr *(self.max_decay**self.cycle)\n\n        r   = (np.tanh(-time\/period *16 +8)+1)*0.5\n        lr = min_lr + r*(max_lr-min_lr)\n\n        return lr\n\n\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.3f, max_lr=%0.3f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\nclass NullScheduler():\n    def __init__(self, lr=0.01 ):\n        super(NullScheduler, self).__init__()\n        self.lr    = lr\n        self.cycle = 0\n\n    def __call__(self, time):\n        return self.lr\n\n    def __str__(self):\n        string = 'NullScheduler\\n' \\\n                + 'lr=%0.5f '%(self.lr)\n        return string\n\n\n# net ------------------------------------\n# https:\/\/github.com\/pytorch\/examples\/blob\/master\/imagenet\/main.py ###############\ndef adjust_learning_rate(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndef get_learning_rate(optimizer):\n    lr=[]\n    for param_group in optimizer.param_groups:\n        lr +=[ param_group['lr'] ]\n\n    assert(len(lr)==1) #we support only one param_group\n    lr = lr[0]\n\n    return lr","2cc29a12":"class SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x\nclass NeuralNet3(nn.Module):\n    def __init__(self, num_features, num_labels, pretrained_bert):\n        super(NeuralNet3, self).__init__()\n        self.config = transformers.GPT2Config.from_pretrained(pretrained_bert, output_hidden_states=False)\n        self.gptmodel = transformers.GPT2Model(self.config)\n        self.gpt = self.gptmodel.from_pretrained( pretrained_bert,config =self.config)\n        \n        self.num_features = num_features\n        self.num_labels = num_labels\n        \n        self.encoded_dropout = SpatialDropout( 0.2 )\n        self.pooled_dropout = nn.Dropout( 0.2 )        \n        \n        self.feature_linear = nn.Sequential(\n            nn.Linear( self.num_features, self.num_features ),\n            nn.ReLU( inplace=True ),\n            nn.Dropout( 0.2 ),            \n        )\n        \n        '''\n        self.feature_linear = nn.Sequential(\n            nn.Linear( self.num_features, self.num_features ),\n            nn.BatchNorm1d( self.num_features ),\n            nn.ReLU( inplace=True ),\n            nn.Linear( self.num_features, self.num_features2 ),\n        )\n        '''\n        \n        dense_hidden_units = self.gpt.config.hidden_size * 3 + self.num_features\n        \n        self.linear1 = nn.Linear( dense_hidden_units, dense_hidden_units )\n        self.linear2 = nn.Linear( dense_hidden_units, dense_hidden_units )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear( dense_hidden_units, num_labels ),\n        )\n        \n    def forward( self, ids, masks, segments, feature ):  \n        \n        feature_output = self.feature_linear( feature )\n        outputs = self.gpt( input_ids=ids, attention_mask=masks, token_type_ids=segments)\n\n        last_hidden_state,present = self.gpt( input_ids=ids, attention_mask=masks, token_type_ids=segments)\n       # sequence_output = self.encoded_dropout(sequence_output)\n       # pooled_output = self.pooled_dropout(pooled_output)     \n\n      #  h12 = hidden_states[-1][:, 0].reshape((-1, 1, 768))\n      #  h11 = hidden_states[-2][:, 0].reshape((-1, 1, 768))\n      #  h10 = hidden_states[-3][:, 0].reshape((-1, 1, 768))\n      #  h9 = hidden_states[-4][:, 0].reshape((-1, 1, 768))\n\n      #  hidden_states = torch.cat([h9, h10, h11, h12], 1)\n        last_hidden_state = self.encoded_dropout(last_hidden_state)\n\n        avg_pool = torch.mean( last_hidden_state, 1 )\n        max_pool, _ = torch.max( last_hidden_state, 1 )\n\n        h_conc = torch.cat( ( avg_pool, max_pool, last_hidden_state[:, -1, :], feature_output ), 1 )\n        h_conc_linear  = F.relu(self.linear1(h_conc))\n        hidden = h_conc + h_conc_linear \n            \n        h_conc_linear  = F.relu(self.linear2(hidden))\n        hidden = hidden + h_conc_linear      \n        \n        return self.classifier( hidden )\n    ","b31aa645":"def compute_input_title_question( df, tokenizer, max_sequence_length=512 ):\n    \n    input_ids, input_masks, input_segments = [], [], []\n    \n    for _, instance in df.iterrows():\n         \n        title    = tokenizer.tokenize(instance.question_title)\n        question = tokenizer.tokenize(instance.question_body)\n\n        if (len(title)+len(question)+3) > max_sequence_length:\n            if len(title) > 30:\n                title = title[:30]\n                \n            question_len = max_sequence_length - len(title) - 3\n            question = question[:question_len]\n        \n        #token = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] \n        #token_ids = tokenizer.convert_tokens_to_ids(token)\n        \n        title_ids    = tokenizer.convert_tokens_to_ids(title)\n        question_ids = tokenizer.convert_tokens_to_ids(question)\n        cls_ids      = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids      = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        token_ids =  title_ids  + question_ids \n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        len_q = len(question_ids)\n        len_qf = int(len(question_ids)\/2)\n        len_ql = len_q-len_qf\n        segments = [0]*(len(title_ids)) + [1]*(len(question_ids)) + padding\n       # segments = [0]*(len(title_ids)+2) + [1]*(len_qf+1)+[2]*(len_ql) + padding\n\n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),   \n    ]","4b8eda53":"def compute_input_title_answer( df, tokenizer, max_sequence_length=512 ):\n    \n    input_ids, input_masks, input_segments = [], [], []\n    \n    for _, instance in df.iterrows():\n         \n        title  = tokenizer.tokenize(instance.question_title)\n        answer = tokenizer.tokenize(instance.answer)\n\n        if (len(title)+len(answer)+3) > max_sequence_length:\n            if len(title) > 30:\n                title = title[:30]\n                \n            answer_len = max_sequence_length - len(title) - 3\n            answer = answer[:answer_len]\n        \n        #token = [\"[CLS]\"] + title + [\"[SEP]\"] + answer + [\"[SEP]\"] \n        #token_ids = tokenizer.convert_tokens_to_ids(token)\n        \n        title_ids  = tokenizer.convert_tokens_to_ids(title)\n        answer_ids = tokenizer.convert_tokens_to_ids(answer)\n        cls_ids    = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids    = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        token_ids =  title_ids  + answer_ids \n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        segments = [0]*(len(title_ids)) + [1]*(len(answer_ids)) + padding\n        \n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),   \n    ]","51f2c6a4":"def compute_input_arrays( df, tokenizer, max_sequence_length=512 ):\n    \n    input_ids, input_masks, input_segments = [], [], []    \n    t_max_len = 35     \n    \n    for _, instance in df.iterrows():\n        \n        title    = tokenizer.tokenize(instance.question_title)\n        question = tokenizer.tokenize(instance.question_body)\n        answer   = tokenizer.tokenize(instance.answer)\n\n        if (len(title)+len(question)+len(answer)+4) > max_sequence_length:\n            if len(title) > t_max_len:\n                title = title[:t_max_len]\n                \n            question_len = ( max_sequence_length - len(title) - 4 ) \/\/ 2\n            question = question[:question_len]\n            \n            answer_len = max_sequence_length - len(title) - len(question) - 4\n            answer = answer[:answer_len]\n        \n        #token = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n        #token_ids = tokenizer.convert_tokens_to_ids(token)\n        \n        title_ids    = tokenizer.convert_tokens_to_ids(title)\n        question_ids = tokenizer.convert_tokens_to_ids(question)\n        answer_ids   = tokenizer.convert_tokens_to_ids(answer) \n        cls_ids      = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids      = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        token_ids = cls_ids + title_ids + sep_ids + question_ids + sep_ids + answer_ids + sep_ids\n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        segments = [0]*(len(title_ids)+len(question_ids)+3) + [1]*(len(answer_ids)+1) + padding\n        \n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),   \n    ]","aea782c2":"from sklearn.model_selection import GroupKFold","efff0ace":"n_splits = 6\n\n'''\nx_train = train_feature.values\ny_train = train_df[target_columns].values\n\ncv = KFold( n_splits=n_splits, random_state=SEED )\nkfold_split = list( cv.split( x_train, y_train ) )'''\n\ncv = GroupKFold( n_splits=n_splits )\nkfold_split = list( cv.split( X=train_df.question_body, groups=train_df.question_body ) )   \n\n'''write_pickle_to_file( 'kfold_split_index.pkl', kfold_split )\n'''\n\n#kfold_split = read_pickle_from_file( model_weight_path1 + 'kfold_split_index.pkl' )\n","6b0aad10":"test_pred_datas = {}\ntest_pred_weights = {}\n\nfor column in target_columns:\n    test_pred_datas[column] = np.zeros( len(test_df) )\n    test_pred_weights[column] = 0.0\n    \ndef add_test_pred_data( prediction, columns, weight ):\n    for column_idx, column in enumerate( columns ):\n        test_pred_datas[column] += weight * prediction[:, column_idx]  \n        test_pred_weights[column] += weight    \n        \nvalidation_datas = {}\nvalidation_counts = {}\n\nfor column in target_columns:\n    validation_datas[column] = np.zeros( len(train_df) )\n    validation_counts[column] = np.zeros( len(train_df) )\n\ndef add_validation_data( prediction, columns, idx ):\n    for column_idx, column in enumerate( columns ):\n        validation_datas[column][idx] += prediction[:, column_idx]  \n        validation_counts[column][idx] += 1.0    \n        \n        \ndef mean_spearmanr_correlation_score( y_true, y_pred ):\n    num_labels = y_pred.shape[1]\n    score = np.nanmean( [ spearmanr( y_pred[:, idx], y_true[:, idx] ).correlation for idx in range(num_labels) ] )\n    return score \n\nclass QuestDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, features, labels = None):\n        \n        self.inputs   = inputs\n        self.features = features\n        \n        if labels is not None:\n            self.labels = labels\n        else:\n            self.labels = None\n\n    def __getitem__(self, idx):\n        \n        input_ids       = self.inputs[0][idx]\n        input_masks     = self.inputs[1][idx]\n        input_segments  = self.inputs[2][idx]\n        input_features  = self.features[idx]\n        \n        if self.labels is not None: # targets\n            input_labels = self.labels[idx]\n            return input_ids, input_masks, input_segments, input_features, input_labels\n        \n        return input_ids, input_masks, input_segments, input_features\n\n    def __len__(self):\n        return len(self.inputs[0])","b6f170a2":"def model_test( test_inputs, x_test, label_columns, weight_files ):\n    \n    batch_size = 6\n\n    test_dataset = QuestDataset( test_inputs, x_test, None )\n    test_loader = torch.utils.data.DataLoader( test_dataset, batch_size=batch_size, shuffle=False )    \n    \n    num_features = x_test.shape[1]\n    num_labels   = len(label_columns)\n\n    for fname in weight_files:\n\n        model = NeuralNet3( num_features, num_labels, pretrained_bert )\n        model.cuda()\n\n        model.load_state_dict( torch.load( fname ) )      \n        model.eval()\n     \n        test_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in test_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                test_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            test_preds_fold = np.array( test_preds_fold )\n            add_test_pred_data( test_preds_fold, label_columns, 1.0 )\n\n        del model\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    del test_dataset, test_loader","c1acdad0":"def model_validation( train_inputs, x_train, label_columns, weight_files ):\n    \n    if len(kfold_split) != len(weight_files):\n        return\n    \n    batch_size   = 6    \n    num_features = x_test.shape[1]\n    num_labels   = len(label_columns)\n\n    for k, (train_idx, valid_idx) in enumerate(kfold_split):\n        \n        x_train_valid = x_train[valid_idx]\n\n        train_inputs_valid = [x[valid_idx] for x in train_inputs]\n\n        valid_dataset = QuestDataset( train_inputs_valid, x_train_valid, None )\n        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False )\n        \n        model = NeuralNet3( num_features, num_labels, pretrained_bert )\n        model.cuda()\n\n        fname = weight_files[k]\n        model.load_state_dict( torch.load( fname ) )      \n        model.eval()\n     \n        valid_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in valid_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                valid_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            valid_preds_fold = np.array( valid_preds_fold )\n            add_validation_data( valid_preds_fold, label_columns, valid_idx )\n\n        del model, valid_dataset, valid_loader\n        torch.cuda.empty_cache()\n        gc.collect()","1e5534a9":"def model_test_validation( label_columns, train_inputs, test_inputs, x_train, x_test, weight_files ):\n    \n    if len(kfold_split) != len(weight_files):\n        return\n    \n    batch_size   = 6    \n    num_features = x_test.shape[1]\n    num_labels   = len(label_columns)\n\n    test_dataset = QuestDataset( test_inputs, x_test, None )\n    test_loader = torch.utils.data.DataLoader( test_dataset, batch_size=batch_size, shuffle=False )   \n    \n    for k, (train_idx, valid_idx) in enumerate(kfold_split):\n        \n        fname = weight_files[k]\n        print( k+1, fname )\n        \n        x_train_valid = x_train[valid_idx]\n        train_inputs_valid = [x[valid_idx] for x in train_inputs]\n\n        valid_dataset = QuestDataset( train_inputs_valid, x_train_valid, None )\n        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False )\n        \n        model = NeuralNet3( num_features, num_labels, pretrained_bert )\n        model.cuda()\n\n        model.load_state_dict( torch.load( fname ) )      \n        model.eval()\n     \n        #====================\n        #validation\n        valid_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in valid_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                valid_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            valid_preds_fold = np.array( valid_preds_fold )\n            add_validation_data( valid_preds_fold, label_columns, valid_idx )\n            \n        #====================\n        #test\n        test_preds_fold  = []\n\n        with torch.no_grad():\n            for ids, masks, segments, features in test_loader:\n                ids      = ids.cuda()\n                masks    = masks.cuda()\n                segments = segments.cuda()\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                y_pred = model( ids, masks, segments, features )\n                test_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n            test_preds_fold = np.array( test_preds_fold )\n            add_test_pred_data( test_preds_fold, label_columns, 1.0 )            \n\n        del model, valid_dataset, valid_loader\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    del test_dataset, test_loader","c2eaac29":"tokenizer = transformers.GPT2Tokenizer.from_pretrained( pretrained_bert )","789fd380":"print( 'time: {}'.format( time_to_str((time.time()-start_time_all), 'min' ) ) )","866723ec":"train_inputs = compute_input_title_question( train_df, tokenizer, max_sequence_length=512 )\ntest_inputs = compute_input_title_question( test_df, tokenizer, max_sequence_length=512 )\n\nx_train = train_feature.values\nx_test  = test_feature.values\n\nprint( x_train.shape )\nprint( x_test.shape )\nprint( len( target_question_columns ) )\n\nweight_files = [\n    model_weight_path1 ,\n    model_weight_path2 ,\n    model_weight_path3 ,\n    model_weight_path4 ,\n    model_weight_path5,\n    model_weight_path6,\n]\n\nmodel_test_validation( target_question_columns, train_inputs, test_inputs, x_train, x_test, weight_files )\n\ndel x_train, x_test\ndel train_inputs, test_inputs\n","5f37d100":"train_inputs = compute_input_arrays( train_df, tokenizer, max_sequence_length=512 )\ntest_inputs = compute_input_arrays( test_df, tokenizer, max_sequence_length=512 )\n\nx_train = train_feature.values\nx_test  = test_feature.values\n\nprint( x_train.shape )\nprint( x_test.shape )\nprint( len( target_answer_columns ) )\n\nweight_files = [\n    model_weight_path7,\n    model_weight_path8,\n    model_weight_path9,\n    model_weight_path10,\n    model_weight_path11,\n    model_weight_path12,\n]\n\nmodel_test_validation( target_answer_columns, train_inputs, test_inputs, x_train, x_test, weight_files )\n\ndel x_train, x_test\ndel train_inputs, test_inputs\n","8021e01f":"del train_feature, test_feature\ndel target_question_columns, target_answer_columns \n","e22f6e66":"for column in target_columns:\n    print( np.sum( validation_counts[column] ), np.min( validation_counts[column] ), np.max( validation_counts[column] ), column )\n    \nvalidationTG  = pd.DataFrame()\n\nfor column in target_columns:\n    preds = validation_datas[column]\n    count = validation_counts[column]\n    count = np.where( count < 0.5, 1.0, count )\n    \n    validationTG[column] = preds \/ count\n    \nmean_spearmanr_correlation_score( validationTG.values, train_df[target_columns].values )   \nvalidationTG.head()","6b2ad87a":"mean_spearmanr_correlation_score( validationTG.values, train_df[target_columns].values )   ","24d7d97d":"test_predsTG = pd.read_csv( f\"{folder}sample_submission.csv\" )\n\nfor column in target_columns:\n    preds = test_pred_datas[column]\n    weight = test_pred_weights[column]\n    test_predsTG[column] = preds \/ weight    \n    #output = rankdata( output )\n    #max_val = np.max(output) + 1\n    #output = output \/ max_val + 1e-12\n        \ntest_predsTG.head()","87fa5330":"del target_columns, input_columns\ndel test_pred_datas, test_pred_weights\ndel validation_datas, validation_counts\n\ntorch.cuda.empty_cache()\ngc.collect()","9ca2d2ce":"folder = '..\/input\/google-quest-challenge\/'\npretrained_distilbert_base_uncased = \"..\/input\/pretrainedbertpytorch\/pretrained-bert-pytorch\/distilbert-base-uncased\/\"\nuniversal_sentence_encoder_path = \"..\/input\/universalsentenceencoderlarge4\/\"","e17d68a3":"import os\nimport re\nimport gc\n\nimport pickle  \nimport numpy as np\nimport pandas as pd\nimport random\nimport copy\nimport string\nimport time\n\nimport nltk\nfrom nltk.tag import pos_tag\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import OneHotEncoder, LabelBinarizer\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nimport math\nfrom tqdm import tqdm\n\nfrom spacy.lang.en import English\nfrom urllib.parse import urlparse\nimport math\n\nimport warnings\nwarnings.simplefilter('ignore')","3b020f96":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\nfrom torch.nn.utils.weight_norm import weight_norm\n\nfrom scipy.stats import spearmanr","01d16b0b":"import tensorflow as tf\nimport tensorflow_hub as hub","069b4ed5":"import transformers\nprint(\"transformers:\", transformers.__version__)","ef3d5930":"from radam import RAdam","ba1bf4ab":"SEED = 12345","25463740":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(SEED)","99795568":"import pickle\n\ndef read_pickle_from_file(pickle_file):\n    with open(pickle_file,'rb') as f:\n        x = pickle.load(f)\n    return x\n\ndef write_pickle_to_file(pickle_file, x):\n    with open(pickle_file, 'wb') as f:\n        pickle.dump(x, f, pickle.HIGHEST_PROTOCOL)","d756beae":"train_df = pd.read_csv( f\"{folder}train.csv\" )\ntrain_df.shape","69bc6ccf":"test_df = pd.read_csv( f\"{folder}test.csv\" )\ntest_df.shape","bb144bc8":"#train_df.head(3).T","27b3c57e":"target_columns = [\n    'question_asker_intent_understanding',\n    'question_body_critical',\n    'question_conversational',\n    'question_expect_short_answer',\n    'question_fact_seeking',\n    'question_has_commonly_accepted_answer',\n    'question_interestingness_others',\n    'question_interestingness_self',\n    'question_multi_intent',\n    'question_not_really_a_question',\n    'question_opinion_seeking',\n    'question_type_choice',\n    'question_type_compare',\n    'question_type_consequence',\n    'question_type_definition',\n    'question_type_entity',\n    'question_type_instructions',\n    'question_type_procedure',\n    'question_type_reason_explanation',\n    'question_type_spelling',\n    'question_well_written',\n    'answer_helpful',\n    'answer_level_of_information',\n    'answer_plausible',\n    'answer_relevance',\n    'answer_satisfaction',\n    'answer_type_instructions',\n    'answer_type_procedure',\n    'answer_type_reason_explanation',\n    'answer_well_written'    \n]\n\ninput_columns = [\n    'question_title', \n    'question_body',    \n    'answer'\n]","9fc15fcd":"print( 'target_columns:', len(target_columns) )\nprint( 'input_columns:', len(input_columns) )","23144e9a":"for df in [train_df, test_df]:\n\n    ## domain components\n    df['domcom'] = df['url'].apply(lambda s: s.split(':\/\/')[1].split('\/')[0].split('.'))\n\n    # count components\n    df['dom_cnt'] = df['domcom'].apply(lambda s: len(s))\n\n    # extend length\n    df['domcom'] = df['domcom'].apply(lambda s: s + ['none', 'none'])\n\n    # components\n    for ii in range(0,4):\n        df['url_'+str(ii)] = df['domcom'].apply(lambda s: s[ii])\n\n    # clean up\n    df.drop('domcom', axis = 1, inplace = True)","5b335fec":"train_feature = pd.DataFrame()\ntest_feature = pd.DataFrame()","69e96cd2":"features = ['url_0', 'category']\nenc = OneHotEncoder( handle_unknown='ignore' )\nenc.fit( train_df[features] )\n\nencode_train = enc.transform(train_df[features]).toarray()\nencode_test = enc.transform(test_df[features]).toarray()\n\ncolumns = ['encode_{}'.format(i) for i in range(encode_train.shape[1])]\n\nencode_train = pd.DataFrame( encode_train, columns=columns )\ntrain_feature = pd.concat((train_feature, encode_train), axis=1)\n\nencode_test = pd.DataFrame( encode_test, columns=columns )\ntest_feature = pd.concat((test_feature, encode_test), axis=1)   \n\ndel encode_train, encode_test, enc","cffc083e":"print( train_feature.shape )\nprint( test_feature.shape )","a0bec774":"class QuestBertDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, labels = None):\n        \n        self.inputs   = inputs\n        \n        if labels is not None:\n            self.labels = labels\n        else:\n            self.labels = None\n\n    def __getitem__(self, idx):\n        \n        input_ids       = self.inputs[0][idx]\n        input_masks     = self.inputs[1][idx]\n        \n        if self.labels is not None: # targets\n            input_labels = self.labels[idx]\n            return input_ids, input_masks, input_labels\n        \n        return input_ids, input_masks\n\n    def __len__(self):\n        return len(self.inputs[0])","b2e55c4e":"def compute_input_text( texts, tokenizer, max_sequence_length=512 ):\n    \n    input_ids   = []\n    input_masks = []\n    \n    for text in texts:\n         \n        text = tokenizer.tokenize(text)\n        \n        text_ids = tokenizer.convert_tokens_to_ids(text)\n        cls_ids  = tokenizer.convert_tokens_to_ids( [\"[CLS]\"] )   \n        sep_ids  = tokenizer.convert_tokens_to_ids( [\"[SEP]\"] ) \n        \n        if (len(text_ids)+2) > max_sequence_length:\n            text_ids = text_ids[:max_sequence_length-2]        \n        \n        token_ids = cls_ids + text_ids + sep_ids\n        padding = [0] * (max_sequence_length - len(token_ids))\n        \n        ids      = token_ids + padding\n        masks    = [1]*len(token_ids) + padding\n        \n        input_ids.append(ids)\n        input_masks.append(masks)\n\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(), \n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long()\n    ]","2bab4fbd":"def get_bert_feature( tokenizer, model, df, column ):\n    \n    print( column )\n    \n    inputs = compute_input_text( df[column].values, tokenizer )\n    dataset = QuestBertDataset( inputs, None )\n    loader = torch.utils.data.DataLoader( dataset, batch_size=6, shuffle=False, drop_last=False )   \n    \n    preds_fold = []\n\n    model.eval() \n\n    with torch.no_grad():\n        for ids, masks in tqdm(loader):\n            ids   = ids.cuda()\n            masks = masks.cuda()\n\n            outputs = model( input_ids=ids, attention_mask=masks )  \n            x = outputs[0][:, 0, :]\n\n            preds_fold.extend( x.cpu().data.numpy().tolist() )    \n            \n    preds_fold = np.array( preds_fold )\n    \n    return preds_fold","f7811e38":"tokenizer = transformers.DistilBertTokenizer.from_pretrained( pretrained_distilbert_base_uncased )\nmodel = transformers.DistilBertModel.from_pretrained( pretrained_distilbert_base_uncased )\nmodel.cuda()\n\nprint( 'train:' )\ntrain_question_title_dense = get_bert_feature( tokenizer, model, train_df, 'question_title' )\ntrain_question_body_dense  = get_bert_feature( tokenizer, model, train_df, 'question_body' )\ntrain_answer_dense         = get_bert_feature( tokenizer, model, train_df, 'answer' )\n\nprint( 'test:' )\ntest_question_title_dense = get_bert_feature( tokenizer, model, test_df, 'question_title' )\ntest_question_body_dense  = get_bert_feature( tokenizer, model, test_df, 'question_body' )\ntest_answer_dense         = get_bert_feature( tokenizer, model, test_df, 'answer' )\n\ndel tokenizer, model","86ffbb1a":"embed = hub.load(universal_sentence_encoder_path)\n\nembeddings_train = {}\nembeddings_test = {}\n\nfor text in input_columns:\n    print(text)\n    train_text = train_df[text].str.replace('?', '.').str.replace('!', '.').tolist()\n    test_text = test_df[text].str.replace('?', '.').str.replace('!', '.').tolist()\n    \n    curr_train_emb = []\n    curr_test_emb = []\n    batch_size = 4\n    ind = 0\n    while ind*batch_size < len(train_text):\n        curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n        ind += 1\n        \n    ind = 0\n    while ind*batch_size < len(test_text):\n        curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n        ind += 1    \n        \n    embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)\n    embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)\n    \ndel embed\ngc.collect()","4f5eb1b7":"embeddings_train_df = pd.DataFrame()\nembeddings_test_df = pd.DataFrame()\n\nl2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)\ncos_dist = lambda x, y: (x*y).sum(axis=1)\nabs_dist = lambda x, y: np.abs(x-y).sum(axis=1)\nsum_dist = lambda x, y: (x+y).sum(axis=1)\n\ndist_columns = [\n    ['question_title_embedding', 'answer_embedding'],\n    ['question_body_embedding', 'answer_embedding'],\n    ['question_body_embedding', 'question_title_embedding'],\n]\n\nfor i, columns in enumerate(dist_columns):\n    embeddings_train_df[f'l2_dist_embedding_{i}']  = l2_dist( embeddings_train[columns[0]], embeddings_train[columns[1]] )\n    embeddings_train_df[f'cos_dist_embedding_{i}'] = cos_dist( embeddings_train[columns[0]], embeddings_train[columns[1]] )\n    embeddings_train_df[f'abs_dist_embedding_{i}'] = abs_dist( embeddings_train[columns[0]], embeddings_train[columns[1]] )\n    embeddings_train_df[f'l2_dist_embedding_{i}']  = sum_dist( embeddings_train[columns[0]], embeddings_train[columns[1]] )\n    \n    embeddings_test_df[f'l2_dist_embedding_{i}']  = l2_dist( embeddings_test[columns[0]], embeddings_test[columns[1]] )\n    embeddings_test_df[f'cos_dist_embedding_{i}'] = cos_dist( embeddings_test[columns[0]], embeddings_test[columns[1]] )\n    embeddings_test_df[f'abs_dist_embedding_{i}'] = abs_dist( embeddings_test[columns[0]], embeddings_test[columns[1]] )\n    embeddings_test_df[f'l2_dist_embedding_{i}']  = sum_dist( embeddings_test[columns[0]], embeddings_test[columns[1]] )    ","e8e6ac65":"x_train = np.hstack( [item for k, item in embeddings_train.items()] + [train_question_title_dense, train_question_body_dense, train_answer_dense, embeddings_train_df.values, train_feature.values]  )\nx_test  = np.hstack( [item for k, item in embeddings_test.items()] + [test_question_title_dense, test_question_body_dense, test_answer_dense, embeddings_test_df.values, test_feature.values]  )\ny_train = train_df[target_columns].values","6f972125":"del train_feature, test_feature\ndel embeddings_train, embeddings_test\ndel embeddings_train_df, embeddings_test_df\ndel train_question_title_dense, train_question_body_dense, train_answer_dense\ndel test_question_title_dense, test_question_body_dense, test_answer_dense","4b7ced28":"print( x_train.shape )\nprint( x_test.shape )\nprint( y_train.shape )","e49a2b8d":"# 'Cyclical Learning Rates for Training Neural Networks'- Leslie N. Smith, arxiv 2017\n#       https:\/\/arxiv.org\/abs\/1506.01186\n#       https:\/\/github.com\/bckenstler\/CLR\n\nclass CyclicScheduler1():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10 ):\n        super(CyclicScheduler1, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n\n    def __call__(self, time):\n\n        #sawtooth\n        #r = (1-(time%self.period)\/self.period)\n\n        #cosine\n        time= time%self.period\n        r = (np.cos(time\/self.period *np.pi)+1)\/2\n\n        lr = self.min_lr + r*(self.max_lr-self.min_lr)\n        return lr\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.3f, max_lr=%0.3f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\nclass CyclicScheduler2():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10, max_decay=1.0, warm_start=0 ):\n        super(CyclicScheduler2, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n        self.max_decay = max_decay\n        self.warm_start = warm_start\n        self.cycle = -1\n\n    def __call__(self, time):\n        if time<self.warm_start: return self.max_lr\n\n        #cosine\n        self.cycle = (time-self.warm_start)\/\/self.period\n        time = (time-self.warm_start)%self.period\n\n        period = self.period\n        min_lr = self.min_lr\n        max_lr = self.max_lr *(self.max_decay**self.cycle)\n\n\n        r   = (np.cos(time\/period *np.pi)+1)\/2\n        lr = min_lr + r*(max_lr-min_lr)\n\n        return lr\n\n\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.4f, max_lr=%0.4f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\n#tanh curve\nclass CyclicScheduler3():\n\n    def __init__(self, min_lr=0.001, max_lr=0.01, period=10, max_decay=1.0, warm_start=0 ):\n        super(CyclicScheduler3, self).__init__()\n\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.period = period\n        self.max_decay = max_decay\n        self.warm_start = warm_start\n        self.cycle = -1\n\n    def __call__(self, time):\n        if time<self.warm_start: return self.max_lr\n\n        #cosine\n        self.cycle = (time-self.warm_start)\/\/self.period\n        time = (time-self.warm_start)%self.period\n\n        period = self.period\n        min_lr = self.min_lr\n        max_lr = self.max_lr *(self.max_decay**self.cycle)\n\n        r   = (np.tanh(-time\/period *16 +8)+1)*0.5\n        lr = min_lr + r*(max_lr-min_lr)\n\n        return lr\n\n\n\n    def __str__(self):\n        string = 'CyclicScheduler\\n' \\\n                + 'min_lr=%0.3f, max_lr=%0.3f, period=%8.1f'%(self.min_lr, self.max_lr, self.period)\n        return string\n\n\nclass NullScheduler():\n    def __init__(self, lr=0.01 ):\n        super(NullScheduler, self).__init__()\n        self.lr    = lr\n        self.cycle = 0\n\n    def __call__(self, time):\n        return self.lr\n\n    def __str__(self):\n        string = 'NullScheduler\\n' \\\n                + 'lr=%0.5f '%(self.lr)\n        return string\n\n\n# net ------------------------------------\n# https:\/\/github.com\/pytorch\/examples\/blob\/master\/imagenet\/main.py ###############\ndef adjust_learning_rate(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndef get_learning_rate(optimizer):\n    lr=[]\n    for param_group in optimizer.param_groups:\n        lr +=[ param_group['lr'] ]\n\n    assert(len(lr)==1) #we support only one param_group\n    lr = lr[0]\n\n    return lr","ccd41f95":"def mean_spearmanr_correlation_score( y_true, y_pred ):\n    num_labels = y_pred.shape[1]\n    return np.nanmean( [ spearmanr( y_pred[:, idx], y_true[:, idx] ).correlation for idx in range(num_labels) ] )","89abc83e":"class QuestDataset( torch.utils.data.Dataset ):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.x[idx], self.y[idx]\n        else:\n            return self.x[idx]","666c2674":"class NeuralNet(nn.Module):\n    def __init__(self, num_features, num_labels):\n        super(NeuralNet, self).__init__()\n        \n        self.num_features = num_features\n        self.num_labels = num_labels\n        \n        self.classifier = nn.Sequential(\n            nn.Linear( self.num_features, self.num_features ),\n            nn.Dropout( 0.2 ),\n            nn.Linear( self.num_features, self.num_features),\n          #  nn.Dropout( 0.1 ),                 \n            nn.Linear( self.num_features, self.num_labels ),\n        )\n        \n    def forward( self, features ):\n        return self.classifier( features )","02439483":"test_pred_datas = {}\ntest_pred_weights = {}\n\ndef init_test_pred_data():\n    for column in target_columns:\n        test_pred_datas[column] = np.zeros( len(test_df) )\n        test_pred_weights[column] = 0.0\n    \ndef add_test_pred_data( prediction, columns, weight ):\n    for column_idx, column in enumerate( columns ):\n        test_pred_datas[column] += weight * prediction[:, column_idx]  \n        test_pred_weights[column] += weight    ","a3ac1d6b":"validation_datas = {}\nvalidation_counts = {}\n\ndef init_validation_data():\n    for column in target_columns:\n        validation_datas[column] = np.zeros( len(train_df) )\n        validation_counts[column] = np.zeros( len(train_df) )\n    \ndef add_validation_data( prediction, columns, idx ):\n    for column_idx, column in enumerate( columns ):\n        validation_datas[column][idx] += prediction[:, column_idx]  \n        validation_counts[column][idx] += 1.0    ","59fe1890":"init_test_pred_data()\ninit_validation_data()","7e9d51f6":"n_splits = 5\n\n#cv = KFold(n_splits=n_splits, random_state=SEED)\n#kfold_split = list( cv.split( x_train, y_train ) )\n\ncv = GroupKFold( n_splits=n_splits )\nkfold_split = list( cv.split( X=train_df.question_body, groups=train_df.question_body ) )   ","ca0ca336":"n_epochs = 50\npatience = 5\nscores   = []\n\nbatch_size = 32\n\nnum_features = x_train.shape[1]\nnum_labels   = y_train.shape[1]\n    \nfor k, (train_idx, valid_idx) in enumerate( kfold_split ):\n    \n    print( \"k:\", k+1 )\n    \n    #train\n    x_train_train = x_train[train_idx]\n    y_train_train = y_train[train_idx]\n    \n    train_dataset = QuestDataset( x_train_train, y_train_train )\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True )\n    \n    #valid\n    x_train_valid = x_train[valid_idx]\n    y_train_valid = y_train[valid_idx]\n    \n    valid_dataset = QuestDataset( x_train_valid, y_train_valid )\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False )\n    \n    model = NeuralNet( num_features, num_labels )\n    model.cuda()\n    \n    best_weights = copy.deepcopy( model.state_dict() ) \n    loss_fn = nn.BCEWithLogitsLoss()\n    \n    #optimizer = optim.Adam( model.parameters(), lr=2e-5 )\n    optimizer = RAdam( model.parameters(), lr=2e-5 )\n    \n    schduler = CyclicScheduler2( min_lr=2e-6, max_lr=2e-5, period=20, warm_start=0, max_decay=0.9 )\n    \n    min_loss = np.inf\n    counter = 0\n    \n    for epoch in range(n_epochs):\n    #for epoch in tqdm( range(n_epochs) ):\n        \n        lr = schduler( epoch )\n        adjust_learning_rate( optimizer, lr )\n        #lr = get_learning_rate( optimizer )        \n        \n        model.train()\n        train_loss = []\n            \n        for features, labels in train_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            labels   = torch.tensor(labels,dtype=torch.float32).cuda()   \n            \n            y_pred = model( features )\n            loss = loss_fn( y_pred, labels )        \n                           \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss.append( loss.item() )\n        \n        avg_train_loss = np.mean( train_loss )\n            \n        model.eval()\n        val_loss = []\n        \n        with torch.no_grad():\n            for features, labels in valid_loader:\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                labels   = torch.tensor(labels,dtype=torch.float32).cuda()   \n                \n                y_pred = model( features )\n                loss = loss_fn( y_pred, labels )\n                val_loss.append( loss.item() )\n\n        avg_val_loss = np.mean( val_loss )       \n        \n        if avg_val_loss < min_loss:\n            min_loss = avg_val_loss\n            counter = 0\n            best_weights = copy.deepcopy( model.state_dict() ) \n                \n        else:\n            counter += 1\n            # print('Early stopping: %i \/ %i' % (counter, self.patience))\n            if counter >= patience and epoch > 12:\n                # print('Early stopping at epoch', epoch + 1)\n                break        \n        \n    model.load_state_dict( best_weights )    \n    model.eval()\n    valid_preds_fold = []\n    valid_true_fold = []\n    \n    with torch.no_grad():\n        for features, labels in valid_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            labels   = torch.tensor(labels,dtype=torch.float32).cuda()  \n            y_pred = model( features )\n            \n            valid_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n            valid_true_fold.extend( labels.cpu().data.numpy().tolist() )\n       \n    valid_preds_fold = np.array( valid_preds_fold )\n    valid_true_fold = np.array( valid_true_fold )\n    \n    add_validation_data( valid_preds_fold, target_columns, valid_idx )\n    score = mean_spearmanr_correlation_score( valid_preds_fold, valid_true_fold )\n    print('Score:', score)\n    \n    scores.append(score)\n    test_preds_fold  = []\n    \n    test_dataset = QuestDataset( x_test, None )\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False )\n\n    with torch.no_grad():\n        for features in test_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            y_pred = model( features )\n            \n            test_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n        test_preds_fold = np.array( test_preds_fold )\n        add_test_pred_data( test_preds_fold, target_columns, 1.0 )\n        \n    del model, optimizer, loss_fn, best_weights\n    del train_dataset, train_loader\n    del valid_dataset, valid_loader  \n    del test_dataset, test_loader\n    torch.cuda.empty_cache()\n    gc.collect() \n\nprint( '================' )\nprint( 'Mean score:', np.mean(scores)) ","7a04a060":"validation0 = pd.DataFrame()\n\nfor column in target_columns:\n    preds = validation_datas[column]\n    count = validation_counts[column]\n    count = np.where( count < 0.5, 1.0, count )\n    \n    validation0[column] = preds \/ count","a309af2a":"validation0.head()","267a5806":"mean_spearmanr_correlation_score( train_df[target_columns].values, validation0.values )","a7439cd0":"test_preds0 = pd.read_csv( f\"{folder}sample_submission.csv\" )\n\nfor column in target_columns:\n    output = test_pred_datas[column] \/ test_pred_weights[column]\n    test_preds0[column] = output","ccef6ede":"test_preds0.head()","05ea70f3":"LSTM_UNITS = 512\n#LSTM_UNITS = 1024\nDENSE_HIDDEN_UNITS = 6 * LSTM_UNITS\n\nclass MODEL_v001(nn.Module):\n    def __init__(self, num_features, num_labels ):\n        super().__init__()\n        self.lstm1 = nn.LSTM( num_features , LSTM_UNITS, bidirectional=True, batch_first=True )\n        self.lstm2 = nn.LSTM( LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.2 )\n        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.linearnorm = nn.LayerNorm(DENSE_HIDDEN_UNITS)\n        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.linearnorm2 = nn.LayerNorm(DENSE_HIDDEN_UNITS)\n        self.linear_sub_out = nn.Linear(DENSE_HIDDEN_UNITS, num_labels)\n\n    def forward(self, x, lengths=None):\n        h_lstm1, _ = self.lstm1(x)\n        h_lstm2, _ = self.lstm2(h_lstm1)\n\n        avg_pool1 = torch.mean(h_lstm1, 1)\n        avg_pool2 = torch.mean(h_lstm2, 1)\n        max_pool2, _ = torch.max(h_lstm2, 1)\n\n        h_conc = torch.cat((avg_pool1, max_pool2, avg_pool2), 1)\n        h_conc_linear1 = self.linearnorm(F.relu(self.linear1(h_conc)))\n        h_conc_linear2 = self.linearnorm2(F.relu(self.linear2(h_conc)))\n\n        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n        out = self.linear_sub_out(hidden)\n        \n        return out","48779e45":"x_train = np.expand_dims( x_train, 1 )\nx_test = np.expand_dims( x_test, 1 )","ae2a9599":"init_test_pred_data()\ninit_validation_data()","0bba6fd7":"n_splits = 5\n\n#cv = KFold(n_splits=n_splits, random_state=SEED)\n#kfold_split = list( cv.split( x_train, y_train ) )\n\ncv = GroupKFold( n_splits=n_splits )\nkfold_split = list( cv.split( X=train_df.question_body, groups=train_df.question_body ) )   ","2eea95e9":"n_epochs = 8\npatience = 4\nscores   = []\n\nbatch_size = 8\n\nnum_features = x_train.shape[2]\nnum_labels   = y_train.shape[1]\n    \nfor k, (train_idx, valid_idx) in enumerate( kfold_split ):\n    \n    print( \"k:\", k+1 )\n    \n    #train\n    x_train_train = x_train[train_idx]\n    y_train_train = y_train[train_idx]\n    \n    train_dataset = torch.utils.data.TensorDataset(\n        torch.from_numpy(x_train[train_idx]), \n        torch.from_numpy(y_train[train_idx])\n    )\n    \n    train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=batch_size, shuffle=True, drop_last=True )\n    \n    #valid\n    valid_dataset = torch.utils.data.TensorDataset(\n        torch.from_numpy(x_train[valid_idx]), \n        torch.from_numpy(y_train[valid_idx])\n    )\n    \n    valid_loader = torch.utils.data.DataLoader( valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False )\n    \n    model = MODEL_v001( num_features, num_labels )\n    model.cuda()\n    \n    best_weights = copy.deepcopy( model.state_dict() ) \n    loss_fn = nn.BCEWithLogitsLoss()\n    \n    optimizer = torch.optim.Adam( model.parameters() )\n    #optimizer = optim.Adam( model.parameters(), lr=2e-5 )\n    #optimizer = RAdam( model.parameters(), lr=2e-5 )\n    \n    min_loss = np.inf\n    counter = 0\n    \n    for epoch in range(n_epochs):\n    #for epoch in tqdm( range(n_epochs) ):   \n        \n        model.train()\n        train_loss = []\n            \n        for features, labels in train_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            labels   = torch.tensor(labels,dtype=torch.float32).cuda()   \n            \n            y_pred = model( features )\n            loss = loss_fn( y_pred, labels )        \n                           \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss.append( loss.item() )\n        \n        avg_train_loss = np.mean( train_loss )\n            \n        model.eval()\n        val_loss = []\n        \n        with torch.no_grad():\n            for features, labels in valid_loader:\n                features = torch.tensor(features,dtype=torch.float32).cuda()\n                labels   = torch.tensor(labels,dtype=torch.float32).cuda()   \n                \n                y_pred = model( features )\n                loss = loss_fn( y_pred, labels )\n                val_loss.append( loss.item() )\n\n        avg_val_loss = np.mean( val_loss )       \n        \n        if avg_val_loss < min_loss:\n            min_loss = avg_val_loss\n            counter = 0\n            best_weights = copy.deepcopy( model.state_dict() ) \n                \n        else:\n            counter += 1\n            # print('Early stopping: %i \/ %i' % (counter, self.patience))\n            if counter >= patience:\n                # print('Early stopping at epoch', epoch + 1)\n                break        \n        \n    model.load_state_dict( best_weights )    \n    model.eval()\n    valid_preds_fold = []\n    valid_true_fold = []\n    \n    with torch.no_grad():\n        for features, labels in valid_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            labels   = torch.tensor(labels,dtype=torch.float32).cuda()  \n            y_pred = model( features )\n            \n            valid_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n            valid_true_fold.extend( labels.cpu().data.numpy().tolist() )\n       \n    valid_preds_fold = np.array( valid_preds_fold )\n    valid_true_fold = np.array( valid_true_fold )\n    \n    add_validation_data( valid_preds_fold, target_columns, valid_idx )\n    score = mean_spearmanr_correlation_score( valid_preds_fold, valid_true_fold )\n    print('Score:', score)\n    \n    scores.append(score)\n    test_preds_fold  = []\n    \n    test_dataset = QuestDataset( x_test, None )\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False )\n\n    with torch.no_grad():\n        for features in test_loader:\n            features = torch.tensor(features,dtype=torch.float32).cuda()\n            y_pred = model( features )\n            \n            test_preds_fold.extend( torch.sigmoid( y_pred ).cpu().data.numpy().tolist() )\n\n        test_preds_fold = np.array( test_preds_fold )\n        add_test_pred_data( test_preds_fold, target_columns, 1.0 )\n        \n    del model, optimizer, loss_fn, best_weights\n    del train_dataset, train_loader\n    del valid_dataset, valid_loader  \n    del test_dataset, test_loader\n    torch.cuda.empty_cache()\n    gc.collect() \n\nprint( '================' )\nprint( 'Mean score:', np.mean(scores)) ","f4d0832e":"validationLSTM = pd.DataFrame()\n\nfor column in target_columns:\n    preds = validation_datas[column]\n    count = validation_counts[column]\n    count = np.where( count < 0.5, 1.0, count )\n    \n    validationLSTM[column] = preds \/ count","fcf40afd":"validationLSTM.head()","99d5af6f":"mean_spearmanr_correlation_score( validationLSTM.values, train_df[target_columns].values )","a19d597e":"test_predsLSTM = pd.read_csv( f\"{folder}sample_submission.csv\" )\n\nfor column in target_columns:\n    output = test_pred_datas[column] \/ test_pred_weights[column]\n    test_predsLSTM[column] = output","af3ab79e":"test_predsLSTM.head()","d817ad4f":"del train_df, test_df\ndel x_train, x_test, y_train\ndel validation_datas, validation_counts\ndel test_pred_datas, test_pred_weights","31274e4a":"blabla","b78fded4":"data_dir = '..\/input\/google-quest-challenge\/'\ntrain = pd.read_csv(path_join(data_dir, 'train.csv'))\ntest = pd.read_csv(path_join(data_dir, 'test.csv'))\nsample = pd.read_csv(path_join(data_dir, 'sample_submission.csv'))\n\nprint(train.shape, test.shape)\ntrain.head()","6fadb644":"targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]","988f8d84":"def compute_spearmanr_ignore_nan(trues, preds):\n    rhos = []\n    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n        rhos.append(spearmanr(tcol, pcol).correlation)\n    return np.nanmean(rhos)","ff0a27cc":"from functools import partial\nimport scipy as sp\n\nclass OptimizedRounder(object):\n    def __init__(self,correlation):\n        self.correlation = correlation\n        self.coef_ = 0\n        self.score = 0\n\n    def _kappa_loss(self, coef, X, y):\n        a= X.copy()\n        b=y.copy()\n        X_p = pd.cut(a, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0,1,2])\n        \n        a[X_p == 0] = 0\n        a[X_p == 2] = 1 \n\n        #print(\"validation score = {}\".format(spearmanr(a, b).correlation))\n        if spearmanr(a, b).correlation < self.correlation:\n            self.score = spearmanr(a, b).correlation\n            return - spearmanr(a, b).correlation + (self.correlation - spearmanr(a, b).correlation + 1)**10\n        else:\n            self.score = spearmanr(a, b).correlation\n            return - spearmanr(a, b).correlation\n\n    def fit(self, X, y,coef_ini):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = coef_ini\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def coefficients(self):\n        return self.coef_['x']\n    def score_fc(self):\n        return self.score","fd9eeddf":"from collections import Counter\n\ndef optimize_preds( y_df, x_df, preds_df ):\n    \n    for title in targets:\n        \n        y1 = np.asarray(y_df[title].copy())\n        X1 = np.asarray(x_df[title].copy())\n        \n        x_original     = np.asarray(x_df[title].copy())\n        preds_original = np.asarray(preds_df[title].copy())     \n\n        correlation = spearmanr(y1, X1).correlation\n        print(title)\n        print(correlation)\n\n        coefficients_target = [0,0]\n        correlation = spearmanr(y1, X1).correlation\n        okcor = spearmanr(y1, X1).correlation\n        maxi = correlation\n        liste = [[0.1,0.9],[0.2,0.9],[0.3,0.9],[0.3,0.8],[0.2,0.7],[0.3,0.7],[0.2,0.6],[0.5,0.9],[0.3,0.6],[0.4,0.8],[0.7,0.9],[0.8,0.9]]\n\n        for L in liste:\n            optR = OptimizedRounder(correlation)\n            optR.fit(X1,y1,L)\n            coefficients = optR.coefficients()\n            if optR.score_fc() > maxi:\n                maxi = optR.score_fc()\n                coefficients_target = coefficients\n\n        if maxi != spearmanr(y1, X1).correlation:\n            oof = X1.copy()\n            oof[oof > coefficients_target[1]] = 1\n            oof[oof <= coefficients_target[0]] = 0\n\n            X1 = np.asarray(preds_df[title].copy())\n            oof_test = X1.copy()\n            oof_test[oof_test > coefficients_target[1]] = 1\n            oof_test[oof_test <= coefficients_target[0]] = 0\n\n            score = spearmanr(y1, oof).correlation\n            if score - okcor > 0.001:\n                print(\"difference validation score = {}\".format(score - okcor))\n                x_df[title] = oof\n\n                dist = Counter(x_df[title])\n\n                if 0 in list(dist.keys()):\n                    dist[0] \/= len(x_df)\n                if 1 in list(dist.keys()):\n                    dist[1] \/= len(x_df)\n\n                acum = 0\n                bound = {}\n\n                if 0 in list(dist.keys()):\n                    acum = dist[0]\n                    bound[0] = np.percentile(preds_df[title], acum * 100)\n\n                if 1 in list(dist.keys()):\n                    acum = 1 - dist[1]\n                    bound[1] = np.percentile(preds_df[title], acum * 100)\n\n                def classify(x):\n                    if 0 in list(dist.keys()):\n                        if 1 in list(dist.keys()):\n                            if x <= bound[0]:\n                                return 0\n                            elif x <= bound[1]:\n                                return x\n                            else:\n                                return 1\n                        else:\n                            if x <= bound[0]:\n                                return 0\n                            else:\n                                return x\n                    else:\n                        if 1 in list(dist.keys()):\n                            if x <= bound[1]:\n                                return x\n                            else:\n                                return 1\n                        else:\n                            return x\n\n                final_pred = np.array(list(map(classify, preds_df[title])))\n                if len(np.unique(oof_test)) != 1:\n                    print(coefficients_target)\n                    preds_df[title] = final_pred","548a45c1":"\nvalidationN=pd.read_csv('..\/input\/nirjharbert003\/validation_preds_df_003.csv') \ntest_predsN=pd.read_csv('..\/input\/nirjharbert003\/submission_003.csv')\n\nprint(\"Nirjhar model : \")\ncompute_spearmanr_ignore_nan(np.asarray(train[targets].copy()), np.asarray(validationN[targets].copy()))\n","a68cf513":"\nvalidationN1=pd.read_csv('..\/input\/dataset-nirjhar\/validation_preds_df_002.csv') \ntest_predsN1=pd.read_csv('..\/input\/dataset-nirjhar\/submission_002.csv')\n\nprint(\"Nirjhar model : \")\ncompute_spearmanr_ignore_nan(np.asarray(train[targets].copy()), np.asarray(validationN1[targets].copy()))\n","4c7cfdbb":"data_table = []\ndata_table.append( {'Name': 'QUEST-003-55',            'valid': copy.deepcopy( validationT ),    'test_preds': copy.deepcopy( test_predsT ) } )\n#data_table.append( {'Name': 'QUEST-005-04-1',          'valid': copy.deepcopy( validationT2 ),   'test_preds': copy.deepcopy( test_predsT2 ) } )\ndata_table.append( {'Name': 'QUEST-006-03-GPT2',        'valid': copy.deepcopy( validationTG ),   'test_preds': copy.deepcopy( test_predsTG ) } )\ndata_table.append( {'Name': 'QUEST-005-07-distilbert', 'valid': copy.deepcopy( validation0 ),    'test_preds': copy.deepcopy( test_preds0 ) } )\ndata_table.append( {'Name': 'QUEST-005-07-lstm',       'valid': copy.deepcopy( validationLSTM ), 'test_preds': copy.deepcopy( test_predsLSTM ) } )\ndata_table.append( {'Name': 'QUEST-Bert-Nirjhar',       'valid': copy.deepcopy( validationN ), 'test_preds': copy.deepcopy( test_predsN ) } )\ndata_table.append( {'Name': 'QUEST-Bert-Nirjhar1',       'valid': copy.deepcopy( validationN1 ), 'test_preds': copy.deepcopy( test_predsN1 ) } )","ffaa642a":"n_original = len(data_table)\nscore_list = []\n\nfor i in range( n_original ):\n    print( '=========================' )\n    print( data_table[i]['Name'] )\n    print( '=========================' )\n    \n    data_table[i]['valid'] = pd.DataFrame(data_table[i]['valid']).rank() \/ len(data_table[i]['valid'])\n    data_table[i]['test_preds'] = pd.DataFrame(data_table[i]['test_preds']).rank() \/ len(data_table[i]['test_preds'])   \n    \n    data_table.append( copy.deepcopy( data_table[i] ) )\n        \n    score1 = compute_spearmanr_ignore_nan( np.asarray( train[targets].copy() ), np.asarray( data_table[i]['valid'].copy() ) )\n    \n    optimize_preds( train, data_table[i]['valid'], data_table[i]['test_preds'] )\n    \n    score2 = compute_spearmanr_ignore_nan( np.asarray( train[targets].copy() ), np.asarray( data_table[i]['valid'].copy() ) )\n    score_list.append( [score1, score2] )","b79eabce":"for i in range( len(score_list) ):    \n    score1, score2 = score_list[i][0], score_list[i][1]\n    print( '{:.6f} -> {:.6f} ({:.6f}) : {}'.format( score1, score2, score2 - score1, data_table[i]['Name'] ) )","cb473216":"validation_totale = train[targets].copy()\ntest_preds_totale = sample.copy()","2c925e24":"for title in targets:\n\n    y1 = np.asarray(train[title].copy())\n\n    X_list = [ np.asarray( x['valid'][title].copy() ) for x in data_table ]\n    test_list = [ np.asarray( x['test_preds'][title].copy() ) for x in data_table ]     \n    corr_list = [ spearmanr(y1, x).correlation for x in X_list ]\n\n    i = np.argmax(corr_list)\n\n    corr_best  = copy.deepcopy( corr_list[i] )\n    x_best     = copy.deepcopy( X_list[i] )\n    test_best  = copy.deepcopy( test_list[i] )\n    \n    for weight_range in np.arange( 0.45, 0.95, 0.005 ):\n        \n        corr_list2 = [c*c for c in corr_list]\n        cmin = np.min( corr_list2 )\n        cmax = np.max( corr_list2 )\n\n        weights = ( corr_list2 - cmin ) \/ ( cmax - cmin ) \n        weights *= weight_range\n        weights += ( 1.0 - weight_range )\n\n        #print( weight_range, weights, title )\n\n        x = np.average( X_list, axis=0, weights=weights )   \n        x = rankdata( x ) \/ len( x )\n        corr = spearmanr( y1, x ).correlation\n\n        if corr > corr_best:\n            corr_best  = copy.deepcopy( corr )\n            x_best     = copy.deepcopy( x )\n\n            t = np.average( test_list, axis=0, weights=weights )   \n            t = rankdata( t ) \/ len( t )       \n            test_best  = copy.deepcopy( t )  \n            \n\n    validation_totale[title] = copy.deepcopy( x_best )\n    test_preds_totale[title] = copy.deepcopy( test_best )","a49a3000":"compute_spearmanr_ignore_nan(np.asarray(train[targets].copy()), np.asarray(validation_totale[targets].copy()))","8fb88e57":"def function_spelling(row):\n    if row in 'CULTURE':\n        return 1\n    else:\n        return 0\n\nvalidation_totale['question_type_spelling'] = train['category'].apply(function_spelling)*validation_totale['question_type_spelling']","ac6a38b9":"compute_spearmanr_ignore_nan(np.asarray(train[targets].copy()), np.asarray(validation_totale[targets].copy()))","273212e5":"submission = pd.read_csv(path_join(data_dir, 'sample_submission.csv'))\n\nfor title in targets:\n    for i, row in test_preds_totale.iterrows():\n        submission.loc[submission['qa_id'] == row['qa_id'], title] = row[title]\n    ","a7af5024":"submission['question_type_spelling'] = test['category'].apply(function_spelling)*submission['question_type_spelling']\n#submission['question_type_spelling'] = test['question_user_page'].apply(function_spelling2)*validation['question_type_spelling']","d516d57f":"compute_spearmanr_ignore_nan(np.asarray(train[targets].copy()), np.asarray(validation_totale[targets].copy()))","03609df5":"for title in targets:\n    submission[title] = submission[title].apply(lambda x: 1 if x>1 else x)","5b6d9dfc":"submission.to_csv(\"submission.csv\", index = False)\nsubmission.head()","5b729437":"submission.describe()","7812ed09":"### DISTILBERT","cc0423da":"## Load data","54839ee6":"# 006-55-gpt2-01-1","9a1d1e3d":"### Features","e68a073e":"#### Bert","7ce02ebe":"### test","22849528":"#### count","22dd3e5b":"### Model","6ed6e1a6":"### remove nan","90dc6cb0":"## Extract target variables","f94b060f":"#### Text cleaning","b0a14eab":"# post processing","fbe6dd70":"#### Text based features","79c9c6db":"# QUEST_005_07_DISTILBERT+LSTM (DISTILBERT)","1e32339f":"### submission","57de29df":"## Load data","89202f52":"#### Label Preprocessing\n- https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/discussion\/100961","ccc78736":"# QUEST_005_04_1","89032021":"def function_spelling2(row):\n    if 'english.stackexchange' in str(row):\n        return 1\n    if 'ell.stackexchange' in str(row):\n        return 1\n    else:\n        return 0\n#validation_totale['question_type_spelling'] = train['question_user_page'].apply(function_spelling2)*validation_totale['question_type_spelling']","bf9ea233":"### validation","348c1f88":"### Universal Sentence Encoder","0cd9e449":"#### Encode","f611bf90":"### question","5e00afef":"## Features","fbb7b0f2":"### Model","3ae457e3":"### validation","dfaa9a81":"# quest-003-55-bert-07-3-valid","b93f1816":"### test","2b96726f":"### validation","4379ba88":"| Name                    | valid          | test_preds     |\n|-------------------------|----------------|----------------|\n| QUEST_005_07-distilbert | validation0    | test_preds0    |\n| QUEST-003-55            | validationT    | test_predsT    |\n| QUEST-006-55 -GPT2      | validationTG    | test_predsTG  |\n| QUEST-005-04-1          | validationT2   | test_predsT2   |\n| QUEST-005_07-lstm       | validationLSTM | test_predsLSTM |","12c491ab":"### answer","e0c03e4d":"# QUEST_005_07_DISTILBERT+LSTM (LSTM)","8282e2f1":"## Extract target variables"}}