{"cell_type":{"57ec49b3":"code","54800999":"code","7b1292bb":"code","2a1789fd":"code","5386762c":"code","cf228323":"code","896ebe28":"code","2fc5b386":"code","7d31aa0e":"code","3f78feb4":"code","2b5556bc":"code","ae752e9a":"code","078601ed":"code","49dc3676":"code","c2fa7fd2":"code","f138121c":"code","8c64deca":"code","3d014af4":"code","8ee757a3":"code","1d123612":"code","25bcdde4":"code","34213cdb":"code","670f07b7":"code","b3187762":"code","dfaf65b2":"code","e4014ce1":"code","a6be19c0":"markdown","91650262":"markdown","afc44db9":"markdown","16f26546":"markdown"},"source":{"57ec49b3":"## import library\n!pip install quandl\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport pandas as pd   \nimport quandl\nimport numpy as np\nimport matplotlib.pyplot as plt  #for plotting\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\n#from model_selection import cross_validation\nfrom sklearn.svm import SVR\n#from mlxtend.regressor import StackingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n","54800999":"## data source \n\ndf=quandl.get('WIKI\/GOOGL')","7b1292bb":"##data summary\ndf.head()","2a1789fd":"## redefining data adding removin feture\n### create the specfic ammount of label and feture \ndf1=df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]\n\n###redefining the data\n### adding some feture to the datasets\ndf1['volatility']=(df1['Adj. High']-df1['Adj. Close'])\/df1['Adj. Close']\ndf1['PCT_Change']=(df1['Adj. Close']-df1['Adj. Open'])\/df1['Adj. Open'] ","5386762c":"## making final dataframe\ndf1=df1[['Adj. Close','volatility','PCT_Change','Adj. Open','Adj. Volume']]","cf228323":"## setting the target column\nforcast_col='Adj. Close'","896ebe28":"## deal with the null data\ndf1.fillna(-999999,inplace=True)","2fc5b386":"## for predicting one percent of the data\nimport math\nforcast_out = int(math.ceil(.1*(len(df1))))\nprint (forcast_out)","7d31aa0e":"## displaying the previous output\nY=df1[forcast_col]\nX=range(len(df1[forcast_col]))\nfig_size=[30,5]\nplt.rcParams[\"figure.figsize\"] = fig_size\nplt.plot(X,Y)","3f78feb4":"##storing the previous data in  a dataframe\ndf1['label'] = df[forcast_col].shift(-forcast_out)\ny1 = df1['label']\nx1=range(len(df1['label']))\nfig_size=[30,5]\nplt.rcParams[\"figure.figsize\"] = fig_size\nplt.plot(x1,y1)","2b5556bc":"## dropping the first column which is the output\nX=np.array(df1.drop(['label'],1))","ae752e9a":"##scale the data\nX=preprocessing.scale(X)\nX=X[:-forcast_out]  ##data what is known\nX_lately=X[-forcast_out:] ##data we predict\ndf1.dropna(inplace=True)","078601ed":"Y=np.array(df1['label'])","49dc3676":"##split the training and testing data\nxtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=0.2)","c2fa7fd2":"## training separtely the classifier\n##first knn\nn_neighbors=1\nclf1 = KNeighborsRegressor(n_neighbors)  # create a classifire object\nclf1.fit(xtrain,ytrain) # train data related with fir() method\naccuracy1=clf1.score(xtest,ytest) # test data related with score() method\nprint (\"the accuracy is \"+str(accuracy1))","f138121c":"## second linear regression\nfrom sklearn.linear_model import LinearRegression\nclf2 = LinearRegression()  # create a classifire object\nclf2.fit(xtrain,ytrain) # train data related with fir() method\naccuracy2=clf2.score(xtest,ytest) # test data related with score() method\nprint (\"the accuracy is \"+str(accuracy2))\n","8c64deca":"## third support vector machine\nfrom sklearn import svm\nclf3 = svm.SVR()  # create a classifire object\nclf3.fit(xtrain,ytrain) # train data related with fir() method\naccuracy3=clf3.score(xtest,ytest) # test data related with score() method\nprint (\"the accuracy is \"+str(accuracy3))","3d014af4":"clf4 = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\nclf4.fit(xtrain,ytrain) # train data related with fir() method\naccuracy4=clf4.score(xtest,ytest) # test data related with score() method\nprint (\"the accuracy is \"+str(accuracy4))","8ee757a3":"class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)   \n","1d123612":"averaged_models = AveragingModels(models = (clf1, clf2, clf3, clf4))","25bcdde4":"averaged_models.fit(xtrain,ytrain)","34213cdb":"accuracy=averaged_models.score(xtest,ytest)","670f07b7":"accuracy","b3187762":"df2=pd.DataFrame()\ndf3=pd.DataFrame()\ndf4=pd.DataFrame()\ndf5=pd.DataFrame()\ndf6=pd.DataFrame()","dfaf65b2":"forcast_set1=clf1.predict(X_lately)\nforcast_set2=clf2.predict(X_lately)\nforcast_set3=clf3.predict(X_lately)\nforcast_set4=clf4.predict(X_lately)\nfinal_forcast_set=averaged_models.predict(X_lately)\ndf2['forcast']=np.array(forcast_set1)\ndf3['forcast']=np.array(forcast_set2)\ndf4['forcast']=np.array(forcast_set3)\ndf5['forcast']=np.array(forcast_set4)\ndf6['forcast']=np.array(final_forcast_set)\n","e4014ce1":"fig_size=[30,30]\nplt.rcParams[\"figure.figsize\"] = fig_size\ndf2['forcast'].plot()\ndf3['forcast'].plot()\ndf4['forcast'].plot()\ndf5['forcast'].plot()\ndf6['forcast'].plot()\nplt.legend(loc=4)\n\nplt.ylabel('Price')","a6be19c0":"## The Orange one is our improved stacked model output, less noise more accuracy","91650262":"## This is better than the individual one","afc44db9":"# applying the stacking method we developed","16f26546":"# Apple Corporation Stock Prices, Dividends and Splits"}}