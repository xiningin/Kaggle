{"cell_type":{"0171cdce":"code","bbd8d054":"code","9e947bb0":"code","3cb7aef2":"code","354ff499":"code","24c58aa7":"code","74401190":"code","d371108c":"code","08b22c41":"code","80506d25":"markdown","9531ff9d":"markdown","a6e6bf7a":"markdown","f2b7db6c":"markdown","8cc74289":"markdown","bdc016c8":"markdown","5755ef20":"markdown"},"source":{"0171cdce":"import torch \nimport torch.nn.functional as F\n\nfrom torch import nn, optim \nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T, datasets\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport plotly.express as px\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","bbd8d054":"transform = T.Compose([\n    T.ToTensor(),\n    T.Normalize((0.5,), (0.5,))\n])","9e947bb0":"trainset = datasets.MNIST('..\/input\/mnist-dataset-pytorch', train = True, transform = transform)\ntestset = datasets.MNIST('..\/input\/mnist-dataset-pytorch', train = False, transform = transform)","3cb7aef2":"class ArcFace(nn.Module):\n    \n    def __init__(self,in_features,out_features,margin = 0.7 ,scale = 64):\n        super().__init__()\n        \n        self.in_features = in_features\n        self.out_features = out_features\n        self.scale = scale\n        self.margin = margin \n        \n        self.weights = nn.Parameter(torch.FloatTensor(out_features,in_features))\n        nn.init.xavier_normal_(self.weights)\n        \n    def forward(self,features,targets):\n        cos_theta = F.linear(features,F.normalize(self.weights),bias=None)\n        cos_theta = cos_theta.clip(-1+1e-7, 1-1e-7)\n        \n        arc_cos = torch.acos(cos_theta)\n        M = F.one_hot(targets, num_classes = self.out_features) * self.margin\n        arc_cos = arc_cos + M\n        \n        cos_theta_2 = torch.cos(arc_cos)\n        logits = cos_theta_2 * self.scale\n        return logits\n    \n    \nclass MNIST_Model(nn.Module):\n    \n    def __init__(self):\n        super(MNIST_Model, self).__init__()\n\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50,3)\n        self.arc_face = ArcFace(in_features = 3, out_features = 10)\n        \n    def forward(self,features,targets = None):\n        \n        x = F.relu(F.max_pool2d(self.conv1(features), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        _,c,h,w = x.shape\n        x = x.view(-1, c*h*w)\n        x = F.relu(self.fc1(x))\n        x = F.normalize(self.fc2(x))\n        \n        if targets is not None:\n            logits = self.arc_face(x,targets)\n            return logits\n        return x","354ff499":"model = MNIST_Model()\nmodel.to(device)","24c58aa7":"class TrainModel():\n    \n    def __init__(self,criterion = None,optimizer = None,schedular = None,device = None):\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.schedular = schedular\n        self.device = device\n        \n    def accuracy(self,logits,labels):\n        ps = torch.argmax(logits,dim = 1).detach().cpu().numpy()\n        acc = accuracy_score(ps,labels.detach().cpu().numpy())\n        return acc\n\n    def get_dataloader(self,trainset,validset):\n        trainloader = DataLoader(trainset,batch_size = 64, num_workers = 4, pin_memory = True)\n        validloader = DataLoader(validset,batch_size = 64, num_workers = 4, pin_memory = True)\n        return trainloader, validloader\n        \n    def train_batch_loop(self,model,trainloader,i):\n        \n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        pbar_train = tqdm(trainloader, desc = \"Epoch\" + \" [TRAIN] \" + str(i+1))\n        \n        for t,data in enumerate(pbar_train):\n            \n            images,labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            logits = model(images,labels)\n            loss = self.criterion(logits,labels)\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            epoch_loss += loss.item()\n            epoch_acc += self.accuracy(logits,labels)\n            \n            pbar_train.set_postfix({'loss' : '%.6f' %float(epoch_loss\/(t+1)), 'acc' : '%.6f' %float(epoch_acc\/(t+1))})\n            \n        return epoch_loss \/ len(trainloader), epoch_acc \/ len(trainloader)\n            \n    \n    def valid_batch_loop(self,model,validloader,i):\n        \n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        pbar_valid = tqdm(validloader, desc = \"Epoch\" + \" [VALID] \" + str(i+1))\n        \n        for v,data in enumerate(pbar_valid):\n            \n            images,labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            logits = model(images,labels)\n            loss = self.criterion(logits,labels)\n            \n            epoch_loss += loss.item()\n            epoch_acc += self.accuracy(logits,labels)\n            \n            pbar_valid.set_postfix({'loss' : '%.6f' %float(epoch_loss\/(v+1)), 'acc' : '%.6f' %float(epoch_acc\/(v+1))})\n            \n        return epoch_loss \/ len(validloader), epoch_acc \/ len(validloader)\n            \n    \n    def run(self,model,trainset,validset,epochs):\n    \n        trainloader,validloader = self.get_dataloader(trainset,validset)\n        \n        for i in range(epochs):\n            \n            model.train()\n            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader,i)\n            \n            model.eval()\n            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader,i)\n            \n        return model ","74401190":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.0001)\n\n\nmodel = TrainModel(criterion, optimizer, device).run(model, trainset, testset, 20)","d371108c":"emb = []\ny = []\n\ntestloader = DataLoader(testset,batch_size = 64)\nwith torch.no_grad():\n    for images,labels in tqdm(testloader):\n        \n        images = images.to(device)\n        embeddings = model(images)\n        \n        emb += [embeddings.detach().cpu()]\n        y += [labels]\n        \n    embs = torch.cat(emb).cpu().numpy()\n    y = torch.cat(y).cpu().numpy()","08b22c41":"tsne_df = pd.DataFrame(\n    np.column_stack((embs, y)),\n    columns = [\"x\",\"y\",\"z\",\"targets\"]\n)\n\nfig = px.scatter_3d(tsne_df, x='x', y='y', z='z',\n              color='targets')\nfig.show()","80506d25":"## Image Embeddings","9531ff9d":"## ArcFace CNN Model ","a6e6bf7a":"## Transforms and dataset","f2b7db6c":"# ArcFace Implementation on MNIST Dataset \n\nPaper : [https:\/\/arxiv.org\/abs\/1801.07698](https:\/\/arxiv.org\/abs\/1801.07698)\n\nTraining pipeline for a simple arcface cnn model on mnist dataset. As I was implementing first time I wanted to try first on mnist dataset just for practice. You can use the same for shopee competition. PyTorch framework is used for training. At last I had also plotted the image embeddings. \n\nkernel which helped me to implement arcface :\n[https:\/\/www.kaggle.com\/slawekbiel\/arcface-explained](https:\/\/www.kaggle.com\/slawekbiel\/arcface-explained)","8cc74289":"![](https:\/\/www.weak-learner.com\/assets\/img\/blog\/personal\/arcface_archi.png)","bdc016c8":"## Imports","5755ef20":"## Training"}}