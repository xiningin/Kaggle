{"cell_type":{"05124b72":"code","a9374e68":"code","3ecdd1ef":"code","bbe3ef85":"code","e0eadd9f":"code","15201475":"code","de154a0c":"code","aef6912c":"code","e1a53e41":"code","b0ee50fb":"code","f2cb9fe3":"code","90049ee7":"markdown","a8d0634f":"markdown","83e2f872":"markdown","5e75f944":"markdown","a70092ad":"markdown","185fa27f":"markdown","ef6760ae":"markdown","746ee6ab":"markdown","f10da517":"markdown","7744ac65":"markdown","a45ff6df":"markdown","ff57d53c":"markdown"},"source":{"05124b72":"from keras.datasets import imdb\ntop_words = 10000\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)","a9374e68":"x_train[0]","3ecdd1ef":"imdb.get_word_index()","bbe3ef85":"word_dict = imdb.get_word_index()\nword_dict = { key:(value + 3) for key, value in word_dict.items() }\nword_dict[''] = 0  # Padding\nword_dict['>'] = 1 # Start\nword_dict['?'] = 2 # Unknown word\nreverse_word_dict = { value:key for key, value in word_dict.items() }\nprint(' '.join(reverse_word_dict[id] for id in x_train[0]))","e0eadd9f":"from keras.preprocessing import sequence\nmax_review_length = 500\nx_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\nx_test = sequence.pad_sequences(x_test, maxlen=max_review_length)","15201475":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Flatten\n\nembedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\nmodel.add(Flatten())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","de154a0c":"hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=128)","aef6912c":"scores = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1] * 100))","e1a53e41":"import string\nimport numpy as np\n\ndef analyze(text):\n    # Prepare the input by removing punctuation characters, converting\n    # characters to lower case, and removing words containing numbers\n    translator = str.maketrans('', '', string.punctuation)\n    text = text.translate(translator)\n    text = text.lower().split(' ')\n    text = [word for word in text if word.isalpha()]\n\n    # Generate an input tensor\n    input = [1]\n    for word in text:\n        if word in word_dict and word_dict[word] < top_words:\n            input.append(word_dict[word])\n        else:\n            input.append(2)\n    padded_input = sequence.pad_sequences([input], maxlen=max_review_length)\n\n    # Invoke the model and return the result\n    result = model.predict(np.array([padded_input][0]))[0][0]\n    return result","b0ee50fb":"analyze('Easily the most stellar experience I have ever had.')","f2cb9fe3":"analyze('The long lines and poor customer service really turned me off.')","90049ee7":"# Show the first review in x_train in textual format","a8d0634f":"# Examples","83e2f872":"# Function to analyze for other sentences","5e75f944":"# Creating a neural network that performs sentiment analysis","a70092ad":"**The first number in the list \u2014 1 \u2014 doesn't represent a word at all. It marks the start of the review and is the same for every review in the dataset. The numbers 0 and 2 are reserved as well, and you subtract 3 from the other numbers to map an integer in a review to the corresponding integer in the dictionary. The second number \u2014 14 \u2014 references the word that corresponds to the number 11 in the dictionary, the third number represents the word assigned the number 19 in the dictionary, and so on.**","185fa27f":"# Model Validation","ef6760ae":"Fortunately, Keras includes a function that takes a list of lists as input and converts the inner lists to a specified length by truncating them if necessary or padding them with 0s. Enter the following code into the notebook and run it to force all the lists representing movie reviews in x_train and x_test to a length of 500 integers.","746ee6ab":"# Keras is to build a neural network that scores text for sentiment","f10da517":"When you train a neural network with collection of tensors, each tensor needs to be the same length. At present, the lists representing reviews in x_train and x_test have varying lengths.","7744ac65":"**Keras is an open-source Python library that dramatically simplifies the building of neural networks.With Keras, you can build sophisticated neural networks with just a few dozen lines of code and train them to classify images, analyze text for sentiment, do natural-language processing, and perform other tasks at which deep learning excels.**","a45ff6df":"The variable named x_train is a list of 25,000 lists, each of which represents one movie review. (x_test is also a list of 25,000 lists representing 25,000 reviews. x_train will be used for training, while x_test will be used for testing.) But the inner lists \u2014 the ones representing movie reviews \u2014 don't contain words; they contain integers.","ff57d53c":"The reason the inner lists contain numbers rather than text is that you don't train a neural network with text; you train it with numbers. Specifically, you train it with tensors. In this case, each review is a 1-dimensional tensor (think of a 1-dimensional array) containing integers identifying the words contained in the review."}}