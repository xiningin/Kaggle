{"cell_type":{"76e5afab":"code","eaf978ea":"code","9fcfeefb":"code","57f94808":"code","3f473484":"code","8603c4c7":"code","ff540bb7":"code","ac67618e":"code","dcc0649f":"code","df649a3b":"code","6da46e5d":"code","d7d3efcd":"code","a51ada22":"code","a04b2a62":"code","33589791":"code","c6a8675e":"code","fc5657bb":"code","0736ae32":"code","1f2aadbf":"code","264ffa26":"code","83e16c46":"code","507ac7d2":"code","1e005361":"code","3c36efbb":"code","96c32cbb":"code","0509203b":"code","fff00e5f":"code","7c50238d":"code","82484a1c":"code","6783c1ec":"code","66f0109a":"code","05e6c234":"code","f3ffeaa6":"code","7ac3b550":"code","446625e8":"code","545ebfa1":"code","fd7eb794":"markdown","0121a152":"markdown","196b1035":"markdown","5d15421d":"markdown"},"source":{"76e5afab":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","eaf978ea":"cc_info = pd.read_csv(\"..\/input\/superaicreditcardpref\/cc_info.csv\")\ncc_txn = pd.read_csv(\"..\/input\/superaicreditcardpref\/cc_txn.csv\")\ndemo = pd.read_csv(\"..\/input\/superaicreditcardpref\/demo.csv\")\ntrain = pd.read_csv(\"..\/input\/superaicreditcardpref\/train.csv\")\ntest = pd.read_csv(\"..\/input\/superaicreditcardpref\/test.csv\")","9fcfeefb":"cc_info['one'] = 1\nnumber_of_cc = pd.pivot_table(cc_info, values='one', index=['id'], columns=['old_cc_label'], aggfunc=np.sum).fillna(0)\nnumber_of_cc.rename_axis(None, axis=1,inplace=True)\nnumber_of_cc.rename(columns={\n    0:'old_cc_0',\n    1:'old_cc_1',\n    2:'old_cc_2',\n    3:'old_cc_3',\n    4:'old_cc_4',\n    5:'old_cc_5',\n    6:'old_cc_6',\n    7:'old_cc_7',\n    8:'old_cc_8',\n    9:'old_cc_9',\n    10:'old_cc_10',\n    11:'old_cc_11',\n    12:'old_cc_12'\n}, inplace=True)\nnumber_of_cc","57f94808":"cc_info.drop(columns=['one'], inplace=True)\ninfo = cc_info.groupby('id').mean().drop(columns=['old_cc_no', 'old_cc_label']).join(cc_info.id.value_counts())\ninfo = info.rename(columns={'id':'cc_info_count', 'n1':'info_n1'})\n\ninfo = cc_info.groupby('id').median().drop(columns=['old_cc_no', 'old_cc_label']).join(info)\ninfo = info.rename(columns={'n1':'info_n1_m'})\n\ninfo","3f473484":"txn = cc_txn.groupby('id').mean().drop(columns=['old_cc_no', 'c1', 'c2', 'c3', 'c4', 'c5']).join(cc_txn.id.value_counts())\ntxn = txn.rename(columns={'id':'cc_txn_count', 'n1':'txn_n1', 'n2':'txn_n2', 'n3':'txn_n3'})\n\ntxn = cc_txn.groupby('id').median().drop(columns=['old_cc_no']).join(txn)\ntxn = txn.rename(columns={'n1':'txn_n1_m', 'n2':'txn_n2_m', 'n3':'txn_n3_m'})\ntxn = txn.rename(columns={'c1':'txn_c1', 'c2':'txn_c2', 'c3':'txn_c3', 'c4':'txn_c4', 'c5':'txn_c5'})\n\ntxn","8603c4c7":"train","ff540bb7":"df_train = train.set_index('id').join([demo.set_index('id'), txn, info, number_of_cc])\ndf_train.c3.replace([0,1],[1,0], inplace=True)\ndf_train.n1.fillna(0, inplace=True)\ndf_train.n4.fillna(0, inplace=True)\n\ndf_test = test.set_index('id').join([demo.set_index('id'), txn, info, number_of_cc])\ndf_test.c3.replace([0,1],[1,0], inplace=True)\ndf_test.n1.fillna(0, inplace=True)\ndf_test.n4.fillna(0, inplace=True)\n\ndf_train.info(), df_test.info()","ac67618e":"df_train.c2.replace('n', 0, inplace=True)\ndf_test.c2.replace('n',0, inplace=True)","dcc0649f":"df_test.info()","df649a3b":"df_train = df_train.astype({'c1':'category',\n                            'c2':'category',\n                            'c3':'category', \n                            'c4':'category',\n                            'label':'category',\n                            'txn_c1':'category',\n                            'txn_c2':'category',\n                            'txn_c3':'category', \n                            'txn_c4':'category', \n                            'txn_c5':'category' })\n\ndf_test = df_test.astype({'c1':'category',\n                            'c2':'category',\n                            'c3':'category', \n                            'c4':'category',\n                            'txn_c1':'category',\n                            'txn_c2':'category',\n                            'txn_c3':'category', \n                            'txn_c4':'category', \n                            'txn_c5':'category' })","6da46e5d":"df_train","d7d3efcd":"df_train.info()","a51ada22":"from sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","a04b2a62":"from sklearn.metrics import log_loss\ndef Score(TrueY, PredY):\n    SampleWeight = TrueY.value_counts()\/len(TrueY)\n    SampleWeightLabel = TrueY.replace(dict(SampleWeight))\n    return log_loss(y_true=TrueY, y_pred=PredY, sample_weight = SampleWeightLabel)","33589791":"from sklearn import preprocessing","c6a8675e":"df_train","fc5657bb":"Unable_Preprocessing = ['c1', 'c2', 'c3', 'c4', 'label', 'txn_c1', 'txn_c2', 'txn_c3', 'txn_c4', 'txn_c5']","0736ae32":"# scaler = preprocessing.StandardScaler().fit(df_train[df_train.columns.difference(Unable_Preprocessing)])","1f2aadbf":"df_train","264ffa26":"# df_train[df_train.columns.difference(Unable_Preprocessing)] = scaler.transform(df_train[df_train.columns.difference(Unable_Preprocessing)])","83e16c46":"def OneHot(Data,Columns):\n    Tmp = Data;\n    for column in Columns:\n        try:\n            ToOneHot = Tmp[column];\n            Tmp = Tmp.drop(columns=[column]);\n            for key in tqdm(set(ToOneHot), desc=f\"{column}\"):\n                Tmp[f\"{column} - {key}\"] = (ToOneHot == key).astype(int)\n        except: pass;\n    return Tmp;","507ac7d2":"# df_train = OneHot(df_train, ['c1', 'c2', 'c3', 'c4'])","1e005361":"x_train, x_test, y_train, y_test = train_test_split(df_train[df_train.columns.difference(['label'])], \n                                                    df_train.label, test_size=0.1, stratify=df_train.label, random_state=69)\n\n# get the number of samples of each class divided the total number of samples\nsample_weight_train = y_train.value_counts()\/len(y_train)\n\n# apply the sample weight dict on the labels to obtain a list of weights\nsample_weight_train_label = y_train.replace(dict(sample_weight_train))","3c36efbb":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB, CategoricalNB, BernoulliNB, ComplementNB \nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost import XGBClassifier","96c32cbb":"classifiers = [\n#     LGBMClassifier(),\n    CatBoostClassifier(task_type=\"GPU\", early_stopping_rounds=10)#,\n#     DecisionTreeClassifier(max_depth=5),\n#     RandomForestClassifier(max_depth=5, n_estimators=20, max_features=1),\n#     BernoulliNB()\n    ]","0509203b":"from tqdm import tqdm","fff00e5f":"list_loss = []\nlist_train_loss = []\ntrained_models = []\n\nfor i, modely in enumerate(tqdm(classifiers)):\n    model = modely\n    \n#     if i == 0: ## LGB\n#         model.fit(x_train, y_train, eval_metric=Score, sample_weight = sample_weight_train_label)\n#     elif i == 1: ## cat boost\n    x_train_meow = x_train.astype({'c1':'int64',\n                                    'c2':'int64',\n                                    'c3':'int64', \n                                    'c4':'int64',\n                                    'txn_c1':'int64',\n                                    'txn_c2':'int64',\n                                    'txn_c3':'int64', \n                                    'txn_c4':'int64', \n                                    'txn_c5':'int64' })\n    x_test_meow = x_test.astype({'c1':'int64',\n                                'c2':'int64',\n                                'c3':'int64', \n                                'c4':'int64',\n                                'txn_c1':'int64',\n                                'txn_c2':'int64',\n                                'txn_c3':'int64', \n                                'txn_c4':'int64', \n                                'txn_c5':'int64' })\n    model.fit(x_train_meow, y_train, ['c1','c2','c3','c4','txn_c1','txn_c2','txn_c3','txn_c4','txn_c5'],\n              sample_weight = sample_weight_train_label)\n#     else:\n#         model.fit(x_train, y_train, sample_weight = sample_weight_train_label)\n        \n#     if i == 1: ## cat\n    \n    y_pred = model.predict_proba(x_test_meow)\n    y_train_pred = model.predict_proba(x_train_meow)\n#     else:\n#         y_pred = model.predict_proba(x_test)\n#         y_train_pred = model.predict_proba(x_train)\n    \n    list_loss.append(Score(y_test, y_pred))\n    list_train_loss.append(Score(y_train, y_train_pred))\n    trained_models.append(model)","7c50238d":"for train_loss, test_loss, model in zip(list_train_loss, list_loss, classifiers):\n    print(str(model))\n    print('Train loss :', train_loss)\n    print('Test loss :', test_loss)\n    print('')","82484a1c":"df_test","6783c1ec":"df_test = df_test.astype({'c1':'int64',\n                        'c2':'int64',\n                        'c3':'int64', \n                        'c4':'int64',\n                        'txn_c1':'int64',\n                        'txn_c2':'int64',\n                        'txn_c3':'int64', \n                        'txn_c4':'int64', \n                        'txn_c5':'int64' })","66f0109a":"df_test = df_test.reindex(sorted(df_test.columns), axis=1)\ndf_test","05e6c234":"model = trained_models[0]\ny_pred_s = model.predict_proba(df_test)","f3ffeaa6":"y_pred_s","7ac3b550":"test = pd.DataFrame()\ntest['Id'] = df_test.index","446625e8":"test[['class0', 'class1', 'class2', 'class3', 'class4', 'class5', 'class6', \n      'class7', 'class8', 'class9', 'class10', 'class11', 'class12']] = y_pred_s\ntest.to_csv(\"submission.csv\", index = False)","545ebfa1":"for i,j in zip(trained_models, classifiers):\n    feature_imp = pd.DataFrame(sorted(zip(i.feature_importances_,df_train[df_train.columns.difference(['label'])].columns)), columns=['Value','Feature'])\n\n    plt.figure(figsize=(10, 5))\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n    plt.title(str(j))\n    plt.tight_layout()\n    plt.show()","fd7eb794":"# Preprocessing","0121a152":"## Modeling \n\nThe metric is \n$$ -\\frac{1}{N} \\sum_{o=1}^N \\sum_{c=1}^{M} w_c y_{o,c} \\ln(p_{o,c})$$\n- Where $m$ is the number of classes (13)\n- $n$ is the number of observations\n- $y$ is an indicator for a correctly predicted class $c$ for observation $o$\n- $w$ is the weight of class $c$, where the weight is (# samples of each class in train.csv)\/(# samples in train.csv)","196b1035":"### Explanation of Dataset Layout\n\n- **Train** contains the ids of customers, with their corresponding class labels\n- **Test** contains the ids of customers without their class labels\n- **Demo** contains the demographic information for all 100000 customers in train and the 153450 in test\n    - id of the customer\n    - c1: 2 categories, probably \n    - c2: 10 categories\n    - n1: (credit limit)\n    - c3: 2 categories (heavily imbalanced)\n    - n2 \n    - n3: probably age (norammly distributed around 40)\n    - n4: probably monthly salary (exponential)\n    - c4: 2 categories\n- **ccinfo** contains information about credit cards for customers in train and in test\n    - n1: unknown # \u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e23\u0e31\u0e49\u0e07\u0e17\u0e35\u0e48\u0e23\u0e39\u0e14\n    - old_cc_label: CardType\n- **cctxn** contains information about credit card transactions for customers in their set\n    - n1: RegisterDate, # \u0e27\u0e31\u0e19\u0e17\u0e35\u0e48\u0e2a\u0e21\u0e31\u0e04\u0e23 1 - 365 (Number)\n    - t1: Product, # \u0e0a\u0e37\u0e48\u0e2d\u0e2a\u0e34\u0e19\u0e04\u0e49\u0e32 (Text)\n    - old_cc_no: CardNo\n","5d15421d":"# Loss"}}