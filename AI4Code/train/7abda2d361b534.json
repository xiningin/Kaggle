{"cell_type":{"0bf4feec":"code","c25e08e6":"code","ffda76ab":"code","c5b8238f":"code","67eab3d3":"code","82f69a07":"code","aa641c46":"code","6cfa6490":"code","8ac9228f":"code","92837538":"code","3095b698":"code","3de81f28":"code","7d3ef850":"code","3a22b59d":"code","6f5c38d4":"code","c0bcf808":"code","be74099c":"code","a5d005e1":"code","160223b3":"code","f8ebd72e":"code","9e5eab9f":"code","2894bd9a":"markdown","7b024784":"markdown","9dbf7b5c":"markdown","11499e3c":"markdown"},"source":{"0bf4feec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c25e08e6":"df = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf.head()","ffda76ab":"df.shape","c5b8238f":"df['RainTomorrow'].value_counts()","67eab3d3":"df.isnull().sum()","82f69a07":"df = df.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)\ndf.columns","aa641c46":"# drop date column\ndf = df.drop('Date', axis=1)","6cfa6490":"# drop rows if RainTomorrow is null\ndf = df[df['RainTomorrow'].notna()]\ndf.isnull().sum()","8ac9228f":"categorical_features = []\nnumeric_features = []\nfeatures = df.columns.values.tolist()\nfor col in features:\n    if df[col].dtype != 'object': \n        numeric_features.append(col)\n    else:\n        categorical_features.append(col)\n\nprint(f'categorical_features: {categorical_features}')\nprint(f'numeric_features: {numeric_features}')","92837538":"for col in numeric_features:\n    mean = df[col].mean()\n    df[col] = df[col].fillna(mean)\n    \nfor col in categorical_features:\n    mode = df[col].mode()[0]\n    df[col] = df[col].fillna(mode)\n\ndf.isnull().sum()","3095b698":"from sklearn.preprocessing import LabelEncoder\n# Encoding categorical features\nfor col in categorical_features:\n    le = LabelEncoder()\n    le.fit(list(df[col].astype(str).values))\n    df[col] = le.transform(list(df[col].astype(str).values))","3de81f28":"y = df['RainTomorrow']\nX = df.drop('RainTomorrow', axis=1)","7d3ef850":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","3a22b59d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nC = [0.001, 0.01, 0.1, 1, 10, 100]\npenalty = ['l2']\ntol = [0.5]\n\nlogreg_gscv = GridSearchCV(estimator=LogisticRegression(), \n                                param_grid={'C': C,\n                                            'penalty': penalty,\n                                            'tol':tol},   \n                                scoring='neg_log_loss',\n                                cv=5)","6f5c38d4":"logreg_gscv.fit(X_scaled, y)\nlogreg_gscv.best_params_","c0bcf808":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)","be74099c":"logreg = LogisticRegression(C = logreg_gscv.best_params_['C'],\n                           penalty = logreg_gscv.best_params_['penalty'],\n                           tol = logreg_gscv.best_params_['tol'])\nlogreg.fit(X_train, y_train)\ny_pred=logreg.predict(X_test)","a5d005e1":"from sklearn import metrics\nmetrics.accuracy_score(y_test,y_pred)","160223b3":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm=confusion_matrix(y_test,y_pred)\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nplt.figure(figsize = (8,5))\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")","f8ebd72e":"print(metrics.classification_report(y_test, y_pred))","9e5eab9f":"metrics.log_loss(y_test, y_pred)","2894bd9a":"## Build Model ","7b024784":"## Model Evaluation","9dbf7b5c":"## Drop columns with most missing values","11499e3c":"## Fill missing values"}}