{"cell_type":{"a6559a95":"code","73387115":"code","4fa50698":"code","f8460d91":"code","5b70df7d":"code","3a8daf3d":"code","d2f38570":"code","1e2c867a":"code","35cb5ac8":"code","e9f1db47":"code","2eb1c238":"code","5fa01cf7":"code","d1e8d268":"code","e7d63e7d":"code","78d21cb4":"code","73a941f4":"code","1a428c01":"code","4a47fa25":"code","3fd50d4c":"code","86b92c6e":"code","aad532ee":"code","76b6d871":"code","3ee0e94f":"code","dd708a1b":"code","7c00ff60":"code","24010588":"code","e0698f9e":"code","bf668221":"code","31a8db4b":"code","93b9f940":"code","6e9952d0":"code","15935d8b":"code","0c137f5d":"code","c4823b07":"code","d7940edc":"code","1b205e5c":"code","01d71836":"code","b3312d4a":"code","bfdb2ff0":"code","e897fa37":"code","458d9674":"code","d42d2753":"code","7bc5116a":"code","c4350ddb":"code","cf89adb9":"markdown","fad006ab":"markdown","b6385268":"markdown","e6ff8f85":"markdown","9b04871f":"markdown","fe441c46":"markdown","9f3cebff":"markdown","5b15ce6f":"markdown","d6583cd8":"markdown","85adc165":"markdown","463bd2ff":"markdown","83e054b0":"markdown","ee6e6d66":"markdown","b87b4415":"markdown","38fd926d":"markdown","fda2f620":"markdown","b6deb11b":"markdown","72e864c9":"markdown","d459ea60":"markdown","e0855846":"markdown","6bc85a6d":"markdown","594f12c2":"markdown","c12756dc":"markdown","930b3976":"markdown","787869d8":"markdown","18003691":"markdown"},"source":{"a6559a95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73387115":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nsns.set()","4fa50698":"data=pd.read_csv(\"\/kaggle\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv\")\ndata.head(10)","f8460d91":"data.describe(include=\"all\")","5b70df7d":"data.isna().sum()","3a8daf3d":"from statistics import mode ","d2f38570":"data[\"education\"].unique()","1e2c867a":"data[\"education\"]=data[\"education\"].fillna(mode(data[\"education\"]))","35cb5ac8":"data[\"education\"].isna().sum()","e9f1db47":"data[\"cigsPerDay\"].unique()","2eb1c238":"data[\"cigsPerDay\"]=data[\"cigsPerDay\"].fillna(data[\"cigsPerDay\"].mean())","5fa01cf7":"data[\"cigsPerDay\"].isna().sum()","d1e8d268":"data[\"BPMeds\"].unique()","e7d63e7d":"data[\"BPMeds\"]=data[\"BPMeds\"].fillna(mode(data[\"BPMeds\"]))","78d21cb4":"data[\"BPMeds\"].isna().sum()","73a941f4":"data[\"totChol\"].unique()","1a428c01":"data[\"totChol\"]=data[\"totChol\"].fillna(data[\"totChol\"].mean())","4a47fa25":"data[\"totChol\"].isna().sum()","3fd50d4c":"data[\"glucose\"].unique()","86b92c6e":"data[\"glucose\"]=data[\"glucose\"].fillna(data[\"glucose\"].mean())","aad532ee":"data=data.dropna()","76b6d871":"data.isna().sum()","3ee0e94f":"data.head(5)","dd708a1b":"data.describe(include=\"all\")","7c00ff60":"X_r=data.drop([\"TenYearCHD\"],axis=1)\ny_r=data[\"TenYearCHD\"]","24010588":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","e0698f9e":"bf=SelectKBest(score_func=chi2,k=10)\nfit=bf.fit(X_r,y_r)","bf668221":"dfscores=pd.DataFrame(fit.scores_)\ndfcolumns=pd.DataFrame(X_r.columns)","31a8db4b":"featurescores=pd.concat([dfcolumns,dfscores],axis=1)\nfeaturescores.columns=[\"spec\",\"score\"]\nfeaturescores","93b9f940":"print(featurescores.nlargest(10,'score'))","6e9952d0":"X=data[[\"sysBP\",\"glucose\",\"age\",\"totChol\",\"cigsPerDay\",\"diaBP\",\"prevalentHyp\",\"diabetes\",\"BPMeds\",\"male\"]]\ny=data[\"TenYearCHD\"]","15935d8b":"data[\"TenYearCHD\"].value_counts()","0c137f5d":"from imblearn.under_sampling import NearMiss","c4823b07":"nm= NearMiss()\nX_res,y_res=nm.fit_sample(X,y)","d7940edc":"X_res.shape,y_res.shape","1b205e5c":"data.dtypes","01d71836":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","b3312d4a":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)","bfdb2ff0":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","e897fa37":"logisticRegr = LogisticRegression()","458d9674":"logisticRegr.fit(X_train, y_train)","d42d2753":"predictions = logisticRegr.predict(X_test)","7bc5116a":"score = logisticRegr.score(X_test, y_test)\nprint(score)","c4350ddb":"confusion_matrix = metrics.confusion_matrix(y_test,predictions)\nprint(confusion_matrix)","cf89adb9":"# Data Splitting and Logistic Regression","fad006ab":"# under sampling","b6385268":"# Data Exploration","e6ff8f85":"First we will check whether the information is categorical or continuous.\n\nIf they are continuous null values can be replaced by mean(The Arithmetic Mean is the average of the numbers).\n\nIf they are categorical null values can be replaced by mode(The number which appears most often in a set of numbers).","9b04871f":"totChol seems to be continuous.\nso we replace by mean.","fe441c46":"# reading data file","9f3cebff":"Feature Selection","5b15ce6f":"We are getting accuracy of 72%.\nIt can be improved by cross validaation.","d6583cd8":"education has 105 missing values.\n\ncigsPerDay has 29 missing values.\n\nBPMeds has 53 missing values.\n\ntotChol has 50 missing values.\n\nBMI has 19 missing values.\n\nheartRate has 1 missing values\n\nglucose has 388 missing values.","85adc165":"when we see the dependent feature the mean is quite low around 0.15 ie the dataset is imbalanced.","463bd2ff":"we see datatypes of allcolumns using \".dtypes\" command","83e054b0":"World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant\/risk factors of heart disease as well as predict the overall risk using logistic regression.\n","ee6e6d66":"we try to see them separately","b87b4415":"# Introduction","38fd926d":"feature scaling ","fda2f620":"now they seems to be balanced","b6deb11b":"# Handling Missing Values","72e864c9":"BPMeds is categorical.\nso we replace by mode.","d459ea60":"education is categorical.\nso we replace by mode.","e0855846":"# LOGISTIC REGRESSION TO PREDICT HEART DISEASE.\n![](http:\/\/)","6bc85a6d":"cigsPerDay seems to be continuous.\nso we replace by mean.","594f12c2":"using both to understand and see difference","c12756dc":"to make it balance we have two option under sampling and over sampling ","930b3976":"glucose seems to be continuous.\nso we replace by mean.","787869d8":"BMI & heartRate still have null values but the number is too less .\n\nso we simply drop the rows.","18003691":"we checks if further null values are there."}}