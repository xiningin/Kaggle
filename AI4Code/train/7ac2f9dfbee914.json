{"cell_type":{"2a68b10c":"code","953ba42e":"code","244133ef":"code","a0942a7c":"code","63de5b82":"code","79d51770":"code","a47b2c0f":"code","0d0e08f2":"code","57904144":"code","3864db30":"code","f3115bd2":"code","5be08439":"code","a92e415c":"code","df5b1289":"code","4e745dde":"code","dfc328ba":"code","7ac8dba2":"code","a2385674":"code","cac3239f":"code","f6617c7f":"code","73018fa8":"code","b2bdfb9d":"code","f73e1b70":"code","f3c3476d":"code","2c82f58b":"code","44485b08":"code","31a63e71":"code","478e1b0b":"code","60dd8ddf":"code","899f63ee":"markdown","ca62ff7e":"markdown","0437cc37":"markdown","03d4258d":"markdown","cdf078ae":"markdown","6234d3c7":"markdown","c8a84d3b":"markdown","4ff6a831":"markdown","dd592091":"markdown","dfcdd4a4":"markdown","b62133ff":"markdown","6fdd172f":"markdown","3dee4a23":"markdown","d1f48a92":"markdown","b3a7d89b":"markdown","d546c74d":"markdown","12a89028":"markdown"},"source":{"2a68b10c":"#Import packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom  sklearn import svm\n\n#Read CSV data\ndata = pd.read_csv(\"..\/input\/train_u6lujuX_CVtuZ9i (1).csv\")","953ba42e":"#preview data\ndata.head()","244133ef":"#Preview data information\ndata.info()","a0942a7c":"#Check missing values\ndata.isnull().sum()","63de5b82":"# percent of missing \"Gender\" \nprint('Percent of missing \"Gender\" records is %.2f%%' %((data['Gender'].isnull().sum()\/data.shape[0])*100))","79d51770":"print(\"Number of people who take a loan group by gender :\")\nprint(data['Gender'].value_counts())\nsns.countplot(x='Gender', data=data, palette = 'Set2')","a47b2c0f":"# percent of missing \"Married\" \nprint('Percent of missing \"Married\" records is %.2f%%' %((data['Married'].isnull().sum()\/data.shape[0])*100))","0d0e08f2":"print(\"Number of people who take a loan group by marital status :\")\nprint(data['Married'].value_counts())\nsns.countplot(x='Married', data=data, palette = 'Set2')","57904144":"# percent of missing \"Dependents\" \nprint('Percent of missing \"Dependents\" records is %.2f%%' %((data['Dependents'].isnull().sum()\/data.shape[0])*100))","3864db30":"print(\"Number of people who take a loan group by dependents :\")\nprint(data['Dependents'].value_counts())\nsns.countplot(x='Dependents', data=data, palette = 'Set2')","f3115bd2":"# percent of missing \"Self_Employed\" \nprint('Percent of missing \"Self_Employed\" records is %.2f%%' %((data['Self_Employed'].isnull().sum()\/data.shape[0])*100))","5be08439":"print(\"Number of people who take a loan group by self employed :\")\nprint(data['Self_Employed'].value_counts())\nsns.countplot(x='Self_Employed', data=data, palette = 'Set2')","a92e415c":"# percent of missing \"LoanAmount\" \nprint('Percent of missing \"LoanAmount\" records is %.2f%%' %((data['LoanAmount'].isnull().sum()\/data.shape[0])*100))","df5b1289":"ax = data[\"LoanAmount\"].hist(density=True, stacked=True, color='teal', alpha=0.6)\ndata[\"LoanAmount\"].plot(kind='density', color='teal')\nax.set(xlabel='Loan Amount')\nplt.show()","4e745dde":"# percent of missing \"Loan_Amount_Term\" \nprint('Percent of missing \"Loan_Amount_Term\" records is %.2f%%' %((data['Loan_Amount_Term'].isnull().sum()\/data.shape[0])*100))","dfc328ba":"print(\"Number of people who take a loan group by loan amount term :\")\nprint(data['Loan_Amount_Term'].value_counts())\nsns.countplot(x='Loan_Amount_Term', data=data, palette = 'Set2')","7ac8dba2":"# percent of missing \"Credit_History\" \nprint('Percent of missing \"Credit_History\" records is %.2f%%' %((data['Credit_History'].isnull().sum()\/data.shape[0])*100))","a2385674":"print(\"Number of people who take a loan group by credit history :\")\nprint(data['Credit_History'].value_counts())\nsns.countplot(x='Credit_History', data=data, palette = 'Set2')","cac3239f":"train_data = data.copy()\ntrain_data['Gender'].fillna(train_data['Gender'].value_counts().idxmax(), inplace=True)\ntrain_data['Married'].fillna(train_data['Married'].value_counts().idxmax(), inplace=True)\ntrain_data['Dependents'].fillna(train_data['Dependents'].value_counts().idxmax(), inplace=True)\ntrain_data['Self_Employed'].fillna(train_data['Self_Employed'].value_counts().idxmax(), inplace=True)\ntrain_data[\"LoanAmount\"].fillna(train_data[\"LoanAmount\"].mean(skipna=True), inplace=True)\ntrain_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].value_counts().idxmax(), inplace=True)\ntrain_data['Credit_History'].fillna(train_data['Credit_History'].value_counts().idxmax(), inplace=True)","f6617c7f":"#Check missing values\ntrain_data.isnull().sum()\ntrain_data","73018fa8":"#Convert some object data type to int64\ngender_stat = {\"Female\": 0, \"Male\": 1}\nyes_no_stat = {'No' : 0,'Yes' : 1}\ndependents_stat = {'0':0,'1':1,'2':2,'3+':3}\neducation_stat = {'Not Graduate' : 0, 'Graduate' : 1}\nproperty_stat = {'Semiurban' : 0, 'Urban' : 1,'Rural' : 2}\n\ntrain_data['Gender'] = train_data['Gender'].replace(gender_stat)\ntrain_data['Married'] = train_data['Married'].replace(yes_no_stat)\ntrain_data['Dependents'] = train_data['Dependents'].replace(dependents_stat)\ntrain_data['Education'] = train_data['Education'].replace(education_stat)\ntrain_data['Self_Employed'] = train_data['Self_Employed'].replace(yes_no_stat)\ntrain_data['Property_Area'] = train_data['Property_Area'].replace(property_stat)","b2bdfb9d":"#Preview data information\ndata.info()\ndata.isnull().sum()","f73e1b70":"#Separate feature and target\nx = train_data.iloc[:,1:12]\ny = train_data.iloc[:,12]\n\n#make variabel for save the result and to show it\nclassifier = ('Gradient Boosting','Random Forest','Decision Tree','K-Nearest Neighbor','SVM')\ny_pos = np.arange(len(classifier))\nscore = []","f3c3476d":"clf = GradientBoostingClassifier()\nscores = cross_val_score(clf, x, y,cv=5)\nscore.append(scores.mean())\nprint('The accuration of classification is %.2f%%' %(scores.mean()*100))","2c82f58b":"clf = RandomForestClassifier(n_estimators=10)\nscores = cross_val_score(clf, x, y,cv=5)\nscore.append(scores.mean())\nprint('The accuration of classification is %.2f%%' %(scores.mean()*100))","44485b08":"clf = DecisionTreeClassifier()\nscores = cross_val_score(clf, x, y,cv=5)\nscore.append(scores.mean())\nprint('The accuration of classification is %.2f%%' %(scores.mean()*100))","31a63e71":"clf = KNeighborsClassifier()\nscores = cross_val_score(clf, x, y,cv=5)\nscore.append(scores.mean())\nprint('The accuration of classification is %.2f%%' %(scores.mean()*100))","478e1b0b":"clf  =  svm.LinearSVC(max_iter=5000)\nscores = cross_val_score(clf, x, y,cv=5)\nscore.append(scores.mean())\nprint('The accuration of classification is %.2f%%' %(scores.mean()*100))","60dd8ddf":"plt.barh(y_pos, score, align='center', alpha=0.5)\nplt.yticks(y_pos, classifier)\nplt.xlabel('Score')\nplt.title('Classification Performance')\nplt.show()","899f63ee":"### Credit History - Missing Values","ca62ff7e":"## Reference\n1. J. Heo and J. Y. Yang, \"AdaBoost Based Bankruptcy Forecasting of Korean Construction Company,\" Applied Soft Computing, vol. 24, pp. 494-499, 2014.\n2. C.-F. Tsai, \"Feature Selection in Bankruptcy Prediction,\" Knowledge Based System, pp. 120-127, 2009.","0437cc37":"## 1. Import Packages & Data","03d4258d":"### Gender - Missing Values","cdf078ae":"This kernel I want try to make a loan approval prediction based on [Loan Prediction](https:\/\/www.kaggle.com\/ninzaami\/loan-predication\/home) dataset. Previously, I was made the same work for my university couse task but with different dataset. You can see my previous work on [this link](https:\/\/github.com\/hafidhfikri\/Bankruptcy-Prediction-Model) (in Bahasa). This work will compare the result of loan approval prediction classiffication algorithm with different dataset from my previous work. In previous work I get the Gradient Boosting Classifier as the best classifier for loan aproval prediction. Beside that, I want to make some improvement in this kernel inspired by the work of [Baligh's](https:\/\/www.kaggle.com\/mnassrib\/titanic-logistic-regression-with-python).","6234d3c7":"## 2. Data Quality & Missing Value Assesment","c8a84d3b":"### Loan Amount - Missing Values","4ff6a831":"## 5. Result","dd592091":"### Dependents- Missing Values","dfcdd4a4":"## 4. Making Prediction","b62133ff":"The result is Gradient Boosting Classifier have the highest score from other classification algorithm. These result are similar to my previous works.","6fdd172f":"### Loan Amount Term - Missing Values","3dee4a23":"> # Loan Approval Prediction","d1f48a92":"### Self Employed - Missing Values","b3a7d89b":"Based on my assessment of the missing values in the dataset, I'll make the following changes to the data:\n\n* If \"Gender\" is missing for a given row, I'll impute with Male (most common answer).\n* If \"Married\" is missing for a given row, I'll impute with yes (most common answer).\n* If \"Dependents\" is missing for a given row, I'll impute with 0 (most common answer).\n* If \"Self_Employed\" is missing for a given row, I'll impute with no (most common answer).\n* If \"LoanAmount\" is missing for a given row, I'll impute with mean of data.\n* If \"Loan_Amount_Term\" is missing for a given row, I'll impute with 360 (most common answer).\n* If \"Credit_History\" is missing for a given row, I'll impute with 1.0 (most common answer).","d546c74d":"### Married - Missing Values","12a89028":"## 3. Final Adjustments to Data"}}