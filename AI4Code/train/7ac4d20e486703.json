{"cell_type":{"dc8f9e74":"code","21329607":"code","ee624323":"code","9c663cc6":"code","5e0c81f3":"code","42072ab6":"code","d0718d2a":"code","8355ed04":"code","9423aadd":"code","e9e4f3d3":"code","4569eebe":"code","605a66d9":"code","9ac42192":"code","27eb9eb5":"code","097bf8e4":"code","d8682121":"code","b1bb6446":"code","6384abfe":"code","b2eaed70":"code","ab33d6bc":"code","9c0fe494":"code","f432c4c7":"code","f4ec5e46":"code","b5d1aa15":"code","3de9445d":"code","3dc1609c":"code","e81dde9a":"code","efc4a9c6":"code","f87607b7":"code","72de3b26":"code","26eac8da":"code","ffa9168c":"markdown","5f15c285":"markdown","30aae385":"markdown","7b4cf078":"markdown","823829f7":"markdown"},"source":{"dc8f9e74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21329607":"import matplotlib.pyplot as plt\nimport keras","ee624323":"data=pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")","9c663cc6":"data.head()","5e0c81f3":"data.shape","42072ab6":"train=data.iloc[:,1:]\ntrain.shape","d0718d2a":"label=data[\"label\"]\nlabel.shape","8355ed04":"plt.figure(figsize=(16,5))\nfor i in range(1,12):\n    plt.subplot(3,4,i)\n    plt.imshow(train.iloc[i].values.reshape(28,28),cmap=\"gray\")","9423aadd":"num_classes=label.unique()\nprint(num_classes)","e9e4f3d3":"train_label=keras.utils.to_categorical(label,len(num_classes))\nprint(train_label.shape)\nprint(type(train_label))","4569eebe":"train=train.values\ntrain=train.reshape(-1,28,28,1)\nprint(train.shape)\nprint(type(train))","605a66d9":"train=train.astype(\"float32\")\ntrain=train\/255\nprint(train.shape)","9ac42192":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(train,train_label,test_size=0.1,random_state=1)\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)\n","27eb9eb5":"from keras.preprocessing.image import ImageDataGenerator","097bf8e4":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\nll=datagen.fit(x_train)","d8682121":"from keras.models import Sequential,load_model\nfrom keras.layers import Conv2D,Dense,Flatten\nfrom keras.layers import MaxPool2D,BatchNormalization,Dropout\n\n","b1bb6446":"model=Sequential()\n\n# 1.katman\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\n\n# 2.katman\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.1))\n\n# 3.katman\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\n# 4.katman\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Tam ba\u011flant\u0131 katman\u0131\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\n# \u00c7\u0131k\u0131\u015f katman\u0131\nmodel.add(Dense(10, activation = \"softmax\"))\n\n\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n\nmodel.summary()","6384abfe":"hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=64),\n                           epochs=30,\n                           shuffle=True,\n                           validation_data=(x_val,y_val))","b2eaed70":"plt.figure(figsize=(15,3))\nplt.subplot(1,2,1)\nplt.plot(hist.history[\"loss\"],\"r\",label=\"Training Loss\",alpha=0.5)\nplt.plot(hist.history[\"val_loss\"],\"b\",label=\"Validation Loss\",alpha=0.5)\nplt.xlabel(\"Train\",fontsize=13)\nplt.ylabel(\"Loss\",fontsize=13)\nplt.legend(loc=\"upper right\")\n\nplt.figure(figsize=(15,3))\nplt.subplot(1,2,2)\nplt.plot(hist.history[\"accuracy\"],\"g\",label=\"Training Accuracy\",alpha=0.8)\nplt.plot(hist.history[\"val_accuracy\"],\"m\",label=\"Validation Accuracy\",alpha=0.8)\nplt.xlabel(\"Train\",fontsize=13)\nplt.ylabel(\"Accuracy\",fontsize=13)\nplt.legend(loc=\"lower right\")","ab33d6bc":"test=pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")","9c0fe494":"test.head()","f432c4c7":"x_test=test.iloc[:,1:]\nx_test.shape","f4ec5e46":"y_test=test.iloc[:,0]\ny_test.shape","b5d1aa15":"x_test=x_test.values.reshape(-1,28,28,1)\nx_test=x_test\/255","3de9445d":"print(x_test.shape)","3dc1609c":"y_test=keras.utils.to_categorical(y_test,len(num_classes))\ny_test.shape","e81dde9a":"labels=test.iloc[:,0]\nlabels.shape\n\nimages=test.iloc[:,1:]\nimages.shape\n","efc4a9c6":"images=images.values\nlabels=labels.values","f87607b7":"images[3].shape","72de3b26":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","26eac8da":"lp=int(input(\"Tahmin etmek istedi\u011finiz resimin numaras\u0131n\u0131 giriniz\"))\npredicted=model.predict(x_test[lp].reshape(-1,28,28,1))\nls=np.argmax(predicted)\n\nplt.figure(figsize=(12,3))\nplt.imshow(images[lp].reshape(28,28),cmap=\"gray\")\nplt.xlabel(\"Tahmininiz\"+\" \"+str(class_names[ls]))\n","ffa9168c":"\u015eimdi e\u011fitim modelimizi haz\u0131rlayal\u0131m.","5f15c285":"Haydi \u015fimdide ger\u00e7ekten test edelim.","30aae385":"Haydi \u015fimdi Data Augmentation yapal\u0131m","7b4cf078":"Verilerimizi okuyal\u0131m.","823829f7":"Haydi bir ka\u00e7\u0131n\u0131n nas\u0131l g\u00f6z\u00fckt\u00fc\u011f\u00fcne bakal\u0131m"}}