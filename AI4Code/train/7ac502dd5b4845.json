{"cell_type":{"b51a70b2":"code","d567172d":"code","0ba74bd3":"code","6c7e99c9":"code","8f9d5c57":"code","55f750a9":"code","d5397a56":"code","8cf34c5f":"code","24390a07":"code","1d05a2d0":"code","b40df1ca":"code","a9044dc9":"code","fd70a796":"code","327f4336":"code","b80180fe":"code","a6507886":"code","6304390c":"code","7e2528de":"code","730bd804":"code","ac27e41f":"code","0989cae8":"code","b5dac666":"code","c8c71592":"code","38c164f9":"code","f7d85d14":"code","893a7c3e":"code","569a797e":"code","80d45166":"code","86bd9ae6":"code","2e6126da":"code","96bf86d6":"code","bd7e6a00":"code","7832059b":"markdown","9ef32ffc":"markdown","0ca7775e":"markdown","3ac412b2":"markdown","307cfb30":"markdown","b0eb1ab8":"markdown","e3c62e91":"markdown","5d89ddd6":"markdown","81b6fd98":"markdown","684149bd":"markdown","95ccf2f4":"markdown","bd225839":"markdown","a8e9f924":"markdown","d1ff5cf7":"markdown","19d36ec6":"markdown","000df8b4":"markdown","3e5e65ad":"markdown","b512d4d6":"markdown","7522c784":"markdown","c7752065":"markdown","ec1a5bc7":"markdown","ff4f50c5":"markdown","5ee11289":"markdown","946d1293":"markdown","a57100f8":"markdown"},"source":{"b51a70b2":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\n\nimport os\nimport cv2\nfrom sklearn import preprocessing\nfrom pathlib import Path","d567172d":"\ntrain_path = []\nlabel_train = []\n\npath_train = \"..\/input\/fingers\/train\/\"\n\nfor filename in os.listdir(path_train):\n    \n    train_path.append(path_train+filename)\n    whole_label = filename.split('_')[1]\n    useful_label = whole_label.split('.')[0]\n    label_train.append(useful_label)\n\nprint(\"Number of train images: \", len(train_path))\nprint(\"First 6 labels: \", label_train[:6])","0ba74bd3":"test_path = []\nlabel_test = []\n\npath_train = \"..\/input\/fingers\/test\/\"\n\nfor filename in os.listdir(path_train):\n    \n    test_path.append(path_train+filename)\n    whole_label = filename.split('_')[1]\n    useful_label = whole_label.split('.')[0]\n    label_test.append(useful_label)\n\nprint(\"Number of test images: \", len(test_path))\nprint(\"First 6 labels: \", label_train[:6])","6c7e99c9":"train_path[0]","8f9d5c57":"# checking train path\nimage = cv2.imread(train_path[0]) \n\n# the first image bleongs to clean directory under train\nplt.imshow(image)\nplt.title(label_train[0], fontsize = 20)\nplt.axis('off')\nplt.show()","55f750a9":"# checking train path\nimage = cv2.imread(test_path[95]) \n\n# the first image bleongs to clean directory under train\nplt.imshow(image)\nplt.title(label_test[95], fontsize = 20)\nplt.axis('off')\nplt.show()","d5397a56":"X_train = []\nX_test = []\n\n# reading images for train data\nfor path in train_path:\n    \n    image = cv2.imread(path)        \n    image =  cv2.resize(image, (50,50))    \n    X_train.append(image)\n    \n# reading images for test data\nfor path in test_path:\n    \n    image = cv2.imread(path)        \n    image =  cv2.resize(image, (50,50))    \n    X_test.append(image)\n\nX_test = np.array(X_test)\nX_train = np.array(X_train)","8cf34c5f":"print(\"Shape of X_train: \", X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)","24390a07":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255\nX_test \/= 255","1d05a2d0":"lable_encoder = preprocessing.LabelEncoder()\ny_train_temp = lable_encoder.fit_transform(label_train)\ny_test_temp = lable_encoder.fit_transform(label_test)\n\nprint(\"Integer encoded values for train: \", y_train_temp)\nprint(\"Integer encoded values for test: \", y_test_temp)","b40df1ca":"y_train = keras.utils.to_categorical(y_train_temp, 12)\ny_test = keras.utils.to_categorical(y_test_temp, 12)\n\nprint(\"Categorical values for y_train:\", y_train)\nprint(\"Categorical values for y_test:\", y_test)","a9044dc9":"X_train_A , X_train_B = X_train[:9000], X_train[-9000:]\ny_train_A , y_train_B = y_train[:9000], y_train[-9000:]","fd70a796":"print(\"Shape of X_train_A: \", X_train_A.shape, \", shape of X_train_B: \", X_train_B.shape)","327f4336":"# uncomment to check if they are different or not\n# X_train_A == X_train_B","b80180fe":"model_seq = Sequential()\n\n# input shape for first layer is 50,50,3 -> 50 * 50 pixles and 3 channels\nmodel_seq.add(Conv2D(32, (3, 3), padding='same', input_shape=(50, 50, 3), activation=\"relu\"))\nmodel_seq.add(Conv2D(32, (3, 3), activation=\"relu\"))\n\n# maxpooling will take highest value from a filter of 2*2 shape\nmodel_seq.add(MaxPooling2D(pool_size=(2, 2)))\n\n# it will prevent overfitting\nmodel_seq.add(Dropout(0.25))\n\nmodel_seq.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\nmodel_seq.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel_seq.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_seq.add(Dropout(0.25))\n\nmodel_seq.add(Flatten())\nmodel_seq.add(Dense(512, activation=\"relu\"))\nmodel_seq.add(Dropout(0.5))\n\n# last layer predicts 12 labels\nmodel_seq.add(Dense(12, activation=\"softmax\"))\n\n# Compile the model\nmodel_seq.compile(\n    loss='categorical_crossentropy',\n    optimizer=\"adam\",\n    metrics=['accuracy']\n)\n\nmodel_seq.summary()","a6507886":"keras.utils.plot_model(model_seq, \"keras_seq_model.png\", show_shapes=True)","6304390c":"# two inputs\ninput_1 = keras.Input(shape=(50, 50, 3))\ninput_2 = keras.Input(shape=(50, 50, 3))\n\n\n# for input 1\nconv_1_1 = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(input_1)\nconv_1_2 = Conv2D(32, (3, 3), activation=\"relu\")(conv_1_1)\nmax_1_1 = MaxPooling2D(pool_size=(2, 2))(conv_1_2)\ndrop_1_1 = Dropout(0.25)(max_1_1)\nconv_1_3 = Conv2D(64, (3, 3), padding='same', activation=\"relu\")(drop_1_1)\nconv_1_4 = Conv2D(64, (3, 3), activation=\"relu\")(conv_1_3)\nmax_1_2 = MaxPooling2D(pool_size=(2, 2))(conv_1_4)\ndrop_1_2 = Dropout(0.25)(max_1_2)\nflat_1 = Flatten()(drop_1_2)\n\n# for input 2\nconv_2_1 = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(input_2)\nconv_2_2 = Conv2D(32, (3, 3), activation=\"relu\")(conv_2_1)\nmax_2_1 = MaxPooling2D(pool_size=(2, 2))(conv_2_2)\ndrop_2_1 = Dropout(0.3)(max_2_1)\nconv_2_3 = Conv2D(64, (3, 3), padding='same', activation=\"relu\")(drop_2_1)\nconv_2_4 = Conv2D(64, (3, 3), activation=\"relu\")(conv_2_3)\nmax_2_2 = MaxPooling2D(pool_size=(2, 2))(conv_2_4)\ndrop_2_2 = Dropout(0.3)(max_2_2)\nflat_2 = Flatten()(drop_2_2)\n\n# merge both falt layers\nmerge = concatenate([flat_1, flat_2])\n\ndense = Dense(512, activation=\"relu\")(merge)\ndrop = Dropout(0.5)(dense)\n\noutput = Dense(12, activation=\"softmax\")(drop)\n\n# creating model\nmodel_fun = Model(inputs = [input_1,input_2], outputs = output, name=\"functional_model\")\n\n# compile the model\nmodel_fun.compile(\n    loss='categorical_crossentropy',\n    optimizer=\"adam\",\n    metrics=['accuracy']\n)\n\nmodel_fun.summary()\n","7e2528de":"keras.utils.plot_model(model_fun, \"keras_func_model.png\", show_shapes=True)","730bd804":"# training the model\nhistory_seq = model_seq.fit(\n    X_train,\n    y_train,\n    batch_size=50,\n    epochs=30,\n    validation_split=0.2,\n    shuffle=True\n)","ac27e41f":"history_fun = model_fun.fit(\n    [X_train[:9000], X_train[-9000:]],\n    y_train,\n    batch_size=50,\n    epochs=30,\n    validation_split=0.2,\n    shuffle=True\n)","0989cae8":"# for sequential model\n# saving the structure of the model\nmodel_structure = model_seq.to_json()\nf = Path(\"model_seq_structure.json\")\nf.write_text(model_structure)\n\n# saving the neural network's trained weights\nmodel_seq.save_weights(\"model_seq_weights.h5\")\n\n\n\n# for functional model\n# saving the structure of the model\nmodel_structure = model_fun.to_json()\nf = Path(\"model_fun_structure.json\")\nf.write_text(model_structure)\n\n# saving the neural network's trained weights\nmodel_fun.save_weights(\"model_fun_weights.h5\")\n\n","b5dac666":"# displaying the model accuracy\n\nfig, axs = plt.subplots(1, 2 , figsize = [10,5])\n\nplt.suptitle(\"For Sequential Model\", fontsize = 20)\n\naxs[0].plot(history_seq.history['accuracy'], label='train', color=\"red\")\naxs[0].plot(history_seq.history['val_accuracy'], label='validation', color=\"blue\")\naxs[0].set_title('Model accuracy')\naxs[0].legend(loc='upper left')\naxs[0].set_ylabel('accuracy')\naxs[0].set_xlabel('epoch')\n\naxs[1].plot(history_seq.history['loss'], label='train', color=\"red\")\naxs[1].plot(history_seq.history['val_loss'], label='validation', color=\"blue\")\naxs[1].set_title('Model loss')\naxs[1].legend(loc='upper left')\naxs[1].set_xlabel('epoch')\naxs[1].set_ylabel('loss')\n\nplt.show()\n\n","c8c71592":"fig, axs = plt.subplots(1, 2 , figsize = [10,5])\n\nplt.suptitle(\"For functional api model\", fontsize = 20)\n\naxs[0].plot(history_fun.history['accuracy'], label='train', color=\"red\")\naxs[0].plot(history_fun.history['val_accuracy'], label='validation', color=\"blue\")\naxs[0].set_title('Model accuracy')\naxs[0].legend(loc='upper left')\naxs[0].set_ylabel('accuracy')\naxs[0].set_xlabel('epoch')\n\naxs[1].plot(history_fun.history['loss'], label='train', color=\"red\")\naxs[1].plot(history_fun.history['val_loss'], label='validation', color=\"blue\")\naxs[1].set_title('Model loss')\naxs[1].legend(loc='upper left')\naxs[1].set_xlabel('epoch')\naxs[1].set_ylabel('loss')\n\nplt.show()\n","38c164f9":"print(\"For sequential model: \")\nscore, accuracy = model_seq.evaluate(X_test, y_test)\nprint('Test score achieved: ', score)\nprint('Test accuracy achieved: ', accuracy)","f7d85d14":"print(\"For functional API model: \")\nscore, accuracy = model_fun.evaluate([X_test[:9000], X_test[-9000:]], y_test)\nprint('Test score achieved: ', score)\nprint('Test accuracy achieved: ', accuracy)","893a7c3e":"pred = model_seq.predict(X_test)\npred[:10]","569a797e":"y_test[:10]","80d45166":"fig, axs= plt.subplots(2,5, figsize=[24,12])\n\n\ncount=0\nfor i in range(2):    \n    for j in range(5):  \n        \n        img = cv2.imread(test_path[count])\n        \n        results = np.argsort(pred[count])[::-1]\n      \n        labels = lable_encoder.inverse_transform(results)\n        \n        axs[i][j].imshow(img)\n        axs[i][j].set_title(labels[0], fontsize = 20)\n        axs[i][j].axis('off')\n\n        count+=1\n        \nplt.suptitle(\"Sequential Model : all predictions are shown in title\", fontsize = 24)        \nplt.show()","86bd9ae6":"pred2 = model_fun.predict([X_test[:9000], X_test[-9000:]])\npred2[20:30]","2e6126da":"fig, axs= plt.subplots(2,5, figsize=[24,12])\n\n\ncount=20\nfor i in range(2):    \n    for j in range(5):  \n        \n        img = cv2.imread(test_path[count])\n        \n        results = np.argsort(pred2[count])[::-1]\n      \n        labels = lable_encoder.inverse_transform(results)\n        \n        axs[i][j].imshow(img)\n        axs[i][j].set_title(labels[0], fontsize = 20)\n        axs[i][j].axis('off')\n\n        count+=1\n        \nplt.suptitle(\"Functional Model : all predictions are shown in title\", fontsize = 24)        \nplt.show()","96bf86d6":"!pip install keract","bd7e6a00":"from keract import get_activations, display_heatmaps\nkeract_inputs = X_test[:1]\nkeract_targets = y_test[:1]\nactivations = get_activations(model_seq, keract_inputs)\ndisplay_heatmaps(activations, keract_inputs, save=False)","7832059b":"# Creating the Sequential model #","9ef32ffc":"# Visualising output of each layer in sequential model and functional api model\n\n","0ca7775e":"## Analysing with sequential model first, then we will use functional model ##","3ac412b2":"Inputs for functional model keras","307cfb30":"Keras model works on numpy arrays and thus, images are required to convert to numpy. Same goes for the labels","b0eb1ab8":"# Thank you #","e3c62e91":"# Analysing the results #","5d89ddd6":"Divding each pixel value in range 0 - 255 with 255 to get numbers in range 0 - 1","81b6fd98":"# Classifying the finger images\n\nGoal: Our goal is to classify the unknown images into clean house or messy house label. For this purpose we will use Keras Sequential model and Functional API , with Categorical Crossentropy and softmax activation as we have 12 target categories.\n\n1. [Reading the data](#Reading-the-data)\n2. [Verifying the images](#Verifying-the-images)\n3. [Creating train , test and validation set](#Creating-train-,-test-and-validation-set)\n4. [Creating the Sequential model](#Creating-the-Sequential-model)\n5. [Training the model](#Training-the-model)\n6. [Storing the results](#Storing-the-results)\n7. [Analysing the results](#Analysing-the-results)","684149bd":"# Training the model","95ccf2f4":"# Storing the results #","bd225839":"Calculating the accuracy achieved","a8e9f924":"Source code for the following visualization is taken from this amazing documentation [Visualize layer outputs of your Keras classifier with Keract](https:\/\/www.machinecurve.com\/index.php\/2019\/12\/02\/visualize-layer-outputs-of-your-keras-classifier-with-keract\/)","d1ff5cf7":"# References: #\n\n1. [Keras Guide train and evaluate](https:\/\/www.tensorflow.org\/guide\/keras\/train_and_evaluate)\n2. [Machine Learning Mastery](https:\/\/machinelearningmastery.com\/keras-functional-api-deep-learning\/)\n3. [Keras API Models](https:\/\/keras.io\/api\/models\/)\n4. [Keras multiple inputs and mixed data](https:\/\/www.pyimagesearch.com\/2019\/02\/04\/keras-multiple-inputs-and-mixed-data\/)\n5. [Visualize layer outputs of your Keras classifier with Keract](https:\/\/www.machinecurve.com\/index.php\/2019\/12\/02\/visualize-layer-outputs-of-your-keras-classifier-with-keract\/)","19d36ec6":"# Reading the data","000df8b4":"# Verifying the images #","3e5e65ad":"Retrieving the path is relatively easy. The only challenge is to retrieve the label. The label is stored in the image name. Example: The following is a path:\n\n*..\/input\/fingers\/train\/00048bba-979b-4f84-b833-5bbbb082b582_0L.png*\n\nThe last two characters before .png are labels. Here 0L is a label which indicates 0 fingers from left hand. Thus, it requires to step to retrieve 0L.\n\n1. Split the image name with '_' and take the second half (0L.png)\n2. Split the result obtained in step 1 with '.' and take the first half\n","b512d4d6":"At last displaying the model prediction for first 10 images of test set","7522c784":"Label encoding all the labels and then converting to categorical values","c7752065":"# Creating train , test and validation set #","ec1a5bc7":"Displaying the model accuracy and loss using graphs","ff4f50c5":"Importing all the libraries required first","5ee11289":"### Let's take images from range 20-30 for functional model api anaylsis","946d1293":"## For sequential model","a57100f8":"Storing the results for future use"}}