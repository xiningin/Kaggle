{"cell_type":{"2e232689":"code","fb244961":"code","fac89496":"code","f60eb158":"code","955252b2":"code","8b9f6ff0":"code","b34026b7":"code","8485cca5":"code","71c5cfa8":"code","ead5a0ab":"code","1d8ba002":"code","8b09c399":"code","cbc9a7a5":"markdown","227dbdd3":"markdown","9e3bccb4":"markdown","f169de6b":"markdown","ec4f6282":"markdown","795dc916":"markdown","2f7eccca":"markdown","40852c8f":"markdown","0644a900":"markdown","ab8ea4c5":"markdown","c42f51b4":"markdown","fc8418ac":"markdown","bae9c8ac":"markdown","82efbf62":"markdown","27585f77":"markdown","7a0d3cd1":"markdown","ad91d625":"markdown"},"source":{"2e232689":"#Import libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#sklearn libraries\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","fb244961":"#Load the data\nzoo = pd.read_csv('..\/input\/zoo-animal-classification\/zoo.csv')\nclass_df = pd.read_csv('..\/input\/zoo-animal-classification\/class.csv')","fac89496":"#Combine the zoo and the class files\nzoo = zoo.merge(class_df,how='left',left_on='class_type',right_on='Class_Number')\n","f60eb158":"zoo","955252b2":"\nprint(zoo.columns)\n\nprint(zoo['animal_name'].unique() )\n\nprint(zoo['Class_Type'].unique() )\n\n","8b9f6ff0":"plt.figure(figsize=(10,10))\nsns.light_palette(\"seagreen\", as_cmap=True)\nfig = sns.countplot(x=zoo['Class_Type'],label=\"Count\", palette = \"Greens_r\")\nfig = fig.get_figure()\n","b34026b7":"plt.figure(figsize=(13,13))\ncorr = zoo.iloc[:,1:-1].corr()\nsns.heatmap(corr, cmap = \"Greens\", annot=True)\nplt.show()","8485cca5":"# Remove unwanted columns, and assign the x and y values\nfeatures = ['hair', 'feathers', 'eggs', 'milk', 'airborne',\n       'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous',\n       'fins', 'legs', 'tail', 'domestic', 'catsize']\nX = zoo[features]\ny = zoo['Class_Number']\n\n# Split these x and y values into testing\ntrain_X, val_X, train_y, val_y = train_test_split(X,y, random_state=1 )","71c5cfa8":"#Implement KNN\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(train_X,train_y)\n\npred = knn.predict(train_X)\nprint(\"Accuracy: {}\".format(accuracy_score(train_y, pred)))","ead5a0ab":"# Let's try many iterations of N\n\n#Create an empty list to later insert our results\naccuracy = []\n\n#Let's check all the way to 50 neighbors away\nneighbors = range(1,50)\nfor i in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_X,train_y)\n    pred = knn.predict(train_X)\n    accuracy.append(metrics.accuracy_score(train_y, pred))\n\n#Now print the results\nprint(accuracy)","1d8ba002":"#Let's visualize these results\nplt.figure(figsize=(10,10))\nplt.plot(neighbors,accuracy, color = 'green')\nplt.xlabel('Value of N')\n_ = plt.ylabel('Accuracy')","8b09c399":"dec = DecisionTreeClassifier(random_state=1)\ndec = dec.fit(train_X,train_y)\npred = dec.predict(val_X)\n\nplt.figure(figsize=(25,25))\n_ = tree.plot_tree(dec,feature_names = features,filled = True)\n\nprint(\"Accuracy: \" + str(accuracy_score(val_y,pred)))\n\n","cbc9a7a5":"It is evident that using a decision tree is much more effective of a solution -- netting us a 96% accuracy rating.","227dbdd3":"For our Machine Learning portion, we are going to split the data into our feautures and our target values.\n\n> Our **feautures** to be tested are: *hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, fins, legs, tail, domestic, catsize.*\n\n> Our **target value** to predict are the class types: *mammal, fish, bird, invertebrate, bug, amphibian, reptile.*\n\nUsing our various methods, we are going to split the data into specific training and testing sections and see which is the most accurate form of classification. Basically, we are training our machine to use various algorithms to go through the list of animal feautures and see if it can accurately predict which type of animal it is based off of what type of bodily feautures it possesses. ","9e3bccb4":"# c) Test Splitting","f169de6b":"To get a brief idea of what we expect, let's first run a correlation plot on all our feautres and see if any arise.","ec4f6282":"What is KNN?\n\nFrom medium.com,\n> *K-nearest neighbors (KNN) is a type of supervised learning algorithm used for both regression and classification. KNN tries to predict the correct class for the test data by calculating the distance between the test data and all the training points. Then select the K number of points which is closet to the test data. The KNN algorithm calculates the probability of the test data belonging to the classes of \u2018K\u2019 training data and class holds the highest probability will be selected. In the case of regression, the value is the mean of the \u2018K\u2019 selected training points.*","795dc916":"# **Classification using Zoo Animals**\n\nThis project was my first foray into Machine Learning. \n\nIn this project, I am using a dataset of over 100 zoo animals (comprised of all their various feautures). I will be using two methods of classification -- K-Nearest Neighbors and Decision Trees -- to try and train my machine to predict what class type each animal belongs to after assessing each of their bodily feautures. ","2f7eccca":"# **3) Conclusion**","40852c8f":"# **b) Brief Exploratory Analysis** ","0644a900":"# **Table of Contents**\n* **a)** Code Library Set-Up\n* **b)** Brief Exploratory Analysis\n* **c)** Test Splitting\n* **1)** K-Nearest Neighbors Classification\n* **2)** Decision Tree Classification\n* **3)** Conclusion","ab8ea4c5":"# **a) Code Library Set-Up**","c42f51b4":"# **1) K-Nearest Neighbors**","fc8418ac":"We can see that using a Decision Tree, our accuracy in correctly classifying an animal is **96%**.","bae9c8ac":"What is a decision tree?\n\nFrom medium.com,\n> DTs are ML algorithms that progressively divide data sets into smaller data groups based on a descriptive feature, until they reach sets that are small enough to be described by some label.","82efbf62":" # So what's in the data?\n \n* 101 animals\n* The feautures are:\n    * hair\n    * feathers\n    * eggs\n    * milk\n    * airborne\n    * aquatic\n    * predator\n    * toothed\n    * backbone\n    * venomous\n    * fins\n    * legs\n    * tail\n    * domestic\n    * catsize\n* The types of classes are: \n    * mammal\n    * fish\n    * bird\n    * invertebrate\n    * bug\n    * amphibian\n    * reptile","27585f77":"# Visualization of our data","7a0d3cd1":"Below is a basic plot showing how much of each species we have.","ad91d625":"# 2) Decision Tree"}}