{"cell_type":{"d9b6eaff":"code","fc258e37":"code","5eebb30e":"code","8a217bf3":"code","fe7583c0":"code","c908c08b":"code","d49fdcd5":"code","fa4f70df":"code","a07038e9":"code","81bf54a7":"code","309ce457":"code","e3f6116c":"markdown","fd623f84":"markdown"},"source":{"d9b6eaff":"#import data and libraries\nimport numpy as np\nimport pandas as pd \nimport os\nimport math\nimport matplotlib.pyplot as plt\n\nimport sklearn\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier as DTC\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","fc258e37":"#print data\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/bankrupcy\/train.csv\")\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/bankrupcy\/test.csv\")\n\ntrain_data.columns = [c.replace(' ', '') for c in train_data.columns]\ntest_data.columns = [c.replace(' ', '') for c in test_data.columns]\n\n#train_data.head()\ntrain_data.info()\n#test_data.head()\n#test_data.info()","5eebb30e":"#detect missing values\n\n#missing values replace with mean\ndef missingval(data):\n    for i in data.columns:\n        if data[i].mode()[0] != 0:\n           data[i] = [data[i].mean() if x==0 else x for x in data[i]]\n        \n\n    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n    imp = imp.fit(data)\n\nmissingval(train_data)\nmissingval(test_data)\n\ntrain_data.head()","8a217bf3":"#outliers univariate method\n\n\ndef outlier(train_data):\n    # boolean features without outliers\n    no_outliers = ['id', 'Bankrupt', 'oneifnetincomewasnegativeforthelasttwoyearzerootherwise', 'oneiftotalliabilitiesexceedstotalassetszerootherwise']\n    for c in train_data.columns:\n        if c in no_outliers:\n            continue\n        for x in [c]:\n            q75,q25 = np.percentile(train_data.loc[:,x],[75,25])\n            intr_qr = q75-q25\n\n            max = q75+(1.5*intr_qr)\n            min = q25-(1.5*intr_qr)\n            #min = 0\n            \n            #Winsorizing outliers : trim outliers to mean ans max\n            train_data.loc[train_data[x] < min ,x] = min\n            train_data.loc[train_data[x] > max ,x] = max\n\noutlier(train_data)\noutlier(test_data)\ntrain_data.info()\n","fe7583c0":"#Data distribution varies conciderably amoung features\n#all either Normal, left tail, or right tail\n\nfor c in train_data.columns:\n    plt.hist(train_data[c].values)\n    plt.show()","c908c08b":"#data normalization\n#features of different magnitudes are equalized for more accurate comparison with varying data distriubtions\n\ndef normalize(data):\n    scaler = MinMaxScaler() \n    data=pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n\n#normalize(train_data)\n#normalize(test_data)\n\nobject = StandardScaler()\nobject.fit_transform(train_data)\nobject.fit_transform(test_data)\n\ntrain_data.head()","d49fdcd5":"#decision tree classifier model\n\nfeatures = test_data.columns\n\nX = train_data[features]\ny = train_data.Bankrupt\n\n#split dataset 80\/20\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, stratify=y, random_state=123)\n\n#instanciate decision tree\ndt = DTC(max_depth=7, criterion='gini', min_samples_leaf = 1, random_state=123)\n\n#fit dt to training set\ndt.fit(X_train, y_train)\n# predict values for test set\ny_pred = dt.predict(X_test)\n\n\n#scores\nresult1 = sklearn.metrics.classification_report(y_test, y_pred)\nprint(\"Classification Report:\",)\nprint(result1)\n\n#accuracy score\nprint(\"accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred))\n\n#ROC AUC\nprint(\"ROC AUC:\", sklearn.metrics.roc_auc_score(y_test, y_pred))\n\n#F1\nprint(\"F1:\", sklearn.metrics.f1_score(y_test, y_pred))\n\n","fa4f70df":"#save DTC predictions to csv\n\n#dt.fit(X, y) \nX_test2 = pd.get_dummies(test_data[features])\npredictions = dt.predict_proba(X_test2)\n\noutput = pd.DataFrame({'id': test_data.id, 'Bankrupt': predictions[:,1]}) \noutput.to_csv('submissionDTC.csv', index=False) \nprint(\"Your submission was saved!\")","a07038e9":"#Random forest classifier model\n\nseed = 123\n\nX = train_data[features]\ny = train_data.Bankrupt\n#split dataset 80\/20\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.1, stratify=y, random_state=seed)\nmodel = RandomForestClassifier(n_estimators=100, max_features = 8, max_depth=9, min_samples_leaf=1, criterion='entropy', random_state=seed)\n\nmodel.fit(X_train, y_train) \ny_pred = model.predict(X_test)\n\n\n\n#scores\nresult1 = sklearn.metrics.classification_report(y_test, y_pred)\nprint(\"Classification Report:\",)\nprint(result1)\n\n#accuracy score\nprint(\"accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred))\n#ROC AUC\nprint(\"ROC AUC:\", sklearn.metrics.roc_auc_score(y_test, y_pred))\n\n#train data F1\nprint(\"F1:\", sklearn.metrics.f1_score(y_test, y_pred))","81bf54a7":"#feature importance\nfeature_imp = pd.Series(model.feature_importances_,index=train_data.columns.drop('id')).sort_values(ascending=False)\nfeature_imp.head(5)","309ce457":"#save RFC predictions to csv\n\nmodel.fit(X, y) \npredictions = model.predict_proba(X_test2)\n\noutput = pd.DataFrame({'id': test_data.id, 'Bankrupt': predictions[:,1]})\noutput.to_csv('submissionRFC.csv', index=False) \nprint(\"Your submission was saved!\")\n","e3f6116c":"\n    You must load the data from the provided CSV files.\n    You must check for missing values within the training data.\n    If the training data contains missing values, you must describe and implement an approach to handle those missing values.\n    You must check for outliers within the training data.\n    If the training data contains outliers, you must describe and implement an approach to handle those outliers.\n    You must determine whether or not you will implement normalization or standardization, and explain your decision.\n    You must build and train a decision tree model on the training data.\n    You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your decision tree model.\n    You must build and train a random forest model on the training data.\n    You must report the best ROC AUC score, F1 score, and accuracy score that you were able to obtain for your random forest model.\n    You must select the best model that you are able to generate and use that model to predict the target vector for the test data.\n    Your notebook must be saved with the output enabled so that we can see the results of each cell after it has been run.\n        Failure to adhere to this criterion will result in a 0 for this portion of your score.\n","fd623f84":"Austin Dunlop CAP 4611 Spring 2021 Kaggle username: Au7413"}}