{"cell_type":{"f9d5c348":"code","d898dd2a":"code","e130cf3a":"code","0134b5f0":"code","d7f5022a":"code","c66830cb":"code","4fc1ecc6":"code","16fe57c8":"code","4d3ca2e0":"code","295246ad":"code","561743d7":"code","7f6d2afb":"code","b31bc6c3":"code","3cada367":"markdown","8787fa27":"markdown","3932f0da":"markdown","2d0a1ec6":"markdown","cad477fb":"markdown","0f337209":"markdown","e31a474a":"markdown","75849134":"markdown"},"source":{"f9d5c348":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ndir = '..\/input'\nprint(os.listdir(dir))\n# Any results you write to the current directory are saved as output.","d898dd2a":"from __future__ import print_function\n\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing.data import QuantileTransformer\n\nimport seaborn as sns\nsns.set(style=\"white\", color_codes=True)\n\n%matplotlib inline\n\n\nimport warnings\nwarnings.simplefilter('ignore')","e130cf3a":"dataset = pd.read_csv(dir + '\/housing.csv')","0134b5f0":"dfX = pd.DataFrame(dataset['median_income'])\ncol = dfX['median_income'].values.reshape(-1, 1)\n\nscalers = [\n    #('Unscaled data', X),\n    ('standard scaling', StandardScaler()),\n    ('min-max scaling', MinMaxScaler()),\n    ('max-abs scaling', MaxAbsScaler()),\n    ('robust scaling', RobustScaler(quantile_range=(25, 75))),\n    ('quantile transformation (uniform pdf)', QuantileTransformer(output_distribution='uniform')),\n    ('quantile transformation (gaussian pdf)', QuantileTransformer(output_distribution='normal')),\n    ('sample-wise L2 normalizing', Normalizer())\n]\n\nfor scaler in scalers:\n    dfX[scaler[0]] = scaler[1].fit_transform(col)\n    \ndfX.head()","d7f5022a":"orig = dfX['median_income']\norig_mean = orig.mean()\nbins = 50\nalpha=0.5\n\ndef plot_experiment(name):\n    normalized = dfX[name]\n    plt.figure(figsize=(10,5))\n    plt.hist(orig, bins, alpha=alpha, label='Original')\n    plt.axvline(orig_mean, color='k', linestyle='dashed', linewidth=1)\n\n    plt.hist(normalized, bins, alpha=alpha, label=name)\n    plt.axvline(normalized.mean(), color='k', linestyle='dashed', linewidth=1)\n    plt.legend(loc='upper right')\n\n    plt.figure(figsize=(5,5))\n    g = sns.jointplot(x=\"median_income\", y=name, data=dfX, kind='hex', ratio=3)\n    #sns.violinplot(x='median_income', data=dfX, )\n    #sns.violinplot(x='standard scaling', data=dfX)\n    #plt.boxplot(dfX['median_income'])\n    #plt.boxplot(dfX['standard scaling'])\n    plt.show()\n","c66830cb":"plot_experiment('standard scaling')","4fc1ecc6":"plot_experiment('min-max scaling')","16fe57c8":"plot_experiment('max-abs scaling')","4d3ca2e0":"plot_experiment('robust scaling')","295246ad":"plot_experiment('quantile transformation (uniform pdf)')","561743d7":"plot_experiment('quantile transformation (gaussian pdf)')","7f6d2afb":"plot_experiment('sample-wise L2 normalizing')","b31bc6c3":"dfX[['median_income', 'sample-wise L2 normalizing']].sample(20)","3cada367":"From http:\/\/scikit-learn.org\/stable\/auto_examples\/preprocessing\/plot_all_scaling.html\n","8787fa27":"## QuantileTransformer (uniform output)\n\nQuantileTransformer applies a non-linear transformation such that the probability density function of each feature will be mapped to a uniform distribution. In this case, all the data will be mapped in the range [0, 1], even the outliers which cannot be distinguished anymore from the inliers.\n\nAs RobustScaler, QuantileTransformer is robust to outliers in the sense that adding or removing outliers in the training set will yield approximately the same transformation on held out data. But contrary to RobustScaler, QuantileTransformer will also automatically collapse any outlier by setting them to the a priori defined range boundaries (0 and 1).","3932f0da":"## StandardScaler\n\nStandardScaler removes the mean and scales the data to unit variance. However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values.\n\nStandardScaler therefore cannot guarantee balanced feature scales in the presence of outliers.","2d0a1ec6":"## RobustScaler\nUnlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: most of the transformed values lie in a [-2, 3] range. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below).","cad477fb":"## QuantileTransformer (Gaussian output)\nQuantileTransformer has an additional output_distribution parameter allowing to match a Gaussian distribution instead of a uniform distribution. Note that this non-parametetric transformer introduces saturation artifacts for extreme values.","0f337209":"## MaxAbsScaler\nMaxAbsScaler differs from the previous scaler such that the absolute values are mapped in the range [0, 1]. On positive only data, this scaler behaves similarly to MinMaxScaler and therefore also suffers from the presence of large outliers.","e31a474a":"## Normalizer\nThe Normalizer rescales the vector for each sample to have unit norm, independently of the distribution of the samples. It can be seen on both figures below where all samples are mapped onto the unit circle. In our example the two selected features have only positive values; therefore the transformed data only lie in the positive quadrant. This would not be the case if some original features had a mix of positive and negative values.","75849134":"## MinMaxScaler\n\nMinMaxScaler rescales the data set such that all feature values are in the range [0, 1]. \n\nAs StandardScaler, MinMaxScaler is very sensitive to the presence of outliers."}}