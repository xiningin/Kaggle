{"cell_type":{"dc3fd0b9":"code","058d292f":"code","7b845949":"code","cbc02c4f":"code","707b758c":"code","f34e74c2":"code","9941fd79":"code","ffaf7b79":"code","776920ec":"code","657b0012":"code","776b0595":"code","0f6196cb":"code","f645735e":"code","5eab8404":"markdown"},"source":{"dc3fd0b9":"import shutil\nimport os\nimport numpy as np\nimport fastai\nfrom fastai import *\nfrom fastai.vision.all import *\nfrom fastai.imports import *\nfrom fastai.vision import *\nfrom fastai.metrics import *\n\nfrom fastai.vision.all import *\n","058d292f":"# unzip train and test data\n\n!unzip -q \"\/kaggle\/input\/hotdogornot\/train.zip\"\n!unzip -q \"\/kaggle\/input\/hotdogornot\/test.zip\"\n","7b845949":"# get file paths for training images\ntrain_file_path = \"train_kaggle\/\"\n\n# replace chili-dog and frankfurter to hotdog\nfor file in os.listdir(train_file_path):\n    if 'chili-dog' in file:\n        os.rename(os.path.join(train_file_path, file), os.path.join(train_file_path, file.replace('chili-dog', 'hotdog')))\n    elif 'frankfurter' in file:\n        os.rename(os.path.join(train_file_path, file), os.path.join(train_file_path, file.replace('frankfurter', 'hotdog')))\n\nimage_paths = get_image_files(train_file_path)\nprint(image_paths[:20])","cbc02c4f":"# settings\n\nmodel = models.resnet50\nwork_dir = os.getcwd()\nimage_size=299\nbatch_size=16","707b758c":"# Splitting training data into train\/validation by sub-folders so we can automatically create labels\n# image pre-processing in preparation for training\n\ndata = ImageDataLoaders.from_name_re(path=train_file_path,\n                                   fnames=image_paths, \n                                   pat=r'([^\/]+)_\\d+\\.jpg$', \n                                   valid_pct=0.2,\n                                   ds_tfms=aug_transforms(), \n                                   test='data\/test_kaggle', \n                                   bs=batch_size,\n                                   num_workers=0,\n                                   seed=42,\n                                   item_tfms=Resize(image_size),\n                                   batch_tfms=Normalize.from_stats(*imagenet_stats))\ndata.show_batch()","f34e74c2":"# creates a Learner: an abstraction connecting a model, an optimizer, and the data to train it on \u2014 and automatically chooses an appropriate loss function.For this example the learner, we will:\n# Automatically download an ImageNet pretrained model\n# Remove the classification head of the model\n# Replace it with a head appropriate for this particular dataset\n# Set appropriate defaults for the optimizer, weight decay, learning rate, and other hyperparameters (users can override the defaults as well)\nlearn = cnn_learner(data, model, metrics=accuracy, model_dir=work_dir)","9941fd79":"# Fine-tunes the model using the 1-cycle policy: \n# Annealing both learning rates and momentums\n# Printing metrics on the validation set\n# Displaying results in an HTML or console table\n# Recording losses and metrics after every batch\n# A GPU will be used if available: it will first train the head for one epoch while the body of the model is frozen, then fine-tune as many epochs given, using discriminative learning rates.\nmetric = \"valid_loss\"\ndelta = 0.005\nlearn.fine_tune(\n    5, \n#     cbs=[\n#     EarlyStoppingCallback(monitor=metric, min_delta=delta, patience=10),\n#     SaveModelCallback(monitor=metric, min_delta=delta),\n#     ReduceLROnPlateau(monitor=metric, min_delta=delta, patience=5)\n#     ]\n) ","ffaf7b79":"# look at test results for a random set of files\nlearn.show_results()","776920ec":"# calculate and plot confusion matrix\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)","657b0012":"# plot top losses for wrong predictions with high confidence\ninterp.plot_top_losses(5, nrows=5)","776b0595":"# export model file\nlearn.path = Path(os.getcwd())\nlearn.export()","0f6196cb":"# predict on test set\n\ntest_file_path = \"test_kaggle\/\"\ntest_img = get_image_files(test_file_path)\n\ntest_dl = learn.dls.test_dl(test_img)\npred_tensor, ignored, preds = learn.get_preds(dl=test_dl, with_decoded=True)\n","f645735e":"# create submission file\ndict_label_order = {order: label for order,label in enumerate(learn.dls.vocab)}\nprediction = [dict_label_order[x.item()] for x in preds] \nfn = [str(f).rsplit('\/',1)[1] for f in test_dl.items]\npred_df = pd.DataFrame({'image_id': fn, 'prediction':prediction})\npred_df['label'] = pred_df['prediction']\npred_df[['image_id', 'label']].to_csv('sumbmission.csv', index=False)","5eab8404":"# Data Import"}}