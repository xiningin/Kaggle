{"cell_type":{"ad8d2d70":"code","341e033f":"code","27c96465":"code","7c4a5f17":"code","76889ede":"code","ca4c986c":"code","741d37ac":"code","a49710b8":"code","717e48f3":"code","bbbbc4dd":"code","38a266b9":"code","98a3fa5a":"code","ca58b206":"code","5cd07172":"code","b47efaed":"code","6d3dd4e8":"code","921eeb7c":"code","c103cbef":"code","ea3abe81":"code","65a036ec":"code","5d86dd92":"code","e29938a9":"code","b59edefe":"code","db8af9d4":"code","ba6a05a2":"code","4a0dbb66":"code","270be8cf":"code","0a27d18c":"code","6914d39d":"code","6c3c4342":"markdown","2aed170e":"markdown","605f38ee":"markdown","f8116ff4":"markdown","eb3f97fd":"markdown","66c57cca":"markdown","3fdb22d7":"markdown","f485dabf":"markdown","d702564f":"markdown","29b65b58":"markdown","9cf33718":"markdown","e3057614":"markdown","1538c2d5":"markdown","e5e83f39":"markdown","83557bc6":"markdown","5bb74989":"markdown"},"source":{"ad8d2d70":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom statistics import mean\nimport re\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nimport lightgbm as lgb\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","341e033f":"#importing datasets\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain.head()","27c96465":"#drop id columns\ntrain = train.drop('PassengerId', axis = 1)\ntest = test.drop('PassengerId', axis = 1)\n\ntrain_features = train.drop('Survived', axis = 1)\ntrain_dependent = train['Survived']\n\nnumerical_cols = []\ncategorical_cols = []\nfor col in train_features.columns:\n    if train_features[col].dtype in  ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']:\n        numerical_cols.append(col)\n    elif train_features[col].dtype == object:\n        categorical_cols.append(col)\n        \ncolumns = numerical_cols + categorical_cols\ntrain_features = train_features[columns]\ntest = test[columns]\n\nprint(train_features.columns, train_features.shape)\nprint(train_dependent.shape)\nprint(test.columns, test.shape)","7c4a5f17":"#merge train_features and test\nfeatures = pd.concat([train_features, test], axis = 0)\nfeatures.dtypes","76889ede":"null = features[numerical_cols].isna().sum().sort_values(ascending = False)\nnull","ca4c986c":"#imputing missing values in the age column w\/the mean.\nx = features.iloc[:, 1].values\nx = x.reshape(-1,1)\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(x)\nx = imputer.transform(x)\nfeatures.iloc[:, 1] = x","741d37ac":"#handling null fare values\n#Check the row with null Fare Value since its only one record\nfeatures[features[\"Fare\"].isnull()]","a49710b8":"#check for Fare prices for passengers in 3rd class who embarked from Southampton.\nfor a,b,c in zip(features[\"Fare\"], features[\"Pclass\"], features[\"Embarked\"]):\n    if b == 3 and c == \"S\":\n        fare = a\n\n#find the average fare for these passengers\nclass_3_list = [fare]\nm = mean(class_3_list)\n\n#replace the nan with this average\nfeatures[\"Fare\"].fillna(m, inplace = True) ","717e48f3":"null = features[categorical_cols].isnull().sum().sort_values(ascending = False)\nnull","bbbbc4dd":"#dealing w\/missing cabin data in both datasets\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n\nfeatures['Cabin'] = features['Cabin'].fillna(\"U0\")\nfeatures['Deck'] = features['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\nfeatures['Deck'] = features['Deck'].map(deck)\nfeatures['Deck'] = features['Deck'].fillna(0)\nfeatures['Deck'] = features['Deck'].astype(int)\nfeatures = features.drop(['Cabin'], axis=1)","38a266b9":"#imputing null values in Embarked column w\/the value with highest frequency.\ny = features.iloc[:, -1].values\ny = y.reshape(-1,1)\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimputer = imputer.fit(y)\ny = imputer.transform(y)\nfeatures.iloc[:, -1] = y","98a3fa5a":"features.isna().any()","ca58b206":"#handling the name column\ntitles = {\"Mr\": 0, \"Mrs\": 1, \"Miss\": 2, \"Master\": 3, \"Rare\": 4}\n\n# extract titles\nfeatures['Title'] = features.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# replace titles with a more common title or as Rare\nfeatures['Title'] = features['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                        'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\nfeatures['Title'] = features['Title'].replace('Mlle', 'Miss')\nfeatures['Title'] = features['Title'].replace('Ms', 'Miss')\nfeatures['Title'] = features['Title'].replace('Mme', 'Mrs')\n\n# convert titles into numbers\nfeatures['Title'] = features['Title'].map(titles)\n\n# filling NaN with 0, to get safe\nfeatures['Title'] = features['Title'].fillna(0)\n\nfeatures = features.drop(['Name'], axis=1)","5cd07172":"#creating categories\n#age\nfeatures['Age'] = features['Age'].astype(int)\nfeatures.loc[ features['Age'] <= 11, 'Age'] = 0\nfeatures.loc[(features['Age'] > 11) & (features['Age'] <= 18), 'Age'] = 1\nfeatures.loc[(features['Age'] > 18) & (features['Age'] <= 22), 'Age'] = 2\nfeatures.loc[(features['Age'] > 22) & (features['Age'] <= 27), 'Age'] = 3\nfeatures.loc[(features['Age'] > 27) & (features['Age'] <= 33), 'Age'] = 4\nfeatures.loc[(features['Age'] > 33) & (features['Age'] <= 40), 'Age'] = 5\nfeatures.loc[(features['Age'] > 40) & (features['Age'] <= 66), 'Age'] = 6\nfeatures.loc[ features['Age'] > 66, 'Age'] = 7\nfeatures['Age'] = features['Age'].astype(int)","b47efaed":"train_dependent.head()","6d3dd4e8":"features['Age_Class']= features['Age'] * features['Pclass']\nfeatures['Fare_Class']= features['Fare'] * features['Pclass']\nfeatures = features.drop(['Ticket'], axis=1)\nfeatures.columns","921eeb7c":"# def ticket_clean():\n\n#     global combined\n\n#     # A function that extracts each prefix of the ticket, returns 'Unknown' if no prefix (i.e the ticket is a digit)\n#     def cleanTicket(ticket):\n#         ticket = ticket.replace('.', '')\n#         ticket = ticket.replace('\/', '')\n#         ticket = ticket.split()\n#         ticket = map(lambda t: t.strip(), ticket)\n#         ticket = list(filter(lambda t: not t.isdigit(), ticket))\n#         if len(ticket) > 0:\n#             return ticket[0]\n#         else:\n#             return 'Unknown'\n\n#     # Extracting dummy variables from tickets:\n\n#     features['Ticket'] = features['Ticket'].map(cleanTicket)\n#     tickets_dummies = pd.get_dummies(features['Ticket'], prefix='Ticket')\n#     features = pd.concat([features, tickets_dummies], axis=1)\n#     features.drop('Ticket', inplace=True, axis=1)\n\n#     status('Ticket')\n#     return features\n\n# features = ticket_clean()","c103cbef":"# numerical variables\nskew_features = features[numerical_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features","ea3abe81":"# Normalize skewed features with boxcox transformation\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))","65a036ec":"#defining numerical features again to include the added features for the correlation plot to be plotted.\nnumerical_cols= []\nfor column in train_features.columns:\n    if train_features[column].dtype in ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']:\n        numerical_cols.append(column)\n\nnew_train_set = pd.concat([features.iloc[:len(train_dependent), :], train_dependent], axis=1)","5d86dd92":"def correlation_map(f_data, f_feature, f_number):\n    f_most_correlated = f_data.corr().nlargest(f_number,f_feature)[f_feature].index\n    f_correlation = f_data[f_most_correlated].corr()\n    \n    f_mask = np.zeros_like(f_correlation)\n    f_mask[np.triu_indices_from(f_mask)] = True\n    with sns.axes_style(\"white\"):\n        f_fig, f_ax = plt.subplots(figsize=(12, 10))\n        f_ax = sns.heatmap(f_correlation, mask=f_mask, vmin=0, vmax=1, square=True,\n                           annot=True, annot_kws={\"size\": 10}, cmap=\"BuPu\")\n\n    plt.show()\n\ncorrelation_map(new_train_set, 'Survived', 20)","e29938a9":"features = pd.get_dummies(features).reset_index(drop=True)\nfeatures.shape","b59edefe":"features_to_be_dropped = []\nfor feature in features.columns:\n    all_value_counts = features[feature].value_counts()\n    zero_value_counts = all_value_counts.iloc[0]\n    if zero_value_counts \/ len(features) > 0.995:\n        features_to_be_dropped.append(feature)\nprint('\\nFeatures with predominant zeroes:\\n')\nprint(features_to_be_dropped)\n\nfeatures = features.drop(features_to_be_dropped, axis=1).copy()\nfeatures.shape","db8af9d4":"x_train = features.iloc[:len(train_dependent), :]\nx_test = features.iloc[len(train_dependent):, :]\ny_train = train_dependent\ntrain_set = pd.concat([x_train, y_train], axis=1)","ba6a05a2":"print('train features:', x_train.shape)\nprint('train target:', y_train.shape)\nprint('test features:', x_test.shape)\nprint('train set:', train_set.shape)","4a0dbb66":"xg = xgb.XGBClassifier(\n    n_estimators=2800,\n    min_child_weight=0.1,\n    learning_rate=0.002,\n    max_depth=2,\n    subsample=0.47,\n    colsample_bytree=0.35,\n    gamma=0.4,\n    reg_lambda=0.4,\n    random_state=42,\n    n_jobs=-1,\n)\n\nxg.fit(x_train, y_train, eval_metric='auc')\ny_pred = xg.predict(x_test)","270be8cf":"y_pred.shape","0a27d18c":"new_id = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsubmission_id = list(new_id['PassengerId'])","6914d39d":"predicted_survived = list(y_pred)\n\nnew_id = test.iloc[:, 0]\nfile = pd.DataFrame({'PassengerId':submission_id, 'Survived': predicted_survived})\nsubmission = file.set_index('PassengerId')\nsubmission.to_csv('sub.csv')\n","6c3c4342":"## Skewness","2aed170e":"### Categorical columns","605f38ee":"### creating Age groups","f8116ff4":"### Numerical columns","eb3f97fd":"#### Transforming 'Name' column","66c57cca":"### Numerical and categorical columns","3fdb22d7":"## Encoding categorical variables","f485dabf":"Good enough","d702564f":"### Feature Generation","29b65b58":"### Dropping columns with 0 predominant values","9cf33718":"## Fitting & Predicting ~ XGBoostClassifier","e3057614":"## Submission File","1538c2d5":"## Reconstructing train and test sets","e5e83f39":"## Multicolinearity","83557bc6":"## Null Values","5bb74989":"No columns was dropped."}}