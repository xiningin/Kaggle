{"cell_type":{"841c99a7":"code","275672a6":"code","eb243046":"code","d08be630":"code","feb1098d":"code","4a4baa1c":"code","527c5d31":"code","9d0a08ae":"code","09e26132":"code","53d112b1":"code","8ec23965":"code","1f3bdf14":"code","97971b0b":"code","86edb5e9":"code","d7f396d6":"code","90ce3dd3":"code","f5f29224":"code","137e1c7f":"code","68e0ef80":"code","b5715283":"code","9ce3664b":"code","bc3ac275":"code","bec1a883":"code","0d1658aa":"code","552e3fda":"code","d1bfdd99":"code","38a08607":"code","e6a27e26":"code","dce036cd":"code","5b9681ae":"code","5204b58e":"code","667bc6f0":"code","81cbcdcc":"code","53993df5":"code","ec897ec0":"code","b1a03c80":"code","4f2b3acb":"code","19c9ad49":"code","9689ab54":"code","2aa1d64b":"code","0ed83ca5":"code","3c069b91":"code","a4955c4a":"code","3d199f25":"code","227d8375":"code","48eee8ea":"code","ccb6686f":"code","34ccd93a":"code","35f2b865":"code","76c13076":"code","34da8d9a":"code","ff862713":"code","850de3d5":"code","cf67add6":"code","daaf917d":"code","87ee2ef2":"code","b0a671b3":"code","7c2ca0aa":"code","c924fd82":"code","84a2c26e":"code","64f5e0b6":"code","cec17f24":"code","981e2c40":"code","c170bb7d":"code","d31496b4":"code","53c9645e":"code","91cec1e5":"code","964ce913":"code","cdfae886":"code","6ac597f4":"code","1bee6166":"code","2cf62ac6":"code","77f3c27c":"code","128c4c78":"code","9be994e2":"code","164c4b95":"code","d21c36d9":"code","b9af379b":"code","97687ad4":"code","a0d8c800":"code","03358d6c":"code","6d94ec9f":"code","aa697bb1":"code","3aa9ee5d":"code","ae5f19db":"code","c8b39ca8":"code","e10c998d":"code","0ff06f3d":"code","e7826700":"code","21df4c5e":"code","73dcac55":"code","9fb6ff0e":"code","f984cfe6":"code","1fac3336":"code","96530750":"code","5a00b719":"code","904b0d2a":"code","ec2d933a":"code","166d5cc1":"code","da68d105":"code","cb287a55":"code","cbd5d2ec":"code","172d27f6":"code","8144473a":"code","31440220":"code","fee3d928":"code","ac9f47bc":"code","19227ddb":"code","34820fe9":"code","6592e378":"code","1e82efb5":"code","777d3bb6":"code","59c3b3e6":"code","c1289aac":"code","f66f460e":"code","d9cb12e8":"code","e36b4f3c":"code","76aa53b1":"code","20568a37":"code","b66206af":"code","e264682d":"code","b1576a71":"code","7d09e516":"code","d58e39c3":"code","66ef0be8":"code","4caf9132":"code","6784fe92":"code","b8335186":"code","9170fef7":"code","6807651c":"code","4f8ba3aa":"code","b2ff0ba8":"code","74eb82b2":"code","0803982b":"code","4e64f8fa":"code","1e944346":"code","5c2c1db3":"code","cf6d7cb3":"markdown","79104755":"markdown","52d14308":"markdown","9dba3d96":"markdown","66e910af":"markdown","555b266d":"markdown","dfbc9246":"markdown","9b214b14":"markdown","562c5c65":"markdown","fefc5ae9":"markdown","f9938121":"markdown","d59c95de":"markdown","2b359314":"markdown","301d5b25":"markdown","5e956178":"markdown","31ec3fcc":"markdown","08e27338":"markdown","2bfa2549":"markdown","b47910e2":"markdown","17fe6010":"markdown","492fb4a9":"markdown","f24c6b73":"markdown","70416e94":"markdown","29041e60":"markdown","7d230ca5":"markdown","ae5fa3d0":"markdown","37f6fcec":"markdown","38352f05":"markdown","719a8946":"markdown","c2c7bdd5":"markdown","20869181":"markdown","da39f34f":"markdown","5c327476":"markdown","5c394145":"markdown","8eabc0bd":"markdown","9fc92c06":"markdown","b471a2c1":"markdown","8af516bc":"markdown","a34444c9":"markdown","503204ee":"markdown","89510efb":"markdown","15aff078":"markdown","50bf349f":"markdown","a7774e0b":"markdown","c2b35aef":"markdown","df68f120":"markdown","1d3e6277":"markdown","a33c0cfe":"markdown","515c0e28":"markdown","4fdd80d8":"markdown","77e94f02":"markdown","55126e41":"markdown","760bfd3e":"markdown","61ddc91a":"markdown","ed92c018":"markdown","685682c6":"markdown","99adee63":"markdown","eb44fde5":"markdown","106386b3":"markdown","ad222d93":"markdown"},"source":{"841c99a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n#import necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","275672a6":"#import the data\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","eb243046":"import missingno as msno\nmsno.matrix(train)","d08be630":"msno.bar(train)","feb1098d":"#Delete 'Cabin' column as it has a a lot of missing values\ndel train['Cabin']\ndel test['Cabin']","4a4baa1c":"#analysis of the missing persons\ntrain[(train['Age'].isnull()) & train['Survived'] == 1]\nprint(f\"Persons with Missing Age that survived {len(train[(train['Age'].isnull()) & train['Survived'] == 1])}\")\n\n\ntrain[(train['Age'].isnull()) & train['Survived'] == 0]\nprint(f\"Persons with Missing Age that didn\\'t survived {len(train[(train['Age'].isnull()) & (train['Survived'] == 0)])}\")","527c5d31":"train['Embarked'].value_counts()","9d0a08ae":"#repalce the missing values 'Embarked' column with the highest occuring frequency.\ntrain['Embarked'] = train['Embarked'].fillna('S') \ntest['Embarked'] = test['Embarked'].fillna('S') ","09e26132":" train.describe().T","53d112b1":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (9,9))\nsns.countplot(x=\"Survived\", data=train)\n#annotatinos\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")","8ec23965":"fig = px.pie(train,values=\"Survived\",names=\"Sex\",template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Sex composition of Survive Passengers',\n           layout_showlegend=False)","1f3bdf14":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Pclass\", data=train,ax = ax[0])\nsns.countplot(x=\"Pclass\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","97971b0b":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.countplot(x=\"Pclass\",hue = 'Sex',data=train)\nfig.suptitle('Composition of passenger classs', fontsize =15)\n#annotations\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","86edb5e9":"ax = sns.catplot(x ='Pclass', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs Ticket class ')","d7f396d6":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Pclass\",hue = 'Survived',data=train[train['Sex'] == 'male'],ax = ax[0])\nsns.countplot(x=\"Pclass\",hue = 'Survived', data=train[train['Sex'] == 'female'],ax = ax[1])\nax[0].set_title('Male')\nax[1].set_title('Female')\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")\nfig.suptitle('Sex Composition of passenger classs', fontsize =15)   ","90ce3dd3":"fig,ax = plt.subplots(figsize = (15,6))\nax = sns.boxplot(y=\"Pclass\", x=\"Age\",orient=\"h\", data=train)\nfig.suptitle('Age distribution of passenger classs', fontsize=15)","f5f29224":"fig = px.pie(train,\n             values=\"Fare\",\n             names=\"Pclass\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Percentage of Fare collected through Pclass',\n           layout_showlegend=False)\nfig.show()","137e1c7f":"print('Total Passengers by Pclass')\nprint(train['Pclass'].value_counts())","68e0ef80":"print('Total Survived Passengers by Pclass')\nprint(train[train['Survived'] == 1]['Pclass'].value_counts())","b5715283":"print('Percentage of  Survived Passengers by Pclass')\ntrain[train['Survived'] == 1]['Pclass'].value_counts() \/ train['Pclass'].value_counts()","9ce3664b":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Sex\", data=train,ax = ax[0])\nsns.countplot(x=\"Sex\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 3,height ,ha=\"center\")","bc3ac275":"fig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train)\nfig.suptitle('Distribution of passenger\\'s age', fontsize=15)","bec1a883":"print('Passengers composition by Sex')\ntrain['Sex'].value_counts()","0d1658aa":"print('Survived Passengers composition by Sex')\ntrain[train['Survived'] == 1]['Sex'].value_counts()","552e3fda":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x=train['Age'],color = '#6edb00')","d1bfdd99":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True ,data=train,ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train,ax = ax[1])","38a08607":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x = train[train['Age'] <=18.0]['Age'],color = '#d9003d')\nfig.suptitle('Age distribution of minors', fontsize=15)","e6a27e26":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['Age'] <=18.0],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['Age'] <=18.0],ax = ax[1])\nfig.suptitle('Age distribution of minors', fontsize=15)","dce036cd":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Age'] <=18.0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Age'] <=18.0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Survival percenatge of minors', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","5b9681ae":"print('Total minors Sex-wise')\ntrain[train['Age'] <=18.0]['Sex'].value_counts()","5204b58e":"#extract the initial title of the name\ntrain['Name_initial'] = train['Name'].apply(lambda x : x.split(',')[1].split('.')[0])","667bc6f0":"fig,ax = plt.subplots(figsize = (15,6))\nax = sns.countplot(x = 'Name_initial',data = train)\n#annotations\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,height ,ha=\"center\")\nfig.suptitle('Count of Initial name of Passengers', fontsize=15)","81cbcdcc":"fig,ax = plt.subplots(figsize = (9,9))\nax = plt.pie(x=train['Name_initial'].value_counts().head(6), autopct=\"%.1f%%\", labels = train['Name_initial'].value_counts().head(6).index,pctdistance=0.5)\nfig.suptitle('Compositon of the top 6 occuring initial name', fontsize=15)","53993df5":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"SibSp\", data=train,ax = ax[0])\nsns.countplot(x=\"SibSp\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor p in ax[0].patches:\n    height = p.get_height()\n    ax[0].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")","ec897ec0":"ax = sns.catplot(x ='SibSp', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs sibling \/ spouce abord ')","b1a03c80":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['SibSp'] >= 1],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['SibSp'] >= 1],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with one or more siblings \/ spouce', fontsize=15)","4f2b3acb":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] >= 1],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] >= 1],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least one siblings \/ spouce', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","19c9ad49":"print('Gender distribution of Passengers who travelled with one or more siblings\/spouce')\ntrain[(train['SibSp'] >= 1)]['Sex'].value_counts()","9689ab54":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['SibSp'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['SibSp'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with no siblings \/ spouce', fontsize=15)","2aa1d64b":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] == 0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['SibSp'] == 0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least no siblings \/ spouce', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","0ed83ca5":"print('Gender distribution of Passengers who travelled with no siblings')\ntrain[(train['SibSp'] == 0)]['Sex'].value_counts()","3c069b91":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nax[0] = sns.countplot(x=\"Parch\", data=train,ax = ax[0])\nax[1] = sns.countplot(x=\"Parch\",hue = 'Survived', data=train,ax = ax[1])\n#annotatinos\nfor i in np.arange(1):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","a4955c4a":"ax = sns.catplot(x ='Parch', y ='Survived',hue = 'Sex',kind = 'point' ,data = train,height = 6)\nax.fig.suptitle('Survival Rate vs Parent \/ child abord ')","3d199f25":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True, hue = 'Survived',data=train[train['Parch'] >= 1],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True, hue = 'Sex',data=train[train['Parch'] >= 1],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with one or more siblings \/ spouce', fontsize=15)","227d8375":"print('Age description of passengers who travelled with one or more parents \/ children')\ntrain[train['Parch'] >= 1]['Age'].describe()","48eee8ea":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Parch'] >= 1],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Parch'] >= 1],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least one parents \/ children', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","ccb6686f":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['Parch'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['Parch'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled with no parent \/ child', fontsize=15)","34ccd93a":"print('Age description of passengers who travelled with no parent \/ child')\ntrain[train['Parch'] == 0]['Age'].describe()","35f2b865":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[train['Parch'] == 0],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[train['Parch'] == 0],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled with at least no parent \/ child', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","76c13076":"fig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.histplot(x=\"Age\",kde = True,hue = 'Survived',data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[0])\nsns.histplot(x=\"Age\",kde = True,hue = 'Sex',data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[1])\nfig.suptitle('Age distribution of Passengers who travelled without family', fontsize=15)","34da8d9a":"print('Age description of passengers who travelled without family')\ntrain[(train['Parch'] == 0) & (train['SibSp'] == 0)]['Age'].describe()","ff862713":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nsns.countplot(x=\"Survived\", data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],ax = ax[0])\nsns.countplot(x=\"Survived\", data=train[(train['Parch'] == 0) & (train['SibSp'] == 0)],hue = 'Sex',ax = ax[1])\nfig.suptitle('Passengers who travelled without family', fontsize=15)\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")","850de3d5":"fig,ax = plt.subplots(figsize = (9,3))\nax = sns.boxplot(x=train['Fare'],color = '#ff7a70')","cf67add6":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True, data=train,ax = ax[0])\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data=train,ax = ax[1])","daaf917d":"for i in np.arange(1,4):\n    fig,ax = plt.subplots(figsize = (15,6))\n    sns.histplot(x=\"Fare\",hue = 'Survived',kde = True,data = train[train['Pclass'] == i])\n    fig.suptitle(f'Distribution of {i} class Fare', fontsize=15)\n","87ee2ef2":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data = train[train['Fare'] >= 100 ])\nfig.suptitle('Passengers whose Fare is more than \u00a3 100', fontsize=15)","b0a671b3":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1,2,figsize = (15,6))\nax[0] = sns.countplot(x=\"Survived\", data = train[train['Fare'] >= 100 ],ax = ax[0])\nax[1] = sns.countplot(x=\"Survived\", data = train[train['Fare'] >= 100 ],hue = 'Sex',ax = ax[1])\n#annotatinos\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + .3,height ,ha=\"center\")\n        \nfig.suptitle('Survival of Passengers whose Fare is more than \u00a3 100', fontsize=15) ","7c2ca0aa":"print('Survived passengers whose ticket costs more than \u00a3 100')\ntrain[train['Fare'] >= 100 ]['Survived'].value_counts()","c924fd82":"print('Sex composition survived passengers whose ticket costs more than \u00a3 100')\ntrain[(train['Fare'] >= 100) & train['Survived'] == 1]['Sex'].value_counts()","84a2c26e":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(figsize = (15,6))\nsns.histplot(x=\"Fare\",bins=30,kde = True,hue = 'Survived', data = train[train['Fare'] <= 50 ])\nfig.suptitle('Passengers whose Fare is less than \u00a3 50', fontsize=15)","64f5e0b6":"fig,ax = plt.subplots(figsize = (9,6))\nax = sns.countplot(x=\"Survived\", data = train[train['Fare'] <= 50 ])\n#annotatinos\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\nfig.suptitle('Survival of Passengers whose Fare is less than \u00a3 50', fontsize=15)    ","cec17f24":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Embarked\",data=train,ax = ax[0])\nsns.countplot(x=\"Embarked\",hue = 'Survived', data=train,ax = ax[1])\n#annnotations\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\n#add title\nfig.suptitle('Passengers count', fontsize=15)","981e2c40":"fig = px.pie(train,\n             values=\"Fare\",\n             names=\"Embarked\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.update(layout_title_text='Percentage of Fare collected through Embarked',\n           layout_showlegend=False)\nfig.show()\n","c170bb7d":"sns.set_theme(style=\"darkgrid\")\nfig,ax = plt.subplots(1, 2,figsize = (15,6))\nsns.countplot(x=\"Embarked\",hue = 'Pclass',data=train,ax = ax[0])\nsns.countplot(x=\"Embarked\",hue = 'Sex', data=train,ax = ax[1])\n#annnotations\nfor i in np.arange(2):\n    for p in ax[i].patches:\n        height = p.get_height()\n        ax[i].text(p.get_x()+p.get_width()\/2., height + 1,height ,ha=\"center\")\n#add title\nfig.suptitle('Ticket Class and Sex composition', fontsize=15)","d31496b4":"train.skew()","53c9645e":"train.kurt()","91cec1e5":"for i in train.columns[1:]:\n    if train[i].dtype != 'object':\n        print(i)\n        print('IQR: ',train[i].quantile(.75) - train[i].quantile(.25))\n        print('')\n","964ce913":"train.corr()","cdfae886":"plt.figure(figsize=(9,9))\nsns.heatmap(train.drop('PassengerId',axis = 1).corr(), vmax=1, square=True,annot=True,cmap='RdBu')\nplt.title('Correlation between different attributes')\nplt.show()","6ac597f4":"sns.pairplot(train.drop('PassengerId',axis = 1), hue=\"Survived\")","1bee6166":"#grab the ids of the passenger's id of the test data\nids = test['PassengerId']","2cf62ac6":"train = train.drop(['PassengerId','Name','Ticket','Name_initial'],axis = 1)\ntest = test.drop(['PassengerId','Name','Ticket'],axis = 1)\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)","77f3c27c":"train.head(3)","128c4c78":"test.head(3)","9be994e2":"from sklearn.model_selection import train_test_split","164c4b95":"# separate intro train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop('Survived', axis=1),  # just the features\n    train['Survived'],  # the target\n    test_size=0.3,  # the percentage of obs in the test set\n    random_state=0)  # for reproducibility\n\nX_train.shape, X_test.shape","d21c36d9":"#impute the misssing values with median\nX_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())\nX_test['Age'] = X_test['Age'].fillna(X_train['Age'].median())","b9af379b":"#impute the misssing values with median in the test\ntest['Age'] = test['Age'].fillna(X_train['Age'].median())\ntest['Fare'] = test['Fare'].fillna(X_train['Fare'].median())","97687ad4":"print('Check the missing values of test')\ntest.isnull().sum()","a0d8c800":"#scale the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_std = scaler.transform(X_train)\nX_test_std = scaler.transform(X_test)","03358d6c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics","6d94ec9f":"logisticRegr = LogisticRegression(penalty='l1', solver='liblinear')\n#fit the model\nlogisticRegr.fit(X_train_std, y_train)","aa697bb1":"#predictions and score\npredictions = logisticRegr.predict(X_test_std)\nprint(f\"The score on the Test-dataset is {logisticRegr.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticRegr.score(X_train_std, y_train)}\")","3aa9ee5d":"def plot_condution_metrics(y_test,predictions):\n    #condusion metrics\n    cm = metrics.confusion_matrix(y_test, predictions)\n    score = np.mean([y_test == predictions])\n    #plot\n    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=1, square = True,cbar = False);\n    plt.ylabel('Actual label');\n    plt.xlabel('Predicted label');\n    all_sample_title = 'Accuracy Score: {0}'.format(score)\n    plt.title(all_sample_title, size = 15);","ae5f19db":"#confusion metrics\nplot_condution_metrics(y_test,predictions)","c8b39ca8":"#cross-val score\nscore = cross_val_score(logisticRegr, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","e10c998d":"#store the cv-score\nmodel_performance = {}\nmodel_performance['Logistic Regression(Lasso)'] = score.mean()","0ff06f3d":"logisticRegr = LogisticRegression(penalty='l2', solver='liblinear')\n#fit the model\nlogisticRegr.fit(X_train_std, y_train)","e7826700":"#predictions and score\npredictions = logisticRegr.predict(X_test_std)\nprint(f\"The score on the Test-dataset is {logisticRegr.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticRegr.score(X_train_std, y_train)}\")","21df4c5e":"plot_condution_metrics(y_test,predictions)","73dcac55":"#cross-val score\nscore = cross_val_score(logisticRegr, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","9fb6ff0e":"model_performance['Logistic Regression(Ridge)'] = score.mean()","f984cfe6":"from sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\n\n#trasform into polynomial features\nX_train_p = poly.fit_transform(X_train)\nX_test_p = poly.fit_transform(X_test)\n\n#standard scale\nscaler = StandardScaler()\nscaler.fit(X_train_p)\nX_train_std = scaler.transform(X_train_p)\nX_test_std = scaler.transform(X_test_p)","1fac3336":"#fit the model\nlogisticPolyRegr = LogisticRegression(solver='liblinear')\nlogisticPolyRegr.fit(X_train_std, y_train)\n\n#predictions and score\npredictions = logisticPolyRegr.predict(X_test_std)\nprint(f\"The score on the Test-dataset is {logisticPolyRegr.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {logisticPolyRegr.score(X_train_std, y_train)}\")","96530750":"plot_condution_metrics(y_test,predictions)","5a00b719":"#cross-val score\nscore = cross_val_score(logisticPolyRegr, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","904b0d2a":"model_performance['Polynomial Logistic Regression'] = score.mean()","ec2d933a":"poly_degrees = [2,3,4,5,6]\ndegree_loop_values = []\nfor degree in poly_degrees:\n    poly = PolynomialFeatures(degree = degree)\n\n    #trasform into polynomial features\n    X_train_p = poly.fit_transform(X_train)\n    X_test_p = poly.fit_transform(X_test)\n\n    #standard scale\n    scaler = StandardScaler()\n    scaler.fit(X_train_p)\n    X_train_std = scaler.transform(X_train_p)\n    X_test_std = scaler.transform(X_test_p)\n    \n    logisticPolyRegr = LogisticRegression(solver='liblinear')\n    logisticPolyRegr.fit(X_train_std, y_train)\n\n    score = cross_val_score(logisticPolyRegr, X_train_std, y_train, cv=10,scoring='accuracy')\n    degree_loop_values.append([degree,score.mean(),np.std(score)])","166d5cc1":"pd.DataFrame(degree_loop_values,columns = ['Degree','Mean_cv','Std_cv'],)","da68d105":"# separate intro train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop('Survived', axis=1),  # just the features\n    train['Survived'],  # the target\n    test_size=0.3,  # the percentage of obs in the test set\n    random_state=0)  # for reproducibility\n\nX_train.shape, X_test.shape","cb287a55":"#impute the misssing values with median\nX_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())\nX_test['Age'] = X_test['Age'].fillna(X_train['Age'].median())\n#scale the data\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_std = scaler.transform(X_train)\nX_test_std = scaler.transform(X_test)","cbd5d2ec":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\ngnb = GaussianNB()\npredictions = gnb.fit(X_train, y_train).predict(X_test)","172d27f6":"print(f\"The score on the Test-dataset is {gnb.score(X_test, y_test)}\")\nprint(f\"The score on the Train-dataset is {gnb.score(X_train, y_train)}\")","8144473a":"plot_condution_metrics(y_test,predictions)","31440220":"#cross-val score\nscore = cross_val_score(gnb, X_train, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","fee3d928":"model_performance['Naive Bayes (gausian)'] = score.mean()","ac9f47bc":"from sklearn.svm import SVC","19227ddb":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n    {\n        \"C\" : [0.3,1,10,25,100],\n        \"gamma\" : ['scale', 10,1, 0.1,0.01, 0.001,0.0001],\n        \"kernel\" : ['rbf',]\n        \n    },\n]\noptimat_parameters = GridSearchCV(\n    SVC(),\n    param_grid,\n    cv = 9,\n    scoring = 'accuracy',\n    verbose = 0\n)\noptimat_parameters.fit(X_train_std,y_train)\nprint(optimat_parameters.best_params_)","34820fe9":"from sklearn import svm\nclf_svm = svm.SVC(C =  1, gamma = 'scale',kernel = 'rbf',random_state = 42)\npredictions = clf_svm.fit(X_train_std, y_train).predict(X_test_std)","6592e378":"print(f\"The score on the Test-dataset is {clf_svm.score(X_test_std, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_svm.score(X_train_std, y_train)}\")","1e82efb5":"plot_condution_metrics(y_test,predictions)","777d3bb6":"#cross-val score\nscore = cross_val_score(clf_svm, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","59c3b3e6":"model_performance['SVM (rbf)'] = score.mean()","c1289aac":"from sklearn.tree import DecisionTreeClassifier,plot_tree\n\nclf_dt = DecisionTreeClassifier(random_state=42)","f66f460e":"# separate intro train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop('Survived', axis=1),  # just the features\n    train['Survived'],  # the target\n    test_size=0.3,  # the percentage of obs in the test set\n    random_state=0)  # for reproducibility\n\nX_train.shape, X_test.shape\n\n#impute the misssing values with median\nX_train['Age'] = X_train['Age'].fillna(X_train['Age'].median())\nX_test['Age'] = X_test['Age'].fillna(X_train['Age'].median())","d9cb12e8":"#build a preliminary tree\npredictions = clf_dt.fit(X_train, y_train).predict(X_test)","e36b4f3c":"fig,ax = plt.subplots(figsize = (25,12))\nax = plot_tree(\n    clf_dt,\n    filled = True,\n    rounded = True,\n    class_names = ['Not Survived',\"Survived\"],\n    feature_names = train.drop('Survived', axis=1).columns\n    \n)","76aa53b1":"print(f\"The score on the Test-dataset is {clf_dt.score(X_test, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_dt.score(X_train, y_train)}\")","20568a37":"plot_condution_metrics(y_test,predictions)","b66206af":"#cross-val score\nscore = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","e264682d":"path = clf_dt.cost_complexity_pruning_path(X_train,y_train)\nccp_alphas = path.ccp_alphas\nccp_alphas = ccp_alphas[:-1]\n\ncct_dts = []\n\nfor ccp_alpha in ccp_alphas:\n    clf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = ccp_alpha)\n    clf_dt.fit(X_train,y_train)\n    cct_dts.append(clf_dt)\n    \n","b1576a71":"train_scores = [clf.score(X_train, y_train) for clf in cct_dts]\ntest_scores = [clf.score(X_test, y_test) for clf in cct_dts]\n\nfig, ax = plt.subplots(figsize = (12,9))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","7d09e516":"#looking at the figure and 'eye-balling' we see the alpha of 0.00375 could be a bette value\n# using K-fold CV\nclf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = 0.00375)\nscores = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\n#plot \ndf_cv = pd.DataFrame(data = {'tree' : range(9),'accuracy':scores})\ndf_cv.plot(x = 'tree',y = 'accuracy',marker = 'o',linestyle = '--')","d58e39c3":"alpha_loop_values = []\n\nfor ccp_alpha in ccp_alphas:\n    clf_dt = DecisionTreeClassifier(random_state=42,ccp_alpha = ccp_alpha)\n    scores = cross_val_score(clf_dt, X_train, y_train, cv=9,scoring='accuracy')\n    alpha_loop_values.append([ccp_alpha,np.mean(scores),np.std(scores)])\n    \n#storing in a pandas datframe\nalpha_df = pd.DataFrame(alpha_loop_values,columns = ['alpha','mean_Score','std_score'])\n\n#plot df\nalpha_df.plot(x = 'alpha',y = 'mean_Score',marker = 'o',linestyle = '--')","66ef0be8":"print('alpha values with cv score > .8')\nalpha_df[alpha_df['mean_Score'] > .8 ]","4caf9132":"ideal_alpha = 0.002961","6784fe92":"clf_dt_prune = DecisionTreeClassifier(random_state=42,ccp_alpha = ideal_alpha)\npredictions = clf_dt_prune.fit(X_train, y_train).predict(X_test)","b8335186":"fig,ax = plt.subplots(figsize = (25,9))\nax = plot_tree(\n    clf_dt_prune,\n    filled = True,\n    rounded = True,\n    class_names = ['Not Survived',\"Survived\"],\n    feature_names = train.drop('Survived', axis=1).columns\n    \n)","9170fef7":"print(f\"The score on the Test-dataset is {clf_dt_prune.score(X_test, y_test)}\")\nprint(f\"The score on the Train-dataset is {clf_dt_prune.score(X_train, y_train)}\")","6807651c":"plot_condution_metrics(y_test,predictions)","4f8ba3aa":"#cross-val score\nscore = cross_val_score(clf_dt_prune, X_train_std, y_train, cv=9,scoring='accuracy')\nprint(f'The Cross-Valiation Score is {score.mean()}')","b2ff0ba8":"model_performance['Decison Tree'] = score.mean()","74eb82b2":"model_performance","0803982b":"model_df = pd.DataFrame.from_dict(model_performance,orient = 'index',columns = ['Mean CV Score'])\nmodel_df = model_df.sort_values(by ='Mean CV Score',ascending = False)\nmodel_df","4e64f8fa":"gig,ax = plt.subplots(figsize = (12,6))\nsns.barplot(x=\"Mean CV Score\", y=model_df.index, data=model_df,color = '#fc8a26')","1e944346":"#scale the test data\ntest_std = scaler.transform(test)\npredictions = clf_svm.predict(test_std)","5c2c1db3":"output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","cf6d7cb3":"### Explanatory Data Analysis","79104755":"##### Passengers travelling with no parent  \/ child.","52d14308":"##### Fare Vs Passengers class","9dba3d96":"#### Column: Fare\n<br>","66e910af":"#### Column : SibSp (Number of Siblings \/ Spouses Aboard)\n<br>","555b266d":"#### <li>About 55.1 % (491) of the total passengers (891) booked 3rd class ticket.\n#### <li>About 62.96 % (136) of the total 1st classs passengers (184) survived.\n#### <li>Only 24.23% (119) of the total 3rd classs passengers (491) survived.  ","dfbc9246":"#### Cost-complxity prunnig the decison tree","9b214b14":"#### Let's See the Correlation among these attributes","562c5c65":"##### Passengers travelling with one or more siblings \/ spouce.","fefc5ae9":"#### <li>About 34.36% (109) of the total passengers (678) survived who travelled with one or more parent \/ child. \n#### <li>About 48.72% (153) of the total female-passengers (314) survived travelled with one or more parent \/ child. \n ","f9938121":"#### Column : Sex\n<br>","d59c95de":"#### Column : Survived\n","2b359314":"#### Builing the optimam SVM model","301d5b25":"##### Analysis of passengers whose fare is more than \u00a3 100","5e956178":"#### <li>About 74.2 % (233) of the total Female passengers (314) survived.\n#### <li>About 18.89 % (109) of the total Male passengers (577) survived.","31ec3fcc":"#### <li>Only about 38.38 % (342) of the total passengers (891) survived.","08e27338":"#### As we can see the Support Vector Machine with the 'rbf' kernel gives the best result","2bfa2549":"#### IQR (Inter Quartile Range)","b47910e2":"##### Analysis of passengers whose fare is less than \u00a3 50","17fe6010":"#### <li>About 82.04% (731) of the total passenger's (891) fare was less than \u00a3 50. \n#### <li>Only 31.87% (233) of those survived (731) survived.","492fb4a9":"#### <li>About 60.26% (537) of the passengers (891) travelled without family.\n#### <li>About 84.42% (347) of the male passengers (411) who travelled without family couldn\\'t survive","f24c6b73":"#### <li>About 96.68 % (91) of the female 1st classs passengers (94) survived.\n#### <li>Only 13.54% (47) of the male 3rd classs passengers (347) survive","70416e94":"#### Cross-validation and Hypeer-parameter tuning","29041e60":"The best-fit polynomial degree is 2","7d230ca5":"#### One-hot encoding","ae5fa3d0":"#### Column : Embarked (C = Cherbourg; Q = Queenstown; S = Southampton)\n<br>","37f6fcec":"#### Grid-Search CV to find the optimum parameters","38352f05":"#### Column : Age\n<br>","719a8946":"#### <li>About 5.94% (53) of the total passenger's (891) fare was more than \u00a3 100. \n#### <li>About 73.58% (39) of those passengers (53) survived. \n#### <li>About 82.05% (32) of those survived (39) were females.","c2c7bdd5":"#### <li>About 46.64% (132) of the total passengers (283) survived who travelled with one or more siblings \/ spouce. \n#### <li>About 44.58% (140) of the total female-passengers (314) travelled with one or more siblings \/ spouce. \n#### <li>About 68.57% (96) of the total female-passengers (140) survived who travelled with one or more siblings \/ spouce.\n#### <li>Only 25.17% (36) of the total male-passengers (143) survived who travelled with one or more siblings \/ spouce. ","20869181":"#### Polynomial Logistic Regression","da39f34f":"##### Passengers travelling without family (without parnent \/ child or sibling \/ spouce)","5c327476":"#### Check for missing values","5c394145":"#### Building the best tree","8eabc0bd":"#### Impute the missing values","9fc92c06":"Looking at the figure and 'eye-balling' we see the alpha of 0.00375 could be a bette value","b471a2c1":"#### Cross validation to find the optimal value of alpha","8af516bc":"#### Decision Trees","a34444c9":" As we see on one split i returns a very low accuracy of about 73%. So this value of alpha may not be the best\n So we use K-fold CV on all the values of alpha to find the optimum parameter","503204ee":"#### Logistic Regression(Lasso)","89510efb":"#### Column : Parch (Number of Parents\/Children Aboard)\n<br>","15aff078":"#### Analysis of minor-passengers","50bf349f":"#### <li>About 15.60% (139) of the total passengers (891) were minors. \n#### <li>About 50.35% (70) of the minor passengers (139) survived. \n#### <li>About 67.64% (46) of the female-minor passengers (68) survived.","a7774e0b":"#### Kurtosis","c2b35aef":"#### Naive Bayes","df68f120":"##### Passengers travelling with one or more parents \/ children.","1d3e6277":"##### Passengers travelling with no siblings\/spouce","a33c0cfe":"#### Column : Pclass\n<br>","515c0e28":"[link from which this NB was created](https:\/\/www.kaggle.com\/dibkb9\/titanic-disaster)","4fdd80d8":"#### <li>Only 34.53% (210) of passengers (610) survived who travelled with no siblings.\n#### <li>About 55.51% (174) of the total female-passengers (314) survived travelled with no siblings.     \n#### <li>About 78.73% (137) of female-passengers (174) survived who travelled with no siblings.\n#### <li>Only 16.62% (73) of male-passengers (434) survived who travelled with no siblings.    ","77e94f02":"### Data Preprocessing","55126e41":"#### <li>About 51.17% (109) of the total passengers (213) survived who travelled with one or more parents \/ children. \n#### <li>About 38.21% (120) of the total female-passengers (314) survived travelled with one or more parents \/ children. \n#### <li>About 66.66% (80) of the total female-passengers (120) survived who travelled with one or more parents \/ children.\n#### <li>About 38.18% (29) of the total male-passengers (93) survived who travelled with one or more parents \/ children. ","760bfd3e":"#### Logistic Regression(Ridge)","61ddc91a":"#### Visualizing the model performance","ed92c018":"#### <li>About 62.968 % (136) of the 1st classs passengers (216) survived.\n#### <li>Only 24.23% (119) of the 3rd classs passengers (491) survived.","685682c6":"#### Making Submissions\n","99adee63":"### Model Preparation","eb44fde5":"#### Support Vector Machine","106386b3":"#### Skewness","ad222d93":"#### Column : Name\n<br>"}}