{"cell_type":{"7efa6085":"code","0cbf75c6":"code","5d7abe1b":"code","6cdb4d4c":"code","a79a9048":"code","095ffce2":"code","a2887e50":"code","47c5d79f":"code","2a412626":"code","860c16d6":"code","3232a06f":"code","ca446c71":"code","f88834af":"code","c3f93bc8":"code","0eb86413":"code","ba02248f":"code","2814eb7a":"code","3899888c":"code","85fc78f8":"code","c14f92fe":"code","ec86a7e3":"markdown","188ad414":"markdown","5cbcb005":"markdown","a18cda25":"markdown","2a6da992":"markdown","0ecb2d42":"markdown","9cb5bf9e":"markdown","4269967d":"markdown","f331f689":"markdown","81372265":"markdown","eea848d3":"markdown","7c50ccda":"markdown","f6f7fd2a":"markdown","dcc91321":"markdown","bb325150":"markdown","044ba9cb":"markdown","3c65f299":"markdown","500f9649":"markdown","f96b771b":"markdown","ebf09add":"markdown"},"source":{"7efa6085":"conda install -c conda-forge hdbscan","0cbf75c6":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import shapiro     #normality test\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom scipy.spatial import distance\nfrom sklearn.decomposition import PCA\nfrom yellowbrick.regressor import ResidualsPlot \nfrom mpl_toolkits.mplot3d import Axes3D   #plot 3D\nfrom hdbscan import HDBSCAN\nfrom statsmodels.stats.stattools import durbin_watson\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\nfrom sklearn import metrics","5d7abe1b":"# reading dataset \ndata = pd.read_csv('..\/input\/real-estate-price-prediction\/Real estate.csv')\n\nprint(data.info(),\n      '\\n___________duplicated()___________\\n', data.duplicated().any(), \n      '\\n___________isnull()___________\\n', data.isnull().sum()\n      )\ndata.head(3)","6cdb4d4c":"#dropping columns\ncolumns_to_drop = ['X1 transaction date', 'No']\ndata = data.drop(columns_to_drop, axis=1)\ndata.head(3)","a79a9048":"#normality Shapiro-Wilk test function\ndef normality_test(data):\n  stat, p_value = shapiro(data)    #Shapiro-Wilk test\n  alpha = 0.05\n\n  if p_value > alpha:\n    print('Normality test: Gaussian')  #fail in reject H0 (null hypothesis H0: follow normal distribution)\n  else:\n    print('Normality test: Non Gaussian') #reject H0 (alternative hypothesis H1: does not follow normal distribution)\n\n\n#data plot (2D and 3D)\ndef data_scatter(data_, pca, n_dim, ax, color):\n  if(n_dim == 2):\n    plt.scatter(data_[:,0], data_[:,1], color=color)    #plot 2D\n  else:\n    ax.scatter(data_[:,0], data_[:,1], data_[:,2], color=color)  #plot 3D\n    ax.set_zlabel('Dimension 3 (%.f %%)' % (round(pca.explained_variance_ratio_.cumsum()[2], 2)*100)) #third principal component\n  plt.xlabel('Dimension 1 (%.f %%)' % (round(pca.explained_variance_ratio_.cumsum()[0], 2)*100)) #first principal component\n  plt.ylabel('Dimension 2 (%.f %%)' % (round(pca.explained_variance_ratio_.cumsum()[1], 2)*100)) #second principal component","095ffce2":"plt.figure(figsize=(13,5))\n\nfor feat, grd in zip(data, range(231,237)):\n  plt.subplot(grd)\n  sns.boxplot(y=data[feat], color='grey')\n  plt.ylabel('Value')\n  plt.title('Boxplot\\n%s'%feat)\nplt.tight_layout()","a2887e50":"#HDBSCAN clustering\nhdb = HDBSCAN(min_cluster_size=2).fit(data)\nhdb_pred = hdb.labels_\n\n#data color\ncol_cl = ['grey'] * len(hdb_pred)\n\n#defining outlier (index and color)\nindex_outlier = []\nfor i, out in zip(range(len(data)), hdb_pred):\n  if out == -1:               \n    index_outlier.append(i)   #index of data defined as outlier\n    col_cl[i] = 'firebrick'       #outlier defined as black\n\n\n#data visualization \n#PCA: dimension reduction\npca = PCA()\ndata_ = pca.fit_transform(data)\n\n#2D data plot\nax = plt.figure(figsize=(4, 3))\ndata_scatter(data_, pca, 2, ax, col_cl)\n\n#3D data plot\nfig = plt.figure(figsize=(4, 3))\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=20, azim=134)\ndata_scatter(data_, pca, 3, ax, col_cl)","47c5d79f":"#visualizing data (without outliers)\nplt.figure(figsize=(15, 3))\n\n#plot old data\nplt.subplot(131)\nplt.plot(data['Y house price of unit area'], color='grey')\nplt.ylim(top=np.max(data['Y house price of unit area'])+10)\nplt.scatter(index_outlier, data.loc[index_outlier]['Y house price of unit area'], color='firebrick')    #plotting outliers\n\n#defining new data\nnew_data = data.drop(index_outlier)\n\n#plot new data\nplt.subplot(132)\nplt.plot(new_data['Y house price of unit area'], color='grey')\nplt.ylim(top=np.max(data['Y house price of unit area'])+10)\n\n#new house price values boxplot plot\nplt.subplot(133)\nsns.boxplot(y=new_data['Y house price of unit area'], color='grey')\n\nplt.tight_layout()","2a412626":"data = new_data.reset_index()\ndata.describe()","860c16d6":"print('Assumption of normality')\nnormality_test(data)","3232a06f":"#correlation matrix\nmask = np.triu(np.ones_like(data.corr())) \n\nplt.figure(figsize=(15, 7))\n\nplt.subplot(121)\nsns.heatmap(data.corr(method='spearman'), annot=True, linewidths=.9, fmt= '.2f', cmap='Greys', mask=mask) \n\nplt.subplot(122)\nsns.heatmap(data.corr(method='spearman'), annot=True, linewidths=.9, fmt= '.2f', cmap='Greys', mask=mask) \n\nplt.tight_layout()","ca446c71":"sns.pairplot(data, y_vars='Y house price of unit area', palette = sns.set_palette(['#696969']),\n             x_vars=['X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']);","f88834af":"#dropping columns\nX = data.loc[:,'X2 house age' : 'X6 longitude']\ny = data.loc[:,'Y house price of unit area']\n\n#Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg = LinearRegression().fit(X_train, y_train)    #fit train set\nprice_predict = reg.predict(X_test)\n\n#regression coefficients\nindex_reg = ['Intercept', 'X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X4 number of convenience stores', 'X6 longitude']\npd.DataFrame(data=np.append(reg.intercept_, reg.coef_), index=index_reg, columns=['values']).transpose()","c3f93bc8":"#Predictions plot\nplt.figure(figsize=(10,4))\n\ndef plot_regression(real, predicted, color, title):\n  plt.scatter(real, predicted, color=color)\n  plt.plot([real.min(), real.max()], [real.min(), real.max()], 'k--', lw=4)\n  plt.xlabel('Real Price')\n  plt.ylabel('Predicted')\n  plt.title(title)\n\n\n#Real price vs train-test predictions plot (without outliers)\nplt.subplot(131)\nplot_regression(y_test, price_predict, 'cornflowerblue', 'Linear Regression Predictions \\nTrain-test split')\nplt.show()","0eb86413":"#Predictions comparison plot\nplt.figure(figsize=(15,4))\n\nplt.plot(np.array(y_test), color='grey', label='Real')\nplt.plot(price_predict, color='cornflowerblue', label='Train-test split')\nplt.xlabel('House')\nplt.ylabel('Price')\nplt.title('Predictions Comparison (same split)')\nplt.legend(loc=4)\nplt.show()\n\n\n#Predictions distance (in general)\nprint('Euclidean distance between prices')\nprint('- Real vs train-test: %.3f' % distance.euclidean(y_test, price_predict))","ba02248f":"#R2 coefficient, MAE and MSE measures\nprint('Test split evaluation \\n',\n      'Coefficient of determination R2: %.3f \\n' % r2_score(y_test, price_predict),\n      'Mean Absolute Error: %.2f \\n' % (sum(abs(y_test - price_predict)) \/ len(y_test)),    \n      'Mean Square Error: %.2f' % mean_squared_error(y_test, price_predict))\n","2814eb7a":"residuals = y_test - price_predict\n\nprint('Assumption of normality in residuals')\nnormality_test(residuals)","3899888c":"visualizer = ResidualsPlot(LinearRegression(), hist=False, train_color='darksalmon', test_color='darkseagreen')\nvisualizer.fit(X_train, y_train)\nvisualizer.score(X_test, y_test)\nvisualizer.poof(); ","85fc78f8":"stat_ols = sm.OLS(y, X)\nstat_ols = stat_ols.fit()\n\nDurbin_Watson = durbin_watson(stat_ols.resid)\nr = 1 - Durbin_Watson\/2\n\nif round(r) == 0:\n  print('Without auto-correlation')\nelse:\n  print('With auto-correlation')\n\nprint('\\nDurbin_Watson:', Durbin_Watson)","c14f92fe":"X_constant = sm.add_constant(X)\nstat_ols_const = sm.OLS(y,X_constant).fit()\nresids = stat_ols_const.resid\n\ngq_test = sms.het_goldfeldquandt(resids, stat_ols_const.model.exog)[1]\n\nprint('Goldfeld-Quandt test')\nif gq_test < 0.05:\n  print('Heteroscedasticity with p-value =', gq_test)\nelse:\n  print('Homoscedasticity with p-value =', gq_test)","ec86a7e3":"Goldfeld-Quandt homoscedasticity test","188ad414":"Predictions plot","5cbcb005":"**Residuals analysis**","a18cda25":"Normality test","2a6da992":"**Evaluation**","0ecb2d42":"Dropping outliers\n- Outlier defined by HDBSCAN clustering","9cb5bf9e":"Autocorrelation: Durbing-Watson test\n","4269967d":"# Exporatory Data Analysis","f331f689":"**Prices plot**\n- Plot: real vs cross-validation\n- Distance: prediction distance in general (real vs train-test split) ","81372265":"Data:\n- Transaction date (purchase)\n- House age\n- Distance to the nearest MRT station (metric not defined)\n- Amount of convenience stores\n- Location (latitude and longitude)\n- House price of unit area \n\n\n\n","eea848d3":"Box-plot","7c50ccda":"**Prediction**\n- Train-test split","f6f7fd2a":"Dropping non useful columns","dcc91321":"Correlation matrix","bb325150":"# Pre-processing\n\n- Reading dataset ","044ba9cb":"Homoscedasticity","3c65f299":"Normality","500f9649":"Functions","f96b771b":"Feature comparison (dependence)\n- dependent and independent features","ebf09add":"# Linear Regression"}}