{"cell_type":{"f64d61bb":"code","ade8ba05":"code","1642a318":"code","6ba428a1":"code","eda49787":"code","9782eb9b":"code","8b475827":"code","7bbc47d8":"code","3a285436":"code","ff57062a":"code","4588a7e3":"code","64403190":"code","8ee86fad":"code","5a17f22d":"code","9f4cc73e":"code","303c0bf2":"code","e1ced87d":"code","d616d314":"code","ff1fc0dc":"code","f8d3c0f3":"code","ba56023c":"code","1f88aba6":"code","94e59c39":"code","77eb722a":"code","c480f6d5":"code","4c2543b8":"code","be3bc17c":"code","b0bcd658":"code","d3817b3d":"code","c88daee6":"code","0b712de7":"code","938470df":"code","e1042bd4":"code","184d9314":"markdown","98ed0fab":"markdown","a95e9450":"markdown","64779781":"markdown","e54ae849":"markdown","5350fe52":"markdown","1807e20b":"markdown","499de792":"markdown","0dd56426":"markdown","edf9e5bc":"markdown","0f1c66d9":"markdown","76fb8a24":"markdown","6079790c":"markdown","7327d18d":"markdown","01c65351":"markdown","24555fdf":"markdown","a9980e6e":"markdown","56cfb8e7":"markdown","3e990ae3":"markdown","676df5c5":"markdown","19f9f123":"markdown","138b42fc":"markdown","4af30f7e":"markdown","c4061bb2":"markdown"},"source":{"f64d61bb":"import os\nimport re # For Regular Expression \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk # Natural Language Tool Kits\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'retina'","ade8ba05":"df = pd.read_csv('..\/input\/17k-apple-app-store-strategy-games\/appstore_games.csv')\ndf = df.drop_duplicates().reset_index()\ndisplay(df.head(5))\nprint(df.info())","1642a318":"import re # For Regular Expression \nimport nltk # Natural Language Tool Kits\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import bigrams\nfrom nltk import trigrams","6ba428a1":"print(df['Description'][9])","eda49787":"# Remove useless strings and lower the words.\ndef rm_lower(description):\n    description = re.sub(r'\\\\n', ' ', description)\n    description = re.sub(r'\\\\u....', ' ', description)\n    description = re.sub(r'\\\\x..', ' ', description)\n    description = re.sub(r'http.*html', ' ', description)\n    description = re.sub(r'http.*com', ' ', description)\n    description = re.sub(r'www.*com', ' ', description)\n    description = re.sub(r'\\W+', ' ', description)\n    description = re.sub(r'\\d', ' ', description)\n    description = ' '.join(description.split()).lower()\n    return description","9782eb9b":"print(rm_lower(df['Description'][9]))","8b475827":"def tk(description):\n    description = rm_lower(description)\n    token = word_tokenize(description)\n#     token = [word.lower() for word in token]\n#     token = [word for word in token if word]\n    stopwords_en = set(stopwords.words('english')) # set of stopwords\n#     stopwords_en_withpunct = stopwords_en.union(set(punctuation))\n    token = [word for word in token if word not in stopwords_en]\n    token = [WordNetLemmatizer().lemmatize(word) for word in token]\n#     fdist1 = fdist.most_common(5)\n#     FreqDist(token)\n    return token","7bbc47d8":"print(tk(df['Description'][9]))","3a285436":"token_dict = {}\nfor i in range(len(df)):\n    token_dict[df['Name'][i]] = tk(df['Description'][i])","ff57062a":"for i, (k, v) in enumerate(token_dict.items()):\n    if i in range(0, 1):\n        print(k, v)","4588a7e3":"entire_description = []\nfor i in token_dict.values():\n    entire_description += i\n\nbio_tokens = bigrams(entire_description)\ntemp = []\nfor i in bio_tokens:\n    temp.append(i)\nbio_tokens = temp\nfreq_bio = FreqDist(bio_tokens)\n\ntri_tokens = trigrams(entire_description)\ntemp = []\nfor i in tri_tokens:\n    temp.append(i)\ntri_tokens = temp\nfreq_tri = FreqDist(tri_tokens)","64403190":"freq_sig = FreqDist(entire_description)\nfreq_sig = pd.DataFrame({'Word': list(dict(freq_sig).keys()),\n                       'Count': list(dict(freq_sig).values())})\n\nfreq_bio = FreqDist(bio_tokens)\nfreq_bio = pd.DataFrame({'Word': list(dict(freq_bio).keys()),\n                       'Count': list(dict(freq_bio).values())})\n\nfreq_tri = FreqDist(tri_tokens)\nfreq_tri = pd.DataFrame({'Word': list(dict(freq_tri).keys()),\n                       'Count': list(dict(freq_tri).values())})","8ee86fad":"wordcloud = WordCloud(background_color=None, width=800, height=1200, mode='RGBA').generate(' '.join(entire_description))","5a17f22d":"# Draw the wordcloud graph\nplt.figure(dpi=300)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Wordcloud of Description')\nplt.show()\n# plt.savefig('wordcloud.pgn')","9f4cc73e":"plt.figure(dpi=300)\nplt.grid(ls='--')\nsns.barplot(x='Count', y='Word', data=freq_sig.sort_values('Count', ascending=False)[0:20], \n            palette=\"Set3\")\nplt.title('The Most Common Words in Single Grams')\nplt.show()\n# plt.savefig('Singlegrams.png')","303c0bf2":"plt.figure(dpi=300)\nplt.grid(ls='--')\nsns.barplot(x='Count', y='Word', data=freq_bio.sort_values('Count', ascending=False)[0:20], palette=\"Set3\")\nplt.title('The Most Common Words in Birams')\nplt.show()\n# plt.savefig('Bigrams.png')","e1ced87d":"import networkx as nx","d616d314":"num = 100\nnw = []\nfor i in range(num):\n    nw.append(freq_bio.sort_values('Count', ascending=False)['Word'][i])","ff1fc0dc":"G = nx.from_edgelist(nw)","f8d3c0f3":"colo = np.array(list(dict(G.degree()).values())) \nfig = plt.figure(dpi=300)\nnx.draw_circular(G, with_labels=True, node_color=colo, cmap=plt.cm.twilight, node_size=80, line_color='grey',\n        linewidths=0.8, width=0.8, font_size=6, alpha=0.8, font_family='fantasy')\nplt.title(\"Top 100 Most Common Words's Network\" )\nplt.show()\n# plt.savefig('100network.png')","ba56023c":"plt.figure(dpi=300)\nplt.grid(ls='--')\nsns.barplot(x='Count', y='Word', data=freq_tri.sort_values('Count', ascending=False)[0:20], palette=\"Set1\")\nplt.title('The Most Common Words in Trigrams')\nplt.show()\n# plt.savefig('Trigrams.png')","1f88aba6":"effective_words = []\nfor i, (k, v) in enumerate(token_dict.items()):\n    if i in range(len(df)):  \n        effective_words.append(len(v))\ndf['Effective Words'] = effective_words\ndisplay(df[['Name', 'Description', 'Effective Words']].head())","94e59c39":"plt.figure(dpi=300)\nsns.barplot(x='Average User Rating', y='Effective Words', data=df, palette=\"Set1\")\nplt.title('Average User Rating Vs. Effective Words')\nplt.show()","77eb722a":"def count_tags(tags):\n    noun = 0\n    adj = 0\n    verb = 0\n    adverb = 0\n    for i in tags:\n        if i[1] == 'JJ':\n            adj += 1\n        if i[1] == 'NN':\n            noun += 1\n        if i[1] == 'VB':\n            verb += 1\n        if i[1] == 'RB':\n            adverb += 1\n    return [noun, adj, verb, adverb]","c480f6d5":"num_noun = []\nnum_adj = []\nnum_verb = []\nnum_adverb = []\nfor i in df['Name']:   \n    tags = count_tags(nltk.pos_tag(token_dict[i]))\n    num_noun.append(tags[0])\n    num_adj.append(tags[1])\n    num_verb.append(tags[2])\n    num_adverb.append(tags[3])","4c2543b8":"df['The Proportion of N.'] = num_noun \/ df['Effective Words']\ndf['The Proportion of Adj.'] = num_adj \/ df['Effective Words']\ndf['The Proportion of V.'] = num_verb \/ df['Effective Words']\ndf['The Proportion of Adv.'] = num_adverb \/ df['Effective Words']","be3bc17c":"display(df[['Name', 'Effective Words', 'The Proportion of N.', 'The Proportion of Adj.', 'The Proportion of V.', 'The Proportion of Adv.']].head())","b0bcd658":"plt.figure(dpi=300)\nsns.barplot(x='Average User Rating', y='The Proportion of Adj.', data=df, palette=\"Set1\")\nplt.title('Average User Rating Vs. The Number of Adj.')\nplt.show()","d3817b3d":"title_token_dict = {}\nfor i in range(len(df)):\n    title_token_dict[df['Name'][i]] = tk(df['Name'][i])","c88daee6":"title_entire_description = []\nfor i in title_token_dict.values():\n    title_entire_description += i\n\ntitle_bio_tokens = bigrams(title_entire_description)\ntemp = []\nfor i in title_bio_tokens:\n    temp.append(i)\ntitle_bio_tokens = temp\ntitle_freq_bio = FreqDist(title_bio_tokens)","0b712de7":"title_freq_sig = FreqDist(title_entire_description)\ntitle_freq_sig = pd.DataFrame({'Word': list(dict(title_freq_sig).keys()),\n                       'Count': list(dict(title_freq_sig).values())})\n\ntitle_freq_bio = FreqDist(title_bio_tokens)\ntitle_freq_bio = pd.DataFrame({'Word': list(dict(title_freq_bio).keys()),\n                       'Count': list(dict(title_freq_bio).values())})","938470df":"plt.figure(dpi=300)\nplt.grid(ls='--')\nsns.barplot(x='Count', y='Word', data=title_freq_sig.sort_values('Count', ascending=False)[1:21], palette=\"Set3\")\nplt.title('The Most Common Words in Single Grams of Title')\nplt.show()","e1042bd4":"plt.figure(dpi=300)\nplt.grid(ls='--')\nsns.barplot(x='Count', y='Word', data=title_freq_bio.sort_values('Count', ascending=False)[1:21], palette=\"Set3\")\nplt.title('The Most Common Words in Birams of Title')\nplt.show()","184d9314":"For example, we can extract any of the tokened descriptions by specifing the name of the game.","98ed0fab":"Draw a wordcloud of description in terms of single gram.","a95e9450":"In this chapter, check the description of the games overall, which combine all the description into one string and then tokenized it to explore some feature of strategy game's description.","64779781":"# Text Analysis of Title of the App\n\nThe title of the app contains the theme and the type of this game.","e54ae849":"As we can observe from above two pictures, in terms of single words, \"game\" is the most frequent word obviously.","5350fe52":"### Bigrams and Trigrams\n\nAnd here, we inreoducing bigrams and trigrams.\n\nA bigram or digram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words. A bigram is an n-gram for n=2. The frequency distribution of every bigram in a string is commonly used for simple statistical analysis of text in many applications, including in computational linguistics, cryptography, speech recognition, and so on.\n\nGappy bigrams or skipping bigrams are word pairs which allow gaps (perhaps avoiding connecting words, or allowing some simulation of dependencies, as in a dependency grammar).\n\nHead word bigrams are gappy bigrams with an explicit dependency relationship.\n\nBigrams help provide the conditional probability of a token given the preceding token, when the relation of the conditional probability is applied:\n\n$${\\displaystyle P(W_{n}|W_{n-1})={P(W_{n-1},W_{n}) \\over P(W_{n-1})}}$$\n\nThat is, the probability ${\\displaystyle P()}$ of a token ${\\displaystyle W_{n}}$ given the preceding token ${\\displaystyle W_{n-1}}W_{{n-1}}$ is equal to the probability of their bigram, or the co-occurrence of the two tokens ${\\displaystyle P(W_{n-1},W_{n})}$, divided by the probability of the preceding token.","1807e20b":"# Text Analysis of Description of the App\n\nThe description of the app contains the information and the feature of this game. So it may cover some valuable things. But the formate of the text is the struggle thing that has to be dealt with.","499de792":"It can be easily seen the combination of each words from this network graph.","0dd56426":"#### App 'Barrels' Example (After `rm_lower()`)","edf9e5bc":"#### App 'Barrels' Example (After `tk()`)","0f1c66d9":"There are many conspicuous words showed on this wordcloud map such as \"player\", \"feature\", \"world\" and \"battle\", which can be infered that most of description focus on the international function and competitiveness of the game.","76fb8a24":"#### App 'Barrels' Example (Before `rm_lower()`)","6079790c":"### Word Tokenization Function\n\nIn this function, we have to tokenize the sentences which is splitting up \u201csentences\u201d into \u201cwords\u201d. \n\n#### Stopwords:\n\nThen remove those **Stopwords** which are non-content words that primarily has only grammatical function like \"i\", \"me\" and \"you\" these words.\n\n#### Stemming and Lemmatization:\n\n- **Stemming**: Trying to shorten a word with simple regex rules\n- **Lemmatization**: Trying to find the root word with linguistics rules (with the use of regexes)\n> (See also: [Stemmers vs Lemmatizers](#https:\/\/stackoverflow.com\/q\/17317418\/610569) question on StackOverflow)\n\nIn this procedure, we use **Lemmatization**.","7327d18d":"# EDA and NLP on Mobile Games\n\nThis is about **Exploratory Data Analysis** and **Natural Language Processing** on 17k Mobile Strategy Games data from https:\/\/www.kaggle.com\/tristan581\/17k-apple-app-store-strategy-games.\n\n### Overview\n\nThe mobile games industry is worth billions of dollars, with companies spending vast amounts of money on the development and marketing of these games to an equally large market. Using this data set, insights can be gained into a sub-market of this market, strategy games. This sub-market includes titles such as Clash of Clans, Plants vs Zombies and Pokemon GO.\n\n### Background\n\nThis is the data of 17007 strategy games on the Apple App Store. It was collected on the 3rd of August 2019, using the iTunes API and the App Store sitemap.\n\n### Some ideas\n\nYou could use the number of ratings as a proxy indicator for the overall success of a game, and then work out what factors make a successful game. Or you could measure the state of the market over time and try predict where it is headed. And I think an analysis of the icons of the apps would be pretty cool.\n\n---","01c65351":"## Genarate the Token Dictionary\n\nStore token list of all games. In dictionary, the key is the name of the application and the value is the token of that discription.","24555fdf":"## Build the Function","a9980e6e":"It can be showed that most of description are added hyper link which related to its company's page or its profile page of social media. On the other hand, puzzle game is the main part of these strategy game. \"real time\" is also specified as the main feature of the most strategy game.","56cfb8e7":"Except from some hyper links like \"facebook\", \"twitter\" and some platform name \"iphone\", \"ipad\", two types of games are popular \"tic-tac-toe\" and \"tower-defense-game\". And most of strategy games are think highly of its globalization which allows players can connect to each other.","3e990ae3":"Averagely, the games that rated as 1 have relatively higher effective words. Hence, the number of words cannot represent the quality of the application.","676df5c5":"### Remove and Lower Function\n\nFor example blow, we want to remove escape character like `\\`, `\\\\n`, unicode character like `\\uXXXX` and other useless punctuation and hyper links of websites. `\\n` is the return character so we replace that with space character becuase this can be recongenized by token tool later. `\\uXXXX` is the unicode characcter which represent some invaluable things in appstore like some arrows and emojis. After remove these character we have to lower the strings to keep the consistence.","19f9f123":"## Entire Description","138b42fc":"# Import Packages and Browse the Data","4af30f7e":"## Acquire a new attribute -- Type of Words\n\n$The\\ number\\ of\\ adjective\\ words$\n\n$$W_{Type_j}=\\sum T(D[i])_{Type_j}$$\n\n$Where\\ T\\ is\\ the\\ token\\ function\\ and\\ D\\ is\\ the\\ description\\ feature.\\ Type\\ include\\ noun,adj.,v.\\ and\\ adv.$","c4061bb2":"## Acquire a new attribute -- Effective Words\n\n$The\\ number\\ of\\ effective\\ words$\n\n$$W_{eff.}=\\sum T(D[i])$$\n\n$Where\\ T\\ is\\ the\\ token\\ function\\ and\\ D\\ is\\ the\\ description\\ feature$"}}