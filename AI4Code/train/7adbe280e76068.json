{"cell_type":{"c01d9ce5":"code","8287a787":"code","db605b56":"code","752cb141":"code","47cdcea0":"code","fcc17d36":"code","37977657":"code","56e46630":"code","bc96ef6e":"code","3fcf5ade":"code","bdd09d7f":"code","9f104f62":"code","6f5db26f":"code","2f3c1518":"code","5ccb173e":"code","394e9624":"code","960b8616":"code","46c58101":"code","bfa4c00e":"code","0470bb15":"code","29179e04":"code","b392d020":"code","f671668d":"code","cf0cb42f":"code","7bc82896":"code","a4416bde":"code","23bc9695":"code","f3654c91":"code","ab8fcb32":"code","659065c7":"code","d9f3dffe":"code","db755c1c":"code","423f671a":"code","538ea1c5":"code","b64e2f0e":"code","53b37a28":"markdown","c1645c34":"markdown","47f47118":"markdown","fa4f74d7":"markdown","a315311a":"markdown"},"source":{"c01d9ce5":"import pandas as pd\nimport numpy as np\n","8287a787":"data = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\ndata.head()","db605b56":"data['sentiment'].value_counts()","752cb141":"data.dtypes","47cdcea0":"import nltk\nnltk.download(\"stopwords\")\nnltk.download('wordnet')","fcc17d36":"from nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlm = WordNetLemmatizer()\n","37977657":"data['review'] = data['review'].str.lower()","56e46630":"#data['review'].replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)","bc96ef6e":"data['review'].replace('https?:\/\/\\S+|www\\.\\S+',\" \",regex=True,inplace=True)\ndata['review'].replace('<.*?>',\" \",regex=True,inplace=True)\ndata['review'].replace('@\\w+',\" \",regex=True,inplace=True)\ndata['review'].replace('#\\w+',\" \",regex=True,inplace=True)\ndata['review'].replace(\"[^\\w\\s\\d]\",\" \",regex=True,inplace=True)\ndata['review'].replace(r'( +)',\" \",regex=True,inplace=True)\ndata['review'].replace(\"[^a-zA-Z]\",\" \",regex=True,inplace=True)","3fcf5ade":"#train = data['review'][:40000]\n#test = data['review'][40000:]","bdd09d7f":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding,Dense,LSTM\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","9f104f62":"data_lem = []\nfor i in range(0,len(data.index)):\n  temp = data['review'][i].split()\n  temp = [word.lower() for word in temp]\n  temp = [word for word in temp if word not in stopwords.words(\"english\")]\n  temp = \" \".join(temp)\n  data_lem.append(temp)","6f5db26f":"voc_size = 90000","2f3c1518":"from keras.preprocessing.text import Tokenizer\nt = Tokenizer(num_words=voc_size,oov_token='<OOV>')\nt.fit_on_texts(data_lem)\nword_index=t.word_index\ntotal_vocab=len(word_index)","5ccb173e":"total_vocab","394e9624":"train = t.texts_to_sequences(data_lem)","960b8616":"set_length = 700\nembedded_docs_train = pad_sequences(train,padding='pre',maxlen =set_length)","46c58101":"from tensorflow.keras.layers import Flatten,Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.layers import Bidirectional","bfa4c00e":"import keras\nopt = keras.optimizers.Adam(learning_rate=0.01)","0470bb15":"import keras\nvector_feature = 200\nmodel = Sequential()\nmodel.add(Embedding(voc_size,vector_feature,input_length=set_length))\nDropout(0.20)\nmodel.add(LSTM(64,return_sequences=True))\nmodel.add(Flatten())\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","29179e04":"model.summary()","b392d020":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\nlabels = pd.get_dummies(data['sentiment'],drop_first=True)\n","f671668d":"labels['positive'] = labels['positive'].astype(int)","cf0cb42f":"x_final = embedded_docs_train\ny_final = labels['positive']","7bc82896":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.33)","a4416bde":"y_test.shape","23bc9695":"history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=4,batch_size=64,verbose=1)","f3654c91":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='val loss')\nplt.legend()\nplt.show()","ab8fcb32":"\nimport matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'],label='train accuracy')\nplt.plot(history.history['val_accuracy'],label='val accuracy')\nplt.legend()\nplt.show()","659065c7":"predict = model.predict(X_test)\nlen(predict)","d9f3dffe":"predict[0]","db755c1c":"sent = []\nfor i in range(len(predict)):\n    if predict[i] >= 0.5:\n      sent.append(1)\n    else:\n      sent.append(0)\n","423f671a":"result = pd.DataFrame(list(zip(sent,np.array(y_test))),columns=['predict','actual'])","538ea1c5":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(np.array(y_test),sent)","b64e2f0e":"from sklearn.metrics import accuracy_score\naccuracy_score(np.array(y_test),sent)","53b37a28":"# IMDB Review Sentimental Analysis","c1645c34":"# Data Cleaning","47f47118":"# Results","fa4f74d7":"# Data Processing","a315311a":"# LSTM Model "}}