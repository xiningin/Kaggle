{"cell_type":{"74f79668":"code","16867d97":"code","518ca169":"code","b3cd9bb0":"code","cab23775":"code","3ee6fff9":"code","3be86dfe":"code","27203711":"code","e71564f1":"code","fc9d00e3":"code","423f9f39":"code","6dec023b":"code","39875048":"code","2d2cf37b":"code","886c40dd":"code","e1496402":"code","26f15625":"code","04663231":"code","b0fef53d":"code","3fbbe248":"code","18fc7ac2":"code","4b1ac32d":"code","3c637abf":"code","c10410dc":"code","58305f3d":"code","a29efc62":"code","9ce3acf2":"markdown","e3b3fea0":"markdown","204bab25":"markdown","db7e2108":"markdown","3fbde7eb":"markdown","b8166fd1":"markdown","c58456b8":"markdown","e5e84b70":"markdown","db70b805":"markdown","6a90a0f2":"markdown","fe894d77":"markdown","e829cf1f":"markdown","abd1a66b":"markdown","59ec7199":"markdown","fd1d01dd":"markdown","8f99423c":"markdown","d87214bf":"markdown","0dc209be":"markdown","ec2f6096":"markdown","4c65e55a":"markdown"},"source":{"74f79668":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16867d97":"train = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","518ca169":"train.head()","b3cd9bb0":"test.head()","cab23775":"print(train.shape)\nprint(test.shape)","3ee6fff9":"train.describe()","3be86dfe":"# Check if target variable has any missing values\ntrain['SalePrice'].isna().sum()","27203711":"train.SalePrice.isnull().sum()","e71564f1":"# Take X, y, X_test from dataframes\nX = train.drop(['SalePrice'], axis=1)\ny = train.SalePrice\nX_test = test","fc9d00e3":"print(X.shape, y.shape, X_test.shape)","423f9f39":"cat_cols = [col for col in X.columns if X[col].nunique() < 10 and X[col].dtype == 'object']\nnum_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n\nall_cols = num_cols + cat_cols\nX_reduced = X[all_cols]\nX_test_reduced = X_test[all_cols]\n\nprint(X_reduced.shape, X_test_reduced.shape)","6dec023b":"from sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error","39875048":"num_tranformer = SimpleImputer(strategy='median')\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', num_tranformer, num_cols),\n    ('cat', cat_transformer, cat_cols)\n])","2d2cf37b":"from sklearn.ensemble import RandomForestRegressor","886c40dd":"model = RandomForestRegressor(n_estimators=100, random_state=0)","e1496402":"model_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])","26f15625":"from sklearn.model_selection import cross_val_score\n\nscores = -1 * cross_val_score(model_pipeline, \n                              X_reduced, y,\n                             cv = 5,\n                             scoring = 'neg_mean_absolute_error')\n\nprint(f'Avg score: {scores.mean()}')","04663231":"from xgboost import XGBRegressor","b0fef53d":"model_2 = XGBRegressor(random_state=0)","3fbbe248":"model_2_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model_2)\n])","18fc7ac2":"xgb_scores = -1 * cross_val_score(model_2_pipeline,\n                                 X_reduced, y,\n                                 cv=5,\n                                 scoring='neg_mean_absolute_error')\nprint(f'XGB: Avg MAE score: {xgb_scores.mean()}')","4b1ac32d":"model_3 = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4, random_state=0)\nmodel_3_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model_3)\n])","3c637abf":"xgb_2_scores = -1 * cross_val_score(model_3_pipeline, \n                                   X_reduced, y,\n                                   cv = 5,\n                                   scoring='neg_mean_absolute_error')\nprint(f'XGBRegressor, Avg MAE = {xgb_2_scores.mean()}')","c10410dc":"# Fit model_3_pipeline on X_reduced dataset\nmodel_3_pipeline.fit(X_reduced, y)","58305f3d":"preds_test = model_3_pipeline.predict(X_test_reduced)","a29efc62":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test_reduced.index,\n                      'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","9ce3acf2":"By basic stastics, you can get a feel about the distribution of data in each column.\n\n_Point to note, in above result is that, it includes only 'numerical' columns._","e3b3fea0":"### Prepare a Pipeline to perform following things:\n+ Impute Numerical columns with strategy='median'\n+ Impute categorical columns with strategy='most_frequent'\n+ One-Hot encode categorical columns with less than 10 categories\n+ RandomForestRegressor model","204bab25":"The avg score from XGBoost didn't improve much.","db7e2108":"In the above table from `train` dataframe, we can see that there are columns with `NaN` values which indicates that our dataset has columns with missing values.","3fbde7eb":"### Check for the shape of `train` and `test` DataFrames","b8166fd1":"Now, we have baseline model with MAE of 17,684.79 from RandomForestRegressor model.","c58456b8":"### Model 2: XGBoostRegressor with default parameters","e5e84b70":"### Separate `Target variable` and `Features` from Training and Testing dataframes","db70b805":"## Baseline model\nUse `RandomForestRegressor` to find the baseline model","6a90a0f2":"Let's tune parameters for XGBoost","fe894d77":"### Load libraries to prepare for Pipeline","e829cf1f":"### Check for basic statistics in `train` dataframe","abd1a66b":"## Prepare for submission","59ec7199":"Now, this model gives us better MAE score for the dataset.","fd1d01dd":"## Data loading into Pandas DataFrames\n\nWe load the data from CSV files for Training and Testing into `train` and `test` Pandas DataFrames. This is the very first step to start any ML\/DL project.","8f99423c":"### Check for `NaN` in target variable","d87214bf":"### Check top 5 rows in `train` and `test` DataFrames\nThis can help us to start familiarising with the data.","0dc209be":"Above result shows that we have \n+ Training dataset with 1460 rows and 80 columns\n+ Testing dataset with 1459 rows and 79 columns. _The column missing is the 'SalePrice' which is our target variable._","ec2f6096":"## Take numerical columns and categorical columns those have less than 10 unique categories","4c65e55a":"Similarly, we can observe that `test` data also has columns with missing values."}}