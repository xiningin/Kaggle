{"cell_type":{"2437902a":"code","564655f4":"code","1f9c94ac":"code","215b7f40":"code","b0f488e0":"code","93bb8743":"code","fccc29e9":"code","85b5db37":"markdown","ff6ce7ca":"markdown","98bb6550":"markdown","b99ff2a7":"markdown"},"source":{"2437902a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# the data si from yahoo finance \n# link :https:\/\/finance.yahoo.com\/quote\/IAM.PA\/history?period1=1601337600&period2=1609200000&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\n#code inspiration is from towardsdatascience.com\n#link : https:\/\/towardsdatascience.com\/predicting-stock-prices-using-a-keras-lstm-model-4225457f0233\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","564655f4":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","1f9c94ac":"df= pd.read_csv(\"..\/input\/iam-stockprice-dataset\/IAM.csv\")\ndf = df.dropna(how='any',axis=0) #remove null rows\ntrain, test = train_test_split(df, test_size=0.2,shuffle=False)\ndataset_train = train\ntraining_set = dataset_train.iloc[:, 1:2].values\nprint(train.head())","215b7f40":"# MinMaxScaler from scikit-learn to scale our dataset into numbers between 0 and 1\nsc = MinMaxScaler(feature_range=(0,1))\ntraining_set_scaled = sc.fit_transform(training_set)\n#we create data in 60 timesteps and convert it into an array using NumPy. \n#Then, we convert the data into a 3D array with X_train samples, \n#60 timestamps, and one feature at each step.\nX_train = []\ny_train = []\nfor i in range(60, len(training_set_scaled)):\n    X_train.append(training_set_scaled[i-60:i, 0])\n    y_train.append(training_set_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)\n\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))","b0f488e0":"model = Sequential()\n\nmodel.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=50,return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=50,return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=1))\n\nmodel.compile(optimizer='adam',loss='mean_squared_error')\n#later must add the epochs value for more precision\nmodel.fit(X_train,y_train,epochs=10,batch_size=32)","93bb8743":"dataset_test =test\nreal_stock_price = dataset_test.iloc[:, 1:2].values\n\ndataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs = sc.transform(inputs)\nX_test = []\n\nfor i in range(60, len(inputs)):\n    X_test.append(inputs[i-60:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = model.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","fccc29e9":"plt.plot(real_stock_price, color = 'black', label = 'maroc telecom  Stock Price')\nplt.plot(predicted_stock_price, color = 'green', label = 'Predicted maroc telecom  Stock Price')\nplt.title('maroc telecom Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('maroc telecom Stock Price')\nplt.legend()\nplt.show()","85b5db37":"# test","ff6ce7ca":"# plot the data","98bb6550":"# geting the data","b99ff2a7":"# making and training the model"}}