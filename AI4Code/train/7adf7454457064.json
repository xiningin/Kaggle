{"cell_type":{"54d9b882":"code","2723cd00":"code","ce020ead":"code","e55eece6":"code","df45d49a":"code","e2a42363":"code","a972e39d":"code","d454f2a4":"code","be4de9e0":"code","835bad18":"code","cc3f8815":"code","f14692c4":"code","8ad49293":"code","899f0fc1":"code","c1ba61b0":"code","7f590da2":"code","2c011e58":"code","57a31420":"code","93f47475":"code","ff3e6082":"code","2a1f02f9":"code","e8a9a76a":"code","cd750c69":"code","b9c2ba89":"code","d1e18c04":"code","57e4b707":"code","4a27a31b":"code","0ccecbb7":"code","9ad96e65":"code","7054e1c8":"code","84348af8":"code","b411b31c":"code","f321106c":"code","e9f80f2a":"code","e5fed5cb":"code","a42c8bbc":"code","ce571316":"code","f6b0670b":"code","f4d7087f":"code","ac49ce23":"code","c7786964":"code","6c2b166f":"code","1e2f3fa2":"code","aad00584":"code","4a0d7ad6":"code","9f7882a4":"code","4034e19c":"code","7f708c0d":"code","3fab68b0":"code","02966ce0":"code","d38acaa0":"code","4171253d":"code","9c658cc3":"code","1e277b7d":"code","c52c3f09":"code","6a67c7b7":"code","bc42627f":"code","168bb77c":"code","3fbdd4d0":"code","de2dd2df":"code","1cde755b":"code","22d24194":"code","5c555609":"code","efe3e301":"code","47583b90":"code","995794c2":"code","1a481238":"code","a621cff3":"code","6eca9f62":"code","17928ea2":"code","baf26097":"code","bd1df728":"code","8d82431b":"code","cf101a61":"code","8c49b7a2":"code","dc85578c":"code","97b4f47b":"code","a0e523d9":"code","6c2425a1":"code","205ddafc":"code","5ac091d2":"code","15245c01":"code","859885b7":"code","158600c5":"code","76da1a15":"code","bdd8112b":"code","887300b0":"code","036e4530":"code","c73d20d0":"code","7cd4432f":"code","4b673791":"code","c6814f77":"code","b216e190":"code","f97201cd":"code","be7f43d3":"code","ce8f6537":"code","78abdcad":"code","1a0d41f4":"code","5ac0db5f":"code","f58e9200":"code","75c04b03":"code","27306a67":"code","c5a8f51a":"code","fe1bb93a":"code","a4d4650a":"code","3e85db8e":"code","e47107ca":"code","00dcb099":"code","c29b3e1f":"code","66ae6e48":"code","2c156b5d":"code","8ff692ef":"code","c95e8bf3":"code","4afd3342":"code","d9b8d4de":"code","b127920b":"code","4819e313":"code","ee599b88":"code","031e0e2d":"code","2c8173e6":"code","37923576":"code","d6dddfd0":"code","ddcb930e":"code","46b449e2":"code","394ef7c4":"code","5a23a816":"code","fcf8696c":"code","c1a797f1":"code","c027075a":"code","71cc4810":"code","74e071f9":"code","7d4ddd5b":"code","756dddca":"code","0c0a05a6":"code","785a4a34":"code","58755e7d":"code","50a18476":"code","31fc624d":"code","71aec40a":"code","c1dfe1d7":"code","54a70517":"code","9cab9ea5":"code","46f13ec4":"code","b66f2f47":"code","ce7bb39a":"code","d01616f1":"code","5dbff5f0":"code","d90c3476":"code","b54d5e48":"code","e5303bc6":"markdown","b119ee9f":"markdown","e32060bd":"markdown","56986fc7":"markdown","bf2ac860":"markdown","205b1bda":"markdown","2c463188":"markdown","ff043e52":"markdown","25c61a08":"markdown","39a0e886":"markdown","a08eb3eb":"markdown","0462047c":"markdown","7ae186ef":"markdown","d072342d":"markdown","6c117bfd":"markdown","0d50f6b5":"markdown","9a35aab0":"markdown","bcb48be8":"markdown","062ce24b":"markdown","b7318c8d":"markdown","44aa5ca7":"markdown","1205a118":"markdown","2ea853e4":"markdown","32999a7f":"markdown","441e44e8":"markdown","4ce52f11":"markdown","eeccc987":"markdown","0a868c15":"markdown","51a96ee4":"markdown","46db98e3":"markdown","6a29ea8d":"markdown","dec30375":"markdown","f8982961":"markdown","eb16cad5":"markdown","55de3264":"markdown","64588380":"markdown","9396e085":"markdown","93ab767f":"markdown","1ab8e9dc":"markdown","82add04a":"markdown","00720a16":"markdown","2e576f6e":"markdown","8159b189":"markdown","11593e5e":"markdown","fb20249f":"markdown","431eaba0":"markdown","78e40510":"markdown","188194c4":"markdown","8f526a23":"markdown","d0c6a316":"markdown","04a2aa0a":"markdown","56f9c906":"markdown","ae7f1dcf":"markdown","bbc0b061":"markdown","55ee4120":"markdown","de774802":"markdown","c10012c4":"markdown","e8681145":"markdown","f10d43da":"markdown","d9f3be7a":"markdown","2dcd3ae3":"markdown","5f20e128":"markdown","ec4a4fbb":"markdown","af351dd0":"markdown","78b7e721":"markdown","a91462be":"markdown","53c069ca":"markdown","282214b9":"markdown","d0107d0e":"markdown","d00888ae":"markdown","573b3b0e":"markdown","83291633":"markdown","f84a89fa":"markdown","0051bbde":"markdown","c5c17e94":"markdown","48d5f04e":"markdown","3ef01230":"markdown","dd3c192b":"markdown","e775238d":"markdown","31af5df9":"markdown","95756d8f":"markdown","c67caead":"markdown","07032bbd":"markdown","600d3028":"markdown","e78d00fd":"markdown","fdea6460":"markdown","4c2a4ec1":"markdown","0f8c8914":"markdown","b85d18ca":"markdown","aa6a762c":"markdown","033cc52f":"markdown","589f288e":"markdown","d10fd169":"markdown","ec7faff4":"markdown","a3351dd1":"markdown","4a859ef3":"markdown","0318ab07":"markdown","e30ff2f5":"markdown","8fc44e86":"markdown","cccaf7c8":"markdown","aa1c5f7c":"markdown","0400455e":"markdown"},"source":{"54d9b882":"import numpy as np\nimport pandas as pd\nimport os\nimport json\n\npd.set_option('display.max_colwidth', 220)","2723cd00":"datasets_info = {\n    2021: \"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\",\n    2020: \"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\",\n    2019: \"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\",\n    2018: \"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\"\n}\n\nquestions_info = {\n    'single questions': [\n        (\"Duration\",\n             [\"Duration (in seconds)\"]),\n        (\"Age\",\n             [\"What is your age\"]),\n        (\"Gender\",\n             [\"What is your gender\"]),\n        (\"Country\",\n             [\"In which country do you currently reside\"]),\n        (\"Education\",\n             [\"What is the highest level of formal education that you have attained or plan to attain within the next 2 years\"]),\n        (\"Current role\",\n             [\"Select the title most similar to your current role (or most recent title if retired)\"]),\n        (\"Writing code\",\n             [\"For how many years have you been writing code and\/or programming\",  # [2020-2021]\n              \"How long have you been writing code to analyze data\"]),             # [2018-2019]\n        (\"Programming language\",\n             [\"What programming language would you recommend an aspiring data scientist to learn first\"]),    \n        (\"Computing platform\",\n             [\"What type of computing platform do you use most often for your data science projects\"]),\n        (\"Used a TPU\",\n             [\"Approximately how many times have you used a TPU (tensor processing unit)\"]),\n        (\"Used ML methods\",\n             [\"For how many years have you used machine learning methods\"]),\n        (\"In what industry\",\n             [\"In what industry is your current employer\/contract (or your most recent employer if retired)\"]),\n        (\"Size of the company\",\n             [\"What is the size of the company where you are employed\"]),\n        (\"Individuals are responsible\",\n             [\"Approximately how many individuals are responsible for data science workloads at your place of business\"]),    \n        (\"ML methods into business\",\n             [\"Does your current employer incorporate machine learning methods into their business\"]),\n        (\"Compensation, USD\",\n             [\"What is your current yearly compensation (approximate $USD)\"]),\n        (\"Spent money,  USD\",\n             [\"Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)\"]),\n        (\"Cloud platforms\",\n             [\"Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)\"]),\n        (\"Following big data products\",\n             [\"Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often\"]),\n        (\"Following business intelligence tools\",\n             [\"Which of the following business intelligence tools do you use most often\"]),\n        (\"Primary tool\",\n             [\"What is the primary tool that you use at work or school to analyze data\"])\n    ],\n    'group questions': [\n        (\"Programming languages use on a regular basis\",\n             [\"What programming languages do you use on a regular basis\"]),\n        (\"IDE's use on a regular basis\",\n             [\"Which of the following integrated development environments (IDE's) do you use on a regular basis\",\n              \"Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years\"]),  # 2018\n        (\"Hosted notebook products use on a regular basis\",\n             [\"Which of the following hosted notebook products do you use on a regular basis\",\n              \"Which of the following hosted notebooks have you used at work or school in the last 5 years\"]),  # 2018\n        (\"Specialized hardware use on a regular basis\",\n             [\"Which types of specialized hardware do you use on a regular basis\"]),\n        (\"Visualization libraries or tools use on a regular basis\",\n             [\"What data visualization libraries or tools do you use on a regular basis\",\n              \"What data visualization libraries or tools have you used in the past 5 years\"]),\n        (\"ML frameworks use on a regular basis\",\n             [\"Which of the following machine learning frameworks do you use on a regular basis\",\n              \"What machine learning frameworks have you used in the past 5 years\"]),\n        (\"ML algorithms use on a regular basis\",\n             [\"Which of the following ML algorithms do you use on a regular basis\"]),\n        (\"CV methods use on a regular basis\",\n             [\"Which categories of computer vision methods do you use on a regular basis\"]),\n        (\"NLP methods use on a regular basis\",\n             [\"Which of the following natural language processing (NLP) methods do you use on a regular basis\"]),\n        (\"Important part of your role at work\",\n             [\"Select any activities that make up an important part of your role at work\"]),\n        (\"Cloud computing platforms use on a regular basis\",\n             [\"Which of the following cloud computing platforms do you use on a regular basis\"]),\n        (\"Cloud computing platforms to become more familiar\",\n             [\"Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years\"]),\n        (\"Cloud computing products use on a regular basis\",\n             [\"Do you use any of the following cloud computing products on a regular basis\"]),\n        (\"Cloud computing products to become more familiar\",\n             [\"In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products\"]),\n        (\"Big data products use on a regular basis\",\n             [\"Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis\"]),\n        (\"Big data products to become more familiar\", \n             [\"Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years\"]),\n        (\"BI tools use on a regular basis\",\n             [\"Which of the following business intelligence tools do you use on a regular basis\"]),\n        (\"BI tools to become more familiar\",\n             [\"Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years\"]),\n        (\"AutoML use on a regular basis\",\n             [\"Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis\"]),\n        (\"AutoML to become more familiar\",\n             [\"Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years\"]),\n        (\"AutoML use on a regular basis --2\",\n             [\"Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis\"]),\n        (\"Specific AutoML tools to become more familiar\",\n             [\"Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years\"]),\n        (\"Use any tools to help manage machine learning experiments\",\n             [\"Do you use any tools to help manage machine learning experiments\"]),\n        (\"In the next 2 years, do you hope to become more familiar\",\n             [\"In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments\"]),\n        (\"Where publicly share\",\n             [\"Where do you publicly share your data analysis or machine learning applications\",\n              \"Where do you publicly share or deploy your data analysis or machine learning applications\"]),\n        (\"Platforms or data science courses\",\n             [\"On which platforms have you begun or completed data science courses\"]),\n        (\"Favorite media sources\",\n             [\"Who\/what are your favorite media sources that report on data science topics\"])\n    ]\n}","ce020ead":"datasets = {}\n\nfor year_data, path_to_data in datasets_info.items():\n    datasets[year_data] = pd.read_csv(path_to_data, low_memory=False)","e55eece6":"for x_year in datasets.keys():\n    print(x_year, \":\", datasets.get(x_year).shape)","df45d49a":"# For check and dataset description\nlatest_data = max(datasets.keys())\n\n# 'single columns' \/ 'multi questions'\ncolumns_info = {}","e2a42363":"def replace_cols_name(cols_diff, group_num=None):\n    if group_num or group_num == 0:\n        new_indices = [\"GA\" + str(group_num) + \"_\" + str(x)\n                       for x in cols_diff.index.to_list()\n                           if isinstance(x, int)]\n    else:\n        new_indices = [\"SA\" + str(x)\n                       for x in cols_diff.index.to_list()\n                           if isinstance(x, int)]\n\n    if new_indices:\n        cols_diff.index = new_indices\n\n    for x_year in datasets.keys():\n        if x_year in cols_diff.columns:\n            replace_dict = pd.DataFrame(cols_diff[x_year].index,\n                                        cols_diff[x_year].values).to_dict()[0]\n\n            datasets.get(x_year).rename(columns=replace_dict,\n                                       inplace=True)","a972e39d":"def single_cols_diff(questions):\n    result = {year_data: [] for year_data in datasets.keys()}\n    \n    def search_col_name(df, questions_list):\n        for col in df.columns:\n            for question in questions_list:\n                if question in df.loc[0, col]:\n                    return df[col].name\n\n    for question_info in questions:\n        short_name, versions = question_info\n\n        for x_year in result.keys():\n            data_header = datasets.get(x_year).head(1)\n\n            col_name = search_col_name(data_header, versions)\n            result[x_year].append(col_name)\n    \n    result = pd.DataFrame(result)\n\n    result_question = [versions[0]\n                       for short_name, versions in questions]\n    result['question'] = pd.Series(result_question)\n    \n    return result","d454f2a4":"single_cols = single_cols_diff(questions_info.get('single questions'))\ncolumns_info['single columns'] = single_cols.to_dict()\n\nsingle_cols.loc[1:]","be4de9e0":"check_year = 2018\ncheck_cols = \"Q12_MULTIPLE_CHOICE\"\nprint(datasets.get(check_year).loc[0, check_cols])\ndatasets.get(check_year).loc[1: , check_cols].unique()","835bad18":"check_year = 2019\ncheck_cols = \"Q14\"\nprint(datasets.get(check_year).loc[0, check_cols])\ndatasets.get(check_year).loc[1: , check_cols].unique()","cc3f8815":"check_year = 2021\ncheck_cols = \"Q41\"\nprint(datasets.get(check_year).loc[0, check_cols])\ndatasets.get(check_year).loc[1: , check_cols].unique()","f14692c4":"replace_cols_name(single_cols)\n\ndatasets.get(latest_data).head(3)","8ad49293":"def group_cols_diff(questions):\n    qroup_cols_marker = \"_\"\n    txt_choice_marker = \"- Selected Choice -\"\n\n    concat_data = []\n\n    for x_year in datasets.keys():\n        first_row = datasets.get(x_year).head(1)\n        qroup_cols = first_row.filter(like=qroup_cols_marker)\n\n        def get_group_values(data, questions):\n            data = data.T #.filter(like=questions_marker)\n            is_choice = data[0].str.contains(txt_choice_marker)\n            data = data[is_choice]\n            \n            for question in questions:\n                result = data.loc[data[0].str.contains(question, regex=False), 0]\n\n                if result.any():\n                    df = result.str.split(txt_choice_marker, expand=True)[1] \\\n                                            .str.strip().reset_index().set_index(1)\n                    df = df.rename(columns={'index': x_year})\n                    return df\n\n        group_values = get_group_values(qroup_cols, questions)\n        concat_data.append(group_values)\n    \n    result = pd.concat(concat_data, axis=1)\n    result['choise'] = result.index\n    result = result.reset_index(drop=True)\n    \n    return result.replace({np.nan: None})\n\n\ndef group_result(indx):\n    _, versions = group_questions[indx]\n    print(\"\\n({}): {}\\n\".format(indx, versions[0]))\n    return pd.DataFrame(columns_info.get('group columns')[indx])\n\n\ndef group_replace(col_info, base_info, x_year, is_test=False):\n    result = False\n    col_name, col_value = col_info\n\n    if col_name in datasets.get(x_year).columns:\n        base_col_name, base_col_value = base_info\n        old_value = col_value\n        new_value = base_col_value\n        \n        unique_list = datasets.get(x_year)[col_name].unique()\n        notna_sum =  datasets.get(x_year)[col_name].notna().sum()\n        \n        if new_value not in unique_list:\n            datasets.get(x_year)[col_name].replace(regex=[old_value],\n                                                   value=new_value,\n                                                       inplace=True)            \n            result = True\n\n        if is_test == True:\n            print(x_year, col_name)\n            print(\"Replace:\", result)\n            print(\"Values ({}) before: {}\\n\".format(notna_sum, unique_list))\n            print(\"Values ({}) after: {}\\n\".format(\n                            datasets.get(x_year)[col_name].notna().sum(),\n                                datasets.get(x_year)[col_name].unique()))\n        \n    return result\n\n\ndef group_update(base_info, upd_cols_info, x_year, is_test=False):\n    base_col_name, base_col_value = base_info\n\n    if base_col_name in datasets.get(x_year).columns:\n        for upd_col_info in upd_cols_info:\n            col_name, col_value = upd_col_info\n            isna_sum = datasets.get(x_year)[base_col_name].isna().sum()\n\n            result = False\n\n            # 1. Replace and get status\n            status = group_replace(upd_col_info, base_info, x_year)\n\n            if status == True:\n                # 2. Fillna base_col_name <<< col_name\n                datasets.get(x_year)[base_col_name].fillna(\n                                    datasets.get(x_year)[col_name], inplace=True)\n                # 3. Drop col_name\n                datasets.get(x_year).drop([col_name], axis=1, inplace=True)\n\n                result = True\n\n            if is_test:\n                print(x_year, base_col_name, \"<<<\", col_name)\n                print(\"Update:\", result)\n                print(\"IsNa before:\", isna_sum)\n                print(\"IsNa after:\", datasets.get(x_year)[base_col_name].isna().sum())\n","899f0fc1":"group_questions = questions_info.get('group questions')\n\ngroup_result_dict =  {i: group_cols_diff(check_question[1])\n                      for i, check_question in enumerate(group_questions)}\n\ncolumns_info['group columns'] = {col_indx: col_diff.to_dict()\n                                 for col_indx, col_diff in group_result_dict.items()}","c1ba61b0":"len(group_result_dict)","7f590da2":"locals().update({'group_{}'.format(x): x for x in group_result_dict.keys()})\nprint(group_0, \"...\", group_26)","2c011e58":"group_result(group_0)","57a31420":"x_year = 2018\n\n# Javascript\nbase_info = ('Q16_Part_6', 'Javascript')\ncol_info = ('Q16_Part_6', 'Javascript\/Typescript')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q16_Part_18', 'Other')\nupd_cols_info = [\n    ('Q16_Part_7', 'Visual Basic\/VBA'),\n    ('Q16_Part_10', 'Scala'),\n    ('Q16_Part_11', 'Julia'),\n    ('Q16_Part_12', 'Go'),\n    ('Q16_Part_13', 'C#\/.NET'),\n    ('Q16_Part_14', 'PHP'),\n    ('Q16_Part_15', 'Ruby'),\n    ('Q16_Part_16', 'SAS\/STATA')\n]\ngroup_update(base_info, upd_cols_info, x_year)","93f47475":"x_year = 2019\n\n# C\/C++\nbase_info = ('Q18_Part_4', 'C\/C++')\ncol_info = ('Q18_Part_4', 'C$')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q18_Part_5', 'C\\+\\+')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q18_Part_12', 'Other')\nupd_cols_info = [\n    ('Q18_Part_8', 'TypeScript')\n]\ngroup_update(base_info, upd_cols_info, x_year)","ff3e6082":"x_year = 2020\n\n# C\/C++\nbase_info = ('Q7_Part_4', 'C\/C++')\ncol_info = ('Q7_Part_4', 'C$')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q7_Part_5', 'C\\+\\+')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q7_OTHER', 'Other')\nupd_cols_info = [\n    ('Q7_Part_8', 'Julia'),\n    ('Q7_Part_9', 'Swift')\n]\ngroup_update(base_info, upd_cols_info, x_year)","2a1f02f9":"x_year = 2021\n\n# C\/C++\nbase_info = ('Q7_Part_4', 'C\/C++')\ncol_info = ('Q7_Part_4', 'C$')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q7_Part_5', 'C\\+\\+')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q7_OTHER', 'Other')\nupd_cols_info = [\n    ('Q7_Part_8', 'Julia'),\n    ('Q7_Part_9', 'Swift')\n]\ngroup_update(base_info, upd_cols_info, x_year)","e8a9a76a":"_ = group_cols_diff(group_questions[group_0][1])\n_","cd750c69":"replace_cols_name(_, group_0)","b9c2ba89":"group_result(group_1)","d1e18c04":"x_year = 2018\n\n# Jupyter (JupyterLab, Jupyter Notebooks, etc)\nbase_info = ('Q13_Part_1', 'Jupyter (JupyterLab, Jupyter Notebooks, etc)')\ncol_info = ('Q13_Part_1', 'Jupyter\/IPython')\n_ = group_replace(col_info, base_info, x_year)\n\n# Visual Studio (Visual Studio Code)\nbase_info = ('Q13_Part_8', 'Visual Studio (Visual Studio Code)')\ncol_info = ('Q13_Part_8', 'Visual Studio')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q13_Part_4', 'Visual Studio Code')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Vim \/ Emacs\nbase_info = ('Q13_Part_11', 'Vim \/ Emacs')\ncol_info = ('Q13_Part_11', 'Vim')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q13_Part_15', 'Other')\nupd_cols_info = [\n    ('Q13_Part_6', 'Atom'),\n    ('Q13_Part_5', 'nteract'),\n    ('Q13_Part_12', 'IntelliJ')\n]\ngroup_update(base_info, upd_cols_info, x_year)","57e4b707":"x_year = 2019\n\n# Visual Studio (Visual Studio Code)\nbase_info = ('Q16_Part_6', 'Visual Studio (Visual Studio Code)')\ncol_info = ('Q16_Part_6', 'Visual Studio \/ Visual Studio Code')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q16_Part_12', 'Other')\nupd_cols_info = [\n    ('Q16_Part_4', 'Atom')\n]\ngroup_update(base_info, upd_cols_info, x_year)","4a27a31b":"x_year = 2020\n\n# Visual Studio (Visual Studio Code)\nbase_info = ('Q9_Part_3', 'Visual Studio (Visual Studio Code)')\ncol_info = ('Q9_Part_3', '^Visual Studio$|Visual Studio \\\/ Visual Studio Code')\n_ = group_replace(col_info, base_info, x_year)\n\nupd_cols_info = [\n    ('Q9_Part_4', 'Visual Studio Code \\(VSCode\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","0ccecbb7":"x_year = 2021\n# Jupyter (JupyterLab, Jupyter Notebooks, etc)\nbase_info = ('Q9_Part_1', 'Jupyter (JupyterLab, Jupyter Notebooks, etc)')\nupd_cols_info = [\n    ('Q9_Part_11', 'Jupyter Notebook')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Visual Studio \/ Visual Studio Code\nbase_info = ('Q9_Part_3', 'Visual Studio (Visual Studio Code)')\ncol_info = ('Q9_Part_3', 'Visual Studio')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q9_Part_4', 'Visual Studio Code \\(VSCode\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","9ad96e65":"_ = group_cols_diff(group_questions[group_1][1])\n_","7054e1c8":"replace_cols_name(_, group_1)","84348af8":"group_result(group_2)","b411b31c":"x_year = 2018\n\n# Kaggle Notebooks\nbase_info = ('Q14_Part_1', 'Kaggle Notebooks')\ncol_info = ('Q14_Part_1', 'Kaggle Kernels')\n_ = group_replace(col_info, base_info, x_year)\n\n# Azure Notebooks\nbase_info = ('Q14_Part_3', 'Azure Notebooks')\ncol_info = ('Q14_Part_3', 'Azure Notebook')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Colab Notebooks\nbase_info = ('Q14_Part_2', 'Google Colab Notebooks')\ncol_info = ('Q14_Part_2', 'Google Colab')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Cloud (AI Platform, Datalab, etc)\nbase_info = ('Q14_Part_5', 'Google Cloud (AI Platform, Datalab, etc)')\ncol_info = ('Q14_Part_5', 'Google Cloud Datalab')\n_ = group_replace(col_info, base_info, x_year)\n\n# Binder \/ JupyterHub\nbase_info = ('Q14_Part_9', 'Binder \/ JupyterHub')\ncol_info = ('Q14_Part_9', 'JupyterHub\/Binder')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q14_Part_11', 'Other')\nupd_cols_info = [\n    ('Q14_Part_4', 'Domino Datalab'),\n    ('Q14_Part_6', 'Paperspace'),\n    ('Q14_Part_7', 'Floydhub'),\n    ('Q14_Part_8', 'Crestle')\n]\ngroup_update(base_info, upd_cols_info, x_year)","f321106c":"x_year = 2019\n\n# Kaggle Notebooks\nbase_info = ('Q17_Part_1', 'Kaggle Notebooks')\ncol_info = ('Q17_Part_1', 'Kaggle Notebooks \\(Kernels\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Azure Notebooks\nbase_info = ('Q17_Part_3', 'Azure Notebooks')\ncol_info = ('Q17_Part_3', 'Microsoft Azure Notebooks')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Colab Notebooks\nbase_info = ('Q17_Part_2', 'Google Colab Notebooks')\ncol_info = ('Q17_Part_2', 'Google Colab')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Cloud (AI Platform, Datalab, etc)\nbase_info = ('Q17_Part_4', 'Google Cloud (AI Platform, Datalab, etc)')\ncol_info = ('Q17_Part_4', 'Google Cloud Notebook Products \\(AI Platform, Datalab, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q17_Part_12', 'Other')\nupd_cols_info = [\n    ('Q17_Part_5', 'Paperspace \/ Gradient'),\n    ('Q17_Part_8', 'IBM Watson Studio'),\n    ('Q17_Part_9', 'Code Ocean'),\n    ('Q17_Part_6', 'FloydHub'),\n    ('Q17_Part_10', 'AWS Notebook Products \\(EMR Notebooks, Sagemaker Notebooks, etc\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","e9f80f2a":"x_year = 2020\n\n# Google Colab Notebooks\nbase_info = ('Q10_Part_2', 'Google Colab Notebooks')\ncol_info = ('Q10_Part_2', 'Colab Notebooks')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Cloud (AI Platform, Datalab, etc)\nbase_info = ('Q10_Part_10', 'Google Cloud (AI Platform, Datalab, etc)')\ncol_info = ('Q10_Part_10', 'Google Cloud AI Platform Notebooks')\n_ = group_replace(col_info, base_info, x_year)\n\nupd_cols_info = [\n    ('Q10_Part_11', 'Google Cloud Datalab Notebooks')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q10_OTHER', 'Other')\nupd_cols_info = [\n    ('Q10_Part_4', 'Paperspace \/ Gradient'),\n    ('Q10_Part_6', 'Code Ocean'),\n    ('Q10_Part_7', 'IBM Watson Studio'),\n    ('Q10_Part_8', 'Amazon Sagemaker Studio'),\n    ('Q10_Part_9', 'Amazon EMR Notebooks'),\n    ('Q10_Part_12', 'Databricks Collaborative Notebooks')\n]\ngroup_update(base_info, upd_cols_info, x_year)","e5fed5cb":"x_year = 2021\n\n# Google Colab Notebooks\nbase_info = ('Q10_Part_2', 'Google Colab Notebooks')\ncol_info = ('Q10_Part_2', 'Colab Notebooks')\n_ = group_replace(col_info, base_info, x_year)\n\n# Google Cloud (AI Platform, Datalab, etc)\nbase_info = ('Q10_Part_10', 'Google Cloud (AI Platform, Datalab, etc)')\ncol_info = ('Q10_Part_10', 'Google Cloud Notebooks \\(AI Platform \/ Vertex AI\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nupd_cols_info = [\n    ('Q10_Part_11', 'Google Cloud Datalab')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q10_OTHER', 'Other')\nupd_cols_info = [\n    ('Q10_Part_4', 'Paperspace \/ Gradient'),\n    ('Q10_Part_6', 'Code Ocean'),\n    ('Q10_Part_7', 'IBM Watson Studio'),\n    ('Q10_Part_8', 'Amazon Sagemaker Studio Notebooks'),\n    ('Q10_Part_9', 'Amazon EMR Notebooks'),\n    ('Q10_Part_12', 'Databricks Collaborative Notebooks'),\n    ('Q10_Part_13', 'Zeppelin \/ Zepl Notebooks'),\n    ('Q10_Part_14', 'Deepnote Notebooks'),\n    ('Q10_Part_15', 'Observable Notebooks')\n]\ngroup_update(base_info, upd_cols_info, x_year)","a42c8bbc":"_ = group_cols_diff(group_questions[group_2][1])\n_","ce571316":"replace_cols_name(_, group_2)","f6b0670b":"group_result(group_3)","f4d7087f":"x_year = 2019\n\n# CPUs >>> 2019 year: 10472\ndatasets.get(x_year).drop(['Q21_Part_1'], axis=1, inplace=True)\n\n# None\nbase_info = ('Q21_Part_4', 'None')\ncol_info = ('Q21_Part_4', 'None \/ I do not know')\n_ = group_replace(col_info, base_info, x_year)","ac49ce23":"x_year = 2021\n\n# GPUs\nbase_info = ('Q12_Part_1', 'GPUs')\ncol_info = ('Q12_Part_1', 'NVIDIA GPUs')\n_ = group_replace(col_info, base_info, x_year)\n\n# TPUs\nbase_info = ('Q12_Part_2', 'TPUs')\ncol_info = ('Q12_Part_2', 'Google Cloud TPUs')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q12_OTHER', 'Other')\nupd_cols_info = [\n    ('Q12_Part_3', 'AWS Trainium Chips'),\n    ('Q12_Part_4', 'AWS Inferentia Chips')\n]\ngroup_update(base_info, upd_cols_info, x_year)","c7786964":"_ = group_cols_diff(group_questions[group_3][1])\n_","6c2b166f":"replace_cols_name(_, group_3)","1e2f3fa2":"group_result(group_4)","aad00584":"x_year = 2018\n\n# Ggplot \/ ggplot2\nbase_info = ('Q21_Part_1', 'Ggplot \/ ggplot2')\ncol_info = ('Q21_Part_1', 'ggplot2')\n_ = group_replace(col_info, base_info, x_year)\n\n# Plotly \/ Plotly Express\nbase_info = ('Q21_Part_6', 'Plotly \/ Plotly Express')\ncol_info = ('Q21_Part_6', 'Plotly')\n_ = group_replace(col_info, base_info, x_year)\n\n# D3 js\nbase_info = ('Q21_Part_5', 'D3 js')\ncol_info = ('Q21_Part_5', 'D3')\n_ = group_replace(col_info, base_info, x_year)\n\n# Leaflet \/ Folium\nbase_info = ('Q21_Part_10', 'Leaflet \/ Folium')\ncol_info = ('Q21_Part_10', 'Leaflet')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q21_Part_13', 'Other')\nupd_cols_info = [\n    ('Q21_Part_11', 'Lattice')\n]\ngroup_update(base_info, upd_cols_info, x_year)","4a0d7ad6":"x_year = 2019\n\n# D3 js\nbase_info = ('Q20_Part_5', 'D3 js')\ncol_info = ('Q20_Part_5', 'D3\\.js')\n_ = group_replace(col_info, base_info, x_year)\n","9f7882a4":"_ = group_cols_diff(group_questions[group_4][1])\n_","4034e19c":"replace_cols_name(_, group_4)","7f708c0d":"group_result(group_5)","3fab68b0":"x_year = 2018\n\n# Scikit-learn\nbase_info = ('Q19_Part_1', 'Scikit-learn')\ncol_info = ('Q19_Part_1', 'Scikit-Learn')\n_ = group_replace(col_info, base_info, x_year)\n\n# Fast.ai\nbase_info = ('Q19_Part_7', 'Fast.ai')\ncol_info = ('Q19_Part_7', 'Fastai')\n_ = group_replace(col_info, base_info, x_year)\n\n# LightGBM\nbase_info = ('Q19_Part_14', 'LightGBM')\ncol_info = ('Q19_Part_14', 'lightgbm')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q19_Part_19', 'Other')\nupd_cols_info = [\n    ('Q19_Part_5', 'Spark MLlib'),\n    ('Q19_Part_6', 'H20'),\n    ('Q19_Part_8', 'Mxnet'),\n    ('Q19_Part_11', 'mlr'),\n    ('Q19_Part_12', 'Prophet'),\n    ('Q19_Part_13', 'randomForest'),\n    ('Q19_Part_15', 'catboost'),\n    ('Q19_Part_16', 'CNTK'),\n    ('Q19_Part_17', 'Caffe')\n]\ngroup_update(base_info, upd_cols_info, x_year)","02966ce0":"x_year = 2019\n\n# Other\nbase_info = ('Q28_Part_12', 'Other')\nupd_cols_info = [\n    ('Q28_Part_4', 'RandomForest'),\n    ('Q28_Part_9', 'Spark MLib')\n]\ngroup_update(base_info, upd_cols_info, x_year)","d38acaa0":"x_year = 2020\n\n# Other\nbase_info = ('Q16_OTHER', 'Other')\nupd_cols_info = [\n    ('Q16_Part_6', 'MXNet'),\n    ('Q16_Part_9', 'CatBoost'),\n    ('Q16_Part_10', 'Prophet'),\n    ('Q16_Part_11', 'H2O 3'),\n    ('Q16_Part_13', 'Tidymodels'),\n    ('Q16_Part_14', 'JAX')\n]\ngroup_update(base_info, upd_cols_info, x_year)","4171253d":"x_year = 2021\n\n# PyTorch\nbase_info = ('Q16_Part_4', 'PyTorch')\nupd_cols_info = [\n    ('Q16_Part_15', 'PyTorch Lightning')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q16_OTHER', 'Other')\nupd_cols_info = [\n    ('Q16_Part_6', 'MXNet'),\n    ('Q16_Part_9', 'CatBoost'),\n    ('Q16_Part_10', 'Prophet'),\n    ('Q16_Part_11', 'H2O 3'),\n    ('Q16_Part_13', 'Tidymodels'),\n    ('Q16_Part_14', 'JAX'),\n    ('Q16_Part_16', 'Huggingface')    \n]\ngroup_update(base_info, upd_cols_info, x_year)","9c658cc3":"_ = group_cols_diff(group_questions[group_5][1])\n_","1e277b7d":"replace_cols_name(_, group_5)","c52c3f09":"group_result(group_6)","6a67c7b7":"x_year = 2019\n\n# Transformer Networks\nbase_info = ('Q24_Part_10', 'Transformer Networks (BERT, gpt, etc)')\ncol_info = ('Q24_Part_10', 'Transformer Networks \\(BERT, gpt-2, etc\\)')\n_ = group_replace(col_info, base_info, x_year)","bc42627f":"x_year = 2020\n\n# Transformer Networks\nbase_info = ('Q17_Part_10', 'Transformer Networks (BERT, gpt, etc)')\ncol_info = ('Q17_Part_10', 'Transformer Networks \\(BERT, gpt-3, etc\\)')\n_ = group_replace(col_info, base_info, x_year)","168bb77c":"x_year = 2021\n\n# Transformer Networks\nbase_info = ('Q17_Part_10', 'Transformer Networks (BERT, gpt, etc)')\ncol_info = ('Q17_Part_10', 'Transformer Networks \\(BERT, gpt-3, etc\\)')\n_ = group_replace(col_info, base_info, x_year)","3fbdd4d0":"_ = group_cols_diff(group_questions[group_6][1])\n_","de2dd2df":"replace_cols_name(_, group_6)","1cde755b":"group_result(group_7)","22d24194":"_ = group_cols_diff(group_questions[group_7][1])\nreplace_cols_name(_, group_7)","5c555609":"group_result(group_8)","efe3e301":"# Transformer language models\n\nx_year = 2019\nbase_info = ('Q27_Part_4', 'Transformer language models (GPT, BERT, XLnet, etc)')\ncol_info = ('Q27_Part_4', 'Transformer language models \\(GPT-2, BERT, XLnet, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nx_year = 2020\nbase_info = ('Q19_Part_4', 'Transformer language models (GPT, BERT, XLnet, etc)')\ncol_info = ('Q19_Part_4', 'Transformer language models \\(GPT-3, BERT, XLnet, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nx_year = 2021\nbase_info = ('Q19_Part_4', 'Transformer language models (GPT, BERT, XLnet, etc)')\ncol_info = ('Q19_Part_4', 'Transformer language models \\(GPT-3, BERT, XLnet, etc\\)')\n_ = group_replace(col_info, base_info, x_year)","47583b90":"_ = group_cols_diff(group_questions[group_8][1])\n_","995794c2":"replace_cols_name(_, group_8)","1a481238":"group_result(group_9)","a621cff3":"_ = group_cols_diff(group_questions[group_9][1])\nreplace_cols_name(_, group_9)","6eca9f62":"group_result(group_10)","17928ea2":"x_year = 2019\n\n# IBM Cloud \/ Red Hat\nbase_info = ('Q29_Part_4', 'IBM Cloud \/ Red Hat')\ncol_info = ('Q29_Part_4', 'IBM Cloud')\n_ = group_replace(col_info, base_info, x_year)\n\nupd_cols_info = [\n    ('Q29_Part_10', 'Red Hat Cloud')    \n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q29_Part_12', 'Other')\nupd_cols_info = [\n    ('Q29_Part_5', 'Alibaba Cloud'),\n    ('Q29_Part_6', 'Salesforce Cloud'),\n    ('Q29_Part_9', 'VMware Cloud')\n]\ngroup_update(base_info, upd_cols_info, x_year)","baf26097":"x_year = 2020\n\n# Other\nbase_info = ('Q26_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q26_A_Part_7', 'Salesforce Cloud'),\n    ('Q26_A_Part_8', 'VMware Cloud'),\n    ('Q26_A_Part_9', 'Alibaba Cloud'),\n    ('Q26_A_Part_10', 'Tencent Cloud')\n]\ngroup_update(base_info, upd_cols_info, x_year)","bd1df728":"x_year = 2021\n\n# Other\nbase_info = ('Q27_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q27_A_Part_7', 'Salesforce Cloud'),\n    ('Q27_A_Part_8', 'VMware Cloud'),\n    ('Q27_A_Part_9', 'Alibaba Cloud'),\n    ('Q27_A_Part_10', 'Tencent Cloud')\n]\ngroup_update(base_info, upd_cols_info, x_year)","8d82431b":"_ = group_cols_diff(group_questions[group_10][1])\n_","cf101a61":"replace_cols_name(_, group_10)","8c49b7a2":"group_result(group_11)","dc85578c":"_ = group_cols_diff(group_questions[group_11][1])\n_\nreplace_cols_name(_, group_11)","97b4f47b":"group_result(group_12)","a0e523d9":"group_result(group_13)","6c2425a1":"group_result(group_14)","205ddafc":"x_year = 2020\n\n# PostgreSQL\nbase_info = ('Q29_A_Part_2', 'PostgreSQL')\ncol_info = ('Q29_A_Part_2', 'PostgresSQL')\n_ = group_replace(col_info, base_info, x_year)\n\n# Microsoft (SQL Server, Azure Database, Storage, etc)\nbase_info = ('Q29_A_Part_8', 'Microsoft (SQL Server, Azure Database, Storage, etc)')\ncol_info = ('Q29_A_Part_8', 'Microsoft SQL Server')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_A_Part_10', 'Microsoft Azure Data Lake Storage'),\n    ('Q29_A_Part_9', 'Microsoft Access')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)\nbase_info = ('Q29_A_Part_11', 'Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)')\ncol_info = ('Q29_A_Part_11', 'Amazon Redshift')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_A_Part_12', 'Amazon Athena'),\n    ('Q29_A_Part_13', 'Amazon DynamoDB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)\nbase_info = ('Q29_A_Part_14', 'Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)')\ncol_info = ('Q29_A_Part_14', 'Google Cloud BigQuery')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_A_Part_15', 'Google Cloud SQL'),\n    ('Q29_A_Part_16', 'Google Cloud Firestore')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q29_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q29_A_Part_6', 'Snowflake'),\n    ('Q29_A_Part_7', 'IBM Db2')\n]\ngroup_update(base_info, upd_cols_info, x_year)","5ac091d2":"x_year = 2021\n\n# Microsoft (SQL Server, Azure Database, Storage, etc)\nbase_info = ('Q32_A_Part_8', 'Microsoft (SQL Server, Azure Database, Storage, etc)')\ncol_info = ('Q32_A_Part_8', 'Microsoft SQL Server')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_A_Part_9', 'Microsoft Azure SQL Database'),\n    ('Q32_A_Part_10', 'Microsoft Azure Cosmos DB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)\nbase_info = ('Q32_A_Part_11', 'Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)')\ncol_info = ('Q32_A_Part_11', 'Amazon Redshift')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_A_Part_12', 'Amazon Aurora'),\n    ('Q32_A_Part_13', 'Amazon RDS'),\n    ('Q32_A_Part_14', 'Amazon DynamoDB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)\nbase_info = ('Q32_A_Part_15', 'Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)')\ncol_info = ('Q32_A_Part_15', 'Google Cloud BigQuery')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_A_Part_16', 'Google Cloud SQL'),\n    ('Q32_A_Part_17', 'Google Cloud Firestore'),\n    ('Q32_A_Part_18', 'Google Cloud BigTable'),\n    ('Q32_A_Part_19', 'Google Cloud Spanner')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n    \n# Other\nbase_info = ('Q32_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q32_A_Part_6', 'Snowflake'),\n    ('Q32_A_Part_7', 'IBM Db2')\n]\ngroup_update(base_info, upd_cols_info, x_year)","15245c01":"_ = group_cols_diff(group_questions[group_14][1])\n_","859885b7":"replace_cols_name(_, group_14)","158600c5":"group_result(group_15)","76da1a15":"x_year = 2020\n\n# PostgreSQL\nbase_info = ('Q29_B_Part_2', 'PostgreSQL')\ncol_info = ('Q29_B_Part_2', 'PostgresSQL')\n_ = group_replace(col_info, base_info, x_year)\n\n# Microsoft (SQL Server, Azure Database, Storage, etc)\nbase_info = ('Q29_B_Part_8', 'Microsoft (SQL Server, Azure Database, Storage, etc)')\ncol_info = ('Q29_B_Part_8', 'Microsoft SQL Server')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_B_Part_10', 'Microsoft Azure Data Lake Storage'),\n    ('Q29_B_Part_9', 'Microsoft Access')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)\nbase_info = ('Q29_B_Part_11', 'Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)')\ncol_info = ('Q29_B_Part_11', 'Amazon Redshift')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_B_Part_12', 'Amazon Athena'),\n    ('Q29_B_Part_13', 'Amazon DynamoDB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)\nbase_info = ('Q29_B_Part_14', 'Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)')\ncol_info = ('Q29_B_Part_14', 'Google Cloud BigQuery')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q29_B_Part_15', 'Google Cloud SQL'),\n    ('Q29_B_Part_16', 'Google Cloud Firestore')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q29_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q29_B_Part_6', 'Snowflake'),\n    ('Q29_B_Part_7', 'IBM Db2')\n]\ngroup_update(base_info, upd_cols_info, x_year)","bdd8112b":"x_year = 2021\n\n# Microsoft (SQL Server, Azure Database, Storage, etc)\nbase_info = ('Q32_B_Part_8', 'Microsoft (SQL Server, Azure Database, Storage, etc)')\ncol_info = ('Q32_B_Part_8', 'Microsoft SQL Server')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_B_Part_9', 'Microsoft Azure SQL Database'),\n    ('Q32_B_Part_10', 'Microsoft Azure Cosmos DB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)\nbase_info = ('Q32_B_Part_11', 'Amazon (Redshift, Aurora, RDS, DynamoDB, Athena, etc)')\ncol_info = ('Q32_B_Part_11', 'Amazon Redshift')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_B_Part_12', 'Amazon Aurora'),\n    ('Q32_B_Part_14', 'Amazon RDS'),\n    ('Q32_B_Part_13', 'Amazon DynamoDB')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)\nbase_info = ('Q32_B_Part_15', 'Google (Cloud BigQuery, SQL, Firestore, BigTable, etc)')\ncol_info = ('Q32_B_Part_15', 'Google Cloud BigQuery')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q32_B_Part_16', 'Google Cloud SQL'),\n    ('Q32_B_Part_17', 'Google Cloud Firestore'),\n    ('Q32_B_Part_18', 'Google Cloud BigTable'),\n    ('Q32_B_Part_19', 'Google Cloud Spanner')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Other\nbase_info = ('Q32_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q32_B_Part_6', 'Snowflake'),\n    ('Q32_B_Part_7', 'IBM Db2')\n]\ngroup_update(base_info, upd_cols_info, x_year)","887300b0":"_ = group_cols_diff(group_questions[group_15][1])\n_","036e4530":"replace_cols_name(_, group_15)","c73d20d0":"group_result(group_16)","7cd4432f":"x_year = 2020\n\n# Other\nbase_info = ('Q31_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q31_A_Part_4', 'Looker'),\n    ('Q31_A_Part_9', 'Domo'),\n    ('Q31_A_Part_10', 'TIBCO Spotfire'),\n    ('Q31_A_Part_11', 'Alteryx'),\n    ('Q31_A_Part_12', 'Sisense'),\n    ('Q31_A_Part_13', 'SAP Analytics Cloud'),\n    ('Q31_A_Part_7', 'Einstein Analytics')\n]\ngroup_update(base_info, upd_cols_info, x_year)","4b673791":"x_year = 2021\n\n# Other\nbase_info = ('Q34_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q34_A_Part_4', 'Looker'),\n    ('Q34_A_Part_7', 'Tableau CRM'),\n    ('Q34_A_Part_9', 'Domo'),\n    ('Q34_A_Part_10', 'TIBCO Spotfire'),\n    ('Q34_A_Part_11', 'Alteryx'),\n    ('Q34_A_Part_12', 'Sisense'),\n    ('Q34_A_Part_13', 'SAP Analytics Cloud'),\n    ('Q34_A_Part_14', 'Microsoft Azure Synapse'),\n    ('Q34_A_Part_15', 'Thoughtspot')\n]\ngroup_update(base_info, upd_cols_info, x_year)","c6814f77":"_ = group_cols_diff(group_questions[group_16][1])\n_","b216e190":"replace_cols_name(_, group_16)","f97201cd":"group_result(group_17)","be7f43d3":"x_year = 2020\n\n# Other\nbase_info = ('Q31_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q31_B_Part_4', 'Looker'),\n    ('Q31_B_Part_9', 'Domo'),\n    ('Q31_B_Part_10', 'TIBCO Spotfire'),\n    ('Q31_B_Part_11', 'Alteryx'),\n    ('Q31_B_Part_12', 'Sisense'),\n    ('Q31_B_Part_13', 'SAP Analytics Cloud'),\n    ('Q31_B_Part_7', 'Einstein Analytics')\n]\ngroup_update(base_info, upd_cols_info, x_year)","ce8f6537":"x_year = 2021\n\n# Other\nbase_info = ('Q34_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q34_B_Part_4', 'Looker'),\n    ('Q34_B_Part_7', 'Tableau CRM'),\n    ('Q34_B_Part_9', 'Domo'),\n    ('Q34_B_Part_10', 'TIBCO Spotfire'),\n    ('Q34_B_Part_11', 'Alteryx'),\n    ('Q34_B_Part_12', 'Sisense'),\n    ('Q34_B_Part_13', 'SAP Analytics Cloud'),\n    ('Q34_B_Part_14', 'Microsoft Azure Synapse'),\n    ('Q34_B_Part_15', 'Thoughtspot')\n]\ngroup_update(base_info, upd_cols_info, x_year)","78abdcad":"_ = group_cols_diff(group_questions[group_17][1])\n_","1a0d41f4":"replace_cols_name(_, group_17)","5ac0db5f":"group_result(group_18)","f58e9200":"x_year = 2020\n\n# Google AutoML, H2O Driverless AI)\nbase_info = ('Q33_A_Part_6', 'Automation of full ML pipelines (e.g. Google AutoML, H2O Driverless AI)')\ncol_info = ('Q33_A_Part_6', 'Automation of full ML pipelines \\(e\\.g\\. Google AutoML, H20 Driverless AI\\)')\n_ = group_replace(col_info, base_info, x_year)","75c04b03":"_ = group_cols_diff(group_questions[group_18][1])\n_","27306a67":"replace_cols_name(_, group_18)","c5a8f51a":"group_result(group_19)","fe1bb93a":"x_year = 2020\n\n# Google AutoML, H2O Driverless AI)\nbase_info = ('Q33_B_Part_6', 'Automation of full ML pipelines (e.g. Google Cloud AutoML, H2O Driverless AI)')\ncol_info = ('Q33_B_Part_6', 'Automation of full ML pipelines \\(e\\.g\\. Google Cloud AutoML, H20 Driverless AI\\)')\n_ = group_replace(col_info, base_info, x_year)","a4d4650a":"_ = group_cols_diff(group_questions[group_19][1])\n_","3e85db8e":"replace_cols_name(_, group_19)","e47107ca":"group_result(group_20)","00dcb099":"x_year = 2020\n\n# H2O Driverless AI\nbase_info = ('Q34_A_Part_2', 'H2O Driverless AI')\ncol_info = ('Q34_A_Part_2', 'H20 Driverless AI')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q34_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q34_A_Part_5', 'Tpot'),\n    ('Q34_A_Part_6', 'Auto-Keras'),\n    ('Q34_A_Part_7', 'Auto-Sklearn'),\n    ('Q34_A_Part_8', 'Auto_ml'),\n    ('Q34_A_Part_9', 'Xcessiv'),\n    ('Q34_A_Part_10', 'MLbox')\n]\ngroup_update(base_info, upd_cols_info, x_year)","c29b3e1f":"x_year = 2021\n\n# Other\nbase_info = ('Q37_A_OTHER', 'Other')\nupd_cols_info = [\n    ('Q37_A_Part_5', 'Amazon Sagemaker Autopilot'),\n    ('Q37_A_Part_6', 'Azure Automated Machine Learning')\n]\ngroup_update(base_info, upd_cols_info, x_year)","66ae6e48":"_ = group_cols_diff(group_questions[group_20][1])\n_","2c156b5d":"replace_cols_name(_, group_20)","8ff692ef":"group_result(group_21)","c95e8bf3":"x_year = 2020\n\n# H2O Driverless AI\nbase_info = ('Q34_B_Part_2', 'H2O Driverless AI')\ncol_info = ('Q34_B_Part_2', 'H20 Driverless AI')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q34_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q34_B_Part_5', 'Tpot'),\n    ('Q34_B_Part_6', 'Auto-Keras'),\n    ('Q34_B_Part_7', 'Auto-Sklearn'),\n    ('Q34_B_Part_8', 'Auto_ml'),\n    ('Q34_B_Part_9', 'Xcessiv'),\n    ('Q34_B_Part_10', 'MLbox')\n]\ngroup_update(base_info, upd_cols_info, x_year)","4afd3342":"x_year = 2021\n\n# Other\nbase_info = ('Q37_B_OTHER', 'Other')\nupd_cols_info = [\n    ('Q37_B_Part_5', 'Amazon Sagemaker Autopilot'),\n    ('Q37_B_Part_6', 'Azure Automated Machine Learning')\n]\ngroup_update(base_info, upd_cols_info, x_year)","d9b8d4de":"_ = group_cols_diff(group_questions[group_21][1])\n_","b127920b":"replace_cols_name(_, group_21)","4819e313":"group_result(group_22)","ee599b88":"group_result(group_23)","031e0e2d":"group_result(group_24)","2c8173e6":"_ = group_cols_diff(group_questions[group_24][1])\nreplace_cols_name(_, group_24)","37923576":"group_result(group_25)","d6dddfd0":"x_year = 2019\n\n# Kaggle Learn Courses\nbase_info = ('Q13_Part_6', 'Kaggle Learn Courses')\ncol_info = ('Q13_Part_6', 'Kaggle Courses \\(i\\.e\\. Kaggle Learn\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q13_Part_12', 'Other')\nupd_cols_info = [\n    ('Q13_Part_5', 'DataQuest')\n]\ngroup_update(base_info, upd_cols_info, x_year)","ddcb930e":"x_year = 2020\n\n# Other\nbase_info = ('Q37_OTHER', 'Other')\nupd_cols_info = [\n    ('Q37_Part_9', 'Cloud-certification programs \\(direct from AWS, Azure, GCP, or similar\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","46b449e2":"x_year = 2021\n\n# Other\nbase_info = ('Q40_OTHER', 'Other')\nupd_cols_info = [\n    ('Q40_Part_9', 'Cloud-certification programs \\(direct from AWS, Azure, GCP, or similar\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","394ef7c4":"_ = group_cols_diff(group_questions[group_25][1])\n_","5a23a816":"replace_cols_name(_, group_25)","fcf8696c":"group_result(group_26)","c1a797f1":"x_year = 2018\n\nbase_info = ('Q38_Part_3', 'Reddit')\ncol_info = ('Q38_Part_3', 'r\/machinelearning')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q38_Part_4', 'Kaggle')\ncol_info = ('Q38_Part_4', 'Kaggle forums')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q38_Part_5', 'Course Forums')\ncol_info = ('Q38_Part_5', 'Fastai forums')\n_ = group_replace(col_info, base_info, x_year)\n\n# YouTube\nbase_info = ('Q38_Part_6', 'YouTube')\ncol_info = ('Q38_Part_6', 'Siraj Raval YouTube Channel')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q38_Part_9', 'Cloud AI Adventures \\(YouTube\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Podcasts\nbase_info = ('Q38_Part_8', 'Podcasts')\ncol_info = ('Q38_Part_8', 'Linear Digressions Podcast')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q38_Part_16', 'Partially Derivative Podcast'),\n    ('Q38_Part_17', 'The Data Skeptic Podcast')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\n# Blogs\nbase_info = ('Q38_Part_13', 'Blogs')\ncol_info = ('Q38_Part_13', 'FastML Blog')\n_ = group_replace(col_info, base_info, x_year)\nupd_cols_info = [\n    ('Q38_Part_14', 'KDnuggets Blog'),\n    ('Q38_Part_18', 'Medium Blog Posts'),\n    ('Q38_Part_19', 'Towards Data Science Blog'),\n    ('Q38_Part_20', 'Analytics Vidhya Blog')\n]\ngroup_update(base_info, upd_cols_info, x_year)\n\nbase_info = ('Q38_Part_12', 'Journals')\ncol_info = ('Q38_Part_12', 'Journal Publications')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q38_Part_21', 'None')\ncol_info = ('Q38_Part_21', 'None\/I do not know')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q38_Part_22', 'Other')\nupd_cols_info = [\n    ('Q38_Part_2', 'Hacker News'),\n    ('Q38_Part_7', 'DataTau News Aggregator'),\n    ('Q38_Part_10', 'FiveThirtyEight\\.com'),\n    ('Q38_Part_11', 'ArXiv & Preprints'),\n    ('Q38_Part_15', \"O'Reilly Data Newsletter\")\n]\ngroup_update(base_info, upd_cols_info, x_year)","c027075a":"x_year = 2019\n\nbase_info = ('Q12_Part_1', 'Twitter')\ncol_info = ('Q12_Part_1', 'Twitter \\(data science influencers\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_3', 'Reddit')\ncol_info = ('Q12_Part_3', 'Reddit \\(r\/machinelearning, r\/datascience, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_4', 'Kaggle')\ncol_info = ('Q12_Part_4', 'Kaggle \\(forums, blog, social media, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_5', 'Course Forums')\ncol_info = ('Q12_Part_5', 'Course Forums \\(forums\\.fast\\.ai, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_6', 'YouTube')\ncol_info = ('Q12_Part_6', 'YouTube \\(Cloud AI Adventures, Siraj Raval, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_7', 'Podcasts')\ncol_info = ('Q12_Part_7', 'Podcasts \\(Chai Time Data Science, Linear Digressions, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_8', 'Blogs')\ncol_info = ('Q12_Part_8', 'Blogs \\(Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q12_Part_9', 'Journals')\ncol_info = ('Q12_Part_9', 'Journal Publications \\(traditional publications, preprint journals, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q12_Part_12', 'Other')\nupd_cols_info = [\n    ('Q12_Part_10', 'Slack Communities \\(ods\\.ai, kagglenoobs, etc\\)'),\n    ('Q12_Part_2', 'Hacker News \\(https\\:\/\/news\\.ycombinator\\.com\/\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","71cc4810":"x_year = 2020\n\nbase_info = ('Q39_Part_1', 'Twitter')\ncol_info = ('Q39_Part_1', 'Twitter \\(data science influencers\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_3', 'Reddit')\ncol_info = ('Q39_Part_3', 'Reddit \\(r\/machinelearning, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_4', 'Kaggle')\ncol_info = ('Q39_Part_4', 'Kaggle \\(notebooks, forums, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_5', 'Course Forums')\ncol_info = ('Q39_Part_5', 'Course Forums \\(forums\\.fast\\.ai, Coursera forums, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_6', 'YouTube')\ncol_info = ('Q39_Part_6', 'YouTube \\(Kaggle YouTube, Cloud AI Adventures, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_7', 'Podcasts')\ncol_info = ('Q39_Part_7', 'Podcasts \\(Chai Time Data Science, O\u2019Reilly Data Show, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_8', 'Blogs')\ncol_info = ('Q39_Part_8', 'Blogs \\(Towards Data Science, Analytics Vidhya, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q39_Part_9', 'Journals')\ncol_info = ('Q39_Part_9', 'Journal Publications \\(peer-reviewed journals, conference proceedings, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q39_OTHER', 'Other')\nupd_cols_info = [\n    ('Q39_Part_2', \"Email newsletters \\(Data Elixir, O'Reilly Data & AI, etc\\)\"),\n    ('Q39_Part_10', 'Slack Communities \\(ods\\.ai, kagglenoobs, etc\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","74e071f9":"x_year = 2021\n\nbase_info = ('Q42_Part_1', 'Twitter')\ncol_info = ('Q42_Part_1', 'Twitter \\(data science influencers\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_3', 'Reddit')\ncol_info = ('Q42_Part_3', 'Reddit \\(r\/machinelearning, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_4', 'Kaggle')\ncol_info = ('Q42_Part_4', 'Kaggle \\(notebooks, forums, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_5', 'Course Forums')\ncol_info = ('Q42_Part_5', 'Course Forums \\(forums\\.fast\\.ai, Coursera forums, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_6', 'YouTube')\ncol_info = ('Q42_Part_6', 'YouTube \\(Kaggle YouTube, Cloud AI Adventures, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_7', 'Podcasts')\ncol_info = ('Q42_Part_7', 'Podcasts \\(Chai Time Data Science, O\u2019Reilly Data Show, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_8', 'Blogs')\ncol_info = ('Q42_Part_8', 'Blogs \\(Towards Data Science, Analytics Vidhya, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\nbase_info = ('Q42_Part_9', 'Journals')\ncol_info = ('Q42_Part_9', 'Journal Publications \\(peer-reviewed journals, conference proceedings, etc\\)')\n_ = group_replace(col_info, base_info, x_year)\n\n# Other\nbase_info = ('Q42_OTHER', 'Other')\nupd_cols_info = [\n    ('Q42_Part_2', \"Email newsletters \\(Data Elixir, O'Reilly Data & AI, etc\\)\"),\n    ('Q42_Part_10', 'Slack Communities \\(ods\\.ai, kagglenoobs, etc\\)')\n]\ngroup_update(base_info, upd_cols_info, x_year)","7d4ddd5b":"_ = group_cols_diff(group_questions[group_26][1])\n_","756dddca":"replace_cols_name(_, group_26)","0c0a05a6":"concat_data = []\nconcat_keys = []\n\nfor x_year in datasets.keys():\n    selected_cols = datasets.get(x_year).filter(regex=\"SA|GA\", axis=1) \\\n                                        .columns.to_list()\n    concat_data.append(datasets.get(x_year).loc[1: , selected_cols])\n    concat_keys.append(x_year)\n\nconcated_data = pd.concat(concat_data, keys=concat_keys)","785a4a34":"dataset_head= {}\n\nfor col_name in concated_data.columns:\n    if col_name not in dataset_head:\n        for x_year in datasets.keys():\n            if col_name in datasets.get(x_year).columns:\n                dataset_head[col_name] = datasets.get(x_year).loc[:0, col_name]\n                break\n\ndataset_head = pd.DataFrame(dataset_head)","58755e7d":"dataset = concated_data.reset_index(level=0) \\\n                            .rename(columns={'level_0': 'Year'}) \\\n                                .reset_index(drop=True)\ndataset_description = pd.DataFrame({\"Year\": [\"Dataset year\"]}).join(dataset_head)","50a18476":"print(dataset.shape)\nprint(dataset_description.shape)","31fc624d":"dataset_description","71aec40a":"# Col: 'Duration'\n_ = {'SA0': 'Duration'}\ndataset.rename(columns=_, inplace=True)\ndataset_description.rename(columns=_, inplace=True)\n\nif pd.api.types.is_string_dtype(dataset['Duration']):\n    dataset['Duration'] = (dataset['Duration'].astype(int) \/ 60).round(2)\n    dataset_description['Duration'] = 'Duration (in minutes)'","c1dfe1d7":"# Cols: Strip all SAGA cols\nsaga_cols = dataset.filter(regex=\"SA|GA\", axis=1).columns.to_list()\ndataset[saga_cols] = dataset[saga_cols].apply(lambda col: col.str.strip())\n\n# Col: Age\nage_col = \"SA1\"\n_ = {'70-79': '70+', '80+': '70+'}\ndataset[age_col].replace(_, inplace=True)\n\n# Col: Gender\ngender_col = \"SA2\"\n_ = {'Male': 'Man', 'Female': 'Woman'}\ndataset[gender_col].replace(_, inplace=True)\n\n# Col: Country\ncountry_col = \"SA3\"\nselected_threshold = 35\nif dataset[country_col].nunique() > selected_threshold:\n    all_countries = pd.DataFrame(dataset[country_col].value_counts()).T\n    _ = all_countries.pop('Other')\n    popular_countries = all_countries.iloc[:, :selected_threshold -1].columns.to_list()\n    other_countries = [x_country for x_country in all_countries\n                       if x_country not in popular_countries]\n\n    dataset[country_col] = dataset[country_col].replace(other_countries, 'Other')\n    \n_ = {'United States of America': 'USA',\n     'United Kingdom of Great Britain and Northern Ireland': 'Britain',\n     'Iran, Islamic Republic of...': 'Iran'}\ndataset[country_col].replace(_, inplace=True)\n\n# Col: Degree or not degree\ndegree_col = \"SA4\"\n_ = {'Professional doctorate': 'Professional degree',\n     'No formal education past high school': 'Other',\n     'Some college\/university study without earning a bachelor\u2019s degree': 'Other'}\ndataset[degree_col].replace(_, inplace=True)\n\n# Col: Employed\nemployed_col = \"SA5\"\n_ = {'Data Analyst': 'Analyst (Data, Business, etc)',\n     'Business Analyst': 'Analyst (Data, Business, etc)',\n     'Marketing Analyst': 'Analyst (Data, Business, etc)',\n     'Manager': 'Manager (Product, Project, etc)',\n     'Product Manager': 'Manager (Product, Project, etc)',\n     'Product\/Project Manager': 'Manager (Product, Project, etc)',\n     'Program\/Project Manager': 'Manager (Product, Project, etc)',\n     'Research Scientist': 'Research Scientist (Assistant)',\n     'Research Assistant': 'Research Scientist (Assistant)',     \n     'DBA\/Database Engineer': 'Other',\n     'Data Scientist': 'Data Scientist (ML Engineer)',\n     'Machine Learning Engineer': 'Data Scientist (ML Engineer)',\n     'Currently not employed': 'Not employed',\n     'Chief Officer': 'Other',\n     'Consultant': 'Other',\n     'Principal Investigator': 'Other',\n     'Salesperson': 'Other',\n     'Data Journalist': 'Other',\n     'Developer Advocate': 'Other',\n     'Developer Relations\/Advocacy': 'Other'\n}\ndataset[employed_col].replace(_, inplace=True)\n\n# Col: Coding time\ncoding_time_col = \"SA6\"\n_ = {'< 1 year': '< 1 years',\n     '1-2 years': '1-3 years',\n     '20-30 years': '20+ years',\n     '30-40 years': '20+ years',\n     '40+ years': '20+ years',\n     'I have never written code but I want to learn': 'I have never written code',\n     'I have never written code and I do not want to learn': 'I have never written code'\n}\ndataset[coding_time_col].replace(_, inplace=True)\n\n# Col: Coding lang\ncoding_lang_col = \"SA7\"\n_ = {'C': 'C\/C++',\n     'C++': 'C\/C++',\n     'Go': 'Other',\n     'Swift': 'Other',\n     'Scala': 'Other',\n     'Bash': 'Other',\n     'Julia': 'Other',\n     'TypeScript': 'Other',\n     'SAS': 'Other',\n     'VBA': 'Other'\n}\ndataset[coding_lang_col].replace(_, inplace=True)\n\n# Col: Device\ndevice_col = \"SA8\"\n_ = {'A laptop': 'A personal computer',\n     'A personal computer or laptop': 'A personal computer',\n     'A personal computer \/ desktop': 'A personal computer',\n     'A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)': 'A cloud computing platform',\n     'A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)': 'A deep learning workstation'\n}\ndataset[device_col].replace(_, inplace=True)\n\n# Col: Used TPU\nused_tpu_col = \"SA9\"\n_ = {'More than 25 times': '25+ times'\n}\ndataset[used_tpu_col].replace(_, inplace=True)\n\n# Col: Used ML methods\nused_ml_col = \"SA10\"\n_ = {'Under 1 year': '< 1 years',\n     '< 1 year': '< 1 years',\n     '10-15 years': '10+ years',\n     '10-20 years': '10+ years',\n     '20+ years': '10+ years',\n     '20 or more years': '10+ years',\n     \n     'I do not use machine learning methods': 'I do not use ML',\n     'I have never studied machine learning and I do not plan to': 'I do not use ML',\n     'I have never studied machine learning but plan to learn in the future': 'I do not use ML'\n}\ndataset[used_ml_col].replace(_, inplace=True)\n\n# Col: Industry\nindustry_col = \"SA11\"\n_ = {'I am a student': np.nan\n}\ndataset[industry_col].replace(_, inplace=True)\n# Year    Notna\n# 2018    21685  <<< del 4658 'I am a student'\n# 2021    16325\n\n# Col: Size company\ncompany_col = \"SA12\"\n_ = {'10,000 or more employees': '10,000+ employees',\n     '> 10,000 employees': '10,000+ employees'\n}\ndataset[company_col].replace(_, inplace=True)\n\n# Col: Workloads\nworkloads_col = \"SA13\"\n_ = {'10-14': '10-19',\n     '15-19': '10-19'\n}\ndataset[workloads_col].replace(_, inplace=True)\n\n# Col: Compensation\ncompensation_col = \"SA15\"\n_ = {'I do not wish to disclose my approximate yearly compensation': np.nan,\n     '$0-999': '0-10,000',\n     '1,000-1,999': '0-10,000',\n     '2,000-2,999': '0-10,000',\n     '3,000-3,999': '0-10,000',\n     '4,000-4,999': '0-10,000',\n     '5,000-7,499': '0-10,000',\n     '7,500-9,999': '0-10,000',\n\n     '10,000-14,999': '10,000-50,000',\n     '15,000-19,999': '10,000-50,000',\n     '10-20,000': '10,000-50,000',\n     '20,000-24,999': '10,000-50,000',\n     '20-30,000': '10,000-50,000',\n     '25,000-29,999': '10,000-50,000',\n     '30,000-39,999': '10,000-50,000',\n     '30-40,000': '10,000-50,000',\n     '40,000-49,999': '10,000-50,000',\n     '40-50,000': '10,000-50,000',\n     \n     '50,000-59,999': '50,000-100,000',\n     '50-60,000': '50,000-100,000',\n     '60,000-69,999': '50,000-100,000',\n     '60-70,000': '50,000-100,000',\n     '70,000-79,999': '50,000-100,000',\n     '70-80,000': '50,000-100,000',\n     '80,000-89,999': '50,000-100,000',\n     '80-90,000': '50,000-100,000',\n     '90,000-99,999': '50,000-100,000',\n     '90-100,000': '50,000-100,000',\n     \n     '100,000-124,999': '100,000-150,000',\n     '100-125,000': '100,000-150,000',\n     \n     '125,000-149,999': '100,000-150,000',\n     '125-150,000': '100,000-150,000',\n     \n     '150,000-199,999': '150,000-200,000',\n     '150-200,000': '150,000-200,000',\n     \n     '200,000-249,999': '200,000-250,000',\n     '200-250,000': '200,000-250,000',\n     \n     '250,000-299,999': '250,000-300,000',\n     '250-300,000': '250,000-300,000',\n     \n     '300,000-499,999': '300,000-500,000',\n     '300,000-500,000': '300,000-500,000',\n     '300-400,000': '300,000-500,000',\n     '400-500,000': '300,000-500,000',\n     \n     '$500,000-999,999': '500,000+',\n     '> $500,000': '500,000+',\n     '>$1,000,000': '500,000+'\n}\ndataset[compensation_col].replace(_, inplace=True)\n\n# Col: Use products\nuse_products_col = \"SA18\"\n_ = {'Amazon Athena': 'Amazon (Redshift, RDS, Athena, Aurora, etc)',\n     'Amazon Aurora': 'Amazon (Redshift, RDS, Athena, Aurora, etc)',\n     'Amazon DynamoDB': 'Amazon (Redshift, RDS, Athena, Aurora, etc)',\n     'Amazon RDS': 'Amazon (Redshift, RDS, Athena, Aurora, etc)',\n     'Amazon Redshift': 'Amazon (Redshift, RDS, Athena, Aurora, etc)',\n     \n     'Google Cloud BigQuery': 'Google Cloud (BigQuery, BigTable, SQL, etc)',\n     'Google Cloud BigTable': 'Google Cloud (BigQuery, BigTable, SQL, etc)',\n     'Google Cloud Firestore': 'Google Cloud (BigQuery, BigTable, SQL, etc)',\n     'Google Cloud SQL': 'Google Cloud (BigQuery, BigTable, SQL, etc)',\n     'Google Cloud Spanner': 'Google Cloud (BigQuery, BigTable, SQL, etc)',\n     \n     'Microsoft SQL Server': 'Microsoft (SQL Server, Access, Azure, etc)',\n     'Microsoft Access': 'Microsoft (SQL Server, Access, Azure, etc)',\n     'Microsoft Azure Cosmos DB': 'Microsoft (SQL Server, Access, Azure, etc)',\n     'Microsoft Azure Data Lake Storage': 'Microsoft (SQL Server, Access, Azure, etc)',\n     'Microsoft Azure SQL Database': 'Microsoft (SQL Server, Access, Azure, etc)',\n     \n     'PostgresSQL': 'PostgreSQL'\n}\ndataset[use_products_col].replace(_, inplace=True)\n\n# Col: Use business intelligence tools\nuse_bi_col = \"SA19\"\n_ = {'TIBCO Spotfire': 'Other',\n     'Tableau CRM': 'Other',\n     'Looker': 'Other',\n     'Microsoft Azure Synapse': 'Other',\n     'Domo': 'Other',\n     'Sisense': 'Other',\n     'Einstein Analytics': 'Other',\n     'Thoughtspot': 'Other'\n}\ndataset[use_bi_col].replace(_, inplace=True)\n\n# Col: Use tool to analyze data\nuse_tool_col = \"SA20\"\n_ = {'Local or hosted development environments (RStudio, JupyterLab, etc.)':\n         'Local development environments (RStudio, JupyterLab, etc.)'}\ndataset[use_tool_col].replace(_, inplace=True)","54a70517":"def save_to_json(result, file_name, dir_to_save='info_data'):\n    if not os.path.exists(dir_to_save) and dir_to_save.isidentifier():\n        os.mkdir(dir_to_save)\n\n    if os.path.isdir(dir_to_save):\n        path_to_file = os.path.join(dir_to_save, file_name)\n    else:\n        path_to_file = file_name\n        \n    with open(path_to_file, \"w\") as json_file:\n        json.dump(result, json_file, indent=4)","9cab9ea5":"# save_to_json(columns_info, \"columns_info.json\")\n# save_to_json(datasets_info, \"datasets_info.json\")\n# save_to_json(questions_info, \"questions_info.json\")\n\n# dataset.to_csv(\"kaggle_survey_2018-2021_data.csv\", index=False)\n# dataset_description.to_csv(\"kaggle_survey_2018-2021_header.csv\", index=False)","46f13ec4":"dataset.info(memory_usage='deep', verbose=False)","b66f2f47":"sa_cols = dataset.filter(like=\"SA\").columns.to_list()\nsa_cols_stats = dataset.groupby('Year').count()[sa_cols].T \\\n                        .join(dataset_description[sa_cols].T)\nsa_cols_stats","ce7bb39a":"dataset[sa_cols].describe().T","d01616f1":"def group_stats(group_number, is_year=False):\n    find_group = \"GA\" + str(group_number) + \"_\"\n    ga_cols = dataset.filter(like=find_group).columns.to_list()\n    \n    if ga_cols:\n        questions = questions_info.get('group questions')[group_number][1]\n        question = questions[0]\n        print(\"\\nGroup question': {}\\n\".format(question))\n        \n        info_stats = dataset.filter(like=find_group).describe().T\n        year_stats = dataset.groupby('Year').count()[ga_cols].T \\\n                                    .join(info_stats[['top', 'count']]) \\\n                                        .rename(columns={'top': 'answer'})\n        if is_year == True:\n            return year_stats\n        else:\n            return info_stats","5dbff5f0":"group_stats(group_26)","d90c3476":"group_stats(group_26, is_year=True).sort_values(by='count', ascending=False)","b54d5e48":"# ...","e5303bc6":"### === Show group ===","b119ee9f":"## 3.2. Multi columns","e32060bd":"### Replace column names","56986fc7":"### === Show group ===","bf2ac860":"### === Show group ===","205b1bda":"# 1. Libraries & Settings","2c463188":"### Replace column names","ff043e52":"### Replace column names","25c61a08":"### Replace group","39a0e886":"### Check group","a08eb3eb":"### Replace group","0462047c":"### Check group","7ae186ef":"### Replace group","d072342d":"### Check group","6c117bfd":"### Replace group","0d50f6b5":"## 7.2 Group answers","9a35aab0":"### Replace column names","bcb48be8":"### Check group","062ce24b":"### Replace group","b7318c8d":"### === Show group ===","44aa5ca7":"### Replace group","1205a118":"### Replace column names","2ea853e4":"### Check group","32999a7f":"# 6. Saving information","441e44e8":"### Replace group","4ce52f11":"### Check group","eeccc987":"### Replace group","0a868c15":"### Replace column names","51a96ee4":"### === Show group ===","46db98e3":"### Replace column names","6a29ea8d":"# 3. Main changes","dec30375":"### Replace column names","f8982961":"### === Show group ===","eb16cad5":"### === Show group ===","55de3264":"### Check group","64588380":"### === Show group ===","9396e085":"### === Show group ===","93ab767f":"### Replace group","1ab8e9dc":"### Replace column names","82add04a":"### === Show group ===","00720a16":"### Replace group","2e576f6e":"### === Show group ===","8159b189":"### Replace column names","11593e5e":"### Replace column names","fb20249f":"### Replace column names","431eaba0":"### Replace group","78e40510":"### Replace group","188194c4":"### Check group","8f526a23":"### === Show group ===","d0c6a316":"### === Show group ===","04a2aa0a":"### === Show group ===","56f9c906":"### Check group","ae7f1dcf":"### === Show group ===","bbc0b061":"# 4. Create main dataset","55ee4120":"### === Show group ===","de774802":"# 5. Additional changes","c10012c4":"### Replace column names","e8681145":"### === Show group ===","f10d43da":"### Replace column names","d9f3be7a":"### === Show group ===","2dcd3ae3":"### Replace column names","5f20e128":"### Replace column names","ec4a4fbb":"### Replace column names","af351dd0":"### Replace column names","78b7e721":"# 7. Simple data analysis","a91462be":"### Replace column names","53c069ca":"### Replace column names","282214b9":"### Check group","d0107d0e":"## 3.1. Single columns","d00888ae":"# 2. Loading data","573b3b0e":"### Check group","83291633":"### Check group","f84a89fa":"### Check group","0051bbde":"### === Show group ===","c5c17e94":"### Check result","48d5f04e":"### Replace group","3ef01230":"### Replace group","dd3c192b":"### === Show group ===","e775238d":"### Check group","31af5df9":"### === Show group ===","95756d8f":"### === Show group ===","c67caead":"### Replace group","07032bbd":"### === Show group ===","600d3028":"### Check group","e78d00fd":"### Replace column names","fdea6460":"## 7.1 Single answers","4c2a4ec1":"### === Show group ===","0f8c8914":"### Check group","b85d18ca":"### Replace group","aa6a762c":"### Replace column names","033cc52f":"### Replace column names","589f288e":"### Replace group","d10fd169":"### Check group","ec7faff4":"### Replace group","a3351dd1":"### Check group","4a859ef3":"### Replace group","0318ab07":"### === Show group ===","e30ff2f5":"### === Show group ===","8fc44e86":"### Check group","cccaf7c8":"### === Show group ===","aa1c5f7c":"### Check group","0400455e":"### Replace column names"}}