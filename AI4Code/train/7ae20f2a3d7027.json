{"cell_type":{"a1f84966":"code","76a6d9a1":"code","5a7d77f6":"code","53d01dd8":"code","80b6d8d5":"code","c90c87b5":"code","e59b9315":"code","d580a64b":"code","66d43991":"markdown","d459271e":"markdown","ea74b07e":"markdown","11d1b0cb":"markdown","9f9be45e":"markdown","21b23f99":"markdown","6e0a527d":"markdown","62dbc375":"markdown"},"source":{"a1f84966":"import gc\nimport os\nimport joblib\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom PIL import Image, ImageOps\n\ntf.random.set_seed(42)\ntf.keras.mixed_precision.experimental.set_policy('mixed_float16')\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nmpl.rcParams['figure.dpi'] = 600\n\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('WARNING')","76a6d9a1":"cancer_dir = '..\/input\/brian-tumor-dataset\/Brain Tumor Data Set\/Brain Tumor Data Set\/Brain Tumor\/'\nhealthy_dir = '..\/input\/brian-tumor-dataset\/Brain Tumor Data Set\/Brain Tumor Data Set\/Healthy\/'\n\ncancer_files = os.listdir(cancer_dir)\nhealthy_files = os.listdir(healthy_dir)\n\nNEW_SIZE = 128\n\nx = np.zeros((len(cancer_files) + len(healthy_files), NEW_SIZE, NEW_SIZE), dtype = np.float32)\n\nfor i in range(len(cancer_files)):\n    image = Image.open(cancer_dir + cancer_files[i])\n    x[i, :, :] = np.asarray(ImageOps.grayscale(image).resize((NEW_SIZE, NEW_SIZE)))\n\nfor i in range(len(healthy_files)):\n    image = Image.open(healthy_dir + healthy_files[i])\n    x[i + len(cancer_files), :, :] = np.asarray(ImageOps.grayscale(image).resize((NEW_SIZE, NEW_SIZE)))\n\ny = np.array([True] * len(cancer_files) + [False] * len(healthy_files))\n\ngc.collect()","5a7d77f6":"i = np.random.randint(len(cancer_files), size = 100)\n\nfig, axs = plt.subplots(10, 10, sharex = True, sharey = True, figsize = (15, 15))\nplt.subplots_adjust(wspace = .05, hspace = .05)\n\nx_select = x[i, :, :]\n\nfor i in range(10):\n    for j in range(10):\n        k = i * 10 + j\n        axs[i][j].imshow(x_select[k, :, :], cmap = 'gray', vmin = 0, vmax = 255)\n        axs[i][j].axes.get_xaxis().set_visible(False)\n        axs[i][j].axes.get_yaxis().set_visible(False)","53d01dd8":"i = np.random.randint(len(healthy_files), size = 100) + len(cancer_files)\n\nfig, axs = plt.subplots(10, 10, sharex = True, sharey = True, figsize = (15, 15))\nplt.subplots_adjust(wspace = .05, hspace = .05)\n\nx_select = x[i]\n\nfor i in range(10):\n    for j in range(10):\n        k = i * 10 + j\n        axs[i][j].imshow(x_select[k], cmap = 'gray', vmin = 0, vmax = 255)\n        axs[i][j].axes.get_xaxis().set_visible(False)\n        axs[i][j].axes.get_yaxis().set_visible(False)","80b6d8d5":"from tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\ndef define_model(input_shape, n_classes, n_conv_branches = 1, dropout = 0.2, reg_alpha = 1e-3):\n    inputs = layers.Input(shape = input_shape)\n    \n    b_in = layers.experimental.preprocessing.Rescaling(1. \/ 255)(inputs)\n    \n    branches = [b_in] * n_conv_branches\n    \n    for i in range(n_conv_branches):\n        for filter_size in [32, 64, 128, 128, 128, 128, 128]:\n            branches[i] = layers.Conv2D(\n                filters = filter_size,\n                kernel_size = 3,\n                padding = 'same',\n                kernel_regularizer = regularizers.L2(reg_alpha),\n                bias_regularizer = regularizers.L2(reg_alpha)\n            )(branches[i])\n            branches[i] = layers.MaxPool2D(pool_size = (2, 2))(branches[i])\n            branches[i] = layers.ReLU()(branches[i])\n            branches[i] = layers.Dropout(dropout)(branches[i])\n    \n    if n_conv_branches > 1:\n        b_out = layers.concatenate(branches)\n        b_out = layers.Flatten()(b_out)\n    else:\n        b_out = layers.Flatten()(branches[0])\n    \n    b_out = layers.Dense(\n        units = 128,\n        kernel_regularizer = regularizers.L2(reg_alpha),\n        bias_regularizer = regularizers.L2(reg_alpha)\n    )(b_out)\n    b_out = layers.BatchNormalization()(b_out)\n    b_out = layers.ReLU()(b_out)\n    b_out = layers.Dropout(dropout)(b_out)\n    \n    outputs = layers.Dense(units = n_classes)(b_out)\n    \n    return Model(inputs, outputs)","c90c87b5":"model = define_model(\n    (x.shape[1], x.shape[2], 1),\n    2,\n    2,\n    0.2,\n    1e-3\n)\n\ntf.keras.utils.plot_model(model, show_shapes = True, show_layer_names = False)","e59b9315":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import StratifiedKFold\n\nN_SPLITS = 10\nCHECKPOINT_DIR = '.\/checkpoint'\n\ncv = StratifiedKFold(n_splits = N_SPLITS, random_state = 42, shuffle = True)\n\ncv_val_scores = np.zeros(N_SPLITS)\nhistories = []\n\nk = 0\n\nfor train_i, val_i in cv.split(x, y):\n    x_train = x[train_i, :]\n    x_valid = x[val_i, :]\n    \n    y_train = y[train_i]\n    y_valid = y[val_i]\n    \n    gc.collect()\n    \n    optimizer = Adam(\n        learning_rate = 5e-4,\n    )\n    \n    model = define_model(\n        (x.shape[1], x.shape[2], 1),\n        2,\n        2,\n        0.2,\n        1e-3\n    )\n    \n    model.compile(\n        optimizer = optimizer,\n        loss = SparseCategoricalCrossentropy(from_logits = True),\n        metrics = ['accuracy']\n    )\n    \n    checkpoint_call = ModelCheckpoint(\n        filepath = CHECKPOINT_DIR,\n        save_weights_only = True,\n        monitor = 'val_accuracy',\n        mode = 'max',\n        save_best_only = True\n    )\n    \n    stopping_call = EarlyStopping(\n        monitor = 'val_accuracy',\n        patience = 50,\n        mode = 'max'\n    )\n    \n    history = model.fit(\n        x_train, y_train,\n        validation_data = (x_valid, y_valid),\n        epochs = 200,\n        callbacks = [checkpoint_call, stopping_call],\n        batch_size = 64,\n    )\n    \n    histories += [history]\n    \n    model.load_weights(CHECKPOINT_DIR)\n    predictor_model = tf.keras.Sequential([model, layers.Softmax()])\n    \n    cv_val_scores[k] = model.evaluate(x_valid, y_valid)[1]\n    \n    k += 1","d580a64b":"print('Validation AUC: {:.6} \u00b1 {:.4}'.format(cv_val_scores.mean(), cv_val_scores.std()))","66d43991":"# Explore datasets","d459271e":"# Model\n\nThis is a computer vision problem, so CNNs are likely to perform well.","ea74b07e":"# Preamble\n\nThis dataset consists of metadata in csv format, and images that we need to import. The images also need to be converted to grayscale and resized all to the same size. In this notebook we will use 128x128, which is a good compromise between speed and accuracy.","11d1b0cb":"Let's plot an instance of our model:","9f9be45e":"## Cross-validation","21b23f99":"## 100 random healthy images","6e0a527d":"## Architecture\n\nIn the next hidden cell a function to create our model is defined.","62dbc375":"## 100 random cancer images"}}