{"cell_type":{"01472d42":"code","56272c1f":"code","86fd4198":"code","771d8d01":"code","966af54a":"code","b63aa1f3":"code","35bea1b3":"code","ad22651f":"code","d70b97cf":"code","682676a2":"code","242060d3":"code","a6e4c522":"code","5a98d57b":"markdown","fbb9216f":"markdown","065a6f8a":"markdown","a3df1462":"markdown","c6680be7":"markdown","35483962":"markdown","72ba3f9f":"markdown"},"source":{"01472d42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56272c1f":"df=pd.read_csv('..\/input\/ntt-data-global-ai-challenge-06-2020\/COVID-19_and_Price_dataset.csv')","86fd4198":"df.shape","771d8d01":"df=df.drop(['Date'], axis=1)","966af54a":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(df)","b63aa1f3":"Scaled_data= scaler.transform(df)","35bea1b3":"from sklearn.decomposition import PCA","ad22651f":"pca=PCA(n_components=2)\npca.fit(Scaled_data)","d70b97cf":"x_pca=pca.transform(Scaled_data)","682676a2":"Scaled_data.shape","242060d3":"x_pca.shape","a6e4c522":"import matplotlib.pyplot as plt\nplt.figure(figsize=(8,6))\nplt.scatter(x_pca[:,0],x_pca[:,1])\nplt.xlabel('first component')\nplt.ylabel('second component')","5a98d57b":"Shape of the Dataset consist of 125 rows and 849 columns","fbb9216f":"Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a compressed form.\n\nGenerally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\n\nIn the example below, we use PCA and select 2 principal components from 849 features","065a6f8a":"**Plotted the compressed data and found the some correlation in the dataset**","a3df1462":"Importing Sklearn Library for standard scaler function","c6680be7":"Importing PCA from sklearn to reduce the dimension of the dataset and preserve the relevant features.","35483962":"**Importing Dataset Covid19 and price dataset**","72ba3f9f":"After applying PCA techique Dimension of the dataset readuced to 2 from 849"}}