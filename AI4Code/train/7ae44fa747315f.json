{"cell_type":{"23f7822c":"code","64148c28":"code","7b0370a5":"code","3fb3aec7":"code","21c1a69f":"code","33679ff9":"code","ac20d035":"code","9206ed82":"code","8af556a5":"code","91bff88e":"code","01ccf124":"code","9d710bb6":"code","764b9454":"code","301e0e10":"code","d1cd7577":"code","877b6c19":"code","e9dac0f4":"code","c8fdd2d5":"code","cb0946ac":"code","07ae2dd7":"code","fcd52fa8":"code","2d921355":"code","d6b2b5c6":"code","ec4f2109":"code","293ed8ca":"code","c577b6cb":"code","9321db98":"code","e6b70907":"code","3bb833af":"code","5ef4af92":"code","920daec5":"code","9fff0fbb":"code","161ba669":"code","3b084ba2":"code","ad2558cb":"code","99b2ec8a":"code","d5d43a11":"code","06cf3e65":"code","958fc0df":"code","866f9cea":"code","5ae9ac68":"code","dca808ad":"code","0e4b2a91":"code","52a659c4":"code","a382ccc4":"code","f8fcedf3":"markdown","52b1774f":"markdown","9fcdf98f":"markdown","bbbb100a":"markdown","c2825f99":"markdown","5e51e7e1":"markdown","0bf925a3":"markdown","56595516":"markdown","94ac1dba":"markdown","1eb0571c":"markdown","b52feb9b":"markdown","570b62aa":"markdown","503269fc":"markdown","b1c643ff":"markdown","c6b0f69d":"markdown","35303537":"markdown","6e8b1a6a":"markdown","ae6c114f":"markdown","9767abf0":"markdown","859555a8":"markdown","413f7ac8":"markdown","a973a39a":"markdown","525e8209":"markdown","f9f93105":"markdown"},"source":{"23f7822c":"\nimport pandas as pd \n\nall_food_data = pd.read_csv( \"https:\/\/static.openfoodfacts.org\/data\/en.openfoodfacts.org.products.csv\", sep=\"\\t\", encoding=\"utf-8\") # raw dataframe\n\nall_food_data.info() # datasets infos and memory usage","64148c28":"\nall_food_data.shape # this returns the database size","7b0370a5":"i = 0 # initialize column count\ncolnum = []\ncolname = []\nnullpc = []\nfor col in all_food_data:\n    i +=1 # update the counter\n    nulsum = sum(pd.isnull(all_food_data[col])) # sum of null value for the column (empty cells)\n    numrows = len(all_food_data)\n    nuls_pourcent = (sum(pd.isnull(all_food_data[col]))\/numrows)*100  # % of null value for the column\n    r_nuls_pourcent = round(nuls_pourcent, 3) # return only the first 3 digits after the comma of the percentage float value\n    #create columnstats database\n    colnum.append(i) # first column: column number\n    colname.append(col) # column name\n    nullpc.append(r_nuls_pourcent) # % null values\n    #print('Column ',i, ' name: ',col, '*   Null values (NaN) in this column: ', nulsum, ' % null: ', r_nuls_pourcent) # print the information for each row","3fb3aec7":"df_nul = pd.DataFrame({'num':colnum, 'name':colname, '%null':nullpc})\ndf_nul = df_nul.sort_values(by='%null', ascending=False)\n","21c1a69f":"import matplotlib.pyplot as plt\nplt.figure(figsize=(23,8))\n\nplt.bar(df_nul['name'], df_nul['%null'])\nplt.title('NaN % in the dataframe', color=\"red\", fontsize = 14)\nplt.ylabel('% empty cell in the column', color=\"red\", fontsize = 14)\nplt.xticks(rotation='vertical')\nplt.rcParams['figure.constrained_layout.use'] = True\nplt.savefig(\"null.png\", format=\"PNG\", dpi = 100)","33679ff9":"df_nul[df_nul['name'].str.contains(r'carbon(?!$)')] # check for % null in the carbon footprint column","ac20d035":"#indexcarbon = df_nul.name[df_nul.name == 'carbon-footprint_100g'].index.tolist()\nindexcarbon = df_nul.set_index('name').index.get_loc( 'carbon-footprint_100g')\nprint ('row index containing carbon footprint % null is : ',indexcarbon)\nnulthresold = df_nul.iloc[indexcarbon, 2]\nprint('carbon footprint % null is : ',nulthresold)","9206ed82":"\ndf_del = df_nul[df_nul['%null'] > nulthresold] \ndf_keep = df_nul[df_nul['%null'] <= nulthresold] # data to keep\nprint(df_del.shape) # check number of columns that get left out \ndf_keep.head()","8af556a5":"enoughfilled_list = df_keep['name'].tolist()\nenoughfilled_list\n","91bff88e":"new_food_data = all_food_data[enoughfilled_list] # create a new dataframe that contains only listed columns\nnew_food_data.shape","01ccf124":"    no_duplicates__food_data = new_food_data.drop_duplicates(keep=False) #remove duplicates \n    duplicateRowsDF = no_duplicates__food_data[no_duplicates__food_data.duplicated(keep=False)] # create a variable that identify any duplicate row in the dataframe\n    print(\"All Duplicate Rows based on all columns are :\")\n    print(duplicateRowsDF)\n    print('no more duplicates: yes!')","9d710bb6":"no_duplicates__food_data.shape","764b9454":"print(list(no_duplicates__food_data)) # get headers","301e0e10":"nonan_df = no_duplicates__food_data.dropna(subset=['carbon-footprint_100g']) #drop most empty rows from the thresold category and check contents\nnonan_df.head()","d1cd7577":"df_filteren = nonan_df.filter(regex='_en')\nen = list(df_filteren)\ndf_filtertag = nonan_df.filter(regex='_tag')\ntag = list(df_filtertag)\nfilterlist= en + tag\nprint(filterlist)","877b6c19":"no_duplicates__food_data.drop(filterlist, axis = 1, inplace = True)\nno_duplicates__food_data.shape","e9dac0f4":"# are French and British score the same? (suspiciously they have same %null)\nprint(nonan_df['nutrition-score-fr_100g'].equals(nonan_df['nutrition-score-uk_100g'])) # function that checks whether two columns contain same values","c8fdd2d5":"# first step : lists of columns we are interested for each section of the statistical study. \n\n\neco_raw = ['product_name','nutrition-score-fr_100g', 'nutrition_grade_fr','nova_group', 'pnns_groups_1', 'pnns_groups_2', 'main_category', 'categories', 'carbon-footprint_100g', 'carbon-footprint-from-meat-or-fish_100g', 'ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n']\ndf_eco_raw = no_duplicates__food_data[eco_raw] # this is the corresponding dataframe with raw data\n\n\n","cb0946ac":"print(df_eco_raw.pnns_groups_2.value_counts(dropna=True)) # sensible subdivision, even if a large part is unknown\nprint(df_eco_raw.pnns_groups_2.shape)","07ae2dd7":"df_eco_raw['pnns_groups_2'] = df_eco_raw['pnns_groups_2'].str.lower()\n","fcd52fa8":"df_eco_raw","2d921355":"print(df_eco_raw.pnns_groups_1.value_counts(dropna=True)) # very broad. Grouping fish, meat, eggs together would bias environmental impact ","d6b2b5c6":"# categories section has too many entries to be representative, stats would be confusing\ndf_cat_count = pd.value_counts(df_eco_raw['categories'].values, sort=True) # transform the counts in a database\n\ndf_cat_count = df_cat_count.reset_index()\ndf_cat_count.columns = ['category', 'count']\ndf_cat_count = df_cat_count[df_cat_count['count'] > 500] # showing only those above 500 it can be seen that some are very similar \nprint (df_cat_count)","ec4f2109":"print(df_eco_raw.main_category.value_counts(dropna=True))","293ed8ca":"# many categories in the main_category section. Some containing only one product are not descriptive\ndf_cat_count = pd.value_counts(df_eco_raw['main_category'].values, sort=True) # transform the counts in a database\n\ndf_cat_count = df_cat_count.reset_index()\ndf_cat_count.columns = ['main_category', 'count']\ndf_cat_count = df_cat_count[df_cat_count['count'] > 100] # filter low counts\nprint (df_cat_count)\n\n","c577b6cb":"grades = ['nutrition_grade_fr','nutrition-score-fr_100g']\ndf_food_grades = no_duplicates__food_data[grades] \ndf_food_grades = df_food_grades.groupby(['nutrition_grade_fr']).mean()\ndf_food_grades = df_food_grades.reset_index(level=0, inplace=False) # nutrition grade as first column\ndf_food_grades\n","9321db98":"import matplotlib.pyplot as plt\nplt.figure(figsize=(5,5))\nplt.scatter(df_food_grades['nutrition_grade_fr'],  df_food_grades['nutrition-score-fr_100g'])\n\nplt.xlabel('nutrition_grade_fr', color=\"red\", fontsize = 14)\nplt.ylabel('average nutrition_score_fr', color=\"red\", fontsize = 14)\nfrom google.colab import files\nplt.savefig(\" Nutrition grade.png\", format=\"PNG\")\n","e6b70907":"df_food_grades['nutrition_grade_fr_n'] = 22 - df_food_grades['nutrition-score-fr_100g']\ndf_food_grades = df_food_grades.round(0)\ndf_food_grades.head()","3bb833af":"plt.figure(figsize=(5,5))\nplt.scatter(df_food_grades['nutrition_grade_fr'],  df_food_grades['nutrition_grade_fr_n'])\n\nplt.xlabel('nutrition_grade_fr', color=\"red\", fontsize = 14)\nplt.ylabel('nutrition_av_grade_fr', color=\"red\", fontsize = 14)\nfrom google.colab import files\nplt.savefig(\" Nutrition grade 2.png\", format=\"PNG\")","5ef4af92":"no_duplicates__food_data['Nutritional quality 100g'] = 1\/no_duplicates__food_data['nutrition-score-fr_100g'] # inverse of nutritional score\nplt.figure(figsize=(10,5))\nplt.scatter(no_duplicates__food_data['Nutritional quality 100g'], no_duplicates__food_data['nutrition-score-fr_100g'])\nplt.xlabel('quality', color=\"red\", fontsize = 14)\nplt.ylabel('Nutritional score', color=\"red\", fontsize = 14)","920daec5":"# convert food grades into numbers based on the category average food score\ndf_eco_raw ['nutrition_grade_fr_n'] = df_eco_raw ['nutrition_grade_fr']\ndf_eco_raw  = df_eco_raw.replace({'nutrition_grade_fr_n': {'a': 25, 'b': 21, 'c': 16, 'd': 8, 'e':1}})","9fff0fbb":"nova = ['nova_group','nutrition_grade_fr_n'] # how much is the food processed? nove class describes it\ndf_food_nova = df_eco_raw[nova] \ndf_food_nova = df_food_nova.groupby(['nova_group']).mean()\ndf_food_nova = df_food_nova.reset_index(level=0, inplace=False) # gets nova class to the first column\ndf_food_nova\n\n","161ba669":"import numpy as np\n\nfrom sklearn import linear_model\nX0 = np.matrix([np.ones(df_food_nova.shape[0]),df_food_nova['nutrition_grade_fr_n'] ]).T\ny0 = np.matrix([df_food_nova['nova_group']]).T\n\nregr = linear_model.LinearRegression() \nregr.fit(X0, y0)\ny_pred = regr.predict(X0)\naccuracy0 = regr.score(X0, y0)\nprint(accuracy0)","3b084ba2":"# without the outlier\ndf_food_nova = df_food_nova.drop([1])\ndf_food_nova","ad2558cb":"X0 = np.matrix([np.ones(df_food_nova.shape[0]),df_food_nova['nutrition_grade_fr_n'] ]).T\ny0 = np.matrix([df_food_nova['nova_group']]).T\n\nregr = linear_model.LinearRegression() \nregr.fit(X0, y0)\ny_pred = regr.predict(X0)\naccuracy0 = regr.score(X0, y0)\nprint(accuracy0)","99b2ec8a":"plt.figure(figsize=(10,5))\nplt.scatter(df_food_nova['nutrition_grade_fr_n'], df_food_nova['nova_group'])\nplt.plot(df_food_nova['nutrition_grade_fr_n'],y_pred, color = 'tomato' )\nplt.xlabel('Nutritional grade', color=\"red\", fontsize = 14)\nplt.ylabel('Food nova group - how much is it processed', color=\"red\", fontsize = 14)\nfrom google.colab import files\nplt.savefig(\"processed score.png\", format=\"PNG\")","d5d43a11":"eco_all = ['product_name','nutrition_grade_fr','nutrition_grade_fr_n', 'pnns_groups_2' , 'carbon-footprint_100g', 'carbon-footprint-from-meat-or-fish_100g', 'ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n']\ndf_eco_all = df_eco_raw[eco_all]\ndf_eco_all = df_eco_all.sort_values(by=['carbon-footprint_100g'], ascending=False) \ndf_eco_all[:-10] # the first 10 rows of the dataframe after elimination of redundant columns\nprint(df_eco_all.shape)","06cf3e65":"# lots of empty cells in the column 'carbon-footprint' and 'carbon-footprint-from-meat-or-fish_100g'. \n# Dropping for both limits the database to 10 rows only\ndf_eco_all_noNan = df_eco_all.dropna(subset=['carbon-footprint-from-meat-or-fish_100g', 'carbon-footprint_100g'])\ndf_eco_all_noNan = df_eco_all_noNan.sort_values(by=['carbon-footprint-from-meat-or-fish_100g'], ascending=False)\n# After eliminating them we can see the relationship of this and the rest of the database\ndf_eco_all_noNan \n","958fc0df":"# It can be observed from the above table that carbon-footprint-from-meat-or-fish_100g \tis not really informative\n# specific only to those 10 products, so also this category can be eliminated for statistical treatment\n\n\ndf_eco = df_eco_all.drop(columns=['carbon-footprint-from-meat-or-fish_100g'])\ndf_eco.head()\n","866f9cea":"palmoil = ['ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n']\ndf_palm = df_eco_all[palmoil]\ndf_palm = df_palm.dropna()\ndf_palm = df_palm.sort_values(by=['ingredients_from_palm_oil_n'], ascending=False)\ndf_palm.head()","5ae9ac68":"numeric = ['ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n', 'carbon-footprint_100g']\ndf_n = df_eco[numeric]\ndf_n.head()\nstats = df_n.describe()\nstats.to_csv('stat.csv')\nstats","dca808ad":"\ndf_carbon = df_eco[df_eco['carbon-footprint_100g'] > 10] # filter unrealistic values\ndf_n = df_carbon[numeric]\ndf_n.describe() # have a look if now stats look reasonable","0e4b2a91":"df_scaled =((df_n-df_n.min())\/(df_n.max()-df_n.min()))*10\ndf_scaled = df_scaled.rename(columns={'ingredients_from_palm_oil_n': \"palm_oil\", 'ingredients_that_may_be_from_palm_oil_n': \"palm oil?\", 'carbon-footprint_100g': \"CO2\"})\ndf_scaled","52a659c4":"import seaborn as sns\n%matplotlib inline\nbox_plot_scaled = sns.boxplot( data= df_scaled)\nfig = box_plot_scaled.get_figure()\nplt.ylabel(\"Scaled values\")\nfig.savefig(\"box.png\", dpi= 100)","a382ccc4":"df_eco.to_csv('openfoodfacts_Eco.csv')","f8fcedf3":"# selection of relevant columns to describe the categories of food","52b1774f":"After a first cleaning step, we can now create subsets of the dataframe by choosing the columns relevant the statistical analysis. \n","9fcdf98f":"Finally we can export clean data relevant to our study into a new csv file, easy to import since is 50MB vs. 1.4GB for the whole data)","bbbb100a":"There may be still row duplicates. Remove and check if there are any left.","c2825f99":"The file is fairly big, 177 columns with 1047591 rows each","5e51e7e1":"the minimum value of carbon footprint is negative... rather unrealistic isn't it?","0bf925a3":"# selection of variables that describe the nutritional quality","56595516":"Detailed information about each column can be checked online at :\nhttps:\/\/static.openfoodfacts.org\/data\/data-fields.txt\n\nBut:\nWhich columns are relevant for our study? and how much is stored in these columns? To answer these questions we run a for loop that returns for each the column name, its null values count and % of empty cells.","94ac1dba":"based on the above table the two variables seem proportional. In the plot below it is clear that they are inverse proportional","1eb0571c":"some categories in the PNNS_2 classification are double:one with lower case (fruits), and one with capital (Fruits)","b52feb9b":"# selection of variables that describe the environmental impact","570b62aa":"To fit data of nutritional quality then rather than the average score, we can create a variable, with a value 'nutrition_av_grade_fr' directly proportional to the grade","503269fc":"main_category contains too many values. Some with very few entries and even among those that have more than 100 entries some don't correspond actually to a food category but rather to a product (escalopes, bavette d'aloyau...)","b1c643ff":"# The environmental impact of food quality. Part 1: data exploration and cleaning#\n\nThis project focussed on the relationship between food quality and its environmental impact. Statistical analysis is carried out on the data sourced from the openfoodfact database. This notebook illustrates the first part of the project.","c6b0f69d":"# Preliminary exploration and variables selection","35303537":"To describe the food category the most informative column is pnns_groups_2. Even if a lot are labelled as unknown. ","6e8b1a6a":"Due to the way the score is calculated, the above numerical representation works better than a simple inverse of the nutritional score","ae6c114f":"We examine now the correlation of quality with nova grade, which indicates how much the food is processed","9767abf0":"carbon footprint is a necessary variable but has a high % of empty cells. Variables with a higher percentage can be dropped","859555a8":" And since the french food grade is inverse proportional to the score","413f7ac8":"#Stats and outliers final check","a973a39a":"column containing in the name '_tag' or '_en' have redundant information. Should be deleted","525e8209":"While we don't consider the carbon footprint specific from meat and fish, both variables related to palm oil are kept since information for each is distinct","f9f93105":"Import the data directly from openfoodfacts website using Pandas library"}}