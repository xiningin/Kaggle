{"cell_type":{"3618f155":"code","db0eb27f":"code","d665f5a0":"code","ffaf32fa":"code","27492611":"code","a4c84f85":"code","b71c0e03":"code","a82973bb":"code","60c94f91":"code","817eaaf3":"code","48e23401":"code","ad4ee81b":"code","f7bcfba4":"code","d6c6a313":"code","61f26963":"code","b2411c87":"code","357b854f":"code","7ab3ebe1":"code","f3098a50":"code","c6d42005":"code","0ccd287f":"code","74ddc64f":"code","32da6e01":"code","d1694d21":"code","1b968d5e":"code","3957991c":"code","10aedec2":"markdown","89a12c0f":"markdown","491dcdbb":"markdown","dcc19bf0":"markdown","53fe28e9":"markdown","14ef7315":"markdown","e4e886b7":"markdown","53de595a":"markdown","9044008a":"markdown","c365c701":"markdown","aae2ef0c":"markdown","9a38b6dc":"markdown","5094ce80":"markdown"},"source":{"3618f155":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","db0eb27f":"%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","d665f5a0":"# load the training data\nX = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nX.shape","ffaf32fa":"X.head()","27492611":"# what is the highest value?\nX.max().max()","a4c84f85":"y = X['label']\nX.drop(['label'], axis=1, inplace=True)","b71c0e03":"# change the range to see more!\nfor i in range(3):\n    # convert to an array and reshape\n    a_digit = X.loc[i].to_numpy().reshape(28, 28) \n    plt.imshow(a_digit, cmap=matplotlib.cm.binary)\n    print('The digit label', y.loc[i])\n    plt.show()","a82973bb":"# normalise the data by dividing by the max (as a float)\nX \/= 255.0\n# convert X to an array\nX = np.array(X)","60c94f91":"# reshape to be [samples][width][height][channels]\nXr = X.reshape(X.shape[0], 28, 28, 1)\n# check the shape\nXr.shape","817eaaf3":"# convert class vectors to binary class matrices\nnum_classes = 10\ny = to_categorical(y, num_classes)","48e23401":"# split into a training and validation set\nX_train, X_val, y_train, y_val = train_test_split(Xr, y, test_size=0.2, random_state=42, shuffle=True)","ad4ee81b":"# callback to reduce the learning rate \nred_lr = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, mode='max' )\n# stop the epochs when there is no more improvement in the validation set\nes = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=5)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, input_shape=(28, 28, 1) , kernel_size=(7,7), activation='elu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='elu'))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='elu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(300, activation='elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(300, activation='elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())\n\n#Train the model\nmodel_his = model.fit(X_train, y_train, \n                      batch_size=50,\n                      epochs=50, \n                      callbacks=[es, red_lr],\n                      validation_data=(X_val, y_val) \n                      )\n","f7bcfba4":"# Plot train vs test accuracy per epoch\nplt.figure()\n# Use the history metrics\nplt.plot(model_his.history['acc'])\nplt.plot(model_his.history['val_acc'])\n# Make it pretty\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'])\n# the highest accuracy score for the adding another hidden layer\nprint('\\nThe highest test score', max(model_his.history['val_acc']).round(3))\nplt.show()","d6c6a313":"val_preds = model.predict(X_val)\nval_numbers = np.argmax(val_preds, axis=1)\ny_val_numbers = np.argmax(y_val, axis=1)","61f26963":"# create a df to hold the results\nresult = pd.DataFrame({'predicted label' : val_numbers, 'actual labels' : y_val_numbers})\n# label the incorrect results\nresult['correct'] = result['predicted label'] == result['actual labels']\n# select the incorrect results\nwrong = result[result['correct'] == False]\n\n# which numbers did the model get wrong?\nwrong['actual labels'].value_counts()","b2411c87":"w_list = wrong[:18].index\nplt.figure(figsize=(9, 12))\nfor i, v in enumerate(w_list):\n    plt.subplot(6,3,i+1)\n    plt.imshow(X_val[v][:,:,0], cmap=matplotlib.cm.binary)\n    plt.title('Pred: {} Act: {}'.format(wrong['predicted label'][v], wrong['actual labels'][v]))\nplt.tight_layout()\nplt.show()\n","357b854f":"# load the test data\nX_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n# check the shape\nX_test.shape","7ab3ebe1":"# normalise the data by dividing by the max (as a float)\nX_test \/= 255.0\n# convert X_test to an array\nX_test = np.array(X_test)\n# reshape to be [samples][width][height][channels]\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\n","f3098a50":"# predict the test set\npreds = model.predict(X_test)","c6d42005":"# What does the first predcition look like?\npreds[0]","0ccd287f":"# convert back from a categorical array to an array of the digits predicted\nnum_preds = np.argmax(preds, axis=1)","74ddc64f":"# load the submission template\nsub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","32da6e01":"sub.head()","d1694d21":"# replace the label values with the model predictions\nsub['Label'] = num_preds","1b968d5e":"# check that it worked\nsub.head()","3957991c":"# output the submission file\nsub.to_csv('.\/submission.csv', index=False)","10aedec2":"### Imports required","89a12c0f":"## Set up the CNN","491dcdbb":"### Reshape to images  \nA CNN requires that the the flattened array provided is reshaped back into layers of squares , so the filter can be passed over the image correctly","dcc19bf0":"### Monitor the training","53fe28e9":"There isn't a single number the model gets wrong, it performs better on 0's ,1's and 6's.\nLets have a look at some of the misidentified numbers.","14ef7315":"## Which images is the model predicting incorrectly?","e4e886b7":"## Predict the test set  \n### Prepare the test data","53de595a":"### What do the original images look like?","9044008a":"For the majority of these its clear to see why the model got them wrong and I already think it may be overfitting, possibly to the validation set. I do not think it is worth trying to improve the model any further for now. The nest step is to try it on the withheld test set and see how the model performs on unseen data.","c365c701":"## Prepare the training Data","aae2ef0c":"### Scale the data  \nScaling the data will improve the convergence speed and the accuracy of the model.","9a38b6dc":"# Testing a CNN on MNIST  \nHow does a Convolutional Neural Network (CNN) perfom on the MNIST Digits data set?\n\nref: [Digit Recogniser Competition](https:\/\/www.kaggle.com\/c\/digit-recognizer)\n \nscores ~0.992","5094ce80":"## Have a look at the data and prepare it."}}