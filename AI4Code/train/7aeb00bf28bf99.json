{"cell_type":{"ddd4b282":"code","4de2516a":"code","c96e2599":"code","0110e494":"code","f504aa8c":"markdown","470af506":"markdown","50cbd8ec":"markdown","8aa98f09":"markdown","889d8f4a":"markdown","1d752a8f":"markdown"},"source":{"ddd4b282":"# import libraries\n# we are not importing libraries used for csv files, as keras deals with all of these\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D #images are two dimensional. Videos are three dimenstional with time.\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\n#initialize the classifier CNN\nclassifier = Sequential() #Please note that there is another way to build a mode: Functional API.\n\n#applying convolution operation --> build the convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n#32, 3, 3 --> 32 filters with 3 x 3 for each filter. \n#start with 32 filters, and then create more layers with 64, 128, 256, etc\n#expected format of the images.\n# 256, 256, 3 --> 3 color channels (RGB), 256 x 256 pixels. But when using CPU, 3, 64, 64 --> due to computational limitation","4de2516a":"#Max Pooling --> create a pooling layer\nclassifier.add(MaxPooling2D(pool_size = (2,2)))\n# 2 x 2 size --> commonly used to keep much information.\n\n#Flattening --> creating a long vector.\nclassifier.add(Flatten()) #no parameters needed.\n\n#classic ANN - full connection\nclassifier.add(Dense(output_dim = 128, activation = 'relu'))\n#common practice: number of hidden nodes between the number of input nodes and output nodes, and choose powers of 2\nclassifier.add(Dense(output_dim = 1, activation = 'sigmoid'))","c96e2599":"classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])","0110e494":"#Data augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/training_set', \n                                                    target_size = (64, 64), \n                                                    batch_size = 32,\n                                                   class_mode = 'binary')\ntest_set = test_datagen.flow_from_directory('..\/input\/test_set',\n                                                target_size = (64, 64),\n                                                 batch_size = 32, \n                                                 class_mode = 'binary')\n\nclassifier.fit_generator(training_set, \n                         samples_per_epoch = 8005, \n                        nb_epoch = 2, \n                        validation_data = test_set, \n                        nb_val_samples = 2025)","f504aa8c":"Below are key concepts used in Convolutional Neural Networks.\n\n# Convolution Operation\nThe aim of convolution operation is to reduce the size of an image, by using feature detectors that keep only the specific patterns within the image. Stride is the number of pixels with which we slide the detector. If it is one, we are moving it one pixel each time and recording the value (adding up all the multiplied values). Many feature detectors are used, and the algorithm finds out what is the optimal way to filter images. 3 x 3 feature detector is commonly used, but other sizes can be used.\n\n# ReLU\nAfter feature detectors are applied upon images, ReLU is used to increase non-linearity within images. \n\n# Max Pooling\nTake a 2 x 2 box on the top left corner (starting here), and record the maximum number within the box. Slide it to the right with the stride of 2 (commonly used), and move onto the next row if completed. Repaet this step until all the pixels are evaluated. Aim of max pooling is to keep all the important features even if images have spatial or textual distortions, and also reduce the size which prevents overfitting. So, after applying convolution operation to images, than pooling is applied.\n\nOther pooling techniques are also available such as Mean Pooling, which takes the average of pixels within the box.\n\n# Flattening\nFlatten the matrix into a long vector which will be the input to the artificial neural network\n\n# Full Connection\nImplement full Artificial Neural Network model to optimize weights.\n\n# Softmax & Cross entropy\nSoftmax function brings all predicted values to be between 0 and 1, and make them add up to 1. It also comes hand-in-hand with cross-entropy method. \n\nJust seeing how many wrong predictions the classifier made is not enough to evaluate the performance of ANNs. Instead, Cross Entropy should be used to measure how good the model is, as there can be two models that produce same results while one produced better percentages than the other. For classificaion, Cross Entropy should be used, and for regression, Mean Squared Error should be used. \n\n---------\n\nWe will create a dog vs cat classifier. To be able to work with keras library, we need proper structure of images. There should be two folders: Test set and Train set. And, in each folder, cat images and dog images should be placed in two separate folders. In this way, keras will understand how to work with them.\n","470af506":"## 2. Compile the model","50cbd8ec":"# Convolutional Neural Networks (CNN) - Keras\n\nCreated by: Sangwook Cheon\n\nDate: Dec 31, 2018\nUpdated: Jun 27, 2019\n\nThis is step-by-step guide to Convolutional Neural Network (CNN), which I created for reference. I added some useful notes along the way to clarify things. This notebook's content is from A-Z Datascience course, and I hope this will be useful to those who want to review materials covered, or anyone who wants to learn the basics of CNN.\n\n## Content:\n### Explanation\n1. Convolution operation\n2. ReLU\n3. Max Pooling\n4. Flattening\n5. Full-connection\nSoftmax & Cross entropy\n\n### IMPLEMENTATION\n1. Data preprocessing\n2. Build the Keras model\n3. Compile and fit the model\n4. Make predictions and determine accuracy\n\n--------- ","8aa98f09":"## 4. Improving the model\nThere are two possible ways of reducing variane, which is making the model fit more to the train set.\n* Add more convolutional layers \n    * This will allow more features to be detected prior to fitting to ANN. Make sure to not include input_dim, and include MaxPooling step. Flattening should be at the end of all the layers.\n* Add more fully-connected layer (hidden layers)\n    * Catches more complex behaviors\n    \nThank you for reading this kernel. If you found this helpful, please upvote the kernel or put a short comment below. ","889d8f4a":"## 3. Fit the model on images, image preprocessing\nData augmentation prevents overfitting, by generating more samples of the images through flipping, rotating, distorting, etc. Keras has built-in Image Augmentation function. To learn more about this function, refer to this [guide](https:\/\/keras.io\/preprocessing\/image\/). ","1d752a8f":"## 1. Build the CNN model"}}