{"cell_type":{"91b4d356":"code","76bd5918":"code","8e0f6cbb":"code","ebbd1176":"code","53b45d30":"code","d07ffc91":"code","7b63b760":"code","e2fa3799":"code","6ac2a3e2":"code","930d339a":"code","5d3a2c7a":"code","2ab6932d":"code","1e9a4590":"code","f84e0856":"code","054a8ab6":"code","7a89b466":"code","ff54ef34":"code","e2098cf4":"code","cf9af779":"code","15d8867c":"code","e0b2358c":"code","cb419551":"code","ed52aa43":"code","3149c7cf":"code","37fbe0b7":"code","c67c92df":"code","cb5f2d44":"code","926f9c8d":"code","50129546":"markdown","827d595f":"markdown","ea5bd270":"markdown","f95726f6":"markdown","9f44338b":"markdown","cd4a1949":"markdown","4953f0bd":"markdown","4268ebef":"markdown","347093ec":"markdown"},"source":{"91b4d356":"import numpy as np\nimport os\nfrom os.path import isfile\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\nfrom keras.layers.advanced_activations import ELU\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nfrom keras import backend\nfrom keras.utils import np_utils\nfrom keras.optimizers import Adam, RMSprop\nfrom keras import regularizers\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np\nnp.random.seed(1001)\nimport os\nimport shutil\nimport IPython\nimport seaborn as sns\nfrom scipy.io import wavfile\nfrom tqdm import tqdm_notebook \nimport IPython.display as ipd\nimport librosa\nimport numpy as np\nimport scipy\nfrom keras import losses, models, optimizers\nfrom keras.activations import relu, softmax\nfrom keras.callbacks import (EarlyStopping, LearningRateScheduler,\n                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\nfrom keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\nfrom keras.utils import Sequence, to_categorical\nfrom keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten,\n                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation)\nfrom keras.utils import Sequence, to_categorical\nfrom keras import backend as K","76bd5918":"import sys\nsys.stdout.write('hello')","8e0f6cbb":"train_folder = '..\/input\/midasemotions\/meld\/train\/'\nval_folder = '..\/input\/midasemotions\/meld\/val\/'","ebbd1176":"test_folder = ''","53b45d30":"wav_files = os.listdir(train_folder+'happy\/')\nindex = random.randint(0, len(wav_files)-1)\nfname = train_folder+'happy\/'+wav_files[index]\nrate, data = wavfile.read(fname)\nprint(\"Sampling (frame) rate = \", rate)\nprint(\"Total samples (frames) = \", data.shape)\nplt.plot(data, '-', )\n","d07ffc91":"plt.figure(figsize=(16, 4))\nplt.plot(data[:500], '.'); plt.plot(data[:500], '-');","7b63b760":"plt.figure(figsize=(10, 5))\nlibrosa.display.specshow(data.T, y_axis='mel', x_axis='time')\nplt.colorbar(format='%+2.0f dB')\nplt.title('Test Melspectogram')\nplt.tight_layout()","e2fa3799":"emotions = {'happy':0, 'sad':1, 'disgust':2, 'neutral':3, \n               'fear':4}\n\n\nreverse_emotions = {v: k for k, v in emotions.items()}\nprint(reverse_emotions)","6ac2a3e2":"class Config(object):\n    def __init__(self,\n                 sampling_rate=16000, audio_duration=2, n_classes=41,\n                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n                 max_epochs=50, n_mfcc=20):\n        self.sampling_rate = sampling_rate\n        self.audio_duration = audio_duration\n        self.n_classes = n_classes\n        self.use_mfcc = use_mfcc\n        self.n_mfcc = n_mfcc\n        self.n_folds = n_folds\n        self.learning_rate = learning_rate\n        self.max_epochs = max_epochs\n\n        self.audio_length = self.sampling_rate * self.audio_duration\n        if self.use_mfcc:\n            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length\/512)), 1)\n        else:\n            self.dim = (self.audio_length, 1)","930d339a":"def audio_norm(data):\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)\/(max_data-min_data+1e-6)\n    return data-0.5","5d3a2c7a":"X=[]\nY=[]","2ab6932d":"def prepare_train_data( config, data_dir):\n   # X = np.empty(shape=(size, config.dim[0], config.dim[1], 1))\n   # Y = np.zeros(shape = (size,5))\n   # print(X.shape)\n    input_length = config.audio_length\n    index = 0\n    for emotion_dir in os.listdir(data_dir):\n        label = emotion_dir\n        audio_dir = data_dir+ emotion_dir\n        count  = 0\n        if label == 'neutral':\n            count = 0\n        elif label == 'happy':\n            count = 3\n        else :\n            count = 15\n        for file in os.listdir(audio_dir):\n            \n            file_path = audio_dir+'\/\/' + file\n            data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n            \n            # Random offset \/ Padding\n            if len(data) > input_length:\n                max_offset = len(data) - input_length\n                offset = np.random.randint(max_offset)\n                data = data[offset:(input_length+offset)]\n            else:\n                if input_length > len(data):\n                    max_offset = input_length - len(data)\n                    offset = np.random.randint(max_offset)\n                else:\n                    offset = 0\n                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n            d = data\n            data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n            data = np.expand_dims(data, axis=-1)\n            #X[index,] = data\n            X.append(data)\n            l = emotions[label]\n            #Y[index][l] = 1\n            z= np.zeros(5)\n            z[l]=1\n            Y.append(z)\n            #print(Y[index])\n            #print(index)\n            #index+=1\n            noise_examples = count\/3 \n            while noise_examples :\n                noise_factor = random.randint(0,10)%100\n                noise = np.random.randn(len(d))\n                augmented_data = d + noise_factor * noise\n                data = augmented_data\n                if len(data) > input_length:\n                    max_offset = len(data) - input_length\n                    offset = np.random.randint(max_offset)\n                    data = data[offset:(input_length+offset)]\n                else:\n                    if input_length > len(data):\n                        max_offset = input_length - len(data)\n                        offset = np.random.randint(max_offset)\n                    else:\n                        offset = 0\n                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n                data = librosa.feature.mfcc(augmented_data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n                data = np.expand_dims(data, axis=-1)\n                X.append(data)\n                Y.append(z)\n                noise_examples-=1\n             \n            pitch_examples = count\/3 \n            while pitch_examples : \n                    pitch_factor = random.randint(0, 20)\/10\n                    data = librosa.effects.pitch_shift(d, config.sampling_rate, pitch_factor)\n                    if len(data) > input_length:\n                        max_offset = len(data) - input_length\n                        offset = np.random.randint(max_offset)\n                        data = data[offset:(input_length+offset)]\n                    else:\n                        if input_length > len(data):\n                            max_offset = input_length - len(data)\n                            offset = np.random.randint(max_offset)\n                        else:\n                            offset = 0\n                        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n                    data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n                    data = np.expand_dims(data, axis=-1)\n                    X.append(data)\n                    Y.append(z)\n                    pitch_examples -= 1\n             \n            time_examples = count\/3  \n            while time_examples :\n                speed_factor =random.randint(1,2)\n                data = librosa.effects.time_stretch(d, speed_factor)\n                if len(data) > input_length:\n                    max_offset = len(data) - input_length\n                    offset = np.random.randint(max_offset)\n                    data = data[offset:(input_length+offset)]\n                else:\n                    if input_length > len(data):\n                        max_offset = input_length - len(data)\n                        offset = np.random.randint(max_offset)\n                    else:\n                        offset = 0\n                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n                data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n                data = np.expand_dims(data, axis=-1)\n                X.append(data)\n                Y.append(z)\n                #print(Y[len(Y)-1])\n                time_examples -= 1  \n           #print(X[len(X)-1].shape)    \n    #return X,Y","1e9a4590":"def prepare_val_data( config, data_dir,size):\n    X = np.empty(shape=(size, config.dim[0], config.dim[1], 1))\n    Y = np.zeros(shape = (size,5))\n    print(X.shape)\n    input_length = config.audio_length\n    index = 0\n    for emotion_dir in os.listdir(data_dir):\n        \n        label = emotion_dir\n        audio_dir = data_dir+ emotion_dir\n        for file in os.listdir(audio_dir):\n            file_path = audio_dir+'\/\/' + file\n            data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n            \n            # Random offset \/ Padding\n            if len(data) > input_length:\n                max_offset = len(data) - input_length\n                offset = np.random.randint(max_offset)\n                data = data[offset:(input_length+offset)]\n            else:\n                if input_length > len(data):\n                    max_offset = input_length - len(data)\n                    offset = np.random.randint(max_offset)\n                else:\n                    offset = 0\n                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n            d = data\n            data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n            data = np.expand_dims(data, axis=-1)\n            X[index,] = data\n            l = emotions[label]\n            Y[index][l] = 1\n    print('Done')        \n    return X,Y       ","f84e0856":"config = Config(sampling_rate=16000, audio_duration=1, n_folds=10, \n                learning_rate=0.0001, use_mfcc=True, n_mfcc=50)","054a8ab6":" prepare_train_data(config,train_folder)","7a89b466":" prepare_train_data(config,val_folder)","ff54ef34":"#Xval , Yval = prepare_val_data(config,val_folder,830)","e2098cf4":"Y_train = np.asarray(Y)","cf9af779":"X_train = np.asarray(X)","15d8867c":"mean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\nX_train = (X_train - mean)\/std\n","e0b2358c":"from sklearn.model_selection import train_test_split\nXtrain, Xval, Ytrain, Yval = train_test_split(X_train,Y_train, test_size = 0.3)","cb419551":"def get_2d_dummy_model(config):\n    \n    nclass = config.n_classes\n    \n    inp = Input(shape=(config.dim[0],config.dim[1],1))\n    x = GlobalMaxPool2D()(inp)\n    out = Dense(nclass, activation=softmax)(x)\n\n    model = models.Model(inputs=inp, outputs=out)\n    opt = optimizers.Adam(config.learning_rate)\n\n    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n    return model\n\n\ndef get_2d_conv_model(config):\n\n    inp = Input(shape=(config.dim[0],config.dim[1],1))\n    x = Convolution2D(32, (3,3), padding=\"same\")(inp)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    \n    x = Convolution2D(64, (3,3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    \n    x = Convolution2D(128, (3,3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    \n    x = Convolution2D(256, (3,3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n\n    x = Flatten()(x)\n    x = Dense(64)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    out = Dense(5, activation=softmax)(x)\n\n    model = models.Model(inputs=inp, outputs=out)\n    opt = optimizers.Adam(config.learning_rate)\n\n    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n    return model","ed52aa43":"model = get_2d_conv_model(config)\n    ","3149c7cf":"print(model.summary())","37fbe0b7":"history = model.fit(X_train, Y_train, validation_data=(Xval, Yval), epochs=10)","c67c92df":"plt.plot(history.history['loss']) ","cb5f2d44":"plt.plot(history.history['val_loss'])","926f9c8d":"model.save('model.h5')","50129546":"**Function for populating validation data**","827d595f":"**Importing Libraries**","ea5bd270":"**Mapping of given emotions to constants**","f95726f6":"**Lists for storing features corresponding to .wav files and the corresponding labels**","9f44338b":"**Function for populating training data**","cd4a1949":"> Due to non-uniform distribution of audio files corresponding to a given label, I have chosen to apply data augmentation which mainly includes mainly includes the following methods:\n>1. Noise Injection\n>2. Changing Pitch\n>3. Changing Speed","4953f0bd":"**Model Definiton and Architecture**","4268ebef":"**Normalization Function**","347093ec":"**Visualizations**"}}