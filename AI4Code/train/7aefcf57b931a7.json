{"cell_type":{"193ca3b6":"code","f92d8ffa":"code","1ae56e60":"code","c3e44d6c":"code","bb6fc957":"code","9ac8d75c":"code","e2e097f8":"code","01bddfb7":"code","0981b13a":"code","5b87f25a":"code","b23622a4":"code","ed9605ac":"code","704f5e95":"code","9ec89e8e":"code","f46b65df":"code","727b7f9f":"code","ec314566":"code","b10d6867":"code","221110f3":"code","003d32ad":"code","491c2ca8":"code","8364eaea":"code","e4ef523a":"code","19c16585":"code","dc87b585":"code","d4012a97":"markdown","b81c8657":"markdown","be6b2e9f":"markdown","72b10f87":"markdown","71360f66":"markdown","feee2278":"markdown","74060470":"markdown","25c6f87f":"markdown","52e80ad6":"markdown","c14b609d":"markdown","3be37fd5":"markdown","91a1c2aa":"markdown"},"source":{"193ca3b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f92d8ffa":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn import model_selection\nfrom sklearn import ensemble\nfrom sklearn import pipeline","1ae56e60":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","c3e44d6c":"## Number of records \nprint(df.shape[0])","bb6fc957":"## Number of features \nprint(df.shape[1]-1)","9ac8d75c":"df.dtypes","e2e097f8":"df.isnull().sum()","01bddfb7":"df_class_0=df[df.Class==0]\ndf_class_1=df[df.Class==1]","0981b13a":"fig,ax = plt.subplots(figsize=(10,10))\nfor a,c in zip([df_class_0,df_class_1],['r','b']):\n    sns.histplot(data=a,x='Time',ax=ax,color=c,alpha=0.4)\n","5b87f25a":"fig,ax = plt.subplots(figsize=(10,10))\n\nfor a,c in zip([df_class_0[df_class_0.Amount<1000],df_class_1[df_class_1.Amount<1000]],['r','b']):\n    sns.histplot(data=a,x='Amount',ax=ax,color=c,alpha=0.4)","b23622a4":"df.Amount.describe()","ed9605ac":"df.Amount.quantile(q=0.99)\n# We see that for nearly 99% transactions the amount is less than 1018 So this clearly means that we have a outlier let us check the data for this outlier ","704f5e95":"df[df.Amount>10000]","9ec89e8e":"# We see that we have only 7 transaction which are more than 10000 amount","f46b65df":"# Let us build a simple model first using randomforestclassifier","727b7f9f":"X = df.drop('Class',axis=1)\ny = df.Class.values","ec314566":"from sklearn.model_selection import cross_val_score,train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nscale_columns = ['Time','Amount']\npreprocess = make_column_transformer((StandardScaler(),scale_columns),remainder='passthrough')\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y)\nlogreg = LogisticRegression()\npipe = make_pipeline(preprocess,logreg)\nscore = np.mean(cross_val_score(pipe,X_train,y_train,cv=5,scoring='roc_auc'))\nprint(score)","b10d6867":"from sklearn.metrics import confusion_matrix,accuracy_score\npipe.fit(X_train,y_train)\nprint(accuracy_score(y_train,pipe.predict(X_train)))","221110f3":"print(accuracy_score(y_test,pipe.predict(X_test)))","003d32ad":"# We are getting a high roc_auc_score and a high accuracy for test set","491c2ca8":"y_pred_proba = pipe.predict_proba(X_test)[:,1]\ny_pred_proba[:2]","8364eaea":"y_pred = []\nfor i in y_pred_proba:\n    if i<0.9668675096379374:\n        y_pred.append(0)\n    else:\n        y_pred.append(1)","e4ef523a":"cm = confusion_matrix(y_test,y_pred)","19c16585":"ax = sns.heatmap(cm,fmt=' ',annot=True)\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')","dc87b585":"from sklearn.metrics import plot_roc_curve\n\nplot_roc_curve(pipe,X_test,y_test)\nplt.show()","d4012a97":"We have around 28500 records and 30 features","b81c8657":"We can see that the time taken for both type of transactions is same. So time is not a parameter on which the class of transaction depend ","be6b2e9f":"There are no null values in the dataset","72b10f87":"We have build a really good model.","71360f66":"## Checking the number of features in the dataset","feee2278":"## Impoting the libraries","74060470":"## Importing the dataset","25c6f87f":"## Checking the data type of each features","52e80ad6":"## Exploratory data Analysis","c14b609d":"## Checking the null values","3be37fd5":"## Amount","91a1c2aa":"## Time"}}