{"cell_type":{"a9315420":"code","9acb94a3":"code","74a19d8d":"code","bbbbace8":"code","47e27a48":"code","9f6addfd":"code","0bb05049":"code","234cddbd":"code","466590c7":"markdown","ca464c0e":"markdown","1d604916":"markdown","54b61200":"markdown"},"source":{"a9315420":"#import library\nfrom keras.datasets import fashion_mnist\nfrom keras.layers import Input, Dense\nfrom keras.models import Model","9acb94a3":"#Load Dataset\n(x_train, _), (x_test, _) = fashion_mnist.load_data()","74a19d8d":"#Rescale  dataset\nimport numpy as np\n\nx_train = x_train.astype('float32') \/ 255.\nx_test = x_test.astype('float32') \/ 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))","bbbbace8":"#Build Autoencoder Model\n\ntarget_dimension = 16\n\n#Encoder\ninput_img = Input(shape=(784,))\nencoder = Dense(128, activation='relu')(input_img)\nencoder = Dense(64, activation='relu')(encoder)\nencoder = Dense(32, activation='relu')(encoder)\n\n#code\ncoded = Dense(target_dimension, activation='relu')(encoder)\n\n#Decoder\ndecoder = Dense(32, activation='relu')(coded)\ndecoder = Dense(64, activation='relu')(decoder)\ndecoder = Dense(128, activation='relu')(decoder)\ndecoder = Dense(784, activation='sigmoid')(decoder)\n\nautoencoder = Model(input_img, decoder)","47e27a48":"#compile model\nautoencoder.compile(loss = 'binary_crossentropy',\n                    optimizer = 'adam')","9f6addfd":"autoencoder.summary()","0bb05049":"#Training model\nautoencoder.fit(x_train, x_train,\n                epochs=20,\n                batch_size=100,\n                shuffle=True,\n                validation_data=(x_test, x_test))","234cddbd":"#Display original data and reconstruction data\nimport matplotlib.pyplot as plt\ndecoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(25, 5))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i+1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i+1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \nplt.show()","466590c7":"This project aim to implementation of Deep Autoencoder with Keras, this project use fashion mnist dataset from keras\n\nFashion mnist is is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. \n\nThe class labels are:\n\nLabel\tDescription\n0.\tT-shirt\/top\n1.\tTrouser\n2.\tPullover\n3.\tDress\n4.\tCoat\n5.\tSandal\n6.\tShirt\n7.\tSneaker\n8.\tBag\n9.\tAnkle boot ","ca464c0e":"<h3>What is Autoencoder?<\/h3>\nAutoencoder is one of type neural network where the input is same as the output, autoencoder learn the input data and reconstruct the input data, autoencoder used for dimensionality reduction\n\n![Autoencoder](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRj6teOvotqH0V03TJsL5avWnHWSUBFlJUJIgSjrdff2dz3ca5C&usqp=CAU)","1d604916":"<a href=\"https:\/\/colab.research.google.com\/github\/Nanangk\/Deep_Autoencoder_Implementation_with_Keras\/blob\/master\/Deep_Autoencoder_Implementation.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","54b61200":"#Deep Autoencoder Implementation"}}