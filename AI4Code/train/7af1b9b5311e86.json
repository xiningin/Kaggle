{"cell_type":{"79887b94":"code","62a951af":"code","cd9a1c42":"code","41b8e475":"code","18f6b886":"code","2fa13a53":"code","f8d9f17a":"code","6af30621":"code","e886e0ff":"code","a1bb248f":"code","58042bd6":"code","7507fd3b":"code","06484bb5":"code","774db7db":"code","073348a3":"code","93df3785":"code","29f6a200":"code","c262b4a2":"code","73e6ceb2":"code","caf4e542":"code","162a14d2":"code","94079800":"code","91c5005a":"markdown","3c7420b1":"markdown","1fe7cafb":"markdown"},"source":{"79887b94":"import os\nimport numpy as np\nimport pandas as pd","62a951af":"train = pd.read_csv(\"..\/input\/shopee-product-matching\/train.csv\")\ntest = pd.read_csv(\"..\/input\/shopee-product-matching\/test.csv\")\nsub = pd.read_csv(\"..\/input\/shopee-product-matching\/sample_submission.csv\")\ntrain.head()","cd9a1c42":"#\u627e\u51fa\u6bcf\u6b04\u4f4dunique\u6709\u5e7e\u985e\n#for col in train.columns:\n    #print(col + \":\" + str(len(train[col].unique())))","41b8e475":"#\u6b63\u78ba\u7b54\u6848\n#tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n#train['target'] = train.label_group.map(tmp)\n#print('train shape is', train.shape )\n#train.head()","18f6b886":"#\u4ee5tiltes\u5206\u985e\u53ef\u5206\u621033117\u985e\uff0c\u9810\u6e2c\u4e00\u6a23\u7684title\u6703\u6709\u4e00\u6a23\u7684label_group\n\n#labels = train.groupby(\"title\")[\"image\"].count().reset_index()\n#labels.columns=[\"title\",\"image_num\"]\n#titles = labels.sort_values(\"image_num\")\n#titles","2fa13a53":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english',binary = True, max_features = 25000)\ntfidf_matrix = vectorizer.fit_transform(test.title)\nprint(type(tfidf_matrix))\nprint(tfidf_matrix.shape)\n\ntfidfs = tfidf_matrix.toarray()\nwords = vectorizer.get_feature_names()\n#pd.DataFrame(tfidfs,columns=words)\n#tfidfs","f8d9f17a":"from sklearn.metrics.pairwise import cosine_similarity\n\n#\u8a08\u7b97\u76f8\u4f3c\u5ea6\ncosine_similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n#print(cosine_similarity_matrix)","6af30621":"print(cosine_similarity_matrix.shape)","e886e0ff":"'''# cosine_sim[0] \u70ba\u7b2c\u4e00\u500b\u6587\u4ef6\u8207\u5176\u4ed6\u6587\u4ef6\u7684\u76f8\u4f3c\u5ea6\ncosine_sim = cosine_similarity_matrix[0]\n\n# \u53bb\u9664\u7b2c\u4e00\u500b\u6587\u4ef6(\u67e5\u8a62\u6587\u4ef6)\ncosine_sim = cosine_sim[1:]\n\n# \u5c07\u6587\u4ef6\u7de8\u865f\u8207\u6587\u4ef6\u76f8\u4f3c\u5ea6\u6253\u5305\u70batuple\nsim_scores = list(enumerate(cosine_sim))\n\n# \u4ee5\u76f8\u4f3c\u5ea6\u964d\u51aa\u6392\u5217\nsim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n# \u8a2d\u5b9athreshold\u53d6\u51fa\u76f8\u4f3c\u7684title\ntop10 = sim_scores[:10]\n\nthreshold = 0.8\nprint(\"\u7b2c\u4e00\u53e5\", train.title[0])\n\nfor i in sim_scores:\n    idx, score = i[0] , i[1]\n    \n    if score > threshold:\n        #train[\"title_pred\"]= train.posting_id[idx]\n        print(\"\u8207\u5176\u76f8\u4f3c\u70ba:\",idx, train.title[idx],score)\n    else:\n        break\n'''","a1bb248f":"def similarity(title):\n    cntx = test[['title', 'posting_id']]\n    #Reverse mapping of the index\n    indices = pd.Series(test.index, index = test['title']).drop_duplicates()\n         \n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_similarity_matrix[idx-1]))\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n    uplimit = len(test['title']) if len(test['title']) < 50 else 50\n    sim_scores = sim_scores[0:uplimit]\n    post_indices = [i[0] for i in sim_scores if i[1] > .8]\n    recommend = cntx.iloc[post_indices]\n    output=[]\n    output.append(cntx.iloc[idx,1])\n    for index, row in recommend.iterrows():\n        output.append(row['posting_id'])\n    return output\n\n    #return ' '.join( np.unique(output))","58042bd6":"'''\n# The Top 3 similar matches\n#threshold = 0.8\n\ndef similarity(title):\n    cntx = train[['title', 'posting_id']]\n    #Reverse mapping of the index\n    indices = pd.Series(train.index, index = train['title']).drop_duplicates()\n         \n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_similarity_matrix[idx-1]))\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n    #sim_scores = sim_scores[0:1]\n    \n    for i in sim_scores:\n        book_indices,scores  = i[0],i[1]\n        if scores > threshold:\n            recommend = cntx.iloc[book_indices]\n            output=''\n            for index, row in recommend.iteritems():\n                output+=row['posting_id']+\" \"\n        else:\n            break \n        return output\n'''\n        ","7507fd3b":"#\u6b63\u78ba\u7b54\u6848\n#tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n#train['target'] = train.label_group.map(tmp)\n#print('train shape is', train.shape )\n#train.head()","06484bb5":"#train['f1'] = train.apply(getMetric('phash_pred'),axis=1)\n#print('CV score for baseline =',train.f1.mean())","774db7db":"'''def getMetric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row.target, row[col]))\n        return 2*n \/ (len(row.target) + len(row[col]))\n    return f1score'''","073348a3":"#\u4e00\u6a23image phash match\u5728\u4e00\u8d77\n\ntmp2 = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['phash_pred'] = test.image_phash.map(tmp2)","93df3785":"#def tostr(x):\n#    return ' '.join(x)\n#test['phash_pred'] = test.phash_pred.map(tostr)\n","29f6a200":"test['title_pred']=test['title'].apply(similarity)\ntest.head()","c262b4a2":"# Function to combine predictions\ndef combine_predictions(row):\n    x = np.concatenate([row['phash_pred'], row['title_pred']])\n    return ' '.join( np.unique(x) )","73e6ceb2":"test['matches'] = test.apply(combine_predictions, axis = 1)\ntest.head()","caf4e542":"test[['posting_id', 'matches']].head()","162a14d2":"test[['posting_id', 'matches']].to_csv('submission.csv', index = False)\nsub = pd.read_csv('submission.csv')\nsub.head()","94079800":"#def tostr(x):\n#    return ' '.join(x)\n#train['phash_pred'] = train.phash_pred.map(tostr)\n#train['target'] = train.target.map(tostr)\n#train.head()","91c5005a":"# cosine_similarity","3c7420b1":"# \u8a08\u7b97TFIDF","1fe7cafb":"### Use image phash"}}