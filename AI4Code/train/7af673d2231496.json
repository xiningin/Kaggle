{"cell_type":{"810cdd26":"code","3973ce51":"code","07ec11ea":"code","7ad68f4c":"code","eff98982":"code","57001cb9":"code","fd6ffd0b":"code","c8e9f755":"code","bb1b26f0":"code","d0ab2b9c":"code","f160ef3f":"code","c9ad1060":"code","cec55804":"code","75092b9d":"code","0ecc7179":"code","2f56dca9":"code","4d6cce7d":"code","54b5ead6":"code","2d4da0b1":"code","70170070":"code","117d9190":"markdown","5e0ea593":"markdown","7e628e76":"markdown","40102554":"markdown","c06c2797":"markdown","2b6cb366":"markdown","5e54dab7":"markdown","b64ea638":"markdown","cb20a011":"markdown","5e48fe35":"markdown","d97c58d2":"markdown"},"source":{"810cdd26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","3973ce51":"import matplotlib.pyplot as plt\nimport seaborn as sn\n\nfrom pprint import pprint\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\n","07ec11ea":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","7ad68f4c":"print('train shape:', train.shape)\nprint('test shape:', test.shape)","eff98982":"train.head()","57001cb9":"test.head()","fd6ffd0b":"image0 = test.iloc[3,:]     \n                                        \nimg = np.array(image0).reshape(28,28)\nplt.imshow(img,cmap='binary')","c8e9f755":"X = train.drop('label',axis=1)\nY = train['label']","bb1b26f0":"X = np.array(X, dtype=\"float\") \/ 255.0\nY = Y.values","d0ab2b9c":"\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n# Creating the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","f160ef3f":"# Using the random grid to search for best hyperparameters\nrforest = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation\nrf_random = RandomizedSearchCV(estimator = rforest, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","c9ad1060":"# Fit the random search model\n\n#Takes A LOT of time so i'll skip it, you can see output in the next cell\n#rf_random.fit(X, Y)\n#rf_random.best_params_","cec55804":"params = {'bootstrap': False,\n 'max_depth': 40,\n 'max_features': 'auto',\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'n_estimators': 140}","75092b9d":"rforest = RandomForestClassifier(**params)\nrforest.fit(X , Y)","0ecc7179":"Y_train_predicted = rforest.predict(X)","2f56dca9":"cmrforest = confusion_matrix(Y, Y_train_predicted)\n\nplt.figure(figsize=(10,7))\nsn.heatmap(cmrforest ,annot=True , fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')\nrforest.score(X,Y)","4d6cce7d":"X_test = np.array(test, dtype=\"float\") \/ 255.0","54b5ead6":"Y_predicted = rforest.predict(X_test)\n\nY_predicted.shape","2d4da0b1":"index = np.arange(1, Y_predicted.shape[0]+1)\ndata = {'ImageId' : index, \"Label\" : Y_predicted}\ndf = pd.DataFrame(data=data)\ndf.head()\n","70170070":"df.to_csv('out.csv', index=False)","117d9190":"## Normalizing X and extracting values from Y","5e0ea593":"# Splitting train dataset\n","7e628e76":"## Fitting Random Forest Classifier with the best parameters from Randomized Search ","40102554":"# Reading the dataset","c06c2797":"# Using Random Forest","2b6cb366":"# Making predictions on test data","5e54dab7":"# Exporting predictions to appropriate submission format","b64ea638":"# Prepairing test dataset","cb20a011":"# Measuring performance on the training set ","5e48fe35":"# Visualising data","d97c58d2":"##  Tuning parameters with randomized search "}}