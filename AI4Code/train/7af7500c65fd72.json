{"cell_type":{"7181859e":"code","ed76df41":"code","405ec6f1":"code","4f469518":"code","709f8bde":"code","648714d8":"code","b5f07181":"code","04d9ea7a":"code","7196bfb7":"code","bdb7e34d":"code","73c9f837":"code","e0d095fe":"code","9df65b1c":"code","f0c487ce":"code","439c58c6":"code","e2c8b798":"code","b89ed7fe":"code","b512d624":"code","21798990":"code","38730d56":"code","1fd60cbd":"code","f66f852f":"code","25a4f9bf":"code","e0178f44":"code","12e1ec66":"code","929184d2":"code","8b397dc6":"code","5c0263de":"code","e83a833c":"markdown","cadadbe7":"markdown","a539ff11":"markdown","4b78eb26":"markdown","99536808":"markdown"},"source":{"7181859e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ed76df41":"#importing initial libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# not to see warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","405ec6f1":"# inputing datasets\ndf1=pd.read_csv(\"..\/input\/crimes-in-boston\/crime.csv\", engine='python')\ndf1.head()","4f469518":"df2=pd.read_csv(\"..\/input\/crimes-in-boston\/offense_codes.csv\", engine='python')\ndf2.head()","709f8bde":"# to see is there any duplicates\nprint(len(df1))\nprint(len(df1.drop_duplicates(subset='INCIDENT_NUMBER', keep='first')))","648714d8":"# let us delete duplicates really:)\ndf1=df1.drop_duplicates(subset='INCIDENT_NUMBER', keep='first').reset_index(drop=True)","b5f07181":"# to get general information\ndf1.info()","04d9ea7a":"# to see missing values in Lat column\ndf1[df1['Lat'].isnull()]","7196bfb7":"df1[df1['Lat'].isnull()]['Location'].unique()\n# No values besides (0.00000, 0.00000)","bdb7e34d":"print(len(df2))\nprint(len(df2.drop_duplicates(subset='CODE', keep='first')))","73c9f837":"df2=df2.drop_duplicates(subset='CODE', keep='first').reset_index(drop=True)","e0d095fe":"df2.info()","9df65b1c":"# importing libraries for Geographic and Interactive visualizations\nfrom folium import Choropleth, Circle, Marker, Map\nfrom folium.plugins import HeatMap, MarkerCluster\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport math","f0c487ce":"# took data only year is 2015. Just for interest and not not freeze kernel while map visualization\ndf1_part = df1[df1['YEAR'] == 2015]\ndf1_2015=df1_part.copy()\ndf1_2015 = df1_2015.groupby('OFFENSE_CODE_GROUP')['INCIDENT_NUMBER'].count().reset_index()\ndf1_2015=df1_2015.sort_values(by='INCIDENT_NUMBER', ascending=False)[:10]\ndf1_2015","439c58c6":"# Crime\/Offenses number over most 10 types of Crime\/Offenses in interactive bar plot of plotly\nfig = px.bar(df1_2015, x='OFFENSE_CODE_GROUP', y='INCIDENT_NUMBER',\n             hover_data=['OFFENSE_CODE_GROUP', 'INCIDENT_NUMBER'], color='INCIDENT_NUMBER',\n             labels={'INCIDENT_NUMBER':'The Number of Crimes'}, height=500, width=1000, \n             title='The Number of Crimes over Offense Group')\nfig.show()","e2c8b798":"# creating weekend and midweek dataframes\ndf1_we=df1[(df1['DAY_OF_WEEK']=='Saturday')|(df1['DAY_OF_WEEK']=='Sunday')]\ndf1_mw=df1[~(df1['DAY_OF_WEEK']=='Saturday')|(df1['DAY_OF_WEEK']=='Sunday')]","b89ed7fe":"df1_we=df1_we.groupby('HOUR')['INCIDENT_NUMBER'].count().reset_index()\ndf1_we","b512d624":"df1_mw=df1_mw.groupby('HOUR')['INCIDENT_NUMBER'].count().reset_index()\ndf1_mw","21798990":"# Crime\/Offenses weekend and midweek number of Crimes\/Offenses in interactive bar plot of plotly\nfig = go.Figure(layout={'height':550})\nfig.add_trace(go.Bar(x=df1_we['HOUR'], y=df1_we['INCIDENT_NUMBER'], name='Weekend', marker_color='rgb(55, 83, 109)'))\nfig.add_trace(go.Bar(x=df1_mw['HOUR'], y=df1_mw['INCIDENT_NUMBER'], name='Midweek', marker_color='rgb(26, 118, 255)'))\nfig.update_layout(title='Number of Offenses in Weekend\/Midweek over the Hours', xaxis_tickfont_size=14,\n    yaxis=dict(title='Number of Offenses', titlefont_size=16, tickfont_size=14),\n    xaxis=dict(title='Hour', titlefont_size=16, tickfont_size=14),\n    legend=dict(x=0, y=1.0, bgcolor='rgba(255, 255, 255, 0)', bordercolor='rgba(255, 255, 255, 0)'), \n                  barmode='group', bargap=0.15, bargroupgap=0.1)\nfig.show()","38730d56":"# Heatmap of Hour and Weekday\nx = df1.DAY_OF_WEEK\ny = df1.HOUR\nfig = go.Figure(go.Histogram2d(x=x,y=y))\nfig.update_layout(title='Heat scale on number of Offenses', xaxis_tickfont_size=14,\n    yaxis=dict(title='Hour', titlefont_size=16, tickfont_size=14),\n    xaxis=dict(title='Week day', titlefont_size=16, tickfont_size=14))\nfig.show()","1fd60cbd":"# Cluster map of crime\/offense incidents \nm = Map(location=[42.361145, -71.057083], zoom_start=13)\ncluster = MarkerCluster()\nfor idx, row in df1_part.iterrows():\n    if not math.isnan(row['Long']) and not math.isnan(row['Lat']):\n        cluster.add_child(Marker([row['Lat'], row['Long']]))\nm.add_child(cluster)","f66f852f":"# Heatpmap of crime\/offense area locations\ndf1_part.dropna(subset=['Lat'], inplace=True)\ndf1_part.dropna(subset=['Long'], inplace=True)\nm = Map(location=[42.361145, -71.057083], zoom_start=13, )\nHeatMap(data=df1_part[['Lat','Long']], radius=10).add_to(m)\nm","25a4f9bf":"# Streets with the highest ten(10) rank of crime\/offense quantity\nst=df1.groupby(['STREET'])['INCIDENT_NUMBER'].count().reset_index().sort_values('INCIDENT_NUMBER', ascending=False)[:10]\nst","e0178f44":"# Percentage distribution of Crimes\/Offenses on Streets in the visualization of Pie graph\nfig = px.pie(st, values=st['INCIDENT_NUMBER'], \n             title='Percentage distrubution of Offenses on Streets', \n             names=st['STREET'])\nfig.show()","12e1ec66":"# Number of Crimes\/Offenses on Streets in the visualization of Line plot\nfig = go.Figure(layout={'height':550})\nfig.add_trace(go.Line(x=st['STREET'], y=st['INCIDENT_NUMBER'], name='Street', marker_color='rgb(26, 118, 255)'))\nfig.update_layout(title='Number of Most Offenses over the Streets', xaxis_tickfont_size=14,\n    yaxis=dict(title='Number of Offenses', titlefont_size=16, tickfont_size=14),\n    xaxis=dict(title='Street', titlefont_size=16, tickfont_size=14))\nfig.show()","929184d2":"df1['YEAR'].unique()","8b397dc6":"# creating dataframe includes count of cases in all year and month\ng=pd.DataFrame(data={'MONTH':np.arange(1,13,1)})\nfor x in [2015,2016,2017,2018]: \n    # or pd['YEAR'].unique()\n    g=g.merge(df1[df1['YEAR']==x].groupby('MONTH')['INCIDENT_NUMBER'].count().reset_index().iloc[:,:],\n            left_on='MONTH', right_on='MONTH', how='outer')\ng.columns=['MONTH','2015','2016','2017','2018']\ng=g.fillna(0)\ng","5c0263de":"# Number of cases in each year over the months on visualization of line plot\nfig = go.Figure(layout={'height':550})\nfig.add_trace(go.Line(x=g['MONTH'], y=g['2015'], name='2015', marker_color='rgb(227, 20, 20)'))\nfig.add_trace(go.Line(x=g['MONTH'], y=g['2016'], name='2016', marker_color='rgb(21, 5, 247)')),\nfig.add_trace(go.Line(x=g['MONTH'], y=g['2017'], name='2017', marker_color='rgb(45, 227, 5)'))\nfig.add_trace(go.Line(x=g['MONTH'], y=g['2018'], name='2018', marker_color='rgb(86, 0, 245)'))\n\nfig.update_layout(title='Number of Offenses in some Years over the Months', xaxis_tickfont_size=5,\n    yaxis=dict(title='Number of Offenses', titlefont_size=16, tickfont_size=14),\n    xaxis=dict(title='Month', titlefont_size=16, tickfont_size=14),\n    legend=dict(x=0, y=0.5, bgcolor='rgba(255, 255, 255, 0)', bordercolor='rgba(255, 255, 255, 0)'), \n                bargap=0.1, bargroupgap=0.1)\nfig.show()","e83a833c":"### I needed dataframe has number of cases in **each Month and Year**. To do right that, seems the simplest way, but it takes time and would be unprofessional if there were more 4 years\n#### df1[df1['YEAR']==2015].groupby('MONTH')['INCIDENT_NUMBER'].count().reset_index()","cadadbe7":"## **If you appreciated really or liked, Please upvote, comment and follow to see other our works**","a539ff11":"#### Here we have missing values in some columns like **DISTRICT, SHOOTING, STREET, LAT, Long**. So we may need actions droping, filling or other to work later on it efficeintly, **according to our neeed**!","4b78eb26":"**Grouping by Hour**","99536808":"###  In the initial time, I wanted to fill missing values in **Lat and Long columns** with data of **Location column** has same values. Then, when we look at those data(rows) which have missing values in Lat or Long column above, may see Location has no missing values right row. **However**, Location's values are like **(0.0000, 0.0000) that consist of only 0(zeroes)**. Hence, I suspect these are wrong, unsuitable values and decided not to fill them. Because it is not a normal occasion of all are 0(zeroes) and can be dangerous implement analyzing actions to filled with 0(zeroes) in normally!"}}