{"cell_type":{"ac2fa92d":"code","8dea7227":"code","c8603236":"code","55d681d2":"code","d2524894":"code","34a550d0":"code","18d9dd5e":"code","1372f2df":"code","f39188ed":"code","b7e9b3e9":"code","8aba4d10":"code","5954bbeb":"code","d401425d":"code","9b855842":"markdown","2ed87595":"markdown","3d14310d":"markdown","991dbc8f":"markdown","22189250":"markdown","48ddb044":"markdown","fb3480d3":"markdown"},"source":{"ac2fa92d":"# Required Libraries\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nwarnings.filterwarnings(\"ignore\")","8dea7227":"# Load Dataset\nmnist = tf.keras.datasets.mnist\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nprint(f'Training set: {X_train.shape}')\nprint(f'Testing set: {X_test.shape}')","c8603236":"# Plotting sample images of hand written characters using plt.imshow()\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(5, 5))\nax1.imshow(X_train[0]);\nax2.imshow(X_train[1000]);\nax3.imshow(X_train[45000]);","55d681d2":"X_train = tf.pad(tensor=X_train, paddings=[[0, 0], [2,2], [2,2]])\/255\nX_test = tf.pad(tensor=X_test, paddings=[[0, 0], [2,2], [2,2]])\/255\n\nX_train.shape","d2524894":"X_train = tf.expand_dims(X_train, axis=3, name=None)\nX_test = tf.expand_dims(X_test, axis=3, name=None)\nX_train.shape","34a550d0":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)","18d9dd5e":"y_train[0]","1372f2df":"# Building the LeNet Model\n\ninput_shape = (32, 32, 1)                                                                                                                 # Input is 32X32 with single channel as it is grayscale\nmodel = tf.keras.Sequential()                                                                                                             # Sequential groups a linear stack of layers\nmodel.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape))              # 1st Convolution layer\nmodel.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))                                                             # Average pooling\nmodel.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1),activation='tanh'))                                       # 2nd Convolution layer\nmodel.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))                                                             # Average pooling\nmodel.add(tf.keras.layers.Flatten())                                                                                                      # Flattening of the layer\nmodel.add(tf.keras.layers.Dense(units=120, activation='tanh'))                                                                            # Dense layer\nmodel.add(tf.keras.layers.Flatten())                                                                                                      # Flattening of the layer\nmodel.add(tf.keras.layers.Dense(units=84, activation='tanh'))                                                                             # Dense layer\nmodel.add(tf.keras.layers.Dense(units=10, activation='softmax'))                                                                          # Output layer\nmodel.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])                                 # Compiling","f39188ed":"# Training the Model\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test), verbose=0)","b7e9b3e9":"training_history = pd.DataFrame(history.history)\ntraining_history.columns = ['Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy']\n\n# Plotting Scores\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n\nax1.plot(training_history[['Train Loss', 'Test Loss']]);\nax1.title.set_text('Train loss V\/S Test loss')\nax1.set_xlabel('Epochs');\nax1.set_ylabel('Loss');\nax1.legend('best', labels=['Train', 'Test']);\nax1.grid(color = 'green', linestyle = '--', linewidth = 0.5);\n\nax2.plot(training_history[['Train Accuracy', 'Test Accuracy']]);\nax2.title.set_text('Train accuracy V\/S Test accuracy')\nax2.set_xlabel('Epochs');\nax2.set_ylabel('Accuracy');\nax2.legend('best', labels=['Train', 'Test']);\nax2.grid(color = 'green', linestyle = '--', linewidth = 0.5);","8aba4d10":"# Evaluate the Model on the Test Data\nmodel_performance = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {round(model_performance[0]*100, 2)}% | Test Accuracy: {round(model_performance[1]*100, 2)}%')","5954bbeb":"prediction = model.predict(X_test)\n\ndef predict_handwritten_char(index):\n  \"\"\"\n  Function to display hand written character and probability scores\n  \"\"\"\n  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 2))\n  x, y = np.arange(0, 10), prediction[index]\n\n  ax1.imshow(tf.squeeze(X_test[index]));\n  ax2.bar(x, y);\n\n  ax2.set_xticks(x);\n  ax2.set_ylabel('Probability Score');\n  ax2.set_xlabel('Hand Written Characters');","d401425d":"index = [522, 648, 67, 8796, 41]\n\nfor i in index:\n  predict_handwritten_char(i)","9b855842":"# Predict\n- Squeeze the tensor size from (32, 32, 1) to (32, 32) as imshow takes 2D array as input","2ed87595":"`y_train[0]` has a value 1 in the 5th index, which means that this array represents the number 5.","3d14310d":"### Please <font color='green'>upvote<\/font> if you found this notebook useful\n### [LinkedIn](https:\/\/www.linkedin.com\/in\/siddheshshankar94\/) | [GitHub](https:\/\/github.com\/siddheshshankar?tab=repositories) | [Linktree](https:\/\/linktr.ee\/siddheshshankar)","991dbc8f":"# Architecture\n![Parameters](https:\/\/raw.githubusercontent.com\/blurred-machine\/Data-Science\/master\/Deep%20Learning%20SOTA\/img\/arch.jpg)","22189250":"# LeNet Architecture\n- CNN is used to detect patterns in the image, character recognition, object detection, real time movement detection etc.\n- LeNet, also referred as LeNet-5 was a research article published in the year 1998.\n- LeNet was used primarily for OCR and character recognition in documents.<br><br>\n\n![LeNet Architecture](https:\/\/drek4537l1klr.cloudfront.net\/elgendy\/v-3\/Figures\/05_01.png)\n\n- We have a character 3 shown as the input image. This character has to be recognised through multiple layers. This is proposed by LeNet 1998.\n- Primary task of this architecture is given a handwritten character as input, LeNet should correctly cassify it.\n\n","48ddb044":"One-hot encode the labels: Converts a class vector (integers) to binary class matrix. This can be converted into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data.","fb3480d3":"CNN\u2019s accept 4-dimensional tensors as inputs having the dimensions of batch size, height, width, and channel. Since MNIST images are grayscale, the last dimension does not necessarily exist. We need to expand the tensor and create a dummy dimension at axis number 3."}}