{"cell_type":{"12d6f8b3":"code","2739c6f3":"code","0a8406a7":"code","b8484e4d":"code","895a8ec1":"code","1c70d478":"code","e8ed2afe":"code","e8d2ab55":"code","1bc83110":"code","4850fcad":"code","d5e90856":"code","1babcbf1":"code","bb24edc9":"code","ae96c264":"code","6e894332":"code","7cbb479d":"code","dd68c1ca":"code","9b8fc2e9":"code","b7138dbe":"code","7a74ee81":"code","2cf442d5":"code","4dba1487":"code","2b28e69a":"code","638ff44f":"code","e6fbcd50":"code","9c47cd67":"code","0620b81f":"code","497327d1":"markdown","634ad41d":"markdown","a99a9fb4":"markdown","5d545c23":"markdown","d4e263f2":"markdown"},"source":{"12d6f8b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2739c6f3":"import tensorflow as tf","0a8406a7":"data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndata","b8484e4d":"y_data = data['label']\ndata.pop('label')\nx_data = data","895a8ec1":"x_data","1c70d478":"y_data","e8ed2afe":"num_classes = len(y_data.unique())\nprint(\"Total Number of classes\", num_classes)\n\ntotal_pixels = len(x_data.columns)\nprint(\"Total Number of pixel data\", total_pixels)\n","e8d2ab55":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimage = np.array(x_data.iloc[10]).reshape(28, 28)\n# image\n\nplt.imshow(image)\n# shw.reshape(28, 28)\nplt.colorbar()\nplt.show()","1bc83110":"for i in range(8):\n    ax = plt.subplot(2, 4, i + 1)\n    plt.imshow(np.array(x_data.iloc[i]).reshape(28, 28))\n    plt.title(y_data[i])\n    plt.axis('off')","4850fcad":"from sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y = train_test_split(x_data, y_data, test_size = 0.2, random_state = 123)","d5e90856":"print(train_x.shape)\nprint(train_y.shape)\nprint(valid_x.shape)\nprint(valid_y.shape)","1babcbf1":"train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y))\nval_ds = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))","bb24edc9":"train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.batch(32).prefetch(tf.data.AUTOTUNE)","ae96c264":"kernel_size = 3\n\nrescale_layer = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1.\/255)\nreshape_layer = tf.keras.layers.Reshape((28, 28, 1))\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape = [28, 28]))\nmodel.add(reshape_layer)\nmodel.add(rescale_layer)\n\nmodel.add(tf.keras.layers.Conv2D(128, 3, activation = 'relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Conv2D(128, 3, activation = 'relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Conv2D(256, 3, activation = 'relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2, 2))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n\nmodel.compile(loss =tf.keras.losses.sparse_categorical_crossentropy, \n              optimizer = tf.keras.optimizers.Adam(lr=1e-3), \n              metrics = 'accuracy')","6e894332":"model.summary()","7cbb479d":"history = model.fit(train_ds, validation_data = val_ds, epochs = 20)","dd68c1ca":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']","9b8fc2e9":"def plot_history(train_history, val_history, label):\n  plt.plot(train_history, label=f'Training {label}')\n  plt.plot(val_history, label=f'Validation {label}')\n  plt.xlabel('Epochs')\n  plt.legend()\n  return plt.show()","b7138dbe":"plot_history(train_loss, val_loss, 'Loss')\nplot_history(train_acc, val_acc, 'Accuracy')","7a74ee81":"test_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest_data","2cf442d5":"predictions = model.predict(test_data)\nprediction_values = np.argmax(predictions,axis = 1)\nprediction_values","4dba1487":"sample_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsample_submission","2b28e69a":"y_pred = pd.DataFrame()\ny_pred['Label'] = prediction_values\ny_pred","638ff44f":"indexing = pd.DataFrame()\nindexing['ImageId'] = y_pred.index+1\nindexing","e6fbcd50":"submission = pd.concat([indexing, y_pred], axis = 1)\nsubmission.reset_index()\nsubmission","9c47cd67":"submission.to_csv('submission.csv', index=False)","0620b81f":"sample_data = pd.read_csv('.\/submission.csv')\nsample_data","497327d1":"## MODEL","634ad41d":"## READING DATA","a99a9fb4":"## TEST DATA EVALUATION","5d545c23":"## ANALYZING DATA","d4e263f2":"## PERFORMANCE EVALUATION"}}