{"cell_type":{"0d790313":"code","4c3f2439":"code","9ccb8561":"code","eb698946":"code","7eac015a":"code","089d3f7c":"code","b21b605f":"code","dd5886ff":"code","6c63fbe8":"code","2e524a19":"code","962c2fd9":"code","7eebc50f":"code","73e94513":"code","51dfdee8":"code","4cfe53a0":"code","9810ca04":"code","2888cd55":"code","86e1bacc":"code","bbc624a3":"code","8e3b0ba7":"code","1768be23":"code","680f6e43":"code","8669d7c5":"code","52c583f9":"code","5abbb757":"code","53d900db":"markdown","3c2fecb4":"markdown","fed8fcd0":"markdown","c2d1b454":"markdown","5062c738":"markdown","922803f9":"markdown","acff6221":"markdown","3278a475":"markdown","17d7bf61":"markdown","7d808740":"markdown","50c3b9fb":"markdown","f83ffda2":"markdown","d6948563":"markdown","540af836":"markdown","dcd88062":"markdown","6d61076c":"markdown","29161ecb":"markdown","1a8afe04":"markdown","d5913bf6":"markdown","88262d81":"markdown","06e49c73":"markdown"},"source":{"0d790313":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection  import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, cross_val_predict, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score","4c3f2439":"iris_data = pd.read_csv(\"..\/input\/iris\/Iris.csv\")    #reading csv file using pandas\niris_data","9ccb8561":"iris_data = iris_data.drop(['Id'], axis = 1)    # dropping Id column as it is not required\niris_data","eb698946":"iris_data.Species.unique()    # we can see that their are three types of flower species","7eac015a":"iris_data.describe()    # describe function is used to have a look on the numericals of the dataset","089d3f7c":"iris_data.info()    # info function is used to get the details of each column","b21b605f":"sns.pairplot(iris_data)    #formming pairplot graph to see relation between the columns\nplt.show()","dd5886ff":"corr = iris_data.corr()    \nsns.heatmap(corr, annot = True)     # Setting `annot = True` shows the value of each cell of heatmap","6c63fbe8":"label_encoder = preprocessing.LabelEncoder()","2e524a19":"iris_data['Species'] = label_encoder.fit_transform(iris_data['Species'])   #fit_transform is a function of label_encoder\niris_data","962c2fd9":"iris_data['Species'].value_counts()   #value_count is used to count the number of each type in the column","7eebc50f":"a = iris_data.values","73e94513":"iris_data = pd.DataFrame(preprocessing.StandardScaler().fit_transform(a))    #transforming the datapoints of variable a\niris_data","51dfdee8":"iris_data = iris_data.rename(columns={0:'SepalLengthCm',1:'SepalWidthCm',2:'PetalLengthCm',3:'PetalWidthCm',4:'Species'}) \niris_data","4cfe53a0":"iris_data['Species'].dtype","9810ca04":"iris_data['Species'] = iris_data['Species'].astype('int32')    #astype is a function to change data-type of a columns\niris_data","2888cd55":"data = iris_data.values\nX, y = data[:,:-1], data[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)    #splitting the data into 80 : 20 ratio","86e1bacc":"print(X.shape, y.shape)","bbc624a3":"def performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ' + str(classifier.best_score_))\n    print('Best Parameters: ' + str(classifier.best_params_))","8e3b0ba7":"kfold = StratifiedKFold(n_splits = 10)","1768be23":"knn = KNeighborsClassifier()\nparam_grid = {'algorithm' : ['auto'],\n             'metric':['minkowski'],\n             'metric_params':[None],\n             'p':[2],\n             'weights':['uniform']}\nclf_knn = GridSearchCV(knn, param_grid = param_grid, cv = kfold)\nbest_clf_knn = clf_knn.fit(X_train, y_train)\nperformance(best_clf_knn, 'KNeighboursClassifier')\n\n## heatmap\ny_pred = cross_val_predict(knn,X,y,cv=kfold)\nsns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix', y=1.05, size=15)","680f6e43":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"b\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"r\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","8669d7c5":"g = plot_learning_curve(best_clf_knn.best_estimator_,\"KNN mearning curves\",X_train,y_train,cv=kfold)","52c583f9":"y_pred = best_clf_knn.predict(X_test)","5abbb757":"print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, best_clf_knn.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test,y_pred))","53d900db":"A great plot comes to our notice!\ud83d\ude0b","3c2fecb4":"We created a variable named `a` to store all the values of the dataset to furthur transform them.","fed8fcd0":"## Bravo! We got great accuracy...\n### Clasififcation is 100% accurate for test data. \ud83e\udd29\ud83d\ude0e","c2d1b454":"# 3. Data Preprocessing","5062c738":"# 8. Training the Model","922803f9":"# 9. Making Predictions","acff6221":"Our data looks good now but wait! our columns' name changed as we have created a new DataFrame. So we have to rename them.","3278a475":"Please upvote this notebook if you like and find it helpful and please comment down below your views and suggestions. \n# Thank You! \ud83d\ude0a","17d7bf61":"# 6. Data Standardization\nThe result of standardization (or Z-score normalization) is that the features will be rescaled to ensure the mean and the standard deviation to be 0 and 1, respectively.","7d808740":"# 4. Data Visualization","50c3b9fb":"# 10. Checking Accuracy","f83ffda2":"There we go!! Time for Training the model...","d6948563":"# 5. Label Encoding","540af836":"Label Encoding refers to converting the labels especially, `object-type`, into numeric form so as to convert it into the machine-readable form.\nAs the dataset have only three species namely, `Iris-setosa`, `Iris-versicolor`, `Iris-virginica`, so we will use sklearn's `LabelEncoder`","dcd88062":"Look, the Species column changed into 1, 2, 3 for the three species respectively.","6d61076c":"# 1. Importing necessary Libraries ","29161ecb":"# 7. Splitting Data for Training and Testing\nBefore Training the model, it is required to split the data into train and test data. For this we will use, sklearn's `train_test_split`","1a8afe04":"For finding correlationship between the columns we will be using `heatmap`.","d5913bf6":"# 2. Reading Data","88262d81":"# Iris Species Classification Using K Nearest Neighbours (KNN)\nKNN is a model that classifies data points based on the points that are most similar to it. Also, it's to use and will less time in computation. Therefore, we will use KNN classifier training the model and making predicitions in this notebook.","06e49c73":"If we see, the species column too turned into `float dtype`, so we have to again convert it into `int dtype` for predicitions."}}