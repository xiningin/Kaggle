{"cell_type":{"72ac9444":"code","5c7edca8":"code","500c4a3b":"code","b7b5077a":"code","9633cc59":"code","5ce10342":"code","1735b4f3":"code","8062ada5":"code","4472702a":"code","92486af3":"code","a185728c":"code","c1649853":"code","a2bda585":"code","25005d4f":"code","5d196720":"code","3050e441":"code","ecb97c09":"code","66b70e29":"code","37e1f9f3":"code","2d5951b7":"code","b5de6f39":"code","0badba92":"code","a4150af7":"code","56c1c4de":"code","d38bfc08":"code","add7fd30":"code","328c62fd":"code","90ac9a74":"code","3902b081":"code","21cd4b83":"code","600f202d":"code","1b9589cc":"code","db83656d":"code","59546a41":"code","276416de":"code","43282e4d":"code","657677bb":"code","126c459f":"code","e3a56218":"code","bb5ff8fe":"code","ea27cbb2":"code","2564c108":"code","cb5c89bc":"code","8366b8c6":"code","16b853fb":"code","02d957e7":"code","4966bb91":"code","4b3d199a":"code","3a17e8aa":"markdown","cae501ad":"markdown","e0f71e26":"markdown","7764ba4a":"markdown","0af68030":"markdown","9b609355":"markdown","5d242fc8":"markdown","af518a20":"markdown","dfdd40f0":"markdown","0360e953":"markdown","0882d950":"markdown","5ade4eaf":"markdown","5070250d":"markdown","1c0054a3":"markdown","48ad5a16":"markdown","86f843f1":"markdown","853cd68e":"markdown","6ee53e58":"markdown","f32b74fc":"markdown","8f01de26":"markdown","b04c98af":"markdown","2ec62cc2":"markdown","5370a7f0":"markdown"},"source":{"72ac9444":"############\n# Packages #\n############\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\nimport numpy as np\nimport math\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom scipy import stats\nfrom IPython.display import display, Latex\n\n############\n# Settings #\n############\n# Pandas Settings\npd.set_option('max_rows', 20)\npd.set_option('display.colheader_justify', 'left')\n# plotly.express Settings\n# px.defaults.template = 'plotly_white' # \"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\npx.defaults.width = 1200\npx.defaults.height = 600\n# plotly.io Settings for both plotly.graph_objects and plotly.express\npio.templates.default = \"plotly_white\" # \"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"\n# pio.kaleido.scope.default_format = 'svg'\n# pio.kaleido.scope.default_scale = 1\n\n#############\n# Documents #\n#############\n# IPython\n#    https:\/\/ipython.org\/ipython-doc\/stable\/interactive\/reference.html#dynamic-object-information\n# Pandas\n#    https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/index.html#api\n# Numpy\n#    https:\/\/numpy.org\/doc\/stable\/reference\/index.html\n# Plotly\n#    https:\/\/plotly.com\/python-api-reference\/index.html\n# Plotly - Image Export Settings (Kaleido)\n#    https:\/\/plotly.com\/python\/static-image-export\/\n# Statistical functions (scipy.stats)\n#    https:\/\/docs.scipy.org\/doc\/scipy\/reference\/stats.html","5c7edca8":"# Source: https:\/\/docs.google.com\/spreadsheets\/d\/1MYNUtC47Pg8hdoCjOXaHqF-thheGpUshrFA21BAJnNc\/edit#gid=0\nbaseline = pd.read_csv(\n    #'https:\/\/raw.githubusercontent.com\/ZacksAmber\/Udacity-A-B-Testing-by-Google\/main\/data\/Final%20Project%20Baseline%20Values%20-%20Sheet1.csv',\n    '..\/input\/udacity-ab-testing-by-google-datasets\/data\/Final Project Baseline Values - Sheet1.csv',\n    index_col=False,\n    header=None,\n    names=['Metric Name', 'Value']\n)\n\nbaseline","500c4a3b":"# Define baseline metrics\ncookies = 40000\nclicks = 3200\n# enrollments is counted by user-ids\nenrollments = 660\n# Enrollment probability\np_enrollments = enrollments \/ cookies\n# Click-through-probability\nCTP = clicks \/ cookies\ngross_conversion = enrollments \/ clicks\nretention = 0.53\nnet_conversion = gross_conversion * retention\n\n# Dictonary of Gross conversion\nGC = {}\nGC['p'] = gross_conversion\nGC['d_min'] = 0.01\nGC['n'] = clicks\n\n# Dictonary of Retention\nR = {}\nR['p'] = retention\nR['d_min'] = 0.01\nR['n'] = enrollments\n\n# Dictonary of Net Conversion\nNC = {}\nNC['p'] = net_conversion\nNC['d_min'] = 0.0075\nNC['n'] = clicks","b7b5077a":"# Define function ge_se to calculate Standard Error\ndef get_se(p, n):\n    SE = np.sqrt(p * (1-p) \/ n)\n    return round(SE, 4)\n\nGC['SE'] = get_se(GC['p'], GC['n'])\nR['SE'] = get_se(R['p'], R['n'])\nNC['SE'] = get_se(NC['p'], NC['n'])\n\nprint(GC)\nprint(R)\nprint(NC)","9633cc59":"sample_cookies = 5000\nratio = sample_cookies \/ cookies\n\ndf_SE = pd.DataFrame({\n    'Standard Error': [get_se(GC['p'], GC['n'] * ratio), \n                       get_se(R['p'], R['n'] * ratio), \n                       get_se(NC['p'], NC['n'] * ratio)]\n    }, \n    index=['Gross conversion', 'Retention', 'Net conversion']\n)\n\ndf_SE","5ce10342":"# Z-Score\n\n# Signifiance Level\nalpha = 0.05\n# n is the number of eveluation metrics.\nn = 3\n\n# individual a of method 1\nz1 = stats.norm.ppf(1 - (alpha**(1\/n) \/ 2))\n\n# individual a of method 2, Bonferroni correction\nz2 = stats.norm.ppf(1 - (alpha\/n) \/ 2)\n\nprint(z1)\nprint(z2)","1735b4f3":"# Margin of Error\n\n# Set NumPy printionoptions\nnp.set_printoptions(suppress=True)\n# Calculate margin of error\nm1 = z1 * np.array([GC['SE'], R['SE'], NC['SE']])\nm2 = z2 * np.array([GC['SE'], R['SE'], NC['SE']])\n\nprint(np.around(m1, 4))\nprint(np.around(m2, 4))","8062ada5":"d_min = np.array([0.01, 0.01, 0.0075])\n\nprint(m1 < d_min)\nprint(m2 < d_min)","4472702a":"def get_z_score(sig):\n    \"\"\"\n    Return z-score\n    \"\"\"\n    return stats.norm.ppf(sig)\n\ndef sample_size(p1=0.10, p2=0.102, alpha=0.05, beta=0.2, alternative=\"two-sided\", formula=False):\n    \"\"\"\n    Return sample size per variation\n\n    p1: float\n        probability in control group\n        Baseline conversion rate: bcr = p1\n            An estimate of the metric being analyzed before making any changes\n    p2: float\n        probability in treatment group\n        Minimum Detectable Effect: mde = p2 - p1 = d\n            The Minimum Detectable Effect is the smallest effect that will be detected (1-\u03b2)% of the time.\n    alpha: float\n        The risk of rejecting a true hypothesis.\n    beta: float\n        The risk of accepting a false null hypothesis when a particular value of the alternative hypothesis is true.\n        Power: 1 - \u03b2, also called sensitivity\n        Sensitivity \u2014 the probability that the null hypothesis is not rejected when it should be\n\n    Reference:\n        https:\/\/itl.nist.gov\/div898\/handbook\/prc\/section2\/prc222.htm\n        https:\/\/jeffshow.com\/caculate-abtest-required-sample-size.html\n        https:\/\/www.evanmiller.org\/ab-testing\/sample-size.html\n    \"\"\"\n    if alternative == \"two-sided\":\n        z1 = get_z_score(1 - alpha\/2)\n        if formula is True:\n            display(Latex(r\"$H_0: P_A - P_B = 0$\"))\n            display(Latex(r\"$H_1: P_A - P_B = d$\"))\n            display(Latex(r\"$N = (z_{1-\\alpha\/2} + z_{1-\\beta})^2 \\left( \\frac{\\sigma}{\\delta} \\right)^2$\"))\n            # display(Latex(r\"$n=\\frac{(Z_{1-\\alpha\/2}\\sqrt{2p_1 (1-p_1)}+Z_{1-\\beta}\\sqrt{p_1(1-p_1)+p_2(1-p_2)})^2}{d^2}$\"))\n    elif alternative == \"one-sided\":\n        z1 = get_z_score(1 - alpha)\n        if formula is True:\n            display(Latex(r\"$H_0: P_A - P_B = 0$\"))\n            display(Latex(r\"$H_1: P_A - P_B = d$\"))\n            display(Latex(r\"$N = (z_{1-\\alpha} + z_{1-\\beta})^2 \\left( \\frac{\\sigma}{\\delta} \\right)^2$\"))\n            # display(Latex(r\"$n=\\frac{(Z_{1-\\alpha}\\sqrt{2p_1 (1-p_1)}+Z_{1-\\beta}\\sqrt{p_1(1-p_1)+p_2(1-p_2)})^2}{d^2}$\"))\n    else:\n        raise ValueError(\"alternative must be one of ['two-sided', 'one-sided']\")\n    z2 = get_z_score(1 - beta)\n    d = p2 - p1\n    z = z1 + z2\n    p_pool = (p1 + p2) \/ 2\n    variance = p_pool * (1 - p_pool)\n    n = z**2 * variance * 2 \/ d**2\n\n    return int(np.round(n, 0))","92486af3":"# Gross Conversion\nprint(GC)\n\n# Retention\nprint(R)\n\n# Net Conversion\nprint(NC)","a185728c":"# Sample Size (clicks or enrollments) from function sample_size()\nGC['Sample Size'] = sample_size(p1=GC['p'], p2=GC['p']+GC['d_min'], alpha=0.05, beta=0.2, alternative=\"two-sided\")\nR['Sample Size'] = sample_size(p1=R['p'], p2=R['p']+R['d_min'], alpha=0.05, beta=0.2, alternative=\"two-sided\")\nNC['Sample Size'] = sample_size(p1=NC['p'], p2=NC['p']+NC['d_min'], alpha=0.05, beta=0.2, alternative=\"two-sided\")\n\nprint(GC)\nprint(R)\nprint(NC)","c1649853":"# Sample Size (clicks or enrollments) from Evan's Awesome A\/B Tools\n# https:\/\/www.evanmiller.org\/ab-testing\/sample-size.html\nGC['Sample Size'] = 25835\nR['Sample Size'] = 39115\nNC['Sample Size'] = 27413\n\nprint(GC)\nprint(R)\nprint(NC)","a2bda585":"GC['pageviews'] = int(round(GC['Sample Size'] \/ CTP * 2, 0))\nGC['pageviews']","25005d4f":"R['pageviews'] = int(round(R['Sample Size'] \/ p_enrollments * 2))\nR['pageviews'] ","5d196720":"NC['pageviews'] = int(round(NC['Sample Size'] \/ CTP * 2))\nNC['pageviews']","3050e441":"max([GC['pageviews'], R['pageviews'], NC['pageviews']])","ecb97c09":"print(GC)","66b70e29":"df_sample_size = pd.DataFrame({\n    'Baseline Conversion Rate': [GC['p'], R['p'], NC['p']],\n    '$d_{min}$': [GC['d_min'], R['d_min'], NC['d_min']],\n    'Alpha': 0.05,\n    'Beta': 0.2,\n    'Power': 0.8,\n    'Sample Size': [GC['Sample Size'], R['Sample Size'], NC['Sample Size']],\n    'Pageviews(cookies)': [GC['pageviews'], R['pageviews'], NC['pageviews']]\n    }, index=['Gross conversion', 'Retention', 'Net conversion']\n)\n\ndef highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]\n\ndf_sample_size.style.format({\"Sample Size\": \"{:,.0f}\", \"Pageviews(cookies)\": \"{:,.0f}\"})","37e1f9f3":"# Define cookies fraction\ncookies_fraction = 1","2d5951b7":"# Duration of Gross conversion\nGC['duration'] = math.ceil(GC['pageviews'] \/ (cookies * cookies_fraction))\n\n# Duration of Retention\nR['duration'] = math.ceil(R['pageviews'] \/ (cookies * cookies_fraction))\n\n# Duration of Net conversion\nNC['duration'] = math.ceil(NC['pageviews'] \/ (cookies * cookies_fraction))","b5de6f39":"duration_table = pd.DataFrame({\n    'Metric Name': ['Gross conversion', 'Retention', 'Net conversion'],\n    'Sample Size': [GC['Sample Size'], R['Sample Size'], NC['Sample Size']], \n    'Minimum pageviews': [GC['pageviews'], R['pageviews'], NC['pageviews']],\n    'Fraction of experiment traffic': [cookies_fraction] * 3,\n    'Duration': [GC['duration'], R['duration'], NC['duration']]\n})\n\nduration_table.style.format({\"Sample Size\": \"{:,.0f}\", \"Minimum pageviews\": \"{:,.0f}\"})","0badba92":"# Source: https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0\n# Import Dataset of control\n# control = pd.read_csv('https:\/\/raw.githubusercontent.com\/ZacksAmber\/Udacity-A-B-Testing-by-Google\/main\/data\/Final%20Project%20Results%20-%20Control.csv')\ncontrol = pd.read_csv('..\/input\/udacity-ab-testing-by-google-datasets\/data\/Final Project Results - Control.csv')\n\n\ncontrol","a4150af7":"# Source: https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0\n# Import Dataset of experiment\n# experiment = pd.read_csv('https:\/\/raw.githubusercontent.com\/ZacksAmber\/Udacity-A-B-Testing-by-Google\/main\/data\/Final%20Project%20Results%20-%20Experiment.csv')\nexperiment = pd.read_csv('..\/input\/udacity-ab-testing-by-google-datasets\/data\/Final Project Results - Experiment.csv')\n\n\nexperiment","56c1c4de":"# Summarize control, skip 0, which is Date\ncontrol_sum = list(control.iloc[:, 1:].sum())\n# Summarize experiment, skip 0, which is Date\nexperiment_sum = list(experiment.iloc[:, 1:].sum())\n\n# Define DataFrame santiy_checks\nsanity_checks = pd.DataFrame({\n    'A': control_sum,\n    'B': experiment_sum,\n}, index=['cookies', 'clicks', 'enrollments', 'payments'])\n\n# Format the DataFrame\nsanity_checks = sanity_checks.astype({'A': 'int32', 'B': 'int32'})\n\nsanity_checks","d38bfc08":"sanity_checks['Total'] = sanity_checks.A + sanity_checks.B\n# For cookies and clicks, P = 0.5 for evenly spilting the traffic to control and experiment;\n# For enrollments and payments, P = 0.5, the null hypothesis is that there is no difference between control and experiment.\nsanity_checks['p'] = 0.5\n# Variance\nsanity_checks['Var'] = sanity_checks['p'] * (1 - sanity_checks['p'])\n# Standard Error\nsanity_checks['SE'] = np.sqrt(sanity_checks['Var'] \/ sanity_checks['Total'])\n# Significance Level\nsanity_checks['alpha'] = 0.05\n# Margin of Error\nsanity_checks['MOE'] = stats.norm.ppf(1 - sanity_checks['alpha']\/2) * sanity_checks['SE']\n# CI lower bound\nsanity_checks['CI lower bound'] = sanity_checks['p'] - sanity_checks['MOE']\n# CI upper bound\nsanity_checks['CI upper bound'] = sanity_checks['p'] + sanity_checks['MOE']\n# Observed\nsanity_checks['Observed'] = sanity_checks['A'] \/ sanity_checks['Total']\n# Pass or not\nsanity_checks['Pass'] = sanity_checks.apply(lambda x: (x['CI lower bound'] <= x['Observed']) and (x['Observed'] <= x['CI upper bound']),axis=1)\n# Difference\nsanity_checks['d'] = abs((sanity_checks['B'] - sanity_checks['A']) \/ sanity_checks['Total'])\n\nsanity_checks.round(4)","add7fd30":"# Define function sanity_check to calculate margin of error, confidence interval\ndef one_sample_prop(N, X, alpha=0.05, p0=0, alternative=\"two-sided\", round=4, formula=False):\n    \"\"\"\n    One-Sample Proportion for Sanity Check.\n\n    Return\n        - Margin of Error\n        - Left edge of Confidence Interval\n        - Right edge of Confidence Interval\n        - Observed probability\n        - Statistical Significance (If CI does not contain p0, return True.)\n        - Practical Significance (If CI does not contain p_hat, the difference does matter to business.)\n\n    N: int\n        Control data and Experiment data\n    X: int\n        Control data\n    alpha: float\n        Default: 0.05\n        Significance Level: between 0 to 1\n    p0: float\n        Population probability. Leave it blank if it is unknown.\n    alternative: str\n        Default: \"two-sided\"\n        One of \"two-sided\" or \"one-sided\"\n    round: int\n        Default: 4\n        Round a number to a given precision in decimal digits.\n    formula: boolean\n        Default: False\n        Display formula.\n\n    Reference:\n        [Binomial proportion confidence interval](https:\/\/en.wikipedia.org\/wiki\/Binomial_proportion_confidence_interval)\n        [Hypothesis Testing for One Sample Proportion](https:\/\/online.stat.psu.edu\/stat800\/lesson\/5\/5.2)\n\n    >>> binomial_CI(N=1000, X=450, p=0.5, alternative=\"two-sided\", round=4)\n    \"\"\"\n\n    # Validate significance level - alpha\n    if (0 <= alpha <= 1) is False:\n        raise ValueError(f'significance level (alpha) must be in the range of [0, 1]')\n\n    if alternative == \"two-sided\":\n        z = get_z_score(1 - alpha\/2)\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: p = p_0$\"))\n            display(Latex(r\"$\\displaystyle H_1: p \\neq p_0$\"))\n            display(Latex(r\"$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\"))\n            display(Latex(r\"$\\displaystyle \\displaystyle SE = \\sqrt{\\frac{\\sigma^2}{n}}$\"))\n            display(Latex(r\"$\\displaystyle Z_{\\gamma} = Z_{1 - \\frac{\\alpha}{2}}$\"))\n            display(Latex(r\"$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\cdot SE$\"))\n            display(Latex(r\"$\\displaystyle CI = \\hat p \\pm MOE_{\\gamma}$\"))\n    elif alternative == \"one-sided\":\n        z = get_z_score(1 - alpha)\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: p = p_0$\"))\n            display(Latex(r\"$\\displaystyle H_1: p \\neq p_0$\"))\n            display(Latex(r\"$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\"))\n            display(Latex(r\"$\\displaystyle \\displaystyle SE = \\sqrt{\\frac{\\sigma^2}{n}}$\"))\n            display(Latex(r\"$\\displaystyle Z_{\\gamma} = Z_{1 - \\alpha}$\"))\n            display(Latex(r\"$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\cdot SE$\"))\n            display(Latex(r\"$\\displaystyle CI = \\hat p \\pm MOE_{\\gamma}$\"))\n    else:\n        raise ValueError(\"alternative must be one of ['two-sided', 'one-sided']\")\n    \n    # Estimated probability of success, which is the sample statistic, the midpoint of Confidence Interval\n    p_hat = X \/ N\n\n    # If population probability is unknown, the program will use estimated probability for calculation.\n    if p0 == 0:\n        p = p_hat\n    else:\n        p = p0\n\n    # When not proper for normal distribution assumption\n    if N * p <= 5 or N * (1 - p) <= 5:\n        return False\n\n    # Standard Error of Two-tailed test\n    SE = math.sqrt(p * (1 - p) \/ N)\n\n    # Margin of Error\n    m = z * SE\n\n    # Left & Right boundary of Confidence Interval\n    CI_left, CI_right = p - m, p + m\n\n    # Statistical Significance\n    if CI_left <= p0 <= CI_right: # There is no difference\n        statistical_significance = False\n    elif p0 == 0:\n        statistical_significance = None\n    else:\n        statistical_significance = True\n\n    # Pratical Significance\n    if CI_left <= p_hat <= CI_right: # The difference does not matter to the business\n        pratical_significance = False\n    else:\n        pratical_significance = True\n\n    return np.round(m, round), np.round(CI_left, round), np.round(CI_right, round), np.round(p_hat, round), statistical_significance, pratical_significance","328c62fd":"df_sanity_checks = pd.DataFrame(\n    columns=['Margin of Error', 'CI lower bound', 'CI upper bound', 'Observed', 'Statistical Significance', 'Practical Significance'], \n    index=['cookies', 'clicks', 'CTP']\n    )","90ac9a74":"# Hypothesis Testing for One-Sample Proportions (Sanity Check)\n# cookies\n# p0 is 0.5\nresult = one_sample_prop(N=sanity_checks.loc['cookies', 'Total'], X=sanity_checks.loc['cookies', 'A'], p0=0.5, round=4, formula=False)\n\ndf_sanity_checks.loc['cookies', :] = result","3902b081":"# Hypothesis Testing for One-Sample Proportions (Sanity Check)\n# clicks\n# p0 is 0.5\nresult = one_sample_prop(N=sanity_checks.loc['clicks', 'Total'], X=sanity_checks.loc['clicks', 'A'], p0=0.5, round=4)\n\ndf_sanity_checks.loc['clicks', :] = result","21cd4b83":"# Hypothesis Testing for One-Sample Proportions (Sanity Check)\n# CTP\n# p0 is unknown\nresult = one_sample_prop(N=sanity_checks.loc['cookies', 'A'], X=sanity_checks.loc['clicks', 'A'], round=4)\n\ndf_sanity_checks.loc['CTP', :] = result","600f202d":"df_sanity_checks","1b9589cc":"# Summarize control, skip 0, which is Date. And filter not null rows.\ncontrol_notnull_sum = list(control[control['Enrollments'].notnull() & control['Payments'].notnull()].iloc[:, 1:].sum())\n# Summarize experiment, skip 0, which is Date. And filter not null rows.\nexperiment_notnull_sum = list(experiment[experiment['Enrollments'].notnull() & experiment['Payments'].notnull()].iloc[:, 1:].sum())","db83656d":"# Define DataFrame santiy_checks\nanalysis_test = pd.DataFrame({\n    'A': control_notnull_sum,\n    'B': experiment_notnull_sum,\n}, index=['cookies', 'clicks', 'enrollments', 'payments'])\n\n# Format the DataFrame\nanalysis_test = analysis_test.astype({'A': 'int32', 'B': 'int32'})\n\nanalysis_test","59546a41":"analysis_test.loc['Gross conversion', :] = analysis_test.loc['enrollments', :] \/ analysis_test.loc['clicks', :]\nanalysis_test.loc['Retention', :] = analysis_test.loc['payments', :] \/ analysis_test.loc['enrollments', :]\nanalysis_test.loc['Net conversion', :] = analysis_test.loc['payments', :] \/ analysis_test.loc['cookies', :]\nanalysis_test['d_min'] = [3000, 240, None, None, 0.01, 0.01, 0.0075]\nanalysis_test['Total'] = analysis_test['A'] + analysis_test['B']\n\nanalysis_test.round(4)","276416de":"def two_sample_prop(n1, n2, x1, x2, d_min, alpha=0.05, alternative=\"two-sided\", round=4, formula=False):\n    \"\"\"\n    Two-Sample Proportion for analysis.\n\n    Return\n        - Margin of Error\n        - Left edge of Confidence Interval\n        - Right edge of Confidence Interval\n        - Observed probability\n        - Statistical Significance (If CI contains 0)\n        - Practical Significance (If CI > d_min or CI < -d_min)\n\n    n1: int\n        Sample size of group A\n    n2: int\n        Sample size of group B\n    x1: int\n        Successful count of group A\n    x2: int\n        Successful count of group B\n    d_min: float\n        Minimum Effect Difference\n    alpha: float\n        Default: 0.05\n        Significance Level: between 0 to 1\n    alternative: str\n        Default: \"two-sided\"\n        One of \"two-sided\" or \"one-sided\"\n    round: int\n        Default: 4\n        Round a number to a given precision in decimal digits.\n    formula: boolean\n        Default: False\n        Display formula.\n\n    Reference\n        [Hypothesis Testing for Two-Sample Proportions](https:\/\/online.stat.psu.edu\/stat800\/lesson\/5\/5.5)\n\n    >>> two_sample_prop(n1=1000, n2=1000, x1=20, x2=57, d_min=0.02, alpha=0.05, alternative=\"two-sided\", round=4, formula=True)\n    \"\"\"\n\n    if alternative == \"two-sided\":\n        z = get_z_score(1 - alpha\/2)\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: P_A - P_B = 0$\"))\n            display(Latex(r\"$\\displaystyle H_1: P_A - P_B = d$\"))\n            display(Latex(r\"$\\displaystyle \\hat d = p_2 - p_1$\"))\n            display(Latex(r\"$\\displaystyle \\hat p = \\frac{x_1 + x_2}{n_1 + n_2}$\"))\n            display(Latex(r\"$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\"))\n            display(Latex(r\"$\\displaystyle SE = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{n_1} + \\frac{1}{n_2})}$\"))\n            display(Latex(r\"$\\displaystyle Z_{\\gamma} = Z_{1 - \\frac{\\alpha}{2}}$\"))\n            display(Latex(r\"$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\times SE$\"))\n            display(Latex(r\"$\\displaystyle CI = \\hat d \\pm MOE_{\\gamma}$\"))\n    elif alternative == \"one-sided\":\n        z = get_z_score(1 - alpha)\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: P_A - P_B = 0$\"))\n            display(Latex(r\"$\\displaystyle H_1: P_A - P_B = d$\"))\n            display(Latex(r\"$\\displaystyle \\hat d = p_2 - p_1$\"))\n            display(Latex(r\"$\\displaystyle \\hat p = \\frac{x_1 + x_2}{n_1 + n_2}$\"))\n            display(Latex(r\"$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\"))\n            display(Latex(r\"$\\displaystyle SE = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{n_1} + \\frac{1}{n_2})}$\"))\n            display(Latex(r\"$\\displaystyle Z_{\\gamma} = Z_{1 - \\alpha}$\"))\n            display(Latex(r\"$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\times SE$\"))\n            display(Latex(r\"$\\displaystyle CI = \\hat d \\pm MOE_{\\gamma}$\"))\n    else:\n        raise ValueError(\"alternative must be one of ['two-sided', 'one-sided']\")\n\n    # A is control; B is experiment\n    p1 = x1 \/ n1\n    p2 = x2 \/ n2\n    p_hat = (x1 + x2) \/ (n1 + n2)\n    SE_pool = np.sqrt(p_hat * (1 - p_hat) * (1\/n1 + 1\/n2))\n    # Difference, the CI middle point\n    d_hat = p2 - p1\n\n    # Margin of Error\n    m = z * SE_pool\n\n    # Confidence Interval\n    CI_left, CI_right = d_hat - m, d_hat + m\n\n    # Statistical Significance\n    if CI_left <= 0 <= CI_right: # There is a difference between two groups\n        statistical_significance = False\n    else:\n        statistical_significance = True\n\n    \n    # Pratical Significance\n    if CI_right < -d_min or CI_left > d_min: # The difference does matter to business\n        pratical_significance = True\n    else:\n        pratical_significance = False\n    \n    return np.round(m, round), np.round(CI_left, round), np.round(CI_right, round), np.round(d_hat, round), statistical_significance, pratical_significance","43282e4d":"df_analysis = pd.DataFrame(\n    columns=['Margin of Error', 'CI lower bound', 'CI upper bound', 'Observed', 'Statistical Significance', 'Practical Significance'], \n    index=['Gross conversion', 'Net conversion']\n    )","657677bb":"# Hypothesis Testing for Two-Sample Proportions\n# Gross conversion\nresult = two_sample_prop(n1=analysis_test.loc['clicks', 'A'], n2=analysis_test.loc['clicks', 'B'], x1=analysis_test.loc['enrollments', 'A'], x2=analysis_test.loc['enrollments', 'B'], d_min=0.01, round=4, formula=True)\n# -0.012 < -0.01 (d_min)\n\ndf_analysis.loc['Gross conversion', :] = result","126c459f":"# Hypothesis Testing for Two-Sample Proportions\n# Net conversion\nresult = two_sample_prop(n1=analysis_test.loc['clicks', 'A'], n2=analysis_test.loc['clicks', 'B'], x1=analysis_test.loc['payments', 'A'], x2=analysis_test.loc['payments', 'B'], d_min=0.0075, round=4, formula=False)\n\ndf_analysis.loc['Net conversion', :] = result","e3a56218":"df_analysis","bb5ff8fe":"# Define function binom_test returning binomial test p-value or binomial probability\ndef binom_test(x, n, p=0.5, alternative=\"two-sided\", cumulative=True, round=4, formula=False):\n    \"\"\"\n    Binomial test\n\n    Return\n        - When cumulative=False, return Probability.\n        - When cumulative=True, return cumulative Probabiltiy, which is p-value.\n\n    Return expected different d, margin of error m, CI left boundary CI_left, CI right boundary CI_right.\n\n    x: int\n        The number of successes, or if x has length 2, it is the number of successes and the number of failures.\n    n: int\n        The number of trials. This is ignored if x gives both the number of successes and failures.\n    p: float, optional\n        The hypothesized probability of success. 0 <= p <= 1. The default value is p = 0.5.\n    alternative: {\u2018two-sided\u2019, \u2018greater\u2019, \u2018less\u2019}, optional\n        Indicates the alternative hypothesis. The default value is \u2018two-sided\u2019.\n    cumulative: boolean, optional\n        Return the cumulative probability. The default value is True.\n    round: int, optional\n        Round a number to a given precision in decimal digits. The default value is 4.\n    formula: boolean\n        Display formula. The default value is False.\n\n    Reference\n        [Binomial test](https:\/\/en.wikipedia.org\/wiki\/Binomial_test)\n        [scipy.stats.binom_test](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.stats.binom_test.html#scipy.stats.binom_test)\n        [Tests with Matched Samples](https:\/\/sphweb.bumc.bu.edu\/otlt\/mph-modules\/bs\/bs704_nonparametric\/BS704_Nonparametric5.html)\n\n    >>> binom_test(n=14, x=9, p=0.5, alternative='two-sided', cumulative=True, round=4, formula=True)\n    >>> binom_test(n=14, x=9, p=0.5, alternative='greater', cumulative=True, round=4, formula=True)\n    >>> binom_test(n=14, x=9, p=0.5, cumulative=False, round=4, formula=True)\n    \"\"\"\n\n    if alternative == \"two-sided\":\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: \\pi = \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle H_1: \\pi \\neq \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle Pr(X = k) = {n \\choose k} p^k (1 - p)^{n-k}$\"))\n            display(Latex(r\"$\\displaystyle p = \\sum_{i \\in \\mathcal{I}} Pr(X = i) = \\sum_{i \\in \\mathcal{I}} {n \\choose i} p^k (1 - p)^{n-i}$\"))\n    elif alternative == \"greater\":\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: \\pi = \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle H_1: \\pi \\neq \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle Pr(X = k) = {n \\choose k} p^k (1 - p)^{n-k}$\"))\n            display(Latex(r\"$\\displaystyle p = \\sum^k_{i=0} Pr(X = i) = \\sum^k_{i=0} {n \\choose i} p^k (1 - p)^{n-i}$\"))\n    elif alternative == \"less\":\n        if formula is True:\n            display(Latex(r\"$\\displaystyle H_0: \\pi = \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle H_1: \\pi \\neq \\pi_0$\"))\n            display(Latex(r\"$\\displaystyle Pr(X = k) = {n \\choose k} p^k (1 - p)^{n-k}$\"))\n            display(Latex(r\"$\\displaystyle p = \\sum^k_{i=0} Pr(X = i) = \\sum^k_{i=0} {n \\choose i} p^k (1 - p)^{n-i}$\"))\n    else:\n        raise ValueError(\"alternative must be one of ['two-sided', 'greater', 'less']\")\n\n    if cumulative is True:\n        return np.round(stats.binom_test(x, n, p, alternative), round)\n    else:\n        return np.round(math.comb(n, k) * p**k * (1-p)**(n-k), round)","ea27cbb2":"notnull_control = control[control.Payments.notnull()]\nnotnull_experiment = experiment[experiment.Payments.notnull()]","2564c108":"# The number of successful trials, when the Gross conversion in experiment is greater than it is in the control\nx = sum(notnull_experiment.Enrollments \/ notnull_experiment.Clicks > notnull_control.Enrollments \/ notnull_control.Clicks)\nn = len(notnull_experiment)\n\nbinom_test(x=x, n=n, p=0.5, cumulative=True, alternative='two-sided', formula=True)","cb5c89bc":"# The number of successful trials, when the Net conversion in experiment is greater than it is in the control\nx = sum(notnull_experiment.Payments \/ notnull_experiment.Clicks > notnull_control.Payments \/ notnull_control.Clicks)\nn = len(notnull_experiment)\n\nbinom_test(x=x, n=n, p=0.5, cumulative=True, alternative='two-sided', formula=False)","8366b8c6":"# Define function bootstrapped_df to return the mean of Gross conversion and Net conversion through simulation\ndef bootstrapped_metric(df1, df2, repetitions):\n    sample_size1 = len(df1)\n    sample_size2 = len(df2)\n    d_GC = np.array([])\n    d_NC = np.array([])\n    \n    for i in range(repetitions):\n        # Sampling\n        sample1 = df1.sample(n=sample_size1, replace=True, random_state=i) # Use the same random_state to ensure we have the same row number\n        sample2 = df2.sample(n=sample_size2, replace=True, random_state=i)\n        # Generate one value\n        # Gross conversion = Enrollments \/ Clicks\n        gross_conversion1 = sample1['Enrollments'].sum() \/ sample1['Clicks'].sum()\n        gross_conversion2 = sample2['Enrollments'].sum() \/ sample2['Clicks'].sum()\n        d_GC = np.append(d_GC, gross_conversion2 - gross_conversion1)\n        # Net conversion = Payments \/ Clicks\n        net_conversion1 = sample1['Payments'].sum() \/ sample1['Clicks'].sum()\n        net_conversion2 = sample2['Payments'].sum() \/ sample2['Clicks'].sum()\n        d_NC = np.append(d_NC, net_conversion2 - net_conversion1)\n\n    return d_GC, d_NC","16b853fb":"d_GC, d_NC = bootstrapped_metric(notnull_control, notnull_experiment, repetitions=10000)","02d957e7":"# Define bootstrapped_hist to draw the histogram\ndef bootstrapped_hist(array, label, d_min, alpha):\n    # Confidence Level\n    CL = 1 - alpha\n    left_tail = alpha \/ 2\n    left = np.quantile(array, q=left_tail, interpolation='higher')\n\n    right_tail = alpha \/ 2 + CL\n    right = np.quantile(array, q=right_tail, interpolation='higher')\n\n    # Histogram\n    fig = go.Figure()\n    fig.add_trace(\n        go.Histogram(\n            x=array,\n            histnorm='percent',\n            name=label,\n            marker_color=\"rgba(55, 73 ,99, .9)\" # rgb + opacity\n        )\n    )\n\n    # Empirical confidence interval\n    fig.add_shape(\n        type=\"line\", \n        x0=left, y0=0, \n        x1=right, y1=0, \n        line_color=\"yellow\",\n        name='Empirical CI'\n    )\n    # Statistical confidence interval\n    fig.add_shape(\n        type=\"line\", \n        x0=df_analysis.loc[label, 'CI lower bound'], y0=-0.02, \n        x1=df_analysis.loc[label, 'CI upper bound'], y1=-0.02, \n        line=dict(\n            color='black',\n            dash='dashdot'\n        ),\n        name='Statistical CI'\n    )\n    # Mark +d_min\n    fig.add_trace(\n        go.Scatter(\n            mode=\"markers\",\n            x=[d_min],\n            y=[0],\n            name=f\"+{d_min}\",\n            marker=dict(\n                color=\"red\",\n                size=9\n            )\n        )\n    )\n    # Mark -d_min\n    fig.add_trace(\n        go.Scatter(\n            mode=\"markers\",\n            x=[-d_min],\n            y=[0],\n            name=f\"-{d_min}\",\n            marker=dict(\n                color=\"red\",\n                size=9\n            )\n        )\n    )\n    # Set layout\n    title = f\"{label} Distribution of difference\"\n    title += f\"<br>Experiment Times: 10,000\"\n    fig.update_layout(\n        title=title,\n        xaxis_title=f'{label} difference',\n        yaxis_title='Percent',\n        width=1200,\n        height=600\n    )\n\n    # Save plot to the root directory of the current Python kernel.\n    # fig.write_image(f\"{label}.svg\")\n\n    return fig","4966bb91":"# Gross conversion\nbootstrapped_hist(d_GC, label='Gross conversion', d_min=0.01, alpha=0.05)","4b3d199a":"# Net conversion\nbootstrapped_hist(d_NC, label='Net conversion', d_min=0.0075, alpha=0.05)","3a17e8aa":"\n---\n\n## Analysis\n\nThe data for you to analyze is [here](https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0). This data contains the raw information needed to compute the above metrics, broken down day by day. Note that there are two sheets within the spreadsheet - one for the experiment group, and one for the control group.\n\n\nThe meaning of each column is:\n\n- **Pageviews**: Number of unique cookies to view the course overview page that day.\n- **Clicks**: Number of unique cookies to click the course overview page that day.\n- **Enrollments**: Number of user-ids to enroll in the free trial that day.\n- **Payments**: Number of user-ids who enrolled on that day to remain enrolled for 14 days and thus make a payment. (Note that the date for this column is the start date, that is, the date of enrollment, rather than the date of the payment. The payment happened 14 days later. Because of this, the enrollments and payments are tracked for 14 fewer days than the other columns.)\n\n\n### Sanity Checks (A\/A Test)\n\nStart by checking whether your invariant metrics are equivalent between the two groups. If the invariant metric is a simple count that should be randomly split between the 2 groups, you can use a binomial test as demonstrated in Lesson 5. Otherwise, you will need to construct a confidence interval for a difference in proportions using a similar strategy as in Lesson 1, then check whether the difference between group values falls within that confidence level.\n\n\nIf your sanity checks fail, look at the day by day data and see if you can offer any insight into what is causing the problem.\n\n**Q: For each metric that you choose as an invariant metric, compyte a 95% confidence interval for the value you expect to observe. Enter the upper and lower bounds, and the observed value, all to 4 decimal places.**\n\nInvariant Metrics:\n- cookies(pageviews)\n- clicks\n- CTP(Clicks-through-probability, whichs is clicks \/ cookies)\n\nUse the information from [Final Project Results: Control and Experiment](https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0) to answer the analysis questions. Note that control data and experiment data are on separate tabs of the spreadsheet.\n\n**A:**\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th><\/th>\n      <th>Margin of Error<\/th>\n      <th>CI lower bound<\/th>\n      <th>CI upper bound<\/th>\n      <th>Observed<\/th>\n      <th>Statistical Significance<\/th>\n      <th>Practical Significance<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>cookies<\/th>\n      <td>0.0012<\/td>\n      <td>0.4988<\/td>\n      <td>0.5012<\/td>\n      <td>0.5006<\/td>\n      <td>False<\/td>\n      <td>False<\/td>\n    <\/tr>\n    <tr>\n      <th>clicks<\/th>\n      <td>0.0041<\/td>\n      <td>0.4959<\/td>\n      <td>0.5041<\/td>\n      <td>0.5005<\/td>\n      <td>False<\/td>\n      <td>False<\/td>\n    <\/tr>\n    <tr>\n      <th>CTP<\/th>\n      <td>0.0009<\/td>\n      <td>0.0812<\/td>\n      <td>0.083<\/td>\n      <td>0.0821<\/td>\n      <td>None<\/td>\n      <td>False<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n\nTips:\n- Statistical Significance (If CI does not contain p0, return True.)\n- Practical Significance (If CI does not contain p_hat, the difference does matter to business.)\n\n---\n\n#### Hypothesis Testing for One Sample Proportion\n> [Binomial proportion confidence interval](https:\/\/en.wikipedia.org\/wiki\/Binomial_proportion_confidence_interval)\n> [Hypothesis Testing for One Sample Proportion](https:\/\/online.stat.psu.edu\/stat800\/lesson\/5\/5.2)\n\nIf we have $p$, use $p$ instead of $\\hat p$.\n\n$\\displaystyle H_0: p = p_0$\n\n$\\displaystyle H_1: p \\neq p_0$\n\n$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\n\n$\\displaystyle \\displaystyle SE = \\sqrt{\\frac{\\sigma^2}{n}}$\n\n$\\displaystyle Z_{\\gamma} = Z_{1 - \\alpha}$\n\n$\\displaystyle Z_{\\gamma} = Z_{1 - \\frac{\\alpha}{2}}$\n\n$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\cdot SE$\n\n$\\displaystyle CI = \\hat p \\pm MOE_{\\gamma}$","cae501ad":"A: According to above table, when we assign 100% daily traffic to this experiment, we have the minimum duration. We only have 40,000 pageviews (unique cookies) per day. Therefore, we need to abandon `Retention` as an qualified evaluation metric due to the too long-running experiment.\n\nThe minimum duration for `Gross conversion` and `Net conversion` are 17 days and 18 days. For ensuring the effectiveness of the experiment, we need run the experiment at least 18 days.","e0f71e26":"---\n\n## Calculating Standard Error\n\n**Q: For each metric you selected as an evaluation metric, make an analytic estimate of its standard error, given a sample size of 5,000 cookies visiting the course overview page. Enter each estimate in the appropriate box to 4 decimal places**\n\nHints\nHint 1: Make sure you are only using information given in the [table of baseline values](https:\/\/docs.google.com\/a\/knowlabs.com\/spreadsheets\/d\/1MYNUtC47Pg8hdoCjOXaHqF-thheGpUshrFA21BAJnNc\/edit#gid=0). Do not use [the results of the experiment](https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0), since this step should be done before the experiment is run.\n\nHint 2: Make sure you figure out how many units of analysis will correspond to 5000 pageviews for each metric. Again, use the given [baseline values](https:\/\/docs.google.com\/a\/knowlabs.com\/spreadsheets\/d\/1MYNUtC47Pg8hdoCjOXaHqF-thheGpUshrFA21BAJnNc\/edit#gid=0).\n\n> [Standard error](https:\/\/en.wikipedia.org\/wiki\/Standard_error)\n\n$\\displaystyle \\sigma^2 = p(1 - p)$\n\n$\\displaystyle SE = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}$\n\n---\n\n**A:**\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th><\/th>\n      <th>Standard Error<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>Gross conversion<\/th>\n      <td>0.0202<\/td>\n    <\/tr>\n    <tr>\n      <th>Retention<\/th>\n      <td>0.0549<\/td>\n    <\/tr>\n    <tr>\n      <th>Net conversion<\/th>\n      <td>0.0156<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>","7764ba4a":"---\n\n### Effect Size Tests\n\nNext, for your evaluation metrics, calculate a confidence interval for the difference between the experiment and control groups, and check whether each metric is statistically and\/or practically significance. A metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)\n\n\nIf you have chosen multiple evaluation metrics, you will need to decide whether to use the Bonferroni correction. When deciding, keep in mind the results you are looking for in order to launch the experiment. Will the fact that you have multiple metrics make those results more likely to occur by chance than the alpha level of 0.05?\n\n**Q: For each of your evaluation metrics, comput a confidence interval around the difference.**\n\n**A:**\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th><\/th>\n      <th>Margin of Error<\/th>\n      <th>CI lower bound<\/th>\n      <th>CI upper bound<\/th>\n      <th>Observed<\/th>\n      <th>Statistical Significance<\/th>\n      <th>Practical Significance<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>Gross conversion<\/th>\n      <td>0.0086<\/td>\n      <td>-0.0291<\/td>\n      <td>-0.012<\/td>\n      <td>-0.0206<\/td>\n      <td>True<\/td>\n      <td>True<\/td>\n    <\/tr>\n    <tr>\n      <th>Net conversion<\/th>\n      <td>0.0067<\/td>\n      <td>-0.0116<\/td>\n      <td>0.0019<\/td>\n      <td>-0.0049<\/td>\n      <td>False<\/td>\n      <td>False<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n\n**Q: Did you use the Bonferroni correction?**\n- No\n\n---\n\nEvaluation Metrics:\n- Gross conversion\n- Net conversion\n\nThe experiment data can be found in [this spreadsheet](https:\/\/docs.google.com\/spreadsheets\/d\/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8\/edit#gid=0); use this information to answer the analysis questions. Note that control data and experiment data are on separate tabs of the spreadsheet.\n\n> [Hypothesis Testing for Two-Sample Proportions](https:\/\/online.stat.psu.edu\/stat800\/lesson\/5\/5.5)\n\n$\\displaystyle H_0: P_A - P_B = 0$\n\n$\\displaystyle H_1: P_A - P_B = d$\n\n$\\displaystyle \\hat d = p_2 - p_1$\n\n$\\displaystyle \\hat p = \\frac{x_1 + x_2}{n_1 + n_2}$\n\n$\\displaystyle \\sigma^2 = \\hat p (1 - \\hat p)$\n\n$\\displaystyle SE = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{n_1} + \\frac{1}{n_2})}$\n\n$\\displaystyle Z_{\\gamma} = Z_{1 - \\frac{\\alpha}{2}}$\n\n$\\displaystyle Z_{\\gamma} = Z_{1 - \\alpha}$\n\n$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\times SE$\n\n$\\displaystyle CI = \\hat d \\pm MOE_{\\gamma}$","0af68030":"**A:**\n\nThe potential frustrated students have two categories:\n- Category A: Students who do not finish the prerequisite courses.\n- Category B: Students who have issues but cannot find any help.\n\n`Cancellation rate` definition:\n- `Gross conversion` - `Net conversion`\n\n---\n\n### Experiment 1\n\nFor Category A students, Udacity can ask them when they click on \"start free trial\". This experiment is highly similar to the current experiment.\n\n- **Experiment**: A reminder of prerequisite courses for Free Trial\n- **Goal**: Minimize the course cancellation rate of **\"Free Trial\"** users by guiding the improper students to the basic course.\n- **Experiment Hypothesis**: The hypothesis was that this might set a clearer entrance for students who are able to finish the courses. For the students who need to finish prerequisite courses, guide them to the basic courses page, leading to a decrease in the number of frustrated students. The `clicks` will be tracked before the \"free trial\" started. If the experiment hypothesis is true, the experiment will have lower `enrollments`, leading to lower `Gross conversion` and higher `Net conversion`. Therefore, we have lower `Cancellation rate`.\n- **Experiment Change**: For the users who click on **\"start free trial\"**, Udacity will ask the users whether or not they have enough basic knowledge to complete the course.\n- **Unit of diversion**: cookies\n\nMetrics:\n\n- **Number of cookies**: That is, number of unique cookies to view the course overview page. ($d_{min}=3000$)\n- **Number of user-ids**: That is, number of users who enroll in the free trial. ($d_{min}=50$)\n- **Number of clicks**: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). ($d_{min}=240$)\n- **Click-through-probability**: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. ($d_{min}=0.01$)\n- **Gross conversion**: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. ($d_min=0.01$)\n- **Retention**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of user-ids to complete checkout. ($d_{min}=0.01$)\n- **Net conversion**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.0075$)","9b609355":"Given the sample size of cookies is 5,000, and the above calculations are based on the cookies of 40,000. Therefore, we need to adjust each `n` to the ratio of 5,000:40,000.","5d242fc8":"---\n\n## Follow-Up Experiment: How to Reduce Early Cancellations\n\n**Q: If you wanted to reduce the number of frustrated students who cancel early in the course, what experiment would you try? Give a brief description of the change you would make, what your hypothesis would be about the effect of the change, what metrics you would want to measure, and what unit of diversion you would use. Include an explanation of each of your choices.**","af518a20":"Before calcuating the minimum pageviews(unique cookies) for each metric, we need to know that the above minimum sample size is `clicks` or `enrollments`(counted by user-id). Therefore, we need to divide them by probability.\n- CTP = clicks \/ cookies\n- p_enrollment = enrollments \/ cookies\n\nFor `Gross conversion`, the formula is $\\frac{C_{enrollments}}{C_{clicks}}$. The unit of diversion is `clicks`. So the number of minimum pageviews is $\\displaystyle clicks \\div CTP \\cdot 2 \\Rightarrow clicks \\div \\frac{clicks}{cookies} \\cdot 2$","dfdd40f0":"The maximum pageviews for two gruops from `Gross conversion`, `Retention`, and `Net conversion` is 4,741,212.","0360e953":"\n---\n\n### Experiment 2\n\nFor Category B students, Udacity can track the students' stats. For instance, make a trigger system that lets the coach contact the students who submit the wrong answers more than three times for the same question.\n\n- **Experiment**: An initiative coaching service for frustrated students\n- **Goal**: Minimize the course cancellation rate of **\"Free Trial\"** users by providing initiative coaching services to the students.\n- **Experiment Hypothesis**: The hypothesis was that this might set a trigger system for providing initiative coaching services to the students who stuck in the quizzes or assignments. After helping the frustrated students, the course completion rate may be increased. If the hypothesis is true, the experiment will have a higher `Net conversion`. Therefore, we have a lower `Cancellation rate`.\n- **Experiment Change**: For the users who click on **\"start free trial\"** and have issues, Udacity provides initiative coaching services.\n- **Unit of diversion**: cookies\n\nMetrics:\n\n- **Number of cookies**: That is, number of unique cookies to view the course overview page. ($d_{min}=3000$)\n- **Number of user-ids**: That is, number of users who enroll in the free trial. ($d_{min}=50$)\n- **Number of clicks**: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). ($d_{min}=240$)\n- **Click-through-probability**: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. ($d_{min}=0.01$)\n- **Gross conversion**: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. ($d_min=0.01$)\n- **Retention**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of user-ids to complete checkout. ($d_{min}=0.01$)\n- **Net conversion**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.0075$)","0882d950":"---\n\n### Choosing Duration and Exposure\n\n**Q: What percentage of Udacity's traffic would you divert to this experiment (assuming there were no other experiments you wanted to run simultaneously)? Is the change risky enough that you wouldn't want to run on all traffic?**\n\n**Q: Given the percentage you chose, how long would the experiment take to run, using the analytic estimates of variance? If the answer is longer than a few weeks, then this is unreasonably long, and you should reconsider an earlier decision.**\n\n- **Udacity currently has 40,000 pageviews (unique cookies) to view course overview page per day.**\n- For calculating the minimum duration, we divert 100% daily cookies for this experiment. You can also modify the fraction.\n\n**A:**\n\n<table id=\"T_99a59_\"><thead>    <tr>        <th class=\"blank level0\"><\/th>        <th class=\"col_heading level0 col0\">Metric Name<\/th>        <th class=\"col_heading level0 col1\">Sample Size<\/th>        <th class=\"col_heading level0 col2\">Minimum pageviews<\/th>        <th class=\"col_heading level0 col3\">Fraction of experiment traffic<\/th>        <th class=\"col_heading level0 col4\">Duration<\/th>    <\/tr><\/thead><tbody>\n                <tr>\n                        <th id=\"T_99a59_level0_row0\" class=\"row_heading level0 row0\">0<\/th>\n                        <td id=\"T_99a59_row0_col0\" class=\"data row0 col0\">Gross conversion<\/td>\n                        <td id=\"T_99a59_row0_col1\" class=\"data row0 col1\">25,835<\/td>\n                        <td id=\"T_99a59_row0_col2\" class=\"data row0 col2\">645,875<\/td>\n                        <td id=\"T_99a59_row0_col3\" class=\"data row0 col3\">1<\/td>\n                        <td id=\"T_99a59_row0_col4\" class=\"data row0 col4\">17<\/td>\n            <\/tr>\n            <tr>\n                        <th id=\"T_99a59_level0_row1\" class=\"row_heading level0 row1\">1<\/th>\n                        <td id=\"T_99a59_row1_col0\" class=\"data row1 col0\">Retention<\/td>\n                        <td id=\"T_99a59_row1_col1\" class=\"data row1 col1\">39,115<\/td>\n                        <td id=\"T_99a59_row1_col2\" class=\"data row1 col2\">4,741,212<\/td>\n                        <td id=\"T_99a59_row1_col3\" class=\"data row1 col3\">1<\/td>\n                        <td id=\"T_99a59_row1_col4\" class=\"data row1 col4\">119<\/td>\n            <\/tr>\n            <tr>\n                        <th id=\"T_99a59_level0_row2\" class=\"row_heading level0 row2\">2<\/th>\n                        <td id=\"T_99a59_row2_col0\" class=\"data row2 col0\">Net conversion<\/td>\n                        <td id=\"T_99a59_row2_col1\" class=\"data row2 col1\">27,413<\/td>\n                        <td id=\"T_99a59_row2_col2\" class=\"data row2 col2\">685,325<\/td>\n                        <td id=\"T_99a59_row2_col3\" class=\"data row2 col3\">1<\/td>\n                        <td id=\"T_99a59_row2_col4\" class=\"data row2 col4\">18<\/td>\n            <\/tr>\n    <\/tbody><\/table>\n    \nAccording to above table, when we assign 100% daily traffic to this experiment, we have the minimum duration. We only have 40,000 pageviews (unique cookies) per day. Therefore, we need to abandon `Retention` as an qualified evaluation metric due to the too long-running experiment.","5ade4eaf":"With respect to FWER control, the Bonferroni correction can be conservative if there are a large number of tests and\/or the test statistics are positively correlated.\n\nThus, I decided not to use Bonferroni correction.\n\n---\n\n### Sample Size per Variation\n\n$\\displaystyle  \\hat p_{pool}= \\frac{X_{cont}+X_{exp}}{N_{cont}+ N_{exp}}$\n\n$\\displaystyle \\sigma^2 = \\hat p_{pool}(1 - \\hat p_{pool})$\n\n$\\displaystyle SE_{pool} = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})}$\n\nFor calculating the minimize sample size of control and experiment, $N_{cont} = N_{exp}= N$, then we have:\n$\\displaystyle \\hat p_{pool} = \\frac{X_{cont}+X_{exp}}{N + N} = \\frac{X_{cont}}{2N} + \\frac{X_{exp}}{2N} = \\frac{p_{cont}}{2} + \\frac{p_{exp}}{2} = \\frac{p_{cont} + p_{exp}}{2}$\n\nTherefore:\n\n$\\displaystyle SE_{pool} = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})} = \\sqrt{\\sigma^2 \\cdot (\\frac{1}{N} + \\frac{1}{N})} = \\sqrt{\\sigma^2 \\cdot \\frac{2}{N}}$\n\nIn this case, $d_{min}$ is equal to Margin of Error.\n\n$d_{min} = p_{exp} - p_{cont}$\n\n$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\cdot SE = d_{min}$\n\n$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\cdot SE_{pool} \\Rightarrow d_{min} = Z_{\\gamma} \\cdot \\sqrt{\\sigma^2 \\cdot \\frac{2}{N}} \\Rightarrow d_{min}^2 = Z_{\\gamma}^2 \\cdot \\sigma^2 \\cdot \\frac{2}{N} \\Rightarrow N = \\frac{Z_{\\gamma}^2 \\cdot \\hat p_{pool} \\cdot (1 - \\hat p_{pool}) \\cdot 2}{d^2}$\n\n$\\displaystyle N = \\frac{Z_{\\gamma}^2 \\cdot \\hat p_{pool} \\cdot (1 - \\hat p_{pool}) \\cdot 2}{d^2} = (z_{1-\\alpha\/2} + z_{1-\\beta})^2 \\left( \\frac{\\sigma}{\\delta} \\right)^2 \\Rightarrow \\mbox{for two-sided test}$\n\n$\\displaystyle N = \\frac{Z_{\\gamma}^2 \\cdot \\hat p_{pool} \\cdot (1 - \\hat p_{pool}) \\cdot 2}{d^2} = (z_{1-\\alpha} + z_{1-\\beta})^2 \\left( \\frac{\\sigma}{\\delta} \\right)^2 \\Rightarrow \\mbox{for one-sided test}$\n\n---\n\n#### Calculating Number of Pageviews\n\nThe above formula is used by R power.prop.test and Evan's Awesome A\/B Tools.\n\nYou can also visit [Evan's Awesome A\/B Tools](https:\/\/www.evanmiller.org\/ab-testing\/sample-size.html) to calculate the power. \n\nHowever, there is a error between Evan's Awesome A\/B Tools and the formula. Using the proper values as you need.","5070250d":"# Udacity A\/B Testing by Google\n\nThe final project of Udacity A\/B Testing by Google.\n\n[This project](https:\/\/classroom.udacity.com\/courses\/ud257\/lessons\/4126079196\/concepts\/42072285530923) is from Udacity free course [A\/B Testing by Google](https:\/\/www.udacity.com\/course\/ab-testing--ud257).\n\n---\n\nGithub: [Udacity-A-B-Testing-by-Google](https:\/\/github.com\/ZacksAmber\/Udacity-A-B-Testing-by-Google)\n\nYouTube: [15 Minutes Data Science: Udacity Course Completion A\/B Testing](https:\/\/youtu.be\/13d0D6zCwkY)\n\nKaggle: [Udacity-A-B-Testing-by-Google](https:\/\/www.kaggle.com\/zacksshen\/udacity-ab-testing-by-google)\n\nAuthor: [Zacks Shen](https:\/\/www.linkedin.com\/in\/zacks-shen\/)\n\n---\n\nReference:\n\n> [AB Testing With Python - Walkthrough Udacity's Course Final Project](https:\/\/www.kaggle.com\/tammyrotem\/ab-tests-with-python\/comments)\n\n> [Udacity-AB-Testing-Final-Project](https:\/\/github.com\/shubhamlal11\/Udacity-AB-Testing-Final-Project)","1c0054a3":"Here is the table of three evaluation metrics.\n\n|Metric Name|Metric Formula|$d_{min}$|Notation|Python Notation|\n|:-:|:-:|:-:|:-:|:-:|\n|Gross conversion|$\\frac{C_{enrollments}}{C_{clicks}}$|0.01|Gross conversion|`gross_conversion`|\n|Retention|$\\frac{C_{payments}}{C_{enrollments}}$|0.01|Retention|`retention`|\n|Net conversion|$\\frac{C_{payments}}{C_{clicks}}$|0.0075|Net conversion|`net_conversion`|","48ad5a16":"---\n\n## Make a Recommendation\n\n**Q: Finally, make a recommendation. Would you launch this experiment, not launch it, dig deeper, run a follow-up experiment, or is it a judgment call? If you would dig deeper, explain what area you would investigate. If you would run follow-up experiments, briefIy describe that experiment. If it is a judgment call, explain what factors would be relevant to the decision.**","86f843f1":"---\n\n## Sign Test\n\nFor each evaluation metric, do a sign test using the day-by-day breakdown. If the sign test does not agree with the confidence interval for the difference, see if you can figure out why.\n\n**Q: Run a  sign test on each of your evaluation metrics using the day-by-day data. Enter each pvalue, and indicate whether each result is statistically significant.**\n\n\n**A:**\n\n- The p-value of Gross conversion is 0.0026, which is less than 0.05. Therefore, Gross conversion is statistically significant.\n- The p-value of Net conversion is 0.6776, which is greater than 0.05. Therefore, Net conversion is not statistically significant.\n\n---\n\n> [Binomial test](https:\/\/en.wikipedia.org\/wiki\/Binomial_test)\n\n$\\displaystyle H_0: \\pi = \\pi_0$\n\n$\\displaystyle Pr(X = k) = {n \\choose k} p^k (1 - p)^{n-k}$\n\none-tailed\n- $\\displaystyle p = \\sum^k_{i=0} Pr(X = i) = \\sum^k_{i=0} {n \\choose i} p^k (1 - p)^{n-i}$\n\ntwo-tailed\n- $\\displaystyle p = \\sum_{i \\in \\mathcal{I}} Pr(X = i) = \\sum_{i \\in \\mathcal{I}} {n \\choose i} p^k (1 - p)^{n-i}$","853cd68e":"**A:**\n\nRecall the definitions of the following metrics:\n- **Number of clicks** is the unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). \n- **Enrollments**: Number of user-ids to enroll in the free trial that day.\n- **Payments**: Number of user-ids who enrolled on that day to remain enrolled for 14 days and thus make a payment. (Note that the date for this column is the start date, that is, the date of enrollment, rather than the date of the payment. The payment happened 14 days later. Because of this, the enrollments and payments are tracked for 14 fewer days than the other columns.)\n\nTo be more clear, the **Payments** is included in the **Enrollments**, which means there are two kinds of users:\n- Enrolled in the \"start free trial\" and make a payment\n- Enrolled in the \"start free trial\" and do not make a payment\n\nTherefore, if we can reduce the users of enrollments but keep the payments the same. We can assign the coaching services to potential paying users effectively and have the same revenue, leading to an increase in the users experience.\n\n---\n\nBased on our analysis, The Confidence Interval of Gross conversion ($\\displaystyle \\frac{C_{enrollments}}{C_{clicks}}$) is [-0.0291, -0.012] with a 95% confidence level. And it is statistical significance and practical significance. Therefore, we are 95% confident that after applying the change (asking users who do not have 5 hours for learning per week to switch to \"access course materials\"), the overall enrollments decreased, which means some users decide not to enroll in the \"start free trial\". It will help Udacity effectively distribute the human resource to the potential paying users.\n\nAdditionally, the Confidence Interval of the Net conversion ($\\displaystyle \\frac{C_{payments}}{C_{clicks}}$) is [-0.0116, 0.0019] with 95% confidence level. And it neither statistical significance or practical significance. Therefore, we are 95% confident that after applying the change, there is no difference between the control and experiment, which means we stay the payments at the same level but reduce the overall users of \"start free trial\". Because some users of \"start free trial\" may not continue to check out. Our target is to suggest this kind of users switch to \"access course materials\".\n\n---\n\nIn conclusion, I recommend launching this change in the production environment. It can help Udacity reach the original goal:\n- Improving the experience of the rest users of \u201cstart free trials\u201d since Udacity has less users to share the coaching services.\n\n\nBeyond the one goal, there are three extra benefits: \n- With the users' experience improved, Udacity may attract more potential users.\n- Or Udacity can keep the user experience at the same level and reduce the current coaching teams in order to decrease the cost.\n- The change will not make a directly tremendous impact on the current revenue.","6ee53e58":"## Hypothesis Testing\n\n- control group, also called group`A`.\n- experiment group, also called group `B`.\n\n- **Null Hypothesis**: There is no difference in group `A` and `B`.\n- **Alternative Hypothesis**: There is a difference in group `A` and `B`.\n\n$\\displaystyle H_0: P_B - P_A = 0$\n\n$\\displaystyle H_1: P_B - P_A \\neq 0 \\Rightarrow P_B - P_A = d$\n\n[Type I Error](https:\/\/en.wikipedia.org\/wiki\/Type_I_and_type_II_errors):\n$\\alpha$ = P({reject null | null true})\n\n[Type II Error](https:\/\/en.wikipedia.org\/wiki\/Type_I_and_type_II_errors):\n$\\beta$ = P({failed to reject | null false})\n\n[Power](https:\/\/en.wikipedia.org\/wiki\/Power_of_a_test):\n$1 - \\beta$\n\n<img src=\"https:\/\/i.stack.imgur.com\/R0ncP.png\" width=800 height=400 \/>\n\n<img src=\"http:\/\/strata.uga.edu\/8370\/lecturenotes\/images\/errors.png\" width=800 height=400 \/>\n\n\n---\n\n## Metrics Choice\n\nA\/B Testing requires two types of metrics: Invariant Metrics and Evaluation Metrics.\n\nThe following are the possible metrics:\n\nAny place \"unique cookies\" are mentioned, the uniqueness is determined by day. (That is, the same cookie visiting on different days would be counted twice.) User-ids are automatically unique since the site does not allow the same user-id to enroll twice.\n\n- **Number of cookies**: That is, number of unique cookies to view the course overview page. ($d_{min}=3000$)\n- **Number of user-ids**: That is, number of users who enroll in the free trial. ($d_{min}=50$)\n- **Number of clicks**: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). ($d_{min}=240$)\n- **Click-through-probability**: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. ($d_{min}=0.01$)\n- **Gross conversion**: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.01$)\n- **Retention**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of user-ids to complete checkout. ($d_{min}=0.01$)\n- **Net conversion**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.0075$)\n\n\n---\n\n### The Process of Users' Behaviors\n\nFor more details, watch the video: [15 Minutes Data Science: Udacity Course Completion A\/B Testing](https:\/\/youtu.be\/13d0D6zCwkY)\n\n![](https:\/\/raw.githubusercontent.com\/ZacksAmber\/PicGo\/master\/img\/20210610235631.png)\n\n![](https:\/\/raw.githubusercontent.com\/ZacksAmber\/PicGo\/master\/img\/20210610235809.png)\n\n![](https:\/\/raw.githubusercontent.com\/ZacksAmber\/PicGo\/master\/img\/20210611000004.png)\n\n  1. Visit Udacity website\n  2. Open course page (`cookies` or called `pageviews`)\n  3. Choose \"start free trial\" or \"access course materials\".\n     1. \"access course materials\"\n        1. Free users -> no charging\n     2. \"start free trial\" (`clicks`)\n        1. Less than 5 hours per week for learning -> <mark>Experiment change: suggested for switching to \"access course materials\"<\/mark>\n        2. 5 hours per week for learning -> stay here (`user-id`)\n           1. Course completion & Subscription (`enrollment` & `payment`)\n           2. Course completion & Cancel Subscription (`enrollment`)\n           3. Course incomplete & Subscription (`enrollment` & `payment`)\n           4. Course incomplete & Cancel Subscription (`enrollment`)\n\n---\n\n### Choosing Invariant Metrics\n\n**Q: Choose invariant metrics and explain the reasons.**\n\n**Invariant metrics:**\n- Population sizing metrics, based on your unit of diversion. Your population of control and experiment should be comparable.\n- Actual invariants, those metrics that shouldn\u2019t change when you run your experiment.\n\n**A:**\n\n|Metric Name|Metric Formula|$d_{min}$|Notation|Python Notation|Reason|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|Number of cookies|#number of unique cookies to view the course overview page|3000 cookies|$C_{cookies}$|`cookies`|Population sizing metric|\n|Number of clicks|#number of unique cookies to click the \"Start free trial\" button|240 clicks|$C_{clicks}$|`clicks`|Population sizing metric|\n|Click-through-probability|$\\displaystyle \\frac{C_{clicks}}{C_{cookies}}$|0.01|CTP|`CTP`|Population sizing metric|\n\n- Number of cookies is our population metric. Additionally, the Experiment change happening before the cookies are recorded. Therefore, Number of cookies is an invariant metric.\n- Number of clicks, which are recorded before the Experiment change occurred.\n- Click-through-probability, which are recorded before the Experiment change occurred.","f32b74fc":"Sign Test\n\nA: \n- The p-value of Gross conversion is 0.0026, which is less than 0.05. Therefore, Gross conversion is statistically significant.\n- The p-value of Net conversion is 0.6776, which is greater than 0.05. Therefore, Net conversion is not statistically significant.","8f01de26":"For `Retention`, the formula is $\\frac{C_{payments}}{C_{enrollments}}$. The unit of diversion is `enrollments`(user-ids). So the number of minimum pageviews is $\\displaystyle enrollments \\div p\\_enrollments \\cdot 2 \\Rightarrow enrollment \\div \\frac{enrollment}{cookies} \\cdot 2$","b04c98af":"---\n\n## Sizing\n\n- Calculating Number of Pageviews\n- Choosing Duartion and Exposure\n\n---\n\n### Calculating Number of Pageviews\n\n**Q: Choosing Number of Samples given Power**\n\nUsing the analytic estimates of variance, how many pageviews total (across both groups) would you need to collect to adequately power the experiment? Use an alpha of 0.05 and a beta of 0.2. Make sure you have enough power for each metric.\n\n**A:**\n\n**Will you use the Bonferroni correction in your analysis phase?**\n- No\n\nFor $d_{min} = [0.01, 0.01, 0.0075]$ of Gross conversion, Retention, and Net conversion, none of $\\alpha_{individual} = [0.0172, 0.0464, 0.0132]$ of Bonferroni corretion is qualified to $d_{min}$. Therefore, I decided not to use Bonferroni correction due to its conservativeness\n\n**Which evaluation metrics did you select?**\n- Gross conversion\n- Retention\n- Net conversion\n\n**How many pageviews will you need?**\n\nUse alpha = 0.05 and beta = 0.2. Round your answer to the nearest integer, if necessare. \n- `471212`\n\n<table id=\"T_86970_\"><thead>    <tr>        <th class=\"blank level0\"><\/th>        <th class=\"col_heading level0 col0\">Baseline Conversion Rate<\/th>        <th class=\"col_heading level0 col1\"><span class=\"MathJax_Preview\" style=\"color: inherit;\"><\/span><span class=\"MathJax\" id=\"MathJax-Element-533-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"<math xmlns=&quot;http:\/\/www.w3.org\/1998\/Math\/MathML&quot;><msub><mi>d<\/mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m<\/mi><mi>i<\/mi><mi>n<\/mi><\/mrow><\/msub><\/math>\" role=\"presentation\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-17134\" style=\"width: 2.121em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.711em; height: 0px; font-size: 122%;\"><span style=\"position: absolute; clip: rect(1.301em, 1001.71em, 2.531em, -999.997em); top: -2.182em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-17135\"><span class=\"msubsup\" id=\"MathJax-Span-17136\"><span style=\"display: inline-block; position: relative; width: 1.711em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.145em, 1000.55em, 4.238em, -999.997em); top: -4.027em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-17137\" style=\"font-family: STIXMathJax_Normal-italic;\">\ud835\udc51<\/span><span style=\"display: inline-block; width: 0px; height: 4.033em;\"><\/span><\/span><span style=\"position: absolute; top: -3.89em; left: 0.55em;\"><span class=\"texatom\" id=\"MathJax-Span-17138\"><span class=\"mrow\" id=\"MathJax-Span-17139\"><span class=\"mi\" id=\"MathJax-Span-17140\" style=\"font-size: 70.7%; font-family: STIXMathJax_Normal-italic;\">\ud835\udc5a<\/span><span class=\"mi\" id=\"MathJax-Span-17141\" style=\"font-size: 70.7%; font-family: STIXMathJax_Normal-italic;\">\ud835\udc56<\/span><span class=\"mi\" id=\"MathJax-Span-17142\" style=\"font-size: 70.7%; font-family: STIXMathJax_Normal-italic;\">\ud835\udc5b<\/span><\/span><\/span><span style=\"display: inline-block; width: 0px; height: 4.033em;\"><\/span><\/span><\/span><\/span><\/span><span style=\"display: inline-block; width: 0px; height: 2.189em;\"><\/span><\/span><\/span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.246em; border-left: 0px solid; width: 0px; height: 1.171em;\"><\/span><\/span><\/nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\"><msub><mi>d<\/mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>m<\/mi><mi>i<\/mi><mi>n<\/mi><\/mrow><\/msub><\/math><\/span><\/span><script type=\"math\/tex\" id=\"MathJax-Element-533\">d_{min}<\/script><\/th>        <th class=\"col_heading level0 col2\">Alpha<\/th>        <th class=\"col_heading level0 col3\">Beta<\/th>        <th class=\"col_heading level0 col4\">Power<\/th>        <th class=\"col_heading level0 col5\">Sample Size<\/th>        <th class=\"col_heading level0 col6\">Pageviews(cookies)<\/th>    <\/tr><\/thead><tbody>\n                <tr>\n                        <th id=\"T_86970_level0_row0\" class=\"row_heading level0 row0\">Gross conversion<\/th>\n                        <td id=\"T_86970_row0_col0\" class=\"data row0 col0\">0.206250<\/td>\n                        <td id=\"T_86970_row0_col1\" class=\"data row0 col1\">0.010000<\/td>\n                        <td id=\"T_86970_row0_col2\" class=\"data row0 col2\">0.050000<\/td>\n                        <td id=\"T_86970_row0_col3\" class=\"data row0 col3\">0.200000<\/td>\n                        <td id=\"T_86970_row0_col4\" class=\"data row0 col4\">0.800000<\/td>\n                        <td id=\"T_86970_row0_col5\" class=\"data row0 col5\">25,835<\/td>\n                        <td id=\"T_86970_row0_col6\" class=\"data row0 col6\">645,875<\/td>\n            <\/tr>\n            <tr>\n                        <th id=\"T_86970_level0_row1\" class=\"row_heading level0 row1\">Retention<\/th>\n                        <td id=\"T_86970_row1_col0\" class=\"data row1 col0\">0.530000<\/td>\n                        <td id=\"T_86970_row1_col1\" class=\"data row1 col1\">0.010000<\/td>\n                        <td id=\"T_86970_row1_col2\" class=\"data row1 col2\">0.050000<\/td>\n                        <td id=\"T_86970_row1_col3\" class=\"data row1 col3\">0.200000<\/td>\n                        <td id=\"T_86970_row1_col4\" class=\"data row1 col4\">0.800000<\/td>\n                        <td id=\"T_86970_row1_col5\" class=\"data row1 col5\">39,115<\/td>\n                        <td id=\"T_86970_row1_col6\" class=\"data row1 col6\">4,741,212<\/td>\n            <\/tr>\n            <tr>\n                        <th id=\"T_86970_level0_row2\" class=\"row_heading level0 row2\">Net conversion<\/th>\n                        <td id=\"T_86970_row2_col0\" class=\"data row2 col0\">0.109312<\/td>\n                        <td id=\"T_86970_row2_col1\" class=\"data row2 col1\">0.007500<\/td>\n                        <td id=\"T_86970_row2_col2\" class=\"data row2 col2\">0.050000<\/td>\n                        <td id=\"T_86970_row2_col3\" class=\"data row2 col3\">0.200000<\/td>\n                        <td id=\"T_86970_row2_col4\" class=\"data row2 col4\">0.800000<\/td>\n                        <td id=\"T_86970_row2_col5\" class=\"data row2 col5\">27,413<\/td>\n                        <td id=\"T_86970_row2_col6\" class=\"data row2 col6\">685,325<\/td>\n            <\/tr>\n    <\/tbody><\/table>\n\n---\n\n#### Familywise Error Rate (FWER)\n\n**Less conservative multiple comparison methods**\n\nThe [Bonferroni correction](http:\/\/en.wikipedia.org\/wiki\/Bonferroni_correction) is a very simple method, but there are many other methods, including the [closed testing procedure](http:\/\/en.wikipedia.org\/wiki\/Closed_testing_procedure), the [Boole-Bonferroni bound](http:\/\/en.wikipedia.org\/wiki\/Bonferroni_bound), and the [Holm-Bonferroni method](http:\/\/en.wikipedia.org\/wiki\/Holm%E2%80%93Bonferroni_method). [This article](http:\/\/en.wikipedia.org\/wiki\/Multiple_comparisons_problem) on multiple comparisons contains more information, and this article contains more information about the false discovery rate (FDR), and methods for controlling that instead of the familywise error rate (FWER).\n\n**Tracking multiple metrics**\n\nProblem: Probability of any false positive increases as you increase number of metrics\n\nSolution: Use higher confidence level for each metric\n\nMethod 1: Assume independence\n- $\\alpha_{overall} = 1 - (1 - \\alpha_{individual})^n$\n\nMethod 2: Bonferroni correction\n- simple\n- no assumptions\n- too conservative - guaranteed to give $\\displaystyle \\alpha_{overall}$ at least as small as specified\n- $\\displaystyle \\alpha_{individual} = \\frac{\\alpha_{overall}}{n}$\n\nfor example:\n\n$\\displaystyle \\alpha_{overall} = 0.05, n=3 \\Rightarrow \\alpha_{individual} = 0.0167$\n\n---\n\nMargin of Error\n\n> [Margin of Error](https:\/\/en.wikipedia.org\/wiki\/Margin_of_error)\n\n$\\displaystyle MOE_{\\gamma} = Z_{\\gamma} \\times SE = d_{min}$","2ec62cc2":"---\n\n## Bootstrapping\n\nThe [bootstrapping(statistics)](https:\/\/en.wikipedia.org\/wiki\/Bootstrapping_(statistics)) can figure out an estimation of confidence interval from limited sample data. In this section, I randomly draw (with replacement) the whole set of data from `notnull_control` and `notnull_experiment` 10,000 times. For each repetition, I calculated the difference in `Gross conversion` and `Net conversion` between experiment and control.\n\nThe below two histograms showing that the empirical confidence interval (gold solid line), statistical confidence interval (black dash line), $-d_{min}$ and $+d_{min}$. As we can see, the simulations are pretty close to the statistical value. Therefore, we are 95% confident that there is a statistically significant negative difference in `Gross conversion` between experiment and control; we are 95% confident that there is no statistically significant difference in `Net conversion` between experiment and control.\n\n![Gross conversion](https:\/\/raw.githubusercontent.com\/ZacksAmber\/PicGo\/master\/img\/20210606234601.svg)\n\n![Net conversion](https:\/\/raw.githubusercontent.com\/ZacksAmber\/PicGo\/master\/img\/20210606234621.svg)","5370a7f0":"For `Net conversion`, the formula is $\\frac{C_{payments}}{C_{clicks}}$. The unit of diversion is `clicks`. So the number of minimum pageviews is $\\displaystyle clicks \\div CTP \\cdot 2 \\Rightarrow clicks \\div \\frac{clicks}{cookies} \\cdot 2$"}}