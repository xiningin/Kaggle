{"cell_type":{"cef88841":"code","5f085b66":"code","b2daf390":"code","799bc99e":"code","f4e0f050":"code","76877741":"code","fe58c35a":"code","8441899d":"code","79ee81d2":"code","b4ff74fc":"code","c3cdbe9f":"code","d996a163":"code","f3b17705":"code","f1576158":"code","51a4bbb6":"code","a3f22cdd":"code","367feb09":"code","691e45bf":"code","90f68758":"code","2a8cbecf":"code","cff1fd4d":"code","ca4868ee":"markdown","6de07f80":"markdown","2f1adfe5":"markdown","4103289b":"markdown","cd6aee24":"markdown","f6382be9":"markdown","a3a6102e":"markdown","24569949":"markdown","93939ae8":"markdown","ff342b34":"markdown","cd7c911c":"markdown","e406aff9":"markdown"},"source":{"cef88841":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5f085b66":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\n\nfrom tqdm import tqdm\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, SpatialDropout1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import EarlyStopping\n\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold","b2daf390":"!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","799bc99e":"data = pd.read_json(\"..\/input\/Sarcasm_Headlines_Dataset.json\", lines = True)\ndata = data[[\"headline\", \"is_sarcastic\"]]\ndata.head(10)","f4e0f050":"analyzer = SentimentIntensityAnalyzer()\n\nfinal_list = []\nfor sent in data['headline']:\n    senti = analyzer.polarity_scores(sent)\n    list_temp=[]\n    for key, value in senti.items():\n        temp = value\n        list_temp.append(temp)\n    final_list.append(list_temp)","76877741":"temp_df = pd.DataFrame(final_list, columns=['compound','neg','neu','pos'], index=data.index)\ndata = pd.merge(data, temp_df, left_index=True,right_index=True)\ndata.head()","fe58c35a":"train_df, test_df = train_test_split(data, test_size=0.15, random_state=101)\ntrain_df, val_df = train_test_split(train_df, test_size=0.10, random_state=101)\nprint(\"Train size:{}\".format(train_df.shape))\nprint(\"Validation size:{}\".format(val_df.shape))\nprint(\"Test size:{}\".format(test_df.shape))","8441899d":"embed_size = 300 \nmax_features = 50000 \nmaxlen = 100 \n\n## fill up the missing values\ntrain_X = train_df[\"headline\"].fillna(\"_na_\").values\nval_X = val_df[\"headline\"].fillna(\"_na_\").values\ntest_X = test_df[\"headline\"].fillna(\"_na_\").values\n\n## Tokenize the sentences\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(train_X))\ntrain_X = tokenizer.texts_to_sequences(train_X)\nval_X = tokenizer.texts_to_sequences(val_X)\ntest_X = tokenizer.texts_to_sequences(test_X)\n\n## Pad the sentences \ntrain_X = pad_sequences(train_X, maxlen=maxlen)\nval_X = pad_sequences(val_X, maxlen=maxlen)\ntest_X = pad_sequences(test_X, maxlen=maxlen)\n\n## Get the target values\ntrain_y = train_df['is_sarcastic'].values\nval_y = val_df['is_sarcastic'].values","79ee81d2":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size)(inp)\nx = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\nx = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(32, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel1 = Model(inputs=inp, outputs=x)\nadam =  Adam(lr=0.0001,decay=0.00001)\nmodel1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n\nprint(model1.summary())","b4ff74fc":"model1.fit(train_X, train_y, batch_size=512, epochs=50, validation_data=(val_X, val_y), \n           callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=15, restore_best_weights=True)])","c3cdbe9f":"y_pred1 = model1.predict([val_X], batch_size=512, verbose=1)\ny_pred1 = y_pred1>0.26\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint(\"Accuracy Score: \", accuracy_score(val_y, y_pred1))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(val_y, y_pred1))\nprint(\"F1 Score: \", metrics.f1_score(val_y, y_pred1))","d996a163":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size)(inp)\nx = Conv1D(256, maxlen)(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(32, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel2 = Model(inputs=inp, outputs=x)\nadam =  Adam(lr=0.0001,decay=0.00001)\nmodel2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n\nprint(model2.summary())","f3b17705":"model2.fit(train_X, train_y, batch_size=512, epochs=50, validation_data=(val_X, val_y), \n           callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=15, restore_best_weights=True)])","f1576158":"y_pred2 = model2.predict([val_X], batch_size=512, verbose=1)\ny_pred2 = y_pred2>0.4\n\nprint(\"Accuracy Score: \", accuracy_score(val_y, y_pred2))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(val_y, y_pred2))\nprint(\"F1 Score: \", metrics.f1_score(val_y, y_pred2))","51a4bbb6":"data_X = data[\"headline\"].fillna(\"_na_\").values\ndata_X = tokenizer.texts_to_sequences(data_X)\ndata_X = pad_sequences(data_X, maxlen=maxlen)\n\ny_pred_data1 = model1.predict([data_X], batch_size=512, verbose=1)\ny_pred_data2 = model2.predict([data_X], batch_size=512, verbose=1)","a3f22cdd":"d1 = pd.DataFrame(y_pred_data1,columns=['BiRNN'], index=data.index)\nd2 = pd.DataFrame(y_pred_data2,columns=['CNN'], index=data.index)\nd = pd.merge(d1, d2, left_index=True,right_index=True)\n\ndata = pd.merge(data, d, left_index=True,right_index=True)\n\ndata.head()","367feb09":"temp_X = data[['compound','neg','neu','pos','BiRNN','CNN']]\ntemp_y = data['is_sarcastic']\n\nX_train, X_test, y_train, y_test = train_test_split(temp_X,temp_y, test_size=0.33, random_state=101)","691e45bf":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\nparams = {'boosting_type': 'gbdt',\n          'objective': 'binary',\n          'metric': {'l2', 'l1'},\n          'num_leaves': 100,\n          'learning_rate': 0.1,\n          'feature_fraction': 0.9,\n          'bagging_fraction': 0.8,\n          'bagging_freq': 5,\n          'verbose': 1\n         }\n\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=500,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=15)","90f68758":"y_pred_lgb = gbm.predict(X_test, num_iteration=gbm.best_iteration)\ny_pred_lgb = y_pred_lgb>0.4\n\nprint(\"Accuracy Score: \", accuracy_score(y_test, y_pred_lgb))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_lgb))\nprint(\"F1 Score: \", metrics.f1_score(y_test, y_pred_lgb))","2a8cbecf":"svc = SVC(gamma='auto')\n\ncv = KFold(n_splits=10, random_state=42, shuffle=True)\nscores = []\ni = 1\nfor train_index, test_index in cv.split(temp_X):\n    \n    X_train, X_test =  temp_X.values[train_index], temp_X.values[test_index]\n    y_train, y_test = temp_y[train_index], temp_y[test_index]\n    \n    svc.fit(X_train, y_train)\n    print(\"Iteration: \",i,\" - Score = \",svc.score(X_test, y_test).round(3))\n    scores.append(svc.score(X_test, y_test))\n    i+=1","cff1fd4d":"y_pred_svc = svc.predict(temp_X)\n\nprint(\"Accuracy Score: \", accuracy_score(temp_y, y_pred_svc))\nprint(\"Confusion Matrix: \\n\", confusion_matrix(temp_y, y_pred_svc))\nprint(\"F1 Score: \", metrics.f1_score(temp_y, y_pred_svc))","ca4868ee":"## Takeaways:","6de07f80":"## Preprocess data for use in Deep Learning","2f1adfe5":"## Trying kFold with Support Vector Classifier","4103289b":"## Using vader to append the sentiment intensity of the sentences","cd6aee24":"## Using LightGBM to get the final prediction","f6382be9":"## CNN Conv1D","a3a6102e":"Based on the following paper: https:\/\/arxiv.org\/pdf\/1610.08815.pdf","24569949":"## Bidirection CuDNN ","93939ae8":"## Append the results from CuDNN GRU and CNN to the original dataset","ff342b34":"* Based on the above data, I think combining the inputs from Bidirectional GRU & CNN along with sentiment splits gives a better prediction of sarcasm when classified with Support Vector Machines. \n* So it would make sense to create a specific system that takes a sentence, estimates the sentiment and calculates the metadata in pretrained GRU & CNN models and that output is sent through the pretrained SVC.\n* CNN seems to be better at spotting sarcasm in a sentence as compared to RNN(GRU).","cd7c911c":"I have used the kernel for structuring my deep learning models: https:\/\/www.kaggle.com\/yabutaka\/learning-sarcasm-with-bidirectional-gru\nThank you https:\/\/www.kaggle.com\/yabutaka!","e406aff9":"Please let me know what you guys think."}}