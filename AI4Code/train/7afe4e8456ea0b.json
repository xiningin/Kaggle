{"cell_type":{"34233986":"code","1c65a055":"code","86628770":"code","b4bb0658":"code","9776d970":"code","58255b41":"code","d427b15e":"code","2e770f49":"code","c11f560a":"code","566fc939":"code","76743d2a":"code","a3821257":"code","028cca97":"code","fd1f8a09":"code","c1a15716":"code","27b913c6":"code","e8a7eed2":"code","aebc7bd0":"code","80c8412d":"code","20e3350f":"code","d1fd74cc":"code","ebd59fa0":"code","611d73fa":"code","4dcd7aa8":"code","a435d6ad":"code","a65d5b23":"code","1240bda4":"code","4e202214":"code","20906ce6":"code","e443e565":"code","21230040":"code","5e040e42":"code","d9cb79dc":"code","7b18ac41":"code","6eadb0dc":"code","b5f9ac42":"code","5efe3c59":"code","cb8c75df":"code","09cd9678":"code","d848bceb":"code","c169d8e4":"code","72f80df6":"code","689abcfe":"code","7ff51c9a":"code","6a027571":"markdown","ce212066":"markdown","8d1ed013":"markdown","b9938699":"markdown","ab6fb4e7":"markdown","9a01ebc6":"markdown","540d3002":"markdown","18a626d2":"markdown","d2f2bc79":"markdown","fcdcca89":"markdown","4eb32c9e":"markdown","2c8a00cc":"markdown","77ec94ea":"markdown","eac1a3c4":"markdown","839e2805":"markdown","317841cc":"markdown","837fce8b":"markdown","0b0a639a":"markdown","1d9996b3":"markdown","2e80e818":"markdown","84e993dc":"markdown","ca0d831a":"markdown","38357e41":"markdown","16f6cc6b":"markdown","8f8e5913":"markdown","b441bb2c":"markdown","08b74310":"markdown","10868d0f":"markdown","b5c1bfd7":"markdown","4239c422":"markdown","989fdd1c":"markdown","5b239cd0":"markdown","4683b358":"markdown","b9d8aaed":"markdown","9e3459d6":"markdown","2723ee0f":"markdown"},"source":{"34233986":"import numpy as np\nprint('numpy version\\t:',np.__version__)\nimport pandas as pd\nprint('pandas version\\t:',pd.__version__)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy import stats\n\n# Regular expressions\nimport re\n\n# seaborn : advanced visualization\nimport seaborn as sns\nprint('seaborn version\\t:',sns.__version__)\n\nimport os # accessing directory structure\n\npd.options.mode.chained_assignment = None #set it to None to remove SettingWithCopyWarning\npd.options.display.float_format = '{:.4f}'.format #set it to convert scientific noations such as 4.225108e+11 to 422510842796.00\npd.set_option('display.max_columns', 100) # to display all the columns\n","1c65a055":"print(os.listdir('..\/input'))","86628770":"##         Read the data to Python dataframe\n\ndef formatFile(file):\n\n    nRowsRead = None # specify 'None' if want to read whole file\n    fileName = '..\/input\/'+file\n    \n    df_in = pd.read_csv(fileName, delimiter=',', nrows = nRowsRead)\n    df_in.dataframeName = fileName\n\n    #print(\"data frame number of records =\" ,df_in.shape[0] , \"\\n\", \" data frame columns = \", df_in.shape[1])\n\n\n    df_in['Day'] = df_in['Gmt time'].astype(str).str[:10]\n    df_in['Month'] = df_in['Gmt time'].astype(str).str[6:10]+df_in['Gmt time'].astype(str).str[3:5]\n    df_in['Close'] = df_in['Close'].astype(float)\n\n    selected_columns = df_in[[\"Day\",\"Close\"]]\n    new_df = selected_columns.copy()\n    df_Day = new_df.groupby(by='Day', as_index=False).mean()\n\n    selected_columns = df_in[[\"Month\",\"Close\"]]\n    new_df = selected_columns.copy()\n    df_Month = new_df.groupby(by='Month', as_index=False).mean()\n    \n    print(file, \"  data frame df_Day records =\" ,df_Day.shape[0] ,  \" data frame columns = \", df_Day.shape[1]) \n    print(file, \"  data frame df_Month records =\" ,df_Day.shape[0] ,  \" data frame columns = \", df_Day.shape[1]) \n\n    return df_Day,df_Month\n\n","b4bb0658":"def CountRecords():\n    for file in os.listdir('..\/input'):\n        fileName = '..\/input\/'+file\n        \n        df_in = pd.read_csv(fileName, delimiter=',', nrows = None)\n        df_in.dataframeName = fileName\n\n        print(file, \"\\t,\" ,df_in.shape[0] ,  \",\\t\", df_in.shape[1],\"\\n\") ","9776d970":"CountRecords()","58255b41":"    # bitcoin file data frame\n    fileName = 'BTC_USD.csv'\n   \n    df_bitcoin_day, df_bitcoin_month = formatFile(fileName)","d427b15e":"def mergeWithBitCoinFile(file):\n\n    df_day,df_mon                    = formatFile(file)\n  \n    merged_df = pd.DataFrame.merge(df_bitcoin_day, df_day, how=\"inner\", on='Day')\n    \n    return merged_df","2e770f49":"for file in os.listdir('..\/input'):\n    print(\"correlatin between BTC_USD.csv file and \",file,\"\\n\")\n    merged_df = mergeWithBitCoinFile(file)\n    correlation = merged_df.corr()\n    print(\"\\n\")\n    correlation","c11f560a":"def plotbitcoin(df,fileName):\n    x = df['Month']\n    y_1 = df['Close_x']\n    y_2 = df['Close_y']\n\n    plt.plot(x, y_1)\n    plt.plot(x, y_2)\n    \n    plt.xlabel('Months')  \n    plt.ylabel('ClosePrice')  \n  \n    pltName = 'BitCoin vs '+fileName\n    # displaying the title \n    plt.title(pltName)\n\n    plt.show()\n","566fc939":"df_bitcoin_day,df_bitcoin_month = formatFile('BTC_USD.csv')\n\nfor file in os.listdir('..\/input'):\n    merge_df = mergeWithBitCoinFile(file)\n    plotbitcoin(merge_df,file)","76743d2a":"plotbitcoin(merge_df)","a3821257":"df_gold_month.dtypes\n\ndf_gold_month.columns","028cca97":"\nmerge_df.columns\n\n# gca stands for 'get current axis'\n","fd1f8a09":"bitcon_gold.describe()","c1a15716":"def univariate(df,col,vartype,hue =None):\n    \n    '''\n    Univariate function will plot the graphs based on the parameters.\n    df      : dataframe namehttp:\/\/localhost:8888\/notebooks\/A2-LendingClub-16Sep19\/A2-16Sep-2019.ipynb#4.-Data-Analysis:-Univariate-Analysis\n    col     : Column name\n    vartype : variable type : continuos or categorical\n                Continuos(0)   : Distribution, Violin & Boxplot will be plotted.\n                Categorical(1) : Countplot will be plotted.\n    hue     : It's only applicable for categorical analysis.\n    \n    '''\n    sns.set(style=\"darkgrid\")\n    \n    if vartype == 0:\n        fig, ax=plt.subplots(nrows =1,ncols=3,figsize=(20,8))\n        ax[0].set_title(\"Distribution Plot\")\n        sns.distplot(df[col],ax=ax[0])\n        ax[1].set_title(\"Violin Plot\")\n        sns.violinplot(data =df, x=col,ax=ax[1], inner=\"quartile\")\n        ax[2].set_title(\"Box Plot\")\n        sns.boxplot(data =df, x=col,ax=ax[2],orient='v')\n    \n    if vartype == 1:\n        temp = pd.Series(data = hue)\n        fig, ax = plt.subplots()\n        width = len(df[col].unique()) + 6 + 4*len(temp.unique())\n        fig.set_size_inches(width , 7)\n        ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n        if len(temp.unique()) > 0:\n            for p in ax.patches:\n                ax.annotate('{:1.1f}%'.format((p.get_height()*100)\/float(len(loan))), (p.get_x()+0.05, p.get_height()+20))  \n        else:\n            for p in ax.patches:\n                ax.annotate(p.get_height(), (p.get_x()+0.32, p.get_height()+20)) \n        del temp\n    else:\n        exit\n        \n    plt.show()\n","27b913c6":"def bivariate_prob(df,col,stacked= True):\n    '''\n    df      : Dataframe\n    col     : Column Name\n    stacked : True(default) for Stacked Bar\n    '''\n    # get dataframe from crosstab function\n    plotCrosstab = crosstab(df,col)\n    \n    linePlot = plotCrosstab[['Probability_Charged Off']]      \n    barPlot =  plotCrosstab.iloc[:,0:2]\n    ax = linePlot.plot(figsize=(20,8), marker='o',color = 'r')\n    ax2 = barPlot.plot(kind='bar',ax = ax,rot=1,secondary_y=True,stacked=stacked)\n    ax.set_title(df[col].name.title()+' vs Probability Charge Off',fontsize=20,weight=\"bold\")\n    ax.set_xlabel(df[col].name.title(),fontsize=14)\n    ax.set_ylabel('Probability of Charged off',color = 'b',fontsize=14)\n    ax2.set_ylabel('Number of Applicants',color = 'g',fontsize=14)\n    plt.show()","e8a7eed2":"bivariate_prob(bitcon_gold,'Day',True)","aebc7bd0":"bivariate_prob(df,'Close')","80c8412d":"univariate(df,'Close',0)","20e3350f":"\n\nloan_df = pd.read_csv(\"loan.csv\", encoding=\"ISO-8859-1\")\ndict_df = pd.read_csv(\"Data_Dictionary.csv\", encoding=\"ISO-8859-1\")\nprint(\"loan data frame len =\" ,loan_df.shape[0] , \"\\n\", \"loan data frame columns = \", loan_df.shape[1])\n\n\n## Check and Correcting the datatype of columns\n\n# int_rate strip the % sign\nloan_df['int_rate'] = loan_df['int_rate'].str.rstrip('%').astype('float64')\n\n\n# months, get the number\nloan_df['term'] = loan_df['term'].str.rstrip('months').astype('int64')\n\n# Zip code : The first 3 numbers of the zip code provided by the borrower in the loan application.\nloan_df['zip_code'] = loan_df['zip_code'].str.rstrip('xx').astype('int64')\n\n# amounts change them to float\nloan_df['loan_amnt'] = loan_df['loan_amnt'].astype('float64')\nloan_df['funded_amnt'] = loan_df['loan_amnt'].astype('float64')\n","d1fd74cc":"\n####   Check the percentage of missing column values.\ncolnames = (loan_df.isnull().sum()\/len(loan_df))\n\n####    Remove all columns with very high missing percentage - 0.4 i.e 40% is taken for our analysis\ncolnames = list(colnames[colnames.values>= 0.4].index)\nloan_df.drop(labels = colnames,axis =1,inplace=True)        \nprint(\"Number of Columns dropped\\t: \",len(colnames))\n\n\n####    Check the percentage of missing row values.\nrownames = (loan_df.transpose().isnull().sum()\/len(loan_df))\n\n####     Remove all rows with very high missing percentage - 40% is taken for our analysis\nrownames = list(rownames[rownames.values > 0.4].index)\nloan_df.drop(loan_df.index[rownames],inplace=True) \nprint(\"\\nNumber of Rows dropped\\t: \",len(rownames))\n\n####  Convert amounts to numeric\nnumeric_cols = ['loan_amnt','funded_amnt','funded_amnt_inv','installment','int_rate','annual_inc','dti']\n\nloan_df[numeric_cols] = loan_df[numeric_cols].apply(pd.to_numeric)\n\n####  remove columns which are not needed\nnot_required_cols = [\"id\",\"url\"]\nloan_df.drop(labels = not_required_cols, axis =1, inplace=True)\n\nloan_df.drop(loan_df.index[loan_df['loan_status'] == 'Current'], inplace = True)\n\n","ebd59fa0":"# 3.Derived metrics\n","611d73fa":"\n#### Create bins for Interest rate\nbinsIntRate = [0, 7.5, 10, 12.5, 15,20]\nslotIntRate = ['0-7.5', '7.5-10', '10-12.5', '12.5-15', '15 and above']\nloan_df['int_rate_range'] = pd.cut(loan_df['int_rate'], binsIntRate, labels=slotIntRate)\n\n#### Create Bins for range of Loan Amount\nbinsLoanAmt = [0, 10000, 20000, 30000,40000]\nslotLoamAmt = ['0-10000', '10000-20000', '20000-30000', '30000 and above']\nloan_df['loan_amnt_range'] = pd.cut(loan_df['loan_amnt'], binsLoanAmt, labels=slotLoamAmt)\n\n\n#### Create Bins for range of Annual Income\nbinsAnnInc = [0, 25000, 50000, 75000, 100000,1000000]\nslotAnnInc = ['0-25000', '25000-50000', '50000-75000', '75000-100000', '100000 and above']\nloan_df['annual_inc_range'] = pd.cut(loan_df['annual_inc'], binsAnnInc, labels=slotAnnInc)\n\n\n##### Extract month and year from issue date\nloan_df['issue_month'],loan_df['issue_year'] = loan_df['issue_d'].str.split('-', 1).str\n\nmonths_order = [\"Jan\", \"Feb\", \"Mar\", \"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\nloan_df['issue_month'] = pd.Categorical(loan_df['issue_month'],categories=months_order, ordered=True)\n\n","4dcd7aa8":"def univariate(df,col,vartype,hue =None):\n    \n    '''\n    Univariate function will plot the graphs based on the parameters.\n    df      : dataframe namehttp:\/\/localhost:8888\/notebooks\/A2-LendingClub-16Sep19\/A2-16Sep-2019.ipynb#4.-Data-Analysis:-Univariate-Analysis\n    col     : Column name\n    vartype : variable type : continuos or categorical\n                Continuos(0)   : Distribution, Violin & Boxplot will be plotted.\n                Categorical(1) : Countplot will be plotted.\n    hue     : It's only applicable for categorical analysis.\n    \n    '''\n    sns.set(style=\"darkgrid\")\n    \n    if vartype == 0:\n        fig, ax=plt.subplots(nrows =1,ncols=3,figsize=(20,8))\n        ax[0].set_title(\"Distribution Plot\")\n        sns.distplot(df[col],ax=ax[0])\n        ax[1].set_title(\"Violin Plot\")\n        sns.violinplot(data =df, x=col,ax=ax[1], inner=\"quartile\")\n        ax[2].set_title(\"Box Plot\")\n        sns.boxplot(data =df, x=col,ax=ax[2],orient='v')\n    \n    if vartype == 1:\n        temp = pd.Series(data = hue)\n        fig, ax = plt.subplots()\n        width = len(df[col].unique()) + 6 + 4*len(temp.unique())\n        fig.set_size_inches(width , 7)\n        ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n        if len(temp.unique()) > 0:\n            for p in ax.patches:\n                ax.annotate('{:1.1f}%'.format((p.get_height()*100)\/float(len(loan))), (p.get_x()+0.05, p.get_height()+20))  \n        else:\n            for p in ax.patches:\n                ax.annotate(p.get_height(), (p.get_x()+0.32, p.get_height()+20)) \n        del temp\n    else:\n        exit\n        \n    plt.show()\n\n  \n\n","a435d6ad":"  \nunivariate(df=loan_df,col='loan_amnt',vartype=0)  \n","a65d5b23":"univariate(df=loan_df,col='int_rate',vartype=0)","1240bda4":"loan_df[\"annual_inc\"].describe()\n\n","4e202214":"quan = loan_df[\"annual_inc\"].quantile(0.99)\nloan_df_t = loan_df_t[loan_df_t[\"annual_inc\"] < quan]\nloan_df_t[\"annual_inc\"].describe()","20906ce6":"univariate(df=loan_df,col='loan_status',vartype=1)","e443e565":"univariate(df=loan_df,col='purpose',vartype=1)","21230040":"univariate(df=loan_df,col='term',vartype=1)","5e040e42":"<font color='blue'><b>Analysis<\/b>: 73% of applicants applied loan for 36 months term period.<\/font> ","d9cb79dc":"plt.figure(figsize=(16,12))\nsns.boxplot(data =loan_df, x='purpose', y='loan_amnt', hue ='loan_status')\nplt.title('Purpose of Loan vs Loan Amount')\nplt.show()","7b18ac41":"loan_correlation = loan_df.corr()\nloan_correlation","6eadb0dc":"f, ax = plt.subplots(figsize=(14, 9))\nsns.heatmap(loan_correlation, \n            xticklabels=loan_correlation.columns.values,\n            yticklabels=loan_correlation.columns.values,annot= True)\nplt.show()","b5f9ac42":"def crosstab(df,col):\n    '''\n    df : Dataframe\n    col: Column Name\n    '''\n    crosstab = pd.crosstab(df[col], df['loan_status'],margins=True)\n    crosstab['Probability_Charged Off'] = round((crosstab['Charged Off']\/crosstab['All']),3)\n    crosstab = crosstab[0:-1]\n    return crosstab","5efe3c59":"# Probability of charge off\ndef bivariate_prob(df,col,stacked= True):\n    '''\n    df      : Dataframe\n    col     : Column Name\n    stacked : True(default) for Stacked Bar\n    '''\n    # get dataframe from crosstab function\n    plotCrosstab = crosstab(df,col)\n    \n    linePlot = plotCrosstab[['Probability_Charged Off']]      \n    barPlot =  plotCrosstab.iloc[:,0:2]\n    ax = linePlot.plot(figsize=(20,8), marker='o',color = 'r')\n    ax2 = barPlot.plot(kind='bar',ax = ax,rot=1,secondary_y=True,stacked=stacked)\n    ax.set_title(df[col].name.title()+' vs Probability Charge Off',fontsize=20,weight=\"bold\")\n    ax.set_xlabel(df[col].name.title(),fontsize=14)\n    ax.set_ylabel('Probability of Charged off',color = 'b',fontsize=14)\n    ax2.set_ylabel('Number of Applicants',color = 'g',fontsize=14)\n    plt.show()","cb8c75df":"filter_states = loan_df.addr_state.value_counts()\nfilter_states = filter_states[(filter_states < 10)]\n\nloan_df_filter_states = loan_df.drop(labels = loan_df[loan_df.addr_state.isin(filter_states.index)].index)","09cd9678":"states = crosstab(loan_df_filter_states,'addr_state')\ndisplay(states.tail(20))\n\nbivariate_prob(df =loan_df_filter_states,col ='addr_state')","d848bceb":"purpose = crosstab(loan_df,'purpose')\ndisplay(purpose)\n\nbivariate_prob(df =loan_df,col ='purpose',stacked=False)","c169d8e4":"grade = crosstab(loan_df,'grade')\ndisplay(grade)\n\nbivariate_prob(df =loan_df,col ='grade',stacked=False)\nbivariate_prob(df =loan_df,col ='sub_grade')","72f80df6":"annual_inc_range = crosstab(loan_df,'annual_inc_range')\ndisplay(annual_inc_range)\n\nbivariate_prob(df =loan_df,col ='annual_inc_range')","689abcfe":"int_rate_range = crosstab(loan_df,'int_rate_range')\ndisplay(int_rate_range)\n\nbivariate_prob(df =loan_df,col ='int_rate_range')","7ff51c9a":"emp_length = crosstab(loan_df,'emp_length')\ndisplay(emp_length)\n\nbivariate_prob(df =loan_df,col ='emp_length')","6a027571":"<font color='green'><b>Analysis<\/b> most of the loans are taken by people with income between 30k and 50k\n <\/font>","ce212066":"####  Purpose of loan","8d1ed013":"<font color='blue'><b>Analysis<\/b>: Applicants who has taken the Loan for 'small business' has the highest probabilty of charge off of 27%. Banks should take collateral to loans for purpose of 'small business'<\/font> ","b9938699":"### Target Variable\n* <font color='blue'><b>Loan Status<\/b><\/font>\n\n### Top  Major variables to consider before giving loan: \n1. <font color='blue'><b>Purpose of Loan<\/b> Caution : Small business<\/font>\n2. <font color='blue'><b>Employment Length<\/b> Caution : 10+ years applicants<\/font>\n3. <font color='blue'><b>Grade<\/b> Caution: Grade above G <\/font>\n4. <font color='blue'><b>Interest Rate<\/b> Caution: 15 and above Interest rate<\/font>\n5. <font color='blue'><b>Term<\/b> Caution : Above 36 months <\/font>","ab6fb4e7":"#### a.Loan amount","9a01ebc6":"#### b.Interest rate","540d3002":"#### 4. Annual Income Range vs Probability Charge Off","18a626d2":"<font color='blue'><b>Analysis<\/b>: with this data Applicants with 10+ years are defaulting more.. <\/font> ","d2f2bc79":"#### 2. Purpose of Loan vs Probability Charge Off","fcdcca89":"#  2. Data Cleaning","4eb32c9e":"<font color='blue'><b>Analysis<\/b>: 14% of the applicants Charged off.<\/font> ","2c8a00cc":"##  Bivariate Analysis\nchoose two or more feature to understand the default variable.","77ec94ea":"<font color='green'><b>Analysis <\/b>:Most of the loans are distributed between 9% and 14%.<\/font> ","eac1a3c4":"#### 1. Location vs Probability Charge Off","839e2805":"###  Categorical variables\n\n","317841cc":"# Conclusion","837fce8b":"#   1. Data Understanding","0b0a639a":"#### c.Annual Income","1d9996b3":"#### 3. Grade\/Subgrade vs Probability Charge Off","2e80e818":"# Charge off percentage Analysis","84e993dc":"<font color='blue'><b>Analysis<\/b>: As we move from Grade A to G, probability that person will charged off is increasing.<\/font>  ","ca0d831a":"####  Loan Term","38357e41":"#### Loan Status","16f6cc6b":"<font color='green'><b>Analysis<\/b> mean = 68968.9264 and std = 63793.7658 , max = 6000000 \n    we need to remove the outliners and taking 90% quantile\n <\/font>","8f8e5913":"#### HeatMap: All continuos variables","b441bb2c":"#### 6. Employment Length vs Probability Charge Off","08b74310":"<font color='blue'><b>Analysis<\/b>: Approx 46% of the applicants applied loan for paying their other loans(Debt Consolidation).<\/font> ","10868d0f":"#### 5. Interest rate Range vs Probability Charge Off","b5c1bfd7":"### Continuous Variables","4239c422":"<font color='blue'><b>Insights<\/b>: As the interest rate is increasing the probability that person will default is increasing with highest of 25% at 15% & above interest bracket.<\/font>  ","989fdd1c":"<font color='green'><b>Loan Amount Analysis <\/b>:Most of the loans are distributed between 5000 to 15000 USD.<\/font> ","5b239cd0":"#### 2. Correlation Matrix : ","4683b358":"#  4. Data Analysis: Univariate Analysis","b9d8aaed":"<font color='blue'><b>Analysis<\/b>: Multiple States have high probability of charge,highest being 'NV' at 22%<\/font>","9e3459d6":"# Libraries import and setting the required options","2723ee0f":"<font color='blue'><b>Analysis<\/b>: As the annual income is decreasing the probability that person will default is increasing with highest of 12% at (0 to 25000) salary bracket.<\/font>  "}}