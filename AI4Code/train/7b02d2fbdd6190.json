{"cell_type":{"fe9fb94f":"code","8cae8f2f":"code","ad5ab982":"code","036c7116":"code","da472d6d":"code","f060945f":"code","c839b128":"code","238be51b":"code","eb9e1554":"code","d0b60d2d":"code","0c151ab2":"code","d107c6b9":"code","0eb76dfd":"code","6526e99e":"code","a44302ee":"code","5779e24d":"code","b90a4824":"code","630f44e5":"code","8c006549":"code","1c1d31b2":"code","88a226e6":"code","d579728d":"code","0ecd9423":"code","f7e51c82":"code","c9c5f12c":"code","2f021582":"code","c65d429c":"code","b760dfad":"code","f328ef8d":"code","657ee4e9":"code","bfe1afd2":"code","422da0db":"code","b0d3a6c3":"code","a0b60a8f":"code","0b914c5f":"code","6ab8b906":"code","a6817a29":"code","1303a4bd":"code","88a1d10d":"code","c4b38883":"code","1556928f":"code","aafec6bd":"markdown","12a43328":"markdown","e24d821d":"markdown","df5f115a":"markdown","a08aff51":"markdown","9963a720":"markdown","240cab30":"markdown","365563a7":"markdown","c690f333":"markdown","25ab38f9":"markdown","a92518c1":"markdown","4d503f83":"markdown","8bf0f274":"markdown","06ee8355":"markdown","abffc857":"markdown","b7908da6":"markdown","ed62d9b0":"markdown","1cc2cd03":"markdown","0bb7b662":"markdown","a3c02c2e":"markdown","97c612b5":"markdown","e743e7e2":"markdown","9b3b8feb":"markdown","34e20344":"markdown","0e28bf5d":"markdown","bb576ebf":"markdown"},"source":{"fe9fb94f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cae8f2f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom numpy import mean\nfrom numpy import std\nimport string\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom category_encoders import MEstimateEncoder\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nwarnings.filterwarnings('ignore')\n\n# Function for comparing different approaches\ndef score_dataset(X, y, model=RandomForestClassifier(n_estimators=100, random_state=2, max_depth=5)):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n    # Metric is Accuracy\n    score = cross_val_score(\n        model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n    print('Accuracy: %.3f (%.3f)' % (mean(score), std(score)))\n\ndef make_mi_scores(X, y):\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","ad5ab982":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.tail()","036c7116":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","da472d6d":"survived_data = train_data[train_data['Survived'] == 1]\nsurvived = survived_data.count().values[1]\nsurvival_percent = (survived\/891) * 100\nprint('The percentage of survived people in training data are {}'.format(survival_percent))","f060945f":"# Remove rows with missing target, separate target from predictors\nX = train_data.copy()\nX_test = test_data.copy()\n\nX.dropna(axis=0, subset=['Survived'], inplace=True)","c839b128":"X.dtypes","238be51b":"# Number of missing values in each column of training data\nmissing_val_count_by_column = (X.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","eb9e1554":"# 1. Filling missing cabin values with 'Unknown'\nX[\"Cabin\"] = X[\"Cabin\"].fillna(\"Unknown\")\nX_test[\"Cabin\"] = X_test[\"Cabin\"].fillna(\"Unknown\")","d0b60d2d":"# 2. Embarked: Replace NaN with most frequent values\nmost_frequent_category=X['Embarked'].mode()[0]  # 'S' is the most frequent value\nX[\"Embarked\"].fillna(most_frequent_category,inplace=True)\nX_test[\"Embarked\"].fillna(most_frequent_category,inplace=True)","0c151ab2":"# 3. Age: Create feature to show rows with missing values of Age:\nX['Age_NA'] = np.where(train_data.Age.isnull(), 1, 0)\nX_test['Age_NA'] = np.where(test_data.Age.isnull(), 1, 0)\n\n# Visualize Age_NA vs survival rate\nprint(X[\"Age_NA\"].value_counts())\ndf = pd.DataFrame({'Age_NA': X['Age_NA'],'Survived': X['Survived']})\ndf.head()\nsns.factorplot('Age_NA','Survived', data = df)","d107c6b9":"# Use median grouped by Sex and Pclass\n    \nby_sex_class = X.groupby(['Sex', 'Pclass'])\n\ndef impute_median(series):\n    return series.fillna(series.median())\n\nX[\"Age\"] = by_sex_class['Age'].transform(impute_median)\nX_test[\"Age\"] = by_sex_class['Age'].transform(impute_median)\n\nX.tail()","0eb76dfd":"# Number of missing values in each column of test data\nmissing_val_count_by_column = (X_test.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","6526e99e":"# Replace NaN Fare with mean\nX_test = X_test.fillna(X_test['Fare'].mean())","a44302ee":"# Check how many unique values each feature has:\nfor column in X.columns:\n    print(column, len(X[column].unique()))","5779e24d":"X_temp = X.copy()\ny = X_temp.pop('Survived')\nmi_scores = make_mi_scores(X_temp, y)\n\nprint(mi_scores.head(20))\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores.head(20))","b90a4824":"labelencoder = LabelEncoder()","630f44e5":"# Drop passenger id since nothing can be gathered form unique id's\nX = X.drop([\"PassengerId\"], axis=1)\nX_test = X_test.drop([\"PassengerId\"], axis=1)","8c006549":"# Function to separate title from name\ndef separate_name(title):\n    return title.str.extract(' ([A-Za-z]+)\\.', expand = False)","1c1d31b2":"# Add column Title\nX[\"Title\"] = separate_name(train_data[\"Name\"])\nX_test[\"Title\"] = separate_name(test_data[\"Name\"])\n\n# Drop Name column\nX = X.drop([\"Name\"], axis=1)\nX_test = X_test.drop([\"Name\"], axis=1)\nX.head()","88a226e6":"labelencoder.fit(pd.concat([X['Title'], X_test['Title']], axis=0, sort=False))\nX['Title'] = labelencoder.transform(X['Title'])\nX_test['Title'] = labelencoder.transform(X_test['Title'])\nX.head()","d579728d":"train_data['Age Group'] = pd.cut(train_data['Age'], 5)\ntrain_data[['Age Group', 'Survived']].groupby(['Age Group'], as_index=False).mean().sort_values(by='Age Group', ascending=True)","0ecd9423":"sns.violinplot(x=\"Age Group\", y=\"Survived\", data=train_data)","f7e51c82":"def group_age(dataset):\n    data = dataset.copy()\n    data.loc[ data['Age'] <= 16, 'Age'] = 0\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n    data.loc[ data['Age'] > 64, 'Age'] = 4\n    return data","c9c5f12c":"X[\"Age Group\"] = group_age(X)[\"Age\"]\nX_test[\"Age Group\"] = group_age(X_test)[\"Age\"]\n\n# drop age column\nX = X.drop([\"Age\"], axis=1)\nX_test = X_test.drop([\"Age\"], axis=1)\nX.head()","2f021582":"gender_map = {'female' : 1, 'male' : 0}\nX = X.replace({\"Sex\": gender_map})\nX_test = X_test.replace({\"Sex\": gender_map})\nX.head()","c65d429c":"labelencoder.fit(pd.concat([X['Cabin'], X_test['Cabin']], axis=0, sort=False))\nX['Cabin'] = labelencoder.transform(X['Cabin'])\nX_test['Cabin'] = labelencoder.transform(X_test['Cabin'])\nX.head()","b760dfad":"X['Ticket'].head()","f328ef8d":"# Function that takes ticket and returns list of ticket types\ndef separate_ticket(data_ticket):\n    ticket_type = []\n    for i in range(len(data_ticket)):\n            ticket =data_ticket.iloc[i]\n\n            for c in string.punctuation:\n                ticket = ticket.replace(c,\"\")\n                split_ticket = ticket.split(\" \")   \n            if len(split_ticket) == 1:\n                ticket_type.append('NO')\n            else: \n                ticket_type.append(split_ticket[0])\n    return ticket_type ","657ee4e9":"# Create new column for ticket type\nX[\"Ticket type\"] = separate_ticket(train_data.Ticket)\nX_test[\"Ticket type\"]= separate_ticket(test_data.Ticket)\nX.head()","bfe1afd2":"# Check how many samples are there for each ticket type\nprint(X[\"Ticket type\"].value_counts())","422da0db":"#for those types that have less than 10 samples in training set, assign type to 'OTHER':\nfor t in X['Ticket type'].unique():\n    if len(X[X['Ticket type']== t]) < 10:\n        X.loc[X['Ticket type'] == t, 'Ticket type'] = 'OTHER'\n       \n    \nfor t in X['Ticket type'].unique():\n    if t not in X['Ticket type'].unique():\n        X_test.loc[X_test['Ticket type'] == t, 'Ticket type'] = 'OTHER'\n        \nprint(X['Ticket type'].unique())\nprint(X_test['Ticket type'].unique())","b0d3a6c3":"sns.barplot(x = 'Ticket type', y = 'Survived', data = X)","a0b60a8f":"# Drop ticket column\nX = X.drop(['Ticket'], axis=1)\nX_test = X_test.drop(['Ticket'], axis=1)","0b914c5f":"labelencoder.fit(pd.concat([X['Ticket type'], X_test['Ticket type']], axis=0, sort=False))\nX['Ticket type'] = labelencoder.transform(X['Ticket type'])\nX_test['Ticket type'] = labelencoder.transform(X_test['Ticket type'])\nX.head()","6ab8b906":"labelencoder.fit(pd.concat([X['Embarked'], X_test['Embarked']], axis=0, sort=False))\nX['Embarked'] = labelencoder.transform(X['Embarked'])\nX_test['Embarked'] = labelencoder.transform(X_test['Embarked'])\nX.head()","a6817a29":"X['Family Size'] = X['SibSp'] + X['Parch']\nX_test['Family Size'] = X_test['SibSp'] + X_test['Parch']\nX[['Family Size', 'Survived']].groupby(['Family Size']).mean().sort_values(['Survived'], ascending = False)","1303a4bd":"# Drop sibling and parent count columns\nX.drop(['SibSp', 'Parch'], inplace = True, axis = 1)\nX_test.drop(['SibSp', 'Parch'], inplace = True, axis = 1)","88a1d10d":"print(\"Accuracy after performing feature engineering\")\nX_temp = X.copy()\ny = X_temp.pop('Survived')\nscore_dataset(X_temp, y)","c4b38883":"X.head()","1556928f":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=2)\n   \nmodel.fit(X_temp, y)\npredictions = model.predict(X_test)\nX_test.head()\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","aafec6bd":"**Age column**","12a43328":"Creating age groups based on above groups","e24d821d":"Label encode ticket type","df5f115a":"**Embarked**","a08aff51":"Since there are too many ticket types, combine less frequent ticket types into one category","9963a720":"**Gender**","240cab30":"Label encode Sex column","365563a7":"Label encode Title column","c690f333":"**SibSp and Parch**","25ab38f9":"**Embarked column**","a92518c1":"**Ticket**","4d503f83":"# Feature Engineering","8bf0f274":"Younger passengers had more chances at survival than older ones","06ee8355":"Passengers with missing age information have low survival rate. Therefore Age_NA column can also be kept.","abffc857":"**Name**\n: Name in itself is not very useful. But the title included in the name can be useful","b7908da6":"Label encode Cabin column","ed62d9b0":"Ticket column may indicate the class of the passenger, which can relate to survival rate as suggested by mi scores.","1cc2cd03":"**Cabin column**","0bb7b662":"Sibling and parent count columns may be combined to form family size","a3c02c2e":"**Cabin**","97c612b5":"View mi scores: Use mutual_info_classif since target 'Survived' is categorical","e743e7e2":"**Treating missing values in test set**","9b3b8feb":"# Handling columns with missing data \nAge, Cabin, Embarked have missing values","34e20344":"Passengers of ticket class 'PC' had high chance of survival","0e28bf5d":"**Passenger id**","bb576ebf":"**Age**: may be useful if binned into discrete intervals"}}