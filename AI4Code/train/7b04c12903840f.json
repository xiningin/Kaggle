{"cell_type":{"c057f510":"code","ccf91474":"code","1995109a":"code","1a8d0df7":"code","3cb0bac7":"code","73d48ce1":"code","0e7e69ce":"code","6f669483":"code","78ecb80a":"code","d2133853":"code","7637ea7a":"code","379cba75":"code","c11032d3":"code","fb44e0c2":"code","4fe1859b":"code","cfbdb5ba":"code","7bc18a0c":"code","644d91e7":"code","0fda026c":"code","2d767fc0":"code","2baa6c47":"code","a6c0443f":"code","6f535b83":"code","23907a53":"code","0530ff7d":"code","06d8b4dd":"code","570d562e":"code","96b0b556":"code","ab3dbdb8":"code","46d4ea90":"code","2de5740d":"code","7ce41824":"code","1c3daa85":"markdown","363a4592":"markdown","96381c94":"markdown","955f017f":"markdown","73acf77a":"markdown","eedb1226":"markdown","0a8c268a":"markdown","c293048e":"markdown","57cd1507":"markdown","d088e9bb":"markdown","5d24496b":"markdown","01f691b2":"markdown","91d15df3":"markdown","579f97f4":"markdown","6553593c":"markdown","2488e432":"markdown","11651f75":"markdown","c8832d8d":"markdown","a3bd6d76":"markdown","7fe9e8db":"markdown","ce4a02c5":"markdown","273e4968":"markdown","6c699d6f":"markdown","304d89b6":"markdown","3ecab9f9":"markdown","93ee3789":"markdown","5810fee1":"markdown","b5512a1b":"markdown"},"source":{"c057f510":"from IPython.core.display import display, HTML, Javascript\nhtml_contents =\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <link rel=\"stylesheet\" href=\"https:\/\/www.w3schools.com\/w3css\/4\/w3.css\">\n        <link rel=\"stylesheet\" href=\"https:\/\/fonts.googleapis.com\/css?family=Kadwa\">\n        <link rel=\"stylesheet\" href=\"https:\/\/fonts.googleapis.com\/css?family=Open Sans\">\n        <style>\n        .title-section {\n            font-family: \"Kadwa\", Arial, sans-serif;\n            color: \"#6A8CAF\";\n            letter-spacing: 2px;\n            }\n        body {\n            font-family: \"Open Sans\", Arial, sans-serif;\n            }\n        <\/style>\n    <\/head>\n<\/html>\n\"\"\"\nHTML(html_contents)","ccf91474":"# from matplotlib.finance import candlestick2_ohlc\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport matplotlib.pyplot as plt\nimport math\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')","1995109a":"# Install finplot library\n# !pip -q install mplfinance\n# import mplfinance as mpf","1a8d0df7":"# load dataset\ntrain = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/train.csv\")\nasset_details = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/asset_details.csv\")\ndf_test = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/example_test.csv\")\nmapping = dict(asset_details[['Asset_ID', 'Asset_Name']].values)\ntrain[\"Asset name\"] = train[\"Asset_ID\"].map(mapping)","3cb0bac7":"df_train = train\ndf_asset_details = asset_details","73d48ce1":"asset_details.sort_values(by=['Weight'], inplace=True, ascending=False)","0e7e69ce":"temp = train.reset_index(drop = True) \ntemp['TIME'] = pd.to_datetime(temp['timestamp'], unit='s')","6f669483":"##########TRANSACTIONS##########\ntemp['Year'] = temp['TIME'].dt.year\ntemp.columns =[column.replace(\" \", \"_\") for column in temp.columns]\ntemp.dropna()[['Open', 'High', 'Low', 'Close', 'Volume','VWAP']]\nvolume_yr = temp.groupby(['Year','Asset_name'])['Volume'].max().reset_index()\nvolume_yr = volume_yr.query(\"Year == 2021\")","78ecb80a":"plt.rcParams['figure.dpi'] = 300\nfig = plt.figure(figsize=(3, 5), facecolor='#F7F7F7')\ngs = fig.add_gridspec(2, 1)\ngs.update(wspace=1.5, hspace=1.1)\n\nbackground_color = \"#F7F7F7\"\ncolor_map = [\"#E8F0F2\" for _ in range(20)]\ncolor_map[4] = \"#C9CCD5\" #F2A154 79B4B7\ncolor_map[1] = \"#F2A154\"\ncolor_map[6] = \"#F2A154\"\nsns.set_palette(sns.color_palette(color_map))\n\nax0 = fig.add_subplot(gs[0, 0])\nax0.set_facecolor(background_color)\n\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\n\nfor s in ['bottom','left']:\n  ax0.spines[s].set_linewidth(0.5)\n  ax0.spines[s].set_color('grey')\n    \n#graph\nax0 = sns.barplot(ax=ax0, y=volume_yr['Volume']\/1000, x=volume_yr['Asset_name'], \n                      zorder=2, linewidth=0.3, edgecolor=\"#7F7C82\", \n                      orient='v', saturation=0.9, alpha=0.7)\nax0.grid(which='major', axis='y', zorder=0, color='#CDD0CB', linewidth=0.2, alpha=0.5)\nax0.set_yscale('symlog')\n\n#format axis\nax0.set_ylabel(\"Volume\",fontsize=3, weight='semibold')\nax0.set_xlabel(\"Crypto Currency\",fontsize=3, weight='semibold')\nax0.tick_params(labelsize=3, width=0.2, length=1)\nplt.setp( ax0.xaxis.get_majorticklabels(), rotation=45, ha=\"right\" )\n\n#title\nx0, x1 = ax0.get_xlim()\ny0, y1 = ax0.get_ylim()\nax0.text(x0, y1+2000000, 'Volume by Year', fontsize=4, ha='left', va='top', weight='semibold')\n\ny_format = ticker.FuncFormatter(lambda x, p: format(int(x), ','))\nax0.yaxis.set_major_formatter(y_format)\n\nplt.show()","d2133853":"#Extract Bitcoin data\ntemp = train.query(\"Asset_ID == 1\").reset_index(drop = True) # bitcoin\ntemp['TIME'] = pd.to_datetime(temp['timestamp'], unit='s')\n\nall_data = temp.groupby(['Asset_ID', 'Asset name']).resample('D', on='TIME', origin='start').agg(\n    {\"Open\": \"first\", \n     \"Close\": \"last\", \n     \"Low\": \"min\", \n     \"High\": \"max\",\n     \"Volume\": \"last\",\n     \"VWAP\": \"max\"\n    }\n).dropna()[['Open', 'High', 'Low', 'Close', 'Volume','VWAP']]\n\nall_data=all_data.reset_index()\nall_data=all_data.set_index('TIME')","7637ea7a":"start = dt.datetime.strptime('2018-01-01', '%Y-%m-%d')\nend = dt.datetime.strptime('2021-09-20', '%Y-%m-%d')\nselected_data = all_data.loc[start:end,['Open','High','Low','Close', 'VWAP', 'Volume']]","379cba75":"# mpf.plot(selected_data, # the dataframe containing the OHLC (Open, High, Low and Close) data\n#          type='candle', # use candlesticks \n#          volume=True, # also show the volume\n#          mav=(5, 15), # use two different moving averages\n#          figratio=(3,1), # set the ratio of the figure\n#          style='yahoo',  # choose the yahoo style\n#          title='Bitcoin Daily'\n#          )","c11032d3":"#RSI\nall_data['Diff'] = all_data.groupby('Asset_ID')['Close'].transform(lambda x: x.diff())\nall_data['Up'] = all_data['Diff']\nall_data.loc[(all_data['Up']<0), 'Up'] = 0\n\nall_data['Down'] = all_data['Diff']\nall_data.loc[(all_data['Down']>0), 'Down'] = 0 \nall_data['Down'] = abs(all_data['Down'])\n\nall_data['avg_5up'] = all_data.groupby('Asset_ID')['Up'].transform(lambda x: x.rolling(window=5).mean())\nall_data['avg_5down'] = all_data.groupby('Asset_ID')['Down'].transform(lambda x: x.rolling(window=5).mean())\n\nall_data['avg_15up'] = all_data.groupby('Asset_ID')['Up'].transform(lambda x: x.rolling(window=15).mean())\nall_data['avg_15down'] = all_data.groupby('Asset_ID')['Down'].transform(lambda x: x.rolling(window=15).mean())\n\nall_data['RS_5'] = all_data['avg_5up'] \/ all_data['avg_5down']\nall_data['RS_15'] = all_data['avg_15up'] \/ all_data['avg_15down']\n\nall_data['RSI_5'] = 100 - (100\/(1+all_data['RS_5']))\nall_data['RSI_15'] = 100 - (100\/(1+all_data['RS_15']))\n\nall_data['RSI_ratio'] = all_data['RSI_5']\/all_data['RSI_15']","fb44e0c2":"start = dt.datetime.strptime('2021-01-01', '%Y-%m-%d')\nend = dt.datetime.strptime('2021-09-20', '%Y-%m-%d')\nselected_data = all_data.loc[start:end,['Open','High','Low','Close','RSI_15', 'VWAP', 'Volume']]\n# apd = mpf.make_addplot(selected_data['RSI_15'],panel=2,color='lime',ylim=(10,90),secondary_y=True)\n# mpf.plot(selected_data, # the dataframe containing the OHLC (Open, High, Low and Close) data\n#          type='candle', # use candlesticks \n#          volume=True, # also show the volume\n#          mav=(5,15), # use two different moving averages\n#          figratio=(3,1), # set the ratio of the figure\n#          addplot=apd, # RSI\n#          style='yahoo',  # choose the yahoo style\n#          title='Bitcoin Daily (RSI)' # title\n#          )","4fe1859b":"#Extract Ethereum data\ntemp1 = train.query(\"Asset_ID == 6\").reset_index(drop = True) # Etherium\ntemp1['TIME'] = pd.to_datetime(temp1['timestamp'], unit='s')\n\nall_data1 = temp1.groupby(['Asset_ID', 'Asset name']).resample('D', on='TIME', origin='start').agg(\n    {\"Open\": \"first\", \n     \"Close\": \"last\", \n     \"Low\": \"min\", \n     \"High\": \"max\",\n     \"Volume\": \"last\",\n     \"VWAP\": \"max\"\n    }\n).dropna()[['Open', 'High', 'Low', 'Close', 'Volume','VWAP']]\n\nall_data1=all_data1.reset_index()\nall_data1=all_data1.set_index('TIME')","cfbdb5ba":"#RSI\nall_data1['Diff'] = all_data1.groupby('Asset_ID')['Close'].transform(lambda x: x.diff())\nall_data1['Up'] = all_data1['Diff']\nall_data1.loc[(all_data1['Up']<0), 'Up'] = 0\n\nall_data1['Down'] = all_data1['Diff']\nall_data1.loc[(all_data1['Down']>0), 'Down'] = 0 \nall_data1['Down'] = abs(all_data1['Down'])\n\nall_data1['avg_5up'] = all_data1.groupby('Asset_ID')['Up'].transform(lambda x: x.rolling(window=5).mean())\nall_data1['avg_5down'] = all_data1.groupby('Asset_ID')['Down'].transform(lambda x: x.rolling(window=5).mean())\n\nall_data1['avg_15up'] = all_data1.groupby('Asset_ID')['Up'].transform(lambda x: x.rolling(window=15).mean())\nall_data1['avg_15down'] = all_data1.groupby('Asset_ID')['Down'].transform(lambda x: x.rolling(window=15).mean())\n\nall_data1['RS_5'] = all_data1['avg_5up'] \/ all_data1['avg_5down']\nall_data1['RS_15'] = all_data1['avg_15up'] \/ all_data1['avg_15down']\n\nall_data1['RSI_5'] = 100 - (100\/(1+all_data1['RS_5']))\nall_data1['RSI_15'] = 100 - (100\/(1+all_data1['RS_15']))\n\nall_data1['RSI_ratio'] = all_data1['RSI_5']\/all_data1['RSI_15']","7bc18a0c":"start = dt.datetime.strptime('2021-01-01', '%Y-%m-%d')\nend = dt.datetime.strptime('2021-09-20', '%Y-%m-%d')\nselected_data1 = all_data1.loc[start:end,['Open','High','Low','Close','RSI_15', 'VWAP', 'Volume']]\n# apd = mpf.make_addplot(selected_data1['RSI_15'],panel=2,color='lime',ylim=(10,90),secondary_y=True)\n# mpf.plot(selected_data1, # the dataframe containing the OHLC (Open, High, Low and Close) data\n#          type='candle', # use candlesticks \n#          volume=True, # also show the volume\n#          mav=(5,15), # use two different moving averages\n#          figratio=(3,1), # set the ratio of the figure\n#          addplot=apd, # RSI\n#          style='yahoo',  # choose the yahoo style\n#          title='Ethereum Daily' # title\n#          )","644d91e7":"from sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport matplotlib.pyplot as plt\nimport math\nplt.style.use('fivethirtyeight')","0fda026c":"data = selected_data.filter(['Close'])\ndataset = data.values\ntraining_data_len = math.ceil(len(dataset) * .8)\n\n# Scale the Data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\n# Create the training data set\n# Create the scaled training data set\ntrain_data = scaled_data[0:training_data_len, :]\n\n# Split the data itno x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i,0])\n    y_train.append(train_data[i,0])","2d767fc0":"# Convert the x_train and y_train to numpy arrays\nx_train, y_train = np.array(x_train), np.array(y_train)\n# Reshape the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n# x_train.shape\n\n# Build the LSTM Model\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\nmodel.add(LSTM(50, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))","2baa6c47":"# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)\n\n# Create the testing data set\n# Create new array containing scaled values from index 1028 to 1359\ntest_data = scaled_data[training_data_len - 60: , :]\n\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len: , :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# convert data to numpy array\nx_test = np.array(x_test)\n\n# reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n\n# Get the models predicted price values\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean square error (RMSE)\nrmse = np.sqrt( np.mean( predictions - y_test )**2 )","a6c0443f":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n\n# Visualize the data\nplt.figure(figsize=(12,6))\nplt.title('LSTM Model Bitcoin', fontsize=12)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Close Price USD ($)', fontsize=12)\nplt.tick_params(labelsize=9, width=0.2, length=1)\n\nplt.plot(train['Close'], linewidth=2.0)\nplt.plot(valid[['Close', 'Predictions']], linewidth=2.0)\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right', fontsize=9)\nplt.show()","6f535b83":"# import pandas_datareader as web\n# # Get the quote\n# btc_quote = web.DataReader('BTC-USD', data_source='yahoo', start='2018-01-01', end='2021-09-20')\n# # Create a new dataframe\n# new_df = btc_quote.filter(['Close'])\n# # Get the last 60 days closing price\n# last_60_days = new_df[-60:].values\n# # Scale the data to be values between 0 and 1\n# last_60_days_scaled = scaler.transform(last_60_days)\n# #Create an empty list\n# X_test = []\n# # Append the past 60 days\n# X_test.append(last_60_days_scaled)\n# # convert to numpy array\n# X_test = np.array(X_test)\n# # Reshape\n# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n# # Get the predicted scaled price\n# pred_price = model.predict(X_test)\n# # undo the scaling\n# pred_price = scaler.inverse_transform(pred_price)[0]\n# btc_quote2 = web.DataReader('BTC-USD', data_source='yahoo', start='2021-09-20', end='2021-09-20')\n# actual_price = btc_quote2['Close'][0]\n# actual_price\n# accuracy = ((pred_price-actual_price)\/actual_price)*100\n# print('Prediction close price at 9-20-2021: $', pred_price, sep='')\n# print('Actual price at 9-20-2021: $', actual_price, sep='')\n# print('Accuracy: ', accuracy, '%', sep='')","23907a53":"data1 = selected_data1.filter(['Close'])\ndataset1 = data1.values\ntraining_data_len1 = math.ceil(len(dataset1) * .8)\n# Scale the Data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data1 = scaler.fit_transform(dataset1)\n# Create the training data set\n# Create the scaled training data set\ntrain_data1 = scaled_data1[0:training_data_len1, :]\n\n# Split the data itno x_train and y_train data sets\nx_train1 = []\ny_train1 = []\n\nfor i in range(60, len(train_data1)):\n    x_train1.append(train_data1[i-60:i,0])\n    y_train1.append(train_data1[i,0])\n    \n# Convert the x_train and y_train to numpy arrays\nx_train1, y_train1 = np.array(x_train1), np.array(y_train1)\n# Reshape the data\nx_train1 = np.reshape(x_train1, (x_train1.shape[0], x_train1.shape[1], 1))\n# x_train.shape\n\n# Build the LSTM Model\nmodel1 = Sequential()\nmodel1.add(LSTM(50, return_sequences=True, input_shape=(x_train1.shape[1], 1)))\nmodel1.add(LSTM(50, return_sequences=False))\nmodel1.add(Dense(25))\nmodel1.add(Dense(1))","0530ff7d":"# Compile the model\nmodel1.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel1.fit(x_train1, y_train1, batch_size=1, epochs=1)","06d8b4dd":"# Create the testing data set\n# Create new array containing scaled values from index 1028 to 1359\ntest_data1 = scaled_data1[training_data_len1 - 60: , :]\n\n# Create the data sets x_test and y_test\nx_test1 = []\ny_test1 = dataset1[training_data_len1: , :]\nfor i in range(60, len(test_data1)):\n    x_test1.append(test_data1[i-60:i, 0])\n    \n# convert data to numpy array\nx_test1 = np.array(x_test1)\n\n# reshape the data\nx_test1 = np.reshape(x_test1, (x_test1.shape[0], x_test1.shape[1], 1))\n\n# Get the models predicted price values\npredictions1 = model1.predict(x_test1)\npredictions1 = scaler.inverse_transform(predictions1)\n\n# Get the root mean square error (RMSE)\nrmse1 = np.sqrt( np.mean( predictions1 - y_test1 )**2 )","570d562e":"# Plot the data\ntrain1 = data1[:training_data_len1]\nvalid1 = data1[training_data_len1:]\nvalid1['Predictions'] = predictions1\n\n# Visualize the data\nplt.figure(figsize=(12,6))\nplt.title('Model', fontsize=12)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Close Price USD ($)', fontsize=12)\nplt.tick_params(labelsize=9, width=0.2, length=1)\n\nplt.plot(train1['Close'], linewidth=2.0)\nplt.plot(valid1[['Close', 'Predictions']], linewidth=2.0)\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right', fontsize=9)\nplt.show()","96b0b556":"temp = df_train.reset_index(drop = True) \ntemp['TIME'] = pd.to_datetime(temp['timestamp'], unit='s')\nstart = dt.datetime.strptime('2021-01-01', '%Y-%m-%d')\nend = dt.datetime.strptime('2021-09-20', '%Y-%m-%d')\ntrain_data = temp.loc[temp[\"TIME\"].between(start, end)]","ab3dbdb8":"# train test split df_train into 80% train rows and 20% valid rows\n\ndef get_Xy_and_model_for_asset(df_train, asset_id):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]\n    df = df.filter(['Close'])\n    df = df.values\n    training_data_len = math.ceil(len(df) * .001)\n    # Scale the Data\n    scaler = MinMaxScaler(feature_range=(0,1))\n    scaled_data = scaler.fit_transform(df)\n    # Create the training data set\n    # Create the scaled training data set\n    train_data = scaled_data[0:training_data_len, :]\n\n    # Split the data itno x_train and y_train data sets\n    x_train = []\n    y_train = []\n\n    for i in range(60, len(train_data)):\n        x_train.append(train_data[i-60:i,0])\n        y_train.append(train_data[i,0])\n\n    # Convert the x_train and y_train to numpy arrays\n    x_train, y_train = np.array(x_train), np.array(y_train)\n    # Reshape the data\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n    # x_train.shape\n    # Build the LSTM Model\n    model = Sequential()\n    model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n    model.add(LSTM(50, return_sequences=False))\n    model.add(Dense(25))\n    model.add(Dense(1))\n    # Compile the model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    # Train the model\n    model.fit(x_train, y_train, batch_size=1, epochs=1) # LSTM model\n    return x_train, y_train, model\n\nXs = {}\nys = {}\nmodels = {}\n\nfor asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n    X, y, model = get_Xy_and_model_for_asset(train_data, asset_id)       \n    try:\n        Xs[asset_id], ys[asset_id], models[asset_id] = X, y, model\n    except: \n        Xs[asset_id], ys[asset_id], models[asset_id] = None, None, None","46d4ea90":"sup_train = pd.read_csv('..\/input\/g-research-crypto-forecasting\/supplemental_train.csv', \n                 usecols=['Close', 'Target', 'Asset_ID','timestamp'], dtype={'Asset_ID': 'int8'})\nsup_train['datetime'] = pd.to_datetime(sup_train['timestamp'], unit='s')\nsup_train = sup_train.set_index('datetime').drop('timestamp', axis=1)\nsup_train = sup_train[(sup_train.index.year == 2021) & (sup_train.index.month > 5)]\nsup_trains = {asset_id: sup_train[sup_train['Asset_ID'] == asset_id].resample('1min').interpolate().copy() for asset_id in sup_train['Asset_ID'].unique()}\ndel sup_train","2de5740d":"import gresearch_crypto\nenv = gresearch_crypto.make_env()\niter_test = env.iter_test()","7ce41824":"df = pd.read_csv('..\/input\/g-research-crypto-forecasting\/supplemental_train.csv', \n                 usecols=['Target', 'Asset_ID','timestamp'], dtype={'Asset_ID': 'int8'})\ndf['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\ndf = df.set_index('datetime').drop('timestamp', axis=1)\ndf = df[(df.index.year == 2021) & (df.index.month > 5)]\ndfs = {asset_id: df[df['Asset_ID'] == asset_id].resample('1min').interpolate().copy() for asset_id in df['Asset_ID'].unique()}\ndel df\nfor df_test, df_pred in iter_test:\n    df_test['datetime'] = pd.to_datetime(df_test['timestamp'], unit='s')\n    for _, row in df_test.iterrows():\n        try:\n            df = dfs[row['Asset_ID']]\n            closest_train_sample = df.iloc[df.index.get_loc(row['datetime'], method='nearest')]\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = closest_train_sample['Target']\n        except:\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = 0\n    df_pred['Target'] = df_pred['Target'].fillna(0)\n    env.predict(df_pred)","1c3daa85":"We see that the prediction line (green line) for Ethereum is aligned with the trend. If we bought the ethereum in early August at around USD21,000, then from this prediction we can sell it at above USD30,000, we can get a decent profit of around 30% within less than two months. We have tested the LTSM prediction modeling to Bitcoin and Ethereum and show that this model works well for crypto currency prediction. \n\nIf we compare with technical indicator which help us in making trading decision, the machine learning approach provide us more confident prediction. We see the visualization prediction in the future where the price direction in the future. While on the other hand technical indicator will give us the signal much closer time frame before the direction start changing its direction.\n\nThe two cryptos analysis shows similar result with acceptable predictions. Then we can assure that this LSTM model should works well with other crypto currencies. So next we will do same steps to get the best estimator.","363a4592":"# <span class=\"title-section w3-xxlarge\">Relative Strength Index (RSI)<\/span>\nRSI is one of the most common momentum indicator aimed at quantifies price changes and the speed of such change. The most elementary way of using the index is buying when an asset or cryptocurrency is oversold, and selling when it\u2019s overbought.\n\nGenerally, an asset is overbought when the RSI value is 70% or above, and oversold when the value is 30% or below. When an asset is overbought, it\u2019s a clear signal of a looming downtrend. On the flip side, oversold security is a sign of an incoming upward trend. In this case, the weakness of the asset is running out of steam and it\u2019s gathering momentum to climb higher. \n\nRSI is the source of diverse trend trading strategies. One other common trading strategy is buying or selling when RSI hits the midline or crosses it. This depicts the start of a new trend. \n\nWhen the RSI is above 50, a bullish trend is brewing. When it\u2019s below 50, it\u2019s the start of a bearish trend. \n\nWhile using the midline cross-trading strategy, traders frequently use the ratios of 70\/30, 50\/50 or 60\/40 as resistance and support in bullish or bearish trends. \n\nWhen the resistance suffers a hit, a trend reversal may occur. Hence, traders should spring to action accordingly.","96381c94":"The chart shows the best performance of Bitcoin this year. By combining SMA and RSI together we have a better indicators for trading decision. The technical indicator tells that we only buy when the the blue line (SMA_5) is above red line (SMA_15) and RSI is above 80, and sell when the red line is below the green line and RSI is below 20.\n\nYou see the price drop in January this year, then rebound back and continue rise and reach all time high at April. RSI indicator reach its lowest below 20 in end of April. Fast SMA (5) crossing the long SMA (15) happened few times, where you can buy, and sell when SMA (5) crossing down the SMA (15). RSI helps tells the confirmation to buy or sell.","955f017f":"## <span class=\"title-section w3-xlarge\">References:<\/span>\n[Wikipedia: Cryptocurrency](https:\/\/en.wikipedia.org\/wiki\/Cryptocurrency)<br>\n[Most Commonly-Used Periods in Creating Moving Average (MA) Lines](https:\/\/www.investopedia.com\/ask\/answers\/122414\/what-are-most-common-periods-used-creating-moving-average-ma-lines.asp)<br>\n[Implementation of Technical Indicators into a Machine Learning framework for Quantitative Trading](https:\/\/towardsdatascience.com\/implementation-of-technical-indicators-into-a-machine-learning-framework-for-quantitative-trading-44a05be8e06)<br>\n[AlgoTrading using Technical Indicator and ML models](https:\/\/www.analyticsvidhya.com\/blog\/2021\/01\/algotrading-using-technical-indicator-and-ml-models\/)<br>\n[What Is RSI and How Do You Apply It to Crypto Trading?](https:\/\/learn.bybit.com\/trading\/what-is-rsi-and-how-do-you-apply-it-to-crypto-trading\/)<br>\n[Technical Analysis 101: The Best Technical Indicators for Crypto and Stocks](https:\/\/coinmarketcap.com\/alexandria\/article\/technical-analysis-101-the-best-technical-indicators-for-crypto-and-stocks)<br>\n[Simple Sequence Prediction With LSTM](https:\/\/medium.com\/@nutanbhogendrasharma\/simple-sequence-prediction-with-lstm-69ff0f4d57cd)<br>\n[How to Develop LSTM Models for Time Series Forecasting](https:\/\/machinelearningmastery.com\/how-to-develop-lstm-models-for-time-series-forecasting\/)","73acf77a":"Check the price if the prediction is correct!","eedb1226":"The result is +\/- 10.7% precision compare to actual close price. Or can I say the accuracy is 90%?  When you close your trading, you will get the actual price. So it is not about the accuracy in terms of dollars, but more importantly help us indicate the direction of how the market is going in the future.\n\nNow, let's see how much gain do we get.","0a8c268a":"<span class=\"title-section w3-xlarge\">Thank you for visiting this notebook!<\/span>\n\n<p>If you like this notebook, you know it is <span class=\"w3-tag w3-large\"><b>FREE<\/b><\/span> to click the upvote button.<\/p>\n<p>Thanks for reading this notebook. If you have any feedback or comments please write it down the comment section below. Let's learn technical analysis, algo trading and machine learning for crypto trading together!<\/p>","c293048e":"### <span class=\"title-section w3-large\">Prediction vs Actual Price<\/span><br>\nWe see from the chart above, price direction prediction whether the price will be up or down. Next, let's check the accuracy of LSTM prediction. We can check the actual price directly from Yahoo!","57cd1507":"Bitcoin has highest weight is the top on the list, followed by Ethereum. We will focus on the top two crypto currencies.","d088e9bb":"### <span class=\"title-section w3-large\">Plot the data.<\/span>","5d24496b":"# <span class=\"title-section w3-xxlarge\">Moving Average<\/span>\nMoving averages simplify and smoothen price fluctuations, reducing the noise and giving you a better idea of which direction the market is going, and where it might potentially go. Reducing noise from a chart will give you a much clearer picture of what is happening.\n\nMA\u2019s are calculated by summing up the previous data points, or candles, which are then divided by the number of points. What does this mean?\n\nA 20 MA is derived from summing up the previous 20 periods, divided by 20.\nA 100 MA is derived from summing up the previous 100 periods, divided by 100.\n\n## <span class=\"title-section w3-xxlarge\">Simple Moving Average (SMA)<\/span>\n\nThe Simple Moving Average, or SMA line, is calculated based on the closing price of a period. A \u2018period\u2019 means a candle. For example, the closing price of 3 periods or candles is summed up and then divided by 3. Every period in the calculation has the same weight.\n\n             An example: we have 3 periods, $50, $45, and $60.\n             The formula is: 50 + 45 + 60 = 155 \/ 3 (the number of periods) = 51.66 as a 3 SMA.\n\nThe Simple Moving Average is very smooth and is at its strongest as a long-term indicator, on any timeframe.","01f691b2":"# <span class=\"title-section w3-xxlarge\">LSTM Prediction<\/span>","91d15df3":"# <span class=\"title-section w3-xxlarge\">Cryptocurrency<\/span>\n\nAccording to Wikipedia, a cryptocurrency, crypto-currency, or crypto is a collection of binary data which is designed to work as a medium of exchange. Individual coin ownership records are stored in a ledger, which is a computerized database using strong cryptography to secure transaction records, to control the creation of additional coins, and to verify the transfer of coin ownership. Cryptocurrencies are generally fiat currencies, as they are not backed by or convertible into a commodity. Some crypto schemes use validators to maintain the cryptocurrency. In a proof-of-stake model, owners put up their tokens as collateral. In return, they get authority over the token in proportion to the amount they stake. Generally, these token stakers get additional ownership in the token over time via network fees, newly minted tokens or other such reward mechanisms. Cryptocurrency does not exist in physical form (like paper money) and is typically not issued by a central authority. Cryptocurrencies typically use decentralized control as opposed to a central bank digital currency (CBDC). When a cryptocurrency is minted or created prior to issuance or issued by a single issuer, it is generally considered centralized. When implemented with decentralized control, each cryptocurrency works through distributed ledger technology, typically a blockchain, that serves as a public financial transaction database.\n\nBitcoin, first released as open-source software in 2009, is the first decentralized cryptocurrency. Since the release of bitcoin, many other cryptocurrencies have been created.<a href=\"#f4\" id=\"a1\"><sup>[2]<\/sup><\/a>","579f97f4":"## <span class=\"title-section w3-xlarge\">Submission<\/span><br>\nEverything looks good. It is now the time to submit the result.","6553593c":"Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video).\n\nLSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.\nA common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n\nLSTMs are very powerful in sequence prediction problems because they\u2019re able to store past information. This is important in our case because the previous price of a stock is crucial in predicting its future price.","2488e432":"<span class=\"w3-tag w3-large\"><b>Crypto Trading Analysis<\/b><\/span><br>\n<span class=\"title-section w3-xxxlarge\">Technical Indicator vs ML Prediction<\/span>","11651f75":"![art-rachen-sM4r-swmcoY-unsplash.jpg](attachment:63316ae0-8d07-4554-b61b-f695eb7e06cd.jpg)<br>\n[Image by Art Rachen](https:\/\/unsplash.com\/photos\/sM4r-swmcoY?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink)","c8832d8d":"<span class=\"w3-tag w3-large\"><b>WARNING<\/b><\/span>\n\n*This notebook is written for [G-Research Crypto Forecasting](https:\/\/www.kaggle.com\/c\/g-research-crypto-forecasting) competition at Kaggle and learning purposes only. Do not use it for real trading with real money. The information provided on this notebook does not constitute investment advice, financial advice, trading advice, or any other sort of advice and you should not treat any of the website's content as such. This notebook does not recommend that any cryptocurrency should be bought, sold, or held by you. Do conduct your own due diligence and consult your financial advisor before making any investment decisions.*","a3bd6d76":"# <span class=\"title-section w3-xxlarge\">Ethereum LSTM prediction<\/span>\nNow let's do the same LSTM modeling for Ethereum as we did earlier for Bitcoin.","7fe9e8db":"### <span class=\"title-section w3-large\">Build the LSTM Model.<\/span>","ce4a02c5":"# <span class=\"title-section w3-xxlarge\">Ethereum Performance<\/span>\n\nNow let's do the same for Ethereum and see its performance.","273e4968":"### <span class=\"title-section w3-large\">Split the data.<\/span>","6c699d6f":"# <span class=\"title-section w3-xxlarge\">Technical Indicator<\/span>\n\nTechnical Analysis (TA) is a popular technique to evaluate stocks or coins based on similar data points and elements. This articulation will tell you about TA while also delving into trading indicators before we conclude with the best indicators for you. \n\nThe price charts of any coin\/stock are free for diverse interpretations. Hence, during TA, technicals like support levels can go for a toss as every trader with their prejudice intact can draw support lines at different price points. Support and resistance zones are vital and drawing them should never boil down to destiny.\n\nTo remove this uncertainty and provide a level-playing field, technical indicators are used. They are mathematical calculations used to plot lines on the price chart to identify trends and key price points of a coin\/stock.\nThink of trading indicators as a map that guides you through the maze of ambiguity. Using them in coalition with a bit of market psychology and understanding of risk will enable you to make better trading decisions. Given their quantitative nature, you can also automate your trades using these indicators.<a href=\"#f4\" id=\"a1\"><sup>[3]<\/sup><\/a>","304d89b6":"New comer crypto currency Dodgecoin, has highest volume transaction this year, while the two most popular currencies Bitcoin and Etherium are a lot less volumes.","3ecab9f9":"# <span class=\"title-section w3-xxlarge\">Bitcoin Performance<\/span>\nNow let us see how is the performance of Bitcoin from the data. The given data is from 2018 until end of 2020 last year, lowest timeframe is in seconds. For our analysis let's assume we will trade on daily time frame or longer. We use simple technical indicators that commonly use for technical analysis: Simple Moving Average (SMA) and Relative Strength Index (RSI).","93ee3789":"## <span class=\"title-section w3-xlarge\">Bitcoin LSTM prediction<\/span>","5810fee1":"# Price prediction for all assets","b5512a1b":"We can see that by using simple technical indicators on daily trading, we can get nice profits. In 2020 shows a significant price increases started around May, despite of the pandemic of Covid-19. We see the spike of Covid-19 was during Marc 2020 then back to rise again during pandemic."}}