{"cell_type":{"dcc6e936":"code","c90843e9":"code","f6b818ae":"code","c6fa39ac":"code","9d4bd5ad":"code","f22e98aa":"code","875ba322":"code","fd72ad8d":"code","427073df":"code","3d90840f":"code","2d138cc0":"code","cc047d3c":"code","a1374d13":"code","63ddcb2d":"code","cc3ad5c5":"code","caa76759":"code","4f368ab4":"code","0607fd2f":"code","9aa41e2c":"code","cdd5d28e":"code","14a4893b":"code","cb1eccb0":"code","c11e3524":"code","b1d86e53":"code","0b11ba95":"markdown","69426b0b":"markdown","46c2208a":"markdown","372a3fff":"markdown","9454a7f4":"markdown","f68f7dc8":"markdown","0401d18c":"markdown","c7b11cc9":"markdown"},"source":{"dcc6e936":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n    break\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c90843e9":"directory = '\/kaggle\/input\/rockpaperscissors'\nprint(os.listdir(directory))","f6b818ae":"labels = ['paper','scissors','rock']\nnb = len(labels)","c6fa39ac":"import tensorflow as tf\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping","9d4bd5ad":"def input_target_split(train_dir,labels):\n    dataset = []\n    count = 0\n    for label in labels:\n        folder = os.path.join(train_dir,label)\n        for image in os.listdir(folder):\n            img=load_img(os.path.join(folder,image), target_size=(150,150))\n            img=img_to_array(img)\n            img=img\/255.0\n            dataset.append((img,count))\n        print(f'\\rCompleted: {label}',end='')\n        count+=1\n    random.shuffle(dataset)\n    X, y = zip(*dataset)\n    \n    return np.array(X),np.array(y)","f22e98aa":"X, y = input_target_split(directory,labels)","875ba322":"import matplotlib.pyplot as plt","fd72ad8d":"plt.figure(figsize = (15 , 9))\nn = 0\nfor i in range(15):\n    n+=1\n    plt.subplot(5 , 5, n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(X[i])\n    plt.title(f'Label: {labels[y[i]]}')","427073df":"np.unique(y,return_counts=True)","3d90840f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=42)\nprint(np.unique(y_train,return_counts=True),np.unique(y_test,return_counts=True))","2d138cc0":"datagen = ImageDataGenerator(horizontal_flip=True,\n                             vertical_flip=True,\n                             rotation_range=20,\n                             zoom_range=0.2,\n                             width_shift_range = 0.2,\n                             height_shift_range = 0.2,\n                             shear_range=0.1,\n                             fill_mode=\"nearest\")\n\ntestgen = ImageDataGenerator()\n\ndatagen.fit(X_train)\ntestgen.fit(X_test)","cc047d3c":"y_train = np.eye(nb)[y_train]\ny_test = np.eye(nb)[y_test]","a1374d13":"model = Sequential()\nmodel.add(Conv2D(32, (3,3), input_shape=(150,150,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(32, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dense(units=3, activation='softmax'))","63ddcb2d":"model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])","cc3ad5c5":"model.summary()","caa76759":"filepath= \"model_cnn_final.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=False)\n\nearly_stopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n\n# learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n#                                             patience=3, \n#                                             verbose=1, \n#                                             factor=0.2, \n#                                             min_lr=0.00001)\n\ncallbacks_list = [\n        checkpoint,\n        early_stopping,\n#         learning_rate_reduction\n    ]\n","4f368ab4":"hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n                                        validation_data=testgen.flow(X_test,y_test,batch_size=32),\n                                        epochs=50,\n                                        callbacks=callbacks_list)","0607fd2f":"model_saved = tf.keras.models.load_model('model_cnn_final.h5')","9aa41e2c":"y_pred = model_saved.predict(X_test)\npred = np.argmax(y_pred,axis=1)\nprint(pred)","cdd5d28e":"ground = np.argmax(y_test,axis=1)","14a4893b":"from sklearn.metrics import classification_report\n\nprint(classification_report(ground,pred,target_names = labels))","cb1eccb0":"test = pd.DataFrame()","c11e3524":"test.to_csv(\"sample.csv\")","b1d86e53":"tf.__version__","0b11ba95":"# **Classification Report of the model**","69426b0b":"# **Compiling the model with its optimizer, loss function and metric**","46c2208a":"# **Splitting the images and labels into training and test set**","372a3fff":"# **Defining the CNN Model**","9454a7f4":"# **Applying Data Augmentation Techniques**","f68f7dc8":"# **Visualizing the Images**","0401d18c":"# **Defining the callbacks for the model such as EarlyStopping and Best Model Checkpoint**","c7b11cc9":"# **Dividing the Images and Labels**"}}