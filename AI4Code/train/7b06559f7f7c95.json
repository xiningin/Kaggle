{"cell_type":{"31b9387d":"code","0ae6f032":"code","0657f61c":"code","0ebbbae2":"code","823afafd":"code","1a87b53d":"code","df8fc595":"code","a9cebae9":"code","39815623":"code","0485039b":"code","255913a4":"code","b455acff":"code","488a3c1d":"code","b681bc0a":"code","8a091b44":"code","6d7bebe4":"code","8868e5c4":"code","2d953626":"code","d454c118":"code","313656f9":"code","cfe7412c":"code","28f7dd2c":"code","2957e5ed":"code","24f05984":"code","5c3dffcd":"code","f7b89f9c":"code","5aac6c6b":"code","93f06017":"code","0229fb95":"code","87c67caf":"markdown","3831729b":"markdown","cf7aae29":"markdown","f67d52da":"markdown","7fcdccc6":"markdown","27206b29":"markdown","97879c70":"markdown","da140d5a":"markdown","3e85e11c":"markdown","a6c254cb":"markdown","c5e835b7":"markdown","c8dee759":"markdown","a2b7310b":"markdown","8cbaa93b":"markdown","745c00a5":"markdown"},"source":{"31b9387d":"import numpy as np\nimport pandas as pd\nfrom fastai.vision import *\nfrom fastai.tabular import *\nimport matplotlib.pyplot as plt\nimport re","0ae6f032":"path=Path('\/kaggle\/working\/')","0657f61c":"train=pd.read_csv('\/kaggle\/input\/train.csv')\ntrain['index'] = train.index\ntrain.head()","0ebbbae2":"class PixelList(ImageList):\n    def open(self,index):\n        regex = re.compile(r'\\d+')\n        fn = re.findall(regex,index)\n        df_fn = self.inner_df[self.inner_df.index.values == int(fn[0])]\n        img_pixel = df_fn.drop(labels=['label','index'],axis=1).values\n        img_pixel = img_pixel.reshape(28,28)\n        img_pixel = np.stack((img_pixel,)*3,axis=-1)\n        return vision.Image(pil2tensor(img_pixel,np.float32).div_(255))","823afafd":"src = (PixelList.from_df(train,'.',cols='index')\n      .split_by_rand_pct(0.1)\n      .label_from_df(cols='label'))","1a87b53d":"tfms=get_transforms(rand_pad(padding=5,size=28,mode='zeros'))","df8fc595":"data = (src.transform(tfms,size=128)\n       .databunch(num_workers=5,bs=48)\n       .normalize())\n","a9cebae9":"data.show_batch(rows=3,figsize=(10,7))","39815623":"learner=cnn_learner(data,models.resnet101,metrics=[FBeta(),accuracy,error_rate])","0485039b":"learner.lr_find()\nlearner.recorder.plot(suggestion=True)","255913a4":"lr=9e-3","b455acff":"learner.fit_one_cycle(5,slice(lr))","488a3c1d":"learner.save('Resnet1')","b681bc0a":"learner.lr_find()\nlearner.recorder.plot(suggestion=True)","8a091b44":"learner.freeze_to(2)","6d7bebe4":"learner.fit_one_cycle(4,slice(5e-6,lr\/50))","8868e5c4":"learner.save('Resnetfinal')","2d953626":"train=pd.read_csv('\/kaggle\/input\/train.csv')\ndata=TabularDataBunch.from_df(path,train,dep_var='label',valid_idx=range(4000,6000))","d454c118":"tablearner=tabular_learner(data,layers=[200,100],ps=[0.001,0.01],emb_drop=0.004,metrics=accuracy)","313656f9":"tablearner.lr_find()\ntablearner.recorder.plot(suggestion=True)","cfe7412c":"lr=2.2e-2","28f7dd2c":"tablearner.fit_one_cycle(10,slice(lr),wd=0.1)","2957e5ed":"tablearner.lr_find()\ntablearner.recorder.plot(suggestion=True)","24f05984":"tablearner.fit_one_cycle(4,4e-6,wd=0.1)","5c3dffcd":"df_test = pd.read_csv('..\/input\/test.csv')\ndf_test['label'] = 0\ndf_test['index'] = df_test.index\ndf_test.head()","f7b89f9c":"learner.load('Resnetfinal')","5aac6c6b":"learner.data.add_test(PixelList.from_df(df_test,path='.',cols='index'))","93f06017":"pred_test = learner.get_preds(ds_type=DatasetType.Test)\ntest_result = torch.argmax(pred_test[0],dim=1)\nresult = test_result.numpy()","0229fb95":"final = pd.Series(result,name='Label')\nsubmission = pd.concat([pd.Series(range(1,28001),name='ImageId'),final],axis=1)\nsubmission.to_csv('submit.csv',index=False)","87c67caf":"We are adding the index number for now for easier manipulation. We'll be removing it later.","3831729b":"Now we call it just like our vanilla ImageList. We have to pass cols='index' because PixelList \"open\" expects that argument.","cf7aae29":"## FastAI Vision CNN learner on tabular data","f67d52da":"## Training Resnet\n\nThis part is pretty self-explanatory. We get a Resnet101, train for a bit and see the results.","7fcdccc6":"## What About DenseNet?\n\nI have experimented a bit with densenet as well. But as it takes an obscene amount of time to train, I've decided not to include it this round.\nDenseNet201 gave >98%, but not quite like resnet; not doing justice to the time it took to train.\n","27206b29":"Let's look at the data now.","97879c70":"Even though the digit recognizer dataset is organized as a table, it is indeed pictures of handwritten digits. We usually treat it as any other tabular classification problem, but it may be worth transforming it into a set of pictures and applying fastai.vision library on it. Fastai Vision is pretty good, let's see how it holds up against Tabular in its home turf.\n\nWe are going to literally turn rows into pictures. To do that we need to make our own Imagelist class to change how the data loads into our databunch. ","da140d5a":"Getting transforms is a bit tricky. These are not ordinary images, so flipping, zooming and cropping will yield weird instances. Also padding needs to be zeros, we can not expect reflection on the paddings.","3e85e11c":"Let's unfreeze all layers except first two and train some more.","a6c254cb":"## Creating Custom ImageList\n\nWe need an ImageList to chuck into the cnn. So we should make a sub-class of the ImageList and change how it loads the data.","c5e835b7":"## Verdict [spoilers: Resnet wins]\n\nAfter some trial and error, I've found tabular learner to work best under the params I've chosen above. With no input pre-processing, Tabulars best accuracy is around 97~98%.\nWhere Resnet gives <99% results every time. It seems resnet has asserted its dominance again.","c8dee759":"## Submit!\n\nSo we have our winner.\n","a2b7310b":"**Step By Step :**\n\n1. Declaring our own PixelList class, subclass of ImageList so that it inherits everything.\n2. While subclassing an ItemList we can modify three methods and \"open\" is one of them. We are going to override this method because it is called when ImageList tries to open an image.\n        For more details check [here](https:\/\/docs.fast.ai\/tutorial.itemlist.html#Creating-a-custom-ItemList-subclass).\n3. Defining a regular expression to find integers and compile it.\n4. Finding and save the rows matching index number.\n5. Picking a dataframe of only the index we have already chosen to read as an image.\n6. Droping index and label, they are not parts of the picture and taking an array of values.\n7. Reshaping 784x1 to 28x28 array.\n8. Blowing the image up 3 times.\n9. Creating an Image from the array using vision.image library.\n        For more details check [here](https:\/\/docs.fast.ai\/vision.image.html#pil2tensor).","8cbaa93b":"Finally we get them as size 128 and normalize them. We're not using imagenet_stats for the same reason.","745c00a5":"## Training Tabular Learner\n\nWe just create a databunch, get a tabular learner and train it.\nTabular learner will consider this a classfication problem by default. All 784 columns are going to become features, so we have to be careful not to overfit."}}