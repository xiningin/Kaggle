{"cell_type":{"98954688":"code","ab4d1c87":"code","2804f7ed":"code","b665ec30":"code","1b550ece":"code","f434ec64":"code","91e6141b":"code","87f1afc6":"code","13c08f65":"code","471e43d9":"code","85b6f6be":"code","f979ab6d":"code","a440a0f9":"code","488e9886":"code","4972da00":"code","5ddb6b61":"code","089b1712":"code","742b812f":"code","053d3f74":"code","0c2e70a4":"code","26fe0e85":"code","fa9502bb":"code","ab3d9be3":"code","9bf25b5f":"code","41047c85":"code","24d7891d":"code","a1f09b1b":"code","37cb78a6":"code","743eb999":"code","a0a6d14d":"code","0d8e7674":"code","2400039a":"code","f18a191d":"code","d33bc6c2":"code","052cd564":"code","c08fb484":"code","0a23d7ef":"code","ccf75bb0":"code","f22c0e0b":"code","52082ae6":"code","4a8798c4":"code","b03a51da":"code","5e354858":"code","e1492dc7":"code","69d460f7":"code","c052e5b0":"code","0c7611ef":"code","f7e74bb9":"code","ba1256b9":"code","86604bf8":"markdown","b928ad93":"markdown","946c3136":"markdown","802ef48d":"markdown","768ee664":"markdown","83d90d7f":"markdown","9eb6c379":"markdown","37cc3910":"markdown","a1aa577a":"markdown","00f057ea":"markdown","9ca363af":"markdown","cc2840d4":"markdown","2983fb91":"markdown","61c0132c":"markdown"},"source":{"98954688":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom IPython.display import clear_output\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import RidgeClassifier\n","ab4d1c87":"df=pd.read_excel('..\/input\/telco-customer-churn-ibm-dataset\/Telco_customer_churn.xlsx')\ndf.head()","2804f7ed":"df.info()","b665ec30":"#Eliminer les espaces dans les noms des colonnes\ndf.columns = df.columns.map(lambda x: x.replace(' ', ''))","1b550ece":"df.hist(bins=10,figsize=(15,15))","f434ec64":"plt.figure(figsize=(10,7),facecolor='#eeeeee')\nsns.heatmap(pd.crosstab(df.PhoneService,df.InternetService),annot=True,fmt=\"d\",cmap=\"Blues\")\nplt.title('Phone Service & Internet Service\\n ',fontsize=26,color='brown')","91e6141b":"plt.figure(figsize=(10,7),facecolor='#eeeeee')\nsns.heatmap(pd.crosstab(df.Gender,df.Contract),annot=True,fmt=\"d\",cmap=\"Blues\")\nplt.title('Gender & Contract\\n ',fontsize=26,color='brown')","87f1afc6":"plt.figure(figsize=(10,7),facecolor='#eeeeee')\nsns.heatmap(pd.crosstab(df.SeniorCitizen,df.PaymentMethod),annot=True,fmt=\"d\",cmap=\"Blues\")\nplt.title('SeniorCitizen & PaymentMethod\\n ',fontsize=26,color='brown')","13c08f65":"import plotly.express as px\nfig = px.density_heatmap(df, x=\"Gender\",y='ChurnLabel', \n                 template=\"plotly_dark\",  marginal_x='histogram', marginal_y='histogram',\n                 animation_frame='Contract')\nfig.show()\n","471e43d9":"fig = px.scatter(df, x=\"Latitude\",y='Longitude', color=\"ChurnLabel\",\n                 template=\"plotly_dark\",  \n                 animation_frame='City')\nfig.show()","85b6f6be":"plt.figure(figsize=(10,7),facecolor='#eeeeee')\nplt.scatter(data=df.query(\"ChurnLabel == 'Yes'\"),x=\"Latitude\",y='Longitude',alpha=0.09)","f979ab6d":"fig = px.density_mapbox(data_frame=df, lat='Latitude', lon='Longitude', radius=10,\n                        center=dict(lat=38, lon=-110), zoom=2.5,animation_frame='ChurnLabel',\n                        mapbox_style=\"stamen-terrain\")\nfig.show()","a440a0f9":"df.drop(['CustomerID','Count','Country', 'State', 'LatLong','ChurnReason','ChurnLabel', 'ChurnScore', 'CLTV'],axis=1,inplace =True)\n","488e9886":"#convert object column to float64 columns\ndf['TotalCharges']=df['TotalCharges'].apply(pd.to_numeric,errors='coerce') ","4972da00":"print(df.isnull().sum())\nprint('La somme des valeurs null: ', df.isnull().sum().sum())","5ddb6b61":"MoyTotalCharge = df.TotalCharges.mean()\ndf.TotalCharges = df.TotalCharges.fillna(MoyTotalCharge)","089b1712":"print(df.shape)\nprint('La somme des valeurs null',df.isnull().sum().sum())","742b812f":"df['tenure_bin'] = pd.cut(df.TenureMonths,\n                          pd.IntervalIndex.from_tuples([(-1,6),(6,12),(12,18),(18,24),\n                                                        (24,30),(30,36),(36,42),(42,48),\n                                                        (48,54),(54,60),(60,66),(66,72)]))\ndf.head()","053d3f74":"df = pd.concat([df, pd.get_dummies(df.tenure_bin, prefix='tenure_bin')], axis=1)\ndf = pd.concat([df, pd.get_dummies(df.Contract, prefix='Contract')], axis=1)\ndf = pd.concat([df, pd.get_dummies(df.PaymentMethod, prefix='PaymentMethod')], axis=1)\ndf = pd.concat([df, pd.get_dummies(df.InternetService, prefix='InternetService')], axis=1)\ndf.drop(['TenureMonths','tenure_bin','Contract','PaymentMethod','InternetService'],axis = 1 ,inplace = True)\n\nencodeur = LabelEncoder()\nfor col in df.columns:\n     if col in ['City','Gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling','MultipleLines','OnlineSecurity',\n                'OnlineBackup','DeviceProtection' , 'TechSupport', 'StreamingTV', 'StreamingMovies', 'StreamingTV']:\n        df[col] = encodeur.fit_transform(df[col])","0c2e70a4":"df.head()","26fe0e85":"df.shape","fa9502bb":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr())","ab3d9be3":"plt.figure(figsize=(15,8))\ndf.corr()['ChurnValue'].sort_values(ascending = False).plot(kind='bar')","9bf25b5f":"df.drop(['ZipCode','Latitude','Longitude','City'],axis = 1 ,inplace = True)","41047c85":"X=df.drop('ChurnValue',axis=1)\ny=df.ChurnValue\ncolName= X.columns\n\nscaler=MinMaxScaler()\nX= scaler.fit_transform(X)\nX","24d7891d":"roc_auc={}\npr_auc={}","a1f09b1b":"def TestSelection(model,X,y):\n  #SFS\n  sfs = SFS(model, \n           k_features=\"best\", \n           forward=True, # if forward = True then SFS otherwise SBS\n           floating=False, \n           verbose=2,\n           scoring='accuracy',\n           cv=10\n           )\n  sfs.fit(X, y)\n\n  #SBS\n  sbs = SFS(model, \n           k_features=\"best\", \n           forward=False, # if forward = True then SFS otherwise SBS\n           floating=False, \n           verbose=2,\n           scoring='accuracy',\n           cv=10\n           )\n  sbs.fit(X, y)\n\n  ## Sequential Forward Floating Selection\n  sffs = SFS(model, \n           k_features=\"best\", \n           forward=True, \n           floating=True, \n           scoring='accuracy',\n           cv=10,\n           verbose=2)\n  sffs = sffs.fit(X, y)\n\n  # Sequential Backward Floating Selection\n  sbfs = SFS(model, \n           k_features=\"best\", \n           forward=False, \n           floating=True, \n           scoring='accuracy',\n           cv=10,\n           verbose=2)\n  sbfs = sbfs.fit(X, y)\n  clear_output() \n\n  print('sfs score:',sfs.k_score_ )\n  print('sbs score:',sbs.k_score_ )\n  print('sffs score:',sffs.k_score_ )\n  print('sbfs score:',sbfs.k_score_ )\n  score_sfs = []\n  score_sbs = []\n  score_sffs = []\n  score_sbfs = []\n  for i in range(1,X.shape[1]):\n        score_sfs.append(sfs.subsets_[i]['avg_score'])\n        score_sbs.append(sbs.subsets_[i]['avg_score'])\n        score_sffs.append(sffs.subsets_[i]['avg_score'])\n        score_sbfs.append(sbfs.subsets_[i]['avg_score'])\n  plt.plot(score_sfs , label=\"sfs\")\n  plt.plot(score_sbs , label =\"sbs\")\n  plt.plot(score_sffs , label =\"sffs\")\n  plt.plot(score_sbfs , label =\"sbfs\")\n  plt.xlabel('features')\n  plt.ylabel('accuracy')\n  plt.legend()\n\n  ListSelection = pd.DataFrame([sfs.k_score_,sbs.k_score_,sffs.k_score_,sbfs.k_score_])\n  m = ListSelection.idxmax(axis=0)[0]\n  if m == 0 : return sfs\n  if m == 1 : return sbs\n  if m == 2 : return sffs\n  if m == 3 : return sbfs","37cb78a6":"model = LogisticRegression(random_state=42, max_iter =10000)\nLR_FS=TestSelection(model,X,y)","743eb999":"print('best features !! : ',LR_FS.k_feature_names_)\ncolNum = list(map(int, LR_FS.k_feature_names_))\ncolLogisticReg = colName[colNum]\nX_LR_FS = LR_FS.transform(X)\nX_LR_FS = pd.DataFrame(X_LR_FS, columns=colLogisticReg)\nX_LR_FS","a0a6d14d":"X_train, X_test, y_train, y_test= train_test_split(X_LR_FS, y, \n                                                   stratify=y,\n                                                   test_size=0.2,\n                                                   random_state=1)","0d8e7674":"from sklearn.model_selection import cross_validate\nLR = LogisticRegression(random_state=42)\nscores = cross_validate(LR,X,y,cv=5, n_jobs=-1, scoring=('roc_auc', 'average_precision'))\nroc_auc['LogisticRegression'] = np.mean(np.array(scores['test_roc_auc']))\npr_auc['LogisticRegression'] = np.mean(np.array(scores['test_average_precision']))","2400039a":"model = RidgeClassifier()\nRidgeClassifier_FS = TestSelection(model,X,y)","f18a191d":"print('best features !! : ',RidgeClassifier_FS.k_feature_names_)\ncolNum = list(map(int, RidgeClassifier_FS.k_feature_names_))\ncolRidgeClassifier_FS = colName[colNum]\nX_RidgeClassifier_FS = RidgeClassifier_FS.transform(X)\nX_RidgeClassifier_FS = pd.DataFrame(X_RidgeClassifier_FS, columns=colRidgeClassifier_FS)\nX_RidgeClassifier_FS","d33bc6c2":"X_train, X_test, y_train, y_test= train_test_split(X_RidgeClassifier_FS, y, \n                                                   stratify=y,\n                                                   test_size=0.2,\n                                                   random_state=1)","052cd564":"from sklearn.linear_model import RidgeClassifier\nRC = RidgeClassifier(random_state=42)\nscores = cross_validate(RC,X_train,y_train,cv=5, n_jobs=-1, scoring=('roc_auc', 'average_precision'))\nroc_auc['Ridge Classifier'] = np.mean(np.array(scores['test_roc_auc']))\npr_auc['Ridge Classifier'] = np.mean(np.array(scores['test_average_precision']))","c08fb484":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nGaussianNB_FS = TestSelection(model,X,y)","0a23d7ef":"print('best features !! : ',GaussianNB_FS.k_feature_names_)\ncolNum = list(map(int, GaussianNB_FS.k_feature_names_))\ncolGaussianNB_FS = colName[colNum]\nX_GaussianNB_FS = GaussianNB_FS.transform(X)\nX_GaussianNB_FS = pd.DataFrame(X_GaussianNB_FS, columns=colGaussianNB_FS)\nX_GaussianNB_FS","ccf75bb0":"X_train, X_test, y_train, y_test= train_test_split(X_GaussianNB_FS, y, \n                                                   stratify=y,\n                                                   test_size=0.2,\n                                                   random_state=1)","f22c0e0b":"GNB = GaussianNB()\nscores = cross_validate(GNB,X_train,y_train,cv=5, n_jobs=-1, scoring=('roc_auc', 'average_precision'))\nroc_auc['GaussianNB'] = np.mean(np.array(scores['test_roc_auc']))\npr_auc['GaussianNB'] = np.mean(np.array(scores['test_average_precision']))","52082ae6":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier()\nknn_FS = TestSelection(model,X,y)","4a8798c4":"print('best features !! : ',knn_FS.k_feature_names_)\ncolNum = list(map(int, knn_FS.k_feature_names_))\ncolknn_FS_FS = colName[colNum]\nX_knn_FS = knn_FS.transform(X)\nX_knn_FS = pd.DataFrame(X_knn_FS, columns=colknn_FS_FS)\nX_knn_FS","b03a51da":"X_train, X_test, y_train, y_test= train_test_split(X_knn_FS, y, \n                                                   stratify=y,\n                                                   test_size=0.2,\n                                                   random_state=1)","5e354858":"knn = KNeighborsClassifier()\nscores = cross_validate(knn,X_train,y_train,cv=5, n_jobs=-1, scoring=('roc_auc', 'average_precision'))\nroc_auc['knn'] = np.mean(np.array(scores['test_roc_auc']))\npr_auc['knn'] = np.mean(np.array(scores['test_average_precision']))","e1492dc7":"pd.DataFrame.from_dict(roc_auc,orient='index', columns=['ROC-AUC']).sort_values(by='ROC-AUC', ascending=False)\n","69d460f7":"pd.DataFrame.from_dict(pr_auc,orient='index', columns=['PR-AUC']).sort_values(by='PR-AUC', ascending=False)","c052e5b0":"from scipy.stats import loguniform\nfrom sklearn.model_selection import RandomizedSearchCV\nparams = {\n    'penalty':['l1','l2','elasticnet'],\n    'C': loguniform(1e-3, 1000),\n    'solver':['newton-cg', 'lbfgs', 'liblinear']\n}\nlr = LogisticRegression()\nmodel = RandomizedSearchCV(lr, params, random_state=42, n_iter=300, scoring='roc_auc', n_jobs=-1, cv=5, refit=True)\nsearch = model.fit(X, y)\n\nprint(\"Best parameters via GridSearch\", search.best_params_)\nprint(search.best_score_)\n\n","0c7611ef":"X_train, X_test, y_train, y_test= train_test_split(X_LR_FS, y, \n                                                   stratify=y,\n                                                   test_size=0.2,\n                                                   random_state=1)\nbest_model = search.best_estimator_\nbest_model.fit(X_train, y_train)\n","f7e74bb9":"print('accuracy: ',accuracy_score(y_test,best_model.predict(X_test)))\nprint('roc_auc: ', roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]))\n","ba1256b9":"from sklearn.metrics import plot_confusion_matrix\nprint('confusion_matrix: ',plot_confusion_matrix(best_model,X_test,y_test,values_format='d' ))","86604bf8":"## Read Data ","b928ad93":"KNeighborsClassifier","946c3136":"## Visualisation  ","802ef48d":"**LogisticRegression**","768ee664":"**GaussianNB**","83d90d7f":"TotalCharges is stored as string. There are 11 rows stored TotalCharges that could not be casted as float and turned out they have missing values. I decided to change those 11 rows to mean value of the column.","9eb6c379":"\n\nIt turns out Logistic Regression is the most performing model to perform the classification which achieves highest ROC-AUC and PR-AUC score. Next, we will tune the hyperparameter for Logistic Regression\n","37cc3910":"**`Hyperparemeter finetuning`**","a1aa577a":"# Evaluation","00f057ea":"**RidgeClassifier**\n","9ca363af":"The following features are decided to be removed:  \nZipCode,Latitude,Longitude,City because lesser correlated with Churn","cc2840d4":"# **Data preprocessing**","2983fb91":"**Feature Engineering**","61c0132c":"## Import Libraries"}}