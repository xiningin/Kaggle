{"cell_type":{"40136347":"code","98d9015f":"code","a3418609":"code","48f37e14":"code","fde4d524":"code","f2ff5d0e":"code","d2198d38":"code","16189b1e":"code","76a125dc":"code","670ab0d1":"code","a520427c":"code","9931b15c":"code","6a083706":"code","e9576296":"code","0d3332cf":"code","49715371":"code","039a0b7f":"code","1c15cb28":"code","621b9ab4":"code","0932be40":"code","95f8f791":"code","93b956d3":"code","449bdb26":"code","48b0ccd8":"code","0bac9b85":"code","85eb3e91":"code","22c3da8a":"code","121a2732":"code","05eb793c":"code","3ecf42cb":"code","93c07a69":"code","10136646":"code","69d6b802":"code","e1c31364":"code","51cd19b3":"code","6088915a":"code","b4647996":"code","27d4165f":"code","aca326c2":"code","9c3925b5":"code","0286c2f6":"code","a74448ea":"code","f3623810":"code","e0f3244d":"code","27f5b3ef":"code","73c5c41d":"code","d2096ff2":"code","6b097a92":"code","b860ce00":"code","949cd361":"code","d81880ad":"code","cdd366c5":"code","f244bad8":"code","4017a84b":"code","6d36cd34":"code","f5720e3c":"code","f54fd6f6":"code","d8f191c8":"code","48c3e1b0":"code","05f6eea6":"code","a2b0cbe7":"markdown","e3c6db02":"markdown","15d2ad7d":"markdown","270a665e":"markdown","2e0a812c":"markdown","f2b583ff":"markdown","222927de":"markdown","e806466c":"markdown","1b0a07b0":"markdown","90b151f7":"markdown"},"source":{"40136347":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport plotly.express as px \nfrom warnings import filterwarnings as filt\nfrom scipy.stats import skew, norm \n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12, 6)\nfilt('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98d9015f":"base_path = '\/kaggle\/input\/fashionmnist\/fashion-mnist_'","a3418609":"traindf = pd.read_csv(f'{base_path}train.csv')\ntestdf = pd.read_csv(f'{base_path}test.csv')\n\nprint(traindf.shape)\nprint(testdf.shape)","48f37e14":"traindf.head()","fde4d524":"traindf.label.unique()","f2ff5d0e":"to_replace = {\n    0 : 0,\n    1 : 1,\n    2 : 2,\n    3 : 3,\n    4 : 4,\n    5 : 5,\n    6 : 0,\n    7 : 6,\n    8 : 7,\n    9 : 8 \n}\n\ntraindf['label'] = traindf.label.replace(to_replace)\ntestdf['label'] = testdf.label.replace(to_replace)","d2198d38":"label_names = {\n    0 :\"Top\",\n    1 :\"Trouser\",\n    2 :\"Pullover\",\n    3 :\"Dress\",\n    4 :\"Coat\",\n    5 :\"Sandal\",\n    #     6 :\"Shirt\",\n    6 :\"Sneaker\",\n    7 :\"Bag\",\n    8 :'Ankle boot',\n}","16189b1e":"df = traindf.copy()\ndf['label'] = df.label.replace(label_names)\ndef show_img(idx, df):\n    x = df.iloc[idx]\n    target = x.label\n    pxs = x[1:].values.reshape(28, 28).astype(float)\n    plt.imshow(pxs)\n    plt.title(target)\n    plt.colorbar()\n    plt.axis('off')","76a125dc":"st = 150\nfor i in range(st, st + 5):\n    plt.figure(i)\n    show_img(i, df)","670ab0d1":"sns.countplot(df.label)","a520427c":"from sklearn.model_selection import train_test_split","9931b15c":"from sklearn.manifold import TSNE\n\ndef sample(x, y, frac):\n    x, xt, y, yt = train_test_split(x, y, train_size = frac, stratify = y)\n    return x, y\n\n\ndef tsne_plot(x, y, params = {'n_components' : 3}, frac = 1):\n    x, y = sample(x, y, frac)\n    print(f'sample about {x.shape[0]} rows of images')\n    tsne = TSNE(**params, verbose = 1 )\n    xtsne = pd.DataFrame(tsne.fit_transform(x), index = x.index, columns = ['x', 'y', 'z'])\n    xtsne['target'] = y\n    return px.scatter_3d(data_frame = xtsne, x = 'x', y = 'y', z = 'z', title = 'fashion mnist scatter plot', color = 'target')","6a083706":"x = df.drop(['label'], axis = 1)\ny = df.label\nparams = {\n    'n_components' : 3,\n    'n_iter' : 1500\n}\nx.shape[0] * 0.125","e9576296":"tsne_plot(x, y, params, frac = 0.12)","0d3332cf":"import tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical, plot_model ","49715371":"x.shape[0] * 0.15","039a0b7f":"xt = traindf.drop(['label'], axis = 1) \/ 255.0\nyt = traindf.label\nnum_classes = yt.unique().shape[0]\nyt = to_categorical(yt, num_classes)\n\nx_train, x_dev, y_train, y_dev = train_test_split(xt, yt, test_size = .15, stratify = yt, random_state = 123)\nx_test = testdf.drop(['label'], axis = 1) \/ 255.0\ny_test = testdf.label\ny_test = to_categorical(y_test, num_classes)\n\nprint(f'x train :==> {x_train.shape}')\nprint(f'y train :==> {y_train.shape}')\nprint(f'x dev   :==> {x_dev.shape}')\nprint(f'y dev   :==> {y_dev.shape}')","1c15cb28":"x_dev.describe()","621b9ab4":"sns.countplot(np.argmax(y_train, axis = 1))\nplt.title('target label counts for training');","0932be40":"sns.countplot(np.argmax(y_dev, axis = 1))\nplt.title('target label counts for dev');","95f8f791":"sns.countplot(np.argmax(y_test, axis = 1))\nplt.title('target label counts for test');","93b956d3":"from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import Sequential\nimport tensorflow.keras as keras \nimport tensorflow as tf\n\nmetrics = tf.keras.metrics","449bdb26":"128 * 2","48b0ccd8":"model = Sequential([\n    # input layer     \n    Input(shape = (28 * 28, ), name = 'input_layer'),\n    \n    # hidden layer 1     \n    Dense(128, activation = 'relu', name = 'hidden_layer_1'),\n    #     Dropout(0.3),\n    \n    # hidden layer 2\n    Dense(32,  activation = 'relu', name = 'hidden_layer_2'),\n    Dropout(0.15),\n    \n    # hidden layer 3\n    Dense(32,  activation = 'relu', name = 'hidden_layer_3'),\n    Dropout(0.15),\n    \n    # output layer\n    Dense(10,  activation = 'softmax', name = 'output_layer')\n])\n\nmodel","0bac9b85":"plot_model(model, show_layer_names = True, show_shapes = True)","85eb3e91":"model.compile(\n    optimizer = SGD(learning_rate = 0.01),\n    loss = keras.losses.CategoricalCrossentropy(),\n    metrics = ['accuracy', metrics.Precision(), metrics.Recall()]\n)","22c3da8a":"128 *2","121a2732":"history = model.fit(\n    x = x_train,\n    y = y_train,\n    batch_size = 64,\n    epochs = 18,\n    validation_data = (x_dev, y_dev),\n)","05eb793c":"his = pd.DataFrame(history.history)\nhis.head()","3ecf42cb":"plt.plot(his.loss)\nplt.plot(his.val_loss)\nplt.legend(['training loss', 'validation loss'])\nplt.title('training and validation loss')","93c07a69":"plt.plot(his.accuracy)\nplt.plot(his.val_accuracy)\nplt.legend(['training accuracy', 'validation accuracy'])\nplt.title('training and validation accuracy')","10136646":"plt.plot(his.precision_6)\nplt.plot(his.val_precision_6)\nplt.legend(['training precision', 'validation precision'])\nplt.title('training and validation precision')","69d6b802":"plt.plot(his.recall_6)\nplt.plot(his.val_recall_6)\nplt.legend(['training recall', 'validation recall'])\nplt.title('training and validation recall')","e1c31364":"from sklearn.metrics import classification_report, confusion_matrix\n\npred = np.argmax(model.predict(x_test), axis = 1)\ny_true = np.argmax(y_test, axis = 1)","51cd19b3":"print(classification_report(y_true, pred))","6088915a":"sns.heatmap(confusion_matrix(y_true, pred), fmt = '.1f', annot = True)","b4647996":"128 * 2","27d4165f":"model2 = Sequential([\n    # input layer     \n    Input(shape = (28 * 28, ), name = 'input_layer'),\n    \n    # hidden layer 1     \n    Dense(512, activation = 'tanh', name = 'hidden_layer_1'),\n    #  Dropout(0.3),\n    \n    # hidden layer 2\n    Dense(256,  activation = 'tanh', name = 'hidden_layer_2'),\n    #     Dropout(0.2),\n    \n    # hidden layer 3\n    Dense(128,  activation = 'tanh', name = 'hidden_layer_3'),\n    #     Dropout(0.15),\n    \n    # output layer\n    Dense(9,  activation = 'softmax', name = 'output_layer')\n])\n\nmodel","aca326c2":"model2.compile(\n    optimizer = SGD(learning_rate = 0.01),\n    loss = keras.losses.CategoricalCrossentropy(),\n    metrics = ['accuracy', metrics.Precision(), metrics.Recall()]\n)","9c3925b5":"history2 = model2.fit(\n    x = x_train,\n    y = y_train,\n#     batch_size = 64,\n    epochs = 30,\n    validation_data = (x_dev, y_dev),\n)","0286c2f6":"his2 = pd.DataFrame(history.history)\nhis2.head()","a74448ea":"plt.plot(his2.loss)\nplt.plot(his2.val_loss)\nplt.legend(['training loss', 'validation loss'])\nplt.title('training and validation loss')","f3623810":"plt.plot(his2.accuracy)\nplt.plot(his2.val_accuracy)\nplt.legend(['training accuracy', 'validation accuracy'])\nplt.title('training and validation accuracy')","e0f3244d":"pred = np.argmax(model2.predict(x_test), axis = 1)\ny_true = np.argmax(y_test, axis = 1)","27f5b3ef":"print(classification_report(y_true, pred))\nsns.heatmap(confusion_matrix(y_true, pred), fmt = '.1f', annot = True)","73c5c41d":"from sklearn.base import BaseEstimator\n\nclass AutoEncoder(BaseEstimator):\n    def __init__(self, layers, bottleneck_unit = 10, compiler_params = {}):\n        self.layers = layers\n        self.compiler_params = compiler_params\n        self.model = None\n        self.bottleneck_unit = bottleneck_unit\n        self.initialize_layers()\n        self.loss = None\n        \n    def initialize_layers(self):\n        self.model = Sequential()\n        \n        # Encoder layer         \n        self.model.add(Input(shape = (self.layers[0],), name = 'Input_Layer'))\n        for ind, units in enumerate(self.layers[1:]):  \n            self.model.add(Dense(units, activation = 'relu', name = f'Encoder_Layer_{ind + 1}'))\n        \n        # bottle-neck layer\n        self.model.add(Dense(self.bottleneck_unit, activation = 'sigmoid', name = 'Latent_Space'))\n        \n        # Decoder layer\n        for ind, units in enumerate(reversed(self.layers)):  \n            self.model.add(Dense(units, activation = 'relu', name = f'Decoder_Layer_{ind + 1}'))\n            \n        self.model.compile(**self.compiler_params)\n        \n        return self\n        \n    def fit(self, fit_params : dict):\n        history = self.model.fit(**fit_params)\n        self.loss = history.history\n        return \n    \n    def predict(self, pred_params : dict):\n        return self.model.predict(**pred_params)\n    \n    def plot_arch(self):\n        if self.model:\n            return plot_model(self.model, \n                       show_layer_names = True, \n                       show_shapes = True, \n                )","d2096ff2":"28 * 28","6b097a92":"from keras.callbacks import EarlyStopping\n\nlayers = [784, 700, 350, 174]\n\ncompiler_params = {\n    'optimizer' : Adam(),\n    'loss' : 'mse'\n}\n\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n\nfit_params = {\n    'x' : x_train,\n    'y' : x_train,\n    \"batch_size\" : 128,\n    'epochs' : 20,\n    'validation_data' : (x_dev, x_dev),\n    'callbacks' : [early_stopping]\n}\n\npred_params = {\n    'x' : x_test\n}","b860ce00":"autoencoder = AutoEncoder(layers = layers, compiler_params = compiler_params)\nautoencoder.plot_arch()","949cd361":"autoencoder.fit(fit_params)","d81880ad":"pd.DataFrame(autoencoder.loss).plot(kind = 'line')\nplt.title('reconstruction error');","cdd366c5":"for i in range(5):\n    plt.figure(i)\n    show_img(i, testdf)","f244bad8":"denoised = autoencoder.predict({'x': x_test}) \ndenoised = denoised.reshape(-1, 28, 28)","4017a84b":"for ind, img in enumerate(denoised[:5]):\n    plt.figure(ind)\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')","6d36cd34":"new_x_train = autoencoder.predict({'x' : x_train})\nnew_x_dev = autoencoder.predict({'x' : x_dev})","f5720e3c":"plot_model(model)","f54fd6f6":"new_x_train.shape","d8f191c8":"history = model.fit(\n    x = new_x_train, \n    y = y_train,\n    batch_size = 128,\n    epochs = 50,\n    validation_data = (new_x_dev, y_dev)\n)","48c3e1b0":"his2 = pd.DataFrame(history.history)\nplt.plot(his2.loss)\nplt.plot(his2.val_loss)\nplt.legend(['training loss', 'validation loss'])\nplt.title('training and validation loss')","05f6eea6":"plt.plot(his2.accuracy)\nplt.plot(his2.val_accuracy)\nplt.legend(['training accuracy', 'validation accuracy'])\nplt.title('training and validation accuracy')","a2b0cbe7":"images before denoising","e3c6db02":"we'll use the same model we used before denoising ","15d2ad7d":"#### model 2 ","270a665e":"something interesting here is one pixle is 0 for all the above shirts in the shoulder part ","2e0a812c":"* we got the accuracy of around 91% in the testing dataset\n* in order to increase the accuracy more we can also rename coat, pullover and classify them as Top\n* now lets try to denoise the imgs using autoencoder(vanilla) ( practicing ) ","f2b583ff":"we can see that similar types of accessories are clustered together ","222927de":"#### Network Architecture ","e806466c":"looks like this wasnt a good idea but still it was pretty good learning about autoencoders","1b0a07b0":"#### After training and validation i found that there was no much difference between T-shirt and shirt so its better to merge them both and classify as 'Top'","90b151f7":"images after denoising "}}