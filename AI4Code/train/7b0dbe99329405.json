{"cell_type":{"42617e84":"code","f6ebe696":"code","9ed161f5":"code","176dff07":"code","59d375a4":"code","0a21dccb":"code","4a3876a6":"code","507fffdc":"code","78deaa7d":"code","7c2dc91d":"code","c202126f":"code","862d67a3":"code","f0bd7013":"code","a4d915e6":"code","1ddba337":"code","ebba2db1":"code","1ad6b717":"code","e1c51107":"code","3ffca309":"code","53a91aaa":"code","9bc52ddd":"code","ef913f2e":"code","201b0bf0":"code","cb4c2d5e":"code","c4b84ee9":"code","1df2e914":"code","21b9c8e0":"code","fee5669c":"code","ad810b34":"code","965c98a0":"code","04fe9b79":"code","0ea6f477":"code","3ec122ab":"code","6ff7b7fa":"code","fdf81966":"code","ea07fdd3":"code","557ad4b6":"code","c61bf637":"code","54dd9570":"code","5bbc63a5":"code","e5db1fb5":"code","71fc776e":"code","25e237a4":"code","5ec6bdbd":"code","58e9d506":"code","b052f907":"code","0a6132b7":"code","2c71a09d":"code","05956b9c":"code","89ffe620":"code","be394155":"code","5506fe3a":"code","0aa5d4eb":"code","b5a436d0":"code","431b58d5":"code","1b373119":"code","3c76612c":"code","5423338e":"code","2ff4d385":"markdown","5db9938e":"markdown","54be5850":"markdown","2fdfaf57":"markdown","e113627c":"markdown","b89fb494":"markdown","abe659fc":"markdown","d57384ef":"markdown","6973ee05":"markdown","47831dcb":"markdown","feee9bac":"markdown","8e1ba7a3":"markdown","2e176552":"markdown","ebfcd741":"markdown","7100b45f":"markdown","fa22bd1a":"markdown","6216056a":"markdown","1164d842":"markdown","8ce5541b":"markdown","131a7db3":"markdown"},"source":{"42617e84":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f6ebe696":"# reading train data\ntrain=pd.read_csv('..\/input\/titanic\/train.csv')\n\n# reading test data\ntest=pd.read_csv('..\/input\/titanic\/test.csv') ","9ed161f5":"# printing first five rows of the data set\ntrain.head()","176dff07":"# number of rows and columns\ntrain.shape ","59d375a4":"# column names\ntrain.columns ","0a21dccb":"# number of null values in dataset\ntrain.isnull().sum() ","4a3876a6":"train['Sex'].value_counts()","507fffdc":"# countplot\nsns.countplot(x='Sex', data=train)","78deaa7d":"train['Pclass'].value_counts()","7c2dc91d":"sns.countplot(x='Pclass', data=train)","c202126f":"train['Embarked'].value_counts()","862d67a3":"sns.countplot(x='Embarked', data=train)","f0bd7013":"train['SibSp'].value_counts()","a4d915e6":"sns.countplot(x='SibSp', data=train)","1ddba337":"# new feature\ntrain['Died'] = 1 - train['Survived']","ebba2db1":"train.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar',\n                                                           figsize=(10, 5),\n                                                           stacked=True)","1ad6b717":"train.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar',\n                                                            figsize=(10, 5),\n                                                            stacked=True)","e1c51107":"figure = plt.figure(figsize=(16, 7))\nplt.hist([train[train['Survived'] == 1]['Fare'], train[train['Survived'] == 0]['Fare']], \n         stacked=True, bins = 50, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend()","3ffca309":"titles = set()\nfor name in train['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","53a91aaa":"Title_Dictionary = {\"Capt\": \"Officer\",\"Col\": \"Officer\",\"Major\": \"Officer\",\"Jonkheer\": \"Royalty\",\"Don\": \"Royalty\",\"Sir\" : \"Royalty\",\"Dr\": \"Officer\",\"Rev\": \"Officer\",\"the Countess\":\"Royalty\",\"Mme\": \"Mrs\",\"Mlle\": \"Miss\",\"Ms\": \"Mrs\",\"Mr\" : \"Mr\",\"Mrs\" : \"Mrs\",\"Miss\" : \"Miss\",\"Master\" : \"Master\",\"Lady\" : \"Royalty\"}","9bc52ddd":"train['Title'] = train['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ntrain['Title'] = train.Title.map(Title_Dictionary)\ntrain.head()","ef913f2e":"# dropping umwanted columns\ndf1=train.drop(['Name','Ticket','Cabin','PassengerId','Died'], axis=1)\ndf1.head()","201b0bf0":"train.Title.value_counts()","cb4c2d5e":"# Converting categorical feature to numeric\ndf1.Sex=df1.Sex.map({'female':0, 'male':1})\ndf1.Embarked=df1.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'NaN'})\ndf1.Title=df1.Title.map({'Mr':0, 'Miss':1, 'Mrs':2,'Master':3,'Officer':4,'Royalty':5})\ndf1.head()","c4b84ee9":"# median age of each sex\nmedian_age_men=df1[df1['Sex']==1]['Age'].median()\nmedian_age_women=df1[df1['Sex']==0]['Age'].median()","1df2e914":"# filling null values in 'Age' with respective median age\ndf1.loc[(df1.Age.isnull()) & (df1['Sex']==0),'Age']=median_age_women\ndf1.loc[(df1.Age.isnull()) & (df1['Sex']==1),'Age']=median_age_men","21b9c8e0":"# checking for null values\ndf1.isnull().sum()","fee5669c":"# dropping rows with null value\ndf1.dropna(inplace=True)","ad810b34":"# Data is cleaned to have no null value\ndf1.isnull().sum()","965c98a0":"# cleaned dataset\ndf1.head()","04fe9b79":"df1.Age = (df1.Age-min(df1.Age))\/(max(df1.Age)-min(df1.Age))\ndf1.Fare = (df1.Fare-min(df1.Fare))\/(max(df1.Fare)-min(df1.Fare))","0ea6f477":"df1.describe()","3ec122ab":"from sklearn.model_selection import train_test_split","6ff7b7fa":"X_train, X_test, y_train, y_test = train_test_split(\n    df1.drop(['Survived'], axis=1),\n    df1.Survived,\n    test_size= 0.2,\n    random_state=0,\n    stratify=df1.Survived\n)","fdf81966":"# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\nfrom sklearn.metrics import accuracy_score\n\nY_pred = clf.predict(X_test)\naccuracy_score(y_test, Y_pred)","ea07fdd3":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test, Y_pred)\ncm","557ad4b6":"sns.heatmap(cm,annot=True)","c61bf637":"# test dataset\ntest.head()","54dd9570":"titles = set()\nfor name in test['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","5bbc63a5":"test['Title'] = test['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ntest['Title'] = test.Title.map(Title_Dictionary)\ntest.head()","e5db1fb5":"# dropping unwanted columns\ndf2=test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)","71fc776e":"# Converting categorical feature to numeric\ndf2.Sex=df2.Sex.map({'female':0, 'male':1})\ndf2.Embarked=df2.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'nan'})\ndf2.Title=df2.Title.map({'Mr':0, 'Miss':1, 'Mrs':2,'Master':3,'Officer':4,'Royalty':5})\ndf2.head()","25e237a4":"# Checking for null values\ndf2.isnull().sum()","5ec6bdbd":"# median age of each sex\nmedian_age_men2=df2[df2['Sex']==1]['Age'].median()\nmedian_age_women2=df2[df2['Sex']==0]['Age'].median()","58e9d506":"# filling null values with respective median age\ndf2.loc[(df2.Age.isnull()) & (df2['Sex']==0),'Age']=median_age_women2\ndf2.loc[(df2.Age.isnull()) & (df2['Sex']==1),'Age']=median_age_men2","b052f907":"# filling null values with median fare\ndf2['Fare']=df2['Fare'].fillna(df2['Fare'].median())","0a6132b7":"df2.isnull().sum()","2c71a09d":"# Null value in the title column\ndf2[df2.Title.isnull()]","05956b9c":"df2=df2.fillna(2)","89ffe620":"# Data is cleaned to have no null value\ndf2.isnull().sum()","be394155":"# cleaned dataset\ndf2.head()","5506fe3a":"# feature scaling\ndf2.Age = (df2.Age-min(df2.Age))\/(max(df2.Age)-min(df2.Age))\ndf2.Fare = (df2.Fare-min(df2.Fare))\/(max(df2.Fare)-min(df2.Fare))","0aa5d4eb":"# test dataset\ndf2.head()","b5a436d0":"pred = clf.predict(df2)","431b58d5":"pred","1b373119":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": pred\n    })\nsubmission.to_csv('submission.csv', index=False)","3c76612c":"pred_df = pd.read_csv('submission.csv')","5423338e":"# visualizing predicted values\nsns.countplot(x='Survived', data=pred_df)","2ff4d385":"- **Logistic Regression**","5db9938e":"## Prediction","54be5850":"Passengers with cheaper ticket fares are more likely to die. Put differently, passengers with more expensive tickets, and therefore a more important social status, seem to be rescued first.","2fdfaf57":"## Cleaning test dataset","e113627c":"Two null values in Embarked column","b89fb494":"## Exploratory Data Analysis","abe659fc":"## Feature Engineering","d57384ef":"Different titles in the train set are:","6973ee05":"Since the person is a woman with age 39, filling the title with 2 (mapped value for the title 'Mrs')","47831dcb":"## Data Modelling","feee9bac":"Plotting the same graph but with ratio instead.","8e1ba7a3":"## Confusion Matrix","2e176552":"**The Titanic challenge** on Kaggle is a competition in which the task is to predict the survival or the death of a given passenger based on a set of variables describing him such as his age, his sex, or his passenger class on the boat. \n\nI have recently achieved an accuracy score of **0.78708** on the public leaderboard. I have used **Logistic regression** for prediction. As I'm writing this post, I am ranked among the **top 9%** of all Kagglers.","ebfcd741":"## Introduction","7100b45f":"## Feature Scaling","fa22bd1a":"Now, visualizing survival based on the fare.","6216056a":"## Importing libraries","1164d842":"Visualizing survival based on the gender.","8ce5541b":"The Sex variable seems to be a discriminative feature. Women are more likely to survive.","131a7db3":"## Cleaning the  train dataset"}}