{"cell_type":{"9a175b9c":"code","f8725efd":"code","eac63bc0":"code","decb8e4b":"code","79b5d509":"code","371d9afb":"code","9eb07db3":"code","e131e23c":"code","7c0aa15f":"code","e1f5e47d":"code","3e24c265":"code","4ba9a720":"code","c32ec501":"code","5d239e54":"code","5f62ee99":"code","591f0ebb":"code","60a49325":"code","070ac78b":"code","5471c9a5":"code","a92fa568":"code","bdcf768b":"code","1ad84534":"code","f179894b":"code","bea822fe":"code","5ebeb278":"code","0503f34b":"code","c7bacab3":"code","68c4b0fb":"code","83e78153":"markdown","3526cae9":"markdown","3c9287c5":"markdown","6bf93f58":"markdown","6f77e35a":"markdown","d7cf95ab":"markdown","2b131e41":"markdown","921bc2a8":"markdown","11c3fdcc":"markdown","5ed2a199":"markdown","611a3907":"markdown"},"source":{"9a175b9c":"#Improt all the needed pacakges\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n","f8725efd":"import numpy as np\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()","eac63bc0":"market_train_df.info()","decb8e4b":"news_train_df.info()","79b5d509":"print(market_train_df.time.min())\nmarket_train_df_5years=market_train_df[market_train_df.time>'2011-12-30 22:00:00+0000']\n","371d9afb":"market_train_df_5years.to_csv(\"market_2011_2016.csv\",index=False)","9eb07db3":"import os\nprint(os.listdir(\"..\/input\"))","e131e23c":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inlinemarket_train_df.info()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","7c0aa15f":"#Deal with the missing number,fill the missing values as mean values,\nmissing_cols=['returnsClosePrevMktres1',\n              'returnsOpenPrevMktres1',\n              'returnsClosePrevMktres10',\n              'returnsOpenPrevMktres10']\n\nfor col in missing_cols:\n    market_train_df[col]=market_train_df[col].fillna(market_train_df[col].mean())","e1f5e47d":"import datetimeprint(f'The market data start from {market_train_df[\"time\"].min()}, and end on {market_train_df[\"time\"].max()}')","3e24c265":"#Explore the data related to returns.\n#data = []\nreturn_terms=[\n             \"returnsClosePrevRaw1\",\n             \"returnsOpenPrevRaw1\",\n             \"returnsClosePrevMktres1\",\n             \"returnsOpenPrevMktres1\",\n             \"returnsClosePrevRaw10\",\n             \"returnsOpenPrevRaw10\",\n             \"returnsClosePrevMktres10\",\n             \"returnsOpenPrevMktres10\",\n             \"returnsOpenNextMktres10\"\n             ] \nfor  return_term in return_terms:\n    market_train_df[return_term]=market_train_df[return_term].clip(-1,1)\n","4ba9a720":"print(f'The news data start from {news_train_df[\"time\"].min()}, and end on {news_train_df[\"time\"].max()}')\n","c32ec501":"headlineTag_dic = {k: v for v, k in enumerate(news_train_df['headlineTag'].unique())}\nprovider_dic = {k: v for v, k in enumerate(news_train_df['provider'].unique())}\nmarketCommentary_map = {False:0,True:1}\nnews_drop_col=['time','sourceTimestamp','assetName','headline','subjects','audiences']\n#news_train_df=news_train_df.sample(6000000)","5d239e54":"import numpy as np\nimport pandas as pd\n#This function expands a row in to multiple rows from the list of assetcodes.\ndef expand(df, expand_column):\n    lens = []\n    d = {}\n    expands_list=[]\n    for i,item in df[expand_column].items():\n        expand=list(item[2:-2].split(\"\\', \\'\"))\n        lens.append(len(expand))\n        expands_list.extend(expand)        \n    d[expand_column] = expands_list\n    \n    #print(len(d[expand_column]))\n    #print(np.mean(lens))\n    for col in df.columns.values:\n        if col != expand_column:\n             d[col] = np.repeat(df[col].values, lens)\n    return pd.DataFrame(d)\n","5f62ee99":"def prep_market(market_df):    \n    #print(\"Deal with the market data\")\n    market_df=market_df.drop(['assetName'],axis=1)\n    market_df[\"time\"]=pd.to_datetime(market_df[\"time\"])\n    market_df['time'] = market_df.time.dt.date\n    market_df['close_to_open'] = market_df['close'] \/ market_df['open'] \n    #print(f'The shape of market data is {market_df.shape}')\n    return market_df\n    \ndef prep_news(news_df):    \n    #print(\"Deal with the news data\")    \n    news_df['firstCreated']=pd.to_datetime(news_df['firstCreated'])\n    news_df=news_df.drop(news_drop_col,axis=1)\n    news_df['headlineTagT'] = news_df['headlineTag'].map(headlineTag_dic)    \n    news_df['provider'] = news_df['provider'].map(provider_dic)    \n    news_df['marketCommentary'] = news_df['marketCommentary'].map(marketCommentary_map)\n    #print('expand')\n    news_df=expand(news_df, \"assetCodes\")\n    #print('group')\n    #news_df = news_df.groupby(['firstCreated', 'assetCodes'], as_index=False).mean()\n    #print(f'The shape of news data is {news_df.shape}')\n    return news_df\n\ndef group_news(news_df):\n    #print('group')\n    news_df['firstCreated']=news_df['firstCreated'].dt.date\n    news_df = news_df.groupby(['firstCreated', 'assetCodes'], as_index=False).mean()\n    return news_df\n\ndef merge_market_news(market_df,news_df):    \n    market_and_news_df = pd.merge(market_df, news_df, left_on=['time', 'assetCode'], right_on=['firstCreated', 'assetCodes'])   \n    return market_and_news_df","591f0ebb":"\nnews_train_df=prep_news(news_train_df)\nnews1=news_train_df[news_train_df['firstCreated']<=\"2009-12-31\"]\nnews2=news_train_df[(news_train_df['firstCreated']<=\"2012-12-31\")&(news_train_df['firstCreated']>\"2009-12-31\")]\nnews3=news_train_df[news_train_df['firstCreated']>\"2012-12-31\"]\ndel(news_train_df)\nnews1=group_news(news1)\nnews2=group_news(news2)\nnews3=group_news(news3)\nnews_train_df=pd.concat([news1,news2,news3],sort='False')\n","60a49325":"market_train_df=prep_market(market_train_df)\nmarket_news_train_df = merge_market_news(market_train_df, news_train_df)\n","070ac78b":"features_col=['volume', 'close', 'open', 'returnsClosePrevRaw1','returnsOpenPrevRaw1', \n              'returnsClosePrevMktres1','returnsOpenPrevMktres1', 'returnsClosePrevRaw10',\n              'returnsOpenPrevRaw10', 'returnsClosePrevMktres10','returnsOpenPrevMktres10', \n              'close_to_open', 'urgency', 'takeSequence', 'provider',\n              'bodySize', 'companyCount', 'marketCommentary', 'sentenceCount','wordCount', \n              'firstMentionSentence', 'relevance', 'sentimentClass','sentimentNegative', \n              'sentimentNeutral', 'sentimentPositive','sentimentWordCount', 'noveltyCount12H', \n              'noveltyCount24H','noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n              'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D','headlineTagT']\n\nfeatures_col_market=['volume', 'close', 'open', 'returnsClosePrevRaw1','returnsOpenPrevRaw1', \n                     'returnsClosePrevMktres1','returnsOpenPrevMktres1', 'returnsClosePrevRaw10',\n                     'returnsOpenPrevRaw10', 'returnsClosePrevMktres10','returnsOpenPrevMktres10', 'close_to_open']","5471c9a5":"UpOrDown = market_news_train_df.returnsOpenNextMktres10 >= 0\nUpOrDown = UpOrDown.values\nreturns = market_news_train_df.returnsOpenNextMktres10.values\nX=market_news_train_df[features_col].values\nmins_X = np.min(X, axis=0)\nmaxs_X = np.max(X, axis=0)\nrange_X = maxs_X - mins_X\nX = 1 - ((maxs_X - X) \/ range_X)\n","a92fa568":"UpOrDown_market = market_train_df.returnsOpenNextMktres10 >= 0\nUpOrDown_market = UpOrDown_market.values\nreturns_market = market_train_df.returnsOpenNextMktres10.values\nX_market=market_train_df[features_col_market].values\nmins_X_market = np.min(X_market, axis=0)\nmaxs_X_market = np.max(X_market, axis=0)\nrange_X_market = maxs_X_market - mins_X_market\nX_market = 1 - ((maxs_X_market - X_market) \/ range_X_market)\n\n","bdcf768b":"import lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, UpOrDown_train, UpOrDown_test, returns_train, returns_test = model_selection.train_test_split(X, UpOrDown, returns, test_size=0.1, random_state=99)","1ad84534":"params = {'learning_rate': 0.05, 'max_depth': 5, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel = lgb.train(params, train_set=lgb.Dataset(X_train, label=UpOrDown_train), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train, label=UpOrDown_train), lgb.Dataset(X_test, label=UpOrDown_test)],\n                  verbose_eval=50, early_stopping_rounds=30)\n","f179894b":"X_train_market, X_test_market, UpOrDown_train_market, UpOrDown_test_market, returns_train_market, returns_test_market = model_selection.train_test_split(X_market, UpOrDown_market, returns_market, test_size=0.1, random_state=99)\n\nparams = {'learning_rate': 0.05, 'max_depth': 5, 'boosting': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'is_training_metric': True, 'seed': 42}\nmodel_market = lgb.train(params, train_set=lgb.Dataset(X_train_market, label=UpOrDown_train_market), num_boost_round=2000,\n                  valid_sets=[lgb.Dataset(X_train_market, label=UpOrDown_train_market), lgb.Dataset(X_test_market, label=UpOrDown_test_market)],\n                  verbose_eval=50, early_stopping_rounds=30)","bea822fe":"df = pd.DataFrame({'imp': model.feature_importance(), 'col':features_col})\ndf = df.sort_values(['imp','col'], ascending=[True, False])\ndf.plot.bar(x='col',y='imp')","5ebeb278":"df_market = pd.DataFrame({'imp': model_market.feature_importance(), 'col':features_col_market})\ndf_market = df_market.sort_values(['imp','col'], ascending=[True, False])\ndf_market.plot.bar(x='col',y='imp')","0503f34b":"#Predect only use market data\n'''\ndays = env.get_prediction_days()\nimport time\nn_days = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')    \n    market_obs_df=prep_market(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live_market=market_obs_df[features_col_market].values\n    X_live_market=1-((maxs_X_market - X_live_market) \/ range_X_market)\n    lp_market = model_market.predict(X_live_market)\n    confidence_market = 2 * lp_market -1\n    preds_market= pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence_market})\n    predictions_template_df = predictions_template_df.merge(preds_market,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n\nenv.write_submission_file()\n'''","c7bacab3":"\ndays = env.get_prediction_days()\nimport time\n\nn_days = 0\n\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    market_obs_df=prep_market(market_obs_df)\n\n    news_obs_df=prep_news(news_obs_df)\n    news_obs_df=group_news(news_obs_df)\n    market_news_obs_df = merge_market_news(market_obs_df, news_obs_df)\n    assetcode_set=set(market_news_obs_df['assetCode'].values)\n    X_live = market_news_obs_df[features_col].values\n    X_live = 1 - ((maxs_X - X_live) \/ range_X)        \n    lp = model.predict(X_live)\n    confidence = 2 * lp -1\n    preds = pd.DataFrame({'assetCode':market_news_obs_df['assetCode'],'confidence':confidence})\n    \n    market_only_obs_df=market_obs_df[~market_obs_df['assetCode'].isin(assetcode_set)]\n    X_live_market_only=market_only_obs_df[features_col_market].values\n    X_live_market_only=1-((maxs_X_market - X_live_market_only) \/ range_X_market)\n    lp_market_only = model_market.predict(X_live_market_only)\n    confidence_market_only = 2 * lp_market_only -1\n    preds_market_only= pd.DataFrame({'assetCode':market_only_obs_df['assetCode'],'confidence':confidence_market_only})\n    \n    preds_all=pd.concat([preds,preds_market_only],sort='False')\n    \n    predictions_template_df = predictions_template_df.merge(preds_all,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    \nenv.write_submission_file()","68c4b0fb":"# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('.') if '.csv' in filename])\n\n","83e78153":"There are 9328750 rows with 35 features in the news train set.","3526cae9":"**2.1  Feature engineering**","3c9287c5":"## 2. Build a model without the content of the news as the baseline. ","6bf93f58":"Check with the missing values. There are 4 features with missing values.","6f77e35a":"Find if there are any missing value in news_train_df. We are lucky that no missing value is found in news trainning data.","d7cf95ab":"**2.3  Buiding estimator with market and news data**","2b131e41":"**2.2  Traning and testing date splitting**","921bc2a8":"## 2. Load and explore the data \nFirst let's import the module and create an environment. According to the compition rules we must use custom kaggle.competitions.twosigmerfanews Python module to import the market and news data.","11c3fdcc":"**2.3  Buiding estimator with only market data **","5ed2a199":"# Using Market State and Financial News to Predict Stocks Movement\n## 1.  Introduction\nIn this [kaggle competition](https:\/\/www.kaggle.com\/c\/two-sigma-financial-news) we will predict how stocks will change based on the market state and news articles.  We will loop through a long series of trading days; for each day, we'll receive an updated state of the market, and a series of news articles which were published since the last trading day, along with impacted stocks and sentiment analysis.  We'll use this information to predict whether each stock will have increased or decreased ten trading days into the future.  \n\n**Evaluation details**: we must predict a signed confidence value,$\\hat{y}_{ti} \\in [-1,1]$, which is multiplied by the market-adjusted return of a given assetCode over a ten day window. If we expect a stock to have a large positive return--compared to the broad market--over the next ten days, we might assign it a large, positive confidenceValue (near 1.0). If we expect a stock to have a negative return, you might assign it a large, negative confidenceValue (near -1.0). If unsure, you might assign it a value near zero.\n\n$$x_t = \\sum_i \\hat{y}_{ti}  r_{ti}  u_{ti},$$\n\nwhere $r_{ti}$ is the 10-day market-adjusted leading return for day t for instrument i, and $u_{ti}$ is a 0\/1 universe variable that controls whether a particular asset is included in scoring on a particular day.\n\nThe submission score is then calculated as the mean divided by the standard deviation of your daily xt values:\n$$\\text{score} = \\frac{\\bar{x}_t}{\\sigma(x_t)}.$$\nIf the standard deviation of predictions is 0, the score is defined as 0.\n\n","611a3907":"## Import and explore the training data\nIn accordance with the competition rule we import the data with the custom module \"twosigmanews\". There are 4,072,956 rows and 16 columns in the maket training set and 9,328,750 rows with 35 columns in the news training set."}}