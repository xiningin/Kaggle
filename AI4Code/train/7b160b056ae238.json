{"cell_type":{"51bfa8fc":"code","fc553879":"code","611e909b":"code","1b12c8d5":"code","a2cb5f19":"code","67089657":"code","d734716a":"code","43dac462":"code","3de056bf":"code","0d9dbe39":"code","457da6a3":"code","9cad8dc3":"code","7fcf8ab2":"code","0e24ada3":"code","94ca2756":"code","e2266f91":"code","25093b48":"code","29e44710":"code","dce8479c":"code","5a259714":"code","362ea336":"code","4b79c572":"code","57d31817":"code","cd96a4de":"code","501f004a":"code","f9155b7a":"code","0f2ada39":"code","67be48d4":"markdown","22efd58e":"markdown","e8b1d102":"markdown","7ea0024f":"markdown"},"source":{"51bfa8fc":"# import os\n# os.listdir('..\/output\/kaggle\/working\/')","fc553879":"# os.listdir('..\/output\/kaggle\/working\/data')","611e909b":"# len(os.listdir('..\/output\/kaggle\/working\/data'))","1b12c8d5":"# os.makedirs('..\/output\/kaggle\/working\/data')\n\n# for x in os.listdir('..\/output\/kaggle\/working\/'):\n#     print(x)","a2cb5f19":"from distutils.dir_util import copy_tree\n\nfrom_directory = '..\/input\/plant-disease\/raw\/color'\nto_directory = '..\/output\/kaggle\/working\/data'\n\ncopy_tree(from_directory, to_directory)","67089657":"# for x in os.listdir('..\/output\/kaggle\/working\/data'):\n#     print(x)","d734716a":"from distutils.dir_util import copy_tree\n\nfrom_directory = '..\/input\/rice-diseases-image-dataset\/LabelledRice\/Labelled'\nto_directory = '..\/output\/kaggle\/working\/data'\n\ncopy_tree(from_directory, to_directory)","43dac462":"# for x in os.listdir('..\/output\/kaggle\/working\/data'):\n#     print(x)","3de056bf":"# len(os.listdir('..\/output\/kaggle\/working\/data'))","0d9dbe39":"from shutil import rmtree","457da6a3":"to_delete = ['..\/output\/kaggle\/working\/data\/Soybean___healthy',\n             '..\/output\/kaggle\/working\/data\/Raspberry___healthy',\n             '..\/output\/kaggle\/working\/data\/Blueberry___healthy',\n             '..\/output\/kaggle\/working\/data\/Orange___Haunglongbing_(Citrus_greening)']\n\nfor directory in to_delete:\n    rmtree(directory)","9cad8dc3":"len(os.listdir('..\/output\/kaggle\/working\/data'))","7fcf8ab2":"import os\nimport time\nimport cv2\nimport glob\nimport matplotlib.pyplot as plt\n","0e24ada3":"print(os.listdir(\"..\/output\/kaggle\/working\/data\/\"))","94ca2756":"import glob\ncountplant = glob.glob('..\/output\/kaggle\/working\/data\/*\/*JPG')\n    \ncountrice = glob.glob('..\/output\/kaggle\/working\/data\/*\/*jpg')\n\nprint(len(countplant), len(countrice))\n","e2266f91":"import pandas as pd\n\nimage_names = glob.glob('..\/output\/kaggle\/working\/data\/*\/*JPG') + glob.glob('..\/output\/kaggle\/working\/data\/*\/*jpg')\nprint(\"Total number of training images: \", len(image_names))\n\n# make train_image_names as serie object\nimage_names = pd.Series(image_names)","25093b48":"# train_df: a dataframe with 2 field: Filename, ClassId\ntrain_df = pd.DataFrame()\n\n# generate Filename field\ntrain_df['Filename'] = image_names.map(lambda img_name: img_name.split(\"\/\")[-1])\n\n# generate ClassId field\ntrain_df['ClassId'] = image_names.map(lambda img_name: img_name.split(\"\/\")[-2])\n\ntrain_df.head()","29e44710":"plot_df = train_df.sample(25).reset_index()\nplt.figure(figsize=(30, 30))\n\n\nfor i in range(25):\n    img_name = plot_df.loc[i, 'Filename']\n    label_str = (plot_df.loc[i, 'ClassId'])\n    plt.subplot(5,5,i+1)\n    plt.imshow(plt.imread(os.path.join('..\/output\/kaggle\/working\/data\/',label_str, img_name)))\n    plt.title(label_str)\n    plt.xticks([])\n    plt.yticks([])","dce8479c":"class_id_distribution = train_df['ClassId'].value_counts()\nclass_id_distribution","5a259714":"import numpy as np\n\nplt.figure(figsize=(20,20))\nplt.barh(class_id_distribution.index, class_id_distribution.values)","362ea336":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n","4b79c572":"num_classes = 25\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nresnet_model = Sequential()\nresnet_model.add(BatchNormalization())\nresnet_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nresnet_model.add(Dense(num_classes, activation='softmax'))\n\n# Indicate whether the first layer should be trained\/changed or not.\nresnet_model.layers[0].trainable = False\n\n# Compile the model\nresnet_model.compile(optimizer='sgd', \n                     loss='categorical_crossentropy', \n                     metrics=['accuracy'])","57d31817":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","cd96a4de":"early_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=3, restore_best_weights=True\n)\n","501f004a":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\ndata_dir = '..\/output\/kaggle\/working\/data'\ndata_generator = ImageDataGenerator(preprocess_input, validation_split=0.2,\n    shear_range=0.2,\n    rotation_range=359,\n    zoom_range=0.5,\n    horizontal_flip =True,\n    vertical_flip = True)\n\ntrain_generator = data_generator.flow_from_directory(\n    directory=data_dir,\n    target_size=(image_size, image_size),\n    batch_size=10,\n    class_mode='categorical',\n    subset='training',\n    seed=42  \n)\n\nvalidation_generator = data_generator.flow_from_directory(\n    directory=data_dir,\n    target_size=(image_size, image_size),\n    class_mode='categorical',\n    subset='validation',\n    seed=42\n)\n\n# fit_stats below saves some statistics describing how model fitting went\n# the key role of the following line is how it changes my_new_model by fitting to data\nfit_stats = resnet_model.fit(train_generator,\n                             validation_data=validation_generator,\n                             validation_steps=1,\n                             epochs=20,\n                             callbacks=[early_stop])","f9155b7a":"acc = fit_stats.history['accuracy']\nval_acc = fit_stats.history['val_accuracy']\n\nloss = fit_stats.history['loss']\nval_loss = fit_stats.history['val_loss']\n\nepochs = 8\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label=\"Training Accuracy\")\nplt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\nplt.legend(loc = \"lower right\")\nplt.title(\"Training and Validation Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, acc, label = \"Training Loss\")\nplt.plot(epochs_range, val_loss, label = \"Validation Loss\")\nplt.legend(loc = \"upper right\")\nplt.title(\"Training and Validation Loss\")\nplt.show()\n\nprint(acc)","0f2ada39":"resnet_model.summary()","67be48d4":"## Don't run the first 6 cells","22efd58e":"# Visualisasi Data","e8b1d102":"# Transfer Learning With Augmentation & BatchNormalization\n**using RestNet50**","7ea0024f":"# Part Coba2 Nurul"}}