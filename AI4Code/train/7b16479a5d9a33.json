{"cell_type":{"a47d2428":"code","dcd0d3ea":"code","0ae8846f":"code","ea6a4174":"code","4bd209ec":"code","49caa3ea":"code","1631b1cd":"code","4ebb262e":"markdown","9084d556":"markdown","f94eaa4a":"markdown","5383449f":"markdown","5066816e":"markdown","4ce4569d":"markdown"},"source":{"a47d2428":"'''Libraries'''\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error,accuracy_score\nfrom xgboost import XGBRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","dcd0d3ea":"'''Data'''\n\n#Sample\nsample = pd.read_csv(\"..\/input\/lish-moa\/sample_submission.csv\")\n\n#Test\ntest_features = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\",index_col='sig_id')\n\n#Train\ntrain_features = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\",index_col='sig_id')\ntrain_nonscore = pd.read_csv(\"..\/input\/lish-moa\/train_targets_nonscored.csv\",index_col='sig_id')\ntrain_score = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\",index_col='sig_id')","0ae8846f":"g_features = [feature for feature in train_features.columns if feature.startswith('g-')]\nc_features = [feature for feature in train_features.columns if feature.startswith('c-')]\nother_features = [feature for feature in train_features.columns if feature not in g_features and feature not in c_features]\n                                                            \n\nprint(f'Number of g- Features: {len(g_features)}')\nprint(f'Number of c- Features: {len(c_features)}')\nprint(f'Number of Other Features: {len(other_features)} ({other_features})')","ea6a4174":"cols = train_score.columns\nsubmission = pd.DataFrame({'sig_id': test_features.index})\ntotal_loss = 0\n\nSEED = 42","4bd209ec":"'''Build Model & Traning'''\n\nfor c, column in enumerate(cols,1):\n    \n    y = train_score[column]\n    \n    # Split\n    X_train_full, X_valid_full, y_train, y_valid = train_test_split(train_features, y, train_size=0.9, test_size=0.1, random_state=SEED)\n    X_train = X_train_full.copy()\n    X_valid = X_valid_full.copy()\n    X_test = test_features.copy()\n\n    # One-hot encode the data (to shorten the code, we use pandas)\n    X_train = pd.get_dummies(X_train)\n    X_test = pd.get_dummies(X_test)\n    X_valid = pd.get_dummies(X_valid)\n    \n    X_train, X_test = X_train.align(X_test, join='left', axis=1)\n    X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n    \n    \n    # Define Regressor Model\n    model = XGBRegressor(\n                         tree_method = 'gpu_hist',\n                         min_child_weight = 31.580,\n                         learning_rate = 0.055,\n                         colsample_bytree = 0.655,\n                         gamma = 3.705,\n                         max_delta_step = 2.080,\n                         max_depth = 25,\n                         n_estimators = 170,\n                         #subsample =  0.864, \n                         subsample =  0.910,\n                         booster='dart',\n                         validate_parameters = True,\n                         grow_policy = 'depthwise',\n                         predictor = 'gpu_predictor'\n                              \n                        )\n                        \n    # Train Model\n    model.fit(X_train, y_train)\n    pred = model.predict(X_valid)\n    \n    # Loss\n    mae = mean_absolute_error(y_valid,pred)\n    mdae = median_absolute_error(y_valid,pred)\n    mse = mean_squared_error(y_valid,pred)\n    \n    total_loss += mae\n    \n    # Prediction\n    predictions = model.predict(X_test)\n    submission[column] = predictions\n    \n    print(\"Regressing through col-\"+str(c)+\", Mean Abs Error: \"+str(mae)+\", Median Abs Error: \"+str(mdae)+\", Mean Sqrd Error: \"+str(mse))\n\n\n","49caa3ea":"print(\"Loss: \", total_loss\/206)","1631b1cd":"# Saving the submission\nsubmission.to_csv('submission.csv', index=False)","4ebb262e":"### [100920] ** Updated Paramater Values **","9084d556":"## Features\n\n* sig_id is the unique sample id\n* Features with g- prefix are gene expression features and there are 772 of them (from g-0 to g-771)\n* Features with c- prefix are cell viability features and there are 100 of them (from c-0 to g-99)\n* cp_type is a binary categorical feature which indicates the samples are treated with a compound or with a control perturbation (trt_cp or ctl_vehicle)\n* cp_time is a categorical feature which indicates the treatment duration (24, 48 or 72 hours)\n* cp_dose is a binary categorical feature which indicates the dose is low or high (D1 or D2)","f94eaa4a":"## Model Building & Training","5383449f":"# Mechanisms of Action Predictions \n\nAs per [National Cancer Institute](https:\/\/www.cancer.gov\/publications\/dictionaries\/cancer-terms\/def\/mechanism-of-action), **Mechanism of Action (MoA)** is a term used to describe how a drug or other substance produces an effect in the body. For example, a drug\u2019s mechanism of action could be how it affects a specific target in a cell, such as an enzyme, or a cell function, such as cell growth. Knowing the mechanism of action of a drug may help provide information about the safety of the drug and how it affects the body. It may also help identify the right dose of a drug and which patients are most likely to respond to treatment. Also called MOA.\n\n\nIn this notebook, we'll predict multiple targets of the **Mechanism of Action (MoA)** responses of different samples. Samples are drugs profiled at different time points and doses. The dataset consists of various group of features and there are more than two hundred targets of enzymes and receptors.\n\nWe'll use XGBoost Regressor with specific parameter values to make our predictions. ","5066816e":"## Libraries","4ce4569d":"## Data"}}