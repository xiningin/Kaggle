{"cell_type":{"a77a46ef":"code","6232016a":"code","d34ca96a":"code","591d0ff0":"code","04c0a041":"code","5334625a":"code","f076f7d3":"code","99e8215b":"code","e60cbf3b":"code","7aa9be03":"code","5c704dbf":"code","3e235bb4":"code","bb19b52d":"code","3f3f5d72":"code","77dceb03":"code","9c7b296f":"code","f73342ca":"code","7f1c6cc9":"code","26e09b51":"code","23dfc978":"code","38a948c3":"code","acae8381":"code","58bef0a8":"code","23f94d59":"code","9a7334ae":"code","abf30c66":"code","9adb6486":"code","86f57af3":"code","9bfcd2d4":"code","a0702ea4":"code","175fba61":"code","0094d3f0":"code","95472982":"code","0ec751f2":"code","08c8b665":"code","2c0da1b5":"code","7372fc7f":"code","8f973dd8":"code","12ec9b2a":"code","e96fa123":"code","3b0fa4ad":"code","3a89b739":"code","f6f4ad66":"markdown","24a35002":"markdown","e505e1e6":"markdown","f7c073e4":"markdown","68348f35":"markdown","a2e5c4ef":"markdown","264da26f":"markdown","8bdad897":"markdown","47787544":"markdown","51e578a6":"markdown"},"source":{"a77a46ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","6232016a":"data = pd.read_csv('..\/input\/earthquake-database\/database.csv')","d34ca96a":"data","591d0ff0":"data.info()","04c0a041":"data = data.drop('ID', axis=1)","5334625a":"data.isna().sum()","f076f7d3":"null_columns = data.loc[:, data.isna().sum() > 0.66 * data.shape[0]].columns","99e8215b":"data = data.drop(null_columns, axis=1)","e60cbf3b":"data.isna().sum()","7aa9be03":"data['Root Mean Square'] = data['Root Mean Square'].fillna(data['Root Mean Square'].mean())","5c704dbf":"data = data.dropna(axis=0).reset_index(drop=True)","3e235bb4":"data.isna().sum().sum()","bb19b52d":"data","3f3f5d72":"data['Month'] = data['Date'].apply(lambda x: x[0:2])\ndata['Year'] = data['Date'].apply(lambda x: x[-4:])\n\ndata = data.drop('Date', axis=1)","77dceb03":"data['Month'] = data['Month'].astype(np.int)","9c7b296f":"data[data['Year'].str.contains('Z')]","f73342ca":"invalid_year_indices = data[data['Year'].str.contains('Z')].index\n\ndata = data.drop(invalid_year_indices, axis=0).reset_index(drop=True)","7f1c6cc9":"data['Year'] = data['Year'].astype(np.int)","26e09b51":"data['Hour'] = data['Time'].apply(lambda x: np.int(x[0:2]))\n\ndata = data.drop('Time', axis=1)","23dfc978":"data","38a948c3":"data['Status'].unique()","acae8381":"data['Status'] = data['Status'].apply(lambda x: 1 if x == 'Reviewed' else 0)","58bef0a8":"numeric_columns = [column for column in data.columns if data.dtypes[column] != 'object']","23f94d59":"corr = data[numeric_columns].corr()","9a7334ae":"plt.figure(figsize=(12, 10))\nsns.heatmap(corr, annot=True, vmin=-1.0, vmax=1.0)\nplt.show()","abf30c66":"numeric_columns.remove('Status')","9adb6486":"scaler = StandardScaler()\nstandardized_df = pd.DataFrame(scaler.fit_transform(data[numeric_columns].copy()), columns=numeric_columns)","86f57af3":"plt.figure(figsize=(18, 10))\nfor column in numeric_columns:\n    sns.kdeplot(standardized_df[column], shade=True)\nplt.xlim(-3, 3)\nplt.show()","9bfcd2d4":"data","a0702ea4":"data['Type'].unique()","175fba61":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","0094d3f0":"data = onehot_encode(\n    data,\n    ['Type', 'Magnitude Type', 'Source', 'Location Source', 'Magnitude Source'],\n    ['t', 'mt', 's', 'ls', 'ms']\n)","95472982":"data","0ec751f2":"y = data.loc[:, 'Status']\nX = data.drop('Status', axis=1)","08c8b665":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","2c0da1b5":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=56)","7372fc7f":"X.shape","8f973dd8":"y.mean()","12ec9b2a":"inputs = tf.keras.Input(shape=(104,))\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[tf.keras.metrics.AUC(name='auc')]\n)\n\n\nbatch_size = 32\nepochs = 30\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n    verbose=0\n)","e96fa123":"plt.figure(figsize=(18, 6))\n\nepochs_range = range(epochs)\ntrain_loss, val_loss = history.history['loss'], history.history['val_loss']\ntrain_auc, val_auc = history.history['auc'], history.history['val_auc']\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\nplt.legend()\nplt.title(\"Loss Over Time\")\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_auc, label=\"Training AUC\")\nplt.plot(epochs_range, val_auc, label=\"Validation AUC\")\nplt.legend()\nplt.title(\"AUC Over Time\")\n\nplt.show()","3b0fa4ad":"model.evaluate(X_test, y_test)","3a89b739":"len(y_test)","f6f4ad66":"# Getting Started","24a35002":"# Visualization","e505e1e6":"# Splitting and Scaling","f7c073e4":"# Modeling and Training","68348f35":"# Preprocessing","a2e5c4ef":"# Results","264da26f":"# Encoding","8bdad897":"# Feature Engineering","47787544":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/cpCCZj3U608","51e578a6":"# Task for Today  \n\n***\n\n## Earthquake Type Prediction  \n\nGiven *data about earthquakes*, let's try to predict if a given earthquake is **automatic or reviewed**.  \n(An earthquake is \"reviewed\" when automatic earthquake detection systems fail to record the earthquake.)\n  \nWe will use a TensorFlow ANN to make our predictions."}}