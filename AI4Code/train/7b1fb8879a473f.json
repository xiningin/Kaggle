{"cell_type":{"0d731913":"code","df7f9159":"code","90bfc23e":"code","55b4a51c":"code","82103411":"code","59164dd4":"code","4f2e3810":"code","f88a3961":"code","0e248692":"code","49f2c9fa":"code","af05018a":"code","ac386fc2":"code","8ebe3691":"code","6d2c9334":"code","cbf79d01":"code","8d71cb17":"code","0e1dfccf":"code","e9e4e55e":"code","71cecc34":"code","4cda0dca":"code","60d05d13":"markdown","9c37b651":"markdown","e475dd21":"markdown"},"source":{"0d731913":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","df7f9159":"car_data = pd.read_csv(\"..\/input\/car-prices\/car_prices.csv\")","90bfc23e":"car_data.head()","55b4a51c":"car_data.rename({\"Unnamed: 0.1\":\"a\"}, axis=\"columns\", inplace=True) # Renamed and dropped the 2 unnamed columns.\ncar_data.drop([\"a\"], axis=1, inplace=True)\n\ncar_data.rename({\"Unnamed: 0\":\"b\"}, axis=\"columns\", inplace=True) \ncar_data.drop([\"b\"], axis=1, inplace=True)","82103411":"car_data.head(2) # Confirm if the two unnamed columns were droped.","59164dd4":"car_data.isnull().sum() # Check for null values.","4f2e3810":"# stroke has 4 null values, therefore clean by getting the mean:\n\ncar_data['stroke'].fillna(car_data['stroke'].mean(), inplace=True)","f88a3961":"# Recheck if null values have been solved \n\ncar_data.isnull().sum()","0e248692":"car_data.describe() # Statistical summary of the data","49f2c9fa":"# Correlation between the variables using Heatmap.\n\n\nplt.figure(figsize=(25,15))\nplt.title(\"(fig-1) Correlation of all Variables \")\nsns.heatmap(car_data.corr(), annot = True) \nplt.show()   ","af05018a":"### Summarize\/group categorical data in a column.\n\n\ndrive_wheels_counts=car_data[\"drive-wheels\"].value_counts().to_frame() ","ac386fc2":"plt.figure(figsize=(10,6))\nplt.title(\"(fig-2) Relationship between Drive-Wheel Categories and Price\")\nsns.barplot(x=\"drive-wheels\", y= 'price',data=car_data)\nplt.show","8ebe3691":"plt.figure(figsize=(25,15))\nplt.title(\"(fig-3) Relationship between Makes and Price\")\nsns.boxplot(x= \"make\", y= 'price',data=car_data)\nplt.show()","6d2c9334":"# 1. The prediction target in this case is PRICE\n\ny = car_data.price","cbf79d01":"# 2. The catalysts for prediction are the FEATURES columns\n\ncar_features = [\"engine-size\", 'horsepower', 'city-mpg', 'highway-mpg',\"bore\", \"stroke\", \"peak-rpm\", \"normalized-losses\", 'symboling', \"wheel-base\", \"length\",'height', 'width', \"curb-weight\"]\n\nX = car_data[car_features]","8d71cb17":"X.describe()","0e1dfccf":"from sklearn.tree import DecisionTreeRegressor\n\n# Define model\n\ncar_model = DecisionTreeRegressor(random_state=1)\n","e9e4e55e":"# 2. Fit Model\n\ncar_model.fit(X, y)\n\n","71cecc34":"# 3. Prediction\n\n\nprint(\"Making predictions for the first 5 cars:\")\nprint(X.head(5))\nprint(\"The predictions are\")\nprint(car_model.predict(X.head(5)))","4cda0dca":"#scoring the model\n\ncar_model.score(X,y)","60d05d13":"# Select data for modeling\n### -> 1. Prediction Target\n### -> 2. Choosing Features","9c37b651":"# Building Model\n### -> 1. Define (Type of Model)\n### -> 2. Fit (Patterns from data)\n### -> 3. Prediction\n### -> 4. Score model","e475dd21":"# Import and explorring raw data"}}