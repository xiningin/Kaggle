{"cell_type":{"20f5dbf5":"code","bbc9c6cd":"code","49f098af":"code","f77d6c29":"code","ca392131":"code","0fec92b2":"code","190c34f0":"code","564b8d6d":"code","599ce8d8":"code","1e7c956e":"code","775cfb27":"code","f1bf01b6":"code","569bf841":"code","318ea73b":"code","243090d9":"code","257f5c56":"code","241b0a44":"code","69f2bd2d":"code","ee713b10":"code","ec44029c":"code","12fdc3e0":"code","e2a05eb7":"code","4967e053":"code","72af0911":"code","b0a06a91":"code","1fe8b365":"code","5a6cca9d":"code","6caa5246":"code","182c3c0b":"code","effd2d3f":"code","a822c6f9":"code","0a5b6904":"code","67303fac":"code","7e983b10":"markdown","8ffda0fb":"markdown","a375230d":"markdown","9fe421c7":"markdown","abb0121c":"markdown","2de28b19":"markdown","ef27e201":"markdown","02dfebc7":"markdown","7ffa96e9":"markdown","82fca91c":"markdown","89684c1f":"markdown"},"source":{"20f5dbf5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing |Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nimport random\nfrom sklearn.utils import shuffle\nimport seaborn as sns\nimport keras\n# Any results you write to the current directory are saved as output.","bbc9c6cd":"def loadImages(root_dir,mode='train',labels_dict={'street':0,'sea':1,'glacier':2,'mountain':3,'buildings':4,'forest':5}):\n    image_sizes=[]\n    images=[]\n    scene_type=[]\n    if mode=='train':\n        # Read the folders inside the root directory and the label is the name of the sub-directory\n        for labels in os.listdir(root_dir):\n            label=labels_dict[labels]\n            for image_file in os.listdir(root_dir+\"\/\"+labels):\n                image = cv2.imread(root_dir+labels+r'\/'+image_file)\n                image_sizes.append(image.shape)\n                ## There are images of multiple sizes in the data. Let us resize them\n                \n                image=cv2.resize(image,(150,150))\n                images.append(image)\n                scene_type.append(label)\n        ### We need to shuffle the data set\n        \n        images,scenes= shuffle(images,scene_type,random_state=1234)\n        \n        ### Convert the list to numpy array \n        images=np.array(images)\n        scenes=np.array(scenes)\n        \n        return images,scenes\n    \n                ","49f098af":"images,labels=loadImages(\"..\/input\/seg_train\/seg_train\/\")","f77d6c29":"print(\"Shape of Images  in Training Data\",images.shape)\nprint(\"Shape of Labels in Training Data\",labels.shape)","ca392131":"sns.countplot(labels)","0fec92b2":"labels_dict={'street':0,'sea':1,'glacier':2,'mountain':3,'buildings':4,'forest':5}\ninverse_labels={value:key for key,value in labels_dict.items()}\n","190c34f0":"TRAIN_DATASET_PATH=\"..\/input\/seg_train\/seg_train\/\"\nimport keras\nfrom keras import models as Models\nfrom keras import layers as Layers\nfrom keras import optimizers as Optimizers\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, mode='train', ablation=None, image_cls={'street':0,'sea':1,'glacier':2,'mountain':3,'buildings':4,'forest':5}, \n                 batch_size=32, dim=(150, 150), n_channels=3, shuffle=True,train_test_split=0.8):\n        \"\"\"\n        Initialise the data generator\n        \"\"\"\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = {}\n        self.list_IDs = []\n        \n        # glob through directory of each class \n        label_class=[key for key,val in image_cls.items()]\n        for i, cls in enumerate(label_class):\n            paths = glob.glob(os.path.join(TRAIN_DATASET_PATH, cls, '*'))\n            brk_point = int(len(paths)*train_test_split) #Divide the data into 80:20 - training and validation set\n            if mode == 'train':\n                paths = paths[:brk_point]\n            else:\n                paths = paths[brk_point:]\n            if ablation is not None:\n                paths = paths[:ablation]\n            self.list_IDs += paths\n            self.labels.update({p:i for p in paths})\n            \n        self.n_channels = n_channels\n        self.n_classes = len(label_class)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        \n       \n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img = cv2.imread(ID)\n            img = img\/255\n            ## Resize the image\n            img=cv2.resize(img,self.dim)\n            X[i,] = img\n          \n            # Store class\n            y[i] = self.labels[ID]\n        \n        \n        return X, y","564b8d6d":"from keras.applications import VGG16\n","599ce8d8":"vgg_conv = VGG16(weights='imagenet',\n                  include_top=False,input_shape=(150,150,3))\n","1e7c956e":"vgg_conv.summary()","775cfb27":"model=Models.Sequential()\nmodel.add(vgg_conv)\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(180,activation='relu'))\nmodel.add(Layers.Dense(100,activation='relu'))\nmodel.add(Layers.Dense(50,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(6,activation='softmax'))","f1bf01b6":"model.summary()","569bf841":"vgg_conv.trainable=False","318ea73b":"model.summary()","243090d9":"model.compile(optimizer=Optimizers.Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\ntraining_generator=DataGenerator('train',train_test_split=0.7)\nvalidation_generator=DataGenerator('val')\nhistory=model.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    epochs=10)","257f5c56":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","241b0a44":"vgg_conv.trainable=True\nset_trainable=False\nfor layer in vgg_conv.layers:\n    if layer.name=='block5_conv1':\n        set_trainable=True\n    if set_trainable==True:\n        layer.trainable=True\n    else:\n        layer.trainable=False","69f2bd2d":"model1=Models.Sequential()\nmodel1.add(vgg_conv)\nmodel1.add(Layers.Flatten())\nmodel1.add(Layers.Dense(180,activation='relu'))\nmodel1.add(Layers.Dense(100,activation='relu'))\nmodel1.add(Layers.Dense(50,activation='relu'))\n#model1.add(Layers.Dropout(rate=0.5))\nmodel1.add(Layers.Dense(6,activation='softmax'))","ee713b10":"model1.summary()","ec44029c":"model1.compile(optimizer=Optimizers.Adam(lr=0.00001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\ntraining_generator=DataGenerator('train',train_test_split=0.7)\nvalidation_generator=DataGenerator('val')\nhistory=model1.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    epochs=15)","12fdc3e0":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","e2a05eb7":"TEST_DATASET=\"..\/input\/seg_test\/seg_test\/\"","4967e053":"test_images,test_labels=loadImages(TEST_DATASET)","72af0911":"img_tensor=np.empty((len(test_images),150,150,3))\ny=np.empty((len(test_images)),dtype=int)\ny_pred=np.empty((len(test_images)),dtype=int)\nfor idx,img in enumerate(test_images):\n    img = img\/255\n    ## Resize the image\n    img=cv2.resize(img,(150,150))\n    img_tensor[idx,] = img\n    y[idx]=test_labels[idx]\n    \ny_pred=model1.predict_classes(img_tensor)\n\n    ","b0a06a91":"y_pred","1fe8b365":"y","5a6cca9d":"y_pred=list(y_pred)\ny=list(y)","6caa5246":"y_pred=[inverse_labels[val] for val in y_pred]\ny=[inverse_labels[val] for val in y]","182c3c0b":"correct_pred=0\nfor idx in range(0,len(y)):\n    \n    if y[idx]==y_pred[idx]:\n        correct_pred=correct_pred+1\n    else:\n        correct_pred=correct_pred\n        \nprint(\"Number of Correct Predictions\",correct_pred)\n        ","effd2d3f":"print(len(y))","a822c6f9":"acuuarcy=correct_pred\/len(y)\nprint(\"Accuracy is\",acuuarcy)","0a5b6904":"incorrect_pred=len(y) - correct_pred\nincorrect_pred","67303fac":"f,ax = plt.subplots(66,5,figsize=(700,700)) \n#f.subplots_adjust(0,0,10,10)\n\nincorrect_idx=[]\nfor idx in range(0,len(y)):\n    if y[idx]!=y_pred[idx]:\n        incorrect_idx.append(idx)\n\nprint(len(incorrect_idx))\nfor i in range(0,66,1):\n    for j in range(0,5,1):\n        if len(incorrect_idx)>0:\n            idx=incorrect_idx.pop()\n            ax[i,j].imshow(test_images[idx])\n            ax[i,j].set_title(y[idx]+\"-\"+y_pred[idx])\n            ax[i,j].axis('off')\n        ","7e983b10":"We want to freeze the weights learnt during training on ImageNet, so we will freeze the vgg_conv layer","8ffda0fb":"We can see by the tenth epoch, the model has achieved 99% accuracy of the training data and the validation accuracy is >0.90. Let us know use this model to predict on our test data","a375230d":"Since we do not want to change the weight too much, we will use smaller learning rates","9fe421c7":"## Fine Tuning PreTrained Convnet\n\nIn a CNN, in the feature extraction layers,the earlier levels learn genric features while the top layers learn features realted to the images.This means, our VGG Net also in the top layers has learnt informtiion particular to the images it was trained on. For this purpise, we can fine tune only the weights of the top Conv layers.\nReason why it is not good to retrain all the layers is that the model may opverfit, As we saw we have almost 15Million Parameters to learn and on this small dataset of images it will overfit.\n\nSo let us freeze all layers upto the block5_conv in VGG16 and build our model","abb0121c":"We see that the numver of trainable parameters has reduced significantly","2de28b19":"### Number of cases where y_pred = y","ef27e201":"### In keras, data generators are used to allow training of data in batches. Keras, by default offers an Image DataGenerator, but many a times you will need to customise the data generation. So we will build our own data generator","02dfebc7":"### Let us look at the ones where, the model has wrongly classified","7ffa96e9":"With much lesser epochs we have achieved higher accuracies using a pre-trained model.","82fca91c":"## Load Images in Test_dataset and get the images","89684c1f":"## We now have to add our fully connected layer on top of VGG. We have 6 Classes to predict and hence we will have a softmax layer with 6 neurons in the output layer.\n\n"}}