{"cell_type":{"5b1e9d74":"code","680d1dfb":"code","38cc5ab3":"code","326832f6":"code","3ddca694":"code","5b65c299":"code","8fc39cf3":"code","8768c839":"code","1363a18e":"code","294f2c9f":"code","750156ce":"code","440ebd86":"code","826870a3":"code","503d45bb":"code","725dc440":"code","b921f940":"code","56235853":"code","0a8ae3cf":"code","de133910":"code","85f9b258":"code","3e90fdd7":"code","1bba2d2a":"code","feeca911":"code","07a85348":"code","5a5c2f5b":"code","e2b5d245":"code","71017e50":"markdown","26f1caa1":"markdown"},"source":{"5b1e9d74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt  #Vizualisation package\nimport seaborn as sns #Vizualisation package\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","680d1dfb":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","38cc5ab3":"df.head()","326832f6":"df.describe()","3ddca694":"df.info()","5b65c299":"plt.figure(figsize = (10,8))\nsns.heatmap(df.corr(),annot = True);","8fc39cf3":"df.corr()['target'].sort_values()","8768c839":"sns.countplot(data = df,x= 'target')","1363a18e":"\ng = sns.FacetGrid(df, col='target')\ng = g.map(sns.distplot, \"age\")","294f2c9f":"g = sns.kdeplot(df[\"age\"][(df[\"target\"] == 0) & (df[\"age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(df[\"age\"][(df[\"target\"] == 1) & (df[\"age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"No Disease\",\"Disease\"])","750156ce":"g = sns.barplot(x=\"sex\",y=\"target\",data=df)\ng = g.set_ylabel(\"Survival Probability\")","440ebd86":"sns.pairplot(df[['age','trestbps', 'chol','thalach','target']],hue='target')","826870a3":"sns.regplot(x= 'thalach',y = 'age',data = df)","503d45bb":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","725dc440":"X = df.drop('target',axis=1)\ny = df['target']","b921f940":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","56235853":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)","0a8ae3cf":"scaler = StandardScaler()","de133910":"scaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","85f9b258":"from collections import Counter","3e90fdd7":"kfold = StratifiedKFold(n_splits=10)","1bba2d2a":"random_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\n\n\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, scaled_X_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\n\n\n\n\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","feeca911":"log_model = LogisticRegression()","07a85348":"log_model.fit(scaled_X_train,y_train)","5a5c2f5b":"y_pred = log_model.predict(scaled_X_test)","e2b5d245":"output = pd.DataFrame({'chol': X_test.chol, 'target': y_pred})\noutput.to_csv('my_submission.csv', index=False)","71017e50":"In the dataset we have more people who has heart disease than the one has not","26f1caa1":"So we have no NA value! Nice!"}}