{"cell_type":{"822dbc9b":"code","a1aebccb":"code","eec9a165":"code","b4ae07b4":"code","8d32e9e5":"code","09ed3d89":"code","699062bc":"code","4154ab21":"code","c1d4b3de":"code","c5bfc2a7":"code","05ecfa07":"code","abcc1a6b":"code","79a09eaf":"code","169a2e35":"code","3af25ce9":"code","c9e895c6":"markdown","5e98e528":"markdown","b02b2a35":"markdown","32de1b69":"markdown","913a8ef6":"markdown","79c2242e":"markdown","4720788b":"markdown","f7aff4d0":"markdown","9b388170":"markdown","e71ba845":"markdown"},"source":{"822dbc9b":"try:\n    import pandas as pd\n    import numpy as np\n    import time\n    import os\n    import string\n\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    from scipy.stats import gaussian_kde\n    print(\"Loading libraries...\")\n    time.sleep(2)\n    print(\"Loading successful.\")\n    \n    pd.set_option('display.max_colwidth', 10000)\nexcept ImportError as e:\n    print(f\"There are some libraries missing {e}\")","a1aebccb":"ROOT_DIR = '..\/input\/commonlitreadabilityprize'\ntrain_df = pd.read_csv(os.path.join(ROOT_DIR,\"train.csv\"),\n                    dtype={'target':np.float32,'standard_error':np.float32})","eec9a165":"train_df.head()","b4ae07b4":"train_df.info()","8d32e9e5":"train_df.describe(include='all')","09ed3d89":"print(f\"Ids :{len(train_df.id.unique())}\")\nprint(f\"Excerpt :{len(train_df.excerpt.unique())}\")\nprint(f\"Target :{len(train_df.target.unique())}\")\nprint(f\"Standarad error:{len(train_df.standard_error.unique())}\")","699062bc":"train_df.sort_values('target', ascending=False).head(1)[['id','excerpt','standard_error','target']]","4154ab21":"train_df[train_df['target'] == train_df['standard_error']][['id','excerpt','standard_error','target']]","c1d4b3de":"train_df.sort_values('target', ascending=True).head(1)[['id','excerpt','standard_error','target']]","c5bfc2a7":"train_df['length_passage'] = train_df['excerpt'].apply(len)","05ecfa07":"train_df['difficulty'] = np.where(train_df['target'] <= 0, 0, 1)\ntrain_df.head()","abcc1a6b":"x = train_df['target']\ny = train_df['standard_error']\n\nbins = 100\n\nplt.figure(figsize=(8,6))\nsns.set_theme(style=\"whitegrid\")\nplt.hist(x, bins, alpha=.7,color='red', label='target')\nplt.hist(y, bins, alpha=.7, color='black',label='standard_error')\nplt.legend(loc='upper right')\nplt.show()","79a09eaf":"plt.figure(figsize=(8,6))\nsns.set_theme(style=\"whitegrid\")\nplt.title('standard error vs target', fontsize=10)\nsns.histplot(data=train_df, x=\"target\",y=\"standard_error\", bins=250)","169a2e35":"plt.figure(figsize=(8,6))\nsns.set_theme(style=\"whitegrid\")\nplt.title('Easy and difficult passage counts', fontsize=10)\nax = sns.countplot(x=\"difficulty\", data=train_df,palette='husl')","3af25ce9":"\nplt.figure(figsize=(8,6))\nsns.set_theme(style=\"whitegrid\")\nbins=100\n\nplt.hist(train_df[train_df['difficulty']==0]['length_passage'], bins, range=[400,1500],\n         alpha=0.6, label='easy to read passage')\nplt.hist(train_df[train_df['difficulty']==1]['length_passage'], bins, range=[400,1500],\n         alpha=0.6, label='difficult to read passage')\nplt.title('Easy and difficult passage lengths', fontsize=10)\nplt.xlabel('Length of passage', fontsize=10)\nplt.ylabel('Samples', fontsize=10)\nplt.legend(fontsize=10)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","c9e895c6":"-  id,exceprt and target has a one to one relation. there is no duplicate all have separate values\n- in standard error there are 3 duplicate values\n- there are missing values in the two columns (url_legal and licence)\n- as there were multiple raters, standard_error tells us the measure of spread of scores among the raters for each excerpt,it is heavily skewed.","5e98e528":"<a id=\"3\"><\/a>\n<h3 style=\"background-color:pink;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Meta features <\/h3>\n\n- lets make some features which will help us for the furthur analysis\n- length_passage (feature) : it is the length of each passages\n- difficulty (feature): reading difficulty score 0 for easy passages, score 1 for difficult passages\n","b02b2a35":"<a id=\"4\"><\/a>\n<h3 style=\"background-color:pink;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Exploratory data analysis<\/h3>\n","32de1b69":"- They are taken from various sources, and they are ranked by ease of read compared to baseline excerpt. Hardest and easiest to read excerpts are displayed along with the baseline excerpt (text).\n- Easiest excerpt to read (25ca8f498) is a very plain text,easy to read text.Sentences are short, diction and syntax are elementary level. There are no excessive amount of conjunctions and punctuations.\n\n- Hardest excerpt to read (4626100d8) is in fact hard to understand. Sentences are long, diction and syntax are academic level. There are lots sentences connected to each with conjunctions and lots of punctuations.","913a8ef6":"#### *Please upvote.......thank you*","79c2242e":"<a id=\"table\"><\/a>\n<h1 style=\"background-color:pink;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;\">Table Of Content<\/h1>\n\n\n* [1. Problem definition](#1)\n* [2. Initial analysis](#2)\n* [3. Meta features](#3)\n* [3. Exploratory data analysis](#4)","4720788b":"<a id=\"1\"><\/a>\n<h3 style=\"background-color:pink;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Problem definition<\/h3>\n\n\n### Can machine learning identify the appropriate reading level of a passage of text, and help inspire learning? \n\n\n- It is very important to understand the problem before solving it, let us try to understand the question fisrt \n- we have seen reading passages in schools, here in this competition we are provided with different reading passages\n- Different passages have different reading complexity, some can be easy to read other may not be that easy\n- In this competition we are asked to  build an algorithms, which will rate the complexity of reading passages (for grade 3-12 classroom use)\n- In simple language : how easy a given passage(from literature) to read ? use your data science in this case?\n- This competition will help students, teachers and administrators\n\n#### what are the features in the dataset and what they say\n\n- id - unique ID for excerpt\n- url_legal - URL of source (this is blank in the test set.)\n- license - license of source material (this is blank in the test set.)\n- excerpt - text to predict reading ease of\n- target - reading ease\n- standard_error - measure of spread of scores among multiple raters for each excerpt(Not included for test data.)","f7aff4d0":"### Lets have a look at the passages based on thair readability level\n- Easiest passage is having highest positive value (1.711)\n- Baseline has zero value\n- Hardest has lowest negative value (-3.676)","9b388170":"- Target feature is showing normal distribution \n- standard error is highly skewed\n- As seen from the graph the standard error reduces towards the middle, but increases towards both ends. This means regardless of the excerpt being complex or simple people rating vary widely and thus standard error rises at both ends","e71ba845":"<a id=\"2\"><\/a>\n<h3 style=\"background-color:pink;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Initial analysis <\/h3>\n\n- In the initial analysis we will try to understand the data set in a basic level"}}