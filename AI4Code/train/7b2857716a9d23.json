{"cell_type":{"cb07069e":"code","239c11b3":"code","9a13b55e":"code","481cc0ff":"code","4d41b443":"code","c86788fe":"code","5aff1db7":"code","ef3e51c2":"code","191901b3":"code","39674d46":"code","a9e3a1b8":"code","c9d49401":"code","cf9f8fac":"code","535a3968":"code","1a2c617f":"code","d50f462c":"code","b572d465":"code","dbd02070":"code","eefb2104":"code","1c835bf7":"code","b83927fa":"code","cf427c40":"markdown","d5944911":"markdown","93e4f70d":"markdown","deb66ac9":"markdown"},"source":{"cb07069e":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport gresearch_crypto\nimport time\nimport datetime\n\nTRAIN_CSV = '\/kaggle\/input\/g-research-crypto-forecasting\/train.csv'\nASSET_DETAILS_CSV = '\/kaggle\/input\/g-research-crypto-forecasting\/asset_details.csv'","239c11b3":"df_train = pd.read_csv(TRAIN_CSV)\ndf_train.head()","9a13b55e":"df_asset_details = pd.read_csv(ASSET_DETAILS_CSV).sort_values(\"Asset_ID\")\ndf_asset_details","481cc0ff":"def get_features(df, \n                 asset_id, \n                 train=True):\n    '''\n    This function takes a dataframe with all asset data and return the lagged features for a single asset.\n    \n    df - Full dataframe with all assets included\n    asset_id - integer from 0-13 inclusive to represent a cryptocurrency asset\n    train - True - you are training your model\n          - False - you are submitting your model via api\n    '''\n    \n    df = df[df['Asset_ID']==asset_id]\n    df = df.sort_values('timestamp')\n    if train == True:\n        df_feat = df.copy()\n        # define a train_flg column to split your data into train and validation\n        totimestamp = lambda s: np.int32(time.mktime(datetime.datetime.strptime(s, \"%d\/%m\/%Y\").timetuple()))\n        valid_window = [totimestamp(\"12\/03\/2021\")]\n        df_feat['train_flg'] = np.where(df_feat['timestamp']>=valid_window[0], 0,1)\n        df_feat = df_feat[['timestamp','Asset_ID','Close','Target','train_flg']].copy()\n    else:\n        df = df.sort_values('row_id')\n        df_feat = df[['Asset_ID','Close','row_id']].copy()\n    \n    # Create your features here, they can be lagged or not\n    df_feat['sma15'] = df_feat['Close'].rolling(15).mean()\/df_feat['Close'] -1\n    df_feat['sma60'] = df_feat['Close'].rolling(60).mean()\/df_feat['Close'] -1\n    df_feat['sma240'] = df_feat['Close'].rolling(240).mean()\/df_feat['Close'] -1\n    \n    '''\n    \n    df_feat['return15'] = df_feat['Close'][:-15]\/df_feat['Close'][15:] -1\n    df_feat['return60'] = df_feat['Close'][:-60]\/df_feat['Close'][60:] -1\n    df_feat['return240'] = df_feat['Close'][:-240]\/df_feat['Close'][240:] -1\n    ''' \n    df_feat = df_feat.fillna(0)\n    \n    return df_feat","4d41b443":"# create your feature dataframe for each asset and concatenate\nfeature_df = pd.DataFrame()\nfor i in range(14):\n    feature_df = pd.concat([feature_df,get_features(df_train,i,train=True)])","c86788fe":"# assign weight column feature dataframe\nfeature_df = pd.merge(feature_df, df_asset_details[['Asset_ID','Weight']], how='left', on=['Asset_ID'])","5aff1db7":"# define features for LGBM\nfeatures = ['Asset_ID','sma15','sma60','sma240','return15','return60','return240']\ncategoricals = ['Asset_ID']","ef3e51c2":"# define the evaluation metric\ndef weighted_correlation(a, train_data):\n    \n    weights = train_data.add_w.values.flatten()\n    b = train_data.get_label()\n    \n    \n    w = np.ravel(weights)\n    a = np.ravel(a)\n    b = np.ravel(b)\n\n    sum_w = np.sum(w)\n    mean_a = np.sum(a * w) \/ sum_w\n    mean_b = np.sum(b * w) \/ sum_w\n    var_a = np.sum(w * np.square(a - mean_a)) \/ sum_w\n    var_b = np.sum(w * np.square(b - mean_b)) \/ sum_w\n\n    cov = np.sum((a * b * w)) \/ np.sum(w) - mean_a * mean_b\n    corr = cov \/ np.sqrt(var_a * var_b)\n\n    return 'eval_wcorr', corr, True","191901b3":"# For the rolling average we can only store samples for the respective window  , say 15 minutes mot the others as that sounds dumb and not needed\n# I will also give some additional functions for you other than rolling average so that you need to code them out\n\n\n\n\nclass RollingAverage():\n    '''\n    This code is for saving up ram in Rolling average  lagged feats\n    '''\n    def __init__(self,windows=[]):\n          \n            self.max_length=max(windows)\n            self.dataframes=[]\n    def compute(self,current):\n        self.dataframes.append(float(current['Close']))\n       \n        if len(self.dataframes)>self.max_length: \n            self.dataframes.pop(0)  # This sample is not needed anymore so we can remove it\n      \n       \n        min15avg=np.mean(np.array(self.dataframes)[max([-1*len(self.dataframes),-15]):]) # 15min window average\n        min60avg=np.mean(np.array(self.dataframes)[max([-1*len(self.dataframes),-65]):]) # 16min window average\n        min240avg=np.mean(np.array(self.dataframes)[max([-1*len(self.dataframes),-240]):])# 240 min window average\n        # Compute features here \n        current['sma15'] = min15avg\/current['Close'] - 1 \n        current['sma60'] = min60avg\/current['Close'] - 1\n        current['sma240'] = min240avg\/current['Close'] - 1\n        \n        \n        return current\n    \n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n        \n        \n                \n        \n    \n    ","39674d46":"dfcrop=df_train[df_train['Asset_ID']==0]\ndfcrop.head()","a9e3a1b8":"rollingavg=RollingAverage([15,60,240])\n","c9d49401":"rollingavg.max_length","cf9f8fac":"rollingavg.compute(dfcrop.iloc[0])","535a3968":"rollingavg.compute(dfcrop.iloc[1])","1a2c617f":"\nrollingavg.compute(dfcrop.iloc[2])","d50f462c":"avgs=[RollingAverage([15,60,240]) for _ in range(14)] # Create 14 different objects one for each asset","b572d465":"# Exponentially Weighted Average\nclass ExponentiallyWeightedAverage:\n    v1=0\n    def __init__(self,beta):\n        self.beta=beta\n    def compute(self,value):\n        self.v1=self.beta*value+(1-self.beta)*self.v1\n        return self.v1\newm=ExponentiallyWeightedAverage(0.75)\nprint(ewm.compute(dfcrop.iloc[0]))\nprint(ewm.compute(dfcrop.iloc[1]))       \nprint(ewm.compute(dfcrop.iloc[2]))     ","dbd02070":"dfcrop.head()","eefb2104":"# Measures the rate of change of a feature over time\nclass RateCalculator:\n    def __init__(self,default=0.0):\n        # Default value is rate for first timestamp\n        self.default=default\n        self.previous=False\n    def compute(self,row):\n        if type(self.previous)==type(False):\n            self.previous=row.copy()\n            row[list(row.keys())]=self.default\n            \n            return row\n        \n        final=row\/self.previous\n        self.previous=row\n        return final\n    \nrate=RateCalculator()\nprint(rate.compute(dfcrop.iloc[0]))\n\nprint(rate.compute(dfcrop.iloc[1]))       \nprint(rate.compute(dfcrop.iloc[2]))     \n\n        \n        \n        \n        ","1c835bf7":"avgs=[RollingAverage([15,60,240]) for _ in range(14)] # Create 14 different objects one for each asset\newms=[ExponentiallyWeightedAverage(0.75) for _ in range(14)]\nrates=[RateCalculator(1.0) for _ in range(14)]\n","b83927fa":"start = time.time()\n\nenv = gresearch_crypto.make_env()\niter_test = env.iter_test()\n\n# create dataframe to store data from the api to create lagged features\nhistory = pd.DataFrame()\nfor i, (df_test, df_pred) in enumerate(iter_test):\n    \n\n    for j , row in df_test.iterrows():\n        # get features using history dataframe\n        avg=avgs[int(row['Asset_ID'])]\n        ewm=ewms[int(row['Asset_ID'])]\n        rate=rates[int(row['Asset_ID'])]\n        row_features1=avg.compute(row)\n        row_features2=ewm.compute(row)\n        row_features3=rate.compute(row)\n      \n        y_pred = float(row_features1['sma15']) # Giving a naive submission for now\n\n        df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = y_pred\n    \n    # we only want to keep the necessary recent part of our history dataframe, which will depend on your\n    # max_lookback value (your furthest lookback in creating lagged features).\n \n    \n    # Send submissions\n    env.predict(df_pred)\nstop = time.time()\nprint(stop-start)","cf427c40":"# Functions :-","d5944911":"# Submitting Lagged Features via API\n\nIn this notebook we submit a lagged features via the API.\n\nThe API works by providing a single row for each Asset - one timestamp at a time - to prevent using future data in predictions.\n\nIn order to utilise lagged features in our model, we must store the outputs from the API so we can calculate features using past data.","93e4f70d":"# Editing starts here\nSome kernels are saving the entire previous history dataframe for prediction that sounds really bizzare, I mean the memory usage will be way too high . So here rather than saving all the previous samples we only save the computations from the past sample , in this way we can save up a lot of memory , otherwise we may face a lot of compute_issues.\n\n[Note] Just for the sake of an example i am submitting one of the created features as the predictions and not training a new model to do so","deb66ac9":"# Submit"}}