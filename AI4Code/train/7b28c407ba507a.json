{"cell_type":{"19e17513":"code","1c8e6ca9":"code","d092f893":"code","a9d601a0":"code","d0fbb6fa":"code","a25fd9c0":"code","a6b11582":"code","c030c68b":"code","77f8bf30":"code","1a649419":"code","971a9659":"code","cb1f1afc":"code","fda3f1ce":"code","a2acafea":"code","8e8973de":"code","2f047a28":"code","3c8ba9a2":"code","dbb58a6e":"code","7564307c":"code","fafe18a0":"code","42dc0726":"code","e43b596c":"code","e01de07b":"markdown","51f530ba":"markdown","cb43acab":"markdown"},"source":{"19e17513":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder   # handling categorical data \nfrom sklearn.model_selection import train_test_split            # split the data into taring and testing set\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report # check accuracy of predicted result\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1c8e6ca9":"data = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')","d092f893":"data.head()","a9d601a0":"data.shape","d0fbb6fa":"# our dataset contains 8124 rows and 23 columns","a25fd9c0":"# lets check if there any missing values\ndata.info()","a6b11582":"data.describe()","c030c68b":"# lets divide the data into features and label","77f8bf30":"# beacause data contains so many categorical features we only take some features for our model","1a649419":"X = data.iloc[:, 1 : 6].values      # Features\ny = data.iloc[:, 0].values          # label","971a9659":"le = LabelEncoder()\nohe = OneHotEncoder(categorical_features = 'all')","cb1f1afc":"X[:, 0] = le.fit_transform(X[:, 0])\nX[:, 1] = le.fit_transform(X[:, 1])\nX[:, 2] = le.fit_transform(X[:, 2])\nX[:, 3] = le.fit_transform(X[:, 3])\nX[:, 4] = le.fit_transform(X[:, 4])","fda3f1ce":"X = ohe.fit_transform(X).toarray()","a2acafea":"# removing dummy variable trap\nX = X[:, [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30]]","8e8973de":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","2f047a28":"# train the model \nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)","3c8ba9a2":"# Predicting the results of our model\ny_pred = classifier.predict(X_test)","dbb58a6e":"# create confusion matrix\nconfusion_matrix(y_test, y_pred)","7564307c":"# check accuracy\naccuracy_score(y_test, y_pred)","fafe18a0":"# check f1score\nprint(classification_report(y_test, y_pred))","42dc0726":"# hope you guys liked it ","e43b596c":"# thankyou for visit","e01de07b":"# RandomForestClassifier","51f530ba":"# Handling categorical features","cb43acab":"## Split the data into training and testing set"}}