{"cell_type":{"9a2ef04f":"code","4fee1e14":"code","be2a2d5c":"code","53c0c455":"code","88d34e87":"code","4f746609":"code","00244772":"code","a3b694bd":"code","e6eead2e":"code","a53ef3b7":"code","5d3f3b9e":"code","50f291b8":"code","b2c5ad6a":"code","a1a7eb39":"code","ea4dc4ac":"code","6c24c982":"code","22cacb8f":"code","13769a1a":"markdown","1fac7bb3":"markdown","a7fa2ae5":"markdown","1e2d7b45":"markdown","ceba03aa":"markdown","cae7cdc3":"markdown","ededbf03":"markdown","d32a6bce":"markdown","1ced9a75":"markdown","45fe6845":"markdown","7b6c3569":"markdown","c50bb82c":"markdown","5a5e2c3f":"markdown"},"source":{"9a2ef04f":"import tensorflow as tf\nimport numpy as np\nimport time\nfrom collections import defaultdict\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.applications import resnet50\nfrom keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nimport skimage\nfrom skimage import transform\nfrom PIL import Image\nfrom matplotlib import cm\nimport cv2\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import DBSCAN\nfrom matplotlib import pyplot as plt\nimport random\nfrom tqdm import tqdm","4fee1e14":"!ls ..\/input\/gbt-energy-detection-outputs-fine-resolution","be2a2d5c":"%matplotlib inline\nnp_images = np.load('..\/input\/gbt-energy-detection-outputs-fine-resolution\/GBT_58202_44201_KEPLER738B_fine_filtered.npy')\nplt.imshow(np_images[0], cmap='viridis')\nplt.figure(figsize=(12,16))\nnp_images = np.take(np_images,np.random.permutation(np_images.shape[0]),axis=0,out=np_images)\nprint(np_images.shape)","53c0c455":"conv_only_model = ResNet50(include_top=False,\n                 weights='imagenet',\n                 input_shape=(32, 256, 3),\n                 pooling=\"max\")\n# conv_only_model.summary()","88d34e87":"def resize_and_rgb(img, shape=(224, 224)):\n  np_images_resized = skimage.transform.resize(image=img, output_shape = shape)\n  np_images_resized -= np.min(np_images_resized)\n  np_images_resized = np_images_resized \/ np.max(np_images_resized)\n  im = cv2.cvtColor(np.float32(np_images_resized),cv2.COLOR_GRAY2RGB)\n  return im\n\nconverted_img = np.zeros((5000, 32, 256, 3))\nfor k in tqdm(range(converted_img.shape[0])):\n  converted_img[k,:,:,:] = resize_and_rgb(np_images[k,:,:], (32, 256))\n\nplt.imshow(converted_img[0])","4f746609":"# # Scale the input image to the range used in the trained network\nx = resnet50.preprocess_input(converted_img)\n# # Run the image through the deep neural network to make a prediction\npredictions = conv_only_model.predict(x)\n","00244772":"def k_means_clustering_fit(inputdata, clusters):\n  kmeans = KMeans(n_clusters=clusters, init='k-means++', max_iter=3000, n_init=100, random_state=2)\n  kmeans.fit(inputdata)\n  generated = np.zeros((clusters))\n  prediction =  kmeans.predict(inputdata)\n  for i in range(0,inputdata.shape[0]):\n    for k in range(0,clusters):\n      if prediction[i]==k:\n        generated[k]+=1\n  print(generated)\n\n  names = np.zeros((clusters))\n  for t in range(0,clusters):\n    names[t]=t\n  plt.title('Distribution In Classes')\n  plt.xlabel(\"Num of Samples\")\n  plt.ylabel(\"Classes\")\n  plt.bar(names, generated)\n  return prediction, kmeans","a3b694bd":"hold =[]\nclusters = 15\nprint(\"Predicted classes are ....\")\nhold, kmeans = k_means_clustering_fit(predictions, clusters)","e6eead2e":"k_means_labels =  kmeans.predict(predictions)\nk_means_cluster_members = defaultdict(list)\nfor i in range(k_means_labels.shape[0]):\n    k_means_cluster_members[k_means_labels[i]].append(i)","a53ef3b7":"for clu in range(clusters):\n  index_pick = k_means_cluster_members[clu][0]\n  plt.figure(figsize=(12,16))\n  plt.title('Spectrogram Sample for Cluster '+str(clu))\n  plt.xlabel(\"Fchans\")\n  plt.ylabel(\"Time\")\n  plt.imshow(np_images[index_pick,:,:], interpolation='nearest')\n  plt.show()","5d3f3b9e":"cluster = 5\nfor index in k_means_cluster_members[cluster][:10]:\n    plt.figure(figsize=(12,16))\n    plt.title('Spectrogram Sample for Cluster '+str(cluster))\n    plt.xlabel(\"Fchans\")\n    plt.ylabel(\"Time\")\n    plt.imshow(np_images[index,:,:], interpolation='nearest')","50f291b8":"cluster = 12\nfor index in k_means_cluster_members[cluster][:10]:\n    plt.figure(figsize=(12,16))\n    plt.title('Spectrogram Sample for Cluster '+str(cluster))\n    plt.xlabel(\"Fchans\")\n    plt.ylabel(\"Time\")\n    plt.imshow(np_images[index,:,:], interpolation='nearest')","b2c5ad6a":"def DBSCAN_clustering_fit(inputdata):\n  dbscan = DBSCAN(eps=0.5, min_samples=3, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=-1)\n  prediction = dbscan.fit_predict(inputdata)\n  print(np.max(prediction))\n  clusters = np.max(prediction)\n  print(prediction)\n  generated = np.zeros((clusters))\n  for i in range(0,inputdata.shape[0]):\n    for k in range(0,clusters):\n      if prediction[i]==k:\n        generated[k]+=1\n  print(generated)\n\n  names = np.zeros((clusters))\n  for t in range(0,clusters):\n    names[t]=t\n  plt.bar(names, generated)\n  return prediction, dbscan\n\ndbscan_labels, dbscan = DBSCAN_clustering_fit(predictions)\n\ndbscan_cluster_members = defaultdict(list)\nfor i in range(dbscan_labels.shape[0]):\n    dbscan_cluster_members[dbscan_labels[i]].append(i)","a1a7eb39":"np.count_nonzero(dbscan_labels == -1)","ea4dc4ac":"for clu in range(10):\n  index_pick = dbscan_cluster_members[clu][0]\n  plt.figure(figsize=(12,16))\n  plt.title('Spectrogram Sample for Cluster '+str(clu))\n  plt.xlabel(\"Fchans\")\n  plt.ylabel(\"Time\")\n  plt.imshow(np_images[index_pick,:,:], interpolation='nearest')\n  plt.show()","6c24c982":"cluster = 5\nfor index in dbscan_cluster_members[cluster][:10]:\n    plt.figure(figsize=(12,16))\n    plt.title('Spectrogram Sample for Cluster '+str(cluster))\n    plt.xlabel(\"Fchans\")\n    plt.ylabel(\"Time\")\n    plt.imshow(np_images[index,:,:], interpolation='nearest')","22cacb8f":"cluster = 12\nfor index in dbscan_cluster_members[cluster][:10]:\n    plt.figure(figsize=(12,16))\n    plt.title('Spectrogram Sample for Cluster '+str(cluster))\n    plt.xlabel(\"Fchans\")\n    plt.ylabel(\"Time\")\n    plt.imshow(np_images[index,:,:], interpolation='nearest')","13769a1a":"## K-Means Clustering \n\nHere we define a simple function that wraps the Sklearn Kmeans algorithm in a function that allows us to get the prediction and the model in a simple method. K Means algorithm work by approximating the centroids of `n` clusters by iteratively readjusting the centroids based on the mean distance between its nearest neighbors.\n\n<p align=\"center\" height=\"200px\"> \n    <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/e\/ea\/K-means_convergence.gif\">\n<\/p>\n\nWe then cluster the samples based on the encoded vectors from the `RESNET50` model. The number of clusters is a tuned hyper parameter that we can change and for this case we chose 15 based on experimentation. ","1fac7bb3":"DBSCAN gave a lot more clusters, but unfortunately a lot of samples were deemed outliers by the algorithm.","a7fa2ae5":"# SETI RESNET50 and Energy Detection \n\n#### Notebook By  [Peter Ma](https:\/\/PETERMA.CA) | [Shirley Wang](https:\/\/github.com\/shirls537) | [Yuhong Chen](https:\/\/github.com\/FX196) \nIn our previous SETI Kaggle notebook we covered the concept of [Energy Detection](https:\/\/www.kaggle.com\/petterma\/seti-energy-detection) where we statistically searched for an anomalous amount of energy present in any window sample of our radio spectrogram data. Now the next step is differentiating the types of signals actually found by our algorithm in a fine resolution file. The simple goal is to: *group similar signals together and seperate ones that are different.*\n\n\nIn this notebook we will explore the usage of RESNET50 to encode the features of hits found by our [Energy Detection algorithm](https:\/\/www.kaggle.com\/petterma\/seti-energy-detection) and clustering them into different categories using K-Means and DBSCAN algorithms.\n","1e2d7b45":"## Comparison\n\nCompared to DBSCAN, K-means had a more controllable number of clusters, and relatively balanced clusters. It also makes sure that all samples get assigned a cluster, whereas DBSCAN has a potential of generating a large number of outliers (in our case, more than 80% were deemed outliers by the algorithm).\nHowever, DBSCAN showed better results when we look at samples in each cluster, although DBSCAN was not able to find a cluster for most samples, the ones it put into a cluster was very similar.\n","ceba03aa":"## Visualize and Shuffle Data\n\nAfter downloading the `5gb` file we want to plot it to examine the data we're working with. We also want to shuffle the data, since the `numpy` file is stacked in order in terms of `frequency` and since this notebook doesn't have nearly enough memory to handle all the preproccessing, we will be taking a random sample of 5000 instead.","cae7cdc3":"## Data Preprocessing\nBecause ResNet-50 is trained on RGB data, we convert our \"images\" which contain power intensities received at different timesteps and frequencies into an RGB image by scaling it to a 0-1 range and using `cv2.cvtColor`.\nWe also resize the image to fit the ResNet input requirements.\nThis creates a 4-d tensor of [num_samples, 32, 256, 3]. ","ededbf03":"## RESNET50 \nRESNET50 Paper | [Link](https:\/\/arxiv.org\/pdf\/1512.03385.pdf) \n\nThe RESNET50 model contains 50 convolution layers with residual skip connections. We won't go into the details of RESNET50, as its a very popular model used widely in the community, however what we're doing differently is **removing the fully connected layers** and using the convolution layers as a method of feature extraction from the original input. Removing the fully connected layers also removes the restriction on our input data that it has to have a shape of (224, 224). The convolutional-only model only requires that both dimensions have greater than 32 elements. Therefore we upsample by a factor of 2 on the time axis to resize our inputs into (32, 256).\n\n\nOur output shape would be [num_samples,2048]. We would then cluster these N-d vectors.  \n\n<p align=\"center\" height=\"200px\"> \n    <img src=\"https:\/\/www.aimspress.com\/fileOther\/PIC\/MBE\/mbe-16-05-165-g004.jpg\">\n<\/p>","d32a6bce":"## DBSCAN\n\nBesides using K-Means, we can also use density-based methods like [DBSCAN](https:\/\/en.wikipedia.org\/wiki\/DBSCAN) for clustering. Instead of taking in a specified number of clusters, DBSCAN looks at sample points within a set radius of other sample points, and clusters them together based on local density. DBSCAN performs well on highly non-convex spaces, which is expected of the extracted feature space from the ResNet-50 model.","1ced9a75":"## Getting Energy Detection Data\n\nSince we want to preform clustering on the Energy Detection algorithm, we can grab the results from the [BL@Scale](http:\/\/seti.berkeley.edu\/bl-scale) project built by the UC Berkeley Seti Research Team. *The data will be in the shape [num_smaples, 16, 256],  axis 1, and 2 represent the spectrograms time and frequency respectively*.  \n\nIn this notebook, we explore some data from [Kepler738B](https:\/\/exoplanets.nasa.gov\/exoplanet-catalog\/5193\/kepler-738-b\/) observed by the Green Bank Telescope, and filtered using our Energy Detection algorithm.\n\n**Note:** The dataset is already linked to the notebook but the direct link is provided just incase.\n\n`https:\/\/storage.googleapis.com\/bl-scale\/GBT_58202_44201_KEPLER738B_fine\/filtered.npy`","45fe6845":"After looking at sampes from each cluster, lets look at more samples from one cluster to see how well the model groups similar signals together.","7b6c3569":"We'll visualize the results from DBSCAN the same way we visualized resultsfrom K-means. We'll plot a sample from each cluster, and take a close look at some of the clusters. Because there are so many clusters, we'll just show the first 10.","c50bb82c":"## Importing Packages\nSince we're using a pretrained model of RESNET50 we'd want to get access to the model weights by importing it from Keras. We also want to use the KMeans and DBSCAN algorithm to preform the clustering. ","5a5e2c3f":"## K-Means Result\n\nHere are the results from our clustering algorithm after encoding the features in `RESNET50` and the results are promising as it shows the model began grouping signals of similar features into the same category. This method can help us reject RFI (radio frequency interferance) or true transient signals."}}