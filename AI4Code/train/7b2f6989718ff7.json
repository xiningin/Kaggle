{"cell_type":{"307f52ff":"code","9192728d":"code","a73e3919":"code","9baca5ae":"code","9e5228b3":"code","7ec31dca":"code","0ed877d2":"code","1a58e8c5":"code","339e7a27":"code","308abfe7":"code","8cdf41f0":"code","60b713bb":"code","67f4c26e":"code","e20d01c1":"code","3347d74d":"code","d8ce9ffb":"code","b3bc8d35":"code","38efcfd6":"code","e81ae2c9":"code","052ad972":"code","e86645f4":"code","96fe3103":"code","b5cba78e":"code","2f75b0cd":"code","2963370f":"code","936944a9":"code","341e82f3":"markdown","2cca7aac":"markdown","a7cfedec":"markdown","e17624ce":"markdown","737558c1":"markdown","76786162":"markdown","296ecd8e":"markdown","333acd00":"markdown","d30c7732":"markdown","38b08dd6":"markdown","78acdd3e":"markdown","33b3bae6":"markdown","75009f27":"markdown","344455dc":"markdown","c1a88bee":"markdown","84d4fd3a":"markdown","2c11c236":"markdown","41dd1e8c":"markdown","b81af323":"markdown"},"source":{"307f52ff":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\nimport time\n\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","9192728d":"data = pd.read_csv('..\/input\/predict-test-scores-of-students\/test_scores.csv')","a73e3919":"data.head()","9baca5ae":"data=data.set_index('student_id')","9e5228b3":"data.info()","7ec31dca":"#display(data.groupby('teaching_method').mean())\ndisplay(data.groupby(['school_type','school_setting','teaching_method']).median())","0ed877d2":"px.histogram(data,x='posttest',color=\"teaching_method\",color_discrete_map={'Standard':'lightgray','Experimental':'darkgray'})","1a58e8c5":"nonstandard = pd.DataFrame(data[data['teaching_method']!='Standard'].groupby('school').count()['n_student']).rename({'n_student':'Non Standard'},axis=1)\nstandard = pd.DataFrame(data[data['teaching_method']=='Standard'].groupby('school').count()['n_student']).rename({'n_student':'Standard'},axis=1)\n\nschools = pd.concat([standard,nonstandard],axis=1)\nschools = schools.replace(np.nan, 0)\nschools['total']=schools['Standard']+schools['Non Standard']\nschools=schools.sort_values(by='total',ascending=False).reset_index()\n#schools","339e7a27":"fig = px.bar(schools, x=\"school\", y=[\"Standard\",'Non Standard'],title=\"Number of Students in each school\")\nfig.show()","308abfe7":"fig = px.sunburst(data.groupby(['school_type','school_setting','teaching_method','gender']).count().reset_index(), \n                  path=['school_setting','school_type','teaching_method'],\n                  color_discrete_map={'Suburban':'black', 'Urban':'gold', 'Rural':'darkblue'},\n                  values='n_student',title=\"Distributtion by setting, type and teaching_method\",\n                  height=500)\nfig.show()","8cdf41f0":"fig = px.scatter(data, x=\"pretest\", y=\"posttest\", trendline=\"ols\",height=500,width=1000,title='Relation between posttest and pretest marks')\nfig.show()","60b713bb":"plt.figure(figsize=(10,10))\nfig = px.scatter(data, x=\"pretest\", y=\"posttest\" ,height=500,width=1000,facet_col='teaching_method',color=\"school_type\",\n                title='Differnece between posttest and pretest marks of children based on School type')\nfig.show()","67f4c26e":"plt.figure(figsize=(10,10))\nfig = px.scatter(data, x=\"pretest\", y=\"posttest\" ,height=500,width=1000,facet_col='teaching_method',color=\"school_setting\",\n                title='Differnece between posttest and pretest marks of children based on School Setting')\nfig.show()","e20d01c1":"plt.figure(figsize=(10,10))\nfig = px.scatter(data, x=\"pretest\", y=\"posttest\" ,height=500,width=1000,color='gender',facet_col=\"teaching_method\",\n                title='Differnece between posttest and pretest marks of children based on gender')\nfig.show()","3347d74d":"plt.figure(figsize=(10,10))\nfig = px.scatter(data, x=\"pretest\", y=\"posttest\" ,height=500,width=1000,facet_col='teaching_method',color=\"lunch\",\n                title='Differnece between posttest and pretest marks of children based on free lunch')\nfig.show()","d8ce9ffb":"fig = px.scatter(data, x=\"n_student\", y=\"posttest\" ,height=400,width=900,color='teaching_method',trendline='lowess',title='Relation between marks and number of student per class')\nfig.show()","b3bc8d35":"from sklearn.preprocessing import LabelEncoder\nto_be_encoded = ['school','school_setting','school_type','classroom','teaching_method','gender','lunch']\nlabel_encoder = LabelEncoder()\ndfs = []\nfor i in to_be_encoded:\n    temp = pd.DataFrame({'Before Encoding':data[i].unique(),'After Encoding':label_encoder.fit_transform(data[i].unique())})\n    dfs.append([temp.sort_values(by=['After Encoding']),i])\n    data[i] = label_encoder.fit_transform(data[i])\nfor i in dfs:\n    print(i[1])\n    display(i[0])\n    print('\\n')","38efcfd6":"X = data.drop('posttest',axis=1)\nY = data['posttest']","e81ae2c9":"Y","052ad972":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX[['pretest','n_student']] = sc.fit_transform(X[['pretest','n_student']])","e86645f4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=52)","96fe3103":"# Lasso regresor\nfrom sklearn.linear_model import Lasso\nlasso=Lasso()\n\n#ElasticNet\nfrom sklearn.linear_model import ElasticNet\nenet=ElasticNet()\n\n#Decision Tree\nfrom sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor()\n\n#KNR\nfrom sklearn.neighbors import KNeighborsRegressor\nknr=KNeighborsRegressor()\n\n#Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingRegressor\ngbr=GradientBoostingRegressor()\n\n#MLP\nfrom sklearn.neural_network import MLPRegressor\nmlp = MLPRegressor(random_state=1, max_iter=500)\n\n# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\n#Random Forest\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\n\n#RandomForest with Grid Search\nn_estimators = [int(x) for x in np.arange(10,500,2)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.arange(1,50,1)]\nmax_depth.append(None)\nmin_samples_split = [int(x) for x in np.arange(1,50,1)]\nmin_samples_leaf = [int(x) for x in np.arange(1,10,1)]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nrf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","b5cba78e":"models = [lr,rf,rf_random,mlp,lasso,enet,gbr,dtr,knr]","2f75b0cd":"from sklearn import metrics\nmodel_acc = []\nmodel_mae = []\nmodel_mse = []\nmodel_rmse = []\nmodel_time = []\n\nfor i in models:\n    start=time.time()\n    i.fit(X_train,Y_train)\n    stop=time.time()\n    pred = i.predict(X_test)\n    h=[]\n    for j in pred:\n        h.append(round(j,0))\n    model_acc.append(round((i.score(X_test, Y_test)*100),2))\n    model_mae.append(round((metrics.mean_absolute_error(Y_test, h)),2))                 \n    model_mse.append(round((metrics.mean_squared_error(Y_test, h)),2))\n    model_rmse.append(round(np.sqrt(metrics.mean_squared_error(Y_test, h)),2))\n    model_time.append(stop-start)\nmodels = pd.DataFrame({'Models':models,'Accuracy':model_acc,'MAE':model_mae,'MSE':model_mse,'RMSE':model_rmse,'Time (s)':model_time})","2963370f":"models = models.sort_values(by=['Accuracy'],ascending=False).reset_index().drop('index',axis=1)\nbest = models['Models'][0]\nmodels['Models']=models['Models'].astype(str).str.split(\"(\", n = 2, expand = True)[0]\nmodels","936944a9":"print('Thus,the best model is',models['Models'][0])\nprint('Accuracy:',models['Accuracy'][0])\nprint('MAE:',models['MAE'][0])\nprint('MSE:',models['MSE'][0])\nprint('RMSE:',models['RMSE'][0])\n\npred = best.predict(X_test)\nh=[]\nfor i in pred:\n    h.append(round(i,0))\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.scatter(Y_test,h)\nplt.subplot(1,2,2)\nsns.distplot((Y_test-h),bins=150,axlabel = \"error\")","341e82f3":"# EDA","2cca7aac":"# <center> Post Test prediction","a7cfedec":"# Importing libraries","e17624ce":"Reading the _csv_ data into a _pandas dataframe_","737558c1":"# Feature Splitting","76786162":"# Test Train split","296ecd8e":"Due the large range of pretest values and n_stufdents (continuous variale), they are scaled down using the standard scaler.<br>\nOthe features are ot scaled down as they are catergorical variables","333acd00":"All the non numeric values are converted to numeric in order for easy deployment of ML models.","d30c7732":"# Model Selection","38b08dd6":"Importing the various neccessary libraries. The ones being used here are:\n* numpy\n* pandas\n* seaborn\n* matplotlib\n* scikit learn\n* matplotlib\n* time","78acdd3e":"Checking the datatype and size of each column","33b3bae6":"Grouping the data by school type, school setting, and tecahing method hen seeing the median for number of students, pretest marks aand postest marks","75009f27":"# Feature Scaling","344455dc":"# Importing data","c1a88bee":"Since each student's student id is unique, the same will be used as index","84d4fd3a":"# One Hot Encoding","2c11c236":"Viewing the data using the *head* function","41dd1e8c":"Selecting the columns to be taken as feature set, _X_, and target value, _Y_","b81af323":"Distribution of marks by teaching method"}}