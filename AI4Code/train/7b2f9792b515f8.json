{"cell_type":{"ecefb3b9":"code","813f75a9":"code","4806be43":"code","451694b8":"code","0209a2e4":"code","ef02c3f5":"code","ad8a05e6":"code","8f4d2c4f":"code","f03b3a87":"code","8d0f2818":"code","cec3e52f":"code","c75118a3":"code","7ee32d4f":"code","9e80cb30":"code","1e362541":"code","f224861c":"code","0e309515":"code","b3367e46":"code","1e2b0e75":"code","0b87ff75":"code","06f9f813":"code","d2220c66":"code","aa8cc0e1":"code","05bf3ff8":"code","96bb3c00":"markdown","05085cfc":"markdown","12c07f39":"markdown","df38e219":"markdown","e31bf490":"markdown","0ea2af10":"markdown","9be585fc":"markdown","39617ce1":"markdown","049ac708":"markdown","07e6dc8b":"markdown","396201b3":"markdown","bcd26d2f":"markdown","6bb1fdce":"markdown","804a2e1a":"markdown","9891df21":"markdown","b8898d65":"markdown"},"source":{"ecefb3b9":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = set(STOPWORDS)\n\nfrom textblob import TextBlob\n\nimport re\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","813f75a9":"# Reading data\ndf=pd.read_csv('\/kaggle\/input\/coronavirus-covid19-tweets-late-april\/2020-04-16 Coronavirus Tweets.CSV')\ndf.head()","4806be43":"# display columns\ndf.columns","451694b8":"# dropping columns\ntweet = df.copy()\ntweet.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\ntweet.head()","0209a2e4":"# filtering data with 'country_code = IN' and 'language = en'\ntweet =tweet[(tweet.country_code == \"IN\") & (tweet.lang == \"en\")].reset_index(drop = True)\ntweet.drop(['country_code','lang'],axis=1,inplace=True)\ntweet.head()","ef02c3f5":"# created_at column\ntweet[\"created_at\"] = tweet[\"created_at\"].apply(lambda i:(int(i.split(\"T\")[1].split(\":\")[0])+int(i.split(\"T\")[1].split(\":\")[1])\/60))","ad8a05e6":"# shape\ntweet.shape","8f4d2c4f":"# check missing values\ntweet.isna().sum()","f03b3a87":"# data preprocessing\nfor i in range(tweet.shape[0]) :\n    tweet['text'][i] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)|(#[A-Za-z0-9]+)\", \" \", tweet['text'][i]).split()).lower()\ntweet['text'].head()","8d0f2818":"fav = tweet[['favourites_count','text']].sort_values('favourites_count',ascending = False)[:5].reset_index()\nfor i in range(5):\n    print(i,']', fav['text'][i],'\\n')","cec3e52f":"retweet = tweet[['retweet_count','text']].sort_values('retweet_count',ascending = False)[:5].reset_index()\nfor i in range(5):\n    print(i,']', retweet['text'][i],'\\n')","c75118a3":"plt.figure(1, figsize=(10,6))\nplt.hist(tweet[\"created_at\"],bins = 24);\nplt.xlabel('Hours',size = 15)\nplt.ylabel('No. of Tweets',size = 15)\nplt.title('No. of Tweets per Hour',size = 15)","7ee32d4f":"def show_wordcloud(data , title = None):\n    wordcloud = WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40).generate(str(data))\n  \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    plt.title(title, size = 25)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()\n\nshow_wordcloud(tweet['text'])","9e80cb30":"stopwords","1e362541":"#Removing Stop Words\ntweet['text'] = tweet['text'].apply(lambda tweets: ' '.join([word for word in tweets.split() if word not in stopwords]))\ntweet['text'].head() ","f224861c":"tweet['sentiment'] = ' '\ntweet['polarity'] = None\nfor i,tweets in enumerate(tweet.text) :\n    blob = TextBlob(tweets)\n    tweet['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        tweet['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        tweet['sentiment'][i] = 'negative'\n    else :\n        tweet['sentiment'][i] = 'neutral'\ntweet.head()","0e309515":"print(tweet.sentiment.value_counts())\nsns.countplot(x='sentiment', data = tweet);","b3367e46":"plt.figure(figsize=(10,6))\nsns.distplot(tweet['polarity'], bins=30)\nplt.title('Sentiment Distribution',size = 15)\nplt.xlabel('Polarity',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.show();","1e2b0e75":"pos = tweet['text'][tweet['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = tweet['text'][tweet['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = tweet['text'][tweet['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","0b87ff75":"count = pd.DataFrame(tweet.groupby('sentiment')['favourites_count'].sum())\ncount.head()","06f9f813":"words = []\nwords = [word for i in tweet.text for word in i.split()]","d2220c66":"freq = Counter(words).most_common(30)\nfreq = pd.DataFrame(freq)\nfreq.columns = ['word', 'frequency']\nfreq.head()","aa8cc0e1":"plt.figure(figsize = (10, 10))\nsns.barplot(y=\"word\", x=\"frequency\",data=freq);","05bf3ff8":"tweet.to_csv('tweet.csv',index=False)","96bb3c00":"## Top 5 most retweeted tweets:","05085cfc":"The following words can be seen: covid, fear, chinese, starving, strategy.","12c07f39":"## Top 5 most favourited tweets:","df38e219":"## Analyzing Text for Sentiment","e31bf490":"# Number of Tweets\/Hour","0ea2af10":"## Using Word Clouds to see the higher fequency words from each sentiment","9be585fc":"# Twitter Sentiment Analysis of Covid-19   \n* Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.   \n* There are worldwide curfews, quarantines and lockdown established to prevent further spread of the virus.   \n* The basic agenda for this project is to use the #tags and other twitter components to analyse the behaviour of the indian citizens towards the overall situation of the lockdown.\n\n\n### Timeline of lockdown :\nPhase 1 : 25 March \u2013 14 April   \nPhase 2 : 15 April \u2013 3 May   \nPhase 3 : 4 May \u2013 17 May   \nPhase 4 : 18 May \u2013 31 May   \nPhase 5 : 1 June \u2013 30 June     \n\nWe will be analyzing the tweets on 16th April,2020 i.e a day after Phase-2 was declared.\n\n### A simple web-app using Streamlit is deployed for displaying the visualizations. : https:\/\/covid19-sentiment-analysis.herokuapp.com\/    \n\nThe source code and dataset for the same can be found here : https:\/\/github.com\/kartik-mohan\/Covid19-Sentiment-Analysis","39617ce1":"# Reading Data","049ac708":"## Sentiment Distribution","07e6dc8b":"# Most frequently appearing words","396201b3":"#### Analyzing text using TextBlob to predict the sentiment of the text and categorise it as 'Positive', 'Negative' or 'Neutral'.","bcd26d2f":"# Conclusion  \nWe can conclude that mostly people have a positive and neutral sentiment towards the start of Lockdown-2.","6bb1fdce":"# Cleaning Data","804a2e1a":"# Importing Packages","9891df21":"# Word Cloud : ","b8898d65":"### Removing Stopwords"}}