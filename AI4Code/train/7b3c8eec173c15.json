{"cell_type":{"66459c1c":"code","ed651565":"code","2e600800":"code","700d3bb8":"code","9ca5307e":"code","4fa53a6a":"code","65fb2651":"code","f9d0f441":"code","be6b99fd":"code","02de47dc":"code","8e7a7c41":"code","673dc6cd":"code","02759131":"code","6759939a":"code","657a7526":"code","27b5a360":"code","b5a5b0b6":"code","892351b1":"markdown","da69e818":"markdown","1fdd077f":"markdown","0d5862e1":"markdown","f1ebab10":"markdown","cfef0997":"markdown","4a82e861":"markdown","c717c63b":"markdown","5a1e476e":"markdown","7411edec":"markdown","8e7b13b6":"markdown","4c4c6c82":"markdown","22c85d0e":"markdown","c7636ec3":"markdown","102db84b":"markdown"},"source":{"66459c1c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats\nimport seaborn as sns\n\nfrom IPython.display import Image","ed651565":"Image(\"..\/input\/d\/matteodefelice\/gordonbush-wind\/gordonbush.png\")","2e600800":"df = pd.read_csv('..\/input\/d\/matteodefelice\/gordonbush-wind\/gordonbush-2016_2018.csv')\ndf.info()","700d3bb8":"x = df[['latitude', 'longitude', 'time', 'u100', 'v100', 'ws']]\nx = x.assign(point = x['latitude'].astype(str) + x['longitude'].astype(str))\nx = x.drop(['latitude', 'longitude'], axis = 1)\nx = x.pivot(index = 'time', columns = ['point'], values = ['u100', 'v100', 'ws'])\nx.columns = x.columns.to_flat_index().str.join('_')\nx = x.reset_index().drop('time', axis = 1)\nprint(x.shape)","9ca5307e":"x.head()","4fa53a6a":"y = df.loc[df['latitude'] == 58.25].loc[df['longitude'] == -4]['ActualGenerationOutput']\ny.shape","65fb2651":"X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.75, random_state = 41)","f9d0f441":"ct = ColumnTransformer( [ (\"numeric\", StandardScaler(), slice(0, 48))  ]  )\nX_train = ct.fit_transform(X_train)\nX_test  = ct.transform(X_test)","be6b99fd":"md = Sequential()\nmd.add(InputLayer(input_shape=(X_train.shape[1],)))\nmd.add(Dense(128, activation='relu'))\nmd.add(Dense(1, activation='linear'))","02de47dc":"md.summary()","8e7a7c41":"stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\nmd.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\nmd.fit(X_train, Y_train, epochs = 100, batch_size = 20, verbose=0,validation_split=0.2, callbacks=[stop])","673dc6cd":"loss, acc = md.evaluate(X_test, Y_test.values, verbose=0)\nprint(\"MAE\", loss, \"MSE:\", acc)","02759131":"y_hat = md.predict(X_test, verbose=0)\nprint(scipy.stats.pearsonr(Y_test.values, y_hat.flatten()))\n# PLOT\nplt.scatter(y = y_hat, x = Y_test.values)\nplt.xlabel('Testing wind generation')\nplt.ylabel('Network testing prediction')\nplt.title('Wind generation on the testing data')\nplt.grid(True)","6759939a":"df_test = pd.read_csv('..\/input\/d\/matteodefelice\/gordonbush-wind\/gordonbush-2019.csv')\nxt = df_test[['latitude', 'longitude', 'time', 'u100', 'v100', 'ws']]\nxt = xt.assign(point = xt['latitude'].astype(str) + xt['longitude'].astype(str))\nxt = xt.drop(['latitude', 'longitude'], axis = 1)\nxt = xt.pivot(index = 'time', columns = ['point'], values = ['u100', 'v100', 'ws'])\nxt.columns = xt.columns.to_flat_index().str.join('_')\nxt = xt.reset_index().drop('time', axis = 1)\n\nyt = df_test.loc[df_test['latitude'] == 58.25].loc[df_test['longitude'] == -4]['ActualGenerationOutput']\nxt.shape, yt.shape","657a7526":"xt = ct.transform(xt)","27b5a360":"y_hat_test = md.predict(xt, verbose=0)\nprint(scipy.stats.pearsonr(yt.values, y_hat_test.flatten()))\n# PLOT\nplt.scatter(y = y_hat_test, x = yt.values)\nplt.xlabel('Testing wind generation')\nplt.ylabel('Network testing prediction')\nplt.title('Wind generation on the testing data')\nplt.grid(True)\n\nfig, axs = plt.subplots(2, 1, figsize=(12, 5))\nbins = np.linspace(0, 80, 20)\n\nsns.histplot(y_hat_test, bins = bins, ax = axs[0], kde = False).set(title='Predicted')\nsns.histplot(yt, bins = bins, ax = axs[1], kde = False).set(title = 'Observed (2019)')\n\nplt.show()","b5a5b0b6":"plt.plot(y_hat_test[0:200])\nplt.plot(yt.values[0:200])","892351b1":"We set an early stopping criterion (using a 20% of validation data) and we use the MAE to train the network. If the validation error does not improve in 20 epochs the training stops. The training takes ~20 seconds. ","da69e818":"# Modelling wind power generation with a neural network\n\nIn this example we use a neural network implemented with `Keras` trained with actual generation data provided by [ENTSO-E](https:\/\/transparency.entsoe.eu\/) and wind speed data from [C3S ERA5](https:\/\/climate.copernicus.eu\/climate-reanalysis)","1fdd077f":"Scaling the features use the same scaler used for the training data.","0d5862e1":"So far, we have trained and tested the network on the wind generation for the period 2016-2018, let's see how it works applying the same network predicting the year 2019. We start loading the data as we did before.","f1ebab10":"The correlation coefficient on the testing dataset seems rather decent, as the scatter plot suggests the network seems able to generalise. ","cfef0997":"Let's see the MAE and the MSE on the testing dataset.","4a82e861":"Splitting the data in training and testing.","c717c63b":"A bit of data wrangling to transform the data frame in a \"wide\" format, with 16x3 columns.","5a1e476e":"Predictors are scaled using a `StandardScaler` ","7411edec":"The hourly data used for training is for the period 2016-2018.","8e7b13b6":"For the output we just need to extract the time-series of generation of any grid point. In fact, in the original data frame, it is repeated for each lat\/lon pair. ","4c4c6c82":"The selected onshore wind farm is in Scotland. In the map we show the location of the 35 turbines (blue triangle) and the 16 grid points used as predictors. For each grid point we have the two components of 100-metre wind (`u100` and `v100`) and the actual wind speed (`ws`).\n","22c85d0e":"Again the correlation coefficient and the scatter plot. The correlation is smaller, and we can see more cases where the network predicts generation while the actual one is zero or very small (~10). Is this maintenance? Or perhaps curtailment? ","c7636ec3":"This network has 6401 trainable parameters, we can add layers or experiment other activation functions or number of neurons. ","102db84b":"We create a neural network with 128 hidden neurons."}}