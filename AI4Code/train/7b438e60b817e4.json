{"cell_type":{"33ddc714":"code","33d0a869":"code","7bbc234d":"code","e301b47e":"code","fed5635d":"code","4ed442d4":"code","c316eefc":"code","a5733316":"code","73566af9":"code","c8ce7e86":"code","c0255818":"code","7492ad2b":"code","33bd0f6f":"code","ac13fd52":"code","94e63f8b":"code","5eb12749":"code","088b6475":"code","7024c0a9":"code","2d574939":"code","aa9de59a":"code","10ba3912":"code","4b2caedb":"code","8d7c1e49":"code","6a73c079":"markdown","a44b8a6e":"markdown","08afe518":"markdown","fd84b191":"markdown","1afeaa18":"markdown"},"source":{"33ddc714":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33d0a869":"train = pd.read_pickle(\"..\/input\/speed-up-reading-csv-to-pickle\/train.pkl\")","7bbc234d":"train = train.head(n=2500000).reset_index(drop = True)","e301b47e":"ids = train.time_id.unique()","fed5635d":"train_ids = ids[0:812]\nval_ids = ids[812:]","4ed442d4":"set(train_ids).intersection(set(val_ids))","c316eefc":"train.head()","a5733316":"val = train.loc[train.time_id.isin(val_ids)]\ntrain = train.loc[train.time_id.isin(train_ids)]\n","73566af9":"del train_ids , val_ids , ids","c8ce7e86":"train.tail()","c0255818":"val.head()","7492ad2b":"print(train.shape)\nprint(val.shape)\nprint(set(train.time_id).intersection(set(val.time_id)))","33bd0f6f":"## Separate Normally and Skewed Distributed Features\nnormal_features = [1 , 2 , 6 , 9 , 20 , 21, 24\n                  ,28 , 35 , 36 , 40 , 43 ,\n                  50 , 51 , 57 , 67 , 69 , 72,\n                  75 , 76 ,82 ,85 , 86 ,\n                  90 , 93 , 94 , 96 , 98 ,\n                  103 , 105 , 109 , 106 , 114 ,116,\n                  125 , 126 , 130 , 133 , 134 ,135 ,139,140 , 141 ,144,146,\n                  141 ,171,\n                  178 , 180 , 185 , 189 , 192 , 194 ,195 ,199,\n                  205 , 206 ,212 ,213 , 217 , 221 ,222,223,\n                  226 , 230 , 239 ,242 ,\n                   252 , 254 ,256 , 259 ,261 , 266 ,273,\n                  276 , 283 , 285 , 290 , 297]\n\n\nnormal_features_list = ['f_'+str(i) for i in normal_features]\n\n\nprint(\"Number of Normally dist features approx are\",len(normal_features_list))\n\nall_features_list = ['f_'+str(i) for i in range(0 , 300)]\nskewed_features_list = list(set(all_features_list).difference(set(normal_features_list)))\nprint(\"Number of Skewed dist features approx are\",len(skewed_features_list))\n## Check for mistakes\nprint(set(skewed_features_list).intersection(set(normal_features_list)))","ac13fd52":"scaler_normal = StandardScaler()\nscaler_outlier = RobustScaler()\n\ntrain[normal_features_list] = scaler_normal.fit_transform(train[normal_features_list])\ntrain[skewed_features_list] = scaler_outlier.fit_transform(train[skewed_features_list])","94e63f8b":"train.head()","5eb12749":"## Always apply scaler transform on validation data separately\nval[normal_features_list] = scaler_normal.transform(val[normal_features_list])\nval[skewed_features_list] = scaler_outlier.transform(val[skewed_features_list])","088b6475":"def pearson_coef(data):\n    return data.corr()['target']['preds']\n\ndef comp_metric(valid_df):\n    return np.mean(valid_df[['time_id', 'target', 'preds']].groupby('time_id').apply(pearson_coef))","7024c0a9":"import os\nimport glob\nfrom joblib import Parallel, delayed\nimport pandas as pd\nimport numpy as np\nimport scipy as sc\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns', 300)","2d574939":"def train_and_evaluate(train , val):\n    params = {\n      'objective': 'rmse',  \n      'boosting_type': 'gbdt',\n      'num_leaves': 100,\n      'n_jobs': -1,\n      'learning_rate': 0.1,\n      'feature_fraction': 0.8,\n      'bagging_fraction': 0.8,\n      'verbose': -1\n    }\n    models = []\n    groups = train['time_id']\n    x_train = train.drop(['row_id', 'target', 'time_id','investment_id'], axis = 1)\n    y_train = train['target']\n    oof_predictions = np.zeros(val.shape[0])\n    x_val = val.drop(['row_id', 'target', 'time_id','investment_id'], axis = 1)\n    y_val = val['target']\n    train_dataset = lgb.Dataset(x_train, y_train)\n    val_dataset = lgb.Dataset(x_val, y_val)\n    model = lgb.train(params = params, \n                      train_set = train_dataset, \n                      valid_sets = [train_dataset, val_dataset], \n                      num_boost_round = 500, \n                      early_stopping_rounds = 50, \n                      verbose_eval = 50)\n        # Add predictions to the out of folds array\n    oof_predictions = model.predict(x_val)\n    val['preds'] = oof_predictions\n    models.append(model)\n    print(\"OOF PCC :\")    \n    print(comp_metric(val))\n    return oof_predictions , models\n","aa9de59a":"oof_predictions , models = train_and_evaluate(train , val)","10ba3912":"del train ,val","4b2caedb":"import ubiquant\nenv = ubiquant.make_env()  \niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    X_test = test_df.drop([\"row_id\",'investment_id'], axis=1)\n    X_test[normal_features_list] = scaler_normal.transform(X_test[normal_features_list])\n    X_test[skewed_features_list] = scaler_outlier.transform(X_test[skewed_features_list])\n    y_preds = [model.predict(X_test, num_iteration=model.best_iteration) for model in models]\n    sample_prediction_df[\"target\"] = sum(y_preds) \/ len(y_preds)\n    env.predict(sample_prediction_df)","8d7c1e49":"sample_prediction_df","6a73c079":"## Validation Strategy \n1. 1013 unique time_ids in train\n2. Using 20% of 1013 approximately last 200 time ids for validation","a44b8a6e":"### Lightgbm Model","08afe518":"## Applying Preprocessing","fd84b191":"## Acknowledgements\n1. https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda#4.-Features\n2. https:\/\/www.kaggle.com\/valleyzw\/ubiquant-lgbm-baseline\n3. https:\/\/www.kaggle.com\/ilialar\/ubiquant-eda-and-baseline","1afeaa18":"## About \n1. From [this](https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda#4.-Features) EDA notebook it is quite evident that there are some features which appears kind off normally distributed , while some features have skewed distributions\n2. I am applying StandardScaler() of sklearn for Features that follows normal distribution and RobustScaler() for Features having skewed distributions as RobustScaler() works best in case of Outliers\n3. For Training and Validation I am not doing anything significant , I am using top 2.5 Million Datapoints for train and validations\n4. In train I am using first 812 ids for train and the remaining approx 200 for validation\n5. If you find this notebook useful please drop an upvote , it will motivate me to produce more work :) , in this competition\n6. Any Feedbacks are much appreciated."}}