{"cell_type":{"d70e265f":"code","0ee994b6":"code","d87ab93f":"code","4f1ba5e2":"code","8965fd15":"code","2b7df1be":"code","35973b40":"code","c77f9581":"code","a77477ce":"code","266e09dc":"code","e981465c":"code","1de92386":"code","4a92de0f":"markdown","2a9f54ec":"markdown","c59f9404":"markdown"},"source":{"d70e265f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.preprocessing as preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nimport os\nbp='\/kaggle\/input\/titanic'\nprint(os.listdir(bp))\n\n# Any results you write to the current directory are saved as output.","0ee994b6":"train_df=pd.read_csv(bp+'\/train.csv')\ntrain_df.head()","d87ab93f":"test_df=pd.read_csv(bp+'\/test.csv')\nIDtest = test_df['PassengerId']\ntest_df.head()\n","4f1ba5e2":"submission_df=pd.read_csv(bp+'\/gender_submission.csv')\nsubmission_df.head()","8965fd15":"print('elements in sub data : ',submission_df.shape)\nprint('elements in train data : ',train_df.shape)\nprint('elements in test data : ',test_df.shape)","2b7df1be":"total = train_df.isnull().sum().sort_values(ascending= False)\npercent= (train_df.isnull().sum()\/train_df.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data=pd.concat([total,percent], axis=1, keys=['total','percent'])\nmissing_train_data","35973b40":"total = test_df.isnull().sum().sort_values(ascending= False)\npercent= (test_df.isnull().sum()\/test_df.isnull().count()*100).sort_values(ascending = False)\nmissing_test_data=pd.concat([total,percent], axis=1, keys=['total','percent'])\nmissing_test_data","c77f9581":"ports = pd.get_dummies(train_df.Embarked , prefix='Embarked')\ntrain = train_df.join(ports)\ntrain.drop(['Embarked'], axis=1, inplace=True)\ntrain.Sex = train_df.Sex.map({'male':0, 'female':1})\ny = train.Survived.copy()\nX = train.drop(['Survived'], axis=1) \nX.drop(['PassengerId'],axis=1,inplace=True)\nX.drop(['Cabin'],axis=1, inplace=True)\nX.drop(['Ticket'],axis=1, inplace=True)\nX.drop(['Name'],axis=1, inplace=True)\n\nX.Age.fillna(X.Age.median(), inplace=True) ","a77477ce":"X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.33, random_state=40)\nprint('The length of training data : ',X_train.shape, y_train.shape)\nprint('The length of testing data : ',X_test.shape, y_test.shape)","266e09dc":"model= LogisticRegression(max_iter=2)\nmodel.fit(X_train, y_train)\n\npredictions= model.predict(X_test)\npredictions","e981465c":"from sklearn.metrics import accuracy_score\nprint('accuracy score of : ',accuracy_score(predictions, y_test))","1de92386":"subs=pd.Series(model.predict(X_test), name='Survived')\nresults= pd.concat([IDtest, subs],axis=1)\nresults.to_csv(\"Final Submission File.csv\",index=False)\nresults.head(5)","4a92de0f":"Check for Missing data","2a9f54ec":"Submissions","c59f9404":"from this cabin and age columns have majority of missing values in training dataset"}}