{"cell_type":{"91f4e293":"code","e866595e":"code","35caa365":"code","018dbd41":"code","65482196":"code","657c19ce":"code","95bf0aa1":"code","8033dcf4":"code","b69e72ea":"code","9e35d84c":"code","ef2e3fd3":"code","a6154218":"code","de23d275":"code","a2c9b7cf":"markdown","e657ebe1":"markdown","9eefe5d3":"markdown","dd4b0aea":"markdown","813cff9b":"markdown","6af2d983":"markdown","55d6f632":"markdown","c44ead48":"markdown","385cd37b":"markdown","6b2bcddd":"markdown"},"source":{"91f4e293":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e866595e":"!pip install tensorflow-datasets\n\n# Import TensorFlow Datasets\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\n\n\n# Helper libraries\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#enable eager execution for image.numpy() method\ntf.enable_eager_execution()\ntf.executing_eagerly()","35caa365":"dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\ntrain_dataset, test_dataset = dataset['train'], dataset['test']","018dbd41":"train_dataset","65482196":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']","657c19ce":"num_train_examples = metadata.splits['train'].num_examples\nnum_test_examples = metadata.splits['test'].num_examples\nprint(\"Number of training examples: {}\".format(num_train_examples))\nprint(\"Number of test examples:     {}\".format(num_test_examples))","95bf0aa1":"print(metadata.supervised_keys)\n\n#Normalize function is getting Images, Label from the mnist metadata.supervised_keys\ndef normalize(images, labels):\n  images = tf.cast(images, tf.float32)\n  images \/= 255\n  return images, labels\n\n# The map function applies the normalize function to each element in the train\n# and test datasets. It is similar to df.apply()\ntrain_dataset =  train_dataset.map(normalize)\ntest_dataset  =  test_dataset.map(normalize)\n\n# The first time you use the dataset, the images will be loaded from disk\n# Caching will keep them in memory, making training faster\ntrain_dataset =  train_dataset.cache()\ntest_dataset  =  test_dataset.cache()","8033dcf4":"tf.executing_eagerly()","b69e72ea":"# Take a single image, and remove the color dimension by reshaping\nfor image, label in test_dataset.take(1):\n  break\nimage = image.numpy().reshape((28,28))\n\n# Plot the image - voila a piece of fashion clothing\nplt.figure()\nplt.imshow(image, cmap=plt.cm.binary)\n\n#Note the reason why we created class_names[] is because the label is a number in Dataset\nplt.xlabel(label)\nplt.colorbar()\nplt.grid(False)\nplt.show()","9e35d84c":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n])","ef2e3fd3":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","a6154218":"BATCH_SIZE = 32\nmodel_1 = model.fit(train_dataset.batch(BATCH_SIZE), epochs=5)","de23d275":"model.save('Fashion_Classifier_Model.h5') ","a2c9b7cf":"Load the dataset and fetch its training and testing data","e657ebe1":"RESOURCE ==========\n* https:\/\/github.com\/tensorflow\/examples\/blob\/master\/courses\/udacity_intro_to_tensorflow_for_deep_learning\/l03c01_classifying_images_of_clothing.ipynb","9eefe5d3":"We will now normalize the Pixel data (28x28 are there) . This will help correct any skew in data","dd4b0aea":"Assemble the NN Model architecture with the no. of Nuerions and the activation function to be used!!!!","813cff9b":"Compile the NN with a Loss Function and a Gradient Descent function and also metrics ","6af2d983":"Refer https:\/\/github.com\/tensorflow\/tensorflow\/issues\/27519 if you are unable to run below code\n\n\nThe below code is taking 1 image as a 28x28 pixel value and then plotting it unsing plty","55d6f632":"Also try out what google did in thier colab!!! \nhttps:\/\/colab.research.google.com\/github\/tensorflow\/examples\/blob\/master\/courses\/udacity_intro_to_tensorflow_for_deep_learning\/l03c01_classifying_images_of_clothing.ipynb#scrollTo=o_Dp8971McQ1","c44ead48":"You get details of DATA from METADATA variable when the mnist is loaded","385cd37b":"1) Naive training\n\nNOTE---\nValueError: Error when checking input: expected flatten_2_input to have 4 dimensions, but got array with shape (28, 28, 1)\n\nThe above error comes when you do - model_1 = model.fit(train_dataset, epochs=5)\n\nTo avoid this make use of BATCH_SIZE\n\nSo .... the 4 dimentions are - \na)BATCH_SIZE\nb)28\nc)28\nd)1\n","6b2bcddd":"Since the class names are not included with the dataset, store them here to use later when plotting the images:"}}