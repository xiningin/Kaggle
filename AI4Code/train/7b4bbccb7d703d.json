{"cell_type":{"7d5fe387":"code","4d5d816b":"code","8f88e8ca":"code","5afdcca7":"code","b93b71c2":"code","a3a9616c":"code","cc9d5fef":"code","0463e118":"code","b5d1d5e8":"code","755547c3":"code","44ed8f21":"code","38ae8d65":"code","034cbe18":"code","4bdc97c3":"code","09e555e4":"code","de2dc7c5":"code","fd8fc1ca":"code","8f6d0fee":"code","f4e352e8":"code","c38523df":"code","c42c1839":"code","2deb8ad6":"code","19581834":"code","d03883b7":"code","1a29fc4d":"code","f3ffe73d":"code","03368d42":"code","88a60ac3":"code","d819b92b":"code","fb44fdbf":"code","da75e1ac":"code","cef79dd7":"code","c03766c3":"code","763c3712":"code","3e96c35e":"code","d6d9b0cd":"code","d1526ea4":"code","5921ca16":"code","566b8c81":"code","7fcfca05":"code","168b0c97":"code","37f29282":"code","c78bcb10":"code","d6f85c1a":"code","845b6978":"code","09528ca7":"code","e97de22c":"code","5a78dd83":"code","f292cfe4":"code","5e612bcc":"code","fafc4a82":"code","eb0edf2d":"code","27a4f895":"code","902ce9ac":"code","9cf0ea20":"code","795862c7":"code","dac52b47":"code","846c83e1":"code","0145cdaa":"code","f81e95d4":"code","8f7486f6":"code","eaa0aa84":"code","3e9debf0":"code","46c1aacc":"code","4d5d9236":"code","05e14c22":"code","3f5e1bba":"code","aecd835e":"code","8b9d550d":"code","e67d1112":"code","4fc10587":"code","81364117":"code","99891127":"code","03da2640":"code","36373409":"code","07fde432":"code","548beda6":"code","0260677a":"code","b076cec5":"code","b0056d04":"code","5116f684":"code","0c089881":"code","596201c4":"code","c84170ad":"code","cd78270c":"code","6a95f2fc":"code","6627b37d":"code","4614cf82":"code","61902d83":"code","70992937":"code","a331e575":"code","d8446dd5":"code","232ac103":"markdown","4a75a10e":"markdown","1848c427":"markdown","72ada9bd":"markdown","ac1b71cd":"markdown","3b0ac2ba":"markdown","67ac1e15":"markdown","603312dd":"markdown","0bf71b8b":"markdown","8ea18247":"markdown","beec997e":"markdown","23df805d":"markdown","f4301717":"markdown","332e2a9b":"markdown","3d830c8d":"markdown","8399881d":"markdown","58775def":"markdown","9fd25637":"markdown","5acff580":"markdown","b34966c3":"markdown","894c4897":"markdown","3be723d2":"markdown","614a0b7e":"markdown","4f00fd81":"markdown","4ea2a16b":"markdown","3074b402":"markdown","27483533":"markdown","bfd4a160":"markdown","5a6cd465":"markdown","6fe80ee0":"markdown","9301fc16":"markdown","e3115f6a":"markdown","8ea3b976":"markdown","a3f84a21":"markdown","677f9a8f":"markdown","4c09f559":"markdown","1ca2bf92":"markdown","2c60e898":"markdown","ededd3c1":"markdown","57bbf583":"markdown","33eb6010":"markdown","51609be5":"markdown","b8326ddf":"markdown","4e7e6f78":"markdown","ffade278":"markdown","fe7e18b5":"markdown","033f4ce1":"markdown","9bc80eb6":"markdown","5db0ab2e":"markdown","cadee29e":"markdown","c88a58b4":"markdown","f370d1dd":"markdown"},"source":{"7d5fe387":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, Lasso\nfrom scipy.stats import norm\nimport warnings\nimport datetime\nimport time\n\n\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\nplt.style.use('ggplot')\nsns.set(font_scale=1.5)\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline","4d5d816b":"#import data file \nboston_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\nboston_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","8f88e8ca":"#f=open('data_description.txt', 'r').print(f.read())\n# To see data_description","5afdcca7":"#show all the colunms,to get view to all its data\npd.set_option('display.max_columns', None)\nboston_train.head(3)","b93b71c2":"pd.set_option('display.max_columns', None)\nboston_test.head(3)","a3a9616c":"boston_train.shape, boston_test.shape","cc9d5fef":"boston_train.info()","0463e118":"boston_test.info()","b5d1d5e8":"pd.set_option('display.max_columns', None)\nboston_train.describe()","755547c3":"#print colunms with object values\nobject_df = boston_train.select_dtypes(include=object)\nobject_df.head()","44ed8f21":"#print colunms with object values\nobject_test_df = boston_test.select_dtypes(include=object)\nobject_test_df.head()","38ae8d65":"#print colunms with numeric type values\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnumeric_df = boston_train.select_dtypes(include=numerics)\nnumeric_df.head()","034cbe18":"numeric_test_df  = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnumeric_test_df  = boston_test.select_dtypes(include=numerics)\nnumeric_test_df.head()","4bdc97c3":"boston_train[['YearBuilt','GarageType','GarageYrBlt']].head(3)","09e555e4":"null_dict_t = dict(boston_test.isnull().sum().sort_values(ascending= True ))","de2dc7c5":"for a, b in null_dict_t.items():\n    if b > 0:\n        print(a + ': ', b)\n    else:\n        pass","fd8fc1ca":"null_dict = dict(boston_train.isnull().sum().sort_values(ascending= True ))","8f6d0fee":"for a, b in null_dict.items():\n    if b > 0:\n        print(a + ': ', b)\n    else:\n        pass","f4e352e8":"#isnull() return True \n#for all the places where the data is missing.\n\n#create an inch-by-inch image\nplt.figure(figsize=(12,8))\n\n#Plot a heatmap for visualization missing data\nsns.heatmap(boston_train.isnull(), cbar=True)\nplt.show()","c38523df":"boston_train.head(2)","c42c1839":"# data description says NA means No Garage and that mean the rest columns of Garage will be the same \ncol_G = ['GarageType','GarageQual' , 'GarageCond', 'GarageFinish']\nfor col in col_G:\n    boston_train[col] = boston_train[col].fillna('NoGarage')","2deb8ad6":"# data description says NA means No Garage and that mean the rest columns of Garage will be the same \ncol_G = ['GarageType','GarageQual' , 'GarageCond', 'GarageFinish']\nfor col in col_G:\n    boston_test[col] = boston_test[col].fillna('NoGarage')","19581834":"# data description says NA means No Basement\n#Replacing the missing data with NoGrage (Since  NA = No Basement ) then all the missing value will be no Basement\ncol_G = ['BsmtQual','BsmtCond' , 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nfor col in col_G:\n    boston_train[col] = boston_train[col].fillna('NoBasement')","d03883b7":"#all of this columns missing it is not missing value it is mean:\n# PoolQC : data description says NA means \"No Pool\"\n# Fence : data description says NA means \"No Fence\"\n# MiscFeature: data description says NA means \"No misc value\"\n# Alley : data description says NA means \"No alley access\"\n# FireplaceQu : data description says NA means \"No Fireplace\"\n\ncol_str = ['PoolQC', 'Fence', 'MiscFeature', 'Alley','Electrical', 'FireplaceQu','MasVnrType' ]\nfor col in col_str:\n    boston_train[col] = boston_train[col].fillna('None')","1a29fc4d":"#all of this columns missing it is not missing value it is mean:\n# PoolQC : data description says NA means \"No Pool\"\n# Fence : data description says NA means \"No Fence\"\n# MiscFeature: data description says NA means \"No misc value\"\n# Alley : data description says NA means \"No alley access\"\n# FireplaceQu : data description says NA means \"No Fireplace\"\n\ncol_str = ['PoolQC','Utilities', 'Fence', 'MiscFeature', 'Alley','Electrical', 'FireplaceQu','MasVnrType', 'Functional', 'Electrical', 'KitchenQual', 'MSSubClass' ]\nfor col in col_str:\n    boston_test[col] = boston_train[col].fillna('None')","f3ffe73d":"# data description says NA means No Basement\n#Replacing the missing data with NoGrage (Since  NA = No Basement ) then all the missing value will be no Basement\ncol_G = ['BsmtQual','BsmtCond' , 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nfor col in col_G:\n    boston_test[col] = boston_test[col].fillna('NoBasement')","03368d42":"col_str = ['PoolQC', 'Fence', 'MiscFeature', 'Alley','Electrical', 'FireplaceQu','MasVnrType' ]\nfor col in col_str:\n    boston_test[col] = boston_test[col].fillna('None')","88a60ac3":"# Replacing missing data with 0 (Since No garage = no cars in such garage.) and no \ncol_num = ['GarageYrBlt','MasVnrArea' ]\nfor col in col_num:\n    boston_train[col] = boston_train[col].fillna(0)\n# group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood    \nboston_train['LotFrontage'] = boston_train.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n# NA values for LotFrontage with mean of column\n#boston_train.LotFrontage.fillna(value=combined['LotFrontage'].mean(), inplace=True)","d819b92b":"#changing the value of month from number to month name to make it more understand \nmonth_map =  {\"MoSold\":     {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \n         7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'} }\n\nboston_train.replace(month_map, inplace=True)","fb44fdbf":"# Replacing missing data with 0 (Since No garage = no cars in such garage.) and no \ncol_num = ['GarageYrBlt','MasVnrArea' ]\nfor col in col_num:\n    boston_test[col] = boston_test[col].fillna(0)\n# group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood    \nboston_test['LotFrontage'] = boston_test.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","da75e1ac":"#changing the value of month from number to month name to make it more understand \nmonth_map =  {\"MoSold\":     {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \n         7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'} }\n\nboston_test.replace(month_map, inplace=True)","cef79dd7":"# Replacing missing data with 0 (Since No garage = no cars in such garage.) and no \ncol_num = ['GarageYrBlt','MasVnrArea', 'BsmtFullBath', 'BsmtHalfBath' , 'BsmtFinSF1', 'TotalBsmtSF', 'BsmtFinSF2', 'GarageCars','GarageArea' , 'BsmtUnfSF']\nfor col in col_num:\n    boston_test[col] = boston_test[col].fillna(0)","c03766c3":"# SaleType : Fill in again with most frequent which is \"WD\"\nboston_test['SaleType'].fillna(boston_test['SaleType'].mode()[0], inplace=True)","763c3712":"plt.subplots(figsize=(10, 5))\n\nboston_train.MoSold.value_counts().plot(kind='bar',color='gray');","3e96c35e":"Over_all_Qual =  {\"OverallQual\":     {1:'VeryPoor', 2:'Poor', 3:'Fair', 4:'BelowAverage', 5:'Average', 6:'Above Average', \n         7:'Good', 8:'VeryGood', 9:'Excellent', 10:'VeryExcellent'} }\n\nboston_train.replace(Over_all_Qual, inplace=True)","d6d9b0cd":"Over_all_Qual =  {\"OverallQual\":     {1:'VeryPoor', 2:'Poor', 3:'Fair', 4:'BelowAverage', 5:'Average', 6:'Above Average', \n         7:'Good', 8:'VeryGood', 9:'Excellent', 10:'VeryExcellent'} }\n\nboston_test.replace(Over_all_Qual, inplace=True)","d1526ea4":"plt.subplots(figsize=(10, 5))\n\nboston_train.OverallQual.value_counts().plot(kind='bar',color='gray');","5921ca16":"Over_all_Cond =  {\"OverallCond\":     {1:'VeryPoor', 2:'Poor', 3:'Fair', 4:'BelowAverage', 5:'Average', 6:'Above Average', \n         7:'Good', 8:'VeryGood', 9:'Excellent', 10:'VeryExcellent'} }\n\nboston_train.replace(Over_all_Cond, inplace=True)","566b8c81":"Over_all_Cond =  {\"OverallCond\":     {1:'VeryPoor', 2:'Poor', 3:'Fair', 4:'BelowAverage', 5:'Average', 6:'Above Average', \n         7:'Good', 8:'VeryGood', 9:'Excellent', 10:'VeryExcellent'} }\n\nboston_test.replace(Over_all_Cond, inplace=True)","7fcfca05":"plt.subplots(figsize=(10, 5))\n\nboston_train.OverallCond.value_counts().plot(kind='bar',color='gray');","168b0c97":"#Some of the non-numeric features are stored as numbers. They should be converted to strings.\n#train data frame\nboston_train['MSSubClass'] = boston_train['MSSubClass'].apply(str)\nboston_train['YrSold'] = boston_train['YrSold'].apply(str)\nboston_train['MoSold'] = boston_train['MoSold'].apply(str)\n# Changing OverallCond into a categorical variable\nboston_train['OverallCond'] = boston_train['OverallCond'].astype(str)\nboston_train['OverallQual'] = boston_train['OverallQual'].astype(str)","37f29282":"#Some of the non-numeric features are stored as numbers. They should be converted to strings.\n#test data frame\nboston_test['MSSubClass'] = boston_test['MSSubClass'].apply(str)\nboston_test['YrSold'] = boston_test['YrSold'].apply(str)\nboston_test['MoSold'] = boston_test['MoSold'].apply(str)\n# Changing OverallCond into a categorical variable\nboston_test['OverallCond'] = boston_test['OverallCond'].astype(str)\nboston_test['OverallQual'] = boston_test['OverallQual'].astype(str)","c78bcb10":"#replace the all missing values in colunms MSZoning with RM\nboston_test.MSZoning.replace(np.nan,'RM', inplace=True, regex=True)","d6f85c1a":"#replace the NaN value in columns 'Exterior1st','Exterior2nd' with \"other\"\ncol_G = ['Exterior1st','Exterior2nd']\nfor col in col_G:\n    boston_test[col] = boston_test[col].fillna('Other')","845b6978":"boston_test['MSZoning'] = boston_test['MSZoning'].astype(str)","09528ca7":"boston_test.GarageCars.replace(np.nan,0, inplace=True, regex=True)\nboston_test.GarageArea.replace(np.nan,0, inplace=True, regex=True)","e97de22c":"#check if there any missing values test data frame\nnull_dict_t = dict(boston_test.isnull().sum())\n\nfor a, b in null_dict_t.items():\n    if b > 0:\n        print(a + ': ', b)\n    else:\n        pass","5a78dd83":"#check if there any missing values\nnull_dict= dict(boston_train.isnull().sum())\nfor a, b in null_dict.items():\n    if b > 0:\n        print(a + ': ', b)\n    else:\n        pass","f292cfe4":"for col in list(boston_train.corr()[['SalePrice']].sort_values('SalePrice', ascending=False).index.values):\n    \n    if col != 'SalePrice':\n        plt.figure()\n        plt.ylabel('Sale Price')\n        plt.xlabel(col)\n        plt.scatter(boston_train[col], boston_train['SalePrice']);\n    else:\n        pass","5e612bcc":"sns.lmplot(x='GrLivArea', y='SalePrice', hue='BldgType', \n           aspect=2,\n           fit_reg=False,\n           data=boston_train);","fafc4a82":"# remove the outliner in columns GrLiveArea\nboston_train.drop(boston_train[boston_train['SalePrice'] > 500000].index, inplace=True)\n\n# remove the outliner in columns GrLiveArea\nboston_train.drop(boston_train[(boston_train['GrLivArea'] > 4000) ].index, inplace=True)\n","eb0edf2d":"sns.lmplot(x='GrLivArea', y='SalePrice', hue='BldgType', \n           aspect=2,\n           fit_reg=False,\n           data=boston_train);","27a4f895":"# dist plot shows skewness in the target variable 'SalePrice'\nfig, ax = plt.subplots(figsize=(10,5))\nax = sns.distplot(boston_train['SalePrice'], kde=True, bins=20);","902ce9ac":"# Set the default matplotlib figure size:\nfig, ax = plt.subplots(figsize=(20, 21))   \n\n# x and y labels.\nax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=17, rotation=60)\nax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=17, rotation=0)\n\n\nsns.heatmap(boston_train.corr(), ax = ax, fmt='.1f', annot=True)\nplt.title('Correlation of licenses and accidents')\n\n#show the plot and get  \nplt.show()","9cf0ea20":"#Find the top 12 Features Most Correlated With Sale Price\ncols = boston_train.corr().nlargest(12, 'SalePrice').index","795862c7":"# HeatMap for the 12 fr\nplt.subplots(figsize=(20,20))\nsns.set(font_scale=1.25)\nsns.heatmap(boston_train[cols].corr() ,annot=True)","dac52b47":"corr = boston_train.corr().nlargest(12, 'SalePrice')\n\nplt.subplots(figsize=(16, 9))\nsns.barplot(x=corr.index, y=corr['SalePrice'])\n\nplt.title('Top 12 Features Most Correlated With Sale Price', fontsize=24)\nplt.xlabel('Feature', fontsize=18)\nplt.ylabel('Correlation Sale Price', fontsize=18)\n\nplt.xticks(rotation=60)\nplt.tight_layout()","846c83e1":"boston_train.head(1)","0145cdaa":"var = 'OverallQual'\nplt.subplots(figsize=(15,15))\nsns.boxplot(x=boston_train[var], y=boston_train['SalePrice'])","f81e95d4":"#plot size \nplt.subplots(figsize=(16, 9))\n\nhood_prices=pd.DataFrame(boston_train.groupby('Neighborhood')['SalePrice'].mean())\nsns.barplot(x=hood_prices.index, y=hood_prices['SalePrice'],color='gray')\n\n\nplt.title('Most Sale Neighbourhood', fontsize=20)\nplt.xlabel('Neighbourhood', fontsize=15)\nplt.ylabel('Sale Price', fontsize=15)\nplt.xticks(rotation=60)\nplt.tight_layout()\n# plt.savefig('figures\/Neighborhood_vs_SalePrice_boxplot.png')","8f7486f6":"plt.subplots(figsize=(16, 9))\n\nboston_train.HouseStyle.value_counts().plot(kind='bar',color='gray');\nplt.title('Style of dwelling', fontsize=20)\nplt.xlabel('House Style', fontsize=20)\nplt.ylabel('Number of Houses', fontsize=20)\nplt.xticks(rotation=60,fontsize=20)","eaa0aa84":"plt.subplots(figsize=(16, 9))\n\nhood_prices=pd.DataFrame(boston_train.groupby('HouseStyle')['SalePrice'].mean())\nsns.barplot(x=hood_prices.index, y=hood_prices['SalePrice'],color='gray')\n\nplt.title('The Most House Style correlated with Sale Price', fontsize=20)\nplt.xlabel('House Style', fontsize=20)\nplt.ylabel('Sale Price', fontsize=20)\nplt.xticks(rotation=60,fontsize=20)\nplt.tight_layout()\n# plt.savefig('figures\/Neighborhood_vs_SalePrice_boxplot.png')","3e9debf0":"fig, ax = plt.subplots(figsize=(10,5))\nax.scatter(boston_train['SalePrice'], boston_train['GrLivArea'])\nax.set_xlabel('Buildings Sale Price')\nax.set_ylabel('living area square feet')\nplt.show()","46c1aacc":"# sklearn imports\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, KFold\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error","4d5d9236":"boston_test.shape, boston_train.shape","05e14c22":"#make copy and dumies for train data\n\ntrain_copy = boston_train\ntrain_copy = pd.get_dummies(train_copy)\ntrain_copy.shape","3f5e1bba":"#make copy and dumies for test data\n\ntest_copy = boston_test\ntest_copy = pd.get_dummies(test_copy)\ntest_copy.shape","aecd835e":"# to show the missing colunms that are not in test_copy \n\nset(test_copy.columns).symmetric_difference(set(train_copy.columns))","8b9d550d":"#Fill all the missing colunms with 0 values \n#to get the same number of colunms in both data \n#also will add SalePrice columns in test , will deleted it next\nlist_not_test = list(set(train_copy.columns) - set(test_copy.columns))\n\nfor col in list_not_test:\n    test_copy[col] = 0","e67d1112":"#check that the both data have the same number of columns \ntest_copy.shape, train_copy.shape","4fc10587":"#delete the SalePrice and 'Exterior1st_Other','MSSubClass_150' in test_copy \ntest_copy.drop(['SalePrice'],axis=1,inplace=True)","81364117":"test_copy.drop(['Exterior1st_Other'],axis=1,inplace=True)","99891127":"set(test_copy.columns).symmetric_difference(set(train_copy.columns))","03da2640":"#creating matrices for sklearn:\n\ny = train_copy['SalePrice'] \nX = train_copy.drop('SalePrice',axis=1)#will take all colnums from train exsecpt SalePrice columns\n","36373409":"#check after delete SalePrice \nX.shape,test_copy.shape","07fde432":"#split the data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","548beda6":"#Instantiate StandardScaler\nss = StandardScaler()\n\n#fit\nss.fit(X_train)\n\n#transform\nX_train_sc = ss.transform(X_train)\nX_test_sc = ss.transform(X_test)","0260677a":"from sklearn.model_selection import GridSearchCV\nscore_calc = 'neg_mean_squared_error'","b076cec5":"def get_best_score(grid):\n    \n    best_score = np.sqrt(-grid.best_score_)\n    print(best_score)    \n    print(grid.best_params_)\n    print(grid.best_estimator_)\n    \n    return best_score","b0056d04":"\nlinreg = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\ngrid_linear = GridSearchCV(linreg, parameters, cv=5, verbose=1 , scoring = score_calc)\ngrid_linear.fit(X_train, y_train)\n\nsc_linear = get_best_score(grid_linear)","5116f684":"linreg_sc = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\ngrid_linear_sc = GridSearchCV(linreg_sc, parameters, cv=5, verbose=1 , scoring = score_calc)\ngrid_linear_sc.fit(X_train_sc, y_train)\n\nsc_linear_sc = get_best_score(grid_linear_sc)","0c089881":"linregr_all = LinearRegression()\n\nlinregr_all.fit(X, y)\npred_linreg_all = linregr_all.predict(X_test)\npred_linreg_all[pred_linreg_all < 0] = pred_linreg_all.mean()","596201c4":"from sklearn.neighbors import KNeighborsRegressor\n\nparam_grid = {'n_neighbors' : [2,3,4,5,6,7,10,15] ,    \n              'weights' : ['uniform','distance'] ,\n              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n\ngrid_knn = GridSearchCV(KNeighborsRegressor(), param_grid, cv=10, refit=True, verbose=1, scoring = score_calc)\ngrid_knn.fit(X_train_sc, y_train)\n\nsc_knn = get_best_score(grid_knn)","c84170ad":"pred_knn = grid_knn.predict(X_test_sc)","cd78270c":"\nparam_grid = { 'max_depth' : [7,8,9,10] , 'max_features' : [11,12,13,14] ,\n               'max_leaf_nodes' : [None, 12,15,18,20] ,'min_samples_split' : [20,25,30],\n                'presort': [False,True] , 'random_state': [5] }\n            \ngrid_dtree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=8, refit=True, verbose=1, scoring = score_calc)\ngrid_dtree.fit(X_train_sc, y_train)\n\nsc_dtree = get_best_score(grid_dtree)\n\npred_dtree = grid_dtree.predict(X_test)","6a95f2fc":"from sklearn.ensemble import RandomForestRegressor\n\nparam_grid = {'min_samples_split' : [3,4,5,7,10], 'n_estimators' : [70,100], 'random_state': [5] }\ngrid_rf = GridSearchCV(RandomForestRegressor(), param_grid, cv=7, refit=True, verbose=1, scoring = score_calc)\ngrid_rf.fit(X_train_sc, y_train)\n\nsc_rf = get_best_score(grid_rf)\nsc_rf","6627b37d":"from sklearn.linear_model import Lasso\n\nlasso = Lasso()\nparameters = {'alpha':[1e-03,0.01,0.1,0.5,0.8,1], 'normalize':[True,False], 'tol':[1e-06,1e-05,5e-05,1e-04,5e-04,1e-03]}\ngrid_lasso = GridSearchCV(lasso, parameters, cv=5, verbose=1, scoring = score_calc)\ngrid_lasso.fit(X_train_sc, y_train)\n\nsc_lasso = get_best_score(grid_lasso)\n\npred_lasso = grid_lasso.predict(X_test)","4614cf82":"from sklearn.linear_model import Ridge\n\nridge = Ridge()\nparameters = {'alpha':[0.001,0.005,0.01,0.1,0.5,1], 'normalize':[True,False], 'tol':[1e-06,5e-06,1e-05,5e-05]}\ngrid_ridge = GridSearchCV(ridge, parameters, cv=5, verbose=1, scoring = score_calc)\ngrid_ridge.fit(X_train, y_train)\n\nsc_ridge = get_best_score(grid_ridge)","61902d83":"ridge_sc = Ridge()\nparameters = {'alpha':[0.001,0.005,0.01,0.1,0.5,1], 'normalize':[True,False], 'tol':[1e-06,5e-06,1e-05,5e-05]}\ngrid_ridge_sc = GridSearchCV(ridge_sc, parameters, cv=10, verbose=1, scoring = score_calc)\ngrid_ridge_sc.fit(X_train_sc, y_train)\n\nsc_ridge_sc = get_best_score(grid_ridge_sc)","70992937":"# it seems we're not getting any better results than these, lets export the csv and get our score on kaggle\npred_rf = grid_ridge.predict(test_copy)\nscoring_df = pd.concat((pd.Series(boston_test.Id, name='Id'), pd.Series(pred_rf, name='SalePrice')), axis=1)\nscoring_df.head(10)","a331e575":"scoring_df.to_csv(\"house_price_submission.csv\", index=False)","d8446dd5":"scoring_df.tail(5)","232ac103":"![images.jpg](attachment:images.jpg)","4a75a10e":"# * Basic-EDA","1848c427":"#### 4. Briefly describe the data\n\nTake your time looking through the data and briefly describe the data in the markdown cell below. Note things about what the columns might mean, and the general information that is conveyed in the dataframe.\n\nbosten train data:\n\n\nbosten test data:","72ada9bd":"Yes there are some obvious issues in couple of columns.\n\n1- 14 columns : have NaN values were acctualy do have values which is NA \n   we need to replace each NaN with NA\n\n2- MasVnrArea and GarageYrBlt : has 8 and 81 missing values , we might replace them with mean or medin\n    \n3- Electrical: have one NaN vaule.","ac1b71cd":"There is no missing values in train and test data frames","3b0ac2ba":"#### 2- BsmtCond: Evaluates the general condition of the basement\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical - slight dampness allowed\n       Fa\tFair - dampness or some cracking or settling\n       Po\tPoor - Severe cracking, settling, or wetness\n       NA\tNo Basement","67ac1e15":"# K Nearest Neighbors","603312dd":"![Screen%20Shot%202020-03-30%20at%202.47.59%20AM.png](attachment:Screen%20Shot%202020-03-30%20at%202.47.59%20AM.png)\n\nwith Decision Tree","0bf71b8b":"### Top 12 Features Most Correlated With Sale Price\nshow the top 12 features correlated with SalePrice form the most Highest correlated to the lowest ","8ea18247":"#### Observation: ","beec997e":"##### Investigate the relationship between YearBuilt, GarageType and GarageYrBlt","23df805d":"Model tuning and selection with GridSearchCV","f4301717":"### RandomForestRegressor\n","332e2a9b":"![2020-03-30%20054625.png](attachment:2020-03-30%20054625.png)\nwith Ridge regression using RidgeCV","3d830c8d":"##  print output file","8399881d":"### High Light:\n    \n1. probably won't begin with the height of the basement ceiling.\n2. the proximity to an east-west railroad\n3. proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.","58775def":"\\Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.","9fd25637":"OverallQual: Rates the overall material and finish of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\n       5\tAverage\n       4\tBelow Average\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\t\nOverallCond: Rates the overall condition of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\t\n       5\tAverage\n       4\tBelow Average\t\n       3\tFair\n       2\tPoor\n       1\tVery Poor","5acff580":"### 2. Display data","b34966c3":"#### Observation and Recomdation:\nRemove all the buildings have area more than 4000 square feet\n\nRemove all bulidings that cost more than 500,000","894c4897":"### 1. Read In data House Prices","3be723d2":"## **Datasets Description**","614a0b7e":"# Data Import and Cleaning","4f00fd81":"## String features","4ea2a16b":"###### boston_train data frame ","3074b402":"# Decision Tree","27483533":"###### boston_test data frame ","bfd4a160":"### 3. Columns that have null values:","5a6cd465":"## Numerical features","6fe80ee0":"### Show the most  sale neighbourhood","9301fc16":"# LASSO regression using LassoCV","e3115f6a":"###### boston_train data frame ","8ea3b976":"### HeatMap","a3f84a21":"**We notic that the train and test data dont have the same numbers of colunms **","677f9a8f":"### Replace colunms values","4c09f559":"from above result we find GarageYrBlt , MasVnrArea have object type values , they need to be change to numrical value\n","1ca2bf92":"## Look for outliers","2c60e898":"## Linear Regression","ededd3c1":"#### 1- GarageType: Garage location\n\t\t\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage","57bbf583":"### Check if there any missing values","33eb6010":"from above result we find GarageYrBlt , MasVnrArea have object type values , they need to be change to numrical value\n","51609be5":"## Scikit-learn basic regression models and comparison of results\u00b6\nTest simple sklearn models and compare by metrics\n\nWe test the following Regressors from scikit-learn:\n\n* LinearRegression\n\n* Ridge\n\n*  Lasso\n\n* Stochastic Gradient Descent\n\n* DecisionTreeRegressor","b8326ddf":"# Ridge regression using RidgeCV","4e7e6f78":"### Show most correlated house style with saled price \n\n       1Story\tOne story\n       1.5Fin\tOne and one-half story: 2nd level finished\n       1.5Unf\tOne and one-half story: 2nd level unfinished\n       2Story\tTwo story\n       2.5Fin\tTwo and one-half story: 2nd level finished\n       2.5Unf\tTwo and one-half story: 2nd level unfinished\n       SFoyer\tSplit Foyer\n       SLvl\tSplit Level","ffade278":"![%D8%AA%D8%B9%D9%84%D9%8A%D9%82%20%D8%AA%D9%88%D8%B6%D9%8A%D8%AD%D9%8A%202020-03-30%20055640.png](attachment:%D8%AA%D8%B9%D9%84%D9%8A%D9%82%20%D8%AA%D9%88%D8%B6%D9%8A%D8%AD%D9%8A%202020-03-30%20055640.png)\nwith RandomForestRegressor","fe7e18b5":"### Show all columns of object type","033f4ce1":"###### boston_test data frame ","9bc80eb6":"Group member Names:\n    \n    1-saad alsharef\n    2-Mohammed saud\n    3-howida saeed","5db0ab2e":"The plot shows that the target variable 'SalePrice' is not normal distribution","cadee29e":"### Show the most  House Style","c88a58b4":"### Show all columns of numeric type","f370d1dd":"#### 4b. Are there any obvious issues with the observations?"}}