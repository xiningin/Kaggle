{"cell_type":{"ac31ecc3":"code","c35f211d":"code","6c2f178e":"code","5121d1cc":"code","c0aaa76a":"code","c4728ce7":"code","d5d6b2a3":"code","b2eeaa24":"code","d2faa323":"code","67cde064":"code","d39d2f26":"code","e211cf61":"code","75580c3a":"code","032552e3":"code","58eb96af":"code","4774e538":"code","ca99b967":"code","bc105e27":"code","fc14f117":"code","a9e01c81":"code","21daae81":"code","ddb87003":"code","bce471e6":"code","9b4fd8f5":"code","5b15ff43":"code","3e66deb3":"code","765e4a15":"code","5d6ad667":"code","f38edfad":"code","2d47a84b":"code","05f8ccd3":"code","5a20fe6f":"code","72cc1f23":"code","8eb459a3":"code","9c432ba5":"code","4fbf5386":"code","2ff7f049":"markdown","9d8345e2":"markdown","d244ec74":"markdown","e798b2f4":"markdown","f994cdf4":"markdown","fec19e22":"markdown","3ac21bb9":"markdown","89766049":"markdown","125450f2":"markdown","af8a9195":"markdown","4b2cab2f":"markdown","fc95faa8":"markdown","f359bd21":"markdown"},"source":{"ac31ecc3":"import os\nprint(os.listdir('..\/input\/fruits-123\/fruits_classification'))","c35f211d":"dataPath = '..\/input\/fruits-123\/fruits_classification'","6c2f178e":"# Import Libraries\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom sklearn.metrics import classification_report, confusion_matrix","5121d1cc":"import numpy as np\nimport cv2\nimport glob\nimport random\n\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt","c0aaa76a":"def prepare_image(filepath):\n    img = cv2.imread(filepath)\n    img_resized = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img_result  = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n    return img_result","c4728ce7":"dirList = glob.glob(dataPath+'\/*') # list of all directories in dataPath\ndirList.sort() # sorted in alphabetical order\nprint(dirList)","d5d6b2a3":"Y_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*')\n    [Y_data.append(i) for file in fileList]\nprint(Y_data)","b2eeaa24":"X_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*')\n    [X_data.append(prepare_image(file)) for file in fileList]\nX_data = np.asarray(X_data)\nprint(X_data.shape)","d2faa323":"## random shuffle\nfrom sklearn.utils import shuffle\nX_data, Y_data = shuffle(X_data, Y_data, random_state=0)","67cde064":"print(Y_data)","d39d2f26":"testNum = random.randint(0,len(X_data)-1)\nprint(testNum)\nplt.imshow(X_data[testNum])","e211cf61":"num_classes = len(dirList) \nlabels = [dir.replace(dataPath+\"\/\", \"\") for dir in dirList]\nprint(labels)","75580c3a":"equilibre = []\n[equilibre.append(Y_data.count(i)) for i in range(len(dirList))]\nprint(equilibre)","032552e3":"# plot the circle of value counts in dataset\nplt.figure(figsize=(5,5))\nmy_circle=plt.Circle( (0,0), 0.5, color='white')\nplt.pie(equilibre, labels=labels, colors=['red','green','blue','yellow'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","58eb96af":"# Data Normalisation\nX_train = X_data \/ 255.0\nprint(X_train.shape)","4774e538":"# One-hot encoding\nY_train = to_categorical(Y_data)\nprint(Y_train.shape)","ca99b967":"input_shape = (224, 224, 3)","bc105e27":"# use MobieNet V2 as base model\nnet=MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) \n\n# add Fully-Connected Layers to Model\nx=net.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) # FC layer 1\nx=Dense(64,activation='relu')(x)   # FC layer 2\nout=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=net.input,outputs=out)\n\nmodel.summary()","fc14f117":"# show layers no. & name\nfor i,layer in enumerate(model.layers):\n    print(i,layer.name)","a9e01c81":"# set extra layers to trainable \nfor layer in model.layers[:155]:\n    layer.trainable=False\nfor layer in model.layers[155:]:\n    layer.trainable=True","21daae81":"model.summary()","ddb87003":"# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","bce471e6":"# Train Model (target is loss <0.01)\nbatch_size= 16\nnum_epochs = 20\nhistory = model.fit(X_train,Y_train,batch_size=batch_size,epochs=num_epochs) #,validation_data=(X_valid,Y_valid))","9b4fd8f5":"# Save Model\nmodel.save('tl_fruits.h5')","5b15ff43":"def classify_fruits(imageFile):\n    testData = prepare_image(imageFile).reshape(1,224,224,3)\n    testData = testData \/ 255.0\n    predictions = model.predict(testData)\n    maxindex = int(np.argmax(predictions))\n    print(predictions[0][maxindex],labels[maxindex])\n    return labels[maxindex]","3e66deb3":"imageFile=dirList[0]+'\/Apple 1.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","765e4a15":"imageFile=dirList[1]+'\/cene00001.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","5d6ad667":"imageFile=dirList[2]+'\/Kiwi A001.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","f38edfad":"imageFile=dirList[3]+'\/Orange001.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","2d47a84b":"imageFile=dirList[4]+'\/Pitaya001.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","05f8ccd3":"imageFile=dirList[5]+'\/Tamotoes001.png'\nplt.imshow(prepare_image(imageFile))\nclassify_fruits(imageFile)","5a20fe6f":"Y_pred = model.predict(X_train)\ny_pred = np.argmax(Y_pred,axis=1)\n#y_label= [labels[k] for k in y_pred]\ncm = confusion_matrix(Y_data, y_pred)\nprint(cm)","72cc1f23":"print(classification_report(Y_data, y_pred, target_names=labels))","8eb459a3":"TP = cm[1, 1]\nTN = cm[0, 0]\nFP = cm[0, 1]\nFN = cm[1, 0]\nspecificity = TN \/ float( TN + FP)\nsensitivity = TP \/ float(FN + TP)\nprint('Specificity:',specificity)\nprint('Sensitivity:',sensitivity)","9c432ba5":"import itertools\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n        \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","4fbf5386":"plot_confusion_matrix(cm, \n                      normalize=False,\n                      target_names = labels,\n                      title=\"Confusion Matrix, not Normalized\")","2ff7f049":"### check 1 picture per category","9d8345e2":"## Save Model","d244ec74":"## Test Model","e798b2f4":"## Data Normalisation","f994cdf4":"### shuffle data","fec19e22":"# Worms Classification\n## Transfer Learning : Mobilenet V2","3ac21bb9":"### set FC-layers to trainable","89766049":"## Transfer Learning setup","125450f2":"## Load MobileNet v2 model & add FC-layers","af8a9195":"## Prepare Data","4b2cab2f":"## Confusion Matrix report","fc95faa8":"## Plot Confusion Matrix","f359bd21":"## Dataset = worms4 (cabbage_worm, corn_earworm, cutworm, fall_armyworm)"}}