{"cell_type":{"c2f2d9f2":"code","ebc460cb":"code","7700d744":"code","e320a639":"code","cc95c6d1":"code","d5385133":"code","31ff9fa9":"code","505f5bf8":"code","dd8008de":"code","1f9bcd86":"code","0564899f":"code","eb703f49":"code","78c41564":"code","4da9661b":"code","1a01e9cb":"code","d95b5f71":"code","d98eab59":"code","9b03f4b8":"code","6e82704a":"code","d770f207":"code","b20188d4":"code","8608aee7":"code","a8a5de28":"code","08cffa45":"code","ad4d6e00":"code","da48b67f":"code","70407f99":"code","72096a8f":"markdown","ee340b8a":"markdown","e5dae28d":"markdown","bd1328c7":"markdown","47f17ad2":"markdown","e8bda164":"markdown","18c1f816":"markdown","b2f12755":"markdown","c5d2b3e5":"markdown","fe925db8":"markdown","0ead9f39":"markdown","f3dd7d5f":"markdown","206ce97d":"markdown"},"source":{"c2f2d9f2":"import seaborn as sns\nimport numpy as np\nimport numpy.random as rnd\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline","ebc460cb":"n = 100\nA = np.random.normal(0,1,(n,n))\nB = A.copy()\n# Dot product implemented in pure Python\ndef dot_py(A,B):\n    N,D = A.shape\n    D,M = B.shape\n    out = np.zeros((N,D))\n    for n in range(N):\n        for m in range(M):\n            for d in range(D):\n                out[n,m] += A[n,d]*B[d,m]\n    return out","7700d744":"### Univariate normal (Gaussian) distribution\n\n\nX = rnd.normal(loc=0, scale=4, size=550)\n\n#or using scipy package\nfrom scipy.stats import norm \n\nX = norm.rvs(loc=0,scale=4,size=550)\n\nplt.figure(figsize=(8,4))\n# Histogram plot \nplt.hist(X,bins=30, rwidth=0.9, alpha=0.5, density=True)\nplt.grid()\n_=sns.kdeplot(X, color='r')\n","e320a639":"### Numpy Usage Example: Univariate normal (Gaussian) PDF","cc95c6d1":"def normal_pdf(X, mean=0, sigma=1):\n    return 1.\/np.sqrt(2*np.pi*sigma**2)*np.exp(-(X - mean)**2\/(2*sigma**2))","d5385133":"X = np.linspace(-5,8,100)\nplt.figure(figsize=(6,3))\nplt.grid()\nplt.axvline(1,c='r',ls='--', label='$\\\\mu$')\n_=plt.plot(X,normal_pdf(X,1,2),label='pdf')\n_=plt.legend()","31ff9fa9":"X = np.linspace(-5,8,100)\nplt.figure(figsize=(6,3))\nplt.grid()\nplt.axvline(1,c='r',ls='--', label='$\\\\mu$')\n_=plt.plot(X,normal_pdf(X,1,2),label='pdf')\n_=plt.legend()","505f5bf8":"m = 1\nsigma = 4\nprint(normal_pdf(X,m,sigma)[:3], norm.pdf(X,m,sigma)[:3]) # print the values just for first three elements","dd8008de":"assert np.allclose(normal_pdf(X,m,sigma), norm.pdf(X,m,sigma)) # make sure all of the results are the same","1f9bcd86":"# Define some means and standart deviations\nmu = [-5,0,5]\nK = len(mu)\nsigma2 = np.power(K*[2], np.arange(1,K+1))\nprint(mu,sigma2)","0564899f":"import matplotlib as mpl\n# set some global plot settings\nmpl.rcParams['lines.linewidth'] = 2\nmpl.rcParams['figure.figsize'] = (10,8)\n\n# define the grid of the canvas (plot) \nfig,axs = plt.subplots(K,K,sharey=True,figsize=(8,8))\n\nX = np.linspace(-10,10,100) # define some testing values to calculate Gaussian PDF\nK = len(mu)\nfor i in range(K):\n    for j in range(K):\n        ax = axs[i,j] \n        m = mu[i]\n        s2 = sigma2[j]\n        pdf = normal_pdf(X,mean=m,sigma=s2)\n        ax.plot(X,pdf, label=f'$\\mu$ = {m} \\n$\\sigma^2$ = {s2}')\n        ax.axvline(m,ls='--',c='g')\n        ax.grid()\n        ax.legend(loc=1)\naxs[2,1].set_xlabel('$x$',fontsize=15)\naxs[1,0].set_ylabel('$pdf(x)$', fontsize=15)\nfig.tight_layout()","eb703f49":"theta_real = 0.35 # true theta value for the Binomial distribution\\","78c41564":"# Observed data\n\ntrials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150, 210, 270, 330] # number of trials\ndata = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48, 78, 96, 118]  # number of the observed heads","4da9661b":"from scipy.stats import beta\n\nalphas = [1, .1, 5]\nbetas = [1, .1, 5]\n\nx = np.linspace(0, 1, 200)\nK = len(alphas)\nfig, axs = plt.subplots(K, K, sharex=True, sharey=True, figsize = (10,10))\nfor i in range(K):\n    for j in range(K):\n        alpha = alphas[i]\n        bet = betas[j]\n        rv = beta(alpha, bet)\n        ax = axs[i,j]\n        ax.plot(x, rv.pdf(x))\n        ax.plot(0, 0, label=\"$\\\\alpha$ = {:3.2f}\\n$\\\\beta$ = {:3.2f}\".format(alpha, bet), alpha=0)\n        ax.axvline(alpha\/(alpha + bet),ls='--',c='g')\n        ax.legend()\n        ax.grid()\naxs[2,1].set_xlabel('$x$',fontsize=15)\naxs[1,0].set_ylabel('$pdf(x)$', fontsize=15)\nfig.tight_layout()","1a01e9cb":"beta_params = [(1, 1), (0.1, 0.1), (5, 5)] # Beta distiribution parameters used as priors\nx = np.linspace(0, 1, 100)","d95b5f71":"fig = plt.figure(figsize=(16,12))\nfor idx, N in enumerate(trials):\n    if idx == 0:\n        plt.subplot(5, 3, 2)\n    else:\n        plt.subplot(5, 3, idx+3)\n    heads = data[idx]\n    for (alpha_prior, beta_prior), c in zip(beta_params, ('b', 'r', 'g')):\n        alpha_hat = heads + alpha_prior\n        beta_hat = N - heads + beta_prior\n        p_post = beta.pdf(x, alpha_hat, beta_hat)\n        plt.plot(x, p_post, c)\n        plt.grid(axis='x')\n        plt.fill_between(x, 0, p_post, color=c, alpha=0.1)\n    plt.axvline(alpha_hat\/(alpha_hat + beta_hat),ymax=1, c='r',linestyle='--')\n    plt.axvline(theta_real, ymax=1, color='g',linestyle='--')\n    plt.plot(0, 0, label=\"{:d} experiments\\n{:d} heads\".format(N,heads), alpha=0)\n    plt.xlim(0,1)\n    plt.xlabel(r'$\\theta$', fontsize=15)\n    plt.legend()\n    plt.gca().axes.get_yaxis().set_visible(False)\n    plt.tight_layout()","d98eab59":"import numpy.linalg as la\ndef multivariate_normal_pdf(X, mean=np.zeros(2), cov = 1*np.eye(2)):\n    N,d = X.shape\n    Xm  = X - mean[None] # (N,d) - (1,d)\n    C = 1.\/np.sqrt(2*np.pi**d*np.linalg.det(cov))\n    lst = [C*np.exp(-0.5*(Xm[i]).T @ la.inv(cov) @ (Xm[i])) for i in range(N)]\n    return np.array(lst)","9b03f4b8":"mu = np.zeros(2)\ncov = np.eye(2)\nX = rnd.multivariate_normal(mu,cov,size=100)\nprint('Shape:',X.shape)\nprint(X[:5])","6e82704a":"from matplotlib import cm\ndef draw_plot_gaussian(mu,cov,n=500):\n    X = rnd.multivariate_normal(mu,cov,size=n)\n    cs = multivariate_normal_pdf(X,mu,cov)\n    plt.figure()\n    plt.scatter(*X.T,marker='*',c=cs, cmap=cm.rainbow,\n                label=f'$\\mu$ = {np.round(X.mean(0))}\\n$\\sigma$={np.round(X.std(0))}')\n    plt.scatter(*X.mean(0),color='k',linewidth=5)\n    plt.margins(0.2)\n    plt.grid()\n    _=plt.legend()","d770f207":"draw_plot_gaussian(mu,cov)","b20188d4":"s1 = 1\ns2 = 4\nps = [0.2,-0.5,0.8]\nfor p in ps:\n    cov = np.array(\n        [\n            [s1*s1,p*s1*s2],\n            [p*s2*s1,s2*s2]\n        ])\n    draw_plot_gaussian(mu,cov)","8608aee7":"from scipy.special import gamma\n\ndef dirichlet_pdf(X, alpha):\n    assert np.all(X > 0) & np.all(X < 1)\n    assert np.all(alpha > 0)\n    assert len(alpha.shape) == 1\n    assert len(alpha) >= 2\n    assert X.shape[0] == len(alpha)\n\n    B = np.prod(gamma(alpha))\/gamma(np.sum(alpha))\n\n    # K,N ** K\n    return np.prod(X ** (alpha[:,None]-1), 0) \/ B","a8a5de28":"K = 5\nX = np.abs(rnd.normal(0,1,size=(K,100)))\nX = X \/ X.sum(0)[None]\nX[:,:5],np.sum(X[:,:5],0)","08cffa45":"alpha = np.ones(K)\ndirichlet_pdf(X[:,:2], alpha)","ad4d6e00":"# There is a PDF implementation in SciPy package \nfrom scipy.stats import dirichlet\nalpha = np.ones(K)\ndirichlet.pdf(X[:,:1],alpha)","da48b67f":"# Sample from the Dirichlet distribution\ndirichlet.rvs(alpha,size=3)","70407f99":"assert np.allclose( dirichlet_pdf(X,alpha), dirichlet.pdf(X,alpha))","72096a8f":"#### Prior distribution\n<center>\n$\n\\large{p(\\theta | \\alpha, \\beta) = \\text{Beta}(\\alpha,\\beta)= \\frac{1}{B(\\alpha,\\beta)}}\\theta^{\\alpha-1}(1 - \\theta)^{\\beta-1}, \\quad B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\n$\n<br>","ee340b8a":"* ## Numpy Usage Example: Gaussian (multivariate) PDF \n<br><br>\n<center>\n$\n\\boxed{\n    {\\mathcal{N}(x | \\mu, \\Sigma)} = \n    \\frac{1}{\\sqrt{(2\\pi)^d |\\Sigma|}}\n    \\exp\\Big(-\\frac{1}{2} (x - \\mu)^{\\top}\\Sigma^{-1}(x-\\mu)\\Big)\n    , \\quad \\mu \\in \\mathbb{R}^{(d)}, \\quad \\Sigma \\in \\mathbb{R}^{(d,d)}\n}\n$","e5dae28d":"#### Posterior distribution\n<center>\n    $\\large{\\overbrace{p(\\theta | h, \\alpha, \\beta)}^{\\text{posterior}} \\propto  \\overbrace{\\theta^{h} (1 - \\theta)^{N-h}}^{\\text{likelihood}} \\overbrace{\\theta^{\\alpha-1}(1 - \\theta)^{\\beta-1}}^{\\text{prior}}\n    }$\n<br><br>","bd1328c7":"## Coin flipping example \n\n","47f17ad2":"<center>\n$\\boxed{\\small{\\mathcal{N}(x | \\mu, \\sigma)} = \n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{\\Big(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\Big)}}$","e8bda164":"### Analyse for different parameter values ( i.e. means and variances )","18c1f816":"<center>\n$\n\\large{p(\\theta | h, \\alpha, \\beta) \\propto \\theta^{ h + \\alpha -1 }(1 - \\theta)^{N - h + \\beta-1} }\n$\n<\/center>\n    <hr>\n<center>\n$\n\\large{p(\\theta | h, \\alpha, \\beta) = \\text{Beta}(\\hat{\\alpha},\\hat{\\beta}), \\text{where} \\quad \\hat{\\alpha} = h+\\alpha, \\quad \\hat{\\beta} = N - h + \\beta }\n$","b2f12755":"### Dirichlet distribution ( distribution of distributions ) Multivariate Beta","c5d2b3e5":"### Beta distribution","fe925db8":"# Mulivariate Distributions","0ead9f39":"#### Model distribution (likelihood)\n<br>\n<center>\n$\n\\large{p( h,N | \\theta) = \\text{Binomial}(h,N |\\theta) = \\binom{N}{h} \\theta^{h} (1 - \\theta)^{N-h}}\n$\n<\/center>\n<hr>","f3dd7d5f":"### Multivariate normal (Gaussian) distribution (d=2)   \n","206ce97d":"<center>\n$\n\\boxed{\n    {\n        K \\geq 2, \\quad \\alpha = (\\alpha_1,...,\\alpha_K), \\quad \\alpha_i > 0 \\\\\n        x_i \\in (0,1) \\quad \\text{and} \\quad \\sum_{i=1}^K x_i=1, \\quad \\hat{\\alpha} = \\sum_{i=1}^K \\alpha_i \\\\\n        \\mathcal{Dir}(x|\\alpha) = \\mathcal{C}(\\alpha)\\prod_{i=1}^K x_i^{\\alpha-1}, \n        \\quad \\mathcal{C}(\\alpha) = \\frac{\\Gamma(\\hat{\\alpha})}{\\prod_{i=1}^K \\Gamma(\\alpha_i)}, \\quad\n        \\Gamma(z) =  \\int_0^{\\infty} x^{z-1}e^{-x}dx\n    }\n}\n$"}}