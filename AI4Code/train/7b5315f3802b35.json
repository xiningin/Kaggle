{"cell_type":{"9a70001e":"code","3200305d":"code","9761a528":"code","eb54905d":"code","c0d57962":"code","72d86372":"code","6af6a2d1":"code","2659cd01":"code","e8e1da78":"code","364a11be":"code","d9a498af":"code","bb201d8b":"code","786defbf":"code","5fbe1e8a":"code","f5d4a3f9":"code","7063dbc6":"code","2065c857":"code","e9f3d16a":"code","79c3f69a":"code","e2f40b6f":"code","854c9624":"code","a6e1116d":"code","311d15ad":"code","2f3cf07f":"code","c88a92db":"code","6bab0078":"code","8a379794":"code","aec5d8be":"code","0e5f128f":"code","be36d5a2":"code","b62aa4b9":"code","d674e2ca":"code","f5ab6a83":"code","d571c91a":"code","e7333de5":"code","0ca477dd":"code","7305e36e":"code","6c81a021":"code","2fb65555":"code","afb37ed3":"code","f19baa85":"code","11a5439f":"code","a31236ef":"markdown","bc724d96":"markdown","921dc7c9":"markdown","1fc02b71":"markdown","2eaec182":"markdown","9f584ec3":"markdown","8bdd1379":"markdown","fb080719":"markdown","4331bcfd":"markdown","ffa46649":"markdown","f4772e3b":"markdown","c95623f9":"markdown","08c34ee7":"markdown","dd6cc620":"markdown","0f12a38a":"markdown","95f82f79":"markdown","2b913036":"markdown","18813ce8":"markdown","530be136":"markdown","be013fed":"markdown","f1ae3d12":"markdown","32abf070":"markdown","64779abe":"markdown","d2ee4884":"markdown","22d7a8a5":"markdown","ae0cc408":"markdown","99727ffc":"markdown","d028ffb2":"markdown","58334688":"markdown","d075facb":"markdown","8d0a80ba":"markdown","67d59c6c":"markdown","2e3fc751":"markdown","58a8b6e7":"markdown"},"source":{"9a70001e":"# Importamos las librerias a utilizar en esta tarea\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\n# Librer\u00edas de Sklearn.\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score","3200305d":"# Se lee el archivo .csv que contiene la data\nData = pd.read_csv('\/kaggle\/input\/machine-predictive-maintenance-classification\/predictive_maintenance.csv')\n# Data = pd.read_excel(\"predictive_maintenance.xlsx\")\n# Data = pd.read_csv('predictive_maintenance.csv')\n# print(data)\n# print('filas,columnas',data.shape)","9761a528":"# Se ve el contenido de la dataset. En el dato de Grasa, se modifica la tabla, \n# ya que con el nombre de Fat habia un problema de lectura.\n\nData","eb54905d":"# Se ve la informaci\u00f3n del dataset el cual contiene variables de tipo entero,\n# y alfanum\u00e9ricas.\n\nData.info()","c0d57962":"# Cambiamos de tipo object a  num\u00e9rico, ya que como objet no podemos trabajarlo en python, y cambiamos\n# el tipo de dato de obs y Species_Name para poder trabajar con estos datos m\u00e1s adelante en el entrenamiento\nfrom sklearn.preprocessing import LabelEncoder\nData['Type'] = LabelEncoder().fit_transform(Data['Type']) \nData['Failure Type'] = LabelEncoder().fit_transform(Data['Failure Type']) \n# al correr este c\u00f3digo poner la linea anterior como comentario y luego correrlo sin # para que reconozca \n#y ponga el datoObs como Int64, de lo contrario habr\u00e1 error\nData.info()","72d86372":"# En el caso de eliminar los outlier se recomienda utilizar la siguiente linea de codigo.\n# Dataset1 = Data.dropna() \n# Dataset1.isna().sum() \nData","6af6a2d1":"plt.figure(figsize = (8,8))\n\nData['Type'].value_counts().plot.pie(explode = [0.03, 0.03, 0.03], colors = ['dodgerblue', 'orange', 'limegreen'], autopct = '%1.1f%%', shadow = True)\nplt.xlabel(''),plt.ylabel('')\nplt.title('Porcentaje de variantes de calidad del producto')\nplt.show()","2659cd01":"Data = Data[['UDI', 'Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Target', 'Failure Type']]\nData","e8e1da78":"#visualizamos la tabla de correlaci\u00f3n de todas las variables, pero cuesta visualizar el valor de correlaci\u00f3n\n#exacta, por ello utilizaremos m\u00e1s adelante otra matriz de correlaci\u00f3n con dato exacto.\nplt.figure(figsize=(10,10))\n\nCorrelacion = Data.corr()\nsns.heatmap(Correlacion, cmap = 'Blues', linewidths = 0.3, linecolor = 'dodgerblue', annot = True,\n            vmin = -1, vmax = 1, cbar_kws = {'orientation':'vertical'}, square = True, cbar = True)\nplt.title('Correlaci\u00f3n de las variables del Dataset')\nplt.show()","364a11be":"Correlacion","d9a498af":"plt.figure(figsize=(20,17))\n\nplt.subplot(331)\nplt.hist(Data[\"UDI\"], color = \"darkorange\", edgecolor = 'purple', alpha = 0.8, linewidth = 3)\nplt.title('Identificaci\u00f3n'), plt.xlabel('Identificador m\u00e1quina'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(332)\nplt.hist(Data[\"Type\"], color = \"green\", edgecolor = 'black', alpha = 0.8, linewidth = 3)\nplt.title('Calidad del producto'), plt.xlabel('Variante de calidad.'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(333)\nplt.hist(Data[\"Air temperature [K]\"], color = \"dodgerblue\", edgecolor = 'navy', alpha = 0.8, linewidth = 3)\nplt.title('Temperatura del aire'), plt.xlabel('Kelvin [K].'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(334)\nplt.hist(Data[\"Process temperature [K]\"], color = \"gold\", edgecolor = 'purple', alpha = 0.8, linewidth = 3)\nplt.title('Temperatura de proceso'), plt.xlabel('Kelvin [K]'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(335)\nplt.hist(Data[\"Rotational speed [rpm]\"], color = \"darkred\", edgecolor = 'limegreen', alpha = 0.8, linewidth = 3)\nplt.title('Velocidad de rotaci\u00f3n'), plt.xlabel('[rpm]]'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(336)\nplt.hist(Data[\"Torque [Nm]\"], color = \"slategrey\", edgecolor = 'black', alpha = 0.8, linewidth = 3)\nplt.title('Torque'), plt.xlabel('[rpm]].'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(337)\nplt.hist(Data[\"Tool wear [min]\"], color = \"lime\", edgecolor = 'dodgerblue', alpha = 0.8, linewidth = 3)\nplt.title('Desgaste m\u00e1quina'), plt.xlabel('[min]]'), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(338)\nplt.hist(Data[\"Target\"], color = \"turquoise\", edgecolor = 'slategray', alpha = 0.8, linewidth = 3)\nplt.title('Etiqueta de falla'), plt.xlabel(''), plt.ylabel('Muestras.'), plt.grid()\n\nplt.subplot(339)\nplt.hist(Data[\"Failure Type\"], color = \"deeppink\", edgecolor = 'purple', alpha = 0.8, linewidth = 3)\nplt.title('Tipo de falla'), plt.xlabel(''), plt.ylabel('Muestras.'), plt.grid()\n\nplt.show()\n\n#vemos la disribucion normal de los datos que trabajaremos para los algortimos KNN Y SVM\n#sns.pairplot(Data, vars = ['Air temperature [K]','Process temperature [K]'], kind = 'scatter', markers = ['o','s'])","bb201d8b":"plt.figure(figsize=(20,15))\n\nplt.subplot(331), sns.boxplot(y = Data[\"UDI\"], color = 'tomato', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"UDI\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Identificaci\u00f3n'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(332), sns.boxplot(y = Data[\"Type\"], color = 'green', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Type\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Calidad del producto'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(333), sns.boxplot(y=Data[\"Air temperature [K]\"], color = 'slategrey', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Air temperature [K]\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Temperatura del aire'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(334), sns.boxplot(y=Data[\"Process temperature [K]\"], color = 'dodgerblue', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Process temperature [K]\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Temperatura de proceso'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(335), sns.boxplot(y=Data[\"Rotational speed [rpm]\"], color = 'lime', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Rotational speed [rpm]\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Velocidad de rotaci\u00f3n'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(336), sns.boxplot(y=Data[\"Torque [Nm]\"], color = 'darkblue', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Torque [Nm]\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Torque'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(337), sns.boxplot(y=Data[\"Tool wear [min]\"], color = 'darkred', medianprops = dict(color = \"yellow\"))\nsns.stripplot(y = Data[\"Tool wear [min]\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Desgaste m\u00e1quina'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(338), sns.boxplot(y=Data[\"Target\"], color = 'darkmagenta', medianprops = dict(color = \"yellow\"));\nsns.stripplot(y = Data[\"Target\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Etiqueta de falla'), plt.ylabel('')\nplt.grid()\n\nplt.subplot(339), sns.boxplot(y=Data[\"Failure Type\"], color = 'turquoise', medianprops = dict(color = \"yellow\"));\nsns.stripplot(y = Data[\"Failure Type\"], jitter = False, color = \"yellow\", edgecolor = 'gray')\nplt.title('Bloxplot Tipo de falla'), plt.ylabel('')\nplt.grid()\n\nplt.show()","786defbf":"#sns.pairplot(Data, hue = 'Type', vars = ['Air temperature [K]','Process temperature [K]','Rotational speed [rpm]','Torque [Nm]','Tool wear [min]'], \n#            kind = 'scatter'), plt.show()","5fbe1e8a":"from keras.models import Sequential\n\n# Tipos de capas\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization, Flatten\nfrom keras.losses import sparse_categorical_crossentropy","f5d4a3f9":"X_Data = Data[['UDI', 'Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Failure Type']]\nY_Data = Data['Target']","7063dbc6":"X_train, X_test, Y_train, Y_test = train_test_split(X_Data, Y_Data, test_size = .8)\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","2065c857":"model = Sequential()\n# Capas de Neuronas.\n\n# Capa densa con 50 neuronas y 8 variables de entrada.\nmodel.add(Dense(50, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n\n# Capa para evitar que los pesos crezcan y exista sobreentrenamiento.\nmodel.add(Dropout(0.5))\n\n# Capa densa con 500 neuronas y 500 variables de entrada.\nmodel.add(Dense(500, input_dim = 500, kernel_initializer='uniform', activation='relu'))\n\n# Capa para evitar que los pesos crezcan y exista sobreentrenamiento.\nmodel.add(Dropout(0.5))\n\n# Capa densa con 2 neuronas.\nmodel.add(Dense(2, kernel_initializer='uniform', activation='sigmoid'))","e9f3d16a":"model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","79c3f69a":"model.fit(X_train, Y_train, batch_size=30, epochs=100)","e2f40b6f":"scores = model.evaluate(X_train, Y_train)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","854c9624":"#Se trabaja en x con todos los datos de caracteristicas y en Y con la clasificaci\u00f3n\n# que corresponde a si tiene falla o no, se somete a clasificaci\u00f3n con los pasos a \n#continuaci\u00f3n.\nX = Data.drop('Failure Type', axis = 1)\nY = Data['Failure Type'].values","a6e1116d":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8)","311d15ad":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","2f3cf07f":"print(X_test) # vemos los datos de test escalada","c88a92db":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.8)","6bab0078":"from sklearn.svm import SVC\nCLF = SVC(kernel = 'linear')\nCLF.fit(X_train, Y_train)","8a379794":"y_pred = CLF.predict(X_test)","aec5d8be":"from sklearn.metrics import classification_report, confusion_matrix\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix(Y_test,y_pred), cmap = 'Blues', annot = True, square = True, linewidths = 0.8, linecolor = 'green', cbar = True)\nplt.xlabel('Predicted Class'), plt.ylabel('True Class')\nplt.title('Matriz de confusi\u00f3n - SVM.')\nplt.show()\n\nprint('Matriz de confusi\u00f3n SVM')\nprint('')\nprint(confusion_matrix(Y_test,y_pred))","0e5f128f":"from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(Y_test,y_pred))\nprint(classification_report(Y_test,y_pred))","be36d5a2":"# Se crea un data frame con las car\u00e1cteristicas y se eliminan las columnas 'Target' y 'Failure type'\n# que corresponden a las variables que se pueden predecir.\ndata_feat_X= Data.drop(['Target','Failure Type'], axis=1)\ndata_feat_X.head() ","b62aa4b9":"# Se crea un arreglo correspondiente a nuestra variable de salida\ndata_predict_Y= Data['Failure Type'].values\ndata_predict_Y","d674e2ca":"# Se dividen los datos \n# se utliza un test size del 80% y el 20% restante para validaci\u00f3n.\nX_train, X_validation, y_train, y_validation = train_test_split(data_feat_X, data_predict_Y, test_size = .8, random_state = 123)","f5ab6a83":"# Se importa el clasificador desde scikit-learn\nfrom sklearn.ensemble import RandomForestClassifier","d571c91a":"rand_F = RandomForestClassifier(max_depth=500,n_estimators=500)","e7333de5":"# Se entrena el modelo utilizando el comando .fit \n# como argumentos las variables de entrada y salida de entrenamiento. \nrand_F.fit(X_train, y_train)\n\n# Se determina el desempe\u00f1o(R2) del modelo con el comando .score \nrandomforest_score = rand_F.score(X_validation, y_validation)\nprint('Forest Score: ', randomforest_score)\n","0ca477dd":"from sklearn.metrics import confusion_matrix,classification_report\ny_error = rand_F.predict(X_validation)\nprint(classification_report(y_validation,y_error))\nprint(confusion_matrix(y_validation,y_error))","7305e36e":"from sklearn.model_selection import GridSearchCV, cross_val_score\n\ncross_val_score(rand_F, X_train, y_train, cv=10) # se utilizan 10 divisiones para obetner el score. ","6c81a021":"# Score promedio\ncross_val_score(rand_F, X_train, y_train, cv=5).mean()","2fb65555":"# sea crea el grid \nn_estimators = [10, 100, 500, 1000]\nmax_depth = [None, 50, 100, 500]\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth)","afb37ed3":"# Busqueda\ngrid = GridSearchCV(estimator=rand_F, \n                    param_grid=param_grid,\n                    cv=5,\n                    verbose=2,\n                    n_jobs=-1)\n\ngrid_result = grid.fit(X_train, y_train)","f19baa85":"# Mejores parametros\ngrid_result.best_params_","11a5439f":"# Mejor Score \ngrid_result.best_score_","a31236ef":"## Clasificaci\u00f3n de Mantenimiento Predictivo para m\u00e1quinas.\n\nEl dataset escogido presenta un conjunto de datos sinteticos que reflejan el mantenimiento predictivo real encontrado en la industria.\n\nEst\u00e1 compuesto por 10 columnas, las cuales se detallar\u00e1n a continuaci\u00f3n:\n\n- UDI: Identificador de la m\u00e1quina. Es un valor \u00fanico para cada una.\n- Product ID: Indica la calidad del producto. Posee una letra L (baja - 50% de todos los productos), M (Media - 30%) y H (Alta - 20%). Adem\u00e1s tiene un numero de serie especifico de la variante de calidad del producto.\n- Type: Tipo del producto. Los valores son una letra L, M y H, de acuerdo con la descripci\u00f3n mencionada en la columna anterior *Product ID*.\n- Air Temperature [K]: Corresponde a la temperatura del Aire medida en Grados Kelvin.\n- Process Temperature [K]: Corresponde a la temperatura del proceso medida en Grados Kelvin.\n- Rotational speed [rpm]: Velocidad de rotaci\u00f3n de la m\u00e1quina medida en revoluciones por minuto. \n- Torque [Nm]: Torque medido en Newton metros. Sus datos est\u00e1n distribuidos normalmente alrededor de los 40 Nm y sin valores negativos.\n- Tool wear [min]: Desgaste de la herramienta. Las variantes de calidad H\/M\/L a\u00f1aden 5\/3\/2 minutos de desgaste de la herramienta usada en el proceso.\n- Target: Etiqueta que indica si la maquina falla o no. Sus valores son 0 o 1 donde 0 indica que la maquina no fallado y 1 que la m\u00e1quina si ha fallado.\n- Failure Type: Indica el tipo de falla. Est\u00e1s pueden ser: *No Failure* (Sin fallo), *Heat Dissipation Failure* (Falla por disipaci\u00f3n de calor), *Power Failure* (Falla de alimentaci\u00f3n), *Overstrain Failure* (Falla por Sobrefuerza), *Tool Wear Failure* (Falla por desgaste de la herramienta) y *Random Failures* (Fallas aleatorias).","bc724d96":"Una matriz de confusi\u00f3n, tambi\u00e9n conocida como matriz de error, es una tabla resumida que se utiliza para evaluar el rendimiento de un modelo de clasificaci\u00f3n. El n\u00famero de predicciones correctas e incorrectas se resumen con los valores de conteo y se desglosan por cada clase.","921dc7c9":"## Redes Neuronales - Keras.\n\n__Algoritmos de clasificaci\u00f3n: Se utilizan para entrenar un modelo con el fin de predecir el resultado de una variable de salida. Para el dataset, se predice si la m\u00e1quina fallar\u00e1 o no (Clasificaci\u00f3n binaria).__\n\n*Los algoritmos de redes neuronales son inspirados por el proceso de aprendizaje que se produce en el cerebro humano. Consiste en una red de neuronas (par\u00e1metros) que permiten al algoritmo aprender y mejorar analizando datos. Las capas neuronales producen una salida a partir de una o varias entradas, enviando se\u00f1ales de capa en capa hasta la \u00faltima, la cual entregar\u00e1 el resultado final del modelo.*","1fc02b71":"Se crea la instancia rand_F correspondiente al clasificador, usando como para metros la profundidad y el numero de estimadores.\n \nEstos parametros no son cr\u00edticos, debido a que rand_F no sufre problemas de overfit, aunque aumentar mucho el n\u00famero de arboles aumenta el gasto de memoria.","2eaec182":"Se aprecia que el dataset est\u00e1 limpio y no contiene datos at\u00edpicos, por lo tanto no se realiza ninguna modificaci\u00f3n.","9f584ec3":"Se definen como variables predictoras todas las columnas menos Target, que es la variable a predecir y contiene la informaci\u00f3n de si falla la m\u00e1quina o no.","8bdd1379":"En base a los datos utilizados para test que corresponde a un 80% se obtiene un accuracy de un 0.99 que corresponde a un 99% que es un muy buen desempe\u00f1o en la regresi\u00f3n.","fb080719":"M\u00e1quinas de Vector Soporte (Vector Support Machines, SVMs) es un algoritmo de clasificaci\u00f3n y regresi\u00f3n desarrollado en la d\u00e9cada de los 90, dentro del campo de la ciencia computacional. Aunque inicialmente se desarroll\u00f3 como un m\u00e9todo de clasificaci\u00f3n binaria, su aplicaci\u00f3n se ha extendido a problemas de clasificaci\u00f3n m\u00faltiple y regresi\u00f3n. Las M\u00e1quinas de Vector Soporte se fundamentan en el Maximal Margin Classifier, que a su vez, se basa en el concepto de hiperplano. La librer\u00eda Scikit Learn contiene implementaciones en Python de los principales algoritmos de SVM.\n\nEl principal uso se da para clasificaci\u00f3n binaria, para categorizar datos en dos grupos. Dependiendo de la cantidad de caracteristicas que utilizaremos ser\u00e1 el plano, espacio en donde nos moveremos para clasificar y obtener los resultados al objetivo que se quiere tener en la clasificaci\u00f3n.Support vector machine (SVM) es un algoritmo de aprendizaje supervisado que se utiliza en muchos problemas de clasificaci\u00f3n y regresi\u00f3n, incluidas aplicaciones m\u00e9dicas de procesamiento de se\u00f1ales, procesamiento del lenguaje natural y reconocimiento de im\u00e1genes y voz.","4331bcfd":"Se crea el modelo secuencial y se a\u00f1aden capas de neuronas.","ffa46649":"## Clasificador Random Forest\nRandom Forest es un algoritmo que puede ser de regresi\u00f3n o clasificaci\u00f3n, este se basa en arboles de decisi\u00f3n individuales, donde cada uno es entrenado con una muestra aleatoria extraida de los datos de entrenamiento. Esto se fundamenta en el metodo de *esemble* tipo *Bagging* , que consiste en ajustar multiples modelos con diferentes subconjuntos aleatorios de los datos de entrenamiento, como valor final se toma la media de todas las predicciones o la clase m\u00e1s frecuente. \n\nLos algoritmos basados en arboles de decision, se han convertido en referentes en el ambito predictivo debido a sus buenos resultados en diferentes areas y multiples ventajas, tales como: baja influencia de outliers, selecci\u00f3n de predictores de forma automatica, bajo numero de hiperparametros y no sufre problemas de overfitting por muchos arboles que se agreguen. ","f4772e3b":"### Grid search ","c95623f9":"###Busqueda de outliers: BoxPlots ","08c34ee7":"Se eval\u00faa la calidad del modelo con los datos X_train e Y_train. Adem\u00e1s se visualiza el resultado de p\u00e9rdida (1.3%) y precisi\u00f3n del algoritmo (99.7%)","dd6cc620":"se oberva una diferencia en el score, dependiendo de como se distribuyen los datos. ","0f12a38a":"El que se utilizar\u00e1 para este ejemplo es de regresi\u00f3n lineal.","95f82f79":"*Modelo:* Desde la librer\u00eda keras.models se crea un Modelo _Secuencial_. \n\n*Tipos de capas:* Se importan varios tipos de capas con el comando keras.layers.","2b913036":"### Escalamiento de Datos\nEste es uno de los primeros pasos y mas importantes, seguido de la limpieza de datos, eliminando los datos NaN y outliers, revisando la correlaci\u00f3n y quitando los elementos necesarios para realizar el estudio mas acotado, podemos escalar los datos que originalmente ten\u00edamos. Para nuestro ejemplo no fue necesaria la limpieza de datos ya que estaba muy completa y limpia.","18813ce8":"Se genera la simulaci\u00f3n del modelo de entrenamiento especificando en cuantos lotes de datos se entrenar\u00e1 el modelo (batch_size = 30). Tambi\u00e9n se evalua periodicamente el algoritmo, registrando la p\u00e9rdida y la precisi\u00f3n del modelo (epochs=100)","530be136":"### Validaci\u00f3n cruzada\nEsto permite entrenar el modelo utlizando toda la data, creando n diferentes divisones de la data y entrenando el modelo n veces.","be013fed":"El modelo logra un 97% de accuracy en la metrica F1. ","f1ae3d12":"# Algoritmos.","32abf070":"### Histogramas de cada variable.","64779abe":"### Conclusiones finales.\nLos 3 algoritmos logran un gran desempe\u00f1o por sobre el 95%. El Random Forest, tiene la ventaja de tener menos hiperpar\u00e1metros, por lo que es m\u00e1s simple de ajustar. En cuanto a SVM es facil de utilizar, presentando un buen desempe\u00f1o cuando la data no contiene outliers. Tiene alto costo computacional. En cuanto al Neuronal Networks, tambi\u00e9n presenta un buen desempe\u00f1o, dependiente de las epocas y en cuantos lotes de datos se entrenar\u00e1 el modelo. ","d2ee4884":"Se define una funci\u00f3n de p\u00e9rdida, tipo de optimizador y metrica de desempe\u00f1o, que calcula la frecuencia de con la que la predicci\u00f3n coincide con el dataset real.","22d7a8a5":"Del modelo considerando 100 \u00e9pocas, se aprecia un mayor valor de precisi\u00f3n con el paso del tiempo. En cuanto a la p\u00e9rdida tambi\u00e9n disminuye con el paso de las \u00e9pocas, aunque sus valores no crezcan como la precisi\u00f3n.","ae0cc408":"Se elimina del dataset la variable ProductID ya que contiene valores alfanumericos.","99727ffc":"## SVM (Maquina de Soporte Vectorial)","d028ffb2":"# Limpieza de datos \n\n###### Notamos que tenemos varias variables como objet:  Type, Failure Type para python se trabaja con datos entero, flotantes, por ello debemos modificar el tipo de informaci\u00f3n por la que sea f\u00e1cil de trabajar. Ademas se tiene que la columna de  Product ID, es unica para cada producto, es por ello que no se puede normalizar a un solo valor ya que se compone de letras y numeros.\n\nLas variables de tipo object (*Tipo* y *Failure Type*) se convierten de alfanum\u00e9ricas a num\u00e9ricas con el comando LabelEncoder().fit_transform() y nuevamente se muestra la informaci\u00f3n de la data para visualizar que todas las variables son de tipo num\u00e9rico.\n","58334688":"##An\u00e1lisis columnas correlacionadas\n###### Se realiza utilizando un mapa de color para ver la correlacion entre variables. Utilizando la data limpia, sin datos Nan y sin outliers.","d075facb":"Todas las columnas, excepto Product ID son n\u00fameros, ya que es un dato muy d\u00edficil de transformar.","8d0a80ba":"### Reporte completo del algoritmo SVM y desempe\u00f1o","67d59c6c":"Se define los conjuntos de entrenamiento (20%) y test (80%). Tambi\u00e9n se normalizan las variables predictoras de entrenamiento y test en un valor entre 0 y 1 con el comando scaler.fit_transform","2e3fc751":"Se realiza un diagrama de torta que muestra el porcentaje de datos de cada tipos de variantes de calidad de los productos, variables que fueron transformadas de object a int64, donde:\n\nL = 1, M = 2, H = 0","58a8b6e7":"# PROYECTO 2 \u2013 AN\u00c1LISIS DE ALGORITMOS DE MACHINE LEARNING \n\n## Integrantes : Daniel Quezada - Camila Beltr\u00e1n - Antonio Valenzuela \n\n### LinkDataset: https:\/\/www.kaggle.com\/shivamb\/machine-predictive-maintenance-classification\/version\/1 "}}