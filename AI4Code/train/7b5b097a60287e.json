{"cell_type":{"be23e953":"code","3d389ef3":"code","c0631319":"code","6667aed4":"code","cd06ecaa":"code","55070933":"code","226d8382":"code","8f69fa02":"code","4f3fb6db":"code","436490b9":"code","a360c92b":"code","c7aacc21":"code","27eb4ba1":"code","53eca504":"code","41587606":"code","bd95b189":"code","04de6b0a":"code","6cb425a3":"code","154565c2":"code","bb0d7259":"code","59fbeb88":"code","e1a96a02":"code","15ec11c5":"code","61ab8751":"code","b984a5a8":"code","ba4055f4":"code","caf00cbb":"code","2934d852":"code","c4a55782":"code","3b5f8a55":"code","3e81213f":"code","742da7c6":"code","073f8554":"code","ba92c3b9":"code","b888d387":"code","e03cb4d1":"code","f7684f43":"code","54b68619":"code","93c82d2f":"code","93c13013":"code","f345ea72":"code","ee64fd7c":"code","dc93038c":"code","8d226e8d":"code","b727315d":"code","def14488":"code","e93f0ff6":"code","ac7a4c46":"code","5f7d1ec1":"code","eae4bed1":"code","e9565fa3":"code","846c5466":"code","b45d86d0":"code","351d6af5":"code","0c6eb6ea":"code","839b3ebf":"code","ba8edf6b":"code","b7cd12e6":"code","00011e4d":"code","50ff0d6a":"code","93c20fa0":"code","fee88801":"code","bcac784e":"code","a6d3824e":"code","e3098f6e":"code","f0e89bef":"code","a94481fe":"code","4eb86ec9":"code","6275ee60":"code","785e09c6":"code","13a7ac4a":"code","ef676cb9":"code","13b4ed79":"code","2d64bfc9":"code","2377219d":"code","eeb9e245":"code","afd3c55e":"code","1ba3055c":"code","eb64d323":"code","57d1da90":"code","22b37e1e":"code","f9624c21":"code","8d4caa51":"code","fab370b7":"code","2c3192eb":"code","31cbd96f":"code","0000b160":"code","1247bdb7":"code","c973012e":"code","7ffdf5fe":"code","8f897877":"code","8fb96071":"code","301f3ab8":"code","1d6a94a3":"code","4180a301":"code","00b53f6e":"code","a09d37b4":"code","2b88fcaa":"code","585a70df":"code","343c7353":"code","bbf3b76e":"code","4b784b64":"code","0e237f89":"code","686929df":"code","07b2558e":"code","90978551":"code","cdc608c3":"code","7ef3a3b1":"code","b84541a1":"code","eb854c7d":"code","e189939b":"code","0b1e6d18":"code","9586e360":"markdown","7941a947":"markdown","38b01b46":"markdown","e1dba5e2":"markdown","160fe83f":"markdown","b02711a7":"markdown","607de876":"markdown","ff06b94c":"markdown","c205d5f1":"markdown","77fdf9f2":"markdown","426a3f53":"markdown","ff0efa33":"markdown","d80b30e7":"markdown","54c7d5ce":"markdown","b6782bd5":"markdown","a0e259b4":"markdown","987a233a":"markdown","65815beb":"markdown","9a08f3df":"markdown","aca8c771":"markdown","8cdb2167":"markdown","10bb9665":"markdown","8ba0e5c0":"markdown","b89a20f7":"markdown","e23c7c03":"markdown","0b576b4c":"markdown","36e41cbc":"markdown","7b25a98c":"markdown","4a69968f":"markdown","69205cd8":"markdown","107779bb":"markdown","44a11e16":"markdown","8369f775":"markdown","da65cf2e":"markdown","1e9a81d4":"markdown","fe989e9f":"markdown","e0cb7073":"markdown","7817806f":"markdown","3f6ec13a":"markdown","1bd58a4c":"markdown","c2e2104a":"markdown","9932d458":"markdown","a3831ed8":"markdown","f612a74a":"markdown","92137259":"markdown","406228d6":"markdown","483c7406":"markdown","9fcb8384":"markdown","6c4152bf":"markdown","53ef2e77":"markdown","90793c6f":"markdown","ecf0e3b6":"markdown","422d47c6":"markdown","a4487c97":"markdown","7684a5f1":"markdown","1d4845c6":"markdown","28f0727a":"markdown","9dcd9482":"markdown","f387287b":"markdown","05a5d9fa":"markdown","113787b9":"markdown","535ac1df":"markdown","c14255c0":"markdown","8e11e1d7":"markdown","ce8a024a":"markdown","41894ae7":"markdown","3b98e12e":"markdown","788bd764":"markdown","97d0969a":"markdown","e18b76f3":"markdown","559e03db":"markdown","37c40fcc":"markdown","ccfa0d7e":"markdown","32a93630":"markdown","adb373b0":"markdown","2e949931":"markdown","0c5332cd":"markdown","9acf3810":"markdown","4097db8f":"markdown"},"source":{"be23e953":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3d389ef3":"# importing libraries\n# we already have numpy as np and pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# importing more libraries, particular to modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC","c0631319":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","6667aed4":"# reading competition data files\ntrain_org = pd.read_csv('..\/input\/uconn_comp_2018_train.csv')\ntest_org = pd.read_csv('..\/input\/uconn_comp_2018_test.csv')","cd06ecaa":"# checking length of data files\nlen(train_org)\nlen(test_org)","55070933":"# checking number of variables in data files\nlen(train_org.columns)\nlen(test_org.columns)","226d8382":"# getting to know the column names\ntrain_org.columns","8f69fa02":"# taking a peek at some data\n##~ train_org.head()","4f3fb6db":"# checking missing values in train data\n##~ train_org.isnull().sum()","436490b9":"# checking missing values in development set data\n##~ test_org.isnull().sum()","a360c92b":"train = train_org.copy(deep=True)\ntest = test_org.copy(deep=True)","c7aacc21":"# overview of train data\n##~ train.describe()","27eb4ba1":"# overview of test data\n##~ test.describe()","53eca504":"# checking if claim_number has all unique values\nlen(np.unique(train.claim_number)) == len(train)","41587606":"# reading the data type of claim_number\ntrain.claim_number.dtype\n\n# reading a sample of claim_number\n##~ train.claim_number.sample(5)\n\n# number of missing values in claim_number\ntrain.claim_number.isnull().sum()","bd95b189":"# description of variable\n##~ train.claim_number.describe()","04de6b0a":"# reading the data type of the variable\ntrain.age_of_driver.dtype\n\n# reading a sample of age_of_driver\n##~ train.age_of_driver.sample(5)\n\n# number of missing values in age_of_driver\ntrain.age_of_driver.isnull().sum()","6cb425a3":"# mean age of driver\ntrain.age_of_driver.mean()\n\n# median age of driver\ntrain.age_of_driver.median()","154565c2":"# lets get to know the distribution of the age_of_driver\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(24,6)\nsns.distplot(train.age_of_driver)","bb0d7259":"# outliers\n##~ train.age_of_driver.describe()\ntrain.age_of_driver.max()","59fbeb88":"# modifying ages above 90 years as 90\ntrain.age_of_driver[train.age_of_driver > 90] = 90\ntest.age_of_driver[test.age_of_driver > 90] = 90","e1a96a02":"# adding safty rating buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['age_of_driver_buckets'] = train.age_of_driver\ntrain['age_of_driver_buckets'][train.age_of_driver >= 62] = 'Very High'\ntrain['age_of_driver_buckets'][(train.age_of_driver >= 51) & (train.age_of_driver < 62)] = 'High'\ntrain['age_of_driver_buckets'][(train.age_of_driver >= 43) & (train.age_of_driver < 51)] = 'High Average'\ntrain['age_of_driver_buckets'][(train.age_of_driver >= 35) & (train.age_of_driver < 43)] = 'Low Average'\ntrain['age_of_driver_buckets'][(train.age_of_driver >= 24) & (train.age_of_driver < 35)] = 'Low'\ntrain['age_of_driver_buckets'][train.age_of_driver < 24] = 'Very Low'\n\ntest['age_of_driver_buckets'] = test.age_of_driver\ntest['age_of_driver_buckets'][test.age_of_driver >= 62] = 'Very High'\ntest['age_of_driver_buckets'][(test.age_of_driver >= 51) & (test.age_of_driver < 62)] = 'High'\ntest['age_of_driver_buckets'][(test.age_of_driver >= 43) & (test.age_of_driver < 51)] = 'High Average'\ntest['age_of_driver_buckets'][(test.age_of_driver >= 35) & (test.age_of_driver < 43)] = 'Low Average'\ntest['age_of_driver_buckets'][(test.age_of_driver >= 24) & (test.age_of_driver < 35)] = 'Low'\ntest['age_of_driver_buckets'][test.age_of_driver < 24] = 'Very Low'","15ec11c5":"# reading the data type of the variable\ntrain.gender.dtype\n\n# reading a sample of gender\n##~ train.gender.sample(5)\n\n# number of missing values in gender\ntrain.gender.isnull().sum()","61ab8751":"# distribution of gender\ntrain.gender.value_counts()","b984a5a8":"# reading the data type of the variable\ntrain.marital_status.dtype\n\n# reading a sample of variable\n##~ train.marital_status.sample(5)\n\n# number of missing values for the variable\ntrain.marital_status.isnull().sum()","ba4055f4":"# distribution of variable\ntrain.marital_status.value_counts()","caf00cbb":"# here we observe the gender type 1 is dominant\n# hence lets impute the 5 missing values with the mode, that is 1\n# this is fine as the number of missing value is very low\n# we will do the same treatment in the development set as well\ntrain.marital_status.fillna(train.marital_status.value_counts().index[0], inplace=True)\ntest.marital_status.fillna(test.marital_status.value_counts().index[0], inplace=True)","2934d852":"train.safty_rating.describe()","c4a55782":"fig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train.safty_rating)","3b5f8a55":"# adding safty rating buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['safty_rating_buckets'] = train.safty_rating\ntrain['safty_rating_buckets'][train.safty_rating >= 105] = 'Very High'\ntrain['safty_rating_buckets'][(train.safty_rating >= 90) & (train.safty_rating < 105)] = 'High'\ntrain['safty_rating_buckets'][(train.safty_rating >= 76) & (train.safty_rating < 90)] = 'High Average'\ntrain['safty_rating_buckets'][(train.safty_rating >= 65) & (train.safty_rating < 76)] = 'Low Average'\ntrain['safty_rating_buckets'][(train.safty_rating >= 50) & (train.safty_rating < 65)] = 'Low'\ntrain['safty_rating_buckets'][train.safty_rating < 50] = 'Very Low'\n\ntest['safty_rating_buckets'] = test.safty_rating\ntest['safty_rating_buckets'][test.safty_rating >= 105] = 'Very High'\ntest['safty_rating_buckets'][(test.safty_rating >= 90) & (test.safty_rating < 105)] = 'High'\ntest['safty_rating_buckets'][(test.safty_rating >= 76) & (test.safty_rating < 90)] = 'High Average'\ntest['safty_rating_buckets'][(test.safty_rating >= 65) & (test.safty_rating < 76)] = 'Low Average'\ntest['safty_rating_buckets'][(test.safty_rating >= 50) & (test.safty_rating < 65)] = 'Low'\ntest['safty_rating_buckets'][test.safty_rating < 50] = 'Very Low'\ntest['safty_rating_buckets']","3e81213f":"# adding 0-9 interger variable ratings\ntrain['safty_rating_int'] = np.round(train.safty_rating \/ 10)\ntest['safty_rating_int'] = np.round(test.safty_rating \/ 10)","742da7c6":"# adding safty_rating transformed variable, square of log of safty_rating\ntrain['safty_rating_logsq'] = np.square(np.log(train.safty_rating))\ntest['safty_rating_logsq'] = np.square(np.log(test.safty_rating))","073f8554":"fig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train.safty_rating_logsq)","ba92c3b9":"train.annual_income.describe()","b888d387":"# imputing Median value for Incomes where Income is less than 10000\ntrain.annual_income[train.annual_income < 10000] = 37610\ntest.annual_income[test.annual_income < 10000] = 37610","e03cb4d1":"sns.set_style('whitegrid')\nfig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train.annual_income)","f7684f43":"# treating outliers\ntrain.annual_income[train.annual_income > 48000] = 48000\ntest.annual_income[test.annual_income > 48000] = 48000","54b68619":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['annual_income_buckets'] = train.annual_income\ntrain['annual_income_buckets'][train.annual_income >= 42500] = 'Very High'\ntrain['annual_income_buckets'][(train.annual_income >= 39300) & (train.annual_income < 42500)] = 'High'\ntrain['annual_income_buckets'][(train.annual_income >= 37600) & (train.annual_income < 39300)] = 'High Average'\ntrain['annual_income_buckets'][(train.annual_income >= 35500) & (train.annual_income < 37600)] = 'Low Average'\ntrain['annual_income_buckets'][(train.annual_income >= 32500) & (train.annual_income < 35500)] = 'Low'\ntrain['annual_income_buckets'][train.annual_income < 32500] = 'Very Low'\ntrain['annual_income_buckets']\n\ntest['annual_income_buckets'] = test.annual_income\ntest['annual_income_buckets'][test.annual_income >= 42500] = 'Very High'\ntest['annual_income_buckets'][(test.annual_income >= 39300) & (test.annual_income < 42500)] = 'High'\ntest['annual_income_buckets'][(test.annual_income >= 37600) & (test.annual_income < 39300)] = 'High Average'\ntest['annual_income_buckets'][(test.annual_income >= 35500) & (test.annual_income < 37600)] = 'Low Average'\ntest['annual_income_buckets'][(test.annual_income >= 32500) & (test.annual_income < 35500)] = 'Low'\ntest['annual_income_buckets'][test.annual_income < 32500] = 'Very Low'\ntest['annual_income_buckets']","93c82d2f":"train.high_education_ind.value_counts()\ntrain.high_education_ind.isnull().sum()\ntest.high_education_ind.isnull().sum()","93c13013":"train.address_change_ind.value_counts()\n\ntrain.address_change_ind.isnull().sum()\ntest.address_change_ind.isnull().sum()","f345ea72":"train.living_status.value_counts()\n\ntrain.living_status.isnull().sum()\ntest.living_status.isnull().sum()","ee64fd7c":"train.zip_code.describe()\nlen(train.zip_code.value_counts())\nlen(test.zip_code.value_counts())","dc93038c":"# truncating last 2 digits of zip_code\ntrain.zip_code = np.round(train.zip_code \/ 100)\ntest.zip_code = np.round(test.zip_code \/ 100)","8d226e8d":"train.zip_code.value_counts()\ntest.zip_code.value_counts()","b727315d":"train.claim_date.describe()","def14488":"# extracting claim_date month\ntrain['claim_date_formatted'] = pd.to_datetime(train['claim_date'], format = \"%m\/%d\/%Y\")\ntrain['claim_month'] = train['claim_date_formatted'].dt.month\n\n# extracting claim_date_delta\ntrain['claim_date_delta'] = (train['claim_date_formatted'] - train['claim_date_formatted'].min())\ntrain['claim_date_delta'] = train['claim_date_delta'].apply(lambda x: str(x).split()[0]).astype(int)\ntrain.drop(['claim_date', 'claim_date_formatted'], axis = 1, inplace = True)","e93f0ff6":"# extracting claim_date_delta\ntest['claim_date_formatted'] = pd.to_datetime(test['claim_date'], format = \"%m\/%d\/%Y\")\ntest['claim_month'] = test['claim_date_formatted'].dt.month\n\n# extracting claim_date_delta\ntest['claim_date_delta'] = (test['claim_date_formatted'] - test['claim_date_formatted'].min())\ntest['claim_date_delta'] = test['claim_date_delta'].apply(lambda x: str(x).split()[0]).astype(int)\ntest.drop(['claim_date', 'claim_date_formatted'], axis = 1, inplace = True)","ac7a4c46":"train.claim_day_of_week.value_counts()\n\ntrain.claim_day_of_week.isnull().sum()\ntest.claim_day_of_week.isnull().sum()","5f7d1ec1":"train.accident_site.value_counts()\n\ntrain.accident_site.isnull().sum()\ntest.accident_site.isnull().sum()","eae4bed1":"train.past_num_of_claims.value_counts()\n\ntrain.past_num_of_claims.isnull().sum()\ntest.past_num_of_claims.isnull().sum()","e9565fa3":"train.witness_present_ind.value_counts()\n\ntrain.witness_present_ind.isnull().sum()\ntest.witness_present_ind.isnull().sum()","846c5466":"train.liab_prct.describe()","b45d86d0":"fig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train.liab_prct)","351d6af5":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['liab_prct_buckets'] = np.round(train.liab_prct \/ 20)\ntest['liab_prct_buckets'] = np.round(test.liab_prct \/ 20)","0c6eb6ea":"train.channel.value_counts()\n\ntrain.channel.isnull().sum()\ntest.channel.isnull().sum()","839b3ebf":"train.policy_report_filed_ind.value_counts()\n\ntrain.policy_report_filed_ind.isnull().sum()\ntest.policy_report_filed_ind.isnull().sum()","ba8edf6b":"train.claim_est_payout.describe()\n\ntrain.claim_est_payout.isnull().sum()","b7cd12e6":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['claim_est_payout_buckets'] = train.claim_est_payout\ntrain['claim_est_payout_buckets'][train.claim_est_payout >= 8500] = 'Very High'\ntrain['claim_est_payout_buckets'][(train.claim_est_payout >= 6250) & (train.claim_est_payout < 8500)] = 'High'\ntrain['claim_est_payout_buckets'][(train.claim_est_payout >= 4650) & (train.claim_est_payout < 6250)] = 'High Average'\ntrain['claim_est_payout_buckets'][(train.claim_est_payout >= 3350) & (train.claim_est_payout < 4650)] = 'Low Average'\ntrain['claim_est_payout_buckets'][(train.claim_est_payout >= 1100) & (train.claim_est_payout < 3350)] = 'Low'\ntrain['claim_est_payout_buckets'][train.claim_est_payout < 1100] = 'Very Low'\ntrain['claim_est_payout_buckets']\n\ntest['claim_est_payout_buckets'] = test.claim_est_payout\ntest['claim_est_payout_buckets'][test.claim_est_payout >= 8500] = 'Very High'\ntest['claim_est_payout_buckets'][(test.claim_est_payout >= 6250) & (test.claim_est_payout < 8500)] = 'High'\ntest['claim_est_payout_buckets'][(test.claim_est_payout >= 4650) & (test.claim_est_payout < 6250)] = 'High Average'\ntest['claim_est_payout_buckets'][(test.claim_est_payout >= 3350) & (test.claim_est_payout < 4650)] = 'Low Average'\ntest['claim_est_payout_buckets'][(test.claim_est_payout >= 1100) & (test.claim_est_payout < 3350)] = 'Low'\ntest['claim_est_payout_buckets'][test.claim_est_payout < 1100] = 'Very Low'\ntest['claim_est_payout_buckets']","00011e4d":"train.age_of_vehicle.describe()\n\nsum(train.age_of_vehicle.isnull())","50ff0d6a":"train.age_of_vehicle[train.age_of_vehicle.isnull()] = 5\ntest.age_of_vehicle[test.age_of_vehicle.isnull()] = 5","93c20fa0":"fig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train.age_of_vehicle)","fee88801":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['age_of_vehicle_buckets'] = train.age_of_vehicle\ntrain['age_of_vehicle_buckets'][train.age_of_vehicle >= 6] = 'Very High'\ntrain['age_of_vehicle_buckets'][(train.age_of_vehicle >= 5) & (train.age_of_vehicle < 6)] = 'High'\ntrain['age_of_vehicle_buckets'][(train.age_of_vehicle >= 3) & (train.age_of_vehicle < 5)] = 'Low'\ntrain['age_of_vehicle_buckets'][train.age_of_vehicle < 3] = 'Very Low'\ntrain['age_of_vehicle_buckets']\n\ntest['age_of_vehicle_buckets'] = test.age_of_vehicle\ntest['age_of_vehicle_buckets'][test.age_of_vehicle >= 6] = 'Very High'\ntest['age_of_vehicle_buckets'][(test.age_of_vehicle >= 5) & (test.age_of_vehicle < 6)] = 'High'\ntest['age_of_vehicle_buckets'][(test.age_of_vehicle >= 3) & (test.age_of_vehicle < 5)] = 'Low'\ntest['age_of_vehicle_buckets'][test.age_of_vehicle < 3] = 'Very Low'\ntest['age_of_vehicle_buckets']","bcac784e":"train.vehicle_category.value_counts()\n\nsum(train.vehicle_category.isnull())","a6d3824e":"train.vehicle_price.describe()\n\nsum(train.vehicle_price.isnull())","e3098f6e":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['vehicle_price_buckets'] = train.vehicle_price\ntrain['vehicle_price_buckets'][train.vehicle_price >= 41500] = 'Very High'\ntrain['vehicle_price_buckets'][(train.vehicle_price >= 29500) & (train.vehicle_price < 41500)] = 'High'\ntrain['vehicle_price_buckets'][(train.vehicle_price >= 21000) & (train.vehicle_price < 29500)] = 'Average High'\ntrain['vehicle_price_buckets'][(train.vehicle_price >= 14250) & (train.vehicle_price < 21000)] = 'Average Low'\ntrain['vehicle_price_buckets'][(train.vehicle_price >= 5000) & (train.vehicle_price < 14250)] = 'Low'\ntrain['vehicle_price_buckets'][train.vehicle_price < 5000] = 'Very Low'\ntrain['vehicle_price_buckets']\n\ntest['vehicle_price_buckets'] = test.vehicle_price\ntest['vehicle_price_buckets'][test.vehicle_price >= 41500] = 'Very High'\ntest['vehicle_price_buckets'][(test.vehicle_price >= 29500) & (test.vehicle_price < 41500)] = 'High'\ntest['vehicle_price_buckets'][(test.vehicle_price >= 21000) & (test.vehicle_price < 29500)] = 'Average High'\ntest['vehicle_price_buckets'][(test.vehicle_price >= 14250) & (test.vehicle_price < 21000)] = 'Average Low'\ntest['vehicle_price_buckets'][(test.vehicle_price >= 5000) & (test.vehicle_price < 14250)] = 'Low'\ntest['vehicle_price_buckets'][test.vehicle_price < 5000] = 'Very Low'\ntest['vehicle_price_buckets']","f0e89bef":"train.vehicle_color.value_counts()\n\nsum(train.vehicle_color.isnull())","a94481fe":"train.vehicle_weight.describe()\n\nsum(train.vehicle_weight.isnull())","4eb86ec9":"# adding income buckets, classes based on Standard Deviation and Quartile Ranges\ntrain['vehicle_weight_buckets'] = train.vehicle_weight\ntrain['vehicle_weight_buckets'][train.vehicle_weight >= 41500] = 'Very High'\ntrain['vehicle_weight_buckets'][(train.vehicle_weight >= 29500) & (train.vehicle_weight < 41500)] = 'High'\ntrain['vehicle_weight_buckets'][(train.vehicle_weight >= 21000) & (train.vehicle_weight < 29500)] = 'Average High'\ntrain['vehicle_weight_buckets'][(train.vehicle_weight >= 14250) & (train.vehicle_weight < 21000)] = 'Average Low'\ntrain['vehicle_weight_buckets'][(train.vehicle_weight >= 5000) & (train.vehicle_weight < 14250)] = 'Low'\ntrain['vehicle_weight_buckets'][train.vehicle_weight < 5000] = 'Very Low'\ntrain['vehicle_weight_buckets']\n\ntest['vehicle_weight_buckets'] = test.vehicle_weight\ntest['vehicle_weight_buckets'][test.vehicle_weight >= 41500] = 'Very High'\ntest['vehicle_weight_buckets'][(test.vehicle_weight >= 29500) & (test.vehicle_weight < 41500)] = 'High'\ntest['vehicle_weight_buckets'][(test.vehicle_weight >= 21000) & (test.vehicle_weight < 29500)] = 'Average High'\ntest['vehicle_weight_buckets'][(test.vehicle_weight >= 14250) & (test.vehicle_weight < 21000)] = 'Average Low'\ntest['vehicle_weight_buckets'][(test.vehicle_weight >= 5000) & (test.vehicle_weight < 14250)] = 'Low'\ntest['vehicle_weight_buckets'][test.vehicle_weight < 5000] = 'Very Low'\ntest['vehicle_weight_buckets']","6275ee60":"train.fraud.value_counts()\n\nsum(train.fraud.isnull())","785e09c6":"train = train[~(train.fraud == -1)]","13a7ac4a":"train = train.apply(lambda x: x.fillna(x.value_counts().index[0]))\ntest = test.apply(lambda x: x.fillna(x.value_counts().index[0]))","ef676cb9":"# verifing no missing values are remaining in train and test data\ntrain.isnull().sum().sum()\nnp.sum(test.isnull()).sum()","13b4ed79":"# Amount Claim per unit Weight of Vehicle\ntrain['f1_claim_weight'] = np.log(train.claim_est_payout**2 \/ train.vehicle_weight)\ntest['f1_claim_weight'] = np.log(test.claim_est_payout**2 \/ test.vehicle_weight)\n\ntrain['f1_claim_weight'] = np.round(train['f1_claim_weight'], 1)\ntest['f1_claim_weight'] = np.round(test['f1_claim_weight'], 1)\n\ntrain['f1_claim_weight'].describe()","2d64bfc9":"# checking f1 distribution\nfig, ax = plt.subplots()\nfig.set_size_inches(12,6)\nsns.distplot(train['f1_claim_weight'])","2377219d":"# Amount Claim per unit Weight of Vehicle\ntrain['f2_income_claims'] = np.round(train.annual_income \/ 1000)*10 + train.past_num_of_claims\ntest['f2_income_claims'] = np.round(test.annual_income \/ 1000)*10 + test.past_num_of_claims\n\ntrain['f2_income_claims'].describe()\nlen(set(train['f2_income_claims']))","eeb9e245":"# verifing no missing values are remaining in train and test data\ntrain.isnull().sum().sum()\nnp.sum(test.isnull()).sum()","afd3c55e":"# creating subsets of data to be used for modeling\ntrain_total_x = train.drop('fraud', axis = 1)\ntrain_total_y = train['fraud']\ntest_x = test","1ba3055c":"# verifing no missing values are remaining in train and test data\ntrain_total_x.isnull().sum().sum()\nnp.sum(test_x.isnull()).sum()","eb64d323":"# label encoder\nle = LabelEncoder()\nobj_columns = [col for col in train_total_x.select_dtypes(include = ['object'])]","57d1da90":"# applying label encoder\nfor col in obj_columns:\n    train_total_x[col] = le.fit_transform(train_total_x[col])\n    test_x[col] = le.transform(test[col])","22b37e1e":"len(set(np.round(train_total_x.claim_est_payout, -2)))","f9624c21":"train.marital_status.value_counts()","8d4caa51":"train_total_x.high_education_ind.value_counts()","fab370b7":"# Amount Claim per unit Weight of Vehicle\ntrain_total_x['f3_accidents_claims'] = (train_total_x.accident_site * 10) + (train_total_x.past_num_of_claims)\ntest_x['f3_accidents_claims'] = (test_x.accident_site * 10) + (test_x.past_num_of_claims)\n\ntrain_total_x['f3_accidents_claims'].describe()\nlen(set(train_total_x['f3_accidents_claims']))","2c3192eb":"train_total_x['f4_liab_income'] = np.round((train_total_x.liab_prct * np.round(train_total_x.annual_income,-2)), -4)\ntest_x['f4_liab_income'] = np.round((test_x.liab_prct * np.round(test_x.annual_income,-2)), -4)\n\ntrain_total_x['f4_liab_income'].describe()\nlen(set(train_total_x['f4_liab_income']))","31cbd96f":"train_total_x['f5_liab_price'] = np.round((train_total_x.liab_prct * np.round(train_total_x.vehicle_price,-2)), -4)\ntest_x['f5_liab_price'] = np.round((test_x.liab_prct * np.round(test_x.vehicle_price,-2)), -4)\n\ntrain_total_x['f5_liab_price'].describe()\nlen(set(train_total_x['f5_liab_price']))","0000b160":"train_total_x['f6_liab_price_safty'] = np.round((train_total_x.liab_prct * np.round(train_total_x.vehicle_price,-2)), -4) \/ train_total_x.safty_rating\ntest_x['f6_liab_price_safty'] = np.round((test_x.liab_prct * np.round(test_x.vehicle_price,-2)), -4) \/ test_x.safty_rating\n\ntrain_total_x['f6_liab_price_safty'].describe()\nlen(set(train_total_x['f6_liab_price_safty']))","1247bdb7":"train_total_x['f7_claim_num_payout'] = (train_total_x.claim_number**3) * train_total_x.claim_est_payout\ntest_x['f7_claim_num_payout'] = (test_x.claim_number**3) * test_x.claim_est_payout\n\ntrain_total_x['f7_claim_num_payout'].describe()\nlen(set(train_total_x['f7_claim_num_payout']))","c973012e":"train_total_x['f8_living_claims'] = (train_total_x.living_status + 1) * (train_total_x.past_num_of_claims + 1)\ntest_x['f8_living_claims'] = (test_x.living_status + 1) * (test_x.past_num_of_claims + 1)\n\ntrain_total_x['f8_living_claims'].describe()\nlen(set(train_total_x['f8_living_claims']))","7ffdf5fe":"train_total_x['f9_witness_payout'] = (train_total_x.witness_present_ind + 1) * (train_total_x.past_num_of_claims + 1) * np.round(train_total_x.claim_est_payout, -2)\ntest_x['f9_witness_payout'] = (test_x.witness_present_ind + 1) * (test_x.past_num_of_claims + 1) * np.round(test_x.claim_est_payout, -2)\n\ntrain_total_x['f9_witness_payout'].describe()\nlen(set(train_total_x['f9_witness_payout']))","8f897877":"train_total_x['f10_interaction_f2_f3'] = np.sqrt((train_total_x.f2_income_claims + 1) * (train_total_x.f3_accidents_claims + 1))\ntest_x['f10_interaction_f2_f3'] = np.sqrt((test_x.f2_income_claims + 1) * (test_x.f3_accidents_claims + 1))\n\ntrain_total_x['f10_interaction_f2_f3'].describe()\nlen(set(train_total_x['f10_interaction_f2_f3']))","8fb96071":"train_total_x['f11_education_claim'] = (train_total_x.claim_est_payout) \/ (train_total_x.high_education_ind + 1)\ntest_x['f11_education_claim'] = (test_x.claim_est_payout) \/ (test_x.high_education_ind + 1)\n\ntrain_total_x['f11_education_claim'].describe()\nlen(set(train_total_x['f11_education_claim']))","301f3ab8":"train_total_x['f12_witness_f5'] = (train_total_x.witness_present_ind + 1) * np.log(train_total_x.f5_liab_price + 1)\ntest_x['f12_witness_f5'] = (test_x.witness_present_ind + 1) * np.log(test_x.f5_liab_price + 1)\n\ntrain_total_x['f12_witness_f5'].describe()\nlen(set(train_total_x['f12_witness_f5']))","1d6a94a3":"train_total_x['f13_matital_f2'] = np.round((train_total_x.marital_status + 1) * np.sqrt(train_total_x.f2_income_claims),1)\ntest_x['f13_matital_f2'] = np.round((test_x.marital_status + 1) * np.sqrt(test_x.f2_income_claims),1)\n\ntrain_total_x['f12_witness_f5'].describe()\nlen(set(train_total_x['f12_witness_f5']))","4180a301":"# removing features not important - Sawyer Model\nremove_cols = ['f1_claim_weight', 'f7_claim_num_payout', 'claim_day_of_week', 'claim_est_payout_buckets',\n               'f9_witness_payout', 'vehicle_price_buckets', 'f4_liab_income', 'witness_present_ind', 'age_of_driver', 'policy_report_filed_ind',\n              'marital_status', 'living_status', 'accident_site', 'channel', 'f5_liab_price', 'age_of_driver_buckets', 'vehicle_category',\n              'vehicle_weight_buckets', 'age_of_vehicle_buckets', 'liab_prct_buckets', 'vehicle_color', 'claim_month', 'annual_income_buckets',\n              'safty_rating_logsq', 'safty_rating_int', 'safty_rating_buckets']\n\ntrain_total_x = train_total_x.drop(remove_cols, axis = 1)\ntest_x = test_x.drop(remove_cols, axis = 1)","00b53f6e":"# columns list\nfinal_cols = train_total_x.columns","a09d37b4":"# Normalizing Data\n##~ norm = Normalizer()\n##~ train_total_x = norm.fit_transform(train_total_x)\n##~ test_x = norm.transform(test_x)","2b88fcaa":"# MinMax Scaling\nscaler = MinMaxScaler()\ntrain_total_x = scaler.fit_transform(train_total_x)\ntest_x = scaler.transform(test_x)","585a70df":"train_total_x = pd.DataFrame(train_total_x)\ntest_x = pd.DataFrame(test_x)","343c7353":"train_total_x.head()","bbf3b76e":"np.sum(np.sum(train_total_x.isnull()))\nnp.sum(np.sum(test_x.isnull()))","4b784b64":"# train-development split\ntrain_x, devl_x, train_y, devl_y = train_test_split(train_total_x, train_total_y, test_size = 0.35, random_state = 3)","0e237f89":"len(train_x)\nlen(train_y)\n##! len(devl_x)\n##! len(devl_y)","686929df":"# number of columns\nlen(train_x.columns)\n##! len(devl_x.columns)\nlen(test_x.columns)","07b2558e":"train_y.sum()\ntrain_y.sum() \/ len(train_y)\n\n##! devl_y.sum()\n##! devl_y.sum() \/ len(devl_y)","90978551":"## Sawyer\n\nfrom xgboost import XGBClassifier\nparam_test2 = {'learning_rate':[0.1], 'reg_alpha':[3,30,70,150,200]}\ngsearch2 = GridSearchCV(estimator = XGBClassifier(n_estimators=1000,gamma=4,max_depth=2,min_child_weight=5),\n                        param_grid = param_test2, scoring='roc_auc',cv=10)\ngsearch2.fit(train_x, train_y)\nprint('Accurary of Xgboost Classifier on train_x: {:.3f}' .format(gsearch2.score(train_x, train_y)))\nprint('Accurary of Xgboost Classifier on devl_x: {:.3f}' .format(gsearch2.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', gsearch2.best_params_)\nprint('Grid best score (accuary):', gsearch2.best_score_)","cdc608c3":"xgb2_train = gsearch2.predict_proba(train_x)[:,1]\nxgb2_devl = gsearch2.predict_proba(devl_x)[:,1]\nxgb2_predictions = gsearch2.predict_proba(test_x)[:,1]\nsum(np.round(xgb2_train))\nsum(np.round(xgb2_devl))\nsum(np.round(xgb2_predictions))","7ef3a3b1":"imp_feat = pd.DataFrame(gsearch2.best_estimator_.feature_importances_, final_cols)\nimp_feat.sort_values(by=[0], ascending=False)","b84541a1":"train_predictions = xgb2_train\ndevl_predictions = xgb2_devl\ntest_predictions = xgb2_predictions","eb854c7d":"print('Accurary of Final Classifier on train_x: {:.3f}' .format(roc_auc_score(train_y, train_predictions)))\nprint('Accurary of Final Classifier on devl_x: {:.3f}' .format(roc_auc_score(devl_y, devl_predictions)))","e189939b":"my_submission = pd.DataFrame({'claim_number': test_org.claim_number, 'fraud': test_predictions})\nmy_submission.to_csv('submission.csv', index=False)","0b1e6d18":"my_submission.head()","9586e360":"imp_feat = pd.DataFrame(xgb_grid.best_estimator_.feature_importances_, final_cols)\nimp_feat.sort_values(by=[0], ascending=False)","7941a947":"## Gradient Boosting Classifier","38b01b46":"## XGB without GridSearch (GradientBoostingClassifier from sklearn)","e1dba5e2":"## 23. vehicle_color - Color of first party vehicle","160fe83f":"## Normalizing Data","b02711a7":"#### Data Modification","607de876":"log_train = log_grid.predict_proba(train_x)[:,1]\nlog_devl = log_grid.predict_proba(devl_x)[:,1]\nlog_predictions = log_grid.predict_proba(test_x)[:,1]\nsum(np.round(log_predictions))","ff06b94c":"from sklearn.metrics import f1_score,confusion_matrix\ncm_2 = confusion_matrix(devl_y,gsearch2.predict(devl_x))\nsns.heatmap(cm_2,annot=True,fmt=\"d\")","c205d5f1":"## Creating Train - Test Working Copy","77fdf9f2":"## 10. zip_code - Driver\u2019s living address zipcode","426a3f53":"xgb_train = xgb_grid.predict_proba(train_x)[:,1]\nxgb_devl = xgb_grid.predict_proba(devl_x)[:,1]\nxgb_predictions = xgb_grid.predict_proba(test_x)[:,1]\nsum(np.round(xgb_predictions))","ff0efa33":"## Absolute New & Weird Features","d80b30e7":"#### Note: All unique values, can act as Primary Key","54c7d5ce":"#### Data Modification","b6782bd5":"## 11. claim_date - Date of first notice of claim","a0e259b4":"## XGB Model (Sawyer's Code)","987a233a":"from sklearn.ensemble import GradientBoostingClassifier\nxgb_grid = GradientBoostingClassifier(learning_rate = 0.3, max_depth = 3, min_samples_leaf = 10, max_leaf_nodes = 2) #0.3 #3 #10 #2\nxgb_grid.fit(train_x, train_y)\nprint('Accurary of Gradient Boosting Classifier on train_x: {:.3f}' .format(xgb_grid.score(train_x, train_y)))\nprint('Accurary of Gradient Boosting Tree Regression Classifier on devl_x: {:.3f}' .format(xgb_grid.score(devl_x, devl_y)))","65815beb":"## Random Forest","9a08f3df":"train_predictions = np.array([xgb_train, log_train, nn_train])\ntrain_predictions = train_predictions.sum(axis=0)\/3\n\ndevl_predictions = np.array([xgb_devl, log_devl, nn_devl])\ndevl_predictions = devl_predictions.sum(axis=0)\/3\n\ntest_predictions = np.array([xgb_predictions, log_predictions, nn_predictions])\ntest_predictions = test_predictions.sum(axis=0)\/3\n\nsum(np.round(test_predictions))","aca8c771":"cutoff = 0.5\ntrain_predictions[train_predictions > cutoff] = 1\ndevl_predictions[devl_predictions > cutoff] = 1\ntest_predictions[test_predictions > cutoff] = 1","8cdb2167":"## 19. claim_est_payout - Estimated claim payout","10bb9665":"# building decision tree classifier\ngrid_values = {'max_leaf_nodes': [35,55,75]} #\ndf_clf = DecisionTreeClassifier(min_samples_split=0.085, max_features=25)\ndt_grid = GridSearchCV(df_clf, param_grid = grid_values, scoring = 'roc_auc', cv=10)\ndt_grid.fit(train_x, train_y)\nprint('Accurary of Decision Tree Classifier on train_x: {:.3f}' .format(dt_grid.score(train_x, train_y)))\nprint('Accurary of Decision Tree Regression Classifier on devl_x: {:.3f}' .format(dt_grid.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', dt_grid.best_params_)\nprint('Grid best score (accuary):', dt_grid.best_score_)","8ba0e5c0":"## 2. age_of_driver - Getting to know the Old Man (The Age of Driver)","b89a20f7":"\n## Number of Positive Cases","e23c7c03":"dt_train = dt_grid.predict_proba(train_x)[:,1]\ndt_devl = dt_grid.predict_proba(devl_x)[:,1]\ndt_predictions = dt_grid.predict_proba(test_x)[:,1]\nsum(np.round(dt_predictions))","0b576b4c":"## 18. policy_report_filed_ind - Policy report filed indicator","36e41cbc":"#### Note: There are two classes, 1 and 0. Majority class is 1 (with 12k values) vs 0 (with 5k values)\n#### There were 5 missing values, the values were imputed the mode, which is 1","7b25a98c":"## More New Features","4a69968f":"## 1. claim_number - Understanding our Primary Key","69205cd8":"## Feature Selection","107779bb":"## 15. witness_present_ind - Witness indicator of the claim","44a11e16":"#### Note: Classes are near equally distributed","8369f775":"# Min-Max Scaling\nscaler = MinMaxScaler()\nnum_columns = ['age_of_driver', 'safty_rating_logsq', 'annual_income', 'high_education_ind',\n            'address_change_ind', 'witness_present_ind', 'liab_prct', 'policy_report_filed_ind',\n            'claim_est_payout', 'age_of_vehicle', 'vehicle_price', 'vehicle_weight', 'claim_date_delta']\n\nfor col in num_columns:\n    train_total_x[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(train_total_x[col])),columns=[col])\n    test_x[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(test_x[col])),columns=[col])\n#test_x[col] = scaler.transform(test_x[col])\n\n# converting back to Data Frame\ntrain_total_x = pd.DataFrame(train_total_x)\ntest_x = pd.DataFrame(test_x)","da65cf2e":"## Logistic Regression","1e9a81d4":"#### Note: We observe postive skewness, that is right skewed data for the age of driver.\n#### Modified ages above 90 years as 90","fe989e9f":"## 16. liab_prct - Liability percentage of the claim","e0cb7073":"rf_train = rf_clf.predict_proba(train_x)[:,1]\nrf_devl = rf_clf.predict_proba(devl_x)[:,1]\nrf_predictions = rf_clf.predict_proba(test_x)[:,1]\nsum(np.round(rf_predictions))","7817806f":"#### + adding new Variables","3f6ec13a":"from sklearn.neural_network import MLPClassifier\n#nn_clf = MLPClassifier(hidden_layer_sizes = [20,12,7], solver='lbfgs', random_state = 0).fit(train_x, train_y)\nnn_clf = MLPClassifier(solver='adam', activation = 'relu',alpha = 0.3,\n                         hidden_layer_sizes = [7,7,7],\n                         random_state = 0).fit(train_x, train_y)\nprint('Accurary of NN Classifier on train_x: {:.3f}' .format(roc_auc_score(train_y, nn_clf.predict_proba(train_x)[:,1])))\nprint('Accurary of NN Classifier on devl_x: {:.3f}' .format(roc_auc_score(devl_y, nn_clf.predict_proba(devl_x)[:,1])))","1bd58a4c":"## Rough Work","c2e2104a":"## Neural Network","9932d458":"# removing features not important - My Model\nremove_cols = ['vehicle_price','f1_claim_weight',\n               'age_of_vehicle_buckets', 'f6_liab_price_safty', 'claim_number', 'living_status', 'vehicle_weight', 'claim_day_of_week',\n               'f5_liab_price', 'f7_claim_num_payout', 'vehicle_price_buckets', 'f4_liab_income', 'safty_rating_int', 'claim_month',\n               'vehicle_weight', 'safty_rating_buckets', 'claim_day_of_week', 'claim_est_payout_buckets', 'claim_number',\n               'annual_income_buckets', 'liab_prct_buckets', 'age_of_driver_buckets', 'channel', 'accident_site', 'vehicle_color',\n               'vehicle_weight_buckets', 'age_of_driver', 'vehicle_category', 'policy_report_filed_ind']\n\ntrain_total_x = train_total_x.drop(remove_cols, axis = 1)\ntest_x = test_x.drop(remove_cols, axis = 1)","a3831ed8":"## 13. accident_site - Accident location, highway, parking lot or local","f612a74a":"## 6. annual_income - Annual income of Driver","92137259":"## 8. address_change_ind - Whether or not the driver changed living address in past 1 year","406228d6":"train_total_x.annual_income = np.round(train_total_x.annual_income \/ 1000)\ntrain_total_x.claim_est_payout = np.round(train_total_x.claim_est_payout \/ 100)\ntrain_total_x.vehicle_price = np.round(train_total_x.vehicle_price \/ 100)\ntrain_total_x.claim_date_delta = np.round(train_total_x.claim_date_delta \/ 10)\n\ntest_x.annual_income = np.round(test_x.annual_income \/ 1000, 2)\ntest_x.claim_est_payout = np.round(test_x.claim_est_payout \/ 100)\ntest_x.vehicle_price = np.round(test_x.vehicle_price \/ 100)\ntest_x.claim_date_delta = np.round(test_x.claim_date_delta \/ 100,1)","483c7406":"## XGB Parameter Tuning\n\nfrom xgboost import XGBClassifier\nparam_test2 = {'n_estimators': [100]}\ngsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, max_depth=5, min_child_weight=1,\n                                                  gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',\n                                                  nthread=4, scale_pos_weight=1, seed=27),\n                        param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=10)\n\ngsearch2.fit(train_x, train_y)\nprint('Accurary of Xgboost Classifier on train_x: {:.3f}' .format(gsearch2.score(train_x, train_y)))\nprint('Accurary of Xgboost Classifier on devl_x: {:.3f}' .format(gsearch2.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', gsearch2.best_params_)\nprint('Grid best score (accuary):', gsearch2.best_score_)","9fcb8384":"## 4. marital_status - Marital Status of the Driver","6c4152bf":"## Analyzing Data before passing to Model","53ef2e77":"# building logistic classifier\ngrid_values = {'C':[10]}\nlog_clf = LogisticRegression(penalty='l1')\nlog_grid = GridSearchCV(log_clf, param_grid = grid_values, scoring = 'roc_auc')\nlog_grid.fit(train_x, train_y)\nprint('Accurary of Logistic Regression Classifier on train_x: {:.3f}' .format(log_grid.score(train_x, train_y)))\nprint('Accurary of Logistic Regression Classifier on devl_x: {:.3f}' .format(log_grid.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', log_grid.best_params_)\nprint('Grid best score (accuary):', log_grid.best_score_)","90793c6f":"## Decision Tree","ecf0e3b6":"from sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier().fit(train_x, train_y)\nprint('Accurary of Random Forest Classifier on train_x: {:.3f}' .format(roc_auc_score(train_y, rf_clf.predict_proba(train_x)[:,1])))\nprint('Accurary of Random Forest Classifier on devl_x: {:.3f}' .format(roc_auc_score(devl_y, rf_clf.predict_proba(devl_x)[:,1])))","422d47c6":"nn_train = nn_clf.predict_proba(train_x)[:,1]\nnn_devl = nn_clf.predict_proba(devl_x)[:,1]\nnn_predictions = nn_clf.predict_proba(test_x)[:,1]\nsum(np.round(nn_predictions))","a4487c97":"## 22. vehicle_price - Price of first party vehicle","7684a5f1":"## 25. fraud - Fraud indicator (0=no, 1=yes). This is the response variable","1d4845c6":"## 17. channel - The channel of policy purchasing","28f0727a":"## 20. age_of_vehicle - Age of first party vehicle","9dcd9482":"# building Support Vector Classifier\ngrid_values = {'gamma': [0.001, 0.03, 1, 10, 300]}\nsvc_clf = SVC(kernel = 'rbf')\nsvc_grid = GridSearchCV(svc_clf, param_grid = grid_values, scoring = 'roc_auc')\nsvc_grid.fit(train_x, train_y)\nprint('Accurary of Support Vector Classifier on train_x: {:.3f}' .format(svc_grid.score(train_x, train_y)))\nprint('Accurary of Support Vector Classifier on devl_x: {:.3f}' .format(svc_grid.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', svc_grid.best_params_)\nprint('Grid best score (accuary):', svc_grid.best_score_)","f387287b":"## 14. past_num_of_claims - Number of claims the driver reported in past 5 years","05a5d9fa":"## 9. living_status - Driver\u2019s living status, own or rent","113787b9":"# Introduction to the Problem","535ac1df":"## 3. gender - Gender of Driver","c14255c0":"## Support Vector Classifier","8e11e1d7":"## 21. vehicle_category - Category of first party vehicle","ce8a024a":"## Imputing Nulls","41894ae7":"## 7. high_education_ind - Driver\u2019s high education index","3b98e12e":"## 12. claim_day_of_week - Day of week of first notice of claim","788bd764":"## Gaussian Naive Bayes","97d0969a":"## 5. safty_rating - Safety Rating Index of Driver","e18b76f3":"#### + adding new Variables","559e03db":"## v12\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngrid_values = {'max_features': [9,'log2'], 'min_samples_leaf': [10,20,30], 'max_leaf_nodes': [2,3]}\nxgb_clf = GradientBoostingClassifier(n_estimators = 440, random_state=9, max_features =3, learning_rate=0.1, max_depth=3)\n\nxgb_grid = GridSearchCV(xgb_clf, param_grid = grid_values, scoring = 'roc_auc', cv=10)\nxgb_grid.fit(train_x, train_y)\nprint('Accurary of Gradient Boosting Classifier on train_x: {:.3f}' .format(xgb_grid.score(train_x, train_y)))\nprint('Accurary of Gradient Boosting Tree Regression Classifier on devl_x: {:.3f}' .format(xgb_grid.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', xgb_grid.best_params_)\nprint('Grid best score (accuary):', xgb_grid.best_score_)","37c40fcc":"nb_train = nb_clf.predict_proba(train_x)[:,1]\nnb_devl = nb_clf.predict_proba(devl_x)[:,1]\nnb_predictions = nb_clf.predict_proba(test_x)[:,1]\nsum(np.round(nb_predictions))","ccfa0d7e":"# Setting up the Space","32a93630":"## 24. vehicle_weight - Weight of first party vehicle","adb373b0":"# Exploratory Data Analysis","2e949931":"from sklearn.naive_bayes import GaussianNB\nnb_clf = GaussianNB().fit(train_x, train_y)\nprint('Accurary of GaussianNB Classifier on train_x: {:.3f}' .format(roc_auc_score(train_y, nb_clf.predict_proba(train_x)[:,1])))\nprint('Accurary of GaussianNB Classifier on devl_x: {:.3f}' .format(roc_auc_score(devl_y, nb_clf.predict_proba(devl_x)[:,1])))","0c5332cd":"All first party physical damage claims will be filtered by claim handlers and some of them will be referred to fraud detection team. Your data is a sample of these referred claims from 2015 to 2016. There are two datasets, train and test. In test data, fraud indicator is NA. Your work is to build a model on training data and apply your model to predict the fraud indicator for each claim in test data.\n\n**File descriptions**\n* train.csv - the training set\n* test.csv - the test set\n* sampleSubmission.csv - a sample submission file in the correct format\n\n**Data fields**\n* **claim number** - Claim ID (cannot be used in model)\n* **age_of_driver** - Age of driver\n* **gender** - Gender of driver\n* **marital_status** - Marital status of driver\n* **safty_rating** - Safety rating index of driver\n* **annual_income** - Annual income of driver\n* **high_education_ind** - Driver\u2019s high education index\n* **address_change_ind** - Whether or not the driver changed living address in past 1 year\n* **living_status** - Driver\u2019s living status, own or rent\n* **zip_code** - Driver\u2019s living address zipcode\n* **claim_date** - Date of first notice of claim\n* **claim_day_of_week** - Day of week of first notice of claim\n* **accident_site** - Accident location, highway, parking lot or local\n* **past_num_of_claims** - Number of claims the driver reported in past 5 years\n* **witness_present_ind** - Witness indicator of the claim\n* **liab_prct** - Liability percentage of the claim\n* **channel** - The channel of policy purchasing\n* **policy_report_filed_ind** - Policy report filed indicator\n* **claim_est_payout** - Estimated claim payout\n* **age_of_vehicle** - Age of first party vehicle\n* **vehicle_category** - Category of first party vehicle\n* **vehicle_price** - Price of first party vehicle\n* **vehicle_color** - Color of first party vehicle\n* **vehicle_weight** - Weight of first party vehicle\n* **fraud** - Fraud indicator (0=no, 1=yes). This is the response variable","9acf3810":"## v13\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngrid_values = {'min_samples_leaf': [20], 'max_leaf_nodes': [2]}\nxgb_clf = GradientBoostingClassifier(learning_rate = 0.1, n_estimators = 440, random_state=9, max_features ='sqrt', max_depth = 3, subsample=0.7)\n\nxgb_grid = GridSearchCV(xgb_clf, param_grid = grid_values, scoring = 'roc_auc', cv=10)\nxgb_grid.fit(train_x, train_y)\nprint('Accurary of Gradient Boosting Classifier on train_x: {:.3f}' .format(xgb_grid.score(train_x, train_y)))\nprint('Accurary of Gradient Boosting Tree Regression Classifier on devl_x: {:.3f}' .format(xgb_grid.score(devl_x, devl_y)))\n\nprint('Grid best parameter (max. accuary): ', xgb_grid.best_params_)\nprint('Grid best score (accuary):', xgb_grid.best_score_)","4097db8f":"## Modeling"}}