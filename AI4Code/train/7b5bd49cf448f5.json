{"cell_type":{"d786a1be":"code","9d28dbd9":"code","10524c11":"code","306dfd90":"code","4f3ac521":"code","a7becff1":"code","e385f842":"code","2260ebbe":"code","52ba4ad3":"code","815a2f63":"code","8d971a87":"code","f98930e5":"code","99c4fc35":"code","7bc4b0f9":"code","b5b9676f":"code","48683028":"code","84517d46":"code","7b4e96cd":"code","f0e778d2":"code","01265242":"code","e9c581e7":"code","ee3a7b05":"code","ee6ce20c":"code","14dbde0a":"code","a11d510b":"code","7a5a621c":"code","4c91a008":"code","0fb02a07":"code","81fc47fc":"code","f0a7304b":"code","11e9f509":"code","0d5aef66":"code","ec0a1c67":"code","0b1ad164":"code","378507aa":"code","3113122d":"code","7e301db2":"code","484fbbdf":"code","4307a23d":"code","f35fe63b":"code","71895546":"code","0a21a256":"code","59398140":"code","2cdb623a":"code","641bcf2e":"code","189b3719":"code","b7b99115":"code","20c5e952":"code","091be4cc":"markdown","640a9b5a":"markdown","3204a20f":"markdown","74fa82ee":"markdown","93571609":"markdown","891396e5":"markdown","d02017fc":"markdown","8b8bc68b":"markdown","e2805505":"markdown","77cf7838":"markdown","263afd85":"markdown","d8511f35":"markdown","c093c78b":"markdown"},"source":{"d786a1be":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport csv\nfrom pandas import DataFrame \nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nimport time\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nwarnings.filterwarnings('ignore')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9d28dbd9":"data_train = pd.read_csv('\/kaggle\/input\/healthcare-dataset-stroke-data\/train_2v.csv',low_memory=False,skipinitialspace=True)\ndata_test = pd.read_csv('\/kaggle\/input\/healthcare-dataset-stroke-data\/test_2v.csv',low_memory=False,skipinitialspace=True)","10524c11":"print(data_test.shape)\nprint(data_train.shape)\nprint(data_test.columns)\nprint(data_train.columns)","306dfd90":"data_stroke =data_train","4f3ac521":"data_stroke.head()","a7becff1":"data_stroke.isnull().sum()","e385f842":"sns.heatmap(data_stroke.isnull(), yticklabels=False, cbar=False, cmap='viridis')","2260ebbe":"f, ax = plt.subplots(figsize=(8, 6))\nsns.countplot(x=\"stroke\", data=data_stroke, color=\"c\")\nplt.show()","52ba4ad3":"data_stroke['age'].hist(bins=100)","815a2f63":"sns.kdeplot(data_stroke.loc[(data_stroke['stroke']==1), \n            'age'], color='r', shade=True, Label='Stroke') \n  \nsns.kdeplot(data_stroke.loc[(data_stroke['stroke']==0),  \n            'age'], color='b', shade=True, Label='No Stroke') \n  \nplt.xlabel('Age') \nplt.ylabel('Probability Density') ","8d971a87":"sns.kdeplot(data_stroke.loc[(data_stroke['stroke']==1), \n            'avg_glucose_level'], color='r', shade=True, Label='Stroke') \n  \nsns.kdeplot(data_stroke.loc[(data_stroke['stroke']==0),  \n            'avg_glucose_level'], color='b', shade=True, Label='No Stroke') \n  \nplt.xlabel('Avg_glucose_level') \nplt.ylabel('Probability Density') ","f98930e5":"sns.kdeplot(data_stroke.loc[(data_stroke['stroke']==1), \n            'hypertension'], color='r', shade=True, Label='Stroke') \n  \nsns.kdeplot(data_stroke.loc[(data_stroke['stroke']==0),  \n            'hypertension'], color='b', shade=True, Label='No Stroke') \n  \nplt.xlabel('hypertension') \nplt.ylabel('Probability Density') ","99c4fc35":"sns.kdeplot(data_stroke.loc[(data_stroke['stroke']==1), \n            'bmi'], color='r', shade=True, Label='Stroke') \n  \nsns.kdeplot(data_stroke.loc[(data_stroke['stroke']==0),  \n            'bmi'], color='b', shade=True, Label='No Stroke') \n  \nplt.xlabel('Body Mass Index') \nplt.ylabel('Probability Density') ","7bc4b0f9":"data_stroke['bmi'].fillna(data_stroke['bmi'].mean(),inplace=True)","b5b9676f":"from sklearn.preprocessing import LabelEncoder\n# instantiate labelencoder object\nlabelEncoder = LabelEncoder()\ndata_stroke['gender'] = labelEncoder.fit_transform(data_stroke['gender'])\ndata_stroke['ever_married'] = labelEncoder.fit_transform(data_stroke['ever_married'])\ndata_stroke['work_type'] = labelEncoder.fit_transform(data_stroke['work_type'])\ndata_stroke['Residence_type'] = labelEncoder.fit_transform(data_stroke['Residence_type'])","48683028":"data_stroke.isnull().sum()","84517d46":"print(data_stroke.smoking_status.value_counts())\nprint(data_stroke[data_stroke.smoking_status.isnull()]['stroke'].value_counts())","7b4e96cd":"data_stroke.drop('smoking_status',axis = 1, inplace = True)","f0e778d2":"data_stroke.drop('id',axis = 1, inplace = True)","01265242":"data_stroke.isnull().sum()","e9c581e7":"data_shuffled = data_stroke.sample(frac=1,random_state=4)\ndf_Isstroke = data_stroke.loc[data_stroke['stroke'] == 1]\ndf_Nostroke = data_stroke.loc[data_stroke['stroke'] == 0].sample(n= 4500,random_state= 101)","ee3a7b05":"df_data_stroke = pd.concat([df_Isstroke,df_Nostroke])","ee6ce20c":"df_data_stroke.stroke.value_counts()","14dbde0a":"from sklearn.model_selection import train_test_split \nfrom sklearn.utils import shuffle\ndf_data_stroke = shuffle(df_data_stroke)\nX = df_data_stroke.drop('stroke', axis = 1)\ny = df_data_stroke['stroke']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=101)","a11d510b":"print('X Train dataset shapes',X_train.shape)\nprint('Y Train dataset shapes',y_train.shape)\nprint('X Test dataset shapes',X_test.shape)\nprint('Y Test dataset shapes',y_test.shape)","7a5a621c":"from sklearn.linear_model import LogisticRegression","4c91a008":"logRe = LogisticRegression()\nlogRe.fit(X_train,y_train)","0fb02a07":"predictions = logRe.predict(X_test)","81fc47fc":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","f0a7304b":"print(classification_report(y_test,predictions))\nlogRe.score(X_test, y_test)","11e9f509":"print(confusion_matrix(y_test,predictions))","0d5aef66":"from sklearn import metrics\nsns.heatmap(confusion_matrix(y_test,predictions), annot= True, fmt=\".2f\")\nplt.title('Logistic Regression \\n Confusion Matrix', fontsize=14)\nprint(roc_auc_score(y_test, predictions))","ec0a1c67":"test_stroke = y_test.values\nfor i in range(0, len(test_stroke)):\n    if predictions[i] == test_stroke[i]:\n        print ('Pred: {0} Actual:{1}'.format(predictions[i], test_stroke[i]))\n    else:\n        print('Wrong Prediction')\n        print ('Pred: {0} Actual:{1}'.format(predictions[i], test_stroke[i]))","0b1ad164":"import statsmodels.api as sm\n\nlogit_model = sm.Logit(y_train,sm.add_constant(X_train))","378507aa":"result = logit_model.fit()","3113122d":"print(result.summary2())","7e301db2":"def get_significant_vars(lm):\n    #Store the pvalues to corresponding columns\n    df_p_vals = pd.DataFrame(lm.pvalues)\n    df_p_vals['vars'] = df_p_vals.index\n    df_p_vals.columns=['p_values','variables']\n    return list(df_p_vals[df_p_vals['p_values']<=0.05]['variables'])","484fbbdf":"significant_var= get_significant_vars(result)\nprint(significant_var)","4307a23d":"if 'const' in significant_var:\n    significant_var.remove('const')\n    logit_model1 = sm.Logit(y_train,sm.add_constant(X_train[significant_var]))","f35fe63b":"final_logit = logit_model1.fit()","71895546":"print(final_logit.summary2())","0a21a256":"# cols_significant = significant_var.remove('const')\n\nprint(X_test[significant_var].columns)\nresult =final_logit.predict(sm.add_constant(X_test[significant_var]))\nY_pred_df= pd.DataFrame({\"actuals\":y_test,\"predicted_prob\":result})\nY_pred_df.sample(100,random_state=50)","59398140":"Y_pred_df['Predicted']= Y_pred_df.predicted_prob.map(lambda x: 1 if x > 0.3 else 0)\nY_pred_df.sample(100,random_state=42)","2cdb623a":"def create_cm(actuals, predicted):\n    sns.heatmap(confusion_matrix(actuals,predicted), annot= True, fmt=\".2f\")\n    plt.title('Logistic Regression \\n Confusion Matrix', fontsize=14)\n    plt.ylabel('True Lable')\n    plt.xlabel('Predicted Lable')\n    plt.show()","641bcf2e":"create_cm(Y_pred_df.actuals,Y_pred_df.Predicted)","189b3719":"print(classification_report(Y_pred_df.actuals,Y_pred_df.Predicted))","b7b99115":"def create_roc_auc(actuals, predicted):\n    logit_roc_auc = roc_auc_score(actuals, predicted)\n    fpr, tpr, thresholds = roc_curve(actuals, predicted )\n    plt.figure()\n    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n    plt.plot([0, 1], [0, 1],'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Log_ROC')\n    plt.show()","20c5e952":"create_roc_auc(Y_pred_df.actuals,Y_pred_df.Predicted)","091be4cc":"**Optimal classification cut off value**\n\nLets assume the OCC value us 0.3 as of now","640a9b5a":"**StatsModel api- LogisticRegression **","3204a20f":"**EDA on dataset**","74fa82ee":"**UnderSampling technique**\n \nsince the data is imbalanced , the undersampling technique is processed","93571609":"** Dropping the smoking_status column , Since 30% of data is missing**","891396e5":"**Handling Missing Data**","d02017fc":"**Since there is no stroke column available in test dataset , considering only Train dataset for whole analysis**","8b8bc68b":"**Get the significant variables from logit model**","e2805505":"**Applying Logistic Regression Model**","77cf7838":"**ID column is not required in this Logistic Regression Prediction **","263afd85":"**Split the data as train and test**","d8511f35":"**A countplot shows the counts of observations in each categorical bin using bars.**","c093c78b":"**Handling the Categorical columns**"}}