{"cell_type":{"17dbb006":"code","2a8a1623":"code","3172237a":"code","afbcaf9e":"code","2df583a6":"code","cdb6f2b5":"code","6792b084":"code","f1b2920c":"code","b0596165":"code","49b26403":"code","92bbeb0c":"code","a37a9a45":"code","c6741b0e":"code","d4e05cff":"code","e1a21a23":"code","fd6ddba3":"code","77620db8":"code","8c2c03d7":"code","ae77db8d":"code","1c3cb904":"code","882996d1":"code","b1f3f1c3":"code","908a6f54":"code","d93474ed":"code","ee865c03":"code","ca1fa83e":"markdown","47c8e3e6":"markdown","ac113f18":"markdown","f8a5128b":"markdown","c5e76ff5":"markdown","039648a9":"markdown","aa40bfad":"markdown","39a3d534":"markdown","d7a426c2":"markdown","fc97251a":"markdown","8e5bccdf":"markdown","322fb31f":"markdown","36c354ec":"markdown"},"source":{"17dbb006":"import time\nimport copy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\ntorch.manual_seed(17)","2a8a1623":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\",dtype = np.float32)\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\",dtype = np.float32)\nsubmission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nprint(\"Train set shape:\", train.shape)\nprint(\"Test set shape:\", test.shape)","3172237a":"label_dist = dict(train.label.value_counts())\nnumber = label_dist.keys()\ncount = label_dist.values() \n   \nfig = plt.figure(figsize = (8, 5)) \n   \nplt.bar(number, count, width = 0.5) \n  \nplt.xlabel(\"Label\") \nplt.ylabel(\"No. of samples\") \nplt.title(\"Distribution of labels\") \nplt.show() ","afbcaf9e":"plt.imshow(train.iloc[0, 1:].values.reshape(28,28))\nplt.axis(\"off\")\nplt.title(str(train.iloc[0, 0]))\nplt.show()","2df583a6":"#numpy.ndarray\nlabels = train.label.values\ndata = train.iloc[:, 1:].values \/ 255 # Normalization","cdb6f2b5":"#torch.Tensor\nlabels = torch.from_numpy(labels).type(torch.LongTensor)\ndata = torch.from_numpy(data).view(data.shape[0], 1, 28, 28)","6792b084":"#split the data\ntrain_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size = 0.2, random_state = 42) ","f1b2920c":"class CustomTensorDataset(Dataset):\n\n    def __init__(self, data, labels=None, transform=None):      \n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n    def __getitem__(self, index):       \n        x = self.data[index]\n        \n        if self.transform is not None:\n            x = self.transform(x)\n        if self.labels is not None:\n            y = self.labels[index]\n            return x, y\n        else:\n            return x\n\n    def __len__(self):    \n        return self.data.size(0)","b0596165":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomAffine(degrees=20, scale=(1.1, 1.1)),\n    transforms.RandomCrop((28, 28), padding=2, pad_if_needed=True, fill=0, padding_mode='constant'),\n    transforms.ToTensor()\n])","49b26403":"sample = CustomTensorDataset(train_data[:3], train_labels[:3])\nsample_aug = CustomTensorDataset(train_data[:3], train_labels[:3], transform=transform)\n\nfig, axs = plt.subplots(2, 3)\n\nfor idx, item in enumerate(zip(sample, sample_aug)):\n    \n    im = item[0][0].squeeze().numpy()\n    im_aug = item[1][0].squeeze().numpy()\n\n    axs[0, idx].imshow(im)\n    axs[0, idx].set_title(\"w\/o aug\")\n    axs[0, idx].axis('off')\n    \n    axs[1, idx].imshow(im_aug)\n    axs[1, idx].set_title(\"aug\")\n    axs[1, idx].axis('off')","92bbeb0c":"#create training and validation sets\ntrainset = ConcatDataset([\n    CustomTensorDataset(train_data, train_labels),\n    CustomTensorDataset(train_data, train_labels, transform=transform)\n])\nvalset = CustomTensorDataset(val_data, val_labels)","a37a9a45":"#create dataloaders to make use of batching and shuffling\ntrain_loader = DataLoader(trainset, batch_size=32, shuffle=True)\nval_loader = DataLoader(valset, batch_size=32, shuffle=False)","c6741b0e":"#define the device to use\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","d4e05cff":"class Block(nn.Module):\n    \n    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n        super(Block, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        \n    def forward(self, x):\n        identity = x\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n        x += identity\n        x = self.relu(x)\n        return x","e1a21a23":"class ResNet_18(nn.Module):\n    \n    def __init__(self, image_channels, num_classes):\n        \n        super(ResNet_18, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        #resnet layers\n        self.layer1 = self.__make_layer(64, 64, stride=1)\n        self.layer2 = self.__make_layer(64, 128, stride=2)\n        self.layer3 = self.__make_layer(128, 256, stride=2)\n        self.layer4 = self.__make_layer(256, 512, stride=2)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n        \n    def __make_layer(self, in_channels, out_channels, stride):\n        \n        identity_downsample = None\n        if stride != 1:\n            identity_downsample = self.identity_downsample(in_channels, out_channels)\n            \n        return nn.Sequential(\n            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n            Block(out_channels, out_channels)\n        )\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        x = self.avgpool(x)\n        x = x.view(x.shape[0], -1)\n        x = self.fc(x)\n        return x \n    \n    def identity_downsample(self, in_channels, out_channels):\n        \n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n            nn.BatchNorm2d(out_channels)\n        )","fd6ddba3":"model = ResNet_18(1, 10)","77620db8":"#count trainable parameters of the model\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ncount_parameters(model)","8c2c03d7":"#move the model to the device\nmodel.to(device)\nnext(model.parameters()).is_cuda","ae77db8d":"#define everything we need for training\nepochs = 5\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)","1c3cb904":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False):\n    \n    since = time.time()\n    val_acc_history = []\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]: # Iterate over data\n                \n                inputs = transforms.functional.resize(inputs, (112, 112))\n                inputs = inputs.to(device)\n\n                labels = labels.to(device)\n\n                optimizer.zero_grad() # Zero the parameter gradients\n\n                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n                    \n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n\n                    if phase == 'train': # Backward + optimize only if in training phase\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            \n            if phase == 'val': # Adjust learning rate based on val loss\n                lr_scheduler.step(epoch_loss)\n                \n            epoch_acc = running_corrects.double() \/ len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","882996d1":"model, _ = train_model(model, {\"train\": train_loader, \"val\": val_loader}, criterion, optimizer, epochs)","b1f3f1c3":"#prepare test set for the model\ntest = test.values \/ 255\ntest = torch.from_numpy(test).view(test.shape[0], 1, 28, 28)","908a6f54":"#prepare a dataloader with the test set\ntestset = CustomTensorDataset(test, None)\ntest_loader = DataLoader(testset, batch_size=32, shuffle=False)","d93474ed":"#turn on the evaluation mode and make predictions batch by batch (otherwise it lack gpu memory)\n#to use predictions for the submission we first need to transfer to the cpu\nmodel.eval()\nlabels = []\nfor inputs in test_loader:\n    inputs = transforms.functional.resize(inputs, (112, 112))\n    inputs = inputs.to(device)\n    outputs = model(inputs)\n    _, predictions = torch.max(outputs, 1)\n    predictions = predictions.to(\"cpu\")\n    labels.extend(predictions.numpy())","ee865c03":"submission['Label'] = labels\nsubmission.to_csv('submission.csv', index=False)","ca1fa83e":"#### Identity dosnsampling is the way for skip connections to match the size of the main flow when it has been changed. It uses a convolutional layer to handle both, reducing width and height of the feature maps as well as increasing the number of channels. This approach adds a little more complexity to the model compared to the parameter-free identity mapping, but leads to slightly better results, according to the original paper","47c8e3e6":"#### Define a basic ResNet18 building block. It differs a little from larger ResNet architectures, but the overall logic is the same. The block consist of two convolutional layers and supports skip connections.","ac113f18":"#### TensorDataset class does not support transformations by default. We need to create a custom dataset class to add augmentations and use the data in DataLoaders","f8a5128b":"# Submission","c5e76ff5":"    In this notebook we'll use Pytorch to implement ResNet18 from scratch.\n    We will also create a custom dataset class with augmentation\n    \n    Source article:\n    https:\/\/arxiv.org\/pdf\/1512.03385.pdf","039648a9":"# Training","aa40bfad":"#### Define ResNet18 architecture. It has some feature extraction at the beggining and four ResNet blocks with skip connections. At the end we use adaptive average pooling (for the model to be agnostic to the input image size) and a fully-connected layer","39a3d534":"#### Visualize one of the images in the dataset","d7a426c2":"# Data preparation","fc97251a":"#### As we work with tensors, we first need to transform our data to images, apply transformations and transform it back to tensors","8e5bccdf":"#### Visualise data with and without augmentation","322fb31f":"# Model","36c354ec":"#### Visualise label distribution"}}