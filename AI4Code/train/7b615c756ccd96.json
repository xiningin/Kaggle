{"cell_type":{"4cfe0c8c":"code","a3da5fdb":"code","eada2241":"code","6e1b28a0":"code","40b99b89":"code","759a0a96":"code","b3cdb6a2":"code","3f0b6a66":"code","5eade95b":"code","10def234":"code","73fe6d9c":"code","c8494639":"code","9b051021":"code","052f93ba":"code","a517eaa1":"code","d87663dc":"code","1b686f40":"code","dd844d66":"code","3096f1c6":"code","b83505ee":"markdown","10541e40":"markdown","4682d49b":"markdown","d75112ec":"markdown","d56328ff":"markdown","c07e1b2e":"markdown","dac4f6e3":"markdown","a811a17b":"markdown","5ce2cbdc":"markdown","a103e579":"markdown","2a12bbb0":"markdown","02f2b5c7":"markdown","18a9800b":"markdown","1fbc0cb7":"markdown","09d16774":"markdown","fb20c6ea":"markdown"},"source":{"4cfe0c8c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms","a3da5fdb":"print(torch.__version__)","eada2241":"class DatasetMNIST(Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((1, 28, 28))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","6e1b28a0":"train_dataset = DatasetMNIST('..\/input\/train.csv', transform=None)","40b99b89":"# we can access and get data with index by __getitem__(index)\nimg, lab = train_dataset.__getitem__(0)","759a0a96":"print(img.shape)\nprint(type(img))","b3cdb6a2":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)","3f0b6a66":"train_iter = iter(train_loader)\nprint(type(train_iter))","5eade95b":"images, labels = train_iter.next()\n\nprint('images shape on batch size = {}'.format(images.size()))\nprint('labels shape on batch size = {}'.format(labels.size()))","10def234":"# make grid takes tensor as arg\n# tensor : (batchsize, channels, height, width)\ngrid = torchvision.utils.make_grid(images)\n\nplt.imshow(grid.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(labels.numpy());","73fe6d9c":"class DatasetMNIST2(Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, we use ToTensor(), so we define the numpy array like (H, W, C)\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","c8494639":"train_dataset2 = DatasetMNIST2('..\/input\/train.csv', transform=torchvision.transforms.ToTensor())","9b051021":"img, lab = train_dataset2.__getitem__(0)\n\nprint('image shape at the first row : {}'.format(img.size()))","052f93ba":"train_loader2 = DataLoader(train_dataset2, batch_size=8, shuffle=True)\n\ntrain_iter2 = iter(train_loader2)\nprint(type(train_iter2))\n\nimages, labels = train_iter2.next()\n\nprint('images shape on batch size = {}'.format(images.size()))\nprint('labels shape on batch size = {}'.format(labels.size()))","a517eaa1":"grid = torchvision.utils.make_grid(images)\n\nplt.imshow(grid.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(labels.numpy());","d87663dc":"transform = transforms.Compose([\n    transforms.ToPILImage(), # because the input dtype is numpy.ndarray\n    transforms.RandomHorizontalFlip(0.5), # because this method is used for PIL Image dtype\n    transforms.ToTensor(), # because inpus dtype is PIL Image\n])","1b686f40":"train_dataset3 = DatasetMNIST2('..\/input\/train.csv', transform=transform)","dd844d66":"train_loader3 = DataLoader(train_dataset3, batch_size=8, shuffle=True)\n\ntrain_iter3 = iter(train_loader3)\nprint(type(train_iter3))\n\nimages, labels = train_iter3.next()\n\nprint('images shape on batch size = {}'.format(images.size()))\nprint('labels shape on batch size = {}'.format(labels.size()))","3096f1c6":"grid = torchvision.utils.make_grid(images)\n\nplt.imshow(grid.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(labels.numpy());","b83505ee":"### 3.5 transform is [ToTensor(), some augmentations]\n\ntransforms.* methods use some type of input data like (tensor only), (tensor or numpy), (PILimage only), so you have to consider the order of transform","10541e40":"### 3.4 transform is ToTensor()**","4682d49b":"### 3.3 take a look at the dataset\n\nyou have to use data loader in PyTorch that will accutually read the data within batch size and put into memory.","d75112ec":"we now didn't convert numpy array.","d56328ff":"I haven't  understood the concepts of both dataset and DataLoader yet ...","c07e1b2e":"we can look at images and labels of batch size by extracting data .next() method.","dac4f6e3":"# PyTorch Dataset and DataLoader\n\n* **1. Introduction**\n* **2. Version Check**\n* **3. Dataset and DataLoader tutorials**\n    * 3.1 Cumtom Dataset\n    * 3.2 transform is None\n    * 3.3 take a look at the dataset\n    * 3.4 transform is ToTensor()\n    * 3.5 transform is [ToTensor(), some augmentations]\n","a811a17b":"you can notice that the first image is horizontally flipped.","5ce2cbdc":"## 2. Version check\n\nThe behaviour of ToTensor() method in torchvision was changed from 0.3.0 to 0.4.0.\n\nIn 0.4.0 version, only **torch.ByteTensor** can be divided by 255 although other tensor types are not divided automatically.\n\nso you have to convert data type of input data to **np.uint8** of ndarray.\n\n**BE CAREFULL!!** (because pytorch official source code don't refer to this)\n\nofficial code : \n\n```python\nclass ToTensor(object):\n    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n    \"\"\"\n\n    def __call__(self, pic):\n        \"\"\"\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n        Returns:\n            Tensor: Converted image.\n        \"\"\"\n        return F.to_tensor(pic)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '()'\n```","a103e579":"**ToTensor()**\n\n```python\n    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n    (this is only for np.uint8 type)\n    \"\"\"\n```\n\nToTensor() takes **PIL image** or **numpy ndarray** (both shapes are (Height, Width, Channels))\n\n**ToPILImage**\n\n```python\n    \"\"\"Convert a tensor or an ndarray to PIL Image.\n    Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape\n    H x W x C to a PIL Image while preserving the value range.\n    Args:\n        mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).\n            If ``mode`` is ``None`` (default) there are some assumptions made about the input data:\n            1. If the input has 3 channels, the ``mode`` is assumed to be ``RGB``.\n            2. If the input has 4 channels, the ``mode`` is assumed to be ``RGBA``.\n            3. If the input has 1 channel, the ``mode`` is determined by the data type (i,e,\n            ``int``, ``float``, ``short``).\n    .. _PIL.Image mode: https:\/\/pillow.readthedocs.io\/en\/latest\/handbook\/concepts.html#concept-modes\n    \"\"\"\n```\n\nToPILImage() takes **torch.*Tensor ( C, H, W )** or **numpy ndarray ( H, W, C )**\n\n**RandomHorizontalFlip**\n\n```python\n    \"\"\"Horizontally flip the given PIL Image randomly with a given probability.\n    Args:\n        p (float): probability of the image being flipped. Default value is 0.5\n    \"\"\"\n```\n\nRandomHorizontalFlip() takes **PIL Image** only","2a12bbb0":"### 3.1 Custom Dataset\n\nyou have to overwrite **__len__()** and **__getitem__()** functions.\n\nofficial code : \n\n```python\nclass Dataset(object):\n    \"\"\"An abstract class representing a Dataset.\n    All other datasets should subclass it. All subclasses should override\n    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n    supporting integer indexing in range from 0 to len(self) exclusive.\n    \"\"\"\n\n    def __getitem__(self, index):\n        raise NotImplementedError\n\n    def __len__(self):\n        raise NotImplementedError\n\n    def __add__(self, other):\n        return ConcatDataset([self, other])\n```\n\n- **__init__()** : initial processes like reading a csv file, assigning transforms, ... \n- **__len__()** : return the size of input data\n- **__getitem__()** : return data and label at orbitary index","02f2b5c7":"## 3. Dataset and DataLoader Tutorial","18a9800b":"if you want to take data augmentation, you have to make List using **torchvision.transforms.Compose**\n\nthis function can convert some image by order within **\\__call__** method.\n\n```python\nclass Compose(object):\n    \"\"\"Composes several transforms together.\n    Args:\n        transforms (list of ``Transform`` objects): list of transforms to compose.\n    Example:\n        >>> transforms.Compose([\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.ToTensor(),\n        >>> ])\n    \"\"\"\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        for t in self.transforms:\n            img = t(img)\n        return img\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + '('\n        for t in self.transforms:\n            format_string += '\\n'\n            format_string += '    {0}'.format(t)\n        format_string += '\\n)'\n        return format_string\n    ```","1fbc0cb7":"we can use dataloader as iterator by using iter() function.","09d16774":"### 3.2 transform is None","fb20c6ea":"let's create dataset for loading handwritten-digits data"}}