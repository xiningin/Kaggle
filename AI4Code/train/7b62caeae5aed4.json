{"cell_type":{"17a479a8":"code","d8e296c8":"code","00ae0168":"code","c7e19044":"code","f5e78e9a":"code","bb6e4f1a":"code","d74de9c3":"code","a92a819a":"markdown"},"source":{"17a479a8":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image as img\nfrom os import listdir\n\nfrom keras import Model, backend as K\nfrom keras.layers import *\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import Progbar","d8e296c8":"epochs = 30\nbatch_size = 64\nalpha = 1 # Variable used to decay noise and rotation.\nstddev = .2\nrotation_range = 10\ndirectory = '..\/input\/data\/data\/'\nfiles = len(listdir(directory))\nreal_shape = (64, 64)","00ae0168":"class VariableGaussianNoise(Layer):\n    def __init__(self, stddev, seed=None, **kwargs):\n        self.stddev = K.variable(stddev)\n        self.seed = seed\n        super(VariableGaussianNoise, self).__init__(**kwargs)\n    \n    def call(self, x, training=None):\n        def noise():\n            return x+K.random_normal(K.shape(x), stddev=self.stddev, seed=self.seed)\n            \n        return K.in_train_phase(noise,\n                                x, training=training)\n    \n    def compute_output_shape(self, input_shape):\n        return input_shape\n        \n    def set_stddev(self, stddev):\n        K.set_value(self.stddev, max(0., stddev))","c7e19044":"def gen():\n    x = Input((512,))\n    y = Dense(4*4*512)(x)\n    y = LeakyReLU(.2)(y)\n    y = Reshape((4, 4, 512))(y)\n    \n    y = Conv2D(512, 3, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = UpSampling2D()(y)\n    \n    y = Conv2DTranspose(512, 3, strides=2, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(256, 3, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2DTranspose(256, 3, strides=2, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(128, 3, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2DTranspose(128, 3, strides=2, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(64, 3, padding='same')(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2D(3, 1, activation='tanh')(y)\n    \n    return Model(x, y)\n\ndef disc():\n    x = Input(real_shape+(3,))\n    y = VariableGaussianNoise(stddev, name='noise')(x)\n    \n    y = Conv2D(64, 3)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(128, 4, strides=2)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2D(128, 3)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(256, 4, strides=2)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2D(256, 3)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(512, 4, strides=2)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Conv2D(512, 3)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(512, 2)(y)\n    y = LeakyReLU(.2)(y)\n    y = BatchNormalization()(y)\n    \n    y = Flatten()(y)\n    y = Dense(1024)(y)\n    y = LeakyReLU(.2)(y)\n    y = Dense(1)(y)\n    \n    return Model(x, y)","f5e78e9a":"gen = gen()\ndisc = disc()\n\ngen.summary()\ndisc.summary()\n\nreal = Input(real_shape+(3,))\nz = Input((512,))\nfake = gen(z)\ndisc_r = disc(real)\ndisc_f = disc(fake)\n\n# Generator and discriminator losses according to RaGAN described in Jolicoeur-Martineau (2018).\n# Credits to Smith42 on GitHub for the implementation. (https:\/\/github.com\/Smith42\/keras-relativistic-gan)\ndef relGenLoss(y_true, y_pred):\n    epsilon=0.000001\n    return -(K.mean(K.log(K.sigmoid(disc_f - K.mean(disc_r, axis=0))+epsilon), axis=0)\\\n            +K.mean(K.log(1-K.sigmoid(disc_r - K.mean(disc_f, axis=0))+epsilon), axis=0))\n\ndef relDiscLoss(y_true, y_pred):\n    epsilon=0.000001\n    return -(K.mean(K.log(K.sigmoid(disc_r - K.mean(disc_f, axis=0))+epsilon), axis=0)\\\n            +K.mean(K.log(1-K.sigmoid(disc_f - K.mean(disc_r, axis=0))+epsilon), axis=0))\n\ngen.trainable = True\ndisc.trainable = False\ngen_train = Model([real, z], [disc_r, disc_f])\ngen_train.compile(SGD(2e-3, .5, nesterov=True), [relGenLoss, None])\ngen_train.summary()\n\ngen.trainable = False\ndisc.trainable = True\ndisc_train = Model([real, z], [disc_r, disc_f])\ndisc_train.compile(SGD(3e-3, .5, nesterov=True), [relDiscLoss, None])\ndisc_train.summary()","bb6e4f1a":"def dataGenerator():\n    file_list = listdir(directory)\n    image_data_generator = ImageDataGenerator(rotation_range = 10*alpha,\n                                              horizontal_flip = True,\n                                              preprocessing_function = lambda x: x\/127.5-1)\n    \n    for i in range(files\/\/batch_size):\n        images = []\n        \n        for j in range(batch_size):\n            images.append(np.array(img.open(directory+file_list[i*batch_size+j]).resize(real_shape)))\n            \n        yield next(image_data_generator.flow(np.array(images),\n                                             batch_size=batch_size,\n                                             shuffle=False))","d74de9c3":"dummy_y = np.zeros((batch_size,))\ngen_loss = []\ndisc_loss = []\n\nfor e in range(epochs):\n    target = files\/\/batch_size\n    progbar = Progbar(target)\n    data_generator = dataGenerator()\n    \n    print('Epoch ', e+1, '\/', epochs)\n    for i in range(target):\n        progbar.update(i+1)\n        \n        gen.trainable = False\n        disc.trainable = True\n        data = next(data_generator)\n        z = np.random.normal(scale=.25, size=(batch_size, 512))\n        disc_loss.append(disc_train.train_on_batch([data, z], dummy_y))\n        \n        gen.trainable = True\n        disc.trainable = False\n        gen_loss.append(gen_train.train_on_batch([data, z], dummy_y))\n    \n    alpha *= .9\n    disc.get_layer('noise').set_stddev(alpha*stddev)\n    \nplt.plot(gen_loss, 'r-')\nplt.plot(disc_loss, 'b-')\nplt.savefig('Losses.png')\n\nfig, axs = plt.subplots(5, 5, figsize=(10, 10))\nfor i in range(5):\n    for j in range(5):\n        axs[i][j].axis('off')\n        axs[i][j].imshow(gen.predict(np.random.normal(scale=.25, size=(1, 512)))[0]\/2+.5)\nplt.savefig('Samples.png')\n\nnp.save('Generator Weights.npy', gen.get_weights())\nnp.save('Discriminator Weights.npy', disc.get_weights())","a92a819a":"Dataset consists of 21551 anime faces scraped from www.getchu.com, then cropped using the anime face detection algorithm in https:\/\/github.com\/nagadomi\/lbpcascade_animeface.\n\nOriginal dataset by Mckinsey666, uploaded by Soumik Rakshit"}}