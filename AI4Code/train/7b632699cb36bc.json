{"cell_type":{"c8fa9127":"code","ee297d18":"code","1edc0ba7":"code","6dec1593":"code","420b680a":"code","dfefc45b":"code","7726fde5":"code","ee941bd0":"code","87aece43":"code","d0bb9a6f":"code","6128a52b":"code","ede1bd72":"code","f8019006":"markdown","e2febb3b":"markdown","51b5a289":"markdown","8def8e7d":"markdown","8deda9c4":"markdown","99dbee42":"markdown","4d657058":"markdown","0e4f18fa":"markdown","30b8eb50":"markdown","b6e5a1d6":"markdown","595acaed":"markdown"},"source":{"c8fa9127":"\ndata_dir=r'..\/input\/yikes-spiders-15-species'\ntrain_dir = data_dir + '\/train'\nvalid_dir = data_dir + '\/valid'\ntest_dir = data_dir + '\/test'","ee297d18":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport torchvision\nfrom torchvision import *\nfrom torch.utils.data import Dataset, DataLoader","1edc0ba7":"training_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\nvalidation_transforms = transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\n\ntesting_transforms = transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\n\n# Load the datasets with ImageFolder\ntraining_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\nvalidation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\ntesting_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)","6dec1593":"train_loader = torch.utils.data.DataLoader(training_dataset,batch_size=32,shuffle=True,num_workers=64)\nvalid_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=32,shuffle=True,num_workers=64)\ntest_loader = torch.utils.data.DataLoader(testing_dataset,batch_size=32,shuffle=True,num_workers=64)","420b680a":"import pathlib\nroot=pathlib.Path(train_dir)\nclasses=sorted([j.name.split('\/')[-1] for j in root.iterdir()])\nclasses","dfefc45b":"model = models.resnet18(pretrained=True)\nprint(model.fc)\n# out:\n# Linear(in_features=512, out_features=1000, bias=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 15)\nprint(model.fc)","7726fde5":"from torch.optim.lr_scheduler import StepLR\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\nexp_lr_scheduler = StepLR(optimizer,\nstep_size=2,\ngamma=0.1)\n","ee941bd0":"import torch.optim as optim\n\nn_epochs = 12\nprint_every = 10\nvalid_loss_min = np.Inf\nval_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\ntotal_step = len(train_loader)\nfor epoch in range(1, n_epochs+1):\n    running_loss = 0.0\n    correct = 0\n    total=0\n    print(f'Epoch {epoch}\\n')\n    for batch_idx, (data_, target_) in enumerate(train_loader):\n        data_, target_ = data_.to(device), target_.to(device)\n        optimizer.zero_grad()\n        \n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _,pred = torch.max(outputs, dim=1)\n        correct += torch.sum(pred==target_).item()\n        total += target_.size(0)\n        if (batch_idx) % 20 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n            \n    train_acc.append(100 * correct \/ total)\n    train_loss.append(running_loss\/total_step)\n    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct\/total):.4f}')\n    batch_loss = 0\n    total_t=0\n    correct_t=0\n    with torch.no_grad():\n        model.eval()\n        for data_t, target_t in (valid_loader):\n            data_t, target_t = data_t.to(device), target_t.to(device)\n            outputs_t = model(data_t)\n            loss_t = criterion(outputs_t, target_t)\n            batch_loss += loss_t.item()\n            _,pred_t = torch.max(outputs_t, dim=1)\n            correct_t += torch.sum(pred_t==target_t).item()\n            total_t += target_t.size(0)\n        val_acc.append(100 * correct_t\/total_t)\n        val_loss.append(batch_loss\/len(valid_loader))\n        network_learned = batch_loss < valid_loss_min\n        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t\/total_t):.4f}\\n')\n\n        \n        if network_learned:\n            valid_loss_min = batch_loss\n            torch.save(model.state_dict(), 'resnet.pt')\n            print('Improvement-Detected, save-model')\n    model.train()","87aece43":"from matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20,10))\nplt.title(\"Train-Validation Accuracy\")\nplt.plot(train_acc, label='train')\nplt.plot(val_acc, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('accuracy', fontsize=12)\nplt.legend(loc='best')","d0bb9a6f":"def test_accuracy(model, test_loader):\n\n    # Do validation on the test set\n    model.eval()\n    model.to('cuda')\n\n    with torch.no_grad():\n    \n        accuracy = 0\n    \n        for images, labels in iter(test_loader):\n    \n            images, labels = images.to('cuda'), labels.to('cuda')\n    \n            output = model.forward(images)\n\n            probabilities = torch.exp(output)\n        \n            equality = (labels.data == probabilities.max(dim=1)[1])\n        \n            accuracy += equality.type(torch.FloatTensor).mean()\n        \n        print(\"Test Accuracy: {}\".format(accuracy\/len(test_loader)))    \n        \n        \ntest_accuracy(model, test_loader)","6128a52b":"def imshow(inp, title=None):\n    plt.figure(figsize=(25,25))\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    \n    if title is not None:\n        plt.title(title)\ninputs, classes = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nclass_names = testing_dataset.classes\noutputs = model(inputs.to(device))\n_, preds = torch.max(outputs,1)\n\nimshow(out, title=[class_names[x] for x in preds])\n\n","ede1bd72":"torch.save(model.state_dict(), \".\/resnet18.pt\")","f8019006":"The **ImageFolder** dataset was utilized in the code above to pull images from our data folders and adjust the transformations to the ones I described earlier. Then, for batch iteration, I'll define our data loaders:","e2febb3b":"Next we need too define our transforms, load the data, and configure our batch samplers.First we\u2019ll define our transforms:","51b5a289":"* 1- Training loop.\n* 2- Validation loop","8def8e7d":"I love spiders so much thats why I'm here, anyway; I'll use ResNet18 model that has been pre\u2010trained with ImageNet data. ResNet18 is designed to detect 1,000 classes, and in our case, we need 15 classes.\nBut first, let\u2019s begin by loading our data, defining our transforms, and configuring our dataloaders for batch sampling.I\u2019ll leverage functions from the Torchvision library for creating the datasets, loading the data, and applying the data transforms.\n","8deda9c4":"We have the test set also. So we could use for the model's performance on completely new images","99dbee42":"We first load ResNet18 model with the torchvision.models.resnet18(). Then, we read the number offeatures before the final layer with model.fc.in_features. Then we change the final layer by directly setting model.fc to a fully connected layer with two outputs.We have a ResNet18 model with all weights pretrained with ImageNet images except for the last layer. ","4d657058":"I\u2019ll display a batch of images and show how our model classified them: here is the steps and explanation:\n* 1- Define a new function to plot images\n* 2- Switch from C \u00d7 H \u00d7 W to H \u00d7 W \u00d7 C image formats for plotting.\n* 3- Undo the normalization\n* 4- images from our test dataset.\n* 5- Perform classification using our fine-tuned ResNet18.\n* 6- Display the images + predicted classes.","0e4f18fa":"Notice that I randomly resize, crop, and flip images for training **but not for validation and testing**. The crazy numbers used in the Normalize transforms are precomputed values for the means and standard deviations.\n","30b8eb50":"**Testing\n\n","b6e5a1d6":"configure our training with the following code:\n\n* 1 Move the model to a GPU if available.\n\n* 2 Define loss function.\n\n* 3-Define  optimizer algorithm.\n\n* 4-Use a learning rate scheduler.\n\n","595acaed":"We\u2019re using a batch size of 8, and we set num_workers to 64 to configure four CPU processes to handle the parallel processing (thanks to the Kaggle. I never do that in my pc that has been made in wood). Now that we have prepared our training and validation data, we can design our model. But first I'd like to check how many classes that we have in our data. "}}