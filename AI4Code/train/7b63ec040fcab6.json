{"cell_type":{"e6d8de68":"code","434af915":"code","1030b5d3":"code","469fe07e":"code","f644db9e":"code","3726449b":"code","0b493cfc":"code","e0f44afd":"code","9dbcf66e":"code","b6382821":"code","ab150a6c":"code","db7c7940":"code","863b5032":"code","96771135":"code","3f37f453":"markdown","97276273":"markdown","707263e2":"markdown","9aabccac":"markdown","7d4dacad":"markdown","4002348b":"markdown","53b07368":"markdown","dfb517a6":"markdown"},"source":{"e6d8de68":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\n\n# set the random seed\nseed = 314\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\ntrain_path = '..\/input\/yoga-4class-no-jpegs\/content\/cleaned\/DATASET\/TRAIN\/'\ntest_path = '..\/input\/yoga-4class-no-jpegs\/content\/cleaned\/DATASET\/TEST\/'","434af915":"class_names = []\ntrain_distrib = []\ntest_distrib = []\n\n# for train\nfor dir in os.listdir(train_path):\n    class_names.append(dir) # append the folder name, the class\n    number = len(os.listdir(train_path+dir+'\/')) # count the files on the dir\n    train_distrib.append(number) # append that number\n    \n# for test\nfor dir in os.listdir(test_path):\n    #class_names.append(dir) # append the folder name, the class\n    number = len(os.listdir(test_path+dir+'\/')) # count the files on the dir\n    test_distrib.append(number) # append that number\n\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.pie(train_distrib, labels=class_names)\nplt.title(f'Train - {sum(train_distrib)} files')\nplt.subplot(1,2,2)\nplt.pie(test_distrib, labels=class_names)\nplt.title(f'Test - {sum(test_distrib)} files')\nplt.show()","1030b5d3":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# instance and adjust the options\ntrain_datagen = ImageDataGenerator(\n    rescale = 1\/255, # normalize the values\n    shear_range = 0.2, # it means to cut the image\n    zoom_range = 0.2, # make zoom\n    horizontal_flip = True # invert horizontally\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1\/ 255,\n    horizontal_flip = True,\n    validation_split=0.25, # this is going to be for val\n)","469fe07e":"image_size = 128\n\n# and load the images\ntrain_gen = train_datagen.flow_from_directory(\n    train_path, # the data folder\n    batch_size = 16,\n    class_mode = 'categorical', # for multi class\n    target_size = (image_size, image_size), # the image size\n    shuffle = True,\n    seed = 314\n)\n\n# test, and i will use some of these images for validation\ntest_gen = test_datagen.flow_from_directory(\n    test_path, # the data folder\n    batch_size = 16,\n    class_mode = 'categorical', # for multi class\n    target_size = (image_size, image_size), # the image size\n    shuffle = True,\n    seed = seed,\n    subset='training', # since test will be bigger than val\n)\n\n# now validation\nval_gen = test_datagen.flow_from_directory(\n    test_path, # the test folder\n    batch_size = 16,\n    class_mode = 'categorical', # for multi class\n    target_size = (image_size, image_size), # the image size\n    shuffle = True,\n    seed = seed,\n    subset='validation', # since test will be bigger than val\n)\n","f644db9e":"from tensorflow.keras import Sequential, layers\n\nnum_classes = len(class_names)\n\nmodel = Sequential([\n    # the imput shape must be defined\n    layers.InputLayer(input_shape=[image_size, image_size, 3]),\n\n    layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n\n    layers.Flatten(),\n    \n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3), # this layer turn off random neurons each step\n    # it helps to improve the model and helps to prevent overfitting\n    \n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),\n    \n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","3726449b":"from tensorflow.keras.callbacks import EarlyStopping\n\n# this will be some strict to prevent overfitting\nearly_stopping = EarlyStopping(\n    min_delta=0.005, # min loss improve\n    patience=5, # epochs for the stop\n    restore_best_weights=True\n)\n\nfrom PIL import ImageFile\n# ask PIL to be tolerant of files that are truncated (missing some file from the block) by changing a setting.\n# if that option isn't enabled training will trow an error\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nhistory = model.fit(\n    train_gen,\n    validation_data = val_gen,\n    epochs = 25,\n    callbacks = [early_stopping]\n)","0b493cfc":"plt.figure(figsize=(15, 10))\n\n# plot the loss function\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.title('Loss Function')\nplt.grid(True)\nplt.legend()\n\n# and the accuracy\nplt.subplot(1,2,2)\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='validation')\nplt.grid(True)\nplt.title('Accuracy')\nplt.legend()\n\nplt.show()","e0f44afd":"results = model.evaluate(test_gen, batch_size=1)\nprint(\"test loss, test acc:\", results)","9dbcf66e":"from sklearn.metrics import classification_report\n\n# make predictions with the model and the test generator\ny_pred = model.predict(test_gen)\n# take the maximum number, as there are 5 numbers for each pred\ny_pred = np.argmax(y_pred, axis=1)\n# print the report\nprint(classification_report(test_gen.classes, y_pred))","b6382821":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# define the matrix with the real classes and the predicted\nm = confusion_matrix(test_gen.classes, y_pred)\n# the labels for the plot\nlabels = class_names\nplt.figure(figsize=(20, 8))\n# create the plot\nheatmap = sns.heatmap(m, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', color='blue')\n# labels for the axes\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.title('Confusion Matrix')\nplt.show()","ab150a6c":"from tensorflow.keras.preprocessing.image import img_to_array, load_img\n\nimages = [] # path of the images\nanswers = [] # correct labels \n\n# 2 images per class\n\nfor clas in os.listdir(test_path):\n    count = 0\n    for image_path in os.listdir(test_path + clas + '\/'):\n        # append the image path\n        images.append(test_path + clas + '\/' + image_path)\n        # append the answer\n        answers.append(clas)\n        count += 1 # count how many images have been appent\n        if count == 2:\n            break # only the two first ones\n\n# load the image\nimage = load_img(images[0], target_size=(128, 128))\n# copnvert to array\ninput_arr = img_to_array(image)\n# convert as a batch for the model\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\n# and finally predict\nprediction = model.predict(input_arr)\n# squeeze because shape is (1,5)\nprint(np.squeeze(prediction))\nplt.imshow(image)","db7c7940":"# recive the prediction and returns the label\ndef list_to_label(ls):\n    lis = np.squeeze(ls) # remove extra dimension\n    lis = list(lis)\n    index = lis.index(1) # look for the 1\n    return class_names[index]\n\ndef read_image(path, size=128):\n    # load the image\n    image = load_img(path, target_size=(size, size))\n    # copnvert to array\n    input_arr = img_to_array(image)\n    # convert as a batch for the model\n    input_arr = np.array([input_arr])  # Convert single image to a batch.\n    # and finally predict\n    # prediction = model.predict(input_arr)\n    return image, input_arr\n    \n\n# plot the predictions\nplt.figure(figsize=(20,8))\n\nfor img_path, ans, i in zip(images, answers, np.arange(10)):\n    img, arr = read_image(img_path) # read the image\n    pred = model.predict(arr) # predict\n    plt.subplot(2,5,i+1) # set the plot position\n    plt.imshow(img) # plot the image\n    # set the title with the pred and the answer\n    plt.title(f'real: {ans}, pred: {list_to_label(pred)}')\n    plt.axis('off')\n\nplt.show()","863b5032":"model.save('yoga_4class_cnn.h5')","96771135":"# this is how the model can be loaded\nloaded_model = keras.models.load_model('.\/yoga_4class_cnn.h5')\n\n# make one test prediction\n\n# load an image\nimg, arr = read_image(images[0])\n# an image with more quality for the end\nhd_image, nothing = read_image(images[0], size=1024)\n# predict\npred = loaded_model.predict(arr)\n# show results\nplt.figure(figsize=(8,8))\nplt.imshow(hd_image)\nplt.title(f'Predicted: {list_to_label(pred)}, Real: {ans}')\nplt.axis('off')\nplt.show()","3f37f453":"# The Model, a CNN","97276273":"# See the data distribtion","707263e2":"# Conclusion\nThe results as we see in the **confusion matrix** are not the better, but the **model evaluation** shows an accuracy of 90%. Looking at the previous images I think that there are `yoga positions that really resemble to others`, and it appears that the model could not learn entirely that similarities. However It `looks like the model can identify certain positions with more accuracy for instance the downdog position`. I guess that with more images the model could learn and improve with a better performance for distinguish those similar positions.\n\n\nThank you for the dataset.","9aabccac":"# Yoga Position Classification of 4 Classes with Keras CNN","7d4dacad":"# Save the Model","4002348b":"# Evaluate and Confusion Matrix","53b07368":"# Some Predict Examples","dfb517a6":"# Use more data, Data Augmentacion\nIt means creating more data through some modifications to the images given in the dataset and then create more data.\n\nSince `there's no validation folder` I decide to use the `25% or 20% of the test dataset for validation set,` as the training set is more important than test set and there's no much data."}}