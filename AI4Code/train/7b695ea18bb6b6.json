{"cell_type":{"45631d85":"code","c74151d6":"code","fadb2958":"code","3ae6fe58":"code","adb5145e":"code","f6a0f0cc":"code","736ec11d":"code","950743b6":"code","163d7cb9":"code","399390ca":"code","dbacc952":"code","19f24fa1":"code","6a6a1aef":"code","4d1c8c2a":"code","de60a429":"code","621f5607":"code","1bbf0160":"code","cbb3dbbb":"code","679216ab":"code","2758dff2":"code","bc76ee70":"code","5f46509c":"code","9f0f7284":"code","0a95ec10":"code","000822f8":"code","a9f4ff37":"code","49c6423e":"code","87f1229b":"code","9cdea243":"code","7f3a3988":"code","acfa077e":"code","156399b6":"code","e155104b":"code","05704fb3":"code","8e0d3b42":"code","7ca76c24":"code","5374d5a9":"code","17e1b37e":"code","b6453dca":"code","6455c24b":"code","8f08ec56":"code","8e13ca23":"code","6d50db18":"code","848163de":"code","c8d4f891":"code","d23a9ade":"code","79a1f686":"markdown","de7b0f05":"markdown","efd08b04":"markdown","e7ab16dd":"markdown","d3d130ae":"markdown","afa08608":"markdown","84808769":"markdown","3205f39d":"markdown","2d3f0eeb":"markdown","3bb04b78":"markdown","58307631":"markdown","c16522b2":"markdown","abd60dba":"markdown","9a78695d":"markdown","37c6e83b":"markdown","36bc0834":"markdown","af496e17":"markdown","2d8444a7":"markdown","1412bc19":"markdown","ddd67655":"markdown","8ec38045":"markdown","66a9322f":"markdown","d6217062":"markdown","accdf31a":"markdown","7fb35b3d":"markdown","fe2caa36":"markdown","b13f9740":"markdown","982c3187":"markdown","e913cced":"markdown","31d4309b":"markdown","16eeadfb":"markdown","4fb65604":"markdown","20759e19":"markdown","0086d7ca":"markdown","a74c015f":"markdown"},"source":{"45631d85":"# Uncomment and run the commands below if imports fail\n# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n# !pip install matplotlib --upgrade --quiet\n!pip install jovian --upgrade --quiet","c74151d6":"import torch\nimport jovian\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","fadb2958":"project_name='02-insurance-linear-regression' # will be used by jovian.commit","3ae6fe58":"DATASET_URL = \"https:\/\/hub.jovian.ml\/wp-content\/uploads\/2020\/05\/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","adb5145e":"dataframe_raw = pd.read_csv(DATA_FILENAME)\ndataframe_raw.head()","f6a0f0cc":"your_name = 'Debshila' # at least 5 characters","736ec11d":"torch.manual_seed(1)\ndef customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])\/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])\/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","950743b6":"dataframe = customize_dataset(dataframe_raw, your_name)\n# dataframe.info()\ndataframe.head()","163d7cb9":"num_rows = dataframe.shape[0]\nprint(num_rows)","399390ca":"num_cols = dataframe.shape[1]\nprint(num_cols)","dbacc952":"input_cols = list(dataframe.columns)[0:-1]\nprint(input_cols)","19f24fa1":"categorical_cols = list(dataframe.select_dtypes(include='object').columns)\ncategorical_cols","6a6a1aef":"output_cols = ['charges']","4d1c8c2a":"# Write your answer here\nprint('Charges descriptives:\\n', dataframe.charges.describe())\nimport seaborn as sns\nsns.boxplot(data = dataframe, x = \"charges\")\n","de60a429":"jovian.commit(project=project_name, environment=None)","621f5607":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    inputs_array = dataframe1[input_cols].to_numpy()\n    targets_array = dataframe1[output_cols].to_numpy()\n    return inputs_array, targets_array","1bbf0160":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\ninputs_array, targets_array","cbb3dbbb":"inputs = torch.from_numpy(inputs_array).type(torch.float32)\ntargets = torch.from_numpy(targets_array).type(torch.float32)","679216ab":"inputs.dtype, targets.dtype","2758dff2":"# TensorDataset allows access to rows from inputs and targets as tuples, \n# and provides standard APIs for working with many different types of datasets in PyTorch.\ndataset = TensorDataset(inputs, targets)\ndataset[0:2]","bc76ee70":"val_percent = .2 # between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(dataset,[train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length\nprint('length of training ds: ', len(train_ds),'\\n length of validation ds: ', len(val_ds))","5f46509c":"batch_size = 64","9f0f7284":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","0a95ec10":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","000822f8":"jovian.commit(project=project_name, environment=None)","a9f4ff37":"input_size = len(input_cols)\noutput_size = len(output_cols)\n\nprint(input_size, output_size)","49c6423e":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size,output_size)                  # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb.float())                          # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out, targets)                          # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out, targets)                           # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","87f1229b":"model = InsuranceModel()","9cdea243":"list(model.parameters())","7f3a3988":"jovian.commit(project=project_name, environment=None)","acfa077e":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","156399b6":"result = evaluate(model, val_loader) # Use the the evaluate function\nprint(result)","e155104b":"epochs = 500\nlr = 1e-2\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","05704fb3":"epochs = 500\nlr = 1e-3\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","8e0d3b42":"epochs = 500\nlr = 1e-4\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","7ca76c24":"epochs = 500\nlr = 1e-5\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","5374d5a9":"epochs = 500\nlr = 1e-6\nhistory5 = fit(epochs, lr, model, train_loader, val_loader)","17e1b37e":"all_loss = [result] + history1 + history2 + history3 + history4 + history5\n\nall_loss\n# Function to plot loss\ndef plot_loss(loss_list_dict = history5):\n    loss_val = [val['val_loss'] for val in loss_list_dict]\n    print(pd.Series(loss_val).describe())\n#     print('Minimum loss value: 'min(loss_val))\n    sns.lineplot(x = range(len(loss_val)),y = loss_val)\n    return loss_val[-1]\n    \nplot_loss(all_loss)\n\n\n","b6453dca":"val_loss = plot_loss(all_loss)\nprint(val_loss)","6455c24b":"jovian.log_metrics(val_loss=val_loss)","8f08ec56":"jovian.commit(project=project_name, environment=None)","8e13ca23":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)                # fill this\n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","6d50db18":"input, target = val_ds[0]\npredict_single(input, target, model)","848163de":"input, target = val_ds[10]\npredict_single(input, target, model)","c8d4f891":"input, target = val_ds[23]\npredict_single(input, target, model)","d23a9ade":"jovian.commit(project=project_name, environment=None)\njovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes","79a1f686":"**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **","de7b0f05":"## Step 4: Train the model to fit the data\n\nTo train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","efd08b04":"Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results.","e7ab16dd":"Read through the [Pandas documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/categorical.html) to understand how we're converting categorical variables into numbers.","d3d130ae":"**Q: What are the column titles of the input variables?**","afa08608":"## Step 2: Prepare the dataset for training\n\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays.","84808769":"Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`.","3205f39d":"**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n\nHint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works.","2d3f0eeb":"Let's look at a batch of data to verify everything is working fine so far.","3bb04b78":"## Step 1: Download and explore the data\n\nLet us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. ","58307631":"# Insurance cost prediction using linear regression\n\nIn this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https:\/\/www.kaggle.com\/mirichoi0218\/insurance\n\n\nWe will create a model with the following steps:\n1. Download and explore the dataset\n2. Prepare the dataset for training\n3. Create a linear regression model\n4. Train the model to fit the data\n5. Make predictions using the trained model\n\n\nThis assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n- PyTorch basics: https:\/\/jovian.ml\/aakashns\/01-pytorch-basics\n- Linear Regression: https:\/\/jovian.ml\/aakashns\/02-linear-regression\n- Logistic Regression: https:\/\/jovian.ml\/aakashns\/03-logistic-regression\n- Linear regression (minimal): https:\/\/jovian.ml\/aakashns\/housing-linear-minimal\n- Logistic regression (minimal): https:\/\/jovian.ml\/aakashns\/mnist-logistic-minimal\n\nAs you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n","c16522b2":"Let's save our work by committing to Jovian.","abd60dba":"Let us answer some basic questions about the dataset. \n\n\n**Q: How many rows does the dataset have?**","9a78695d":"## Step 5: Make predictions using the trained model\n\n**Q: Complete the following function definition to make predictions on a single input**","37c6e83b":"## Step 3: Create a Linear Regression Model\n\nOur model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n","36bc0834":"**Q: What are the column titles of output\/target variable(s)?**","af496e17":"**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**","2d8444a7":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`.","1412bc19":"Let's check out the weights and biases of the model using `model.parameters`.","ddd67655":"Let's log the final validation loss to Jovian and commit the notebook","8ec38045":"We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)","66a9322f":"One final commit before we train the model.","d6217062":"\nWe are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible.","accdf31a":"**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\nUse this data visualization cheatsheet for referece: https:\/\/jovian.ml\/aakashns\/dataviz-cheatsheet","7fb35b3d":"**Q: How many columns doe the dataset have**","fe2caa36":"Remember to commit your notebook to Jovian after every step, so that you don't lose your work.","b13f9740":"To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https:\/\/data36.com\/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection\/","982c3187":"Are you happy with your model's predictions? Try to improve them further.","e913cced":"**Q: Which of the input columns are non-numeric or categorial variables ?**\n\nHint: `sex` is one of them. List the columns that are not numbers.","31d4309b":"**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n\nHint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https:\/\/pytorch.org\/docs\/stable\/nn.functional.html#loss-functions","16eeadfb":"The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers.","4fb65604":"Finally, we can create data loaders for training & validation.\n\n**Q: Pick a batch size for the data loader.**","20759e19":"## (Optional) Step 6: Try another dataset & blog about it\n\nWhile this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https:\/\/jovian.ml\/aakashns\/housing-linear-minimal), or [this one](https:\/\/jovian.ml\/aakashns\/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n\nHere are some sources to find good datasets:\n\n- https:\/\/lionbridge.ai\/datasets\/10-open-datasets-for-linear-regression\/\n- https:\/\/www.kaggle.com\/rtatman\/datasets-for-regression-analysis\n- https:\/\/archive.ics.uci.edu\/ml\/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n- https:\/\/people.sc.fsu.edu\/~jburkardt\/datasets\/regression\/regression.html\n- https:\/\/archive.ics.uci.edu\/ml\/datasets\/wine+quality\n- https:\/\/pytorch.org\/docs\/stable\/torchvision\/datasets.html\n\nWe also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n\n- Interesting title & subtitle\n- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n- Downloading & exploring the data\n- Preparing the data for training\n- Creating a model using PyTorch\n- Training the model to fit the data\n- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n- Making predictions using the model\n\nAs with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https:\/\/medium.com\/jovianml\/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n\nDon't forget to share your work on the forum: https:\/\/jovian.ml\/forum\/t\/share-your-work-here-assignment-2\/4931","0086d7ca":"**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**","a74c015f":"**Q: What is the final validation loss of your model?**"}}