{"cell_type":{"72b58b7e":"code","8df2281d":"code","94172370":"code","1cfd495f":"code","862d2bcb":"code","bec2dde7":"code","8f3db629":"code","f498d155":"code","d0fb602a":"code","a5617363":"code","fa2f8c53":"code","d27e84c7":"code","e06f3f41":"code","4e9f2327":"code","10bcfdfa":"code","bcaf0827":"code","3d2232c0":"code","735a218c":"code","8ee5557e":"code","6aff8050":"code","f52b55a9":"code","238ebebf":"code","758d7fcb":"code","6863ddd0":"code","4add22d7":"code","b9acca5d":"code","445dab3f":"code","fe8a0bce":"code","ad5b8d6f":"code","a7e7c317":"code","8ad58043":"code","2b2f944b":"code","d5ef65bb":"code","c35c0942":"code","a25d8657":"code","64d67c19":"markdown","e1ad71f9":"markdown"},"source":{"72b58b7e":"#import all the libraries\nimport os\nimport string\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport torchvision\nfrom torchvision.datasets import CIFAR10\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor, Normalize","8df2281d":"#Train dataset configuration\nclass ASLDataset(Dataset):\n    char_to_int = {c: ord(c) - ord('A') for c in string.ascii_uppercase}\n    char_to_int['del'] = 26\n    char_to_int['nothing'] = 27\n    char_to_int['space'] = 28\n    int_to_char = {value: key for key, value in char_to_int.items()}\n        \n    def __init__(self, directory: str, train: bool = True, transform=None, label_transform=None):\n        super().__init__()\n        \n        self.directory = os.path.join(directory, 'train' if train else 'test')\n        self.transform = transform\n        self.label_transform = label_transform\n        \n        self.x = None\n        self.y = None\n        \n        self._load_images()\n    \n    def __getitem__(self, idx):\n        x, y = torchvision.io.read_image(self.x[idx]).type(torch.float32), self.y[idx]\n        \n        if self.transform:\n            x = self.transform(x)\n        if self.label_transform:\n            y = self.label_transform(y)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def _load_images(self):\n        self.x = []\n        self.y = []\n        \n        for c in os.listdir(self.directory):\n            class_name = c\n            class_dir = os.path.join(self.directory, class_name)\n            for img in os.listdir(class_dir):\n                self.x.append(os.path.join(class_dir, img))\n                self.y.append(self.char_to_int[class_name])\n                \n        self.y = torch.tensor(self.y, dtype=torch.int64)\n    \n    @staticmethod\n    def get_classname(idx: int) -> str:\n        return ASLDataset.int_to_char[idx]","94172370":"ts = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","1cfd495f":"#Path of the data store in train and test\nasl_train = ASLDataset('..\/input\/aslalphabet\/dataset', transform=ts)\nasl_test = ASLDataset('..\/input\/aslalphabet\/dataset', transform=ts, train=False)","862d2bcb":"print(len(asl_train))\nprint(len(asl_test))","bec2dde7":"#sampler\ntrain_sampler = SubsetRandomSampler(np.arange(len(asl_train)))\ntest_sampler = SubsetRandomSampler(np.arange(len(asl_test)))","8f3db629":"#loader using sampler\ntrain_loader = DataLoader(asl_train, 32, sampler=train_sampler)\ntest_loader = DataLoader(asl_test, 32, sampler=test_sampler)","f498d155":"for x, y in train_loader:\n    print(x.shape)\n    print(y.shape)","d0fb602a":"#train path\nasl_train.x","a5617363":"#test path\nasl_test.x","fa2f8c53":"#Test dataset configuration\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes: int = 1000) -> None:\n        super(AlexNet, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","d27e84c7":"model = AlexNet(29)","e06f3f41":"#using adam optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","4e9f2327":"#print minibatch of train data\nprint(len(train_loader.dataset))\nprint(len(train_loader))","10bcfdfa":"epochs = 10\n\nfor e in range(epochs):\n    running_loss = 0.0\n    \n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 7 == 6:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 7))\n            running_loss = 0.0","bcaf0827":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss \/= num_batches\n    correct \/= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","3d2232c0":"test(test_loader, model, nn.CrossEntropyLoss())","735a218c":"#Accuracy of each class\nclass_correct = list(0. for i in range(29))\nclass_total = list(0. for i in range(29))\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(len(labels)):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(29):\n    print('Accuracy of %5s : %2d %%' % (\n        ASLDataset.int_to_char[i], 100 * class_correct[i] \/ class_total[i]))","8ee5557e":"from torchvision import models","6aff8050":"model = models.alexnet(pretrained=True)","f52b55a9":"for param in model.parameters():\n    param.requires_grad = False","238ebebf":"print(model)","758d7fcb":"new_clf = nn.Sequential(\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=9216, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=4096, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=4096, out_features=1000, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=1000, out_features=29, bias=True),\n)","6863ddd0":"model.classifier = new_clf","4add22d7":"print(model)","b9acca5d":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","445dab3f":"epochs = 10\n\nfor e in range(epochs):\n    running_loss = 0.0\n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 7 == 6:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 7))\n            running_loss = 0.0","fe8a0bce":"test(test_loader, model, nn.CrossEntropyLoss())","ad5b8d6f":"model = models.resnet152(pretrained=True)","a7e7c317":"print(model)","8ad58043":"new_fc = torch.nn.Sequential(\n    nn.Linear(in_features=2048, out_features=1000, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=1000, out_features=29, bias=True),\n)","2b2f944b":"model.fc = new_fc","d5ef65bb":"print(model)","c35c0942":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","a25d8657":"epochs = 5\n\nfor e in range(epochs):\n    running_loss = 0.0\n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 7 == 6:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 7))\n            running_loss = 0.0","64d67c19":"# > **Pre-trained AlexNet**","e1ad71f9":"# > **AlexNet**"}}