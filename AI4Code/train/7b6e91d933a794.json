{"cell_type":{"08cf6e4b":"code","9ab46084":"code","0b1908c7":"code","edac8d53":"code","a510d028":"code","49a124cb":"code","2cf5881a":"code","c32d2cff":"code","59751574":"code","808d1da2":"code","a6d0b21a":"code","6cf2322c":"code","53029778":"code","3d9817e8":"markdown","54e3a14b":"markdown","a2b2ed41":"markdown","3ba9f755":"markdown","85dfd715":"markdown","abe9d330":"markdown","631221ba":"markdown","d4f739ff":"markdown"},"source":{"08cf6e4b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\nimport torchvision.datasets as datasets # Has standard datasets we can import in a nice way\nimport torchvision.transforms as transforms # Transformations we can perform on our dataset\nimport torch.nn.functional as F # All functions that don't have any parameters\nfrom torch.utils.data import DataLoader, Dataset # Gives easier dataset managment and creates mini batches\nfrom torchvision.datasets import ImageFolder\nimport torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\nfrom PIL import Image","9ab46084":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu","0b1908c7":"from sklearn.model_selection import train_test_split\ndataset = ImageFolder(\"..\/input\/cat-and-dog\/training_set\/training_set\/\")\ntrain_data, test_data, train_label, test_label = train_test_split(dataset.imgs, dataset.targets, test_size=0.2, random_state=42)\n\n# ImageLoader Class\n\nclass ImageLoader(Dataset):\n    def __init__(self, dataset, transform=None):\n        self.dataset = self.checkChannel(dataset) # some images are CMYK, Grayscale, check only RGB \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, item):\n        image = Image.open(self.dataset[item][0])\n        classCategory = self.dataset[item][1]\n        if self.transform:\n            image = self.transform(image)\n        return image, classCategory\n        \n    \n    def checkChannel(self, dataset):\n        datasetRGB = []\n        for index in range(len(dataset)):\n            if (Image.open(dataset[index][0]).getbands() == (\"R\", \"G\", \"B\")): # Check Channels\n                datasetRGB.append(dataset[index])\n        return datasetRGB","edac8d53":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.5]*3, [0.5]*3)\n]) # train transform\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.5]*3, [0.5]*3)\n]) # test transform\n\ntrain_dataset = ImageLoader(train_data, train_transform)\ntest_dataset = ImageLoader(test_data, test_transform)","a510d028":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)","49a124cb":"from tqdm import tqdm\nfrom torchvision import models\n# load pretrain model and modify...\nmodel = models.resnet50(pretrained=True)\n\n# If you want to do finetuning then set requires_grad = False\n# Remove these two lines if you want to train entire model,\n# and only want to load the pretrain weights.\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)\n\nmodel.to(device)","2cf5881a":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n\n# Train and test\n\ndef train(num_epoch, model):\n    for epoch in range(0, num_epoch):\n#         current_loss = 0.0\n#         current_corrects = 0\n        losses = []\n        model.train()\n        loop = tqdm(enumerate(train_loader), total=len(train_loader)) # create a progress bar\n        for batch_idx, (data, targets) in loop:\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n            scores = model(data)\n            \n            loss = criterion(scores, targets)\n            optimizer.zero_grad()\n            losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            _, preds = torch.max(scores, 1)\n#             current_loss += loss.item() * data.size(0)\n#             current_corrects += (preds == targets).sum().item()\n#             accuracy = int(current_corrects \/ len(train_loader.dataset) * 100)\n            loop.set_description(f\"Epoch {epoch+1}\/{num_epoch} process: {int((batch_idx \/ len(train_loader)) * 100)}\")\n            loop.set_postfix(loss=loss.data.item())\n        \n        # save model\n        torch.save({ \n                    'model_state_dict': model.state_dict(), \n                    'optimizer_state_dict': optimizer.state_dict(), \n                    }, 'checpoint_epoch_'+str(epoch)+'.pt')\n\n\n        \n# model.eval() is a kind of switch for some specific layers\/parts of the model that behave differently,\n# during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. \n# You need to turn off them during model evaluation, and .eval() will do it for you. In addition, \n# the common practice for evaluating\/validation is using torch.no_grad() in pair with model.eval() \n# to turn off gradients computation:\n        \ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for x, y in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n            output = model(x)\n            _, predictions = torch.max(output, 1)\n            correct += (predictions == y).sum().item()\n            test_loss = criterion(output, y)\n            \n    test_loss \/= len(test_loader.dataset)\n    print(\"Average Loss: \", test_loss, \"  Accuracy: \", correct, \" \/ \",\n    len(test_loader.dataset), \"  \", int(correct \/ len(test_loader.dataset) * 100), \"%\")","c32d2cff":"if __name__ == \"__main__\":\n    train(5, model) # train\n    test() # test","59751574":"print(\"----> Loading checkpoint\")\ncheckpoint = torch.load(\".\/checpoint_epoch_4.pt\") # Try to load last checkpoint\nmodel.load_state_dict(checkpoint[\"model_state_dict\"]) \noptimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])","808d1da2":"# Check the test set\ndataset = ImageFolder(\"..\/input\/cat-and-dog\/test_set\/test_set\/\", \n                     transform=transforms.Compose([\n                         transforms.Resize((224, 224)), \n                         transforms.ToTensor(), \n                         transforms.Normalize([0.5]*3, [0.5]*3)\n                     ]))\nprint(dataset)\ndataloader = DataLoader(dataset, batch_size=1, shuffle = False)","a6d0b21a":"# for j, (data, labels) in enumerate(dataloader):\nwith torch.no_grad():\n    model.eval()\n    for data, target in dataloader:\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        _, predicted = torch.max(output, 1)\n        print(f\"predicted ----> {predicted[0]}\")","6cf2322c":"def RandomImagePrediction(filepath):\n    img_array = Image.open(filepath).convert(\"RGB\")\n    data_transforms=transforms.Compose([\n        transforms.Resize((224, 224)), \n        transforms.ToTensor(), \n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ])\n    img = data_transforms(img_array).unsqueeze(dim=0) # Returns a new tensor with a dimension of size one inserted at the specified position.\n    load = DataLoader(img)\n    \n    for x in load:\n        x=x.to(device)\n        pred = model(x)\n        _, preds = torch.max(pred, 1)\n        print(f\"class : {preds}\")\n        if preds[0] == 1: print(f\"predicted ----> Dog\")\n        else: print(f\"predicted ----> Cat\")","53029778":"if __name__ == \"__main__\":\n    RandomImagePrediction(\"..\/input\/prediction-pytorch\/dog\/d41586-020-01430-5_17977552.jpg\") # dog image\n    RandomImagePrediction(\"..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4011.jpg\") # cat image\n    RandomImagePrediction(\"..\/input\/prediction-pytorch\/dog\/322868_1100-1100x628.jpg\") # dog image","3d9817e8":"## Import all dependencies","54e3a14b":"## Resnet50 Transfer learning technique\n\n![Structure-of-the-ResNet-50-used-for-reservoir-recognition.jpg](attachment:Structure-of-the-ResNet-50-used-for-reservoir-recognition.jpg)","a2b2ed41":"# create a function to predict random cats and dog images","3ba9f755":"# Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n\n## The DataLoader supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning.","85dfd715":"![image-classification-using-transfer-learning-in-pytorch.png](attachment:image-classification-using-transfer-learning-in-pytorch.png)\n\n## PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab.\n\n![pytoch-cnn.jpg](attachment:pytoch-cnn.jpg)","abe9d330":"## Set device","631221ba":"## train test split","d4f739ff":"> CrossEntropy or other loss functions is divided by the number of elements i.e. the reduction parameter is mean by default.\n\n*     torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n\n> Hence, loss.item() contains the loss of entire mini-batch, but divided by the batch size. That's why loss.item() is multiplied with batch size, given by inputs.size(0), while calculating running_loss\n> (stackoverflow)"}}