{"cell_type":{"355d728e":"code","48081f06":"code","198a0aea":"code","b14a744d":"code","42d006dc":"code","c6ef39a8":"code","cffdd84f":"code","019a1691":"code","0fea21d4":"code","00d8b965":"code","0d279261":"code","6d64e74f":"code","579faf8c":"code","7fea7aa8":"code","2b7afdac":"code","ad45eca6":"markdown","ce3208f9":"markdown"},"source":{"355d728e":"import torch\nimport torchvision\nfrom torch import nn\nfrom torchvision.transforms import transforms\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom torch.autograd import Variable","48081f06":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","198a0aea":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","b14a744d":"x = train_df.iloc[:,1:].values\ny = train_df.iloc[:,0].values\nz = test_df.iloc[::].values\nprint(\"X shape : {}\".format(x.shape))\nprint(\"Y shape : {}\".format(y.shape))\nprint(\"Z shape : {}\".format(z.shape))","42d006dc":"plt.subplots(5, 5, figsize=(15,15))\nfor i in range(5*5):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(x[i].reshape(28,28), 'gray')\n    plt.xlabel(\"Target : \" + str(y[i]))\nplt.show()","c6ef39a8":"class Dataset(Dataset):\n\n    def __init__(self, data):\n        self.data = data\n        self.n_samples = data.shape[0]\n        self.x_data = torch.tensor(data.iloc[::].values, dtype=torch.long)  # size [n_samples, n_features]\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):\n        return self.x_data[index].reshape(28,28)\n\n    # we can call len(dataset) to return the size\n    def __len__(self):\n        return self.n_samples\n    def get_long_type(self, target):\n        target = target.type(torch.LongTensor)\n        return target","cffdd84f":"\n# Hyper-parameters\ninput_size = 784\nhidden_size = 100\nnum_classes = 10\nnum_epochs = 2\nbatch_size = 100\nlearning_rate = 0.001\ntrain_dataset = torchvision.datasets.MNIST(root='.\/data', train=True, transform=transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]), download=True)\n# test_dataset = torchvision.datasets.MNIST(root='.\/data', train=False, transform=transforms.Compose(\n#     [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\ntest_dataset = Dataset(test_df)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","019a1691":"# for images in test_loader:\n#             images = images.to(device)\n#             train = Variable(images.view(100,1,28,28)).to(device)\n#             print(images,train)\n#             break","0fea21d4":"examples = iter(train_loader)\nsamples, labels = examples.__next__()\n\nprint(samples.shape, labels.shape)","00d8b965":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n    \n    def forward(self, x):\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        out = self.maxpool1(out)\n        out = self.cnn2(out)\n        out = self.relu2(out)\n        out = self.maxpool2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        \n        return out\n\n# batch_size, epoch and iteration\nn_total_steps = len(train_loader)\nbatch_size = 100\nnum_epochs = 10\nmodel = CNNModel()\nif torch.cuda.is_available():\n    model.cuda()\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 0.1\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","0d279261":"for epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        train = Variable(images.view(100,1,28,28)).to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(train)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (i + 1) % 100 == 0:\n            print(f'Epoch [{epoch + 1}\/{num_epochs}], Step [{i + 1}\/{n_total_steps}], Loss: {loss.item():.4f}')","6d64e74f":"def evalueate_model(model, test_loader):\n    predictions = []\n    model.eval()\n    for images in test_loader:\n        images = images.to(device)\n        train = Variable(images.view(100,1,28,28).type(torch.float32)).to(device)\n        with torch.no_grad():\n            predicts = model(train)\n            predicts = predicts.argmax(axis=1)\n            predicts = predicts.cpu().numpy()\n            \n            # Put the batch size data into the list one by one.\n            for pred in predicts:\n                predictions.append(pred)\n    return(predictions)","579faf8c":"pred = evalueate_model(model, test_loader)","7fea7aa8":"submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label'] = pred\nsubmission.head(25)","2b7afdac":"submission.to_csv('submission.csv', index=False)","ad45eca6":"# Visualize data","ce3208f9":"# Checkout data"}}