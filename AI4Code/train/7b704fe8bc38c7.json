{"cell_type":{"ac8115ca":"code","1b8c4c2c":"code","607f78ea":"code","71acca87":"code","7ef16781":"code","a8330fe7":"code","c72f806e":"code","a2a44c0f":"code","e2ca52b8":"code","df09e189":"code","9260767a":"code","cf3d5120":"code","5577381f":"markdown","5dcc162f":"markdown","b89e9f42":"markdown","f20bcb26":"markdown","91c2afa6":"markdown","31b400e6":"markdown","e16cda2d":"markdown","dc4560f9":"markdown","07aa76a0":"markdown","e301f961":"markdown","e3e5fa68":"markdown"},"source":{"ac8115ca":"!git clone https:\/\/github.com\/ultralytics\/yolov5\n!mv yolov5\/* .\/","1b8c4c2c":"!python -m pip install --upgrade pip\n!pip install -r requirements.txt","607f78ea":"import numpy as np \nimport pandas as pd \nimport os\nfrom tqdm.auto import tqdm\nimport shutil as sh\n","71acca87":"df = pd.read_csv('..\/input\/global-wheat-detection\/train.csv')\nbboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    df[column] = bboxs[:,i]\ndf.drop(columns=['bbox'], inplace=True)\ndf['x_center'] = df['x'] + df['w']\/2\ndf['y_center'] = df['y'] + df['h']\/2\ndf['classes'] = 0\n\ndf = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\ndf.head()","7ef16781":"index = list(set(df.image_id))\nsource = 'train'\nif True:\n    for fold in [0]:\n        val_index = index[len(index)*fold\/\/5:len(index)*(fold+1)\/\/5]\n        for name,mini in tqdm(df.groupby('image_id')):\n            if name in val_index:\n                path2save = 'val2017\/'\n            else:\n                path2save = 'train2017\/'\n            if not os.path.exists('convertor\/fold{}\/labels\/'.format(fold)+path2save):\n                os.makedirs('convertor\/fold{}\/labels\/'.format(fold)+path2save)\n            with open('convertor\/fold{}\/labels\/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n                row = row\/1024\n                row = row.astype(str)\n                for j in range(len(row)):\n                    text = ' '.join(row[j])\n                    f.write(text)\n                    f.write(\"\\n\")\n            if not os.path.exists('convertor\/fold{}\/images\/{}'.format(fold,path2save)):\n                os.makedirs('convertor\/fold{}\/images\/{}'.format(fold,path2save))\n            sh.copy(\"..\/input\/global-wheat-detection\/{}\/{}.jpg\".format(source,name),'convertor\/fold{}\/images\/{}\/{}.jpg'.format(fold,path2save,name))","a8330fe7":"!python train.py --img 1024 --batch 2 --epochs 10 \\\n                 --data ..\/input\/wheat-detection-yolov5-utils\/wheat0.yaml \\\n                 --cfg models\/yolov5x.yaml \\\n                 --weights yolov5x.pt\n","c72f806e":"# copy saved model to weights folder\n!cp runs\/exp4\/weights\/best.pt weights","a2a44c0f":"# remove convertor of training data\n!rm -rf convertor","e2ca52b8":"# Detect test images\n!python detect.py --source '..\/input\/global-wheat-detection\/test\/' --weight weights\/best.pt --output 'inference\/output' ","df09e189":"!ls -l inference\/output","9260767a":"from IPython.display import Image, clear_output  # to display images\nImage(filename='inference\/output\/2fd875eaa.jpg', width=600)","cf3d5120":"Image(filename='inference\/output\/348a992bb.jpg', width=600)","5577381f":"The output images are stored at `inference\/output`.","5dcc162f":"## Test Model","b89e9f42":"## Train Model","f20bcb26":"## Prepare training data to YOLOv5 format\n\nMore information [here](https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data). We need two additional YAML files for both dataset and model configurations. The dataset configuration file is available [here](https:\/\/www.kaggle.com\/viroviro\/wheat-detection-yolov5-utils). The model configuration file we use is available in the repository of YOLOv5.","91c2afa6":"## Cloning repository of YOLOv5","31b400e6":"This is a notebook for the Kaggle competition [Global Wheat Detection](https:\/\/www.kaggle.com\/c\/global-wheat-detection).\n\nWe use [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5).\n","e16cda2d":"### Display Output Images","dc4560f9":"There are 10 test images at `..\/input\/global-wheat-detection\/test\/`.","07aa76a0":"We use pretrained weights on COCO dataset. The pretrained weights are auto-downloaded from [Google Drive](https:\/\/drive.google.com\/drive\/folders\/1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J). The training can be slow, so sure you have an accelerator to GPU (1 epoch takes 15 mins approximately using GPU).","e301f961":"# Wheat detection using YOLOv5","e3e5fa68":"The final output indicates the location where the model was saved. In this case, at `runs\/exp0\/weights\/best.pt`."}}