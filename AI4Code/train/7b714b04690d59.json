{"cell_type":{"27e9a14d":"code","8d35f78d":"code","f1429c7b":"code","d2f25eb9":"code","ffc47e30":"code","b9d0f214":"code","24e128c3":"code","71a0e4f6":"code","d07f962e":"code","6c6f8caf":"code","0bf3332c":"code","46d9f4f2":"code","80379c04":"code","5f1edbd5":"code","b7d0bbc3":"code","bc02d089":"code","90ea3bf3":"code","2291684e":"code","3939d0d2":"code","e46aa604":"code","4c048c84":"code","6b1edac6":"code","2dfe38c0":"code","9ebb9a53":"code","12aa8277":"code","d648f4b8":"code","887faaa0":"code","d9b274a3":"code","25b53a47":"code","59e7c788":"code","a09e971d":"code","15abae51":"code","3da178f7":"code","f1c889a0":"code","bf967d15":"code","59b46195":"code","7c34a410":"code","c1873779":"code","805b2e8b":"code","144ed933":"code","15418903":"code","40996856":"code","4bec91d9":"markdown"},"source":{"27e9a14d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d35f78d":"data = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ndata.shape","f1429c7b":"data.sample(10)","d2f25eb9":"data.info()","ffc47e30":"data.columns","b9d0f214":"data.columns","24e128c3":"# will work with the first 50 features\ndf1=data[['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9','f10','f11','f12','f13','f14','f15',\n          'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24','f25','f26','f27','f28','f29','f30',\n          'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39','f40','f41','f42','f43','f44','f45',\n          'f46', 'f47', 'f48', 'f49', 'f50', 'claim']]","71a0e4f6":"df1.sample(10)","d07f962e":"# checking null values\ndf1.isnull().sum()","6c6f8caf":"# dropping the rows with null values\ndf1 = df1.dropna(axis=0)\ndf1.sample(10)","0bf3332c":"# no null values\ndf1.isnull().sum()","46d9f4f2":"#unique values\ndf1.nunique()","80379c04":"df1.groupby(['claim']).size()","5f1edbd5":"df1['f10'].plot.hist(bins=10, figsize=(10, 8));","b7d0bbc3":"df1['f40'].plot.hist(bins=10, figsize=(10, 8));","bc02d089":"df1.plot.scatter(x='f1',\n                                y='f10',\n                                c='DarkBlue',\n                                figsize=(10, 8));","90ea3bf3":"df1.plot.scatter(x='f10',\n                                y='f30',\n                                c='DarkBlue',\n                                figsize=(10, 8));","2291684e":"df1.plot.scatter(x='f10',\n                                 y='f20',\n                                 c='claim',\n                                 colormap='viridis',\n                                 figsize=(20, 18));","3939d0d2":"df1.describe().transpose().round(2)","e46aa604":"df1.info()","4c048c84":"#checking for correlation\npearson_corr = df1.corr(method='pearson')\n\npearson_corr","6b1edac6":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (20, 18))\n\nsns.heatmap(pearson_corr, \n            linewidth=1, \n            annot=True, \n            annot_kws={'size' : 10} )\n\nplt.title('Pearson correlations', fontsize=25)\n\nplt.show()","2dfe38c0":"# feature selection with yellow brick\n!pip install yellowbrick --upgrade","9ebb9a53":"target = df1['claim']\n\nfeatures = df1.drop('claim', axis=1)","12aa8277":"from yellowbrick.target import FeatureCorrelation\n\nfeature_names = list(features.columns)","d648f4b8":"from matplotlib.pyplot import figure\n\nfigure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\n\nvisualizer.fit(features, target)\n\nvisualizer.poof()","887faaa0":"final_features = features[['f48','f47','f46','f45','f42','f41','f39','f38','f36','f35','f34','f32','f31','f24','f21','f14','f13','f1','f2','f3','f5','f6','f7','f8']]","d9b274a3":"final_features.head()","25b53a47":"final_features.shape","59e7c788":"from sklearn.model_selection import train_test_split\n\nX = final_features\nY = target\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)","a09e971d":"x_train.shape, y_train.shape,x_test.shape, y_test.shape","15abae51":"x_train.sample(10)","3da178f7":"y_train","f1c889a0":"x_test.head()","bf967d15":"y_test","59b46195":"from sklearn.ensemble import RandomForestClassifier","7c34a410":"rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)","c1873779":"rnd_clf.fit(x_train, y_train)","805b2e8b":"from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix,accuracy_score\ny_pred = rnd_clf.predict(x_test)\nprint(accuracy_score(y_test, y_pred))","144ed933":"rnd_clf.score(x_test, y_test)","15418903":"confusion_matrix(y_test,y_pred)","40996856":"plot_confusion_matrix(rnd_clf,x_test,y_test)","4bec91d9":"The default correlation calculated is the Pearson correlation"}}