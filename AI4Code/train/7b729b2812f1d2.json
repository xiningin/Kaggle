{"cell_type":{"958d6c9c":"code","8ebfe172":"code","c6969ccd":"code","7c05a90d":"code","2e7dc3fc":"code","9923da29":"code","9fb68862":"code","938768f6":"code","92dfd5a4":"code","e46b64eb":"code","b8fc1dcd":"code","2d456812":"code","4f54c29b":"code","50282ce9":"code","a7548c4d":"code","0c8d4bb0":"code","2f283f1e":"code","513ddc85":"markdown","5196272b":"markdown","61f1df6d":"markdown","cc853fd9":"markdown","783b7a82":"markdown","3c0a3dd7":"markdown","b0d5a22d":"markdown","a11adb92":"markdown","281618d5":"markdown","4d333227":"markdown","70da6a15":"markdown","10f860d2":"markdown","77016d55":"markdown","f0daa340":"markdown"},"source":{"958d6c9c":"import os\nimport sys\n# for timm(kaggle notebook only: internet disabled)\n# from pytorch-image-models dataset\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')","8ebfe172":"# asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore')\n\n#general\nimport pickle\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport gc\nimport cv2\nimport imageio\nfrom itertools import product\ngc.enable()\nimport glob\npd.set_option('display.max_columns', None) \nfrom PIL import Image\n\n# visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# augmentation\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# deep learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# metrics\nfrom sklearn.metrics import mean_squared_error\n\n# cv\nfrom sklearn.model_selection import KFold\n\nimport glob, re","c6969ccd":"class Config:\n    model_name = \"swint_large224\"\n    base_dir = \"\/content\/drive\/MyDrive\/petfinder\"\n    data_dir = \"..\/input\/petfinder-pawpularity-score\/\"\n    model_dirs = [\n        \"..\/input\/train-pytorch-swin-5fold-some-tips\"\n    ]\n    output_dir = \".\"\n    img_train_dir = os.path.join(data_dir, \"train\")\n    img_test_dir = os.path.join(data_dir, \"test\")\n    random_seed = 555\n    tta_times = 1 # 1: no TTA\n    tta_beta = 1 \/ tta_times\n    model_path = \"swin_large_patch4_window7_224\"\n    pretrained = False\n    inp_channels = 3\n    im_size =  224\n    batch_size = 32\n    num_workers = 0 # >0: OS Error\n    out_features = 1\n    dropout = 0\n    scheduler_name = \"OneCycleLR\" #OneCycleLR","7c05a90d":"def seed_everything(seed=Config.random_seed):\n    os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark =True\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","2e7dc3fc":"test_file_path = os.path.join(Config.data_dir, 'test.csv')\n\ndef return_imgfilepath(name, folder=Config.img_train_dir):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path","9923da29":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","9fb68862":"test_df = pd.read_csv(test_file_path)\ntest_df['file_path'] = test_df['Id'].apply(lambda x: return_imgfilepath(x, folder=Config.img_test_dir))\ntarget = 'Pawpularity'\nfilepaths = test_df['file_path'].values","938768f6":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\ndef get_train_transforms(epoch, dim = Config.im_size):\n    return A.Compose(\n        [             \n            # resize like Resize in fastai\n            A.SmallestMaxSize(max_size=dim, p=1.0),\n            A.RandomCrop(height=dim, width=dim, p=1.0),\n            A.VerticalFlip(p = 0.5),\n            A.HorizontalFlip(p = 0.5)\n            #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n        ]\n  )\n\ndef get_inference_fixed_transforms(mode=0, dim = Config.im_size):\n    if mode == 0: # do not original aspects, colors and angles\n        return A.Compose([\n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n            ], p=1.0)\n    elif mode == 1:\n        return A.Compose([\n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),,\n                A.VerticalFlip(p = 1.0)\n            ], p=1.0)    \n    elif mode == 2:\n        return A.Compose([\n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n                A.HorizontalFlip(p = 1.0)\n            ], p=1.0)\n    elif mode == 3:\n        return A.Compose([\n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n                A.Transpose(p=1.0)\n            ], p=1.0)\n        \ndef get_inference_random_transforms(mode=0, dim = Config.im_size):\n    if mode == 0: # do not original aspects, colors and angles\n        return A.Compose([\n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n            ], p=1.0)\n    else:\n        return A.Compose(\n            [            \n                A.SmallestMaxSize(max_size=dim, p=1.0),\n                A.CenterCrop(height=dim, width=dim, p=1.0),\n                A.VerticalFlip(p = 0.5),\n                A.HorizontalFlip(p = 0.5)\n                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n            ]\n      )","92dfd5a4":"class PetDataset(Dataset):\n    def __init__(self, image_filepaths, targets, transform=None):\n        self.image_filepaths = image_filepaths\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.image_filepaths[idx]\n        with open(image_filepath, 'rb') as f:\n            image = Image.open(f)\n            image_rgb = image.convert('RGB')\n        image = np.array(image_rgb)\n\n        if self.transform is not None:\n            image = self.transform(image = image)[\"image\"]\n        \n        image = image \/ 255 # convert to 0-1\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        target = self.targets[idx]\n\n        image = torch.tensor(image, dtype = torch.float)\n        target = torch.tensor(target, dtype = torch.float)\n        return image, target","e46b64eb":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] \/ metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \ndef usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)","b8fc1dcd":"class PetNet(nn.Module):\n    def __init__(\n        self,\n        model_name = Config.model_path,\n        out_features = Config.out_features,\n        inp_channels=Config.inp_channels,\n        pretrained=Config.pretrained\n    ):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n    \n    def forward(self, image):\n        output = self.model(image)\n        return output","2d456812":"def notta_fn(filepaths, model):\n    print(f'no tta')\n    model.eval()\n    tta_mode = 0\n    fold_preds = []\n    test_dataset = PetDataset(\n      image_filepaths = filepaths,\n      targets = np.zeros(len(filepaths)),\n      #transform = get_inference_random_transforms(tta_mode)\n      transform = get_inference_fixed_transforms(tta_mode)\n    )\n    test_loader = DataLoader(\n      test_dataset,\n      batch_size = Config.batch_size,\n      shuffle = False,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    stream = tqdm(test_loader)\n    for i, (images, target) in enumerate(stream, start = 1):\n        images = images.to(device, non_blocking = True).float()\n        target = target.to(device, non_blocking = True).float().view(-1, 1)\n        with torch.no_grad():\n            output = model(images)\n\n        pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n        fold_preds.extend(pred)\n    fold_preds = np.array(fold_preds)\n    del test_loader, test_dataset\n    gc.collect()\n    torch.cuda.empty_cache()\n    return fold_preds","4f54c29b":"def tta_fn(filepaths, model):\n    model.eval()\n    tta_preds = []\n    for tta_mode in range(Config.tta_times):\n        print(f'tta mode:{tta_mode}')\n        test_dataset = PetDataset(\n          image_filepaths = filepaths,\n          targets = np.zeros(len(filepaths)),\n          #transform = get_inference_random_transforms(tta_mode)\n          transform = get_inference_fixed_transforms(tta_mode)\n        )\n        test_loader = DataLoader(\n          test_dataset,\n          batch_size = Config.batch_size,\n          shuffle = False,\n          num_workers = Config.num_workers,\n          pin_memory = True\n        )\n        stream = tqdm(test_loader)\n        tta_pred = []\n        for i, (images, target) in enumerate(stream, start = 1):\n            images = images.to(device, non_blocking = True).float()\n            target = target.to(device, non_blocking = True).float().view(-1, 1)\n            with torch.no_grad():\n                output = model(images)\n\n            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n            tta_pred.extend(pred)\n        tta_preds.append(tta_pred)\n    tta_preds = np.array(tta_preds)\n    # default preds * tta_beta + aug_preds mean * ( 1 - tta_beta)\n    # print(test_preds.shape)\n    fold_preds = Config.tta_beta * tta_preds[0] + ( 1 - Config.tta_beta) * np.mean(tta_preds[1:], axis =0)\n    del test_loader, test_dataset\n    gc.collect()\n    torch.cuda.empty_cache()\n    return fold_preds","50282ce9":"oof_df = pd.DataFrame()\n\n\"\"\"\ntest predict loop\n\"\"\"\nbest_rmse = np.inf\ntest_preds = []\nfor model_dir in Config.model_dirs:\n    test_preds_model = []\n    for model_path in glob.glob(f'{model_dir}\/*pth'):\n        print(f'inference: {model_path}')\n        test_preds_fold = []\n        model = PetNet()\n        model.load_state_dict(torch.load(model_path))\n        model = model.to(device)\n        model.eval()\n        if Config.tta_times > 1:\n            test_preds_fold = tta_fn(filepaths, model)\n        else:\n            test_preds_fold = notta_fn(filepaths, model)\n        test_preds_model.append(test_preds_fold)\n    test_preds_model = np.array(test_preds_model)\n    test_preds.append(np.mean(test_preds_model, axis=0))","a7548c4d":"preds = np.array(test_preds)\nfinal_predictions = np.mean(preds, axis =0)\nsubmission = pd.DataFrame()\nsubmission['Id'] = test_df['Id']\nsubmission['Pawpularity'] = final_predictions","0c8d4bb0":"submission.head()","2f283f1e":"submission.to_csv(\"submission.csv\", index = False)","513ddc85":"device\/seed setting","5196272b":"mount data","61f1df6d":"## augmentations","cc853fd9":"## setup","783b7a82":"## utils","3c0a3dd7":"## prepare data","b0d5a22d":"## params about models","a11adb92":"## test_predict","281618d5":"config","4d333227":"## Dataset","70da6a15":"## prepare data","10f860d2":"training notebook is below\n\nhttps:\/\/www.kaggle.com\/ytakayama\/train-pytorch-swin-5fold-some-tips","77016d55":"## submission \nensemble mean of each fold","f0daa340":"## model"}}