{"cell_type":{"91bd5d25":"code","13ba12b5":"code","aad04820":"code","9c4d7ce4":"code","d3ec8993":"code","2b91b730":"code","aae71827":"code","6b4b40a0":"code","25e3a7fd":"code","da501ce4":"code","a3bb71fe":"code","9726b78a":"code","f55f6f71":"code","508ac08e":"code","2fdd2abc":"code","c1fd6843":"code","41c1317a":"code","0feeb374":"code","ca19a762":"code","454bac07":"code","49999f70":"code","9677e8bc":"code","9a146867":"code","b5c2561c":"code","eee4abe9":"code","948775e9":"code","51a382a6":"code","3f023215":"code","6ef7b205":"code","e1469ada":"code","f1d5b8e1":"code","0af79091":"code","0c7668f4":"code","13fa5ad6":"code","bc3704ca":"code","fff5883e":"code","7b10b3a9":"code","c5957565":"code","ab023636":"code","ad7b2f8d":"code","9c845892":"code","7e0cc5f5":"code","028e2311":"code","7c17b0b0":"code","8aa0243f":"code","1e8031a6":"code","598556bf":"code","fb540332":"code","f607711e":"markdown","4d08dfd3":"markdown"},"source":{"91bd5d25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13ba12b5":"import pandas as pd\nimport numpy as np\nimport re\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom wordcloud import WordCloud,STOPWORDS\n%matplotlib inline\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer \n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","aad04820":"df = pd.read_csv(\"\/kaggle\/input\/internet-articles-data-with-users-engagement\/articles_data.csv\", index_col=0)","9c4d7ce4":"df.head()","d3ec8993":"df.describe()","2b91b730":"df.shape","aae71827":"df.info()","6b4b40a0":"df.columns","25e3a7fd":"df = df[['source_id','author', 'title',\n       'description']]","da501ce4":"df.head()","a3bb71fe":"df.isnull().sum()","9726b78a":"df = df.dropna()","f55f6f71":"df.isnull().sum()","508ac08e":"df.shape","2fdd2abc":"df.source_id.unique()","c1fd6843":"df['source_id'].value_counts()","41c1317a":"df.loc[df['source_id'] == \"1\"]","0feeb374":"df = df.drop([750])","ca19a762":"df['source_id'].value_counts()","454bac07":"sns.countplot(y=df['source_id'])","49999f70":"df['author'].value_counts().head(10)","9677e8bc":"df['author'].value_counts().head(10).plot(kind='barh')","9a146867":"df.head(10)","b5c2561c":"df['title'] = df['title'].apply(lambda x: x.lower())\ndf['description'] = df['description'].apply(lambda x: x.lower())","eee4abe9":"df.head(10)","948775e9":"df['title'] = df['title'].replace(r'[^A-Za-z0-9 ]+', '', regex=True)\ndf['description'] = df['description'].replace(r'[^A-Za-z0-9 ]+', '', regex=True)","51a382a6":"df.head(10)","3f023215":"df['description'].sample(10)","6ef7b205":"df['description'][5]","e1469ada":"def clean_text(text, lemmatizer = WordNetLemmatizer(), \n                  stop_words = set(stopwords.words('english'))):\n      \n    words = word_tokenize(text)\n    \n    filtered_words = []\n    \n    for word in words:\n        \n        if word not in stop_words and word.isalpha():\n            filtered_words.append(lemmatizer.lemmatize(word))\n    \n    return filtered_words","f1d5b8e1":"title_word_list = df['title'].apply(lambda x: clean_text(x))","0af79091":"title_word_list[:10]","0c7668f4":"word_length_title = [len(w) for w in title_word_list]","13fa5ad6":"plt.hist(word_length_title, bins=25)\nplt.title('WordLength for title')\nplt.ylabel('count')\nplt.xlabel('Length of text')\nplt.grid()\nplt.show()","bc3704ca":"words_title = clean_text(''.join(str(df['title'].tolist())))","fff5883e":"words_title[:15]","7b10b3a9":"(pd.Series(nltk.ngrams(words_title, 2)).value_counts())[:20]","c5957565":"bigrams_series_title = (pd.Series(nltk.ngrams(words_title, 2)).value_counts())[:20]\n\nbigrams_series_title.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('20 Most Frequently Occuring Bigrams')\nplt.ylabel('Bigram')\nplt.xlabel('# of Occurances')","ab023636":"word_cloud = WordCloud(background_color=\"white\", \n               max_words=2000,\n               relative_scaling='auto',\n               colormap='winter')\n\nword_cloud.generate(','.join(words_title))\nplt.figure( figsize=(12,10) )\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n","ad7b2f8d":"description_word_list = df['description'].apply(lambda x: clean_text(x))","9c845892":"description_word_list[:10]","7e0cc5f5":"word_length_desc = [len(w) for w in description_word_list]\n\nplt.hist(word_length_desc, bins=25)\nplt.title('WordLength for Description')\nplt.ylabel('count')\nplt.xlabel('Length of text')\nplt.grid()\nplt.show()","028e2311":"words_desc = clean_text(''.join(str(df['description'].tolist())))","7c17b0b0":"words_desc[:15]","8aa0243f":"(pd.Series(nltk.ngrams(words_desc, 3)).value_counts())[:20]","1e8031a6":"trigrams_series_title = (pd.Series(nltk.ngrams(words_desc, 3)).value_counts())[:20]\n\ntrigrams_series_title.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('20 Most Frequently Occuring Trigrams')\nplt.ylabel('trigram')\nplt.xlabel('# of Occurances')","598556bf":"bigrams_series_title = (pd.Series(nltk.ngrams(words_desc, 2)).value_counts())[:20]\n\nbigrams_series_title.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('20 Most Frequently Occuring Bigrams')\nplt.ylabel('bigram')\nplt.xlabel('# of Occurances')","fb540332":"word_cloud = WordCloud(background_color=\"white\", \n               max_words=2000,\n               relative_scaling='auto',\n               colormap='winter')\n\nword_cloud.generate(','.join(words_desc))\nplt.figure( figsize=(12,10) )\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","f607711e":"# Description Text analysis","4d08dfd3":"# Title Text analysis"}}