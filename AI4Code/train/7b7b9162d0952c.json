{"cell_type":{"9c794e0e":"code","2a160546":"code","f65f7e24":"code","387ed8a8":"code","b6b0fc08":"code","c077cc34":"code","77d62c77":"code","d7d75321":"code","af6395c3":"code","495e435f":"code","3f9890c2":"code","68468bb9":"code","c08859dc":"code","88861b2a":"code","55054fce":"code","10351c7e":"code","011c328a":"code","04c8f2db":"markdown","72515d16":"markdown","f5102b80":"markdown","6d5a754f":"markdown","d3599fa0":"markdown","badc275f":"markdown","b7c0f81a":"markdown","961af43f":"markdown","ede2b8e5":"markdown","18f5c3eb":"markdown","7ad754a5":"markdown"},"source":{"9c794e0e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport math\nfrom textwrap import wrap\nwarnings.filterwarnings('ignore')\nsns.set_palette('Set2')\nsns.set_style('darkgrid')\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a160546":"df = pd.read_csv('..\/input\/south-park-series\/sp_lines.csv', encoding='utf8')\ndf.head()","f65f7e24":"df1 = pd.read_csv('..\/input\/south-park-series\/sp_ratings.csv', encoding='utf8')\ndf1.head()","387ed8a8":"#Thiago Panini https:\/\/www.kaggle.com\/thiagopanini\/pycomp-predicting-survival-on-titanic-disaster\/notebook\n\n!pip install pycomp","b6b0fc08":"#Codes by Thiago Panini https:\/\/www.kaggle.com\/thiagopanini\/pycomp-predicting-survival-on-titanic-disaster\/notebook\n\n# Importing libraries\nfrom pycomp.viz.insights import *\n\n# Character rate\ncharacter_map = {'Kyle', 'Eric Cartman'}\ncharacter_colors = ['crimson', 'darkslateblue']\nplot_donut_chart(df=df, col='character', label_names=character_map, colors=character_colors,\n                 title='South Park Characters')","c077cc34":"#Code by Mohammad Imran Shaikh https:\/\/www.kaggle.com\/shikhnu\/covid19-tweets-eda-visualization-wordcloud\n\nunique_df = pd.DataFrame()\nunique_df['Features'] = df.columns\nunique=[]\nfor i in df.columns:\n    unique.append(df[i].nunique())\nunique_df['Uniques'] = unique\n\nf, ax = plt.subplots(1,1, figsize=(15,7))\n\nsplot = sns.barplot(x=unique_df['Features'], y=unique_df['Uniques'], alpha=0.8)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center',\n                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\nplt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\nplt.ylabel('#Unique values', size=12, weight='bold')\nplt.xlabel('Features', size=12, weight='bold')\nplt.xticks(rotation=90)\nplt.show()","77d62c77":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.character)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Set1', background_color=\"purple\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","d7d75321":"s = (df.isna().sum()\/df.shape[0]*100)<50\ndf_modified = df[s.index[s].tolist()]\nprint (df_modified.shape)\ndf_modified.head()","af6395c3":"plt.rcParams['font.size'] = 14\nfig, ax = plt.subplots(2, 2, figsize=(20,20))\nfor col, ax in zip(['character','text','episode_name'], ax.flat):\n    dict_ = df_modified[col].value_counts().head(10).to_dict()\n    if ('Not Available' in dict_.keys()):\n        dict_.pop('Not Available')\n    labels = []\n    for i in dict_.keys():\n        i = i.split(' ')\n        if (len(i) > 6):\n            i[math.ceil(len(i)\/2)-1] += '\\n'\n            labels.append(' '.join(i))\n        else:\n            labels.append(' '.join(i))\n    ax.pie(x=list(dict_.values()), labels=labels, shadow=True, startangle=0)\n    \n    col = (' '.join(col.split('_'))).upper()\n    ax.set_title(col, weight='bold', fontsize=18)\nplt.tight_layout()\nplt.show()","495e435f":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.episode_name)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Pastel1', background_color=\"blue\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","3f9890c2":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.character.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.character.value_counts().head(10))\nprint('*'*20)\n\nc = df.character.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='y')\nplt.xticks(rotation=45)","68468bb9":"tfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df['episode_name'])\nprint(tfidf_matrix.shape)","c08859dc":"cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","88861b2a":"indices = pd.Series(df.index, index=df['text']).drop_duplicates()\nprint(indices)","55054fce":"idx = indices['yeah go home you little dildo']\nprint(idx)","10351c7e":"def get_recommendations(text, cosine_sim=cosine_sim):\n    idx = indices[text]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    episodes_indices = [i[0] for i in sim_scores]\n\n    return df['text'].iloc[episodes_indices]","011c328a":"get_recommendations('the president is on the loose again')","04c8f2db":"![](https:\/\/lh3.googleusercontent.com\/proxy\/rN0IhAqy4fs5SJUff1oKlog1YLgcOhm0d2CZJkj5oes_XeTuxJzfs8NKWVtXi-ugzMAPMW1ayUR9ZPZF9vehsfGfZ3h316qa03T9lLPkZLfmmVK64vFSZH1BHFwDbHM1Lom_Cew)dudeiwantthat.com","72515d16":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSLtQD8bPtQ_sVoyJ8FJ128cGYSgiLgvbwXgA&usqp=CAU)southparkshop.com","f5102b80":"#Codes by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity","6d5a754f":"![](https:\/\/www.denofgeek.com\/wp-content\/uploads\/2020\/09\/South-Park-Pandemic-Special.png?resize=768%2C432)https:\/\/www.denofgeek.com\/tv\/south-park-pandemic-special-death-sincere-season\/","d3599fa0":"![](https:\/\/pm1.narvii.com\/6459\/9b16094ea4ecff1498ae7bf8e0b2e7704325011a_hq.jpg)aminoapps.com","badc275f":"Text Mining South Park\n\n![](https:\/\/www.kaylinpavlik.com\/content\/images\/2016\/04\/southpark_ranked_plot.png)kaylingpavlik.com","b7c0f81a":"![](https:\/\/i.ytimg.com\/vi\/oechxHhMZNE\/hqdefault.jpg)southpark.ubisoft.com","961af43f":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQw3BFXC1Gc5-5DEI0NjR15F2uck0xTqrbJfA&usqp=CAU)southparkshop.com","ede2b8e5":"![](https:\/\/static.onecms.io\/wp-content\/uploads\/sites\/6\/2020\/10\/01\/southpark.jpg)ew.com","18f5c3eb":"![](https:\/\/media.vanityfair.com\/photos\/5f75ed361c04dd0b4319dac8\/master\/pass\/Screenshot%202020-10-01%20at%2010.06.53%20AM.png)vanityfair.com","7ad754a5":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRNvtRM23a93sqnhcJOYQtMwWIFrgMV0z-0Ag&usqp=CAU)gamerant.com"}}