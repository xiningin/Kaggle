{"cell_type":{"13029495":"code","d7d640c5":"code","a09f46f6":"code","e3671cf3":"code","3c9205ec":"code","4749bf8e":"code","58efd1ee":"code","93d7f07f":"code","58da002f":"code","8642acb5":"code","e14f2c3c":"code","0ce92cbe":"code","dd95da86":"code","1b66dc12":"code","7124198d":"code","b4a6862d":"code","2a5feee3":"code","c5da08bd":"code","d81165bb":"code","d5183b3e":"code","a6b3af6c":"code","a5e9cdaa":"code","4824725c":"code","f20c5534":"code","448c6329":"code","a121c894":"code","6a187c60":"code","6195298e":"code","99f48026":"code","3cc0db6f":"code","133f0563":"code","30fe6bf7":"code","7bab920b":"code","19219a8b":"markdown","c3fa99ab":"markdown","b4d2d5a0":"markdown","74a50610":"markdown","ecf5f457":"markdown"},"source":{"13029495":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy import stats\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (12, 10)\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7d640c5":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\nDV = 'SalePrice'\n","a09f46f6":"with open('\/kaggle\/input\/house-prices-advanced-regression-techniques\/data_description.txt', 'r') as fp:\n    data = fp.read()","e3671cf3":"train.shape, test.shape","3c9205ec":"train[:2]","4749bf8e":"missing_df = train.isnull().sum() \/ len(train)\nmissing_df = missing_df[missing_df > 0]\nmissing_df.sort_values(inplace=True)\nmissing_df = missing_df.reset_index(name='count')","58efd1ee":"fig, ax = plt.subplots(figsize=(10.0, 7.0))\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.barplot(x = 'count', y = 'index', data=missing_df)\nplt.xticks(rotation = 90)\nplt.show()","93d7f07f":"numeric_data = train.select_dtypes(include=[np.number])\ncat_data = train.select_dtypes(exclude=[np.number])","58da002f":"del numeric_data['Id']","8642acb5":"fig, ax = plt.subplots(figsize=(10.0, 7.0))\ncorr = numeric_data.corr()\nsns.heatmap(corr)\nplt.show()","e14f2c3c":"d = train.groupby(['OverallQual'])[DV].mean().reset_index()\n\nfont = {'family': 'serif',\n        'color':  'darkred',\n        'weight': 'normal',\n        'size': 16,\n        }\n\nfig, ax = plt.subplots(figsize=(9, 7))\npos = np.arange(len(d))\n\nrects = ax.barh(pos, d['SalePrice'])\n\nax.set_yticks(pos)\nax.set_yticklabels(d['OverallQual'])\nax.set_xlabel('SalePrice', fontdict=font)\nax.set_ylabel('OverallQual', fontdict=font)\n\nplt.show()","0ce92cbe":"d = cat_data.describe().loc['unique']\n\nfont = {'family': 'serif',\n        'color':  'darkred',\n        'weight': 'normal',\n        'size': 16,\n        }\n\nfig, ax = plt.subplots(figsize=(12, 10))\npos = np.arange(len(d))\n\nrects = ax.barh(pos, d)\n\nax.set_yticks(pos)\nax.set_yticklabels(d.index)\nax.set_ylabel('Unique count', fontdict=font)\n\n\nplt.show()","dd95da86":"cat_data.columns","1b66dc12":"numeric_data.columns","7124198d":"train[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageCars']]","b4a6862d":"train.plot.scatter(x='TotalBsmtSF', y='SalePrice');","2a5feee3":"for c in train.isnull().sum()[train.isnull().sum() > 0].index:\n    train[c].fillna(0, inplace=True)","c5da08bd":"alldata = train.copy()","d81165bb":"alldata = alldata[(alldata['TotalBsmtSF'] < 5000)]\n\nalldata['_House_Age'] = alldata['YrSold'] - alldata['YearBuilt']\n\nalldata['_Garage_Age'] = alldata['GarageYrBlt'] - alldata['YearBuilt']\n\nalldata['_Age'] = alldata['GarageYrBlt'] - alldata['YearBuilt']","d5183b3e":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","a6b3af6c":"def rmse(y_test,y_pred):\n      return np.sqrt(mean_squared_error(y_test,y_pred))","a5e9cdaa":"drop_feats = ['Id', DV, 'YearBuilt', 'YrSold']\ncustom_feats = ['_House_Age', '_Garage_Age']\n\ntrain_feats = list(numeric_data.columns)[:]\ntrain_feats = list(set(train_feats) - set(drop_feats))\n#train_feats += custom_feats","4824725c":"X = alldata[train_feats]\n\nY = np.log(alldata[DV])","f20c5534":"reg = LinearRegression()\nreg.fit(X, Y)\ny_pred = reg.predict(X)","448c6329":"print(rmse(Y, y_pred))","a121c894":"# import xgboost as xgb\n\n# regr = xgb.XGBRegressor(colsample_bytree=0.2,\n#                        gamma=0.0,\n#                        learning_rate=0.05,\n#                        max_depth=6,\n#                        min_child_weight=1.5,\n#                        n_estimators=7200,\n#                        reg_alpha=0.9,\n#                        reg_lambda=0.6,\n#                        subsample=0.2,\n#                        seed=42)\n                        \n                        \n# regr.fit(X, Y)\n# y_pred = regr.predict(X)                        ","6a187c60":"# print(rmse(Y, y_pred))","6195298e":"for c in test.isnull().sum()[test.isnull().sum() > 0].index:\n    test[c].fillna(0, inplace=True)","99f48026":"sample_submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\n","3cc0db6f":"sample_submission[:1]","133f0563":"my_submission = pd.DataFrame(list(zip(test['Id'], np.exp(reg.predict(test[train_feats])))), columns=['Id', DV])","30fe6bf7":"my_submission[:1]","7bab920b":"my_submission.to_csv('submission.csv', index=False)","19219a8b":"#### Find correlation","c3fa99ab":"#### Find nulls","b4d2d5a0":"#### Find numerical and categorical variables","74a50610":"### Feature engineering","ecf5f457":"### Model Training and Evaluation"}}