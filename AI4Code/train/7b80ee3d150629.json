{"cell_type":{"afc9e14c":"code","dbb17134":"code","0a791ed0":"code","caa72ebb":"code","9a804270":"code","b0796bb0":"code","4abda796":"code","9a9f7468":"code","920da5a3":"code","cee0903c":"code","a57bd47c":"code","f59d50c3":"code","c5e780dc":"code","8ea44a05":"code","df9b3ff1":"code","d6bc87a8":"code","290555a3":"code","31128ca9":"code","e24e7b03":"code","1fa83582":"code","2da3970a":"code","8dfb9575":"code","27afeecb":"code","dd0c9155":"code","170c3660":"code","5e21dd44":"markdown","51746321":"markdown","48e0a91b":"markdown","d7b2d0ff":"markdown","7b8e259b":"markdown","222a2247":"markdown","462e3fee":"markdown","3ff79a0d":"markdown","29a46280":"markdown"},"source":{"afc9e14c":"import numpy as np\nimport pandas as pd\nimport keras\nimport sklearn\nfrom keras.layers import Dense, Dropout\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.metrics import mean_squared_error\n#plt.style.use('dark_background')\nimport warnings\nwarnings.filterwarnings('ignore')\n#sns.set(style = 'ticks', context = 'talk')\n%matplotlib inline","dbb17134":"df = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndf.head()","0a791ed0":"df = df.drop(['Unnamed: 0'], axis = 1) # axis representes column or row\ndf.head()","caa72ebb":"sns.factorplot(x = 'cut', data = df, kind = 'count', aspect = 3)","9a804270":"sns.factorplot(x = 'clarity', data = df, kind = 'count', aspect = 3)","b0796bb0":"sns.factorplot(x = 'color', data = df, kind = 'count', aspect = 3)","4abda796":"sns.factorplot(x = 'cut', y = 'price', data = df, kind = 'box', aspect = 3)","9a9f7468":"sns.factorplot(x = 'clarity', y = 'price', data = df, kind = 'box', aspect = 3)","920da5a3":"sns.factorplot(x = 'color', y = 'price', data = df, kind = 'box', aspect = 3)","cee0903c":"plt.figure(figsize = (12,12))\nsns.heatmap(data = df.corr(), square = True, annot = True, cmap = 'BuPu')","a57bd47c":"df.dtypes","f59d50c3":"df.isna().sum()","c5e780dc":"encoder = LabelEncoder()\n\nencoder.fit(df['cut'])\ndf['cut'] = encoder.transform(df['cut'])\n\nencoder.fit(df['color'])\ndf['color'] = encoder.transform(df['color'])\n\nencoder.fit(df['clarity'])\ndf['clarity'] = encoder.transform(df['clarity'])\n\ndf.dtypes","8ea44a05":"df.head()","df9b3ff1":"X = df.drop(['price'], axis = 1)\ny = df['price']\n\nprint(X.head())\nprint()\nprint(y.head())","d6bc87a8":"print('X shape: ', X.shape)\nprint('y shape: ', y.shape)","290555a3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6)","31128ca9":"X_train = (X_train - X_train.mean()) \/ X_train.std()\nX_test = (X_test - X_test.mean()) \/ X_test.std()","e24e7b03":"model = Sequential()\n\nmodel.add(Dense(100, input_dim = X.shape[1], activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(80, activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(90, activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dropout(0.22))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mse','mae'])\nhistory = model.fit(X_train, y_train, validation_split = 0.15, batch_size = 15, epochs = 100, verbose = 0)","1fa83582":"plt.plot(history.history['mse'])\nplt.plot(history.history['val_mse'])\nplt.title('Mean_Squared_Error')\nplt.xlabel('epochs')\nplt.ylabel('MSE')\nplt.legend(['Training', 'Validation'], loc = 'upper right')\nplt.show()","2da3970a":"plt.plot(history.history['mae'])\nplt.plot(history.history['val_mae'])\nplt.title('Mean Absolute Error')\nplt.xlabel('Epochs')\nplt.ylabel('MAE')\nplt.legend(['Training', 'Validation'], loc = 'upper right')\nplt.show()","8dfb9575":"scores = model.evaluate(X_test, y_test, verbose = 0)\nprint('Mean_squared_error of testing model: ', scores[1])","27afeecb":"print('Mean Absolute Error of testing model: ', scores[2])","dd0c9155":"y_pred = model.predict(X_test).flatten() #converts 2d array into a 1d array for easy plotting\n\nplt.axes(aspect = 'equal')\nplt.scatter(y_test, y_pred)\nplt.xlabel('True Prices')\nplt.ylabel('Predicted Prices')\nplt.xlim([0, 22000])\nplt.ylim([0, 22000])\nplt.plot([0, 22000], [0, 22000], color = 'red')\n\nplt.show()","170c3660":"error = y_pred - y_test\n\nplt.hist(error, bins = 25)\nplt.xlabel('Prediction Error')\nplt.ylabel('Count')\n\nplt.show()","5e21dd44":"Lets visualize our code before any other changes","51746321":"Create keras model","48e0a91b":"3 objects. We need to conver those after we check null values","d7b2d0ff":"Now that our code looks good enough, lets seperate and create our training sets","7b8e259b":"all good. time to convert","222a2247":"Looks like 'Unnamed: 0' are the ID's so we can just remove that column as it doesnt prove any use to us","462e3fee":"create testing splits now","3ff79a0d":"Normalize our data","29a46280":"Good! Now lets see what else we can do to the data.\nIt seems that we have a couple of objects in 'cut', 'clarity', and 'color' so we should go and try to convert them into categorical numbers. Lets confirm first by checking the dtypes and if there are any null values."}}