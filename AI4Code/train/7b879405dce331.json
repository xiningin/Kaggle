{"cell_type":{"73d78535":"code","fbce1324":"code","580cf0ea":"code","a407a33a":"code","9133a29e":"code","44288b80":"code","fe7353cc":"code","3233c64d":"code","479f850e":"code","6bc87755":"code","6f4ff3f2":"code","ab641a7c":"code","511db4ef":"code","9c51fbfa":"code","aaa61000":"code","958b52f0":"code","a50f9fa5":"code","129bb7f1":"code","5f5e7c36":"code","9dca7cee":"code","e58348eb":"code","77f126dd":"code","8033d133":"code","b7c5493f":"code","65883067":"markdown","6b238b2b":"markdown","83da1942":"markdown","5c633bc0":"markdown"},"source":{"73d78535":"# Importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","fbce1324":"data = pd.read_csv(\"..\/input\/ozone-level-detection\/eighthr.data.csv\", header=None)\ndf = pd.DataFrame(data)","580cf0ea":"df.shape","a407a33a":"df.head()","9133a29e":"df.info()","44288b80":"df = df.drop([0], axis=1)  # Dropping Date column as it is not useful in prediction and analysis","fe7353cc":"for i in df.columns:\n  df[i] = df[i].replace(['?'], np.nan)","3233c64d":"df.head()","479f850e":"# showing column wise %ge of NaN values they contains\nnull_col = []\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n  if df[i].isna().mean()*100 > 0:\n    null_col.append(i)","6bc87755":"# Since dataset contains values in str format, changing it into float values\n\nfor i in df.columns[:-1]:\n  df[i] = df[i].astype(str).astype(float)","6f4ff3f2":"for i in null_col:\n  df[i] = df[i].fillna(df[i].mean())\n\n# lets check for null values again\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)","ab641a7c":"# Checking for unbalanced dataset\n\nplt.figure(figsize=(5,5))\nax = sns.countplot(x=73, data=df)\n\nfor p in ax.patches:\n        ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\n","511db4ef":"from imblearn.over_sampling import RandomOverSampler\n\noversample = RandomOverSampler()\nx, y = oversample.fit_resample(df.drop([73], axis=1), df[73])\n\nnew_df = pd.DataFrame(x, columns=df.drop([73], axis=1).columns)\nnew_df[73] = y\n\nnew_df.head()\n\n","9c51fbfa":"cormap = new_df.corr()\nfig, ax = plt.subplots(figsize=(50,50))\nsns.heatmap(cormap, annot = True)","aaa61000":"# Simple Function to get the name of top most corelated attributes\n\ndef get_corelated_col(cor_dat, threshold):\n# Cor_data to be column along which corelation to be measured\n#Threshold be the value above wich of corelation to considered\n\n  feature=[]\n  value=[]\n  for i ,index in enumerate(cor_dat.index):\n    if abs(cor_dat[index]) > threshold:\n      feature.append(index)\n      value.append(cor_dat[index])\n\n    df = pd.DataFrame(data = value, index = feature, columns=['corr value'])\n  return df","958b52f0":"top_corelated_values = get_corelated_col(cormap[73], 0.40)\ntop_corelated_values","a50f9fa5":"final_df = df[top_corelated_values.index]\nfinal_df.head()","129bb7f1":"X = new_df.drop([73], axis=1)\ny = new_df[73]","5f5e7c36":"# Scale the data to be between -1 and 1\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\nX.head()","9dca7cee":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","e58348eb":"# model training \n\nfrom sklearn.svm import SVC\n\nmodel= SVC(kernel='rbf')   # Here kernel used is RBF (Radial Basis Function)\nmodel.fit(X_train, y_train)","77f126dd":"# Prediction\n\ny_pred = model.predict(X_test)\n\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\npred_df.head()","8033d133":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(mat, annot = True)","b7c5493f":"from sklearn import metrics\n\n# Measure the Accuracy Score\nprint(\"Accuracy score of the predictions: {value:.2f} %\".format(value=metrics.accuracy_score(y_pred, y_test)*100))\n","65883067":">Let's further see how other attributes are related to each other using pairplot","6b238b2b":"> Since no column has signficant missing values, there is no need to drop column here . Now fill the num values the mean\nof columns","83da1942":"> Here we can see that all the classes are balanced.","5c633bc0":"> Since at some places dataset contains __'?'__ symbol, so we are changing it into __Nan__ value. "}}