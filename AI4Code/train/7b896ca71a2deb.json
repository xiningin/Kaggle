{"cell_type":{"797391ba":"code","94a9597f":"code","85287bf9":"code","288a9662":"code","30863f4c":"code","b8beb822":"code","a39b2096":"code","f5e1a79f":"code","d46b5a53":"code","10acd919":"code","5a8718b9":"code","91510abc":"code","c41672da":"markdown"},"source":{"797391ba":"import numpy as np \nimport pandas as pd \n\nimport os\nfrom transformers import *\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport random\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm","94a9597f":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","85287bf9":"test_df = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')","288a9662":"test_df","30863f4c":"class Data(Dataset):\n    def __init__(self, data):\n        super().__init__()\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):       \n        excerpt = self.data.excerpt[idx]\n        return excerpt","b8beb822":"test_data = Data(data = test_df) \ntest_loader = DataLoader(dataset = test_data, shuffle=False, batch_size = 64)","a39b2096":"class ReadabilityModel(PreTrainedModel): \n    def __init__(self, conf):\n        super(ReadabilityModel, self).__init__(conf) \n        self.roberta = RobertaModel(config=conf)\n        self.drop_out = nn.Dropout(0.1)\n        self.l1 = nn.Linear(768 * 1, 1)\n        torch.nn.init.normal_(self.l1.weight, std=0.02)\n    \n    def forward(self, ids, mask):\n        out = self.roberta(\n            input_ids=ids,\n            attention_mask=mask\n        )\n        out = out['hidden_states']\n        out = out[-1]\n        out = self.drop_out(out)\n        out = torch.mean(out, 1, True)\n        \n        preds = self.l1(out)\n\n        preds = preds.squeeze(-1).squeeze(-1)\n\n        return preds","f5e1a79f":"tokenizer = RobertaTokenizerFast.from_pretrained('..\/input\/robertabase', model_max_length=514) \n\nmodel_config = RobertaConfig()\nmodel_config.output_hidden_states = True\nmodel_config.max_position_embeddings=514\nmodel_config.vocab_size = 50265\nmodel_config.type_vocab_size = 1\n\nmodel = ReadabilityModel(model_config)\nif torch.cuda.is_available():\n    model.load_state_dict(torch.load(\"..\/input\/commonlit-readability-roberta-simple-baseline\/roberta_baseline.bin\"))\nelse: \n    model.load_state_dict(torch.load(\"..\/input\/commonlit-readability-roberta-simple-baseline\/roberta_baseline.bin\", map_location=torch.device('cpu')))\nmodel = model.to(device)","d46b5a53":"model.eval()\nwith torch.no_grad():\n    for i, excerpts in enumerate(tqdm(test_loader)):\n        batch = tokenizer(list(excerpts), truncation=True, padding=True, return_tensors='pt', add_special_tokens=False)\n        input_ids = batch['input_ids']\n        input_ids = input_ids.to(device, dtype=torch.long)\n        attention_mask = batch['attention_mask']\n        attention_mask = attention_mask.to(device, dtype=torch.long)\n            \n        preds = model(input_ids, attention_mask)       \n        preds = preds.cpu().detach().numpy()\n\n        if i==0:\n            preds_test = preds\n        else:\n            preds_test = np.concatenate((preds_test,preds), axis=None)","10acd919":"submission_df = pd.DataFrame({'id': test_df.id, 'target': preds_test})","5a8718b9":"submission_df.to_csv('\/kaggle\/working\/submission.csv', index=False)","91510abc":"submission_df","c41672da":"Inference with a simple RoBerta model.\n\nThe notebook to train the model is available here: https:\/\/www.kaggle.com\/hannes82\/commonlit-readability-roberta-simple-baseline"}}