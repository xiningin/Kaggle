{"cell_type":{"a8873f37":"code","02bc5dfd":"code","251c673a":"code","49d89854":"code","fadd4292":"code","d0030f2a":"code","81b7bde7":"code","593c536d":"code","2cd6be83":"code","29466104":"code","b43ad128":"code","2c39706e":"code","a2707a84":"code","24e971a7":"code","9a11df8d":"code","3e35b7ae":"code","e688e7b3":"code","a813fd95":"code","34b6c71b":"code","47203ec0":"code","7832b368":"markdown","482bf32b":"markdown","7a49dbb4":"markdown","aec07f0f":"markdown"},"source":{"a8873f37":"import os\nimport cv2\nimport numpy as np\nfrom collections import defaultdict\n\nimport scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalMaxPool2D\nfrom tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","02bc5dfd":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\nfor dir_ in os.listdir(INPUT_PATH):\n    count = 0\n    for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n        count += 1\n    print(f\"{dir_} has {count} number of images\")","251c673a":"TOP_EMOTIONS = [\"happy\", \"surprise\", \"anger\", \"sadness\", \"fear\"]","49d89854":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\ndata = defaultdict(str)\nfor dir_ in os.listdir(INPUT_PATH):\n    if dir_ in TOP_EMOTIONS:\n        data[dir_] = defaultdict(list)\n        for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n            sub = f.split(\"_\")[0]\n            data[dir_][sub].append(f)\n\n# data","fadd4292":"def preprocess_list(x):\n    return int((x.split(\"_\")[2]).split(\".\")[0])\n\ndef preprocess_dict(x):\n    res = list(np.argsort(list(map(preprocess_list, x))))\n    return [x[i] for i in res]\n\ndef img2array(x,path):\n    arr = np.empty(shape=(3,48,48))\n    for i,f in enumerate(x):\n        img = cv2.imread(path+f, 0)\n        arr[i] = img\n    return arr","d0030f2a":"for emotion in data:\n    data[emotion] = dict((k, preprocess_dict(v)) for k, v in data[emotion].items())\n    data[emotion] = dict((k, img2array(v, path=INPUT_PATH + emotion + \"\/\")) for k, v in data[emotion].items())\n\n# data","81b7bde7":"for k,v in data.items():\n    print(f\"{k} has {len(v)} samples\")","593c536d":"surprise = np.stack(data[\"surprise\"].values(), axis=0)\nsurprise = surprise.reshape(*surprise.shape,1)\n\nhappy = np.stack(data[\"happy\"].values(), axis=0)\nhappy = happy.reshape(*happy.shape,1)\n\nanger = np.stack(data[\"anger\"].values(), axis=0)\nanger = anger.reshape(*anger.shape,1)\n\nsadness = np.stack(data[\"sadness\"].values(), axis=0)\nsadness = sadness.reshape(*sadness.shape,1)\n\nfear = np.stack(data[\"fear\"].values(), axis=0)\nfear = fear.reshape(*fear.shape,1)\n\nX = np.concatenate((surprise, happy, anger, sadness, fear))\ny = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\ny = np_utils.to_categorical(y)\n\nX.shape, y.shape","2cd6be83":"label_emotion_mapper = {0:\"surprise\", 1:\"happy\", 2:\"anger\", 3:\"sadness\", 4:\"fear\"}","29466104":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, stratify=y, shuffle=True, random_state=42)\nX_train.shape, X_valid.shape","b43ad128":"np.random.seed(42)\nsurprise_idx = np.random.choice(np.where(y_train[:, 0]==1)[0], size=1)\nhappy_idx = np.random.choice(np.where(y_train[:, 1]==1)[0], size=1)\nanger_idx = np.random.choice(np.where(y_train[:, 2]==1)[0], size=1)\nsad_idx = np.random.choice(np.where(y_train[:, 3]==1)[0], size=1)\nfear_idx = np.random.choice(np.where(y_train[:, 4]==1)[0], size=1)\n\nfig = pyplot.figure(1, (6,13))\n\ni = 0\nfor name, idx in zip(label_emotion_mapper.values(), [surprise_idx, happy_idx, anger_idx, sad_idx, fear_idx]):\n    for j in range(3):\n        i += 1\n        ax = pyplot.subplot(5,3,i)\n        sample_img = X_train[idx][0,j,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(name)","2c39706e":"# data normalization\nX_train = X_train \/ 255.\nX_valid = X_valid \/ 255.","a2707a84":"def build_dcnn(input_shape, show_arch=True):\n    \"\"\"\n    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n    atleast in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n    results.\n    \"\"\"\n    net = Sequential(name='DCNN')\n\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n    net.add(Dropout(0.45, name='dropout_1'))\n\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n    net.add(Dropout(0.45, name='dropout_2'))\n\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n    net.add(Dropout(0.4, name='dropout_3'))\n\n    net.add(\n        Conv2D(\n            filters=512,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_7'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    net.add(\n        Conv2D(\n            filters=512,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_8'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_8'))\n    \n    net.add(Dropout(0.4, name='dropout_4'))\n    \n    net.add(GlobalMaxPool2D(name=\"globalmax2d\"))\n    \n    if show_arch:\n        net.summary()\n    \n    return net","24e971a7":"def memory_model(input_shape, num_class, show_arch=True):\n    dcnn = build_dcnn(input_shape[1:], show_arch=False)\n    \n    model = Sequential(name=\"convolutional_Bidrectional_LSTM\")\n\n    model.add(\n        TimeDistributed(\n            dcnn,\n            input_shape=input_shape,\n            name=\"time_distributed\",\n        )\n    )\n    \n    model.add(Bidirectional(LSTM(128, return_sequences=True, name=\"bidirect_lstm_1\")))\n    model.add(Dropout(.35, name=\"dropout_1\"))\n    model.add(Bidirectional(LSTM(64, return_sequences=False, name=\"bidirect_lstm_2\")))\n    model.add(Dropout(.45, name=\"dropout_2\"))\n\n    model.add(\n        Dense(\n            128,\n            activation='elu',\n            kernel_initializer='he_normal',\n            name='dense_1'\n        )\n    )\n    model.add(BatchNormalization(name='batchnorm_1'))\n    model.add(Dropout(.7, name=\"dropout_3\"))\n\n    model.add(\n        Dense(\n            num_class,\n            activation='softmax',\n            name='out_layer'\n        )\n    )\n    \n    if show_arch:\n        model.summary()\n    \n    return model","9a11df8d":"early_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.00005,\n    patience=12,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.8,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n#     early_stopping,\n    lr_scheduler,\n]\n\nbatch_size = 32\nepochs = 100","3e35b7ae":"INPUT_SHAPE = (3, 48, 48, 1)\noptim = optimizers.Nadam(0.001)\n\nmodel = memory_model(INPUT_SHAPE, num_class=5)\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optim,\n        metrics=['accuracy']\n)","e688e7b3":"history = model.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","a813fd95":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history.png')\npyplot.show()","34b6c71b":"yhat_valid = model.predict_classes(X_valid)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid, figsize=(7,7))\npyplot.savefig(\"confusion_matrix.png\")\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(y_valid, axis=1) != yhat_valid)}\\n\\n')\nprint(classification_report(np.argmax(y_valid, axis=1), yhat_valid))","47203ec0":"np.random.seed(0)\nindices = np.random.choice(range(X_valid.shape[0]), size=15, replace=False)\n\nfig = pyplot.figure(1, (9,30))\n\ni = 0\nfor idx in indices:\n    true_emotion = label_emotion_mapper[np.argmax(y_valid[idx])]\n    pred_emotion = label_emotion_mapper[model.predict_classes(np.expand_dims(X_valid[idx], axis=0))[0]]\n    \n    for j in range(3):\n        i += 1\n        ax = pyplot.subplot(15,3,i)\n        sample_img = X_valid[idx,j,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"t:{true_emotion}, p:{pred_emotion}\")","7832b368":"`If we have more data to train then we will get better and more generalized model.`","482bf32b":"### Data Preprocessing\n\nI first make the data compatible for neural nets","7a49dbb4":"`sadness` and `fear` has very low number of images as compared to other classes","aec07f0f":"`The fluctuations in the epoch metrics is due to the fact that we have very low data for such a complex task.`"}}