{"cell_type":{"1ba43b1b":"code","392aefb8":"code","26fba742":"code","2d4ae95b":"code","350f93fc":"code","d712a651":"code","fbffc8c1":"code","93f3d1ad":"code","8e33ae30":"code","5b50d95c":"code","1ec694b6":"code","537d2487":"code","2c9696b5":"code","636cc8dc":"code","04a2fc11":"code","0dfcd5b6":"code","42003713":"code","6737387a":"code","75ab97f9":"code","b791493e":"code","c7ddece4":"code","0b4cc3be":"code","b25d5e12":"code","6beb2c05":"code","9b3f7d97":"code","c1c94b6c":"code","3de20741":"code","ea2d12c0":"code","a3423669":"code","8bd9e040":"code","0f4c605a":"code","c83c2b00":"code","4e31f2b1":"code","23f417aa":"code","e044336d":"code","817dd42e":"code","470acddf":"code","5c9aaa74":"code","19ff8c00":"markdown","d30a4452":"markdown","e4f99634":"markdown","82c1908b":"markdown","d439d0db":"markdown","15c5344e":"markdown","398476d0":"markdown","96b57bca":"markdown","b2e10554":"markdown","9f2808c4":"markdown","0ae9099c":"markdown","12eb22ba":"markdown"},"source":{"1ba43b1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","392aefb8":"!pip install chart_studio\nimport chart_studio.plotly as py # visualization library\n","26fba742":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # visualization library\nimport matplotlib.pyplot as plt # visualization library\nfrom plotly.offline import init_notebook_mode, iplot # plotly offline mode\ninit_notebook_mode(connected=True) \nimport plotly.graph_objs as go # plotly graphical object\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nimport operator","2d4ae95b":"weather = pd.read_csv(\"..\/input\/weatherww2\/Summary of Weather.csv\")\nweather_station_location = pd.read_csv(\"..\/input\/weatherww2\/Weather Station Locations.csv\")\n","350f93fc":"weather.columns","d712a651":"weather_station_location.columns","fbffc8c1":"index0=[\"WBAN\",\"NAME\",\"STATE\/COUNTRY ID\",\"Latitude\",\"Longitude\"] \n\n\nsta_loc_df = weather_station_location.reindex(columns=index0 ,fill_value=0)\nsta_loc_df.info()","93f3d1ad":"index1=[\"MaxTemp\",\"MinTemp\", \"Date\"]\n\nwea_df = weather.reindex(columns=index1, fill_value=0)\nwea_df.info()","8e33ae30":"wea_df = wea_df[:][:500]    \nwea_df.head(4)","5b50d95c":"sta_loc_df.tail(4)","1ec694b6":"wea_df.describe().T","537d2487":"pd.to_datetime(wea_df['Date'])","2c9696b5":"sns.pairplot(wea_df, kind=\"reg\")","636cc8dc":"# See picture with scatter or plot method\n\n\n\nplt.figure(figsize=(22,10))\nplt.plot(wea_df.Date, wea_df.MaxTemp, wea_df.MinTemp,)\nplt.title(\"Max and Min Temperature of Dates\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Max and Min Temperature\")\nplt.legend()\nplt.show()","04a2fc11":"\ny = np.array(wea_df['MaxTemp']).reshape(-1, 1)\nX = np.array(wea_df['MinTemp']).reshape(-1, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 13)","0dfcd5b6":"corr=wea_df.corr()\nsns.heatmap(corr, cmap = 'Wistia', annot= True);","42003713":"corr1=sta_loc_df.corr()\nsns.heatmap(corr1, cmap = 'Wistia', annot= True);","6737387a":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()  \nlin_reg.fit(X_train, y_train)","75ab97f9":"y_pred = lin_reg.predict(X_test)                                     # Predict Linear Model\naccuracy_score = lin_reg.score(X_test, y_test)                       # Accuracy score\nprint(\"Linear Regression Model Accuracy Score: \" + \"{:.1%}\".format(accuracy_score))","b791493e":"from sklearn.metrics import mean_squared_error,r2_score\n\nlin_reg_r2=r2_score(y_test, y_pred)\n\nprint(\"R2 Score: \" +\"{:.3}\".format(lin_reg_r2))\n\n\n","c7ddece4":"import statsmodels.api as sm\nmodel=sm.OLS(lin_reg.predict(X_test),X_test)\nprint(model.fit().summary())","0b4cc3be":"# Finally draw figure of Linear Regression Model\n\nplt.scatter(X_test, y_test, color='r')\nplt.plot(X_test, y_pred, color='g')\nplt.show()","b25d5e12":"from sklearn.linear_model import LinearRegression\n\nX_train_val=X_train\ny_train_val=y_train\n\nlin_reg0 = LinearRegression()  \nlin_reg0.fit(X_train_val, y_train_val)\n\nplt.scatter(X_train_val ,y_train_val ,color=\"red\")\nplt.plot(X_train,lin_reg0.predict(X_train_val),color=\"blue\")\n","6beb2c05":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg=PolynomialFeatures(degree= 5)\nx_poly=poly_reg.fit_transform(X_train)\nprint(x_poly)\n\nlin_reg2=LinearRegression()\nlin_reg2.fit(x_poly,y_train)\n\npoly_pred=lin_reg2.predict(x_poly)","9b3f7d97":"rmse = np.sqrt(mean_squared_error(y_train,poly_pred))\npoly_reg_r2 = r2_score(y_train,poly_pred)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(poly_reg_r2))","c1c94b6c":"plt.scatter(X_train, y_train, s=50,color=\"red\")\n# sort the values of x before line plot\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(X_train,poly_pred), key=sort_axis)\nX_train, poly_pred = zip(*sorted_zip)\nplt.plot(X_train, poly_pred, color='blue')\nplt.show()","3de20741":"from sklearn.tree import DecisionTreeRegressor\n\ndt_reg = DecisionTreeRegressor()          \ndt_reg.fit(X_train,y_train)","ea2d12c0":"dt_predict = dt_reg.predict(X_train)","a3423669":"plt.scatter(X_train,y_train, color=\"red\")                           \nX_grid = np.arange(min(np.array(X_train)),max(np.array(X_train)), 0.01)  \nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.plot(X_grid,dt_reg.predict(X_grid),color=\"blue\")\nplt.xlabel(\"Temperature\")\nplt.ylabel(\"Salinity\")\nplt.title(\"Decision Tree Model\")\nplt.show()","8bd9e040":"rmse = np.sqrt(mean_squared_error(y_train,dt_predict))\ndt_reg_r2 = r2_score(y_train,dt_predict)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(dt_reg_r2))","0f4c605a":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=6, random_state=0)\nrf_reg.fit(X_train,y_train)\nrf_predict = rf_reg.predict(X_train)\n","c83c2b00":"plt.scatter(X_train,y_train, color=\"red\")                          \nX_grid = np.arange(min(np.array(X_train)),max(np.array(X_train)), 0.01)  \nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.plot(X_grid,rf_reg.predict(X_grid),color=\"blue\")             \nplt.xlabel(\"Temperature\")\nplt.ylabel(\"Salinity\")\nplt.title(\"Random Forest Model\")\nplt.show()","4e31f2b1":"rmse = np.sqrt(mean_squared_error(y_train,rf_predict))\nrf_reg_r2 = r2_score(y_train,rf_predict)\nprint(\"RMSE Score for Test set: \" +\"{:.2}\".format(rmse))\nprint(\"R2 Score for Test set: \" +\"{:.2}\".format(rf_reg_r2))","23f417aa":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nxTra_sc=sc.fit_transform(X_train)\nyTra_sc=sc.fit_transform(y_train)\nxTes_sc=sc.fit_transform(X_test)","e044336d":"from sklearn.svm import SVR\nsvr_reg =SVR(kernel =\"rbf\") #di\u011fer se\u00e7enekler: linear, poly\nsvr_reg.fit(xTra_sc,yTra_sc)\n\nplt.scatter(xTra_sc,yTra_sc,color=\"red\")\nplt.plot(xTra_sc,svr_reg.predict(xTra_sc),color=\"blue\")\n\n","817dd42e":"from sklearn.metrics import r2_score\n# Haydi r2 de\u011feri hesaplayal\u0131m.\nprint(\"SVR R2 de\u011feri\")\n#olceki de\u011ferler scale'li olanlar al\u0131nd\u0131.\n\nsvr_reg_r2= r2_score(yTra_sc, svr_reg.predict(xTra_sc))\nprint(svr_reg_r2)\n","470acddf":"print(\"Weather Prediction\")\nprint(\"Linear: \")\nprint(lin_reg.predict([[10]]))\nprint(\"Polynomial: \")\nprint(lin_reg2.predict(poly_reg.fit_transform([[10]])))\nprint(\"SVR: rbf?\")\nprint(svr_reg.predict([[10]]))\nprint(\"Decision Tree: \")\nprint(dt_reg.predict([[10]]))\nprint(\"Random Forest : \")\nprint(rf_reg.predict([[10]]))\n\n","5c9aaa74":"\n#%% R2 DE\u011eERLER\u0130 KAR\u015eILA\u015eTIRMA\n\nprint(\"\u00b7\u00b7\u00b7R2 DE\u011eERLER\u0130\u00b7\u00b7\u00b7\")\nprint(\"Linear Regression     :     \"+str(lin_reg_r2))\nprint(\"Polynomial Regression :     \"+str(poly_reg_r2))\nprint(\"Decision Tree         :     \"+str(dt_reg_r2))\nprint(\"Random Forest         :     \"+str(rf_reg_r2))\nprint(\"SVR Regression        :     \"+str(svr_reg_r2))\n","19ff8c00":"Datay\u0131 y\u00fckleyelim","d30a4452":"# 3.Decision Tree","e4f99634":"# 1. Linear Regression\nII.D\u00fcnya Sava\u015f\u0131nda, g\u00fcnl\u00fck min ve max s\u0131cakl\u0131k aras\u0131nda nas\u0131lbir ili\u015fki var?","82c1908b":"# 4. SVR\nDo\u011fru sonu\u00e7 alabilmek i\u00e7in scale edilmesi gerekiyor de\u011ferlerin. ","d439d0db":"\u015eimdi datam\u0131z\u0131 biraz tan\u0131mam\u0131z gerekiyor.\n","15c5344e":"Weather:\n- STA: weather station number (WBAN)(Weather Bureau, Air Force, and Navy)\n- Date: Date of temperature measurement (S\u0131cakl\u0131k \u00f6l\u00e7\u00fcm tarihi)\n- MeanTemp: Mean temperature (Ortalama S\u0131cakl\u0131k)\n\nWeather station location:\n- WBAN: Weather station number \n- NAME: weather station name\n- STATE\/COUNTRY ID: acronym of countries\n- Latitude: Latitude of weather station (Meteoroloji istasyonunun enlemi)\n- Longitude: Longitude of weather station (Meteoroloji istasyonunun boylam\u0131)","398476d0":"G\u00f6r\u00fcld\u00fc\u011f\u00fc \u00fczre datam\u0131zda bir\u00e7ok s\u00fctun var. Biz bunlardan sadece bir ka\u00e7 tanesini kullanaca\u011f\u0131z. Bu y\u00fczden sadece o kolonlardan olu\u015fan yeni data frameler olu\u015ftural\u0131m","96b57bca":"# 2. Polynomial Regression","b2e10554":"# 4. Random Forest","9f2808c4":"\u00d6ncelikle ihityac\u0131m\u0131z olan k\u00fct\u00fcphaneleri ekliyoruz.","0ae9099c":"#### Korelasyon Matrisi\nKorelasyon ba\u011f\u0131ml\u0131 ve ba\u011f\u0131ms\u0131z de\u011fi\u015fken aras\u0131ndaki ili\u015fkinin g\u00fcc\u00fcn\u00fc a\u00e7\u0131klar.","12eb22ba":"# R-Squared \nKonumuza ba\u015flamadan \u00f6nce algoritmalar\u0131m\u0131z\u0131n hangisinin daha do\u011fru sonu\u00e7lar verece\u011fini tespit etmemize yarayan R2 score'dan bahsetmek istiyorum.\n\n**R\u00b2 ,regresyon ile modelin ne kadar uyumlu oldu\u011funu g\u00f6sterir.**\n\n\n\\begin{aligned} &\\text{R}^2 = 1 - \\frac{ \\text{Unexplained Variation} }{ \\text{Total Variation} } \\\\ \\end{aligned} \n\u200b\t  \n\n\n\n\n   **Hata Kareleri Toplam\u0131**(Verinin Varyasyonu)\n   \n    \u2211(gercek deger-tahmin)\u00b2\n    \u2211( yi - y'i)\u00b2\n\n   **Ortalama Farklar\u0131n Toplam\u0131**\n   \n   Burada OFT olarak buldu\u011fumuz de\u011fer en k\u00f6t\u00fc \u00e7\u0131kabilecek ihtimaldir. \u00d6rne\u011fin bir kilo tahmini yap\u0131lsa s\u0131n\u0131f i\u00e7erisinde, en kolay yol t\u00fcm s\u0131n\u0131f\u0131n ortalama kilosunu bulup herkese o tahmini yapmakt\u0131r. \n   \n    \u2211(yi - y ort)\u00b2 \n\n   **R\u00b2**\n   \n    R\u00b2 =  1- ( HKT \/ OFT ) \n\n>R\u00b2 de\u011ferleri 0 ile 1 aras\u0131ndad\u0131r. \nEn aptal olarak tan\u0131mlayabilece\u011fimiz algoritman\u0131n R-kare si 0 s-\u00e7\u0131kacakt\u0131r.\n%100 l\u00fck bir sonu\u00e7 yani R\u00b2'nin 1 \u00e7\u0131kmas\u0131 demek sonu\u00e7lar\u0131 tam olarak tahmin edebiliyoruz demektir. Fakat overfitting dedi\u011fimiz ezberleme durumunun ger\u00e7ekle\u015fme ihtimalinden \u00f6t\u00fcr\u00fc b\u00f6yle bir sonu\u00e7 da istenmez. Bir modelin R\u00b2 de\u011feri 0,50 ise, g\u00f6zlemlenen varyasyonun yakla\u015f\u0131k yar\u0131s\u0131 modelin girdileri ile a\u00e7\u0131klanabilir."}}