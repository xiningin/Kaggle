{"cell_type":{"f1878590":"code","6d0d611e":"code","64560e2e":"code","62102f06":"code","f4a21383":"code","dc3b8d53":"code","27d7c27e":"code","e39ea836":"code","dd684f1b":"code","163de9c9":"code","6251e213":"code","a7df9bcc":"code","886df747":"code","eb9166a3":"code","fa10ae41":"code","d0104d00":"code","74fc18d9":"code","f840ce5b":"code","8fa685a3":"code","91b154c9":"code","f31443a1":"code","b241a5f7":"code","3695ead9":"code","950de53a":"code","522f1a95":"code","dce4715c":"markdown","12835821":"markdown","7c8c60b4":"markdown","2af05fff":"markdown","78eeb8f2":"markdown","04ddb945":"markdown","86d36c96":"markdown"},"source":{"f1878590":"%matplotlib inline","6d0d611e":"#from google.colab import drive\n#drive.mount('\/content\/drive')","64560e2e":"# License: BSD\n# Author : Sasank Chilamkurthy\n# Modificado 20210823\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nEPOCHS=50\nEPOCHS=2\n\nplt.ion()   # interactive mode","62102f06":"import tensorflow as tf\ntf.test.is_gpu_available()","f4a21383":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]), 'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# Set clasificado MGCD\ndata_dir = '..\/input\/basecd\/MGCD'\n\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'test']}\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=2)\n              for x in ['train', 'test']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n\nclass_names = image_datasets['train'].classes\n\n# Set clasificados Savernet\ndata_dir_sv = '..\/input\/clasificades'\n\nimage_datasets_sv = {x: datasets.ImageFolder(os.path.join(data_dir_sv, x), data_transforms[x])\n                  for x in ['train', 'test']}\n\ndataloaders_sv = {x: torch.utils.data.DataLoader(image_datasets_sv[x], batch_size=4, shuffle=True, num_workers=2)\n              for x in ['train', 'test']}\n\ndataset_sizes_sv = {x: len(image_datasets_sv[x]) for x in ['train', 'test']}\nclass_names_sv = image_datasets_sv['train'].classes\n\n\n## Torch Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n","dc3b8d53":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# MGCD\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n\n# Savernet\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders_sv['train']))\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n","27d7c27e":"def train_model(model, criterion, optimizer, scheduler, num_epochs=EPOCHS):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    vals_train_loss = []\n    vals_test_loss = []\n    vals_acc = []\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            if phase == 'train':\n                vals_train_loss.append(epoch_loss)\n            else:\n                vals_test_loss.append(epoch_loss)\n                vals_acc.append(epoch_acc)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, vals_train_loss, vals_test_loss, vals_acc","e39ea836":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['test']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","dd684f1b":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n# model_ft.fc = nn.Linear(num_ftrs, 2)\nmodel_ft.fc = nn.Linear(num_ftrs, len(class_names))\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","163de9c9":"model_ft_sv = model_ft\nnum_ftrs = model_ft_sv.fc.in_features\nmodel_ft_sv.fc = nn.Linear(num_ftrs, len(class_names))\n\nmodel_ft_sv = model_ft_sv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft_sv = optim.SGD(model_ft_sv.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft_sv, step_size=7, gamma=0.1)\n","6251e213":"_train_losess = []\n_test_losess = []\n_accuracy = []\nmodel_ft, _train_losses, _test_losses, _accuracy = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCHS)","a7df9bcc":"plt.figure(figsize=(10,5))\nplt.title(\"Training and Test Loss - Accuracy\")\nplt.plot(_test_losses,label=\"Test\")\nplt.plot(_train_losses,label=\"Train\")\nplt.plot(_accuracy,label=\"Acc\")\nplt.xlabel(\"Iteraciones\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n","886df747":"#persisto modelo mgcd\n#path = '\/content\/drive\/My Drive\/savernet\/modelos\/modelo_mgcd.pt'\n#torch.save(model_ft.state_dict(), path)\npath = '\/content\/drive\/My Drive\/savernet\/modelos\/chkp_modelo_mgcd.pt'\ntorch.save({\n            '_train_losses': _train_losses, \n            '_test_losses': _test_losses, \n            '_accuracy': _accuracy,\n            'model_ft_state_dict': model_ft.state_dict()\n            }, path)","eb9166a3":"visualize_model(model_ft)","fa10ae41":"model_ft_sv, _train_losses, _test_losses, _accuracy = train_model(model_ft_sv, criterion, optimizer_ft_sv, exp_lr_scheduler, num_epochs=EPOCHS)","d0104d00":"plt.figure(figsize=(10,5))\nplt.title(\"Training and Test Loss - Accuracy\")\nplt.plot(_test_losses,label=\"Test\")\nplt.plot(_train_losses,label=\"Train\")\nplt.plot(_accuracy,label=\"Acc\")\nplt.xlabel(\"Iteraciones\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","74fc18d9":"#persisto modelo sv\npath = '\/content\/drive\/My Drive\/savernet\/modelos\/chkp_modelo_sv.pt'\ntorch.save({\n            '_train_losses': _train_losses, \n            '_test_losses': _test_losses, \n            '_accuracy': _accuracy,\n            'model_ft_sv.state_dict': model_ft_sv.state_dict()\n            }, path)","f840ce5b":"visualize_model(model_ft_sv)","8fa685a3":"# Matriz de Confusi\u00f3n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ndef get_num_correct(preds, labels):\n    return preds.argmax(dim=1).eq(labels).sum().item()\n\n@torch.no_grad()\ndef get_all_preds(model, loader):\n    \n    #borrar\n    i = 0\n    print(len(loader))\n    \n    all_preds = torch.tensor([])\n    for batch in loader:\n        images, labels = batch\n\n        #borrar\n        i=i+1\n        print(i)\n\n        preds = model(images)\n        all_preds = torch.cat(\n            (all_preds, preds)\n            ,dim=0\n        )\n    return all_preds\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","91b154c9":"#Predicciones MGCD\nwith torch.no_grad():\n    prediction_loader = torch.utils.data.DataLoader(image_datasets['train'])\n    train_preds = get_all_preds(model_ft, prediction_loader)\n\n","f31443a1":"# CM MGCD\npreds_correct = get_num_correct(train_preds, torch.as_tensor(image_datasets['train'].targets))\nprint('Total Correctas:', preds_correct)\nprint('Accuracy:', preds_correct \/ len(image_datasets['train']))\n\ncm = confusion_matrix(image_datasets['train'].targets, train_preds.argmax(dim=1))\nprint(type(cm))\n#cm\n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, class_names_sv)","b241a5f7":"#Predicciones SV\nwith torch.no_grad():\n    prediction_loader = torch.utils.data.DataLoader(image_datasets_sv['train'])\n    train_preds = get_all_preds(model_ft_sv, prediction_loader)\n","3695ead9":"# CM SV\npreds_correct = get_num_correct(train_preds, torch.as_tensor(image_datasets_sv['train'].targets))\nprint('Total Correctas:', preds_correct)\nprint('Accuracy:', preds_correct \/ len(image_datasets_sv['train']))\n\ncm = confusion_matrix(image_datasets_sv['train'].targets, train_preds.argmax(dim=1))\nprint(type(cm))\n#cm\n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, class_names_sv)","950de53a":"# restaurar de persistido mdcg\n#path = '\/content\/drive\/My Drive\/savernet\/modelos\/modelo_mgcd.pt'\npath = '\/content\/drive\/My Drive\/savernet\/modelos\/chkp_modelo_mgcd.pt'\n# descomentar para ejecutar\nif torch.cuda.is_available():\n    map_location=lambda storage, loc: storage.cuda()\nelse:\n    map_location='cpu'\n\nchkp_modelo_mgcd = torch.load(path, map_location=map_location)\nmodel_ft.load_state_dict(chkp_modelo_mgcd['model_ft_state_dict'])\n_train_losses = chkp_modelo_mgcd['_train_losses']\n_test_losses = chkp_modelo_mgcd['_test_losses']\n_accuracy = chkp_modelo_mgcd['_accuracy']\n","522f1a95":"# restaurar de persistido sv\n#path = '\/content\/drive\/My Drive\/savernet\/modelos\/modelo_sv.pt'\npath = '\/content\/drive\/My Drive\/savernet\/modelos\/chkp_modelo_sv.pt'\n# descomentar para ejecutar\nif torch.cuda.is_available():\n    map_location=lambda storage, loc: storage.cuda()\nelse:\n    map_location='cpu'\n##model_ft_sv.load_state_dict(torch.load(path, map_location=map_location))\n#chkp_modelo_sv = torch.load(path)\n#model_ft_sv.load_state_dict(chkp_modelo_sv['model_ft_sv_state_dict'])\n#_train_losses = chkp_modelo_sv['_train_losses']\n#_test_losses = chkp_modelo_sv['_test_losses']\n#_accuracy = chkp_modelo_sv['_accuracy']","dce4715c":"## Datos","12835821":"Entrenar y Evaluar","7c8c60b4":"## F I N ##################################################","2af05fff":"funcion para Visualizar predicciones","78eeb8f2":"## Train","04ddb945":"####################################################","86d36c96":"####################################################"}}