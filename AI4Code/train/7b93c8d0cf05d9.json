{"cell_type":{"92c886dd":"code","67ccb3c9":"code","d4039cf0":"code","add7bc5c":"markdown"},"source":{"92c886dd":"import tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras as K\nfrom tensorflow.keras import layers as L\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom random import choices\n\nnp.random.rand()\n\ntrain = pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\ntrain.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\n\nfeatures = [c for c in train.columns if \"feature\" in c]\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\n\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T","67ccb3c9":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = L.Input(shape=(num_columns,))\n    x = L.BatchNormalization()(inp)\n    x = L.Dropout(dropout_rates)(x)\n    for i in range(3):\n        x = L.Dense(hidden_units)(x)\n        x = L.BatchNormalization()(x)\n        x = L.Activation(K.activations.swish)(x)\n        x = L.Dropout(dropout_rates)(x)\n    \n    x = L.Dense(num_labels)(x)\n    out = L.Activation(\"sigmoid\")(x)\n\n    model = K.models.Model(inputs=inp, outputs=out)\n    \n    model.summary()\n    \n    model.compile(\n        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n        loss = K.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics = K.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model\n\nepochs = 200\nbatch_size = 4096\nhidden_units = 350\ndropout_rates = 0.2\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\nK.backend.clear_session()\n\nclf = create_mlp(\n    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nclf.load_weights('.\/model.h5') #use starting from 2nd run\n\nclf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)","d4039cf0":"# save model\nclf.save(f'model.h5')\n# inference\nth = 0.503\nmodels = [clf]\nf = np.median\nimport janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred = f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","add7bc5c":"This notebook shouldnt overfit.\n\nI removed the seed.\n\n"}}