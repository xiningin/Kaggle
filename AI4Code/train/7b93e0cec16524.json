{"cell_type":{"dc21542e":"code","82c155d0":"code","4a7a5ee5":"code","48504786":"code","ef565e36":"code","6a16fda4":"code","159ba4dd":"code","35bab8d5":"code","9278b59a":"code","13dd6e56":"code","e9401437":"code","39cd3212":"code","08826527":"code","e42755c8":"code","68ea53d7":"code","5ee70117":"code","01331f06":"code","6cfc8f77":"code","38d37b1d":"code","c37ed192":"code","ce49cda5":"code","d53f6def":"code","afecd264":"code","2644406f":"code","8c5e0b3a":"code","13239a25":"code","405d6b14":"code","1997aa7a":"code","7febe178":"code","e3c1f9c5":"code","16814e0b":"code","eec72059":"code","99cf2da4":"code","ab423597":"code","fa78fdce":"code","c9107117":"code","ac7eebff":"code","95f412d0":"code","8be89012":"code","99ae0c6f":"code","0ad62aac":"code","1a83e7f8":"code","f4ed5389":"code","a5862468":"code","768e9859":"code","051f9ed1":"code","8ee1b4a7":"code","fc637502":"markdown","cd3c0b4e":"markdown","3dc7c575":"markdown","7ecd2046":"markdown","a6c6d36c":"markdown","b46704d9":"markdown"},"source":{"dc21542e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","82c155d0":"from scipy import stats\nimport squarify as sq\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nimport seaborn as sns\nimport sklearn\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score, KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB,BernoulliNB\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n%matplotlib inline","4a7a5ee5":"filename='\/kaggle\/input\/top50spotify2019\/top50.csv'\ndf=pd.read_csv(filename,encoding='ISO-8859-1')\ndf.head()","48504786":"print(df.shape)","ef565e36":"#Renaming the columns\ndf.rename(columns={'Track.Name':'track_name','Artist.Name':'artist_name','Beats.Per.Minute':'beats_per_minute','Loudness..dB..':'Loudness(dB)','Valence.':'Valence','Length.':'Length', 'Acousticness..':'Acousticness','Speechiness.':'Speechiness'},inplace=True)\ndf.head()","6a16fda4":"df.isnull().sum()\ndf.fillna(0)","159ba4dd":"# The datatypes of the different attributes of the dataset\nprint(df.dtypes)","35bab8d5":"#Calculating the number of songs of each genre\nprint(type(df['Genre']))\npopular_genre=df.groupby('Genre').size()\nprint(popular_genre)\ngenre_list=df['Genre'].values.tolist()","9278b59a":"#Calculating the number of songs by each of the artists\nprint(df.groupby('artist_name').size())\npopular_artist=df.groupby('artist_name').size()\nprint(popular_artist)\nartist_list=df['artist_name'].values.tolist()","13dd6e56":"df.isnull().sum()\ndf.fillna(0)","e9401437":"pd.set_option('precision', 3)\ndf.describe()","39cd3212":"#Finding out the skew for each attribute\nskew=df.skew()\nprint(skew)\n# Removing the skew by using the boxcox transformations\ntransform=np.asarray(df[['Liveness']].values)\ndf_transform = stats.boxcox(transform)[0]\n# Plotting a histogram to show the difference \nplt.hist(df['Liveness'],bins=10) #original data\nplt.show()\nplt.hist(df_transform,bins=10) #corrected skew data\nplt.show()","08826527":"transform1=np.asarray(df[['Popularity']].values)\ndf_transform1 = stats.boxcox(transform1)[0]\n# Plotting a histogram to show the difference \n# plt.hist(df['Popularity'],bins=10) original data\n# plt.show()\n# plt.hist(df_transform1,bins=10) #corrected skew data\n# plt.show()\nsns.distplot(df['Popularity'],bins=10,kde=True,kde_kws={\"color\": \"k\", \"lw\": 2, \"label\": \"KDE\"},color='yellow')\nplt.show()\nsns.distplot(df_transform1,bins=10,kde=True,kde_kws={\"color\": \"k\", \"lw\": 2, \"label\": \"KDE\"},color='black') #corrected skew data\nplt.show()","e42755c8":"pd.set_option('display.width', 100)\npd.set_option('precision', 3)\ncorrelation=df.corr(method='spearman')\nprint(correlation)","68ea53d7":"# Bar graph to see the number of songs of each genre\nfig, ax=plt.subplots(figsize=(30,12))\nlength=np.arange(len(popular_genre))\nplt.bar(length,popular_genre,color='green',edgecolor='black',alpha=0.7)\nplt.xticks(length,genre_list)\nplt.title('Most popular genre',fontsize=18)\nplt.xlabel('Genre',fontsize=16)\nplt.ylabel('Number of songs',fontsize=16)\nplt.show()","5ee70117":"# heatmap of the correlation \nplt.figure(figsize=(10,10))\nplt.title('Correlation heatmap')\nsns.heatmap(correlation,annot=True,vmin=-1,vmax=1,cmap=\"GnBu_r\",center=1)","01331f06":"fig, ax=plt.subplots(figsize=(12,12))\nlength=np.arange(len(popular_artist))\nplt.barh(length,popular_artist,color='red',edgecolor='black',alpha=0.7)\nplt.yticks(length,artist_list)\nplt.title('Most popular artists',fontsize=18)\nplt.ylabel('Artists',fontsize=16)\nplt.xlabel('Number of songs',fontsize=16)\nplt.show()","6cfc8f77":"# Analysing the relationship between energy and loudness\nfig=plt.subplots(figsize=(10,10))\nsns.regplot(x='Energy',y='Loudness(dB)',data=df,color='black')","38d37b1d":"fig=plt.subplots(figsize=(10,10))\nplt.title('Dependence between energy and popularity')\nsns.regplot(x='Energy', y='Popularity',\n            ci=None, data=df)\nsns.kdeplot(df.Energy,df.Popularity)","c37ed192":"scatter_matrix(df)\nplt.gcf().set_size_inches(30, 30)\nplt.show()","ce49cda5":"df.plot(kind='box', subplots=True)\nplt.gcf().set_size_inches(30,30)\nplt.show()","d53f6def":"plt.figure(figsize=(14,8))\nsq.plot(sizes=df.Genre.value_counts(), label=df[\"Genre\"].unique(), alpha=.8 )\nplt.axis('off')\nplt.show()","afecd264":"#Pie charts \nlabels = df.artist_name.value_counts().index\nsizes = df.artist_name.value_counts().values\ncolors = ['red', 'yellowgreen', 'lightcoral', 'lightskyblue','cyan', 'green', 'black','yellow']\nplt.figure(figsize = (10,10))\nplt.pie(sizes, labels=labels, colors=colors)\nautopct=('%1.1f%%')\nplt.axis('equal')\nplt.show()","2644406f":"#Linear regression, first create test and train dataset\nx=df.loc[:,['Energy','Danceability','Length','Loudness(dB)','Acousticness']].values\ny=df.loc[:,'Popularity'].values","8c5e0b3a":"# Creating a test and training dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30)","13239a25":"# Linear regression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\nprint(regressor.intercept_)\nprint(regressor.coef_)","405d6b14":"#Displaying the difference between the actual and the predicted\ny_pred = regressor.predict(X_test)\ndf_output = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(df_output)","1997aa7a":"#Checking the accuracy of Linear Regression\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","7febe178":"plt.figure(figsize=(10,10))\nplt.plot(y_pred,y_test,color='black',linestyle='dashed',marker='*',markerfacecolor='red',markersize=10)\nplt.title('Error analysis')\nplt.xlabel('Predicted values')\nplt.ylabel('Test values')","e3c1f9c5":"# Cross validation score\nx=df.loc[:,['Energy','Danceability']].values\ny=df.loc[:,'Popularity'].values\nregressor=LinearRegression()\nmse=cross_val_score(regressor,X_train,y_train,scoring='neg_mean_squared_error',cv=5)\nmse_mean=np.mean(mse)\nprint(mse_mean)\ndiff=metrics.mean_squared_error(y_test, y_pred)-abs(mse_mean)\nprint(diff)","16814e0b":"x=df.loc[:,['artist_name']].values\ny=df.loc[:,'Genre'].values","eec72059":"# Label encoding of features\nx.shape\nencoder=LabelEncoder()\nx = encoder.fit_transform(x)\nx=pd.DataFrame(x)\nx","99cf2da4":"# Label Encoding of target\nEncoder_y=LabelEncoder()\nY = Encoder_y.fit_transform(y)\nY=pd.DataFrame(Y)\nY","ab423597":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n\n#Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(x_train)\nx_train=sc.transform(x_train)\nx_test=sc.transform(x_test)","fa78fdce":"# KNN Classification\n# sorted(sklearn.neighbors.VALID_METRICS['brute'])\nknn = KNeighborsClassifier(n_neighbors = 17)\nknn.fit(x_train,y_train)\ny_pred=knn.predict(x_test)","c9107117":"error=[]\nfor i in range(1,30):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i=knn.predict(X_test)\n    error.append(np.mean(pred_i!=y_test))","ac7eebff":"plt.figure(figsize=(10,10))\nplt.plot(range(1,30),error,color='black',marker='o',markerfacecolor='cyan',markersize=10)\nplt.title('Error Rate K value')\nplt.xlabel('K Value')\nplt.ylabel('Mean error')","95f412d0":"x=df.loc[:,['Energy','Length','Danceability','beats_per_minute', 'Acousticness']].values\ny=df.loc[:,'Popularity'].values","8be89012":"# Creating a test and training dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30)","99ae0c6f":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred=gnb.predict(X_test)\ndf_output = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(df_output)","0ad62aac":"# Testing the accuracy of Naive Bayes \nscores=cross_val_score(gnb,X_train,y_train,scoring='accuracy',cv=3).mean()*100\nprint(scores)","1a83e7f8":"sns.jointplot(x=y_test, y=y_pred, kind=\"kde\", color=\"r\")","f4ed5389":"x=df.loc[:,['Energy','Length','Danceability','beats_per_minute', 'Acousticness']].values\ny=df.loc[:,'Popularity'].values","a5862468":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30)","768e9859":"# Linear SVM model \nLinSVC = LinearSVC(penalty='l2', loss='squared_hinge', dual=True)\nLinSVC.fit(X_train, y_train)\ny_pred=gnb.predict(X_test)\ndf_output = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(df_output)","051f9ed1":"# Testing the accuracy\nscores=cross_val_score(LinSVC,X_train,y_train,scoring='accuracy',cv=3).mean()*100\nprint(scores)","8ee1b4a7":"sns.jointplot(x=y_test, y=y_pred, kind=\"reg\", color=\"b\");","fc637502":"Firstly we have to import the libraries","cd3c0b4e":"I think we should check the null values and correct that, because that is the only thing which creates trouble.","3dc7c575":"Now let us check some visualisations on the dataset.","7ecd2046":"Let us check the number of rows and columns","a6c6d36c":"Now let us load our dataset","b46704d9":"We have done many visualisations, Now its time to develop some machine learning models on our dataset so to predict the trend. "}}