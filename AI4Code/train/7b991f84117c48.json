{"cell_type":{"203df0a5":"code","5d44d8d0":"code","88d75a23":"code","e72e980b":"code","28d8d662":"code","19f96266":"code","ef6f7669":"code","9868db27":"code","fd8edd71":"code","f8db7d56":"code","b53e0165":"code","5ec54fbc":"code","dc012da8":"code","d9c20cb1":"code","1b82833e":"code","74b30dec":"code","edfbcd65":"code","17c287f2":"code","9dd68fd8":"code","55972cce":"code","55e01225":"code","e048e27b":"code","9a93a330":"code","5b711f15":"code","81603eee":"code","bae0c977":"code","dcfeade7":"markdown","e9835256":"markdown","43167f88":"markdown","fc04a499":"markdown","eac20044":"markdown","56cd4838":"markdown","9328bbe5":"markdown","22c2fafa":"markdown","96bb7e45":"markdown","800a1b3e":"markdown","708e4b52":"markdown","c5538a84":"markdown","5d501365":"markdown","96789d8b":"markdown","ff58bccc":"markdown","29efdb29":"markdown"},"source":{"203df0a5":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport math, datetime\n\nimport numpy as np \nimport pandas as pd\npd.set_option('display.max_columns', None)\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import(mean_squared_error)","5d44d8d0":"train = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nitems = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nitem_categories = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nshops = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")","88d75a23":"train.tail(3)","e72e980b":"test.head(3)","28d8d662":"print('train shape',train.shape)\nprint('test shape',test.shape)\nprint('duplicated rows',train.duplicated().sum())\nprint('number of columns with missing values',train.isnull().any().sum())\nprint('number of columns with missing values',test.isnull().any().sum())","19f96266":"# Missing Values\nimport seaborn as sns\nplt.figure(figsize=(10,5))\nsns.heatmap(data=train.isnull(),cmap=\"viridis\")\nplt.show()","ef6f7669":"# Convert date values to datetime\ntrain['date'] = pd.to_datetime(train['date'])","9868db27":"# Convert a datetime column to a string one\ntrain['year_month'] = train['date'].apply(lambda x: x.strftime('%Y-%m')) ","fd8edd71":"# Drop unnecessary features\ntrain = train.drop(['date','item_price'], axis=1)\ntrain.head(3)","f8db7d56":"# group features to get the number of products sold per month. You are predicting a monthly amount of this measure\ntrain_group = train.groupby(['year_month', 'shop_id', 'item_id']).sum().reset_index()\ntrain_group.head()","b53e0165":"df = train_group.pivot_table(index=['shop_id','item_id'], columns='year_month', values='item_cnt_day', \n                        fill_value=0)\ndf.reset_index(inplace=True)\ndf.head()","5ec54fbc":"df_test = pd.merge(test, df, on=['shop_id','item_id'], how='left')\ndf_test.drop(['ID', '2013-01'], axis=1, inplace=True)\ndf_test = df_test.fillna(0)\ndf_test.head()","dc012da8":"X = df[df.columns[:-1]]\ny = df[df.columns[-1]]\nprint(X.shape)\nprint(y.shape)","d9c20cb1":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2, random_state=15)\nprint(X_train.shape)\nprint(X_test.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)","1b82833e":"def evaluate_model(model):\n    RMSE_train = mean_squared_error(y_train, model.predict(X_train))\n    RMSE_test = mean_squared_error(y_test, model.predict(X_test))\n    \n    print('Train set mse:', RMSE_train)\n    print('Test set mse:', RMSE_test)\n    print('Test set score:', model.score(X_train,y_train))\n    \n    return RMSE_train, RMSE_test","74b30dec":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression().fit(X_train, y_train)","edfbcd65":"RMSE_train_log, RMSE_test_log = evaluate_model(log)","17c287f2":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100)\nrf.fit(X_train,y_train)","9dd68fd8":"RMSE_train_rf, RMSE_test_rf = evaluate_model(rf)","55972cce":"from sklearn.linear_model import SGDClassifier\nsgdc = SGDClassifier().fit(X_train, y_train)","55e01225":"RMSE_train_sgdc, RMSE_test_sgdc = evaluate_model(sgdc)","e048e27b":"df_models_acc = pd.DataFrame({\n    'Model': ['log', 'rf', 'svr'],\n    'RMSE_Train': [RMSE_train_log, RMSE_train_rf, RMSE_train_sgdc],\n    'RMSE_Test': [RMSE_test_log, RMSE_test_rf, RMSE_test_sgdc],\n})\ndf_models_acc.sort_values(by='RMSE_Test')","9a93a330":"submission = sample_submission.drop('item_cnt_month', axis=1)\n\n# RandomForestRegressor\nprediction = rf.predict(df_test)\nprediction = list(map(round, prediction))\nsubmission['item_cnt_month'] = prediction\nsubmission.head()","5b711f15":"# Are our test and submission dataframes the same length?\nif len(submission) == len(sample_submission):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","81603eee":"# Convert submisison dataframe to csv for submission to csv for Kaggle submisison\nsubmission.to_csv('Predict_Future_Sales_Submission.csv', index=False)\nprint('Submission CSV is ready!')","bae0c977":"# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"Predict_Future_Sales_Submission.csv\")\nsubmissions_check.head()","dcfeade7":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.2 Random Forest\n    <\/h4>\n<\/div>","e9835256":"<a id='1'><\/a>\n<div class=\"alert alert-block alert-danger\">\n<h2>1 Importing packages<\/h2>\n<\/div>","43167f88":"<a id='5'><\/a>\n<div class=\"alert alert-block alert-danger\">\n    <h2>\n        5. Submission\n    <\/h2>\n<\/div>","fc04a499":"<a id='41'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.1 Separate the dataset into train and test\n   <\/h3>\n<\/div>","eac20044":"<a id='2'><\/a>\n## 2.Read CSV files into DataFrame","56cd4838":"## Index\n\n[1.Importing packages](#1)<br>\n[2.Read CSV files into DataFrame](#2)<br>\n[3.Data Preprocessing](#3)<br>\n[4.Regressions and Results](#4)<br>\n    <ul>\n        <li>[4.1. Separate the dataset into train and test ](#41)<\/li>\n        <li>[4.2. Running Machine Learning Models](#42)<\/li>\n    <\/ul>\n[5.Submission](#5)<br>\n[6.References](#6)","9328bbe5":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.3 Stochastic Gradient Descent\n    <\/h4>\n<\/div>","22c2fafa":"<a id='3'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    3 Data Preprocessing\n    <\/h2>\n<\/div>","96bb7e45":"Since RandomForestRegressor gets the best results, it will be used for the submission.","800a1b3e":"<a id='42'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.2 Running Machine Learning Models\n   <\/h3>\n<\/div>","708e4b52":"https:\/\/www.kaggle.com\/yasserhessein\/predict-future-sales-using-4-algorithms-regression<br>","c5538a84":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.1 Logistic\n    <\/h4>\n<\/div>","5d501365":"<a id='6'><\/a>\n## 6. References","96789d8b":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.4 Model_Selection - Final\n    <\/h4>\n<\/div>","ff58bccc":"You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.<br>\n\n\n<h3>File descriptions<\/h3>\n    <ul>\n        <li>sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.<\/li>\n        <li>test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.<\/li>\n        <li>sample_submission.csv - a sample submission file in the correct format.<\/li>\n        <li>items.csv - supplemental information about the items\/products.<\/li>\n        <li>item_categories.csv  - supplemental information about the items categories.<\/li>\n        <li>shops.csv- supplemental information about the shops.<\/li>\n    <\/ul>\n            \n<h3>Data fields<\/h3>\n    <ul>\n        <li>ID - an Id that represents a (Shop, Item) tuple within the test set<\/li>\n        <li>shop_id - unique identifier of a shop<\/li>\n        <li>item_id - unique identifier of a product<\/li>\n        <li>item_category_id - unique identifier of item category<\/li>\n        <li>item_cnt_day - number of products sold. You are predicting a monthly amount of this measure<\/li>\n        <li>item_price - current price of an item<\/li>\n    <li>date - date in format dd\/mm\/yyyy<\/li>\n    <li>date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33<\/li>\n    <li>item_name - name of item<\/li>\n    <li>shop_name - name of shop<\/li>\n    <li>item_category_name - name of item category<\/li>\n    <li>This dataset is permitted to be used for any purpose, including commercial use.<\/li>\n    <\/ul>","29efdb29":"<a id='4'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    4. Regressions and Results\n    <\/h2>\n<\/div>"}}