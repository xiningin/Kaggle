{"cell_type":{"630f5efc":"code","b9e1ff2b":"code","dbdc135c":"code","6352df60":"code","0058420f":"code","0856327a":"code","25bd8c37":"code","24cf1dd9":"code","e8cace61":"code","aca27be8":"code","e41c4ebc":"code","67ad777d":"code","08a5c700":"code","e04b7f7f":"code","78ce58e2":"code","551d7d40":"code","6d14c3e2":"code","88e9081f":"code","493e4dac":"code","161b2fc5":"code","129caf87":"code","08776d3d":"markdown"},"source":{"630f5efc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","b9e1ff2b":"# Keras stuff\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras import backend as k_backend","dbdc135c":"file_path = '\/kaggle\/input\/digit-recognizer\/'","6352df60":"# load traing and test sets\ntrain = pd.read_csv(file_path + 'train.csv')\ntest = pd.read_csv(file_path + 'test.csv')","0058420f":"# separate the labels column from the training set\nY_train = train[['label']]\nX_train = train.drop(train.columns[[0]], axis=1)\nX_test = test","0856327a":"# have a glance on the data\nsample = X_train.iloc[0, :]\nsample = sample.values.reshape([28, 28])\nplt.imshow(sample, cmap='gray')\nprint('This is: ' + str(Y_train.iloc[1000, 0]))","25bd8c37":"X_train = np.array(X_train)\nX_test = np.array(X_test)","24cf1dd9":"# reshape the images in the train and test sets to thier original sizes\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","e8cace61":"# the original LeNet-5 describes a 32*32 input images. So let's pad ours\nX_train = np.pad(X_train, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')\nX_test = np.pad(X_test, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')","aca27be8":"# standardize the training set to keep weights under control during optimization\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\nX_train = (X_train - mean_px) \/ std_px","e41c4ebc":"# One-hot-encode the training set labels\nY_train = to_categorical(Y_train)","67ad777d":"# create the input layer\nX_input = Input(shape=(32, 32, 1))","08a5c700":"# the first block of layers: conv1 + maxpool1\nconv1 = Conv2D(filters=6, kernel_size=5, strides=(1, 1), activation='relu')(X_input)\nmax_pool1 = MaxPooling2D(pool_size=2, strides=2)(conv1)","e04b7f7f":"# the second block of layers: conv2 + maxpool2\nconv2 = Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu')(max_pool1)\nmax_pool2 = MaxPooling2D(pool_size=2, strides=2)(conv2)","78ce58e2":"# flatten the input, then apply two standard fully connected layers\nflat = Flatten()(max_pool2)\ndense1 = Dense(units=120, activation='relu')(flat)\ndense2 = Dense(units=84, activation='relu')(dense1)","551d7d40":"# the output layers\nout_enc = Dense(units=10, activation='softmax')(dense2)","6d14c3e2":"# create and compile the model\ndigit_recognizer = Model(inputs=X_input, outputs=out_enc)\ndigit_recognizer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","88e9081f":"# train and save the model\ndigit_recognizer.fit(X_train, Y_train, epochs=42, steps_per_epoch=31)\ndigit_recognizer.save('digit_recognizer_model_lenet5.h5')","493e4dac":"# use the trained model to predict the labels of the test set\ny_pred = digit_recognizer.predict(X_test)","161b2fc5":"# decode the labels and concatenate with image IDs\nlabels = np.argmax(y_pred, axis=1)\nlabels = labels.reshape([len(labels), 1])\nindex = np.arange(1, len(y_pred) + 1)\nindex = index.reshape([len(index), 1])\noutput = np.concatenate([index, labels], axis=1)","129caf87":"# write predictions to the disk. Cheers!\nnp.savetxt('digit_recognizer_predictions.csv', output, delimiter=',', fmt=\"%s\", header='ImageId,Label', comments='')","08776d3d":"Hand-written digit recognizer using LeNet-5 Convolutional Neural Network achitecture.\n\nThe training set is the MNIST dataset."}}