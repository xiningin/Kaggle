{"cell_type":{"bb008d81":"code","b65416d2":"code","1b66d0a7":"code","11ea4302":"code","ba38feab":"code","6d97f5cd":"code","4262fe12":"code","7573c049":"code","e342fa1f":"code","e102756a":"code","503c372c":"code","915f5f7b":"code","22f4431d":"code","90460090":"code","47dc7279":"code","b28c4005":"code","d247a0d1":"code","d6266410":"code","b7c067fa":"code","20f01937":"code","8eeba37c":"code","757cd843":"markdown","261bef08":"markdown"},"source":{"bb008d81":"# Import the required packages\nimport os\nimport numpy as np \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pathlib\nimport librosa.display\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport librosa","b65416d2":"# Get the data directories\ndata_dir = \"..\/input\/speaker-recognition-dataset\/16000_pcm_speeches\/\"\nos.listdir(data_dir)","1b66d0a7":"# get wav paths\ndef get_wav_paths(speaker):\n    speaker_path = data_dir + speaker\n    all_paths = [item for item in os.listdir(speaker_path)]\n    return all_paths","11ea4302":"nelson_mandela_paths = get_wav_paths(\"Nelson_Mandela\")\nmargaret_thatcher_paths = get_wav_paths(\"Magaret_Tarcher\")\nbenjamin_netanyau_paths = get_wav_paths(\"Benjamin_Netanyau\")\njens_stoltenberg_paths = get_wav_paths( 'Jens_Stoltenberg')\njulia_gillard_paths = get_wav_paths(\"Julia_Gillard\")\n\nnoise1_paths = get_wav_paths(\"_background_noise_\")\nnoise2_paths = get_wav_paths(\"other\")","ba38feab":"# load the data\ndef load_wav(wav_path, speaker):\n    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n        wav_path = data_dir + speaker + \"\/\" + wav_path\n        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n        wav_loader = tf.io.read_file(wav_filename_placeholder)\n        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n        wav_data = sess.run(\n            wav_decoder, feed_dict={\n                wav_filename_placeholder: wav_path\n            }).audio.flatten().reshape((1, 16000))\n        sess.close()\n    return wav_data","6d97f5cd":"# create training data\ndef generate_training_data(speaker_paths, speaker, label):\n    wavs, labels = [], []\n    for i in tqdm(speaker_paths):\n        wav = load_wav(i, speaker)\n        wavs.append(wav)\n        labels.append(label)\n    return wavs, labels\n","4262fe12":"nelson_mandela_wavs, nelson_mandela_labels = generate_training_data(nelson_mandela_paths, \"Nelson_Mandela\", 0) \nmargaret_thatcher_wavs, margaret_thatcher_labels = generate_training_data(margaret_thatcher_paths, \"Magaret_Tarcher\", 1) \nbenjamin_netanyau_wavs, benjamin_netanyau_labels = generate_training_data(benjamin_netanyau_paths, \"Benjamin_Netanyau\", 2) \njens_stoltenberg_wavs, jens_stoltenberg_labels = generate_training_data(jens_stoltenberg_paths, \"Jens_Stoltenberg\", 3) \njulia_gillard_wavs, julia_gillard_labels = generate_training_data(julia_gillard_paths, \"Julia_Gillard\", 4) ","7573c049":"# remove the extra wav for Julia Gillard\njulia_gillard_labels = julia_gillard_labels[1:]\njulia_gillard_wavs = julia_gillard_wavs[1:]","e342fa1f":"all_wavs = nelson_mandela_wavs + margaret_thatcher_wavs + benjamin_netanyau_wavs + jens_stoltenberg_wavs + julia_gillard_wavs\nall_labels = nelson_mandela_labels + margaret_thatcher_labels + benjamin_netanyau_labels + jens_stoltenberg_labels + julia_gillard_labels","e102756a":"from scipy.io.wavfile import read\nfrom scipy.io.wavfile import write\nfrom random import randint\n\ndef cut_random_section(noise2, size2):\n    size21 = noise2.size\n    starting_point2 = randint(0,(noise2.size - size2))\n    end_point2 = starting_point2 + size2\n    noise_cut_part2 = noise2[starting_point2:end_point2]\n    return noise_cut_part2\n\ndef mix(audio1, noise1, snr1):\n    audio_max = max(audio1)\n    if audio_max==0:\n        audio_max = int(np.random.uniform(0.7,1)*32767)\n    audio1 = audio1*1.\n    audio1 = audio1\/audio_max\n    noise1 = cut_random_section(noise1, audio1.size)\n    noise1 = noise1*1.\n    noise1 = noise1\/max(noise1)\n    gain = pow(10,(snr1\/10.))\n    numerator = np.mean(abs(audio1)**2)\n    denominator = numerator\/gain\n    noise_power = np.mean(abs(noise1)**2)\n    mult_value = (denominator\/noise_power)**0.5\n    noisy1 = audio1 + noise1*mult_value\n    if max(audio1)==0:\n        noisy1 = noise1\n    else:    \n        noisy1 = noisy1\/max(noisy1)\n    noisy1 = np.array(noisy1*audio_max, dtype='int16')\n    return noise1*mult_value, mult_value, noisy1\n\nnoise_wavs = []\nnoise_labels = []\nsnr_dB = 10\nfor i in range(len(all_wavs)):\n    for noise in os.listdir(data_dir + 'other'):\n        fs, noise_file = read(data_dir + 'other\/' + noise)\n        x = all_wavs[i][0]\n        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n        if noisy.any() != 0:\n            noise_wavs.append(noisy)\n            noise_labels.append(all_labels[i])\n    for noise in os.listdir(data_dir + '_background_noise_'):\n        fs, noise_file = read(data_dir + '_background_noise_\/' + noise)\n        x = all_wavs[i][0]\n        if len(noise_file.shape) > 1:\n            noise_file = np.reshape(noise_file, (noise_file.shape[0]*noise_file.shape[1]))\n        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n        if noisy.any() != 0:\n            noise_wavs.append(noisy)\n            noise_labels.append(all_labels[i]) \n    if i%200 == 0:\n        print(i)","503c372c":"for i in range(len(all_wavs)):\n    noise_labels.append(all_labels[i])\n    noise_wavs.append(all_wavs[i][0])\nfinal_wavs = np.array(noise_wavs)\nfinal_labels = np.array(noise_labels)\n\nprint(final_wavs.shape, final_labels.shape)","915f5f7b":"# split the dataset into trainin and testing set\\\ntrain_wavs, test_wavs, train_labels, test_labels = train_test_split(final_wavs, final_labels, test_size=0.1)","22f4431d":"train_x, train_y = np.array(train_wavs), np.array(train_labels)\ntest_x, test_y = np.array(test_wavs), np.array(test_labels)","90460090":"train_y = tf.keras.utils.to_categorical(train_y)\ntest_y = tf.keras.utils.to_categorical(test_y)","47dc7279":"# import csv\n# with open('train_x.csv', 'wt') as f:\n#     csv_writer = csv.writer(f, quoting=csv.QUOTE_NONE)\n#     csv_writer.writerows(train_x)\n# with open('test_x.csv', 'wt') as f:\n#     csv_writer = csv.writer(f, quoting=csv.QUOTE_NONE)\n#     csv_writer.writerows(test_x)\n# with open('train_y.csv', 'wt') as f:\n#     csv_writer = csv.writer(f, quoting=csv.QUOTE_NONE)\n#     csv_writer.writerows(train_y)\n# with open('test_y.csv', 'wt') as f:\n#     csv_writer = csv.writer(f, quoting=csv.QUOTE_NONE)\n#     csv_writer.writerows(test_y)","b28c4005":"# MFCC Feature Extraction\n\ntrain_x_new = []\ntest_x_new = []\nINPUT_SHAPE = (126,40)\n\ntrain_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n\ncount = 0\nfor sample in train_x:\n    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n    train_x_new[count, :, :20] = mfcc.T\n    train_x_new[count, :, 20:30] = mfcc_delta.T\n    train_x_new[count, :, 30:] = mfcc_double_delta.T\n    count += 1\n    if count%500 == 0:\n        print('Train', count)\n        \ntest_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n\ncount = 0\nfor sample in test_x:\n    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n    test_x_new[count, :, :20] = mfcc.T\n    test_x_new[count, :, 20:30] = mfcc_delta.T\n    test_x_new[count, :, 30:] = mfcc_double_delta.T\n    count += 1\n    if count%500 == 0:\n        print('Test', count)","d247a0d1":"train_x_new = np.expand_dims(train_x_new, axis=3)\ntest_x_new = np.expand_dims(test_x_new, axis=3)\nprint(train_x_new.shape, test_x_new.shape)","d6266410":"# create a model\ndef create_model(speech_feature):\n    model = tf.keras.Sequential()\n    if speech_feature == \"spectrogram\":\n        model.add(Spectrogram(n_dft=512, n_hop=256, input_shape=(1, 16000),\n                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n                            trainable_kernel=False, name='static_stft'))\n    elif speech_feature == \"melspectrogram\":\n        model.add(Melspectrogram(sr=16000, n_mels=128,n_dft=512, n_hop=256,\n                            input_shape=(1 , 16000),return_decibel_melgram=True,\n                            trainable_kernel=False, name='melgram'))\n        \n    elif speech_feature == \"mfcc\":\n        model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", input_shape=(126,40,1)))\n        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n#         model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n\n        model.add(tf.keras.layers.Flatten())        \n        model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n                , loss = \"categorical_crossentropy\"\n                , metrics = [\"accuracy\"])\n        return model\n\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(5, activation=\"softmax\"))\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n            , loss = \"categorical_crossentropy\"\n            , metrics = [\"accuracy\"])\n    return model","b7c067fa":"# mfcc model\nmodel3 = create_model(\"mfcc\")\nmodel3.summary()","20f01937":"model3.fit(x=train_x_new, y=train_y, epochs=5, validation_data=(test_x_new, test_y))","8eeba37c":"model3.save('speaker_ver1a_model.h5')","757cd843":"# Create a simple model","261bef08":"# Process training dataset"}}