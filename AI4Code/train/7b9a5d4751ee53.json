{"cell_type":{"791c7b9a":"code","1d5edb38":"code","ed644068":"code","20c27022":"code","5f15fe70":"code","5fa32e62":"code","d470ccbb":"code","b85b0138":"code","1a560812":"code","6869d6e0":"code","9fc0e1b0":"code","e9836138":"code","040b8284":"code","5156ab8d":"code","a28d77fe":"code","ab6dbd2b":"code","a2220768":"code","2d1c92a9":"code","7b250153":"code","727bcdc4":"code","c9cb6d91":"code","dfc2f1af":"code","16248ca4":"markdown","1dccc47c":"markdown","2101db50":"markdown","b14e4edd":"markdown","eb2bb3cc":"markdown","2fec5b49":"markdown","9ce5e8db":"markdown","d3caf0a3":"markdown","53fbb809":"markdown","6bb3ad69":"markdown","fc0446a9":"markdown","3766b364":"markdown","033e9a94":"markdown","cb8391f8":"markdown"},"source":{"791c7b9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d5edb38":"import copy\nimport time\nimport torch\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport matplotlib.pyplot as plt","ed644068":"batch_size = 16\ninput_img_size = 28\nvalidation_size = 0.1\nNum_out_features = 10\nmax_epochs = 20\nlearning_rate = 0.005","20c27022":"train_csv = '\/kaggle\/input\/digit-recognizer\/train.csv'\ntest_csv = '\/kaggle\/input\/digit-recognizer\/test.csv'","5f15fe70":"train_val_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\ntrain_val_label_df = train_val_df['label']\ntrain_val_data_df = train_val_df.drop(['label'], axis = 1)\n\ntrain_val_data = train_val_data_df.to_numpy()\ntrain_val_label = train_val_label_df.to_numpy()\nX_test = test_df.to_numpy()\n\nX_train, X_val, y_train, y_val = train_test_split(train_val_data, train_val_label, \n                                                test_size=validation_size, random_state=42)\n\nprint('shape of X_train:', X_train.shape)\nprint('shape of y_train:', y_train.shape)\nprint('shape of X_val:', X_val.shape)\nprint('shape of y_val:', y_val.shape)\nprint('shape of X_test:', X_test.shape)","5fa32e62":"figure = plt.figure(figsize=(10,10))\ncols, rows = 4, 4\nfor i in range(1, cols * rows + 1):\n    img = X_train[i]\n    lbl = y_train[i]\n    figure.add_subplot(rows, cols, i)\n    plt.title(str(lbl))\n    plt.axis(\"off\")\n    plt.imshow(img.reshape(28,28), 'gray')\nplt.show()","d470ccbb":"class DigitDataset(Dataset):\n    def __init__(self, data_array, label_array):\n        self.data_array = data_array\n        self.label_array = label_array\n    def __len__(self):\n        return len(self.data_array)\n\n    def __getitem__(self, idx):\n        image = self.data_array[idx]\n        image = image.reshape(28,28)\n        image = image\/255.\n        #PIL_image = Image.fromarray(image.astype('uint8'))\n        label = self.label_array[idx]\n        label = torch.tensor(label)\n        transform = transforms.Compose([\n#                                         transforms.Resize(32),\n#                                         transforms.RandomCrop(28),\n#                                         transforms.RandomHorizontalFlip(),\n#                                         transforms.RandomVerticalFlip(),\n                                        transforms.ToTensor()])\n        image = transform(image)\n        return (image, label)","b85b0138":"Xy_train_obj = DigitDataset(X_train, y_train)\nXy_val_obj = DigitDataset(X_val, y_val)\n\ntrain_dataloader = DataLoader(Xy_train_obj, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(Xy_val_obj, batch_size=batch_size, shuffle=True)\n\ndataloaders, dataset_sizes = dict(), dict()\n\ndataloaders['train'] = train_dataloader\ndataloaders['val'] = val_dataloader\ndataset_sizes['train'] = len(train_dataloader.dataset)\ndataset_sizes['val'] = len(val_dataloader.dataset)\n","1a560812":"def trainer(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    history = {'train': {'acc': [], 'loss':[]}, 'val':{'acc': [], 'loss':[]}}\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device, dtype=torch.float)\n                labels = labels.to(device, dtype=torch.float)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels.long())\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            \n            history[phase]['loss'].append(epoch_loss)\n            history[phase]['acc'].append(epoch_acc)\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, history","6869d6e0":"model = models.resnet18(pretrained=True)\nmodel.conv1 = nn.Conv2d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, Num_out_features)","9fc0e1b0":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","e9836138":"trained_model, history = trainer(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=max_epochs)","040b8284":"train_loss, val_loss = history['train']['loss'], history['val']['loss']\ntrain_acc, val_acc = history['train']['acc'], history['val']['acc']\nx_values = np.linspace(0,max_epochs, max_epochs)","5156ab8d":"plt.plot(x_values, train_loss)\nplt.plot(x_values, val_loss)\nplt.legend()\nplt.title('Loss')\nplt.show()","a28d77fe":"plt.plot(x_values, train_acc)\nplt.plot(x_values, val_acc)\nplt.legend()\nplt.title('Accuracy')\nplt.show()","ab6dbd2b":"y_pred = []\ntrained_model = trained_model.to(device)\nfor image in X_val:\n    image = image.reshape(28,28)\n    image = image\/255.\n    transform = transforms.Compose([transforms.ToTensor()])\n    img = transform(image).unsqueeze(0)\n    img = img.to(device, dtype=torch.float)\n    pred = trained_model(img)\n    _, pred = torch.max(pred, 1)\n    y_pred.append(pred.item())","a2220768":"validation_accuracy = round(accuracy_score(y_val, y_pred), 3)\nactual_lbls = precision_recall_fscore_support(y_val, y_pred)[3]\ncon_mat = confusion_matrix(y_val, y_pred)\npreds_lbls = con_mat.diagonal()","2d1c92a9":"print('Validation accuracy:',validation_accuracy)\nprint('Digitwise accuracy:')\nfor i in range(0,Num_out_features):\n    act_i, pred_i = actual_lbls[i], preds_lbls[i]\n    accuracy_of_digit = round(pred_i\/act_i, 3)\n    print('{} accuracy:{} [{}\/{}]'.format(i, accuracy_of_digit, pred_i, act_i) )","7b250153":"disp = ConfusionMatrixDisplay(confusion_matrix=con_mat)\nfig, ax = plt.subplots(figsize=(12,12))\ndisp.plot(ax = ax) ","727bcdc4":"y_test = []\nfor image in X_test:\n    image = image.reshape(28,28)\n    image = image\/255.\n    transform = transforms.Compose([transforms.ToTensor()])\n    img = transform(image).unsqueeze(0)\n    img = img.to(device, dtype=torch.float)\n    pred = trained_model(img)\n    _, pred = torch.max(pred, 1)\n    y_test.append(pred.item()) ","c9cb6d91":"figure = plt.figure(figsize=(15,15))\ncols, rows = 8,8\nfor i in range(1, cols * rows + 1):\n    img = X_test[i]\n    lbl = y_test[i]\n    figure.add_subplot(rows, cols, i)\n    plt.title(str(lbl))\n    plt.axis(\"off\")\n    plt.imshow(img.reshape(28,28), 'gray')\nplt.show()","dfc2f1af":"test = dict()\ntest['ImageId'] = [i for i in range(1,len(y_test)+1)]\ntest['Label'] =  y_test   \ndf = pd.DataFrame(test)\ndf.to_csv('results_new.csv', index=False)","16248ca4":"### Display validation results","1dccc47c":"### Visualize test results","2101db50":"### Accuracy matrics","b14e4edd":"### Save test results","eb2bb3cc":"### Model testing","2fec5b49":"### Required Libraries","9ce5e8db":"### Parameters","d3caf0a3":"### Finetuning resnet pretrained model","53fbb809":"### Train the model","6bb3ad69":"### Visaulize training results","fc0446a9":"### Data preparation","3766b364":"### Setup required optimizer and loss functions","033e9a94":"### Build dataloarders","cb8391f8":"### Visualize data"}}