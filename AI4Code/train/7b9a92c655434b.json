{"cell_type":{"de899a9f":"code","c9c0c615":"code","797a9660":"code","dea33c2c":"code","3a911b31":"code","f45b2a4c":"code","cee555bb":"code","4de5d22e":"code","4325f74f":"code","cde3186b":"code","49213577":"code","bb99a778":"code","d30cd19a":"code","c4c3e0ce":"code","2e471aaa":"code","1fcba796":"code","909e514c":"code","bc1bc567":"code","b261ec1e":"code","b24d294b":"code","9727996e":"markdown","34855342":"markdown","c8d3d02a":"markdown","0aaa0622":"markdown","40a07ed2":"markdown","a4364599":"markdown","8ae2884d":"markdown","38f4e2ac":"markdown","82400eeb":"markdown","086e98ab":"markdown","f677811a":"markdown","9dfb0a00":"markdown","afe81eac":"markdown","4d386af9":"markdown"},"source":{"de899a9f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\n\nimport tensorflow\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")","c9c0c615":"filepath = \"\/kaggle\/input\/air-quality-in-milan-summer-2020\/aq_milan_summer_2020.csv\"\ndf = pd.read_csv(filepath)\ndf.head()","797a9660":"df.info()","dea33c2c":"df.describe().transpose()","3a911b31":"df = df.rename({\"local_datetime\":\"ds\",\"pm2p5\":\"y\"}, axis=1)\ndf[\"ds\"] = pd.to_datetime(df[\"ds\"])\ndf = df.set_index(\"ds\")\ndf= df.asfreq(freq=\"H\")\ndf.head()","f45b2a4c":"roll_mean = df.y.rolling(5).mean()\nroll_std = df.y.rolling(5).std()\n\nplt.figure(figsize=(16, 7))\nplt.plot(df, label=\"Concentration\")\nplt.plot(roll_mean ,label=\"Moving Average\",linewidth=2.5)\nplt.xlabel(\"Date\")\nplt.ylabel(\"ug\/m3\")\nplt.legend()\nplt.title(\"Concentration of PM2.5 (ug\/m3)\")\nplt.show()","cee555bb":"decompose_result_add = seasonal_decompose(df, model=\"additive\", extrapolate_trend=\"freq\")\ndecompose_result_mul = seasonal_decompose(df, model=\"multiplicative\", extrapolate_trend=\"freq\")\n\nplt.rcParams.update({'figure.figsize': (16, 7)})\ndecompose_result_mul.plot().suptitle(\"Multiplicative Decompose\", fontsize=18)\ndecompose_result_add.plot().suptitle(\"Additive Decompose\", fontsize=18)\nplt.show()","4de5d22e":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16, 7))\nplot_acf(df,lags=50, ax=ax1)\nplot_pacf(df,lags=50, ax=ax2)\nplt.show()","4325f74f":"adf_result = adfuller(df)\nprint('ADF Statistic: %.3f' % adf_result[0])\nprint('p-value: %.3f' % adf_result[1])\nprint('Critical Values:')\nfor key, value in adf_result[4].items():\n    print('\\t%s: %.3f' % (key, value))","cde3186b":"scaler = MinMaxScaler(feature_range=(0, 1))\ndf[[\"y\"]] = scaler.fit_transform(df[[\"y\"]])\n\ny_train, y_test =train_test_split(df,shuffle=False, test_size=0.3)\n\nprint(f'Train: {y_train.shape}')\nprint(f'Test: {y_test.shape}')","49213577":"def sampling(sequence, n_steps):\n    X, Y = list(), list()\n    for i in range(len(sequence)):\n        sam = i + n_steps\n        if sam > len(sequence)-1:\n            break\n            \n        x, y = sequence[i:sam], sequence[sam]\n        X.append(x)\n        Y.append(y)\n        \n    return np.array(X), np.array(Y)","bb99a778":"n_steps = 3\nn_features = 1\n\nX_train, Y_train = sampling(y_train[\"y\"].tolist(), n_steps)\nX_test, Y_test = sampling(y_test[\"y\"].tolist(), n_steps)\n    \nX_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\nX_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))","d30cd19a":"model = Sequential()\nmodel.add(LSTM(50, activation=\"relu\", input_shape=(n_steps, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\", loss=\"mse\")\nmodel.summary()","c4c3e0ce":"history = model.fit(X_train, Y_train,validation_data=(X_test, Y_test),epochs=8, batch_size=50,verbose=1)","2e471aaa":"plt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"model train vs validation loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"validation\"])\nplt.show()","1fcba796":"y_train = y_train.iloc[n_steps:,:]\ny_test = y_test.iloc[n_steps:,:]\n\ntrain_pred = model.predict(X_train)\ntest_pred = model.predict(X_test)\n\ny_train[\"pred_train\"] = pd.Series(train_pred.flatten(), index=y_train.index)\ny_test[\"pred_test\"] = pd.Series(test_pred.flatten(), index=y_test.index)","909e514c":"train_score = mean_squared_error(y_train.y,y_train.pred_train)\nprint('Train Score: %.4f MSE' % (train_score))\nprint('Train Score: %.4f RMSE' % (np.sqrt(train_score)))\n\ntest_score = mean_squared_error(y_test.y,y_test.pred_test)\nprint('Test Score: %.4f MSE' % (test_score))\nprint('Test Score: %.4f RMSE' % (np.sqrt(test_score)))","bc1bc567":"result= pd.concat([y_train,y_test])\nresult[[\"y\",\"pred_train\",\"pred_test\"]] = scaler.inverse_transform(result[[\"y\",\"pred_train\",\"pred_test\"]])\n\nresult.plot()\nplt.show()","b261ec1e":"pred = model.predict(X_test[-24:])\nindex=pd.date_range(start=\"2020-09-20 23:00:00\", periods=24, freq=\"H\")\npred_df = pd.DataFrame(pred.flatten(), index=index, columns=[\"pred\"])\n\nresult= pd.concat([result,pred_df])\nresult[[\"pred\"]] = scaler.inverse_transform(result[[\"pred\"]])","b24d294b":"forecast = result[[\"y\",\"pred\"]]\n\nplt.plot(forecast.y, label=\"Concentration\")\nplt.plot(forecast.pred ,label=\"Forecast\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"ug\/m3\")\nplt.legend()\nplt.title(\"Concentration of PM2.5 (ug\/m3)\")\nplt.show()","9727996e":"## Exploratory Data Analysis <a name=\"EDA\"><\/a>","34855342":"### Validation Model","c8d3d02a":"## Data Preparation and Manipulation <a name=\"Data_Preparation_Manipulation\"><\/a>","0aaa0622":"### Model","40a07ed2":"## Importing Data <a name=\"Importing_Data\"><\/a>","a4364599":"## Create Model <a name=\"Create_Model\"><\/a>","8ae2884d":"## Forecasting <a name=\"Forecasting\"><\/a>","38f4e2ac":"# Table of Contents\n1. [Importing Data](#Importing_Data)\n2. [Data Preparation and Manipulation](#Data_Preparation_Manipulation)\n3. [Exploratory Data Analysis](#EDA)\n4. [Create Model](#Create_Model)\n5. [Forecasting](#Forecasting)","82400eeb":"### Sampling","086e98ab":"The model looks good now let's make a forecast!","f677811a":"The additive decomposition, looks quite random. So ideally, additive decomposition should be preferred for this particular series.","9dfb0a00":"I hope you like the result.","afe81eac":"For this series, the p-value is very close to zero and much lower than the 3 confidence values mentioned. Therefore, we can reject the null hypothesis for this series. According to the ADF test, the time series of the concentration of particulate matter 2.5 in the air of Milan is therefore stationary.","4d386af9":"### Data Preparation"}}