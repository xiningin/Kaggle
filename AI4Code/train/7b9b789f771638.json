{"cell_type":{"6c7a0534":"code","7a3dac3c":"code","acd8ca23":"code","62676e98":"code","f56a2933":"code","b044df9b":"code","2b5370d3":"code","d305a5d2":"code","25deca82":"code","387723b8":"code","3f6966f7":"code","fe0792ca":"code","9e3a8b88":"code","e82bdb09":"code","26e58696":"code","8b790e4a":"code","ff42183d":"code","09c539b8":"code","85742ec5":"code","b7acb1f3":"code","a1d10a02":"code","2bc4c398":"code","2ecfa031":"code","f41b2614":"code","ae596224":"code","57ed0658":"code","6cbe7897":"code","4feb456d":"code","f9353aca":"code","075356c3":"code","870f9cb6":"code","f3a78d8d":"markdown","6d61db75":"markdown","c912bf4b":"markdown","43c95af3":"markdown","06c65165":"markdown","583ab7f7":"markdown","85bb075b":"markdown","b4c8aef4":"markdown","bf17e4ac":"markdown","5dfb565e":"markdown","6fe7826b":"markdown","41792074":"markdown","70ab2772":"markdown","4e8d41c5":"markdown","2582b128":"markdown","121ae8d1":"markdown","2038c8a0":"markdown","8ecdb56d":"markdown","85c7d72b":"markdown","142548df":"markdown","05993313":"markdown","a6376609":"markdown","f5392f18":"markdown","f2465e00":"markdown","fd13c32f":"markdown","e8331070":"markdown"},"source":{"6c7a0534":"! pip install -q rich dabl","7a3dac3c":"import numpy as np\nfrom scipy import stats\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom rich import print as _pprint\nfrom rich.progress import track\nfrom colorama import Fore, Style\n\nimport dabl\n\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom IPython.display import HTML\nimport tensorflow as tf\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\nf = open(\"..\/input\/notebookassets\/blue.css\").read()\nHTML(f\"<style>{f}<\/style>\")","acd8ca23":"def cprint(string):\n    _pprint(f\"[black]{string}[\/black]\")\n    \ndef cout(string: str, color=Fore.RED):\n    \"\"\"\n    Saves some work\n    \"\"\"\n    print(color+string+Style.RESET_ALL)\n\ndef stats(scol, col):\n    cout(f\"Average Value in the Column: {scol} is: {np.mean(col):.4f}\", Fore.RED)\n    cout(f\"Median Value in the Column: {scol} is: {np.median(col):.4f}\", Fore.BLUE)\n    cout(f\"Maxmimum Value in the Column: {scol} is: {np.max(col):.4f}\", Fore.GREEN)\n    cout(f\"Minimum Value in the Column: {scol} is: {np.min(col):.4f}\", Fore.YELLOW)\n    cout(f\"50th Quantile of the Column: {scol} is: {np.quantile(col, 0.5):.4f}\", Fore.CYAN)\n    cout(f\"75th Quantile of the Column: {scol} is: {np.quantile(col, 0.75):.4f}\", Fore.MAGENTA)","62676e98":"train_file = pd.read_csv(\"..\/input\/tabular-playground-series-mar-2021\/train.csv\")\ntest_file = pd.read_csv(\"..\/input\/tabular-playground-series-mar-2021\/test.csv\")\n\ntrain_file.head()","f56a2933":"train_file.describe()","b044df9b":"names = train_file['target'].value_counts().index.tolist()\nvalues = train_file['target'].value_counts().tolist()\n\nplt.figure(figsize=(9, 9))\nplt.pie(x=values, labels=names, autopct=\"%1.2f%%\", colors=[\"cyan\", \"blue\"], explode=[0, 0.05])\nplt.title(\"Target Value Pie-Chart\")\nplt.show()","2b5370d3":"# Get a list of Categorical as well as continuous column names\ncatCols = [f\"cat{i}\" for i in range(0, 19)]\nconCols = [f\"cont{i}\" for i in range(0, 11)]","d305a5d2":"# Show Unique categories in feature columns\ncprint(\"[bold magenta] Categorical Features in the dataset [\/bold magenta]\")\nfor col in catCols:\n    print(f\"Number of features in {col}: \", end='')\n    cout(f\"{train_file[col].nunique()}\", color=Fore.MAGENTA)","25deca82":"# # Show some quick stats of Continuous Features\n# cprint(\"[bold green] Continuous Features and their Basic Statistics [\/bold green]\")\n# for col in conCols:\n#     print(f\"\\n{'-'*20} Column: {col} {'-'*20}\\n\")\n#     stats(col, train_file[col])","387723b8":"fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Continuous Features (cont0-cont10)', fontsize=16)\n\nfor idx, col in enumerate(train_file[conCols]):\n    i,j = (idx \/\/ 4, idx % 4)\n    sns.kdeplot(train_file[col], color=\"blue\", shade=True, label=\"%1.1f\"%(train_file[col].skew()), ax=ax[i,j])\n\nfig.delaxes(ax[2, 3])\nplt.tight_layout()\nplt.show()","3f6966f7":"fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Continuous Features with Targets (cont0-cont10)', fontsize=16)\n\nfor idx, col in enumerate(train_file[conCols]):\n    i,j = (idx \/\/ 4, idx % 4)\n    current_plot_1 = train_file.loc[train_file['target'].astype(int) == 1][col]\n    current_plot_0 = train_file.loc[train_file['target'].astype(int) == 0][col]\n    f1 = sns.kdeplot(current_plot_0, color=\"blue\", shade=True, ax=ax[i,j], label=\"Target-0\")\n    f2 = sns.kdeplot(current_plot_1, color=\"purple\", shade=True, ax=ax[i,j], label=\"Target-1\")\n    f1 = f1.legend(loc=\"best\")\n    f2 = f2.legend(loc=\"best\")\n    \nfig.delaxes(ax[2, 3])\nplt.tight_layout()\nplt.show()","fe0792ca":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Categorical Features (cat0-cat18)', fontsize=16)\n\ncatCols_s = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat6', 'cat9', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\nfor idx, col in enumerate(train_file[catCols_s]):\n    i, j = (idx \/\/ 4, idx % 4)\n    sns.histplot(x=col, data=train_file, ax=ax[i, j], color='green')\n\nfig.delaxes(ax[3, 3])\nplt.tight_layout()\nplt.show()","9e3a8b88":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Categorical Features with respect to Targets(cat0-cat18)', fontsize=16)\n\ncatCols_s = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat6', 'cat9', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\nfor idx, col in enumerate(train_file[catCols_s]):\n    i, j = (idx \/\/ 4, idx % 4)\n    f1 = sns.histplot(x=col, data=train_file[train_file['target'].astype(int)==0], ax=ax[i, j], color='green', label='Target-0')\n    f2 = sns.histplot(x=col, data=train_file[train_file['target'].astype(int)==1], ax=ax[i, j], color='yellow', label='Target-1')\n    f1 = f1.legend(loc=\"best\")\n    f2 = f2.legend(loc=\"best\")\n\nfig.delaxes(ax[3, 3])\nplt.tight_layout()\nplt.show()","e82bdb09":"ixs = train_file['cat5'].value_counts().index.tolist()[:10]\ncat5_fl = train_file[train_file['cat5'].isin(ixs)]['cat5']\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat5_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat5\")\n\ntotal = len(train_file['cat5'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 5\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","26e58696":"ixs = train_file['cat7'].value_counts().index.tolist()[:10]\ncat7_fl = train_file[train_file['cat7'].isin(ixs)]['cat7'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat7_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat7\")\n\ntotal = len(train_file['cat7'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","8b790e4a":"ixs = train_file['cat8'].value_counts().index.tolist()[:10]\ncat8_fl = train_file[train_file['cat8'].isin(ixs)]['cat8'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat8_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat8\")\n\ntotal = len(train_file['cat8'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","ff42183d":"ixs = train_file['cat10'].value_counts().index.tolist()[:10]\ncat10_fl = train_file[train_file['cat10'].isin(ixs)]['cat10'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat10_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat10\")\n\ntotal = len(train_file['cat10'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width() \/ 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","09c539b8":"corr = train_file[conCols+[\"target\"]].corr()\n\nfig = px.imshow(corr, title=\"Correlation Heatmap Between Continuous Features and Target\", color_continuous_scale=px.colors.sequential.Hot_r)\nfig.show()","85742ec5":"dabl.plot(train_file, target_col='target')","b7acb1f3":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","a1d10a02":"# Encode the categorical features\ndef encodeCategoricalColumns(train, test):\n    for col in track(catCols, description=\"[red]Encoding...[\/red]\"):\n        le = LabelEncoder()\n        fit_data = pd.concat([train[col], test[col]])\n        le.fit(fit_data)\n        train[col] = le.transform(train[col])\n        test[col] = le.transform(test[col])\nencodeCategoricalColumns(train_file, test_file)","2bc4c398":"# Shuffle the data and then split features and targets\ntrain_csv = train_file.sample(frac=1).reset_index(drop=True)\ndata = train_csv.drop(['id', 'target'], axis=1)\ntarget = train_csv[['target']]\ntarget_train = tf.keras.utils.to_categorical(target)\n\nprint(f\"Data Shape: {data.shape}, Target shape: {target_train.shape}\")","2ecfa031":"# Function to get the number of input & output dimensions for the embeddings \ndef get_emb_dims(categorical_column):\n    in_dim = categorical_column.nunique()\n    out_dim = int(np.sqrt(in_dim))\n    return in_dim, out_dim\n\n# for c in catCols:\n#     ind, oud = get_emb_dims(data[c])\n#     print(f\"{c}: in-{ind}, out-{oud}\")","f41b2614":"def build_categorical_model(cat_data=data[catCols]):\n    # Cat-0\n    cat0_inp = tf.keras.Input(shape=(1,))\n    cat0_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat0')(cat0_inp)\n    cat0_out = tf.keras.layers.Reshape(target_shape=(1,))(cat0_out)\n    \n    # Cat-1\n    cat1_inp = tf.keras.Input(shape=(1,))\n    cat1_out = tf.keras.layers.Embedding(input_dim=15, output_dim=3, name='cat1')(cat1_inp)\n    cat1_out = tf.keras.layers.Reshape(target_shape=(3,))(cat1_out)\n    \n    # Cat-2\n    cat2_inp = tf.keras.Input(shape=(1,))\n    cat2_out = tf.keras.layers.Embedding(input_dim=19, output_dim=4, name='cat2')(cat2_inp)\n    cat2_out = tf.keras.layers.Reshape(target_shape=(4,))(cat2_out)\n    \n    # Cat-3\n    cat3_inp = tf.keras.Input(shape=(1,))\n    cat3_out = tf.keras.layers.Embedding(input_dim=13, output_dim=3, name='cat3')(cat3_inp)\n    cat3_out = tf.keras.layers.Reshape(target_shape=(3,))(cat3_out)\n    \n    # Cat-4\n    cat4_inp = tf.keras.Input(shape=(1,))\n    cat4_out = tf.keras.layers.Embedding(input_dim=20, output_dim=4, name='cat4')(cat4_inp)\n    cat4_out = tf.keras.layers.Reshape(target_shape=(4,))(cat4_out)\n    \n    # Cat-5\n    cat5_inp = tf.keras.Input(shape=(1,))\n    cat5_out = tf.keras.layers.Embedding(input_dim=84, output_dim=9, name='cat5')(cat5_inp)\n    cat5_out = tf.keras.layers.Reshape(target_shape=(9,))(cat5_out)\n    \n    # Cat-6\n    cat6_inp = tf.keras.Input(shape=(1,))\n    cat6_out = tf.keras.layers.Embedding(input_dim=16, output_dim=4, name='cat6')(cat6_inp)\n    cat6_out = tf.keras.layers.Reshape(target_shape=(4,))(cat6_out)\n    \n    # Cat-7\n    cat7_inp = tf.keras.Input(shape=(1,))\n    cat7_out = tf.keras.layers.Embedding(input_dim=51, output_dim=7, name='cat7')(cat7_inp)\n    cat7_out = tf.keras.layers.Reshape(target_shape=(7,))(cat7_out)\n    \n    # Cat-8\n    cat8_inp = tf.keras.Input(shape=(1,))\n    cat8_out = tf.keras.layers.Embedding(input_dim=61, output_dim=7, name='cat8')(cat8_inp)\n    cat8_out = tf.keras.layers.Reshape(target_shape=(7,))(cat8_out)\n    \n    # Cat-9\n    cat9_inp = tf.keras.Input(shape=(1,))\n    cat9_out = tf.keras.layers.Embedding(input_dim=19, output_dim=4, name='cat9')(cat9_inp)\n    cat9_out = tf.keras.layers.Reshape(target_shape=(4,))(cat9_out)\n    \n    # Cat-10\n    cat10_inp = tf.keras.Input(shape=(1,))\n    cat10_out = tf.keras.layers.Embedding(input_dim=299, output_dim=17, name='cat10')(cat10_inp)\n    cat10_out = tf.keras.layers.Reshape(target_shape=(17,))(cat10_out)\n    \n    # Cat-11\n    cat11_inp = tf.keras.Input(shape=(1,))\n    cat11_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat11')(cat11_inp)\n    cat11_out = tf.keras.layers.Reshape(target_shape=(1,))(cat11_out)\n    \n    # Cat-12\n    cat12_inp = tf.keras.Input(shape=(1,))\n    cat12_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat12')(cat12_inp)\n    cat12_out = tf.keras.layers.Reshape(target_shape=(1,))(cat12_out)\n    \n    # Cat-13\n    cat13_inp = tf.keras.Input(shape=(1,))\n    cat13_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat13')(cat13_inp)\n    cat13_out = tf.keras.layers.Reshape(target_shape=(1,))(cat13_out)\n    \n    # Cat-14\n    cat14_inp = tf.keras.Input(shape=(1,))\n    cat14_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat14')(cat14_inp)\n    cat14_out = tf.keras.layers.Reshape(target_shape=(1,))(cat14_out)\n    \n    # Cat-15\n    cat15_inp = tf.keras.Input(shape=(1,))\n    cat15_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat15')(cat15_inp)\n    cat15_out = tf.keras.layers.Reshape(target_shape=(2,))(cat15_out)\n    \n    # Cat-16\n    cat16_inp = tf.keras.Input(shape=(1,))\n    cat16_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat16')(cat16_inp)\n    cat16_out = tf.keras.layers.Reshape(target_shape=(2,))(cat16_out)\n    \n    # Cat-17\n    cat17_inp = tf.keras.Input(shape=(1,))\n    cat17_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat17')(cat17_inp)\n    cat17_out = tf.keras.layers.Reshape(target_shape=(2,))(cat17_out)\n    \n    # Cat-18\n    cat18_inp = tf.keras.Input(shape=(1,))\n    cat18_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat18')(cat18_inp)\n    cat18_out = tf.keras.layers.Reshape(target_shape=(2,))(cat18_out)\n    \n    # Concatenate all entity embedding layers.\n    input_layers = [cat0_inp, cat1_inp, cat2_inp, cat3_inp, cat4_inp, cat5_inp, cat6_inp, cat7_inp, cat8_inp, cat9_inp, cat10_inp, cat11_inp, cat12_inp, cat13_inp, cat14_inp, cat15_inp, cat16_inp, cat17_inp, cat18_inp]\n    output_layers = [cat0_out, cat1_out, cat2_out, cat3_out, cat4_out, cat5_out, cat6_out, cat7_out, cat8_out, cat9_out, cat10_out, cat11_out, cat12_out, cat13_out, cat14_out, cat15_out, cat16_out, cat17_out, cat18_out]\n    \n    concat = tf.keras.layers.Concatenate(name=\"combine-embd\")(output_layers)\n    \n    # Add Dense, Dropout and Batchnorm\n    bn = tf.keras.layers.BatchNormalization(name=\"embd-bn\")(concat)\n    dropout_1 = tf.keras.layers.Dropout(0.3, name=\"embd-drop1\")(bn)\n    fc1 = tf.keras.layers.Dense(1024, activation='relu', name=\"embd-fc1\")(dropout_1)\n    dropout_2 = tf.keras.layers.Dropout(0.5, name=\"embd-drop2\")(fc1)\n    fc2 = tf.keras.layers.Dense(512, activation='relu', name=\"embd-fc2\")(dropout_2)\n    dropout_3 = tf.keras.layers.Dropout(0.5, name=\"embd-drop3\")(fc2)\n    cat_output = tf.keras.layers.Dense(64, activation='relu', name=\"embd-out\")(dropout_3)\n    \n    # Return the Last Layer output\n    return input_layers, cat_output\n\ndef build_continuous_model(con_data=data[conCols]):\n    # Model for Continuous Data\n    con_inputs = tf.keras.Input(shape=(con_data.shape[1]))\n    \n    fc1 = tf.keras.layers.Dense(512, activation='relu', name=\"cont_fc1\")(con_inputs)\n    drp1 = tf.keras.layers.Dropout(0.5, name=\"cont_drop1\")(fc1)\n    fc2 = tf.keras.layers.Dense(256, activation='relu', name=\"cont_fc2\")(drp1)\n    drp2 = tf.keras.layers.Dropout(0.3, name=\"cont_drop2\")(fc2)\n    fc3 = tf.keras.layers.Dense(128, activation='relu', name=\"cont_fc3\")(drp2)\n    drp3 = tf.keras.layers.Dropout(0.3, name=\"cont_drop3\")(fc3)\n    con_output = tf.keras.layers.Dense(64, activation='relu', name=\"cont_out\")(drp3)\n    \n    return con_inputs, con_output","ae596224":"def build_model():\n    cat_inputs, cat_outputs = build_categorical_model(data[catCols])\n    con_inputs, con_outputs = build_continuous_model(data[conCols])\n    \n    # Concatenate the outputs\n    all_layers_out = [cat_outputs, con_outputs]\n    concat_outputs = tf.keras.layers.Concatenate()(all_layers_out)\n    fc1 = tf.keras.layers.Dense(256, activation='relu', name=\"all_fc1\")(concat_outputs)\n    drp1 = tf.keras.layers.Dropout(0.3, name=\"all_drop1\")(fc1)\n    fc2 = tf.keras.layers.Dense(128, activation='relu', name=\"all_fc2\")(drp1)\n    drp2 = tf.keras.layers.Dropout(0.3, name=\"all_drop2\")(fc2)\n    fc3 = tf.keras.layers.Dense(64, activation='relu', name=\"all_fc3\")(drp2)\n    drp3 = tf.keras.layers.Dropout(0.5, name=\"all_drop3\")(fc3)\n    fc4 = tf.keras.layers.Dense(16, activation='relu', name=\"all_fc4\")(drp3)\n    output = tf.keras.layers.Dense(2, activation='softmax', name=\"all_out\")(fc4)\n    \n    all_inputs = cat_inputs + [con_inputs]\n    return tf.keras.Model(inputs=all_inputs, outputs=output)","57ed0658":"# Initialize a temporary model so that we can see the model architecture plot.\ntemp_model = build_model()\ntf.keras.utils.plot_model(temp_model)","6cbe7897":"# Init KFolds training\nkfold = KFold(5, shuffle=False)\n\nfor fold_, (train_idx, valid_idx) in enumerate(kfold.split(data, target)):\n    print(f\"{'='*20} FOLD: {fold_+1} {'='*20}\")\n    # Get this fold's training and validation splits\n    trainX, trainY = data.iloc[train_idx], target_train[train_idx]\n    validX, validY = data.iloc[valid_idx], target_train[valid_idx]\n    \n    training_data = ([trainX[f\"cat{i}\"] for i in range(0, 19)] + [trainX[conCols]], trainY)\n    validation_data = ([validX[f\"cat{i}\"] for i in range(0, 19)] + [validX[conCols]], validY)\n\n    # Initalize this fold's model\n    with strategy.scope():\n        model = build_model()\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Init early stopping so that we don't train the model more than we have to\n    early_stopper = tf.keras.callbacks.EarlyStopping(\n        monitor='val_acc',\n        patience=2,\n        mode='max',\n        restore_best_weights=True\n    )\n    \n    # Also have a model checkpoint\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=f\"fold_{fold_}_model.h5\",\n        monitor='val_acc',\n        mode='max',\n        save_best_only=True\n    )\n    \n    # Fit this fold's model\n    model.fit(\n        training_data[0],\n        training_data[1],\n        epochs=5,\n        validation_data=validation_data,\n        callbacks=[early_stopper, checkpoint]\n    )","4feb456d":"# Get the testing data in the right shape for inference\ntest_ids = test_file['id']\ntest = test_file.drop(['id'], axis=1)\ntest_data = [test[f\"cat{i}\"] for i in range(0, 19)] + [test[conCols]]","f9353aca":"# Do the inference\npreds = model.predict(test_data)\npreds = preds.argmax(1)\nprint(preds)  # Printing some predictions for sanity check","075356c3":"# Save the inference into a submission file\nsubmission_file = pd.DataFrame()\nsubmission_file['id'] = test_ids.tolist()\nsubmission_file['target'] = preds\nsubmission_file.to_csv(\"submission.csv\", index=None)\nsubmission_file.head()","870f9cb6":"cprint(\"[bold green]UNDER WORK! MORE CELLS ARE BEING ADDED DAILY![\/bold green]\")","f3a78d8d":"<div class=\"alert alert-block alert-info\">\nKeep in mind that I am training this model for only 2 epochs per fold (reason being it's high time consumption).\nI encourage you to fork the notebook (if you do, leaving an upvote would be nice \ud83d\ude01) and then increasing the number of folds and playing around with other numbers to see how the results change!\n<\/div>","6d61db75":"<div class=\"alert alert-block alert-info\">\nThis Competition (unlike it's predecessors) wants us to classify the data points into either of 2 categories (0 or 1).\nAs you can probably see from below, the dataset is not very balanced when looking from the Target Column's perspective.\n<\/div>","c912bf4b":"### Feature: cat10\n\nSame as cat5, cat7 and cat8, I am only showing the top-10 most occuring values here.","43c95af3":"Just like the Continuous Features, let's see how the selected categorical features change with Targets. ","06c65165":"### Feature: cat5\n\nSince the feature `cat5` has *over 80* different categories, I will be plotting only the top-10 most occuring ones.","583ab7f7":"## Categorical Features\n\nLet's now take a look at the Categorical features in this Dataset and the distribution of their various categories.","85bb075b":"## Continuous Features\n\nLet's begin by seeing this month's data's continuous features and how they are distributed.","b4c8aef4":"# Peeking the Data \ud83d\udc41\n\nLet's start by taking a peek at the data and getting some basic insights from it!\n<!-- <div class=\"alert alert-block alert-info\"><\/div> -->","bf17e4ac":"Then we encode categorical columns in both training and testing sets to make them ready for modelling.","5dfb565e":"First get the TPU for faster training.","6fe7826b":"Now, let's train this model and see how it performs!","41792074":"## A brief look at Target Column","70ab2772":"Use the above defined functions to build this huge model.","4e8d41c5":"# Multi Input Embeddings Model - Tensorflow \ud83c\udf06\n\nLet's start modelling by using one of the model types that I experimented in last TPS Competition (Feburary).\n\nFor Categorical features, I am using Entity Embeddings for every feature then concatenating them and then passing them to a few final layers where they are combined with the features learned from the Dense network built for continuous data.","2582b128":"<div class=\"alert alert-block alert-info\">\n    Thanks for taking your time to look at my work!\n    <br><br>\n    <bold>If you like this notebook, you can consider giving an upvote! It will help me make more useful content!<\/bold>\n<\/div>","121ae8d1":"Let's now see how Continuous features behave based on what target variable they represent.","2038c8a0":"## Correlation Between Continuous features and Target\n\nLet us now plot the correlation between continuous features and the target and see how things change.","8ecdb56d":"As you can see above, the categories `BI`, `AB` and `BU` dominate the count for this feature.","85c7d72b":"<div class=\"alert alert-block alert-info\">\nI have not plotted the following Categorical Columns in the Above Plot:\n    \n<code>cat5<\/code>,\n<code>cat7<\/code>,\n<code>cat8<\/code>,\n<code>cat10<\/code>.\n\nThe Reason behind this was that since there were so many categories, it wouldn't fit into subplots.\nWe shall plot them separately down below.\n<\/div>","142548df":"### Feature: cat7\n\nSame as cat5, I am only showing the top-10 most occuring values here.","05993313":"# Inference \ud83c\udf0c\n\nNow let's do quick inference based on the model(s) trained above.","a6376609":"## A closer look at some Categorical features.\n\nLet's now take a look at the aforementioned 4 categorical features that are too clumsy to fit in a subplots.","f5392f18":"### Feature: cat8\n\nSame as cat5 and cat7, I am only showing the top-10 most occuring values here.","f2465e00":"# Data and Library Imports \ud83d\udcda\n\nLet's start this interesting competition by first importing data and libraries!","fd13c32f":"# DABL Plot","e8331070":"# Advanced Exploratory Data Analysis \ud83d\udcca\n\nLet's now start with detailed Exploratory Data Analysis and take a look at different combinations of features, one by one!"}}