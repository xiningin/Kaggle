{"cell_type":{"68b41a8c":"code","9fa7094d":"code","9bcb04bc":"code","9fd009ae":"code","f8473b3e":"code","8ee9e36a":"code","33bf19ff":"code","6b83c361":"code","a5cad094":"code","fd6068f3":"code","eaaf70f7":"code","cf852674":"code","f3cd0e6f":"code","9511cd45":"code","01f9b8fc":"code","4cdae339":"code","115c38ad":"code","119f489e":"code","60c09914":"code","9ef0d6aa":"code","5192fae2":"markdown","d95a9f69":"markdown","4597bf52":"markdown","c6f307e4":"markdown","0cd22baf":"markdown","59a0707a":"markdown","230cdd35":"markdown","b4a6ad29":"markdown","a78ff985":"markdown","896dde2a":"markdown","5e7818db":"markdown","6aee2256":"markdown"},"source":{"68b41a8c":"import pandas as pd\nimport os\nimport shutil\n\npd.set_option('display.max_colwidth', None)\n\ntrain_csv = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')","9fa7094d":"os.mkdir('images\/')\nfor i in range(100):\n    i += 1\n    os.mkdir(f'.\/images\/{i}')","9bcb04bc":"Path = []\nIMG_DIR = '..\/input\/petfinder-pawpularity-score\/train'\nfor i in train_csv['Id']:\n    Path.append(f'{IMG_DIR}\/{i}.jpg')\ntrain_csv['Cur_Path'] = Path \ntrain_csv.head()","9fd009ae":"Path = []\nIMG_DIR = '.\/images'\nfor i in train_csv['Pawpularity']:\n    Path.append(f'{IMG_DIR}\/{i}\/')\ntrain_csv['Wan_Path'] = Path\ntrain_csv.head()","f8473b3e":"for i,j in zip(train_csv['Cur_Path'],train_csv['Wan_Path']):\n    shutil.copy2(i,j)","8ee9e36a":"Path = []\nfor i,j in zip(train_csv['Wan_Path'],train_csv['Id']):\n    Path.append(f'{i}{j}.jpg')\ntrain_csv['New_Path'] = Path","33bf19ff":"train_csv.drop(['Cur_Path','Wan_Path'],axis=1,inplace=True)","6b83c361":"import PIL \n\nimage = PIL.Image.open(\".\/images\/34\/07305d3af8b61f21a0ff5e42f2101f9d.jpg\")\nwidth, height = image.size\nwidth, height","a5cad094":"train_images = train_csv[['Id','New_Path' ,'Pawpularity']]\ntrain_images['Pawpularity'].value_counts()\n#Checking the distributions of iamges","fd6068f3":"from sklearn.model_selection import train_test_split\ntrain_df,test_df = train_test_split(train_images,train_size=0.75,shuffle=True,random_state = 1)","eaaf70f7":"image_sample = train_images.sample(5000, random_state = 1).reset_index(drop=True)\nimage_sample # For quickie test outs training","cf852674":"import tensorflow as tf\n\ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split = 0.2,\n    brightness_range = (0.1,1.0),\n)\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    brightness_range = (0.1,1.0)\n)","f3cd0e6f":"train_images = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = 'New_Path',\n    y_col = 'Pawpularity',\n    target_size =(120,120),\n    color_mode='rgb',\n    class_mode = 'raw',\n    batch_size = 64,\n    shuffle= True,\n    seed=42,\n    subset= 'training',\n)\n\n\nvalidation_images = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = 'New_Path',\n    y_col = 'Pawpularity',\n    target_size =(120,120),\n    color_mode='rgb',\n    class_mode = 'raw',\n    batch_size=64,\n    shuffle= True,\n    seed=42,\n    subset= 'validation',\n)\n\ntest_images = train_generator.flow_from_dataframe(\n    dataframe = test_df,\n    x_col = 'New_Path',\n    y_col = 'Pawpularity',\n    target_size =(120,120),\n    color_mode='rgb',\n    class_mode = 'raw',\n)","9511cd45":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ndata_augmentation = keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n    layers.experimental.preprocessing.RandomContrast(factor=0.1)\n    ])\nmodel = keras.Sequential(\n    [data_augmentation,\n     keras.layers.Conv2D(filters=16,padding='same',kernel_size=(3,3),activation='relu',input_shape=(120,120,3)),\n     keras.layers.BatchNormalization(),\n     keras.layers.MaxPool2D(strides=(2,2)),\n     keras.layers.Conv2D(filters=32,padding='same',kernel_size=(3,3),activation='relu',input_shape=(480,480,3)),\n     keras.layers.MaxPool2D(strides=(2,2)),\n     keras.layers.Conv2D(filters=32,padding='same',kernel_size=(3,3),activation='relu',input_shape=(480,480,3)),\n     keras.layers.MaxPool2D(strides=(2,2)),\n     keras.layers.GlobalAveragePooling2D(),\n     keras.layers.Dense(512,activation = 'relu'),\n     keras.layers.Dense(1024,activation = 'relu'),\n     keras.layers.Dense(1,activation='linear')\n    ]\n)\n#     inputs=tf.keras.Input(shape=(240,240,3))\n#     x = tf.keras.layers.Conv2D(filters=32,kernel_size=(2,2),activation='relu')(inputs)\n#     x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n#     x = tf.keras.layers.Conv2D(filters=64,kernel_size=(2,2),activation='relu')(inputs)\n#     x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n#     x = tf.keras.layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu')(inputs)\n#     x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n#     x = tf.keras.layers.GlobalAveragePooling2D()(x)\n#     x = tf.keras.layers.Dense(256,activation='relu')(x)\n#     x = tf.keras.layers.Dense(256,activation='relu')(x)\n#     outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n#     model = tf.keras.Model(inputs=inputs,outputs=outputs)\n    \nmodel.compile(\n    optimizer=keras.optimizers.RMSprop(),\n    loss='mse')\n\nhistory = model.fit(\n                    train_images,\n                    validation_data = validation_images,\n                    epochs=100,\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)])","01f9b8fc":"import numpy as np\nfrom sklearn.metrics import r2_score\n\npredicted_paws = np.squeeze(model.predict(test_images))\ntrue_paw=test_images.labels\n\nrmse=np.sqrt(model.evaluate(test_images,verbose=0))\nprint(f'RMSE {rmse:.5f}')\nr2=r2_score(true_paw,predicted_paws)\nprint(f'R2 {r2:.5f}')","4cdae339":"np.mean(true_paw)","115c38ad":"Submission_df = pd.Series([i for i in test_df['Id']]).to_frame(name='Id')\n# It is okay it has random state is always the same","119f489e":"dirty_predicted_paw = np.squeeze(model.predict(test_images))\nSubmission_df['Pawpularity']=pd.Series([f'{i:.2f}' for i in dirty_predicted_paw]).astype('float32')\n# I know right quite hard to read, i am not even sorry round function is bugged as hell","60c09914":"Submission_df.dtypes","9ef0d6aa":"os.mkdir\nSubmission_df.to_csv('.\/submission.csv',index=False,encoding='utf-8')\n#Fix format later","5192fae2":"* Checking image size of a few pics too see how many pixels i can  pass through","d95a9f69":"### Making the CSV file","4597bf52":"* Taking a good luck at the distribution of values also getting rid of metadata wont be necessary","c6f307e4":"# Seeing the end result","0cd22baf":"* Constructin the paths","59a0707a":"# Loading images","230cdd35":"* Droping unecessary paths","b4a6ad29":"# First steps: Improvement\n1. Model need to be cleaner lets build a sequential model\n2. Lets augment artificially the images, making the distribution of data more equal","a78ff985":"* Sample to train quickly, doesnt contain all data","896dde2a":"* Build up the train_df, and test_df","5e7818db":"## On this part i am going to be constructing the path column\n* I did a step by step frame loop, that constructed 3 sort of columns and fused then on a later ocasion\n* If anyone has an idea on how to improve it(takes a while), just comment here\n* The path will come in handy when we reach the data aug part, and analysis","6aee2256":"# Model (needs improvement)"}}