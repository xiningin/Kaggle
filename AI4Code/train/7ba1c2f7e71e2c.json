{"cell_type":{"19a539d6":"code","aed4d673":"code","ac31772f":"code","6ac13580":"code","6fbb0aba":"code","07817688":"code","f9c46ce6":"code","e1eb0f3b":"code","ee243db0":"code","b059c241":"code","ff5b7eef":"code","473a6dbe":"code","fd70296e":"code","e0529ef5":"code","81744d56":"code","d9702596":"code","fb028265":"code","f9ddba7f":"markdown","ef057fcb":"markdown","19b32adf":"markdown","f30323e7":"markdown","58f475a3":"markdown","8c641f7a":"markdown","94149155":"markdown","9703fd6b":"markdown","ded2999e":"markdown","b865ebcc":"markdown","64244809":"markdown","9d4ebc98":"markdown","f129e43c":"markdown","50081042":"markdown","0952b0a0":"markdown","3b869997":"markdown"},"source":{"19a539d6":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","aed4d673":"df = pd.read_csv(\"..\/input\/winequality-red.csv\")\ndf.head(3)","ac31772f":"quality = df[\"quality\"].values\ncategory = []\nfor num in quality:\n    if num<5:\n        category.append(\"Bad\")\n    elif num>6:\n        category.append(\"Good\")\n    else:\n        category.append(\"Mid\")","6ac13580":"#Create new data\ncategory = pd.DataFrame(data=category, columns=[\"category\"])\ndata = pd.concat([df,category],axis=1)\ndata.drop(columns=\"quality\",axis=1,inplace=True)","6fbb0aba":"data.head(3)","07817688":"plt.figure(figsize=(10,6))\nsns.countplot(data[\"category\"],palette=\"muted\")\ndata[\"category\"].value_counts()","f9c46ce6":"plt.figure(figsize=(12,6))\nsns.heatmap(df.corr(),annot=True)","e1eb0f3b":"plt.figure(figsize=(12,6))\nsns.barplot(x=df[\"quality\"],y=df[\"alcohol\"],palette=\"Reds\")","ee243db0":"plt.figure(figsize=(12,6))\nsns.jointplot(y=df[\"density\"],x=df[\"alcohol\"],kind=\"hex\")","b059c241":"X= data.iloc[:,:-1].values\ny=data.iloc[:,-1].values","ff5b7eef":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y =LabelEncoder()\ny= labelencoder_y.fit_transform(y)","473a6dbe":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)","fd70296e":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","e0529ef5":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train,y_train)\npred_svc =svc.predict(X_test)","81744d56":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_svc))","d9702596":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\npred_knn=knn.predict(X_test)\nprint(classification_report(y_test, pred_knn))","fb028265":"conclusion = pd.DataFrame({'models': [\"SVC\",\"KNN\"],\n                           'accuracies': [accuracy_score(y_test,pred_svc),accuracy_score(y_test,pred_knn)]})\nconclusion","f9ddba7f":"\n\n\n\n* **In this data, I classified wine qualities into 3 categories as good, mid and bad.  Then, I explored the new data with data visualization libraries.** \n\n* **For prediction I used K-Nearest Neighbors, Support Vector Machine and Random Forest models.** \n\n* **For conclusion, I matched accuracy scores according to model prediction ratios**\n","ef057fcb":"Here SVC is more accurate.","19b32adf":"** Setting features, labels and\nEncoding the categorical data**\n\n**[](http:\/\/)(good=1, med=2, bad=3)**","f30323e7":"## Training the Model and Predicting the Test Data \n\nNow its time to train our models on our training data and predict each of them!","58f475a3":"**Scaling the data for optimise predictions**","8c641f7a":"**Basic Imports**","94149155":"## Support Vector Machine","9703fd6b":"**Classify The Quality**","ded2999e":"## Exploratory Data Analysis\n\n**Let's explore the data!**\n\n___\n**Here I counted the number of each class and checked correlation of the columns**","b865ebcc":"## Introduction","64244809":"**According to heatmap, we can focus on alcohol-quality and density-alcohol relations to get meaningful exploration**","9d4ebc98":"**Get The Data**","f129e43c":"## Training and Testing Data\n**Now that we've explored the data a bit, let's go ahead and split the data into training and testing sets.**","50081042":"## K-Nearest Neighbors","0952b0a0":"> **Please leave me a comment and upvote the kernel if you liked at the end.**","3b869997":"## Conclusion\n\n**Time to match the results!**"}}