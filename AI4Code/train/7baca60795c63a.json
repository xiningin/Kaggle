{"cell_type":{"6af4df74":"code","d27e32ef":"code","98e94298":"code","48fe5032":"code","8261ccf3":"code","7424ad0a":"code","ebeb05fe":"code","3b1cd6cf":"code","b70ea124":"code","0a58a9e7":"code","3cff0134":"code","8ee7ffb6":"code","594bc8f9":"code","f683e814":"code","632c0c81":"code","535f5987":"code","17f196b8":"code","8c6f500d":"code","8e0d7e1c":"code","18450f36":"code","2814eb43":"code","d011cf54":"code","ae1d68fa":"code","20eeaf17":"code","8c7db97d":"code","13eca5cf":"code","ec13094e":"code","84eab68c":"code","2fec1167":"code","c482f2d1":"code","a40a5bc6":"code","2c70adb2":"code","f99d549e":"code","b7295cfe":"code","8530225d":"code","f7d8ae9a":"code","7a070c5c":"code","45fabda0":"code","ddc46113":"code","256e4d46":"code","4260de10":"code","aa42d03f":"code","9e771f98":"code","ab762346":"code","ce68af89":"code","5ea2bb96":"code","8733fb22":"code","a6b23e37":"code","959e6311":"code","46abb4cf":"code","5fa2187e":"code","839dd063":"code","4e1bb31e":"markdown","f471ddae":"markdown","d30859e4":"markdown","0d47368a":"markdown","3f298891":"markdown","d5e1c4a2":"markdown","0ba1d32b":"markdown","3d6fbafd":"markdown","77507dbf":"markdown","e89a4bd5":"markdown","1f9b7c5e":"markdown","1b9c7737":"markdown","48e94535":"markdown","00224d5f":"markdown","a9309cc2":"markdown","1bb8bc3b":"markdown","7a9230d4":"markdown","a0a9310f":"markdown","5c4a547f":"markdown","bd38a0ef":"markdown","ea6e24a1":"markdown"},"source":{"6af4df74":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d27e32ef":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom warnings import filterwarnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy import stats\nfrom warnings import filterwarnings","98e94298":"pd.options.mode.chained_assignment = None\nfilterwarnings(action='ignore')","48fe5032":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nX_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","8261ccf3":"train_df.head()","7424ad0a":"train_df.info()","ebeb05fe":"train_df.describe()","3b1cd6cf":"missing = pd.DataFrame()\nmissing['num of missed'] = train_df.isna().sum().sort_values(ascending=False)\nmissing['percent'] = train_df.isna().sum()\/train_df.isna().count()\nmissing","b70ea124":"# creating a new feature \"family size\" and \"title\" and dropping useless columns\n\ndef preprocessor(df):\n    df['Title'] = '-'\n    for i in df:\n        df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n    df['Family size'] = df['SibSp']+df['Parch']+1\n\n    df.drop(['PassengerId', 'Name', 'Ticket', 'Parch',\n            'SibSp', 'Cabin'], axis=1, inplace=True)\n    return df","0a58a9e7":"train_df.dtypes","3cff0134":"train_df = preprocessor(train_df)","8ee7ffb6":"train_df['Fare'].describe()","594bc8f9":"sns.distplot(train_df['Fare'], fit=stats.norm)","f683e814":"train_df.drop(['Fare'], axis=1, inplace=True)","632c0c81":"# some barplots to see how the dataset looks like\n\ndef bar_visualizer(df, size):\n    if size != 'default':\n        plt.figure(figsize=(15, 5))\n    plot = sns.barplot(x=df[df.columns[0]],\n                       y=df[df.columns[1]], palette='muted')\n    for bar in plot.patches:\n        plot.annotate(format(bar.get_height(), 'g'),\n                      (bar.get_x() + bar.get_width() \/ 2,\n                       bar.get_height()), ha='center', va='center',\n                      size=12, xytext=(0, 4),\n                      textcoords='offset points')","535f5987":"temp = train_df.groupby('Sex', as_index=False)['Survived'].sum()","17f196b8":"bar_visualizer(temp, 'default')","8c6f500d":"temp = train_df.groupby('Pclass', as_index=False)['Survived'].sum()\ntemp","8e0d7e1c":"bar_visualizer(temp, 'default')","18450f36":"temp = train_df.groupby('Embarked', as_index=False)['Survived'].sum()","2814eb43":"bar_visualizer(temp, 'default')","d011cf54":"temp = train_df.groupby('Family size', as_index=False)['Survived'].sum()","ae1d68fa":"bar_visualizer(temp, 'default')","20eeaf17":"temp = train_df.groupby('Survived', as_index=False)['Age'].mean()\ntemp","8c7db97d":"bar_visualizer(temp, 'default')","13eca5cf":"temp = train_df.groupby('Title', as_index=False)['Age'].mean()","ec13094e":"bar_visualizer(temp, 'customized')","84eab68c":"train_df.isna().sum()","2fec1167":"# there are just two of missing values in this column, we can easily drop them.\n\ntrain_df.dropna(subset=['Embarked'], inplace=True)","c482f2d1":"# since we know each person's title, we could use it as an estimator for imputing this column\ntitle_age = train_df.groupby(\n    'Title')['Age'].mean()\n\ntitle_age = title_age.to_dict()\ntitle_age","a40a5bc6":"indexes = train_df.loc[train_df['Age'].isna()].index\n\nfor index in indexes:\n    for key in title_age.keys():\n        if train_df['Title'][index] == key:\n            train_df['Age'][index] = title_age[key]","2c70adb2":"train_df.drop('Title', axis=1, inplace=True)","f99d549e":"train_df = pd.get_dummies(train_df, drop_first=True)\ntrain_df","b7295cfe":"X = train_df.drop('Survived', axis=1)\ny = train_df['Survived']","8530225d":"X_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42)","f7d8ae9a":"X_train","7a070c5c":"from sklearn.preprocessing import StandardScaler","45fabda0":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom lightgbm import LGBMClassifier","ddc46113":"classifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_val)","256e4d46":"print(accuracy_score(y_val, y_pred))","4260de10":"lgb_clf = LGBMClassifier()","aa42d03f":"lgb_clf.fit(X_train, y_train)","9e771f98":"y_pred = lgb_clf.predict(X_val)\nprint(accuracy_score(y_val, y_pred))","ab762346":"X_test = preprocessor(X_test)","ce68af89":"X_test.isna().sum()","5ea2bb96":"X_test.drop(['Fare'], axis=1, inplace=True)","8733fb22":"title_age = X_test.groupby(\n    'Title')['Age'].mean()\n\ntitle_age = title_age.to_dict()\ntitle_age","a6b23e37":"title_age['Ms'] = 28","959e6311":"indexes = X_test.loc[X_test['Age'].isna()].index\n\nfor index in indexes:\n    for key in title_age.keys():\n        if X_test['Title'][index] == key:\n            X_test['Age'][index] = title_age[key]","46abb4cf":"X_test.drop('Title', axis=1, inplace=True)","5fa2187e":"X_test = pd.get_dummies(X_test, drop_first=True)\nX_test","839dd063":"y_pred = lgb_clf.predict(X_test)","4e1bb31e":"### Survived\/Title","f471ddae":"### LightGBM Classifier(default parameters)","d30859e4":"### Survived\/Family Size","0d47368a":"## Some info about the dataset","3f298891":"Apparently huge amount of values are missed, because even though we have the average of this column is too low, So this column is not worth keeping and feeding it to our model. ","d5e1c4a2":"## Training a model","0ba1d32b":"### Survived\/Sex","3d6fbafd":"### Survived\/Embarked","77507dbf":"'Title' is a categorical feature and we only needed it for imputing NaN variables in 'Age' column, so we can drop it now.","e89a4bd5":"### Random Forest(default parameters)","1f9b7c5e":"## Loading datasets","1b9c7737":"All done.\nwe'd better check if 'Fare' column is worth keeping it or not.","48e94535":"## Replacing missing values","00224d5f":"### Embarked","a9309cc2":"## Preprocessing the test set","1bb8bc3b":"## Categorical Features","7a9230d4":"## Train and Validation split","a0a9310f":"### Age","5c4a547f":"### Survived\/Average Age","bd38a0ef":"### Survived\/Pclass","ea6e24a1":"### Predicting the test set"}}