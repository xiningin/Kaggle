{"cell_type":{"38fa630d":"code","85a0c24c":"code","931cfdf4":"code","d841950b":"code","87e2d459":"code","b5c5efdc":"code","68a3f2f6":"code","3c8f58d9":"code","8b474360":"code","ac764d7a":"code","34806233":"code","b31fe280":"code","8f43be8c":"code","25ff5d1d":"code","9b3ebda6":"code","f1225d8f":"code","89ff747d":"code","53221153":"code","bab89a85":"code","15df9de8":"code","7f4c870b":"code","1e72704a":"code","50e76ae4":"markdown","da2c6c79":"markdown","e9363847":"markdown","6e428192":"markdown","ec53d952":"markdown","2a7cd5a6":"markdown","068a2b03":"markdown","7dea8c60":"markdown","b7474554":"markdown","26f10186":"markdown","baa25060":"markdown","998080c1":"markdown","cf0b790b":"markdown","4412a4f1":"markdown","79ee1f7a":"markdown","8d423899":"markdown"},"source":{"38fa630d":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","85a0c24c":"\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings\nwarnings.filterwarnings('ignore')","931cfdf4":"data = pd.read_csv(\"..\/input\/av-janatahack-machine-learning-in-agriculture\/train_yaOffsB.csv\")\ndata.shape ","d841950b":"data.head(3).append(data.tail(3))\n","87e2d459":"data['ID'].nunique() \n","b5c5efdc":"import missingno as msno\nprint(data.isnull().sum())\n\np = msno.bar(data, figsize = (9,6))","68a3f2f6":"data.info()\n","3c8f58d9":"data['Number_Weeks_Used'].fillna(method = 'ffill', inplace = True)\ndata['Number_Weeks_Used'] = data['Number_Weeks_Used'].astype('int64')\n\n","8b474360":"col = data.columns.tolist()\ncol.remove('ID')\ndata[col].describe(percentiles = [.25,.5,.75,.95,.97,.99])  ","ac764d7a":"data[(data['Season'] == 1) & (data['Crop_Damage'] == 1) & (data['Soil_Type'] == 0)].head() \n","34806233":"pd.DataFrame(data.groupby(['Crop_Damage','Crop_Type'])['Pesticide_Use_Category'].count())\n","b31fe280":"pd.DataFrame(data.groupby(['Crop_Damage','Season','Crop_Type'])['Estimated_Insects_Count'].count())\n","8f43be8c":"\ndf = pd.DataFrame( data[data['Crop_Damage'] == 1 ].mean(), columns = ['Values'])\ndf[ 'Variance'] = pd.DataFrame( data[data['Crop_Damage'] == 1 ].var())\ndf[ 'Standard deviation'] = pd.DataFrame( data[data['Crop_Damage'] == 1 ].std())\ndf[ 'Median'] = pd.DataFrame( data[data['Crop_Damage'] == 1 ].median())\ndf","25ff5d1d":"plt.subplot(1,2,1)\nsns.countplot(x = 'Crop_Damage' , palette= 'cool', data= data) \nplt.title(\"Count plot of Crop damage (target variable)\")\n\nplt.subplot(1,2,2)\ncount = data['Crop_Damage'].value_counts()\ncount.plot.pie(autopct = '%1.1f%%',colors=['green','orange','blue'], figsize = (10,7),explode = [0,0.1,0.1],title = \"Pie chart of Percentage of Crop_Damage\")","9b3ebda6":"plt.figure(figsize = (10,6))\nplt.subplot(1,2,1)\nsns.countplot(x = 'Crop_Type' , palette= 'cool', data= data) \nplt.title(\"Count plot of Crop_Type\")\n\nplt.subplot(1,2,2)\nsns.countplot(data['Crop_Type'], hue = data['Crop_Damage'],palette=\"rocket_r\")\nplt.title(\"Plot of crop damage Vs Crop type\")","f1225d8f":"data[col].hist(figsize=(10,15),color = 'green')\n","89ff747d":"sns.distplot(data['Estimated_Insects_Count'], kde = True, hist = True, bins= 30)\nplt.title(\"Density plot of Estimated_Insects_Count\")","53221153":"\nplt.figure(figsize = (15,5))\nsns.countplot(data['Number_Weeks_Used'], palette = 'hsv')\nplt.title('Count of Number_Weeks_Used')\nplt.show() \nsns.countplot(data['Number_Doses_Week'], palette = 'hsv')\nplt.title('Count of Number_Doses_Week')\nplt.show() ","bab89a85":"\nsns.countplot(data['Pesticide_Use_Category'], palette = 'dark')\nplt.title(\"Count plot of Pesticide_Use_Category\")\nplt.show()\nsns.catplot(x = 'Pesticide_Use_Category', y = 'Estimated_Insects_Count', kind = 'box', data = data, hue = 'Crop_Damage', palette= 'rocket_r')\nplt.title(\"Box plot of Pesticide_Use_Category\")\n","15df9de8":"\nplt.figure(figsize = (10,5))\nplt.subplot(1,2,1)\nsns.countplot(data['Season'], palette = 'hsv')\nplt.title('Count plot of Season')\nplt.subplot(1,2,2)\nsns.countplot(data['Season'], hue = data['Crop_Damage'], palette = 'hsv')\nplt.title('Count plot of Crop_Damage in Seasons')\nplt.show() ","7f4c870b":"import plotly.express as px\n\nfig = px.sunburst(data, path=[ 'Season','Crop_Type'], title=\"Crop type in various seasons\")\n\nfig.show()","1e72704a":"\nsns.countplot(data['Season'], hue = data['Crop_Type'])\nplt.title('Count plot of Crop_type in Seasons')","50e76ae4":"<div class=\"alert alert-danger\">\n<h2><strong>Missing values<\/strong><\/h2>\n<\/div>","da2c6c79":"![image.png](attachment:image.png)","e9363847":"**Inference**\n\n* Crop type 0 has larger data points as compared to the crop type 1\n\n* More than 50000 of the crops of crop type 0 and 20000 of crops of crop type 1 are alive\n\n* There is more damage to crop 0 due to pesticides","6e428192":"\n<h3 style=\"background-color:LightGreen; color:red\" >These are some of the basic analysis that are performed on the data at the first phase, added to this we can also perform correlation analysis as well. In our case we have most of the variables are multilevel categorical variables.We cannot perform Pearson's correlation, this can be carried out by the statistical test such as ANOVA.<\/h3>\n\n<h2 style=\"background-color:LightRed; color:blue\">Hope you find this article helpful. Please upvote ! <\/h2>","ec53d952":"![image.png](attachment:image.png)","2a7cd5a6":"\n\n<h3 style=\"border:2px solid Tomato;\">By the count plot and pie chart we can infer that crop alive category has larger data points as compared to the other two categories. Since this is a multi-class classification problem, this is a clear case of multi-class imbalance problem.<\/h3>","068a2b03":"<div class=\"alert alert-danger\">\n<h2><strong>Filtering the data<\/strong><\/h2>\n<\/div>","7dea8c60":"<div class=\"alert alert-danger\">\n<h2><strong>Library Imports<\/strong><\/h2>\n<\/div>","b7474554":"<div class=\"alert alert-danger\">\n<h2><strong>Summary of data<\/strong><\/h2>\n<\/div>","26f10186":"<h3 style=\"border:2px solid Tomato;\"> Pandas describe() function provides the statistical summary about the data such as mean, max, min, standard deviation, count along with this we can also pass the percentiles where we will be able to get the idea about the outliers in the data.<\/h3>\n\n","baa25060":"<div class=\"alert alert-danger\">\n<h2><strong>View at the dataset<\/strong><\/h2>\n<\/div>","998080c1":"<div class=\"alert alert-danger\">\n<h2><strong>Graphical analysis<\/strong><\/h2>\n<\/div>","cf0b790b":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#libraries\" role=\"tab\" aria-controls=\"profile\">Import Libraries<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#load\" role=\"tab\" aria-controls=\"messages\">Load Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#visual\" role=\"tab\" aria-controls=\"settings\">Missing value treatment<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#word\" role=\"tab\" aria-controls=\"settings\">Summary of data<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#clean\" role=\"tab\" aria-controls=\"settings\">Filtering data<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#split\" role=\"tab\" aria-controls=\"settings\">Graphical analysis<span \n                                                                                                                                                   class=\"badge badge-primary badge-pill\">6<\/span><\/a>","4412a4f1":"<div class=\"alert alert-warning\">  \n<h2><strong>Why exploratory data analysis (EDA) ?<\/strong><\/h2>\n\n\n<p><h4>Exploratory data analysis is an approach to analyze the data. It's where a data enthusiast would be able to get an idea of overall structure of a dataset by bird's eye view. Data science often consist of advanced statistical and machine learning techniques. However, often the power of exploratory data analysis (EDA) is underestimated. In statistics, exploratory data analysis is an approach to analyzing dataset to summarize their main characteristics, often with visual methods. EDA is capable of telling us what kind of statistical techniques or modelling can be applied for the data.\n\nEDA also plays a important role in feature engineering part as well. Having a good idea about the features in the data set, we will be able to create more significant features.\n    <\/h4> <\/p>\n    \n<\/div>","79ee1f7a":"\n<div class=\"alert alert-warning\">  \n<h2><strong>Main purpose of EDA<\/strong><\/h2>\n  \n* ****Check the missing values in data or any irrelevant characters****\n* **Detect the Anomalies\/Outliers in data**\n* **Incorrect Headers of features**\n* **Understand each and every data point by various analysis techniques**\n* **Analyze the relationship between the variables**\n    ","8d423899":"*Here i have used forward fill to impute the missing values just for simplicity, you could use any of the methods such as mean, median , mode etc..or just drop the missing values.*"}}