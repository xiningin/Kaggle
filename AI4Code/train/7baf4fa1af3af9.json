{"cell_type":{"1bc7eb41":"code","4b9d3b43":"code","c786f871":"code","0cf76fe1":"code","f0963ffe":"code","e8316774":"code","6eab1f76":"code","8dd1f471":"code","c5d9cb78":"code","c1286395":"code","bfd0eba2":"code","ae19d97e":"code","021c3976":"code","e3d88d3f":"code","b0cd3f17":"code","0f9ff671":"code","cb534d2c":"code","f7a1ee32":"code","f0879649":"code","04247530":"code","73747ac8":"code","dae560d4":"code","d52e177e":"code","9cf0f1c6":"code","13a596de":"code","a21ed6c4":"code","cb9d54aa":"code","2818cf85":"code","2f723238":"code","0d76df0d":"code","3511bf0b":"code","eba735be":"code","6aa7c835":"code","0686e3fd":"code","768c3d5f":"code","4978aeb0":"code","0ec3efe9":"code","4ba8e2dc":"code","a2c989a0":"code","7500bdad":"code","efde7907":"code","90472845":"code","24e1c732":"code","cba94f84":"code","15e0af0a":"code","5272eaee":"code","37a4ab1d":"code","4410bc20":"code","00e46e18":"code","a1c79e28":"code","cdfe0a7f":"code","4c55506f":"code","e2e2421e":"code","6e16403b":"code","08c5ecbd":"code","511708f6":"code","215bc3ce":"code","fe1f4ac3":"code","cfcddec6":"code","93e69e7b":"code","c6f03e85":"code","f9b6542b":"code","2f14c25f":"code","3d9fbde9":"code","a4ac6dcd":"code","313412a7":"code","84e6a580":"code","981fa3d2":"code","30e11a97":"code","71b7e19f":"code","69ceac98":"code","13964b79":"code","29aa2fa0":"code","410b8e4d":"code","76e91bce":"code","994ab20d":"code","76389daa":"code","1dad99cd":"code","54c8b024":"code","5edbb573":"code","179df5fc":"code","3283749e":"code","70c3a88f":"code","f1e27874":"code","dae91a26":"code","d74a0f57":"code","edde5a1b":"code","a7b2631e":"code","a8c81ac6":"code","95f42c84":"code","75ab4cf0":"code","e8a202bc":"code","4933ea38":"code","dce8d428":"code","6c384e7a":"code","75f7242b":"code","74feedb0":"code","310004cf":"code","076060da":"code","934be0b0":"code","2fbe04d7":"code","84ebb6ed":"markdown","602f984a":"markdown","8a9238ba":"markdown","5e55a2b0":"markdown","ed31a167":"markdown","3940a78a":"markdown","5d171b8f":"markdown","36c72351":"markdown","26a46c27":"markdown","0dc2302d":"markdown","01180e3b":"markdown","9ec1c8e0":"markdown","67ea2705":"markdown","37b609c5":"markdown","5128487c":"markdown","a3071005":"markdown","603ad26a":"markdown","da05c600":"markdown","fe27ebb1":"markdown","43b8aaca":"markdown","a9573747":"markdown","2dfa68df":"markdown","1fb2943e":"markdown","bbe64736":"markdown","6413c6bb":"markdown","32dce6d0":"markdown","19ffff3b":"markdown","3de9deba":"markdown","ea7ee095":"markdown","ac1e583e":"markdown","31e3ab6f":"markdown","f1e22c6a":"markdown","28c6870e":"markdown","e42c7f71":"markdown","0fe8e325":"markdown","037f7727":"markdown","15339964":"markdown","d31fadb9":"markdown","b8a1901a":"markdown","1deee885":"markdown","559b1ca6":"markdown","cf315737":"markdown","86209d1d":"markdown","05aeb054":"markdown","945c232d":"markdown","06a177c4":"markdown","fe9613ea":"markdown","1d374208":"markdown","ca6aa658":"markdown","618c0bfc":"markdown","abb0f884":"markdown","927a2c94":"markdown"},"source":{"1bc7eb41":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b9d3b43":"# Read in King County data file\n\nhousing_df = pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")","c786f871":"housing_df.info()","0cf76fe1":"housing_df.head()","f0963ffe":"housing_df.describe().transpose()","e8316774":"# Plot home price distribution\n\nplt.figure(figsize=(10, 8))\nsns.distplot(housing_df['price'], bins=50, hist_kws=dict(edgecolor=\"white\", linewidth=1))\n\nplt.ticklabel_format(style='plain')","6eab1f76":"# Examine relationship of bedrooms to price\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 8))\n\naxes[0].set_title('Bedrooms Countplot')\nsns.countplot(housing_df['bedrooms'], ax=axes[0], color='maroon')\n\naxes[1].set_title('Bedrooms vs. Price')\nsns.boxplot(x='bedrooms', y='price', data=housing_df, ax=axes[1])\n\nplt.tight_layout()","8dd1f471":"# Plot square feet vs price\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='sqft_living', y='price', data=housing_df).set_title('Square Feet vs. Price')\n\nplt.ticklabel_format(style='plain')","c5d9cb78":"# Map homes, set hue='price' to see geographic distribution of home sales\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='long', y='lat', data=housing_df, hue='price').set_title('King County Home Sales')","c1286395":"# Look at top 50 home sales\n\nhousing_df.sort_values('price', ascending=False).head(50)","bfd0eba2":"# Look at 99th percentile record\n\nnn_perc_index = round(len(housing_df) * 0.01)\n\nnn_perc = housing_df.sort_values('price', ascending=False).iloc[nn_perc_index]['price']\n\nprint(\"99th percentile home price = {}\".format(nn_perc))","ae19d97e":"bottom_99_perc = housing_df.sort_values('price', ascending=False).iloc[nn_perc_index:]","021c3976":"# Re-map homes using bottom 99%, set hue='price', to see geographic distribution of home sales\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='long', y='lat',\n                data=bottom_99_perc, hue='price',\n                palette='RdYlGn', edgecolor=None, alpha=0.2).set_title('King County Home Sales')","e3d88d3f":"# Plot waterfront and view vs price boxplot\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 8))\n\naxes[0].set_title('Waterfront Impact on Price')\nsns.boxplot(x='waterfront', y='price', data=housing_df, ax=axes[0])\n\naxes[1].set_title('View Impact on Price')\nsns.boxplot(x='view', y='price', data=housing_df, ax=axes[1])","b0cd3f17":"housing_df.head()","0f9ff671":"# Drop `id` column\n\nhousing_df = housing_df.drop('id', axis=1)","cb534d2c":"housing_df['date'] = pd.to_datetime(housing_df['date'])","f7a1ee32":"# Extract year\n\nhousing_df['year'] = housing_df['date'].apply(lambda date : date.year)","f0879649":"# Extract month\n\nhousing_df['month'] = housing_df['date'].apply(lambda date : date.month)","04247530":"# Extract day\n\nhousing_df['day'] = housing_df['date'].apply(lambda date : date.day)","73747ac8":"# Plot relationship of year to price\n\nsns.lineplot(x=housing_df['year'].unique(), y=housing_df.groupby('year').mean()['price']).set_title('Year vs. Price')","dae560d4":"# Plot relationship of month to price\n\nmonths = sorted(housing_df['month'].unique())\nmonths_avg_prices = housing_df.groupby('month').mean()['price']\n\nsns.lineplot(x=months, y=months_avg_prices).set_title('Month vs. Price')","d52e177e":"# Plot relationship of day to price\n\ndays = sorted(housing_df['day'].unique())\ndays_avg_prices = housing_df.groupby('day').mean()['price']\n\nsns.lineplot(x=days, y=days_avg_prices).set_title('Day vs. Price')","9cf0f1c6":"# Drop `date`, `day` columns\n\nhousing_df = housing_df.drop(['date', 'day'], axis=1)","13a596de":"housing_df.info()","a21ed6c4":"housing_df['zipcode'].value_counts()","cb9d54aa":"zipcode_data = housing_df.groupby('zipcode').mean()\n\nzipcode_data.sort_values('price', ascending=False)","2818cf85":"# Add average home price for each zipcode function\n\nhousing_df['zipcode_avg'] = housing_df['zipcode'].apply(lambda zipcode : zipcode_data.loc[zipcode]['price'])","2f723238":"# Drop `zipcode` column\n\nhousing_df = housing_df.drop(['zipcode'], axis=1)","0d76df0d":"def most_recent_year(year_built, year_renovated):\n    if year_built > year_renovated:\n        return year_built\n    else:\n        return year_renovated","3511bf0b":"# Explore whether looking at the most recent of the two is more powerful than looking at each one individually\n\nhousing_df['most_recent_work'] = housing_df.apply(lambda x : most_recent_year(x['yr_built'], x['yr_renovated']), axis=1)","eba735be":"# Plot year built, year renovated, and the most recent of the two vs price\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 4))\n\nsns.scatterplot(x='yr_built', y='price', data=housing_df, ax=axes[0])\nsns.scatterplot(x='yr_renovated', y='price', data=housing_df, ax=axes[1])\nsns.scatterplot(x='most_recent_work', y='price', data=housing_df, ax=axes[2])","6aa7c835":"# Drop `most_recent_work` column\n\nhousing_df = housing_df.drop('most_recent_work', axis=1)","0686e3fd":"housing_df[(housing_df['bedrooms'] == 33) | (housing_df['bedrooms'] == 11) | (housing_df['bedrooms'] == 10)]","768c3d5f":"# Drop 33-bedroom home\n\ndrop_index = housing_df[housing_df['bedrooms'] == 33].index\nhousing_df = housing_df.drop(drop_index)","4978aeb0":"X = housing_df.drop('price', axis=1)\ny = housing_df['price']","0ec3efe9":"from sklearn.model_selection import train_test_split","4ba8e2dc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","a2c989a0":"from sklearn.linear_model import LinearRegression","7500bdad":"linear_model = LinearRegression()","efde7907":"linear_model.fit(X_train, y_train)","90472845":"linear_predictions = linear_model.predict(X_test)","24e1c732":"plt.figure(figsize=(12, 8))\nplt.scatter(y_test, linear_predictions)\nplt.plot(y_test, y_test, color='r')","cba94f84":"from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\nfrom math import sqrt","15e0af0a":"linear_score = explained_variance_score(y_test, linear_predictions)\nlinear_mae = mean_absolute_error(y_test, linear_predictions)\nlinear_rmse = sqrt(mean_squared_error(y_test, linear_predictions))\n\nprint(\"Linear Regression Score: {:.4f}\".format(linear_score))\nprint(\"Linear Regression MAE: {:.4f}\".format(linear_mae))\nprint(\"Linear Regression RMSE: {:.4f}\".format(linear_rmse))","5272eaee":"X = housing_df.drop('price', axis=1).values\ny = housing_df['price'].values","37a4ab1d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","4410bc20":"from sklearn.preprocessing import StandardScaler","00e46e18":"x_scaler = StandardScaler()\ny_scaler = StandardScaler()","a1c79e28":"# Transform feature trainging & testing values\nX_train = x_scaler.fit_transform(X_train)\nX_test = x_scaler.transform(X_test)\n\n# Transform target training values\ny_train = y_scaler.fit_transform(y_train.reshape(-1, 1))","cdfe0a7f":"from sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV","4c55506f":"rbf_regressor = SVR(kernel='rbf')","e2e2421e":"# Cross validation parameters\n\nparam_grid = {\n    'C': [1, 5, 10, 15],\n    'gamma': [0.1, 0.01, 0.001]\n}","6e16403b":"rbf_cross_val = GridSearchCV(rbf_regressor, param_grid, n_jobs=-1, verbose=3)","08c5ecbd":"rbf_cross_val.fit(X_train, np.ravel(y_train))","511708f6":"rbf_predictions = rbf_cross_val.predict(X_test)","215bc3ce":"rbf_predictions = y_scaler.inverse_transform(rbf_predictions)","fe1f4ac3":"rbf_score = explained_variance_score(y_test, rbf_predictions)\nrbf_mae = mean_absolute_error(y_test, rbf_predictions)\nrbf_rmse = sqrt(mean_squared_error(y_test, rbf_predictions))\n\nprint(\"RBF Score: {:.4f}\".format(rbf_score))\nprint(\"RBF MAE: {:.4f}\".format(rbf_mae))\nprint(\"RBF RMSE: {:.4f}\".format(rbf_rmse))","cfcddec6":"lin_regressor = SVR(kernel='linear')","93e69e7b":"lin_regressor.fit(X_train, np.ravel(y_train))","c6f03e85":"lin_predictions = lin_regressor.predict(X_test)","f9b6542b":"lin_predictions = y_scaler.inverse_transform(lin_predictions)","2f14c25f":"lin_score = explained_variance_score(y_test, lin_predictions)\nlin_mae = mean_absolute_error(y_test, lin_predictions)\nlin_rmse = sqrt(mean_squared_error(y_test, lin_predictions))\n\nprint(\"Linear Score: {:.4f}\".format(lin_score))\nprint(\"Linear MAE: {:.4f}\".format(lin_mae))\nprint(\"Linear RMSE: {:.4f}\".format(lin_rmse))","3d9fbde9":"poly_regressor = SVR(kernel='poly')","a4ac6dcd":"poly_regressor.fit(X_train, np.ravel(y_train))","313412a7":"poly_predictions = poly_regressor.predict(X_test)","84e6a580":"poly_predictions = y_scaler.inverse_transform(poly_predictions)","981fa3d2":"poly_score = explained_variance_score(y_test, poly_predictions)\npoly_mae = mean_absolute_error(y_test, poly_predictions)\npoly_rmse = sqrt(mean_squared_error(y_test, poly_predictions))\n\nprint(\"Polynomial Score: {:.4f}\".format(poly_score))\nprint(\"Polynomial MAE: {:.4f}\".format(poly_mae))\nprint(\"Polynomial RMSE: {:.4f}\".format(poly_rmse))","30e11a97":"# Print RBF results\nrbf_score = explained_variance_score(y_test, rbf_predictions)\nrbf_mae = mean_absolute_error(y_test, rbf_predictions)\nrbf_rmse = sqrt(mean_squared_error(y_test, rbf_predictions))\n\nprint(\"RBF Score: {:.4f}\".format(rbf_score))\nprint(\"RBF MAE: {:.4f}\".format(rbf_mae))\nprint(\"RBF RMSE: {:.4f}\\n\".format(rbf_rmse))\n\n# Print linear results\nlin_score = explained_variance_score(y_test, lin_predictions)\nlin_mae = mean_absolute_error(y_test, lin_predictions)\nlin_rmse = sqrt(mean_squared_error(y_test, lin_predictions))\n\nprint(\"Linear Score: {:.4f}\".format(lin_score))\nprint(\"Linear MAE: {:.4f}\".format(lin_mae))\nprint(\"Linear RMSE: {:.4f}\\n\".format(lin_rmse))\n\n# Print polynomial results\npoly_score = explained_variance_score(y_test, poly_predictions)\npoly_mae = mean_absolute_error(y_test, poly_predictions)\npoly_rmse = sqrt(mean_squared_error(y_test, poly_predictions))\n\nprint(\"Polynomial Score: {:.4f}\".format(poly_score))\nprint(\"Polynomial MAE: {:.4f}\".format(poly_mae))\nprint(\"Polynomial RMSE: {:.4f}\".format(poly_rmse))","71b7e19f":"fig, ax = plt.subplots(1, 3, figsize=(20, 8))\n\nsns.scatterplot(x=y_test, y=rbf_predictions, ax=ax[0])\nax[0].plot(y_test, y_test, color='r')\nax[0].set_title('RBF SVR Predictions')\nax[0].set_xlabel('Actual Sale Prices')\nax[0].set_ylabel('Predicted Prices')\n\nsns.scatterplot(x=y_test, y=lin_predictions, ax=ax[1])\nax[1].plot(y_test, y_test, color='r')\nax[1].set_title('Linear SVR Predictions')\nax[1].set_xlabel('Actual Sale Prices')\nax[1].set_ylabel('Predicted Prices')\n\nsns.scatterplot(x=y_test, y=poly_predictions, ax=ax[2])\nax[2].plot(y_test, y_test, color='r')\nax[2].set_title('Polynomial SVR Predictions')\nax[2].set_xlabel('Actual Sale Prices')\nax[2].set_ylabel('Predicted Prices')","69ceac98":"X = housing_df.drop('price', axis=1).values\ny = housing_df['price'].values","13964b79":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","29aa2fa0":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV","410b8e4d":"rand_forest = RandomForestRegressor(n_estimators=300)","76e91bce":"rand_forest.fit(X_train, y_train)","994ab20d":"rand_forest_predictions = rand_forest.predict(X_test)","76389daa":"rand_forest_score = explained_variance_score(y_test, rand_forest_predictions)\nrand_forest_mae = mean_absolute_error(y_test, rand_forest_predictions)\nrand_forest_rmse = sqrt(mean_squared_error(y_test, rand_forest_predictions))\n\nprint(\"Random Forest Score: {:.4f}\".format(rand_forest_score))\nprint(\"Random Forest MAE: {:.4f}\".format(rand_forest_mae))\nprint(\"Random Forest RMSE: {:.4f}\\n\".format(rand_forest_rmse))","1dad99cd":"rf_rand = RandomForestRegressor()","54c8b024":"# Number of trees\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n\n# Number of features at every split\nmax_features = ['auto', 'sqrt', 'log2']\n\n# Max levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\nmax_depth.append(None)\n\n# Min samples to split node\nmin_samples_split = [2, 5, 10]\n\n# Min samples at each leaf\nmin_samples_leaf = [1, 2, 4]\n\n# Bootstrapping\nbootstrap = [True, False]\n\nrandom_param_grid = {\n    'n_estimators': n_estimators,\n    'max_features': max_features,\n    'max_depth': max_depth,\n    'min_samples_split': min_samples_split,\n    'min_samples_leaf': min_samples_leaf,\n    'bootstrap': bootstrap\n}\n\nprint(random_param_grid)","5edbb573":"rf_rand_regressor = RandomizedSearchCV(rf_rand, random_param_grid, cv=3, verbose=3, n_jobs=-1)","179df5fc":"rf_rand_regressor.fit(X_train, y_train)","3283749e":"rf_rand_predictions = rf_rand_regressor.predict(X_test)","70c3a88f":"rf_rand_score = explained_variance_score(y_test, rf_rand_predictions)\nrf_rand_mae = mean_absolute_error(y_test, rf_rand_predictions)\nrf_rand_rmse = sqrt(mean_squared_error(y_test, rf_rand_predictions))\n\nprint(\"Randomized RF Score: {:.4f}\".format(rf_rand_score))\nprint(\"Randomized RF MAE: {:.4f}\".format(rf_rand_mae))\nprint(\"Randomized RF RMSE: {:.4f}\".format(rf_rand_rmse))","f1e27874":"fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n\nsns.scatterplot(x=y_test, y=rand_forest_predictions, ax=ax[0])\nax[0].plot(y_test, y_test, color='r')\nax[0].set_title('Standard RF Predictions')\nax[0].set_xlabel('Actual Sale Prices')\nax[0].set_ylabel('Predicted Prices')\n\nsns.scatterplot(x=y_test, y=rf_rand_predictions, ax=ax[1])\nax[1].plot(y_test, y_test, color='r')\nax[1].set_title('Randomized CV RF Predictions')\nax[1].set_xlabel('Actual Sale Prices')\nax[1].set_ylabel('Predicted Prices')","dae91a26":"# Print standard RF results\nrand_forest_score = explained_variance_score(y_test, rand_forest_predictions)\nrand_forest_mae = mean_absolute_error(y_test, rand_forest_predictions)\nrand_forest_rmse = sqrt(mean_squared_error(y_test, rand_forest_predictions))\n\nprint(\"Random Forest Score: {:.4f}\".format(rand_forest_score))\nprint(\"Random Forest MAE: {:.4f}\".format(rand_forest_mae))\nprint(\"Random Forest RMSE: {:.4f}\\n\".format(rand_forest_rmse))\n\n# Print cross-validated RF results\nrf_rand_score = explained_variance_score(y_test, rf_rand_predictions)\nrf_rand_mae = mean_absolute_error(y_test, rf_rand_predictions)\nrf_rand_rmse = sqrt(mean_squared_error(y_test, rf_rand_predictions))\n\nprint(\"Randomized RF Score: {:.4f}\".format(rf_rand_score))\nprint(\"Randomized RF MAE: {:.4f}\".format(rf_rand_mae))\nprint(\"Randomized RF RMSE: {:.4f}\".format(rf_rand_rmse))","d74a0f57":"X = housing_df.drop('price', axis=1).values\ny = housing_df['price'].values","edde5a1b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","a7b2631e":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42 )","a8c81ac6":"from sklearn.preprocessing import MinMaxScaler","95f42c84":"scaler = MinMaxScaler()","75ab4cf0":"X_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)","e8a202bc":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam","4933ea38":"X_train.shape","dce8d428":"model = Sequential()\n\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(5, activation='relu'))\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mse')\n\nearlystop = EarlyStopping(monitor='val_loss', min_delta=250000, patience=50)","6c384e7a":"model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val),\n          callbacks=[earlystop], batch_size=128, epochs=4000)","75f7242b":"losses = pd.DataFrame(model.history.history)","74feedb0":"losses.plot()","310004cf":"nn_predictions = model.predict(X_test)","076060da":"plt.figure(figsize=(12, 8))\nplt.scatter(y_test, nn_predictions)\nplt.plot(y_test, y_test, color='r')","934be0b0":"nn_score = explained_variance_score(y_test, nn_predictions)\nnn_mae = mean_absolute_error(y_test, nn_predictions)\nnn_rmse = sqrt(mean_squared_error(y_test, nn_predictions))\n\nprint(\"Neural Network Score: {:.4f}\".format(nn_score))\nprint(\"Neural Network MAE: {:.4f}\".format(nn_mae))\nprint(\"Neural Network RMSE: {:.4f}\".format(nn_rmse))","2fbe04d7":"print(\"==========================================\")\nprint(\"Linear Regression Results:\\n\")\nprint(\"Explained Varaince Score = {:.4f}\".format(linear_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(linear_mae))\nprint(\"Root Mean Squared Error = {:.4f}\".format(linear_rmse))\nprint(\"==========================================\")\nprint(\"Support Vector Regression Results:\\n\")\nprint(\"RBF Kernel:\")\nprint(\"Explained Variance Score = {:.4f}\".format(rbf_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(rbf_mae))\nprint(\"Root Mean Squared Error = {:.4f}\\n\".format(rbf_rmse))\nprint(\"Linear Kernel:\")\nprint(\"Explained Variance Score = {:.4f}\".format(lin_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(lin_mae))\nprint(\"Root Mean Squared Error = {:.4f}\\n\".format(lin_rmse))\nprint(\"Polynomial Kernel:\")\nprint(\"Explained Variance Score = {:.4f}\".format(poly_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(poly_mae))\nprint(\"Root Mean Squared Error = {:.4f}\".format(poly_rmse))\nprint(\"==========================================\")\nprint(\"Random Forest Regression Results:\\n\")\nprint(\"Standard Random Forest:\")\nprint(\"Explained Variance Score = {:.4f}\".format(rand_forest_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(rand_forest_mae))\nprint(\"Root Mean Squared Error = {:.4f}\\n\".format(rand_forest_rmse))\nprint(\"Randomized CV Random Forest:\")\nprint(\"Randomized RF Score: {:.4f}\".format(rf_rand_score))\nprint(\"Randomized RF MAE: {:.4f}\".format(rf_rand_mae))\nprint(\"Randomized RF RMSE: {:.4f}\".format(rf_rand_rmse))\nprint(\"==========================================\")\nprint(\"Neural Network Results:\\n\")\nprint(\"Explained Variance Score = {:.4f}\".format(nn_score))\nprint(\"Mean Absolute Error = {:.4f}\".format(nn_mae))\nprint(\"Root Mean Squared Error = {:.4f}\".format(nn_rmse))\nprint(\"==========================================\")","84ebb6ed":"**Notes:**\n* Homes mostly concentrated in 2-4 bedroom range\n* High variance in bedroom number vs. price\n* There apparently are 10, 11, and 33-bedroom homes, but median prices of these homes do not seem very high. This may be an error in the data","602f984a":"# Summarize Results","8a9238ba":"**Notes:**\n* Predictably, a pretty good correlation between living space and price","5e55a2b0":"### Linear Kernel","ed31a167":"# Support vector regression","3940a78a":"# Exploratory data analysis","5d171b8f":"### Extract date features","36c72351":"### Explore year built vs. year renovated... whether either has strong predictive power","26a46c27":"### Evaluate model","0dc2302d":"### Build model","01180e3b":"### Create randomized cross-validation model","9ec1c8e0":"Cannot think of any other features to engineer at this time... Let's move on to building our model","67ea2705":"### Train test split","37b609c5":"### Make predictions","5128487c":"Some of these records seem like bad data.\n* 33 bedrooms, 1.75 bathrooms, only 1600 sq ft, and a \\\\$640K sale price... Seems wrong. Let's drop it.\n* Skeptical of others as well, but going to leave them for now","a3071005":"### Train test split","603ad26a":"### Difficult to distinguish most home prices because prices have such a long tail on the high end... Find an appropriate cut-off point where we can reduce the number of outliers without sacrificing too much data. And maybe use a better color scheme.","da05c600":"**Notes:**\n* Fairly normal distribution\n* Long tail on the high end","fe27ebb1":"Not helpful... drop `most_recent_work` column","43b8aaca":"### Evaluate models","a9573747":"**Notes:**\n* Predictably, having a waterfront property or a better view appears to correlate with higher prices","2dfa68df":"Notes:\n* RBF using cross validation has best explained variance score by far\n* Other models might work with cross validation as well, but model fitting is far too slow\n* Manually tested some different hyperparameter combinations for the others, and I think it's unlikely that either will outperform RBF","1fb2943e":"### Too many values for dummy variables... convert zipcode to ordinal values by replacing with zipcode average home price","bbe64736":"# Linear regression","6413c6bb":"# Neural network","32dce6d0":"### Evaluate model","19ffff3b":"### Train model","3de9deba":"### Train model","ea7ee095":"## Plot homes using latitude & longitude","ac1e583e":"### Scale data","31e3ab6f":"### Polynomial Kernel","f1e22c6a":"**Notes:**\n* Record volume appears to start increasing around \\\\$3.0M - \\\\$3.5M, in accordance with the histplot shown above.","28c6870e":"### Evaluate models","e42c7f71":"**Notes:**\n* Strong relationship between year and price (there are only two years represented in this dataset)\n* Looks like there could be some relationship between month and price\n* There does not seem to be any relationship between day and price... drop `day` column","0fe8e325":"### Build model","037f7727":"### Make predictions","15339964":"## Examine the distribution of prices and how they relate to various other property attributes, e.g. bedrooms, sq ft, etc.","d31fadb9":"### Look for bad data","b8a1901a":"### Create standard random forest","1deee885":"### Zipcode is a categorical variable, so we cannot feed it into our model as is... Extract zipcode features","559b1ca6":"### RBF Kernel","cf315737":"### Build models","86209d1d":"### Build model","05aeb054":"### Train test split","945c232d":"### 99th percentile appears to be right around where the tail really starts to go long --> rerun geographic analysis using bottom 99% of data","06a177c4":"# Feature engineering","fe9613ea":"`id` column appears to be just random numbers... drop `id` column","1d374208":"**Notes:**\n* There appears to be pretty high concentration among high-priced homes \n* Many of the areas where high-price homes are concentrated appear to be on the water","ca6aa658":"### Train test split","618c0bfc":"# Random forest","abb0f884":"### Scale data","927a2c94":"**Notes:**\n* 21 columns\n    * Almost all numerical (date = only object column) \n    * Most look useful\n    * No NULL values"}}