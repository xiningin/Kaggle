{"cell_type":{"b1f50cc6":"code","30a890d5":"code","2f021758":"code","ada67381":"code","56596d40":"code","9283842d":"code","4252c44b":"code","a5055700":"code","4d17dcf6":"code","303c4c9f":"markdown","529c3525":"markdown","acdefb9f":"markdown","69719763":"markdown"},"source":{"b1f50cc6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tensorflow import keras\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","30a890d5":"IM_SIZE = 256","2f021758":"model = keras.models.load_model('..\/input\/effect0-brain\/Brain_flair_model_effect.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})","ada67381":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    #data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef get_prediction_per_case(patient):\n    \n    path = f'..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{patient}\/FLAIR\/'\n\n    list_subfolders_with_paths = [f for f in os.listdir(path)]\n    \n    prediction = []\n    \n    for images in list_subfolders_with_paths:\n        \n            \n        img = read_xray(path+images)\n                       \n        if np.max(img) > 0 and np.mean(img)>= 0.015:\n                \n                \n            img =  cv2.resize(img,(IM_SIZE,IM_SIZE))\n            \n            img = cv2.merge((img,img,img))\n            img = tf.reshape(img, (-1, IM_SIZE, IM_SIZE, 3))\n            \n            pred = model.predict(img)\n            \n            prediction.append(pred)\n    \n    return np.mean(prediction,axis=0)[0][0]","56596d40":"get_prediction_per_case('00047')","9283842d":"df = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv',dtype=\"string\")","4252c44b":"df['MGMT_value'] = df['BraTS21ID'].apply(get_prediction_per_case)","a5055700":"#df['MGMT_value'] = df['MGMT_value'].apply(lambda x: rd.uniform(0, 1))\ndf[['BraTS21ID', 'MGMT_value']].to_csv('submission.csv', index = False)","4d17dcf6":"df","303c4c9f":"# Training\n\nThis notebooke was used for training:\n\nhttps:\/\/www.kaggle.com\/lucamtb\/brain-tumer-train-class-flair","529c3525":"## Parameters","acdefb9f":"## Model","69719763":"## Some function"}}