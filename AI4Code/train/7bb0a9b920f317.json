{"cell_type":{"efcd2f00":"code","c8d7c237":"code","cae7257c":"code","be455ca9":"code","1de236e3":"code","aef206b4":"code","4b1c9998":"code","96bef782":"code","6e92382c":"code","8b37b326":"code","05adb89c":"code","56b6f4db":"code","4a7ab2b4":"code","f2cbe715":"code","a361a2b1":"code","beb6ec0f":"code","dc05c06e":"code","72e5593e":"code","6649196c":"code","846f7263":"code","caa266aa":"code","be7901c5":"code","66825dd7":"code","1d0539f6":"code","5ff3330a":"code","730a144c":"code","20391f3f":"code","1ea461e6":"code","17092e99":"code","1cba2cc8":"code","9eb99c8b":"code","724e92df":"code","271cb3b6":"code","4634f978":"code","20f7bfde":"code","67442c0b":"code","a1e98902":"code","88981210":"code","8c1501b1":"code","3b48b664":"code","1e428edc":"code","0d1eaaed":"code","a13535a8":"code","7ce50c46":"code","06cf7a02":"code","cff09bcc":"code","13978ecc":"code","bb510c97":"markdown","d9925ad2":"markdown","29ba6b9f":"markdown","35fef5db":"markdown","1d10520c":"markdown","ce726592":"markdown","271ee397":"markdown","32a02fab":"markdown","17cd42fd":"markdown","d609676f":"markdown","0b7e67a9":"markdown","70e2bbbd":"markdown","51fdf696":"markdown","8fa577b6":"markdown","ca26c0f3":"markdown","c0568035":"markdown"},"source":{"efcd2f00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c8d7c237":"#Dataset url: https:\/\/grouplens.org\/datasets\/movielens\/latest\/\n! ls ..\/input","cae7257c":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ntext = [\"London Paris London\",\"Paris Paris London\"]\n","be455ca9":"cv = CountVectorizer()\ncount_matrix = cv.fit_transform(text)\ncount_matrix.toarray()","1de236e3":"similarity_scores = cosine_similarity(count_matrix)\nprint(similarity_scores)","aef206b4":"# importing the dataset\nimport pandas as pd\n \nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\n \n# this is a very toy example, do not try this at home unless you want to understand the usage differences\ndocs=[\"the house had a tiny little mouse\",\n      \"the cat saw the mouse\",\n      \"the mouse ran away from the house\",\n      \"the cat finally ate the mouse\",\n      \"the end of the mouse story\"\n     ]","4b1c9998":" \n#instantiate CountVectorizer()\ncv=CountVectorizer()\n \n# this steps generates word counts for the words in your docs\nword_count_vector=cv.fit_transform(docs)\nword_count_vector.toarray()","96bef782":"word_count_vector.shape","6e92382c":"#compute IDF Values\n \ntfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\ntfidf_transformer.fit(word_count_vector) ","8b37b326":"\n# print idf values\ndf_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"])\n \n# sort ascending\ndf_idf.sort_values(by=['idf_weights'])","05adb89c":"#With Tfidfvectorizer you compute the word counts, idf and tf-idf values all at once. It\u2019s really simple\nfrom sklearn.feature_extraction.text import TfidfVectorizer#With Tfidfvectorizer you compute the word counts, idf and tf-idf values all at once. It\u2019s really simple\ntfidf_vectorizer=TfidfVectorizer(use_idf=True)\n \n# just send in all your docs here\nfitted_vectorizer=tfidf_vectorizer.fit(docs)\ntfidf_vectorizer_vectors=fitted_vectorizer.transform(docs)","56b6f4db":"import pandas as pd\nimport numpy as np","4a7ab2b4":"credits = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")\nmovies_df = pd.read_csv(\"..\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")","f2cbe715":"credits.head()","a361a2b1":"movies_df.head()","beb6ec0f":"print(\"Credits:\",credits.shape)\nprint(\"Movies Dataframe:\",movies_df.shape)","dc05c06e":"credits_column_renamed = credits.rename(index=str, columns={\"movie_id\": \"id\"})\nmovies_df_merge = movies_df.merge(credits_column_renamed, on='id')\nmovies_df_merge.head()","72e5593e":"movies_cleaned_df = movies_df_merge.drop(columns=['homepage', 'title_x', 'title_y', 'status','production_countries'])\nmovies_cleaned_df.head()","6649196c":"movies_cleaned_df.info()","846f7263":"movies_cleaned_df.head(1)['overview']","caa266aa":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\nmovies_cleaned_df['overview'] = movies_cleaned_df['overview'].fillna('')","be7901c5":"tfv_matrix = tfv.fit_transform(movies_cleaned_df['overview'])\ntfv_matrix.shape","66825dd7":"from sklearn.metrics.pairwise import sigmoid_kernel\n\n# Compute the sigmoid kernel\nsig = sigmoid_kernel(tfv_matrix, tfv_matrix)","1d0539f6":"# Reverse mapping of indices and movie titles\nindices = pd.Series(movies_cleaned_df.index, index=movies_cleaned_df['original_title']).drop_duplicates()","5ff3330a":"indices","730a144c":"indices['Newlyweds']","20391f3f":"sig[4799]","1ea461e6":"list(enumerate(sig[indices['Newlyweds']]))","17092e99":"def give_rec(title, sig=sig):\n    # Get the index corresponding to original_title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores \n    sig_scores = list(enumerate(sig[idx]))\n\n    # Sort the movies in the decending order on basis of similarity score \n    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n\n    # Scores of the 10 most similar movies\n    sig_scores = sig_scores[1:11]\n\n    # Movie indices\n    movie_indices = [i[0] for i in sig_scores]\n\n    # Top 10 most similar movies\n    return movies_cleaned_df['original_title'].iloc[movie_indices]","1cba2cc8":"# Testing our content-based recommendation system with the seminal film Spy Kids\ngive_rec('Avatar')","9eb99c8b":"! ls ..\/input\/movie-rating","724e92df":"import pandas as pd\nimport numpy as np","271cb3b6":"movies_df = pd.read_csv('..\/input\/movie-rating\/movies.csv',usecols=['movieId','title'],dtype={'movieId': 'int32', 'title': 'str'})\nrating_df=pd.read_csv('..\/input\/movie-rating\/ratings.csv',usecols=['userId', 'movieId', 'rating'],\n    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})","4634f978":"movies_df.head()","20f7bfde":"rating_df.head()","67442c0b":"#mering dataset on bbased on movie_id\n\ndf = pd.merge(rating_df,movies_df,on='movieId')\ndf.head()","a1e98902":"\ncombine_movie_rating = df.dropna(axis = 0, subset = ['title'])\nmovie_ratingCount = (combine_movie_rating.groupby(by = ['title'])['rating'].count().reset_index().rename(columns = {'rating': 'totalRatingCount'})\n     [['title', 'totalRatingCount']]\n    )\nmovie_ratingCount.head()","88981210":"rating_with_totalRatingCount = combine_movie_rating.merge(movie_ratingCount, left_on = 'title', right_on = 'title', how = 'left')\nrating_with_totalRatingCount.head()","8c1501b1":"\nprint(movie_ratingCount['totalRatingCount'].describe())","3b48b664":"popularity_threshold = 50\nrating_popular_movie= rating_with_totalRatingCount.query('totalRatingCount >= @popularity_threshold')\nrating_popular_movie.head()","1e428edc":"rating_popular_movie.shape","0d1eaaed":"\n## First lets create a Pivot matrix\n\nmovie_features_df=rating_popular_movie.pivot_table(index='title',columns='userId',values='rating').fillna(0)\nmovie_features_df.head()\n","a13535a8":"from scipy.sparse import csr_matrix\n\nmovie_features_df_matrix = csr_matrix(movie_features_df.values)\n\nfrom sklearn.neighbors import NearestNeighbors\n\n\nmodel_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\nmodel_knn.fit(movie_features_df_matrix)","7ce50c46":"movie_features_df.shape","06cf7a02":"query_index = np.random.choice(movie_features_df.shape[0])\nprint(query_index)\ndistances, indices = model_knn.kneighbors(movie_features_df.iloc[query_index,:].values.reshape(1, -1), n_neighbors = 6)","cff09bcc":"movie_features_df.head()","13978ecc":"\nfor i in range(0, len(distances.flatten())):\n    if i == 0:\n        print('Recommendations for {0}:\\n'.format(movie_features_df.index[query_index]))\n    else:\n        print('{0}: {1}, with distance of {2}:'.format(i, movie_features_df.index[indices.flatten()[i]], distances.flatten()[i]))","bb510c97":"**TfidfVectorizer short tutorial**\n\nFor more information check belwo link: \n\nhttps:\/\/kavita-ganesan.com\/tfidftransformer-tfidfvectorizer-usage-differences\/#.Xc4cwdIzbtQ","d9925ad2":"**Recommendation system**\n\nA recommendation engine filters the data using different algorithms and recommends the most relevant items to users. It first captures the past behavior of a customer and based on that, recommends products which the users might be likely to buy.","29ba6b9f":"**CountVectorizer and cosine_similarity**","35fef5db":"**Content Based Recommender System Working**\n\nfor more information\nhttps:\/\/www.academyofdatascience.com\/blog-by-prashant\/","1d10520c":"**\u25cf Popularity Based Recommender System**\n\nPopularity based recommender system recommends the most popular items to the users. Most popular items is the item that is used by most number of users. For example, youtube trending list recommends the most popular videos of the day.\n\n\n**\u25cf Content Based Recommender System**\n\n Content based recommender systems recommends similar items used by the user in the past.\nFor example, Netflix recommends us the similar movies to the movie we recently watched.\nSimilarly, Youtube also recommends us similar videos to the videos in our watch history.\n\n\n**\u25cf Collaborative Filtering based Recommender System**\n\nCollaborative Filtering based recommender system creates profiles of users based on the items the user likes. Then it recommends the items liked by a user to the user with similar profile.\n\nFor example, Google creates our profile based on our browsing history and then shows us the relevant ads\n\n\nNow we\u2019ll be building a Content Based Hollywood movie recommender system in Python programming language.","ce726592":"Drpping unnecessary columns from dataframe","271ee397":"**Nearest Neighbor item based Collaborative Filtering**","32a02fab":"Notice that the words \u2018mouse\u2019 and \u2018the\u2019 have the lowest IDF values. This is expected as these words appear in each and every document in our collection. The lower the IDF value of a word, the less unique it is to any particular document","17cd42fd":"renaming movies_id columns to id in credits datatframe and mering it to movies_df dataframe","d609676f":"let\u2019s check the shape. We should have 5 rows (5 docs) and 16 columns (16 unique words, minus single character words):","0b7e67a9":"**Tfidftransformer vs. Tfidfvectorizer**\n\n\nWith Tfidftransformer you will systematically compute word counts using CountVectorizer and then compute the Inverse Document Frequency (IDF) values and only then compute the Tf-idf scores.\n\nWith Tfidfvectorizer on the contrary, you will do all three steps at once. Under the hood, it computes the word counts, IDF values, and Tf-idf scores all using the same dataset.","70e2bbbd":"For average weight recommendation system check below kernel. \n\nhttps:\/\/www.kaggle.com\/uttam94\/average-weight-recommedation-system","51fdf696":"If you like the kernel,please share and upvote the kernel .","8fa577b6":"Now lets make a recommendations based on the movie\u2019s plot summaries given in the overview column. So if our user gives us a movie title, our goal is to recommend movies that share similar plot summaries.","ca26c0f3":"Scikit-learn\u2019s Tfidftransformer and Tfidfvectorizer aim to do the same thing, which is to convert a collection of raw documents to a matrix of TF-IDF features. The differences between the two modules can be quite confusing and it\u2019s hard to know when to use which. This article shows you how to correctly use each module, the differences between the two and some guidelines on what to use when.","c0568035":"**Types of Recommender System**\n\nThere are basically two main components of any recommendation system, Users and Items. Items are the entities that are recommended by the recommender system to the users. Let\u2019s understand by taking some examples.\n\nNetflix recommends movies to the people, hence movies are items and people are users, while Facebook recommends the people you may know to the people, here people are users and people are items too.\n\nThere are three types of recommender systems that are mostly used:"}}