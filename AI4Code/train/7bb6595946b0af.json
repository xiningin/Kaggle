{"cell_type":{"49b749fd":"code","76ef3be8":"code","0cd14689":"code","475f39ea":"code","bc19c7ab":"code","0679018d":"code","9766248b":"code","700158ca":"code","f6bcbc3b":"code","913f5a1b":"code","78e6049e":"code","9192da94":"code","5ee0d316":"code","5bd1add4":"code","45ebe7dc":"code","0eca33e6":"code","ef05bce4":"code","342e9338":"markdown","1e4bbcb2":"markdown","78dca94f":"markdown","a57965b9":"markdown","84751816":"markdown","5c2c04b9":"markdown","6663749c":"markdown","81bf5be7":"markdown"},"source":{"49b749fd":"import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dropout \nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import concatenate\n\n","76ef3be8":"import os \nimport numpy as np \nimport pandas as pd \nimport imageio \nimport matplotlib.pyplot as plt \n%matplotlib inline \n\npath =''\nimage_path = os.path.join(path,'..\/input\/semantic-drone-dataset\/dataset\/semantic_drone_dataset\/original_images\/')\nmask_path = os.path.join(path,'..\/input\/semantic-drone-dataset\/dataset\/semantic_drone_dataset\/label_images_semantic\/')\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]\nimage_list = sorted(image_list)\nmask_list = sorted(mask_list)\n\nprint(\"number of images is : {} \".format(len(image_list)))\n\nprint(image_list[0])\nprint(mask_list[0])","0cd14689":"n = 10 # you can chose any index \nimg  = imageio.imread(image_list[n])\nprint(img.shape)\nmask = imageio.imread(mask_list[n])\nprint(mask.shape)\n\n# now let's plot \nfig ,arr  = plt.subplots(1,2,figsize=(15,10))\narr[0].imshow(img)\narr[0].set_title('Original Image')\narr[1].imshow(mask)\narr[1].set_title('Mask')","475f39ea":"image_list_dataset = tf.data.Dataset.list_files(image_list ,shuffle=False)\nmask_list_dataset = tf.data.Dataset.list_files(mask_list , shuffle=False)\nimages_filenames = tf.constant(image_list)\nmasks_filenames = tf.constant(mask_list)\n\ndataset = tf.data.Dataset.from_tensor_slices((images_filenames\n                                              ,masks_filenames))\nfor image,mask in dataset.take(1) : \n    print(image)\n    print(mask)","bc19c7ab":"def process_path(image_path,mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img,channels=3)\n    img = tf.image.convert_image_dtype(img,tf.float32) #this do the same as dividing by 255 to set the values between 0 and 1 (normalization)\n    \n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask,channels=3)\n    mask = tf.math.reduce_max(mask,axis=-1,keepdims=True)\n    return img , mask\n\ndef preprocess(image,mask) : \n    input_image = tf.image.resize(image,(96,128),method='nearest')\n    input_mask = tf.image.resize(mask,(96,128),method='nearest')\n    \n    return input_image , input_mask\n\nimage_ds = dataset.map(process_path) # apply the preprocces_path function to our dataset\nprint(image_ds)\nprocessed_image_ds = image_ds.map(preprocess) # apply the preprocess function to our dataset","0679018d":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \n    conv = Conv2D(n_filters, \n                  kernel_size = 3,     \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n    conv = Conv2D(n_filters, \n                  kernel_size = 3, \n                  activation='relu',\n                  padding='same',\n                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n   \n    \n\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n        \n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n        \n        \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection","9766248b":"def upsampling_block(expansive_input, contractive_input, n_filters=32):\n    \n    up = Conv2DTranspose(\n                 n_filters,  \n                 kernel_size = 3,\n                 strides=(2,2),\n                 padding='same')(expansive_input)\n    \n    merge = concatenate([up, contractive_input], axis=3)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,   \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n    conv = Conv2D(n_filters,  \n                 kernel_size = 3,  \n                 activation='relu',\n                 padding='same',\n                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n    \n    \n    return conv","700158ca":"def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n    \n    inputs = Input(input_size)\n    \n    #contracting path\n    cblock1 = conv_block(inputs, n_filters)\n    cblock2 = conv_block(cblock1[0], 2*n_filters)\n    cblock3 = conv_block(cblock2[0], 4*n_filters)\n    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.3) \n    cblock5 = conv_block(cblock4[0],16*n_filters, dropout_prob=0.3, max_pooling=None)     \n    \n    #expanding path\n    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n    \n    conv10 = Conv2D(n_classes, kernel_size=1, padding='same')(conv9)  \n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model","f6bcbc3b":"img_height = 96\nimg_width = 128\nnum_channels = 3\n\nunet = unet_model((img_height, img_width, num_channels))","913f5a1b":"unet.summary()","78e6049e":"unet.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","9192da94":"EPOCHS = 150\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 500\nBATCH_SIZE = 16\nprocessed_image_ds.batch(BATCH_SIZE)\ntrain_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(processed_image_ds.element_spec)\nmodel_history = unet.fit(train_dataset, epochs=EPOCHS)","5ee0d316":"plt.plot(model_history.history[\"accuracy\"])","5bd1add4":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","45ebe7dc":"def create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","0eca33e6":"def show_predictions(dataset=None, num=1):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = unet.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])","ef05bce4":"show_predictions(train_dataset, 6)","342e9338":"# 1. Our model is ready !!","1e4bbcb2":"# 4. preprocessing our data","78dca94f":"# 3. explore some images :","a57965b9":"# 5.  Define The Conv Block For The Contracting Path\n","84751816":"# 2. load and split the data ","5c2c04b9":"# 6. Define the upsampling block for the expanding path","6663749c":"# 1. import the necessery libraries\n","81bf5be7":"# 7. Finally! ,  we will Define the unet model \n## which composes of a set of conv blocks and upsampling blocks"}}