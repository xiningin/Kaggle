{"cell_type":{"118da8a3":"code","37717957":"code","0070aa72":"code","003e4c97":"code","e269016b":"code","ec3668ac":"code","3b2a5c3e":"code","5ae57ddf":"code","cd26f481":"code","d7ae8f3a":"code","662a43d2":"code","682cefcf":"code","6a96abba":"code","72f40178":"code","6bdd25eb":"code","77183f0b":"code","c241405f":"code","9bcebd12":"code","92ccf41b":"code","2a1a4b17":"code","d13ee4ea":"code","da3cccce":"code","3182dedb":"code","c2d2aae9":"code","3c7a18ad":"code","21284e00":"code","05ce2447":"code","41c55dbd":"code","b97556fe":"code","e9bf3b83":"code","2bd959fc":"code","fb39b7e8":"code","1b31e76e":"code","d6760ada":"code","82b982e8":"code","7498155f":"code","48f3de81":"code","5801cd14":"code","de03663a":"code","879a2737":"code","603cfd00":"code","d8e9d9f0":"code","4fe45896":"code","e7726422":"code","f4ce4ae3":"code","06e210c3":"code","1dce42e2":"code","30f1a063":"code","3519f378":"code","e53b4712":"code","9b5051bb":"code","bd33c3fd":"code","83ce432a":"code","659db261":"code","5602f731":"markdown","04d9192e":"markdown","ac44b7ed":"markdown","0f99ef17":"markdown","87758f05":"markdown","c99c4f5d":"markdown","1b452b1b":"markdown","40d936f3":"markdown","d1805129":"markdown","6e135754":"markdown","c18a6f27":"markdown","c5b71582":"markdown","ef5843ed":"markdown","f24b1490":"markdown","da1473ab":"markdown","b293893e":"markdown","30dc0e34":"markdown","38c579da":"markdown","57c630a2":"markdown","70ffdddc":"markdown","f7a1c4af":"markdown","95233e13":"markdown","c987cd16":"markdown","3dfdfe2e":"markdown","545bda14":"markdown","fd96073f":"markdown","7dff3592":"markdown","1e748151":"markdown","cac595e5":"markdown","67a21353":"markdown","14e9d3b8":"markdown","a427200a":"markdown","104484d6":"markdown","a29f7f7e":"markdown","f0b5aed4":"markdown","f7461dd1":"markdown","0a729e8e":"markdown","dab9c59c":"markdown","036ea69c":"markdown","51657d4b":"markdown","11b9f619":"markdown","7d6c7c7d":"markdown","d0ff0028":"markdown","ee710ce1":"markdown","0502678c":"markdown","970e42d1":"markdown"},"source":{"118da8a3":"from IPython.display import Image\nImage(\"\/kaggle\/input\/new-york-city-airbnb-open-data\/New_York_City_.png\")","37717957":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0070aa72":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression,LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error","003e4c97":"data=pd.read_csv(\"\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv\")\ndata.head(2)","e269016b":"data.info()","ec3668ac":"len(data.columns),len(data)\n\n# here we 16 columns and 48895 rows","3b2a5c3e":"data.dtypes","5ae57ddf":"data.drop([\"host_name\",\"name\"],axis=1,inplace=True)","cd26f481":"data_num=data.select_dtypes(include=[int,float])   # since we have no float dtype column in dataframe\n","d7ae8f3a":"def detect_outlier(col):\n    outlier=[]\n    threshold=3\n    mean=np.mean(col)\n    stdeviation=np.std(col)\n    \n    for i in col:\n        z_score=(i-mean)\/\/stdeviation\n        if z_score > threshold:\n            outlier.append(i)\n    \n    return outlier","662a43d2":"dict_for_numerical_columns={}\nfor i in data_num.columns:\n    # intialising the dictionary\n    dict_for_numerical_columns[i]=0   \nfor i in dict_for_numerical_columns:\n    # sending each and every column in data_num\n    l=detect_outlier(data_num[i])      \n    dict_for_numerical_columns[i]=l\n\nprint(dict_for_numerical_columns)\n\n# from this, we found that there are outliers in data","682cefcf":"outlier=[]  # for storing the outlier columns\nfor i in dict_for_numerical_columns:\n    if len(dict_for_numerical_columns[i])>1:\n        print(f\"the {i} has {len(dict_for_numerical_columns[i])} outliers\")\n        outlier.append(i)\nprint(\"*****outlier columns************\")\nprint(*outlier)","6a96abba":"fig=plt.figure(1,(20,5)) # 20 is length of x-axis in below figure and 5 is length of y axis\nax=plt.subplot(1,1,1)   #(1,1,1) denotes in 1x1 grid 1st plot\nsns.boxplot(x=\"variable\",y=\"value\",data=pd.melt(data_num))\nplt.show()","72f40178":"fig=plt.figure(11,(15,10))\nfor i,col in enumerate(data_num.columns):\n    ax=plt.subplot(4,3,i+1)\n    sns.boxplot(data_num[col],linewidth=1,palette=\"plasma\")\n    plt.tight_layout()\nplt.show()","6bdd25eb":"outlier # it is a list of all outliers","77183f0b":"o1=data.iloc[list(data[outlier[0]][dict_for_numerical_columns[\"price\"]].index)]\no1.head(2)","c241405f":"o2=data.iloc[list(data[outlier[1]][dict_for_numerical_columns['minimum_nights']].index)]\no2.head(2)","9bcebd12":"o3=data.iloc[list(data[outlier[2]][dict_for_numerical_columns[ 'number_of_reviews']].index)]\n\no3[\"number_of_reviews\"].unique()","92ccf41b":"o4=data.iloc[list(data[outlier[3]][dict_for_numerical_columns['calculated_host_listings_count']].index)]\no4.head(2)","2a1a4b17":"outliers_data=pd.concat([o1,o2,o3,o4])\n# now we combined all outliers into a single dataframe\nlen(data),len(outliers_data),len(o1),len(o2),len(o3),len(o4)\n\n# you will be shocked why we get 1701 when we all outliers' dataframes\n\n# by concatenating,we do add duplicated rows too\n","d13ee4ea":"# duplicate rows in outliers_data and original outliers_data rows\nlen(outliers_data[outliers_data.duplicated()]),len(outliers_data.index)","da3cccce":"data.drop(outliers_data.index,axis=0,inplace=True)\n# all rows are removed(duplicated too)","3182dedb":"len(data),\n# thus obtained rows are 48895-(1701-1382)=48576","c2d2aae9":"data.isnull().sum()","3c7a18ad":"data.drop(\"last_review\",axis=1,inplace=True)","21284e00":"sns.countplot(x=data[\"reviews_per_month\"],data=data)","05ce2447":"data.reviews_per_month.isnull().sum()","41c55dbd":"data.dropna(how=\"any\",inplace=True)\ndata.reviews_per_month.isnull().sum()\n# hence we have no missing values","b97556fe":"data.skew()\n# the skew which are +ve are right skew\n# the skew which are -ve are left skew","e9bf3b83":"skew_columns=[\"id\",\"host_id\",\"price\",\"minimum_nights\",\"number_of_reviews\",\"reviews_per_month\",\"calculated_host_listings_count\",\"availability_365\"]\nfig=plt.figure(1,(15,9))\nfor i,col in enumerate(skew_columns):\n    ax=plt.subplot(4,3,i+1)\n    sns.distplot(data[col],kde=50)\n    ax.set_xlabel(col)\n    ax.set_title(f\"{col} distribution\")\n    plt.tight_layout()\nplt.show()\n    ","2bd959fc":"plt.figure(figsize=(10,6))\nsns.scatterplot(data.longitude,data.latitude,hue=data.neighbourhood_group)\nplt.show()","fb39b7e8":"plt.figure(figsize=(10,6))\nsns.scatterplot(data.longitude,data.latitude,hue=data.price,palette=\"plasma\")\nplt.ioff()","1b31e76e":"data.head(3)","d6760ada":"corr = data.corr(method='pearson')\nplt.figure(figsize=(15,8))\nsns.heatmap(corr, annot=True,)\ndata.columns","82b982e8":"# we are assuming that these columns are not useful to predict\ndata.drop([\"latitude\"],axis=1,inplace=True)\ndata.drop([\"longitude\"],axis=1,inplace=True)","7498155f":"sns.pairplot(data)","48f3de81":"k=data\nk.head()","5801cd14":"data[\"room_type\"].nunique(),data[\"neighbourhood_group\"].nunique(),data[\"neighbourhood\"].nunique()\n# we dont consider for dummy values of neighbourhood_group and neighbourhood columns","de03663a":"data[\"room_type\"].unique()","879a2737":"p=pd.get_dummies(data.room_type)\np.head()","603cfd00":"data1=pd.concat([p,data],axis=1)\n# after concatenating,we removed the original column\ndata1.drop(\"room_type\",axis=1,inplace=True)\ndata1.head()","d8e9d9f0":"data1.head()","4fe45896":"data1.drop([\"neighbourhood_group\",\"neighbourhood\",\"host_id\"],axis=1,inplace=True)\ndata1.head()","e7726422":"data1.head()","f4ce4ae3":"data1.drop(\"id\",axis=1,inplace=True)\n# let place the prize column at last\nd=data1[\"price\"]\ndata1.drop(\"price\",axis=1,inplace=True)\ndata1[\"price\"]=d","06e210c3":"x=data1.iloc[:,0:8]\ny=data1[\"price\"]\nmodel1=SelectKBest(score_func=chi2,k=7)\nmodel1=model1.fit(x,y)\nfeatures1=model1.transform(x)","1dce42e2":"print(model1.scores_)\nprint(\"********************\")\n\n# we have to select the highest score column for best accuracy\n# so the columns are shared_room,availability_365,calculated_host_listings_count,reviews_per_month,number_of_reviews,Private room","30f1a063":"model1.scores_=pd.Series(model1.scores_,index=x.columns)\nmodel1.scores_.nlargest(13).plot(kind=\"barh\")\nplt.show()","3519f378":"data1.columns","e53b4712":"data1.drop(list(set(data1.columns)-set([ 'Shared room','Entire home\/apt', 'Private room',\n       'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n       'calculated_host_listings_count', 'availability_365'])),axis=1,inplace=True)","9b5051bb":"data1[\"price\"]=y\ndata1.head()\n# our new modified dataset","bd33c3fd":"x=data1.iloc[:,0:5]\ny=data1.iloc[:,5]","83ce432a":"len(data.reviews_per_month)\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx=scaler.fit_transform(x)\n# y has only one column, we need to reshape to single array\ny=np.array(y)\ny=y.reshape(-1,1)\ny=scaler.fit_transform(y)\n","659db261":"from sklearn.ensemble import RandomForestRegressor\nimport math\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=101)\nmodel=RandomForestRegressor(n_estimators=100,max_depth=15,random_state=0)\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nmath.sqrt(mean_squared_error(y_pred,y_test))","5602f731":"* Price and number_of_reviews are highly skewed and id and availability_365 are low skewed ","04d9192e":"### number_of_reviews.column","ac44b7ed":"## **Notice from missing values**\n* last_review and reviews_per_month has nearly 10000 mising values\n* since last_review is an object,we remove it\n* so we need to find what method to replace the missing values","0f99ef17":"#### we can clearly get an idea by below plots","87758f05":"## I am open for suggestions and opinions and if you found helpful,please upvote it\ud83d\ude01","c99c4f5d":"#### we can also find this by box-plot,Scatterplot","1b452b1b":"# Anamoly Detection","40d936f3":"### Standardisation","d1805129":"* for multivariate analysis,we use correlation plot and scatter plot","6e135754":"## Pairplot","c18a6f27":"#### Now,removing all outliers from original data","c5b71582":"* lets remove other columns in data1\n* requiredcolumns=[\"shared_room\",\"availability_365\",\"calculated_host_listings_count\",\"reviews_per_month\",\"number_of_reviews\",\"Private room\"]\n","ef5843ed":"## **Skew of Univariate Distributions**","f24b1490":"we know that \nthe price has 215 outliers\n\nthe minimum_nights has 301 outliers\n\nthe number_of_reviews has 626 outliers\n\nthe calculated_host_listings_count has 559 outliers\n\n","da1473ab":"1. #### from above, we have  outliers in data.we have to take some steps in order to get better results","b293893e":"##### Notice from above plot","30dc0e34":"### minimum_nights columns","38c579da":"## Feature Selection\n* we use  \n          chisquare test\n          Recursive Feature Elimination","57c630a2":"lets combine all outliers dataframes into one as when we individually remove,we get some misding indices","70ffdddc":"* Maximum all plots are having same price except one","f7a1c4af":"* from above we can replace Nan values with\n                                   1: mean\n                                   2: mode\n                                   3: median\n                                   4: drop the column\n* Here i assume, to replace with mean","95233e13":"**Here we need to predict Price with high accuracy**","c987cd16":"Now,lets find out the number of columns and rows ","3dfdfe2e":"# Lets start EDA","545bda14":"* correlation gives an indication how related the changes are between the two variables.\n* if two variables change in same direction,they are positively correlated \n* if they are in opposite direction,they are negatively correlated\n* if we have high correalted between variables leads to poor performance in regression models","fd96073f":"### Chisquare Test","7dff3592":"#### lets have a look at outliers' columns data.","1e748151":"#### we remove object columns ","cac595e5":"**Skew of data refers to a distribution that assumed to Gaussian that is squashed or shifted in one direction.\n\n**if we know the skew of a column,we can use it to increase accuracy of models","67a21353":"#### correlation matrix plot","14e9d3b8":"### Notice from skew","a427200a":"### PRICE column","104484d6":"### now finally we dont have any outlier which affect mean and standard deviation","a29f7f7e":" # Table of Contents\n   * Importing necessary Libraries\n   * EDA\n   * Anamoly Detection\n        * Z-score\n        * outliers\n        * plotiing outliers\n        * Removing outliers\n   * Skew plots\n   * Multivariate Plots and analysis\n   * Missing values\n   * Dummy values\n   * Correlation plot and pairplot\n   * Feature Selection\n        * Chi Square Test\n   * Training and testing model\n   * Analysing the model","f0b5aed4":"## z_score=(x-mean)\/standard deviation\n##### if any value greater than 3*standard deviation(1),then that value is an outlier ","f7461dd1":"#### scatterplot of longitude and lattitude","0a729e8e":"* we identify the best columns using chi square test","dab9c59c":"## Dummy values for less unique columns\n\n* we use dummy values for less number of unique values in columns (those are <=3)","036ea69c":"* for regression models, we use RMSE,MSE and for classification models we use confusion matrix and classification report","51657d4b":"### Removing Outlier rows","11b9f619":"### calculated_host_listings_count column","7d6c7c7d":"## lets find out the missing values","d0ff0028":"## Multivariate Plots and Analysis","ee710ce1":"### it is important to find outliers in data as they affect the mean and standard deviation we have two methods to find them.One by standard deviation and other is Inter quartile range.\n \n#### lets find out numerical columns","0502678c":"* many of us,still confuse what to do with outliers\n* since we have 48895 rows,we can remove the outlier without considering its affect\n* if we have low number of rows,we have to check whether it affects or not as some outlier data may be important.","970e42d1":"## Standard Scaler\n* we standadize the values with mean 0 and deviation 1"}}