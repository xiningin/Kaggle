{"cell_type":{"561d7f51":"code","e3d5c214":"code","c19229e8":"code","c32881cb":"code","01c21143":"code","9c67926f":"code","ccdd42dd":"code","61ae42da":"code","cc3835bb":"code","621955f4":"code","6067587c":"code","3070a047":"code","c50c99fb":"code","b9f3c762":"code","4711720a":"code","3940f2f7":"code","d3bf1d23":"code","cbff59cd":"code","636c3f89":"code","b3301e0e":"code","8167128b":"code","41b85820":"code","8608b24b":"code","d3e1a1af":"code","bcc0f855":"code","5c8de361":"code","810cc2f0":"code","1d215f47":"code","7b516787":"code","6988212c":"code","f1211e0f":"code","31c9189c":"code","fa67b950":"code","6715fb13":"code","8d018ae6":"code","1b300560":"code","ca9db247":"code","14688770":"code","eec8bbdf":"code","7f5a602e":"code","1dfb10e9":"code","72ff5119":"code","25f2a23e":"code","c4cf7469":"code","7422abf8":"code","b4f5308d":"code","622c3479":"code","9db304d5":"code","c2b4e973":"code","77b55730":"code","47494b13":"code","cfeddfb1":"code","9f6b0d08":"code","7c648786":"code","f427ee7f":"code","06f28a68":"code","ec1cfcc1":"code","374be48a":"code","f9d4a906":"code","95f43a86":"code","445529e2":"code","6deff288":"code","7620c4f3":"code","8cef1a11":"code","8d6834e1":"code","f61788ad":"code","296cd46c":"code","4b63ed88":"code","3086a4b5":"code","2f227430":"code","98a27f60":"code","11704c9f":"code","f2ca29f0":"code","c40489ef":"markdown","5b6ad897":"markdown","6ae2d58a":"markdown","239733d1":"markdown","e9cc14ff":"markdown","5a1076fd":"markdown","763e962a":"markdown","01a9d1e4":"markdown","1a45dd6f":"markdown","85c1f513":"markdown","740e46b4":"markdown","e2f45503":"markdown","e24d50c3":"markdown","976b739b":"markdown","3bb87163":"markdown","5f7a6abb":"markdown","521df310":"markdown","29057112":"markdown","1ffbc4d6":"markdown","4e59a703":"markdown","4de1a952":"markdown","1b7e3fc4":"markdown","2a657642":"markdown","79abc7c8":"markdown","669bbd9c":"markdown","3deeb858":"markdown","dc5b8986":"markdown","1d60f60e":"markdown","85b629b9":"markdown","df183599":"markdown","df62cc2d":"markdown","d69acec5":"markdown","8a065ddb":"markdown","a417305a":"markdown","1f89c5e4":"markdown","c4547629":"markdown","af1c9054":"markdown","c587f94d":"markdown","25ca1b8c":"markdown","0fe736f2":"markdown","41114735":"markdown","cbfd9b65":"markdown","43882c5b":"markdown","135200c5":"markdown","c29dab19":"markdown","d66996a1":"markdown","21bba521":"markdown","65369302":"markdown","0ff5087b":"markdown","b8474443":"markdown","39cf8eaf":"markdown","135ecf29":"markdown","3a3bf292":"markdown","0c8b162f":"markdown","8de8f84a":"markdown","e1e99697":"markdown","431d385a":"markdown","f3f0ebb6":"markdown","c918f832":"markdown","bc68ec45":"markdown","8843ec15":"markdown","54fb29e6":"markdown","86f2c48f":"markdown","7dff1273":"markdown","9a4eba8c":"markdown","ec969e21":"markdown","1d39e097":"markdown","b32c2ed5":"markdown"},"source":{"561d7f51":"import numpy as np \nimport pandas as pd","e3d5c214":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","c19229e8":"df.head(5)","c32881cb":"df.columns","01c21143":"from bokeh.io import output_notebook\nfrom bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.transform import cumsum\nfrom bokeh.palettes import Spectral6\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.layouts import gridplot\nfrom math import pi","9c67926f":"output_notebook()","ccdd42dd":"df['target'].value_counts()","61ae42da":"df['target'].value_counts()[0]","cc3835bb":"unique = [\"0\", '1']\ntop = [df['target'].value_counts()[0], df['target'].value_counts()[1]]\nsource = ColumnDataSource(data = dict(Target = unique, counts = top, color = Spectral6))","621955f4":"p = figure(\n    x_range = unique,\n    plot_height = 500,\n    plot_width = 500,\n    x_axis_label = 'Target',\n    y_axis_label = 'Count(Target)',\n    title = 'Count of People Having Heart Disease and Not Having Heart Disease',\n    tools = \"hover\", tooltips=\"@Target: @counts\"\n)\n\np.vbar(\n    x = 'Target',\n    top = 'counts',\n    bottom = 0,\n    width = 0.9,\n    source = source,\n    color = 'color'\n)","6067587c":"target = {\n            'No Heart Disease' : df['target'].value_counts()[0], \n          'Have Heart Disease' : df['target'].value_counts()[1]\n         }\n\ndata = pd.Series(target).reset_index(name = 'value').rename(columns = {'index':'target'})\ndata['angle'] = data['value']\/data['value'].sum() * 2 * pi\ndata['color'] = ['skyblue', 'salmon']","3070a047":"p1 = figure(\n            plot_height = 500, \n            plot_width = 500, \n            title = \"Proportion of People Having Heart Disease and not Having Heart Disease\", \n            toolbar_location = None,\n            tools = \"hover\", \n            tooltips = \"@target: @value\", \n            x_range = (-0.5, 1.0)\n            )\n\np1.wedge(\n        x = 0, y = 1, radius = 0.4,\n        start_angle = cumsum('angle', include_zero=True), \n        end_angle = cumsum('angle'),\n        line_color = \"white\", \n        fill_color = 'color', \n        legend_field = 'target', \n        source = data\n        )\n\np1.legend.location = \"top_right\"\n\np1.legend.label_text_font_size = '5pt'","c50c99fb":"show(gridplot([[p], [p1]]))","b9f3c762":"print(\"Percentage of people having Heart Disease\", round(df['target'].value_counts()[1] \/ (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)\nprint(\"Percentage of people not having Heart Disease\", round(df['target'].value_counts()[0] \/ (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)","4711720a":"df.isnull().sum()","3940f2f7":"categorical_var = []\ncontinuous_var = []\n\nfor column in df.columns:\n    if len(df[column].unique()) <= 10:\n        print(f\"{column} : {df[column].unique()}\")\n        categorical_var.append(column)\n        print()\n    else:\n        continuous_var.append(column)\n        \nprint(\"Categorical Variables are: \", categorical_var)\nprint(\"Continuous Variables are: \", continuous_var)","d3bf1d23":"def count_of_each_category(column_name):\n    \"\"\"\n    A function which will plot the count of each category for a particular column using bokeh.\n    \"\"\"\n    values = {}\n    for i in df[column_name].value_counts().index:\n        values[i] = df[column_name].value_counts()[i]\n    column = list(values.keys())\n    top = list(values.values())\n    source = ColumnDataSource(data = dict(Classes = column, counts = top, color = Spectral6))\n\n    p2 = figure(\n        plot_height = 400,\n        plot_width = 400,\n        x_axis_label = column_name,\n        y_axis_label = 'Count(Classes)',\n        tools=\"hover\", tooltips=\"@Classes: @counts\"\n    )\n\n    p2.vbar(\n        x = 'Classes',\n        top = 'counts',\n        bottom = 0,\n        width = 0.9,\n        source = source,\n        color = 'color'\n    )\n    \n    return p2\n    ","cbff59cd":"p2 = count_of_each_category('sex')\nshow(p2)","636c3f89":"# For analyzing how much proportion of male or female have heart disease. \n\nsex_vs_target = df.groupby(['sex', 'target'])['sex'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [sex_vs_target[1], sex_vs_target[3]],\n        'No Heart Disease'   : [sex_vs_target[0], sex_vs_target[2]]\n        }\n\np3 = figure(plot_height = 400, plot_width = 400, title = \"Sex vs Target\",\n           )\n\np3.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data,\n             legend_label = condition)\n\np3.legend.location = \"top_left\"\n\np3.legend.label_text_font_size = '7pt'\nshow(p3)","b3301e0e":"p4 = count_of_each_category('cp')\nshow(p4)","8167128b":"# For analyzing what proportion of different chest pain types patient have heart disease. \n\ncp_vs_target = df.groupby(['cp', 'target'])['cp'].count().to_list()\n\nunique = [0, 1, 2, 3]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [cp_vs_target[1], cp_vs_target[3], cp_vs_target[5],cp_vs_target[7]],\n        'No Heart Disease'   : [cp_vs_target[0], cp_vs_target[2], cp_vs_target[4], cp_vs_target[6]]\n        }\n\np5 = figure(plot_height = 400, plot_width = 400, title = \"Chest Pain vs Target\")\n\np5.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np5.legend.location = \"top_right\"\n\np5.legend.label_text_font_size = '7pt'\nshow(p5)","41b85820":"p6 = count_of_each_category('fbs')\nshow(p6)","8608b24b":"# For analyzing how much proportion of diabetic and non-diabetic patients have heart disease. \n\nfbs_vs_target = df.groupby(['fbs', 'target'])['fbs'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [fbs_vs_target[1], fbs_vs_target[3]],\n        'No Heart Disease'   : [fbs_vs_target[0], fbs_vs_target[2]]\n        }\n\np7 = figure(plot_height = 400, plot_width = 400, title = \"Fasting Blood Sugar vs Target\")\n\np7.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np7.legend.location = \"top_right\"\n\np7.legend.label_text_font_size = '7pt'\nshow(p7)","d3e1a1af":"p8 = count_of_each_category('restecg')\nshow(p8)","bcc0f855":"restecg_vs_target = df.groupby(['restecg', 'target'])['restecg'].count().to_list()\n\nunique = [0, 1, 2]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [restecg_vs_target[1], restecg_vs_target[3], restecg_vs_target[5]],\n        'No Heart Disease'   : [restecg_vs_target[0], restecg_vs_target[2], restecg_vs_target[4]]\n        }\n\np9 = figure(plot_height = 400, plot_width = 400, title = \"Restecg vs Target\")\n\np9.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np9.legend.location = \"top_right\"\n\np9.legend.label_text_font_size = '7pt'\nshow(p9)","5c8de361":"p10 = count_of_each_category('exang')\nshow(p10)","810cc2f0":"exang_vs_target = df.groupby(['exang', 'target'])['exang'].count().to_list()\n\nunique = [0, 1]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [restecg_vs_target[1], restecg_vs_target[3]],\n        'No Heart Disease'   : [restecg_vs_target[0], restecg_vs_target[2]]\n        }\n\np11 = figure(plot_height = 400, plot_width = 400, title = \"Exang vs Target\")\n\np11.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np11.legend.location = \"top_right\"\n\np11.legend.label_text_font_size = '7pt'\nshow(p11)","1d215f47":"p12 = count_of_each_category('slope')\nshow(p12)","7b516787":"slope_vs_target = df.groupby(['slope', 'target'])['slope'].count().to_list()\n\nunique = [0, 1, 2]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [slope_vs_target[1], slope_vs_target[3], slope_vs_target[5]],\n        'No Heart Disease'   : [slope_vs_target[0], slope_vs_target[2], slope_vs_target[4]]\n        }\n\np13 = figure(plot_height = 400, plot_width = 400, title = \"Slope vs Target\")\n\np13.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\n\np13.legend.location = \"top_left\"\n\np13.legend.label_text_font_size = '5pt'\nshow(p13)","6988212c":"p14 = count_of_each_category('ca')\nshow(p14)","f1211e0f":"ca_vs_target = df.groupby(['ca', 'target'])['ca'].count().to_list()\n\nunique = [0, 1, 2, 3, 4]\ncondition = ['Have Heart Disease', 'No Heart Disease']\ncolors = [\"#e84d60\", \"#718dbf\"]\ndata = {\n        'Classes' : unique,\n        'Have Heart Disease' : [ca_vs_target[1], ca_vs_target[3], ca_vs_target[5], ca_vs_target[7], ca_vs_target[9]],\n        'No Heart Disease'   : [ca_vs_target[0], ca_vs_target[2], ca_vs_target[4], ca_vs_target[6], ca_vs_target[8]]\n        }\n\np15 = figure(plot_height = 400, plot_width = 400, title = \"Ca vs Target\")\n\np15.vbar_stack(condition, x ='Classes', width = 0.9, color = colors, source = data, legend_label = condition)\np15.legend.location = \"top_right\"\n\np15.legend.label_text_font_size = '7pt'\nshow(p15)","31c9189c":"def plot_cont_var(column_name):\n    \"\"\"\n    A function which makes histogram for continuous variables.\n    \"\"\"\n    hist1, edges1 = np.histogram(df[df[\"target\"] == 0][column_name], density = True, bins = 40)\n    hist2, edges2 = np.histogram(df[df[\"target\"] == 1][column_name], density = True, bins = 40)\n\n    p = figure(\n        plot_height = 500,\n        plot_width = 500,\n        x_axis_label = column_name,\n        title = column_name.capitalize() + ' vs Target'\n    )\n\n    p.quad(\n        bottom = 0,\n        top = hist1,\n        left = edges1[:-1],\n        right = edges1[1:],\n        line_color = 'white',\n        color = 'blue', # Blue represents patients not having heart disease.\n        alpha = 0.6\n    )\n\n    p.quad(\n        bottom = 0,\n        top = hist2,\n        left = edges2[:-1],\n        right = edges2[1:],\n        line_color = 'white',\n        color = 'red', # Red represents patients having heart disease.\n        alpha = 0.6\n    )\n\n\n\n    return p\n\n","fa67b950":"p16 = plot_cont_var('age')\nshow(p16)","6715fb13":"continuous_var","8d018ae6":"p17 = plot_cont_var('trestbps')\nshow(p17)","1b300560":"p18 = plot_cont_var('chol')\nshow(p18)","ca9db247":"p19 = plot_cont_var('thalach')\nshow(p19)","14688770":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# I have used seaborn for plotting correlation matrix as its \n# much faster and much more easier than bokeh ","eec8bbdf":"corr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(15, 15))\nax = sns.heatmap(corr_matrix,\n                 annot = True,\n                 linewidths = 0.5,\n                 fmt = \".2f\",\n                 cmap = \"YlGnBu\");\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","7f5a602e":"df.drop('target', axis=1).corrwith(df.target).plot(kind = 'bar', grid = True, \n                                                   figsize = (12, 8), \n                                                   title = \"Correlation with Target\")","1dfb10e9":"from pandas import get_dummies\n\ncategorical_var.remove('target') # Removing the 'target' column from the list of categorical variables.\ndataframe = pd.get_dummies(df, columns = categorical_var)","72ff5119":"dataframe.head()","25f2a23e":"dataframe.columns","c4cf7469":"X = dataframe.drop('target', axis = 1)\ny = dataframe['target']","7422abf8":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","b4f5308d":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","622c3479":"X_train_std = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","9db304d5":"X_train_std","c2b4e973":"X_test","77b55730":"from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix","47494b13":"def evaluation(model, x_train_std, y_train, x_test, y_test, train = True):\n    if train == True:\n        pred = model.predict(x_train_std)\n        classifier_report = pd.DataFrame(classification_report(y_train, pred, output_dict = True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"F1 Score: {round(f1_score(y_train, pred), 2)}\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    if train == False:\n        pred = model.predict(x_test)\n        classifier_report = pd.DataFrame(classification_report(y_test, pred, output_dict = True))\n        print(\"Test Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"F1 Score: {round(f1_score(y_test, pred), 2)}\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{classifier_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","cfeddfb1":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver = 'liblinear')\nlr.fit(X_train_std, y_train)\n\nevaluation(lr, X_train_std, y_train, X_test, y_test, True)\nevaluation(lr, X_train_std, y_train, X_test, y_test, False)","9f6b0d08":"train_score_lr = round(accuracy_score(y_train, lr.predict(X_train_std)) * 100, 2)\ntest_score_lr = round(accuracy_score(y_test, lr.predict(X_test)) * 100, 2)","7c648786":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators = 400)\nrfc.fit(X_train_std, y_train)\n\nevaluation(rfc, X_train_std, y_train, X_test, y_test, True)\nevaluation(rfc, X_train_std, y_train, X_test, y_test, False)","f427ee7f":"train_score_rfc = round(accuracy_score(y_train, rfc.predict(X_train_std)) * 100, 2)\ntest_score_rfc = round(accuracy_score(y_test, rfc.predict(X_test)) * 100, 2)","06f28a68":"accuracy_scores = []\nfor i in range(1, 1000, 100):\n    rfc = RandomForestClassifier(n_estimators = i)\n    rfc.fit(X_train_std, y_train)\n    accuracy_scores.append(accuracy_score(y_test, rfc.predict(X_test)))\nprint(accuracy_scores)","ec1cfcc1":"from sklearn.neighbors import KNeighborsClassifier","374be48a":"accuracy_scores = []\n\nfor i in range(1, 10):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train_std, y_train)\n    accuracy_scores.append(accuracy_score(y_test, knn.predict(X_test)))\n    \nprint(accuracy_scores)","f9d4a906":"knn = KNeighborsClassifier(n_jobs = 9)\nknn.fit(X_train_std, y_train)\n\nevaluation(knn, X_train_std, y_train, X_test, y_test, True)\nevaluation(knn, X_train_std, y_train, X_test, y_test, False)","95f43a86":"train_score_knn = round(accuracy_score(y_train, knn.predict(X_train_std)) * 100, 2)\ntest_score_knn = round(accuracy_score(y_test, knn.predict(X_test)) * 100, 2)","445529e2":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', gamma=0.1, C=1.0)\nsvm.fit(X_train_std, y_train)\n\nevaluation(svm, X_train_std, y_train, X_test, y_test, True)\nevaluation(svm, X_train_std, y_train, X_test, y_test, False)","6deff288":"train_score_svm = round(accuracy_score(y_train, svm.predict(X_train_std)) * 100, 2)\ntest_score_svm = round(accuracy_score(y_test, svm.predict(X_test)) * 100, 2)","7620c4f3":"models = {\n           'Train Accuracy': [train_score_lr, train_score_rfc, train_score_knn, train_score_svm],\n          'Test Accuracy' : [test_score_lr, test_score_rfc, test_score_knn, test_score_svm]\n         }\n\nmodels = pd.DataFrame(models, index = ['Logistic Regression', 'Random Forest Classifier', 'K-Nearest Neighbor', 'Support Vector Machine'])","8cef1a11":"models.head()","8d6834e1":"from sklearn.model_selection import GridSearchCV","f61788ad":"params = {\n        \"C\": np.logspace(-4, 4, 20), # For Regularization\n          \"solver\": [\"liblinear\"]}\n\nlr = LogisticRegression()\n\nlr_cv = GridSearchCV(lr, params, scoring = \"accuracy\", n_jobs = -1, verbose = 1, cv = 5)","296cd46c":"lr_cv.fit(X_train_std, y_train)","4b63ed88":"best_params = lr_cv.best_params_\nprint(f\"Best parameters: {best_params}\")","3086a4b5":"lr = LogisticRegression(**best_params)\n\nlr.fit(X_train_std, y_train)\n\nevaluation(lr, X_train_std, y_train, X_test, y_test, True)\nevaluation(lr, X_train_std, y_train, X_test, y_test, False)","2f227430":"train_score_lr = round(accuracy_score(y_train, lr.predict(X_train_std)) * 100, 2)\ntest_score_lr = round(accuracy_score(y_test, lr.predict(X_test)) * 100, 2)","98a27f60":"train_score = []\ntest_score = []\nneighbors = range(1, 30)\n\nfor k in neighbors:\n    model = KNeighborsClassifier(n_neighbors = k)\n    model.fit(X_train_std, y_train)\n    train_score.append(accuracy_score(y_train, model.predict(X_train_std)))","11704c9f":"plt.figure(figsize=(12, 8))\n\nplt.plot(neighbors, train_score, label=\"Train score\")\n# plt.plot(neighbors, test_score, label=\"Test score\")\nplt.xticks(np.arange(1, 31, 1))\nplt.xlabel(\"Number of Neighbors\")\nplt.ylabel(\"Model Score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the train data: {max(train_score)*100:.2f}%\")","f2ca29f0":"knn = KNeighborsClassifier(n_neighbors = 27)\nknn.fit(X_train_std, y_train)\n\nevaluation(knn, X_train_std, y_train, X_test, y_test, True)\nevaluation(knn, X_train_std, y_train, X_test, y_test, False)","c40489ef":"Before we train any model, I will create a function which will help to evaluate the model.","5b6ad897":"As we can see that there a number of continuous variables, we need to scale the data so that the continuous variables don't get majority of the weight or in other words, become the deciding factor to predict whether the patient has heart disease. We would also need to convert some categorical variable into dummy variables.","6ae2d58a":"The patients having maximum heart rate greater than 150 are at a greater risk of having heart disease.","239733d1":"For now we will take the number of neighbors to be 9. ","e9cc14ff":"Resting Blood Pressure (in mm Hg on admission to the hospital) anything above 130-140 is typically cause for concern","5a1076fd":"# 5. Hyperparameter Tuning","763e962a":"We can see a large proportion of patients having 'ca' value of type 0 and type 4 had Heart Disease.","01a9d1e4":"### Support Vector Machine","1a45dd6f":"Through Logistic Regression we were able to achieve Training Accuracy of 88.55 % and Testing Accuracy of 86.84 %.","85c1f513":"As type 2 means Downslopins which is a sign of unhealthy heart, most patients with type 2 slope had Heart Disease.","740e46b4":"For performing EDA, I will be using [Bokeh](https:\/\/bokeh.org).","e2f45503":"A large proportion of people having restecg of type 1 actually have heart disease. We must take care of ST-T Wave abnormality as it can range from mild symptoms to severe problems.","e24d50c3":"**Now we will see the relation of the Continuous Variables with the target.**","976b739b":"### Chest Pain vs Target","3bb87163":"Before we scale the data, we need to split the data into train and test. We can not apply scaling before splitting because test set is the real world data which the trained model would have never seen. Therefore, we will scale the test data according to the train data","5f7a6abb":"Those patients having Blood Pressure in the range of 120 to 160 have the highest chance of having heart disease","521df310":"maximum heart rate achieved","29057112":"**Now we will explore the relation of these categorical variables with the target.**","1ffbc4d6":"FBS > 120 mg\/dl (1 = true; 0 = false). \n\nThose whose Fasting Blood Sugar is greater than 120 indicates that the patient is diabetic.","4e59a703":"We can see that both X_train and X_test has been scaled. Now we can apply Machine Learning Algorithms.","4de1a952":"### K-nearest neighbors with Hyperparameter Tuning","1b7e3fc4":"exang means exercise induced angina (1 = yes; 0 = no). Angina is a type of chest pain caused by reduced blood flow to the heart","2a657642":"Now we will determine the right number of n_estimators to be used:","79abc7c8":"### Logistic Regression with Hyperparameter Tuning","669bbd9c":"0: Nothing to note\n\n1: ST-T Wave abnormality can range from mild symptoms to severe problems signals non-normal heart beat\n\n2: Possible or definite left ventricular hypertrophy. Enlarged heart's main pumping chamber\n","3deeb858":"# 4. Training Machine Learning Algorithms","dc5b8986":"### Fasting Blood Sugar vs Target ","1d60f60e":"We can see that 'fbs' and 'chol' are least related with 'target' whereas other features are highly correlated with the 'target' variable.","85b629b9":"The first step before we start performing EDA, preprocessing the data, building the ML model is to check whether the variable to predict i.e 'target' is balanced or not. By checking this we can get to know which evaluation metrics will be better suited for this particular dataset.","df183599":"# 3. Data Pre-processing","df62cc2d":"#### Loading the libraries","d69acec5":"So we don't have any null values present which saves us a lot of time :)","8a065ddb":"First let's classify these columns as Catergorical or Continuous. For Categorical variables we will print out the unique categories for that particular column.","a417305a":"There is no particular age at which the person is more prone to having heart disease, which proves that age is just a number.","1f89c5e4":"We can see that having 500 number of trees gives the highest accuracy hence we have used 500 above.","c4547629":"### Exercise Induced Angina vs Target","af1c9054":"### K Nearest Neighbor","c587f94d":"Through Random Forest Classifier we were able to achieve Training Accuracy of 100 % and Testing Accuracy of 84.21 %.","25ca1b8c":"#### Loading the dataset","0fe736f2":"Deciding the right number of Neighbors.","41114735":"### Slope vs Target","cbfd9b65":"**In this notebook we are going to perform Exploratory Data Analysis and use various Machine Learning Models to predict whether the patient has heart disease or not depending on the values of various features. I will be using Bokeh and a little bit of Seaborn to plot the graphs.**\n\n**Please Upvote if you like the notebook and do provide your valuable feedback.**","43882c5b":"The correlation between the features with target is not that clear in the correlation matrix as there are a large number of features, lets visualize it in another way.","135200c5":"### Ca vs Target","c29dab19":"Next we need to check whether there are null values present in the dataset.","d66996a1":"# 2. Exploratory Data Analysis(EDA)","21bba521":"### Random Forest Classifier","65369302":"We might think that more number of men have heart disease but if we observe closely, we can see that more proportion of female have heart disease as compared to men.","0ff5087b":"### Age vs Target","b8474443":"# Using EDA and Machine Learning to Predict Heart Disease","39cf8eaf":"### Thalach vs Target","135ecf29":"Different Chest Pain Types:\n\n0: Typical angina: chest pain related decrease blood supply to the heart\n\n1: Atypical angina: chest pain not related to heart\n\n2: Non-anginal pain: typically esophageal spasms (non heart related)\n\n3: Asymptomatic: chest pain not showing signs of disease\n","3a3bf292":"###  Cholestoral vs Target","0c8b162f":"Task:\n    \n    Given various parameters about a patient, can we predict whether or not they have heart disease?","8de8f84a":"### Resting Blood Pressure vs Target","e1e99697":"slope - the slope of the peak exercise ST segment\n\n0: Upsloping: better heart rate with excercise (uncommon)\n\n1: Flatsloping: minimal change (typical healthy heart)\n\n2: Downslopins: signs of unhealthy heart","431d385a":"It's really shocking to know that majority of the asymptomatic (Type 3) cases and Non-anginal pain patients (Type 2) ended up having heart disease.","f3f0ebb6":"### Summary","c918f832":"## Features","bc68ec45":"### Restecg vs Target","8843ec15":"ca - number of major vessels (0-3) colored by flourosopy\n\ncolored vessel means the doctor can see the blood passing through\n\nthe more blood movement the better (no clots)","54fb29e6":"# 1. Is Dataset Balanced ?","86f2c48f":"### Sex vs Target","7dff1273":"We can see that the dataset is balanced as there is no major difference between the proportion of people having heart disease and those not having heart disease.","9a4eba8c":"Let's have a look at what each of these columns means:\n\n1. **age** -> Age of the person.\n2. **sex** -> Sex of the person.  (1 = male; 0 = female)\n3. **cp** -> Chest Pain Type. It can take values of 0, 1, 2, 3.\n4. **trestbps** -> Resting Blood Presssure (Measured in mm Hg on admission to the hospital). It can take continuous values from 94 to 200.  \n5. **chol** -> Serum Cholestrol in mg\/dl. It also takes continuous values.\n6. **fbs** -> Fasting Blood Sugar. It can take value of either 1 or 0.\n7. **restecg** -> Resting Electrocardiographic Results. It can take value of 0, 1 or 2.\n8. **thalach** -> Maximum Heart Rate achieved. It can take continuous value from 71 to 202.\n9. **exang** -> Exercise Induced Angina. It can take value either of 0 or 1.\n10. **oldpeak** -> ST depression induced by exercise relative to rest. It takes continuous decimal values.\n11. **slope** -> the slope of the peak exercise ST segment. It can take value of either 0, 1 or 2.\n12. **ca** -> Number of major vessels colored by flourosopy. It can take value of either 0, 1, 2, 3 or 4. \n13. **thal** -> 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. **target** -> Indicates the presence or absence of heart disease. (= the predicted attribute)","ec969e21":"# 3. Correlation Matrix","1d39e097":"We can see that patient having Cholestrol level greater than 200 had heart disease.","b32c2ed5":"### Logistic Regression"}}