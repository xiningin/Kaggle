{"cell_type":{"66978e5d":"code","1fe983e1":"code","4722ae2a":"code","b8f82fee":"code","88e14d8f":"code","0b843b57":"code","5e7d40ff":"code","2ed8fc22":"code","24849e22":"code","a5aa2d9f":"code","f12f1786":"code","c1d6cf06":"code","4595beab":"code","1d03d9b2":"code","4e633f0c":"code","f389fdee":"code","b09078c2":"code","d6ad5d87":"code","e8e86d3a":"code","eb3e29c6":"code","4741b4ca":"code","4dbdd281":"code","0ae951a9":"code","1bbb9fc0":"code","7d3c6e87":"code","f1fb504d":"code","15598f04":"code","b9332a49":"code","27872e0f":"code","38d143dc":"markdown","8d67e47b":"markdown","aceed178":"markdown","ed0badf6":"markdown","1b567114":"markdown","20c84d2c":"markdown","e37a4f65":"markdown","71ac4f9f":"markdown","bc1f2941":"markdown","6c6da2b6":"markdown","cbed3df1":"markdown","53051df6":"markdown","55172360":"markdown","9d178019":"markdown","1c1bcb1e":"markdown","bc3270e3":"markdown","8f9ba5e9":"markdown","277c2204":"markdown","9f0df700":"markdown","0b47a384":"markdown","3c9dfdbf":"markdown","604781d5":"markdown","889a3b33":"markdown","197cf91f":"markdown","39970fc0":"markdown","c6597874":"markdown","03b03b48":"markdown","32cf272a":"markdown","27137ca6":"markdown","d2db9baa":"markdown","a3d8fa29":"markdown","2fc102db":"markdown","e099ab92":"markdown","1b5667dd":"markdown","6806be9f":"markdown","e5b26982":"markdown","5e3c4309":"markdown","43039413":"markdown","33b5cb19":"markdown","5e8875ca":"markdown","a6f94de9":"markdown","962f5f90":"markdown"},"source":{"66978e5d":"!pip install dart\n!pip install adtk","1fe983e1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport logging\nlogging.disable(logging.CRITICAL)\nsns.set_palette(\"tab10\")\nimport pandas as pd\nfrom darts import TimeSeries\nfrom darts.models import ARIMA, VARIMA, AutoARIMA, RegressionEnsembleModel,  ExponentialSmoothing, Theta\nfrom darts.models import FourTheta, Prophet, FFT, RandomForest, LightGBMModel, TFTModel, NaiveSeasonal, NaiveDrift\nfrom darts.models import TransformerModel, NBEATSModel, BlockRNNModel, RNNModel, TCNModel\nfrom  darts.utils.likelihood_models import GaussianLikelihood\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, remove_seasonality, remove_trend, plot_residuals_analysis\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\nfrom adtk.detector import InterQuartileRangeAD, PersistAD\nfrom adtk.aggregator import OrAggregator\nfrom adtk.data import validate_series\nfrom adtk.visualization import plot\nfrom darts.utils.utils import ModelMode, SeasonalityMode\nimport statsmodels as sm\nimport statsmodels.tsa.stattools as ts\nimport shutup\nshutup.please()","4722ae2a":"dataset = 'AirPassengers.csv'","b8f82fee":"df = pd.read_csv(dataset)","88e14d8f":"print(df.head())","0b843b57":"print(df.shape)","5e7d40ff":"print(df.info())","2ed8fc22":"df['Month'] = pd.to_datetime(df['Month'])","24849e22":"df['Lag'] = df['#Passengers'].diff(12)\ndf.dropna(inplace=True)","a5aa2d9f":"print(df.describe(include='all'))","f12f1786":"def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n    plt.figure(figsize=(16,5), dpi=dpi)\n    plt.plot(x, y, color='tab:red')\n    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n    plt.show()\n\nplot_df(df, x=df['Month'], y=df['#Passengers'], title='Air Passengers Per Month')","c1d6cf06":"df['year'] = [d.year for d in df.Month]\ndf['month'] = [d.strftime('%b') for d in df.Month]\nyears = df['year'].unique()\nfig, axes = plt.subplots(1, 2, figsize=(16,5), dpi= 80)\nsns.boxplot(x='year', y='#Passengers', data=df, ax=axes[0])\nsns.boxplot(x='month', y='#Passengers', data=df.loc[~df.year.isin([1991, 2008]), :])\n\n# Set Title\naxes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=18); \naxes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\nplt.show()","4595beab":"s = pd.read_csv('AirPassengers.csv', index_col=\"Month\", parse_dates=True, squeeze=True)\ns = validate_series(s)\nquantile_ad = InterQuartileRangeAD(c=1.5)\nnegative_persist_ad = PersistAD(c=1.5, side='negative',window = 12)\npositive_persist_ad = PersistAD(c=1.5, side='positive',window = 12)\nquantile_anomalies = quantile_ad.fit_detect(s)\nnegative_anomalies = negative_persist_ad.fit_detect(s)\npositive_anomalies = positive_persist_ad .fit_detect(s)\nanomalies = pd.concat([quantile_anomalies,negative_anomalies,positive_anomalies],axis=1)\nanomalies.columns=[\"InterQuartile\", \"Positive\",\"Negative\"]\nanomalies = OrAggregator().aggregate(anomalies)\nplot(s, anomaly={'InterQuartile':quantile_anomalies, \"Positive\": positive_anomalies, \"Negative\": negative_anomalies},anomaly_marker={'InterQuartile':'x', \"Positive\": \"^\", \"Negative\": \"v\"}, ts_linewidth=1, ts_markersize=1, anomaly_markersize=5, anomaly_color={'InterQuartile':'gray', \"Positive\": \"green\", \"Negative\": \"red\"}, anomaly_tag=\"marker\");","1d03d9b2":"series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\ncheck_seasonality(series)","4e633f0c":"from statsmodels.tsa.seasonal import seasonal_decompose\ncomponents_add = seasonal_decompose(df['#Passengers'],model='additive',period=12)\ncomponents_mul = seasonal_decompose(df['#Passengers'],model='multiplicative',period=12)\n\nfigure_add = components_add.plot()\nfigure_mul = components_mul.plot()\nfigure_add.set_size_inches(16, 5)\nfigure_mul.set_size_inches(16, 5)","f389fdee":"residuals = remove_trend(remove_seasonality(series))","b09078c2":"plot_residuals_analysis(residuals)","d6ad5d87":"def dftest_stationarity(timeseries):\n    dftest = ts.adfuller(timeseries,)\n    dfoutput = pd.Series(dftest[0:4], \n                         index=['Test Statistic','p-value','Lags Used','Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)\n    #Determing rolling statistics\n    rolmean = timeseries.rolling(window=12).mean()\n    rolstd = timeseries.rolling(window=12).std()\n\n    #Plot rolling statistics:\n    plt.figure(figsize=(16,5))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean and Standard Deviation')\n    plt.grid()\n    plt.show()","e8e86d3a":"dftest_stationarity(df['#Passengers'])","eb3e29c6":"dftest_stationarity(df['Lag'])","4741b4ca":"series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\ntraining, validation = series.split_after(0.7)\nyear_series = datetime_attribute_timeseries(pd.date_range(start=series.start_time(), freq=series.freq_str, periods=1000),\n                                             attribute='year', one_hot=False)\nyear_series = Scaler().fit_transform(year_series)\nmonth_series = datetime_attribute_timeseries(year_series, attribute='month', one_hot=True)\ncovariates = year_series.stack(month_series)","4dbdd281":"global_models = [\n    TransformerModel(input_chunk_length=30,output_chunk_length=20),\n    NBEATSModel(input_chunk_length=30,output_chunk_length=20),\n    BlockRNNModel(model='LSTM',input_chunk_length=30,output_chunk_length=20),\n    BlockRNNModel(model='GRU',input_chunk_length=30,output_chunk_length=20),\n    BlockRNNModel(model='RNN',input_chunk_length=30,output_chunk_length=20),\n    RNNModel(model='LSTM',input_chunk_length=30,output_chunk_length=20),\n    RNNModel(model='GRU',input_chunk_length=30,output_chunk_length=20),\n    RNNModel(model='RNN',input_chunk_length=30,output_chunk_length=20),\n    RandomForest(lags=12),\n    LightGBMModel(lags=12),\n]\n\nnon_global_models = [\n    NaiveSeasonal(K=12),\n    NaiveDrift(),\n    ARIMA(),\n    AutoARIMA(),\n    ExponentialSmoothing(),\n    Theta(),\n    FourTheta(),\n    Prophet(),\n    FFT(trend='poly'),\n]\n\nxgb_model = xgb.XGBRegressor()\nensemble_model = RegressionEnsembleModel(forecasting_models=non_global_models,\n                                         regression_train_n_points=len(training)\/\/10,\n                                         regression_model=xgb_model)\n\nmodels=[]\nscores=[]","0ae951a9":"def eval_model(model, series=series,tra_series=training, val_series=validation):\n    model.fit(training)\n    pred_series = model.predict(len(validation))\n    models.append(model)\n    scores.append(mape(pred_series, validation))","1bbb9fc0":"for model in non_global_models:\n    eval_model(model)\n\nfor model in global_models:\n    eval_model(model)\n\neval_model(ensemble_model)","7d3c6e87":"model_scores = pd.DataFrame({'Model':models,'MAPE_Score':scores})\nmodel_scores.sort_values('MAPE_Score',ascending=True,inplace=True)\nmodel_scores","f1fb504d":"model = models[4]\npred_series =model.predict(len(validation))\nplt.figure(figsize=(16,5))\nseries.plot(label='actual')\npred_series.plot(label='forecast',low_quantile=0.05, high_quantile=0.95)\nplt.title('model {} obtains MAPE: {:.2f}%'.format(model,mape(pred_series, validation)))\nplt.legend();","15598f04":"backtest = model.historical_forecasts(series=series,start=0.3,forecast_horizon=3)\nerror = mape(backtest, series)\nplt.figure(figsize=(16,5))\nseries.plot(label='data')\nbacktest.plot(lw=3, label='{}, MAPE={:.2f}%'.format(model, error))\nplt.title('Backtests with 3-months forecast horizon')\nplt.legend();","b9332a49":"parameters= {\n'trend':[ModelMode.ADDITIVE, ModelMode.MULTIPLICATIVE],\n'damped':[True,False],\n'seasonal':[SeasonalityMode.ADDITIVE, SeasonalityMode.MULTIPLICATIVE],\n'seasonal_periods':[12],\n}","27872e0f":"model.gridsearch(parameters=parameters,series=training,start=0.3,metric=mape,forecast_horizon=3)\nmodel.fit(training)\npred_series =model.predict(len(validation),num_samples=1000)\nplt.figure(figsize=(16,5))\nseries.plot(label='actual')\npred_series.plot(label='forecast',low_quantile=0.05, high_quantile=0.95)\nplt.title('Grid Searched Model {} obtains MAPE: {:.2f}%'.format(model,mape(pred_series, validation)))\nplt.legend();","38d143dc":"1. darts\n2. adtk","8d67e47b":"## Load the dataset","aceed178":"Time Series Decomposition","ed0badf6":"## Load the libraries","1b567114":"* Based on trend: the number of passengers is increasing every year\n* Based on seasonality: summer months are the ones with the most travellers","20c84d2c":"The steps in solving the Regression Problem are as follows:\n1. Packages to be installed\n2. Load the libraries\n3. Load the dataset\n4. General information about the dataset\n5. Exploratory Data Analysis (EDA)\n6. Key Findings and Insights\n7. Modeling\n8. Recommendations","e37a4f65":"Residuals_Analysis","71ac4f9f":"## Exploratory Data Analysis (EDA)","bc1f2941":"We selected the best model based on the lowest score as the model for the modeling task","6c6da2b6":"**Actions taken for data cleaning and feature engineering**","cbed3df1":"Summary Statistics for Time Series","53051df6":"location of dataset","55172360":"Visual Exploration of Time Series","9d178019":"Based on the comparasion above, this time seris is multiplicative as there is no pattern for residuals","1c1bcb1e":"Train regression model on the dataset to predict the number of passengers","bc3270e3":"## Packages to be installed","8f9ba5e9":"The time series is stationary and ready for modeling","277c2204":"we can see the model really successed on understanding the time series","9f0df700":"Features Encoding","0b47a384":"Test for stationarity with Augmented Dickey Fuller Test (ADF Test)","3c9dfdbf":"1. numpy\n2. pandas\n3. matplotlib\n4. seaborn\n5. darts\n6. xgboost\n7. adtk","604781d5":"## Recommendation","889a3b33":"**Modelling  Task Details**\n\n| S No. | Description| Category| Type |\n| --- | --- | --- | --- | \n|1 | Data being used| Structured | Numerical |\n|2 | Machine learning problem | Regression |  Univariate |\n|3 | Relevant ML and DL models | Mutiple Ml and DL Model | Times-Series Related |\n|4 | Technical metrics | MAPE | Percentage (the lower the better) |\n|5 | Hyperparameter optimization techniques | Grid search | Specified Dictionary |\n|6 | Computation method | On-premise | CPU | \n|7 | Additional Features | Historical Forecast | Check for Perfomance | ","197cf91f":"Test for Seasonnality and Frequency Period","39970fc0":"sampling the data","c6597874":"## Key Findings and Insights","03b03b48":"**Plan for Data Exploration, Feature Engineering and Modelling**","32cf272a":"The dataset know as Monthly International Airline Passengers Dataset and it used mostly in Univariate Time Series Analysis.\nIt has a total of 144 rows and 2 columns\n\n| S No. | Column | Description| Data Type | Category| Type\n| --- | --- | --- | --- | --- | --- |\n|1 | Month | Month and the year of the flight | Int | Discrete | Variable |\n|2 | #Passengers | Number of Passengers for the corresponding month | Int | Discrete | Target |","27137ca6":"Detecting Anamolies in the Time Series","d2db9baa":"dataset information","a3d8fa29":"number of rows and coulmns in dataset","2fc102db":"correcting date format","e099ab92":"we will be training Multiple algorithms from the Darts library and the comparing them according to accuracy on the testing dataset\nExpected runtime: 1 Hours","1b5667dd":"Selected model can be grid searched with parameters in order to increase its accuracy","6806be9f":"testing for stationary after differencing the time-seris","e5b26982":"## Modeling","5e3c4309":"We need to test if the prposed model really captured the pattern in the data, so we ask the the model to look at more historical data and start building the prediction from earlier point","43039413":"## General information about the dataset","33b5cb19":"**Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.**","5e8875ca":"Boxplot of Year-wise (Trend) and Month-wise (Seasonal) Distribution","a6f94de9":"reading the dataset into dataframe","962f5f90":"**Brief description of the data set you chose and a summary of its attributes**"}}