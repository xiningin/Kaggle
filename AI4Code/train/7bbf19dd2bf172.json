{"cell_type":{"3a0563a9":"code","e58f46da":"code","ae55a198":"code","5a78263a":"code","659a2b1d":"code","d8e39e93":"code","9a4804df":"code","45205452":"code","83333ceb":"code","1f48af1d":"code","9aa1510c":"code","649c005f":"code","bda7d12a":"code","137a7229":"code","a9d715c5":"code","28b0a859":"code","ccdeafa5":"code","b19dc399":"code","c878973b":"code","abf1bd98":"code","97ae8818":"code","96208652":"code","3fce0f6f":"code","1f5ec82e":"code","922a6ae9":"code","08524c35":"code","675b332e":"code","2523df27":"code","6336cb9c":"code","d9a98ce0":"code","e36cdec1":"code","8bb6890b":"code","7bad5299":"code","775e433e":"code","2173c813":"code","eba2d852":"code","824aa75f":"code","7386e4b8":"code","e451c072":"code","3867d257":"code","fde0010e":"code","a017be05":"code","5c18627e":"code","62b225e9":"code","9fe35e71":"code","41b9660f":"code","42dac48a":"code","32a4e80f":"code","ab61b043":"code","e6ae9619":"code","2c666cf4":"code","ae7ef15c":"code","4e5224f8":"code","b2f4cb22":"code","896dc821":"code","25bd3fd9":"code","4f6b9a3b":"code","dc425857":"code","7bee2603":"code","cdd1273a":"code","be77ee43":"code","de8b7354":"code","e3e24423":"code","84bde12a":"code","ea762ed1":"code","5b37bca8":"code","8524f081":"code","021c73e8":"code","82b73be6":"markdown","de845d2a":"markdown","806220d4":"markdown","3a65c0e1":"markdown","c24b56ec":"markdown","a30c1891":"markdown","7d5cdaf2":"markdown","4ca540e1":"markdown","b67ee137":"markdown","16414a6e":"markdown","c8767cae":"markdown"},"source":{"3a0563a9":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nimport numpy as np","e58f46da":"df1_tweets = pd.read_csv('..\/input\/viral-tweets-predictions\/train_tweets.csv')\ndf2_tweets = pd.read_csv('..\/input\/viral-tweets-predictions\/test_tweets.csv')","ae55a198":"df1_tweets","5a78263a":"df1_tweets.info()","659a2b1d":"for col in df1_tweets.columns:\n    print('Column: {0}. Unique Count: {1}'.format(col, df1_tweets[col].unique()))","d8e39e93":"categorical_val = []\ncontinous_val = []\nfor column in df1_tweets.columns:\n    print('==================================================================')\n    print(f\"{column} : {df1_tweets[column].unique()}\")\n    if len(df1_tweets[column].unique()) <= 10:\n        categorical_val.append(column)\n    else:\n        continous_val.append(column)","9a4804df":"df1_tweets.virality.value_counts().plot(kind=\"bar\", color=[\"red\", \"green\",\"blue\",\"grey\",\"yellow\"])","45205452":"df1_tweets.isna().sum()","83333ceb":"missing_values_count = df1_tweets.isnull().sum()\n\ntotal_cells = np.product(df1_tweets.shape)\n\ntotal_missing = missing_values_count.sum()\n\npercentage_missing = (total_missing\/total_cells)*100\nprint(percentage_missing)","1f48af1d":"NAN = [(c, df1_tweets[c].isnull().mean()*100) for c in df1_tweets]\nNAN = pd.DataFrame(NAN, columns=['column_name', 'percentage'])\nNAN","9aa1510c":"df1_tweets.ffill(inplace=True)","649c005f":"df1_tweets.head()","bda7d12a":"df1_tweets.isna().sum()","137a7229":"df1_tweets['tweet_attachment_class'].value_counts().plot(kind ='bar',figsize=[10,5])\ndf1_tweets['tweet_attachment_class'].value_counts()","a9d715c5":"from sklearn import preprocessing","28b0a859":"le = preprocessing.LabelEncoder()\nle.fit(df1_tweets['tweet_has_attachment'])\nlist(le.classes_)\ndf1_tweets['tweet_has_attachment'] = le.transform(df1_tweets['tweet_has_attachment']) ","ccdeafa5":"le1 = preprocessing.LabelEncoder()\nle.fit(df1_tweets['tweet_attachment_class'])\nlist(le.classes_)\ndf1_tweets['tweet_attachment_class'] = le.transform(df1_tweets['tweet_attachment_class'])","b19dc399":"from sklearn.ensemble import RandomForestRegressor","c878973b":"x = df1_tweets.copy()\ny = x.pop('virality')","abf1bd98":"for colname in x.select_dtypes('object'):\n    x[colname],_ = x[colname].factorize()\n    \ndiscrete_features = x.dtypes ==int","97ae8818":"z = df1_tweets[\"virality\"]\n\nsns.countplot(z)\n\n\ntarget_temp = df1_tweets.virality .value_counts()\n\nprint(target_temp)","96208652":"print(\"Percentage of tweets rated 5: \"+str(y.where(y==5).count()*100\/29625))\nprint(\"Percentage of tweets rated 4: \"+str(y.where(y==4).count()*100\/29625))\nprint(\"Percentage of tweets rated 3: \" +str(y.where(y==3).count()*100\/29625))\nprint(\"Percentage of tweets rated 2: \"+str(y.where(y==2).count()*100\/29625))\nprint(\"Percentage of tweets rated 1: \"+str(y.where(y==1).count()*100\/29625))","3fce0f6f":"print(df1_tweets[\"tweet_user_id\"].unique())\nplt.figure(figsize=(13,7))\nsns.barplot(df1_tweets[\"tweet_user_id\"],y)","1f5ec82e":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(categorical_val, 1):\n    plt.subplot(3, 3, i)\n    df1_tweets[df1_tweets[\"virality\"] == 1][column].hist(bins=40, color='red', label='ads = *', alpha=1,width=0.2)\n    df1_tweets[df1_tweets[\"virality\"] == 2][column].hist(bins=40, color='blue', label='ads = **', alpha=1,width=0.2)\n    df1_tweets[df1_tweets[\"virality\"] == 3][column].hist(bins=40, color='green', label='ads = ***', alpha=1,width=0.2)\n    df1_tweets[df1_tweets[\"virality\"] == 4][column].hist(bins=40, color='yellow', label='ads = ****', alpha=1,width=0.2)\n    df1_tweets[df1_tweets[\"virality\"] == 5][column].hist(bins=40, color='violet', label='ads = *****', alpha=1,width=0.2)\n    plt.legend()\n    plt.xlabel(column)","922a6ae9":"print(df1_tweets[\"tweet_topic_ids\"].unique())\nplt.figure(figsize=(13,7))\nsns.barplot(df1_tweets[\"tweet_topic_ids\"],y)","08524c35":"sns.distplot(df1_tweets[\"tweet_hashtag_count\"])","675b332e":"sns.histplot(data=df1_tweets, x=\"tweet_created_at_year\", kde = True)","2523df27":"plt.figure(figsize=(14,6))\nsns.histplot(data=df1_tweets, x=\"tweet_user_id\", hue=\"virality\",multiple=\"stack\")","6336cb9c":"df1_tweets","d9a98ce0":"plt.figure(figsize=(14,6))\nsns.histplot(data=df1_tweets, x=\"tweet_created_at_day\", hue=\"virality\",multiple=\"stack\")","e36cdec1":"plt.figure(figsize=(14,6))\nsns.histplot(data=df1_tweets, x=\"tweet_created_at_hour\", hue=\"virality\",multiple=\"stack\")","8bb6890b":"plt.figure(figsize=(14,6))\nsns.histplot(data=df1_tweets, x=\"tweet_created_at_month\", hue=\"virality\",multiple=\"stack\")","7bad5299":"sns.histplot(\n    df1_tweets, x=\"tweet_created_at_hour\", y=\"virality\", hue=\"virality\", legend=False\n)","775e433e":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.30,random_state=0)","2173c813":"X_train.shape","eba2d852":"X_test.shape","824aa75f":"from sklearn.metrics import accuracy_score","7386e4b8":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(X_train,Y_train)\n\nY_pred_nb = nb.predict(X_test)","e451c072":"Y_pred_nb.shape","3867d257":"score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")","fde0010e":"import xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model.fit(X_train, Y_train)\n\nY_pred_xgb = xgb_model.predict(X_test)","a017be05":"score_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using XGBoost is: \"+str(score_xgb)+\" %\")","5c18627e":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train,Y_train)\nY_pred_knn=knn.predict(X_test)","62b225e9":"score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")","9fe35e71":"from sklearn.tree import DecisionTreeClassifier\n\nmax_accuracy = 0\n\n\nfor x in range(200):\n    dt = DecisionTreeClassifier(random_state=x)\n    dt.fit(X_train,Y_train)\n    Y_pred_dt = dt.predict(X_test)\n    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n    if(current_accuracy>max_accuracy):\n        max_accuracy = current_accuracy\n        best_x = x\n\n\ndt = DecisionTreeClassifier(random_state=best_x)\ndt.fit(X_train,Y_train)\nY_pred_dt = dt.predict(X_test)","41b9660f":"score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")","42dac48a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.metrics import roc_auc_score","32a4e80f":"classifier = RandomForestClassifier()\nclassifier.fit(X_train, Y_train)","ab61b043":"y_pred = classifier.predict(X_test)\n\nprint(\"Classification Report:\",)\nprint (classification_report(Y_test, y_pred))\nprint(\"Accuracy:\", accuracy_score(Y_test,y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(Y_test, y_pred))","e6ae9619":"score_rdc = round(accuracy_score(y_pred,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using random forest is: \"+str(score_rdc)+\" %\")","2c666cf4":"scores = [score_nb,score_knn,score_dt,score_xgb]\nalgorithms = [\"Naive Bayes\",\"K-Nearest Neighbors\",\"Decision Tree\",\"XGBoost\"]    \n\nfor i in range(len(algorithms)):\n    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")","ae7ef15c":"sns.set(rc={'figure.figsize':(8,6)})\nplt.xlabel(\"Algorithms\")\nplt.ylabel(\"Accuracy score\")\n\nsns.barplot(algorithms,scores)","4e5224f8":"df2_tweets","b2f4cb22":"NAN = [(c, df2_tweets[c].isnull().mean()*100) for c in df2_tweets]\nNAN = pd.DataFrame(NAN, columns=['column_name', 'percentage'])\nNAN","896dc821":"columns_None = ['tweet_topic_ids']\ndf2_tweets[columns_None] = df2_tweets[columns_None].fillna(df2_tweets.mode().iloc[0])","25bd3fd9":"le2 = preprocessing.LabelEncoder()\nle2.fit(df2_tweets['tweet_has_attachment'])\nlist(le2.classes_)\ndf2_tweets['tweet_has_attachment'] = le2.transform(df2_tweets['tweet_has_attachment'])","4f6b9a3b":"le3 = preprocessing.LabelEncoder()\nle3.fit(df2_tweets['tweet_attachment_class'])\nlist(le3.classes_)\ndf2_tweets['tweet_attachment_class'] = le3.transform(df2_tweets['tweet_attachment_class'])","dc425857":"df2_tweets. info()","7bee2603":"from sklearn.ensemble import RandomForestRegressor","cdd1273a":"for colname in df2_tweets.select_dtypes('object'):\n    df2_tweets[colname],_ = df2_tweets[colname].factorize()\n    \ndiscrete_features = df2_tweets.dtypes ==int","be77ee43":"df2_tweets","de8b7354":"df2_tweets.shape","e3e24423":"Y_pred_xgb = xgb_model.predict(df2_tweets)","84bde12a":"Y_pred_dt = dt.predict(df2_tweets)","ea762ed1":"Y_pred_knn=knn.predict(df2_tweets)","5b37bca8":"submission1 = pd.DataFrame({\n        \"tweet_id\": df2_tweets['tweet_id'],\n        \"Virality\": Y_pred_xgb\n    })","8524f081":"submission2 = pd.DataFrame({\n        \"tweet_id\": df2_tweets['tweet_id'],\n        \"Virality\": Y_pred_knn\n    })","021c73e8":"submission3 = pd.DataFrame({\n        \"tweet_id\": df2_tweets['tweet_id'],\n        \"virality\": Y_pred_dt\n    })","82b73be6":"#### At evening time tweets go viral due to most of the person goes free at evening time.","de845d2a":"## K Nearest Neighbors","806220d4":"## Train Test Split","3a65c0e1":"## Final Accuracy of all Models that which Model is best fitted","c24b56ec":"## Decision Tree","a30c1891":"## Random Forest Classifier","7d5cdaf2":"## Naive Bayes","4ca540e1":"## Model Fitting","b67ee137":"### Rating 1 tweets ar made at daily basis but virality is not so much but 5 star are less nut go much viral","16414a6e":"## XG Boost","c8767cae":"##### tweets are most viral in july , august, september but fall in october due to exam time & this shows virality main focused by students"}}