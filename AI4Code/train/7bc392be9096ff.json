{"cell_type":{"d74eefd1":"code","ba16f41f":"code","fa53c3c0":"code","b7908b1b":"code","2f61be2d":"code","00e33736":"code","583076d1":"code","9b7db23a":"code","9723fbe0":"code","1f0e8726":"code","b3a4c53e":"code","7b1303f9":"code","5ef312ad":"code","7b81027a":"code","a10d00f4":"code","8f1c5e06":"code","0520557a":"code","a236d879":"markdown","4a28472a":"markdown"},"source":{"d74eefd1":"  import numpy as np\n  from sklearn.linear_model import LogisticRegression\n  from sklearn import svm\n  from sklearn import datasets\t\t\n  from sklearn import svm    \t\t\t\n  import numpy as np\n  import matplotlib.pyplot as plt   \n  from sklearn.ensemble import RandomForestClassifier, VotingClassifier","ba16f41f":"# import iris data to model Svm classifier\nI_D=datasets.load_iris()","fa53c3c0":"I_D['data']","b7908b1b":"I_D['target']","2f61be2d":"#visualize_sepal_data taking first two features\nx=I_D.data[:,:2]  \ny=I_D.target\nplt.scatter(x[:,0],x[:,1], c=y)\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\nplt.title('Sepal Width & Length')\nplt.show()","00e33736":"#visualize_petal_data taking last two features\nx=I_D.data[:,2:]  \ny=I_D.target\nplt.scatter(x[:,0],x[:,1], c=y)\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')\nplt.title('Petal Width & Length')\nplt.show()","583076d1":"# Now we use a spilt function\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(I_D.data,I_D.target,test_size=0.2)","9b7db23a":"#we apply a support vector m\/c\n\n#SVM model with linear kernel\nx_sepal=x_train[:,:2] \ny_sepal=y_train\n\nsvc=svm.SVC(kernel='linear', C=2.8).fit(x_sepal,y_sepal)","9723fbe0":"# LinearSVC (linear kernel)\nlin_svc = svm.LinearSVC(C=2.8,max_iter=3000).fit(x_sepal, y_sepal)\n\n# SVC with RBF kernel\nrbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=2.8).fit(x_sepal, y_sepal)\n\n# SVC with polynomial (degree 3) kernel\npoly_svc = svm.SVC(kernel='poly', degree=3, C=2.8).fit(x_sepal, y_sepal)","1f0e8726":"# Sepal test parformance\n\ny_pred_svc=svc.predict(x_test[:,:2])\ny_pred_lin_svc=lin_svc.predict(x_test[:,:2])\ny_pred_rbf_svc=rbf_svc.predict(x_test[:,:2])\ny_pred_poly_svc=poly_svc.predict(x_test[:,:2])\n\n#print Sepal test Praformance\n\nfrom sklearn.metrics import accuracy_score as ac\nprint(\"Accuracy Score:\")\nprint('SVM with kernel(linear):',ac(y_test,y_pred_svc)*100)\nprint('SVM with linear svc:',ac(y_test,y_pred_lin_svc)*100)\nprint('SVM with kernel(rbf):',ac(y_test,y_pred_rbf_svc)*100)\nprint('SVM with kernel(poly):',ac(y_test,y_pred_poly_svc)*100)","b3a4c53e":"# sepal training performance\n\ny_pred_svc=svc.predict(x_sepal)\ny_pred_lin_svc=lin_svc.predict(x_sepal)\ny_pred_rbf_svc=rbf_svc.predict(x_sepal)\ny_pred_poly_svc=poly_svc.predict(x_sepal)\n\n# print for sepal training performance\n\nfrom sklearn.metrics import accuracy_score as ac\nprint(\"Accuracy Score:\")\nprint('SVM with kernel(linear):',ac(y_sepal,y_pred_svc)*100)\nprint('SVM with linear svc:',ac(y_sepal,y_pred_lin_svc)*100)\nprint('SVM with kernel(rbf):',ac(y_sepal,y_pred_rbf_svc)*100)\nprint('SVM with kernel(poly):',ac(y_sepal,y_pred_poly_svc)*100)\n","7b1303f9":"#SVM model with linear kernel\nx_petal=x_train[:,2:] \ny_petal=y_train\n\nsvc1=svm.SVC(kernel='linear', C=1.0).fit(x_petal,y_petal)","5ef312ad":"# LinearSVC (linear kernel)\nlin_svc1 = svm.LinearSVC(C=1.0,max_iter=3000).fit(x_petal, y_petal)\n\n# SVC with RBF kernel\nrbf_svc1 = svm.SVC(kernel='rbf', gamma=0.7, C=1.0).fit(x_petal, y_petal)\n\n# SVC with polynomial (degree 3) kernel\npoly_svc1 = svm.SVC(kernel='poly', degree=5, C=1.0).fit(x_petal, y_petal)","7b81027a":"# Testing performance for Petal\ny_pred_svc1=svc.predict(x_test[:,2:])\ny_pred_lin_svc1=lin_svc.predict(x_test[:,2:])\ny_pred_rbf_svc1=rbf_svc.predict(x_test[:,2:])\ny_pred_poly_svc1=poly_svc.predict(x_test[:,2:])\n\n# print testing performance for Petal\n\nprint(\"Accuracy Score:\")\nprint('SVM with kernel(linear):',ac(y_test,y_pred_svc1)*100)\nprint('SVM with linear svc:',ac(y_test,y_pred_lin_svc1)*100)\nprint('SVM with kernel(rbf):',ac(y_test,y_pred_rbf_svc1)*100)\nprint('SVM with kernel(poly):',ac(y_test,y_pred_poly_svc1)*100)","a10d00f4":"# Petal training performance\n\ny_pred_svc1=svc.predict(x_petal)\ny_pred_lin_svc1=lin_svc.predict(x_petal)\ny_pred_rbf_svc1=rbf_svc.predict(x_petal)\ny_pred_poly_svc1=poly_svc.predict(x_petal)\n\n# print for sepal training performance\n\nfrom sklearn.metrics import accuracy_score as ac\nprint(\"Accuracy Score:\")\nprint('SVM with kernel(linear):',ac(y_petal,y_pred_svc1)*100)\nprint('SVM with linear (svc):',ac(y_petal,y_pred_lin_svc1)*100)\nprint('SVM with kernel(rbf):',ac(y_petal,y_pred_rbf_svc1)*100)\nprint('SVM with kernel(poly):',ac(y_petal,y_pred_poly_svc1)*100)\n\n\n","8f1c5e06":"  clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n  clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n  clf3 = svm.SVC()","0520557a":"##VOTING CLASSIFIER\nfrom sklearn.ensemble import VotingClassifier\n\n#create a dictionary of our models\nestimators=[('log_reg', clf1), ('rf', clf2), ('svm', clf3)]\n\n#create our voting classifier, inputting our models\nensemble = VotingClassifier(estimators, voting='hard')\n\n#fit model to training data\nensemble.fit(x_sepal, y_sepal)\n\n#test our model on the test data\nensemble.score(x_sepal, y_sepal)","a236d879":"# SVM Model for Petal","4a28472a":"# Use iris dataset. Create a stacked model of ensemble using RandomForest, SVM and Logistic Regression. Evaluate your model performance.\n"}}