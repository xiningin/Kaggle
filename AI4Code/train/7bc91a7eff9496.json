{"cell_type":{"8bd9dd54":"code","5e78a0be":"code","d8d999ac":"code","db710be3":"code","83a5b124":"code","9a6248e0":"code","8ade9f49":"code","ed12b4c8":"code","87d51efd":"code","374f20d3":"code","48fc2a51":"code","d7b599a7":"code","f8de8235":"code","37a9ba4d":"markdown","5779ee4a":"markdown","9a6cc0df":"markdown","f59f6889":"markdown","75ed8c3c":"markdown","3d115795":"markdown","8d1d76af":"markdown","48eca436":"markdown","9ce679e1":"markdown","4a3b2636":"markdown","3d1b3806":"markdown","e34846de":"markdown","31b9fadf":"markdown"},"source":{"8bd9dd54":"# importing python packages:\nimport pandas as pd\nfrom decimal import Decimal\nfrom sklearn.metrics import mean_absolute_error\nfrom matplotlib.pyplot import hist\nimport seaborn as sns\nfrom numpy import sum\nfrom numpy import median\nfrom numpy import mean\nfrom sklearn import preprocessing\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.linear_model import Lasso\nfrom matplotlib.pyplot import hist\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.linear_model import Lasso\n# loading files:\nmain_file=\"..\/input\/neobank-transactions\/2016-09-19_79351_training.csv\"\nmain=pd.read_csv(main_file,parse_dates=['transaction_date'], dtype = {'mcc_group':'str','user_id': 'str','amount_n26_currency': 'int','transaction_type': 'str'})\ntransaction_type_file=\"..\/input\/neobank-transactions\/transaction_types.csv\"\ntransaction_type=pd.read_csv(transaction_type_file, dtype='str')\nmcc_group_file=\"..\/input\/neobank-transactions\/mcc_group_definition.csv\"\nmcc_group=pd.read_csv(mcc_group_file, dtype='str')\n# handling null values:\nmain.columns = main.columns.str.strip()\nmain['mcc_group'] = main['mcc_group'].fillna('Unknown')\n# data integration:\ntesting_training=pd.merge(left=main,right=transaction_type,how='left', left_on='transaction_type', right_on='type')\ntesting_training=pd.merge(left=testing_training,right=mcc_group,how='left', left_on='mcc_group', right_on='mcc_group')\ntesting_training=testing_training[['user_id','transaction_date','explanation_y','agent','direction','explanation_x','amount_n26_currency']]","5e78a0be":"#delivered column for month:\ntesting_training['month'] = testing_training['transaction_date'].dt.month\n#split to trainig and testing sets:\ntesting=testing_training[testing_training['month']==7]\ntraining=testing_training[testing_training['month']!=7]\n#removing non-mutual users:\ncond = ~training['user_id'].isin(testing['user_id'])\ntraining=training.drop(training[cond].index)\ncond = ~testing['user_id'].isin(training['user_id'])\ntesting=testing.drop(testing[cond].index)\n#soring by user id:\ntesting =testing.sort_values(by=['user_id'], ascending=True)\ntraining =training.sort_values(by=['user_id'], ascending=True)","d8d999ac":"#converting direction rows to columns:\ntesting_user=testing.pivot_table( index = ['user_id'] , columns=['direction'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\ntesting_user=testing_user.reset_index()\ntraining_user=training.pivot_table( index = ['user_id'] , columns=['direction'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\ntraining_user=training_user.reset_index()\n#instantiating:\nmape_total_out=0\nmape_total_in=0\ntotal_AE_out={}\ntotal_AE_in={}\n# avoiding division by zero error using temporary values:\ntraining_user.loc[training_user['In'] ==0, 'In'] =0.46395169417715465\ntraining_user.loc[training_user['Out'] ==0, 'Out'] = 0.6283420872431762\ntesting_user.loc[testing_user['In'] ==0, 'In'] =0.46395169417715465\ntesting_user.loc[testing_user['Out'] ==0, 'Out'] = 0.6283420872431762\n#comparing Comparing the average of training set with corresponding users in testing set:\nfor i in range(0, len(training_user.index)):\n        if float(training_user.values[i,2])==float(testing_user.values[i,2]):\n            mape_out=0\n        else:\n            mape_out=abs((float(training_user.values[i,2])-float(testing_user.values[i,2]))\/float(training_user.values[i,2]))*100\n        total_AE_out[training_user.values[i,0]]=mape_out\n        mape_total_out=mape_total_out+mape_out\n        if float(training_user.values[i,1])==float(testing_user.values[i,1]):\n            mape_in=0\n        else:\n            mape_in=abs((float(training_user.values[i,1])-float(testing_user.values[i,1]))\/float(training_user.values[i,1]))*100\n        total_AE_in[training_user.values[i,0]]=mape_in\n        mape_total_in=mape_total_in+mape_in\n# calculacting accuracy:\nmape_average_out=mape_total_out\/i\nmape_average_in=mape_total_in\/i\n# Visualization:\nprint(mape_average_in,'% error (MAPE) for income')\nprint(mape_average_out,'% error (MAPE) for expense')  \nfig, axes = plt.subplots(1, 2)       \nplt.rcdefaults()\n\nbin_list=[]\nfor i in range(0,200,2):\n    bin_list.append(i)\naxes[0].hist(total_AE_in.values(), rwidth=0.7,bins=bin_list, color='g')\naxes[1].hist(total_AE_out.values(), rwidth=0.7,bins=bin_list,  color='r')\naxes[0].set_title('Income error percentage')\naxes[1].set_title('Expense error percentage')\naxes[1].set_ylabel('Number of Clients')\naxes[0].set_ylabel('Number of Clients')\naxes[1].set_xlabel('MAPE (error %)')\naxes[0].set_xlabel('MAPE (error %)')\nplt.grid(axis='y', alpha=0.75)   \n","db710be3":"#Dividing users to highly accurate users versus low accurate users:\nAccurate_users={}\nNot_accurate_users={}\nthreshold=10\nfor key in total_AE_in:\n    value=total_AE_in[key]\n    if value<=threshold:\n        Accurate_users[key]=value\n    else:\n        Not_accurate_users[key]=value\nfor key in total_AE_out:\n    value=total_AE_out[key]\n    if value<=10:\n        Accurate_users[key]=value\n    else:\n        Not_accurate_users[key]=value\ncond = ~training['user_id'].isin(Accurate_users.keys())\naccurate=training.drop(training[cond].index)\ncond = training['user_id'].isin(Accurate_users.values())\nnot_accurate=training.drop(training[cond].index)\n#Aggregated dataframe based on user id and month:\nnot_accurate_monthly=not_accurate.groupby(['user_id','month'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\nnot_accurate_monthly=not_accurate_monthly.reset_index()\naccurate_monthly=accurate.groupby(['user_id', 'month'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\naccurate_monthly=accurate_monthly.reset_index()","83a5b124":"fig, axes = plt.subplots(1, 2)\nbin_list=[]\nfor i in range(0,150,2):\n    bin_list.append(i)\naccurate_monthly['mean'].plot.hist(bins=bin_list,grid=True, rwidth=0.9,label='accurate',ax=axes[0], color='g')\nnot_accurate_monthly['mean'].plot.hist(bins=bin_list, grid=True, rwidth=0.9, label='not_accurate', ax=axes[1], color='r')\naxes[1].set_xlabel('Amount of transactions')\naxes[0].set_xlabel('Amount of transactions')\naxes[1].set_ylabel('Number of Clients')\naxes[0].set_ylabel('Number of Clients')\naxes[1].legend()\naxes[0].legend()\nplt.legend(loc='upper right')\nplt.grid(axis='y', alpha=0.75)","9a6248e0":"#Aggregated dataframe based on direction column:\nnot_accurate_direction=not_accurate.groupby(['direction'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\nnot_accurate_direction=not_accurate_direction.reset_index()\naccurate_direction=accurate.groupby(['direction'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\naccurate_direction=accurate_direction.reset_index()\n#Visualization:\nsns.set_style('whitegrid')\nfig, ax =plt.subplots(1,2)\nplt.subplots_adjust(hspace = 0.8)\nfig.set_size_inches(11.7, 4.27)\nsns.barplot(y='direction',palette = 'hls',order = [\"In\", \"Out\"] ,x='mean', data=accurate_direction, ax=ax[0], estimator=mean).set_title('Amount of Transaction Directions (High accuracy users)')\nsns.barplot(y='direction',palette = 'hls',order = [\"In\", \"Out\"], x='mean', data=not_accurate_direction, ax=ax[1], estimator=mean).set_title('Amount of Transaction Directions (Low accuracy users)')","8ade9f49":"#Aggregated dataframe based on month and explanation_y columns:\nnot_accurate_explanation_y=not_accurate.groupby(['month','explanation_y'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\nnot_accurate_explanation_y=not_accurate_explanation_y.reset_index()\naccurate_explanation_y=accurate.groupby(['month','explanation_y'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\naccurate_explanation_y=accurate_explanation_y.reset_index()\n#visualization:\nsns.set_style('whitegrid')\nfig, ax =plt.subplots(1,2)\nplt.subplots_adjust(hspace = 0.8)\nfig.set_size_inches(11.7, 7.27)\nplt.subplots_adjust(hspace = 0.2,wspace = 0.8)\nsns.barplot(y='explanation_y',ci = None, x='mean', data=accurate_explanation_y, ax=ax[0], estimator=mean).set_title('Amount of Explanation_why (High accuracy users)')\nsns.barplot(y='explanation_y',ci = None,  x='mean', data=not_accurate_explanation_y, ax=ax[1], estimator=mean).set_title('Amount of explanation_why (Low accuracy users)')","ed12b4c8":"#Aggregated dataframe based on the explanation_x column:\nnot_accurate_explanation_x=not_accurate.groupby(['explanation_x'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\nnot_accurate_explanation_x=not_accurate_explanation_x.reset_index()\naccurate_explanation_x=accurate.groupby(['explanation_x'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\naccurate_explanation_x=accurate_explanation_x.reset_index()\nsns.set_style('whitegrid')\n#visualization:\nfig, ax =plt.subplots(1,2)\nplt.subplots_adjust(hspace = 0.8)\nfig.set_size_inches(11.7, 7.27)\nplt.subplots_adjust(hspace = 0.2,wspace = 0.8)\nsns.barplot(y='explanation_x',ci = None, x='mean', data=accurate_explanation_x, ax=ax[0], estimator=mean).set_title('Amount of transaction types (accurate)')\nsns.barplot(y='explanation_x',ci = None,  x='mean', data=not_accurate_explanation_x, ax=ax[1], estimator=mean).set_title('Amount of transaction types (not_accurate)')","87d51efd":"#Aggregated dataframe based on month and agent columns:\nnot_accurate_agent=not_accurate.groupby(['month','agent'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\nnot_accurate_agent=not_accurate_agent.reset_index()\nnot_accurate_agent.to_csv('not_accurate_agent.csv')\naccurate_agent=accurate.groupby(['month','agent'], as_index=False).amount_n26_currency.agg(['max', 'min', 'count', 'median', 'mean','sum'])\naccurate_agent=accurate_agent.reset_index()\naccurate_agent.to_csv('accurate_agent.csv')\n#visualization:\nsns.set_style('whitegrid')\nfig, ax =plt.subplots(1,2)\nplt.subplots_adjust(hspace = 0.8)\nfig.set_size_inches(11.7, 7.27)\nplt.subplots_adjust(hspace = 0.2,wspace = 0.8)\nsns.barplot(y='agent',ci = None, x='mean', data=accurate_agent, ax=ax[0], estimator=mean).set_title('Amount of Transaction per Medium (accurate)')\nsns.barplot(y='agent',ci = None,  x='mean', data=not_accurate_agent, ax=ax[1], estimator=mean).set_title('Amount of Transaction per Medium (not_accurate)')","374f20d3":"#converting distinct entries of explanation_y values to columns:\npivoted_explanation_y=testing_training.pivot_table( index = ['user_id','month'] , columns=['explanation_y'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\npivoted_explanation_y_training=pivoted_explanation_y.reset_index()\n#converting distinct entries of explanation_x values to columns:\npivoted_explanation_x=testing_training.pivot_table( index = ['user_id','month'] , columns=['explanation_x'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\npivoted_explanation_x=pivoted_explanation_x.reset_index()\n#converting distinct entries of direction values to columns:\npivoted_direction=testing_training.pivot_table( index = ['user_id','month'] , columns=['direction'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\npivoted_direction=pivoted_direction.reset_index()\n#converting distinct entries of direction values to columns:\npivoted_agent=testing_training.pivot_table( index = ['user_id','month'] , columns=['agent'], values = 'amount_n26_currency', aggfunc='mean').fillna(0)\npivoted_agent=pivoted_agent.reset_index()\n# group by user_id and month columns:\nmonthly=testing_training.groupby(['user_id','month'], as_index=False).amount_n26_currency.mean()\nmonthly=monthly.reset_index()\n# merging all pivoted data:\npivoted=pd.merge(left=monthly,right=pivoted_explanation_y,how='left', left_on=['user_id','month'], right_on=['user_id','month'])\npivoted=pd.merge(left=pivoted,right=pivoted_explanation_x,how='left', left_on=['user_id','month'], right_on=['user_id','month'])\npivoted=pd.merge(left=pivoted,right=pivoted_agent,how='left', left_on=['user_id','month'], right_on=['user_id','month'])\npivoted=pd.merge(left=pivoted,right=pivoted_direction,how='left', left_on=['user_id','month'], right_on=['user_id','month'])\npreprocessed=pivoted.reset_index()\n# dividing data to testing and training (month July is testing)\npreprocessed_testing=preprocessed[preprocessed['month']==7]\npreprocessed_training=preprocessed[preprocessed['month']!=7]\npreprocessed.head()","48fc2a51":"# selecting training and testing columns:\ncolumns=preprocessed_training.columns\ncolumns=columns.drop('user_id')\ncolumns=columns.drop('index')\ncolumns=columns.drop('level_0')\ncolumns=columns.drop('In')\ncolumns=columns.drop('Out')\ny_train = preprocessed_training[['In','Out']]\npreprocessed_training=preprocessed_training[columns]\nX_train=preprocessing.scale(preprocessed_training[columns])\nprint(X_train.shape)\nX_test=preprocessing.scale(preprocessed_testing[columns])\ny_test = preprocessed_testing[['In','Out']]\n# defining the model:\nmodel_july = Lasso(alpha=1.0, max_iter = 100000)\n# training the model:\nmodel_july.fit(X_train, y_train)\n# predicting unseen values (testing is month july):\nprediction_result=model_july.predict(X_test)\n# instantiating accuracy variables:\ntotal_AE_out={}\nmape_total_out=0\ntotal_AE_in={}\nmape_total_in=0\n# avoiding division by zero error using temporary values:\ny_test.loc[y_test['In'] ==0, 'In'] =0.46395169417715465\ny_test.loc[y_test['Out'] ==0, 'Out'] = 0.6283420872431762\n# measuring accuracy (MAPE):\nfor i in range(0, len(y_test)):\n        mape_out=abs((y_test.iloc[i]['Out']-prediction_result[i][1])\/y_test.iloc[i]['Out'])*100\n        total_AE_out[i]=mape_out\n        mape_total_out=mape_total_out+mape_out\n        mape_in=abs((y_test.iloc[i]['In']-prediction_result[i][0])\/y_test.iloc[i]['In'])*100\n        total_AE_in[i]=mape_in\n        mape_total_in=mape_total_in+mape_in\nmape_average_in=mape_total_in\/i\nmape_average_out=mape_total_out\/i\n#visualization:\nprint(mape_average_in,'% error for incomes')\nprint(mape_average_out,'% error for expenses')\nfig, axes = plt.subplots(1, 2, constrained_layout=True)       \nplt.rcdefaults()\naxes[0].hist(total_AE_in.values(), color='g',bins=bin_list)\naxes[1].hist(total_AE_out.values(), color='r',bins=bin_list)\naxes[0].set_title('Income error percentage')\naxes[1].set_title('Expense error percentage')\naxes[1].set_ylabel('Number of Clients')\naxes[0].set_ylabel('Number of Clients')\naxes[1].set_xlabel('MAPE (error %)')\naxes[0].set_xlabel('MAPE (error %)')\nplt.grid(axis='y', alpha=0.75)","d7b599a7":"print(model_july.coef_[0])\nprint(preprocessed_training.columns[(model_july.coef_[0]!=0).ravel().tolist()])\nprint(model_july.coef_[1])\nprint(preprocessed_training.columns[(model_july.coef_[1]!=0).ravel().tolist()])","f8de8235":"columns=preprocessed.columns\n\npreprocessed_selected=preprocessed[columns]\ny_train =preprocessed_selected[['In','Out']]\n\ny_test =preprocessed_selected[['In','Out']]\ncolumns=columns.drop('user_id')\ncolumns=columns.drop('index')\ncolumns=columns.drop('In')\ncolumns=columns.drop('Out')\npreprocessed_selected=preprocessed_selected[columns]\nX_train=preprocessing.scale(preprocessed_selected[columns])\npreprocessed_selected['month']=8\nX_test=preprocessing.scale(preprocessed_selected[columns])\nmodel = Lasso(alpha=1.0, max_iter = 100000)\nmodel.fit(X_train, y_train)\nprediction_result=model.predict(X_test)\npreprocessed['Income'] = prediction_result[:, 0]\npreprocessed['Expense'] =prediction_result[:, 1]\npreprocessed.to_csv(\"result.csv\", columns=['user_id','month','Income', 'Expense'], index=False)","37a9ba4d":"Lasso model to generate result for the month August:","5779ee4a":"Histogram: Amount of transaction per month for highly accurate users versus low accurate users:","9a6cc0df":"1. Calculating average for training set\n2. Comparing the average of training set with corresponding users in testing set\n3. measuring accuracy using MAPE\n4. visualization","f59f6889":"1. Import required packages\n2. read csv files\n3. merge join files","75ed8c3c":"Comparing the input and output transactions between highly accurate users and low accurate users:","3d115795":"Lasso model to predict July data:","8d1d76af":"Comparing the reasons of transactions between highly accurate users and low accurate users:","48eca436":"shrinked features:","9ce679e1":"1. Dividing users to highly accurate users versus low accurate users based on the above average technique (threshold is 10% MAPE)\n2. Aggregating dataframe based on user id and month","4a3b2636":"Data pivoting:","3d1b3806":"1. create a delivered column for month of transaction\n2. split to trainig and testing sets. Testing is for the month July and training is for Feb-May.\n3. removing non-mutual users\n4. #soring by user id:","e34846de":"Comparing the transaction media between highly accurate users and low accurate users:","31b9fadf":"Comparing the transaction types between highly accurate users and low accurate users:"}}