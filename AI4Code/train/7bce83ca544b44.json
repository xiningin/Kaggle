{"cell_type":{"1062f274":"code","e9becbec":"code","3200af83":"code","3bc8caf5":"code","6bf1c970":"code","8f891d68":"code","ab097c10":"code","6fbac2cf":"code","bde04a87":"code","1ac30f16":"code","457a033e":"code","106ac5eb":"code","0ab4c268":"code","0c00534d":"code","6fd28d47":"code","fadf88d9":"code","44043203":"code","36fd533b":"code","b5721f34":"code","187c2dd3":"code","fd3d3470":"code","c6231826":"code","7bbee500":"code","211fb301":"code","445637da":"code","b52886a7":"code","27cb33d6":"code","f1d9f868":"markdown","a5061b35":"markdown","1946f07c":"markdown","8a324c54":"markdown","f09341fa":"markdown","662a12b2":"markdown"},"source":{"1062f274":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd \nfrom skimage import io, color\nimport skimage\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e9becbec":"def display(img):\n    plt.figure()\n    plt.set_cmap('gray')\n    plt.imshow(img)\n    plt.show()\n\n\ndef combineLAB(l, a, b):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = a\n    zeros[:, :, 2] = b\n    return zeros\n\n\ndef combineAB(a, b):\n    shape = (a.shape[0], b.shape[1], 2)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = a\n    zeros[:, :, 1] = b\n    return zeros\n\n\ndef combineL_AB(l, ab):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = ab[:, :, 0]\n    zeros[:, :, 2] = ab[:, :, 1]\n    return zeros\n\n\ndef make3channels(gray):\n    shape = (gray.shape[0], gray.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = gray\n    zeros[:, :, 1] = gray\n    zeros[:, :, 2] = gray\n    return zeros\n\n\ndef get_l_from_gray(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    gray = color.rgb2gray(img)\n    gray = make3channels(gray)\n    lgray = color.rgb2lab(gray, illuminant='D50')[:, :, 0]\n    return lgray\n\n\ndef get_ab_from_file(file):\n    img = io.imread(file)\n    ab = np.zeros((64, 64, 2))\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n\n\ndef lab_normal_image(path):\n    l, ab = load_img_for_training(path)\n    l, ab = (l-127.5)\/127.5, (ab-127.5)\/127.5\n    return l, ab\n\n\ndef rgb_image(l, ab):\n    shape = (l.shape[0],l.shape[1],3)\n    img = np.zeros(shape)\n    img[:,:,0] = l[:,:,0]\n    img[:,:,1:]= ab\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    return img\n\n\ndef load_img_for_training(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    lab = color.rgb2lab(img, illuminant='D50')\n    l, a, b = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n    ab = combineAB(a, b)\n    lgray = get_l_from_gray(img_path)\n    return lgray, ab\n\n\ndef save_ab_file(image, filepath):\n    # add in 0zeros to its first component\n    shape = (image.shape[0], image.shape[1], 3)\n    new_ab_image = np.zeros(shape)\n    new_ab_image[:, :, 1] = image[:, :, 0]\n    new_ab_image[:, :, 2] = image[:, :, 1]\n    save_file(new_ab_image, filepath)\n\n\ndef save_file(image, filepath):\n    io.imsave(filepath, image)\n\n\ndef load_ab_image(path):\n    img = io.imread(path)\n    shape = (img.shape[0], img.shape[1], 2)\n    ab = np.zeros(shape)\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n","3200af83":"# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","3bc8caf5":"def normalize(image):\n    # convert image from range 0-256 to \n    #image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n    image = image\/255\n    return image\n\ndef unnormalize(image):\n    image = (image*255)\n    return image.astype('uint8')","6bf1c970":"gray_scale = np.load('\/kaggle\/input\/image-colorization\/l\/gray_scale.npy')[:5000]\nab_scale = np.load('\/kaggle\/input\/image-colorization\/ab\/ab\/ab1.npy')[:5000]\nprint(gray_scale.shape)\nprint(ab_scale.shape)","8f891d68":"index = 4579\nl_sample,ab_sample = gray_scale[index].reshape((224,224,1)),ab_scale[index]\nrgb_sample = rgb_image(l_sample,ab_sample)\ndisplay(rgb_sample)\ndisplay(l_sample[:,:,0])","ab097c10":"x = np.zeros((5000,224,224,3), dtype='uint8')\n\nfor i in range(5000):\n    l_sample = (gray_scale[i]).reshape((224,224,1))\n    ab_sample = (ab_scale[i])\n    x[i] = rgb_image(l_sample, ab_sample)\n    \ndisplay(x[0])","6fbac2cf":"print(x[0])","bde04a87":"x = x\/256.0","1ac30f16":"from keras import *\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.optimizers import *\nfrom matplotlib import pyplot as plt\nfrom utils import *\nfrom keras.initializers import RandomNormal, Zeros","457a033e":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16\nimport keras","106ac5eb":"IMAGE_SIZE = (224, 224)\n#IMAGE_SIZE = (160, 160)\n\n# = VGG16(input_shape = (224, 224, 3), # Shape of our images\n#include_top = False, # Leave out the last fully connected layer\n#weights = 'imagenet')\n#base_model = keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.EfficientNetB4(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n\nbase_model = keras.applications.InceptionResNetV2(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.InceptionV3(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n\n#base_model = keras.applications.MobileNetV2(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.ResNet50(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.ResNet152V2(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#base_model = keras.applications.VGG19(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n\n#base_model = keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nbase_model.summary()\nencoder = base_model","0ab4c268":"base_model.output_shape[1:4]\n","0c00534d":"from keras.layers import *\n\n#dec_input = Input((7,7,512))\ndec_input = Input(base_model.output_shape[1:4])\n\n\ndec_x = ReLU()(dec_input)\n\nlayer_dim = [512, 512, 256, 128, 64, 32]\n\nfor i in layer_dim:\n    dec_x = Conv2DTranspose(i, (2, 2), strides=(2, 2), padding='same', activation='relu')(dec_x)\n    dec_x = Conv2D(i, 2, padding='same', activation='relu')(dec_x)\n\n    \ndec_x = Conv2D(3,2,padding='same',activation='sigmoid')(dec_x)\n# resize layer from https:\/\/stackoverflow.com\/questions\/41903928\/add-a-resizing-layer-to-a-keras-sequential-model\ndec_x = keras.layers.Lambda( \n    lambda image: tf.image.resize_images( \n        image, \n        (224, 224), \n        method = tf.image.ResizeMethod.BICUBIC,\n        align_corners = True, # possibly important\n        preserve_aspect_ratio = True\n    )\n)(dec_x)\n\ndecoder = Model(inputs=[dec_input], outputs=[dec_x])\ndecoder.compile(optimizer='adam', loss='mse', metrics=['acc'])\ndecoder.summary()","6fd28d47":"model_out = decoder(encoder.output)\nencoder.trainable=False\nmodel = Model(encoder.input, model_out)\nmodel.compile(optimizer='adam', loss='mae', metrics=['acc'])\nmodel.summary()","fadf88d9":"samples = x.shape[0]\n#epochs = 100\nepochs = 10\n\nhistory = model.fit(x,x,validation_split=0.1,epochs=epochs,batch_size=64,)\nmodel.save('model.h5')","44043203":"h = history\nplt.plot(h.history['acc'])\nplt.plot(h.history['val_acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title('Model Loss')\nplt.show()\n\nplt.plot(h.history['acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.title('Model Loss')\nplt.show()","36fd533b":"def save_images(generator, samples):\n    ab_values = generator.predict(samples)\n    plt.figure()\n    plt.set_cmap('gray')\n    for i in range(ab_values.shape[0]):\n        rgb = unnormalize(ab_values[i])\n        display(rgb)\n        display(samples[i])\n        ax = plt.subplot(64, 64, i+1)\n        im = ax.imshow(rgb)\n        plt.tight_layout()\n        plt.title(i)\n    plt.show()\n    plt.savefig('gan_generated_image.png')\n\nsamples = x[0:10]\nsave_images(model,samples)","b5721f34":"enc_x = encoder.predict(samples)\nprint(enc_x.shape)","187c2dd3":"dec_x = decoder.predict(enc_x)\nprint(dec_x.shape)","fd3d3470":"display(samples[2])","c6231826":"display(dec_x[2])","7bbee500":"encoder.save('enc.h5')","211fb301":"decoder.save('dec.h5')","445637da":"encoder.layers[-1].output.shape.as_list()","b52886a7":"decoder.layers[0].input.shape.as_list()","27cb33d6":"decoder.layers[0].input.shape.as_list() == encoder.layers[-1].output.shape.as_list()","f1d9f868":"**Data Loading**","a5061b35":"# Define Encoder Network using pretrained model","1946f07c":"**UTILS**","8a324c54":"# Combine Encoder and Decoder into one large network","f09341fa":"# Define Decoder Network","662a12b2":"**Architecture**"}}