{"cell_type":{"b3e31ea8":"code","be458d88":"code","95f5dfd5":"code","8e6a28d7":"code","715f34fe":"code","95fec489":"code","d02eae7c":"code","081ff3f4":"code","6c030d70":"code","812cd74a":"code","0ebf55c0":"code","cd833e6d":"code","f31e902c":"code","83903f47":"code","6c35b3a9":"code","ecbaf5e6":"code","58c65504":"code","ec81aff8":"code","7108993f":"code","c968a265":"code","1e0a0354":"code","8e401a68":"code","108264e2":"code","76593923":"code","372d6b3c":"code","dff7ac2e":"code","e4d624f4":"code","7b800afd":"code","ca58877a":"markdown","1525e3a7":"markdown","fc70710b":"markdown","183d7018":"markdown","85bd3c0d":"markdown","f01df836":"markdown","0bc4e310":"markdown","4fa7b1b4":"markdown","29d23aa0":"markdown","03db5dcf":"markdown","b711f0a3":"markdown","8bf572b1":"markdown","46f1d4fa":"markdown","e553d86d":"markdown","0894c4b4":"markdown","5e35b405":"markdown","390a1ca1":"markdown","47f706e6":"markdown","74ad726a":"markdown","04841920":"markdown","352fe0f3":"markdown","4fbb335c":"markdown","bb9fe880":"markdown","b947d8e5":"markdown","2bc3d112":"markdown","b4493232":"markdown","0072ac6c":"markdown","ef76bf3c":"markdown","fc55c18f":"markdown","419caa99":"markdown","84a4dea7":"markdown","a6f561cf":"markdown"},"source":{"b3e31ea8":"# Basic libraries\nimport numpy as np\nimport pandas as pd\n\n# model libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n# model accuracy check\nfrom sklearn import metrics\n\n# plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","be458d88":"# read the data\ntrain_file = '..\/input\/digit-recognizer\/train.csv'\ntest_file = '..\/input\/digit-recognizer\/test.csv'\n\ndf_train = pd.read_csv(train_file)\ndf_test = pd.read_csv(test_file)\n","95f5dfd5":"df_train.head()","8e6a28d7":"df_train.shape","715f34fe":"# columns pixel0....pixel785 are independent variable of a digit\n# column label contains the digit (dependent variable)\n\ndf_train.columns","95fec489":"df_test.shape","d02eae7c":"df_test.columns","081ff3f4":"# no null values in train dataset\n\ndf_train.isnull().values.any()","6c030d70":"df_train.info()","812cd74a":"# print the frequency of each label\n\nprint(df_train['label'].value_counts())\nsns.countplot(df_train['label'])","0ebf55c0":"plt.figure(figsize=(12,4))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(df_train.drop(['label'],axis=1).values[i].reshape(28,28) )\n    plt.axis('off')\nplt.show()\n\n# print corresponding labels:\nprint(list(df_train['label'].loc[0:9]))\nprint(list(df_train['label'].loc[10:19]))\nprint(list(df_train['label'].loc[20:29]))","cd833e6d":"plt.figure(figsize=(12,4))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    plt.imshow(df_test.values[i].reshape(28,28) )\n    plt.axis('off')\nplt.show()","f31e902c":"X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['label'],axis=1),\n                                                   df_train['label'],\n                                                   test_size = 0.2,\n                                                   random_state=13)","83903f47":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","6c35b3a9":"X_train.head()","ecbaf5e6":"y_train.head()","58c65504":"# build model RandomForest with best parameters\n\n# Set the parameters by cross-validation\nparameter_grid = {'n_estimators': (np.arange(10,20)),\n                  'criterion': ['gini', 'entropy'],\n                  'max_depth': (np.arange(10,30)) }\n\n# use KFold\ncross_validation = KFold(n_splits=10)\n\n# define model search and fit\n#-- gs = GridSearchCV(RandomForestClassifier(), param_grid=parameter_grid, cv=cross_validation)\n#-- gs.fit(X_train, y_train)\n#-- print('Best score: {0}'.format(gs.best_score_))\n#-- print('Best parameters: {0}'.format(gs.best_params_))\n\n# store best parameter model\n#-- m1 = gs.best_estimator_\n#-- print(m1)\n","ec81aff8":"m1 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=18, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=19, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n\nm1.fit(X_train, y_train)\n","7108993f":"# run preduction on X_test\n# then check accuracy on y_test\n\ny_pred = m1.predict(X_test)\ny_pred","c968a265":"print('Accuracy score for y_test: ', metrics.accuracy_score(y_test,y_pred))","1e0a0354":"pd.DataFrame(metrics.confusion_matrix(y_test,y_pred))","8e401a68":"X_test['label'] = y_test\nX_test['pred'] = y_pred","108264e2":"X_test_err = X_test[X_test['label'] != X_test['pred']]\nX_test_err.shape","76593923":"for i in range(11):  \n    print('Label {0}, Prediction {1}'.format(X_test_err['label'].values[i],X_test_err['pred'].values[i]))\n    plt.figure(figsize=(1,1))\n    plt.imshow(X_test_err.drop(['label','pred'],axis=1).values[i].reshape(28,28) )\n    plt.axis('off')\n    plt.show()\n","372d6b3c":"pred = m1.predict(df_test)\npred","dff7ac2e":"# display digit images\nfor i in range(11):  \n    print('Prediction {0}'.format(pred[i]))\n    plt.figure(figsize=(1,1))\n    plt.imshow(df_test.values[i].reshape(28,28) )\n    plt.axis('off')\n    plt.show()\n","e4d624f4":"pred = pd.Series(pred,name=\"Label\")","7b800afd":"submit = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\n\nsubmit.to_csv(\"cnn_mnist_randomforest_gridsearch.csv\",index=False)","ca58877a":"This notebook is divided into below 4 section:\n1. Introduction\n2. Data read, preparation and explore\n3. RandomForest GridSearch\n4. Model test on validation set\n5. Result Submission\n","1525e3a7":"Display few images and their respective predicted labels","fc70710b":"### RandomForest Model\n\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. Random forest model expects numeric values. \nSome advantages of using Random Forest are as follows:\n1.\tThe same random forest algorithm or the random forest classifier can use for both classification and the regression task.\n2.\tRandom forest classifier will handle the missing values.\n3.\tWhen we have more trees in the forest, random forest classifier won\u2019t over fit the model. \n\n","183d7018":"I end this notebook here with leaving further scope of improvement to GridSearch. Share your improvement ideas in comments. If you found this notebook helpful or you just liked it, some upvotes would be very much appreciated. It will keep me motivated :)\n\nThanks for visiting. ","85bd3c0d":"Total 402 prediction error in model","f01df836":"In first attempt, I ran with below set of parameter grid. GridSearch took 24+ hours and still running. I killed it in betwen and reduced paramter grid. \n\n- 'n_estimators': (np.arange(10,20)),\n- 'criterion': ['gini', 'entropy'],\n- 'max_features': ['auto', 'sqrt', 'log2', None]\n- 'max_depth': (np.arange(20,40))\n","0bc4e310":"Each digit image is of 28x28 size which is total of 784 pixels. These pixel values are stored in columns pixel0....pixel785 (independent variable) for a digit. \nColumn label contains the corresponding digit (dependent variable).","4fa7b1b4":"Finally, time to run model on required test set and sumbit the result on Kaggle","29d23aa0":"Model is not doing a good job for images even with small distortion. Model has scope for further improvement","03db5dcf":"### Basic data check","b711f0a3":"In second attempt, I removed max_festures parameters and reduced max_depth to (10,30). Search gott completed in 4hours\n\n- 'max_depth': (np.arange(10,30))\n","8bf572b1":"Let's disply few images from error set","46f1d4fa":"From test, display few initial images. Need to predict the lable for these. ","e553d86d":"Data set is used from Kaggle competition link: https:\/\/www.kaggle.com\/c\/digit-recognizer\/","0894c4b4":"### Run on test data (df_test) and display few test images","5e35b405":"From train set, display few initial images and corresponding labels:","390a1ca1":"### Import libraries","47f706e6":"# 5. Final Submission","74ad726a":"For both the option, i used KFold of 10. In below cell, \n\n**NOTE:** I have disabled GridSearch option('#--') and used best parameters returned directly to build the model. I did so only to upload this notebook quicker. But you can remove it while using GridSearch","04841920":"Test data set contains 784 pixel values for a digit. It does not contain the label.\n\nNeed to indentify the digit based on the 784 pixels. ","352fe0f3":"### Perform train-test split\n\nTrain data set is divided in 80:20 ratio for train\/test\n","4fbb335c":"# 2. Data read, preparation and explore","bb9fe880":"# 1. Introduction\n\nThis is the simplest demonstration of RandomForest model with best parameters identified with GridSearch. \n\nInitially, I provided all options for GridSearch, but it took more than 24+ to search and still not done. Impatiently, I killed it and started afresh with fever parameters to search and it completed in 4hours. \n\nI achieved 95% accuracy score which is not that great, but it can serve as a base approach which can be worked upon further to improve accuracy. \n\nI believe with all option of GridSearch, more accuracy could be achieved. But I simply didn't have patience to wait for it. Might be I will try it on AWS and it run for the time it need.  \n\nWithout wasting your time further, lets dive into it.\n","b947d8e5":"# 4. Model test on validation set (y_test)","2bc3d112":"Model built is 95.21% accurate. That means model is able to identify digit accuratly most of time. \n\nLet's see confusion matrix to check where model fails","b4493232":"### Explore Train Dataset","0072ac6c":"### Model accuracy","ef76bf3c":"### Read data files","fc55c18f":"# RandomForest with GridSearch for best parameter. ","419caa99":"Building models on personal computer has its own limitations. Like in this case, GridSearch with all parameter options, took 244+ hours and still not done. I plan to run GridSearch with all parameters option on AWS cloud solution and let it take time that it needs.","84a4dea7":"# 3. RandomForest GridSearch","a6f561cf":"### Combine both actual and predicted label for comparison"}}