{"cell_type":{"93f25d65":"code","89fb655a":"code","b5ceedbc":"code","d0dc5d6c":"code","bb101da1":"code","34b31641":"code","22c62ed4":"code","ca9cdd68":"code","0a8e41c9":"code","96feb5bc":"code","b8177472":"code","15f8b8c7":"code","6b3e0e66":"code","ad3fc19e":"code","116568f1":"code","2b2c5815":"code","edd9c40e":"code","d7f8c13a":"code","5f0b4d01":"code","38558b75":"code","b20dc39b":"code","f47e4bdf":"code","f4644522":"code","47d65001":"code","3e4c4628":"code","a9fd897f":"code","045a5c18":"code","44925657":"code","8ca8cc96":"code","edcf6e66":"code","a5d02c8d":"code","c1e520b1":"code","d78d184c":"code","37875997":"code","5b6d002c":"code","866072b7":"code","b4c26de8":"code","a22f5be5":"markdown","dc087e5c":"markdown","b0e5fa30":"markdown","c088983f":"markdown","24b93458":"markdown","c7457332":"markdown","e95ebfed":"markdown","9aa9a853":"markdown","7c36a432":"markdown","f505fac9":"markdown","771ab681":"markdown","e0b97001":"markdown","cc98a43d":"markdown","1d92c856":"markdown","4ab57560":"markdown","d70ad7c9":"markdown","fcb4c9ac":"markdown","addec33e":"markdown","f63a4813":"markdown","c32e5061":"markdown","b2f0ecc0":"markdown","e9eedf0e":"markdown"},"source":{"93f25d65":"'''\n!pip install pycocotools\n!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n#Run -> Restart and Clear Cell Outputs\n!pip uninstall -y numpy\n!pip uninstall -y numpy #(again)\n!pip install numpy\n#Run -> Restart and Clear Cell Outputs\n#May need to uninstall and reinstall numpy several times, inconsistent\n'''","89fb655a":"'''\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport os\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\n'''","b5ceedbc":"'''\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    #Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n        \n    return data\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im\n'''","d0dc5d6c":"'''\n#for split in ['train', 'test']:\nfor split in ['test']:\n    save_dir = f'\/kaggle\/working\/siim-covid19\/{split}\/'\n\n    os.makedirs(save_dir, exist_ok=True)\n\n    save_dir = f'\/kaggle\/working\/siim-covid19\/{split}\/study\/'\n    os.makedirs(save_dir, exist_ok=True)\n\n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=1000)  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n'''","bb101da1":"import shutil\nimport os\n\nshutil.copytree('\/kaggle\/input\/siim-covid19-resized-to-256px-jpg\/test', '\/kaggle\/working\/test\/')\nshutil.copytree('\/kaggle\/input\/siim-covid19-resized-to-256px-jpg\/train', '\/kaggle\/working\/all\/')\n\nfile_names = os.listdir('\/kaggle\/working\/test\/')\n    \nfor file_name in file_names:\n    shutil.move(os.path.join('\/kaggle\/working\/test\/', file_name), '\/kaggle\/working\/all\/')","34b31641":"!pip install --upgrade seaborn","22c62ed4":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","ca9cdd68":"dim = 512 #512, 256, 'original'\nfold = 4","0a8e41c9":"train_df = pd.read_csv(f'..\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df.head()","96feb5bc":"train_df['image_path'] = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train\/'+train_df.image_id+('.png' if dim!='original' else '.jpg')\ntrain_df.head()","b8177472":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","15f8b8c7":"train_df['x_min'] = train_df.apply(lambda row: (row.x_min)\/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)\/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)\/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)\/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)\/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)\/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()","6b3e0e66":"features = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\nX = train_df[features]\ny = train_df['class_id']\nX.shape, y.shape","ad3fc19e":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","116568f1":"\n%%time\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(n_components = 2, perplexity = 40, random_state=1, n_iter=5000)\ndata_X = X\ndata_y = y.loc[data_X.index]\nembs = tsne.fit_transform(data_X)\n# Add to dataframe for convenience\nplot_x = embs[:, 0]\nplot_y = embs[:, 1]","2b2c5815":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.axis('off')\nscatter = plt.scatter(plot_x, plot_y, marker = 'o',s = 50, c=data_y.tolist(), alpha= 0.5,cmap='viridis')\nplt.legend(handles=scatter.legend_elements()[0], labels=classes)","edd9c40e":"from scipy.stats import gaussian_kde\n\n\nx_val = train_df.x_mid.values\ny_val = train_df.y_mid.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('x_mid')\n# ax.set_ylabel('y_mid')\nplt.show()","d7f8c13a":"x_val = train_df.w.values\ny_val = train_df.h.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('bbox_width')\n# ax.set_ylabel('bbox_height')\nplt.show()","5f0b4d01":"x_val = train_df.width.values\ny_val = train_df.height.values\n\n# Calculate the point density\nxy = np.vstack([x_val,y_val])\nz = gaussian_kde(xy)(xy)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nax.axis('off')\nax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n# ax.set_xlabel('image_width')\n# ax.set_ylabel('image_height')\nplt.show()","38558b75":"gkf  = GroupKFold(n_splits = 5)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.image_id.tolist())):\n    train_df.loc[val_idx, 'fold'] = fold\ntrain_df.head()","b20dc39b":"train_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","f47e4bdf":"os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/labels\/val', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/val', exist_ok = True)\nlabel_dir = '\/kaggle\/input\/vinbigdata-yolo-labels-dataset\/labels'\nfor file in tqdm(train_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/train')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/train')\n    \nfor file in tqdm(val_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/val')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/val')","f4644522":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","47d65001":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\n\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","3e4c4628":"#shutil.rmtree('\/kaggle\/working\/yolov5')","a9fd897f":"# https:\/\/www.kaggle.com\/ultralytics\/yolov5\n# !git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')\n# %pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","045a5c18":"# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 30 --data \/kaggle\/working\/vinbigdata.yaml --weights yolov5x.pt --cache","44925657":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels_correlogram.jpg'));","8ca8cc96":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels.jpg'));","edcf6e66":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch0.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch1.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch2.jpg'))","a5d02c8d":"fig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'runs\/train\/exp\/test_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'runs\/train\/exp\/test_batch{row}_pred.jpg', fontsize = 12)","c1e520b1":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/results.png'));","d78d184c":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/confusion_matrix.png'));","37875997":"#shutil.rmtree('\/kaggle\/working\/siim-covid19')\nos.chdir('\/kaggle\/working\/yolov5')","5b6d002c":"!python detect.py --weights '\/kaggle\/working\/yolov5\/runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--save-txt\\\n--source \/kaggle\/working\/all\\\n#--source \/kaggle\/input\/siim-covid19-resized-to-256px-jpg\/test\\\n--exist-ok","866072b7":"#https:\/\/stackoverflow.com\/questions\/65381312\/how-to-convert-a-yolo-darknet-format-into-csv-file\n\nimport glob\nos.chdir(r'\/kaggle\/working\/yolov5\/runs\/detect\/exp\/labels')\nmyFiles = glob.glob('*.txt')\n\nwidth=256\nheight=256\nimage_id=0\nfinal_df=[]\n\nfor item in myFiles:\n    \n    row=[]\n    bbox_temp=[]\n    \n    \n    with open(item, 'rt') as fd:\n        first_line = fd.readline()\n        splited = first_line.split();\n        \n        row.append(item)\n\n        try:\n            bbox_temp.append(float(splited[1])*width)\n            bbox_temp.append(float(splited[2])*height)\n            bbox_temp.append(float(splited[3])*width)\n            bbox_temp.append(float(splited[4])*height)\n            row.append(bbox_temp)\n            final_df.append(row)\n        except:\n            print(\"file is not in YOLO format!\")\n            \n    print(row)\ndf = pd.DataFrame(final_df,columns=['image_id', 'width', 'height','bbox'])\ndf.to_csv(\"saved.csv\",index=False)\n\nsaved = pd.read_csv(f'saved.csv')\nsaved.head()","b4c26de8":"shutil.rmtree('\/kaggle\/working\/vinbigdata')\nshutil.rmtree('runs\/detect')\nfor file in (glob('runs\/train\/exp\/**\/*.png', recursive = True)+glob('runs\/train\/exp\/**\/*.jpg', recursive = True)):\n    os.remove(file)","a22f5be5":"# Class Distribution","dc087e5c":"# Split","b0e5fa30":"# Train","c088983f":"# Pre-Processing","24b93458":"# [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg)\n![](https:\/\/user-images.githubusercontent.com\/26833433\/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png)","c7457332":"# Only 14 Class","e95ebfed":"# Image Aspect Ratio","9aa9a853":"# Version\n* `v13`: Fold4\n* `v12`: Fold3\n* `v10`: Fold2\n* `v09`: Fold1\n* `v03`: Fold0","7c36a432":"# YOLOv5 Stuff","f505fac9":"Link: <a href=\"\/kaggle\/working\/yolov5\/runs\/detect\/exp\/labels\/saved.csv\"> Download File <\/a>","771ab681":"# Batch Image","e0b97001":"# BBox Location","cc98a43d":"# (Loss, Map) Vs Epoch","1d92c856":"## bbox_w Vs bbox_h","4ab57560":"## x_mid Vs y_mid","d70ad7c9":"# Get Class Name","fcb4c9ac":"# Transform COVID Data into 256x256","addec33e":"# Confusion Matrix","f63a4813":"# t-SNE Visualization","c32e5061":"# Cleaning","b2f0ecc0":"# GT Vs Pred","e9eedf0e":"# Copying Files"}}