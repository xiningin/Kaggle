{"cell_type":{"63197265":"code","13a80c2f":"code","655d6182":"code","838a621d":"code","641c85ca":"code","d75194cb":"code","8ff2219e":"code","322b5e7a":"code","95f31d37":"code","bc448e9f":"code","9684634f":"code","6220498a":"code","efd16635":"code","7d2d5989":"code","122e3870":"code","c93512c0":"code","492eea3c":"code","67f3ffcb":"code","c2921e3a":"code","7681f09c":"code","de9c7838":"code","ed0791e1":"code","b511b035":"code","4dae4031":"code","b25a58ab":"code","f121a734":"code","83c5080a":"code","35c35227":"code","11eb7207":"code","6d16d46c":"code","15e5d6f1":"code","1114c41c":"code","a67274d1":"code","08a463d6":"code","97c554d0":"code","c4ed2ab8":"code","d4e37c1f":"code","03fe37d0":"code","29a5d608":"code","27237aee":"code","505105a6":"code","adb5b6bf":"code","40bf3f94":"code","5af09150":"code","f32df907":"code","c80fdf75":"code","39fdee48":"code","795c9100":"code","9fbb60a7":"code","bd0e62cb":"code","9eb795fa":"code","6ea9db4f":"code","7149d090":"code","26459993":"code","bcd0b056":"markdown","f3c1375c":"markdown","942da3b1":"markdown","03888f3e":"markdown","0850d022":"markdown","f3d4b455":"markdown","4ba7339d":"markdown","df6a3046":"markdown","a538e7cf":"markdown"},"source":{"63197265":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","13a80c2f":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","655d6182":"df= pd.read_csv(\"..\/input\/auto-data-car-price-prediction-regression\/AutoData.csv\")\ndf.head()","838a621d":"df.shape","641c85ca":"df.describe()","d75194cb":"df.isnull().sum() #checking null values","8ff2219e":"df.dtypes","322b5e7a":"import pandas as pd  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nimport seaborn as sns\n%matplotlib inline","95f31d37":"plt.figure(figsize=(10,6))\nplt.tight_layout()\nsns.distplot(df['price'])","bc448e9f":"df.describe()","9684634f":"df.corr()","6220498a":" \n\nfig_dims = (10, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.heatmap(df.corr(), annot = True,ax=ax)","efd16635":"# carwidth as potential predictor variable of price\n\nsns.regplot(x=\"carwidth\", y=\"price\", data=df)\nplt.ylim(0,)\ndf[[\"carwidth\", \"price\"]].corr()","7d2d5989":"# curbweight as potential predictor variable of price\n\nsns.regplot(x=\"curbweight\", y=\"price\", data=df)\nplt.ylim(0,)\ndf[[\"curbweight\", \"price\"]].corr()","122e3870":"# enginesize as potential predictor variable of price\n\nsns.regplot(x=\"enginesize\", y=\"price\", data=df)\nplt.ylim(0,)\ndf[[\"enginesize\", \"price\"]].corr()","c93512c0":"# horsepower as potential predictor variable of price\n\nsns.regplot(x=\"horsepower\", y=\"price\", data=df)\nplt.ylim(0,)\ndf[[\"horsepower\", \"price\"]].corr()","492eea3c":"# citympg as potential predictor variable of price\n\nsns.regplot(x=\"citympg\", y=\"price\", data=df)\nplt.ylim(0,)\ndf[[\"citympg\", \"price\"]].corr()","67f3ffcb":"df.head()","c2921e3a":"# Let's look at the relationship between \"fueltype\" and \"price\"\n\nsns.boxplot(x=\"fueltype\", y=\"price\", data=df)","7681f09c":"# Let's look at the relationship between \"aspiration\" and \"price\"\n\nsns.boxplot(x=\"aspiration\", y=\"price\", data=df)","de9c7838":"# Let's look at the relationship between \"doornumber\" and \"price\"\n\nsns.boxplot(x=\"doornumber\", y=\"price\", data=df)","ed0791e1":"# Let's look at the relationship between \"carbody\" and \"price\"\n\nsns.boxplot(x=\"carbody\", y=\"price\", data=df)","b511b035":"# Let's look at the relationship between \"drivewheel\" and \"price\"\n\nsns.boxplot(x=\"drivewheel\", y=\"price\", data=df)","4dae4031":"# Let's look at the relationship between \"enginelocation\" and \"price\"\n\nsns.boxplot(x=\"enginelocation\", y=\"price\", data=df)","b25a58ab":"df.head()","f121a734":"df.dtypes","83c5080a":"# Let's look at the relationship between \"enginetype\" and \"price\"\n\nsns.boxplot(x=\"enginetype\", y=\"price\", data=df)","35c35227":"# Let's look at the relationship between \"cylindernumber\" and \"price\"\n\nsns.boxplot(x=\"cylindernumber\", y=\"price\", data=df)","11eb7207":"#binning for horsepower\n\nbin_labels = ['Low (0-100)', 'Medium (100-150)', 'High (150+)']\ndf['horsepower-group'] = pd.cut(\n    df['horsepower'],\n    bins=[0, 100, 150, df['horsepower'].max()],\n    labels=bin_labels\n)","6d16d46c":" plt.bar(bin_labels, df[\"horsepower-group\"].value_counts())\n\n# set x\/y labels and plot title\nplt.xlabel(\"horsepower\")\nplt.ylabel(\"count\")\nplt.title(\"horsepower bins\")","15e5d6f1":"# Let's look at the relationship between \"cylindernumber\" and \"price\"\n\nsns.boxplot(x=\"horsepower-group\", y=\"price\", data=df)","1114c41c":"#importing libraries\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","a67274d1":"X = df[['enginesize','stroke','peakrpm', 'wheelbase' ,'carlength' ,\n       'carwidth' ,'carheight' ,'curbweight' ,'boreratio' ,'citympg']].values\n    \n#X= adf.loc[:,adf.columns != 'price']\ny = df['price'].values","08a463d6":"df1=pd.DataFrame({'feature_names': ['enginesize','stroke','peakrpm', 'wheelbase' ,'carlength' ,\n       'carwidth' ,'carheight' ,'curbweight' ,'boreratio' ,'citympg']})","97c554d0":"import statsmodels.api as sm\nfrom scipy import stats\n\n\nX1 = sm.add_constant(X)\nest = sm.OLS(y, X1)\nest1 = est.fit()\nprint(est1.summary())","c4ed2ab8":"from yellowbrick.features import Rank1D\n\n# Instantiate the 1D visualizer with the Sharpiro ranking algorithm\nvisualizer = Rank1D(algorithm='shapiro')\n\nvisualizer.fit(X, y)           # Fit the data to the visualizer\nvisualizer.transform(X)        # Transform the data","d4e37c1f":"X=df[['enginesize','stroke','peakrpm','curbweight','carwidth','citympg']].values    \ny = df['price'].values","03fe37d0":"import numpy as np\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\nfrom yellowbrick.target.feature_correlation import feature_correlation\n\n\n\nfeatures = np.array(df1['feature_names'])\nvisualizer = feature_correlation(X, y, labels=features)\nplt.tight_layout()","29a5d608":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","27237aee":"regressor = LinearRegression()  \nregressor.fit(X_train, y_train)","505105a6":"y_pred = regressor.predict(X_test)","adb5b6bf":"from sklearn.metrics import r2_score\n\nr2 = r2_score(y_test, y_pred)*100\nprint('The R2 for this model is:', r2,'%')","40bf3f94":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn import model_selection\n\nresults1 = []\nkfold1 = model_selection.KFold(n_splits=4, random_state=42)\ncv_results1 = model_selection.cross_val_score(regressor, X_train,y_train,cv=kfold1,scoring='r2')\nresults1.append(cv_results1)\nmsg=\"{}: {}\".format('Linear Regression',cv_results1.mean())\nprint(msg) ","5af09150":"from yellowbrick.model_selection import FeatureImportances\n\n# Load the regression dataset\n#dataset = load_concrete(return_dataset=True)\n#X, y = dataset.to_data()\n\n# Title case the feature for better display and create the visualizer\n\nviz = FeatureImportances(LinearRegression(), relative=False,labels=features)\n\n# Fit and show the feature importances\nviz.fit(X, y)\nviz.show()","f32df907":"from sklearn.ensemble import RandomForestRegressor \n  \n # create regressor object \nrfc = RandomForestRegressor(n_estimators = 100, random_state = 0) \n  \n# fit the regressor with x and y data \nrfc.fit(X, y) ","c80fdf75":"y_pred1 = rfc.predict(X_test)","39fdee48":"r21 = r2_score(y_test, y_pred1)*100\nprint('The R2 for this model is:', r21,'%')","795c9100":"results = []\nkfold = model_selection.KFold(n_splits=5, random_state=42)\ncv_results = model_selection.cross_val_score(rfc, X_train,y_train,cv=kfold,scoring='r2')\nresults.append(cv_results)\nmsg=\"{}: {}\".format('Random forest regresser',cv_results.mean())\nprint(msg) ","9fbb60a7":"from yellowbrick.model_selection import ValidationCurve\n\n\nviz = ValidationCurve(\n    RandomForestRegressor(), param_name=\"max_depth\",\n    param_range=np.arange(1, 11), cv=10, scoring=\"r2\"\n)\n\n# Fit and show the visualizer\nviz.fit(X, y)\nviz.show()","bd0e62cb":"df1= pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n","9eb795fa":"df1","6ea9db4f":"df1.plot(kind='line',figsize=(15,6))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","7149d090":"from yellowbrick.regressor import prediction_error\n\n# Instantiate the linear model and visualizer\nmodel = RandomForestRegressor(random_state=42)\nvisualizer = prediction_error(model, X_train, y_train, X_test, y_test)","26459993":"from yellowbrick.regressor import prediction_error\n\n# Instantiate the linear model and visualizer\nmodel = LinearRegression()\nvisualizer = prediction_error(model, X_train, y_train, X_test, y_test)","bcd0b056":"## **K fold Cross validation**","f3c1375c":"# Automobile Dataset ","942da3b1":"# EDA","03888f3e":"# Prediction Error Plot","0850d022":"# MULTIPLE LINEAR REGRESSION MODEL","f3d4b455":"# Correlation heat map with Seaborn","4ba7339d":"# RandomForestRegressor","df6a3046":"The maximum price range of cars are around 1000.  ","a538e7cf":"## The main Factors that drive price are-\n1. Engine size a\n2. Stroke\n3. Compression Ratio\n4. Peak rpm\n"}}