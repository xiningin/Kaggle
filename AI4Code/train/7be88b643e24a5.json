{"cell_type":{"b370d6aa":"code","023c978f":"code","1e45b2b0":"code","2f73e2a2":"code","f59256f7":"code","2847c641":"code","fd38128b":"code","b4a5f463":"code","3a0b4992":"code","ef8cf81b":"code","e73050c9":"code","d13f688d":"code","3354fa71":"code","67dcc90f":"code","91163a64":"code","23f98d57":"code","627b4e9f":"code","c2f3eb5c":"code","5ad5f636":"code","99314d9d":"code","f4aa7b8d":"code","9e9ccc57":"code","7ab26e2d":"code","9922cf64":"code","bfb323fe":"code","5e96684c":"code","64e84cd8":"code","ab8d1fd1":"code","715ac37b":"markdown"},"source":{"b370d6aa":"!pip install lmfit --quiet\n!pip install numdifftools --quiet","023c978f":"import numpy as np\nimport glob\nimport copy\nfrom lmfit import minimize, Parameters\nimport scipy.optimize\nimport plotly.graph_objects as go","1e45b2b0":"files = glob.glob('\/kaggle\/input\/*\/19*.dat')\nfiles = glob.glob('\/kaggle\/input\/*\/*.dat')","2f73e2a2":"def get_uncertainty(rawdata):\n    \"\"\"\n    From the rawdata provided make an estimate of the uncertainty for each row of data\n    Use the std, but if it is too small, use an estimate based on assuming a uniform distribution\n    on a quantizer.   This works for ANDO power meters because they only have 4 digit resolution\n    on the higher ranges.\n    \"\"\"\n    Nfit = rawdata.shape[0]\n    N = rawdata.shape[1]\n    std = rawdata.std(axis=1, ddof=1)\n    avg = rawdata.mean(axis=1)\n    min_unc = np.zeros(avg.shape)\n\n    # Use estimate quantization error as lower bound\n    #   this works for the ando power meters we are using to monitor\n    min_unc[avg > 1e-9] = 1e-12 * 0.5 \/ (3**0.5)\n    min_unc[avg > 1e-6] = 1e-9 * 0.5 \/ (3**0.5)\n    min_unc[avg > 1e-3] = 1e-6 * 0.5 \/ (3**0.5)\n\n    # replace std with uncertainty from a uniform distribution in the\n    # quantization of the power meter if the std is too small\n    unc = np.where(std < min_unc, min_unc, std)\n    return unc","f59256f7":"data = np.loadtxt(files[1])\n# column format of text file... there are 7 columns\n# time, 1, monitor power, tau_setting, att_setting, range, power_reading\n#\n# The data is also taken in blocks of N at each setting...\n#\n# At the end of the file, there may be extra data to look for drift\n#\n\n\nrngIdx = -2  # Use to be -2, when there was no \"splitter\" measurements\ntauIdx = -3  # column number which indicates the setting for \"tau\"\nattIdx = -4  # column for att setting\npowIdx = -1\n\n# determine N from the data file\nN = (data[:, tauIdx] > 0).nonzero()[0][0]\n\n# delete extra data at the end of the file that could be used to check for drift\nextra = data.shape[0] % (2*N)\ndata = data[:-extra,:]\n\nranges = np.unique(data[:,rngIdx])\nranges.sort()\nranges = ranges[::-1].astype(int)\nd = {}\nfor rng in ranges:\n    d[rng]={}\n    d[rng]['v'] = data[(data[:,rngIdx] == rng) & (data[:,tauIdx]==0),powIdx].reshape((-1,N))\n    d[rng]['vt'] = data[(data[:,rngIdx] == rng) & (data[:,tauIdx]==3),powIdx].reshape((-1,N))\n    d[rng]['att'] = data[(data[:,rngIdx] == rng) & (data[:,tauIdx]==3),attIdx][::N]\n    d[rng]['vstd'] = get_uncertainty(d[rng]['v'])\n    d[rng]['vtstd'] = get_uncertainty(d[rng]['vt'])\n    d[rng]['range'] = rng\n    d[rng]['N'] = N\ndavg = copy.deepcopy(d)\nfor rng in ranges:\n    davg[rng]['v'] = davg[rng]['v'].mean(axis=1)\n    davg[rng]['vt'] = davg[rng]['vt'].mean(axis=1)\n\nfig = go.Figure()\nfig.add_scatter(y=data[:,2])\nfig.show()","2847c641":"def init_params(N=3):\n    \"\"\"\n    Create parameters used by lmfit... This is for data on a single range\n    \"\"\"\n    params = Parameters()\n    params.add('tau', value=1) # using fixed and unknown attenuator technique\n    for i in range(2, (N+1)):\n        params.add(f'b{i}',1)\n    return params\n\ndef P(params, v):\n    \"\"\"\n    Compute linearized power P given the parameters of the polynomial and the readings v\n    \"\"\"\n    out = v+0;  # make a new copy of v for out\n    #out = np.array(v) # make a new copy of v four out\n    k=2\n    name = f'b{k}'\n    while name in params:\n        out += params[name]*(v**k)\n        k += 1\n        name = f'b{k}'\n    return out\n\ndef dP(params, v):\n    \"\"\"\n    Compute dP\/dv\n    \"\"\"\n    out = 1;\n    k=2\n    name = f'b{k}'\n    while name in params:\n        out += k * params[name]*(v**(k-1))\n        k += 1\n        name = f'b{k}'\n    return out\n","fd38128b":"def init_params_ranges(N=[], ranges=[]):\n    \"\"\"\n    Create a new set of parameters for fitting... this will cover all ranges simultaneously\n    e.g.\n        parameter b102 is the v**2 coefficeint for the -10 range\n        parameter b303 is the v**3 coefficient for the -30 range\n    \"\"\"\n    params = Parameters()\n    params.add('tau', value=0.5)\n    #params.add('tau', value=0.5062319209579774, vary=False)#, min=0, max=1) # using fixed and unknown attenuator technique\n    N_idx = 0\n    for rng in ranges:\n        for i in range(2, (N[N_idx]+1)):\n            params.add(f\"b{-rng}{i}\",0)#, min=-1e6, max=1e6)\n        N_idx += 1\n    return params\n\ndef residuals3(params):\n    #  assumes params is an lmfit Parameters\n    #  get raw data via global variable davg\n    global davg\n    results = []\n    for rng in davg.keys():\n        v = davg[rng]['v']\n        vt = davg[rng]['vt']\n        vunc = davg[rng]['vstd']\n        vtunc = davg[rng]['vtstd']\n        k = 2\n        out = vt - params['tau']*v\n        name = f'b{k-rng*10}'\n        #print(name)\n        while name in params:\n            #print(name,params[name])\n            out += params[name]*(vt**k - params['tau'] * (v**k))\n            k += 1\n            name = f'b{k-rng*10}'\n        # Estimate uncertainty for out and divide the residual by it.\n        #.  estimate is rough 1st order estimate\n        out \/= (vtunc**2 + (params['tau']*vunc)**2)**0.5\n        results.append(out)\n    results = np.hstack(results)\n    return results","b4a5f463":"params = init_params_ranges([4, 3, 2, 2, 2, 2], ranges)\nfit = minimize(residuals3, params, method='leastsq')\nfit","3a0b4992":"def redchi(N_list):\n    N_list = N_list.astype(int)\n    params = init_params_ranges(N_list, ranges)\n    fit = minimize(residuals3, params, method='leastsq')\n    return fit.redchi","ef8cf81b":"#N_fit = scipy.optimize.differential_evolution(redchi, bounds=[(1,6)]*6)\n#%timeit scipy.optimize.brute(redchi, ranges=(slice(1, 5, 1),)*6)\n","e73050c9":"#%timeit scipy.optimize.differential_evolution(redchi, bounds=[(1,5)]*6)\n","d13f688d":"N_fit = scipy.optimize.differential_evolution(redchi, bounds=[(1,5)]*6)\nN_list = N_fit.x.astype(int)\nN_fit, N_list","3354fa71":"N_fit = N_list\nN_list = N_fit.x.astype(int)\n","67dcc90f":"#N_list = np.array([3, 3, 3, 3, 2, 2])\nparams = init_params_ranges(N_list, ranges)\nfit = minimize(residuals3, params, method='leastsq')\nfit","91163a64":"davg[-60]['v']","23f98d57":"def P_range(params, rng, v):\n    #  assumes params is an lmfit Parameters\n    global davg\n    results = []\n    k = 2\n    out = v + 0\n    name = f'b{k-rng*10}'\n    while name in params:\n        out += params[name]*(v**k)\n        k += 1\n        name = f'b{k-rng*10}'\n    return out","627b4e9f":"from uncertainties import ufloat\nfrom uncertainties import unumpy as unp","c2f3eb5c":"rng = -20\nr_list = []\nfor rng in [-20, -30, -40, -50, -60]:\n    overlap = set(davg[rng]['att']).intersection(davg[rng+10]['att'])\n    idx1 = [list(davg[rng]['att']).index(x) for x in overlap]\n    idx2 = [list(davg[rng+10]['att']).index(x) for x in overlap]\n    \n    #r = P_range(fit.params, rng+10, davg[rng+10]['v'][idx2]) \/ P_range(fit.params, rng, davg[rng]['v'][idx1])\n    r = P_range(fit.params, rng+10, np.hstack([davg[rng+10]['v'][idx2], davg[rng+10]['vt'][idx2]])) \/ \\\n    P_range(fit.params, rng, np.hstack([davg[rng]['v'][idx1], davg[rng]['vt'][idx1]]))\n    r_list.append(ufloat(r.mean(), r.std()))","5ad5f636":"r_list, np.array(r_list).cumprod()","99314d9d":"for rng in ranges:\n    rel_unc = davg[rng]['vstd']\/davg[rng]['v']\n    print(rng, rel_unc.min(), rel_unc.max(), rel_unc.mean(), rel_unc.std())","f4aa7b8d":"def P_range_unc(params, rng, v):\n    #  assumes params is an lmfit Parameters\n    global davg\n    results = []\n    k = 2\n    out = v + 0\n    name = f'b{k-rng*10}'\n    while name in params:\n        coeff = ufloat(params[name].value, params[name].stderr)\n        out += coeff*(v**k)\n        #print(coeff*(v**k))\n        k += 1\n        name = f'b{k-rng*10}'\n    return out","9e9ccc57":"fit.params","7ab26e2d":"(0.1**2 + 0.002**2)**0.5 \/ 2\n","9922cf64":"for rng in ranges:\n    print(rng)\n\n    davg[rng]['v+unc'] = unp.uarray(davg[rng]['v'], davg[rng]['vstd'])","bfb323fe":"rng = -60\nP_range_unc(fit.params, rng, davg[rng]['v+unc'])","5e96684c":"rng = -20\nr_list = []\nfor rng in [-20, -30, -40, -50, -60]:\n    overlap = set(davg[rng]['att']).intersection(davg[rng+10]['att'])\n    idx1 = [list(davg[rng]['att']).index(x) for x in overlap]\n    idx2 = [list(davg[rng+10]['att']).index(x) for x in overlap]\n    \n    r = P_range_unc(fit.params, rng+10, davg[rng+10]['v+unc'][idx2]) \/ \\\n        P_range_unc(fit.params, rng, davg[rng]['v+unc'][idx1])\n    \n    print(r, r.mean(), unp.nominal_values(r).std())\n    ","64e84cd8":"rng = -10\nimport matplotlib.pyplot as plt\n#plt.rcParams['text.usetex'] = True\n#plt.clf()\nfig = go.Figure()\nfor rng in ranges:\n    x = davg[rng]['v']\n    y = P_range_unc(fit.params, rng, davg[rng]['v+unc']) \/ davg[rng]['v']\n    y = unp.nominal_values(y)\n    #plt.semilogx(x,y-1,'o')\n    fig.add_scatter(x=x,y=y-1,name=f'range: {rng}', mode='markers')\n#plt.xlabel('reading')\n#plt.ylabel(r'$\\frac{p(reading)}{reading}-1$', fontsize=36)\nfig.update_layout(xaxis_type=\"log\") #, yaxis_type=\"log\")\nfig.update_layout(\n    title=\"Plot Title\",\n    xaxis_title=\"reading\",\n    yaxis_title=r\"$\\frac{p(reading)}{reading}-1$\",\n    legend_title=\"\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    )\n)\n\nfig.show()","ab8d1fd1":"import bqplot\n","715ac37b":"Equation to use to parameterize the non-linearity (conversion function)\n$$P(V) = V + \\sum_{k=2}^N b_k V^k$$\n$$ \\sigma_P^2 = [1 + \\sum_{k=2}^{N} k b_k V^{k-1}]^2 \\sigma_V^2 $$"}}