{"cell_type":{"f2b9cb50":"code","06c33569":"code","405fd4e8":"code","71f151e8":"code","de8d3c95":"code","75e514ba":"code","e900eb83":"code","1ec4f31f":"code","839b6926":"code","edac1bdb":"code","83d5527c":"code","66d2de90":"code","c775feee":"code","597b1acf":"code","73626015":"markdown","065ef6db":"markdown","ff8542b8":"markdown","d0b3fdf2":"markdown","f4fce7a8":"markdown","6873b4f3":"markdown","3b03de4f":"markdown","db37b6be":"markdown"},"source":{"f2b9cb50":"\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\nfrom PIL import Image\nfrom keras import layers, models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.layers import Activation\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","06c33569":"def display_grid(data, path, w =10, h =10, columns = 4, rows = 5):\n    fig=plt.figure(figsize=(12, 8))\n    for i in range(1, columns*rows +1):\n        file = data[i]\n        file = os.path.join(path, file)\n        img = Image.open(file)\n        fig.add_subplot(rows, columns, i)\n        imshow(img)\n    plt.show()\n    \ndef plot_results(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize = (24, 6))\n    plt.subplot(1,2,1)\n    plt.plot(epochs, acc, 'b', label = 'Training Accuracy')\n    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')\n    \n\n\n    plt.subplot(1,2,2)\n    plt.plot(epochs, loss, 'b', label = 'Training Loss')\n    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')\n    plt.show()\n \ndef get_best_epcoh(history):\n    valid_acc = history.history['val_acc']\n    best_epoch = valid_acc.index(max(valid_acc)) + 1\n    best_acc =  max(valid_acc)\n    print('Best Validation Accuracy Score {:0.5f}, is for epoch {}'.format( best_acc, best_epoch))\n    return best_epoch","405fd4e8":"base_dir = '\/kaggle\/input\/cars-wagonr-swift\/data\/'\ntrain_swift = os.listdir(os.path.join(base_dir, 'train\/swift') )\nval_swift  = os.listdir(os.path.join(base_dir, 'validation\/swift') )\ntest_swift  =  os.listdir(os.path.join(base_dir, 'test\/swift') )\nprint('Instances for Class Swift: Train {}, Validation {} Test {}'.format(len(train_swift), len(val_swift), len(test_swift)))","71f151e8":"#Sanity checks: no overlaping bteween train test and validation sets\nval_train = [x for x in val_swift if x in train_swift]\ntest_train = [x for x in test_swift if x in train_swift]\nval_test =  [x for x in test_swift if x in val_swift]\nlen(val_train), len(test_train), len(val_test)","de8d3c95":"display_grid(data = train_swift, path = os.path.join(base_dir, 'train\/swift'), w =10, h =10, columns = 8, rows = 5)","75e514ba":"train_wr = os.listdir(os.path.join(base_dir, 'train\/wagonr') )\nval_wr  = os.listdir(os.path.join(base_dir, 'validation\/wagonr') )\ntest_wr  =  os.listdir(os.path.join(base_dir, 'test\/wagonr') )\nprint('Instances for Class Wagonr: Train {}, Validation {} Test {}'.format(len(train_swift), len(val_swift), len(test_swift)))","e900eb83":"#Sanity checks: no overlaping bteween train test and validation sets\nval_train = [x for x in val_wr if x in train_wr]\ntest_train = [x for x in test_wr if x in train_wr]\nval_test =  [x for x in test_wr if x in val_wr]\nlen(val_train), len(test_train), len(val_test)","1ec4f31f":"display_grid(data = train_wr, path = os.path.join(base_dir, 'train\/wagonr'), w =10, h =10, columns = 8, rows = 5)","839b6926":"def build_cnn(display_summary =False):\n    model = models.Sequential()\n    model.add( layers.Conv2D(32, (3,3),  input_shape = (150, 150, 3)) )    \n    model.add(Activation(\"relu\"))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add( layers.Conv2D(64, (3,3)) )    \n    model.add(Activation(\"relu\"))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add( layers.Conv2D(128, (3,3)) )   \n    model.add(Activation(\"relu\"))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add( layers.Conv2D(128, (3,3)) )    \n    model.add(Activation(\"relu\"))\n    model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dropout(0.5))\n    \n    model.add(layers.Dense(512))    \n    model.add(Activation(\"relu\"))\n    model.add(layers.BatchNormalization())\n   \n    model.add(layers.Dense(1, activation= 'sigmoid'))\n\n    model.compile(loss = 'binary_crossentropy',\n                  optimizer = optimizers.RMSprop(lr = 1e-4),\n                  metrics = ['acc']\n                  )\n    if display_summary:\n       model.summary()\n    return model","edac1bdb":"datagen = ImageDataGenerator( rotation_range= 40,\n                              width_shift_range = 0.2,\n                             height_shift_range = 0.2,\n                             shear_range = 0.2,\n                             zoom_range = 0.2,\n                             horizontal_flip = True,\n#                              fill_mode = 'nearest'                              \n                            )\n\npath = os.path.join(base_dir, 'train\/swift')\nfile = train_swift[1]\nimage_path = os.path.join(path, file )\n\nimg = image.load_img(image_path, target_size = (150,150))\nx= image.img_to_array(img)\nx = x.reshape((1,) + x.shape)\ni =0 \nfig=plt.figure(figsize=(16, 8))\nfor batch in datagen.flow(x, batch_size = 1):\n    i +=  1\n    fig.add_subplot(2, 4, i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n  \n    if i % 8 == 0:\n        break\n    ","83d5527c":"\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation' )\n\n\ntrain_datagen = ImageDataGenerator(\n                                  rescale = 1.\/255,\n                                  rotation_range= 40,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  shear_range = 0.2,\n                                  zoom_range = 0.2  ,\n                                  horizontal_flip = True,\n                                   )\ntest_datagen = ImageDataGenerator(rescale= 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                                   train_dir,              \n                                                   target_size = (150,150), #Resize images to 150 X 150\n                                                   batch_size  = 20,\n                                                   class_mode = 'binary'\n                                                   )\nvalidation_generator = test_datagen.flow_from_directory(\n                                                   validation_dir,              \n                                                   target_size = (150,150), #Resize images to 150 X 150\n                                                   batch_size  = 20,\n                                                   class_mode = 'binary'\n                                                   )\n\nfor data_batch, labels_batch, in train_generator:\n    print('Data Batch shape:', data_batch.shape)\n    print('Labels Batch shape:', labels_batch.shape)\n    break","66d2de90":"model = build_cnn(display_summary = True)\n","c775feee":"%%time\ncallback_list = [#save best model                    \n                 ModelCheckpoint(filepath= 'model.h5', monitor= 'val_acc', save_best_only= True),\n\n                 ]\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 120,  # = num_train_images\/batch size(2400\/20)\n                            epochs = 200,\n                            validation_data = validation_generator,\n                            callbacks = callback_list,\n                            validation_steps = 40  # = num_valid_images\/batch_size\n                             )\n","597b1acf":"plot_results(history)\nbest_epoch =get_best_epcoh(history)","73626015":"### Train Vs Validation Accuracy\/Loss","065ef6db":"### Data Augumenation data example","ff8542b8":"## Build CNN Model With Drop out and BN","d0b3fdf2":"### Fit Model","f4fce7a8":"## Class Wagonr","6873b4f3":"## Data Preprocessing","3b03de4f":"## Data Preprocessing with Augumentation","db37b6be":"## Class Swift"}}