{"cell_type":{"9392edcb":"code","3e764711":"code","e7dfbb56":"code","c157b176":"markdown","d34b0a5c":"markdown","c64e1709":"markdown"},"source":{"9392edcb":"pip install bs4","3e764711":"import urllib.request,urllib.parse,urllib.error\nfrom bs4 import BeautifulSoup\nimport ssl\n\n\n# Ignore SSL certificate errors\nctx = ssl.create_default_context()\nctx.check_hostname = False\nctx.verify_mode = ssl.CERT_NONE\n\nurl =input('Enter -') \nhtml =urllib.request.urlopen(url,context=ctx).read()\nsoup=BeautifulSoup(html,'html.parser')\n\n\n\ntags=soup('span')\n\ns=0\nc=0\nfor tag in tags:\n    c=c+1\n    s=s+int(tag.contents[0])\nprint('count ',c)\nprint('sum',s)\n    ","e7dfbb56":"#importing libraries\nimport urllib.request,urllib.parse,urllib.error\nfrom bs4 import BeautifulSoup\nimport ssl\n\n\n# Ignore SSL certificate errors\nctx = ssl.create_default_context()\nctx.check_hostname = False\nctx.verify_mode = ssl.CERT_NONE\n\n\n#defining a function to parse the html\ndef soup(url):\n    html =urllib.request.urlopen(url,context=ctx).read()\n    soup=BeautifulSoup(html,'html.parser')\n    return soup\n\n#taking inputs and defining empty lists to use\nurl= input('Enter url : ')\ncount=eval(input('Enter count : '))\npos=eval(input('Enter position : '))\nlst1=[]#final list that is printed\nlst2=[]\n\nlst1.append(url)\nc=0\nwhile c<count:#to run the function as user specifies\n    sp=soup(url)#calling the function\n    for a in sp.find_all('a',href=True):\n        lst2.append(a['href'])\n    lst1.append(lst2[pos-1])\n    url=lst2[pos-1]#replacing the url\n    lst2=[]# emptying the list 2\n    c=c+1\n\nfor i in lst1:\n    print('Retrieving: ',i)\n\n","c157b176":"## week 4\n### Assignment 2","d34b0a5c":"# web crawler\nThe simle webcrawler that collects specified links from urls","c64e1709":"# Using Python to Access Web Data\n## Week 4\n### Assignment 1"}}