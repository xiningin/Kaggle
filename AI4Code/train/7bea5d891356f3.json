{"cell_type":{"aedf80aa":"code","fa32e4c4":"code","8f48af32":"code","b32b6d6e":"code","ec692405":"code","4de41763":"code","d44ae699":"code","b9519f5d":"code","a7ca855c":"code","fbc19c17":"code","82137f56":"code","9205053c":"code","592c5e0f":"code","94ded83d":"code","e4f4fa2a":"markdown","f7cb576d":"markdown","00c050af":"markdown","1eec4338":"markdown","acf3e30f":"markdown","f7b1b3ce":"markdown","216dd579":"markdown"},"source":{"aedf80aa":"import numpy as np\nimport pandas as pd","fa32e4c4":"gap_train = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/google-research-datasets\/gap-coreference\/master\/gap-development.tsv\", delimiter='\\t')\ngap_test = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/google-research-datasets\/gap-coreference\/master\/gap-test.tsv\", delimiter='\\t')\ngap_valid = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/google-research-datasets\/gap-coreference\/master\/gap-validation.tsv\", delimiter='\\t')","8f48af32":"test_stage_1 = pd.read_csv('..\/input\/test_stage_1.tsv', delimiter='\\t')\nsub = pd.read_csv('..\/input\/sample_submission_stage_1.csv')","b32b6d6e":"# !pip install https:\/\/github.com\/huggingface\/neuralcoref-models\/releases\/download\/en_coref_md-3.0.0\/en_coref_md-3.0.0.tar.gz\n# !pip install cymem==1.31.2 spacy==2.0.12","ec692405":"# import en_coref_md\n# from spacy.tokens import Doc","4de41763":"# nlp = en_coref_md.load()","d44ae699":"# class WhitespaceTokenizer(object):\n#     def __init__(self, vocab):\n#         self.vocab = vocab\n#     def __call__(self, text):\n#         words = text.split(' ')\n#         words = [word for word in words]\n#         spaces = [True] * len(words)\n#         return Doc(self.vocab, words=words, spaces=spaces)\n# nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)","b9519f5d":"# gap_train.iloc[0:2, :]","a7ca855c":"# def check_coref(row):\n#     text = row[\"Text\"]\n#     words = text.split()\n\n#     pronoun = row[\"Pronoun\"]\n#     pronoun_off = row[\"Pronoun-offset\"]\n#     A = row[\"A\"]\n#     len_a = len(A.split())\n#     A_off = row[\"A-offset\"]\n#     B = row[\"B\"]\n#     len_b = len(B.split())\n#     B_off = row[\"B-offset\"]\n#     position = 0\n#     for i, word in enumerate(words):\n#         if position == pronoun_off:\n#             pronoun_word_index = i\n#         if position == A_off:\n#             A_off_word_index = (i, i+len_a)\n#         if position == B_off:\n#             B_off_word_index = (i, i+len_b)\n#         position += len(word) + 1\n#     #print(A_off_word_index, B_off_word_index, pronoun_word_index)\n#     doc = nlp(text)\n#     token = None\n#     try:\n#         token = doc[pronoun_word_index]\n#     except:\n#         print(pronoun, pronoun_off)\n#     try:\n#         print(token, A, B, token._.coref_clusters)\n#     except:\n#         return [0, 0, 1]\n    \n# gap_train.apply(check_coref, axis=1)","fbc19c17":"# test_stage_1","82137f56":"def measure_dist(row):\n    pro_off = row[\"Pronoun-offset\"]\n    a_off = row[\"A-offset\"]\n    b_off = row[\"B-offset\"]\n    a_dist = np.abs(pro_off - a_off)\n    b_dist = np.abs(pro_off - b_off)\n    dist_tot = a_dist + b_dist\n    a_val = a_dist\/dist_tot\n    b_val = b_dist\/dist_tot\n    neither = .5\n    return [a_val, b_val, neither]\ntest_stage_1[\"preds\"] = test_stage_1.apply(measure_dist, axis = 1)","9205053c":"test = test_stage_1.preds.apply(pd.Series)","592c5e0f":"sub[\"A\"] = test[0]\nsub[\"B\"] = test[1]\nsub[\"NEITHER\"] = test[2]","94ded83d":"sub[['ID', 'A', 'B', 'NEITHER']].to_csv('submission.csv', index=False)","e4f4fa2a":"## Load Competition Data","f7cb576d":"Writing a custom tokenizer to replace SpaCy's. This one will simply split on spaces. SpaCy's is good, but it makes it much more complicated if the tokenizer is changing the character lengths because that is part of the information we have for knowing where the pronouns and referenced terms are. ","00c050af":"Wrote a ridiculous function to try to line up the character offset to actually match the words we are looking for. It resolves the correct words in all but 12 pronouns. Have not spent much time trying to figure out why these few do not resolve correctly, but my hypothesis is places where there are double spaces. ","1eec4338":"## Load GAP Coreference Data\n\n","acf3e30f":"In order to make the coreference model load correctly we need to install the correct specific version of the neuralcoref model, cymem and spacy. Order is also important. If you install neuralcoref after it will not work. ","f7b1b3ce":"After giving up on that I tried a much simpler approach of just weighting the decisions based on how far they are from the pronouns. \n\nI.e (pronoun at 271, A at 298, B at 341)\n\nA_dist = 298 - 271\n\nB_dist = 341 - 271\n\ntotal dist = A_dist(27) +B_dist( 70)\n\na_val = A_dist(27)\/total_dist(97)\n\nb_val = B_dist(70)\/total_dist(97)\n\n\nThis will calculate weights to give A and B. I weighted neither to simply always be .5 so that it balances with the other two since they will always add up to 1. In this competition we dont need the probability to sum to 1 since it is renormalized on a per row basis according to the rule section. \n","216dd579":"I tried to make spaCy work for this task, I am still convinced that there is a way to do it but it seemed like too much work. Eventually gave up and tried to see if potentially just picking the closest word everytime would be a decent baseline, but it turns out it is worse than the all .33 predictions. "}}