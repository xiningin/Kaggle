{"cell_type":{"032715d2":"code","b450cd22":"code","36166455":"code","6431effb":"code","78ea29a2":"code","9ebd61c3":"code","7cb65437":"code","97398eb8":"code","ad969f82":"code","e30b9fa2":"code","40fcec00":"code","71504b0c":"code","7ada74c6":"code","8480ec23":"code","cbb850cf":"code","4dc8310f":"code","7e481ff6":"code","9c07737c":"code","e1fd3d72":"code","8143fbed":"code","58acd69d":"code","2c3c3385":"code","7955d408":"code","121d250d":"code","b1bbb090":"code","762e25f3":"code","d0ebf1f4":"code","beb4cc05":"code","e0a33ff1":"code","fe87b1b3":"code","e9b3a389":"code","92b254b8":"code","ca46a85d":"code","311f143f":"code","774d1653":"code","48d8f5b0":"code","3f59f012":"code","3860a5de":"code","34a2b883":"code","329af7c2":"code","4ec374b8":"code","d4ac0027":"code","bd00979e":"code","5a6b6f95":"code","3ecca4d7":"code","f1271a25":"code","aa8e9e16":"markdown","b42df02e":"markdown","58dbad26":"markdown","834ef5e6":"markdown","fa4daaee":"markdown","d6fb6a57":"markdown","b53b0efe":"markdown","4b2c3766":"markdown","50fe53b9":"markdown","49ebb88a":"markdown","12dfcaba":"markdown","45522105":"markdown","e67efec1":"markdown","7e01524a":"markdown","5c130cbe":"markdown","f64cdbfd":"markdown","74029d15":"markdown","8935c8a2":"markdown","69a1832c":"markdown","2303faea":"markdown","84e4b42a":"markdown"},"source":{"032715d2":"!pip install gensim\n!pip install tensorflow\n!pip install ftfy\n!pip install gensim\n!pip install skorch\n!pip install scikit-learn==0.23.1\n","b450cd22":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n\nfrom numpy.ma import MaskedArray\nimport sklearn.utils.fixes\n\nsklearn.utils.fixes.MaskedArray = MaskedArray","36166455":"import random\nimport string\nimport re\nfrom ftfy import fix_text\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument","6431effb":"train = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis-pmr3508\/data_train.csv\")","78ea29a2":"train.head(10)","9ebd61c3":"train.info()","7cb65437":"train.describe()","97398eb8":"print (train.duplicated().sum()\/24984.00000*100, \"%\")\n","ad969f82":"train.isna().sum()","e30b9fa2":"train.drop_duplicates(subset='review', keep='first', inplace=True)","40fcec00":"print (train.duplicated().sum()\/24984.00000*100, \"%\")","71504b0c":"def clean(text):\n    \n    txt = text.lower().replace(\"<br \/>\",\" \") # tags html\n    txt = txt.replace(\" \u2014 \", \" \") # h\u00edfens\n    txt = fix_text(txt) # Mojibakes\n    txt = txt.translate(str.maketrans('', '', string.punctuation)) # pontua\u00e7\u00e3o\n    \n    txt = re.sub(\"\\d+\", ' <number> ', txt) # token especial para n\u00fameros\n    txt = re.sub(' +', ' ', txt) # espa\u00e7os extras\n    \n    return txt","7ada74c6":"X = train['review']\nY = train['positive']","8480ec23":"X = X.apply(clean)","cbb850cf":"X.head()","4dc8310f":"X = X.apply(lambda x: x.split())\nX.head()","7e481ff6":"from gensim.models.doc2vec import Doc2Vec\n\nD2V = Doc2Vec.load(\"..\/input\/sentiment-analysis-pmr3508\/doc2vec\")\n\nprint (\"A configura\u00e7\u00e3o \u00e9 dada por \" , D2V, \"\\n\\n\", \"A primeira linha\\n \", D2V[0])","9c07737c":"def emb(txt, model, normalize=False): \n    model.random.seed(42)\n    x=model.infer_vector(txt, steps=20)\n    \n    if normalize: return(x\/np.sqrt(x@x))\n    else: return(x)","e1fd3d72":"X = [emb(x, D2V) for x in X] \nX = np.array(X)","8143fbed":"X","58acd69d":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import loguniform as sp_loguniform\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=42)","2c3c3385":"Hyperpar = {'hidden_layer_sizes': [2**i for i in np.arange(3,7)], \n                \"alpha\": sp_loguniform(0.000001, 0.1),\n               'learning_rate': ['constant','adaptive']}\nMLP = MLPClassifier(random_state=42 , early_stopping=True)\n\nsearch_MLP1 = RandomizedSearchCV(MLP, Hyperpar, n_iter=30, cv=2, n_jobs=-1, scoring='roc_auc', random_state=0, verbose=2)\n\nscore1 = search_MLP1.fit(X_train, Y_train)","7955d408":"Hyperpar2Cam = {'hidden_layer_sizes': [(2**i, 2**j) for i in np.arange(3,7) for j in np.arange(3,7)], \n                \"alpha\": sp_loguniform(0.000001, 0.1),\n               'learning_rate': ['constant','adaptive']}\n\nMLP2 = MLPClassifier(random_state=42 , early_stopping=True)\n\nsearch_MLP2 = RandomizedSearchCV(MLP2, Hyperpar2Cam, n_iter=30, cv=2, n_jobs=-1, scoring='roc_auc', random_state=0, verbose=2)\n\nscore2 = search_MLP2.fit(X_train, Y_train)","121d250d":"score1.best_params_\n\n","b1bbb090":"score1.best_score_","762e25f3":"score1.best_params_","d0ebf1f4":"score2.best_score_","beb4cc05":"score2.best_params_","e0a33ff1":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(solver=\"liblinear\", random_state=5)\n\nlogregres = dict( C=np.linspace(0.01, 10, 100), penalty=[\"l1\", \"l2\"])\n\n\nlogreg = RandomizedSearchCV(logreg,logregres,scoring=\"roc_auc\", cv=2, n_iter=30,n_jobs=-1, random_state = 0\n)\nlogreg_res = logreg.fit(X, Y)\n\n","fe87b1b3":"logreg_res.best_params_","e9b3a389":"logreg_res.best_score_","92b254b8":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch","ca46a85d":"# Nossa rede neural\nclass MLPNet(nn.Module):\n    def __init__(self, hidden1_dim=512, hidden2_dim=64, p=0.2):\n        super().__init__()\n        self.fc1 = nn.Linear(50, hidden1_dim)           \n        self.fc2 = nn.Linear(hidden1_dim, hidden2_dim)  \n        self.fc3 = nn.Linear(hidden2_dim, 2) \n        \n        self.dropout = nn.Dropout(p)                \n        \n    def forward(self, X, **kwargs):\n        fc_out = F.relu(self.fc1(X))              \n        fc_out = self.dropout(fc_out)                   \n        \n        fc_out = F.relu(self.fc2(fc_out))              \n        fc_out = self.dropout(fc_out)                  \n        \n        fc_out = self.fc3(fc_out)                       \n        soft_out = F.softmax(fc_out, dim=-1)            \n        \n        return soft_out\n    ","311f143f":"import torch\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmlp_net = MLPNet().to(device)","774d1653":"import skorch\nfrom torch import optim\nfrom skorch import NeuralNetClassifier\n\nskorch_net = NeuralNetClassifier(mlp_net,\n                                 max_epochs=20,\n                                 lr=1e-4,\n                                 optimizer=optim.Adam,\n                                 optimizer__weight_decay=1e-4,\n                                 train_split=False,\n                                 verbose=0,\n                                 iterator_train__shuffle=True,\n                                 )","48d8f5b0":"data_test1 = pd.read_csv(\"..\/input\/sentiment-analysis-pmr3508\/data_test1.csv\")","3f59f012":"X_test1 = data_test1['review'].tolist()\nY_test1 = data_test1['positive']","3860a5de":"X_test1 = [clean(x) for x in X_test1]\nX_test1 = [x.split() for x in X_test1]\nX_test1 = [emb(x, D2V) for x in X_test1]\nX_test1 = np.array(X_test1)","34a2b883":"RN1 = roc_auc_score(Y_test1, search_MLP1.predict_proba(X_test1)[:,1])\nprint(RN1)","329af7c2":"RN2 = roc_auc_score(Y_test1, search_MLP2.predict_proba(X_test1)[:,1])\nprint(RN2)","4ec374b8":"Flor = roc_auc_score(Y_test1, logreg.predict(X_test1))\nprint(Flor)","d4ac0027":"data_test2 = pd.read_csv(\"..\/input\/sentiment-analysis-pmr3508\/data_test2_X.csv\")","bd00979e":"X_test2 = data_test2['review'].tolist()\nX_test2 = [clean(x) for x in X_test2]\nX_test2 = [x.split() for x in X_test2]\nX_test2 = [emb(x, D2V) for x in X_test2]\nX_test2 = np.array(X_test2)","5a6b6f95":"predict = search_MLP2.predict_proba(X_test2)[:,1]","3ecca4d7":"submission = {'positive': predict}\nsubmission = pd.DataFrame(submission)\n\nsubmission.head(10)","f1271a25":"submission.to_csv(\"submission.csv\", index = True, index_label = 'Id')","aa8e9e16":"Temos um modelo pr\u00e9 treinado do Cod2Vec, que \u00e9 o modelo apresentado anteriormente, podemos agora incorporar a fun\u00e7\u00e3o Emb do notebook a ser seguido em X","b42df02e":"Dentre as compara\u00e7\u00f5es obtidas, temos que:","58dbad26":"Podemos visualizar que os dados est\u00e3o uniformes, podemos agora processar os dados de X","834ef5e6":"Ap\u00f3s a cria\u00e7\u00e3o das redes neurais com 1 e 2 camadas, podemos comparar o score dos problemas em quest\u00e3o com diferentes solu\u00e7\u00f5es, utilizaremos a regress\u00e3o log\u00edstica, caracterizado como uma t\u00e9cnica estat\u00edstica que produz um modelo que termite a predi\u00e7\u00e3o por meio de uma s\u00e9rie de vari\u00e1veis","fa4daaee":"Temos que n\u00e3o h\u00e1 dados faltantes, e 0.38% dos dados duplicados, portanto podemos zera-los \"dropando\" os dados.","d6fb6a57":"# Pytorch","b53b0efe":"A finalidade desse trabalho \u00e9 realizar por meio de Redes Neurais a an\u00e1lise de sentimentos de um banco de dados com coment\u00e1rios pr\u00e9 determinados como positivos ou negativos acerca das cr\u00edticas do IMDb utilizando o Doc2Vec.\nO primeiro passo \u00e9 realizar a instala\u00e7\u00e3o das bibliotecas necess\u00e1rias para efetuar viabilizar as transforma\u00e7\u00f5es do texto em vetores, e aplica\u00e7\u00e3o das redes neurais. \n\nHash - 105","4b2c3766":"Com os dados fatiados, podemos efetivamente visualizar efetivamente como vetores","50fe53b9":"Rede neural \u00e9 definido pela SAS como Redes neurais s\u00e3o sistemas de computa\u00e7\u00e3o com n\u00f3s interconectados que funcionam como os neur\u00f4nios do c\u00e9rebro humano. Usando algoritmos, elas podem reconhecer padr\u00f5es escondidos e correla\u00e7\u00f5es em dados brutos, agrup\u00e1-los e classific\u00e1-los, e \u2013 com o tempo \u2013 aprender e melhorar continuamente.\nUsaremos esse recurso para buscar encontrar um par\u00e2metros que tenham o maior score poss\u00edvel, com 1 e 2 layers escondidas, come\u00e7aremos com o uso do scikit-learn. e em seguida ser\u00e1 feita uma compara\u00e7\u00e3o entre os valores buscando o m\u00e9todo mais eficiente.","49ebb88a":"Para continuar, ser\u00e1 necess\u00e1rio utilizar os recursos necess\u00e1rios do sklearn:","12dfcaba":"Usaremos tamb\u00e9m o Pytorch para buscar scores potencialmente maiores do que j\u00e1 temos. O PyTorch \u00e9 um projeto open-source cujo principal desenvolvedor \u00e9 o laborat\u00f3rio de Pesquisa em AI do Facebook. Ele foi escrito usando uma combina\u00e7\u00e3o de Python, C++ e CUDA, sendo pensado como uma ferramenta para Python. Logo:","45522105":"Para que seja poss\u00edvel efetuar a classifica\u00e7\u00e3o, primeiramente \u00e9 necess\u00e1rio efetuar o pr\u00e9-processamento para que haja uniformiza\u00e7\u00e3o das palavras, e dessa forma visualiza-las como um vetor com baixa influ\u00eancia da individualidade redativa de cada pessoa durante a escrita dos coment\u00e1rios, retirar os coment\u00e1rios duplicados e verificar se h\u00e1 dados faltantes.","e67efec1":"# Pr\u00e9-Processamento","7e01524a":"Efetuado as opera\u00e7\u00f5es de pr\u00e9-processamento, temos margem para continuar colocando a fun\u00e7\u00e3o de limpeza desenvolvido por Felipe Maia Polo:","5c130cbe":"# Redes neurais","f64cdbfd":"Temos que os dados s\u00e3o divididos em \"review\", que ser\u00e1 o texto convertido em vetores, e \"positive\" que s\u00e3o valores associados em 0 e 1, entre os quais 0 significa opini\u00e3o n\u00e3o positiva, e 1 opini\u00e3o positiva. \nA descri\u00e7\u00e3o do \"positive\" express\u00e3o m\u00e9dia 0.50001, o que indica que existe um n\u00famero semelhante entre opini\u00f5es positiva e negativa nessa base dedados.\nFeita essa an\u00e1lise, podemos verificar se h\u00e1 dados faltantes ou se h\u00e1 dados ausentes:","74029d15":"Precisamos agora realizar a leitura dos dados de treino, e em seguida visualizar os primeiros dados para verificar se os dados foram efetivamente lidos.","8935c8a2":"Estes foram os melhores resultados para o n\u00famero de intera\u00e7\u00f5es determinados, podemos ver que o score n\u00e3o muda muito efetivamente com o aumento das camadas.","69a1832c":"# Compara\u00e7\u00e3o com m\u00e9todos alternativos","2303faea":"Para verificar se a data frame foi importado:","84e4b42a":"# Introdu\u00e7\u00e3o"}}