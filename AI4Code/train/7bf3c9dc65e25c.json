{"cell_type":{"f7e9c36f":"code","65194778":"code","13b4e03c":"code","a09e3240":"code","afddf6c6":"code","aa570614":"code","a10901ce":"code","1e488f68":"code","e5c13930":"code","35bb65b1":"code","54945bc4":"code","badd35d1":"code","3b646cc2":"code","4183d78a":"code","e2538ca9":"code","881d310b":"code","424d6841":"code","b8bed30b":"code","d30673a6":"code","e936aa21":"code","58735606":"markdown","5ca8d312":"markdown","ae915535":"markdown"},"source":{"f7e9c36f":"import numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import NearestNeighbors\nfrom imblearn.over_sampling import SMOTENC","65194778":"TRAIN_FEATURES_PATH = \"..\/input\/lish-moa\/train_features.csv\"\nTRAIN_TARGETS_PATH = \"..\/input\/lish-moa\/train_targets_scored.csv\"\nDOSE_MAPPING = {\"D1\": 0, \"D2\": 1}\nTIME_MAPPING = {24: 0, 48: 2, 72: 3}","13b4e03c":"train_targets_df = pd.read_csv(TRAIN_TARGETS_PATH)\ntrain_features_df = pd.read_csv(TRAIN_FEATURES_PATH)\ntrain = train_features_df.merge(train_targets_df, on=\"sig_id\")\ntrain = (\n    train.loc[lambda df: df[\"cp_type\"] == \"trt_cp\"]\n    .reset_index(drop=True)\n    .drop([\"cp_type\", \"sig_id\"], axis=1)\n)","a09e3240":"train[\"cp_dose\"] = train[\"cp_dose\"].map(DOSE_MAPPING)\ntrain[\"cp_time\"] = train[\"cp_time\"].map(TIME_MAPPING)","afddf6c6":"FEATURES = sorted(train_features_df.drop([\"cp_type\", \"sig_id\"], axis=1).columns.tolist())\nTARGETS = sorted(train_targets_df.drop(\"sig_id\", axis=1).columns.tolist())","aa570614":"print(len(TARGETS))\nprint(FEATURES[:5])\nprint(TARGETS[:5])","a10901ce":"def get_tail_label(df: pd.DataFrame, ql=[0.05, 1.]) -> list:\n    \"\"\"\n    Find the underrepresented targets.\n    Underrepresented targets are those which are observed less than the median occurance.\n    Targets beyond a quantile limit are filtered.\n    \"\"\"\n    irlbl = df.sum(axis=0)\n    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n    irlbl = irlbl.max() \/ irlbl\n    threshold_irlbl = irlbl.median()\n    tail_label = irlbl[irlbl > threshold_irlbl].index.tolist()\n    return tail_label\n\ndef get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.05, 1.]):\n    \"\"\"\n    return\n    X_sub: pandas.DataFrame, the feature vector minority dataframe\n    y_sub: pandas.DataFrame, the target vector minority dataframe\n    \"\"\"\n    tail_labels = get_tail_label(y, ql=ql)\n    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n    \n    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n    return X_sub, y_sub\n\ndef nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n    \"\"\"\n    Give index of 10 nearest neighbor of all the instance\n    \n    args\n    X: np.array, array whose nearest neighbor has to find\n    \n    return\n    indices: list of list, index of 5 NN of each element in X\n    \"\"\"\n    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n    euclidean, indices = nbs.kneighbors(X)\n    return indices\n\ndef MLSMOTE(X, y, n_sample, neigh=5):\n    \"\"\"\n    Give the augmented data using MLSMOTE algorithm\n    \n    args\n    X: pandas.DataFrame, input vector DataFrame\n    y: pandas.DataFrame, feature vector dataframe\n    n_sample: int, number of newly generated sample\n    \n    return\n    new_X: pandas.DataFrame, augmented feature vector data\n    target: pandas.DataFrame, augmented target vector data\n    \"\"\"\n    indices2 = nearest_neighbour(X, neigh=5)\n    n = len(indices2)\n    new_X = np.zeros((n_sample, X.shape[1]))\n    target = np.zeros((n_sample, y.shape[1]))\n    for i in range(n_sample):\n        reference = random.randint(0, n-1)\n        neighbor = random.choice(indices2[reference, 1:])\n        all_point = indices2[reference]\n        nn_df = y[y.index.isin(all_point)]\n        ser = nn_df.sum(axis = 0, skipna = True)\n        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n        ratio = random.random()\n        gap = X.loc[reference,:] - X.loc[neighbor,:]\n        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n    new_X = pd.DataFrame(new_X, columns=X.columns)\n    target = pd.DataFrame(target, columns=y.columns)\n    return new_X, target\n\n\n#\u00a0TODO: Adapt this to MLSMOTE?\n#\u00a0smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n#\u00a0X_resampled, y_resampled = smote_nc.fit_resample(X, y)","1e488f68":"#\u00a0Should be a DataFrame\nX = train.loc[:, FEATURES]\ny = train.loc[:, TARGETS]","e5c13930":"X.shape","35bb65b1":"N_SAMPELS = 1000\nN_NEIGHBORS = 5","54945bc4":"X_sub, y_sub = get_minority_samples(X, y)  # Getting minority samples of that datframe\nX_res, y_res = MLSMOTE(X_sub, y_sub, N_SAMPELS, N_NEIGHBORS)  # Applying MLSMOTE to augment the dataframe","badd35d1":"y_res.head()","3b646cc2":"X_res.head()","4183d78a":"X_res[\"cp_time\"].value_counts()","e2538ca9":"X_res[\"cp_dose\"].value_counts()","881d310b":"y_res.sum()","424d6841":"X_res.mean()","b8bed30b":"X.mean()","d30673a6":"pd.concat([X, X_res]).to_csv(\"augmented_train_features.csv\", index=False)","e936aa21":"pd.concat([y, y_res]).to_csv(\"augmented_train_targets.csv\", index=False)","58735606":"#\u00a0Saving the new data","5ca8d312":"#\u00a0Old vs augmented data","ae915535":"An application of the MLSMOTE technique implemented in the following [notebook](https:\/\/www.kaggle.com\/tolgadincer\/upsampling-multilabel-data-with-mlsmote) (upvote it if you find it useful) to the MoA dataset.\n\nNotice that for now, I don't know yet how to deal with categorical features (one idea though is to do one-hot encoding first then apply the standard method). \n\nLet me know in the comments if you have an idea.\nEnjoy!"}}