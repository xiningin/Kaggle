{"cell_type":{"71f270c0":"code","90632b5e":"code","6f8124d5":"code","df4161ab":"code","25f9d6ad":"code","ff315b7c":"code","5af9521f":"code","2d9ce298":"code","47816c28":"code","328799e7":"code","f3431215":"code","9fce3beb":"code","3240fabd":"code","7ea676a0":"code","9301781b":"code","2b4f378e":"code","e9614955":"code","609be922":"code","23289f17":"code","c34db962":"code","e5fed7b0":"code","daa15039":"code","f38291e1":"code","07d13edf":"code","79fcb91c":"code","ffacf1d1":"code","56c143f0":"code","b83ca7a6":"code","8b8c9072":"code","cf92e347":"code","25a85d1c":"markdown","f91c3cd1":"markdown","156a39e8":"markdown","77d1361c":"markdown","65601d8f":"markdown","8fde575f":"markdown"},"source":{"71f270c0":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","90632b5e":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nfrom fastai.utils.mem import *","6f8124d5":"path = Path('\/kaggle\/input\/iwildcam-2019-fgvc6')\n\ndebug =1\nif debug:\n    train_pct=0.04\nelse:\n    train_pct=0.5","df4161ab":"# Load train dataframe\ntrain_df = pd.read_csv(path\/'train.csv')\ntrain_df = pd.concat([train_df['id'],train_df['category_id']],axis=1,keys=['id','category_id'])\ntrain_df.head()","25f9d6ad":"# Load sample submission\ntest_df = pd.read_csv(path\/'test.csv')\ntest_df = pd.DataFrame(test_df['id'])\ntest_df['predicted'] = 0\ntest_df.head()\n","ff315b7c":"free = gpu_mem_get_free_no_cache()\n# the max size of bs depends on the available GPU RAM\nif free > 8200: bs=64\nelse:           bs=32\nprint(f\"using bs={bs}, have {free}MB of GPU RAM free\")\n\ntfms = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4,\n                      p_affine=1., p_lighting=1.)\n# app_train = app_train.append(app_test).reset_index()","5af9521f":"train, test = [ImageList.from_df(df, path=path, cols='id', folder=folder, suffix='.jpg') \n               for df, folder in zip([train_df, test_df], ['train_images', 'test_images'])]\nif debug:\n    src= train.split_subsets(train_size=train_pct, valid_size= train_pct*2)\n#     test=test[:1000]\nelse:\n    src= train.split_subsets(train_size=train_pct, valid_size=0.2, seed=2)\n#     src= train.split_by_rand_pct(0.2, seed=2)\n\nprint(src)\n    \ndef get_data(size, bs, padding_mode='reflection'):\n    return (src.label_from_df(cols='category_id')\n           .add_test(test)\n           .transform(tfms, size=size, padding_mode=padding_mode)\n           .databunch(bs=bs).normalize(imagenet_stats))    \n    \n# data = (train.split_by_rand_pct(0.2, seed=2)\n#         .label_from_df(cols='category_id')\n#         .add_test(test)\n#         .transform(get_transforms(), size=32)\n#         .databunch(path=Path('.'), bs=64).normalize())","2d9ce298":"data = get_data(224, bs, 'zeros')","47816c28":"def _plot(i,j,ax):\n    x,y = data.train_ds[3]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(8,8))","328799e7":"# learn = cnn_learner(data, base_arch=models.densenet121, metrics=[FBeta(),accuracy], wd=1e-5).mixup()\ngc.collect()\n# wd=1e-2\nwd=1e-1\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate, bn_final=True, wd=wd )\nlearn.model_dir= '\/kaggle\/working\/'","f3431215":"# lr=1e-2\n# learn.fit_one_cycle(3, slice(lr), pct_start=0.8)","9fce3beb":"# learn.save('223')","3240fabd":"# learn.unfreeze()\n# learn.lr_find()\n# learn.recorder.plot(suggestion=True)","7ea676a0":"# # lr = 2e-2\n# # learn.fit_one_cycle(2, slice(lr))\n\n# learn.fit_one_cycle(6, max_lr=slice(5.75E-06,lr\/5), pct_start=0.8)","9301781b":"# learn.save('224')","2b4f378e":"!cp \/kaggle\/input\/fastai-starter-iwildcam-2019-ad561b\/224.pth \/kaggle\/working\nlearn.load('224')","e9614955":"data = get_data(352,bs)\nlearn.data = data\n","609be922":"learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))\nlearn.save('352')","23289f17":"# !cp \/kaggle\/input\/352pth\/352.pth \/kaggle\/working\n# learn.load('352')","c34db962":"learn.unfreeze()","e5fed7b0":"learn.lr_find()\nlearn.recorder.plot()","daa15039":"lr = 1e-3\nlearn.fit_one_cycle(8, slice(lr\/100, lr))","f38291e1":"learn.save('stage-2-sz32')","07d13edf":"# !cp \/kaggle\/input\/stage-2-sz32.pth \/kaggle\/working\n# learn.load('stage-2-sz32')","79fcb91c":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","ffacf1d1":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","56c143f0":"test_preds = learn.get_preds(DatasetType.Test)\ntest_df['predicted'] = test_preds[0].argmax(dim=1)","b83ca7a6":"test_df.shape","8b8c9072":"csv_path ='\/kaggle\/working\/submission.csv'\ntest_df.to_csv(csv_path, index=False)","cf92e347":"# # import the modules we'll need\n# from IPython.display import HTML\n# import base64\n\n\n# # function that takes in a dataframe and creates a text link to  \n# # download it (will only work for files < 2MB or so)\n# def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n#     csv = df.to_csv()\n#     b64 = base64.b64encode(csv.encode())\n#     payload = b64.decode()\n#     html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n#     html = html.format(payload=payload,title=title,filename=filename)\n#     return HTML(html)\n\n\n\n# # create a link to download the dataframe\n# create_download_link(test_df[90000:120000])\n","25a85d1c":"# Use Fastai ","f91c3cd1":"## Test predictions","156a39e8":"## Interpretation\n\nThe fastai library also provides some functions for interpreting the models, such as displaying images with the top losses, displaying confusion matrices, and [more](https:\/\/docs.fast.ai\/vision.learner.html#ClassificationInterpretation).","77d1361c":"## Train model\n","65601d8f":"# \u8cc7\u6599\u589e\u5f37","8fde575f":"Here, we use discriminative learning rates, where lower learning rates are used for the earlier layers in the model."}}