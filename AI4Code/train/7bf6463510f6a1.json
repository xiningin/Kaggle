{"cell_type":{"87550e10":"code","a315298c":"code","b3115e8f":"code","5919a820":"code","5649dceb":"code","e9374fe0":"code","a9b5868d":"code","a2826140":"code","eca6f515":"code","8f8291db":"code","e2a45c37":"code","a7c85a72":"code","f25389d6":"code","f5ed5d5c":"code","314cba27":"code","a1431a2c":"code","9df42314":"code","220fb3ad":"code","b1f2678f":"code","d53cd5fd":"code","f9bfcc39":"code","c25e59f1":"code","b5da2bf7":"code","97f87564":"code","a53e4d43":"code","d0a6c116":"code","6129a854":"code","9a9aa838":"code","d81c2cce":"code","0d5a8837":"code","cf283a1a":"code","9a3de1a6":"code","90240f5f":"code","a54122ac":"code","590778b2":"code","71b4c90c":"code","1c4364a9":"code","ab4e9e4c":"code","b9152ffd":"code","c1bc6f8f":"code","85a6717f":"code","fa8348e5":"code","63476c49":"code","19a9edea":"code","de1bc622":"code","8f0b2bf0":"code","37476701":"code","7e2f8a21":"code","73a96930":"code","bda3dc48":"code","b460b05a":"code","fc03eac9":"code","e3d2ee40":"code","9adb2bc8":"code","71acfdab":"code","4aee7288":"code","e92e777c":"code","ad3847b0":"code","f659cf33":"code","36912b50":"markdown","718e7ebc":"markdown","16771dc6":"markdown","5645b571":"markdown"},"source":{"87550e10":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","a315298c":"path = os.getcwd()+'..\/input\/train.csv'","b3115e8f":"data = pd.read_csv('..\/input\/train.csv')","5919a820":"print(data.head())","5649dceb":"data.describe()","e9374fe0":"data.isnull().sum()","a9b5868d":"# percent of missing \"Age\" \nprint('Percent of missing \"Age\" records is %.2f%%' %((data['Age'].isnull().sum()\/data.shape[0])*100))","a2826140":"ax = data[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ndata[\"Age\"].plot(kind='density', color='teal')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","eca6f515":"# mean age\nprint('The mean of \"Age\" is %.2f' %(data[\"Age\"].mean(skipna=True)))\n# median age\nprint('The median of \"Age\" is %.2f' %(data[\"Age\"].median(skipna=True)))","8f8291db":"print('Percent of missing \"Cabin\" records is %.2f%%' %((data['Cabin'].isnull().sum()\/data.shape[0])*100))","e2a45c37":"# percent of missing \"Embarked\" \nprint('Percent of missing \"Embarked\" records is %.2f%%' %((data['Embarked'].isnull().sum()\/data.shape[0])*100))","a7c85a72":"import seaborn as sns\nprint('Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):')\nprint(data['Embarked'].value_counts())\nsns.countplot(x='Embarked', data=data, palette='Set2')\nplt.show()","f25389d6":"print('The most common boarding port of embarkation is %s.' %data['Embarked'].value_counts().idxmax())","f5ed5d5c":"\ndata[\"Age\"].fillna(data[\"Age\"].median(skipna=True), inplace=True)\ndata[\"Embarked\"].fillna(data['Embarked'].value_counts().idxmax(), inplace=True)\ndata.drop('Cabin', axis=1, inplace=True)","314cba27":"data.isnull().sum()","a1431a2c":"data.head()","9df42314":"plt.figure(figsize=(15,8))\nax = data[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ndata[\"Age\"].plot(kind='density', color='teal')\nax.legend(['Raw Age'])\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","220fb3ad":"## Create categorical variable for traveling alone\ndata['TravelAlone']=np.where((data[\"SibSp\"]+data[\"Parch\"])>0, 0, 1)\ndata.drop('SibSp', axis=1, inplace=True)\ndata.drop('Parch', axis=1, inplace=True)","b1f2678f":"#create categorical variables and drop some variables\ndata=pd.get_dummies(data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\ndata.drop('Sex_female', axis=1, inplace=True)\ndata.drop('PassengerId', axis=1, inplace=True)\ndata.drop('Name', axis=1, inplace=True)\ndata.drop('Ticket', axis=1, inplace=True)\n\n\ndata.head()","d53cd5fd":"path = os.getcwd()+'..\/input\/test.csv'\ntest_df = pd.read_csv('..\/input\/test.csv')\ntest_data = test_df.copy()\ntest_data[\"Age\"].fillna(data[\"Age\"].median(skipna=True), inplace=True)\ntest_data[\"Fare\"].fillna(data[\"Fare\"].median(skipna=True), inplace=True)\ntest_data.drop('Cabin', axis=1, inplace=True)\n\ntest_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\n\ntest_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)\n\ntesting = pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\ntesting.drop('Sex_female', axis=1, inplace=True)\ntesting.drop('PassengerId', axis=1, inplace=True)\ntesting.drop('Name', axis=1, inplace=True)\ntesting.drop('Ticket', axis=1, inplace=True)\n\nfinal_test = testing\nfinal_test.head()","f9bfcc39":"def sigmoid(z):\n    return 1 \/ (1 + np.exp(-z))","c25e59f1":"def cost(theta, X, y):\n    theta = np.matrix(theta)\n    X = np.matrix(X)\n    y = np.matrix(y)\n    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n    return np.sum(first - second) \/ (len(X))","b5da2bf7":"cols = list(data.columns.values) #Make a list of all of the columns in the df\ncols.pop(cols.index('Survived')) #Remove b from list\ndata = data[cols+['Survived']] #Create new dataframe with columns in the order you want\ndata.head()","97f87564":"# add a ones column - this makes the matrix multiplication work out easier\ndata.insert(0, 'Ones', 1)\n\n# set X (training data) and y (target variable)\n\n\n\n\n# convert to numpy arrays and initalize the parameter array theta\n","a53e4d43":"cols = data.shape[1]\ncols","d0a6c116":"X = data.iloc[:,0:cols-1]\n","6129a854":"X","9a9aa838":"Y = data.iloc[:,cols-1:cols]\n\n","d81c2cce":"Y.shape","0d5a8837":"X.shape","cf283a1a":"theta = np.zeros(11)","9a3de1a6":"theta.shape","90240f5f":"X.shape, theta.shape, Y.shape","a54122ac":"cost(theta, X, Y)","590778b2":"def gradient(theta, X, y):\n    theta = np.matrix(theta)\n    X = np.matrix(X)\n    y = np.matrix(y)\n    \n    parameters = int(theta.ravel().shape[1])\n    grad = np.zeros(parameters)\n    \n    error = sigmoid(X * theta.T) - y\n    \n    for i in range(parameters):\n        term = np.multiply(error, X[:,i])\n        grad[i] = np.sum(term) \/ len(X)\n    \n    return grad","71b4c90c":"theta.shape","1c4364a9":"import scipy.optimize as opt\nresult = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, Y))\ncost(result[0], X, Y)","ab4e9e4c":"\ntheta_min = np.matrix(result[0])\nX= np.matrix(X)\nY=np.matrix(Y)\nX.shape,theta.shape, result[0].shape,theta_min.shape,theta_min.T.shape","b9152ffd":"def predict(theta, X):\n    probability = sigmoid(X * theta.T)\n    return [1 if x >= 0.5 else 0 for x in probability]\n\ntheta_min = np.matrix(result[0])\npredictions = predict(theta_min, X)\ncorrect = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, Y)]\ntemp = sum(map(int,correct))\naccuracy_test = temp\/ len(correct)\nprint ('accuracy_test = {0}%'.format(accuracy_test*100))\n","c1bc6f8f":"Y.shape","85a6717f":"final_test","fa8348e5":"final_test.insert(0, 'Ones', 1)","63476c49":"final_test.insert(11, 'Survived', 1)","19a9edea":"X_test = final_test.iloc[:,0:cols-1]","de1bc622":"X_test = np.matrix(X_test)","8f0b2bf0":"Y_test = final_test.iloc[:,cols-1:cols]","37476701":"Y_test = np.matrix(Y_test)","7e2f8a21":"final_test","73a96930":"predict(theta_min,X_test)","bda3dc48":"Survived_test = predict(theta_min,X_test)","b460b05a":"Survived_test= pd.DataFrame(Survived_test)","fc03eac9":"Survived_test.head()","e3d2ee40":"final_test['Survived'] = Survived_test","9adb2bc8":"final_test['Survived'].count()\n","71acfdab":"test_df['PassengerId'].count()","4aee7288":"final_test['Survived'].head()","e92e777c":"df1 = pd.DataFrame(test_df['PassengerId'])\ndf2= pd.DataFrame(final_test['Survived'])\nconcat = pd.merge(df1,df2, left_index=True, right_index = True)\nconcat.head()","ad3847b0":"concat.head()","f659cf33":"concat.to_csv('concat.csv',index=False)","36912b50":"\n## 2.3. Embarked - Missing Values","718e7ebc":"### Now, apply the same changes to the test data. <br>\nI will apply to same imputation for \"Age\" in the Test data as I did for my Training data (if missing, Age = 28).  <br> I'll also remove the \"Cabin\" variable from the test data, as I've decided not to include it in my analysis. <br> There were no missing values in the \"Embarked\" port variable. <br> I'll add the dummy variables to finalize the test set.  <br> Finally, I'll impute the 1 missing value for \"Fare\" with the median, 14.45.","16771dc6":"## 2.4. Final Adjustments to Data (Train & Test)","5645b571":"Also create categorical variables for Passenger Class (\"Pclass\"), Gender (\"Sex\"), and Port Embarked (\"Embarked\"). "}}