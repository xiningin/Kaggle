{"cell_type":{"082f271a":"code","8b0b810d":"code","1fca0f4f":"code","f335df57":"code","3a09b613":"code","20e67083":"code","18bed08b":"code","3d69f925":"code","f14d53f2":"code","ff600a7e":"code","8faaf539":"code","576af5fc":"code","b40a940e":"code","5ce51a12":"code","5660b647":"code","4a09c42b":"code","1778d554":"code","4fa6b081":"code","b9a50108":"code","a0cda74a":"code","cd467328":"code","ac4f6467":"code","f594176f":"code","f360fd5c":"code","643aacfa":"code","12d4d507":"code","88239345":"code","051bfd4a":"code","f37447eb":"code","53afb80f":"code","1cf5b73e":"code","47c9f432":"code","213d0c05":"code","630fd2b8":"code","936f4df2":"code","721fa9b7":"code","5e90662c":"code","c75e8742":"code","12439f81":"code","4d8813d0":"code","1a6566d8":"code","a1049a9a":"code","d17bb390":"code","2a159a29":"code","deb7a771":"code","c8d3d036":"code","78183726":"code","d049980e":"code","22f9cd79":"code","21c3d1f2":"code","4b820f52":"code","108c32f1":"code","ea10d9db":"code","5a932a95":"code","aab1b525":"code","673398d3":"code","2c6929c9":"code","fdb4d731":"code","1a7b6c4d":"markdown","cd3703cb":"markdown","82153f42":"markdown"},"source":{"082f271a":"!pip install chart-studio","8b0b810d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom plotly import tools\nimport chart_studio.plotly  as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fca0f4f":"\nimport datetime, pytz\n#Function to convert time field from pure number into readable format\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))","f335df57":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)","3a09b613":"data['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='ffill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='ffill', inplace=True)","20e67083":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Hours')\nplt.plot(data.Weighted_Price, '-', label='By Hours')","18bed08b":"### Convert data into monthly data for ARIMA model\ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","3d69f925":"from scipy import stats\nimport statsmodels.api as sm\nimport warnings\nfrom itertools import product\n### Decomposition of the time series\ndecomposition = sm.tsa.seasonal_decompose(data.Weighted_Price)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nfig = plt.figure(figsize=(20,8))\n\nplt.subplot(411)\nplt.plot(data.Weighted_Price, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\n\nfig.suptitle('Decomposition of Prices Data')\nplt.show()","f14d53f2":"# Initial approximation of parameters\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n\n# Model Selection\nresults = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data.Weighted_Price, order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12),enforce_stationarity=False,\n                                            enforce_invertibility=False).fit(disp=-1)\n    except ValueError:\n        #print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","ff600a7e":"# Best Models\nresult_table = pd.DataFrame(results)\nresult_table.columns = ['parameters', 'aic']\nprint(result_table.sort_values(by = 'aic', ascending=True).head())\nprint(best_model.summary())","8faaf539":"df_month2 = data[['Weighted_Price']]\nfuture = pd.DataFrame()\ndf_month2 = pd.concat([df_month2, future])\ndf_month2['forecast'] = best_model.predict(start=0, end=200)\nplt.figure(figsize=(15,7))\ndf_month2.Weighted_Price.plot()\ndf_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\nplt.legend()\nplt.title('Bitcoin Prices (USD) Predicted vs Actuals, by months')\nplt.ylabel('mean USD')\nplt.show()","576af5fc":"# # Prediction\n# df_month2 = df_month[['Weighted_Price']]\n# date_list = [datetime(2017, 6, 30), datetime(2017, 7, 31), datetime(2017, 8, 31), datetime(2017, 9, 30), \n#              datetime(2017, 10, 31), datetime(2017, 11, 30), datetime(2017, 12, 31), datetime(2018, 1, 31),\n#              datetime(2018, 1, 28)]\n# future = pd.DataFrame(index=date_list, columns= df_month.columns)\n# df_month2 = pd.concat([df_month2, future])\n# df_month2['forecast'] = invboxcox(best_model.predict(start=0, end=75), lmbda)\n# plt.figure(figsize=(15,7))\n# df_month2.Weighted_Price.plot()\n# df_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\n# plt.legend()\n# plt.title('Bitcoin exchanges, by months')\n# plt.ylabel('mean USD')\n# plt.show()","b40a940e":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='ffill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='ffill', inplace=True)","5ce51a12":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Hours')\nplt.plot(data.Weighted_Price, '-', label='By Hours')","5660b647":"len(data)","4a09c42b":"data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\nlen(data)\n","1778d554":"data","4fa6b081":"data = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata","b9a50108":"# split data\nsplit_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()\n","a0cda74a":"# Data preprocess\ntraining_set = data_train.values\ntraining_set = np.reshape(training_set, (len(training_set), 1))\ntraining_set","cd467328":"training_set","ac4f6467":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\ntraining_set = sc.fit_transform(training_set)\nX_train = training_set[0:len(training_set)-1]\ny_train = training_set[1:len(training_set)]\n\nX_train.shape","f594176f":"X_train = np.reshape(X_train, (len(X_train), 1, 1)) ## make train set shape from (31243, 1) to (31243,1,1)\nX_train.shape","f360fd5c":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","643aacfa":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Activation\n\n\nmodel = Sequential()\nmodel.add(LSTM(128,activation=\"sigmoid\",input_shape=(1,1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.summary()","12d4d507":"### Train model\nmodel.fit(X_train, y_train, epochs=10, batch_size=50, verbose=2)","88239345":"# Making the predictions\ntest_set = data_test.values\ninputs = np.reshape(test_set, (len(test_set), 1))\ninputs = sc.transform(inputs)\ninputs = np.reshape(inputs, (len(inputs), 1, 1))\npredicted_BTC_price = model.predict(inputs)\npredicted_BTC_price = sc.inverse_transform(predicted_BTC_price)","051bfd4a":"data_test['Weighted_Price_Prediction'] = predicted_BTC_price\ndata_all = pd.concat([data_test, data_train], sort=False)","f37447eb":"_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","53afb80f":"#saving the predicted values in a common data frame for future comparision\nfinal_data = data_all\nfinal_data = final_data.reset_index()\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'lstm'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm']]","1cf5b73e":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='09-01-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('August 2018 Forecast vs Actuals')","47c9f432":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='08-08-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","213d0c05":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nplt.style.use('fivethirtyeight')","630fd2b8":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","936f4df2":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\nsplit_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()\n_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","721fa9b7":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","5e90662c":"X_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","c75e8742":"X_train.head(5)","12439f81":"y_train","4d8813d0":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nmodel =  xgb.XGBRegressor(objective ='reg:linear',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 100)\nmodel.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=50,\n       verbose=False) # Change verbose to True if you want to see it train","1a6566d8":"data_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)","a1049a9a":"#saving the predicted values in a common data frame for future comparision\nfinal_data = data_all\nfinal_data = final_data.reset_index()\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'lstm'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm']]","d17bb390":"final_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'xgboost'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm','xgboost']]","2a159a29":"_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","deb7a771":"mean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","c8d3d036":"mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","78183726":"data_train = data_train.reset_index().rename(columns={'Timestamp':'ds', 'Weighted_Price':'y'})","d049980e":"data_train.head()","22f9cd79":"model = Prophet()\nmodel.fit(data_train)","21c3d1f2":"# Predict on test set with model\ndata_test_fcst = model.predict(df=data_test.reset_index().rename(columns={'Timestamp':'ds'}))","4b820f52":"# Plot the forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = model.plot(data_test_fcst, ax=ax)","108c32f1":"# Plot the components\nfig = model.plot_components(data_test_fcst)","ea10d9db":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = model.plot(data_test_fcst, ax=ax)","5a932a95":"#for comparision of predictions\ndata_fcst = data_test_fcst\ndata_fcst = data_fcst.rename(columns={'ds': 'Timestamp'})\ndata_all = pd.concat([data_fcst, data_train], sort=False)\nfinal_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'yhat': 'prophet'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm','xgboost','prophet']]","aab1b525":"final_data","673398d3":"data_test","2c6929c9":"mean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test_fcst['yhat'])","fdb4d731":"mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test_fcst['yhat'])","1a7b6c4d":"### Prophet","cd3703cb":"## XGBoost","82153f42":"## LSTM"}}