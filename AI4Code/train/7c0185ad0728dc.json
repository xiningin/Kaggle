{"cell_type":{"0acbfe2b":"code","70b2607c":"code","d3af5f43":"code","86b406a8":"code","766c16c6":"code","49f88b1e":"code","db14f163":"code","8b09e110":"markdown","118293e6":"markdown"},"source":{"0acbfe2b":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt","70b2607c":"train = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\noof_woda = pd.read_csv(\"..\/input\/tfkeras-dnn-without-augmentation\/oof.csv\")\noof_wda = pd.read_csv(\"..\/input\/tfkeras-dnn-with-augmentation\/oof.csv\")","d3af5f43":"train = train[train.Cover_Type != 5]","86b406a8":"mapping = {0:0, 1:1, 2:2, 3:4, 4:5, 5:6}\noof_woda = np.array([mapping[i] for i in np.argmax(oof_woda[['prob_0', 'prob_1', 'prob_2', 'prob_3', 'prob_5', 'prob_6']].values, axis=1)])\noof_woda = oof_woda + 1\noof_wda = np.array([mapping[i] for i in np.argmax(oof_wda[['prob_0', 'prob_1', 'prob_2', 'prob_3', 'prob_5', 'prob_6']].values, axis=1)])\noof_wda = oof_wda + 1","766c16c6":"cm = confusion_matrix(train.Cover_Type, oof_woda, labels=np.unique(train.Cover_Type))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()\n\naccuracy = np.sum(train.Cover_Type == oof_woda) \/ len(oof_woda)\nprint(f\"oof accuracy without pseudo-labelling: {accuracy:0.5f}\")","49f88b1e":"cm = confusion_matrix(train.Cover_Type, oof_wda, labels=np.unique(train.Cover_Type))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()\n\naccuracy = np.sum(train.Cover_Type == oof_wda) \/ len(oof_wda)\nprint(f\"oof accuracy with pseudo-labelling: {accuracy:0.5f}\")","db14f163":"cm_wda = confusion_matrix(train.Cover_Type, oof_wda, labels=np.unique(train.Cover_Type))\ncm_woda = confusion_matrix(train.Cover_Type, oof_woda, labels=np.unique(train.Cover_Type))\n\ncm = cm_wda - cm_woda\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()","8b09e110":"Using pseudo-labels seems to improve performances at oof level. How are these extra performances achieved? ","118293e6":"Let's compare how pseudo-labelling augments the performances of the a DNN model by using error analysis. By comparing errors on out-of-fold predictions you can have a clearer idea of what happens."}}