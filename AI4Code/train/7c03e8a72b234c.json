{"cell_type":{"b0a3ee30":"code","4f8cab4f":"code","e637f5a0":"code","3d8336e9":"code","563cd92e":"code","c669b714":"code","41d6410e":"code","0bbf8df5":"code","109c79df":"code","58b9ff12":"code","398fb5ea":"code","c322e885":"code","669875a1":"code","073fa084":"code","0de08711":"code","7ae7457c":"code","1a3c4655":"code","cbc9f393":"code","b979e42d":"code","897b0eb7":"code","fe475091":"code","4d550f1a":"code","6c453dad":"code","a26025d0":"code","f68085d4":"code","8a83c14c":"code","b97ef8ce":"code","fdf7ca34":"markdown","9b22f160":"markdown","d653517c":"markdown","f7e14bf5":"markdown","80ecb760":"markdown","ad22dd99":"markdown","aaa63203":"markdown","0940ec94":"markdown","b213c4a4":"markdown","cd7d7836":"markdown","57685295":"markdown","92d3cdc0":"markdown","50a50005":"markdown","0ead5666":"markdown","962f7fb8":"markdown","518c6a76":"markdown","f5e131e7":"markdown","f7bbb032":"markdown","3c3ccb7a":"markdown","875941d5":"markdown","971415dc":"markdown","03ea2b39":"markdown","d19e91dd":"markdown","ef8dfc65":"markdown","69655dc0":"markdown","74a3b1e6":"markdown","3a4b3359":"markdown","db6d4eab":"markdown","4a87a97e":"markdown","8d54cb59":"markdown","d5530c1e":"markdown","76268066":"markdown","026fce94":"markdown","163919b5":"markdown","8ff476fb":"markdown","78c48ca9":"markdown","38bee06a":"markdown","4478a2d1":"markdown","2fdcad8c":"markdown","1babbd93":"markdown","bc63a77d":"markdown","8917d3fb":"markdown","50d1f355":"markdown","c24126fc":"markdown","d55fc7ca":"markdown","3c27c809":"markdown","f73b8220":"markdown","0dedd1ff":"markdown","97de1cdf":"markdown","5eeaa437":"markdown","400f5bfc":"markdown","13cddd1c":"markdown","32ca07f1":"markdown","27855d9d":"markdown","36dd854e":"markdown","094c1611":"markdown","a9be0f70":"markdown","256deb07":"markdown","779f0107":"markdown","bebf5fdf":"markdown"},"source":{"b0a3ee30":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom scipy.stats import norm\nfrom scipy.stats import probplot ","4f8cab4f":"ais = pd.read_csv(\"\/kaggle\/input\/australian-athletes-data-set\/ais.csv\")","e637f5a0":"hist_data = [ais[ais[\"sex\"]==\"m\"][\"rcc\"], ais[ais[\"sex\"]==\"f\"][\"rcc\"]]\ngroup_labels = [\"male\", \"female\"]\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,show_rug=False)\nfig['layout'].update(title={\"text\" : 'Distribution of rcc count based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"rcc\",yaxis_title=\"probability density\")\nfig.update_layout(width=500,height=500)\nfig","3d8336e9":"hist_data = [ais[ais[\"sex\"]==\"m\"][\"wcc\"], ais[ais[\"sex\"]==\"f\"][\"wcc\"]]\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,show_rug=False)\nfig['layout'].update(title={\"text\" : 'Distribution of wcc count based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"wcc\",yaxis_title=\"probability density\")\nfig.update_layout(width=500,height=500)","563cd92e":"hist_data = [ais[ais[\"sex\"]==\"m\"][\"bmi\"], ais[ais[\"sex\"]==\"f\"][\"bmi\"]]\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,show_rug=False)\nfig['layout'].update(title={\"text\" : 'Distribution of Body mass index(BMI) based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"bmi\",yaxis_title=\"probability density\")\nfig.update_layout(width=500,height=500)","c669b714":"hist_data = [ais[ais[\"sex\"]==\"m\"][\"pcBfat\"], ais[ais[\"sex\"]==\"f\"][\"pcBfat\"]]\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,show_rug=False)\nfig['layout'].update(title={\"text\" : 'Distribution of percent Body fat(pcBfat) based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"pcBfat\",yaxis_title=\"probability density\")\nfig.update_layout(width=500,height=500)","41d6410e":"hist_data = [ais[ais[\"sex\"]==\"m\"][\"lbm\"], ais[ais[\"sex\"]==\"f\"][\"lbm\"]]\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,show_rug=False)\nfig['layout'].update(title={\"text\" : 'Distribution of lean body mass(lbm) based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"lbm\",yaxis_title=\"probability density\")\nfig.update_layout(width=500,height=500)","0bbf8df5":"counts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"m\"]['rcc'],bins = 100, density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"male\"))\ncounts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"f\"]['rcc'],bins = 100,density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"female\"))\nfig['layout'].update(title={\"text\" : 'CDF of rcc based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"rcc\",yaxis_title=\"probability\")\nfig.update_layout(width=500,height=500)","109c79df":"counts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"m\"]['pcBfat'],bins = 200, density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"male\"))\ncounts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"f\"]['pcBfat'],bins = 200,density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"female\"))\nfig['layout'].update(title={\"text\" : 'CDF of pcBfat based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"pcBfat\",yaxis_title=\"probability\")\nfig.update_layout(width=500,height=500)","58b9ff12":"counts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"m\"]['lbm'],bins = 200, density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"male\"))\ncounts, bin_edges = np.histogram(ais[ais[\"sex\"]==\"f\"]['lbm'],bins = 200,density = True)\npdf = counts\/(sum(counts))\ncdf = np.cumsum(pdf)\nfig.add_trace(go.Scatter(x=bin_edges[1:], y=cdf,mode='lines',name = \"female\"))\nfig['layout'].update(title={\"text\" : 'CDF of lbm based on Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"lbm\",yaxis_title=\"probability\")\nfig.update_layout(width=500,height=500)","398fb5ea":"fig = ff.create_distplot([ais[\"ht\"]], [\"ht\"],show_hist=False,show_rug=False)\nfig['layout'].update(title={'text':'Distribution of height','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"height\",yaxis_title=\"probability\")\nfig.update_layout(showlegend = False,width=500,height=500)\nfig","c322e885":"fig = ff.create_distplot([ais[\"wt\"]], [\"wt\"],show_hist=False,show_rug=False)\nfig['layout'].update(title={'text':'Distribution of weight','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"weight\",yaxis_title=\"probability\")\nfig.update_layout(showlegend = False,width=500,height=500)\nfig","669875a1":"from scipy.stats import skew\nprint(\"Skewness of height parameter : \", skew(ais[\"ht\"]))\nprint(\"Skewness of weight parameter : \", skew(ais[\"wt\"]))","073fa084":"fig = ff.create_distplot([ais[\"ht\"]], [\"ht\"],show_hist=False,show_rug=False,curve_type=\"normal\")\nfig['layout'].update(title={'text':'Distribution of height','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"height\",yaxis_title=\"probability\")\nfig.update_layout(showlegend = False,width=500,height=500)\nfig","0de08711":"from scipy.stats import norm\nprint(\"% of atheletes heights falling below 165 cm is : \", norm.cdf(165, loc = np.mean(ais[\"ht\"]), scale = np.std(ais[\"ht\"])))\nprint(\"% of atheletes heights falling between 165 and 185 cm is : \", norm.cdf(185, loc = np.mean(ais[\"ht\"]), scale = np.std(ais[\"ht\"])) - norm.cdf(165, loc = np.mean(ais[\"ht\"]), scale = np.std(ais[\"ht\"])))\nprint(\"% of atheletes heights falling above 185 cm is : \", 1- norm.cdf(185, loc = np.mean(ais[\"ht\"]), scale = np.std(ais[\"ht\"])))","7ae7457c":"from scipy.stats import probplot\nqq = probplot(ais[\"wt\"], dist='norm')\nx = np.array([qq[0][0][0],qq[0][0][-1]])\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=qq[0][0],y=qq[0][1], mode = 'markers',showlegend=False))\nfig.add_trace(go.Scatter(x=x,y=qq[1][1] + qq[1][0]*x,showlegend=False,mode='lines'))\nfig['layout'].update(title={'text':'Q-Q plot of height','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"Theoretical quantiles\",yaxis_title=\"Sample quantiles\")\nfig.update_layout(width=500,height=500)\nfig","1a3c4655":"from scipy.stats import shapiro\nprint(\"p-value obtained from Shapiro-Wilk test : \", shapiro(ais[\"ht\"])[1])","cbc9f393":"from scipy.stats import kstest\nprint(kstest(ais[\"ht\"],\"norm\", args = (np.mean(ais[\"ht\"]), np.std(ais[\"ht\"]))))","b979e42d":"print(\"mean:\",np.mean(ais[\"ht\"]))\nnp.std(ais[\"ht\"])","897b0eb7":"def Chebyshev(low_limit, mean, std):\n    k = (mean - low_limit) \/ std\n    #k = (np.mean(data) - low_limit) \/ np.std(data) \n    return (1-(1\/(k**2)))","fe475091":"print(\"% of athelete having height between 160.68 and 199.52 cm : \", Chebyshev(160.68,np.mean(ais[\"ht\"]),np.std(ais[\"ht\"])))\nprint(\"% of athelete having height between 150.97 and 209.23 cm : \", Chebyshev(150.97,np.mean(ais[\"ht\"]),np.std(ais[\"ht\"])))","4d550f1a":"fig = ff.create_distplot([ais[\"ferr\"]], [\"ferr\"],show_hist=False,show_rug=False)\nfig['layout'].update(title={'text':'Distribution of height','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"height\",yaxis_title=\"probability\")\nfig.update_layout(showlegend = False,width=500,height=500)\nfig","6c453dad":"qq = probplot(ais[\"ferr\"], dist='lognorm',sparams=(1,0))\nx = np.array([qq[0][0][0],qq[0][0][-1]])\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=qq[0][0],y=qq[0][1], mode = 'markers',showlegend=False))\nfig.add_trace(go.Scatter(x=x,y=qq[1][1] + qq[1][0]*x,showlegend=False,mode='lines'))\nfig['layout'].update(title={'text':'Q-Q plot of height for log-normality','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"Theoretical quantiles\",yaxis_title=\"Sample quantiles\")\nfig.update_layout(width=500,height=500)\nfig","a26025d0":"from scipy.stats import binom\nn= 50 #total number of fixed trials\np= 0.1237 #probability of success\nprint(\"probability that exactly two atheletes play basketball : \", binom.pmf(2,50,0.1237))\nprint(\"probability that exactly at most 10 atheletes play basketball : \", binom.cdf(10,50,0.1237))\nprint(\"probability that exactly at least 20 atheletes play basketball : \", np.round((1- binom.cdf(20,50,0.1237)) + binom.pmf(20,50,0.1237)))","f68085d4":"n = 50\np = 0.1237\nx1 = np.arange(0, 12,2)\ny1 = binom.pmf(x1, n, p)\nfig = go.Figure([go.Bar(x=x1, y=y1)])\nfig['layout'].update(title={\"text\" : 'PMF - Binomial Distribution','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"# of successes in 50 trails\",yaxis_title=\"prob.\")\nfig.update_layout(width=500,height=500)\nfig","8a83c14c":"fig = go.Figure([go.Bar(x=ais[\"sex\"].value_counts().index, y=ais[\"sex\"].value_counts().values)])\nfig['layout'].update(title={\"text\" : 'Distribution of Sex','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"Sex\",yaxis_title=\"count\")\nfig.update_layout(width=500,height=500)\nfig","b97ef8ce":"hist_data = [ais[((ais[\"wcc\"]>=7.70) & (ais[\"wcc\"]<=9.90)) | ((ais[\"wcc\"]>=4.40) & (ais[\"wcc\"]<5.50))][\"wcc\"]]\ngroup_labels = [\"wcc\"]\nfig = ff.create_distplot(hist_data, group_labels, bin_size=1.10,show_curve=False, show_rug = False,histnorm = \"probability\")\nfig['layout'].update(title={\"text\" : 'Distribution of wcc','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'}, xaxis_title=\"wcc\",yaxis_title=\"prob.\")\nfig.update_layout(width=500,height=500)\nfig","fdf7ca34":"#### b. Shapiro-Wilk test\n\nIt's a numeric test to check whether a sample is normally distributed or not. It is a hypothesis based test where null and alternate hypothesis is defined as below - \n\n$H_0$(Null Hypothesis) - Sample is normally distributed\n\n$H_{1}$(Alternate Hypothesis) - Sample is not normally distributed\n\nThis, if the p value obtained for the W statistic is less than significance level($\\alpha$) then null hypothesis is rejected On the other hand, if the p value is greater than $\\alpha$ then we failed to reject null hypothesis.","9b22f160":"Let's plot the distribution of **ferr** feature. ","d653517c":"Here, height is slightly skewed to the left whereas weight is slightly to the right.","f7e14bf5":"#### Importing necessary libraries and loading the data","80ecb760":"#### c. Analysing bmi","ad22dd99":"From the curves we can easily observe that height and weight are almost normally distributed but there exist a small amount of asymmetricity which can be measured through **skewness**.  \n\n**skewness** - it is a statistical parameter to measure asymmetricity about the mean in a distribution of random variable. This paramtere value can be positive, negative or undefined. A negative value indicates data is left skewed whereas a positive value indicates data is right skewed.","aaa63203":"### Univariate analysis using CDF","0940ec94":"So there is 50% chance that a random athelete will be man, similarly therte is 50% chance for a random athelete to be female. ","b213c4a4":"#### Conclusion\n\nThe best predictor based on misclassification error among rcc, pcBfat, lbm is lbm. ","cd7d7836":"#### a. QQ Plot\n\nIt is a graphical method for comparing two probability distributions by plotting their quantiles against each other. For normality test one distribution is w.r.t. given sample that we want to test and the another distribution is the standard normal distribution.\nThere are builtin methods available in statsmodels and scipy package to plot Q-Q plot. We can also plot it manually. \n\n**Steps for plotting Q-Q plot manually**\n\nAssume X is a random variable representing the given sample and Y$\\backsim(0,1)$ is a random variable that follows standard normal distribution with mean($\\mu$) equals to 0 and standard deviation($\\sigma$) equals to 1.\n- Compute all the percentiles of X. Say $x_{1}^{'}$, $x_{2}^{'}$, $x_{3}^{'}$...............$x_{100}^{'}$. These percentiles are also known as sample quantiles.\n- Compute all the percentiles of Y. Say $y_{1}^{'}$, $y_{2}^{'}$, $y_{3}^{'}$...............$y_{100}^{'}$. These percentiles are also known as theoritical quantiles.\n- Plot each percentile of X against the same percentile of Y. i.e. 2d points are formed as ($x_{1}^{'}$, $y_{1}^{'}$), ($x_{2}^{'}$,$y_{2}^{'}$), ......... ($x_{100}^{'}$, $y_{100}^{'}$).\n- If all the points lie on a straight line(reference line $y=x$) then X follows a normal distribution.  \n","57685295":"From the CDF curves we can observe that upto 64.10(condition value from built model) 12.74% of the male are misclassified as female, similarly 7% of the female  are misclassified as male above 64.10. \n\nSo the total misclassification error = 12.74 + 7 = 19.74% ","92d3cdc0":"From the CDF curves we can observe that upto 11.80(condition value from built model) 18% of the female are misclassified as male, similarly 14.70% of the male  are misclassified as female above 11.80. \n\nSo the total misclassification error = 18 + 14.70 = 32.70% ","50a50005":"#### c. Analysing lbm","0ead5666":"All the above simple models were leading to some sort of misclassification but using **PDF** we are unable to compute level of misclassification. The magnitude of misclassification error can be obtained using **CDF** curve.\n","962f7fb8":"### Properties of Normal Distribution\n\n![image.png![image.png](attachment:image.png)](attachment:image.png)\n\n- Mean = median = mode\n- Symmetric in nature\n- Total area under the curve  = 1\n- As we move away from the mean, the PDF value decreases\n- As the variance increases the distribution spread also increases and the curve becomes more wider \n- 68-95-99.7 Empirical rule\n    - 68.2% of the data lies within one standard deviation away from the mean\n    - 95% of the data lies within two standard deviation away from the mean\n    - 99.7% of the data lies within three standard deviation away from the mean","518c6a76":"## 1. Normal distribution","f5e131e7":"Normal(Guassian) distribution is a bell shaped curve, its distribution pattern is observed in most of the natural phenomena such as height, weight, marks etc. It has two parameters - mean($\\mu$) and standard deviation($\\sigma$). \n\nPDF of a random variable which follows normal distribution is given as \n\n$$P(X=x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^-\\frac{(x-\\mu)^2}{2\\sigma^2}$$\n\n","f7bbb032":"### Normality test\n\nNormality test are used to determine whether the data is normally distribution or not OR whether the sample data comes from normally distributed population or not.    \nThere are various kind of graphical and numeric tests to determine this.\n- Graphical tests\n    - Histogram\/density plot\n    - Q-Q plot\n- Numeric tests\n    - Shapiro-Wilk test\n    - Kolmogorov-Smironv test","3c3ccb7a":"A simple model(as shown below) can be built using **lbm** but agian it misclassifies the male points below 64.10 as female and the female points above 64.10 as male.\n``` \nif(lbm<=64.10):\n    sex = \"female\"\nelse:\n    sex = \"male\"\n```","875941d5":"### Univariate analysis using pdf","971415dc":"Here for $\\alpha$ = 0.05, obtained p value(0.2120) > $\\alpha$ , so we failed to reject null hypothesis i.e height came from a normally distributed population.","03ea2b39":"From the underlying dataset, we can observe that only 12.37%(25\/202) atheletes play Basketball, Now if we choose a random sample of 50 atheletes then \n- What is the probability that exactly two atheletes play basketball?\n- What is the probability that at most 10 atheletes play basketball?\n- What is the probability that at least 20 atheletes play basketball?\n\nSince all the above questions hold a varying number of successes(2,10,20) from fixed number of trails(50) with p = 0.1237 so binomial distribution can be used to answer these questions.","d19e91dd":"A simple model(as shown below) can be built using **pcBfat** but agian it leads to some misclassification.\n``` \nif(pcBfat<=11.80):\n    sex = \"male\"\nelse:\n    sex = \"female\"\n```","ef8dfc65":"#### b. Analysing wcc","69655dc0":"From the plot can we assume height feature follows normal distribution?\n\nHere, most of the points fall about the reference line so our assumption seems to fairly safe.","74a3b1e6":"Let's try to build a simple classification model to classify **Sex** of an athelete using one variable at a time. For this purpose, probability density function(PDF) is very helpful to assess importance of a continuous variable.","3a4b3359":"If we know in advance that a variable follows normal distribution then we can easily tell many properties of the variable without looking at the actual data.\n","db6d4eab":"**Rules of thumb to determine most significant features using PDF :-   **\n\n- Higher the seperation among pdf curves for different classes of target variable better the classification\n![image.png![image.png](attachment:image.png)](attachment:image.png)","4a87a97e":"## 2. LogNormal distribution \n\nA random variable X is said to be lognormally distributed if natural logarithm of X is normally distributed. In other words X$\\backsim LogNormal$($\\mu$,$\\sigma$) if $\\log{(X)}$ is normally distributed. \n\nPDF of a log normally distributed random variable is given as \n\n$$P(X=x) = \\frac{1}{x\\sqrt{2\\pi}\\sigma}e^-\\frac{(\\log{x}-\\mu)^2}{2\\sigma^2}$$\n","8d54cb59":"## 4. Uniform distributions\n\nBased on the type of random variable there are two types of uniform distributions.\n1. Discrete uniform distribution for discrete random variable\n2. Continuous uniform distribution for continuous random variable","d5530c1e":"Here for $\\alpha$ = 0.05, obtained p value(0.7958) > $\\alpha$ , so we failed to reject null hypothesis i.e height follows normal distribution.","76268066":"Let's try to answer following questions using Chebyshev inequality.\n- What % of athelete has height between 160.68 and 199.52 cm?\n- What % of athelete has height between 150.97 and 209.23 cm?","026fce94":"Since the pdf curves of **bmi** for both the gender categories are overlapping each other so the simple classfication model will have a high level of missclassification. ","163919b5":"### Preface\n\nAs the name suggests probability distribution is the distribution of total probability across all the possible outcomes of a random variable.\nFor example assume a bank provides four different kind of debit cards(Classic, Silver, Gold, Platinum) to its customers. Each of these debit cards have specific values for different parameters like maximum transaction amount, reward points, annual service cost, maximum purchase amount etc.\nThe bank provides debit cards based on the customer features like age, educational status, Profession, salary, size of family, place of residence etc.\n\nNow assume a software professional opens account in the bank then what kind of debit card should be provided to him. After analysing all the customer features the bank comes with a probability table as shown below.\n\n|  Classic  |  Silver  |  Gold  |  Platinum  |\n|------|------|------|------|------|\n|  0.18 | 0.32| 0.42 | 0.08 |\n\nAbove table represents probability distribution of debit card where total probability(1.0) is distributed across all the four type of debit cards with their corresponding probability values.\n\nProbability distribution is essential in -\n- Data Analysis \n- Decision making","8ff476fb":"### 4.a Discrete uniform distribution\n\nA discrete uniform distribution is a symmetric distribution with following properties. \n\n- It has fixed number of outcomes.\n- All the outcomes are equally likely to occur.\n\nIf a random variable $X$ follows discrete uniform distribution and it has $k$ discrete values say $x_{1}$, $x_{2}$, $x_{3}$,.....$x_{k}$, then PMF of $X$ is given as \n$$P(X=x_{k}) = \\frac{1}{k}$$\n","78c48ca9":"#### a. Analysing rcc","38bee06a":"#### a. Analysing rcc","4478a2d1":"## Types of Probability distribution\n\nBased on the type of a random variable(discrete or continuous) there are two types of Probability distributions - Discrete and Continuous. In this course we are going to discuss following probability distributions.\n1. Discrete probability distribution\n    - Discrete uniform \n    - Binomial distribution\n2. Continuous probability distribution\n    - Continuous uniform\n    - Normal distribution\n    - Lognormal distribution","2fdcad8c":"- Overlapping **PDF** curves lead to worst classification \n![image.png![image.png](attachment:image.png)](attachment:image.png)\n\nNow let's perform univariate analysis on a subset of features using **PDF**.","1babbd93":"### Normality check of height, weight column through visualization and skewness","bc63a77d":"Since the pdf curves of **wcc** for both the gender categories are overlapping each other so it is very hard to come up with a condition for simple classfication.  ","8917d3fb":"From the given dataset, we can observe that **sex** feature has two possible values male and female. There is almost equal number of male(100) and female(102) atheletes so if we assume that **sex** feature strictly follows uniform distribution then \n$$P(X=male) = P(X=female) =  \\frac{1}{2} = 0.5$$","50d1f355":"#### Comparing distribution of ferr against log normal distribution using QQ plot\n\nQQ plot can be used to compare two probability distributions by plotting their quantiles against each other.","c24126fc":"Let's consider a subset of data having wcc values between 4.40 and 5.40 for one set and between 7.70 and 9.90 for another set. Distribution of this subset of data is as shown below where probability is same across all three bins of continuous range.  ","d55fc7ca":"### 4.b Continuous uniform distribution\n\nIf a continuous uniformly distributed random variable $X$ is defined in a and b then PDF of $X$ is given as \n$$P(X=x_{k}) = \\frac{1}{b-a}$$\n","3c27c809":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python\/","f73b8220":"If height feature had perfectly followed normal distibution then above questions would have easily answered using CDF of normal distribution","0dedd1ff":"#### c. Kolmogorov\u2013Smirnov(K-S) test \n\nK-S test provides a way to - \n- check whether a sample is drawn from a reference probability distribution or not(one-sample K\u2013S test)\n- check whether two samples are drawn from the same distribution or not(two-sample K\u2013S test)\n\nIt is a hypothesis based test where null and alternate hypothesis for one-sample K\u2013S test is defined as below - \n\n$H_{0}$(Null Hypothesis) - Sample follows the reference distribution\n\n$H_{1}$(Alternate Hypothesis) - Sample does not follow the reference distribution","97de1cdf":"### Chebyshev inequality\n\nBy following 68-95-99.7 Empirical rule of a normally distributed dataset, we know that what % of data lies within $k$ standard deviation from the mean but what if the data does not follow normal distribution? OR how to know what fraction of data lies within $k$ standard deviation from the mean for any random distribution?\n\nTo answer such questions pertaining to dispersion of data for a random distribution Chebyshev inequality is used.\n\n**Chebyshev inequality** states that no more than $\\frac{1}{k^2}$ fraction of data falls more than $k$ standard deviations away from the mean $$P(\\left\\lvert{X-\\mu}\\right\\rvert>=k\\sigma) <= \\frac{1}{k^2}$$\n\n$$P(X>=\\mu + k\\sigma \\;\\;|\\;\\;X<=\\mu - k\\sigma) <= \\frac{1}{k^2}$$\n\nin simplifed terms\n$$P(\\mu-k\\sigma <= X <= \\mu-k\\sigma) > 1- \\frac{1}{k^2}$$\n\nIn other words, at least $(1- \\frac{1}{k^2})$ fraction of data falls within $k$ standard deviations from the mean for a sample with finite mean and finite standard deviation.\n\nLet's explore the inequality more with a few values of $k$.\n\n- For $k$ = 2, $(1- \\frac{1}{k^2})$ = 0.75 i.e. at least 75% of the data falls within two standard deviations of the mean for any random distribution.\n- For $k$ = 3, $(1- \\frac{1}{k^2})$ = 0.89 i.e. at least 89% of the data falls within three standard deviations of the mean for any random distribution.\n","5eeaa437":"#### b. Analysing pcBfat","400f5bfc":"From the CDF curves we can observe that upto 4.68(condition value from built model) 12.74% of the male are misclassified as female, similarly 19% of the female  are misclassified as male above 4.68. \n\nSo the total misclassification error = 12.74 + 19 = 31.74% ","13cddd1c":"Let's perform data analysis and decison making on the underlying Australian athletes dataset.","32ca07f1":"#### d. Analysing pcBfat","27855d9d":"Now let's try to answer the below questions.\n- What % of athelete has height <=165 cm?\n- What % of athelete has height between 165 and 185 cm?\n- What % of athelete has height >185 cm?\n\nFor a random variable with finite mean and standard deviation, these above questions can be easily answered using **Chebyshev's inequality**.  \n\nAssume for a moment that height strongly follows normal distibution then its distribution would have looked like below - ","36dd854e":"## 3. Binomial distribution\n\nBinomial distribution is a discrete probability distribution for obtaining exactly $k$ successes out of $n$ Bernoulli trails. \n\nCharacteristics of a Bernoulli trails - \n- Each trail has only two possible outcomes - success and failure.\n- Total number of trails are fixed.\n- Probability of success and failure remains same through out all the trails.\n- The trails are independent of each other. \n\nBinomial distribution is a way of calculating the probability of $k$ successes from $n$ Bernoulli trails.\n\nThe PMF of a binomial random variate is given as \n\n\\begin{equation*}\nP(X=k)   = {n \\choose k} p^k (1-p)^{ n-k}\n\\end{equation*}\n\nwhere p = probability of success and (1-p) = probability of failure\n\nk = number of successes and (n-k) = number of failures\n","094c1611":"We can observe that **ferr** feature follows some sort of log normal distribution where the right portion has long tall than the left one. ","a9be0f70":"Similarly, we can consider other variables to build a simple classification model like this. To find out the most significant variable, univariate analysis using pdf can be performed.   ","256deb07":"#### e. Analysing lbm","779f0107":"From the above QQ plot we can observe that most of the points are not closely residing on the reference line so ferr feature does not strictly follow log normal distribution. ","bebf5fdf":"Since the **PDF**s of **rcc** across both the gender categories are slightly overlapping each other so it is not possible to **correctly** classify all the points based on some condition. A simple model can be built by considering the intersection point of both the **PDF**s  \n\n``` \nif(rcc<=4.68):\n    sex = \"female\"\nelse:\n    sex = \"male\"\n```\n    \nFrom **PDF** curve we can observe that upto 4.68(value at intersection) more number of points belong to female category than man, similarly after 4.68 there are more number of male points. But this model leads to misclassification for the points belonging to female category after 4.68 and similary for the points belonging to male category before 4.68. "}}