{"cell_type":{"07fa9fed":"code","8a2bfe6c":"code","ad3f3f97":"code","fc484dec":"code","e9ae35de":"code","d1ef51de":"code","fdf54b58":"code","cb429f2f":"code","4ff4a6b5":"code","81ccd5bc":"code","fa287b57":"code","c53bfa2c":"code","f739bdf6":"code","caeefc47":"code","78c8240b":"code","028fe659":"code","953415a3":"code","6a263ad9":"code","e6b427ef":"code","4f7fca69":"code","cb5ea4f6":"code","667ce50b":"markdown"},"source":{"07fa9fed":"import pickle\nimport torch\nimport numpy as np\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt","8a2bfe6c":"# instructed method to import data\ndef unpickle(file):\n    with open(file, 'rb') as f:\n        pdict = pickle.load(f, encoding='bytes')\n    return pdict","ad3f3f97":"# assigning to qmnist\nqmnist = unpickle(\"..\/input\/qmnist-the-extended-mnist-dataset-120k-images\/MNIST-120k\")","fc484dec":"qmnist","e9ae35de":"# using to transform arrays to tensors\npreprocessing = transforms.Compose([transforms.ToTensor()])","d1ef51de":"data = qmnist['data']\n# make pixel values fall between 0 and 1\ndata = data\/255\nlabels = qmnist['labels']\n# want labels horizontally stacked\nlabels = labels.reshape(1,-1)\n# applt tensor transformation\nlabels = preprocessing(labels)\n# verifying array changed to tensor \nlabels[0][0]","fdf54b58":"# putting feature and target into same array\ndataset = [[data[index], [labels[0][0][index]]] for index in range(0, 119999)]\ndataset[0]","cb429f2f":"# manual train test split (test size of 0.2)\ntrain_split = len(dataset)-len(dataset)\/5\ntrain = dataset[:int(train_split)]\ntest = dataset[int(train_split):]","4ff4a6b5":"train[10]","81ccd5bc":"# shuffling training set with a batch size of 10\ntrainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\ntestset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)","fa287b57":"trainset","c53bfa2c":"int(labels[0][0][0])","f739bdf6":"# checking distribution of labels\ntotal = 0\ncount = 0\n\ndict_count = {x:0 for x in range(0, 10)}\n\nfor label in labels[0][0]:\n    dict_count[int(label)] += 1\n    total += 1\n    \nprint(dict_count)","caeefc47":"# defining network\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(28*28, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 64)\n        self.fc4 = nn.Linear(64, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        \n        return F.log_softmax(x, dim=1)\n    \nnet = Net().double()\nnet","78c8240b":"# using crossentropy as this is a classification problem\nloss_function = nn.CrossEntropyLoss()\n# setting learning rate and parameters through Adam optimizer\noptimizer = optim.Adam(net.parameters(), lr=0.001)","028fe659":"# checking batch sizes worked\nfor data in trainset:\n    print(data)\n    break","953415a3":"for epoch in range(3): # 3 epochs\n    for data in trainset:\n        X, y = data  # X: features, y: targets (in batches of 10)\n        net.zero_grad()  # sets gradients to 0 before loss calc\n        output = net(X.view(-1,28*28))  # pass in the reshaped batch\n        loss = F.nll_loss(output, y[0])  # compare and calculate loss\n        loss.backward()  # apply loss back through network\n        optimizer.step()  # optimize weights with loss\n    print(loss)","6a263ad9":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    for data in testset:\n        X, y = data\n        output = net(X.view(-1, 28*28))\n        \n        for idx, i in enumerate(output):\n            if torch.argmax(i) == y[0][idx]:\n                correct += 1\n            total += 1\n            \nprint(f\"Accuracy: {round(correct\/total*100, 3)}\")","e6b427ef":"# running a prediction\nplt.imshow(X[0].view(28, 28))\nplt.show()","4f7fca69":"net(X[0].view(-1, 28*28))[0] #getting array of output values","cb5ea4f6":"print(torch.argmax(net(X[0].view(-1, 28*28))[0])) #display index with greatest value","667ce50b":"## New to data science (especially pytorch) so I probably don't have the best solution, feedback would be appreciated"}}