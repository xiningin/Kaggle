{"cell_type":{"b7d67434":"code","44e9df43":"code","f76ec18e":"code","584e0199":"code","4ddb2246":"code","c7b7d2c7":"code","c7356432":"code","443f2306":"code","68117a2b":"code","e5b22d59":"code","c9754f90":"code","d398fe6a":"code","08b77e57":"code","0d0d6981":"code","01360cf2":"code","6f5386ce":"code","920a861e":"code","29b13545":"code","46a512c6":"code","81ff85f8":"code","7696c9f5":"code","df851e4b":"code","5dbe14f7":"code","8b35b81c":"code","c684c5b0":"code","b9d78e30":"code","137fa80c":"code","bd8733c8":"code","5522b613":"code","df195674":"code","b9a229c2":"code","7bf69c63":"code","fac32408":"code","a2f5e70a":"code","ec5e5d7a":"code","7860dec5":"code","ed0f2088":"code","246bd597":"code","d04fc77a":"code","73d603b1":"code","ab40d320":"code","14b6ae0c":"code","89b375cb":"code","9bfeb558":"code","4e459997":"code","2c3f11a8":"code","ae888630":"code","eec7c30a":"code","3a0af991":"code","6db320cc":"code","4e9a478b":"code","e7792ab3":"code","1651b082":"code","5ab91fa8":"code","e2b78450":"code","bf384d84":"code","e464b7d1":"code","6d7f8acd":"code","42df5386":"markdown","44c91f2e":"markdown","241e8f9b":"markdown","ad20188c":"markdown","a91b8688":"markdown","0882f7e5":"markdown","7e01aea4":"markdown","4c2ba6dc":"markdown","af244e20":"markdown","7005df33":"markdown","e9b2c008":"markdown","1f4a6e76":"markdown","94c39b5c":"markdown","c2f5db0b":"markdown","912e03ab":"markdown","d264611f":"markdown","d7ac13eb":"markdown","d541a235":"markdown","969f1bee":"markdown","48b1774e":"markdown","366584e3":"markdown","b15a4c61":"markdown","acafc2fd":"markdown"},"source":{"b7d67434":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn as sk\n\npd.reset_option(\"^display\")\npd.options.mode.chained_assignment = None","44e9df43":"test = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')\ntrain = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')","f76ec18e":"titanic = pd.concat([train, test])\ntrain_index = train.index\ntest_index = test.index","584e0199":"print (f\"Total no of rows: {titanic.shape[0]}\")\nprint(\"\")\nmissing = titanic.isna()\nfor col in missing.columns:\n    if missing[col].sum() > 0:\n        print(\"Column:\", col)\n        print(\"num of missing values:\", missing[col].sum())\n        print(\"\")","4ddb2246":"titanic['Deck'] = titanic['Cabin'].str.slice(0,1)\ntitanic.drop(['Cabin'], axis=1, inplace=True)\ntitanic['Deck'] = titanic['Deck'].fillna(\"N\")","c7b7d2c7":"titanic.head()","c7356432":"Deck_dummy = pd.get_dummies(titanic['Deck'], prefix='Deck')\n\nfor column in Deck_dummy.columns:\n    titanic[column] = Deck_dummy[column]\ntitanic.drop('Deck',axis=1,inplace=True)","443f2306":"titanic.head()","68117a2b":"corr = titanic.corr()\ncorr['Survived'].sort_values(ascending=False)","e5b22d59":"#let's see what else having no cabin data is related to\ncorr['Deck_N']","c9754f90":"titanic['Deck_AFGT'] = titanic[['Deck_A','Deck_F','Deck_G','Deck_T']].max(axis=1)\ntitanic.drop(['Deck_A','Deck_F','Deck_G','Deck_T'],axis=1,inplace=True)\n\ntitanic['Deck_DE'] = titanic[['Deck_D','Deck_E']].max(axis=1)\ntitanic.drop(['Deck_D','Deck_E'],axis=1,inplace=True)","d398fe6a":"titanic.head()","08b77e57":"Sex_dummy = pd.get_dummies(titanic['Sex'])\n\ntitanic['female'] = Sex_dummy['female']\ntitanic['male'] = Sex_dummy['male']\ntitanic.drop(['Sex'], axis=1, inplace=True)","0d0d6981":"#have observed the letters in some of the tickets provides a clue to the place of embarkment\ntitanic[['Embarked','Ticket']].head()","01360cf2":"titanic[['Embarked','Ticket']].loc[titanic['Embarked'].isnull() == True]","6f5386ce":"titanic[['Embarked','Ticket']].loc[titanic['Ticket'] == '113572']","920a861e":"titanic['Embarked'].value_counts()","29b13545":"#Southhampton was by far the most embarked place\ntitanic['Embarked'].replace(np.nan, 'S',inplace=True)\ntitanic[['Embarked','Ticket']].loc[titanic['Ticket'] == '113572']","46a512c6":"#as there is only one missing value, keep it simple and just take the average for the passenger class\ntitanic[['Pclass','Fare']].loc[titanic['Fare'].isnull() == True]","81ff85f8":"titanic[['Fare']].loc[titanic['Pclass'] == 3].mean()","7696c9f5":"titanic['Fare'].loc[1044] = 13.3\ntitanic['Fare'].loc[1044]","df851e4b":"Embarked_dummy = pd.get_dummies(titanic['Embarked'],prefix='Embarked')\n\nfor column in Embarked_dummy.columns:\n    titanic[column] = Embarked_dummy[column]\ntitanic.drop('Embarked',axis=1,inplace=True)","5dbe14f7":"titanic.head()","8b35b81c":"corr = titanic.corr()","c684c5b0":"corr['Age'].sort_values(ascending=False)","b9d78e30":"pd.options.display.max_rows = 10\ntitanic[['Name','Age']]","137fa80c":"#see if we can also use the titles (Mr\/Mrs\/Miss,etc) to help predict age\n#extract titles\npd.reset_option(\"^display\")\n\nget_title = lambda name : name.split(\", \", 2)[1].split(\".\")[0]\n\ntitanic['Title'] = titanic['Name'].apply(get_title)","bd8733c8":"titanic[['Name','Title']]","5522b613":"titanic[['Title']].value_counts()","df195674":"titanic['Title'].unique()","b9a229c2":"#merge Ms with Miss (arbitrary choice)\ntitanic['Title'].replace('Ms','Miss',inplace=True)\n\n#merge titles with very few results into \"other\"\nother_titles = ['Col','Mlle','Major','Major','Don','Dona','the Countess','Jonkheer','Lady','Sir','Mme','Capt']\ntitanic['Title'].replace(other_titles,'Other',inplace=True)","7bf69c63":"titanic.drop('Name',axis=1,inplace=True)\ntitanic","fac32408":"titanic['Title'].unique()","a2f5e70a":"Title_dummy = pd.get_dummies(titanic['Title'],prefix='Title')\n\nfor column in Title_dummy.columns:\n    titanic[column] = Title_dummy[column]\ntitanic.drop('Title',axis=1,inplace=True)","ec5e5d7a":"titanic","7860dec5":"age = titanic.copy()\nage_train = age[['Pclass','Age','Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Other','Title_Rev']]\\\n            .loc[age['Age'].isnull() == False]\n\nage_test = age[['Pclass','Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Other','Title_Rev']]\\\n            .loc[age['Age'].isnull() == True]","ed0f2088":"#linear regression\nfrom sklearn import linear_model\nregression = linear_model.LinearRegression()\nx = np.array(age_train[['Pclass','Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Other','Title_Rev']])\ny = np.array(age_train[['Age']])\nregression.fit(x,y)\nprint('Coefficients: ', regression.coef_)","246bd597":"#Predictions\ny_hat = regression.predict(np.array(age_test))\ny_hat[:10]","d04fc77a":"age_test['Age'] = y_hat","73d603b1":"New_Ages = age_test[['Age']]\nNew_Ages","ab40d320":"Existing_Ages = age_train[['Age']]\nExisting_Ages","14b6ae0c":"Final_Ages = pd.concat([Existing_Ages,New_Ages])\nFinal_Ages","89b375cb":"#it seems to have concatenated fine but is displaying weird\nFinal_Ages.loc[1301]","9bfeb558":"titanic['Age'] = Final_Ages['Age']\ntitanic","4e459997":"titanic['Age'].isnull().value_counts()","2c3f11a8":"titanic.columns","ae888630":"titanic.drop(['Ticket','Title_Dr', 'Title_Master',\n       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Other', 'Title_Rev'],axis=1,inplace=True)\ntitanic.head()","eec7c30a":"missing = titanic.isna()\nfor col in missing.columns:\n    if missing[col].sum() > 0:\n        print(\"Column:\", col)\n        print(\"num of missing values:\", missing[col].sum())\n        print(\"\")","3a0af991":"normalise = lambda x : (x - np.min(x))\/(np.max(x) - np.min(x))\n\ncolumns = ['Age','Fare']\n\nfor column in columns:\n    titanic[[column]] = titanic[[column]].apply(normalise)\n\ntitanic.head()","6db320cc":"#Train\n\ntitanic_train = titanic.loc[train_index,:]\ntitanic_targets = titanic_train['Survived']\ntitanic_train.drop('Survived',axis=1,inplace=True)\n\n#Test\ntitanic_test = titanic.loc[test_index, :]\ntitanic_test.drop('Survived',axis=1,inplace=True)","4e9a478b":"titanic_train.head()","e7792ab3":"titanic_test.head()","1651b082":"#fit\n\nfrom sklearn.linear_model import LogisticRegression\n\n#liblinear is good for small datasets according to scikitlearn documentation\nLR = LogisticRegression(C=0.5, solver='liblinear').fit(titanic_train, titanic_targets.ravel())\nLR","5ab91fa8":"print('Coefficients: ', LR.coef_)","e2b78450":"#predict\n\nSurvivor_estimates = LR.predict(titanic_test).astype(int)\nSurvivor_estimates","bf384d84":"Survivor_estimates = pd.DataFrame(Survivor_estimates,index=test_index,columns=['Survived'])\nSurvivor_estimates","e464b7d1":"np.unique(Survivor_estimates, return_counts=True)","6d7f8acd":"#Survivor_estimates.to_csv('Titanic Logistic Regression.csv')","42df5386":"**Filling in missing ages with linear regression**","44c91f2e":"**Result**\n<br><br>\nAfter playing around with the regularisation parameters the best score from Logistic Regression came with C = 0.01: **0.78708**","241e8f9b":"**One-hot encoding for Sex**","ad20188c":"Split the data back into train and test","a91b8688":"Let's group decks together into similar survival groups, to reduce the dimensionality of our model later on (helps prevent overfitting).","0882f7e5":"Perhaps unsurprisingly, a high age is related to a high passenger class. We could try to use this information to fill in the missing values.","7e01aea4":"**Filling in missing values for Embarked**","4c2ba6dc":"Looks like lack of cabin data is also an indicator of a low Passenger Class, which could explain the lower survival rate.","af244e20":"**Logistic Regression**","7005df33":"Quick sense check on the coefficients before we make our predictions on the test data:\n<br>\n<br>\nExpect higher class to be correlated with higher age; -5.95 looks reasonable\n<br>\nThe title \"Master\" is used for young boys, hence we expect a lower age; -30.24 confirms this.\n<br>\n\"Miss\" refers to unmarried women, hence it makes sense to put a lower weight on it than Mrs (-16.28 vs -2.96)","e9b2c008":"**One-hot encoding for Deck**","1f4a6e76":"**Importing and preparing the data**","94c39b5c":"**Filling in missing value for Fare**","c2f5db0b":"Assumption #1: the first letter of the cabin is the section of the ship, ie the deck.\n<br\/>\nAssumption #2: passengers in the same deck have a similar chance of survival (ceteris paribus)","912e03ab":"Assumption: Rare titles (with the exception of Ms) are a sign of high status, and may be correlated with a higher age","d264611f":"**Titanic Dataset Solution using Logistic Regression**","d7ac13eb":"**One Hot Encoding for Title**","d541a235":"Normalise Data","969f1bee":"It looks like survival is relatively less likely for passengers with no cabin data.","48b1774e":"**Cabin Data**","366584e3":"**Age**","b15a4c61":"Well, that's pretty useless. Let's resort to filling them in with the mode. At least we can be pretty certain they embarked from the same place.","acafc2fd":"**One-hot encoding for Embarked**"}}