{"cell_type":{"b734472d":"code","5106b590":"code","ae46a796":"code","7564b4e7":"code","c0ae18f5":"code","e1aa83a3":"code","fd5feef0":"code","6f6ff792":"code","f795bbf2":"code","1f947659":"code","0cf0c205":"code","995ec8b7":"code","aed5a182":"code","ada4954b":"code","7a8edda9":"code","ce93b229":"code","3bddedd2":"code","7bde0072":"code","7a6a2433":"code","60852dcb":"code","88717bac":"code","2d6b109e":"code","65f8e2ac":"code","2a1edc9d":"code","1abf6f1c":"code","434922dc":"code","d21ee7d3":"code","f67fdaf7":"code","d5e21c88":"code","6888f3ef":"code","4fa35582":"code","70fceb59":"code","0420a624":"markdown","ec8afefa":"markdown","613f8e5e":"markdown","4ce0267d":"markdown","117795fd":"markdown","8f4c9ac4":"markdown","64733689":"markdown","05ed44b4":"markdown","dba2f6ca":"markdown","cf90e8f3":"markdown","de21c335":"markdown","1254262e":"markdown","638fffdf":"markdown","7a589edd":"markdown","5b1df64f":"markdown","e404a9b0":"markdown","c344857d":"markdown","14a882f6":"markdown","48b412e4":"markdown","adaf04b4":"markdown","da3e4f9d":"markdown","99e638e3":"markdown"},"source":{"b734472d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport random\n\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('ggplot')","5106b590":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nss = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")","ae46a796":"train.head(3)","7564b4e7":"FEATURES = [\n    \"song_duration_ms\",\n    \"acousticness\",\n    \"danceability\",\n    \"energy\",\n    \"instrumentalness\",\n    \"key\",\n    \"liveness\",\n    \"loudness\",\n    \"audio_mode\",\n    \"speechiness\",\n    \"tempo\",\n    \"time_signature\",\n    \"audio_valence\",\n]","c0ae18f5":"TARGET = ['song_popularity']","e1aa83a3":"train.shape, test.shape","fd5feef0":"train.head()","6f6ff792":"train.info()","f795bbf2":"print(f\"The train set has {train.isnull().sum().sum()} missing values, and the test set has {test.isnull().sum().sum()}.\")","1f947659":"plt.figure(figsize=(9, 6))\nsns.heatmap(train.isna().transpose(),\n            cmap=\"Blues\",\n            cbar_kws={'label': 'Missing Data'})\nplt.title('Missing Values in Train data', weight = 'bold', size = 20, color = 'red')\nplt.xticks(size = 12, color = 'red')\nplt.yticks(size = 12, color = 'red')\nplt.show();","0cf0c205":"ncounts = pd.DataFrame([train.isna().mean(), test.isna().mean()]).T\nncounts = ncounts.rename(columns={0: \"train_missing\", 1: \"test_missing\"})\n\nncounts.query(\"train_missing > 0\").plot(\n    kind=\"barh\", figsize=(9, 6), title=\"% of Values Missing\"\n)\nplt.show()","995ec8b7":"nacols = [\n    \"song_duration_ms\",\n    \"acousticness\",\n    \"danceability\",\n    \"energy\",\n    \"instrumentalness\",\n    \"key\",\n    \"liveness\",\n    \"loudness\",\n]","aed5a182":"train.song_popularity =train.song_popularity.astype('bool')\nplt.figure(figsize = (9, 6))\nax = sns.countplot(data = train , x = 'song_popularity', palette = 'Blues_r',linewidth=5,edgecolor=sns.color_palette(\"Blues_r\", 3))\nplt.title(\"Target: Song Popularity\",weight = 'bold', color = 'black', size = 18)\nplt.ylabel(\" \")\nplt.xlabel(\" \")\nplt.xticks(size = 12, weight ='bold')\nplt.yticks(size = 12, weight ='bold')\nplt.show()","ada4954b":"useful_cols = [col for col in train.columns if col not in ['id', 'song_popularity']]\ncols_dist = [col for col in useful_cols if col not in ['key', 'audio_mode', 'time_signature']]\n\nplt.figure(figsize = (18, 12))\ncolor_ = [ '#9D2417', '#AF41B4', '#003389' ,'#3C5F41',  '#967032', '#2734DE'] \nfor i in enumerate(train[cols_dist].columns):\n  rand_col = color_[random.sample(range(6), 1)[0]]\n\n  plt.subplot(4,3,i[0]+1)\n  sns.kdeplot(data = train, x = i[1], hue = 'song_popularity', fill = rand_col, color = rand_col )\n  plt.title (i[1], color = 'maroon')\n  plt.xlabel(\" \")\n  plt.ylabel(\" \")\n  plt.xticks(rotation = 45)\n  plt.tight_layout()","7a8edda9":"train[\"n_missing\"] = train[nacols].isna().sum(axis=1)\ntest[\"n_missing\"] = test[nacols].isna().sum(axis=1)","ce93b229":"train[\"n_missing\"].value_counts().plot(\n    kind=\"bar\", title=\"Number of Missing Values per Sample\"\n)","3bddedd2":"cat_features = [\"key\", \"audio_mode\"]\ntrain.groupby(\"audio_mode\")[\"n_missing\"].mean()","7bde0072":"train.groupby(\"time_signature\")[\"n_missing\"].agg(['mean','count'])","7a6a2433":"train.groupby(\"song_popularity\")[\"n_missing\"].mean()","60852dcb":"train_missing_tag_df = train[nacols].isna()\ntrain_missing_tag_df.columns = \\\n    [f\"{c}_missing\" for c in train_missing_tag_df.columns]","88717bac":"train = pd.concat([train, train_missing_tag_df], axis=1)","2d6b109e":"test_missing_tag_df = test[nacols].isna()\ntest_missing_tag_df.columns = \\\n    [f\"{c}_missing\" for c in test_missing_tag_df.columns]","65f8e2ac":"test = pd.concat([test, test_missing_tag_df], axis=1)","2a1edc9d":"!git clone https:\/\/github.com\/analokmaus\/kuma_utils.git","1abf6f1c":"import sys\nsys.path.append(\"kuma_utils\/\")\nfrom kuma_utils.preprocessing.imputer import LGBMImputer","434922dc":"%%time\nlgbm_imtr = LGBMImputer(n_iter=100, verbose=True)\n\ntrain_lgbmimp = lgbm_imtr.fit_transform(train[FEATURES])\ntest_lgbmimp = lgbm_imtr.transform(test[FEATURES])\ntrain_imp = pd.DataFrame(train_lgbmimp, columns=FEATURES)\ntest_imp = pd.DataFrame(test_lgbmimp, columns=FEATURES)","d21ee7d3":"train_blank = pd.DataFrame(train.drop(train[FEATURES], axis=1))\ntrain_filled = pd.concat([train_blank, train_imp], axis=1)\ntrain_filled['key'] = round(train_filled['key'])\ntrain_filled = pd.get_dummies(train_filled, columns=['key','time_signature'])","f67fdaf7":"test_blank = pd.DataFrame(test.drop(test[FEATURES], axis=1))\ntest_filled = pd.concat([test_blank, test_imp], axis=1)\ntest_filled['key'] = round(test_filled['key'])\ntest_filled = pd.get_dummies(test_filled, columns=['key','time_signature'])","d5e21c88":"train_filled.columns","6888f3ef":"FULL_FEATURES = ['n_missing',\n                 'song_duration_ms_missing',\n                 'acousticness_missing',\n                 'danceability_missing',\n                 'energy_missing',\n                 'instrumentalness_missing',\n                 'key_missing',\n                 'liveness_missing',\n                 'loudness_missing',\n                 'song_duration_ms',\n                 'acousticness',\n                 'danceability',\n                 'energy',\n                 'instrumentalness',\n                 'liveness',\n                 'loudness',\n                 'audio_mode',\n                 'speechiness',\n                 'tempo',\n                 'audio_valence',\n                 'key_0.0',\n                 'key_1.0',\n                 'key_2.0',\n                 'key_3.0',\n                 'key_4.0',\n                 'key_5.0',\n                 'key_6.0',\n                 'key_7.0',\n                 'key_8.0',\n                 'key_9.0',\n                 'key_10.0',\n                 'key_11.0',\n                 'time_signature_2',\n                 'time_signature_3',\n                 'time_signature_4',\n                 'time_signature_5']","4fa35582":"from xgboost import XGBClassifier\n\nxgb_predictions = 0\nxgb_scores = []\n\nskf = StratifiedKFold(n_splits=12, shuffle=True, random_state=42)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train_filled[FULL_FEATURES], train_filled[TARGET])):\n  \n  print(12*\"=\", f\"Fold={fold+1}\", 12*\"=\")\n  start_time = time.time()\n  \n  X_train, X_valid = train_filled.iloc[train_idx][FULL_FEATURES], train_filled.iloc[valid_idx][FULL_FEATURES]\n  y_train , y_valid = train_filled[TARGET].iloc[train_idx] , train_filled[TARGET].iloc[valid_idx]\n\n  model = XGBClassifier(objective = 'binary:logistic', eval_metric = 'auc')\n  model.fit(X_train, y_train,verbose=0)\n  \n  preds_valid = model.predict_proba(X_valid)[:, 1]\n  auc = roc_auc_score(y_valid,  preds_valid)\n  xgb_scores.append(auc)\n  run_time = time.time() - start_time\n  \n  print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n  test_preds = model.predict_proba(test_filled[FULL_FEATURES])[:, 1]\n  xgb_predictions += test_preds\/12\n    \nprint(\"Mean AUC :\", np.mean(xgb_scores))","70fceb59":"xgb_submission = ss.copy()\nxgb_submission['song_popularity'] = xgb_predictions\nxgb_submission.to_csv(\"submission.csv\",index=False)\nxgb_submission.head()","0420a624":"Let's add on some tag columns for all of the missing data","ec8afefa":"## Creating the submission CSVs for each model\n\n### LGBM","613f8e5e":"ctb_submission = ss.copy()\nctb_submission['song_popularity'] = ctb_predictions\nctb_submission.to_csv(\"submission.csv\",index=False)\nctb_submission.head()","4ce0267d":"Let's get an idea of the ratio of missing values","117795fd":"Do we see an imbalance in missing values when splitting by other features?","8f4c9ac4":"## Let's jump into some more EDA before handing the missing values\n\nFirst, let's check out the ratio of Popular to Unpopular songs","64733689":"from catboost import CatBoostClassifier\n\nctb_predictions = 0\nctb_scores = []\n\nskf = StratifiedKFold(n_splits=12, shuffle=True, random_state=42)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train_filled[FULL_FEATURES], train_filled[TARGET])):\n  \n  print(12*\"=\", f\"Fold={fold+1}\", 12*\"=\")\n  start_time = time.time()\n  \n  X_train, X_valid = train_filled.iloc[train_idx][FULL_FEATURES], train_filled.iloc[valid_idx][FULL_FEATURES]\n  y_train , y_valid = train_filled[TARGET].iloc[train_idx] , train_filled[TARGET].iloc[valid_idx]\n\n  model = CatBoostClassifier(objective = 'Logloss')\n  model.fit(X_train, y_train,verbose=0)\n  \n  preds_valid = model.predict_proba(X_valid)[:, 1]\n  auc = roc_auc_score(y_valid,  preds_valid)\n  ctb_scores.append(auc)\n  run_time = time.time() - start_time\n  \n  print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n  test_preds = model.predict_proba(test_filled[FULL_FEATURES])[:, 1]\n  ctb_predictions += test_preds\/12\n    \nprint(\"Mean AUC :\", np.mean(ctb_scores))","05ed44b4":"Looks like they're about the same - around 10% in eight of the columns. Let's pull those columns out as 'nacols'","dba2f6ca":"### XGBoost","cf90e8f3":"### XBBoost Classifier","de21c335":"## LightGBM Imputer\n\nTime to fill in the missing data. I'll use the LightGBM Importer here (shoutout to Rob Mulla for his [great video on handling missing data](https:\/\/www.youtube.com\/watch?v=EYySNJU8qR0))","1254262e":"### CatBoost Classifier","638fffdf":"## Looks like we have some missing values","7a589edd":"Maybe there are some obvious correlations between the features and the popularity of the song?","5b1df64f":"No smoking guns here, let's get back to cleaning up the missing values.\n\nHow many missing values per observation?","e404a9b0":"How do the Train and Test data vary, if at all, when it comes to missing values?","c344857d":"### CatBoost","14a882f6":"import time\nfrom sklearn.model_selection import StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\n\n\nlgbm_predictions = 0\nlgbm_scores = []\n\nskf = StratifiedKFold(n_splits=12, shuffle=True, random_state=42)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train_filled[FULL_FEATURES], train_filled[TARGET])):\n  \n  print(12*\"=\", f\"Fold={fold+1}\", 12*\"=\")\n  start_time = time.time()\n  \n  X_train, X_valid = train_filled.iloc[train_idx][FULL_FEATURES], train_filled.iloc[valid_idx][FULL_FEATURES]\n  y_train , y_valid = train_filled[TARGET].iloc[train_idx] , train_filled[TARGET].iloc[valid_idx]\n\n  model = LGBMClassifier(objective = 'binary', metric = 'auc')\n  model.fit(X_train, y_train,verbose=0)\n  \n  preds_valid = model.predict_proba(X_valid)[:, 1]\n  auc = roc_auc_score(y_valid,  preds_valid)\n  lgbm_scores.append(auc)\n  run_time = time.time() - start_time\n  \n  print(f\"Fold={fold+1}, AUC score: {auc:.2f}, Run Time: {run_time:.2f}s\")\n  test_preds = model.predict_proba(test_filled[FULL_FEATURES])[:, 1]\n  lgbm_predictions += test_preds\/12\n    \nprint(\"Mean AUC :\", np.mean(lgbm_scores))","48b412e4":"lgbm_submission = ss.copy()\nlgbm_submission['song_popularity'] = lgbm_predictions\nlgbm_submission.to_csv(\"submission.csv\",index=False)\nlgbm_submission.head()","adaf04b4":"## Now let's try out some classification models\n\n### LGBM Classifier","da3e4f9d":"# Building the Models\n\nGrabbing all of the new columns, including the missing data tag columns and the dummy categorical columns\n\n","99e638e3":"# EDA\n\nLet's take a look around the data and see if we can't find anything that stands out."}}