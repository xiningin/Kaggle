{"cell_type":{"4b9ccce1":"code","22580186":"code","d8141c11":"code","c7c8a7db":"code","a99d52aa":"code","9e8f207f":"code","4c6db6a2":"code","985b7495":"code","c9d51737":"code","e8ab4cb5":"code","71449bfc":"code","7fc68fde":"code","3a8c635b":"code","92d7882b":"code","dc364294":"code","54d3bd45":"code","b26649ea":"code","ed5eedb2":"code","4b73fc8d":"markdown","a84d72cd":"markdown","558fed8d":"markdown","0716baba":"markdown"},"source":{"4b9ccce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22580186":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\ndf = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.head(10)","d8141c11":"#Observing the columns and their dtypes, it seems fine\ndf.info()","c7c8a7db":"#Defining list of X features for building our model\nfeatures = list(df.columns)\nfeatures","a99d52aa":"#Visualise the class label counts\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,5))\n\nax = sn.countplot(x=\"Outcome\", data=df)","9e8f207f":"#Visualize the distribution of class labels on the correlation grid of all features\nsn.pairplot(data=df, hue=\"Outcome\");","4c6db6a2":"#Drop all na values from our dataset\ndf=df.dropna()","985b7495":"#Checking actual value counts for the class labels\ndf.Outcome.value_counts()","c9d51737":"## Importing resample from *sklearn.utils* package.\nfrom sklearn.utils import resample\n\n# Separate the case of yes-sdiabetese and no-diabetese\nno_diabetes = df[df.Outcome == 0]\nyes_diabetes = df[df.Outcome == 1]\n\n##Upsample the yes-diabetese cases.\ndf_minority_upsampled = resample(yes_diabetes, \n                                 replace=True,     # sample with replacement\n                                 n_samples=250) \n\n# Combine majority class with upsampled minority class\nnew_df = pd.concat([no_diabetes, df_minority_upsampled])\nnew_df.info()","e8ab4cb5":"from sklearn.utils import shuffle\nnew_df = shuffle(new_df)","71449bfc":"#Define X and y to fit our model\nX = new_df[features]\ny = new_df['Outcome']","7fc68fde":"#Train test split in the ratio 80:20\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","3a8c635b":"#Building a decision tree model using Gini criteria\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nclf_tree = DecisionTreeClassifier( max_depth = 5, criterion = 'gini' )\nclf_tree.fit( X_train, y_train )","92d7882b":"#We will use decision tree for our classification\nfrom sklearn import metrics\ntree_predict = clf_tree.predict( X_test )\nmetrics.roc_auc_score( y_test, tree_predict )","dc364294":"## Defining the matrix to draw the confusion metrix from actual and predicted class labels\n\ndef draw_cm( actual, predicted ):\n    # Invoking confusion_matrix from metric package. The matrix will oriented as [1,0] i.e.\n    # the classes with label 1 will be reprensted the first row and 0 as second row \n    cm = metrics.confusion_matrix( actual, predicted)\n    ## Confustion will be plotted as heatmap for better visualization\n    ## The lables are configured to better interpretation from the plot\n    sn.heatmap(cm, annot=True,  fmt='.2f', \n               xticklabels = [\"Yes Diabetes\", \"No Diabetes\"]  , \n               yticklabels = [\"Yes Diabetes\", \"No Diabetes\"] )\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","54d3bd45":"#Plot confusion matrix\ny_pred= clf_tree.predict( X_test )\ndraw_cm( y_test, y_pred)","b26649ea":"print( metrics.classification_report( y_test, y_pred ) )","ed5eedb2":"from sklearn import tree\ntext_representation = tree.export_text(clf_tree, feature_names=features)\nprint(text_representation)","4b73fc8d":"#### Data Description\n\n#### Predict the onset of diabetes based on diagnostic measures.\n\n* SUMMARY *\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n\nSeveral constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n- Pregnancies: Number of times pregnant\n- Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n- BloodPressure: Diastolic blood pressure (mm Hg)\n- SkinThickness: Triceps skin fold thickness (mm)\n- Insulin: 2-Hour serum insulin (mu U\/ml)\n- BMI: Body mass index (weight in kg\/(height in m)^2)\n- DiabetesPedigreeFunction: Diabetes pedigree function\n- Age: Age (years)\n- Outcome: Class variable (0 or 1)\n\n#### Outcome is our target variable","a84d72cd":"#### We have used resampling technique and solved the data imbalance issue, we have a model which is trained on the resampled dataset and predicts with 100 % accuracy, from the Confusion matrix we note their are 0 misclassifications which is a good news.","558fed8d":"### We start by loading our dataset and coding dependencies","0716baba":"#### We note the slightly imbalanced dataset, we need to use oversampling to manage the bias that may come while model building due to the data imbalance"}}