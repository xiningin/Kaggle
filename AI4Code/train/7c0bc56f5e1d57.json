{"cell_type":{"5c8536ee":"code","3f94f006":"code","55d33443":"code","957f8739":"code","26f88cf0":"code","dd34e7c1":"code","69c220a6":"code","099c3ce1":"code","bd57a7b8":"code","223e1b0c":"code","fab7fa1d":"code","defc3d35":"code","d52dbe11":"code","e3d1de9c":"code","c31efe91":"code","1cb742dc":"code","c42bccb3":"code","6d35cfa9":"code","81fc6eab":"code","06d92e60":"code","8c9c44bd":"code","8f36ac57":"code","4e8658f4":"code","8439b298":"markdown","047c4e5f":"markdown","4f65ae80":"markdown","c9a39495":"markdown","f36347ec":"markdown","62d8354b":"markdown","75f4f3b1":"markdown","931bf3d2":"markdown","f1bec372":"markdown","43bb6b77":"markdown","1c275082":"markdown","f9773569":"markdown","bea860ea":"markdown","d4be0508":"markdown","10220233":"markdown","9b2b694f":"markdown","3e27bbd5":"markdown","c34670a1":"markdown","cbeb90f3":"markdown","2bf2fe31":"markdown","0f45d88f":"markdown"},"source":{"5c8536ee":"!pip install torch==1.9.0 -q\n!pip install torchvision==0.10.0 -q\n!pip install --upgrade scikit-learn -q","3f94f006":"!nvidia-smi","55d33443":"import os\nimport time\nimport json\nfrom pathlib import Path\n\nimport h5py\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\n\nfrom tqdm.auto import tqdm, trange\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (f1_score, \n                             classification_report, \n                             plot_confusion_matrix,\n                             ConfusionMatrixDisplay)\n\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom torchvision import transforms as VisTransforms\nimport torchvision\n\n\n\n\nimport matplotlib.pyplot as plt\n\nimport multiprocessing as mp\n\n\nplt.style.use('ggplot')","957f8739":"torch.hub._validate_not_a_forked_repo=lambda a,b,c: True","26f88cf0":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nDATASET_PATH = \"..\/input\/chest-xray-pneumonia\/chest_xray\"\nSAVE_LOCATION = \"output\/\"\nPath(SAVE_LOCATION).mkdir(parents=True, exist_ok=True)\nIMAGE_SIZE = (256, 256)\n\nLR = 1e-2\nPRETRAINED_LR = 1e-6\nMOMENTUM = 0.9\nBETAS = (0.9, 0.999)\nADAM_EPS = 1e-8\nWEIGHT_DECAY = 1e-1\nMAX_GRADIENT_NORM = 0.5\n\nLR_SCHEDULE_GAMMA = 0.9\nT_0_COSINE_ANNEALING = 10\nT_MULT_COSINE_ANNEALING = 2\n\n\nEARLY_STOPPING_PATIENCE = 20\n\nBATCH_SIZE = {\n    \"train\": 128,\n    \"test\": 256,\n}\n\nMAX_EPOCHS = 100","dd34e7c1":"sizes = []\nlabels = []\n\nfor root, _, files in os.walk(os.path.join(DATASET_PATH, \"train\")):\n    for f in files:\n        if f.endswith(\".jpeg\"):\n            img = Image.open(os.path.join(root, f))\n            w, h = img.size\n            aspect = w \/ h\n            sizes.append((w, h, aspect))\n            labels.append(Path(root).stem)\n\n\nsizes = np.asarray(sizes)\n\nw = sizes[:, 0]\nh = sizes[:, 1]\na = sizes[:, 2]\n\nfig, axes = plt.subplots(3, 1, figsize=(8,10))\n\naxes[0].hist(w, bins=100)\naxes[0].set_title(\"Width Distribution\")\naxes[1].hist(h, bins=100)\naxes[1].set_title(\"Height Distribution\")\naxes[2].hist(a, bins=20)\naxes[2].set_title(\"Aspect Distribution\")\npass","69c220a6":"uniques, counts = np.unique(labels, return_counts=True)\nplt.bar(uniques, counts, color=[\"brown\", \"green\"])\nplt.title('Distribution of Labels in the Training Set')\npass","099c3ce1":"n = len(labels)\nn_classes = len(set(labels)) # == 2\n# balanced weight formula: n_total\/(n_classes * n_samples_in_ith_class)\nclassification_weights = {\n    idx: n\/(v*n_classes) for idx, (k, v) in enumerate(zip(*np.unique(labels, return_counts=True)))\n}\nprint(classification_weights)","bd57a7b8":"class LabelTransformer:\n    def __call__(self, label):\n        label = label.lower()\n        if label == \"normal\":\n            return 0\n        else:\n            return 1","223e1b0c":"class ImageResizer:\n    def __init__(self, size, optional=False):\n        self.size = size\n        self.optional = optional\n    def __call__(self, input_img):\n        h, w = input_img.shape\n        target = cv2.resize(input_img, \n                            (self.size, self.size),  \n                            interpolation = cv2.INTER_CUBIC)\n        return target","fab7fa1d":"class PreProcessor:\n    def __init__(self,\n                 pipeline):\n        self.preprcoessing_pipeline = pipeline\n\n    def __call__(self, input_img):\n        processed = self.preprcoessing_pipeline(input_img)\n        return processed        ","defc3d35":"class PneumoniaDataset(Dataset):\n    def __init__(self, \n                 subset, \n                 preprocessor, \n                 image_transforms,\n                 label_transforms,\n                 root=DATASET_PATH,\n                 debug=False):\n        super().__init__()\n        assert subset in [\"train\", \"test\", \"val\"]\n        self.folder_path = os.path.join(root, subset)\n        self.dataset_name = subset\n\n        self.preprocessor = preprocessor\n        self.image_transforms = image_transforms\n        self.label_transforms = label_transforms\n\n        self._preprocess(debug)\n    \n    def _preprocess(self, debug):\n        '''\n            This function saves the processed data into a list\n\n            debug: flag to create a debug set using a limited number of samples\n        '''\n        images_path = []\n        labels = []\n        for root, __, files in os.walk(self.folder_path):\n            for f in files:\n                if f.endswith(\".jpeg\"):\n                    fpath = os.path.join(root, f)\n                    l = Path(root).stem\n                    images_path.append(fpath)\n                    labels.append(self.label_transforms(l))\n                \n        \n        if debug:\n            images_path = images_path[:50]\n            labels = labels[:50]\n\n        if os.path.exists(self.dataset_name):\n            os.remove(self.dataset_name)\n        \n        self.data = []\n\n        for idx, fpath in enumerate(tqdm(images_path, \n                                         desc=f\"creating {self.dataset_name} set\")):\n            # reading images as grayscales\n            img = cv2.imread(fpath, 0)\n            img = self.preprocessor(img)\n            \n            self.data.append(\n                {\n                    \"image\": img,\n                    \"label\": labels[idx]\n                }\n            )\n        \n        self._len = len(self.data)\n\n    \n    def __len__(self):\n        return self._len\n\n    def __getitem__(self, idx):\n        img = self.data[idx][\"image\"]\n        l = self.data[idx][\"label\"]\n        \n        img = self.image_transforms(img)\n        l = torch.LongTensor([l])\n\n        return {\n            \"image\": img,\n            \"label\": l\n        }","d52dbe11":"# We need to make sure the data is batched correctly\nclass BatchCollater:\n    def __call__(self, data):\n        batch = {k: [] for k in data[-1]}\n        for d in data:\n            for k in d:\n                batch[k].append(d[k])\n        for k in batch:\n            batch[k] = torch.stack(batch[k], dim=0)\n        batch[\"label\"] = batch[\"label\"].squeeze()\n        return batch\n\nclass Initializer:\n    def __init__(self):\n        '''\n            This class helps us initiate all the required data stuff with ease.\n        '''\n        pass\n\n    \n    def initialize(self, debug=False):\n        preprocessor = PreProcessor(\n            pipeline=VisTransforms.Compose([ImageResizer(IMAGE_SIZE[0]),])\n            )\n        image_transforms = VisTransforms.Compose([VisTransforms.ToTensor(),\n                                                  # GrayScale mapping\n                                                  VisTransforms.Lambda(\n                                                      lambda x: torch.cat([x, x, x]).clone()\n                                                      ),\n                                                  VisTransforms.RandomChoice(\n                                                      [VisTransforms.ColorJitter(\n                                                          brightness=0.3,\n                                                          contrast=0.3,\n                                                          ),\n                                                       VisTransforms.RandomAffine(\n                                                           degrees=20, \n                                                           shear=3,\n                                                           translate=(0.2, 0.2)\n                                                           ),\n                                                       VisTransforms.RandomHorizontalFlip(\n                                                           p=1),\n                                                       ],),\n                                                  VisTransforms.Normalize(\n                                                      mean=[0.485, 0.456, 0.406],\n                                                      std=[0.229, 0.224, 0.225]\n                                                      )])\n        label_transforms = LabelTransformer()\n\n        train_dataset = PneumoniaDataset(\"train\", \n                                         preprocessor, \n                                         image_transforms, \n                                         label_transforms, \n                                         debug=debug)\n\n        val_dataset = PneumoniaDataset(\"val\", \n                                       preprocessor, \n                                       image_transforms, \n                                       label_transforms, \n                                       debug=debug)\n\n        test_dataset = PneumoniaDataset(\"test\", \n                                        preprocessor, \n                                        image_transforms, \n                                        label_transforms, \n                                        debug=debug)\n\n        train_loader = DataLoader(\n            dataset=train_dataset, \n            batch_size=BATCH_SIZE[\"train\"], \n            shuffle=True, \n            num_workers=2,\n            collate_fn=BatchCollater(),\n            prefetch_factor=2,\n        )\n\n        test_loader_params = val_loader_params = dict(batch_size=BATCH_SIZE[\"test\"],\n                                                      collate_fn=BatchCollater(), \n                                                      shuffle=False,)\n        \n\n        val_loader = DataLoader(dataset=val_dataset, **val_loader_params)\n        test_loader = DataLoader(dataset=test_dataset, **test_loader_params)\n\n        return dict(\n            train_dataset=train_dataset,\n            train_loader=train_loader,\n            val_dataset=val_dataset,\n            val_loader=val_loader,\n            test_dataset=test_dataset,\n            test_loader=test_loader,\n        )","e3d1de9c":"# From https:\/\/gist.github.com\/jeasinema\/ed9236ce743c8efaf30fa2ff732749f5\n\nimport torch.nn.init as init\n\n\ndef weight_init(m):\n    '''\n    Initializes the weights of a module.\n    \n    Usage:\n        model = Model()\n        model.apply(weight_init)\n    '''\n    if isinstance(m, nn.Conv1d):\n        init.normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.Conv2d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.Conv3d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose1d):\n        init.normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose2d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose3d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.BatchNorm1d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.BatchNorm2d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.BatchNorm3d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.Linear):\n        init.xavier_normal_(m.weight.data)\n        init.normal_(m.bias.data)\n    elif isinstance(m, nn.LSTM):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.LSTMCell):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.GRU):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.GRUCell):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)","c31efe91":"def load_pretrained():\n    pretrained_model = torchvision.models.mobilenetv3.mobilenet_v3_small(pretrained=True,\n                                                                         progress=True)\n    return pretrained_model.features\n\n\nclass PneumoniaNet(nn.Module):\n    def __init__(self, \n                 input_dim,\n                 finetune=False):\n        \n        super().__init__()\n\n        self.loss_fn = nn.CrossEntropyLoss(\n            weight=torch.FloatTensor(list(classification_weights.values()))\n            )\n\n        self.input_dim = torch.as_tensor(input_dim)\n        \n        self.input_encoder = load_pretrained()\n\n        # Freezing all layers but the last two\n        for param in self.input_encoder[:-2].parameters():\n            param.requires_grad = False\n\n        self.output_decoder = nn.Sequential(        \n            nn.AdaptiveAvgPool2d((1,1)),\n            nn.Flatten(),\n            nn.Dropout(),\n            nn.Linear(576, 2),\n        )\n\n        self._init_weights()\n\n\n    def _init_weights(self):\n        self.output_decoder.apply(weight_init)\n        \n\n    def forward(self, x):\n        assert x.shape[-2] == self.input_dim[0] and x.shape[-1] == self.input_dim[1]\n\n        x = self.input_encoder(x)\n        x = self.output_decoder(x)\n\n        return x\n\n\n    def loss(self, outputs, targets):\n        return self.loss_fn(outputs, targets)\n        \n\n\n    def generate_opt(self):\n        params = [\n                  {\"params\": nn.ModuleList([self.output_decoder]).parameters()},\n                  {\"params\": self.input_encoder[-2:].parameters(), \"lr\": PRETRAINED_LR,}\n        ]\n        \n        return torch.optim.AdamW(\n                params,\n                lr=LR,\n                weight_decay=WEIGHT_DECAY,\n                betas=BETAS,\n                eps=ADAM_EPS\n        )\n","1cb742dc":"# From https:\/\/gist.github.com\/stefanonardo\/693d96ceb2f531fa05db530f3e21517d\nclass EarlyStopping:\n    def __init__(self, mode='min', \n                 min_delta=0, \n                 patience=EARLY_STOPPING_PATIENCE,\n                 percentage=False):\n        self.mode = mode\n        self.min_delta = min_delta\n        self.patience = patience\n        self.best = None\n        self.num_bad_epochs = 0\n        self.is_better = None\n        self._init_is_better(mode, min_delta, percentage)\n\n        # This helps us saving the model\n        # whenever this is true we will save the model\n        self.testing_patience = False\n\n        if patience == 0:\n            self.is_better = lambda a, b: True\n            self.step = lambda a: False\n\n    def stop(self, metrics):\n        if self.best is None:\n            self.best = metrics\n            return False\n\n        if np.isnan(metrics):\n            self.testing_patience = True\n            return True\n\n        if self.is_better(metrics, self.best):\n            self.num_bad_epochs = 0\n            self.best = metrics\n            self.testing_patience = False\n        else:\n            self.num_bad_epochs += 1\n            self.testing_patience = True\n\n        if self.num_bad_epochs >= self.patience:\n            self.testing_patience = True\n            return True\n\n        return False\n\n    def _init_is_better(self, mode, min_delta, percentage):\n        if mode not in {'min', 'max'}:\n            raise ValueError('mode ' + mode + ' is unknown!')\n        if not percentage:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - min_delta\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + min_delta\n        else:\n            if mode == 'min':\n                self.is_better = lambda a, best: a < best - (\n                            best * min_delta \/ 100)\n            if mode == 'max':\n                self.is_better = lambda a, best: a > best + (\n                            best * min_delta \/ 100)","c42bccb3":"def compute_f1(outputs, targets):\n    binary_outputs = outputs.argmax(dim=-1).detach().cpu().squeeze().numpy()\n    targets = targets.detach().cpu().squeeze().numpy()\n    return f1_score(targets, binary_outputs)\n\n# A Simple Helper class to circumvent sklearn's need for classifiers\nclass IdentityClassifier:\n    def __init__(self):\n        self._estimator_type = 'classifier'\n        self._classes = [0, 1]\n\n    def predict(self, X):\n        return X\n\ndef classification_report_string_with_dict(**params):\n    if \"output_dict\" in params:\n        params.pop(\"output_dict\")\n    return classification_report(**params), classification_report(output_dict=True, **params)\n","6d35cfa9":"class Trainer:\n    def __init__(self,\n                 model,\n                 model_name,\n                 train_loader,\n                 val_loader,\n                 test_loader,\n                 max_epochs=MAX_EPOCHS,\n                 amp=True,\n                 progress=False,\n                 device=device):\n    \n        self.device = device\n        self.model = model\n\n        self.opt = self.model.generate_opt()\n\n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.opt,\n            T_0_COSINE_ANNEALING,\n            T_MULT_COSINE_ANNEALING,\n            verbose = False,\n        )\n\n        self.stopper = EarlyStopping()\n\n        self.cur_epoch = 1\n        self.max_epochs = max_epochs\n\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n\n        self.model_name = model_name\n        self.save_loc = os.path.join(SAVE_LOCATION, model_name)\n        \n\n        self.training_info = []\n\n        self.amp = amp\n\n        self.debug = False\n        self.progress = progress\n        \n    @property\n    def debug(self):\n        return self._debug\n\n    @property\n    def amp(self):\n        return self._amp\n    \n    @amp.setter\n    def amp(self, flag):\n        self._amp = flag\n        self.scaler = torch.cuda.amp.GradScaler(enabled=self._amp)\n\n\n    @debug.setter\n    def debug(self, flag):\n        self._debug = flag\n        if flag is False:\n            if hasattr(self, \"original_values\"):\n                for item in self.original_values:\n                    self.__dict__[item] = self.original_values[item]\n        else:\n            self.original_values = {\n                \"train_loader\": self.train_loader,\n                \"val_loader\": self.val_loader,\n                \"test_loader\": self.test_loader,\n                \"max_epochs\": self.max_epochs,\n            }\n            self.train_loader = DataLoader(self.train_loader.dataset, \n                                           batch_size=2,\n                                           shuffle=False,\n                                           num_workers=2,\n                                           collate_fn=BatchCollater(),\n                                           prefetch_factor=2)\n            \n            self.val_loader = DataLoader(self.val_loader.dataset, \n                                           batch_size=4,\n                                           collate_fn=BatchCollater(),\n                                           shuffle=False)\n            \n            self.test_loader = DataLoader(self.test_loader.dataset, \n                                          batch_size=4,\n                                          collate_fn=BatchCollater(),\n                                          shuffle=False)\n            self.max_epochs = 1\n\n\n    @property\n    def save_loc(self):\n        return self._save_loc\n\n    @save_loc.setter\n    def save_loc(self, path):\n        \n        self.model_save_location = os.path.join(path, f\"saved_model.model\")\n        self.training_info_location = os.path.join(path, \"training_info.json\")\n        self.test_info_location = os.path.join(path, \"test_info.json\")\n\n        self._save_loc = path\n        Path(self._save_loc).mkdir(exist_ok=True)\n\n\n    def save_model(self):\n        state_dict = {\n            \"training_info\": self.training_info,\n            \"model_state\": self.model.state_dict(),\n            \"opt_state\": self.opt.state_dict(),\n            \"scaler_state\": self.scaler.state_dict()\n        }\n\n        torch.save(state_dict, self.model_save_location)\n\n\n    def save_training_info(self):\n        with open(self.training_info_location, \"w\") as jfile:\n            json.dump(self.training_info, jfile)\n\n    def load_model(self):\n        state_dict = torch.load(self.model_save_location)\n        self.training_info = state_dict[\"training_info\"]\n        self.model.load_state_dict(state_dict[\"model_state\"])\n        self.opt.load_state_dict(state_dict[\"opt_state\"])\n        self.scaler.load_state_dict(state_dict[\"scaler_state\"])\n\n        \n    def validate(self):\n        running_info = {\n                    \"loss\": 0,\n                    \"f1\": 0,\n                    \"numel\": 0,\n        }\n        self.model.eval()\n        with torch.no_grad():\n            for batch in self.val_loader:\n                for k in batch:\n                    batch[k] = batch[k].to(self.device)\n\n                outputs = self.model(batch[\"image\"])\n                loss = self.model.loss(outputs, batch[\"label\"])\n\n                batch_size = len(batch[\"image\"])\n                running_info[\"loss\"] += loss.item() * batch_size\n                running_info[\"f1\"] += compute_f1(outputs, batch[\"label\"]) * batch_size\n                running_info[\"numel\"] += batch_size\n            \n        val_info = {\n            f\"val_loss\": running_info[\"loss\"] \/ running_info[\"numel\"],\n            f\"val_f1\": running_info[\"f1\"] \/ running_info[\"numel\"]\n        }\n\n        return val_info\n\n    def test(self):\n        outputs = []\n        targets = []\n        self.model.eval()\n        loss = 0\n        with torch.no_grad():\n            for batch in self.test_loader:\n                for k in batch:\n                    batch[k] = batch[k].to(self.device)\n\n                o = self.model(batch[\"image\"])\n\n                loss += self.model.loss(o, batch[\"label\"]).item() * len(batch[\"label\"])\n\n                outputs.extend(o.argmax(dim=-1).detach().cpu().tolist())\n                targets.extend(batch[\"label\"].detach().cpu().tolist())\n                \n        outputs = np.asarray(outputs).astype(np.int)\n        targets = np.asarray(targets).astype(np.int)\n        \n        \n        report, test_info = classification_report_string_with_dict(\n                y_true=targets,\n                y_pred=outputs,\n                target_names = [\"Normal\", \"Pneumonia\"],\n            )\n        \n        \n        test_info[\"test_loss\"] = loss \/ len(outputs)\n\n        print(report)\n        print(f\"test_loss: {test_info['test_loss']}\")\n\n\n        fig, ax = plt.subplots()\n        ax.grid(None)\n        plot_confusion_matrix(IdentityClassifier(), outputs, targets,\n                              display_labels=[\"Normal\", \"Pneumonia\"],\n                              normalize='true', \n                              values_format='.2%',\n                              ax=ax)\n        \n        plt.show()\n\n        with open(self.test_info_location, \"w\") as jfile:\n            json.dump(test_info, jfile)\n\n\n    def train(self):\n        self.model.train()\n        begin = True\n        for epoch in range(self.cur_epoch, self.max_epochs+1):\n            running_info = {\n                    \"loss\": 0,\n                    \"f1\": 0,\n                    \"numel\": 0,\n                }\n            if self.progress:\n                pbar = tqdm(total=len(self.train_loader), \n                            desc= f\"Epoch {epoch} out of {self.max_epochs}.\",\n                            leave=False)\n\n            for batch in self.train_loader:\n                for k in batch:\n                    batch[k] = batch[k].to(self.device)\n\n                self.opt.zero_grad()\n                with torch.cuda.amp.autocast(enabled=self.amp):\n                    outputs = self.model(batch[\"image\"])\n                    loss = self.model.loss(outputs, batch[\"label\"])\n            \n                self.scaler.scale(loss).backward()\n                self.scaler.unscale_(self.opt)\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), MAX_GRADIENT_NORM)\n                self.scaler.step(self.opt)\n                self.scaler.update()\n\n                batch_size = len(batch[\"image\"])\n                batch_loss = loss.item()\n                running_info[\"loss\"] += batch_size * batch_loss\n                running_info[\"f1\"] += compute_f1(outputs, batch[\"label\"]) * batch_size\n                running_info[\"numel\"] += batch_size\n                \n                if self.progress:\n                    pbar.set_postfix(batch_loss=batch_loss)\n                    pbar.update()\n                    time.sleep(0.01)\n            \n            self.cur_epoch = epoch\n            self.scheduler.step()\n            \n            if self.progress:\n                pbar.close()\n                time.sleep(0.01)\n                \n            info = {\n                \"epoch\": epoch,\n                \"train_loss\": running_info[\"loss\"] \/ running_info[\"numel\"],\n                \"train_f1\": running_info[\"f1\"] \/ running_info[\"numel\"],\n            }\n            \n            info.update(self.validate())\n            self.training_info.append(info)\n\n            message = \"\\t\".join([f\"{k}: {v:.3f}\" for k, v in info.items()])\n            print(message)\n            self.save_training_info()\n            if self.stopper.stop(info[\"val_loss\"]):\n                break\n            else:\n                if self.stopper.testing_patience is False:\n                    self.save_model()\n            ","81fc6eab":"initer = Initializer()\nparams = initer.initialize(debug=False)","06d92e60":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\nmodel = PneumoniaNet(input_dim=IMAGE_SIZE).to(device)\ntrainer = Trainer(\n    model,\n    \"pneumonia_model\",\n    train_loader=params[\"train_loader\"],\n    val_loader=params[\"val_loader\"],\n    test_loader=params[\"test_loader\"],\n    amp=True,\n)\nprint(\n    f\"Total learnable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):.2E}\"\n)\n","8c9c44bd":"trainer.train()","8f36ac57":"# Plotting loss and f1 score for train and validation\nfig, axes = plt.subplots(2, 1, figsize=(7,11))\n\ntraining_info = pd.DataFrame(trainer.training_info)\n\ntraining_info.plot(x=\"epoch\", \n                   y =[\"train_loss\", \"val_loss\"], \n                   ax=axes[0])\naxes[0].set_title(\"Loss During Training\")\n\ntraining_info.plot(x=\"epoch\", \n                   y =[\"train_f1\", \"val_f1\"], \n                   ax=axes[1])\naxes[1].set_title(\"F1 Score During Training\")\n\nplt.show()","4e8658f4":"# Loading best model\ntrainer.load_model()\ntrainer.test()","8439b298":"### Intializing the datasets and the loaders","047c4e5f":"# Imports","4f65ae80":"### Intitializing the model and the trainer class","c9a39495":"# Introduction\n\nIn this notebook, we use a CNN to classify pneumonia cases. The dataset in question is available at kaggle by [this link](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia). The problem has been solved by the use of ShuffleNet and MobileNet's previous versions before, but in this kernel we are using a small MobileNetV3 via transfer learning and then finetuning its last layers in addition to learn a new classification head. This makes this solution extremly lightweight. Stay Tuned!","f36347ec":"# Pre-training plots\n\n### Plotting widths and heights of the images in the dataset\n\n\nThis helps us choose a better size (I've chosen it before;).) The chosen input dimension is 256x256, because:\n\n1 - All image sizes are bigger than this.\n\n2 - Bigger image size means more detials, and we can afford to use bigger image sizes because we're effectively single channel network (although we map grayscale to RGB finally).","62d8354b":"### Training the model","75f4f3b1":"We used multiple augmentations in order to further augment the dataset and avoid overfitting. ColorJitter changes the brightness and contrast, using affine transformations we change the rotation, shear, and translation of pixel values and finally using horizontal flip we make sure the model is able to find the pneumonia regions in either sides of the chest.","931bf3d2":"# Definitions\n\n## Defining Transforms\n\n\nThese are some useful transforms that will help us get the data ready to be an input to the CNN.","f1bec372":"Apparently there is a problem with pytorch 1.9's implementation of torch hub which this helps to alieviate.","43bb6b77":"## Defining the Trainer Class","1c275082":"# Code","f9773569":"# Plotting and printing the test results","bea860ea":"# Plotting the training history","d4be0508":"### Plotting the distribution of classes and choosing adequate weightings.","10220233":"## Defining the Initializer","9b2b694f":"## Defining the Dataset","3e27bbd5":"# Training","c34670a1":"## Defining the PneumoniaNet\n\nThis CNN uses a small MobileNetV3 architecture, and freezes all but its the last two modules which are then are finetuned via a smaller learning rate than the classification head. The last two modules are An inverted residual module + a 1x1 convolution module. This makes the model extremly lightweight to use and extremly resistant to overfitting because of the lack of parameters.","cbeb90f3":"As I mentioned above, we use LR scheduling (cosine annealing with warm restarts) and early stopping regularizations, which chooses the best model by it's validation loss value.","2bf2fe31":"These are a bunch of helper functions and classes, just to use in the trainer class. The most intersting point is that we are using a CosineAnnealing learning rate scheme that has warmups every few steps with a dynamic cyclical routine. The cycle lengthens everytime it completes a new one. ","0f45d88f":"# Defining Constants"}}