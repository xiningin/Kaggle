{"cell_type":{"75c4d2ec":"code","065afeb9":"code","44ef42e8":"code","c3565893":"code","b2f23e05":"code","ce35c85f":"code","45c04e7f":"code","f39e6a33":"code","e0a7830a":"code","6b4903a9":"code","a29fe0ae":"code","2d0cd5db":"code","7771a33e":"code","676225a5":"code","54e72001":"code","aa049b75":"code","340a7707":"code","00e80fff":"code","a7724137":"code","32ba7cef":"code","03b93a88":"code","ee4474d0":"code","a35ed1b8":"code","fec5462b":"code","c38b24a1":"code","69608f83":"code","9fcf9b06":"code","c4d208e3":"code","78cbc40b":"code","0e2789a5":"code","a2f3c74f":"code","742999a2":"code","b6c4debc":"code","7f789cd3":"code","031aa957":"code","52f75abc":"code","45eb69cc":"code","9011f9b9":"code","210da951":"code","e66bd24a":"code","9cf995fe":"code","c345024a":"code","338a0780":"code","91c089f2":"code","8eee57a5":"code","8f250f7c":"code","50f69ac5":"code","4793758e":"code","ac1c90ab":"code","e30356dc":"code","a529d8a3":"code","8fe65dd6":"code","b3b85957":"code","01b5202f":"code","b5eb4e28":"code","a943b835":"code","6106d3fb":"markdown","0d7f10f6":"markdown","821884d0":"markdown","513e56df":"markdown","af0bb30b":"markdown","04e2379b":"markdown","ee32c462":"markdown","91e08a74":"markdown"},"source":{"75c4d2ec":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","065afeb9":"! pip install pandas --upgrade","44ef42e8":"import pandas as pd\nimport numpy as np\nimport seaborn as sns #visualisation\nimport matplotlib.pyplot as plt #visualisation\n\nimport math, time, random, datetime\nimport seaborn as sns\nimport missingno\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%load_ext google.colab.data_table\nplt.style.use('seaborn-whitegrid')\n%matplotlib inline \nsns.set(color_codes=True)","c3565893":"df_train = pd.read_csv(\"\/kaggle\/input\/forest-cover-type-prediction\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/forest-cover-type-prediction\/test.csv\")\ndf_sub = pd.read_csv(\"\/kaggle\/input\/forest-cover-type-prediction\/sampleSubmission.csv\")","b2f23e05":"df_train.head(10)","ce35c85f":"df_test.head()","45c04e7f":"df_sub.head()","f39e6a33":"df_train.dtypes","e0a7830a":"df_train.isna().sum()","6b4903a9":"df_train.columns","a29fe0ae":"df_train.describe()","2d0cd5db":"con_columns = [ 'Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n    \ncat_columns = [ 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n\nout_label = 'Cover_Type'","7771a33e":"df_train[con_columns].describe()","676225a5":"df_train.head()","54e72001":"def plot_continous_data( df, columnlist, nbins=50):\n  count = 0\n  for col in columnlist:\n    for index in range(2):\n      plt.figure(count, figsize=(10,5))\n      count += 1\n      #sns.distplot(df_train[col])\n      if index == 0:\n        df_train[col].plot.hist(bins=nbins)\n      else:\n        sns.distplot(df_train[col])\n","aa049b75":"plot_continous_data(df_train, con_columns, 50)","340a7707":"def box_plot_continous_data( df, columnlist):\n  count = 0\n  for col in columnlist:\n    for index in range(2):\n      plt.figure(count, figsize=(10,5))\n      count += 1\n      sns.boxplot(df_train[col])","00e80fff":"box_plot_continous_data(df_train, con_columns)","a7724137":"for index in range(len(con_columns)):\n  plt.figure(index, figsize=(10,5))\n  sns.boxplot(y = df_train[con_columns[index]], x = df_train[out_label])","32ba7cef":"for index in range(len(con_columns)):\n  plt.figure(index, figsize=(10,5))\n  sns.violinplot(y = df_train[con_columns[index]], x = df_train[out_label])","03b93a88":"con_columns","ee4474d0":"collist = con_columns[:3]\ncollist.append(out_label)\nsns.pairplot(df_train[ collist ], hue = \"Cover_Type\", diag_kind=\"hist\")\n","a35ed1b8":"collist = con_columns[3:6]\ncollist.append(out_label)\nsns.pairplot(df_train[ collist ], hue = \"Cover_Type\", diag_kind=\"hist\")","fec5462b":"collist = con_columns[6:10]\ncollist.append(out_label)\nsns.pairplot(df_train[ collist ], hue = \"Cover_Type\", diag_kind=\"hist\")","c38b24a1":"for index in range(len(cat_columns)):\n  plt.figure(index, figsize=(10,5))\n  #print(df_train.groupby(out_label)[cat_columns[index]].value_counts())\n  #print(df_train.groupby(out_label)[cat_columns[index]].sum())\n  #print(df_train.groupby(out_label)[cat_columns[index]].value_counts())\n  df_train.groupby(out_label)[cat_columns[index]].sum().plot.bar()\n  plt.title(cat_columns[index])\n  #sns.barplot(x= cat_columns[index], y=out_label, data=df_train)","69608f83":"for index in range(len(cat_columns)):\n  plt.figure(index, figsize=(10,5))\n  df_train.groupby(out_label)[cat_columns[index]].value_counts().plot.bar()\n  plt.title(cat_columns[index])","9fcf9b06":"for col in df_train.columns:\n  print( col , \" -> \" , len(df_train[col].value_counts()) )\n  #print( df_train[col].value_counts() )","c4d208e3":"def remove_outliers(df, col):\n  q1 = df[col].quantile(0.25)\n  q3 = df[col].quantile(0.75)\n  iqr = q3 - q1\n  min_threshold = q1 - 1.5*iqr\n  max_threshold = q3 + 1.5*iqr\n  #min_threshold, max_threshold = df[col].quantile([0.01,0.99])\n  print(\" Column Name ->\", col, \"\\n min-threshold -> \" , min_threshold, \"\\n max-threshold -> \" , max_threshold )\n  print(\"#######################################################################################################\")\n  df.loc[df[col]>=max_threshold , col] = df[col].mean()\n  df.loc[df[col]<=min_threshold , col] = df[col].mean()\n  #df.loc[df[col]>=max_threshold , col] = max_threshold ## capping the thresholds\n  #df.loc[df[col]<=min_threshold , col] = min_threshold\n  #df[col].plot.box()\n  return df","78cbc40b":"df_train.corr()","0e2789a5":"df_train.head()","a2f3c74f":"df_train = pd.read_csv(\"\/kaggle\/input\/forest-cover-type-prediction\/train.csv\")","742999a2":"df_train = df_train.drop(columns=['Soil_Type7', 'Soil_Type15', 'Id'])","b6c4debc":"df_train.columns","7f789cd3":"con_columns","031aa957":"#for col in con_columns:\n#  df_train = remove_outliers(df_train, col)","52f75abc":"df_train[con_columns].describe()","45eb69cc":"df_test.head()","9011f9b9":"for col in df_test.columns:\n  print( col , \" -> \" , len(df_test[col].value_counts()) )","210da951":"df_test = df_test.drop(columns=['Soil_Type7', 'Soil_Type15', 'Id'])","e66bd24a":"df_test.columns","9cf995fe":"from sklearn.preprocessing import MinMaxScaler\n\n\nX_train = df_train.drop(columns=['Cover_Type'])\ny_train = df_train[\"Cover_Type\"]\n#X_train = df_train\n\nX_test = df_test\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(X_train)\n\n# transform training data\nX_train_norm = norm.transform(X_train)\n\n#y_train = X_train_norm[\"Cover_Type\"] \n#X_train_norm = X_train_norm.drop(columns=['Cover_Type'])\n\n# transform testing data\nX_test_norm = norm.transform(X_test)","c345024a":"def ml_algorithm(algo, X_train, y_train, cv):\n\n  model = algo.fit(X_train, y_train)\n  acc = round(model.score(X_train, y_train)* 100, 2)\n\n  train_pred = model_selection.cross_val_predict(algo, \n                                                  X_train, \n                                                  y_train, \n                                                  cv=cv, \n                                                  n_jobs = -1)\n  \n  acc_cv = round(metrics.accuracy_score(y_train, train_pred) * 100, 2)\n    \n  return train_pred, acc, acc_cv","338a0780":"start_time = time.time()\ntrain_pred_log, acc_log, acc_cv_log = ml_algorithm(LogisticRegression(), \n                                                               X_train_norm, \n                                                               y_train, \n                                                                    10)\nlog_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_log)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_log)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=log_time))","91c089f2":"# k-Nearest Neighbours\nstart_time = time.time()\ntrain_pred_knn, acc_knn, acc_cv_knn = ml_algorithm(KNeighborsClassifier(), \n                                                  X_train_norm, \n                                                  y_train, \n                                                  10)\nknn_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_knn)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_knn)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=knn_time))","8eee57a5":"# Gaussian Naive Bayes\nstart_time = time.time()\ntrain_pred_gaussian, acc_gaussian, acc_cv_gaussian = ml_algorithm(GaussianNB(), \n                                                                      X_train_norm, \n                                                                      y_train, \n                                                                           10)\ngaussian_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gaussian)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gaussian)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gaussian_time))","8f250f7c":"# Linear SVC\nstart_time = time.time()\ntrain_pred_svc, acc_linear_svc, acc_cv_linear_svc = ml_algorithm(LinearSVC(),\n                                                                X_train_norm, \n                                                                y_train, \n                                                                10)\nlinear_svc_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_linear_svc)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_linear_svc)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=linear_svc_time))","50f69ac5":"# Stochastic Gradient Descent\nstart_time = time.time()\ntrain_pred_sgd, acc_sgd, acc_cv_sgd = ml_algorithm(SGDClassifier(), \n                                                  X_train_norm, \n                                                  y_train,\n                                                  10)\nsgd_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_sgd)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_sgd)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=sgd_time))","4793758e":"start_time = time.time()\ntrain_pred_gbt, acc_gbt, acc_cv_gbt = ml_algorithm(GradientBoostingClassifier(), \n                                                                       X_train_norm, \n                                                                       y_train,\n                                                                       10)\ngbt_time = (time.time() - start_time)\nprint(\"Accuracy: %s\" % acc_gbt)\nprint(\"Accuracy CV 10-Fold: %s\" % acc_cv_gbt)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=gbt_time))","ac1c90ab":"model = GradientBoostingClassifier(random_state=45).fit(X_train_norm, y_train)\n\nacc = round(model.score(X_train_norm, y_train)* 100, 2) \n\npred = model.predict(X_test_norm)\n","e30356dc":"print(\"Accuracy of the model is {}\".format(acc))","a529d8a3":"print(pred.shape)","8fe65dd6":"unique, counts = np.unique(pred, return_counts=True)\nprint(dict(zip(unique, counts)))","b3b85957":"print(type(X_test_norm))\nprint(X_test_norm.shape)","01b5202f":"df_test = pd.read_csv(\"\/kaggle\/input\/forest-cover-type-prediction\/test.csv\")","b5eb4e28":"df_test.columns","a943b835":"submission = pd.DataFrame()\nsubmission['Id'] = df_test['Id']\nsubmission['Cover_Type'] = pred # our model predictions on the test dataset\nsubmission.head(10)","6106d3fb":"we need to remove columns **Soil_Type7** **Soil_Type15** as they show no variation in data","0d7f10f6":"#**Features**\n\n**Elevation** - Elevation in meters\n\n**Aspect** - Aspect in degrees azimuth\n\n**Slope** - Slope in degrees\n\n**Horizontal_Distance_To_Hydrology** - Horz Dist to nearest surface water features\n\n**Vertical_Distance_To_Hydrology** - Vert Dist to nearest surface water features\n\n**Horizontal_Distance_To_Roadways** - Horz Dist to nearest roadway\n\n**Hillshade_9am (0 to 255 index)** - Hillshade index at 9am, summer solstice\n\n**Hillshade_Noon** (0 to 255 index) - Hillshade index at noon, summer solstice\n\n**Hillshade_3pm** (0 to 255 index) - Hillshade index at 3pm, summer solstice\n\n**Horizontal_Distance_To_Fire_Points** - Horz Dist to nearest wildfire ignition points\n\n**Wilderness_Area** (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation\n\n**Soil_Type** (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n\n**Cover_Type** (7 types, integers 1 to 7) - Forest Cover Type designation","821884d0":"## **Comparing continous features with label**\n\n### **Features** : \n'Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points'\n\n**Label :** Cover_Type","513e56df":"#**My Process Flow**\n\na. Understanding the data types\n\nb. Exploring the continous data features and relation with target feature\n\nc. Exploring the categorical features and relation with target feature\n\nd. Removing the outliers\n\ne. Removing the unnecessary data columns\n\nf. Feature scaling\/Normalization \n\ng. Finding important features\n\nh. Building models on top cleaned data\n\ni. Submitting the best performing model predictions\n\n\n","af0bb30b":"Check ing the unique value counts across all the columns","04e2379b":"##**columns** -- \n \n **'Slope'**,\n\n **'Horizontal_Distance_To_Hydrology'**,\n\n **'Vertical_Distance_To_Hydrology'**,\n\n **'Horizontal_Distance_To_Roadways'**,\n\n **'Hillshade_9am'**,\n\n **'Hillshade_Noon'**,\n\n **'Hillshade_3pm'**,\n\n **'Horizontal_Distance_To_Fire_Points'**\n\nhave outliers\n \nwe need to remove them.","ee32c462":"## **Feature Scaling \/ Normalization**","91e08a74":"## **Comparing categorical features with label**\n\n### **Features** : \n'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40'\n\n**Label :** Cover_Type"}}