{"cell_type":{"864d9b16":"code","4d1b2f77":"code","88641a88":"code","4e39a96a":"code","9d28583d":"code","d8d605da":"code","9309a791":"code","0207ed71":"code","b115e734":"code","0bb911a6":"code","773b67ef":"code","6dcf0e23":"code","f5051a7d":"code","e86c0095":"code","1b62bbbd":"code","ab29f5c3":"code","06732380":"code","e8b30ca9":"code","9055c151":"code","fd301003":"code","f01d554e":"code","ac45e0ec":"code","4e90c63b":"code","bc52dc0e":"code","5f718741":"markdown","74e73259":"markdown","d8868fd2":"markdown","a0b57f07":"markdown","2e9022a3":"markdown","d157ac1c":"markdown","8d37318c":"markdown"},"source":{"864d9b16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4d1b2f77":"import tensorflow\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pandas as pd","88641a88":"DF = pd.read_csv('..\/input\/Churn_Modelling.csv')\nDF.head(5)","4e39a96a":"DF.set_index('RowNumber')","9d28583d":"DF.columns","d8d605da":"DF =DF.drop(['CustomerId','Surname'],axis=1)","9309a791":"DF['Gender'].value_counts()","0207ed71":"DF['gender_Cat']=0\nDF.loc[(DF['Gender']=='Female'), 'gender_Cat'] = 1","b115e734":"print(DF['gender_Cat'].value_counts())\nDF.ix[1:10,['Gender','gender_Cat']]","0bb911a6":"from sklearn.preprocessing import LabelEncoder\nlabel_X_country_encoder = LabelEncoder()\nDF['Geography_cat'] = label_X_country_encoder.fit_transform(DF['Geography'])\n","773b67ef":"DF[DF['Balance']==0.0].count()","6dcf0e23":"DF['Exited'].value_counts()","f5051a7d":"X = DF.drop(['Exited','Gender','Geography'],axis=1) # Credit Score through Estimated Salary - features\ny = DF['Exited'] # Exited target\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","e86c0095":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","1b62bbbd":"import keras\nimport tensorflow as tf\ntf.set_random_seed(42)\n#Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))\nmodel.add(tf.keras.layers.Dense(activation = 'relu', units=6, kernel_initializer='uniform')) \nmodel.add(tf.keras.layers.Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) \n\nfrom keras import optimizers\n\nsgd = tf.keras.optimizers.SGD(lr=0.03)\n#Compile the model\nmodel.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\nhistory_sgd=model.fit(X_train, y_train, batch_size=10, epochs=40)","ab29f5c3":"y_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5)\n\ntest_loss, test_acc = model.evaluate(x=X_test,y=y_test.values)\nprint(\"Accuracy: \",test_acc)\nprint(\"Loss: \",test_loss)","06732380":"from sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)\n\nlabels = ['Class 0', 'Class 1']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","e8b30ca9":"#Initialize Sequential model\nmodel2 = tf.keras.models.Sequential()\nmodel2.add(tf.keras.layers.Dense(activation = 'relu', input_dim = 11, units=8))\nmodel2.add(tf.keras.layers.Dense(activation = 'relu', units=8)) \nmodel2.add(tf.keras.layers.Dense(activation = 'sigmoid', units=1)) \nmodel2.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\nmodel2.summary()\nhistory_adam=model2.fit(X_train, y_train, batch_size=10, epochs=40)\n\n#history_adam=model2.fit(X_train, y_train, batch_size=10, epochs=40)","9055c151":"y_pred = model2.predict(X_test)\ny_pred = (y_pred > 0.5)\ntest_loss, test_acc = model2.evaluate(x=X_test,y=y_test)\nprint(\"Accuracy: \",test_acc)\nprint(\"Loss: \",test_loss)\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)","fd301003":"from imblearn.over_sampling import SMOTE\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\nratio='minority'\n#sm = SMOTE(random_state=2)\nsm = SMOTE(ratio='minority')\n#X_sm, y_sm = smote.fit_sample(X, y.ravel())\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n\nprint('After OverSampling, the shape of X_train: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of y_train: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n","f01d554e":"#Normalize the data\n\nX_train_res = sc.fit_transform(X_train_res)","ac45e0ec":"#Initialize Sequential model\nmodel3 = tf.keras.models.Sequential()\nmodel3.add(tf.keras.layers.Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))\nmodel.add(tf.keras.layers.Dropout(0.6))\nmodel3.add(tf.keras.layers.Dense(activation = 'relu', units=6, kernel_initializer='uniform')) \nmodel3.add(tf.keras.layers.Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) \nsgd = tf.keras.optimizers.SGD(lr=0.01)\n#Compile the model\nmodel3.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n\n#adam=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False)\n\nmodel3.compile(optimizer=sgd, loss = 'binary_crossentropy', metrics=['accuracy'])\nmodel3.summary()\n\nhistory_smote_sgd=model3.fit(X_train_res, y_train_res, epochs=40)","4e90c63b":"y_pred = model3.predict(X_test)\ny_pred = (y_pred > 0.5)\ntest_loss, test_acc = model3.evaluate(x=X_test,y=y_test)\nprint(\"Accuracy: \",test_acc)\nprint(\"Loss: \",test_loss)\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\nprint('Confusion matrix:\\n', conf_mat)","bc52dc0e":"from matplotlib import pyplot\n# plot metrics\npyplot.plot(history_sgd.history['acc'],label='sgd')\npyplot.plot(history_adam.history['acc'],label='adam')\npyplot.plot(history_smote_sgd.history['acc'],label='smote_adam')\n#pyplot.legend([line1, line2, line3], ['sgd', 'adam', 'smote_adam'])\npyplot.legend()\n\npyplot.show()","5f718741":"****Using SMOTE to create the synthetic data","74e73259":"Drop the columns which are unique for all users like IDs","d8868fd2":"Normalize the dataset","a0b57f07":"****Attempt 2-Changing the optimiser","2e9022a3":"There is a imbalance between the two classes and the model will incorrectly learn the classification since   the number of people leaving 25.5% and 74.5% people did not exit the bank\nwe could use synthetic data to correct this imbalance","d157ac1c":"Attempt 1","8d37318c":"Converting the Gender Column to Numeric"}}