{"cell_type":{"2f633d26":"code","ecd25f5d":"code","5b7f1f5a":"code","fdbd80a0":"code","cdc614cc":"code","2e0f1070":"code","9570c8d2":"code","5a3d2a19":"code","c569f115":"code","c421dc07":"code","5a4544d1":"code","4f1f7e69":"code","339d7b33":"code","73da945f":"code","3013e335":"code","1ca0df8c":"code","ee60435d":"code","b8dd93be":"code","a9d040ba":"code","d11af7d6":"code","5d422a8c":"code","9f0c24c2":"code","4086f4df":"code","73470019":"code","c14cf138":"code","91d08165":"code","123d20ea":"code","66539a75":"code","ac7ff157":"code","313fe8fb":"code","838a3247":"code","b5a7c43f":"code","405662c3":"code","2cadc3dd":"code","915c4cf9":"code","9c4e6a75":"code","6d2a6599":"code","852305d6":"code","473ff3b4":"code","e3c23b67":"code","1a8f96a7":"code","d9b1b9b8":"code","1d060d59":"code","e3646f8f":"code","3df2b6ab":"code","e4d02225":"code","ee5efd55":"code","23329ade":"code","729c6769":"code","6e72f144":"code","2c9015fe":"code","b19ae073":"code","ed1ee6cb":"code","a13b26b7":"code","0dc46d35":"code","452cf797":"code","8d5f8bdb":"code","b2faca70":"code","da99ba84":"code","2697c5c8":"markdown","505e4fa6":"markdown","dd1a7a08":"markdown","f39eaa99":"markdown","4d6f6dec":"markdown","298e28fb":"markdown"},"source":{"2f633d26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecd25f5d":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import metrics\n\n","5b7f1f5a":"filename='\/kaggle\/input\/data-clean-wids\/No_Missing_Train_v1.0.csv'\ntrain_df=pd.read_csv(filename)","fdbd80a0":"filename =\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\"\nunlabelled_df=pd.read_csv(filename)","cdc614cc":"train_df.head()","2e0f1070":"train_df.drop(['Unnamed: 0','index','demo_cat_mode_x','demo_cat_mode_y'],axis=1,inplace=True)","9570c8d2":"unlabelled_df.shape","5a3d2a19":"train_df.shape","c569f115":"X = train_df.copy()\ny = X.pop('diabetes_mellitus')","c421dc07":"X.shape","5a4544d1":"missing_col=set(unlabelled_df.columns)-set(X.columns)\nunlabelled_df.drop(missing_col,axis=1,inplace=True)","4f1f7e69":"unlabelled_df.shape","339d7b33":"all_data = X.append(unlabelled_df)\ndf_train = all_data[:len(X)]\ndf_pred = all_data[len(X):].reset_index(drop=True)","73da945f":"X.shape","3013e335":"df_pred.shape","1ca0df8c":"df_pred=df_pred[Final_var]","ee60435d":"X=X[Final_var]","b8dd93be":"Final_var=['hospital_id','age','bmi','elective_surgery','ethnicity','gender','height','hospital_admit_source','icu_admit_source','icu_id','icu_stay_type','icu_type','pre_icu_los_days','readmission_status','albumin_apache','apache_2_diagnosis','apache_3j_diagnosis','arf_apache','bilirubin_apache','bun_apache','creatinine_apache','fio2_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache','glucose_apache','heart_rate_apache','hematocrit_apache','intubated_apache','map_apache','paco2_apache','paco2_for_ph_apache','pao2_apache','ph_apache','resprate_apache','sodium_apache','temp_apache','urineoutput_apache','ventilated_apache','wbc_apache','d1_diasbp_invasive_max','d1_diasbp_invasive_min','d1_diasbp_max',\n           'd1_diasbp_min','d1_diasbp_noninvasive_max','d1_diasbp_noninvasive_min','d1_heartrate_min','d1_mbp_invasive_max','d1_mbp_invasive_min','d1_resprate_max','d1_resprate_min','d1_spo2_max','d1_spo2_min','d1_sysbp_invasive_max','d1_sysbp_invasive_min','d1_sysbp_max','d1_sysbp_min','d1_sysbp_noninvasive_max','d1_sysbp_noninvasive_min','d1_temp_max','d1_temp_min','h1_diasbp_max','h1_diasbp_min','h1_heartrate_max','h1_resprate_max',\n           'h1_resprate_min','h1_spo2_max','h1_spo2_min','h1_sysbp_max','h1_sysbp_noninvasive_max',\n           'h1_temp_max','d1_bilirubin_max','d1_calcium_max','d1_glucose_min','d1_hco3_max','d1_inr_max','d1_lactate_max','d1_platelets_max',\n           'd1_potassium_max','d1_potassium_min','h1_potassium_max','d1_arterial_ph_max','d1_arterial_ph_min','d1_arterial_po2_max','d1_arterial_po2_min','d1_pao2fio2ratio_max','d1_pao2fio2ratio_min','aids','cirrhosis','hepatic_failure','immunosuppression','leukemia','lymphoma','solid_tumor_with_metastasis']","a9d040ba":"all_data.shape","d11af7d6":"all_data=all_data[Final_var]","5d422a8c":"features_cat = [cname for cname in all_data.columns if\n                    all_data[cname].dtype == \"object\"]","9f0c24c2":"# Select numerical columns\nfeatures_num = [cname for cname in all_data.columns if \n                all_data[cname].dtype in ['int64', 'float64']]","4086f4df":"transformer_num = make_pipeline(\n    SimpleImputer(strategy=\"mean\"), # there are a few missing values\n    StandardScaler(),\n)\ntransformer_cat = make_pipeline(\n    SimpleImputer(strategy=\"most_frequent\"),\n    OneHotEncoder(handle_unknown='ignore'),\n)\n\npreprocessor = make_column_transformer(\n    (transformer_num, features_num),\n    (transformer_cat, features_cat),\n)\n\n# stratify - make sure classes are evenlly represented across splits\nX_train, X_valid, y_train, y_valid = \\\n    train_test_split(X, y, stratify=y, train_size=0.75)\n\nX_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)\n\ninput_shape = [X_train.shape[1]]","73470019":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# YOUR CODE HERE: define the model given in the diagram\nmodel = keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1,activation='sigmoid')\n])\n\n","c14cf138":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy','AUC']\n)","91d08165":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=1000,\n    callbacks=[early_stopping],\n    verbose=0, # hide the output because we have so many epochs\n\n)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n#history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")","123d20ea":"\n\n\ndf_pred = preprocessor.transform(df_pred)\n\n\n","66539a75":"pred=model.predict_proba(df_pred).flatten()\n\n","ac7ff157":"len(pred)","313fe8fb":"pd.DataFrame({'encounter_id':unlabelled_df['encounter_id'].values,\n    'diabetes_mellitus':model.predict_proba(df_pred).flatten()}).to_csv('Submission_NN_3.csv',\n                                                                   index=False)","838a3247":"X_full=train_df.copy()","b5a7c43f":"X_test_full=unlabelled_df.copy()","405662c3":"# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['diabetes_mellitus'], inplace=True)\ny = X_full.diabetes_mellitus\nX_full.drop(['diabetes_mellitus'], axis=1, inplace=True)","2cadc3dd":"# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)","915c4cf9":"# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]","9c4e6a75":"# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]","6d2a6599":"# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","852305d6":"# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","473ff3b4":"my_model = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nmy_model.fit(X_train, y_train)\n# Get predictions\npredictions = my_model.predict(X_valid)\nprint('Report:', classification_report(y_valid, preds))","e3c23b67":"\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n# Preprocessing of training data, fit model \nclf.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_valid)\n\nprint('Report:', classification_report(y_valid, preds))","1a8f96a7":"# Preprocessing of test data, fit model\npreds_test = clf.predict(X_test)","d9b1b9b8":"predictions = my_model.predict(X_test)","1d060d59":"filename='\/kaggle\/input\/widsdatathon2021\/SolutionTemplateWiDS2021.csv'\nsubmission=pd.read_csv(filename)","e3646f8f":"submission.head()","3df2b6ab":"preds_test.shape","e4d02225":"# Save test predictions to file\n#output = pd.DataFrame({'encounter_id': submission.encounter_id,\n #                      'diabetes_mellitus': preds_test})\n#output.to_csv('submission_randomforestclassifier.csv', index=False)","ee5efd55":"# Save test predictions to file\noutput = pd.DataFrame({'encounter_id': submission.encounter_id,\n                       'diabetes_mellitus': predictions})\noutput.to_csv('submission_XGBoost.csv', index=False)","23329ade":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndef gini(y, pred):\n    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n    g = 2 * metrics.auc(fpr, tpr) -1\n    return g\n\ndef gini_lgb(preds, dtrain):\n    y = list(dtrain.get_label())\n    score = gini(y, preds) \/ gini(y, y)\n    return 'gini', score, True","729c6769":"import lightgbm as lgb\nfrom lightgbm import LGBMModel,LGBMClassifier\nLgb = LGBMClassifier(n_estimators=1000, silent=False, random_state =94, max_depth=5,num_leaves=31,objective='binary',metrics ='auc')","6e72f144":"Train_lgb = lgb.Dataset(X,label=y)","2c9015fe":"params = {\n    'max_depth' : 5,\n    'num_leaves' : 31,\n    'objective' : 'binary',\n    'metric' : 'auc'\n}","b19ae073":"X = preprocessor.transform(X)","ed1ee6cb":"df_pred.shape","a13b26b7":"fit_model = Lgb.fit(X, y,eval_metric=gini_lgb)","0dc46d35":"y_test_pred = fit_model.predict_proba(df_pred)[:,1]","452cf797":"pd.DataFrame({'encounter_id':unlabelled_df['encounter_id'].values,'diabetes_mellitus':y_test_pred}).to_csv('LGB2.csv', index=False)","8d5f8bdb":"len(y_test_pred)","b2faca70":"from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor","da99ba84":"train_pool = Pool(data=X,label = y,cat_features=features_cat)","2697c5c8":"# LGB","505e4fa6":"# Catboost","dd1a7a08":"# Random Forest Classifer","f39eaa99":"# XGBoost","4d6f6dec":"test data cleaning","298e28fb":"# Deep Learning"}}