{"cell_type":{"30a8b948":"code","1fe9bdcf":"code","cb808db4":"code","5df43d52":"code","dc7ddd1d":"code","5600f7c5":"code","3d53a528":"code","df02d7b3":"code","24fd1d4e":"code","39edef4f":"code","3e42020e":"code","dabd687f":"code","3c670142":"code","a538b414":"code","f666febb":"code","e607e736":"code","427c8b5c":"code","6a635f81":"code","8ca78cfa":"code","a3391e16":"code","586af133":"code","ba63b0b6":"code","7dac56de":"code","acf3dc8b":"code","38e4611a":"code","ac0fe464":"code","ac7bab67":"code","b3730f45":"code","58ca1eaa":"code","a7603e06":"code","3d0540d7":"code","42c13c7c":"code","60afb156":"markdown","d359999e":"markdown","84975062":"markdown","2f8140af":"markdown","74fad9de":"markdown","ec70ba28":"markdown"},"source":{"30a8b948":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='ignore')\nplt.style.use(['seaborn-bright','dark_background'])","1fe9bdcf":"data = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndata.head()","cb808db4":"data.shape","5df43d52":"data.isnull().sum()","dc7ddd1d":"data.info()","5600f7c5":"data.describe()","3d53a528":"import plotly.express as px","df02d7b3":"fig = px.box(data, x = 'Outcome', y = 'Pregnancies', color = 'Outcome', notched = True, height = 300, width = 500)\nfig.show()","24fd1d4e":"data_0 = data[data['Outcome']==0]\ndata_1 = data[data['Outcome']==1]","39edef4f":"q1 = data_0['Pregnancies'].quantile(0.25)\nq3 = data_0['Pregnancies'].quantile(0.75)\nIQR = q3 - q1\nupper_whisker = q3+1.5*IQR\nlower_whisker = q1-1.5*IQR\nupper_whisker, lower_whisker","3e42020e":"data['Pregnancies'] = np.where((data['Outcome']==0) & (data['Pregnancies']>upper_whisker), upper_whisker, data['Pregnancies'])\ndata['Pregnancies'] = np.where((data['Outcome']==0) & (data['Pregnancies']<lower_whisker), lower_whisker, data['Pregnancies'])","dabd687f":"for i in data.columns:\n    if i != 'Outcome' and i !='Pregnancies':\n        fig = px.box(data, x = 'Outcome', y = i, color = 'Outcome', notched = True, height = 300, width = 500)\n        fig.show()","3c670142":"for i in data.columns:\n    if i!='Outcome' and i!='Pregnancies':\n        q1 = data_0[i].quantile(0.25)\n        q3 = data_0[i].quantile(0.75)\n        iqr = q3 - q1\n        upper_whisker = q3+1.5*iqr\n        lower_whisker = q1-1.5*iqr\n        data[i] = np.where((data['Outcome']==0) & (data[i]>upper_whisker), upper_whisker, data[i])\n        data[i] = np.where((data['Outcome']==0) & (data[i]<lower_whisker), lower_whisker, data[i])\n        \n        q1 = data_1[i].quantile(0.25)\n        q3 = data_1[i].quantile(0.75)\n        iqr = q3 - q1\n        upper_whisker = q3+1.5*iqr\n        lower_whisker = q1-1.5*iqr\n        data[i] = np.where((data['Outcome']==1) & (data[i]>upper_whisker), upper_whisker, data[i])\n        data[i] = np.where((data['Outcome']==1) & (data[i]<lower_whisker), lower_whisker, data[i])","a538b414":"for i in data.columns:\n    if i != 'Outcome' and i !='Pregnancies':\n        fig = px.box(data, x = 'Outcome', y = i, color = 'Outcome', notched = True, height = 300, width = 500)\n        fig.show()","f666febb":"fig = px.scatter_3d(data, x = 'Glucose', y = 'Age', z = 'BloodPressure', color = 'Outcome', \n                   height = 500, width = 700)\nfig.show()","e607e736":"plt.figure(figsize = (20, 15))\n\nplt.subplot(2,4,1)\nplt.title('Pregnancies')\nsns.distplot(data['Pregnancies'], kde = True, color = 'lime' )\n\nplt.subplot(2,4,2)\nplt.title('Glucose')\nsns.distplot(data['Glucose'], kde = True, color = 'dodgerblue' )\n\nplt.subplot(2,4,3)\nplt.title('Blood Pressure ')\nsns.distplot(data['BloodPressure'], kde = True, color = 'r' )\n\nplt.subplot(2,4,4)\nplt.title('BMI')\nsns.distplot(data['BMI'], kde = True, color = 'y' )\n\nplt.subplot(2,4,5)\nplt.title('SkinThickness')\nsns.distplot(data['SkinThickness'], kde = True, color = 'pink' )\n\nplt.subplot(2,4,6)\nplt.title('Insulin')\nsns.distplot(data['Insulin'], kde = True, color = 'orange' )\n\nplt.subplot(2,4,7)\nplt.title('DiabetesPedigreeFunction')\nsns.distplot(data['DiabetesPedigreeFunction'], kde = True, color = 'purple' )\n\nplt.subplot(2,4,8)\nplt.title('Age')\nsns.distplot(data['Age'], kde = True, color = 'c' )\n\nplt.show()","427c8b5c":"plt.figure(figsize=(10, 8))\nsns.heatmap(data.corr(), annot = True, cmap = 'winter')\nplt.title('Correleation Heatmap')\nplt.show()","6a635f81":"data['Outcome'].value_counts()","8ca78cfa":"X = data.drop(columns = ['Outcome'])\ny = data['Outcome']","a3391e16":"from imblearn.over_sampling import SMOTE","586af133":"smote = SMOTE()\nX_sample, y_sample = smote.fit_resample(X, y)\n\nprint('Original dataset \\n',y.value_counts()) \nprint('Resample dataset \\n', y_sample.value_counts())","ba63b0b6":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train , y_test = train_test_split(X_sample,y_sample, test_size=0.15,random_state=101)","7dac56de":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","acf3dc8b":"from sklearn.metrics import classification_report, confusion_matrix","38e4611a":"models = []\nmodels.append((\"LR\",LogisticRegression(solver='liblinear')))\nmodels.append((\"DT\",DecisionTreeClassifier()))\nmodels.append((\"RF\",RandomForestClassifier()))\nmodels.append((\"ET\",ExtraTreesClassifier()))\nmodels.append((\"GB\",GradientBoostingClassifier()))\nmodels.append((\"SVC\",SVC()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\nmodels.append((\"GNB\",GaussianNB()))","ac0fe464":"for name, model in models:\n    model.fit(x_train, y_train)\n    train_pred = model.predict(x_train)\n    test_pred = model.predict(x_test)\n    print(name)\n    print(classification_report(y_train,train_pred))\n    print(classification_report(y_test,test_pred))\n    \n    plt.figure(figsize=(6, 4))\n    plt.title(\"Training Data\")\n    sns.heatmap(confusion_matrix(y_train,train_pred), annot = True, cmap = 'rainbow')\n    plt.show()\n    plt.title('Testing Data')\n    sns.heatmap(confusion_matrix(y_test,test_pred), annot=True, cmap = 'cool')\n    plt.show()\n    print('')","ac7bab67":"model1 = DecisionTreeClassifier()\nmodel2 = RandomForestClassifier()\nmodel3 = ExtraTreesClassifier()","b3730f45":"model1.fit(x_train,y_train)\nmodel2.fit(x_train,y_train)\nmodel3.fit(x_train,y_train)\n\n\npred_prob1_ts = model1.predict_proba(x_test)\npred_prob2_ts = model2.predict_proba(x_test)\npred_prob3_ts = model3.predict_proba(x_test)\n\npred_prob1_tr = model1.predict_proba(x_train)\npred_prob2_tr = model2.predict_proba(x_train)\npred_prob3_tr = model3.predict_proba(x_train)","58ca1eaa":"from sklearn.metrics import roc_curve\n\nfpr1_ts, tpr1_ts, thresh1_ts = roc_curve(y_test, pred_prob1_ts[:,1], pos_label=1)\nfpr2_ts, tpr2_ts, thresh2_ts = roc_curve(y_test, pred_prob2_ts[:,1], pos_label=1)\nfpr3_ts, tpr3_ts, thresh3_ts = roc_curve(y_test, pred_prob3_ts[:,1], pos_label=1)\n\nfpr1_tr, tpr1_tr, thresh1_tr = roc_curve(y_train, pred_prob1_tr[:,1], pos_label=1)\nfpr2_tr, tpr2_tr, thresh2_tr = roc_curve(y_train, pred_prob2_tr[:,1], pos_label=1)\nfpr3_tr, tpr3_tr, thresh3_tr = roc_curve(y_train, pred_prob3_tr[:,1], pos_label=1)\n\n\nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)","a7603e06":"from sklearn.metrics import roc_auc_score\nauc_score1 = roc_auc_score(y_test, pred_prob1_ts[:,1])\nauc_score2 = roc_auc_score(y_test, pred_prob2_ts[:,1])\nauc_score3 = roc_auc_score(y_test, pred_prob3_ts[:,1])\n\n\nprint(f\"{auc_score1} , {auc_score2}, {auc_score3}\")","3d0540d7":"plt.figure(figsize=(16, 10))\nplt.plot(fpr1_ts, tpr1_ts, linestyle='--',color='r', label='DecisionTree Test')\nplt.plot(fpr2_ts, tpr2_ts, linestyle=':',color='lime', label='RandomForest Test')\nplt.plot(fpr3_ts, tpr3_ts, linestyle='-.',color='b', label='ExtraTree Test')\n\nplt.plot(fpr1_tr, tpr1_tr, linestyle='--',color='pink', label='DecisionTree Train')\nplt.plot(fpr2_tr, tpr2_tr, linestyle=':',color='orange', label='RandomForest Train')\nplt.plot(fpr3_tr, tpr3_tr, linestyle='-.',color='dodgerblue', label='ExtraTree Train')\n\nplt.plot(p_fpr, p_tpr, linestyle='-', color='y')\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show();","42c13c7c":"final_model = ExtraTreesClassifier()\nfinal_model.fit(x_train, y_train)\npred = final_model.predict(x_test)\nprint(f\"Classification report\\n {classification_report(pred, y_test)}\")\nprint(f\"Score = {final_model.score(x_test,y_test)}\")","60afb156":"### Choosing best three models","d359999e":"### Checking for outliers","84975062":"### Balancing unbalanced datset using oversampling","2f8140af":"### Model training and evaluation","74fad9de":"### ExtraTree Classifier Performs best on testing data as compared to Decision Tree and Random Forest","ec70ba28":"### Removing outliers using IQR method"}}