{"cell_type":{"1575beee":"code","7da61c5b":"code","90a54092":"code","50f03953":"code","7bca1e2b":"code","349a500c":"code","f1bd00f2":"code","cf73495e":"code","441d5210":"code","fc30af83":"code","e40e3e73":"code","354f2e6f":"code","6bfdb84f":"code","0b588ea1":"code","634c3281":"code","28f7a68e":"code","a3be8cf7":"code","6e247feb":"code","3b719e7a":"code","4805a83a":"code","e1d8da6f":"code","7f08c67a":"code","e72fc621":"code","434a4be2":"code","3991c1c8":"markdown","39efe94f":"markdown","bd6e9711":"markdown","fa88e118":"markdown","73120f13":"markdown","5ba39ff6":"markdown","715751b2":"markdown","c4617e12":"markdown","dda1fd71":"markdown","1b95385c":"markdown","8104ffe5":"markdown","9dead278":"markdown","b69b116b":"markdown","d6849114":"markdown"},"source":{"1575beee":"import copy, cv2, json, os, time, torch, torchvision\n\nfrom collections import OrderedDict\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom torch import nn\nfrom torch import optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torch.utils.data as data\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data.dataloader import DataLoader\nfrom torchvision import models\nfrom torchvision import transforms\nimport torchvision.datasets as datasets\n\nprint(os.listdir(\"..\/input\"))\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom matplotlib.pyplot import figure","7da61c5b":"print(len(os.listdir('..\/input\/train')))\nprint(len(os.listdir('..\/input\/test')))\ntrain = pd.read_csv('..\/input\/train.csv')\ntrain.head(3)","90a54092":"train.groupby('Id').count().sort_values('Image',ascending = False).head(10)","50f03953":"train.groupby('Id').count().plot.hist(range = (0,10))","7bca1e2b":"id_map = train[['Id']].drop_duplicates()\nid_map.index = list(range(0,len(id_map)))\nwhale_dict = id_map['Id'].to_dict()\nid_dict = dict((v,k) for k,v in whale_dict.items())\n#id_dict","349a500c":"with Image.open('..\/input\/test\/0027089a4.jpg') as img:\n    fig, ax = plt.subplots()\n    ax.imshow(img)","f1bd00f2":"def whale_list(whale_id,df = train):\n    return df[df['Id']==whale_id]['Image'].tolist()","cf73495e":"image_list = whale_list('w_23a388d')[:1]\nfor img_path in image_list:\n    with Image.open('..\/input\/train\/' + img_path) as img:\n        fig, ax = plt.subplots()\n        ax.imshow(img)","441d5210":"class HW_Dataset(Dataset):\n    def __init__(self,filepath, csv_path,transform=None):\n        self.file_path = filepath\n        self.df = pd.read_csv(csv_path)\n        self.transform = transform\n        self.image_list = [x for x in os.listdir(self.file_path)]\n        \n    def __len__(self):\n        return(len(self.image_list))\n    \n    def __getitem__(self,idx):\n        img_path = os.path.join(self.file_path,self.df.Image[idx])\n        label = self.df.Id[idx]\n        img = Image.open(img_path).convert('RGB')\n        img = self.transform(img)\n        \n        return img, label\n\ndef label_to_id(label):\n    x = [id_dict[i] for i in label]\n    return torch.tensor(x)\n\n# Process a PIL image for use in a PyTorch model\ndef process_image(image):\n    #img_transform = transforms.Compose([\n#        transforms.ToTensor()])\n    img_transform = transform\n    pil_image = Image.open(image)\n    pil_image = img_transform(pil_image).float()\n    np_image = np.array(pil_image)    \n    return np_image\n\ndef imshow(image, ax=None, title=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    # PyTorch tensors assume the color channel is the first dimension\n    # but matplotlib assumes is the third dimension\n    image = image.transpose((1, 2, 0))\n    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n    image = np.clip(image, 0, 1)\n    ax.imshow(image)\n    return ax","fc30af83":"#old 256\ndims = 128\n\ntransform = transforms.Compose([\n                              transforms.Resize((dims, dims)),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                     std=[0.229, 0.224, 0.225])])\n\ndim1 = max(int(dims**2\/2),5005)\ndim2 = max(int((dims**2)\/4),5005)\nprint(dim1)\nprint(dim2)","e40e3e73":"train_dataset = HW_Dataset('..\/input\/train\/','..\/input\/train.csv', transform)\ntest_dataset = HW_Dataset('..\/input\/test\/','..\/input\/train.csv', transform)\nlen(test_dataset.image_list)","354f2e6f":"train_dataset[0][0].size()","6bfdb84f":"# example\na = list(range(10))\nb = list(range(5,15))\nnp.setdiff1d(a,b) #in a and not in b","0b588ea1":"test_size = .2\nn = len(train_dataset)\n\nnp.random.seed(0)\na = list(range(n))\n\ntrain_index = np.random.choice(a,replace=False,size = int(n*(1-test_size)))\ntest_index = np.setdiff1d(a,train_index)\nprint(train_index.size)\nprint(test_index.size)","634c3281":"data_train = copy.deepcopy(train_dataset)\ndata_train.image_list = [train_dataset.image_list[i] for i in train_index]\n\ndata_test = copy.deepcopy(train_dataset)\ndata_test.image_list = [train_dataset.image_list[i] for i in test_index]\n\ngen_train = DataLoader(data_train,batch_size=16, shuffle=True)\ngen_test = DataLoader(data_test,batch_size=16, shuffle=True)\nfull_train_generator = DataLoader(train_dataset,batch_size=16, shuffle=True)\nfull_test_generator = DataLoader(test_dataset,batch_size=16, shuffle=True)\n\nprint(len(gen_train))\nprint(len(gen_test))\nprint(len(full_train_generator))\nprint(len(full_test_generator))","28f7a68e":"print(len(train_dataset))\nprint(len(test_dataset))\nprint(len(data_train))\nprint(len(data_test))","a3be8cf7":"model = models.vgg11(pretrained=True)\n\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(dim1, dim2)),                        \n                          ('relu', nn.ReLU()),\n                          ('fc2', nn.Linear(dim2, 5005)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n\nmodel.classifier = classifier\n\ncriterion = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.003)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","6e247feb":"epochs = 14\ntraining_data = full_train_generator\n#training_data = gen_train\n\nx = time.time()\nimage_count = len(training_data)\nupdates = 4\nprogress_printer = int(image_count\/updates)\n\nfor e in range(epochs):\n    running_loss, i = 0, 0\n\n    for image, label in training_data:            \n        label = label_to_id(label)\n        image, label = image.to(device), label.to(device)\n        i +=1 \n        if i % progress_printer == 0:\n            print('{:.0f}% complete'.format(i\/image_count*100))\n            print('Epoch Rate: {}'.format(round((time.time() - x)*updates\/60),2))\n            x = time.time()\n        log_ps = model(image)\n        loss = criterion(log_ps, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    print('epoch {}: loss: {}'.format(e,running_loss))","3b719e7a":"image_path = \"..\/input\/train\/002b4615d.jpg\"\nshowthis = imshow(process_image(image_path))","4805a83a":"image_list = whale_list('w_23a388d')[:1]\nfor img_path in image_list:\n    with Image.open('..\/input\/train\/' + img_path) as img:\n        fig, ax = plt.subplots()\n        ax.imshow(img)","e1d8da6f":"def predict(image_path, model, n=5):\n    with torch.no_grad():\n        model.eval()\n        np_array = process_image(image_path)\n        if np_array.shape[0] == 1:\n            #print(np_array.shape)\n            np_array = np.repeat(np_array[:, :], 3, axis=0)\n            #print(np_array.shape)\n        tensor = torch.from_numpy(np_array)\n        model = model.cuda()\n        inputs = Variable(tensor.float().cuda())\n        inputs = inputs.unsqueeze(0)\n        output = model.forward(inputs)  \n        predictions = torch.exp(output).data.topk(n)\n        probabilities = predictions[0].cpu()\n        classes = predictions[1].cpu()\n        classes_np = classes.numpy()[0]\n        classes = [whale_dict[classes_np[i]] for i in list(range(len(classes_np)))]        \n        return probabilities.numpy()[0], classes\n\ndef predict_image(image_path,n = 5):\n    probabilities, classes = predict(image_path, model)\n    fig = plt.figure(figsize=(8,8))\n    ax1 = plt.subplot2grid((20,10), (0,0), colspan=10, rowspan=10)\n    ax2 = plt.subplot2grid((20,10), (10,2), colspan=5, rowspan=8)\n    image = Image.open(image_path)\n    ax1.imshow(image)\n    y_pos = np.arange(n)\n    ax2.set_yticks(y_pos)\n    ax2.set_yticklabels(classes)\n    ax2.invert_yaxis()\n    ax2.set_xlabel('Probability')\n    ax2.barh(y_pos, probabilities)\n    plt.show()\n    return classes","7f08c67a":"rank = 500\nranked_whales = train.groupby('Id').count().sort_values('Image',ascending = False).reset_index()\nwhale = ranked_whales['Id'][rank-1]\nprint(whale)\n\nprint(ranked_whales[rank-2:rank+1])\n#whale = 'w_23a388d'\n\nfor image_path in whale_list(whale,train.loc[test_index])[:2]:    \n    print(image_path)\n    image_path = '..\/input\/train\/' + image_path\n    x = predict_image(image_path)\n    print(x[0] == whale)\n    print(x)\n    ","e72fc621":"image_list = copy.deepcopy(test_dataset.image_list)\ni = 0\n\njpegs = []\npredictions = []\n\n#for the_jpeg in test_dataset.image_list:\nfor the_jpeg in image_list:  \n    i +=1\n    if i % 1000 == 0:\n        print(i)\n    image_path = '..\/input\/test\/' + the_jpeg\n    x, y = predict(image_path,model)\n    preds = ' '.join(y)\n    jpegs.append(the_jpeg)\n    predictions.append(preds)    \n\njpegs\npredictions\n\nwhale_predictions = pd.DataFrame({'Image':jpegs,'Id':predictions})\nprint(whale_predictions.shape)\nwhale_predictions.head()","434a4be2":"whale_predictions.to_csv('second_submission_attempt.csv',index=False)","3991c1c8":"# **Imports**","39efe94f":"## Show","bd6e9711":"## **Simple Functions and Setup**","fa88e118":"### **Most Popular Whales**","73120f13":"# **Exploratory**","5ba39ff6":"## **Classes and Functions**","715751b2":"### **Custom train_test_split**\nNot sure how to use sklearn.model_selection train_test_split in this instance, since dataset is a list of tuples, so I will create a random indexing on my own","c4617e12":"## **Accuracy View**","dda1fd71":"# **Data Setup**","1b95385c":"# **Model Setup**","8104ffe5":"#old transform\ndims = 256\ntransform = transforms.Compose([transforms.Resize((256,256)),#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                                transforms.ToTensor()])","9dead278":"## Create and Submit Predictions","b69b116b":"# **Train Model**","d6849114":"# **Prediction Functions**"}}