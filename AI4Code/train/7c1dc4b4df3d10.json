{"cell_type":{"c9e71233":"code","61f8cfa9":"code","382c46d1":"code","51846117":"code","87ea77cc":"code","d4973c74":"code","bb73de7d":"code","45d67bae":"code","0fded66e":"code","04b35e33":"code","230d57dd":"code","da75d2fc":"code","6d9b20f7":"code","a4271d89":"code","54aa066f":"code","8bfb672e":"code","1f4aad0d":"code","d834bb2f":"code","1f26ba7b":"code","e2201476":"code","fb396627":"code","858131c0":"code","b2badde4":"code","259b5cb5":"code","f5caf49e":"code","feccdc91":"code","6f882162":"code","882c3519":"code","f636e8a2":"code","10c1ad11":"code","9ed0ff48":"code","db506c2e":"code","d089a71e":"code","13892d8e":"code","c8195513":"code","85e1faca":"code","528f0f96":"code","186ce3ad":"code","7a532ff8":"code","6d19d5d7":"code","dd07cdb2":"code","c146a3fe":"code","d1369da3":"code","c0400392":"code","8f5b0c4c":"code","a560039b":"code","41150446":"code","f8b56cb0":"code","959c4f5c":"code","12ab79f0":"code","78082bbd":"code","4ac98603":"code","afca344e":"code","e2cce761":"code","1dd5825d":"code","15670e60":"code","ed185ec3":"code","85ab2b33":"code","194a7a50":"code","bfd83968":"code","c3a42457":"code","06e94f88":"code","fbfaa9be":"code","5caaa84c":"code","78e4fd80":"code","c3a8dfea":"code","5fb97fd3":"code","352d7431":"code","672c4561":"code","207cc60f":"code","347937d5":"code","aa6efb1d":"code","3ae05cb7":"code","50b93c77":"code","5a5cabf2":"code","1e6908ba":"code","22849423":"code","37970063":"code","21eb66d0":"code","8266a4ef":"code","efdc7f37":"code","86e4fb71":"code","4d2695c8":"code","7291b373":"code","a7535815":"code","98e96316":"code","9b6b6944":"code","b6f95523":"code","04f9823a":"code","7d7916fd":"code","9713fcd5":"code","3d58e9cb":"code","374bb6f6":"code","3286706c":"code","0fd63885":"code","4d10f70c":"code","681e5da0":"code","4f96b855":"code","67ceaceb":"code","2c7f4e64":"code","99a21c68":"code","31f87ace":"code","ffb72cab":"code","08bc1944":"code","7a8f08e0":"code","7585506b":"code","0909d587":"code","f8f9fa75":"code","ad6b4a53":"code","a8752764":"markdown","bdbfd181":"markdown","0cdb428c":"markdown","4cf514ac":"markdown","5a9c62db":"markdown","f815957e":"markdown","ff476cd8":"markdown","d95dad46":"markdown","ca11a4de":"markdown","73ee2caf":"markdown","690907d8":"markdown","51c1f6c4":"markdown","2012f38f":"markdown","53b7cfe5":"markdown","89340154":"markdown","5603a0a7":"markdown","40d25ff4":"markdown","222da28c":"markdown","47c9e510":"markdown","7628e5de":"markdown","178fe62e":"markdown","d22549c9":"markdown","b65a01a3":"markdown","e5f2eb19":"markdown","1e91844f":"markdown"},"source":{"c9e71233":"import warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.arima_model import ARIMA\n\nimport warnings","61f8cfa9":"warnings.filterwarnings('ignore')","382c46d1":"# Plotly and Cufflinks setup\n\n#!pip install plotly\n#!pip install cufflinks\n#!pip install chart_studio\n\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\n\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nprint(__version__) #requires version >= 1.9.0\n\nimport cufflinks as cf\n\n#for Notebooks\ninit_notebook_mode(connected = True)\n\n#for offline use\ncf.go_offline()","51846117":"# from google.colab import drive\n# drive.mount('\/content\/drive')","87ea77cc":"path = \"..\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv\"","d4973c74":"df = pd.read_csv(path,  parse_dates = [\"M-Y\"], low_memory = False, na_values = [\"NaN\", 'NaT', ' -   '])","bb73de7d":"pd.set_option('display.max_columns', None)","45d67bae":"df.head(5)","0fded66e":"len(df)","04b35e33":"df.info()","230d57dd":"df.columns","da75d2fc":"drop_columns_0 = df.columns[-5:]\ndrop_columns_0","6d9b20f7":"df.drop(drop_columns_0, axis = 1, inplace = True)","a4271d89":"drop_columns_1 = [\"item_id\", \"created_at\", \"increment_id\", \"sales_commission_code\", \"Working Date\" , \"BI Status\" , \"Year\", \"Month\", \"Customer Since\", \"FY\"]","54aa066f":"df.drop(drop_columns_1, axis = 1, inplace = True)","8bfb672e":"df = df[['Customer ID', 'sku', 'category_name_1', 'status', 'qty_ordered',  'price', 'grand_total',\n       'discount_amount', ' MV ', 'payment_method', 'M-Y']]","1f4aad0d":"missing = pd.DataFrame(df.isnull().sum())\nmissing.transpose()","d834bb2f":"total_missing_values = df.isnull().sum().sum()\ntotal_missing_values","1f26ba7b":"df.dropna(axis = 0, how = 'any', inplace = True)","e2201476":"#Checking again for missing values\nmissing = pd.DataFrame(df.isnull().sum())\nmissing.transpose()","fb396627":"#Checking again\ntotal_missing_values = df.isnull().sum().sum()\ntotal_missing_values","858131c0":"#Checking again for missing values in ' MV ' col\ndf[' MV '].isnull().sum()#.sum()","b2badde4":"df.head(5)","259b5cb5":"len(df)","f5caf49e":"df['M-Y'].unique()","feccdc91":"df['M-Y'].nunique()","6f882162":"df['M-Y'].value_counts()","882c3519":"df[df['qty_ordered'] == 0]['qty_ordered'].value_counts()","f636e8a2":"df[df['price'] == 0]['price'].value_counts()","10c1ad11":"df[df[' MV '] == '0'][' MV '].value_counts()","9ed0ff48":"df[df['grand_total'] == 0]['grand_total'].value_counts()","db506c2e":"#found 9465 cells containing 0.0 in column 'grand_total'\n#replace 0.0 from corresponding values of ' MV ' column","d089a71e":"def replace_zeros(x, y):\n    if x == 0:\n        return y\n    else: \n        return x","13892d8e":"df.columns","c8195513":"df['grand_total'] = df.apply(lambda z: replace_zeros(z['grand_total'], z[' MV ']), axis = 1)","85e1faca":"#Checking again\ndf[df['grand_total'] == 0]['grand_total'].value_counts()","528f0f96":"df.head(5)","186ce3ad":"len(df)","7a532ff8":"df.columns","6d19d5d7":"df_no_of_orders_cat = pd.crosstab(df['M-Y'], df['category_name_1']) #, margins = True\ndf_no_of_orders_cat","dd07cdb2":"df[df['M-Y'] == '2016-08-01']['category_name_1'].value_counts()","c146a3fe":"df_no_of_orders_cat.plot(figsize = (12, 8), legend = True)\nplt.show()","d1369da3":"# layout = go.Layout(title = \"Number of Orders Per Category\", \n#                    xaxis = {'title': 'Month-Year'}, \n#                    yaxis = {'title': 'No. of Orders'}, \n#                    showlegend = True, \n#                    width = 1000, \n#                    height = 600,)\n\n# df_no_of_orders_cat.iplot(kind = 'line', layout = layout) ","c0400392":"# import plotly.express as px\n\n# fig = px.line(df_no_of_orders_cat)\n\n# fig.update_xaxes(title_text='Month-Year')\n# fig.update_yaxes(title_text='No. of Orders')\n\n# fig.show()","8f5b0c4c":"df = df_no_of_orders_cat","a560039b":"df.head(2)","41150446":"#df['Appliances']","f8b56cb0":"df_new = df[\"Men's Fashion\"]","959c4f5c":"df_new.plot(figsize = (12, 8), legend = True)\nplt.show()","12ab79f0":"df.index","78082bbd":"rolmean = df_new.rolling(window = 12).mean()\nrolstd = df_new.rolling(window = 12).std()","4ac98603":"#rolmean, rolstd","afca344e":"plt.figure(figsize = (10, 6))\norig = plt.plot(df_new, color = 'blue', label = 'Original')\nmean = plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\nstd = plt.plot(rolstd, color = 'green', label = 'Rolling Std')\nplt.legend(loc = 'best')\nplt.title(\"Rolling Mean & Standard Deviation\")\nplt.show(block = False)","e2cce761":"# Need to have p-value around 0.5 or less to have data stationary","1dd5825d":"from statsmodels.tsa.stattools import adfuller","15670e60":"print(\"Results of Diceky-Fuller Test:\\n\")\n\ndftest = adfuller(df_new, autolag = 'AIC')\n\ndfoutput = pd.Series(dftest[0:4], index = ['Test Statistics', 'p-Value', '#Lags Used', 'No. of Obeservations Used'])\n\nfor key, value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\n\ndfoutput","ed185ec3":"#to make data stationary it depends on data sometime you need to take log of data, square of data, or cube of data\n#in this case we already have stationary data as seen in 'Dickey-Fuller Test' and in the plot of 'Rolling Statistics'\n#we are doing following steps only for illustration","85ab2b33":"plt.figure(figsize = (10, 6))\ndata_logScale = np.log(df_new)\nplt.plot(data_logScale)\nplt.show()","194a7a50":"data_logScale","bfd83968":"plt.figure(figsize = (10, 6))\nmovingAverage = data_logScale.rolling(window = 12).mean()\nmovingSTD = data_logScale.rolling(window = 12).std()\nplt.plot(data_logScale, color = 'blue')\nplt.plot(movingAverage, color = 'red', label = 'Moving Average')\nplt.plot(movingSTD, color = 'green', label = 'Moving STD')\nplt.legend(loc = 'best')\nplt.title('Moving Average and Moving STD Or Plotting with log of Data')\nplt.show()","c3a42457":"movingAverage","06e94f88":"data_LogScale_Minus_movingAverage = data_logScale - movingAverage\ndata_LogScale_Minus_movingAverage\n\n#Remove NaN Values\ndata_LogScale_Minus_movingAverage.dropna(inplace = True)\ndata_LogScale_Minus_movingAverage = pd.DataFrame(data_LogScale_Minus_movingAverage)\ndata_LogScale_Minus_movingAverage","fbfaa9be":"#this step is the copy of above steps, just putting all together in a function","5caaa84c":"from statsmodels.tsa.stattools import adfuller\n\ndef test_stationarity(timeseries):\n    \n    # Determine Rolling Statistics\n    \n    average = timeseries.rolling(window = 12).mean()\n    std = timeseries.rolling(window = 12).std()\n    \n    # Plot Rolling Statistics\n    \n    plt.figure(figsize = (10, 6))\n    plt.plot(timeseries, color = 'blue')\n    plt.plot(average, color = 'red', label = 'Average')\n    plt.plot(std, color = 'green', label = 'STD')\n    plt.legend(loc = 'best')\n    plt.title('Average and STD with Data')\n    plt.show()\n    \n    # Perform Dickey-Fuller Test\n    \n    print(\"\\n\")\n    print(\"Results of Dickey-Fuller Test: \\n\")\n    dftest = adfuller(timeseries, autolag = 'AIC')\n\n    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistics', 'p-Value', '#Lags Used', 'No. of Obeservations Used'])\n\n    for key, value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    \n    return dfoutput","78e4fd80":"# pass original data or log of data or square\/cube of data\n# data either in Series or DataFrame\ntest_stationarity(data_LogScale_Minus_movingAverage)","c3a8dfea":"test_stationarity(data_logScale)","5fb97fd3":"test_stationarity(df_new)","352d7431":"test_stationarity(df_new)","672c4561":"#Write reasons which data you are using\n\n# As Seen from above results, we have increasing value of p-value, therefore our original data or data_logScale was sufficient enough to preceed further since it had less p-value\n# We are using data_logScale in this case","207cc60f":"exponentialDecayWeightedAverage = data_logScale.ewm(halflife = 12, min_periods = 0, adjust = True).mean()\n\nplt.figure(figsize = (10, 6))\nplt.plot(data_logScale, color = 'blue')\nplt.plot(exponentialDecayWeightedAverage, color = 'red')\nplt.show()","347937d5":"# The red line in plot above shows data has slightly increased trend","aa6efb1d":"data_logScale_Minus_exponentialDecayWeightedAverage = data_logScale - exponentialDecayWeightedAverage","3ae05cb7":"test_stationarity(data_logScale_Minus_exponentialDecayWeightedAverage)","50b93c77":"# Now we know that our data is stationary","5a5cabf2":"# Now we will shift the values into time series so that we can use it in the forecasting","1e6908ba":"# Subtract the value of Mean from the actual value ","22849423":"# Here we have taken lag of one or just shifted values by 1\ndata_shifted = data_logScale - data_logScale.shift()\n\nplt.figure(figsize = (10, 6))\nplt.plot(data_shifted)\nplt.show()","37970063":"# ARIMA MODEL\n\n# It has 3 (three) models in it\n# 1) AR = Auto Regressive Model\n# 2) MA = Moving Average Model\n# 3) I = Integration\n\n# It takes 3 (three) parameters\n# P, Q, D\n# D=1 (since we shifted by 1)\n# Calculation of P, Q in later steps","21eb66d0":"data_shifted.values","8266a4ef":"# Drop Any NaN values\ndata_shifted.dropna(inplace = True)","efdc7f37":"test_stationarity(data_shifted)","86e4fb71":"# Output in above plot is quite flat\n# So here you Null_Hypothesis or the augmented 'Dickey-Fuller Test' we take the Null Hypotheis is rejected and hence we can say that time series is stationary now","4d2695c8":"# Now lets see the componets of time series","7291b373":"from statsmodels.tsa.seasonal import seasonal_decompose\ntime_series = data_logScale\ndecomposition = seasonal_decompose(time_series, model = 'additive')\n\nobserved = decomposition.observed # Original\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\n# Plot \n\n# plt.figure(figsize = (10, 6))\n# plt.subplot(411)\n# plt.plot(observed, color = 'blue', label = 'Observed')\n# plt.legend(loc = 1)\n\n\n# plt.subplot(412)\n# plt.plot(trend, color = 'black', label = 'Trend')\n# plt.legend(loc = 1)\n\n\n# plt.subplot(413)\n# plt.plot(seasonal, color = 'green', label = 'Seasonal')\n# plt.legend(loc = 1)\n\n\n# plt.subplot(414)\n# plt.plot(residual, color = 'yellow', label = 'Residual')\n# plt.legend(loc = 1)\n\n# plt.tight_layout()\n# plt.show() ","a7535815":"# Plot \nlst_time_series_decompostion = [observed, trend, seasonal, residual]\nstr_lst = ['Observed', 'Trend', 'Seasonal', 'Residual']\nmycolor = ['Black', 'Purple', 'Green', 'Red', 'Blue', 'Orange', 'Grey', 'Violet']\n\nfor i in range(len(lst_time_series_decompostion)):\n    \n    layout = go.Layout(title = \"Time Series-Decomposed: \" + str_lst[i], \n                   xaxis = {'title': 'Month-Year'}, \n                   #yaxis = {'title': ''}, \n                   showlegend = True, \n                   width = 700, \n                   height = 300)\n    \n    lst_time_series_decompostion[i].iplot(kind = 'line', layout = layout, color = mycolor[i]) \n    ","98e96316":"# Check noise if its stationary or not","9b6b6944":"decomposedLogData = residual\ndecomposedLogData.dropna(inplace = True)\ntest_stationarity(decomposedLogData)","b6f95523":"#### ACF will give Q\n#### PACF will give P","04f9823a":"# from statsmodels.tsa.stattools import acf, pacf\n\n# lag_acf = acf(data_shifted, nlags = 11) #nlag must be less than the half of dataset\n# lag_pacf = pacf(data_shifted, nlags = 11, method ='ols')\n\n# # --Plot ACF and PACF Graphs--\n\n# fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n# fig.suptitle('')\n\n# # Plot ACF Graph\n\n# ax1.plot(lag_acf)\n# ax1.axhline(y = 0, linestyle = '--', color = 'grey')\n# ax1.axhline(y = -1.96\/np.sqrt(len(data_shifted)), linestyle = '--', color = 'grey')\n# ax1.axhline(y = 1.96\/np.sqrt(len(data_shifted)), linestyle = '--', color = 'grey')\n# ax1.set_title(\"Auto Correlation\")\n\n# # Plot PACF Graph\n\n# ax2.plot(lag_pacf)\n# ax2.axhline(y = 0, linestyle = '--', color = 'grey')\n# ax2.axhline(y = -1.96\/np.sqrt(len(data_shifted)), linestyle = '--', color = 'grey')\n# ax2.axhline(y = 1.96\/np.sqrt(len(data_shifted)), linestyle = '--', color = 'grey')\n# ax2.set_title(\"Partial Auto Correlation\")\n\n# plt.tight_layout()\n# plt.show()","7d7916fd":"from statsmodels.tsa.stattools import acf, pacf\n\nlag_acf = acf(data_shifted, nlags = 11) #nlag must be less than the half of dataset\nlag_pacf = pacf(data_shifted, nlags = 11, method ='ols')\n\nlag_acf = pd.DataFrame(lag_acf)\nlag_pacf = pd.DataFrame(lag_pacf)\n\n# Plot\n\nlag_acf_pacf = [lag_acf, lag_pacf]\nlst_lag_acf_pacf = ['ACF', 'PACF']\nmycolor = ['Black', 'Purple', 'Green', 'Red', 'Blue', 'Orange', 'Grey', 'Violet']\n\nfor i in range(len(lag_acf_pacf)):\n    \n    layout = go.Layout(title = lst_lag_acf_pacf[i], \n                   #xaxis = {'title': 'Month-Year'}, \n                   #yaxis = {'title': ''}, \n                   showlegend = True, \n                   width = 700, \n                   height = 500, hovermode = 'closest' )\n    \n    lag_acf_pacf [i].iplot(kind = 'line', layout = layout, color = mycolor[i]) ","9713fcd5":"# Now look for x-axis value when y = 0 \n# in both graphs values on x-axis are 1, therefore\n# P, Q = 1 (alsmost)","3d58e9cb":"from statsmodels.tsa.arima_model import ARIMA","374bb6f6":"## AR Model","3286706c":"model = ARIMA(data_logScale, order = (0, 1, 1)) #p = 0, d = 1, q = 1\nresults_AR = model.fit(disp = -1)\n\nplt.figure(figsize = (10, 5))\nplt.plot(data_shifted)\nplt.plot(results_AR.fittedvalues, color = 'red')\nplt.title('Residual Sum of Squares: %.4f'% sum((results_AR.fittedvalues - data_shifted)**2))\nplt.tight_layout()\nplt.show()","0fd63885":"# ideal Rss = 1.0292\n# RSS value in this case is quite high ","4d10f70c":"## MA Model\n\nmodel = ARIMA(data_logScale, order = (1, 1, 0)) #p = 0, d = 1, q = 0\nresults_MA = model.fit(disp = -1)\n\nplt.figure(figsize = (10, 5))\nplt.plot(data_shifted)\nplt.plot(results_MA.fittedvalues, color = 'red')\nplt.title('Residual Sum of Squares: %.4f'% sum((results_MA.fittedvalues - data_shifted)**2))\nplt.tight_layout()\nplt.show()","681e5da0":"# ARIMA Model\nmodel = ARIMA(data_logScale, order = (2, 1, 1)) #p = 1, d = 1, q = 1\nresults_ARIMA = model.fit(disp = -1)\n\nplt.figure(figsize = (10, 5))\nplt.plot(data_shifted)\nplt.plot(results_ARIMA.fittedvalues, color = 'red')\nplt.title('Residual Sum of Squares: %.4f'% sum((results_ARIMA.fittedvalues - data_shifted)**2))\nplt.tight_layout()\nplt.show()","4f96b855":"# Combined RSS must be less\n# in this case RSS too high in any case\n# which is trouble","67ceaceb":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy = True)\npredictions_ARIMA_diff.head()","2c7f4e64":"# Convert to Cummulative Sum\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.head()","99a21c68":"data_logScale.index","31f87ace":"type(data_logScale)","ffb72cab":"predictions_ARIMA = pd.Series(data_logScale)","08bc1944":"predictions_ARIMA = predictions_ARIMA.add(predictions_ARIMA_diff_cumsum, fill_value = 0)\npredictions_ARIMA.head()","7a8f08e0":"# Since we took the log earlier, therefore convert it back\npredictions_ARIMA = np.exp(predictions_ARIMA)","7585506b":"plt.figure(figsize = (10, 5))\nplt.plot(df_new, color = 'blue')\nplt.plot(predictions_ARIMA, color = 'orange')\nplt.tight_layout()\nplt.show()","0909d587":"len(data_logScale)","f8f9fa75":"data_logScale","ad6b4a53":"plt.figure(figsize = (10, 5))\nresults_ARIMA.plot_predict(start = 1, end = 25)\nplt.tight_layout()\nplt.show() \n#results_ARIMA.forecast(steps = 100)\n\n\n# start = 24 # which is the index position in time series\n#end = 24 + 3 # 3 is no. of data points for future","a8752764":"#### Reason: To see the Trends present in Time Series","bdbfd181":"### Re arranging Columns","0cdb428c":"### Creating a function to perform test on data to check its stationarity and plot of 'Rolling statistics' and 'Dickey-Fuller Test'","4cf514ac":"#### Droping Columns = ['Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25']","5a9c62db":"### Test Stationarity","f815957e":"### Forecasting","ff476cd8":"### Calculate difference b\/w Log Scale Data and Moving Average","d95dad46":"# Loading Data","ca11a4de":"**Task 6: Predict and Forecasting**","73ee2caf":"### Perform Dickey-Fuller Test","690907d8":"#### Droping Columns \"items_id\", \"created_at\", \"increment_id\", \"sales_commission_code\", \"Working Date\" , \"BI Status\" , \"Year\", \"Month\", \"FY\"","51c1f6c4":"### Calculate Moving Average with the Same Window","2012f38f":"### Droping off Missing Values Rows","53b7cfe5":"### Determine the rolling statistics","89340154":"### Now DataFrame Without 0(Zeros) and Null Values","5603a0a7":"### Calculate Weighted Average of Time Series","40d25ff4":"### ARIMA Model","222da28c":"### Droping off Un-necessary Columns","47c9e510":"#### Check For Missing Data","7628e5de":"### Plot rolling statistics","178fe62e":"### Estimate the Trend","d22549c9":"### Plot ACF and PACF Graphs","b65a01a3":"# Data Pre-Processing","e5f2eb19":"### Looking for 0 (zeros) in integer or float value columns","1e91844f":"### Calculate diff b\/w logScale and exponentialDecayWeightedAverage"}}