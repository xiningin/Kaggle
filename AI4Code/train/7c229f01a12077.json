{"cell_type":{"fbc63692":"code","4f3f80a7":"code","e1ebeecb":"code","738d85e3":"code","0674b64d":"code","fa3e6dec":"code","bfda94f0":"code","3b3ef30b":"code","35913b51":"code","71b031ff":"code","4421a6bd":"code","e181a8e6":"code","e9cb58cd":"code","5bc7dfdd":"code","c2735f05":"code","a6c37c29":"code","aaf03961":"code","af579ac3":"code","9fe7d66e":"code","292730a0":"code","4c35877f":"code","0d386921":"code","05a5753b":"code","3c745489":"code","7019abf2":"code","aaf88517":"code","21a339c5":"code","387d2546":"code","4156fb16":"code","189574af":"code","6e1792ef":"code","0f01851d":"code","ad0f2d4f":"code","f1420e11":"code","dcdfc9d2":"code","09b0d191":"code","049f74d8":"code","6d75e5f8":"code","a1397848":"code","adcf9f79":"code","e7f36656":"code","711b413c":"code","05941ed3":"code","4e96ae57":"code","be105fba":"code","359a4d4b":"code","a06db5a1":"code","02ee3068":"code","7e8167b7":"markdown","884a6922":"markdown","0cd49e4d":"markdown","9993a38b":"markdown","ab1c86d2":"markdown","c7f7c821":"markdown","53343919":"markdown","d1fa28f0":"markdown","6f7b4506":"markdown","078560f2":"markdown","932d060b":"markdown","0df98b9d":"markdown","66f88ea8":"markdown","2dddd77e":"markdown","c769f9ce":"markdown","7aabab66":"markdown","b38ebf8f":"markdown","6e431f7a":"markdown","32502629":"markdown","f124e2eb":"markdown","7dc94f61":"markdown","1fbbfb40":"markdown","ab8bdbea":"markdown","5df05763":"markdown","d11ef7bb":"markdown","46ebe05d":"markdown","437c7f7e":"markdown","95560b0e":"markdown","89ff7667":"markdown","48779a43":"markdown","28166a91":"markdown","b733e819":"markdown","298b3cc2":"markdown","bc9a59dc":"markdown","6861b052":"markdown","ec091859":"markdown","58fcdec2":"markdown","5df0c800":"markdown","a263c6fa":"markdown","8c8f5412":"markdown","eacfe867":"markdown","db908a2a":"markdown","7b1c6110":"markdown","da363fa9":"markdown","d82b2e24":"markdown","bffc8dba":"markdown","e3ed3181":"markdown","9585f438":"markdown","c1b60407":"markdown","589ded46":"markdown","7233443f":"markdown","b73b6820":"markdown","bc914543":"markdown","dc06005f":"markdown","9c0ce70c":"markdown","5fb80b7b":"markdown"},"source":{"fbc63692":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","4f3f80a7":"#reading data\ndata = pd.read_csv(\"..\/input\/bike-sharing-demand\/train.csv\")\ndata","e1ebeecb":"data.info()","738d85e3":"#reformatting the datetime feature\ndata['datetime'] = pd.to_datetime(data['datetime'],format='%Y-%m-%d %H:%M:%S')\n\n#add new columns from the datetime column\ndata['month'] = data['datetime'].dt.month \ndata['day'] = data['datetime'].dt.day\ndata['hour'] = data['datetime'].dt.hour \ndata['dayofweek'] = data['datetime'].dt.dayofweek \n\ndata = data.drop([\"datetime\"],axis=1)","0674b64d":"data.describe()","fa3e6dec":"fig, ax = plt.subplots(3,2, figsize=(16,15))\n\n#casual customers distribution plots\nsns.distplot(data[\"casual\"],ax=ax[0][0])\ndata.boxplot(\"casual\", ax=ax[0][1])\n\n#registered customers distribution plots\nsns.distplot(data[\"registered\"], ax=ax[1][0])\ndata.boxplot(\"registered\", ax=ax[1][1])\n\n#all customers distribution plots\nsns.distplot(data[\"count\"], ax=ax[2][0])\ndata.boxplot(\"count\", ax=ax[2][1])\n\nfig.show()","bfda94f0":"#normalizing columns(casual, registered and count) using log transform\ndata['casual_log'] = np.log((1+ data['casual']))\ndata['registered_log'] = np.log((1+ data['registered']))\ndata['count_log'] = np.log((1+ data['count']))\n\n#resulting distributing\nfig, ax = plt.subplots(1,3, figsize=(16,5))\ndata.boxplot(\"casual_log\", ax=ax[0])\ndata.boxplot(\"registered_log\", ax=ax[1])\ndata.boxplot(\"count_log\", ax=ax[2])\n\nfig.show()","3b3ef30b":"corr = data.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, center=0,\n            square=True, linewidths=.5)\n","35913b51":"def plot_category_with_user_type(category): \n    ''' \n    function to plot inputed category with its count, casual and registered distributions\n    input: category name\n    output: showing 3 plots for count, casual and registered respectively\n    '''\n    #set plot up\n    fig, ax = plt.subplots(1,3, figsize=(16,5), sharey=True)\n    #title\n    fig.suptitle(\"User Distribution According To \" + category, fontsize=14)\n    #plot 3 plots for count,casual and registered customers \n    sns.barplot(x = category, y = \"count\", data = data, ax = ax[0])\n    sns.barplot(x = category, y = \"casual\", data = data, ax = ax[1])\n    sns.barplot(x = category, y = \"registered\", data = data, ax = ax[2])\n    fig.show()","71b031ff":"plot_category_with_user_type(\"season\")","4421a6bd":"plot_category_with_user_type(\"month\")","e181a8e6":"plot_category_with_user_type(\"day\")","e9cb58cd":"plot_category_with_user_type(\"dayofweek\")","5bc7dfdd":"plot_category_with_user_type(\"hour\")","c2735f05":"plot_category_with_user_type(\"weather\")","a6c37c29":"plot_category_with_user_type(\"windspeed\")","aaf03961":"plot_category_with_user_type(\"temp\")","af579ac3":"plot_category_with_user_type(\"humidity\")","9fe7d66e":"#setting plot up\nfig, ax = plt.subplots(1,7, figsize=(50,7), sharey=True)\n\ndays=[\"Monday\", \"Tuesday\", \"Wednsdays\", \"Thursday\", \"Friday\",\"Saturday\", \"Sunday\"]\n\nfor i in range(7): \n    #split data according to week-day\n    day_data= data[data[\"dayofweek\"] == i]\n    #plot day's dstribution\n    sns.barplot(x = \"hour\", y = \"count\", data = day_data, ax = ax[i]).set_title(\"Booking Distribution by Hours on \" + days[i])\nfig.show()","292730a0":"#calculate the difference between temp and atemp\naverege_diff_atemp_and_temp = data[\"atemp\"] - data[\"temp\"]\n#binarize the resulting values to classify as bigger or smaller\naverege_diff_atemp_and_temp[averege_diff_atemp_and_temp >= 0] = 1\naverege_diff_atemp_and_temp[averege_diff_atemp_and_temp < 0] = 0\n#sum the result to calculate the precentage of atemps higher than temps\nsum(averege_diff_atemp_and_temp) \/ len(averege_diff_atemp_and_temp)","4c35877f":"#calculate the correlation between temp, atemp and humidity\ncorrelation = data[[\"temp\", \"atemp\", \"humidity\"]].corr()\ncorrelation","0d386921":"fig = plt.figure(figsize=(10,5))\nplt1 = fig.add_subplot(121)\nplt2 = fig.add_subplot(122)\n\n#naming plots\nplt1.set_title('atemp vs temp')\nplt2.set_title('atemp vs hyumidiy')\n#ploting plots\nplt1.scatter(data[\"atemp\"], data[\"temp\"])\nplt2.scatter(data[\"atemp\"], data[\"humidity\"])\n\n","05a5753b":"#dropping atemp\ndata = data.drop([\"atemp\"],axis=1)","3c745489":"#calculating correlence array for the attributes bellow\ncorrelation = data[[\"season\",\"temp\", \"weather\", \"windspeed\", \"humidity\"]].corr()\ncorrelation","7019abf2":"plt.scatter(data[\"weather\"], data[\"humidity\"])","aaf88517":"#plotting the holidays distribution excluding the weekends \nholiday_data = data[(data[\"holiday\"]==1) & (data[\"dayofweek\"]<5)]\n\nsns.barplot(x = \"hour\", y = \"count\", data = holiday_data)","21a339c5":"hot_encoded_data = data.join(pd.get_dummies(data[\"season\"], prefix=\"season\")).join(pd.get_dummies(data[\"weather\"], prefix=\"weather\"))\nhot_encoded_data.head()","387d2546":"hot_encoded_data = hot_encoded_data.drop([\"count\", \"registered\",\"casual\"],axis=1)\nhot_encoded_data = hot_encoded_data.drop([\"holiday\", \"dayofweek\"],axis=1)\nhot_encoded_data = hot_encoded_data.drop([\"month\", \"season\", \"weather\", \"windspeed\"],axis=1)","4156fb16":"#importing packages\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler","189574af":"def partition_data(full_data):\n    ''' \n    takes a dataframe and seperates it into train and test data by splitting it by \"day\" \n    input: full dataframe\n    output: x-axis training set\n    output: y-axis training set\n    output: x-axis test set\n    output: x-axis test set    \n    '''\n    #split data by day\n    train_data = full_data[data[\"day\"]<15]\n    test_data = full_data[data[\"day\"]>14]\n\n    #dropping the day column\n    train_data = train_data.drop([\"day\"],axis=1)\n    test_data = test_data.drop([\"day\"],axis=1)\n    \n    #splitting the training data into x and y axises\n    x_train = train_data.drop([\"casual_log\", \"count_log\", \"registered_log\"],axis=1)\n    y_train = train_data[[\"count_log\"]]\n\n    #splitting the test data into x and y axises\n    x_test = test_data.drop([\"casual_log\", \"count_log\", \"registered_log\"],axis=1)\n    y_test = test_data[[\"count_log\"]]\n    \n    return x_train, y_train, x_test, y_test","6e1792ef":"def build_model(data, model, plot = False, tuning_parameter = 1, result= False):\n    '''\n    build and return model and MSE according to the entered keyword\n    input: full dataframe\n    input: model keyword\n    input: boolean value to draw a plot or not -optional-\n    input: tuning parameter for the model\n    output: the model\n    output: MSE value\n    '''\n    #split data using the previous function\n    x_train, y_train, x_test, y_test = partition_data(data)\n    \n    #models dictionary\n    models={\n        \"linear\" : LinearRegression(),\n        \"ridge\" : Ridge(alpha = tuning_parameter),\n        \"knn\" : KNeighborsRegressor(n_neighbors = tuning_parameter),\n        \"decision_tree\" : DecisionTreeRegressor(random_state=42)\n    }\n    \n    #initiate model\n    lModel = models[model]\n    #fit the training data in the model\n    lModel.fit(X = x_train, y = y_train)\n    \n    #predict new values\n    y_predicted=lModel.predict(X= x_test) \n\n    #calculate MSE\n    MSE = mean_squared_error(y_test, y_predicted)\n    \n    #plot real vs predicted values if the plot boolean is true\n    if (plot):\n        plt.figure(figsize=(5, 5))\n        plt.scatter(y_test, y_predicted)\n        plt.ylabel(\"predicted values\")\n        plt.xlabel(\"real values\")\n        #find min and max in the test target values\n        minimum = math.ceil(y_test.min())\n        maximum = math.ceil(y_test.max())\n        #plot a diagonal line accross the scattered plot to better see the difference in values\n        #idealy all points should be on the diagonal line\n        plt.plot( [minimum,maximum],[minimum,maximum], color='red')\n    if (result): return lModel, MSE, y_predicted\n    return lModel, MSE","0f01851d":"def undo_log_transform(data): \n    return (np.floor(np.exp(data) -1))\n","ad0f2d4f":"#build a linear model and plot the result\nmodel, MSE, linear_result = build_model(hot_encoded_data, \"linear\", plot = True, result = True)","f1420e11":"#vlaues predicted from model\nundo_log_transform(linear_result)","dcdfc9d2":"from sklearn.preprocessing import PolynomialFeatures\n\n#set up the polynomial fearues object\npolynomial_fearues = PolynomialFeatures(degree=4, interaction_only=True)\n\npolynomial_fearures_data = hot_encoded_data[[\"workingday\", \"hour\", \"temp\", \"humidity\"]]\n\n#make polynomial features out of the data\npolynomial_fearues = polynomial_fearues.fit_transform(polynomial_fearures_data)\n#turn the result into a dataframe\nintr_features = pd.DataFrame(polynomial_fearues)","09b0d191":"list_of_MSEs = []\nlist_of_thetas = []\n\n#for each column in the polynomial fearues dataset: append it to the data and test the model\nfor (columnName, columnData) in intr_features.iteritems():\n    polynomial_hypothesis_data = hot_encoded_data.drop([\"workingday\", \"hour\", \"temp\", \"humidity\"],axis=1)\n    #appending the column\n    polynomial_hypothesis_data[\"polynomial_factor\"] = columnData\n    \n    #build model and assess it\n    model, MSE = build_model(polynomial_hypothesis_data, \"linear\")\n    \n    list_of_MSEs.append(MSE)\n    list_of_thetas.append(model.coef_)\n    \nlist_of_MSEs","049f74d8":"#partition data to find the best tunning parameter\nx_train, y_train, x_test, y_test = partition_data(hot_encoded_data)\n\n#this object can find the best alpha to be used for this model\nregr_cv = RidgeCV(alphas=[0.1, 1.0, 5.0, 10.0, 20, 25, 30, 40, 50, 100, 200, 500, 1000, 2000])\n\nmodel_cv = regr_cv.fit(x_train, y_train)\nmodel_cv.alpha_","6d75e5f8":"#build ridge model with the found alpha\nmodel, MSE, ridge_result = build_model(hot_encoded_data, \"ridge\", tuning_parameter = 25, plot = True, result = True)\nMSE","a1397848":"#vlaues predicted from model\nundo_log_transform(ridge_result)","adcf9f79":"#prepare data for the model\ntree_data = data.drop([\"month\", \"count\", \"registered\",\"casual\",\"holiday\", \"dayofweek\", \"windspeed\"],axis=1)\n#build and assess model\nmodel, MSE, tree_result =build_model(tree_data, \"decision_tree\", plot = True, result = True)\nMSE","e7f36656":"#vlaues predicted from model\nundo_log_transform(tree_result)","711b413c":"#packages for visuallizing the decision tree\nfrom sklearn import tree\nimport graphviz\nfrom IPython.display import SVG\nfrom IPython.display import display","05941ed3":"#find columns names\ncolumns = tree_data.drop([\"casual_log\", \"count_log\", \"registered_log\", \"day\"],axis=1).columns\n\n#plot each feature with its importance in the model\nplt.figure(figsize=(10, 5))\nplt.bar(columns, model.feature_importances_)\nplt.ylabel(\"importance\")\nplt.xlabel(\"features\")\n","4e96ae57":"#plotting the decision tree\ntree_data = tree.export_graphviz(model, feature_names = columns, filled=True, rounded=True,max_depth=6)\n\ngraph = graphviz.Source(tree_data)\ndisplay(SVG(graph.pipe(format='svg')))","be105fba":"#scalling the target data for the K-nn model\nscaler = StandardScaler()\ngeneral_data = hot_encoded_data[[\"casual_log\", \"count_log\", \"registered_log\"]]\nscaler.fit(general_data)\nscaled = scaler.transform(general_data)\nscaled = pd.DataFrame(data=scaled, columns = general_data.columns)\n\n#turning the target log value into int because K-nn doesn't work with float values\nscaled[\"casual_log\"] = (scaled[\"casual_log\"] * 10) .apply(np.floor)\nscaled[\"registered_log\"] = (scaled[\"registered_log\"] * 10) .apply(np.floor)\nscaled[\"count_log\"] = (scaled[\"count_log\"] * 10) .apply(np.floor)\n\n#join the new columns\ngeneral_data = general_data.join(hot_encoded_data.drop([\"casual_log\", \"count_log\", \"registered_log\"],axis=1))","359a4d4b":"#finding the best k value\nk_values = [3, 4, 5, 6, 7, 8, 9, 10, 15, 30]\n\nMSEs_values =[]\nmodels = []\n\nfor k_value in k_values: \n    #build and assess model\n    model, MSE = build_model(general_data, \"knn\", tuning_parameter = k_value)\n    MSEs_values.append(MSE)\n    models.append(model)\nMSEs_values","a06db5a1":"model, MSE, knn_result = build_model(general_data, \"knn\", tuning_parameter = 7, plot = True, result = True)","02ee3068":"#vlaues predicted from model\nundo_log_transform(knn_result)","7e8167b7":"## Table of Contents\n- [**Ground Truths About Data**](#facts)\n- [**EDA and Feature Engineering**](#EDA)\n    - [Importing packages and reading the data](#import)\n    - [Log Transform](#log)\n    - [Distributions of the bookings according to the features](#features)\n    - [Distribution of booking by Hours and Day-of-Week Together](#dayhour)\n    - [Weather-Related values Collerence](#weather)\n    - [Is the workingday atribute enough?](#workingday)\n    - [Hot-Encoding the Weather and Season attributes](#hot)\n    - [Dropping Useless Columns](#drop)\n- [**Machine Learning Models**](#ML)\n    - [Linear Regression](#linear)\n    - [Linear Regression-polynomial features](#linearp)\n    - [Ridge](#ridge)    \n    - [Decision Tree](#tree)\n    - [K-nn](#knn)\n\n    ","884a6922":" there's a clear connection between the tempreture and the increasing bookings.","0cd49e4d":"### - By Day Of Week <a class=\"anchor\" id=\"weeks\"><\/a>","9993a38b":"<div class=\"alert alert-block alert-info\">\n    <b>let's look at the distibution of bookings in holidays, is it similar to regular days?<\/b>    \n<\/div>","ab1c86d2":"[We've also seen](#weeks) that the distribution among weeks is consistent, and is about the same for all days except for weekends. which is considered in the workday attribute, leads us to believe that: \n<div class=\"alert alert-block alert-success\">\n    <b>there's no need for the dayofweek attribute<\/b>\n<\/div>","c7f7c821":"the distribution is almost consistent regardless of the windspeed except for a couple of outliers.<br>\nWindspeed should be excluded.","53343919":"### - By Weather","d1fa28f0":"*** \n# Machine Learning Models <a class=\"anchor\" id=\"ML\">","6f7b4506":"### - By Windspeed","078560f2":"as seen above, The booking distribution in holidays is very similar to [weekends](#dayhour), and the workingday bolean atribute is taking this variable in account (it's 1 when the day isn't a holiday or a weekend).<br>\n<div class=\"alert alert-block alert-success\">\n    <b>there's no need for the holiday attribute<\/b>\n<\/div>","932d060b":"### Importing packages and reading the data <a class=\"anchor\" id=\"import\"><\/a>","0df98b9d":"<div class=\"alert alert-block alert-info\">\nWeather and Season attributes are categorical, which makes them unacceptable for a lot of models, we will use Hot-encoding to turn these categorical values into binary valueS for each label\n    <\/div>","66f88ea8":"# EDA and Feature Engineering <a class=\"anchor\" id=\"EDA\"><\/a>","2dddd77e":"### Distribution of booking by Hours and Day-of-Week Together <a class=\"anchor\" id=\"dayhour\"><\/a>","c769f9ce":"## Distributions of the bookings according to the features: <a class=\"anchor\" id=\"features\"><\/a>\n - season \n - month\n - day\n - day of the week \n - hour\n - weather \n - windspeed\n - temp\n - humidity\n\nand see how the bookings are distributed into casual and registered for each category\n\n<div class=\"alert alert-block alert-info\">\nFirst let's look at the correlation matrix to get an overview of how the variable are connected\n<\/div>","7aabab66":"the distribution is almost consistent in workdays and peaks on start and end times of typical jobs, but it changes in the weekend and becomes distributed throughout the day peaking in the middle of the day.","b38ebf8f":"## Ridge <a class=\"anchor\" id=\"ridge\">","6e431f7a":"### - By Hour","32502629":"### Log Transform  <a class=\"anchor\" id=\"log\"><\/a>\n#### Let's look at the outliers in casual, registered and count using frequency plots","f124e2eb":"users (registered and casual) show a <b>pattern through the seasons<\/b>, bookings are at their lowest in the spring (season1), they peak in summer and fall(season2+3), and fall a bit in winter(season4).<br>\nmatching results show in the months distribution.\n","7dc94f61":"<div class=\"alert alert-block alert-info\">\n\nthe datetime column is type object, so it needs some engineering\n<\/div>","1fbbfb40":"### Dropping Useless Columns <a class=\"anchor\" id=\"drop\">","ab8bdbea":"## Linear Regression-polynomial features <a class=\"anchor\" id=\"linearp\">","5df05763":"## Weather-Related values Collerence  <a class=\"anchor\" id=\"weather\"><\/a>\n### Let's take a look at \"atemp\" and answer these questions\n- is atemp always bigger than the real tempreture?\n- is there a connection between atemp and humidity? if the answer to the first question is yes can the reason be humidity?\n- should we use it in the models?\n","d11ef7bb":"<div class=\"alert alert-block alert-info\">\nLet's try to use polynomial features to improve the model\n    <\/div>","46ebe05d":"### Hot-Encoding the Weather and Season attributes  <a class=\"anchor\" id=\"hot\"><\/a>","437c7f7e":"<div class=\"alert alert-block alert-success\">\nthese almost normally distributed values will be used in the ML models later in this notebook. \n<\/div>","95560b0e":" - casual users tend to book more when the weather is better\n - registered users surprisingly book consistently except when the weather is \"Light Snow, light rain...\"(number3)\n \n the difference in patterns strengthenes the theory of different purposes between registered and casual users\n ","89ff7667":"[We've previously seen](#months) that the distribution of bookings is consistent throughout the month regardles of the days number which leads us to believe that:\n<div class=\"alert alert-block alert-success\">\n    <b>there's no need for the day attribute<\/b>\n<\/div>","48779a43":"### - By Temp\n","28166a91":"<div class=\"alert alert-block alert-info\">\nThe MSEs values are bigger when using polynomial features than when using simple linear regression, so we will ignore them.\n   <\/div>","b733e819":"by looking at the correlation values and the scatter plot, atemp and temp are clearly correlated while atemp and humidity not correlated at all.\n   <div class=\"alert alert-block alert-success\">\n \n since atemp is highly correlated with temp with a 99% rate, <b>atemp won't be used in building the models<\/b> and will be dropped.\n    <\/div>","298b3cc2":"## Linear Regression <a class=\"anchor\" id=\"linear\">","bc9a59dc":"people tend to rent bikes when the humidity is lower than usual, but the change isn't that drastic and the variance is big","6861b052":"In the next section we will be trying out the following machine learning models: \n - Linear Regression\n - Linear Regression - polynomial features\n - Ridge\n - Descion tree\n - K-nn","ec091859":"- it appears that there's no nulls or missing values in the dataframe\n- it appears that there's some outliers in the (casual, registered and count) columns since the max value is a lot higher than the 75%(quartile) value\n- the rest of the columns appear to be normally distributed\n","58fcdec2":"### By Month","5df0c800":"<b>7<\/b> is the best value for k ","a263c6fa":" - casual users usually use bikes in the middle of the day and consistently peak from 12-6pm\n - registered users bookings peak at 8am and 5-6pm which strenghthens the theory that they use bikes for work rather than leisure.","8c8f5412":"### The distribution is <b>consistent throughout the month<\/b> ","eacfe867":"### - By Humidity","db908a2a":"### By season","7b1c6110":"\n - The number of bookings is consistent in general throughout the week for the company, but there's a slight fall on sunday which is a holiday.<br> \n - There's a pattern among casual non-registering users, there's a peak of usage on saturday and sunday, probably because saturday is the end of the week which means high traffic, and friday is the weekend. \n - There's a pattern among registered users, the booking are consistent throughout the week except fot saturday and sunday, which can be the result of multiple reasons that need to be considered in later research : \n     1. There isn't enough bikes because of the higher demand on bikes by non-registered users near weekends which means more bikes should be introduced to the system.\n     2. Regular users might not be enjoying the experience so much which can result on only using the bikes when flexability and speed are needed rather for leisure.","da363fa9":"## By Day <a class=\"anchor\" id=\"months\"><\/a>","d82b2e24":"### Is there a correlence between the season, temperature, weather, windspeed and the humidity?","bffc8dba":"# Bike Sharing Competition\n### by: Rama Salahat\n***","e3ed3181":"<div class=\"alert alert-block alert-info\">\nit's obvious that the three columns are positively skewed, let's use <b>log transform <\/b> to normalize the distribution a bit.\n<\/div>","9585f438":"<img src=\"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3948\/media\/bikes.png\" alt=\"Bike Sharing Competition\" \/>","c1b60407":"<div class=\"alert alert-block alert-info\">\nas you can see there's no significant correlation between the weather, temperature, weather, windspeed and humidity, so all features will be used in the model\n<\/div>","589ded46":"### Is the workingday atribute enough? (deleting day, dayofweek and holiday) <a class=\"anchor\" id=\"workingday\"><\/a>","7233443f":"## Ground Truths About Data <a class=\"anchor\" id=\"facts\"><\/a>\n\n - seasons column's values stand for: \n1. spring\n2. summer\n3. fall\n4. winter \n\n\n - weather stands for: \n1. Clear, Few clouds, Partly cloudy, Partly cloudy\n2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n4. Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n\n\n - temp - temperature in Celsius\n - atemp - \"feels like\" temperature in Celsius\n - casual - number of non-registered user rentals initiated\n - registered - number of registered user rentals initiated\n - count - number of total rentals\n\n\n\n***","b73b6820":"<div class=\"alert alert-block alert-success\">\nyou can see that there's some <b>slight correlation<\/b> between some values, but the correlation for each feature is too small to make the prediction dependent on one value, which is why a machine learning model is needed.\n<\/div>","bc914543":"\nin this notebook we're using data from https:\/\/www.kaggle.com\/c\/bike-sharing-demand\/overview\nthat precisely tracks hourly bike rental data spanning two years for the first 19 days of each month. <br><br>\nWe're going to do an EDA and feature engineer the data to better fit the following models: \n- simple linear regression\n- ridge regression\n- k-nn\n- decision tree\n\nand try to predict future values for the total count of bikes rented during each hour \n","dc06005f":"## K-NN  <a class=\"anchor\" id=\"knn\">","9c0ce70c":"## Decision Tree  <a class=\"anchor\" id=\"tree\">","5fb80b7b":"<div class=\"alert alert-block alert-success\">\n    so yes,<b> 99%<\/b> of the times atemp is <b>greater<\/b> than the real tempreture!\n    <\/div>"}}