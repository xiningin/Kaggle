{"cell_type":{"55e36b39":"code","b010b8e1":"code","4678672b":"code","0c3c40c2":"code","e9b1ad38":"code","14daf84d":"code","5c4fde7e":"code","515208f9":"code","7bdac70f":"code","2f9f64a1":"code","f2914085":"code","f322faf7":"code","51be35b7":"code","ffdaeef9":"code","b794def4":"code","b6b07e82":"code","1cadb005":"code","e2509c43":"code","44f6714b":"code","8d8f1f98":"code","c01f2107":"code","63bbfaac":"code","d8bebc15":"code","690ffb34":"code","ca04c122":"code","b96b7af1":"code","2cce91a4":"code","c8b9341d":"code","d2b40a12":"code","fa703471":"code","cbd73a4f":"code","87e0f7f1":"code","b3ff36b2":"code","812403b3":"code","b3b9aa87":"code","acdc1a4a":"code","ce06f249":"code","b14cb6e1":"code","e4fe522a":"code","30393de0":"code","d5500ce1":"code","d1d27ab1":"code","593058c5":"code","20748ab4":"code","97453af1":"code","290acea8":"markdown","5b881418":"markdown","11fac71a":"markdown","82ef2538":"markdown","55c6ac52":"markdown","b2d3218f":"markdown","104cf464":"markdown","0cec5bc2":"markdown","14aa923a":"markdown"},"source":{"55e36b39":"#importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","b010b8e1":"#importing dataset\ndf=pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')\ndf.head()","4678672b":"df.shape","0c3c40c2":"df.info()","e9b1ad38":"df.describe()","14daf84d":"df.isnull().sum()\n#There is no null values","5c4fde7e":"sns.pairplot(df,hue='HeartDisease')\n","515208f9":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","7bdac70f":"sns.set_theme(style=\"whitegrid\")\nsns.boxplot(x=\"Age\", data=df, palette=\"Set3\")\nplt.title(\"Age Distribution\")","2f9f64a1":"fig = plt.figure(figsize = (15,20))\nax = fig.gca()\ndf.hist(ax = ax)","f2914085":"df.HeartDisease.value_counts().plot(kind='bar')\nplt.xlabel(\"Heart Diseases or Not\")\nplt.ylabel(\"Count\")\nplt.title(\"Heart Diseases\")\n#Here we can see that dataset is not much imbalanced so there is no need to balance.","f322faf7":"cat = ['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope']","51be35b7":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\ndf[cat] = df[cat].apply(lb.fit_transform)\n","ffdaeef9":"X=df.drop('HeartDisease',axis=1)\nX.head()","b794def4":"y=df['HeartDisease']\ny.head()","b6b07e82":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=0)\n","1cadb005":"X_train.shape","e2509c43":"from sklearn.preprocessing import QuantileTransformer\nscaler=QuantileTransformer()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)","44f6714b":"from sklearn.neighbors import KNeighborsClassifier","8d8f1f98":"knn=KNeighborsClassifier(n_neighbors=5,metric='euclidean',p=2)\nknn.fit(X_train,y_train)","c01f2107":"y_pred=knn.predict(X_test)\ny_pred","63bbfaac":"knn.score(X_test,y_test)","d8bebc15":"from sklearn.metrics import accuracy_score\nfrom sklearn import metrics","690ffb34":"metrics.accuracy_score(y_test,y_pred)","ca04c122":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nmat","b96b7af1":"from sklearn.metrics import classification_report\ntarget_names = ['Heart Diseases', 'Normal']\nprint(classification_report(y_test, y_pred, target_names=target_names))","2cce91a4":"#For selecting K value\nerror_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","c8b9341d":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='red', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","d2b40a12":"#From graph we can see that optimize k value is 16,17,18\n# Now we will train our KNN classifier with this k values\n\nknn=KNeighborsClassifier(n_neighbors=3,metric='euclidean',p=2)\nknn.fit(X_train,y_train)","fa703471":"y_pred=knn.predict(X_test)\ny_pred","cbd73a4f":"knn.score(X_test,y_test)","87e0f7f1":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(mat, annot=True)","b3ff36b2":"from sklearn.metrics import classification_report\ntarget_names = ['Diabetes', 'Normal']\nprint(classification_report(y_test, y_pred, target_names=target_names))","812403b3":"!pip install h2o","b3b9aa87":"import h2o\n# We will be using default parameter Here with H2O init method\nh2o.init()","acdc1a4a":"# Convert to h2o dataframe\nhf = h2o.H2OFrame(df)","ce06f249":"# Data Transform - Split train : test datasets\ntrain, valid = hf.split_frame(ratios = [.80], seed = 1234)\nprint(\"Training Dataset\", train.shape)\nprint(\"Validation Dataset\", valid.shape)","b14cb6e1":"train.head(5)","e4fe522a":"valid.head()","30393de0":"# Identify predictors and response\nfeatureColumns = train.columns\ntargetColumn   = \"HeartDisease\"\nfeatureColumns.remove(targetColumn)","d5500ce1":"import time\nfrom h2o.automl import H2OAutoML\n\n        \n# Run AutoML for YY base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=12, seed=1234,\n                balance_classes = True\n               )\naml.train(x=featureColumns, y=targetColumn, training_frame = train, validation_frame = valid)\n\n","d1d27ab1":"lb = aml.leaderboard\nprint(lb.head(rows = lb.nrows))\n\n# Explain an AutoML object i.e. explain all models\nexa = aml.explain(valid)\n","593058c5":"# Evaluate the best model with testing data.\nmodel = aml.leader ","20748ab4":"!pip install scikit-plot","97453af1":"# For Classification\nimport scikitplot as skplt\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix\n\n# Predict with the best model.\npredicted_y = model.predict(valid[featureColumns])\n\npredicted_data = predicted_y.as_data_frame()\nvalid_dataset = valid.as_data_frame()\n\n# Evaluate the skill of the Trained model\nacc                 = accuracy_score(valid_dataset[targetColumn], np.round(abs(predicted_data['predict'])))\nclassReport         = classification_report(valid_dataset[targetColumn], np.round(abs(predicted_data['predict'])))\nconfMatrix          = confusion_matrix(valid_dataset[targetColumn], np.round(abs(predicted_data['predict']))) \n        \nprint(); print('Testing Results of the trained model: ')\nprint(); print('Accuracy : ', acc)\nprint(); print('Confusion Matrix :\\n', confMatrix)\nprint(); print('Classification Report :\\n',classReport)\n\n# Confusion matrix\nskplt.metrics.plot_confusion_matrix(valid_dataset[targetColumn], np.round(abs(predicted_data['predict'])), figsize=(7,7)); plt.show()","290acea8":"# Data Exploration","5b881418":"  5. Which are most useful variable in classification? Prove using correlation.","11fac71a":"# **Heart Failure Prediction!**\n\nIn this Notebook we will see how to apply KNN and how to use H2o.ai automl library for classification task. If you find this notebook usefull please Upvote!","82ef2538":"6. Quantify goodness of your model and discuss steps taken for improvement.\n\n    For this dataset KNN had archive 87% accuracy. We can further improve accuracy by using bagging and boosting techniques.\n\n7. Can we use KNN for regression also? Why \/ Why not?\n\n    KNN algorithm can be used for both classification and regression problems. The KNN algorithm uses \u2018feature similarity\u2019 to predict the values of any new data points. This means that the new point is assigned a value based on how closely it resembles the points in the training set.\n\n8. Discuss drawbacks of algorithms such as KNN\n  \n    -> It does not work well with large dataset and high dimensional dataset.\n\n    -> Knn is noise sensitive dataset, we need to do feature engineering like outlier removal, handling missing value,etc.\n\n    -> Require high memory \u2013 need to store all of the training data\n\n    -> Given that it stores all of the training, it can be computationally expensive\n","55c6ac52":"\n Now we can plot the distribution of data wrt dependent variable i.e HeartDisease","b2d3218f":"# Data Preprocessing","104cf464":"To select optimize k value we will use elbow method","0cec5bc2":"# Using H2o.ai AutoML","14aa923a":"# Using KNN\n\nK-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm which can be used for both classification as well as regression predictive problems. However, it is mainly used for classification predictive problems in industry. The following two properties would define KNN well \u2212\n\n* Lazy learning algorithm \u2212 KNN is a lazy learning algorithm because it does not have a specialized training phase and uses all the data for training while classification.\n\n* Non-parametric learning algorithm \u2212 KNN is also a non-parametric learning algorithm because it doesn\u2019t assume anything about the underlying data."}}