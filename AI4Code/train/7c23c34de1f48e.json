{"cell_type":{"23d6dc99":"code","e8099160":"code","a90b6009":"code","719a56fa":"code","5cbaa3c3":"code","bea4d50f":"code","49cdb8e2":"code","c886f193":"code","b09f0e4c":"code","4dedb058":"code","79b3fe83":"code","50afca03":"code","fb2ee745":"code","053b8737":"markdown","5134c0fa":"markdown","7a890c65":"markdown","d80714fe":"markdown","4cc5e20a":"markdown","8f902231":"markdown"},"source":{"23d6dc99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('csv'):\n            print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport gc\nimport random\n\nfrom IPython import display as ipd\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport spacy\nfrom spacy import displacy\n\nfrom wordcloud import WordCloud\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","e8099160":"TRAIN_PATH = '..\/input\/feedback-prize-2021\/train\/'\nTEST_PATH = '..\/input\/feedback-prize-2021\/test\/'\n\nsubmission = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')\n## add text file names\ntrain[\"file_path\"] = train[\"id\"].apply(lambda identifier: \"..\/input\/feedback-prize-2021\/train\/\" + identifier + \".txt\")\n\ntrain['discourse_id'] = train['discourse_id'].astype(int)\ntrain['discourse_start'] = train['discourse_start'].astype(int)\ntrain['discourse_end'] = train['discourse_end'].astype(int)\ntrain[\"discourse_len\"] = train[\"discourse_end\"] - train[\"discourse_start\"]\n\ntrain.head(2)","a90b6009":"## distribution of discourse_start and discourse_end by discorse_type\n\nf, (ax1, ax2) = plt.subplots(nrows = 2, ncols = 1, figsize=(16, 8), sharey=True)\nsns.histplot( train, x='discourse_start', ax=ax1, hue=\"discourse_type\", element=\"step\")\nsns.histplot( train, x='discourse_end', ax=ax2, hue=\"discourse_type\", element=\"step\")","719a56fa":"## value counts histograms for discourse_type and discourse_type_num\nf, (ax1, ax2) = plt.subplots(nrows = 2, ncols = 1, figsize=(16, 12))\nsns.histplot( train, x='discourse_type', ax=ax1)\nax1.tick_params(axis='x', rotation=90)\nsns.histplot( train, x='discourse_type_num', ax=ax2)\nax2.tick_params(axis='x', rotation=90)","5cbaa3c3":"f, ax1 = plt.subplots(nrows = 1, ncols = 1, figsize=(16, 6))\nsns.histplot( train, x='discourse_len', ax=ax1)","bea4d50f":"TYPE_COLORS = {\n            'Lead': '#EAE4E9',\n            'Position': '#FFF1E6',\n            'Evidence': '#CDDAFD',\n            'Claim': '#FAD2E1',\n            'Concluding Statement': '#E2ECE9',\n            'Counterclaim': '#BEE1E6',\n            'Rebuttal': '#DFE7FD'\n         }\n\ndef display_text(text_id):\n    ents = []\n    for i, row in train[train['id'] == text_id].iterrows():\n        ents.append({ 'start': int(row['discourse_start']), \n                      'end': int(row['discourse_end']), \n                      'label': row['discourse_type']\n                    })\n\n    with open(TRAIN_PATH + f'{text_id}.txt', 'r') as file: \n        data = file.read()\n\n    doc = { \"text\": data, \"ents\": ents, \"title\": text_id }\n    options = {\"ents\": train.discourse_type.unique().tolist(), \"colors\": TYPE_COLORS}\n    displacy.render(doc, style=\"ent\", options=options, manual=True, jupyter=True)","49cdb8e2":"display_text('423A1CA112E2')","c886f193":"display_text('0000D23A521A')","b09f0e4c":"display_text('008015604AA0')","4dedb058":"def build_text_for_discourse_type(df, discourse_type):\n    text = []\n    for i, row in df[df['discourse_type'] == discourse_type].iterrows():\n        sentence = ' '.join(row['discourse_text'].split())\n        text.append(sentence.split())\n\n    temp = [word for sublist in text for word in sublist]\n    text = ' '.join(temp)\n\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n    filtered_sentence = []\n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n        \n    return ' '.join(filtered_sentence)","79b3fe83":"text = build_text_for_discourse_type( train, 'Claim')\nwordcloud = WordCloud(collocations = False, background_color = 'white').generate(text)\n\nplt.figure(figsize=(16,6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","50afca03":"text = build_text_for_discourse_type( train, 'Evidence')\nwordcloud = WordCloud(collocations = False, background_color = 'white').generate(text)\n\nplt.figure(figsize=(16,6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","fb2ee745":"text = build_text_for_discourse_type( train, 'Counterclaim')\nwordcloud = WordCloud(collocations = False, background_color = 'white').generate(text)\n\nplt.figure(figsize=(16,6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","053b8737":"## Distributions","5134c0fa":"## Visualizing text\n\nthis part based on notebook: https:\/\/www.kaggle.com\/thedrcat\/feedback-prize-eda-with-displacy\n\ntried to implement by hand but this is way better :)\n\nAnother great implementation is here: https:\/\/www.kaggle.com\/robikscube\/student-writing-competition-twitch","7a890c65":"# Feedback Prize - Evaluating Student Writing\n\n## Analyze argumentative writing elements from students grade 6-12\n\n\nAutomatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. ","d80714fe":"## Data Description","4cc5e20a":"The dataset contains argumentative essays written by U.S students in grades 6-12. The essays were annotated by expert raters for elements commonly found in argumentative writing.\n\nTask is to predict the human annotations. You will first need to segment each essay into discrete rhetorical and argumentative elements (i.e., discourse elements) and then classify each element as one of the following:\n\n- Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader\u2019s attention and point toward the thesis\n- Position - an opinion or conclusion on the main question\n- Claim - a claim that supports the position\n- Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n- Rebuttal - a claim that refutes a counterclaim\n- Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n- Concluding Statement - a concluding statement that restates the claims\n\ntrain.csv - a .csv file containing the annotated version of all essays in the training set\n- id - ID code for essay response\n- discourse_id - ID code for discourse element\n- discourse_start - character position where discourse element begins in the essay response\n- discourse_end - character position where discourse element ends in the essay response\n- discourse_text - text of discourse element\n- discourse_type - classification of discourse element\n- discourse_type_num - enumerated class label of discourse element\n- predictionstring - the word indices of the training sample, as required for predictions","8f902231":"## Word cloud"}}