{"cell_type":{"03c8a6f8":"code","758ca22d":"code","09b86d7d":"code","da780d5d":"code","056536fc":"code","1c4d2706":"code","e40b34f8":"code","51c98cb5":"code","0c34ba1b":"code","e552b87f":"code","d93eadbb":"code","35732cc9":"code","9d34b671":"code","10cb5c08":"code","8473abd7":"code","fa608933":"code","6050c233":"code","f2b3d4a9":"code","fda3d6c9":"code","0695d6f0":"code","deaeb40d":"code","56c8e154":"code","95bf2f05":"code","1170131c":"code","911040d3":"code","17171554":"code","dce70303":"code","1fd2d64b":"code","41055797":"code","4a9adcc7":"code","45123237":"code","90140ac3":"code","7fedfaf6":"code","0327cddb":"code","eb38d5d1":"code","6ed16989":"code","0ae65e75":"code","9faac9db":"code","74e3ba9d":"code","40256a29":"markdown","231bfb07":"markdown","b372916a":"markdown","7bcf4146":"markdown","c74e3683":"markdown","64c4d9ad":"markdown","271d5d9e":"markdown","bea374f2":"markdown","41b43e7b":"markdown","7dc64230":"markdown","7d5a21e1":"markdown","279bd23d":"markdown","491708b9":"markdown","018e6d3d":"markdown","af284165":"markdown","da6ca8bc":"markdown","ce927549":"markdown","a472a437":"markdown"},"source":{"03c8a6f8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","758ca22d":"from scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix","09b86d7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da780d5d":"data = pd.read_csv('..\/input\/iris-classifier-with-knn\/Iris.csv')\ndata.shape","056536fc":"data.columns","1c4d2706":"data.head()","e40b34f8":"data.tail()","51c98cb5":"data.describe()","0c34ba1b":"data.isnull().sum()","e552b87f":"sns.boxplot(y=data['SepalLengthCm'])","d93eadbb":"sns.boxplot(y=data['SepalWidthCm'])","35732cc9":"sns.boxplot(y=data['PetalLengthCm'])","9d34b671":"sns.boxplot(y=data['PetalWidthCm'])","10cb5c08":"data['Species'].value_counts()","8473abd7":"data.shape","fa608933":"features = data.drop('Species', axis=1)\ntarget = data['Species']","6050c233":"z = np.abs(stats.zscore(features))\nprint(z)","f2b3d4a9":"threshold = 3\nprint(np.where(z>threshold))","fda3d6c9":"data_new = features[z>threshold]\nprint(data_new)","0695d6f0":"sns.pairplot(data, hue='Species')","deaeb40d":"scale = StandardScaler()","56c8e154":"scale.fit(features)","95bf2f05":"scaled_features=scale.transform(features)","1170131c":"data_new = pd.DataFrame(scaled_features)\ndata_new.head(3)","911040d3":"x_train, x_test, y_train, y_test = train_test_split(data_new, target, test_size=0.25, random_state=45)","17171554":"x_train.shape","dce70303":"x_train.head()","1fd2d64b":"x_test.head()","41055797":"y_train.head()","4a9adcc7":"y_test.head()","45123237":"model = KNeighborsClassifier(n_neighbors=1)","90140ac3":"model.fit(x_train, y_train)","7fedfaf6":"pred = model.predict(x_test)","0327cddb":"pred","eb38d5d1":"confusion_matrix(y_test, pred)","6ed16989":"print(classification_report(y_test, pred))","0ae65e75":"error_rate = []\nfor i in range(1,40):\n    model = KNeighborsClassifier(n_neighbors=i)\n    model.fit(x_train,y_train)\n    pred_i = model.predict(x_test)\n    error_rate.append(np.mean(pred_i!=y_test))","9faac9db":"plt.figure(figsize=(15,6))\nplt.plot(range(1,40),error_rate, color='red',linestyle='dashed', marker='o',markerfacecolor='blue', markersize=8)\nplt.title(\"Elbow Graph\")\nplt.xlabel(\"K-Value\")\nplt.ylabel(\"Error Rate\")","74e3ba9d":"model = KNeighborsClassifier(n_neighbors=21)\n\nmodel.fit(x_train,y_train)\npred = model.predict(x_test)\n\nprint('WITH K=21')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","40256a29":"### Confusion Matrix","231bfb07":"### Pair Plot\nNow, Let's identify the distribution of datapoints based on the multi-dimensional plots as shown below","b372916a":"### Outlier Detection\nZ-Score function in the statistics is used to identify the outliers in your dataset","7bcf4146":"From the visulaization data from Pairplot, we identified that \"Setosa\" species are clearly seperated from the other two. But There is some overlapping in the datapoints between \"Versicolor\" and \"Virginica\"","c74e3683":"### Elbow Method\nTo identify the optimal value of 'K', we need to perform Elbow method.","64c4d9ad":"### Import the Dataset\nHere in this case, we have imported the Iris dataset from Kaggle.","271d5d9e":"### Split the Data\nSo, finally we scaled down the data and the next step is to split the dataset into train and test sets","bea374f2":"### Data Exploration\nNow, in this step, you will need to identify and understand about various parameters in your dataset. Also plot some visualizations to understand about the distribution of your dataset.\n1. Find the Dimensions of your Data\n2. Print the head and tail of your data to understand various features of your dataset\n3. Identify the information about your dataset (like column names, datatypes etc.)\n4. Describe the summary features of your Dataset (Mean, Count, Quantiles etc.)\n5. Plot all the required Visualizations.","41b43e7b":"Now, before treating the outliers, we just look at the Feature description of the target parameter \"Species\". This shows that there are 3 types of species and are of equal in number.\n1. Versicolor = 50\n2. Setosa = 50\n3. Virginica = 50","7dc64230":"Now, Find out if your Dataset has any null values.Because your model will not give you proper accuracy when your data has NA's in them. ","7d5a21e1":"### Data Preprocessing","279bd23d":"Now, Sepal Width Feature looks like it has some outliers in it's data. So, now we have to preprocess these outliers for proper funtioning of the dataset to create a Machine Learning Model","491708b9":"Successfully, we have predicted the values of the test dataset and now, our next task is to know if our model has predicted correctly or not. For knowing this, you have to evaluate your model with various performance metrics like Confusion Matrix and Classification Report.","018e6d3d":"### Scaling\nIt's time for the predictor variables to be scaled down to a common value. We use standard scaler technique because the distribution is Standard Normal Distribution.","af284165":"Seperate the Predictor Variables and the Target Variables","da6ca8bc":"So, from our Exploration, it is observed that a datapoint with ID=16 is an outlier. So, after detecting the outlier you can either remove the outlier datapoint or replace the outlier value with some benchmark value. This process depends on the dataset you are choosing and the type of problem.","ce927549":"So, it looks like our dataset does not have any Missing Values. So now, we will look if there are any outliers in the dataset using the Boxplot Visualizations and identify if we have any outliers in the data.","a472a437":"### Model Train\nOnce after you have splitted the dataset into training and test dataset, our task is to train the model with your training data. Since, I dont know the value of K correctly, I estimate the value of K as 1 and train the model. Later on you can find the value of K using the Elbow method and replace it with K to improve your model accuracy."}}