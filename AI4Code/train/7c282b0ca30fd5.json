{"cell_type":{"49c66931":"code","d1dfa9eb":"code","b79db0bd":"code","c79e48b4":"code","72e743c8":"code","a5c1ed35":"code","df037cd7":"code","e22bfb93":"code","6f2e8d3c":"code","7c8196df":"code","2e170bd8":"code","5d74009e":"code","fa78bc33":"code","03dc4266":"code","23075eea":"code","281fe3c8":"code","18223e2c":"code","8645f099":"code","6771ee9a":"code","79cbf58f":"code","148abd9b":"code","d7803bd2":"code","a3c2bf8b":"code","5317f640":"code","143483a5":"code","216bd7b5":"code","05816a0a":"code","31e4601f":"code","1d72239b":"code","629bb2d8":"markdown","4baea1e8":"markdown","d56f5936":"markdown","e201b283":"markdown","6efe0a16":"markdown","7a20f882":"markdown","eff52e93":"markdown"},"source":{"49c66931":"import gc\nimport os\nimport pickle\nimport random\nimport time\nfrom collections import Counter, defaultdict\nfrom operator import itemgetter\nfrom functools import partial\nfrom pathlib import Path\nfrom psutil import cpu_count\n\nimport numpy as np\nimport pandas as pd\n\nimport librosa\nfrom PIL import Image, ImageOps\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\n\nfrom fastprogress import master_bar, progress_bar","d1dfa9eb":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 666\nseed_everything(SEED)","b79db0bd":"N_JOBS = cpu_count()\nos.environ['MKL_NUM_THREADS'] = str(N_JOBS)\nos.environ['OMP_NUM_THREADS'] = str(N_JOBS)\nDataLoader = partial(DataLoader, num_workers=N_JOBS)","c79e48b4":"# from official code https:\/\/colab.research.google.com\/drive\/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\ndef _one_sample_positive_class_precisions(scores, truth):\n    \"\"\"Calculate precisions for each true class for a single sample.\n\n    Args:\n      scores: np.array of (num_classes,) giving the individual classifier scores.\n      truth: np.array of (num_classes,) bools indicating which classes are true.\n\n    Returns:\n      pos_class_indices: np.array of indices of the true classes for this sample.\n      pos_class_precisions: np.array of precisions corresponding to each of those\n        classes.\n    \"\"\"\n    num_classes = scores.shape[0]\n    pos_class_indices = np.flatnonzero(truth > 0)\n    # Only calculate precisions if there are some true classes.\n    if not len(pos_class_indices):\n        return pos_class_indices, np.zeros(0)\n    # Retrieval list of classes for this sample.\n    retrieved_classes = np.argsort(scores)[::-1]\n    # class_rankings[top_scoring_class_index] == 0 etc.\n    class_rankings = np.zeros(num_classes, dtype=np.int)\n    class_rankings[retrieved_classes] = range(num_classes)\n    # Which of these is a true label?\n    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n    retrieved_class_true[class_rankings[pos_class_indices]] = True\n    # Num hits for every truncated retrieval list.\n    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n    precision_at_hits = (\n            retrieved_cumulative_hits[class_rankings[pos_class_indices]] \/\n            (1 + class_rankings[pos_class_indices].astype(np.float)))\n    return pos_class_indices, precision_at_hits\n\n\ndef calculate_per_class_lwlrap(truth, scores):\n    \"\"\"Calculate label-weighted label-ranking average precision.\n\n    Arguments:\n      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n        of presence of that class in that sample.\n      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n        test's real-valued score for each class for each sample.\n\n    Returns:\n      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n        class.\n      weight_per_class: np.array of (num_classes,) giving the prior of each\n        class within the truth labels.  Then the overall unbalanced lwlrap is\n        simply np.sum(per_class_lwlrap * weight_per_class)\n    \"\"\"\n    assert truth.shape == scores.shape\n    num_samples, num_classes = scores.shape\n    # Space to store a distinct precision value for each class on each sample.\n    # Only the classes that are true for each sample will be filled in.\n    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n    for sample_num in range(num_samples):\n        pos_class_indices, precision_at_hits = (\n            _one_sample_positive_class_precisions(scores[sample_num, :],\n                                                  truth[sample_num, :]))\n        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n            precision_at_hits)\n    labels_per_class = np.sum(truth > 0, axis=0)\n    weight_per_class = labels_per_class \/ float(np.sum(labels_per_class))\n    # Form average of each column, i.e. all the precisions assigned to labels in\n    # a particular class.\n    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) \/\n                        np.maximum(1, labels_per_class))\n    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n    #                = np.sum(precisions_for_samples_by_classes) \/ np.sum(precisions_for_samples_by_classes > 0)\n    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n    #                = np.sum(per_class_lwlrap * weight_per_class)\n    return per_class_lwlrap, weight_per_class","72e743c8":"dataset_dir = Path('..\/input\/freesound-audio-tagging-2019')\npreprocessed_dir = Path('..\/input\/fat2019_prep_mels1')","a5c1ed35":"csvs = {\n    'train_curated': dataset_dir \/ 'train_curated.csv',\n    #'train_noisy': dataset_dir \/ 'train_noisy.csv',\n    'train_noisy': preprocessed_dir \/ 'trn_noisy_best50s.csv',\n    'sample_submission': dataset_dir \/ 'sample_submission.csv',\n}\n\ndataset = {\n    'train_curated': dataset_dir \/ 'train_curated',\n    'train_noisy': dataset_dir \/ 'train_noisy',\n    'test': dataset_dir \/ 'test',\n}\n\nmels = {\n    'train_curated': preprocessed_dir \/ 'mels_train_curated.pkl',\n    'train_noisy': preprocessed_dir \/ 'mels_trn_noisy_best50s.pkl',\n    'test': preprocessed_dir \/ 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n}","df037cd7":"train_curated = pd.read_csv(csvs['train_curated'])\ntrain_noisy = pd.read_csv(csvs['train_noisy'])\ntrain_df = train_curated #pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n#train_df.head()","e22bfb93":"test_df = pd.read_csv(csvs['sample_submission'])\n#test_df.head()","6f2e8d3c":"labels = test_df.columns[1:].tolist()\n#labels","7c8196df":"num_classes = len(labels)\n#num_classes","2e170bd8":"y_train = np.zeros((len(train_df), num_classes)).astype(int)\nfor i, row in enumerate(train_df['labels'].str.split(',')):\n    for label in row:\n        idx = labels.index(label)\n        y_train[i, idx] = 1\n\ny_train.shape","5d74009e":"# with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n#     x_train = pickle.load(curated)\n#     x_train.extend(pickle.load(noisy))\nwith open(mels['train_curated'], 'rb') as curated:\n    x_train = pickle.load(curated)\n\nwith open(mels['test'], 'rb') as test:\n    x_test = pickle.load(test)\n    \nlen(x_train), len(x_test)","fa78bc33":"class FATTrainDataset(Dataset):\n    def __init__(self, mels, labels, transforms, crop=True):\n        super().__init__()\n        self.mels = mels\n        self.labels = labels\n        self.transforms = transforms\n        self.crop = crop\n        \n    def __len__(self):\n        return len(self.mels)\n    \n    def __getitem__(self, idx):\n        image = Image.fromarray(self.mels[idx], mode='RGB')      \n\n        if self.crop:\n            time_dim, base_dim = image.size\n            crop = random.randint(0, time_dim - base_dim)\n            image = image.crop([crop, 0, crop + base_dim, base_dim])\n\n        image = self.transforms(image).div_(255)\n        \n        label = self.labels[idx]\n        label = torch.from_numpy(label).float()\n        \n        return image, label","03dc4266":"class FATTestDataset(Dataset):\n    def __init__(self, fnames, mels, transforms):\n        super().__init__()\n        self.fnames = fnames\n        self.mels = mels\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        new_idx = idx % len(self.fnames)\n        \n        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n        image = self.transforms(image).div_(255)\n\n        fname = self.fnames[new_idx]\n        \n        return image, fname","23075eea":"transforms_dict = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        #transforms.RandomHorizontalFlip(0.5),\n        transforms.ToTensor(),\n    ]),\n}","281fe3c8":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.zeros_(m.bias)\n        \n    def forward(self, x):\n        x_conv1 = self.conv1(x)\n        x = self.conv2(x_conv1)\n        x = F.avg_pool2d(x + x_conv1, 2)\n        return x","18223e2c":"class Classifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv = nn.Sequential(\n            ConvBlock(in_channels=3, out_channels=64),\n            ConvBlock(in_channels=64, out_channels=128),\n            ConvBlock(in_channels=128, out_channels=256),\n            ConvBlock(in_channels=256, out_channels=512),\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(512, 128),\n            nn.PReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.1),\n            nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.mean(x, dim=3)\n        x, _ = torch.max(x, dim=2)\n        x = self.fc(x)\n        return x","8645f099":"Classifier(num_classes=num_classes)","6771ee9a":"test_image = Image.fromarray(x_train[0], mode='RGB')\nprint(test_image.size)\ntest_image","79cbf58f":"del test_image","148abd9b":"import math\nimport torch\nfrom torch.optim import Optimizer\n\n\nclass AdamW(Optimizer):\n    \"\"\"Implements AdamW algorithm.\n\n    It has been proposed in `Fixing Weight Decay Regularization in Adam`_.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n\n    .. Fixing Weight Decay Regularization in Adam:\n    https:\/\/arxiv.org\/abs\/1711.05101\n    \"\"\"\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay)\n        super(AdamW, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError('AdamW does not support sparse gradients, please consider SparseAdam instead')\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = torch.zeros_like(p.data)\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                state['step'] += 1\n\n                # according to the paper, this penalty should come after the bias correction\n                # if group['weight_decay'] != 0:\n                #     grad = grad.add(group['weight_decay'], p.data)\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n                denom = exp_avg_sq.sqrt().add_(group['eps'])\n\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n                step_size = group['lr'] * math.sqrt(bias_correction2) \/ bias_correction1\n\n                p.data.addcdiv_(-step_size, exp_avg, denom)\n\n                if group['weight_decay'] != 0:\n                    p.data.add_(-group['weight_decay'], p.data)\n\n        return loss","d7803bd2":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","a3c2bf8b":"def train_model(x_trn, x_val, y_trn, y_val, train_transforms, model, num_epochs=100, lr=1e-3, batch_size=71, fine_tune=False, weight_file_name='weight_best.pt'):\n    test_batch_size = 1\n    eta_min = 1e-6\n    t_max = 10\n    mixup_alpha = 1.0\n    \n    num_classes = y_train.shape[1]\n    \n    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms, crop=False)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n\n    criterion = nn.BCEWithLogitsLoss().cuda()\n    optimizer = AdamW(params=model.parameters(), lr=lr, weight_decay=lr\/10)\n    if fine_tune:\n        scheduler = ReduceLROnPlateau(optimizer, mode='min')\n    else:\n        scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n    \n\n    best_epoch = -1\n    best_lwlrap = 0.\n\n    for epoch in range(num_epochs):\n        start_time = time.time()\n        model.train()\n        avg_loss = 0.\n\n        for x_batch, y_batch in train_loader:\n            x_batch = x_batch.cuda()\n            y_batch = y_batch.cuda()\n            \n            x_batch, targets_a, targets_b, lam = mixup_data(x_batch, y_batch, mixup_alpha)\n            x_batch, targets_a, targets_b = map(Variable, (x_batch, targets_a, targets_b))\n\n            preds = model(x_batch)\n            loss = mixup_criterion(criterion, preds, targets_a, targets_b, lam)\n            #loss = criterion(preds, y_batch)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            avg_loss += loss.item() \/ len(train_loader)\n\n        model.eval()\n        valid_preds = np.zeros((len(x_val), num_classes))\n        avg_val_loss = 0.\n\n        for i, (x_batch, y_batch) in enumerate(valid_loader):\n            preds = model(x_batch.cuda()).detach()\n            loss = criterion(preds, y_batch.cuda())\n\n            preds = torch.sigmoid(preds)\n            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n\n            avg_val_loss += loss.item() \/ len(valid_loader)\n            \n        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n        lwlrap = (score * weight).sum()\n        \n        log_epoch = epoch % 5 == 0\n        if lwlrap > best_lwlrap:\n            log_epoch = True\n            best_epoch = epoch + 1\n            best_lwlrap = lwlrap\n            torch.save(model.state_dict(), weight_file_name)\n            \n        if log_epoch:\n            elapsed = time.time() - start_time\n            print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n            \n        if fine_tune:\n            scheduler.step(avg_val_loss)\n        else:\n            scheduler.step()\n            \n    return {\n        'best_epoch': best_epoch,\n        'best_lwlrap': best_lwlrap,\n        'weight_file_name' : weight_file_name,\n    }","5317f640":"def pick_best_result(result1, result2):\n    if result2['best_lwlrap'] > result1['best_lwlrap']:\n        return result2\n    else:\n        return result1","143483a5":"test_loader = DataLoader(FATTestDataset(test_df['fname'], x_test, transforms_dict['test']), batch_size=1, shuffle=False)\n\nkf = KFold(n_splits=5, random_state=SEED, shuffle=True)\npredictions = []\nresults = []\nfor train_index, test_index in kf.split(np.arange(len(train_df))):\n    fold = str(len(predictions) + 1)\n    \n    x_trn = list(itemgetter(*train_index)(x_train))\n    y_trn = np.array(list(itemgetter(*train_index)(y_train)))\n    \n    x_val = list(itemgetter(*test_index)(x_train))\n    y_val = np.array(list(itemgetter(*test_index)(y_train)))\n    \n    model = Classifier(num_classes=num_classes).cuda()\n    result1 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), num_epochs=75, batch_size=10, weight_file_name=fold + 'weight_best.pt')\n    print(\"Rough annealing:\")\n    print(result1)\n\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(result1['weight_file_name']))\n    result2 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), num_epochs=35, lr=4e-4, weight_file_name=fold + 'weight_best_tune_stage1.pt')\n    print(\"Fine annealing:\")\n    print(result2)\n\n    best_result = pick_best_result(result1, result2)\n\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(best_result['weight_file_name']))\n    result3 = train_model(x_trn, x_val, y_trn, y_val, transforms_dict['train'], model.cuda(), lr=5e-5, num_epochs=60, fine_tune=True, weight_file_name=fold + 'weight_best_tune_stage2.pt')\n    print(\"Fine tuning:\")\n    print(result3)\n\n    best_result = pick_best_result(best_result, result3)\n    results.append(best_result)\n    model = Classifier(num_classes=num_classes)\n    model.load_state_dict(torch.load(best_result['weight_file_name']))\n    model.cuda()\n    model.eval()\n    \n    all_outputs = []\n    for images, _ in test_loader:\n        preds = torch.sigmoid(model(images.cuda()).detach())\n        all_outputs.append(preds.cpu().numpy())\n    fold_preds = np.concatenate(all_outputs)\n    predictions.append(fold_preds)","216bd7b5":"test_df[labels] = np.mean(np.array(predictions), axis=0)\ntest_df.to_csv('submission_mean.csv', index=False)\ntest_df.head()","05816a0a":"def predict_model(test_fnames, x_test, test_transforms, num_classes, model):\n    batch_size = 1\n\n    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    model.cuda()\n    model.eval()\n\n    all_outputs, all_fnames = [], []\n\n    pb = progress_bar(test_loader)\n    for images, fnames in pb:\n        preds = torch.sigmoid(model(images.cuda()).detach())\n        all_outputs.append(preds.cpu().numpy())\n        all_fnames.extend(fnames)\n\n    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n                              index=all_fnames,\n                              columns=map(str, range(num_classes)))\n    test_preds = test_preds.groupby(level=0).mean()\n\n    return test_preds","31e4601f":"def lwlrap_key(result):\n    return result['best_lwlrap']","1d72239b":"best_result = max(results, key=lwlrap_key)\nprint(best_result)\n\nmodel = Classifier(num_classes=num_classes)\nmodel.load_state_dict(torch.load(best_result['weight_file_name']))\nmodel.cuda()\nmodel.eval()\n\ntest_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, model)\ntest_df[labels] = test_preds.values\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","629bb2d8":"### dataset","4baea1e8":"### model","d56f5936":"* Training notebook.\n* You would need to submit result in the separate one.\n* Unfortunately, I can't reproduce my training -> maybe you would be more lucky...\n\n![image.png](attachment:image.png)","e201b283":"### utils","6efe0a16":"### imports","7a20f882":"### train","eff52e93":"### predict"}}