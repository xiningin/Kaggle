{"cell_type":{"f683ca7a":"code","1c0a73fc":"code","480b2d28":"code","0fb8f438":"code","c4310c7e":"code","26714f11":"code","fae87b27":"code","80a467a4":"code","384780e5":"code","2c1f2027":"code","62175d0f":"code","b46705c3":"code","a8625bfd":"code","7077abeb":"code","e5bf852e":"code","46191c2d":"code","7f753ab7":"code","e22f03d9":"code","d38e21e3":"code","80c3286f":"code","b5a1cae4":"code","7b2b1d9d":"code","d173dbc8":"code","c1aa48ff":"code","224beffd":"code","3d5a6313":"code","65a3b6be":"code","dbe12491":"code","81dd143d":"code","f7ae898c":"code","0dd9824a":"code","2c7ee136":"code","5a21de7f":"code","99dfb6b0":"code","4fd4a366":"code","6157c562":"code","9dc52cd8":"code","235d2b24":"code","c91f7ded":"code","699c6337":"code","b54d4fb9":"markdown","70a4cecf":"markdown","c696864e":"markdown","2e5cf843":"markdown","2480d2ae":"markdown","de5a810d":"markdown","fde6e418":"markdown","5eb4f622":"markdown","2235192c":"markdown","f3e947f2":"markdown","ef168584":"markdown","deea1c99":"markdown","a6a4f491":"markdown","668339ca":"markdown","2d9aee5e":"markdown","07e3e6cf":"markdown","ab065e31":"markdown","8c9d5f55":"markdown","7fc9feb2":"markdown","ceff5c99":"markdown"},"source":{"f683ca7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory  \n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c0a73fc":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import r2_score\n!pip install catboost\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nimport xgboost as xgb\n!pip install xgboost","480b2d28":"df = pd.read_csv('..\/input\/craigslist-carstrucks-data\/vehicles.csv')","0fb8f438":"df.head()","c4310c7e":"fig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","26714f11":"del df['url']\ndel df['region_url']\ndel df['vin']\ndel df['title_status']\ndel df['size']\ndel df['image_url']\ndel df['county']\ndel df['id']\ndel df['state']\ndel df['long']\ndel df['lat']\ndel df['description']\ndel df['region']","fae87b27":"fig, ax = plt.subplots(figsize=(14,10))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","80a467a4":"df = df.dropna()","384780e5":"df.drop(df[df.price.values == 0].index, inplace = True)\ndf.drop(df[df.year.values > 2019].index, inplace = True)\ndf.drop(df[df.odometer.values > 55000].index, inplace = True)\ndf.price.dropna(axis = 0, inplace = True)\ndf.drop(df[df.price.values < 700].index, inplace = True)","2c1f2027":"df['year'] = (df['year']-1900).astype(int)\ndf['odometer'] = df['odometer'].astype(int)","62175d0f":"df = df[df['price'] > 1000]\ndf = df[df['price'] < 40000]\n# Rounded ['odometer'] to 5000\ndf['odometer'] = df['odometer'] \/\/ 5000\ndf = df[df['year'] > 110]","b46705c3":"import string\n# realization preprocessing\ndef preprocess(doc):\n    try:\n        # lower the text\n        doc = doc.lower()\n        # remove punctuation, spaces, etc.\n        for p in string.punctuation + string.whitespace:\n            doc = doc.replace(p, ' ')\n        # remove extra spaces, merge back\n        doc = doc.strip()\n        doc = ' '.join([w for w in doc.split(' ') if w != ''])\n    except:\n        pass\n    return doc","a8625bfd":"for colname in df.select_dtypes(include = np.object).columns:\n    df[colname] = df[colname].map(preprocess)\ndf.head()","7077abeb":"df = df[:50000]","e5bf852e":"columns = ['manufacturer', 'fuel', 'type', 'transmission', 'drive', 'paint_color', 'model', 'cylinders', 'condition']","46191c2d":"le = LabelEncoder()\nfor col in columns:\n    if col in df.columns:\n        le.fit(list(df[col].astype(str).values))\n        df[col] = le.transform(list(df[col].astype(str).values))","7f753ab7":"scaler = StandardScaler()\ndf = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)","e22f03d9":"df.corr()","d38e21e3":"# sample data for best results\ndf = df.sample(frac=1).reset_index(drop=True)","80c3286f":"y = df['price']\ny","b5a1cae4":"del df['price']","7b2b1d9d":"X_classic = df","d173dbc8":"X_classic","c1aa48ff":"X_train_classic, X_test_classic, y_train, y_test = train_test_split(X_classic, y, test_size=0.20)","224beffd":"X_train_classic.shape, X_test_classic.shape","3d5a6313":"%%time\nreg = LinearRegression().fit(X_train_classic, y_train)","65a3b6be":"predictions = reg.predict(X_test_classic)","dbe12491":"print(metrics.r2_score(y_test, predictions))","81dd143d":"print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","f7ae898c":"%%time\nalphas = np.linspace(1, 1000, 100)\n\nweights = np.empty((len(X_classic.columns), 0))\nfor alpha in alphas:\n    ridge_regressor = Ridge(alpha)\n    ridge_regressor.fit(X_train_classic, y_train)\n    weights = np.hstack((weights, ridge_regressor.coef_.reshape(-1, 1)))\nplt.plot(alphas, weights.T)\nplt.xlabel('regularization coef')\nplt.ylabel('weight value')\nplt.show()","0dd9824a":"ridge = Ridge(alpha = 1)\nridge.fit(X_train_classic, y_train)\npredictions = ridge.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","2c7ee136":"lasso = Lasso(alpha = 1)\nlasso.fit(X_train_classic, y_train)\npredictions = lasso.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","5a21de7f":"SVR = SVR()\nSVR.fit(X_train_classic, y_train)\npredictions = SVR.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","99dfb6b0":"sgd = SGDRegressor(alpha = 0.002004008016032064, penalty = 'l2')\nsgd.fit(X_train_classic, y_train)\npredictions = sgd.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","4fd4a366":"decision_tree = DecisionTreeRegressor()\ndecision_tree.fit(X_train_classic, y_train)\npredictions = decision_tree.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","6157c562":"rnd_forest_reg = RandomForestRegressor(max_depth = 14, min_samples_split = 2, n_estimators = 1000)\nrnd_forest_reg.fit(X_train_classic, y_train)\npredictions = rnd_forest_reg.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","9dc52cd8":"Ada_Boost = AdaBoostRegressor()\nAda_Boost.fit(X_train_classic, y_train)\npredictions = Ada_Boost.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","235d2b24":"xbg_reg = xgb.XGBRegressor(max_depth = 7, learning_rate = 0.1, n_estimators = 130, reg_lambda = 0.5)\nxbg_reg.fit(X_train_classic, y_train)\npredictions = xbg_reg.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","c91f7ded":"from catboost import CatBoostRegressor, Pool","699c6337":"model = CatBoostRegressor(iterations=15000, \n                           task_type=\"GPU\",\n                           devices='0:1')\nmodel.fit(X_train_classic,\n          y_train,\n          verbose=False)\n\npredictions = model.predict(X_test_classic)\nprint(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint('R2: ', metrics.r2_score(y_test, predictions))","b54d4fb9":"#### Catboost","70a4cecf":"#### Lower the text","c696864e":"#### Look null values in dataset and delete unnecessary data","2e5cf843":"### Decision tree, random forest and different boost","2480d2ae":"#### Clip the dataset","de5a810d":"#### Linear regression","fde6e418":"#### Ridge","5eb4f622":"### Train-test split","2235192c":"### Classic algorithms","f3e947f2":"#### Delete anomaly values","ef168584":"#### Lasso","deea1c99":"#### SVR","a6a4f491":"### Import libraries","668339ca":"#### Random forest","2d9aee5e":"#### Label encoding","07e3e6cf":"#### SGD","ab065e31":"#### Decision tree","8c9d5f55":"#### AdaBoost Regressor","7fc9feb2":"### Preprocessing","ceff5c99":"#### XGBoost"}}