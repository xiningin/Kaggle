{"cell_type":{"5e14adbe":"code","92608caf":"code","ebf5dd78":"code","4b1c8534":"code","84371373":"code","06affb9b":"code","f4de0773":"code","2e7a6ac6":"code","d3f4990e":"code","c73773ca":"code","058603f3":"code","eb2c1fc2":"code","9f038f8e":"code","32ba7a44":"code","5e0ce2cc":"code","3ab3a361":"code","bb2661d5":"code","09752d63":"code","41d1bc4f":"code","6fe9fdc4":"code","842c90f4":"code","249ba3ef":"code","bcd25b71":"code","189115b2":"code","c560bc2f":"markdown","4b30d944":"markdown","0a50f83a":"markdown","8fe27535":"markdown","9b7c5bdf":"markdown","4a3006b5":"markdown","12ab4b90":"markdown","3aae2848":"markdown","c22a7de4":"markdown","6d813c91":"markdown","a491c860":"markdown","0c2f7532":"markdown","86f357ba":"markdown","3706b2c1":"markdown","27a625aa":"markdown","239a0737":"markdown","0856b2cf":"markdown","793e291e":"markdown","312166bb":"markdown"},"source":{"5e14adbe":"import sys\nimport pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib\nimport keras\n\nprint('Python: {}'.format(sys.version))\nprint('Pandas: {}'.format(pd.__version__))\nprint('Numpy: {}'.format(np.__version__))\nprint('Sklearn: {}'.format(sklearn.__version__))\nprint('Matplotlib: {}'.format(matplotlib.__version__))\n\n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix","92608caf":"df=pd.read_csv(\"..\/input\/diabetes.csv\")","ebf5dd78":"#Describe the dataset\ndf.describe()","4b1c8534":"df[df['Glucose'] == 0]","84371373":"df.info()","06affb9b":"df.duplicated().sum()\ndf.drop_duplicates(inplace=True)","f4de0773":"df.info()","2e7a6ac6":"columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n\nfor col in columns:\n    df[col].replace(0, np.NaN, inplace=True)\n    \ndf.describe()","d3f4990e":"df.info()","c73773ca":"df.dropna(inplace=True)\n\n# summarize the number of rows and columns in df\ndf.describe()","058603f3":"df.info()","eb2c1fc2":"dataset = df.values\nprint(dataset.shape)","9f038f8e":"X = dataset[:,0:8]\nY = dataset[:, 8].astype(int)","32ba7a44":"print(X.shape)\nprint(Y.shape)\nprint(Y[:5])","5e0ce2cc":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X)","3ab3a361":"print(scaler)","bb2661d5":"X_standardized = scaler.transform(X)\n\ndata = pd.DataFrame(X_standardized)\ndata.describe()","09752d63":"from sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","41d1bc4f":"# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, verbose = 1)\n\n# define the grid search parameters\nbatch_size = [10, 20, 40]\nepochs = [10, 50, 100]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","6fe9fdc4":"# import necessary packages\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(neuron1, neuron2):\n    # create model\n    model = Sequential()\n    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n\n# define the grid search parameters\nneuron1 = [4, 8, 16]\nneuron2 = [2, 4, 8]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","842c90f4":"y_pred = grid.predict(X_standardized)","249ba3ef":"print(y_pred.shape)","bcd25b71":"print(y_pred[:5])","189115b2":"from sklearn.metrics import classification_report, accuracy_score\n\nprint(accuracy_score(Y, y_pred))\nprint(classification_report(Y, y_pred))","c560bc2f":"**DataFrame where the Glucose concentration of a patient is pulled to 0**","4b30d944":"**Import necessary sklearn and keras packages**","0a50f83a":"**Normalize the data using sklearn StandardScaler**","8fe27535":"**Removing the Duplicates**","9b7c5bdf":"# Breakdown of this notebook:\n1. **Importing Libraries**\n2. **Loading the dataset:** Load the data and import the libraries\n3. **Data Cleaning:** <br>\n - Deleting redundant columns.\n - Renaming the columns.\n - Dropping duplicates.\n - Cleaning individual columns.\n - Remove the NaN values from the dataset\n - Some Transformations\n3. **Traininig the Model**\n4. **Generate a Classification Report**","4a3006b5":"**Loading the Dataset**","12ab4b90":" # <font color='green'>Please upvote if you found this helpful :)<\/font>","3aae2848":"**Do a grid search to find the optimal number of neurons in each hidden layer**","c22a7de4":"**Do a grid search for the optimal batch size and number of epochs**","6d813c91":"**Generate predictions with optimal hyperparameters**","a491c860":"<h3>Importing Libraries<\/h3>","0c2f7532":"**Convert dataframe to numpy array**","86f357ba":"**Drop rows with missing values**","3706b2c1":"<h2>Generate a classification report<\/h2>","27a625aa":"**Transform and display the training data**","239a0737":"# Pima Indians Diabetes","0856b2cf":"## Training the Model","793e291e":"**Preprocess the data, mark zero values as NaN and drop**","312166bb":"**Split into input (X) and an output (Y)**"}}