{"cell_type":{"3c790a80":"code","8f42a3f4":"code","4479e72c":"code","56e86e7f":"code","a441fc35":"code","a4943165":"code","6b905046":"code","95c891fc":"code","a56ab2e2":"code","922568fa":"code","94590196":"code","1c76da9a":"code","ed587a44":"code","23079a13":"code","ef79da9c":"code","f1c04efe":"code","3d46f77b":"code","aa289342":"code","96699ef1":"code","29ebbb69":"code","410d31f0":"code","3ceee2bf":"code","4d27134c":"code","c66f80fc":"code","159e6402":"code","99649491":"code","a1c51007":"code","96b80002":"code","34e0e9ba":"markdown","31cad717":"markdown","fd9e82c8":"markdown","1b9dd401":"markdown","8be2be2a":"markdown","984bd483":"markdown","47dee5ab":"markdown","0372de63":"markdown","cae4adb9":"markdown","7e13b825":"markdown","c27ebe66":"markdown","ea5f0274":"markdown"},"source":{"3c790a80":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc,os,sys\n\nfrom sklearn import metrics, preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.feature_selection import RFE, RFECV, VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.svm import NuSVC\n\nsns.set_style('darkgrid')\npd.options.display.float_format = '{:,.3f}'.format\n\nprint(os.listdir(\"..\/input\"))","8f42a3f4":"%%time\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(train.shape, test.shape)","4479e72c":"train.head()","56e86e7f":"null_cnt = train.isnull().sum().sort_values()\nprint('null count:', null_cnt[null_cnt > 0])","a441fc35":"c = train['target'].value_counts().to_frame()\nc.plot.bar()\nprint(c)","a4943165":"fig, ax = plt.subplots(1, 3, figsize=(16,3), sharey=True)\n\ntrain['muggy-smalt-axolotl-pembus'].hist(bins=50, ax=ax[0])\ntrain['dorky-peach-sheepdog-ordinal'].hist(bins=50, ax=ax[1])\ntrain['slimy-seashell-cassowary-goose'].hist(bins=50, ax=ax[2])","6b905046":"for col in train.columns:\n    unicos = train[col].unique().shape[0]\n    if unicos < 1000:\n        print(col, unicos)","95c891fc":"train['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))\n#test['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))","a56ab2e2":"print(train['wheezy-copper-turtle-magic'].describe())\nprint()\nprint('unique value count:', train['wheezy-copper-turtle-magic'].nunique())","922568fa":"numcols = train.drop(['id','target','wheezy-copper-turtle-magic'],axis=1).select_dtypes(include='number').columns.values","94590196":"pca = PCA()\n#pca.fit(train[list(numcols) + ['wheezy-copper-turtle-magic']])\npca.fit(train[numcols])\nev_ratio = pca.explained_variance_ratio_\nev_ratio = np.hstack([0,ev_ratio.cumsum()])\n\nplt.xlabel('components')\nplt.plot(ev_ratio)\nplt.show()","1c76da9a":"X_subset = train[train['wheezy-copper-turtle-magic'] == 0][numcols]\n\npca.fit(X_subset)\nev_ratio = pca.explained_variance_ratio_\nev_ratio = np.hstack([0,ev_ratio.cumsum()])\n\nplt.xlabel('components')\nplt.plot(ev_ratio)\nplt.show()","ed587a44":"from sklearn.neighbors import KNeighborsClassifier\n\nX_subset = train[train['wheezy-copper-turtle-magic'] == 0][numcols]\nY_subset = train[train['wheezy-copper-turtle-magic'] == 0]['target']\n\nfor k in range(2, 10):\n    knc = KNeighborsClassifier(n_neighbors=k)\n    knc.fit(X_subset, Y_subset)\n    score = knc.score(X_subset, Y_subset)\n    print(\"[{}] score: {:.2f}\".format(k, score))","23079a13":"all_data = train.append(test, sort=False).reset_index(drop=True)\ndel train, test\ngc.collect()\n\nall_data.head()","ef79da9c":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","f1c04efe":"corr_matrix = all_data.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.95)]\ndel upper\n\ndrop_column = all_data.columns[to_drop]\nprint('drop columns:', drop_column)\n#all_data.drop(drop_column, axis=1, inplace=True)","3d46f77b":"X_train = all_data[all_data['target'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['target'].isnull()].drop(['target'], axis=1).reset_index(drop=True)\ndel all_data\ngc.collect()\n\n# drop ID_code\nX_train.drop(['id'], axis=1, inplace=True)\nX_test_ID = X_test.pop('id')\n\nY_train = X_train.pop('target')\n\nprint(X_train.shape, X_test.shape)","aa289342":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nsplits = 11\n\nfor i in range(512):\n    train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n    train2_y = Y_train[X_train['wheezy-copper-turtle-magic'] == i]\n    test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5)\n    train2 = sel.fit_transform(train2)\n    test2 = sel.transform(test2)    \n    \n    skf = StratifiedKFold(n_splits=splits, random_state=42)\n    for train_index, test_index in skf.split(train2, train2_y):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_index], train2_y.iloc[train_index])\n        oof_preds[idx1[test_index]] = clf.predict_proba(train2[test_index])[:,1]\n        sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","96699ef1":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","29ebbb69":"len(X_train[(oof_preds > 0.3) & (oof_preds < 0.7)])","410d31f0":"X_train = X_train[(oof_preds <= 0.3) | (oof_preds >= 0.7)]\nY_train = Y_train[(oof_preds <= 0.3) | (oof_preds >= 0.7)]","3ceee2bf":"X_test_p1 = X_test[(sub_preds <= 0.01)].copy()\nX_test_p2 = X_test[(sub_preds >= 0.99)].copy()\nX_test_p1['target'] = 0\nX_test_p2['target'] = 1\nprint(X_test_p1.shape, X_test_p2.shape)\n\nY_train = pd.concat([Y_train, X_test_p1.pop('target'), X_test_p2.pop('target')], axis=0)\nX_train = pd.concat([X_train, X_test_p1, X_test_p2], axis=0)\nY_train.reset_index(drop=True, inplace=True)\nX_train.reset_index(drop=True, inplace=True)","4d27134c":"_='''\n'''\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nfor i in range(512):\n    train_f = (X_train['wheezy-copper-turtle-magic'] == i)\n    test_f = (X_test['wheezy-copper-turtle-magic'] == i)\n    X_train_sub = X_train[train_f][numcols]\n    Y_train_sub = Y_train[train_f]\n    X_test_sub = X_test[test_f][numcols]\n\n    lda = LDA(n_components=1)\n    lda.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'lda'] = lda.transform(X_train_sub).reshape(-1)\n    X_test.loc[test_f, 'lda'] = lda.transform(X_test_sub).reshape(-1)\n    \n    knc = KNeighborsClassifier(n_neighbors=3)\n    knc.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'knc'] = knc.predict_proba(X_train_sub)[:,1]\n    X_test.loc[test_f, 'knc'] = knc.predict_proba(X_test_sub)[:,1]\n","c66f80fc":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nsplits = 11\n\nfor i in range(512):\n    train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n    train2_y = Y_train[X_train['wheezy-copper-turtle-magic'] == i]\n    test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5)\n    train2 = sel.fit_transform(train2)\n    test2 = sel.transform(test2)    \n    \n    skf = StratifiedKFold(n_splits=splits, random_state=42)\n    for train_index, test_index in skf.split(train2, train2_y):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_index], train2_y.iloc[train_index])\n        oof_preds[idx1[test_index]] = clf.predict_proba(train2[test_index])[:,1]\n        sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","159e6402":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","99649491":"submission = pd.DataFrame({\n    'id': X_test_ID,\n    'target': sub_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","a1c51007":"submission['target'].hist(bins=25, alpha=0.6)\nprint(submission['target'].sum() \/ len(submission))","96b80002":"submission.head()","34e0e9ba":"### target","31cad717":"# Feature engineering","fd9e82c8":"# Submit","1b9dd401":"# Predict","8be2be2a":"# Prepare","984bd483":"### Add pseudo labeled data","47dee5ab":"### KNeighborsClassifier","0372de63":"### PCA","cae4adb9":"# Data analysis","7e13b825":"### 'wheezy-copper-turtle-magic'","c27ebe66":"### any feature","ea5f0274":"# Load data"}}