{"cell_type":{"5cf8a0b8":"code","dff2932f":"code","ae5eb156":"code","7e5e034a":"code","c0cb8642":"code","8d2a5dd8":"code","028a733b":"code","5a01ec7c":"code","e6f52b2f":"code","ce4a139c":"code","f702b3bc":"code","6d7aa67d":"code","187b6162":"code","6b5b10c4":"code","47f1e2fb":"markdown","ab18c4f2":"markdown","7c310d73":"markdown","acb8eac7":"markdown","bd42532e":"markdown","923d20ef":"markdown"},"source":{"5cf8a0b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dff2932f":"# create the training & test sets\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(\"train.shape:\", train.shape)\nprint(\"test.shape:\", test.shape)","ae5eb156":"X_train = train.iloc[:,1:].values.astype('float32') # all pixel values\nY_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","7e5e034a":"#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\nX_train, X_test = X_train \/ 255.0, X_test \/ 255.0","c0cb8642":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 2)","8d2a5dd8":"print(\"X_train.shape:\", X_train.shape)\nprint(\"X_val.shape:\", X_val.shape)\nprint(\"Y_train.shape:\", Y_train.shape)\nprint(\"Y_val.shape:\", Y_val.shape)\nprint(\"X_test.shape:\", X_test.shape)","028a733b":"# In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (5,5), activation = 'relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(32, (5,5), activation = 'relu'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","5a01ec7c":"model.summary()","e6f52b2f":"model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])","ce4a139c":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy', \n                                            patience = 3, \n                                            verbose = 1, \n                                            factor = 0.5, \n                                            min_lr = 0.00001)\nepochs = 30\nbatch_size = 86","f702b3bc":"# With data augmentation to prevent overfitting\ndatagen = ImageDataGenerator(\n        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip = False)  # randomly flip images\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_train)","6d7aa67d":"# fits the model on batches with real-time data augmentation\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size = batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, \n                              steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                              callbacks = [learning_rate_reduction])","187b6162":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.title('Training and validation accuracy')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Accuracy\", \"Validation Accuracy\"])\n\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.title('Training and validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Loss\", \"Validation Loss\"])\n\nplt.figure()","6b5b10c4":"predictions = model.predict_classes(X_test, verbose = 0)\nsubmissions = pd.DataFrame({\"ImageId\": list(range(1, len(predictions) + 1)), \"Label\": predictions})\nsubmissions.to_csv(\"cnn_output.csv\", index = False, header = True)","47f1e2fb":"# Visualize the model","ab18c4f2":"# Compile the model","7c310d73":"# Set CNN model","acb8eac7":"# Fit the model","bd42532e":"# Data augmentation","923d20ef":"# Output"}}