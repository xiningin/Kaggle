{"cell_type":{"9b3e7af5":"code","5f60f4d0":"code","5fd13735":"code","b73e8c80":"code","1b09bec0":"code","5e117412":"code","a99b4f2e":"code","1c2a3a9c":"code","6409924d":"code","df54cb6b":"code","d9cec058":"code","d88afb6b":"code","bc51499e":"code","15267a77":"code","8fa272a1":"code","ef2021bc":"code","8d6583c5":"code","d2c60c50":"code","f6794ee7":"code","ef3f275a":"code","5a799e3d":"code","c9603076":"code","e4199d36":"code","aa29d7bf":"code","cdd9c8ea":"code","40ff9fe4":"code","c001c846":"code","1c644107":"code","ab67467f":"code","0de12d20":"code","2891166f":"code","3986547c":"code","db30fc70":"code","faa60271":"code","2993049e":"code","5286de46":"code","8fe89e44":"code","7b7e2774":"code","637d3c0b":"code","f5d7d639":"code","36b4a132":"code","9cb2d300":"code","6a07c924":"code","25593c0f":"markdown","1b7f29a5":"markdown","6a9ad643":"markdown","8f5f471b":"markdown","34e52cc6":"markdown","d373f0b8":"markdown"},"source":{"9b3e7af5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f60f4d0":"df_train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","5fd13735":"df_train.head(5)","b73e8c80":"df_train.info()","1b09bec0":"df_train.describe().transpose()","5e117412":"df_train.isnull().count()","a99b4f2e":"import seaborn as sns","1c2a3a9c":"sns.countplot(df_train['Survived'],data=df_train,hue='Sex',palette='coolwarm')","6409924d":"df_train.drop(['Cabin','Name','Ticket'],axis=1,inplace=True)\n","df54cb6b":"df_train","d9cec058":"df_train.replace(['male'],1,inplace=True)\ndf_train.replace(['female'],0,inplace=True)","d88afb6b":"df_train","bc51499e":"df_train.replace(['S'],0,inplace=True)\ndf_train.replace(['C'],1,inplace=True)\ndf_train.replace(['Q'],2,inplace=True)\n","15267a77":"df_train.head(5)","8fa272a1":"sns.heatmap(df_train.corr(),cmap='crest',annot=True)","ef2021bc":"sns.pairplot(df_train,hue='Sex',palette='coolwarm')","8d6583c5":"df_train['Age'].fillna(df_train['Age'].mean(), inplace = True)\ndf_train['Fare'].fillna(df_train['Fare'].mean(), inplace = True)\ndf_train['Embarked'].fillna(df_train['Embarked'].mean(), inplace = True)","d2c60c50":"df_train.head(5)","f6794ee7":"df_train.isnull()","ef3f275a":"df_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","5a799e3d":"df_test","c9603076":"df_test.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)","e4199d36":"df_test.head(4)","aa29d7bf":"df_test['Age'].fillna(df_test['Age'].mean(), inplace = True)\ndf_test['Fare'].fillna(df_test['Fare'].mean(), inplace = True)\n","cdd9c8ea":"df_test.replace(['S'],0,inplace=True)\ndf_test.replace(['C'],1,inplace=True)\ndf_test.replace(['Q'],2,inplace=True)\n","40ff9fe4":"df_test['Embarked'].fillna(df_test['Embarked'].mean(), inplace = True)","c001c846":"df_test.head(4)","1c644107":"df_test.replace(['male'],1,inplace=True)\ndf_test.replace(['female'],0,inplace=True)\n","ab67467f":"cols=['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\nX_train=df_train[cols]\ny_train=df_train['Survived']\nX_test=df_test[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\ny_test=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","0de12d20":"y_test.head(5)","2891166f":"y_test","3986547c":"from sklearn.preprocessing import MinMaxScaler","db30fc70":"scaler=MinMaxScaler()","faa60271":"scaler.fit(X_train)","2993049e":"X_train=scaler.transform(X_train)\nX_test=scaler.transform(X_test)","5286de46":"import tensorflow as tf \nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense\n","8fe89e44":"model=Sequential()\nmodel.add(Dense(5,activation='relu'))\nmodel.add(Dense(4,activation='relu'))\nmodel.add(Dense(3,activation='relu'))\nmodel.add(Dense(2,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\n\n\n","7b7e2774":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","637d3c0b":"model.fit(X_train, y_train, batch_size = 10,epochs= 400)","f5d7d639":"model.history.history","36b4a132":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss","9cb2d300":"model_loss.plot()","6a07c924":"predictions = model.predict_classes(X_test)\npred=predictions.round()\npred","25593c0f":"**From the dataset we can analyse that there is no need for cabin col for making a prediction model so we will drop that col but we are using ANN for prediction so we can give any input to out model and it adapts itself wrt to the model given **","1b7f29a5":"**To prevent the data from overfitting the scaler is being applied only to the train set**","6a9ad643":"**Now we will train our model using Keras and tenorflow as in ANN **","8f5f471b":"**So we need to convert the categorical cols to the numerical cols **","34e52cc6":"****Now we can see that we have removed all the null values,now we will move towards analysis of the test data \n****","d373f0b8":"**from this we get to know that we dont have any null values in any of the columns**\n"}}