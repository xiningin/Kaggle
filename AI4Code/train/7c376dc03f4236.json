{"cell_type":{"20e7328e":"code","667301eb":"code","60d06f3d":"code","85a9939d":"code","638eba03":"code","75309978":"code","ccbced3e":"code","1e139da3":"code","226a6772":"code","248ccb30":"code","ae78061e":"code","e4f32100":"code","67a996ce":"code","40d4791a":"markdown","4fccba73":"markdown","92c1cf4a":"markdown","53f95c0b":"markdown","3ff5c463":"markdown","d69eb02e":"markdown","425f708a":"markdown","4a3574e7":"markdown","8c4a76bd":"markdown","b73fc148":"markdown","3b5425c5":"markdown","7fc31963":"markdown","eef2e13a":"markdown"},"source":{"20e7328e":"# San Francisco Crime Prediction\n###  we will be predicting the type of crime commited in San Francisco given the dates, day of the week, PD district, address and location.","667301eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing as prepro\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom collections import Counter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","60d06f3d":"train = pd.read_csv('..\/input\/san-francisco-crime-classification\/train.csv')\ntest = pd.read_csv('..\/input\/san-francisco-crime-classification\/test.csv')\n\nX=train.copy()","85a9939d":"for i in ['DayOfWeek', 'PdDistrict', 'Address', 'Category']:\n    X[i] = prepro.LabelEncoder().fit_transform(X[i])\n    if i not in ['Category']:\n        test[i] = prepro.LabelEncoder().fit_transform(test[i])","638eba03":"X['year'] = pd.to_datetime(X['Dates']).dt.year\nX['month'] = pd.to_datetime(X['Dates']).dt.month\nX['day'] = pd.to_datetime(X['Dates']).dt.day\nX['hour'] = pd.to_datetime(X['Dates']).dt.hour\nX['minute'] = pd.to_datetime(X['Dates']).dt.minute\n\ntest['year'] = pd.to_datetime(test['Dates']).dt.year\ntest['month'] = pd.to_datetime(test['Dates']).dt.month\ntest['day'] = pd.to_datetime(test['Dates']).dt.day\ntest['hour'] = pd.to_datetime(test['Dates']).dt.hour\ntest['minute'] = pd.to_datetime(test['Dates']).dt.minute","75309978":"for i in [[6, 'month'], [8, 'hour'], [10, 'day']]:\n    feature = i[1]\n    bins = i[0]\n    X[feature+' bin'] = np.floor_divide(X[feature], len(np.unique(X[feature]))\/bins)","ccbced3e":"y = X['Category']\nX = X.drop(['Descript', 'Resolution', 'Dates', 'Category'], axis=1)\ntest = test.drop(['Dates', 'Id'], axis=1)","1e139da3":"fig = plt.figure(figsize=(11, 6))\nsns.heatmap(X.corr(), annot=True, linewidths=.1)\nplt.title('Heatmap for X', fontsize=15)\nplt.show()","226a6772":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(10, 12))\nfig.tight_layout(pad=5.0)\n\ncount = Counter(X['year'])\nax1.bar(count.keys(), count.values(), color='yellow')\nax1.set_title('Amount of crime over the years')\nax1.set_ylabel('Amount of crime')\nax1.set_xlabel('Years')\n\ncount = Counter(X['DayOfWeek'])\nax2.bar(np.unique(train['DayOfWeek']), count.values(), color='blue')\nax2.set_title('Amount of crime per day of the week')\nax2.set_ylabel('Amount of crime')\nax2.set_xlabel('Day of the week')\n\ncount = Counter(X['month'])\nax3.bar(['Jan.', 'Feb.', 'March', 'April', 'May', 'June', 'July', 'August','Sept.','Oct.','Nov.','Dec.'],count.values(),color='green')\nax3.set_title('Amount of crime over the months')\nax3.set_ylabel('Amount of crime')\nax3.set_xlabel('Month')\n\ncount = Counter(X['hour'])\nax4.bar(count.keys(), count.values(), color='purple')\nax4.set_title('Amount of crime in an hour')\nax4.set_ylabel('Amount of crime')\nax4.set_xlabel('Hour')\n\ncount = Counter(X['minute'])\nax5.bar(count.keys(), count.values(), color='red')\nax5.set_title('Amount of crime in a minute')\nax5.set_ylabel('Amount of minute')\nax5.set_xlabel('minute')\n\nplt.show()","248ccb30":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 18))\nfig.tight_layout(pad=17.0)\n\ncount = Counter(train['PdDistrict'])\ndata = (np.array(sorted(count.items(), key=lambda x:x[1], reverse=True)).T).tolist()\nsns.barplot(data[0], data[1])\nplt.title('Crime per neighbourhood')\nplt.ylabel('Amount of crime')\nplt.xlabel('Neighbourhood')\n\ncount = Counter(train['Category'])\ndata = (np.array(sorted(count.items(), key=lambda x:x[1])).T).tolist()\nax1.tick_params()\nax1.bar(data[0], data[1])\nax1.set_xticklabels(data[0], rotation=90)\nax1.set_title('Types of crime')\nax1.set_ylabel('Amount of crime')\nplt.show()","ae78061e":"for i in [['month bin', 'blue'], ['hour bin', 'red'], ['day bin', 'green']]:\n    count = Counter(X[i[0]])\n    color = i[1]\n    plt.bar(count.keys(), count.values(), color=color)\n    plt.title(i[0])\n    plt.ylabel('Amount of crime')\n    plt.xlabel(i[0].split()[0])\n    plt.show()","e4f32100":"y = to_categorical(y)\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=1, test_size=0.2)\nX_train = prepro.StandardScaler().fit_transform(X_train)\nX_val = prepro.StandardScaler().fit_transform(X_val)","67a996ce":"model = Sequential()\n\nmodel.add(Dense(128, activation='relu', input_shape=(X.shape[1],)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(39, activation='softmax'))\n    \nmodel.compile(metrics=['accuracy'], loss='categorical_crossentropy', optimizer='adam')   \nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=100, steps_per_epoch=2195)\n        \nfor j in list(history.history.keys()):\n    plt.plot(history.history[j])\n    plt.title(j + ' over epochs')\n    plt.ylabel(j)\n    plt.xlabel('Epochs')\n    plt.show()","40d4791a":"### The feature engineering begins by encoding the categorical features (Day of the week, PD district, address and category) using a LabelEncoder.","4fccba73":"### The last part of this notebook is to create and tune a neural network.","92c1cf4a":"### Finally, we create three bar charts which show the amount of crime in all of the bins which we created earlier.","53f95c0b":"### Now the year, month, day, hour and minute variables are extracted out of the 'date' feature and added to the dataset.","3ff5c463":"### The following graphs take a look at the types of crime commited and the neighbourhoods in which they occurred.","d69eb02e":"### The final piece of feature engineering which is done is binning the month, hour and day features.","425f708a":"# Data visualisation","4a3574e7":"### Firstly, we will collect the train and test data.","8c4a76bd":"### In order to feed the data to our model, we must first make y categorical and standardise X train and test.","b73fc148":"### Then, the amount of crime per years, day of the week, months, hours and minute are plotted using a bar chart.","3b5425c5":"# Predicting crime with a neural network","7fc31963":"### We start visualising the data with a correlation heatmap for all the features in our X dataset.","eef2e13a":"# Feature engineering"}}