{"cell_type":{"d2434a3c":"code","2456c888":"code","d0884888":"code","b941900e":"code","9423cd5f":"code","a7fd01dc":"code","20aecc09":"code","149ab2d2":"code","ac8dbb9b":"code","010bca6d":"markdown","2e54764f":"markdown","19a619ec":"markdown","06b6fdc4":"markdown","2c0818d8":"markdown"},"source":{"d2434a3c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2456c888":"# To start with importing libraries which are essential for the case\nimport pandas as pd","d0884888":"# Data Preprocessing\n\n# Reading the csv format of datasets as movie and rating \nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n\n# Merging dataframes on movieId\ndf = movie.merge(rating, how=\"left\", on=\"movieId\")\n\ndf.head()\ndf.info()\n\n# Counting titles and assigning as comment_counts \ncomment_counts = pd.DataFrame(df[\"title\"].value_counts())\n\n# Finding rare comments for movies and assiging movies as rare_movies\nrare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n\n# Finding most commented movies and assigning as common_movies\ncommon_movies = df[~df[\"title\"].isin(rare_movies)]\n\n# Show user ratings by considering userid and movie names and assign the resulting pivot table as user_movie_df\nuser_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n\n# Determining the random user to suggest\n# random_user = int(pd.Series(user_movie_df.index).sample(1, random_state=45).values)\n# print(random_user)\n# In this case i will use the following id\nrandom_user = 108170","b941900e":"# Determining the movies watched by the user to be suggested.\n\n# Assining random user as df\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\n\n# Assining the movies watched by random user as df\nmovies_watched_random_user = random_user_df.columns[random_user_df.notna().any()].tolist()\n\n# Number of movies watched by random user\nlen(movies_watched_random_user)","9423cd5f":"# Detecting the ids of other users watching the same movies\n\n# Shooting the watched movies with the audience ids in df\nmovies_watched_df = user_movie_df[movies_watched_random_user]\nmovies_watched_df.head()\nmovies_watched_df.shape\n\n# Calculating how many of the movies watched by the users are the movies watched by the random user\nuser_movie_count = movies_watched_df.T.notnull().sum()\nuser_movie_count = user_movie_count.reset_index()\nuser_movie_count.columns = [\"userId\", \"movie_count\"]\n\n# Selecting users with more than 60 percent similarity to recommend\nperc = len(movies_watched_random_user) * 60 \/ 100\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > perc][\"userId\"]\n\n# Checking the selected users\nusers_same_movies.head()\nusers_same_movies.count()\nusers_same_movies.index","a7fd01dc":"# Determining the users who are most similar to the user to be suggested\n\n# Creating the final df\nfinal_df = movies_watched_df[movies_watched_df.index.isin(users_same_movies)]\nfinal_df.head()\nfinal_df.shape\n\n# Examining the relationship between selected users and each other\ncorr_df = final_df.T.corr().unstack().sort_values()\ncorr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\ncorr_df.index.names = ['user_id_1', 'user_id_2']\ncorr_df = corr_df.reset_index()\ncorr_df.head()\n\n# Examining the relationship between random user and selected users\ntop_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n    [\"user_id_2\", \"corr\"]].reset_index(drop=True)\ntop_users = top_users.sort_values(by='corr', ascending=False)\ntop_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)","20aecc09":"# Weighted average recommendation score\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\ntop_users_ratings = top_users_ratings[top_users_ratings[\"userId\"] != random_user]\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\n\n# Recommendation_df\nrecommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\nrecommendation_df = recommendation_df.reset_index()\n\n# User_based recommendation\nmovies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5].sort_values(\"weighted_rating\",\n                                                                                                   ascending=False)\nmovies_to_be_recommend = movies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]])[0:5]\nprint(movies_to_be_recommend)","149ab2d2":"# Selection of the user's most recent highest rated movie\nuser = 108170\nmovie_id = rating[(rating[\"userId\"] == user) & (rating[\"rating\"] == 5.0)]. \\\n               sort_values(by=\"timestamp\", ascending=False)[\"movieId\"][0:1].values[0]\nprint(movie_id)","ac8dbb9b":"# Item_based recommendation\n\ndef check_id(dataframe, id):\n    movie_name = dataframe[dataframe[\"movieId\"] == id][[\"title\"]].values[0].tolist()\n    print(movie_name)\n\ndef item_based_recommender(movie_name, user_movie_df):\n    movie_name = user_movie_df[movie_name]\n    return user_movie_df.corrwith(movie_name).sort_values(ascending=False)[1:6].index\n\ncheck_id(movie, 7044)\nitem_based_recommender('Wild at Heart (1990)', user_movie_df)","010bca6d":"I used movielens-20m-dataset in this study. The dataset was provided by MovieLens, a movie recommendation service. It contains the rating scores for these movies along with the movies. It contains 2,000,0263 ratings across 27,278 movies. It is known that all selected users voted for at least 20 movies.\nVariables:\n\n**movie.csv**\n1. movieId \u2013 Unique movie number. (UniqueID)\n2. title \u2013 Movie name\n**ratings.csv**\n1. userid \u2013 Unique user number. (UniqueID)\n2. movieId \u2013 Unique movie number. (UniqueID)\n3. rating \u2013 The rating given to the movie by the user\n4. timestamp \u2013 Evaluation date\n\nI tried to make a prediction for the user whose ID I added using the user-based and item-based recommender methods.","2e54764f":"# Case Study with Hybrid Recommendation","19a619ec":"![image.png](attachment:c5831df1-5ef9-4595-bb0b-acdeb8e29c3f.png)","06b6fdc4":"Hybrid recommender systems are used to improve the quality of the model and make more effective recommendations.\n\n**User_based recommender:**\nThis filtering method usually aims to analyze the behavior or preferences of the user and to predict what the user will like by extracting the similarity with other users. In short, it tries to associate similar customers and offers potential products based on what customers choose.\n\n**Item_based recommender:**\nIt is very similar to the user_based recommender but focuses on product similarity rather than finding similarity among customers. In this algorithm, the customer who buys any item is recommended similar items that other users have bought.","2c0818d8":"# Hybrid Recommender Systems"}}