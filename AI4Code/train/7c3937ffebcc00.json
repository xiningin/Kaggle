{"cell_type":{"ba6feeec":"code","f8ff2301":"code","8922c3ea":"code","6d4b426c":"code","2f0e4730":"code","2d8fdf58":"code","71d761b6":"code","e6b893e6":"code","b3d74769":"code","eef5a2ea":"code","af27f2b2":"code","216b6a5d":"code","3f8edf00":"code","464bd4b7":"code","99956ae7":"code","62740286":"code","e366a020":"code","c04a5f21":"code","a254b750":"code","87d4c600":"code","255c9be8":"code","eee78723":"code","97981b24":"markdown","1823a288":"markdown","0d245d47":"markdown","5fd569fd":"markdown","0a23e6cb":"markdown","4c9367d8":"markdown","4628c365":"markdown","54d46422":"markdown","a1a51e14":"markdown","a9d8d682":"markdown","7114710b":"markdown","28ee93fe":"markdown","accfe16b":"markdown","531d8e57":"markdown","84f2df2a":"markdown","33af968f":"markdown","52f6b17d":"markdown","a423869f":"markdown","8401fa53":"markdown","60a855ac":"markdown","33bbafb0":"markdown","54df2821":"markdown","cac5e8e4":"markdown","a9ff3000":"markdown","227fc1d8":"markdown","8fed7002":"markdown","1bafdbaa":"markdown","bc5c11dc":"markdown"},"source":{"ba6feeec":"import matplotlib.pyplot as matplotlib\nimport seaborn\nimport pandas\nimport numpy\n%matplotlib inline\n\n# Fun\u00e7\u00e3o para fazer reshape de listas 1D\ndef reshape(list1D):\n     return numpy.array(list1D).reshape(-1,1)\n    \n# Fun\u00e7\u00e3o para imprimir nosso modelo de Regress\u00e3o Logistica\ndef plot_ours(model):\n    x = numpy.linspace(0,1,50)\n    y = model.predict(reshape(x))\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Our Logistic model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n    \n# Fun\u00e7\u00e3o para imprimir o modelo \"padr\u00e3o\" de Regress\u00e3o Logistica \ndef plot_lr():\n    logistical = lambda x: numpy.exp(x)\/(1+numpy.exp(x))   \n    x = numpy.linspace(-10,10,50)\n    y = logistical(x)\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Logisitc Regression model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n\nplot_lr()\n# Apresentar o que \u00e9 um notebook a = 1, ...","f8ff2301":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport random\n\n# Uma fun\u00e7\u00e3o para criar um dataset com 10.000 n\u00fameros entre 0 e 1 classificados como 0 ou 1 (as vezes errado)\ndef create_dataset():\n    x = [random.random() for i in range(10000)]\n    classify = lambda i: int(i > 0.5) if random.random() > 0.1 else int(not i > 0.5)\n    dataset = pandas.DataFrame(x,columns=['x'])\n    dataset['y'] = dataset['x'].apply(classify)\n    return dataset \n    \ndataset = create_dataset()\ndataset","8922c3ea":"seaborn.scatterplot(data=dataset,x='x',y='y', alpha=0.01)","6d4b426c":"import tree\n# Aqui mapeia os dois tipos de diagn\u00f3sticos no espa\u00e7o\ndef plot_cancer_sizes(df):\n    matplotlib.figure(figsize=(12,12))\n    seaborn.kdeplot(df[df['diagnosis']=='M'].perimeter_worst, df[df['diagnosis']=='M'].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\n    seaborn.kdeplot(df[df['diagnosis']=='B'].perimeter_worst, df[df['diagnosis']=='B'].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)\n    matplotlib.show()\n\n# Faz um plot do perimeter_worst para os dois diagn\u00f3sticos\ndef plot_cancer_perimeter(df):\n    fig = seaborn.FacetGrid(df, hue=\"diagnosis\", aspect=3)\n    fig.map(seaborn.kdeplot, \"perimeter_worst\", shade=True)\n    fig.add_legend()\n    matplotlib.show()\n\n# Faz um plot da \u00e1rvore de decis\u00f5es\ndef plot_tree(model,x_train):\n    matplotlib.figure(figsize=(15,15))\n    tree.plot_tree(model, feature_names=x_train.columns, class_names=['benigno','maligno'], fontsize=14, filled=True)\n    matplotlib.show()\n\n# Faz um plot das import\u00e2ncias para um Random Forest\ndef plot_importances(model,df):\n    importances = model.feature_importances_\n    indices = numpy.argsort(importances)\n    matplotlib.figure(figsize=(12,8))\n    matplotlib.barh(range(len(indices)), importances[indices], color='b', align='center')\n    matplotlib.yticks(range(len(indices)), df.columns[indices])\n    matplotlib.suptitle('Import\u00e2ncia das caracter\u00edsticas')\n    matplotlib.show()\n\ncancer = pandas.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ncancer","2f0e4730":"plot_cancer_sizes(cancer)","2d8fdf58":"nosso_cancer = list({\n 'radius_mean': 17.99,\n 'texture_mean': 10.38,\n 'perimeter_mean': 122.8,\n 'area_mean': 1001.0,\n 'smoothness_mean': 0.1184,\n 'compactness_mean': 0.2776,\n 'concavity_mean': 0.3001,\n 'concave points_mean': 0.1471,\n 'symmetry_mean': 0.2419,\n 'fractal_dimension_mean': 0.07871,\n 'radius_se': 1.095,\n 'texture_se': 0.9053,\n 'perimeter_se': 8.589,\n 'area_se': 153.4,\n 'smoothness_se': 0.006399,\n 'compactness_se': 0.04904,\n 'concavity_se': 0.05372999999999999,\n 'concave points_se': 0.01587,\n 'symmetry_se': 0.03003,\n 'fractal_dimension_se': 0.006193,\n 'radius_worst': 25.38,\n 'texture_worst': 17.33,\n 'perimeter_worst': 184.6,\n 'area_worst': 2019.0,\n 'smoothness_worst': 0.1622,\n 'compactness_worst': 0.6656,\n 'concavity_worst': 0.7119,\n 'concave points_worst': 0.2654,\n 'symmetry_worst': 0.4601,\n 'fractal_dimension_worst': 0.1189\n}.values())\n\nmodel.predict(reshape(nosso_cancer).transpose())","71d761b6":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n","e6b893e6":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, result))","b3d74769":"def plot_iris(df):\n    seaborn.pairplot(df, hue=\"Species\")\n    matplotlib.show()\n\niris = pandas.read_csv('..\/input\/iris\/Iris.csv')\niris","eef5a2ea":"plot_iris(iris)","af27f2b2":"titanic_train = pandas.read_csv(\"..\/input\/titanic\/train.csv\")\ntitanic_test = pandas.read_csv(\"..\/input\/titanic\/test.csv\")\ntitanic_train","216b6a5d":"import string\nimport time\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\ndef clear_sentence(sentence):\n    sentence = sentence.replace('<br \/>', ' ')\n    sentence = sentence.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n    sentence = sentence.lower()\n    return sentence\n\nimdb = pandas.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")\nimdb","3f8edf00":"diabetes = pandas.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndiabetes","464bd4b7":"def plt_digit_from_row(row):\n    label, image = mnist_train.values[row,0], mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='hot')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n\nmnist_train = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_train.csv\")\nmnist_test = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")\nmnist_train.head()","99956ae7":"plt_digit_from_row(0)","62740286":"mnist_train_labels, mnist_train_values = mnist_train.values[:,0], mnist_train.values[:,1:]\nmnist_test_labels, mnist_test_values = mnist_test.values[:,0], mnist_test.values[:,1:]","e366a020":"model = LogisticRegression()\n\nmodel.fit(mnist_train_values, mnist_train_labels)\n\n\nprediction = model.predict(mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","c04a5f21":"def plt_clothes_from_row(row):\n    label, image = fashion_mnist_train.values[row,0], fashion_mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='gray')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n    \nfashion_mnist_train, fashion_mnist_test = pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\"), pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nfashion_mnist_train.head()","a254b750":"plt_clothes_from_row(0)","87d4c600":"fashion_mnist_train_labels, fashion_mnist_train_values = fashion_mnist_train.values[:,0], fashion_mnist_train.values[:,1:]\nfashion_mnist_test_labels, fashion_mnist_test_values = fashion_mnist_test.values[:,0], fashion_mnist_test.values[:,1:]","255c9be8":"model = LogisticRegression()\n\nmodel.fit(fashion_mnist_train_values, fashion_mnist_train_labels)\n\nprediction = model.predict(fashion_mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","eee78723":"from mpl_toolkits.basemap import Basemap\n\n# Precisa ter as colunas 'lat' e 'long'. Retorna o mesmo dataframe com apenas os tweets na regi\u00e3o da austr\u00e1lia.\ndef pegar_tweets_na_australia(dataframe):\n    bot_lat, top_lat, left_lon, right_lon = -44,-10,109,156\n    top = dataframe.lat <= top_lat\n    bot = dataframe.lat >= bot_lat\n    left = dataframe.long >= left_lon\n    right = dataframe.long <= right_lon\n    index = top&bot&left&right \n    return dataframe[index]\n\n# Passe seu dataframe com os dados que voc\u00ea quer plotar e uma legenda (como string).\ndef plotar_mapa(dataframe,legenda):\n    Australia_map = Basemap(llcrnrlat=-44,urcrnrlat=-10,llcrnrlon=109,urcrnrlon=156)\n    matplotlib.figure(figsize=(12,10))\n    Australia_map.bluemarble(alpha=0.9)\n    seaborn.scatterplot(x='long', y='lat', data=dataframe, alpha=1, s=200, label=legenda)\n    matplotlib.show()","97981b24":"Ok, agora vamos ver outro tipo de modelo chamado RandomForestClassifier. Veja que o modelo de aplica\u00e7\u00e3o no c\u00f3digo \u00e9 o mesmo!","1823a288":"# Desafio 3: Diabetes\nO dataset a seguir possui dados sobre a incid\u00eancia de diabetes na popula\u00e7\u00e3o do povo Pima. Seu desafio \u00e9 descobrir a coluna outcome baseado nos outros dados. Seu desafio \u00e9 ultrapassar 82% de precis\u00e3o.","0d245d47":"Ok, neste come\u00e7o iremos apresentar o que \u00e9 um modelo, o que \u00e9 x, y, labels\/test, fit e predict. Lembre-se que toda Intelig\u00eancia Artificial \u00e9 um modelo matem\u00e1tico para y = f(x), onde x ser\u00e3o os dados de entrada, y os dados de resposta, e f a nossa fun\u00e7\u00e3o. No caso estamos estudando uma fun\u00e7\u00e3o da forma ```f(x) = exp(x)\/(1+numpy.exp(x))```. N\u00f3s n\u00e3o iremos entrar na matem\u00e1tica por tr\u00e1s disso mas basta entender que ele \u00e9 uma curva.\n\nO que faremos a seguir \u00e9 um \"arredondador\", ou um classificador de 0's e 1's. Queremos que ele fa\u00e7a 0.00231 -> 0 e 0.7987 -> 1, e assim em diante.","5fd569fd":"Conseguimos ver como \u00e9 a imagem redimensionando o a matriz `1x784` para uma `28x28`:","0a23e6cb":"Agora, vamos visualizar como o tamanho do per\u00edmetro e tamanho da \u00e1rea se comportam para o tipo maligno e benigno","4c9367d8":"Veja s\u00f3 como os dados se parecem:","4628c365":"# Aprendendo a usar o Kaggle\n\nOl\u00e1, seja bem vindo ao Workshop de classificadores de ML do Iris Data Science. N\u00f3s preparamos esse notebook para que voc\u00ea possa aprender do 0 at\u00e9 o conhecimento b\u00e1sico de uso de ML. Esse material \u00e9 baseado em dados de competi\u00e7\u00f5es e nas aulas do Prof. Pascal Yim (E.C. Lille). Os slides da apresenta\u00e7\u00e3o est\u00e3o dispon\u00edveis [aqui](https:\/\/docs.google.com\/presentation\/d\/1_tE7RopalM4mJ96sh-ZBx7KKVsOyTRndLNh5KJrTjL0\/edit?usp=sharing).\n\nSe voc\u00ea nunca utilizou o Kaggle, crie sua conta e clique em \"Copy and Edit\" neste notebook e come\u00e7e a programar!\n\nSe voc\u00ea \u00e9 iniciante, comece aqui pelo come\u00e7o e siga as instru\u00e7\u00f5es. Se voc\u00ea j\u00e1 possui experi\u00eancia, pode seguir a frente e tentar os desafios!","54d46422":"Voc\u00ea vai precisar fazer o escalamento das imagens para poder ","a1a51e14":"Ok, cansamos de usar Logistic Regression. Queremos modelos diferentes para fazer aprendizado de m\u00e1quina! Vamos tentar utilizar uma \u00e1rvore de decis\u00f5es, \u00e9 o mesmo \"modelo\" que o Akinator funcionava!","a9d8d682":"Agora que sabemos como fazer o _fit_ do nosso modelo, vamos ver como ele se parece graficamente. E vamos colocar alguns n\u00fameros de entrada para ele tentar adivinhar!","7114710b":"# Desafio 4: MNIST - Digit Recognizer\nDataset com d\u00edgitos escritos \u00e0 m\u00e3o e seus respectivos valores. Cada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n| Digito representado | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:","28ee93fe":"Vamos aplicar novamente o que j\u00e1 sabemos.","accfe16b":"Ok, s\u00f3 que voc\u00ea nunca encontrar\u00e1 na sua vida os dados dessa forma. Eles normalmente est\u00e3o armazenados em datasets que podem ser acessados por dataframes. A forma mais comum de acessar um dataset \u00e9 utilizando a biblioteca pandas. Vamos ver esse dataset de dataset de \\[0,1\\]  que possui mais 10.000 n\u00fameros. (Aten\u00e7\u00e3o, por volta de 10% das respostas est\u00e3o erradas!)","531d8e57":"# Mexendo com dados reais (Cancer de Mama)\n\n\n","84f2df2a":"# IRIS\n\nIris, o desafio que deu nome ao nome do nosso grupo, \u00e9 um dataset do tipo de flor Iris (e n\u00e3o o olho!). Nele, h\u00e1 tr\u00eas tipos de esp\u00e9cies, com as informa\u00e7\u00f5es sobre s\u00e9palas e p\u00e9talas.","33af968f":"Ok, fa\u00e7a x com todas as colunas menos o diagn\u00f3stico, e y como diagn\u00f3stico! Lembre de separar os dados e aplicar a Regress\u00e3o Log\u00edstica","52f6b17d":"# Desafio 2: IMDB","a423869f":"E agora vamos aprender um pouco sobre classifica\u00e7\u00e3o, como precis\u00e3o, recall, f1-score, e **LOSS**","8401fa53":"Vamos aplicar nossa regress\u00e3o log\u00edstica.","60a855ac":"Vamos ver como cada informa\u00e7\u00e3o se comporta para cada esp\u00e9cie.","33bbafb0":"# Desafio 1: Titanic\n\nO seu objetivo \u00e9 descobrir, dado as informa\u00e7\u00f5es de um passageiro no navio Titanic, se ele sobreviveu ou n\u00e3o o acidente (coluna survived). Neste caso, voc\u00ea perceber\u00e1 que algumas colunas podem deixar seu aprendizado pior. Outro ponto importante \u00e9 que h\u00e1 varias informa\u00e7\u00f5es faltantes (NaN).\n\n**Objetivos**\n- Voc\u00ea consegue preencher as informa\u00e7\u00f5es faltantes de alguma forma? Como?\n- Tente ultrapassar 80% de precis\u00e3o.\n\n\n","54df2821":"A acur\u00e1cia foi ruim, como voc\u00ea pode ver. O que aconteceu? Ser\u00e1 que tem alguma coluna que est\u00e1 fazendo nossos dados tendenciosos? (dica: tem sim)","cac5e8e4":"Vamos predizer cancer! O dataset a seguir \u00e9 sobre canc\u00ear de mama no estado de Wisconsin. Na coluna do 'diagnosis' podemos ver os dois diagn\u00f3sticos para cancer de mama: Maligno e Benigno. Vamos tentar adivinhar o diagn\u00f3stico baseado apenas nas informa\u00e7\u00f5es m\u00e9dicas que temos.","a9ff3000":"Primeiro passo: Tire a coluna in\u00fatil no final!","227fc1d8":"Ok, o seu desafio agora \u00e9 utilizar Machine Learning para fazer uma An\u00e1lise de Sentimentos nas reviews de filmes do IMDB. Neste dataset voc\u00ea possui 50.000 reviews de filmes classificadas como \"positiva\" e \"negativa\". Neste dataset, seu modelo pode demorar bastante (coisa de 5 minutos para cima). O qu\u00ea voc\u00ea precisa fazer:\n\n- Limpar as reviews (use a fun\u00e7\u00e3o clear_sentence para cada string do dataset)\n- Separe o treinamento e teste.\n- Vetorizar as palavras (pode usar o HashingVectorizer()). Procure no google como aplicar isso.\n- Coloque em um Machine Learning.\n\n**Objetivos**\n- Qual \u00e9 o melhor tipo de modelo de ML para esse NLP? (Dica: pense em modelos que trabalham com vetores)\n- Ultrapasse 90% de precis\u00e3o neste dataset demorando menos de 1 minuto para rodar (utilize time.time() para pegar os tempos.\n\n\n","8fed7002":"# Desafio Final: Predizer elei\u00e7\u00f5es com Tweets\n\nDessa vez nem preparamos o dataset para voc\u00ea. Utilizando o dataset das elei\u00e7\u00f5es australianas, voc\u00ea consegue predizer que regi\u00f5es da Austr\u00e1lia apoiam qual partido? Tente treinar seu modelo em algum dataset classificado com positivo e negativo e ent\u00e3o fa\u00e7a o .fit() no dataset das elei\u00e7\u00f5es. Voc\u00ea pode utilizar a fun\u00e7\u00e3o a seguir para plotar seus dados.","1bafdbaa":"Lembre-se sempre da aplica\u00e7\u00e3o de IA: classificar coisas! Imagine que eu sou um m\u00e9dico com um paciente com essas condi\u00e7\u00f5es. O c\u00e2ncer \u00e9 maligno ou benigno?","bc5c11dc":"# Desafio 5: Fashion MNIST\nDataset com desenhos de tipos de roupa classificadas com labels\nCada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n\n| Label de cada roupa | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:"}}