{"cell_type":{"f21d6a15":"code","990a0a5c":"code","d7c540c2":"code","9b79bb09":"code","e7f5a500":"code","8ff328a1":"code","0b3359ad":"code","182a076c":"code","6f200c10":"code","cdb54ecd":"code","a1dee251":"code","135918ef":"code","db11eaef":"code","7c698d8c":"code","3eb12d52":"code","1c142d02":"code","b092c0bc":"code","eddf32df":"code","af85615d":"code","8249f49b":"markdown","6301de60":"markdown","64d9e1d1":"markdown","ec546bb0":"markdown","d74aa854":"markdown","2d012f36":"markdown","12e88c54":"markdown","98ed4526":"markdown","9cac4d06":"markdown","e83d0bc0":"markdown","faa89c1c":"markdown","eb8fc797":"markdown","6ed8c1cd":"markdown","d1a42e72":"markdown","f82ac0c0":"markdown"},"source":{"f21d6a15":"class Config:\n    def __init__(self):\n        self.config = 0\n        self.gpu_on = 1\n        self.optuna_tuner = 0\n        self.optuna_train = 0\n        self.config_size = 754\n        self.data_dir = '..\/input\/ventilator-pressure-prediction\/'\n        self.post_processing = {\n                                'max_pressure': 64.82099173863948,\n                                'min_pressure': -1.8957442945646408,\n                                'diff_pressure': 0.07030215,\n                                }       \nconfig = Config()","990a0a5c":"if config.gpu_on:\n    !rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm\n    !git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","d7c540c2":"if config.gpu_on:\n    !apt-get install -y -qq libboost-all-dev","9b79bb09":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","e7f5a500":"if config.gpu_on:\n    !cd LightGBM\/python-package\/;python3 setup.py install --precompile","8ff328a1":"if config.gpu_on:\n    !mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n    !rm -r LightGBM","0b3359ad":"if config.gpu_on:\n    !nvidia-smi","182a076c":"import os\nimport gc\nimport glob\nimport time\nimport random\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nimport optuna\nimport optuna.integration.lightgbm as lgbo\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler","6f200c10":"# Dtype Changed for low size data\ndtypes = {'id': 'int32',\n          'breath_id': 'int32',\n          'R' : 'int8',\n          'C' : 'int8',\n          'time_step': 'float64',\n          'u_in': 'float64',\n          'u_out': 'int8',\n          'pressure': 'float64'}\n\n# Read train CSV data\ndef read_train():\n    train = pd.read_csv(config.data_dir + 'train.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\n        train_tmp = pd.DataFrame()\n        for i in lst_train:\n            train_tmp = pd.concat([train_tmp, train[train['breath_id'] == i]], axis=0)\n        train = train_tmp\n    train = train.astype(dtypes)\n    return train\n\n# Read test CSV data\ndef read_test():\n    test = pd.read_csv(config.data_dir + 'test.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_test = random.sample(set(test['breath_id'].unique()), config.config_size)\n        test_tmp = pd.DataFrame()\n        for i in lst_test:\n            test_tmp = pd.concat([test_tmp, test[test['breath_id'] == i]], axis=0)\n        test = test_tmp\n    test = test.astype(dtypes)\n    return test  \n\ntrain = read_train()   \ntrain.head(2)","cdb54ecd":"## Describe in exclude id columns\ntrain[train.columns[1:]].describe(include='all').round(3)","a1dee251":"lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\nfig, ax = plt.subplots(1, 3, figsize=(30, 6))\nsns.set(font_scale=1.2)\nfor i, num in enumerate(random.sample(lst_train, 3)):\n    df = train[train['breath_id']==num]\n    ax2 = ax[i].twinx()\n\n    sns.lineplot(data=df, x='time_step', y='pressure', label='pressure', ax=ax[i])\n    sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[i])\n    sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n\n    ax[i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}', xlim=(-0.2, 3.2), ylim=(-5, 105))\n    ax[i].legend(loc=(0.75, 0.7))\n    ax2.legend(loc=(0.75, 0.6))\nplt.show()","135918ef":"def log_exp_return(series):\n    return np.exp(np.log1p(series).diff(1).fillna(0))\n\ndef data_clean(df):\n    ## timestep\u306b\u76f4\u7dda\u6027\u304c\u7121\u3044\u30c7\u30fc\u30bf\u3092\u524a\u9664\n    time_step_diff_limit = 0.04\n    non_liner_timestep_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            non_liner_timestep_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n    \n    ## \u8ca0\u306epressure\u5024\u3092\u6301\u3064\u30c7\u30fc\u30bf\u3092\u524a\u9664\n    minus_pressure_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        m = grp[\"pressure\"].min()\n        if m < 0:\n            minus_pressure_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(minus_pressure_breath_ids)]   \n    \n    ## u_out = 1\u306estep\u6570\u304c52\u4ee5\u4e0a\u306e\u30c7\u30fc\u30bf\u3092\u524a\u9664\n    u_out_open_step_counts_over52_breath_ids = list()\n    for k, grp in train.groupby(\"breath_id\"):\n        count = grp.groupby(\"u_out\")[\"id\"].count()[1]\n        if count > 51:\n            u_out_open_step_counts_over52_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(u_out_open_step_counts_over52_breath_ids)] \n    \n    return df\n\n\ndef preprocessing(df):   \n    # time diff\n    df['time_diff'] = df['time_step'].groupby(df['breath_id']).diff(1).fillna(0)\n    \n    # basic parameter\n    df['u_in_ratio'] = df['u_in'].groupby(df['breath_id']).apply(log_exp_return)\n    df['area_unit'] = df['u_in'] * df['time_diff']\n    df['area_ratio'] = df['area_unit'].groupby(df['breath_id']).apply(log_exp_return)\n    \n    # Create Time Windows\n    def create_time_window(df, time_min, time_max, diff_time):\n        feature_dict = {\n                        'u_in': [np.max, np.std], \n                        'area_unit': [np.max, np.std], \n                        'u_in_ratio': [np.prod, np.std],\n                        'area_ratio': [np.prod, np.std]\n                        }\n        for time_stamp in np.arange(time_min, time_max, diff_time):\n            df_tmp = df[['time_step'] + list(feature_dict.keys())][(df['time_step'] >= time_stamp - diff_time) & (df['time_step'] < time_stamp)] \\\n                        .groupby(df['breath_id']).agg(feature_dict)\n            df_tmp.columns = ['_'.join(col) for col in df_tmp.columns]\n            df = pd.merge(df, df_tmp.add_suffix(f'_{time_stamp}_term').reset_index(), on='breath_id', how='left')\n            del df_tmp\n            gc.collect()\n            time.sleep(3)\n\n        return df\n    \n    df = create_time_window(df, 0.5, 2.0, 0.5)\n    \n    # u_in shift change \n    for i in np.arange(1, 5, 1):\n        df[f'u_in_lag_fwrd{i}'] = df['u_in'].groupby(df['breath_id']).shift(i)\n        df[f'u_in_lag_back{i}'] = df['u_in'].groupby(df['breath_id']).shift(int(-i))                                   \n\n        df[f'u_out_lag_fwrd{i}'] = df['u_out'].groupby(df['breath_id']).shift(i)\n        df[f'u_out_lag_back{i}'] = df['u_out'].groupby(df['breath_id']).shift(int(-i))\n        \n        df[f'u_in_diff{i}'] = df['u_in'] - df[f'u_in_lag_fwrd{i}']\n        df[f'u_out_diff{i}'] = df['u_out'] - df[f'u_out_lag_fwrd{i}']      \n\n    # u_in parameter\n    df['last_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('last')\n    df['first_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('first')\n    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()  \n    df['u_in_diff_max'] = df['u_in'] - df['u_in'].groupby(df['breath_id']).max()\n    df['u_in_diff_ave'] = df['u_in'] - df['u_in'].groupby(df['breath_id']).mean()  \n                                      \n    # u_in area\n    df['last_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('last')\n    df['first_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('first')  \n    \n    df = df.fillna(0)\n    \n    # u_out parameter\n    df['cross_u_in']= df['u_in'] * df['u_out']\n    df['cross_area']= df['area_unit'] * df['u_out']\n    df['cross_time']= df['time_step'] * df['u_out']\n    df['u_out'] = df['u_out'].astype('str')\n    \n    # R, C parameter\n    df['R'] = df['R'].astype('str')\n    df['C'] = df['C'].astype('str')\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df, drop_first=True) \n    \n    return df\n\ntrain = data_clean(train)\ntarget = train[\"pressure\"].values\ntrain = train.drop([\"id\", \"pressure\"], axis=1)\ntrain = preprocessing(train)\ntrain = train.drop(['breath_id'], axis=1)\nfeature_column = train.columns.values","db11eaef":"rs = RobustScaler()\ntrain = rs.fit_transform(train)\nprint(f'train shape: {train.shape}')","7c698d8c":"class LGBM:\n    def __init__(self, feature_column, train, target):\n        self.num_boost_round_optuna = 100\n        if config.optuna_train:\n            self.num_boost_round = 200\n            self.verbose_eval = 100\n        else:\n            self.num_boost_round = 15000\n            self.verbose_eval = 5000\n        self.n_splits = 3\n        self.early_stopping_rounds = 100\n        self.kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=2021)\n        self.boosters = []\n        self.eval_results_lst = []\n        self.feature_column = feature_column\n        self.feature_importance = pd.DataFrame()\n        self.train, self.target = train, target\n        del train, target\n        gc.collect()\n        \n    # Hyperparameter OputunaTunerCV\n    def optuna_tuner(self, params):\n        lgb_trn = lgbo.Dataset(self.train, label=self.target)       \n        study_tuner = optuna.create_study(direction='minimize') \n        tuner =  lgbo.LightGBMTunerCV(params=params, \n                                      train_set=lgb_trn,\n                                      num_boost_round=self.num_boost_round_optuna, \n                                      early_stopping_rounds=self.early_stopping_rounds, \n                                      verbose_eval=self.verbose_eval,\n                                      folds=self.kf,\n                                      study=study_tuner)\n        tuner.run()\n        return tuner.best_params\n        \n    def lgbm_train(self, params, reg):\n        # Lughgbm train\n        for fold, (trn_idx, val_idx) in enumerate(self.kf.split(self.train, self.target)):\n            eval_results = {}\n            print(\"=\"*15 + f' Fold {fold+1} started at {time.ctime()} ' + \"=\"*15)\n            lgb_trn = reg.Dataset(self.train[trn_idx], label=self.target[trn_idx])\n            lgb_val = reg.Dataset(self.train[val_idx], label=self.target[val_idx])\n                        \n            booster = reg.train(params=params, \n                                train_set=lgb_trn, \n                                valid_sets=[lgb_trn, lgb_val],\n                                valid_names=['Train', 'Valid'], \n                                num_boost_round=self.num_boost_round, \n                                early_stopping_rounds=self.early_stopping_rounds, \n                                verbose_eval=self.verbose_eval,\n                                evals_result=eval_results)\n                        \n            self.eval_results_lst.append(eval_results)\n            self.boosters.append(booster)\n            \n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = self.feature_column\n            fold_importance[\"importance\"] = booster.feature_importance()\n            fold_importance[\"fold\"] = fold + 1\n            self.feature_importance = pd.concat([self.feature_importance, fold_importance], axis=0)\n        \n            del lgb_trn, lgb_val, fold_importance, booster, eval_results\n            gc.collect()\n                \n    # Vizualize Importance columns\n    def importance_show(self, top=20):\n        df_tmp = self.feature_importance\n        sns.set(font_scale=1.2)\n        fig, ax = plt.subplots(1, self.n_splits, figsize=(30, 20))\n        for i in range(self.n_splits):\n            df = df_tmp[df_tmp[\"fold\"]==i+1].sort_values('importance', ascending=False)\n            sns.barplot(data=df[:top], x=\"importance\", y=\"feature\", ci=None, ax=ax[i])\n            ax[i].set_title(f\"Fold: {i+1}\")\n        plt.tight_layout()\n        plt.show()\n        \n        del df_tmp\n        gc.collect()","3eb12d52":"lgbm_inst = LGBM(feature_column, train, target)\n\n# Params base\nbest_params = {\n                'objective': 'regression_l1', \n                'metric': 'l1', \n                'boosting_type': 'gbdt', \n                'verbose': -1, 'random_state': 2021\n              }\n\n# GPU \nif config.gpu_on:\n    best_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n\n# TunerCV version\nif config.optuna_tuner:\n    best_params = lgbm_inst.optuna_tuner(best_params)\n\n# Train\nelse:\n    # LightGBM Optuna Train\n    if config.optuna_train:\n        lgbm_inst.lgbm_train(best_params, lgbo)\n    else:\n        best_params.update({\n                            'feature_pre_filter': False, \n                            'lambda_l1': 0.0, \n                            'lambda_l2': 0.0, \n                            'num_leaves': 255, \n                            'feature_fraction': 0.8999999999999999, \n                            'bagging_fraction': 1.0, \n                            'bagging_freq': 0, \n                            'min_child_samples': 20\n                            })\n        lgbm_inst.lgbm_train(best_params, lgb)\n        \ngc.collect()    \nprint(best_params)","1c142d02":"if not config.optuna_tuner:\n    fig, ax = plt.subplots(1, lgbm_inst.n_splits, figsize=(30, 6))\n    for i, results in enumerate(lgbm_inst.eval_results_lst):\n        ax[i].plot(np.log(results['Train']['l1']), label='train')\n        ax[i].plot(np.log(results['Valid']['l1']), label='valid')\n        ax[i].set(xlabel=\"Boosting round\", ylabel = 'Log_loss', title = f'Training Fold {i+1}')\n    plt.legend()\n    plt.show()","b092c0bc":"if not config.optuna_tuner:\n    # Score AVE & STD in CV\n    scores = list()\n    for result in lgbm_inst.eval_results_lst:\n        scores.append(result['Valid']['l1'][-1])\n    print('\\n CV mean score: {0:.5f}, std: {1:.5f}.'.format(np.mean(scores), np.std(scores)))\n\n    # Show Importance\n    lgbm_inst.importance_show(top=20)","eddf32df":"if  config.config and not config.optuna_tuner:\n    tmp = list()\n    for booster in lgbm_inst.boosters:\n        tmp.append(booster.predict(train, num_iteration=booster.best_iteration))\n\n    train_pred = read_train()\n    train_pred[\"pred_pressure\"] = sum(tmp) \/lgbm_inst.n_splits\n    train_pred[\"mae_unit\"] = np.abs(train_pred[\"pred_pressure\"] - train_pred[\"pressure\"])\n    train_pred = pd.merge(train_pred, pd.DataFrame(train_pred.groupby(\"breath_id\")[\"mae_unit\"].mean()).rename(columns={\"mae_unit\": \"mae\"}), how=\"left\", on=\"breath_id\")\n    \n    lst_train_pred = random.sample(set(train_pred['breath_id'].unique()), config.config_size)\n    \n    fig, ax = plt.subplots(2, 3, figsize=(30, 12))\n    sns.set(font_scale=1.2)\n    for i, num in enumerate(random.sample(lst_train_pred , 3)):\n        df = train_pred[train_pred['breath_id']==num]\n\n        sns.lineplot(data=df, x='time_step', y='pressure', label='actual', ax=ax[0, i])\n        sns.lineplot(data=df, x='time_step', y='pred_pressure', label='predict', ax=ax[0, i])\n        sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[0, i])\n        sns.lineplot(x=df['time_step'], y=np.log(df['mae_unit']), label='mae_unit', ax=ax[1, i])\n        ax[0, i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}, MAE: {round(df[\"mae\"].mean(), 3)}', xlim=(-0.2, 3.2))\n        ax[0, i].legend(loc=(0.75, 0.7))\n        ax[1, i].set(xlabel='Timestep', ylabel='mae_unit', title=f'breath_id: {num}, MAE: {round(df[\"mae\"].mean(), 3)}', xlim=(-0.2, 3.2), ylim=(-2.1, 0.6))\n        ax2 = ax[1, i].twinx()\n        sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n        ax[1, i].legend(loc=(0.75, 0.2))\n        ax2.legend(loc=(0.75, 0.1))\n    plt.tight_layout()\n    plt.show()","af85615d":"if not config.optuna_tuner:\n    del train, target\n    gc.collect()\n\n    dtypes.pop(\"pressure\")\n    test = read_test()\n    test = preprocessing(test)\n    test = test.drop([\"id\", 'breath_id'], axis=1)\n    test = rs.transform(test)\n    print(f'test shape: {test.shape}')\n\n    submission = pd.read_csv(config.data_dir + \"sample_submission.csv\")[:test.shape[0]]\n    for booster in lgbm_inst.boosters:\n        submission['pressure'] += booster.predict(test, num_iteration=booster.best_iteration)\n\n    del test\n    gc.collect()\n\n    submission['pressure'] \/= lgbm_inst.n_splits\n#   submission[\"pressure\"] = np.round((submission[\"pressure\"] - config.post_processing[\"min_pressure\"]) \/ config.post_processing[\"diff_pressure\"]) * config.post_processing[\"diff_pressure\"] + config.post_processing[\"min_pressure\"]\n    submission[\"pressure\"] = np.clip(submission[\"pressure\"], config.post_processing[\"min_pressure\"], config.post_processing[\"max_pressure\"])\n    submission.to_csv('submission_lgb.csv', index=False)\n    print(submission.tail(2))","8249f49b":"### 2-4. Checking overfitting\n- Checking overfitting using eval_results dict","6301de60":"### 2-3. LightGBM Train","64d9e1d1":"### 0-2. Libarary","ec546bb0":"### 1-5. RobustScaler","d74aa854":"## 2. LightGBM\n### 2-1. LightGBM class\n- Create Class\n- You can change easier any parameters","2d012f36":"## 1 EDA & Preprocessing\n### 1-1. Train & Test data","12e88c54":"### 2-5. Scores & Feature Importance\n- Visualize how each explanatory variable affects the objective function","98ed4526":"## 0. Introduction\n- Updated 10\/15\/2021\n- GPU usage\n- This code is a baseline with LighGBM train method.\n- Shown to confirm overfitting\n- Shown Importance feature by lightGBM feature_importance function\n- Finished to submit","9cac4d06":"## 3.Submission","e83d0bc0":"### 1-4. Preprocessing","faa89c1c":"### 0-1. GPU Prepare\n- You need to turn on \"GPU Accelerator\"\n- You need to turn on Inernet setting\n- https:\/\/www.kaggle.com\/dromosys\/gpu-accelerated-lightgbm-full","eb8fc797":"### 2-6. Predict Train data show","6ed8c1cd":"### 1-3. Time series data(pressure\/ u_in \/ u_out)\n- from [https:\/\/www.kaggle.com\/kaitohonda\/beginner-lgbm](https:\/\/www.kaggle.com\/kaitohonda\/beginner-lgbm)","d1a42e72":"### 1-2. Exploratory Data Analysis\n### Feature\n- id - globally-unique time step identifier across an entire file\n- breath_id - globally-unique time step for breaths\n- R - lung attribute indicating how restricted the airway is (in cmH2O\/L\/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n- C - lung attribute indicating how compliant the lung is (in mL\/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon\u2019s latex, with higher C having thinner latex and easier to blow.\n- time_step - the actual time stamp.\n- u_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n- u_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n- pressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","f82ac0c0":"- You need to delete comment out when you wnat to use GPU"}}