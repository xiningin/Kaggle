{"cell_type":{"4466debf":"code","a70d4591":"code","110d717a":"code","0436cab5":"code","f59a403a":"code","d2bf5840":"code","4458f87c":"code","ed18c024":"code","e103ee44":"code","0662d22a":"code","a0c3d2cd":"code","feba2f08":"code","031a2802":"code","2ddb0c13":"code","0f01e81d":"code","0a6c7a01":"code","d687ee3c":"code","190b8c1b":"code","9916c347":"code","c7500188":"code","7c44f417":"markdown","f08572e7":"markdown"},"source":{"4466debf":"import xgboost as xgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","a70d4591":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")","110d717a":"train.head()","0436cab5":"print(train.columns.to_list())","f59a403a":"target_name=['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\ntrain_name=['deg_C','relative_humidity','absolute_humidity','sensor_1','sensor_2',\n            'sensor_3','sensor_4','sensor_5',]","d2bf5840":"target = train[target_name]\ntarget0 = train['target_carbon_monoxide']\ndata = train[train_name]","4458f87c":"columns=data.columns.to_list()\nprint(columns)","ed18c024":"def objective(trial,data=data,target=target0):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n\n        'lambda': trial.suggest_uniform('lambda',5.0,6.0),\n        'alpha': trial.suggest_uniform('alpha',2.0,2.4),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.3,0.5),\n        'subsample': trial.suggest_uniform('subsample', 0.5,0.6),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.04,0.06),\n        'n_estimators': trial.suggest_int('n_estimators', 100,2000),\n        'max_depth': trial.suggest_int('max_depth', 15,20),\n        'random_state': trial.suggest_int('random_state', 1000,2000),\n        'min_child_weight': trial.suggest_int('min_child_weight', 20,60),\n        \n        'use_label_encoder': trial.suggest_categorical('use_label_encoder',['False']),\n        'objective': trial.suggest_categorical('objective',['reg:tweedie']), \n        'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  #'gpu_hist','hist'       \n    }\n    model = xgb.XGBRegressor(**param)      ###\n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","e103ee44":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=8)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","0662d22a":"study.trials_dataframe()","a0c3d2cd":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","feba2f08":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","031a2802":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","2ddb0c13":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['lambda','min_child_weight'])","0f01e81d":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","0a6c7a01":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","d687ee3c":"Best_trial=study.best_trial.params\nprint(Best_trial)","190b8c1b":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")\nprint(sample.shape)\nsample","9916c347":"preds = np.zeros((sample.shape[0],sample.shape[1]-1))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor i in range(3):\n    for trn_idx, test_idx in kf.split(train[columns],target[target_name[i]]):\n        X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n        y_tr,y_val=target.iloc[trn_idx,i],target.iloc[test_idx,i]     ######\n        model = xgb.XGBRegressor(**Best_trial)\n        model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n        preds[:,i]+=model.predict(test[columns])\/kf.n_splits    ######\n        rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n        print(rmse)","c7500188":"subm = sample\nsubm[target_name] = pd.DataFrame(preds)\nsubm.to_csv('submission.csv',index=False)\nsubm","7c44f417":"#### Tuning manually repeated and the range of values narrowed.","f08572e7":"# XGBoost with Optuna tuning\n* doc: \nhttps:\/\/github.com\/optuna\/optuna"}}