{"cell_type":{"466b8753":"code","fa64a547":"code","3d0439d9":"code","0c36ae85":"code","bfbda033":"code","9e54a169":"code","9114a71f":"code","41798e35":"code","6efc9301":"code","944c8782":"code","1af58e3b":"code","06210651":"code","29e1ad39":"code","70092ebd":"code","3fcd2364":"code","0d74f324":"code","a4bc18fd":"code","0f44d4f7":"code","5f602dbd":"code","9b53a39b":"code","1c05484a":"code","1b7e1768":"code","f94f3b80":"code","fa6e2fe2":"code","db7be9c2":"code","a80a0407":"markdown","28e4402f":"markdown","7151b526":"markdown","88d39b93":"markdown","01cbcaae":"markdown","902d7a70":"markdown","07794d4a":"markdown","73be95fe":"markdown","0159501f":"markdown","01a9e5c8":"markdown","3be80ae7":"markdown","54d9918a":"markdown","51efcbb2":"markdown","ed92c72e":"markdown","17f5d1b1":"markdown","19231ff6":"markdown"},"source":{"466b8753":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\ndb = pd.read_csv('\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv')\ndb.head()","fa64a547":"db.info() #no missings","3d0439d9":"db = db.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)","0c36ae85":"pd.options.display.max_rows = 200\ndb.groupby('Exited').describe().T","bfbda033":"from sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\ndb_cat = db[['Gender', 'Geography']] \ndb_cat_encoded = ordinal_encoder.fit_transform(db_cat)","9e54a169":"from sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder()\ndb_cat_encoded_1hot = cat_encoder.fit_transform(db_cat_encoded)\ndb_cat_encoded_1hot","9114a71f":"array = db_cat_encoded_1hot.toarray()\n\ndb_cat_encoded_1hot_df = pd.DataFrame(array)\ndb_cat_encoded_1hot_df.head()","41798e35":"db_cat_encoded_1hot_df.columns = ['M', 'F','France', 'Germany', 'Spain' ]","6efc9301":"db_final = db.merge(db_cat_encoded_1hot_df, left_index = True, right_index = True)\ndb_final.head()","944c8782":"#making bins to be able to split correctly, but using in regression\/forest the original variable\ndb_final['Credit_Score'] = pd.cut(db_final['CreditScore'], bins = [0,500,650,720,np.inf], labels = [1,2,3,4])\n\ndb_final['Estimated_Salary'] = pd.cut(db_final['EstimatedSalary'], bins = [0,50000,100000,150000,np.inf], labels = [1,2,3,4])\n\ndb_final['Age_new'] = pd.cut(db_final['Age'], bins = [0,30,35,45,60,np.inf], labels = [1,2,3,4,5])","1af58e3b":"db_final.head()","06210651":"train, test = train_test_split(db_final, test_size = 0.2,\n                               stratify = db_final[['Estimated_Salary','Credit_Score',\n                                                    'M','F', 'France','Germany', 'Spain','Exited']])","29e1ad39":"train_label = train['Exited']\ntrain = train.drop(['Exited','Gender', 'Geography'], axis = 1)\n\ntest_label = test['Exited']\ntest = test.drop(['Exited','Gender', 'Geography'], axis = 1)","70092ebd":"param_grid = {\n    'C': [0.01, 0.05,0.1,0.15,0.3,0.5,0.8,1,5,3,5,5,10,20,50,100,150,200,300,400,1000],\n    'max_iter': [50, 100, 150]\n    }\n\nlog_reg = LogisticRegression()\ngrid_search = GridSearchCV(estimator = log_reg , param_grid = param_grid, \n                          cv = 10)\ngrid_search.fit(train,train_label)\ngrid_search.best_params_","3fcd2364":"best_grid = grid_search.best_estimator_\nbest_grid","0d74f324":"predict_label = best_grid.predict(test)\n\nfrom sklearn.metrics import classification_report\nclassification_report(test_label, predict_label)\ntarget_names = ['0','1']\nprint(classification_report(test_label, predict_label, target_names=target_names))","a4bc18fd":"from sklearn.metrics import accuracy_score\naccuracy_score(test_label, predict_label) #an accuracy of 0.79 ( for the first run)","0f44d4f7":"from pprint import pprint \n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [int(x) for x in np.linspace(start = 5, stop = 800, num = 30)]\n\nmax_features = ['auto', 'sqrt']\n\nmax_depth = [int(x) for x in np.linspace(5, 2000, num = 30)]\nmax_depth.append(None)\n\nmin_samples_split = [2, 4, 6, 10]\n\nmin_samples_leaf = [1,2, 4, 6, 10]\n\n\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","5f602dbd":"forest_reg = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = forest_reg, param_distributions = random_grid, n_iter = 100, cv = 3, \n                               verbose=2, random_state=42, n_jobs = -1)\n\nrf_random.fit(train,train_label)","9b53a39b":"rf_random.best_params_","1c05484a":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [1500,2000, 2200],\n    'max_features': ['sqrt'],\n    'min_samples_leaf': [8,10,12],\n    'min_samples_split': [4,6,8],\n    'n_estimators': [360,550,600,650,700]\n}","1b7e1768":"\nrf = RandomForestClassifier()\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\n\ngrid_search.fit(train,train_label)\ngrid_search.best_params_","f94f3b80":"best_grid = grid_search.best_estimator_\n\nbest_grid","fa6e2fe2":"predict_label_2 = best_grid.predict(test)\n\nfrom sklearn.metrics import classification_report\nclassification_report(test_label, predict_label_2)\ntarget_names = ['0','1']\nprint(classification_report(test_label, predict_label_2, target_names=target_names))","db7be9c2":"from sklearn.metrics import accuracy_score\naccuracy_score(test_label, predict_label_2) # nice, 0.86 accuracy for the first run :)  ","a80a0407":"==== Grid Search ====","28e4402f":"**In this notebook I'm using two approaches to determine if a bank's clients will leave or not, by using information like credit score, number of products or salary. The two ways to determine this is to make a classification with the help of 1) Logistic Regression and 2) Random Forests.**","7151b526":"Let's take a quick look to see how the two groups are different:","88d39b93":"Let's see what data we have in here:","01cbcaae":"I will be using Grid Search, so below I'm giving some various values for the C parameter and see what parameter is the best:","902d7a70":"There are some important variables that I want to use when making the train\/test split; for this, I will make some groups that wll be used for stratification: ","07794d4a":"# Random Forest","73be95fe":"I noticed there are some variables that are not useful, like the customer's ID or name, so I'll delete those:","0159501f":"Now I'll be making the train\/test split by considering salary, credit score, country and gender as criterias:","01a9e5c8":"Firstly, I'll be using Randomized Search to get a hint of what parameter options would be best, and then I'll use them and other closer values in a Grid Search:","3be80ae7":"# Logistic Regression","54d9918a":"In conclusion, The Random Forest algorithm got a better accuracy, of 0.86, compared to the Logistic Regression, with 0.79.","51efcbb2":"==== Randomized Search ====","ed92c72e":"Let's check the classification report and accuracy:","17f5d1b1":"Isolating the target variables:","19231ff6":"Now, there are two important variables that are categorical, Gender and the country of origin, expressed by the Geography variable; in the following steps I will encode those ones into 1 and 0 and merge them to the initial database."}}