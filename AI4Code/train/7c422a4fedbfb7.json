{"cell_type":{"c8bdaae7":"code","cad1b651":"code","d11043bb":"code","3e5089db":"code","84efe277":"code","adc1dc2b":"code","99100dbf":"code","e2addd93":"markdown","b6753637":"markdown"},"source":{"c8bdaae7":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')","cad1b651":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nsample_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","d11043bb":"# Sex\u3068Embarked\u306eOne-Hot\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\ntrain = pd.get_dummies(train, columns=['Sex', 'Embarked'])\ntest = pd.get_dummies(test, columns=['Sex', 'Embarked'])\n\n# \u4e0d\u8981\u306a\u5217\u306e\u524a\u9664\ntrain.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\ntest.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\n\n# train\u306e\u8868\u793a\ndisplay(train.head())\n\nX_train = train.drop(['Survived'], axis=1)  # X_train\u306ftrain\u306eSurvived\u5217\u4ee5\u5916\ny_train = train['Survived']  # Y_train\u306ftrain\u306eSurvived\u5217","3e5089db":"def objective(trial):\n    kf = KFold(n_splits=3)\n    gbm = lgb.LGBMClassifier(objective='binary')\n    oof = np.zeros(len(train))\n\n    for fold, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):\n        train_x, valid_x = X_train.iloc[train_index], X_train.iloc[valid_index]\n        train_y, valid_y = y_train[train_index], y_train[valid_index]\n        gbm = lgb.LGBMClassifier(objective='binary',\n                                 reg_alpha=trial.suggest_loguniform('reg_alpha', 1e-4, 100.0),\n                                 reg_lambda=trial.suggest_loguniform('reg_lambda', 1e-4, 100.0),\n                                 num_leaves=trial.suggest_int('num_leaves', 10, 40),\n                                 silent=True)\n        gbm.fit(train_x, train_y, eval_set = [(valid_x, valid_y)],\n                early_stopping_rounds=20,\n                verbose=-1) # \u5b66\u7fd2\u306e\u72b6\u6cc1\u3092\u8868\u793a\u3057\u306a\u3044\n        oof[valid_index] = gbm.predict(valid_x)\n\n    accuracy = accuracy_score(y_train, oof)\n    return 1.0 - accuracy  # \u6700\u5c0f\u3092\u63a2\u7d22\u3059\u308b\u306e\u3067\u30011-acuuracy\u306b\u3057\u3066\u3044\u308b","84efe277":"study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n# \u30b7\u30fc\u30c9\u3092\u56fa\u5b9a\u3002\n# \u53c2\u8003\uff1ahttps:\/\/qiita.com\/phorizon20\/items\/1b795beb202c2dc378ed\n\nstudy.optimize(objective, n_trials=50)","adc1dc2b":"print(study.best_params)\nreg_alpha = study.best_params['reg_alpha']\nreg_lambda = study.best_params['reg_lambda']\nnum_leaves = study.best_params['num_leaves']","99100dbf":"kf = KFold(n_splits=3, shuffle=True, random_state=0)\n\n# \u30b9\u30b3\u30a2\u3068\u30e2\u30c7\u30eb\u3092\u683c\u7d0d\u3059\u308b\u30ea\u30b9\u30c8\nscore_list = []\ntest_pred = np.zeros((len(test), 3))\n\nfor fold_, (train_index, valid_index) in enumerate(kf.split(X_train, y_train)):\n    train_x = X_train.iloc[train_index]\n    valid_x = X_train.iloc[valid_index]\n    train_y = y_train[train_index]\n    valid_y = y_train[valid_index]\n    \n    print(f'fold{fold_ + 1} start')\n\n    gbm = lgb.LGBMClassifier(objective='binary',\n                             num_leaves=num_leaves,\n                             reg_alpha=reg_alpha,\n                             reg_lambda=reg_lambda)  # \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6307\u5b9a\n    gbm.fit(train_x, train_y,\n            eval_set = [(train_x, train_y), (valid_x, valid_y)],\n            early_stopping_rounds=20,\n            verbose= -1)\n    \n    oof = gbm.predict(valid_x, num_iteration=gbm.best_iteration_)\n    score_list.append(round(accuracy_score(valid_y, oof)*100,2))\n    test_pred[:, fold_] = gbm.predict_proba(test)[:, 1]\n    print(f'fold{fold_ + 1} end\\n' )\nprint(score_list, '\u5e73\u5747score', np.mean(score_list))\npred = (np.mean(test_pred, axis=1) > 0.5).astype(int)\nsample_submission['Survived'] = pred\nsample_submission.to_csv('optuna.csv', index=False)","e2addd93":"# \u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\n\n* reg_alpha\u3068reg_lambda\u306f\u30ed\u30b0\u30b9\u30b1\u30fc\u30eb\uff08trial.suggest_loguniform\uff09\n* num_leaves\u3092int\uff08trial.suggest_int\uff09\n\n\u3092\u9078\u629e\u3057\u3066\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3002  \n\n\u305d\u306e\u4ed6\u3001suggest_categorical\u3001suggest_discrete_uniform\u3001suggest_uniform\u306a\u3069\u3092\u9078\u629e\u3067\u304d\u308b\u3002\n\u8a73\u3057\u304f\u306f\u3001[\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/trial.html)\u3092\u53c2\u7167","b6753637":"optuna\u3092\u4f7f\u3063\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u3057\u3066\u307f\u308b\n\n* LightGBM\u306eScikit-learn\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u4f7f\u3063\u3066\u3001\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u306e\u30c7\u30fc\u30bf\u3067\u3001reg_alpha\u3068reg_lambda\u3092\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u307f\u308b\u4f8b\u3092\u66f8\u3044\u3066\u307f\u307e\u3057\u305f\n* LightGBM\u306eScikit-learn\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u4f7f\u308f\u306a\u3044\u4f8b\u306f\u3001[\u516c\u5f0f\u306eexamples](https:\/\/github.com\/optuna\/optuna-examples\/blob\/main\/lightgbm\/lightgbm_simple.py)\u7b49\u3092\u53c2\u7167\u304f\u3060\u3055\u3044\n"}}