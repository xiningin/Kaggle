{"cell_type":{"ea292777":"code","1ae715a2":"code","c88b6ff6":"code","63f5a764":"code","35e55df8":"code","b6e62f79":"code","36fa4e9b":"code","b172db0d":"code","d5c7780a":"code","141282ea":"code","624e8f96":"code","2f9ca4a5":"code","f2166163":"code","2bbc2aea":"code","d7f8798c":"code","afcce94b":"code","9ba83d3d":"code","28bd5694":"code","97bf3308":"code","c83d4952":"code","e181032f":"code","bdaca027":"code","fe09318f":"code","a865bcc3":"code","e65ebc1d":"code","04980594":"code","b6949478":"code","cabc1f8c":"code","418886d2":"code","8cbd635d":"code","1bdc700d":"code","2f1f987c":"code","f8d2e564":"code","f6926647":"code","2e7d1efb":"code","1af1a1ba":"code","42799e8c":"code","dc5e9143":"code","3836fbf4":"code","5851943f":"code","e5aba659":"code","bf37ba7a":"code","20986ead":"code","87f2e1c3":"code","0c8d68e2":"markdown","ff18d273":"markdown","07423f97":"markdown","394981f9":"markdown","6b4cdf27":"markdown","fbd793f0":"markdown","81454138":"markdown","4db4ef53":"markdown","1de4fdc5":"markdown","f5e96e7e":"markdown","473d0284":"markdown","d10df9c5":"markdown","529332f6":"markdown","7154a25b":"markdown","b96c5673":"markdown","77d3564e":"markdown","78e878a4":"markdown"},"source":{"ea292777":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ae715a2":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10, 10)","c88b6ff6":"df=pd.read_csv('\/kaggle\/input\/breaking-bad-tv-show-all-seasons-episodes-data\/breaking_bad.csv')","63f5a764":"df","35e55df8":"df['Season'].unique()","b6e62f79":"df['Directed by'].unique()","36fa4e9b":"df['Written by'].unique()","b172db0d":"df.describe()","d5c7780a":"import datetime","141282ea":"df['Date']=pd.to_datetime(df['Date'])","624e8f96":"df['Year']=df['Date'].dt.year","2f9ca4a5":"df['Month']=df['Date'].dt.month","f2166163":"df.isnull().sum()","2bbc2aea":"df=df.dropna(how='all')","d7f8798c":"df['U.S. viewers_million'].plot()","afcce94b":"df['Rating_IMDB'].plot()","9ba83d3d":"sns.heatmap(df.corr())","28bd5694":"df.groupby('Season')['U.S. viewers_million'].mean().plot.bar(title='average vewers by seasons')","97bf3308":"df.groupby('Season')['Rating_IMDB'].mean().plot.bar(title='average Rating_IMDB by seasons')","c83d4952":"df.groupby(['Season','Directed by'])['U.S. viewers_million'].mean().sort_values(ascending=False).plot.bar()","e181032f":"df.groupby(['Season','Written by'])['U.S. viewers_million'].mean().sort_values(ascending=False).plot.bar()","bdaca027":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\nimport squarify\nimport seaborn as sns\n\nlist_stopwords = set(stopwords.words('english'))","fe09318f":"df1=df.loc[:,['Title','Summary']]\ndf1=df1.dropna()","a865bcc3":"df1","e65ebc1d":"df1['Title'] = df1['Title'].str.lower()\ndf1['Title'] = df1['Title'].apply(word_tokenize)\ndf1['Title'] = df1['Title'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf1['Title'] = df1['Title'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\n\ndf1['Summary'] = df1['Summary'].str.lower()\ndf1['Summary'] = df1['Summary'].apply(word_tokenize)\ndf1['Summary'] = df1['Summary'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf1['Summary'] = df1['Summary'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\n","04980594":"df1","b6949478":"df.loc[:,['Title','Summary']]=df1.loc[:,['Title','Summary']]","cabc1f8c":"df","418886d2":"df_s1=df[df['Season']==1]\ndf_s2=df[df['Season']==2]\ndf_s3=df[df['Season']==3]\ndf_s4=df[df['Season']==4]\ndf_s5=df[df['Season']==5]","8cbd635d":"df_title_explo1=pd.DataFrame(df_s1['Title'].explode())\ndf_title_explo1=df_title_explo1[df_title_explo1['Title'] != '']\ndf_title_explo1=df_title_explo1[df_title_explo1['Title'] != 's']\ndf_title_explo1=pd.DataFrame(df_title_explo1.groupby('Title')['Title'].count().sort_values(ascending=False))\n\ndf_title_explo2=pd.DataFrame(df_s2['Title'].explode())\ndf_title_explo2=df_title_explo2[df_title_explo2['Title'] != '']\ndf_title_explo2=df_title_explo2[df_title_explo2['Title'] != 's']\ndf_title_explo2=pd.DataFrame(df_title_explo2.groupby('Title')['Title'].count().sort_values(ascending=False))\n\ndf_title_explo3=pd.DataFrame(df_s3['Title'].explode())\ndf_title_explo3=df_title_explo3[df_title_explo3['Title'] != '']\ndf_title_explo3=df_title_explo3[df_title_explo3['Title'] != 's']\ndf_title_explo3=pd.DataFrame(df_title_explo3.groupby('Title')['Title'].count().sort_values(ascending=False))\n\ndf_title_explo4=pd.DataFrame(df_s4['Title'].explode())\ndf_title_explo4=df_title_explo4[df_title_explo4['Title'] != '']\ndf_title_explo4=df_title_explo4[df_title_explo4['Title'] != 's']\ndf_title_explo4=pd.DataFrame(df_title_explo4.groupby('Title')['Title'].count().sort_values(ascending=False))\n\ndf_title_explo5=pd.DataFrame(df_s5['Title'].explode())\ndf_title_explo5=df_title_explo5[df_title_explo5['Title'] != '']\ndf_title_explo5=df_title_explo5[df_title_explo5['Title'] != 's']\ndf_title_explo5=pd.DataFrame(df_title_explo5.groupby('Title')['Title'].count().sort_values(ascending=False))","1bdc700d":"from wordcloud import WordCloud","2f1f987c":"print(df_title_explo1.index)\nprint(df_title_explo2.index)\nprint(df_title_explo3.index)\nprint(df_title_explo4.index)\nprint(df_title_explo5.index)","f8d2e564":"word1=\"\"\"'bag', 'cancer', 'cat', 'crazy', 'deal', 'gray', 'handful', 'man',\n       'matter', 'noroughstufftype', 'nothin', 'pilot', 'river'\"\"\"\nword2=\"\"\"'4', 'abq', 'seven', 'saul', 'phoenix', 'peekaboo', 'negro', 'mandala',\n       'grilled', 'dead', 'days', 'call', 'breakage', 'bit', 'better', 'bee',\n       'azul', 'thirtyseven'\"\"\"\nword3=\"\"\"'m\ufffds', 'abiquiu', 'caballo', 'sin', 'see', 'one', 'nombre', 'minute',\n       'measures', 'measure', 'light', 'kafkaesque', 'ift', 'half', 'green',\n       'full', 'fly', 'sunset'\"\"\"\nword4=\"\"\"'box', 'bug', 'thirtyeight', 'space', 'snub', 'shotgun', 'salud',\n       'problem', 'points', 'open', 'house', 'hermanos', 'face', 'end', 'dog',\n       'cutter', 'crawl', 'cornered', 'bullet', 'times'\"\"\"\nword5=\"\"\"'blood', 'buried', 'state', 'say', 'rabid', 'pay', 'ozymandias', 'name',\n       'money', 'madrigal', 'live', 'hazard', 'granite', 'gliding', 'freight',\n       'free', 'fiftyone', 'felina', 'dog', 'die', 'dead', 'confessions',\n       'buyout', 'tohajiilee'\"\"\"","f6926647":"wc1 = WordCloud(background_color=\"white\", width=600,height=500)\nwc1.generate(word1)\nplt.imshow(wc1)\nplt.axis('off')","2e7d1efb":"wc2 = WordCloud(background_color=\"white\", width=600,height=500)\nwc2.generate(word2)\nplt.imshow(wc2)\nplt.axis('off')","1af1a1ba":"wc3 = WordCloud(background_color=\"white\", width=600,height=500)\nwc3.generate(word3)\nplt.imshow(wc3)\nplt.axis('off')","42799e8c":"wc4 = WordCloud(background_color=\"white\", width=600,height=500)\nwc4.generate(word4)\nplt.imshow(wc4)\nplt.axis('off')","dc5e9143":"wc5 = WordCloud(background_color=\"white\", width=600,height=500)\nwc5.generate(word5)\nplt.imshow(wc5)\nplt.axis('off')","3836fbf4":"df_summary_explo1=pd.DataFrame(df_s1['Summary'].explode())\ndf_summary_explo1=df_summary_explo1[df_summary_explo1['Summary'] != '']\ndf_summary_explo1=df_summary_explo1[df_summary_explo1['Summary'] != 's']\ndf_summary_explo1=pd.DataFrame(df_summary_explo1.groupby('Summary')['Summary'].count().sort_values(ascending=False).head(30))\ndf_summary_explo1=df_summary_explo1.rename(columns={'Summary': 'num'})\n\ndf_summary_explo2=pd.DataFrame(df_s2['Summary'].explode())\ndf_summary_explo2=df_summary_explo2[df_summary_explo2['Summary'] != '']\ndf_summary_explo2=df_summary_explo2[df_summary_explo2['Summary'] != 's']\ndf_summary_explo2=pd.DataFrame(df_summary_explo2.groupby('Summary')['Summary'].count().sort_values(ascending=False).head(30))\ndf_summary_explo2=df_summary_explo2.rename(columns={'Summary': 'num'})\n\ndf_summary_explo3=pd.DataFrame(df_s3['Summary'].explode())\ndf_summary_explo3=df_summary_explo3[df_summary_explo3['Summary'] != '']\ndf_summary_explo3=df_summary_explo3[df_summary_explo3['Summary'] != 's']\ndf_summary_explo3=pd.DataFrame(df_summary_explo3.groupby('Summary')['Summary'].count().sort_values(ascending=False).head(30))\ndf_summary_explo3=df_summary_explo3.rename(columns={'Summary': 'num'})\n\ndf_summary_explo4=pd.DataFrame(df_s4['Summary'].explode())\ndf_summary_explo4=df_summary_explo4[df_summary_explo4['Summary'] != '']\ndf_summary_explo4=df_summary_explo4[df_summary_explo4['Summary'] != 's']\ndf_summary_explo4=pd.DataFrame(df_summary_explo4.groupby('Summary')['Summary'].count().sort_values(ascending=False).head(30))\ndf_summary_explo4=df_summary_explo4.rename(columns={'Summary': 'num'})\n\ndf_summary_explo5=pd.DataFrame(df_s5['Summary'].explode())\ndf_summary_explo5=df_summary_explo5[df_summary_explo5['Summary'] != '']\ndf_summary_explo5=df_summary_explo5[df_summary_explo5['Summary'] != 's']\ndf_summary_explo5=pd.DataFrame(df_summary_explo5.groupby('Summary')['Summary'].count().sort_values(ascending=False).head(30))\ndf_summary_explo5=df_summary_explo5.rename(columns={'Summary': 'num'})","5851943f":"x = df_summary_explo1['num']\nlabel = df_summary_explo1.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.rcParams[\"figure.figsize\"] = (10, 10)\nplt.axis('off')\nplt.show()","e5aba659":"x = df_summary_explo2['num']\nlabel = df_summary_explo2.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","bf37ba7a":"x = df_summary_explo3['num']\nlabel = df_summary_explo3.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","20986ead":"x = df_summary_explo4['num']\nlabel = df_summary_explo4.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","87f2e1c3":"x = df_summary_explo5['num']\nlabel = df_summary_explo5.index\nsquarify.plot(x, label=label,color=sns.color_palette('husl'))\nplt.axis('off')\nplt.show()","0c8d68e2":"# Top 30 words in summary in season3","ff18d273":"# Top 30 words in summary in season2","07423f97":"# season4 Title analysis","394981f9":"# Top 30 words in summary in season4","6b4cdf27":"# season5 Title analysis","fbd793f0":"# Correlation between features","81454138":"# season2 Title analysis","4db4ef53":"# season3 Title analysis","1de4fdc5":"# Top 30 words in summary in season1","f5e96e7e":"# The average vewers by seasons","473d0284":"# 'U.S. viewers_million' by seasons and directors","d10df9c5":"# Trend of 'Rating_IMDB'","529332f6":"# Trend of 'U.S. viewers_million'","7154a25b":"# season1 Title analysis","b96c5673":"# Top 30 words in summary in season5","77d3564e":"# 'U.S. viewers_million' by seasons and witers","78e878a4":"# The average Rating_IMDB by seasons"}}