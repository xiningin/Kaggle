{"cell_type":{"27ad1bf9":"code","ae303640":"code","47fee66f":"code","c51cdac6":"code","eac63bb8":"code","9231cca8":"code","b411af41":"code","b31166c8":"code","5bbaa961":"code","2b41fbdb":"code","47666a8c":"code","18abfe06":"code","8798d161":"code","b1bc8115":"code","d0f36566":"code","27c8f86c":"code","83213ee9":"code","08044867":"code","3a16f3a6":"code","a2e04f01":"code","45c318a0":"code","6b6a0b5e":"code","1a3d8d06":"code","d0875cb8":"code","42605119":"code","c950d0b9":"code","524481cc":"code","d1ca9543":"code","75c348bf":"code","9a08ab06":"code","9ff491c7":"code","efefded7":"code","f78e777e":"code","39e3fcdf":"code","bbb324c7":"code","aa11b829":"code","bedc606a":"code","155d9d67":"code","08e56e91":"code","dbb41b20":"code","50809231":"code","8e6f71c6":"code","15f02d5f":"code","ceabca3e":"code","81165429":"markdown","d1773f5f":"markdown","5b76b90b":"markdown","397b5e1e":"markdown","daa65d26":"markdown","163bb125":"markdown","5c330d20":"markdown","a9a9dcdc":"markdown"},"source":{"27ad1bf9":"## Requried library\n!pip install isodate\nimport isodate\nfrom googleapiclient.discovery import build\nimport argparse\nfrom datetime import datetime\nfrom scipy import stats\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","ae303640":"# define developer key, api service name and api version\nDEVELOPER_KEY = \"AIzaSyBWnXJwk09QE_XIHdGMTTPYfyS6siyDRS8\"\nYOUTUBE_API_SERVICE_NAME = \"youtube\"\nYOUTUBE_API_VERSION = \"v3\"\nyoutube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)","47fee66f":"# define a funtion to get data for a query or topic\ndef search_result(topic):\n    data_list = []  # get all data into a list\n    \n    # search in youtube for a query\n    res = youtube.search().list( q = topic, part=\"id,snippet\", maxResults='50').execute()\n    \n    # to get next page of data in youtube search\n    nextPageToken = res.get('nextPageToken')\n    while ('nextPageToken' in res):\n        data_list.append(res['items'])\n        nextPage = youtube.search().list(q = topic, part=\"id,snippet\", maxResults='50',\n                                         pageToken=nextPageToken).execute()\n        res['items'] = res['items'] + nextPage['items']\n        if 'nextPageToken' not in nextPage:\n            res.pop('nextPageToken', None)\n        else:\n            nextPageToken = nextPage['nextPageToken']\n        \n        if(len((data_list)) == 7):\n            break;\n            \n    return data_list","c51cdac6":"new = search_result('math')\nnew","eac63bb8":"(new[0][0]['id'])","9231cca8":"# get the list of video ids from search result\ndef video_ids_list(data):\n    ids_list = []\n    for i in range(len(data)):\n        for j in range(len(data[i])):\n            if(list(data[i][j]['id'].keys())[1] == 'videoId'):\n                ids_list.append(data[i][j]['id']['videoId'])\n    return ids_list","b411af41":"# get the part of video by searching in youtube using video ids\ndef data_columns(video_part, video_ids):\n    search_data = []\n    for i in range(0, len(video_ids)):\n        res = (youtube).videos().list(id=video_ids[i], part=video_part).execute()\n        search_data += res['items']\n    return search_data","b31166c8":"# Define a function to make a csv file which contain video title, duration, topic, published at, liked, dislike,\n# view, favorite count ect as columns.\ndef csv_file(video_list, topic):\n    \n    # get data column topic\n    Topic = [topic]*len(video_list)\n    \n    # get content Details\n    contentDetails = data_columns('contentDetails', video_list)\n    dur = []       # Duration of video\n    for i in range(len(video_list)):\n        sec = isodate.parse_duration(contentDetails[i]['contentDetails']['duration']).seconds\n        dur.append((sec % 3600) \/\/ 60)\n    \n    \n    snippets = data_columns('snippet', video_list)\n    Video_Title = []                 # video title \n    Published_At = []                # publish at\n    for i in range(len(video_list)):\n        dt = datetime.strptime(snippets[i]['snippet']['publishedAt'], '%Y-%m-%dT%H:%M:%SZ')\n        Published_At.append(str(dt))\n        Video_Title.append(snippets[i]['snippet']['title'])\n    \n    \n    stats = data_columns('statistics', video_list)\n    title=[ ]        # video title\n    liked=[ ]        # likes on video\n    disliked=[ ]     # dislike on video\n    favorites =[ ]   # favorites vote on video\n    views=[ ]        # total view on video\n    url=[ ]          # video title\n    comment=[ ]   # video title\n    timequried = []\n    for i in range(len(video_list)):\n        #title.append((videos[i])['snippet']['title'])\n        #url.append(\"https:\/\/www.youtube.com\/watch?v=\"+(videos[i])['snippet']['resourceId']['videoId'])\n        timequried.append(str(datetime.now().time()))\n        if 'viewCount' in (list(stats[i]['statistics'].keys())):\n            views.append(int((stats[i])['statistics']['viewCount']))\n        else:\n            views.append(0)\n        \n        if 'likeCount' in (list(stats[i]['statistics'].keys())):\n            liked.append(int((stats[i])['statistics']['likeCount']))\n        else:\n            liked.append(0)\n        \n        if 'likeCount' in (list(stats[i]['statistics'].keys())):\n            disliked.append(int((stats[i])['statistics']['dislikeCount']))\n        else:\n            disliked.append(0)\n    \n        if 'commentCount' in (list(stats[i]['statistics'].keys())):\n            comment.append(int((stats[i])['statistics']['commentCount']))\n        else:\n            comment.append(0)\n        \n        if 'favoriteCount' in (list(stats[i]['statistics'].keys())):\n            favorites.append(int((stats[i])['statistics']['favoriteCount']))\n        else:\n            favorites.append(0)\n    \n    \n    # make a csv file\n    data = {'Topic':Topic, 'Timequried':timequried, 'Video ID':video_list, 'Video_Title':Video_Title,'Published_At':Published_At,'duration(m)':dur,\n            'favorite':favorites,'liked':liked,'disliked':disliked,'views':views,'comment':comment}\n    df=pd.DataFrame(data)\n    return df","5bbaa961":"math_data = search_result('math')\nmath_video_list = video_ids_list(math_data)\nmath_video_list","2b41fbdb":"len(math_video_list)","47666a8c":"math_csv = csv_file(math_video_list, 'math')\nmath_csv.to_csv(\"math.csv\", index=False)\nmath_csv","18abfe06":"math_csv.info()","8798d161":"Enginner_data = search_result('engineering')\nEnginner_video_list = video_ids_list(Enginner_data)\nEnginner_video_list","b1bc8115":"engineer_csv = csv_file(Enginner_video_list, 'Enginnering')\nengineer_csv.to_csv(\"engineer.csv\", index=False)\nengineer_csv","d0f36566":"engineer_csv.to_csv(\"engineer.csv\", index=False)","27c8f86c":"engineer_csv.info()","83213ee9":"science_data = search_result('science')\nscience_list = video_ids_list(science_data)\nscience_list","08044867":"len(science_list)","3a16f3a6":"science_csv = csv_file(science_list, 'science')\nscience_csv.to_csv(\"science.csv\", index=False)\nscience_csv","a2e04f01":"science_csv.to_csv(\"science.csv\", index=False)","45c318a0":"science_csv.info()","6b6a0b5e":"dataframe = pd.concat([math_csv, engineer_csv, science_csv])\ndataframe.to_csv('solution.csv', index=False)\ndataframe.head()","1a3d8d06":"dataframe.info()","d0875cb8":"dataframe.describe()","42605119":"dataframe.isnull().sum()","c950d0b9":"df = dataframe.drop(['Published_At', 'Timequried', 'Topic', 'Video ID', 'Video_Title', 'favorite'], axis=1)\ndf_zscore = (df - df.mean())\/df.std()\ndf_zscore","524481cc":"sns.pairplot(df_zscore)","d1ca9543":"dataframe.hist(alpha=0.8, figsize=(8,6))\nplt.tight_layout()\nplt.show()","75c348bf":"import seaborn as sns\nsns.distplot(dataframe['liked'])","9a08ab06":"sns.distplot(dataframe['disliked'])","9ff491c7":"sns.distplot(dataframe['comment'])","efefded7":"matrix = dataframe.corr()\nf, ax = plt.subplots(figsize=(9,6))\nsns.heatmap(matrix, vmax=1, square=True, cmap='BuPu')","f78e777e":"dataframe.rank(method ='average') ","39e3fcdf":"dataset = dataframe.drop(['Published_At','Timequried','Topic','Video ID','Video_Title','favorite',\n                          'duration(m)','disliked','liked'], axis=1)\ndataset","bbb324c7":"dataset['total_like'] = dataframe['liked'] - dataframe['disliked']\ndataset","aa11b829":"dataset['totel_point'] = dataset['views'] + dataset['comment'] +  dataset['total_like']\ndataset","bedc606a":"percent_rank = dataset.rank(method ='average', pct=True) \npercent_rank","155d9d67":"percent_rank.max()","08e56e91":"def find_rank(value):\n    ans = 0\n    if(value<=0.2):\n        ans = 1\n    elif(0.2<value<=0.4):\n        ans = 2\n    elif(0.4<value<=0.6):\n        ans = 3\n    elif(0.6<value<=0.8):\n        ans = 4\n    elif(0.8<value<=1):\n        ans = 5\n    return ans","dbb41b20":"list(percent_rank['totel_point'])[1]","50809231":"rank = []\nfor i in range(len(dataset['totel_point'])):\n    rank.append(find_rank(list(percent_rank['totel_point'])[i]))","8e6f71c6":"rank","15f02d5f":"dataframe['rank'] = rank\ndataframe","ceabca3e":"dataframe.to_csv(\"solution.csv\", index=False)","81165429":"## Save the file","d1773f5f":"## Give rating 1-5","5b76b90b":"## Z score visulization","397b5e1e":"## rank","daa65d26":"## Data Analysis","163bb125":"## Data analysis and cleaning","5c330d20":"## Calculate Z Score","a9a9dcdc":"## Check null values"}}