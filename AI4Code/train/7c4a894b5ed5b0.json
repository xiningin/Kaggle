{"cell_type":{"f680adaf":"code","04543b67":"code","a814a787":"code","6c41cb23":"code","4dd12c41":"code","39f3a88e":"code","fc58a453":"code","50fc015e":"code","7a2d648c":"code","fc2b01c2":"code","93034733":"code","01436ad0":"code","0353e760":"code","a3341f43":"code","3fe9d1ae":"code","be6b8d43":"code","03068aae":"code","9e8ce765":"code","09c2b571":"code","da179931":"code","d759f1ec":"code","daa492d4":"code","ac3741ce":"code","6e8ac9a0":"code","d7e59b24":"code","ac28b263":"code","10c74be9":"code","3b742037":"code","87c7c8a6":"markdown","a98cabd6":"markdown","2c98311b":"markdown","e927d0d6":"markdown","44c96a36":"markdown","9908ea10":"markdown","0901dc7c":"markdown","b756c213":"markdown","3a2a2e6f":"markdown","300ad845":"markdown","94609b06":"markdown","984753d2":"markdown","e1c25a35":"markdown"},"source":{"f680adaf":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.impute import SimpleImputer\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost.sklearn import XGBRegressor\nprint('Compelete Imports')","04543b67":"#File Path Full\nfile_path_train='..\/input\/house-prices-advanced-regression-techniques\/train.csv'\nfile_path_test='..\/input\/house-prices-advanced-regression-techniques\/test.csv'\n\n# Read the train data\ndp_train = pd.read_csv(file_path_train, index_col='Id')\n# Read the test data\ndp_test=pd.read_csv(file_path_test,index_col='Id')\n# Remove rows with missing target, separate target from predictors\n\ndp_train.dropna(axis=0, subset=['SalePrice'], inplace=True)\n#define target\ny = dp_train.SalePrice\n#Remove target colum\nX = dp_train.drop(['SalePrice'], axis=1)\nX_test=dp_test\n\n# To keep things simple, we'll use only numerical predictors\n# X = dp_train.select_dtypes(exclude=['object'])\n# X_test = X_test_full.select_dtypes(exclude=['object'])\n# # To keep things simple, we'll use only numerical predictors\n# X = X_full.select_dtypes(exclude=['object'])\n# X_test = dp_test.select_dtypes(exclude=['object'])\n\n\nprint('Read Done!')\n# X_test.head()\n\n# X.head()","a814a787":"# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n\nprint('Split Done!')","6c41cb23":"# X_train.isna().sum()","4dd12c41":"\npd.concat([dp_train.isnull().sum(),\n          100* dp_train.isnull().sum()\/len(dp_train)],\n         axis=1).rename(columns={0:'Missing Records',1:'Percentage (%)'})","39f3a88e":"category_colums=[colum for colum in X.columns if X[colum].dtype == 'object']\nlen(category_colums)","fc58a453":"y.isna().sum()","50fc015e":"X_train.isna().sum()","7a2d648c":"cols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()]\nlen(cols_with_missing)","fc2b01c2":"# # Number of missing values in each column of training data\n# missing_val_count_by_column = (X_train.isnull().sum())\n# print(missing_val_count_by_column[missing_val_count_by_column > 0])\n# missing_val_count_by_column[missing_val_count_by_column > 0].shape","93034733":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=10, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","01436ad0":"bad_cols = [ col for col in category_colums if set(X[col].unique()) != set(X_test[col].unique()) ]\nbad_cols","0353e760":"len(bad_cols)","a3341f43":"X.drop(columns=bad_cols,axis=1,inplace=True)\nX_test.drop(columns=bad_cols,axis=1,inplace=True)","3fe9d1ae":"category_colums=[colum for colum in X.columns if X[colum].dtype == 'object']\nlen(category_colums)","be6b8d43":"from sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer(strategy='most_frequent')\nimputed_X=pd.DataFrame(my_imputer.fit_transform(X))\nimputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n\n# Imputation removed column names; put them back\nimputed_X.columns = X.columns\nimputed_X_test.columns = X_test.columns\n","03068aae":"imputed_X.head()","9e8ce765":"imputed_X_test.head()","09c2b571":"# Make copy to avoid changing original data \nimputed_X_lable = X.copy()\nimputed_X_test_lable = X_test.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in category_colums:\n    imputed_X_lable[col] = label_encoder.fit_transform(imputed_X[col])\n    imputed_X_test_lable[col] = label_encoder.transform(imputed_X_test[col])\n","da179931":"imputed_X_lable","d759f1ec":"imputed_X_test_lable","daa492d4":"imputed_X_lable.dtypes\\","ac3741ce":"parameters = [{\n    'n_estimators': list(range(100, 1001, 100)), \n    'learning_rate': [x \/ 100 for x in(range(5, 100, 10))], \n    'max_depth': list(range(6, 70, 6))\n}]\nparameters","6e8ac9a0":"\ngsearch = GridSearchCV(estimator=XGBRegressor(),\n                       param_grid = parameters, \n                       scoring='neg_mean_absolute_error',\n                       n_jobs=4,\n                       cv=5,\n                       verbose=7)\n\ngsearch.fit(imputed_X_lable,y)\n\ngsearch.best_params_.get('n_estimators'),gsearch.best_params_.get('learning_rate'),gsearch.best_params_.get('max_depth')","d7e59b24":"best_n_estimators=gsearch.best_params_.get('n_estimators')\nbest_learning_rate=gsearch.best_params_.get('learning_rate')\nbest_max_depth=gsearch.best_params_.get('max_depth')\n\nbest_n_estimators,best_learning_rate,best_max_depth","ac28b263":"best_model=XGBRegressor(n_estimators=best_n_estimators,\n                       learning_rate=best_learning_rate,\n                       max_depth=best_max_depth)\nbest_model.fit(imputed_X_lable,y)","10c74be9":"my_preds_test=best_model.predict(imputed_X_test_lable)\nmy_preds_test\n","3b742037":"my_output=pd.DataFrame(\n{'Id':X_test.index,\n'SalePrice':my_preds_test})\nmy_output.to_csv('submission.csv',index=False)\nprint('create output done!')","87c7c8a6":"#### get columns with missing values","a98cabd6":"## count columns with missing values ","2c98311b":"# Make output","e927d0d6":"# Use Grid_Search_CV to get Best Parameters\n","44c96a36":"## Prediction ","9908ea10":"# Imputation for Messing Values","0901dc7c":"# Label Encoding for Hundel Categories","b756c213":"## Split ","3a2a2e6f":"## Get Best Parameters ","300ad845":"# Setup hyper-parameters","94609b06":"# My Imports","984753d2":"# Best Model","e1c25a35":"# Import my dataSet Train_test"}}