{"cell_type":{"ae9b511e":"code","7035dfd7":"code","e3a70805":"code","e16e47d7":"code","a8206a2d":"code","eb041aa2":"code","87506fb7":"code","ed50df9b":"code","192fb0cf":"code","47cb3424":"code","b1b8c9c7":"code","635bdc21":"code","c19f6225":"code","97fd389c":"code","bfb36c13":"code","5ea20348":"code","33c7ecec":"code","4fd17b27":"code","d6628a5e":"code","1fe3db8e":"code","502f731e":"code","d8ad6582":"code","a39c0998":"code","a2076585":"code","9ee329c0":"code","ed85d1f2":"markdown","eeed110d":"markdown","796027b3":"markdown","01887716":"markdown","8994a661":"markdown","0e234ec1":"markdown","0b1ea5df":"markdown","b8001f26":"markdown","8a35db72":"markdown","55df5d23":"markdown","bae15aba":"markdown","ef7c303e":"markdown","564d6640":"markdown","c626ac68":"markdown","8d37bca2":"markdown","357b387b":"markdown","7ab64773":"markdown"},"source":{"ae9b511e":"# importaci\u00f3n de librerias para realizar la lectura del conjunto de datos\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import ScalarMappable\nfrom matplotlib import rcParams\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom iso3166 import countries\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\n\n\nrcParams['figure.figsize'] = 15,10.5\nrcParams['figure.dpi'] = 60\n\n","7035dfd7":"#cargamos el conjunto de datos en un dataframe y mostramos los 10 primeros registros\n\ndf = pd.read_csv('..\/input\/youtube-new\/USvideos.csv')\ndf.head(10)","e3a70805":"#Observamos que columnas tiene nuestro conjunto de datos y los tipos de cada dato\ndf.info()","e16e47d7":"Cantidad_Comentarios = df['category_id'].value_counts().reset_index()\nCantidad_Comentarios.columns = ['category_id', 'comment_count']\n\nsns.barplot(x = \"category_id\", y = \"comment_count\", data = Cantidad_Comentarios.head(5), palette='PuOr')\nrcParams['figure.figsize'] = 5,15\nplt.show()","a8206a2d":"likes_canal = df['channel_title'].value_counts().reset_index()\nlikes_canal.columns = ['channel_title', 'video_id']\n\n\nsns.barplot(x = \"video_id\", y = \"channel_title\", data = likes_canal.head(10), palette='PuOr')\nplt.show()","eb041aa2":"text = \"\".join(tags for tags in df['tags'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud = WordCloud(stopwords=stopwords, background_color='black').generate(text)\n\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","87506fb7":"vec = TfidfVectorizer(stop_words = 'english')\nvec.fit(df['tags'].values)\nfeatures = vec.transform(df['tags'].values)\nkmeans = KMeans(n_clusters = 3, random_state = 0)\nkmeans.fit(features)","ed50df9b":"res = kmeans.predict(features)\ndf['Cluster'] = res","192fb0cf":"text_cluster_1 = \" \".join(tweet for tweet in df[df['Cluster'] == 0]['tags'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_1 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_1)\n\nplt.imshow(wordcloud_1)\nplt.axis('off')\nplt.show()","47cb3424":"text_cluster_2 = \" \".join(tweet for tweet in df[df['Cluster'] == 1]['tags'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_2 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_2)\n\nplt.imshow(wordcloud_2)\nplt.axis('off')\nplt.show()","b1b8c9c7":"text_cluster_3 = \" \".join(tweet for tweet in df[df['Cluster'] == 1]['tags'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_3 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_3)\n\nplt.imshow(wordcloud_3)\nplt.axis('off')\nplt.show()","635bdc21":"top_users = df.sort_values('views', ascending =  False).drop_duplicates(subset = 'title', keep = 'first')\ntop_users = top_users[['title', 'views']]\ntop_users = pd.merge(top_users, number_tweets, 'inner')\n\n\n#Normalize the scale to make the color bar on the right of the bar plot\nnorm = plt.Normalize(top_users['likes'].min(), top_users['likes'].max())\nsm = plt.cm.ScalarMappable(cmap=\"PuOr\", norm=norm)\nsm.set_array([])\n#Show the barplot with color bar\nax = sns.barplot(x=\"views\", y = \"title\" , data = top_users.head(15), hue = 'tweets', dodge = False, palette = 'PuOr')\nax.get_legend().remove()\nax.figure.colorbar(sm)\nplt.show()\n","c19f6225":"top_users = df.sort_values('user_followers', ascending =  False).drop_duplicates(subset = 'user_name', keep = 'first')\ntop_users = top_users[['user_name', 'user_followers']]\ntop_users = pd.merge(top_users, number_tweets, 'inner')\n\n\n#Normalize the scale to make the color bar on the right of the bar plot\nnorm = plt.Normalize(top_users['tweets'].min(), top_users['tweets'].max())\nsm = plt.cm.ScalarMappable(cmap=\"PuOr\", norm=norm)\nsm.set_array([])\n#Show the barplot with color bar\nax = sns.barplot(x=\"user_followers\", y = \"user_name\" , data = top_users.head(15), hue = 'tweets', dodge = False, palette = 'PuOr')\nax.get_legend().remove()\nax.figure.colorbar(sm)\nplt.show()","97fd389c":"device = df['source'].value_counts().reset_index()\ndevice.columns = ['source', 'count']\ndevice['percent_tweets'] = round(device['count']\/device['count'].sum()*100, 2)\n\n\nsns.barplot(x = \"percent_tweets\", y = \"source\", data = device.head(10), palette = 'PuOr')\nplt.show()","bfb36c13":"df['user_created'] = pd.to_datetime(df['user_created'])\nnew_users = df[['user_created', 'user_name']].drop_duplicates(subset = 'user_name', keep = 'first')\nnew_users['user_created']= new_users['user_created'].dt.year\ncount_year = new_users['user_created'].value_counts().reset_index()\ncount_year.columns = ['year', 'number']\ncount_year\n\ncount_year['year'] = count_year[count_year['year']>1990]\nsns.lineplot(x = 'year', y = 'number', data = count_year, hue=\"year\",marker = 'o')\nplt.xlabel('Year')\nplt.ylabel('Number of New Users')\nplt.show()\n","5ea20348":"df['hashtags'] = df['hashtags'].fillna('[]')\ndf['hashtags_count'] = df['hashtags'].apply(lambda x: len(x.split(',')))\ndf.loc[df['hashtags'] == '[]', 'hashtags_count'] = 0\n\n# let's see the number of hashtags used by users\n#hashtag_per_user = df[['user_name','hashtags_count']].sort_values('hashtags_count', ascending =  False).drop_duplicates(subset = 'user_name', keep = 'first')\n#sns.barplot(x=\"hashtags_count\", y = \"user_name\", data = hashtag_per_user.head(30), palette = 'Blues_r')\n#plt.show()","33c7ecec":"def hashtags_split(x):\n    return str(x).lower().replace('[','').replace(']','').replace(\"'\",'').replace(\" \", '').split(',')\n\nhashtag_tweets = df.copy()\nhashtag_tweets['hashtag'] = hashtag_tweets['hashtags'].apply(lambda row: hashtags_split(row))\nhashtag_tweets = hashtag_tweets.explode('hashtag')\nhashtag_tweets.loc[hashtag_tweets['hashtag'] == '', 'hashtag'] = 'No Hashtag'\nhashtag_tweets.head()","4fd17b27":"hashtag_number = hashtag_tweets['hashtag'].value_counts().reset_index()\nhashtag_number.columns = ['hashtag', 'count']\n\nsns.barplot(x=\"count\", y = \"hashtag\", data = hashtag_number.head(10), palette = 'PuOr')\nplt.show()","d6628a5e":"text = \"\".join(tweet for tweet in df['text'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud = WordCloud(stopwords=stopwords, background_color='black').generate(text)\n\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","1fe3db8e":"vec = TfidfVectorizer(stop_words = 'english')\nvec.fit(df['text'].values)\nfeatures = vec.transform(df['text'].values)","502f731e":"kmeans = KMeans(n_clusters = 3, random_state = 0)\nkmeans.fit(features)","d8ad6582":"res = kmeans.predict(features)\ndf['Cluster'] = res\n","a39c0998":"text_cluster_1 = \" \".join(tweet for tweet in df[df['Cluster'] == 0]['text'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_1 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_1)\n\nplt.imshow(wordcloud_1)\nplt.axis('off')\nplt.show()","a2076585":"text_cluster_2 = \" \".join(tweet for tweet in df[df['Cluster'] == 1]['text'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_2 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_2)\n\nplt.imshow(wordcloud_2)\nplt.axis('off')\nplt.show()","9ee329c0":"text_cluster_3 = \" \".join(tweet for tweet in df[df['Cluster'] == 1]['text'])\nstopwords = set(STOPWORDS)\nstopwords.update(['https', 't','co', 'many', 's'])\n\nwordcloud_3 = WordCloud(max_words = 250, stopwords=stopwords, background_color='black').generate(text_cluster_3)\n\nplt.imshow(wordcloud_3)\nplt.axis('off')\nplt.show()","ed85d1f2":"<p style=\"text-align:justify; font-size: 24px\">\nAn\u00e1lisis de Sentimientos.<\/p>","eeed110d":"<p style=\"text-align:justify; font-size: 18px\">\n    Claramente podemos observar que las palabras que m\u00e1s se repiten son COVID 19, COVID, CORONAVIRUS, CASE, y people.\n    <\/p>","796027b3":"<p style=\"text-align:justify; font-size: 18px\">\nEl gr\u00e1fico del apartado 3 muestra claramente que los 3 dispositivos m\u00e1s usados para publicar tweets son Twitter apps, Twitter Android y Twitter for iphone. En su contraste entre las menos uasadas tenemos a Sprout Social, Instragam y FTTT. \n    <\/p>\n<p style=\"text-align:justify; font-size: 18px\">\n4.- Incremento de Tweets por A\u00f1o\n<\/p>\n","01887716":"<div>\n    <h1><p style=\"text-align:left; font-size: 24px\"> EXPLORACION Y ANALISIS DE DATOS DE YOUTUBE EE.UU.<\/p><\/h1>  \n<\/div>","8994a661":"<p style=\"text-align:justify; font-size: 24px\"> An\u00e1lisis de Textos <\/p>\n<p style=\"text-align:justify; font-size: 18px\">\nA continuaci\u00f3n realizaremos un an\u00e1lisis del texto que contienen los tweets que se han realizado durante la pandemia del covid 19. Para ello usaremos la columna hashtag para poder crear un wordcloud.<\/p>","0e234ec1":"<p style=\"text-align:justify; font-size: 18px\">\n3- <\/p>","0b1ea5df":"<p style=\"text-align:justify; font-size: 18px\">\nEn el gr\u00e1fico analizado en el punto 2, podemos observar que el usuario CNN cuenta con una mayor cantidad de seguidores, pero estos seguidores no han muchos comentarios sobre el covid 19, a diferencia de los usuarios The Times of India y China Xinhua que han realizadop una mayor cantidad de comentarios pero que no cuentan con una gran cantidad de seguidores.<\/p>\n\n<p style=\"text-align:justify; font-size: 18px\">\n3.- Medios m\u00e1s usados para publicar Tweets.<\/p>\n    ","b8001f26":"<p style=\"text-align:justify; font-size: 18px\">\nEl gr\u00e1fico del apartado 4 muestra claramente el incremento o decremento de usuarios en twitter entre los a\u00f1os 2006 y 2020, se puede observar un incremento de abismal de usuarios en el a\u00f1o 2009 que r\u00e1pidamente a ido en descenso en los a\u00f1os posteriores. Entre los a\u00f1os 2014 y 2018 se mantiene una constante en la cantidad de usuarios creados y a partir de finales del 2018 la tendencia aumenta hasta el 2020. <\/p>","8a35db72":"**2- TOP 10 - VIDEOS TOTALES POR CANAL**","55df5d23":"<p style=\"text-align:justify; font-size: 18px\">\nLo primero quew haremos ser\u00e1 reemplazar los datos nulos para poder obtener mejores gr\u00e1ficas y determinar cuales son los hashtags m\u00e1s populares en la base.<\/p>","bae15aba":"<p style=\"text-align:justify; font-size: 24px\"> Visualizaci\u00f3n de Datos <\/p>","ef7c303e":"<p style=\"text-align:justify; font-size: 18px\">\nEl presente gr\u00e1fico muestra cuales son los Hastags m\u00e1s relevantes en la base de datos<\/p>","564d6640":"<p p style=\"text-align:justify; font-size: 24px\"> CONTENIDO <\/p>\n<p style=\"text-align:justify; font-size: 18px\">\n    <ul style=\"text-align:justify; font-size: 18px\">\n        <li>Conjunto de datos<\/li>\n        <li>An\u00e1lisis del contenido<\/li>\n        <li>Clusterizaci\u00f3n<\/li>\n        \n<\/ul>\n    <\/p>\n    ","c626ac68":"<p style=\"text-align:justify; font-size: 18px\">\n   Ahora procederemos a realizar un wordcloud de los t\u00f3picos m\u00e1s relevantes.\n    <\/p>","8d37bca2":"<img src=\"https:\/\/neilpatel.com\/wp-content\/uploads\/2015\/09\/youtube.png\" align = 'center'>\n<p><i>INTEGRANTES - GRUPO 5<\/i><\/p>\n<p><i>- Veruska Palomino Cisneros<\/i><\/p>\n<p><i>- Bhernard Beisaga Arenas<\/i><\/p>\n<p><i>- Eraldo Valdivia Pinto<\/i><\/p>\n<p><i>- Miguel Paz Salinas<\/i><\/p>\n","357b387b":"<p style=\"text-align:justify; font-size: 18px\">\n    De los 3 grupos que se tienen para poder analizar se puede observar la siguiente el primer grupo muestra una tendencia a comentarios negativos en relaci\u00f3n al covit destacan palabras como pandemia, auxilio, casos y coronavirus. Sin embargo mientras analizamos el clustr 2 y 3 esta tendencia dismuniye pues est\u00e1 m\u00e1s destinada a la prevenci\u00f3n con palabras como mascarilla, noticias de hoy y el mundo por lo tanto podemos afirmnar que es un escenario mas positivo. \n    <\/p>\n","7ab64773":"# <p style=\"text-align:justify; font-size: 18px\">1.- Likes Totales por Canal - TOP 5<\/p>\n    \n   <p style=\"text-align:justify; font-size: 16px\">- CATEGORIA <\/p>\n   <p style=\"text-align:justify; font-size: 16px\">- 26 - Videotutoriales <\/p>\n   <p style=\"text-align:justify; font-size: 16px\">- 24 - Entretenimiento <\/p>\n   <p style=\"text-align:justify; font-size: 16px\">- 23 - Comedia <\/p>\n   <p style=\"text-align:justify; font-size: 16px\">- 22 - Videoblogs <\/p>\n   <p style=\"text-align:justify; font-size: 16px\">- 10 - Musica <\/p>"}}