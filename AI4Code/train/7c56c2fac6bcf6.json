{"cell_type":{"7aeeaea9":"code","a46d691e":"code","936bc8d3":"code","479d9c23":"code","d6254a62":"code","4663cb8d":"code","34caf0e9":"code","3b7151d3":"code","fd415d7e":"code","ef60cb15":"code","37862c3f":"code","804b0787":"code","ab565c41":"code","bd01b4f6":"code","faf40adc":"code","7199be06":"code","7cf34bb2":"code","5b1e24ea":"code","2cac0ff9":"code","5c29fe0d":"code","d462bae7":"code","a76b3cca":"code","8b0197f7":"code","a27c9726":"code","88fd22a2":"code","60112b78":"code","990c60a5":"code","55e86513":"code","9454ed18":"code","5f65cfa5":"code","cc24926f":"code","d07380c4":"code","b6de5c8e":"code","cf34c70b":"code","7e7da2c1":"code","7585fc25":"code","25899022":"code","9b3d7c46":"code","b5e1173a":"code","b141e7d1":"code","fd40c0a7":"code","ff0fd1d1":"code","ebc4eafc":"code","0f984ca5":"code","99173c20":"code","c51b6325":"code","9d8d02b8":"code","f634258b":"code","90d77b51":"code","b6256492":"code","619e93b6":"code","14c2ff43":"code","e8768040":"code","f1988217":"code","5b3d494e":"code","8b87bd5e":"code","feec0409":"code","1588275f":"code","4000c35e":"code","cee9edfe":"code","41d7cc72":"code","288c4f56":"code","0ee025ca":"code","71accdf4":"code","6bf3e779":"code","9f98d89c":"code","fbd9c0b0":"code","0a91e37a":"code","2422b384":"markdown","18379ddb":"markdown","b63d8af7":"markdown","2bf0cdf4":"markdown","7cc3966f":"markdown","21e8e338":"markdown","ed247eee":"markdown","a4404939":"markdown","13984449":"markdown","5d5f1602":"markdown","72c3d438":"markdown","05401f96":"markdown","c0ff5812":"markdown","48d09afe":"markdown","e19edcd7":"markdown","8085c3d6":"markdown","6ae75d6c":"markdown","a4930d2f":"markdown","02a61974":"markdown","79c297d9":"markdown","c0b0daa2":"markdown","804c85f3":"markdown","d562d202":"markdown","f030aac0":"markdown"},"source":{"7aeeaea9":"# importing packages\nimport numpy as np #Linear Algebra library\nimport pandas as pd #Data Analytical library\nimport matplotlib.pyplot as plt #Data Visualisation Library\nimport seaborn as sns #Statistical Visualisation Library\nimport sklearn.model_selection as ms\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","a46d691e":"# importing the training data and displaying first 100 cols.\ndf=pd.read_csv('..\/input\/ml-hackathon\/train_SJC.csv') \npd.set_option('display.max_columns', 100)\ndf","936bc8d3":"df.info() # information about the dataframe","479d9c23":"df.shape","d6254a62":"df.describe().transpose() #information about the data of non object dtypes","4663cb8d":"df.select_dtypes(include='object').describe().transpose()#information about the data of object dtypes","34caf0e9":"#creating a copy of data for preprocessing\ndf_copy = df.copy()\ndf_copy","3b7151d3":"df_copy.shape","fd415d7e":"# Checking for null values\ndf_copy.isnull().sum()","ef60cb15":"# imputing all missing values\ndf_copy['MaritalStatus'].fillna(df_copy['MaritalStatus'].mode()[0],inplace = True)\ndf_copy['WeeklyWages'].fillna(df_copy['WeeklyWages'].mean(),inplace = True)\ndf_copy['HoursWorkedPerWeek'].fillna(df_copy['HoursWorkedPerWeek'].mean(),inplace = True)\n","37862c3f":"df_copy.shape","804b0787":"# rechecking for null values\ndf_copy.isnull().sum()","ab565c41":"df_copy.describe().transpose()#information about the data of non object dtypes","bd01b4f6":"df_copy.select_dtypes(include='object').describe().transpose()#information about the data of object dtypes","faf40adc":"df_copy.plot.box(figsize = (16,6)) #Outlier analysis using boxplots\nplt.xticks(rotation = 90)","7199be06":"\ndf_copyz=df_copy.drop(['UltimateIncurredClaimCost','InitialIncurredCalimsCost'],axis=1)\ndf_copyz.plot.box(figsize = (16,6))\nplt.xticks(rotation = 90)\n","7cf34bb2":"plt.figure(figsize = (10, 10)) #correlation plot\nsns.heatmap(df_copy)","5b1e24ea":".corr(), annot = True, cmap = 'Blues')\nplt.title('Correlation matrix for numerical features')","2cac0ff9":"sns.distplot(df_copy,x=df_copy['UltimateIncurredClaimCost']) #distribution of the target variable","5c29fe0d":"sns.displot(data=df_copy,x='UltimateIncurredClaimCost',\n            col='MaritalStatus',palette='rocket',kind='hist')","d462bae7":"sns.displot(data=df_copy,x='UltimateIncurredClaimCost',\n            col='Gender',palette='rocket',kind='hist')","a76b3cca":"plt.figure(figsize=(15,6))\nsns.violinplot(x ='UltimateIncurredClaimCost',y='InitialIncurredCalimsCost',data=df_copy)\nplt.show()","8b0197f7":"# we remove columns whoose values have 0 variance\nfrom sklearn.feature_selection import VarianceThreshold\nvarthresh=VarianceThreshold(threshold=0)\nvarthresh.fit(df_copy)","a27c9726":"varthresh.get_support()","88fd22a2":"df_copy=df_copy.drop(['DaysWorkedPerWeek'],axis=1)#removing 'DaysWorkedPerWeek'","60112b78":"import sklearn.preprocessing as pre #importing sklearn.preprocessingsklearn.preprocessing\nlb=pre.LabelEncoder()","990c60a5":"#list of categorical variables\nlst=df_copy.select_dtypes(include='object').columns.to_list()\nlst","55e86513":"for x in lst: #Encoding one by one from the list\n    df_copy[x]=lb.fit_transform(df_copy[x])\ndf_copy.head()","9454ed18":"# features are listed\nsel_feat=['ClaimNumber','Age','Gender','MaritalStatus','DependentChildren','DependentsOther','WeeklyWages',\n                                        'PartTimeFullTime','HoursWorkedPerWeek','DaysWorkedPerWeek',\n                                        'ClaimDescription','InitialIncurredCalimsCost']","5f65cfa5":"df_ml=df_copy[sel_feat]#the list is made into a dataframe\ndf_ml","cc24926f":"df_test= pre.minmax_scale(df_ml.values) #using minmax scaling, the values are scaled between 0 and 1\ndf_test","d07380c4":"df_Norm = pd.DataFrame(data = df_test, columns = df_ml.columns.to_list()) # the scaled values are put back into df\ndf_Norm.head()","b6de5c8e":"# Input and target variables are separately written\ninput_var=df_Norm\ntarget=df_copy['UltimateIncurredClaimCost']\n","cf34c70b":"#train test splitting on 70:30 ratio\nx_train,x_test,y_train,y_test=ms.train_test_split(input_var,target,\n                                                  test_size=.3,random_state=11111)\nLR=LinearRegression()\nLR.fit(x_train,y_train)\nimportance = LR.coef_\nimportance","7e7da2c1":"# Input and target variables are separately written\ninput_var=df_Norm\ntarget=df_copy['UltimateIncurredClaimCost']\n","7585fc25":"#train test splitting on 70:30 ratio\nx_train,x_test,y_train,y_test=ms.train_test_split(input_var,target,\n                                                  test_size=.3,random_state=11111)","25899022":"#fitting linear regression\nLR=LinearRegression()\nLR.fit(x_train,y_train)","9b3d7c46":"# y_pred is the predictions\ny_pred=LR.predict(x_test)","b5e1173a":"# original and predicted data\ny_test,y_pred","b141e7d1":"#train and test results and rmse values\ntar_scr = LR.score(x_train,y_train)\ntes_scr = LR.score(x_test,y_test)\nmse = mean_squared_error(y_test,y_pred)\nrmse=np.sqrt(mse)","fd40c0a7":"# results tabulated\nfinalreport = {'Linear Regression':[tar_scr,tes_scr,rmse]}\nReport  = pd.DataFrame(finalreport, index = ['Train Score','Test Score','RMSE'])\nReport","ff0fd1d1":"# Calculating mean rmse from 10 fold crossvalidation\nfrom sklearn.model_selection import cross_val_score\nmse=cross_val_score(LR,input_var,target,scoring='neg_mean_squared_error',cv=10)\nmean_mse=np.mean(mse)\nRmse=np.sqrt(-mean_mse)\nRmse","ebc4eafc":"#Ridge regression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\n\nridge=Ridge()\nparameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\nridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\nridge_regressor.fit(input_var,target)\n","0f984ca5":"print(ridge_regressor.best_params_)\nprint(ridge_regressor.best_score_)","99173c20":"# original and predicted data using ridge\n\nprediction_ridge=ridge_regressor.predict(x_test)\ny_test,prediction_ridge","c51b6325":"# Rmse using ridge\nmse = mean_squared_error(y_test,prediction_ridge)\nrmse=np.sqrt(mse)\nrmse","9d8d02b8":"#lasso regression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nlasso=Lasso()\nparameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\nlasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n\nlasso_regressor.fit(input_var,target)\nprint(lasso_regressor.best_params_)\nprint(lasso_regressor.best_score_)","f634258b":"## original and predicted data using lasso\n\nprediction_lasso=lasso_regressor.predict(x_test)\ny_test,prediction_lasso","90d77b51":"# rmse using lasso\nmse = mean_squared_error(y_test,prediction_lasso)\nrmse=np.sqrt(mse)\nrmse","b6256492":"dftst=pd.read_csv('..\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv')\ndftst","619e93b6":"# checking null values\ndftst.isnull().sum()","14c2ff43":"# imputing null with mode\ndftst['MaritalStatus'].fillna(dftst['MaritalStatus'].mode()[0],inplace = True)\n","e8768040":"# rechecking null values\ndftst.isnull().sum()","f1988217":"lst","5b3d494e":"# label encoding\nfor x in lst:\n    dftst[x]=lb.fit_transform(dftst[x])\ndftst.head()","8b87bd5e":"df_ml=dftst[sel_feat]\ndf_ml","feec0409":"# minmax scaling\ndf_test= pre.minmax_scale(df_ml.values)\ndf_test","1588275f":"# normalised data\ndf_Norm = pd.DataFrame(data = df_test, columns = df_ml.columns.to_list())\ndf_Norm.head()","4000c35e":"# making predictions\ny_prednew7=lasso_regressor.predict(df_Norm)","cee9edfe":"y_pred1=ridge_regressor.predict(df_Norm)","41d7cc72":"# csv = pd.read_csv(\"..\/input\/insurance-prediction\/sample_submission.csv\")\n# csv[\"UltimateIncurredClaimCost\"]=y_prednew","288c4f56":"# csv.to_csv(\"Submission1.csv\", index = False)","0ee025ca":"# csv = pd.read_csv(\"..\/input\/insurance-prediction\/sample_submission.csv\")\n# csv[\"UltimateIncurredClaimCost\"]=y_pred1","71accdf4":"# csv.to_csv(\"Submission2.csv\", index = False)","6bf3e779":"ypred10=LR.predict(df_Norm)\n","9f98d89c":"ypred10.shape","fbd9c0b0":"csv = pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\ncsv[\"UltimateIncurredClaimCost\"]=ypred10","0a91e37a":"csv.to_csv(\"Submission10.csv\", index = False)","2422b384":"# create an empty list to store the output indices from multiple cols\nindex_list=[]\ncols=['InitialIncurredCalimsCost','UltimateIncurredClaimCost','WeeklyWages','HoursWorkedPerWeek','DaysWorkedPerWeek']\nfor i in cols:\n    index_list.extend(outliers(df_copy,i))\n    ","18379ddb":"def outliers(df,ft): #defining a function to detect outliers\n    Q1=df[ft].quantile(0.25)\n    Q3=df[ft].quantile(0.75)\n    IQR=Q3-Q1\n    Lower_Whisker = Q1-1.5*IQR\n    Upper_Whisker = Q3+1.5*IQR\n    ls=df.index[ (df[ft]<Lower_Whisker) | (df[ft]>Upper_Whisker) ]\n    return ls","b63d8af7":"###  8) Loading test data","2bf0cdf4":"### 3.3) Data Visualisation","7cc3966f":"## ML 24 Hrs Hackathon","21e8e338":"### 3.1) Descriptive Statistics","ed247eee":"### 7) Using Regularization techniques","a4404939":"### 7.2) Lasso Regression","13984449":"df_clean=remove(df_copy,index_list)#df_clean is the new df after removing the outliers\ndf_clean.shape","5d5f1602":"### 6) Model Building (Linear Regression)","72c3d438":"### 4) Feature Selection","05401f96":"### 4) Encoding the data","c0ff5812":"# Transformation of DateTimeOfAccident and DateReported to datetime format \ndf_clean['DateTimeOfAccident'] = pd.to_datetime(df_clean['DateTimeOfAccident'])\ndf_clean['DateReported'] = pd.to_datetime(df_clean['DateReported'])\ndf_clean\n","48d09afe":"### Feature Engineering","e19edcd7":"### 2) Data Preprocessing","8085c3d6":"### 2.1) Data cleaning","6ae75d6c":"def remove(df,ls): #this function gives a new dataframe without any outliers\n    ls= sorted(set(ls))\n    df=df.drop(ls)\n    return df","a4930d2f":"### 5) Data Normalisation","02a61974":"### 3) EDA\n- Descriptive Statistics\n- Outlier Analysis\n- Data Visualization","79c297d9":"### 3.2) Outlier Analysis","c0b0daa2":"### 1)Data Loading","804c85f3":"### 2.2) Data Transformation","d562d202":"### 7.1) Ridge Regression","f030aac0":"I chose linear regression model to predict the target variable. Linear regression is a very good \nmethod to predict target values which are continous in nature.Also I tried different regularization techniques,lasso and ridge regression.Also I could get a better rmse value for linear regression model."}}