{"cell_type":{"0e1d4ec0":"code","a5eca57e":"code","ce773351":"code","0f688e49":"code","53e444b2":"code","fd956876":"code","667bb5b8":"code","69aaac18":"markdown","df09e379":"markdown","ea68a006":"markdown","ff70a897":"markdown","c0f3a069":"markdown","19b09aff":"markdown","3a86fab8":"markdown","eb82ddf8":"markdown","509acfaa":"markdown"},"source":{"0e1d4ec0":"from kaggle_environments import make, evaluate\nimport numpy as np\nfrom random import choice","a5eca57e":"def makeBoard(obs):\n    return np.reshape(obs.board,(6,7))","ce773351":"# (credit to https:\/\/www.kaggle.com\/tanreinama\/simple-game-tree-max-depth-4 for checkWin function)\ndef checkWin(board):\n    for y in range(board.shape[0]):\n        for x in range(board.shape[1]):\n            if x+3 < board.shape[1] and board[y,x] != 0:\n                if board[y,x] == board[y,x+1] and \\\n                   board[y,x+1] == board[y,x+2] and \\\n                   board[y,x+2] == board[y,x+3]:\n                    return board[y,x]\n            if y+3 < board.shape[0] and board[y,x] != 0:\n                if board[y,x] == board[y+1,x] and \\\n                   board[y+1,x] == board[y+2,x] and \\\n                   board[y+2,x] == board[y+3,x]:\n                    return board[y,x]\n            if x+3 < board.shape[1] and y+3 < board.shape[0] and board[y,x] != 0:\n                if board[y,x] == board[y+1,x+1] and \\\n                   board[y+1,x+1] == board[y+2,x+2] and \\\n                   board[y+2,x+2] == board[y+3,x+3]:\n                    return board[y,x]\n            if x+3 < board.shape[1] and y+3 < board.shape[0] and board[y+3,x] != 0:\n                if board[y+3,x] == board[y+2,x+1] and \\\n                   board[y+2,x+1] == board[y+1,x+2] and \\\n                   board[y+1,x+2] == board[y,x+3]:\n                    return board[y+3,x]\n    return 0","0f688e49":"def ifDropInCol(board, col, player):  \n    newBoard=board.copy()\n    if newBoard[0,col]==0:\n        zeroLoc=0\n        for y in range(newBoard.shape[0]):\n            if newBoard[y,col]==0:\n                zeroLoc=y\n        newBoard[zeroLoc,col]=player\n        return newBoard","53e444b2":"def myAgent(obs, config):    \n    # Which player is which?\n    myPlayer=obs.mark\n    otherPlayer=myPlayer % 2 + 1\n    board=makeBoard(obs)\n    moves=[c for c in range(config.columns) if obs.board[c]==0]\n\n    ##### Actual Agent Starts Here\n\n    # Find any definite winning Moves\n    for m in moves:\n        if checkWin(ifDropInCol(board,m,myPlayer))==myPlayer:\n            return m\n        \n    # Find any Defending Moves\n    for d in moves:\n        if checkWin(ifDropInCol(board,d,otherPlayer))==otherPlayer:\n            return d\n        \n    # Centerload Random Choices so Center is more likely\n    if 3 in moves:\n        for i in range(8):\n            moves.append(3) \n    if 2 in moves:\n        for i in range(4):\n            moves.append(2)\n    if 4 in moves:\n        for i in range(4):\n            moves.append(4)\n    if 1 in moves:\n        for i in range(2):\n            moves.append(1)\n    if 5 in moves:\n        for i in range(2):\n            moves.append(5)\n            \n    # Randomly return an available space from the list.\n    if len(moves)!=1:\n        return choice(moves)\n    \n    # If theres only 1 space available return it (choice errors out with fewer than 2 options)\n    else:\n        return moves[0]\n    \n","fd956876":"def avgReward(x):\n    rewards=[a if a[0]!=None else [.5,.5] for a in x]\n    return sum(r[0] for r in rewards) \/ sum(r[0] + r[1] for r in rewards)","667bb5b8":"reps=100\nrandomFirst=evaluate('connectx',[myAgent,'random'], num_episodes=reps)\nprint(\"Agent vs Random, Going first: \"+str(avgReward(randomFirst)))\nrandomSecond=evaluate('connectx',['random',myAgent], num_episodes=reps)\nprint(\"Agent vs Random, Going second: \"+str(1-avgReward(randomSecond)))\n\n#Reduce Reps for Negamax, as it takes a lot longer to run...\nreps=20\nnegamaxFirst=evaluate('connectx',[myAgent,'negamax'], num_episodes=reps)\nprint(\"Agent vs Negamax, Going first: \"+str(avgReward(negamaxFirst)))\nnegamaxSecond=evaluate('connectx',['negamax',myAgent], num_episodes=reps)\nprint(\"Agent vs Negamax, Going second: \"+str(1-avgReward(negamaxSecond)))","69aaac18":"The checkWin function (credit to kernel posted by user tanreinama) goes through the grid and checks to see if there are any 4 in a rows vertically, horizontally, or in either diagonal","df09e379":"the ifDropInCol function creates another board simulating what the board would look like if you (or your opponent) picked that column.","ea68a006":"First for some bookkeeping.  The Agent notes down which player you are and what the opponent is, as well as creates a board from the observation since it's easier to work with.  It then looks and sees which columns still have open space in them and notes them as the possible moves you can mak\n\nNow the logic begns.  The agent simulates dropping a tile into each space and sees if any would win you the game.  If so, it takes that move.\n\nIf there are no definite winning spaces, the agent checks if dropping an opponent tile into an available space would make them win the game.  If so, you go there instead blocking it.\n\nIf neither of those two methods give a definite best spot to go, it picks a space randomly.  However, This random decision is weighted towards the center being most likely, then the next rows out and so on with the edges being least likely.  This is based on the thought that the center spaces are \"Better\" since they can be involved in the most 4-in-a-rows.","ff70a897":"Now we wanst to test this against Random and Negamax.  To do that we'll need a reward function.  \n\nThe below is slightly modified from other ones you may see posted , I was having issues with handling of ties and this solved it.","c0f3a069":"The makeBoard function turns the observation list into a 2d array.","19b09aff":"This Is a pretty basic Agent runs off of three basic principles:\n   1) If there is a clear winning move you should take it\n   2) If there is a clear winning move for your opponent you should block it\n   3) Spaces close to the center tend to be better than those near the edges","3a86fab8":"The agent almost always outperforms random, and does better than 50\/50 against negamax.  \nThe Agent continues to improve as more rules are added, but it also slows down.  For a rules-based approach this is a good starting point.","eb82ddf8":"First let's import everything we'll need.","509acfaa":"Now to run some simulations, as both first and second player"}}