{"cell_type":{"c8312aa7":"code","ac61d089":"code","6fb08f1b":"code","909cb529":"code","c2c62c10":"code","ed8a280f":"code","f75520ae":"code","2ee91c86":"code","7872babf":"code","85cd8d4e":"code","e26e67fe":"code","fc737024":"code","edf85a99":"code","d1ac22d5":"code","59a0fe8e":"code","fcfd44e1":"code","3977f4b4":"code","a798e7b3":"code","9da28ef6":"code","d4ddb3d3":"code","fa52c5ee":"code","c6edb300":"code","e32cfff1":"code","910e9a0a":"code","caac4566":"code","b6c3db27":"code","0fb88136":"code","d1d657e6":"code","7a981d26":"code","08ab0a22":"code","2e92a75a":"code","12fdb524":"code","4b1c9320":"code","fca858e6":"code","924face6":"code","0febf4e0":"code","290048a9":"code","4cbacac9":"code","c19889f1":"code","f9a214b5":"code","6942a678":"code","1c2577ab":"code","a17eae96":"code","f0faee29":"code","b79417b7":"code","04669318":"code","5a879d77":"code","751eef7c":"code","d9eeaf82":"code","5a1c408c":"markdown","2ead57e8":"markdown","c1dae251":"markdown","42a6e4e5":"markdown","0fe72aa1":"markdown","346b8bea":"markdown","0ace9db2":"markdown","eea46d56":"markdown","714e07f5":"markdown","89943be8":"markdown","341fee30":"markdown","42fd5936":"markdown","e5675803":"markdown","ca348d74":"markdown","ec1156ee":"markdown","fd749dfe":"markdown","d43fb7d3":"markdown"},"source":{"c8312aa7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac61d089":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\n","6fb08f1b":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nall_data = [train,test]","909cb529":"train.head()","c2c62c10":"train.info()","ed8a280f":"train.describe()","f75520ae":"print (train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\n\nprint()\nprint(pd.crosstab(train.Survived,train.Sex))\n\nplt.figure(figsize=(12,5))\nsns.countplot(x=\"Sex\", data=train, hue=\"Survived\",palette=\"hls\")\nplt.title('Sex Distribuition by survived or not', fontsize=20)\nplt.xlabel('Sex Distribuition',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()\n","2ee91c86":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","7872babf":"print (train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean())","85cd8d4e":"print (train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean())","e26e67fe":"for dataset in all_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\nsns.factorplot(x=\"FamilySize\",y=\"Survived\", data=train, kind=\"bar\",size=6, aspect=1.6)\nplt.show()","fc737024":"train = train.drop(['Parch', 'SibSp'], axis=1)\ntest = test.drop(['Parch', 'SibSp'], axis=1)\nall_data = [train, test]\ntrain.head()","edf85a99":"x = train['Age']\nplt.hist(x)\n","d1ac22d5":"x = train[['Age' , 'Survived']]\nx1 = x.loc[x['Survived'] == 1]\nx2 = x.loc[x['Survived'] == 0]\nbins = np.linspace(0, 80, 10)\nplt.hist([x1['Age'], x2['Age']], bins, label=['Survived == 1', 'Survived == 0'])\nplt.legend(loc = \"upper right\")\n\n\n","59a0fe8e":"print(pd.crosstab(train.Survived, train.Embarked))\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Embarked\", data=train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Embarked',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()\n","fcfd44e1":"train.isnull().sum()","3977f4b4":"test.isnull().sum()","a798e7b3":"for dataset in all_data:\n    dataset['Age'].fillna(dataset['Age'].mean(),inplace=True)\n    dataset['Embarked'].fillna('S', inplace = True)\n    dataset['Fare'].fillna(dataset['Fare'].mean(), inplace = True)\nall_data = [train, test]\n","9da28ef6":"train.isnull().sum()","d4ddb3d3":"test.isnull().sum()","fa52c5ee":"#Converting Embarked to integer\nports = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in all_data:\n    dataset['Embarked'] = dataset['Embarked'].map(ports)\nall_data = [train,test]\n","c6edb300":"#Converting Sex to integer\nports = {\"male\": 0, \"female\": 1}\nfor dataset in all_data:\n    dataset['Sex'] = dataset['Sex'].map(ports)\nall_data = [train,test]\n","e32cfff1":"for dataset in all_data:\n    dataset = dataset.drop(['Ticket', 'Cabin'], axis =1, inplace = True)\nall_data = [train, test]\n","910e9a0a":"train.info()","caac4566":"train.isnull().sum()","b6c3db27":"quartile1 = 20\nmedian = 28\nquartile3 = 38\nfor dataset in all_data:\n    dataset.loc[ dataset['Age'] <= quartile1, 'Age' ] = 0\n    dataset.loc[ (dataset['Age'] > quartile1 ) & (dataset['Age'] < median ), 'Age'] = 1\n    dataset.loc[ (dataset['Age'] > median ) & (dataset['Age'] < quartile3 ), 'Age'] = 2\n    dataset.loc[ dataset['Age'] >= quartile3, 'Age' ] = 3\nall_data =[train, test]","0fb88136":"quartile1 = 8\nmedian = 14\nquartile3 = 31\nfor dataset in all_data:\n    dataset.loc[ dataset['Fare'] <= quartile1, 'Fare' ] = 0\n    dataset.loc[ (dataset['Fare'] > quartile1 ) & (dataset['Fare'] <= median ), 'Fare'] = 1\n    dataset.loc[ (dataset['Fare'] > median ) & (dataset['Fare'] < quartile3 ), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] >= quartile3, 'Fare' ] = 3\nall_data =[train, test]\n","d1d657e6":"plt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Fare\", data=train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('Fare',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()","7a981d26":"y = list()\nfor i in range(891):\n    x = train['Name'][i]\n    y.append(len(x))\ntrain['NameLength'] = y","08ab0a22":"y = list()\nfor i in range(418):\n    x = test['Name'][i]\n    y.append(len(x))\ntest['NameLength'] = y\n\nall_data = [train, test]","2e92a75a":"test['NameLength'].describe()","12fdb524":"quartile1 = 20\nmedian = 25\nquartile3 = 31\n\nfor dataset in all_data:\n    dataset.loc[ dataset['NameLength'] <= quartile1, 'NameLength' ] = 0\n    dataset.loc[ (dataset['NameLength'] > quartile1 ) & (dataset['NameLength'] <= median ), 'NameLength'] = 1\n    dataset.loc[ (dataset['NameLength'] > median ) & (dataset['NameLength'] < quartile3 ), 'NameLength'] = 2\n    dataset.loc[ dataset['NameLength'] >= quartile3, 'NameLength' ] = 3\nall_data =[train, test]","4b1c9320":"plt.figure(figsize=(12,5))\n\nsns.countplot(x=\"NameLength\", data=train, hue=\"Survived\",palette=\"hls\")\nplt.title('Class Distribuition by survived or not',fontsize=20)\nplt.xlabel('NameLength',fontsize=17)\nplt.ylabel('Count', fontsize=17)\n\nplt.show()","fca858e6":"for dataset in all_data:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nall_data = [train, test]\n\npd.crosstab(train['Title'], train['Sex'])","924face6":"for dataset in all_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","0febf4e0":"ports = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in all_data:\n    dataset['Title'] = dataset['Title'].map(ports)\n    dataset['Title'] = dataset['Title'].fillna(0)\n","290048a9":"train = train.drop(['Name', 'PassengerId'], axis=1)\ntest = test.drop(['Name'], axis=1)\nall_data = [train, test]","4cbacac9":"X_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nX_test  = test.drop(\"PassengerId\", axis=1).copy()\n\n#Apply RandomForestClassifier\nrandom_forest= RandomForestClassifier(n_estimators=100,\n                             max_features='auto',\n                             criterion='entropy',\n                             max_depth=10)\nrandom_forest.fit(X_train, Y_train)\n\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")","c19889f1":"#Apply GradientBoostingClassifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n                                 max_depth=1, random_state=0).fit(X_train, Y_train)\ny_prediction= clf.predict(X_test)\nclf.score(X_train, Y_train)\nacc_clf = round(clf.score(X_train, Y_train) * 100, 2)\nprint(round(acc_clf,2,), \"%\")","f9a214b5":"#Apply LGBMClassifier\n\nfrom lightgbm import LGBMClassifier\nmodel = LGBMClassifier().fit(X_train, Y_train)\ny_predict= model.predict(X_test)\nmodel.score(X_train, Y_train)\nacc_model = round(model.score(X_train, Y_train) * 100, 2)\nprint(round(acc_model,2,), \"%\")","6942a678":"#Apply Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nprint(round(acc_log,2,), \"%\")","1c2577ab":"# Apply Decision Tree\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\n\nY_pred = decision_tree.predict(X_test)\n\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nprint(round(acc_decision_tree,2,), \"%\")","a17eae96":"from xgboost import XGBClassifier\n\nparams_xgb = {'colsample_bylevel': 0.7, 'learning_rate': 0.03, 'max_depth': 3, \n              'n_estimators': 400, 'reg_lambda': 15, 'subsample': 0.5}\nxgb = XGBClassifier(**params_xgb)\ny_preds = xgb.fit(X_train, Y_train).predict(X_test)\nacc_xgb = round(xgb.score(X_train, Y_train) * 100, 2)\nprint(round(acc_xgb,2,), \"%\")","f0faee29":"results = pd.DataFrame({\n    'Model': ['LGBMClassifier', 'Logistic Regression', \n              'Random Forest', 'Boosting', \n              'Decision Tree', 'xgb'],\n    'Score': [ acc_model,acc_log,\n              acc_random_forest, acc_clf,\n              acc_decision_tree, acc_xgb]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(7)","b79417b7":"from sklearn.model_selection import cross_val_score\nrf = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","04669318":"importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head(15)\n","5a879d77":"importances.plot.bar()","751eef7c":"xgb = XGBClassifier(**params_xgb)\ny_preds = xgb.fit(X_train, Y_train).predict(X_test)","d9eeaf82":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': y_preds})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5a1c408c":"4. Parch","2ead57e8":"A. Age","c1dae251":"2. Categorical data in *Sex, Embarked*","42a6e4e5":"B. Fare","0fe72aa1":"1. Missing Values in *Age, Cabin, Embarked*","346b8bea":"3. Mix of numbers and letters in *Ticket, Cabin*","0ace9db2":"6. Embarked","eea46d56":"**Cleaning**","714e07f5":"2. Pclass","89943be8":"1. Sex","341fee30":"C. Name","42fd5936":"3. SibSp","e5675803":"5. SibSp + Parch","ca348d74":"**ML**","ec1156ee":"4. Let's simplify the informations","fd749dfe":"**Exploration**","d43fb7d3":"5. Age"}}