{"cell_type":{"33d3efcd":"code","0d9d5f12":"code","42fd42b9":"code","a4137139":"code","22daba1b":"code","6a2c206d":"code","b96837df":"code","962b8840":"code","1ca1d6eb":"code","c0a99fe4":"code","2020c363":"code","a67a5365":"code","9efb2a7f":"code","ffbd6cf2":"code","73c48027":"code","0213b2ff":"code","54eea9b9":"code","1410daf1":"code","f0d8da98":"markdown","05e7fa81":"markdown","7555970a":"markdown","d8080b88":"markdown","333c0164":"markdown","5dd50aab":"markdown","1e797a3b":"markdown","3b03226d":"markdown","5962bb66":"markdown","2c5917f3":"markdown","1101ff23":"markdown","46992030":"markdown","4a0cc432":"markdown","602bb877":"markdown"},"source":{"33d3efcd":"## This kernel must be run on Python=3.6\nimport numpy as np \nimport pandas as pd  #Python Data Analysis Library\nimport random\n\nimport scipy.ndimage as scipyImg\nimport scipy.misc as misc\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport os\n\n%matplotlib inline","0d9d5f12":"## Disabling filter warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","42fd42b9":"## Defining basic functions\ndef basic_readImg(directory, filename):\n    '''Reading an RGB image through the scipy library. Provides an array.\n    Sintaxe: basic_readImg(directory, filename).'''\n    sample = scipyImg.imread(directory + filename, mode='RGB')\n    if sample.shape[2] != 3:\n        return 'The input must be an RGB image.'\n    return sample\n\ndef basic_showImg(img, size=4):\n    ''' Displays the image at the chosen size. The image (img) should be read through basic_readImg().\n    Sintaxe: basic_showImg(img, size=4).'''\n    plt.figure(figsize=(size,size))\n    plt.imshow(img)\n    plt.show()\n    \ndef basic_writeImg(directory, filename, img):\n    misc.imsave(directory+filename, img)","a4137139":"## Loading the dataset and showing the first rows:\ndepths = pd.read_csv('..\/input\/depths.csv')\ndepths.head(2)","22daba1b":"train_masks = pd.read_csv('..\/input\/train.csv')\ntrain_masks.head(2)","6a2c206d":"def rleToMask(rleString,height,width):\n    rows,cols = height,width\n    try:\n        rleNumbers = [int(numstring) for numstring in rleString.split(' ')]\n        rlePairs = np.array(rleNumbers).reshape(-1,2)\n        img = np.zeros(rows*cols,dtype=np.uint8)\n        for index,length in rlePairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n    except:\n        img = np.zeros((cols,rows))\n    return img","b96837df":"file_imgs = os.listdir(path='..\/input\/train\/images\/')\nfile_masks = os.listdir(path='..\/input\/train\/masks\/')\nprint('Images found: {0}\\nCorresponding masks: {1}'.format(len(file_imgs), len(file_masks)))","962b8840":"## Defining a function since there's sample without valid RLE.\ndef choose_sample(data=train_masks):\n    ## Choosing a random image from train dataset:\n    sample = random.choice(range(len(data)))\n\n    ## Parsing the sample information:\n    sample_id = data['id'][sample]\n    sample_depth = depths[depths['id'] == sample_id]['z'].values[0]\n    sample_RLEstring = data['rle_mask'][sample]\n    try: \n        sample_RLE = rleToMask(sample_RLEstring, 101,101)\n    except: \n        sample_RLE = np.zeros((101,101))\n    file_name = sample_id + '.png'\n    sample_img = basic_readImg('..\/input\/train\/images\/',file_name)\n    sample_mask = basic_readImg('..\/input\/train\/masks\/',file_name)\n    \n    fig1, axes = plt.subplots(1,3, figsize=(10,4))\n    axes[0].imshow(sample_img)\n    axes[0].set_xlabel('Subsurface image')\n    axes[1].imshow(sample_mask)\n    axes[1].set_xlabel('Provided mask')\n    axes[2].imshow(sample_RLE)\n    axes[2].set_xlabel('Decoded RLE mask')\n    fig1.suptitle('Image ID = {0}\\nDepth = {1} ft.'.format(sample_id, sample_depth));\n    return","1ca1d6eb":"choose_sample()","c0a99fe4":"df1 = depths.set_index('id')\ndf2= train_masks.set_index('id')\ndataset = pd.concat([df1, df2], axis=1, join='inner')\ndataset = dataset.reset_index()","2020c363":"dataset['mask'] = dataset['rle_mask'].apply(lambda x: rleToMask(x, 101,101))","a67a5365":"def salt_proportion(imgArray):\n    try: \n        unique, counts = np.unique(imgArray, return_counts=True)\n        ## The total number of pixels is 101*101 = 10,201\n        return counts[1]\/10201.\n    except: \n        return 0.0","9efb2a7f":"dataset['salt_proportion'] = dataset['mask'].apply(lambda x: salt_proportion(x))","ffbd6cf2":"dataset.head()","73c48027":"sns.set();\nsns.distplot(dataset['z'], bins=20)","0213b2ff":"sns.pairplot(dataset, vars=['z', 'salt_proportion'])","54eea9b9":"dataset['target'] = pd.cut(dataset['salt_proportion'], bins=[0, 0.001, 0.1, 0.4, 0.6, 0.9, 1.0], \n       include_lowest=True, labels=['No salt', 'Very low', 'Low', 'Medium', 'High', 'Very high'])","1410daf1":"dataset.tail()","f0d8da98":"<a name='secC'><\/a>\n## C. Exploratory Data Analysis\n<a name='secC.1'><\/a>\n### C.1. Creating a feature dataset\nPutting together all the training information we have.\n","05e7fa81":"<a name='secC.2'><\/a>\n### C.2. Taking a look at depth\nHow is depth distributed along the dataset?\n","7555970a":"<a name='secB'><\/a>\n## B. Understanding the data\n<a name='secB.1'><\/a>\n### B.1. Background  \n*The information in this section is from [TGS Salt Challenge page](https:\/\/www.kaggle.com\/c\/tgs-salt-identification-challenge\/data)*.  \n\nSeismic data is collected using reflection seismology, or seismic reflection. The method requires a controlled seismic source of energy, such as compressed air or a seismic vibrator, and sensors record the reflection from rock interfaces within the subsurface. The recorded data is then processed to create a 3D view of earth\u2019s interior. Reflection seismology is similar to X-ray, sonar and echolocation.\n\nA seismic image is produced from imaging the reflection coming from rock boundaries. The seismic image shows the boundaries between different rock types. In theory, the strength of reflection is directly proportional to the difference in the physical properties on either sides of the interface. While seismic images show rock boundaries, they don't say much about the rock themselves; some rocks are easy to identify while some are difficult.\n\nThere are several areas of the world where there are vast quantities of salt in the subsurface. One of the challenges of seismic imaging is to identify the part of subsurface which is salt. Salt has characteristics that makes it both simple and hard to identify. Salt density is usually 2.14 g\/cc which is lower than most surrounding rocks. The seismic velocity of salt is 4.5 km\/sec, which is usually faster than its surrounding rocks. This difference creates a sharp reflection at the salt-sediment interface. Usually salt is an amorphous rock without much internal structure. This means that there is typically not much reflectivity inside the salt, unless there are sediments trapped inside it. The unusually high seismic velocity of salt can create problems with seismic imaging.\n","d8080b88":"<a name='secB.2'><\/a>\n### B.2. Available data\nThe data is a set of images chosen at various locations chosen at random in the subsurface. The images are 101 x 101 pixels and each pixel is classified as either salt or sediment. In addition to the seismic images, the depth of the imaged location is provided for each image. The goal of the competition is to segment regions that contain salt.","333c0164":"This kernel proposal is to carry out the initial analysis of the images made available by TGS.  \n\n## Summary:\n* [A. Initial statements](#secA)  \n\n* [B. Understanding the data](#secB)\n  * [B.1. Background](#secB.1)\n  * [B.2. Available data](#secB.2)  \n  * [B.3. Loading the data](#secB.3)\n  * [B.4. Choosing a random sample](#secB.4)\n  \n* [C. Feature extraction](#secC)\n  * [C.1 Creating a feature dataset](#secC.1)\n  * [C.2 Taking a look at depth](#secC.2)\n  * [C.3 Target defining](#secC.3)","5dd50aab":"<a name='secB.3'><\/a>\n### B.3. Loading the data\n#### Depths database reading  \nThe depth underground (in feet) of each image is available on the *depths.csv* file, where the attribute *id* is the unique image identifier and *z* is its depth in feet (1 feet equals 0.3048 meters).","1e797a3b":"Regarding the training data, for each subsurface image there is its corresponding mask, listed below:","3b03226d":"In order to read such encoded masks, I will make use of [the function created by Robert](https:\/\/www.kaggle.com\/robertkag\/rle-to-mask-converter) at Kaggle, which reads the RLE string and generates an image array corresponding to the mask:  ","5962bb66":"<a name='secA'><\/a>\n## A. Initial statements","2c5917f3":"<a name='secC.3'><\/a>\n### C.3. Target defining\nIn this first approach I will consider the salt proportion as a target feature. In this way, I'll divide the dataset into four salty categories:  \ni. No salt [0%]  \nii. Very low [0.01% - 10%]  \niii. Low [10.01% - 40%]  \niv. Medium [40.01% - 60%]  \nv. High [60.01% - 90%]  \nvi. Very high [> 90%]","1101ff23":"#### Training set masks in RLE\nTGS has also made available some [Run-length encoding (RLE)](https:\/\/en.wikipedia.org\/wiki\/Run-length_encoding) masks with the salt portion of the images already identified.","46992030":"The pairplot above results are expected, since the salt proportion in each image is related to the region from which the data were colected. Next steps now is to extract some features from the *salty* regions in order to correlate it with depth as well as other attributes.","4a0cc432":"<a name='secB.4'><\/a>\n### B.4. Choosing a random sample","602bb877":"# TGS - Salt identification challenge\nFirst exploratory data analysis.  \n2018.07.20  "}}