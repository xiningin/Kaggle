{"cell_type":{"5298864f":"code","de6dab5e":"code","a41a9229":"code","b8669caa":"code","2915ab90":"code","17d227e9":"code","8ab13ca6":"code","61924784":"code","5cb7d8fb":"code","d83eaf71":"code","bc07022a":"code","d1c4e3dd":"code","fb068b33":"code","489f8bd2":"code","14c85740":"code","ea3ff646":"code","9cbe9061":"code","46239766":"code","3b61db71":"code","9d31066d":"code","e37b877f":"code","93e64caa":"code","bd3b9a17":"code","3e5b6d5b":"code","980d548a":"code","08b40fcb":"code","0bb99e01":"code","3836af93":"code","a05f7046":"code","aa7aac00":"code","7c630442":"code","3f649b33":"code","ae590509":"code","2a377d9d":"code","f7b83abb":"code","58efe277":"code","fa0b1797":"code","313e71cd":"code","8ec569bf":"markdown","2f164cd5":"markdown","ac1ee64f":"markdown","16ba5ccd":"markdown","3613d172":"markdown","28544324":"markdown","7e119192":"markdown","c355c704":"markdown","051e6829":"markdown","9db6697f":"markdown"},"source":{"5298864f":"from fastai.core import *\nPath.read_csv = lambda o: pd.read_csv(o)\ninput_path = Path(\"\/kaggle\/input\/data-science-bowl-2019\") # kaggle\n# input_path = Path(\"data\/\") # local\npd.options.display.max_columns=200\npd.options.display.max_rows=200\ninput_path.ls()","de6dab5e":"train_with_features_part2 = pd.read_feather(\"..\/input\/dsbowl-feng-part2\/train_with_features_part2.fth\") #kaggle\n# train_with_features_part2 = pd.read_feather(\"output\/dsbowl-feng-part2\/train_with_features_part2.fth\") #local","a41a9229":"sample_subdf = (input_path\/'sample_submission.csv').read_csv()\n# specs_df = (input_path\/\"specs.csv\").read_csv()\n# train_labels_df = (input_path\/\"train_labels.csv\").read_csv()\n# train_df = (input_path\/\"train.csv\").read_csv()\ntest_df = (input_path\/\"test.csv\").read_csv()","b8669caa":"# for c in ['event_id', 'type', 'title', 'world', 'event_code']: print(c, set(test_df[c]).difference(set(train_df[c])))","2915ab90":"from fastai.tabular import *\nimport types\n\nstats = [\"median\",\"mean\",\"sum\",\"min\",\"max\"]\nUNIQUE_COL_VALS = pickle.load(open(\"..\/input\/dsbowl-feng-part2\/UNIQUE_COL_VALS.pkl\", \"rb\")) #kaggle\n# UNIQUE_COL_VALS = pickle.load(open(\"output\/dsbowl-feng-part2\/UNIQUE_COL_VALS.pkl\", \"rb\")) #local","17d227e9":"for k in UNIQUE_COL_VALS.__dict__.keys(): print(k, len(UNIQUE_COL_VALS.__dict__[k]))","8ab13ca6":"def array_output(f):\n    def inner(*args, **kwargs): return array(listify(f(*args, **kwargs))).flatten()\n    return inner\n\nfeature_funcs = []\n\n@array_output\ndef time_elapsed_since_hist_begin(df):\n    \"total time passed until assessment begin\"\n    return df['timestampElapsed'].max() - df['timestampElapsed'].min()\n\nfeature_funcs.append(time_elapsed_since_hist_begin)\n\n@array_output\ndef time_elapsed_since_each(df, types, dfcol):\n    \"time since last occurence of each types, if type not seen then time since history begin\"\n    types = UNIQUE_COL_VALS.__dict__[types]\n    last_elapsed = df['timestampElapsed'].max()\n    _d = dict(df.iloc[:-1].groupby(dfcol)['timestampElapsed'].max())\n    return [last_elapsed - _d[t] if t in _d else time_elapsed_since_hist_begin(df)[0] for t in types]\n\nfeature_funcs.append(partial(time_elapsed_since_each, types=\"media_types\", dfcol=\"type\"))\nfeature_funcs.append(partial(time_elapsed_since_each, types=\"titles\", dfcol=\"title\"))\nfeature_funcs.append(partial(time_elapsed_since_each, types=\"event_ids\", dfcol=\"event_id\"))\nfeature_funcs.append(partial(time_elapsed_since_each, types=\"worlds\", dfcol=\"world\"))\nfeature_funcs.append(partial(time_elapsed_since_each, types=\"event_codes\", dfcol=\"event_code\"))\n\n@array_output\ndef countfreqhist(df, types, dfcol, freq=False):\n    \"count or freq of types until assessment begin\"\n    types = UNIQUE_COL_VALS.__dict__[types]\n    _d = dict(df[dfcol].value_counts(normalize=(True if freq else False)))\n    return [_d[t] if t in _d else 0 for t in types]\n\nfeature_funcs.append(partial(countfreqhist, types=\"media_types\", dfcol=\"type\", freq=False))\nfeature_funcs.append(partial(countfreqhist, types=\"media_types\", dfcol=\"type\", freq=True))\n\nfeature_funcs.append(partial(countfreqhist, types=\"titles\", dfcol=\"title\", freq=False))\nfeature_funcs.append(partial(countfreqhist, types=\"titles\", dfcol=\"title\", freq=True))\n\nfeature_funcs.append(partial(countfreqhist, types=\"event_ids\", dfcol=\"event_id\", freq=False))\nfeature_funcs.append(partial(countfreqhist, types=\"event_ids\", dfcol=\"event_id\", freq=True))\n\nfeature_funcs.append(partial(countfreqhist, types=\"worlds\", dfcol=\"world\", freq=False))\nfeature_funcs.append(partial(countfreqhist, types=\"worlds\", dfcol=\"world\", freq=True))\n\nfeature_funcs.append(partial(countfreqhist, types=\"event_codes\", dfcol=\"event_code\", freq=False))\nfeature_funcs.append(partial(countfreqhist, types=\"event_codes\", dfcol=\"event_code\", freq=True))\n\n@array_output\ndef overall_event_count_stats(df):\n    \"overall event count stats until assessment begin\"\n    return df['event_count'].agg(stats)\nfeature_funcs.append(overall_event_count_stats)\n\n@array_output\ndef event_count_stats_each(df, types, dfcol):\n    \"event count stats per media types until assessment begin, all zeros if media type missing for user\"\n    types = UNIQUE_COL_VALS.__dict__[types]\n    _stats_df = df.groupby(dfcol)['event_count'].agg(stats)\n    _d = dict(zip(_stats_df.reset_index()[dfcol].values, _stats_df.values))\n    return [_d[t] if t in _d else np.zeros(len(stats)) for t in types]\nfeature_funcs.append(partial(event_count_stats_each, types=\"media_types\", dfcol=\"type\"))\nfeature_funcs.append(partial(event_count_stats_each, types=\"titles\", dfcol=\"title\"))\nfeature_funcs.append(partial(event_count_stats_each, types=\"event_ids\", dfcol=\"event_id\"))\nfeature_funcs.append(partial(event_count_stats_each, types=\"worlds\", dfcol=\"world\"))\nfeature_funcs.append(partial(event_count_stats_each, types=\"event_codes\", dfcol=\"event_code\"))\n\n@array_output\ndef overall_session_game_time_stats(df):\n    \"overall session game time stats until assessment begin\"\n    return df['game_time'].agg(stats)\nfeature_funcs.append(overall_session_game_time_stats)\n\n@array_output\ndef session_game_time_stats_each(df, types, dfcol):\n    \"session game time stats per media types until assessment begin, all zeros if missing for user\"\n    types = UNIQUE_COL_VALS.__dict__[types]\n    _stats_df = df.groupby(dfcol)['game_time'].agg(stats)\n    _d = dict(zip(_stats_df.reset_index()[dfcol].values, _stats_df.values))\n    return [_d[t] if t in _d else np.zeros(len(stats)) for t in types]\nfeature_funcs.append(partial(session_game_time_stats_each, types=\"media_types\", dfcol=\"type\"))\nfeature_funcs.append(partial(session_game_time_stats_each, types=\"titles\", dfcol=\"title\"))\nfeature_funcs.append(partial(session_game_time_stats_each, types=\"event_ids\", dfcol=\"event_id\"))\nfeature_funcs.append(partial(session_game_time_stats_each, types=\"worlds\", dfcol=\"world\"))\nfeature_funcs.append(partial(session_game_time_stats_each, types=\"event_codes\", dfcol=\"event_code\"))\n\nlen(feature_funcs)","61924784":"def get_test_assessment_start_idxs(df): \n    return list(df.sort_values(\"timestamp\")\n                  .query(\"type == 'Assessment' & event_code == 2000\")\n                  .groupby(\"installation_id\").tail(1).index)\n\ndef get_sorted_user_df(df, ins_id):\n    \"extract sorted data for a given installation id and add datetime features\"\n    _df = df[df.installation_id == ins_id].sort_values(\"timestamp\").reset_index(drop=True)\n    add_datepart(_df, \"timestamp\", time=True)\n    return _df\n\ndef get_test_feats_row(idx, i):\n    \"get all faeatures by an installation start idx\"\n    df = test_df\n    ins_id = df.loc[idx, \"installation_id\"]\n    _df = get_sorted_user_df(df, ins_id)\n    assessment_row = _df.iloc[-1]\n    row_feats = np.concatenate([f(_df) for f in feature_funcs])\n    feat_row = pd.Series(row_feats, index=[f\"static_feat{i}\"for i in range(len(row_feats))])\n    row = pd.concat([assessment_row, feat_row])\n    return row","5cb7d8fb":"# # testit with single assessment row\n# start_idxs = get_test_assessment_start_idxs(test_df)\n# get_test_feats_row(start_idxs[0], 0)","d83eaf71":"# Feature Engineering part 1\nstart_idxs = get_test_assessment_start_idxs(test_df)\nres = parallel(partial(get_test_feats_row), start_idxs)\ntest_with_features_df_part1 = pd.concat(res,1).T","bc07022a":"test_with_features_df_part1.shape","d1c4e3dd":"test_with_features_df_part1.head(2)","fb068b33":"def target_encoding_stats_dict(df, by, targetcol):\n    \"get target encoding stats dict, by:[stats]\"\n    _stats_df = df.groupby(by)[targetcol].agg(stats)   \n    _d = dict(zip(_stats_df.reset_index()[by].values, _stats_df.values))\n    return _d","489f8bd2":"def _value_counts(o, freq=False): return dict(pd.value_counts(o, normalize=freq))\ndef countfreqhist_dict(df, by, targetcol, types, freq=False):\n    \"count or freq histogram dict for categorical targets\"\n    types = UNIQUE_COL_VALS.__dict__[types]\n    _hist_df = df.groupby(by)[targetcol].agg(partial(_value_counts, freq=freq))\n    _d = dict(zip(_hist_df.index, _hist_df.values))\n    for k in _d: _d[k] = array([_d[k][t] for t in types]) \n    return _d","14c85740":"f1 = partial(target_encoding_stats_dict, by=\"title\", targetcol=\"num_incorrect\")\nf2 = partial(target_encoding_stats_dict, by=\"title\", targetcol=\"num_correct\")\nf3 = partial(target_encoding_stats_dict, by=\"title\", targetcol=\"accuracy\")\nf4 = partial(target_encoding_stats_dict, by=\"world\", targetcol=\"num_incorrect\")\nf5 = partial(target_encoding_stats_dict, by=\"world\", targetcol=\"num_correct\")\nf6 = partial(target_encoding_stats_dict, by=\"world\", targetcol=\"accuracy\")\n\nf7 = partial(countfreqhist_dict, by=\"title\", targetcol=\"accuracy_group\", types=\"accuracy_groups\",freq=False)\nf8 = partial(countfreqhist_dict, by=\"title\", targetcol=\"accuracy_group\", types=\"accuracy_groups\",freq=True)\nf9 = partial(countfreqhist_dict, by=\"world\", targetcol=\"accuracy_group\", types=\"accuracy_groups\",freq=False)\nf10 = partial(countfreqhist_dict, by=\"world\", targetcol=\"accuracy_group\", types=\"accuracy_groups\",freq=True)","ea3ff646":"# Feature Engineering part 2\n_idxs = test_with_features_df_part1.index\nfeat1 = np.stack(test_with_features_df_part1['title'].map(f1(train_with_features_part2)).values)\nfeat2 = np.stack(test_with_features_df_part1['title'].map(f2(train_with_features_part2)).values)\nfeat3 = np.stack(test_with_features_df_part1['title'].map(f3(train_with_features_part2)).values)\nfeat4 = np.stack(test_with_features_df_part1['world'].map(f4(train_with_features_part2)).values)\nfeat5 = np.stack(test_with_features_df_part1['world'].map(f5(train_with_features_part2)).values)\nfeat6 = np.stack(test_with_features_df_part1['world'].map(f6(train_with_features_part2)).values)\nfeat7 = np.stack(test_with_features_df_part1['title'].map(f7(train_with_features_part2)).values)\nfeat8 = np.stack(test_with_features_df_part1['title'].map(f8(train_with_features_part2)).values)\nfeat9 = np.stack(test_with_features_df_part1['world'].map(f9(train_with_features_part2)).values)\nfeat10 = np.stack(test_with_features_df_part1['world'].map(f10(train_with_features_part2)).values)\n\n# create dataframe with same index to merge later\n_test_feats = np.hstack([feat1, feat2, feat3, feat4, feat5, feat6, feat7, feat8, feat9, feat10])\n_test_feats_df = pd.DataFrame(_test_feats, index=_idxs)\n_test_feats_df.columns = [f\"targenc_feat{i}\"for i in range(_test_feats_df.shape[1])]","9cbe9061":"test_with_features_part2 = pd.concat([test_with_features_df_part1, _test_feats_df],1)","46239766":"test_with_features_part2.shape","3b61db71":"# check to see train and test have same features\nnum_test_feats = [c for c in test_with_features_part2.columns if c.startswith(\"static\")]\nnum_train_feats = [c for c in train_with_features_part2.columns if c.startswith(\"static\")]\nassert num_train_feats == num_test_feats\n# check to see train and test have same features\nnum_test_feats = [c for c in test_with_features_part2.columns if c.startswith(\"targenc\")]\nnum_train_feats = [c for c in train_with_features_part2.columns if c.startswith(\"targenc\")]\nassert num_train_feats == num_test_feats","9d31066d":"from fastai.tabular import *","e37b877f":"train_with_features_part2.shape, test_with_features_part2.shape","93e64caa":"# load CV installation_ids\ntrn_val_ids = pickle.load(open(\"..\/input\/dsbowl-feng-part2\/CV_installation_ids.pkl\", \"rb\")) #kaggle\n# trn_val_ids = pickle.load(open(\"output\/dsbowl-feng-part2\/CV_installation_ids.pkl\", \"rb\")) #local","bd3b9a17":"# pick trn-val installation ids\nfoldidx = 0\ntrn_ids, val_ids = trn_val_ids[foldidx]\nvalid_idx = (train_with_features_part2[train_with_features_part2.installation_id.isin(val_ids)].index)\nlen(valid_idx)","3e5b6d5b":"# label distribution for training fold to be used in metric\ntrain_labels_dist = (train_with_features_part2[train_with_features_part2.installation_id.isin(trn_ids)]['accuracy_group']\n    .value_counts(normalize=True))\ntrain_labels_dist_quantiles = np.cumsum([train_labels_dist[i] for i in range(3)])\ntrain_labels_dist_quantiles","980d548a":"# get data\ncat_names = ['title','world','timestampMonth','timestampWeek','timestampDay','timestampDayofweek',\n             'timestampDayofyear','timestampHour']\ncont_names = [c for c in train_with_features_part2.columns if c.startswith(\"static\")]\ncont_names += [c for c in train_with_features_part2.columns if c.startswith(\"targenc\")]\n\nprocs = [FillMissing, Categorify, Normalize]\ndata = TabularDataBunch.from_df(bs=256, path=\".\", df=train_with_features_part2, dep_var=\"accuracy\", \n                                valid_idx=valid_idx, procs=procs, cat_names=cat_names, cont_names=cont_names)\n\ndata.add_test(TabularList.from_df(test_with_features_part2, cat_names=cat_names, cont_names=cont_names));","08b40fcb":"data.batch_size","0bb99e01":"# metric\nfrom fastai.metrics import RegMetrics\nfrom sklearn.metrics import cohen_kappa_score\n\ndef convert_preds_with_search(preds, targs): \n    \"soft accuracy 0-1 preds to accuracy groups by optimized search thresholds\"\n    pass\n\ndef convert_preds(preds, q):\n    \"soft accuracy 0-1 preds to accuracy groups given quantiles 'q'\"\n    preds = preds.view(-1)\n    targ_thresh = np.quantile(preds, q)\n    hard_preds = torch.zeros_like(preds)\n    hard_preds[preds <= targ_thresh[0]] = 0\n    hard_preds[(preds > targ_thresh[0]) & (preds <= targ_thresh[1])] = 1\n    hard_preds[(preds > targ_thresh[1]) & (preds <= targ_thresh[2])] = 2\n    hard_preds[preds > targ_thresh[2]] = 3\n    return hard_preds\n\ndef convert_targs(targs):\n    \"convert accuracy to accuracy group for targs\"\n    targs = targs.view(-1)\n    targ_thresh = [0, 0.5, ]\n    hard_targs = torch.zeros_like(targs)\n    hard_targs[targs == 0] = 0\n    hard_targs[(targs > 0) & (targs < 0.5)] = 1\n    hard_targs[targs == 0.5] = 2\n    hard_targs[targs == 1] = 3\n    return hard_targs\n# assert not any(convert_targs(tensor(train_labels_df['accuracy'])) != tensor(train_labels_df['accuracy_group']))\n\nclass KappaScoreRegression(RegMetrics):\n    def __init__(self): pass\n    def on_epoch_end(self, last_metrics, **kwargs):\n        \"convert preds and calc qwk\"\n        preds = convert_preds(self.preds, q=train_labels_dist_quantiles)\n        targs = convert_targs(self.targs)\n        qwk = cohen_kappa_score(preds, targs, weights=\"quadratic\")\n        return add_metrics(last_metrics, qwk)","3836af93":"# learner\nlearner = tabular_learner(data, [256,256], y_range=(0.,1.), ps=0.5)","a05f7046":"# callbacks\nfrom fastai.callbacks import *\nearly_cb = EarlyStoppingCallback(learner, monitor=\"kappa_score_regression\", mode=\"max\", patience=5)\nsave_cb = SaveModelCallback(learner, monitor=\"kappa_score_regression\", mode=\"max\", name=f\"bestmodel_fold{foldidx}\")\ncbs = [early_cb, save_cb]","aa7aac00":"# random cohen kappa score\n_preds, _targs = learner.get_preds()\n_preds, _targs = convert_preds(_preds, q=train_labels_dist_quantiles), convert_targs(_targs)","7c630442":"learner.metrics = [KappaScoreRegression()]","3f649b33":"learner.fit_one_cycle(10, 1e-3, callbacks=cbs)","ae590509":"# get test preds\n_preds,_targs=learner.get_preds(DatasetType.Test)","2a377d9d":"# label distribution for training fold to be used in metric\ntrain_labels_dist = (train_with_features_part2['accuracy_group'].value_counts(normalize=True))\nq = np.cumsum([train_labels_dist[i] for i in range(3)])\n# get accuracy groups\npreds = to_np(convert_preds(_preds, q=q))","f7b83abb":"# get installation ids for test set\ntest_ids = test_with_features_part2['installation_id'].values; len(test_ids)","58efe277":"# generate installation_id : pred dict\ntest_preds_dict = dict(zip(test_ids, preds)); len(test_preds_dict)","fa0b1797":"# create submission\nsample_subdf['accuracy_group'] = sample_subdf.installation_id.map(test_preds_dict).astype(int)\nsample_subdf.to_csv(\"submission.csv\", index=False)","313e71cd":"sample_subdf.head()","8ec569bf":"### TabularLearner Model\n\nHere we use a single validation but in later stages once we finalize features we should use cross-validation. We don't over optimize the model or do any hyperparameter search since the whole purpose is to get a baseline and build on top of it in upcoming parts.","2f164cd5":"All unique values in test set are also present in training set","ac1ee64f":"### TabularLearner with part 2\n\n\n**To see how features are generated in more detail:** [Feature Engineering Part 2 Notebook](https:\/\/www.kaggle.com\/keremt\/fastai-feature-engineering-part2-46-features\/edit)\n\n**Additions:**\n\n- KappaScoreRegression metric\n- Predefined CV folds\n- Save best model\n- Convert test preds by train distribution","16ba5ccd":"### Submit","3613d172":"### Read Data","28544324":"### Test Features (part1)\n\nBasically here we redefine the feature generation code for test.","7e119192":"### end :)","c355c704":"### Test Feature Engineering\n\nTest set in LB and Private LB is different than what is publicly shared. So feature engineering and inference for test set should be done online.","051e6829":"### Test Features (part2)","9db6697f":"### Imports"}}