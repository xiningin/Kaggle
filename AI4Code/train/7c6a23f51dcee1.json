{"cell_type":{"1a5518a5":"code","f7fcab88":"code","ea835070":"code","0824dd8f":"code","06cc9a88":"code","fc8cb830":"code","5f15fad9":"code","0aeafe80":"code","94b699f6":"code","5122b2c4":"code","26f66a13":"code","73898f80":"code","b9dfb8e4":"code","f60652a3":"code","011aeb77":"code","794d99d9":"code","62dd793c":"code","1d85de1b":"code","93a31504":"code","b92e6ed5":"code","f60eb1d8":"code","578caf86":"code","f90bcf4c":"code","cf2cd0e4":"code","fadc4510":"code","ab2db9ac":"markdown","0d20b067":"markdown","9f420a60":"markdown","99085160":"markdown","aeeac9e9":"markdown","b473405a":"markdown","8c14cf85":"markdown","eb991aa6":"markdown","59d5c13d":"markdown","150bf45a":"markdown"},"source":{"1a5518a5":"# basic library\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# visulization library\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# deep learning library\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder","f7fcab88":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nsample_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","ea835070":"train_df","0824dd8f":"train_df.info()","06cc9a88":"test_df.info()","fc8cb830":"# Get rid of columns that are not useful\ntrain = train_df.drop(columns= ['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\ntest = test_df.drop(columns= ['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)","5f15fad9":"train.head()","0aeafe80":"sns.boxplot(x=\"Survived\", y=\"Age\", data=train_df)","94b699f6":"train['Age'] = train['Age'].fillna(train['Age'].mean())\ntest['Age'] = test['Age'].fillna(test['Age'].mean())","5122b2c4":"sns.countplot(x='Embarked', data=train)","26f66a13":"train['Embarked'] = train['Embarked'].fillna('C')","73898f80":"# store feature matrix in \"X\"\nX_train = train.iloc[:, 1:]   \n\n# store response vector in \"y\"\ny_train = train.iloc[:,0]    \n\nprint(X_train.shape)\nprint(y_train.shape)","b9dfb8e4":"X_train.head()","f60652a3":"y_train.head()","011aeb77":"## Preprocess the PClass column \ndef preprocess_pclass_cols(df):\n    #converting integer classes to Letters and prepare for One Hot Encoding\n    df['Pclass'] = df['Pclass'].map({1: 'AC', 2: 'BC', 3 : 'CC'})\n    return df","794d99d9":"X_train = preprocess_pclass_cols(X_train)\nX_test = preprocess_pclass_cols(test)","62dd793c":"X_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(test)","1d85de1b":"X_train.head()","93a31504":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","b92e6ed5":"X_train[0]","f60eb1d8":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Dense(12, input_shape=X_train.shape[1:], kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\n\n# 1st hidden layer\nmodel.add(keras.layers.Dense(200, kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.BatchNormalization())\n\n# 2nd hidden layer\nmodel.add(keras.layers.Dense(200, kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.BatchNormalization())\n\n# 3rd hidden layer\nmodel.add(keras.layers.Dense(200, kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.BatchNormalization())\n\n# 4th hidden layer\nmodel.add(keras.layers.Dense(200, kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.BatchNormalization())\n\n# 5th hidden layer\nmodel.add(keras.layers.Dense(200, kernel_initializer='he_normal'))\nmodel.add(keras.layers.Activation('elu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.BatchNormalization())\n\n# output layer\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))","578caf86":"model.summary()","f90bcf4c":"checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', verbose=1, monitor='accuracy',save_best_only=True, mode='auto') \nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=100, callbacks=[checkpoint], verbose=False)","cf2cd0e4":"y_pred = model.predict(X_test)\ntest_labels = sample_submission['Survived']\ny_pred = y_pred.round().astype(int)\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(sample_submission['Survived'], y_pred)\nprint(cm)\naccuracy_score(sample_submission['Survived'], y_pred)","fadc4510":"sample_submission['Survived'] = y_pred\nsample_submission.to_csv('submission.csv',index=False)","ab2db9ac":"## Data cleaning","0d20b067":"# Titanic - Machine Learning from Disaster\nhttps:\/\/www.kaggle.com\/c\/titanic\/overview","9f420a60":"## Preprocssing the data\n* Scalar Transformation","99085160":"## Splitting Features and Labels","aeeac9e9":"### Seperate the features and Labels","b473405a":"### Useless columns","8c14cf85":"## Check distribution of Age Box plot over Survived data","eb991aa6":"## One hot Encoding of Col: Sex, Embarked.\nCheck with One hot encoding on PClass also","59d5c13d":"## Model Creation","150bf45a":"Thanks to  https:\/\/www.kaggle.com\/jenilsavani\/ann-with-84-accuracy-titanic"}}