{"cell_type":{"e168e0a8":"code","9177af04":"code","52758255":"code","9150bfdc":"code","f1c9072b":"code","679b1aac":"code","18684d9f":"code","cb5f7eb1":"code","f0affeae":"code","2b3a4ff0":"code","9cedb1a4":"code","d44fc197":"code","97b9e7a0":"code","20dc7d73":"code","a34a935c":"code","d3361c9e":"code","518d8fe5":"code","9e7a5e2b":"code","9af05ac3":"code","a1524d1d":"code","5b49f2a7":"code","5b4303c1":"code","9b01d34a":"code","46f9d812":"code","3d742960":"code","aaf01768":"code","62b82c73":"code","46099028":"code","d76a7751":"code","da50f212":"code","68aba649":"code","17edff2b":"code","616c007f":"code","a974a985":"code","975e0df0":"code","6cc4f07d":"code","f60c1e81":"code","5259f90c":"code","47d546bc":"code","77540992":"code","5970d542":"code","0bce4a28":"markdown","8932763a":"markdown","ff4c008b":"markdown","c4a356d0":"markdown","7b9cf8cd":"markdown","7595ad54":"markdown","2424d588":"markdown","523eb63e":"markdown","a904f5e5":"markdown","bbc3caef":"markdown","cbb07655":"markdown"},"source":{"e168e0a8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\nimport plotly.express as px\n### so that u dont have warnings\nfrom warnings import filterwarnings\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nfilterwarnings('ignore')\n# Custom colors\nclass color:\n    S = '\\033[1m' + '\\033[93m'\n    E = '\\033[0m'\n    \nmy_colors = [\"#E7C84B\", \"#4EE4EA\", \"#4EA9EA\", \"#242179\", \"#AB51E9\", \"#E051E9\"]\nprint(color.S+\"Notebook Color Scheme:\"+color.E)\nsns.palplot(sns.color_palette(my_colors))\n\n# Set Style\nsns.set_style(\"white\")\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.spines.left'] = False\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['axes.spines.top'] = False\nplt.rcParams.update({'font.size': 17})","9177af04":"#### Read in the training data","52758255":"# Read in the training data\ntrain_df = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\n\n# Print some useful information\nprint(color.S+\"Train Data has:\"+color.E, \"{:,}\".format(train_df.shape[0]), \"observations.\", \"\\n\" +\n      color.S+\"Number of Missing Values:\"+color.E, train_df.isna().sum()[0], \"\\n\" +\n      \"\\n\" +\n      color.S+\"Head of Training Data:\"+color.E)\ntrain_df.head(5)","9150bfdc":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\n\n# Print some useful information\nprint(color.S+\"Test Data has:\"+color.E, \"{:,}\".format(test_df.shape[0]), \"observations.\", \"\\n\" +\n      color.S+\"Number of Missing Values:\"+color.E, test_df.isna().sum()[0], \"\\n\" +\n      \"\\n\" +\n      color.S+\"Head of Training Data:\"+color.E)\ntest_df.head(5).style.background_gradient(cmap = 'Reds')","f1c9072b":"train_df.head()","679b1aac":"train_df.tail()","18684d9f":"train_df.shape","cb5f7eb1":"train_df.info()","f0affeae":"train_df.dtypes","2b3a4ff0":"feature_na=[feature for feature in train_df.columns if train_df[feature].isnull().sum()>0]\nfeature_na","9cedb1a4":"#% of missing values\nfor feature in feature_na:\n    print('{} has {} % missing values'.format(feature,np.round(trian_df[feature].isnull().sum()\/len(train_df)*100,4)))","d44fc197":"train_df['loss'].unique()","97b9e7a0":"train_df.describe().style.background_gradient(cmap = 'Reds')","20dc7d73":"train_df.max()","a34a935c":"train_df.describe().T.style.bar(subset=['mean'], color='red')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","d3361c9e":"# Skewness of the distribution\n\nprint(train_df.skew())\n","518d8fe5":"data_corr = train_df.corr()\ndata_corr.style.background_gradient(cmap = 'copper')","9e7a5e2b":"sns.scatterplot(x='f1', y='f2', hue='loss', data=train_df)","9af05ac3":"sns.scatterplot(x=train_df['f1'], y=train_df['loss'])","a1524d1d":"sns.regplot(x=train_df['f1'], y=train_df['loss'])","5b49f2a7":"train_df.groupby('f1')['loss'].mean().nlargest(20).plot.bar()","5b4303c1":"sns.set_style(style='whitegrid')\nsns.distplot(train_df['loss'])","9b01d34a":"plt.figure(figsize=(10,7))\nchains=train_df['loss'].value_counts()[0:20]\nsns.barplot(x=chains,y=chains.index,palette='deep')\nplt.title(\"Most loss \")\nplt.xlabel(\"Number of outlets\") ","46f9d812":"x=train_df['f1'].value_counts()\nlabels=['accepted','not accepted']","3d742960":"fig = px.scatter_3d(train_df.iloc[:500], x='f0', y='f1', z='f2',\n                    color='loss')\nfig.show()","aaf01768":"plt.figure(figsize=(20,12))\ntrain_df['loss'].value_counts().nlargest(20).plot.bar(color='red')\nplt.gcf().autofmt_xdate()","62b82c73":"train_df['loss'].isna().sum()","46099028":"len(train_df['loss'].unique())","d76a7751":"trace1 = go.Bar( \n        x = train_df.groupby('f1')['f2'].max().nlargest(12).index,\n        y = train_df.groupby('f3')['f4'].max().nlargest(12),\n        name= 'loss')\niplot([trace1])","da50f212":"fig = px.box(train_df.head(500),x='f1',y='loss')\nfig.show()","68aba649":"sns.kdeplot(train_df[\"loss\"]);","17edff2b":"train_df.head()","616c007f":"X = train_df.iloc[:, [2, 3]].values\ny = train_df.iloc[:, 4].values","a974a985":"from sklearn.impute import SimpleImputer\nimputer=SimpleImputer(missing_values=np.nan,strategy='mean')\nimputer=imputer.fit(X[:,1:3])\nX[:,1:3]=imputer.transform(X[:,1:3])","975e0df0":"#Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nlabelencoder_X=LabelEncoder()\nX[:,0]=labelencoder_X.fit_transform(X[:,0])","6cc4f07d":"from sklearn.compose import ColumnTransformer\nct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],remainder='passthrough')\nX = ct.fit_transform(X)","f60c1e81":"labelencoder_y=LabelEncoder()\ny=labelencoder_y.fit_transform(y)","5259f90c":"y","47d546bc":"#Spliting dataset into training set and testing test\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n","77540992":"# Fitting K-NN to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)","5970d542":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n","0bce4a28":"### Work with Train Data","8932763a":"### Data Interaction\n\u2022Correlation\n*  Correlation tells relation between two attributes.\n*  Correlation requires continous data. Hence, ignore categorical data\n* Calculates pearson co-efficient for all combinations\n","ff4c008b":"### Goal for This notebook:\n1. Feature Engineernig \n2. Clean Data\n3. Feature Extraction\n4. Visualise Data\n","c4a356d0":"### calculate avg f1 and loss","7b9cf8cd":"#### How many types ofLosses we have?","7595ad54":"### Load data and liberary\n* Here we load basic liberary ","2424d588":"### Read in the Test data","523eb63e":"### Showing Basics Statistics\nNow that you\u2019ve seen what data types are in your dataset, it\u2019s time to get an overview of the values each column contains. You can do this with .describe():\n","a904f5e5":" #### getting all NAN features","bbc3caef":"*  This data haven't any decimal value all value float","cbb07655":"##### Loss distribution"}}