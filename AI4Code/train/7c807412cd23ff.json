{"cell_type":{"1dd813c8":"code","69b04192":"code","bd858636":"code","77162e17":"code","8d1ffe86":"code","04e82440":"code","9a2fd01b":"code","2ab375a1":"code","d8e2ac47":"code","f813498a":"code","70b7ec78":"code","3a382fa6":"code","beddfb94":"code","f1757cda":"code","b631f092":"code","0ee4dd59":"code","98c2d7bf":"code","fbeefd46":"code","78b056c8":"code","81d228ba":"code","e1cbe464":"code","3b416bc9":"code","b7ff053f":"code","6ee7d4b4":"code","65a7949b":"code","62325e3f":"code","7a073c7d":"markdown","3c99e4f9":"markdown","f74c64c4":"markdown","15b30b31":"markdown","fd778259":"markdown","54343f57":"markdown","25bbec0a":"markdown","b205a8d9":"markdown"},"source":{"1dd813c8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))","69b04192":"def load_train_data():\n    return pd.read_csv('..\/input\/quickdraw_train.csv', index_col='id')\n\ndef load_test_data():\n    return pd.read_csv('..\/input\/quickdraw_test_x.csv', index_col='id')","bd858636":"df_train = load_train_data()\nprint(df_train.shape)\nprint(df_train.head(5))","77162e17":"df_test = load_test_data()\n\ndf_test \/= 255\n\nprint(df_test.shape)\nprint(df_test.head(5))","8d1ffe86":"df_train['category'].unique()","04e82440":"df_train['subcategory'].unique()","9a2fd01b":"df_train['subcategory'].value_counts().head()","2ab375a1":"def show_sample(df):\n    fig = plt.figure(figsize=(16, 16)) \n    unique_samples = df.sample(df.shape[0]).drop_duplicates('subcategory').sort_values(['category','subcategory']).reset_index(drop=True)\n    images_per_row = 6\n    rows = int(np.ceil(unique_samples.shape[0] \/ images_per_row))\n    for i, row in unique_samples.iterrows():\n        plt.subplot(rows, images_per_row, i+1)\n        im = row[:-2].astype(float).values \n        plt.title(f\"{row[-1]} ({row[-2]})\")\n        plt.imshow(im.reshape([28,28]), cmap='gray', vmin=0, vmax=255, )\n        frame1 = plt.gca()\n        frame1.axes.get_xaxis().set_visible(False)\n        frame1.axes.get_yaxis().set_visible(False)\n        \ndef show_drawing(data):\n    \"\"\"\n    Show a drawing from either a dataframe or a numpy array\n    \"\"\"\n    if type(data) == type(pd.Series()):\n        im = data[[f\"pix{x}\" for x in range(28*28)]].values.reshape((28,28)).astype(float)\n        title = ''\n        if 'subcategory' in data.index:\n            title = f\"{data['subcategory']} ({data['category']})\"\n    elif type(data) == type(np.zeros(1)): \n        im = data.reshape((28,28)).astype(float)\n        title = ''\n    else:\n        print('ERROR: data not suitable: dataframe or numpy array supported')\n        return\n\n    plt.imshow(im, cmap='gray', vmin=0, vmax=255)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(title)\n    plt.show()\n    ","d8e2ac47":"show_sample(df_train)","f813498a":"show_drawing(df_test.iloc[0])","70b7ec78":"df_train.head()","3a382fa6":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, BatchNormalization, MaxPooling2D\nfrom keras.optimizers import RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nbatch_size = 128\nnum_classes = 42\nepochs = 25\ntest_size = 0.2","beddfb94":"df_x = df_train.drop(['category', 'subcategory'], axis=1)\ndf_y = df_train[['subcategory']]\n\n# the data, split between train and test sets\nx_train, x_test, y_train, y_test = train_test_split(df_x.values, df_y.values, test_size = test_size, random_state = 42)\n\n# floats!\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n#don't forget to normalize your data!\nx_train \/= 255\nx_test \/= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('x_train shape:', x_train.shape)\nprint('x_test shape: ', x_test.shape)\n\n# convert class vectors to binary class matrices\nle = LabelEncoder()\ny_train = le.fit_transform(y_train.flatten())\ny_test  = le.transform(y_test.flatten())\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape: ', y_test.shape)","f1757cda":"# Set seed\nnp.random.seed(42)\n\n# Reshape data to fit model\nx_train = x_train.reshape(x_train.shape[0],28,28,1)\nx_test = x_test.reshape(x_test.shape[0],28,28,1)\n\n# Define model\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation='relu', input_shape=(28,28,1)))\n#model.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='exponential'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='softsign'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(42, activation = 'softmax'))","b631f092":"model.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","0ee4dd59":"test = model.predict(df_test.values.reshape(21000,28,28,1))\nle.inverse_transform(np.argmax(test, axis=1))","98c2d7bf":"# FOR CNN\npredictions = model.predict(df_test.values.reshape(21000,28,28,1))\npredictions = le.inverse_transform(np.argmax(predictions, axis=1))\npredictions","fbeefd46":"df_submission = df_test.copy()\ndf_submission['subcategory'] = predictions\ndf_submission = df_submission[['subcategory']]\n\ndf_submission.head()","78b056c8":"from collections import Counter\n\nlabels, values = zip(*Counter(df_submission['subcategory']).items())\n\nindexes = np.arange(len(labels))\nwidth = 1\n\nplt.figure(figsize=(40,5))\nplt.bar(indexes, values, width)\nplt.xticks(indexes + width * 0.5, labels)\nplt.show()","81d228ba":"def make_submission_file(df, filename='submission.csv'):\n    assert 'subcategory' in df.columns, 'subcategory columns is missing'\n    assert df.shape[0] == 21000, 'you should have 21000 rows in your submission file'\n    df.to_csv(filename)","e1cbe464":"make_submission_file(df_submission, 'FAA_mlp_kernel_rip_off_submission_13.csv')","3b416bc9":"predictions = model.predict(x_train)\nle.inverse_transform(np.argmax(predictions, axis=1))","b7ff053f":"predictions = le.inverse_transform(np.argmax(model.predict(x_train), axis=1))\n\nlabels, values = zip(*Counter(predictions).items())\n\nindexes = np.arange(len(labels))\nwidth = 1\n\nplt.figure(figsize=(40,5))\nplt.bar(indexes, values, width)\nplt.xticks(indexes + width * 0.5, labels)\nplt.show()","6ee7d4b4":"predictions = le.inverse_transform(np.argmax(y_train, axis=1))\n\nlabels, values = zip(*Counter(predictions).items())\n\nindexes = np.arange(len(labels))\nwidth = 1\n\nplt.figure(figsize=(40,5))\nplt.bar(indexes, values, width)\nplt.xticks(indexes + width * 0.5, labels)\nplt.show()","65a7949b":"predictions = le.inverse_transform(np.argmax(model.predict(x_test), axis=1))\n\nlabels, values = zip(*Counter(predictions).items())\n\nindexes = np.arange(len(labels))\nwidth = 1\n\nplt.figure(figsize=(40,5))\nplt.bar(indexes, values, width)\nplt.xticks(indexes + width * 0.5, labels)\nplt.show()","62325e3f":"predictions = le.inverse_transform(np.argmax(y_test, axis=1))\n\nlabels, values = zip(*Counter(predictions).items())\n\nindexes = np.arange(len(labels))\nwidth = 1\n\nplt.figure(figsize=(40,5))\nplt.bar(indexes, values, width)\nplt.xticks(indexes + width * 0.5, labels)\nplt.show()","7a073c7d":"### Now predict on the test set\n1. Create a prediction\n2. Save the prediction as submission file using the `create_submissiong()` method.\n3. Upload on kaggle\n4. Check your score and win!","3c99e4f9":"There are 42 different classes for the images, these are the labels that we aim to predict. In the training set there are 1000 images per class. The test set contains 500 images per class, 50% will be used for the public leaderboard, 50% will be used for the final score in the private leaderboard. Be aware that your score can thus change after the submission deadline.","f74c64c4":"### Load data","15b30b31":"### Specify the model architecture\nIt contains two dense (feed-forward) neural network layers of each 512 hidden nodes, followed by a relu activation.","fd778259":"## Example code for benchmark submission\n## Simple Keras MLP from MNIST example \n(https:\/\/github.com\/keras-team\/keras\/blob\/master\/examples\/mnist_mlp.py)","54343f57":"### Preprocessing data","25bbec0a":"#### Insight into data\nAs you can see, there are 2 categories. These categories are not used as labels not are they in the test set. Is there a way to use them? Who knows, feel free to find out for yourself!","b205a8d9":"### to show that the images in the test set are similar"}}