{"cell_type":{"f1fc8714":"code","f281f501":"code","2891acb6":"code","912dc775":"code","a1d5d6d4":"code","5a1d15d1":"code","402b7ddc":"code","ac7e64c4":"code","f9ff4c66":"code","049cb7ad":"code","da22d5c9":"markdown","4610557d":"markdown","10a29cc7":"markdown","a5d0c269":"markdown","c5b3e892":"markdown"},"source":{"f1fc8714":"import numpy as np\nimport pandas as pd\n#tensorflow version 2.0\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n#reading data\nmnist_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nmnist_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","f281f501":"mnist_train.shape,mnist_test.shape","2891acb6":"#standardization\nmnist_train.iloc[:,1:] \/= 255\n\n#splitting features and target column\nx_train = mnist_train.iloc[:,1:]\ny_train = mnist_train.iloc[:,0]\nx_test= mnist_test\/255\n\n#further splitting train set into validation and training set\nx_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.3,random_state = 12345)","912dc775":"plt.figure(figsize=(10, 10))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(np.array(x_test.iloc[i]).reshape(28,28))\nplt.show()","a1d5d6d4":"sns.countplot(y_train)\nplt.title('Classes distribution in train set');","5a1d15d1":"sns.countplot(y_validate)\nplt.title('Classes distribution in validation set');","402b7ddc":"image_rows = 28\nimage_cols = 28\nimage_shape = (image_rows,image_cols,1)\nx_train = tf.reshape(x_train,[x_train.shape[0],*image_shape])\nx_test = tf.reshape(x_test,[x_test.shape[0],*image_shape])\nx_validate = tf.reshape(x_validate,[x_validate.shape[0],*image_shape])","ac7e64c4":"cnn_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    tf.keras.layers.MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    tf.keras.layers.MaxPooling2D(pool_size=2) ,\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Flatten(), # flatten out the layers\n    tf.keras.layers.Dense(200,activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(200,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(25,activation = 'softmax')\n])\n\ncnn_model.compile(loss ='sparse_categorical_crossentropy',\n                  optimizer='adam',metrics =['accuracy'])\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n\nhistory = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=500,\n    epochs=60,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n    callbacks=early_stop\n)","f9ff4c66":"plt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Training - Accuracy');","049cb7ad":"# Making submissions\nsubmissions = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmissions['Label'] = cnn_model.predict_classes(x_test)\nsubmissions.to_csv('submission.csv',index=False)","da22d5c9":"# Convolutional Neural Network\n\nThe term deep neural nets refers to any neural network with several hidden layers. Convolutional neural nets are a specific type of deep neural net which are especially useful for image recognition. Specifically, convolutional neural nets use convolutional and pooling layers, which reflect the translation-invariant nature of most images.\n\nFor this, we need to reshape our input data.","4610557d":"Let's have a look at the images in our dataset.","10a29cc7":"Let's see if our data is balanced.","a5d0c269":"***Please upvote and provide suggestions.***","c5b3e892":"Now we define our model. The layer in model network (keras.layers.Flatten) transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). This layer unstacks rows of pixels in the image and lining them up and has no parameters to learn; it only reformats the data. Pooling layers are then added to further reduce the number of parameters.\n\nAfter the pixels are flattened, the network consists of a sequence of two keras.layers.Dense layers. These are densely connected, or fully connected, neural layers.\n\nA problem with training neural networks is in the choice of the number of training epochs to use. Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset."}}