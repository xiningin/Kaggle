{"cell_type":{"6d180732":"code","2608fbbc":"code","c78fa2f1":"code","1c5c1adb":"code","40e8426f":"code","edd89f38":"code","459b91c8":"code","125922ee":"code","da89d260":"code","94be2187":"code","6f9d61eb":"code","7562b99a":"code","5baf307a":"code","dedcbbba":"code","7c31a69f":"code","ac876045":"code","19af8615":"code","198525f6":"code","35c121b7":"code","ac378d93":"code","a49b7e9d":"code","c3f196f2":"code","0f2dc1c5":"code","ce57869a":"code","9327da64":"code","ff7e339f":"code","adc0930b":"markdown","9933c611":"markdown","dc4ee058":"markdown","cfab72cd":"markdown","9029636c":"markdown","ab85ece5":"markdown","2e81b4c5":"markdown","a1775337":"markdown","0cec78a1":"markdown","06f726c5":"markdown"},"source":{"6d180732":"import pandas as pd\n\ndf_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","2608fbbc":"print(df_train.describe())\nprint(df_train.info())\nprint(df_train.sample(10))\nprint(df_train.isna().sum())","c78fa2f1":"df_train = df_train.drop('Cabin', axis = 1)\ndf_train = df_train.dropna(axis=0, subset=['Embarked'])\nprint(df_train.isna().sum())","1c5c1adb":"import numpy as np\ndf_train['Age'] = df_train['Age'].fillna(np.mean(df_train['Age'], axis = 0))\nprint(df_train.isna().sum())\nprint(df_train['Age'].describe())","40e8426f":"print(df_train.corr(method = 'pearson')['Survived'].sort_values(ascending = False))","edd89f38":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.pairplot(df_train, hue = 'Survived')\nplt.show()","459b91c8":"print(df_train.columns)\nprint(df_train.dtypes)","125922ee":"df_train_num = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\ndf_train_object = ['Name', 'Sex', 'Ticket',  'Embarked' ]","da89d260":"for feature in df_train_num:\n    sns.boxplot(data = df_train, y = feature)\n    plt.show()","94be2187":"ls = []\nfor feature in df_train_num:\n    Q1 = df_train[feature].quantile(0.05)\n    Q3 = df_train[feature].quantile(0.95)\n    IQR = Q3-Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    ls.extend(df_train.index[(df_train[feature] < lower_bound) | (df_train[feature] > upper_bound)])\n    \nprint(ls)","6f9d61eb":"df_train = df_train.drop(ls, axis = 0)\nprint(df_train.shape)","7562b99a":"df_num = df_train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\ndf_object = df_train[['Sex', 'Embarked' ]]\n\ndf_object = pd.get_dummies(df_object, drop_first = True)\n","5baf307a":"df_final = pd.concat([df_num,df_object], axis = 1)\n","dedcbbba":"df_train = df_final\ndf_train.shape\ndf_train.reset_index(drop = True)","7c31a69f":"X = df_train.drop('Survived', axis = 1)\ny = df_train['Survived']","ac876045":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)","19af8615":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()","198525f6":"from sklearn.model_selection import GridSearchCV\n\nmax_depth = [2,3,4,5,6]\nn_estimators = range(100,200,5)\ncriterion = [\"gini\", \"entropy\"]\nn_jobs = [-1]\nbootstrap = [True, False]\n\nparams = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"criterion\": criterion, \"n_jobs\": n_jobs, \"bootstrap\":bootstrap}\ngrid = GridSearchCV(rf, params, cv=5)\n\ngrid.fit(X_train, y_train)\nprint(\"best parameters: \" + str(grid.best_params_))","35c121b7":"y_pred = grid.predict(X_test)","ac378d93":"from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, mean_squared_error as MSE\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy: \" + str(accuracy))\n\nprecision = precision_score(y_test, y_pred)\nprint(\"precision: \" + str(precision))\n\nrecall = recall_score(y_test, y_pred)\nprint(\"recall: \" + str(recall))\n\nmatrix = confusion_matrix(y_test, y_pred)\nprint(\"confusion matrix: \" + str(matrix))\n\nmse = MSE(y_test, y_pred)\nRMSE = mse**(1\/2)\nprint(\"RMSE: \" + str(RMSE))\nprint(\"std y_test: \" + str(np.std(y_test)))","a49b7e9d":"df_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\ndf_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis = 1)\n\ndf_passengerID = df_test['PassengerId']\n\ndf_nume = df_test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n\ndf_obj = df_test[['Sex','Embarked']]\ndf_obj = pd.get_dummies(df_obj, drop_first = True)\n\ndf_test = pd.concat([df_nume,df_obj], axis = 1)\ndf_test.head()","c3f196f2":"df_test[\"Age\"] = df_test[\"Age\"].fillna(np.mean(df_test[\"Age\"]), axis = 0)\ndf_test[\"Fare\"] = df_test[\"Fare\"].fillna(np.mean(df_test[\"Fare\"]), axis = 0)\ndf_test.isna().sum()","0f2dc1c5":"Prediction = grid.predict(df_test)\nprint(Prediction)","ce57869a":"Prediction = pd.DataFrame(Prediction)\nPrediction.columns = ['Survived']\nPrediction.head()","9327da64":"Submission = pd.concat([df_passengerID, Prediction], axis = 1)\nSubmission.reset_index(drop=True)\nSubmission","ff7e339f":"Submission.to_csv('Submission.csv', index = False)","adc0930b":"# Predicting on the testing set","9933c611":"# Train Test Split","dc4ee058":"Here is my very first project with python. I used random forest to predict who survived and determined the best parameters with gridsearchcv.\nI detailled my workflow hoping for feedback on what and how i could improve!","cfab72cd":"# Introduction","9029636c":"# Exploring the data","ab85ece5":"# Formating the testing set","2e81b4c5":"# Preprocessing","a1775337":"# Evaluating the fit of the model","0cec78a1":"# Preparing submission file","06f726c5":"# Building Model"}}