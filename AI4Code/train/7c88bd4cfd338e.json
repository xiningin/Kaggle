{"cell_type":{"93a2fe9b":"code","a9182103":"code","6aef5107":"code","380aefa2":"code","a3d7040a":"code","07e48010":"code","09669f57":"code","6ca6e960":"code","ec671b52":"code","d49264c9":"code","dbe87aa2":"code","ecfacd55":"code","93a7b9c5":"code","140cbb17":"code","14c035e8":"code","3f7dbbb9":"code","eebfbcf3":"code","c2b994a0":"markdown","7d44cede":"markdown","1d170015":"markdown","bbb3b7b4":"markdown","88f80058":"markdown","6d31577b":"markdown","8fabf7db":"markdown","7ab3926a":"markdown","47fa8d94":"markdown","8f8f61c8":"markdown","06eaa6b3":"markdown","5cebd10f":"markdown","04938e07":"markdown","1fb5e0c5":"markdown","6922adec":"markdown","f9331af7":"markdown"},"source":{"93a2fe9b":"import numpy as np\nimport os\nimport cv2\nimport zipfile\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping\nimport random\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom tqdm import tqdm","a9182103":"for dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6aef5107":"with zipfile.ZipFile('..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip') as z:\n    z.extractall(\".\")\n\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip') as z:\n    z.extractall(\".\")\n\nprint(os.listdir('.'))","380aefa2":"DATADIR = '.\/train'\ntraining_data = []\nRESIZE = 100\nX = []\ny = []\n\ndef create_training_data():\n    for img in os.listdir(DATADIR):\n        try:\n            img_array = cv2.imread(os.path.join(DATADIR,img), cv2.IMREAD_GRAYSCALE)            \n            img2 = cv2.resize(img_array, (RESIZE,RESIZE))\n            img2 = (img2 - img2.mean())\/img2.std()\n            if img[:3] == 'dog':\n                class_num = 0\n            else:\n                class_num = 1\n            X.append(img2)\n            y.append(class_num)\n        except Exception as e:\n            pass\n        \ncreate_training_data()","a3d7040a":"X = np.array(X).reshape(-1, RESIZE, RESIZE, 1)\ny = np.asarray(y)","07e48010":"(X_train, X_val, y_train, y_val) = train_test_split(X, y, test_size=0.3, random_state=42)","09669f57":"aug_train = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")\n\ngenerator_val = ImageDataGenerator()","6ca6e960":"aug_train.fit(X_train)\n\ngenerator_val.fit(X_val)","ec671b52":"model = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","d49264c9":"earlystop = EarlyStopping(patience=5)\n\nhistory = model.fit(aug_train.flow(X_train, y_train, batch_size=32), validation_data=generator_val.flow(X_val, y_val, batch_size=32), epochs=100, callbacks=[earlystop])","dbe87aa2":"arr = model.predict(X_val.astype(float))\npredicted_label = np.argmax(arr, axis=1)\nprint(\"Model accuracy on validation set: {:.4f}\".format(accuracy_score(y_val, predicted_label)))","ecfacd55":"cm  = confusion_matrix(y_val, predicted_label)\nplot_confusion_matrix(cm,figsize=(6,6), cmap=plt.cm.Blues, colorbar=True)\nplt.xticks(range(2), ['Dogs', 'Cats'], fontsize=16)\nplt.yticks(range(2), ['Dogs', 'Cats'], fontsize=16)\nplt.show()","93a7b9c5":"TESTDIR = '.\/test'\nLABELS = [\"DOG\", \"CAT\"]\ntest_data = []\nRESIZE = 100\nX_test = []\nX_id = []\n\ndef create_test_data():\n    for img in os.listdir(TESTDIR):\n        try:\n            img_array = cv2.imread(os.path.join(TESTDIR,img), cv2.IMREAD_GRAYSCALE)            \n            img2 = cv2.resize(img_array, (RESIZE,RESIZE))\n            X_test.append(img2)\n            img_num = img.split('.')[0]\n            X_id.append(np.array(img_num))\n            \n        except Exception as e:\n            pass\n        \ncreate_test_data()\nX_test = np.array(X_test).reshape(-1, RESIZE, RESIZE, 1)\n\n\narr_test = model.predict(X_test.astype(float))\n","140cbb17":"submission = pd.DataFrame({'id':X_id,'label':arr_test[:,0]})","14c035e8":"submission.head()","3f7dbbb9":"filename = 'Prediction1.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","eebfbcf3":"test_predicted_label = np.argmax(arr_test, axis=1)\nfig=plt.figure(figsize=(20,20))\n\nfor counter, img in enumerate(X_test[:40]):\n    ax = fig.add_subplot(10,4,counter+1)\n    ax.imshow(X_test[counter,:,:,0], cmap='gray')\n    plt.title(LABELS[test_predicted_label[counter]])\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    \nplt.tight_layout()\nplt.show()","c2b994a0":"## Let's now generate a submission file according to the instructions","7d44cede":"# Now, we have two folders containing each train and test images\n# The next step is to load the training data\n## Both features (images) and labels (dog or cat) are loaded into a python list","1d170015":"# So we need to extract the images in the zip files","bbb3b7b4":"## Evaluate model accuracy on the validation dataset","88f80058":"## We build now a CNN. Let's try with a simple one consisnting in 5 Conv layer, one dense layer and one ouput layer","6d31577b":"## The ImageDataGenerator.fit method is used for feature normalization","8fabf7db":"# Let's have a look of where the data is","7ab3926a":"## First, we create generators for augmentation of training data and for normalization of validation data","47fa8d94":"# A try to the dogs vs cats dataset using a simple CNN\nThis has been one of my first ML projects.\n\nI got inspired by [sentdesk](https:\/\/pythonprogramming.net\/convolutional-neural-network-deep-learning-python-tensorflow-keras\/), [Adrian Rosebrock](https:\/\/www.pyimagesearch.com\/2018\/12\/24\/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial\/) and [Uysim Ty](https:\/\/www.kaggle.com\/uysimty\/keras-cnn-dog-or-cat-classification). Thanks!\n\nAny feedback would be great :)","8f8f61c8":"# Import necessary packages","06eaa6b3":"# Now, it is time to build and train a simple CNN model","5cebd10f":"## I'm too late for the competition, but let's see how the model works for some examples of the test data s","04938e07":"## Let's have a look at the correlation matrix","1fb5e0c5":"## Ok, let's now train the model","6922adec":"## The python list containing the loaded data is converted into two numpy arrays, one for features and one for labels","f9331af7":"## Now, we divide the training data into two sets, one for training and one for validation"}}