{"cell_type":{"c36f6e68":"code","808be11f":"code","a52421da":"code","b2595f57":"code","ef470b9f":"code","d27b70cc":"code","e2e19219":"code","9a19e0d0":"code","2ae65d53":"code","0bbc03de":"code","b1f5595a":"code","2e570536":"code","76957cd2":"code","5566dff0":"code","a63d57bc":"code","78d82189":"code","cb036014":"code","a8760db0":"code","408ef489":"code","d38263d8":"code","7898b15d":"code","96237add":"code","54683131":"code","84404300":"code","bd69c6e3":"code","38ea44f4":"code","2956ca5f":"code","05f310b8":"code","c7124080":"code","cca4d04b":"code","e4ee8784":"code","a0a402a8":"code","074acf8c":"code","ecd30947":"code","5913ab4f":"code","6729f236":"code","dec46209":"code","44bb1475":"code","67d337b2":"code","2811f73e":"markdown","1356c5b5":"markdown","b71a2a50":"markdown","cb51a053":"markdown","482d81c8":"markdown"},"source":{"c36f6e68":"#!pip3 install librosa","808be11f":"import IPython.display as ipd\nimport numpy as np\nimport pandas as pd\nimport librosa\nfrom librosa import display\nimport matplotlib.pyplot as plt\nimport os\nfrom scipy.io import wavfile as wav","a52421da":"def make_data_frame_from_txt(file_name):\n    file = pd.read_csv('\/kaggle\/input\/dataset\/'+ file_name,header=None)\n    df_names = pd.DataFrame(file)\n    df_names = df_names.rename(columns={0: 'file_path'})\n    df_names['file_path'] = df_names['file_path'].astype(str)\n    #df_names['features'] = \"\"\n    #df_names['features'] = df_names['features'].astype('object') \n    df_names[['command','file_name']] = df_names['file_path'].str.split(\"\/\",expand=True)\n    df_names[['speaker_id']] = df_names.file_name.str.split(\"_\",expand=True)[0]\n    return df_names","b2595f57":"df_testing_names = make_data_frame_from_txt('testing_list.txt')\ndf_validation_names = make_data_frame_from_txt('validation_list.txt')\ndf_train_names = make_data_frame_from_txt('train_list.txt')","ef470b9f":"#This is for testing the code on a small amount of the dataset \n#this is only to test that the format is correct, as we get a nonequal destribution of labels\n#df_testing_names = df_testing_names[:100]\n#df_validation_names = df_validation_names[:100]\n#df_train_names = df_train_names[:100]","d27b70cc":"print(df_train_names.head)\n#print(df_train_names.features.info)","e2e19219":"#See how many different speaker we have and how many of each\n#np.set_printoptions(threshold=100)\nprint(\"\\n validation \\n\")\nprint(df_validation_names['speaker_id'].value_counts(normalize=True))\nprint(df_validation_names['command'].value_counts(normalize=True))\n\nprint(\"\\n testing \\n\")\nprint(df_testing_names['speaker_id'].value_counts(normalize=True))\nprint(df_testing_names['command'].value_counts(normalize=True))\n\nprint(\"\\ntrain\\n\")\nprint(df_train_names['speaker_id'].value_counts(normalize=True))\nprint(df_train_names['command'].value_counts(normalize=True))","9a19e0d0":"#For the shape of the extracted fetatures\nn_mfcc = 40","2ae65d53":"fn = '\/kaggle\/input\/voicecommands\/sheila\/004ae714_nohash_0.wav'\nlibrosa_audio, librosa_sample_rate = librosa.load(fn)\nscipy_sample_rate, scipy_audio = wav.read(fn)\nprint(\"Original sample rate: {}\".format(scipy_sample_rate))\nprint(\"Librosa sample rate: {}\".format(librosa_sample_rate))\n\nprint('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio),np.max(scipy_audio)))\nprint('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))\n\nplt.figure(figsize=(12, 4))\nplt.plot(scipy_audio)\nplt.savefig('original_audio.png')\n\n# Librosa: mono track\nplt.figure(figsize=(12,4))\nplt.plot(librosa_audio)\nplt.savefig('librosa_audio.png')\n\nmfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc = n_mfcc)\n\nprint(mfccs.shape)\n\nplt.figure(figsize=(8,8))\nlibrosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\nplt.savefig('MFCCs.png')\n\nfrom tensorflow.python.client import device_lib\n\nprint(device_lib.list_local_devices())","0bbc03de":"def extract_features(file_name):\n    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n    mfccs_processed = np.mean(mfccs.T,axis=0)\n    return mfccs_processed","b1f5595a":"# Applying the function to the train data by accessing each row of the dataframe\n#features_testing = df_testing_names.apply(extract_features, axis=1)\n#features_validation = df_validation_names.apply(extract_features, axis=1)\n#features_train = df_train_names.apply(extract_features, axis=1)\n","2e570536":"def attach_features_to_dataframe(df):\n    features = []\n    path = '\/kaggle\/input\/voicecommands\/'\n    for index, row in df.iterrows():\n        file_path = row['file_path']\n        file_name = os.path.join(os.path.abspath(path), file_path)\n        features.append(extract_features(file_name))\n        #df.at[index,'features'] = features\n    return features","76957cd2":"#df_testing_names \n#df_validation_names\n#df_train_names","5566dff0":"test_features = attach_features_to_dataframe(df_testing_names)\ndf_testing_names['features'] = test_features","a63d57bc":"#df_testing_names.head","78d82189":"validation_features = attach_features_to_dataframe(df_validation_names)\ndf_validation_names['features'] = validation_features","cb036014":"train_features = attach_features_to_dataframe(df_train_names)\ndf_train_names['features'] = train_features","a8760db0":"#print(train_features)\n","408ef489":"#print(np.array(df_testing_names.features), df_testing_names.command,df_testing_names.speaker_id)","d38263d8":"#import csv\n#with open('test_features_df.csv', 'w', newline='', encoding='utf-8') as f:\n    #writer = csv.writer(f)\n  #  for row in range(len(df_testing_names)):\n #       print(df_testing_names.iloc[row])\n#        f.write(str(df_testing_names.iloc[row]))\n  #  writer = (df_testing_names)\ndf_testing_names.to_csv('test_features_df.csv')","7898b15d":"df_validation_names.to_csv('validation_features_df.csv')","96237add":"df_train_names.to_csv('train_features_df.csv')","54683131":"#df_train_names.head","84404300":"\n#Copy the path and read_csv, for example:\n#df_testing_names = pd.read_csv(\"..\/input\/smallscvsettest1\/test_features_df(1).csv\")\n#df_train_names = pd.read_csv(\"..\/input\/smallscvsettest1\/train_features_df(1).csv\")\n#df_validation_names = pd.read_csv(\"..\/input\/smallscvsettest1\/validation_features_df(1).csv\")","bd69c6e3":"from sklearn.preprocessing import LabelEncoder , StandardScaler\nfrom keras.utils import to_categorical\n# Convert features and corresponding classification labels into numpy arrays\nX_train = np.array(df_train_names.features.tolist())\ny_train = np.array(df_train_names.speaker_id)#.tolist())\nz_train = np.array(df_train_names.file_name)#.tolist())\n# Convert features and corresponding classification labels into numpy arrays\nX_val = np.array(df_validation_names.features.tolist())\ny_val = np.array(df_validation_names.speaker_id)#.tolist())\nz_val = np.array(df_validation_names.file_name)#.tolist())\n# Convert features and corresponding classification labels into numpy arrays\nX_test = np.array(df_testing_names.features.tolist())\ny_test = np.array(df_testing_names.speaker_id)#.tolist())\nz_test = np.array(df_testing_names.file_name)#.tolist())\n","38ea44f4":"length_y_train = y_train.shape[0]\nlength_y_val = y_val.shape[0]\nlength_y_test = y_test.shape[0]\nprint(length_y_train)","2956ca5f":"# Encode the classification labels\nle = LabelEncoder()\ny_combined = np.concatenate((y_train,y_val,y_test))\n#print(y_combined)\ny_combined_encoded = to_categorical(le.fit_transform(y_combined))\nnum_labels = y_combined_encoded.shape[1]\n","05f310b8":"#print(y_train)\n#print(y_test)","c7124080":"#array[start:\u200bstop:step];\ny_train_encoded = y_combined_encoded[:length_y_train]\ny_val_encoded = y_combined_encoded[length_y_train:length_y_val+length_y_train]\ny_test_encoded = y_combined_encoded[length_y_val+length_y_train:]","cca4d04b":"print((y_train_encoded.shape))","e4ee8784":"print(y_test_encoded)","a0a402a8":"#Scale x values to be around 0\nss = StandardScaler()\nX_train_encoded = ss.fit_transform(X_train)\nX_val_encoded = ss.transform(X_val)\nX_test_encoded = ss.transform(X_test)","074acf8c":"from sklearn import metrics \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split \n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical","ecd30947":"#Number of labels indiacating the classes that we want to classify\n#With a softmax activation layer, consider \n\ndef build_model_graph(input_shape=(n_mfcc,)):\n    model = Sequential()\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    #y shape is 1\n    model.add(Dense(num_labels))\n    model.add(Activation('softmax'))\n    # Compile the model\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')    \n    return model\nmodel = build_model_graph()","5913ab4f":"#print(X_train)\n#print(y_train)\n#print(X_val)\n#print(y_val)","6729f236":"print(X_train_encoded.shape)\nprint(y_train_encoded.shape)\nprint(X_val_encoded.shape)\nprint(y_val_encoded.shape)","dec46209":"from keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \nimport tensorflow as tf\n\nnum_epochs = 1000\nnum_batch_size = 256 #256\n\n#log_dir = \"logs\/fit\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\nmy_callbacks = [\n    #patience is how long the it will keep training after it has gotten a worse accuracy, if no better result has been found in the meantime\n    #EarlyStoppingAtMinLoss(patience=200),\n    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n    #CustomLearningRateScheduler(lr_schedule)\n  #  tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1),\n]\n#Set verbose to 1 if information about the tranining procedure is desired\nhistory = model.fit(X_train_encoded, y_train_encoded, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_val_encoded, y_val_encoded), verbose=1)#,callbacks=my_callbacks)\n\n","44bb1475":"print(history.history.keys())","67d337b2":"# Check out our train accuracy and validation accuracy over epochs.\ntrain_accuracy = history.history['accuracy']\ntrain_loss = history.history['loss']\n\nval_accuracy = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\n\n\n# create figure and axis objects with subplots()\nfig,ax = plt.subplots(figsize=(30,15))\n\n\n# Generate line plot of training, testing loss over epochs.\nax.set_xlabel('Epoch', fontsize = 18,rotation=0)\nax.set_ylabel('Categorical Crossentropy', fontsize = 18)\nax.plot(train_accuracy, label='Training Accuracy', color='#185fad')\nax.plot(val_accuracy, label='Validation Accuracy', color='orange')\nax.legend(fontsize = 18,loc=10)\n\n# Set title\n\nplt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n\nticks=[]\nfor i in range(0,11):\n    var = num_epochs\/10\n    ticks.append(var*i)\n\n\n# twin object for two different y-axis on the sample plot\nax2=ax.twinx()\n# make a plot with different y-axis using second axis object\nax2.plot(train_loss, label='Training Loss', color='purple')\nax2.plot(train_accuracy, label='Validation Loss', color='red')\nax2.set_ylabel('Loss',fontsize=18)\n\n\n\"\"\"\n'best' \t0\n'upper right' \t1\n'upper left' \t2\n'lower left' \t3\n'lower right' \t4\n'right' \t5\n'center left' \t6\n'center right' \t7\n'lower center' \t8\n'upper center' \t9\n'center' \t10\n\"\"\"\n\nax2.legend(fontsize = 18,loc=5)\nplt.xticks(ticks=ticks,labels=ticks,rotation=0)\n\n\n# Tweak spacing to prevent clipping of tick-labels\nplt.subplots_adjust(bottom=0.15)\nplt.grid()\nplt.show()\nplt.savefig('training_loss_graph.png');\n\n","2811f73e":"# Test audio file","1356c5b5":"# Load csv files","b71a2a50":"Storing data frame set in csv files","cb51a053":"# Building model and training","482d81c8":"# Extracting features and writing to csv files"}}