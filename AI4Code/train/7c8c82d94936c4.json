{"cell_type":{"8bb226b1":"code","5c1fa547":"code","544412fb":"code","401c4605":"markdown","506fe1d5":"markdown","f5e87353":"markdown","6c7eb3c5":"markdown","d1524f30":"markdown","be4f1eac":"markdown","c5bcf8e2":"markdown","5d1d6318":"markdown","0b3c8535":"markdown"},"source":{"8bb226b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport pandas as pd\n# Any results you write to the current directory are saved as output.","5c1fa547":"resnet_7_lw = pd.read_csv(\"..\/input\/ensemble\/resnet_c8.csv\") # wrong file name\nresnet_10 = pd.read_csv(\"..\/input\/ensemble\/resnet_c10.csv\") \nresnet_15 = pd.read_csv(\"..\/input\/ensemble\/resnet_c15.csv\")\nresnet_20 = pd.read_csv(\"..\/input\/ensemble\/resnet_c20.csv\") \n\nvgg_3 = pd.read_csv(\"..\/input\/ensemble\/vgg_c3.csv\")\nvgg_5 = pd.read_csv(\"..\/input\/ensemble\/vgg_c5.csv\")\nvgg_6 = pd.read_csv(\"..\/input\/ensemble\/vgg_c6.csv\")\n\n# ensemble only on above probabilities results in a 0.99435 private score\n\n# these last two are actually another ensembles - I do not recall on which commits were they done\nresnet_19 = pd.read_csv(\"..\/input\/ensemble\/resnet_c19.csv\")\nresnet_16_lw = pd.read_csv(\"..\/input\/ensemble\/lw_1.csv\")\n\n# these last two files improves the score to 0.99464","544412fb":"new_cols = [\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"]\nparams=[resnet_7_lw,resnet_10,resnet_15,resnet_20,vgg_3,vgg_5,vgg_6,resnet_16_lw,resnet_19]\ndef mean(nr=None,*args):\n    if not nr:\n        nr = len(args)\n    s = args[0][new_cols]\n    for i in range(1,len(args)):\n        s+=args[i][new_cols]\n    return s\/nr\n\nnew_classes = mean(len(params),*params)\narr = new_classes.values\n\nsubmission = pd.read_csv(os.path.join(\"..\/input\/cursive-hiragana-classification\",\"sample_submission.csv\"))\nsubmission['Class'] = np.argmax(arr, axis=1)\nsubmission.to_csv(os.path.join(\".\",\"submission.csv\"), index=False)  ","401c4605":"# [VGG kernel](https:\/\/www.kaggle.com\/bogdanluncasu\/vgg-kernel)","506fe1d5":"{kernel}_{commit_id}_{need_to_load_weights}","f5e87353":"# [Resnet kernel](https:\/\/www.kaggle.com\/bogdanluncasu\/resnet )","6c7eb3c5":"# Train a generative model","d1524f30":"* **Kernel** - is either Resnet kernel or VGG kernel(can be found above)\n* **Commit_id** - is the commit number in which the probabilities were extracted\n* **need_to_load_weights** - due some errors some of the models did not save the probabilities files - they need to be created by loading the model and do inference on test dataset","be4f1eac":"The notebook for training a generative model for each class can be found at the following [link](https:\/\/www.kaggle.com\/bogdanluncasu\/gan-kernel?scriptVersionId=12060924)","c5bcf8e2":"The csv files used on ensemble can be obtain as follow:","5d1d6318":"# Ensembling on output probabilities","0b3c8535":"In order to load weights the [load-weights](https:\/\/www.kaggle.com\/bogdanluncasu\/load-weights-kernel) kernel has been used"}}