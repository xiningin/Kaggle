{"cell_type":{"ce7f60b5":"code","d1389401":"code","6815d943":"code","62bd408c":"code","da6fac37":"code","8d2ac331":"code","ca395452":"code","a638551a":"code","e432a49d":"code","4e25547d":"code","0d569973":"code","4df2358f":"code","17046745":"code","3bac07b1":"code","f31b1e01":"code","7dd936c7":"code","363a86b8":"code","6ec3a4e5":"code","535ab06a":"code","380c2d16":"code","4b9b0821":"markdown","39018743":"markdown","85499152":"markdown","f93974c7":"markdown","65874241":"markdown","b3ed7448":"markdown","2ac63a5f":"markdown","f116e5de":"markdown","530a70dc":"markdown","234a63ff":"markdown","ad5e70ac":"markdown","b9d9d070":"markdown","63fced31":"markdown"},"source":{"ce7f60b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         pass\n# #         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1389401":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6815d943":"train_path=('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train')\ntest_path=('..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test')","62bd408c":"from matplotlib.image import imread\nplt.imshow(imread('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/Z\/Z1.jpg'))","da6fac37":"# dim1=[]\n# dim2=[]\n\n# for i in os.listdir(train_path):\n#     for j in os.listdir(\"\/\".join([train_path,i])):\n#         img=imread(\"\/\".join([train_path,i,j]))\n#         d1,d2,color=img.shape\n#         dim1.append(d1)\n#         dim2.append(d2)\n        \n# sns.jointplot(x=dim1,y=dim2)","8d2ac331":"image_dat='..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/Z\/Z1.jpg'\nimsh=imread(image_dat).shape\nimsh1=imsh\nimsh","ca395452":"plt.imshow(imread(image_dat))","a638551a":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_gen=ImageDataGenerator(rescale=1.\/255,validation_split=0.20)\nimg_gen","e432a49d":"imsh1=(64,64,3)","4e25547d":"batch_size=32\ntrain_imgen=img_gen.flow_from_directory(train_path,\n                                        target_size=imsh1[:2],\n                                        color_mode='rgb',\n                                        batch_size=batch_size,\n                                        class_mode='categorical',\n                                        subset='training',\n                                        shuffle=True\n                                       )\n","0d569973":"validation_generator = img_gen.flow_from_directory(\n    train_path, \n    target_size=imsh1[:2],\n    color_mode='rgb',\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=True\n    )","4df2358f":"train_imgen.class_indices","17046745":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,AveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow import keras\n# e=EarlyStopping(patience=5)","3bac07b1":"model=Sequential()\n\nmodel.add(Conv2D(filters=16,kernel_size=4,input_shape=imsh1,activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n          \nmodel.add(Conv2D(filters=32,kernel_size=4,activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\nmodel.add(Conv2D(filters=64,kernel_size=4,activation='relu'))\nmodel.add(MaxPool2D(pool_size=2))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(512,activation='relu'))\n# model.add(Dropout(0.5))\nmodel.add(Dense(29,activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","f31b1e01":"# model=my_model\nmodel.summary()","7dd936c7":"results=model.fit(x=train_imgen,\n                  epochs=10,\n                  verbose=2,\n                  validation_data=validation_generator)\n# ,\n#                   callbacks=[e])","363a86b8":"d1=pd.DataFrame(results.history)\nd1.plot()","6ec3a4e5":"model.save('model.h5')","535ab06a":"from tensorflow.keras.preprocessing import image\nimg=[]\npr_img=[]\nfor i in os.listdir(test_path):\n    myi=image.load_img(\"\/\".join([test_path,i]),target_size=imsh1)\n    img.append(myi)\n#     plt.imshow(myi)\n\nfor i in img:\n    myi1=np.expand_dims(i,axis=0)\n    pr_img.append(myi1)\n    ","380c2d16":"pred=[]\nd={}\ns=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ@#\"\nfor i,j in train_imgen.class_indices.items():\n    d[j]=i\n\n# print(d)    \n\nfor i in pr_img:\n    a=np.argmax(model.predict(i), axis=-1)\n    pred.append(d[a[0]])\n\n# print(pred)\n\nfor i in range(len(pred)):\n    print(pred[i],\"  <----  \",s[i])","4b9b0821":"# Dim checking","39018743":"# Prepare data","85499152":"# Path checking","f93974c7":"# Model eval analysis","65874241":"# Model fitting","b3ed7448":"# Image check","2ac63a5f":"# Test analysis","f116e5de":"# Val set flow","530a70dc":"# Train set flow","234a63ff":"# Image checking","ad5e70ac":"# Model save","b9d9d070":"# Package Import","63fced31":"# Indices check"}}