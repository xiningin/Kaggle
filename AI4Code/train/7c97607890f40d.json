{"cell_type":{"4af39766":"code","abcdf68a":"code","173d51b6":"code","4e6186fb":"code","c5c91315":"code","d066ebc7":"code","e61fd7cc":"code","6b940084":"code","0115b019":"code","af5ae8ec":"code","020845ec":"code","bdc9277d":"code","dd62cdb3":"code","d4dbdd0d":"code","ce40ccd3":"code","46b539bf":"code","07faa313":"code","4e36cdf9":"code","0c180d2d":"code","94c18895":"code","c468ca59":"code","34982f6f":"code","2b1f3b92":"code","6d9223a6":"code","8f9d3e77":"code","28c7fd28":"code","af2e54f7":"code","b361870d":"code","60800a30":"code","953445eb":"code","aba54ca3":"code","f4c00512":"code","76158e57":"code","77457142":"code","50f50a12":"code","7ed15382":"code","a28787b5":"code","d7d972f7":"code","133ea6bd":"code","499b5bc7":"code","8c27d12d":"code","6113338f":"code","f284a1d9":"code","70adc35a":"code","9ae8adf3":"code","8c20a318":"code","676e51ae":"code","b8517f51":"code","4d5b8483":"code","0d771c6c":"code","0b49cdcd":"code","5012ad9a":"code","ee93e202":"code","fadedb37":"code","8e6e4f92":"code","5bc6483e":"code","439b55b2":"markdown","f94b9ec2":"markdown","276ec092":"markdown","cc6bf71e":"markdown","13013493":"markdown","a5693a21":"markdown","0ff01470":"markdown","b6557f69":"markdown","81fb591f":"markdown","fe36194e":"markdown"},"source":{"4af39766":"import numpy as np\nimport pandas as pd\nimport time\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nlistdir(\"..\/input\")\n\nfrom sklearn.linear_model import LogisticRegression","abcdf68a":"### Reading the data\nkaggle=1\nif kaggle==1:\n    train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\n    test=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n    sample=pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nelse:\n    train=pd.read_csv(\"train.csv\")\n    test=pd.read_csv(\"test.csv\")\n    sample=pd.read_csv(\"sample_submission.csv\")","173d51b6":"###Glimpse of the data:\ntrain.head()","4e6186fb":"test.head()","c5c91315":"print(f'Shape of train:{train.shape}\\nShape of test:{test.shape}')","d066ebc7":"## Check the label :\ntrain.label.value_counts().sort_index()","e61fd7cc":" !pip install pretrainedmodels","6b940084":"import pretrainedmodels","0115b019":"## import libraries for our training:\nimport torch\nimport torchvision\nfrom torchvision import transforms,datasets,models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.utils import make_grid\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom PIL import Image\n","af5ae8ec":"train_ds,valid_ds=train_test_split(train,random_state=42,test_size=0.2,stratify=train['label'])\nlen(train_ds),len(valid_ds)","020845ec":"## Credits https:\/\/www.kaggle.com\/juiyangchang\/cnn-with-pytorch-0-995-accuracy\n## Credits https:\/\/www.kaggle.com\/artyomp\/resnet50-baseline\nn_pixels=len(test.columns)\nNUM_CLASSES=10\nnormalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\n\ntrain_trans = transforms.Compose([transforms.ToPILImage(),transforms.Grayscale(num_output_channels=3),transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),transforms.RandomRotation(0.3),\n                               transforms.ToTensor(),\n                               normalize])\n\n#valid_trans = transforms.Compose([transforms.ToPILImage(),transforms.Grayscale(num_output_channels=3),\n                               #transforms.ToTensor(),\n                               #normalize])\n\n\nclass data_load():\n    \n    def __init__(self,file,transform=None):\n        \n        df = file\n        \n        if len(df.columns) == n_pixels:\n            # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])\n","bdc9277d":"batch_size=64\n\ntrain_ds=data_load(train_ds,transform=train_trans)\nvalid_ds=data_load(valid_ds,transform=train_trans)\ntest_ds=data_load(test,transform=train_trans)\n\n","dd62cdb3":"# train_loader=torch.utils.data.DataLoader(train_ds,batch_size=batch_size,shuffle=True)\n# valid_loader=torch.utils.data.DataLoader(valid_ds,batch_size=batch_size,shuffle=True)\n# test_loader=torch.utils.data.DataLoader(test_ds,batch_size=batch_size,shuffle=True)","d4dbdd0d":"# def imshow(axis, inp):\n#     \"\"\"Denormalize and show\"\"\"\n#     inp = inp.numpy().transpose((1, 2, 0))\n#     mean = np.array([0.485, 0.456, 0.406])\n#     std = np.array([0.229, 0.224, 0.225])\n#     inp = std * inp + mean\n#     inp = np.clip(inp, 0, 1)\n#     axis.imshow(inp)","ce40ccd3":"# img, label = next(iter(train_loader))\n# print(img.size(), label.size())\n# fig = plt.figure(1, figsize=(16,4))\n# grid = ImageGrid(fig, 111, nrows_ncols=(8,8), axes_pad=0.05)    \n# for i in range(img.size()[0]):\n#     ax = grid[i]\n#     imshow(ax, img[i])\n","46b539bf":"# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# print(device)\n# print(\"Using device\",torch.cuda.get_device_name(0))","07faa313":"# !ls ..\/input\/pretrained-pytorch-models\/","4e36cdf9":"# cache_dir = expanduser(join('~', '.torch'))\n# if not exists(cache_dir):\n#     makedirs(cache_dir)\n# models_dir = join(cache_dir, 'models')\n# if not exists(models_dir):\n#     makedirs(models_dir)","0c180d2d":"# !cp ..\/input\/pretrained-pytorch-models\/* ~\/.torch\/models\/","94c18895":"# !ls ~\/.torch\/models","c468ca59":"# resnet=models.resnet50(pretrained=True)","34982f6f":"# print(resnet)","2b1f3b92":"# use_gpu = torch.cuda.is_available()\n# inputs, labels = next(iter(train_loader))\n# if use_gpu:\n#     resnet = resnet.cuda()\n#     inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n# else:\n#     inputs, labels = Variable(inputs), Variable(labels)\n# outputs = resnet(inputs)\n# outputs.size()","6d9223a6":"# We see that the model is working file and it is by default output 1000 classes whereas MNIST has 10 classes . Lets modify the final fc layer to output 10 classes.","8f9d3e77":"# print(resnet.fc)","28c7fd28":"# print(resnet.fc.in_features,resnet.fc.out_features)","af2e54f7":"# final_in_features = resnet.fc.in_features\n# resnet.fc=nn.Linear(final_in_features,10,bias=True)\n\n","b361870d":"# criterion = torch.nn.CrossEntropyLoss()\n# optimizer=torch.optim.Adam(resnet.fc.parameters(),lr=3e-4,betas=(0.9, 0.99), weight_decay=0.0002)\n# #optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.001, momentum=0.9)\n# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n\n# dloaders = {'train':train_loader, 'valid':valid_loader}","60800a30":"# start_time = time.time()\n# model = train_model(dloaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=1)\n# print('Training time: {:10f} minutes'.format((time.time()-start_time)\/60))","953445eb":"# #From  https:\/\/www.kaggle.com\/artgor\/pytorch-whale-identifier\n# #https:\/\/stackoverflow.com\/questions\/53975717\/pytorch-connection-between-loss-backward-and-optimizer-step\n# n_epochs = 5\n# for epoch in range(1, n_epochs+1):\n#     print(time.ctime(), 'Epoch:', epoch)\n\n#     train_loss = []\n    \n\n#     for batch_i, (data, target) in enumerate(train_loader):\n#         # print(f'Batch {batch_i} of 50')\n#         data, target = data.cuda(), target.cuda()\n#         resnet=resnet.cuda()\n#         optimizer.zero_grad()\n#         output = resnet(data)\n#         loss = criterion(output, target)\n#         train_loss.append(loss.item())\n\n#         loss.backward()\n#         optimizer.step()\n#     exp_lr_scheduler.step()\n\n#     print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')","aba54ca3":"# resnet=models.resnet50(pretrained=True)","f4c00512":"# class MNISTnet(nn.Module):\n#     def __init__(self):\n#         super(MNISTnet,self).__init__()\n        \n#         self.cnn_model =nn.Sequential(\n#             nn.Conv2d(3,32,kernel_size=5,stride=1,padding=2),  # (N,3,28,28) --> (N,32,28,28)\n#             nn.ReLU(),\n#             nn.BatchNorm2d(32),\n#             nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1), # (N,32,28,28) --> (N,64,28,28)\n#             nn.MaxPool2d(kernel_size=2,stride=2), # (N,64,28,28) --> (N,64,14,14)\n#             nn.Dropout(0.5),\n#             nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1), # (N,64,14,14) --> (N,128,14,14)\n#             nn.BatchNorm2d(128),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2,stride=2), # (N,128,14,14) --> (N,128,7,7)\n#             nn.Dropout(0.5)\n#         )\n        \n#         self.fc=nn.Sequential(\n#         nn.Linear(6272,512),\n#         nn.ReLU(),\n#         nn.Dropout(0.5),\n#         nn.Linear(512,10))\n        \n#     def forward(self,x):\n#         #print(\"Original feature size:\",x.shape)\n#         x=self.cnn_model(x)\n#         #print(\"After CNN model feature size\",x.shape)\n#         x=x.view(x.size(0),-1)\n#         #print(\"After flattening layer feature size\",x.shape)\n#         x=self.fc(x)\n#         #print(x.shape)\n        \n#         return x\n        ","76158e57":"# model=MNISTnet().cuda()\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer=torch.optim.Adam(model.parameters(),lr=3e-4)\n# #exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n\n# if torch.cuda.is_available():\n#     model = model.cuda()\n#     criterion = criterion.cuda()\n\n# # dloaders = {'train':train_loader, 'valid':valid_loader}","77457142":"#print(model)","50f50a12":"def evaluation(dataloader):\n    total, correct = 0, 0\n    for data in dataloader:\n        inputs, labels = data\n        inputs, labels = inputs.cuda(), labels.cuda()\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100 * correct \/ total","7ed15382":"# %%time\n# loss_arr = []\n# loss_epoch_arr = []\n# max_epochs = 10\n\n# for epoch in range(max_epochs):\n\n#     for i, (inputs,labels) in enumerate(train_loader,0):\n\n#         #inputs, labels = data\n#         inputs, labels = inputs.cuda(), labels.cuda()\n       \n#         outputs = model(inputs)\n#         loss = criterion(outputs, labels)\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n        \n#         loss_arr.append(loss.item())\n        \n#     loss_epoch_arr.append(loss.item())\n        \n#     print('Epoch: %d\/%d, Train acc: %0.2f, Valid acc: %0.2f' % (epoch, max_epochs, evaluation(train_loader), evaluation(valid_loader)))\n    \n    \n# plt.plot(loss_epoch_arr)\n# plt.show()","a28787b5":"#torch.save(model.state_dict(),'model.ckpt')","d7d972f7":"# sample.head()\n# #print(sample.shape)","133ea6bd":"##https:\/\/www.kaggle.com\/tunguz\/kannada-mnist-logistic-regression-baseline\n\nX=train[train.columns[1:]].values\nY=train.label.values\n\nlr = LogisticRegression(C=15, solver='lbfgs', multi_class='multinomial')\nlr.fit(X, Y)","499b5bc7":"# def prediction(data_loader):\n#     model.eval()\n#     test_pred = torch.LongTensor()\n    \n#     for i, data in enumerate(data_loader):\n#         data = Variable(data, volatile=True)\n#         if torch.cuda.is_available():\n#             data = data.cuda()\n            \n#         output = model(data)\n        \n#         pred = output.cpu().data.max(1, keepdim=True)[1]\n#         test_pred = torch.cat((test_pred, pred), dim=0)\n        \n#     return test_pred","8c27d12d":"preds=lr.predict(test.values)","6113338f":"# test_pred=prediction(test_loader)","f284a1d9":"# sample = pd.DataFrame(np.c_[np.arange(1, len(test_ds)+1)[:,None], test_pred.numpy()], \n#                       columns=['ImageId', 'Label'],index=None)","70adc35a":"sample['Label']=preds\n","9ae8adf3":"sample.to_csv(\"sample_submission.csv\",index=False)","8c20a318":"sample.head()","676e51ae":"#Credits - https:\/\/www.kaggle.com\/ambarish\/icassava-2019-cadene-models-2\/notebook\n# Thank you Bukun","b8517f51":"def se_resnext50_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n    return model","4d5b8483":"# model = se_resnext50_32x4d(pretrained=True)","0d771c6c":"#print(model)","0b49cdcd":"# for param in model.parameters():\n#     param.requires_grad = False\n\n# # new final layer with 10 classes\n# model.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n# num_ftrs = model.last_linear.in_features\n# model.last_linear = torch.nn.Linear(num_ftrs, 10)\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer=torch.optim.Adam(model.parameters(),lr=3e-4)\n# if device:\n#     model = model.cuda()\n#     criterion=criterion.cuda()","5012ad9a":"# %%time\n# loss_arr = []\n# loss_epoch_arr = []\n# max_epochs = 20\n\n# for epoch in range(max_epochs):\n\n#     for i, (inputs,labels) in enumerate(train_loader,0):\n\n#         #inputs, labels = data\n#         inputs, labels = inputs.cuda(), labels.cuda()\n       \n#         outputs = model(inputs)\n#         loss = criterion(outputs, labels)\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n        \n#         loss_arr.append(loss.item())\n        \n#     loss_epoch_arr.append(loss.item())\n        \n#     print('Epoch: %d\/%d, Train acc: %0.2f, Valid acc: %0.2f' % (epoch, max_epochs, evaluation(train_loader), evaluation(valid_loader)))\n    \n    \n# plt.plot(loss_epoch_arr)\n# plt.show()","ee93e202":"# torch.save(model.state_dict(),'se_resnext.ckpt')","fadedb37":"# test_pred=prediction(test_loader)","8e6e4f92":"# sample_1 = pd.DataFrame(np.c_[np.arange(1, len(test_ds)+1)[:,None], test_pred.numpy()], \n#                       columns=['ImageId', 'Label'],index=None)\n# sample_1.to_csv(\"se_resnet_sample_submission.csv\",index=False)","5bc6483e":"# sample_1.head()","439b55b2":"This model scores 0.0971 in the public leaderboard .Going by the train,valid accuracy , the model has terribly overfit.Lets check the pretrained se_resnet50_32x4d model for this dataset.","f94b9ec2":"This is my first kernel in computer vision and as a hello world example , I have taken the MNIST dataset for training a CNN model for digit recognizer . I have used Pytorch framework for developing the model and this kernel is a work in progress trying to lay my hands on various pretrained models and checking the accuracy.Also , I have tried to build my own nn model .I may not be right on implementing all the approaches and criticism is always welcome.","276ec092":"The below code is taken from - https:\/\/www.kaggle.com\/pvlima\/use-pretrained-pytorch-models","cc6bf71e":"All the digits seem to be equally represented except for 5 which is ~3800 .","13013493":"Lets try with our own neural network.","a5693a21":"Lets use the pretrained resnet architecture for building the ConvNet and check the accuracy.","0ff01470":"# MNIST Digit Recognizer ","b6557f69":"### Loading the libraries","81fb591f":"From the description of the dataset , it is understood that the train dataset has 785 columns and each image is of dimension 28 x 28 . The label column represents the label provided by users and this is the column which we are supposed to predict.","fe36194e":"## Building the convolution layer:\n"}}