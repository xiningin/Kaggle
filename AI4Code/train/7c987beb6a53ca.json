{"cell_type":{"349938bb":"code","0404bc94":"markdown","db9a5ed3":"markdown"},"source":{"349938bb":"import warnings\nimport keras as K\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.datasets import cifar10\nfrom keras.applications import inception_v3\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.neural_network import MLPClassifier\n\nwarnings.simplefilter(\"ignore\")\n\n(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n\n\ndef preprocess_data(X, y):\n    X = inception_v3.preprocess_input(X)\n    y = np_utils.to_categorical(y, 10)\n    return X, y\n\n\nx_train, y_train = preprocess_data(X_train, Y_train)\nx_test, y_test = preprocess_data(X_test, Y_test)\n\n\ninput_tensor = K.Input(shape=(32, 32, 3))\ninput_tensor_resize = K.layers.Lambda(\n    lambda image: K.backend.resize_images(\n        image, (int(100 \/ 32)), (int(100 \/ 32)),\n        \"channels_last\"))(input_tensor)\n\ny = K.layers.ZeroPadding2D(padding=4)(input_tensor_resize)\n\npre_trained_model = tf.keras.applications.InceptionV3(\n    include_top=False,\n    weights=None,\n    input_tensor=y)\n\n\nx = K.layers.Flatten()(pre_trained_model.output)\nx = K.layers.Dense(10, activation='softmax')(x)\n\n\nmodel = K.models.Model(pre_trained_model.input, x)\n\nopt = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmodel.fit(x_train, y_train,\n          validation_data=(x_test, y_test),\n          batch_size=128,\n          epochs=200,\n          verbose=1)\n\n\nscore = model.evaluate(x_test,\n                       y_test,\n                       verbose=0)\n\nprint(score)\n\ninputs = [model.input]\n_finalconv_dense = K.backend.function(inputs, [pre_trained_model.output])\n\n\nC1 = _finalconv_dense(x_train[0:1])\nC1 = np.squeeze(C1)\ntrain = np.zeros((x_train.shape[0], C1.shape[0]+1))\ntest = np.zeros((x_test.shape[0], C1.shape[0]+1))\n\ny_train = [np.argmax(y, axis=None, out=None) for y in y_train]\ny_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n\ntrain[:, -1] = y_train\nfor i in range(x_train.shape[0]):\n    x = x_train[i:i+1]\n    train[i, :-1] = np.squeeze(_finalconv_dense(x))\n\ntest[:, -1] = y_test\nfor i in range(x_test.shape[0]):\n    x = x_test[i:i+1]\n    test[i, :-1] = np.squeeze(_finalconv_dense(x))\n\nnp.savetxt('_Training_dense.csv',\n           train, delimiter=\",\", fmt='%g')\nnp.savetxt('_Test_dense.csv',\n           test, delimiter=\",\", fmt='%g')","0404bc94":"# About this Script\n\n## Author: Seyedsaman Emami\n\nIn the following notebook, I considered the CIFAR10  type dataset which is a Image processing problem.\n\nThe `Inception v3` from the Keras library is used to train.\n\nReference\n\n* [Rethinking the Inception Architecture for Computer Vision (CVPR 2016)](https:\/\/arxiv.org\/abs\/1512.00567)\n\n<h4>hyperparameters<\/h4>\nThe hyperparameters setting are as follows;\n\n```Python\n{include_top=False, weights=None, input_tensor= K.layers.ZeroPadding2D(padding=4)(input_tensor_resize)}\n```\n\nThe weights here are equal to None and that means I am training the pre_trained model from the scratch for the CIFAR10.\nYou may want to check the similar code [here](https:\/\/www.kaggle.com\/samanemami\/pre-trained-inception-v3-with-keras) with the ImageNet as its weight, which means the pre_trained model trained on over one million images.\n\n<hr>\n\n<h4>The reason for using this model;<\/h4>\n\nIt would be a good idea to use a pre-trained model to improve the accuracy of this specific dataset.\nFor instance, in this work([convolutional -NN | CIFAR10 {79% acc - 138 sec}](https:\/\/www.kaggle.com\/samanemami\/convolutional-nn-cifar10-79-acc-138-sec)), you can see that the accuracy of the CNN is not good enough to continue with that model.\n\nMoreover, you can see that I used the Keras function to extract the output of the trained model to use as an input of the different algorithms.\n\n\n<hr>\n\n<h5>I tried to keep everything as simple as possible, if you have any doubts or questions, please feel free to ask in the comments.<\/h5>\n\n<hr>\n<hr>","db9a5ed3":"### Author: [Seyedsaman Emami](https:\/\/github.com\/samanemami)\n\nIf you want to have this method or use the outputs of the notebook, you can fork the Notebook as following (copy and Edit Kernel).\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">\n\n<hr>\n\n## You can find some of my developments [here](https:\/\/github.com\/samanemami?tab=repositories).\n\n<hr>"}}