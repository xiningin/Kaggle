{"cell_type":{"afa5bf1d":"code","384b932b":"code","f94ba143":"code","61f77e31":"code","9f251422":"code","758c42e6":"code","ad1dde58":"code","7a53fd0a":"code","9d6a86da":"code","aa4af1af":"code","2b1d4a9a":"code","62e1ef8d":"code","87922ce9":"code","118bb33e":"code","3bc42251":"code","d8bf7a28":"code","8f64b999":"code","b183d479":"code","6b39067a":"code","4123c4d5":"code","2fec0716":"code","962082e5":"code","dd4b6dc0":"code","cb5b7af8":"code","46b70f7d":"code","35d07622":"code","25e256a3":"code","836398a6":"code","7e9ae30a":"code","3b95aebd":"code","f46aaa79":"code","55fd530f":"code","b4464c59":"code","0a99033e":"code","3f428940":"code","866d3471":"code","a132b9c0":"code","ea70e456":"code","d037afc2":"code","443505b6":"code","4d69001e":"code","05ed23df":"code","593b7592":"code","3d9aaedb":"code","87cd6dcc":"markdown","2f3bf55d":"markdown","6978127d":"markdown","b876d27f":"markdown","c9621fae":"markdown","5632a4ef":"markdown","09f63570":"markdown","6cf6f06b":"markdown","99e8fb79":"markdown","a589ff5c":"markdown","e2b7c4e7":"markdown","22ac5093":"markdown","b00b29ca":"markdown","4338ceb1":"markdown","407a0114":"markdown","d1f004ab":"markdown","c0b0d2b2":"markdown","8a7cf0f0":"markdown"},"source":{"afa5bf1d":"#Loading The Libraries\n\n#For uploading and accessing the data\nimport pandas as pd\nimport numpy as np\n\n#For visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install dexplot -q\n!pip install dabl -q\n!pip install sweetviz -q\n!pip install autoviz -q\n!pip install pycaret -q\n!pip install datasist -q\n\n\n\n\n# for visualizations\nplt.style.use('fivethirtyeight')\n\n# for interactive visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\nfrom sklearn.preprocessing import StandardScaler\n\nfrom pandas_profiling import ProfileReport\nimport sweetviz as sv\n\nimport dexplot as dxp\nimport dabl\nimport sweetviz as sv\n","384b932b":"df = pd.read_csv(\"..\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv\")\n\ndatA = ff.create_table(df.head())\n\npy.iplot(datA)","f94ba143":"df.info()","61f77e31":"df.describe()","9f251422":"df_plot = df.copy()\ndi = {1: \"Male\", 0: \"Female\"}\ndj = {0 : 'normal', 1 :'fixed defect', 2 : 'reversable defect'}\ndk = {0:'Less chance of Heart Attack',1:'High Chance of Heart Attack'}\n\n\ndf_plot['sex'].replace(di, inplace=True)\ndf_plot['thal'].replace(dj, inplace=True)\ndf_plot['target'].replace(dk, inplace=True)\nprint(df_plot)","758c42e6":"profile = ProfileReport(df_plot, title='Pandas Profiling Report')","ad1dde58":"profile.to_notebook_iframe()","7a53fd0a":"my_report = sv.analyze(df,target_feat='target')\nmy_report.show_html()","9d6a86da":"from IPython.display import HTML\n\nHTML(filename=\".\/SWEETVIZ_REPORT.html\")","aa4af1af":"clean_data = dabl.clean(df, verbose=1)\nclean_data.describe()","2b1d4a9a":"types = dabl.detect_types(clean_data)\ntypes","62e1ef8d":"dabl.plot(clean_data, 'target')","87922ce9":"dabl_classifer = dabl.SimpleClassifier(random_state=0)","118bb33e":"X = clean_data.drop('target', axis=1)\nsc = StandardScaler()\nX = sc.fit_transform(X)\ny = clean_data.target\ndabl_classifer.fit(X, y)","3bc42251":"from autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()","d8bf7a28":"sep = ','\ntarget = 'target'\nfilename = '..\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv'","8f64b999":"dft = AV.AutoViz(filename, sep=sep, depVar=target, dfte=df_plot, header=0, verbose=2,\n                            lowess=False,chart_format='svg',max_rows_analyzed=1500,max_cols_analyzed=30)","b183d479":"from pycaret.classification import *\nclassifier = setup(df, target = 'target', session_id=42, experiment_name='heart',normalize=True,silent=True)","6b39067a":"best_model = compare_models(blacklist=['nb','svm','qda'])","4123c4d5":"lr = create_model('lr', fold = 10)","2fec0716":"rf = create_model('rf', fold = 5)","962082e5":"models(type='ensemble').index.tolist()","dd4b6dc0":"ensembled_models = compare_models(whitelist = models(type='ensemble').index.tolist(), fold = 3)","cb5b7af8":"tuned_lr = tune_model(lr)","46b70f7d":"plot_model(lr)","35d07622":"plot_model(rf)","25e256a3":"plot_model(lr, plot = 'confusion_matrix')","836398a6":"plot_model(rf, plot = 'confusion_matrix')\n","7e9ae30a":"plot_model(rf, plot = 'feature')","3b95aebd":"plot_model(lr, plot = 'class_report')","f46aaa79":"plot_model(rf, plot = 'class_report')\n","55fd530f":"import datasist as ds\n# Quick summary of a data using the describe function in the structdata module\nds.structdata.describe(df_plot)","b4464c59":"# Show categorical features\ncat_feats = ds.structdata.get_cat_feats(df_plot)\ncat_feats","0a99033e":"# Show Numerical features\nnum_feats = ds.structdata.get_num_feats(df_plot)\nnum_feats","3f428940":"# Get Unique Count\nds.structdata.get_unique_counts(df_plot)","866d3471":"# Visualize Missing\nds.visualizations.plot_missing(df_plot)","a132b9c0":"ds.structdata.display_missing(df_plot)","ea70e456":"#check the unique classes in each categorical feature\nds.structdata.class_count(df_plot)","d037afc2":"# Autoviz Integration\nds.visualizations.autoviz(df_plot)","443505b6":"#VISUALIZATION FOR CATEGORICAL FEATURES\nds.visualizations.countplot(df_plot)","4d69001e":"ds.visualizations.catbox(data=df_plot, target='target', fig_size=(10,7))","05ed23df":"ds.visualizations.boxplot(data=df_plot, target='target', fig_size=(5,5))","593b7592":"ds.visualizations.catbox(data=df_plot, target='target')","3d9aaedb":"ds.visualizations.violinplot(data=df_plot, target='target')","87cd6dcc":"# <a id='5'>5. AutoViz<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a><img src = \"https:\/\/github.com\/AutoViML\/AutoViz\/raw\/master\/logo.png\">\n<br>\nAutoViz is a one-click visualization engine: It creates powerful charts that anyone from a beginner to an expert can use.\n\nAutoViz knows creating charts from any data manually is hard: It's even harder when you don't know what's in it. AutoViz starts by first analyzing your data to know if it is a Classification, Regression, Unsupervised or Time Series problem. It then chooses the best charts to maximize your insights...","2f3bf55d":"#### Base Model Comparison ","6978127d":"# <a id='3'>3. SweetViz<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a><img src = \"https:\/\/camo.githubusercontent.com\/4d5936eda5ab56d2cef1975e6a750b3b376ef90b\/687474703a2f2f636f6f6c74696d696e672e636f6d2f53562f6c6f676f2e706e67\">\n<br>\n<b>Sweetviz is an open source Python library that generates beautiful, high-density visualizations to kickstart EDA (Exploratory Data Analysis) with a single line of code. Output is a fully self-contained HTML application.The system is built around quickly visualizing target values and comparing datasets. Its goal is to help quick analysis of target characteristics, training vs testing data, and other such data characterization tasks.<\/b>","b876d27f":"#### Analyze Model with Plot Curves\n##### ROC Curve","c9621fae":"#### Create Custom Models","5632a4ef":"###### dabl detects features types and automatically cleans the data this makes analysing the data extremely fast.","09f63570":"#### Feature Importance Plot","6cf6f06b":"##### Confusion Metrics","99e8fb79":"# <a id='2'>2. Pandas Profiling<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a>\n#### From Github-\n##### Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\n##### [](http:\/\/)For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n\n* Type inference: detect the types of columns in a dataframe.\n* Essentials: type, unique values, missing values\n* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n* Most frequent values\n* Histogram\n* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n* Missing values matrix, count, heatmap and dendrogram of missing values\n* Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.\n* File and Image analysis extract file sizes, creation dates and dimensions and scan for truncated images or those containing EXIF information.","a589ff5c":"# <a id='1'>1. Overview<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a>\n## Exploratory Data Analysis \n### Playing with Automated EDA Tools \nExploratory Data Analysis (EDA) plays a very important role in understanding the dataset. Whether you are going to build a Machine Learning Model or if it's just an exercise to bring out insights from the given data, EDA is the primary task to perform. While it's undeniable that EDA is very important, The task of performing Exploratory Data Analysis grows in parallel with the number of columns your dataset has got.","e2b7c4e7":"# <a id='4'>4. Data Analysis Baseline Library<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a>\n###### Dabl offers a tool to automate many of the repetitive tasks involved in the initial model development phase. Although features are currently a little limited, the functionality that does exist is very promising. Looking at the Github repo development is very much ongoing with the latest commit to the project happening as recently as November 15th 2019.\n\n### Data Preprocessing\n##### Ordinarily, the first Step of a machine learning project would be to Perform EDA and necessary preprocessing prior to training any machine learning model. Dabl seeks to automate this process. If you run the following commands dabl will attempt to identify missing values, feature types and erroneous data.","22ac5093":"###### Dabl also seeks to speed up the model selection process. By running a very small amount of code dabl trains a selection of scikit-learn models and returns the corresponding scores.\n","b00b29ca":"#### Hyperparameter Tuning","4338ceb1":"#### Classification Report","407a0114":"# <a id='7'>7. Datasist<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a>\n\n##### Datasist is a python package providing fast, quick, and an abstracted interface to popular and frequently used functions or techniques relating to data analysis, visualization, data exploration, feature engineering, Computer, NLP, Deep Learning, modeling, model deployment etc.\n\n<img src = \"https:\/\/gblobscdn.gitbook.com\/assets%2F-LyFPbiBAwD4nrB_qWNH%2F-LyFQzeAX6C4CZz4koDG%2F-LyFaP2OcHN8Lhyxyw2Y%2Fdlogo.jpeg?alt=media&token=39ed7ff9-a020-4011-86c4-e047d7d12e46\">","d1f004ab":"### Made with \u2764\ufe0f ","c0b0d2b2":"\n# \u2764\ufe0f Attack Prediction\n<img src='https:\/\/2rdnmg1qbg403gumla1v9i2h-wpengine.netdna-ssl.com\/wp-content\/uploads\/sites\/3\/2020\/01\/mildHeartAttack-866257238-770x553-745x490.jpg' height=500 width=500\/>\n\n#### About data set\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to\nthis date.The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no\/less chance of heart attack and 1 = more chance of heart attack\n\n#### Attribute Information\n- age\n- sex\n- chest pain type (4 values)\n- resting blood pressure\n- serum cholestoral in mg\/dl\n- fasting blood sugar > 120 mg\/dl\n- resting electrocardiographic results (values 0,1,2)\n- maximum heart rate achieved\n- exercise induced angina\n- oldpeak = ST depression induced by exercise relative to rest\n- the slope of the peak exercise ST segment\n- number of major vessels (0-3) colored by flourosopy\n- thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n- target: 0= less chance of heart attack 1= more chance of heart attack\n\n## <a id='toc'>Table of Contents<\/a>\n1. [Overview](#1)\n2. [Pandas Profiling](#2)\n3. [SweetViz](#3)\n4. [Data Analysis Baseline Library](#4)\n5. [AutoViz](#5)\n6. [Pycaret](#6)\n7. [Datasist](#7)","8a7cf0f0":"# <a id='6'>6. Pycaret<\/a>\n<a href='#toc'><span class=\"label label-info\">Go back to the Table of Contents<\/span><\/a>\n<img src = \"https:\/\/github.com\/pycaret\/pycaret\/raw\/master\/pycaret2-features.png\">\n\n###### PyCaret is an open source low-code machine learning library in Python that aims to reduce the hypothesis to insights cycle time in a ML experiment. It enables data scientists to perform end-to-end experiments quickly and efficiently. In comparison with the other open source machine learning libraries, PyCaret is an alternate low-code library that can be used to perform complex machine learning tasks with only few lines of code. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, Microsoft LightGBM, spaCy and many more."}}