{"cell_type":{"a5c914ea":"code","7bfae58f":"code","175bf5dc":"code","f5eb3df5":"code","11d72f66":"code","04ba03df":"code","6deb92d1":"code","a73421e2":"code","4c9aa937":"code","d1f75693":"code","65159402":"code","dc0ff60b":"code","80189bea":"code","6639d9fd":"code","5bbe44fd":"code","1db3d035":"code","e3ab89ac":"code","c557cabf":"code","74a38192":"code","29a56537":"code","b1f38909":"code","6ca8da88":"code","20725593":"code","8d6d833f":"code","34958dca":"code","42b45a28":"code","fc662252":"code","809c6390":"code","4ee543c0":"markdown","83766905":"markdown","622513c1":"markdown","fecb1bb2":"markdown","b3f996ef":"markdown","ef90642b":"markdown","95f18a13":"markdown","5f6b0489":"markdown","19c6d9cf":"markdown","0aea7274":"markdown","30e446f4":"markdown","a5aecbc3":"markdown","0aa4a888":"markdown","6bf5b09c":"markdown","f0fc1dac":"markdown","8dbf2502":"markdown","83ccd250":"markdown","649f3618":"markdown","f5665c86":"markdown","9173328f":"markdown","5e9cfdb7":"markdown","0bcf2aff":"markdown","cbf457f9":"markdown","ac1659f5":"markdown","6a78d15d":"markdown"},"source":{"a5c914ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7bfae58f":"df=pd.read_csv('..\/input\/202122-epl-playerstats\/2021-22_EPL_PlayerStats.csv',index_col=0)\ndf.sample(10,random_state=42)","175bf5dc":"#Maximum games played by a player\nplt.subplots(1,1,figsize=(10,5))\nsns.histplot(df,x='MP',kde=True,binwidth=1)\nplt.title('Frequency of Matches Played',size=15)\nplt.xlabel('Matches Played',size=15)\nplt.show()","f5eb3df5":"df[df.isna().any(axis=1)].head(5)","11d72f66":"df=df[df['MP']>10]\ndf['Primary_pos']=df['Pos'].str.split(',').str[0]\ndf['Secondary_pos']=df['Pos'].str.split(',').str[1]\ndf['Secondary_pos']=df['Secondary_pos'].fillna('NA')\ndf.drop(columns=['Pos'],inplace=True)\ndf=df.fillna(0)","04ba03df":"tot=0\nc=0\nfeats=df.columns[2:-2]\ncorr=df.iloc[:,2:-2].corr() # [2:-2] are the metric columns\nfor i,c1 in enumerate(corr.index):\n    for j in range(i+1,len(corr)):\n        if abs(corr.loc[c1,corr.columns[j]]) > 0.5: #cheecking whether correlation >0.5\n            tot+=1\n        c+=1\ntot","6deb92d1":"#PCA\nx=df.iloc[:,2:-2].values\nx=StandardScaler().fit_transform(x)\npca=PCA()\npc=pca.fit_transform(x) #Matrix of principal components","a73421e2":"#Variance explained by each principal component\ndic={}\ns=0\nfor i,v in enumerate(pca.explained_variance_):\n    s=s+v\n    dic[i+1]=s*100\/pca.explained_variance_.sum()\nplt.subplots(1,1,figsize=(15,8))\nplt.bar(dic.keys(),dic.values())\nplt.title('Explained variance of principal components',size=15)\nplt.xlabel('Principal Components',size=15)\nplt.ylabel('Percentage')\nplt.show()","4c9aa937":"axes=pca.components_ #Prinicpal axes (eignevectors) obtained from PCA\npc.T[0] #First principal component","d1f75693":"#Function to extract top 10 variables in a PC\ndef feat_pc(axes,feats,n):\n    ind=np.argsort(abs(axes[n]))[-10:]\n    df=pd.DataFrame()\n    df['variables']=feats[ind][::-1]\n    df['coefficient']=axes[n][ind][::-1]\n    df['percentage']=100*np.square(df['coefficient'])\n    return df","65159402":"#First principal component\nfeat_pc(axes,feats,0)","dc0ff60b":"#Utility functions\ndef pos_infor(df,l,names=False):\n    df['cl']=l\n    for i in df['cl'].unique():\n        print(i)\n        print(df.groupby('cl').get_group(i)['Primary_pos'].value_counts())\n        if names==True:\n            print(df.groupby('cl').get_group(i)['Player'].head(20).values)\n    df.drop(columns=['cl'],inplace=True)\n\ndef kmeans_scores(pc,ul,c1,c2=0):\n    scores=[]\n    for i in range(1,ul+1):\n        kmeans=KMeans(i)\n        if c2==0:\n            kmeans.fit(pc.T[c1-1].reshape(-1,1))\n        else:\n            kmeans.fit(np.vstack((pc.T[c1-1],pc.T[c2-1])).T)\n        scores.append(kmeans.inertia_)\n    plt.plot(range(1,i+1),scores)\n    plt.xlabel('Number of Clusters')\n    plt.title('Elbow Method')\n    plt.show()\n\ndef cluster_plot(pc,i,c1):\n    kmeans=KMeans(i)\n    l=kmeans.fit_predict(pc.T[c1-1].reshape(-1,1))\n    plt.subplots(1,1,figsize=(14,6))\n    sc=plt.scatter(np.arange(0,300),pc.T[c1-1],c=l)\n    plt.xlabel('player index')\n    plt.ylabel('PC'+str(c1))\n    plt.show()\n    return l","80189bea":"kmeans_scores(pc,6,1)","6639d9fd":"l=cluster_plot(pc,2,1)","5bbe44fd":"#Primary player positions in the above clusters\npos_infor(df,l)","1db3d035":"#2nd principal component\nfeat_pc(axes,feats,1)","e3ab89ac":"kmeans_scores(pc,6,2)","c557cabf":"l=cluster_plot(pc,3,2)","74a38192":"pos_infor(df,l,names=True)","29a56537":"feat_pc(axes,feats,10)","b1f38909":"kmeans_scores(pc,6,9)","6ca8da88":"l=cluster_plot(pc,3,9)","20725593":"kmeans_scores(pc,12,1,2)","8d6d833f":"kmeans=KMeans(4)\nl=kmeans.fit_predict(pc[::,:2])\ncen=kmeans.cluster_centers_\ndf['pc1']=pc.T[0]\ndf['pc2']=pc.T[1]\ndf['cluster']=l","34958dca":"sns.relplot(data=df, x='pc1', y='pc2', hue='cluster', palette='tab10', kind='scatter',height=8.27, aspect=11.7\/8.27)\nplt.show()","42b45a28":"pos=[['GK','DF'],['MF','FW']]\nf,ax=plt.subplots(2,2,figsize=(20,10))\nfor i in range(0,2):\n    for j in range(0,2):\n        r=df[df['Primary_pos']==pos[i][j]]\n        sns.scatterplot(ax=ax[i,j],data=r, x='pc1', y='pc2', hue='cluster', palette='tab10',s=40)\n        ax[i][j].set_title(pos[i][j],size=15)","fc662252":"def player_cluster(pos,cl,df):\n    db=df.groupby('cluster').get_group(cl)\n    return db[db['Primary_pos']==pos]","809c6390":"db=player_cluster('MF',1,df)\ndb","4ee543c0":"Based on this component,the KMeans algorithm, I believe, has clustered players according to their creativity and ball progression actions. If you watch football, you'll recognize that players in cluster '0' make a lot of ball progression and are involved in a lot of teamplay in the attcking third. Contrarily, cluster '1' have rather immobile players who either solely score goals (forwards) or stick to their defensive duties. ","83766905":"# First Principal Component","622513c1":"The first 2 principal components(PCs) explain around 53% of the variation in data, while the first 5 PCs describe more than 70% of the variation. Clearly, there was no point in carrying all the 83 metrics. I'll consider only the first two\nPCs going forward. Let's dig them up to see what information they relay.","fecb1bb2":"# Second Principal Component","b3f996ef":"According to the above elbow plot, two clusters are sufficient for adequate grouping based on just the first principal component.","ef90642b":"From a total possible of 3403 unique variable pairs, 687 have an absolute correlation of more than 0.5. Hence, I'll use PCA to transform the variables and extract only the important information.","95f18a13":"Coefficients, as discussed above, are the weights of each variable. Negative coefficient implies a negative correlation of the variable with the PC. Percentage is calculated as the square of each coefficient times 100. Basically, the percentage of each variable in the PC.","5f6b0489":"# Tenth Principal Componenet\nNow, let's look at a PC that does not explain a lot of variation in data. PC 10 expalins only around 1.5% of the variation","19c6d9cf":"Few metrics are NULL for certain players and I'll replace them with 0.","0aea7274":"From the variable compostition, it's not at all transparent what information this component relays. As opposed to the first two PCs which had majority contribution from similar variables, attacking output and passing types respectively, PC 10 is composed of many uncorrelated variables (Yellow cards, Goal errors and Left foot passes have little in common).","30e446f4":"The above first principal component can also be obtained by the dot product of x (original variables) and the first principal axis","a5aecbc3":"Remember that PC1 is associated with attacking output (goals,assists etc) while PC2 is associated with ball progression and involvement in attacking third. Based on this, let's analyze the four clusters. Below, I have created a function to see the names belonging to each cluster.\n\n**Cluster 0**\n1. All players in this cluster have negative values for both PC1 and PC2\n2. These are mainly defensive players. All goalkeepers, hence, quite undestandably belong to this cluster. Rest of this cluster comprises mainly of defenders, and a few midfilders who I believe must be the ones responsible for screening the back line.\n\n**Cluster 1**\n1. Positive values for both PC1 and PC2\n2. This cluster mainly includes midfilders and forwards. There are only 3 defenders in this clusters. They must be the modern highly active full-backs who shuttle up and down the flank providing assistance in the attacking third. \n3. Players in this cluster are perhaps the cheif creators in their teams. Mohamed Salah, Trent, Bruno Fernandes etc fall in this cluster.\n\n**Cluster 2**\n1. Positive PC1 but negative PC2\n2. These are players who have good attacking numbers (maybe not as good as the ones in cluster 1), but aren't involved a lot in the build up play in the attacking half. As it mainly includes forwards, I belive these are typical goalpoachers.\n\n**Cluster 3**\n1. Negative PC1 but postive PC2\n2. Highly active players who cover a lot of distance and progress the ball, but don't have hight attacking numbers. Mainly composed of defenders and midfielders like Henderson,Fabinho, Declan Rice etc.","0aa4a888":"4 clusters seem to be the right choice here","6bf5b09c":"The second principal component divides the data well into three clusters.","f0fc1dac":"You can check the data description to find what each of these variables track. SPA, for instance, is the the total short passes attempted. So, the second principal componet takes into account the type of passes made by the player.Carries, TotalDistCarry,ProgPass quantify how much a player is responsible in progressing the ball forward(toward's opposition half). SCPass are passes that create a shot. In essense, the second principal component relays information about the playing style of a player. It is correlated with players who make a lot of good passes and are involved heavily in teamplay.","8dbf2502":"# Relating principal components with original variables\nPCs in isolation are neither fascinating nor intuitive unless one is able to compare them to the orginial variables. Essentially, each PC is a mixture (some linear combination) of the original variables, and it'd be useful to determine how much of each variable is present in a particular PC. How to do that? Well, some simple math will help with that.\n\nConsider a data-space with n variables then the first principal component can be written as:\n$$PC1=a_{11}X_{1}+a_{12}X_{2}+..+a_{1n}X_{n}$$\nI won't deep-dive into the math behind PCA, but if you're familiar with it, you'd know that the vector $[a_{11}\\,a_{12}\\,a_{13}\\,...a_{1n}]$ is the axis which explains the most variation in data and $\\sum_{1}^{n}a_{1n}^{2}=1$. Now, as PC1 is a dot product of this vector and the data-space(x), the amount of a variable 'k' in PC1 can be ascertained by the coefficient $a_{1k}$. Essentially, you can think of these coefficients as the weights of the original variables in PC1. Let's see how this works in code.","83ccd250":"# Combining PC1 and PC2\nFinally, let's see how the first two principal components, in combination, cluster the data.","649f3618":"Evidently, the first PC is associated more with the goals and assists made by players. It's also negatively associated with touches in the defensive third. Hence,this component should help differntiate attacking and defensive players. Let's the same by performing clustering on just the first principal component","f5665c86":"Cluster '0' comprises mainly of defenders and all the goalkeepers, while cluster '1' has all the forward players and very few defenders. This division conforms with the variable composition of PC1 which we discussed above. As PC1 gives more weight to variables related to goals and assists, it helped differentiate between attacking and defensive players. It'll be interesting to know more about the 9 defenders belonging to cluster '1'. But first, let's repeat the exercise for some more principal components.","9173328f":"# Checking for Correlation","5e9cfdb7":"# PCA","0bcf2aff":"Notice how the y range (range of principal component) has shrunk. It varied from -10 to 20 for PC2. This observation is in accordance with the PCA theory. As latter components explain less variation, the data-points are concentrated in a narrower range. This also results in inefficient clustering. The reduction in elbow score from a single cluster to 3 clusters is quite less compared to PC1 and PC2.","cbf457f9":"As the data is from the current season till matchday-20, the maximum appearances by any player is 20. For the analysis, I am going to ignore players who have played less than 10 games. Also, if you notice in the dataframe above, few players have multiple postitions. I'll separate them into primary and secondary positions.","ac1659f5":"The KMeans algorithm has clustered the data into groups based on negative and positive PC1 values. Let's now see the majority primary position of these clusters.","6a78d15d":"I collected data on premier league player performances for the current season(2021-22) from [fbref.com](http:\/\/https:\/\/fbref.com\/en\/). It consists of 83 different player metrics.The website data on many more metrics if you want to check them out. The idea is to use these metrics to bucket players according to their playing style. A generic way to do so would be to simply differentiate players according to their positions, however, that's not interesting. If at all you're a football fanatic and have been following the game for a while, you ought to be privy to the how often postitions in modern football overlap. Many full-backs engage extensively in attacks, often sacrificing defensive responsibilites, while central midfielders cover for them at the back. I want to see whether the clustering algorithm, based on these 83 metrics, can capture this trend.\n\nPS: Check the dataset description if you want to know what these metrics are"}}