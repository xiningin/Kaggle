{"cell_type":{"ba42c139":"code","59152600":"code","a11f32fc":"code","7ca36fb9":"code","111142f7":"code","25db46ce":"markdown"},"source":{"ba42c139":"#import libraries \n\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport cv2\nimport os\nimport numpy as np\nfrom PIL import Image, ImageChops\nfrom torchvision import transforms\n\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom torchvision import models\nimport pickle\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  ","59152600":"# make label \n\ndef labelling(x):\n    try:\n        return int(x[0]), int(x[1]), int(x[2]), int(x[3]), str(x[4]), str(x[5]), str(x[6])\n    except:\n        return int(x[0]), int(x[1]), int(x[2]), int(x[3]), str(x[4]), str(x[5]), str('No')\n\n    \n#make dataset for torch\nclass CatPlateDataset(Dataset):\n    def __init__(self, df, imfolder, train, label='label_1',transforms=None):\n\n        self.df = df\n        self.imfolder = imfolder\n        self.transforms = transforms\n        self.train = train\n        self.label = label\n\n    def __getitem__(self, index):\n        im_path = os.path.join(self.imfolder, self.df.iloc[index]['file_name'])\n\n        x = cv2.imread(im_path, cv2.COLOR_BGR2RGB)\n\n        x = np.swapaxes(x, 0, 2)\n        x = x\/255\n\n        #x = self.transforms(x)\n\n        if self.train:\n            y1 = np.asarray(self.df.iloc[index]['label_1'])#.values\n            y2 = np.asarray(self.df.iloc[index]['label_2'])\n            y3 = np.asarray(self.df.iloc[index]['label_3'])\n            y4 = np.asarray(self.df.iloc[index]['label_4'])\n            y5 = np.asarray(self.df.iloc[index]['label_5'])\n            y6 = np.asarray(self.df.iloc[index]['label_6'])\n            y7 = np.asarray(self.df.iloc[index]['label_7'])\n            return x, (y1, y2, y3, y4, y5, y6, y7)\n        else:\n            return x\n\n    def __len__(self):\n        return len(self.df)","a11f32fc":"# Convolutional neural network (two convolutional layers)\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.fc = nn.Linear(101088, 1024)\n        \n        self.fc1 = nn.Linear(1024, num_classes['label_1'])\n        self.fc2 = nn.Linear(1024, num_classes['label_4'])\n        self.fc3 = nn.Linear(1024, num_classes['label_3'])\n        self.fc4 = nn.Linear(1024, num_classes['label_4'])\n\n        self.fc5 = nn.Linear(1024, num_classes['label_5'])\n        self.fc6 = nn.Linear(1024, num_classes['label_6'])\n        self.fc7 = nn.Linear(1024, num_classes['label_7'])\n        \n    def forward(self, x):\n        \n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        \n        out = self.fc(out)\n        \n        out1 = self.fc1(out)\n        out2 = self.fc2(out)\n        out3 = self.fc3(out)\n        out4 = self.fc4(out)\n        out5 = self.fc5(out)\n        out6 = self.fc6(out)\n        out7 = self.fc7(out)\n        \n        return out1, out2, out3, \\\n               out4, out5, out6, out7","7ca36fb9":"ROOT = '..\/input\/mlub-mongolian-car-plate-prediction\/'\n\ntrain = pd.read_csv(ROOT+'training.csv')\n\ntrain = train.reset_index(drop=True)\n\ntrain['label_1'],train['label_2'], train['label_3'], \\\ntrain['label_4'], train['label_5'], train['label_6'], \\\ntrain['label_7'] = zip(*train['plate_number'].map(labelling))\n\ntest = pd.read_csv(ROOT+'submission.csv')\ntest['label_1'],test['label_2'], test['label_3'], \\\ntest['label_4'], test['label_5'], test['label_6'], \\\ntest['label_7'] = zip(*test['plate_number'].map(labelling))\n\nlabel = ['label_1', 'label_2', 'label_3', 'label_4',\n         'label_5', 'label_6', 'label_7']\n\n#make string label into integer \nout_dim = {}\nencoders = {}\nfor lab in label:\n    encoders[lab] = OrdinalEncoder().fit(train[[lab]])\n    train[lab] = encoders[lab].transform(train[[lab]])\n    out_dim[lab] = len(train[lab].unique())\n\nepochs = 10\n\nbest_val = None\nes_patience = 3\n\nmodel = ConvNet(num_classes=out_dim)\n\nmodel = model.to(device)\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = ReduceLROnPlateau(optimizer=optim, mode='min', patience=2, verbose=True, factor=0.4)\ncriterion = nn.CrossEntropyLoss()\n\nval = train.sample(n=500, random_state=1)\ntrain_data = train\n\ntrain_set = CatPlateDataset(df=train_data.reset_index(),\n                        imfolder=ROOT + 'training\/training',\n                        train=True,\n                        label=label,\n                        transforms=None)\n\ntrain_loader = DataLoader(dataset=train_set, batch_size=16, shuffle=True)\n\nval_set = CatPlateDataset(df=val.reset_index(),\n                            imfolder=ROOT + 'training\/training',\n                            train=True,\n                            label=label,\n                            transforms=None)\n\nval_loader = DataLoader(dataset=val_set, batch_size=32, shuffle=False)\n\nfor epoch in range(epochs):\n    model_path = 'model.pth'\n    train_preds = []\n    y_true = []\n    epoch_loss = 0\n    correct = 0\n    total = 0\n    for x, y in tqdm(train_loader):\n        #print(x.shape)\n        out1, out2, out3, out4, \\\n        out5, out6, out7 = model(x.to(device).float())\n\n        loss = criterion(out1, y[0].to(device).long()) + criterion(out2, y[1].to(device).long()) +\\\n               criterion(out3, y[2].to(device).long()) + criterion(out4, y[3].to(device).long()) +\\\n               criterion(out5, y[4].to(device).long()) + criterion(out6, y[5].to(device).long()) + \\\n               criterion(out7, y[6].to(device).long())\n\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n\n        epoch_loss += loss.item()\n\n    print(\n        'Epoch {:03}: | Loss: {:.3f}'.format(\n            epoch + 1,\n            epoch_loss))\n\n    total = 0\n    correct = 0\n    model.eval()\n    with torch.no_grad():\n        for x, y in tqdm(val_loader):\n            out = model(x.to(device).float())\n\n            for j, pred in enumerate(out):\n                _, predicted = torch.max(pred.data, 1)\n\n                total += y[j].size(0)\n                correct += (predicted == y[j].to(device).long()).sum().item()\n\n    acc = 100 * correct \/ total\n    print('Test Accuracy of the model: {} %'.format(100 * correct \/ total))\n\n    scheduler.step(acc)\n    if not best_val:\n        best_val = acc  # So any validation roc_auc we have is the best one for now\n        torch.save(model, model_path)  # Saving the model\n        continue\n\n    if acc > best_val:\n        best_val = acc\n        patience = es_patience  # Resetting patience since we have new best validation accuracy\n        torch.save(model, model_path)  # Saving current best model\n        best_epoch = epoch\n    else:\n        patience -= 1\n        if patience == 0:\n            print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n            break\n","111142f7":"test = pd.read_csv(ROOT+'submission.csv')\n\ntest['label_1'],test['label_2'], test['label_3'], \\\ntest['label_4'], test['label_5'], test['label_6'], \\\ntest['label_7'] = zip(*test['plate_number'].map(labelling))\n\ntest_set = CatPlateDataset(df=test.reset_index(),\n                            imfolder=ROOT + 'test\/test',\n                            train=False,\n                            label=label,\n                            transforms=None)\n\ntest_loader = DataLoader(dataset=test_set, batch_size=128, shuffle=False)\n\n\npred_y = {'label_1': [], 'label_2': [], 'label_3': [], 'label_4': [],\n          'label_5': [], 'label_6': [], 'label_7': []}\n\n\nfor x in tqdm(test_loader):\n    out_prob = {}\n    model.eval()  # switch model to the evaluation mode\n    with torch.no_grad():\n        outs = model(x.to(device).float())\n        for out, lab in zip(outs, label):\n            out_prob[lab] = out\n        \n\n    for lab in label:\n        _, predicted = torch.max(out_prob[lab].data, 1)\n        pred = predicted.detach().cpu().numpy()\n        pred_y[lab]+=list(encoders[lab].inverse_transform(np.expand_dims(pred, axis=1)).flatten())\n\npreds = pd.DataFrame.from_dict(pred_y)\n\npreds['label_7']=np.where(preds['label_7'].values=='No', '', preds['label_7'].values)\n\npreds['plate_number'] = preds.agg('{0[label_1]}{0[label_2]}{0[label_3]}{0[label_4]}{0[label_5]}{0[label_6]}{0[label_7]}'.format, axis=1)\npreds['file_name'] = test['file_name'].values\npreds[['file_name', 'plate_number']].to_csv('submission.csv', index=False)","25db46ce":"\u042d\u043d\u044d \u043a\u0435\u0440\u043d\u0435\u043b \u0434\u044d\u044d\u0440 \u0437\u0443\u0440\u0430\u0433\u043d\u0430\u0430\u0441 \u043c\u0430\u0448\u0438\u043d\u044b \u0434\u0443\u0433\u0430\u0430\u0440 \u0442\u0430\u043d\u0438\u0445\u0430\u0434 \u0445\u044d\u0440\u0445\u044d\u043d \u0433\u04af\u043d\u0437\u0433\u0438\u0439 \u0441\u0443\u0440\u0433\u0430\u043b\u0442\u044b\u043d \u0437\u0430\u0433\u0432\u0430\u0440 \u0441\u0443\u0440\u0433\u0430\u0436 \u0431\u043e\u043b\u043e\u0445\u044b\u0433 \u0445\u0430\u0440\u0443\u0443\u043b\u043b\u0430\u0430. "}}