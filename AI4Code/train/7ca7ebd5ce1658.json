{"cell_type":{"b132dd77":"code","ae9cbec2":"code","c83310f0":"code","5b28a861":"code","8f98cd10":"code","38fa104c":"code","7482f5e2":"code","748721f8":"code","55ca8749":"code","cec2ccf8":"code","ab1ae4f2":"code","fb3d8c3e":"code","d9056844":"code","cb45264c":"code","57c69b8b":"code","e05155d6":"code","bd6d48c2":"code","6714d76e":"code","50685a04":"code","3a15b384":"code","99f9d87c":"code","64f5b1a0":"code","61e77cd0":"code","c429f9e7":"code","febfcc60":"code","4861f041":"code","92ec0f83":"code","c401c435":"code","daba098d":"code","36384bd6":"code","d368baa0":"code","b0e2866a":"code","8b06bd26":"code","9d7bf490":"code","e0013f2a":"code","d244777f":"code","ee8f1a9c":"code","c98053cc":"code","6a92d894":"code","03e04a81":"code","1667c059":"code","f59400c1":"code","2ebd4ee2":"code","d9eb2cd3":"code","852fd643":"code","2ac69827":"code","e660b0d4":"code","b4209a8c":"code","b81da29f":"code","9f176fc5":"code","a366f70f":"code","8ccf9328":"code","38bb21ef":"code","66e859b5":"code","f7b60b6f":"code","497b161d":"code","ec8a37d1":"code","cd3f6896":"code","f7ac81dc":"code","ac82c2c3":"code","8e7c6094":"code","4911ebb6":"code","8addd53d":"code","09e00983":"code","9280a5f4":"code","30c15a27":"code","f793f292":"code","11f9c904":"code","f688fa3c":"code","127d6452":"code","8734d2ab":"code","1361f565":"code","1a660ef5":"code","2719cdec":"code","0d127ba0":"code","7bb8d4f3":"code","ee89e4a6":"code","8503c49c":"code","e73064e5":"code","c1291d5f":"code","3b91f708":"code","7eb6dd6b":"code","86a8d5a6":"code","b29f06a6":"code","eb1dfa02":"code","70327adc":"code","0a9f6847":"code","e12461f2":"code","92d6855d":"code","a90192ae":"code","129d06d4":"code","2a2cc232":"code","8947c1ba":"markdown","906fc086":"markdown","99cb551e":"markdown","cae3e205":"markdown","ed7ec29a":"markdown","c2f6fff2":"markdown","5531ff31":"markdown","c063fcf9":"markdown","127ede11":"markdown","49d19172":"markdown","5e36799f":"markdown","a31dac9d":"markdown","40b2bd61":"markdown","33029d3d":"markdown","2497260a":"markdown","ed0d4759":"markdown","aac56379":"markdown","d614bcfc":"markdown","8b2e92ae":"markdown","a16bef72":"markdown","5bc2c11e":"markdown","0ea804e9":"markdown","9f722139":"markdown","05158109":"markdown","c9088697":"markdown","853b2be7":"markdown","5d7499b9":"markdown","4fa74c97":"markdown","1fddbef8":"markdown","d481bda0":"markdown","91854115":"markdown","fb5175d5":"markdown","b8c06cd1":"markdown","b967e457":"markdown","520456c3":"markdown","911f064e":"markdown","a6ad782f":"markdown","555c9a78":"markdown","41b9ddce":"markdown","f01480b1":"markdown","1e63904a":"markdown","bad24249":"markdown","05ae9f60":"markdown","29653e51":"markdown","a9c7754a":"markdown","d4bb51cb":"markdown","088d42bb":"markdown","df1ac515":"markdown","0f41e7c5":"markdown","2e804b37":"markdown","6815fb2e":"markdown","5baa761d":"markdown","da6bf024":"markdown","b19769ce":"markdown","db702b23":"markdown","68c9b5a8":"markdown","03a49e7d":"markdown","be99cc10":"markdown","a60dc899":"markdown","416cd24d":"markdown","1c04d9f7":"markdown","686788ab":"markdown"},"source":{"b132dd77":"# !pip install palmerpenguins","ae9cbec2":"# import palmerpenguins # the data\n# from palmerpenguins import load_penguins # the data\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns # for pretty charts\nimport sklearn # modeling\nimport matplotlib as mpl # plotting\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)","c83310f0":"penguins = pd.read_csv(\"..\/input\/penguins\/penguins.csv\")\npenguins.head(6)\n# penguins['species'].value_counts()","5b28a861":"penguins['species'].value_counts()","8f98cd10":"penguins.info()","38fa104c":"penguins.isna().sum()","7482f5e2":"df = penguins.copy() # this allows alterations to be made to new data without changing original data","748721f8":"df[df['sex'].isna()] # display the records with nans in a dataframe","55ca8749":"df.drop(index=[3,271], inplace=True) # drop records inplace\ndf.reset_index(inplace=True, drop=True) # reset index and drop old index\ndf.drop(columns= 'Unnamed: 0', inplace = True)\ndf.head()","cec2ccf8":"# now we have 9 missing values in the sex attribute only\ndf.isna().sum()","ab1ae4f2":"df.drop(columns='year', inplace=True) # inplace = true saves the change immediately without having to save in a new object\ndf.head()","fb3d8c3e":"# Descriptive Statistics\ndf.describe().transpose()","d9056844":"import scipy.stats as stats\n\n# print skewness of each attribute\nfor (colName, colData) in df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].iteritems():\n  print(\"Feature name: {0}, Skewness: {1}\".format(colName, stats.skew(colData)))","cb45264c":"# print kurtosis of each attribute\nfor (colName, colData) in df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].iteritems():\n  print(\"Feature name: {0}, Skewness: {1}\".format(colName, stats.kurtosis(colData)))","57c69b8b":"# correlation matrix\ndf.corr()","e05155d6":"# lets see what our target distribution looks like\nplt.figure(figsize=(7,5))\nsns.countplot(x = df['species'], alpha = 0.65, saturation=0.85)\nplt.title('Target Distributions', size = 13, y = 1.01)\nplt.xlabel(\"\")\nplt.tick_params(axis='both', labelsize = 12)","bd6d48c2":"sns.set_theme(style=\"white\")\ng = sns.relplot(data=df, alpha = 0.6,\n                x=\"bill_length_mm\", y=\"bill_depth_mm\",\n                hue=\"island\", size=\"body_mass_g\",\n                palette=\"Set1\", sizes=(40, 250),height = 7)\n\ng.despine(left=True, bottom=True) # removes axis spines\ng.set_axis_labels(\"Bill Length\", \"Bill Depth\")","6714d76e":"sns.set_theme(style=\"white\")\ng = sns.relplot(\n    data=df, sizes=(40, 250), alpha = 0.6,\n    x=\"bill_length_mm\", y=\"bill_depth_mm\",\n    hue=\"species\", size=\"body_mass_g\",\n    palette=\"Set1\", height = 7)\n\ng.despine(left=True, bottom=True) # removes axis spines\ng.set_axis_labels(\"Bill Length\", \"Bill Depth\")","50685a04":"# df['species'].groupby(['island', 'species']).count()\/ len(df)\n\n# wrap with two square brackets to return a dataframe\ndf.groupby(['island', 'species'])[['species']].count()","3a15b384":"ax = plt.figure(figsize = (8,6))\nax = sns.boxplot(data=df, x = 'species', y ='body_mass_g',\n                 palette=\"Set2\")\nax.set_ylabel('Body Mass (g)')\nax.set_xlabel(\"\")\nax.set_title('Body Mass by Species')\nax.tick_params(axis='x', labelsize = 12)","99f9d87c":"ax = plt.figure(figsize = (8,6))\nax = sns.boxplot(data=df, x = 'species', y ='bill_depth_mm',\n                 palette=\"Set2\")\nax.set_ylabel('Bill Depth (mm)')\nax.set_xlabel(\"\")\nax.set_title('Bill Depth by Species')","64f5b1a0":"ax = plt.figure(figsize = (8,6))\nax = sns.boxplot(data=df, x = 'species', y ='bill_length_mm',\n                 palette=\"Set2\")\nax.set_ylabel('Bill length (mm)')\nax.set_xlabel(\"\")\nax.set_title('Bill length by Species')","61e77cd0":"ax = plt.figure(figsize = (8,6))\nax = sns.boxplot(data=df, x = 'species', y ='flipper_length_mm',\n                 palette=\"Set2\")\nax.set_ylabel('Flipper length (mm)')\nax.set_xlabel(\"\")\nax.set_title('Flipper length by Species')","c429f9e7":"g = sns.catplot(\n    data=df, kind=\"bar\",\n    x=\"species\", y=\"body_mass_g\", hue=\"sex\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\ng.despine(left=True)\ng.set_axis_labels(\"\", \"Body mass (g)\")\ng.legend.set_title(\"\")","febfcc60":"# seperate male from female Adelie species\nmale = df[df['sex'] == 'male']\nmale_adel_spec = male[male['species'] =='Adelie']\nfemale = df[df['sex'] =='female']\nfemale_adel_spec = female[female['species'] =='Adelie']\n\n# Convert to array\nbody_mass_male = np.array(male_adel_spec['body_mass_g'])\nbody_mass_female = np.array(female_adel_spec['body_mass_g'])","4861f041":"# standard deviations of the two groups\nbody_mass_male.std(), body_mass_female.std()","92ec0f83":"from scipy.stats import ttest_ind\n\nresult = ttest_ind(body_mass_male, body_mass_female, equal_var=False)\n\nprint(\"Since p-value= {:1.4f}, --> reject the null hypothesis\".format(result.pvalue))\nprint(\"   There is no evidence to suggest that male and female Adelie penguins' mean body weights (g) are equal.\")","c401c435":"g = sns.catplot(\n    data=df, kind=\"bar\",\n    x=\"species\", y=\"bill_length_mm\", hue=\"sex\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\ng.despine(left=True)\ng.set_axis_labels(\"\", \"Bill length (mm)\")\ng.legend.set_title(\"\")","daba098d":"g = sns.catplot(\n    data=df, kind=\"bar\",\n    x=\"species\", y=\"bill_depth_mm\", hue=\"sex\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\ng.despine(left=True)\ng.set_axis_labels(\"\", \"Bill depth (mm)\")\ng.legend.set_title(\"\")","36384bd6":"g = sns.catplot(\n    data=df, kind=\"bar\",\n    x=\"species\", y=\"flipper_length_mm\", hue=\"sex\",\n    ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\ng.despine(left=True)\ng.set_axis_labels(\"\", \"Flipper length (mm)\")\ng.legend.set_title(\"\")","d368baa0":"df[df['sex'].isna()]","b0e2866a":"df.groupby(['species', 'sex'])[['sex']].count()","8b06bd26":"bill_len_by_sex_spec = df.groupby(['sex', 'species']).median()['bill_length_mm']\nbill_dep_by_sex_spec = df.groupby(['sex', 'species']).median()['bill_depth_mm']\nflip_len_by_sex_spec = df.groupby(['sex', 'species']).median()['flipper_length_mm']\nbody_mass_by_sex_spec = df.groupby(['sex', 'species']).median()['body_mass_g']\n\nfor species in set(df['species']):\n    for sex in ['female', 'male']:\n        print('Median bill length of Species: {}- {}s: {}'.format(species, sex, bill_len_by_sex_spec[sex][species]))\n        print('Median bill depth of Species: {}- {}s: {}'.format(species, sex, bill_dep_by_sex_spec[sex][species]))\n        print('Median flip length of Species: {}- {}s: {}'.format(species, sex, flip_len_by_sex_spec[sex][species]))\n        print('Median body mass of Species: {}- {}s: {}'.format(species, sex, body_mass_by_sex_spec[sex][species]))\n        print('-------------------------------------------------------')\nprint(\"-------------\")\n\nprint('Median bill length of all Species: {}'.format(df['bill_length_mm'].median()))\nprint('Median bill depth of all Species: {}'.format(df['bill_depth_mm'].median()))\nprint('Median flip length of all Species: {}'.format(df['flipper_length_mm'].median()))\nprint('Median body mass of all Species: {}'.format(df['body_mass_g'].median()))","9d7bf490":"# we can first create a dictionary, then map it to the sex feature\nsex_map = {'male': 0,\n           'female': 1}\nsex_map","e0013f2a":" df2 = df.copy()\n\n# map dictionary to sex variable\ndf2['Sex'] = df2['sex'].map(sex_map)\ndf2.drop(columns=['species', 'island', 'sex'], inplace=True)\ndf_array_imp = np.array(df2)","d244777f":"from sklearn.preprocessing import MinMaxScaler\n\npreprocess = MinMaxScaler()\narray_norm = preprocess.fit_transform(df_array_imp) # fits to data, then transforms it\narray_norm","ee8f1a9c":"from sklearn.impute import KNNImputer\n\n# now we can impute the missing values based on the neighboring values\nimputer = KNNImputer(n_neighbors=4)\ndf_array_imp= imputer.fit_transform(array_norm)","c98053cc":"# add column names\ndf_imputed = pd.DataFrame(df_array_imp, columns=['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g','sex'])","6a92d894":"# replace sex column back in original data\ndf['sex'] = df_imputed['sex'].astype(int)\ndf.head()","03e04a81":"# no more missing values!\ndf.isna().sum()","1667c059":"# map back to string format for more visuals\nsex_map = {0: 'male',\n           1: 'female'}\ndf['sex'] = df['sex'].map(sex_map)","f59400c1":"df.head()","2ebd4ee2":"# Regression plot\ng = sns.lmplot(data=df,\n               x='bill_length_mm', y = 'bill_depth_mm', \n               hue = 'species', height=6)\ng.set_axis_labels('Bill length (mm)', 'Bill depth (mm)')\ng.set(title = \"Multiple Regression Plot\")","d9eb2cd3":"# scatterplot with distributions by colored by species\ng = sns.jointplot(x= 'body_mass_g', y = 'flipper_length_mm',\n                  data = df, \n                  color = 'm', height = 7, hue = 'species')","852fd643":"# regression plot\ng = sns.jointplot(x= 'bill_length_mm', y = 'flipper_length_mm',\n                  data = df, kind = 'reg', truncate = False,\n                  color = 'm', height = 7)","2ac69827":"# swarm plot can be used in place of a violin plot to show each observation\nax = plt.figure(figsize=(11,6))\nax = sns.swarmplot(data=df, x = 'body_mass_g', y = 'sex', hue = 'species')\nax.set(xlabel='Body Mass')\nax.set(title = 'Body Mass by Species and Sex')\nax.set(ylabel='')","e660b0d4":"# pairs of scatterplots and distributions\nsns.set_theme(style='white')\nsns.pairplot(df, hue='species')","b4209a8c":"# replace names with integers\nspecies_map = {'Adelie': 0, 'Gentoo': 1, 'Chinstrap': 2}\n\ndf2 = df.copy() # make copy\n\n# Map Species names as integers\ndf2['target'] = df2['species'].map(species_map) ","b81da29f":"# take one feature and convert to array\nX = np.array(df2['flipper_length_mm']).reshape(-1,1)\ny = (df2['target'] == 1).astype(np.int) # 1 if Gentoo, else 0","9f176fc5":"from sklearn.linear_model import LogisticRegression\n\n# specify model parameters and save to an object\nlog_reg = LogisticRegression(solver = 'lbfgs', random_state = 5)\n\n# Fit model to data\nlog_reg.fit(X, y)","a366f70f":"# Return evenly spaced numbers over a min and max interval of feature\nX_new = np.linspace(194, 220, 1000).reshape(-1, 1)\n# Make prediction on each value\ny_proba = log_reg.predict_proba(X_new)\ndecision_boundary = X_new[y_proba[:, 1]>=0.5][0]\n\n# Plot probabilities for flipper lengths\nplt.figure(figsize=(11, 5.5))\nplt.plot([decision_boundary, decision_boundary], [0, 1], \"k:\", linewidth=1.5)\nplt.plot(X_new, y_proba[:,1], \"g-\", linewidth = 2, label = \"Gentoo\")\nplt.plot(X_new, y_proba[:,0], \"b--\", linewidth = 2, label = \"Not Gentoo\")\nplt.title(\"Probabilities for Flipper Lengths\")\nplt.xlabel(\"Flipper Length\")\nplt.ylabel(\"Probability\")\nplt.legend(loc=\"center left\", fontsize=12.5)\nplt.text(205, .93, \"Decision Boundary\", fontsize = 9.5, bbox=dict(facecolor = 'red', alpha = 0.40))\nplt.show()","8ccf9328":"# Find the value for the decision boundary cutoff\ndecision_boundary = X_new[y_proba[:, 1]>=0.5][0]\nprint(\"For this model, the decision boundary for flipper length is:\", str(decision_boundary[0]))\n\nprint(\" -This means flipper lengths above this value will be classified as a Gentoo\")","38bb21ef":"df.columns","66e859b5":"# Convert our data to an array\ndf_array = np.array(df2)\nX = df_array[:, (2,3)] # Use features 'bill_length_mm', 'bill_depth_mm'\n\n# Dividing values by 10 for plotting only - normalization should be handled differently for final model\n# This simply keeps the transformations simpler\nX = X \/10\n\n# Define Model parameters\n# C is a regularization term; helps avoid overfitting model (solver = Limited Memory Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno algorithm)\nlog_reg = LogisticRegression(solver='lbfgs', C=10**5, random_state=5) \n\n# Fit model\nlog_reg.fit(X, y)","f7b60b6f":"# Return coordinate matrices from coordinate vectors.\nx0, x1 = np.meshgrid(\n    np.linspace(2.7, 6.3, 500).reshape(-1,1),\n    np.linspace(1, 2.2, 500).reshape(-1,1)\n    )\n\nX_new = np.c_[x0.ravel(), x1.ravel()] # concatenate arrays along second axis\n\ny_proba = log_reg.predict_proba(X_new) # predict using new data\n\n# plot data as shapes\nplt.figure(figsize=(17,11))\nplt.plot(X[y==0, 0], X[y==0, 1], \"bs\", markersize = 8)\nplt.plot(X[y==1, 0], X[y==1, 1], \"g^\", markersize = 9)\n\n# plot a contour map of decision boundaries\nzz = y_proba[:, 1].reshape(x0.shape)\ncontour = plt.contour(x0, x1, zz, cmap = plt.cm.brg)\n\n# Calculate decision boundary\nleft_right = np.array([2,7])\nboundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) \/ log_reg.coef_[0][1]\n\n# Define plot parameters\nplt.clabel(contour, inline=1, fontsize=14)\nplt.plot(left_right, boundary, \"k--\", linewidth=2)\nplt.text(3, 2, \"Not Gentoo\", fontsize=15, color=\"b\", ha=\"center\", bbox=dict(facecolor = 'blue', alpha = 0.10))\nplt.text(5.8, 1.4, \"Gentoo\", fontsize=15, color=\"g\", ha=\"center\", bbox=dict(facecolor = 'green', alpha = 0.10))\nplt.xlabel(\"Bill length\", fontsize=14)\nplt.ylabel(\"Bill Depth\", fontsize=14)\nplt.axis([2.7, 6.3, 1.25, 2.2])\nplt.title(\"Probability Cuttoffs for Gentoo Penguins\", fontsize = 18)\nplt.show()\n","497b161d":"# Same data as before \n# X = df_array[:, (2,1)] # select bill length and width; convert to an array\n\ny = np.array(df2['target'])\n# X = X\/10 # dividing all by 10 for demo and so the contour plot is more readable - normalization should be applied instead","ec8a37d1":"# define model params\nsoftmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n\n# fit model\nsoftmax_reg.fit(X, y)","cd3f6896":"# Return coordinate matrices from coordinate vectors.\nx0, x1 = np.meshgrid(\n    np.linspace(2.7, 6.3, 500).reshape(-1,1),\n    np.linspace(1, 2.2, 500).reshape(-1,1)\n    )\n\n# concatenate arrays along second axis\nX_new = np.c_[x0.ravel(), x1.ravel()] \n\n# prediction probabilties\ny_proba = softmax_reg.predict_proba(X_new)\n# class predictions\ny_predict = softmax_reg.predict(X_new)\n\n# reshape array\nzz1 =y_proba[:,1].reshape(x0.shape)\nzz = y_predict.reshape(x0.shape)","f7ac81dc":"# create markers\nplt.figure(figsize=(17, 11))\nplt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Chinstrap: Class 2\", markersize = 8)\nplt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Gentoo: Class 1\", markersize = 8)\nplt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Adelie: Class 0\", markersize = 8)\n\n# set color map\nfrom matplotlib.colors import ListedColormap\ncustom_cmap = ListedColormap(['#fafab0', '#9898ff','lightgreen'])\n\n# plot contour map\nplt.contourf(x0, x1, zz, cmap=custom_cmap, alpha = 0.35)\ncontour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\nplt.clabel(contour, inline=1, fontsize=14)\nplt.xlabel(\"Bill length\/10\", fontsize=14)\nplt.ylabel(\"Bill Depth\/10\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=14)\nplt.axis([2.7, 6.3, 1.25, 2.2])\nplt.title(\"Probability Cuttoffs for Gentoo Penguins\", fontsize = 18)\nplt.show()","ac82c2c3":"divisor = 10\nb_len = 50 \/ divisor\nb_depth = 18 \/ divisor\n\nprint(\"--------------------------------------\")\nprint(\"Original Values: \")\nprint(\" Bill Length = 50mm; Bill Depth = 18\")\nprint(\"\")\nprint(\"Plotting Coordinates:\")\nprint(\" Bill Length = \",b_len)\nprint(\" Bill Depth = \", b_depth)\nprint(\"--------------------------------------\")\nprint(\"With a bill length of 50, and depth of 18, the predicted class would be: \", \n      softmax_reg.predict([[b_len, b_depth]])[0])","8e7c6094":"# start with fresh copy of the data\ndf = penguins.copy()\ndf_strat = df.copy()\n# We will drop year since it does not provide useful information\ndf.drop(columns=['year','Unnamed: 0'],inplace = True)\n\n# list of features\nfeatures = list(df.columns)\ndf =df.reindex(columns=features)\nfeatures","4911ebb6":"from sklearn.model_selection import train_test_split, StratifiedShuffleSplit","8addd53d":"# get target variables and drop from frame\ny = df.pop('species')\nX = df.copy()","09e00983":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 5)\n\nprint(\"Training sample length: \", len(X_train))\nprint(\"Validation sample length: \", len(X_val))\nprint(\"----------------------------------\")\nprint(\"Training shape: \", X_train.shape)\nprint(\"Validation length: \", X_val.shape)\nprint('---------------------------')\nprint(\"Target sample length: \", y_train.shape)\nprint(\"Target sample length: \", y_val.shape)","9280a5f4":"y_val.value_counts() \/ len(y_val)","30c15a27":"y_train.value_counts() \/ len(y_train)","f793f292":"# for comparing the differences between simple random and strat\ntrain, test = train_test_split(df_strat, test_size = 0.2, random_state = 5)","11f9c904":"# define strat sampling parameters\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=5)\n\n# Loop through each record and perform split by species proportion\nfor train_index, test_index in split.split(df_strat, df_strat['species']):\n  strat_train_set = df_strat.loc[train_index]\n  strat_test_set = df_strat.loc[test_index]","f688fa3c":"strat_test_set['species'].value_counts() \/ len(strat_test_set)","127d6452":"strat_train_set['species'].value_counts() \/ len(strat_train_set)","8734d2ab":"# define a function that takes input data, and returns proportions of that category\ndef income_cat_proportions(data):\n    return data[\"species\"].value_counts() \/ len(data)","1361f565":"# Create a dataframe for visualization\ncompare_props = pd.DataFrame({\n    \"Overall\": income_cat_proportions(df_strat),\n    \"Stratified\": income_cat_proportions(strat_test_set),\n    \"Random\": income_cat_proportions(test),\n}).sort_index()\n\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] \/ compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] \/ compare_props[\"Overall\"] - 100","1a660ef5":"compare_props","2719cdec":"# copy data\nX_train_strat = strat_train_set.copy()\nX_test_strat = strat_test_set.copy()\n\n# pop target variables\ny_train_strat = X_train_strat.pop('species')\ny_test_strat = X_test_strat.pop('species')\n\nX_train_strat.drop(columns='year', inplace=True)\nX_test_strat.drop(columns='year', inplace=True)","0d127ba0":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_selector as selector","7bb8d4f3":"# define our numeric transformer\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\n# define our categorical transformer\ncat_transformer = Pipeline(steps=[ \n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('OneHot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Define our full pipeline\npreprocessor = ColumnTransformer(transformers=[ \n    ('num', numeric_transformer, selector(dtype_exclude=\"object\")),\n    ('cat', cat_transformer, selector(dtype_exclude=\"float64\"))\n])","ee89e4a6":"# fit then transform training data\nX_train = preprocessor.fit_transform(X_train_strat)\n\n# # transform test data\nX_test = preprocessor.transform(X_test_strat)\n\n# X_train = np.array(X_train)\n\n# X_train.toarray()\n# X_test.toarray()","8503c49c":"# import models\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB","e73064e5":"# List of model names\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\"]\n\n# List of classifiers and parameters\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    DecisionTreeClassifier(max_depth=7),\n    RandomForestClassifier(max_depth=10, n_estimators=10, max_features=5),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier()]","c1291d5f":"y_train = y_train_strat.copy()","3b91f708":"# convert labels to numeric representation\nspecies_map = {'Adelie': 0, 'Gentoo': 1, 'Chinstrap': 2}\ny_train = np.array(y_train.map(species_map))\ny_test = np.array(y_test_strat.map(species_map))\n\n# y_train = y_train.map(species_map)\n# y_test = y_test_strat.map(species_map)","7eb6dd6b":"# y= np.array(y_train)\n# y.todense()","86a8d5a6":"# iterate over classifiers, fit and return test set scores\nfor name, clf in zip(names, classifiers):\n  clf.fit(X_train, y_train)\n  print(name,':',clf.score(X_test, y_test))\n  print('---------')","b29f06a6":"clf_nearestN = KNeighborsClassifier(3)\nclf_rf = DecisionTreeClassifier(max_depth=7)\nclf_nn = MLPClassifier(alpha=1, max_iter=1000)\n\nclf_nearestN.fit(X_train, y_train)\nclf_rf.fit(X_train, y_train)\nclf_nn.fit(X_train, y_train)","eb1dfa02":"from sklearn.model_selection import cross_val_score\n\n# cross validation\nnearestN_scores = cross_val_score(clf_nearestN, X_train, y_train, cv = 3)  \nrf_scores = cross_val_score(clf_rf, X_train, y_train, cv = 3) \nnn_scores = cross_val_score(clf_nn, X_train, y_train, cv = 3) ","70327adc":"plt.figure(figsize=(10,6))\nplt.plot([1]*3, nearestN_scores, \".\")\nplt.plot([2]*3, rf_scores, \".\")\nplt.plot([3]*3, nn_scores, \".\")\n\nplt.boxplot([nearestN_scores, rf_scores, nn_scores], labels=(\"Nearest Neighbors\", \"Decision Tree\", \"ML Perceptron\"))\nplt.ylabel(\"Accuracy\", fontsize= 14)\nplt.show()","0a9f6847":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"_______________________________________________________________________\")\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n\n        print(\"_______________________________________________________________________\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n\n\nprint_score(clf_nearestN, X_train, y_train, X_test, y_test, train=True)\nprint_score(clf_nearestN, X_train, y_train, X_test, y_test, train=False)\nprint_score(clf_rf, X_train, y_train, X_test, y_test, train=True)\nprint_score(clf_rf, X_train, y_train, X_test, y_test, train=False)\nprint_score(clf_nn, X_train, y_train, X_test, y_test, train=True)\nprint_score(clf_nn, X_train, y_train, X_test, y_test, train=False)","e12461f2":"df = penguins.copy()\ndf.drop(columns='year', inplace=True)\ndf.drop(index=[3,271], inplace=True) # drop records inplace\ndf.reset_index(inplace=True, drop=True) # reset index and drop old index\n\ny = df.pop('species')\ny = np.array(y.map(species_map))","92d6855d":"from sklearn.decomposition import PCA","a90192ae":"# define our numeric transformer\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\n# define our categorical transformer\ncat_transformer = Pipeline(steps=[ \n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('OneHot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# define PCA and modeling\npca_pipe = PCA(n_components=3)\n\npreprocessor = ColumnTransformer(\n    transformers = [\n      ('num', numeric_transformer, selector(dtype_exclude=\"object\")),\n      ('cat', cat_transformer, selector(dtype_include='object'))])\n\n# Define our full pipeline\nclf_rf_final = Pipeline(steps=[ \n    ('preprocessor', preprocessor),\n    ('pca', pca_pipe),\n    ('classifier', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=2))\n])","129d06d4":"clf_rf_final.fit(df, y)","2a2cc232":"clf_rf_final.score(df, y)","8947c1ba":"Distribution of Sex is about even for each species so replacing with most common is not a good approach.\n\n**Lets see what the medians for each attribute grouped by `sex` and `species` are:**","906fc086":"### PLOT: Probabilities with 2 Features","99cb551e":"# Final Model","cae3e205":"**Short-listed Best Models**\n- Nearest Neighbors: 0.9855\n- Neural Net : 0.9855\n- Decision Tree: 0.9855\n\nLets perform some cross validation on these models to see how they perform as we introduce data variation","ed7ec29a":"- Each feature shows that male and female penguins differ in overall size, as well as sizes of each other feature.\n  - Males are generally larger then females.\n\n**Now Lets take a look at our missing values again:**","c2f6fff2":"# Modeling Examples\n\nUsing [Scikit-Learn](https:\/\/scikit-learn.org\/stable\/index.html)","5531ff31":"# Model Comparison","c063fcf9":"- Gentoo has larger Flipper lengths\n\n\n**Now lets compare the various species' attributes by sex:**","127ede11":"# Missing Values - KNN Imputer\n\n- Lets Fill the missing values in `sex` using KNN imputation.\n- First we need to convert the string values in sex attribute to numeric representations:","49d19172":"- As we saw earlier in the descriptive statistics, Body Mass and Flipper length have the strongest positive correlation among feature; that is easily seen in the plot above.\n\n- Its also worth noting the **nice seperation in flipper length distributions between Adelie and Gentoo** species; this will be a *good feature for training*.","5e36799f":"# Sampling\n- Simple Random Sampling","a31dac9d":"**Thank you for looking, I hope you enjoyed!**\n- Comments are suggestions are welcome, I am a student of data science and am always up for learning more!","40b2bd61":"**Next we should normalize the data to prevent any bias caused by differing magnitudes of each feature when performing imputation**\n\n- There are several ways to do this but I will demonstrate using `MinMaxScaler`\n- This puts all values between 0-1 ","33029d3d":"- We could do this for all groups but lets detour back to visualizations","2497260a":"# Stratified Sampling\n\n- However, if we do not have a balanced sample, we may wish to preserve the distribution in each split.\n- We can do this with stratified sampling.","ed0d4759":"**Positive Skew:**\n- Flipper length\n- Body Mass\n\n**Negative Skew:**\n- Bill Depth\n","aac56379":"- We see that the proportions of species classes are imbalanced in each set","d614bcfc":"### Plot Probability Contour Map","8b2e92ae":"- Gentoo has smaller Bill depth\n- Similar sizes between Chinstrap and Adelie, larger than Gentoo.\n- We have 1 outlier in Bill depth for the Adelie species","a16bef72":"- Seems like the continuous variables missing all come from the same two records.\n- Let's take a look at the sex variable","5bc2c11e":"**I add the imputed values back to the non-normalized data simply for visualization**\n- Later in the modeling process I will handle normalization again","0ea804e9":"- When dealing with uneven target distributions, we may want to consider Stratified Sampling to preserve distribution among training and testing sets; more on this later.","9f722139":"# Preprocess Pipelines","05158109":"# **Palmer Penguins Classification and EDA**","c9088697":"**Let's look for other patterns in the data**","853b2be7":"- Stratified sampling is much more representative of the data\n- The % error difference between proportions of species in each sample is much lower than that of simple random sample","5d7499b9":"## PLOT: Probabilities for 1 feature","4fa74c97":"# Models\n\n- A simple model will perform just fine for this dataset but lets demo several models for fun.","1fddbef8":"- Gentoo and Chinstrap species has similar Bill Lengths\n- Adelie generally has shorter bill lengths\n- Outlier in Bill length for the Gentoo species","d481bda0":"**Predict the penguin species with a Bill length of 50mm and depth of 18**\n- Remember we divided all records by 10 for easier plotting","91854115":"- **Now we can visualize the cutoff probabilities for each species easily and see which records the model has trouble with**\n","fb5175d5":"**Let's make some boxplots to explore the varying weights of the penguins:**","b8c06cd1":"# Full Machine Learning Project\n- Now I'll complete a full ML project using the penguins dataset to predict penguin species without the detours","b967e457":"# Logistic Regression - 2 Features","520456c3":"**Null:** In the population, male and female Adelie penguins have equal mean body weights (g).\n\n**Alternative:** In the population, male and female Adelie penguins have unequal mean body weights (g).\n\n- **Alpha:** 0.05 \n  - Reject the null if p-value < Alpha\n- **Test Statistic:** Sample Mean\n- **Test:** t-Test for means of two independent samples; unequal variances ","911f064e":"- **This suggests differing variances among the groups**","a6ad782f":"- Body Mass has a very strong positive correlation with flipper length\n- Also Flipper length and Bill length have a strong positive correlation\n\n**Let's look at the distribution of our target variables:**","555c9a78":"**Voila!** \n\nNow the proportions of classes are the same in each split","41b9ddce":"# Evaluation\n- Lets compare other classification metrics\n","f01480b1":"**First lets explore ways to deal with missing Values**\n\n- We have missing values in:\n  - **Numeric**\n    - `bill_length_mm`: float\n    - `bill_depth_mm`: float         \n    - `flipper_length_mm`: float     \n    - `body_mass_g`: float\n  - **Categorical:**           \n    - `sex`: string `{'male', 'female'}` \n    - `island`: string `{'Biscoe', 'Dream', 'Torgersen'}`            \n\n- We saw above a way to use KNN imputer, but this time I will just use a simple imputer for simplicity.","1e63904a":"# Logistic Regression - 1 Feature\n\n- Let's start with a model using only 1 feature, `flipper length`","bad24249":"- Biscoe island does not have Chinstrap species and is the only island to contain Gentoo.\n\n- Torgersen island are made up of only Adelie species\n  - We are missing features from a penguin from Torgersen\n  - It might be a good idea to replace these features based on the Adelie species\n\n- Each island contains some Adelie species","05ae9f60":"- According to the data, male and female penguins mostly differ in body mass across each species\n- However, we would need to perform a t-Test to test if this is significant\n\nLet's detour and see how this could be performed:","29653e51":"**Since each feature has differences in when grouped by sex and species, maybe we can impute the missing sex values based on the other numerical features:**","a9c7754a":"# Detour: Hypothesis Test - Independent Group Means","d4bb51cb":"**It appears that as the Decision treee observes variation in the training data, it has difficulty generalizing in this case**","088d42bb":"- It seems like **`species`** **Chinstrap** may be primarily located on Biscoe island and it seems them may also be natually larger birds.\n\nWe can also group data by island, and species count the records on each:","df1ac515":"\n**Lets look at the distributions after Cross-Validating:**","0f41e7c5":"- I'll drop record 3 and 271 since most of their data is missing\n- We will explore ways to deal with the rest of the missing values","2e804b37":"- Based on the two features, Bill length and bill width, our classifier can estimated the probabilities of new penguins.\n- Dashed line is the decision boundary for the classification.\n- You can see where the model made some misclassifications near the boundaries","6815fb2e":"- If we wish to do a simple split, we could use the following method.","5baa761d":"**This method does not preserve the representation between species classes as we noted earlier**\n\nLet's see what this means:","da6bf024":"# Making Predictions","b19769ce":"# Exploratory Data Analysis & Visualization\n\nUsing [Seaborn](https:\/\/seaborn.pydata.org\/index.html) \n- Now for some fun exploring the patterns of the different species of penguins and their features:","db702b23":"- Gentoo are heavier penguins\n- Similar weights between the others\n- We also see some outlier in body mass for Chinstrap","68c9b5a8":"# References\n**Data originally published in:**\n\n- Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081. https:\/\/doi.org\/10.1371\/journal.pone.0090081\n\n**Data citations:**\n\nAd\u00e9lie penguins:\n\n- Palmer Station Antarctica LTER and K. Gorman, 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Ad\u00e9lie penguins (Pygoscelis adeliae) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 5. Environmental Data Initiative. https:\/\/doi.org\/10.6073\/pasta\/98b16d7d563f265cb52372c8ca99e60f (Accessed 2020-06-08).\n\nGentoo penguins:\n\n- Palmer Station Antarctica LTER and K. Gorman, 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Gentoo penguin (Pygoscelis papua) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 5. Environmental Data Initiative. https:\/\/doi.org\/10.6073\/pasta\/7fca67fb28d56ee2ffa3d9370ebda689 (Accessed 2020-06-08).\n\nChinstrap penguins:\n\n- Palmer Station Antarctica LTER and K. Gorman, 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Chinstrap penguin (Pygoscelis antarcticus) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 6. Environmental Data Initiative. https:\/\/doi.org\/10.6073\/pasta\/c14dfcfada8ea13a17536e73eb6fbe9e (Accessed 2020-06-08).","03a49e7d":"# The Data\n\nData were collected and made available by [Dr. Kristen Gorman](htthttps:\/\/www.uaf.edu\/cfos\/people\/faculty\/detail\/kristen-gorman.phpps:\/\/) and the [Palmer Station, Antarctica LTER](https:\/\/pal.lternet.edu\/), a member of the [Long Term Ecological Research Network](https:\/\/lternet.edu\/).\n- There are **3 different species of penguins** in this dataset, collected from 3 islands in the **Palmer Archipelago, Antarctica.**","be99cc10":"**Categorical Data:**\n- `species`, `island`, `sex`; *nominal*\n- `year` *ordinal*\n\n**Numerical Data:**\n- `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g` ; *continuous*\n\n**Target Variable**\n- `species`\n\nWe also have some missing values to deal with:\n","a60dc899":"# Multinomial Regression \/ Softmax\n- Supports multiple classes\n- Predicts one class at a time (cannot be used to predict multiple people in one picture).\n- Cost function: Cross-entropy - penalizes the model when it estimates low probabilities for a class.\n- Use hyperparameter `multi_class = \"multinomial\"` to use softmax\n- Make sure you use a solver that can handle softmax such as `lbfgs`\n- Regularization is applied by default and can be controlled with `C`\n  - Higher `C` applies less regularization and lower applies more.","416cd24d":"# Load packages\n\n- Load some of the required packages for this notebook\n\n- If cell 3 does not run, uncomment and run the following `!pip` cell:","1c04d9f7":"- We could drop these variables, however lets try to see if we can impute them using another approach later on\n- Lets examine the data further to see if we can find a good method for this\n  - I'll drop the `year` column since it won't be very useful for this task","686788ab":"It seems Biscoe Island may have larger birds\n\n- We can create the same plot but replace `hue` with `species` to look into this more:"}}