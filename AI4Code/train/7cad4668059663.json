{"cell_type":{"73e07b00":"code","cf15824b":"code","c50e434e":"code","edae25cc":"code","e011bbba":"code","fbd5843b":"code","1fa38f15":"code","19b7903f":"code","6445628d":"code","50e62642":"code","eb91142a":"code","0001d0aa":"markdown"},"source":{"73e07b00":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n!pip install interpret -q\n\nfrom interpret import show\nfrom interpret.glassbox import ExplainableBoostingClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\nfrom sklearn.utils import resample\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nwarnings.filterwarnings(\"ignore\")","cf15824b":"dateparse = lambda dates: [pd.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') for d in dates]\ndf_ = pd.read_csv('\/kaggle\/input\/incidents\/public.csv',parse_dates=[0,], dtype={\"TIME_TYPE\":'category','WORK_NO':'category', \"WORK_DESC\": 'category', \"FUNC_CAT\": 'category', \"TOT_BRK_TM\": np.float16, \"EmpNo_Anon\": 'category'}, date_parser=dateparse)","c50e434e":"train_df, test = train_test_split(df_, test_size=0.2, random_state=42)\ndel df_","edae25cc":"wa_hols = [\n    '2009-01-01', '2009-01-26', '2009-03-02', '2009-04-10', '2009-04-11',\n    '2009-04-12', '2009-04-13', '2009-04-25', '2009-04-27', '2009-06-01',\n    '2009-09-28', '2009-12-25', '2009-12-26', '2009-12-28', '2010-01-01',\n    '2010-01-26', '2010-03-01', '2010-04-02', '2010-04-05', '2010-04-26',\n    '2010-06-07', '2010-09-27', '2010-12-25', '2010-12-26', '2010-12-27',\n    '2010-12-28', '2011-01-01', '2011-01-26', '2011-03-07', '2011-04-22',\n    '2011-04-25', '2011-04-26', '2011-06-06', '2011-10-28', '2011-12-25',\n    '2011-12-26', '2011-12-27', '2012-01-01', '2012-01-02', '2012-01-26',\n    '2012-03-05', '2012-04-06', '2012-04-09', '2012-04-25', '2012-06-04',\n    '2012-10-01', '2012-12-25', '2012-12-26', '2013-01-01', '2013-01-26',\n    '2013-03-04', '2013-03-29', '2013-04-01', '2013-04-25', '2013-06-03',\n    '2013-09-30', '2013-12-25', '2013-12-26', '2014-01-01', '2014-01-27',\n    '2014-03-03', '2014-04-18', '2014-04-19', '2014-04-21', '2014-04-25',\n    '2014-06-02', '2014-09-29', '2014-12-25', '2014-12-26', '2015-01-01',\n    '2015-01-26', '2015-03-02', '2015-04-03', '2015-04-04', '2015-04-06',\n    '2015-04-25', '2015-04-27', '2015-06-01', '2015-09-28', '2015-12-25',\n    '2016-01-01', '2016-01-26', '2016-03-07', '2016-03-25', '2016-03-28',\n    '2016-04-25', '2016-06-06', '2016-09-26', '2016-12-25', '2016-12-26',\n    '2016-12-27', '2017-01-01', '2017-01-02', '2017-01-26', '2017-03-06',\n    '2017-04-14', '2017-04-17', '2017-04-25', '2017-06-05', '2017-09-25',\n    '2017-12-25', '2017-12-26', '2018-01-01', '2018-01-26', '2018-03-05',\n    '2018-03-30', '2018-04-02', '2018-04-25', '2018-06-04', '2018-09-24',\n    '2018-12-25', '2018-12-26', '2019-01-01', '2019-01-28', '2019-03-04',\n    '2019-04-19', '2019-04-22', '2019-04-25', '2019-06-03', '2019-09-30',\n    '2019-12-25', '2019-12-26', '2020-01-01', '2020-01-27', '2020-03-02',\n    '2020-04-10', '2020-04-13', '2020-04-25', '2020-04-27', '2020-06-01',\n    '2020-09-28', '2020-12-25', '2020-12-26', '2020-12-28', '2021-01-01',\n    '2021-01-26', '2021-03-01', '2021-04-02', '2021-04-05', '2021-04-25',\n    '2021-04-26', '2021-06-07', '2021-09-27', '2021-12-25', '2021-12-26',\n    '2021-12-27', '2021-12-28'\n]\n\nwa_hols = pd.to_datetime(wa_hols, format=\"%Y-%m-%d\")\n\n\ninput_cols = [\n    'WORK_NO_NCDWN',\n    'WORK_DESC_Downtime', \n    'WORK_DESC_TCS: PB   Pole Broken\/Damaged',\n    'WORK_DESC_TCS: PP   Part Power',  \n    'WORK_DESC_TCS: Drop Out Fuse',\n    'time',\n    'month',\n    \"hour\",\n    'year', \n    \"day_of_year\",\n    'EmpNo_Anon_6-8',\n    'EmpNo_Anon_4-6',\n    'EmpNo_Anon_2-4_09',\n    'Work_no_2TW','Work_no_2Y0',\n    'Work_no3',\n    'Work_no0',\n    'overtime',\n    'normal_time',\n    'FUNC_CAT_O',\n    \"TOT_BRK_TM\",\n    \"holiday\"\n    'FUNC_CAT_S_sum',\n    'FUNC_CAT_N_sum',\n    'FUNC_CAT_O_std',\n    'overtime_std',\n    \"FUNC_CAT_S_std\",\n    'normal_time_std',\n]\n\n\ndef shuffle_df(df, random_seed=42):\n    return df.sample(frac=1, random_state=random_seed, replace=False)\n\ndef oversample(df, y_col, n=None, random_state=42):\n    \"\"\"Sample an equal amount from each class, with replacement\"\"\"\n    gs = [g for _, g in df.groupby(y_col)]\n    if n is None:\n        n = max(len(g) for g in gs)\n\n    # sample equal number of each group\n    gs = [g.sample(n, random_state=random_state, replace=True) for g in gs]\n    # concat, and shuffle\n    df = pd.concat(gs, 0)\n    df = shuffle_df(df)\n    return df\n\n\ndef preprocess(df, is_training = True):\n    \n    #df['Work_no_2'] = df.WORK_NO.apply(lambda x: x[:2])\n    df['Work_no0'] = df.WORK_NO.str[0]#.apply(lambda x: str(x)[1])\n    #df['Work_no0'] = df.WORK_NO.str[0].values\n    #df['Work_no-1'] = df.WORK_NO.apply(lambda x: str(x)[-1:])\n    #df['Work_no2'] = df.WORK_NO.apply(lambda x: str(x)[2:3])\n    df['Work_no3'] = df.WORK_NO.apply(lambda x: x[3] if len(x)>=4 else 'pp')\n    #df['Work_no4'] = df.WORK_NO.apply(lambda x: str(x)[4:5])\n    #df['Work_no5'] = df.WORK_NO.apply(lambda x: str(x)[5:6])\n    #df['Work_no6'] = df.WORK_NO.apply(lambda x: str(x)[6:7])\n    #df['Work_no7'] = df.WORK_NO.apply(lambda x: str(x)[7:8])\n    #df['Work_no_2-4'] = df.WORK_NO.apply(lambda x: str(x)[2:4])\n    #df['Work_no_4-6'] = df.WORK_NO.apply(lambda x: str(x)[4:6])\n    #df['Work_no_6-'] = df.WORK_NO.apply(lambda x: str(x)[6:])\n    \n    df['EmpNo_Anon_2-4'] = df.EmpNo_Anon.apply(lambda x: x[2:4])\n    df['EmpNo_Anon_2-4_09'] = df['EmpNo_Anon_2-4'] == '09'\n    #df['EmpNo_Anon_2-4_07'] = df['EmpNo_Anon_2-4'] == '07'\n    #df['EmpNo_Anon_2-4_06'] = df['EmpNo_Anon_2-4'] == '06'\n    #df['EmpNo_Anon_2-4_02'] = df['EmpNo_Anon_2-4'] == '02'\n    #df['EmpNo_Anon_2-4_90'] = df['EmpNo_Anon_2-4'] == '90'\n    #df['EmpNo_Anon_2-4_97'] = df['EmpNo_Anon_2-4'] == '97'\n    #df['EmpNo_Anon_2-4_10'] = df['EmpNo_Anon_2-4'] == '10'\n    \n    #df['Work_no_2TT'] = df.WORK_NO.apply(lambda x: x[:2]=='TT')\n    df['Work_no_2Y0'] = df.WORK_NO.apply(lambda x: x[:2]=='Y0')\n    df['Work_no_2TW'] = df.WORK_NO.apply(lambda x: x[:2]=='TW')\n    \n    df['EmpNo_Anon_4-6'] = df.EmpNo_Anon.apply(lambda x: x[4:6])\n\n    df['EmpNo_Anon_6-8'] = df.EmpNo_Anon.apply(lambda x: x[6:])\n    \n    df['WORK_NO_NSAFE'] = df.WORK_NO=='NSAFE'\n    df['WORK_NO_NCDWN'] = df.WORK_NO=='NCDWN'\n    \n    df['WORK_DESC_Downtime'] = df.WORK_DESC=='Downtime'\n    df['WORK_DESC_TCS: PB   Pole Broken\/Damaged'] = df.WORK_DESC=='TCS: PB   Pole Broken\/Damaged'\n    df['WORK_DESC_TCS: PP   Part Power'] = df.WORK_DESC=='TCS: PP   Part Power'\n    df['WORK_DESC_TCS: Drop Out Fuse'] = df.WORK_DESC=='TCS: Drop Out Fuse'\n\n    dt = df.Work_DateTime.dt\n    df['time'] = dt.date\n    df[\"hour\"] = dt.hour\n    df[\"day_of_week\"] = dt.dayofweek\n    df[\"day_of_year\"] = dt.dayofyear\n    df[\"month\"] = dt.month_name()\n    df[\"year\"] = dt.year\n\n    df[\"holiday\"] = dt.round(\"1D\").isin(wa_hols)\n    \n    df['FUNC_CAT_S'] = np.where(df.FUNC_CAT=='Support',1,0)\n    df['FUNC_CAT_O'] = np.where(df.FUNC_CAT=='Operational',1,0)\n    df['FUNC_CAT_N'] = np.where(df.FUNC_CAT=='Network or Asset',1,0)    \n    \n    df['overtime'] = np.where(df['TIME_TYPE']== 'Overtime', 1, 0)\n    df['normal_time'] = np.where(df.TIME_TYPE=='Normal Time', 1, 0)    \n\n    grouped = df[['time','FUNC_CAT_S', 'FUNC_CAT_N']].groupby(by=['time'], dropna=False).sum()\n    df = pd.merge(df, grouped, how=\"left\",on=[\"time\"],suffixes=('', '_sum'))\n    grouped = df[['time','FUNC_CAT_O','overtime',\"FUNC_CAT_S\",\"normal_time\"]].groupby(by=['time'], dropna=False).std()\n    df = pd.merge(df, grouped, how=\"left\",on=[\"time\"],suffixes=('', '_std'))\n    for x in ['FUNC_CAT_O_std','overtime_std',\"FUNC_CAT_S_std\", 'normal_time_std']:\n        df[x]=df[x].fillna(0)\n    if is_training:\n        return df[input_cols + ['incident']]\n    else:\n        return df[input_cols]","e011bbba":"target_columns = [\"incident\"]\n\ndef train(data):\n    df = preprocess(data)\n    df = oversample(df, \"incident\", n=25000)\n    \n    y_train = df[target_columns]\n    \n    X_train = df.drop(columns=target_columns)\n\n    model = ExplainableBoostingClassifier(random_state=42, interactions=2, learning_rate=0.00005, validation_size=0.2)\n    model.fit(X_train, y_train)\n    ebm_global = model.explain_global()\n    show(ebm_global)\n    \n    return model","fbd5843b":"model = train(train_df)\nTest_prep = preprocess(test, False)\ntarget_columns = [\"incident\"]\ntargets = test[target_columns]","1fa38f15":"ebm_local = model.explain_local(Test_prep[:25], targets[:25])\nshow(ebm_local)","19b7903f":"Test_prep.isnull().sum()","6445628d":"predictions=model.predict_proba(Test_prep)[:,1]","50e62642":"sns.set(font_scale=1.5)\nsns.set_color_codes(\"muted\")\n\nplt.figure(figsize=(10, 8))\nfpr, tpr, thresholds = roc_curve(targets, predictions, pos_label=1)\nlw = 2\nplt.plot(fpr, tpr, lw=lw, label='ROC curve ')\nplt.plot([0, 1], [0, 1])\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve')\nplt.savefig(\"ROC.png\")\nplt.show()","eb91142a":"roc_auc_score(targets, predictions)","0001d0aa":"0.7057267026981926"}}