{"cell_type":{"c9ab8929":"code","3a97b0a5":"code","1ff58f09":"code","29568139":"code","c6c0d089":"code","d8bf9270":"code","7b49b1ea":"code","2c93d8cb":"code","2d19aa2c":"code","a60ecfd8":"code","da627147":"code","86007fbe":"code","c6d33685":"code","2f4d8739":"code","8c66c3be":"code","a71c6e74":"code","c4ca5921":"code","99f44602":"code","80400852":"code","dd26c742":"code","a6f2ff88":"code","d6ca45d7":"code","616c1a93":"code","d23b2f2c":"code","d0cd85d7":"code","36cf0772":"code","8856e8ab":"code","74a61492":"code","e96fcb75":"code","4db1b90e":"code","6f392a32":"code","19cec21b":"code","99c62b9c":"code","4bf63e2d":"code","bf37f194":"code","4ebdc54c":"code","94fd6c60":"code","bfd1ae37":"code","111942ae":"code","177745ff":"code","c8eef5aa":"code","025b4d77":"code","2f5de955":"code","ca6d8ff2":"code","0fa6a70c":"code","3ffdbc81":"code","e5c96270":"code","1c279ac9":"code","cbc67a6f":"code","6eb90fe9":"code","ede94a37":"code","df070edb":"code","8ddaa9e8":"code","a4c618c0":"code","c42e7474":"code","05bc01eb":"code","eb722c93":"code","66922cfb":"code","c74112d8":"code","52454126":"code","67dac648":"code","537a4cbf":"code","fc7be8f9":"code","324654c0":"code","8c4e1456":"code","c5f5c56e":"code","0425024e":"code","26ec6e21":"code","ee24935b":"code","a0ff2955":"code","c8640645":"code","785c3aa0":"code","8bc4f57d":"code","7619030d":"markdown","208e4e99":"markdown","b3d62027":"markdown","a2c06ad1":"markdown","7a9716e2":"markdown","5f883977":"markdown","33057158":"markdown","b1d44f95":"markdown","d0185c9a":"markdown","55d8c429":"markdown","b37776ac":"markdown","68c02607":"markdown","f191f7c4":"markdown","175c4e77":"markdown","313c7fb1":"markdown","6ae68df5":"markdown","20b32cf4":"markdown","30d339c9":"markdown","7cf2d6f5":"markdown","bec88a7a":"markdown","9a451bf9":"markdown","fe3bf214":"markdown","15d2709b":"markdown","1f426f78":"markdown","b39c0fa6":"markdown","e4b43a18":"markdown","cae79598":"markdown","37770f10":"markdown","8e0ebee1":"markdown","2b4ddfdb":"markdown","1a0570fb":"markdown","e867c1fe":"markdown","e33972a9":"markdown","b7b64377":"markdown","73de3256":"markdown","251d437d":"markdown","2736f8b8":"markdown","5b2adb12":"markdown","3e2c2331":"markdown","792debce":"markdown","ac52b0c0":"markdown","b357db38":"markdown","da0830a9":"markdown","2f6fe697":"markdown","57150c61":"markdown"},"source":{"c9ab8929":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","3a97b0a5":"trn_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntst_data   = pd.read_csv('..\/input\/titanic\/test.csv')\ndatasets = {'train_data':trn_data, 'test_data':tst_data}\nfor data_name, data in datasets.items():\n    print(data_name)\n    display(data.head())\n    display(data.describe(include='all'))\n    display(data.isnull().sum().to_frame().T)","1ff58f09":"data_name, data = 'train_data', trn_data\nprint(data_name)\nf,ax=plt.subplots(1,2,figsize=(18,4))\ndata['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=data,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","29568139":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(data.groupby(['Sex','Survived'])['Survived'].count().to_frame())\n\nf,ax=plt.subplots(1,2,figsize=(18,4))\ndata[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex',hue='Survived',data=data,ax=ax[1])\nax[1].set_title('Sex:Survived vs Dead')\nplt.show()","c6c0d089":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(pd.crosstab(data.Pclass,data.Survived,margins=True)\n        .style.background_gradient(cmap='summer_r'))\n\nf,ax=plt.subplots(1,2,figsize=(18,4))\ndata['Pclass'].value_counts().plot.bar(ax=ax[0])\nax[0].set_title('Number Of Passengers By Pclass')\nax[0].set_ylabel('Count')\nsns.countplot('Pclass',hue='Survived',data=data,ax=ax[1])\nax[1].set_title('Pclass:Survived vs Dead')\nplt.show()","d8bf9270":"display(pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True).style.background_gradient(cmap='summer_r'))\n\nsns.pointplot('Pclass','Survived',hue='Sex',data=data)\nplt.show()","7b49b1ea":"data_name, data = 'train_data', trn_data\nprint(data_name)\nprint('Oldest Passenger was of:',data['Age'].max(),'Years')\nprint('Youngest Passenger was of:',data['Age'].min(),'Years')\nprint('Average Age on the ship:',data['Age'].mean(),'Years')\n\nf,ax=plt.subplots(1,2,figsize=(18,4))\nsns.violinplot(\"Pclass\", \"Age\", hue=\"Survived\", data=data, split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot(\"Sex\", \"Age\", hue=\"Survived\", data=data, split=True, ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","2c93d8cb":"for data_name, data in datasets.items():\n    print(data_name)\n    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')\n    display(pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r'))\n    display(data.groupby('Initial')['Age'].describe().T)\n\n    print(data_name, '(Age is null)')\n    data_null = data.loc[data['Age'].isnull(), :]\n    display(pd.crosstab(data_null.Initial, data_null.Sex).T.style.background_gradient(cmap='summer_r'))","2d19aa2c":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(data.groupby('Initial')['Survived'].describe().T)","a60ecfd8":"for data_name, data in datasets.items():\n    print(data_name)\n    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.').replace(\n        ['Capt','Col','Countess','Don','Dona','Dr','Jonkheer','Lady','Major','Master','Mlle','Mme','Ms'  ,'Rev','Sir'],\n        ['Capt','Col','Countess','Mr' ,'Mrs' ,'Dr','Jonkheer','Lady','Major','Master','Miss','Mrs','Miss','Rev','Mr'])\n    display(pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r'))\n    display(data.groupby('Initial')['Age'].describe().T)\n    data_null = data.loc[data['Age'].isnull(), :]\n    display(pd.crosstab(data_null.Initial, data_null.Sex).T.style.background_gradient(cmap='summer_r'))","da627147":"for data_name, data in datasets.items():\n    data['Age2'] = data['Age']\n    data.loc[(data.Age.isnull())&(data.Initial=='Dr'    ),'Age2'] = 42\n    data.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age2'] =  5\n    data.loc[(data.Age.isnull())&(data.Initial=='Mr'    ),'Age2'] = 32\n    data.loc[(data.Age.isnull())&(data.Initial=='Mrs'   ),'Age2'] = 36\n    data.loc[(data.Age.isnull())&(data.Initial=='Miss'  ),'Age2'] = 22\n    print(data_name, data.Age2.isnull().any())","86007fbe":"data_name, data = 'train_data', trn_data\nprint(data_name)\nf,ax=plt.subplots(1,2,figsize=(18,4))\ndata.loc[data['Survived']==0, 'Age2'].plot.hist(ax=ax[0], bins=20, color='red', edgecolor='black')\nax[0].set_title('Survived= 0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\ndata.loc[data['Survived']==1, 'Age2'].plot.hist(ax=ax[1], bins=20, color='green', edgecolor='black')\nax[1].set_title('Survived= 1')\nx2=list(range(0,85,5))\nax[1].set_xticks(x2)\n\nsns.catplot('Initial', 'Survived', data=data, col='Pclass', kind='bar')\nplt.show()","c6d33685":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(pd.crosstab(\n    [data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True)\n    .style.background_gradient(cmap='summer_r'))\n\nprint(data_name, '(Embarked is null)')\ndata_null = data.loc[data['Embarked'].isnull(), :]\ndisplay(data_null)","2f4d8739":"sns.pointplot('Embarked','Survived',data=data)\nfig=plt.gcf()\nfig.set_size_inches(5,3)\nplt.show()","8c66c3be":"f,ax=plt.subplots(2,2,figsize=(18,8))\nsns.countplot('Embarked',data=data,ax=ax[0,0])\nax[0,0].set_title('# Of Passengers Boarded')\nsns.countplot('Embarked',hue='Sex',data=data,ax=ax[0,1])\nax[0,1].set_title('Male-Female Split for Embarked')\nsns.countplot('Embarked',hue='Survived',data=data,ax=ax[1,0])\nax[1,0].set_title('Embarked vs Survived')\nsns.countplot('Embarked',hue='Pclass',data=data,ax=ax[1,1])\nax[1,1].set_title('Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2,hspace=0.5)\nplt.show()","a71c6e74":"sns.catplot('Pclass','Survived',hue='Sex',col='Embarked',data=data, kind='point')\nfig=plt.gcf()\nfig.set_size_inches(18,4)\nplt.show()","c4ca5921":"for data_name, data in datasets.items():\n    data['Embarked2'] = data['Embarked']\n    data['Embarked2'].fillna('S',inplace=True)\n    print(data_name, data.Embarked2.isnull().any())","99f44602":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r'))\n\nf,ax=plt.subplots(1,2,figsize=(18,4))\nsns.barplot('SibSp','Survived',data=data,ax=ax[0])\nax[0].set_title('SibSp vs Survived')\nsns.pointplot('SibSp','Survived', data=data, ax=ax[1])\nax[1].set_title('SibSp vs Survived')\nplt.show()","80400852":"pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')","dd26c742":"data_name, data = 'train_data', trn_data\nprint(data_name)\ndisplay(pd.crosstab(data.Parch,data.Pclass).style.background_gradient(cmap='summer_r'))\n\nf,ax=plt.subplots(1,2,figsize=(18,4))\nsns.barplot('Parch','Survived',data=data,ax=ax[0])\nax[0].set_title('Parch vs Survived')\nsns.pointplot('Parch','Survived',data=data,ax=ax[1])\nax[1].set_title('Parch vs Survived')\nplt.show()","a6f2ff88":"for data_name, data in datasets.items():\n    print(data_name)\n    print('Highest Fare was:',data['Fare'].max())\n    print('Lowest Fare was:',data['Fare'].min())\n    print('Average Fare was:',data['Fare'].mean())\n    display(data.groupby(['Pclass'])['Fare'].describe())\n    \n    f,ax=plt.subplots(1,3,figsize=(18,4))\n    sns.histplot(data.loc[data['Pclass']==1, 'Fare'], kde=True, ax=ax[0])\n    ax[0].set_title('Fares in Pclass 1')\n    sns.histplot(data.loc[data['Pclass']==2, 'Fare'], kde=True, ax=ax[1])\n    ax[1].set_title('Fares in Pclass 2')\n    sns.histplot(data.loc[data['Pclass']==3, 'Fare'], kde=True, ax=ax[2])\n    ax[2].set_title('Fares in Pclass 3')\n    plt.show()\n    \n    # sns.displot(data=data, x='Fare', kind='hist', kde=True, col='Pclass')\n    # plt.show()\n    \n    # display(data.loc[data['Fare']<1.0, :])\n    # display(data.loc[data['Fare']>400, :])","d6ca45d7":"for data_name, data in datasets.items():\n    display(data.loc[data['Fare'].isnull(), :])","616c1a93":"for data_name, data in datasets.items():\n    data['Fare2'] = data['Fare']\n    data.loc[(data['Fare2'].isnull())&(data['Pclass']==1), 'Fare2'] = 84.0\n    data.loc[(data['Fare2'].isnull())&(data['Pclass']==2), 'Fare2'] = 21.0\n    data.loc[(data['Fare2'].isnull())&(data['Pclass']==3), 'Fare2'] = 14.0","d23b2f2c":"for data_name, data in datasets.items():\n    display(data.loc[data['Fare2'].isnull(), :])","d0cd85d7":"data.columns.tolist()","36cf0772":"data_name, data = 'train_data', trn_data\nprint(data_name)\nsns.heatmap(data[['PassengerId', 'Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', \n                  'Age2', 'Embarked2', 'Fare2']]\n            .corr(),annot=True,cmap='RdYlGn',linewidths=0.2) \nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","8856e8ab":"# for data_name, data in datasets.items():\n#     print(data_name)\n#     data['Age_band']=0\n#     data.loc[                   data['Age2']<=16 ,'Age_band']=0\n#     data.loc[(16<data['Age2'])&(data['Age2']<=32),'Age_band']=1\n#     data.loc[(32<data['Age2'])&(data['Age2']<=48),'Age_band']=2\n#     data.loc[(48<data['Age2'])&(data['Age2']<=64),'Age_band']=3\n#     data.loc[ 64<data['Age2']                    ,'Age_band']=4\n#     display(data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer'))","74a61492":"data_name, data = 'train_data', trn_data\nn_bins = 8\nprint(data_name)\ndata['Age_band'], bins = pd.qcut(data['Age2'], n_bins, retbins=True)\nprint(bins)\ndata.groupby(['Age_band'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","e96fcb75":"for data_name, data in datasets.items():\n    data['Age_band'] = 0\n    for i in range(n_bins):\n        data.loc[(data['Age2']>bins[i])&(data['Age2']<=bins[i+1]),'Age_band'] = i","4db1b90e":"data_name, data = 'train_data', trn_data\nprint(data_name)\nsns.catplot('Age_band','Survived', hue='Sex', data=data,kind='point', col='Pclass')\nfig=plt.gcf()\nfig.set_size_inches(18,4)\nplt.show()","6f392a32":"for data_name, data in datasets.items():\n    print(data_name)\n    data['Family_Size'] = 0\n    data['Family_Size'] = data['Parch'] + data['SibSp'] #family size\n    data['Alone'] = 0\n    data.loc[data.Family_Size==0,'Alone']=1 #Alone","19cec21b":"data_name, data = 'train_data', trn_data\nprint(data_name)\nf,ax=plt.subplots(1,2,figsize=(18,4))\nsns.pointplot('Family_Size','Survived',data=data,ax=ax[0])\nax[0].set_title('Family_Size vs Survived')\nsns.pointplot('Alone','Survived',data=data,ax=ax[1])\nax[1].set_title('Alone vs Survived')\nplt.show()\n\nsns.catplot('Alone','Survived', hue='Sex', data=data,kind='point', col='Pclass')\nfig=plt.gcf()\nfig.set_size_inches(18,4)\nplt.show()","99c62b9c":"data_name, data = 'train_data', trn_data\nn_bins = 6\nprint(data_name)\ndata['Fare_cat'], bins = pd.qcut(data['Fare'], n_bins, retbins=True)\nprint(bins)\ndata.groupby(['Fare_cat'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","4bf63e2d":"for data_name, data in datasets.items():\n    data['Fare_cat'] = 0\n    for i in range(n_bins):\n        data.loc[(data['Fare2']>bins[i])&(data['Fare2']<=bins[i+1]),'Fare_cat'] = i","bf37f194":"data_name, data = 'train_data', trn_data\nprint(data_name)\nsns.catplot('Fare_cat','Survived',data=data,hue='Sex', col='Pclass', kind='point')\nplt.show()","4ebdc54c":"# for data_name, data in datasets.items():\n#     data['Sex2'     ] = data['Sex'     ].replace(['male','female'],[0,1])\n#     data['Embarked3'] = data['Embarked2'].replace(['S','C','Q'],[0,1,2])\n#     data['Initial2' ] = data['Initial' ].replace(\n#         ['Mr' ,'Mrs','Miss','Countess','Lady','Master','Dr','Capt','Col','Major','Rev','Jonkheer'],range(12))\n#     display(data.info())","94fd6c60":"# Initial\u30ab\u30e9\u30e0\u3092\u30ab\u30c6\u30b4\u30ea\u578b\u306b\u5909\u63db\ninitial_categories = set()\nfor data in datasets.values():\n    initial_categories |= set(data['Initial'].unique().tolist())\nfor data in datasets.values():\n    data['Initial2'] = pd.Categorical(\n        data['Initial'], categories=initial_categories)\n    display(data.info())","bfd1ae37":"# dummy\u5909\u6570\u5316\ndatasets2 = {}\ncolumns = ['Pclass', 'Initial2', 'Sex', 'Embarked2'] # dummy\u5909\u6570\u5316\u3059\u308b\u30ab\u30e9\u30e0\n\nfor data_name, data in datasets.items():\n    datasets2[data_name] = pd.get_dummies(\n        data, columns=columns, drop_first=True)\n    display(datasets2[data_name].info())","111942ae":"for data_name, data in datasets2.items():\n    datasets2[data_name] = data.drop(\n        ['PassengerId','Name','Age','Ticket','Fare','Cabin',\n         'Embarked', 'Initial','Age2', 'Fare2'],axis=1)\n    display(datasets2[data_name].info())","177745ff":"# for data_name, data in datasets2.items():\n#     print(data_name)\n#     sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n#     fig=plt.gcf()\n#     fig.set_size_inches(18,15)\n#     plt.xticks(fontsize=14)\n#     plt.yticks(fontsize=14)\n#     plt.show()","c8eef5aa":"for data_name, data in datasets2.items():\n    print(data_name)\n    display(data.isnull().sum())","025b4d77":"#importing all the required ML packages\nfrom sklearn.linear_model import LogisticRegression #logistic regression\nfrom sklearn import svm #support vector Machine\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.naive_bayes import GaussianNB #Naive bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix","2f5de955":"data = datasets2['train_data']\ntrn, vld = train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\ntrn_X = trn[trn.columns[1:]]\ntrn_Y = trn[trn.columns[:1]]\nvld_X = vld[vld.columns[1:]]\nvld_Y = vld[vld.columns[:1]]\nX     = data[data.columns[1:]]\nY     = data[data.columns[:1]]","ca6d8ff2":"model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\nmodel.fit(trn_X,trn_Y)\nprediction1=model.predict(vld_X)\nprint('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,vld_Y))","0fa6a70c":"model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\nmodel.fit(trn_X,trn_Y)\nprediction2=model.predict(vld_X)\nprint('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,vld_Y))","3ffdbc81":"model = LogisticRegression()\nmodel.fit(trn_X,trn_Y)\nprediction3=model.predict(vld_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction3,vld_Y))","e5c96270":"model=DecisionTreeClassifier()\nmodel.fit(trn_X,trn_Y)\nprediction4=model.predict(vld_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,vld_Y))","1c279ac9":"model=KNeighborsClassifier(n_neighbors=8) \nmodel.fit(trn_X,trn_Y)\nprediction5=model.predict(vld_X)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction5,vld_Y))","cbc67a6f":"a_index=list(range(1,11))\na=pd.Series()\nx=[0,1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(trn_X,trn_Y)\n    prediction=model.predict(vld_X)\n    a=a.append(pd.Series(metrics.accuracy_score(prediction,vld_Y)))\nplt.plot(a_index, a)\nplt.xticks(x)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()\nprint('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())","6eb90fe9":"model=GaussianNB()\nmodel.fit(trn_X,trn_Y)\nprediction6=model.predict(vld_X)\nprint('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction6,vld_Y))","ede94a37":"model=RandomForestClassifier(n_estimators=100)\nmodel.fit(trn_X,trn_Y)\nprediction7=model.predict(vld_X)\nprint('The accuracy of the Random Forests is',metrics.accuracy_score(prediction7,vld_Y))","df070edb":"from sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nxyz=[]\naccuracy=[]\nstd=[]\nclassifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\nfor model in models:\n    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n    cv_result = cv_result[~np.isnan(cv_result)]  # cv_result \u304b\u3089 nan \u3092\u524a\u9664\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\nnew_models_dataframe = pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \nnew_models_dataframe","8ddaa9e8":"plt.subplots(figsize=(12,6))\nbox=pd.DataFrame(accuracy,index=[classifiers])\nbox.T.boxplot()","a4c618c0":"new_models_dataframe['CV Mean'].plot.bar(width=0.8)\nplt.title('Average CV Mean Accuracy')\nfig=plt.gcf()\nfig.set_size_inches(8,5)\nplt.show()","c42e7474":"f,ax=plt.subplots(3,3,figsize=(12,10))\n\ny_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\nax[0,0].set_title('Matrix for rbf-SVM')\n\ny_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\nax[0,1].set_title('Matrix for Linear-SVM')\n\ny_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\nax[0,2].set_title('Matrix for KNN')\n\ny_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\nax[1,0].set_title('Matrix for Random-Forests')\n\n# \u4ee5\u524d\u52d5\u4f5c\u3057\u3066\u3044\u305f\u30b3\u30fc\u30c9\u304c\u30a8\u30e9\u30fc\u306b\u306a\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u3002\n# scikit-learn\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5f71\u97ff\u3057\u3066\u3044\u305d\u3046\u3002LogisticRegression()\u306e\u52d5\u304d\u304c\u5c11\u3057\u5909\u308f\u3063\u305f\u3002\n# y_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\n# cv=2\u306b\u3059\u308b\u3068\u306a\u305c\u304b\u901a\u308b\u3002\ny_pred = cross_val_predict(LogisticRegression(),X,Y,cv=2)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\nax[1,1].set_title('Matrix for Logistic Regression')\n\ny_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\nax[1,2].set_title('Matrix for Decision Tree')\n\ny_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\nax[2,0].set_title('Matrix for Naive Bayes')\n\nplt.subplots_adjust(hspace=0.2,wspace=0.2)\nplt.show()","05bc01eb":"from sklearn.model_selection import GridSearchCV\nC=[0.05, 0.1, 0.2, 0.4, 0.8, 1.6]\ngamma=[0.1, 0.2, 0.4, 0.8]\nkernel=['rbf','linear']\nhyper={'kernel':kernel,'C':C,'gamma':gamma}\ngd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True, n_jobs=-1)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_, 'kernel=', gd.best_estimator_.kernel)","eb722c93":"kfold = KFold(n_splits=10, random_state=22)\nmodel = svm.SVC(kernel='rbf', C=0.8, gamma=0.1)\ncross_val_score(model, X, Y, cv = kfold, scoring = \"accuracy\")\nprint(cv_result.mean(), cv_result.std())","66922cfb":"n_estimators=range(100,1000,100)\nhyper={'n_estimators':n_estimators}\ngd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True, n_jobs=-1)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","c74112d8":"kfold = KFold(n_splits=10, random_state=22)\nmodel = RandomForestClassifier(n_estimators=500, random_state=0)\ncross_val_score(model, X, Y, cv = kfold, scoring = \"accuracy\")\nprint(cv_result.mean(), cv_result.std())","52454126":"from sklearn.ensemble import VotingClassifier\nmodel=VotingClassifier(\n    estimators=[\n        ('KNN',KNeighborsClassifier(n_neighbors=10)),\n        ('RBF',svm.SVC(probability=True,kernel='rbf',C=0.5,gamma=0.1)),\n        ('RFor',RandomForestClassifier(n_estimators=500,random_state=0)),\n        ('LR',LogisticRegression(C=0.05)),\n        ('DT',DecisionTreeClassifier(random_state=0)),\n        ('NB',GaussianNB()),\n        ('svm',svm.SVC(kernel='linear',probability=True))], \n    voting='soft')\nmodel.fit(trn_X,trn_Y)\nprint('The accuracy for ensembled model is:',model.score(vld_X,vld_Y))\nresult = cross_val_score(model,X,Y, cv=10, scoring=\"accuracy\")\nprint('The cross validated score is', result.mean(), result.std())","67dac648":"from sklearn.ensemble import BaggingClassifier\nmodel = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\nmodel.fit(trn_X,trn_Y)\nprint('The accuracy for bagged KNN is:', model.score(vld_X, vld_Y))\nresult = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\nprint('The cross validated score for bagged KNN is:',result.mean(), result.std())","537a4cbf":"model = BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,n_estimators=100)\nmodel.fit(trn_X,trn_Y)\nprint('The accuracy for bagged Decision Tree is:', model.score(vld_X,vld_Y))\nresult = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\nprint('The cross validated score for bagged Decision Tree is:',result.mean(), result.std())","fc7be8f9":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\nresult = cross_val_score(ada, X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for AdaBoost is:',result.mean(), result.std())","324654c0":"from sklearn.ensemble import GradientBoostingClassifier\ngrad = GradientBoostingClassifier(n_estimators=500, random_state=0, learning_rate=0.1)\nresult = cross_val_score(grad, X, Y, cv=10, scoring='accuracy')\nprint('The cross validated score for Gradient Boosting is:',result.mean(), result.std())","8c4e1456":"import xgboost as xg\nxgboost = xg.XGBClassifier(n_estimators=900, learning_rate=0.1)\nresult = cross_val_score(xgboost, X, Y, cv=10, scoring='accuracy')\nprint('The cross validated score for XGBoost is:', result.mean(), result.std())","c5f5c56e":"n_estimators=[25, 40, 50, 75, 100, 200, 500, 1000]\nlearn_rate=[0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0]\nhyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\ngd=GridSearchCV(estimator=AdaBoostClassifier(), param_grid=hyper, verbose=True, n_jobs=-1)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_, 'n_estimators=', gd.best_estimator_.n_estimators)","0425024e":"ada=AdaBoostClassifier(n_estimators=200, learning_rate=0.05, random_state=0)\nresult=cross_val_predict(ada,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True,fmt='2.0f')\nplt.show()","26ec6e21":"f,ax=plt.subplots(2,2,figsize=(15,12))\nmodel=RandomForestClassifier(n_estimators=500,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\nax[0,0].set_title('Feature Importance in Random Forests')\nmodel=AdaBoostClassifier(n_estimators=200,learning_rate=0.05,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\nax[0,1].set_title('Feature Importance in AdaBoost')\nmodel=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\nax[1,0].set_title('Feature Importance in Gradient Boosting')\nmodel=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\nax[1,1].set_title('Feature Importance in XgBoost')\nplt.show()","ee24935b":"model = AdaBoostClassifier(n_estimators=200, learning_rate=0.05, random_state=0)\nmodel.fit(X, Y)\nprediction = model.predict(vld_X)\nprint(metrics.accuracy_score(prediction,vld_Y))","a0ff2955":"tst_X = datasets2['test_data']\nprediction = model.predict(tst_X)\nprediction.shape","c8640645":"subm_data = pd.DataFrame({'PassengerId':tst_data['PassengerId'], 'Survived':prediction})\ndisplay(subm_data.head())\ndisplay(subm_data.info())","785c3aa0":"subm_data.to_csv(\"submission_tt_model_03_20210928.csv\", index=False)","8bc4f57d":"#","7619030d":"### Survived","208e4e99":"## 6. Ensembling","b3d62027":"## 5. Hyper-Parameters Tuning","a2c06ad1":"### Cross Validation","7a9716e2":"### Confusion Matrix","5f883977":"### SVM","33057158":"### Age_band","b1d44f95":"### Sex","d0185c9a":"### 3-6 Gaussian Naive Bayes","55d8c429":"### 3-5 K-Nearest Neighbours(KNN)","b37776ac":"#### Hyper-Parameter Tuning for AdaBoost","68c02607":"### Initial","f191f7c4":"#### Bagged KNN","175c4e77":"### Embarked","313c7fb1":"### 3-1 Radial Support Vector Machines(rbf-SVM)","6ae68df5":"### Parch","20b32cf4":"#### Stochastic Gradient Boosting","30d339c9":"### 3-4 Decision Tree","7cf2d6f5":"### Age","bec88a7a":"## 3. Predictive Modeling","9a451bf9":"### SibSp","fe3bf214":"## 4. Evaluation","15d2709b":"### 3-3 Logistic Regression","1f426f78":"#### Feature Importance","b39c0fa6":"### 3-7 Random Forests","e4b43a18":"### Converting String Values into Numeric","cae79598":"### Random Forests","37770f10":"### Boosting","8e0ebee1":"### Fare","2b4ddfdb":"##### AdaBoost(Adaptive Boosting)","1a0570fb":"#### XGBoost","e867c1fe":"#### Bagged DecisionTree","e33972a9":"### Pclass","b7b64377":"### Correlation Between The Features","73de3256":"## 1. Exploratory Data Analysis(EDA)","251d437d":"# Titanic model_01","2736f8b8":"### Family_Size, Alone","5b2adb12":"## 7. Predict for test set data","3e2c2331":"### Overview","792debce":"#### Confusion Matrix for the Best Model","ac52b0c0":"### 6-2 Bagging","b357db38":"## 2. Feature Engineering and Data Cleaning","da0830a9":"### 3-2 Linear Support Vector Machine(linear-SVM)","2f6fe697":"### Fare_Range","57150c61":"### 6-1 Voting Classifier"}}