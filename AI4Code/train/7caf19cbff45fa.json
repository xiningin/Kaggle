{"cell_type":{"2474d4ea":"code","84c786c9":"code","7cc331b2":"code","f8f0c7fa":"code","f72e0db1":"code","d4764e0e":"code","b9d661f4":"code","194ac490":"code","c7db27cc":"code","dd27d750":"code","f97edc28":"code","423ce5a0":"code","72cd1449":"code","2b958439":"code","5610af74":"markdown","14102694":"markdown","5bff1745":"markdown","e7528695":"markdown","8c0012b6":"markdown","370d3239":"markdown","650db335":"markdown","d41fc5a7":"markdown","1908c5d4":"markdown","a7f7889c":"markdown","adbffe63":"markdown","5d42a18b":"markdown","3a1029aa":"markdown","461eb535":"markdown","409c16e5":"markdown"},"source":{"2474d4ea":"resize_w = 256  # \u753b\u50cf\u306e\u30ea\u30b5\u30a4\u30ba\u5e45\u3092\u6307\u5b9a\nresize_h = 256  # \u753b\u50cf\u306e\u30ea\u30b5\u30a4\u30ba\u9ad8\u3055\u3092\u6307\u5b9a\nchannel = 3  # \u753b\u50cf\u306e\u30ab\u30e9\u30fc\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u6307\u5b9a\n\ntest_size_rate = 0.100 # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092Train\/Test\u306b\u5206\u5272\u3059\u308b\u969b\u306e\u3001Test data\u306e\u6bd4\u7387\uff080.0\u301c1.0\uff09\n\nepochs = 200  # \u5b66\u7fd2\u56de\u6570\u3092\u6307\u5b9a\nn_batch = 8  # \u4e00\u5ea6\u306b\u307e\u3068\u3081\u3066\u5b66\u7fd2\u3059\u308b\u30c7\u30fc\u30bf\u6570\u3002\n             # \u5024\u304c\u5927\u304d\u3044\u3068\u5b66\u7fd2\u304c\u5b89\u5b9a\u3057\u65e9\u304f\u9032\u3080\u304c\u3001\u5927\u304d\u3059\u304e\u308b\u3068\u5404\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u304c\u5e73\u5747\u5316\u3055\u308c\u308b\u305f\u3081\u9006\u306b\u5b66\u7fd2\u304c\u9032\u307e\u306a\u3044\u3002\n             # (GPU\u8a08\u7b97\u901f\u5ea6\u306e\u95a2\u4fc2\u30672\u306en\u4e57\u3092\u6307\u5b9a\u3059\u308b\u306e\u304c\u304a\u3059\u3059\u3081)","84c786c9":"import cv2\n# \u753b\u50cf\u304c\u5927\u304d\u3044\u3068\u8a08\u7b97\u304c\u9045\u3044\u305f\u3081\u3001\u30ea\u30b5\u30a4\u30ba\u7e2e\u5c0f\ndef resize(tmp_image):\n    return cv2.resize(tmp_image , (resize_h, resize_w))\n\n# 4\u6b21\u5143\u914d\u5217\u5316()\u3000\ndef to_4d(tmp_image):\n    return tmp_image.reshape(1, resize_h, resize_w, channel)   \n\n# 256\u6bb5\u968e\u306e\u8272\u8abf\u30920.0~1.0\u306b\u3059\u308b\ndef normalize(tmp_image):\n    return tmp_image \/ 255.0\n\ndef adjust(img, alpha=1.0, beta=0.0):\n    # \u7a4d\u548c\u6f14\u7b97\u3092\u884c\u3046\u3002\n    dst = alpha * img + beta\n    return np.clip(dst, 0.0, 255.0)\n\n# \u753b\u50cf\u306e\u524d\u51e6\u7406\u4ed8\u304d\u30ed\u30fc\u30c9\ndef load_preprocessed_image(image_filepath):\n    tmp_image = cv2.imread(image_filepath)\n    tmp_image = resize(tmp_image)\n    tmp_image = adjust(tmp_image, 1.3, 40)    \n    tmp_image = normalize(tmp_image)\n    tmp_image = to_4d(tmp_image)\n\n    return tmp_image","7cc331b2":"import pandas as pd\nroot_dir = \"\/kaggle\/input\/mj1-anomaly-images-detection-challenge\/\"\ntrain_csv_filepath = root_dir + \"train.csv\"\n\n# \u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\ntrain_df = pd.read_csv(train_csv_filepath)","f8f0c7fa":"import numpy as np\nfrom keras.utils import np_utils\n\nimages = None\nfor fn in train_df['filename']:\n    image_filepath = root_dir + 'train\/' + fn\n    tmp_image = load_preprocessed_image(image_filepath)\n    if (images is None):\n        images = tmp_image\n    else:\n        images = np.vstack((images, tmp_image))\n\nanomaly_flags = np.array([flag for flag in train_df['anomaly']])\nanomaly_flags = np_utils.to_categorical(anomaly_flags, 2)","f72e0db1":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=test_size_rate, random_state=0)\n\nfor train_index, test_index in sss.split(images, anomaly_flags):\n    X_train = images[train_index]\n    y_train = anomaly_flags[train_index]\n    X_test = images[test_index]\n    y_test = anomaly_flags[test_index]","d4764e0e":"# over-sampling\u3092\u8a66\u3057\u307e\u3059\u3002\n\ntmp = pd.DataFrame(y_train[:, 1]).value_counts().values\nprint(tmp)\nlabel_ok_num = tmp[0]\nlabel_ng_num = tmp[1]\n\nwhile(label_ok_num != label_ng_num):\n    rand_index = np.random.randint(0, len(y_train))\n\n    label_is_ng = (y_train[rand_index, 1] == 1.0)\n    if label_is_ng:\n        X_train = np.vstack((X_train, [X_train[rand_index]]))\n        y_train = np.vstack((y_train, [y_train[rand_index]]))\n        label_ng_num += 1\n    print(label_ng_num, end='\\r')","b9d661f4":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=360)\n\ndatagen.fit(X_train)","194ac490":"import tensorflow as tf\n\n# a. \u3059\u3067\u306b\u5b66\u7fd2\u6e08\u307f\u306e\u30aa\u30fc\u30d7\u30f3\u306a\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u3092\u7528\u610f\n# a. Prepare an accurate open model that has already been trained.  \nbase_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    pooling='avg'\n)\n\n# b. \u5b66\u7fd2\u3057\u306a\u3044\u3088\u3046\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u8a2d\u5b9a \n# b. Set the parameters so that it does not learn.  \nbase_model.trainable = False\n\n# c. a\u306e\u4e0b\u306b\u300c2.\u51fa\u529b\u7d50\u679c\u3092\u63a8\u5b9a\u3059\u308b\u5c64\u300d\u3092\u8ffd\u52a0\n# c. Add \"2. Estimating the output result layer\" under a. \nmodel = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.Dense(1024, activation='relu'), \n    tf.keras.layers.Dense(128, activation='relu'),        \n    tf.keras.layers.Dense(2, activation='softmax')\n])\n\nmodel.summary()","c7db27cc":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","dd27d750":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=n_batch),\n                    steps_per_epoch=len(X_train) \/ n_batch,\n                    epochs=epochs,\n                    validation_data=(X_test, y_test))\n\ntrain_score = model.evaluate(X_train, y_train, verbose=0)\ntest_score = model.evaluate(X_test, y_test, verbose=0)\nprint('Train Loss:{0:.3f}'.format(train_score[0]))\nprint('Train accuracy:{0:.3}'.format(train_score[1]))\nprint('Test Loss:{0:.3f}'.format(test_score[0]))\nprint('Test accuracy:{0:.3}'.format(test_score[1]))","f97edc28":"import glob\nfrom pathlib import Path\n\ntest_images = None\ntest_filenames = None\nfor test_filepath in glob.glob('\/kaggle\/input\/mj1-anomaly-images-detection-challenge\/test\/*.png'):\n    tmp_image = load_preprocessed_image(test_filepath)\n    if (test_images is None):\n        test_images = tmp_image\n        test_filenames = [Path(test_filepath).name]\n    else:\n        test_images = np.vstack((test_images, tmp_image))\n        test_filenames.append(Path(test_filepath).name)","423ce5a0":"result_predict = model.predict(test_images)\nresult_predict = np.argmax(result_predict, axis=1)\nresult_predict","72cd1449":"submit_filepath = \"\/kaggle\/input\/mj1-anomaly-images-detection-challenge\/sample_submit.csv\"\nsubmit_df = pd.read_csv(submit_filepath, index_col=0)\n\nfor i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\n    \nsubmit_df.to_csv('result_submit.csv')\nsubmit_df[:20]","2b958439":"for i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\nsubmit_df.to_csv('result_submit.csv')\nprint(submit_df)","5610af74":"# \u25a0-- \u8ee2\u79fb\u5b66\u7fd2(Transfer Learning)\n\n\u8ee2\u79fb\u5b66\u7fd2\u306f\u5927\u307e\u304b\u306b\u3044\u3046\u3068\u3001\u300c\u3059\u3067\u306b\u5b66\u7fd2\u6e08\u307f\u306e\u30aa\u30fc\u30d7\u30f3\u306a\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u3092\u6d41\u7528\u3057\u3066\u3001\u7c21\u5358\u306b\u81ea\u5206\u306e\u76ee\u7684\u306e\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u4f5c\u308b\u65b9\u6cd5\u300d\u3067\u3059\u3002  \n\n\u5b66\u7fd2\u30e2\u30c7\u30eb\u306b\u306f\u300c1.\u5165\u529b\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u3092\u6349\u3048\u308b\u5c64\u300d\u3068\u300c2.\u51fa\u529b\u7d50\u679c\u3092\u63a8\u5b9a\u3059\u308b\u5c64\u300d\u304c\u3042\u308a\u3001  \n1\u306e\u5c64\u3092\u305d\u306e\u307e\u307e\u306b\u3057\u30662\u306e\u5c64\u3092\u81ea\u5206\u306e\u76ee\u7684\u306b\u5408\u3046\u3088\u3046\u306b\u5dee\u3057\u66ff\u3048\u308b\u3053\u3068\u3067\u8ee2\u79fb\u5b66\u7fd2\u3092\u5b9f\u73fe\u3057\u307e\u3059.  \n\n\u5177\u4f53\u7684\u306b\u306f  \na. \u3059\u3067\u306b\u5b66\u7fd2\u6e08\u307f\u306e\u30aa\u30fc\u30d7\u30f3\u306a\u9ad8\u7cbe\u5ea6\u306a\u30e2\u30c7\u30eb\u3092\u7528\u610f  \nb. \u5b66\u7fd2\u3057\u306a\u3044\u3088\u3046\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u8a2d\u5b9a  \nc. a\u306e\u4e0b\u306b\u300c2.\u51fa\u529b\u7d50\u679c\u3092\u63a8\u5b9a\u3059\u308b\u5c64\u300d\u3092\u8ffd\u52a0  \n\u3092\u884c\u3044\u307e\u3059\u3002\n\n---\n\nTransfer learning is, roughly speaking, \"a way to easily create a learning model for your own purposes by appropriating an open, highly accurate model that has already been trained.  \n\nA learning model has two layers: 1. a layer that captures the characteristics of the input data, and 2. a layer that estimates the output results.  \nTransfer learning can be achieved by leaving the first layer as it is and replacing the second layer with the one that suits your purpose.  \n\nSpecifically  \n**a. Prepare an accurate open model that has already been trained.  \nb. Set the parameters so that it does not learn.  \nc. Add \"2. Estimating the output result layer\" under a. ** \n","14102694":"## \u5224\u5b9a","5bff1745":"https:\/\/www.kaggle.com\/ruruamour\/sample-code2-augmentation  \n\u3053\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3067\u306f\u5c11\u3057\u7cbe\u5ea6\u304c\u4f38\u3073\u307e\u3057\u305f\u304c\u307e\u3060\u307e\u3060\u5224\u5b9a\u7cbe\u5ea6\u3092\u4e0a\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002  \n\u3053\u306eNotebook\u3067\u306f\u8ee2\u79fb\u5b66\u7fd2\u3068\u3044\u3046\u624b\u6cd5\u3092\u4f7f\u3063\u3066\u7c21\u5358\u306b\u9ad8\u7cbe\u5ea6\u306a\u6a5f\u68b0\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002  \n\n\uff08The above sample code shows a slight increase in accuracy, but the accuracy can still be improved.    \nThis Notebook uses a technique called transfer learning to easily create a highly accurate machine learning model.  \uff09","e7528695":"## \u7d50\u679c\u3092csv\u3067\u51fa\u529b","8c0012b6":"# \u524d\u6e96\u5099 - Preprocess code","370d3239":"## Preprocess5. Augmantation (\u753b\u50cf\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u5909\u5316\u3055\u305b\u3066\u3001\u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u30d0\u30ea\u30a8\u30fc\u30b7\u30e7\u30f3\u3092\u3082\u305f\u305b\u308b\uff09","650db335":"> Total params: 3,701,186  \n> Trainable params: 1,443,202  \n> Non-trainable params: 2,257,984  \n\n\u3068\u3044\u3046\u7d50\u679c\u306b\u306a\u308a\u307e\u3059\u3002  \nimagenet\u3068\u3044\u3046\u6c4e\u7528\u7684\u306a\u5927\u898f\u6a21\u753b\u50cf\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u304a\u308a\u3001\u69d8\u3005\u306a\u753b\u50cf\u306e\u7279\u5fb4\u304c\u629c\u304d\u51fa\u305b\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002  \n\u8ee2\u79fb\u5b66\u7fd2\u3092\u3059\u308b\u3053\u3068\u3067\u3001\u300c1.\u5165\u529b\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u3092\u6349\u3048\u308b\u5c64\u300d\u306b\u5fc5\u8981\u3060\u3063\u305f2,257,984\u500b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5b66\u7fd2\u3059\u308b\u624b\u9593\u304c\u7701\u3051\u307e\u3057\u305f\u3002\n\n--- \n\n\nThe results are shown above.\n\nWe have used imagenet, a general-purpose trained model of a large image dataset, which allows us to extract features from various images.  \nBy using transfer learning, we saved the time and effort of learning the 2,257,984 parameters required.","d41fc5a7":"## \u203b\u6ce8\n\n\u5b66\u7fd2\u6e08\u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9  \n> base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(  \n\n\u306e\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u306b\u306a\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002  \n\n\u305d\u306e\u5834\u5408\u306f\u3001\u3053\u306eNoteBook \u306e Internet \u8a2d\u5b9a\u3092\u30aa\u30f3\u306b\u3059\u308b\u3053\u3068\u3067\u3001\u554f\u984c\u304c\u89e3\u6d88\u3055\u308c\u307e\u3059\u3002  \n\u8a73\u7d30\u306f\u4e0b\u8a18\u306e\u30ea\u30f3\u30af\u3092\u3054\u78ba\u8a8d\u304f\u3060\u3055\u3044\u3002  \n\nhttps:\/\/stackoverflow.com\/questions\/47378542\/kaggle-could-not-download-resnet50-pretrained-model","1908c5d4":"## Preprocess1. \u753b\u50cf\u51e6\u7406\u95a2\u6570\u5b9a\u7fa9 - Image Processing Functions","a7f7889c":"## \u5b66\u7fd2 - Learning Process","adbffe63":"## Preprocess3. Train\/Test split","5d42a18b":"## Preprocess4. Over Sampling (\u4e0d\u5747\u8861\u306a\u5b66\u7fd2\u30c7\u30fc\u30bf\u6570\u3092\u63c3\u3048\u308b\u51e6\u7406\uff09","3a1029aa":"## Preprocess2. \u753b\u50cf\u3068\u30e9\u30d9\u30eb\u306e\u30ed\u30fc\u30c9 - Load Dataset","461eb535":"# \u8abf\u6574\u30d1\u30e9\u30e1\u30fc\u30bf - Config\n","409c16e5":"## \u5b66\u7fd2\u301c\u5224\u5b9a\u301c\u7d50\u679c\u51fa\u529b\u307e\u3067\u3002"}}