{"cell_type":{"a2c0f7b8":"code","8b29e214":"code","bd0adae1":"code","8b738ce0":"code","073a8a06":"code","b0d8e58a":"code","75648593":"code","40eac3a4":"code","dd25cd9a":"code","57224c70":"code","ea6b8ed5":"code","762fb592":"code","d977c1c9":"code","653da67e":"code","898f1646":"code","2683f866":"code","432347ee":"code","697b469c":"code","fdcad437":"code","40f6f32c":"code","dde2cd41":"code","404fa4ef":"code","caab3f07":"code","0ec6cbf2":"code","037a14e7":"code","9d91c19f":"code","8e014e83":"code","7c9b2201":"code","ddbfde17":"code","8de05da2":"code","bb896c56":"markdown","e2f01536":"markdown","d791650b":"markdown","6edfbfad":"markdown","d5287b7a":"markdown","dfcd03fd":"markdown"},"source":{"a2c0f7b8":"%matplotlib inline\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport os, ast, cv2\nimport matplotlib.pyplot as plt\nimport dask.dataframe    as dd\n\nimport pandas as pd\nimport numpy  as np\nfrom tqdm import tqdm\nfrom ast  import literal_eval","8b29e214":"DP_DIR    = '..\/input\/shuffle-csvs\/'\nINPUT_DIR = '..\/input\/quickdraw-doodle-recognition\/'\n\nBASE_SIZE = 256\nNCSVS     = 100\nNCATS     = 340\n\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)","bd0adae1":"#\n# \ub370\uc774\ud130\ub97c \uc77d\uc5b4\uc624\uae30 \uc804\n# dask.dataframe\uc73c\ub85c \ubd88\ub7ec\uc640\n# \uac04\ub2e8\ud558\uac8c \uad6c\uc870\ub9cc \ud655\uc778\n#\nddf = dd.read_csv('..\/input\/quickdraw-doodle-recognition\/train_simplified\/a*.csv')","8b738ce0":"ddf","073a8a06":"ddf.head(10)","b0d8e58a":"ddf.tail(10)","75648593":"# dask.compute \uc2dc \uba40\ud2f0\ud504\ub85c\uc138\uc2f1 \uc635\uc158\uc744 \uc8fc\uc5b4 \ube60\ub974\uac8c \uc5f0\uc0b0\ud560 \uc218 \uc788\uac8c\ub054\nrow = ddf.loc[1].compute(scheduler='processes', num_workers=4)\nrow.iloc[0]","40eac3a4":"stroke = row.iloc[0]['drawing']\ntitle  = 'Unrecognized ' + row.iloc[0]['word']","dd25cd9a":"print(stroke)\nprint(type(stroke))","57224c70":"print(literal_eval(stroke))\nprint(literal_eval(stroke)[0])\nprint(type(literal_eval(stroke)[0]))","ea6b8ed5":"#\n# stroke \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \uadf8\ub9b0\ub2e4\n# time_color\ub97c \uc774\uc6a9\ud558\uc5ec\n# \ud68d \uc21c\uc11c\uc640 \ubc29\ud5a5\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub3c4\ub85d\n#\ndef draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n    for t, stroke in enumerate(raw_strokes):\n        for i in range(len(stroke[0]) - 1):\n            color = 255 - min(t, 10) * 13 if time_color else 255\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n    if size != BASE_SIZE:\n        return cv2.resize(img, (size, size))\n    else:\n        return img\n\nplt.imshow(draw_cv2(literal_eval(stroke)), cmap='bone')\nplt.title(title)\nplt.show()","762fb592":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers  import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers  import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models  import Sequential, load_model\nfrom tensorflow.keras.callbacks    import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers   import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input","d977c1c9":"def apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n    score = 0.0\n    num_hits = 0.0\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits \/ (i + 1.0)\n    if not actual:\n        return 0.0\n    return score \/ min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","653da67e":"#\n# \uc774\ubbf8\uc9c0 \ub370\uc774\ud130 \uc0dd\uc131 \ubc0f \uc804\ucc98\ub9ac\n# \uacfc\uc801\ud569\uc744 \ud53c\ud558\uae30\uc704\ud574 \uc81c\uacf5\ub41c \ud559\uc2b5\uc14b\uc744 \uc154\ud50c\ud558\uc5ec \uc0ac\uc6a9\ud558\uc600\ub2e4\n# \ndef image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n    while True:\n        for k in np.random.permutation(ks):\n            \n            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing'] = df['drawing'].apply(ast.literal_eval)\n                x = np.zeros((len(df), size, size, 1))\n                \n                for i, raw_strokes in enumerate(df.drawing.values):\n                    x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw,\n                                             time_color=time_color)\n                x = preprocess_input(x).astype(np.float32)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield x, y\n\ndef df_to_image_array_xd(df, size, lw=6, time_color=True):\n    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n    x = np.zeros((len(df), size, size, 1))\n    for i, raw_strokes in enumerate(df.drawing.values):\n        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n    x = preprocess_input(x).astype(np.float32)\n    return x","898f1646":"STEPS = 1000\nEPOCHS = 20\nsize = 80\nbatchsize = 300","2683f866":"# \ub9c8\uc9c0\ub9c9 \ud30c\uc77c\uc744 valid set\uc73c\ub85c \uc0ac\uc6a9\nvalid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=34000)\nx_valid = df_to_image_array_xd(valid_df, size)\ny_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\nprint(x_valid.shape, y_valid.shape)","432347ee":"train_datagen = image_generator_xd(size=size, batchsize=batchsize, ks=range(NCSVS - 1))","697b469c":"# \ud559\uc2b5\uc14b \ud655\uc778\nx, y = next(train_datagen)\nn = 3\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(9, 9))\nfor i in range(n**2):\n    ax = axs[i \/\/ n, i % n]\n    (-x[i]+1)\/2\n    ax.imshow((-x[i, :, :, 0] + 1)\/2, cmap=plt.cm.bone)\n    ax.axis('off')\nplt.tight_layout()\nplt.show();","fdcad437":"model = MobileNetV2(input_shape=(size, size, 1), alpha=1., weights=None, classes=NCATS)\nmodel.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\nmodel.summary()","40f6f32c":"filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\ncallbacks = [EarlyStopping(patience=5, verbose=0), ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n                      min_delta=0.005, mode='max', cooldown=3, verbose=1), checkpoint\n]\nhists = []\nhist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n    callbacks = callbacks\n)\nhists.append(hist)","dde2cd41":"valid_predictions = model.predict(x_valid, batch_size=128, verbose=1)\nmap3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions).values)\nprint('Map3: {:.3f}'.format(map3))","404fa4ef":"y_loss  = hist.history['loss']\n\nx_len = np.arange(len(y_loss))\nplt.plot(x_len, y_loss, marker='.',  c='blue', label='Trainset_loss')\n\nplt.legend(loc='upper right')\nplt.grid()\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()","caab3f07":"model_conv1D = load_model('..\/input\/quickdraw\/model_cnn_1.hdf5', custom_objects = {'top_3_accuracy':top_3_accuracy})\nprint(model_conv1D.summary())\n\ndel model_conv1D","0ec6cbf2":"model_conv2D_m = load_model('..\/input\/quickdraw\/model_cnn_2.hdf5', custom_objects = {'top_3_accuracy':top_3_accuracy})\nprint(model_conv2D_m.summary())\n\ndel model_conv2D_m","037a14e7":"del train_datagen, valid_predictions, hists, x_valid, y_valid","9d91c19f":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\ntest.head()\nx_test = df_to_image_array_xd(test, size)\nprint(test.shape, x_test.shape)","8e014e83":"test_predictions = model.predict(x_test, batch_size=128, verbose=1)","7c9b2201":"top3 = preds2catids(test_predictions)\ntop3.head()\ntop3.shape","ddbfde17":"cats = list_all_categories()\nid2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\ntop3cats = top3.replace(id2cat)\ntop3cats.head()\ntop3cats.shape","8de05da2":"test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\nsubmission = test[['key_id', 'word']]\nsubmission.to_csv('submission.csv'.format(int(map3 * 10**4)), index=False)\nsubmission.head()\nsubmission.shape","bb896c56":"**### \ud559\uc2b5 \uacb0\uacfc \ud655\uc778**","e2f01536":"2. Conv2D\ub97c merge\ud558\uc5ec \ubd84\ub958\ud558\ub294 \ubc29\uc2dd","d791650b":"cf) \ub2e4\ub978 \ubaa8\ub378\n\n1. stroke\uc758 1\ucc28\uc6d0 \ud615\ud0dc\ub85c \ubcc0\ud658\ud558\uace0 \ucc28\ubd84\ud558\uc5ec \ubd84\uc11d\ud558\ub294 \ubc29\uc2dd","6edfbfad":"**### \uc804\ucc98\ub9ac \ubc0f \ud559\uc2b5**\n\nCNN\uacfc RNN\uc744 \uae30\ubc18\uc73c\ub85c \uc5ec\ub7ec \ubaa8\ub378\uc744 \uc124\uacc4\ud558\uc5ec\n\n\uc815\ud655\ub3c4, \uc5f0\uc0b0\ub7c9, \uc18d\ub3c4\ub4f1\uc744 \ube44\uad50\ud558\uc600\uc744 \ub54c \uac00\uc7a5 \uba54\ubaa8\ub9ac \ubd80\ub2f4\uc774 \uc801\uc73c\uba70 \ube44\uad50\uc801 \ube60\ub978 \ud559\uc2b5\uc774 \uac00\ub2a5\ud588\ub358 MobileNetV2\ub97c \uc120\ud0dd\ud558\uc600\ub2e4.\n\n","d5287b7a":"**### \ub370\uc774\ud130 \ud655\uc778**","dfcd03fd":"**### \ud14c\uc2a4\ud2b8\uc14b \uc608\uce21**"}}