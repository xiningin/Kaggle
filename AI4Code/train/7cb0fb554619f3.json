{"cell_type":{"5367c77c":"code","cee50cf1":"code","d18df836":"code","1b102c23":"code","a530afb7":"code","8fc721f6":"code","5eee8540":"code","1e2fc705":"code","ef981333":"code","1bce3686":"code","f56440b4":"code","ccebf1d1":"code","f2dad0e0":"code","28547858":"code","347032fb":"code","d2d0d75a":"code","2f6a2a01":"code","80d5e560":"code","46d4ed8c":"code","26ae7d0a":"code","793c7e32":"code","88c30841":"code","dc2c1f0a":"code","52ae71ac":"markdown","c4b260b1":"markdown","3c987b11":"markdown","cb86821e":"markdown","c5a42ee2":"markdown","de82a840":"markdown","47bb5e27":"markdown","ca5c8055":"markdown","d131c29c":"markdown","993239ee":"markdown","15d009e1":"markdown","b82e926c":"markdown","6c10ac8c":"markdown","54468c13":"markdown","6628b41d":"markdown","b726fce6":"markdown","5225b7ad":"markdown","c41625f4":"markdown","6de671d9":"markdown","5397c5c1":"markdown","83fe9b27":"markdown"},"source":{"5367c77c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nfrom keras.models import Sequential,Model\nfrom tensorflow.python.keras.preprocessing.image import load_img,ImageDataGenerator,img_to_array\nfrom tensorflow.python.keras.layers import Conv2D, MaxPooling2D,Activation,Dropout,BatchNormalization,Flatten,Dense\nfrom keras.applications import VGG19,ResNet50,VGG16\nfrom keras.optimizers import SGD, RMSprop , Adam\n\nimport numpy as np\nimport cv2","cee50cf1":"Path='\/kaggle\/input\/kermany2018\/oct2017\/OCT2017\/'\nbase_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","d18df836":"validation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n","1b102c23":"test_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","a530afb7":"train_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))","8fc721f6":"def image_show(x):\n    for i in range(3):\n        # define subplot\n        plt.subplot(330 + 1 + i)\n        # generate batch of images\n        batch = x.next()\n        # convert to unsigned integers for viewing\n        image = batch[0].astype('uint8')\n        # plot raw pixel data\n        plt.imshow(image)\n        # show the figure\n    plt.show()","5eee8540":"# Shear Image : Shear tool is used to shift one part of an image, \n#a layer, a selection or a path to a direction and the other part to the opposite direction.\ntrain_datagen_shear = ImageDataGenerator(\n    shear_range=0.8,\n    )\n\n#Zoom\ntrain_datagen_zoom = ImageDataGenerator(\n    zoom_range=0.5,\n    horizontal_flip=True)\n\n#Flipping the Image \ntrain_datagen_flip = ImageDataGenerator(\n    horizontal_flip=True,\n    vertical_flip=True)\n\n\n\n","1e2fc705":"image=load_img('..\/input\/kermany2018\/OCT2017 \/test\/CNV\/CNV-1016042-1.jpeg')\nf=img_to_array(image)\nsample=np.expand_dims(f,axis=0)\nprint('Image size',sample.shape)\n","ef981333":"print(\"Shear image\")\ntrain_generator_shear=train_datagen_shear.flow(sample,batch_size=1)\nshears=image_show(train_generator_shear)","1bce3686":"print(\"Zoom image\")\ntrain_generator_zoom=train_datagen_zoom.flow(sample,batch_size=1)\nshears=image_show(train_generator_zoom)","f56440b4":"print(\"FLIP image\")\ntrain_generator_flip=train_datagen_flip.flow(sample,batch_size=1)\nshears=image_show(train_generator_flip)","ccebf1d1":"img_height=224\nimg_width=224\nbatch_size=64","f2dad0e0":"def create_model(lr,ep,bt):\n    print('Learning Rate',lr)\n    print('Number of Epochs',ep)\n    print(\"Batch Number\",bt)\n    \n    \n    train_datagen = ImageDataGenerator(rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n    train_generator = train_datagen.flow_from_directory(train_dir,target_size=(img_height,img_width),batch_size=bt,class_mode='categorical',subset='training')\n\n    test_generator = train_datagen.flow_from_directory(\n        test_dir,\n        target_size=(img_height,img_width),\n        batch_size=bt,\n        class_mode='categorical')\n\n    validation_generator = train_datagen.flow_from_directory(\n        validation_dir, \n        target_size=(img_height,img_width),\n        batch_size=bt,\n        class_mode='categorical')\n    \n    \n    base_model1 =  ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n    model = Sequential()\n    \n    model.add(Flatten(input_shape=base_model1.output_shape[1:]))\n    model.add(Dense(1024))\n    model.add(Activation('relu'))\n    model.add(Dense(512))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(4))\n    model.add(Activation('softmax'))\n    \n    model = Model(inputs=base_model1.input, outputs=model(base_model1.output))\n    #model = Model(inputs=base_model2.input, outputs=model(base_model2.output))\n\n    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=lr, momentum=0.9),metrics=['accuracy'])\n    #model.summary()\n    model.fit_generator(generator=train_generator,\n                    steps_per_epoch=train_generator.samples\/\/800,\n                    validation_data=validation_generator,\n                    validation_steps=validation_generator.samples,\n                    epochs=ep\n                    )","28547858":"#batchs=[32,64]\n#epochs=[10,20,45]\n\nlearn=[0.01,0.001,0.0001]\n''''\nfor i in range(len(batchs)):\n    for j in range(len(learn)):\n            BT=batchs[i]\n            tune=create_model(learn[j],3,BT)\ncreate_model(0.01,1,64)\n'''\n\n\n\n\n\n","347032fb":"\n\n\n##DATA AUGMENTATION\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n#IMAGE FLOW FOR TRAINING \ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height,img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training')\n\n#IMAGE FLOW FOR TESTING \ntest_generator = train_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height,img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n#IMAGE FLOW FOR VALIDATION \nvalidation_generator = train_datagen.flow_from_directory(\n    validation_dir, \n    target_size=(img_height,img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n\n","d2d0d75a":"base_model2 =  ResNet50(weights='imagenet', include_top=False, input_shape=(img_height,img_width, 3))\n\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=base_model2.output_shape[1:]))\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(4))# Number of classes \nmodel.add(Activation('softmax'))\n\n\n\nmodel = Model(inputs=base_model2.input, outputs=model(base_model2.output))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001, momentum=0.9),\n              metrics=['accuracy'])\n#model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n\nmodel.summary()","2f6a2a01":"resnet50_history=model.fit_generator(generator=train_generator,\n                    steps_per_epoch=train_generator.samples\/\/800,\n                    validation_data=validation_generator,\n                    validation_steps=test_generator.samples\/\/16,\n                    epochs=20,\n                    verbose=1,\n                    max_queue_size=100,\n                    workers = 4 ,\n                    use_multiprocessing=True,\n                    )","80d5e560":"plt.plot(resnet50_history.history['loss'],'r')\nplt.plot(resnet50_history.history['val_loss'],'b')\n\n","46d4ed8c":"plt.plot(resnet50_history.history['accuracy'],'r')\nplt.plot(resnet50_history.history['val_accuracy'],'b')","26ae7d0a":"model.evaluate(test_generator)\n\ntest_steps_per_epoch = np.math.ceil(test_generator.samples \/ test_generator.batch_size)\n\npredictions = model.predict(test_generator, steps = test_steps_per_epoch)\n\npredicted_classes = np.argmax(predictions, axis=1)\n#print(predicted_classes)","793c7e32":"true_classes = test_generator.classes\n#print(true_classes)\nclass_labels = list(test_generator.class_indices.keys()) \n#print(class_labels)","88c30841":"from sklearn.metrics import classification_report\n\nreport = classification_report(true_classes, predicted_classes, target_names = class_labels)\nprint(report) ","dc2c1f0a":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncm = confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize=(8,8))\nsns.heatmap(cm, fmt='.0f', annot=True, linewidths=0.2, linecolor='purple')\nplt.xlabel('predicted value')\nplt.ylabel('Truth value')\nplt.show()","52ae71ac":"***PLEASE UPVOTE THE NOTEBOOK ***\n\n\n***PLEASE ALSO SHARE THOUGHTS AND SUGGESTION IN THE COMMENT SECTION ***\n\n\n***STAY SAFE STAY HEALTHY ***\n\n***JAI BHARAT***","c4b260b1":"We cannot try to maximize both precision and recall because there is a trade-off between them. Increasing precision decreases recall and vice versa. We can aim to maximize precision or recall depending on the task. For an email spam detection model, we try to maximize precision because we want to be correct when an email is detected as spam. We do not want to label a normal email as spam (i.e. false positive). On the other hand, for a tumor detection task, we need to maximize recall because we want to detect positive classes as much as possible.\n\nThere is another measure that combines precision and recall into a single number and that is F1 score.","3c987b11":"***\u201chyperparameter tuning is choosing a set of optimal hyperparameters for a learning algorithm\u201d.***","cb86821e":"Reference Link for more understanding : https:\/\/towardsdatascience.com\/how-to-best-evaluate-a-classification-model-2edb12bcc587","c5a42ee2":"***RESNET MODEL***","de82a840":"Hyper Parameter tune : Learning rate and batch in VGG19","47bb5e27":"****Hyper Parameter Tunning *****","ca5c8055":"Learning rate =0.001 , Batch =64 will provide Good Result . After Running the Create Model Function.","d131c29c":"***Precision***","993239ee":" Resnet short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully. Prior to ResNet training very deep neural networks was difficult due to the problem of vanishing gradients.\n\nAlexNet, the winner of ImageNet 2012 and the model that apparently kick started the focus on deep learning had only 8 convolutional layers, the VGG network had 19 and Inception or GoogleNet had 22 layers and ResNet 152 had 152 layers. In this blog we will code a ResNet-50 that is a smaller version of ResNet 152 and frequently used as a starting point for transfer learning.\n","15d009e1":"**Data Augmentation******","b82e926c":"*****Precision = TP\/(TP+FP)*****","6c10ac8c":"Data augmentation is a technique to artificially create new training data from existing training data. This is done by applying domain-specific techniques to examples from the training data that create new and different training examples.\n\nImage data augmentation is perhaps the most well-known type of data augmentation and involves creating transformed versions of images in the training dataset that belong to the same class as the original image.\n\nTransforms include a range of operations from the field of image manipulation, such as shifts, flips, zooms, and much more.","54468c13":"***PLOT OF RESNET50***","6628b41d":"Precision measures how good our model is when the prediction is positive.Precision measures how good our model is when the prediction is positive.","b726fce6":"*****Recall = TP\/(TP+FN)*****","5225b7ad":"Recall measures how good our model is at correctly predicting positive classes.\nThe focus of recall is actual positive classes. It indicates how many of the positive classes the model is able to predict correctly.","c41625f4":"****Model Classification Report ****","6de671d9":"****Recall****","5397c5c1":"    True positive (TP): Predicting positive class as positive (ok)\n    False positive (FP): Predicting negative class as positive (not ok)\n    False negative (FN): Predicting positive class as negative (not ok)\n    True negative (TN): Predicting negative class as negative (ok)","83fe9b27":"***UNDERSTANDING***"}}