{"cell_type":{"74f148a6":"code","e95ddd6e":"code","294581fe":"code","dedde024":"code","4f7c6465":"code","41c7caf6":"code","f069da4b":"code","29541e1b":"code","3e6a16cb":"code","b14fed74":"code","6651d4ca":"code","622765f1":"code","a04d421b":"code","1bd9e96d":"code","1774dbdc":"code","a0d2bbfd":"code","87ad8c83":"code","fe187ad3":"code","4e5739d8":"code","e600f88d":"code","854d6914":"code","f8e2d0fd":"code","4c6af6d9":"code","210cb7bb":"code","26a33e88":"code","f8db9589":"code","b9b726e0":"code","0d79f636":"markdown","42933099":"markdown","35fe187d":"markdown","19c6217d":"markdown","4edd8183":"markdown","6d7f2595":"markdown","0866062c":"markdown","4d68e404":"markdown","e1a5c95c":"markdown","b4caf5d2":"markdown"},"source":{"74f148a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","e95ddd6e":"# Show the path you will use\ndata = pd.read_csv('..\/input\/Pokemon.csv')","294581fe":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","dedde024":"data.head()  # Display first five elements of data \n#data.tail() # Display last five elements of data","4f7c6465":"data.isnull().sum()  # Display the number of null elements","41c7caf6":"# columns gives column names of features\ndata.columns","f069da4b":"# shape gives number of rows and columns in a tuble\ndata.shape","29541e1b":"# For example, lets take a look at frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","3e6a16cb":"# For example, max HP is 255 or min defense is 5\ndata.describe() # it ignores null entries","b14fed74":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack', by='Legendary')","6651d4ca":"# Firstly I create a new data from pokemons data to explain melt more easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","622765f1":"# lets melt it\n# id_vars -> what we do not wish to melt\n# value_vars -> what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","a04d421b":"# Index is name\n# Columns (Attack and Defense) are variable\n# And values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","1bd9e96d":"# Firstly lets create 2 data frames\ndata1 = data.head()\ndata2 = data.tail()\n# Now lets combine them as vertical (axis=0)\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","1774dbdc":"# Now lets combine Attack and Defense columns as horizontal (axis=1)\ndata1 = data['Attack'].head()\ndata2 = data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1)\nconc_data_col","a0d2bbfd":"data.dtypes  # Display data types of columns","87ad8c83":"# lets convert object(string) to categorical and integer to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","fe187ad3":"# Let's see differences\n# As you can see Type 1 is converted from object to categorical\n# And Speed is converted from integer to float\ndata.dtypes","4e5739d8":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","e600f88d":"# Lets check Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN values","854d6914":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","f8e2d0fd":"# Let's check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","4c6af6d9":"# In order to run all code, we need to make this line comment\n# assert 1==2  # returns an error because it is false","210cb7bb":"assert data['Type 2'].notnull().all() # returns nothing because we drop nan values","26a33e88":"data[\"Type 2\"].fillna('empty',inplace = True)","f8db9589":"assert data['Type 2'].notnull().all() # returns nothing because we do not have nan values","b9b726e0":"# With assert statement we can check lots of things. For example;\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","0d79f636":"**Visual Exploratory Data Analysis**","42933099":"**Basic steps to start Data Science: PART3**","35fe187d":"**Exploratory Data Analysis**\n\nvalue_counts(): frequency counts \n\noutliers: is the value that considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n\n**We will use describe() method. Describe method includes:**\n\n* count: number of entries\n\n* mean: average of entries\n\n* std: standart deviation\n\n* min: minimum entry\n\n* 25%: first quantile\n\n* 50%: median or second quantile\n\n* 75%: third quantile\n\n* max: maximum entry\n\n**What is  quantile?**\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","19c6217d":"**Missing Data and Testing with Assert**","4edd8183":"**Read more here:**\n* [Basic steps to start Data Science: PART1](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction)\n\n* [Basic steps to start Data Science: PART2](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction-2)\n\n* [Basic steps to start Data Science: PART4](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction-4)","6d7f2595":"**Diagnose Data for Cleaning**\n\nWe need to diagnose and clean data before exploring. \nUnclean data:\n\n* Column name inconsistency like upper-lower case letter or space between words\n\n* missing data\n\n* different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data","0866062c":"**Concatenating Data**\n\nData combining","4d68e404":"**Tidy Data**","e1a5c95c":"**Pivoting Data**\n\nReverse of melting.","b4caf5d2":"**Data Types**\n\nThere are 5 basic data types: object(string), boolean, integer, float and categorical. "}}