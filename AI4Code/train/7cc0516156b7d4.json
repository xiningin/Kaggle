{"cell_type":{"8bf2ea3c":"code","120f6d00":"code","8d97a560":"code","22df80bf":"code","84263447":"code","a417b300":"code","35db3771":"code","6e407000":"code","cf39825f":"code","8e385ee4":"code","e8ca035f":"code","47051fc2":"code","ff8d9230":"code","1871f1b8":"code","292ba8eb":"code","6eeee150":"code","c775f634":"code","76cbb30b":"code","8718d596":"code","d6414d94":"code","2db8c513":"code","1fd3a4bf":"code","7bb778a9":"code","1240ede8":"code","d27dd2c0":"code","a70791d7":"code","d3f5de3a":"code","2c059503":"code","dd7acc87":"code","0111fda9":"code","3721e82f":"code","229cfc8b":"code","0ab83f86":"code","c76da110":"code","f0ad40c8":"code","486936dd":"code","3a090310":"code","b10ab9a2":"code","783a41c5":"code","2d6e5f23":"code","f4ed9938":"code","caa1486b":"code","7231112e":"code","7fdefb46":"code","74e1ebb5":"code","2313b8e6":"code","a645eac5":"code","147ec7d3":"code","34e18c96":"code","e4822193":"code","04ea570c":"code","76af70f7":"code","cdfe34b5":"code","ed0f1395":"code","a3b636ba":"code","96cf4019":"code","a2563001":"code","9b053e10":"code","3a192678":"code","b78cb90a":"code","fb2bc5eb":"code","3068d94b":"code","ec80a2dd":"code","9b9125b8":"code","3b806bf7":"code","9a6147be":"code","095209e7":"code","2afc45fd":"code","aaec0de9":"code","c097ee21":"code","50f02b02":"code","a865befd":"code","296461e8":"code","304527d1":"code","a406a88c":"code","e8ce22cc":"code","be10ff67":"code","39df6929":"code","da898adb":"code","7755a280":"code","f024c411":"code","b0d1788c":"code","834d51d4":"code","f48f3731":"code","5334d1e9":"code","061c7cd3":"code","c7fefa15":"code","fb6cffb8":"code","b5ca1e78":"code","aeefa311":"code","f54367ad":"code","8e7771e0":"code","6c47b64c":"code","008ba260":"code","1d5af794":"code","934b607a":"code","dac82102":"code","367b861d":"code","0414c33e":"markdown","be001b37":"markdown","21a28e77":"markdown","6eae2ed2":"markdown","32088294":"markdown","a018ae81":"markdown","f8179fbe":"markdown","4bcb19af":"markdown","cd1e9e41":"markdown","734bfd3f":"markdown","8dc75a6b":"markdown","aa1737bd":"markdown","6dd64d40":"markdown","8ed2aa97":"markdown","be425814":"markdown"},"source":{"8bf2ea3c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\n%matplotlib  inline","120f6d00":"train =  pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv', parse_dates = ['datetime'])\nsampsub = pd.read_csv(\"..\/input\/bike-sharing-demand\/sampleSubmission.csv\")","8d97a560":"# show top 5 rows\ntrain.head()","22df80bf":"#size of dataframe\nprint(train.shape)\nprint(test.shape)","84263447":"print(train.info())\nprint(test.info())","a417b300":"train[\"season\"] = train[\"season\"].astype(\"category\")\ntrain[\"weather\"] = train[\"weather\"].astype(\"category\")\ntrain[\"holiday\"] =  train[\"holiday\"].astype(\"category\")\ntrain[\"workingday\"] =  train[\"workingday\"].astype(\"category\")\n\ntest[\"season\"] = test[\"season\"].astype(\"category\")\ntest[\"weather\"] = test[\"weather\"].astype(\"category\")\ntest[\"holiday\"] =  test[\"holiday\"].astype(\"category\")\ntest[\"workingday\"] =  test[\"workingday\"].astype(\"category\")","35db3771":"# Extract month , dow, hour from date\ndate = pd.to_datetime(train['datetime'])\ntrain['month'] = date.dt.month_name().astype(\"category\")\ntrain['dow'] = date.dt.day_name().astype(\"category\")\ntrain['hour'] = date.dt.hour.astype(\"category\")\n\ndate1 = pd.to_datetime(test['datetime'])\ntest['month'] = date1.dt.month_name().astype(\"category\")\ntest['dow'] = date1.dt.day_name().astype(\"category\")\ntest['hour'] = date1.dt.hour.astype(\"category\")","6e407000":"train.head()","cf39825f":"test.head()","8e385ee4":"'''\n    This function performs the univariate analyse for numeric varriable \n    \n    Parameters\n    ---------\n    data  : dataframe, \n    field : string, feature name  \n    \n    Returns:\n        skewness, kurtosis, mean,min,max,rangeval, histogram, probplot,boxplot of varriable\n'''\ndef univariate_analysis_numeric(data,field):\n    skewness = data[field].skew()\n    kurtosis = data[field].kurt()\n    mean = data[field].mean()\n    minval = data[field].min()\n    maxval = data[field].max()\n    st_dev = data[field].std()\n    median = data[field].median()\n    rangeval = maxval - minval\n    points = mean-st_dev, mean+st_dev\n    fig, axes = plt.subplots(1, 3,figsize=(15,6))\n    sns.histplot(data=data, x=field,kde=True, ax=axes[0])\n    sns.boxplot(data=data, x=field,  ax=axes[1])\n    stats.probplot(data[field],plot=axes[2])\n    fig.suptitle('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n                                                                                                   round(kurtosis,2),\n                                                                                                   round(skewness,2),\n                                                                                                   (round(minval,2),round(maxval,2),round(rangeval,2)),\n                                                                                                   round(mean,2),\n                                                                                                   round(median,2)),fontsize=\"13\")    ","e8ca035f":"univariate_analysis_numeric(train,\"temp\")","47051fc2":"univariate_analysis_numeric(train,\"atemp\")","ff8d9230":"univariate_analysis_numeric(train,\"humidity\")","1871f1b8":"univariate_analysis_numeric(train,\"windspeed\")","292ba8eb":"univariate_analysis_numeric(train,\"casual\")","6eeee150":"univariate_analysis_numeric(train,\"registered\")","c775f634":"univariate_analysis_numeric(train,\"count\")","76cbb30b":"def univariate_analysis_categorical(data,field):\n    norm_count = data[field].value_counts(normalize = True)\n    val_count =  data[field].value_counts()\n    n_uni = data[field].nunique()\n    norm_df = pd.DataFrame(norm_count)\n    norm_df.columns = [\"fraction\"]\n    #Plotting the variable with every information\n    fig,axes = plt.subplots(1,2,figsize=(15,6))\n    ax = sns.countplot(data=data,x=field,ax=axes[0])\n    ax.set_title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,val_count))\n    ax1 = sns.barplot(x=norm_df.index,y=\"fraction\" ,data=norm_df, ax=axes[1])\n    ax1.set_title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))","8718d596":"univariate_analysis_categorical(train,\"weather\")","d6414d94":"univariate_analysis_categorical(train,\"holiday\")","2db8c513":"univariate_analysis_categorical(train,\"holiday\")","1fd3a4bf":"univariate_analysis_categorical(train,\"hour\")","7bb778a9":"univariate_analysis_categorical(train,\"dow\")","1240ede8":"univariate_analysis_categorical(train,\"month\")","d27dd2c0":"sns.heatmap(train.corr(),annot=True)","a70791d7":"sns.pairplot(train)","d3f5de3a":"\ndef draw_ridge_plot(data,catfield,numfield):\n    # Initialize the FacetGrid object\n    g = sns.FacetGrid(train, col=catfield,hue=catfield)\n\n    # # Draw the densities in a few steps\n    g.map(sns.kdeplot, numfield, shade=False)\n    g.map(plt.axhline, y=0, lw=2)\n\n    # # Define and use a simple function to label the plot in axes coordinates\n    def label(x, color, label):\n        ax = plt.gca()\n        ax.text(0, .2, label, color=color, ha=\"left\", va=\"center\", transform=ax.transAxes)\n    g.map(label, numfield)\n\n    # Set the subplots to overlap\n    # g.fig.subplots_adjust(hspace=-.25)\n\n    # # Remove axes details that don't play well with overlap\n    # g.set_titles(\"\")\n    g.set(yticks=[])\n    g.despine(bottom=True, left=True)\n\n    g1 = sns.catplot(data=data,x=catfield,kind=\"box\",y=numfield,col=catfield)\n    g1.set(xticks=[])","2c059503":"draw_ridge_plot(train,\"season\",\"count\")","dd7acc87":"draw_ridge_plot(train,\"season\",\"humidity\")","0111fda9":"draw_ridge_plot(train,\"season\",\"windspeed\")","3721e82f":"draw_ridge_plot(train,\"season\",\"temp\")","229cfc8b":"draw_ridge_plot(train,\"season\",\"atemp\")","0ab83f86":"draw_ridge_plot(train,\"season\",\"registered\")","c76da110":"draw_ridge_plot(train,\"season\",\"casual\")","f0ad40c8":"draw_ridge_plot(train,\"weather\",\"count\")","486936dd":"draw_ridge_plot(train,\"weather\",\"humidity\")","3a090310":"draw_ridge_plot(train,\"weather\",\"atemp\")","b10ab9a2":"draw_ridge_plot(train,\"weather\",\"temp\")","783a41c5":"draw_ridge_plot(train,\"weather\",\"windspeed\")","2d6e5f23":"draw_ridge_plot(train,\"weather\",\"registered\")","f4ed9938":"draw_ridge_plot(train,\"weather\",\"casual\")","caa1486b":"draw_ridge_plot(train,\"month\",\"count\")","7231112e":"draw_ridge_plot(train,\"month\",\"humidity\")","7fdefb46":"draw_ridge_plot(train,\"month\",\"temp\")","74e1ebb5":"draw_ridge_plot(train,\"month\",\"atemp\")","2313b8e6":"draw_ridge_plot(train,\"month\",\"windspeed\")","a645eac5":"draw_ridge_plot(train,\"month\",\"registered\")","147ec7d3":"draw_ridge_plot(train,\"month\",\"casual\")","34e18c96":"draw_ridge_plot(train,\"dow\",\"count\")","e4822193":"draw_ridge_plot(train,\"dow\",\"temp\")","04ea570c":"draw_ridge_plot(train,\"dow\",\"humidity\")","76af70f7":"draw_ridge_plot(train,\"dow\",\"windspeed\")","cdfe34b5":"draw_ridge_plot(train,\"dow\",\"registered\")","ed0f1395":"draw_ridge_plot(train,\"dow\",\"casual\")","a3b636ba":"draw_ridge_plot(train,\"hour\",\"count\")","96cf4019":"draw_ridge_plot(train,\"hour\",\"temp\")","a2563001":"draw_ridge_plot(train,\"hour\",\"humidity\")","9b053e10":"draw_ridge_plot(train,\"hour\",\"casual\")","3a192678":"draw_ridge_plot(train,\"hour\",\"registered\")","b78cb90a":"import numpy as np\ndef BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  '''   P-value \u2264 \u03b1: The variables have a statistically significant association (Reject H0)\n        If the p-value is less than or equal to the significance level, you reject the null hypothesis and conclude that there is a statistically significant association between the variables. \n    P-value > \u03b1: Cannot conclude that the variables are associated (Fail to reject H0)\n        If the p-value is larger than the significance level, you fail to reject the null hypothesis because there is not enough evidence to conclude that the variables are associated.   '''\n    \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n#   plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n  groupeddata = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  plt.figure(figsize=(20, 20))\n  ax1 = plt.subplot(2,3,1)\n  ax2 = plt.subplot(2,3,2)\n  ax3 = plt.subplot(2,3,3)\n  sns.countplot(x=cat, hue=tar, data=data,ax=ax1)\n  ax1.set_title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n  groupeddata.plot(kind='bar', stacked='True', ax=ax2)\n  tbl = ax3.table(cellText=groupeddata.values.round(decimals=2),\n          rowLabels=groupeddata.index,\n          colLabels=groupeddata.columns,\n          cellLoc = 'right', rowLoc = 'center',loc=\"center\",bbox = [0.1, 0, 2, 1])\n  tbl.auto_set_font_size(False)\n  tbl.set_fontsize(10)\n  tbl.scale(2, 2)\n  ax3.axis(\"off\")\n  int_level = data[cat].value_counts()","fb2bc5eb":"BVA_categorical_plot(train,\"season\",\"weather\")","3068d94b":"BVA_categorical_plot(train,\"season\",\"holiday\")","ec80a2dd":"BVA_categorical_plot(train,\"season\",\"workingday\")","9b9125b8":"BVA_categorical_plot(train,\"dow\",\"weather\")","3b806bf7":"BVA_categorical_plot(train,\"weather\",\"hour\")","9a6147be":"fig, scatter = plt.subplots(figsize = (20,15))\nsns.scatterplot(x=\"temp\",y=\"casual\",hue=\"season\",style=\"weather\",data=train,ax=scatter)","095209e7":"fig, scatter = plt.subplots(figsize = (20,15))\nsns.scatterplot(x=\"temp\",y=\"registered\",hue=\"season\",style=\"weather\",data=train,ax=scatter)","2afc45fd":"# fig, scatter = plt.subplots(figsize = (20,15))\nsns.catplot(data=train,x=\"hour\",y=\"casual\",row=\"season\",col=\"weather\")","aaec0de9":"# fig, scatter = plt.subplots(figsize = (20,15))\nsns.catplot(data=train,x=\"season\",y=\"casual\",row=\"hour\",col=\"weather\",kind=\"box\")","c097ee21":"sns.catplot(data=train,x=\"season\",y=\"casual\",row=\"hour\",col=\"workingday\" ,kind=\"box\")","50f02b02":"train.head()","a865befd":"test.head()","296461e8":"train0 = train.drop([\"datetime\",\"casual\",\"registered\",\"atemp\"],axis=1)\ntest0  =  test.drop([\"datetime\",\"atemp\"],axis=1) ","304527d1":"train_df =  pd.get_dummies(train0,drop_first=True)\ntest_df = pd.get_dummies(test0,drop_first=True)","a406a88c":"train_df.info()\ntest_df.info()","e8ce22cc":"feature_scale =  [\"temp\",\"humidity\",\"windspeed\"]\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nscaler = StandardScaler()\nscaler_test = StandardScaler()\nscaler.fit(train_df[feature_scale])\ntrain_df[feature_scale] = scaler.transform(train_df[feature_scale])\n\nscaler_test = StandardScaler()\nscaler_test.fit(test_df[feature_scale])\ntest_df[feature_scale] = scaler_test.transform(test_df[feature_scale])","be10ff67":"final_data=train_df","39df6929":"from sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.linear_model import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\nimport statsmodels.formula.api as smf\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport pickle","da898adb":"# Let's create a function to create adjusted R-Squared\ndef adj_r2(x,r2):\n    n = x.shape[0]\n    p = x.shape[1]\n    adjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\n    return adjusted_r2","7755a280":"np.random.seed(0)\n# split the train and validation data\ndf_train, df_test = train_test_split(final_data, train_size = 0.7, test_size = 0.3, random_state = 100)\ny_train = df_train[\"count\"]\nX_train = df_train.drop([\"count\"],axis=1)\nX_val =  df_test.drop([\"count\"],axis=1)\ny_val = df_test[\"count\"]","f024c411":"X_train.info()","b0d1788c":"'''\n    train_X: Independent features for training  \n    train_Y: target feature for training \n    Val_X  : Independent feature for Validation \n    Val_Y  : target feature for Validation\n'''\ndef build_lr_model(train_X,train_Y,val_X,val_Y,modelname):\n    lregression = LinearRegression()\n    lregression.fit(train_X,train_Y)\n    reg_predict_model(lregression,val_X, val_Y)\n    save_model(modelname,lregression)\n    \ndef build_lasso_model(train_X,train_Y,val_X, val_Y,modelname):\n    # Lasso Regularization\n    # LassoCV will return best alpha and coefficients after performing 10 cross validations\n    lasscv = LassoCV(alphas = None,cv =10, max_iter = 100000, normalize = True)\n    lasscv.fit(train_X, train_Y)    \n    alpha = lasscv.alpha_\n    print(\"Best alpha : \",alpha)\n    lasso_reg = Lasso(alpha)\n    lasso_reg.fit(train_X, train_Y)\n    reg_predict_model(lasso_reg,val_X, val_Y)\n#     modelname = 'lasso_finalized_model.pickle'\n    save_model(modelname,lasso_reg)\n\ndef build_ridge_model(train_X,train_Y,val_X, val_Y,modelname):\n    # Using Ridge regression model\n    # RidgeCV will return best alpha and coefficients after performing 10 cross validations. \n    # We will pass an array of random numbers for ridgeCV to select best alpha from them    \n    alphas = np.random.uniform(low=0, high=10, size=(50,))\n    ridgecv = RidgeCV(alphas = alphas,cv=10,normalize = True)\n    ridgecv.fit(train_X, train_Y)\n    print(\"Best alpha : \",ridgecv.alpha_)\n    ridge_model = Ridge(alpha=ridgecv.alpha_)\n    ridge_model.fit(train_X, train_Y)\n    reg_predict_model(ridge_model,val_X, val_Y)    \n#     modelname = 'ridge_finalized_model.pickle'\n    save_model(modelname,ridge_model)\n\ndef build_elasticnet_model(train_X,train_Y,val_X, val_Y,modelname):\n    # Elastic net\n    elasticCV = ElasticNetCV(alphas = None, cv =10)\n    elasticCV.fit(train_X, train_Y)\n    print(\"Best alpha : \",elasticCV.alpha_)\n    print(\" l1 ratio : \",elasticCV.l1_ratio)\n    elasticnet_reg = ElasticNet(alpha = elasticCV.alpha_,l1_ratio=0.5)\n    elasticnet_reg.fit(train_X, train_Y)    \n    reg_predict_model(elasticnet_reg,val_X, val_Y)    \n#     modelname = 'elasticnet_finalized_model.pickle'\n    save_model(modelname,elasticnet_reg)\n\ndef build_knn_model(train_X,train_Y,val_X,val_Y,modelname):\n    neigh = KNeighborsRegressor(n_neighbors=5)\n    neigh.fit(train_X, train_Y)\n    reg_predict_model(neigh,val_X, val_Y)    \n    save_model(modelname,neigh)    \n    \ndef save_model(modelname,model):\n    # saving the model to the local file system\n    pickle.dump(model, open(modelname, 'wb'))    \n\ndef reg_predict_model(model,val_X, val_Y):    \n    predict_Y =  model.predict(val_X)\n    print(\"Mean Squared Error\",mean_squared_error(val_Y,predict_Y,squared=False))\n    print(\"Mean Absolute Error\",mean_absolute_error(val_Y,predict_Y))\n    print(\"R2\",r2_score(val_Y,predict_Y))\n    print(\"adjR2\",adj_r2(val_X,r2_score(val_Y,predict_Y)))\n    print(\"MeanSquaredError\",mean_squared_error(val_Y,predict_Y))\n    \ndef model_stats_analysis(data,exclude_features,target_feature):\n    lm = smf.ols(formula=target_feature+'~ '+'+'.join(data.columns.difference(exclude_features)), data=data).fit()\n    print(lm.summary())\n\ndef find_vif(data):\n    vif = pd.DataFrame()\n    vif['Features'] = data.columns\n    vif['VIF'] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    print(vif)  ","834d51d4":"# here consider all columns and analyse the performance of the model\nmodel_stats_analysis(final_data,['count'],'count')","f48f3731":"find_vif(X_train)","5334d1e9":"model_stats_analysis(final_data,['count','dow_Monday','month_July','month_October','month_September',\"month_August\",\"month_June\",\"month_November\",\"month_December\",'month_January','month_February','month_March','dow_Sunday','dow_Tuesday','weather_4','workingday_1','windspeed','holiday_1','dow_Wednesday','dow_Thursday'],'count')","061c7cd3":"exclude_columns = ['count','dow_Monday','month_July','month_October','month_September',\"month_August\",\"month_June\",\"month_November\",\"month_December\",'month_January','month_February','month_March','dow_Sunday','dow_Tuesday','weather_4','workingday_1','windspeed','holiday_1','dow_Wednesday','dow_Thursday']\nselected_columns = X_train.columns.difference(exclude_columns)\nfind_vif(X_train[selected_columns])","c7fefa15":"X_val.head()","fb6cffb8":"print(\"------------Simple model with all features-------------\")\n# build simple model with all features\nbuild_lr_model(X_train,y_train,X_val,y_val,\"simple_model_with_all_features.pickle\")\nprint(\"------------Basic model with selected features-------------\")\n# build simple model selected  features\nbuild_lr_model(X_train[selected_columns],y_train,X_val[selected_columns],y_val,\"simple_model_with_selected_features.pickle\")","b5ca1e78":"print(\"------------Lasso with all features-------------\")\nbuild_lasso_model(X_train,y_train,X_val,y_val,\"lasso_model_with_all_features.pickle\")\n# print(\"----------Lasso with selected features---------\")\n# build_lasso_model(X_train[selected_columns],y_train,X_val[selected_columns],y_val)","aeefa311":"print(\"-------------Ridge with all Features---------\")\nbuild_ridge_model(X_train,y_train,X_val,y_val,\"ridge_model_with_all_features.pickle\")\n# print(\"-------------Ridge with Selected Features---------\")\n# build_ridge_model(X_train[selected_columns],y_train,X_val[selected_columns],y_val)","f54367ad":"print(\"-------------elasticnet with all Features---------\")\nbuild_elasticnet_model(X_train,y_train,X_val,y_val,\"elasticnet_model_with_all_features.pickle\")\n# print(\"-------------elasticnet with Selected Features---------\")\n# build_elasticnet_model(X_train[selected_columns],y_train,X_val[selected_columns],y_val)","8e7771e0":"print(\"-------------KNN with all Features---------\")\nbuild_knn_model(X_train,y_train,X_val,y_val,\"knn_model_with_all_features.pickle\")\nprint(\"-------------knn with Selected Features---------\")\nbuild_knn_model(X_train[selected_columns],y_train,X_val[selected_columns],y_val,\"knn_model_with_selected_features.pickle\")","6c47b64c":"# import os\n# os.remove(\"\/kaggle\/working\/elasticnet_finalized_model.pickle\")","008ba260":"test_df[selected_columns].info()","1d5af794":"loaded_model = pickle.load(open(\"knn_model_with_selected_features.pickle\", 'rb'))\na = loaded_model.predict(test_df[selected_columns])","934b607a":"submission = pd.DataFrame({ \"datetime\": sampsub.datetime, \"count\": a})","dac82102":"submission[\"count\"] = np.where(submission[\"count\"]>0,submission[\"count\"],0)","367b861d":"submission.to_csv(\"submission_knn.csv\", index=False)","0414c33e":"# Feature Engineering","be001b37":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Univariate Analysis - Numerical<\/h2> ","21a28e77":"\n<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Univariate Analysis - Categorical<\/h2> ","6eae2ed2":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Import Libraries and Utilities <\/h2> ","32088294":"### Drop Unwanted Columns\n\n<table>\n    <thead>\n        <th>Column<\/th>\n        <th>Reason<\/th>        \n    <\/thead>\n    <tbody>\n        <tr>\n            <td>datetime<\/td>\n            <td>Extracted hour,month, day of week<\/td>\n        <\/tr>\n        <tr>\n            <td>casual,registered<\/td>\n            <td>both columns sum is count ,so i have removed<\/td>\n        <\/tr>\n        <tr>\n            <td>atemp<\/td>\n            <td>temp and a temp is highly correlated<\/td>\n        <\/tr>\n        <tr>\n            <td>holiday<\/td>\n            <td>Most of the bike rental happened in workingday and also we have a column for working day <\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>","a018ae81":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Data Loading<\/h2> ","f8179fbe":"### Analyse the model ","4bcb19af":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">  Bivariate Analysis<\/h2> ","cd1e9e41":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">  Multivariate Analysis <\/h2> ","734bfd3f":"<h1 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: center\"> Bike Sharing System<\/h1> \n<div class = 'image'> <img style=\"float:center; border:5px solid grey; width:75%\" align=center src = https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3948\/media\/bikes.png> \n<\/div>\n\nBike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.\n\nThe data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.\n\n<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Data Fields Description<\/h2> \n<ol>\n    <li> <strong>datetime : <\/strong> hourly date + timestamp <\/li>\n    <li> <strong>season : <\/strong>  1 = spring, 2 = summer, 3 = fall, 4 = winter  <\/li>\n    <li> <strong>holiday : <\/strong> whether the day is considered a holiday<\/li>\n    <li> <strong>workingday : <\/strong> whether the day is neither a weekend nor holiday <\/li>\n    <li> <strong>weather<\/strong><\/li>\n        \n        1: Clear, Few clouds, Partly cloudy, Partly cloudy  \n        2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n        3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n        4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n        \n    \n<li> <strong>temp : <\/strong> temperature in Celsius  <\/li>\n<li> <strong>atemp : <\/strong> \"feels like\" temperature in Celsius  <\/li>\n<li> <strong>humidity : <\/strong> relative humidity <\/li>\n<li> <strong>windspeed : <\/strong>  wind speed  <\/li>\n<li> <strong>atemp<\/strong> \"feels like\" temperature in Celsius  <\/li>\n<li> <strong>casual : <\/strong> number of non-registered user rentals initiated<\/li>\n<li> <strong>registered : <\/strong>  number of registered user rentals initiated <\/li>\n<li> <strong>count : <\/strong>   number of total rentals <\/li>\n<\/ol>","8dc75a6b":"<h2 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Varriable Identification and Typecasting<\/h2> ","aa1737bd":"\n**VIF and P-Value of features**\n  \n   **P-Value**\n    \n    Null Hypothesis - No relationship with features and target column\n\n    significant p-value = 0.05\n    \n    so, p-value < 0.05 - rejecting null hypothesis means include feature because it has a relationship with target column\n        p-value > 0.05 - Accepting null hypothesis means exclude the feature because it doesn't affect the target column\n \n **Varriance Inflation Factor**\n          \n          VIF =  1\/1-R2\n          \n          if R2 is 0.90,  \n          VIF = 1\/(1-0.9) =  10\n          so VIF 10, means 90% relationship b\/w the independent features, it makes multi colinearity.\n<table style=\"width:50%; text-align:center\">\n    <thead>\n        <th>Column<\/th>\n        <th>Reason<\/th>        \n    <\/thead>\n    <tbody>\n        <tr>\n            <td>dow_Saturday<\/td>\n            <td>High P Value<\/td>\n        <\/tr>\n        <tr>\n            <td>dow_Tuesday<\/td>\n            <td>High P value<\/td>\n        <\/tr>\n        <tr>\n            <td>weather_4<\/td>\n            <td>High P value<\/td>\n        <\/tr>\n        <tr>\n            <td>holiday_1<\/td>\n            <td>High P_value <\/td>\n        <\/tr>\n        <tr>\n            <td>dow_Wednesday<\/td>\n            <td>High P_value <\/td>\n        <\/tr>\n        <tr>\n            <td>dow_Thursday<\/td>\n            <td>High P_value <\/td>\n        <\/tr>\n        <tr>\n            <td>windspeed<\/td>\n            <td>High P_value <\/td>\n        <\/tr>\n        <tr>\n            <td>workingday_1<\/td>\n            <td>High VIF <\/td>\n        <\/tr>\n        <tr>\n            <td>dow_Monday<\/td>\n            <td>High P_value <\/td>\n        <\/tr>\n    <\/tbody>\n<\/table>","6dd64d40":"### Categorical Encoding","8ed2aa97":"# Model Building","be425814":"### Scaling"}}