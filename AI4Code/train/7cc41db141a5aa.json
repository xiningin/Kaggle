{"cell_type":{"ab9ce6d1":"code","6836b62b":"code","6b3beddf":"code","b2074d72":"code","c793cd96":"code","2b26b6b9":"code","be8f47c0":"code","3fd2c865":"code","2ec872fd":"code","694914f1":"code","0040fb30":"code","6194516e":"code","f46421a5":"code","ee4b3bc4":"code","1f808da2":"code","cfb005a9":"code","1d0c8968":"code","9c9ac652":"code","d4111eac":"code","622d5e9a":"markdown"},"source":{"ab9ce6d1":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nsns.set(style='white',context='notebook',palette='deep')","6836b62b":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')","6b3beddf":"Y_train=train[\"label\"]\nX_train=train.drop(labels=[\"label\"],axis=1)\ndel train\ng=sns.countplot(Y_train)","b2074d72":"#check the data\nX_train.isnull().any().describe()\ntest.isnull().any().describe()","c793cd96":"#normalize the data\nfrom sklearn import preprocessing\nmin_max_scaler=preprocessing.MinMaxScaler()\nX_train=min_max_scaler.fit_transform(X_train)\ntest=min_max_scaler.fit_transform(test)","2b26b6b9":"X_train=X_train.reshape(-1,28,28,1)\ntest=test.reshape(-1,28,28,1)","be8f47c0":"Y_train=to_categorical(Y_train,num_classes=10)\n","3fd2c865":"random_seed=2\nX_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.1,random_state=random_seed)","2ec872fd":"g=plt.imshow(X_train[0][:,:,0])","694914f1":"model=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu'))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation=\"softmax\"))","0040fb30":"# define the optimizer\noptimizer=RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)\nmodel.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","6194516e":"learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_1r=0.00001)\nepochs=1\nbatch_size=86","f46421a5":"datagen=ImageDataGenerator(featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,samplewise_std_normalization=False,zca_whitening=False,\n                          rotation_range=10,zoom_range=0.1,width_shift_range=0.1,horizontal_flip=False,vertical_flip=False)\ndatagen.fit(X_train)","ee4b3bc4":"history=model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size),epochs=epochs,validation_data=(X_val,Y_val),\n                           verbose=2,steps_per_epoch=X_train.shape[0]\/\/batch_size,callbacks=[learning_rate_reduction])","1f808da2":"fig,ax=plt.subplots(2,1)\nax[0].plot(history.history['loss'],color='b',label=\"Training loss\")\nax[0].plot(history.history['val_loss'],color='r',label=\"validation loss\",axes=ax[0])\nlegend=ax[0].legend(loc='best',shadow=True)\nax[1].plot(history.history['acc'],color='b',label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'],color='r',label=\"Validation accuracy\")\nlegend=ax[1].legend(loc='best',shadow=True)","cfb005a9":"def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks=np.arange(len(classes))\n    plt.xticks(tick_marks,classes,rotation=45)\n    plt.yticks(tick_marks,classes)\n    if normalize:\n        cm=cm.astype('float')\/cm.sum(axis=1)[:,np.newaxis]\n    thresh=cm.max()\/2.\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,cm[i,j],horizontalalignment=\"center\",color=\"white\"if cm[i,j]>thresh else  \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nY_pred=model.predict(X_val)\nY_pred_classes=np.argmax(Y_pred,axis=1)\nY_true=np.argmax(Y_val,axis=1)\nconfusion_mtx=confusion_matrix(Y_true,Y_pred_classes)\nplot_confusion_matrix(confusion_mtx,classes=range(10))","1d0c8968":"errors=(Y_pred_classes-Y_true!=0)\nY_pred_classes_errors=Y_pred_classes[errors]\nY_pred_errors=Y_pred[errors]\nY_true_errors=Y_true[errors]\nX_val_errors=X_val[errors]\ndef display_errors(errors_index,img_errors,pred_errors,obs_errors):\n    n=0\n    nrows=2\n    ncols=3\n    fig,ax=plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error=errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label:{}\\nTrue label:{}\".format(pred_errors[error],obs_errors[error]))\n            n+=1\nY_pred_errors_prob=np.max(Y_pred_errors,axis=1)\ntrue_prob_errors=np.diagonal(np.take(Y_pred_errors,Y_true_errors,axis=1))\ndelta_pred_true_errors=Y_pred_errors_prob-true_prob_errors\nsorted_dela_errors=np.argsort(delta_pred_true_errors)\nmost_important_errors=sorted_dela_errors[-6:]\ndisplay_errors(most_important_errors,X_val_errors,Y_pred_classes_errors,Y_true_errors)","9c9ac652":"results=model.predict(test)\nresults=np.argmax(results,axis=1)\nresults=pd.Series(results,name=\"Label\")","d4111eac":"submission=pd.concat([pd.Series(range(1,28001),name=\"ImageId\"),results],axis=1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","622d5e9a":"# CNN acc 0.982"}}