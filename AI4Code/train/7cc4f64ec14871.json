{"cell_type":{"89d95bf7":"code","8fdefc30":"code","bffc3b3e":"code","ee58aaf7":"code","10bd2f5c":"code","70eba9ac":"code","c1973912":"code","6aa364dd":"code","f5f7269b":"code","f4228b70":"code","92599cc6":"code","4cfd80d8":"code","3518477e":"code","c7ea9eba":"code","4424b966":"code","1acf9744":"markdown"},"source":{"89d95bf7":"%%capture\n!pip install timm","8fdefc30":"import time\nfrom tqdm import tqdm_notebook as tqdm\n#import tqdm.notebook import tqdm\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import lr_scheduler\nimport timm\nfrom timm.scheduler.cosine_lr import CosineLRScheduler\nfrom timm.scheduler.plateau_lr import PlateauLRScheduler\nimport warnings\nwarnings.filterwarnings('ignore')","bffc3b3e":"!ls -l ..\/input\/midsw251birds2021","ee58aaf7":"class args:\n    lr = 0.0001\n    epochs = 55\n    batch_size = 36\n    num_workers = 8\n    folds = 5\n    compeition_name = 'midsw251birds2021'","10bd2f5c":"alldf = pd.read_csv(f'..\/input\/{args.compeition_name}\/train.csv')\nalldf['filename'] = 'train\/' + alldf['filename']\n# Split the training dataset into a training and a validation\nvaldf = alldf[::args.folds]\ntrndf = alldf[~alldf.filename.isin(valdf.filename)]\n# Load our test data\ntstdf = pd.read_csv(f'..\/input\/{args.compeition_name}\/test.csv')\ntstdf['filename'] = 'test\/' + tstdf['filename']\nmetadf = pd.read_csv(f'..\/input\/{args.compeition_name}\/metadata.csv')\nmetadf = metadf.set_index('label')\nprint(f'File shapes -- train : {trndf.shape}, valid : {valdf.shape}, test : {tstdf.shape}')\ntrndf.head()","70eba9ac":"imgnetmeans = [0.22363983, 0.18190407, 0.2523437 ]\nimgnetstds = [0.32451536, 0.2956294,  0.31335256]\n#\u00a0Using albumentations, check some examples here : https:\/\/albumentations.readthedocs.io\/en\/latest\/examples.html \ndef trntransforms():\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Transpose(p=0.5),\n        A.augmentations.transforms.Blur(p=0.5),\n        ToTensorV2(),\n        ])\n\ndef tsttransforms():\n    return A.Compose([\n        ToTensorV2(),\n    ])\n\nclass BirdDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        self.data = df\n        self.img_dir = f'..\/input\/{args.compeition_name}\/'\n        self.transform = transform\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        fname = self.data.iloc[idx]['filename']\n        img_path = f'{self.img_dir}\/{fname}'\n        image = cv2.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image = image)['image']\n        image = image.float() \/ 255.\n        label = -1 if self.mode=='test' else self.data.iloc[idx]['label']\n        \n        return image, label","c1973912":"# Define our dataset\ntrndataset = BirdDataset(trndf, 'train', trntransforms())\nvaldataset = BirdDataset(valdf, 'valid', tsttransforms())\ntstdataset = BirdDataset(tstdf, 'test', tsttransforms())","6aa364dd":"# Test the dataset\nimg, label = next(iter(trndataset))\nspecies = metadf.loc[label]['name']\nprint(f'Species : {species}')\n#Image.fromarray(img)\nimgviz = (img * 255).transpose(0, 2).numpy().astype(np.uint8)\nImage.fromarray(imgviz)","f5f7269b":"loaderargs = {'num_workers' : args.num_workers, 'batch_size':args.batch_size, 'pin_memory': False, 'drop_last': False}\ntrnloader = DataLoader(trndataset, shuffle = True, **loaderargs)\nvalloader = DataLoader(valdataset, shuffle = False, **loaderargs)\ntstloader = DataLoader(tstdataset, shuffle = False, **loaderargs)","f4228b70":"# creates efficientnet-b0 architecture\ndevice = torch.device(\"cuda:0\")\nmodel = timm.create_model('resnet101d', pretrained=True)\nmodel = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n# Loss function\ncriterion = torch.nn.CrossEntropyLoss()\n\nnum_epochs = args.epochs","92599cc6":"#Implementing a Cosine Annealing LR\nn_warmup_epochs = 10\nn_steps = len(trnloader)\n\nscheduler = CosineLRScheduler(\n            optimizer,\n            t_initial= num_epochs,\n            lr_min=0.000001,\n            warmup_lr_init=0.001,\n            warmup_t= n_warmup_epochs)","4cfd80d8":"since = time.time()\n\nlrls = []\nglobal_step = 0\nbeta = 1.0\n\nfor epoch in range(num_epochs):\n    print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(trnloader, total=int(len(trnloader)))\n    for step, batch in enumerate(tk0):\n        inputs = batch[0].to(device, dtype=torch.float)\n        labels = batch[1].to(device).long()\n        \n        ##Cosine LR\n        scheduler.step(global_step)\n        global_step += 1\n        lrls.append(optimizer.param_groups[0]['lr'])\n        \n        ####Mixup\n        lam = np.random.beta(beta, beta)\n        rand_index = torch.randperm(inputs.size()[0]).to(device) \n        # make an index which reorders the batch\n    \n        # Reorder the labels\n        labels_a = labels\n        labels_b = labels[rand_index]\n    \n        # Partially mixup up the batch\n        inputs_mixed = lam * inputs + (1 - lam) * inputs[rand_index]\n    \n        optimizer.zero_grad()\n        output = model(inputs_mixed)\n    \n        # Partial loss against original labels, partial loss against mixed up labels\n        loss = criterion(output, labels_a) * lam + criterion(output, labels_b) * (1. - lam)\n        \n        ####End Mixup\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        tk0.set_postfix(train_loss=(running_loss \/ (step+1)))\n        \n    valpreds = []\n    model.eval()\n    running_loss = 0.0\n    tkval = tqdm(valloader, total=int(len(valloader)))\n    for step, batch in enumerate(tkval):\n        inputs = batch[0].to(device, dtype=torch.float)\n        labels = batch[1].to(device).long()\n        with torch.no_grad():\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        valpreds .append(outputs)\n        running_loss += loss.item()\n        tkval.set_postfix(valid_loss=(running_loss \/ (step+1)))\n    preds = torch.cat(valpreds).argmax(1).detach().cpu().numpy()\n    print(f'Valid accuracy {(valdf.label.values == preds).mean():.4f}')\n    print(lrls[epoch])","3518477e":"# Submit \ntstpreds = []\ntktst = tqdm(tstloader, total=int(len(tstloader)))\nfor step, batch in enumerate(tktst):\n    inputs = batch[0].to(device, dtype=torch.float)\n    with torch.no_grad():\n        outputs = model(inputs)\n        tstpreds.append(outputs)\npredicted_labels = torch.cat(tstpreds).argmax(1).detach().cpu().numpy()\ntstdf['label'] = predicted_labels","c7ea9eba":"tstdf.filename = tstdf.filename.str.replace('test\/test\/', 'test\/')\ntstdf.to_csv('submission.csv', index = False)","4424b966":"tstdf.head()","1acf9744":"* Baseline Accuracy - Valid accuracy 0.9392 after 5 epochs\n* Change 1 - Valid accuracy 0.9497 after 10 epochs\n    - Cosine Annealing Scheduler - 2 warmup, min lr 0.00000\n    - epochs 20\n    - batch 48\n* Change 2 - Change 1 + Mixup Valid accuracy 0.9466 after 7 epochs\n    - beta = 1.0\n* Change 3 Change 2 + Valid accuracy 0.9615 after 60 Epochs\n    - initial lr 0.001\n    - added a blur p = 0.5\n* Change 4 Change 3 + Switch to Resnet 101d Valid accuracy 0.9619 after 10 Epochs 5:25 per epoch\n* Change 5 Chage 3 + Reduce batch size to 36\n   "}}