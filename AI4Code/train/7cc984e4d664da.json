{"cell_type":{"42ebd8e4":"code","cd5b8998":"code","a46bf881":"code","9cd87d9b":"code","93f06df4":"code","45a916f5":"code","3b77269a":"code","1141d5e5":"code","abf035d7":"code","d432aa5f":"code","92f14c83":"code","23e31e04":"code","30c390da":"code","678d4023":"code","407ebab9":"code","a1367aae":"code","09a76b97":"code","28a43629":"code","fc43ec46":"code","e44080cb":"code","aa681d4e":"code","cc7494a2":"markdown","eddeea65":"markdown","97f55c7a":"markdown","2639ffda":"markdown"},"source":{"42ebd8e4":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.data import Dataset as ds\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.cluster import KMeans\n\nfrom PIL import Image\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(0)\ntf.random.set_seed(0)","cd5b8998":"strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","a46bf881":"train = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntrain['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/train\/' + train['Id'] + '.jpg'\ntrain.head(3)","9cd87d9b":"test = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\ntest['path'] = '\/kaggle\/input\/petfinder-pawpularity-score\/test\/' + test['Id'] + '.jpg'","93f06df4":"def size_and_shape(row):\n    img = Image.open(row['path'])\n    return pd.Series([img.size[0], img.size[1], os.path.getsize(row['path'])])","45a916f5":"scale = MinMaxScaler()\n\ntrain[['width', 'height', 'size']] = pd.DataFrame(scale.fit_transform(train.apply(size_and_shape, axis=1).values))\ntest[['width', 'height', 'size']] = pd.DataFrame(scale.transform(test.apply(size_and_shape, axis=1).values))","3b77269a":"k = KMeans(8, random_state=0)\n\ntrain['cluster'] = k.fit_predict(train.drop(['Id', 'Pawpularity', 'path'], axis=1))\ntest['cluster'] = k.predict(test.drop(['Id', 'path'], axis=1))","1141d5e5":"p = PCA(random_state=0)\n\ntrain = train.join(pd.DataFrame(p.fit_transform(train.drop(['Id', 'Pawpularity', 'path'], axis=1))))\ntest = test.join(pd.DataFrame(p.transform(test.drop(['Id', 'path'], axis=1))))","abf035d7":"train, val= train_test_split(train, test_size=0.2, random_state=0)","d432aa5f":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 299\nBATCH_SIZE = 64","92f14c83":"train = train[['Pawpularity']].join(train.drop('Pawpularity', axis=1))\nval = val[['Pawpularity']].join(val.drop('Pawpularity', axis=1))","23e31e04":"def process_data(path, meta, augment=False, label=True):\n    img = tf.io.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, dtype=tf.float32)\n    img = tf.image.central_crop(img, 1.0)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = keras.applications.efficientnet.preprocess_input(img)\n    img = tf.cast(img, dtype=tf.float64)\n    \n    if augment:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_saturation(img, 0.9, 1.1)\n        img = tf.image.random_contrast(img, 0.9, 1.1)\n        \n    if label:\n        return (img, meta[1:]), meta[0]\n    return (img, meta), 0","30c390da":"# train_ds = tf.data.Dataset.from_tensor_slices((train['path'], train.drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n# val_ds = tf.data.Dataset.from_tensor_slices((val['path'], val.drop(['path', 'Id'], axis=1).astype(float))).map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\ntest_ds = ds.from_tensor_slices((test['path'], test.drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, False, False)).batch(BATCH_SIZE).prefetch(AUTOTUNE)","678d4023":"eff_model = keras.models.load_model('\/kaggle\/input\/keras-applications-models\/Xception.h5')\neff_model.trainable = False\n\ndef get_model():\n    img_input = tfl.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    meta_input = tfl.Input(shape=(32,))\n\n    X = eff_model(img_input)\n    X = tfl.BatchNormalization()(X)\n\n    con = tfl.concatenate([X, meta_input])\n\n    X = tfl.Dense(64, activation='relu')(con)\n    X = tfl.Dense(64, activation='relu')(X)\n    \n    X = tfl.Dropout(0.3)(X)\n\n    out = tfl.Dense(1)(X)\n\n    model = keras.Model(inputs=[img_input, meta_input], outputs=out)\n    \n    return model","407ebab9":"model = get_model()","a1367aae":"tf.keras.utils.plot_model(model, show_shapes=True)","09a76b97":"k = 5\nfold = KFold(k,shuffle=True)","28a43629":"models = []\nhistories = []\n\nfor i, (t_ids, v_ids) in enumerate(fold.split(train)):\n    \n    keras.backend.clear_session()\n\n    print(\"\\n\\n===========================================================================================\\n\")\n    train_ds = ds.from_tensor_slices((train.iloc[t_ids]['path'], train.iloc[t_ids].drop(['path', 'Id'], axis=1).astype(float))).map(lambda x,y: process_data(x, y, True)).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    val_ds = ds.from_tensor_slices((train.iloc[v_ids]['path'], train.iloc[v_ids].drop(['path', 'Id'], axis=1).astype(float))).map(process_data).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    model = get_model()\n    \n    early_stop = keras.callbacks.EarlyStopping(\n        patience=3,\n        restore_best_weights=True)\n\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-3,\n        decay_steps=1000,\n        decay_rate=0.9,\n        staircase=True)\n    \n    model.compile(keras.optimizers.Adam(learning_rate=lr_schedule), \n            loss='mse', \n            metrics=[keras.metrics.RootMeanSquaredError()])\n    \n    history = model.fit(train_ds,\n                   validation_data=val_ds,\n                   epochs=20,\n                   callbacks=[early_stop])\n    \n    models.append(model)\n    histories.append(history)","fc43ec46":"# preds = model.predict(test_ds)\npreds = models[0].predict(test_ds)\/k\n\nfor i in range(1,k):\n    preds += models[i].predict(test_ds)\/k","e44080cb":"preds","aa681d4e":"test['Pawpularity'] = preds\ntest[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)","cc7494a2":"### Read data","eddeea65":"### Feature Engineering","97f55c7a":"### Import libraries","2639ffda":"### Build the model"}}