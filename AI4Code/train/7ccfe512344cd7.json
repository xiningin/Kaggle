{"cell_type":{"4c610561":"code","7c635161":"code","505c179e":"code","0bf97358":"code","55fdc2e2":"code","6a1882a5":"code","7a5d17e6":"code","19e79d93":"code","eca1f331":"code","6787d611":"code","073bf032":"code","6c889370":"code","faa872c7":"code","19e02454":"code","a2e382e4":"code","74102821":"code","71e999e3":"markdown","e5355b61":"markdown"},"source":{"4c610561":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom nltk import word_tokenize\n\nimport os, re\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7c635161":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain.head()","505c179e":"### function to clean text (remove punctuation, links, lowercase all letters, etc)\ndef clean_text(text):\n    temp = text.lower()\n    temp = re.sub('\\n', \" \", temp)\n    temp = re.sub('\\'', \"\", temp)\n    temp = re.sub('-', \" \", temp)\n    temp = re.sub(r\"(http|https|pic.)\\S+\",\" \",temp)\n    temp = re.sub(r'[^\\w\\s]',' ',temp)\n    \n    return temp\n\n### list of stop words that need to be removed\nstop_words = ['as', 'in', 'of', 'is', 'are', 'were', 'was', 'it', 'for', 'to', 'from', 'into', 'onto', \n              'this', 'that', 'being', 'the','those', 'these', 'such', 'a', 'an']\n### function to remove unnecessary words\ndef remove_stopwords(text):\n    tokenized_words = word_tokenize(text)\n    temp = [word for word in tokenized_words if word not in stop_words]\n    temp = ' '.join(temp)\n    return temp\n\n### We save the cleaned and normalized texts in the new column, called 'clean'\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\ntrain['clean']","0bf97358":"def combine_attributes(text, keyword):\n    var_list = [text, keyword]\n    combined = ' '.join(x for x in var_list if x)\n    return combined\n\ntrain.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)","55fdc2e2":"X = train['combine']\ny = train['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)","6a1882a5":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","7a5d17e6":"from sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\n\nclf = SVC(kernel='linear')\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","19e79d93":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)","eca1f331":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, y_pred)","6787d611":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ntest.head()","073bf032":"### apply preprocessing on train data\ntrain['clean'] = train['text'].apply(clean_text)\ntrain['clean'] = train['clean'].apply(remove_stopwords)\n\n### apply preprocessing on test data\ntest['clean'] = test['text'].apply(clean_text)\ntest['clean'] = test['clean'].apply(remove_stopwords)","6c889370":"train.fillna('', inplace=True)\ntrain['combine'] = train.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)\n\ntest.fillna('', inplace=True)\ntest['combine'] = test.apply(lambda x: combine_attributes(x['clean'], x['keyword']), axis=1)","faa872c7":"X_train = train['combine']\ny_train = train['target']\n\nX_test = test['combine']","19e02454":"vectorizer = TfidfVectorizer()\n\nX_train_vect = vectorizer.fit_transform(X_train)\nX_test_vect = vectorizer.transform(X_test)","a2e382e4":"clf = SVC(kernel='linear')\nclf.fit(X_train_vect, y_train)\n\ny_pred = clf.predict(X_test_vect)","74102821":"result = pd.DataFrame({'id':test['id'], 'target':y_pred})\nresult.to_csv('svm_submission.csv', index=False)\n","71e999e3":"# Train and Create Submission","e5355b61":"# Test the Data using Accuracy"}}