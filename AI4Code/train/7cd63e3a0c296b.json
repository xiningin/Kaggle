{"cell_type":{"8ce44f51":"code","5ab76497":"code","744157ab":"code","c7502552":"code","429b88eb":"code","a9a1f788":"code","cf130ac5":"code","85576ad8":"markdown","8d94250f":"markdown","aa09a1aa":"markdown","3bc7cc39":"markdown","c4ee27b9":"markdown","e238fd63":"markdown"},"source":{"8ce44f51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom kaggle.competitions import nflrush\n\nimport io\nimport re\nfrom pprint import pprint\nimport numpy as np\nimport pandas as pd\nimport tensorflow\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom keras.engine.saving import load_model\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD, Adam\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport multiprocessing\nfrom keras import backend as F","5ab76497":"env = nflrush.make_env()\ntrain_df = pd.read_csv('\/kaggle\/input\/nfl-big-data-bowl-2020\/train.csv', low_memory=False)","744157ab":"def generate_categorical_encoders(train, features):\n    encoders = {}\n    for feature in features:\n        train[feature] = train[feature].fillna('missing')\n        encoder = LabelEncoder()\n        encoder.fit(train[feature].values)\n        le_dict = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n        encoders[feature] = le_dict\n    return encoders\n\n\ndef encode_categorical_features(df, features, encoders):\n    for f in features:\n        df[f] = df[f].fillna('missing')\n        df[f] = df[f].map(encoders[f])\n\ndef aggreate_by_play(df, configs):\n    df = df.sort_values('PlayId')\n    agg_df = pd.DataFrame({\n        'PlayId': list(df['PlayId'].unique())\n    }).sort_values('PlayId')\n    # TODO aggerate with a sliding window\n    for config in configs:\n        feature = config[0]\n        if feature == 'PlayId' or feature not in df.columns:\n            continue\n        gy = df.groupby('PlayId')\n        for agg_func in config[2]:\n            if agg_func == 'first':\n                agg_df[feature] = gy[feature].agg(agg_func).values\n            else:\n                agg_df[f'{feature}_{agg_func}'] = gy[feature].agg(agg_func).values\n    return agg_df\n\nclass Metric(Callback):\n    def __init__(self, model, callbacks, data):\n        super().__init__()\n        self.model = model\n        self.callbacks = callbacks\n        self.data = data\n\n    def on_train_begin(self, logs=None):\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs=None):\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n    def on_epoch_end(self, batch, logs=None):\n        X_train, y_train = self.data[0][0], self.data[0][1]\n        y_pred = self.model.predict(X_train)\n        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) \/ (199 * X_train.shape[0])\n        logs['tr_CRPS'] = tr_s\n\n        X_valid, y_valid = self.data[1][0], self.data[1][1]\n\n        y_pred = self.model.predict(X_valid)\n        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) \/ (199 * X_valid.shape[0])\n        logs['val_CRPS'] = val_s\n        print('tr CRPS', tr_s, 'val CRPS', val_s)\n\n        for callback in self.callbacks:\n            callback.on_epoch_end(batch, logs)\n\n\nclass Gambler():\n    def __init__(self, input_size):\n        super().__init__()\n        self.input_size = input_size\n        self.models = {}\n        self.scalers = {}\n\n    def construct_model(self):\n        opm = Adam(learning_rate=0.001)\n        # opm = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n        model = Sequential([\n            Dense(128, input_shape=(self.input_size,)),\n            Activation('relu'),\n            Dense(64),\n            Activation('relu'),\n            Dense(199),\n            Activation('softmax'),\n        ])\n\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=opm,\n                      metrics=[])\n        return model\n\n    def train(self, X_train, X_valid, y_train, y_valid, fold):\n        self.models[fold] = self.construct_model()\n\n        self.scalers[fold] = StandardScaler()\n        X_train = self.scalers[fold].fit_transform(X_train)\n        X_valid = self.scalers[fold].transform(X_valid)\n\n        es = EarlyStopping(monitor='val_CRPS',\n                           mode='min',\n                           restore_best_weights=True,\n                           verbose=2,\n                           patience=5)\n        es.set_model(self.models[fold])\n        metric = Metric(self.models[fold], [es], [(X_train, y_train), (X_valid, y_valid)])\n        self.models[fold].fit(X_train, y_train,\n                              verbose=0,\n                              callbacks=[metric],\n                              epochs=1000, batch_size=128)\n\n    def predict(self, X, fold):\n        X = self.scalers[fold].transform(X)\n        preds = self.models[fold].predict(X)\n        return preds\n    \n    def predict_final(self, X):\n        final = None\n        for fold in self.models.keys():\n            preds = self.predict(X, fold)\n            if final is None:\n                final = preds \/ (len(self.models.keys()))\n            else:\n                final += preds \/ (len(self.models.keys()))\n        return final\n\ndef train_loop(gambler, df, num_folds):\n    spliter = KFold(n_splits=num_folds)\n    oof_predictions = np.zeros((df.shape[0], 199))\n    oof_targets = np.zeros((df.shape[0], 199))\n    oof_ids = np.zeros(df.shape[0])\n    fold = 0\n    for train_index, valid_index in spliter.split(df):\n        print('###', fold, '###')\n        dataset_train = df.loc[train_index].copy()\n        dataset_valid = df.loc[valid_index].copy()\n\n        X_train = dataset_train[useful_raw_features].copy().fillna(-10)\n        X_valid = dataset_valid[useful_raw_features].copy().fillna(-10)\n\n        # get targets\n        targets = dataset_train['Yards']\n        y_train = np.zeros((targets.shape[0], 199))\n        for idx, target in enumerate(list(targets)):\n            y_train[idx][99 + target] = 1\n\n        targets = dataset_valid['Yards']\n        y_valid = np.zeros((targets.shape[0], 199))\n        for idx, target in enumerate(list(targets)):\n            y_valid[idx][99 + target] = 1\n\n        gambler.train(X_train, X_valid, y_train, y_valid, fold)\n    \n        oof_predictions[valid_index] = gambler.predict(X_valid, fold)\n        oof_targets[valid_index] = y_valid\n        oof_ids[valid_index] = dataset_valid['PlayId'].values\n        fold += 1\n    return oof_ids, oof_predictions, oof_targets","c7502552":"raw_feature_configs = [\n    ('GameId', 2, ['first']),\n    ('PlayId', 2, ['first']),\n    ('Team', 2, ['first']),\n    ('X', 0, ['max', 'mean', 'std']),\n    ('Y', 0, ['max', 'mean', 'std']),\n    ('S', 0, ['max', 'mean', 'std']),\n    ('A', 0, ['max', 'mean', 'std']),\n    ('Dis', 0, ['mean']),\n    ('Orientation', 0, ['mean']),\n    ('Dir', 0, ['mean']),\n    # ('NflId', 1, ['expand']),\n    # ('DisplayName', 2, []),\n    # ('JerseyNumber', 2, []),\n    ('Season', 1, ['first']),\n    ('YardLine', 0, ['mean']),\n    # ('Quarter', 1, ['first']),\n    ('GameClock', 0, ['first']),\n    ('PossessionTeam', 1, ['first']),\n    ('Down', 2, ['first']),\n    ('Distance', 0, ['first']),\n    ('FieldPosition', 1, ['first']),\n    ('HomeScoreBeforePlay', 2, ['first']),\n    ('VisitorScoreBeforePlay', 2, ['first']),\n    ('NflIdRusher', 1, ['first']),\n    # ('OffenseFormation', 1, ['first']),\n    # ('OffensePersonnel', 1, ['first']),\n    ('DefendersInTheBox', 0, ['first']),\n    # ('DefensePersonnel', 1, ['first']),\n    ('PlayDirection', 2, ['first']),\n    # ('TimeHandoff', 2, []),\n    ('TimeSnap', 2, ['first']),\n    # ('PlayerHeight', 0, ['mean', 'max', 'min', 'std']),\n    ('PlayerWeight', 0, ['mean', 'max', 'min', 'std']),\n    ('PlayerBirthDate', 2, []),\n    ('PlayerCollegeName', 2, []),\n    ('HomeTeamAbbr', 1, ['first']),\n    ('VisitorTeamAbbr', 1, ['first']),\n    ('Week', 0, ['first']),\n    ('Stadium', 1, ['first']),\n    ('Location', 1, ['first']),\n    ('StadiumType', 2, ['first']),\n    ('Turf', 1, ['first']),\n    ('GameWeather', 1, ['first']),\n    ('Temperature', 0, ['first']),\n    ('Humidity', 0, ['first']),\n    ('WindSpeed', 0, ['first']),\n    ('WindDirection', 1, ['first']),\n    ('Yards', 2, ['first']),\n]\n","429b88eb":"train_df['GameClock'] = train_df['GameClock'].str.replace(':', '').astype(int)\ntrain_df['Age'] = [2019 - int(v.split('\/')[2]) for v in train_df['PlayerBirthDate'].values]\nraw_feature_configs.append(('Age', 0, ['mean', 'min', 'max']))","a9a1f788":"play_df = aggreate_by_play(train_df, raw_feature_configs)\n\nunuse_features = [f[0] for f in raw_feature_configs if f[1] == 2]\nuseful_raw_features = [f for f in play_df.columns if f not in unuse_features]\ncategorical_features = [f for f in play_df.columns if\n                        str(play_df[f].dtype) == 'object' and f not in unuse_features]\n\nencoders = generate_categorical_encoders(play_df, categorical_features)\nencode_categorical_features(play_df, categorical_features, encoders)\n\ngambler = Gambler(len(useful_raw_features))\noof_ids, oof_predictions, oof_targets = train_loop(gambler, play_df, 5)\n\noof_targets = np.clip(np.cumsum(oof_targets, axis=1), 0, 1)\noof_predictions = np.clip(np.cumsum(oof_predictions, axis=1), 0, 1)\n\noof_score = ((oof_predictions - oof_targets) ** 2) \\\n                .sum(axis=1).sum(axis=0) \/ (199 * oof_targets.shape[0])\nprint('out of fold score', oof_score)\n","cf130ac5":"from tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\n\ncount = 0\nwith tqdm_notebook(total=3438) as pbar:\n    for (test_df, sample_prediction_df) in (env.iter_test()):\n        test_df['GameClock'] = test_df['GameClock'].str.replace(':', '').astype(int)\n        test_df['Age'] = [2019 - int(v.split('\/')[2]) for v in test_df['PlayerBirthDate'].values]\n        \n        play_df = aggreate_by_play(test_df, raw_feature_configs)\n        encode_categorical_features(play_df, categorical_features, encoders)\n        play_df = play_df[useful_raw_features].fillna(-10)\n\n        # for visualization\n        if count % 170 == 0:\n            p_fold_0 = gambler.predict(play_df, 0)\n            fp_fold_0 = np.clip(np.cumsum(p_fold_0, axis=1), 0, 1)\n\n            p_fold_1 = gambler.predict(play_df, 1)\n            fp_fold_1 = np.clip(np.cumsum(p_fold_1, axis=1), 0, 1)\n\n            p_fold_2 = gambler.predict(play_df, 2)\n            fp_fold_2 = np.clip(np.cumsum(p_fold_2, axis=1), 0, 1)\n\n            p_fold_3 = gambler.predict(play_df, 3)\n            fp_fold_3 = np.clip(np.cumsum(p_fold_3, axis=1), 0, 1)\n\n            p_fold_4 = gambler.predict(play_df, 4)\n            fp_fold_4 = np.clip(np.cumsum(p_fold_4, axis=1), 0, 1)\n            \n            p_fold_mean = gambler.predict_final(play_df)\n            fp_fold_mean = np.clip(np.cumsum(p_fold_mean, axis=1), 0, 1)\n            \n            fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n\n            pd.Series(p_fold_0[0]).plot(ax=axes[0,0])\n            pd.Series(p_fold_1[0]).plot(ax=axes[0,0])\n            pd.Series(p_fold_2[0]).plot(ax=axes[0,0])\n            pd.Series(p_fold_3[0]).plot(ax=axes[0,0])\n            pd.Series(p_fold_4[0]).plot(ax=axes[0,0])\n            pd.Series(p_fold_mean[0]).plot(ax=axes[0,1])\n            pd.Series(fp_fold_mean[0]).plot(ax=axes[1,0])\n            fig.suptitle(f'Prediction {count}, with PlayId {test_df[\"PlayId\"].iloc[0]}')\n            axes[0][0].set_title('Softmax outputs of 5 folds')\n            axes[0][1].set_title('Mean of softmax outputs of 5 folds')\n            axes[1][0].set_title('Cum. Sum of the mean of softmax outputs of 5 folds')\n            plt.show()\n            \n            \n        # prediction\n        p = gambler.predict_final(play_df)\n        p = np.clip(np.cumsum(p, axis=1), 0, 1)\n        # submission\n        submission_df = pd.DataFrame(data=p, columns=sample_prediction_df.columns)\n        env.predict(submission_df)\n        pbar.update(1)\n        count += 1\n        \nenv.write_submission_file()","85576ad8":"# Main Functions","8d94250f":"# Keras Starter & Metric CRPS & Early Stopping \ud83d\ude80\n\n**Intro:**\n1. Only have done some naive aggregations by PlayId\n2. Fully Connected NN\n3. Cum Sum the Softmax output and clip to 0,1\n4. Early Stopping Support for CRPS and restoring back to the \"best\" weights\n5. A Scalable codebase that allows you to edid\n6. Please **Upvote** this kernel! \ud83d\udc4d\ud83c\udffb","aa09a1aa":"# Model Training + Validation","3bc7cc39":"# Feature Engineering","c4ee27b9":"# Test Prediction & Probability Distribution Visualization","e238fd63":"# Aggreation Configs"}}