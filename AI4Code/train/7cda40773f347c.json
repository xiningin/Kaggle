{"cell_type":{"cee2d5eb":"code","9770444b":"code","8ef54bc8":"code","e7e55ac1":"code","168439c0":"code","1f4e3713":"markdown"},"source":{"cee2d5eb":"import os\nimport numpy as np\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model, load_model\nimport matplotlib.pyplot as plt\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","9770444b":"def predictor(model_path,image_path, img_size, scalar, offset, verbose, class_list):\n    if verbose:\n        print('Loading model this may take up to 15 seconds')\n    model=load_model(model_path)\n    img=plt.imread(image_path)\n    display_img=img\/255.0\n    img=cv2.resize(img, img_size)\n    img=img\/scalar + offset\n    img=np.expand_dims(img, axis=0)\n    prediction=model.predict(img)\n    index=np.argmax(prediction)\n    prob=prediction[0][index] * 100\n    klass=class_list[index]\n    if verbose:\n        plt.axis('off') \n        title=f'{klass} - {prob:5.2f} %'\n        plt.title(title, color='green', fontsize=18)\n        plt.imshow(display_img) \n    return klass,prob, display_img","8ef54bc8":"image_path=r'..\/input\/musical-instruments-image-classification\/test\/acordian\/1.jpg'\nmodel_path=r'..\/input\/musical-instruments-image-classification\/EfficientNetB3-instruments-99.33.h5'\nimg_size=(224,224)\nscalar=1 # EfficientNet expects pixels in range 0 to 255\noffset=0 # no offset required for EfficienNet models\nverbose=1 # display results of prediction\nclasses=['Didgeridoo', 'Tambourine', 'Xylophone', 'acordian', 'alphorn', 'bagpipes', 'banjo', 'bongo drum',\n         'casaba', 'castanets', 'clarinet', 'clavichord', 'concertina', 'drums', 'dulcimer', 'flute',\n         'guiro', 'guitar', 'harmonica', 'harp', 'marakas', 'ocarina', 'piano', 'saxaphone', 'sitar', \n         'steel drum', 'trombone', 'trumpet', 'tuba', 'violin']\nklass,prob, display_img=predictor(model_path,image_path, img_size, scalar, offset, verbose, classes)","e7e55ac1":"### example with verbose=False","168439c0":"verbose=False\nklass,prob, display_img=predictor(model_path,image_path, img_size, scalar, offset, verbose, classes)\ntitle=f'{klass} - {prob:5.2f} %'\nplt.title(title, color='green', fontsize=18)\nplt.imshow(display_img) ","1f4e3713":"The predictor function predicts a single image using a trained model the call is\n - klass,prob, display_img=predictor( model_path,image_path, img_size, scalar, offset, verbose, class_list)   \n **where:**\n - **model_path** is the path to the stored model  \n - **image_path** is the full path to the image.      \n - **image_size** is a tupple of the image size the model was trained on\n - **scalar** is a float rpresenting the scale factor pixels were divided by in the trained model\n              for EfficientNet models scalar =1 as it accepts pixel in the range 0 to 255 and offset=0\n              for many models pixels are scaled in the range -1 to +1 so scalar is 127.5\n                  and the offset value is -1\n              for models trained on pixels in the range 0 to 1 scalar=255 and the offset is 0\n - **offset** is a float representing the pixel offset value\n - **verbose** is a boolean. \n               If True the image is displayed with the title of the image as the class\n               and the prediction probability\n - **class_list** is an ordered list of class names.\n               You can get the class_list in various ways\n                The best way is in the classification kernel have the code\n                classes=list(train_gen.class_indices.keys()) where train_gen is the train \n                print(classes). Then copy this printed list and use it as the class_list\nThe function returns\n - **klass** - the predict class name\n - **prob** - the predicted probability for the image being in the predicted class\n - **display_img** the image resulting from reading in the file_path.\n                   Note this image has pixels in the range 0 to 1 and is NOT resized\n"}}