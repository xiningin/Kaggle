{"cell_type":{"3038c270":"code","5b1fe0e2":"code","8e6d4247":"code","dbf73b57":"code","ffe8e874":"code","b9cfeada":"code","51265609":"code","43b2f004":"code","9b784e9f":"code","598fb453":"code","845c3153":"code","68fb769a":"code","40db64bf":"code","e7467075":"code","041f4bd6":"code","c36914b6":"code","db67de36":"code","9bd77c47":"code","6e06c819":"markdown","62300277":"markdown","892d3b42":"markdown","849f8acc":"markdown","d75ad879":"markdown","d44c1734":"markdown","4af60e5c":"markdown","02143bed":"markdown"},"source":{"3038c270":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b1fe0e2":"class SimpleLinearRegression:\n    def __init__(self):\n        pass\n       \n    def fit(self, x, y):\n        self.independent = x\n        self.dependent = y\n        \n        self.Mx = np.mean(x)\n        self.My = np.mean(y)\n\n        self.SSx = sum((x-self.Mx)**2)\n        self.SSy = sum((y-self.My)**2)\n        self.SP = sum((x-self.Mx)*(y-self.My))\n\n        self.a = self.SP\/self.SSx\n        self.b = self.My - (self.a*self.Mx)\n        self.r = round(self.SP \/ np.sqrt(self.SSx * self.SSy), 3)\n        self.xi = (self.b*-1) \/ self.a\n       \n    def predict(self, x, dplaces=3):\n        try:\n            return round(self.a*x+self.b, dplaces)\n        except:\n            return np.around(self.a*x+self.b, dplaces)\n   \n    def geteq(self):\n        return 'y = {0}x + {1}'.format(self.a,self.b)","8e6d4247":"model = SimpleLinearRegression()","dbf73b57":"import matplotlib.pyplot as plt\nimport seaborn as sns","ffe8e874":"data = pd.read_csv('..\/input\/random-linear-regression\/train.csv')\ntest = pd.read_csv('..\/input\/random-linear-regression\/test.csv')","b9cfeada":"data[data['y'].isnull() == True]","51265609":"data.drop(213, axis=0, inplace=True)","43b2f004":"x = np.array(data['x'])\ny = np.array(data['y'])","9b784e9f":"model.fit(x, y)","598fb453":"model.r","845c3153":"model.geteq(), model.xi","68fb769a":"yeq = 1.0006563818563046*x + -0.10726546430100825","40db64bf":"sns.set_theme(style='whitegrid')\nplt.figure(figsize=(32,18))\nplt.scatter(x,y, color='b', marker='+')\nplt.plot(x, yeq, color='r')\nplt.title('Regression Line with Scatter')\nplt.ylabel('Dependent')\nplt.xlabel('Independent')\nplt.axis('scaled')\nplt.show()","e7467075":"tx = np.array(test['x'])","041f4bd6":"tx","c36914b6":"preds = model.predict(tx)","db67de36":"from sklearn.metrics import mean_absolute_error as mae\n\nmae(y_true=test['y'], y_pred=preds)","9bd77c47":"output = pd.DataFrame({'x': tx, 'y': preds})\n\noutput.to_csv('predictions.csv', index=False)","6e06c819":"The mean absolute error for the linear regression model is very low, indicating that the least squares regression line is accurate.","62300277":"Define bivariate linear regression class. The code for this can be seen at [https:\/\/github.com\/manmadetomcat\/Simple-Linear-Regression](http:\/\/)","892d3b42":"The equation (rounded to two decimal places) is y = x - 0.11. The y-intercept of this line is -0.1 and the x-intercept is 0.1. A scatter plot with a regression line can be used to check our equation.","849f8acc":"# Checking the least squares regression line","d75ad879":"# Predicting with the test set","d44c1734":"The product moment correlation coefficient is 0.995  which suggests that we have a very strong positive correlation between x and y.","4af60e5c":"# Plotting and calculating the equation","02143bed":"# Defining the Linear Regressor"}}