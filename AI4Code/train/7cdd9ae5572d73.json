{"cell_type":{"3313ee7b":"code","ec42ee79":"code","e4a861b3":"code","475e6b1e":"code","1522ed6d":"code","e53d45e9":"code","9351b518":"code","84aabe53":"code","c3f231d5":"code","f0b7e968":"code","b798fb9c":"code","4cc2596c":"code","a2e7a7c8":"code","81efb5ad":"code","bb746ee3":"code","997b42a3":"code","e6d707c6":"code","64676917":"code","ce8c9e46":"code","51b5f46f":"code","d4365782":"code","12212cb2":"code","0fd227b8":"code","7b4de749":"code","3395892d":"code","3133def4":"code","297c5b45":"code","6908f4d5":"code","99cbf57e":"code","6b0590d5":"code","89dda2ed":"code","b0f5bb98":"code","bf00adb1":"code","6290043b":"code","a9899bc2":"code","0f7b1182":"code","c12be01f":"code","ed02c334":"code","5ec839cd":"code","d8630569":"code","b99355c4":"code","4f7aefeb":"code","abd22841":"code","fbfbf44a":"code","5b5dacce":"code","64b71eed":"code","ad49e36d":"code","3dbcc09a":"code","0bfa77cb":"code","388f2a83":"code","c9f18e01":"code","f93f45ee":"code","68c5635e":"code","3276e7de":"code","11273c51":"code","af7fd58a":"code","8e857e91":"code","ff4cacb3":"code","227aa61c":"markdown","164c0bc1":"markdown","12788e3b":"markdown","7c4c5c63":"markdown","fde37b22":"markdown","ce9e3db3":"markdown","01cb7f84":"markdown","ad2284b3":"markdown","2da68d01":"markdown","e25c92b8":"markdown","7e03de86":"markdown","4b29c526":"markdown","3ebab3b2":"markdown","5b1bbf1a":"markdown","5728d07d":"markdown","21255fd6":"markdown","dc1e508d":"markdown","c4a47bde":"markdown","cef3c4e6":"markdown","29b00442":"markdown","b027996b":"markdown","0f403f0a":"markdown","2ef650e7":"markdown","30e09802":"markdown","d3ba6c56":"markdown","d6d90713":"markdown","51d12785":"markdown","6a46a24f":"markdown","b5d23333":"markdown","89cf6701":"markdown","5109e07a":"markdown","814d318f":"markdown","092fcacf":"markdown","be660419":"markdown","a84d3d2a":"markdown","34400517":"markdown","debdf4b9":"markdown","644714fa":"markdown","cdeca81d":"markdown","1f0475a3":"markdown","b4c520e8":"markdown","6c449923":"markdown","f1260597":"markdown","db5d98d8":"markdown","ca43fd0c":"markdown","dc19e0ea":"markdown","4fb6db5b":"markdown","5855976c":"markdown","fb35c70e":"markdown","741b6bad":"markdown"},"source":{"3313ee7b":"%%HTML\n<style type=\"text\/css\">\ndiv.h1 {\n    background-color:#eebbcb; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 35px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 50px;\n}\n\ndiv.h2 {\n    background-color:#2ca9e1; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 35px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 50px;\n}\n<\/style>","ec42ee79":"import gc\nimport glob\nfrom itertools import chain\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom tqdm import tqdm\nimport seaborn as sns","e4a861b3":"!ls ..\/input\/predict-volcanic-eruptions-ingv-oe\/","475e6b1e":"train = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv\")\nsample_submission = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv\")","1522ed6d":"segment_csvs = glob.glob(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/*\")\nsegment_csvs_test = glob.glob(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/test\/*\")","e53d45e9":"segment_csvs[0:10]","9351b518":"print(\"Number of files under train\/ is:\", len(segment_csvs))\nprint(\"Number of files under test\/ is:\", len(segment_csvs_test))\n\nduplicated_segment_id = [segment_id for segment_id in [ test_segment_id.split(\"\/\")[-1] for test_segment_id in segment_csvs_test]\n                         if (segment_id in [ train_segment_id.split(\"\/\")[-1] for train_segment_id in segment_csvs])]\n\nprint(\"Segment ids both in train and test are:\", duplicated_segment_id)","84aabe53":"train_379022420 = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/379022420.csv\")\ntrain_1002275321 = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/1002275321.csv\")","c3f231d5":"train.head()","f0b7e968":"train.info()","b798fb9c":"sample_submission.head()","4cc2596c":"sample_submission.info()","a2e7a7c8":"train_379022420.head()","81efb5ad":"train_379022420.info()","bb746ee3":"train_1002275321.head()","997b42a3":"train_1002275321.info()","e6d707c6":"g = sns.distplot(train[\"time_to_eruption\"],  kde=False, rug=False, color=\"r\")\ng.set_title(\"distribution of time_to_eruption of train data\")","64676917":"def crete_lineplot(segment_id):\n    df = pd.read_csv(f\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{segment_id}.csv\")    \n    graphs = []\n\n    for i in range(0, 9 , 5):\n        idxs = list(np.array([0, 1, 2, 3, 4]) + i)\n\n        fig, axs = plt.subplots(1, 5, sharey=True)\n        for k, item in enumerate(idxs):\n            g = sns.lineplot(data=df[f\"sensor_{item+1}\"], ax=axs[k], color=\"g\")\n            g.set_title(f\"sensor: {item+1}\")\n            g.set(ylim=(-10000, 10000))\n            graphs.append(g)","ce8c9e46":"crete_lineplot(379022420)","51b5f46f":"fig = plt.figure(figsize=(10, 5))\ndf_379022420 = pd.read_csv(f\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/379022420.csv\") \nboxplot = df_379022420.boxplot(column=[f'sensor_{i}' for i in range(1,11)])","d4365782":"def tidying_df(df):\n    df_tidying = pd.DataFrame(columns=[\"value\", \"sensor\"])\n\n    for i in range(1, (df_379022420.shape[1]+1) ):\n        df_sensor = df_379022420[[f\"sensor_{i}\"]].copy()\n        df_sensor.columns = [\"value\"]\n        df_sensor[\"sensor\"] = f\"sensor_{i}\"\n    \n        df_tidying = pd.concat([df_tidying, df_sensor], axis=0, ignore_index=True)\n\n    return df_tidying","12212cb2":"df_379022420_tidy = tidying_df(df_379022420)","0fd227b8":"df_379022420_tidy.head()","7b4de749":"fig = plt.figure(figsize=(10, 5))\nsns.violinplot(data=df_379022420_tidy, x=\"sensor\" , y=\"value\")","3395892d":"train[train[\"segment_id\"] == 379022420]","3133def4":"def crete_distplot(segment_id):\n    df = pd.read_csv(f\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{segment_id}.csv\")    \n    graphs = []\n\n    for i in range(0, 9 , 5):\n        idxs = list(np.array([0, 1, 2, 3, 4]) + i)\n\n        fig, axs = plt.subplots(1, 5, sharey=True)\n        for k, item in enumerate(idxs):\n            g = sns.distplot(df[f\"sensor_{item+1}\"], ax=axs[k], color=\"y\")\n            g.set_title(f\"sensor: {item+1}\")\n            g.set(ylim=(0, 0.0025))\n            graphs.append(g)","297c5b45":"crete_distplot(379022420)","6908f4d5":"sns.pairplot(df_379022420)","99cbf57e":"train[train[\"time_to_eruption\"] < 60000]","6b0590d5":"def crete_lineplot_with_supplementarywire(segment_id, xs):\n    df = pd.read_csv(f\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{segment_id}.csv\")    \n    graphs = []\n\n    for i in range(0, 9 , 5):\n        idxs = list(np.array([0, 1, 2, 3, 4]) + i)\n\n        fig, axs = plt.subplots(1, 5, sharey=True)\n        for k, item in enumerate(idxs):\n            g = sns.lineplot(data=df[f\"sensor_{item+1}\"], ax=axs[k])\n            \n            for supplementarywire_x in xs:\n                axs[k].plot([supplementarywire_x, supplementarywire_x], [-10000, 10000], c='r', ls='--')\n            g.set_title(f\"sensor: {item+1}\")\n            g.set(ylim=(-10000, 10000))\n            graphs.append(g)","89dda2ed":"crete_lineplot_with_supplementarywire(1658693785, [1300, 27000])","b0f5bb98":"crete_lineplot_with_supplementarywire(1626437563, [13000, 53000])","bf00adb1":"def count_outlier(df, j):\n    q1 = np.percentile(df[f\"sensor_{j}\"], 25, axis=0)\n    q3 = np.percentile(df[f\"sensor_{j}\"], 75, axis=0)\n    \n    max = 2.5*q3 - 1.5*q1\n    min = -0.5*q3 - 1.5*q1\n    \n    return (len(df[f\"sensor_{j}\"][df[f\"sensor_{j}\"]  > max] + len(df[f\"sensor_{j}\"][df[f\"sensor_{j}\"]  < min])))","6290043b":"!ls ..\/input\/ingv-sensor-processed","a9899bc2":"#for i, segment_id in tqdm(enumerate(train[\"segment_id\"])):\n#    df_segment_id = pd.read_csv(f\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{segment_id}.csv\").fillna(0)\n#    \n#    for j in range(10):\n#        train.loc[i, f\"sensor_{j+1}_max\"] = np.max(df_segment_id.fillna(0), axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_min\"] = np.min(df_segment_id.fillna(0), axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_mean\"] = np.mean(df_segment_id.fillna(0), axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_var\"] = np.var(df_segment_id.fillna(0), axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_75_percentile\"] = np.percentile(df_segment_id, 75, axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_95_percentile\"] = np.percentile(df_segment_id, 95, axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_99_percentile\"] = np.percentile(df_segment_id, 99, axis=0)[j]\n#        train.loc[i, f\"sensor_{j+1}_outlier\"] = count_outlier(df_segment_id, j+1)\n#        train.loc[i, f\"sensor_{j+1}_null\"] = 1 if df_segment_id.isnull().any()[j] else 0\n\n#To save memory, I use processed data in my other notebook. \n#If you want to reproduce data processing, remove above comment outs\ntrain = pd.read_csv(\"..\/input\/ingv-sensor-processed\/train_preprocessed.csv\")","0f7b1182":"train.head()","c12be01f":"def plot_with_plotly(df, value):\n    \"\"\"value: max, min, mean or var\"\"\"\n    fig = make_subplots(rows=5, cols=2)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_1_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_1_{value}\",\n        mode=\"markers\"\n    ), row=1, col=1)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_2_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_2_{value}\",\n        mode=\"markers\"\n    ), row=1, col=2)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_3_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_3_{value}\",\n        mode=\"markers\"\n    ), row=2, col=1)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_4_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_4_{value}\",\n        mode=\"markers\"\n    ), row=2, col=2)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_5_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_5_{value}\",\n        mode=\"markers\"\n    ), row=3, col=1)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_6_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_6_{value}\",\n        mode=\"markers\"\n    ), row=3, col=2)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_7_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_7_{value}\",\n        mode=\"markers\"\n    ), row=4, col=1)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_8_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_8_{value}\",\n        mode=\"markers\"\n    ), row=4, col=2)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_9_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_9_{value}\",\n        mode=\"markers\"\n    ), row=5, col=1)\n\n    fig.append_trace(go.Scatter(\n        x=df[f\"sensor_10_{value}\"],\n        y=df[\"time_to_eruption\"],\n        name=f\"sensor_10_{value}\",\n        mode=\"markers\"\n    ), row=5, col=2)\n\n    fig.update_layout(height=600, width=600, title_text=f\"({value} of each sensor data) vs (time_to_eruption)\")\n    fig.show()","ed02c334":"def plot_with_seaborn(df, value):\n    \"\"\"value: max, min, mean or var\"\"\"\n    fig, axes = plt.subplots(5, 2, figsize=(10,20))\n    fig.suptitle(f\"({value} of each sensor data) vs (time_to_eruption)\")\n    g1 = sns.scatterplot(ax=axes[0, 0], data=df, x=df[f\"sensor_1_{value}\"], y=df[\"time_to_eruption\"], color='orange')\n    g2 = sns.scatterplot(ax=axes[0, 1], data=df, x=df[f\"sensor_2_{value}\"], y=df[\"time_to_eruption\"], color='darkgoldenrod')\n    g3 = sns.scatterplot(ax=axes[1, 0], data=df, x=df[f\"sensor_3_{value}\"], y=df[\"time_to_eruption\"], color='darkkhaki')\n    g4 = sns.scatterplot(ax=axes[1, 1], data=df, x=df[f\"sensor_4_{value}\"], y=df[\"time_to_eruption\"], color='olive')\n    g5 = sns.scatterplot(ax=axes[2, 0], data=df, x=df[f\"sensor_5_{value}\"], y=df[\"time_to_eruption\"], color='lime')\n    g6 = sns.scatterplot(ax=axes[2, 1], data=df, x=df[f\"sensor_6_{value}\"], y=df[\"time_to_eruption\"], color='green')\n    g7 = sns.scatterplot(ax=axes[3, 0], data=df, x=df[f\"sensor_7_{value}\"], y=df[\"time_to_eruption\"], color='darkturquoise')\n    g8 = sns.scatterplot(ax=axes[3, 1], data=df, x=df[f\"sensor_8_{value}\"], y=df[\"time_to_eruption\"], color='blue')\n    g9 = sns.scatterplot(ax=axes[4, 0], data=df, x=df[f\"sensor_9_{value}\"], y=df[\"time_to_eruption\"], color='violet')\n    g10 = sns.scatterplot(ax=axes[4, 1], data=df, x=df[f\"sensor_10_{value}\"], y=df[\"time_to_eruption\"], color='darkmagenta')\n    \n    \n    #fig.update_layout(height=600, width=600, title_text=f\"({value} of each sensor data) vs (time_to_eruption)\")\n    fig.show()","5ec839cd":"#If you want intaractive plot, use,\n#plot_with_plotly(train, \"max\")\n\nplot_with_seaborn(train, \"max\")\n\n","d8630569":"g_max_mean = sns.scatterplot(x=np.mean(train[[f\"sensor_{i}_max\" for i in range(1, 11)]], axis=1),\n                             y=train[\"time_to_eruption\"])\ng_max_mean.set_title(\"mean of max of each sensor data in each segment vs time_to_eruption\")","b99355c4":"#If you want intaractive plot, use,\n#plot_with_plotly(train, \"min\")\n\nplot_with_seaborn(train, \"min\")","4f7aefeb":"g_min_mean = sns.scatterplot(x=np.mean(train[[f\"sensor_{i}_min\" for i in range(1, 11)]], axis=1),\n                             y=train[\"time_to_eruption\"])\ng_min_mean.set_title(\"mean of minimum of each sensor data in each segment vs time_to_eruption\")","abd22841":"#If you want interactive plot, use,\n#plot_with_plotly(train, \"mean\")\n\nplot_with_seaborn(train, \"mean\")","fbfbf44a":"g_mean_mean = sns.scatterplot(x=np.mean(train[[f\"sensor_{i}_mean\" for i in range(1, 11)]], axis=1),\n                             y=train[\"time_to_eruption\"])\ng_mean_mean.set_title(\"mean of mean of each sensor data in each segment vs time_to_eruption\")","5b5dacce":"#If you want interactive plot, use,\n#plot_with_plotly(train, \"var\")\n\nplot_with_seaborn(train, \"var\")","64b71eed":"g_var_mean = sns.scatterplot(x=np.mean(train[[f\"sensor_{i}_var\" for i in range(1, 11)]], axis=1),\n                             y=train[\"time_to_eruption\"])\ng_var_mean.set_title(\"mean of var of each sensor data in each segment vs time_to_eruption\")","ad49e36d":"#If you want interactive plot, use,\n#plot_with_plotly(train, \"75_percentile\")\n\nplot_with_seaborn(train, \"75_percentile\")","3dbcc09a":"#If you want interactive plot, use,\n#plot_with_plotly(train, \"95_percentile\")\n\nplot_with_seaborn(train, \"95_percentile\")","0bfa77cb":"#If you want interactive plot, use,\n#plot_with_plotly(train, \"99_percentile\")\n\nplot_with_seaborn(train, \"99_percentile\")","388f2a83":"plot_with_seaborn(train, \"outlier\")","c9f18e01":"def plot_with_seaborn_countplot(df, value):\n    \"\"\"null\"\"\"\n    fig, axes = plt.subplots(5, 2, figsize=(10,20))\n    fig.suptitle(f\"({value} of each sensor data) vs (time_to_eruption)\")\n    g1 = sns.countplot(ax=axes[0, 0], data=df, x=df[f\"sensor_1_{value}\"],  color='orange')\n    g2 = sns.countplot(ax=axes[0, 1], data=df, x=df[f\"sensor_2_{value}\"], color='darkgoldenrod')\n    g3 = sns.countplot(ax=axes[1, 0], data=df, x=df[f\"sensor_3_{value}\"], color='darkkhaki')\n    g4 = sns.countplot(ax=axes[1, 1], data=df, x=df[f\"sensor_4_{value}\"], color='olive')\n    g5 = sns.countplot(ax=axes[2, 0], data=df, x=df[f\"sensor_5_{value}\"], color='lime')\n    g6 = sns.countplot(ax=axes[2, 1], data=df, x=df[f\"sensor_6_{value}\"], color='green')\n    g7 = sns.countplot(ax=axes[3, 0], data=df, x=df[f\"sensor_7_{value}\"], color='darkturquoise')\n    g8 = sns.countplot(ax=axes[3, 1], data=df, x=df[f\"sensor_8_{value}\"], color='blue')\n    g9 = sns.countplot(ax=axes[4, 0], data=df, x=df[f\"sensor_9_{value}\"], color='violet')\n    g10 = sns.countplot(ax=axes[4, 1], data=df, x=df[f\"sensor_10_{value}\"], color='darkmagenta')\n    \n    \n    #fig.update_layout(height=600, width=600, title_text=f\"({value} of each sensor data) vs (time_to_eruption)\")\n    fig.show()","f93f45ee":"plot_with_seaborn_countplot(train, \"null\")","68c5635e":"train.to_csv('train_preprocessed.csv', index=False)","3276e7de":"import numpy as np\n\nfrom sklearn.linear_model import LinearRegression\nimport scipy.stats as spstats\n\n\ndef basic_statistics(t_X, x, s, sensor, postfix=''):\n    \"\"\"Computes basic statistics for the training feature set.\n    \n    Args:\n        t_X (pandas.DataFrame): The feature set being built.\n        x (pandas.Series): The signal values.\n        s (int): The integer number of the segment.\n        postfix (str): The postfix string value.\n    Return:\n        t_X (pandas.DataFrame): The feature set being built.\n    \"\"\"\n\n    t_X.loc[s, f'{sensor}_sum{postfix}']       = x.sum()\n    t_X.loc[s, f'{sensor}_mean{postfix}']      = x.mean()\n    t_X.loc[s, f'{sensor}_std{postfix}']       = x.std()\n    t_X.loc[s, f'{sensor}_var{postfix}']       = x.var() \n    t_X.loc[s, f'{sensor}_max{postfix}']       = x.max()\n    t_X.loc[s, f'{sensor}_min{postfix}']       = x.min()\n    t_X.loc[s, f'{sensor}_median{postfix}']    = x.median()\n    t_X.loc[s, f'{sensor}_skew{postfix}']      = x.skew()\n    t_X.loc[s, f'{sensor}_mad{postfix}']       = x.mad()\n    t_X.loc[s, f'{sensor}_kurtosis{postfix}']  = x.kurtosis()\n\n    return t_X\n\n\n\ndef quantiles(t_X, x, s, sensor, postfix=''):\n    \"\"\"Calculates quantile features for the training feature set.\n    Args:\n        t_X (pandas.DataFrame): The feature set being built.\n        x (pandas.Series): The signal values.\n        s (int): The integer number of the segment.\n        postfix (str): The postfix string value.\n    Return:\n        t_X (pandas.DataFrame): The feature set being built.\n    \"\"\"\n    t_X.loc[s, f'{sensor}_q999{postfix}']     = np.quantile(x ,0.999)\n    t_X.loc[s, f'{sensor}_q99{postfix}']      = np.quantile(x, 0.99)\n    t_X.loc[s, f'{sensor}_q95{postfix}']      = np.quantile(x, 0.95)\n    t_X.loc[s, f'{sensor}_q87{postfix}']      = np.quantile(x, 0.87)\n    t_X.loc[s, f'{sensor}_q13{postfix}']      = np.quantile(x, 0.13)  \n    t_X.loc[s, f'{sensor}_q05{postfix}']      = np.quantile(x, 0.05)\n    t_X.loc[s, f'{sensor}_q01{postfix}']      = np.quantile(x, 0.01)\n    t_X.loc[s, f'{sensor}_q001{postfix}']     = np.quantile(x ,0.001)\n    \n    x_abs = np.abs(x)\n    t_X.loc[s, f'{sensor}_q999_abs{postfix}'] = np.quantile(x_abs, 0.999)\n    t_X.loc[s, f'{sensor}_q99_abs{postfix}']  = np.quantile(x_abs, 0.99)\n    t_X.loc[s, f'{sensor}_q95_abs{postfix}']  = np.quantile(x_abs, 0.95)\n    t_X.loc[s, f'{sensor}_q87_abs{postfix}']  = np.quantile(x_abs, 0.87)\n    t_X.loc[s, f'{sensor}_q13_abs{postfix}']  = np.quantile(x_abs, 0.13)\n    t_X.loc[s, f'{sensor}_q05_abs{postfix}']  = np.quantile(x_abs, 0.05)\n    t_X.loc[s, f'{sensor}_q01_abs{postfix}']  = np.quantile(x_abs, 0.01)\n    t_X.loc[s, f'{sensor}_q001_abs{postfix}'] = np.quantile(x_abs, 0.001)\n    \n    t_X.loc[s, f'{sensor}_iqr']     = np.subtract(*np.percentile(x, [75, 25]))\n    t_X.loc[s, f'{sensor}_iqr_abs'] = np.subtract(*np.percentile(x_abs, [75, 25]))\n\n    return t_X\n\n\ndef __linear_regression(arr, abs_v=False):\n    \"\"\"\n    \"\"\"\n    idx = np.array(range(len(arr)))\n    if abs_v:\n        arr = np.abs(arr)\n    lr = LinearRegression()\n    fit_X = idx.reshape(-1, 1)\n    lr.fit(fit_X, arr)\n    return lr.coef_[0]\n\n\ndef __classic_sta_lta(x, length_sta, length_lta):\n    sta = np.cumsum(x ** 2)\n    # Convert to float\n    sta = np.require(sta, dtype=np.float)\n    # Copy for LTA\n    lta = sta.copy()\n    # Compute the STA and the LTA\n    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n    sta \/= length_sta\n    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n    lta \/= length_lta\n    # Pad zeros\n    sta[:length_lta - 1] = 0\n    # Avoid division by zero by setting zero values to tiny float\n    dtiny = np.finfo(0.0).tiny\n    idx = lta < dtiny\n    lta[idx] = dtiny\n    return sta \/ lta\n\n\ndef linear_regression(t_X, x, s, sensor, postfix=''):\n    t_X.loc[s, f'{sensor}_lr_coef{postfix}'] = __linear_regression(x)\n    t_X.loc[s, f'{sensor}_lr_coef_abs{postfix}'] = __linear_regression(x, True)\n    return t_X\n\n\ndef classic_sta_lta(t_X, x, sensor, s):\n    t_X.loc[s, f'{sensor}_classic_sta_lta1_mean'] = __classic_sta_lta(x, 500, 10000).mean()\n    t_X.loc[s, f'{sensor}_classic_sta_lta2_mean'] = __classic_sta_lta(x, 5000, 100000).mean()\n    t_X.loc[s, f'{sensor}_classic_sta_lta3_mean'] = __classic_sta_lta(x, 3333, 6666).mean()\n    t_X.loc[s, f'{sensor}_classic_sta_lta4_mean'] = __classic_sta_lta(x, 10000, 25000).mean()\n    return t_X\n\n\ndef fft(t_X, x, s, sensor, postfix=''):\n    \"\"\"Generates basic statistics over the fft of the signal\"\"\"\n    z = np.fft.fft(x)\n    fft_real = np.real(z)\n    fft_imag = np.imag(z)\n\n    t_X.loc[s, f'fft_A0']             = abs(z[0])\n    \n    t_X.loc[s, f'{sensor}_fft_real_mean{postfix}']      = fft_real.mean()\n    t_X.loc[s, f'{sensor}_fft_real_std{postfix}']       = fft_real.std()\n    t_X.loc[s, f'{sensor}_fft_real_max{postfix}']       = fft_real.max()\n    t_X.loc[s, f'{sensor}_fft_real_min{postfix}']       = fft_real.min()\n    t_X.loc[s, f'{sensor}_fft_real_median{postfix}']    = np.median(fft_real)\n    t_X.loc[s, f'{sensor}_fft_real_skew{postfix}']      = spstats.skew(fft_real)\n    t_X.loc[s, f'{sensor}_fft_real_kurtosis{postfix}']  = spstats.kurtosis(fft_real)\n    \n    t_X.loc[s, f'{sensor}_fft_imag_mean{postfix}']      = fft_imag.mean()\n    t_X.loc[s, f'{sensor}_fft_imag_std{postfix}']       = fft_imag.std()\n    t_X.loc[s, f'{sensor}_fft_imag_max{postfix}']       = fft_imag.max()\n    t_X.loc[s, f'{sensor}_fft_imag_min{postfix}']       = fft_imag.min()\n    t_X.loc[s, f'{sensor}_fft_imag_median{postfix}']    = np.median(fft_imag)\n    t_X.loc[s, f'{sensor}_fft_imag_skew{postfix}']      = spstats.skew(fft_imag)\n    t_X.loc[s, f'{sensor}_fft_imag_kurtosis{postfix}']  = spstats.kurtosis(fft_imag)\n    \n    return t_X","11273c51":"def count_outlier(x):\n    q1 = np.percentile(x, 25)\n    q3 = np.percentile(x, 75)\n    \n    max = 2.5*q3 - 1.5*q1\n    min = -0.5*q3 - 1.5*q1\n    \n    return (len(x[x  > max] + len(x[x  < min])))\n\ndef outlier(t_X, x, s, sensor, postfix=''):\n    t_X.loc[s, f'{sensor}_outlier{postfix}'] = count_outlier(x)\n    return t_X","af7fd58a":"training_and_pred = False","8e857e91":"if training_and_pred:\n    train = pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv')\n    train_set = pd.DataFrame()\n    train_set['segment_id'] = train.segment_id\n    train_set = train_set.set_index('segment_id')\n\n    j = 0\n    for seg in train.segment_id:\n        signals = pd.read_csv(f'\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train\/{seg}.csv')\n        for i in range(1, 11):\n            sensor_id = f'sensor_{i}'\n            train_set = basic_statistics(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n            train_set = quantiles(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n        \n            ###Add this line\n            train_set = outlier(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n        \n            train_set = linear_regression(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n            train_set = fft(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n        \n    train_set = pd.merge(train_set.reset_index(), train, on=['segment_id'], how='left').set_index('segment_id')\n    \n    \n    test = pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')\n    test_set = pd.DataFrame()\n    test_set['segment_id'] = test.segment_id\n    test_set = test_set.set_index('segment_id')\n\n\n    for seg in test.segment_id:\n        signals = pd.read_csv(f'\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/test\/{seg}.csv')\n        for i in range(1, 11):\n            sensor_id = f'sensor_{i}'\n            test_set = basic_statistics(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n            test_set = quantiles(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n        \n            ###Add this line\n            test_set = outlier(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n        \n            test_set = linear_regression(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n            test_set = fft(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')","ff4cacb3":"import lightgbm as lgbm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold,StratifiedKFold, RepeatedKFold\n\nif training_and_pred:\n\n    y = train_set['time_to_eruption']\n    feature_df = train_set.drop(['time_to_eruption'], axis = 1)\n\n    scaler = StandardScaler()\n    scaler.fit(feature_df)\n    scaled_feature_df = pd.DataFrame(scaler.transform(feature_df), columns=feature_df.columns)\n    scaled_test_df    = pd.DataFrame(scaler.transform(test_set), columns=test_set.columns)\n\n    print(scaled_feature_df.shape)\n    print(scaled_test_df.shape)\n\n\n    n_fold = 5\n    folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n    scaled_feature_df_columns = scaled_feature_df.columns.values\n\n\n    params = {\n        'num_leaves': 85,\n        'min_data_in_leaf': 10, \n        'objective':'regression',\n        'max_depth': -1,\n        'learning_rate': 0.001,\n        'max_bins': 2048,\n        \"boosting\": \"gbdt\",\n        \"feature_fraction\": 0.91,\n        \"bagging_freq\": 1,\n        \"bagging_fraction\": 0.91,\n        \"bagging_seed\": 42,\n        \"metric\": 'mae',\n        \"lambda_l1\": 0.1,\n        \"verbosity\": -1,\n        \"nthread\": -1,\n        \"random_state\": 42\n    }\n\n\n    oof = np.zeros(len(scaled_feature_df))\n    predictions = np.zeros(len(scaled_test_df))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(scaled_feature_df, y.values)):\n    \n        strLog = \"fold {}\".format(fold_)\n        print(strLog)\n    \n        X_tr, X_val = scaled_feature_df.iloc[trn_idx], scaled_feature_df.iloc[val_idx]\n        y_tr, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n        model = lgbm.LGBMRegressor(**params, n_estimators = 20000, n_jobs = -1)\n        model.fit(X_tr, y_tr, \n              eval_set=[(X_tr, y_tr), (X_val, y_val)], eval_metric='mae',\n              verbose=1000, early_stopping_rounds=400)\n    \n        oof[val_idx] = model.predict(X_val, num_iteration=model.best_iteration_)\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"Feature\"] = scaled_feature_df_columns\n        fold_importance_df[\"importance\"] = model.feature_importances_[:len(scaled_feature_df_columns)]\n        fold_importance_df[\"fold\"] = fold_ + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        #predictions\n        predictions += model.predict(scaled_test_df, num_iteration=model.best_iteration_) \/ folds.n_splits\n    \n    \n    submission = pd.DataFrame()\n    submission['segment_id'] = test_set.index\n    submission['time_to_eruption'] = predictions\n    submission.to_csv('submission_recent.csv', header=True, index=False)    ","227aa61c":"Sensor 6, in particular, takes great value in 2 ~ 4 le7 time_to_eruption area.","164c0bc1":"<a id=\"3\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Data overview<\/div>\n\nLet's check overview, data type, NaN of loaded data.\n\ntrain.csv includes segment_id and time_to_eruption. There are 4431 data. \"time_to_eruption\" represents time until the next eruption. This value is target of this competition. \"segment_id\" is ID code for the data segment. Matches the name of the associated data file in [train|test]\/*.","12788e3b":"### <div class=\"alert alert-block alert-warning\">In this notebook, I set up not to train and predict. If you want to do so, please set \"training_and_pred\" to True.<\/div>","7c4c5c63":"<a id=\"4\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Visualization<\/div>\n\nHere, I'll check and visualize train and sensor data, and get a better understanding of these data.","fde37b22":"### Trends 75, 95 and 99 percentiles of each sensor data and time_to_eruption.\n\nWe'll check trends between 75, 95 and 99 percentiles of each sensor data and time_to_eruption. ","ce9e3db3":"In particular, sensors 2, 5 and 9 often seem to be down. Sensors 1, 4 and 7 often seem to be rarely down.","01cb7f84":"<a id=\"6\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Application to prediction<\/div>\n\nHere, I apply count of outlier as feature for baseline notebook, and make sure it is improved.\n\nFor the baseline, I use @ajcostarino 's great notebook (https:\/\/www.kaggle.com\/ajcostarino\/ingv-volcanic-eruption-prediction-lgbm-baseline).\n\nI improved lb score 6614776 -> 6555212.","ad2284b3":"There are three kind of files.\n\n- train.csv:  trainig data witch includes segment_id and time_to_eruption.\n\n- sample_submission.csv: sample submission file witch includes segment_id and time_to_eruption all 0.\n\n- [train|test]\/*.csv: File which contains ten minutes of logs from ten different sensors arrayed around a volcano.\n\nWe have to predict \"time_to_eruption\" of sample_submission.","2da68d01":"### Trends between max of each sensor data and time_to_eruption.\n\nLet's check trends between max of each sensor data and time_to_eruption. Until time_to_eruption ~ 1e7, some sensor data has large max. We might predict this area.","e25c92b8":"<a id=\"1\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Introduction<\/div>\n\nDetecting volcanic eruptions before they happen is an important problem that has historically proven to be a very difficult. This is because once an eruption occurs, it can cause extensive damage for many people. \n\nIn this competition, we have to find the way for long-term predictions of the next volcanic eruptions. We need to have an in-depth understanding of the trends of data points, no matter how close or far away from each eruption.\n\nIn this notebook, I'll check given data, and do visualization and eda to get good understanding and insight for the data.","7e03de86":"Most of the values are below a certain value (depending on the number of sensors), which from this point of view makes the predictions look difficult in this area.\n\nThe same is true when averaged across sensors.","4b29c526":"## **Summary**\n\n1. Checked overview of given data.\n\n1. Checked trends of segments which as large or small(especially smaller than 10 min) time_to_eruption by plots.\n\n1. Visualized relation between descriptive statistics values and time_to_eruption. Especially,\n\n  - In small time_to_eruption area (~ 1.0 * 10^7), descriptive statistics value such as variance get larger. \n\n  - In large time_to_eruption area (5.0 * 10^7 ~ ), sensor9 has large outlier count at some segment.\n\n  - In medium time_to_eruption area (2.0 * 10^7 ~ 4.0 * 10^7), sensor6 tend to have slightly large parcentile(95% and 99%) value.\n  \n1. Applied found feature for baseline notebook and confirmed improvement(lb score 6614776 -> 6555212.).","3ebab3b2":"Next, sensor data. Each file contains ten minutes of logs from ten different sensors arrayed around a volcano. The readings have been normalized within each segment, in part to ensure that the readings fall within the range of int16 values.\n\nFor example, 379022420.csv has float type data and no lack.","5b1bbf1a":"<a id=\"5\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">EDA<\/div>","5728d07d":"## In this kernel I add count of outlier here. \u2193\u2193\u2193","21255fd6":"### pair plot of each sensor data.\n\nNext, I plot pair plot. There doesn't seem to be any similarities in trends between the sensor data.","dc1e508d":"### Trends between count of outlier of each sensor data and time_to_eruption.\n\nFinaly, we'll check trends between count of outlier of each sensor data and time_to_eruption. \n\nUnlike the previous other values, we can see that the x-axis value is larger for large time_to_eruption. Also, for small time_to_eruption, the value of x-axis does not tend to be large. ","c4a47bde":"Sample submission includes segment_id and time_to_eruption all 0. As you can see from the number of data under the test seen above, there are 4520 rows.","cef3c4e6":"Here, let's search trends for good represents time until the next eruption.","29b00442":"### Distplot of each sensor data.\n\nI'll plot distplot of each sensor data. First, I create crete_distplot in convenience.","b027996b":"Second, check what sensor data is available. Sensor data named by \"segment_id\" + \".csv\".\n\nThere are no data which taken in same segment.","0f403f0a":"### Trends between minimum of each sensor data and time_to_eruption.\n\nNex't we'll check trends between minimum of each sensor data and time_to_eruption. \n\nAs with the maximum, until time_to_eruption ~ 1e7, some sensor data has large negative value. We might predict this area.","2ef650e7":"I create new function which can plot lineplot with supplementary wire. ","30e09802":"If we get average across sensors, most values are near 0.","d3ba6c56":"Huuum.... It doesn't look so bad when we say there are signals at 250 second intervals...","d6d90713":"The value of time_to_eruption seems to be about the same number of times. The number decrease at 4e7 and above.","51d12785":"But, some sensor data has lack. See following data of 1002275321 segment.","6a46a24f":"In particular, we can see that sensor9 has a distinctly different feature for large time_to_eruption than before. If there is time before the next eruption, the tremor should be smaller, so it may be easier to detect it as an outlier when big tremor occurs.","b5d23333":"# <div class=\"h1\">INGV - Volcanic Eruption Prediction<\/div>\n\n![Volcano](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/a4\/Volcano_q.jpg\/440px-Volcano_q.jpg)\n\n\n## **Content**\n1. [Introduction](#1)\n1. [Libraries and dataset](#2)\n1. [Data overview](#3)\n1. [Visualization](#4)\n   - Train data\n   - Sensor data\n1. [EDA](#5)\n   - Trends between max of each sensor data and time_to_eruption.\n   - Trends between minimum of each sensor data and time_to_eruption.\n   - Trends between mean of each sensor data and time_to_eruption.\n   - Trends between variance of each sensor data and time_to_eruption.\n   - Trends 75, 95 and 99 percentiles of each sensor data and time_to_eruption.\n   - Trends between count of outlier of each sensor data and time_to_eruption.\n   - Sensor down time.\n1. [Application to prediction](#6)","89cf6701":"<a id=\"2\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Libraries and dataset<\/div>","5109e07a":"## Train data","814d318f":"### Sensor down time.\n\nI also processed whether or not each sensor was down in each segment. For the power supply, sensors have down time and then, data will be null. \n\nIn my data process above, I convert 1 if there are null and 0 if there aren't.\n\nLike this, \n\n> train.loc[i, f\"sensor_{j+1}_null\"] = 1 if df_segment_id.isnull().any()[j] else 0","092fcacf":"### Line plot of each sensor data.","be660419":"We can see that the value of the second sensor in particular fluctuates greatly.\n\nOther graphs are seems to be quiet.","a84d3d2a":"### Violinplot of each sensor data.\n\nI also create violinplot. For plot, I create function we can let data tidy.","34400517":"The supplementary line on sensor2 looks like good...","debdf4b9":"Most of the values are above a certain value (depending on the number of sensors), and from this point of view, the data in this area seems to be tricky to predict.\n\nThe same is true when averaged across sensors.","644714fa":"## Relation between time_to_eruption and descriptive statistics value\n\nI tried to plot relation between time_to_eruption and following descriptive statistics values.\n\n- max\n\n- minimum\n\n- mean\n\n- variance\n\n- 75, 95 and 99 percentiles\n\n- count of outliners\n\nThis is because, we can guess that there might be some signs in 10 minutes sensor datas before eruption. If we found that in descriptive statistics value of sensor datas, we can use them for good prediction.","cdeca81d":"## Sensor data\n\nTo simple visualize, first, I check segment id 379022420 data. For line plots and other plots that cannot be written for 10 sensors at a time, I made the function myself. Some of the dataframes are re-read, but I just prioritized ease of processing, so don't worry about it.","1f0475a3":"There are a lot of sensor data, I'll load following 2 data for explanation.","b4c520e8":"We can check down rate for each sensors by countplot.","6c449923":"### Trends between mean of each sensor data and time_to_eruption.\n\nNex't we'll check trends between mean of each sensor data and time_to_eruption. \n\nNote that I filled NaN by 0, so there are some side effect.\n\nMost of the values are clustered around 0. Rarely there seems to be data with a large mean. Also, there are many data with large mean for small time_to_eruption.","f1260597":"Let's load train data and sample_submission.","db5d98d8":"### Trends between variance of each sensor data and time_to_eruption.\n\nNext we'll check trends between variance of each sensor data and time_to_eruption. \n\nFor small time_to_eruption, we can see that there is a large variance. This trend is same as max and minimum, but it's more pronounced. ","ca43fd0c":"The plots seems to be a left-right target. The average seems to be zero. Variance seems to be different by sensors.","dc19e0ea":"### Boxplot of each sensor data.\n\nI think detecting outliers will be important, so I'll also write a box-beard diagram.","4fb6db5b":"Also I create 2 functions to be able to visualize it all at once. I'll define these functions in following 2 cell and hide them. If you want to see them, please open the cells.","5855976c":"### premise from discussion\n\nI think there are some ambiguity information for given data, but some important points have been made clear in the discussion. Here's a summary of what I've picked up.\n\n- One volcano (https:\/\/www.kaggle.com\/c\/predict-volcanic-eruptions-ingv-oe\/discussion\/190936)\n\n- Same 10 sensors (https:\/\/www.kaggle.com\/c\/predict-volcanic-eruptions-ingv-oe\/discussion\/191445)\n\n- unit of time_to_eruption and time span of sensor data records are 0.01s. (https:\/\/www.kaggle.com\/c\/predict-volcanic-eruptions-ingv-oe\/discussion\/190682)\n\n- Sensor has downtime(https:\/\/www.kaggle.com\/c\/predict-volcanic-eruptions-ingv-oe\/discussion\/191444).","fb35c70e":"### question\n\nData which time_to_eruption is smaller than 60000 represents eruption in it's value and graph?","741b6bad":"### Preparation.\n\nI'll calculate above values for each train data."}}