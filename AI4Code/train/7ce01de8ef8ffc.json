{"cell_type":{"bc516051":"code","5b9e956e":"code","fd5bd385":"code","0e29580a":"code","5ce1b8d2":"code","428dfb6a":"code","b1813a21":"code","bf32af1b":"code","37443f59":"code","f6b3deb6":"code","9d514b5c":"code","31d76cc1":"code","22b8335a":"code","831d4844":"code","0fb27f2b":"code","67bef3c0":"code","9fda0e61":"code","936f0358":"code","45bcee96":"code","a57baf6e":"code","66379d92":"code","d31f32e9":"markdown","b9017e34":"markdown","9c38368b":"markdown","889256d4":"markdown","3f6b7088":"markdown","d4c5cebb":"markdown"},"source":{"bc516051":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.metrics import accuracy_score,precision_recall_curve,precision_score,recall_score,confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss","5b9e956e":"dataset = pd.read_csv('..\/input\/heart.csv')","fd5bd385":"columns = dataset.columns[0:-1]\n\nprint(columns)","0e29580a":"sns.countplot(dataset.target)\nplt.show()","5ce1b8d2":"smote = SMOTE()\ndataset_x,dataset_y = smote.fit_sample(dataset.drop('target',axis=1),dataset[['target']])","428dfb6a":"dataset_x = pd.DataFrame(dataset_x)\ndataset_x.columns = columns","b1813a21":"dataset_y = pd.DataFrame(dataset_y)\ndataset_y.columns = ['target']\ndataset_y.head()","bf32af1b":"sns.countplot(dataset_y.target)","37443f59":"dataset = dataset_x.join(dataset_y,how='right')\ndataset.head()","f6b3deb6":"normal = dataset[dataset.target == 0]\ndisease = dataset[dataset.target == 1]","9d514b5c":"for i in columns:\n    sns.distplot(normal[i],color='g')\n    sns.distplot(disease[i],color='r')\n    plt.show()","31d76cc1":"sns.heatmap(dataset.corr())","22b8335a":"dataset = dataset[['cp','thalach','oldpeak','target']]\ndataset.head()","831d4844":"train_x, test_x, train_y, test_y = train_test_split(dataset.drop('target',axis=1),dataset[['target']],test_size = 0.20,random_state = 42)","0fb27f2b":"scaler = StandardScaler()\ntrain_x = scaler.fit_transform(train_x)\ntest_x = scaler.transform(test_x)","67bef3c0":"cl = LogisticRegression()\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","9fda0e61":"cl = KNeighborsClassifier(n_neighbors=5)\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","936f0358":"cl = RandomForestClassifier()\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","45bcee96":"cl = GaussianNB()\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","a57baf6e":"cl = SVC()\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","66379d92":"cl = MLPClassifier(hidden_layer_sizes = 3,activation='relu',solver='adam',warm_start = False,max_iter=500)\ncl.fit(train_x,train_y)\npred = cl.predict(test_x)\ncm = confusion_matrix(test_y,pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint(\"Accuracy Score: \",accuracy_score(test_y,pred))\nprint(\"Precision Score: \",precision_score(test_y,pred))\nprint(\"Recall Score: \",recall_score(test_y,pred))","d31f32e9":"It is hard to call this data set imbalanced. But I have not so much data. So I just want to use an over-sampling technique which is called SMOTE.","b9017e34":"Now number of 0s equals to number of 1s","9c38368b":"**SUMMARY**\n\nI assume that I have a scenario and in this scenario a person comes to doctor. Doctor checks her heart disease probability by using model. If model says she has heart disease, doctor wants check-up. For this scenario, if you call a normal person as patient, you do not loss anything. So here recall is more important. I can call normal one as patient but not patient as normal. So I choose to use Naive Bayes method for this data.","889256d4":"After this point, I check each metrics for each methods. Some methods are missing, I know..","3f6b7088":"Distributions are really bad. But I take least bad ones.","d4c5cebb":"I have seperated data set into two sets which are for normal and disease. So I will plot for both and check distributions. "}}