{"cell_type":{"e4013f16":"code","01abd56b":"code","988cc2e1":"code","1e21ca5a":"code","5af693fe":"code","2c9a9005":"code","a587d9e4":"code","11aa32fd":"code","622aba38":"code","3fd4ef37":"code","65fa5a6c":"code","36310f45":"code","e9a8ebbe":"code","e695fe67":"code","30ed17ab":"code","f9921ee0":"code","5f4e64c4":"code","6540de31":"code","935f322c":"code","3cd9bb7a":"code","ef123276":"code","02f7b2b9":"code","c2073501":"code","e6d535b7":"code","5c408b49":"code","d5d71ff8":"code","5ddd035c":"code","d9ca4117":"code","f9efb9e9":"code","496628a9":"code","f110cf33":"code","ca206111":"markdown","9c131d13":"markdown","e3f6a7c5":"markdown","32de4ae3":"markdown","d18236e9":"markdown","122e732c":"markdown","272647ac":"markdown","d722ad32":"markdown"},"source":{"e4013f16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01abd56b":"# import libraries\nimport numpy as np \nimport pandas as pd \nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('darkgrid')\npd.set_option('display.float_format', lambda x: '{:.2f}'.format(x)) #Limiting floats output to 2 decimal points\n\nfrom fastai.tabular import *","988cc2e1":"test = pd.read_csv('..\/input\/TTiDS20\/test_no_target.csv')\ntrain = pd.read_csv('..\/input\/TTiDS20\/train.csv')\n","1e21ca5a":"#Save the 'Id' column\ntrain_ID = train['Unnamed: 0']\ntest_ID = test['Unnamed: 0']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop('Unnamed: 0', axis = 1, inplace = True)\ntest.drop('Unnamed: 0', axis = 1, inplace = True)","5af693fe":"sns.distplot(train['price']) ;\n\n# Get the fitted parameters \n(mu, sigma) = norm.fit(train['price'])\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nplt.title('price distribution');","2c9a9005":"# log-transform the price\ntrain['price'] = train['price'].apply(np.log)\n\nsns.distplot(train['price'])\nplt.show();","a587d9e4":"ntrain = train.shape[0]\nntest = test.shape[0]\n\ny_train = train.price.values.copy()\nall_data = pd.concat((train, test), sort = 'True').reset_index(drop=True)\nall_data.drop(['price'], axis=1, inplace=True)\nall_data.drop(['engine_capacity'], axis=1, inplace=True)\n\nall_data.drop(['zipcode'], axis=1, inplace=True)\n\nprint(\"all_data size is : {}\".format(all_data.shape))","11aa32fd":"missing_data = (all_data.isnull().sum() \/ len(all_data)).sort_values(ascending = False)*100\n\nmissing_data = pd.DataFrame(missing_data)\n\nplt.figure(figsize = (10,7))\nmissing_data.head(20).plot(kind = 'bar')\nplt.title('Percent of missing data');","622aba38":"col = train.corr().nlargest(10, 'price')['price'].index\ncorr_matrix = np.corrcoef(train[col].values.T)","3fd4ef37":"plt.figure(figsize = (10,8))\nsns.heatmap(corr_matrix, cmap = 'coolwarm', annot = True, xticklabels= col.values, yticklabels= col.values);","65fa5a6c":"ntrain = train.shape[0]\nntest = test.shape[0]\n\ny_train = train.price.values.copy()\nall_data = pd.concat((train, test), sort = 'True').reset_index(drop=True)\nall_data.drop(['price'], axis=1, inplace=True)\nall_data.drop(['model'], axis=1, inplace=True)\nall_data.drop(['gearbox'], axis=1, inplace=True)\nall_data.drop(['fuel'], axis=1, inplace=True)\nall_data.drop(['mileage'], axis=1, inplace=True)\n\n\n\n\nprint(\"all_data size is : {}\".format(all_data.shape))","36310f45":"missing_data = (all_data.isnull().sum() \/ len(all_data)).sort_values(ascending = False)*100\n\nmissing_data = pd.DataFrame(missing_data)\nmissing_data.head(5)","e9a8ebbe":"all_data","e695fe67":"all_data['registration_year'] = all_data['registration_year'].astype(str) \nall_data['type'] = all_data['type'].astype(str) \nall_data['brand'] = all_data['brand'].astype(str) \n","30ed17ab":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","f9921ee0":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)","5f4e64c4":"train = all_data[:ntrain]\ntest = all_data[ntrain:] ","6540de31":"TARGET = 'price'","935f322c":"cat_names = list(train.select_dtypes(include = ['object', 'bool']).columns)","3cd9bb7a":"cont_names = list(train.select_dtypes(exclude = ['object', 'bool']).columns)","ef123276":"# Add back sale prices\ntrain['price'] = y_train\n","02f7b2b9":"# defining steps to process the input data\nprocs = [FillMissing, Categorify, Normalize]\n\n# Test tabularlist\ntest = TabularList.from_df(test, cat_names=cat_names, cont_names=cont_names, procs=procs)","c2073501":"data = (TabularList.from_df(train, path='.', cat_names=cat_names, cont_names=cont_names, procs=procs)\n                        .split_by_rand_pct(valid_pct = 0.2)\n                        .label_from_df(cols = TARGET, label_cls = FloatList, log = False )\n                        .add_test(test)\n                        .databunch(bs = 128))","e6d535b7":"data.show_batch(rows=5, ds_type=DatasetType.Valid)","5c408b49":"max_log_y = (np.max(train['price'])*1.2)\ny_range = torch.tensor([0, max_log_y], device=defaults.device)","d5d71ff8":"def mean_absolute_percentage_error(y_true:Tensor, y_pred:Tensor):\n    y_true, y_pred = torch.from_numpy(np.array(y_true)), torch.from_numpy(np.array(y_pred))\n    return (torch.abs((y_true - y_pred) \/ y_true) * 100).mean()","5ddd035c":"# create the model\nlearn = tabular_learner(data, layers=[800,200], ps=[0.001,0.01], y_range = y_range, emb_drop=0.04, metrics=mean_absolute_percentage_error)\n\nlearn.model\n\n# select the appropriate learning rate\nlearn.lr_find()\n\n# we typically find the point where the slope is steepest\nlearn.recorder.plot()","d9ca4117":"# Fit the model based on selected learning rate\nlearn.fit_one_cycle(30, max_lr =1e-03)","f9efb9e9":"#Plotting The losses for training and validation\nlearn.recorder.plot_losses(skip_start = 500)","496628a9":"# get predictions\npreds, targets = learn.get_preds(DatasetType.Test)\nlabels = [np.exp(p[0].data.item()) for p in preds]\n\n# create submission file to submit in Kaggle competition\nsubmission = pd.DataFrame({'Id': test_ID, 'Predicted': labels})\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.describe()","f110cf33":"submission.head()","ca206111":"Visualizing correlations in the dataset","9c131d13":"# Transforming numerical features into categorical","e3f6a7c5":"# Deadling with missing data","32de4ae3":"# Skewed features\n","d18236e9":"# Save results","122e732c":"# Checking the target","272647ac":"# Data Loading","d722ad32":"FASTAI Modelling"}}