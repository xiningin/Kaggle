{"cell_type":{"fc1c806d":"code","27568eef":"code","69e7e171":"code","93bd73a9":"code","b3326643":"code","61960cc4":"code","127d7076":"code","4a3f9d0a":"code","04bf1c8e":"code","0d26a637":"code","aca8673e":"code","4affd173":"code","e0cd5441":"code","136249a7":"code","d6a64818":"code","674e1e71":"code","ddda276d":"code","933ca1e7":"code","b9cbad51":"code","467a8e8b":"markdown","a690bc67":"markdown","80f38dcb":"markdown","5761e511":"markdown","8f106bee":"markdown","f2c195bf":"markdown","b287a5c6":"markdown","24493a97":"markdown","356abf67":"markdown","f4097f9d":"markdown"},"source":{"fc1c806d":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","27568eef":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten,BatchNormalization, Dropout, Lambda\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","69e7e171":"data = pd.read_pickle('\/kaggle\/input\/traffic-signs-preprocessed\/data0.pickle')","93bd73a9":"print('keys:', data.keys())","b3326643":"x_train = data['x_train']\nx_validation = data['x_validation']","61960cc4":"numberOfClass = 43\n\ndef preprocess_data(x,y):\n    x_data = preprocess_input(x)\n    y_data = to_categorical(y, numberOfClass)\n    return x_data, y_data","127d7076":"x_train.shape","4a3f9d0a":"x_train = x_train.swapaxes(1,2)\nx_train = x_train.swapaxes(2,3)","04bf1c8e":"x_train.shape","0d26a637":"x_validation = x_validation.swapaxes(1,2)\nx_validation = x_validation.swapaxes(2,3)","aca8673e":"plt.figure(figsize=(20,15))\nfor i in range(428,440):\n    plt.subplot(4,4,(i%12)+1)\n    plt.imshow(x_train[i].astype(np.uint8))\n    plt.tight_layout()","4affd173":"x_train, y_train = preprocess_data(x_train, data['y_train'])\nx_validation, y_validation = preprocess_data(x_validation, data['y_validation'])","e0cd5441":"resnet_model = ResNet50(include_top = False, weights = \"imagenet\", input_shape = (224,224,3))","136249a7":"print(resnet_model.summary())","d6a64818":"# Freeze resnet layers\nfor layer in resnet_model.layers:\n    layer.trainable = False","674e1e71":"img_size = (224,224)\n\nmodel = Sequential() \nmodel.add(Lambda(lambda image: tf.image.resize(image,img_size)))\nmodel.add(resnet_model)\n\n# Fully connected layer\nmodel.add(Flatten()) \nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(numberOfClass, activation='softmax'))","ddda276d":"model.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])","933ca1e7":"hist = model.fit(x_train, y_train, validation_data =(x_validation,y_validation), epochs = 10, batch_size = 1000)","b9cbad51":"model.summary()","467a8e8b":"# ResNet-50\n\n![image.png](attachment:7e00840f-4b90-43af-8f1d-acdc56f13125.png)\n\nResNet-50 (Residual Networks) is a deep neural network that is used as a backbone for many computer vision applications like object detection, image segmentation, etc. ResNet was created by the four researchers Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun and it was the winner of the ImageNet challenge in 2015 with an error rate of 3.57%. It also addressed the problem of vanishing gradient that was common in very deep neural networks like itself.\n","a690bc67":"# Load Data","80f38dcb":"# Preprocess ","5761e511":"# Import Libraries","8f106bee":"# Modeling","f2c195bf":"# Using weights of ResNet-50","b287a5c6":"# Visualization","24493a97":"### \u2b50\ufe0f If you like it, please upvote!","356abf67":"# Transfer Learning\n\n![image.png](attachment:5a2aa5cb-f816-47d4-967b-a8aa112c4449.png)\n\nTransfer or inductive learning is a supervised learning technique that reuses parts of a previously trained model on a new network tasked for a different but similar problem.\n\nUsing a pre-trained model significantly reduces the time required for feature engineering and training. The first step is to select a source model, ideally one with a large dataset to train with. Many research institutions release these models and datasets as open-sourced projects, so it\u2019s not necessary to create your own.\n\nThe next step is to decide which layers to reuse in your own network. The goal is create a framework that is at least better than a naive model, so you can be assured some new feature learning takes place.  Typically deeper layers are reused as these tend to be more general whereas the top layers tend to more finely tuned to a particular problem.  \nFinally, the new model is trained on the new data set as usual.   The advantage is that the model tends to convergence much faster and thus less data and compute time is required.","f4097f9d":"# \ud83d\udccc Introduction\n\n![image.png](attachment:11d4acb0-5b87-475e-87ec-8e4da3bc53be.png)\n\n*  **In this notebook, we will classify traffic signs using the transfer learning method with ResNet-50.**\n\n**Content:**\n\n<font color= '#ff6574'> \n1. Transfer Learning <br>\n2. ResNet-50 <br>  \n3. Import Libraries <br>\n4. Load Data <br>\n5. Preprocess <br>\n6. Visualization <br>\n7. Using weights of ResNet-50 <br>\n8. Modeling <br>"}}