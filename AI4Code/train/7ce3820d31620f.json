{"cell_type":{"a3d1214e":"code","937b7539":"code","80de47ce":"code","9a64154d":"code","b38d1704":"code","61d64df9":"code","07dd5c71":"code","5019ad4a":"code","8e3816c1":"code","b821ed39":"code","8044f96b":"code","ce4085fb":"code","362b97c7":"code","2daa2635":"code","0066cd6d":"code","13a59f37":"code","232dfc79":"code","bd066c35":"code","63b64db6":"code","608187e9":"code","93833136":"code","a8447e8d":"code","6e6af3c2":"code","6db1be02":"code","8625b74c":"code","b54a0850":"code","10b43a96":"code","aafa129a":"code","7f49c5dd":"code","2177e5e5":"code","d1e717ea":"code","5a19b37e":"code","7167a9b2":"code","77ff2423":"code","05528f63":"code","cd41cdb0":"code","7778b661":"code","e81908a6":"code","38e4f8df":"code","7978fc12":"code","8d813214":"code","8a7c831f":"code","39ca8d71":"code","47ed0346":"code","9d0c69d1":"code","f4a6bbec":"code","50307004":"code","47f68750":"code","449cd9e2":"code","d2969de3":"code","8b70f056":"code","7223a153":"markdown","6b13e808":"markdown","ed1d8adb":"markdown","80b66f1d":"markdown","fcbbfd4b":"markdown","c299374b":"markdown","369a2c83":"markdown","d9763f4c":"markdown","2290a4d7":"markdown","adcf6b73":"markdown","b857eabe":"markdown","11882473":"markdown","d03f3080":"markdown","872cbf86":"markdown","9ab20e16":"markdown","3bab8fbb":"markdown","92524129":"markdown","195aad62":"markdown","abacdc58":"markdown","8d18711c":"markdown","ecf00d74":"markdown","8ee05bfd":"markdown","48ed78f9":"markdown","2fb63318":"markdown"},"source":{"a3d1214e":"!wget https:\/\/storage.googleapis.com\/kaggle-data-sets\/828148%2F1415088%2Fcompressed%2Flast %281%29.pt.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1597579030&Signature=DM%2F5rNsYn2Vc2mPZutF6Ikctl5sApV8rTrDlhbVgdBkb4mcTgK9do%2BHHQTKB6I10ihUOxjDRlZ2khSaQ5jUMWNrZ46PpLUBqkYGxOceykni4KB0PdacWYovZiHCBCKdq3hI6nakCfPS%2BN7GaeMpggm7HutTMU2jwwDEXMyH0LhyA8Ou9h9A5zjehgDQ8mw0yIgtEIW4EPJRtOk2V1u4CHL5PH156l%2FU4F4GAIhHnGYxXJ%2B%2BFD3b8MAmLOIZDu9qnJCr%2BEU6nz4SMUDbFksTtEa4NToKSfnInn8hEwdo0cyRCrRxIu%2BCB0VG3mZ4bxVCZ55ag8F3Uk2p4Z9CjFSlY9A%3D%3D","937b7539":"! conda install -y gdown","80de47ce":"%cd \/kaggle\/working\/\n\n!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n!pip install numpy==1.17\n!pip install PyYAML==5.3.1\n!pip install git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI\n#We'll also install [Apex by NVIDIA]\n!git clone https:\/\/github.com\/NVIDIA\/apex && cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" . --user && cd .. && rm -rf apex","9a64154d":"%cp -arv  \/kaggle\/input\/yolov5-chafik-1\/yolo \/kaggle\/working\n%cd \/kaggle\/working\/yolo\n# start download dataset \n!gdown --id 1e3IQIJf21NTtC-pn6PJwCG1G0T4HyKQM","b38d1704":"%cp -arvf \"\/kaggle\/input\/last-yolo\/last (1).pt\"   \/kaggle\/working\/yolo\/yolov5\/weights\/last.pt\n","61d64df9":"from pathlib import Path\nfrom tqdm import tqdm\nimport numpy as np\nimport json\nimport urllib\nimport PIL.Image as Image\nimport cv2\nimport torch\nimport torchvision\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nrcParams['figure.figsize'] = 16, 10\n\nnp.random.seed(42)","07dd5c71":"\ndir=\"\/content\/perfect_dataset\/images\"\noutput_dir=\"\/content\/datasetFinal\"\nimport cv2\nimport os\n\ncpt=0\nN=len(os.listdir(dir))\n\nfor name in os.listdir(dir):\n    img=cv2.imread(os.path.join(dir,name))\n    img=cv2.resize(img,(196,96))\n    cpt+=1  \n    print(\"\\rpercent {:.2f}%, {}\".format(100*cpt\/N,name), end='')\n\n    cv2.imwrite(os.path.join(output_dir,name), img)\n   \n\n","5019ad4a":"import cv2\nimport os\nimport shutil\nimport numpy as np\n\n\noutput=\"\/content\/drive\/My Drive\/youssra\/yolo\"\nif not os.path.exists(output):\n        os.makedirs(output)\noutput=\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\"\nif not os.path.exists(output):\n        os.makedirs(output)\noutput=\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/images\"\nif not os.path.exists(output):\n        os.makedirs(output)                \noutput=\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/labels\"\nif not os.path.exists(output):\n        os.makedirs(output)  \n\n\ndef split(directory,foldername,liste):\n  nbr=0\n  filePath=\"\/content\/images__0094.txt\"\n\n  output=os.path.join(\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/images\",foldername)\n  if not os.path.exists(output):\n        os.makedirs(output)\n  output=os.path.join(\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/labels\",foldername)\n  if not os.path.exists(output):\n        os.makedirs(output)      \n  print(\"\\n\"+foldername+\"\\n\")      \n  N=len(liste) \n  for image_name in liste:\n      img_path=os.path.join(directory,image_name)\n\n      destination=os.path.join(\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/images\",foldername)\n      shutil.move(img_path, destination)\n      # create new file .txt\n\n\n      original = filePath\n      target = os.path.join(\"\/content\/drive\/My Drive\/youssra\/yolo\/datasetFinal\/labels\",foldername,image_name.split(\".jpg\")[0]+\".txt\")\n\n      shutil.copyfile(original, target)\n      nbr+=1\n      print(\"\\rpercent {:.2f}%, {}:{}\".format(100*nbr\/N,foldername,nbr), end='')\n  \n\n\n# find all images\nimages_dir=\"\/content\/datasetFinal\"\nlistOfImages=os.listdir(images_dir)\nnbr=len(listOfImages)\n#take 80 percent of dataset for traing\nN=int(nbr*0.80)\nnp.random.shuffle(listOfImages)\n# train\ndirectory=\"\/content\/datasetFinal\"\nsplit(directory,\"train\",liste=listOfImages[-N:])\n# # val\ndirectory=\"\/content\/datasetFinal\"\nsplit(directory,\"val\",liste=listOfImages[:-N])\n\n","8e3816c1":"import os\noutput=\"\/kaggle\/working\/yolo\"\nif not os.path.exists(output):\n    os.makedirs(output)\n    \n%cd \/kaggle\/working\/yolo\n\n!mkdir dataset_21_2825_2\n%cd  dataset_21_2825_2\n\n\n!curl -L \"https:\/\/app.roboflow.ai\/ds\/QKJSwZ1IzA?key=gQ0GD10nQO\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip","b821ed39":"%cd \/kaggle\/working\/yolo\/dataset_21_2825_2\n%cp -arvn test\/images\/* valid\/images \n%cp -arvn test\/labels\/* valid\/labels\n!rm -rf \"\/kaggle\/working\/yolo\/dataset_21_2825_2\/test\"\n","8044f96b":"%cd \/kaggle\/working\/yolo\/dataset_21_2825_2\n%mv train\/images train\/train\n%mv train\/labels  valid\/train\n\n%mv valid\/images  train\/val\n%mv  valid\/labels valid\/val\n\n%mv train images\n%mv valid labels","ce4085fb":"ls \/kaggle\/working\/dataset_21_2825","362b97c7":"import csv\nimport os\nimport copy\n\ndef convert_list_to_string(org_list, seperator=' '):\n    \"\"\" Convert list to string, by joining all item in list with given separator.\n        Returns the concatenated string \"\"\"\n    return seperator.join(org_list)\n\ndef checkClasses(input_dir,input_folder,output_folder):\n    output=os.path.join(input_dir,output_folder)\n    #names=['Metale80A', 'fusible10mini', 'fusible15Medium', 'fusible15mini', 'fusible20', 'fusible20Medium', 'fusible20mini', 'fusible30Medium', 'fusible40', 'fusible5', 'fusible50', 'fusible60', 'fusible70', 'fusible80', 'relai', 'relaiGreen', 'relaiYellow', 'symbole', 'vide']\n    names=['fusible5','fusible10mini','fusible15Medium','fusible15mini','fusible20','fusible20Medium','fusible20mini','fusible30Double','fusible30Medium','fusible40','fusible40Medium','fusible50','fusible60','fusible70','fusible80','Metale80A','relai','relaiGreen','relaiYellow','symbole','vide']\n    if not os.path.exists(output):\n        os.makedirs(output)\n    print(\"\\n\"+input_folder+\"\\n\")\n    cpt=0\n    output_file=os.path.join(input_dir,output_folder)\n    N=len(os.listdir(os.path.join(input_dir,input_folder)))\n    for fileName in os.listdir(os.path.join(input_dir,input_folder)):\n      if fileName!=\".ipynb_checkpoints\" and fileName != \".ipynb_checkpoints.txt\":\n        \n        input_file=os.path.join(input_dir,input_folder,fileName)\n        output_file=os.path.join(input_dir,output_folder,fileName)\n        # Using readlines() \n        file1 = open(input_file, 'r') \n        file2 = open(output_file, 'w') \n        Lines = file1.readlines() \n        className=fileName.split(\"_jpg.\")[0]\n        numOfClass=names.index(className)\n        cpt+=1\n        # Strips the newline character \n        for line in Lines: \n          \n          # Replace the target string\n          column=line.split(\" \")\n          column[0]=str(numOfClass)\n          line = convert_list_to_string(column)\n          file2.write(line)\n        file2.close()\n        file1.close()\n        print(\"\\rpercent {:.2f}%\".format(100*cpt\/N), end='')\n\n\n\ninput_dir= \"\/kaggle\/working\/yolo\/dataset_21_2825_2\/labels\"\ninput_folder=\"train\"\noutput_folder=\"train1\"\ncheckClasses(input_dir,input_folder,output_folder)\ninput_folder=\"val\"\noutput_folder=\"val1\"\ncheckClasses(input_dir,input_folder,output_folder)\n\n\n","2daa2635":"print(\"\\n******\\n\")\n%cd \/kaggle\/working\/yolo\/dataset_21_2825_2\/labels\n!rm -rf  train val\n\n!mv train1 train\n!mv val1 val","0066cd6d":"cp -arv \/kaggle\/input\/yolov5-chafik-1\/yolo\/data\/data_21_2825.yaml \/kaggle\/working\/yolo\/data\/data_21_2825_2.yaml ","13a59f37":"    input_file='\/kaggle\/working\/yolo\/data\/data_21_2825_2.yaml'\n    text_to_search='dataset_21_2825'\n    # print(text_to_search)\n    replacement_text='dataset_21_2825_2'\n    #read input file\n    fin = open(input_file, \"rt\")\n    #read file contents to string\n    data = fin.read()\n    #replace all occurrences of the required string\n    data = data.replace(text_to_search, replacement_text)\n    #close the input file\n    fin.close()\n    #open the input file in write mode\n    fin = open(input_file, \"wt\")\n    #overrite the input file with the resulting data\n    fin.write(data)\n    #close the file\n    fin.close()","232dfc79":"%cp -arvn \/kaggle\/working\/yolo\/dataset_21_2825_2\/*  \/kaggle\/working\/yolo\/dataset_21_2825\/\n%ls  \/kaggle\/working\/yolo\/dataset_21_2825\/labels\/train | wc","bd066c35":"ls  \/kaggle\/working\/yolo\/dataset_21_2825\/labels\/train | wc","63b64db6":"%cd \/kaggle\/working\/yolo\n\n!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd yolov5\n!git checkout ec72eea62bf5bb86b0272f2e65e413957533507f","608187e9":"ls  \/kaggle\/input\/data-file","93833136":"%cd \/kaggle\/working\/yolo\/yolov5\/\n!rm -rf detect.py train.py test.py\n%cd \/kaggle\/input\/data-file\/\n%cp -arv detect.py  test.py  train.py \/kaggle\/working\/yolo\/yolov5\/\n!mkdir \/kaggle\/working\/yolo\/data\n\n%cp -arv data_21_2825.yaml \/kaggle\/working\/yolo\/data\n!rm -rf \/kaggle\/working\/yolo\/yolov5\/models\/yolov5x.yaml\n%cd \/kaggle\/input\/data-file\/\n%cp -arv yolov5x.yaml \/kaggle\/working\/yolo\/yolov5\/models","a8447e8d":"!ls \/kaggle\/working\/yolo\/yolov5\/weights\/","6e6af3c2":"# download last.pt\n!gdown --id 1vKO0gzGf2pdEOB0lJPtYQ4o_vKlKKYWG -O \/kaggle\/working\/yolo\/yolov5\/weights\/","6db1be02":"rm -rf \/kaggle\/working\/yolo.tar.gz","8625b74c":"%cd \/kaggle\/working\/\n!tar -czvf yolo.tar.gz  yolo\/","b54a0850":"%cd \/kaggle\/working\/\n%cp -arv yolo.tar.gz  \/kaggle\/input\/data-file\/","10b43a96":"!pip install pydrive","aafa129a":"!pip install google-colab","7f49c5dd":"from google.colab import files\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n      name=fn, length=len(uploaded[fn])))\n  \n# Then move kaggle.json into the folder where the API expects to find it.\n!mkdir -p ~\/.kaggle\/ && mv kaggle.json ~\/.kaggle\/ && chmod 600 ~\/.kaggle\/kaggle.json","2177e5e5":"%cd \/kaggle\/working\/yolo\/yolov5\n!python train.py  --batch 7 --epochs 3500 \\\n  --data ..\/data\/data_21_2825.yaml  \\\n  --name yolov5x_21_2825  --img 1024 --cfg ..\/models\/yolov5x.yaml --weights .\/weights\/last.pt \\\n  # --adam #--cache","d1e717ea":"%cp -arvn \/kaggle\/working\/yolo\/yolov5\/weights\/last.pt \/kaggle\/working\/\n#%cp -arv \/kaggle\/working\/yolo\/yolov5\/weights\/best.pt \/kaggle\/working\/","5a19b37e":"rm -rf \"\/kaggle\/working\/last (1).pt\" \/kaggle\/working\/best.pt \/kaggle\/working\/last.pt","7167a9b2":"%cd \/kaggle\/working\/yolo\/yolov5\n# Look at training curves in tensorboard:\n%load_ext tensorboard\n%tensorboard --logdir=runs","77ff2423":"!mkdir \/kaggle\/working\/weights","05528f63":"ls -s \/kaggle\/working\/yolo\/yolov5\/weights\/ \/kaggle\/working\/weights","cd41cdb0":"%cd \/kaggle\/working\/yolo\/yolov5\n!ls -l .\/weights\/","7778b661":"%cp -arv \/kaggle\/working\/yolov5 \/kaggle\/input\/data-file\/","e81908a6":"from IPython.display import FileLink\nFileLink('\/kaggle\/last.csv')","38e4f8df":"%cp -arv \/kaggle\/working\/last.pt \/kaggle\/last.csv","7978fc12":"from utils.utils import plot_results\n\nplot_results();","8d813214":"ls \/kaggle\/working\/yolo\/yolov5\/data","8a7c831f":"# Run YOLOv5s on COCO test-dev2017 with argument --task test\n%cd \/kaggle\/working\/yolo\/yolov5\n\n# Run YOLOv5s on COCO test-dev2017 with argument --task test\n!python test.py --weights .\/weights\/best.pt \\\n--data ..\/data\/data_21_2825.yaml --task val","39ca8d71":"cp -arv ","47ed0346":"import base64\nimport io\nimport json\nimport os\nfrom email import utils, encoders\nfrom email.message import EmailMessage\nfrom email.mime import application, multipart, text, base, image, audio\nimport mimetypes\n\nfrom apiclient import errors\nfrom googleapiclient import discovery, http\nfrom google.oauth2 import service_account","9d0c69d1":"\n\n\ndef get_environment_variables():\n    \"\"\" Retrieves the environment variables and returns them in\n        a dictionary object.\n    \"\"\"\n    env_var_dict = {\n        'to': os.environ.get('TO'),\n        'subject': os.environ.get('SUBJECT'),\n        'body': os.environ.get('BODY'),\n        'file': os.environ.get('FILE')\n    }\n\n    return env_var_dict\n\n\ndef send_email(email_subject, email_body, email_sender='my_service_account@gmail.com', email_to='', email_cc='', email_bcc='', files=None):\n\n    # Pulling in the string value of the service key from the parameter\n    with open(os.environ.get('SERVICE_KEY_PASSWORD')) as f:\n        service_account_info = json.loads(f.read())\n\n    # Define which scopes we're trying to access\n    SCOPES = ['https:\/\/www.googleapis.com\/auth\/gmail.send']\n\n    # Setting up credentials using the gmail api\n    credentials = service_account.Credentials.from_service_account_info(service_account_info, scopes=SCOPES)\n    # This allows us to assign an alias account to the message so that the messages aren't coming from 'ServiceDriod-8328balh blah blah'\n    delegated_credentials = credentials.with_subject(email_sender)\n    # 'Building' the service instance using the credentials we've passed\n    service = discovery.build(serviceName='gmail', version='v1', credentials=delegated_credentials)\n\n    # Building out the email \n    message = multipart.MIMEMultipart()\n    message['to'] = email_to\n    message['from'] = email_sender\n    message['date'] = utils.formatdate(localtime=True)\n    message['subject'] = email_subject\n    message['cc'] = email_cc\n    message['bcc'] = email_bcc\n    message.attach(text.MIMEText(email_body, 'html'))\n\n\n    for f in files or []:\n        f = f.strip(' ')\n        mimetype, encoding = mimetypes.guess_type(f)\n\n        # If the extension is not recognized it will return: (None, None)\n        # If it's an .mp3, it will return: (audio\/mp3, None) (None is for the encoding)\n        # For an unrecognized extension we set mimetype to 'application\/octet-stream' so it won't return None again. \n        if mimetype is None or encoding is not None:\n            mimetype = 'application\/octet-stream'\n        main_type, sub_type = mimetype.split('\/', 1)\n\n        # Creating the attachement:\n        # This part is used to tell how the file should be read and stored (r, or rb, etc.)\n        if main_type == 'text':\n            print('text')\n            with open(f, 'rb') as outfile:\n                attachement = text.MIMEText(outfile.read(), _subtype=sub_type)\n        elif main_type == 'image':\n            print('image')\n            with open(f, 'rb') as outfile:\n                attachement = image.MIMEImage(outfile.read(), _subtype=sub_type)\n        elif main_type == 'audio':\n            print('audio')\n            with open(f, 'rb') as outfile:\n                attachement = audio.MIMEAudio(outfile.read(), _subtype=sub_type)          \n        elif main_type == 'application' and sub_type == 'pdf':   \n            with open(f, 'rb') as outfile:\n                attachement = application.MIMEApplication(outfile.read(), _subtype=sub_type)\n        else:                              \n            attachement = base.MIMEBase(main_type, sub_type)\n            with open(f, 'rb') as outfile:\n                attachement.set_payload(outfile.read())\n\n        encoders.encode_base64(attachement)\n        attachement.add_header('Content-Disposition', 'attachment', filename=os.path.basename(f))\n        message.attach(attachement)\n\n    media_body = http.MediaIoBaseUpload(io.BytesIO(message.as_bytes()), mimetype='message\/rfc822', resumable=True)\n    body_metadata = {} # no thread, no labels in this example\n\n    try:\n        print('Uploading file...')\n        response = service.users().messages().send(userId='me', body=body_metadata, media_body=media_body).execute()\n        print(response)\n    except errors.HttpError as error:\n        print('An error occurred when sending the email:\\n{}'.format(error))\n\n\nif __name__ == '__main__':\n\n    env_var_dict = get_environment_variables()\n    print(\"Sending email...\")\n    send_email(email_subject=env_var_dict['subject'], \n            email_body=env_var_dict['body'], \n            email_to=env_var_dict['to'],\n            files=env_var_dict['file'].split(','))\n\n    print(\"Email sent!\")","f4a6bbec":"%cd \/kaggle\/working\/yolo\/yolov5\n!find ..\/dataset_21_2825\/images\/val\/ -maxdepth 1 -type f | head -10 | xargs cp -t \"inference\/images\/\"","50307004":"cp -arv \"\/content\/drive\/My Drive\/youssra\/yolo\/dataset\/test\/images\" \"\/content\/drive\/My Drive\/youssra\/yolo\/yolov5\/inference\/\"","47f68750":"%cd \/kaggle\/working\/yolo\/yolov5\n!python detect.py --weights weights\/best.pt \\\n  --conf 0.5 --source inference\/images\/  --img 1024 # --view-img\n\nimport os,cv2\nimport matplotlib.pyplot as plt\ninput_dir=\"\/kaggle\/working\/yolo\/yolov5\/inference\/output\"\nfor imageName in os.listdir(input_dir):\n  img=cv2.imread(os.path.join(input_dir,imageName))\n  #ploting image with predicted class name        \n  plt.figure(figsize = (15,16))\n  plt.imshow(img)\n  plt.axis('off')\n  plt.title(\"***\")\n  plt.show()  ","449cd9e2":"def load_image(img_path: Path, resize=True):\n  img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n  img = cv2.resize(img, (128, 256), interpolation = cv2.INTER_AREA)\n  return img\n\ndef show_grid(image_paths):\n  images = [load_image(img) for img in image_paths]\n  images = torch.as_tensor(images)\n  images = images.permute(0, 3, 1, 2)\n  grid_img = torchvision.utils.make_grid(images, nrow=11)\n  plt.figure(figsize=(24, 12))\n  plt.imshow(grid_img.permute(1, 2, 0))\n  plt.axis('off');","d2969de3":"#ploting image with predicted class name        \nplt.figure(figsize = (4,4))\nplt.imshow(new_img)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","8b70f056":"img_paths = list(Path(\"inference\/output\").glob(\"*.jpeg\"))[:22]\nshow_grid(img_paths)","7223a153":"# **Install gdown**","6b13e808":"We need two configuration files. One for the dataset and one for the model we're going to use. Let's download them:","ed1d8adb":"## References\n\n- [Clothing Item Detection for E-Commerce dataset](https:\/\/www.kaggle.com\/dataturks\/clothing-item-detection-for-ecommerce)\n- [YOLOv5 GitHub](https:\/\/github.com\/ultralytics\/yolov5)\n- [YOLOv5 Train on Custom Data](https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data)\n- [NVIDIA Apex on GitHub](https:\/\/github.com\/NVIDIA\/apex)\n- [YOLOv4: Optimal Speed and Accuracy of Object Detection](https:\/\/arxiv.org\/pdf\/2004.10934.pdf)","80b66f1d":"# **Test**","fcbbfd4b":"## **Evaluation**\n\nThe project includes a great utility function `plot_results()` that allows you to evaluate your model performance on the last training run:","c299374b":"# **Training**","369a2c83":"# **download yolov5 with dataset**","d9763f4c":"## Summary\n\nYou now know how to create a custom dataset and fine-tune one of the YOLO v5 models on your own. Nice!\n\n- [Read the tutorial](https:\/\/www.curiousily.com\/posts\/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python\/)\n- [Run the notebook in your browser (Google Colab)](https:\/\/colab.research.google.com\/drive\/1e4zvS6LyhOAayEDh3bz8MXFTJcVFSvZX?usp=sharing)\n- [Read the `Getting Things Done with Pytorch` book](https:\/\/github.com\/curiousily\/Getting-Things-Done-with-Pytorch)\n\nHere's what you've learned:\n\n- Install required libraries\n- Build a custom dataset in YOLO\/darknet format\n- Learn about YOLO model family history\n- Fine-tune the largest YOLO v5 model\n- Evaluate the model\n- Look at some predictions\n\nHow well does your model do on your dataset? Let me know in the comments below.\n\nIn the next part, you'll learn how to deploy your model a mobile device.","2290a4d7":"To be honest with you. I am really blown away with the results!","adcf6b73":"We'll use the `detect.py` script to run our model on the images. Here are the parameters we're using:\n\n- weights weights\/best_yolov5x_clothing.pt - checkpoint of the model\n- img 640 - resize the images to 640x640 px\n- conf 0.4 - take into account predictions with confidence of 0.4 or higher\n- source .\/inference\/images\/ - path to the images","b857eabe":"# Object Detection on a Custom Dataset using YOLO v5\n\n> TL;DR Learn how to build a custom dataset for YOLO v5 (darknet compatible) and use it to fine-tune a large object detection model. The model will be ready for real-time object detection on mobile devices.\n\nIn this tutorial, you'll learn how to fine-tune a pre-trained YOLO v5 model for detecting and classifying clothing items from images.\n\n- [Read the tutorial](https:\/\/www.curiousily.com\/posts\/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python\/)\n- [Run the notebook in your browser (Google Colab)](https:\/\/colab.research.google.com\/drive\/1e4zvS6LyhOAayEDh3bz8MXFTJcVFSvZX?usp=sharing)\n- [Read the `Getting Things Done with Pytorch` book](https:\/\/github.com\/curiousily\/Getting-Things-Done-with-Pytorch)\n\nHere's what we'll go over:\n\n- Install required libraries\n- Build a custom dataset in YOLO\/darknet format\n- Learn about YOLO model family history\n- Fine-tune the largest YOLO v5 model\n- Evaluate the model\n- Look at some predictions\n\nHow good our final model is going to be?\n\n","11882473":"## **Making predictions**\n\nLet's pick 50 images from the validation set and move them to `inference\/images` to see how our model does on those:","d03f3080":"# **Check number of each class**","872cbf86":"## Prerequisites\n\nLet's start by installing some required libraries by the YOLOv5 project:","9ab20e16":"# **Split Dataset**","3bab8fbb":"The training took around 30 minutes on Tesla P100. The best model checkpoint is saved to `weights\/best_yolov5x_clothing.pt`.","92524129":"Here are some of the images along with the detected clothing:","195aad62":"We'll write a helper function to show the results:","abacdc58":"The dataset contains a single JSON file with URLs to all images and bounding box data.\n\nLet's import all required libraries:","8d18711c":"# **Resize Dataset**","ecf00d74":"# **download yolov5**","8ee05bfd":"Looks like the mean average precision (mAP) is getting better throughout the training. The model might benefit from more training, but it is good enough.","48ed78f9":"# **Import Dataset**","2fb63318":"# ***Trianing***"}}