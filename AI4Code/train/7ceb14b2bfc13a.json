{"cell_type":{"194c618e":"code","95f95ab9":"code","7f14e8d3":"code","7e06be03":"code","24072c9e":"code","1ea0ea03":"code","f0e6e7d7":"code","1ae1d08e":"code","03bac8c6":"markdown","67c97edc":"markdown","a2b2aa63":"markdown","4ccaae1e":"markdown","1231b712":"markdown","09699d02":"markdown","2346d166":"markdown"},"source":{"194c618e":"# importing library to handle files\nimport os\nfrom os import listdir\n\n# importing library to handle runtime manipulation\nimport sys\n\n# importing library to parse annotations\nfrom xml.etree import ElementTree\n\n# importing library to deal with numeric arrays\nimport numpy\nfrom numpy import zeros\nfrom numpy import asarray\nfrom numpy import expand_dims","95f95ab9":"# installing tensorflow 1.15 to ensure compatibility with Mask R-CNN\n!pip install tensorflow==1.15\n\nimport tensorflow as tf\n\nprint(tf.__version__)","7f14e8d3":"# installing keras 2.1.0 to ensure compatibility with Mask R-CNN\n!pip install keras==2.1.0\n\nimport keras\n\nprint(keras.__version__)","7e06be03":"# cloning Mask R-CNN from Github\n!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n\n# directory to save logs and trained model\nROOT_DIR = '\/kaggle\/working'\nsys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))\n\n# importing Mask R-CNN\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nfrom mrcnn.model import mold_image\nfrom mrcnn.utils import Dataset\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log","24072c9e":"# class that defines and loads the kangaroo dataset\nclass KangarooDataset(Dataset):\n    \n    # loading the dataset definitions\n    def load_dataset(self, dataset_dir, is_train=True):\n        \n        # defining one class\n        self.add_class(\"dataset\", 1, \"kangaroo\")\n        \n        # defining data locations\n        images_dir = dataset_dir + '\/images\/'\n        annotations_dir = dataset_dir + '\/annots\/'\n        \n        # finding all images\n        for filename in listdir(images_dir):\n            \n            # extracting image id\n            image_id = filename[:-4]\n            \n            # limiting to 4 images for starter code\n            if int(image_id) <=4:\n            \n                # skipping bad images\n                if image_id in ['00090']:\n                    continue\n                    \n                # skipping all images after 2 if we are building the train set\n                if is_train and int(image_id) <= 2:\n                    continue\n                    \n                # skipping all images before 2 if we are building the test\/val set\n                if not is_train and int(image_id) > 2:\n                    continue\n                    \n                img_path = images_dir + filename\n                ann_path = annotations_dir + image_id + '.xml'\n                \n                # adding to dataset\n                self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n            \n    # loading all bounding boxes for an image\n    def extract_boxes(self, filename):\n        \n        # loading and parsing the file\n        root = ElementTree.parse(filename)\n        boxes = list()\n        \n        # extracting each bounding box\n        for box in root.findall('.\/\/bndbox'):\n            xmin = int(box.find('xmin').text)\n            ymin = int(box.find('ymin').text)\n            xmax = int(box.find('xmax').text)\n            ymax = int(box.find('ymax').text)\n            coors = [xmin, ymin, xmax, ymax]\n            boxes.append(coors)\n            \n        # extracting image dimensions\n        width = int(root.find('.\/\/size\/width').text)\n        height = int(root.find('.\/\/size\/height').text)\n        \n        return boxes, width, height\n    \n    # loading the masks for an image\n    def load_mask(self, image_id):\n        \n        # getting details of image\n        info = self.image_info[image_id]\n        \n        # defining box file location\n        path = info['annotation']\n        \n        # loading XML\n        boxes, w, h = self.extract_boxes(path)\n        \n        # creating one array for all masks, each on a different channel\n        masks = zeros([h, w, len(boxes)], dtype='uint8')\n        \n        # creating masks\n        class_ids = list()\n        \n        for i in range(len(boxes)):\n            box = boxes[i]\n            row_s, row_e = box[1], box[3]\n            col_s, col_e = box[0], box[2]\n            masks[row_s:row_e, col_s:col_e, i] = 1\n            class_ids.append(self.class_names.index('kangaroo'))\n            \n        return masks, asarray(class_ids, dtype='int32')\n \n    # loading an image reference\n    def image_reference(self, image_id):\n        \n        info = self.image_info[image_id]\n        \n        return info['path']","1ea0ea03":"# class that defines the configuration\nclass KangarooConfig(Config):\n    \n    # defining the name of the configuration\n    NAME = \"kangaroo_cfg\"\n    \n    # number of classes (background + kangaroo)\n    NUM_CLASSES = 1 + 1\n    \n    # number of training steps per epoch, images per GPU, bacth size and validation steps\n    STEPS_PER_EPOCH = 2\n    IMAGES_PER_GPU = 1\n    BATCH_SIZE = 1\n    VALIDATION_STEPS = 2","f0e6e7d7":"# downloading pre-trained weights for Mask R-CNN\n!wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n!ls -lh mask_rcnn_coco.h5\n\nCOCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\"","1ae1d08e":"# preparing train set\ntrain_set = KangarooDataset()\ntrain_set.load_dataset('\/kaggle\/input\/wildlife-images-kangaroo\/Wildlife_Kangaroo', is_train=True)\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_ids))\n\n# preparing test\/val set\ntest_set = KangarooDataset()\ntest_set.load_dataset('\/kaggle\/input\/wildlife-images-kangaroo\/Wildlife_Kangaroo', is_train=False)\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_ids))\n\n# preparing config\nconfig = KangarooConfig()\nconfig.display()\n\n# defining the model\nmodel = modellib.MaskRCNN(mode='training', model_dir=ROOT_DIR, config=config)\n\n# loading weights (mscoco) and exclude the output layers\nmodel.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n\n# training weights (output layers or 'heads')\nmodel.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=1, layers='heads')","03bac8c6":"# Model weights","67c97edc":"I'd like to thank Jason Brownlee for providing an in depth explanation (which can be accessed [here](https:\/\/machinelearningmastery.com\/how-to-train-an-object-detection-model-with-keras\/)) of the starter code for Mask R-CNN implemented in this kaggle kernel.\n\nThe code being run in this notebook is only for demonstration purposes; to evaluate the model and improve its performance, many more images from the original dataset need to be included in the training and test sets.","a2b2aa63":"# Model training","4ccaae1e":"# Importing libraries","1231b712":"# Model configuration","09699d02":"# Preprocessing","2346d166":"# Acknowledgment"}}