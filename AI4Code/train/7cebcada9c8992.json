{"cell_type":{"4b6988fe":"code","7ab9e75c":"code","8d9a4ecc":"code","b72d633a":"code","e8e89ef3":"code","90ce6088":"code","09c704f5":"code","8cbb232e":"code","12b8102a":"code","abad2068":"code","d4030721":"code","e724031e":"code","fd9c54ef":"code","66e4eddf":"code","5dac5935":"code","019ae880":"code","02a7980c":"code","afb99ab2":"code","1cd3485c":"code","554b5121":"code","29783d61":"code","4c440540":"code","54a678cf":"code","c42d07e2":"code","8aa91298":"code","92950a32":"code","7663dabd":"code","e625fa61":"code","bcaaf909":"code","f6d78b6f":"code","6aa8b851":"code","7c1f2872":"code","072031dd":"code","c3bdd846":"code","678d5369":"code","f5204ee1":"code","59bf32a7":"code","d9041ba2":"code","6e395225":"code","cd5a03a3":"code","875596e9":"code","1b89f381":"code","062fc922":"code","0a66dbcb":"code","c85648ed":"code","f50326ca":"code","659ba2b2":"code","82b6ac98":"code","836446f0":"code","171e0642":"code","f79332cc":"code","568e8b23":"code","1133f9f8":"code","52c92f43":"code","77b0be05":"code","316eae32":"code","b7d4c7dd":"code","e7f37dd9":"code","a5fb21f8":"code","e0bf6cc0":"code","a31507ac":"code","d6067f75":"code","a7b6d30f":"code","1711ea44":"code","b3a756b7":"code","179f0f1b":"code","db1d22b6":"code","fe8c4eeb":"code","c4e0c565":"code","8c93863d":"code","6ef25118":"code","4d6f7f25":"code","8fc7b617":"code","4e9ea9e1":"markdown","b581d347":"markdown","8e6e4278":"markdown","c80e7dc8":"markdown","cd6d7273":"markdown","23b84220":"markdown","12406087":"markdown","edd69777":"markdown","6ffe5602":"markdown"},"source":{"4b6988fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ab9e75c":"import warnings\nwarnings.filterwarnings('ignore')\n\n#importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","8d9a4ecc":"cars = pd.read_csv('..\/input\/car-data\/CarPrice_Assignment.csv')\ncars.head()","b72d633a":"cars.shape","e8e89ef3":"cars.describe()","90ce6088":"cars.info()","09c704f5":"#Data Cleaning and preparatin ","8cbb232e":"CompanyName = cars['CarName'].apply(lambda x : x.split(' ')[0])\ncars.insert(3,\"CompanyName\", CompanyName)\ncars.drop(['CarName'], axis=1, inplace=True)\ncars.head()","12b8102a":"cars.CompanyName.unique()","abad2068":"cars.CompanyName = cars.CompanyName.str.lower()\n\ndef replace_name(a,b):\n    cars.CompanyName.replace(a,b,inplace=True)\n\nreplace_name('maxda','mazda')\nreplace_name('porcshce','porsche')\nreplace_name('toyouta','toyota')\nreplace_name('vokswagen','volkswagen')\nreplace_name('vw','volkswagen')\n\ncars.CompanyName.unique()","d4030721":"cars.loc[cars.duplicated()]","e724031e":"cars.columns","fd9c54ef":"#vizualing the data\nplt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Car Price Distribution Plot')\nsns.distplot(cars.price)\n\nplt.subplot(1,2,2)\nplt.title('Car Price Spread')\nsns.boxplot(y=cars.price)\n\nplt.show()","66e4eddf":"print(cars.price.describe(percentiles = [0.25,0.50,0.75, 0.85, 0.90, 1]))","5dac5935":"plt.figure(figsize=(25,6))\n\nplt.subplot(1,3,1)\nplt1 = cars.CompanyName.value_counts().plot(kind='bar')\nplt.title('Companies Histogram')\nplt1.set(xlabel = 'Car Company', ylabel='Frequency of company ')\n\nplt.subplot(1,3,2)\nplt1 = cars.fueltype.value_counts().plot(kind='bar')\nplt.title('Fuel Type Histogram')\nplt1.set(xlabel = 'Fuel Type', ylabel='Frequency of fuel type ')\n\nplt.subplot(1,3,3)\nplt1 = cars.carbody.value_counts().plot(kind='bar')\nplt.title('Car Type Histogram')\nplt1.set(xlabel = 'Car Type', ylabel='Frequency of car Type ')\n\nplt.show()","019ae880":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Symboling Histogram')\nsns.countplot(cars.symboling, palette=('cubehelix'))\n\nplt.subplot(1,2,2)\nplt.title('Symboling vs Price')\nsns.boxplot(x=cars.symboling, y=cars.price, palette=(\"cubehelix\"))\n\nplt.show()","02a7980c":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nplt.title('Engine Type Histogram')\nsns.countplot(cars.enginetype, palette=(\"Blues_d\"))\n\nplt.subplot(1,2,2)\nplt.title('Engine Type vs Price')\nsns.boxplot(x=cars.enginetype, y=cars.price, palette=(\"PuBuGn\"))\n\nplt.show()","afb99ab2":"df = pd.DataFrame(cars.groupby(['enginetype'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar(figsize=(8,6))\nplt.title('Engine Type vs Average Price')\nplt.show()","1cd3485c":"plt.figure(figsize=(25, 6))\n\ndf = pd.DataFrame(cars.groupby(['CompanyName'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Company Name vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['fueltype'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['carbody'])['price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Car Type vs Average Price')\nplt.show()\n","554b5121":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.title('Door Number Histogram')\nsns.countplot(cars.doornumber, palette=(\"plasma\"))\n\nplt.subplot(1,2,2)\nplt.title('Door Number vs Price')\nsns.boxplot(x=cars.doornumber, y=cars.price, palette=(\"plasma\"))\n\nplt.show()\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.title('Aspiration Histogram')\nsns.countplot(cars.aspiration, palette=(\"plasma\"))\n\nplt.subplot(1,2,2)\nplt.title('Aspiration vs Price')\nsns.boxplot(x=cars.aspiration, y=cars.price, palette=(\"plasma\"))\n\nplt.show()","29783d61":"def plot_count(x,fig):\n    plt.subplot(4,2,fig)\n    plt.title(x+'Histogram')\n    sns.countplot(cars[x], palette=('magma'))\n    plt.subplot(4,2,(fig+1))\n    plt.title(x+'vs Price')\n    sns.boxplot(x=cars[x], y=cars.price, palette=('magma'))\n    \nplt.figure(figsize=(15,20))\n\nplot_count('enginelocation', 1)\nplot_count('cylindernumber', 3)\nplot_count('fuelsystem', 5)\nplot_count('drivewheel', 7)\n\nplt.tight_layout()","4c440540":"def scatter(x,fig):\n    plt.subplot(5,2,fig)\n    plt.scatter(cars[x],cars['price'])\n    plt.title(x+'vs Price')\n    plt.ylabel('Price')\n    plt.xlabel(x)\n    \nplt.figure(figsize=(10,20))\n\nscatter('carlength', 1)\nscatter('carwidth', 2)\nscatter('carheight', 3)\nscatter('curbweight', 4)\n\nplt.tight_layout()","54a678cf":"def pp(x,y,z):\n    sns.pairplot(cars, x_vars=[x,y,z], y_vars='price', size=4, aspect=1, kind='scatter')\n    plt.show()\n    \npp('enginesize','boreratio', 'stroke')\npp('compressionratio', 'horsepower', 'peakrpm')\npp('wheelbase', 'citympg', 'highwaympg')","c42d07e2":"np.corrcoef(cars['carlength'], cars['carwidth'])[0, 1]","8aa91298":"#Fuel economy\ncars['fueleconomy'] = (0.55 * cars['citympg']) + (0.45 * cars['highwaympg'])","92950a32":"#Binning the Car Companies based on avg prices of each Company.\ncars['price'] = cars['price'].astype('int')\ntemp = cars.copy()\ntable = temp.groupby(['CompanyName'])['price'].mean()\ntemp = temp.merge(table.reset_index(), how='left',on='CompanyName')\nbins = [0,10000,20000,40000]\ncars_bin=['Budget','Medium','Highend']\ncars['carsrange'] = pd.cut(temp['price_y'],bins,right=False,labels=cars_bin)\ncars","7663dabd":"#Bivariate analysis\nplt.figure(figsize=(8,6))\n\nplt.title('Fuel economy vs Price')\nsns.scatterplot(x=cars['fueleconomy'],y=cars['price'],hue=cars['drivewheel'])\nplt.xlabel('Fuel Economy')\nplt.ylabel('Price')\n\nplt.show()\nplt.tight_layout()","e625fa61":"#fuel economy has a negative correlation between price and is significant\n","bcaaf909":"plt.figure(figsize=(25,6))\n\ndf = pd.DataFrame(cars.groupby(['fuelsystem','drivewheel','carsrange'])['price'].mean().unstack(fill_value=0))\ndf.plot.bar()\nplt.title('Car Range vs Average Price')\nplt.show()","f6d78b6f":"cars_lr = cars[['price', 'fueltype', 'aspiration','carbody', 'drivewheel','wheelbase',\n                  'curbweight', 'enginetype', 'cylindernumber', 'enginesize', 'boreratio','horsepower', \n                    'fueleconomy', 'carlength','carwidth', 'carsrange']]\ncars_lr.head()","6aa8b851":"sns.pairplot(cars_lr)\nplt.show()","7c1f2872":"#Defining the map function\n\ndef dummies(x,df):\n    temp = pd.get_dummies(df[x],drop_first = True)\n    df = pd.concat([df, temp], axis = 1)\n    df.drop([x], axis = 1, inplace = True)\n    return df\n\n# Applying the function to the cars_lr\n\ncars_lr = dummies('fueltype',cars_lr)\ncars_lr = dummies('aspiration',cars_lr)\ncars_lr = dummies('carbody',cars_lr)\ncars_lr = dummies('drivewheel',cars_lr)\ncars_lr = dummies('enginetype',cars_lr)\ncars_lr = dummies('cylindernumber',cars_lr)\ncars_lr = dummies('carsrange',cars_lr)","072031dd":"cars_lr.head()","c3bdd846":"#Train-test split and feature scaling\n\nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(cars_lr, train_size=0.7, test_size= 0.3, random_state=100)","678d5369":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnum_vars = ['wheelbase', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","f5204ee1":"df_train.head()","59bf32a7":"df_train.describe()","d9041ba2":"#Correlation using heatmap\nplt.figure(figsize = (30,25))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","6e395225":"#Dividing data into X and y variables\ny_train = df_train.pop('price')\nX_train = df_train","cd5a03a3":"#Model building\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","875596e9":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm,10)\nrfe = rfe.fit(X_train, y_train)","1b89f381":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","062fc922":"X_train.columns[rfe.support_]","0a66dbcb":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","c85648ed":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X","f50326ca":"def checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","659ba2b2":"#MODEL 1\nX_train_new = build_model(X_train_rfe,y_train)","82b6ac98":"#p-vale of twelve seems to be higher than the significance value of 0.05, hence dropping it as it is insignificant in presence of other variables.","836446f0":"X_train_new = X_train_rfe.drop([\"twelve\"], axis = 1)","171e0642":"#MODEL 2\nX_train_new = build_model(X_train_new,y_train)","f79332cc":"X_train_new = X_train_new.drop([\"fueleconomy\"], axis = 1)","568e8b23":"#MODEL 3\nX_train_new = build_model(X_train_new,y_train)","1133f9f8":"#Calculating the Variance Inflation Factor\ncheckVIF(X_train_new)","52c92f43":"#dropping curbweight because of high VIF value.\nX_train_new = X_train_new.drop([\"curbweight\"], axis = 1)","77b0be05":"#MODEL 4\nX_train_new = build_model(X_train_new,y_train)","316eae32":"checkVIF(X_train_new)","b7d4c7dd":"#MODEL 5\nX_train_new = build_model(X_train_new,y_train)","e7f37dd9":"checkVIF(X_train_new)","a5fb21f8":"#dropping wagon because of high p-value.","e0bf6cc0":"X_train_new = X_train_new.drop([\"wagon\"], axis = 1)","a31507ac":"#MODEL 6\nX_train_new = build_model(X_train_new,y_train)","d6067f75":"checkVIF(X_train_new)","a7b6d30f":"#MODEL 7\n#Dropping dohcv to see the changes in model statistics\nX_train_new = X_train_new.drop([\"dohcv\"], axis = 1)\nX_train_new = build_model(X_train_new,y_train)\ncheckVIF(X_train_new)","1711ea44":"#Residual analysis of model\nlm = sm.OLS(y_train, X_train_new).fit()\ny_train_price = lm.predict(X_train_new)","b3a756b7":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)   ","179f0f1b":"#Prediction and evaluation","db1d22b6":"#Scaling the test set\nnum_vars = ['wheelbase', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","fe8c4eeb":"#Dividing into X and y\ny_test = df_test.pop('price')\nX_test = df_test","c4e0c565":"# Now let's use our model to make predictions.\nX_train_new = X_train_new.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","8c93863d":"# Making predictions\ny_pred = lm.predict(X_test_new)","6ef25118":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","4d6f7f25":"#EVALUATION OF THE MODEL\n# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)   ","8fc7b617":"print(lm.summary())","4e9ea9e1":"**Deriving new features**","b581d347":"Inference : \n\n1. The plot is right skewed which means that most of the prices in the dataset are below 15,000\n2. There is a significant difference between the mean and the median of the price distribution\n3. The data points are far more spread out from the mean, which indicates high variance in the prices. (85% of the prices are below 18,500, whereas the remaining 15% are between 18,500 and 45,400)","8e6e4278":"Car Prediction","c80e7dc8":"**We have to find out  which variables are significant in predicting the price of a car**\n**How well those variables describe the price of a car**","cd6d7273":"List of significant variables after Visual analysis :\n- Car Range \n- Engine Type \n- Fuel type \n- Car Body \n- Aspiration \n- Cylinder Number \n- Drivewheel \n- Curbweight \n- Car Length\n- Car width\n- Engine Size \n- Boreratio \n- Horse Power \n- Wheel base \n- Fuel Economy ","23b84220":"Visualize numerical data","12406087":"**Error terms seem to be approximately normally distributed, so the assumption on the linear modeling seems to be fulfilled**","edd69777":"  Step 3.1 : Visualising Categorical Data\n- CompanyName\n- Symboling\n- fueltype\n- enginetype\n- carbody\n- doornumber\n- enginelocation\n- fuelsystem\n- cylindernumber\n- aspiration\n- drivewheel","6ffe5602":"Inference :\nR-sqaured and Adjusted R-squared (extent of fit) - 0.899 and 0.896 - 90% variance explained.\nF-stats and Prob(F-stats) (overall model fit) - 308.0 and 1.04e-67(approx. 0.0) - Model fir is significant and explained 90% variance is just not by chance.\np-values - p-values for all the coefficients seem to be less than the significance level of 0.05. - meaning that all the predictors are statistically significant."}}