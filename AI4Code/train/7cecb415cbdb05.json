{"cell_type":{"8730c70f":"code","ff519b88":"code","c91a1ecb":"code","881366ea":"code","a8185621":"code","26db6f1a":"code","f7599c27":"code","df1526e7":"code","9d89db48":"code","8830d674":"code","367a7d7d":"code","dcb49122":"code","ee33aaf8":"code","68b1b475":"code","7cf88665":"code","e8d1775d":"code","b7012ea5":"code","f1cdfc04":"code","a9c855d8":"code","d3ce127b":"code","7fe43ab8":"code","5bbc0432":"code","3f698b18":"code","0c14c664":"code","72da9511":"code","913d5b89":"code","06ef642c":"code","032cf339":"code","6cbb43fb":"code","754f6c0a":"code","be188116":"code","650e76a8":"code","ec69cb1b":"code","2fb260d2":"code","e633056c":"code","0d31526f":"code","bedced40":"code","5d6701ca":"code","f8cbde9c":"markdown","486e6d85":"markdown","0783e13e":"markdown","b6106155":"markdown","b580ee72":"markdown","ec24de53":"markdown","2ca6ff61":"markdown","ad012d1a":"markdown","ec718f70":"markdown","06a9a3c3":"markdown"},"source":{"8730c70f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom random import sample \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff519b88":"metadata = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv\", low_memory = False, nrows = 25000)\nmetadata = metadata.drop([19730]) # Remove rows with bad ID\nmetadata.sample(3)","c91a1ecb":"metadata.shape","881366ea":"# Calculate mean of vote average column\nC = metadata['vote_average'].mean()\nprint(C)","a8185621":"# Calculate the minimum number of votes required to be in the chart, m\nm = metadata['vote_count'].quantile(0.90)\nprint(m)","26db6f1a":"q_movies = metadata.copy().loc[metadata['vote_count'] >= m]\nq_movies.shape","f7599c27":"# Function that computes the weighted rating of each movie\ndef weighted_rating(x, m = m, C = C):\n    v = x['vote_count']\n    R = x['vote_average']\n    \n    # Calculation based on the IMDB formula\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","df1526e7":"# Define a new feature 'score' and calculate its value with `weighted_rating()`\nq_movies['score'] = q_movies.apply(weighted_rating, axis = 1)","9d89db48":"#Sort movies based on score calculated above\nq_movies = q_movies.sort_values('score', ascending = False)\n\n#Print the top 15 movies\nq_movies[['title', 'vote_count', 'vote_average', 'score']].head(20)","8830d674":"import plotly.express as px\ndata = q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)\n\nfig = px.bar(data, x = 'title', y = 'score',\n             hover_data = ['vote_count', 'vote_average'], color='score',\n             labels = {'score':'IMDB Score', 'title': 'Movie Name'}, height = 400,\n             title = 'Movie rating disturbition')\nfig.show()","367a7d7d":"#Print plot overviews of the first 5 movies.\nmetadata['overview'].head()","dcb49122":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words = 'english')\n\n#Replace NaN with an empty string\nmetadata['overview'] = metadata['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(metadata['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","ee33aaf8":"sample(tfidf.get_feature_names(), 10)","68b1b475":"# Import linear_kernel\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim.shape","7cf88665":"cosine_sim[1]","e8d1775d":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(metadata.index, index = metadata['title']).drop_duplicates()\nindices[:10]","b7012ea5":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim = cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return metadata['title'].iloc[movie_indices]","f1cdfc04":"metadata['title'][:5]","a9c855d8":"get_recommendations('Batman Forever')","d3ce127b":"get_recommendations('Toy Story')","7fe43ab8":"# Load keywords and credits\ncredits = pd.read_csv('\/kaggle\/input\/the-movies-dataset\/credits.csv', nrows = 25000)\nkeywords = pd.read_csv('\/kaggle\/input\/the-movies-dataset\/keywords.csv', nrows = 25000)","5bbc0432":"# Convert IDs to int. Required for merging\nkeywords['id'] = keywords['id'].astype('int')\ncredits['id'] = credits['id'].astype('int')\nmetadata['id'] = metadata['id'].astype('int')\n\n# Merge keywords and credits into your main metadata dataframe\nmetadata = metadata.merge(credits, on = 'id')\nmetadata = metadata.merge(keywords, on = 'id')","3f698b18":"# Print the first two movies of your newly merged metadata\nmetadata.head(2)","0c14c664":"metadata.shape","72da9511":"# Parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\n\nfeatures = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(literal_eval)","913d5b89":"def get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","06ef642c":"def get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[:3]\n        return names\n\n    #Return empty list in case of missing\/malformed data\n    return []","032cf339":"# Define new director, cast, genres and keywords features that are in a suitable form.\nmetadata['director'] = metadata['crew'].apply(get_director)\n\nfeatures = ['cast', 'keywords', 'genres']\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(get_list)","6cbb43fb":"# Print the new features of the first 3 films\nmetadata[['title', 'cast', 'director', 'keywords', 'genres']].head(3)","754f6c0a":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #Check if director exists. If not, return empty string\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","be188116":"# Apply clean_data function to your features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(clean_data)","650e76a8":"def create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])","ec69cb1b":"# Create a new soup feature\nmetadata['soup'] = metadata.apply(create_soup, axis=1)\nmetadata[['soup']].head(5)","2fb260d2":"# Import CountVectorizer and create the count matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(metadata['soup'])\ncount_matrix.shape","e633056c":"# Compute the Cosine Similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","0d31526f":"# Reset index of your main DataFrame and construct reverse mapping as before\nmetadata = metadata.reset_index()\nindices = pd.Series(metadata.index, index=metadata['title'])","bedced40":"get_recommendations('The Dark Knight Rises', cosine_sim2)","5d6701ca":"get_recommendations('Toy Story', cosine_sim2)","f8cbde9c":"### Now, let's use the cosine_similarity to measure the distance between the embeddings","486e6d85":"### Finally, let's sort the DataFrame in descending order based on the score feature column and output the title, vote count, vote average, and weighted rating (score) of the top 20 movies.","0783e13e":"### Next, let's calculate the number of votes, m, received by a movie in the 90th percentile. The pandas library makes this task extremely trivial using the .quantile() method of pandas:","b6106155":"### You can now reuse your get_recommendations() function by passing in the new cosine_sim2 matrix as your second argument.","b580ee72":"#### These are some of the similar movies recommended by the engine","ec24de53":"### Since we are trying to build a clone of IMDB's Top 250, let's use its weighted rating formula as a metric\/score. Mathematically, it is represented as follows:\n\n### WeightedRating(WR) = (v\/(v+m) * R) + (m\/(m+v) * C)\n\nIn the above equation,\n\n* v is the number of votes for the movie\n\n* m is the minimum votes required to be listed in the chart\n\n* R is the average rating of the movie\n\n* C is the mean vote across the whole report\n\n#### Let's define a new feature score, of which you'll calculate the value by applying this function to your DataFrame of qualified movies:","2ca6ff61":"### Fortunately, scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines.\n\n* Import the Tfidf module using scikit-learn\n* Remove stop words like 'the', 'an', etc. since they do not give any useful information about the topic\n* Replace not-a-number values with a blank string\n* Finally, construct the TF-IDF matrix on the data","ad012d1a":"## Content-Based Recommender","ec718f70":"## Credits, Genres, and Keywords Based Recommender","06a9a3c3":"### As a first step, let's calculate the value of C, the mean rating across all movies using the pandas .mean() function:"}}