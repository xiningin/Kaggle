{"cell_type":{"0162c7fc":"code","d434e6b3":"code","a60aaa1a":"code","ffbd2ebf":"code","bb2eb727":"code","81a144f2":"markdown","c3101bcc":"markdown","ffe59c34":"markdown","0065c35d":"markdown","3976bc68":"markdown"},"source":{"0162c7fc":"import os\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef read_image_to_array(fn):\n    image = cv2.imread(fn)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)","d434e6b3":"DATA_DIR = \"..\/input\/lane-detection-for-carla-driving-simulator\"\n\nx_train_dir = os.path.join(DATA_DIR, 'train')\ny_train_dir = os.path.join(DATA_DIR, 'train_label')\n\nx_valid_dir = os.path.join(DATA_DIR, 'val')\ny_valid_dir = os.path.join(DATA_DIR, 'val_label')","a60aaa1a":"# pick the first image from the training directory and show it\nsample_fn = os.path.join(x_train_dir, os.listdir(x_train_dir)[0])\nprint(sample_fn)\nplt.imshow(read_image_to_array(sample_fn));","ffbd2ebf":"# function that takes filename of a training image 'fn' and returns the filename of the corresponding label image\ndef label_func(fn): \n    return str(fn).replace(\".png\", \"_label.png\").replace(\"train\", \"train_label\").replace(\"val\/\", \"val_label\/\")","bb2eb727":"# get label image for 'sample_fn' using our 'label_func' function\nlabel_fn = label_func(sample_fn)\nprint(label_fn)\n# we multiply the image intensity by 100 to make lane lines visible for the human eye:\nplt.imshow(100*read_image_to_array(label_fn)); ","81a144f2":"### Corresponding label image","c3101bcc":"## Visualize the data","ffe59c34":"### Training image","0065c35d":"First we define variables pointing to the training and validation data. Each dataset (train & val) ist split into a directory for the \"x\", i.e. the images, and a directory for the \"y\", i.e. the labels.","3976bc68":"# Explore Dataset"}}