{"cell_type":{"91d81e25":"code","54b59502":"code","f3823fa8":"code","b9e94407":"code","0b66d0dc":"code","7d258bb8":"code","d2baa67a":"code","751d57e7":"code","0538d24b":"code","791027b6":"code","3f67ff06":"code","99bd3bf6":"code","8d6a83e7":"code","4f754431":"code","0efa9ce8":"code","70d9f81e":"code","9432f8a2":"code","fb927a8f":"code","6ca3adb6":"code","586e4c47":"markdown","3f428634":"markdown","cb8cd8bb":"markdown","17c2155f":"markdown","d23aafe6":"markdown"},"source":{"91d81e25":"import sys\nsys.path.append('..\/input\/brown-clustering')","54b59502":"import os\nimport numpy as np\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\n\nfrom brownclustering import Corpus\nfrom brownclustering import BrownClustering","f3823fa8":"pub_df=pd.read_csv('..\/input\/publication-datasets\/publication_dataset.csv')\npub_df.head()","b9e94407":"%%time\npos_sentences=[]\n\ndef get_positive_sentences(sentences):\n    sentences=eval(sentences)\n    pos_sents=sentences['pos_sents']\n    for sentence in pos_sents:\n        sentence=sentence.lower().strip()\n        words=word_tokenize(sentence)\n        words=[word.strip() for word in words]\n        words=[word for word in words if (word.isalpha() and word.isascii())]\n        pos_sentences.append(words)\n\n_=pub_df.sentences.apply(get_positive_sentences)\nprint('Number Of Positive Sentences:', len(pos_sentences))","0b66d0dc":"from collections import defaultdict\nvocab=defaultdict(int)\nfor sent in pos_sentences:\n    for word in sent:\n        vocab[word]+=1\nprint('Vocab size:', len(vocab))","7d258bb8":"min_freq=10\ncorpus_sentences=[]\nfor sent in pos_sentences:\n    words=[word for word in sent if vocab[word]>min_freq]\n    if len(words)>3:\n        corpus_sentences.append(words)\nprint(\"Corpus Sentences:\", len(corpus_sentences))","d2baa67a":"%%time\ncorpus=Corpus(corpus_sentences, 0.001)\nvocab=corpus.vocabulary\nunigrams=corpus.unigrams\nbigrams=corpus.bigrams\n\nprint('Vocabulary Size:',len(vocab))\nprint('Unigram Size:', len(unigrams))\nprint(\"Bigram Size:\", len(bigrams))","751d57e7":"clustering = BrownClustering(corpus, 6)\nclustering.train()","0538d24b":"clustering.get_similar('taken')","791027b6":"clustering.get_similar('database')","3f67ff06":"clustering.get_similar('collected')","99bd3bf6":"clustering.get_similar('sampled')","8d6a83e7":"clustering.get_similar('from')","4f754431":"clustering.get_similar('this')","0efa9ce8":"codes=clustering.codes()\nprint(len(codes))","70d9f81e":"codes_df=pd.DataFrame.from_dict({\n    'word': list(codes.keys()),\n    'code_':list(codes.values())\n})\ncodes_df.head()","9432f8a2":"clustering.get_similar('obtained', 30)","fb927a8f":"prefix=10\n\ntext1=\"the data is taken from ADNI\"\ntext2=\"This study used data from the National Education Longitudinal Study (NELS:88) to examine the effects of dual enrollment programs for high school students on college degree attainment.\"\n\nprint(text1)\nprint()\nfor word in word_tokenize(text1):\n    word=word.lower()\n    if word not in codes:\n        continue\n    print(codes[word][:prefix], \"-->\", word)\n\nprint(text2)\nprint()\nfor word in word_tokenize(text2):\n    word=word.lower()\n    if word not in codes:\n        continue\n    print(codes[word][:prefix], \"-->\", word)","6ca3adb6":"codes_df[codes_df.code_.apply(lambda x: x.startswith('0100000000'))]","586e4c47":"Lets check the clusters of the context words of database label.","3f428634":"# lets see some of the keywords for extraction","cb8cd8bb":"creating codes of length 5","17c2155f":"# Create Clusters","d23aafe6":"# Build Corpus for the sentences with brown clusters"}}