{"cell_type":{"3338e9c6":"code","5d865480":"code","b32882e2":"code","bbf28718":"code","1ff85649":"code","9ef1af12":"code","45ff51ab":"code","a0186ea5":"code","ebe0acbe":"code","462d08ad":"code","b6cb4e63":"code","ddd794b4":"code","73dcbc2a":"code","85fbbe71":"code","5dc8f3a7":"code","ae2a1798":"code","d9d2e76c":"code","c05eb3c7":"code","1997687b":"code","968a0d45":"code","23c4d195":"code","3d13755b":"code","58712530":"code","8c623930":"code","43e5f34b":"code","ba4b22c1":"code","01032ea8":"code","f8481ac8":"code","ff0fc83f":"code","eeba7502":"code","f11f1bc7":"code","9598d119":"code","effe6578":"code","181a86f7":"code","6b9edb0c":"code","1dfb902b":"code","bb39f806":"code","2781c0ce":"code","2c1b9849":"code","6e51b5e4":"code","d5322ae2":"markdown","344c765d":"markdown","dd49b54f":"markdown","2897d3f9":"markdown","fd7f966c":"markdown"},"source":{"3338e9c6":"#Loading essential packages\nimport numpy as np\nimport pandas as pd","5d865480":"# Loading the dataset\ndf = pd.read_csv('..\/input\/fakenews2\/kaggle_fake_train.csv')","b32882e2":"df.shape","bbf28718":"df.columns","1ff85649":"df.head()","9ef1af12":"#Dropping the 'id' column\ndf.drop('id', axis=1, inplace=True)","45ff51ab":"df.columns","a0186ea5":"#Importing packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ebe0acbe":"#Visualizing the count of 'fake news' in the dataset\nplt.figure(figsize=(10,7))\nsns.countplot(x='label', data=df)\nplt.xlabel('News Classification')\nplt.ylabel('Count')","462d08ad":"print(df.shape)","b6cb4e63":"#Finding any NaN values\ndf.isna().any()","ddd794b4":"#Dropping NaN values\ndf.dropna(inplace=True)\nprint(df.shape)","73dcbc2a":"news = df.copy()","85fbbe71":"news.reset_index(inplace=True)","5dc8f3a7":"#Importing essential libraries for performing Natural Language Processing on 'kaggle_fake_train' dataset\nimport nltk\nimport re\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","ae2a1798":"#Cleaning the news\ncorpus = []\nps = PorterStemmer()\n\nfor i in range(0,news.shape[0]):\n\n  #Cleaning special character from the news-title\n  title = re.sub(pattern='[^a-zA-Z]', repl=' ', string=news.title[i])\n\n  #Converting the entire news-title to lower case\n  title = title.lower()\n\n  #Tokenizing the news-title by words\n  words = title.split()\n\n  #Removing the stopwords\n  words = [word for word in words if word not in set(stopwords.words('english'))]\n\n  #Stemming the words\n  words = [ps.stem(word) for word in words]\n\n  #Joining the stemmed words\n  title = ' '.join(words)\n\n  #Building a corpus of news-title\n  corpus.append(title)","d9d2e76c":"corpus[0:10]","c05eb3c7":"#Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=5000, ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()","1997687b":"X.shape","968a0d45":"X[0:10]","23c4d195":"#Extracting dependent variable from the dataset\ny = news['label']","3d13755b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","58712530":"from sklearn.linear_model import LogisticRegression\nlr_classifier = LogisticRegression(random_state=0)\nlr_classifier.fit(X_train, y_train)","8c623930":"# Predicting the Test set results\nlr_y_pred = lr_classifier.predict(X_test)","43e5f34b":"# Accuracy, Precision and Recall\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nscore1 = accuracy_score(y_test, lr_y_pred)\nscore2 = precision_score(y_test, lr_y_pred)\nscore3 = recall_score(y_test, lr_y_pred)\nprint(\"---- Scores ----\")\nprint(\"Accuracy score is: {}%\".format(round(score1*100,2)))\nprint(\"Precision score is: {}\".format(round(score2,2)))\nprint(\"Recall score is: {}\".format(round(score3,2)))","ba4b22c1":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nlr_cm = confusion_matrix(y_test, lr_y_pred)","01032ea8":"lr_cm","f8481ac8":"# Plotting the confusion matrix\nplt.figure(figsize=(10,7))\nsns.heatmap(data=lr_cm, annot=True, cmap=\"Blues\", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.title('Confusion Matrix for Logistic Regression Algorithm')\nplt.show()","ff0fc83f":"# Hyperparameter tuning the Logistic Regression Classifier\nbest_accuracy = 0.0\nc_val = 0.0\nfor i in np.arange(0.1,1.1,0.1):\n  temp_classifier = LogisticRegression(C=i, random_state=0)\n  temp_classifier.fit(X_train, y_train)\n  temp_y_pred = temp_classifier.predict(X_test)\n  score = accuracy_score(y_test, temp_y_pred)\n  print(\"Accuracy score for C={} is: {}%\".format(round(i,1), round(score*100,2)))\n  if score>best_accuracy:\n    best_accuracy = score\n    c_val = i\nprint('--------------------------------------------')\nprint('The best accuracy is {}% with C value as {}'.format(round(best_accuracy*100, 2), round(c_val,1)))","eeba7502":"classifier = LogisticRegression(C=0.8, random_state=0)\nclassifier.fit(X_train, y_train)","f11f1bc7":"def fake_news(sample_news):\n  sample_news = re.sub(pattern='[^a-zA-Z]',repl=' ', string=sample_news)\n  sample_news = sample_news.lower()\n  sample_news_words = sample_news.split()\n  sample_news_words = [word for word in sample_news_words if not word in set(stopwords.words('english'))]\n  ps = PorterStemmer()\n  final_news = [ps.stem(word) for word in sample_news_words]\n  final_news = ' '.join(final_news)\n\n  temp = cv.transform([final_news]).toarray()\n  return classifier.predict(temp)","9598d119":"# Importing test dataset\ndf_test = pd.read_csv('..\/input\/fakenews1\/kaggle_fake_test.csv')","effe6578":"df_test.columns","181a86f7":"news_title = df_test['title']","6b9edb0c":"news_title.shape","1dfb902b":"#For generating random integer\nfrom random import randint","bb39f806":"#Predicting values\nrow = randint(0,news_title.shape[0]-1)\nsample_news = news_title[row]\n\nprint('News: {}'.format(sample_news))\nif fake_news(sample_news):\n  print('Prediction: This is a FAKE news!')\nelse:\n  print('Prediction: This is a REAL news.')","2781c0ce":"#Predicting values\nrow = randint(0,news_title.shape[0]-1)\nsample_news = news_title[row]\n\nprint('News: {}'.format(sample_news))\nif fake_news(sample_news):\n  print('Prediction: This is a FAKE news!')\nelse:\n  print('Prediction: This is a REAL news.')","2c1b9849":"#Predicting values\nrow = randint(0,news_title.shape[0]-1)\nsample_news = news_title[row]\n\nprint('News: {}'.format(sample_news))\nif fake_news(sample_news):\n  print('Prediction: This is a FAKE news!')\nelse:\n  print('Prediction: This is a REAL news.')","6e51b5e4":"#Predicting values\nrow = randint(0,news_title.shape[0]-1)\nsample_news = news_title[row]\n\nprint('News: {}'.format(sample_news))\nif fake_news(sample_news):\n  print('Prediction: This is a FAKE news!')\nelse:\n  print('Prediction: This is a REAL news.')","d5322ae2":"## *Logistic Regression*","344c765d":"# **Data Cleaning and Preprocessing**","dd49b54f":"# **Model Building**","2897d3f9":"# **Exploring the dataset**","fd7f966c":"# **Predictions**"}}