{"cell_type":{"8735a642":"code","3463695a":"code","f6707dd7":"code","663a731e":"code","e27dc63b":"code","c5fd15aa":"code","61924580":"code","6ff0779a":"code","042659db":"code","3fd04d28":"code","d725d3a5":"code","94174418":"code","eb4fd853":"code","82acafc2":"code","3760c8b0":"code","2a3d9ebe":"code","31ab8739":"code","00928fd2":"code","e7abd486":"code","941e1f12":"code","b0e2ac02":"code","5124390e":"code","c1e3c579":"code","343390db":"code","fa83700e":"code","c0886fdd":"code","1ac1a965":"code","7b5290df":"code","752beaf7":"code","8896e281":"markdown","d5afbeb2":"markdown","8adfc0bf":"markdown","d69aae35":"markdown","e1690af8":"markdown","9ee8b33b":"markdown","f671587b":"markdown","30f08f80":"markdown","4b75c7c2":"markdown","646cf119":"markdown","ca8a81a8":"markdown","cae41b90":"markdown","c0665a6a":"markdown","71a933ce":"markdown"},"source":{"8735a642":"#importing libraries \nimport os\nimport pandas as pd # pandas \nimport numpy as np #numpy \nimport plotly.express as px \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split, KFold\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import r2_score\nimport glob\nfrom tqdm import tqdm\nsns.set_theme(style=\"dark\")\n","3463695a":"# loading the data \ntrain = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\nsample= pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/sample_submission.csv')\n","f6707dd7":"train.head() # printing the head of the train data ","663a731e":"train.shape # shape of the data ","e27dc63b":"train.info() # info about the data ","c5fd15aa":"# basic statistic \ntrain.describe()","61924580":"train['stock_id'].value_counts() # values of stock id on the train set ","6ff0779a":"train['time_id'].value_counts() #values of th time id on the train data ","042659db":"\n\n\ncorrMatrix= train.corr() # correlation between columns on the train data ","3fd04d28":"sns.heatmap(corrMatrix, cmap=\"YlGnBu\",annot=True)\nplt.show()","d725d3a5":"import warnings\nwarnings.filterwarnings('ignore')","94174418":"#checking the target distrbution \nsns.distplot(train['target'], color = 'b', label = 'target distribution')","eb4fd853":"# we load the data from book and train where stock id=0  and time id = 5 \nbook_example = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\ntrade_example =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id","82acafc2":"book_example.head()","3760c8b0":"book_example.shape #302, 11","2a3d9ebe":"trade_example.head()","31ab8739":"trade_example.shape # 40,6","00928fd2":"#ploting the histogram for features in the book example \nbook_example.hist(figsize=(16,12))\nplt.show()","e7abd486":"#ploting the histogram for features in the trade data \ntrade_example.hist(figsize=(16,12))\n","941e1f12":"a = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) \/ (\n                                       book_example['bid_size1']+ book_example['ask_size1'])\n\nb = (book_example['bid_price2'] * book_example['ask_size2'] +\n                                book_example['ask_price2'] * book_example['bid_size2']) \/ (\n                                       book_example['bid_size2']+ book_example['ask_size2'])\n\nbook_example['wap'] = (a + b) \/ 2","b0e2ac02":"sns.set(rc={\"figure.figsize\":(8, 6)})\nsns.lineplot(data=book_example, x=\"seconds_in_bucket\" , y=\"wap\")","5124390e":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \nbook_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]","c1e3c579":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')","343390db":"\nlist_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\nlist_order_trade_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/*')\ndef realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","fa83700e":"len(list_order_book_file_train)\nlen(list_order_trade_file_train)","c0886fdd":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\ndf_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')","1ac1a965":"train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')","7b5290df":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","752beaf7":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ndf_naive_pred_test = df_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\ndf_naive_pred_test.to_csv('submission.csv',index = False)","8896e281":"### We will be back \n> If you Appreciate thsi notebook please upvote.\n","d5afbeb2":"**getting the past realized volatility as prediction for each individual stocks.**","8adfc0bf":"#### Realized volatility calculation","d69aae35":"**Loading the data**","e1690af8":"**Calculating the past realized volatility across the training set**","9ee8b33b":"**Checking the Train data**","f671587b":"**Realized volatility for stock_id 0 on time_id 5**","30f08f80":"**Checking the book and trade parquet**","4b75c7c2":"**joining the output dataframe with train.csv to see the performance of the naive prediction**","646cf119":"**Compute the log return**","ca8a81a8":"#### Note \nThis notebook is based on the tutorial provided by the team of the Optiver and which can be find here [Introduction to financial concepts and data.](https:\/\/www.kaggle.com\/jiashenliu\/introduction-to-financial-concepts-and-data\/notebook#Market-making-and-market-efficiency)","cae41b90":"**Evaluate the naive prediction result by two metrics: RMSPE and R squared.**","c0665a6a":"**Submission**\n","71a933ce":"## Introduction \nThis notebook is for the exploratory analysis of the **Optiver Competition** , the aim of this analysis is to better understand the data we are wrking with in order to spot patterns and trends.\n"}}