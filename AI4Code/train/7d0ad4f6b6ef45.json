{"cell_type":{"2b96b7b4":"code","b1fc3d19":"code","e192bbaa":"code","7b52ad6a":"code","2f156c31":"code","b6c8b1db":"code","6f4906f7":"code","7aaf16ee":"code","0752a903":"code","56a24859":"code","de78b6b9":"code","c05812a5":"code","e1c01709":"code","6891eb72":"code","1ff9c928":"code","4fa7e5da":"code","31ab1bd7":"code","5c4b9186":"code","9c2a1031":"code","872856c2":"code","6ab113d9":"code","0b27e3f9":"code","b3ad9ca2":"code","024b6fd2":"code","9a85558e":"code","20ace213":"code","4fb74e32":"code","8de9ef70":"code","31ff6ddd":"code","ea064dba":"code","3e2230b7":"code","11476ca0":"markdown","60875a2f":"markdown","83f5ec4a":"markdown","65c36589":"markdown","39715b32":"markdown","0b884f35":"markdown","87d6c0dc":"markdown","cac63655":"markdown","efe1770c":"markdown","cd940cbd":"markdown","d7dba160":"markdown","50c4643c":"markdown","f84f50d8":"markdown","c99fff89":"markdown","e3dd1c5d":"markdown","ca0a7cce":"markdown","b68dea80":"markdown","c3462424":"markdown","e0d78f63":"markdown","712b1142":"markdown"},"source":{"2b96b7b4":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost","b1fc3d19":"train=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","e192bbaa":"train.head(3)","7b52ad6a":"test.head(3)","2f156c31":"data=pd.concat((train, test)).reset_index(drop=True)","b6c8b1db":"data.shape","6f4906f7":"data.describe()","7aaf16ee":"plt.figure(figsize=(29,22)) \nsns.heatmap(data.corr(), cmap='Blues',)","0752a903":"data.isnull().sum().sort_values(ascending=False)","56a24859":"plt.figure(figsize=(19,12)) \nsns.heatmap(data.isnull(),yticklabels=False)","de78b6b9":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent =total\/len(data)*100\n    missing_data = pd.concat([total,percent], axis=1, keys=['Total','Percent'])\n    plt.figure(figsize=(29,6))\n    plt.xticks(rotation='90')\n    sns.barplot(x=missing_data[missing_data['Percent']>0].index, y=missing_data[missing_data['Percent']>0].Percent)\nmissing_data(data)","c05812a5":"def drop_columns(data):\n    drop_columns=['PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage']\n    return data.drop(drop_columns,1)\ndata=drop_columns(data)","e1c01709":"missing_data(data)","6891eb72":"def full_nan_by_mean_mod(data):\n    nan_columns=data.columns[data.isnull().any()]\n    for i in nan_columns:\n        if(data[i].dtypes==\"object\"):\n            data[i]=data[i].fillna(data[i].mode()[0])\n        else:\n            data[i]=data[i].fillna(data[i].mean())\n    return data","1ff9c928":"full_nan_by_mean_mod(data)","4fa7e5da":"data.isnull().sum().sort_values(ascending=False)","31ab1bd7":"categorical = (data.dtypes == \"object\")\ncategorical_list = list(categorical[categorical].index)\nprint(categorical_list)","5c4b9186":"def encodee():\n    for i in categorical_list:\n        encode=LabelEncoder()\n        data[i]=encode.fit_transform(data[i])\nencodee()","9c2a1031":"data.head(4)","872856c2":"data.shape","6ab113d9":"df_train=data[:1460]\ndf_test=data[1460:]","0b27e3f9":"print(df_train.shape)\nprint(df_test.shape)","b3ad9ca2":"X = df_train.drop(['SalePrice'],1)\ny = df_train['SalePrice']","024b6fd2":"df_test=df_test.drop(['SalePrice'],1)","9a85558e":"scaler = StandardScaler()\nX=scaler.fit_transform(X)\ndf_test=scaler.transform(df_test)","20ace213":"# lc=[xgboost.XGBRFRegressor(),LinearRegression(),KNeighborsRegressor(),LogisticRegression(),DecisionTreeRegressor(),RandomForestRegressor(),GradientBoostingRegressor(random_state=58,n_estimators=500)]\n# modelss=['xgboost','linearRegression','KNeighborsRegressor','LogisticRegression','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor']","4fb74e32":"# def evalu():\n#     X1=X[:1350]\n#     y1=y[:1350]\n#     X2=X[1350:]\n#     y2=y[1350:]\n#     i=0\n#     for m in lc:\n#         model=m\n#         model.fit(X1, y1)\n#         predicted=model.predict(X2)\n#         print(modelss[i])\n#         print(model.score(X2,y2))\n#         i=i+1\n# evalu()","8de9ef70":"model = GradientBoostingRegressor(random_state=58,n_estimators=500,loss='huber',max_depth=3,max_features=25)","31ff6ddd":"model.fit(X, y)\npredicted=model.predict(df_test)","ea064dba":"predicted","3e2230b7":"indexes=[i for i in range(1461,2920 ,1)]\nmy_submission=pd.DataFrame(indexes,columns=['Id'])\nmy_submission['SalePrice']=predicted\nmy_submission.to_csv('submission.csv', index=False)","11476ca0":"Salesprice have null values because in our test data the saleprice column is not present so at the time of concat the null saleprice is created so neglect this at that time.","60875a2f":"*Correlation*","83f5ec4a":"*NOW OUR DATA IS READY FOR APPYLYING ML MODELS*","65c36589":"*Concat both train and test data*","39715b32":"**Deal with null values**","0b884f35":"Parameters we use in model is \"random_state=58,n_estimators=500,loss='huber',max_depth=3,max_features=25 \"   we find this parameters by parameter tuning","87d6c0dc":"**Importing requirements**","cac63655":"Now encode all the catagorical data with the help of LabelEncoder","efe1770c":"*Plot missing values*","cd940cbd":"**Spit data in train and test**","d7dba160":"drop salesprice column from test data","50c4643c":"**Now its time to scale data**","f84f50d8":"All the missing values is replaced","c99fff89":"**Read data from csv**","e3dd1c5d":"*categorical data*","ca0a7cce":"Now you can see that there is a lots more columns with null values so we are going to deal with that by replacing it with mean if its type of int\/float and mode if its type of object","b68dea80":"Finding best model","c3462424":"we are using GradientBoostingRegressor model for this RandomForest is also best for this.","e0d78f63":"Saving predictions","712b1142":"*Now drop columns which have high number of missing values*"}}