{"cell_type":{"ee7d9063":"code","09829677":"code","15e5a891":"code","1f032a5a":"code","475e2baa":"code","fb7b6eb0":"code","e308d1bf":"code","ebd74077":"code","8a3f941a":"code","1242285a":"code","09c2ad54":"code","4ecb2bc4":"code","03463d63":"code","6adfdae8":"code","33ff002b":"code","98206fab":"code","582c739a":"markdown","449b39cb":"markdown","4647cddb":"markdown","b64df2af":"markdown","9ae0da9a":"markdown","488297bb":"markdown","91ca9ea9":"markdown","e9070cc3":"markdown","1954f78e":"markdown","bcea15d7":"markdown","b5e7e5af":"markdown","1b6ce0c7":"markdown","0ac54104":"markdown","a21280f1":"markdown","1b6fac1c":"markdown","9a4f17e1":"markdown"},"source":{"ee7d9063":"# In the live halite competition, internet is off. You need to include used libraries as text.\n!pip install pytorch_tabnet\nfrom pytorch_tabnet.tab_model import TabNetClassifier\n","09829677":"import torch\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\nfrom random import shuffle\nnp.random.seed(0)\nimport os\nfrom matplotlib import pyplot as plt\n%matplotlib inline","15e5a891":"train = pd.read_csv('..\/input\/halitespawn\/spawn.csv', header=0)\nprint(train.columns)","1f032a5a":"# create some more features\ntrain['step<20'] = (train['step']<20).astype(int)\ntrain['step<100'] = (train['step']<100).astype(int)\ntrain['step_100_200'] = ((train['step']>=100) & train['step']<200).astype(int)\ntrain['step_200_300'] = ((train['step']>=200) & train['step']<300).astype(int)\ntrain['step_300_400'] = (train['step']>=300).astype(int)\ntrain['halite_enough1000'] = (train['halite_m']>1000).astype(int)\ntrain['ships<10'] = (train['ships_m']<=10).astype(int)\ntrain['ships<20'] = (train['ships_m']<=20).astype(int)\ntrain['ships<30'] = (train['ships_m']<=30).astype(int)\ntrain['ships<40'] = (train['ships_m']<=40).astype(int)\ntrain['halite_most'] = (train['halite_m'] > train['halite_max']).astype(int)\ntrain['halite_more'] = (train['halite_m'] > (train['halite_y']\/3)).astype(int)\ntrain['shipswithcargo_m'] = (train['ships_m']-train['shipsg0_m']).astype(int)\ntrain['shipswithcargo_y'] = (train['ships_y']-train['shipsg0_y']).astype(int)\ntrain['ships_less_avg'] = (train['ships_m'] < (train['ships_y']\/3)).astype(int)\ntrain['ships_less_min'] = (train['ships_m'] < train['ships_min']).astype(int)\ntrain['avail_per_ship_m'] = (train['halite_total_now']\/(train['ships_m']+.010)).astype(int)\ntrain['avail_per_ship_all'] = (train['halite_total_now']\/(train['ships_m']+train['ships_y']+.001)).astype(int)","475e2baa":"target = \"spawn\"\n\nint_columns = [\n    # _m==mine, _y==yours\n    'step', 'halite_total_start', 'halite_total_now', 'ships_m', 'ships_y', 'ships_min', 'ships_max', \\\n    'bases_y', 'halite_m', 'halite_y', 'halite_max', 'cargo_m', 'cargo_y', 'shipsg0_m', 'shipsg0_y', 'ship_lost', \\\n    'step<20', 'step<100', 'step_100_200', 'step_200_300', 'step_300_400', \\\n    'halite_enough1000', 'ships<10', 'ships<20', 'ships<30', 'ships<40', \\\n    'halite_most', 'halite_more', 'shipswithcargo_m', 'shipswithcargo_y', 'ships_less_avg', 'ships_less_min', \\\n    'avail_per_ship_m', 'avail_per_ship_all', \\\n]\n\nfeature_columns = ( int_columns + [target])\n","fb7b6eb0":"matches = train.match_id.unique()\nshuffle(matches)\nprint(f'Dataset is {len(train)} steps from {len(matches)} matches')\n\ntrain_matches = matches[:80*len(matches)\/\/100]\ntest_matches = matches[-10:]\nvalid_matches = matches[len(train_matches):-10]\nprint(f'train\/valid\/test matches: {len(train_matches)}\/{len(valid_matches)}\/{len(test_matches)}')\n\ntrain_indices = train.index[train['match_id'].isin(train_matches)].to_list()\nvalid_indices = train.index[train['match_id'].isin(valid_matches)].to_list()\ntest_indices = train.index[train['match_id'].isin(test_matches)].to_list()\n\nunused_feat = ['match_id']\n\nfeatures = [ col for col in train.columns if col not in unused_feat+[target]] \n","e308d1bf":"clf = TabNetClassifier( # default tabnet hyperparameters\n    n_d=64, n_a=64, n_steps=5,\n    gamma=1.5, n_independent=2, n_shared=2,\n    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    scheduler_params = {\"gamma\": 0.95, \"step_size\": 20},\n    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n)","ebd74077":"X_train = train[features].values[train_indices]\ny_train = train[target].values[train_indices]\n\nX_valid = train[features].values[valid_indices]\ny_valid = train[target].values[valid_indices]\n\nX_test = train[features].values[test_indices]\ny_test = train[target].values[test_indices]","8a3f941a":"max_epochs = 90\n\nclf.fit(\n    X_train=X_train, y_train=y_train,\n    X_valid=X_valid, y_valid=y_valid,\n    max_epochs=max_epochs, patience=50,\n    batch_size=16384, virtual_batch_size=256\n)","1242285a":"[feature_columns[i] for i in np.argsort(clf.feature_importances_)[::-1][:10]]","09c2ad54":"explain_matrix, masks = clf.explain(X_test)\nfig, axs = plt.subplots(1, 5, figsize=(20,20))\n\nfor i in range(5):\n    axs[i].imshow(masks[i][:50])\n    axs[i].set_title(f\"mask {i}\")","4ecb2bc4":"plt.plot(clf.history['train']['loss'][6:])\nplt.plot(clf.history['valid']['loss'][6:])","03463d63":"plt.plot([-x for x in clf.history['train']['metric']][6:])\nplt.plot([-x for x in clf.history['valid']['metric']][6:])\n","6adfdae8":"y_pred = clf.predict(X_test)\ntest_acc = accuracy_score(y_pred=y_pred, y_true=y_test)\nprint(f\"FINAL TEST SCORE : {test_acc}\")","33ff002b":"episodes = []\ntest_matches = []\nmatch_id = 0\nfor n, (index, row) in enumerate(train.iloc[test_indices].iterrows()):\n    if row['match_id'] != match_id:\n        test_matches.append(row['match_id'])\n        t = [i for i in range(10)]\n        p = [i for i in range(10)]\n        if match_id>0: episodes.append([t,p])\n        match_id = row['match_id']\n    if y_test[n]: t.append(row['step'])\n    if y_pred[n]: p.append(row['step'])\nepisodes.append([t,p])\n\n","98206fab":"colors = np.array([[1, 0, 0], [0, 0, 1]])\n                   \nfor i in range(10):\n    fig, axs = plt.subplots(1,1)\n    plt.hlines(.5,0,380)  # Draw a horizontal line\n    plt.eventplot(episodes[i], orientation='horizontal', colors=colors)\n    axs.legend([f'Prediction for match {test_matches[i]}','Truth'], bbox_to_anchor=(0., 1.0, 1., .10), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n    plt.axis('off')\n    plt.show()","582c739a":"Here, feature importance masks that indicate which features are selected at each step.","449b39cb":"* The dataset here is 1550 games played by the top 8 submissions of 1 top team. \n* The dataset has already been stripped of steps where we don't have 500 halite, or any bases.\n* The first 10 steps of each game aren't used. Almost all strategies start by creating 10 ships.\n* You can build your own dataset using the Halite Scraper API. \n","4647cddb":"# Conclusion","b64df2af":"* ML solutions that predict ship moves may not be optimal at predicting moments to spawn.\n* In previous Halite competitions, many participants ran an algorithmic spawn schedule alonside a ML ship mover.\n* This notebook is an attempt to predict or imitate spawn event generation through ML. Such a component could be used with a separate ML ship mover.\n* We'll use real games from a top player, and Google's TabNet, to automate ship spawning.","9ae0da9a":"What may help accuracy? More features, more data.\n\nSome spawn algorithms will use more complicated versions of how much halite remains for the number of ships on the board and the regen rate. This could be turned into a feature.\n\nOther strategies will replace lost ships. This could also be featurised.\n\nIs it worth it versus a simple rule for spawning? ","488297bb":"# Background","91ca9ea9":"We can see what the most important features are. Some look a little surprising.","e9070cc3":"# Imports","1954f78e":"We can try to visualise performance.\nThese event plots are 400 steps long from left to right.","bcea15d7":"We'll use features like the number of our ships, our cargo, our halite, as well as the same of opponents.","b5e7e5af":"# Data Preparation","1b6ce0c7":"# Network Parameters","0ac54104":"# Results","a21280f1":"# Predictions","1b6fac1c":"# Loss and Accuracy graphs","9a4f17e1":"# Training"}}