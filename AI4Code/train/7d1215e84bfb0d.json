{"cell_type":{"fede3c44":"code","4f5a4171":"code","f63bfbc5":"code","90ca29a2":"code","d5013d34":"code","eb8d38d5":"code","833669ff":"code","4b956ba0":"code","eb0689da":"code","f0e87a21":"code","faafaf75":"code","9395529a":"code","343c9da9":"code","1f69bced":"code","e2d9c58a":"code","1ea9ba9a":"code","0556678b":"code","f8cbc634":"code","3df7f69f":"code","84225168":"code","2b9814c5":"code","a5f0ae99":"code","1a979e53":"code","3d15dd3e":"code","614fb7f5":"markdown","b41c88be":"markdown","8f34e9f6":"markdown","8da432fc":"markdown"},"source":{"fede3c44":"import pandas as pd # table operations\nimport numpy as np # linear algebra\nimport seaborn as sns # visualizing\nimport os # getting path\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt # visualizing\nimport cv2 # haar cascade\nfrom scipy.spatial import distance\nimport glob\nfrom warnings import filterwarnings\nfrom skimage import io\nfilterwarnings(\"ignore\")\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, Activation\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img ,img_to_array","4f5a4171":"testfile = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\ntrainfile = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\nvalidationfile = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","f63bfbc5":"path  = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/\"","90ca29a2":"dataset = {\"image_path\":[],\"mask_status\":[],\"where\":[]}\nfor where in os.listdir(path):\n    for status in os.listdir(path+\"\/\"+where):\n        for image in glob.glob(path+where+\"\/\"+status+\"\/\"+\"*.png\"):\n            dataset[\"image_path\"].append(image)\n            dataset[\"mask_status\"].append(status)\n            dataset[\"where\"].append(where)\ndataset = pd.DataFrame(dataset)\ndataset","d5013d34":"mask = dataset.value_counts(\"mask_status\")[1]\nwithoutmask = dataset.value_counts(\"mask_status\")[0]\n# count value of mask and without mask\nprint(f\"With Mask: {mask},\\nWithout Mask: {withoutmask}\\n\")\nsns.countplot(dataset[\"mask_status\"])\nplt.show()","eb8d38d5":"#plot to show random picture of image in file\nplt.figure(figsize = (14,10))\nfor i in range(9):\n    random = np.random.randint(1,len(dataset))\n    plt.subplot(3,3,i+1)\n    plt.imshow(load_img(dataset.loc[random,\"image_path\"]))\n    plt.title(dataset.loc[random, \"mask_status\"], size = 10) \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","833669ff":"train_df = dataset[dataset[\"where\"] == \"Train\"]\ntest_df = dataset[dataset[\"where\"] == \"Test\"]\nvalid_df = dataset[dataset[\"where\"] == \"Validation\"]","4b956ba0":"valid_df.head()","eb0689da":"#visualization to show and check if the image for every classes is balanced\nplt.figure(figsize = (15,6))\nplt.subplot(1,3,1)\nsns.countplot(train_df[\"mask_status\"])\nplt.title(\"Train_df\", size = 14, color = \"orange\")\n\n\nplt.subplot(1,3,2)\nsns.countplot(test_df[\"mask_status\"])\nplt.title(\"Test_df\", size = 14, color = \"red\")\n\n\nplt.subplot(1,3,3)\nsns.countplot(valid_df[\"mask_status\"])\nplt.title(\"Validation_df\", size = 14, color = \"blue\")\n\nplt.show()","f0e87a21":"#dictionary to map without mask to value 0 and with mask to 1\nlabels_dict = {'WithoutMask':0,'WithMask':1}\n\n#load validation and training data\ndef load_data(path):\n    \"\"\"\n    Loads sign language dataset.\n    \"\"\"\n    #size = 60,60\n    images, labels = [], []\n\n    for folder in os.listdir(path):\n        \n        print(folder, end = ' | ')\n        for image in os.listdir(path + \"\/\" + folder):\n            temp_img = cv2.imread(path + '\/' + folder + '\/' + image)\n            #convert image to grayscale (for experiment)\n            #temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2GRAY)\n            temp_img = cv2.resize(temp_img, (32,32))\n            images.append(temp_img)\n            labels.append(labels_dict[folder])\n            \n    images = np.array(images)\n    #normalize image \n    images = images.astype('float32')\/255.0\n    #one hot encoding the label\n    labels = keras.utils.to_categorical(labels)\n    \n    X_train = images\n    y_train = labels\n    \n    \n    print()\n    print('Loaded', len(X_train),'images,',' data shape =',X_train.shape)\n    #print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n    \n    return X_train, y_train","faafaf75":"#load validation and training data\nX_train, y_train = load_data(trainfile)\nX_valid, y_valid = load_data(validationfile)","9395529a":"#load validation and training data\nX_train, y_train = load_data(trainfile)\nX_valid, y_valid = load_data(validationfile)","343c9da9":"# **<span style=\"color:#6daa9f;\">4. Model <\/span>**","1f69bced":"#CNN MODEL\ndef create_model(optimizer):\n    model = Sequential()\n    model.add(Conv2D(200, (3, 3), input_shape = (32,32,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    \n    model.add(Conv2D(100, (3, 3), input_shape =(32,32,3)))\n    model.add(Activation('relu'))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    model.add(Dense(50, activation = 'relu'))\n    model.add(Dense(2, activation = 'softmax'))\n    \n    model.compile(loss = \"binary_crossentropy\", optimizer=optimizer, metrics = [\"accuracy\"])\n    model.summary()\n\n    return model","e2d9c58a":"def fit_model(model):\n    \n    model_hist = model.fit(X_train, y_train, batch_size = 50, epochs = 30, validation_data = (X_valid,y_valid))\n    return model_hist","1ea9ba9a":"print('Train and Fit Model 1 with Adam Optimizer and 30 epochs')\nmodel1 = create_model(optimizer = 'adam')\nmodel1_fit = fit_model(model1)","0556678b":"def evaluate_model(model):\n    test_loss,test_acc = model.evaluate(X_valid, y_valid)\n    print('Validation accuracy:', test_acc)\n    print('Validation loss:', test_loss)\n    \nevaluate_model(model1)","f8cbc634":"#plot model performance evaluation\ndef plot_performance(model_fit):\n    plt.figure(figsize = (10,4))\n    plt.subplot(1,2,1)\n    plt.plot(model_fit.history[\"accuracy\"], label = \"train accuracy\", color = \"red\")\n    plt.plot(model_fit.history[\"val_accuracy\"], label = \"validation accuracy\", color = \"blue\")\n    plt.legend()\n\n    plt.subplot(1,2,2)\n    plt.plot(model_fit.history[\"loss\"], label = \"train loss\", color = \"red\")\n    plt.plot(model_fit.history[\"val_loss\"], label = \"validation loss\", color = \"blue\")\n\n    plt.legend()\n    plt.show()","3df7f69f":"plot_performance(model1_fit)","84225168":"#preprocess test data\ndef load_test_data():\n    images = []\n    names = []\n    labels2 = []\n    \n    for folder in os.listdir(testfile):\n        print(folder, end = ' | ')\n\n        for image in os.listdir(testfile+'\/'+folder):\n            \n            temp = cv2.imread(testfile + '\/' + folder + '\/'+image)\n            #temp = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n            temp = cv2.resize(temp, (32,32))\n\n            images.append(temp)\n            names.append(image)\n            labels2.append(labels_dict[folder])\n\n\n   \n            \n            \n    #one hot encoding label\n    #labels2 = keras.utils.to_categorical(labels2)\n\n  \n\n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n            \n    return images, names,labels2\n\ntest_images, test_img_names, labels2 = load_test_data()","2b9814c5":"predictions = [model1.predict_classes(image.reshape(1,32,32,3))[0] for image in test_images]","a5f0ae99":"from sklearn import metrics\n#classification report for test data predictions f1 score,precision,accuracy\nprint(metrics.classification_report(predictions,labels2))","1a979e53":"#return label for prediction\ndef get_labels_for_plot(predictions):\n    predictions_labels = []\n    for i in range(len(predictions)):\n        for ins in labels_dict:\n            if predictions[i] == labels_dict[ins]:\n                predictions_labels.append(ins)\n                break\n    return predictions_labels\n\npredictions_labels_plot = get_labels_for_plot(predictions)","3d15dd3e":"import random as rands\npredfigure = plt.figure(figsize = (20,20))\n#function to plot image with their prediction label\ndef plot_image_1(fig, image, label, prediction, predictions_label, row, col, index):\n    fig.add_subplot(row, col, index)\n    plt.axis('off')\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\" + label\n    plt.title(title)\n    return\n\nrow = 4\ncol = 4\n#plot random processed image in test data with their prediction label \nfor i in range(1,(row*col-1)):\n    image_index = rands.randint(1,950)\n    plot_image_1(predfigure, test_images[image_index], test_img_names[image_index], predictions[image_index], predictions_labels_plot[image_index], row, col, i)\nplt.show()","614fb7f5":"# **<span style=\"color:#6daa9f;\">4. Load Data <\/span>**\n\n* load data\n* preprocessing image - normalize,resize,convert to grayscale(experiment)\n* one hot encoding the label","b41c88be":"## Model evaluation","8f34e9f6":"X_train = X_train.reshape(-1,32,32,1)\nX_valid = X_valid.reshape(-1,32,32,1)","8da432fc":"# **<span style=\"color:#6daa9f;\">1.Import Library & Packages <\/span>**\n"}}