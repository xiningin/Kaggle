{"cell_type":{"4b9140ce":"code","fd49e2ce":"code","fe895920":"code","d66a96a7":"code","6a63a4c5":"code","7f4bab8e":"code","3b65bfca":"code","78b7f8f3":"code","251462c2":"code","94319418":"code","ea10763f":"code","ca3443c7":"code","98a95f38":"code","43a9bfbe":"code","2473025b":"code","328e9c44":"code","bc43e773":"code","0bb2f708":"code","974f66ae":"code","1c95d851":"code","b9c7fb7d":"code","a09563c4":"code","1690311a":"code","a0e15045":"code","8b62bc4e":"code","f49f214b":"code","3952057e":"code","28affdea":"code","55c9e60c":"code","02eaee22":"code","64676b6b":"code","61ab4a5a":"code","e9e7f862":"code","c7d31f52":"code","621616ce":"code","65e4566d":"markdown","1790812d":"markdown","fcb7a42e":"markdown","4ae74aec":"markdown","27cca085":"markdown","d45b9406":"markdown","d8e37c48":"markdown","b5a6be6c":"markdown","1be6d043":"markdown","62d6f05e":"markdown","72d105f0":"markdown","e71a066c":"markdown"},"source":{"4b9140ce":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport matplotlib as mpl\nimport matplotlib.pylab as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold","fd49e2ce":"from sklearn import preprocessing as pp \nfrom scipy.stats import pearsonr \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.metrics import log_loss \nfrom sklearn.metrics import precision_recall_curve, average_precision_score \nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, classification_report ","fe895920":"DATA_DIR  = os.path.join('\/kaggle\/input\/lish-moa')\nTRAIN_FEATURE_FILE = os.path.join(DATA_DIR, 'train_features.csv')\nTEST_FEATURE_FILE = os.path.join(DATA_DIR, 'test_features.csv')\n\nTRAIN_TRAGET_FILE = os.path.join(DATA_DIR, 'train_targets_scored.csv')\nSUBMISSION_FILE = os.path.join(DATA_DIR, 'sample_submission.csv')","d66a96a7":"train_feat = pd.read_csv(TRAIN_FEATURE_FILE)\ntest_feat = pd.read_csv(TEST_FEATURE_FILE)","6a63a4c5":"train_feat.head()","7f4bab8e":"train_feat.describe()","3b65bfca":"train_target = pd.read_csv(TRAIN_TRAGET_FILE)","78b7f8f3":"train_target.head()","251462c2":"train_target.describe()","94319418":"y_columns = train_target.drop(columns='sig_id', axis=0)\ny_columns.columns","ea10763f":"train_target_2 = pd.DataFrame(train_target['11-beta-hsd1_inhibitor'].value_counts())\ntrain_target_2.reset_index(inplace=True)\ntrain_target_2.columns = ['value','count']\n\nprint(train_target_2)\n\nplt.figure(figsize = (5, 5))\nplt.title('11-beta-hsd1_inhibitor')\ng = sns.barplot(x=\"value\", y=\"count\", data=train_target_2, palette=\"pastel\")\n\n\nplt.show()","ca3443c7":"train = pd.merge(train_feat, train_target, on='sig_id')","98a95f38":"train_filter = train[train['5-alpha_reductase_inhibitor'] == 1]\ntrain_filter = train_filter.iloc[:, :876]\ntrain_filter","43a9bfbe":"corr = train_filter.corr(method = 'pearson')\ncorr","2473025b":"#df_heatmap = sns.heatmap(corr, cbar = True, annot = True, annot_kws={'size' : 20}, fmt = '.2f', square = True, cmap = 'Blues')","328e9c44":"train_feat = train_feat.drop(columns=['sig_id'], axis=0)\ntest_feat = test_feat.drop(columns=['sig_id'], axis=0)\n\nfor feature in ['cp_type', 'cp_dose', 'cp_time']:\n    le = LabelEncoder()\n    le.fit(list(train_feat[feature].astype(str).values) + list(test_feat[feature].astype(str).values))\n    train_feat[feature] = le.transform(list(train_feat[feature].astype(str).values))\n    test_feat[feature] = le.transform(list(test_feat[feature].astype(str).values))\n\nprint(train_feat.head(10))\n\nfrom sklearn.preprocessing import StandardScaler\nstd_scaler = StandardScaler()\n\nfitted = std_scaler.fit(train_feat)\n\ntrain_feat_scale = std_scaler.transform(train_feat)\ntrain_feat_scale = pd.DataFrame(train_feat_scale, columns=train_feat.columns, index=list(train_feat.index.values))\n\nprint(train_feat_scale.head(10))","bc43e773":"from sklearn.decomposition import PCA\n\ntrain_index = range(0, len(train_feat_scale))\n\nn_components = 872\nwhiten = False\nrandom_state = 2020\n\npca = PCA(n_components=n_components, whiten=whiten, random_state=random_state)","0bb2f708":"X_train_PCA = pca.fit_transform(train_feat_scale)\nX_train_PCA = pd.DataFrame(data=X_train_PCA, index=train_index)","974f66ae":"print(\"Variance Explained by all 872 principal components: \", sum(pca.explained_variance_ratio_))","1c95d851":"importanceOfPrincipalComponents = pd.DataFrame(data=pca.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint('Variance Captured By First 10 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:9].sum(axis=1).values)\nprint('Variance Captured By First 20 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:19].sum(axis=1).values)\nprint('Variance Captured By First 100 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:99].sum(axis=1).values)\nprint('Variance Captured By First 200 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:199].sum(axis=1).values)\nprint('Variance Captured By First 300 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:299].sum(axis=1).values)\nprint('Variance Captured By First 400 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:399].sum(axis=1).values)\nprint('Variance Captured By First 500 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:499].sum(axis=1).values)","b9c7fb7d":"importanceOfPrincipalComponentsT","a09563c4":"sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","1690311a":"#temp = train_target.iloc[:, 5:20]\n#temp = temp[(temp['acetylcholinesterase_inhibitor'] == 1) | (temp['adenosine_receptor_agonist'] == 1) | (temp['adenylyl_cyclase_activator'] == 1)]\n#temp.head(20)","a0e15045":"def scatterPlot(xDF, yDF, algoName):\n    tempDF = pd.DataFrame(data=xDF.loc[:, 0:1], index=xDF.index)\n    tempDF = pd.concat((tempDF, yDF), axis=1, join='inner')\n    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n    sns.lmplot(x='First Vector', y='Second Vector', hue='Label', data=tempDF, fit_reg=False)\n    \n    ax = plt.gca()\n    ax.set_title('Target Value  :  ' + algoName + '  ' + str(np.sum(tempDF['Label'])))   \n    \n    #print(np.sum(tempDF['Label']))\n\n    \ndef scatterPlot2(xDF, yDF, algoName, column1, column2):\n    tempDF = pd.DataFrame(data=xDF.loc[:, [column1, column2]], index=xDF.index)\n    tempDF = pd.concat((tempDF, yDF), axis=1, join='inner')\n    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n    sns.lmplot(x='First Vector', y='Second Vector', hue='Label', data=tempDF, fit_reg=False)\n    \n    ax = plt.gca()\n    ax.set_title('Separation of Observations using ' + algoName)","8b62bc4e":"for col in y_columns.columns[0:10]:\n    scatterPlot(X_train_PCA, train_target[col], col)\n","f49f214b":"scatterPlot2(train_feat_scale, train_target['trpv_agonist'], 'PCA', 'g-0', 'cp_time')","3952057e":"column_sum = np.sum(train_target, axis=0).to_frame()\ncolumn_sum.reset_index(inplace=True)\n\ncolumn_sum.columns = ['y_name', 'count']\n\ncolumn_sum = column_sum.iloc[1:,:]\ncolumn_sum = column_sum.sort_values(by=['count'], axis=0, ascending=False)\n\ncolumn_sum_top20 = column_sum[:20]\n\nprint(column_sum_top20)\n\nplt.figure(figsize = (20, 10))\nplt.title('# of true labels per column')\ng = sns.barplot(x=column_sum_top20['y_name'], y=column_sum_top20['count'], data=column_sum_top20, palette=\"pastel\")\ng.set_xticklabels(g.get_xticklabels(), rotation=45)\n\nplt.show()\n","28affdea":"column_sum_bottom20 = column_sum[-20:]\n\nprint(column_sum_bottom20)\n\nplt.figure(figsize = (20, 10))\nplt.title('# of true labels per column')\ng = sns.barplot(x=column_sum_bottom20['y_name'], y=column_sum_bottom20['count'], data=column_sum_bottom20, palette=\"pastel\")\ng.set_xticklabels(g.get_xticklabels(), rotation=45)\n\nplt.show()","55c9e60c":"row_sum = np.sum(train_target, axis=1)\n\nrow_sum_vc = pd.DataFrame(row_sum.value_counts())\nrow_sum_vc.reset_index(inplace=True)\nrow_sum_vc.columns = ['tlc','count']\n\nprint(row_sum_vc)\n\nplt.figure(figsize = (10, 10))\nplt.title('# of true labels per row')\nsns.barplot(x=row_sum_vc['tlc'], y=row_sum_vc['count'], data=row_sum_vc, palette=\"pastel\")\nplt.xlabel('target label count')\n\nplt.show()","02eaee22":"ratio_0_1 = row_sum_vc[(row_sum_vc['tlc'] == 0) | (row_sum_vc['tlc'] == 1)]['count'].sum() \/ row_sum_vc['count'].sum()\nprint(f'As for the number of targets for each row, 0 and 1 occupy {ratio_0_1} percent.')","64676b6b":"train_columns = train_feat_scale.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]\ntrain_feat_g = train_feat_scale[g_list]\ntrain_feat_c = train_feat_scale[c_list]","61ab4a5a":"train_feat_g","e9e7f862":"train_feat_c","c7d31f52":"train_index = range(0, len(train_feat_g))\n\nn_components = 772\nwhiten = False\nrandom_state = 2020\n\npca_g_feat = PCA(n_components=n_components, whiten=whiten, random_state=random_state)\n\nX_train_PCA_g = pca_g_feat.fit_transform(train_feat_g)\nX_train_PCA_g = pd.DataFrame(data=X_train_PCA_g, index=train_index)\n\nimportanceOfPrincipalComponents = pd.DataFrame(data=pca_g_feat.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint(importanceOfPrincipalComponents)\n#sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","621616ce":"train_index = range(0, len(train_feat_c))\n\nn_components = 100\nwhiten = False\nrandom_state = 2020\n\npca_c_feat = PCA(n_components=n_components, whiten=whiten, random_state=random_state)\n\nX_train_PCA_c = pca_c_feat.fit_transform(train_feat_c)\nX_train_PCA_c = pd.DataFrame(data=X_train_PCA_c, index=train_index)\n\nimportanceOfPrincipalComponents = pd.DataFrame(data=pca_c_feat.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint(importanceOfPrincipalComponents)\n#sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","65e4566d":"### Target Label (This competetion is Multi Label Classification)","1790812d":"## Number per target","fcb7a42e":"## EDA","4ae74aec":"### Feature Scaler","27cca085":"## Load File, Data","d45b9406":"### pearson correlation","d8e37c48":"## Number per Count","b5a6be6c":"## PCA (Principal Component Analysis)","1be6d043":"This notebook was written for beginners.\nI want to perform data analysis. Check the number of train data and test data.","62d6f05e":"### View feature per target\n#### ex) 5-alpha_reductase_inhibitor","72d105f0":"### Concat train_feat and train_target","e71a066c":"## Import Library"}}