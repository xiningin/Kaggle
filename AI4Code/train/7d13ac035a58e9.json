{"cell_type":{"60d2e9ea":"code","1223e871":"code","09cbc526":"code","14a7f8a6":"code","d06839a3":"code","a6106111":"code","3cc2da24":"code","9e40d869":"code","77a10d33":"code","fd60c2a2":"code","8b4af00b":"code","48cbabf5":"code","b8f27295":"code","bfcbcd53":"code","d8cde3b9":"code","29e2a634":"code","7e74f78b":"code","1204aa1d":"code","8833a93a":"code","990a7330":"code","698b4609":"code","dde0af5b":"code","35bcd4c8":"code","f8c979c3":"code","06521246":"code","7f59532e":"code","29aa2a51":"code","06008611":"code","b7d6caea":"code","411fe5ca":"code","86f2a824":"code","e3470bec":"code","6890806c":"code","3a081fdf":"code","dd09b3a3":"code","155eb68f":"code","28961735":"code","359f4ca7":"code","d3cd56a6":"code","2cbe0cca":"code","c47ab584":"code","e97f0aad":"code","66e7278b":"code","a0e1aed5":"code","0cd13517":"code","115c6586":"code","f1c6ccc9":"code","aa9a63d4":"code","bf245375":"code","12333e6a":"code","55f21cf2":"code","1afe8ba1":"code","fefb6a4c":"code","e3017771":"code","0e4e71af":"code","83f3e17d":"code","a4e26c0b":"code","cbb487c3":"code","24fd2e87":"code","2b582e6d":"code","a943dcad":"code","bb6ef6d1":"code","05263562":"code","b876179a":"code","807b83ee":"code","1aa89cf8":"code","813a3b50":"code","4b55c952":"code","4c6555cd":"code","a94a79cb":"code","89d3a98d":"code","b247497e":"code","1bd92baf":"code","b11bafd9":"code","1a2cb155":"code","3c6f817f":"code","daeb94c1":"code","c4768fdc":"markdown","f72a6255":"markdown","30c1a21d":"markdown","a8a5c7d7":"markdown","cc1448b2":"markdown","afe1724b":"markdown","328c8cc5":"markdown","709d5726":"markdown","f0bbf2eb":"markdown","81f44b9f":"markdown","5abb3182":"markdown","264df553":"markdown","a76fff78":"markdown","c87b97e3":"markdown","54f33b67":"markdown","0bf1b8b9":"markdown","86fe6bc8":"markdown","06260b4a":"markdown","ee7e3d5e":"markdown","e771c9de":"markdown","3efc3be9":"markdown","9dfb5063":"markdown","702ea4d2":"markdown","23156d10":"markdown","3b08e086":"markdown","e25d7810":"markdown","6bf1aa43":"markdown","ccbf7ffe":"markdown","56b62329":"markdown","2cc8bb74":"markdown","58c0f46a":"markdown","959aa68f":"markdown","b9c3efc9":"markdown","e6b52d3e":"markdown","b92d0c4d":"markdown","cf061cba":"markdown","4c90aa61":"markdown","8ae952af":"markdown","803d37f9":"markdown","66ae690e":"markdown","4b778f70":"markdown","a54b2973":"markdown","c963de2d":"markdown","69fa1aee":"markdown","f753f6f9":"markdown","37c5525d":"markdown","5269ebcf":"markdown","5757d9ef":"markdown","86ce820b":"markdown","20751f35":"markdown","09b6dcac":"markdown","89ca0c45":"markdown","00b92821":"markdown","5cabc99f":"markdown","f8eedf2b":"markdown","115e6b0d":"markdown","3b7feb96":"markdown","3d40b891":"markdown","8701fe77":"markdown","8fc3a8ee":"markdown","cecaa034":"markdown","9ec3ba9c":"markdown","5b8c35e1":"markdown","d3e23efc":"markdown","45810352":"markdown","861468c6":"markdown","eee2fce2":"markdown","71c997af":"markdown","bf5aa642":"markdown","d2835465":"markdown","768c6b1a":"markdown","450aa690":"markdown","9b56af59":"markdown","9c4b8429":"markdown","6bd6e8c8":"markdown","3fb193a6":"markdown","98dce6ab":"markdown","3c19a41e":"markdown","fee99a67":"markdown","73ca78cc":"markdown","c0da2278":"markdown","0ee07885":"markdown","f8560e83":"markdown","babe9204":"markdown","2b6d8ef9":"markdown","29999405":"markdown","1f807b0d":"markdown","74080f84":"markdown","0642b587":"markdown","b750e7d0":"markdown","0666fe6b":"markdown","d5e0d627":"markdown","1e3eacdc":"markdown","39656977":"markdown","01472181":"markdown","126c7b82":"markdown","8c13fe2e":"markdown","e38f1e72":"markdown","d0d4e244":"markdown","2bf92a3c":"markdown","295371c5":"markdown","4a56d0f9":"markdown","7a1ebbda":"markdown","492df607":"markdown","e31ade76":"markdown","db6e737c":"markdown","2df76f55":"markdown","cbf4ea72":"markdown","184a8f41":"markdown","c5bd9074":"markdown","6663f6ae":"markdown","46275640":"markdown","db6cfe5b":"markdown","13055d7f":"markdown","6a7df95e":"markdown","c443aec8":"markdown","d0a79abe":"markdown","aa911763":"markdown","390b406c":"markdown","ff045a62":"markdown","f23cf899":"markdown","ebc750f2":"markdown","caf3d868":"markdown","599d60f9":"markdown","a02eed89":"markdown","ea9460e0":"markdown","87c7711a":"markdown","510e0f5a":"markdown","f2c89eef":"markdown","629e6cde":"markdown","f5d3c136":"markdown","e1b7872f":"markdown","9590a210":"markdown","6842bd87":"markdown","2fca372a":"markdown","661466f5":"markdown","8040041a":"markdown","0468e02d":"markdown","86cb8f50":"markdown","2c4b2b70":"markdown"},"source":{"60d2e9ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1223e871":"\n# storing and analysis\nimport numpy as np\nimport pandas as pd\nimport re\n\n# visualization\nimport matplotlib.pyplot as plt\nimport warnings\nimport nltk\nimport string\nimport seaborn as sns\n\n#import text classification modules\nimport os\nfrom nltk.tokenize import WordPunctTokenizer\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\n\nfrom nltk.stem.porter import * \nfrom wordcloud import WordCloud\nimport spacy\nfrom spacy import displacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# import train\/test split module\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\n\n# import scoring metrice\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# suppress cell warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","09cbc526":"#Load the training set and load the test set from kaggle\ntrain_df = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv') #Load train dataset\ntest_df = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv') #Load test dataset","14a7f8a6":"#display first 5 entries of the train data\ntrain_df.head()","d06839a3":"#Display the first 5 entries of the test data\ntest_df.head()","a6106111":"#Print out the Shape of the training data and the testing data\nprint('Shape of Train Dataset:',train_df.shape)\nprint('Shape of Test Dataset:',test_df.shape)","3cc2da24":"#Use the value_counts() method to displace the count of each sentiment in the training dataset\ntrain_df['sentiment'].value_counts()","9e40d869":"#Use the isnull() method to check for null values in training data\n#.sum() method evaluates the total of each column of null values\ntrain_df.isnull().sum()","77a10d33":"#Combining both train and test data set before data cleaning as tweets in both the data set is unstructured\ndata = train_df.append(test_df, ignore_index=True) #Combine the two datasets and assing the variable 'data'","fd60c2a2":"#User Defined function to clean unwanted text patterns from all tweets\n# input - text to clean,pattern to replace\ndef remove_pattern(input_txt, pattern):\n    \"\"\"Removes unwanted text patterns from the tweets.\n    \n    Parameters\n    ----------\n    input_txt: string\n                Original tweet string from the dataset\n    \n    pattern: regular expression\n                pattern of text\n    \n    Returns\n    -------\n    input_txt: string\n        returns the same input string without the given pattern as a result of the regular expresion on the input_text\n    \"\"\"\n    r = re.findall(pattern, input_txt) #create an instance of the regular expression and assign the variable r\n    for i in r:#Loop through the instance\n        input_txt = re.sub(i, '', input_txt) #Remove the twitter handle from the dataset\n        \n    return input_txt","8b4af00b":"# remove twitter handles from the combined dataset (@user)\ndata['tidy_message'] = np.vectorize(remove_pattern)(data['message'], \"@[\\w]*\")\n","48cbabf5":"#Removing RT from tweets and converting to lowercase\ndata['tidy_message'] = data['tidy_message'].str.replace('RT :',' ') #removing rt's\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: x.lower())#Coverting all the tweets to lowercase since they are easier to work with","b8f27295":"data.head()","bfcbcd53":"#Initialise a Short for dictionary and assign it the variable 'short_word_dict'\nshort_word_dict = {\n\"121\": \"one to one\",\n\"a\/s\/l\": \"age, sex, location\",\n\"adn\": \"any day now\",\n\"afaik\": \"as far as I know\",\n\"afk\": \"away from keyboard\",\n\"aight\": \"alright\",\n\"alol\": \"actually laughing out loud\",\n\"b4\": \"before\",\n\"b4n\": \"bye for now\",\n\"bak\": \"back at the keyboard\",\n\"bf\": \"boyfriend\",\n\"bff\": \"best friends forever\",\n\"bfn\": \"bye for now\",\n\"bg\": \"big grin\",\n\"bta\": \"but then again\",\n\"btw\": \"by the way\",\n\"cid\": \"crying in disgrace\",\n\"cnp\": \"continued in my next post\",\n\"cp\": \"chat post\",\n\"cu\": \"see you\",\n\"cul\": \"see you later\",\n\"cul8r\": \"see you later\",\n\"cya\": \"bye\",\n\"cyo\": \"see you online\",\n\"dbau\": \"doing business as usual\",\n\"fud\": \"fear, uncertainty, and doubt\",\n\"fwiw\": \"for what it's worth\",\n\"fyi\": \"for your information\",\n\"g\": \"grin\",\n\"g2g\": \"got to go\",\n\"ga\": \"go ahead\",\n\"gal\": \"get a life\",\n\"gf\": \"girlfriend\",\n\"gfn\": \"gone for now\",\n\"gmbo\": \"giggling my butt off\",\n\"gmta\": \"great minds think alike\",\n\"h8\": \"hate\",\n\"hagn\": \"have a good night\",\n\"hdop\": \"help delete online predators\",\n\"hhis\": \"hanging head in shame\",\n\"iac\": \"in any case\",\n\"ianal\": \"I am not a lawyer\",\n\"ic\": \"I see\",\n\"idk\": \"I don't know\",\n\"imao\": \"in my arrogant opinion\",\n\"imnsho\": \"in my not so humble opinion\",\n\"imo\": \"in my opinion\",\n\"iow\": \"in other words\",\n\"ipn\": \"I\u2019m posting naked\",\n\"irl\": \"in real life\",\n\"jk\": \"just kidding\",\n\"l8r\": \"later\",\n\"ld\": \"later, dude\",\n\"ldr\": \"long distance relationship\",\n\"llta\": \"lots and lots of thunderous applause\",\n\"lmao\": \"laugh my ass off\",\n\"lmirl\": \"let's meet in real life\",\n\"lol\": \"laugh out loud\",\n\"ltr\": \"longterm relationship\",\n\"lulab\": \"love you like a brother\",\n\"lulas\": \"love you like a sister\",\n\"luv\": \"love\",\n\"m\/f\": \"male or female\",\n\"m8\": \"mate\",\n\"milf\": \"mother I would like to fuck\",\n\"oll\": \"online love\",\n\"omg\": \"oh my god\",\n\"otoh\": \"on the other hand\",\n\"pir\": \"parent in room\",\n\"ppl\": \"people\",\n\"r\": \"are\",\n\"rofl\": \"roll on the floor laughing\",\n\"rpg\": \"role playing games\",\n\"ru\": \"are you\",\n\"shid\": \"slaps head in disgust\",\n\"somy\": \"sick of me yet\",\n\"sot\": \"short of time\",\n\"thanx\": \"thanks\",\n\"thx\": \"thanks\",\n\"ttyl\": \"talk to you later\",\n\"u\": \"you\",\n\"ur\": \"you are\",\n\"uw\": \"you\u2019re welcome\",\n\"wb\": \"welcome back\",\n\"wfm\": \"works for me\",\n\"wibni\": \"wouldn't it be nice if\",\n\"wtf\": \"what the fuck\",\n\"wtg\": \"way to go\",\n\"wtgp\": \"want to go private\",\n\"ym\": \"young man\",\n\"gr8\": \"great\",\n\"8yo\":\"eight year old\"\n}","d8cde3b9":"#Function used to lookup shortwords from the dictionary\ndef lookup_dict(text, dictionary):\n    \"\"\"Performs a lookup of the short word and returns the full meaning.\n    \n    Parameters\n    ----------\n    text: string\n        Original tweet string from the dataset\n    dictionary: dictionary\n        dictionary with the short words as keys and the full meaning as the values\n    \n    Returns\n    -------\n    text: string\n        Returns a new tweet string with the full meaning of the word as a result of replacement of the short word from the dictionary\n    \"\"\"\n    for word in text.split(): #split the text into a list and loop through the list for find the words\n        if word.lower() in dictionary: #Lower the words and see if they are in the dictionary\n            if word.lower() in text.split(): #lower the words and see if they are in the text list\n                text = text.replace(word, dictionary[word.lower()]) #replace the word in the text split with the values in the dictionary\n    return text\n","29e2a634":"#Perform lookup of short words and return the string with the full meaning\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: lookup_dict(x,short_word_dict))# Use the short word ","7e74f78b":"#Initiatise a dictionary of apostrophe words and assign the variable 'contractions'\ncontractions = {\n\"ain't\": \"am not \/ are not\",\n\"aren't\": \"are not \/ am not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had \/ he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall \/ he will\",\n\"he'll've\": \"he shall have \/ he will have\",\n\"he's\": \"he has \/ he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has \/ how is\",\n\"i'd\": \"I had \/ I would\",\n\"i'd've\": \"I would have\",\n\"i'll\": \"I shall \/ I will\",\n\"i'll've\": \"I shall have \/ I will have\",\n\"i'm\": \"I am\",\n\"i've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall \/ it will\",\n\"it'll've\": \"it shall have \/ it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had \/ she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall \/ she will\",\n\"she'll've\": \"she shall have \/ she will have\",\n\"she's\": \"she has \/ she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as \/ so is\",\n\"that'd\": \"that would \/ that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has \/ that is\",\n\"there'd\": \"there had \/ there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has \/ there is\",\n\"they'd\": \"they had \/ they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall \/ they will\",\n\"they'll've\": \"they shall have \/ they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had \/ we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall \/ what will\",\n\"what'll've\": \"what shall have \/ what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has \/ what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has \/ when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has \/ where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall \/ who will\",\n\"who'll've\": \"who shall have \/ who will have\",\n\"who's\": \"who has \/ who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has \/ why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had \/ you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall \/ you will\",\n\"you'll've\": \"you shall have \/ you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}","1204aa1d":"#Perform lookup of apostrophe words and return the string with the full meaning\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: lookup_dict(x,contractions))# Use the contraction dictionary to replace the aprostophe words in data with the full meaning\ndata.head()","8833a93a":"# Lookup which emojis exist in the tweets and save them as a list\ntweets_text = data.tidy_message.str.cat() #Concatenate the tweet string and assign the variable 'tweets_text'\nemos = set(re.findall(r\" ([xX:;][-']?.) \",tweets_text)) #Create a regular expression that finds the emojis in the tweets\nemos_count = [] #Initialise an empty list 'emo_count'\nfor emo in emos: #Loop through emoji\n    emos_count.append((tweets_text.count(emo), emo)) #Add emojis found into the emo_count list\nsorted(emos_count,reverse=True) #Sort the list in reverse order","990a7330":"#Initialise a emoji list and assign it to emoticon_dict\nemoticon_dict={\n'XD':'happy',\n';)':'happy',\n':-)':'happy',\n';-)':'happy',\n':P':'happy', \n':)':'happy',\n'x ':'happy',\n':(':'sad',\n':\/':'sad'\n}","698b4609":"#Lookup the emojis in the tweets and replace them with the meaning behind the tweet\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: lookup_dict(x,emoticon_dict))# Use emoticon_dict to replace decode emojis in the dataset","dde0af5b":"#Function to remove the remaining emojis in the tweets\ndef remove_emoji(message):\n    \"\"\"Performs a lookup of the short word and returns the full meaning.\n    \n    Parameters\n    ----------\n    message: string\n        Original tweet string from the dataset\n\n    Returns\n    -------\n    emoji_pattern.sub(r'', message): string\n        Returns a new tweet which has removed unnecesary emojis as a result of the regular expression \n    \"\"\"\n    emoji_pattern = re.compile(\"[\"                   # Create a regular expression\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', message)","35bcd4c8":"#Perform lookup of emojis on the dataset and replace the tweet\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: remove_emoji(x))#Use the remove_emoji function to replace tweets in the dataset","f8c979c3":"# remove special characters, numbers, punctuations\ndata['tidy_message'] = data['tidy_message'].str.replace(\"[^a-zA-Z#]\", \" \")\ndata.head(10)","06521246":"#remove short words of less than 3 letters in length\ndata['tidy_message'] = data['tidy_message'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))#Remove words that are shorter than 3 characters","7f59532e":"data.head()","29aa2a51":"#Use tokenization to the words into a list of tokens \ntokenized_tweet = data['tidy_message'].apply(lambda x: x.split()) #Tokenize the dataset\ntokenized_tweet.head()","06008611":"#Use PorterStemmer() to strip suffixes from the words\nfrom nltk.stem.porter import * #Import * from nltk.stem.porter\nstemmer = PorterStemmer() #Initialize an instance of PorterStemmer and assign it a variable 'stemmer'\n\ntokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) #Stem the dataset\ntokenized_tweet.head()","b7d6caea":"#We will now bring the tokens back together\nfor i in range(len(tokenized_tweet)): #Lopp through token list of stems\n    tokenized_tweet[i] = ' '.join(tokenized_tweet[i]) #Join the list into a string of characters\n\ndata['tidy_message'] = tokenized_tweet #Assign the string of words to the dataset in the tid_message column","411fe5ca":"#Split the dataset back to the training set and the testing set\ntrain = data[:len(train_df)] #Split to the lenght of original training set\ntest = data[len(train_df):]  #Split to the length of original testing set","86f2a824":"#Use the .shape to see the length of the train dataset with the amound of features\ntrain.shape","e3470bec":"#Use the value_counts to see the values of the individual classes\ntrain['sentiment'].value_counts() ","6890806c":"#Create a barplot for the train dataset classes\nNews = train['sentiment'].value_counts()[2] #Take values of class 2 and assign the variable 'News'\nPro= train['sentiment'].value_counts()[1]   #Take values of class 1 and assign the variabe 'Pro'\nNeutral=train['sentiment'].value_counts()[0]#Take the values of class 0 and assign the variable 'Neutral'\nAnti=train['sentiment'].value_counts()[-1]  #Take the values of class -1 and assing the variable 'Anti'\n\nsns.barplot(['News ','Pro','Neutral','Anti'],[News,Pro,Neutral,Anti]) #Use seaborn barplot and add a list of classes\nplt.xlabel('Tweet Classification') #X-label of the data\nplt.ylabel('Count of Tweets')      #Y_label of the data\nplt.title('Dataset labels distribution') #Give the data a title 'Dataset lables distribution'\nplt.show() #Display the dataset\n\nprint('No of Tweets labelled as News:',News) #Print out all the classes values\nprint('No of Tweets labelled as Pro:',Pro)\nprint('No of Tweets labelled as Neutral:',Neutral)\nprint('No of Tweets labelled as Anti:',Anti)\n\nprint('Data is unbalanced and may need to be resampled in order to balance it with only',round(((News\/(News+Pro+Neutral+Anti))*100),2),'% news tweets,',\n      round(((Pro\/(Pro+News+Neutral+Anti))*100),2),'% (pro)positive tweets,',round(((Neutral\/(Neutral+Pro+News+Anti))*100),2),'% neutral tweets and',\n      round(((Anti\/(Anti+Neutral+News+Pro))*100),2),'% (anti)negative tweets') #Print out the percentages that each class represents in the dataset","3a081fdf":"\n#Check the Distribution of Length of Tweets in train and Test Dataset\ntweetLengthTrain = train['message'].str.len() #Compute the length of the elements in the training set\ntweetLengthTest = test['message'].str.len()   #Compute the length of the elements in the test set\nflatui = [\"#15ff00\", \"#ff0033\"]#Color scheme\nsns.set_palette(flatui)\nplt.hist(tweetLengthTrain,bins=20,label='Train_Tweet') #Plot the histogram of training set\nplt.hist(tweetLengthTest,bins=20,label='Test_Tweet')   #Plot the histogram of the test set\nplt.legend()\nplt.show()","dd09b3a3":"#create a new length value column that contains the lengths of the messages\ntrain['message_length'] = train['message'].apply(len)","155eb68f":"#Create a violinplot of the dataset\nplt.figure(figsize=(8,5)) #Set the figsize to 8 and 5 respectively\nplt.title('Sentiments vs. Length of tweets') #Add the title of the violin plot\nsns.violinplot(x='sentiment', y='message_length', data=train,scale='count') #Add the dimentions of the violin plot\nplt.ylabel(\"Length of the tweets\") #Y_lable of the plot\nplt.xlabel(\"Sentiment Class\") #X_label of the plot","28961735":"#Use seaborn to create a boxplot using the message length and the sentiment\nsns.boxplot(x='sentiment',y='message_length',data=train,palette='rainbow')","359f4ca7":"#Use groupby in order to numerically display what the boxplot is trying to show to the user\ntrain['message_length'].groupby(train['sentiment']).describe()","d3cd56a6":"#Create Multiple histograms for all classes\nplt.figure(figsize=(10,6)) #Add figure dimentions\nnbins = np.arange(0,210) #Add the necesarry amount of bins\nplt.hist(train[train['sentiment']==2.0]['message_length'],bins=nbins, color=\"blue\") #Histogram for news class\nplt.hist(train[train['sentiment']==1.0]['message_length'],bins=nbins, color=\"red\") #Histogram for positive class\nplt.hist(train[train['sentiment']==0.0]['message_length'],bins=nbins, color=\"yellow\") #Histogram for neutraL class\nplt.hist(train[train['sentiment']==-1.0]['message_length'],bins=nbins) #Hisogram for negative class\nplt.legend(('2-News','1-Pro','0-Neutral','1-Anti')) #Create a legend to displace each class color\n#plt.ylabel(\"Count of messages\")\nplt.xlabel(\"Message Length\")\nplt.show()","2cbe0cca":"#Create strings for each class\npositive_words =' '.join([text for text in data['tidy_message'][data['sentiment'] == 1]]) #Words in the positve class\nnegative_words = ' '.join([text for text in data['tidy_message'][data['sentiment'] == -1]]) #Words in negative class\nnormal_words =' '.join([text for text in data['tidy_message'][data['sentiment'] == 0]]) #Words in the neutral class\nnews_words =' '.join([text for text in data['tidy_message'][data['sentiment'] == 2]]) #Words in the news class","c47ab584":"#Create a user defined function to display a word cloud for each class\ndef word_cloud(class_words):\n    \"\"\"Generates a word cloud visualization of words in the different class.\n    \n    Parameters\n    ----------\n    class_words: string\n        Words in each class\n\n    Returns\n    -------\n    plt.show(): wordcloud visualisation\n        Returns a visualisation of all the words that come from the class_words string\n    \"\"\"\n    wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(class_words)\n    plt.figure(figsize=(10, 7))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.title(\"Most Common positive words\")\n    plt.axis('off')\n    return plt.show()\n","e97f0aad":"#Visualise all words from the positive class\nword_cloud(positive_words)","66e7278b":"#Visualise all words from the negative class class\nword_cloud(negative_words)","a0e1aed5":"#Visualise all words from the neutral class\nword_cloud(normal_words)","0cd13517":"#Visualise all words from the news class\nword_cloud(news_words)","115c6586":"#Create a function to collect hashtags\ndef hashtag_extract(x):\n    \"\"\"Generate a list of all the hastags in different tweets.\n    \n    Parameters\n    ----------\n    x: string\n        Original tweet from the training dataset\n\n    Returns\n    -------\n    hashtags : list\n        Returns a list of all hashtags in x\n    \"\"\"\n    hashtags = [] #Initialize an empty list\n    for i in x:   #Loop over the words in the tweet\n        ht = re.findall(r\"#(\\w+)\", i) #Create a regular expression to get the hashtags in a tweet\n        hashtags.append(ht) #Add all those hashtags to the empty hashtag list\n\n    return hashtags","f1c6ccc9":"# extracting hashtags from the news\nHT_news = hashtag_extract(data['tidy_message'][data['sentiment'] == 2])\n# extracting hashtags from positive sentiments\nHT_positive = hashtag_extract(data['tidy_message'][data['sentiment'] == 1])\n# extract hashtags from neutral sentiments\nHT_normal = hashtag_extract(data['tidy_message'][data['sentiment'] == 0])\n# extracting hashtags from negative sentiments\nHT_negative = hashtag_extract(data['tidy_message'][data['sentiment'] == -1])\n\n# unnesting list of all sentiments\nHT_news = sum(HT_news,[])\nHT_positive = sum(HT_positive,[])\nHT_normal = sum(HT_normal,[])\nHT_negative = sum(HT_negative,[])","aa9a63d4":"#Create a function that visualises the barplot distribution of the hashtags\ndef bar_dist(x):\n    \"\"\"Generate a barplot of the top appearing hashtags in a class.\n    \n    Parameters\n    ----------\n    x: list\n        List of all hashtag values in a class without the #\n\n    Returns\n    -------\n    plt.show() : matplotlib barplot\n        Returns a barplot of x\n    \"\"\"\n    a = nltk.FreqDist(x) #Create a count of the hashtags in the list\n    d = pd.DataFrame({'Hashtag': list(a.keys()), #Create a dataframe with the values of the counts of a\n                  'Count': list(a.values())})  \n    d = d.nlargest(columns=\"Count\", n = 10) # selecting top 10 most frequent hashtags  \n    plt.figure(figsize=(16,5))\n    ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\") #Initisalise seaborn barplot\n    ax.set(ylabel = 'Count') #Set lables\n    return plt.show()","bf245375":"#Display barplot of the News hastags\nbar_dist(HT_news)","12333e6a":"#Display barplot of the positive hastags\nbar_dist(HT_positive)","55f21cf2":"#Display barplot of the neutral hastags\nbar_dist(HT_normal)","1afe8ba1":"#Display barplot of the neutral hastags\nbar_dist(HT_negative)","fefb6a4c":"#Splitting features and target variables\nX = train['tidy_message'] #X is the features of the cleaned tweets\ny = train['sentiment']    #Y is the target variable which is the train sentiment\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) #Splitting train set into training and testing data\n#Print out the shape of the training set and the testing set\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","e3017771":"# import and call the TFidfVectorizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer #Import TFidfVectorizer from sklearn\ntfidf = TfidfVectorizer() #Call the TFidfVectorizer and assign it to the tfidf variable\n","0e4e71af":"#import CountVectorizer and call it\nfrom sklearn.feature_extraction.text import CountVectorizer #Import CountVectorizer from sklearn\n\ncf= CountVectorizer() #Call the CountVectorizer and assing it to the variable 'cf'","83f3e17d":"#Import metrics from sklearn\nfrom sklearn import metrics","a4e26c0b":"# create a pipeline and fit it with a Logistic Regression\nfrom sklearn.linear_model import LogisticRegression #Import Logistic Regression from sklearn\n\nmodel = LogisticRegression(multi_class='ovr') #Call the Logistic Regression model and assign it to the variable 'model'\n\nclf = Pipeline([('tfidf', tfidf), ('clf', model)]) #Create a pipeline with the TF-IDF Vectorizer with the logistic model\n\n\nclf.fit(X_train, y_train) #Fit the training data to the pipeline\n\ny_pred= clf.predict(X_test) #Make predictions and assign the predictions to y_pred\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the weighted f1 score\nprint(classification_report(y_test, y_pred)) #Classification","cbb487c3":"## create a pipeline and fit it with a Linear Support Vector Classifier\nfrom sklearn.svm import LinearSVC #Import LinearSVC from sklearn \n\nclassifier = LinearSVC() #Call LinearSVC and assign the variable 'classifier'\n\nclf = Pipeline([('tfidf', tfidf), ('clf', classifier)]) #Create a pipeline with the tdidf\n\nclf.fit(X_train, y_train) #Fit the model\ny_pred = clf.predict(X_test) #Make predictions and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1-score\nprint(classification_report(y_test, y_pred)) #Print the classification report","24fd2e87":"## create a pipeline and fit it with a  Support Vector Classifier\nfrom sklearn.svm import SVC #Import SVC from sklearn \n\nclassifier = SVC(kernel='rbf') #Call the SVC with the kernel='rbf' parameter\n\nclf = Pipeline([('tfidf', tfidf), ('clf', classifier)]) #Add the SVC model to the pipeline\n\nclf.fit(X_train, y_train) #Fit the training data\ny_pred = clf.predict(X_test) #Make predictions to the test set and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification","2b582e6d":"#Create a pipeline and predict the test sentiment using logistic regression\nfrom sklearn.linear_model import LogisticRegression #Import Logistic Regression from the sklearn\nmodel = LogisticRegression(multi_class='ovr' ) #Call logistic regression and assign it to the 'model' variable\n\ntext_lr= Pipeline([('cf', cf),('clf',model)]) #Create a pipeline of the bag of words and the logistic regression\n\ntext_lr.fit(X_train, y_train) #Fit the training data to the pipeline\n\ny_pred = text_lr.predict(X_test) #Make a prediction of the test set\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1-score\nprint(classification_report(y_test, y_pred)) #Print out the classification report","a943dcad":"#Create a pipeline and make predictions of the bag of words using linearSVC\nfrom sklearn.svm import LinearSVC #Import LinearSVC from the sklearn\n\n\nclf= Pipeline([('cf', cf),('clf',  LinearSVC())]) #Create a pipeline with the bag or words features and the linearSVC\n\nclf.fit(X_train, y_train) #Fit the training data to the pipeline\n\ny_pred = clf.predict(X_test) #Make predictions with the test data\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print out the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print out the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification report","bb6ef6d1":"## create a pipeline and fit it with a  Support Vector Classifier\nfrom sklearn.svm import SVC #Import SVC from sklearn \n\nclassifier = SVC(kernel='rbf') #Call the SVC with the kernel='rbf' parameter\n\nclf = Pipeline([('cf', cf), ('clf', classifier)]) #Add the SVC model to the pipeline\n\nclf.fit(X_train, y_train) #Fit the training data\ny_pred = clf.predict(X_test) #Make predictions to the test set and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification","05263562":"#Create a barplot for the train dataset classes\nNews = train['sentiment'].value_counts()[2] #Take values of class 2 and assign the variable 'News'\nPro= train['sentiment'].value_counts()[1]   #Take values of class 1 and assign the variabe 'Pro'\nNeutral=train['sentiment'].value_counts()[0]#Take the values of class 0 and assign the variable 'Neutral'\nAnti=train['sentiment'].value_counts()[-1]  #Take the values of class -1 and assing the variable 'Anti'\n\nsns.barplot(['News ','Pro','Neutral','Anti'],[News,Pro,Neutral,Anti]) #Use seaborn barplot and add a list of classes\nplt.xlabel('Tweet Classification') #X-label of the data\nplt.ylabel('Count of Tweets')      #Y_label of the data\nplt.title('Dataset labels distribution') #Give the data a title 'Dataset lables distribution'\nplt.show() #Display the dataset","b876179a":"#Import the resampling module\nfrom sklearn.utils import resample","807b83ee":"#Downsample and upsample train dataset\ndf_majority = train[train.sentiment==1] #Create a new dataframe of the majority pro class\ndf_minority = train[train.sentiment==0] #Create a new dataframefor the minority neutral class\ndf_minority1 = train[train.sentiment==2] #Create a dataframe for the news class\ndf_minority2 = train[train.sentiment==-1]#Create a dataframe for the anti class\n\n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=5000,     # Using a benchmark of 3640\n                                 random_state=123) # reproducible results\n#Upsampling the least minority class\ndf_minority_up = resample(df_minority, \n                        replace=True,    # sample without replacement\n                        n_samples=5000,     # to match the second majority class\n                        random_state=123) # reproducible results\n\ndf_minority_up1 = resample(df_minority1, \n                        replace=True,    # sample without replacement\n                        n_samples=5000,     # to match the second majority class\n                        random_state=123) # reproducible results\n\ndf_minority_up2 = resample(df_minority2, \n                        replace=True,    # sample without replacement\n                        n_samples=5000,     # to match the second majority class\n                        random_state=123) # reproducible results\n\n# Combine minority class with downsampled majority class\ndf_resampled = pd.concat([df_majority_downsampled,df_minority_up,df_minority_up1, df_minority_up2])\n \n# Display new class counts\ndf_resampled.sentiment.value_counts()\n","1aa89cf8":"X = df_resampled['message']\ny = df_resampled['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","813a3b50":"# create a pipeline and fit it with a Logistic Regression\nfrom sklearn.linear_model import LogisticRegression #Import logistic regression model from sklearn\n\nmodel = LogisticRegression(C=50,multi_class='ovr') #Call logistic regression model and assign variable 'model'\n\nclf_sam = Pipeline([('tfidf', tfidf), ('clf', model)]) #Create a pipeline with the logistic model and tf-idf vectorizer\n\n\nclf_sam.fit(X_train, y_train) #Fit the training set\n\ny_pred= clf_sam.predict(X_test) #Fit the test set\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print f1 score\nprint(classification_report(y_test, y_pred)) #Print classification report","4b55c952":"# create a pipeline and fit it with a Logistic Regression\nfrom sklearn.linear_model import LogisticRegression #Import logistic regression model from sklearn\n\nmodel = LogisticRegression(C=100,multi_class='ovr') #Call logistic regression model and assign variable 'model'\n\nclf_sam1 = Pipeline([('cf', cf), ('clf', model)]) #Create a pipeline with the logistic model and bag-of-words\n\n\nclf_sam1.fit(X_train, y_train) #Fit the training set\n\ny_pred= clf_sam1.predict(X_test) #Fit the test set\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print f1 score\nprint(classification_report(y_test, y_pred)) #Print classification report","4c6555cd":"## create a pipeline and fit it with a Linear Support Vector Classifier\nfrom sklearn.svm import LinearSVC #Import LinearSVC from sklearn \n\nclassifier = LinearSVC() #Call LinearSVC and assign the variable 'classifier'\n\nclf = Pipeline([('tfidf', tfidf), ('clf', classifier)]) #Create a pipeline with the tdidf\n\nclf.fit(X_train, y_train) #Fit the model\ny_pred = clf.predict(X_test) #Make predictions and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1-score\nprint(classification_report(y_test, y_pred)) #Print the classification report","a94a79cb":"#Create a pipeline and make predictions of the bag of words using linearSVC\nfrom sklearn.svm import LinearSVC #Import LinearSVC from the sklearn\n\n\nclf= Pipeline([('cf', cf),('clf',  LinearSVC())]) #Create a pipeline with the bag or words features and the linearSVC\n\nclf.fit(X_train, y_train) #Fit the training data to the pipeline\n\ny_pred = clf.predict(X_test) #Make predictions with the test data\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print out the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print out the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification report","89d3a98d":"## create a pipeline and fit it with a  Support Vector Classifier\nfrom sklearn.svm import SVC #Import SVC from sklearn \n\nclassifier = SVC(kernel='rbf') #Call the SVC with the kernel='rbf' parameter\n\nclf_rbf = Pipeline([('tfidf', tfidf), ('clf', classifier)]) #Add the SVC model to the pipeline\n\nclf_rbf.fit(X_train, y_train) #Fit the training data\ny_pred = clf_rbf.predict(X_test) #Make predictions to the test set and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification","b247497e":"## create a pipeline and fit it with a  Support Vector Classifier\nfrom sklearn.svm import SVC #Import SVC from sklearn \n\nclassifier = SVC(kernel='rbf') #Call the SVC with the kernel='rbf' parameter\n\nclf_rbfc = Pipeline([('cf', cf), ('clf', classifier)]) #Add the SVC model to the pipeline\n\nclf_rbfc.fit(X_train, y_train) #Fit the training data\ny_pred = clf_rbfc.predict(X_test) #Make predictions to the test set and assign the variable 'y_pred'\n\nprint('accuracy %s' % accuracy_score(y_pred, y_test)) #Print the accuracy\nprint('f1_score %s' % metrics.f1_score(y_test,y_pred,average='weighted')) #Print the f1 score\nprint(classification_report(y_test, y_pred)) #Print out the classification","1bd92baf":"test_x = test['message'] #Take test messages and assign variable test_x","b11bafd9":"y_pred = clf_rbf.predict(test_x) #Make rbf predictions and assign to t_pred","1a2cb155":"test['sentiment'] = y_pred #Add preditions to test data by create a new column 'sentiment'","3c6f817f":"test['sentiment'] = test['sentiment'].astype(int) #Change the datatype of the submission","daeb94c1":"test[['tweetid', 'sentiment']].to_csv('model_final.csv', index=False)#Extract twitter ID as sentiments to submit to kaggle","c4768fdc":"Text feature extraction is the process of transforming what is essentially a list of words into a feature set that is usable by a classifier. The NLTK classifiers expect dict style feature sets, so we must therefore transform our text into a dict. ","f72a6255":"The facetgrid indicates the tweet length accross all sentiments are destributed around the 50-150 character length. All sentiments having a vast majority of the tweets being in that 100-150 range, indicating that most tweets are generally about climate change are longer in length. People sharing an experience or their thoughs around climate change","30c1a21d":"## 3.3 Load the dataset","a8a5c7d7":"Emojis are special characters ,ideograms and smileys used in tweets and other electronic messages and web pages. They exist as different genres, expressions as objects. The aim is to decode what emojis exists in our tweets and decode them for their meaning. To decode some of the emoticons used to get them into word format since they do contribute towards the mood of the tweet","cc1448b2":"Resampling of the dataset can be done in one or two ways:\n\n- **Downsampling** - taking a random subset of the majority class small enough to match the number of observations in the minority class.\n\n- **Upsampling** - taking repeated random samples from the minority class until we have as many observations as the  majority class. This grows the size of the minority class by effectively duplicating observations at random.\n\nFor this model, we will do it for both ways","afe1724b":"We will start by creating a User-defined function to remove unwanted text patterns from the tweets. It takes two arguments, one is the original string of text and the other is the pattern of text that we want to remove from the string. The function returns the same input string but without the given pattern. We will use this function to remove the pattern \u2018@user\u2019 from all the tweets in our data.","328c8cc5":"### 6.2.2.2 Non-linear SVC","709d5726":"As predicted, balancing the dataset has lead to a significant improvement in the model. The upsampled dataset is performing way better than the model of the original dataset. However, due to downsampling of the data, we see that the pro class f1 score and recall are significantly lower want the rest of the classes\n\nPro class has a significantly lower f1 score now and recall score\n\nThe balance now makes it easier to make predictions on the other classes and seems to be performing much better in this regards","f0bbf2eb":"## 3.1 Data Requirements","81f44b9f":"# Table of Contents","5abb3182":"There exists shortening of the words in tweets that are shortened by an apostrophe. It is thus important to extract the full extent of those words. Looking for all the shortned words with an apostrophe to replace them with full words so we can avoid words being cut when we remove special characters and words loose their meaning","264df553":"\n*   sentiment: Sentiment of tweet\n*   message: Tweet body\n*   tweetid: Twitter unique id\n","a76fff78":"The training features seem slightly more, but more rounded since we now have a balance dataset. We will now evalue the model perfomance of the dataset","c87b97e3":"## 6.1 Splitting the resampled data","54f33b67":"From this classifier, we can immediately appreciate that the model has a higher precision when it comes to classifing smaller dataset in the imbalance classes, although the data imbalance is cause their respective f1 scores, recall to be signigicantly lower than the news class and the positive class which takes a bigger portion of the dataset. We will investiagte how the performance will improve once we balance the data\n\nThe precision, recall and f1-score values for the positive class are higher, and this has to do with the class imbalance we referred to. There are more observations with the positive label, so the model gets better at classifiying those ones because it has more evidence of them.\n\nThe corresponding values in the neutral and negative class are lower.\n\nThe weighted f1-score here gives us a good indication using a single value of how well the model is performed. It is somewhere between the accuracies that the model achieved for each of class 0 and 1, but slightly in favour of class 1, of which there were more examples.\n","0bf1b8b9":"A boxplot or a box-and-whisket plot is a distribution of qualitative datain a way that facilitates comparisons between variables or across levels of a categorical variable. We will thus create a boxplot for the message lengths of the dataset","86fe6bc8":"## 6. Dealing with class imbalance","06260b4a":"The model for linear SVC seems to be getting a high accuracy and high f1 score, which is good however it still struggles to locate the pro sentiments as good as it does the other models.\n\nPro sentiments are and news sentiments are lower on the precisioin but news seem to have high recall and high f1 rating.\n\nNeutral seems to be consistent accorss all predictions\n\nNegative sentiments seem to be performing very weel, more than all the classes","ee7e3d5e":"As expected, the news is reporting on a vast nature of stories, mostly around the climate, climate change and the environment. Political events like Trump, congress of Parties (COP), Paris Agreements are also covered","e771c9de":"The aim of creating multiple histograms is to display which of the classes is likely to prevail more than the other. The most prevailing color is the red of the positive class. This means we have a majority of tweets which are positive and you can compare it to the frequencies of the other classes. During the smaller message lengths the green negative class is prevailing more than the rest, meaning a lot of negative tweets are short in length. While larger length tweets are more prevailant in the longer tweets, meaning positive tweets are more likely to be longer. ","3efc3be9":"## 3.2 Imports","9dfb5063":"We will now create a frequency distribution of the top 10 hashtags for each of the individual classes to see what each hashtag represent for each class","702ea4d2":"A vast majoity of short words which are less than 3 letters long generatlly do not add much information surrounding the sentiment. Words like 'ohh' and 'lol' do not give us much information, thus important to remove them","23156d10":"## 5.2.2 Bag of words features","3b08e086":"### 4.1.6 Multiple Histograms","e25d7810":"# 4. Explanatory Data Analysis","6bf1aa43":"## 5.1 Splitting the data","ccbf7ffe":"The shape print out indicates that the train dataset has 15819 rows with 3 features, while the shape of the testing data indicates 10546 rows with 2 features. This makes sense. The training data contains our target variable, while the testing data will need a predicted target variable imputed in its dataset","56b62329":"* Negative sentiments have most of their tweets between 114 and 140 with an average 123.7 length size of the tweets\n* Neutral has an interquartile range around the 85 and 139 length, meaning neutral tweets very the most, which is confirmed by the largest standard deviation (std) of 32.36 as compared to the rest of the dataset\n* Positive class has a intequartile range of 123 to 137, meaning most positive tweets are longer in length. The standard deviation is at 19.9, which is one of the shorter ones in the dataset meaning there is less variance\n* News tweets have an interquartile range of 108 to 137 and has the smallest standard deviation of 19","2cc8bb74":"# 7. Analysis of the model","58c0f46a":"### 4.1.2 Barplot","959aa68f":"### 6.1 Resampling of the dataset","b9c3efc9":"Our best model to date so far, with a 90% accuracy and 90% f1-score. The Pro sentiment seems to be perfoming much better under the rbf, unlike the with the linear SVC.\nThe negative sentiments are perfoming the best again, and the model seems to be efficient","e6b52d3e":"The biggest plot represents class 1, being the Positive Sentiment of the dataset which takes up 53.92% of the dataset. Which is a good sign when we evaluate how well our product is being received, or how good a social media campaign is doing on the twitter by different users. We can thus see that from the sample of 15819 tweets, 53.92% of the sample have a positive sentiment towards climate change. Good numbers actually. A vast majority of the tweets are of a positive sentiment. \n8.19% of the tweets represent a negative class, a very small margin. Only a small subset of the data has a negative sentiment towards climate change\n14.87%  of the tweets are neutral tweets. News being the second largest sentiment at 23.01%. This includes a lot of news tweets from news twitter accounts and jounalists\n","b92d0c4d":"### 3.4.4 Emoji look up","cf061cba":"We have a 4th feature called the 'tidy_message' feature which is the preprocessed version of the 'message' feature. Otherwise, the length is still 15819 rows and has 4 columns","4c90aa61":"### 3.4.5 Removing other emojis","8ae952af":"Convert a collection of text documents to a matrix of token counts\nThis implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\nIf you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.","803d37f9":"### Sentiment Description","66ae690e":"Logistic Regression is a common S-shaped curve known as the logistic function. This curve is commonly known as a sigmoid. It solves the problem for the following reasons:\n\n* It squeezes the range of output values to exist only between 0 and 1.\n* It has a point of inflection, which can be used to separate the feature space into two distinct areas (one for each class).\n* It has shallow gradients at both its top and bottom, which can be mapped to zeroes or ones respectively with little ambiguity.\n\nWe will add the parameter 'multi_class'='ovr' due to the class being more than binary, it has 4 classes.","4b778f70":"Bag of words features perfom significantly better at finding the different classes than the tf-idf vectorizer. Even for the positive class which was significantly compromised initially. The rest have significantly improved. \n\nPro class is still lower in terms of f1 score and recall compared to the other classes that are near the 90% mark, which it still falls behind somewhat. We can look to tune the parameters to make it even better","a54b2973":"Now we will use the SVC parameter kernel='rbf'. 'rbf' is a classifier for non-linear data","c963de2d":"### 3.4.3 Apostrophe look up","69fa1aee":"We will now split the data back to training set and test set in order to get the overall sentiment on climate change around the tweets we have in our training data","f753f6f9":"### 5.4.1 Logistic regression","37c5525d":"## 5.2 Feature Extraction","5269ebcf":"In conclusion, we were able to pick up the following:\n* Positive Tweets are generalling longer in length\n* Data classes are imbalanced and need to be resampled\n* Negative sentiments consists of a vast majority of political tweets, mostly aimed at the Trump Make America Great Again campaign\n* Both neutral and news data have high engagement, QandA and links to relevant sites and articles\n* Count Vectorizer and Logistic Regression gave the best predictions in the dataset\n\nThe imbalanced dataset perfomed poorly overall, so balancing and resampling the data works much better. \nWith the resampled data, the non linear SVC with the kernel='rbf' perfomed better accross the board","5757d9ef":"We get our best model so far. It performs around 74% accuracy and 73.37% f1-score. They seem to be very close to each other and not as spread as the other models we have attempted. Due to the class imbalance however, it is still does not perfom well to the minority classes in terms of f1 scores and the scores with the recall.\nWe do however have a better performing model","86ce820b":"### 4.1.5 Boxplot","20751f35":"\nIn order to perform sentiment analysis precisely, we need to clean the original text first. In this section, we will remove usernames start with the sign '@', remove hyperlinks start with http:\/\/ and www, and uncontract the negatives. After the cleaning, we will drop the stopwords and tokenize every tweet to get things ready for the analysis.","09b6dcac":"### 3.4.9 Stemming","89ca0c45":"### 6.2.2 Support Vector Machines","00b92821":"1. Introduction\n2. Problem Statement\n3. Data Preprocessing and Cleaning\n4. Explanatory Data Analysis\n5. Model Building\n6. Conclusion","5cabc99f":"To analyze a preprocessed data, it needs to be converted into features. Depending upon the usage, text features can be constructed using assorted techniques \u2013 Bag-of-Words, TF-IDF vecotoriser. We will thus investigate both feature creation models and select the best model base on merits","f8eedf2b":"### Dealing with Retweets and capitalisation","115e6b0d":"Bag-of-Words is a method to represent text into numerical features. Consider a corpus (a collection of texts) called C of D documents {d1,d2\u2026..dD} and N unique tokens extracted out of the corpus C. The N tokens (words) will form a list, and the size of the bag-of-words matrix M will be given by D X N. Each row in the matrix M contains the frequency of tokens in document D(i).","3b7feb96":"# 5. Model Building with cleaned data","3d40b891":"Now I want to see how well the given sentiments are distributed across the train dataset. One way to accomplish this task is by understanding the common words by plotting wordclouds.\n\nA wordcloud is a visualization wherein the most frequent words appear in large size and the less frequent words appear in smaller sizes.","8701fe77":"A vast majority of the neutrals are discussing, engaging and asking about the effects on climate change as seen with words like 'talk','debate','report'. They are speaking about the penguins which are indangered due to the effects of climate change. They speak about the climate, weather, warm, polar bear. There also appears to be http, which suggests a lot of neutral tweets may have a link to an article\n","8fc3a8ee":"## 6.2 Model building using resampled data","cecaa034":"### 4.2.2.2 Positive hashtags","9ec3ba9c":"From the plot above,it can be observed that the train and test datasets have almost the same length of tweets. We will now investigate the sentiment length.","5b8c35e1":"\nEarth's global surface temperature in 2018 was the fourth warmest since 1880. The global average temperature has increased by +1.1\u00b0C since the pre-industrial period. The global mean sea-level rise has amounted to 5 mm per year Ninety (90) percent of the excess heat caused by climate change is stored in the oceans. More than 90 % of the natural disasters are related to weather\n\nWith this in mind, many companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.","d3e23efc":"It is clear the countvectorizered version of the rbf is not working as ptoficiantly as the TD_IDF vectorized version.\n\nIt seems to be working poorly to the pro sentiments, while the neural and the news f1-scores and precision has significantly been reduced.\n\nWe will now take the SVC with the kernel='rbf' to make our final submission","45810352":"### 4.2.2.4 Negative Hashtags","861468c6":"### 6.2.2.1 Linear Models","eee2fce2":"We find an interesting understanding from this graph. As expected climate is the number one positive key hashtags but what is interesting is number 2, and why Leonardo diCaprio was mentioned on the Wordcloud. Before The Flood is a documentary starring actor Leonardo diCaprio spealing with a lot of activists, scientists and world leaders to discuss climate change and possible solutions. It has clearly had a fantasic response to viewers who have expressed positive feedbank, which proves our assumption that a lot of people need more research and knowledge to believe climate change since seeing is believing. Organisations globally can get involved in similar initiatives which can change the sentiment around climate change. The rest of the positive hashtags come from tweeting about the Conference of Parties (cop) which is a mkeeting by the United nations to discuss climate change.","71c997af":"The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected. Each tweet is labelled as one of the following classes:","bf5aa642":"Short words in terms of twitter data have the ability to extract a lot of meaning from them, seeing that tweeting contains a lot of constraits of round about 280 characters per tweet. People have now been able to shortened particular worlds into letters usually less than or equal to three characters to represent a bigger set of meaning. The aim is to initialise a dictionary or short words to extract the full meaning of these tweets","d2835465":"### 3.4.6 Remove Punctuation, Special Characters and Numbers","768c6b1a":"### 4.2.2.3 Neutral hashtags","450aa690":"The model did not perform well compared to the previous data on all front. It is still perfoming better on majority classes yet perfoming poorly to minority classes. \n\n\nThe precision, recall and f1-score values for the positive class are higher, and this has to do with the class imbalance we referred to. There are more observations with the positive label, so the model gets better at classifiying those ones because it has more evidence of them.\n\nThe corresponding values in the neutral and negative class are lower.\n\nThe weighted f1-score here gives us a good indication using a single value of how well the model is performed. It is somewhere between the accuracies that the model achieved for each of class 0 and 1, but slightly in favour of class 1, of which there were more examples.\n","9b56af59":"This method which is based on the frequency method but it is different to the bag-of-words approach in the sense that it takes into account, not just the occurrence of a word in a single document (or tweet) but in the entire corpus.\n\nTF-IDF works by penalizing the common words by assigning them lower weights while giving importance to words which are rare in the entire corpus but appear in good numbers in few documents.\n\nLet\u2019s have a look at the important terms related to TF-IDF:\n\nTF = (Number of times term t appears in a document)\/(Number of terms in the document)\nIDF = log(N\/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\nTF-IDF = TF*IDF","9c4b8429":"\n\n![image.png](data:image\/png;base64,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)\n\n\n\n","6bd6e8c8":"We would like to know the amount of tweets each class in the dataset contains. We will use the value_counts() on the train dataset on the sentiment column to do this","3fb193a6":"Sentiment of class 1 seems to have the vast majority of the counts, with a total of 8530, with class 2, 0 and -1 having a 9640,2353, and 1296 value count respectively. This indicates that the data of class 1 far outweights that of the rest of the class, with class -1 having a significantly lower value count. This indicates that we may be dealing with class imbalance. Further investigation will support the hypothesis made","98dce6ab":"Support Vector Machines aresimilar to the logistic regression, they fit a linear decision boundary. However, unlike logistic regression, they do this in a non-proabilistic way and are able to fit to non-linear data using an algorithm known as the kernel trick. Furthermore, they can be used for both classification and regression. In sklearn, these are called SVC (Support Vector Classifier) and SVR (Support Vector Regression) respectively.","3c19a41e":"As we can see, the vast majority of the news is reporting about Donald Trump and his views on climate change. They also report a vast majority of issues all included in the analysis of the other words included. US Administrator of Environmental Affairs is appearing regularly as well. There also is an 'http', which shows that news tweets may have a link to a news report. The word cloud is also indicating that the words are well distributed and spoken of almost similarly. Most of the words are not frequently requiring except 'Climate Change', 'Change HTTP', 'Warm HTTP', which are linked to tweets having links, and the main topic being thatn of global warming and climate change","fee99a67":"Stemming is a rule-based process of stripping the suffixes (\u201cing\u201d, \u201cly\u201d, \u201ces\u201d, \u201cs\u201d etc) from a word.The goal is to remove word affixes (particularly suffixes) that modify meaning. For example, For example \u2013 \u201cplay\u201d, \u201cplayer\u201d, \u201cplayed\u201d, \u201cplays\u201d and \u201cplaying\u201d are the different variations of the word \u2013 \u201cplay\u201d.It returns words in their base or root form and results in a slightly lower precision.","73ca78cc":"The wordcloud suggests that most positive sentiments are global warming, climate change, believe climate, change real, tackle and the likes depicted in the wordcloud. A strong call for action, to fight climate change by a vast majority of the tweets and a vast majority of people tweeting to others to plea the reality of climate change. There is also quite a lot of http indicating a lot of links in this class","c0da2278":"It is very important to get the core tweet that exists in the tweets. A Retweet is effectively a sharing of another user's original tweet and starts with the RT with the original tweets in qoutes, and we effectively want to deal with the retweets by removing RT. We will the lower the tweets to lower capitalisation to make the text data easier to work with","0ee07885":"We have created a new balanced dataset with 5000 entries for each of the classes. We will now investigate training on the new balanced dataset","f8560e83":"# 1. Introduction","babe9204":"We need to split the data, into training features and training target variables to fit and train the model. ","2b6d8ef9":"\ntrain.csv (15819 rows) to train the model\n\ntest.csv (10546 rows) to test the model","29999405":"Hashtags in twitter are synonymous with the ongoing trends on twitter at any particular point in time. We should try to check whether these hashtags add any value to our sentiment analysis task, i.e., they help in distinguishing tweets into the different sentiments. The tweet seems positive in nature and the hashtags in the tweet convey the same feeling.","1f807b0d":"We looked at the individual f1-scores and accuracy scores, and the countvectoriser pipeline with the logistic regression far out performs the other models. We will continue using this pipeline when evaluating model imbalaces to get a better prediction. For now, we will use this model in order to make our first submission into the competiton","74080f84":"### 4.1.1 Value Counts","0642b587":"A barplot is a chart that presents the categorical data with rectangular bars with heights and lengths proportional to the valuues that they represent. We will create one for our classes in the dataset","b750e7d0":"# 3. Data Preprocessing and Cleaning ","0666fe6b":"Through displaying the first 5 rows of the test and training data, we can already determine that there exists a lot of characters in the tweets will be deemed useless in the dataset. A further preprocesing of the dataset will get rid of the very common words, punctuation and more that can deem it difficult to train the model","d5e0d627":"# 2. Problem Statement","1e3eacdc":"### 3.4.8 Tokenization","39656977":"## 5.2.1 TF-IDF Features","01472181":"### 5.4.2 Linear Support Vector Classifier","126c7b82":"With regards to punctuation, special characters and numbers, many if not all of them do not change or determine the over all sentiment of a tweet. Thus, it is important to remove these from the tweets","8c13fe2e":"## 4.1 Analysis of sentiments","e38f1e72":"### 3.4.1 Remove Twitter Handles (@user)","d0d4e244":"Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph. Now we will tokenize all the cleaned tweets in our dataset. Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens.","2bf92a3c":"The number one negative sentiment from the nagative tweets comes from the Make America Great Again campaign by US President Donald Trump. Possibly this indicates all the negative sentiments he has against Climate Change.","295371c5":"### 4.1.3 Histogram","4a56d0f9":"### 4.1.4 ViolinPlot","7a1ebbda":"We now have a far more comprehensive view of the performance of our model. Since we fit the model using Logistic Regression, we find that it overfits on imbalance datasets. Overall it performs well on class 1, the positive class, and a lot poorer on the other classes because positive classes are more prevailent in the dataset.\n\n- The precision, recall and f1-score values for the positive class are higher, and this has to do with the class imbalance we referred to. There are more observations with the positive label, so the model gets better at classifiying those ones because it has more evidence of them.\n\n- The corresponding values in the neutral and negative class are lower.\n\n- The weighted f1-score here gives us a good indication using a single value of how well the model is performed. It is somewhere between the accuracies that the model achieved for each of class 0 and 1, but slightly in favour of class 1, of which there were more examples.\n","492df607":"The training data set seems not to have any null values. This allows us to further preprocess the data to generate sufficient features for training the models","e31ade76":"We now have a far more comprehensive view of the performance of our model. Since we fit the model usinglinearSVC, the issue with our imbalanced dataset. It picks up the and trains well for the dataset on the class 1 and class 2, but performs poorly on the class -1 and 0 which have less data prevailing. Overall it performs well on class 1, the positive class, and a lot poorer on the other classes because positive classes are more prevailent in the dataset. We do however see an improvement with the f1 score and recall of the smaller classes, even though it comes at a cost of the precision\n\nThe precision, recall and f1-score values for the positive class are higher, and this has to do with the class imbalance we referred to. There are more observations with the positive label, so the model gets better at classifiying those ones because it has more evidence of them.\n\nThe corresponding values in the neutral and negative class are lower.\n\nThe weighted f1-score here gives us a good indication using a single value of how well the model is performed. It is somewhere between the accuracies that the model achieved for each of class 0 and 1, but slightly in favour of class 1, of which there were more examples.","db6e737c":"## 6.2.1 Logistic Regression","2df76f55":"### 4.2.1.3 Neutrals","cbf4ea72":"## 4.2.2 Hashtags","184a8f41":"If we refer back to this barplot, we can see that the data is not balanced. We will be looking to upscale the minority calsses which is the news class, neutral class and anti class and downsample the big majority class. we will look at different values that work the best to improve the model accurancy and f1-scores","c5bd9074":"### 5.3.1 Logistic Regression","6663f6ae":"Using the value_counts() method we can already see that there lies a strong sentiment in our training set on positive sentiment around the climate change, which will be confirmed in the below diagram, indication that the classes are imbalanced. It may cause issues with the performance of the model. More than 50% of people on twitter, according to twitter are spreading positive news around climate change followed by the news publications. We will further investigate what the positive sentiments are, followed by the news and the negative sentiments","46275640":"Class imbalance exists if the data is not evenly distributed. The model is this difficult to train when there are classes that are vastly smaller than other classes. So we will look to at least have a dataset that is more evently distributed to get better results. This is called the resampling of the dataset","db6cfe5b":"### 4.2.1.4 News","13055d7f":"### 6.2.1.2 Logistic Regression with bag_of_words features","6a7df95e":"### 5.3.2 Linear Support Vector Classifier ","c443aec8":"## 5.3 Models using TF-IDF","d0a79abe":"The model for linear SVC seems to be getting a high accuracy and high f1 score, which is good however it still struggles to locate the pro sentiments as good as it does the other models.\n\nPro sentiments are and news sentiments are lower on the precisioin but news seem to have high recall and high f1 rating.\n\nNeutral seems to be consistent accorss all predictions\n\nNegative sentiments seem to be performing very weel, more than all the classes","aa911763":"### 4.2.1 Word cloud","390b406c":"## 4.2 Analysis of common words used in the tweets","ff045a62":"### 3.4.2 Replacing short words with full length words","f23cf899":"Climate change and climate are again top of the list, but interestingly enough we start to see the emergance of Trump tweets. Which is driving up the neutrals. We also see the Before The Flood series which our COP, which makes sense since neutrals do question a lot initially and finally the #QandA, which shows a lot of neutral sentiments in the data are questions. We do however notice that the count values of each hashtag is significantly lower than the positive hashtags and the new hashtags","ebc750f2":"### 6.2.1.1 Logistic Regression with TF-IDF features","caf3d868":"Compared to the linear SVC, the SVC with the kernel='rbf' has a better accuracy score of 72%, however the f1 score is a lot similar to the previous model\n\nTHis model performs better in locating minority classes as seen with the high precision scores for anti class and the neutral class\n\nF1 scores and recall scores of minority class seemingly low, which might be caused again by the imbalancing of the classes.","599d60f9":"### 3.4.7 Removing short words","a02eed89":"A violinplot is a method of ploting numerical data. It is similar to the boxplot with the addition of a rotated kernel density plot on each side. We will make a violin plot to display the distribution of the length of the tweets for each class in the training set","ea9460e0":"Not all emojis will give us necessary meaning to the sentiment analysis. These include, and not limited to, objects and flag emojis. We will thus look  to remove tweets emojis that are deemed not useful for the sentiment analysis","87c7711a":"\nCreate a model that determines whether or not a person believes in climate change or not based on their tweet","510e0f5a":"In building a model using TF-IDF vectorizer we have to build a pipeline that contains both the feature extractor called in this case the TF_IDF vectorizer and fit it to a model. We will the evaluate the metrics of the data and see what could be the best performing model","f2c89eef":"## 5.4 Models using Bag of words","629e6cde":"We will look to distinguish which classes are minority classes and which are majority classes and then downsample and upsample accoringly to make the classes balance","f5d3c136":"A histogram is an approximate representation of the distribution of the numerical or categorical data. In this intsnace, we will investigate the distribution of the length of the tweets for both the testing data and the training data","e1b7872f":"### 4.2.1.2 Negative Words","9590a210":"### Files Used","6842bd87":"The X_train and y_train both have 12655 values, which is 80% of our data, and the X_test and y_test which represents out test data is being 20% of our data which will give us an indication of our accuracy","2fca372a":"### 4.2.1.1 Positive Words","661466f5":"A vast majority of the key words in the negative sentiments are very political and scientific, which indicates a lot of sentimens said by world leaders on the topic of climate change. Trump, a firm anti climate change individual is appearing very significantly, including the terms scientist, made, fake, alarmist which shows either a lot of people not believing that is real on a hunch or because of a lack of scientific evidence to support the claims. There also a lot of words like scam, money, man-made going on indicating one of the reasons they may not really believe climate change or have negative sentiment against it","8040041a":"## 3.4 Data Preprocessing","0468e02d":"\nTwitter handles are masked as @user due to concerns surrounding privacy. These twitter handles hardly give any information about the nature of the tweet therefore we remove them. ","86cb8f50":"### 4.2.2.1 News","2c4b2b70":"### Variable Definitions"}}