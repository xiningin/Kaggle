{"cell_type":{"0ee254ea":"code","c97d3a44":"code","8cfc59cc":"code","717adf2e":"code","5656691d":"code","532d45a8":"code","7b7db936":"code","491218ca":"code","a25d5907":"code","23875e5e":"code","680984aa":"code","c632368d":"code","0852f4e0":"code","0c470b63":"markdown","7a24f2c0":"markdown"},"source":{"0ee254ea":"import numpy as np\nimport pandas as pd","c97d3a44":"data_train = pd.read_csv('..\/input\/umich-si650-nlp\/train.csv')","8cfc59cc":"data_train.head()","717adf2e":"print(data_train.dtypes)\nprint(data_train.describe())\nprint(data_train.info())","5656691d":"x_tr=data_train['sentence']\ny_tr=data_train['label']\nprint('The shape of train {}'.format(x_tr.shape))","532d45a8":"data_train.label.value_counts()","7b7db936":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()","491218ca":"x_tr = vectorizer.fit_transform(data_train.sentence)\nprint(vectorizer.get_feature_names())","a25d5907":"X_train, X_test, Y_train, Y_test = train_test_split(x_tr,y_tr, test_size = 0.3)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","23875e5e":"X_train, X_test, Y_train, Y_test = train_test_split(x_tr,y_tr, test_size = 0.3)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","680984aa":"from keras.models import Sequential\nfrom keras.layers import Dense,Flatten, Dropout, Activation\nfrom keras.layers.convolutional import Conv1D,MaxPooling1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n\nembedding_dim = 32\nmax_nb_word=200\n\nmodel = Sequential()\nmodel.add(Embedding(max_nb_word, embedding_dim, input_length=1903))\nmodel.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Dropout(0.50))\nmodel.add(Dense(2, activation='sigmoid'))\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.summary()","c632368d":"model.fit(X_train, Y_train, batch_size=128, epochs = 10, validation_data = (X_test,Y_test))","0852f4e0":"test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\nprint(test_acc*100)","0c470b63":"# **CNN**","7a24f2c0":"# **Twitter Sentiment Analysis**"}}