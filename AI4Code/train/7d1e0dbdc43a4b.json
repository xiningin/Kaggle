{"cell_type":{"e8cfab9f":"code","dd32d0c6":"code","399c7917":"code","69570dc0":"code","f34f15ea":"code","48e7599a":"code","ae050c89":"code","1c8a58de":"code","60562aef":"code","fcd0c6d3":"code","a52d29d2":"code","dfea7b17":"code","103a38f6":"code","702aa887":"code","f25c3c43":"code","d1411069":"code","5839fb4f":"code","236c4dd0":"code","ec9c9c40":"code","a50099be":"code","09205367":"code","6e2f8427":"code","d7eefb27":"code","653e8bb7":"code","d505df8f":"code","ca431a17":"code","8f84bd0e":"code","d4491694":"code","9dfe10b7":"code","b7d04dab":"code","ed9ccf85":"code","436417f8":"code","69468ec7":"code","7ae2180a":"markdown","52eb2245":"markdown","b238aeea":"markdown","4668a3be":"markdown","99e5253c":"markdown","b050b192":"markdown","9143d24b":"markdown"},"source":{"e8cfab9f":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dd32d0c6":"import os\nimport string\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision\nfrom torchvision.datasets import CIFAR10\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor, Normalize","399c7917":"print('Current Directory: ', os.getcwd())\nprint('Directories in Parent Directory: ', os.listdir('..\/'))","69570dc0":"input_directory = '..\/input'\nprint('Directories in Input Directory: ', os.listdir(input_directory))","f34f15ea":"asl_directory = '..\/input\/asl-alphabet'\ntrain_directory = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ntest_directory = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'","48e7599a":"class ASLDataset(Dataset):\n    char_to_int = {c: ord(c) - ord('A') for c in string.ascii_uppercase}\n    char_to_int['del'] = 26\n    char_to_int['nothing'] = 27\n    char_to_int['space'] = 28\n    int_to_char = {value: key for key, value in char_to_int.items()}\n        \n    def __init__(self, directory: str, transform=None, label_transform=None):\n        super().__init__()\n        \n        self.directory = directory\n        self.transform = transform\n        self.label_transform = label_transform\n        \n        self.x = None\n        self.y = None\n        self._load_images()\n    \n    def __getitem__(self, idx):\n        x, y = torchvision.io.read_image(self.x[idx]).type(torch.float32), self.y[idx]\n        \n        if self.transform:\n            x = self.transform(x)\n        if self.label_transform:\n            y = self.label_transform(y)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def _load_images(self):\n        self.x = []\n        self.y = []\n        \n        for c in os.listdir(self.directory):\n            class_name = c\n            class_dir = os.path.join(self.directory, class_name)\n            for img in os.listdir(class_dir):\n                self.x.append(os.path.join(class_dir, img))\n                self.y.append(self.char_to_int[class_name])\n                \n        self.y = torch.tensor(self.y, dtype=torch.int64)\n    \n    @staticmethod\n    def get_classname(idx: int) -> str:\n        return ASLDatasetTrain.int_to_char[idx]","ae050c89":"class ASLDatasetTest(Dataset):\n    char_to_int = {c: ord(c) - ord('A') for c in string.ascii_uppercase}\n    char_to_int['del'] = 26\n    char_to_int['nothing'] = 27\n    char_to_int['space'] = 28\n    int_to_char = {value: key for key, value in char_to_int.items()}\n        \n    def __init__(self, directory: str, transform=None, label_transform=None):\n        super().__init__()        \n        self.directory = directory\n        self.transform = transform\n        self.label_transform = label_transform        \n        self.x = None\n        self.y = None\n        self._load_images()\n    \n    def __getitem__(self, idx):\n        x, y = torchvision.io.read_image(self.x[idx]).type(torch.float32), self.y[idx]\n        if self.transform:\n            x = self.transform(x)\n        if self.label_transform:\n            y = self.label_transform(y)\n        return x, y\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def _load_images(self):\n        self.x = []\n        self.y = []\n        for img in os.listdir(self.directory):\n            class_name = img[:1]\n            if 'nothing' in img:\n                class_name = 'nothing'\n            elif 'space' in img:\n                class_name = 'space'\n            elif 'del' in img:\n                class_name = 'del'\n            self.x.append(os.path.join(self.directory, img))\n            self.y.append(self.char_to_int[class_name])\n        self.y = torch.tensor(self.y, dtype=torch.int64)\n    \n    @staticmethod\n    def get_classname(idx: int) -> str:\n        return ASLDatasetTest.int_to_char[idx]","1c8a58de":"ts = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","60562aef":"asl_train = ASLDataset('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train', transform=ts)\nasl_test = ASLDatasetTest('..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test', transform=ts)","fcd0c6d3":"asl_train[0]","a52d29d2":"asl_test[0]","dfea7b17":"train_datasampler = SubsetRandomSampler(np.arange(len(asl_train)))\ntrain_dataloader = DataLoader(asl_train, 32, sampler=train_datasampler)","103a38f6":"test_datasampler = SubsetRandomSampler(np.arange(len(asl_test)))\ntest_dataloader = DataLoader(asl_train, 32, sampler=test_datasampler)","702aa887":"for x_train, y_train in train_dataloader:\n    print(x_train.shape)\n    print(y_train.shape)","f25c3c43":"for x_test, y_test in test_dataloader:\n    print(x_test.shape)\n    print(y_test.shape)","d1411069":"print(torch.cuda.is_available())","5839fb4f":"class AlexNet(nn.Module):\n    def __init__(self, num_classes: int = 1000) -> None:\n        super(AlexNet, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","236c4dd0":"model = AlexNet(29)","ec9c9c40":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","a50099be":"print(len(train_dataloader.dataset))\nprint(len(train_dataloader))","09205367":"epochs = 1\n\nfor e in range(epochs):\n    running_loss = 0.0\n    \n    for i, (imgs, labels) in enumerate(train_dataloader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 64 == 63:\n            print('[Epoch: %d | Step %5d] >>loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 64))\n            running_loss = 0.0","6e2f8427":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss \/= num_batches\n    correct \/= size\n    print(f\"Test Error: \\nAccuracy loss: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","d7eefb27":"test(test_dataloader, model, nn.CrossEntropyLoss())","653e8bb7":"class_correct = list(1. for i in range(29))\nclass_total = list(1. for i in range(29))\n\nwith torch.no_grad():\n    for data in test_dataloader:\n        images, labels = data\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(len(labels)):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(29):\n    print('Accuracy of %5s : %2d %%' % (\n        ASLDataset.int_to_char[i], 100 * class_correct[i] \/ class_total[i]))","d505df8f":"from torchvision import models","ca431a17":"class ResNet(nn.Module):\n    \n    def __init__(self, n=7, res_option='A', use_dropout=False):\n        super(ResNet, self).__init__()\n        self.res_option = res_option\n        self.use_dropout = use_dropout\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.norm1 = nn.BatchNorm2d(16)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.layers1 = self._make_layer(n, 16, 16, 1)\n        self.layers2 = self._make_layer(n, 32, 16, 2)\n        self.layers3 = self._make_layer(n, 64, 32, 2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.linear = nn.Linear(64, 10)\n    \n    def _make_layer(self, layer_count, channels, channels_in, stride):\n        return nn.Sequential(\n            ResBlock(channels, channels_in, stride, res_option=self.res_option, use_dropout=self.use_dropout),\n            *[ResBlock(channels) for _ in range(layer_count-1)])\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.norm1(out)\n        out = self.relu1(out)\n        out = self.layers1(out)\n        out = self.layers2(out)\n        out = self.layers3(out)\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\nclass ResBlock(nn.Module):\n    \n    def __init__(self, num_filters, channels_in=None, stride=1, res_option='A', use_dropout=False):\n        super(ResBlock, self).__init__()\n        \n        # uses 1x1 convolutions for downsampling\n        if not channels_in or channels_in == num_filters:\n            channels_in = num_filters\n            self.projection = None\n        else:\n            if res_option == 'A':\n                self.projection = IdentityPadding(num_filters, channels_in, stride)\n            elif res_option == 'B':\n                self.projection = ConvProjection(num_filters, channels_in, stride)\n            elif res_option == 'C':\n                self.projection = AvgPoolPadding(num_filters, channels_in, stride)\n        self.use_dropout = use_dropout\n\n        self.conv1 = nn.Conv2d(channels_in, num_filters, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(num_filters)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(num_filters)\n        if self.use_dropout:\n            self.dropout = nn.Dropout(inplace=True)\n        self.relu2 = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.use_dropout:\n            out = self.dropout(out)\n        if self.projection:\n            residual = self.projection(x)\n        out += residual\n        out = self.relu2(out)\n        return out\nclass IdentityPadding(nn.Module):\n    def __init__(self, num_filters, channels_in, stride):\n        super(IdentityPadding, self).__init__()\n        # with kernel_size=1, max pooling is equivalent to identity mapping with stride\n        self.identity = nn.MaxPool2d(1, stride=stride)\n        self.num_zeros = num_filters - channels_in\n    \n    def forward(self, x):\n        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n        out = self.identity(out)\n        return out\n\nclass ConvProjection(nn.Module):\n\n    def __init__(self, num_filters, channels_in, stride):\n        super(ResA, self).__init__()\n        self.conv = nn.Conv2d(channels_in, num_filters, kernel_size=1, stride=stride)\n    \n    def forward(self, x):\n        out = self.conv(x)\n        return out\nclass AvgPoolPadding(nn.Module):\n\n    def __init__(self, num_filters, channels_in, stride):\n        super(AvgPoolPadding, self).__init__()\n        self.identity = nn.AvgPool2d(stride, stride=stride)\n        self.num_zeros = num_filters - channels_in\n    \n    def forward(self, x):\n        out = F.pad(x, (0, 0, 0, 0, 0, self.num_zeros))\n        out = self.identity(out)\n        return out","8f84bd0e":"model = models.resnet152()","d4491694":"print(model)","9dfe10b7":"\nnew_fc = torch.nn.Sequential(\n    nn.Linear(in_features=2048, out_features=1000, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=1000, out_features=29, bias=True),\n)","b7d04dab":"model.fc = new_fc","ed9ccf85":"print(model)","436417f8":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","69468ec7":"epochs = 1\n\nfor e in range(epochs):\n    running_loss = 0.0\n    for i, (imgs, labels) in enumerate(train_dataloader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 64 == 63:\n            print('[Epoch: %d | Step %5d] >>loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 64))\n            running_loss = 0.0","7ae2180a":"# **Importing All Libaries**","52eb2245":"# **Define Resnet Model**","b238aeea":"# **GPU Available or Not**","4668a3be":"# **Session Start**","99e5253c":"# **Implement Resnet Model**","b050b192":"#  **PyTorch DataLoader**","9143d24b":"# **Define Alexnet Model**"}}