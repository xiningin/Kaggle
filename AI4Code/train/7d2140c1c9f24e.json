{"cell_type":{"13b57758":"code","c59908cc":"code","45861ce6":"code","f89e3057":"code","3ef772cc":"code","fb80bf9b":"markdown","e4ff314d":"markdown","8607f496":"markdown","3622c62c":"markdown","da5c5770":"markdown"},"source":{"13b57758":"pip install selenium","c59908cc":"import requests\nfrom bs4 import BeautifulSoup\nfrom lxml import etree\nfrom selenium import webdriver\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom lxml import html\nfrom multiprocessing import Process","45861ce6":"def get(ano,pg):\n    pg1=pd.DataFrame()\n    for x in range(len(pg)):\n        city=pg[\"Cidade\"]\n        city=city.__getitem__(x)\n        uf=pg[\"UF\"]\n        uf=uf.__getitem__(x)\n        resq=requests.get(f\"https:\/\/www.feriados.com.br\/feriados-{city}-{uf}.php?ano={ano}\")\n        soup = BeautifulSoup(resq.content, 'html.parser')\n\n        tree =soup.find_all('span',attrs={'class':\"style_lista_feriados\"})\n\n        for x in tree:\n            f=x.get_text()\n            df = pd.DataFrame({\"Cidade\": city, \"UF\": uf, \"feriados\": f}, index=[0])\n            if pg1.empty == True:\n                pg1 = pd.concat([df]).reset_index(drop=True)\n            else:\n                pg1 = pd.concat([df, pg1]).reset_index(drop=True)\n\n        print(pg1)\n    return pg1.to_csv(f\"Feriados de todos os municipios {ano}.csv\",sep=\";\", index=False, encoding='latin-1', mode=\"w\",decimal=',')\n","f89e3057":"\ndef BotCreation():\n    options = Options()\n    options.add_argument('--headless')\n    options.add_argument('--disable-gpu')\n    \"Bem eu n\u00e3o sei como faz para rodar o Web river no Notebook, mas basicamente essa parte voc\u00ea\n    \"coloca a pasta que est\u00e1 o exe do web driver.\n    \n    \n    \"basicamente ele vai abrir uma instancia do google chrome, vai se direcionar ao site e fazer \n    \"o scraping de todas as cidades por estado\n    \"eu tentei fazer com requests mas n\u00e3o consegui, ent\u00e3o usei o selenium\"\n    driver = webdriver.Chrome(chrome_options=options,\n                              executable_path='chromedriver.exe')\n    driver.get(\"https:\/\/www.feriados.com.br\/feriados-estado-al.php?ano=2021\")\n    \"Pega informa\u00e7\u00f5es da cidade por estado\"\n\n    estados = ['RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO', 'MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA', 'MG',\n               'ES', 'RJ', 'SP', 'PR', 'SC', 'RS', 'MS', 'MT', 'GO', 'DF']\n    pg = pd.DataFrame()\n\n    for x in estados:\n\n        lista = []\n        df = pd.DataFrame()\n        driver.get(f\"https:\/\/www.feriados.com.br\/feriados-estado-{x}.php?ano=2021\")\n        u = driver.find_element_by_xpath(\n            '\/html\/body\/div[3]\/div[1]\/div[3]\/div[4]\/table\/tbody\/tr[3]\/td\/div[1]\/form\/select[2]')\n        u = u.text\n        cidades = u.replace(\"\\n\", \",\")\n        cidades = cidades.split(\",\")\n        lista.extend(cidades)\n        lista.pop(0)\n        lista = pd.Series(lista)\n        df['Cidade'] = lista\n        df['UF'] = x\n        if pg.empty == True:\n            pg = pd.concat([df]).reset_index(drop=True)\n        else:\n            pg = pd.concat([df, pg]).reset_index(drop=True)\n\n    print(\"Cidades OK\")\n    pg = pg.sort_values(by=[\"UF\"]).reset_index(drop=True)\n    print(pg)\n    \"Pronto j\u00e1 temos todas as informa\u00e7\u00f5es das cidades por estado\"\n    \n    #Aqui voc\u00ea define o ano inicial que voc\u00ea quer\n    ano = 2021\n    y = 0\n    h=pd.DataFrame()\n    #Aqui voc\u00ea define o ano final que voc\u00ea quer\n    while ano <=2021:\n        y = y + 1\n        \"Basicamente ele vai criar um processo com cada ano que voc\u00ea precisa\"\n        if __name__ == '__main__':\n            globals()[f\"Bot {y}\"] = Process(target=get, args=(ano,pg,))\n            print(f\"rbo criado n\u00ba {y}\")\n            \n        new_row={\"Bot Name\":f\"Bot{y}\"}\n\n        h=h.append(new_row,ignore_index=True)\n        ano=ano+1\n\n    \"E retorna um datafram com o nome da vari\u00e1vel criada\"\n    return h\n\n\ndef BotInicializador(bots:pd.DataFrame):\n    bots=bots\n    k=bots[\"Bot Name\"]\n\n    for y in k:\n        print(y)\n        if __name__ == '__main__':\n            globals()[y].start()\n            print(f\"robo {y} inicializado\")\n\n    for y in k:\n        if __name__ == '__main__':\n            globals()[y].join()\n            print(\"Finish\")\n\nhi=BotCreation()\nBotInicializador(hi)\n\n\n","3ef772cc":"options = Options()\noptions.add_argument('--headless')\noptions.add_argument('--disable-gpu')  \ndriver = webdriver.Chrome(chrome_options=options,\n                          executable_path='chromedriver.exe')\n\ndriver.get(\"https:\/\/www.feriados.com.br\/feriados-estado-al.php?ano=2021\")\n\"Pega informa\u00e7\u00f5es da cidade por estado\"\n\nestados = ['RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO', 'MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA', 'MG',\n           'ES', 'RJ', 'SP', 'PR', 'SC', 'RS', 'MS', 'MT', 'GO', 'DF']\npg = pd.DataFrame()\n\nfor x in estados:\n\n    lista = []\n    df = pd.DataFrame()\n    driver.get(f\"https:\/\/www.feriados.com.br\/feriados-estado-{x}.php?ano=2021\")\n    u = driver.find_element_by_xpath(\n        '\/html\/body\/div[3]\/div[1]\/div[3]\/div[4]\/table\/tbody\/tr[3]\/td\/div[1]\/form\/select[2]')\n    u = u.text\n    cidades = u.replace(\"\\n\", \",\")\n    cidades = cidades.split(\",\")\n    lista.extend(cidades)\n    lista.pop(0)\n    lista = pd.Series(lista)\n    df['Cidade'] = lista\n    df['UF'] = x\n    if pg.empty == True:\n        pg = pd.concat([df]).reset_index(drop=True)\n    else:\n        pg = pd.concat([df, pg]).reset_index(drop=True)\n\nprint(\"Cidades OK\")\npg = pg.sort_values(by=[\"UF\"]).reset_index(drop=True)\nprint(pg)\n\n\"Aqui voc\u00ea coloca o ano inicial\"\nano=2021\n\"Aqui voc\u00ea coloca o ano final\"\nwhile ano<=2021:\n    get(ano,pg)\n    ano=ano+1","fb80bf9b":"# Forma numero n\u00ba2 \n\n### Essa forma \u00e9 ideal se voc\u00ea for fazer scraping com 1 ano. Mas ela funciona para fazer com mais de um ano tamb\u00e9m, por\u00e9m demora um pouco mais","e4ff314d":"# Escolha como voc\u00ea deseja fazer\n\n## Bem voc\u00ea pode fazer esse scraping de duas formas:\n\n## -Forma r\u00e1pida por\u00e9m exige mais hardware;\n\n## -Forma lenta por\u00e9m n\u00e3o exige tanto hardware;\n\n\n#### OBS: Ambas formas n\u00e3o v\u00e3o rodar no notebook por causa que precisa do web driver para pegar informa\u00e7\u00f5es das cidades...","8607f496":"# Fun\u00e7\u00e3o que faz o scraping:\n\n### Primeiro passo \u00e9 fazer a fun\u00e7\u00e3o que faz o scraping da pagina, ela pode ser utilizada tanto na primeira forma quanto na segunda. ","3622c62c":"# Forma numero n\u00ba1 (trabalhando com Multiprocessing)\n\n### Essa forma \u00e9 ideal se voc\u00ea for fazer scraping com mais de 1 ano. ","da5c5770":"# Fa\u00e7a a instala\u00e7\u00e3o das bibliotecas e depos importa para o c\u00f3digo\n\n### Neste notebook \u00e9 necess\u00e1rio instalar somente a biblioteca selenium, se voc\u00ea rodar do IDLE voc\u00ea precisar\u00e1 instalar as seguintes bibliotecas:\n\n### -Pandas;\n\n### -Selenium;\n\n### -BeautifulSoup;\n\n"}}