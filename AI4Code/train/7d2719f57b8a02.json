{"cell_type":{"6485e3bd":"code","a2b40cf4":"code","63e637e5":"code","a6777d10":"code","5186aac6":"code","8a753e67":"code","3fcf9a6b":"code","04af1925":"code","8a8ff42f":"code","fb6a4ad6":"code","b17f58e7":"code","1243c043":"code","a05b3640":"code","19ebf63f":"code","111f4bd9":"code","1d49eb68":"markdown","5c7a9e7f":"markdown","29bd813a":"markdown","1d32b81a":"markdown","5a336a3d":"markdown","b781060b":"markdown","78353aa4":"markdown","e4dcac2a":"markdown","b3d3ba36":"markdown","725eeb28":"markdown"},"source":{"6485e3bd":"!pip install pdpipe","a2b40cf4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\nimport pdpipe as pdp\nfrom typing import Tuple, List, Dict\nimport glob\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline\n\nimport category_encoders as ce","63e637e5":"# read data\nin_kaggle = True\n\n\ndef get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n    train_path = ''\n    test_path = ''\n    sample_submission_path = ''\n\n    if is_in_kaggle:\n        # running in Kaggle, inside the competition\n        districts_info_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv'\n        products_info_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv'\n        engagements_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/'\n    else:\n        # running locally\n        districts_info_path = 'data\/districts_info.csv'\n        products_info_path = 'data\/products_info.csv'\n        engagements_path = 'data\/engagement_data'\n\n    return districts_info_path, products_info_path, engagements_path\n\n# set the size of the geo bubble\ndef set_size(value):\n    '''\n    Takes the numeric value of a parameter to visualize on a map (Plotly Geo-Scatter plot)\n    Returns a number to indicate the size of a bubble for a country which numeric attribute value \n    was supplied as an input\n    '''\n    result = np.log(1+value\/100)\n    if result < 0:\n        result = 0.001\n    return result","a6777d10":"districts_info_path, products_info_path, engagements_path = get_data_file_path(in_kaggle)","5186aac6":"districts_df = pd.read_csv(districts_info_path)\ndistricts_df.head()","8a753e67":"products_df = pd.read_csv(products_info_path)\nproducts_df.rename(columns = {'LP ID': 'lp_id'}, inplace = True)\nproducts_df.head()","3fcf9a6b":"# read engagement data files\nall_engagement_files = glob.glob(engagements_path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_engagement_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    # add district_id from the data file name\n    \n    df[\"district_id\"] = filename.replace(\"\\\\\", \"\/\").split(\"\/\")[-1].split(\".\")[0]\n    li.append(df)\n\nengagements_df = pd.concat(li, axis=0, ignore_index=True)\n\nengagements_df.head()","04af1925":"# missing data: engagements_df\n\ntotal = engagements_df.isnull().sum().sort_values(ascending=False)\npercent = (engagements_df.isnull().sum()\/engagements_df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","8a8ff42f":"engagements_df = engagements_df.drop(engagements_df.loc[engagements_df['lp_id'].isnull()].index)\nengagements_df = engagements_df.fillna(0.0)","fb6a4ad6":"# cast lp_id and district_id to int, to enable merging with the products and districts info down the road\nengagements_df[\"lp_id\"] = engagements_df[\"lp_id\"].astype(int)\nengagements_df[\"district_id\"] = engagements_df[\"district_id\"].astype(int)\n#engagements_df[\"time\"] = pd.to_datetime(engagements_df[\"time\"])\nengagements_df.tail()","b17f58e7":"# merge districts and products\nresult_df = pd.merge(engagements_df, districts_df, on=\"district_id\")\nresult_df = pd.merge(result_df, products_df, on=\"lp_id\")","1243c043":"result_df.head()","a05b3640":"agg_digi_learn_df = result_df[result_df[\"Primary Essential Function\"] == 'LC - Digital Learning Platforms']\nagg_engagement_data = agg_digi_learn_df.groupby([\"state\", \"time\"],as_index=False)[\"engagement_index\"].sum().reset_index()\nagg_engagement_data.head(10)","19ebf63f":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\npipeline = pdp.PdPipeline([\n    pdp.ApplyByCols('engagement_index', set_size, 'size', drop=False),\n    pdp.MapColVals('state', us_state_abbrev)\n])\n\nagg_engagement_data = pipeline.apply(agg_engagement_data)\n\nagg_engagement_data.fillna(0, inplace=True)\n\nagg_engagement_data = agg_engagement_data.sort_values(by='time', ascending=True)\nagg_engagement_data.tail()","111f4bd9":"fig = px.scatter_geo(\n    agg_engagement_data, locations=\"state\", locationmode='USA-states',\n    scope=\"usa\",\n    color=\"engagement_index\", \n    size='size', hover_name=\"state\", \n    range_color= [0, 100000], \n    projection=\"albers usa\", animation_frame=\"time\", \n    title='Engagement Index: LC - Digital Learning Platforms', \n    color_continuous_scale=\"portland\")\n\nfig.show()","1d49eb68":"The important notes about the data are listed below\n\n- the observations for engagement are provided for the period of time from Jan 1, 2020 through Dec 31, 2021 inclusive\n- only a fraction of the US states is represented in the dataset provided for this project (it is assumed to be the concious decision of the contest organizers)","5c7a9e7f":"After handling missing data, we will cast a couple of columns in the unified engagements dataframe (*lp_id*, *district_id*) to int. It will be helpful down the road as we are going to merge engagements data with district and product information.\n\n**Note:** We do not convert *time* attribute to *datetime* yet as its string representation will be useful in building the animated geoscatter plots (see below).","29bd813a":"We are going to read districsts data first. For the purpose of the current analysis, we are not going to preprocess this data file any further.","1d32b81a":"Now we are ready to unlock the power of visualization with the animanted geo scatter plot","5a336a3d":"As we can see, there is a tiny fraction of the engagement records without *lp_id* recorded. We will have to drop such obervations since there is no way to map them to any software product listed in products_df.\n\nFor *pct_access* and *engagement_index*, we can interprete 'NaN' values as 0.00, based on the definition of the respective attributes.\n\n**Note:** Just for the convenience reasons, below is the refresher on how *pct_access* and *engagement_index* are defined across this project\n\n- *pct_access* - Percentage of students in the district have at least one page-load event of a given product and on a given day\n- *engagement_index* - Total page-load events per one thousand students of a given product and on a given day\n","b781060b":"# Digital Learning Platform Patterns\n\nWe are going to focus on how Covid-19 and correlated lockdown actions impacted the use of *Digital Learning Platforms* across the selective school districts represented in the datasets for this project.\n\n## Let's Engage Despite the Covid-19!\n\nAs a first step, we will create a separate dataframe where we filter the data for *Digital Learning Platforms* only. After it, we will aggregate the data by observation date (*time* attribute) and the US state (*state*) attribute.","78353aa4":"Now we are going to read the data about e-learning software products. As a part of it, we will have to rename one of the columns in this data set (from *'LP ID'* to *'lp_id'*) for ease of merging with other datasets needed in this analysis, down the road.\n\nFor the purpose of the current analysis, we are not going to preprocess this data file any further.","e4dcac2a":"As a final step, we are ready to combine engagement, district, and product information into a single dataframe. Such a dataframe will then be used as a foundation for futher analytical and EDA activities.","b3d3ba36":"# Reading and Pre-Processing the Data","725eeb28":"Finally, we embark on loading the engagement data. We will combine the individual school district charts into a single dataframe on the fly as well as add a new feature (*district_id*) to the combined dataframe with the engagement data."}}