{"cell_type":{"947f2460":"code","8a660187":"code","692a87ca":"code","93d7d01e":"code","5ca5e000":"code","7c7872be":"code","66dd27f9":"code","5bf9e526":"code","d28caaad":"code","47acd21b":"code","f49777e0":"code","c1af7f1b":"code","c1cdff1d":"code","5355e379":"code","13202afe":"code","389ac868":"code","8b886efc":"code","d880c941":"code","34fdc270":"code","f175b000":"markdown","4ddc3469":"markdown","f08f25e0":"markdown","560d1477":"markdown","4f2d789a":"markdown","31261ddf":"markdown","1bb44a58":"markdown"},"source":{"947f2460":"import numpy as np \nimport pandas as pd \n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport os\nimport pickle\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\n\nfrom tqdm.notebook import tqdm_notebook","8a660187":"SEED = 1234\ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(SEED)","692a87ca":"class ImagePandasDataset(Dataset):\n    def __init__(self, pd_dataframe, img_name_column, img_dir, target_column=None, transform=None):\n        self.pd_dataframe = pd_dataframe\n        self.img_name_column = img_name_column\n        self.img_dir = img_dir\n        self.target_column = target_column\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.pd_dataframe)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.pd_dataframe[self.img_name_column].iloc[idx])\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n            \n        if not self.target_column:\n            return image\n        \n        target = self.pd_dataframe[self.target_column].iloc[idx]\/100.\n        return image, target        ","93d7d01e":"train_images_path = '..\/input\/petfinder-pawpularity-score\/train\/'\ntest_images_path = '..\/input\/petfinder-pawpularity-score\/test\/'\n\ntrain_pd = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest_pd = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n\ntrain_pd.Id = [image_name + '.jpg' for image_name in train_pd.Id]\ntest_pd.Id = [image_name + '.jpg' for image_name in test_pd.Id]\n\n\nimg_transforms_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((300, 300)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntest_ds = ImagePandasDataset(test_pd, 'Id', img_dir=test_images_path, transform=img_transforms_test)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False)","5ca5e000":"train_pd.head(10)","7c7872be":"train_pd.info()","66dd27f9":"sns.heatmap(train_pd.corr(), \n        xticklabels=train_pd.columns[1:],\n        yticklabels=train_pd.columns[1:])","5bf9e526":"sns.histplot(train_pd.Pawpularity)","d28caaad":"most_pawpular = list(train_pd[train_pd.Pawpularity == 100].Id)\nless_pawpular = list(train_pd[train_pd.Pawpularity < 10].Id)","47acd21b":"fig, axes = plt.subplots(2, 9, figsize=(20, 10))\nfig.suptitle('Most pawpular', fontsize=20)\nfor ax in axes.flat:\n    ax.set_yticks([])\n    ax.set_xticks([])\nfor i in range(18):\n  axes[i\/\/9, i%9].imshow(plt.imread(train_images_path + most_pawpular[i]))","f49777e0":"fig, axes = plt.subplots(2, 9, figsize=(20, 10))\nfig.suptitle('Less pawpular', fontsize=20)\nfor ax in axes.flat:\n    ax.set_yticks([])\n    ax.set_xticks([])\nfor i in range(18):\n  axes[i\/\/9, i%9].imshow(plt.imread(train_images_path + less_pawpular[i]))","c1af7f1b":"WEIGHTS_PATH = '..\/input\/pretrained-model-weights-pytorch\/'\n\nVGG_19_bn_PATH = WEIGHTS_PATH + 'vgg19_bn-c79401a0.pth'\nVGG_19_bn = torchvision.models.vgg19_bn\n\nInception_v3_PATH = WEIGHTS_PATH + 'inception_v3_google-1a9a5a14.pth'\nInception_v3 = torchvision.models.Inception3\n\nResnet152_PATH = WEIGHTS_PATH + 'resnet152-b121ed2d.pth'\nResnet152 = torchvision.models.resnet152","c1cdff1d":"def init_pretrained_model(path, model):\n    pretrained_model = model()\n    pretrained_model.aux_logits = False\n    pretrained_model.aux1 = None \n    pretrained_model.aux2 = None\n    pretrained_model.load_state_dict(torch.load(path))\n    pretrained_model.eval()\n    \n    for param in pretrained_model.parameters():\n        param.requires_grad = False\n    return pretrained_model\n\nclass Model(nn.Module):\n  def __init__(self, model_path, pretrained_model):\n    super().__init__()\n    \n    self.pretrained_model = init_pretrained_model(model_path, pretrained_model)\n   \n    self.linear_tail = nn.Sequential(\n        nn.BatchNorm1d(1000),\n        nn.Dropout(0.3),\n        nn.Linear(in_features=1000, out_features=512),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(512),\n        nn.Dropout(0.3),\n        nn.Linear(in_features=512, out_features=256),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(256),\n        nn.Linear(in_features=256, out_features=128),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(128),\n        nn.Linear(in_features=128, out_features=64),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(64),\n        nn.Linear(in_features=64, out_features=32),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(32),\n        nn.Linear(in_features=32, out_features=16),\n        nn.ReLU(),\n        \n        nn.BatchNorm1d(16),\n        nn.Linear(in_features=16, out_features=1),\n        nn.Sigmoid()\n        )\n \n  def forward(self, image):\n    cnn_results = self.pretrained_model(image)\n    return self.linear_tail(cnn_results)","5355e379":"PRETRAINED_MODELS_PATH = '..\/input\/pawpularity-preatrained-models\/'\n\n\nvgg_model = Model(VGG_19_bn_PATH, VGG_19_bn).cuda()\nvgg_model.load_state_dict(torch.load(PRETRAINED_MODELS_PATH + 'pawpularity_vgg19_bn_weights.pt'))\n\ninception_model = Model(Inception_v3_PATH, Inception_v3).cuda()\ninception_model.load_state_dict(torch.load(PRETRAINED_MODELS_PATH + 'pawpularity_inception_v3_weights.pt'))\n\nresnet_model = Model(Resnet152_PATH, Resnet152).cuda()\nresnet_model.load_state_dict(torch.load(PRETRAINED_MODELS_PATH + 'pawpularity_resnet152_weights.pt'))\n\nmodels = [vgg_model, inception_model, resnet_model]\n\n\ninception_orig = init_pretrained_model(Inception_v3_PATH, Inception_v3).cuda()\nresnet_orig = init_pretrained_model(Resnet152_PATH, Resnet152).cuda()\n\n\nlightgbm_inceptionv3 = pickle.load(open(PRETRAINED_MODELS_PATH + 'lightgbm_inceptionv3.pickle', 'rb'))\nlightgbm_resnet152 = pickle.load(open(PRETRAINED_MODELS_PATH + 'lightgbm_resnet152.pickle', 'rb'))\n\nxgboost_inceptionv3 = xgb.Booster()\nxgboost_inceptionv3.load_model(PRETRAINED_MODELS_PATH + 'xgboost_inceptionv3.json')\nxgboost_resnet152 = xgb.Booster()\nxgboost_resnet152.load_model(PRETRAINED_MODELS_PATH + 'xgboost_resnet152.json')","13202afe":"BATCH_SIZE = 128\ntest_ds = ImagePandasDataset(test_pd, img_name_column='Id', img_dir=test_images_path, transform=img_transforms_test)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)","389ac868":"nn_preds = [[], [], []]\n\ndata_after_resnet = np.zeros((len(test_ds), 1000))\ndata_after_inception = np.zeros((len(test_ds), 1000))\n\nn = 0\n\nfor image in tqdm_notebook(test_loader):\n    image = image.cuda()\n    # make new data from pretrained original models\n    data_after_resnet[n: n+BATCH_SIZE] = resnet_orig(image).cpu().numpy()\n    data_after_inception[n: n+BATCH_SIZE] = inception_orig(image).cpu().numpy()\n    \n    # get results from new models\n    for model_num, model in enumerate(models):\n        model.eval()\n        nn_preds[model_num] += [el.item() for el in model(image)]\n        \n    n += BATCH_SIZE","8b886efc":"# get results from new data with boosting models\nlgb_incp_pred = lightgbm_inceptionv3.predict(data_after_inception)\nlgb_rsnt_pred = lightgbm_resnet152.predict(data_after_resnet)\nxgb_incp_pred = xgboost_inceptionv3.predict(xgb.DMatrix(data_after_inception))\nxgb_rsnt_pred = xgboost_resnet152.predict(xgb.DMatrix(data_after_resnet))","d880c941":"mean_boost_preds = (lgb_incp_pred + lgb_rsnt_pred + xgb_incp_pred + xgb_rsnt_pred)\/4\nmean_nn_preds = np.array(nn_preds).mean(0)\nmean_preds = (mean_boost_preds + mean_nn_preds)\/2","34fdc270":"sample_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\nsample_df['Pawpularity'] = 100 * mean_preds\nsample_df.to_csv('submission.csv', index=False)","f175b000":"Numerical features were useless for training so further only images are used","4ddc3469":"# Test","f08f25e0":"# Models","560d1477":"# Train data overview","4f2d789a":"# Imports","31261ddf":"# Data","1bb44a58":"# Set random seed"}}