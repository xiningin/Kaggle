{"cell_type":{"8ce7144d":"code","ec0233cf":"code","4e64a5a4":"code","5cf6e957":"code","c576825b":"code","39505b95":"code","e18d6c78":"code","42e4cdbf":"code","73cb59dd":"code","fb06b46f":"code","2a410215":"code","e2d2f4fa":"code","c04e805a":"code","464617a9":"code","ee8214f6":"code","ab30cda3":"code","0e391db9":"code","9b0c7c78":"code","a109c641":"code","399e9af9":"code","d6191229":"code","a1dae85b":"code","6d7601c7":"code","50d85a95":"code","705ed1e6":"code","39d8f15f":"code","6fe7e9dc":"code","3a162ba9":"code","a3a80c26":"code","183bc364":"code","50b4e947":"code","da75326e":"code","e6be2173":"code","9e31f0ea":"code","e7d69bbf":"code","4ad72e36":"code","b6fad3e6":"code","ba92ab4d":"code","855e717d":"code","234516ac":"code","883e2f24":"code","1a3a10c9":"code","409dae16":"markdown","959e453d":"markdown","225ef6fa":"markdown"},"source":{"8ce7144d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ec0233cf":"import plotly.express as px\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport wordcloud \nimport collections\nimport pandas as pd","4e64a5a4":"train_data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","5cf6e957":"# Observe the meaning of each label in the data\ntrain_data.columns.values","c576825b":"#Check the data base\ntrain_data.info()\n#(Cabin)The cabin number information contains a large number of null values, which are not very helpful for analysis and prediction","39505b95":"train_data.describe(include=['O'])\n#Discover that the name in the dataset is unique\n#There were 577 male passengers\n#The number of people under S boarding port is the largest, 644","e18d6c78":"#Observe the first five data and further screen the meaningless labels\ntrain_data.head(5)\n#PassengerId can be found to have no real meaning and should be excluded in the analysis","42e4cdbf":"#Here we can use word clouds to perform a statistical rendering of passenger names\nname_str_file=''\nfor i in range(len(train_data)):\n    name_str_file+=train_data[train_data.index==i]['Name'].tolist()[0]\n    \n#Remove words that have no real meaning\nSTOPWORDS=['Mr','Miss','Mrs','Dr','Master']\nwc = wordcloud.WordCloud(stopwords=STOPWORDS, width=800, height=600, mode='RGBA', background_color=None).generate(name_str_file)\n\nplt.figure(figsize=(12,8))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","73cb59dd":"name_str_file=name_str_file.split(' ')\nfor i in name_str_file:\n    if i in ['Mr.','Mrs.','Miss.','Dr.','Master.']:\n        name_str_file.remove(i)\n#We can find that the following characters appear more frequently, and then analyze the death rate of each name\nc=collections.Counter(name_str_file)\nname_list=[]\nfor i in range(10):\n    name_list.append(c.most_common(10)[i][0])\n#most common name\nname_list","fb06b46f":"#Calculate the death rate for each name\nname_list=set(name_list)\ntop_name_dataframe=pd.DataFrame()\nfor i in range(len(train_data)):\n    name_str=train_data[train_data.index==i]['Name'].values[0]\n    name_str_copy=set(name_str.split(' '))\n    if name_str_copy&name_list!=set():\n        passage=train_data[train_data['Name']==name_str]\n        passage['Name']=list(name_str_copy&name_list)[0]\n        top_name_dataframe=pd.concat([top_name_dataframe,passage])","2a410215":"top_name_dataframe[['Name', 'Survived']].groupby(['Name'], as_index=False).mean().sort_values(by='Survived', ascending=False)","e2d2f4fa":"c.most_common(10)\n#By comparison, passengers with 'Johan' in their names had the lowest survival rate of just 13 percent","c04e805a":"#It can be seen from the above that the non-empty labels with meanings are Sex, Pclass, SibSp and Parch, which are analyzed one by one\ntrain_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","464617a9":"train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ee8214f6":"train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ab30cda3":"train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0e391db9":"#basic visualization\nplt.style.use('dark_background')\ngrid = sns.FacetGrid(train_data, row='Pclass', col='Sex', height=4, aspect=2)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend(fontsize=12)\nplt.show(grid)","9b0c7c78":"train_data['Ticket'].unique()[:5]\n#You can find that the Ticket tag data is too cluttered and you can eliminate it for analysis efficiency","a109c641":"# here is the gender numeric code for subsequent analysis and prediction\n#train_data_pro['Sex'] = train_data_pro['Sex'].apply(lambda x: str(x).replace('female', '2') if 'female' in str(x) else x)\n#train_data_pro['Sex'] = train_data_pro['Sex'].apply(lambda x: str(x).replace('male', '1') if 'male' in str(x) else x)\n#train_data_pro['Sex'] = train_data_pro['Sex'].astype(int)\n\n#Handle missing values\n#Because there is less missing data of Age, the data that is missing from Age will have an acceptable impact on the data set\ntrain_data=train_data[train_data['Age'].notna()]\ntrain_data.reset_index(drop=True, inplace=True)","399e9af9":"train_data[['Age', 'Survived']].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n# you can find that the age is too dispersed, we can set up an age tag to analyze the data","d6191229":"pd.cut(train_data['Fare'], 6)","a1dae85b":"train_data[['Fare', 'Survived']].groupby(['Fare'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#You can see that the cost is too spread out,we can create a cost tag to analyze the data","6d7601c7":"pd.cut(train_data['Fare'], 6)","50d85a95":"#Cross the Age level\n#(0.34, 13.683] < (13.683, 26.947] < (26.947, 40.21] < (40.21, 53.473] < (53.473, 66.737] < (66.737, 80.0]\ntrain_data.loc[ train_data['Age'] <= 13.683, 'Agerank'] = 1\ntrain_data.loc[(train_data['Age'] > 13.683) & (train_data['Age'] <= 26.947), 'Agerank'] = 2\ntrain_data.loc[(train_data['Age'] > 26.947) & (train_data['Age'] <= 40.21), 'Agerank'] = 3\ntrain_data.loc[(train_data['Age'] > 40.21) & (train_data['Age'] <= 53.473), 'Agerank'] = 4\ntrain_data.loc[(train_data['Age'] > 53.473) & (train_data['Age'] <= 66.737), 'Agerank'] = 5\ntrain_data.loc[(train_data['Age'] > 66.737) & (train_data['Age'] <= 80.0), 'Agerank'] = 6\ntrain_data['Agerank']=train_data['Agerank'].astype(int)\n#Cross the Fare level\n#(-0.512, 85.388] < (85.388, 170.776] < (170.776, 256.165] < (256.165, 341.553] < (341.553, 426.941] < (426.941, 512.329]\ntrain_data.loc[ train_data['Fare'] <= 85.388, 'Farerank'] = 1\ntrain_data.loc[(train_data['Fare'] > 85.388) & (train_data['Fare'] <= 170.776), 'Farerank'] = 2\ntrain_data.loc[(train_data['Fare'] > 170.776) & (train_data['Fare'] <= 256.165), 'Farerank'] = 3\ntrain_data.loc[(train_data['Fare'] > 256.165) & (train_data['Fare'] <= 341.533), 'Farerank'] = 4\ntrain_data.loc[(train_data['Fare'] > 341.533) & (train_data['Fare'] <= 426.941), 'Farerank'] = 5\ntrain_data.loc[(train_data['Fare'] > 426.941), 'Farerank'] = 6\ntrain_data['Farerank']=train_data['Farerank'].astype(int)","705ed1e6":"fig1=px.bar(x=train_data.groupby('Farerank').count().index.tolist(),\\\n       y=train_data.groupby('Farerank').count()['Survived'].tolist())\nfig1.update_traces(marker_line_width=4,marker_line_color='black',selector=dict(type=\"bar\"))\nfig1.update_layout(title='Age distribution',title_font_family='Courier New, monospace')\nfig1.update_layout(xaxis_title='Age',yaxis_title='Amount')\n         \n\nfig2=px.bar(x=train_data.groupby('Farerank').count().index.tolist(),\\\n       y=train_data.groupby('Farerank').count()['Survived'].tolist())\nfig2.update_traces(marker_line_width=4,marker_line_color='black',selector=dict(type=\"bar\"),marker_color='red')\nfig2.update_layout(title='Fare distribution',title_font_family='Courier New, monospace')\nfig2.update_layout(xaxis_title='Fare',yaxis_title='Amount')\n\nfig1.show()\nfig2.show()","39d8f15f":"# here is the gender numeric code for subsequent analysis and prediction\nfor dataset in [train_data,test_data]:\n    dataset['Sex'] = dataset['Sex'].apply(lambda x: str(x).replace('female', '0') if 'female' in str(x) else x)\n    dataset['Sex'] = dataset['Sex'].apply(lambda x: str(x).replace('male', '1') if 'male' in str(x) else x)\n    dataset['Sex'] = dataset['Sex'].astype(int)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('C','1') if 'C' in str(x) else x)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('S','2') if 'S' in str(x) else x)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('Q','3') if 'Q' in str(x) else x)\n    dataset['Embarked'].fillna('2',inplace=True)\n    dataset['Embarked']=dataset['Embarked'].astype(int)","6fe7e9dc":"train_data['Age'].fillna(0,inplace=True)\ntest_data['Age'].fillna(test_data['Age'].mean()-10.5,inplace=True)\ntrain_data['Fare'].fillna(0,inplace=True)\ntest_data['Fare'].fillna(0,inplace=True)","3a162ba9":"train_data=train_data[[ 'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Cabin', 'Embarked','Survived']]\n#Merge Sibsp and Parch into the Family tag\ntrain_data['Family']=train_data['SibSp']+train_data['Parch']\ntrain_data=train_data.drop(['Parch', 'SibSp'], axis=1)\n#Normalize the data form\ntrain_data['Pclass']=train_data['Pclass'].astype(int)\ntrain_data['Age']=train_data['Age'].astype(int)\ntrain_data['Family']=train_data['Family'].astype(int)\n\ntest_data=test_data[[ 'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Cabin', 'Embarked','PassengerId']]    \ntest_data['Family']=test_data['SibSp']+test_data['Parch']\ntest_data=test_data.drop(['Parch', 'SibSp'], axis=1)","a3a80c26":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.layers.core import Dense, Activation, Dropout","183bc364":"y = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\",'Family','Age']\n\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])","50b4e947":"X['Pclass']=X['Pclass']\/X['Pclass'].max()\nX['Fare']=X['Fare']\/X['Fare'].max()\nX['Age']=X['Age']\/X['Age'].max()\nX['Family']=X['Family']\/X['Family'].max()\nX['Embarked']=X['Embarked']\/X['Embarked'].max()\n\nX_test['Pclass']=X_test['Pclass']\/X_test['Pclass'].max()\nX_test['Fare']=X_test['Fare']\/X_test['Fare'].max()\nX_test['Age']=X_test['Age']\/X_test['Age'].max()\nX_test['Family']=X_test['Family']\/X_test['Family'].max()\nX_test['Embarked']=X_test['Embarked']\/X_test['Embarked'].max()","da75326e":"train_data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","e6be2173":"train_data=train_data[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\ntest_data=test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]","9e31f0ea":"train_data=train_data[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\ntest_data=test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\ntest_data['Sex']=test_data['Sex'].astype('category')\ntest_data['Embarked']=test_data['Embarked'].astype('category')\ntest_data['Age']=(test_data['Age']\/test_data['Age'].max()).astype('float32')\ntest_data['Fare']=(test_data['Fare']\/test_data['Fare'].max()).astype('float32')\ntest_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\ntest_data['Embarked'].fillna('C',inplace=True)\ntrain_data['Sex']=train_data['Sex'].astype('category')\ntrain_data['Embarked']=train_data['Embarked'].astype('category')\ntrain_data['Age']=(train_data['Age']\/train_data['Age'].max()).astype('float32')\ntrain_data['Fare']=(train_data['Fare']\/train_data['Fare'].max()).astype('float32')\ntrain_data['Age'].fillna(train_data['Age'].mean(),inplace=True)\ntrain_data['Embarked'].fillna('C',inplace=True)\n\nfor dataset in [train_data,test_data]:\n    dataset['Sex'] = dataset['Sex'].apply(lambda x: str(x).replace('female', '0') if 'female' in str(x) else x)\n    dataset['Sex'] = dataset['Sex'].apply(lambda x: str(x).replace('male', '1') if 'male' in str(x) else x)\n    dataset['Sex'] = dataset['Sex'].astype(int)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('C', '1') if 'C' in str(x) else x)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('S', '2') if 'S' in str(x) else x)\n    dataset['Embarked'] = dataset['Embarked'].apply(lambda x: str(x).replace('Q', '3') if 'Q' in str(x) else x)\n    dataset['Embarked'] = dataset['Embarked'].astype(int)","e7d69bbf":"train_values=train_data.iloc[:,1:].values\ntest_values=test_data.iloc[:,:].values\ntrain_y = np_utils.to_categorical(train_data.iloc[:,0].values,2)","4ad72e36":"model = Sequential()\nmodel.add(Dense(output_dim=20, input_dim=7,activation='relu'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(20))    \nmodel.add(Dropout(0.25))\nmodel.add(Dense(2, activation='softmax'))\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])","b6fad3e6":"model.fit(train_values, train_y, batch_size=100, epochs=525)","ba92ab4d":"pre=model.predict_classes(test_values)","855e717d":"pre=model.predict_classes(test_values)","234516ac":"test_data=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","883e2f24":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': pre})\nprint(output)\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1a3a10c9":"prediction=pd.read_csv('my_submission.csv')","409dae16":"### Based on the above analysis, the data can be further processed","959e453d":"### Pre-analysis (non-empty label)","225ef6fa":"### The special meaning of some labels\n- Survived:\t 1 means yes and 0 means no\n- PassengerId:\tID of passage\n- Pclass:  type of ticket\uff0c3 types: 1 (first class), 2 (second class), 3 (third class)\n- SibSp:  The number of husbands and wives of the passengers\n- Parch\t:The number of parents, the number of children\n- Fare\t:Money spent on ships by passengers\n- Cabin\t:The passenger's cabin number\n- Embarked\t:Port of embarkation: C, Q, S"}}