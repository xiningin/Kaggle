{"cell_type":{"e5a63f86":"code","07ed5853":"code","8751c988":"code","6672be28":"code","676a1705":"code","0f06f8f6":"code","686f65e9":"code","1d102507":"code","6582cd8f":"code","e4b8243f":"code","a639606e":"code","57792929":"code","898b48ff":"code","dcd59a1f":"code","b3a4c1d9":"code","f043e95d":"code","9cd18e15":"code","e70341d0":"code","be8b2391":"code","9472d252":"code","7d4408d1":"code","35cc42c8":"code","68f81b7e":"code","730bba24":"code","b87546ca":"code","821a2e2f":"code","67f6c141":"code","99e75611":"code","78870b72":"code","43667d0e":"code","cbf4d040":"code","b3a5f649":"code","e60d689d":"code","24b1ce98":"code","8a16c5b6":"code","df23abc9":"code","b37e4fb3":"code","9011d386":"code","f44dd13b":"code","74db7ebb":"code","5f8220f2":"code","b8b1d23c":"code","f4500600":"code","d1b9784d":"code","41c19652":"code","62c44743":"markdown","1fa44d28":"markdown","bff3ae32":"markdown","15a963ad":"markdown","2f8176e9":"markdown","81c8c5d4":"markdown","199e11ef":"markdown","d6d87434":"markdown","863fb159":"markdown","f0bfc0e3":"markdown","938dc4c6":"markdown","7a301300":"markdown","1056cdd7":"markdown","fcff90e0":"markdown","16903302":"markdown","b780d541":"markdown","e4815a54":"markdown","6608c392":"markdown","6b79ef60":"markdown","c3b1da6d":"markdown"},"source":{"e5a63f86":"#Importing all the required libraries \n\n!pip install catboost\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils import resample\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import accuracy_score,mean_absolute_error,confusion_matrix,classification_report\n\nimport xgboost\nimport warnings \nwarnings.filterwarnings('ignore')","07ed5853":"# Loading train and test data sets\n\ntrain = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")","8751c988":"#Creating a function with name 'analysis' for extracting data type, unique and null count\n\ndef analysis(data):\n    return pd.DataFrame({\"Data Type\":data.dtypes, \"Unique Count\":data.apply(lambda x: x.nunique(),axis=0), \n                         \"Null Count\": data.isnull().sum() })","6672be28":"# Getting train data analysis\n\nanalysis(train)","676a1705":"# Getting test data analysis\n\nanalysis(test)","0f06f8f6":"#Making a copy of training data\n\ntrain_copy = train.copy()\ntest_copy = test.copy()\nprint(train.shape)","686f65e9":"# Check count of target variable \n\nsns.countplot(train['Is_Lead'])","1d102507":"# Heatmap for numeric variables\n\nplt.figure(figsize = (7,5))\nsns.heatmap(train.corr(), annot = True, cmap = 'YlGnBu')","6582cd8f":"#Scatterlpot to observe Avg_Account_Balance data\n\nplt.figure(figsize=(12,10))\nsns.scatterplot('Age','Avg_Account_Balance',hue='Is_Lead', data=train)","e4b8243f":"# Pair plot among the variables\n\nsns.pairplot(train[['Age', 'Vintage', 'Avg_Account_Balance','Is_Lead']], hue= 'Is_Lead')","a639606e":"# Analyse the distrubtion of various attributes w.r.t target variable\n\nplt.figure(figsize = (15,10))\n\nplt.subplot(2,2,1)\nsns.countplot('Gender', hue = 'Is_Lead', data = train).set_title('Age')\n\nplt.subplot(2,2,2)\nsns.countplot('Occupation', hue = 'Is_Lead', data = train, palette = 'Set2').set_title('Occupation')\n\nplt.subplot(2,2,3)\nsns.countplot('Channel_Code', hue = 'Is_Lead', data = train, ).set_title('Channel_Code')","57792929":"# Check the target variable portion in missing data\n\nsns.countplot('Is_Lead', data = train[train['Credit_Product'].isnull()]).set_title('Age')","898b48ff":"# Convert Age in years to months as Vintage in months\n\ntrain['Age'] = train['Age']*12\ntest['Age'] = test['Age']*12","dcd59a1f":"# Replacing null values with 'Not Sure' for both train and test sets. Its al together creating new class\n\ntrain['Credit_Product'] = train['Credit_Product'].fillna(\"Not Sure\")\ntest['Credit_Product'] = test['Credit_Product'].fillna(\"Not Sure\")\ntrain[train['Credit_Product'] == 'Not Sure'].head()","b3a4c1d9":"# Storing target value in 'Target' attribute for further usage\n\nTarget = pd.DataFrame(train['Is_Lead'])","f043e95d":"# Dropping unwanted columns \n\ntrain = train.drop(['Is_Lead', 'ID'], axis = 1)\ntest = test.drop(['ID'], axis = 1)\n\nprint(\"Shape of train data:\", train.shape)\nprint(\"Shape of test data:\", test.shape)","9cd18e15":"# Concat both sets to data file\n\ndata = pd.concat([train, test])\ndata.shape","e70341d0":"# Trying to reduce skewnees by applying some operators \n\n#data['Vintage'] = round(np.log(round(np.log(data['Vintage']),2)),2)\n#data['Age'] = round(np.log(round(np.log(data['Age']),2)),2)\ndata['Avg_Account_Balance'] = np.log(data['Avg_Account_Balance'])\n\ndata.head()","be8b2391":"# Getting numeric and categorical columns\n\ndata_num_cols = data._get_numeric_data().columns \ndata_cat_cols = data.columns.difference(data_num_cols)\nprint(\"Numeric columns: \", data_num_cols)\nprint()\nprint(\"Categorical columns: \", data_cat_cols)","9472d252":"#Separating both numeric and categorical data from set\n\ndata_num_data = data.loc[:, data_num_cols]\ndata_cat_data = data.loc[:, data_cat_cols]\n\nprint(\"Shape of num data:\", data_num_data.shape)\nprint(\"Shape of cat data:\", data_cat_data.shape)","7d4408d1":"# Using StandardScaler to scale the data\n\ns_scaler = preprocessing.StandardScaler()\ndata_num_data_s = s_scaler.fit_transform(data_num_data)\n\ndata_num_data_s = pd.DataFrame(data_num_data_s, columns = data_num_cols)\n\nfig, (ax1) = plt.subplots(ncols=1, figsize=(8, 5))\nax1.set_title('After StandardScaler')\n\nsns.kdeplot(data_num_data_s['Age'], ax=ax1)\nsns.kdeplot(data_num_data_s['Vintage'], ax=ax1)\nsns.kdeplot(data_num_data_s['Avg_Account_Balance'], ax=ax1);","35cc42c8":"# Dealing with categorical variables using Lable encoding\n\nlabel = LabelEncoder()\ndata_cat_data = data_cat_data.apply(LabelEncoder().fit_transform)","68f81b7e":"# Strorig cleaned data into 'data_new'\n\ndata_num_data_s.reset_index(drop=True, inplace=True)\ndata_cat_data.reset_index(drop=True, inplace=True)\n#df = pd.concat([df1, df2], axis=1)\ndata_new = pd.concat([data_num_data_s, data_cat_data], axis = 1)","730bba24":"# Splitting back the data into train and test\n\ntrain_new = data_new.loc[:245724,]\ntest_new = data_new.loc[245725:,]\n\nprint(\"Shape of train data:\", train_new.shape)\nprint(\"Shape of test data:\", test_new.shape)","b87546ca":"# Splitting train data into train and validation for model building\n\ntrainx,valx,trainy,valy = train_test_split(train_new,Target,test_size=0.3,random_state=1234)\n#print(cust_data.shape)\nprint(trainx.shape)\nprint(valx.shape)","821a2e2f":"# As the data in imbalanced need to sample it. Undersample fits the best in here\n\ntraining_set = pd.concat([trainx, trainy], axis = 1)\nlead = training_set[training_set.Is_Lead == 1]\nnot_lead = training_set[training_set.Is_Lead == 0]","67f6c141":"undersample = resample(not_lead, replace = True, n_samples = len(lead), random_state = 4)","99e75611":"# Storing sampled trainx and trainy data for model training\n\nus_training_set = pd.concat([lead, undersample])\nus_trainy = us_training_set['Is_Lead']\nus_trainx = us_training_set.drop('Is_Lead', axis = 1)","78870b72":"# Storing categorical attributes in a variable and definig SEED value\n\ncat_var = np.where(us_trainx.dtypes != np.float)[0]\nSEED = 1993","43667d0e":"params = {\n    'cat_features':cat_var,\n    'eval_metric': 'AUC',\n    'random_seed': SEED}\n\ncat = CatBoostClassifier(**params)\n\ncross_val_score(cat,us_trainx, us_trainy, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc').mean()","cbf4d040":"# Defining CatBoost classifier\n\n#cat = CatBoostClassifier.fit(X = us_trainx, y = us_trainy, cat_features=categorical_var)\nmod = cat.fit(us_trainx, us_trainy,plot=True, verbose=False)","b3a5f649":"# Predicting values on train and validation sets\n\npred_train_cat = mod.predict(trainx)\npred_val_cat = mod.predict(valx)\npred_val_cat","e60d689d":"# Checking roc_auc_score for both train and validation sets\n\ncat_auc_train = roc_auc_score(trainy, pred_train_cat)\ncat_auc_val = roc_auc_score(valy, pred_val_cat)\nprint(\"ROC_AUC_Score Train: \",cat_auc_train)\nprint(\"ROC_AUC_Score Val: \", cat_auc_val)","24b1ce98":"# Defining XGBoost classifier\n\nxgb = xgboost.XGBClassifier()\n\nxgb = xgb.fit(us_trainx, us_trainy)","8a16c5b6":"cross_val_score(xgb,us_trainx, us_trainy, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc').mean()","df23abc9":"'''# Tried applying cv with less number of paramets but didnt work due to technical constraints\n# Time taken to run: 100min\n\n\nxgb_params = {'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5],\n                'max_depth': [3, 5, 7, 10, 15, 20],\n                'min_child_weight': [1, 3, 5]}\n\ngridcv = GridSearchCV(estimator = classifier,\n                      param_grid = xgb_params)\n\ngridcv.fit(us_trainx, us_trainy)'''","b37e4fb3":"# Predicting on train and validation data \n\npred_train_xgb = xgb.predict(trainx)\npred_val_xgb = xgb.predict(valx)\npred_val_xgb","9011d386":"# Measuring the roc_auc_score values \n\nxgb_auc_train = roc_auc_score(trainy, pred_train_xgb)\nxgb_auc_val = roc_auc_score(valy, pred_val_xgb)\nprint(\"ROC_AUC_Score Train: \",xgb_auc_train)\nprint(\"ROC_AUC_Score Val: \", xgb_auc_val)","f44dd13b":"# Getting Confusion Matrix and Classification Report\n\nresults = confusion_matrix(valy, pred_val_xgb) \nprint('Confusion Matrix :')\nprint(results) \nprint ('Accuracy Score :',accuracy_score(valy, pred_val_xgb))\nprint ('Report : ')\nprint (classification_report(valy, pred_val_xgb))","74db7ebb":"# Model fit\n\nrfc = RandomForestClassifier(max_depth = 15, criterion= 'entropy', n_estimators=200)\nrfc.fit(X = us_trainx,y = us_trainy)","5f8220f2":"cross_val_score(rfc,us_trainx, us_trainy, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc').mean()","b8b1d23c":"# Predicting on train and validation data \n\npred_train_rfc = rfc.predict(trainx)\npred_val_rfc = rfc.predict(valx)\npred_val_rfc","f4500600":"# Measuring the roc_auc_score values \n\nrfc_auc_train = roc_auc_score(trainy, pred_train_rfc)\nrfc_auc_val = roc_auc_score(valy, pred_val_rfc)\nprint(\"ROC_AUC_Score Train: \",rfc_auc_train)\nprint(\"ROC_AUC_Score Val: \", rfc_auc_val)","d1b9784d":"# Getting Confusion Matrix and Classification Report\n\nresults = confusion_matrix(valy, pred_val_rfc) \nprint('Confusion Matrix :')\nprint(results) \nprint ('Accuracy Score :',accuracy_score(valy, pred_val_rfc))\nprint ('Report : ')\nprint (classification_report(valy, pred_val_rfc))","41c19652":"# Copying ID column from tess_copy file and creating 'submission' file\n\n#submission = pd.DataFrame(test_copy['ID'])\n\n# Storing best model output to submisison file\n\n#submission['Is_Lead'] = pred_test_rfc\n#submission.head()\n\n# Downloading the file to local drive\n\n#submission1_XGb = submission.to_csv (r'C:\\Users\\91879\\Desktop\\AV\\Submissions\\Submission_Prudhvi.csv',index = None, header=True)","62c44743":"# Problem Statement: \n\nHappy Customer Bank is trying to cross sell credit cards to its customers and would like to identify whether customer will be intrested in it or not based on some parameters.\n\n## Given Parameters:\n\n1. ID                  - nique Identifier for a row\n2. Gender              - Gender of the Customer\n3. Age                 - Age of the Customer (in Years)\n4. Region_Code         - Code of the Region for the customers\n5. Occupation          - Occupation Type for the customer\n6. Channel_Code        - Acquisition Channel Code for the Customer \u00a0(Encoded)\n7. Vintage             - Vintage for the Customer (In Months)\n8. Credit_Product      - If the Customer has any active credit product (Home loan,Personal loan, Credit Card etc.)\n9. Avg_Account_Balance - Average Account Balance for the Customer in last 12 Months\n10. Is_Active          - If the Customer is Active in last 3 Months\n11. Is_Lead(Target)    - If the Customer is interested for the Credit Card\n                            0 : Customer is not interested\n                            1 : Customer is interested\n\n### Models Used:\n\nCatBoost, XGBoost, RandomForest\n\n\n","1fa44d28":"Notes:\n\n- Both male and female are likely have same amount of interest \n- Self employed people are hingly interested when comapared to others\n- Through x3 channel more chances for credit card","bff3ae32":"Observations:\n\n- Null values present in Credit_Product, so need to identify a way to replace them\n- Data types looks fine","15a963ad":"## Feature Engineering","2f8176e9":"Notes:\n\n- Age: Most of the customers are under 40 are equally spread in Lead\n- While we compare Is_Lead with other attribtues, not able to get clear picture on distribution","81c8c5d4":"Notes:\n\n- As thought, Age and Vintage are correlated. We need to achieve proper scaling between them","199e11ef":"Notes:\n\n- Majority for missing data belongs to interested customers so we need to fill those values. \n- Lets keep the value as 'Not Sure' and check the performance ","d6d87434":"## Let's begin...","863fb159":"Notes: \n\n- Looks like data is imbalanced, need to be careful while splitting ","f0bfc0e3":"## Visualizations","938dc4c6":"Notes:\n\n- Avg_Account_Balance scaled well and others are in bad shape","7a301300":"Notes:\n\n- Surprisingly, account balance is independent of Age. Infact account balance is bit high for age groupof 25-35","1056cdd7":"### 2. XGBoost Classifier","fcff90e0":"## Models","16903302":"### Challenges:\n1. Missing data in Credit_Product attribute - I have careated separate model by keeping Credit_Product as target variable adn rest as input attributes. But it didnt give promising values so finally repalced them with \"Not Sure\". I think the main reason for this could be imbalance nature in the data\n\n2. Target vale imbalance - With the size of the data we have this is a huge imbalance case. I tried various smapling techniques but for binar classifications undersmapling works very well.\n\nInitially, I have created XGBoost, RF, LR and KNN models, and later I have seen some better submission and from there I have tried CatBoost and it worked very well. Need to study much more on CatBoost and its parameters.\n\n\n### Please feel free to add your comments and suggestions!!!","b780d541":"## Submission File","e4815a54":"### 1. CatBoost Classifier","6608c392":"Observations:\n\n- Null values present on ly in Credit_Product, so need to identify a way to replace them\n- Data types looks fine ","6b79ef60":"## Data Loading","c3b1da6d":"### 3. RandomForest Classifier"}}