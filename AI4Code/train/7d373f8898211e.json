{"cell_type":{"57e5f211":"code","59da8e00":"code","9d311d6c":"code","bda83bfc":"code","4514fcc7":"code","a7ec8f80":"code","8455964f":"code","290ea52e":"code","cf1056f1":"code","be8c0d32":"code","16222025":"code","a281e4f6":"code","086fd4ed":"code","9b6631cb":"code","f9c22b19":"code","b0606db6":"markdown","58064de1":"markdown","9050cf7c":"markdown","d4ba4699":"markdown","b2dfe5c3":"markdown","27d8c5f5":"markdown","300af1ac":"markdown","277a815d":"markdown","55785c90":"markdown","f7373afd":"markdown","caebb391":"markdown","ba84ac04":"markdown","749beabf":"markdown"},"source":{"57e5f211":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))","59da8e00":"crime_df = pd.read_csv(\"..\/input\/crime.csv\", encoding=\"latin-1\")\noffense_df = pd.read_csv(\"..\/input\/offense_codes.csv\", encoding=\"latin-1\")","9d311d6c":"print(crime_df.iloc[5],\"\\n############\") \nprint(offense_df.head(),\"\\n###########\")\nprint(crime_df.isnull().sum())     # it's showing nan values ","bda83bfc":"crime_df = crime_df.drop(columns='SHOOTING')\ncrime_df = crime_df.dropna(axis=0)\nprint(crime_df.isnull().sum(),\"\\nShape:\",crime_df.shape)","4514fcc7":"plt.figure(figsize=(8,8))    #We are giving the size of figure\nsns.countplot(x=crime_df.DAY_OF_WEEK)  #countplot taking counts of the columns which you choose \nplt.show() \n\nplt.figure(figsize=(8,8))    \nsns.countplot(x=crime_df.HOUR)  \nplt.show() ","a7ec8f80":"plt.figure(figsize=(8,8))    #first size of figure\n\n#giving the name of piecies\nlabels = 'January', 'Febuary', 'March', 'April', 'May', 'Jun', 'July', 'August', 'September', 'October', 'November', 'December'\nsizes_month = []    \nfor i in range(12):\n    i+=1\n    sizes_month.append(len(crime_df[crime_df['MONTH']==i]))#count of crime for every month\n    \n\nexplode = (0, 0,0,0,0,0,0,0.2,0,0,0,0)  #In here we are choosing one piece of pie it's going out from the middle\n                               \nplt.pie(sizes_month, explode = explode, labels=labels,  \nautopct='%1.1f%%', shadow=True, startangle=90)\n\nplt.axis('equal')\nplt.show()","8455964f":"from wordcloud import WordCloud\ntext = []\nfor i in crime_df.OFFENSE_CODE_GROUP:\n    text.append(i)#here we are adding word to text array but it's looking like this ['Larency','Homicide','Robbery']\ntext = ''.join(map(str, text)) #Now we make all of them like this [LarencyHomicideRobbery]\n\nwordcloud = WordCloud(width=1600, height=800, max_font_size=300,background_color='white').generate(text)\nplt.figure(figsize=(20,17))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","290ea52e":"year_count = []\n\nfor i in crime_df.YEAR.unique():\n    year_count.append(len(crime_df[crime_df['YEAR']==i]))\n\nplt.figure(figsize=(10,5))\nsns.pointplot(x=crime_df.YEAR.unique(),y=year_count,color='red',alpha=0.8)\nplt.xlabel('Year',fontsize = 15,color='blue')\nplt.xticks(rotation=45)\nplt.ylabel('Crime Count',fontsize = 15,color='blue')\nplt.title('Crime vs Year',fontsize = 15,color='blue')\nplt.grid()\nplt.show()","cf1056f1":"from mpl_toolkits.basemap import Basemap\n\nm = Basemap(projection='mill',llcrnrlat=25,urcrnrlat=49.5,\\\n            llcrnrlon=-140,urcrnrlon=-50,resolution='l')\n\nplt.figure(figsize=(25,17))\nm.drawcountries() #for drawing country borders\nm.drawstates()    #for drawing states borders\nm.drawcoastlines()\n#m.fillcontinents(color='#04BAE3', lake_color='#FFFFFF') #giving color \n\nlat = 42.361145\nlon = -71.057083\n\nx,y = m(lon,lat)\nm.plot(x, y, 'ro', markersize=20, alpha=.8) #alpha is making your marker transparent\n\nm.bluemarble() #With this it's make your map like from satellite but if you give colors it will not work\nm.drawmapboundary(color = '#FFFFFF')\nplt.show()","be8c0d32":"import folium\nfrom folium.plugins import HeatMap\n\nmap_hooray = folium.Map(location=[42.361145,-71.057083],\n                    zoom_start = 12, min_zoom=12) #Giving the location just write boston coordinat to google\n\nheat_df = crime_df[crime_df['YEAR']==2017] # I take 2017 cause there is more crime against to other years\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Larceny'] \nheat_df = heat_df[['Lat', 'Long']] #giving only latitude and longitude now in heat_df just latitude and longitude\n                                        #from 2017 larceny responde\n\n\n    \n    \nfolium.CircleMarker([42.356145,-71.064083],\n                    radius=50,\n                    popup='Homicide',\n                    color='red',\n                    ).add_to(map_hooray) #Adding mark on the map but it's hard to find correct place. \n                                         #it's take to muhc time\n    \n    \nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\n#We have to give latitude and longitude like this [[lat, lon],[lat, lon],[lat, lon],[lat, lon],[lat, lon]]\n\nHeatMap(heat_data, radius=10).add_to(map_hooray) #Adding map_hooray to HeatMap\nmap_hooray #Plotting","16222025":"map_hooray = folium.Map(location=[42.361145,-71.057083],\n                    zoom_start = 12, min_zoom=12) \n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Motor Vehicle Accident Response']\nheat_df = heat_df[['Lat', 'Long']]\n\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","a281e4f6":"map_hooray = folium.Map(location=[42.340145,-71.057083],\n                    zoom_start = 13, min_zoom=13) \n\nheat_df = crime_df[crime_df['YEAR']==2017] \nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Drug Violation']\nheat_df = heat_df[['Lat', 'Long']]\n\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","086fd4ed":"map_hooray = folium.Map(location=[42.351145,-71.057083],\n                    zoom_start = 12, min_zoom=12) \n\nheat_df = crime_df[crime_df['YEAR']==2017] \nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Prostitution']\nheat_df = heat_df[['Lat', 'Long']]\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","9b6631cb":"map_hooray = folium.Map(location=[42.341145,-71.057083],\n                    zoom_start = 12, min_zoom = 12) \n\n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Homicide']\nheat_df = heat_df[['Lat', 'Long']]\n\nfolium.CircleMarker([42.313145,-71.078083],\n                    radius=80,\n                    popup='Homicide',\n                    color='red',\n                    ).add_to(map_hooray) #Adding mark on the map but it's hard to find correct place. \n                                         #it's take to muhc time\n\nheat_data = [[row['Lat'],row['Long']] for index, row in heat_df.iterrows()]\nHeatMap(heat_data, radius=10).add_to(map_hooray)\nmap_hooray","f9c22b19":"from folium import plugins\nmap_hooray = folium.Map(location=[42.341145,-71.057083],\n                    zoom_start = 12, min_zoom = 12) \n\n\nheat_df = crime_df[crime_df['YEAR']==2017]\nheat_df = heat_df[heat_df['OFFENSE_CODE_GROUP']=='Drug Violation']\nheat_df = heat_df[['Lat', 'Long']]\n\nheat_df['Month'] = crime_df['MONTH']\n\n# List comprehension to make out list of lists\nheat_data = [[[row['Lat'],row['Long']] for index, row in heat_df[heat_df['Month'] == i].iterrows()] for i in range(1,13)]\n\n# Plot it on the map\nhm = plugins.HeatMapWithTime(heat_data,auto_play=True,max_opacity=0.8)\nhm.add_to(map_hooray)\n# Display the map\nmap_hooray","b0606db6":"**THEN WE JUST CHECKING OUR DATA **","58064de1":"**ABOUT PROSTITUTION**\n\n*Honan-Allston Branch library and Dorchester Avenue road*","9050cf7c":"**ABOUT MOTOR VEHICLE ACCIDENT RESPONSE**\n\n*It's look everywhere is almost same accident it's mean thoese accident not cause of city road planning*\n\n*Probably it's cause of human mistakes*","d4ba4699":"**FIRST WE GONNA READ OUR DATA**\n\n*Generally we don't need to write encoding='latin-1' but for this data we have to*\n\n*We have two data one of them fro crimes other one is for crime codes*","b2dfe5c3":"**HERE IS BOSTON**\n\n*You can change projection from basemap and resolution we have 3 type c, l, h but we can't use h. Resolution is for quality of the map*\n\n*I try to use this plotting for Boston but I couldn't make it. It's not good for the city plotting cause it's doesn't matter which projection you use this plotting is not for the cityies.*","27d8c5f5":"**THERE IS A HEAT MAP BY THE MONTH ABOUT DRUG VIOLATION**\n\n*The boxes about lower left corner of the map: You can see the differences by the moth just use the buttons.*\n\n1-Backward\n\n2-Play reverse\n\n3-Play\n\n4-Foreward\n\n5-Loops","300af1ac":"**CRIME COUNT FOR EVERYDAY AND EVERY HOUR**\n\n*Friday is the first, it might be cause of last day of work for the most of people so people more aggresive in that day*\n\n*And at 17.00 there is more crime compared to other hours of day it's olsa might be cause of work *","277a815d":"**PIE PLOTTING**\n\n*It's look like people do more crazy things in the summer*","55785c90":"**FOLIUM AND HEATMAP IT'S REALLY EASY TO USE AND IT'S GREAT**\n\n*You should only careful for data I mean if you give a big data to folium heatmap it will not gonna plotting or it take lots of time so you have to separate your data to piecies *\n\n*#We have to give latitude and longitude like this [[lat, lon],[lat, lon],[lat, lon],[lat, lon],[lat, lon]]*\n\n**ABOUT LARCENY**\n\n*Most of them around Newburry Street, Boylston Street, State Street and Downtown Crossing*","f7373afd":"**ABOUT HOMICIDE**\n\n*Most of them between and around Roxbury, Dorchester and South Boston*","caebb391":"**ABOUT DRUGS**\n\n*Downtown Crossing and Chinetown Crossing are the most drugs reporting *\n\n*Araound Boston Medical Center ??? *","ba84ac04":"**DATA CLEANING**\n\n*I just drop shooting column cause it's have lots of nan values*\n\n*Then for the other nan values we just drop the line not the column*","749beabf":"**WORDCLOUD**\n\n*It's showing the most used words in the array if a word more used than others it will look much bigger*\n\n*As we can see in this data Vehicle Accident is the most bigger one*\n\n*for making wordcloud you have to merge every word and put them in an one array*\n\n*It must be like this [LarencyHomicideRobbery]*"}}