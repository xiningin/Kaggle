{"cell_type":{"cab64f8d":"code","383f7928":"code","abc0e371":"code","622c383d":"code","bfacefd0":"code","63623051":"code","36f7ef19":"code","ececd460":"code","43aa9717":"code","a09af0ec":"code","412573a1":"code","6dad6647":"code","134f906e":"markdown","77a6bb57":"markdown","1e9c536e":"markdown"},"source":{"cab64f8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","383f7928":"from fastai.vision.all import *","abc0e371":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","622c383d":"def plot_fastai_results(learn):\n    '''\n    Plots sensitivity, speficificty, prevalence, accuracy, and confusion matrix for a fastai model named \"learn\".\n    Some portions are adapted from https:\/\/github.com\/fastai\/fastai\/blob\/master\/nbs\/61_tutorial.medical_imaging.ipynb\n    '''\n    interp = Interpretation.from_learner(learn)\n    interp = ClassificationInterpretation.from_learner(learn)\n    interp.plot_confusion_matrix(figsize=(7,7))\n    losses,idxs = interp.top_losses()\n    len(dls.valid_ds)==len(losses)==len(idxs)\n    upp, low = interp.confusion_matrix()\n    tn, fp = upp[0], upp[1]\n    fn, tp = low[0], low[1]\n    sensitivity = tp\/(tp + fn)\n    print('Sensitivity: ',sensitivity)\n    specificity = tn\/(fp + tn)\n    print('Specificity: ',specificity)\n    #val = dls.valid_ds.cat\n    prevalance = 15\/50\n    print('Prevalance: ',prevalance)\n    accuracy = (sensitivity * prevalance) + (specificity * (1 - prevalance))\n    print('Accuracy: ',accuracy)","bfacefd0":"tfms = aug_transforms(max_rotate=25)","63623051":"len(tfms)","36f7ef19":"from PIL import Image\n\nimage = Image.open(\"..\/input\/unsplash-dataset-images-downloaded-250x250\/downloads\/-KNNQqX9rqY.jpg\")\nimage","ececd460":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","43aa9717":"#Code by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques\n\ndef imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","a09af0ec":"#Code by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques\n\nloader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/unsplash-dataset-images-downloaded-250x250\/downloads\/-KNNQqX9rqY.jpg', loader_transform)","412573a1":"#Code by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques\n\n#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped');","6dad6647":"#Code by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques\n\n#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('..\/input\/unsplash-dataset-images-downloaded-250x250\/downloads\/-KNNQqX9rqY.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","134f906e":"#That's all. Don't mess with Master Tigress. It's HER year.\n\n![](https:\/\/i.kym-cdn.com\/photos\/images\/original\/000\/729\/046\/ee0.jpg)knowyourmeme.com","77a6bb57":"#Acknowledgement\n\nNaim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques","1e9c536e":"#The Year of The Tiger: 2022\n\n2022 is a year of the Water Tiger. It starts from February 1st, 2022, and ends on January 21st, 2023. A Water Tiger year occurs every 60 years.\n\nFor the Record, I was born in 1962."}}