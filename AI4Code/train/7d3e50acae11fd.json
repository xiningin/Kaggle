{"cell_type":{"167dde2c":"code","02a334a8":"code","e46deda6":"code","ad0363de":"code","513abcf1":"code","1b44e7e8":"code","6f4bff89":"code","70f78688":"code","119c1984":"code","195e0baa":"code","899da781":"markdown","e96dd5a7":"markdown","ffe07e00":"markdown","82a37fc2":"markdown","0e046f65":"markdown","6431d980":"markdown","05ebc01c":"markdown","9e7c4a11":"markdown"},"source":{"167dde2c":"import numpy as np\nimport os\nimport shutil\nimport matplotlib.pyplot as plt\nimport zipfile\nimport tensorflow as tf\nimport xml.etree.ElementTree as ET\nfrom tqdm import tqdm\nfrom keras.models import Model \nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.layers.core import Dropout\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import UpSampling2D\nfrom keras.layers import ReLU\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom PIL import Image","02a334a8":"# Constantes y directorios\nSEED = 4250\nnp.random.seed(SEED)\nrandom_dim = 128\nROOT_DIR = '..\/input\/'\nIMAGES_DIR = ROOT_DIR + 'images\/Images\/'\nBREEDS_DIR = ROOT_DIR + 'annotations\/Annotation\/'\nBREEDS = os.listdir(BREEDS_DIR)\nIMAGES = []\nFOLDERS=[]\n\n'''for r, d, f in os.walk(IMAGES_DIR):\n    for folder in d:\n        os.listdir(os.path.join(r, folder)))'''\n        \n# r=root, d=directories, f = files\nfor r, d, f in os.walk(IMAGES_DIR):\n    for file in f:\n        if '.jpg' in file:\n            IMAGES.append(os.path.join(file))\n\nfor r, d, f in os.walk(IMAGES_DIR):\n    for folder in d:\n        FOLDERS.append(os.path.join(r, folder))\n# Resumen\nprint('Total Images: {}'.format(len(IMAGES)))\nprint('Total Annotations: {}'.format(len(BREEDS)))\nprint('Total Carpetas de perros: {}'.format(len(FOLDERS)))\n        \n\n","e46deda6":"def load_images():\n    # Place holder for output \n    all_images = np.zeros((22250, 64, 64, 3))\n\n    # Indice\n    index = 0\n    errores=[]\n    for breed in BREEDS:\n        for dog in os.listdir(BREEDS_DIR + breed):\n            try: \n                img=Image.open(IMAGES_DIR+ breed+'\/'+dog+'.jpg')\n                #print(IMAGES_DIR+ breed+'\/'+dog+'.jpg')\n            except: continue\n            tree = ET.parse(BREEDS_DIR + breed + '\/' + dog)\n            root = tree.getroot()\n            objects = root.findall('object')\n\n            for o in objects:\n                bndbox = o.find('bndbox') \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n\n                # Determina cada lado\n\n                xdelta = xmax - xmin\n                ydelta = ymax - ymin\n                #Filtrar imagenes donde la caja que delimita al perro es muy baja para ser usada\n                if xdelta >= 64 and ydelta >= 64:\n                    img2 = img.crop((xmin, ymin, xmax, ymax))\n                    img2 = img2.resize((64, 64), Image.ANTIALIAS)\n                    image = np.asarray(img2)\n\n                    # Normaliza al rango [-1, 1]\n                    if np.size(image, 2) == 3:\n                        all_images[index,:] = (image.astype(np.float32) - 127.5)\/127.5\n                        index += 1\n                    else:\n                        errores.append(IMAGES_DIR+ breed+'\/'+dog+'.jpg')\n\n\n\n                if index % 1000 == 0:\n                    print('Processed Images: {}'.format(index))\n    print('Total Processed Images: {}'.format(index))\n    print(errores)\n    return all_images","ad0363de":"def create_generator_model():\n    #Inicializacion normal aleatoria de pesos\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    # Modelo\n    model = Sequential()\n\n    # Comienza en 4 * 4\n    start_shape = 64 * 4 * 4\n    model.add(Dense(start_shape, kernel_initializer = init, input_dim = random_dim))\n    model.add(Reshape((4, 4, 64)))\n    \n    # Upsample => 8 * 8 \n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size = 3, padding = \"same\", kernel_initializer = init))\n    model.add(ReLU())\n    \n    # Upsample => 16 * 16 \n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size = 3, padding = \"same\", kernel_initializer = init))\n    model.add(ReLU())\n    \n    # Upsample => 32 * 32\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size = 3, padding = \"same\", kernel_initializer = init))\n    model.add(ReLU())\n    \n    # Upsample => 64 * 64\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size = 3, padding = \"same\", kernel_initializer = init))\n    model.add(ReLU())\n    \n    # output\n    model.add(Conv2D(3, kernel_size = 3, activation = 'tanh', padding = 'same', kernel_initializer=init))\n    model.compile(loss = 'binary_crossentropy', optimizer='rmsprop')\n    print(model.summary())\n\n    return model","513abcf1":"def create_discriminator_model():\n    input_shape = (64, 64, 3)\n\n    #Inicializacion normal aleatoria de pesos\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    # Definir el modelo\n    model = Sequential()\n\n    # Downsample ==> 32 * 32\n    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = init, input_shape = input_shape))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.25))\n\n    # Downsample ==> 16 * 16\n    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = init))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.25))\n    \n    # Downsample => 8 * 8\n    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = init))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.25))\n    \n    # Downsample => 4 * 4\n    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = init))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.25))\n    \n    # Capas finales\n    model.add(Flatten())\n    model.add(Dense(1, activation = 'sigmoid', kernel_initializer = init))\n\n    # Compila el modelo\n    model.compile(loss = 'binary_crossentropy',optimizer='rmsprop')\n    \n    print(model.summary())\n    \n    return model","1b44e7e8":"def create_gan_model(discriminator, random_dim, generator):\n    # Setea trainable to False inicialmente\n    discriminator.trainable = False\n    \n    # Input de la GAN\n    gan_input = Input(shape = (random_dim,))\n    \n    # Generator Output...una imagen\n    generator_output = generator(gan_input)\n    \n    # El output del discriminador es la probabilidad de que una imagen sea real o falsa\n    gan_output = discriminator(generator_output)\n    gan_model = Model(inputs = gan_input, outputs = gan_output)\n    gan_model.compile(loss = 'binary_crossentropy', optimizer='rmsprop')\n    print(gan_model.summary())\n    \n    return gan_model","6f4bff89":"def generator_input(latent_dim, n_samples):\n    # Generar puntos en el espacio latente\n    input = np.random.randn(latent_dim * n_samples)\n\n    # Reshape del input batch para la red\n    input = input.reshape((n_samples, latent_dim))\n\n    return input","70f78688":"def plot_generated_images(epoch, generator, examples = 25, dim = (5, 5)):\n    generated_images = generator.predict(np.random.normal(0, 1, size = [examples, random_dim]))\n    generated_images = ((generated_images + 1) * 127.5).astype('uint8')\n        \n    plt.figure(figsize = (12, 8))\n    for i in range(generated_images.shape[0]):\n        plt.subplot(dim[0], dim[1], i + 1)\n        plt.imshow(generated_images[i], interpolation = 'nearest')\n        plt.axis('off')\n    plt.suptitle('Epoch %d' % epoch, x = 0.5, y = 1.0)\n    plt.tight_layout()\n    plt.savefig('dog_at_epoch_%d.png' % epoch)\n    \ndef plot_loss(d_f, d_r, g):\n    plt.figure(figsize = (18, 12))\n    plt.plot(d_f, label = 'Discriminator Fake Loss')\n    plt.plot(d_r, label = 'Discriminator Real Loss')\n    plt.plot(g, label = 'Generator Loss')\n    plt.legend()\n    plt.savefig('loss_plot.png')\n    plt.close()","119c1984":"def train_model(epochs = 1, batch_size = 128):\n    # Cargar Imagenes\n    x_train = load_images()\n    \n    # Calcular el numero de batches\n    batch_count = x_train.shape[0] \/ batch_size\n\n    # Crear modelos del discriminador y generador\n    generator = create_generator_model()\n    discriminator = create_discriminator_model()\n    \n    # Crear Modelos GAN\n    gan_model = create_gan_model(discriminator, random_dim, generator)\n    \n    # Listado para Loss History\n    discriminator_fake_hist, discriminator_real_hist, generator_hist = [], [], []\n    \n    for e in range(epochs):\n        \n        # Script Stop Counter\n        script_stopper_counter = 0\n        \n        print('======================== Epoch {} ============================='.format(e))\n        for _ in tqdm(range(int(batch_count))):\n            \n            #Perdida del discriminador\n            discriminator_fake_loss, discriminator_real_loss = [], []\n            \n            #Entrenar al discriminador mas que el generador\n            for _ in range(2):\n                # Entrenar el discriminador en imagenes falsas\n                X_fake = generator.predict(generator_input(random_dim, batch_size))\n                y_fake = np.zeros(batch_size)\n                y_fake[:] = 0\n                discriminator.trainable = True\n                d_fake_loss = discriminator.train_on_batch(X_fake, y_fake)\n                \n                # Entrenar el discriminador en imagenes reales\n                X_real = x_train[np.random.randint(0, x_train.shape[0], size = batch_size)]\n                y_real = np.zeros(batch_size)\n                y_real[:] = 0.9  # label smoothing\n                discriminator.trainable = True\n                d_real_loss = discriminator.train_on_batch(X_real, y_real)\n\n                # Guardar Perdida en cada iteracion\n                discriminator_fake_loss.append(d_fake_loss)\n                discriminator_real_loss.append(d_real_loss)\n\n            # Entrenar generador\n            noise = generator_input(random_dim, batch_size)\n            y_gen = np.ones(batch_size)\n            discriminator.trainable = False\n            generator_loss = gan_model.train_on_batch(noise, y_gen)\n\n\n            # Guardar Loss en la lista de historial del Loss\n            discriminator_fake_hist.append(np.mean(discriminator_fake_loss))\n            discriminator_real_hist.append(np.mean(discriminator_real_loss)) \n            generator_hist.append(generator_loss)\n            \n            \n            # En ocasiones el Loss del discriminador explota y se mantiene alto, en ese caso se para el script\n            if np.mean(discriminator_fake_loss) > 10:\n                script_stopper_counter += 1\n        \n        # Resume la calidad de la imagen por epochs durante el entrenamiento\n        if e % 100 == 0:\n            plot_generated_images(e, generator)\n            \n        #Parar script si un epoch tiene perdida explosiva\n        if script_stopper_counter > 160:\n            plot_generated_images(e, generator)\n            break\n            \n    # Grafica la perdida durante el entrenamiento\n    plot_loss(discriminator_fake_hist, discriminator_real_hist, generator_hist)\n\n    # Crea Images.zip\n    z = zipfile.PyZipFile('images.zip', mode = 'w')\n    for k in range(1000):\n        # Genera nuevos perros\n        generated_images = generator.predict(np.random.normal(0, 1, size = [1, random_dim]))\n        image = Image.fromarray(((generated_images + 1) * 127.5).astype('uint8').reshape(64, 64, 3))\n\n        # Salvar en un .zip file \n        f = str(k)+'.png'\n        image.save(f, 'PNG')\n        z.write(f)\n        os.remove(f)\n        \n        # Plot Status Counter\n        if k % 100 == 0: \n            print(k)\n    z.close()","195e0baa":"train_model(300,256)","899da781":"# Precesar Imagenes\nBuscar en la imagen los limites de las anotaciones que marcan donde hay un perro en la imagen ","e96dd5a7":"## GENERADOR","ffe07e00":"## Modelo de la GAN","82a37fc2":"## DISCRIMINADOR","0e046f65":"## Funcion de Graficacion","6431d980":"# Modelo de la RED","05ebc01c":"## Entrenamiento del Modelo","9e7c4a11":"## Generador del input"}}