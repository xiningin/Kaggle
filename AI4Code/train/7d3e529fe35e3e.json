{"cell_type":{"a09da4c2":"code","a1a3f907":"code","4fe904b9":"code","479f1168":"code","c2a9e1b7":"code","90fd3880":"code","2a15e1e5":"code","3085627f":"code","c9e51a0b":"code","6b30ac77":"markdown","fdc38ba2":"markdown","05262cbb":"markdown","7d45c771":"markdown"},"source":{"a09da4c2":"import gc\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow_addons.optimizers import AdamW, Lookahead\nfrom tensorflow.keras.layers import Concatenate, Add\nfrom tensorflow.keras.layers import Activation, Input\nfrom tensorflow.keras.layers import Embedding, Conv1D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout","a1a3f907":"with open(\"..\/input\/tps-june-data-preprocess\/TPS_June_Dataset_Set1.txt\", 'rb') as handle: \n    data = handle.read()\n\nprocessed_data = pickle.loads(data)\ntrain_df = processed_data['train_df']\ntest_df = processed_data['test_df']\n\ncol_list = test_df.columns.to_list()\n\ndel processed_data\ngc.collect()","4fe904b9":"Xtrain = train_df.loc[:, train_df.columns != 'target'].copy()\nYtrain = train_df['target'].copy()\nYtrain_oh = pd.get_dummies(train_df['target']).copy()\nXtest = test_df.copy()\n\nprint(\"Xtrain: {} \\nYtrain: {} \\nYtrain_oh: {} \\nXtest: {}\".format(Xtrain.shape, Ytrain.shape, \n                                                                   Ytrain_oh.shape, Xtest.shape))\n\ndel train_df\ndel test_df\ngc.collect()","479f1168":"def dnn_model(n_features):\n    \n    x_input = Input(shape=(n_features,))\n    \n    x = Embedding(512, 32)(x_input)\n    \n    x = Conv1D(filters=64, kernel_size=3, \n               strides=2, padding='same', \n               kernel_regularizer=l2(0.0003),\n               kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    \n    x = Conv1D(filters=96, kernel_size=3, \n               strides=2, padding='same', \n               kernel_regularizer=l2(0.0003),\n               kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    \n    x = Flatten()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=0.15)(x)\n    \n    x = Dense(units=32, kernel_initializer='he_uniform', \n                kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Dense(units=16, kernel_initializer='he_uniform', \n                kernel_regularizer=l2(0.0001))(x)\n    x = BatchNormalization()(x)\n    x = Activation('swish')(x)\n    x = Dropout(rate=0.1)(x)\n\n    x_output = Dense(units=9, activation='softmax', \n                     kernel_initializer='he_uniform')(x)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","c2a9e1b7":"model = dnn_model(Xtrain.shape[1])\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Lookahead(AdamW(lr=1e-2, \n                                        weight_decay=1e-5, \n                                        clipvalue=700), \n                                  sync_period=10))\nmodel.summary()","90fd3880":"FOLD = 10\nNUM_SEED = 3\nVERBOSE = 0\n\nnp.random.seed(3)\nseeds = np.random.randint(0, 100, size=NUM_SEED)\n\noof_score = 0\ny_pred_meta_dnn = np.zeros((Xtrain.shape[0], 9))\ny_pred_final_dnn = np.zeros((Xtest.shape[0], 9))\ncounter = 0\nmini_batch_size = 128\n\n\nfor sidx, seed in enumerate(seeds):\n    seed_score = 0\n    \n    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n    for idx, (train, val) in enumerate(kfold.split(Xtrain, Ytrain)):\n        counter += 1\n\n        train_x, train_y, train_y_oh = Xtrain.iloc[train], Ytrain.iloc[train], Ytrain_oh.iloc[train]\n        val_x, val_y, val_y_oh = Xtrain.iloc[val], Ytrain.iloc[val], Ytrain_oh.iloc[val]\n\n        model = dnn_model(Xtrain.shape[1])\n        model.compile(loss='categorical_crossentropy',\n                      optimizer=Lookahead(AdamW(lr=1e-2, \n                                                weight_decay=1e-5, \n                                                clipvalue=700), \n                                          sync_period=10))\n\n        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                              restore_best_weights=True, \n                              patience=7, verbose=VERBOSE)\n\n        reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n                                      min_lr=1e-6, patience=3, \n                                      verbose=VERBOSE, mode='min')\n\n        chk_point = ModelCheckpoint('.\/DNN_model.h5', \n                                    monitor='val_loss', verbose=VERBOSE, \n                                    save_best_only=True, mode='min')\n        \n        history = model.fit(\n            train_x, train_y_oh, \n            batch_size=mini_batch_size,\n            epochs=250, \n            verbose=VERBOSE, \n            workers=5,\n            callbacks=[reduce_lr, early, chk_point], \n            validation_data=(val_x, val_y_oh)\n        )\n        \n        model = load_model('.\/DNN_model.h5')\n\n        y_pred = model.predict(val_x)\n        y_pred_meta_dnn[val] += y_pred\n        y_pred_final_dnn += model.predict(Xtest)\n        \n        score = log_loss(val_y_oh, y_pred)\n        oof_score += score\n        seed_score += score\n        print(\"Seed-{} | Fold-{} | OOF Score: {}\".format(seed, idx, score))\n    \n    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score \/ FOLD)))\n\n\ny_pred_meta_dnn = y_pred_meta_dnn \/ float(NUM_SEED)\ny_pred_final_dnn = y_pred_final_dnn \/ float(counter)\noof_score \/= float(counter)\nprint(\"Aggregate OOF Score: {}\".format(oof_score))","2a15e1e5":"np.savez_compressed('.\/DNN_Meta_Features.npz',\n                    y_pred_meta_dnn=y_pred_meta_dnn, \n                    oof_score=oof_score,\n                    y_pred_final_dnn=y_pred_final_dnn)","3085627f":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nsubmit_df = pd.DataFrame()\nsubmit_df['id'] = test_df['id']\nsubmit_df['Class_1'] = y_pred_final_dnn[:,1]\nsubmit_df['Class_2'] = y_pred_final_dnn[:,2]\nsubmit_df['Class_3'] = y_pred_final_dnn[:,3]\nsubmit_df['Class_4'] = y_pred_final_dnn[:,4]\nsubmit_df['Class_5'] = y_pred_final_dnn[:,5]\nsubmit_df['Class_6'] = y_pred_final_dnn[:,6]\nsubmit_df['Class_7'] = y_pred_final_dnn[:,7]\nsubmit_df['Class_8'] = y_pred_final_dnn[:,8]\nsubmit_df['Class_9'] = y_pred_final_dnn[:,0]\nsubmit_df.head()","c9e51a0b":"submit_df.to_csv(\".\/DNN_submission.csv\", index=False)","6b30ac77":"## Create submission file","fdc38ba2":"## Import libraries","05262cbb":"## Build the model","7d45c771":"## Prepare data for model training"}}