{"cell_type":{"14089d3e":"code","9ddb0d8b":"code","60fd2b1e":"code","f462f652":"code","b6894a7c":"code","7037afca":"code","810ed56e":"code","3c4efbe5":"code","2602efe3":"code","2ff8fc02":"code","61fab950":"code","7d8128eb":"code","36a76c02":"code","1e33451c":"code","c6c42eb2":"code","9067511c":"code","7cb9e209":"code","f676e9fd":"code","72fdcfc0":"code","39c2aeb9":"code","eec6ff15":"code","ec1baab9":"code","d6eb9100":"code","ec803180":"code","ac902cbc":"code","c85e2883":"code","7da91c49":"code","191ede81":"code","79e31a79":"code","e9cdabf7":"code","4dc247cc":"code","b5491eab":"code","b78e8a25":"code","db056c4e":"code","286a8856":"code","6b8eec2d":"code","5a7ea35b":"markdown","9b8bb4c8":"markdown","d8edfa0a":"markdown","c732e6f4":"markdown","d1c8a6bb":"markdown","e9df9108":"markdown","bb5a4c94":"markdown","884b39af":"markdown","ba2e2e64":"markdown","a8724729":"markdown","2239d03f":"markdown","056fc154":"markdown","9c122839":"markdown","6b724ea7":"markdown","7f67b6ad":"markdown","e65cc12a":"markdown","4650b7ef":"markdown","259238fb":"markdown","dc2d12ed":"markdown","6ceec9da":"markdown","ab8f4a17":"markdown","2828c710":"markdown","c65bc4e5":"markdown","6640d6d2":"markdown","205942cb":"markdown","ffdf87b2":"markdown","d54a5e7e":"markdown","13374965":"markdown","ad27c55c":"markdown","abbeac76":"markdown","67ac24bb":"markdown","1134fff3":"markdown","67f49549":"markdown","2ce7e990":"markdown","9c92eebf":"markdown","b2dbf9b2":"markdown","d961e0f5":"markdown","4540c131":"markdown","7b6a8c2f":"markdown","d69e344c":"markdown","33a72c9c":"markdown"},"source":{"14089d3e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9ddb0d8b":"import numpy as np \nimport pandas as pd\nimport pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n%matplotlib inline\nimport seaborn as sns; sns.set()\n\nfrom sklearn import tree\nimport graphviz \nimport os\nimport preprocessing \n\nimport numpy as np \nimport pandas as pd \nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, f_classif\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom xgboost import plot_tree, plot_importance\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","60fd2b1e":"dataset = pandas.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndataset.sample(10)","f462f652":"dataset.drop(\"id\", axis=1, inplace=True)\ndataset.drop(\"Unnamed: 32\", axis=1, inplace=True)","b6894a7c":"dataset.info()","7037afca":"dataset.describe()","810ed56e":"#This code is retrieved from here: https:\/\/www.kaggle.com\/kanncaa1\/dataiteam-titanic-eda#Introduction\n\ndef detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","3c4efbe5":"columns = list(dataset.columns)\ncolumns.remove('diagnosis')","2602efe3":"dataset.loc[detect_outliers(dataset,columns)]","2ff8fc02":"# drop outliers\ndataset = dataset.drop(detect_outliers(dataset,columns),axis = 0).reset_index(drop = True)","61fab950":"for i in columns:\n    dataset = dataset[dataset[i] != 0]","7d8128eb":"plt.figure(figsize=(12,8)) \nsns.heatmap(dataset.corr(), annot=False, cmap='Set3', linewidths = 2)\nplt.show()","36a76c02":"plt.figure(figsize=(20, 10))\nsns.set_style('white')\nmask = np.triu(np.ones_like(dataset.corr(), dtype=np.bool))\nheatmap = sns.heatmap(dataset.corr(), mask=mask,annot=False, cmap='Set3', linewidths = 2)\nheatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':30}, pad=16);","1e33451c":"dataset.agg(['skew'])","c6c42eb2":"skews = ['area_mean', 'concavity_mean', 'radius_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'symmetry_se', 'fractal_dimension_se', 'area_worst', 'compactness_worst', 'fractal_dimension_worst' ]","9067511c":"from scipy.stats import norm, skew, boxcox\nfor i in skews:\n    sns.set_style('darkgrid')\n    sns.distplot(dataset[i], fit = norm)\n    plt.title('Skeweed')\n    plt.show()\n    (mu, sigma) = norm.fit(dataset[i])\n    print(\"mu {} : {}, sigma {} : {}\".format(i, mu, i, sigma))\n    print()\n    \n    dataset[i], lam = boxcox(dataset[i])\n\n    sns.set_style('darkgrid')\n    sns.distplot(dataset[i], fit = norm)\n    plt.title('Transformed')\n    plt.show()\n    (mu, sigma) = norm.fit(dataset[i])\n    print(\"mu {} : {}, sigma {} : {}\".format(i, mu, i, sigma))\n    print()","7cb9e209":"dataset.agg(['skew', 'kurtosis']).transpose()","f676e9fd":"dataset['diagnosis'].unique()","72fdcfc0":"diagnosis_mapping = {'M': 0, 'B': 1}\ndataset['diagnosis'] = dataset['diagnosis'].map(diagnosis_mapping)","39c2aeb9":"features = columns\nlabel = ['diagnosis']\n\nX = dataset[features]\ny = dataset[label]","eec6ff15":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101) \nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n\nprint(f'Total # of sample in whole dataset: {len(X)}')\nprint(f'Total # of sample in train dataset: {len(X_train)}')\nprint(f'Total # of sample in validation dataset: {len(X_valid)}')\nprint(f'Total # of sample in test dataset: {len(X_test)}')","ec1baab9":"pipeline_GaussianNB = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_GaussianNB\",GaussianNB())])\n\npipeline_BernoulliNB = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_BernoulliNB\",BernoulliNB())])\n\npipeline_LogisticRegression = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_LogisticRegression\",LogisticRegression())])\n\npipeline_RandomForest = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_RandomForest\",RandomForestClassifier())])\n\npipeline_SVM = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_SVM\",SVC())])\n\npipeline_DecisionTree = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_DecisionTree\",DecisionTreeClassifier())])\n\npipeline_KNN = Pipeline([(\"scaler\",StandardScaler()),\n                     (\"pipeline_KNN\",KNeighborsClassifier())])\n\npipeline_GBC = Pipeline([(\"scaler\",StandardScaler()), (\n                        \"pipeline_GBC\",GradientBoostingClassifier())])\n\npipeline_SGD = Pipeline([(\"scaler\",StandardScaler()), \n                        (\"pipeline_SGD\",SGDClassifier(max_iter=5000, random_state=0))])\n\npipeline_NN = Pipeline([(\"scaler\",StandardScaler()), \n                        (\"pipeline_NN\",MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1))])\n\npipelines = [pipeline_GaussianNB, pipeline_BernoulliNB, pipeline_LogisticRegression, pipeline_RandomForest, pipeline_SVM, pipeline_DecisionTree, pipeline_KNN, pipeline_GBC, pipeline_SGD, pipeline_NN]\n\npipe_dict = {0: \"GaussianNB\", 1: \"BernoulliNB\", 2: \"LogisticRegression\",3: \"RandomForestClassifier\", 4: \"SupportVectorMachine\", 5: \"DecisionTreeClassifier\",\n            6: \"KNeighborsClassifier\", 7: \"GradientBoostingClassifier\", 8:\"Stochastic Gradient Descent\", 9: \"Neural Nets\"}\n\nfor pipe in pipelines:\n    pipe.fit(X_train, y_train)","d6eb9100":"cv_results_acc = []\n\nfor i, model in enumerate(pipelines):\n    cv_score = cross_val_score(model, X_train, y_train, scoring = \"accuracy\", cv = 10)\n    cv_results_acc.append(cv_score)\n    print(\"%s: %f\" % (pipe_dict[i], cv_score.mean()*100))","ec803180":"train_score = pipeline_SVM.score(X_train, y_train)\nprint(f'Train score of trained model     : {train_score*100}')\n\nvalidation_score = pipeline_SVM.score(X_valid, y_valid)\nprint(f'Validation score of trained model: {validation_score*100}')\n\ntest_score = pipeline_SVM.score(X_test, y_test)\nprint(f'Test score of trained model      : {test_score*100}')","ac902cbc":"pred = pipeline_SVM.predict(X_test)","c85e2883":"conf_matrix = confusion_matrix(pred, y_test)\n\nprint(f'Confussion Matrix: \\n{conf_matrix}\\n')\n\nsns.heatmap(conf_matrix, annot=True)","7da91c49":"tn = conf_matrix[0,0]\nfp = conf_matrix[0,1]\ntp = conf_matrix[1,1]\nfn = conf_matrix[1,0]\n\ntotal = tn + fp + tp + fn\nreal_positive = tp + fn\nreal_negative = tn + fp","191ede81":"accuracy  = (tp + tn) \/ total # Accuracy Rate\nprecision = tp \/ (tp + fp) # Positive Predictive Value\nrecall    = tp \/ (tp + fn) # True Positive Rate\nf1score  = 2 * precision * recall \/ (precision + recall)\nspecificity = tn \/ (tn + fp) # True Negative Rate\nerror_rate = (fp + fn) \/ total # Missclassification Rate\nprevalence = real_positive \/ total\nmiss_rate = fn \/ real_positive # False Negative Rate\nfall_out = fp \/ real_negative # False Positive Rate\n\nprint(f'Accuracy    : {accuracy}')\nprint(f'Precision   : {precision}')\nprint(f'Recall      : {recall}')\nprint(f'F1 score    : {f1score}')\nprint(f'Specificity : {specificity}')\nprint(f'Error Rate  : {error_rate}')\nprint(f'Prevalence  : {prevalence}')\nprint(f'Miss Rate   : {miss_rate}')\nprint(f'Fall Out    : {fall_out}')","79e31a79":"print(classification_report(pred, y_test))","e9cdabf7":"print(\"accuracy           :\", metrics.accuracy_score(y_test, pred)*100)","4dc247cc":"print(\"balanced_accuracy  :\", metrics.balanced_accuracy_score(y_test, pred))","b5491eab":"print(\"top_k_accuracy     :\", metrics.top_k_accuracy_score(y_test, pred)*100)","b78e8a25":"print(\"Cohen\u2019s Kappa      :\", metrics.cohen_kappa_score(y_test, pred))","db056c4e":"print(\"average_precision  :\", metrics.average_precision_score(y_test, pred)*100)","286a8856":"print(\"neg_log_loss       :\", metrics.log_loss(y_test, pred)*100)","6b8eec2d":"print(\"jaccard            :\", metrics.jaccard_score(y_test, pred)*100)","5a7ea35b":"<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mtext mathvariant=\"monospace\">top-k accuracy<\/mtext>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>y<\/mi>\n  <mo>,<\/mo>\n  <mrow>\n    <mover>\n      <mi>f<\/mi>\n      <mo stretchy=\"false\">^<\/mo>\n    <\/mover>\n  <\/mrow>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>=<\/mo>\n  <mfrac>\n    <mn>1<\/mn>\n    <msub>\n      <mi>n<\/mi>\n      <mtext>samples<\/mtext>\n    <\/msub>\n  <\/mfrac>\n  <munderover>\n    <mo data-mjx-texclass=\"OP\">&#x2211;<\/mo>\n    <mrow>\n      <mi>i<\/mi>\n      <mo>=<\/mo>\n      <mn>0<\/mn>\n    <\/mrow>\n    <mrow>\n      <msub>\n        <mi>n<\/mi>\n        <mtext>samples<\/mtext>\n      <\/msub>\n      <mo>&#x2212;<\/mo>\n      <mn>1<\/mn>\n    <\/mrow>\n  <\/munderover>\n  <munderover>\n    <mo data-mjx-texclass=\"OP\">&#x2211;<\/mo>\n    <mrow>\n      <mi>j<\/mi>\n      <mo>=<\/mo>\n      <mn>1<\/mn>\n    <\/mrow>\n    <mrow>\n      <mi>k<\/mi>\n    <\/mrow>\n  <\/munderover>\n  <mn>1<\/mn>\n  <mo stretchy=\"false\">(<\/mo>\n  <msub>\n    <mrow>\n      <mover>\n        <mi>f<\/mi>\n        <mo stretchy=\"false\">^<\/mo>\n      <\/mover>\n    <\/mrow>\n    <mrow>\n      <mi>i<\/mi>\n      <mo>,<\/mo>\n      <mi>j<\/mi>\n    <\/mrow>\n  <\/msub>\n  <mo>=<\/mo>\n  <msub>\n    <mi>y<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo stretchy=\"false\">)<\/mo>\n<\/math>","9b8bb4c8":"<a id = \"22\"><\/a>\n### Jaccard Similarity Coefficient Score\n\nThe Jaccard index, or Jaccard similarity coefficient, defined as the size of the intersection divided by the size of the union of two label sets, is used to compare set of predicted labels for a sample to the corresponding set of labels in y_true.\n\nThe Jaccard similarity coefficient of the <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <mi>i<\/mi>\n<\/math>-th samples, with a ground truth label set <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <msub>\n    <mi>y<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n<\/math>\n and predicted label set <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <msub>\n    <mrow>\n      <mover>\n        <mi>y<\/mi>\n        <mo stretchy=\"false\">^<\/mo>\n      <\/mover>\n    <\/mrow>\n    <mi>i<\/mi>\n  <\/msub>\n<\/math>\n, is defined as\n\n<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mi>J<\/mi>\n  <mo stretchy=\"false\">(<\/mo>\n  <msub>\n    <mi>y<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo>,<\/mo>\n  <msub>\n    <mrow>\n      <mover>\n        <mi>y<\/mi>\n        <mo stretchy=\"false\">^<\/mo>\n      <\/mover>\n    <\/mrow>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>=<\/mo>\n  <mfrac>\n    <mrow>\n      <mo stretchy=\"false\">|<\/mo>\n      <msub>\n        <mi>y<\/mi>\n        <mi>i<\/mi>\n      <\/msub>\n      <mo>&#x2229;<\/mo>\n      <msub>\n        <mrow>\n          <mover>\n            <mi>y<\/mi>\n            <mo stretchy=\"false\">^<\/mo>\n          <\/mover>\n        <\/mrow>\n        <mi>i<\/mi>\n      <\/msub>\n      <mo stretchy=\"false\">|<\/mo>\n    <\/mrow>\n    <mrow>\n      <mo stretchy=\"false\">|<\/mo>\n      <msub>\n        <mi>y<\/mi>\n        <mi>i<\/mi>\n      <\/msub>\n      <mo>&#x222A;<\/mo>\n      <msub>\n        <mrow>\n          <mover>\n            <mi>y<\/mi>\n            <mo stretchy=\"false\">^<\/mo>\n          <\/mover>\n        <\/mrow>\n        <mi>i<\/mi>\n      <\/msub>\n      <mo stretchy=\"false\">|<\/mo>\n    <\/mrow>\n  <\/mfrac>\n  <mo>.<\/mo>\n<\/math>","d8edfa0a":"I applied SVM on Breast Cancer in this notebook. I explained the Skewness problem and showed its solution. I examined the results of the model under the title of evaluation metrics and gave information about these metrics. In total, I explained 9 evaluation metrics and showed their calculations.","c732e6f4":"***NOTE:*** *Thank you to Karnika Kapoor for letting me use her pipeline. The original code is available here:* https:\/\/www.kaggle.com\/karnikakapoor\/diamond-price-prediction\/comments","d1c8a6bb":"* In the formula, n is the number of samples, xm is the arithmetic mean of the array (sample mean), and 's' is its standard deviation.\n\n* As the value of skewness moves towards plus infinity, the force of negative skewness increases as it moves towards positive and minus infinity.\n\nSource for this explanation: https:\/\/teachtomachines.com\/2020\/07\/07\/log-donusumu-ile-carpiklik-giderme\/","e9df9108":"![image.png](attachment:878fcc78-edd1-4b88-93d2-d1c45b8c69ef.png)","bb5a4c94":"<a id = \"12\"><\/a>\n## Confusion Matrix\n\nConfusion matrix is a measurement tool that provides information about the accuracy of predictions. The logic behind it is actually simple, but it is often used especially in classification algorithms as it provides easy to understand information about the accuracy of the measurement.","884b39af":"<a id = \"2\"><\/a>\n# Read Datas & Explanation of Features & Information About Datasets","ba2e2e64":"* diagnosis              --> The diagnosis of breast tissues (M = malignant, B = benign)\n* radius_mean            --> mean of distances from center to points on the perimeter\n* texture_mean           --> standard deviation of gray-scale values\n* perimeter_mean         --> mean size of the core tumor\n* area_mean              -->\n* smoothness_mean        --> mean of local variation in radius lengths\n* compactness_mean       --> mean of perimeter^2 \/ area - 1.0\n* concavity_mean         --> mean of severity of concave portions of the contour\n* concave points_mean    --> mean for number of concave portions of the contour\n* symmetry_mean          -->\n* fractal_dimension_mean --> mean for \"coastline approximation\" - 1\n* radius_se              --> standard error for the mean of distances from center to points on the perimeter\n* texture_se             --> standard error for standard deviation of gray-scale values\n* perimeter_se           -->\n* area_se                -->\n* smoothness_se          --> standard error for local variation in radius lengths\n* compactness_se         --> standard error for perimeter^2 \/ area - 1.0\n* concavity_se           --> standard error for severity of concave portions of the contour\n* concave points_se      --> standard error for number of concave portions of the contour\n* symmetry_se            -->\n* fractal_dimension_se   --> standard error for \"coastline approximation\" - 1\n* radius_worst           --> \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n* texture_worst          --> \"worst\" or largest mean value for standard deviation of gray-scale values\n* perimeter_worst        -->\n* area_worst             -->\n* smoothness_worst       --> \"worst\" or largest mean value for local variation in radius lengths\n* compactness_worst      --> \"worst\" or largest mean value for perimeter^2 \/ area - 1.0\n* concavity_worst        --> \"worst\" or largest mean value for severity of concave portions of the contour\n* concave points_worst   --> \"worst\" or largest mean value for number of concave portions of the contour\n* symmetry_wors          -->\n* fractal_dimension_worst--> \"worst\" or largest mean value for \"coastline approximation\" - 1","a8724729":"![image.png](attachment:8e8b7eef-9876-41e9-8b5c-40765c87c317.png)","2239d03f":"<a id = \"19\"><\/a>\n### Cohen\u2019s Kappa\n\nThe function cohen_kappa_score computes Cohen\u2019s kappa statistic. This measure is intended to compare labelings by different human annotators, not a classifier versus a ground truth.\n\nThe kappa score (see docstring) is a number between -1 and 1. Scores above .8 are generally considered good agreement; zero or lower means no agreement (practically random labels).","056fc154":"<a id = \"8\"><\/a>\n# Train - Test Split","9c122839":"<a id = \"20\"><\/a>\n### Average Precision\n\nAP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:","6b724ea7":"**NOTE:** This explanations and formulas were taken from scikit-learn library documentation. You can access documentation via this link: https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#jaccard-similarity-coefficient-score","7f67b6ad":"<a id = \"13\"><\/a>\n## Performance Measures\n\n**TP - True Positive:** The model correctly predicted the positive class as a positive class.\n\n**FP - False Positive:** The model predicted the negative class as a false positive class.\n\n**FN - False Negative:** The model predicted the positive class as false, negative class.\n\n**TN - True Negative:** The model predicted the negative class correctly.","e65cc12a":"<a id = \"23\"><\/a>\n# Conclusion\n\nI tried to explain classification evaluation metrics.\n\n* Quotations are indicated by links.\n* If you have questions, please comment them. I will try to explain if you don't understand.\n* If you liked this notebook, please let me know :)\n\nThank you for your time.","4650b7ef":"<a id = \"9\"><\/a>\n# Pipelines","259238fb":"<a id = \"11\"><\/a>\n# Evaluation Metrics","dc2d12ed":"<a id = \"10\"><\/a>\n# Support Vector Machine","6ceec9da":"<a id = \"21\"><\/a>\n### Log Loss\n\nLog loss, aka logistic loss or cross-entropy loss.\n\nThis is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true. The log loss is only defined for two or more labels. For a single sample with true label <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <mi>y<\/mi>\n  <mo>&#x2208;<\/mo>\n  <mo fence=\"false\" stretchy=\"false\">{<\/mo>\n  <mn>0<\/mn>\n  <mo>,<\/mo>\n  <mn>1<\/mn>\n  <mo fence=\"false\" stretchy=\"false\">}<\/mo>\n<\/math> and a probability estimate <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <mi>p<\/mi>\n  <mo>=<\/mo>\n  <mi>Pr<\/mi>\n  <mo data-mjx-texclass=\"NONE\">&#x2061;<\/mo>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>y<\/mi>\n  <mo>=<\/mo>\n  <mn>1<\/mn>\n  <mo stretchy=\"false\">)<\/mo>\n<\/math>, the log loss is:\n\n\n<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <mi>p<\/mi>\n  <mo>=<\/mo>\n  <mi>Pr<\/mi>\n  <mo data-mjx-texclass=\"NONE\">&#x2061;<\/mo>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>y<\/mi>\n  <mo>=<\/mo>\n  <mn>1<\/mn>\n  <mo stretchy=\"false\">)<\/mo>\n<\/math>","ab8f4a17":"It can be said that skewness is the name given to the distortion of symmetry in data distribution in continuous or in other words, non-categorical data sets. In other words, it is the criterion of asymmetry. In summary, it is expected that the distribution of the data sets will show a normal distribution, but if the available data is contrary to this, it can be mentioned that the data is skewed. These distortions are among the reasons that prevent some machine learning models from learning from data, similar to the effect of imbalanced datasets used for categorical data.\n\nIn the image below, there is a graph showing the number of records belonging to three different data sets. In the data set with a symmetrical distribution as in the green graph, mode median and mean values are equal. In other words, the most frequently found number is both the median number and the average. The situation in the orange graph is expressed as positive skewness, and the situation in the blue graph as negative skewness.","2828c710":"<a id = \"4\"><\/a>\n# Anomaly Detection","c65bc4e5":"**Accuracy Rate:** A measure of how often the classifier predicts correctly.\n\n**Precision:** It shows how many of the values we guess as Positive are actually Positive.\n\n**Recall:** It is a measure of how much the classifier correctly predicts the true positive value. Also known as Sensitivity, Accuracy or Recall. (Sensitivity, Hit Rate or Recall) It should be as high as possible.\n\n**F1 Score:** F1 Score value shows the harmonic mean of Precision and Recall values. The reason why it is a harmonic average instead of a simple average is that we should not ignore extreme cases. If there was a simple average calculation, the F1 Score of a model with a Precision value of 1 and a Recall value of 0 would come as 0.5, and this would mislead us.\n\n**Specificity:** It is a measure of how much the classifier correctly predicted the true negative value.\n\n**Misclassification Rate (Error Rate):** It is a measure of how often the classifier guesses incorrectly. Also known as Error Rate.\n\n**Prevalence:** It is the measure of how often a value of 1 is found at the end of the estimation.\n\n**Miss Rate:** It is the ratio of those predicted to be 0 despite the real value being 1. Also known as loss rate.\n\n**Fall out:** It is the ratio of those predicted to be 1 even though the real value is 0.","6640d6d2":"<a id = \"18\"><\/a>\n### Top-k Accuracy Score\n\nThis metric computes the number of times where the correct label is among the top k labels predicted (ranked by predicted scores). Note that the multilabel case isn\u2019t covered here.","205942cb":"<a id = \"14\"><\/a>\n## Classification Report","ffdf87b2":"Accuracy classification score.\n\nIn multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.","d54a5e7e":"<a id = \"6\"><\/a>\n# Skewness","13374965":"<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mtext>AP<\/mtext>\n  <mo>=<\/mo>\n  <munder>\n    <mo data-mjx-texclass=\"OP\">&#x2211;<\/mo>\n    <mi>n<\/mi>\n  <\/munder>\n  <mo stretchy=\"false\">(<\/mo>\n  <msub>\n    <mi>R<\/mi>\n    <mi>n<\/mi>\n  <\/msub>\n  <mo>&#x2212;<\/mo>\n  <msub>\n    <mi>R<\/mi>\n    <mrow>\n      <mi>n<\/mi>\n      <mo>&#x2212;<\/mo>\n      <mn>1<\/mn>\n    <\/mrow>\n  <\/msub>\n  <mo stretchy=\"false\">)<\/mo>\n  <msub>\n    <mi>P<\/mi>\n    <mi>n<\/mi>\n  <\/msub>\n<\/math>","ad27c55c":"where <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <msub>\n    <mi>P<\/mi>\n    <mi>n<\/mi>\n  <\/msub>\n<\/math> and <math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\">\n  <msub>\n    <mi>R<\/mi>\n    <mi>n<\/mi>\n  <\/msub>\n<\/math> are the precision and recall at the nth threshold. This implementation is not interpolated and is different from computing the area under the precision-recall curve with the trapezoidal rule, which uses linear interpolation and can be too optimistic.","abbeac76":"<a id = \"7\"><\/a>\n# Label Encoding","67ac24bb":"Anomaly is one that differs \/ deviates significantly from other observations in the same sample. An anomaly detection pattern produces two different results. The first is a categorical tag for whether the observation is abnormal or not; the second is a score or trust value. Score carries more information than the label. Because it also tells us how abnormal the observation is. The tag just tells you if it's abnormal. While labeling is more common in supervised methods, the score is more common in unsupervised and semisupervised methods.","1134fff3":"<a id = \"17\"><\/a>\n### Balanced Accuracy\n\nThe balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n\nThe best value is 1 and the worst value is 0.","67f49549":"## Content:\n\n1. [Importing the Necessary Libraries](#1)\n1. [Read Datas & Explanation of Features & Information About Datasets](#2)\n   1. [Variable Descriptions](#3)\n1. [Anomaly Detection](#4)\n1. [Skewness](#5)\n1. [Correlation](#6)\n1. [Label Encoding](#7)\n1. [Train-Test Split](#8)\n1. [Pipelines](#9)\n   1. [Support Vector Machine](#10)   \n1. [Evaluation Metrics](#11)\n   1. [Confusion Matrix](#12)\n   1. [Statistics](#13)\n   1. [Classification Report](#14)\n   1. [Classification Metrics and Scoring (scikit-learn)](#15)\n      1. [Accuracy](#16)\n      1. [Balanced Accuracy](#17)\n      1. [Top-k Accuracy Score](#18)\n      1. [Cohen\u2019s Kappa](#19)\n      1. [Average Precision](#20)\n      1. [Log Loss](#21)\n      1. [Jaccard Similarity Coefficient Score](#22)\n1. [Conclusion](#23)   ","2ce7e990":"<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mtext mathvariant=\"monospace\">balanced-accuracy<\/mtext>\n  <mo>=<\/mo>\n  <mfrac>\n    <mn>1<\/mn>\n    <mn>2<\/mn>\n  <\/mfrac>\n  <mrow data-mjx-texclass=\"INNER\">\n    <mo data-mjx-texclass=\"OPEN\">(<\/mo>\n    <mfrac>\n      <mrow>\n        <mi>T<\/mi>\n        <mi>P<\/mi>\n      <\/mrow>\n      <mrow>\n        <mi>T<\/mi>\n        <mi>P<\/mi>\n        <mo>+<\/mo>\n        <mi>F<\/mi>\n        <mi>N<\/mi>\n      <\/mrow>\n    <\/mfrac>\n    <mo>+<\/mo>\n    <mfrac>\n      <mrow>\n        <mi>T<\/mi>\n        <mi>N<\/mi>\n      <\/mrow>\n      <mrow>\n        <mi>T<\/mi>\n        <mi>N<\/mi>\n        <mo>+<\/mo>\n        <mi>F<\/mi>\n        <mi>P<\/mi>\n      <\/mrow>\n    <\/mfrac>\n    <mo data-mjx-texclass=\"CLOSE\">)<\/mo>\n  <\/mrow>\n<\/math>","9c92eebf":"<a id = \"16\"><\/a>\n### Accuracy","b2dbf9b2":"<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mtext mathvariant=\"monospace\">accuracy<\/mtext>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>y<\/mi>\n  <mo>,<\/mo>\n  <mrow>\n    <mover>\n      <mi>y<\/mi>\n      <mo stretchy=\"false\">^<\/mo>\n    <\/mover>\n  <\/mrow>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>=<\/mo>\n  <mfrac>\n    <mn>1<\/mn>\n    <msub>\n      <mi>n<\/mi>\n      <mtext>samples<\/mtext>\n    <\/msub>\n  <\/mfrac>\n  <munderover>\n    <mo data-mjx-texclass=\"OP\">&#x2211;<\/mo>\n    <mrow>\n      <mi>i<\/mi>\n      <mo>=<\/mo>\n      <mn>0<\/mn>\n    <\/mrow>\n    <mrow>\n      <msub>\n        <mi>n<\/mi>\n        <mtext>samples<\/mtext>\n      <\/msub>\n      <mo>&#x2212;<\/mo>\n      <mn>1<\/mn>\n    <\/mrow>\n  <\/munderover>\n  <mn>1<\/mn>\n  <mo stretchy=\"false\">(<\/mo>\n  <msub>\n    <mrow>\n      <mover>\n        <mi>y<\/mi>\n        <mo stretchy=\"false\">^<\/mo>\n      <\/mover>\n    <\/mrow>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo>=<\/mo>\n  <msub>\n    <mi>y<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo stretchy=\"false\">)<\/mo>\n<\/math>","d961e0f5":"<a id = \"3\"><\/a>\n## Variable Descriptions","4540c131":"<a id = \"5\"><\/a>\n# Correlation","7b6a8c2f":"<a id = \"1\"><\/a>\n# Importing the Necessary Libraries","d69e344c":"# Breast Cancer Classification with Support Vector Machine and Classification Evaluation Metrics","33a72c9c":"<a id = \"15\"><\/a>\n## Classification Metrics and Scoring (scikit-learn)"}}