{"cell_type":{"3577ec19":"code","a4d16a99":"code","c751d59b":"code","e8fee8ba":"code","976b8a4f":"code","340caa80":"code","c5a7f55b":"code","6da73090":"code","80ae888a":"code","55e1a963":"code","6df3c934":"code","9dc54627":"code","e890371e":"code","e0849824":"markdown","036a6586":"markdown","84bd026d":"markdown"},"source":{"3577ec19":"#Importing Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets","a4d16a99":"#Loading the dataset\n\niris = datasets.load_iris()\n\n#Converting into dataframe\n\niris_df = pd.DataFrame(iris.data,columns=iris.feature_names)\niris_df.head()  # to see the first 5 rows","c751d59b":"# Checking for null values\n\niris_df.isnull().sum()","e8fee8ba":"iris_df.shape","976b8a4f":"# Checking for duplicate rows\n\niris_df.duplicated().sum()","340caa80":"#Dropping the duplicate row\n\niris_df.drop_duplicates(inplace=True)","c5a7f55b":"iris_df.shape","6da73090":"# Checking for outliers\n\nfor i in iris_df.columns:\n  if iris_df[i].dtype=='float64':\n    plt.boxplot(iris_df[i])\n    plt.show()","80ae888a":"# Removing outliers using IQR method\n\nQ1,Q3=np.percentile(iris_df['sepal width (cm)'],[25,75])\nIQR=Q3-Q1\nlower=Q1-1.5*IQR\nupper=Q3+1.5*IQR\niris_df['sepal width (cm)']=iris_df['sepal width (cm)'].apply(lambda x: lower if x < lower else upper if x > upper else x)\nplt.boxplot(x=iris_df['sepal width (cm)'])\nplt.show()\n\n","55e1a963":"x = iris_df.iloc[:,[0,1,2,3]].values\n\nfrom sklearn.cluster import KMeans\nwcss=[]                            # Within Cluster Sum of Squares\nfor i in range(1,11):\n  kmeans=KMeans(n_clusters=i,init='k-means++',n_init=10,max_iter=300,random_state=0)\n  kmeans.fit(x)\n  wcss.append(kmeans.inertia_)","6df3c934":"# plotting the results inorder to find the 'The elbow'\n\nplt.plot(range(1,11),wcss,'deeppink')\nplt.title('The elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","9dc54627":"# Clustering\n\nkmeans=KMeans(n_clusters=3,init='k-means++',n_init=10,max_iter=300,random_state=0)\ny = kmeans.fit_predict(x)","e890371e":"# Visualising the clusters on the first two columns\n\nplt.scatter(x[y==0,0],x[y==0,1],s=90,c='plum',label='Iris-setosa',alpha=0.75)\nplt.scatter(x[y==1,0],x[y==1,1],s=90,c='teal',label='Iris-versicolor',alpha=0.75)\nplt.scatter(x[y==2,0],x[y==2,1],s=90,c='steelblue',label='Iris-virginica',alpha=0.75)\n\n#Plotting the centroids of the clusters\n\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=90,c='yellow',label='Centroids')\nplt.legend()\n","e0849824":"From this graph, we can see exactly where the elbow occurs.That is the point from where the WCSS doesn't decrease significantly with every iteration<br>\n\nIn this graph, the elbow seems to be where the number of clusters is 3. So we take K as 3\n","036a6586":"Finding the optimum number of clusters needed ","84bd026d":"**Thus we have clustered the given Iris dataset into three clusters**"}}