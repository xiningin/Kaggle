{"cell_type":{"8b6fd409":"code","72480a74":"code","700d0071":"code","b309154c":"code","adc2d62c":"code","e1568a8a":"code","f094b397":"code","28a502bc":"code","ac005e45":"code","eef346bd":"code","7fd06fa5":"code","34d2658d":"code","0f99c801":"code","10bbf426":"code","07c5a610":"code","ed09bcdc":"code","38714cc6":"code","1da14416":"code","357cde91":"code","cd789dbe":"code","505182c8":"code","13b213f1":"code","b17c5780":"code","a8e40e71":"code","d83bd9e2":"code","9fdc8641":"markdown"},"source":{"8b6fd409":"import os, cv2\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.keras.preprocessing import image\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, AvgPool2D\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.layers import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, array_to_img, load_img\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import shuffle\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","72480a74":"# TensorFlow and tf.kerasimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing import image# Helper libraries\nimport matplotlib.pyplot as pl\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","700d0071":"fpath = \"..\/input\/car-and-truck\/Datasets\/car\/100171.jpg\"\nimg=plt.imread(fpath)\nplt.imshow(img)\nplt.show()","b309154c":"fpath = \"..\/input\/car-and-truck\/Datasets\/truck\/108960305.jpg\"\nimg=plt.imread(fpath)\nplt.imshow(img)\nplt.show()","adc2d62c":"img = image.load_img(fpath, target_size=(224, 224))\nimg_array = image.img_to_array(img)\nimg_batch = np.expand_dims(img_array, axis=0)\nimg_preprocessed = preprocess_input(img_batch)\n","e1568a8a":"model = tf.keras.applications.resnet50.ResNet50()","f094b397":"prediction = model.predict(img_preprocessed)","28a502bc":"print(decode_predictions(prediction, top=3)[0])","ac005e45":"data_dir = '..\/input\/car-and-truck\/Datasets\/'\n\nimages = []\ncar_types = []\nfor car_type in [\"car\",\"truck\"]:\n    car_dir = data_dir + car_type\n    car_files = [car_dir + '\/' + filename for filename in os.listdir(car_dir)]\n    #print(car_files)\n    for filename in car_files:\n        if filename.endswith('jpg'):\n            try:\n                images.append(cv2.resize(cv2.imread(filename), (224,224), interpolation=cv2.INTER_CUBIC))\n                car_types.append(car_type)\n            except Exception as e:\n                print(str(e))\n            \n            \nimages = np.array(images)\ncar_types = np.array(car_types)\n\nle = LabelEncoder()\ncar_types_encoded = le.fit_transform(car_types)\ncar_types_encoded_onehot = np_utils.to_categorical(car_types_encoded)","eef346bd":"print(car_types_encoded_onehot)","7fd06fa5":"images, car_types, car_types_encoded = shuffle(images, car_types, car_types_encoded)\ncar_types_encoded.resize((images.shape[0],1))\nprint(car_types_encoded.shape)\nprint(images.shape)","34d2658d":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3),input_shape=(224, 224, 3),strides = (1,1),  padding = 'same',kernel_initializer='he_normal', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(AvgPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3),strides = (1,1),  padding = 'same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3),strides = (1,1),  padding = 'same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3),strides = (1,1),  padding = 'same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation='relu', kernel_initializer='normal'))\nmodel.add(Dense(units=2, activation='sigmoid', kernel_initializer='normal'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\nmodel.summary()","0f99c801":"car_types_encoded = car_types_encoded.reshape((images.shape[0],1))\ncar_types_2class = np.zeros((images.shape[0],2))\nfor i in range(images.shape[0]):\n    if car_types_encoded[i][0] == 0:\n        car_types_2class[i][0] = 1\n    else:\n        car_types_2class[i][1] = 1\n#print(car_types_2class[1:100,:])\nx_train, x_val, y_train, y_val = train_test_split(images, car_types_2class, test_size=0.2, random_state=0)\nx_train = x_train \/ 255\nx_val = x_val \/ 255\n\n# set train Generator\ndatagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True)\ndatagen.fit(x_train)","10bbf426":"#print(car_types_2class[1:100,:])\n#print(car_types_2class)","07c5a610":"nb_epoch = 20\nbatch_size = 4\n\nfitted_model = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                    steps_per_epoch = x_train.shape[0],\n                    epochs=nb_epoch,\n                    validation_data = (x_val, y_val),\n                    )","ed09bcdc":"#constant\nBATCH_SIZE = 128\nNB_EPOCH = 4\nNB_CLASSES = 10\nVERBOSE = 1\nVALIDATION_SPLIT = 0.2\n#OPTIM = RMSprop()\nfitted_model = model.fit(x_train, y_train, batch_size=BATCH_SIZE,\n                         epochs=NB_EPOCH,\n                         validation_split=VALIDATION_SPLIT, \n                         verbose=VERBOSE)","38714cc6":"plt.plot(fitted_model.history['accuracy'])\nplt.plot(fitted_model.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.show()","1da14416":"plt.figure()\nplt.gcf().clear()\nplt.plot(fitted_model.history['loss'])\nplt.plot(fitted_model.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.show()","357cde91":"from keras.applications.resnet50 import ResNet50 ","cd789dbe":"def build_ResNet50(input_tensor_shape):\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape= input_tensor_shape)\n    \n    x_model = base_model.output\n    \n    x_model = AvgPool2D(name='globalaveragepooling2d')(x_model)\n    \n    x_model = Dense(1024, activation='relu',name='fc1_Dense')(x_model)\n    x_model = Dropout(0.5, name='dropout_1')(x_model)\n    x_model = Flatten()(x_model)\n    x_model = Dense(256, activation='relu',name='fc2_Dense')(x_model)\n    x_model = Dropout(0.5, name='dropout_2')(x_model)\n    \n    predictions = Dense(2, activation='sigmoid',name='output_layer')(x_model)\n    \n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    return model\n\n\n\ninput_tensor_shape = (224,224,3)\n\nmodel2 = build_ResNet50(input_tensor_shape)\n\nmodel2.summary()\nmodel2.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])","505182c8":"nb_epoch = 10\nbatch_size = 4\n#checkpointer = ModelCheckpoint('imagenet', verbose=1, monitor='val_acc',save_best_only=True, save_weights_only=True)\nfitted_model2 = model2.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                    steps_per_epoch = x_train.shape[0],\n                    epochs=nb_epoch,\n                    validation_data = (x_val, y_val),\n                    )","13b213f1":"scores = model2.evaluate(x_train, y_train, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","b17c5780":"from keras.models import model_from_json\n\n\nmodel_json = model2.to_json()\nwith open(\"model2.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel2.save_weights(\"model2.h5\")\nprint(\"Saved model to disk\")","a8e40e71":"json_file = open('.\/model2.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\".\/model2.h5\")\nprint(\"Loaded model from disk\")\n\n# evaluate loaded model on test data\nloaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nscore = loaded_model.evaluate(x_train, y_train, verbose=0)\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))","d83bd9e2":"_, ax = plt.subplots(3,3, figsize=(12,12))\nfor i in range(3):\n    for j in range(3):\n      ax[i,j].imshow(cv2.cvtColor(images[(i*300)+j], cv2.COLOR_BGR2RGB))\n      ax[i,j].axis('off')\n      ax[i,j].set_title(le.inverse_transform(car_types_encoded[(i*300)+j]), size = 20)","9fdc8641":"<p dir='rtl'>\n    \u062f\u0631 \u0627\u06cc\u0646 \u0642\u0633\u0645\u062a \u0627\u0632 resnet \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u06cc\u0645 \u062a\u0627 \u0645\u062f\u0644 \u0686\u0646\u062f\u0646\u0645\u0648\u0646\u0647 \u0631\u0627 \u062a\u0634\u062e\u06cc\u0635 \u062f\u0647\u062f\n<\/p>"}}