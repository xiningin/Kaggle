{"cell_type":{"f10605ea":"code","29c51a45":"code","eea8bf32":"code","965d5443":"code","1d0d20b3":"code","246dae78":"code","4de19232":"code","994a977f":"code","0b72df3a":"code","b066d64e":"code","42cd55a7":"code","c2e04bf1":"code","bf2552da":"code","66952971":"code","147d1544":"code","927ef874":"code","b6fa467e":"code","57a2eb7f":"code","da91afae":"code","8c957d5a":"code","d611bff2":"code","6f78ebaf":"code","11d54796":"code","5e7e08ca":"code","e6eb3e42":"code","1ef2c817":"markdown","b092877d":"markdown"},"source":{"f10605ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29c51a45":"df = pd.read_csv('\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv')","eea8bf32":"split_date = '2019-06-22'","965d5443":"df.reset_index(inplace=True)\ndf.drop(columns=[\"index\"], inplace=True, axis=1)\ndf.head()","1d0d20b3":"#calculating CPM\n#calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \n#((revenue of the publisher*100)\/revenue_share_percentage)\/measurable_impressions)*1000\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","246dae78":"df.drop(columns=['total_revenue'], axis=1, inplace=True)","4de19232":"df.head()","994a977f":"df = df[df.CPM >= 0]","0b72df3a":"df.CPM.plot.density()","b066d64e":"df = df[df.CPM < df.CPM.quantile(0.95)]","42cd55a7":"df.CPM.plot.density()","c2e04bf1":"import math\ndf['LOG'] = df['CPM'].apply(lambda x : math.log(x+1))","bf2552da":"df.LOG.plot.density()","66952971":"numeric_cols = list(df.select_dtypes(include=\"number\"))","147d1544":"heat_mask = list(~(np.array(numeric_cols) == \"LOG\"))","927ef874":"import seaborn as sns\n\ncorr = df.corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(data=corr,vmin=0, vmax=1, cmap=\"YlGnBu\",  square=True, annot=True, mask=heat_mask)\nplt.show()","b6fa467e":"train = df[df['date'] <= split_date]\ntest = df[df['date'] > split_date]","57a2eb7f":"import matplotlib.pyplot as plt\nplt.figure()\ntrain.LOG.plot.density(label=\"train CPM\");\ntest.LOG.plot.density(label=\"test CPM\");\nplt.legend()","da91afae":"train.date.min(), train.date.max(), test.date.min(), test.date.max()","8c957d5a":"useful_columns = list(set(numeric_cols) - {'CPM','LOG'})","d611bff2":"from sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nnum_pipeline=Pipeline([('imputer',SimpleImputer(strategy='median')),('mm_scaler',MinMaxScaler()),])\ncolumn_transformer = ColumnTransformer([(\"num\",num_pipeline,useful_columns)])\n","6f78ebaf":"X_train = train[useful_columns]\nY_train = train.CPM\nX_train_prepd = column_transformer.fit_transform(X_train)","11d54796":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(n_estimators = 30, random_state = 42)\nreg.fit(X_train_prepd, Y_train)","5e7e08ca":"X_test = test[useful_columns]\nY_test = test.CPM\nX_test_prepd = column_transformer.transform(X_test)","e6eb3e42":"Y_test_pred = reg.predict(X_test_prepd)\nmean_squared_error(Y_test, Y_test_pred)","1ef2c817":"## Prepare data","b092877d":"## Remove negative and values below 0.95 Quantile"}}