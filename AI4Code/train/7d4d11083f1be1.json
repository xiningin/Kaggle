{"cell_type":{"23ee3201":"code","2a8ee51c":"code","da701a32":"code","e817bb14":"code","558c56ee":"code","7aae6716":"code","6f2d1c33":"code","356072aa":"code","b144cdb6":"code","6cc459ec":"code","ea05ad71":"code","a5fed230":"code","fc55f7b1":"code","892898e4":"code","635465a3":"code","600ed933":"code","c9954096":"code","f6755b3f":"markdown","828c4249":"markdown","da31b66f":"markdown","513cd7ef":"markdown","53eb2164":"markdown","901af267":"markdown","399420b1":"markdown","694a7462":"markdown"},"source":{"23ee3201":"train_path = '\/kaggle\/input\/cleaned-toxic-comments\/train_preprocessed.csv'\ntest_path = '\/kaggle\/input\/cleaned-toxic-comments\/test_preprocessed.csv'\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","2a8ee51c":"df = pd.read_csv(train_path)\ndf = df.drop(['id','set','toxicity'], axis=1)\n\nprint(\"df.shape =\", df.shape)\ndf.head()","da701a32":"labels = list(df.columns)\nlabels.remove('comment_text')","e817bb14":"ax = df[labels].sum(axis=0).plot(kind='bar', title='number in each label');\nfor p in ax.patches:\n    ax.annotate(str(int(p.get_height())), (p.get_x() * 1.01, p.get_height() * 1.001))","558c56ee":"df['categorized'] = df.iloc[:,1:].sum(axis=1).apply(bool)\ndf['categorized'].value_counts()","7aae6716":"categorized_rows = df[df['categorized'] == True]\nuncategorized_rows = df[df['categorized'] == False].sample(frac=0.3)\n\ndf = categorized_rows.append(uncategorized_rows)\ndf['categorized'].value_counts()","6f2d1c33":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport re\n\nstop_words = set(stopwords.words('english'))\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\nre_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\ndef removeStopWords(sentence):\n    global re_stop_words\n    return re_stop_words.sub(\" \", sentence)\ndf['comment_text'] = df['comment_text'].apply(removeStopWords)\n\nstemmer = SnowballStemmer(\"english\")\ndef stemming(sentence):\n    stemSentence = \"\"\n    for word in sentence.split():\n        stem = stemmer.stem(word)\n        stemSentence += stem\n        stemSentence += \" \"\n    stemSentence = stemSentence.strip()\n    return stemSentence\ndf['comment_text'] = df['comment_text'].apply(stemming)","356072aa":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nMAX_VOCAB = 500\n\nencoder = layers.experimental.preprocessing.TextVectorization(\n                    max_tokens=MAX_VOCAB, standardize='lower_and_strip_punctuation'\n                )\nsequences = df[\"comment_text\"].values\ntargets = df[labels].values\nencoder.adapt(sequences)","b144cdb6":"print(encoder.get_vocabulary()[:20])","6cc459ec":"model = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=64,\n        mask_zero=True),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(targets.shape[1], activation='sigmoid')\n])","ea05ad71":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=[tf.keras.metrics.CategoricalCrossentropy()])","a5fed230":"history = model.fit(sequences, targets, epochs=10,\n                    batch_size=32,\n                    validation_split=0.2)","fc55f7b1":"pred = model.predict(sequences)","892898e4":"from sklearn.metrics import classification_report\nTHRESH = 0.5\nfor i in range(len(labels)):\n    y_true = targets[:,i]\n    y_pred = (pred[:,i] > THRESH).astype(int)\n    print(f\"======={labels[i]}\")\n    print(classification_report(y_true, y_pred))","635465a3":"from scipy import stats\ny_pred = (pred > THRESH)\n\ndifference = tf.math.logical_xor(tf.cast(targets, dtype=bool), y_pred)\ndifference = difference.numpy().sum(axis=1)\nprint(\"difference stats :\\n\\t\",stats.describe(difference))","600ed933":"m = tf.keras.metrics.Recall()\nm.update_state(targets, y_pred)\nm.result().numpy()","c9954096":"m = tf.keras.metrics.Precision()\nm.update_state(targets, y_pred)\nm.result().numpy()","f6755b3f":"There are 143,346 uncategorized rows and 16,225 categorized rows. We decide to drop 100,000 uncategorized rows.","828c4249":"# Down sample","da31b66f":"### From all real ones, <br> how many of them can model correctly predict as one?","513cd7ef":"### From all predicted ones, <br>how many of them are the real one?","53eb2164":"# Explore data","901af267":"Labels: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, `identity_hate`","399420b1":"# Baseline Model","694a7462":"### How many incorrectly classified? "}}