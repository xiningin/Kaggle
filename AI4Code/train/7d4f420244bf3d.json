{"cell_type":{"9a751cbd":"code","a19388a1":"code","ece0955e":"code","4ff1fda2":"code","903c309a":"code","e8f645cd":"code","cdf291d4":"code","7ab3cb87":"code","d9b4a078":"code","d96643c9":"code","edcbd75a":"code","3d70d58b":"code","1df02cda":"code","fa843fcc":"code","268137ee":"code","faad893a":"code","d613d31b":"code","f2453594":"code","a13a20d9":"code","24f855ea":"code","820d9657":"code","6d6294be":"code","28d48650":"code","131c34f1":"code","d2ec136b":"code","1dc60d99":"code","a5aaf14b":"code","026d5293":"code","6e549fb9":"code","9f21f3a6":"code","a0f2ed52":"code","d3cccc51":"code","ae5a973a":"code","e057203f":"code","32d0635b":"code","3529802c":"code","323529d6":"code","cc27d9f5":"code","26675fa9":"code","5bebb223":"code","09a2bd77":"code","0cd8c939":"code","efb3416f":"code","103bdb9b":"code","2db3fdac":"code","27397c31":"code","cda80078":"code","471cf42b":"code","be66bd48":"code","2f869c20":"code","9306c324":"code","901141ca":"code","6d734bb0":"markdown"},"source":{"9a751cbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nfrom scipy.stats import ttest_ind\nfrom statistics import mean,variance\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import Dataset, DataLoader\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a19388a1":"data = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')\ndata.head()","ece0955e":"data.isna().sum()","4ff1fda2":"data = data.dropna()","903c309a":"data.isna().sum() #Checking","e8f645cd":"labels = data[\"Potability\"].unique().tolist()\nvalues = data[\"Potability\"].value_counts().tolist()\n\ndades = [go.Pie(labels=labels, values=values, textinfo='label+percent', hole=0.3, marker_colors=['blue', 'purple'])]\n\nfigure = go.Figure(dades)\nfigure.update_layout(title=\"Potability proportion\", width=900, height=400)\n\niplot(figure)","cdf291d4":"potability_group = data[data[\"Potability\"] == 1]\nnon_potability_group = data[data[\"Potability\"] == 0]","7ab3cb87":"sns.distplot(potability_group[\"ph\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"ph potability group\")\n\nsns.distplot(non_potability_group[\"ph\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"ph non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('pH distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')","d9b4a078":"sns.distplot(potability_group[\"Hardness\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Hardness potability group\")\n\nsns.distplot(non_potability_group[\"Hardness\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Hardness non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('Hardness distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')\n","d96643c9":"sns.distplot(potability_group[\"Solids\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Solids potability group\")\n\nsns.distplot(non_potability_group[\"Solids\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Solids non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('Solids distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')\n","edcbd75a":"sns.distplot(potability_group[\"Chloramines\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Chloramines potability group\")\n\nsns.distplot(non_potability_group[\"Chloramines\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Chloramines non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('Chloramines distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')","3d70d58b":"sns.distplot(potability_group[\"Sulfate\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Sulfate potability group\")\n\nsns.distplot(non_potability_group[\"Sulfate\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Sulfate non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('Sulfate distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')","1df02cda":"sns.distplot(potability_group[\"Conductivity\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Conductivity potability group\")\n\nsns.distplot(non_potability_group[\"Conductivity\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Conductivity non_potability group\")\n\nplt.legend(prop={'size': 8}, title = 'group')\nplt.title('Conductivity distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')","fa843fcc":"sns.distplot(potability_group[\"Organic_carbon\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Organic_carbon potability group\")\n\nsns.distplot(non_potability_group[\"Organic_carbon\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Organic_carbon non_potability group\")\n\nplt.legend(prop={'size': 7}, title = 'group')\nplt.title('Organic_carbon distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')\n","268137ee":"sns.distplot(potability_group[\"Trihalomethanes\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Trihalomethanes potability group\")\n\nsns.distplot(non_potability_group[\"Trihalomethanes\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Trihalomethanes non_potability group\")\n\nplt.legend(prop={'size': 7}, title = 'group')\nplt.title('Trihalomethanes distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')\n","faad893a":"sns.distplot(potability_group[\"Turbidity\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Turbidity potability group\")\n\nsns.distplot(non_potability_group[\"Turbidity\"], hist=True, kde=True, \n             bins=int(180\/5), color = 'orange', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4}, label = \"Turbidity non_potability group\")\n\nplt.legend(prop={'size': 7}, title = 'group')\nplt.title('Turbidity distribution for potability and non-potability group')\nplt.xlabel('Delay (min)')\nplt.ylabel('Density')\n\n","d613d31b":"correlation = data.corr()\n\nplt.figure(figsize=(35,35))\n\nax = sns.heatmap(correlation, annot=True, linewidths=.5)\n","f2453594":"data.corr()['Potability'].sort_values()","a13a20d9":"var = [\"Organic_carbon\",\"Conductivity\",\"Sulfate\",\"Hardness\",\"Trihalomethanes\",\"ph\",\"Chloramines\",\n\"Turbidity\",\"Solids\"]\nX = data.iloc[:, 0:-1]\nY = data.iloc[:, -1]\nX_train,X_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\nX_train_2v = X_train[[\"Sulfate\", \"Chloramines\"]]\nX_test_2v = X_test[[\"Sulfate\", \"Chloramines\"]]\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","24f855ea":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","820d9657":"model = SVC(kernel = 'linear')\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","6d6294be":"model = SVC(kernel = 'rbf')\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","28d48650":"model = SVC(kernel = 'sigmoid')\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","131c34f1":"model = SVC(kernel = 'poly',degree = 1)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","d2ec136b":"model = SVC(kernel = 'poly',degree = 2)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","1dc60d99":"model = KNeighborsClassifier(n_neighbors = 1)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","a5aaf14b":"model = KNeighborsClassifier(n_neighbors = 3)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","026d5293":"model = KNeighborsClassifier(n_neighbors = 5)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","6e549fb9":"model = KNeighborsClassifier(n_neighbors = 7)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","9f21f3a6":"model = KNeighborsClassifier(n_neighbors = 10)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","a0f2ed52":"model = KNeighborsClassifier(n_neighbors = 12)\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","d3cccc51":"model = RandomForestClassifier(max_depth=12,criterion = \"gini\")\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","ae5a973a":"model = RandomForestClassifier(max_depth=12,criterion = \"entropy\")\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","e057203f":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier( max_depth=12, criterion = \"gini\")\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","32d0635b":"model = DecisionTreeClassifier( max_depth=12, criterion = \"entropy\")\nmodel.fit(X_train, y_train)\nacc = accuracy_score(y_test, model.predict(X_test))\nprint(acc)","3529802c":"###Only using two variables: Chlorines and Sulfates\nmodel = SVC(kernel = 'poly',degree = 2)\nmodel.fit(X_train_2v, y_train)\nacc = accuracy_score(y_test, model.predict(X_test_2v))\nprint(acc)","323529d6":"model = LogisticRegression()\nmodel.fit(X_train_2v, y_train)\nacc = accuracy_score(y_test, model.predict(X_test_2v))\nprint(acc)","cc27d9f5":"model = SVC(kernel = 'linear')\nmodel.fit(X_train_2v, y_train)\nacc = accuracy_score(y_test, model.predict(X_test_2v))\nprint(acc)","26675fa9":"model = SVC(kernel = 'poly',degree = 3)\nmodel.fit(X_train_2v, y_train)\nacc = accuracy_score(y_test, model.predict(X_test_2v))\nprint(acc)","5bebb223":"model = KNeighborsClassifier(n_neighbors = 3)\nmodel.fit(X_train_2v, y_train)\nacc = accuracy_score(y_test, model.predict(X_test_2v))\nprint(acc)","09a2bd77":"# use gpu if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using: \",device)","0cd8c939":"batch_size = 64\n\ny_train, y_test = y_train.to_frame(),y_test.to_frame()","efb3416f":"class trainData(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\ntrain_data = trainData(torch.FloatTensor(X_train), \n                       torch.FloatTensor(y_train.values))\n## test data    \nclass testData(Dataset):\n    \n    def __init__(self, X_data):\n        self.X_data = X_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n    \n\ntest_data = testData(torch.FloatTensor(X_test))","103bdb9b":"train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_data, batch_size=1)","2db3fdac":"class SimpleMLP(nn.Module):\n \n    def __init__(self,inp_dim,layer1_dim,layer2_dim,layer3_dim,output_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(inp_dim, layer1_dim)\n        self.fc2 = nn.Linear(layer1_dim,layer2_dim)\n        self.fc3 = nn.Linear(layer2_dim, layer3_dim)\n        self.fc4 = nn.Linear(layer3_dim, output_dim)\n        nn.init.xavier_uniform_(self.fc1.weight)\n        nn.init.zeros_(self.fc1.bias)\n        nn.init.xavier_uniform_(self.fc2.weight)\n        nn.init.zeros_(self.fc2.bias)\n        nn.init.xavier_uniform_(self.fc3.weight)\n        nn.init.zeros_(self.fc3.bias)\n        nn.init.xavier_uniform_(self.fc4.weight)\n        nn.init.zeros_(self.fc4.bias)\n       \n \n    def forward(self, x):\n        out = torch.relu(self.fc1(x))\n        out = torch.tanh(self.fc2(out))\n        out = torch.tanh(self.fc3(out))\n        out = torch.tanh(self.fc4(out))\n        return out","27397c31":"input_size = 9 #9 entry variables\nlayer1_dim = 3\nlayer2_dim = 2\nlayer3_dim = 2\noutput_size = 1\nmodel = SimpleMLP(input_size,layer1_dim,layer2_dim,layer3_dim, output_size)\nprint(model)","cda80078":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc\n","471cf42b":"#learning_rate = 0.000015\nlearning_rate = 0.0001\nepochs = 2000\ncriterion = nn.BCEWithLogitsLoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","be66bd48":"model.train()\nfor e in range(1, epochs+1):\n    epoch_loss = 0\n    epoch_acc = 0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_pred = model(X_batch)\n        loss = criterion(y_pred, y_batch)\n        acc = binary_acc(y_pred, y_batch)\n        \n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n\n    print(f'Epoch {e+0:03}: | Loss: {epoch_loss\/len(train_loader):.5f} | Acc: {epoch_acc\/len(train_loader):.3f}')","2f869c20":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","9306c324":"y_pred_list = []\nmodel.eval()\nwith torch.no_grad():\n    for X_batch in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_test_pred = torch.sigmoid(y_test_pred)\n        y_pred_tag = torch.round(y_test_pred)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","901141ca":"s = 0\nsize = len(y_test)\nfor i in range(size):\n    if ( y_test.iloc[i][\"Potability\"] == y_pred_list[i]): s+=1\n        \ntest_accuracy = s\/size\nprint(test_accuracy)","6d734bb0":"### Neuronal Network with pytorch"}}