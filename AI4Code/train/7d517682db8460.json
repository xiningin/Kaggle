{"cell_type":{"53fef830":"code","4ab43037":"code","3c01ab21":"code","53f613e5":"code","7baac045":"code","5732119e":"code","660fcd6c":"code","8a611bd5":"code","83468997":"code","132294ca":"code","1b90dc23":"code","af2c8c32":"code","06865a53":"code","068162c9":"code","a115c8ba":"code","1e107ee4":"code","6c34ca81":"code","cd6aa572":"code","8a4d3a39":"code","50ac8858":"code","f2b506b2":"code","6638ae44":"code","2f494a79":"code","163ac2c7":"markdown","13d09b23":"markdown","3cd904d8":"markdown","51085a40":"markdown","a5b496a3":"markdown","1c0d790b":"markdown","063849e9":"markdown","0d45d793":"markdown","bc6ed3f2":"markdown","f2eefd6e":"markdown","841cb703":"markdown","169e5aff":"markdown"},"source":{"53fef830":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ab43037":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom ml_metrics import rmse","3c01ab21":"X=pd.read_csv('\/kaggle\/input\/neolen-house-price-prediction\/train.csv',index_col='Id')\nX_test_full=pd.read_csv('\/kaggle\/input\/neolen-house-price-prediction\/test.csv',index_col='Id')\nX.head()\nX.info()","53f613e5":"#Show the price of Houses\nX.SalePrice.hist(bins=80,rwidth=0.7,figsize=(14,4))\nplt.title('Price of Houses')\nplt.show()","7baac045":"sns.pairplot(X[[\"SalePrice\", \"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\"]])","5732119e":"X.dropna(axis=0,subset=['SalePrice'],inplace=True)\ny=X.SalePrice\nx=X.drop(['SalePrice'],axis=1)\n","660fcd6c":"from sklearn.model_selection import train_test_split\nX_train,X_valid,y_train,y_valid = train_test_split(x,y,test_size=0.2,random_state=10)","8a611bd5":"num_cols=X_train.columns[(X_train.dtypes == 'int64') | (X_train.dtypes=='float64')].tolist()\ncat_cols = X_train.columns[X_train.dtypes == 'object'].tolist()\nall_cols=num_cols+cat_cols\n\nX_train_copy = X_train[all_cols].copy()\nX_valid_copy=X_valid[all_cols].copy()\nX_test=X_test_full[all_cols].copy()\n\n\nX_train_copy=pd.get_dummies(X_train_copy)\nX_valid_copy=pd.get_dummies(X_valid_copy)\nX_test=pd.get_dummies(X_test)\n\nX_train_copy, X_valid_copy = X_train_copy.align(X_valid_copy, join='left', axis=1)\nX_train_copy, X_test = X_train_copy.align(X_test, join='left', axis=1)\n\nprint(X_train_copy.shape)\nprint(X_valid_copy.shape)\nprint(X_test.shape)\n","83468997":"X_train_copy.isnull().sum()","132294ca":"X_train_copy.median()","1b90dc23":"from sklearn.impute import SimpleImputer\n\nfinal_imputer = SimpleImputer(strategy='median')\nfinal_X_train = pd.DataFrame(final_imputer.fit_transform(X_train_copy))\nfinal_X_valid = pd.DataFrame(final_imputer.transform(X_valid_copy))\n\n# Imputation removed column names; put them back\nfinal_X_train.columns = X_train_copy.columns\nfinal_X_valid.columns = X_valid_copy.columns","af2c8c32":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(final_X_train,y_train)\npreds_valid = model.predict(final_X_valid)\nprint(\"Score is : \")\nprint(rmse(np.log(y_valid),np.log(preds_valid)))\n","06865a53":"# Checking For Correlation between Features and SalePrice\ncorr=dict(X[X.columns[1:]].corr()['SalePrice'][:])\n#getting the Most Effective Features\nimp_feature=[]\n\nfor key,value in corr.items():\n    if abs(value)>0.5:\n        imp_feature.append(key)\n    \n","068162c9":"imp_feature.remove('SalePrice')","a115c8ba":"print(imp_feature)","1e107ee4":"x_up = x[imp_feature]\n\nfrom sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(x_up, y, random_state=1)","6c34ca81":"final_imputer_up = SimpleImputer(strategy='median')\nfinal_X_train_up = pd.DataFrame(final_imputer_up.fit_transform(train_X))\nfinal_X_valid_up = pd.DataFrame(final_imputer_up.transform(val_X))\n\n# Imputation removed column names; put them back\nfinal_X_train_up.columns = train_X.columns\nfinal_X_valid_up.columns = val_X.columns","cd6aa572":"y","8a4d3a39":"model_up = LinearRegression()\nmodel_up.fit(final_X_train_up,train_y)\npreds_valid_up = model_up.predict(final_X_valid_up)\nprint(\"Score is : \")\nprint(rmse(val_y,preds_valid_up))","50ac8858":"X_test_feature=X_test[imp_feature]\nfinal_X_test = pd.DataFrame(final_imputer_up.fit_transform(X_test_feature))\nfinal_X_test.columns=X_test_feature.columns","f2b506b2":"final_model=LinearRegression()\nfinal_model.fit(final_X_train_up,train_y)\nfinal_preds = final_model.predict(final_X_test)\n","6638ae44":"final_preds","2f494a79":"output = pd.DataFrame({'Id': X_test_full.index,\n                       'SalePrice': final_preds})\noutput.to_csv('submission_Data.csv', index=False)\nprint('done')","163ac2c7":"# Loading Data","13d09b23":"# Building The Model","3cd904d8":"# Random Sampling","51085a40":"# Separating Numerical From Categorical Columns","a5b496a3":"# Importing ","1c0d790b":"# Applying Model On Test Data","063849e9":"# Dealing With Missing Values in Train And Valid Data","0d45d793":"# Submitting and Finishing The Output","bc6ed3f2":"# Feature Engineering For Improvement","f2eefd6e":"# Plotting Pairplot of Some important features","841cb703":"# Feauture Engineering For Test Data","169e5aff":"# Model Improved"}}