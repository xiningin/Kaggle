{"cell_type":{"a1033c51":"code","6e3643d7":"code","cc0a8069":"code","1f4f032a":"code","7c1e3a65":"code","57b32b7f":"code","e94549c1":"code","7bd8b8e8":"code","a338dd59":"code","19177ca7":"code","9343b9ac":"code","fc46f471":"code","88bdcd25":"code","4dc93397":"code","ae6bdd0b":"code","9862dfa4":"code","e0334c8c":"code","59b5da4e":"code","05602918":"code","a669a39b":"code","43bb57f3":"code","33a2da01":"code","cb030f37":"code","23a28969":"code","797fa8ab":"code","9c909dcc":"code","2fec630f":"code","ed6c4338":"code","b3bfbb1f":"code","8717178e":"code","a2b683bf":"code","6a7da4f5":"markdown","ccd4bb3c":"markdown","e09be1eb":"markdown","8b17c273":"markdown","be7f211f":"markdown","2a9e44c8":"markdown","87fc0b68":"markdown","753dc564":"markdown","2a8a29c4":"markdown","850fc88a":"markdown","1e0b8530":"markdown","1053063f":"markdown","b2eda8c3":"markdown","49c4e460":"markdown","dcb2ef68":"markdown","84c78d6f":"markdown","78b2b618":"markdown","feb02f60":"markdown","bc51088c":"markdown","84d1a090":"markdown","e720725f":"markdown","0ed96c99":"markdown","d3e1c647":"markdown","1351d425":"markdown","8eaed1b9":"markdown","5b0a9dcf":"markdown","02c043be":"markdown","8b425b2b":"markdown","cbb67e59":"markdown","bd2d9bfd":"markdown","ead119ec":"markdown","84dbce09":"markdown","ef6dee70":"markdown","fcf77550":"markdown","4f507e96":"markdown","dccc46b8":"markdown","7b9945a4":"markdown"},"source":{"a1033c51":"# Import the dependencies\nimport numpy as np\nfrom scipy.linalg import toeplitz, cholesky, sqrtm, inv\n# import scipy.linalg as la\nfrom scipy import signal\nfrom scipy.integrate import odeint\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\nprint(\"Imports done\")","6e3643d7":"def g_gp(x,v):\n    \"\"\"\n    Generative process, equation of sensory mapping: g_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Hidden causal state, in this example not used\n        \n    OUTPUT:\n        g_gp(x,v) - Temperature in degrees celsius\n        \n    \"\"\"\n    #t0= 20\n    #y=(t0-8)\/(0.2*x**2+1)+8\n    t0=25\n    return t0 -16 \/ (1 + np.exp(5-x\/5))\n\ndef dg_gp(x,v):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of sensory mapping: g'_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'_gp(x,v) - first partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16\/5 * np.exp(5-x\/5) \/ (1+np.exp(5-x\/5))**2\n\ndef ddg_gp(x,v):\n    \"\"\"\n    Double partial derivative of generative process towards x, equation of sensory mapping: g''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''_gp(x,v) - second partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (32*np.exp((2*x)\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**3)-(16*np.exp(x\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**2)\n\ndef dddg_gp(x,v):\n    \"\"\"\n    3rd partial derivative of generative process towards x, equation of sensory mapping: g'''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'''_gp(x,v) - third partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16*np.exp(x\/5+5)*(np.exp((2*x)\/5)-4*np.exp(x\/5+5)+np.exp(10))\/(125*(np.exp(x\/5)+np.exp(5))**4)\n\ndef ddddg_gp(x,v):\n    \"\"\"\n    4th partial derivative of generative process towards x, equation of sensory mapping: g''''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''''_gp(x,v) - 4th partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (16*np.exp(x\/5+5)*(np.exp((3*x)\/5)-11*np.exp((2*x)\/5+5)+11*np.exp(x\/5+10)-np.exp(15)))\/(625*(np.exp(x\/5)+np.exp(5))**5)\n\n# in case you wondered how to calculated all the derivatives in an easy way: https:\/\/www.derivative-calculator.net\/\n\n# Show the temperature curve\nx_show = np.arange (-0,50,0.01)\ny_show = g_gp(x_show,0)\ndy_show = dg_gp(x_show,0)\nplt.plot(y_show, x_show)\n#plt.plot(dy_show, x_show)\nplt.ylabel('Depth (centimeters)')\nplt.xlabel('Temperature (\u00b0 C)')\nplt.gca().invert_yaxis()\nplt.vlines(17, 50, 25, colors='r', linestyles='dashed')\nplt.hlines(25, 10,17, colors='r', linestyles='dashed')\nplt.text(17.3,27,\"temparature 17\u00b0 C\")\nplt.show;\n\nprint('Temperature at 25 centimetres is: ', g_gp(25,0), ' degrees celsius')","cc0a8069":"test=30\nprint(g_gp(test,0),dg_gp(test,0),ddg_gp(test,0),dddg_gp(test,0),ddddg_gp(test,0))\n#Compare with https:\/\/www.derivative-calculator.net\/","1f4f032a":"a=-1\ndef f_gp(x, v):\n    \"\"\"\n    Generative process, equation of motion: f_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Hidden causal state, in this example not used\n        \n    OUTPUT:\n        f_gp(x,v) - Speed of depth position in centimetres \n        \n    \"\"\"\n    return a*x + v\n\ndef df_gp(x, v):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of motion: f'_gp(x) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Hidden causal state, in this example not used\n        \n    OUTPUT:\n        df_gp(x, v) - first derivative of the equation of motion\n        \n    \"\"\"\n    return a\n        \n","7c1e3a65":"# Setting up the time data:\ndt = 0.005; # integration step, average neuron resets 200 times per second\nT = 5+dt; # maximum time considered\nt = np.arange(0,T,dt)\nN= t.size #Amount of data points\nprint ('Amount of data points: ', N)\nprint ('Starting with', t[0:5])\nprint ('Ending with', t[N-5:N])\nprint ('Data elements', np.size(t))","57b32b7f":"def makeNoise(C,s2,t):\n    \"\"\"\n    Generate random noise series with temporal smoothness with desired covariance matrix\n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        C       - desired covariance matrix\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n                  - s2 <= 1e-5 -> produces white noise\n        t       - timeline \n        \n    OUTPUT:\n        ws       - noise sequence with temporal smoothness\n    \"\"\"\n    \n    if np.size(C)== 1:\n        n = 1\n    else:\n        n = C.shape[1]  # dimension of noise\n        \n    # Create the white noise with correct covariance\n    N = np.size(t)      # number of elements\n    L =cholesky(C, lower=True)  #Cholesky method\n    w = np.dot(L,np.random.randn(n,N))\n    \n    if s2 <= 1e-5: # return white noise\n        return w\n    else: \n        # Create the noise with temporal smoothness\n        P = toeplitz(np.exp(-t**2\/(2*s2)))\n        F = np.diag(1.\/np.sqrt(np.diag(np.dot(P.T,P))))\n        K = np.dot(P,F)\n        ws = np.dot(w,K)\n        return ws","e94549c1":"def temporalC(p,s2):\n    \"\"\"\n    Construct the temporal covariance matrix S for noise with embedding order p and smoothness parameter s\n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n        \n    OUTPUT:\n        S       - temporal covariance matrix ((p+1) x (p+1))\n    \"\"\" \n\n    q = np.arange(p+1)\n    \n    r = np.zeros(1+2*(p))\n    r[2*q] = np.cumprod(1-2*q)\/(2*s2)**(q)    \n    \n    S = np.empty([0,p+1])\n\n    for i in range(p+1):\n        S = np.vstack([S,r[q+i]])\n        r = -r\n           \n    return S ","7bd8b8e8":"# Example temporal covariance matrix\np=3 # embedding order of generative model, is the number of derivatives. e.g. p=5  means we have \u03bc(0)  until  \u03bc(6) , which means the vector has 6 entries\nvariance = 1\/2000\nv= temporalC(p,variance)\nprint(v)","a338dd59":"# example precision matrix to see how much higher the higher order motions are taken into the Free Energy calculation\n# Variance of the filter = 1\/2000 as per experiments in this notebook using coloured noise\np=3 # embedding order of generative model\nprint('With coloured noise')\nprint(inv(np.kron(temporalC(p,1\/2000),1)))\nprint('Without noise')\nprint(inv(np.kron(temporalC(p,1\/64),1)))\nprint('With white noise')\nprint(inv(np.kron(temporalC(p,1e-5),1)))","19177ca7":"def derivativeD(p):\n    \"\"\"\n    Construct derivative operator with embedding order p \n    Shifts all variables of a vector up by one and adds a zero at the bottom \n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        D       - derivative matrix ((p+1) x (p+1))\n    \"\"\" \n    D = toeplitz(np.zeros([1,p+1]),np.append(np.array([0,1]),np.zeros([1,p-1])))\n           \n    return D","9343b9ac":"# Show example Derivative matrix\nprint (derivativeD(3))","fc46f471":"# Support functions for generalised coordinates of motion\n\ndef generalize(y,p):\n    \"\"\"\n    Construct generalised value with embedding order p \n    By [y,0,0...]\n    \n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    if np.shape(y)==(p+1, 1):\n        # Generalised value, use it\n        y_tilde=y;\n        return y_tilde\n    \n    # Generalize sensory observation by adding zero's\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n\n    return y_tilde\n\ndef sensor_generalize_exact(y,p,x,v):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by calculating the exact value \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        x       - Hidden state, needed to calculate the exact higher derivatives\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')       \n\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n    if p>=1:\n        y_tilde[1] = dg_gp(x,v)*f_gp(x,v) # note that function f already expresses the motion of x (\\dot x), hence not df_gp needed but f_gp\n    if p>=2:\n        y_tilde[2] = ddg_gp(x,v)*f_gp(x,v)*f_gp(x,v) + dg_gp(x,v)*df_gp(x,v)*f_gp(x,v)\n    if p>=3:\n        y_tilde[3] = dddg_gp(x,v)*f_gp(x,v)**3 + 2*ddg_gp(x,v)*f_gp(x,v)**2*df_gp(x,v) + df_gp(x,v)*(ddg_gp(x,v)*f_gp(x,v)*f_gp(x,v) + dg_gp(x,v)*df_gp(x,v)*f_gp(x,v))\n    \n    return y_tilde\n\ndef sensor_generalize_backward(y,i,p):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by approximating the derivaties from past observations\n    \n    For this example it has been calculated upto 4 derivatives\n    \n    INPUTS:\n        y       - Input sensory signal (array including all history thus far)\n        i       - Current timestamp, so y[i] is the current non-generalised sensory signal\n        p       - embedding order (>=0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y[i]\n    if p>=1:\n        y_tilde[1] = (y[i]-y[i-1])\/dt\n        #print('Generalise backward input : ', y[i],' + ',y[i-1])\n    if p>=2 and i>=2:\n        y_tilde[2] = (y[i]-2*y[i-1]+y[i-2])\/dt**2\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2])\n    if p>=3 and i>=3:\n        y_tilde[3] = (y[i]-3*y[i-1]+3*y[i-2]-y[i-3])\/dt**3\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3])\n    if p>=4 and i>=4:\n        y_tilde[4] = (y[i]-4*y[i-1]+6*y[i-2]-4*y[i-3]+y[i-4])\/dt**4\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3],' + ',y[i-4])\n          \n    return y_tilde\n\ndef standard_vec(p):\n    x = np.zeros((p+1,1))\n    x[0] = 1\n    return x\n\ndef standard_vec_inv(p):\n    x = np.ones((p+1,1))\n    x[0] = 0\n    return x\n\ndef motion_generalize_exact(p,x,v):\n    \"\"\"\n    Construct generalised motion with embedding order p \n    Generalize the motion by calculating the exact value \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        p       - embedding order (>0)\n        x       - Hidden state\n        v       - Hidden cause\n        \n    OUTPUT:\n        x_tilde - Generalised motion\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')       \n\n    x_tilde = np.zeros((p+1,1))\n    x_tilde[0] = x\n    if p>=1:\n        x_tilde[1] = f_gp(x,v)\n    if p>=2:\n        x_tilde[2] = df_gp(x,v)*f_gp(x,v)\n    if p>=3:\n        x_tilde[3] = df_gp(x,v)*df_gp(x,v)*f_gp(x,v)\n        \n    return x_tilde    ","88bdcd25":"class ai_capsule():\n    \"\"\"\n        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one prior\n        In neurology it could e.g. represent a (micro) column or a neuron assembly\n\n        Version 0.2 including generalised coordinates of motion\n    \"\"\"\n    def __init__(self, dt, mu_x_init, p, Sigma_w, Sigma_z, a_mu, s2_w, s2_z):  \n        \n        self.dt = dt    # integration step\n        self.mu_x= mu_x_init # initializing the hidden state, in generalised coordinates of motion\n        self.p = p      # embedding order, number of derevatives in generalised coordinates of motion\n        self.F = 0      # Free Energy\n        self.eps_x =  np.zeros((p+1,1))   # epsilon_x, prediction error on hidden state,  in generalised coordinates of motion\n        self.eps_y = np.zeros((p+1,1)) # epsilon_y, prediction error on sensory measurement,  in generalised coordinates of motion\n        self.Sigma_w = Sigma_w # Estimated variance of the hidden state equals variance of the prior\n        self.Sigma_z = Sigma_z # Estimated variance of the sensory observation \n        self.s2_w = s2_w # Estimated variance of the Gaussian filter used to create the smoothened noise w\n        self.s2_z = s2_z # Estimated variance of the Gaussian filter used to create the smoothened noise z\n        self.alpha_mu = a_mu # Learning rate of the gradient descent mu (hidden state)\n        self.D = derivativeD(self.p)\n        self.I = np.identity(self.p+1)\n        self.Pi_w = inv(np.kron(temporalC(self.p,self.s2_w),self.Sigma_w)) # precision matrix of smoothened noise w\n        self.Pi_z = inv(np.kron(temporalC(self.p,self.s2_z),self.Sigma_z)) # precision matrix of smoothened noise z\n        self.a=-1 # same as the generative model\n        self.Atilde= self.a * self.I\n        #self.c=1\n        #self.Ctilde= self.c * self.I\n        self.std_vec_inv=standard_vec_inv(p)\n        self.std_vec=standard_vec(p)\n    \n    def inference_step (self, i, mu_v, y):\n        \"\"\"\n        Perceptual inference    \n\n        INPUTS:\n            i       - tic, timestamp\n            mu_v    - Hierarchical prior input signal (mean) at timestamp,  in generalised coordinates of motion\n            y       - sensory input signal at timestamp, in generalised coordinates of motion\n\n        INTERNAL:\n            mu_x      - Belief or hidden state estimation, in generalised coordinates of motion\n\n        \"\"\"\n\n            \n        # Calculate prediction errors\n        self.eps_x = (self.D-self.Atilde).dot(self.mu_x) - mu_v  # prediction error hidden state\n        self.eps_y = y - self.std_vec*g_gp(self.mu_x[0],mu_v[0]) - self.std_vec_inv * dg_gp(self.mu_x[0],mu_v[0]) * self.mu_x #prediction error sensory observation\n        # In case a linear state space model is used with linear equation of sensory mapping the below calculation is equivalent\n        #self.eps_y = y - self.Ctilde.dot(self.mu_x) #prediction error sensory observation\n        \n        #print('mu_x=', self.mu_x[0],'mu_y=', g_gp(self.mu_x[0],mu_v[0]), 'x_dot',self.mu_x[1])\n        #print( 'ex',self.eps_x)\n        #print( 'ey',self.eps_y)\n\n        # Free energy gradient\n        dFdmu_x = (self.D-self.Atilde).T.dot(self.Pi_w).dot(self.eps_x) - (dg_gp(self.mu_x[0],mu_v[0]) * self.I).T.dot(self.Pi_z).dot(self.eps_y)\n        # In case a linear state space model is used with linear equation of sensory mapping the below calculation is equivalent\n        #dFdmu_x = (self.D-self.Atilde).T.dot(self.Pi_w).dot(self.eps_x) - self.Ctilde.T.dot(self.Pi_z).dot(self.eps_y)\n        \n        # Perception dynamics\n        dmu_x   = np.dot(self.D,self.mu_x) - self.alpha_mu * dFdmu_x  \n        self.mu_x = self.mu_x + self.dt * dmu_x\n        \n        \n        # Calculate Free Energy to report out\n        self.F= 0.5*( self.eps_x.T.dot(self.Pi_w).dot(self.eps_x) + self.eps_y.T.dot(self.Pi_z).dot(self.eps_y)) #+ np.log(self.Sigma_w * self.Sigma_z) )\n        \n        return self.F.item(0), self.mu_x[0] , g_gp(self.mu_x[0],mu_v[0])","4dc93397":"class ai_capsule_v1():\n    \"\"\"\n        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one prior\n        In neurology it could eg represent a (micro) column\n        \n        Version 0.1, same as the first notebook for base reference \n    \"\"\"\n    def __init__(self,dt, mu_x_init, Sigma_w, Sigma_z, a_mu):   \n        self.dt = dt    # integration step\n        self.mu_x = mu_x_init   # initializing the best guess of hidden state by the hierarchical prior\n        self.F = 0      # Free Energy\n        self.eps_x = 0  # epsilon_x, prediction error on hidden state\n        self.eps_y = 0  # epsilon_y, prediction error on sensory measurement\n        self.Sigma_w = Sigma_w #Estimated variance of the hidden state \n        self.Sigma_z = Sigma_z # Estimated variance of the sensory observation \n        self.alpha_mu = a_mu # Learning rate of the gradient descent mu (hidden state)\n    \n    def g(self,x,v):\n        \"\"\"\n            equation of sensory mapping of the generative model: g(x,v) at point x \n            Given as input for this example equal to the true generative process g_gp(x)\n        \"\"\"\n        return g_gp(x,v)\n    \n    def dg(self, x,v):\n        \"\"\"\n            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x) at point x \n            Given as input for this example equal to the true derivative of generative process dg_gp(x)\n        \"\"\"\n        return dg_gp(x,v)\n    \n    def f(self,x,v):\n        \"\"\"\n            equation of motion of the generative model: f(x,v) at point x \n            Given as input for this example equal to the prior belief v\n        \"\"\"\n        return v\n    \n    # def df(self,x): Derivative of the equation of motion of the generative model: f'(x) at point x\n    # not needed in this example \n  \n    def inference_step (self, i, mu_v, y):\n        \"\"\"\n        Perceptual inference    \n\n        INPUTS:\n            i       - tic, timestamp\n            mu_v    - Hierarchical prior input signal (mean) at timestamp\n            y       - sensory input signal at timestamp\n\n        INTERNAL:\n            mu      - Belief or hidden state estimation\n\n        \"\"\"\n\n        # Calculate prediction errors\n        self.eps_x = self.mu_x - self.f(self.mu_x, mu_v)  # prediction error hidden state\n        self.eps_y = y - self.g(self.mu_x, mu_v) #prediction error sensory observation\n        \n        #print( 'ex',self.eps_x)\n        #print( 'ey',self.eps_y)\n        \n        # Free energy gradient\n        dFdmu_x = self.eps_x\/self.Sigma_w - self.dg(self.mu_x,mu_v) * self.eps_y\/self.Sigma_z\n        # Perception dynamics\n        dmu_x   = 0 - self.alpha_mu*dFdmu_x  # Note that this is an example without generalised coordinates of motion hence dmu_x'=0\n        # motion of mu_x \n        self.mu_x = self.mu_x + self.dt * dmu_x\n        \n        # Calculate Free Energy to report out\n        self.F = 0.5 * ((self.eps_x**2 \/ self.Sigma_w + self.eps_y**2 \/ self.Sigma_z)) #+ np.log(self.Sigma_w * self.Sigma_z) ))\n        \n        return self.F, self.mu_x , self.g(self.mu_x,0)","ae6bdd0b":"def simulation (v, mu_v, x_init, Sigma_w, Sigma_z, s2_w, s2_z, noise, a_mu, p, gen_y):\n    \"\"\"\n    Simulation for perceptual inference in a dynamic environment with generalised coordinates     \n   \n    INPUTS:\n        v          - Hydars actual desired depth, used in generative model\n        mu_v       - Hydars prior belief\/hypotheses of the desired depth\n        x_init     - Hydars actual starting depth, used in generative model\n        Sigma_w    - Variance of the hidden state \n        Sigma_z    - Variance of the sensory observation \n        s2_w       - The variance of the Gaussian filter used to create the smoothened noise w\n        s2_z       - The variance of the Gaussian filter used to create the smoothened noise z\n        noise      - white, smooth or none\n        a_mu       - Learning rate for mu\n        p          - Embedding order of generalised motions of the generative model\n        gen_y      - Method to generalize the sensory observations: exact, backward, extend\n        \n    \"\"\"\n    \n    # Init tracking\n    mu_x = np.zeros(N) # Belief or estimation of hidden state \n    F = np.zeros(N) # Free Energy of AI neuron\n    mu_y = np.zeros(N) # Belief or prediction of sensory signal\n\n\n    # Construct noise signals with temporal smoothness:\n    np.random.seed(42)\n    w = makeNoise(Sigma_w,s2_w,t)\n    z = makeNoise(Sigma_z,s2_z,t)\n\n    # Init the generalised process\n    x = np.zeros(N) # True hidden state\n    y = np.zeros(N) # Sensory signal as input to AI neuron\n    x[0] = x_init\n    if noise == 'white':\n        y[0]=g_gp(x[0],v) + np.random.randn(1) * Sigma_z\n    elif noise == 'smooth':\n        y[0]=g_gp(x[0],v)+ z[0,0] \n    else: #no noise\n        y[0]=g_gp(x[0],v)\n\n    # Create active inference neuron\n    \n    if p==0:\n        # Not generalised, use the basic version\n        # initializing the initial hidden state by Hydars best guess: hierarchical prior\n        mu_x_init=mu_v\n        capsule = ai_capsule_v1(dt, mu_x_init, Sigma_w, Sigma_z, a_mu) \n    else:\n        # Generalised\n        mu_v_tilde=generalize(mu_v,p) # generalize the prior\n        # initializing the initial hidden state by Hydars best guess: hierarchical prior\n        mu_x_init_tilde = mu_v_tilde\n        # alternative initializing the initial hidden state by Hydars the exact actual movement of the hidden state\n        #mu_x_init_tilde = motion_generalize_exact(p, x_init,v)\n        capsule = ai_capsule(dt, mu_x_init_tilde, p, Sigma_w, Sigma_z, a_mu, s2_w, s2_z) \n\n    ssim = time.time() # start sim\n    \n    # Simulation\n\n    for i in np.arange(1,N):\n        # Generative process\n        if noise == 'white':\n            x_dot= f_gp(x[i-1],v) + np.random.randn(1) * Sigma_w\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + np.random.randn(1) * Sigma_z\n        elif noise == 'smooth':\n            x_dot= f_gp(x[i-1],v) + w[0,i]\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + z[0,i]\n        else: #no noise\n            x_dot=f_gp(x[i-1],v)\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v)\n        #Active inference\n        #print('x=',x[i],'y=',y[i], 'x_dot=',x_dot)\n        if p==0:\n            F[i], mu_x[i], mu_y[i] = capsule.inference_step(i,mu_v,y[i])\n        else:\n            # Create generalize sensory observations\n            if gen_y=='exact':\n                y_tilde = sensor_generalize_exact(y[i],p,x[i],v)\n                #print(y_tilde)\n            elif gen_y=='backward':\n                y_tilde = sensor_generalize_backward(y,i,p)\n            elif gen_y=='extend':\n                y_tilde = generalize(y[i],p)\n            else:\n                raise ValueError('Unknown method to create sensory observation in generalised coordinates of motion') \n            F[i], mu_x[i], mu_y[i] = capsule.inference_step(i,mu_v_tilde,y_tilde)\n\n    \n    # Print the results\n    tsim = time.time() - ssim\n    #print('Simulation time: ' + \"%.2f\" % tsim + ' sec' )\n\n    return F, mu_x, mu_y, x, y\n","9862dfa4":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,1,'exact') # emedding order p=1\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,2,'exact') # emedding order p=2\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,3,'exact') # emedding order p=3\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=1');\naxes[0].plot(t[1:],mu_x2[1:],label='p=2');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=1');\naxes[1].plot(t[1:],mu_y2[1:],label='p=2');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=1');\naxes[2].semilogy(t[1:],F2[1:],label='p=2');\naxes[2].semilogy(t[1:],F3[1:],label='p=3');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0', mu_x0[-1]) #show the last\nprint('p=1', mu_x1[-1]) #show the last\nprint('p=2', mu_x2[-1]) #show the last\nprint('p=3', mu_x3[-1]) #show the last","e0334c8c":"x_init = 25.0 # generative process initial depth Hydar\nv = 25.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,4,'extend') # emedding order p=4, extend y\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,4,'backward') # emedding order p=2, backward y\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,4,'exact') # emedding order p=4, backward y\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=4; extend');\naxes[0].plot(t[1:],mu_x2[1:],label='p=2; backward');\naxes[0].plot(t[1:],mu_x3[1:],label='p=4; exact');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=4; extend');\naxes[1].plot(t[1:],mu_y2[1:],label='p=2; backward');\naxes[1].plot(t[1:],mu_y3[1:],label='p=4; exact');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].plot(t[1:],F1[1:],label='p=4; extend');\naxes[2].plot(t[1:],F2[1:],label='p=2; backward');\naxes[2].plot(t[1:],F3[1:],label='p=4; exact');\naxes[2].plot(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","59b5da4e":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 30 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,4,'backward') # emedding order p=4\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=4; backward');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=4; backward');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=4; backward');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","05602918":"print(1.1 * 3) # see how the result below shows 3.3000000000000003","a669a39b":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,10,1,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # uncertain about prior (higher variance)\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,10,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # uncertain about sensor (higher variance)\nF4, mu_x4, mu_y4, x4, y4 = simulation(v,mu_v,x_init,10,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 ; # underctain about prior (higher variance)\nF5, mu_x5, mu_y5, x5, y5 = simulation(v,mu_v,x_init,1,10,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 ; # underctain about sensor (higher variance)\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],mu_x4[1:],label='p=0; trust sensor',linestyle='-.');\naxes[0].plot(t[1:],mu_x5[1:],label='p=0; trust Genmodel',linestyle='--');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],mu_y4[1:],label='p=0; trust sensor',linestyle='-.');\naxes[1].plot(t[1:],mu_y5[1:],label='p=0; trust Genmodel',linestyle='--');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].semilogy(t[1:],F4[1:],label='p=0; trust sensor',linestyle='-.');\naxes[2].semilogy(t[1:],F5[1:],label='p=0; trust Genmodel',linestyle='--');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","43bb57f3":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1e-5,1e-5,'white',1,0,'-') # embedding order p=0 experiment 1.01\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1e-5,1e-5,'white',1,1,'exact') # emedding order p=1\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,1,1e-5,1e-5,'white',1,2,'exact') # emedding order p=2\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,1,1e-5,1e-5,'white',1,3,'exact') # emedding order p=3\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=1');\naxes[0].plot(t[1:],mu_x2[1:],label='p=2');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=1');\naxes[1].plot(t[1:],mu_y2[1:],label='p=2');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=1');\naxes[2].semilogy(t[1:],F2[1:],label='p=2');\naxes[2].semilogy(t[1:],F3[1:],label='p=3');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0', mu_x0[-1]) #show the last\nprint('p=1', mu_x1[-1]) #show the last\nprint('p=2', mu_x2[-1]) #show the last\nprint('p=3', mu_x3[-1]) #show the last","33a2da01":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,0,'-') # embedding order p=0 experiment 1.01\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,1,'exact') # emedding order p=1\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,2,'exact') # emedding order p=2\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,3,'exact') # emedding order p=3\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=1');\naxes[0].plot(t[1:],mu_x2[1:],label='p=2');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=1');\naxes[1].plot(t[1:],mu_y2[1:],label='p=2');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=1');\naxes[2].semilogy(t[1:],F2[1:],label='p=2');\naxes[2].semilogy(t[1:],F3[1:],label='p=3');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0', mu_x0[-1]) #show the last\nprint('p=1', mu_x1[-1]) #show the last\nprint('p=2', mu_x2[-1]) #show the last\nprint('p=3', mu_x3[-1]) #show the last","cb030f37":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,3,'exact') # emedding order p=3 balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,10,10,1\/64,1\/64,'no noise',1,3,'exact') # high variance = high uncertainty =low precision\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,0.1,1\/64,1\/64,'no noise',1,3,'exact') # low variance =  low uncertainty = high precision\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; $\\sigma^2$=1');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; $\\sigma^2$=1');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3; $\\sigma^2$=1');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0; var=1 :', mu_x0[-1]) #show the last\nprint('p=3; var=1 :', mu_x1[-1]) #show the last\nprint('p=3; var=10 low precision :', mu_x2[-1]) #show the last\nprint('p=3; var=0.1 high precision :', mu_x3[-1]) #show the last","23a28969":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,0,'-') # embedding order p=0 balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,3,'exact') # emedding order p=3 balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,10,10,1\/2000,1\/2000,'smooth',1,3,'exact') # high variance = high uncertainty =low precision\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,0.1,1\/2000,1\/2000,'smooth',1,3,'exact') # low variance =  low uncertainty = high precision\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; $\\sigma^2$=1');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; $\\sigma^2$=1');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3; $\\sigma^2$=1');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; $\\sigma^2$=10 low precision');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; $\\sigma^2$=0.1 high precision');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0; var=1 :', mu_x0[-1]) #show the last\nprint('p=3; var=1 :', mu_x1[-1]) #show the last\nprint('p=3; var=10 low precision :', mu_x2[-1]) #show the last\nprint('p=3; var=0.1 high precision :', mu_x3[-1]) #show the last","797fa8ab":"x_init = 25.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 30.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,0.1,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about prior\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,1,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about sensor\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","9c909dcc":"x_init = 25.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'no noise',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,0.1,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about prior\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,1,1\/64,1\/64,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about sensor\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","2fec630f":"x_init = 25.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 30.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,0.1,1\/2000,1\/2000,'smooth',1,3,'exact') # embedding order p=3 ; # underctain about prior\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,1,1\/2000,1\/2000,'smooth',1,3,'exact') # embedding order p=3 ; # underctain about sensor\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","ed6c4338":"x_init = 25.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/2000,1\/2000,'smooth',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,0.1,1\/2000,1\/2000,'smooth',1,3,'exact') # embedding order p=3 ; # underctain about prior\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,1,1\/2000,1\/2000,'smooth',1,3,'exact') # embedding order p=3 ; # underctain about sensor\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","b3bfbb1f":"x_init = 30.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'white',1,0,'-') # embedding order p=0 experiment 1.01 baseline\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'white',1,3,'exact') # emedding order p=3 exact\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'white',1,3,'extend') # emedding order p=3 extend\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,1,1,1\/64,1\/64,'white',1,3,'backward') # emedding order p=3 backward\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3 exact');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3 extend');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3 backward');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3 exact');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3 extend');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3 backward');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3 exact');\naxes[2].semilogy(t[1:],F2[1:],label='p=3 extend');\naxes[2].semilogy(t[1:],F3[1:],label='p=3 backward');\naxes[2].semilogy(t[1:],F0[1:],label='p=0',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);\n\nprint('p=0', mu_x0[-1]) #show the last\nprint('p=3 exact', mu_x1[-1]) #show the last\nprint('p=3 extend', mu_x2[-1]) #show the last\nprint('p=3 backward', mu_x3[-1]) #show the last","8717178e":"x_init = 25.0 # generative process initial depth Hydar\nv = 30.0 # generative process target depth Hydar\nmu_v = 25.0 # generative model, Hydars prior belief of the (target) depth\n\nF0, mu_x0, mu_y0, x0, y0 = simulation(v,mu_v,x_init,1,1,1,1,'no noise',1,0,'-') # embedding order p=0 experiment 1.01; prior and observation precision balanced\nF1, mu_x1, mu_y1, x1, y1 = simulation(v,mu_v,x_init,1,1,1,1,'no noise',1,3,'exact')  # embedding order p=3 ; prior and observation precision balanced\nF2, mu_x2, mu_y2, x2, y2 = simulation(v,mu_v,x_init,1,0.1,1,1,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about prior\nF3, mu_x3, mu_y3, x3, y3 = simulation(v,mu_v,x_init,0.1,1,1,1,'no noise',1,3,'exact') # embedding order p=3 ; # underctain about sensor\n\n\n# Plot results:\nfig, axes = plt.subplots(3, 1, sharex='col');\nfig.suptitle('Active Inference with generalised motions, inferencing part');\naxes[0].plot(t[1:],mu_x1[1:],label='p=3; balanced');\naxes[0].plot(t[1:],mu_x2[1:],label='p=3; trust sensor');\naxes[0].plot(t[1:],mu_x3[1:],label='p=3; trust Genmodel');\naxes[0].plot(t[1:],mu_x0[1:],label='p=0; balanced',linestyle=':');\naxes[0].plot(t[1:],x1[1:],label='Generative process');\naxes[0].hlines(mu_v, 0,T, label='Prior belief')\naxes[0].set_ylabel('$\\mu_x$ position');\naxes[0].ticklabel_format(useOffset=False)\nfig.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\naxes[1].plot(t[1:],mu_y1[1:],label='p=3; balanced');\naxes[1].plot(t[1:],mu_y2[1:],label='p=3; trust sensor');\naxes[1].plot(t[1:],mu_y3[1:],label='p=3; trust Genmodel');\naxes[1].plot(t[1:],mu_y0[1:],label='p=0; balanced',linestyle=':');\naxes[1].plot(t[1:],y1[1:],label='Generative process');\naxes[1].hlines(g_gp(mu_v,0), 0,T, label='Prior belief')\naxes[1].set_ylabel('$\\mu_y$ Temperature');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].grid(1);\naxes[2].semilogy(t[1:],F1[1:],label='p=3;balanced');\naxes[2].semilogy(t[1:],F2[1:],label='p=3; trust sensor');\naxes[2].semilogy(t[1:],F3[1:],label='p=3; trust Genmodel');\naxes[2].semilogy(t[1:],F0[1:],label='p=0; balanced',linestyle=':');\naxes[2].set_xlabel('time [s]');\naxes[2].set_ylabel('Free energy');\naxes[2].grid(1);","a2b683bf":"# example precision matrix to see how much higher the higher order motions are taken into the Free Energy calculation\n# Variance of the filter = 1\/2000 as per experiments in this notebook using coloured noise\np=3 # embedding order of generative model\nprint(inv(np.kron(temporalC(p,1),0.1)))\n","6a7da4f5":"## Experiment 2.11 - Inference in a dynamic environment II with coloured noise\nSame experiment as 2.09 but now woth coloured noise present in the generative process.","ccd4bb3c":"# Experiments\nLet's see the theory in action and showcase perceptual inference in our simulation environment using this active inference version in generalised coordinates of motion. In this example, Hydar has to predict its body temperature and therefor needs to infer the hidden state (its depth). It will do so by minimizing the surprise in it's sensory observations by minimizing the Free Energy.","e09be1eb":"### Notes\n* Despite the noisy sensor it still tracks the hidden state\n* Since there is white noise the estimated variance of the Gaussian filter used to create the smoothed noise is 1e-5 (rough\/white noise)\n* As in the first experiment the prediction with embedding order 1 and the prediction with no generalised coordinates of motion have the exact same result. \n* Notice that the delta between active inference p=2 or p=3 vs. p=0 differs more with white noise. In experiment 1.01 the delta was 0.1-0.2 and in this experiment with noise the delta is 0.4-0.5. Higher embedding orders are closer to the sensor input. ","8b17c273":"# Experiment 2.01 - The first\nSame experiment as 1.01 but now in generalised coordinates of motion.\nIn this experiment there is no movement in order to make it as comparable as possible as experiment 1.01. This is achieved by setting in the generative process the initial depth equal to the target depth.  \nHydar's hypotheses or prior  $\\mu_v$  is that it's depth is 25 meters, so it is expecting a temperature of 17 degrees. Its sensors give somehow a reading of approx 13 degrees, so around 30 meters depth. What to believe? Should it trust it's sensor or its internal hypothesis\/prior expectation?\nLet's compare the results of experiment 1.01 (embedding order p=0 in code below) with this active inference solution in generalised coordinates of motion. \n\nFor this example there is no noise in the generative process yet (although the generative model expects noise to be present) to best see how the belief develops.","be7f211f":"### Notes\n* Nice to observe that when Hydar trusts the sensor (orange line p=3 trust sensor) the internal belief of Hydar first pulls close\/fast towards the generative process and next starts following the line towards it's prior.\n* The role of the prior in case of a dynamic example becomes much more the \"desired prior\", the state the hidden state is moving towards","2a9e44c8":"To recap all you need to perform active inference in the table below:\n\nWhat| Symbol | Description |\n--- | --- | --- |\nposition | $x$  | single external hidden environment state the Hydar brain tries to infer. <br> Hydar lives in a one-dimensional plane, so it is the depth in centimetres | \nposition | $\\tilde \\mu_x$  | Hydars belief or estimation of the depth, the hidden state x it's tries to infer |\nbody temperature sensor | $\\tilde y$  | single sensory observation, in this case the temperature.  | \nStarting position | $x_{init}$  | The initial depth of Hydar in the generative process | \nprior | $v$  | The depth hydar moves towards in the generative process | \nprior | $\\tilde \\mu_v$  | Hydars prior belief of the depth Hydar moves towards | \nfunction of sensory mapping| $g(x,v)$  | Given as input and is equal to the true generative process <br>$g(x,v) = t_0 -\\frac{16}{1+e^{5-\\frac{x}{5}}}$ where $t_0=20$  | \nderivative function of sensory mapping| $g'(x,v)$  | Given as input and is equal to the derivative of the true generative process <br>$g'(x,v) = -\\frac{16e^{5-\\frac{x}{5}}}{5\\left(1+e^{5-\\frac{x}{5}}\\right)^2}$  | \nfunction of motion | $f(x,v)$  | Given as input and is equal to the true generative process <br>$f(x,v) = ax + v $ where a=-1 and v = 10|\nderivative of function of motion | $f'(x,v)$  | Given as input and is equal to the true generative process $f'(x) = a $ |\nFree Energy | $\\mathcal{F}(y,\\mu)$  | $\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$ |\nsensory prediction error | $\\tilde \\varepsilon_y$  | $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x, \\tilde\\mu_v) $ |\nmotion prediction error | $\\tilde \\varepsilon_x$  | $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde\\mu_v) $ |\nDerivative Free Energy | $\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x}$  | $\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$ |","87fc0b68":"## Experiment 2.06 - Noise to signal ratio\nSame example as experiment 1.01 but with different estimations of the noise (different variances 0.1 \/ 1 \/ 10) with balanced variances: $\\sigma_z^2$ equals $\\sigma_w^2$   \nNote: for this example there is no noise in the generative process (although the generative model expects noise to be present) to best see how the belief develops.  \n","753dc564":"## Experiment 2.07 - Noise to signal ratio coloured noise\nSame example as experiment 2.06 but now with the actual coloured noise in the generative process  ","2a8a29c4":"### Notes\n+ Like in the basic non-generalised static model, if Hydar trust the prior expectation more, the lines are closer to prior, and likewise if Hydar trust the sensor more the lines are closer to the generative process that generated the sensory observations\n+ At first glance the line for p=4;trust sensor does converge faster to the sensor reading but next does pull towards the prior belief. It even does not seem to converge. But by extending the timeline to 7000 points (T=35) a kind of of slow oscillation becomes visible (also in e.g. p=4;balanced). Quite simular as in [active inference code by example - 3](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-3). The crucial difference with the first example codebook is that $\\mu_x$ is cast as a motion while in the first notebook as static.\n","850fc88a":"## Thank you\nPlease do copy this kernel and try out for yourself to better understand active inference and the free energy principle. My intent is to help catalyse knowledge and research on Active Inference in an engineering\/robotics\/data sciences\/machine learning context. Hope you liked my notebook (upvote top right), my way to contribute back to this fantastic Kaggle platform and community.","1e0b8530":"### Notes\n+ Hydars belief about the depth start with 25 meters as it's prior and the more the sensory observations keep giving a persistent signal that the temperature is lower is starts shifting it's belief about the depth $p(x \\mid y)$ to approx. 26.7 meters. \n+ Solution 2.01 with embedding order 1 and the solution with no generalised coordinates of motion (experiment 1.01, p=0) have the exact same result while higher embedding orders do not. I couldn't help wondering why? So I needed to write out the equations for this example to find out what is causing this effect. Also a good exercise to really see how the code\/math works. As in above examples I used $\\sigma_w^2=1$,$\\sigma_z^2=1$,$\\alpha_x =1$ and the filters to generate generalised motions $s_w^2=1$,$s_z^2=1$. \n+ Note that since there is no noise I opted to estimate the variance of the filter as 1\/64 (very smooth noise, no rough\/white noise)\n\n### In case of no generalised coordinates of motion (first code notebook) $p=0$  \n* sensory prediction error $\\varepsilon_y = y-g(\\mu_x,\\mu_v) = y-g(\\mu_x,\\mu_v) $ \n* motion prediction error $\\varepsilon_x = \\mu_x-f(\\mu_x,\\mu_v) = \\mu_x-\\mu_v $\n* the hidden state $\\dot{\\mu}_x = - \\alpha_x \\left( \\frac{1}{\\sigma_w^2}\\varepsilon_x - g'(\\mu_x,\\mu_v) \\frac{1}{\\sigma_z^2}\\varepsilon_y \\right) = - \\varepsilon_x + g'(\\mu_x,\\mu_v) \\varepsilon_y= - \\mu_x+\\mu_v  + g'(\\mu_x,\\mu_v) (y-g(\\mu_x,\\mu_v)) $\n\n\n### In case of embedding order $p=1$\n* $\\begin{bmatrix}\\varepsilon_y\\\\ \\varepsilon_y'\\end{bmatrix}= \\begin{bmatrix}y-g({\\mu}_x,{\\mu}_v)\\\\-g'({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\end{bmatrix}$\n* $\\begin{bmatrix}\\varepsilon_x\\\\ \\varepsilon_x'\\end{bmatrix} =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - \\tilde \\mu_v = \\begin{bmatrix}\\mu_x'+\\mu_x-\\mu_v\\\\ \\mu_x'\\end{bmatrix} $  given $f(\\mu_x,\\mu_v) = a \\cdot \\mu_x-\\mu_v$ with $a=-1$\n\nSide note: It is interesting to observe that if you would force $\\mu_x'=0$ (force there are no higher order of motions in the equations) it has the exact same error equations as the solution with no generalised coordinates of motion. That gives some confidence in the math used for generalised coordinates of motion.\n\n* the motion of the hidden state:  \n$$ \\begin{bmatrix}\\dot\\mu_x\\\\ \\ddot\\mu_x\\end{bmatrix} = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\left( \\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y \\right) \\\\\n=\\begin{bmatrix}\\mu_x'\\\\0\\end{bmatrix}-\\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix}\\begin{bmatrix}1 & 0\\\\0 & 2\\end{bmatrix}\\begin{bmatrix}\\varepsilon_x\\\\ \\varepsilon_x'\\end{bmatrix}+\\begin{bmatrix}g'({\\mu}_x,{\\mu}_v)&0\\\\0 & g'({\\mu}_x,{\\mu}_v)\\end{bmatrix}\\begin{bmatrix}1 & 0\\\\0 & 2\\end{bmatrix}\\begin{bmatrix}\\varepsilon_y\\\\ \\varepsilon_y'\\end{bmatrix} \\\\\n=\\begin{bmatrix}\\mu_x'\\\\0\\end{bmatrix}-\\begin{bmatrix}1 & 0\\\\1 & 1\\end{bmatrix}\\begin{bmatrix}\\varepsilon_x\\\\ 2\\varepsilon_x'\\end{bmatrix}+\\begin{bmatrix}g'({\\mu}_x,{\\mu}_v)\\cdot \\varepsilon_y\\\\ 2 \\cdot g'({\\mu}_x,{\\mu}_v) \\cdot \\varepsilon_y'\\end{bmatrix} \\\\\n=\\begin{bmatrix}\\mu_x'-(\\mu_x'+\\mu_x-\\mu_v)\\\\-(\\mu_x'+\\mu_x-\\mu_v)-2 \\cdot \\mu_x'\\end{bmatrix}+\\begin{bmatrix}g'({\\mu}_x,{\\mu}_v)\\cdot (y-g({\\mu}_x,{\\mu}_v))\\\\ 2 \\cdot g'({\\mu}_x,{\\mu}_v) \\cdot (-g'({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}')\\end{bmatrix}$$\n\nAnd now it is easy to observe that update rules for the position (top row) are exactly the same as in the example without generalised coordinates of motion, no wonder I get the exact same result for embedding order p=1. This is because by coincidence I used a function of motion  $f(\\mu_x,\\mu_v) = a \\cdot \\mu_x-\\mu_v$ with $a=-1$ in combination with $\\sigma_w=1$ resulting in a  $\\mu_x'-\\mu_x'$ cancellation. So in this specific case there is no $\\mu_x'$ in the $\\dot \\mu_x$ update rule, the higher order motion is not used. If you change e.g. $\\sigma_w^2=1.3$ the effect is gone.\n\n\n### In case of embedding order $p=2$\nFor completeness sake let's also have a quick look at embedding order 2 and see if  $\\mu_x'$ is not cancelled out.\n* $\\begin{bmatrix}\\varepsilon_y\\\\ \\varepsilon_y'\\\\ \\varepsilon_y''\\end{bmatrix}= \\begin{bmatrix}y-g({\\mu}_x,{\\mu}_v)\\\\-g'({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\-g'({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\end{bmatrix}$\n* $\\begin{bmatrix}\\varepsilon_x\\\\ \\varepsilon_x'\\\\ \\varepsilon_x''\\end{bmatrix} =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - \\tilde \\mu_v = \\begin{bmatrix}\\mu_x'+\\mu_x-\\mu_v\\\\ \\mu_x''+\\mu_x'\\\\\\mu_x''\\end{bmatrix} $  given $f(\\mu_x,\\mu_v) = a \\cdot \\mu_x-\\mu_v$ with (a=-1)\n\n* the motion of the hidden state:  \n$$ \\begin{bmatrix}\\dot\\mu_x\\\\ \\ddot\\mu_x\\\\ \\dddot\\mu_x\\end{bmatrix} = \\begin{bmatrix}\\mu_x'\\\\\\mu_x''\\\\0\\end{bmatrix}-\\begin{bmatrix}1&0&0\\\\1&1&0\\\\0&1&1\\end{bmatrix}\\begin{bmatrix}1.5 & 0 & 1\\\\0 & 2 & 0 \\\\ 1 & 0 & 2\\end{bmatrix}\\begin{bmatrix}\\varepsilon_x\\\\ \\varepsilon_x' \\\\ \\varepsilon_x''\\end{bmatrix}+\\begin{bmatrix}g'({\\mu}_x,{\\mu}_v)&0&0\\\\0 & g'({\\mu}_x,{\\mu}_v)&0 \\\\ 0&0&g'({\\mu}_x,{\\mu}_v)\\end{bmatrix}\\begin{bmatrix}1.5 & 0 & 1\\\\0 & 2 & 0 \\\\ 1 & 0 & 2\\end{bmatrix}\\begin{bmatrix}\\varepsilon_y\\\\ \\varepsilon_y' \\\\ \\varepsilon_y''\\end{bmatrix} \\\\\n=\\begin{bmatrix}\\mu_x'\\\\\\mu_x''\\\\0\\end{bmatrix}-\\begin{bmatrix}1 & 0&0\\\\1 & 1 &0\\\\0&1&1\\end{bmatrix}\\begin{bmatrix}1.5 \\cdot \\varepsilon_x +  \\varepsilon_x''\\\\ 2 \\cdot \\varepsilon_x' \\\\ \\varepsilon_x + 2 \\cdot \\varepsilon_x''\\end{bmatrix}+\\begin{bmatrix}g'({\\mu}_x,{\\mu}_v)\\cdot (1.5 \\cdot \\varepsilon_y + \\varepsilon_y'')\\\\ g'({\\mu}_x,{\\mu}_v)\\cdot 2 \\cdot \\varepsilon_y' \\\\ g'({\\mu}_x,{\\mu}_v)\\cdot (\\varepsilon_y + 2 \\cdot \\varepsilon_y'')\\end{bmatrix} \\\\\n$$\nAs you can already see, $\\mu_x'$ is not cancelled out and moreover even higher orders like $\\mu_x''$ start to trickle in. It is the active inference algorithm making use of the information available in the higher order coordinates of motion to make better predictions (although in this specific example there is no noise in the generative process yet) If the resulting estimation is \"better\" or if the extra effort to calculate the higher order of motions is \"worth it\" remains to be concluded. For now let's concluded that solutions 2.01 and 1.01 are in the same order of magnitude, not exactly the same but quite close. Hydar will survive the small difference in temperature.\n","1053063f":"Given the partial derivative of the Free energy used in the update equations:\n\n$$\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$$\n\nHow much weigh the prediction errors of the higher order of motions in these equations given the precision matrices $\\tilde\\Pi_{{w}}$ and $\\tilde\\Pi_{{z}}$ to come to precision weighted prediction errors? To figure this out we simply have to look at the calculated matrices to give you an intuition how much the higher orders are influencing the Free Energy\n\n\n#### coloured noise\nBoth precision matrices are generated with a filter variance $= \\frac{1}{2000}$ for the coloured noise experiments in this notebook.\nas you can see below, estimating the weighting by considering only the diagonal, if the position (top left) is 100% weighted in the equations the speed is 0.16% weighted, the acceleration is 0.000033% weighted, etc. \n\n#### No noise\nI opted to estimate the variance of the filter as 1\/64 (very smooth noise, no rough\/white noise) in case of no noise in the generative process, so both precision matrices are generated with a filter variance $= \\frac{1}{64}$ for the experiments with no noise in this notebook.\nas you can see below, estimating the weighting by considering only the diagonal, if the position (top left) is 100% weighted in the equations the speed is 5% weighted, the acceleration is 0.03%, etc. This gives you the intuition how much the higher orders are influencing the Free Energy. In order words, active inference can make use a lot of the information in the higher order coordinates of motion (since there is no noise in the generative process)\n\n#### White noise\nBoth precision matrices are generated with a filter variance 1e-5 for the experiments with white noise in this notebook.The higher order coordinates of motion are hardly weighted (e.g. acceleration is 0.003% weighted).","b2eda8c3":"### Notes\n\n* As expected the orange line follows the sensory input\/ generative process stronger then the balanced or trust genmodel lines.","49c4e460":"## How the brain might function - code example 2\n### Free Energy Principle tutorial without a PhD\n  \n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/05\/08\/08\/44\/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https:\/\/pixabay.com\/users\/geralt-9301\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann<\/a> from <a href=\"https:\/\/pixabay.com\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay<\/a> <\/center>   \n<br>\n\nWelcome to my notebook on Kaggle. I did record my notes with examples so it might help others in their journey to understand **Active Inference** minimizing the underlying **Free Energy**. Neuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https:\/\/en.wikipedia.org\/wiki\/Free_energy_principle) (FEP) by [Karl Fristion](https:\/\/en.wikipedia.org\/wiki\/Karl_J._Friston): The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist.\n\nThis is a code example notebook and it belongs to a series of notebooks on the Free Energy Principle tutorial without a PhD. If you are interested to have a deep understanding of this code please read the \"Free Energy Principle tutorial without a PhD\" series ([part 1](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1), [part 2](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), [part 3](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-3), [part 4](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4)). There is a lot to explain but I promise you an excellent journey into something that might hold the key to true AI.","dcb2ef68":"## Experiment 2.10 - Inference in a dynamic environment with coloured noise\nSame experiment as 2.08 but now woth coloured noise present in the generative process.","84c78d6f":"## Generalised sensory observations\nThe generative model of Hydar expects sensory observations in generalised coordinates of motion ($\\tilde y$). What we need to calculate is $\\tilde y=\\begin{bmatrix} y, y', y'', y''', ...\\end{bmatrix}^T$. In this notebook I created 3 possibilities to create these types of sensory signals.\n* Expand, the simplest method by adding zeros for all higher orders of motion, e.g. 42 in generalised coordinates of motion order p=3 becomes $[42,0,0,0]^T$. It basically is the case whereby the sensor cannot read the higher order motions. In the example of Hydar it can only read the temperature and not the rate of change, or if the change is accelerating, etc. \n* Exact, calculate the  generalised coordinates of motion of the sensory signal by the exact differential equations of the generative process, thus $\\tilde y=\\begin{bmatrix} y, y', y'', y''', ...\\end{bmatrix}^T=\\begin{bmatrix} y, \\dot y, \\ddot y, \\dddot y, ...\\end{bmatrix}^T$. To calculate the higher order of motions in a state space system it needs some explanation to understand the code:  \n\n    * $\\dot y=\\frac{\\partial y}{\\partial t} =\\frac{\\partial g_{gp}(x,v)}{\\partial t}=\\frac{\\partial g_{gp}(x,v)}{\\partial x}\\frac{\\partial x}{\\partial t}=\\frac{\\partial g_{gp}(x,v)}{\\partial x}\\dot x= g'_{gp}(x,v)f_{gp}(x,v)$  \n    * $\\ddot y=\\frac{\\partial^2 y}{\\partial t^2}=\\frac{\\partial \\dot y}{\\partial t}=\\frac{\\partial (g_{gp}'(x,v)*f_{gp}(x,v))}{\\partial t}=\\frac{\\partial (g_{gp}'(x,v))}{\\partial t}f_{gp}(x,v)+g_{gp}'(x,v)\\frac{\\partial (f_{gp}(x,v))}{\\partial t}=\\frac{\\partial (g_{gp}'(x,v))}{\\partial x}\\frac{\\partial x}{\\partial t}f_{gp}(x,v) + g_{gp}'(x,v)\\frac{\\partial (f_{gp}(x,v))}{\\partial x}\\frac{\\partial x}{\\partial t}\\\\=g_{gp}''(x,v)f_{gp}(x,v)^2+g_{gp}'(x,v)f_{gp}'(x,v)f_{gp}(x,v) $   \n    * $\\dddot y=\\frac{\\partial^3 y}{\\partial t^3}=\\frac{\\partial \\ddot y}{\\partial t}=\\frac{\\partial (g_{gp}''(x,v)*f_{gp}(x,v)^2+g_{gp}'(x,v)f_{gp}'(x,v)f_{gp}(x,v))}{\\partial t}=\\frac{\\partial (g_{gp}''(x,v)f_{gp}(x,v)^2)}{\\partial t}+f_{gp}'(x,v)\\frac{\\partial (g_{gp}'(x,v)f_{gp}(x,v))}{\\partial t} \\\\ = g_{gp}'''(x,v)f_{gp}(x,v)^3+2g_{gp}''(x,v)f_{gp}(x,v)^2f_{gp}'(x,v)+f_{gp}'(x,v) \\left(  g_{gp}''(x,v)f_{gp}(x,v)^2+g_{gp}'(x,v)f_{gp}'(x,v)f_{gp}(x,v) \\right )$\n\n\n* Note:\n    * $f'(x,v)=\\frac{\\partial f(x,v)}{\\partial x}$  ,  $g'(x,v)=\\frac{\\partial g(x,v)}{\\partial x}$  and  $\\dot x =\\frac{\\partial x}{\\partial t}$. Thus  $f'(x,v)$  is the partial derivative of function f with respect to x and  $\\dot x$  is the time derivative of $x$.\n    * v is a constant in this notebook, so omitting $\\frac{\\partial f(x,v)}{\\partial v}\\frac{\\partial v}{\\partial t}$ and $\\frac{\\partial g(x,v)}{\\partial v}\\frac{\\partial v}{\\partial t}$ because they are 0\n    * Since $f'(x)$ is a constant ($f(x)$ is a linear function) it can be pulled out of the integration and therefore the math simplifies somewhat    \n\n* Backward, calculate the higher order motions by using the backward [taylor expansion](https:\/\/en.wikipedia.org\/wiki\/Taylor_series), using the previous sensory values to provide a first order numerical approximation of the higher order derivatives. e.g. $speed=\\frac{position_{(t)} - position_{(t-1)}}{dt}$. I opted here to only use past sensory observations (hence I called it backward) and not future ones since Hydar cannot predict the future (especially when we start adding sensory impact by action into the equation in coming notebooks).\n","78b2b618":"# Experiment 2.12 - Noise estimation is important\nIf there is one thing I learned, it is how relevant the noise smoothness variance parameters are ($s_w^2$ and $s_z^2$). They effectively determine how much the higher order coordinates of motion are weighted in the calculations (They are used to calculate the precision matrices $\\tilde \\Pi_w$ and $\\tilde \\Pi_z$). The basic idea is that active inference makes use of the information available in the higher order coordinates of motion to make better predictions. But what would happen if these estimates are not correct?\n \n","feb02f60":"## Generative model\n \n\nThis example is with generalised coordinates of motion. Remember from the [second notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2) that $\\tilde x$ is a shorthand notation for\n$$\n\\tilde x=\n\\begin{bmatrix}\nx\n\\\\ \nx' \n\\\\ \nx'' \n\\\\ \n...\n\\\\ \nx^{(p)}\n\\end{bmatrix}\n$$\nWhere the symbol ' means the time derivative d\/dt as estimated by the brain at point t, '' the second derivative, etc. In this example x is the depth\/position, so the Hydar brain is not just estimating the position but also the instantaneous trajectory at the position x  \n\n$$\n\\tilde x=\n\\begin{bmatrix}\nposition \\: x\n\\\\ \nspeed \\: at\\: position\\: x \n\\\\ \nacceleration\\: at\\: position\\: x \n\\\\ \n...\n\\\\ \nx^{(p)}\n\\end{bmatrix}\n$$\nand by doing so Hydar should be able to better predict the motion of $x$ because it simply has more information at its disposal (assuming Hydar estimates e.g. higher order sensory information correct. In experiment 2.12 you'll find an example where higher order sensory information estimates are not correct with nasty consequences for Hydar)\n\nThe generative model (model in the Hydra brain to encode a probabilistic model of the environment\/world in which it is immersed) for Hydar is essentially the same as the generative process but added the higher order generalised motions:   \n\n\n$$ \\mathcal{D} \\tilde x = \\tilde f(\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde w   \\\\\n \\tilde y = \\tilde g (\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde z$$  \n\nwhere\n* Often also written as e.g. $\\tilde f(\\tilde x, \\tilde v)$ but selected here the notation form $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ to highlight these are brain estimates.\n* The function of motion  $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} f(\\mu_x,\\mu_v), \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$ and $f(\\mu_x,\\mu_v)=a\\mu_x+\\mu_v$ is given as input and a=-1 equal to the generative process. In short Hydar beliefs it is moving towards its top-down hierarchical prior $\\mu_v$\n* The function of sensory mapping $\\tilde g(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} g(\\mu_x,\\mu_v), \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$ where $g(\\mu_x,\\mu_v)$ is given as input and is equal to the true generative process. \n\n## Generalised Free Energy\nAs explained in the [second active inference notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), the Free Energy for one active inference capsule in generalised coordinates of motion (applying the Laplace\/mean-field approximation) is:\n$$\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix} = \\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y}) - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix}$$\nWhere\n* $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $  is the the motion prediction error.\n* $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $ is the sensory prediction error. \n* In this notebook we assuming noise levels are constant during inferencing and the Free Energy calculated (because $-\\frac{1}{2} ln\\begin{vmatrix}\\tilde \\Pi\\end{vmatrix}$ is constant with respect to finding the optimum $\\tilde \\mu_x$) as:\n\n$$\\mathcal{F}(\\tilde y, \\mu) =\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$$\n\n\n\n\n## Inference by gradient descent\nAs explained in the [fourth notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4), the gradient descent for a single active inference capsule in generalised coordinates of motion can be compactly written in matrix notation as: \n$$    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\left( \\frac{\\partial \\tilde{\\varepsilon}_x^\\top}{\\partial \\tilde{\\mu}_x}\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\frac{\\partial \\tilde\\varepsilon_y^\\top}{\\partial \\tilde{\\mu_x}}\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y \\right) $$\nwhere the generalised prediction error $\\tilde{ \\varepsilon}_x$  is (remember $f(\\mu_x,\\mu_v)=a\\mu_x+\\mu_v$ and $f'(\\mu_x,\\mu_v)=a$ ):  \n\n$$\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $$  \n$$\n=\n\\begin{bmatrix}\n\\mu_x'\n\\\\ \n\\mu_x'' \n\\\\ \n\\mu_x''' \n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}\n-\n\\begin{bmatrix}\nf({\\mu}_x,\\mu_v)\n\\\\ \n\\partial_{\\mu_x}f({\\mu}_x,\\mu_v)\\cdot{{\\mu}_x}'\n\\\\ \n\\partial_{\\mu_x}f({\\mu}_x,\\mu_v)\\cdot{{\\mu}_x}''\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix} \n$$\n\n$$\n=\n\\begin{bmatrix}\n\\mu_x' - (a\\mu_x + \\mu_v)\n\\\\ \n\\mu_x'' - a{{\\mu}_x}' \n\\\\ \n\\mu_x''' - a{{\\mu}_x}''\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}\n$$\n$$=  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - [\\mu_v,0,0,..]^T  $$\nwhere $\\tilde A = a \\cdot I_{p+1}$  \nAnd now it is also easy to observe that\n$$ \\frac{\\partial \\tilde{\\varepsilon}_x^\\top}{\\partial \\tilde{\\mu}_x}= \\left( \\mathcal{D} - \\tilde A \\right)^T $$\n\nand the generalised prediction error $\\tilde{ \\varepsilon}_y$  is :  \n\n$$\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $$\n\n$$\n=\n\\begin{bmatrix}\ny\n\\\\ \ny' \n\\\\ \ny'' \n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}\n-\n\\begin{bmatrix}\ng({\\mu}_x,{\\mu}_v)\n\\\\ \n\\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\n\\\\ \n\\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}$$\n\nOr as calculated in the AI_capsule SW as: \n$$\n=\n\\begin{bmatrix}\ny\n\\\\ \ny' \n\\\\ \ny'' \n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}\n-\n\\begin{bmatrix}\ng({\\mu}_x,{\\mu}_v)\n\\\\ \n0\n\\\\ \n0\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}\n-\n\\begin{bmatrix}\n0\n\\\\ \n\\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\n\\\\ \n\\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}$$\n\nAnd now it is also easy to observe that\n$$ \\frac{\\partial \\tilde{\\varepsilon}_y^\\top}{\\partial \\tilde{\\mu}_x}= \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T $$\n\nNote that in case of a LTI (Linear Time Invariant) state space model with an equation of sensory mapping given as $g(\\mu_x,\\mu_v)=c\\mu_x$  and $g'(\\mu_x,\\mu_v)=c$ then it can be written as:\n$$\n=\n\\begin{bmatrix}\ny-c{\\mu}_x\n\\\\ \ny'-c{\\mu}_x'\n\\\\ \ny''-c{\\mu}_x''\n\\\\ \n.\n\\\\ \n.\n\\end{bmatrix}$$\n$$\n=  \\tilde y - \\tilde C \\tilde{ \\mu}_x  $$\nwhere $\\tilde C = c \\cdot I_{p+1}$  \nAnd now it is also easy to observe that\n$$ \\frac{\\partial \\tilde{\\varepsilon}_y^\\top}{\\partial \\tilde{\\mu}_x}= \\left( - \\tilde C \\right)^T $$\n\n\n\nSo we can write down the partial derivative of the Free energy as:\n$$\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$$\n\nOr in case of a linear state space as:\n$$\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\tilde C \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$$\n\n$\\tilde \\Pi_w$: the precision matrix of the generalised noise $\\tilde w$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{x}$ at all orders of motion and is calculated as :\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_w}^{-1}= (S(s_w^2) \\otimes \\Sigma_w )^{-1}  $$\n$\\tilde \\Pi_z$: the precision matrix of the generalised noise $\\tilde z$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{y}$ at all orders of motion and is calculated as :\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_z}^{-1}= (S(s_z^2) \\otimes \\Sigma_z )^{-1}  $$\n\n","bc51088c":"# Generative process\n\nThe generative process (the simulation environment simulating the external environment\/world generating the sensory states in this example) is defined by a simple LTI (Linear Time Invariant) [State Space model](https:\/\/en.wikipedia.org\/wiki\/State-space_representation):\n\n$$ \\begin{align*} \\dot x = f_{gp}(x,v) + w &\\Rightarrow  \\dot x = ax + v + w \\: \\: ; a=-1\\\\\ny = g_{gp}(x,v)+z &\\Rightarrow y = t_0 -\\frac{16}{1+e^{5-\\frac{x}{5}}}+ z \\: \\: ; t_0=25 \\end{align*}$$   \n  \nwhere\n* $x$ is the position (depth in centimetres) and $\\dot x$ expresses the motion of $x$\n* $y$ is the temperature (degrees Celsius)\n* The function of motion  $f_{gp}(x,v)$ of this example is dynamic (in contrast to the first example where it was static) and defined as $f_{gp}(x,v) = -x+v$. In the software below more generic implemented as $ax+v$ where $a=-1$. In other words, Hydar moves towards depth $v$: if x=v there is no motion, if x>v then $f_{gp}(x,v)<0$ ( decreases x to v) and if x<v then $f_{gp}(x,v)>0$ (increases x to v) \n* The derivative of the function of motion with respect to $x$ is  $f'_{gp}(x,v) = a$\n* The function of sensory mapping  $g_{gp}(x,v)$  of this example is defined as $g_{gp}(x,v) = t_0 -\\frac{16}{1+e^{5-\\frac{x}{5}}}$ with $t_0=25$ ,  see picture and code below.\n* The derivative of the function of sensory mapping with respect to $x$ is $g'_{gp}(x,v) = -\\frac{16e^{5-\\frac{x}{5}}}{5\\left(1+e^{5-\\frac{x}{5}}\\right)^2}$ (calculated upfront with some good old high-school math)\n\n\n\n","84d1a090":"#### Notes\n* Ouch, in case Hydar expects smooth noise but in reality is in a white noise environment it is lost if it estimates the generalised motions of the sensory signals by a backward method (use the previous sensory values to provide a first order numerical approximation of the higher order derivatives). If it would get the exact higher order generalised motions of the sensory signals (but no idea what biological sensor could calculate that) or simply use the bare position estimation and not the higher order derivatives, it would still work OK-ish. In itself not so strange the estimates get out of control using previous sensory values with significant white noise, for example (snap shot of some actual data): [13.04437722 , 13.95059295 , 13.37895339 , 14.67872492] and calculate the acceleration \"(y[i]-3*y[i-1]+3*y[i-2]-y[i-3])\/dt^3\" you will get 26794131 which is a very large acceleration. Not a problem if the higher order motions are weighted very small, e.g. with an $s^2$<<1, but otherwise cause for wrong predictions.\n\nBelow an interesting case where Hydar estimates the noise with $s_w^2, s_z^2 = 1$ (Remember normally $s_w^2, s_z^2 << 1$)","e720725f":"# Scope code example 2\nThe second code example is a use-case including generalised coordinates of motion for perceptual inference.\n\nScope of the example: \n* One active inference capsule (single hidden state x, single sensory channel y and single hierarchical prior v) \n* **With generalised coordinates of motion**  \n* Dynamic environment\n* The generative model $\\mu_\\theta$ and expected precision of uncertainty $\\mu_\\lambda$ are invariant during the process and for this example given as input. Remember ${\\mu}_x$ is estimated by fast neuronal states while $\\mu_\\theta$ and $\\mu_\\lambda$ adapt on slower timescales (e.g. synaptic efficacy) so invariant during perceptual inference. We simply assume the generative model \/ noise estimation has already been learned and is known (so, function of motion and sensory mapping are given as input).   \n* The brain estimate for the hierarchical prior ($\\mu_v)$ is given as input\n* Active inference by minimizing the Free Energy for one active inference capsule:   \n\n$$\\tilde \\mu_x=\\underset{\\tilde \\mu_x }{Argmin}\\:  \\mathcal{F}( \\tilde y,\\mu) $$ \n* by iteratively taking steps proportional to the negative of the partial derivative of the Free Energy with respect to $\\mu_x$.\n","0ed96c99":"### Notes\n* The resulting curious initial motion can be best explained by looking at the precision matrix where you can see on the diagonal that speed is weighted 50 relative to position 15 (see below). In other words, the algorithm gives higher weight to get the speed first matched right at the expense of the position (which is first moving counter intuitive). \n* Note that it also has to do with the initialisation of the hidden state, in this case [25,0,0,0],e.g. the belief of the initial velocity is 0 but the actual velocity is 5. You can try out for yourself with an exact initialisation by un-commenting \"mu_x_init_tilde = motion_generalize_exact(p, x_init,v)\" in the code. ","d3e1c647":"### Notes\n* As you can observe, despite the noise, active inference is able to track the depth\/temperature.","1351d425":"## Experiment 2.02 - Observe what is expected\nQuick check that what happens if the prior expectation and actual sensor readings do match. Hydar's prior and its actual depth is 25 centimeters, so it is expecting and receiving a temperature of approximately 17 degrees.","8eaed1b9":"<a id='sec2'><\/a>\n# Active inference code version 0.2\nThe heart of the predictive coding for perceptual inference you will find in the inference_step function, where 1 iteration of perceptual inference is executed every time it is called.  \n1. First the  2 prediction errors are calculated\/executed: \n  * $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - \\tilde \\mu_v  $ where $\\tilde A = a \\cdot I_{p+1}$\n  * $\\tilde{ \\varepsilon}_y= \\tilde y -\\begin{bmatrix}g({\\mu}_x,{\\mu}_v)\\\\ 0\\\\ 0\\\\ .\\\\ .\\end{bmatrix}-\\begin{bmatrix}0\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\\\ .\\\\ .\\end{bmatrix}$\n  \n1. Next the motion of the hidden state is calculated\/executed:  \n$$    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\left( \\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y \\right) $$\n\nWhere the [forward Euler method](https:\/\/en.wikipedia.org\/wiki\/Euler_method) is used to execute the motion of $\\dot\\mu_x$.  \n\n","5b0a9dcf":"### Notes\n* By estimating the motions from the sensory readings (backward method) the line is is not straight for embedding order 4.This example is to showcase the effect of floating-point numeric errors which are the root-cause why you see a small deviation. See example below to multiply 1.1 by 3 to showcase what is meant by this numeric error effect. Interesting to see that active inference simply deals with it and the typical curve appears to get an estimation of 30.00000000010 . The numeric error appears for example in the math used to calculate the third derivative \"y[i]-3*y[i-1]+3*y[i-2]-y[i-3]\" (and all observations y[i]..y[i-3] are equal), it is not exactly zero due to this effect. There is a science field called \"numerical analysis\", and is a very large and complex field to try to solve this. Don't think a simple being like Hydar is equipped with it, neither is it a problem to get this small deviation to survive. Just be aware of it for now.","02c043be":"## Experiment 2.08 - Inference in a dynamic environment\nThus far I have used static examples to compare the results with the first code notebook. It is about time to also look at examples with motion in the generative process. In this case the initial depth of Hydar is 25 centimeters and it will sink to 30 centimeters. Hydars internal belief\/prior is 30 centimeters. There is no noise in the generative process (although the generative model expects noise to be present).","8b425b2b":"## Experiment 2.05 - Coloured noise\nSame set-up as experiment experiment 2.01 but now with actual coloured noise in the generative process ","cbb67e59":"## Experiment 2.04 - White noise\nSame set-up as experiment 2.01 but now with some actual white noise in the generative process.","bd2d9bfd":"## Notes\nBasically the some conclusions as experiment 1.06\n* If there is a high precision (low variance), Hydar beliefs it's model\/sensors are more accurate so it can faster converge to the estimation.\n* If there is a low precision (high variance), Hydar takes longer to converge to the position or temperature.\n* Makes sense, the higher (the internal belief of) the precision, the lower uncertainty, the \u00a8bigger steps\u00a8 to converge because Hydar can trust the signals\/beliefs.\n","ead119ec":"## Notes\n* The belief of the hidden state and prediction of the sensory signal is quite stable despite noisy sensory signals.\n* As in the first experiment the prediction with embedding order 1 and the prediction with no generalised coordinates of motion have the exact same result. Higher embedding orders do differ somewhat and are closer to the sensor input. \n* Notice that the delta between active inference p=2 or p=3 vs. p=0 differs also more with colored noise. In experiment 1.01 no noise the delta was 0.1-0.2 , in experiment 1.04 white noise the delta is 0.4-0.5, in this experiment with coloured noise 0.2-0.3. Higher embedding orders are closer to the sensor input. ","84dbce09":"### Notes\n* As you can observe, despite the noise, active inference is able to track the depth\/temperature.","ef6dee70":"## Experiment 2.09 - Inference in a dynamic environment II\nIn this case the initial depth of Hydar is 25 centimeters and it will sink to 30 centimeters. Hydars internal belief\/prior is now 30 centimeters. There is no noise in the generative process (although the generative model expects noise to be present).","fcf77550":"## Long live Hydar!\n\nThe example is set in the simulation environment where Hydar needs to infer its depth based on temperature sensor readings, even when the sensor readings are not what is expected. All while the water is moving. In this example there is a buoyancy (or current) that drives Hydar to a depth of 10 cm.\n\nAs introduced in the 4th notebook, [Hydar](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4\/#sec4) is an early evolutionary imaginary aquatic ancestor that must preserve its physical integrity to survive. For example, it needs to keep in a certain depth range.  \n\nRemember from the [first notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1) that in essence the brain is a prediction mechanism, one that attempts to minimize the error of its hypothesis about the world and the sensory input it receives:\n* The skull-bound brain needs to infer the world.\n* The brain builds an internal model of the world using Bayesian inference (the generative model).\n* Discrepancies between the internal model (the prediction) and the sensory observations result in prediction error.\n* The brain aims to minimize the Free Energy which is equivalent to minimizing prediction errors.\n* By either Improving perception, Acting on the environment, Learning the generative model, Optimizing expected precision of uncertainty. \n\nThe scope of this notebook is improving perception. In this example Hydar's brain is equipped with one active inference capsule to encode the generative model. With one single sensor (y), in this case to measure the temperature, one hidden state it tries to infer (x), in this case the depth, and one prior (v) representing its top-down hypotheses of the hidden state\/depth.  \n\n\n<img src=\"https:\/\/i.imgur.com\/X060mzQ.jpg\" width=800>","4f507e96":"## Experiment 2.03 - Trust your sensors or your prior belief?\nSame set-up as experiment 1.03 but in generalized coordinates of motion. It is experiment 2.01 but now showcase the delta between\n1.  Balanced variances : $\\sigma_z^2$ equals $\\sigma_w^2$ \n1.  Confidence in own sensory observations (bottom-up): low variance $\\sigma_z^2$ compared to $\\sigma_w^2$\n1.  Confidence in the internal model including prior (top-down): low variance $\\sigma_w^2$ compared to $\\sigma_z^2$\n\nFor this example there is no noise in the generative process yet (although the generative model expects noise to be present) to best see how the belief develops.","dccc46b8":"## Notes\nBasically the same results as experiment 1.07\n* The purple line shows the temperature and depth resulting from the low precision sensory input (a significant variance of 10 in both sensor readings and depth in the generative process). The corresponding active inference estimation is the orange (low precision) line. Interesting to see that despite the orange line goes all over the place the green line is relative straight. Good for Hydar else it would be very dizzy. \n","7b9945a4":"### notes\n* As expected, the sensor readings and prior confirm immediately, only 1 observation needed for Hydar to know it's depth. A good sign to showcase the strength of a model with top-down predictions and bottom-up sensory observations to perceive the world fast. \n* The Free Energy is zero, optimal \n\nOne other effect I noticed during testing which might be interesting for readers of this notebook, see below."}}