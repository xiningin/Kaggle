{"cell_type":{"baa13d4e":"code","f7e509c1":"code","ba64f596":"code","0e32313b":"code","945eb07f":"code","79b601ca":"code","f2812ba7":"code","277679a2":"code","be90c560":"code","57063578":"code","cba890e4":"code","a8d1be54":"code","86c4fda0":"code","505da666":"code","43d57443":"code","f91df412":"code","adfbbd22":"code","7b9a73be":"code","ef300ad8":"code","9ea44a02":"code","c9f2d102":"code","18ed4196":"code","95056ccb":"markdown","2bf96e75":"markdown","1cafcf00":"markdown","d8fc96ea":"markdown","59aa7f50":"markdown","df4ad498":"markdown","ed7a0cc2":"markdown","2f0ab266":"markdown","c2725e1a":"markdown","2e5b7ad0":"markdown","4a0f4eeb":"markdown","9eef7edd":"markdown","82105d29":"markdown","649ca96f":"markdown","d0a97847":"markdown","228719a0":"markdown","1594c126":"markdown","643b553a":"markdown","8e7b8e4c":"markdown","2ae07c44":"markdown","5ffc239d":"markdown"},"source":{"baa13d4e":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f7e509c1":"# loading the Boston dataset\nfrom sklearn.datasets import load_boston\nhouse_price = load_boston()\ndf_labels = pd.DataFrame(house_price.target)\ndf = pd.DataFrame(house_price.data)\nprint(df_labels.head())\nprint(df.head())","ba64f596":"df_labels.columns = ['PRICE']\ndf.columns = house_price.feature_names\nprint(df.shape)\nprint(df_labels.shape)","0e32313b":"df_total = df.merge(df_labels, left_index = True, right_index = True)\ndf_total.head()","945eb07f":"\ndf_total.describe()\ndf_total.info()","79b601ca":"plt.hist(df_labels['PRICE'], bins = 8)","f2812ba7":"from scipy.stats import skew,kurtosis \nprint(skew(df_labels['PRICE']))\nprint(kurtosis(df_labels['PRICE'])) ","277679a2":"corr_matrix = df_total.corr(method = 'pearson')\ncorr_matrix ","be90c560":"# standardize and train\/test split: standardize only data, not target\ndf = preprocessing.scale(df)\nX_train, X_test, y_train, y_test = train_test_split(\n    df, df_labels, test_size=0.3, random_state=10)","57063578":"lin_reg = LinearRegression()\nlin_reg.fit(X_train,y_train)","cba890e4":"#on train set\nfrom sklearn.metrics import mean_squared_error\ny_train_predicted = lin_reg.predict(X_train)\nlin_mse = mean_squared_error(y_train_predicted, y_train)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","a8d1be54":"print(lin_reg.intercept_)\nprint(lin_reg.coef_)","86c4fda0":"#on test set\ny_test_predicted = lin_reg.predict(X_test)\nlin_mse = mean_squared_error(y_test_predicted, y_test)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","505da666":"#let's see how rmse compares to the rest of the target var desciptives\ndf_labels['PRICE'].describe()","43d57443":"#do the same with ridge\nridge_reg = Ridge(alpha=0)\nridge_reg.fit(X_train, y_train)\ny_train_predicted = ridge_reg.predict(X_train)\nridge_mse = mean_squared_error(y_train_predicted, y_train)\nridge_rmse = np.sqrt(ridge_mse)\nridge_rmse ","f91df412":"ridge_reg = Ridge(alpha=50)\nridge_reg.fit(X_train, y_train)\ny_train_predicted = ridge_reg.predict(X_train)\nridge_mse = mean_squared_error(y_train_predicted, y_train)\nridge_rmse = np.sqrt(ridge_mse)\nridge_rmse ","adfbbd22":"from sklearn.linear_model import RidgeCV\nregr_cv = RidgeCV(alphas=[0.1,0.3, 0.5,0.7, 1.0, 10.0, 50.0])\nmodel = regr_cv.fit(X_train, y_train)","7b9a73be":"model.alpha_","ef300ad8":"y_train_predicted = regr_cv.predict(X_train)\nridge_mse = mean_squared_error(y_train_predicted, y_train)\nridge_rmse = np.sqrt(ridge_mse)\nridge_rmse ","9ea44a02":"def function(i):\n    ridge_reg = Ridge(alpha = i)\n    ridge_reg.fit(X_train, y_train)\n    y_train_predicted = ridge_reg.predict(X_train)\n    ridge_mse = mean_squared_error(y_train_predicted, y_train)\n    ridge_rmse = np.sqrt(ridge_mse)\n    print(ridge_rmse)","c9f2d102":"function(0.1)","18ed4196":"#on test set\ny_test_predicted = ridge_reg.predict(X_test)\nlin_mse = mean_squared_error(y_test_predicted, y_test)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","95056ccb":"Here I'm having a look at the variables to see if there are any missings to take care of, or categorial variables that should be encoded.","2bf96e75":"After importing I'm splitting the data in two:  1. my target variable, the price - df_labels, and 2. the rest of the independent variables, df.","1cafcf00":"Looks good, almost perfect normal distribution, checking also skewness and kurtosis, that are not bad.","d8fc96ea":"And let's see what RMSE I'll find on the test data with the value for alpha:","59aa7f50":"All good, but they have no column names, must add them:","df4ad498":"Fortunately this is a nice database, no missings and to categorial variables :) ","ed7a0cc2":"And then cheking the RMSE of my model:","2f0ab266":"Now I'm applying the model on the test data:","c2725e1a":"In the next step I'm scaling the data and then splitting it in train\/test data to begin training my model.","2e5b7ad0":"And finally, I'm using a Ridge cross-validation that will help tell me which alpha is the best from a list of alphas:","4a0f4eeb":"Then I'm having a look at the distribution of my target variable, the price:","9eef7edd":"Fiting the regression:","82105d29":"And getting an RMSE a bit higher.\nNow, I want to compare the error I got with the variable itself (expressed in 1Ks): so there's an error of 5.41 on a variable with values between 5 and 50, and a mean of 22.","649ca96f":"In this notebook I tried to run a simple, normal regression and a Ridge regression; Ridge regressions can perform less well on training datasets but better on test datasets because they take into consideration that not all variables are as important as others in the prediction of the dependent variable. \nThe normal regression treates all parameters in an unbiased way.","d0a97847":"Here I'm testing with a new alpha to see how the RMSE changes:","228719a0":"Or I can write it as a function:","1594c126":"Firstly, I'm importing what I need; the database I'll be using is Boston Housing prices, and can be directly loaded (versions I found here on Kaggle didn't have all the variables I has used before).","643b553a":"Now moving on to the Ridge regression; now, in the first example the alpha is 0 so the RMSE is identical to the one above:","8e7b8e4c":"RMSE when we're using the alpha we got after cross-validation:","2ae07c44":"Then, I'm creating a new complete dataframe, just in case I'll need it.\n","5ffc239d":"Then I'm getting to the point that I'm very interested in, the correlations; here a bit of research was needed to get an understanding of the variables, I'm going to mention some of the highly correlated ones:\nLSTAT is the % of the population with lower status, RM is the number of rooms, PTRATIO is the ration between pupils and teachers, TAX is the tax rate."}}