{"cell_type":{"e7a7322f":"code","456c8c79":"code","708b1e56":"code","a3fb8478":"code","e78afaa6":"code","e0bda3f2":"code","d443da1d":"code","a5076b55":"code","41cb1371":"code","f93e94f9":"code","2ce4e1c2":"code","83cef102":"code","ac424c97":"code","fb6c777c":"code","04846757":"code","444e338e":"markdown","68fb488e":"markdown","099adf73":"markdown","c3dfe529":"markdown","daf42149":"markdown","b0a8c27b":"markdown","c27d1e48":"markdown","b52626b2":"markdown","79fb2c77":"markdown"},"source":{"e7a7322f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Classificadores Scikit - https:\/\/www.it-swarm.dev\/pt\/python\/lista-de-todos-os-algoritmos-de-classificacao\/830155863\/\nfrom sklearn.ensemble import (AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier)\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n\n#M\u00e9tricas e pontua\u00e7\u00e3o de avalia\u00e7\u00e3o - https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#classification-metrics\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.feature_selection import SelectFromModel\n\n\nclassifiers_name = [\"Random Forest\", \"QDA\", \"Gaussian Process\", \n                    \"Perceptron\", \"Gaussian Mixture\", \"Naive Bayes Multinomial\", \"Nearest Neighbors\", \"Neural Net\",\n                    \"SVC\", \"Decision Tree\"]\nclassifiers_type = [RandomForestClassifier(), QuadraticDiscriminantAnalysis(), GaussianProcessClassifier(), \n                    Perceptron(), GaussianMixture(), MultinomialNB(), KNeighborsClassifier(), MLPClassifier(),\n                    SVC(), DecisionTreeClassifier()]\n\nscoring_list = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n\n#https:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html\nimportance_classifiers = [AdaBoostClassifier(), ExtraTreesClassifier(),RandomForestClassifier()]\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","456c8c79":"def base_dados_select():\n    global dados_treino, dados_teste, df, dados_inicial, rotulos, nome_recursos_inicial\n    dados_treino = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n    dados_teste = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n    df = pd.concat([dados_treino, dados_teste])\n    dados_treino.rename(columns={'Survived':'target'}, inplace=True)\n    dados_teste.rename(columns={'Survived':'target'}, inplace=True)\n    df.rename(columns={'Survived':'target'}, inplace=True)\n    df['target'].fillna(-1, inplace=True)\n    \n    # Convert objects in integer by quantity order\n    dados_treino['Sex'] = dados_treino['Sex'].replace({'male', 'female'},{0, 1})\n    labels = dados_treino['Ticket'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_treino['Ticket'].replace(labels,codes,inplace=True)\n    labels = dados_treino['Cabin'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_treino['Cabin'].replace(labels,codes,inplace=True)\n    labels = dados_treino['Embarked'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_treino['Embarked'].replace(labels,codes,inplace=True) \n    dados_teste['Sex'] = dados_teste['Sex'].replace({'male', 'female'},{0, 1})\n    labels = dados_teste['Ticket'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_teste['Ticket'].replace(labels,codes,inplace=True)\n    labels = dados_teste['Cabin'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_teste['Cabin'].replace(labels,codes,inplace=True)\n    labels = dados_teste['Embarked'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    dados_teste['Embarked'].replace(labels,codes,inplace=True) \n    df['Sex'] = df['Sex'].replace({'male', 'female'},{0, 1})\n    labels = df['Ticket'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    df['Ticket'].replace(labels,codes,inplace=True)\n    labels = df['Cabin'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    df['Cabin'].replace(labels,codes,inplace=True)\n    labels = df['Embarked'].value_counts(ascending=True).index.tolist()\n    codes = range(1,len(labels)+1)\n    df['Embarked'].replace(labels,codes,inplace=True)\n    \n    # Convert float in integer with round up\n    dados_treino['Age'] = dados_treino['Age'].apply(np.ceil)\n    dados_teste['Age'] = dados_teste['Age'].apply(np.ceil)\n    df['Age'] = df['Age'].apply(np.ceil)\n    \n    # Move target to the end\n    df = df[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked','target']]\n    dados_treino = dados_treino[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked','target']]\n    \n    # Separate dataset in independent and dependent attributes\n    dados_inicial = dados_treino.iloc[:, :-1].values\n    rotulos = dados_treino.iloc[:, -1].values\n    nome_recursos_inicial = dados_treino.iloc[:, :-1].columns.tolist()","708b1e56":"def base_dados_analyse_simple(nome_recursos, uniq_val):\n    # Print data descriptions to understand formats and if total quantity equals unique\n    print(df.head())\n    print(df.info())\n    df_analyse = df.describe()\n    df_analyse = df_analyse.transpose()\n    df_analyse = df_analyse.assign(c_unique = df.nunique(dropna=False))\n    print(df_analyse)\n\n    # Print unique values: to check NaN values and errors\n    if (uniq_val == 1):\n        for col in df:\n            print(col, sorted(df[col].unique()))\n    \n    # Check outliers\n    nr = 0\n    # Round Up\n    len_recursos = len(nome_recursos)\/\/2 + (len(nome_recursos) % 2 > 0)\n    fig, ax = plt.subplots(len_recursos,2, figsize=(20,20))\n    for i in range(len(ax)):\n        for j in range(len(ax[i])):\n            if (nr<len(nome_recursos)):\n                ax[i][j] = sns.stripplot(data=df, y=nome_recursos[nr], jitter=True, ax=ax[i][j])\n                nr += 1\n    fig.suptitle('Checking outliers', position=(.5,1.1), fontsize=20)\n    fig.tight_layout()\n    fig.show()","a3fb8478":"def base_dados_analyse_advanced(dataset, nome_recursos, var_graph, size_x, size_y, var_subplot, var_stacked, dado_x , dado_y): \n    # Round Up\n    len_recursos = len(nome_recursos)\/\/2 + (len(nome_recursos) % 2 > 0)\n    \n    # Graphs\n    if (var_graph == 'area'): ax = dataset.plot(kind='area', figsize=(size_x, size_y), subplots=var_subplot, stacked=var_stacked, title='Area Dados')\n    elif (var_graph == 'line'): ax = dataset.plot(kind='line', figsize=(size_x, size_y), subplots=var_subplot, stacked=var_stacked, title='Linha Dados', x=dado_x, y=dado_y)\n    elif (var_graph == 'bar'): ax = dataset.plot(kind='bar', figsize=(size_x, size_y), subplots=var_subplot, stacked=var_stacked, title='Barra Dados')\n    elif (var_graph == 'barh'): ax = dataset.plot(kind='barh', figsize=(size_x, size_y), subplots=var_subplot, stacked=var_stacked, title='Barra Horizontal Dados')\n    elif (var_graph == 'box'): ax = dataset.plot(kind='box', figsize=(size_x, size_y), subplots=var_subplot, title='Box Dados')\n    elif (var_graph == 'hist'): ax = dataset.plot(kind='hist', figsize=(size_x, size_y), subplots=var_subplot, bins=15, alpha=0.5, title='Histograma Dados')\n    elif (var_graph == 'kde'): ax = dataset.plot(kind='kde', figsize=(size_x, size_y), subplots=var_subplot, title='Densidade Dados', layout=(len_recursos,2))\n    elif (var_graph == 'pie'): ax = dataset.plot(kind='pie', figsize=(size_x, size_y), subplots=var_subplot, title='Pizza Dados')\n    elif (var_graph == 'hexbin'): ax = dataset.plot(kind='hexbin', figsize=(size_x, size_y), subplots=var_subplot, title='HexBin Dados', x=dado_x, y=dado_y)\n    elif (var_graph == 'scatter'): ax = dataset.plot(kind='scatter', figsize=(size_x, size_y), subplots=var_subplot, title='Dispers\u00e3o Dados', x=dado_x, y=dado_y)","e78afaa6":"def base_dados_treat():\n    global df, dados_treino, dados_teste, dados_inicial, rotulos, nome_recursos_inicial\n    #Delete Name column because of PassengerID and Cabin column for having most (1014\/1309) of NaN values \n    dados_treino = dados_treino.drop(['Name', 'Cabin'], axis=1)\n    dados_teste = dados_teste.drop(['Name', 'Cabin'], axis=1)\n    df = df.drop(['Name', 'Cabin'], axis=1)\n    \n    # Check NaN and errors: Replaces NaN by mean\n    dados_treino = dados_treino.fillna(dados_treino.mean())\n    dados_teste = dados_teste.fillna(dados_teste.mean())\n    df = df.fillna(df.mean())\n    \n    # Check outliers: Delete values\n    dados_treino = dados_treino[(dados_treino.Age < 75)]\n    dados_treino = dados_treino[(dados_treino.Fare < 300)]\n    dados_treino = dados_treino[(dados_treino.Parch < 5)]\n    dados_teste = dados_teste[(dados_teste.Age < 75)]\n    dados_teste = dados_teste[(dados_teste.Fare < 300)]\n    dados_teste = dados_teste[(dados_teste.Parch < 5)]\n    df = df[(df.Age < 75)]\n    df = df[(df.Fare < 300)]\n    df = df[(df.Parch < 5)]\n    \n    # Re separate dataset in independent and dependent resources\n    dados_inicial = dados_treino.iloc[:, :-1].values\n    rotulos = dados_treino.iloc[:, -1].values\n    nome_recursos_inicial = dados_treino.iloc[:, :-1].columns.tolist()","e0bda3f2":"def classificadores( dados, rotulos, cross_value, var_predict ):\n    global clf_name, avg_scores\n    clf_name = classifiers_name\n    avg_scores = []\n    avg_scores_1 = []\n    avg_scores_2 = []\n    avg_scores_3 = []\n    print('Number of metrics: ', len(scoring_list))\n    print('Number of classifiers evaluated: ', len(classifiers_type))\n    \n    # Evaluation of all classifiers on the list\n    for clf in classifiers_type:\n        clf.fit(dados, rotulos)\n        scores = cross_validate(clf, dados, rotulos, cv=4, scoring=scoring_list)\n        for score in scoring_list:\n            avg_scores.append(scores['test_'+score].mean())\n            \n    # Rank 3 first positions for classifier evaluation\n    for j in range(0, 2*len(scoring_list), len(scoring_list)):\n        for i in range(j, len(avg_scores)-len(scoring_list), len(scoring_list)):\n            if (avg_scores[j] < avg_scores[i+len(scoring_list)]):\n                if (i ==len(avg_scores)-2*len(scoring_list)):\n                    avg_scores[:len(scoring_list)],avg_scores[-len(scoring_list):] = avg_scores[-len(scoring_list):],avg_scores[j:len(scoring_list)]\n                    clf_name[:len(scoring_list)\/\/len(scoring_list)],clf_name[-len(scoring_list)\/\/len(scoring_list):] = clf_name[-len(scoring_list)\/\/len(scoring_list):],clf_name[:len(scoring_list)\/\/len(scoring_list)]\n                else:\n                    avg_scores[j:len(scoring_list)],avg_scores[(i+len(scoring_list)):(i+2*len(scoring_list))] = avg_scores[(i+len(scoring_list)):(i+2*len(scoring_list))],avg_scores[j:len(scoring_list)]\n                    clf_name[j\/\/len(scoring_list):len(scoring_list)\/\/len(scoring_list)],clf_name[(i+len(scoring_list))\/\/len(scoring_list):(i+2*len(scoring_list))\/\/len(scoring_list)] = clf_name[(i+len(scoring_list))\/\/len(scoring_list):(i+2*len(scoring_list))\/\/len(scoring_list)],clf_name[j\/\/len(scoring_list):len(scoring_list)\/\/len(scoring_list)]\n    avg_scores_1 = avg_scores[:len(scoring_list)]\n    avg_scores_2 = avg_scores[len(scoring_list):(2*len(scoring_list))]\n    avg_scores_3 = avg_scores[(2*len(scoring_list)):(3*len(scoring_list))]\n    \n    # Print classifiers ranking\n    print('Classifiers ranking:')\n    print(clf_name[0]+': ', avg_scores_1)\n    print(clf_name[1]+': ', avg_scores_2)\n    print(clf_name[2]+': ', avg_scores_3)\n    \n    # Comparative chart\n    df_clf = pd.DataFrame({clf_name[0]: avg_scores_1,\n                       clf_name[1]: avg_scores_2,\n                       clf_name[2]: avg_scores_3}, index=scoring_list)\n    ax = df_clf.plot(kind='bar' , rot=0, title='Compare classifiers')\n    \n    # Predict test data\n    if (var_predict == 1):\n        print('CLF_LOOKUP: ', clf_name[0])\n        clf_index = classifiers_name.index(clf_name[0])\n        print('CLF_INDEX: ', clf_index)\n        clf = classifiers_type[clf_index]\n        print('CLF: ', clf)\n        clf.fit(dados, rotulos)\n        test_predict = clf.predict(dados_teste)\n        test_predict = test_predict.astype('int64')\n        submission = pd.DataFrame()\n        submission['PassengerId'] = dados_teste['PassengerId']\n        submission['Survived'] = test_predict\n        print(submission['Survived'].value_counts())\n        submission.to_csv(r'Submission.csv', index = False, header = True)","d443da1d":"def atributos( dados, rotulos, numero_imp, var_print, var_graph ):\n    global dados_novo, nome_recursos_novo\n    if (numero_imp >= 0):\n        # Evaluation of the chosen importance classifier\n        clf = importance_classifiers[numero_imp]\n        clf.fit(dados, rotulos)\n        importance = clf.feature_importances_\n        print(\"Attributes importance: \", importance)\n        std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n        indices = np.argsort(importance)[::-1]\n        print(\"Attributes indices: \", indices)\n        # Print attributes ranking\n        if (var_print == 1):\n            print(\"Attributes ranking:\")\n            for f in range(dados.shape[1]):\n                print(\"%d. atributo %d (%f)\" % (f + 1, indices[f], importance[indices[f]]))\n                \n        # Attributes importance graph\n        if (var_graph == 1):\n            plt.figure()\n            plt.title(\"Attributes importance\")\n            plt.bar(range(dados.shape[1]), importance[indices], align=\"center\")\n            plt.xticks(range(dados.shape[1]), indices)\n            plt.xlim([-1, dados.shape[1]])\n            plt.show()\n            \n        # Select most important attributes\n        model = SelectFromModel(clf, prefit=True)\n        dados_novo = model.transform(dados)\n        n_attrs = dados_novo.shape[1]\n        idx_most_important = importance.argsort()[-n_attrs:]\n        print(idx_most_important)\n        nome_recursos_novo = np.array(nome_recursos_inicial)[idx_most_important]\n        print(nome_recursos_novo)","a5076b55":"base_dados_select()\nbase_dados_analyse_simple(nome_recursos_inicial, True)","41cb1371":"base_dados_treat()\nbase_dados_analyse_simple(nome_recursos_inicial, False)","f93e94f9":"base_dados_analyse_advanced(df, nome_recursos_inicial, 'bar', 20, 20, True, False, None , None)","2ce4e1c2":"base_dados_analyse_advanced(df, nome_recursos_inicial, 'kde', 20, 20, True, False, None , None)","83cef102":"classificadores(dados_inicial, rotulos, 4, 0)","ac424c97":"atributos(dados_inicial, rotulos, 1, 1, 1)","fb6c777c":"pwd","04846757":"classificadores(dados_inicial, rotulos, 4, 1)","444e338e":"## Treat data","68fb488e":"## Check importance level and select the most important attributes","099adf73":"# Import libraries","c3dfe529":"## Get data","daf42149":"# Analyse and treat data","b0a8c27b":"## Classifiers: Selects, trains, evaluates and compares top 3 and predicts with the best","c27d1e48":"# Functions","b52626b2":"# Classify, select atributes and predict","79fb2c77":"## Analyse data"}}