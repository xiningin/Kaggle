{"cell_type":{"f74eb983":"code","8a17b695":"code","415d02d4":"code","6da169ab":"code","5f232fab":"code","0286a549":"code","59e02dab":"code","73b73b98":"code","1130b6e9":"code","6d353124":"code","d4ad2b5e":"code","10100a3a":"code","15e54889":"code","7f5b47e3":"code","fe86bc13":"code","a3538a35":"code","b5430327":"code","5dbf67d8":"code","9beac559":"code","b0953e79":"code","faba186f":"code","cf6ab104":"code","815c0e66":"code","677e1aec":"code","179a84ef":"code","57b525e0":"code","e5867636":"code","cf527fd4":"code","bc46fc55":"code","1dda54b8":"code","30162baf":"code","8d40772e":"code","b7e2a479":"code","3ac0c8a3":"code","de6c453f":"code","9838b3c3":"code","7382d36a":"code","0b573cf6":"code","ec47aa6b":"code","f641cbe4":"code","8f04e3e6":"code","6e35c369":"code","9ccf3e54":"code","2c41ec4d":"markdown","838ef2c4":"markdown"},"source":{"f74eb983":"# adresses ip\n#import re\n#a = df.copy()\n#\"a['ip'] = a['text'].apply(lambda string : re.findall( r'[0-9]+(?:\\.[0-9]+){3}', string))\n#a[a['ip'].str.len()>=1]","8a17b695":"# smiley into text ? (brackets)\n#import re\n#a = df.copy()\n#a['brackets'] = a['text'].apply(lambda string : re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", string))\n#a[a['brackets'].str.len()>=1]","415d02d4":"#df[df['text'].str.contains(\"FVCK\")]","6da169ab":"#df[df['text'].str.contains(\"Your edits to\")] # et les majuscules apr\u00e8s","5f232fab":"#df_train = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\n#df_train[(df_train['less_toxic'].str.contains(\"Your edits to\")) | (df_train['more_toxic'].str.contains(\"Your edits to\"))] # et les majuscules apr\u00e8s","0286a549":"#df[(df['text'].str.contains(\"sockpuppet\")) | (df['text'].str.contains(\"sock puppet\"))]","59e02dab":"#df[df['text'].str.contains(\"STFU\")]","73b73b98":"#df[(df['text'].str.contains(\"Re:\")) | (df['text'].str.contains(\"Reply:\")) | (df['text'].str.contains(\"RE:\")) | (df['text'].str.contains(\"REDIRECT:\"))]","1130b6e9":"#df[df['text'].str.contains(\"User:\")]","6d353124":"#df[df['text'].str.contains(\"nonsense to Wikipedia\")]","d4ad2b5e":"#df[df['text'].str.contains(\"is considered vandalism\")]","10100a3a":"#df[df['text'].str.contains(\"Please stop your disruptive editing\")]","15e54889":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","7f5b47e3":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ndf.head()","fe86bc13":"\"\"\"\n# Cr\u00e9ation de paires arbitraires\nnb = 1000\n\n# M\u00e9lange\nfrom sklearn.utils import shuffle\ndf_ = shuffle(df[['text']].drop_duplicates())\ndf_ = df_[~df_['text'].str.contains('#')]\n\n# Cr\u00e9ation\npaire1 = df_.sample(n = nb, random_state = 1).reset_index(drop=True)['text']\npaire2 = df_.sample(n = nb, random_state = 2).reset_index(drop=True)['text']\npaires = pd.DataFrame({'text1': paire1, 'text2': paire2})\n\n# R\u00e9sultat\nprint(paires.shape)\npaires.head()\n\n# Export CSV\npaires.to_csv('paires_1000_test.csv', sep = '#', index=False)\n\"\"\"","a3538a35":"CONFIG = dict(\n    seed = 42,\n    model_name = '..\/input\/roberta-base',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","b5430327":"MODEL_PATHS = ['..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-0.bin',\n               '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-1.bin',\n               '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-2.bin',\n               '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-3.bin',\n               '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-4.bin']\n\n\n\"\"\"\nMODEL_PATHS = [ '..\/input\/lossfold20211114\/Loss-Fold-0.bin',\n                '..\/input\/lossfold20211114\/Loss-Fold-1.bin',\n                '..\/input\/lossfold20211114\/Loss-Fold-2.bin',\n                '..\/input\/lossfold20211114\/Loss-Fold-3.bin',\n                '..\/input\/lossfold20211114\/Loss-Fold-4.bin']\n\nMODEL_PATHS = ['..\/input\/k\/vincentschuler\/pytorch-w-b-jigsaw-starter\/Loss-Fold-0.bin',\n               '..\/input\/k\/vincentschuler\/pytorch-w-b-jigsaw-starter\/Loss-Fold-1.bin',\n               '..\/input\/k\/vincentschuler\/pytorch-w-b-jigsaw-starter\/Loss-Fold-2.bin',\n               '..\/input\/k\/vincentschuler\/pytorch-w-b-jigsaw-starter\/Loss-Fold-3.bin',\n               '..\/input\/k\/vincentschuler\/pytorch-w-b-jigsaw-starter\/Loss-Fold-4.bin']\n\"\"\"\nprint()","5dbf67d8":"import os\nfrom datetime import datetime\n\nfor file_path in MODEL_PATHS :\n    statbuf = os.stat(file_path)\n    date_derniere_modif = statbuf.st_mtime\n    date_derniere_modif = datetime.fromtimestamp(date_derniere_modif).strftime(\"%A, %B %d, %Y %I:%M:%S\")\n    print(\"Dern\u00e8re modif de {}: {}\".format(file_path, date_derniere_modif))","9beac559":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","b0953e79":"# Traitement\ndef corrige_text(text) :\n    # Suppression des sauts de lignes\n    text = text.replace('\\n', ' ')\n    \n    # Dico : 'vrai mot' : [mots \u00e0 remplacer]\n    dico_replace = {'fuck' : ['F U C K', 'F UCK', 'FU\u00a9K', 'F'],\n                    'you' : ['U']}\n    # Traitement\n    for vrai_mot, liste in dico_replace.items() :\n        for mot_a_remplacer in liste :\n            for mot in (mot_a_remplacer.lower(), mot_a_remplacer.upper()) :\n                if len(mot) > 1 : # attention aux lettres solos\n                    text = text.replace(mot, vrai_mot)\n                else :\n                    text = ' '.join([x if x != mot else vrai_mot for x in text.split(' ')])\n    \n    # R\u00e9sultat\n    return text\n\n# -------------------------\n\ndf['text'] = df['text'].apply(lambda text : corrige_text(text))","faba186f":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","cf6ab104":"test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)","815c0e66":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs","677e1aec":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","179a84ef":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","57b525e0":"preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])","e5867636":"print(f\"Total Predictions: {preds.shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","cf527fd4":"df['score'] = preds\ndf.head()","bc46fc55":"df['score'] = df['score'].rank(method='first')\ndf.head()","1dda54b8":"#df.drop('text', axis=1, inplace=True)\n#df.to_csv(\"submission.csv\", index=False)","30162baf":"# Open the file\ndf_train = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\n\nprint('Dim AVANT :', df_train.shape)","8d40772e":"# If the pair has been ranked by multiple worker, we keep the order that is most unanimous\ndf_train['TEXT_ranked'] = df_train.apply(lambda row : row['less_toxic'] + ':' + row['more_toxic'], axis = 1)\ndf_train['TEXT_paire'] = df_train.apply(lambda row : min(row['less_toxic'], row['more_toxic']) + ':' + max(row['less_toxic'], row['more_toxic']), axis = 1)\ndf_train['Count_paire_ranked'] = df_train.groupby(['TEXT_ranked'])['TEXT_ranked'].transform('count')\ndf_train['Count_paire'] = df_train.groupby(['TEXT_paire'])['TEXT_ranked'].transform('count')\ndf_train['count_max'] = df_train.groupby(['TEXT_paire'])['Count_paire_ranked'].transform(max)\n\n# Selection\ndf_train = df_train[df_train['Count_paire_ranked'] == df_train['count_max']]\ndf_train = df_train[df_train['Count_paire_ranked'] == 3] # every workers agreed\n\n# Delete duplicates\ndf_train = df_train.drop(columns = ['worker'])\ndf_train = df_train.drop_duplicates()\n\n# Results\ndf_train = df_train.sort_values(by = ['TEXT_ranked'])\ndf_train = df_train.drop(columns = ['Count_paire', 'Count_paire_ranked', 'count_max', 'TEXT_ranked', 'TEXT_paire']).drop_duplicates()\nprint('Dim APRES :', df_train.shape)\ndf_train.head()","b7e2a479":"#!pip install openpyxl\n#import openpyxl\n#paires_toxic = pd.read_excel(\"..\/input\/paires-excel\/paires_toxic.xlsx\")\n#paires_toxic = paires_toxic[paires_toxic['MORE_TOXIC_1_ou_2'].isin([1, 2])]\n#paires_toxic.to_csv('paires_toxic_CSV.csv', index=False, sep='#', encoding='utf-8')\n\n#paires_toxic = pd.read_csv(\"..\/input\/paires-csv-new\/paires_toxic_CSV (2).csv\", sep = '#', encoding = 'utf-8')","3ac0c8a3":"# Ajout des donn\u00e9es manuelles\npaires_toxic = pd.read_csv(\"..\/input\/paires-csv-new\/paires_toxic_CSV (2).csv\", sep = '#', encoding = 'utf-8')\npaires_toxic = paires_toxic[paires_toxic['MORE_TOXIC_1_ou_2'].isin([1, 2])]\n\ndef less(row) :\n    if row['MORE_TOXIC_1_ou_2'] == 1 : return row['text2']\n    if row['MORE_TOXIC_1_ou_2'] == 2 : return row['text1']\ndef more(row) :\n    if row['MORE_TOXIC_1_ou_2'] == 1 : return row['text1']\n    if row['MORE_TOXIC_1_ou_2'] == 2 : return row['text2']\n    \npaires_toxic['less_toxic'] = paires_toxic.apply(lambda row : less(row), axis=1)\npaires_toxic['more_toxic'] = paires_toxic.apply(lambda row : more(row), axis=1)\n#paires_toxic['worker'] = pd.Series(['99999999']*len(paires_toxic))\n\npaires_toxic = paires_toxic[['less_toxic', 'more_toxic']]\nprint(\"Nb paires manuelles :\", paires_toxic.shape)\n\n# Ajout des donn\u00e9es manuelles\nprint(\"Nb paires manuelles AVANT :\", df_train.shape)\ndf_train = df_train.append(paires_toxic)\nprint(\"Nb paires manuelles APRES :\", df_train.shape)","de6c453f":"#df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\n#df['score'] = preds\n#df['score'] = df['score'].rank(method='first')\n#df.head()","9838b3c3":"# Add score to the validation dataset\ndf_train = df_train.merge(df[['text', 'score']], left_on = 'less_toxic', right_on = 'text', how = 'left').drop_duplicates()\ndf_train = df_train.rename(columns = {'score' : 'score_less'})\ndf_train = df_train.drop(columns = ['text'])\ndf_train = df_train.merge(df[['text', 'score']], left_on = 'more_toxic', right_on = 'text', how = 'left').drop_duplicates()\ndf_train = df_train.rename(columns = {'score' : 'score_more'})\ndf_train = df_train.drop(columns = ['text'])\n\n# Stats\ndf_train.head()","7382d36a":"# Stats\nprint(len(df_train[df_train['score_more'] < df_train['score_less']]), '\/', len(df_train))","0b573cf6":"# Test\ndf_train[df_train['score_more'] < df_train['score_less']].sort_values(['less_toxic'])","ec47aa6b":"# Correction of scores\ndf_train['score_max_du_less_toxic'] = df_train.groupby(['less_toxic'])['score_more'].transform(min) # score_min des textes + toxics\ndf_train['score_min_du_more_toxic'] = df_train.groupby(['more_toxic'])['score_less'].transform(max) # score_max des textes - toxics\n\n# Join\ndf = df.merge(df_train[['less_toxic', 'score_less', 'score_max_du_less_toxic']], left_on = ['text', 'score'], right_on = ['less_toxic', 'score_less'], how = 'left')\ndf = df.drop(columns = ['less_toxic', 'score_less'])\ndf = df.merge(df_train[['more_toxic', 'score_more', 'score_min_du_more_toxic']], left_on = ['text', 'score'], right_on = ['more_toxic', 'score_more'], how = 'left')\ndf = df.drop(columns = ['more_toxic', 'score_more'])\n\n# Rename\ndf = df.rename(columns = {'score_max_du_less_toxic' : 'borne_max', 'score_min_du_more_toxic' : 'borne_min'}) # le score doit est + petit que borne_max\ndf = df[['comment_id', 'text', 'score', 'borne_min', 'borne_max']].drop_duplicates()\n\n# Aper\u00e7u\ndf.head()","f641cbe4":"# CORRECTION DES SCORES\ndef corrige(row) :\n    score, borne_min, borne_max = row['score'], row['borne_min'], row['borne_max']\n    \n    if not(pd.isna(borne_min)) and not(pd.isna(borne_max)) :\n        if borne_max < borne_min : return (borne_max + borne_min ) \/\/ 2 # return score\n        if score < borne_min : return borne_min+1\n        if score > borne_max : return borne_max-1\n        else :\n            return score\n        \n    elif not(pd.isna(borne_min)) :\n        if score < borne_min : return borne_min+1\n        else : return score\n\n    elif not(pd.isna(borne_max)) :\n        if score > borne_max : return borne_max-1\n        else : return score\n        \n    else :\n        return score\n    \n# --------------------\n\n# Application of correction\ndf['score_corrige'] = df.apply(lambda row : corrige(row), axis=1)\ncorrections = df[df['score'] != df['score_corrige']]\nprint(\"Nb of corrections : {}\/{}.\".format(len(corrections), len(df)))\n\n\n# Show\ncorrections[['comment_id', 'text', 'score', 'score_corrige']]","8f04e3e6":"\"\"\"\n# Cr\u00e9ation de paires du test set\nnb = 1500\n\n# M\u00e9lange\nfrom sklearn.utils import shuffle\ndf_ = df[~df['text'].str.contains('#')]\ndf_ = df_[df_['text'].str.len() < 200]\ndf_ = df_.sort_values(by = ['score']).reset_index(drop=True)\n\n# PAIRES GENTILLES\na = df_.iloc[:600]\npaire1 = a.sample(n = nb\/\/4, random_state = 1).reset_index(drop=True)\npaire2 = a.sample(n = nb\/\/4, random_state = 2).reset_index(drop=True)\ngentilles = pd.DataFrame({})\ngentilles['text1'] = paire1['text']\ngentilles['text2'] = paire2['text']\ngentilles['score1'] = paire1['score']\ngentilles['score2'] = paire2['score']\n\n# PAIRES NORMALES\na = df_.iloc[1000:1800]\npaire1 = a.sample(n = nb\/\/4, random_state = 1).reset_index(drop=True)\npaire2 = a.sample(n = nb\/\/4, random_state = 2).reset_index(drop=True)\nnormales = pd.DataFrame({})\nnormales['text1'] = paire1['text']\nnormales['text2'] = paire2['text']\nnormales['score1'] = paire1['score']\nnormales['score2'] = paire2['score']\n\n# PAIRES MECHANTES\na = df_.iloc[2000:2800]\npaire1 = a.sample(n = nb\/\/4, random_state = 1).reset_index(drop=True)\npaire2 = a.sample(n = nb\/\/4, random_state = 2).reset_index(drop=True)\nmechantes = pd.DataFrame({})\nmechantes['text1'] = paire1['text']\nmechantes['text2'] = paire2['text']\nmechantes['score1'] = paire1['score']\nmechantes['score2'] = paire2['score']\n\n# PAIRES TOXIC\na = df_.iloc[3000:]\npaire1 = a.sample(n = nb\/\/4, random_state = 1).reset_index(drop=True)\npaire2 = a.sample(n = nb\/\/4, random_state = 2).reset_index(drop=True)\ntoxic = pd.DataFrame({})\ntoxic['text1'] = paire1['text']\ntoxic['text2'] = paire2['text']\ntoxic['score1'] = paire1['score']\ntoxic['score2'] = paire2['score']\n\n# Cr\u00e9ation dataframe\ndf_paires_final = gentilles.append(normales).append(mechantes).append(toxic).reset_index(drop=True)\n\n# R\u00e9sultat\nprint(df_paires_final.shape)\n\n# Export CSV\ndf_paires_final.to_csv('paires_test.csv', sep = '#', index=False)\ndf_paires_final.head()\n\"\"\"\nprint()","6e35c369":"# Rank first\ndf = df[['comment_id', 'text', 'score_corrige']].drop_duplicates()\ndf['score'] = df['score_corrige'].rank(method='first')\ndf = df[['comment_id', 'text', 'score']].drop_duplicates()\n\n# Show\ndf.head()","9ccf3e54":"df = df[['comment_id', 'score']].drop_duplicates()\nprint(df.shape)\ndf.to_csv(\"submission.csv\", index=False)","2c41ec4d":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">\ud83c\udfaf Training Kernel: <strong><a href=\"https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-jigsaw-starter\">[Pytorch + W&B] Jigsaw Starter<\/a><\/strong>.<\/span>\n\n\n<div style = \"padding : 20px; font-size : 16px; background-color: rgb(240, 245, 255); box-shadow: rgba(255, 255, 255, 0.2) 0px 0px 0px 1px inset, rgba(0, 0, 0, 0.9) 0px 0px 0px 1px;\">\n\n<span style = \"font-size : 20px;\">\nHi ! :)\n    <br><br>\n<\/span>\n    \n       \n<div class=\"alert alert-warning\">\n    <b>CREDITS :<\/b> This notebook has been mainly written by <b>Debarshi Chanda<\/b>. Many thanks to him for his amazing work <a href=\"https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating\/discussion\/286471\"> (-> Link)<\/a> !\n<\/div>\n<br>\nThe initial score was <b><u>0.816<\/u><\/b> (LB). I added a little piece of code to obtain <b><u>0.817<\/u><\/b>. The optimization was worth being discussed, so I decided to make this notebook public. <br>\n<a href=\"https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating\/discussion\/287426\">-> Link to the discussion of this topic<\/a>\n\nThe thing is : the private test dataset contains pairs of comments from the validation dataset. So if 3\/3 commentators agreed on the classification on a pair of comments, we definitely should listen to them and adapt our rankings to fit their choices. That is, we must lower the score of a comment such that its new score becomes lower than every score of other comment that have been classified more toxic, and vice versa.\n\n[Click here to see the implementation of this principle](#jump)\n\nTell me what you think of it !\n\n<div style = \"background-color: rgb(180,205,80); font-size : 20px;\">\n    And please <b>UPVOTE<\/b> if you liked the content, I would appreciate it a lot :)\n<\/div>\n    \n<\/div>","838ef2c4":"____\n# Correction of the scores of the comments whose pairs are present in the validation dataset <a id='jump'><\/a>"}}