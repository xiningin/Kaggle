{"cell_type":{"e21be0bb":"code","f7873a39":"code","0b8ff560":"code","c3b19dbd":"code","30320d7c":"code","c3305c8f":"code","ac177306":"code","059b4dac":"code","65579421":"code","cf202502":"code","f6f0abe6":"code","e3086d7c":"code","c29091c9":"code","31e94fc3":"code","75f1b1db":"code","a9a87a47":"code","f7664b65":"code","f483b3f7":"code","5efe6b58":"code","2b105391":"code","ffa4d2dc":"code","8772a875":"code","8ea66f70":"code","caa4ed3c":"code","f0b473dc":"code","93354436":"code","06a2b8a4":"code","7d31dfb8":"code","97277c57":"code","36335a48":"code","b731d424":"code","e1d2a5c2":"code","428202df":"markdown","ca279286":"markdown","e4ede19c":"markdown","39dbfa79":"markdown","de05a487":"markdown","531ea50e":"markdown","516c781d":"markdown","c9b2de0c":"markdown","e8f823c8":"markdown","879a9f93":"markdown","5d57a28f":"markdown","e858579a":"markdown"},"source":{"e21be0bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport random\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7873a39":"df = pd.read_csv(\"\/kaggle\/input\/ocular-disease-recognition-odir5k\/full_df.csv\")\ndf.head(3)","0b8ff560":"def has_cataract(text):\n    if \"cataract\" in text:\n        return 1\n    else:\n        return 0","c3b19dbd":"df[\"left_cataract\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))\ndf[\"right_cataract\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))","30320d7c":"left_cataract = df.loc[(df.C ==1) & (df.left_cataract == 1)][\"Left-Fundus\"].values\nleft_cataract[:15]","c3305c8f":"right_cataract = df.loc[(df.C ==1) & (df.right_cataract == 1)][\"Right-Fundus\"].values\nright_cataract[:15]","ac177306":"print(\"Number of images in left cataract: {}\".format(len(left_cataract)))\nprint(\"Number of images in right cataract: {}\".format(len(right_cataract)))","059b4dac":"left_normal = df.loc[(df.C ==0) & (df[\"Left-Diagnostic Keywords\"] == \"normal fundus\")][\"Left-Fundus\"].sample(250,random_state=42).values\nright_normal = df.loc[(df.C ==0) & (df[\"Right-Diagnostic Keywords\"] == \"normal fundus\")][\"Right-Fundus\"].sample(250,random_state=42).values\nright_normal[:15]","65579421":"cataract = np.concatenate((left_cataract,right_cataract),axis=0)\nnormal = np.concatenate((left_normal,right_normal),axis=0)","cf202502":"print(len(cataract),len(normal))","f6f0abe6":"from tensorflow.keras.preprocessing.image import load_img,img_to_array\ndataset_dir = \"\/kaggle\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\/\"\nimage_size=224\nlabels = []\ndataset = []\ndef create_dataset(image_category,label):\n    for img in tqdm(image_category):\n        image_path = os.path.join(dataset_dir,img)\n        try:\n            image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n            image = cv2.resize(image,(image_size,image_size))\n        except:\n            continue\n        \n        dataset.append([np.array(image),np.array(label)])\n    random.shuffle(dataset)\n    return dataset\n        ","e3086d7c":"dataset = create_dataset(cataract,1)","c29091c9":"len(dataset)","31e94fc3":"dataset = create_dataset(normal,0)","75f1b1db":"len(dataset)","a9a87a47":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(dataset)))\n    image = dataset[sample][0]\n    category = dataset[sample][1]\n    if category== 0:\n        label = \"Normal\"\n    else:\n        label = \"Cataract\"\n    plt.subplot(2,5,i+1)\n    plt.imshow(image)\n    plt.xlabel(label)\nplt.tight_layout()    ","f7664b65":"x = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3)\ny = np.array([i[1] for i in dataset])","f483b3f7":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)","5efe6b58":"from tensorflow.keras.applications.vgg19 import VGG19\nvgg = VGG19(weights=\"imagenet\",include_top = False,input_shape=(image_size,image_size,3))","2b105391":"for layer in vgg.layers:\n    layer.trainable = False","ffa4d2dc":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(vgg)\nmodel.add(Flatten())\nmodel.add(Dense(1,activation=\"sigmoid\"))","8772a875":"model.summary()","8ea66f70":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","caa4ed3c":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\ncheckpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_acc\",verbose=1,save_best_only=True,\n                             save_weights_only=False,period=1)\nearlystop = EarlyStopping(monitor=\"val_acc\",patience=5,verbose=1)","f0b473dc":"history = model.fit(x_train,y_train,batch_size=32,epochs=15,validation_data=(x_test,y_test),\n                    verbose=1,callbacks=[checkpoint,earlystop])","93354436":"loss,accuracy = model.evaluate(x_test,y_test)\nprint(\"loss:\",loss)\nprint(\"Accuracy:\",accuracy)","06a2b8a4":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\ny_pred = model.predict_classes(x_test)","7d31dfb8":"accuracy_score(y_test,y_pred)","97277c57":"print(classification_report(y_test,y_pred))","36335a48":"from mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(conf_mat = cm,figsize=(8,7),class_names = [\"Normal\",\"Cataract\"],\n                      show_normed = True);","b731d424":"plt.style.use(\"ggplot\")\nfig = plt.figure(figsize=(12,6))\nepochs = range(1,16)\nplt.subplot(1,2,1)\nplt.plot(epochs,history.history[\"accuracy\"],\"go-\")\nplt.plot(epochs,history.history[\"val_accuracy\"],\"ro-\")\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Train\",\"val\"],loc = \"upper left\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs,history.history[\"loss\"],\"go-\")\nplt.plot(epochs,history.history[\"val_loss\"],\"ro-\")\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Train\",\"val\"],loc = \"upper left\")\nplt.show()","e1d2a5c2":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(x_test)))\n    image = x_test[sample]\n    category = y_test[sample]\n    pred_category = y_pred[sample]\n    \n    if category== 0:\n        label = \"Normal\"\n    else:\n        label = \"Cataract\"\n        \n    if pred_category== 0:\n        pred_label = \"Normal\"\n    else:\n        pred_label = \"Cataract\"\n        \n    plt.subplot(2,5,i+1)\n    plt.imshow(image)\n    plt.xlabel(\"Actual:{}\\nPrediction:{}\".format(label,pred_label))\nplt.tight_layout() ","428202df":"><h3>Prediction:<\/h3>","ca279286":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Cataract Prediction using vgg19<\/h1>\n\n---","e4ede19c":"><h3>Creating Model<\/h3>","39dbfa79":"><h3>Creating Dataset from images<\/h3>","de05a487":"><h3>Learning Curve<\/h3>","531ea50e":"<h3>Dataset Information:<\/h3>\nOcular Disease Intelligent Recognition (ODIR) is a structured ophthalmic database of 5,000 patients with age, color fundus photographs from left and right eyes and doctors' diagnostic keywords from doctors.This dataset is meant to represent \u2018\u2018real-life\u2019\u2019 set of patient information collected by Shanggong Medical Technology Co., Ltd. from different hospitals\/medical centers in China. In these institutions, fundus images are captured by various cameras in the market, such as Canon, Zeiss and Kowa, resulting into varied image resolutions.Annotations were labeled by trained human readers with quality control management. They classify patient into eight labels including:\n\n- Normal (N),\n- Diabetes (D),\n- Glaucoma (G),\n- Cataract (C),\n- Age related Macular Degeneration (A),\n- Hypertension (H),\n- Pathological Myopia (M),\n- Other diseases\/abnormalities (O)","516c781d":"><h3>Dividing dataset into x(features) & y(target)<\/h3>","c9b2de0c":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading!!<\/h1>\n\n---","e8f823c8":"> <h3> Extracting Cataract & Normal information from the Dataset <\/h3>","879a9f93":"- Here i'm going to make a model which is going to  predict an image is belongs to Normal or Cataract category!","5d57a28f":">Normal Images","e858579a":"><h3>Let's see some images<\/h3>"}}