{"cell_type":{"105cb008":"code","8ef2f8ba":"code","9ef07d8f":"code","54d38941":"code","9730a5e0":"code","c1effa61":"code","27940801":"code","2e20977f":"code","598ddc3d":"code","82fe21cb":"code","a19072ae":"code","45ac987b":"code","06fbf1d7":"code","07fb7a7b":"code","b6a567d7":"code","91eb11d7":"code","27139c25":"code","5065272e":"code","aac8793f":"code","971507fc":"code","8c0cf2f0":"code","eb3e9059":"code","30ef7a42":"code","aecf789f":"code","a00c38cf":"code","36b5f000":"code","54b27cf0":"code","e404f0c6":"code","2e5d5609":"code","03081481":"code","d88706d5":"code","749dfe9c":"code","290e040d":"code","742a2cba":"code","43aeda2b":"code","d736c98f":"code","42138ca4":"code","cbd6dcca":"code","38450f5b":"code","57a8cbe1":"code","47f54017":"code","bbdeeda3":"code","25c95e7d":"markdown","cf7e9f17":"markdown","6f6d9661":"markdown","2c3ea579":"markdown","05b0567e":"markdown","9622b9f1":"markdown"},"source":{"105cb008":"%matplotlib inline\n\nimport os, cv2, csv\nimport random\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom tqdm import tqdm_notebook\nfrom matplotlib.patches import Rectangle\n\nfrom skimage import io\nfrom skimage import measure\nfrom skimage.transform import resize\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, MaxPool2D, UpSampling2D, concatenate, add","8ef2f8ba":"train_labels = pd.read_csv ('..\/input\/rsna-512x512-png\/data\/train_labels.csv')\ntrain_labels = train_labels.drop (['Unnamed: 0'], axis = 1)\ntrain_labels.sample (3)","9ef07d8f":"class_info = pd.read_csv ('..\/input\/rsna-512x512-png\/data\/class_info.csv')\nclass_info = class_info.drop (['Unnamed: 0'], axis = 1)\nclass_info.sample (3)","54d38941":"# count_missing_data\ntrain_labels.isnull ().sum ().sort_values (ascending = False)","9730a5e0":"class_info.isnull().sum().sort_values(ascending = False)","c1effa61":"count = class_info [\"class\"].value_counts()\ncount","27940801":"labels = (np.array(count.index))\nsizes = (np.array((count \/ count.sum())*100))\ncolors = ['violet', 'yellow','red']\n\nplt.pie(sizes, labels = labels, colors = colors,\n        autopct = '%1.1f%%', shadow = True, startangle = 90)\nplt.title(\"Class percentage\")\nplt.show ()","2e20977f":"# merge class and labels\ntrain_class = train_labels.merge (class_info, left_on = 'patientId', right_on = 'patientId', how = 'inner')\ntrain_class.sample (3)","598ddc3d":"class_count = train_class.groupby ('Target')['class'].value_counts()\nclass_count","82fe21cb":"fig, ax = plt.subplots (nrows = 1, figsize = (6,6))\ndf = pd.DataFrame(data = {'Exams': class_count.values}, index = class_count.index).reset_index()\nsns.barplot (ax = ax, x = 'Target', y = 'Exams', hue = 'class',data = df, palette = 'Set3')\nplt.title (\"Chest exams class and Target\")\nplt.show ()","a19072ae":"#Locating the penumonia location\n# adding center in df\ntrain_class  ['x_center'] = train_class ['x'] + train_class ['width'] \/ 2\ntrain_class  ['y_center'] = train_class ['y'] + train_class ['height'] \/ 2\n# Plot x and y centers\nsns.jointplot ('x_center', 'y_center', kind = 'kde', data = train_class, height = 9, alpha = 0.5)\nplt.suptitle ('Pneumonia location')\nplt.show ()","45ac987b":"## Aspect ratio of bounding boxes in the sample\ntrain_class ['aspect_ratio'] = train_class ['width'] \/ train_class ['height']\nsns.distplot (train_class ['aspect_ratio'].dropna (), norm_hist=True)\nplt.title ('Distribution plot: Aspect ratio of bounding boxes of images in the sample')\nplt.show ()","06fbf1d7":"# Area of bounding boxes in the sample\ntrain_class ['area'] = train_class ['width'] * train_class ['height']\nsns.distplot (train_class ['area'].dropna (), norm_hist = True)\nplt.title ('Distribution plot: Area of bounding boxes of images in the sample')\nplt.show ()","07fb7a7b":"# Relationship between aspect ratio and area of bounding boxes of images in the sample\nsns.relplot (x = 'area', y = 'aspect_ratio', data = train_class, height = 5, alpha = 0.7, aspect = 1.4)\nplt.title ('Aspect ratio and area of bounding boxes of images in the sample')\nplt.show ()","b6a567d7":"# For the class Lung Opacity, corresponding to values of Target = 1, we plot the density of x, y, width and height.\ntarget1 = train_class [train_class ['Target'] == 1]\nsns.set_style ('whitegrid')\nplt.figure ()\nfig, ax = plt.subplots (2, 2, figsize = (12, 12))\nsns.distplot (target1 ['x'], kde = True, bins = 50, color = \"violet\", ax = ax [0,0])\nsns.distplot (target1 ['y'], kde = True, bins = 50, color = \"red\", ax = ax[0,1])\nsns.distplot (target1 ['width'], kde = True, bins = 50, color = \"green\", ax = ax [1,0])\nsns.distplot (target1 ['height'], kde = True, bins = 50, color = \"yellow\", ax = ax [1,1])\nlocs, labels = plt.xticks ()\nplt.tick_params (axis = 'both', which = 'major', labelsize = 12)\nplt.show ()","91eb11d7":"img_dir = '..\/input\/rsna-512x512-png\/data\/stage_2_train_images'\nprint ('num images: ', len (os.listdir (img_dir)))","27139c25":"# check for duplicate reconrds in training set\nprint(\"Unique patientId in  train_class: \", train_class ['patientId'].nunique())","5065272e":"train_class.shape","aac8793f":"same_classes = train_class.groupby(['patientId','Target', 'class'])['patientId'].count()\nsame_classes","971507fc":"df = pd.DataFrame (data = {'Exams': same_classes.values}, index = same_classes.index).reset_index()\ndf.sample (3)","8c0cf2f0":"tmp = df.groupby(['Exams','Target','class']).count()\ntmp","eb3e9059":"df2 = pd.DataFrame (data = tmp.values, index = tmp.index).reset_index ()\ndf2.columns = ['Exams', 'Target','Class', 'Entries']\ndf2","30ef7a42":"def show_images (data):\n    img_data = list (data.T.to_dict ().values ())\n    f, ax = plt.subplots (3,3, figsize = (16,18))\n    for i, data_row in enumerate (img_data):\n        patientImage = data_row ['patientId']+'.png'\n        imagePath = os.path.join (img_dir, patientImage)\n        image = cv2.imread (imagePath, cv2.IMREAD_GRAYSCALE)\n        ax [i\/\/3, i%3].imshow (image, cmap=plt.cm.bone)\n        ax [i\/\/3, i%3].axis ('off')\n        ax [i\/\/3, i%3].set_title('ID: {}\\nTarget: {}\\nClass: {}\\nWindow: {}:{}:{}:{}'.format(\n                data_row ['patientId'], data_row ['Target'], data_row ['class'], \n                data_row ['x'], data_row ['y'], data_row ['width'], data_row ['height']))\n        \n    plt.show ()","aecf789f":"show_images (train_class [train_class ['Target'] == 1].sample (9))","a00c38cf":"def show_images_with_bboxes (data):\n    img_data = list (data.T.to_dict ().values ())\n    f, ax = plt.subplots (3,3, figsize = (16,18))\n    for i, data_row in enumerate (img_data):\n        patientImage = data_row ['patientId']+'.png'\n        imagePath = os.path.join (img_dir, patientImage)\n        image = cv2.imread (imagePath, cv2.IMREAD_GRAYSCALE)\n        ax [i\/\/3, i%3].imshow (image, cmap=plt.cm.bone)\n        ax [i\/\/3, i%3].axis ('off')\n        ax [i\/\/3, i%3].set_title('ID: {}\\nTarget: {}\\nClass: {}'.format(\n                data_row ['patientId'], data_row ['Target'], data_row ['class']))\n        \n        rows = train_class [train_class ['patientId'] == data_row ['patientId']]\n        boxes = list (rows.T.to_dict ().values ())\n        for j, row in enumerate (boxes):\n            ax [i\/\/3, i%3].add_patch (Rectangle (xy = (row ['x'], row ['y']),\n                        width = row ['width'], height = row ['height'], \n                        color = \"blue\", alpha = 0.1))\n    plt.show ()","36b5f000":"show_images_with_bboxes (train_class [train_class ['Target'] == 1].sample (9))","54b27cf0":"show_images (train_class [train_class ['Target'] == 0].sample (9))","e404f0c6":"# empty dictionary\npneumonia_locations = {}\n# load table\nwith open ('..\/input\/rsna-512x512-png\/data\/train_labels.csv', mode = 'r') as infile:\n    # open reader\n    reader = csv.reader (infile)\n    # skip header\n    next (reader, None)\n    # loop through rows\n    for rows in reader:\n        # retrieve information\n        filename = rows [1]\n        location = rows [2:6]\n        pneumonia = rows [6]\n        # if row contains pneumonia add label to dictionary\n        # which contains a list of pneumonia locations per filename\n        if pneumonia == '1':\n            # convert string to float to int\n            location = [int (float (i)) for i in location]\n            # save pneumonia location in dictionary\n            if filename in pneumonia_locations:\n                pneumonia_locations [filename].append (location)\n            else:\n                pneumonia_locations [filename] = [location]","2e5d5609":"for location in pneumonia_locations ['00436515-870c-4b36-a041-de91049b9ab4']:\n    x, y, w, h = location","03081481":"mask = np.zeros ((1024, 1024))\nmask [y:y+h, x:x+w] = 1\nmask = resize (mask, ((128, 128)), mode = 'symmetric') > 0.5","d88706d5":"mask.astype (np.float32)","749dfe9c":"# load and shuffle filenames\nfilenames = os.listdir (img_dir)\nrandom.shuffle (filenames)\n# split into train and validation filenames\nn_valid_samples = 2560\ntrain_filenames = filenames [n_valid_samples:]\nvalid_filenames = filenames [:n_valid_samples]\nprint ('n train samples', len (train_filenames))\nprint ('n valid samples', len (valid_filenames))\nn_train_samples = len (filenames) - n_valid_samples\nprint ('Total train images:', len (filenames))\nprint ('Images with pneumonia:', len (pneumonia_locations))","290e040d":"class generator (Sequence):\n    \n    def __init__ (self, folder, filenames, pneumonia_locations = None,batch_size = 32,\n                  image_size = 256, shuffle = True, augment = False, predict = False):\n        \n        self.folder = folder\n        self.filenames = filenames\n        self.pneumonia_locations = pneumonia_locations\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.predict = predict\n        self.on_epoch_end()\n        \n    def __load__(self, filename):\n        # load file as numpy array\n        image = cv2.imread (os.path.join (self.folder, filename), cv2.IMREAD_GRAYSCALE)\n        # create empty mask\n        mask = np.zeros ((1024, 1024))\n        # get filename without extension\n        filename = filename.split ('.')[0]\n\n        # if image contains pneumonia\n        if filename in pneumonia_locations:\n            # loop through pneumonia\n            for location in pneumonia_locations [filename]:\n                # add 1's at the location of the pneumonia\n                x, y, w, h = location\n                mask [y:y+h, x:x+w] = 1\n        # if augment then horizontal flip half the time\n        if self.augment and random.random() > 0.5:\n            image = np.fliplr (image)\n            mask = np.fliplr (mask)\n        # resize both image and mask\n        image = resize (image, (self.image_size, self.image_size), mode = 'symmetric')\n        mask = resize (mask, (self.image_size, self.image_size), mode = 'symmetric') > 0.5\n        mask = mask.astype (np.float32)\n        \n        # add trailing channel dimension\n        image = np.expand_dims (image, -1)\n        mask = np.expand_dims (mask, -1)\n        return image, mask\n    \n    def __loadpredict__(self, filename):\n        # load file as numpy array\n        image = cv2.imread (os.path.join (self.folder, filename), cv2.IMREAD_GRAYSCALE)\n        # resize image\n        image = resize (image, (self.image_size, self.image_size), mode = 'symmetric')\n        # add trailing channel dimension\n        image = np.expand_dims (image, -1)\n        return image\n        \n    def __getitem__(self, index):\n        # select batch\n        filenames = self.filenames [index * self.batch_size: (index+1) * self.batch_size]\n        # predict mode: return images and filenames\n        if self.predict:\n            # load files\n            images = [self.__loadpredict__(filename) for filename in filenames]\n            # create numpy batch\n            images = np.array(images)\n            return images, filenames\n        # train mode: return images and masks\n        else:\n            # load files\n            items = [self.__load__ (filename) for filename in filenames]\n            # unzip images and masks\n            images, masks = zip (*items)\n            # create numpy batch\n            images = np.array (images)\n            masks = np.array (masks)\n            return images, masks\n        \n    def on_epoch_end (self):\n        if self.shuffle:\n            random.shuffle (self.filenames)\n        \n    def __len__(self):\n        if self.predict:\n            # return everything\n            return int (np.ceil (len (self.filenames) \/ self.batch_size))\n        else:\n            # return full batches only\n            return int (len (self.filenames) \/ self.batch_size)","742a2cba":"def create_downsample (channels, inputs):\n    x = BatchNormalization (momentum = 0.9)(inputs)\n    x = LeakyReLU (0)(x)\n    x = Conv2D (channels, 1, padding = 'same', use_bias = False)(x)\n    x = MaxPool2D (2)(x)\n    # Added start\n    #x = Conv2D (channels, 1, padding = 'same', use_bias = False)(x)\n    #x = MaxPool2D (2)(x)\n    # Added End\n    return x\n\n\ndef create_resblock (channels, inputs):\n    x = BatchNormalization (momentum = 0.9)(inputs)\n    x = LeakyReLU (0)(x)\n    x = Conv2D (channels, 3, padding='same', use_bias = False)(x)\n    x = BatchNormalization (momentum = 0.9)(x)\n    x = LeakyReLU (0)(x)\n    x = Conv2D (channels, 3, padding = 'same', use_bias = False)(x)\n\n    #Added Start\n    x = BatchNormalization (momentum = 0.9)(x)\n    x = LeakyReLU (0)(x)\n    x = Conv2D (channels, 3, padding = 'same', use_bias = False)(x)\n    #Added End\n    \n    addInput = x;\n    print (\"Add input shape:\", addInput.shape)\n    print (\"Resnet block input shape:\", inputs.shape)\n    resBlockOut = add ([addInput, inputs])\n    print (\"Resnet block out shape:\", resBlockOut.shape)\n    out = concatenate([resBlockOut, addInput], axis = 3)\n    print (\"concat block out shape:\", out.shape)\n    out = Conv2D (channels, 1, padding = 'same', use_bias = False)(out)\n    print (\"mixed block out shape:\", out.shape)\n    return out\n\ndef create_network (input_size, channels, n_blocks = 2, depth = 4):\n    # input\n    inputs = Input (shape = (input_size, input_size, 1))\n    x = Conv2D (channels, 3, padding = 'same', use_bias = False)(inputs)\n    # residual blocks\n    for d in range (depth):\n        channels = channels * 2\n        x = create_downsample (channels, x)\n        for b in range (n_blocks):\n            x = create_resblock (channels, x)\n    # output\n    x = BatchNormalization (momentum = 0.9)(x)\n    x = LeakyReLU (0)(x)\n    x = Conv2D (1, 1, activation = 'sigmoid')(x)\n    outputs = UpSampling2D (2**depth)(x)\n    model = Model (inputs = inputs, outputs = outputs)\n    return model","43aeda2b":"# define iou or jaccard loss function\ndef iou_loss (y_true, y_pred):\n    y_true = tf.reshape (y_true, [-1])\n    y_pred = tf.reshape (y_pred, [-1])\n    intersection = tf.reduce_sum (y_true * y_pred)\n    score = (intersection + 1.) \/ (tf.reduce_sum (y_true) + tf.reduce_sum (y_pred) - intersection + 1.)\n    return 1 - score\n\n# combine bce loss and iou loss\ndef iou_bce_loss (y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy (y_true, y_pred) + 0.5 * iou_loss (y_true, y_pred)\n\n# mean iou as a metric\ndef mean_iou (y_true, y_pred):\n    y_pred = tf.round (y_pred)\n    intersect = tf.reduce_sum (y_true * y_pred, axis = [1, 2, 3])\n    union = tf.reduce_sum (y_true, axis = [1, 2, 3]) + tf.reduce_sum (y_pred, axis = [1, 2, 3])\n    smooth = tf.ones (tf.shape(intersect))\n    return tf.reduce_mean ((intersect + smooth) \/ (union - intersect + smooth))","d736c98f":"# create network and compiler\nmodel = create_network (input_size = 128, channels = 16, n_blocks = 2, depth = 3)\nmodel.compile(optimizer = 'adam',\n              loss = iou_bce_loss,\n              metrics = ['accuracy', mean_iou])\nprint(\"model summary:\", model.summary ())\n\n# cosine learning rate annealing\ndef cosine_annealing (x):\n    lr = 0.001\n    epochs = 25\n    return lr * (np.cos (np.pi * x \/ epochs) + 1.) \/ 2\nlearning_rate = tf.keras.callbacks.LearningRateScheduler (cosine_annealing)","42138ca4":"train_gen = generator (img_dir, train_filenames, pneumonia_locations,\n                      batch_size = 16, image_size = 128, shuffle = False,\n                      augment = True, predict = False)\nvalid_gen = generator (img_dir, valid_filenames, pneumonia_locations,\n                      batch_size = 16, image_size = 128, shuffle = False,\n                      predict = False)","cbd6dcca":"callbacks = [\n    ModelCheckpoint (filepath = 'RSNA_OD.h5', monitor = 'val_loss', save_best_only = True, verbose = 1),\n    learning_rate\n]","38450f5b":"img, mask = next (iter (train_gen))\nout = model (img)\nprint (img.shape)\nprint (mask.shape)\nprint (out.shape)","57a8cbe1":"history = model.fit (train_gen, validation_data = valid_gen,\n                     callbacks = callbacks, epochs = 5, shuffle = True)","47f54017":"model.load_weights ('.\/RSNA_OD.h5')","bbdeeda3":"for imgs, msks in valid_gen:\n    # predict batch of images\n    preds = model.predict (imgs)\n    # create figure\n    f, axarr = plt.subplots (4, 8, figsize = (20,15))\n    axarr = axarr.ravel()\n    axidx = 0\n    # loop through batch\n    for img, msk, pred in zip(imgs, msks, preds):\n        # plot image\n        axarr[axidx].imshow (img [:, :, 0])\n        # threshold true mask\n        comp = msk [:, :, 0] > 0.5\n        comp = comp.astype (np.float32)\n        # apply connected components\n        comp = measure.label(comp)\n        # apply bounding boxes\n        predictionString = ''\n        for region in measure.regionprops (comp):\n            # retrieve x, y, height and width\n            y, x, y2, x2 = region.bbox\n            height = y2 - y\n            width = x2 - x\n            axarr[axidx].add_patch (patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='b',facecolor='none'))\n        # threshold predicted mask\n        comp = pred[:, :, 0] > 0.5\n        # apply connected components\n        comp = measure.label(comp)\n        # apply bounding boxes\n        predictionString = ''\n        for region in measure.regionprops(comp):\n            # retrieve x, y, height and width\n            y, x, y2, x2 = region.bbox\n            height = y2 - y\n            width = x2 - x\n            axarr[axidx].add_patch(patches.Rectangle((x,y),width,height,linewidth=2,edgecolor='r',facecolor='none'))\n        axidx += 1\n    plt.show()\n    # only plot one batch\n    break","25c95e7d":"## data analysis","cf7e9f17":"## corellation","6f6d9661":"## labels","2c3ea579":"## images","05b0567e":"# Build model & Dataset","9622b9f1":"# Data Exploration"}}