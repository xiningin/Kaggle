{"cell_type":{"62d831b8":"code","c33f16ce":"code","3b8a3d58":"code","f57d2d53":"code","532ddd28":"code","4401f65e":"code","c51832b6":"code","71e7803c":"code","057434ab":"code","8dd05a90":"code","0a23e89b":"code","d4bdaaa2":"code","5f35a69a":"code","2d653124":"code","3bd3ac7e":"code","1d34656c":"code","97003817":"code","7dc767d9":"code","034467e2":"code","a09c26aa":"code","7ae5321c":"code","19723d36":"markdown","14335f1a":"markdown","324e1675":"markdown","fcfe464d":"markdown","4b101898":"markdown","b9c3acdf":"markdown","04b9a02c":"markdown","adcb3d2f":"markdown","5d7298ce":"markdown","aaec4366":"markdown","bd8de8e1":"markdown","22c00554":"markdown","53e1ebad":"markdown","5a43ade2":"markdown","2cc1710e":"markdown"},"source":{"62d831b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom dsClass.path_helper import *\n\n# Any results you write to the current directory are saved as output.","c33f16ce":"from IPython.display import HTML\nfrom IPython.display import YouTubeVideo\n\n#HTML('<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/403jzB62dAs?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen><\/iframe>')\nYouTubeVideo('403jzB62dAs')","3b8a3d58":"import os\n\n# change directory to the dataset where our\n# custom scripts are found\nos.chdir(\"\/kaggle\/input\/\")\n\nfrom dsClass.align_custom import AlignCustom\nfrom dsClass.face_feature import FaceFeature\nfrom dsClass.mtcnn_detect import MTCNNDetect\nfrom dsClass.tf_graph import FaceRecGraph","f57d2d53":"import os, sys, glob\nimport cv2\n\nimport argparse\nimport sys\nimport json\nimport numpy as np\nimport time\n\nimport scipy\nimport scipy.io as sio\nfrom scipy.io import loadmat\nfrom datetime import datetime\nimport pandas as pd\nimport time","532ddd28":"dict_faces = dict()\ndict_faces[\"Jaime Lannister\"] = [\"https:\/\/s2.r29static.com\/\/bin\/entry\/97f\/340x408,85\/1832698\/image.jpg\",\n                                \"https:\/\/upload.wikimedia.org\/wikipedia\/en\/thumb\/b\/b4\/Jaime_Lannister-Nikolaj_Coster-Waldau.jpg\/220px-Jaime_Lannister-Nikolaj_Coster-Waldau.jpg\",\n                                 \"https:\/\/upload.wikimedia.org\/wikipedia\/pt\/thumb\/0\/06\/Nikolaj-Coster-Waldau-Game-of-Thrones.jpg\/220px-Nikolaj-Coster-Waldau-Game-of-Thrones.jpg\",\n                                 \"https:\/\/purewows3.imgix.net\/images\/articles\/2017_09\/jaime-lannister-season-7-game-of-thrones-finale1.jpg?auto=format,compress&cs=strip&fit=min&w=728&h=404\",\n                                 \"https:\/\/cdn.newsday.com\/polopoly_fs\/1.13944684.1502107079!\/httpImage\/image.jpeg_gen\/derivatives\/landscape_768\/image.jpeg\",\n                                 \"https:\/\/www.cheatsheet.com\/wp-content\/uploads\/2017\/08\/Jaime-Lannister-Game-of-Thrones.png\",\n                                 \"https:\/\/fsmedia.imgix.net\/9c\/c0\/27\/10\/15e0\/44a4\/8ecb\/9339993b563d\/nikolaj-coster-waldau-as-jaime-lannister-in-game-of-thrones-season-7.png?rect=0%2C0%2C1159%2C580&dpr=2&auto=format%2Ccompress&w=650\",\n                                 \"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQrIQuBKKUocAizwfWtIdhAcvfowLJatKqqDsO3ywYdh3rv-mBk\"\n                                ]","4401f65e":"import cv2\nimport urllib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef read_image_from_url(url2read):\n    req = urllib.request.urlopen(url2read)\n    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n    img = cv2.imdecode(arr, -1) # 'Load it as it is'\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return(img)","c51832b6":"# Check urls and print last image\nfor p in dict_faces.keys():\n    urls = dict_faces[p]\n    for url2read in urls:\n        print(url2read)\n        img = read_image_from_url(url2read)\nplt.imshow(img)        ","71e7803c":"got_faces_url = \"https:\/\/static.independent.co.uk\/s3fs-public\/thumbnails\/image\/2018\/05\/10\/12\/game-of-thrones-finale.jpg?w968h681\"\nimg = read_image_from_url(got_faces_url)\nplt.imshow(img)","057434ab":"os.chdir(\"\/kaggle\/working\/\")\n!wget https:\/\/github.com\/opencv\/opencv\/raw\/master\/data\/haarcascades\/haarcascade_frontalface_default.xml\n!ls","8dd05a90":"import cv2\n#Create the haar cascade\nface_cascade = cv2.CascadeClassifier('\/kaggle\/working\/haarcascade_frontalface_default.xml')\n\ndef find_faces_in_image(orig_img, scaleFactor, minNeighbors, minSize, maxSize):\n    orig_img_copy = orig_img\n    gray = cv2.cvtColor(orig_img_copy, cv2.COLOR_BGR2GRAY)\n    #plt.imshow(gray) \n    \n    # Detect faces in the image\n    faces = face_cascade.detectMultiScale(\n        gray,           \n        scaleFactor=scaleFactor, \n        minNeighbors=minNeighbors,  \n        minSize=minSize, \n        maxSize=maxSize \n    )\n    \n    print(\"Found {0} faces!\".format(len(faces)))\n\n    # Draw a rectangle around the faces\n    for (x, y, w, h) in faces:\n        cv2.rectangle(orig_img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\n    plt.imshow(orig_img_copy)\n\n\nscaleFactor = 1.3\nminNeighbors = 5\nminSize = (60, 60)   \nmaxSize = (70, 70)\nfind_faces_in_image(img.copy(), scaleFactor, minNeighbors, minSize, maxSize)","0a23e89b":"def find_faces_in_frame_of_video(orig_img, scaleFactor, minNeighbors, minSize, maxSize):\n","d4bdaaa2":"# Fancy box drawing function by Dan Masek\n# Code in: https:\/\/www.codemade.io\/fast-and-accurate-face-tracking-in-live-video-with-python\/\ndef draw_border(img, pt1, pt2, color, thickness, r, d):\n    x1, y1 = pt1\n    x2, y2 = pt2\n \n    # Top left drawing\n    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness)\n    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness)\n    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)\n \n    # Top right drawing\n    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness)\n    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness)\n    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)\n \n    # Bottom left drawing\n    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness)\n    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness)\n    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)\n \n    # Bottom right drawing\n    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness)\n    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness)\n    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness) \n    \n\ndef video_file_recog_haar():\n    print(\"[INFO] Reading video file ...\")\n    video_file = get_file_path(\"Game of Thrones 7x07 - Epic Daenerys Dragonpit Entrance.mp4\")\n    print(video_file)\n    if glob.glob(video_file):\n        vs = cv2.VideoCapture(video_file); #get input from file\n    else:\n        print(\"file does not exist\")\n        return\n    \n    frame_width = int(vs.get(3))\n    frame_height = int(vs.get(4))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    framerate = 10.0\n    video_path = \"\/kaggle\/working\/\"\n    out = cv2.VideoWriter(video_path+'output_haar.mp4', fourcc, framerate, (frame_width,frame_height))\n    \n    frame_counter = 0\n    t0 = time.time()\n    while True:        \n        ret,frame = vs.read();\n        if ret:\n            frame_counter+=1\n            if frame_counter%(30\/framerate)==0:\n                min_face_size = 60 #min face size is set to 60x60\n                rects = find_faces_in_frame_of_video(frame, 1.3, 5, (min_face_size,min_face_size), (70,70))\n                print(\"number of faces found in frame \" + str(frame_counter) + \":\",len(rects))\n                aligns = []\n                positions = []\n                for (i, rect) in enumerate(rects):\n                    draw_border(frame, (rect[0],rect[1]), (rect[0] + rect[2],rect[1]+rect[3]), (255,255,255), 1, 10, 10)\n                    cv2.putText(frame,\"Unknown\",\n                                        (rect[0]-4,rect[1]-4),cv2.FONT_HERSHEY_SIMPLEX,0.35,\n                                        (255,255,255),1,cv2.LINE_AA)\n\n\n                out.write(frame)\n                key = cv2.waitKey(1) & 0xFF\n                if key == ord(\"q\"):\n                    break\n        else:\n            break\n    \n    elapsed_time = time.time() - t0\n    print(\"[exp msg] elapsed time for going over the video: \" + str(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n    vs.release()\n    out.release()\n    cv2.destroyAllWindows()\n    \n    print()\n    print(\"Done\")","5f35a69a":"video_file_recog_haar()","2d653124":"def import_from_images():\n    print()\n    print(\"[INFO] Extracting data from images ...\")\n    data_set = dict()\n\n    for new_name in dict_faces.keys():\n        person_features = {\"Left\" : [], \"Right\": [], \"Center\": []};\n        print(\"Extracting:\",new_name)\n        print(\"number of img files:\",len(dict_faces[new_name]))\n        person_imgs = get_person_imgs(dict_faces[new_name]) \n        if person_imgs is None:\n            print(\"extraction of:\",new_name, \" failed\")\n            continue\n        \n        print(\"extracted person_imgs from:\",new_name)\n\n        for pos in person_imgs:\n            person_features[pos] = [np.mean(extract_feature.get_features(person_imgs[pos]),axis=0).tolist()]\n        data_set[new_name] = person_features;\n        \n    f = open('\/kaggle\/working\/facerec_128D.txt', 'w+'); \n    f.write(json.dumps(data_set))\n    \ndef augment_image(img):\n    aug_images = []\n    flip_img = cv2.flip(img, 1)  #https:\/\/docs.opencv.org\/2.4\/modules\/core\/doc\/operations_on_arrays.html?highlight=flip#cv2.flip\n    # for more example see https:\/\/github.com\/aleju\/imgaug\n    aug_images.append(flip_img)\n    return(aug_images)\n\ndef get_person_imgs(urls):\n    person_imgs = {\"Left\" : [], \"Right\": [], \"Center\": []};\n    person_imgs_count = {\"Left\" : 0, \"Right\": 0, \"Center\": 0};\n    counter_break = 0\n    while True:    \n        for url2read in urls:  \n            img = read_image_from_url(url2read) # ****** file = url2read\n            if img is None:\n                print(\"********************* image was not loaded ***********************\")\n                continue\n\n            frames = [img]\n            frames.extend(augment_image(img))   \n\n            for frame in frames:\n                if True:\n                    rects, landmarks = face_detect.detect_face(frame, 40);  # min face size is set to 40x40\n                    for (i, rect) in enumerate(rects):\n                        aligned_frame, pos = aligner.align(160,frame,landmarks[i]);\n                        person_imgs_count[pos]+=1\n                        if len(aligned_frame) == 160 and len(aligned_frame[0]) == 160:\n                            person_imgs[pos].append(aligned_frame)\n                    key = cv2.waitKey(1) & 0xFF\n                    if key == ord(\"q\"):\n                        break\n                else:\n                    break\n            \n        if person_imgs_count[\"Left\"] == 0 or person_imgs_count[\"Right\"] == 0 or person_imgs_count[\"Center\"] == 0:\n            counter_break+=1\n            if counter_break > 3:\n                print(person_imgs_count)  \n                return None\n        else:\n            break\n                            \n    print(person_imgs_count)    \n    return(person_imgs)  ","3bd3ac7e":"def video_file_recog():\n    print(\"[INFO] Reading video file ...\")\n    video_file = \"\/kaggle\/input\/Game of Thrones 7x07 - Epic Daenerys Dragonpit Entrance.mp4\"\n    if glob.glob(video_file):\n        vs = cv2.VideoCapture(video_file); #get input from file\n    else:\n        print(\"file does not exist\")\n        return\n    \n    frame_width = int(vs.get(3))\n    frame_height = int(vs.get(4))\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    framerate = 30.0\n    video_path = \"\/kaggle\/working\/\"\n    out = cv2.VideoWriter(video_path+'output.mp4', fourcc, framerate, (frame_width,frame_height))\n    \n    frame_counter = 0\n    unknown_counter = 0\n    known_counter = 0\n    t0 = time.time()\n    while True:        \n        ret,frame = vs.read();\n        if ret:\n            frame_counter+=1\n            if frame_counter%(30\/framerate)==0:\n                min_face_size = 80 #min face size is set to 80x80\n                rects, landmarks = face_detect.detect_face(frame,min_face_size);\n                print(\"number of faces found in frame \" + str(frame_counter) + \":\",len(rects))\n                aligns = []\n                positions = []\n                for (i, rect) in enumerate(rects):\n                    aligned_face, face_pos = aligner.align(160,frame,landmarks[i])\n                    if len(aligned_face) == 160 and len(aligned_face[0]) == 160:\n                        aligns.append(aligned_face)\n                        positions.append(face_pos)\n                    else: \n                        print(\"Align face failed\") #log        \n                if(len(aligns) > 0):\n                    features_arr = extract_feature.get_features(aligns)\n                    recog_data = findPeople(features_arr,positions);              \n                    print(\"recog_data\", str(recog_data))\n                    for (i,rect) in enumerate(rects):\n                        shrtname = short_name(recog_data[i][0])\n                        acc = round(recog_data[i][1],1)\n                        if \"Unknown\" in recog_data[i][0]:\n                            unknown_counter+=1\n                            #draw bounding box for the face\n                            draw_border(frame, (rect[0],rect[1]), (rect[0] + rect[2],rect[1]+rect[3]), (255,255,255), 1, 10, 10)\n                            cv2.putText(frame,shrtname+\"-\"+str(round(recog_data[i][1],1))+\"%\",\n                                        (rect[0]-4,rect[1]-4),cv2.FONT_HERSHEY_SIMPLEX,0.35,\n                                        (255,255,255),1,cv2.LINE_AA)\n                        else:\n                            known_counter+=1\n                            # draw a fancy border around the faces\n                            draw_border(frame, (rect[0],rect[1]), (rect[0] + rect[2],rect[1]+rect[3]), (124,252,0), 1, 10, 10)  \n                            #draw bounding box for the face\n                            cv2.putText(frame,shrtname+\"-\"+str(round(recog_data[i][1],1))+\"%\",\n                                        (rect[0]-4,rect[1]-4),cv2.FONT_HERSHEY_SIMPLEX,0.35,\n                                        (124,252,0),1,cv2.LINE_AA)                        \n\n            out.write(frame)\n            key = cv2.waitKey(1) & 0xFF\n            if key == ord(\"q\"):\n                break\n        else:\n            break\n    \n    elapsed_time = time.time() - t0\n    print(\"[exp msg] elapsed time for going over the video: \" + str(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))\n    vs.release()\n    out.release()\n    cv2.destroyAllWindows()\n    print(\"known_counter:\",known_counter, \"unknown_counter:\",unknown_counter)\n    \n    print()\n    print(\"Done\")","1d34656c":"def findPeople(features_arr, positions, thres = 0.6, percent_thres = 70):\n    '''\n    :param features_arr: a list of 128d Features of all faces on screen\n    :param positions: a list of face position types of all faces on screen\n    :param thres: distance threshold\n    :return: person name and percentage\n    '''\n    f = open('\/kaggle\/working\/facerec_128D.txt','r')\n    data_set = json.loads(f.read());\n    returnRes = [];\n    for (i,features_128D) in enumerate(features_arr):\n        result = \"Unknown\";\n        smallest = sys.maxsize\n        for person in data_set.keys():\n            person_data = data_set[person][positions[i]];\n            for data in person_data:\n                distance = np.sqrt(np.sum(np.square(data-features_128D)))\n                if(distance < smallest):\n                    smallest = distance;\n                    result = person;\n        percentage =  min(100, 100 * thres \/ smallest)\n        if percentage <= percent_thres :\n            result = \"Unknown\"\n        returnRes.append((result,percentage))\n    return returnRes\n\ndef short_name(name):\n    name_split = name.split(\" \")\n    short_name = name_split[0]\n    if len(name_split) > 1:\n        short_name = short_name + \".\" + name_split[1][0]\n    return(short_name)\n","97003817":"model_path = '..\/input\/model-20170512-110547.ckpt-250000' \n\nos.chdir(\"\/kaggle\/input\/\")\n# initalize\nFRGraph = FaceRecGraph();\naligner = AlignCustom();\nextract_feature = FaceFeature(FRGraph,model_path)\nface_detect = MTCNNDetect(FRGraph, scale_factor=2); #scale_factor, rescales image for faster detection","7dc767d9":"import_from_images()","034467e2":"!ls ..\/working\/ -ashl","a09c26aa":"video_file_recog()","7ae5321c":"!ls ..\/working\/ -ashl","19723d36":"## Generate Face DB Functions","14335f1a":"Based and Inspired by:\n- **https:\/\/github.com\/vudung45\/FaceRec\n- Augmentation code: https:\/\/github.com\/vxy10\/ImageAugmentation\n- Fancy borders: https:\/\/www.codemade.io\/fast-and-accurate-face-tracking-in-live-video-with-python\/","324e1675":"## Mini Assignemnt\nChange paramaters of (scaleFactor, minNeighbors, minSize, maxSize) above to find all faces in the GOT image,\nuse information in: https:\/\/docs.opencv.org\/2.4\/modules\/objdetect\/doc\/cascade_classification.html","fcfe464d":"# Generate Face DB","4b101898":"## Generate face database","b9c3acdf":"# RUN Network Based Detection and Recognition","04b9a02c":"# Detect Faces Using Haar Cascades","adcb3d2f":"# Objective\n\nDetect and recognize the faces in the following youtube video:","5d7298ce":"## Mini assignment\nComplete the following find_faces_in_frame_of_video() function so we can do face derection on the video","aaec4366":"# Questions and Instructions\n\n## Haar Cascade\n- Change paramaters of (scaleFactor, minNeighbors, minSize, maxSize) to find all faces in the GOT image, using find_faces_in_image().\n    - gray is the input grayscale image.\n    - scaleFactor is the parameter specifying how much the image size is reduced at each image scale. It is used to create the scale pyramid.\n    - minNeighbors is a parameter specifying how many neighbors each candidate rectangle should have, to retain it. A higher number gives \n      lower false   positives.\n    - minSize is the minimum rectangle size to be considered a face.\n    - More help can be found in: https:\/\/docs.opencv.org\/2.4\/modules\/objdetect\/doc\/cascade_classification.html\n- Which parameters did the best work?\n- complete function find_faces_in_frame_of_video() to run face detection using  video_file_recog_haar() on the GOT video\n-  Change paramaters of (scaleFactor, minNeighbors, minSize, maxSize) to find as many TRUE faces as possible in video using\n    video_file_recog_haar()\n    - To download output video file (output_haar.mp4): 1. commit notebook 2. goto to offline kernel page 3. in Output tab choose Download All\n    - Which parameters did the best work?\n- Check your parameters with framerate of 30 when you think it is good enough\n\n## MTCNN and Face Vector Search\n- RUN Network Based Detection and Recognition code\n- Download movie output.mp4 and check who was recognized and how many times?\n- Add more individulas to the database so you could recgnize more individuals in video (notice you need images with center, right, left angles)\n- Try to augment the images using the augment_image function, does that improves the accuracy?\n   - For help check opencv image manipulaions and https:\/\/github.com\/aleju\/imgaug\n- Try to change min_face_size and see if you can recgnize faces in more frames\n- How would you increase the accuracy of the recgnition?\n- How would you make the entire process run faster?","bd8de8e1":"# Detection and Recgnition","22c00554":"## Recognition in video file","53e1ebad":"# Imports","5a43ade2":"# Face Detection in Video using Haar","2cc1710e":"Description:\n- Images from Video Capture -> detect faces' regions -> crop those faces and align them \n- each cropped face is categorized in 3 types: Center, Left, Right \n- Extract 128D vectors( face features)\n- Search for matching subjects in the dataset based on the types of face positions. \n- The preexisitng face 128D vector with the shortest distance to the 128D vector of the face on screen is most likely a match\n(Distance threshold is 0.6, percentage threshold is 70%)\n    "}}