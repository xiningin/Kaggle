{"cell_type":{"a6c37160":"code","614d2536":"code","a8f7efa2":"code","d98636e9":"code","de246069":"code","ddbb36e4":"code","707d4f09":"code","864adda3":"code","11004715":"code","2bc70a10":"code","11c15300":"code","1515e717":"code","c80389f4":"markdown","799da0f4":"markdown","0b0a442a":"markdown","daf0f26e":"markdown","7d366b2c":"markdown","be4f56b7":"markdown","3023cc31":"markdown","8a50b1e9":"markdown","e2850cbb":"markdown","32bd0467":"markdown"},"source":{"a6c37160":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","614d2536":"# \n# TPU\u306e\u521d\u671f\u5316\n# \ntry:\n#     TPU\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u60c5\u5831\u3092\u7372\u5f97\u3002TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306f\u30a8\u30e9\u30fc\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU\u5229\u7528\u53ef\u80fd\u306e\u78ba\u8a8d\n    print('Running on TPU:', tpu.master())\n# \u4e0a\u8a18\u3067\u30a8\u30e9\u30fc\uff08\u4f8b\u5916\uff09\u304c\u51fa\u305f\u5834\u5408\u306e\u51e6\u7406\nexcept ValueError:\n    tpu = None\n\n# TPU\u304c\u5229\u7528\u3067\u304d\u308b\u5834\u5408\uff08Accelerator TPU\uff09\nif tpu:\n#   \u30ea\u30e2\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3057\u3066TPU\u3092\u521d\u671f\u5316\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   \u30c7\u30fc\u30bf\u306e\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5206\u6563\u3059\u308b\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\uff08Accelerator None\uff09\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# \u4e26\u5217\u51e6\u7406\u306e\u30ec\u30d9\u30eb\u306b\u95a2\u3059\u308b\u6c7a\u5b9a\u3092AUTO\u3067\u884c\u3046\nAUTO = tf.data.experimental.AUTOTUNE\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","a8f7efa2":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\nprint(train.head())\n\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntrain_label = train.loc[:, 'healthy':].values","d98636e9":"class_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\nplt.bar(range(4), class_weight)","de246069":"# 2\u00d72\u3067\u8868\u793a\nfig, ax = plt.subplots(2, 2)\n# \u30b5\u30f3\u30d7\u30eb\u8aad\u307f\u8fbc\u307f\nimg = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nimg1 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_2.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg')\n# \u5834\u6240\u6307\u5b9a\u3057\u305f\u66f8\u304d\u51fa\u3057\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","ddbb36e4":"# \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u306e\u5b9a\u7fa9\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     \u751f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n    bits = tf.io.read_file(filename)\n#     \u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255\u306eRGB\u30920-1\u306b\u5909\u63db\u3059\u308b\uff08normalize\uff09\n    image = tf.cast(image, tf.float32) \/ 255.0\n#     \u753b\u50cf\u30b5\u30a4\u30ba\u30921365\u00d72048\u304b\u3089768\u00d7768\u306b\u3059\u308b\n    image = tf.image.resize(image, image_size)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u306e\u5b9a\u7fa9\ndef data_augment(image, label=None):\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_left_right(image)\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_up_down(image)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label","707d4f09":"# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u30c7\u30b3\u30fc\u30c9\ntrain_dataset = (\n#     TFR\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u66f8\u304d\u3059\u308b\n    tf.data.TFRecordDataset\n#     \u914d\u5217\u3092\u30b9\u30e9\u30a4\u30b9\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\n    .from_tensor_slices((train_path, train_label))\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(decode_image, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(data_augment, num_parallel_calls=AUTO)\n    .cache()\n    .repeat()\n    .shuffle(1024) #\u30e9\u30f3\u30c0\u30e0\u8981\u7d20\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u30c7\u30b3\u30fc\u30c9\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","864adda3":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","11004715":"# ResNet50,DenseNet101,DenseNet152\u304c\u4f7f\u7528\u53ef\u80fd\nfrom tensorflow.keras.applications import ResNet152\n\nwith strategy.scope():\n    rsn152 = ResNet152(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_rsn152 = Sequential()\n    model_rsn152.add(rsn152)\n    model_rsn152.add(L.GlobalAveragePooling2D())\n    model_rsn152.add(L.Dense(4, activation='softmax'))\n    model_rsn152.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_rsn152.summary())","2bc70a10":"mc_rsn152 = tf.keras.callbacks.ModelCheckpoint('weights_rsn152.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_rsn152.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn152], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","11c15300":"with strategy.scope():\n    model_rsn152.load_weights('weights_rsn152.h5')","1515e717":"probs_rsn152 = model_rsn152.predict(test_dataset, verbose=1)\nsub_rsn152 = sub\nsub_rsn152.loc[:, 'healthy':] = probs_rsn152\nsub_rsn152.to_csv('submission_rsn152.csv', index=False)\nsub_rsn152.head()","c80389f4":"# Predict","799da0f4":"# Define the parameters","0b0a442a":"# Decode images","daf0f26e":"# ResNet","7d366b2c":"# TPU setup","be4f56b7":"# Lets see some images","3023cc31":"# Model","8a50b1e9":"# Import Libraries","e2850cbb":"# Get train and test data","32bd0467":"# Get class weights"}}