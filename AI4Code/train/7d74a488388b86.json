{"cell_type":{"823a0bf3":"code","02787de9":"code","47414ce1":"code","049bdfc3":"code","569ade7d":"code","21a8da1c":"code","7c972793":"code","df1c41f2":"code","d579e5f2":"code","fc0d4638":"code","636c330f":"code","22c93219":"code","c0c0917c":"code","cb350e8e":"code","101e5268":"code","ae7a9247":"code","33ad21ac":"code","911ee6d1":"code","22b6c648":"code","34c8c286":"code","3130e25b":"code","a33e7716":"code","083b7d80":"code","ed34706f":"markdown","f24f39df":"markdown","b4983a11":"markdown"},"source":{"823a0bf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nsns.set_style(style=\"whitegrid\")\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","02787de9":"train = pd.read_csv('..\/input\/creditcard.csv')","47414ce1":"train.head()","049bdfc3":"# NO null value\ntrain.isnull().any().sum()","569ade7d":"train[['Time','Amount','Class']].describe()","21a8da1c":"train.columns","7c972793":"#unbalance class\n\nsns.countplot(x='Class',data=train)\n# to show only comaparision \nplt.yscale('log')","df1c41f2":"# fraud and normal class \nfrauds_t=train[train['Class']==1]\n\nnormal_t=train[train['Class']==0]","d579e5f2":"# Class total input \/\/ unbalance  distribution \ntotal_transaction= len(train)\n\ntotal_fraud =train['Class'].sum();\ntotal_normal=total_transaction-total_fraud\nprint('Total Transaction ={}'.format(total_transaction))\nprint('fraud Data ={}, percentage ={}' .format(total_fraud,(total_fraud\/total_transaction)*100) )\nprint('Normal Data ={} , percentage= {}'.format(total_normal,(total_normal\/total_transaction)*100))\nprint('Fraud data Shape= {}'.format(frauds_t.shape))\nprint('Normal data Shape= {}'.format(normal_t.shape))\n","fc0d4638":"fig ,ax1 =  plt.subplots(nrows=2,ncols=1,figsize=(22,12),sharex=True)\n\nsns.distplot(frauds_t['Amount'],ax=ax1[0],rug=True,bins=70)\nsns.distplot(normal_t['Amount'],ax=ax1[1],rug=True,bins=70)\n\n\nax1[0].set_title('Fraud')\n\nax1[1].set_title('normal')\n\nplt.xlim(0,2000)","636c330f":"fig ,ax= plt.subplots(2,1,figsize=(20,8),sharex=True)\nax[0].hist(frauds_t['Amount'],bins=30)\nax[0].set_title('Frauds')\nax[1].hist(normal_t['Amount'],bins=30)\nax[1].set_title('normal')\nplt.xlabel('Amounts($)')\nplt.yscale('log')\nplt.tight_layout()","22c93219":"#check if any  fraud is abnormal for diff time (48 hour interval (day,night ,morning .. anything))\n# fraud seems to normal  distribution our time  as normal transaction \nfig ,ax1 =  plt.subplots(nrows=2,ncols=1,figsize=(20,8))\n\nax1[0].set_title('Normal Transaction') \nax1[1].set_title('fraud Transaction') \n\nsns.scatterplot(normal_t['Time'],normal_t['Amount'],ax=ax1[0])\n\nsns.scatterplot(frauds_t['Time'],frauds_t['Amount'],ax=ax1[1])\nfig.tight_layout()\n#sns.jointplot(x=\"Amount\", y=\"Time\", data=frauds_t);","c0c0917c":"# approx similar in both \nfig ,ax1 =  plt.subplots(nrows=2,ncols=1,figsize=(22,8),sharex=True)\nax1[0].set_title('Normal Transaction') \nax1[1].set_title('fraud Transaction') \nsns.distplot(normal_t['Time'],ax=ax1[0],)\nsns.distplot(frauds_t['Time'],ax=ax1[1])\nfig.tight_layout()","cb350e8e":"from sklearn.preprocessing import  StandardScaler ","101e5268":"train['Amount'] = StandardScaler().fit_transform(train['Amount'].values.reshape(-1, 1))\nfrauds_t =train[train['Class']==1]\nnormal_t =train[train['Class']==0]\n","ae7a9247":"from sklearn.model_selection import train_test_split","33ad21ac":"#counting  by class \nclass_0_count,class_1_count=train.Class.value_counts()\n# randomly return sample size class_1_count(Fraud)\nclass_0_under = normal_t.sample(class_1_count)\n# make new dataframe (50\/50)\ndf_test =pd.concat([class_0_under,frauds_t])\nprint(df_test.Class.value_counts())\nsns.countplot(df_test['Class'])","911ee6d1":"plt.figure(figsize=(25,12))\n\nsns.heatmap(df_test.corr(),annot=True)","22b6c648":"X_train, X_test, y_train, y_test = train_test_split(df_test.drop(labels=['Time','Class'],axis=1), df_test['Class'], test_size=0.2)","34c8c286":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import  confusion_matrix ,classification_report,roc_auc_score\n#Empirical good default values are max_features=n_features for regression problems, and max_features=sqrt(n_features) for classification tasks\nclf= RandomForestClassifier(verbose=2,n_estimators=300)\n\nclf.fit(X_train,y_train)\n","3130e25b":"def model_representation(y_true,y_predicted):\n    matrix=confusion_matrix(y_true, y_predicted)\n    print(matrix)\n    print(roc_auc_score(y_true,y_predicted))\n    print(classification_report(y_true,y_predicted))\n    TP=matrix[0,0]\n    FP= matrix[0,1]\n    FN =matrix[1,0]\n    TN=matrix[1,1]\n    print('TP={}\\n FP={}\\n FN={}\\n TN={}\\n '.format(TP,FP,FN,TN))\n    sns.heatmap(matrix,annot=True)\n    plt.xlabel('predicted value')\n    plt.ylabel('actual value')\n    plt.title('Confusion Matrix')","a33e7716":"y_pre=clf.predict(X_test)\n\nmodel_representation(y_test,y_pre)","083b7d80":"\nX = train.drop(labels=['Time','Class'],axis=1)\ny= train['Class']\n\ny_pre=clf.predict(X)\n\nmodel_representation(y,y_pre)\n","ed34706f":"**SAMPLING DATA **\n\n WE HAVE UNBALACE CLASS \n* > (fraud Data =492, **percentage** =0.1727485630620034\n* > Normal Data =284315 , **percentage**= 99.82725143693798\n* > Fraud data Shape= (492, 31)\n* > Normal data Shape= (284315, 31))\n\nBalance Class\n* Make 50\/50 (NORMAL AN FRAUD CLASS)\n* Randomly pick  Normal data (492) from 284315\n\n\nShuffle data \n* randomly shuffle (984) data\n","f24f39df":"study **correlation** between data ","b4983a11":"*** Preprocessing**\n* SCALING AMOUNT DATA TO BALANCE MAGNITUDE(**ZERO MEAN AND UNIT VARIANCE**)"}}