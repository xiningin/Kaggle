{"cell_type":{"0181df46":"code","9207e687":"code","baaa96e4":"code","35336022":"code","5f3bd269":"code","d445f39c":"code","50449746":"code","086749c6":"code","1f9be5f6":"code","ce69c229":"code","10692f4f":"code","b17410e4":"code","6fa96b95":"code","9a703e27":"code","2f23135e":"code","d2c766d2":"code","023be801":"code","5319c205":"code","d050a657":"code","2f51dd75":"code","6cf48063":"code","d3f2deb2":"code","9f3fedae":"code","1551d59f":"code","4a0230aa":"code","9aacc927":"code","5a62bf6f":"code","08f1f15f":"code","54a59c9d":"code","25c52e1a":"markdown","4f7f0620":"markdown","f487472d":"markdown","29f1dde0":"markdown","fe29e717":"markdown","bd3a82b2":"markdown","607c2dce":"markdown","2c6e5933":"markdown","f8dc0bf9":"markdown","2fc55217":"markdown","1fa5c8a5":"markdown","300e9d9c":"markdown","c94da253":"markdown"},"source":{"0181df46":"!pip install pandas-datareader   ","9207e687":"import math\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas_datareader as data_reader\nfrom pandas.util.testing import assert_frame_equal #import alterado\n\nfrom tqdm import tqdm_notebook, tqdm\nfrom collections import deque","baaa96e4":"tf.__version__","35336022":"class AI_Trader():\n  \n  def __init__(self, state_size, action_space = 3, model_name = \"AITrader\"):  # state_size podemos tomar tr\u00eas a\u00e7\u00f5es;\n    self.state_size = state_size  # \u00e9 a entrada da rede neural o que est\u00b4vindo do ambiente;\n    self.action_space = action_space\n    self.memory = deque(maxlen = 2000)  # treinamento com a memoriza\u00e7\u00e3o de 2000 a\u00e7\u00f5es;\n    self.model_name = model_name\n    \n    self.gamma = 0.95\n    self.epsilon = 1.0  # aqui se utiliza a\u00e7\u00f5es randomicas ou rede neural, 1.0, quer dizer 100% randomicas sem utilizar rede neural;\n    self.epsilon_final = 0.01\n    self.epsilon_decay = 0.995\n    self.model = self.model_builder()\n    \n  def model_builder(self):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.Input(shape=(self.state_size,)))\n    model.add(tf.keras.layers.Dense(units = 32, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(units = 64, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(units = 128, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(units = self.action_space, activation = \"linear\"))  # problema de regress\u00e3o; retorna o valor das a\u00e7\u00f5es;\n    model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(lr = 0.001))\n    return model   # loss mean squear error;\n\n  \n  def trade(self, state):\n    if random.random() <= self.epsilon:\n      return random.randrange(self.action_space)\n    \n    actions = self.model.predict(state)\n    return np.argmax(actions[0])\n  \n  def batch_train(self, batch_size):\n    batch = []\n    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n      batch.append(self.memory[i])\n      \n    for state, action, reward, next_state, done in batch:\n      if not done:\n        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n        \n      target = self.model.predict(state)\n      target[0][action] = reward\n      \n      self.model.fit(state, target, epochs=1, verbose=0)\n      \n    if self.epsilon > self.epsilon_final:\n      self.epsilon *= self.epsilon_decay\n      ","5f3bd269":"def sigmoid(x):\n  return 1 \/ (1 + math.exp(-x))","d445f39c":"sigmoid(0.5)","50449746":"def stocks_price_format(n):\n  if n < 0:\n    return \"- $ {0:2f}\".format(abs(n))\n  else:\n    return \"$ {0:2f}\".format(abs(n))","086749c6":"stocks_price_format(100)","1f9be5f6":"!pip install -q yfinance","ce69c229":"import yfinance as yf","10692f4f":"#dataset = data_reader.DataReader(\"AAPL\", data_source = \"yahoo\")\ndataset = yf.download(\"AAPL\", start='2019-06-02')","b17410e4":"dataset.head()","6fa96b95":"str(dataset.index[0]).split()[0]","9a703e27":"dataset.index[-1]","2f23135e":"dataset['Close']","d2c766d2":"def dataset_loader(stock_name):  \n  dataset = yf.download(stock_name, start='2019-06-02')\n  start_date = str(dataset.index[0]).split()[0]\n  end_date = str(dataset.index[-1]).split()[0]\n  close = dataset['Close']\n  return close","023be801":"0 - 5 + 1","5319c205":"20 - 5 + 1","d050a657":"dataset[16:21]","2f51dd75":"def state_creator(data, timestep, window_size):\n  starting_id = timestep - window_size + 1\n  \n  if starting_id >= 0:\n    windowed_data = data[starting_id:timestep + 1]\n  else:\n    windowed_data = - starting_id * [data[0]] + list(data[0:timestep + 1])\n    \n  state = []\n  for i in range(window_size - 1):\n    state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\n    \n  return np.array([state]), windowed_data","6cf48063":"stock_name = \"AAPL\"\ndata = dataset_loader(stock_name)","d3f2deb2":"s, w = state_creator(data, 0, 5)","9f3fedae":"s","1551d59f":"w","4a0230aa":"window_size = 10\nepisodes = 1000\nbatch_size = 32\ndata_samples = len(data) - 1","9aacc927":"data_samples","5a62bf6f":"trader = AI_Trader(window_size)","08f1f15f":"trader.model.summary()","54a59c9d":"for episode in range(1, episodes + 1):\n  print(\"Episode: {}\/{}\".format(episode, episodes))\n  state = state_creator(data, 0, window_size + 1)\n  total_profit = 0\n  trader.inventory = []\n  for t in tqdm(range(data_samples)):\n    action = trader.trade(state)\n    next_state = state_creator(data, t + 1, window_size + 1)\n    reward = 0\n    \n    if action == 1: # Comprando uma a\u00e7\u00e3o\n      trader.inventory.append(data[t])\n      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n    elif action == 2 and len(trader.inventory) > 0: # Vendendo uma a\u00e7\u00e3o  \n      buy_price = trader.inventory.pop(0)\n      \n      reward = max(data[t] - buy_price, 0)\n      total_profit += data[t] - buy_price\n      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price))\n      \n    if t == data_samples - 1:\n      done = True\n    else:\n      done = False\n      \n    trader.memory.append((state, action, reward, next_state, done))\n    \n    state = next_state\n    \n    if done:\n      print(\"########################\")\n      print(\"Total profit: {}\".format(total_profit))\n      print(\"########################\")\n      \n   # if len(trader.memory) > batch_size:\n      #trader.batch_train(batch_size)\n     \n  if episode % 10 == 0:\n    trader.model.save(\"ai_trader_{}.h5\".format(episode))\n    ","25c52e1a":"### Model definition","4f7f0620":"## Loading database","f487472d":"### Training loop","29f1dde0":"### Hyper Parameters Configuration","fe29e717":"#### Price Formatting","bd3a82b2":"## If you find this notebook useful, support with an upvote \ud83d\udc4d","607c2dce":"## Maker of states","2c6e5933":"#### Sigmoid","f8dc0bf9":"## Database Processing","2fc55217":"### Definition of auxiliary functions","1fa5c8a5":"## Database Loader","300e9d9c":"## Database Processing","c94da253":"## Training the AI"}}