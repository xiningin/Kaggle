{"cell_type":{"783f2fd1":"code","39021844":"code","3995089d":"code","edfb07eb":"code","c2368ff3":"code","4a1fd072":"code","d1b8b305":"code","03492834":"code","b5c3c84e":"code","c449085d":"code","1a0ac431":"code","01086331":"code","a473d6c2":"code","b052e025":"code","99c3a7cb":"code","a55bc04c":"markdown","7d03c67a":"markdown","a1183f5a":"markdown","2c7bec41":"markdown","6ae7c191":"markdown","4aa178fb":"markdown"},"source":{"783f2fd1":"import numpy as np\nimport pandas as pd","39021844":"df1 = pd.read_csv(\"\/kaggle\/input\/financial-news-headlines\/cnbc_headlines.csv\")\ndf1 = df1.dropna()\ndf1 = df1.drop_duplicates(subset=['Headlines', 'Description'], keep='first')\ndf1.reset_index(drop=True, inplace=True)\ndf1","3995089d":"df1.info()","edfb07eb":"def replace_dt(s):\n    s = s.replace(\"Sept\", \"Sep\").replace(\"March\", \"Mar\").replace(\"April\", \"Apr\").replace(\"June\", \"Jun\").replace(\"July\", \"Jul\")\n    if s[0].isspace():\n        s = s.replace(\" \", \"0\", 1)\n    s = s.replace(\",  \", \", 0\", 1)\n    return s","c2368ff3":"from datetime import datetime\nf = '%I:%M  %p ET %a, %d %b %Y'\ndates = []\ntimes = []\nfor item in df1.iloc[:, 1].values:\n    item = replace_dt(item)\n    dates.append(datetime.strptime(item, f).strftime(\"%m-%d-%Y\"))\n    times.append(datetime.strptime(item, f).strftime(\"%H:%M:%S\"))","4a1fd072":"df1['Date'] = dates\ndf1[\"Date\"] = df1[\"Date\"].astype(\"datetime64\")\ndf1['Time'] = times\ndf1 = df1[[\"Date\", \"Time\", \"Headlines\", \"Description\"]]\ndf1","d1b8b305":"# Storing data for later use (EDA, NLP, ANN and RNN)\n%store df1","03492834":"df2 = pd.read_csv(\"\/kaggle\/input\/financial-news-headlines\/reuters_headlines.csv\")\ndf2 = df2.dropna()\ndf2 = df2.drop_duplicates(subset=['Headlines', 'Description'], keep='first')\ndf2.reset_index(drop=True, inplace=True)\ndf2","b5c3c84e":"df2[\"Time\"] = df2[\"Time\"].astype(\"datetime64\")\ndf2 = df2[[\"Time\", \"Headlines\", \"Description\"]]\ndf2.rename(columns={\"Time\":\"Date\"}, inplace = True)\ndf2","c449085d":"df2.info()","1a0ac431":"# Storing data\n%store df2","01086331":"df3 = pd.read_csv(\"\/kaggle\/input\/financial-news-headlines\/guardian_headlines.csv\")\ndf3 = df3.dropna()\ndf3 = df3.drop_duplicates(subset=['Headlines'], keep='first')\ndf3.reset_index(drop=True, inplace=True)\ndf3","a473d6c2":"df3[\"Time\"] = pd.to_datetime(df3[\"Time\"], errors = 'coerce')\ndf3.rename(columns={\"Time\":\"Date\"}, inplace = True)\ndf3","b052e025":"df3.info()","99c3a7cb":"# Storing data\n%store df3","a55bc04c":"# Data Cleaning (Reuters)","7d03c67a":"## Unusual datetime naming convention","a1183f5a":"Data Cleaning process","2c7bec41":"The abbreviation for September is Sep, not Sept as listed in this data set. At the same time, while many rows use the standard abbreviation form of the month (Sept), others use a different abbreviation, sometimes even the full name of the month (March, April, June, July). Therefore, the function below aims to replace all unusual abbreviations from the datetime. This function also aim to replace leading space \" \" with a \"0\" (padding a character \"0\") before any representation of posted hour (and posted date) that is smaller than 10 (0, 1, ..., 9).","6ae7c191":"# Data Cleaning (the Guardian)","4aa178fb":"# Data Cleaning (CNBC)"}}