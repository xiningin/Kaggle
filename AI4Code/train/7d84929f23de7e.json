{"cell_type":{"3bece12e":"code","1f8780bb":"code","1b7a1e2d":"code","3eff5149":"code","997a8633":"code","454a4b28":"code","86c8c4c4":"code","079d27e4":"code","dcdbe09f":"code","2fc0cb60":"code","cd96f750":"code","72a82cc5":"code","156eea9b":"code","f8c18a35":"code","cdce3bef":"code","d1c5a878":"code","cba3c470":"code","88f8cf4c":"code","7dcb2d4c":"code","06fe3ed8":"code","b7877227":"code","c65ad853":"code","5dd27cc9":"code","d4955f21":"code","45bd1544":"code","04026320":"code","2ae7288a":"markdown","8ada7d4f":"markdown","1f824753":"markdown","03eed0b9":"markdown","481e90dd":"markdown","72362619":"markdown","ba90a77f":"markdown","bd699a80":"markdown","f2a5c0b8":"markdown","019be150":"markdown","5bf6c7eb":"markdown","7cb1f04f":"markdown","120a9d69":"markdown","f7439a5e":"markdown","f05c8e1c":"markdown","caae1b2c":"markdown","8e66cfbf":"markdown"},"source":{"3bece12e":"# Arquivo de dados\nimport os\nprint(os.listdir(\"..\/input\"))","1f8780bb":"import pandas as pd \ndf = pd.read_csv('\/kaggle\/input\/hmeq-data\/hmeq.csv') # arquivo deve estar entre aspas\ndf.head()","1b7a1e2d":"df.info()","3eff5149":"# Quantos valores nulos temos no total\nprint('Soma total dos valores nulos:', df.isnull().sum().values.sum())","997a8633":"# Valores nulos em cada coluna\ndf.isnull().sum()","454a4b28":"# contagem de valores na coluna REASON\ndf['REASON'].value_counts()","86c8c4c4":"df.REASON.fillna('DebtCon', inplace=True)","079d27e4":"# contagem de valores na coluna JOB\ndf['JOB'].value_counts()","dcdbe09f":"df.JOB.fillna('Other', inplace=True)","2fc0cb60":"# Substituindo os valores faltantes das colunas num\u00e9ricas\ndf.fillna(0,inplace=True)","cd96f750":"# Depois das transforma\u00e7\u00f5es\ndf.head()","72a82cc5":"# Vamos converter todas as variaveis categ\u00f3ricas para vari\u00e1veis dummy\ndf = pd.get_dummies(df, columns=['REASON', 'JOB'])","156eea9b":"df.head()","f8c18a35":"# Separando os dados\n# Precisamos de 3 conjuntos de dados: treino, valida\u00e7\u00e3o e teste\n\n# Importando o train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Dividindo em treino e teste a partir dos dados do dataframe\ntrain, test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Dividindo em treino e valida\u00e7\u00e3o a partir dos dados de treino\ntrain, valid = train_test_split(train, test_size=0.2, random_state=42)\n\ntrain.shape, valid.shape, test.shape","cdce3bef":"# Criar a lista de colunas para treino, as chamadas feats\nfeats = [c for c in df.columns if c not in ['BAD']]","d1c5a878":"# Instanciar o modelo Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(random_state=42, n_estimators = 150, min_samples_split = 4, min_samples_leaf = 4)","cba3c470":"# Treinar o modelo\nrf.fit(train[feats], train['BAD'])","88f8cf4c":"# Previs\u00f5es na base de valida\u00e7\u00e3o\npreds_val = rf.predict(valid[feats])\npreds_val","7dcb2d4c":"# Escolher a m\u00e9trica para verificar o desempenho do modelo\n# O exerc\u00edcio pede para usar a acur\u00e1cia\nfrom sklearn.metrics import accuracy_score","06fe3ed8":"# Medir o desempenho na base de valida\u00e7\u00e3o com acur\u00e1cia\naccuracy_score(valid['BAD'], preds_val)","b7877227":"# Previs\u00f5es na base de teste\npreds_teste = rf.predict(test[feats])\npreds_teste","c65ad853":"# Medir o desempenho na base de teste com acur\u00e1cia\naccuracy_score(test['BAD'], preds_teste)","5dd27cc9":"# A biblioteca scikitplot \u00e9 bastante funcinal para plotarmos dados gerados por fun\u00e7oes do scikitlearn\nimport scikitplot as skplt","d4955f21":"# Plotando matriz de confu\u00e7\u00e3o das variaveis preditas nos dados de valida\u00e7\u00e3o\nskplt.metrics.plot_confusion_matrix(valid['BAD'], preds_val)","45bd1544":"# Plotando matriz de confu\u00e7\u00e3o das variaveis preditas nos dados de teste\nskplt.metrics.plot_confusion_matrix(test['BAD'], preds_teste)","04026320":"# Para finalizar ser\u00e1 avaliado a importancia de cada coluna em nosso modelo\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","2ae7288a":"# Pr\u00e9-processamento dos dados\nComo podemos observar nas informa\u00e7\u00f5es sobre o dataframe, a maioria dos itens das colunas s\u00e3o representados por n\u00fameros, mas as colunas REASON e JOB s\u00e3o do tipo objeto, sendo representadas por texto. No dataframe existem tamb\u00e9m alguns valores nulos e ser\u00e3o utilizadas algumas tecnicas para preenche-los. As tecnicas utilizadas em objetos se diferenciam das que usaremos para os n\u00fameros, pois com n\u00fameros apenas substituiremos por 0 os valores faltantes, mas com as objeto substituiremos pelos valores mais frequentes de cada coluna.","8ada7d4f":"# IESB\n# Gradua\u00e7\u00e3o em Ci\u00eancia de Dados\n## Disciplina - Minera\u00e7\u00e3o de Dados e Intelig\u00eancia Computacional\n## Avalia\u00e7\u00e3o - 04\/05\/2020\n## Aluno: Carlos Henrique Carneiro Costa\n## Matricula: 1812120020\n\n### Descri\u00e7\u00e3o\nA base de dados \"Home Equity\" possui dados pessoas e informa\u00e7\u00f5es de empr\u00e9stimo de 5.960 empr\u00e9stimos recentes. Para cada empr\u00e9stimo existem 12 vari\u00e1veis registradas.\nA vari\u00e1vel alvo (`BAD`) indica quando o cliente n\u00e3o pagou o empr\u00e9stimo (valor 1), e quando ele honrou o compromisso (valor 0).\n\n### Objetivo\nCriar um modelo de ML usando RandomForest para prever se determinado cliente ir\u00e1 ou n\u00e3o honrar o empr\u00e9stimo contra\u00eddo.\n\nO desempenho do modelo deve ser medido pela m\u00e9trica de acur\u00e1cia (`accuracy_score`).","1f824753":"> Os Bonus ser\u00e3o apresentados no final do Notebook","03eed0b9":"**Itens avaliados:**\n\n1. Carregamento dos dados\n2. Verifica\u00e7\u00e3o para saber se os dados foram importados corretamente\n3. Pr\u00e9-processamento dos dados (preenchimento de valores em branco, transforma\u00e7\u00e3o de texto em n\u00famero)\n4. Separar dados em treino e valida\u00e7\u00e3o\n5. Instanciar e treinar uma `RandomForest`\n6. Avalia\u00e7\u00e3o da performance do modelo pela m\u00e9trica de acur\u00e1cia (`accuracy_score`).\n7. Buscar a melhoria da acur\u00e1cia mudando os par\u00e2metros do modelo RandomForest.","481e90dd":"A coluna JOB tem seis classifica\u00e7\u00f5es diferentes. A que mais apareceu foi Other e vamos preenches os valores nulos da coluna JOB com Other, que foi a mais frequente.","72362619":"# Precision","ba90a77f":"Como podemos observar a coluna DEBTINC foi a coluna que o modelo considerou mais importante para decidir qual valor retornaria como resultado. JOB e REASON, duas colunas que fizemos mais altera\u00e7\u00f5es, acabaram tendo uma import\u00e2ncia m\u00ednima.","bd699a80":"Veremos a diferen\u00e7a entre antes das tranforma\u00e7\u00f5es e depois delas","f2a5c0b8":"# Separando dados em treino e valida\u00e7\u00e3o (e teste)","019be150":"**B\u00f4nus 3:**\n    \nExplique o que \u00e9 `recall` na matriz de confus\u00e3o acima e d\u00ea 1 exemplo onde isso pode ser \u00fatil.","5bf6c7eb":"# B\u00f4nus\n\nAp\u00f3s terminar o exerc\u00edcio e verificar que est\u00e1 cumprindo todos os itens a serem avaliados, voc\u00ea pode fazer os itens a seguir para ganhar pontos extra na prova:","7cb1f04f":"# Recall","120a9d69":"O modelo acabou desempenhando melhor nos dados de teste do que no de valida\u00e7\u00e3o.","f7439a5e":"**B\u00f4nus 2:**\n    \nExplique o que \u00e9 `precis\u00e3o` na matriz de confus\u00e3o acima e d\u00ea 1 exemplo onde isso pode ser \u00fatil.","f05c8e1c":"**B\u00f4nus 1:**\n    \nPlote uma matriz de confus\u00e3o nas previs\u00f5es dos dados de valida\u00e7\u00e3o.","caae1b2c":"A coluna REASON tem apenas duas classifica\u00e7\u00f5es diferentes: DebtCon e HomeImp. A que mais apareceu foi a DebtCon e vamos preenches os valores nulos da coluna REASON com DebtCon, que foi a mais frequente.","8e66cfbf":"# Carregamento dos dados\nPara carregar os dados corretamente devemos importar a bibiloteca pandas e saber exatemente o endere\u00e7o em que se encontra o arquivo."}}