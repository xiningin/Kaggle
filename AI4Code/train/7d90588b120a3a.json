{"cell_type":{"5e2ce5b5":"code","08de83f6":"code","232ee3ca":"code","ad64342b":"code","78512287":"code","ba9e6a91":"code","d6955219":"code","ceccb45f":"code","c4a01cc3":"code","fb79ab16":"code","fb3384d8":"code","064ebf2f":"code","bcfdbf5a":"code","d8d87562":"code","114977db":"code","2ace51f2":"code","a8bb7dc6":"code","7756daf3":"code","900da3e4":"code","70e8ef84":"code","7b68d594":"code","98fab192":"code","df7f5824":"code","1d29d4fb":"code","abe1295e":"code","ad960e12":"code","c7a52e23":"code","bcd94ab4":"code","0a24454e":"code","6d6093d6":"code","4699bfae":"code","70ca8f84":"code","cd91edd6":"code","367f9522":"code","a88dc1a9":"code","2ec1a47d":"code","4427c31c":"code","2a03192a":"markdown","aeeea58d":"markdown"},"source":{"5e2ce5b5":"# Importing Required Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv1D\nimport wfdb                            # Package for loading the ecg and annotation\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport random\nfrom keras.layers import Bidirectional, LSTM\n# Random Initialization\nrandom.seed(42)","08de83f6":"# Importing Data\ndata = '..\/input\/mit-bih-arrhythmia-database\/'","232ee3ca":"# List of Patients\npatients = ['100','101','102','103','104','105','106','107',\n           '108','109','111','112','113','114','115','116',\n           '117','118','119','121','122','123','124','200',\n           '201','202','203','205','207','208','209','210',\n           '212','213','214','215','217','219','220','221',\n           '222','223','228','230','231','232','233','234']","ad64342b":"# Creating a Empty Dataframe\nsymbols_df = pd.DataFrame()\n\n# Reading all .atr files \nfor pts in patients:\n    # Generating filepath for all .atr file names\n    file = data + pts\n    # Saving annotation object\n    annotation = wfdb.rdann(file, 'atr')\n    # Extracting symbols from the object\n    sym = annotation.symbol\n    # Saving value counts\n    values, counts = np.unique(sym, return_counts=True)\n    # Writing data points into dataframe\n    df_sub = pd.DataFrame({'symbol':values, 'Counts':counts, 'Patient Number':[pts]*len(counts)})\n    # Concatenating all data points  \n    symbols_df = pd.concat([symbols_df, df_sub],axis = 0)","78512287":"# Symbols Dataframe\nsymbols_df","ba9e6a91":"# Value Counts of Different symbols in data\nsymbols_df.groupby('symbol').Counts.sum().sort_values(ascending = False)","d6955219":"# Non Beat Symbols\nnonbeat = ['[','!',']','x','(',')','p','t','u','`',\n           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n\n# Abnormal Beat Symbols\nabnormal = ['L','R','V','\/','A','f','F','j','a','E','J','e','S']\n\n# Normal Beat Symbols\nnormal = ['N']","ceccb45f":"# Classifying normal, abnormal or nonbeat\nsymbols_df['category'] = -1\nsymbols_df.loc[symbols_df.symbol == 'N','category'] = 0\nsymbols_df.loc[symbols_df.symbol.isin(abnormal), 'category'] = 1","c4a01cc3":"# Value counts of different categories\nsymbols_df.groupby('category').Counts.sum()","fb79ab16":"def load_ecg(file):    \n    # load the ecg\n    record = wfdb.rdrecord(file)\n    # load the annotation\n    annotation = wfdb.rdann(file, 'atr')\n    \n    # extracting the signal\n    p_signal = record.p_signal\n\n    # extracting symbols and annotation index\n    atr_sym = annotation.symbol\n    atr_sample = annotation.sample\n    \n    return p_signal, atr_sym, atr_sample","fb3384d8":"# Accessing the ecg points for \nfile = data + patients[8]","064ebf2f":"# Accessing the load ECG function and getting annotation.symbol, annotation.sample, signals\np_signal, atr_sym, atr_sample = load_ecg(file)","bcfdbf5a":"# Analysing annotations value counts for a single record\nvalues, counts = np.unique(sym, return_counts=True)\nfor v,c in zip(values, counts):\n    print(v,c)","d8d87562":"# get abnormal beat index\nab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\nab_index","114977db":"# Generating evenly spaced values\nx = np.arange(len(p_signal))\n\nleft = ab_index[5]-20000\nright = ab_index[5]+20000\n\nplt.figure(figsize=(20,8))\nplt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg',)\nplt.plot(x[atr_sample],p_signal[atr_sample,0],'go',label ='normal')\nplt.plot(x[ab_index],p_signal[ab_index,0],'ro',label='abnormal')\n\nplt.xlim(left,right)\nplt.ylim(p_signal[left:right].min()-0.05,p_signal[left:right,0].max()+0.05)\nplt.xlabel('time index')\nplt.ylabel('ECG signal')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.show()","2ace51f2":"def make_dataset(pts, num_sec, fs, abnormal):\n    # function for making dataset ignoring non-beats\n    # input:\n    #   pts - list of patients\n    #   num_sec = number of seconds to include before and after the beat\n    #   fs = frequency\n    # output: \n    #   X_all = signal (nbeats , num_sec * fs columns)\n    #   Y_all = binary is abnormal (nbeats, 1)\n    #   sym_all = beat annotation symbol (nbeats,1)\n    \n    # initialize numpy arrays\n    num_cols = 2*num_sec * fs\n    X_all = np.zeros((1,num_cols))\n    Y_all = np.zeros((1,1))\n    sym_all = []\n    \n    # list to keep track of number of beats across patients\n    max_rows = []\n    \n    for pt in pts:\n        file = data + pt\n        \n        p_signal, atr_sym, atr_sample = load_ecg(file)\n        \n        # grab the first signal\n        p_signal = p_signal[:,0]\n        \n        # make df to exclude the nonbeats\n        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n                              'atr_sample':atr_sample})\n        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n        \n        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n        sym_all = sym_all+sym\n        max_rows.append(X.shape[0])\n        X_all = np.append(X_all,X,axis = 0)\n        Y_all = np.append(Y_all,Y,axis = 0)\n        \n    # drop the first zero row\n    X_all = X_all[1:,:]\n    Y_all = Y_all[1:,:]\n\n    return X_all, Y_all, sym_all\n","a8bb7dc6":"def build_XY(p_signal, df_ann, num_cols, abnormal):\n    # this function builds the X,Y matrices for each beat\n    # it also returns the original symbols for Y\n    \n    num_rows = len(df_ann)\n\n    X = np.zeros((num_rows, num_cols))\n    Y = np.zeros((num_rows,1))\n    sym = []\n    \n    # keep track of rows\n    max_row = 0\n\n    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n        left = max([0,(atr_sample - num_sec*fs) ])\n        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n        x = p_signal[left: right]\n        if len(x) == num_cols:\n            X[max_row,:] = x\n            Y[max_row,:] = int(atr_sym in abnormal)\n            sym.append(atr_sym)\n            max_row += 1\n    X = X[:max_row,:]\n    Y = Y[:max_row,:]\n    return X,Y,sym","7756daf3":"# Parameter Values\nnum_sec = 3\nfs = 360","900da3e4":"# Accessing the fuction and creating a dataset with ECG digital Points\nX_all, Y_all, sym_all = make_dataset(patients, num_sec, fs, abnormal)","70e8ef84":"# Train Test Split\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.33, random_state=42)","7b68d594":"# Relu for activation function and drop out for regularization\nmodel = Sequential()\nmodel.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Dense(1, activation = 'sigmoid'))","98fab192":"# Compiling model with  binary crossentropy and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])","df7f5824":"# Fitting the model\nmodel.fit(X_train, y_train, batch_size = 32, epochs= 10, verbose = 1)","1d29d4fb":"# Evaluation Metrics\ndef print_report(y_actual, y_pred, thresh):\n    # Function to print evaluation metrics\n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    specificity = sum((y_pred < thresh) & (y_actual == 0)) \/sum(y_actual ==0)\n    prevalence = (sum(y_actual)\/len(y_actual))\n    print('AUC:%.3f'%auc)\n    print('Accuracy:%.3f'%accuracy)\n    print('Recall:%.3f'%recall)\n    print('Precision:%.3f'%precision)\n    print('Specificity:%.3f'%specificity)\n    print('Prevalence:%.3f'%prevalence)\n    print(' ')\n    return auc, accuracy, recall, precision, specificity","abe1295e":"# Predictions\ny_train_preds_dense = model.predict(X_train,verbose = 1)\ny_valid_preds_dense = model.predict(X_valid,verbose = 1)","ad960e12":"# Threshold Value\nthresh = (sum(y_train)\/len(y_train))[0]","c7a52e23":"# Accessing Evaluation Metrics Function\nprint('On Train Data')\nprint_report(y_train, y_train_preds_dense, thresh)\nprint('On Valid Data')\nprint_report(y_valid, y_valid_preds_dense, thresh)","bcd94ab4":"# reshape input to [samples, time steps, features = 1] for CNN\nX_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n\nprint(X_train_cnn.shape)\nprint(X_valid_cnn.shape)","0a24454e":"# Relu for activation function & Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# compile the model with binary crossentropy, and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])\n","6d6093d6":"# Fitting data in model\nmodel.fit(X_train_cnn, y_train, batch_size = 32, epochs= 2, verbose = 1)","4699bfae":"# Predictions\ny_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\ny_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)","70ca8f84":"# Metrics\nprint('Train');\nprint_report(y_train, y_train_preds_cnn, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_cnn, thresh);","cd91edd6":"# Bidirectional LSTM with Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(64, input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2]))))\nmodel.add(Dropout(rate = 0.25))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(\n                loss = 'binary_crossentropy',\n                optimizer = 'adam',\n                metrics = ['accuracy'])","367f9522":"# Fitting Data\nmodel.fit(X_train_cnn[:10000], y_train[:10000], batch_size = 32, epochs= 1, verbose = 1)","a88dc1a9":"# Prediction\ny_train_preds_lstm = model.predict(X_train_cnn[:10000],verbose = 1)\ny_valid_preds_lstm = model.predict(X_valid_cnn,verbose = 1)","2ec1a47d":"# Metrics\nprint('Train');\nprint_report(y_train[:10000], y_train_preds_lstm, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_lstm, thresh);","4427c31c":"from sklearn.metrics import roc_curve, roc_auc_score\n\nfpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_valid, y_valid_preds_cnn)\nauc_valid_cnn = roc_auc_score(y_valid, y_valid_preds_cnn)\n\nfpr_valid_dense, tpr_valid_dense, t_valid_dense = roc_curve(y_valid, y_valid_preds_dense)\nauc_valid_dense = roc_auc_score(y_valid, y_valid_preds_dense)\n\nfpr_valid_lstm, tpr_valid_lstm, t_valid_lstm = roc_curve(y_valid, y_valid_preds_lstm)\nauc_valid_lstm = roc_auc_score(y_valid, y_valid_preds_lstm)\n\nplt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\nplt.plot(fpr_valid_dense, tpr_valid_dense, 'r-', label = 'Dense AUC:%.3f'%auc_valid_dense)\nplt.plot(fpr_valid_lstm, tpr_valid_lstm, 'b-', label = 'LSTM AUC:%.3f'%auc_valid_lstm)\n\nplt.plot([0,1],[0,1], 'k--')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.title('Validation Set')\nplt.show()\n","2a03192a":"<center><h1 class=\"list-group-item list-group-item-success\">Arrhythmia Detection<\/h1><\/center>","aeeea58d":"#### LSTM is not working good on data because we are using a subset of data"}}