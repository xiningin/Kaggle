{"cell_type":{"7d51a814":"code","79a54f0b":"code","be569b5d":"code","14d3f33e":"code","76c3ade4":"code","d376d69f":"code","e1d912f9":"code","8d226ceb":"code","66032ea2":"code","4d7a09ad":"code","63d8bf1e":"code","25bfbf71":"markdown","8c8ca099":"markdown","c6abdbb8":"markdown","5de5bb1d":"markdown","6d842f9e":"markdown","ef390ba0":"markdown","49de80f9":"markdown","c54ab413":"markdown","663aecb0":"markdown","7b355388":"markdown"},"source":{"7d51a814":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","79a54f0b":"from torch.utils.data.dataset import Dataset\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n\n","be569b5d":"class CustomDatasetFromCSV(Dataset):\n    def __init__(self, csv_path, height, width, transforms=None,train=False):\n        self.data = pd.read_csv(csv_path)\n        self.train = train\n        if train:\n            self.labels = np.asarray(self.data.iloc[:, 0])\n        self.height = height\n        self.width = width\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        \n        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28]) \n        if self.train:\n            single_image_label = self.labels[index]\n            img_as_np = np.asarray(self.data.iloc[index][1:]).reshape(28,28).astype('uint8')\n        else:\n            img_as_np = np.asarray(self.data.iloc[index][0:]).reshape(28,28).astype('uint8')\n        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n        img_as_img = Image.fromarray(img_as_np)\n        img_as_img = img_as_img.convert('L')\n        # Transform image to tensor\n        if self.transforms is not None:\n            img_as_tensor = self.transforms(img_as_img)\n        # Return image and the label\n        if self.train:\n            return (img_as_tensor, single_image_label)\n        else:\n            return img_as_tensor\n        \n\n    def __len__(self):\n        return len(self.data.index)\n        \n\n\ntransformations = transforms.Compose([transforms.ToTensor()])\ntrain_data = CustomDatasetFromCSV('..\/input\/train.csv', 28, 28, transformations, True)\ntest_data  = CustomDatasetFromCSV('..\/input\/test.csv', 28, 28, transformations, False)","14d3f33e":"# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 20\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n    num_workers=num_workers)","76c3ade4":"import matplotlib.pyplot as plt\n%matplotlib inline\n    \n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    # print out the correct label for each image\n    # .item() gets the value contained in a Tensor\n    ax.set_title(str(labels[idx].item()))\n\n","d376d69f":"img = np.squeeze(images[1])\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nax.imshow(img, cmap='gray')\nwidth, height = img.shape\nthresh = img.max()\/2.5\nfor x in range(width):\n    for y in range(height):\n        val = round(img[x][y],2) if img[x][y] !=0 else 0\n        ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center',\n                    color='white' if img[x][y]<thresh else 'black')","e1d912f9":"import torch.nn as nn\nimport torch.nn.functional as F\n#import torch.optim as optim\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # linear layer (784 -> 1 hidden node)\n        hidden_1 = 512\n        hidden_2 = 512\n        \n        self.fc1 = nn.Linear(28 * 28, hidden_1)\n        self.fc2 = nn.Linear(hidden_1, hidden_2)\n        self.fc3 = nn.Linear(hidden_2,10)\n        \n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        # flatten image input\n        x = x.view(-1, 28 * 28)\n        # add hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n# initialize the NN\nmodel = Net()\nprint(model)","8d226ceb":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.01)","66032ea2":"n_epochs = 10  # suggest training between 20-50 epochs\n\nmodel.train() # prep model for training\n\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    for data, target in train_loader:\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n        \n    # print training statistics \n    # calculate average loss over an epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n        epoch+1, \n        train_loss\n        ))","4d7a09ad":"\n\nmodel.eval() # prep model for *evaluation*\n\n","63d8bf1e":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages = dataiter.next()\n\n# get sample outputs\noutput = model(images)\n# convert output probabilities to predicted class\n_, preds = torch.max(output, 1)\n# prep images for display\nimages = images.numpy()\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(\"Pred:\"+str(preds[idx].item()))","25bfbf71":"## Load Data","8c8ca099":"## Visualize a Batch of Training Data","c6abdbb8":"\n## Specify Loss Function and Optimizer\n\nIt's recommended to use cross-entropy loss for classification. PyTorch's cross entropy function applies a softmax funtion to the output layer and then calculates the log loss.\n","5de5bb1d":"## View an Image in More Detail","6d842f9e":"\n## Test the Trained Network\n\nFinally, we test our best model on previously unseen test data and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy.\n\n**model.eval()**\n\nmodel.eval() will set all the layers in your model to evaluation mode. This affects layers like dropout layers that turn \"off\" nodes during training with some probability, but should allow every node to be \"on\" for evaluation!\n","ef390ba0":"## Data Loaders","49de80f9":"\n## Visualize Sample Test Results\n\nThis cell displays test images and their labels in this format: predicted (ground-truth). The text will be green for accurately classified examples and red for incorrect predictions.\n","c54ab413":"## Define the Network Architecture\nThe architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting.","663aecb0":"## Import Modules","7b355388":"## Train the Network\n\nThe steps for training\/learning from a batch of data are described in the comments below:\n\n    - Clear the gradients of all optimized variables\n    - Forward pass: compute predicted outputs by passing inputs to the model\n    - Calculate the loss\n    - Backward pass: compute gradient of the loss with respect to model parameters\n    - Perform a single optimization step (parameter update)\n    - Update average training loss\n"}}