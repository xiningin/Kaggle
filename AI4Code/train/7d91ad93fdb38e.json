{"cell_type":{"84f6088e":"code","377b0e66":"code","b53eaf8a":"code","29013117":"code","7f4002c3":"code","4a22c817":"code","3c9de544":"code","924891c3":"code","b58d57b9":"code","74c24578":"code","ee1abaf5":"code","127b6aab":"code","c73bc3e3":"code","369e9929":"code","16dbe8a1":"code","6dc8cbfa":"code","193eeb00":"code","0e05b7c4":"code","4dd37af1":"markdown","4ae45cd4":"markdown","584b7dbf":"markdown","d46b2ca5":"markdown","a843efbd":"markdown","b4dd2c78":"markdown","f015b3b5":"markdown","21e64436":"markdown","e2260933":"markdown","72e67a74":"markdown","9808cc6b":"markdown","204eee3b":"markdown","2d15af92":"markdown"},"source":{"84f6088e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.mixture import BayesianGaussianMixture\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import VarianceThreshold\n\n","377b0e66":"# READ DATA\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')","b53eaf8a":"cnt_compe_data = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n\n    # FIT BGMM\n    X = np.concatenate([train3, test3], axis=0)\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X)\n    clusters = gmm.predict(X)\n    cnt_compe_data[i*4:(i+1)*4] = pd.value_counts(clusters).values","29013117":"plt.hist(cnt_compe_data, bins=np.arange(0, 800, 20))\nplt.show()","7f4002c3":"np.random.seed(71)\ncnt_dummy_2 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=1, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_2[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","4a22c817":"plt.hist(cnt_dummy_2, bins=np.arange(0, 800, 20))\nplt.show()","3c9de544":"np.random.seed(71)\ncnt_dummy_4 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=2, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_4[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","924891c3":"plt.hist(cnt_dummy_4, bins=np.arange(0, 800, 20))\nplt.show()","b58d57b9":"np.random.seed(71)\ncnt_dummy_6 = np.zeros(512*4)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=3, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=4, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_6[i*4:(i+1)*4] = pd.value_counts(clusters_sim).values","74c24578":"plt.hist(cnt_dummy_6, bins=np.arange(0, 800, 20))\nplt.show()","ee1abaf5":"cnt_compe_data = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n\n    # FIT BGMM\n    X = np.concatenate([train3, test3], axis=0)\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X)\n    clusters = gmm.predict(X)\n    cnt_compe_data[i*6:(i+1)*6] = pd.value_counts(clusters).values","127b6aab":"plt.hist(cnt_compe_data, bins=np.arange(0, 800, 20))\nplt.show()","c73bc3e3":"np.random.seed(71)\ncnt_dummy_2 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=1, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_2[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","369e9929":"plt.hist(cnt_dummy_2, bins=np.arange(0, 800, 20))\nplt.show()","16dbe8a1":"np.random.seed(71)\ncnt_dummy_4 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=2, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_4[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","6dc8cbfa":"plt.hist(cnt_dummy_4, bins=np.arange(0, 800, 20))\nplt.show()","193eeb00":"np.random.seed(71)\ncnt_dummy_6 = np.zeros(512*6)\nfor i in tqdm(range(512)):\n    X_dummy, y_dummy = make_classification(\n        n_samples=768, n_features=512, n_informative=40, n_redundant=0, n_repeated=0, \n        n_classes=2, n_clusters_per_class=3, flip_y=0.05\n    )\n\n    sel_sim = VarianceThreshold(threshold=1.5).fit(X_dummy)\n    X_dummy = sel_sim.transform(X_dummy)\n\n    gmm = BayesianGaussianMixture(n_components=6, verbose=0, max_iter=10000)\n    gmm.fit(X_dummy)\n    clusters_sim = gmm.predict(X_dummy)\n    cnt_dummy_6[i*6:(i+1)*6] = pd.value_counts(clusters_sim).values","0e05b7c4":"plt.hist(cnt_dummy_6, bins=np.arange(0, 800, 20))\nplt.show()","4dd37af1":"# Part 1\nmake 4 clusters and see distribution","4ae45cd4":"* Simulation 1 (n_clusters_per_class = 1)","584b7dbf":"* Simulation 3 (n_clusters_per_class = 3)","d46b2ca5":"# Part 2\n6 clusters","a843efbd":"Competition dataset","b4dd2c78":"competition dataset","f015b3b5":"* Simulation 2 (n_clusters_per_class = 2)","21e64436":"* Simulation 1 (n_clusters_per_class = 1)","e2260933":"* Use BGMM to see how many clusters[](http:\/\/) are there.  \nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.mixture.BayesianGaussianMixture.html\n","72e67a74":"OH...","9808cc6b":"* Simulation 2 (n_clusters_per_class = 2)","204eee3b":"Use BGMM(BayesianGaussianMixtureModel), n_components = 4  \nIf 2 clusters (1 cluster for each class), clusters will shrink. ","2d15af92":"* Simulation 3 (n_clusters_per_class = 3)"}}