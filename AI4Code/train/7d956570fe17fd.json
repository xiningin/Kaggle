{"cell_type":{"b35f23ee":"code","37527e08":"code","b203d543":"code","3f5789bc":"code","b4e7492f":"code","56de0a92":"code","a71f53e6":"code","25cb23e4":"code","c836c1e6":"code","a5386ee1":"code","fc4f6127":"code","fa4a4f79":"code","ccb3822d":"code","8ac252c4":"code","d2736800":"code","5e0f12d3":"code","802fd52c":"code","0711e0b9":"code","b0a4b757":"code","db96eca1":"code","009e1d98":"code","cb3ef865":"code","5a40806f":"code","ebe46e78":"code","dbab39c5":"code","557539d7":"code","f4d9c3ae":"code","6cb6d90a":"code","3bfa1a25":"code","2a638db0":"code","d81cecbd":"code","33596748":"code","a24eab0a":"code","c5097130":"code","78512798":"code","d3291a05":"code","bdf7a7d4":"code","cbbd2772":"code","20ba3567":"code","a70981ac":"code","cf875a17":"code","22842872":"code","c028960f":"code","59e332ad":"code","25e44eea":"markdown","3590e3c4":"markdown","06346c19":"markdown","57f84401":"markdown","5f99d717":"markdown","67120178":"markdown","f2601651":"markdown","2770d1dd":"markdown","43aa042b":"markdown","32d10662":"markdown","24135453":"markdown"},"source":{"b35f23ee":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nimport pandas_profiling as pp\n\n# models\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor \nfrom sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, VotingRegressor \nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import RadiusNeighborsRegressor\nimport sklearn.model_selection\nfrom sklearn.model_selection import cross_val_predict as cvp\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","37527e08":"valid_part = 0.3","b203d543":"train0 = pd.read_csv('\/kaggle\/input\/prediction-bod-in-river-water\/train.csv')","3f5789bc":"train0.head(10)","b4e7492f":"train0.info()","56de0a92":"pp.ProfileReport(train0)","a71f53e6":"train0 = train0.drop(['Id','3','4','5','6','7'], axis = 1)\ntrain0 = train0.dropna()\ntrain0.info()","25cb23e4":"train0.head(3)","c836c1e6":"target_name = 'target'","a5386ee1":"# For boosting model\ntrain0b = train0\ntrain_target0b = train0b[target_name]\ntrain0b = train0b.drop([target_name], axis=1)\n# Synthesis valid as test for selection models\ntrainb, testb, targetb, target_testb = train_test_split(train0b, train_target0b, test_size=valid_part, random_state=0)","fc4f6127":"train_target0 = train0[target_name]\ntrain0 = train0.drop([target_name], axis=1)","fa4a4f79":"#For models from Sklearn\nscaler = StandardScaler()\ntrain0 = pd.DataFrame(scaler.fit_transform(train0), columns = train0.columns)","ccb3822d":"train0.head(3)","8ac252c4":"len(train0)","d2736800":"# Synthesis valid as test for selection models\ntrain, test, target, target_test = train_test_split(train0, train_target0, test_size=valid_part, random_state=0)","5e0f12d3":"train.head(3)","802fd52c":"test.head(3)","0711e0b9":"train.info()","b0a4b757":"test.info()","db96eca1":"acc_train_r2 = []\nacc_test_r2 = []\nacc_train_d = []\nacc_test_d = []\nacc_train_rmse = []\nacc_test_rmse = []","009e1d98":"def acc_d(y_meas, y_pred):\n    # Relative error between predicted y_pred and measured y_meas values\n    return mean_absolute_error(y_meas, y_pred)*len(y_meas)\/sum(abs(y_meas))\n\ndef acc_rmse(y_meas, y_pred):\n    # RMSE between predicted y_pred and measured y_meas values\n    return (mean_squared_error(y_meas, y_pred))**0.5","cb3ef865":"def acc_boosting_model(num,model,train,test,num_iteration=0):\n    # Calculation of accuracy of boosting model by different metrics\n    \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    if num_iteration > 0:\n        ytrain = model.predict(train, num_iteration = num_iteration)  \n        ytest = model.predict(test, num_iteration = num_iteration)\n    else:\n        ytrain = model.predict(train)  \n        ytest = model.predict(test)\n\n    print('target = ', targetb[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(targetb, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(targetb, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(targetb, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_testb[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_testb, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_testb, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_testb, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","5a40806f":"def acc_model(num,model,train,test):\n    # Calculation of accuracy of model \u0430\u043a\u0449\u044c Sklearn by different metrics   \n  \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    ytrain = model.predict(train)  \n    ytest = model.predict(test)\n\n    print('target = ', target[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(target, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(target, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(target, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_test[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_test, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_test, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_test, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","ebe46e78":"# Random Forest\n\nrandom_forest = GridSearchCV(estimator=RandomForestRegressor(), param_grid={'n_estimators': [100, 1000]}, cv=5)\nrandom_forest.fit(train, target)\nprint(random_forest.best_params_)\nacc_model(6,random_forest,train,test)","dbab39c5":"# Ridge Regressor\n\nridge = RidgeCV(cv=5)\nridge.fit(train, target)\nacc_model(10,ridge,train,test)","557539d7":"# Extra Trees Regressor\n\netr = ExtraTreesRegressor()\netr.fit(train, target)\nacc_model(12,etr,train,test)","f4d9c3ae":"# MLPRegressor\n\nmlp = MLPRegressor()\nparam_grid = {'hidden_layer_sizes': [i for i in range(2,20)],\n              'activation': ['relu'],\n              'solver': ['adam'],\n              'learning_rate': ['constant'],\n              'learning_rate_init': [0.01],\n              'power_t': [0.5],\n              'alpha': [0.0001],\n              'max_iter': [1000],\n              'early_stopping': [True],\n              'warm_start': [False]}\nmlp_GS = GridSearchCV(mlp, param_grid=param_grid, \n                   cv=10, verbose=True, pre_dispatch='2*n_jobs')\nmlp_GS.fit(train, target)\nacc_model(3,mlp_GS,train,test)","6cb6d90a":"# XGBREG\n\nxgb_clf = xgb.XGBRegressor({'objective': 'reg:squarederror'}) \nparameters = {'n_estimators': [60, 70, 80, 90, 95, 100, 105, 110, 120, 130, 140], \n              'learning_rate': [0.005, 0.01, 0.05, 0.075, 0.1],\n              'max_depth': [3, 5, 7, 9],\n              'reg_lambda': [0.1, 0.3, 0.5]}\nxgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1).fit(trainb, targetb)\nprint(\"Best score: %0.3f\" % xgb_reg.best_score_)\nprint(\"Best parameters set:\", xgb_reg.best_params_)\nacc_boosting_model(7,xgb_reg,trainb,testb)","3bfa1a25":"models = pd.DataFrame({\n    'Model': ['XGB', 'MLPRegressor', 'ExtraTreesRegressor', 'RidgeRegressor', 'Random Forest'],\n    \n    'r2_train': acc_train_r2,\n    'r2_test': acc_test_r2,\n    'd_train': acc_train_d,\n    'd_test': acc_test_d,\n    'rmse_train': acc_train_rmse,\n    'rmse_test': acc_test_rmse\n                     })","2a638db0":"pd.options.display.float_format = '{:,.2f}'.format","d81cecbd":"print('Prediction accuracy for models by R2 criterion - r2_test')\nmodels.sort_values(by=['r2_test', 'r2_train'], ascending=False)","33596748":"print('Prediction accuracy for models by relative error - d_test')\nmodels.sort_values(by=['d_test', 'd_train'], ascending=True)","a24eab0a":"print('Prediction accuracy for models by RMSE - rmse_test')\nmodels.sort_values(by=['rmse_test', 'rmse_train'], ascending=True)","c5097130":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['r2_train'], label = 'r2_train')\nplt.plot(xx, models['r2_test'], label = 'r2_test')\nplt.legend()\nplt.title('R2-criterion for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('R2-criterion, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","78512798":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['d_train'], label = 'd_train')\nplt.plot(xx, models['d_test'], label = 'd_test')\nplt.legend()\nplt.title('Relative errors for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('Relative error, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","d3291a05":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['rmse_train'], label = 'rmse_train')\nplt.plot(xx, models['rmse_test'], label = 'rmse_test')\nplt.legend()\nplt.title('RMSE for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('RMSE, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","bdf7a7d4":"testn = pd.read_csv('\/kaggle\/input\/prediction-bod-in-river-water\/test.csv')\ntestn.info()","cbbd2772":"testn = testn.drop(['Id','3','4','5','6','7'], axis = 1)\ntestn.head(3)","20ba3567":"#For models from Sklearn\ntestn = pd.DataFrame(scaler.transform(testn), columns = testn.columns)","a70981ac":"\nmlp_GS.fit(train0, train_target0)\nmlp_GS.predict(testn)[:3]","cf875a17":"\nxgb_reg.fit(train0, train_target0)\nxgb_reg.predict(train)[:3]","22842872":"random_forest.fit(train0, train_target0)\nrandom_forest.predict(train)[:3]","c028960f":"etr.fit(train0, train_target0)\netr.predict(train)[:3]","59e332ad":"ridge.fit(train0, train_target0)\nridge.predict(train)[:3]","25e44eea":"We can now compare our models and to choose the best one for our problem.","3590e3c4":"The analysis showed that many values \u200b\u200bare only available in stations 1 and 2, while others have much less data. We propose that at the start code, the BOD5 prediction should be carried out only for data from the first two stations","06346c19":"## 6. Models comparison <a class=\"anchor\" id=\"6\"><\/a>\n\n[Back to Table of Contents](#0.1)","57f84401":"[Go to Top](#0)","5f99d717":"## 4. Preparing to modeling <a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","67120178":"## 2. Download datasets <a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","f2601651":"## 1. Import libraries <a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","2770d1dd":"## 7. Prediction <a class=\"anchor\" id=\"7\"><\/a>\n\n[Back to Table of Contents](#0.1)","43aa042b":"## 3. EDA <a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","32d10662":"Thanks to: \"[Vitalii Mokin](https:\/\/www.kaggle.com\/vbmokin\/bod-prediction-in-river-15-regression-models)\"","24135453":"## 5. Tuning models and test for all features <a class=\"anchor\" id=\"5\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}