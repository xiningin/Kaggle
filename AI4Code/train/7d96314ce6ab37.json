{"cell_type":{"554d8bce":"code","0f3cd4d5":"code","7a5a2652":"code","7829120f":"code","01149c37":"code","72d4cdc7":"code","2dabdfc1":"code","b94b7f09":"code","35243160":"code","96d15f20":"code","fab6e43b":"code","8396268a":"code","2ad62993":"code","9d50edd1":"code","cbf4eeb2":"code","51a9810c":"code","9107971f":"code","193c16cc":"code","8e7bc8d5":"code","54035b7f":"code","c451b6c1":"code","1b14e2c0":"code","4e1bd71f":"code","963940bf":"code","1bf79b1a":"code","755ea77c":"code","75b8c1fc":"markdown","3899e6b1":"markdown","b73c48f6":"markdown","49596ceb":"markdown","81ebacc1":"markdown","2ba16893":"markdown","b640f9ac":"markdown","dc78ec8a":"markdown","879d6c05":"markdown","b58cf873":"markdown","f3d48344":"markdown","cfeaf3a6":"markdown","08821bea":"markdown","ed199568":"markdown","c410be7a":"markdown","0709614c":"markdown","46db53e5":"markdown","17585e9c":"markdown","78b1db41":"markdown","885e2ae6":"markdown","657c8175":"markdown","4b4f819a":"markdown","f505f0ac":"markdown","2f4605fa":"markdown","e937b434":"markdown","d7f27c13":"markdown","184985b8":"markdown","b544e021":"markdown","79ab3b0d":"markdown","116cbd2b":"markdown","85ae6c26":"markdown","cf9797e3":"markdown","00f06130":"markdown","558d8cd0":"markdown","6f6508ca":"markdown","1c56a7e6":"markdown","eec8a65a":"markdown","6ad0027f":"markdown","99d6a81e":"markdown","1a445e91":"markdown","ddac92e5":"markdown","559ed93b":"markdown","25943ecf":"markdown"},"source":{"554d8bce":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nimport pycountry\nimport json\nimport time\nimport datetime\nfrom datetime import date\nfrom wordcloud import WordCloud\nimport textblob\nimport itertools","0f3cd4d5":"countries=  [\"GB\", \n\"MX\",  \n\"KR\",\n\"DE\",  \n\"FR\", \n\"US\", \n\"IN\", \n\"RU\", \n\"JP\", \n\"CA\" ]\nfor file in glob(\"..\/input\/youtube-new\/*.csv\"):\n    print(file.split(\"\/\")[3][:2],\n          \" - \",\n          pycountry.countries.get(alpha_2=file.split(\"\/\")[3][:2]).name)","7a5a2652":"#function that extracts category and category id from json string and returns in a dictionary\ndef get_category_dict(json_string):\n    category_dict = {}\n    for items in range(len(json_string[\"items\"])):\n        category_dict[int(json_string[\"items\"][items][\"id\"].strip())] = json_string[\"items\"][items][\"snippet\"][\"title\"]\n    return category_dict\n\n#function that assigns category name to each category id in dataframe\ndef get_categories(cid_values,category_dict):\n    category = []\n    for cid in cid_values:\n        if cid in category_dict:\n            category.append(category_dict[cid])\n        else:\n            category.append(\"Other\")\n    return category\n\n#function that modifies date from YY.DD.MM to YYYY-MM-DD\ndef transform_date(date_values):\n    for item in range(len(date_values)):\n        converted_time = time.strptime(date_values[item], '%y.%d.%m')\n        date_values[item] = str(converted_time.tm_year) + \\\n        \"-\" + \\\n        str(converted_time.tm_mon) + \\\n        \"-\" + \\\n        str(converted_time.tm_mday)\n    return date_values\n\n#function that reuturns the difference in days between publish date and trending date\ndef get_diff(trending_date,publish_date):\n    days = []\n    for td,pd in zip(trending_date,publish_date):\n        #+1 is added to compensate for the number of videos that were published and became trending on the same day. Else it would\n        #have a value of -1\n        days.append((datetime.datetime.strptime(td,\"%Y-%m-%d\") - datetime.datetime.strptime(pd,'%Y-%m-%dT%H:%M:%S.000Z')).days+1)\n    return days\n\n#function that gets the length of each description text\ndef get_desc_length(descriptions):\n    lengths = []\n    for desc in descriptions:\n        lengths.append(len(str(desc)))\n    return lengths\n\ndef get_desc_sentiment(descriptions):\n    sentiments = []\n    for desc in descriptions:\n        if(textblob.TextBlob(str(desc)).sentiment.polarity < 0):\n            sentiments.append(\"Negative\")\n        if(textblob.TextBlob(str(desc)).sentiment.polarity == 0):\n            sentiments.append(\"Neutral\")\n        if(textblob.TextBlob(str(desc)).sentiment.polarity > 0 ):\n            sentiments.append(\"Positive\")\n    return sentiments","7829120f":"country_code = []\ncategory = []\nna = []\nav = []\ncategory_dict = {}\n\nGB = pd.read_csv(\"..\/input\/youtube-new\/GBvideos.csv\")\nGB_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/GB_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(GB_json)\ncategory = get_categories(GB[\"category_id\"].values,category_dict)\ncountry_code = [\"GB\"] * len(GB)\nGB[\"Category\"] = category\nGB[\"Country_code\"] = country_code\nGB[\"trending_date\"] = transform_date(GB[\"trending_date\"].values)\nGB[\"days\"] = get_diff(GB[\"trending_date\"],GB[\"publish_time\"])\nGB[\"desc_length\"] = get_desc_length(GB[\"description\"])\nGB[\"desc_sentiment\"] = get_desc_sentiment(GB[\"description\"])\n\nMX = pd.read_csv(\"..\/input\/youtube-new\/MXvideos.csv\",encoding=\"latin\")\nMX_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/MX_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(MX_json)\ncategory = get_categories(MX[\"category_id\"].values,category_dict)\ncountry_code = [\"MX\"] * len(MX)\nMX[\"Category\"] = category\nMX[\"Country_code\"] = country_code\nMX[\"trending_date\"] = transform_date(MX[\"trending_date\"].values)\nMX[\"days\"] = get_diff(MX[\"trending_date\"],MX[\"publish_time\"])\nMX[\"desc_length\"] = get_desc_length(MX[\"description\"])\nMX[\"desc_sentiment\"] = get_desc_sentiment(MX[\"description\"])\n\nKR = pd.read_csv(\"..\/input\/youtube-new\/KRvideos.csv\",encoding=\"latin\")\nKR_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/KR_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(KR_json)\ncategory = get_categories(KR[\"category_id\"].values,category_dict)\ncountry_code = [\"KR\"] * len(KR)\nKR[\"Category\"] = category\nKR[\"Country_code\"] = country_code\nKR[\"trending_date\"] = transform_date(KR[\"trending_date\"].values)\nKR[\"days\"] = get_diff(KR[\"trending_date\"],KR[\"publish_time\"])\nKR[\"desc_length\"] = get_desc_length(KR[\"description\"])\nKR[\"desc_sentiment\"] = get_desc_sentiment(KR[\"description\"])\n\nDE = pd.read_csv(\"..\/input\/youtube-new\/DEvideos.csv\")\nDE_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/DE_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(DE_json)\ncategory = get_categories(DE[\"category_id\"].values,category_dict)\ncountry_code = [\"DE\"] * len(DE)\nDE[\"Category\"] = category\nDE[\"Country_code\"] = country_code\nDE[\"trending_date\"] = transform_date(DE[\"trending_date\"].values)\nDE[\"days\"] = get_diff(DE[\"trending_date\"],DE[\"publish_time\"])\nDE[\"desc_length\"] = get_desc_length(DE[\"description\"])\nDE[\"desc_sentiment\"] = get_desc_sentiment(DE[\"description\"])\n\nFR = pd.read_csv(\"..\/input\/youtube-new\/FRvideos.csv\")\nFR_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/FR_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(FR_json)\ncategory = get_categories(FR[\"category_id\"].values,category_dict)\ncountry_code = [\"FR\"] * len(FR)\nFR[\"Category\"] = category\nFR[\"Country_code\"] = country_code\nFR[\"trending_date\"] = transform_date(FR[\"trending_date\"].values)\nFR[\"days\"] = get_diff(FR[\"trending_date\"],FR[\"publish_time\"])\nFR[\"desc_length\"] = get_desc_length(FR[\"description\"])\nFR[\"desc_sentiment\"] = get_desc_sentiment(FR[\"description\"])\n\nUS = pd.read_csv(\"..\/input\/youtube-new\/USvideos.csv\")\nUS_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/US_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(US_json)\ncategory = get_categories(US[\"category_id\"].values,category_dict)\ncountry_code = [\"US\"] * len(US)\nUS[\"Category\"] = category\nUS[\"Country_code\"] = country_code\nUS[\"trending_date\"] = transform_date(US[\"trending_date\"].values)\nUS[\"days\"] = get_diff(US[\"trending_date\"],US[\"publish_time\"])\nUS[\"desc_length\"] = get_desc_length(US[\"description\"])\nUS[\"desc_sentiment\"] = get_desc_sentiment(US[\"description\"])\n\nIN = pd.read_csv(\"..\/input\/youtube-new\/INvideos.csv\")\nIN_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/IN_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(IN_json)\ncategory = get_categories(IN[\"category_id\"].values,category_dict)\ncountry_code = [\"IN\"] * len(IN)\nIN[\"Category\"] = category\nIN[\"Country_code\"] = country_code\nIN[\"trending_date\"] = transform_date(IN[\"trending_date\"].values)\nIN[\"days\"] = get_diff(IN[\"trending_date\"],IN[\"publish_time\"])\nIN[\"desc_length\"] = get_desc_length(IN[\"description\"])\nIN[\"desc_sentiment\"] = get_desc_sentiment(IN[\"description\"])\n\nRU = pd.read_csv(\"..\/input\/youtube-new\/RUvideos.csv\",encoding=\"latin\")\nRU_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/RU_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(RU_json)\ncategory = get_categories(RU[\"category_id\"].values,category_dict)\ncountry_code = [\"RU\"] * len(RU)\nRU[\"Category\"] = category\nRU[\"Country_code\"] = country_code\nRU[\"trending_date\"] = transform_date(RU[\"trending_date\"].values)\nRU[\"days\"] = get_diff(RU[\"trending_date\"],RU[\"publish_time\"])\nRU[\"desc_length\"] = get_desc_length(RU[\"description\"])\nRU[\"desc_sentiment\"] = get_desc_sentiment(RU[\"description\"])\n\nJP = pd.read_csv(\"..\/input\/youtube-new\/JPvideos.csv\",encoding=\"latin\")\nJP_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/JP_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(JP_json)\ncategory = get_categories(JP[\"category_id\"].values,category_dict)\ncountry_code = [\"JP\"] * len(JP)\nJP[\"Category\"] = category\nJP[\"Country_code\"] = country_code\nJP[\"trending_date\"] = transform_date(JP[\"trending_date\"].values)\nJP[\"days\"] = get_diff(JP[\"trending_date\"],JP[\"publish_time\"])\nJP[\"desc_length\"] = get_desc_length(JP[\"description\"])\nJP[\"desc_sentiment\"] = get_desc_sentiment(JP[\"description\"])\n\nCA = pd.read_csv(\"..\/input\/youtube-new\/CAvideos.csv\")\nCA_json = json.loads(\"\".join(open(\"..\/input\/youtube-new\/CA_category_id.json\",\"r\").readlines()))\ncategory_dict = get_category_dict(CA_json)\ncategory = get_categories(CA[\"category_id\"].values,category_dict)\ncountry_code = [\"CA\"] * len(CA)\nCA[\"Category\"] = category\nCA[\"Country_code\"] = country_code\nCA[\"trending_date\"] = transform_date(CA[\"trending_date\"].values)\nCA[\"days\"] = get_diff(CA[\"trending_date\"],CA[\"publish_time\"])\nCA[\"desc_length\"] = get_desc_length(CA[\"description\"])\nCA[\"desc_sentiment\"] = get_desc_sentiment(CA[\"description\"])","01149c37":"data = pd.concat([GB,MX,KR,DE,FR,US,IN,RU,JP,CA]).drop(['video_id'],axis=1)","72d4cdc7":"data","2dabdfc1":" data.isna().sum()","b94b7f09":"data.describe().apply(lambda s: s.apply('{0:.5f}'.format)).drop([\"category_id\"],axis=1)","35243160":"plt.figure(figsize=(15,5))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'lightgray'})\nfor i in range(len(countries)):\n    countries,count = np.unique(data['Country_code'],return_counts=True)\n    plt.xlabel(\"Country\")\n    plt.ylabel(\"Count\")\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.bar(countries,count,zorder=3,color = ['forestgreen','green','springgreen','aquamarine','darkslategrey','aqua','powderblue','lightskyblue','lightslategray','lightsteelblue'])\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","96d15f20":"plt.figure(figsize=(15,25))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'lightgray'})\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    dates = data[data[\"Country_code\"] == countries[i]][\"trending_date\"]\n    dates,count = np.unique([date.split(\"-\")[0] for date in dates],return_counts=True)\n    plt.title(countries[i])\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Count\")\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.4, \n                    hspace=0.4)\n    plt.bar(dates,count,zorder=3,color = ['orange','yellow'])\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","fab6e43b":"for i in range(len(countries)):\n    dayslist = data[data[\"Country_code\"] == countries[i]][\"days\"]\n    print(countries[i])\n    print(dayslist.describe())\n    print(\"\\n\\n\")","8396268a":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    categories = data[data[\"Country_code\"] == countries[i]][\"Category\"]\n    categories,count = np.unique(categories,return_counts=True)\n    plt.title(countries[i])\n    plt.xlabel(\"Category\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.8, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.19, \n                    hspace=0.4)\n    plt.bar(categories,count,zorder=3,color = ['deepskyblue','skyblue'])\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","2ad62993":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    publish_time = data[data[\"Country_code\"] == countries[i]][\"publish_time\"]\n    publish_time_year,count = np.unique([i.split(\"-\")[0] for i in publish_time],return_counts=True)\n    plt.title(countries[i])\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.8, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.19, \n                    hspace=0.4)\n    plt.bar(publish_time_year,count,zorder=3,color = ['greenyellow','lawngreen'])\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","9d50edd1":"months = [\"January\",\"Febraury\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\nplt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    publish_time = data[data[\"Country_code\"] == countries[i]][\"publish_time\"]\n    publish_time_month,count = np.unique([i.split(\"-\")[1] for i in publish_time],return_counts=True)\n    plt.title(countries[i])\n    plt.xlabel(\"Month\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.8, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.19, \n                    hspace=0.4)\n    plt.plot([months[int(i)-1] for i in publish_time_month],count,zorder=3)\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","cbf4eeb2":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    comments_disabled = data[data[\"Country_code\"] == countries[i]][\"comments_disabled\"]\n    comments_disabled,comments_disabled_count = np.unique([str(item) for item in comments_disabled],return_counts=True)\n    \n    plt.title(countries[i])\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.bar(comments_disabled,comments_disabled_count,zorder=3,color=[\"lightcoral\",\"brown\"])\n    plt.xlabel(\"Comments Disabled\")\n    plt.ylabel(\"Count\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","51a9810c":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    ratings_disabled = data[data[\"Country_code\"] == countries[i]][\"ratings_disabled\"]\n    ratings_disabled,ratings_disabled_count = np.unique([str(item) for item in ratings_disabled],return_counts=True)\n    \n    plt.title(countries[i])\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.bar(ratings_disabled,ratings_disabled_count,zorder=3,color=[\"lightcoral\",\"brown\"])\n    plt.xlabel(\"Ratings Disabled\")\n    plt.ylabel(\"Count\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","9107971f":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    veor = data[data[\"Country_code\"] == countries[i]][\"video_error_or_removed\"]\n    veor,veor_count = np.unique([str(item) for item in veor],return_counts=True)\n    \n    plt.title(countries[i])\n    plt.xticks(rotation=90)\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.bar(veor,veor_count,zorder=3,color=[\"lightcoral\",\"brown\"])\n    plt.xlabel(\"Video Error or Removed\")\n    plt.ylabel(\"Count\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","193c16cc":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    likes = data[data[\"Country_code\"] == countries[i]][\"likes\"]\n    views = data[data[\"Country_code\"] == countries[i]][\"views\"]\n    plt.title(countries[i] + \" (Correlation Coeffecient - \" + \"{:.2f} )\".format(np.corrcoef(likes,views)[0,1]))\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.scatter(likes,views,zorder=3,color=\"slateblue\")\n    plt.xlabel(\"Likes\")\n    plt.ylabel(\"Views\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","8e7bc8d5":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    likes = data[data[\"Country_code\"] == countries[i]][\"likes\"]\n    comments = data[data[\"Country_code\"] == countries[i]][\"comment_count\"]\n    plt.title(countries[i] + \" (Correlation Coeffecient - \" + \"{:.2f} )\".format(np.corrcoef(likes,comments)[0,1]))\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.scatter(likes,comments,zorder=3,color=\"cornflowerblue\")\n    plt.xlabel(\"Likes\")\n    plt.ylabel(\"Comments\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","54035b7f":"plt.figure(figsize=(15,15))\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\n\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    views = data[data[\"Country_code\"] == countries[i]][\"views\"]\n    comments = data[data[\"Country_code\"] == countries[i]][\"comment_count\"]\n    plt.title(countries[i] + \" (Correlation Coeffecient - \" + \"{:.2f} )\".format(np.corrcoef(views,comments)[0,1]))\n    plt.tick_params(left=False,\n                bottom=False)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.2, \n                    wspace=0.19,\n                    hspace=0.4)\n    \n    plt.scatter(views,comments,zorder=3,color=\"mediumpurple\")\n    plt.xlabel(\"Views\")\n    plt.ylabel(\"Comments\")\n    plt.grid(True,color='white', linestyle='solid', linewidth=2.0, alpha=0.5,zorder=0)","c451b6c1":"pd.set_option('display.float_format', lambda x: '%.5f' % x)\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'white'})\ndislike_count = []\nplt.figure(figsize=(15,15))\nfor i in range(len(countries)):\n    dislike_count = []\n    plt.subplot(5,2,i+1)\n    dayslist = data[data[\"Country_code\"] == countries[i]][\"dislikes\"]\n    category = np.unique(data[data[\"Country_code\"] == countries[i]][\"Category\"])\n    for cat in category:\n        temp = data[data[\"Country_code\"] == countries[i]]\n        temp = temp[temp[\"Category\"] == cat]\n        dislike_count.append(temp[\"dislikes\"].sum())\n    plt.title(countries[i])\n    plt.xlabel(\"Category\")\n    plt.ylabel(\"Dislike Count\")\n    plt.xticks(rotation=90)\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.8, \n                    wspace=0.19,\n                    hspace=0.8)\n    plt.grid(True,color='black', linestyle='solid', linewidth=0.20, alpha=0.5,zorder=0) \n    plt.bar(category,dislike_count,zorder=3,color=[\"sandybrown\",\"peachpuff\",\"peru\",\"bisque\"])   ","1b14e2c0":"tags_list = []\nplt.figure(figsize=(25,25))\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    tags_list = []\n    tags = data[data[\"Country_code\"] == countries[i]][\"tags\"]\n    for taglist in tags:\n        tags_split = taglist.split(\"|\")\n        for item in tags_split:\n            for part in item.split():\n                if \"\/\" in part:\n                    tags_list.append([str(i.strip(\"\\\"\").strip(\"'\").strip(\"#\")) for i in part.split(\"\/\")])\n                if \"\\\\\" in part:\n                     tags_list.append([str(i.strip(\"\\\"\").strip(\"'\").strip(\"#\")) for i in part.split(\"\\\\\")])\n    wordcloudo = WordCloud(background_color=\"white\").generate(\" \".join(list(itertools.chain.from_iterable(tags_list[:30]))))\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.3, \n                    wspace=0.19,\n                    hspace=0.2)\n    plt.title(countries[i],fontdict={\"fontsize\" : 30})\n    plt.axis('off')\n    plt.imshow(wordcloudo)        \n                ","4e1bd71f":"lengths = []\nplt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\nplt.figure(figsize=(15,5))\nfor i in range(len(countries)):\n    lengths.append(data[data[\"Country_code\"] == countries[i]][\"desc_length\"].sum() \/  len(data[data[\"Country_code\"] == countries[i]])) \nplt.bar(countries,lengths,zorder=3,color = [\"darkseagreen\",\"greenyellow\",\"limegreen\",\"lime\",\"forestgreen\",\"springgreen\",\"mediumseagreen\",\"lawngreen\",\"mediumspringgreen\",\"darkgreen\"])\nplt.tick_params(left=False,bottom=False)\nplt.xlabel(\"Country\")\nplt.ylabel(\"Length of Description\")\nplt.grid(True,color=\"white\",linewidth=2.0,zorder=0,alpha=0.5)\nplt.show()","963940bf":"desc_text=\"\"\nplt.figure(figsize=(15,15))\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    desc_text=\"\"\n    for desc in data[data[\"Country_code\"] == countries[i]][\"description\"]:\n        desc_text += str(desc) + \" \" \n    wordcloud = WordCloud(background_color=\"white\").generate(desc_text)\n    plt.axis('off')\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.3, \n                    wspace=0.19,\n                    hspace=0.2)\n    plt.imshow(wordcloud)","1bf79b1a":"plt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\nplt.figure(figsize=(15,20))\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    sentiments,counts = np.unique(data[data[\"Country_code\"] == countries[i]][\"desc_sentiment\"],return_counts=True)\n    plt.tick_params(left=False,bottom=False)\n    plt.title(countries[i])\n    plt.xlabel(\"Sentiment\")\n    plt.ylabel(\"Count\")\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.5, \n                    wspace=0.19,\n                    hspace=0.2)\n    plt.bar(sentiments,counts,zorder=3,color=[\"darkred\",\"yellow\",\"green\"])\n    plt.grid(True,color=\"white\",linewidth=2.0,zorder=0,alpha=0.5)","755ea77c":"plt.rcParams[\"axes.linewidth\"]  = 0\nplt.rcParams.update({'axes.facecolor':'whitesmoke'})\nplt.figure(figsize=(15,20))\nfor i in range(len(countries)):\n    plt.subplot(5,2,i+1)\n    desc_present = data[data[\"Country_code\"] == countries[i]][\"description\"]\n    desc_present = [\"False\" if i is np.nan else \"True\" for i in desc_present]\n    desc_present,counts = np.unique(desc_present,return_counts=True)\n    plt.tick_params(left=False,bottom=False)\n    plt.title(countries[i])\n    plt.xlabel(\"Description Text Present\")\n    plt.ylabel(\"Count\")\n    plt.subplots_adjust(left=0,\n                    bottom=-1.0, \n                    right=0.9, \n                    top=0.5, \n                    wspace=0.19,\n                    hspace=0.2)\n    plt.bar(desc_present,counts,zorder=3,color=[\"tomato\",\"lightsalmon\"])\n    plt.grid(True,color=\"white\",linewidth=2.0,zorder=0,alpha=0.5)","75b8c1fc":"<b>Inference : <\/b><b><i>75%<\/i><\/b> of the trending time varies between <b><i>[1-3]<\/i><\/b> for majority of the geographical areas except <b><i>US<\/i><\/b> where <b><i>75%<\/i><\/b> of the videos take <b><i>9 days<\/i><\/b> to get trending. Similarly, the average number of days for a video to become trending varies between <b><i>[1-3]<\/i><\/b> days for majority of the geographical areas except <b><i>United Kingdom (GB)<\/i><\/b> and <b><i>United States<\/i><\/b> where it takes <b><i>36<\/i><\/b> and <b><i>16<\/i><\/b> days respectively.","3899e6b1":"<b>Inference : <\/b><b><i>Aftermath<\/i><\/b>, <b><i>RCA<\/i><\/b>, <b><i>Musical<\/i><\/b>, <b><i>Music<\/i><\/b>, <b><i>Interscope<\/i><\/b> and <b><i>Shady<\/i><\/b> are the commonly repeated words, although this vary depending on region.","b73c48f6":"<b>Inference : <\/b>In general, Trending videos are majorly published in the year <b><i>2017<\/i><\/b> and <b><i>2018<\/i><\/b> with negligibly less in the previous year except for <b><i>India (IN)<\/i><\/b> and <b><i>Japan (JP)<\/i><\/b> where the trending videos are published only in the years <b><i>2017<\/i><\/b> & <b><i>2018<\/i><\/b> and <b><i>2018<\/i><\/b> respectively.","49596ceb":"<h2>Comments Disabled<\/h2>","81ebacc1":"<b>Inference : <\/b>In General, the mid part of an year (July - October) seems to experience less trending videos in contrast to the beginning and end of an year.","2ba16893":"<h2>Ratings Disabled<\/h2>","b640f9ac":"<h2>Video Error or Removed<\/h2>","dc78ec8a":"<h2>Likes vs Views - Visualisation and Correlation Coeffecient<\/h2>","879d6c05":"<b>Inference : <\/b>Fairly balanced graph, except for <b><i>South Korea (KR)<\/i><\/b> and <b><i>Mexico (MX)<\/i><\/b>. The type of trending category in each of these geographical locations will have an effect on the length of description text on vidoes - Generally, Entertainment, Music etc will have longer description text (because of the crew descriptions, lyrics etc) while Blogs and News will have relatively smaller descriptions.","b58cf873":"<b>Inference : <\/b>From the above visualizations and Correlation Coeffecient values, it is evident that all geographical locations follow a strong relation between <b><i>Likes vs Views<\/i><\/b> i.e, As the number of views of the video increases, the likes that the video gets also increases.\n","f3d48344":"<h2>Sentiment of Description Text<\/h2>","cfeaf3a6":"<h2>WordCloud for Description Text<\/h2>","08821bea":"<h1>Description Text Analysis<\/h1>\n<ul>\n    <li>Analyse the averge length of the description text across regions.<\/li>\n    <li>Genereate Word cloud for the description text across regions.<\/li>\n    <li>Analyse sentiment for each description text.<\/li>\n    <li>Analyse the number of videos which does not have a description text but is still trending<\/li>\n<\/ul>","ed199568":"<h2>Views vs Comments - Visualisation and Correlation Coeffecient<\/h2>","c410be7a":"<h1>Dislikes for Trending Videos<\/h1>","0709614c":"<h2>Data Loading and Engineering<\/h2>\n<p>The data is spread over many files - One for each country. Let us see the countries are present and combine all of them into a single file.<\/p>","46db53e5":"<b>Inference : <\/b>All the countries are having majority of the trending videos in the year of <b><i>2018<\/i><\/b> while Japan has only trending videos in the year <b><i>2018<\/i><\/b>. ","17585e9c":"<b>Inference : <\/b> Except <b><i>Japan(JP)<\/i><\/b> all other countries are having a majority position in the number of trening videos\n","78b1db41":"<h2>Trending Date<\/h2>","885e2ae6":"<b>Inference : <\/b>Overall, Trending video categories are dominated by <b><i>Entertainment<\/i><\/b> and\n<b><i>People & Blogs<\/i><\/b> followed by <b><i>Music<\/i><\/b> and <b><i>News & Politics<\/i><\/b>.","657c8175":"<b>Inference : <\/b>From the above visualizations and Correlation Coeffecient values, it is evident that all geographical locations follow a strong relation between <b><i>Likes vs Comments<\/i><\/b> i.e, As the number of likes for the video increases, the comments that the video gets also increases.\n","4b4f819a":"<b>Inference : <\/b>For all geographical locations, majority of the trending videos has description text present while negligibly less videos became trending without a description text. ","f505f0ac":"<b>Inference : <\/b><b><i>Entertainment<\/i><\/b> and <b><i>Music<\/i><\/b> are the two categories which highest number of dislikes followed by <b><i>Comedy<\/i><\/b> and <b><i>People & Blogs<\/i><\/b>. <b><i>Russia (RU)<\/i><\/b> has dislikes in categories of <b><i>News & Politics<\/i><\/b> and <b><i>Other<\/i><\/b> too.","2f4605fa":"<h2>Combined Dataset<\/h2>","e937b434":"<h1 id=\"stats\">Statistics<\/h1>","d7f27c13":"<h2>Likes vs Comments - Visualisation and Correlation Coeffecient<\/h2>","184985b8":"<h1>Word Cloud - Tags<\/h1>","b544e021":"<h1>Number of days to become trending<\/h1>\n<p>Generate statistics for days column for each country<\/p>","79ab3b0d":"<h1>Dashboard Generation<\/h1>\n","116cbd2b":"<b>Inference : <\/b><b><i>Positive<\/i><\/b> and <b><i>Negative<\/i><\/b> sentiments are majority of most of the geographical locations.<b><i>Negative<\/i><\/b> sentiment is relative less possibly due to the Youtube Policy which removes extrement negative content.","85ae6c26":"<h1>Trending Yotube Video Statistics - EDA<\/h1>\n<p>Exploratory Data Analysis of Trending Youtube Videos<\/p>\n<img src=\"https:\/\/play-lh.googleusercontent.com\/vA4tG0v4aasE7oIvRIvTkOYTwom07DfqHdUPr6k7jmrDwy_qA_SonqZkw6KX0OXKAdk\"\nstyle=\"width : 100%;margin : auto;\">","cf9797e3":"<ul>\n    <li>Assign country code to each dataframe before combining to generate geography-wise analysis.<\/li>\n    <li>Assign category name to corresponding category id to generate category-wise analysis.<\/li>\n    <li>Generate two functions - One to extract category name and id.<br\/ >\n        Other to set category names by using the category id in the dataframe.<\/li>\n    <li>Transform all dates to uniform format of YYYY-MM-DD.<\/li>\n    <li>Get the difference in number of days between published date of video and its trending date.<\/li>\n    <li>Get the length of each description.<\/li>\n<\/ul>","00f06130":"<h2>Videos without description text<\/h2>","558d8cd0":"<h1>Video Parameters<\/h1>\n<ul>\n    <li>Comments Disabled<\/li>\n    <li>Ratings Disabled<\/li>\n    <li>Video Error or Removed<\/li>\n<\/ul>","6f6508ca":"<b>Inference : <\/b>In General, <b><i>Views vs Comments<\/i><\/b> follows a decently strong relation as observed except in <b><i>United Kingdom (GB)<\/i><\/b> where there is a weak relation between Views and Comments.<br \/>\n<b>Conclusion : <\/b>By analysing the above three video parameters, it can be concluded that trending vidoes has all the three parameters, Likes, Views and Comments related in a positive manner i.e, As the views increases, likes and comments also increases with it.","1c56a7e6":"<h2>Geographical Distribution<\/h2>","eec8a65a":"<h2>Category<\/h2>","6ad0027f":"<h1>Relation between video parameters<\/h1>\n<ul>\n    <li>Likes vs Views<\/li>\n    <li>Likes vs Comments<\/li>\n    <li>Views vs Comments<\/li>\n<\/ul>","99d6a81e":"<h2>Video Publish Time<\/h2>\n<p>Video Publish Time can be broken down into two parts - Year and Month.","1a445e91":"<h2>Average length of Description Text<\/h2>","ddac92e5":"<b>Inference : <\/b>The parameters of the trending videos states that majority of the videos did not have <b><i>Comments Disabled<\/i><\/b>, <b><i>Ratings Disabled<\/i><\/b> or <b><i>Video removed<\/i><\/b>.","559ed93b":"<b>Inference : <\/b> Social media terms like <b><i>Google<\/i><\/b>, <b><i>Youtube<\/i><\/b>, <b><i>Facebook<\/i><\/b>, <b><i>Instagram<\/i><\/b>,<b><i>Twitter<\/i><\/b>,<b><i>bit.ly<\/i><\/b> etc are majorly found in description text. Other words like <b><i>Watch<\/i><\/b>, <b><i>Subscribe<\/i><\/b>, <b><i>Follow<\/i><\/b> are also popular in description text.","25943ecf":"<h1 style=\"margin:auto;text-align:center;background-color:rgb(232, 230, 223);border-radius : 5px;padding-top : 25px;padding-bottom : 25px; width : 80%;font-size : 25px;\">Thank you for reading! Upvote and share my notebook if you liked it<\/h1>"}}