{"cell_type":{"485b7312":"code","f5454982":"code","cf0d1d8b":"code","eb1c7534":"code","0e309097":"code","832264a0":"code","4aeba159":"code","1f4f2ae5":"code","90d9e826":"code","cf67580b":"code","1130906d":"code","b009c0d5":"code","83cefe6b":"code","55e4fb63":"code","32921cae":"code","80283a66":"code","404d5243":"code","0e555567":"code","76eb38c1":"code","2219f488":"code","1a904db8":"markdown","e37a66e4":"markdown","9c93745c":"markdown","a1b3c995":"markdown","5230ef32":"markdown","5299a66d":"markdown","29e921f9":"markdown"},"source":{"485b7312":"import math\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom cloud_tpu_client import Client\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n\nprint(f'Current Tensorflow Version: {tf.__version__}')\nClient().configure_tpu_version(tf.__version__, restart_type='ifNeeded')","f5454982":"# Code for connecting to TPU. If not connected then will run in CPU\/GPU Mode\n# However, the current notebook is hardcoded (at places) for running on GPU only\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","cf0d1d8b":"# Important variables that will be needed during the model training\nTRAINING_IMAGES = int(0.9 * 27000)\nVALIDATION_IMAGES = int(0.1 * 27000)\nAUTOTUNE = tf.data.AUTOTUNE\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nEPOCHS = 10\nFINAL_EPOCHS = 20\nIMAGE_HEIGHT = 64\nIMAGE_WIDTH = 64\nIMAGE_SHAPE = (64, 64, 3)\nNO_OF_CLASSES = 10\nTRAINING_STEPS_PER_EPOCH = TRAINING_IMAGES \/\/ BATCH_SIZE\n\nprint(f'# of Training Images: {TRAINING_IMAGES}')\nprint(f'# of Validation Images: {VALIDATION_IMAGES}')\nprint(f'# of Steps per Epoch during Training: {TRAINING_STEPS_PER_EPOCH}')","eb1c7534":"def decode_image(image):\n    '''\n    This will convert the encoded string to image\n    '''\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    return image\n\ndef read_tfrecord(example):\n    '''\n    Converts each record in the TFRecord file with the help \n    of the format specified in the tfds documentation\n    \n    Reference: https:\/\/www.tensorflow.org\/datasets\/catalog\/eurosat#eurosatrgb_default_config\n    '''\n    tfrecord_format = {\n        \"filename\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    label = tf.cast(example['label'], tf.int32)\n    return image, label\n\ndef get_dataset():\n    '''\n    Get the dataset pipeline from the TFRecord File\n    '''\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    dataset = tf.data.TFRecordDataset(filenames=f'{GCS_PATH}\/eurosat-train.tfrecord-00000-of-00001')\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(lambda x,y: (tf.reshape(x,shape=IMAGE_SHAPE), y), num_parallel_calls=AUTOTUNE)\n    return dataset\n\n# `data_augmentation` variable below is a Sequential model which is \n# used for applying transformation to input images.\n# Since these transformations belong to the experimental module,\n# they can not be applied on a TPU and are applied to input images on \n# CPU. In order to avoid CPU Bottleneck, the pipeline created in the\n# `get_data_pipeline` function uses prefetch which does this preprocessing\ndata_augmentation = tf.keras.Sequential([\n    preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomZoom((-0.2, 0)),\n    preprocessing.RandomContrast(0.2),\n])\n\ndef get_data_pipeline(dataset, training=True):\n    '''\n    Produces training and validation pipeline from the entire dataset\n    '''\n    if training:\n        dataset = dataset.map(lambda x,y : (tf.squeeze(data_augmentation(tf.expand_dims(x, axis=0)), axis=0), y), num_parallel_calls=AUTOTUNE)\n        dataset = dataset.repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    else:\n        dataset = dataset.batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\n    return dataset","0e309097":"# This part is currently hardcoded for the TPU version and will throw error\n# if TPU is not connected\nGCS_PATH = KaggleDatasets().get_gcs_path()\n!gsutil ls $GCS_PATH","832264a0":"# Creating dataset pipelines \ndataset = get_dataset()\ntrain_ds = get_data_pipeline(dataset.take(TRAINING_IMAGES))\nval_ds = get_data_pipeline(dataset.skip(TRAINING_IMAGES), training=False)","4aeba159":"# # Un-comment the code to see augmentation of images\n# for image, _ in train_ds.take(2):\n#     plt.figure(figsize=(10, 10))\n#     first_image = image[0]\n#     for i in range(9):\n#         ax = plt.subplot(3, 3, i + 1)\n#         augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n#         plt.imshow(augmented_image[0] \/ 255)\n#         plt.axis('off')","1f4f2ae5":"with strategy.scope():\n    # This will put the models graph on the various cores of the TPU\n    base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=IMAGE_SHAPE)\n    base_model.trainable = False","90d9e826":"def scheduler(epoch, lr):\n    '''\n    This is a custom schedular which decays the rate exponentially every\n    5 epochs.\n    '''\n    if epoch % 5 == 0 and epoch != 0:\n        print(f\"Learning rate updated to {lr * math.exp(-0.8)} on epoch {epoch}\")\n        return lr * math.exp(-0.8)\n    return lr\n\ndef get_classification_model():\n    '''\n    This will return classification model containing dropouts. The base_model\n    is running in inference mode indicated by the parameter `training=False`\n    \n    Dropout used for regularization effect only\n    '''\n    inputs = tf.keras.layers.Input(shape=IMAGE_SHAPE)\n    x = tf.keras.applications.resnet50.preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(128, activation='relu')(x)\n    outputs = Dense(NO_OF_CLASSES, activation='softmax')(x)\n    model = tf.keras.models.Model(inputs, outputs)\n    \n    return model","cf67580b":"with strategy.scope():\n    # The model has to be created within the scope so that the graph of the\n    # model is shared across the TPU cores\n    lr_schedular = tf.keras.callbacks.LearningRateScheduler(scheduler)\n    model = get_classification_model()\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['sparse_categorical_accuracy'])","1130906d":"model.summary()","b009c0d5":"history = model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=TRAINING_STEPS_PER_EPOCH, validation_data=val_ds, callbacks=[lr_schedular])","83cefe6b":"history.history.keys()","55e4fb63":"# \"Accuracy\"\nplt.plot(history.history['sparse_categorical_accuracy'])\nplt.plot(history.history['val_sparse_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","32921cae":"print(\"Number of layers in the base model: \", len(base_model.layers))","80283a66":"with strategy.scope():\n    base_model.trainable = False\n    # Fine-tune from this layer onwards\n    fine_tune_at = 93\n\n    # Freeze all the layers before the `fine_tune_at` layer\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable =  False\n    \n    # It's important to recompile your model after you make any changes\n    # to the `trainable` attribute of any inner layer, so that your changes\n    # are take into account\n    # Reference : https:\/\/www.tensorflow.org\/guide\/keras\/transfer_learning#fine-tuning\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['sparse_categorical_accuracy'])","404d5243":"history_fine_tune = model.fit(train_ds, initial_epoch=EPOCHS, epochs=FINAL_EPOCHS, steps_per_epoch=TRAINING_STEPS_PER_EPOCH, validation_data=val_ds, callbacks=[lr_schedular])","0e555567":"history_fine_tune.history.keys()","76eb38c1":"acc = history.history['sparse_categorical_accuracy']\nval_acc = history.history['val_sparse_categorical_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n\nacc += history_fine_tune.history['sparse_categorical_accuracy']\nval_acc += history_fine_tune.history['val_sparse_categorical_accuracy']\n\nloss += history_fine_tune.history['loss']\nval_loss += history_fine_tune.history['val_loss']","2219f488":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.plot([EPOCHS,EPOCHS],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.plot([EPOCHS,EPOCHS],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","1a904db8":"# Connect to TPU","e37a66e4":"# Creating Dataset","9c93745c":"# Introduction\n\nThe **Eurosat** dataset contains only 27000 images which were futher split into training and validation dataset. Hence Transfer learning and Data-Augmentation were used to improve the performance of the model.\n\n1. This notebook version uses **Resnet50** model pretrained on imagenet weights (without top). First the model is used as a feature extractor to train just the classification layer. Later, the first 93 layers are frozen and the remaining layers are fine-tuned along with the classification layer. This fine-tuning increased the accuracy by **2-3%**\n2. The Data Augmentor **flips, rotates, zooms and applies contrast** to the image before feeding them for training to the TPU. All these augmentation happens only for training pipeline","a1b3c995":"It could be observed from the above graphs that training loss is more than the Validation loss and Training Accuracy is less than Validation accuracy. Though this is counter-intuitive, the difference can be ascribed to the fact that we are using DropOut layer which runs in inference mode during validation.","5230ef32":"# Using Resnet50 for Feature Extraction","5299a66d":"# Building model and Distributing on TPU","29e921f9":"# Fine-Tuning Base model"}}