{"cell_type":{"9b1e840d":"code","626ad1db":"code","67a7cf36":"code","8bec1262":"code","f9866665":"code","da74993d":"code","fc2b9533":"code","12204eea":"code","c2dbd04f":"code","76ea16ad":"code","e52f9914":"markdown","c35e0afc":"markdown","deabff6f":"markdown"},"source":{"9b1e840d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport nltk # it is the one of most comman libraries for Natural Language Process\nimport re # Regular Expression library\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","626ad1db":"data = pd.read_csv(\"..\/input\/gender-classifier-DFE-791531.csv\", encoding=\"latin1\")\n\n# i will use only description column \ndata = pd.concat([data.gender, data.description], axis=1)\ndata.dropna(axis = 0, inplace = True) # we dropped the null rows","67a7cf36":"data.info()","8bec1262":"# genders have two options (male\/female). so i changed male to 0 and female to 1.\ndata.gender = [1 if gender == \"female\" else 0 for gender in data.gender]","f9866665":"description_list = [] # we created a list so we after these steps, we will append into this list\nfor description in data.description:\n    description = re.sub(\"[^a-zA-Z]\", \" \", description)\n    # sub method finds the given pattern ([^a-zA-Z] means, NOT letter like \":\") and changes them with \" \" (space)\n    description = description.lower()\n    # we need to have all letters lowercase (because A is not equall to a)\n    description = nltk.word_tokenize(description)\n    # we make a word list from our text\n    lemma = nltk.WordNetLemmatizer()\n    description = [lemma.lemmatize(word) for word in description]\n    # we found the roots of each words with lemma\n    description = \" \".join(description)\n    # after all these steps,we joined the words together and remake our text.\n    description_list.append(description)\n    # and append these texts into the list we created.","da74993d":"# now, we will implement \"bag of words\" method\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nmax_features = 5000 # we will take top 5000 feature \n\ncv = CountVectorizer(max_features=max_features, stop_words = \"english\")\n# in this method, we remove the stopwords (irrelevant words) in English language. (like \"of\", \"and\", \"the\" etc.)\n\nsparce_matrix = cv.fit_transform(description_list).toarray()\n\nprint(\"top used {} words: {}\".format(max_features, cv.get_feature_names()))","fc2b9533":"y = data.iloc[:, 0].values\nx = sparce_matrix","12204eea":"# train test split\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n","c2dbd04f":"# Random Forest Implementation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)\n\n# prediction\ny_pred = rf.predict(x_test)","76ea16ad":"accuracy = 100.0 * accuracy_score(y_test, y_pred)\nprint(\"Accuracy: \", accuracy)","e52f9914":"Here is how \"Bag of Words\" method works:\n\n![36nfa0trsbqcmt1w4xlsovoevja.png](attachment:36nfa0trsbqcmt1w4xlsovoevja.png)","c35e0afc":"This is my work for NLP. In this kernel, I am trying to implement some basics of Natural Language Process.","deabff6f":"These are the most comman words in description list."}}