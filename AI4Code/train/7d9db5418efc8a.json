{"cell_type":{"ef570197":"code","e10d8a9b":"code","72e6d224":"code","04d65692":"code","2cc51529":"code","52b257d3":"code","f4203b1e":"code","7d944dd7":"code","1d8f5c12":"code","cb1b6f73":"code","a0fe8a25":"code","8f0a1c16":"code","e9a4d02e":"code","06214366":"code","036c9927":"code","384b11b2":"code","702cf355":"code","f30d1566":"code","c44b91aa":"code","85ea4fcd":"code","893b37a6":"code","dd454f45":"code","8d23969a":"code","67330bc8":"code","3546cef0":"code","3637edeb":"code","7693781a":"code","28631f75":"code","fd802505":"code","c3b7cd7c":"code","e254b856":"code","18dba0e9":"code","64501d8d":"code","51628296":"code","51c14591":"code","d33ed00a":"code","95374f5b":"code","d4e47656":"code","484ee46f":"code","c07598d9":"code","1cb8da04":"code","05499541":"markdown","d3b87f35":"markdown","cf741b8b":"markdown","05c38603":"markdown","324350e4":"markdown"},"source":{"ef570197":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e10d8a9b":"#importing the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\nimport time\n%matplotlib inline","72e6d224":"# to see all the comands result in a single kernal \n%load_ext autoreload\n%autoreload 2\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","04d65692":"# to increase no. of rows and column visibility in outputs\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","2cc51529":"#reading data\ntrain=pd.read_csv(\"..\/input\/janatahack-crosssell-prediction\/train.csv\")\ntest=pd.read_csv(\"..\/input\/janatahack-crosssell-prediction\/test.csv\")\nsub=pd.read_csv('..\/input\/janatahack-crosssell-prediction\/sample_submission_iA3afxn.csv')\ntrain.shape\ntest.shape\nsub.shape","52b257d3":"train.head()","f4203b1e":"train.info()\ntest.info()","7d944dd7":"train.describe()\ntest.describe()","1d8f5c12":"sns.countplot(train['Response']);","cb1b6f73":"sns.countplot(train['Response'],hue=train['Previously_Insured']);","a0fe8a25":"sns.countplot(pd.concat([train['Previously_Insured'],test['Previously_Insured']],axis=0));","8f0a1c16":"sns.countplot(train['Response'],hue=train['Gender']);","e9a4d02e":"sns.countplot(pd.concat([train['Gender'],test['Gender']],axis=0));","06214366":"sns.countplot(train['Response'],hue=train['Driving_License']);","036c9927":"sns.countplot(pd.concat([train['Driving_License'],test['Driving_License']],axis=0));","384b11b2":"len(train[train['Driving_License']==0])\/len(train)","702cf355":"sns.countplot(train['Response'],hue=train['Vehicle_Damage']);","f30d1566":"sns.countplot(pd.concat([train['Vehicle_Damage'],test['Vehicle_Damage']],axis=0));","c44b91aa":"sns.countplot(train['Response'],hue=train['Vehicle_Age']);","85ea4fcd":"sns.countplot(pd.concat([train['Vehicle_Age'],test['Vehicle_Age']],axis=0));","893b37a6":"train['id'].nunique()\ntest['id'].nunique()","dd454f45":"sns.distplot(train['Annual_Premium']);","8d23969a":"#Data is left Skewed as we can see from above distplot\ntrain['Annual_Premium']=np.log1p(train['Annual_Premium'])\nsns.distplot(train['Annual_Premium']);","67330bc8":"test['Annual_Premium']=np.log1p(test['Annual_Premium'])\nsns.distplot(test['Annual_Premium']);","3546cef0":"# Missing Values\ntrain.isnull().sum().sum()\ntest.isnull().sum().sum()","3637edeb":"cat_cols=['Driving_License','Gender','Policy_Sales_Channel','Previously_Insured','Region_Code','Vehicle_Age','Vehicle_Damage']","7693781a":"#converting categorical features to numerical features\ntrain['Gender']=train['Gender'].replace({'Male':1,'Female':0})\ntrain['Vehicle_Damage']=train['Vehicle_Damage'].replace({'Yes':1,'No':0})\ntrain['Vehicle_Age']=train['Vehicle_Age'].replace({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})\ntest['Gender']=test['Gender'].replace({'Male':1,'Female':0})\ntest['Vehicle_Damage']=test['Vehicle_Damage'].replace({'Yes':1,'No':0})\ntest['Vehicle_Age']=test['Vehicle_Age'].replace({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})","28631f75":"test_id=test['id']","fd802505":"train=train.drop(columns=['id'],axis=1)\ntest=test.drop(columns=['id'],axis=1)\n#cat_cols=['Gender','Policy_Sales_Channel','Previously_Insured','Region_Code','Vehicle_Age','Vehicle_Damage']","c3b7cd7c":"train.info()\ntest.info()","e254b856":"#Checking correlation between features\nplt.figure(figsize=(10,10))\nsns.heatmap(train.corr(),annot=True);","18dba0e9":"#creating X and y for training\ny=train['Response']\nX=train.drop(columns='Response',axis=1)","64501d8d":"len(test)\/(len(test)+len(train))","51628296":"X_tr,X_te,y_tr,y_te=train_test_split(X,y,random_state=0,test_size=0.25,stratify=y,shuffle=True)","51c14591":"#lgbm stratified k-fold\n#%%time\nerr = [] \ny_pred_tot_lgbm = np.zeros((len(test), 2))\n\n\nfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\ni = 1\n\nfor train_index, test_index in fold.split(X, y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    m = LGBMClassifier(n_estimators=61,reg_alpha=2.1,reg_lambda=2,importance_type='gain')\n    m.fit(x_train, y_train,eval_set=[(x_val, y_val)], categorical_feature=cat_cols,eval_metric='auc',verbose=0)\n    pred_y = m.predict_proba(x_val)[:,1]\n    print(i, \" err_lgm: \", roc_auc_score(y_val,pred_y))\n    err.append(roc_auc_score(y_val,pred_y))\n    y_pred_tot_lgbm+= m.predict_proba(test)\n    i = i + 1\ny_pred_tot_lgbm=y_pred_tot_lgbm\/5\nsum(err)\/5\n","d33ed00a":"#XGBoost stratified k-fold\n#%%time\nerr = [] \ny_pred_tot_xgb = np.zeros((len(test), 2))\n\n\nfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=2020)\ni = 1\n\nfor train_index, test_index in fold.split(X, y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    m = XGBClassifier(n_estimators=114,reg_lambda=2,learning_rate=0.09,max_depth=7,min_child_weight=5)\n    m.fit(x_train, y_train,eval_set=[(x_val, y_val)],eval_metric='auc',verbose=0)\n    pred_y = m.predict_proba(x_val)[:,1]\n    print(i, \" err_xgb: \", roc_auc_score(y_val,pred_y))\n    err.append(roc_auc_score(y_val,pred_y))\n    y_pred_tot_xgb+= m.predict_proba(test)\n    i = i + 1\ny_pred_tot_xgb=y_pred_tot_xgb\/4\nsum(err)\/4","95374f5b":"# changing data type because cat_feature in catboost cannot be float\ntrain['Region_Code']=train['Region_Code'].astype(int)\ntest['Region_Code']=test['Region_Code'].astype(int)\ntrain['Policy_Sales_Channel']=train['Policy_Sales_Channel'].astype(int)\ntest['Policy_Sales_Channel']=test['Policy_Sales_Channel'].astype(int)","d4e47656":"train.info()\ncat_cols\n#creating X and y for training\ny=train['Response']\nX=train.drop(columns='Response',axis=1)\n#X_tr,X_te,y_tr,y_te=train_test_split(X,y,test_size=0.25,stratify=y,shuffle=True,random_state=150303)","484ee46f":"# CatBoost stratified k-fold\n#%%time\nerr = [] \ny_pred_tot_catb = np.zeros((len(test), 2))\n\n\nfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\ni = 1\n\nfor train_index, test_index in fold.split(X, y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    m = CatBoostClassifier(eval_metric='AUC')\n    m.fit(x_train, y_train,eval_set=[(x_val, y_val)],cat_features=cat_cols\n          ,plot=True,early_stopping_rounds=30,verbose=0)\n\n    pred_y = m.predict_proba(x_val)[:,1]\n    print(i, \" err_catb: \", roc_auc_score(y_val,pred_y))\n    err.append(roc_auc_score(y_val,pred_y))\n    y_pred_tot_catb+= m.predict_proba(test)\n    i = i + 1\ny_pred_tot_catb=y_pred_tot_catb\/5\nsum(err)\/5","c07598d9":"#weighted average of stratified xgboost and lgbm\ny_avg_xgb_lgb_kfold=y_pred_tot_lgbm[:,1]*0.61+y_pred_tot_xgb[:,1]*0.39\n# res=pd.concat([test_id,pd.DataFrame(y_avg_xgb_lgb_kfold,columns=['Response'])],axis=1)\n# res.to_csv('avg2_kfold.csv',index=False)","1cb8da04":"#weighted average of above result and catboost\navg3_kfold=y_avg_xgb_lgb_kfold*.59+y_pred_tot_catb[:,1]*0.41\nres=pd.concat([test_id,pd.DataFrame(avg3_kfold,columns=['Response'])],axis=1)\nres.to_csv('avg3_kfold.csv',index=False)","05499541":"I would love to get some suggestions as this is my first notebook.\nPlease comment and upvote if you like the notebook.","d3b87f35":"**Notebook for Jantahack cross-sell prediction (rank 12)**","cf741b8b":"Basic Visualization","05c38603":"Ensembling above three models","324350e4":"Pre-processing"}}