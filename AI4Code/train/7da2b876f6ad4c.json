{"cell_type":{"27831a24":"code","03e87f47":"code","5b9320ba":"code","04f780f2":"code","c4d94f3f":"code","94486587":"code","f45fe088":"markdown","8ccbc0e7":"markdown","feb70062":"markdown","3d43f5af":"markdown","632559a3":"markdown"},"source":{"27831a24":"#########################################                                \n#\n#         Anopheles Project\n#        Detecting malaria in blood cells images\n#       Done by Efi Eisenberg as a self-taught project\n#\n#    Everybody - It will be super cool if you find some way to make the network \n#   work better. Enjoy\n#\n####################################################################################\n\n\nimport torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport numpy as np\n\n## Loading the DATA\n\nGPU = True\nVALIDATION_SIZE = 0.1\nTRAIN_TEST_RATIO = 0.8\nSHUFFLE_DATA_SPLIT = True\nNUM_OF_EPOCH = 3\nLR = 0.002\nMOMENTUM = 0.9\nRANDOM_SEED = np.random.randint(0, 2000000000) # 1984 is our experiment seed\nprint(\"random seed\", RANDOM_SEED)\n\nROOT_DIR = \"..\/input\/cell_images\/cell_images\/\"","03e87f47":"## Preprocessing\n\ntransform = transforms.Compose([transforms.Resize((32, 32)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.1395, 0.2531, 0.3396], [1, 1, 1])])\n\ndataFrame_data = datasets.ImageFolder(root=ROOT_DIR,\n                                      transform=transform)\n\ndf_size = len(dataFrame_data)\nindices = list(range(df_size))\nval_split = int(np.floor(VALIDATION_SIZE*df_size))\ntest_split = df_size - int(np.floor((df_size-val_split)*TRAIN_TEST_RATIO))\n\nif SHUFFLE_DATA_SPLIT:\n    np.random.seed(RANDOM_SEED)\n    np.random.shuffle(indices)\n\nval_indices, test_indices, train_indices = indices[:val_split], indices[val_split:test_split], indices[test_split:]\n\n# Creating data samplers and loaders\n\ntrain_sampler = SubsetRandomSampler(train_indices)\ntest_sampler = SubsetRandomSampler(test_indices)  # SequentialSampler caused problems\nvalid_sampler = SubsetRandomSampler(val_indices)\n\n\ntrain_loader = torch.utils.data.DataLoader(dataFrame_data,\n                                           sampler=train_sampler,\n                                           batch_size=2,\n                                           num_workers=2)\n\ntest_loader = torch.utils.data.DataLoader(dataFrame_data,\n                                           sampler=test_sampler,\n                                           batch_size=2,\n                                           num_workers=2)\n\nval_loader = torch.utils.data.DataLoader(dataFrame_data,\n                                             sampler=valid_sampler,\n                                             batch_size=2,\n                                             num_workers=2)\n\n\nclasses = ('Parasitized', 'Uninfected')","5b9320ba":"## Defining the network\n\nclass ConvNet(nn.Module):\n\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(3, 9, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(9, 16, 3)\n        # an affine operation : y = Wx + b\n        self.fc1 = nn.Linear(16*6*6, 288)\n        self.fc2 = nn.Linear(288, 72)\n        self.fc3 = nn.Linear(72, 2)\n\n    def forward(self, x):\n        x = self.pool(F.elu(self.conv1(x)))\n        x = self.pool(F.elu(self.conv2(x)))\n        x = x.view(-1, 16*6*6)\n        x = F.elu(self.fc1(x))\n        x = F.elu(self.fc2(x))\n        x = self.fc3(x)\n\n        return x\n    \nnet = ConvNet()","04f780f2":"## Training the network\n\nprint(net)\nparam = list(net.parameters())\nprint(\"len of param: \", len(param))\n\ncriteria = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM)\n\nfor epoch in range(NUM_OF_EPOCH):\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        # get the input\n        inputs, labels = data\n\n        # zero the parameters\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criteria(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\nprint('Finished Training')","c4d94f3f":"## Testing\nprint(\"Testing\")\n\ncorrect = 0\ntotal = 0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        c = (predicted == labels).squeeze()\n        if labels.shape[0] == 1:  # Batch of size 1 causes problems\n            c = [c]\n        c_size = len(c)\n\n        for i in range(c_size):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nprint(\"Size of classes: \", class_total)\n\nprint('Accuracy of the network on %d test images: %d %%' % (len(test_loader),\n    100 * correct \/ total))\n\nfor i in range(2):\n    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] \/ class_total[i]))\n\n","94486587":"## Validation\nprint(\"\\nValidation:\")\n\ncorrect = 0\ntotal = 0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nwith torch.no_grad():\n    for data in val_loader:\n        images, labels = data\n        num_of_imgs = labels.shape[0]\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        c = (predicted == labels).squeeze()\n        if labels.shape[0] == 1:  # Batch of size 1 causes problems\n            c = [c]\n        c_size = len(c)\n\n        for i in range(c_size):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nprint(\"Size of classes: \", class_total)\n\nprint('Accuracy of the network on %d validation images: %d %%' % (len(val_loader), 100 * correct \/ total))\n\nfor i in range(2):\n    print('Accuracy of validation %5s : %2d %%' % (classes[i], 100 * class_correct[i] \/ class_total[i]))","f45fe088":"### This is a work in progress from [(github)](https:\/\/github.com\/Eizenborg\/MalariaInfectedBloodCells)","8ccbc0e7":"### Please leave comments and your scores for the validation","feb70062":"## Malaria Classification on Blood Cells images","3d43f5af":"Update : Fixed some bugs. Changed a bit the network to make it's accuracy less variable. Added in-groups accuracy","632559a3":"any error in the code is mine"}}