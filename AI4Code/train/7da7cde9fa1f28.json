{"cell_type":{"162466a0":"code","46d073a8":"code","f9ace356":"code","12010bb8":"code","713b31be":"code","6d5334a2":"code","f5103ec2":"code","93474ad4":"code","cdbbb315":"code","4bcec12f":"code","1594e37a":"markdown","d145f50c":"markdown","11305988":"markdown","2c16bddb":"markdown","cfee8670":"markdown","9ac0a7b3":"markdown"},"source":{"162466a0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npd.set_option('max_columns', 10, 'max_rows', 20)","46d073a8":"df_train = pd.read_csv('..\/input\/X_train.csv', encoding='cp949')\ndf_test = pd.read_csv('..\/input\/X_test.csv', encoding='cp949')\ndf = pd.concat([df_train, df_test])\ndf","f9ace356":"df_train.columns","12010bb8":"from sklearn.decomposition import PCA\n\ndef dummy_to_pca(tr, column_name:str, features) :\n    max_seq = 300\n    max_d = 15\n    col_count = tr.groupby(column_name)[column_name].count()\n    if len(col_count) > max_seq:\n        tops = col_count.sort_values(ascending=False)[0:max_seq].index\n        f =tr.loc[tr[column_name].isin(tops)][['cust_id', column_name]]\n    else:\n        tops = col_count.index\n        f =tr[['cust_id', column_name]]\n    f = pd.get_dummies(f, columns=[column_name])  # This method performs One-hot-encoding\n    f = f.groupby('cust_id').mean()\n    if len(tops) < max_d:\n        max_d = len(tops)\n    pca = PCA(n_components=max_d)\n    pca.fit(f)\n    cumsum = np.cumsum(pca.explained_variance_ratio_) #\ubd84\uc0b0\uc758 \uc124\uba85\ub7c9\uc744 \ub204\uc801\ud569\n    num_d = np.argmax(cumsum >= 0.99) + 1 # \ubd84\uc0b0\uc758 \uc124\uba85\ub7c9\uc774 99%\uc774\uc0c1 \ub418\ub294 \ucc28\uc6d0\uc758 \uc218\n    if num_d == 1:\n        num_d = max_d\n    pca = PCA(n_components=num_d)    \n    result = pca.fit_transform(f)\n    result = pd.DataFrame(result)\n    result.columns = [column_name + '_' + str(column) for column in result.columns]\n    result.index = f.index\n    return pd.concat([features, result], axis=1, join_axes=[features.index])","713b31be":"# Extract Numeric features\nf = df.groupby('cust_id').agg({\n    'amount': [('\ucd1d\uad6c\ub9e4\uc561', 'sum'),('\uad6c\ub9e4\uac74\uc218', 'size'),('\ud3c9\uade0\uad6c\ub9e4\uac00\uaca9', 'mean'),('\ucd5c\ub300\uad6c\ub9e4\uc561', 'max')],\n    'gds_grp_nm': [('\uad6c\ub9e4\uc0c1\ud488\ub2e4\uc591\uc131', lambda x: x.nunique()), \n               ('\uad6c\ub9e4\uc0c1\ud488\ub2e4\uc591\uc131\ube44', lambda x: x.nunique()\/x.count())],\n    'tran_date': [\n        ('\ub0b4\uc810\uc77c\uc218',lambda x: x.str[:10].nunique()),\n        ('\ub0b4\uc810\ube44\uc728',lambda x: x.str[:10].nunique()\/x.count()),\n        ('\uc8fc\ub9d0\ubc29\ubb38\ube44\uc728', lambda x: np.mean(pd.to_datetime(x).dt.dayofweek>4)),\n        ('\ubd04-\uad6c\ub9e4\ube44\uc728', lambda x: np.mean( pd.to_datetime(x).dt.month.isin([3,4,5]))),\n        ('\uc5ec\ub984-\uad6c\ub9e4\ube44\uc728', lambda x: np.mean( pd.to_datetime(x).dt.month.isin([6,7,8]))),\n        ('\uac00\uc744-\uad6c\ub9e4\ube44\uc728', lambda x: np.mean( pd.to_datetime(x).dt.month.isin([9,10,11]))),\n        ('\uaca8\uc6b8-\uad6c\ub9e4\ube44\uc728', lambda x: np.mean( pd.to_datetime(x).dt.month.isin([1,2,12])))\n    ],\n    }).reset_index()\n\n# Encode Categorical features\nf.columns = f.columns.get_level_values(1)\nf.rename(columns={'': 'cust_id'}, inplace=True)\nf = dummy_to_pca(df, 'goods_id', f)\nf = dummy_to_pca(df, 'gds_grp_nm', f)\nf = dummy_to_pca(df, 'gds_grp_mclas_nm', f)\nf = dummy_to_pca(df, 'store_nm', f)\ndf['month'] = pd.to_datetime(df['tran_date']).dt.month.astype(str)\nf = dummy_to_pca(df, 'month', f)\ndf['week'] = pd.to_datetime(df['tran_date']).dt.dayofweek.astype(str)\nf = dummy_to_pca(df, 'week', f)\nf","6d5334a2":"# Features extracted from derived features\nf['\ud3c9\uade0\ub0b4\uc810\uad6c\ub9e4\uc561'] = f['\ucd1d\uad6c\ub9e4\uc561']\/f['\ub0b4\uc810\uc77c\uc218']\nf['\uc8fc\uc911\ubc29\ubb38\ube44\uc728'] = 1 - f['\uc8fc\ub9d0\ubc29\ubb38\ube44\uc728']\nf['\uc8fc\ub9d0\ubc29\ubb38\uc218'] = (f['\uc8fc\ub9d0\ubc29\ubb38\ube44\uc728'] * f['\ub0b4\uc810\uc77c\uc218']).astype('int64')\nf['\uc8fc\uc911\ubc29\ubb38\uc218'] = (f['\uc8fc\uc911\ubc29\ubb38\ube44\uc728'] * f['\ub0b4\uc810\uc77c\uc218']).astype('int64')\nf['\ub0b4\uc810\ub2f9\ud3c9\uade0\uad6c\ub9e4\uac74\uc218'] = f['\uad6c\ub9e4\uac74\uc218']\/f['\ub0b4\uc810\uc77c\uc218']\nf['\uc8fc\uc911\uad6c\ub9e4\uc561'] = (f['\ucd1d\uad6c\ub9e4\uc561'] * f['\uc8fc\uc911\ubc29\ubb38\ube44\uc728']).astype('int64')\nf['\uc8fc\ub9d0\uad6c\ub9e4\uc561'] = (f['\ucd1d\uad6c\ub9e4\uc561'] * f['\uc8fc\ub9d0\ubc29\ubb38\ube44\uc728']).astype('int64')","f5103ec2":"# Split Data\nX_train = pd.DataFrame({'cust_id': df_train.cust_id.unique()})\nX_train = pd.merge(X_train, f, how='left')\ndisplay(X_train)\n\nX_test = pd.DataFrame({'cust_id': df_test.cust_id.unique()})\nX_test = pd.merge(X_test, f, how='left')\ndisplay(X_test)","93474ad4":"IDtest = X_test.cust_id;\nX_train.drop(['cust_id'], axis=1, inplace=True)\nX_test.drop(['cust_id'], axis=1, inplace=True)\ny_train = pd.read_csv('..\/input\/y_train.csv').gender","cdbbb315":"# Learn XGB\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport sys\nimport warnings\nif not sys.warnoptions: warnings.simplefilter(\"ignore\")\n\n# clf = XGBClassifier()\n# parameters = {\n#     'max_depth': [4],\n#     'subsample': [0.9],\n#     'colsample_bytree': [1.0],\n#     'learning_rate' : [0.05],\n#     'min_child_weight': [5],\n#     'silent': [True],\n#     'n_estimators': [200]\n# }\n# clf = GridSearchCV(clf, parameters, n_jobs=1, cv=2)\n# clf.fit(X_train, y_train)\n# best_est = clf.best_estimator_\n# print(best_est)\n\nparameters = {'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 1.0, 'learning_rate': 0.05, \n              'min_child_weight': 5, 'silent': True, 'n_estimators': 200}\nmodel = XGBClassifier(**parameters, random_state=0, n_jobs=-1)\nscore = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n\nprint('{}\\nmean = {:.5f}\\nstd = {:.5f}'.format(score, score.mean(), score.std()))","4bcec12f":"pred = model.fit(X_train, y_train).predict_proba(X_test)[:,1]\nfname = 'submission.csv'\nsubmissions = pd.concat([IDtest, pd.Series(pred, name=\"gender\")] ,axis=1)\nsubmissions.to_csv(fname, index=False)\nprint(\"'{}' is ready to submit.\" .format(fname))","1594e37a":"### Imports","d145f50c":"### Extract features","11305988":"### Encoding categorical features with PCA","2c16bddb":"### Make submissions","cfee8670":"### Read data","9ac0a7b3":"### Build models"}}