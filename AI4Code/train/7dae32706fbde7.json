{"cell_type":{"ff4c25f2":"code","99c3957e":"code","f8dae61c":"code","54a4018b":"code","cf6efaec":"code","70977336":"code","c8660d16":"code","95f6f46d":"code","4466bfd2":"code","42e4d944":"code","0adfe9a3":"code","bf85c265":"code","cd7bba59":"code","d5df9f5f":"code","dbb3d369":"code","73702ad9":"code","42680a4b":"markdown","895a958d":"markdown"},"source":{"ff4c25f2":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","99c3957e":"frames = list()\nresults = pd.read_csv(\"..\/input\/train.csv\")\nfor i in range(1,19):\n    exp = '0' + str(i) if i < 10 else str(i)\n    frame = pd.read_csv(\"..\/input\/experiment_{}.csv\".format(exp))\n    row = results[results['No'] == i]\n    frame['target'] = 1 if row.iloc[0]['tool_condition'] == 'worn' else 0\n    frames.append(frame)\ndf = pd.concat(frames, ignore_index = True)\ndf.head()","f8dae61c":"df.info()","54a4018b":"df_correlation=df.corr()\ndf_correlation.dropna(thresh=1,inplace=True)\ndf_correlation.drop(columns=['Z1_CurrentFeedback','Z1_DCBusVoltage','Z1_OutputCurrent','Z1_OutputVoltage','S1_SystemInertia','target'],inplace=True)\nplt.figure(figsize=(20,20))\nsns.heatmap(df_correlation)\n\n","cf6efaec":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics\n\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nimport gc # for deleting unused variables\n%matplotlib inline\n\n#Creating Test Train Splits\nx=df.drop(columns=['target','Machining_Process'],axis=1)\ny=np.array(df['target'])\nX_train,X_test,y_train,y_test =train_test_split(x,y,train_size=0.8,random_state=100)\n","70977336":"%%time\n#XgBoost\n\nxgb_model=XGBClassifier()\nxgb_model.fit(X_train,y_train)","c8660d16":"# make predictions for test data\n# use predict_proba since we need probabilities to compute auc\ny_pred = xgb_model.predict(X_test)\ny_pred[:10]","95f6f46d":"print(\"Trained on {0} observations and scoring with {1} test samples.\".format(len(X_train), len(X_test)))","4466bfd2":"# roc_auc\n#y_pred=y_pred.round()\nauc = roc_auc_score(y_test, y_pred)\nauc","42e4d944":"from sklearn.metrics import confusion_matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\ncnf_matrix","0adfe9a3":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr, tpr)\nroc_auc\n","bf85c265":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(6, 4))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return fpr, tpr, thresholds","cd7bba59":"draw_roc(y_test,y_pred)","d5df9f5f":"# Error terms\n#Actual vs Predicted\n#c = [i for i in range(1,(len(y_test)+1),1)]\ncount_points=70\nc = [i for i in range(1,count_points+1,1)]\nfig = plt.figure()\nplt.plot(c,y_test[:count_points], color=\"blue\", linewidth=2.5, linestyle=\"-\")#Actual Plot in blue\nplt.plot(c,y_pred[:count_points], color=\"red\",  linewidth=2.5, linestyle=\"--\")#predicted Plot in red\nfig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                               # X-label\nplt.ylabel('Worn_status', fontsize=16)     \n","dbb3d369":"# plot\nplt.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\nplt.show()","73702ad9":"# Feature importances\nfeatures = [(df.columns[i], v) for i,v in enumerate(xgb_model.feature_importances_)]\nfeatures.sort(key=lambda x: x[1], reverse = True)\nfor item in features[:10]:\n    print(\"{0}: {1:0.4f}\".format(item[0], item[1]))","42680a4b":"## Checking the Correlation","895a958d":"## From above we can observe that there is extreme Positive and Negative Correlation between certain attributes"}}