{"cell_type":{"784028a5":"code","a047a854":"code","94a35a46":"code","393fa220":"code","7d1e53ab":"code","11e2f143":"code","8b0158a2":"code","7c579363":"code","464f284d":"code","74c53898":"code","aec78725":"code","24c5a14d":"code","983300eb":"code","441674ff":"code","ae39ecbb":"code","69cd4f33":"code","2b1dff63":"code","c7fca3b5":"code","63dfd9ec":"code","bfd6e2a8":"code","e318b7c9":"code","83630b3c":"markdown","0eddde12":"markdown","625d6220":"markdown","144ae058":"markdown","5d7fdbf9":"markdown","fbc230a1":"markdown","f3f404b9":"markdown","7840f05d":"markdown","cfa1fd92":"markdown","06ec51fd":"markdown","6a04bdb1":"markdown","5187e138":"markdown","b2be9621":"markdown","1f47b56f":"markdown"},"source":{"784028a5":"import numpy as np \nimport pandas as pd \nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf \nfrom keras.utils import to_categorical\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","a047a854":"##### Plotting\ndef Plotting_NeuralNet (data):\n    fig, ax = plt.subplots(1,2 , figsize = (20,7))\n    # summarize history for accuracy\n    ax[0].plot(data.history['accuracy'])\n    ax[0].plot(data.history['val_accuracy'])\n    ax[0].set_title('model accuracy')\n    ax[0].legend(['train', 'test'], loc='upper left')\n\n    # summarize history for loss\n    ax[1].plot(data.history['loss'], label =['loss'])\n    ax[1].plot(data.history['val_loss'] ,label =['val_loss'])\n    ax[1].set_title('model loss')\n    ax[1].legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n#### Visualization\ndef get_label_rotation(angle, offset):\n    # Rotation must be specified in degrees :(\n    rotation = np.rad2deg(angle + offset)\n    if angle <= np.pi:\n        alignment = \"right\"\n        rotation = rotation + 180\n    else: \n        alignment = \"left\"\n    return rotation, alignment\n\ndef add_labels(angles, values, labels, offset, ax):\n    \n    # This is the space between the end of the bar and the label\n    padding = 4\n    \n    # Iterate over angles, values, and labels, to add all of them.\n    for angle, value, label, in zip(angles, values, labels):\n        angle = angle\n        \n        # Obtain text rotation and alignment\n        rotation, alignment = get_label_rotation(angle, offset)\n\n        # And finally add the text\n        ax.text(x=angle, y=value + padding, \n            s=label, ha=alignment, va=\"center\", \n            rotation=rotation, rotation_mode=\"anchor\")","94a35a46":"# Getting Data <----------\npath = '..\/input\/tmnist-alphabet-94-characters\/94_character_TMNIST.csv'\ndf = pd.read_csv(path)\ndf.sample()","393fa220":"# All labels\nall_ = list(df['labels'].unique())\n\n# Regex Pattern\npattern_uc = re.compile(r\"[A-Z]\")\npattern_lc = re.compile(r\"[a-z]\")\npattern_numbers = re.compile(r\"[0-9]\")\npattern_symbols = re.compile(r\"[\\W]|[\\_\\,]\")\n\n# Extracting Pattern\nlower_case = pattern_lc.findall(str(all_))\nUpper_case = pattern_uc.findall(str(all_))\nNumbers_ = pattern_numbers.findall(str(all_))\nSymbols_ = list(set(pattern_symbols.findall(str(all_))))\nSymbols_.pop(27)\n\n# Creating Gropus\ngroup = 1\nfor list_ in (lower_case,Upper_case,Numbers_,Symbols_):\n    df.loc[df['labels'].isin(list_), 'group'] = str(group)\n    group += 1\n","7d1e53ab":"VALUES = df.groupby(['labels']).sum().reset_index()\nVALUES = (VALUES.iloc[:,1:-1].sum(axis=1))*0.000001\nIMAGES_ = (df.groupby(['labels']).count()['names'].values)*0.025\nLABELS = df.groupby(['labels','group']).count().reset_index().sort_values('group')['labels'].values\nGROUP = df.groupby(['labels','group']).count().reset_index().sort_values('group')['group'].values\nGROUPS_SIZE = [26, 26, 10, 32]","11e2f143":"# Add three empty bars to the end of each group\nPAD = 3\nANGLES_N = len(VALUES) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) \/ len(ANGLES)\n\noffset = 0\nOFFSET = np.pi \/ 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n\nfig, ax = plt.subplots(1,2,figsize=(20, 10), subplot_kw={\"projection\": \"polar\"})\nax[0].set_theta_offset(OFFSET)\nax[0].set_ylim(-100, 100)\nax[0].set_frame_on(False)\nax[0].xaxis.grid(False)\nax[0].yaxis.grid(False)\nax[0].set_xticks([])\nax[0].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[0].bar(\n    ANGLES[IDXS], VALUES, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], VALUES, LABELS, OFFSET, ax[0])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[0].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[0].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[0].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n    \n# -------------------------------------\nPAD = 3\nANGLES_N = len(IMAGES_) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) \/ len(ANGLES)\n\noffset = 0\nOFFSET = np.pi \/ 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n    \nax[1].set_theta_offset(OFFSET)\nax[1].set_ylim(-100, 100)\nax[1].set_frame_on(False)\nax[1].xaxis.grid(False)\nax[1].yaxis.grid(False)\nax[1].set_xticks([])\nax[1].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[1].bar(\n    ANGLES[IDXS], IMAGES_, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], IMAGES_, LABELS, OFFSET, ax[1])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[1].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[1].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[1].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n ","8b0158a2":"X = df.iloc[:, 2:-1].astype('float32') # Splitting and turning into Float\ny  = df[['labels']] #Extracting Labels","7c579363":"labels = y['labels'].unique()\nvalues = [num for num in range(len(df['labels'].unique()))]\nlabel_dict= dict(zip(labels,values)) #Creating Dictionary \nlabel_dict_inv = dict(zip(values,labels))\n\nprint(sorted(label_dict.items(), key=lambda x:x[1])[35:45])  #For visualization Purpose","464f284d":"# Transforming\ny['labels'].replace(label_dict, inplace=True) #Maping Values\ny.tail(5)","74c53898":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","aec78725":"Length, Height = 28,28  # <---- Defining LxH \nNCl = y_train.nunique()[0] # Unique targets -- > 94 \n\n# ------>  N of images 28x28\nX_train = np.reshape(X_train.values, (X_train.shape[0] ,Length, Height)) \nX_test = np.reshape(X_test.values, (X_test.shape[0] ,Length, Height))\n\n# -------> Target into Categorical Values\ny_train = to_categorical(y_train, NCl, dtype='int' )\ny_test = to_categorical(y_test, NCl, dtype='int' )\n\nprint(f'X:Train, Test data shape:{X_train.shape},{X_test.shape}')\nprint(f'Y:Train, Test data shape:{y_train.shape},{y_test.shape}')","24c5a14d":"random = shuffle(X_train[:500]) #Randomly shuffle (array  in a consistent way)\nfig,ax = plt.subplots(3,4 , figsize = (10,10)) \naxes = ax.flatten()\n\nfor i in range(12):\n    _,shu = cv2.threshold(random[i], 30, 200, cv2.THRESH_BINARY)\n    axes[i].imshow(np.reshape(random[i], (Length, Height)), cmap = 'Greys')\nplt.show()","983300eb":"from tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping","441674ff":"from IPython.display import display\nfrom PIL import Image\npath=('..\/input\/convo-image\/Convo.png')\ndisplay(Image.open(path))","ae39ecbb":"RGB = 1  # In this case only one instead of 3 because we dont have Color images\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2], RGB)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],RGB)\n\n\nX_train = X_train\/255\nX_test = X_test\/255\nprint(f'Train, Test shapes: {X_train.shape},{X_test.shape}')","69cd4f33":"model = Sequential ()\n\n# Conv -> Maxpool - Dropout [1st - 4rd] ~ Flatten - >  Dense - Dense - output \nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3),input_shape = (Length, Height, RGB), padding = 'same',))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(350))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(NCl, activation = 'softmax'))\n# model.summary()","2b1dff63":"optimizer  = Adam(learning_rate=0.01)\ncallback =EarlyStopping(monitor='loss', patience=5)\nBatch_ = 64\nEpochs_ = 50\n\n#Training -------------- >\nmodel.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\nhistory= model.fit(X_train,y_train, validation_data = (X_test,y_test),batch_size = Batch_ ,\n                   epochs = Epochs_, verbose = 0)\n\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Loss:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)","c7fca3b5":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","63dfd9ec":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1)","bfd6e2a8":"Batch_ = 62\nhistory= model.fit_generator(datagen.flow(X_train,y_train,batch_size = Batch_), \n                             validation_data = (X_test,y_test), epochs = Epochs_,callbacks=[callback], verbose = 0)\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Test Score:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)","e318b7c9":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","83630b3c":"# Building Deep Learning FrameWork\n\n- This is a representation of the Architecture that Iw as using \nStarted with 32 Conv - > Apply some Batch Normalization -> ReLu Transformation X 3 - > Flatten - Dense Layer \n*** My apology*** , the visualization wasnt that good, in my defense I can say I was in my way to my job when I posted this \"Code\".","0eddde12":"### Making Predictions","625d6220":"# Libraries and Fuctions","144ae058":"### Reshaping and Displaying some Images","5d7fdbf9":"## Making Prediction","fbc230a1":"# Creating Training and Test Sets","f3f404b9":"## Second Convolutional Architecture + Data Augmentation","7840f05d":"# Spliting Labels & Images ","cfa1fd92":"# Loading Data","06ec51fd":"#### Thank You very much for passing and check this out \n- This is my very first Convolutional Neural Network\n- In here you will find some amazing charts such as ***Circular Bar Chart**\n- Some technique that I learn - such as *** apply Batch Normalizarion before Passing into Fuction\/transformation ***\n\n### Interesting fact\n- I am surprised that the model didnt improve after applied Image Augmentation *** Maybe I was not doing properly***  please let your comment \/ or any feedback below \n- This is a Very common architecture but it was very porwerfull, Eventually i will use transfer learning with Google models to compare or learn how to improve this model \n","6a04bdb1":"## First Convolutional Architecture","5187e138":"# Transfer Learning and More......","b2be9621":"### Reshaping for CNN","1f47b56f":"## Visualization\n\n- The following Visualization is known as ***Circular bar chart*** each group A,B,C,D represent the different types of data, ***Numbers, Symbols, Letters, etc***\n- The ***Left circular*** bar chart represents the number of pixels in each image - the represeantion might not be that accuracte because I had to scale and the visualization is for practicing purpose only.\n- The  ***Rigth circular*** bar chart represents the number of imaes or distribution.\n- ***Observation*** The data is well Distributed, each class has equal number of images as you can see in the Circular chart bar "}}