{"cell_type":{"a1f2a7f5":"code","6905e11c":"code","bd4cfc73":"code","d92c682e":"code","70dd20de":"code","f8f4bc39":"code","78b1c95a":"code","d5ec8820":"code","39bf1dd5":"code","de021074":"code","b7039dbe":"code","27ccedfc":"code","f1819fb3":"code","ec03ca38":"code","8d49ee01":"code","7201c011":"markdown","6adbf412":"markdown","86f052df":"markdown","b35112f0":"markdown","1a492778":"markdown","47121f14":"markdown","d0bdb4cc":"markdown","07673f60":"markdown","6bbe745b":"markdown","531203d9":"markdown","5f06d39c":"markdown","33a95a24":"markdown","8a1c0cad":"markdown","c5201dcb":"markdown","75a3b485":"markdown"},"source":{"a1f2a7f5":"import torch\nimport numpy as np\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\n\n# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","6905e11c":"from torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 32\n# percentage of training set to use as validation\nvalid_size = 0.2\n\n# convert data to a normalized torch.FloatTensor\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])","bd4cfc73":"data_dir='..\/input\/waste-classification-data\/DATASET'\ntrain_data = datasets.ImageFolder(data_dir + '\/TRAIN', transform=train_transforms)\ntest_data = datasets.ImageFolder(data_dir + '\/TEST', transform=test_transforms)","d92c682e":"num_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n    num_workers=num_workers)","70dd20de":"print(len(train_loader))","f8f4bc39":"#defining classes\n\nclasses=['O','R']","78b1c95a":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# helper function to un-normalize and display an image\ndef imshow(img):\n    img = img \/ 2 + 0.5  # unnormalize\n    plt.imshow(np.transpose(img, (1, 2, 0))) ","d5ec8820":"# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(classes[labels[idx]])","39bf1dd5":"batch = next(iter(train_loader))\nprint(batch[0].shape)\nplt.imshow(batch[0][0].permute(1, 2, 0))\nprint(batch[1][0])","de021074":"model = models.densenet121(pretrained=True)\nmodel","b7039dbe":"# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.densenet121(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.classifier = nn.Sequential(nn.Linear(1024, 256),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(256, 2),\n                                 nn.LogSoftmax(dim=1))\n\ncriterion = nn.NLLLoss()\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n\nmodel.to(device);","27ccedfc":"# number of epochs to train the model\nn_epochs = 20\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_waste.pt')\n        valid_loss_min = valid_loss","f1819fb3":"model.load_state_dict(torch.load('model_waste.pt'))","ec03ca38":"# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nmodel.eval()\n# iterate over test data\nfor data, target in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(2):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","8d49ee01":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimages.numpy()\n\n# move model inputs to cuda, if GPU available\nif train_on_gpu:\n    images = images.cuda()\n\n# get sample outputs\noutput = model(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    imshow(images.cpu()[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","7201c011":"The model has 91% accuracy for Recyclable waste. But, a whopping 98% accuracy for organic waste.","6adbf412":"# Testing the model","86f052df":"## Step 2: Data Augmentation\n\nData Augmentation is basically cropping, resizing, flipping the image data to get more accurate results. This can be done in PyTorch using **transforms** . Also, Normalization helps get data within a range and reduces the skewness which helps learn faster and better. Normalization is done in PyTorch by **transforms.Normalize** wherein two tuples are passed, one tuple has mean for all the three RGB channels followed by the second tuple having standard deviation for all three channels. Data Augmentation is mostly done in training data as it is important to have more accuracy in training so that eventually test accuracy is better. This also increases the amount of training images. Hence, multiple augmentations can be applied on train samples.","b35112f0":"Training the model for desired number of epochs and keeping track of train loss and validation loss. If the validation loss decreases, the model is saved.The simplest thing to do is simply save the state dict with `torch.save`.","1a492778":"The DataLoader takes a dataset (such as you would get from ImageFolder) and returns batches of images and the corresponding labels. You can set various parameters like the batch size and if the data is shuffled after each epoch.","47121f14":"In deep learning, often the training set is split into train samples and validation samples to cross check accuracies. This is done using **SubsetRandomSampler**.","d0bdb4cc":"# Training the Model","07673f60":"Loading the directories and training, testing data.","6bbe745b":"## Step 1: Importing libraries and check if CUDA is available.","531203d9":"# Visualizing the Results","5f06d39c":"## Densenet architecture\n![image.png](attachment:image.png)\n\nImg source:https:\/\/pytorch.org\/hub\/pytorch_vision_densenet\/\n\nDense Convolutional Network (DenseNet), connects each layer to every other layer in a feed-forward fashion. The 1-crop error rates on the imagenet dataset with the pretrained model are 25.35 for top-1 error and 7.83 for top-5 error.","33a95a24":"# Introduction\n\n\nWaste disposal is often a concern for various reasons including eutrophication, toxic waste consumption by animals and land, air or water pollution. Segregating the waste into organic waste and recyclable waste is a good practice to follow. But, manually performing the task is very cumbersome. Hence, the [dataset](https:\/\/www.kaggle.com\/techsash\/waste-classification-data) suggests the use of ML to automate the classification process.\n\n# PyTorch Basics\n\nPyTorch is very popular because of its ease of use and applications in numerous fields of machine learning. In simple terms, PyTorch is basically a python framework that allows tensor computation with strong GPU acceleration for constructing deep neural networks. It provides flexibility and stability for deep learning.","8a1c0cad":"Loading the last saved model for testing.","c5201dcb":"# Transfer Learning\n\nTransfer Learning refers to the process of using already existing pre-trained models for other applications by tweaking the last few layers and using it to classify our desired classes.\nOnce trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our organic and recyclable waste photos with near perfect accuracy.\n\nWith `torchvision.models` these pre-trained networks can be downloaded and used in applications.\n\nHere, the DenseNet121 is used. DenseNet is a very powerful model with 121 layers.\nFor more information about densenet, [Click Here](https:\/\/www.kaggle.com\/pytorch\/densenet121).","75a3b485":"Plotting the images to understand the data. \nO= Organic Waste\nR= Recyclable Waste"}}