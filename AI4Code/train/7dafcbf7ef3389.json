{"cell_type":{"d181f982":"code","4467f865":"code","c4ed2369":"code","7d1458c5":"code","e040ced8":"code","a077d97a":"code","47ce9082":"code","6a7bb42b":"code","1392e87f":"code","b08de6a8":"code","92100f8d":"code","72b407e9":"code","e707d43e":"code","2a8f00fd":"code","9f0bfdec":"code","9df511d2":"code","205502e6":"code","2b47c75d":"markdown","201c4d19":"markdown","3b676fdc":"markdown","779ed73c":"markdown","d6fc5b25":"markdown"},"source":{"d181f982":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4467f865":"import cv2 \nfrom keras.models import Sequential #model\nfrom keras.layers import MaxPool2D, Dense, Flatten, Conv2D, Dropout #layer\nfrom tensorflow.keras.optimizers import Adam, SGD  #optimizer\nfrom tensorflow.keras.utils import to_categorical #utilities\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle","c4ed2369":"df = pd.read_csv('..\/input\/az-handwritten-data\/A_Z Handwritten Data.csv').astype('float32')\ndf.head()","7d1458c5":"x = df.drop('0', axis =1) #features\ny = df['0'] #labels","e040ced8":"#train test split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n\n#reshaping data\nx_train = np.reshape(x_train.values , (x_train.shape[0], 28, 28))\nx_test = np.reshape(x_test.values, (x_test.shape[0], 28, 28)) ","a077d97a":"print('train data shape : ', x_train.shape)\nprint('test data shape : ', x_test.shape)","47ce9082":"word_dict = {0 : 'A', 1 : 'B', 2 : 'C', 3 : 'D',4: 'E',5:'F',6: 'G',7: 'H',8: 'I',9: 'J',\n             10 : 'K',11: 'L',12: 'M',13: 'N',14: 'O',15: 'P',16: 'Q',\n             17: 'R',18 : 'S',19: 'T',20: 'U',21: 'V',22: 'W',23: 'X',24:'Y' ,25:'Z'}\nfor i in word_dict:\n    print(i, word_dict[i]) #values ","6a7bb42b":"#converting labels into integer\ny = np.int0(y)\ncount = np.zeros(26, dtype = 'int')\n#appending count to y\nfor i in y:\n    count[i] = count[i] + 1     \ncount","1392e87f":"alphabets = []\nfor i in word_dict.values():\n    alphabets.append(i)\nalphabets #it contains all the values of the dictionary","b08de6a8":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize= (11, 11))\nsns.barplot(y = alphabets, x = count, palette = 'cool_r')\nplt.xlabel('Count')\nplt.ylabel('Alphabets')\nplt.show()","92100f8d":"#shuffling\nshuffle_ = shuffle(x_train[:100]) #this shuffling is for random images\n\nfig, ax = plt.subplots(3, 3, figsize = (11,11)) \naxes = ax.flatten()\n\n\nfor i in range(9): #looping\n    _, shu = cv2.threshold(shuffle_[i], 30, 200, cv2.THRESH_BINARY) #setting threshold\n    axes[i].imshow(np.reshape((shuffle_[i]),(28, 28)), cmap = 'Greys') \nplt.show()","72b407e9":"#reshaping data for train and test for model input\n\nx_train  = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n#x train reshapping\nx_test  = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n\n#reshapping labels\ny_train = to_categorical(y_train, num_classes = 26, dtype = 'int') \ny_test = to_categorical(y_test, num_classes = 26, dtype = 'int') \n\n\nprint('new shape of x train: ',x_train.shape)\nprint(' new shape of x test shape: ', x_test.shape)\nprint('new shape for y train : ', y_train.shape)\nprint('new shape for y test: ', y_test.shape)","e707d43e":"#Model Creation\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = (28, 28, 1))) #convolutional\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2)) #pooling\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation = 'relu')) #dense layer\nmodel.add(Dense(128, activation = 'relu'))\n\nmodel.add(Dense(26, activation = 'softmax'))","2a8f00fd":"model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_fit = model.fit(x_train, y_train, epochs = 1, validation_data = (x_test, y_test))\nmodel.summary()","9f0bfdec":"#saving the model\nmodel.save(r'model_hand.h5')","9df511d2":"model_fit.history #this displays train and validation accuracies and losses.","205502e6":"#prediction on test\nfig, axes = plt.subplots(3, 3, figsize = (10, 10))\naxes = axes.flatten()\n\nfor i, ax in enumerate(axes):\n    image = np.reshape(x_test[i], (28, 28))\n    ax.imshow(image, cmap = 'Greys')\n    \n    pred = word_dict[np.argmax(y_test[i])]\n    ax.set_title('Prediciton : ' +pred)","2b47c75d":"**splitting data** ","201c4d19":"**this shows the greyscale images**","3b676fdc":"**we can see that the predictions are very accurate**","779ed73c":"### Text Recognition using tensorflow on A-Z Handwritten alphabets dataset","d6fc5b25":"**importing libraries**"}}