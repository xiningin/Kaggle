{"cell_type":{"84fd9504":"code","5b6410fe":"code","9eba38e7":"code","f6c994cd":"code","691dd4e9":"code","4ceb918b":"code","1db7cab0":"code","72287246":"code","12888b22":"code","67d5131d":"markdown","3a3b356d":"markdown","05885b6c":"markdown","06f07cb2":"markdown","c0464a9b":"markdown","75e3ca70":"markdown","68772a15":"markdown"},"source":{"84fd9504":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b6410fe":"import pickle\noriginal = \"\/kaggle\/input\/urani1\/final_project_dataset.pkl\"\ndestination = \"final_dataset.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))","9eba38e7":"enron = pickle.load(open(\"final_dataset.pkl\", \"rb\"))\nenron.pop('TOTAL') #dictionary","f6c994cd":"\ndef featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n    return_list = []\n    if isinstance(sort_keys, str):\n        import pickle\n        keys = pickle.load(open(sort_keys, \"rb\"))\n    elif sort_keys:\n        keys = sorted(dictionary.keys())\n    else:\n        keys = dictionary.keys()\n\n    for key in keys:\n        tmp_list = []\n        for feature in features:\n            try:\n                dictionary[key][feature]\n            except KeyError:\n                print (\"error: key \", feature, \" not present\")\n                return\n            value = dictionary[key][feature]\n            if value==\"NaN\" and remove_NaN:\n                value = 0\n            tmp_list.append( float(value) )\n\n        # Logic for deciding whether or not to add the data point.\n        append = True\n        # exclude 'poi' class as criteria.\n        if features[0] == 'poi':\n            test_list = tmp_list[1:]\n        else:\n            test_list = tmp_list\n        ### if all features are zero and you want to remove\n        ### data points that are all zero, do that here\n        if remove_all_zeroes:\n            append = False\n            for item in test_list:\n                if item != 0 and item != \"NaN\":\n                    append = True\n                    break\n        ### if any features for a given data point are zero\n        ### and you want to remove data points with any zeroes,\n        ### handle that here\n        if remove_any_zeroes:\n            if 0 in test_list or \"NaN\" in test_list:\n                append = False\n        ### Append the data point if flagged for addition.\n        if append:\n            return_list.append( np.array(tmp_list) )\n\n    return np.array(return_list)","691dd4e9":"def targetFeatureSplit( data ):\n    target = []\n    features = []\n    for item in data:\n        target.append( item[0] )\n        features.append( item[1:] )\n\n    return target, features","4ceb918b":"import os\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfig,a=plt.subplots(3,2,squeeze=False,figsize=(15,10))\nff1=featureFormat(enron,[\"poi\",\"salary\",\"deferral_payments\"])\nfor y in range(len(ff1)):\n    if ff1[y][0]==True:\n        a[0][0].scatter(ff1[y][1],ff1[y][2],color='r')\n    else:\n        a[0][0].scatter(ff1[y][1],ff1[y][2],color='g')\nff2=featureFormat(enron,[\"poi\",\"total_payments\",\"loan_advances\"])\nfor z in range(len(ff2)):\n    if ff2[z][0]==True:\n        a[0][1].scatter(ff2[z][1],ff2[z][2],color='r')\n    else:\n        a[0][1].scatter(ff2[z][1],ff2[z][2],color='g')\nff3=featureFormat(enron,[\"poi\",\"total_stock_value\",\"exercised_stock_options\"])\nfor z in range(len(ff3)):\n    if ff3[z][0]==True:\n        a[1][0].scatter(ff3[z][1],ff3[z][2],color='r')\n    else:\n        a[1][0].scatter(ff3[z][1],ff3[z][2],color='g')\nff4=featureFormat(enron,[\"poi\",\"salary\",\"loan_advances\",\"deferral_payments\"])\nfor z in range(len(ff4)):\n    if ff4[z][0]==True:\n        a[1][1].scatter(ff4[z][1],ff4[z][2],color='r')\n    else:\n        a[1][1].scatter(ff4[z][1],ff4[z][2],color='g')\nff5=featureFormat(enron,[\"poi\",\"total_stock_value\",\"restricted_stock\"])\nfor z in range(len(ff5)):\n    if ff5[z][0]==True:\n        a[2][0].scatter(ff5[z][1],ff5[z][2],color='r')\n    else:\n        a[2][0].scatter(ff5[z][1],ff5[z][2],color='g')     \n        \nff6=featureFormat(enron,[\"poi\",\"exercised_stock_options\",\"restricted_stock\"])\nfor z in range(len(ff6)):\n    if ff6[z][0]==True:\n        a[2][1].scatter(ff6[z][1],ff6[z][2],color='r')\n    else:\n        a[2][1].scatter(ff6[z][1],ff6[z][2],color='g') \n\nplt.show()","1db7cab0":"def dict_to_list(key,normalizer):\n    feature_list=[]\n\n    for i in enron:\n        if enron[i][key]==\"NaN\" or enron[i][normalizer]==\"NaN\":\n            feature_list.append(0.)\n        elif enron[i][key]>=0:\n            feature_list.append(float(enron[i][key])\/float(enron[i][normalizer]))\n    return feature_list\n\nfraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\nfraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\np = 0\nfor i in enron:\n    enron[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[p]\n    enron[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[p]\n    p=p+1","72287246":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfeature_list = ['poi','shared_receipt_with_poi','fraction_from_poi_email','fraction_to_poi_email',\"deferral_payments\"]\nu = featureFormat(enron, feature_list)\nlabels, features = targetFeatureSplit(u)\nX_train, X_test, Y_train, Y_test = train_test_split(features, labels,test_size=0.2,random_state=42)\n\n# USING RANDOM FOREST CLASSIFIER\nfrom sklearn.ensemble import RandomForestClassifier\nrr=RandomForestClassifier(max_depth=10, criterion = 'entropy')\nrr.fit(X_train,Y_train)\nprint(\"Accuracy using RandomForestClassifier:\",accuracy_score(Y_test, rr.predict(X_test)))\n\n#USING KNN CLASSIFIER\nfrom sklearn.neighbors import KNeighborsClassifier\n# for i in range(2,17):\n#     neigh = KNeighborsClassifier(n_neighbors=i)\n#     neigh.fit(X_train,Y_train)\n#     print(accuracy_score(Y_test, neigh.predict(X_test)))\n#best accuracy for n=6\nneigh = KNeighborsClassifier(n_neighbors=6)\nneigh.fit(X_train,Y_train)\nprint(\"Accuracy using KNN classifier: \",accuracy_score(Y_test, neigh.predict(X_test)))\n\n#USING GAUSSIAN NAIVE BAYES CLASSIFIER\nfrom sklearn.naive_bayes import GaussianNB\ngb=GaussianNB()\ngb.fit(X_train,Y_train)\nprint(\"Accuracy using GaussianNB classifier: \",accuracy_score(Y_test, gb.predict(X_test)))","12888b22":"print(Y_test)\nprint(rr.predict(X_test))\nprint(neigh.predict(X_test))\nprint(gb.predict(X_test))","67d5131d":"# TRAIN\/TESTing the data using diffeerent classifier","3a3b356d":"# Defining new feature","05885b6c":"# KNN CLASSIFIER has the best accuracy of 95.2%","06f07cb2":"# Importing the pkl file","c0464a9b":"# Printing the predicted values vs the actual values for different classifiers","75e3ca70":"# Checking the relationship between different features by scatterplot","68772a15":"# Defining FeatureFormat and the return list"}}