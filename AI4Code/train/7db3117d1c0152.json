{"cell_type":{"e1957641":"code","5c894d47":"code","983c5d0c":"code","b30119d3":"code","30313eeb":"code","d11a260e":"code","8fc864eb":"code","551422a5":"code","55b81b87":"code","c45f571e":"code","68628170":"code","c988c669":"code","cf0c1aca":"code","fdc11b08":"code","c39bb137":"code","f33b3708":"code","bb69e1ca":"markdown","1d65257f":"markdown","133f95e2":"markdown","22ec1917":"markdown","fd99bd23":"markdown","90f60a57":"markdown","49a2b960":"markdown","e19c5408":"markdown","3546bd9c":"markdown","51c0c393":"markdown","8db4f937":"markdown","e097e070":"markdown","f75e60cd":"markdown","a4bd4374":"markdown"},"source":{"e1957641":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport pylab as pl\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5c894d47":"data = pd.read_csv('..\/input\/FuelConsumptionCo2.csv')\ndata.head(10)","983c5d0c":"# summary of the data \ndata.describe()","b30119d3":"cdf = data[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']]\ncdf.head(10)","30313eeb":"df = cdf \ndf.hist()\nplt.show()","d11a260e":"plt.scatter(cdf['ENGINESIZE'], cdf['CO2EMISSIONS'])\nplt.xlabel('Engine Size')\nplt.ylabel('CO2 Emission')\nplt.show()","8fc864eb":"plt.scatter(cdf.FUELCONSUMPTION_COMB, cdf.CO2EMISSIONS, color='orange')\nplt.xlabel('FUELCONSUMPTION')\nplt.ylabel('CO2 Emission')\nplt.show()","551422a5":"plt.scatter(cdf.CYLINDERS, cdf.CO2EMISSIONS, color='blue')\nplt.xlabel('Cylinders')\nplt.ylabel('CO2 Emissions')\nplt.show()","55b81b87":"tmp = np.random.rand(len(data)) < 0.7 \ntrain = cdf[tmp]\ntest = cdf[~tmp]\nprint(train.head())\nprint(test.head())","c45f571e":"# Training set data distribution\nplt.scatter(train.ENGINESIZE, train.CO2EMISSIONS, color='blue')\nplt.xlabel('Engine Size')\nplt.ylabel('CO2 Emission')\nplt.show()","68628170":"from sklearn import linear_model\nregr = linear_model.LinearRegression()  # linear  Regression object \ntrain_x = np.asanyarray(train[['ENGINESIZE']]) # converts input into nd array \ntrain_y = np.asanyarray(train[['CO2EMISSIONS']])\nregr.fit(train_x, train_y)\nprint ('Coefficients: ', regr.coef_)\nprint ('Intercept: ',regr.intercept_)\n","c988c669":"plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS, color='blue')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\nplt.xlabel(\"Engine size\")\nplt.ylabel(\"Emission\")","cf0c1aca":"from sklearn.metrics import r2_score\ntest_x = np.asanyarray(test[['ENGINESIZE']])\ntest_y = np.asanyarray(test[['CO2EMISSIONS']])\ntest_y_p = regr.predict(test_x)","fdc11b08":"# R2 Score:\nprint('R2 Score: ', r2_score(test_y_p, test_y))","c39bb137":"print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_p - test_y)))","f33b3708":"print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_p - test_y) ** 2))","bb69e1ca":"### Lets select few columns to explore indepth ","1d65257f":"## Evaluation of the model ","133f95e2":"# Creating train and test dataset","22ec1917":"# Reading the Data","fd99bd23":"# Thanks for following this notebook \n<a href = \"https:\/\/www.linkedin.com\/in\/afiz-shaik-1b425427\/\">Afiz<\/a>","90f60a57":"## Data Exploration ","49a2b960":"### R2 Score:\nR-squared is not error, but is a popular metric for accuracy of your model. It represents how close the data are to the fitted regression line. The higher the R-squared, the better the model fits your data. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).","e19c5408":"### Mean absolute error: \nIt is the mean of the absolute value of the errors. This is the easiest of the metrics to understand since it\u2019s just average error.","3546bd9c":" **Coefficient** and** Intercept** in the simple linear regression, are the parameters of the fit line. Given that it is a simple linear regression, with only 2 parameters, and knowing that the parameters are the intercept and slope of the line, sklearn can estimate them directly from our data. Notice that all of the data must be available to traverse and calculate the parameters.\n \n ## plot the fit line","51c0c393":"### Mean Squared Error (MSE): \nMean Squared Error (MSE) is the mean of the squared error. It\u2019s more popular than Mean absolute error because the focus is geared more towards large errors. This is due to the squared term exponentially increasing larger errors in comparison to smaller ones.","8db4f937":"# Simple Linear Regression:\nIn this notebook, we learn how to use scikit-learn to implement simple linear regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, Evaluate your model using test set, and finally use model to predict unknown value","e097e070":"## Modeling the Data","f75e60cd":"## Plot each of these features","a4bd4374":"## Lets see linear is their relation by ploting each of these features"}}