{"cell_type":{"8934e3a0":"code","303384fa":"code","1bfeab2e":"code","803ec9c3":"code","c36a2996":"code","7d5aadbf":"code","c33e9e64":"code","c6d70f1f":"code","ce515c02":"code","af6b26d2":"code","6f8f04ae":"code","894b6452":"code","bbcb3f9a":"code","29b319ba":"code","109831c1":"code","401c6ef0":"code","29901ecf":"code","6ba81ce8":"code","9d969321":"code","e18b66b6":"code","c3e3e3ac":"code","de2c4ed8":"code","5f8b4dc7":"code","cde5d3a6":"code","b8b3e381":"markdown","6b44ae08":"markdown","14e40227":"markdown","bea20707":"markdown","494e427e":"markdown","defee51a":"markdown"},"source":{"8934e3a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","303384fa":"import numpy as np\nimport pandas as pd\nimport os \nimport cv2\nimport matplotlib.pyplot as plt\nimport random\n\n#TensorFlow Packages\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,AveragePooling2D, MaxPooling2D,BatchNormalization,Conv2D","1bfeab2e":"os.chdir('\/kaggle\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset')\n!pwd","803ec9c3":"# Creating a fish category\nFISH = os.listdir()\nFISH","c36a2996":"DATADIR = '\/kaggle\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset'\n\nfor fish in FISH:\n    path = os.path.join(DATADIR,fish) # path to the list of fish directory\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img))\n        plt.imshow(img_array)\n        plt.show()\n        break\n    break\nprint(img_array.shape)","7d5aadbf":"DataDir2 = '\/kaggle\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\n\nos.chdir(DataDir2)\nfor f in FISH:\n    path = os.path.join(DataDir2,f,f) # path to the list of fish directory\n    for img in os.listdir(path):\n        img_array2 = cv2.imread(os.path.join(path,img))\n        plt.imshow(img_array2,  cmap='gray')\n        plt.show()\n        break\n    break\nprint(img_array2.shape)","c33e9e64":"# Let Classified img_array is the test image while img_array2 in the train image\ndata_train = img_array\ndata_test = img_array2","c6d70f1f":"# Resize the train data and test data into 75pixel\nIMG_size = 100\n\n# For Train\nnew_train_array = cv2.resize(data_train, (IMG_size, IMG_size))\nplt.imshow(new_train_array)\nplt.show()\n\n# For Test \nnew_test_array = cv2.resize(data_test, (IMG_size, IMG_size))\nplt.imshow(new_test_array)\nplt.show()","ce515c02":"#Mapping image into its label based on fish name \n\ndef create_dataset(FISH):\n    test_data = []\n    DATADIR = '\/kaggle\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset'\n    os.chdir(DATADIR)\n    for fish in FISH:\n        path = os.path.join(DATADIR,fish) # path to the list of fish director\n        for img in os.listdir(path):\n            class_num = FISH.index(fish)\n            img_array = cv2.imread(os.path.join(path,img))\n            new_array = cv2.resize(img_array, (IMG_size , IMG_size))\n            test_data.append([new_array, class_num])\n    return test_data","af6b26d2":"test_data = create_dataset(FISH)\ntest_df = pd.DataFrame(test_data)\nprint(test_df[1].unique())\nprint(len(test_df))","6f8f04ae":"# Mapping the image into its label based on fish name \n\ndef create_dataset_train(category):\n    train_data = []\n    DataDir2 = '\/kaggle\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'\n    os.chdir(DataDir2)\n    for FISH in category:\n        path = os.path.join(DataDir2,FISH,FISH) # path to the list of fish directory\n        IMG_size = 100\n        class_num = category.index(FISH)\n        for img in os.listdir(path):\n                img_array2 = cv2.imread(os.path.join(path,img))\n                new_array2 = cv2.resize(img_array2, (IMG_size, IMG_size))\n                train_data.append([new_array2,class_num])\n        \n    return train_data","894b6452":"# As you can see i have 2 category for naming the label of each folder because of wrong namin of folder of \n# Horse Mackarel which it is name as Hourse Mackarel and Gilt Head Bream name as Gilt-Head Bream on the \n#training dataset folder.\n\ncategory = ['Black Sea Sprat','Sea Bass','Red Mullet','Trout','Striped Red Mullet','Shrimp','Red Sea Bream','Hourse Mackerel','Gilt-Head Bream']\ntrain_data = create_dataset_train(category)","bbcb3f9a":"train_data[0]","29b319ba":"df_train = pd.DataFrame(train_data)\nprint(df_train[1].unique())\nprint(len(df_train))\ndf_train.shape\nprint(df_train[1].value_counts())","109831c1":"# Lets shuffle the data set \nrandom.shuffle(train_data)\nrandom.shuffle(test_data)","401c6ef0":"# Lets Create Feature and Label List\nX_train = []\ny_train = []\nX_test = []\ny_test = []\nimg_size = 100\n#For Train Dataset\nfor feature, label in train_data:\n    X_train.append(feature)\n    y_train.append(label)\n    \n#For Test Dataset\nfor feature, label in test_data:\n    X_test.append(feature)\n    y_test.append(label)\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\n#X_train = X_train.reshape(len(X_train), 50*50)\n#X_test = X_test.reshape(len(X_test), 50*50)\nX_train = np.array(X_train).reshape(-1, img_size, img_size,3)\nX_test = np.array(X_test).reshape(-1, img_size, img_size,3)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\nprint(X_train.shape)\nprint(X_test.shape)\nX_train.shape","29901ecf":"print(len(X_train))","6ba81ce8":"# use Min-Max Scaling  since the max is 255 pixel and 0 pixel for min\nX_train = X_train\/255.0\nX_test = X_test\/255.0","9d969321":"# the target_value(y_train and y_test) into a 2d dimension so it can fit to the model\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=9)","e18b66b6":"#I use feature_extractor name because i want to use the out of that the random forest\n#INPUT LAYER\nfeature = Sequential()\nfeature.add(Conv2D(40, (3,3), input_shape = X_train.shape[1:], padding = 'same', activation = 'relu'))\nfeature.add(MaxPooling2D())\nfeature.add(tf.keras.layers.BatchNormalization())\n\n#2nd Layer\nfeature.add(Conv2D(55, (3,3), padding = 'same', activation = 'relu'))\nfeature.add(AveragePooling2D())\nfeature.add(tf.keras.layers.BatchNormalization())\n\n#3rd Layer\nfeature.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu'))\nfeature.add(AveragePooling2D())\nfeature.add(tf.keras.layers.BatchNormalization())\n\n#4th Layer\nfeature.add(Flatten())\nx = feature.output\nx = Dense(128, activation = 'relu')(x)\n\n#Output Layer\npred_layer = Dense(9, activation = 'sigmoid')(x)\n\n#Create CNN Model\ncnn_model = Model(inputs = feature.input, outputs = pred_layer)\n\nMETRICS = [ tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n\n\nearly_stopping1 = tf.keras.callbacks.EarlyStopping(\n    monitor='accuracy', min_delta=1, patience=10, verbose=0,\n    mode='auto')\n\ncnn_model.summary()\n\ncnn_model.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay = 1e-6),\n              metrics = METRICS)","c3e3e3ac":"history = cnn_model.fit(X_train, y_train, epochs = 100, validation_split = 0.3, batch_size = 40, callbacks=[early_stopping1])","de2c4ed8":"# Plot training and validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc = 'upper left')\nplt.show()\n\n# Plot training and validation accuracy values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc = 'upper left')\nplt.show()","5f8b4dc7":"prediction_CNN = cnn_model.predict(X_test)\nprediction_CNN = [np.argmax(i) for i in prediction_CNN]","cde5d3a6":"#Confusion Matrix - verify accuracy of each class\nimport seaborn as sns\ncm = tf.math.confusion_matrix(labels = y_test, predictions = prediction_CNN)\nplt.figure(figsize = (10,7))\nsns.heatmap(cm,annot=True, fmt='d')\nplt.xlabel('Prediction')\nplt.ylabel('True_value')","b8b3e381":"### Standardization of Data","6b44ae08":"### Model Prediction","14e40227":"#### Determine if the Model is Good fit, Overfit or Underfit","bea20707":"### Creating CNN Model","494e427e":"### Extraction and Transformation of Image Data","defee51a":"<b>\"THANK YOU FOR READING MY IMAGE CLASSIFICATION USING Convolutional Neural Network\"<\/b><br>\n\"Please leave a comment if you have any question or any suggestion that will help to this notebook\"<br>\n\"Please give me an upvote if you find this useful it will help me alot!\"<br>"}}