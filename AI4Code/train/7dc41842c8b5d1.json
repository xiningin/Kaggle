{"cell_type":{"03a805a4":"code","5c0f04c0":"code","a5815522":"code","e81c8f80":"code","2c0a01ed":"code","4313e754":"code","28ab9ed4":"code","7a7ddba4":"code","09875562":"code","e6435543":"code","e6b001bd":"code","b16f398b":"code","3c0e760d":"code","0f2b1798":"code","187aee64":"code","bad4fddb":"markdown","3b8890a3":"markdown","14de34ac":"markdown","c9a7d187":"markdown","efb39111":"markdown","94dca2b5":"markdown","16ef0e14":"markdown","c3f999c6":"markdown","0561b81f":"markdown","a80e85da":"markdown","2250c9e3":"markdown","97ca7344":"markdown","7212f943":"markdown","eabee640":"markdown","77a1a525":"markdown"},"source":{"03a805a4":"# Set-up: uncomment and run selection for  \n! pip install scispacy\n! pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_sm-0.2.4.tar.gz\n\n# NOT WORKING: nlp.load('en_core_sci_sm') \n# Seting manually\n! mkdir \/kaggle\/working\/scispacy-models\n! wget https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_sm-0.2.4.tar.gz \n! mv en_core_sci_sm-0.2.4.tar.gz \/kaggle\/working\/scispacy-models \n! tar xvfz \/kaggle\/working\/scispacy-models\/en_core_sci_sm-0.2.4.tar.gz -C \/kaggle\/working\/scispacy-models\n\n# Search engine library\n!pip install Whoosh \n\n# Model main folder for the output:\n! mkdir \/kaggle\/working\/indexes","5c0f04c0":"import numpy as np\nimport pandas as pd\nimport json\nimport spacy\n\nfrom time import asctime\nfrom collections import Counter\n\n# object displaying in different formats\nfrom IPython.core.display import display, HTML \n\n# TM\nfrom gensim.models import LdaModel, AuthorTopicModel, LdaMulticore\nfrom gensim.corpora import MmCorpus\n\n# IR\nfrom whoosh.index import * # full-text indexing and searching\n\n# BERTQA\nimport torch # optimized tensor library for deep learning using GPUs and CPUs\nfrom transformers import BertTokenizer, BertForQuestionAnswering, BasicTokenizer # transformers: large-scale transformer models like BERT, and usage scripts for them\nfrom transformers.data.metrics.squad_metrics import _get_best_indexes\n\n# Custom libraries\nfrom indexer import Indexer\nfrom question_answering import QuestionAnswering\nfrom recommender import Recommender\nfrom match import Match","a5815522":"arguments = {'task': 1, \n             'corpus_folder' : '\/kaggle\/input\/CORD-19-research-challenge\/',\n             'metadata_file' : '\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv',\n             'lda_model': '\/kaggle\/input\/covid19-abstract-lda-model\/lda.topics-170.fr-5-50.all-abstracts.model\/lda.topics-170.fr-5-50.all-abstracts.model',\n             'lda_mmcorpus': '\/kaggle\/input\/covid19-abstract-lda-model\/lda.topics-170.fr-5-50.all-abstracts.model\/corpus.mm',\n             'lda_type': 'lda',\n             'index_folder': '\/kaggle\/working\/indexes\/covid-19',\n             'subset_size': 2000, \n             'qa_model' : '\/kaggle\/input\/scibertqasquad\/checkpoint-31500\/',\n             'use_covid_synonyms': True,\n             'only_covid': True,\n             'spacy_model': '\/kaggle\/working\/scispacy-models\/en_core_sci_sm-0.2.4\/en_core_sci_sm\/en_core_sci_sm-0.2.4'}","e81c8f80":"# We define a function that reads the csv file, do some filtering and select the fields of interest\ndef load_metadata(path_to_metada, below_year=2020, above_year=1950):\n    # Select interesting fields from metadata file\n    fields = ['cord_uid','title', 'authors', 'publish_time', 'abstract', 'journal','url', 'has_pdf_parse',\n              'has_pmc_xml_parse', 'pmcid', 'full_text_file', 'sha']\n    # Extract selected fields from metadata file into dataframe\n    df_mdata = pd.read_csv(path_to_metada, skipinitialspace=True, index_col='cord_uid', usecols=fields)\n\n    # WARNING: cord_uid is described as unique, but c4u0gxp5 is repeated. So I remove one of this\n    df_mdata = df_mdata.loc[~df_mdata.index.duplicated(keep='first')]\n    \n    df_mdata['publish_time'] = pd.to_datetime(df_mdata['publish_time'], errors=\"coerce\")\n    df_mdata['publish_year'] = df_mdata['publish_time'].dt.year\n    df_mdata = df_mdata[df_mdata['abstract'].notna()]\n    df_mdata = df_mdata[df_mdata['authors'].notna()]\n    df_mdata['authors'] = df_mdata['authors'].apply(lambda row: str(row).split('; '))\n\n    relevant_time = df_mdata.publish_year.between(above_year, below_year)\n    df_mdata = df_mdata[relevant_time]\n\n    return df_mdata","2c0a01ed":"df_mdata = load_metadata(arguments['metadata_file'])\nprint(\"Number of papers loaded from metadata (after filtering out the repeated ones):\", len(df_mdata))","4313e754":"def load_model(path_to_model, model_type):\n    if model_type == 'lda':\n        return LdaModel.load(path_to_model)\n    elif model_type == 'lmc':\n        return LdaMulticore(path_to_model)\n    else:\n        return AuthorTopicModel.load(path_to_model)\n\ndef load_docind(path_to_docind):\n    with open(path_to_docind, 'r', encoding='utf-8') as f:\n        docind = [doci for doci in f.readlines()]\n    return docind","28ab9ed4":"# load lda\nprint('[INFO - {}] Loading model ({})'.format(asctime(), arguments['lda_type']))\ntm_model = load_model(arguments['lda_model'], arguments['lda_type'])\n\n# generate word index\nword2id = {w: i for i, w in tm_model.id2word.items()}\n\n# load metada corpus\nprint('[INFO - {}] Loading serialized corpus'.format(asctime()))\ncorpus = MmCorpus(arguments['lda_mmcorpus'])\ndocind = load_docind(arguments['lda_mmcorpus'] + '.docind') # EZ DA BEHAR??\n\n# load recommender to compute similarity\nprint('[INFO - {}] Starting the recommeder'.format(asctime()))\nrecommender = Recommender(tm_model, df_mdata, corpus, arguments['lda_type'])\nprint('[INFO - {}] Recommeder ready to use'.format(asctime()))","7a7ddba4":"def parse_description(desc, model_name='en_core_sci_sm'):\n    nlp = spacy.load(model_name)\n\n    # extract all entities in corpus:\n    doc = nlp(desc)\n    matcher = Match()\n    entvocab = set([entity.text for entity in doc.ents if len(entity.text.split(' ')) > 1])\n    matcher.matchinit_from_list(entvocab)\n\n    # mark multword expressions\n    desc = matcher.match(desc)\n    doc = nlp(desc)\n\n    # create a counter of identified terms\n    terms = Counter()\n    for term in doc:\n        if not term.is_stop and not term.is_punct and not term.like_num:\n            terms[term.lemma_] += 1\n    return terms\n\ndef max_pooling(terms, word2id, model):\n    nrows = len(terms)\n    ncolmns = model.num_topics\n    topicmatrix = np.zeros([nrows, ncolmns])\n    for i, term in enumerate(terms.keys()):\n        if term in word2id:\n            for topic in model.get_term_topics(word2id[term], minimum_probability=0.0):\n                topicmatrix[i, topic[0]] = topic[1]\n    max_pool = np.max(topicmatrix, 0)\n    max_pool = max_pool \/ np.sum(max_pool)\n    return max_pool","09875562":"print('[INFO - {}] Parsing task description'.format(asctime()))\ndesc = \"What is known about transmission, incubation, and environmental stability? \" + \\\n       \"Range of incubation periods for the disease in humans \" + \\\n       \"Tools to monitor phenotypic change and potential adaptation of the virus\"\n\nsynonyms = ['coronavirus 2019', 'coronavirus disease 19', 'cov2', 'cov-2', 'covid', 'ncov 2019', '2019ncov',\n            '2019-ncov', '2019 ncov', 'novel coronavirus', 'sarscov2', 'sars-cov-2', 'sars cov 2',\n            'severe acute respiratory syndrome coronavirus 2', 'wuhan coronavirus', 'wuhan pneumonia',\n            'wuhan virus']\nif arguments['use_covid_synonyms']:\n    desc = desc + \" \" + \" \".join(synonyms)\nterms = parse_description(desc)\nprint(terms.most_common(10))\nprint(max_pooling(terms, word2id, tm_model))","e6435543":"tasks = [\n    {\n        'task': \"Task1 - What is known about transmission, incubation, and environmental stability?\",\n        'questions': [\n            \"Range of incubation periods for the disease in humans\",\n            \"Range of incubation periods for the disease in humans depending on age\",\n            \"Range of incubation periods for the disease in humans depending on health status\",\n            \"How long individuals are contagious?\",\n            \"Prevalence of asymptomatic shedding and transmission\",\n            \"Prevalence of asymptomatic shedding and transmission in children\",\n            \"Seasonality of transmission\",\n            \"Charge distribution\",\n            \"Adhesion to hydrophilic\/phobic surfaces\",\n            \"Environmental survival to inform decontamination efforts for affected areas\",\n            \"Viral shedding\",\n            \"Persistence and stability on nasal discharge\",\n            \"Persistence and stability on sputum\",\n            \"Persistence and stability on urine\",\n            \"Persistence and stability on fecal matter\",\n            \"Persistence and stability on blood\",\n            \"Persistence of virus on surfaces of different materials\",\n            \"Persistence of virus on copper\",\n            \"Persistence of virus on stainless steel\",\n            \"Persistence of virus on plastic\",\n            \"Natural history of the virus\",\n            \"Shedding the virus from an infected person\",\n            \"Implementation of diagnostics to improve clinical processes\",\n            \"Implementation of products to improve clinical processes\",\n            \"Disease models, including animal models for infection, disease and transmission\",\n            \"Tools to monitor phenotypic change and potential adaptation of the virus\",\n            \"Studies to monitor phenotypic change and potential adaptation of the virus\",\n            \"Immune response and immunity\",\n            \"Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\",\n            \"Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\",\n            \"Role of the environment in transmission\"\n         ]\n    },\n    {\n        'task': \"Task 2 - What do we know about COVID-19 risk factors?\",\n        'questions': [\n            \"Which are the main risk factors?\",\n            \"Does smoking increase risk for COVID-19?\",\n            \"Is a pre-existing pulmonary disease a risk factor for COVID-19?\",\n            \"Do co-infections increase risk for COVID-19?\",\n            \"Does a respiratory or viral infection increase risk for COVID-19?\",\n            \"Are neonates at increased risk of COVID-19?\",\n            \"Are pregnant women at increased risk of COVID-19?\",\n            \"Is there any socio-economic factor associated with increased risk for COVID-19?\",\n            \"Is there any behavioral factor associated with increased risk for COVID-19?\",\n            \"What is the basic reproductive number?\",\n            \"What is the incubation period?\",\n            \"What are the modes of transmission?\",\n            \"What are the environmental factors?\",\n            \"Risk of fatality among symptomatic hospitalized patients\",\n            \"Risk of fatality among high-risk patient groups\",\n            \"Susceptibility of populations\",\n            \"Public health mitigation measures that could be effective for control\"\n        ]\n    },\n    {\n        'task': \"Task 3 - What do we know about virus genetics, origin, and evolution?\",\n        'questions': [\n            \"Real-time tracking of whole genomes to inform the development of diagnostics\",\n            \"Real-time tracking of whole genomes to inform the development of therapeutics\",\n            \"Real-time tracking of whole genomes to track variations of the virus over time\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to inform the development of diagnostics\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to inform the development of therapeutics\",\n            \"Mechanism for coordinating the rapid dissemination of whole genomes to track variations of the virus over time\",\n            \"Which geographic and temporal diverse sample sets are accessed to understand geographic differences?\",\n            \"Which geographic and temporal diverse sample sets are accessed to understand genomic differences?\",\n            \"Is there more than one strain in circulation?\",\n            \"Is any multi-lateral agreement leveraged such as the Nagoya Protocol?\",\n            \"Is there evidence that livestock could be infected and serve as a reservoir after the epidemic appears to be over?\",\n            \"Has there been any field surveillance to show that livestock could be infected?\",\n            \"Has there been any genetic sequencing to show that livestock could be infected?\",\n            \"Has there been any receptor binding to show that livestock could be infected?\",\n            \"Is there evidence that farmers are infected?\",\n            \"Is there evidence that farmers could have played a role in the origin?\",\n            \"What are the results of the surveillance of mixed wildlife-livestock farms for SARS-CoV-2 and other coronaviruses in Southeast Asia?\",\n            \"What are the results of the experimental infections to test host range for this pathogen?\",\n            \"Which are the animal hosts?\",\n            \"Is there evidence of continued spill-over to humans from animals?\",\n            \"Which are the socioeconomic and behavioral risk factors for the spill-over to humans from animals?\",\n            \"Sustainable risk reduction strategies\"\n        ]\n    },\n    {\n        'task': \"Task 4 - What do we know about vaccines and therapeutics?\",\n        'questions': [\n            \"What is known about the effectiveness of drugs being developed to treat COVID-19 patients?\",\n            \"What is known about the effectiveness of drugs tried to treat COVID-19 patients?\",\n            \"Show results of clinical and bench trials to investigate less common viral inhibitors against COVID-19\",\n            \"Show results of clinical and bench trials to investigate naproxen against COVID-19\",\n            \"Show results of clinical and bench trials to investigate clarithromycin against COVID-19\",\n            \"Show results of clinical and bench trials to investigate Minocyclinethat against COVID-19\",\n            \"Which are the methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients?\",\n            \"What is known about the use of best animal models and their predictive value for a human vaccine?\",\n            \"Capabilities to discover a therapeutic for the disease\",\n            \"Clinical effectiveness studies to discover therapeutics, to include antiviral agents\",\n            \"Which are the models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics?\",\n            \"Efforts targeted at a universal coronavirus vaccine\",\n            \"Efforts to develop animal models and standardize challenge studies\",\n            \"Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers\",\n            \"Approaches to evaluate risk for enhanced disease after vaccination\",\n            \"Assays to evaluate vaccine immune response\",\n            \"Process development for vaccines, alongside suitable animal models\"\n        ]\n    },\n    {\n        'task': \"Task 5 - What has been published about medical care?\",\n        'questions': [\n            \"Resources to support skilled nursing facilities\",\n            \"Resources to support long term care facilities\",\n            \"Mobilization of surge medical staff to address shortages in overwhelmed communities\",\n            \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS)\",\n            \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) for viral etiologies\",\n            \"What are the outcomes of Extracorporeal membrane oxygenation (ECMO) of COVID-19 patients?\",\n            \"What are the outcomes for COVID-19 after mechanical ventilation adjusted for age?\",\n            \"What is known of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19?\",\n            \"What is known of the frequency, manifestations, and course of cardiomyopathy?\",\n            \"What is known of the frequency, manifestations, and course of cardiac arrest?\",\n            \"Application of regulatory standards (e.g., EUA, CLIA)\",\n            \"Ability to adapt care to crisis standards of care level\",\n            \"Approaches for encouraging and facilitating the production of elastomeric respirators, which can save thousands of N95 masks\",\n            \"Which are the best telemedicine practices?\",\n            \"Which are the facilitators to expand the telemedicine practices?\",\n            \"Which are the specific actions to expand the telemedicine practices?\",\n            \"Guidance on the simple things people can do at home to take care of sick people and manage disease\",\n            \"Which are the oral medications that might potentially work?\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate interventions\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate risk factors\",\n            \"Use of artificial intelligence in real-time health care delivery to evaluate outcomes\",\n            \"Which are the challenges, solutions and technologies in hospital flow and organization?\",\n            \"Which are the challenges, solutions and technologies in workforce protection?\",\n            \"Which are the challenges, solutions and technologies in workforce allocation?\",\n            \"Which are the challenges, solutions and technologies in community-based support resources?\",\n            \"Which are the challenges, solutions and technologies in payment?\",\n            \"Which are the challenges, solutions and technologies in supply chain management to enhance capacity, efficiency, and outcomes?\",\n            \"Efforts to define the natural history of disease to inform clinical care, public health interventions, infection prevention control, transmission, and clinical trials\",\n            \"What has been done to develop a core clinical outcome set to maximize usability of data across a range of trials?\",\n            \"Can adjunctive or supportive intervention (e.g. steroids, high flow oxygen)  improve the clinical outcomes of infected patients?\"\n        ]\n    },\n    {\n        'task': \"Task 6 - What do we know about non-pharmaceutical interventions?\",\n        'questions': [\n            \"Which is the best way to scale up NPIs in a more coordinated way to give us time to enhance our health care delivery system capacity to respond to an increase in cases?\",\n            \"Which is the best way to mobilize resources to geographic areas where critical shortfalls are identified?\",\n            \"Rapid design and execution of experiments to examine and compare NPIs currently being implemented\",\n            \"What is known about the efficacy of school closures?\",\n            \"What is known about the efficacy of travel bans?\",\n            \"What is known about the efficacy of bans on mass gatherings?\",\n            \"What is known about the efficacy of social distancing approaches?\",\n            \"Which are the methods to control the spread in communities?\",\n            \"Models of potential interventions to predict costs and benefits depending on race\",\n            \"Models of potential interventions to predict costs and benefits depending on income\",\n            \"Models of potential interventions to predict costs and benefits depending on disability\",\n            \"Models of potential interventions to predict costs and benefits depending on age\",\n            \"Models of potential interventions to predict costs and benefits depending on geographic location\",\n            \"Models of potential interventions to predict costs and benefits depending on immigration status\",\n            \"Models of potential interventions to predict costs and benefits depending on housing status\",\n            \"Models of potential interventions to predict costs and benefits depending on employment status\",\n            \"Models of potential interventions to predict costs and benefits depending on health insurance status\",\n            \"Policy changes necessary to enable the compliance of individuals with limited resources and the underserved with NPIs\",\n            \"Why do people fail to comply with public health advice?\",\n            \"Which is the economic impact of any pandemic?\",\n            \"How can we mitigate risks to critical government services in a pandemic?\",\n            \"Alternatives for food distribution and supplies in a pandemic\",\n            \"Alternatives for household supplies in a pandemic\",\n            \"Alternatives for health diagnoses, treatment, and needed care in a pandemic\"\n        ]\n    },\n    {\n        'task': \"Task 7 - What do we know about diagnostics and surveillance?\",\n        'questions': [\n            \"Which are the sampling methods to determine asymptomatic disease?\",\n            \"What can we do for early detection of disease?\",\n            \"Is the use of screening of neutralizing antibodies such as ELISAs valid for early detection of disease?\",\n            \"Which are the existing diagnostic platforms?\",\n            \"Which are the existing surveillance platforms?\",\n            \"Recruitment, support, and coordination of local expertise and capacity\",\n            \"How states might leverage universities and private laboratories for testing purposes?\",\n            \"Which are the best ways for communications to public health officials and the public?\",\n            \"What is the speed, accessibility, and accuracy of a point-of-care test?\",\n            \"What is the speed, accessibility, and accuracy of rapid bed-side tests?\",\n            \"Rapid design and execution of targeted surveillance experiments calling for all potential testers using PCR in a defined area to start testing and report to a specific entity\",\n            \"Separation of assay development issues from instruments\",\n            \"Which is the role of the private sector to help quickly migrate assays?\",\n            \"What has been done to track the evolution of the virus?\",\n            \"Latency issues and when there is sufficient viral load to detect the pathogen\",\n            \"What is needed in terms of biological and environmental sampling?\",\n            \"Use of diagnostics such as host response markers (e.g., cytokines) to detect early disease or predict severe disease progression\",\n            \"Policies and protocols for screening and testing\",\n            \"Policies to mitigate the effects on supplies associated with mass testing, including swabs and reagents\",\n            \"Technology roadmap for diagnostics\",\n            \"Which are the barriers to developing and scaling up new diagnostic tests?\",\n            \"How future coalition and accelerator models could provide critical funding for diagnostics?\",\n            \"How future coalition and accelerator models could provide critical funding for opportunities for a streamlined regulatory environment?\",\n            \"New platforms and technology (CRISPR) to improve response times\",\n            \"New platforms and technology to employ more holistic approaches\",\n            \"Coupling genomics and diagnostic testing on a large scale\",\n            \"What is needed for rapid sequencing and bioinformatics to target regions of the genome that will allow specificity for a particular variant?\",\n            \"What is needed for sequencing with advanced analytics for unknown pathogens?\",\n            \"What is needed for distinguishing naturally-occurring pathogens from intentional?\",\n            \"What is known about One Health surveillance of humans and potential sources of future spillover or ongoing exposure for this organism and future pathogens?\"\n        ]\n    },\n    {\n        'task': \"Task 8 - Help us understand how geography affects virality\",\n        'questions': [\n            \"Are there geographic variations in the rate of COVID-19 spread?\",\n            \"Are there geographic variations in the mortality rate of COVID-19?\",\n            \"Is there any evidence to suggest geographic based virus mutations?\"\n        ]\n    },\n    {\n        'task': \"Task 9 - What has been published about ethical and social science considerations?\",\n        'questions': [\n            \"Articulate and translate existing ethical principles and standards to salient issues in COVID-2019\",\n            \"Embed ethics across all thematic areas, engage with novel ethical issues that arise and coordinate to minimize duplication of oversight\",\n            \"Support sustained education, access, and capacity building in the area of ethics\",\n            \"Establish a team at WHO that will be integrated within multidisciplinary research and operational platforms and that will connect with existing and expanded global networks of social sciences\",\n            \"Develop qualitative assessment frameworks to systematically collect information related to local barriers and enablers for the uptake and adherence to public health measures for prevention and control\",\n            \"How the burden of responding to the outbreak and implementing public health measures affects the physical and psychological health of those providing care for Covid-19 patients?\",\n            \"Identify the underlying drivers of fear, anxiety and stigma that fuel misinformation and rumor, particularly through social media\"\n        ]\n    },\n    {\n        'task': \"Task 10 - What has been published about information sharing and inter-sectoral collaboration?\",\n        'questions': [\n            \"Which are the methods for coordinating data-gathering with standardized nomenclature?\",\n            \"Sharing response information among planners, providers, and others\",\n            \"Understanding and mitigating barriers to information-sharing\",\n            \"How to recruit, support, and coordinate local expertise and capacity relevant to public health emergency response?\",\n            \"Integration of federal\/state\/local public health surveillance systems\",\n            \"Value of investments in baseline public health response infrastructure preparedness\",\n            \"Modes of communicating with target high-risk populations (elderly, health care workers)\",\n            \"Risk communication and guidelines that are easy to understand and follow\",\n            \"Communication that indicates potential risk of disease to all population groups\",\n            \"Misunderstanding around containment and mitigation\",\n            \"Action plan to mitigate gaps and problems of inequity in the Nation\u2019s public health capability, capacity, and funding to ensure all citizens in need are supported and can access information, surveillance, and treatment\",\n            \"Measures to reach marginalized and disadvantaged populations\",\n            \"Data systems and research priorities and agendas incorporate attention to the needs and circumstances of disadvantaged populations and underrepresented minorities\",\n            \"Mitigating threats to incarcerated people from COVID-19, assuring access to information, prevention, diagnosis, and treatment\",\n            \"Understanding coverage policies (barriers and opportunities) related to testing, treatment, and care\"\n        ]\n    }\n]","e6b001bd":"print(\"[{}] Task number selected: {}\".format(asctime(), arguments['task']))\ntask = tasks[arguments['task'] - 1] \nprint(task['task'])\n\n# join task title and question as description\nprint('[INFO - {}] Parsing task description'.format(asctime()))\ndesc = task['task'] + \" \" + \" \".join(task['questions'])\nsynonyms = ['coronavirus 2019', 'coronavirus disease 19', 'cov2', 'cov-2', 'covid', 'ncov 2019', '2019ncov',\n            '2019-ncov', '2019 ncov', 'novel coronavirus', 'sarscov2', 'sars-cov-2', 'sars cov 2',\n            'severe acute respiratory syndrome coronavirus 2', 'wuhan coronavirus', 'wuhan pneumonia',\n            'wuhan virus']\nif arguments['use_covid_synonyms']:\n    desc = desc + \" \" + \" \".join(synonyms)\n\nterms = parse_description(desc)\ntask_topic_dist = max_pooling(terms, word2id, tm_model)\n\nprint('[INFO - {}] Ranking documents and subseting'.format(asctime()))\nsimilars, distances = recommender.k_nearest_docs(arguments['subset_size'], task_topic_dist, recommender.corpus_topic_dist, \n                                                 only_covid=arguments['only_covid'])\nsubset = df_mdata.loc[similars].copy()\nsubset['similarity'] = 1 - distances","b16f398b":"subset[['title', 'authors', 'journal', 'similarity']].head(10)","3c0e760d":"print('[INFO - {}] Indexing sub-corpus'.format(asctime()))\nindexer = Indexer(subset, arguments['index_folder'], arguments['corpus_folder'])\nindexer.create_index()\nprint('[INFO - {}] Index calculated'.format(asctime()))","0f2b1798":"print('[INFO - {}] Loading pretrained BERT QA'.format(asctime()))\nqa_model = QuestionAnswering(arguments['qa_model'])","187aee64":"# Creates the HTML code to show all the answers colored gradually in the paragraph\ndef color_snippet(text,marks):\n    # Set colors for answers\n    colors = ['#ffebcc','#ffd699', '#ffc266', '#ffad33','#ff9900']\n    \n    # Create HTML code to show the colored paragraph\n    html = '<blockquote>'\n    current_mark = 0\n    for i,mark in enumerate(marks):\n        if current_mark != mark:\n            if current_mark != 0:\n                html += '<\/span>'\n            if mark > 0:\n                html += '<span style=\"background-color: {}\">'.format(colors[mark-1])\n            current_mark = mark\n        html += text[i]\n    if current_mark != 0:\n        html += '<\/span>'\n    html += '<\/blockquote>' \n    return html\n\n\n# Set number of this task\nntask = arguments['task']\n\n# Show title of the task\ntask_title = tasks[ntask-1]['task']\nhtml = html = \"<p><h2>\" + task_title + \"<\/h2><\/p><br>\"\n\n# Set input parameters of the functions above\n# Maximum number of documents to retrieve\nmax_n_docs = 20\n# Maximum number of answers to extract\nmax_n_answers = 5\n# Maximum answer length\nmax_answer_length = 30\n# Amount of Cannotanswers to declare answers as not suitable\nthreshold = 17\n\n# Iterate over all the questions in a task and call the functions above\nfor nq,question in enumerate(tasks[ntask-1]['questions']):\n    # Call the function to retrieve relevant paragraphs of papers\n    df_ir_results = indexer.retrieve_documents(question, topn=max_n_docs)\n    # Call the function to extract answers from paragraphs\n    df_qa_results = qa_model.extract_answers(question, df_ir_results, max_n_answers, max_answer_length)\n\n    # Show the question\n    html += '<br><p><font color=\"#C28A08\"><h3>{}<\/h3><\/font>'.format(question)\n    \n    # Count how many non-null answers are extracted for a question\n    n_cannotanswer = 0\n    for ind in df_qa_results.index:\n        answer = df_qa_results['qa_answers'][ind][0] \n        #Take SQuAD and QuAC cases into account\n        if answer['text'] == 'Cannotanswer' or len(answer['text'])==0:\n            n_cannotanswer += 1\n            \n    if n_cannotanswer < threshold:\n        # Set maximum number of results to show\n        max_n_results = 5\n        n_results = 0\n        for ind in df_qa_results.index:\n            if n_results == max_n_results:\n                break\n            answers = df_qa_results['qa_answers'][ind]\n            # If the first answer is non-null, show the answer\n            #if answers[0]['text'] != 'CANNOTANSWER':\n            \n            if answers[0]['text'] != 'Cannotanswer' and len(answers[0]['text']) != 0:\n                html += '<br><b>{}<\/b> ({}, {}, {})<br>'.format(answers[0]['text'], df_qa_results['date'][ind], df_qa_results['journal'][ind], df_qa_results['title'][ind])\n            \n                # Color the paragraph to highlight the answers\n                marks = [0] * len(df_qa_results['text'][ind])\n               \n                for n_ans, answer in enumerate(answers):\n                    if answer['text'] != 'Cannotanswer':\n                        level = 5 - n_ans\n                        start = answer['start_index']\n                        if answer['end_index'] >= len(marks):\n                            end = len(marks)-1\n                        else:\n                            end = answer['end_index']\n                       \n                        for i in range(start,end):\n                            if marks[i] < level:\n                                marks[i] = level\n                html += color_snippet(df_qa_results['text'][ind], marks)\n                n_results += 1        \n        html += '<hr>'\n    else:\n        html += '<br><font color=\"red\">No suitable answers found.<\/font><br>'\n\n# Display the HTML string that contains all the answers\ndisplay(HTML(html))\nif not os.path.exists(\"html\"):\n    os.mkdir(\"html\")\nhtml_file = open(\"\/kaggle\/working\/html\/task\" + str(ntask) + \".html\",\"w\")\nhtml_file.write(html)\nhtml_file.close()","bad4fddb":"## 7. Select a subset of documents<a class=\"anchor\" id=\"subset\"><\/a>\n\nIn this section we carry out the first of the process. Given a task we select the most relevant papers according the recommender system, and select a subset of paper to be indexed. We take the 2000 most similar papers of the task as a subset. \n\nNote that in `arguments` we can defined the taks number ([go to section to change task number](#options)). In our case, we consider a description of the title and the set of question defined in the task. ","3b8890a3":"## 5. Define a function to parse task descriptions<a class=\"anchor\" id=\"parse\"><\/a>\nIn this section we defined the function that extracts the most representative terms of the description, and from the those term obtained the topic distribution that summarize the description. We defined two functions:\n\n- `parse_description()`: It takes a description as input and returns a set of terms. Function first apply a NER model (scispacy) to recognize multiword entities, which we consider as tokens. After that, the function lematization of the tokens, discarding punctuation marks, stopwords, and numbers. \n\n- `max_pooling()`: It takes a set of terms and their topic distributions, and returns a unique topic distribution that summarize all the iput distribution. The function applies max-pooling over the the topics, selecting the highest value for each topic. \n\nSome description can be generic and could not only describe questions aplicable to COVID-19. Therefore we decide to add a set of synonyms and related words of COVID-19 in order to refine the topic distribution of the task description. ","14de34ac":"Following we load the LDA, generate word index to parse the description and load the serialized corpus.","c9a7d187":"## 4. Start the recommender system<a class=\"anchor\" id=\"recommender\"><\/a>\n\nIn this section we prepare the recommender system that ranks scientific papers according to their topical distribution. As commented above, the recommender deploys LDA model of the [CORD-19 dataset](https:\/\/pages.semanticscholar.org\/coronavirus-research) to sort the paper according to the topical relatedness with the task description. \n\nOnce we parse the description and get its topic distribution. The recommender applies the Jehnssen-Shannon metric to comute similarity between the task descrption and the abstract of the paper.  For the task texts are represented with 170 topics induced from the LDA model (further details in  [COVID-19 LDA Fitting](https:\/\/www.kaggle.com\/oierldl\/covid-19-lda-fitting))\n\nThe recommender system is implemented in a utility script outside this notebook. You can check the details [in this notebook](https:\/\/www.kaggle.com\/oierldl\/recommender).  As the recommender make use a precomputed LDA model and serialized corpus used to estimate the model, we first define some helper functions to load all the required stuff. \n","efb39111":"In the following snippet of code we show the parsing result of a shor description as an example.","94dca2b5":"We can inspect the subset with the following code.","16ef0e14":"## 3. Load information in the metadata file<a class=\"anchor\" id=\"files\"><\/a>\n\nCORD19-dataset includes a metadata file (CSV file) of research papers related to coronavirus and COVID-19. In this section we first load the info in the metadata file into a dataframe object. As we are not interested in all the metadata info, we will select just some of the columns of the CSV file, such as title, publish time, abstract or journal.\n\nNote: this version of the notebook takes v7 of the dataset (from 2020-04-10).\n\nCORD-19.v7 includes info of 51,078 papers, but some of them are repeated (they have the same *cord_uid*). Thus, we filter out the repeated ones.","c3f999c6":"## 2. TM-IR\/QA options<a class=\"anchor\" id=\"options\"><\/a>\nIn order to make easier the control of the main arguments to run the task, in this section we define the paths, models, and similar options. More concretely we indicate the following:\n\n- `task` : Task number (1-10). See [task definitions](#tasks).\n- `corpus_folder`: Path to the dataset \n- `metadata_file`: Path to the metadata file.\n- `lda_model`: Path to LDA model file.\n- `lda_mmcorpus`: Path to the serialized corpus used to train de LDA model. This is required to vectorize the input for the recommender system. \n- `lda_type`: Topic Model type. In this notebook we set to \"lda\".\n- `index_folder`: Path to index folder created by the IR system.\n- `subset_size`: Number of paper selected for indexing\n- `qa_model` : Path to the pretrained model \n- `use_covid_synonyms`: Option to add COVID-19 related terms to include in the task description (True\/False).\n- `only_covid`: Retrieve only documents related COVID-19.\n- `spacy_model`: Path or name to the spacy model\n","0561b81f":"## 1. Install packages and load libraries<a class=\"anchor\" id=\"libraries\"><\/a>\n\nAlthough most the libraries are already instaleed in the kaggle-docker, we need to a few python libraries to properly run the code. In addition we make the output folder for storing the results of the IR\/QA systems.\n\nIn order to run the code it is required to add the following utility scripts `indexer`, `qa`, `recommender`, `match`, and `utils`. You can add utility scrips via `File -> Add utility script`.","a80e85da":"## 6. Define questions for all the tasks<a class=\"anchor\" id=\"questions\"><\/a>\nIn this section we define the questions that will be used as an input for the TM-IR\/QA system implemented in the previous section.\nAs some of the subquestions for each of the tasks defined by the organizers are too complex for the QA system, we refined them.","2250c9e3":"## 9. Question Answering system<a class=\"anchor\" id=\"qa\"><\/a>\n\nThe third main component of the system is the QA system. Given a question in natural language and a paragraph, this system returns the answer to the question in the paragraph or \u201cI don\u2019t know\u201d otherwise. Our implementation for such a system will be based on neural networks techniques. The implementation details will be given below.\n\nIn this section we define question-answering class ([QuestionAnswering](https:\/\/www.kaggle.com\/oierldl\/question-answering)) that contain  a function (`QuestionAnswering.extract_answers()`) that given a question, a dataframe with the relevant paragraphs (returned by the `indexer.retrieve_docs()` function), maximum number of answers to extract and maximum length of the answer, extracts specific answers from all the relevant paragraphs.\n\nThis function returns the dataframe with relevant paragraphs, but with additional data. The best answers are added for each paragraph, specifying the answer itself (text), the score, and the start and end index that define the position of the answer in the paragraph.\n\nFor the implementation of these functions we took the [SciBERT language representation model](https:\/\/arxiv.org\/abs\/1903.10676) and we fine tuned for QA using [SQuAD2.0](https:\/\/arxiv.org\/abs\/1806.03822) and [QuAC](https:\/\/arxiv.org\/abs\/1808.07036) datasets. We performed this fine tuning externally. Thus, we made this [model publicly available in Kaggle](https:\/\/www.kaggle.com\/jonander95\/bertsquadquac), and we just need to load it here.\n\nFollowing the usual reading comprehension method we use BERT as a pointer network. This kind of networks select an answer start and end index given a question and a context. In order to extract the correct answer span we get the highest probability pairs of start and end indexes in the code below. As the input length for the BERT model is fixed, we use a sliding window approach for sequences that are longer than 384 subtokens.\n\nFor further details of the QA component please visit [covid-ixa](https:\/\/www.kaggle.com\/aotegi\/neural-question-answering-for-cord19-task1) notebook. ","97ca7344":"# Topic Model Driven Neural Passage Retrieval Approach\n\n## Task 1: **What is known about transmission, incubation, and environmental stability?**\n\n\n## Note on the Notebook\nThis notebook relies on another submitted notebook ([covid-ixa](https:\/\/www.kaggle.com\/aotegi\/neural-question-answering-for-cord19-task1)) as both share the IR\/QA components. Regarding [covid-ixa](https:\/\/www.kaggle.com\/aotegi\/neural-question-answering-for-cord19-task1) notebook, the contribution of this notebook is the use of LDA models to create a subset of potential papers and create dynamically IR indexing for each of the task descriptions. \n\n## Objective\nOur goal is to use textual Question Answering (QA) techniques to directly find exact answers to the scientific questions listed in [COVID-19 Open Research Dataset Challenge](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge). \nFor this purpose the system returns short replies, and only answers when the quality of retrieval and answers is satisfactory. The user could access the whole paragraphs and documents if further details were needed. We use neural textual Question Answering (QA) techniques to directly find specific answers to the scientific questions listed in [COVID-19 Open Research Dataset Challenge](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge). We adapted the scientific questions given in each task description to be more amenable towards current technology. The system is not tailored towards specific questions, and can be readily used to answer any other question. \n\n\n## Approach\nFor that purpose, we will use the freely available [CORD-19 dataset](https:\/\/pages.semanticscholar.org\/coronavirus-research), which contains metadata of over 51,000 scientific papers (full text is also available for around 40,000 of them) about COVID-19, SARS-CoV-2, and related coronaviruses.\n\nThe implemented system has three main components. The first component is a LDA based **recommender** system, which helps indentifying paper topically related to the task description, and automatically discard those papers that are useful for the researcher. LDA model is uses abstracts to learn a topic model of the [CORD-19 dataset](https:\/\/pages.semanticscholar.org\/coronavirus-research). In this notebook we used a pre-computed LDA model of 170 topics. You can find how to build the LDA model used in for the submission in the following notebook: [COVID-19 LDA Fitting](https:\/\/www.kaggle.com\/oierldl\/covid-19-lda-fitting).\n\nThe second component is an **information retrieval** (IR) system, based on the classical BM25F search algorithm. This system indexes not only the abstracts, but also paragraphs on the full text of the papers.\n\nThe third component of the system is the **question answering** (QA) system that automatically answers questions posed in natural language. The implemented system is based on neural network techniques. More specifically, we have used the [SciBERT language representation model](https:\/\/arxiv.org\/abs\/1903.10676), which is a pretrained language model based on [BERT](https:\/\/arxiv.org\/abs\/1810.04805), but trained on a large corpus of scientific text, including text from biomedical domain. BERT has shown successful results in many NLP tasks, such as QA. Following this approach, we fined tuned SciBERT for QA, using the [SQuAD2.0 dataset](https:\/\/arxiv.org\/abs\/1806.03822), which is a reading comprehension dataset widely used in the QA research community. \n\nNote that the system is identical for all the tasks. Given a set of questions related to a task, returns answers for those questions without any additional tuning.\n\n## Modular Code\nThe notebook  make use of some custom python libraries in order to improve the modularity of the code and simplify the information given the notebook. In order to run the code it is required to add the following utility scripts `indexer`, `qa`, `recommender`, `match`, and `utils`. You can add utility scrips via `File -> Add utility script`. See Section  [Install packages and load libraries](#libraries) for further details on how to correctly set up the notebook.\n\n## Pros and cons\n\nPositive and negative aspects \n\nPositive aspects of the system:\n* System creates filters unrelated papers with the task topic, and therefore can focuses on the relevant information. \n* The system tries to fight information overload: A) returns specific answers to the questions. B) returns answers only when relevant, trying to avoid low quality answers. \n* Given the questions, it is completely automatic and does not need any tuning. The better the questions quality, the better the answers the system provides. \n* The system can be used to easily explore other tasks and information needs, as it directly returns answers to the document collection via new questions.\n* We experimented with different fine-tuning strategies according to two broad types of questions. \n* The system is complementary to labor-intensive information extraction techniques that try to find answers to specific tasks using hand-annotation or manually built rules.\n\nLimitations and possible improvements (cons):\n* We need to test if actually topic model help filtering irrelevant papers. \n* The interface could be richer, allowing more in-depth exploration in cases where the user would like to explore additional documents and answers. \n* Currently the system relies only on the information available in the metadata file and full texts of the CORD19 dataset. We have not used any external source or other related dataset.\n* The speed can easily be improved. It is limited by the 5Gb of storage space available, which makes the system slow in getting abstracts and full documents. Producing larger and richer indices will speed up the system considerably.\n* The system can be easily improved with a more sophisticated Information Retrieval module (see to-dos)\n* The system can be easily improved by incorporating domain-specific annotated development data (see to-dos) and a continuous learning component to keep learning thanks to the feedback of some hand-selected expert users (see to-dos)\n* We also plan to improve the system with a confidence measure in the answers. In the future we would like to introduce an improved confidence measure that combines the IR and QA scores into a unified measure that automatically assesses the quality of the answers (see to-dos).\n\nSome of the limitations are software-engineering tasks which do not add to the technical and scientific part of our system. We thus will focus on the more challenging and hopefully effective improvements of the next to-dos:\n* We will test more sophisticated IR modules for paragraph retrieval (we plan to evaluate on the [TREC-COVID challenge](https:\/\/ir.nist.gov\/covidSubmit\/))\n* We plan to collaborate with third parties to exploit domain-specific development data ([COVID-QA project](https:\/\/github.com\/deepset-ai\/COVID-QA\/tree\/master\/data\/question-answering)) \n* We plan to add a continuous learning component to keep learning thanks to the feedback of hand-selected expert users, using Human In The Loop strategies.\n* We also plan to improve the system with a confidence measure in the answers.\n\n\n\n## Sections\n1. [Install packages and load libraries](#libraries)\n2. [TM-IR\/QA options](#options)\n3. [Load info from metadata file](#files)\n4. [Start the recommender system](#recommender)\n5. [Define a function to parse task descriptions](#parse)\n6. [Define questions for all the tasks](#questions)\n7. [Select a subset of documents](#subset)\n8. [Create an IR index and define retrieval function](#index)\n9. [Question Answering system](#qa)\n10. [Results of passage retrieval](#results)","7212f943":"------","eabee640":"## 10. Results of the passage retrieval<a class=\"anchor\" id=\"results\"><\/a>\nIn this last section, we want to show the results for the task. For that purpose, we will run the above functions to first retrieve relevant paragraphs from the papers, and then extract specific answers from them.\n\nWe set to 20 the maximum number of paragraphs that the IR system returns, but we discard paragraphs where the QA system returns \u201cI don\u2019t know\u201d. Moreover, we decided not to show any results for the questions which receive more than %85 of \u201cI don\u2019t know\u201d answers. For the rest of the questions, we show the best answer string for each of the best five paragraphs, that is, five specific answers per question. Additionally, next to each answer, we show some extra information: the title of the paper from where the answer was extracted (with a link to access online version on the web), the journal and the date of the publication. Moreover, under the answer we show the paragraph from which the answer was extracted. In this paragraph the best 5 answers are highlighted, using different lightness of color (the darker the better the answer)","77a1a525":"## 8. Create an IR index and define retrieval function<a class=\"anchor\" id=\"index\"><\/a>\n\nThe second component of the system that we are going to develop in our approach is the information retrieval system. An information retrieval system is a tool that searches for  documents that are relevant to an information need from a collection of documents. This system has two main modules: (1) the indexing system and (2) the query system. The modules are implemented in a utility sctript  that contains [`Indexer`](`https:\/\/www.kaggle.com\/oierldl\/indexer`) python class.  \n\nThe first module is in charge of creating the primary data structure for the system, which is the index. The second module is the one with which users interact submitting a query based on their information need, and based on this query and using the index, retrieves documents. In this section we create an index on given subset by the recommender system. [`Indexer`](`https:\/\/www.kaggle.com\/oierldl\/indexer`) contains the query module. For the implementation of these modules, we used [Whoosh library](https:\/\/pypi.org\/project\/Whoosh\/), which contains functions for indexing text and then searching the index.\n\nThe index is a data structure that makes it possible to search for information in a document collection in a very efficient way. In short, it lists, for every word, all documents that contain it. We will index the papers related to COVID-19, not only the abstracts that are in the metadata file, but also the full text provided in PMC or PDF JSON format. As having shorter documents is better for the answering system that we will develop later, we will not index the whole text in a paper together. Instead, the indexing unit will be an abstract or each of the paragraphs of the full text (as marked in JSON files).\n\nIn order to create an index, we must define the schema of the index, which is defined in the [`Indexer`](`https:\/\/www.kaggle.com\/oierldl\/indexer`). The schema lists the fields in the index. A field is a piece of information for each document in the index, for example, id, path of the document, title and text. We define the type of these last two fields as \u201cTEXT\u201d, which means that they will be searchable. As it is common practice, we also define to apply the Stemming Analyzer to these text fields. Applying this analyzer all the text will be tokenized, then all the tokens will be converted to lowercase, a stopword filter will be applied in order to remove too common words, and finally, a stemming algorithm will be applied.\n\nIf you check the constructor of the [`Indexer`](`https:\/\/www.kaggle.com\/oierldl\/indexer`), you will find the followin code that defines the schema used to create the index.\n```\n# Schema definition:\n# - id: type ID, unique, stored; cord_uid + \"##abs\" for abstract, and \"##pmc-N\" or \"##pdf-N\" for paragraphs in body text (Nth paragraph)\n# - path: type ID, stored; path to the JSON file (only for papers with full text)\n# - title: type TEXT processed by StemmingAnalyzer; not stored; title of the paper\n# - text: type TEXT processed by StemmingAnalyzer; not stored; content of the abstract section or the paragraph\n\nschema = Schema(id = ID(stored=True,unique=True),\n                path = ID(stored=True),\n                title = TEXT(analyzer=analysis.StemmingAnalyzer()),\n                text = TEXT(analyzer=analysis.StemmingAnalyzer())\n               )\n```\n\nThe module that creates the index is implemented by `Indexer.create_index()`, while the query module (used in the following sections) is implemented by `Indexer.retrieve_documents()`. Please, check [covid-ixa](https:\/\/www.kaggle.com\/aotegi\/neural-question-answering-for-cord19-task1)) as both share the IR\/QA components for further details of how to create an index with Whoosh. \n\nWe index the papers related to the task description, and we index not only the abstracts that are in the metadata file, but also the full text provided in PMC or PDF JSON format. As having shorter documents is better for the answering system, we index  paragraphs of the documents (as marked in JSON files) and abstract when full text is not available.\n\nIndexing could take several minutes."}}