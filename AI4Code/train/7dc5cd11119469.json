{"cell_type":{"0de0d333":"code","d345c136":"code","fae3478c":"code","0d751fd6":"code","847f4da1":"code","7b356106":"code","46afba91":"code","007870ae":"code","fd9d6dcc":"code","5b06732b":"code","9a87d7f5":"code","76c5336d":"code","096c7879":"code","523c8adf":"code","9cabbc79":"markdown","7535ae05":"markdown","e70881c7":"markdown","eda08c6a":"markdown","5bf15811":"markdown","07c522da":"markdown"},"source":{"0de0d333":"# Set-up libraries\nimport os\nimport pandas as pd\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","d345c136":"# Check input data source\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fae3478c":"# Read-in data\ndf = pd.read_csv('..\/input\/iris\/Iris.csv')","0d751fd6":"# Look at some details\ndf.info()","847f4da1":"# Look at some records\ndf.head()","7b356106":"# Check for missing values\ndf.isna().sum()","46afba91":"# Check for duplicate values\ndf.duplicated().sum()","007870ae":"# Look at breakdown of label\ndf['Species'].value_counts()\nsns.countplot(df['Species'])","fd9d6dcc":"# Explore data visually\nsns.pairplot(df, hue='Species')","5b06732b":"# Summarise\ndf.describe()","9a87d7f5":"# Get the features for input\nX = df.drop('Species', axis=1)","76c5336d":"# Build and fit models\nwcss_scores = []\niterations = list(range(1,10))\n\nfor k in iterations:\n    model = KMeans(n_clusters=k)\n    model.fit(X)\n    wcss_scores.append(model.inertia_)","096c7879":"# Plot performances\nplt.figure(figsize=(12,6))\nsns.lineplot(x=iterations, y=wcss_scores)","523c8adf":"# Compare ground truth and cluster labels visually\n\nplt.figure(figsize=(27,27))\n\nplt.subplot(3,2,1)\nplt.title('Ground truth: Petal',fontsize=22)\nplt.xlabel('Petal Width')\nplt.xlabel('Petal Length')\nplt.scatter(df.PetalLengthCm[df.Species == \"Iris-setosa\"],\n            df.PetalWidthCm[df.Species == \"Iris-setosa\"])\nplt.scatter(df.PetalLengthCm[df.Species == \"Iris-versicolor\"],\n            df.PetalWidthCm[df.Species == \"Iris-versicolor\"])\nplt.scatter(df.PetalLengthCm[df.Species == \"Iris-virginica\"],\n            df.PetalWidthCm[df.Species == \"Iris-virginica\"])\n\nplt.subplot(3,2,2)\nplt.title('Ground truth: Sepal',fontsize=22)\nplt.xlabel('Sepal Width')\nplt.xlabel('Sepal Length')\nplt.scatter(df.SepalLengthCm[df.Species == \"Iris-setosa\"],\n            df.SepalWidthCm[df.Species == \"Iris-setosa\"])\nplt.scatter(df.SepalLengthCm[df.Species == \"Iris-versicolor\"],\n            df.SepalWidthCm[df.Species == \"Iris-versicolor\"])\nplt.scatter(df.SepalLengthCm[df.Species == \"Iris-virginica\"],\n            df.SepalWidthCm[df.Species == \"Iris-virginica\"])\n\nplt.subplot(3,2,3)\nplt.title('K = 3: Petal',fontsize=22)\nplt.xlabel('Petal Width')\nplt.xlabel('Petal Length')\nmodel = KMeans(n_clusters=3)\nX['labels'] = model.fit_predict(X)\nplt.scatter(X.PetalLengthCm[X.labels == 0], X.PetalWidthCm[X.labels == 0])\nplt.scatter(X.PetalLengthCm[X.labels == 1], X.PetalWidthCm[X.labels == 1])\nplt.scatter(X.PetalLengthCm[X.labels == 2], X.PetalWidthCm[X.labels == 2])\n\nplt.subplot(3,2,4)\nplt.title('K = 3: Sepal',fontsize=22)\nplt.xlabel('Sepal Width')\nplt.xlabel('Sepal Length')\nmodel = KMeans(n_clusters=3)\nX['labels'] = model.fit_predict(X)\nplt.scatter(X.SepalLengthCm[X.labels == 0], X.SepalWidthCm[X.labels == 0])\nplt.scatter(X.SepalLengthCm[X.labels == 1], X.SepalWidthCm[X.labels == 1])\nplt.scatter(X.SepalLengthCm[X.labels == 2], X.SepalWidthCm[X.labels == 2])\n\nplt.subplot(3,2,5)\nplt.title('K = 2: Petal',fontsize=22)\nplt.xlabel('Petal Width')\nplt.xlabel('Petal Length')\nmodel = KMeans(n_clusters=2)\nX['labels'] = model.fit_predict(X)\nplt.scatter(X.PetalLengthCm[X.labels == 0], X.PetalWidthCm[X.labels == 0])\nplt.scatter(X.PetalLengthCm[X.labels == 1], X.PetalWidthCm[X.labels == 1])\n\nplt.subplot(3,2,6)\nplt.title('K = 2: Sepal',fontsize=22)\nplt.xlabel('Sepal Width')\nplt.xlabel('Sepal Length')\nmodel = KMeans(n_clusters=2)\nX['labels'] = model.fit_predict(X)\nplt.scatter(X.SepalLengthCm[X.labels == 0], X.SepalWidthCm[X.labels == 0])\nplt.scatter(X.SepalLengthCm[X.labels == 1], X.SepalWidthCm[X.labels == 1])","9cabbc79":"## Step 3: Model and evaluate\n\nWe need to create a number of models with different k values, measure the performance of each model, and use the k with the best performance in our final model. \n\nMeasure the performance. Where the ground truth is available, we compare the clusters generated to that of the ground truth.\n","7535ae05":"## Step 0: Understand the problem\nWhat we're trying to do here is to find strong and interesting patterns or similarities from the Iris data.","e70881c7":"## Learn more\nIf you found this example interesting, you may also want to check out:\n\n* [Machine learning in minutes - very fast fundamental examples in Python](https:\/\/www.kaggle.com\/jamiemorales\/machine-learning-in-minutes-very-fast-examples)\n* [List of machine learning methods & datasets](https:\/\/www.kaggle.com\/jamiemorales\/list-of-machine-learning-methods-datasets)\n\nThanks for reading. Don't forget to upvote.","eda08c6a":"## About\nThis notebook contains a very fast fundamental k-means clustering example in Python.\n\nThis work is part of a series called [Machine learning in minutes - very fast fundamental examples in Python](https:\/\/www.kaggle.com\/jamiemorales\/machine-learning-in-minutes-very-fast-examples)\n\nThe approach is designed to help grasp the applied machine learning lifecycle in minutes. It is not an alternative to actually taking the time to learn. What it aims to do is help someone get started fast and gain intuitive understanding of the typical steps early on.","5bf15811":"## Step 2: Preprocess data and understand some more\nThis step typically takes the most time in the cycle but for our purposes, most of the datasets chosen in this series are clean.\n\nReal-world datasets are noisy and incomplete. The choices we make in this step to address data issues can impact downstream steps and the result itself. For example, it can be tricky to address missing data when we don't know why it's missing. Is it missing completely at random or not? It can also be tricky to address outliers if we do not understand the domain and problem context enough.","07c522da":"## Step 1: Set-up and understand data\nThis step helps uncover issues that we will want to address in the next step and take into account when building and evaluating our model. We also want to find interesting relationships or patterns that we can possibly leverage in solving the problem we specified."}}