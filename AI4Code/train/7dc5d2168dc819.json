{"cell_type":{"91d81ad2":"code","f95e464d":"code","6d5061d2":"code","ba49c7f1":"code","c3fd4405":"code","84b0781e":"code","3340c2ec":"code","a94056c1":"code","b5a8ac5d":"code","44cbe46a":"code","3ef417f3":"code","5a5e2be0":"code","85c2b9ff":"code","b344a5ec":"code","700c3ecd":"code","506506f7":"code","7ac7ecc6":"code","4f8323c3":"code","bb6908e9":"code","cced280d":"code","f40fa01e":"code","d9b73318":"code","886702f4":"code","169d1f24":"code","7b83248f":"code","6cafaa20":"code","92649e5a":"code","8944b387":"code","b84de5e0":"code","250b1119":"markdown","ef6f31c6":"markdown","5595024f":"markdown","017d3dba":"markdown","e9d10a4e":"markdown","10f5dea4":"markdown","136f1fb2":"markdown","e87d9a4f":"markdown","2bda9b2a":"markdown","c36bef4e":"markdown","503599da":"markdown","afb9d3fe":"markdown","fed3cd4f":"markdown","6eeccc24":"markdown","3a6744b7":"markdown","e4596352":"markdown","d0993a52":"markdown","0b98ac30":"markdown","2b8eef49":"markdown","88808a46":"markdown"},"source":{"91d81ad2":"# Loading packages\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport missingno as msno\nfrom wordcloud import WordCloud\n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')","f95e464d":"# Reading data\n\ntrain = pd.read_csv(\"..\/input\/google-quest-challenge\/train.csv\")\nSample = pd.read_csv(\"..\/input\/google-quest-challenge\/sample_submission.csv\")","6d5061d2":"# Print first few rows of train data\n\ntrain.head()","ba49c7f1":"# Shape of train data\n\ntrain.shape","c3fd4405":"# Some basic info of train data\n\ntrain.info()","84b0781e":"# Describe train data\n\ntrain.describe()","3340c2ec":"# Let's see the list of column names\n\nlist(train.columns[1:])","a94056c1":"msno.matrix(train)","b5a8ac5d":"train.select_dtypes(include = ['object']).columns.values","44cbe46a":"train.select_dtypes(include = ['float64', 'int64']).columns.values","3ef417f3":"train['question_title'].value_counts().head(30)","5a5e2be0":"len(train['question_title'].unique())","85c2b9ff":"# Question Title\n\nwordcloud = WordCloud(width = 1000, height = 600, max_font_size = 200, max_words = 150, \n                      background_color='white').generate(\" \".join(train.question_title))\n\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","b344a5ec":"# Question Body\n\nwordcloud = WordCloud(width = 1000, height = 600, max_font_size = 200, max_words = 150, \n                      background_color='white').generate(\" \".join(train.question_body))\n\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","700c3ecd":"# Answer\n\nwordcloud = WordCloud(width = 1000, height = 600, max_font_size = 200, max_words = 150,\n                      background_color='white').generate(\" \".join(train.answer))\n\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","506506f7":"Cat = train['category'].value_counts()\n\nfig = go.Figure([go.Bar(x=Cat.index, y=Cat)])\nfig.update_layout(title = \"Count of categories\")\npy.iplot(fig, filename='test')","7ac7ecc6":"Host = train['host'].value_counts()\n\nfig = go.Figure(data = [go.Scatter(x = Host.index, y = Host.values)])\nfig.update_layout(title = \"Distribution of Host\")\npy.iplot(fig, filename='test')","4f8323c3":"targetCol = list(Sample.columns[1:])\ntargetCol","bb6908e9":"train[targetCol].values","cced280d":"corr = train[targetCol].corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(15, 14))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","f40fa01e":"sns.relplot(x=\"question_type_instructions\", y=\"answer_type_instructions\", data=train)","d9b73318":"sns.relplot(y=\"question_opinion_seeking\", x=\"question_fact_seeking\", data=train)","886702f4":"sns.relplot(x=\"answer_type_procedure\", y=\"answer_well_written\", data=train)","169d1f24":"sns.distplot(train[\"question_interestingness_self\"], hist=False, color=\"b\", kde_kws={\"shade\": True})","7b83248f":"sns.distplot(train[\"question_not_really_a_question\"], hist=False, color=\"m\", kde_kws={\"shade\": True})","6cafaa20":"sns.distplot(train[\"question_interestingness_others\"], hist=False, color=\"b\", kde_kws={\"shade\": True})","92649e5a":"sns.distplot(train[\"question_has_commonly_accepted_answer\"], hist=False, rug=True, color=\"g\", kde_kws={\"shade\": True})","8944b387":"sns.distplot(train[\"question_conversational\"], kde=False, color=\"r\")","b84de5e0":"sns.distplot(train[\"question_asker_intent_understanding\"], color=\"m\")","250b1119":"There are so many duplicate questions in our train data. Let's check number of unique questions.","ef6f31c6":"**Please UPVOTE if you find it useful or leave a comment if you have any queries.**","5595024f":"We can clearly see that our target variables are not binary, they are continous. They are in a range of 0 and 1.\n\nLet's see how they are correlated.","017d3dba":"#### Host\n\nThe data includes questions and answers from various StackExchange properties.","e9d10a4e":"## Data Exploration\n\n#### Question Title","10f5dea4":"It seems **question opinion seeking** and **question_fact_seeking** are **autocorrelated**.","136f1fb2":"We can clearly see the features that are correlated like 'question_type_instructions' and 'answer_type_instructions'. Let's see how:","e87d9a4f":"**There are two types of features we have in dataset. Let's see them:**\n\n* **Categorical features**","2bda9b2a":"We have 3583 unique questions. \n\n### WordCloud\n\n* Question Title\n* Question Body\n* Answer\n\nLet's check which words are used most","c36bef4e":"We have 5 categories in our data. Technology is the highest among them.","503599da":"### Category\n\nLet's see the categories:","afb9d3fe":"## Introduction\n\nIn this competition, you\u2019re challenged to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get!","fed3cd4f":"* **Question Title**\n\n  > using, Window, function, user, time, file, use, value, change, one\n   \n   \n* **Question Body**\n   \n  > gt, lt, using, use, one, will, know, new, user\n   \n   \n* **Answer**\n \n  > gt, lt, use, one, using, need, will, time, way, file\n\n\nSeems like most of the words are common in all the three WordClouds.","6eeccc24":"* **Numerical features**","3a6744b7":"It seems like **answer type procedure** and **answer well written** are not correlated at all.","e4596352":"#### Check null\/nan values","d0993a52":"**Let's see some other self-explanatory plots:**","0b98ac30":"We have full dataset that means we don't have missing values in our data.","2b8eef49":"Most of the data is collected from Stackoverflow.com\n\nWe have 30 target variables. Let's see them:","88808a46":"## Statistical Analysis"}}