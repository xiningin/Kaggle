{"cell_type":{"986a7a96":"code","59ec0f43":"code","5b4fae18":"code","535c4b63":"code","1397b2f5":"code","430f0fc8":"code","067863b8":"code","f5014385":"code","04d08f15":"code","dc4bde89":"code","cb0e00f6":"code","e2893615":"code","44c4f790":"code","914b79cc":"code","bf571a1d":"code","e78292a1":"code","164743be":"code","7c12a37e":"code","3fac303e":"code","4e33e0b9":"code","b41f3748":"code","555884cc":"code","fe5d3b40":"code","6aa26a88":"code","0fec0413":"code","10b33a11":"code","78864e2d":"code","20e69a7f":"code","2eb93de2":"code","71967ccb":"code","2a83bbc6":"code","ce1bbfef":"code","32831dd4":"code","8b3b276b":"code","3bfcd1fa":"markdown","aeefd6a3":"markdown","059f37f3":"markdown","a7b015b3":"markdown","05f02537":"markdown","221c6a18":"markdown","47f723d0":"markdown","4dd75196":"markdown","729d74a5":"markdown","3170ece9":"markdown","ebee92c4":"markdown","5a74e9e6":"markdown","80eb6f07":"markdown","715b27c5":"markdown","ea39db9b":"markdown","613d3aaf":"markdown","0cc4b21a":"markdown","4d4cc220":"markdown","2f96d06a":"markdown","5f1d2f96":"markdown"},"source":{"986a7a96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","59ec0f43":"!pip install fastai --upgrade","5b4fae18":"from fastai.tabular.all import *","535c4b63":"df_test= pd.read_csv('\/kaggle\/input\/titanic-extended\/test.csv')\ndf_train= pd.read_csv('..\/input\/titanic-extended\/train.csv')\ndf_train.head()","1397b2f5":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(df_train, title=\"Pandas Profiling Report\")\n","430f0fc8":"profile.to_notebook_iframe()","067863b8":"df_train.dtypes\ng_train =df_train.columns.to_series().groupby(df_train.dtypes).groups\ng_train","f5014385":"cat_names= [\n        'Name', 'Sex', 'Ticket', 'Cabin', \n        'Embarked', 'Name_wiki', 'Hometown', \n        'Boarded', 'Destination', 'Lifeboat', \n        'Body','Class'\n]\n\ncont_names = [ \n    'PassengerId', 'Pclass', 'SibSp', 'Parch', \n    'Age', 'Fare', 'WikiId', 'Age_wiki'\n ]\n\n","04d08f15":"splits = RandomSplitter(valid_pct=0.2)(range_of(df_train))\n\nto = TabularPandas(df_train, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='Survived',\n                   splits=splits)","dc4bde89":"#df_train.dtypes\ng_train =to.train.xs.columns.to_series().groupby(to.train.xs.dtypes).groups\ng_train","cb0e00f6":"to.train.xs.Age_na.head()","e2893615":"to.train","44c4f790":"to.train.xs","914b79cc":"to.train.ys.values.ravel()","bf571a1d":"### RANDOM FOREST\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_valid, y_valid = to.valid.xs, to.valid.ys.values.ravel()","e78292a1":"X_train.head()","164743be":"y_train","7c12a37e":"rnf_classifier= RandomForestClassifier(n_estimators=100, n_jobs=-1)\nrnf_classifier.fit(X_train,y_train)","3fac303e":"import xgboost as xgb\nclassifier=xgb.XGBClassifier(n_jobs=-1,max_depth=12,n_estimators=100)","4e33e0b9":"classifier.fit(X_train,y_train)","b41f3748":"y_pred=rnf_classifier.predict(X_valid)\n\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_pred, y_valid)","555884cc":"y_pred=classifier.predict(X_valid)\n\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_pred, y_valid)","fe5d3b40":"df_test.head()","6aa26a88":"profile = ProfileReport(df_test, title=\"Pandas Profiling Report\")\nprofile.to_notebook_iframe()","0fec0413":"df_test.dtypes\ng_train =df_test.columns.to_series().groupby(df_test.dtypes).groups\ng_train","10b33a11":"cat_names= [\n        'Name', 'Sex', 'Ticket', 'Cabin', \n        'Embarked', 'Name_wiki', 'Hometown', \n        'Boarded', 'Destination', 'Lifeboat', \n        'Body','Class'\n]\n\ncont_names = [ \n    'PassengerId', 'Pclass', 'SibSp', 'Parch', \n    'Age', 'Fare', 'WikiId', 'Age_wiki'\n ]","78864e2d":"test = TabularPandas(df_test, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   )","20e69a7f":"X_test= test.train.xs","2eb93de2":"X_test.head()","71967ccb":"X_test.dtypes\ng_train =X_test.columns.to_series().groupby(X_test.dtypes).groups\ng_train","2a83bbc6":"X_test= X_test.drop('Fare_na', axis=1)","ce1bbfef":"y_pred=classifier.predict(X_test)\n","32831dd4":"y_pred= y_pred.astype(int)","8b3b276b":"output= pd.DataFrame({'PassengerId':df_test.PassengerId, 'Survived': y_pred})\noutput.to_csv('my_submission_titanic.csv', index=False)\noutput.head()","3bfcd1fa":"here is our output","aeefd6a3":"Calculating the average null values we have in our data. It is important to know. Just to get intuition about data ","059f37f3":"using the same for target value","a7b015b3":"#  Importing and Loading files","05f02537":"Getting names of columns according to its datatype.\n\nThis will allow us to understand which feature is int, float, and object(categorical)\n","221c6a18":"avoiding, y_name and split for obvious reasons","47f723d0":"Generally what happens is, we cannot use the output of tabularpandas straightaway. So we need to access it as follows.. just taking peek at train data(for validation data replace train with valid)","4dd75196":"Installing fastai2, yes its not preinstalled. We would need to install on our own.\n\nWarning: If you get some sort of error in importing fastai modules. I would recommend changing notebook environment to\n\n    Always use latest environment Always get the latest package versions, but you may have to modify your code.\n\n","729d74a5":"Now this might be a bit puzzling if you are new to fastai. And its completely alright.\n\ncat_names refers to the features which are categorical.\n\ncont_names refers to the features which are continuous. For example : int and float\n\nfastai needs them in order to do preprocessing for you properly\n","3170ece9":"We just Trained randomforest classifier and predicting accuracy on validation set","ebee92c4":"WOW, we get the accuracy of 0.98 on validation dataset this means on leader board getting rank of 200 something our of 19,000. ","5a74e9e6":"# TEST dataset","80eb6f07":"Using RandomForestClassifier for solving this problem\n\nand taking out X_train and y_train values like we showed before\n","715b27c5":"We have table without any hardcore preprocessing all we did was just to use fastai tabular function to get this","ea39db9b":"# FastAI2\n\nnow we are diving into fastai2. looking down at code. Might be new and intimidating. But no worries,\nfollowing the documentation helped me. https:\/\/docs.fast.ai\/tutorial.tabular\n\nHere we are using fastai TabularPandas library. Which will do all the preprocessing for us.\nbefore that splitting our data into validation set to have a fair amount of idea that we are not overfitting the data. valid_pct= 0.2 means (as you may have guessed by now) it means 20% validation data.\n\ny_names, using column we are targetting to be predicted.\nprocs are [Categorify, FillMissing,Normalize], Convering objects into category, filling the missing value and normalizing the content for quick processing.\n\n\nNOTE:\nTabularpandas function creates a new column if there is any missing value spotted in any particular feature(only float or int column). for example: lets say Fare has a missing value somewhere. It will create a new column named 'Fare_na' where it will have integer values (1 or 2). ","613d3aaf":"getting the table value for test dataset. we used train.xs becoz it lets us extact the data we had given the tabularpandas function\n","0cc4b21a":"doing the same preprocessing we did for training set","4d4cc220":"using 'xs' to get the table in the manner we are used to see it. Notice that it is without 'Survived' column","2f96d06a":"Just taking abit statistical look into data.","5f1d2f96":"Now you would be thinking why we are dropping the 'Fare_na' column. The reason is, originally we trained model on 24 features. But as you know that tabularpandas function creates a new column if there is any missing value spotted in any particular feature.\n\nHere, our test data had some Fare values missing so the function created the boolean column this lead to 25 features. If you try to pass without dropping Fare_na column, it will give you the error that model was trained on 24 features and we are passing 25. That's why dropping Fare_na feature. And dont worry it doesnt have any effect on the output.\n"}}