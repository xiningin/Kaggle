{"cell_type":{"74f62279":"code","6e549f27":"code","d7adcae5":"code","b0b283c6":"code","7ad84364":"code","6d27cc14":"code","d7b7c656":"code","0fa6742c":"code","3dc8afa2":"code","6a832ce4":"code","39a9ac01":"code","37b228c9":"code","2e1a7226":"code","79e1163e":"code","36e1eca9":"code","234b6176":"code","a6d09135":"code","137bb144":"code","64b24482":"code","7b1beb5d":"code","64c23481":"code","1c66a856":"code","3bf256b7":"code","bcf6bc9a":"code","3b6e4938":"code","0f276628":"code","4eedaf7f":"code","5666d163":"code","a0a5d940":"code","dc4fabd8":"code","7ab6337f":"code","0da4482c":"code","d4ca35da":"markdown"},"source":{"74f62279":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e549f27":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\n","d7adcae5":"#constant\nIMAGE_SIZE = 256\nBATCH_SIZE = 32\nCHANNELS = 3\nEPOCHS = 50","b0b283c6":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/potato-data-plant-village\/\",\n    shuffle=True,\n    image_size =(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size = BATCH_SIZE\n)","7ad84364":"class_names = dataset.class_names\nclass_names","6d27cc14":"len(dataset)","d7b7c656":"for image_batch, label_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(label_batch.numpy())","0fa6742c":"for image_batch, label_batch in dataset.take(1):\n    print(image_batch[0].shape)","3dc8afa2":"plt.figure(figsize =(10,10))\nfor image_batch, label_batch in dataset.take(1): # taking 1 batch of 32 images\n    for i in range(12):\n        ax = plt.subplot(3,4,i+1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[label_batch[i]])\n        plt.axis(\"off\")","6a832ce4":"len(dataset)\nprint ( len(dataset) * BATCH_SIZE)  # actual images (last batch is less than BATCH_SIZE though)","39a9ac01":"print(\"Total Dataset:\", len(dataset), \"with each item has images of batch\", BATCH_SIZE)\ntrain_size = 0.8\nTRAIN_SET_SIZE = int(len(dataset) * train_size)\ntrain_ds = dataset.take(TRAIN_SET_SIZE)\ntest_ds = dataset.skip(TRAIN_SET_SIZE)\nprint(\"Train:\", len(train_ds), \", Temp test:\", len(test_ds))\n\nvalidation_size = 0.1\nVALID_SET_SIZE = int(len(dataset) * validation_size)\nvalid_ds = test_ds.take(VALID_SET_SIZE)\ntest_ds = test_ds.skip(VALID_SET_SIZE)\nprint(\"Validation:\", len(valid_ds), \", Test:\", len(test_ds))","37b228c9":"def get_dataset_partitions_tf(ds, train_split=0.8, val_split = 0.1, test_split=0.1, shuffle=True, shuffle_size = 10000):\n    ds_size = len(ds)\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 12)\n        \n    train_size = int(train_split * ds_size)    \n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    \n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n\n    return train_ds, val_ds, test_ds","2e1a7226":"train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)","79e1163e":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)","36e1eca9":"resize_and_rescale = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n    layers.experimental.preprocessing.Rescaling(1.0\/255)    \n])\n\ndata_augmentation = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n])","234b6176":"input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\nn_classes = 3\nmodel = models.Sequential([\n    resize_and_rescale,\n    data_augmentation,\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = input_shape),  # 32 features \/ layers \/ features, (3,3) is filter size\n    layers.MaxPooling2D((2,2)),\n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),\n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),    \n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),   \n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),    \n    \n    layers.Conv2D(64, (3,3), activation='relu'), \n    layers.MaxPooling2D((2,2)),   \n    \n    layers.Flatten(),\n    \n    layers.Dense(64, activation = 'relu'),\n    layers.Dense(n_classes, activation = 'softmax')\n])\n\nmodel.build(input_shape = input_shape)","a6d09135":"model.summary()","137bb144":"model.compile(\n    optimizer = 'adam',\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)","64b24482":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    batch_size = BATCH_SIZE,\n    verbose=1,\n    validation_data=val_ds\n)","7b1beb5d":"scores = model.evaluate(test_ds)","64c23481":"scores","1c66a856":"history.params","3bf256b7":"print(history.history.keys())","bcf6bc9a":"history.history['accuracy']","3b6e4938":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","0f276628":"plt.figure(figsize=(8,8))\n\nplt.subplot(1,2,1)\nplt.plot(range(EPOCHS), acc, label = 'Training Accuracy')\nplt.plot(range(EPOCHS), val_acc, label = 'Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(range(EPOCHS), loss, label = 'Training Loss')\nplt.plot(range(EPOCHS), val_loss, label = 'Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')","4eedaf7f":"for images_batch, labels_batch in test_ds.take(1):\n    \n    # for first image in a batch below code\n    #print(images_batch[0].numpy().astype('uint8')) # 3-d array\n    plt.imshow(images_batch[0].numpy().astype('uint8')) # show image","5666d163":"import numpy as np","a0a5d940":"for images_batch, labels_batch in test_ds.take(1):\n    # working on a first image in a batch of 32 (BATCH_SIZE)\n    first_image = images_batch[0].numpy().astype('uint8')\n    first_label = labels_batch[0].numpy()\n    \n    print(\"first image to predict\")\n    plt.imshow(first_image)\n    print(\"actual label:\", class_names[first_label])\n    \n    batch_predictions = model.predict(images_batch)  # predict all images\n    print(\"predictions:\", class_names[np.argmax(batch_predictions[0])]) # first image\n\n    \n    \n    ","dc4fabd8":"def predict(model, img):\n    img_array = tf.keras.preprocessing.image.img_to_array(img.numpy())\n    \n    img_array = tf.expand_dims(img_array, 0) # creates a batch for an image\n    predictions = model.predict(img_array)\n    \n    predicted_class = class_names[np.argmax(predictions[0])]\n    confidence = round(100 * (np.max(predictions[0])), 2)\n    return predicted_class, confidence\n    ","7ab6337f":"plt.figure(figsize=(15,15))\nfor images, labels in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        predicted_class, confidence = predict(model, images[i])\n        actual_class = class_names[labels[i]]\n        \n        plt.title(f\"Actual: {actual_class}\\n Predicted: {predicted_class}\\n Confidence: {confidence}%\")\n        \n        plt.axis(\"off\")\n        \n        \n        ","0da4482c":"model_version = 1  # increment it manually to have different versions\nmodel.save(f\".\/models\/{model_version}\")","d4ca35da":"Code is from: \n\n* https:\/\/www.youtube.com\/watch?v=dGtDTjYs3xc\n* https:\/\/www.youtube.com\/watch?v=bns5ELvbzVk \n* https:\/\/www.youtube.com\/watch?v=ZN6P_GEJ7lk\n\n\n\nwith minor changes here and there."}}