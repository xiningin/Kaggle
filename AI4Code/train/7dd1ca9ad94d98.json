{"cell_type":{"97bb3a73":"code","d716e5c4":"code","f1c0a577":"code","33065947":"code","dc1c17c6":"code","1b5bceba":"code","763cf472":"code","6ed8caed":"code","4fe8e28e":"code","7439dfdc":"code","37ca8163":"code","bb5c294e":"code","77996823":"code","4650f87c":"code","ec694a36":"code","dd1ffaa5":"code","415690e1":"code","b47a2e83":"code","f25d764a":"code","156c206b":"code","779f0294":"code","cc3c31ad":"code","1da6da70":"code","5062c1cc":"code","881249e8":"code","4295db2a":"code","42e7c180":"code","bb19fe26":"code","a0733d2a":"code","9310994a":"code","2ae08ee6":"code","f12de34d":"code","b34cc145":"code","59ec160d":"code","2d27678a":"code","200dead6":"code","745427e2":"code","7c3fb3a6":"code","3d8aa214":"code","b0bce901":"code","cbfd8eb6":"code","8be2c483":"code","e0d77a23":"code","2249a66c":"code","ede93b3b":"code","deb5e756":"code","524d8ab4":"code","a0a2253c":"code","15dd49ce":"code","6a8e5695":"code","aed72160":"code","b3501d7c":"code","9fecac73":"code","b15d5965":"code","fd9588e2":"code","1969bf1c":"code","8088de77":"markdown","d6a1c60f":"markdown","9de934e7":"markdown","78aefdb6":"markdown","dcc103e4":"markdown","bf7a50a5":"markdown","7715350c":"markdown","59e25951":"markdown","e3bdd2de":"markdown","de3a0724":"markdown","ba681bab":"markdown","969d19bb":"markdown","f2411c75":"markdown","021ddc77":"markdown","aa4bf572":"markdown","44b873b8":"markdown","8136cefd":"markdown","c73e09f3":"markdown","697f93d7":"markdown","9455c328":"markdown","f00c7b7e":"markdown","76639efe":"markdown"},"source":{"97bb3a73":"import seaborn as sns\nimport pandas as pd\nimport plotly.graph_objs as go\nimport plotly\nimport numpy as np\nimport matplotlib.pyplot as plt\npd.options.mode.chained_assignment = None","d716e5c4":"df = pd.read_csv(\"..\/input\/google-play-store-apps\/googleplaystore.csv\")\ndf.isnull().sum()","f1c0a577":"# Rating column have outliers\ndf.hist()","33065947":"df[df['Rating']>5]","dc1c17c6":"df.drop([10472], inplace=True)","1b5bceba":"df.hist()","763cf472":"# fill missing categorical with median\ndef impute_mean(Rating):\n  return Rating.fillna(Rating.median())\ndf['Rating'] = df['Rating'].transform(impute_mean)","6ed8caed":"df.isnull().sum()","4fe8e28e":"df.columns = df.columns.str.replace(' ','_')","7439dfdc":"print(df.Type.mode().values[0])\nprint(df.Current_Ver.mode().values[0])\nprint(df.Android_Ver.mode().values[0])","37ca8163":"# fill missing categorical with mode\ndf['Type'].fillna(str(df.Type.mode().values[0]), inplace=True)\ndf['Current_Ver'].fillna(str(df.Current_Ver.mode().values[0]), inplace=True)\ndf['Android_Ver'].fillna(str(df.Android_Ver.mode().values[0]), inplace=True)","bb5c294e":"df.isnull().sum()","77996823":"df.info()\ndf.sample(4)","4650f87c":"# changing reviews, installs, price, size to numerical values\ndf['Reviews'] = df['Reviews'].apply(lambda x: int(x))\n\ndf['Installs'] = df['Installs'].apply(lambda x: x.replace('+', '') if '+' in str(x) else x)\ndf['Installs'] = df['Installs'].apply(lambda x: x.replace(',', '') if ',' in str(x) else x)\ndf['Installs'] = df['Installs'].apply(lambda x: float(x))\n\ndf['Price'] = df['Price'].apply(lambda x: str(x).replace('$', '') if '$' in str(x) else str(x))\ndf['Price'] = df['Price'].apply(lambda x: float(x))\n\ndf['Size'] = df['Size'].apply(lambda x: str(x).replace('Varies with device', 'NaN') if 'Varies with device' in str(x) else x)\ndf['Size'] = df['Size'].apply(lambda x: str(x).replace('M', '') if 'M' in str(x) else x)\ndf['Size'] = df['Size'].apply(lambda x: str(x).replace(',', '') if ',' in str(x) else x)\ndf['Size'] = df['Size'].apply(lambda x: float(str(x).replace('k', '')) \/ 1000 if 'k' in str(x) else x)\ndf['Size'] = df['Size'].apply(lambda x: float(x))","ec694a36":"df.info()","dd1ffaa5":"df.describe()","415690e1":"df.shape","b47a2e83":"googleplay_user_reviews = pd.read_csv(\"..\/input\/google-play-store-apps\/googleplaystore_user_reviews.csv\")","f25d764a":"googleplay_user_reviews.isnull().sum()","156c206b":"# drop NaN\nuser_review = googleplay_user_reviews.dropna()\nuser_review","779f0294":"user_review.info()","cc3c31ad":"user_review['Translated_Review'].values","1da6da70":"! pip install vaderSentiment","5062c1cc":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n#load VADER\nanalyzer= SentimentIntensityAnalyzer()\nsentence = \"This is a great VADER Example\"\nanalyzer.polarity_scores(sentence)\n\n#result will be sth. like{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6249}","881249e8":"# arr = user_review['Translated_Review'].values\n# out_arr = np.array_str(arr)\n# type(out_arr) ","4295db2a":"# Add VADER metrics to dataframe\nuser_review['compound']= [analyzer.polarity_scores(v)['compound'] for v in user_review['Translated_Review']]\nuser_review['neg'] = [analyzer.polarity_scores(v)['neg'] for v in user_review['Translated_Review']]\nuser_review['neu'] = [analyzer.polarity_scores(v)['neu'] for v in user_review['Translated_Review']]\nuser_review['pos'] = [analyzer.polarity_scores(v)['pos'] for v in user_review['Translated_Review']]\n\n#load the descriptions into textblob\ndesc_blob = [TextBlob(desc) for desc in user_review['Translated_Review']]\n\n#add the sentiment metrics to the dataframe\nuser_review['tb_Pol'] = [b.sentiment.polarity for b in desc_blob]\nuser_review['tb_Subj'] = [b.sentiment.subjectivity for b in desc_blob]","42e7c180":"user_review","bb19fe26":"# drop ['Sentiment', 'Sentiment_Polarity','Sentiment_Subjectivity'] since i will be using vaderSentiment instead of the columns that have already provided those info\nuser_review.drop(['Sentiment', 'Sentiment_Polarity','Sentiment_Subjectivity'], axis=1, inplace=True)","a0733d2a":"# set up conditions to decide whether the data is positive, negative, neutral based on observations of Translated_Review\n# then create new column Sentiment based on the conditions\nconditions = [(user_review['compound'] >= 0.3),\n    (user_review['compound'] <= 0.05) & (user_review['neu'] < 1),\n    (user_review['compound'] > 0.05) & (user_review['compound'] < 0.3),\n    (user_review['compound'] == 0)]\n\n# create a list of the values we want to assign for each condition\nvalues = ['pos', 'neg', 'neu', 'neu']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\nuser_review['Sentiment'] = np.select(conditions, values)","9310994a":"user_review.sample(50)","2ae08ee6":"# get the googleplaystore.csv data\ngoogleplay_df = df\ngoogleplay_df","f12de34d":"# merge and drop NaN\nmerged_df = pd.merge(googleplay_df, user_review, on = \"App\", how = \"inner\")\nmerged_df = merged_df.dropna(subset=['Translated_Review', 'Sentiment'])\nmerged_df","b34cc145":"plt.figure(figsize=(15,15))\ng = sns.scatterplot(merged_df['tb_Pol'], merged_df['tb_Subj'], hue = merged_df['Sentiment'], edgecolor='white', palette=\"twilight_shifted_r\")\nplt.xlabel('Sentiment Polarity', fontsize=20)\nplt.ylabel('Sentiment Subjectivity', fontsize=20)\nplt.title(\"Sentiment Analysis\", fontsize=20)\nplt.show()","59ec160d":"# all sentiment in each category\ngrouped_sentiment_category_sum = merged_df.groupby(['Category']).agg({'Sentiment': 'count'}).reset_index()\ngrouped_sentiment_category_sum","2d27678a":"# check sentiment type and number of apps according to that type\ngrouped_sentiment_category_count= merged_df.groupby(['Category', 'Sentiment']).agg({'App': 'count'}).reset_index()\ngrouped_sentiment_category_count","200dead6":"# sentiment_y = neg+pos+neu for each category\ngroup_sentiment = pd.merge(grouped_sentiment_category_count, grouped_sentiment_category_sum, on=[\"Category\"])\ngroup_sentiment ","745427e2":"# then we can find fraction of each type of sentiment \ngroup_sentiment['Fraction'] = group_sentiment.App\/group_sentiment.Sentiment_y\ngroup_sentiment ","7c3fb3a6":"# all categories\ngroup_sentiment.Category[::3]","3d8aa214":"import plotly.graph_objs as go\nimport plotly\nt1 = go.Bar(\n    x=list(group_sentiment.Category[::3]),\n    y= group_sentiment.Fraction[::3],\n    name='Negative',\n    marker=dict(color = 'rgb(150,0,0)')\n)\n\nt2 = go.Bar(\n    x=list(group_sentiment.Category[::3]),\n    y= group_sentiment.Fraction[1::3],\n    name='Neutral',\n    marker=dict(color = 'rgb(220,220,220)')\n)\n\nt3 = go.Bar(\n    x=list(group_sentiment.Category[::3]),\n    y= group_sentiment.Fraction[2::3],\n    name='Positive',\n    marker=dict(color = 'rgb(0,150,0)')\n)\n\ndata = [t1, t2, t3]\nlayout = go.Layout(\n    title = 'Sentiment analysis',\n    barmode='stack',\n    xaxis = {'tickangle': -45},\n    yaxis = {'title': 'Fraction of reviews'}\n)\n\nfig = go.Figure(data=data, layout=layout)\n\nplotly.offline.iplot({'data': data, 'layout': layout})","b0bce901":"# check translated_review from those categories\nmerged_df.loc[merged_df.Category == \"AUTO_AND_VEHICLES\"]['Translated_Review'].sample(5)","cbfd8eb6":"merged_df.loc[merged_df.Category == \"COMICS\"]['Translated_Review'].sample(5)","8be2c483":"merged_df.loc[merged_df.Category == \"EDUCATION\"]['Translated_Review'].sample(5)","e0d77a23":"g1 = go.Box(\n    y=(merged_df['tb_Pol'][merged_df.Type == \"Paid\"]),\n    name = 'Paid',\n     marker = dict(\n        color = 'rgb(30, 50, 140)',\n    )\n    )\n\ng2 = go.Box(\n    y=(merged_df['tb_Pol'][merged_df.Type == \"Free\"]),\n    name = 'Free',\n     marker = dict(\n        color = 'rgb(150, 30, 140)',\n    )\n    )\n\nlayout = go.Layout(\n    title = \"Sentiment Polarity Distribution\",\n    yaxis= {'title': 'tb_Pol'}\n)\ndata = [g2, g1]\nplotly.offline.iplot({'data': data, 'layout': layout})","2249a66c":"sns.set_style('ticks')\nsns.set_style(\"darkgrid\")\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nax = sns.lineplot(x='Size', y='tb_Pol', data=merged_df)\ntitle = ax.set_title('Sentiment Polarity vs Size')","ede93b3b":"sns.set_style('ticks')\nsns.set_style(\"darkgrid\")\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nax = sns.lineplot(x='Price', y='tb_Pol', data=merged_df)\ntitle = ax.set_title('Sentiment Polarity vs Price')","deb5e756":"sns.set_style('ticks')\nsns.set_style(\"darkgrid\")\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nax = sns.barplot(x='Content_Rating', y='tb_Pol', data=merged_df)\ntitle = ax.set_title('Sentiment Polarity vs Content Rating')","524d8ab4":"sns.set_style('ticks')\nsns.set_style(\"darkgrid\")\nfig, ax = plt.subplots()\nfig.set_size_inches(25, 8)\nplt.xticks(rotation=90)\nax = sns.barplot(x='Genres', y='tb_Pol', data=merged_df)\ntitle = ax.set_title('Sentiment Polarity vs Genres')","a0a2253c":"merged_df","15dd49ce":"most_user_reviews = merged_df.groupby('App')[['Translated_Review']].count().sort_values('Translated_Review', ascending=False).head(10)\nmost_user_reviews","6a8e5695":"plt.figure(figsize=(18,10))\nsns.barplot(most_user_reviews.index, most_user_reviews.Translated_Review)\n\nplt.title('Top 10 Apps with largest number of reviews')\nplt.xticks(rotation=90)\nplt.ylabel(None)\nplt.xlabel('Apps')","aed72160":"grouped_sentiment_app_sum = merged_df.groupby(['App']).agg({'Sentiment': 'count'}).reset_index()\ngrouped_sentiment_app_sum","b3501d7c":"grouped_sentiment_app_count= merged_df.groupby(['App', 'Sentiment']).agg({'compound': 'count'}).reset_index()\ngrouped_sentiment_app_count","9fecac73":"group_sentiment_by_app = pd.merge(grouped_sentiment_app_count, grouped_sentiment_app_sum, on=[\"App\"])\ngroup_sentiment_by_app ","b15d5965":"group_sentiment_by_app['Fraction'] = group_sentiment_by_app.compound\/group_sentiment_by_app.Sentiment_y\ngroup_sentiment_by_app ","fd9588e2":"# highest fraction of positive and also have more than 100 comments to filter out app that has very few comments\nmost_pos_feedback = group_sentiment_by_app[(group_sentiment_by_app['Sentiment_x'] == 'pos') & (group_sentiment_by_app['compound'] > 100)].sort_values(by=\"Fraction\", ascending=False).head(10)","1969bf1c":"plt.figure(figsize=(18,10))\nsns.barplot(most_pos_feedback.App, most_pos_feedback.Fraction)\n\nplt.title('Top 10 Apps with the highest fraction of positive feedback')\nplt.xticks(rotation=75);\nplt.ylabel(None);\nplt.xlabel('Apps');","8088de77":"# Sentiment Subjectivity vs Sentiment Polarity","d6a1c60f":"# Sentiment Polarity of Paid vs Free ","9de934e7":"# Using vaderSentiment","78aefdb6":"[Simple Sentiment Analysis for NLP Beginners and Everyone Else using VADER and TextBlob](https:\/\/medium.com\/swlh\/simple-sentiment-analysis-for-nlp-beginners-and-everyone-else-using-vader-and-textblob-728da3dbe33d)","dcc103e4":"# Data Cleaning","bf7a50a5":"# Sentiment Polarity vs Content Rating","7715350c":"*we need to find fraction of sentiment that are positive*","59e25951":"# Sentiment Polarity vs Size","e3bdd2de":"*This user_review dataframe is now ready for analysis*","de3a0724":"# Apps with the most number of user reviews","ba681bab":"# Apps with the most positive feedback","969d19bb":"# import library","f2411c75":"Thank you for viewing this kernel. Any suggestion is appreciated :)","021ddc77":"*now we have the dataframe where each rows have Translated_Review from users*","aa4bf572":"# Merging 2 dataframe","44b873b8":"# numbers of sentiment in each category","8136cefd":"You can also check out my first part of data analytic of Google Play Dataset [Here](https:\/\/www.kaggle.com\/risenattarach\/googleplay-dataanalytics)!","c73e09f3":"*We can see many positive feedbacks there*","697f93d7":"*Categories: auto and vehicles, comics, education--> more positive feedback and less negative feedback than the other categories*","9455c328":"# Prepare 2 dataframes","f00c7b7e":"*users tend to be more satisfy with paid apps*","76639efe":"# Sentiment Polarity vs Price"}}