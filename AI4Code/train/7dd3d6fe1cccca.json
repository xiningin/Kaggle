{"cell_type":{"61d5756c":"code","e7200d69":"code","c519d9d1":"code","771a6051":"code","bcf59862":"code","4b8c4552":"code","9e409115":"code","3d4488ad":"code","eb2cafd2":"code","4263cf40":"code","da9c0614":"code","a577ff61":"code","7928b76c":"code","99988724":"markdown","1b817c6f":"markdown","99bf5082":"markdown","fbed071f":"markdown","53f3b1a0":"markdown","ddae0709":"markdown","0742ed43":"markdown","56564766":"markdown","03f03039":"markdown","a7f04a72":"markdown","ce5ceac0":"markdown","650f2ea5":"markdown","30804b03":"markdown","34ed0be2":"markdown","c88f1f1b":"markdown","aa3cb971":"markdown","b1e0ce94":"markdown","b7ac1c72":"markdown","fbaa1a84":"markdown","04fe5510":"markdown","c4653c72":"markdown","bbf00696":"markdown","8e3af525":"markdown","0cb453c5":"markdown"},"source":{"61d5756c":"import matplotlib.pyplot as plt\n\nx = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n\nplt.scatter(x, y)\nplt.show()","e7200d69":"# lets see this example first . i can expalin u line by line .\nimport numpy\nimport matplotlib.pyplot as plt\n\nx = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n\nmymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n\nmyline = numpy.linspace(1, 22, 100)\n\nplt.scatter(x, y)\nplt.plot(myline, mymodel(myline))\nplt.show()","c519d9d1":"import numpy\nimport matplotlib.pyplot as plt","771a6051":"x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]","bcf59862":"mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))","4b8c4552":"myline = numpy.linspace(1, 22, 100)","9e409115":"plt.scatter(x, y)","3d4488ad":"plt.plot(myline, mymodel(myline))","eb2cafd2":"plt.show()","4263cf40":"import numpy\nfrom sklearn.metrics import r2_score\n\nx = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n\nmymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n\nprint(r2_score(y, mymodel(x)))","da9c0614":"import numpy\nfrom sklearn.metrics import r2_score\n\nx = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\ny = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n\nmymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n\nspeed = mymodel(17)\nprint(speed)","a577ff61":"import numpy\nimport matplotlib.pyplot as plt\n\nx = [89,43,36,36,95,10,66,34,38,20,26,29,48,64,6,5,36,66,72,40]\ny = [21,46,3,35,67,95,53,72,58,10,26,34,90,33,38,20,56,2,47,15]\n\nmymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n\nmyline = numpy.linspace(2, 95, 100)\n\nplt.scatter(x, y)\nplt.plot(myline, mymodel(myline))\nplt.show()","7928b76c":"import numpy\nfrom sklearn.metrics import r2_score\n\nx = [89,43,36,36,95,10,66,34,38,20,26,29,48,64,6,5,36,66,72,40]\ny = [21,46,3,35,67,95,53,72,58,10,26,34,90,33,38,20,56,2,47,15]\n\nmymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n\nprint(r2_score(y, mymodel(x)))","99988724":"<h1>How Does it Work?<\/h1>\n\nPython has methods for finding a relationship between data-points and to draw a line of polynomial regression. We will show you how to use these methods instead of going through the mathematic formula.\n\nIn the example below, we have registered 18 cars as they were passing a certain tollbooth.\n\nWe have registered the car's speed, and the time of day (hour) the passing occurred.\n\nThe x-axis represents the hours of the day and the y-axis represents the speed:","1b817c6f":"Create the arrays that represent the values of the x and y axis:","99bf5082":"<b>Topic<\/b>\n<h1><font color=\"sky blue\">Polynomial<\/font> Regression<\/h1>\n    \nIn statistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x.","fbed071f":"Display the diagram:","53f3b1a0":"<h1><font color=\"sky blue\">Example<\/font> Explained<\/h1>\nImport the modules you need.","ddae0709":"\n<h3>This is the general equation of a polynomial regression is:<\/h3>\n\nY = \u03b8o + \u03b8\u2081X + \u03b8\u2082X\u00b2 + \u2026 + \u03b8\u2098X\u1d50 + residual error","0742ed43":"<h3>Import <font color=\"blue\"> <u>numpy<\/u> <\/font> and <font color=\"blue\"><u>matplotlib<\/u><\/font> then draw the line of Polynomial Regression:<h3>","56564766":"<h1><font color=\"sky blue\">Bad<\/font> Fit Example<\/h1>\nLet us create an example where polynomial regression would not be the best method to predict future values.","03f03039":"The result: <font color=\"red\">0.00995 indicates a very bad relationship<\/font>, and tells us that this data set is not suitable for polynomial regression.","a7f04a72":"Then specify how the line will display, we start at position 1, and end at position 22:","ce5ceac0":"<h3> r-squared value<h3>","650f2ea5":"<h1><font color=\"sky blue\">R<\/font>-Squared<\/h1>\n    \n    It is important to know how well the relationship between the values of the x- and y-axis is, if there are no relationship the polynomial regression can not be used to predict anything.\n\nThe relationship is measured with a value called the r-squared.\n\nThe r-squared value ranges from 0 to 1, where 0 means no relationship, and 1 means 100% related.\n\nPython and the Sklearn module will compute this value for you, all you have to do is feed it with the x and y arrays:","30804b03":"<h1><font color=\"sky blue\">Example<\/font><\/h1>\nHow well does my data fit in a polynomial regression?","34ed0be2":"<h1><font color=\"sky blue\">Predict<\/font> Future Values<\/h1>\nNow we can use the information we have gathered to predict future values.\n\n<h3><font color=\"sky blue\">Example<\/font><\/h3>: Let us try to predict the speed of a car that passes the tollbooth at around 17 P.M: To do so, we need the same mymodel array from the example above:","c88f1f1b":"Draw the original scatter plot:","aa3cb971":"<h2><font color='red'>Disadvantages of using Polynomial Regression<\/font><\/h2>\n\n+ The presence of one or two outliers in the data can seriously affect the results of the nonlinear analysis.<br>\n+ These are too sensitive to the outliers.<br>\n+ In addition, there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.<br>","b1e0ce94":"<h1><font color=\"sky blue\">Example<\/font><\/h1>\nPredict the speed of a car passing at 17 P.M:","b7ac1c72":"mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))","fbaa1a84":"Draw the line of polynomial regression:","04fe5510":"NumPy has a method that lets us make a polynomial model:","c4653c72":"Example\nThese values for the x- and y-axis should result in a very bad fit for polynomial regression:","bbf00696":"The example predicted a speed to be 88.87, which we also could read from the diagram:","8e3af525":"<h2><font color='green'>Advantages of using Polynomial Regression:<\/font><\/h2>\n\n+ Polynomial provides the best approximation of the relationship between the dependent and independent variable.<br>\n+ A Broad range of function can be fit under it.<br>\n+ Polynomial basically fits a wide range of curvature.<br>","0cb453c5":"<font color=\"red\">Note:<\/font> The result 0.94 shows that there is a very good relationship, and we can use polynomial regression in future predictions."}}