{"cell_type":{"1ac569be":"code","1fe0d662":"code","2aba8b5d":"code","f3c1b5c3":"code","70217c87":"code","8e3cc7d5":"code","c0c7eebb":"code","29f5ed51":"code","bc88a274":"code","7b46d59c":"code","cfa348f6":"code","35266819":"code","2317750b":"code","8d02c718":"code","f790f6d0":"code","1d5f0d51":"code","4e8da27e":"code","619999b3":"code","619048ae":"code","bd254f48":"code","56eb4ebc":"code","1bd24d1d":"code","2b59d9ef":"code","48082f71":"code","c6ef2e20":"markdown","d55eb7aa":"markdown","70596594":"markdown","ee489c10":"markdown","ea84e269":"markdown","d692d02d":"markdown","3eaf8067":"markdown","2384b753":"markdown","7aa4bf38":"markdown","fbfa1bd9":"markdown","0d2ab70d":"markdown","3c5fecc9":"markdown"},"source":{"1ac569be":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport gc\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n","1fe0d662":"print(os.listdir(\"..\/input\"))","2aba8b5d":"train_original = pd.read_csv(\"..\/input\/train.csv\")\nstructures_original = pd.read_csv(\"..\/input\/structures.csv\")\ntest_original = pd.read_csv(\"..\/input\/test.csv\")","f3c1b5c3":"train_original.head()","70217c87":"structures_original.head()","8e3cc7d5":"test_original.head()","c0c7eebb":"structures_original[structures_original['molecule_name'] == 'dsgdb9nsd_000015']","29f5ed51":"moleculeCount = structures_original.groupby(by=['molecule_name','atom'])[['atom']].count()\nmoleculeCount.rename(columns={'atom':'count'},inplace = True)\nmoleculeCount = moleculeCount.unstack(fill_value=0)\nmoleculeCount = moleculeCount['count'].reset_index()\n\nmoleculeCount.head()","bc88a274":"moleculeCount[moleculeCount['molecule_name'] == 'dsgdb9nsd_000015']","7b46d59c":"structures = pd.DataFrame.merge(structures_original,moleculeCount\n                               ,how='inner'\n                               ,left_on = ['molecule_name'] \n                               ,right_on = ['molecule_name']\n                              )\n\nstructures.head()","cfa348f6":"tmp_merge = pd.DataFrame.merge(train_original,structures\n                               ,how='left'\n                               ,left_on = ['molecule_name','atom_index_0'] \n                               ,right_on = ['molecule_name','atom_index']\n                              )\n\ntmp_merge = tmp_merge.merge(structures\n                ,how='left'\n                ,left_on = ['molecule_name','atom_index_1'] \n                ,right_on = ['molecule_name','atom_index']\n               )\n\ntmp_merge.drop(columns=['atom_index_x','atom_index_y','C_x','F_x','H_x','N_x','O_x'],inplace=True)\ntmp_merge.columns = ['id' , 'molecule_name' , 'atom_0' , 'atom_1' , 'type' , 'scalar_coupling_constant' , \n                      'atom_nm_0' , 'x_0' , 'y_0' , 'z_0' , 'atom_nm_1' , 'x_1' , 'y_1' , 'z_1','C','F','H','N','O']\n\ntrain = tmp_merge[['id' , 'molecule_name' , 'atom_0' , 'atom_1' , 'type'  , 'atom_nm_0' , 'x_0' ,\n           'y_0' , 'z_0' , 'atom_nm_1' , 'x_1' , 'y_1' , 'z_1','C','F','H','N','O', 'scalar_coupling_constant']]\ntrain.sort_values(by=['id','molecule_name'],inplace=True)\ntrain.reset_index(inplace=True,drop=True)\n\ntmp_merge = None\n\ntrain.head()","35266819":"tmp_merge = pd.DataFrame.merge(test_original,structures\n                               ,how='inner'\n                               ,left_on = ['molecule_name','atom_index_0'] \n                               ,right_on = ['molecule_name','atom_index']\n                              )\ntmp_merge = tmp_merge.merge(structures\n                ,how='inner'\n                ,left_on = ['molecule_name','atom_index_1'] \n                ,right_on = ['molecule_name','atom_index']\n               )\n\ntmp_merge.drop(columns=['atom_index_x','atom_index_y','C_x','F_x','H_x','N_x','O_x'],inplace=True)\ntmp_merge.columns = ['id' , 'molecule_name' , 'atom_0' , 'atom_1' , 'type' ,  \n                      'atom_nm_0' , 'x_0' , 'y_0' , 'z_0' , 'atom_nm_1' , 'x_1' , 'y_1' , 'z_1','C','F','H','N','O']\n\n\ntest = tmp_merge[['id' , 'molecule_name' , 'atom_0' , 'atom_1' , 'type'  , 'atom_nm_0' , 'x_0' ,\n           'y_0' , 'z_0' , 'atom_nm_1' , 'x_1' , 'y_1' , 'z_1', 'C','F','H','N','O']]\n\n\ntest.sort_values(by=['id','molecule_name'],inplace=True)\ntest.reset_index(inplace=True,drop=True)\n\ntmp_merge = None\n\ntest.head()","2317750b":"\ntrain_original = None\ndel train_original\nstructures_original = None\ndel structures_original\ntest_original = None\ndel test_original\nstructures = None\ndel structures\ngc.collect()","8d02c718":"train['dist'] = np.linalg.norm(train[['x_0', 'y_0', 'z_0']].values - train[['x_1', 'y_1', 'z_1']].values, axis=1)\ntest['dist'] = np.linalg.norm(test[['x_0', 'y_0', 'z_0']].values - test[['x_1', 'y_1', 'z_1']].values, axis=1)\n\ntrain.drop(columns=['x_0', 'y_0', 'z_0','x_1', 'y_1', 'z_1'],inplace=True)\ntest.drop(columns=['x_0', 'y_0', 'z_0','x_1', 'y_1', 'z_1'],inplace=True)","f790f6d0":"train['type'] = pd.Categorical(train['type'])\ntrain['atom_nm_1'] = pd.Categorical(train['atom_nm_1'])\ntest['type'] = pd.Categorical(test['type'])\ntest['atom_nm_1'] = pd.Categorical(test['atom_nm_1'])","1d5f0d51":"train.head()","4e8da27e":"test.head()","619999b3":"X = train[['atom_0' ,  'atom_1' , 'type', 'atom_nm_1', 'C' ,  'F' ,  'H' ,  'N' ,  'O' , 'dist' ]]\n\ny = train['scalar_coupling_constant']","619048ae":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.4, random_state=420)","bd254f48":"lgb_train = lgb.Dataset(X_train,y_train,free_raw_data=True)\nlgb_eval = lgb.Dataset(X_test,y_test,free_raw_data=True)","56eb4ebc":"params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 50, \n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0,\n    'num_boost_round':5000,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.3,\n'early_stopping_rounds':5\n         }","1bd24d1d":"gbm = lgb.train(\n    params,\n    lgb_train,\n\n    valid_sets=lgb_eval\n)","2b59d9ef":"y_predict = gbm.predict(X_test)\nmse = np.sqrt(metrics.mean_squared_error(y_predict,y_test))\n\nprint('Mean Squared Error is : '+str(mse))","48082f71":"submission_df = pd.DataFrame(columns=['id', 'scalar_coupling_constant'])\nsubmission_df['id'] = test['id']\nsubmission_df['scalar_coupling_constant'] = gbm.predict(test[['atom_0' ,  'atom_1' , 'type', 'atom_nm_1', 'C' ,  'F' ,  'H' ,  'N' ,  'O' , 'dist' ]])\nsubmission_df.to_csv('submissions.csv', header=True, index=False)\nsubmission_df.head(10)","c6ef2e20":"OK.\n\nAs per above there are total 9 items in molecule dsgdb9nsd_000015.\n\nCarbon - 2\n\nOxygen - 1\n\nHydrogen - 6\n\nTotal items in each molecule can be calculated by simply grouping structures_original dataframe by molecule_name ans atom with count as a aggregate function","d55eb7aa":"* **Sumbission:**","70596594":"How many items are there in dsgdb9nsd_000015?","ee489c10":"Join structures dataframe with train and test data to include item counts in train and test data.","ea84e269":"I am using below kernel to calculate distance between 2 items in a molecule.\n\nhttps:\/\/www.kaggle.com\/seriousran\/just-speed-up-calculate-distance-from-benchmark\n\nThe Frobenius norm is given by [1]:\n\n||A||F = [\\sum{i,j} abs(a_{i,j})^2]^{1\/2}","d692d02d":"Merge moleculeCount dataframe in original structures dataframe.So tha later we can use that for enriching train and test data.","3eaf8067":"* **Accessing Data and Preperaing Data**","2384b753":"* **General Information**\n\nDevelop an algorithm that can predict the magnetic interaction between two atoms in a molecule (i.e., the scalar coupling constant).","7aa4bf38":"* **Model**","fbfa1bd9":"**Importing Libraries**","0d2ab70d":"Lets have a look at some records from each dataframe","3c5fecc9":"We will be using train.csv, test.csv and structures.csv files for our analysis and model preperation.\n\nLets load those files in dataframe."}}