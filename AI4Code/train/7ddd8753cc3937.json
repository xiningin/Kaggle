{"cell_type":{"7fe54a47":"code","4761ee48":"code","2d63796c":"code","3bb9a441":"code","d1fe39b8":"code","b0ecbed3":"code","1ed710df":"code","fd9fe122":"code","d72bae8d":"code","3bf7cd4a":"code","ecd8e408":"code","a6abc936":"code","9eb4a205":"markdown","53589a97":"markdown","e31986d3":"markdown","87a3cef3":"markdown","39c0ff05":"markdown","a95b3e30":"markdown","337c5b3c":"markdown"},"source":{"7fe54a47":"import pandas as pd\nimport numpy as np\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import  tqdm","4761ee48":"%%time\n\ndata_type_dict = {'row_id': 'int64',\n                  'timestamp': 'int64',\n                  'user_id': 'int32',\n                  'content_id': 'int16',\n                  'content_type_id': 'int8',\n                  'task_container_id': 'int16',\n                  'user_answer': 'int8',\n                  'answered_correctly': 'int8',\n                  'prior_question_elapsed_time': 'float32', \n                  'prior_question_had_explanation': 'boolean'}\n\ntrain_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                       low_memory=True,\n                       dtype=data_type_dict,\n                       nrows = 10**7)","2d63796c":"questions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',index_col=0)\nquestions_df = questions_df.fillna(value={'tags':'-1'})\nquestions_df['correct_answer']=questions_df['correct_answer'].astype(np.int8)\nquestions_df['part']=questions_df['part'].astype(np.int8)","3bb9a441":"test_split = True\ntraining_set_ratio = 0.75","d1fe39b8":"if test_split==True:\n    train_df = train_df.merge(pd.DataFrame(train_df.groupby('user_id')['task_container_id'].agg('max')).rename(columns={'task_container_id':'task_container_id_max'}),\n                          left_on='user_id',right_index=True)\n\n\n    train_df['for_training'] = train_df['task_container_id'].values<=training_set_ratio*train_df['task_container_id_max'].values\n\n    train_df = train_df.drop('task_container_id_max',axis=1)\n\n\n    test_df = train_df.loc[~train_df['for_training']]\n    train_df = train_df.loc[train_df['for_training']]\n\n    train_df = train_df.drop('for_training',axis=1)\n    test_df = test_df.drop('for_training',axis=1)","b0ecbed3":"test_df['group_no']=0\n\nout_col_dict = {name:ii for ii,name in enumerate(test_df.columns)}\n\nfor ii in tqdm(range(1,test_df.shape[0])):\n    if (test_df.iat[ii,out_col_dict['user_id']]==test_df.iat[ii-1,out_col_dict['user_id']]):\n        if (test_df.iat[ii,out_col_dict['task_container_id']]!=test_df.iat[ii-1,out_col_dict['task_container_id']]):\n           test_df.iat[ii,out_col_dict['group_no']] = 1 + test_df.iat[ii-1,out_col_dict['group_no']]\n        else:\n            test_df.iat[ii,out_col_dict['group_no']] = test_df.iat[ii-1,out_col_dict['group_no']]\n\n    else:\n        test_df.iat[ii,out_col_dict['group_no']] = (ii\/\/50_000)*100","1ed710df":"columns_index_expected = ['row_id','group_no','timestamp', 'user_id', 'content_id', 'content_type_id',\n                           'task_container_id', 'prior_question_elapsed_time',\n                           'prior_question_had_explanation', 'prior_group_responses',\n                           'prior_group_answers_correct']","fd9fe122":"groups = test_df.groupby('group_no')\n\ngroup_lengths = []\ntest_groups_list = []\nfor ii,frame in tqdm(groups):\n    group_lengths.append([ii,len(frame['user_id'].unique())])\n    test_groups_list.append(frame)\n    \nfor ii in tqdm(range(len(test_groups_list))):\n    test_groups_list[ii]['prior_group_answers_correct'] = np.nan\n    test_groups_list[ii]['prior_group_responses'] = np.nan \n    if ii>0:\n        test_groups_list[ii].loc[test_groups_list[ii].index[0],'prior_group_responses'] = str(list(test_groups_list[ii-1]['user_answer'].values.astype(np.int8)))\n        test_groups_list[ii].loc[test_groups_list[ii].index[0],'prior_group_answers_correct'] = str(list(test_groups_list[ii-1]['answered_correctly'].values.astype(np.int8)))\n        test_groups_list[ii-1].drop(['user_answer','answered_correctly'],axis=1,inplace=True)\n        test_groups_list[ii-1] = test_groups_list[ii-1][columns_index_expected]\n    else:\n        test_groups_list[ii].loc[test_groups_list[ii].index[0],'prior_group_responses'] = str('[]')\n        test_groups_list[ii].loc[test_groups_list[ii].index[0],'prior_group_answers_correct'] = str('[]')\n    \n    \ntest_groups_list[-1] = test_groups_list[-1][columns_index_expected]","d72bae8d":"test_group_counts_df = pd.DataFrame(group_lengths,columns=['group_no','counts'])\n\nfig,ax=plt.subplots(1,1,figsize=(16,8))\nsns.distplot(test_group_counts_df['counts'],ax=ax,kde_kws={\"cut\":3});","3bf7cd4a":"# Intial groups have lots of bundles\n\ntemp = random.choice(test_groups_list[:10])\nprint(f'This Group has {len(temp[\"user_id\"].unique())} bundle\/bundles')\ndisplay(temp)","ecd8e408":"# Last groups have only a few bundles\n\ntemp = random.choice(test_groups_list[-10:])\nprint(f'This Group has {len(temp[\"user_id\"].unique())} bundle\/bundles')\ndisplay(temp)","a6abc936":"for test_group_single in tqdm(test_groups_list):\n        test_group_single = test_group_single.merge(questions_df,how='left',left_on='content_id',right_index=True)\n        test_group_single['timestamp'] = (test_group_single['timestamp']\/\/1000)\n\n        test_group_single['part'] =  test_group_single['part'].fillna(0).astype(dtype=np.int8)\n        test_group_single['bundle_id'] = test_group_single['bundle_id'].fillna(0).astype(dtype=np.uint16)\n        \n        for ii in range(test_group_single.shape[0]):\n            # make predictions here for each user_id or row_id\n            pass","9eb4a205":"## Reading Data\n\nI use only the first 10 million rows to create the simulation","53589a97":"The compeitition host said that the number of bundles in one group of test data would range from 1 to 1000. the simulated data has a few groups that are a bit larger then 1000 but I believe that this wouldn't be much of an issue.","e31986d3":"# Testing Pipeline with Simulation\n\nYou can check how your pipline works on the test groups by editing the content of the for loop below.","87a3cef3":"# Spliting Data for simulation\n\nHere I truncate the the last 25th percentile of task_container_id for creating simulation data ","39c0ff05":"The code below assigns group numbers to the testing data while ensuring that each group only contains a single bundle for any user_id and that the task_container_id increase chronologically with group_no for each user.\n","a95b3e30":"# Introduction:\n\nHere's a technique that I'm using to simulate how my pipeline manages the new test data provided during submission. I've been using it to fine tune the feature engineering (FE) processess to ensure that the piple (including model prediction) on test groups don't take too long. \n\nYou can use this to check how much time your pipeline and model takes to parse the groups during sumbmission.\n\nFeel free to share techniques that have improved your FE pipeline in the comments. \n","337c5b3c":"## Importing libraries"}}