{"cell_type":{"53dbf965":"code","d224e7b3":"code","2b03b4cf":"code","03f7104c":"code","4e3639cb":"code","165ab871":"code","c53a056e":"code","7f0dc088":"code","17d0a20b":"code","aa30ad6d":"code","b5210c01":"code","b5ac2211":"code","baaa1265":"code","a4f22bd4":"code","3231fae8":"code","fab4caaf":"code","254dd051":"code","aaf6679c":"code","7e257e5c":"markdown","9d87cfb7":"markdown","700ece8b":"markdown","bbcc5474":"markdown","9eae0275":"markdown","2ca8765d":"markdown","d17e677b":"markdown","269161c7":"markdown","44fb3be2":"markdown","35ca9553":"markdown","b75f4339":"markdown","1a84f7ca":"markdown","7aa9d078":"markdown","39fcb34f":"markdown","7cbd6e2f":"markdown","c9125404":"markdown","11395679":"markdown","c32061d4":"markdown","ced768b3":"markdown","a008fb7d":"markdown","0b6468d6":"markdown","ec336bfb":"markdown","fae4ce30":"markdown","8cfd2c1e":"markdown","1cfd8174":"markdown","e4a6d157":"markdown","c437b140":"markdown","4dbf57ad":"markdown"},"source":{"53dbf965":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d224e7b3":"import re\n\nimport seaborn as sns\nfrom sklearn.feature_selection import chi2\nimport matplotlib.pyplot as plt","2b03b4cf":"df = pd.read_csv('\/kaggle\/input\/password-strength-classifier-dataset\/data.csv', error_bad_lines=False)\ndf = df.dropna()","03f7104c":"df.head()","4e3639cb":"# Adding column for length of Password \ndf['length'] = [len(i) for i in df['password']]\n\n# Adding column for ratio lowercase character in password\ndf['lower_freq'] = [len([j for j in i if j.islower()]) \/ len(i) for i in df['password']]\n\n# Adding column for ratio uppercase character in password\ndf['upper_freq'] = [len([j for j in i if j.isupper()]) \/ len(i) for i in df['password']]\n\n# Adding column for ratio numeric character in password\ndf['digit_freq'] = [len([j for j in i if j.isdigit()]) \/ len(i) for i in df['password']]\n\n# Adding column for ratio special character in password\ndf['special_freq'] = [len([j for j in i if not j.isdigit() and not j.isalpha()]) \/ len(i) for i in df['password']]","165ab871":"# Adding column for telling if a column has identical features\ndf['identical_freq'] = [(re.match('([a-z\\\\d])\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1+', i) is not None) for i in df['password']]","c53a056e":"chi2(df['identical_freq'].values.reshape(-1, 1), df['strength'].values)","7f0dc088":"df['type_breaks'] = [len(re.findall('[aA-zZ]+',i)) + len(re.findall('[\\W]+', i)) + len(re.findall('[0-9]+', i)) - 1 for i in df['password']]","17d0a20b":"df.describe(include = 'all')","aa30ad6d":"plt.figure(figsize = (16,8))\nax1 = plt.subplot2grid((2, 3), (0, 0))\nax1 = sns.boxplot(x = 'length', data = df)\n\nax2 = plt.subplot2grid((2, 3), (0, 1))\nax2 = sns.boxplot(x = 'lower_freq', data = df)\n\nax3 = plt.subplot2grid((2, 3), (1, 0))\nax3 = sns.boxplot(x = 'digit_freq', data = df)\n\nax4 = plt.subplot2grid((2, 3), (1, 1))\nax4 = sns.boxplot(x = 'upper_freq', data = df[df['upper_freq'] > 0])\n\nax5 = plt.subplot2grid((2, 3), (0, 2))\nax5 = sns.boxplot(x = 'special_freq', data = df[df['special_freq'] > 0])\n\nax6 = plt.subplot2grid((2, 3), (1, 2))\nax6 = sns.boxplot(x = 'type_breaks', data = df[df['type_breaks'] > 0])","b5210c01":"from IPython.display import display\n\ncols = ['length', 'lower_freq', 'upper_freq', 'digit_freq', 'special_freq']\n\nfor i in cols:\n    print(i)\n    display(df[df[i] > 0].groupby('strength')[i].agg(['max', 'min', 'mean', 'median', pd.Series.mode]))","b5ac2211":"sns.countplot(x = 'strength', data = df)\nplt.plot()\n\nprint(df['strength'].value_counts(),'\\n\\n\\n')","baaa1265":"plt.figure(figsize = (16,16))\nax1 = plt.subplot2grid((3, 3), (0, 0))\nax1 = sns.histplot(x = 'length', data = df, bins=50)\n\nax2 = plt.subplot2grid((3, 3), (0, 1))\nax2 = sns.histplot(x = 'lower_freq', data = df)\n\nax3 = plt.subplot2grid((3, 3), (1, 0))\nax3 = sns.histplot(x = 'digit_freq', data = df)\n\nax4 = plt.subplot2grid((3, 3), (1, 1))\nax4 = sns.histplot(x = 'upper_freq', data = df[df['upper_freq'] > 0])\n\nax5 = plt.subplot2grid((3, 3), (0, 2))\nax5 = sns.histplot(x = 'special_freq', data = df[df['special_freq'] > 0])\n\nax6 = plt.subplot2grid((3, 3), (1, 2))\nax6 = sns.histplot(x = df[df['special_freq'] > 0]['special_freq'].apply(np.log))  # Log Transformation\n\nax7 = plt.subplot2grid((3, 3), (2, 0), colspan = 3)\nax7 = sns.histplot(x = 'type_breaks', data = df, bins=50)","a4f22bd4":"sns.countplot(x = 'identical_freq', data = df)\nplt.plot()\n\nprint(df['identical_freq'].value_counts(),'\\n\\n\\n')","3231fae8":"plt.figure(figsize = (10, 8))\nsns.heatmap(df.corr(), annot = True)\nplt.plot()","fab4caaf":"plt.figure(figsize = (20,12))\nax1 = plt.subplot2grid((2, 4), (0, 0))\nax1 = sns.boxplot(x = df['strength'], y = df['length'], showfliers = False)   # showfliers = False doesn't plot outliers, too messy to infer anything so switched off.\n\nax2 = plt.subplot2grid((2, 4), (0, 1))\nax2 = sns.boxplot(x = 'strength', y = 'lower_freq', data = df[df['lower_freq'] > 0])\n\nax3 = plt.subplot2grid((2, 4), (1, 0))\nax3 = sns.boxplot(x = 'strength', y = 'upper_freq', data = df[df['upper_freq'] > 0])\n\nax4 = plt.subplot2grid((2, 4), (1, 1))\nax4 = sns.boxplot(x = 'strength', y = 'digit_freq', data = df[df['digit_freq'] > 0])\n\nax5 = plt.subplot2grid((2, 4), (0, 2))\nax5 = sns.boxplot(x = 'strength', y = 'special_freq', data = df[df['special_freq'] > 0])\n\nax6 = plt.subplot2grid((2, 4), (1, 2))\nax6 = sns.boxplot(x = 'strength', y = 'type_breaks', data = df[df['type_breaks'] > 0])\n\nax7 = plt.subplot2grid((2, 4), (0, 3), rowspan = 2)\nax7 = sns.boxplot(x = df['strength'], y = df['length'])\nax7 = plt.ylim(0,70)","254dd051":"chi2(df['identical_freq'].values.reshape(-1, 1), df['strength'].values)","aaf6679c":"plt.figure(figsize = (24,16))\ncols = ['length', 'lower_freq', 'upper_freq', 'digit_freq', 'special_freq', 'type_breaks']\nm, n = 0, 0\ns = set()\n\nfor i in cols:\n    for j in cols:\n        if (i, j) in s or (j, i) in s or i == j:\n            continue\n        \n        ax = plt.subplot2grid((3, 5), (m, n))\n        ax = sns.scatterplot(x = i, y = j, hue = 'strength', data = df)\n        s.add((i, j))\n        \n        n += 1\n        if n == 5:\n            n = 0\n            m += 1\nplt.plot()","7e257e5c":"### **Continous-Continuous**","9d87cfb7":"Here you take a look at how multiple feature collectively behave check if there is any clusters being formed or range dependant class distribution being followed. Depending on tasks you can check many things but these are the basic ones you should be looking at.","700ece8b":"Phew! That amount of split only gets one verdict from my side i.e. DELETE DELETE DELETE. This is why it becomes important to check frequency of categorical variable not just to check no. of class but also how they are distributed and in these only you can ask various questions and get their answers.","bbcc5474":"**How did I come up with that particular feature?**\n\nIt wasn't a rocket science I knew that identical sequences affect the strength of password so I found the regex to match the identical sequence with repetition of 2 or more but the p-values were very very low, I talking somewhere around 1e-238. Yea I know xD. My intial response was to dump it but then I thought *what if I increase the threshold of repetition?*. I tried for 3,4,5,6.. until the df gave all False. I noted chi2 of all and found that  for repetition of 7 or more the p value was more than 0.05 so I set that as threshold and created that feature. Weather this feature is useful or not will be tested via Random Forest Feature Importance or other methods and at that time it's fate will be decide.\n\n> To be or not to be? Is the question.","9eae0275":"EDA or Exploratory Data Analysis is a process of understanding the data often to give birth to new features or simply for the purpose to understand the behavior of various features. Now for me EDA and Feature Engineering go hand in hand I may have written the Feature Generation part before this but when working on feature generation I always vizualize and run tests on the generated feature to validate it and add to the feature matrix. \n\nWhen I was getting started with EDA I had no idea how to proceed or what to do? But steady as I accustomed myself with Basic Statistics I started to understand why we do it and what should we do. I you ask me EDA is all about asking questions to the data. What is your distribution? How to you behave w.r.t. another feature? There is no end to the list and there is no end to what you can find with EDA.\n\nEDA is all about asking smart questions but to get started you can use the following pipeline(for categorical target):-\n\n1. **Descriptive Statistics:** Reading Basic Summary Stats to get the vague idea about data distribution To Vizualize you can use Box-Plots, Violin Plots etc.\n2. **Agrregated Descriptive Statistics:** Basic Summary Stats of Features when grouped w.r.t. target to understand the distribution of data among each class. This can make you understand how the values of the feature are distributed among target classes. Kinda like boxplot except outliers are included in calculation\n3. **Univariate Analysis:** Understanding the distribution or class count of the features. The step 1 is a part of Univariate Analysis. Here you can visualize your distribution check out frequency of class in a feature getting basic layout of your features. Histogram, KDE, countplots etc. can be used to vizualize this.\n4. **Bivariate Analysis:** Understanding the behavior of feature w.r.t. other feature(usually target). Now usually the combos and their corresponding plots are:-\n      * **Continuous-Continuous:** Correlation among them can be told by pearson coefficient, you can vizualize that using Heatmaps. You can build scatter plots to vizualize how they move w.r.t. to each other. \n      * **Continuous-Categorical:** Finding how features are splitted over categorical features (I do it just with Target but depending on questions you want answer to you can try it among the features too). Box-Plot, Violin Plot, Strip Plot etc. can be used to vizualize this relationship.\n      * **Categorical-Categorical:** This is the most interesting one, in order to understand if 2 categorical features(usually target being one of them) are dependent on each other you can try using chi-square. To vizualize you can use countplots with target variable as hue what you get from that is basically the same as step 2 so I often don't do it but plots are easier to explain so no reason not to.\n5. **Multivariate Analysis:** Behavior of features w.r.t. multiple features. To vizualize this you can use Joint Plots, Pair Plots or scatter plots with categorical feature(usually target) as hue. 3d scatter plots are an option too but I find them hard to interpret so I avoid them.\n\nThat's a pipeline that you can follow to get started and given the data you can modify it and try other stuff too. Now one question you may ask is that if we have data from step 2 why should I vizualize it with box plots or whatever. Answer to that is **Anscombe's Quartet**. Anscombe's Quartet gives an important lesson i.e. numerical data can be misleading. There are many things you can't check in these Descriptive Stats like effect of outliers, high leverage points, etc. Hence, it is important to vizualize and the fact that graphs are easier to explain to people.","2ca8765d":"Hmm, that's an chi2 stats with value 5.91 for a p-value of 0.052. For those who don't understand it I'm saying that the feature **identical_freq** and target variable are dependent on each other. How can I say that? Well in any test if we take the usual significance level of 0.05 then,\n\n* **p-value < 0.05:** Reject Null Hypothesis for Alternative Hypothesis\n* **p-value >= 0.05:** Fail to reject the Null Hypothesis\n\nSince value the p value we got is more than 0.05 we can reject the Null Hypothesis for Alternative Hypothesis of chi square that says that **\"Both Variables are dependent\"**. Weather this is useful or not we'll check soon.","d17e677b":"## **Multivariate Analysis**","269161c7":"# **Exploratory Data Analysis**","44fb3be2":"Whenever I see a data I don't magically expect the features to get generated on their own or randomly pop up in my mind. The first step I take to generate new features is to understand the factors target variable depends on. Now in this case, we have password strength so you can do a quick google search to check what features password depends on:-\n\n* Length of password\n* Frequency of Lowercase Characters\n* Frequency of Uppercase Characters\n* Frequency of Numeric Characters\n* Frequency of Special Characters\n\nThese will be the result of the google search to find factors effecting strength of password. But thing to understand is won't it be more insightful to check the frequency of characters with respect to length? I length is long frequency will be high but you can instead measure a proportion to get an idea about the distribution of the characters in the password.","35ca9553":"If you search a bit more into the factors affecting you'll find 2 feature that affect the strength of password are:-\n\n* Consecutive Sequence i.e. abc, 123 etc.\n* Identical Sequences i.e. aaaa, bbb, etc.\n\nLet's create a column that tells if there is a identical sequence or not.","b75f4339":"I know I did this above but this is just to explain. Try doing chi2 for categorical columns to check for independancy. Usually I do this when I have categorical target but give the situation you can try it among feature. Remember kaggle and real life analysis are different.\n\nYou can also try hued count plots but in this case **True** data is so less we won't get any proper insights and if you aren't getting insights there is no point plotting it.","1a84f7ca":"Just taking a rough look at the above data I can say the following:-\n* Higher the length, Higher the strength\n* In case on alphabet frequency higher is not better. Probably because it'll not be a strong password if max portion is occupied by just alphabets.\n* Password has more strength if the char types are spread in decent proportions.","7aa9d078":"### **Checking Class Imbalance**","39fcb34f":"* Length and Strength show high correlation not much of a surprise there.\n* identical_freq is least correlated to strength, probably gonna get removed.\n* lower_freq, upper_freq and type_breaks are a bit correlated to strength.\n\nYou can go ahead add a pair-pair plot or something else but I got the answers to most of the questions from this so not going forward. But that doesn't mean there isn't anything more. Different Situation require different EDA.","7cbd6e2f":"Wow that's quite a bit of imbalance among the target classes but thing to know it was purpose does knowing or checking imbalance solve for us? Thing is class imbalance affects the model performance quite a bit so if you try to train the model without tackling this issue you might end up getting a model that's biased towards the majority class so you need to tackle the issue accordingly and hence it becomes important not only to check imbalance but also to know how much imbalance is there.","c9125404":"### **Continuous Variables**","11395679":"### **Categorical Variables**","c32061d4":"### **Categorical-Categorical**","ced768b3":"# Feature Generation\n![maxresdefault (1)-min.jpg](attachment:5a54b85f-b364-432e-ae58-59757d7c6f1e.jpg)","a008fb7d":"## **Univariate Analysis**","0b6468d6":"I usually go for histograms when doing univariate analysis now here you can get the idea about:-\n* **Skewness of Data:** Once you know this you can apply various transformations and use the one that gives the best results. Tackling skewness is important cuz many statistical models(like linear regression) and test work on the assumption of normally distributed data. But Skewness doesn't effect tree based models so based on the task you can decide if you need to tranform it to normal distribution or not.\n* **Data Distribution:** Tells you what bins are of higher range or lower range one example is if you are doing a customer base analysis you can check what age range most customer belongs too or a more common example is if you have text data you can plot length histograms and check the suitable max_length to pad or truncate.\n\nYou can see the (2,3)th plot shows special_freq data after log tranformation I tried square root and cube root transformation too and visualized them but log came to be the best so chose that. This is one of many uses of histograms.","ec336bfb":"## **Bivariate Analysis**","fae4ce30":"Outliers seem to be having fun don't they? From above plot and table you can get a general overview of distribution of the data in each feature. The outliers and the quartile range is there but do we get anything that would provide any insight the table wouldn't have? In my opinion no, the table pretty much told everything and that is why unless I plan showcase I don't usually go on plotting every plot I see. There are two type of approaches:-\n\n* **Plotting for the sake of Plotting:** Lots of Plot but Less on Info.\n* **Plotting for the sake of extraction:** Apt amount of plot but each plot serves a putpose.\n\nBe the better person.","8cfd2c1e":"### **Categorical-Continous**","1cfd8174":"## **Agrregated Descriptive Statistics**","e4a6d157":"## **Descriptive Statistics**","c437b140":"Now this is one of the things that randomly poped up in my mind after learning about the above 2 features is that password is not just depending on the characters in it but also the ordering so I thought that maybe it depends on the no. of groups two like how mixed up these character groups are. For eg, abc12 is not so good but a1b2c is better. How am I sure? See for yourself.\n\n![image.png](attachment:a0a6ec47-80b7-4eb8-a2c9-6eacfce60876.png)\n![image.png](attachment:97366c5b-9141-4448-979b-57f7e5c0a743.png)\n\nCredits: https:\/\/www.my1login.com\/resources\/password-strength-test\/\n\nThat's why I wrote a regex to find all the groups and added the no. of the groups to create the feature **type_breaks**.\n\nSo what happens when you are out of ideas? Simple Answer!\n\n![apes-min.jpg](attachment:393821d4-b05f-4dd0-a4cc-9b2ed4dc7f72.jpg)\n\nWhat I mean to say is when you are stuck take help, **checkout notebooks of other people, ask your mentor or google**. ","4dbf57ad":"Although I don't have much favorites when it comes plots, whatever gets the job done is fine, but if I had one Boxplot would be it. I mean the amount of information that single plot conveys is mind blowing. You get info about outliers, quartiles, median well technically 2nd quartile is median but you get the gist. Now these stuff can bee seen without boxplot but by visualizing them you can clearly check out the trend and splits if any and better interpret. Plotting is a part of pipeline but it's not the pipeline itself. \n\nRegarding the insights we can say that:-\n* We can say that strength can be solely determined based on length since it gives a perfect split. That would be the best feature then but logically that doesn't sound correct because when I ran 2 password of same length over checker they gave 2 different level. Now I understand the logic they use is different and for this data length is the best but of larger scale things might be iffy. But yes longer passwords have more strength so given the circumstance we might even just use length based classification or use it as primary feature.\n\n![image.png](attachment:6c5270f7-2fb4-4e26-afff-04815cf319b7.png)\n![image.png](attachment:304dc9d8-0c1c-4e83-ae3f-0f903b317593.png)\n\n* Higher Lowercase frequency is seen in low strength passwords. For higher strength passwords that can be high too but that is probably effect of length.\n* In upper_freq there is a trend but not as strong as length or lower_freq.\n* In digit_freq there is a split of majority poplutation of strength 1 and 2 but for 0 and 1 strength there is overlap so no tmuch to say there. But we can say a nicely propotioned password is good.\n* Similar but stronger same trend as above in special_freq.\n* Higher strength passwords have more type breaks."}}