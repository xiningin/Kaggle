{"cell_type":{"7ef2fe9c":"code","22fead77":"code","75b265e0":"code","4061f80c":"code","ee911ef4":"code","10e22b2e":"code","c0d3675e":"code","4f6ff4bc":"code","6d2c3ea0":"code","60592fa3":"code","8a375c2d":"code","e9927c21":"code","86f82887":"code","221adbb5":"code","fd0c8f64":"code","ccdc7151":"code","54180718":"code","d4046313":"code","aa96b7b9":"code","5bda5206":"code","6a6100e0":"code","12a56efa":"code","bdbfa12a":"code","5e30f3db":"code","38621db2":"markdown","c5141cfd":"markdown","b3202cc9":"markdown","fe8a9a41":"markdown","f544b9ec":"markdown","f1b23216":"markdown","1eec5551":"markdown"},"source":{"7ef2fe9c":"import numpy as np \nimport pandas as pd\n\nimport random\nimport datetime\nimport seaborn as sns\n\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Dense,Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom keras.losses import binary_crossentropy\nfrom keras import regularizers, optimizers\nfrom keras.optimizers import Adam\n\nfrom keras.applications import ResNet50\n#from keras.applications.resnet_v2 import ResNet50V2\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.nasnet import NASNetMobile\n\n\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger,ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndef append_ext(fn):\n    return fn+\".png\"\n\ndef remove_ext(fn):\n    return fn[:-4]","22fead77":"# Set a seed value\nseed_value= 7 \n\n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nos.environ['PYTHONHASHSEED']=str(seed_value)\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nrandom.seed(seed_value)\n# 3. Set `numpy` pseudo-random generator at a fixed value\nnp.random.seed(seed_value)\n# 4. Set `tensorflow` pseudo-random generator at a fixed value\ntf.set_random_seed(seed_value)\n# 5 Configure a new global `tensorflow` session\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)","75b265e0":"train_labels=pd.read_csv('..\/input\/imet-2019-fgvc6\/train.csv', dtype=str)\n#Changing the attribute ids into lists instead of str seperated by a ' ' to be able to count them\ntrain_labels['attribute_ids']=train_labels['attribute_ids'].str.split(' ')\ntrain_labels[\"id\"]=train_labels[\"id\"].apply(append_ext)\n\ntest_labels=pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv', dtype=str)\ntest_labels[\"id\"]=test_labels[\"id\"].apply(append_ext)\n\nprint('train : \\n', train_labels.head())\nprint('\\ntest : \\n', test_labels.head())\n\nprint('\\ntrain shape: ', len(train_labels))\nprint('\\ntest shape: ', len(test_labels))","4061f80c":"labels = pd.read_csv('..\/input\/imet-2019-fgvc6\/labels.csv', dtype=str)\nprint('labels : ', '\\n', labels.head())\n\nprint('\\nlabels len :', len(labels))","ee911ef4":"datagen=ImageDataGenerator(rescale=1.\/255.,validation_split=0.2)","10e22b2e":"B_size = 128\nTarget_size = (96,96) \n\ntrain_generator=datagen.flow_from_dataframe(\n                                            dataframe=train_labels,\n                                            directory=\"..\/input\/imet-2019-fgvc6\/train\/\",\n                                            x_col=\"id\",\n                                            y_col=\"attribute_ids\",\n                                            subset=\"training\",\n                                            batch_size=B_size,\n                                            seed=seed_value,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=Target_size\n)\n\nvalid_generator=datagen.flow_from_dataframe(\n                                            dataframe=train_labels,\n                                            directory=\"..\/input\/imet-2019-fgvc6\/train\/\",\n                                            x_col=\"id\",\n                                            y_col=\"attribute_ids\",\n                                            subset=\"validation\",\n                                            batch_size=B_size,\n                                            seed=seed_value,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=Target_size\n)\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255.)\n\ntest_generator=test_datagen.flow_from_dataframe(\n                                                dataframe=test_labels,\n                                                directory=\"..\/input\/imet-2019-fgvc6\/test\/\",\n                                                x_col=\"id\",\n                                                y_col=None,\n                                                batch_size=B_size,\n                                                seed=seed_value,\n                                                shuffle=False,\n                                                class_mode=None,\n                                                target_size=Target_size\n)","c0d3675e":"train_generator.n\/\/train_generator.batch_size","4f6ff4bc":"gamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","6d2c3ea0":"def f2_score(y_true, y_pred):\n    beta = 2\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n    \n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    \n    return K.mean(((1+beta**2)*precision*recall) \/ ((beta**2)*precision+recall+K.epsilon()))","60592fa3":"#Callbacks\n\ncheckpoint = ModelCheckpoint(filepath='weights_test.hdf5',\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          mode='auto')","8a375c2d":"def make_model(model_choice, model_name, input_tensor, weights_link, nb_epoch):\n    '''Function to create a model\n    Input:\n    - model_choice          for ex: VGG19(include_top=False, input_tensor=input_tensor)\n    - model_name            (str), name that will be given to the model in tensorboard\n    - input_tensor          Input(width_image, height_image, nb_channels)\n    - weights_link          (str) since no internet, link to the dataset with weights\n    - nb_epoch              (int) number of epoch to train on\n    \n    Output:\n    - model made with keras.model.Model'''\n    \n    base_model = model_choice\n    base_model.load_weights(weights_link)\n    base_model.trainable = False\n    x = base_model.output\n    out = Flatten()(x)\n    out = Dense(1103, activation=\"softmax\")(out)\n    model = Model(input_tensor, out)\n    \n    model.compile(optimizer=Adam(0.001), loss=focal_loss, metrics=[f2_score])\n    #model.summary()\n    \n    history = model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=nb_epoch,\n                    callbacks=[checkpoint, earlystop])\n\n    \n    return model, history","e9927c21":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size","86f82887":"number_epoch = 15\nwidth, height = Target_size\ninput_tensor = Input((width, height, 3))\n\nweights_link = ('..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n\nInceptionResNetV2_model, history = make_model(InceptionResNetV2(weights=None,\n                                                       include_top=False,\n                                                       input_tensor=input_tensor),\n                                              'InceptionResNetV2',\n                                              input_tensor,\n                                              weights_link,\n                                              nb_epoch = number_epoch)","221adbb5":"model_name = 'InceptionResNetV2'\n\nfig, ax =plt.subplots(1,2, figsize=(15, 8))\n    \nax[0].plot(history.history['f2_score'])\nax[0].plot(history.history['val_f2_score'])\nax[0].set_title(model_name +  ' Model F2 score')\nax[0].legend([model_name +  ' Training',model_name +  ' Validation'])\n#ax[0].ylabel('F2 score')\n#ax[0].xlabel('epoch')\n    \nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title(model_name +  ' Model loss')\nax[1].legend([model_name +  ' Training',model_name +  ' Validation'])\n#ax[1].ylabel('Loss')\n#ax[1].xlabel('epoch')","fd0c8f64":"test_generator.reset()\npred=InceptionResNetV2_model.predict_generator(test_generator,\nsteps=STEP_SIZE_TEST+1,\nverbose=1)","ccdc7151":"max_of_each_img=[]\nfor i in range(len(pred)):\n    max_of_each_img.append(pred[i].max())\nsns.distplot(max_of_each_img)","54180718":"threshold_count = 0.03\n\nnb_label_over_thresh_of_each_img=[]\nfor i in range(len(pred)):\n    nb_labels = 0\n    for prediction in range(len(pred[i])):\n        if pred[i][prediction]>=threshold_count:\n            nb_labels+=1\n    nb_label_over_thresh_of_each_img.append(nb_labels)\nsns.distplot(nb_label_over_thresh_of_each_img)\nprint('threshhold used is: ', threshold_count)\nprint('There are {} images without labels'.format(nb_label_over_thresh_of_each_img.count(nb_label_over_thresh_of_each_img==0)))","d4046313":"import operator\n\nthreshold = 0.03\n\nlabel_for_test_img = []\nfor i in range(len(pred)):\n    #list to store the label number over the threshold\n    label_number={}\n    for prediction in range(len(pred[i])):\n        if pred[i][prediction]>=threshold:\n            label_number[prediction] = prediction\n    sorted_label_number = sorted(label_number.items(), key=operator.itemgetter(1), reverse=True)\n    label_for_test_img.append([i[0] for i in sorted_label_number[:5]])\n#    print('for image {} labels are: {}'.format(i, label_number))\n\nlabel_for_test_img[:10]","aa96b7b9":"valid_generator.reset()\npred_valid=InceptionResNetV2_model.predict_generator(valid_generator,\n                                   steps=STEP_SIZE_VALID+1,\n                                   verbose=1)","5bda5206":"label_for_valid_img = []\nfor i in range(len(pred_valid)):\n    #list to store the label number over the threshold\n    label_number={}\n    for prediction in range(len(pred_valid[i])):\n        if pred_valid[i][prediction]>=threshold:\n            label_number[prediction] = prediction\n    sorted_label_number = sorted(label_number.items(), key=operator.itemgetter(1), reverse=True)\n    label_for_valid_img.append([i[0] for i in sorted_label_number[:5]])\n#    print('for image {} labels are: {}'.format(i, label_number))\n\nlabel_for_valid_img[:10]","6a6100e0":"test_labels[\"id\"]=test_labels[\"id\"].apply(remove_ext)","12a56efa":"test_list = pd.Series([list(x) for x in label_for_test_img])\ntest_str = test_list.apply(lambda x: [str(i) for n,i in enumerate(x)])\ntest_str = test_str.apply(lambda l: ' '.join(l))","bdbfa12a":"results=pd.DataFrame({\"id\":test_labels[\"id\"],\n                      \"attribute_ids\":test_str})\nresults.to_csv(\"submission.csv\",index=False)","5e30f3db":"results.head()","38621db2":"Updates to do to improve performances:\n- take into account different image sizes\n- perform data augmentation (but not all images can be augmented the same way. Ex: portrait cannot  be flipped vertically. Some abstract objects \/ representations could).","c5141cfd":"pred is of shape  7443 x 1103: 7443 test examples, and 1103 different labels.\n\nNext step: apply threshold, if over a certain threshold, then consider it as a label. Otherwise, not.","b3202cc9":"v1: last activation changed to softmax","fe8a9a41":"The EDA is done in a [separate Kernel](https:\/\/www.kaggle.com\/maxlenormand\/first-eda-to-get-started)\n\nThis is the first iterations I am doing, simply to have a relevant predicted output. Future work will consist of improving this along multiple aspects.","f544b9ec":"focal loss taken from [this Kernel from KeepLearning](https:\/\/www.kaggle.com\/mathormad\/resnet50-v2-keras-focal-loss-mix-up)","f1b23216":"In order to compare the performances of models, it is important to seed everything. This means random and numpy, but also tensorflow and Keras. The following code was taken from [this article](https:\/\/towardsdatascience.com\/properly-setting-the-random-seed-in-machine-learning-experiments-7da298d1320b) from Cecelia Shao. The article is worth a read for a more in depth look of the effects of correctly seeding.","1eec5551":"f2_score taken from [this Kernel from Alexander Teplyuk](https:\/\/www.kaggle.com\/ateplyuk\/keras-starter)"}}