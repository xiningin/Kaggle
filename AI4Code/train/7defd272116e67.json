{"cell_type":{"b7aaedfb":"code","04e03203":"code","b1f6331f":"code","5f836bd8":"code","79df4f9e":"code","af6fd3b2":"code","3cab297a":"code","15c282a5":"code","7c8719f7":"code","5c19627f":"code","f352daf0":"code","e37fcce3":"code","27b156c0":"code","408cc1e5":"code","fa968c45":"code","b7de2fa0":"code","689da887":"code","a6658b06":"code","1ffbc318":"code","2ff8532e":"code","1e718287":"code","55742040":"code","19175867":"code","4fd3e366":"code","0b5fc40d":"code","4d3f6403":"code","b588396c":"code","9438a45e":"code","55026028":"code","200f2e8c":"code","ed0653b9":"code","8fa2230a":"code","ef5d6539":"markdown","63080ea7":"markdown","3cf73ceb":"markdown","ed56f257":"markdown","00003346":"markdown","7cb676c8":"markdown","61b8a989":"markdown","9f622820":"markdown","71be5bdc":"markdown","1a1076a5":"markdown","9b124c37":"markdown","f5f44a88":"markdown","2a813e09":"markdown","b7df3b61":"markdown","3730d736":"markdown","76266880":"markdown","617940ba":"markdown"},"source":{"b7aaedfb":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')","04e03203":"data=pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","b1f6331f":"data.head()","5f836bd8":"data.info()","79df4f9e":"data.drop(\"id\",axis=1,inplace=True)","af6fd3b2":"data.describe()","3cab297a":"print(\"Unique Values per Variable\")\nfor col in data.columns:\n    un=data[col].unique()\n    print(\"\\n\\nUnique Values in {}:\\n{}\".format(col,un))","15c282a5":"(data[\"gender\"]==\"Other\").sum()","7c8719f7":"data[data[\"gender\"]==\"Other\"]","5c19627f":"data=data.drop(3116,axis=0)","f352daf0":"data.iloc[3114:3118,:]","e37fcce3":"index=[i for i in range(data.shape[0])]\ndata.index=index\ndata.iloc[3114:3118,:]","27b156c0":"from category_encoders.target_encoder import TargetEncoder","408cc1e5":"enc=TargetEncoder()\nto_encode=\"work_type\"\nenc.fit(X=data[to_encode],y=data[\"stroke\"])\nencoded = enc.transform(data[to_encode])","fa968c45":"data[\"work_type\"] = encoded[\"work_type\"]","b7de2fa0":"data[[\"ever_married\",\"Residence_type\",\"gender\"]]=pd.get_dummies(data[[\"ever_married\",\"Residence_type\",\"gender\"]],drop_first=True)","689da887":"data.head()","a6658b06":"print(\"Proportions of 'smoking' categories:\")\ndata[\"smoking_status\"].value_counts()\/data.shape[0]","1ffbc318":"smoking_mapper={\"never smoked\":0,\"formerly smoked\":1,\"smokes\":2,\"Unknown\":np.nan}","2ff8532e":"for i in range(data.shape[0]):\n    status=data[\"smoking_status\"][i]\n    data[\"smoking_status\"][i]=smoking_mapper[status]","1e718287":"data[\"smoking_status\"].unique()","55742040":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import RandomForestRegressor","19175867":"estimator=RandomForestRegressor(max_depth=8)\nmice = IterativeImputer(estimator=estimator,random_state=11,skip_complete=True)","4fd3e366":"impdata=mice.fit_transform(data)","0b5fc40d":"impdata=pd.DataFrame(impdata,columns=data.columns)","4d3f6403":"impdata.isnull().sum()","b588396c":"impdata.head()","9438a45e":"for i in range(impdata.shape[0]):\n    if impdata.loc[i,\"smoking_status\"]<0.5:\n        impdata.loc[i,\"smoking_status\"]=0\n    elif impdata.loc[i,\"smoking_status\"] <1.5:\n        impdata.loc[i,\"smoking_status\"]=1\n    else:\n        impdata.loc[i,\"smoking_status\"]=2","55026028":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('seaborn-darkgrid')","200f2e8c":"fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(16,10))\nfig.suptitle(\"Effect of MICE on Distributions\\n\",fontsize=25)\nsns.histplot(x=data[\"bmi\"],ax=axes[0,0],color=\"mediumspringgreen\")\naxes[0,0].set_title(\"BMI before MICE\")\naxes[0,0].set_xlabel(None)\nsns.histplot(x=impdata[\"bmi\"],ax=axes[0,1],color=\"mediumspringgreen\")\naxes[0,1].set_title(\"BMI after MICE\")\naxes[0,1].set_xlabel(None)\nsns.countplot(x=data[\"smoking_status\"],ax=axes[1,0],palette=\"cool\")\naxes[1,0].set_title(\"Smoking Status before MICE\")\naxes[1,0].set_xlabel(None)\nsns.countplot(x=impdata[\"smoking_status\"],ax=axes[1,1],palette=\"cool\")\naxes[1,1].set_title(\"Smoking Status after MICE\")\naxes[1,1].set_xlabel(None)\nplt.show()","ed0653b9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nrf=RandomForestClassifier(n_jobs=-1,max_depth=7)\nx=impdata.drop('stroke',axis=1)\ny=impdata[\"stroke\"]","8fa2230a":"xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2, random_state=2)\nrf.fit(xtrain,ytrain)\ny_pred_tr=rf.predict(xtrain)\ny_pred_ts=rf.predict(xtest)\ntrain_mat=classification_report(ytrain,y_pred_tr)\ntest_mat=classification_report(ytest,y_pred_ts)\nprint(\"Baseline Random Forest Results:\")\nprint(\"Training Classification_Report:\\n{}\".format(train_mat))\nprint(\"Testing Classification_Report:\\n{}\".format(test_mat))","ef5d6539":"**Hello and welcome**.  \n\n**This is part 1 to a 3-kernel project on Stroke Prediction.**\n\n  \n**Part 1 (which is this one) is Preprocessing: Data Cleaning, Encoding and MICE for missing values**  \n  \n**Part 2 is EDA (including UMAP and PCA) and Random Oversampling**  \nLink: **https:\/\/www.kaggle.com\/mahmoudlimam\/stroke-eda-umap-resampling**\n\n  \n**Part 3 is Detailed Feature extraction and Selection, and model evaluation**  \nLink: **https:\/\/www.kaggle.com\/mahmoudlimam\/stroke-pca-ica-lda-kmeans-dbscan-prediction** \n\nI didn't include a hyperparameter tuning section as Feature Engineering in an F1_Score of 1 with a somewhat deep Random Forest.","63080ea7":"# Pre-processing","3cf73ceb":"### Encoding","ed56f257":"# **Stroke Pre-Processing: MICE & Encoding**","00003346":"\u0627\u0644\u062d\u0645\u062f \u0644\u0644\u0647 \u0627\u0644\u0630\u064a \u0628\u0646\u0639\u0645\u062a\u0647 \u062a\u062a\u0645 \u0627\u0644\u0635\u0627\u0644\u062d\u0627\u062a","7cb676c8":"# Baseline Model","61b8a989":"Now we have a missing row at 3116:","9f622820":"### Dealing with Missing Values","71be5bdc":"# A bit of Exploration","1a1076a5":"\u0628\u0633\u0645 \u0627\u0644\u0644\u0647","9b124c37":"If very few people have a gender value of \"Other\" then it might be better to drop them or turn them into NaN and impute them.  \nSame for people with an \"Unknown\" smoking status, as unknown is the very definition of a missing value.","f5f44a88":"I'll just drop that one.","2a813e09":"That's about 30%.  \nQuite a lot.  \n\"Unknown\" is the very definition of \"missing value\"\/NaN.  \nThus, I'll turn it into NaNs and impute it.  ","b7df3b61":"**What now?**  \n**Resampling**  .\nBut some EDA first.  \nThen resampling. Random sampling to be exact.  \nMake sure you check it out in part 2 here: https:\/\/www.kaggle.com\/mahmoudlimam\/stroke-eda-random-sampling  ","3730d736":"##### Notes:\nThe model scored a very low recall and 1 in precision for the stroke class on the training data.  \nThis shows that the dataset is seriously imbalanced.  \nThe results on the testing data are even worse: the model is classifying everything as without stroke.  ","76266880":"#### Multiple Imputation by Chained Equations (or simply MICE)","617940ba":"Since people who've never smoked are probably less likely (on average) to have a stroke than those who did smoke in the past, which in turn are less likely to have a stroke than those who currently smoke, we can say there is some inherent order to these three categories.  \nThus, it would be meaningful to encode them with 0, 1 & 2.  "}}