{"cell_type":{"e9e11e61":"code","3e35b198":"code","033d19c6":"code","54e1bfbd":"code","ef004b68":"code","e1a897f7":"code","cdb40b81":"code","b787a6ce":"code","5e25aeca":"code","544821d5":"code","46c8bcf8":"code","f7889c77":"code","74c4c71c":"code","37f95546":"code","b93aa309":"code","615fc216":"code","a3b74387":"code","d26ed921":"code","afb76941":"code","69960b18":"code","791d4c37":"code","cbf26442":"code","b9e3ad58":"code","ec561825":"markdown","a11049de":"markdown","8dc9166f":"markdown","ea4936e6":"markdown"},"source":{"e9e11e61":"#import libraries\nimport pandas as pd\nimport numpy as np","3e35b198":"#import dataset, assign it to dataset and view the dataset\ndataset = pd.read_csv('..\/input\/data-science-machine-learning-and-ai-using-python\/petrol_consumption.csv')\ndataset.head()","033d19c6":"#Prepare dataset for training, X = 0:4 columns, Y=4th column\nX = dataset.iloc[:, 0:4]  #feature variable\nY = dataset.iloc[:, 4]    #target variable","54e1bfbd":"#divide the data in to training and test using sklearn's library\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state=0)","ef004b68":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","e1a897f7":"#Lets train the algorithm\nfrom sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=200, random_state=0)\nregressor.fit(X_train, Y_train)\ny_pred = regressor.predict(X_test)","cdb40b81":"#Evaluating the algorithm\nfrom sklearn import metrics\n\nprint('Mean Absolute Error: ', metrics.mean_absolute_error(Y_test, y_pred))\nprint('Mean Squared Error: ', metrics.mean_squared_error(Y_test, y_pred))\nprint('Root Mean Squared Error: ', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))","b787a6ce":"print(y_pred)","5e25aeca":"Y_test.shape","544821d5":"#import libaries, numpy, pandas and sklearn's svm\nimport pandas as pd\nimport numpy as np\nfrom sklearn import svm\n\n#libraries for visualization, matplotlib and seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns;\nsns.set(font_scale=1.2)\n\n%matplotlib inline","46c8bcf8":"#load the dataset as recipes variable\nrecipes = pd.read_csv('..\/input\/data-science-machine-learning-and-ai-using-python\/recipes_muffins_cupcakes.csv')\nrecipes","f7889c77":"sns.pairplot(recipes)","74c4c71c":"#plot the two ingrdients using sns.lmplot('Flour', 'Sugar',data=recipes,hue='Type', palette='Set1',fit_reg=False,scatter_kws={'s':70})\nsns.lmplot('Flour', 'Sugar',data=recipes,hue='Type', palette='Set1',fit_reg=False,scatter_kws={'s':70});","37f95546":"#specifying inputs to the model as ingredients, convert it to matrix\ningredients = recipes[['Flour','Sugar']].to_numpy()\ntype_label = np.where(recipes['Type'] == 'Muffin',0,1)","b93aa309":"#feature names\nrecipe_features = recipes.columns.values[1:].tolist()\nrecipe_features","615fc216":"#lets fit the model\nmodel = svm.SVC(kernel='linear')\nmodel.fit(ingredients, type_label)","a3b74387":"#lets visualize the results\n#Get the seperating hyperplane\nw = model.coef_[0]\na = -w[0]\/w[1]\nxx = np.linspace(30, 60)\nyy = a * xx - (model.intercept_[0])\/w[1]","d26ed921":"#plot the parallel to the seperating hyperplane that pass through the support vectors\nb = model.support_vectors_[0]\nyy_down = a * xx + (b[1] - a * b[0])\nb = model.support_vectors_[-1]\nyy_up =  a * xx + (b[1] - a * b[0])","afb76941":"#lets plot the hyperplane\nsns.lmplot('Flour', 'Sugar',data=recipes,hue='Type', \n           palette='Set1',fit_reg=False,\n           scatter_kws={'s':70});\nplt.plot(xx,yy,linewidth=2,color='black');","69960b18":"#lets plot the margins and support vectors\nsns.lmplot('Flour', 'Sugar',data=recipes,hue='Type', \n           palette='Set1',fit_reg=False,\n           scatter_kws={'s':70});\nplt.plot(xx,yy,linewidth=2,color='black')\nplt.plot(xx,yy_down,'k--')\nplt.plot(xx,yy_up, 'k--')\n\nplt.scatter(model.support_vectors_[:,0], model.support_vectors_[:,1], s= 80, facecolors= 'none')","791d4c37":"#lets predict the new case\n#lets define a function to guess when a recipe is muffin or a cupcake\ndef muffin_or_cupcake(flour, sugar):\n  if(model.predict([[flour,sugar]])) == 0:\n    print('You\\'re looking at a muffin recipe')\n  else:\n    print('You\\'re looking at a cupcake recipe')","cbf26442":"#predict for 50 parts of flour and 20 parts of sugar\nmuffin_or_cupcake(50,20)","b9e3ad58":"#lets plot the new point visually to see where the point lies\nsns.lmplot('Flour', 'Sugar',data=recipes,hue='Type', \n           palette='Set1',fit_reg=False,\n           scatter_kws={'s':70});\nplt.plot(xx,yy,linewidth=2,color='black')\n\nplt.plot(50,20,'yo',markersize='9')","ec561825":"**Problem statement**\n\nTo classify Muffins and Cupcakes using SVM","a11049de":"# **Day 10**\n\n**Random Forest**\n\nIts a type of supervised machine learning alogorithm based on ensemble learning. The random forest combines multiple algorithm of the same type i.e, multiple decision trees, resulting in forest of trees, hence the name Random Forest","8dc9166f":"**Support Vector Machines(SVM)**\n\nIt is a type of supervised machine learning classification algorithm, which tries to find a boundary that divides the data in such a way that the misclassification error can be minimized.","ea4936e6":"**Problem Statement**\n\nTo predict the gas consumption(in millions of gallons) in 48 of the US states based on petrol tax(in cents), per capita income(in dollars), paved highways(in miles) and the proportion of population with the driving license"}}