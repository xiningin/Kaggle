{"cell_type":{"66864bc3":"code","ed532df5":"code","7a27982b":"code","5324a97f":"code","6d6d4649":"code","50dce061":"code","b11cd758":"code","da4980a2":"code","db7b4e57":"code","11d0a4a9":"code","9846089f":"code","6e96b576":"code","172f6320":"code","a129db6a":"code","40c48279":"code","7bb4ff48":"markdown","79fcece2":"markdown","3b20c8b4":"markdown","0e2e32e0":"markdown","02175c71":"markdown","590e0852":"markdown","ef969b85":"markdown","80acd08f":"markdown","0ef52034":"markdown","354ce724":"markdown"},"source":{"66864bc3":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.utils import np_utils\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.datasets import mnist\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator","ed532df5":"def mnistDataPreparation(xy_train):\n    \"\"\" Takes as input the MNIST train.csv data \"\"\"\n    \"\"\" Returns two arrays containing images and labels, properly reshaped for CNN input \"\"\"\n    x_train = xy_train.drop(labels = [\"label\"],axis = 1)\n    x_train = x_train.values.reshape(x_train.shape[0],28,28,1)\n    y_train = xy_train[\"label\"]\n    y_train = y_train.values.reshape(y_train.shape[0],1)\n    return x_train, y_train\n\ndef showRandomDigitsAndLabels(x_train, y_train):\n    \"\"\" Shows twelve random samples from the training set and their labels\"\"\"\n    fig = plt.figure(figsize = (10,10))\n    for i in range(12):\n        randomNumber = np.random.randint(len(x_train))\n        plt.subplot(3,4,i+1)\n        plt.imshow(x_train[randomNumber][:,:,0], cmap='gray')\n        plt.title(\"Label: \" + str(y_train[randomNumber][0]))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\ndef mnistDataNormalization(x_train,y_train):\n    \"\"\" Normalizises the MNIST grayscale images and one-hot encodes the labels\"\"\"\n    x_train = x_train\/255.0\n    y_train = np_utils.to_categorical(y_train,10)\n    return x_train, y_train\n\nclass CustomAugmentation(object):\n    \"\"\" Defines a custom augmentation class\"\"\"\n    \n    kernel = np.ones((3,3),np.uint8)\n    \n    def __init__(self, erosion = False, dilation = False):\n        self.erosion = erosion\n        self.dilation = dilation\n    \n    def __call__(self, img):\n        \n        randomNumber = np.random.random()\n        \n        # Erosion and dilation are never applied together\n        \n        if randomNumber < 0.9:\n            pass\n        elif randomNumber < 0.95:\n            if self.erosion == True:\n                # Apply erosion 5% of the time if True\n                img = cv2.erode(img,CustomAugmentation.kernel,iterations = 1)\n                img = img.reshape(28,28,1)\n        else:\n            if self.dilation == True:\n                # Apply dilation 5% of the time if True\n                img = cv2.dilate(img,CustomAugmentation.kernel,iterations = 1)\n                img = img.reshape(28,28,1)\n                \n        return img\n\ndef augmentSingleDigit(x_train,datagen):\n    \"\"\" Applies data augmentation using datagen.flow on a single random sample from x_train to show\n        data agumentation effect \"\"\"\n    \"\"\" Returns the augmented sample and the corresponding index in the dataset\"\"\"\n    randomNumber = np.random.randint(len(x_train))\n    augmentedDigit = datagen.flow(x_train[randomNumber:randomNumber+1],batch_size = 1)[0][0].reshape(28,28)\n    return augmentedDigit, randomNumber\n\ndef showAugmentationEffect(x_train, augmentFunction):\n    \"\"\" Shows the effect of augmentation function augmentFunction on 8 random samples from x_train\"\"\"\n    plt.figure(figsize = (10,5))\n    for i in range(0,8,2):\n        plt.subplot(2,4,i+1)\n        augmentedDigit, randomNumber = augmentFunction(x_train)\n        plt.imshow(x_train[randomNumber].reshape(28,28),cmap = 'gray')\n        plt.title(str(randomNumber) + \" - Original\")\n        plt.xticks([]), plt.yticks([])\n        plt.subplot(2,4,i+2)\n        plt.imshow(augmentedDigit,cmap = 'gray')\n        plt.title(str(randomNumber) + \" - Augmented\")\n        plt.xticks([]), plt.yticks([])\n    plt.show()\n    \ndef buildModel():\n    \"\"\" Builds and compiles a new convolutional neural network. Also shows the model summary \"\"\"\n    \"\"\" Returns the model and the callbacks array \"\"\"\n    model = Sequential()\n    \n    # First Convolution Layer\n    model.add(Conv2D(32, (5, 5),activation = 'relu', input_shape = (28,28,1)))\n    BatchNormalization(axis=1)\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    BatchNormalization(axis=1)\n    \n    # 25% Dropout\n    model.add(Dropout(0.25))\n    \n    # Second Convolution Layer\n    model.add(Conv2D(64, (5, 5),activation = 'relu', input_shape = (28,28,1)))\n    BatchNormalization(axis=1)\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    BatchNormalization(axis=1)\n    \n    # 25% Dropout\n    model.add(Dropout(0.25))\n    \n    # Fully connected dense layer\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    BatchNormalization()\n    model.add(Dense(10, activation='softmax'))\n    \n    # Shows model summary\n    model.summary()\n    \n    # Compiles the model\n    model.compile(optimizer = RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Leraning rate reduction and early stopping that saves best weights\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1,\\\n                                                 factor=0.5, min_lr=0.00001)\n    early_stopping = EarlyStopping(monitor='val_acc', patience=10, verbose=2, mode='auto',\\\n                               restore_best_weights = True)\n    callbacks = [early_stopping,learning_rate_reduction]\n    \n    return model, callbacks\n\ndef printModelScore(model, x_val, y_val):\n    \"\"\" Prints the model score  obtained on validation set (x_val,y_val) \"\"\"\n    \"\"\" Returns rounded validation accuracy \"\"\"\n    score = model.evaluate(x_val,y_val,verbose=2)\n    metrics = {'loss': 'Validation Loss:', 'acc': 'Validation Accuracy:'}\n    print(metrics[model.metrics_names[0]], score[0])\n    print(metrics[model.metrics_names[1]], score[1])\n    return round(score[1],4)\n    \ndef showWrongPredictions(model,x_val,y_val):\n    \"\"\" Shows twelve random wrong predictions of model on the set (x_val,y_val) \"\"\"\n    \"\"\" Prints predicted label (P) and actual label (A)\"\"\"\n    \n    predictions = model.predict(x_val)\n    \n    # Initializes array containing array indeces of wrongly predicted samples\n    incorrectIndeces = []\n    \n    # Fills the incorrectIndeces list\n    for i in range(len(x_val)):\n        prediction = np.argmax(predictions[i])\n        actual = np.argmax(y_val[i])\n        if prediction != actual:\n            incorrectIndeces.append(i)\n\n    print(str(len(incorrectIndeces)) + \" out of \" + str(len(x_val)) + \" test samples classified incorrectly \")\n    print(\"Showing digits with predictions (P) and actual labels (A)...\")\n    randomOffset = np.random.randint(len(incorrectIndeces)-12)\n    \n    plt.figure(figsize = (10,10))\n    for i, incorrect in enumerate(incorrectIndeces[randomOffset:randomOffset+12]):\n        plt.subplot(3,4,i+1)\n        plt.imshow(x_val[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n        plt.title(\"P: \" + str(np.argmax(predictions[incorrect]))  + \" \/ \" + \"A: \" + str(np.argmax(y_val[incorrect])))\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\ndef showPredictionsOnUnlabeled(test, model):\n    \"\"\" Shows predictions of model on twelve random unlabeled (unseen) samples cointaned in array test\"\"\"\n    plt.figure(figsize = (10,10))\n    randomOffset = np.random.randint(len(test)-12)\n    for i in range(12):\n        j = randomOffset + i\n        intPrediction = np.argmax(model.predict(test[j].reshape(1,28,28,1)))\n        plt.subplot(3,4,i+1)\n        plt.title(\"Predicted: \" + str(intPrediction))\n        plt.imshow(test[j].reshape(28,28), cmap='gray')\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","7a27982b":"# Load train dataset\nxy_train = read_csv(\"..\/input\/train.csv\")\n\n# Prepare and reshape images and labels\nx_train, y_train = mnistDataPreparation(xy_train)\n\n# Show random images from train sample to check correct preparation\nshowRandomDigitsAndLabels(x_train, y_train)","5324a97f":"# Normalize data\nx_train, y_train = mnistDataNormalization(x_train, y_train)\n\n# Split loaded data into training and validation\nrandom_seed = 28\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1,random_state = random_seed)","6d6d4649":"preprocessor = CustomAugmentation(erosion = True, dilation = True)\ndatagen = ImageDataGenerator( preprocessing_function = preprocessor, rotation_range = 10, \\\n                             zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1 )","50dce061":"showAugmentationEffect(x_train, lambda x: augmentSingleDigit(x_train, datagen = datagen))","b11cd758":"datagen.fit(x_train)","da4980a2":"model, callbacks = buildModel()","db7b4e57":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size = 250),\n                              epochs = 100, validation_data = (x_val,y_val),\n                              verbose = 2, steps_per_epoch = x_train.shape[0] \/\/ 250, callbacks = callbacks)","11d0a4a9":"# Prints the model score on the validation set\nscore = printModelScore(model, x_val, y_val)","9846089f":"# Show twelve random wrong predictions\nshowWrongPredictions(model,x_val,y_val)","6e96b576":"# Show twelve random predictions on the unlabeled data from test.csv\ntest = read_csv(\"..\/input\/test.csv\")\ntest = test.values.reshape(test.shape[0],28,28,1)\ntest = test\/255.0\nshowPredictionsOnUnlabeled(test,model)","172f6320":"import time\n\nmodel_json = model.to_json()\ntimecode = time.time()\n\n# Saves the NN structure\nwith open(\"mnist_\" + str(timecode) + \"_\" + str(score) + \".json\",\"w\") as json_file:\n    json_file.write(model_json)\n\n# Saves the model weights\nmodel.save_weights(\"minst_weights_\" + str(timecode) + \"_\" + str(score) + \".h5\")","a129db6a":"import pandas as pd","40c48279":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name = \"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"CCN_MNIST_CustomDataAug.csv\",index=False)","7bb4ff48":"### Submitting test predictions to file","79fcece2":"### Evaluating the model","3b20c8b4":"### Modules","0e2e32e0":"### Functions definitions","02175c71":"## Author: Francesco Lucantoni","590e0852":"### Data augmentation","ef969b85":"### Preparing training and validation arrays","80acd08f":"### Saving the model","0ef52034":"### Building and training the model","354ce724":"# Digit Recognizer - MNIST Data"}}