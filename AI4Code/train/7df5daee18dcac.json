{"cell_type":{"b6b3ca2b":"code","59bbd013":"code","13e322c3":"code","34d248f9":"code","07077b08":"code","ce4601ec":"code","968e486f":"code","97773b35":"code","94c597be":"code","75730143":"code","7e048571":"code","0cf37f67":"code","c1877891":"markdown","b56c13b1":"markdown","175d76af":"markdown","51b5509d":"markdown","a2495612":"markdown","ddbd83dc":"markdown"},"source":{"b6b3ca2b":"import numpy as np\nimport pandas as pd \n# To ignore warinings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom xgboost import XGBClassifier\nfrom collections import Counter","59bbd013":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\n\nTREE_METHOD = \"hist\"\n\nQCUT_BASIS = 10\nQCUT_NUMBER = 20","13e322c3":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","34d248f9":"# 1.get train row size \ntrain_len = len(train)\n\n# 2.concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n\n# 3. empty data => np.nan\ndataset = dataset.fillna(np.nan)\n\n# 4.column encoding and create new features\n# 4.1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 4.2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 4.3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 4.4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n#     age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n#     if not np.isnan(age_pred) :\n#         dataset['Age'].iloc[i] = age_pred\n#     else :\n#         dataset['Age'].iloc[i] = age_med\n        \n        \n# 5.5.Name         \n# dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n# dataset[\"Title\"] = pd.Series(dataset_title)\n# dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n# dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n# dataset = pd.get_dummies(dataset, columns = [\"Title\"])\n\n# 4.6.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# #4.7.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# #4.8.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 4.9.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 4.10.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)\n\n# 5.qcut labelling\nunlabled_col = []\nfor colname, colvalue in dataset.iteritems():\n    if type(colvalue[1]) != str and colvalue.nunique() >= QCUT_BASIS:\n        unlabled_col.append(colname)\n        dataset[colname] = pd.qcut(dataset[colname],QCUT_NUMBER,labels=False,duplicates=\"drop\")\n        \nprint(unlabled_col)\n\n\n# 6.devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)\n","07077b08":"train.head()","ce4601ec":"train[unlabled_col]","968e486f":"train[\"Age\"].value_counts()\n","97773b35":"train[\"Fare\"].value_counts()","94c597be":"def getLabelCount(df,target):\n    return [( labelValue,len(train.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()]\n\nlabelCount = getLabelCount(train,TARGET)\nlabelCount","75730143":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test","7e048571":"model = XGBClassifier(tree_method=TREE_METHOD) \nmodel.fit(X, y)","0cf37f67":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsubmission[TARGET] =model.predict(X_test).astype(int)\nsubmission.to_csv(SUBMISSION_PATH,index=False)\nsubmission.head()","c1877891":"## **Quantile-based discretization** function.\n\nDiscretize variable into equal-sized buckets based on rank or based on sample quantiles. \n\nFor example 1000 values for 10 quantiles would produce a Categorical object indicating quantile membership for each data point.","b56c13b1":"# import ","175d76af":"# preprocessing","51b5509d":"# check Count","a2495612":"# **pandas qcut**","ddbd83dc":"# load"}}