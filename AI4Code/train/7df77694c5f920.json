{"cell_type":{"964126db":"code","22ef78bc":"code","272eb9c8":"code","1be06002":"code","3e1448a8":"code","076b0878":"code","a68f3258":"code","0dacb7d6":"code","ee851eeb":"code","75585903":"code","b0d2ab98":"code","4ffb5930":"code","726de63b":"code","c3d0dd08":"code","e969776e":"code","5fe85d30":"code","43c51473":"code","07ce6cd1":"code","47c0a6fb":"code","ea36b12a":"code","830db36b":"code","4d19e963":"code","afc7dc37":"code","4ceff281":"markdown","f65a58d2":"markdown","ffd9ae56":"markdown","1cb76d5e":"markdown","73862c5c":"markdown","a997956c":"markdown","ae896076":"markdown","6d9e4f75":"markdown","1e38f1b8":"markdown","a734acf3":"markdown","cf1fb88f":"markdown","0f59d9d8":"markdown"},"source":{"964126db":"import pandas as pd\nimport numpy as np\nfrom scipy.sparse import coo_matrix","22ef78bc":"# install implicit package\n# !pip install implicit\nimport implicit","272eb9c8":"!export OPENBLAS_NUM_THREADS=1","1be06002":"FACTORS = 25\n\n# load data\ndf_professionals = pd.read_csv(f'..\/input\/professionals.csv')\ndf_questions = pd.read_csv(f'..\/input\/questions.csv')\ndf_answers = pd.read_csv(f'..\/input\/answers.csv')","3e1448a8":"# helpers for converting id's to indices and vice-versa\np_id_to_idx = { p_id: i for i, p_id in zip(df_professionals.index, df_professionals.professionals_id) }\np_idx_to_id = { i: p_id for p_id, i in p_id_to_idx.items() }\nq_id_to_idx = { q_id: i for i, q_id in zip(df_questions.index, df_questions.questions_id) }\nq_idx_to_id = { i: q_id for q_id, i in q_id_to_idx.items() }","076b0878":"# helper methods\ndef get_prof(prof_id):\n    return df_professionals[df_professionals.professionals_id == prof_id][['professionals_industry', 'professionals_headline']] \n\ndef get_q_and_a(prof_id):\n    pd_q_and_a = pd.merge(left=df_questions, right=df_answers.rename(columns={'answers_question_id': 'questions_id'}), how='left')\n    return pd_q_and_a[pd_q_and_a.answers_author_id == prof_id][['questions_id','questions_title', 'questions_body', 'answers_body']]\n\ndef recommend(prof_id, model, item_users):\n    q_rec_idxs = [q_idx for q_idx, _ in model.recommend(p_id_to_idx[prof_id], item_users.tocsr().T)]\n    return df_questions[df_questions.index.isin(q_rec_idxs)][['questions_id','questions_title', 'questions_body']]\n\ndef train(item_users, user_factors=None, item_factors=None, factors=FACTORS):\n    model = implicit.als.AlternatingLeastSquares(factors=factors, regularization=0.01, dtype=np.float64, iterations=10)\n    if user_factors is not None:\n        model.user_factors = user_factors\n    if item_factors is not None:\n        model.item_factors = item_factors\n    confidence = 20\n    model.fit(confidence * item_users)\n    return model\n\ndef explain(item_users,p_id, q_id, ):\n    _, contributions, _ = model.explain(p_id_to_idx[p_id], item_users.tocsr().T, \n              q_id_to_idx[q_id])\n    q_ids = [q_idx_to_id[q_id] for q_id, _ in contributions]\n    return df_questions[df_questions.questions_id.isin(q_ids)]\n\ndef similar(model, q_id):\n    q_idxs_and_scores = model.similar_items(q_id_to_idx[q_id])\n    q_idxs = [q_idx for q_idx, _ in q_idxs_and_scores]\n    return df_questions[df_questions.index.isin(q_idxs)]","a68f3258":"# save index of of professional and question if an answer exists\np_and_q_idxs = set()\nfor p_id, q_id in zip(df_answers.answers_author_id, df_answers.answers_question_id):\n    if p_id in p_id_to_idx and q_id in q_id_to_idx:\n        p_and_q_idxs.add((p_id_to_idx[p_id], q_id_to_idx[q_id]))\n        \n        \np_idxs, q_idxs = [], []\nfor p_idx, q_idx in p_and_q_idxs:\n    p_idxs.append(p_idx)\n    q_idxs.append(q_idx)\n\n#create sparse matrix\nP = df_professionals.shape[0]\nQ = df_questions.shape[0]\nitem_users = coo_matrix((np.ones(len(p_idxs)), (q_idxs, p_idxs)), shape=(Q, P))","0dacb7d6":"# create model and fit using the matrix, and a confidence level\nmodel = train(item_users)","ee851eeb":"sample_dev_prof_id = '1ec14aee9311480681dfa81b0f193de8'\nget_prof(sample_dev_prof_id)","75585903":"get_q_and_a(sample_dev_prof_id)","b0d2ab98":"recommend(sample_dev_prof_id, model, item_users).values","4ffb5930":"sample_architect_prof_id = 'b45e7851aded479a92282ea3c66300ab'\nget_prof(sample_architect_prof_id)","726de63b":"get_q_and_a(sample_architect_prof_id)","c3d0dd08":"recommend(sample_architect_prof_id, model, item_users).values","e969776e":"# initialize the user and item factor vectors\nuser_factors = np.random.rand(df_professionals.shape[0], FACTORS).astype(np.float32) * 0.1\nitem_factors = np.random.rand(df_questions.shape[0], FACTORS).astype(np.float32) * 0.1\n\n# modify the user factor vector for professionals in the architecture industry \nfor i, industry in zip(df_professionals.index, df_professionals.professionals_industry.values):\n    if industry == industry and 'architecture' in industry.lower():\n        # make the value of the first index much larger than the others\n        user_factors[i, 0] = 5.0\n\n# modify the item factor vector for questions that contain the word architecture        \nfor i, title, body in zip(df_questions.index, df_questions.questions_title, df_questions.questions_body):\n    title, body = title.lower(), body.lower()\n    if 'architecture' in title or 'architecture' in body:\n        # make the value of the first index much larger than the others\n        item_factors[i, 0] = 5.0","5fe85d30":"model = train(item_users, user_factors=user_factors, item_factors=item_factors)","43c51473":"recommend(sample_architect_prof_id, model, item_users).values","07ce6cd1":"sample_bio_prof_id = 'b2def296aff34e5da6b405fae8969e73'\nget_prof(sample_bio_prof_id)","47c0a6fb":"get_q_and_a(sample_bio_prof_id)","ea36b12a":"recommend(sample_bio_prof_id, model, item_users).values","830db36b":"# save index of of professional and question if an answer exists\np_and_q_idxs = set()\nfor p_id, q_id in zip(df_answers.answers_author_id, df_answers.answers_question_id):\n    if p_id in p_id_to_idx and q_id in q_id_to_idx:\n        p_and_q_idxs.add((p_id_to_idx[p_id], q_id_to_idx[q_id]))\n        \n        \np_idxs, q_idxs = [], []\nfor p_idx, q_idx in p_and_q_idxs:\n    p_idxs.append(p_idx)\n    q_idxs.append(q_idx)\n\n# get professionals that have not answered a question\ndf_professionals_cold = df_professionals[~df_professionals.professionals_id.isin(np.unique(df_answers.answers_author_id.values))]\n        \n# get the indices of professionals in the biotechnology and biomedical engineering industry        \nbio_p_idxs, bio_q_idxs = [], []\nfor i, industry in zip(df_professionals_cold.index, df_professionals_cold.professionals_industry.values):\n    if industry == industry and industry.lower() in ['biotechnology', 'biomedical engineering']:\n        bio_p_idxs.append(i)\n\n# get the indices of questions with the terms biotechnology or biomedical engineering in them\nfor i, title, body in zip(df_questions.index, df_questions.questions_title, df_questions.questions_body):\n    title, body = title.lower(), body.lower()\n    if 'biomedical' in title or 'biomedical' in body or 'biotechnology' in title or 'biotechnology' in body:\n        bio_q_idxs.append(i)\n\n# save the pairs of indices to two arrays        \nbp_idxs, bq_idxs = [], []        \nfor i in bio_q_idxs:\n    for j in bio_p_idxs:\n            bq_idxs.append(i)\n            bp_idxs.append(j)\n    \n\n# #create sparse matrix\nP = df_professionals.shape[0]\nQ = df_questions.shape[0]\n\n# assign difference values for questions that professionals answered \n# and questions\/professionals that contain biotechnology\/biomedical engineering\nanswer_values = np.full((len(p_idxs), 1), 1.0)\nbio_values = np.full((len(bp_idxs), 1), 0.001)\n\nvalues = np.concatenate((answer_values, bio_values))\nupdated_item_users = coo_matrix((values[:, 0], (q_idxs + bq_idxs, p_idxs + bp_idxs)), shape=(Q, P), dtype=np.float64)","4d19e963":"model = train(updated_item_users)","afc7dc37":"recommend(sample_bio_prof_id, model, item_users).values","4ceff281":"It seems like a fair assumption that this particular professional is more likely to answer questions about software engineering. Here are the questions that the model recommends:","f65a58d2":"Lets take a look at the results. I've chosen a professional who is in the software industry and has answered 3 questions about software engineering.","ffd9ae56":"Now the recommendations include biotechnology and biomedical engineering related questions.","1cb76d5e":"Based on the questions that the professional has answered, it seems that he or she is more likely to answer a question if it is about architecture. Here are the questions that the model recommends:","73862c5c":"The model predicts questions related to software engineering, which makes sense for this particular example.","a997956c":"Lets look at another professional in the Architecture industry.","ae896076":"For each answer, we assume that a professional likes the question with a certain level of confidence. This confidence value is arbitrarily set to 50. To solve the cold start issue mentioned above, for professionals who have not answered questions we can assume that a professional likes the question, based on data from both the professional and the question, with a much lower level of confidence.","6d9e4f75":"The change caused the algorithm to recommend more architecture related questions.\n\nWhat about professionals that have not answered any questions? Unfortunately, because these professionals will not provide the model with any implicit feedback, their user-factor vectors will be set to 0.","1e38f1b8":"## Improving the Model","a734acf3":"To train the model, we create an items-users matrix where the questions are the items and the users are the professionals. The value of element i, j is set to 1 if the i-th professional answered the j-th question. Otherwise, it is set to 0","cf1fb88f":"Given a professional, the goal is to return a list of questions sorted by the predicted likelihood of the professional answering the question. This can be treated like a recommendation problem with implicit feedback, where the professional is the user and the question is the item. A professional answering a question can be used as a form of implicit feedback. The  [Implicit](https:\/\/github.com\/benfred\/implicit) library is used  to implement a collaboritve filtering algorithm that is based on the method used in [Collaborative Filtering for Implicit Feedback Datasets](http:\/\/yifanhu.net\/PUB\/cf.pdf).","0f59d9d8":"The model failed to recommend any questions about architecture.\n\nThe algorithm is trying to estimate user-factor vectors for each user and item-factor vectors for each item. The vectors are initialized to random values initially. However, what if we used what we know to initialize these vectors to values that may lead to improved recommendations? For example, let's assume that professionals in the architecture industry are more likely to answer questions about architecture. To model, this, we can set the first index in the user-factor vector for professionals with `professionals_industry` equal to \"Architecture\" to a high value, and set the first index in the item-factor vector for questions with `questions_title` or `questions_body` containing the word \"architecture\" to a high value.\n\nThis thinking behind this is from the NVBSVM++ algorithim discussed in a  [fast.ai](https:\/\/www.fast.ai\/) lecture (which referenced [Baselines and Bigrams: Simple, Good Sentiment and Topic Classification](https:\/\/www.aclweb.org\/anthology\/P12-2018))."}}