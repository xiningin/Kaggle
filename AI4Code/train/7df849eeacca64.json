{"cell_type":{"9ae8e698":"code","eff1a02a":"code","77f4e2b2":"code","276ecb16":"code","e5abb18d":"code","41fa561a":"code","c627c7d4":"code","3d66e4d8":"code","f145eebe":"code","9b7e2f59":"code","fd85632c":"code","2a523496":"code","10f199e8":"code","370a0ef1":"code","00fff569":"code","b404ff08":"code","ba84d077":"code","9168fede":"code","fae47a1c":"code","5a850533":"code","b5691938":"code","71f508ea":"code","67bde4da":"code","0b4623cf":"code","7bad21e1":"code","a28a6598":"code","b37caafa":"code","f62ccfe6":"code","55455f37":"code","3e34d1a7":"code","3ed843f4":"markdown","e88f1b2e":"markdown","8510deeb":"markdown","e4b6e5e3":"markdown","7b986168":"markdown","f000cff8":"markdown","b3ad14f9":"markdown","e9d42fe7":"markdown"},"source":{"9ae8e698":"!pip install pytorch-tabnet","eff1a02a":"import numpy as np \nimport pandas as pd \nfrom pandas_profiling import ProfileReport\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, classification_report, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nimport os\nimport torch\n       \nimport gc\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nimport re\n\n\npd.set_option('display.max_columns', 200)\nnp.random.seed(566)\npd.set_option('display.max_rows', 160)\npd.set_option('display.width', 768)\npd.set_option('display.float_format', '{:20,.2f}'.format)\npd.set_option('display.max_colwidth', -1)","77f4e2b2":"TARGET_COL = \"diabetes_mellitus\"\ndf = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nprint(test.shape)","276ecb16":"df","e5abb18d":"### add copies of semi categoircal\/codes - e.g. apache, icd,  + some aggregation heuristics\n\ndf[[\"apache_2_diagnosis_cat\",\"apache_3j_diagnosis_cat\"]] = (df[[\"apache_2_diagnosis\",\"apache_3j_diagnosis\"]]\/\/2).astype(str)\ntest[[\"apache_2_diagnosis_cat\",\"apache_3j_diagnosis_cat\"]] = (test[[\"apache_2_diagnosis\",\"apache_3j_diagnosis\"]]\/\/2).astype(str)","41fa561a":"## Print the categorical columns\nprint([c for c in df.columns if (1<df[c].nunique()) & (df[c].dtype != np.number)& (df[c].dtype != int) ])\ncategorical_cols =  ['hospital_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type',\n                    \"apache_2_diagnosis_cat\",\"apache_3j_diagnosis_cat\"]","c627c7d4":"print(\"categoircals cardinality\")\ndf[categorical_cols].nunique()","3d66e4d8":"## Handle na values\ndf[categorical_cols] = df[categorical_cols].fillna(\"\")\ntest[categorical_cols] = test[categorical_cols].fillna(\"\")\n\nprint(\"nan sum\\n\",df[categorical_cols].isna().sum())","f145eebe":"for col in df.columns[df.dtypes == 'float64']:\n    df.fillna(df[col].mean(), inplace=True)\n    test.fillna(test[col].mean(), inplace=True)","9b7e2f59":"unused_feat = ['encounter_id', 'hospital_id', 'Unnamed: 0']\n\nfeatures = [ col for col in df.columns if col not in unused_feat+[TARGET_COL]] \n","fd85632c":"categorical_columns = ['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type',\n                       \"apache_2_diagnosis_cat\",\"apache_3j_diagnosis_cat\"\n                      ]\ncategorical_dims =  {}\nfor col in categorical_columns:\n    print(col, df[col].nunique())\n    l_enc = LabelEncoder()\n    df[col] = df[col].fillna(\"VV_likely\")\n    test[col] = test[col].fillna(\"VV_likely\")\n    l_enc = l_enc.fit(np.unique(np.concatenate((df[col].unique(), test[col].unique()), axis=None)))\n    df[col] = l_enc.transform(df[col].values)\n    test[col] = l_enc.transform(test[col].values)\n    categorical_dims[col] = len(l_enc.classes_)\n","2a523496":"cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n\ncat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n\n## define embedding dimension per categorical variable. \ncat_emb_dims = [min(50,x\/\/2) for x in cat_dims]","10f199e8":"print(cat_emb_dims)","370a0ef1":"### unsupervised pretraining\n\nunsupervised_model = TabNetPretrainer(\n    n_d=64, n_a=64, n_steps=6,\n#     gamma=1.5,\n    n_independent=4, n_shared=4,\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=cat_emb_dims, # was 1 - ideally\n#     lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2), # was 2e-2\n    scheduler_params = {\"gamma\": 0.95,\n                     \"step_size\": 20},\n    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15,\n    mask_type=\"sparsemax\"\n)","00fff569":"clf = TabNetClassifier(\n    n_d=64, n_a=64, n_steps=6,\n#     gamma=1.5,\n    n_independent=4, n_shared=4,\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=cat_emb_dims, # was 1 - ideally\n#     lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=3e-2), # was 2e-2\n    scheduler_params = {\"gamma\": 0.95,\n                     \"step_size\": 20},\n    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15,\n    mask_type=\"sparsemax\"\n)\n","b404ff08":"n_total = len(df)\n\ntrain_indices, valid_indices = train_test_split(\n    range(n_total), test_size=0.07, random_state=0)","ba84d077":"## Train Test split and remove Target values\n\n\nX_train = df[features].values[train_indices]\ny_train = df[TARGET_COL].values[train_indices]\n\nX_valid = df[features].values[valid_indices]\ny_valid = df[TARGET_COL].values[valid_indices]\n","9168fede":"max_epochs = 2000 if not os.getenv(\"CI\", False) else 2","fae47a1c":"X_valid.shape","5a850533":"test[features].values.shape","b5691938":"np.vstack([X_train,test[features].values]).shape","71f508ea":"### opt: unsupervised pretraining\n## use train and unseen test data! \n\nunsupervised_model.fit(\n    X_train=np.vstack([X_train,test[features].values]),\n        eval_set=[X_valid],\n     max_epochs=100,\n    batch_size = 1024 ,# 1024 default , ~256-512 with GPU\n    pretraining_ratio = 0.35,\n)\n\n# ## save unsup model\n# ### https:\/\/github.com\/dreamquark-ai\/tabnet\/blob\/develop\/pretraining_example.ipynb\n# unsupervised_model.save_model('.\/.4_pretrain')\n\n\n","67bde4da":"## supervised model +- unsuper weights\nclf.fit(\n    X_train=X_train, y_train=y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_name=['train', 'valid'],\n    eval_metric = [ 'auc', 'logloss'], # 'balanced_accuracy',\n    max_epochs=max_epochs,     \n    patience=70,\n    batch_size=16384,\n    virtual_batch_size=512, # 256\n    from_unsupervised=unsupervised_model ## load pretraining  \n)\n\n","0b4623cf":"# plot losses\nplt.plot(clf.history['train_logloss'], label='train logloss');\nplt.plot(clf.history[\"valid_logloss\"], label='valid logloss');","7bad21e1":"# To get final results you may need to use a mapping for classes \n# as you are allowed to use targets like [\"yes\", \"no\", \"maybe\", \"I don't know\"]\n\npreds_mapper = { idx : class_name for idx, class_name in enumerate(clf.classes_)}\n\npreds = clf.predict_proba(X_valid)\n\ny_pred = np.vectorize(preds_mapper.get)(np.argmax(preds, axis=1))\n\n# valid_acc = accuracy_score(y_pred=y_pred, y_true=y_valid)\nvalid_auc = roc_auc_score(y_pred,y_valid)\n\nprint(f\"BEST MODEL cost: {clf.best_cost}\")\nprint(f\"VALID AUC SCORE : {valid_auc}\")","a28a6598":"## top features (unsorted) - \n# X_train.columns[clf.feature_importances_>1e-7]\nfeat_imp = pd.DataFrame([df.drop(TARGET_COL,axis=1,errors=\"ignore\").columns,clf.feature_importances_]).T\nfeat_imp = feat_imp.loc[feat_imp[1]>1e-6].sort_values(1,ascending=False).reset_index(drop=True)\n\nprint(\"top 20: \\n\",feat_imp[0].head(20))\nfeat_imp","b37caafa":"explain_matrix, masks = clf.explain(X_valid)","f62ccfe6":"fig, axs = plt.subplots(1, 5, figsize=(20,20))\n\nfor i in range(5):\n    axs[i].imshow(masks[i][:50])\n    axs[i].set_title(f\"mask {i}\")","55455f37":"test[TARGET_COL] = clf.predict_proba(test[features].values)[:,1]","3e34d1a7":"test[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission.csv\",index=False)","3ed843f4":"#### Nan Values in numerical columns","e88f1b2e":"#### Train\n\n* todo : split in advance (?) by hospital\/icu id ! (despite those features being dropped)","8510deeb":"### Preprocessing:\n#### Nan Values in categorical columns","e4b6e5e3":"# WiDS Datathon 2021: TabNet starter\n### Goal:\nPredecting **Diabetes Mellitus** (a particular type of diabetes) of patient based on the data from the first 24 hours of intensive care of a patient.\n### Credit:\nForked from this notebook: https:\/\/www.kaggle.com\/amr009\/tabnet-simple-baseline\nThanks to [Ruchi Bahtia](https:\/\/www.kaggle.com\/ruchi798) and [Tensor Girl](https:\/\/www.kaggle.com\/usharengaraju) for their starter notebooks, be sure to check and upvote them!\n### Method: \nI am trying the [TabNet](https:\/\/github.com\/dreamquark-ai\/tabnet) library","7b986168":"#### Defining TabNet models\n* Do pretraining first","f000cff8":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/22359\/logos\/header.png?t=2020-12-29-21-53-27)","b3ad14f9":"##### Categorical Encoding","e9d42fe7":"#### Train\/Test split\n\n* TODO: split by groups (icu, hospital id) "}}