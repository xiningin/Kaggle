{"cell_type":{"696b5c9f":"code","04076e9d":"code","f81883bd":"code","93e76933":"code","4abaa16c":"code","445ebe1a":"code","4728f02e":"code","65f04794":"code","9fa4ce62":"code","d269d756":"markdown","0d80ac71":"markdown","13436064":"markdown","3825ad20":"markdown","f0fe2444":"markdown","35bf9f1b":"markdown","2ddd3341":"markdown","7f93c61a":"markdown","89c2cb4a":"markdown","a45aa1ce":"markdown","8c109c24":"markdown"},"source":{"696b5c9f":"# Load Python Package\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\n\n# Load data (loading Titanic dataset)\ndata  = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Make Transformer\npreprocessing = make_column_transformer(\n    (OneHotEncoder(), ['Pclass','Sex']),\n    (SimpleImputer(), ['Age']),\n    remainder='passthrough')\n\n# Fit-Transform data with transformer\npreprocessing.fit_transform(data)","04076e9d":"# Load Python Package\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.compose import make_column_selector\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Make Transformer\npreprocessing = make_column_transformer(\n    (OneHotEncoder(), make_column_selector(dtype_include='object')),\n    (SimpleImputer(), make_column_selector(dtype_include='int')),\n    remainder='drop'\n)\n\n# Fit-Transform data with transformer\npreprocessing.fit_transform(data)","f81883bd":"# Load Python Package\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Split Train and Test\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n# Set variables\nohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\nimputer = SimpleImputer(add_indicator=True, verbose=1)\nscaler = StandardScaler()\nclf = DecisionTreeClassifier()\n# Make Transformer\npreprocessing = make_column_transformer(\n(make_pipeline(imputer,scaler),['Age','Siblings\/Spouses Aboard','Parents\/Children Aboard','Fare'])\n,(ohe, ['Pclass','Sex','Name'])\n,remainder='passthrough')\n# Make pipeline\npipe = make_pipeline(preprocessing, clf)\n# Fit model\npipe.fit(X_train, y_train.values.ravel())\nprint(\"Best score : %f\" % pipe.score(X_test, y_test.values.ravel()))","93e76933":"# Load Python Package\nfrom sklearn.experimental import enable_iterative_imputer, enable_hist_gradient_boosting\nfrom sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer","4abaa16c":"# Load Python Package\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Set variables\nohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\nimputer = SimpleImputer(add_indicator=True, verbose=1)\nclf = DecisionTreeClassifier()\n# Make Transformer\npreprocessing = make_column_transformer(\n(make_pipeline(imputer),['Age','Siblings\/Spouses Aboard','Parents\/Children Aboard','Fare']),\n(ohe, ['Pclass','Sex','Name']),remainder='passthrough')\n# Make pipeline\npipe = make_pipeline(preprocessing, clf)\n# Cross-validation\ncross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()","445ebe1a":"# Import Python Package\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Set variables\nclf = LogisticRegression()\nohe = OneHotEncoder()\nscaler = StandardScaler()\nimputer = SimpleImputer()\n# Make Transformer\npreprocessing = make_column_transformer((make_pipeline(imputer,scaler),['Age','Siblings\/Spouses Aboard','Parents\/Children Aboard','Fare']),(ohe, ['Sex']),remainder='drop')\n# Make pipeline\npipe = make_pipeline(preprocessing, clf)\n# Set params for Grid Search\nparams = {}\nparams['logisticregression__C'] = [0.1,0.2,0.3]\nparams['logisticregression__max_iter'] = [200,500]\n# Run grid search\ngrid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\ngrid.fit(X,y.values.ravel())\nprint(grid.best_score_)\nprint(grid.best)","4728f02e":"# Import Python Package\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Split Train Test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)\n","65f04794":"# Import Python Package\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Split Train, Val and Test \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n# Print dataFrames size\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","9fa4ce62":"# Import Python Package\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nimputer = SimpleImputer()\n# Load data (loading Titanic dataset)\ndata = pd.read_csv('https:\/\/web.stanford.edu\/class\/archive\/cs\/cs109\/cs109.1166\/stuff\/titanic.csv')\n# Set X and y\nX = data.drop('Survived',axis=1)\ny = data[['Survived']]\n# Write function\ndef lower_letter(df):\n   return df.apply(lambda x : x.str.lower())\n# Convert function\nget_lower_letter = FunctionTransformer(lower_letter)\n# Make Pipeline\npreprocess = make_column_transformer((imputer, ['Age']),(get_lower_letter,['Name']),remainder='drop')\npreprocess.fit_transform(X)","d269d756":"# Scikit-Learn Tip #4\n### Need something better than SimpleImputer for missing value imputation? Try KNNImputer or IterativeImputer (inspired by MICE package). Both are multivariate approaches (they take other features into account!)","0d80ac71":"# Scikit-Learn Tip #6\n### You can grid search an entire pipeline and fine optimal tuning parameters.\n","13436064":"# Scikit-Learn Tip #9\n### Want to do feature engineering within a ColumnTransformer or Pipeline? Write your own function and convert it into a transformer using FunctionTransformer.","3825ad20":"# Scikit-Learn Tip #1\n### Use make_column_transformer to apply different preprocessing to different columns","f0fe2444":"# Scikit-Learn Tip #7\n### Are you using train_test_split and working with an imbalanced dataset ? Be sure to set stratify=y so that class proportions are preserved when splitting.","35bf9f1b":"# Scikit-Learn Tip #3\n### Use Pipeline. Pipeline chains together multiple preprocessing steps. The output of each step is used as input to the next step, it makes it easy to apply the same preprocessing to Train and Test.","2ddd3341":"# Scikit-Learn Tip #8\n### Want to use three datasets (Train, Validation and Test) use train_test_split twice","7f93c61a":"# As a data scientist, you are probably using Scikit-Learn to perform machine learning experiments. The objective of this article is to share 9 Scikit-Learn tips to help you optimize your code.","89c2cb4a":"# Scikit-Learn Tip #2\n### Select columns using make_column_selector with make_columns_transformer","a45aa1ce":"# Scikit-Learn Tip #5\n### You can cross-validate an entire pipeline.\n","8c109c24":"![img](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/05\/Scikit_learn_logo_small.svg\/1200px-Scikit_learn_logo_small.svg.png)\n\n\n\nScikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms"}}