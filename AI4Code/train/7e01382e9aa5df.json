{"cell_type":{"60579c4b":"code","09ab1994":"code","cd7c94dc":"code","8b5c4ab6":"code","8bb60533":"code","802c56b1":"code","5a5140b2":"code","5533ec32":"code","917a2a0d":"code","40b537a8":"code","53df298b":"code","a422e209":"code","c9298802":"code","a106eaae":"code","ec5ac8d6":"code","88da5c05":"code","c924b711":"code","5852b41a":"code","6862b839":"code","b7b029c0":"code","dddf8c73":"code","f92f49dd":"code","b4c6af92":"code","8d36160f":"code","cc4a770a":"code","03ba8ece":"code","3cf819f5":"code","e112a0a2":"code","1c2237c4":"code","3af5dcdf":"code","3cd66c80":"code","65d38dc3":"code","669d838a":"code","97b5dfdf":"code","3dd2fd8e":"code","be7b276e":"code","a788c747":"code","f8fd7a35":"markdown","ebde36fd":"markdown","3848a985":"markdown","dbaac1db":"markdown","c20efa98":"markdown","3047c0d6":"markdown","2fa52148":"markdown","50e06b90":"markdown","760d2fb4":"markdown","2c9a15ec":"markdown","19e7addc":"markdown","836efcb7":"markdown","934bd375":"markdown","d70ebd8d":"markdown","95ac4c29":"markdown","c473ff35":"markdown","77c2bc65":"markdown","9cd1712f":"markdown","3ca3477a":"markdown","95f46cbb":"markdown","d1dd8677":"markdown","2fa10697":"markdown","ac2557ad":"markdown","ca633f6d":"markdown","71778082":"markdown","52fa372c":"markdown","5427692a":"markdown","8691422c":"markdown","3046cefc":"markdown","d3abd925":"markdown","7f745c71":"markdown","dcc7d9f3":"markdown","1278a35b":"markdown","003ddae6":"markdown","a37a0940":"markdown","0e396f89":"markdown","cf74fe7f":"markdown","41a4efd0":"markdown","1b2d64bb":"markdown","726b64ba":"markdown"},"source":{"60579c4b":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom pylab import rcParams\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight') \n# Above is a special style template for matplotlib, highly useful for visualizing time series data\n%matplotlib inline\nimport numpy as np\nimport datetime as dt\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nfrom pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())\nnp.set_printoptions(suppress=True)\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","09ab1994":"all_stock = pd.read_csv(\"..\/input\/stock-time-series-20050101-to-20171231\/all_stocks_2006-01-01_to_2018-01-01.csv\")","cd7c94dc":"top10_query = \"\"\"SELECT *\n                 FROM (SELECT Name, AVG(Volume) as Avg\n                       FROM all_stock\n                       GROUP BY Name\n                       ORDER BY AVG(Volume) DESC )\n                 LIMIT 10;\"\"\"\n\n\ntop10 = pysqldf(top10_query)","8b5c4ab6":"stock_10_query = \"\"\"SELECT * FROM all_stock\n                    where Name in ('AAPL', 'GE', 'MSFT', 'INTC', 'CSCO',\n                                   'PFE', 'JPM', 'AABA', 'XOM', 'KO')\"\"\"\n\nstock_10 = pysqldf(stock_10_query)","8bb60533":"stock_10.describe()","802c56b1":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","5a5140b2":"#Missing value proportion in the dataset\nmissing_values_table(stock_10)","5533ec32":"#Dropping all the rows which has NA values\nstock_10.dropna(inplace=True)","917a2a0d":"stock_10.dtypes","40b537a8":"#Converting Object to Date format for Date column\nstock_10['Date'] = pd.to_datetime(stock_10['Date'])","53df298b":"stock_10['Year'] = stock_10['Date'].apply(lambda x: dt.datetime.strftime(x,'%Y'))\nstock_10['Mon'] = stock_10['Date'].apply(lambda x: dt.datetime.strftime(x,'%b'))\nstock_10['Mon-Year'] = stock_10['Date'].apply(lambda x: dt.datetime.strftime(x,'%b-%Y'))","a422e209":"year_trend_query = \"\"\"SELECT Name, Year, AVG(Volume) as Avg\n                      from stock_10\n                      GROUP BY Name, Year\n                      ORDER BY Name, Year;\"\"\"\n\nyear_trend = pysqldf(year_trend_query)\n\nAAPL_trend = year_trend[year_trend.Name == 'AAPL']\nGE_trend = year_trend[year_trend.Name == 'GE']\nMSFT_trend = year_trend[year_trend.Name == 'MSFT']\nINTC_trend = year_trend[year_trend.Name == 'INTC']\nCSCO_trend = year_trend[year_trend.Name == 'CSCO']\nPFE_trend = year_trend[year_trend.Name == 'PFE']\nJPM_trend = year_trend[year_trend.Name == 'JPM']\nAABA_trend = year_trend[year_trend.Name == 'AABA']\nXOM_trend = year_trend[year_trend.Name == 'XOM']\nKO_trend = year_trend[year_trend.Name == 'KO']","c9298802":"data = [\n    go.Scatter(\n        x=AAPL_trend['Year'], \n        y=AAPL_trend['Avg'],\n        name='Apple'\n    ),\n    go.Scatter(\n        x=GE_trend['Year'], \n        y=GE_trend['Avg'],\n        name='GE'\n    ),\n        go.Scatter(\n        x=MSFT_trend['Year'], \n        y=MSFT_trend['Avg'],\n        name='Microsoft'\n    ),\n    go.Scatter(\n        x=INTC_trend['Year'], \n        y=INTC_trend['Avg'],\n        name='Intel'\n    ),\n        go.Scatter(\n        x=CSCO_trend['Year'], \n        y=CSCO_trend['Avg'],\n        name='Cisco'\n    ),\n    go.Scatter(\n        x=PFE_trend['Year'], \n        y=PFE_trend['Avg'],\n        name='Pfizer'\n    ),\n        go.Scatter(\n        x=JPM_trend['Year'], \n        y=JPM_trend['Avg'],\n        name='JPMorgan'\n    ),\n    go.Scatter(\n        x=AABA_trend['Year'], \n        y=AABA_trend['Avg'],\n        name='Altaba'\n    ),\n        go.Scatter(\n        x=XOM_trend['Year'], \n        y=XOM_trend['Avg'],\n        name='Exxon Mobil'\n    ),\n    go.Scatter(\n        x=KO_trend['Year'], \n        y=KO_trend['Avg'],\n        name='Coca-Cola'\n    )\n]\n\nlayout = go.Layout(\n    xaxis=dict(type='category', title='Year'),\n    yaxis=dict(title='Average Volume of Stocks Traded'),\n    title=\"Average Stock Volume Trend - Top 10 Companies stock over 2006 - 2017\"\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='line-chart')","a106eaae":"year_trend_query = \"\"\"SELECT Name, Year, AVG(Close) as Avg\n                      from stock_10\n                      GROUP BY Name, Year\n                      ORDER BY Name, Year;\"\"\"\n\nyear_trend = pysqldf(year_trend_query)\n\nAAPL_trend = year_trend[year_trend.Name == 'AAPL']\nGE_trend = year_trend[year_trend.Name == 'GE']\nMSFT_trend = year_trend[year_trend.Name == 'MSFT']\nINTC_trend = year_trend[year_trend.Name == 'INTC']\nCSCO_trend = year_trend[year_trend.Name == 'CSCO']\nPFE_trend = year_trend[year_trend.Name == 'PFE']\nJPM_trend = year_trend[year_trend.Name == 'JPM']\nAABA_trend = year_trend[year_trend.Name == 'AABA']\nXOM_trend = year_trend[year_trend.Name == 'XOM']\nKO_trend = year_trend[year_trend.Name == 'KO']","ec5ac8d6":"data = [\n    go.Scatter(\n        x=AAPL_trend['Year'], \n        y=AAPL_trend['Avg'],\n        name='Apple'\n    ),\n    go.Scatter(\n        x=GE_trend['Year'], \n        y=GE_trend['Avg'],\n        name='GE'\n    ),\n        go.Scatter(\n        x=MSFT_trend['Year'], \n        y=MSFT_trend['Avg'],\n        name='Microsoft'\n    ),\n    go.Scatter(\n        x=INTC_trend['Year'], \n        y=INTC_trend['Avg'],\n        name='Intel'\n    ),\n        go.Scatter(\n        x=CSCO_trend['Year'], \n        y=CSCO_trend['Avg'],\n        name='Cisco'\n    ),\n    go.Scatter(\n        x=PFE_trend['Year'], \n        y=PFE_trend['Avg'],\n        name='Pfizer'\n    ),\n        go.Scatter(\n        x=JPM_trend['Year'], \n        y=JPM_trend['Avg'],\n        name='JPMorgan'\n    ),\n    go.Scatter(\n        x=AABA_trend['Year'], \n        y=AABA_trend['Avg'],\n        name='Altaba'\n    ),\n        go.Scatter(\n        x=XOM_trend['Year'], \n        y=XOM_trend['Avg'],\n        name='Exxon Mobil'\n    ),\n    go.Scatter(\n        x=KO_trend['Year'], \n        y=KO_trend['Avg'],\n        name='Coca-Cola'\n    )\n]\n\nlayout = go.Layout(\n    xaxis=dict(type='category', title='Year'),\n    yaxis=dict(title='Average Close Price of the Stocks'),\n    title=\"Average Stock Price based on Close Price - Top 10 Companies stock over 2006 - 2017\"\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='line-chart')","88da5c05":"stk = pd.read_csv(\"..\/input\/stock-time-series-20050101-to-20171231\/all_stocks_2006-01-01_to_2018-01-01.csv\", index_col='Date', \n                  parse_dates=['Date'])\n\napp_stk = stk.query('Name == \"AAPL\"')","c924b711":"app_stk['2006':'2017'].plot(subplots=True, figsize=(10,12))\nplt.title('Apple stock trend from 2006 to 2017')\nplt.savefig('app_stk.png')\nplt.show()\n","5852b41a":"app_stk['Change'] = app_stk.Close.div(app_stk.Close.shift())\napp_stk['Change'].plot(figsize=(20,8))","6862b839":"app_stk['Return'] = app_stk.Change.sub(1).mul(100)\napp_stk['Return'].plot(figsize=(20,8))","b7b029c0":"app_stk.Close.diff().plot(figsize=(20,6))","dddf8c73":"stk = pd.read_csv(\"..\/input\/stock-time-series-20050101-to-20171231\/all_stocks_2006-01-01_to_2018-01-01.csv\", index_col='Date', \n                  parse_dates=['Date'])\nms_stk = stk.query('Name == \"MSFT\"')\nitl_stk = stk.query('Name == \"INTC\"')","f92f49dd":"# Plotting before normalization\napp_stk.Close.plot()\nms_stk.Close.plot()\nitl_stk.Close.plot()\nplt.legend(['Apple','Microsoft', 'Intel'])\nplt.show()","b4c6af92":"# Normalizing and comparison\n# Both stocks start from 100\nnorm_app_stk = app_stk.Close.div(app_stk.Close.iloc[0]).mul(100)\nnorm_ms_stk_stk = ms_stk.Close.div(ms_stk.Close.iloc[0]).mul(100)\nnorm_itl_stk_stk = itl_stk.Close.div(itl_stk.Close.iloc[0]).mul(100)\nnorm_app_stk.plot()\nnorm_ms_stk_stk.plot()\nnorm_itl_stk_stk.plot()\nplt.legend(['Apple','Microsoft', 'Intel'])\nplt.show()","8d36160f":"# Rolling window functions\nrolling_app = app_stk.Close.rolling('90D').mean()\napp_stk.Close.plot()\nrolling_app.plot()\nplt.legend(['Close','Rolling Mean'])\n# Plotting a rolling mean of 90 day window with original Close attribute of Apple stocks\nplt.show()","cc4a770a":"# Expanding window functions\napp_stk_mean = app_stk.Close.expanding().mean()\napp_stk_std = app_stk.Close.expanding().std()\napp_stk.Close.plot()\napp_stk_mean.plot()\napp_stk_std.plot()\nplt.legend(['Close','Expanding Mean','Expanding Standard Deviation'])\nplt.show()","03ba8ece":"# OHLC chart of Apple for December 2016\ntrace = go.Ohlc(x=app_stk['12-2016'].index,\n                open=app_stk['12-2016'].Open,\n                high=app_stk['12-2016'].High,\n                low=app_stk['12-2016'].Low,\n                close=app_stk['12-2016'].Close)\ndata = [trace]\niplot(data, filename='simple_ohlc')","3cf819f5":"# OHLC chart of Apple stock for 2016\ntrace = go.Ohlc(x=app_stk['2016'].index,\n                open=app_stk['2016'].Open,\n                high=app_stk['2016'].High,\n                low=app_stk['2016'].Low,\n                close=app_stk['2016'].Close)\ndata = [trace]\niplot(data, filename='simple_ohlc')","e112a0a2":"# OHLC chart of Apple stock 2006 - 2017\ntrace = go.Ohlc(x=app_stk.index,\n                open=app_stk.Open,\n                high=app_stk.High,\n                low=app_stk.Low,\n                close=app_stk.Close)\ndata = [trace]\niplot(data, filename='simple_ohlc')","1c2237c4":"# Candlestick chart of Apple for December 2016\ntrace = go.Candlestick(x=app_stk['12-2016'].index,\n                open=app_stk['12-2016'].Open,\n                high=app_stk['12-2016'].High,\n                low=app_stk['12-2016'].Low,\n                close=app_stk['12-2016'].Close)\ndata = [trace]\niplot(data, filename='simple_candlestick')","3af5dcdf":"# Candlestick chart of Apple for 2016\ntrace = go.Candlestick(x=app_stk['2016'].index,\n                       open=app_stk['2016'].Open,\n                       high=app_stk['2016'].High,\n                       low=app_stk['2016'].Low,\n                       close=app_stk['2016'].Close)\ndata = [trace]\niplot(data, filename='simple_candlestick')","3cd66c80":"# Candlestick chart of Apple stock 2006 - 2017\ntrace = go.Candlestick(x=app_stk.index,\n                       open=app_stk.Open,\n                       high=app_stk.High,\n                       low=app_stk.Low,\n                       close=app_stk.Close)\ndata = [trace]\niplot(data, filename='simple_candlestick')","65d38dc3":"# Consider the Apple stock w.r.t Close price\napp_stk[\"Close\"].plot(figsize=(16,8))","669d838a":"# Decomposition of Apple Stock based on Close price\nrcParams['figure.figsize'] = 11, 9\ndecomposed_app_stk = sm.tsa.seasonal_decompose(app_stk[\"Close\"],freq=360) # The frequncy is annual\nfigure = decomposed_app_stk.plot()\nplt.show()","97b5dfdf":"# Plotting white noise\nrcParams['figure.figsize'] = 16, 6\nwhite_noise = np.random.normal(loc=0, scale=1, size=1000)\n# loc is mean, scale is variance\nplt.plot(white_noise)","3dd2fd8e":"# Plotting autocorrelation of white noise\nplot_acf(white_noise,lags=20)\nplt.show()","be7b276e":"# The original non-stationary plot\nrcParams['figure.figsize'] = 16, 6\ndecomposed_app_stk.trend.plot()","a788c747":"# The new stationary plot\ndecomposed_app_stk.trend.diff().plot()","f8fd7a35":"**14. Absolute change in successive rows of Close price**","ebde36fd":"**King of DJIA**","3848a985":"![](https:\/\/i0.wp.com\/swingalpha.com\/wp-content\/uploads\/2018\/02\/Bull-Vs-Bear-Market-Characteristics-Banner-Image-1-1024x603.jpg)","dbaac1db":"**11. Apple Stock Trend w.r.t Open, High, Low, Close & Volume from 2006 to 2017**","c20efa98":"**20. Stationary **","3047c0d6":"**16. Windows function in Time series**","2fa52148":"**15. Comparing more than two time series**","50e06b90":"**13. Stock return based on Close price**","760d2fb4":"Window functions are used to identify sub periods, calculates sub-metrics of sub-periods.\n\n* **Rolling** - Same size and sliding\n* **Expanding** - Contains all prior values","2c9a15ec":"Boom! Boom! year 2008 - 2009 around the globe. Due to recession and followed by financial meltdown every company took a hit and as a result over the world people reduced their investment due to dry cash flow which can be seen as a downward trend from 2009 w.r.t to volume of stocks traded by top 10 companies around the world.\n\nLet's see how far this has impacted on the stock prices of these top 10 companies.","19e7addc":"For showing the comparison of more than two time series, I am considering the companies of \"Apple\", \"Microsoft\" and \"Intel\".","836efcb7":"This type of chart is used as a trading tool to visualise and analyse the price movements over time for securities, derivatives, currencies, stocks, bonds, commodities, etc. Although the symbols used in Candlestick Charts resemble a Box Plot, they function differently and therefore, are not to be confused with one another.\n\nCandlestick Charts display multiple bits of price information such as the open price, close price, highest price and lowest price through the use of candlestick-like symbols. Each symbol represents the compressed trading activity for a single time period (a minute, hour, day, month, etc). Each Candlestick symbol is plotted along a time scale on the x-axis, to show the trading activity over time.\n\nThe main rectangle in the symbol is known as the real body, which is used to display the range between the open and close price of that time period. While the lines extending from the bottom and top of the real body is known as the lower and upper shadows (or wick). Each shadow represents the highest or lowest price traded during the time period represented. When the market is Bullish (the closing price is higher than it opened), then the body is coloured typically white or green. But when the market is Bearish (the closing price is lower than it opened), then the body is usually coloured either black or red.","934bd375":"**19.2 White Noise**","d70ebd8d":"**19.1 Trend, Seasonality and Noise**\nThese are the components of a time series\n* **Trend** - Consistent upwards or downwards slope of a time series\n* **Seasonality** - Clear periodic pattern of a time series(like sine funtion)\n* **Noise** - Outliers or missing values","95ac4c29":"**18. Candlestick Charts**","c473ff35":"**7. Creating Year and Month-Year columns for analysis**","77c2bc65":"Wow! Here comes the sweet spot. Hit the bull's eye. As we can clearly see that Apple stock seems to follow a trend  every 2 to 3 years. If we remove the \"Apple\" and \"Exxon Mobil\" stock from the legend by clicking the corresponding legends one at a time, we can see a some repeating trends in \"JPMorgan\" and \"Microsoft\".\n\nFurther, When we additionally remove \"Coca-Cola\", \"Altaba\", \"JPMorgan\" and \"Microsoft\", we can clearly see that \"GE\" is the one which got hit heavely due recession because during the year 2009, the price of \"GE\" share alomost got reduced to half of its value.","9cd1712f":"**Why Does it Matter?**\n\nWhite noise is an important concept in time series analysis and forecasting.\n\n**It is important for two main reasons:**\n\n* **Predictability:** If your time series is white noise, then, by definition, it is random. You cannot reasonably model it and make predictions.\n* **Model Diagnostics:** The series of errors from a time series forecast model should ideally be white noise.\nModel Diagnostics is an important area of time series forecasting.\n\nTime series data are expected to contain some white noise component on top of the signal generated by the underlying process.\n\nOnce predictions have been made by a time series forecast model, they can be collected and analyzed. The series of forecast errors should ideally be white noise.\n\nWhen forecast errors are white noise, it means that all of the signal information in the time series has been harnessed by the model in order to make predictions. All that is left is the random fluctuations that cannot be modeled.\n\nA sign that model predictions are not white noise is an indication that further improvements to the forecast model may be possible.\n\n**Reference:** [https:\/\/machinelearningmastery.com\/white-noise-time-series-python\/](http:\/\/)","3ca3477a":"**4. Stats on the numeric columns in the dataset**","95f46cbb":"**9. Average Stock Price based on Close Price - Top 10 Companies stock over 2006 - 2017**","d1dd8677":"**19. Time Series Decomposition**","2fa10697":"**10. Apple Stock for Analysis**","ac2557ad":"**Context**\n\nStock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).\n\n**Content**\nThe data is presented in a couple of formats to suit different individual's needs or computational limitations. I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.\n\nThe folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.\n\nAll the files have the following columns: Date - in format: yy-mm-dd\n\n* Open - price of the stock at market open (this is NYSE data so all in USD)\n* High - Highest price reached in the day\n* Low Close - Lowest price reached in the day\n* Volume - Number of shares traded\n* Name - the stock's ticker name\n\n**Inspiration**\nThis dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided. From these data informative stock stats such as volatility and moving averages can be easily calculated. The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!\n\n**Acknowledgement**\nThis Data description is adapted from the dataset named 'S&P 500 Stock data'. This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.  \n\n**Note:**  \nKindly upvote the kernel if you find it useful.  ","ca633f6d":"A time series may be white noise.\n\nA time series is white noise if the variables are independent and identically distributed with a mean of zero.\n\nThis means that all variables have the same variance (sigma^2) and each value has a zero correlation with all other values in the series.\n\nIf the variables in the series are drawn from a Gaussian distribution, the series is called Gaussian white noise.","71778082":"**Observations:**\n* Clearly an upward trend is seen\n* Uniform seasonal change is seen\n* From Residual, the data seems to have a Non-uniform noise","52fa372c":"Date column seems to have \"object\" as datatype. So, converting the \"Date\" column to Date format. ","5427692a":"**6. Printing the Dtype of the columns**","8691422c":"**0. Loading required Packages & Global options**","3046cefc":"As the number of missing values is very less which are barely not even a percent, I am dropping all the missing values along their row values as well.","d3abd925":"An OHLC chart is any type of price chart that shows the open, high, low and close price of a certain time period. Open-high-low-close Charts (or OHLC Charts) are used as a trading tool to visualise and analyse the price changes over time for securities, currencies, stocks, bonds, commodities, etc. OHLC Charts are useful for interpreting the day-to-day sentiment of the market and forecasting any future price changes through the patterns produced.\n\nThe y-axis on an OHLC Chart is used for the price scale, while the x-axis is the timescale. On each single time period, an OHLC Charts plots a symbol that represents two ranges: the highest and lowest prices traded, and also the opening and closing price on that single time period (for example in a day). On the range symbol, the high and low price ranges are represented by the length of the main vertical line. The open and close prices are represented by the vertical positioning of tick-marks that appear on the left (representing the open price) and on right (representing the close price) sides of the high-low vertical line.\n\nColour can be assigned to each OHLC Chart symbol, to distinguish whether the market is \"bullish\" (the closing price is higher then it opened) or \"bearish\" (the closing price is lower then it opened).","7f745c71":"**17. OHLC charts**","dcc7d9f3":"**5. Function to find the missing values in the dataset**","1278a35b":"**12. Percentage change based on Close price**","003ddae6":"**1. Reading the Dataset**","a37a0940":"**3. Selecting Top 10 Companies stocks from all stocks data**","0e396f89":"A stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time.\n\n* **Strong stationarity:** is a stochastic process whose unconditional joint probability distribution does not change when shifted in time. Consequently, parameters such as mean and variance also do not change over time.\n* **Weak stationarity:** is a process where mean, variance, autocorrelation are constant throughout the time\n\nStationarity is important as non-stationary series that depend on time have too many parameters to account for when modelling the time series. diff() method can easily convert a non-stationary series to a stationary series.","cf74fe7f":"**Note:**  \nKindly upvote the kernel if you find it useful. Suggestions are always welome. Let me know your thoughts in the comment if any.","41a4efd0":"**2. Taking Top 10 stocks w.r.t to Average Volume traded for analysis**","1b2d64bb":"**8. Average Stock Volume Trend - Top 10 Companies stock over 2006 - 2017**","726b64ba":"For the analysis purpose I am taking the Apple stock as it tops the list in both the number of shares traded and with respect to price of the share."}}