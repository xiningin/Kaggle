{"cell_type":{"8aa5c031":"code","ae317a56":"code","02c4dfe0":"code","1c09f2f9":"code","4a3f5784":"code","436de747":"code","3e17367d":"code","32500d2b":"code","0ea79d17":"code","29998b8e":"markdown"},"source":{"8aa5c031":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae317a56":"TRAIN_DIR = '\/kaggle\/input\/fruit-recognition\/train\/train'\n","02c4dfe0":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\nimport matplotlib.pyplot as plt","1c09f2f9":"img_datagen = ImageDataGenerator(rescale=1.\/255,\n                                vertical_flip=True,\n                                horizontal_flip=True,\n                                rotation_range=40,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                zoom_range=0.1,\n                                validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = img_datagen.flow_from_directory(TRAIN_DIR,\n                                                 shuffle=True,\n                                                 batch_size=32,\n                                                 subset='training',\n                                                 target_size=(100, 100))\n\nvalid_generator = img_datagen.flow_from_directory(TRAIN_DIR,\n                                                 shuffle=True,\n                                                 batch_size=16,\n                                                 subset='validation',\n                                                 target_size=(100, 100))","4a3f5784":"model = Sequential()\n\n# model.add(L.Conv2D(64, (5, 5), activation='relu', padding='Same', input_shape=(100, 100, 3)))\n# model.add(L.Conv2D(64, (5, 5), activation='relu', padding='Same'))\n# model.add(L.MaxPool2D((2, 2)))\n# model.add(L.Dropout(0.25))\n\n# model.add(L.Conv2D(128, (3, 3), activation='relu', padding='Same'))\n# model.add(L.Conv2D(128, (3, 3), activation='relu', padding='Same'))\n# model.add(L.MaxPool2D((2, 2), strides=(2, 2)))\n# model.add(L.Dropout(0.25))\n\nmodel.add(keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet',\n                                                                  include_top=False,\n                                                                  input_shape=(100, 100, 3)))\nmodel.add(L.Flatten())\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.Dropout(0.5))\nmodel.add(L.Dense(33, activation='softmax'))\n\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","436de747":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') >= 0.997):\n            print(\"\\nReached 99.7% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\nearly = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, mode='max',\n                                        restore_best_weights=True)\n            \nhistory = model.fit(train_generator, validation_data=valid_generator,\n                   steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n                   validation_steps=valid_generator.n\/\/valid_generator.batch_size,\n                    callbacks=[early],\n                   epochs=10)","3e17367d":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()","32500d2b":"TEST_DIR = '..\/input\/fruit-recognition\/test\/test'\n","0ea79d17":"def number(num):\n    if len(num) == 4:\n        return num\n    elif len(num) == 3:\n        return '0'+num\n    elif len(num) == 2:\n        return '00'+num\n    else:\n        return '000'+num","29998b8e":"# **Imports**\n"}}