{"cell_type":{"4c38511b":"code","f69b045f":"code","b937edfb":"code","805c0758":"code","a3114c54":"code","a4bbde4b":"code","749bdd7c":"code","30c366d7":"code","6fb92523":"code","2c965e4e":"code","d2ffe217":"code","4378d69d":"code","d05403f1":"code","b04143d5":"code","0cebc93f":"code","78837277":"code","60812777":"code","fb1f65fd":"code","505d1316":"code","87c78404":"code","b5d92652":"code","5e6a3ae8":"code","912798b1":"code","446f92da":"code","3417a2d9":"code","f94a6812":"code","ccd1cde7":"code","1a97704d":"code","f225fde0":"code","4225c68e":"code","780b43a3":"code","46689326":"code","8231966a":"code","c6140797":"code","7929568e":"code","f1ec3903":"code","72721e5f":"code","901d577b":"code","d30fc591":"code","87a1b122":"code","1e4dc252":"code","ab581041":"code","0a5670d5":"code","e2b51bfc":"code","26d02ffc":"code","bb2f1dd0":"markdown","008d23c3":"markdown","5b17ba53":"markdown","760820a9":"markdown","173a5b5d":"markdown","94fa94bc":"markdown","fe34f8c4":"markdown","e5da4eaf":"markdown"},"source":{"4c38511b":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns \nfrom matplotlib.image import imread\nimport ast\nimport os","f69b045f":"#Load data\nmeta_df = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')\nmeta_df_test = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/test.csv')","b937edfb":"meta_df.shape","805c0758":"meta_df.isnull().sum()","a3114c54":"meta_df.head()","a4bbde4b":"meta_df.describe(include='all')\n#Could perform imputation here with NaN value","749bdd7c":"meta_df.info()","30c366d7":"meta_df_cat = meta_df.select_dtypes(include = 'object').copy()\nmeta_df_cat.nunique()","6fb92523":"meta_df.duplicated().sum()","2c965e4e":"meta_df.isnull().sum()","d2ffe217":"from os import listdir\nfrom PIL import Image\n\n\"\"\"\nVerifying images are valid\n\"\"\"\ndef validated_images(video_id):\n    path = '..\/input\/tensorflow-great-barrier-reef\/train_images'.format(video_id)\n    print ('Verifying that video {} frames are valid...'.format(video_id))\n    for filename in listdir(path):\n        if '.jpg' in filename:\n            try:\n                image = Image.open(path+filename)\n                image.verify()\n            except (IOError, SyntaxError) as e:\n                print ('Bad file:', filename)\n            print ('Verfied! Video {} has all valid images'.format(video_id))\nfor video_id in range(3):\n    validated_images(video_id)","4378d69d":"sequence_counts = meta_df['sequence'].value_counts().sort_values().reset_index()\nsequence_counts.columns = [['sequence', 'num_frames']]\nprint (\"number of sequences:\", len(sequence_counts))\nsequence_counts.head()","d05403f1":"num_obj_wt_frame = meta_df[meta_df.annotations =='[]']['annotations'].count()\nprint (\"Number of frames without objects:\" , num_obj_wt_frame)","b04143d5":"num_obj_with_frame = meta_df[meta_df.annotations != '[]']['annotations'].count()\nprint (\"Number of frames with objects:\",num_obj_with_frame)","0cebc93f":"#Showing what images can look like\nfolder = '..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/'\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    filename = folder + str(i) + '.jpg'\n    image = imread(filename)\n    plt.imshow(image)\nplt.show()","78837277":"meta_df[meta_df.annotations != '[]'].head()","60812777":"num_obj_wt_frame = meta_df[meta_df.annotations =='[]']['annotations'].count()\nprint (\"Number of frames without objects:\" , num_obj_wt_frame)","fb1f65fd":"num_obj_with_frame = meta_df[meta_df.annotations != '[]']['annotations'].count()\nprint (\"Number of frames with objects:\",num_obj_with_frame)","505d1316":"print('ratio of frames with objects:', num_obj_with_frame \/ len(meta_df))\n\nfig, axes = plt.subplots(1,1, figsize=(12, 6))\n\nsns.barplot(ax=axes, x=['Number of Frames with Objects', 'Number of Frames with No Objects'], y=[num_obj_with_frame, num_obj_wt_frame])\naxes.set_title(\"Distribution of Frames with\/without Objects\")\naxes.set_xlabel(\"Frame Types\")\naxes.set_ylabel(\"Count\")\n\nplt.show()","87c78404":"frame_counts = meta_df['video_id'].value_counts().sort_values().to_frame()\nframe_counts.head()","b5d92652":"meta_df[meta_df.annotations.str.len()>2]","5e6a3ae8":"meta_df.annotations.map(len).value_counts()","912798b1":"meta_df ['video_id'].value_counts()","446f92da":"meta_df['sequence'].value_counts()","3417a2d9":"sns.set_theme(style='whitegrid')\nax=sns.countplot(x='video_id',data=meta_df)","f94a6812":"meta_df_test.head()","ccd1cde7":"meta_df_test.shape","1a97704d":"\nfrom os import listdir\nfrom PIL import Image\n\"\"\"\nVerifying images are valid\n\"\"\"\ndef validate_images(video_id):\n    path = '..\/input\/tensorflow-great-barrier-reef\/train_images'.format(video_id)\n    print ('Verifying that video {} frames are valid...'.format(video_id))\n    for filename in listdir(path):\n        if '.jpg'in filename:\n            try:\n                image = Image.open(path+filename)\n                image.verify()\n            except(IOError,SyntaxError) as e:\n                print ('Bad file:', filename)\n    print('Verified! Video {} has all valid images'.format(video_id))\nfor video_id in range(3):\n    validate_images(video_id)","f225fde0":"#Images of COTS for which we have annotations as []\n\nfor i in range(3):\n    print (\"Video\" + str(i))\n    print (\"Frames with annotations:\" + str((meta_df[meta_df['video_id'] !=i] ['annotations'] != '[]').sum()))\n    print (\"Frames without annotations: \" +str((meta_df[meta_df['video_id']==i]['annotations']!= '[]').sum()))\n    print(\"-------\")","4225c68e":"#load sequence of images with annotations\nfrom PIL import Image, ImageDraw\nimport numpy as np\n\ndef fetch_image_list(df_tmp, video_id, num_images, start_frame_idx):\n    \n    '''\n    Load sequence of images with annotations\n    '''\n    def fetch_image(frame_id):\n        path_base = '..\/input\/tensorflow-great-barrier-reef\/train_images\/video_{}\/{}.jpg'\n        raw_image = Image.open(path_base.format(video_id, frame_id))\n\n        row_frame = df_tmp[(df_tmp.video_id == video_id) & (df_tmp.video_frame == frame_id)].iloc[0]\n        bounding_boxes = ast.literal_eval(row_frame.annotations)\n\n        for box in bounding_boxes:\n            draw = ImageDraw.Draw(raw_image)\n            x0, y0, x1, y1 = (box['x'], box['y'], box['x']+box['width'], box['y']+box['height'])\n            draw.rectangle( (x0, y0, x1, y1), outline=180, width=3)\n        return raw_image\n\n    return [np.array(fetch_image(start_frame_idx + index)) for index in range(num_images)]\n\nimages = fetch_image_list(meta_df, video_id = 0, num_images = 80, start_frame_idx = 25)\n\nprint(\"Num images: \", len(images))\nplt.imshow(images[0], interpolation='nearest')\nplt.axis('off')\nplt.show()","780b43a3":"from matplotlib import animation, rc\nrc('animation',html = 'jshtml')\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(9,9))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n    \n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n    return animation.FuncAnimation(fig,animate_func, frames=len(ims),\n                                  interval=1000\/12)\n\ncreate_animation(images)","46689326":"#Check the meta-data against image data ","8231966a":"#loading images\nvideo_0 = os.listdir('..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0')\nvideo_1 = os.listdir('..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1')\nvideo_2 = os.listdir('..\/input\/tensorflow-great-barrier-reef\/train_images\/video_2')","c6140797":"#Creating the image paths\nmeta_df['image_path'] = \"video_\"+ meta_df['video_id'].astype(str)+'\/'+ meta_df['video_frame'].astype(str)+\".jpg\"\nmeta_df.head()","7929568e":"def show_image(meta_df, idx):\n    f_name = meta_df.iloc[idx]['image_path']\n    return PIL.Image.open(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/\"+f_name)","f1ec3903":"# Finding out whether all the image paths are existing regular files \nmeta_df['image_path'].apply(lambda f_name:os.path.isfile(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/\"+f_name)).all()","72721e5f":"import PIL\nshow_image(meta_df,0).resize((400,256))","901d577b":"#Check the npy files","d30fc591":"pixels = np.load(\"..\/input\/tensorflow-great-barrier-reef\/example_test.npy\")","87a1b122":"pixels.shape","1e4dc252":"PIL.Image.fromarray(pixels[0, :]).resize((400, 256))","ab581041":"PIL.Image.fromarray(pixels[2, :]).resize((400, 256))","0a5670d5":"#Evaluate annotation strings containing literals\nast.literal_eval(meta_df.iloc[16].annotations)","e2b51bfc":"# Change the annotations into a list \nmeta_df ['annotations']= meta_df['annotations'].apply(eval)\nmeta_df[meta_df['annotations'].str.len()>1].iloc[0]['annotations']","26d02ffc":"#Distribution of boxes in frames\nmeta_df['n_objects'] = meta_df['annotations'].str.len()\nmeta_df.value_counts('n_objects').plot.bar(figsize=(10,5),alpha=0.5,rot=0,title='Distribution of boxes in frames');","bb2f1dd0":"  **1. EDA of META-DATA**","008d23c3":"There are no null values.","5b17ba53":"Our EDA has pointed out some considerations to build our model. Thanks, [Diego Gomez](https:\/\/www.kaggle.com\/diegoalejogm), for the [animations](https:\/\/www.kaggle.com\/diegoalejogm\/great-barrier-reefs-eda-with-animations). Thanks, [Prabhakaran D](https:\/\/www.kaggle.com\/get2jawa),for the [basic and simple EDA](https:\/\/www.kaggle.com\/get2jawa\/great-barrier-reefs-basic-simple-eda), Thanks, [Shijin Yang](https:\/\/www.kaggle.com\/sjyangkevin), for sharing your [EDA, Bouding Box Analysis & Annotated Videos](https:\/\/www.kaggle.com\/sjyangkevin\/eda-bouding-box-analysis-annotated-videos) notebook. ","760820a9":"According to The Great Barrier Reef Foundation, COTS are an important part of a healthy ecosystem in a reasonable number on healthy coral reefs since they advance the coral diversity of the reefs. However, when they appear in mass, they can negatively impact the life of the coral reef. \nIt is the reason why we would like to develop a computer vision model to detect these COTS and save the reef from outbreaks. \n","173a5b5d":"The hope for this competition is that we can find a better way to tame COTS outbreaks ethically and effectively. Maybe in the future we will not have to kill a massive number of COTS.","94fa94bc":"Most frames do not have objects in them.","fe34f8c4":"**2. VISUALISTION OF IMAGES**","e5da4eaf":"Please feel free to ask any question or give us any feedback on our work. Thank you. "}}