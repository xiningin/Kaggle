{"cell_type":{"b247d020":"code","121b36ae":"code","2db4574c":"code","d96cd865":"code","69c9b3f5":"code","bec5bfc1":"code","8135573d":"code","de5f7733":"code","66a83dab":"code","3f5efc86":"markdown","e9e55258":"markdown"},"source":{"b247d020":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","121b36ae":"df = pd.read_csv(\"\/kaggle\/input\/las-vegas-tripadvisor-reviews\/lasvegas_tripadvisor.csv\",encoding='utf-8')\ndf","2db4574c":"#df.info\ndf.describe()","d96cd865":"%matplotlib inline \nimport matplotlib.pyplot as plt\ndf.hist(bins=50, figsize=(20,15))\nplt.show()\n","69c9b3f5":"import numpy as np\ndef split_train_test(data, test_ratio):\n    shuffled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled_indices[:test_set_size]\n    train_indices = shuffled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]\n\n","bec5bfc1":"#train_set, test_set = split_train_test(data = df, test_ratio = 0.2)\n#len(train_set)\n\n#Do not use. See below, thanks.","8135573d":"# better approch:\nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(df, test_size = 0.2, random_state = 42)\ntrain_set.head()","de5f7733":"train_set","66a83dab":"test_set","3f5efc86":"### Below is a better approch than above line of code. Above line will regenerate a different test set each time you run the program.","e9e55258":"### "}}