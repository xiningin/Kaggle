{"cell_type":{"239ef210":"code","fb66e59c":"code","8a9bfc10":"code","669a8f21":"code","b9480fc2":"code","2cd35f5c":"code","25368aa6":"code","5af25a29":"code","90ab3875":"code","6b5e0c3e":"code","deed5e9b":"code","f652a98d":"code","2ec97046":"code","fdedf773":"code","9ef4f7c6":"code","bb9bb9d5":"code","36abb87d":"code","47cbd8da":"markdown","0c365809":"markdown","23b1768f":"markdown","5647b890":"markdown","1f8b9a9a":"markdown","d4de9b31":"markdown","74ebdfba":"markdown","e05cdd09":"markdown","9ade362d":"markdown"},"source":{"239ef210":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n","fb66e59c":"root = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/'\npara = '\/Parasitized\/'\nuninf = '\/Uninfected\/'\n\nos.listdir(root)","8a9bfc10":"Parasitized = os.listdir(root+para)\nUninfected = os.listdir(root+uninf)","669a8f21":"plt.figure(figsize = (12,24))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread(root+para+ Parasitized[i])\n    plt.imshow(img)\n    plt.title('PARASITIZED : 1')\n    plt.tight_layout()\nplt.show()\n\nplt.figure(figsize = (12,24))\nfor i in range(4):\n    plt.subplot(2, 4, i+1)\n    img = cv2.imread(root+uninf+ Uninfected[i+1])\n    plt.imshow(img)\n    plt.title('UNINFECTED : 0')\n    plt.tight_layout()\nplt.show()","b9480fc2":"data = []\nlabels = []\n\nfor img in Parasitized:\n    try:\n        img_read = plt.imread(root+para+ img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(1)\n    except:\n        None\n        \nfor img in Uninfected:\n    try:\n        img_read = plt.imread(root+uninf+ img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(0)\n    except:\n        None","2cd35f5c":"image_data = np.array(data)\nlabels = np.array(labels)\n\nnp.random.seed(42)\nidx = np.arange(image_data.shape[0])\nnp.random.shuffle(idx)\nimage_data = image_data[idx]\nlabels = labels[idx]\n\nplt.figure(figsize=(20,8))\nfor i in range(1,17):\n    plt.subplot(2,8,i)\n    plt.imshow(image_data[i])\n    plt.title(labels[i])\nplt.show()","25368aa6":"max_pix = []\nimage_data_s = np.zeros(image_data.shape)\nfor i in range(image_data.shape[0]):\n    max_pix.append(np.max(image_data[i]))\n    image_data_s[i] = image_data[i]+(1-max_pix[i]) \nplt.hist(max_pix)\nplt.title('Maximum color value')\nplt.show()\n","5af25a29":"fig, ax =plt.subplots(10,3,figsize=(16,50))\nfor j in range(10):\n    unique,counts=np.unique(image_data[j].round(1), return_counts=True)\n    \n    ax[j][0].imshow(image_data[j], cmap='gray')\n    ax[j][0].set_title('Cell : {}'.format(labels[j]))\n    for i in range(image_data[j].shape[0]):\n        ax[j][1].hist(image_data[j][i],color=['r','g','b'],alpha=0.2)\n    \n    ax[j][2].plot(np.mean(image_data[j],axis=0))\n    ax[j][2].set_title('Mean Value by column frame')\n    ax[j][1].set_title('Values by pixel')\n    \nplt.show()","90ab3875":"X_tr, X_ts, Y_tr, Y_ts = train_test_split(image_data, labels, test_size=0.15, shuffle=True, stratify=labels, random_state=42)\n\nY_tr = to_categorical(np.array(Y_tr))\nY_ts_p = to_categorical(np.array(Y_ts))","6b5e0c3e":"BatchSize = 128\n\nimg_gen = ImageDataGenerator( rescale=1.\/255.,\n                            brightness_range=(0.75,1.00), \n                            samplewise_center=True,samplewise_std_normalization=True,\n                            data_format='channels_last',\n                            fill_mode='nearest',\n                            validation_split=0.1)\n# Cells are well adjusted to edges so cutting the images may cut the important part.\n# Cells are almost circular, rotating or flipping them is not giving more information due to axial symmetry.\n# We have seen that brightness goes gaussianly from 0.70 to 1.00 so is worthy to do a brightness range.\n# Then rescaling and doing a std transformation make all images mostly equal in ground values.\ntest_gen = ImageDataGenerator(rescale=1.\/255.,\n                              data_format='channels_last',\n                              brightness_range=(0.75,1.00),\n                              samplewise_center=True,samplewise_std_normalization=True)\nimg_gen.fit(X_tr)\ntest_gen.fit(X_ts)\n\ntr_gen = img_gen.flow(X_tr,Y_tr, batch_size=BatchSize, subset = 'training')\nval_gen = img_gen.flow(X_tr,Y_tr, batch_size=BatchSize, subset = 'validation')\nts_gen = test_gen.flow(X_ts,Y_ts_p, batch_size=BatchSize, shuffle=False)","deed5e9b":"model = models.Sequential()\n\n#Input + Conv 1 + ReLU + Max Pooling\nmodel.add(layers.Conv2D(32,(5,5),activation='relu',padding='same',input_shape=X_tr.shape[1:]))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.BatchNormalization())\n\n\n# Conv 2 + ReLU + Max Pooling\nmodel.add(layers.Conv2D(64,(5,5),padding='same',activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.BatchNormalization())\n\n\n# Conv 3 + ReLU + Max Pooling\nmodel.add(layers.Conv2D(128,(3,3),padding='same',activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.BatchNormalization())\n\n# Conv 4 + ReLU + Max Pooling\nmodel.add(layers.Conv2D(256,(3,3),dilation_rate=(2,2),padding='same',activation='relu'))\nmodel.add(layers.Conv2D(256,(3,3),activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.BatchNormalization())\n\n# Fully Connected + ReLU\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(300, activation='relu'))\nmodel.add(layers.Dense(100, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.BatchNormalization())\n\n#Output\n\nmodel.add(layers.Dense(2, activation='softmax'))\n\n\nmodel.summary()","f652a98d":"model.compile(optimizer=optimizers.Adam(lr=0.01),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_loss',mode='min',patience=5,verbose=1)\nRLr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience = 2, verbose = 1, min_delta=1e-3,\n                       min_lr=1e-6)\n\nhistory= model.fit(tr_gen,\n                 epochs=20,\n                 steps_per_epoch=tr_gen.n\/BatchSize,\n                 validation_data=val_gen,\n                 validation_steps=val_gen.n\/BatchSize,\n                 callbacks=[es,RLr])","2ec97046":"fig, ax=plt.subplots(2,1,figsize=(12,10))\nfig.suptitle('Train evaluation')\n\nwith plt.style.context('fivethirtyeight'):\n\n    sns.lineplot(ax= ax[0],x=np.arange(0,len(history.history['accuracy'])),y=history.history['accuracy'])\n    sns.lineplot(ax= ax[0],x=np.arange(0,len(history.history['accuracy'])),y=history.history['val_accuracy'])\n\n    ax[0].legend(['Train','Validation'])\n    ax[0].set_title('Accuracy')\n    ax[0].grid()\n\n    sns.lineplot(ax= ax[1],x=np.arange(0,len(history.history['loss'])),y=history.history['loss'])\n    sns.lineplot(ax= ax[1],x=np.arange(0,len(history.history['loss'])),y=history.history['val_loss'])\n\n    ax[1].legend(['Train','Validation'])\n    ax[1].set_title('Loss')\n    ax[1].grid()\n    \n\nplt.show()","fdedf773":"Y_pred = model.predict(ts_gen,steps=np.ceil(ts_gen.n\/BatchSize))\nY_pred = np.argmax(Y_pred, axis=1)\n","9ef4f7c6":"conf_mat = confusion_matrix(Y_ts,Y_pred)\nsns.set_style(style='dark')\nplt.figure(figsize=(12,8))\nheatmap = sns.heatmap(conf_mat,vmin=np.min(conf_mat.all()), vmax=np.max(conf_mat), annot=True,fmt='d', annot_kws={\"fontsize\":20},cmap='Spectral')\nheatmap.set_title('Confusion Matrix Heatmap\\n\u00bfIs the cell infected?', fontdict={'fontsize':15}, pad=12)\nheatmap.set_xlabel('Predicted',fontdict={'fontsize':14})\nheatmap.set_ylabel('Actual',fontdict={'fontsize':14})\nheatmap.set_xticklabels(['NO','YES'], fontdict={'fontsize':12})\nheatmap.set_yticklabels(['NO','YES'], fontdict={'fontsize':12})\nplt.show()\n\n\nprint('-Accuracy achieved: {:.2f}%\\n-Accuracy by model was: {:.2f}%\\n-Accuracy by validation was: {:.2f}%'.\n      format(accuracy_score(Y_ts,Y_pred)*100,(history.history['accuracy'][-1])*100,(history.history['val_accuracy'][-1])*100))","bb9bb9d5":"index=0\nindex_errors= []\n\nfor label, predict in zip(Y_ts,Y_pred):\n    if label != predict:\n        index_errors.append(index)\n    index +=1","36abb87d":"plt.figure(figsize=(20,8))\n\nfor i,img_index in zip(range(1,17),random.sample(index_errors,k=16)):\n    plt.subplot(2,8,i)\n    plt.imshow(X_ts[img_index])\n    plt.title('Actual: '+str(Y_ts[img_index])+' Predict: '+str(Y_pred[img_index]))\nplt.show()","47cbd8da":"### Fitting ","0c365809":"# CNN Model","23b1768f":"There are some cells bad labeled by the CNN model that seem bad labeled from the beginning. Some others are true errors of the model.","5647b890":"### Architecture","1f8b9a9a":"### Preprocessing images ","d4de9b31":"# Malaria infection","74ebdfba":"### Evaluation","e05cdd09":"# Errors Sample","9ade362d":"# Predictions "}}