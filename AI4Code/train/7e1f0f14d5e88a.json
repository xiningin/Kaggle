{"cell_type":{"a6cbb751":"code","276859f1":"code","decdda73":"code","eabc7747":"code","a8527e2d":"code","6a6f1f88":"code","4758b77b":"code","d035d2cd":"code","8499b429":"code","806bd6c7":"code","84d68757":"code","0bf44945":"code","edf20f4e":"code","ad5aecd3":"code","fd54dfbf":"markdown","250c4ce8":"markdown"},"source":{"a6cbb751":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","276859f1":"data = pd.read_csv(os.path.join(dirname, filename))\n\n## Exploring major factors that are boosting to the Attrition %\n\ncol_val_nunique = [data[c].nunique() for c in data.columns]\nplt.figure(figsize=(10,10))\nplt.scatter(col_val_nunique,data.columns)\nplt.show()\n\n## Most of the columns are having distinct values < 20, can be explored using the groupby method to explore contrubuting factors of attrition","decdda73":"# Function to get Columnname and Dataframe and hilight the groups that are exceeding the average attrition % and displaing the guided value\n\ndef Visualize_Group_By_Column(cname, data):\n    #Calculate % of attrition using overall data\n    gv = data.groupby(by=['Attrition']).get_group('Yes').Attrition.count() \/ data.index.size\n    \n    data_x = data.groupby(by=[cname,'Attrition']).Attrition.count()\n    data_y = data.groupby(by=[cname,'Attrition']).groups.keys()\n    data_x_lst = [x for x in data_x]\n    data_y_lst = [cname + ''.join(str(y)) for y in data_y]\n    data_z_lst = [data.groupby(by=[cname]).get_group(k).index.size for k in data.groupby(by=[cname]).groups.keys()]\n    \n    #Calculate count of expected attrition using gv\n    list2 = [nn for m in [h for h in zip(data_z_lst, list(map(lambda x:x*gv, data_z_lst)))] for nn in m]\n    plt.figure(figsize=(15,10))\n    bars = plt.bar(data_y_lst, data_x_lst, color='maroon', width=0.1)\n    plt.plot(list2,\"--\")\n    for b,j in zip(bars,list2):\n        vx = str(round(b.get_height(),0)) + \" > \" + str(round(j,2))\n    \n    #Identify attrition rate exceeding the guided count value\n        if (b.get_height() > j):\n            plt.text(b.get_x(), b.get_height() + 0.2, vx)\n            b.set_color('r')\n    plt.xticks(rotation=45, ha='right')\n    plt.title(\"Grouped by \" + cname)\n    plt.show()","eabc7747":"## Choosing only columns having distinct values < 15 for exploratory analsysis\nfor c in data.columns:\n    if data[c].nunique() > 2 and data[c].nunique() < 15:\n        print(c)","a8527e2d":"## Use defining function against column BussinessTravel\n\nx = Visualize_Group_By_Column('BusinessTravel',data)\n\n## Result -> Group \"Travel Frequently\" contribute for higher Attrition","6a6f1f88":"## Use defining function against column BussinessTravel\n\nx = Visualize_Group_By_Column('Department',data)\n\n## Result -> Departments \"HumanResources\" and \"Sales\" contribute to higher attrition","4758b77b":"## Use defining function against column Education\n\nx = Visualize_Group_By_Column('Education',data)\n\n## Result -> Employees having education level 1 and 3 slightly exceeded the attrition value","d035d2cd":"## Use defining function against column EducationField\n\nx = Visualize_Group_By_Column('EducationField',data)\n\n## Result -> Employees beloning to \"HumarnResources\", \"Marketting\" and \"Technical Degress\" have more attrition","8499b429":"## Use defining function against column EnvironmentSatisfaction\n\nx = Visualize_Group_By_Column('EnvironmentSatisfaction',data)\n\n## Result -> Employees having lesser environment Satisfaction contribute more attrition","806bd6c7":"## Use defining function against column JobInvolvement\n\nx = Visualize_Group_By_Column('JobInvolvement',data)\n\n## Result -> Employees with lesser job involvement contribute more to Attrition","84d68757":"## Use defining function against column JobLevel\n\nx = Visualize_Group_By_Column('JobLevel',data)\n\n## Result -> Employees in Job Level 1 contribute more to Attrition","0bf44945":"## Use defining function against column JobRole\n\nx = Visualize_Group_By_Column('JobRole',data)\n\n## Result -> Similar to Department, Jobroles in department 'HumanResources', 'Technical' and 'Sales' have more attrition rates","edf20f4e":"## Use defining function against column MaritalStatus\n\nx = Visualize_Group_By_Column('MaritalStatus',data)\n\n## Result -> Employees with Marital Status Single contribute more to Attrition","ad5aecd3":"## Use defining function against column WorkLifeBalance\n\nx = Visualize_Group_By_Column('WorkLifeBalance',data)\n\n## Result -> Worklife balance may not be a much contributor as Attrition is higher across all groups","fd54dfbf":"thanks for reading my analysis, Kindly share feed back!!.","250c4ce8":"though all types of business travel contribute to Attrition, Employees travelling frequently have higher attrition compared to expected level 45."}}