{"cell_type":{"d9fa15ab":"code","4649db40":"code","52da3a4a":"code","6f60b9fe":"code","3b81c12b":"code","6c204a89":"code","40813c5d":"code","5b16a651":"code","85b7951c":"code","6d6b61eb":"code","df5ce433":"code","ca8f559a":"code","dcf7439d":"code","e6658547":"code","5609d080":"code","488d9805":"code","abff619b":"code","eec34913":"code","3bc11833":"code","e79f3440":"code","76698d12":"code","e398609a":"code","b4615034":"code","0e02424b":"code","fa25f055":"code","8406a79b":"code","8287274e":"code","879c4526":"code","44f03a0c":"markdown","2a50fc36":"markdown","46cbb987":"markdown","0a64252d":"markdown","9c83bfac":"markdown","8cf58140":"markdown"},"source":{"d9fa15ab":"#importing libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4649db40":"#importing dataset\nds = pd.read_csv('..\/input\/telecom-users-dataset\/telecom_users.csv')","52da3a4a":"#reviewing dataset\npd.set_option('display.max_columns',None)\nds.head()","6f60b9fe":"#checking type of feaures\nds.info()","3b81c12b":"#as you can see TotalCharges is object and hence converting it into float values\ndef convert(x):\n    try:\n        return float(x)\n    except:\n        return np.NaN\nds['TotalCharges'] = ds['TotalCharges'].apply(convert)","6c204a89":"#dropping these 2 features as they are unnecessary\nds.drop(\"Unnamed: 0\",axis=1,inplace = True)\nds.drop(\"customerID\",axis=1,inplace = True)","40813c5d":"#dataset has 5986 rows and 20 columns\nds.shape","5b16a651":"#checking for null values\nds.isnull().sum()","85b7951c":"#taking care of null values\nds[\"TotalCharges\"]=ds[\"TotalCharges\"].fillna(ds[\"TotalCharges\"].mean())","6d6b61eb":"ds.describe()","df5ce433":"sns.distplot(ds['MonthlyCharges'])","ca8f559a":"sns.distplot(ds['TotalCharges'])","dcf7439d":"tenure = ds['tenure']\nplt.figure(figsize=(10, 7))\nsns.histplot(tenure, bins=50, alpha=0.8)\nplt.title('months a person has been a client of the company', fontsize=18, pad=10)\nplt.xticks(list(range(0, tenure.max(), 5)), fontsize=12)\nplt.yticks(list(range(0, 550, 30)), fontsize=12)\nplt.xlabel('Number of months', fontsize=16)\nplt.ylabel('Number of clients', fontsize=16)\nplt.show()","e6658547":"PaymentMethod = ds['PaymentMethod'].value_counts()\nplt.figure(figsize=(10, 7))\nsns.barplot(x=PaymentMethod.index, y=PaymentMethod.values, alpha=0.8)\nplt.title('clients and their type of payment', fontsize=18, pad=10)\nplt.ylabel('Number of clients', fontsize=14)\nplt.xlabel('Payment type', fontsize=14)\nplt.show()","5609d080":"sns.pairplot(ds,hue = 'Churn')","488d9805":"plt.figure(figsize=(12,10))\nsns.heatmap(ds.corr(),annot=True)","abff619b":"#taking care of categorical values\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ncat = list(ds.dtypes[ds.dtypes == object].index)\nfor i in cat:\n    ds[i]=le.fit_transform(ds[i])","eec34913":"ds.head()","3bc11833":"#defining dependent and independent variables\nx = ds.iloc[:, :-1].values\ny = ds.iloc[:, -1].values","e79f3440":"#splitting data into training and testing set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","76698d12":"#training model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter=1000)\nlr.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = lr.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nlra = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',lra)","e398609a":"#training model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',p = 2)\nknn.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nknna = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","b4615034":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'linear')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva =accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","0e02424b":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva2 = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","fa25f055":"#training model\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = nb.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nnba = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","8406a79b":"#training model\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy')\ndt.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = dt.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\ndta = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","8287274e":"#training model\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nrf.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = rf.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nrfa = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","879c4526":"#comparing accuracies\nplt.figure(figsize= (8,7))\nac = [lra,knna,sva,sva2,nba,dta,rfa]\nname = ['LogReg','knn','svm','KSvm','NBayes','DTree', 'RForest']\nplt.bar(name,ac)","44f03a0c":"AS YOU CAN SEE THE VARIOUS ACCURACIES, AMONG WHICH LOGISTIC REGRESSION DID BEST","2a50fc36":"**APPLYING VARIOUS MODELS**","46cbb987":"**VISUALIZING DATASET**","0a64252d":"PREDICTING CHURN BY APPLYING VARIOUS CLASSIFICATION MODELS. ","9c83bfac":"**NULL VALUES FOUND IN TotalCharges**","8cf58140":"**LOGISTIC REGRESSION**"}}