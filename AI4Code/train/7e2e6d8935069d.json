{"cell_type":{"55ec922d":"code","699aeb5e":"code","10da729b":"code","d836f0b0":"code","cbea5a15":"code","fe70e833":"code","9a7434aa":"code","95c7c20d":"code","e6d975d7":"code","879488bd":"code","eb2b1d37":"code","eb5eabb5":"code","a46ce6ad":"code","0db132da":"code","4571533e":"code","b19f67db":"code","a68cc247":"code","6df269dc":"code","78c0e34e":"code","eb979e0d":"code","3feccf2e":"code","4905030f":"code","43996ae2":"code","fb8d36c0":"code","a64eaeb3":"code","fc9eca64":"markdown","9958dd69":"markdown","287acece":"markdown","6f6a7405":"markdown","0b80a8f7":"markdown","c857a9d1":"markdown","6c17a13b":"markdown","d0412936":"markdown","8aa89e79":"markdown","275b6363":"markdown","451b166a":"markdown","daedcdc1":"markdown","00cc65e6":"markdown","61f8ffb3":"markdown","59b65a98":"markdown","dff3c0e1":"markdown","9e8def02":"markdown","cabca8ea":"markdown"},"source":{"55ec922d":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.utils.data as utils\nfrom torchvision import transforms\nimport torch.nn.functional as F","699aeb5e":"path = '..\/input\/severstal-steel-defect-detection\/'","10da729b":"tr = pd.read_csv(path + 'train.csv')\nprint(len(tr))\ntr.head()","d836f0b0":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\ndf_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","cbea5a15":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","fe70e833":"columns = 1\nrows = 4\nfig = plt.figure(figsize=(20,columns*rows+6))\nfor i in range(1,columns*rows+1):\n    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n    fig.add_subplot(rows, columns, i).set_title(fn)\n    img = cv2.imread( path + 'train_images\/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n    img[mask==1,0] = 255\n    plt.imshow(img)\nplt.show()","9a7434aa":"class ImageData(Dataset):\n    def __init__(self, df, transform, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.subset = subset\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images\/'\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):                      \n        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n        img = Image.open(self.data_path + fn)\n        img = self.transform(img)\n\n        if self.subset == 'train': \n            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n            mask = transforms.ToPILImage()(mask)            \n            mask = self.transform(mask)\n            return img, mask\n        else: \n            mask = None\n            return img       ","95c7c20d":"data_transf = transforms.Compose([\n                                  transforms.Scale((256, 256)),\n                                  transforms.ToTensor()])\ntrain_data = ImageData(df = df_train, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size=4)","e6d975d7":"plt.imshow(train_data[3][0].permute(1, 2, 0))","879488bd":"plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))","eb2b1d37":"def convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n        nn.ReLU(inplace=True),\n    )\n\nclass UNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        \n        self.base_model = models.resnet18()\n        self.base_model.load_state_dict(torch.load(\"..\/input\/resnet18\/resnet18.pth\"))\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3])\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","eb5eabb5":"model = UNet(n_class=1).cuda()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), weight_decay=1e-4, lr = 0.001, momentum=0.9)","a46ce6ad":"%%time\nfor epoch in range(5):      \n    model.train()         \n    for ii, (data, target) in enumerate(train_loader):                         \n        data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)  \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()          \n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))","0db132da":"plt.imshow(train_data[6][0].permute(1, 2, 0))","4571533e":"x = train_data[6][0].unsqueeze(0)\no = model(x.cuda())  \no = o.cpu().detach().numpy() * (-1)\ntmp = np.copy(o)\nmn = np.mean(o)*1.2\ntmp[tmp<mn] = 0\ntmp[tmp>mn] = 1\nplt.imshow(np.squeeze(tmp))","b19f67db":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))\nsub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\nprint(len(sub4))\nsub4.head()","a68cc247":"test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","6df269dc":"%%time\npredict = []\nmodel.eval()\nfor data in test_loader:\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy() * (-1)    \n    predict.append(abs(output[0]))","78c0e34e":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","eb979e0d":"%%time\npred_rle = []\n  \nfor p in predict:        \n    img = np.copy(p)\n    mn = np.mean(img)*1.2\n    img[img<=mn] = 0\n    img[img>mn] = 1\n    img = cv2.resize(img[0], (1600, 256))\n    \n    pred_rle.append(mask2rle(img))","3feccf2e":"submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\nsubmit.head()","4905030f":"img_s = cv2.imread( path + 'test_images\/'+ submit['ImageId_ClassId'][47].split('_')[0])\nplt.imshow(img_s)","43996ae2":"mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\nplt.imshow(mask_s)","fb8d36c0":"submit.head(10)","a64eaeb3":"submit.to_csv('submission.csv', index=False)","fc9eca64":"### Training","9958dd69":"#### To simplify and speed up process, n this kernel I use only images with ClassId=4","287acece":"### Resize images","6f6a7405":"### Read submit file","0b80a8f7":"### Prepare submission file","c857a9d1":"### Show some image and mask","6c17a13b":"Architecture of Model is U-Net with pretrained encoder. In our case it ResNet18.\n\n![](https:\/\/github.com\/ushur\/Severstal-Steel-Defect-Detection\/blob\/master\/unet.jpg?raw=true)","d0412936":"### Create U-Net Model","8aa89e79":"### Show prediction on image from train dataset","275b6363":"### Create test Dataset and DataLoader","451b166a":"### Prediction","daedcdc1":"### Display some images","00cc65e6":"### Create train Dataset and DataLoader","61f8ffb3":"### Import necessary libraries","59b65a98":"### Read train dataframe","dff3c0e1":"### Encode mask ","9e8def02":"### Decode mask","cabca8ea":"### Steel Defect Detection \n\nThis is basic kernel to start participating in this competition.\nIt shows how to use PyTorch for solving the segmentation problem.\nIf you prefer to use Keras, I also created others basic Kernels: \n1. https:\/\/www.kaggle.com\/ateplyuk\/keras-starter-segmentation\n1. https:\/\/www.kaggle.com\/ateplyuk\/keras-starter-u-net"}}