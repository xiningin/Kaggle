{"cell_type":{"56f2115c":"code","4e9e5e92":"code","305c8b2d":"code","2e3c0e86":"code","5b938733":"code","cd43cd95":"code","d95bae5b":"code","38023039":"code","e578e8d2":"markdown","2de0f107":"markdown","d097c85d":"markdown"},"source":{"56f2115c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\n%matplotlib inline\nml.style.use('ggplot')\n\n# Splitting and metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e9e5e92":"test_data = pd.read_csv('\/kaggle\/input\/years-of-experience-and-salary-dataset\/Salary_Data.csv')\nprint(test_data.shape)\ntest_data.head(10)","305c8b2d":"test_data.info()","2e3c0e86":"test_data.describe()","5b938733":"class LinRegGD():\n    def __init__(self,epochs=1000,lr=0.001):\n        self.b0 = 0      # Intercept\n        self.b1 = 0      # Slope\n        self.epochs = epochs\n        self.lr = lr\n    def fit(self,trainx,trainy):\n        # Total number of values\n        N = len(trainx)\n        \n        # Performing the gardient descent\n        for _ in range(self.epochs):\n            Ypred_curr = self.b0 + self.b1*trainx    # Current predicted value\n            b0_d = (-2\/N)*sum(trainy - Ypred_curr)    # Derivative term based on intercept\n            b1_d = (-2\/N)*sum(trainx*(trainy - Ypred_curr))    # Derivative term based on slope\n            \n            # Update slope and intercept\n            self.b1 = self.b1 - (self.lr*b1_d)\n            self.b0 = self.b0 - (self.lr*b0_d)\n        return self\n    def predict(self,testx):\n        Y_pred = self.b0 + (self.b1*testx)\n        return Y_pred","cd43cd95":"X = np.array(test_data.iloc[:,0].values)\ny = np.array(test_data.iloc[:,1].values)\ntrainx,testx,trainy,testy = train_test_split(X,y,test_size=0.3,random_state=5)\n\nlgd = LinRegGD(epochs=5000,lr=0.001)\nlgd.fit(trainx,trainy)\ny_pred = lgd.predict(testx)\ny_pred","d95bae5b":"print(\"R2 Score for this model = \", r2_score(testy,y_pred))","38023039":"plt.figure(figsize=(10,5))\nplt.plot(testx,y_pred,color='blue',label=\"Best Fit Line\")\nplt.scatter(X,y,color='red',label=\"Data points\")\nplt.xlabel(\"YearsExperience\")\nplt.ylabel(\"Salary\")\nplt.title(\"PLOTTING THE BEST FIT CURVE\")\nplt.show()","e578e8d2":"# PLOTTING THE BEST FIT CURVE","2de0f107":"# LINEAR REGRESSION USING GRADIENT DESCENT FROM SCRATCH\nWe create a class, LinRegGD, and define two major methods :\n\n1. fit()\n2. predict()","d097c85d":"# TESTING"}}