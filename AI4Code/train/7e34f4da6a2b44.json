{"cell_type":{"ec0a281e":"code","b81f2b44":"code","81265cb3":"code","b7c87c78":"code","e166bd2f":"code","3096e004":"code","66179acf":"code","78b828f6":"code","f7d2673f":"code","afe1ee8d":"code","4f0313c2":"code","21933be7":"code","237105c0":"code","791760a9":"code","23fc576f":"code","22d083da":"code","89215bd6":"code","e5b3e6f2":"code","713df454":"code","42dfca69":"code","34a7de38":"code","2ad48c1d":"code","cd750ca7":"code","8e6fd532":"code","0f112a7e":"code","276e1b86":"code","3849089b":"code","76583e16":"code","953aa1bb":"code","739f32f4":"code","03ad824f":"code","b7c7d98c":"code","eb163c86":"code","477d4823":"code","dae63c61":"code","9cf08ece":"code","95096a14":"code","5d0bb54a":"code","6304c9a7":"code","c4e1c99f":"code","aae2ecce":"code","301cd4f5":"code","3070f2f7":"code","113e5cd9":"code","890934dc":"code","a2fe6f48":"code","6c937309":"code","e5142e34":"code","edd41028":"code","a83a4d3a":"code","f45e12b5":"code","6e21a7f4":"code","f16c3cf5":"code","417e816c":"code","60959f27":"markdown","190c31f2":"markdown","52d9f6d6":"markdown","1ae2769c":"markdown","6fc6ac32":"markdown","8c59dc29":"markdown","91033b45":"markdown","c138a0ec":"markdown","8511800b":"markdown","19bfd789":"markdown","59486eb0":"markdown"},"source":{"ec0a281e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b81f2b44":"df = pd.read_csv('\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')","81265cb3":"df.info()","b7c87c78":"df.describe()","e166bd2f":"df.profile_report(title='Campus Placement Data - Report', progress_bar=False)","3096e004":"df.drop('sl_no', axis=1, inplace= True)","66179acf":"sns.countplot(\"gender\", hue=\"status\", data=df)\nplt.show()","78b828f6":"#This plot ignores NaN values for salary, igoring students who are not placed\nsns.kdeplot(df.salary[ df.gender==\"M\"])\nsns.kdeplot(df.salary[ df.gender==\"F\"])\nplt.legend([\"Male\", \"Female\"])\nplt.xlabel(\"Salary (100k)\")\nplt.show()","f7d2673f":"#At first we check our target variable\nsns.set_style(\"whitegrid\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\nsns.distplot(df['salary'],color=\"b\")\nsns.despine(trim=True, left=True)\nplt.xlabel('salary')\nplt.ylabel('Frequency')\nplt.title('Distribution of salary')\nprint('Skewness: %f', df['salary'].skew())\nprint(\"Kurtosis: %f\" % df['salary'].kurt())\nplt.show()","afe1ee8d":"sns.countplot(x = df['ssc_b'])\nplt.title('count of ssc_b')\nplt.xlabel('ssc_b')\nplt.ylabel('count')\nplt.show()","4f0313c2":"sns.countplot(x = df['hsc_b'])\nplt.title('count of hsc_b')\nplt.xlabel('hsc_b')\nplt.ylabel('hsc_b')\nplt.show()","21933be7":"sns.countplot(x = df['hsc_s'])\nplt.title('count of hsc_s')\nplt.xlabel('hsc_s')\nplt.ylabel('hsc_s')\nplt.show()","237105c0":"sns.countplot(x = df['degree_t'])\nplt.title('count of degree_t')\nplt.xlabel('degree_t')\nplt.ylabel('degree_t')\nplt.show()","791760a9":"sns.countplot(x = df['workex'])\nplt.title('count of workex')\nplt.xlabel('workex')\nplt.ylabel('workex')\nplt.show()","23fc576f":"sns.countplot(x = df['specialisation'])\nplt.title('count of specialisation')\nplt.xlabel('specialisation')\nplt.ylabel('specialisation')\nplt.show()","22d083da":"sns.countplot(x = df['status'])\nplt.title('count of status')\nplt.xlabel('status')\nplt.ylabel('status')\nplt.show()","89215bd6":"df_clf = df.copy()\ndf_reg = df.copy()","e5b3e6f2":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","713df454":"for col in ('gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation', 'status'):\n  df_clf[col] = le.fit_transform(df_clf[col])","42dfca69":"df_clf.head()","34a7de38":"#we can drop the salary coloumn for our classification problem\ndf_clf.drop('salary', axis=1, inplace= True)","2ad48c1d":"#Correlation and Heatmap\ncorr = df_clf.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap= True)\nplt.figure(figsize =(12, 8))\nsns.heatmap(corr,\n            xticklabels = corr.columns.values,\n            yticklabels = corr.columns.values,\n            annot=True,fmt='.2f',linewidths=0.30,\n            cmap = colormap, linecolor = 'white')\nplt.title('correlations between features')","cd750ca7":"#Pairplot\nsns.pairplot(data = df_clf)\nplt.title('pairplot of data')\nplt.show()","8e6fd532":"df_clf.head()","0f112a7e":"x = df_clf.iloc[:, 0:12].values\nprint(x)","276e1b86":"y = df_clf.iloc[:, 12:13].values\nprint(y)","3849089b":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","76583e16":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","953aa1bb":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(solver='liblinear', random_state = 0)\nclassifier.fit(x_train, y_train)","739f32f4":"y_pred = classifier.predict(x_test)","03ad824f":"from sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_test, y_pred)\ncr = classification_report(y_test, y_pred)\nprint(cm)\nprint(cr)","b7c7d98c":"from sklearn.model_selection import cross_val_score\naccuraices = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuraices.mean()*100))\nprint(\"Standerd Deviation: {:.2f} %\".format(accuraices.std()*100))","eb163c86":"#Let see the ROC curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, y_pred)\nprint('AUC: %.3f' % auc)\n\nfig = plt.figure(figsize=(15,15))\nax = plt.subplot2grid((3,2), (0,0))\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.plot(fpr, tpr, marker='.')\nplt.show()","477d4823":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","dae63c61":"y_pred = classifier.predict(x_test)","9cf08ece":"from sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_test, y_pred)\ncr = classification_report(y_test, y_pred)\nprint(cm)\nprint(cr)","95096a14":"from sklearn.model_selection import cross_val_score\naccuraices = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuraices.mean()*100))\nprint(\"Standerd Deviation: {:.2f} %\".format(accuraices.std()*100))","5d0bb54a":"#Dropping NaNs (in Salary)\ndf_reg.dropna(inplace=True)","6304c9a7":"df_reg.info()","c4e1c99f":"#we can drop the status coloumn\ndf_reg.drop('status', axis=1, inplace= True)","aae2ecce":"df_reg = pd.get_dummies(df_reg).reset_index(drop=True)\ndf_reg.shape","301cd4f5":"#Correlaion & Heatmap\ncorr = df_reg.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap= True)\nplt.figure(figsize =(12, 8))\nsns.heatmap(corr,\n            xticklabels = corr.columns.values,\n            yticklabels = corr.columns.values,\n            annot=True,fmt='.2f',linewidths=0.30,\n            cmap = colormap, linecolor = 'white')\nplt.title('correlations between features')","3070f2f7":"#Lets look the correlation score\nprint (corr['salary'].sort_values(ascending=False), '\\n')","113e5cd9":"#Seperating Depencent and Independent Vaiiables\ny1 = df_reg[\"salary\"].values\nx1 = df_reg.drop(\"salary\", axis=1)\nx1 = df_reg.drop(\"ssc_b_Central\",axis=1)\nx1 = df_reg.drop(\"hsc_b_Others\",axis=1)\nx1 = df_reg.drop(\"hsc_s_Commerce\",axis=1)\nx1 = df_reg.drop(\"degree_t_Others\",axis=1)\nx1 = df_reg.drop(\"hsc_s_Arts\",axis=1)\nx1 = df_reg.drop(\"degree_p\",axis=1)\nx1 = df_reg.drop(\"workex_No\",axis=1)\nx1 = df_reg.drop(\"specialisation_Mkt&HR\",axis=1)\nx1 = df_reg.drop(\"gender_F\",axis=1)\nx1 = df_reg.drop(\"degree_t_Comm&Mgmt\",axis=1)\ncolumn_names = x1.columns.values","890934dc":"#Removing outlayer from data\nx1 = x1[y1 < 400000]\ny1 = y1[y1 < 400000]","a2fe6f48":"x1 = x1.iloc[:,:].values\nprint(x1)","6c937309":"from sklearn.model_selection import train_test_split\nx1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size = 0.2, random_state = 0)","e5142e34":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx1_train = sc.fit_transform(x1_train)\nx1_test = sc.transform(x1_test)","edd41028":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators= 100, random_state=0)\nregressor.fit(x1_train, y1_train) ","a83a4d3a":"y1_pred = regressor.predict(x1_test)","f45e12b5":"print(y1_pred)","6e21a7f4":"print(y1_test)","f16c3cf5":"accuraices_train = regressor.score(x1_train, y1_train)\naccuraices_test = regressor.score(x1_test, y1_test)\nprint(accuraices_train)\nprint(accuraices_test)","417e816c":"#Visualising the Acutal and predicted Result\nplt.plot(y1_test, color = 'deeppink', label = 'Actual')\nplt.plot(y1_pred, color = 'blue', label = 'Predicted')\nplt.grid(alpha = 0.3)\nplt.xlabel('Number of Candidate')\nplt.ylabel('Salary')\nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()","60959f27":"Data preprossing","190c31f2":"We note that some NaN values in sarlay column because of those who are not get job. For predict salary we drop NaN values.","52d9f6d6":"Lets apply Logistic Regression","1ae2769c":"We note that accuracy is good enough ","6fc6ac32":"EDA","8c59dc29":"Machine Learning","91033b45":"We not that accuray is not better than Logistic Regression","c138a0ec":"As predict the salary we can removed the negetivly correlated variables","8511800b":"Now Predict the salary which is regression problem.","19bfd789":"Lets apply Random Forest","59486eb0":"We have two problems. One is binary classification and other is regression. Lets make a copy of data, before we proceeed with specific problems"}}