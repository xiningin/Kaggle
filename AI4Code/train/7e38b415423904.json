{"cell_type":{"3c1a9c1f":"code","c007034b":"code","10985fa8":"code","69e76c93":"code","0ecb0555":"code","c51a03ca":"code","d67e1458":"code","49a8dfa4":"code","039316a6":"code","ac83352d":"code","435b395c":"code","078ca3cc":"code","4351bca0":"code","9c05fae3":"code","b978529c":"code","c45d0872":"code","91cb6c46":"code","4e8387d2":"code","3b2ab5cd":"code","7fd1dc6a":"code","5763afbc":"code","18e69d48":"code","4c9706d4":"code","d9f72ad3":"code","115b7ff0":"code","814c73f6":"code","a5cf2b35":"code","9506dfb7":"code","dcccbaa2":"markdown","651798cf":"markdown","3db7d84c":"markdown","e0bb48dc":"markdown","d7f674ec":"markdown","ee23adc9":"markdown","7964bc98":"markdown","6c39ba43":"markdown","87d4d9d1":"markdown","3547afea":"markdown","362479d4":"markdown","f5da5912":"markdown","da6ae924":"markdown","0184b7c4":"markdown","c422cb55":"markdown","391bd02a":"markdown","a72b1ad0":"markdown","510ace60":"markdown","460eba05":"markdown","5a53c394":"markdown","59cc3be6":"markdown","3a6109ba":"markdown","dee3f071":"markdown","990b0a9f":"markdown","e888c636":"markdown","395ffb88":"markdown","ac82f04a":"markdown","f6f6b62a":"markdown","f53512c7":"markdown","8af6adf1":"markdown","5538c800":"markdown","0905ece5":"markdown","234a09a7":"markdown","81e3e1cc":"markdown","52296c27":"markdown"},"source":{"3c1a9c1f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import (RepeatedStratifiedKFold, cross_validate,\n                                     train_test_split, GridSearchCV,\n                                     LeaveOneOut, KFold, StratifiedKFold,\n                                     cross_val_score)\n\nfrom sklearn.metrics import (classification_report, balanced_accuracy_score,\n                             precision_score, roc_auc_score, accuracy_score,\n                             f1_score, confusion_matrix,classification_report,roc_curve,precision_recall_curve)\nimport traceback\nimport re\nimport pandas.core.algorithms as algos\nfrom pandas import Series\nimport scipy.stats.stats as stats\nimport string\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport random","c007034b":"test = pd.read_csv('..\/input\/task-04\/test_data_without_label.csv')\ndados = pd.read_csv('..\/input\/task-04\/training_data.csv')","10985fa8":"sepsis_ratio = dados['sepse'].value_counts()\nprint(sepsis_ratio)\nsepsis_ratio = sepsis_ratio[1] \/ sepsis_ratio.sum()\nprint(sepsis_ratio)","69e76c93":"dados.isnull().mean().sort_values(ascending = False)","0ecb0555":"dados.drop(columns = \"respiracao\", inplace = True)\ntest.drop(columns = \"respiracao\", inplace = True)","c51a03ca":"def corrigePulso(df, isTest = False):\n    \n    if isTest:\n        sns.boxplot(y = df[\"pulso\"])\n        plt.title(\"Box Plot para a vari\u00e1vel Pulso - Antes de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pulso\"])\n        plt.title(\"Box Plot para a vari\u00e1vel Pulso - Antes de Modificar\")\n        plt.show()\n        \n    indices = df['pulso'].between(600,2000)\n    df.loc[indices,'pulso'] = df.loc[indices,'pulso']\/10\n    indices = df['pulso'] == 0\n    df.loc[indices,'pulso'] = np.nan\n    indices = df['pulso'].between(0,15)\n    df.loc[indices,'pulso'] = df.loc[indices,'pulso']*10\n    \n    if isTest:\n        sns.boxplot(y = df[\"pulso\"])\n        plt.title(\"Box Plot para a vari\u00e1vel Pulso - Depois de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pulso\"])\n        plt.title(\"Box Plot para a vari\u00e1vel Pulso - Depois de Modificar\")\n        plt.show()\n    \n    return df\n\ndef corrigeTemperatura(df, isTest = False):\n    \n    if isTest:\n        sns.boxplot(y = df[\"temperatura\"])\n        plt.title(\"Box Plot para a Temperatura - Antes de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"temperatura\"])\n        plt.title(\"Box Plot para a Temperatura - Antes de Modificar\")\n        plt.show()\n    \n    indices = df[\"temperatura\"].between(300,400)\n    df.loc[indices,\"temperatura\"] = df.loc[indices,\"temperatura\"]\/10\n    indices = df[\"temperatura\"]>3000\n    df.loc[indices,\"temperatura\"] = df.loc[indices,\"temperatura\"]\/100\n    df.loc[df[\"temperatura\"].between(41,299),\"temperatura\"] = np.nan\n    indices = df[\"temperatura\"]<0\n    df.loc[indices,\"temperatura\"] = -df.loc[indices,\"temperatura\"]\n    indices = df[\"temperatura\"].between(0,30)\n    df.loc[indices,\"temperatura\"] = np.nan\n\n    if isTest:\n        sns.boxplot(y = df[\"temperatura\"])\n        plt.title(\"Box Plot para a Temperatura - Depois de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"temperatura\"])\n        plt.title(\"Box Plot para a Temperatura - Depois de Modificar\")\n        plt.show()\n    \n    return df\n\ndef corrigePA(df, isTest = False):\n    \n    if isTest:\n        sns.boxplot(y = df[\"pa_min\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Min - Antes de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pa_min\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Min - Antes de Modificar\")\n        plt.show()\n        \n        \n    if isTest:\n        sns.boxplot(y = df[\"pa_max\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial max - Antes de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pa_max\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial max - Antes de Modificar\")\n        plt.show()\n    \n    # Provavelmente erro de digita\u00e7\u00e3o MIN\n    df.loc[df.loc[:, \"pa_min\"] > 300, \"pa_min\"] = df.loc[df.loc[:, \"pa_min\"] > 300, \"pa_min\"]\/10\n    \n    # Provavelmente erro de digita\u00e7\u00e3o MIN\n    df.loc[df.loc[:, \"pa_min\"] < 20, \"pa_min\"] = df.loc[df.loc[:, \"pa_min\"] < 20, \"pa_min\"]*10\n    \n    # Provavelmente erro de digita\u00e7\u00e3o MAX\n    df.loc[df.loc[:, \"pa_max\"] > 300, \"pa_max\"] = df.loc[df.loc[:, \"pa_max\"] > 300, \"pa_max\"]\/10\n    \n    # Provavelmente erro de digita\u00e7\u00e3o MAX\n    df.loc[df.loc[:, \"pa_min\"] < 20, \"pa_max\"] = df.loc[df.loc[:, \"pa_max\"] < 20, \"pa_max\"]*10\n    \n    \n    # Percebemos que de um modo geral as observa\u00e7\u00f5es relacionadas ao PA_MAX s\u00e3o menores do que as\n    # observa\u00e7\u00f5es relacionadas ao PA_MIN. Acreditamos que isso possa ser um erro na hora de nomear\n    # as colunas. Assim, como isso ocorre de maneira global, decidimos continuar fazendo da maneira\n    # que est\u00e1 nomeado.\n    # A \u00fanica inconsistencia \u00e9 todas as observa\u00e7\u00f5es do PA_MAX tem que ser menores do que que todas\n    # as observa\u00e7\u00f5es do PA_MAX.\n    # Nas linhas abaixo fazemos essa altera\u00e7\u00e3o.\n    if sum(df['pa_min'] < df['pa_max']) > 0:\n        indices = df[df['pa_min'] < df['pa_max']].index\n        for ind in indices:\n            aux = df.loc[ind, \"pa_min\"]\n            df.loc[ind, \"pa_min\"] = df.loc[ind, \"pa_max\"]\n            df.loc[ind, \"pa_max\"] = aux\n    \n    # dados considerados como \"normais\", isto \u00e9, n\u00e3o \u00e9 erro de digita\u00e7\u00e3o\n    indices = df[\"pa_min\"].between(20,300)\n    indices = indices == False # onde t\u00e1 True coloco False e onde est\u00e1 False coloco True\n    \n    df.loc[indices, \"pa_min\"] = np.nan\n    \n    # dados considerados como \"normais\", isto \u00e9, n\u00e3o \u00e9 erro de digita\u00e7\u00e3o\n    indices = df[\"pa_max\"].between(20,300)\n    indices = indices == False # onde t\u00e1 True coloco False e onde est\u00e1 False coloco True\n    \n    df.loc[indices, \"pa_max\"] = np.nan\n     \n    if isTest:\n        sns.boxplot(y = df[\"pa_min\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Min - Depois de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pa_min\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Min - Depois de Modificar\")\n        plt.show()\n\n    if isTest:\n        sns.boxplot(y = df[\"pa_max\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Max - Depois de Modificar\")\n        plt.show()\n    else:\n        sns.boxplot(x = df[\"sepse\"], y = df[\"pa_max\"])\n        plt.title(\"Box Plot para a Press\u00e3o Arterial Max - Depois de Modificar\")\n        plt.show() \n        \n    return df","d67e1458":"dados = corrigePulso(dados)","49a8dfa4":"dados = corrigeTemperatura(dados)","039316a6":"dados = corrigePA(dados)","ac83352d":"test = corrigePulso(test, isTest = True)","435b395c":"test = corrigeTemperatura(test, isTest = True)","078ca3cc":"test = corrigePA(test, isTest = True)","4351bca0":"dados.isnull().mean().sort_values(ascending = False)","9c05fae3":"def sub_na(df):\n    df['temperatura'].fillna(df['temperatura'].median(), inplace=True)\n    df['pulso'].fillna(df['pulso'].median(), inplace=True)\n    df['pa_min'].fillna(df['pa_min'].median(), inplace=True)\n    df['pa_max'].fillna(df['pa_max'].median(), inplace=True)\n    \n    return df","b978529c":"test = sub_na(test)\ndados = sub_na(dados)\ndados.isnull().mean().sort_values(ascending = False)","c45d0872":"X = np.array(dados.loc[:, ['temperatura', 'pulso', 'pa_min', 'pa_max']])\ny = np.array(dados.loc[:, 'sepse'])","91cb6c46":"model = GaussianNB()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=7)\nscores = cross_val_score(model, X, y, scoring = 'balanced_accuracy', cv = cv, n_jobs=-1)\nprint(\"Acur\u00e1cia m\u00e9dia: \", np.mean(scores),\"Desvio padr\u00e3o acur\u00e1cia: \" ,np.std(scores))","4e8387d2":"# hiperparametros para ajustar\nparam_grid = {\n    'n_estimators': [500,600],\n    'learning_rate': [0.1,1]\n}\n\ngs_ab = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid, n_jobs=-1, scoring = \"balanced_accuracy\")\ngs_ab.fit(X,y)\n\nprint('Melhores par\u00e2metros:', gs_ab.best_params_)","3b2ab5cd":"model = AdaBoostClassifier(n_estimators=gs_ab.best_params_[\"n_estimators\"], learning_rate = gs_ab.best_params_[\"learning_rate\"], algorithm='SAMME')\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=7)\nscores = cross_val_score(model, X, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\nprint(\"Acur\u00e1cia m\u00e9dia: \", np.mean(scores),\"Desvio padr\u00e3o acur\u00e1cia: \" ,np.std(scores))","7fd1dc6a":"# hiperparametros para ajustar\nparam_grid = {\n        'min_child_weight': [1, 5],\n        'gamma': [0.5, 1],\n        'subsample': [0.6, 0.8],\n        'colsample_bytree': [0.6, 0.8],\n        'max_depth': [4, 5]\n        }\n\ngs_ab = GridSearchCV(XGBClassifier(), param_grid = param_grid, n_jobs=-1, scoring = \"balanced_accuracy\")\n\ngs_ab.fit(X,y)\n\nprint('Melhores par\u00e2metros:', gs_ab.best_params_)","5763afbc":"model = XGBClassifier(colsample_bytree = gs_ab.best_params_['colsample_bytree'], gamma = gs_ab.best_params_['gamma'],\n                      max_depth = gs_ab.best_params_['max_depth'], min_child_weight= gs_ab.best_params_['min_child_weight'],  subsample = gs_ab.best_params_['subsample'] )\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=7)\nscores = cross_val_score(model, X, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\nprint(\"Acur\u00e1cia m\u00e9dia: \", np.mean(scores),\"Desvio padr\u00e3o acur\u00e1cia: \" ,np.std(scores))","18e69d48":"def _threshold_finder(model, X, y_true):\n      \n    y_predict_proba = model.predict_proba(X)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_true, y_predict_proba)\n    youden_idx = np.argmax(np.abs(tpr - fpr))\n    youden_threshold = thresholds[youden_idx]\n    plt.plot(fpr,tpr)\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    return youden_threshold","4c9706d4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, shuffle = True, random_state = 1367, stratify = y)","d9f72ad3":"fitted_model = XGBClassifier(colsample_bytree = gs_ab.best_params_['colsample_bytree'], gamma = gs_ab.best_params_['gamma'],\n                      max_depth = gs_ab.best_params_['max_depth'], \n                             min_child_weight= gs_ab.best_params_['min_child_weight'],  \n                             subsample = gs_ab.best_params_['subsample'] ).fit(X_train,y_train)","115b7ff0":"best_treshold = _threshold_finder(model = fitted_model, X = X_test, y_true = y_test)\nprint(\"Temos ent\u00e3o, que a melhor probabilidade de corte para o nosso problema \u00e9 : \",best_treshold,\"E abaixo temos tamb\u00e9m a curva ROC\")","814c73f6":"model = XGBClassifier(colsample_bytree = gs_ab.best_params_['colsample_bytree'], gamma = gs_ab.best_params_['gamma'],\n                      max_depth = gs_ab.best_params_['max_depth'], \n                             min_child_weight= gs_ab.best_params_['min_child_weight'],  \n                             subsample = gs_ab.best_params_['subsample'])\n\ncv = StratifiedKFold(n_splits=10)\nacc = list()\nfor train_i, test_i in cv.split(X,y):\n    train_x, train_y = X[train_i], y[train_i]\n    test_x, test_y = X[test_i], y[test_i]\n    model.fit(train_x,train_y)\n    predicted_proba = model.predict_proba(test_x)\n    pred_y = (predicted_proba [:,1] >= best_treshold).astype('int')        \n    # evaluate and store the results\n    acc.append(balanced_accuracy_score(y_true = test_y, y_pred = pred_y))\n        \n    print('.',end=\"\")\nprint('\\n')\nav_acc = np.mean(acc)\nstd_acc = np.std(acc)\nprint('Acur\u00e1cia m\u00e9dia: ',av_acc,'Desvio padr\u00e3o acurpacia: ',std_acc)","a5cf2b35":"#Submiss\u00e3o Kaggle\n#OBS: Como para a competi\u00e7\u00e3o do Kaggle est\u00e1 sendo avaliada a acur\u00e1cia n\u00e3o balanceada, \n#vamos predizer o modelo com a probabilidade de corte padr\u00e3o, por\u00e9m, salientamos que para nosso problema, uma probabilidade de corte \u00f3tima \u00e9 a melhor solu\u00e7\u00e3o.\n\nX_test = np.array(test.loc[:, ['temperatura', 'pulso', 'pa_min', 'pa_max']])\n\nmodel = XGBClassifier(colsample_bytree = gs_ab.best_params_['colsample_bytree'], gamma = gs_ab.best_params_['gamma'],\n                      max_depth = gs_ab.best_params_['max_depth'], min_child_weight= gs_ab.best_params_['min_child_weight'],  subsample = gs_ab.best_params_['subsample'] )\nmodel.fit(X,y)\ny_pred = model.predict(X_test) \nsub = pd.DataFrame(data = {'id':test.loc[:, \"id\"], 'sepse':y_pred})\nsub.to_csv('submission_XGB2.csv',index=False)","9506dfb7":"\nfor i in np.arange(0,len(predicted_proba[:,1])):\n  if predicted_proba[i,1] < 0.05:\n    print('Paciente:',test.loc[i, \"id\"],'Probabilidade:',round(predicted_proba[i,1],3),'verde')\n  elif predicted_proba[i,1] >= 0.05 and predicted_proba[i,1] < 0.3:\n    print('Paciente:',test.loc[i, \"id\"],'Probabilidade:',round(predicted_proba[i,1],3),'amarelo')\n  elif predicted_proba[i,1] >= 0.3:\n    print('Paciente:',test.loc[i, \"id\"],'Probabilidade:',round(predicted_proba[i,1],3),'vermelho')","dcccbaa2":"Propor\u00e7\u00e3o de casos positivos de Sepse nos dados de treinamento.","651798cf":"Percebemos, mediante o gr\u00e1fico acima que mesmo ap\u00f3s a corre\u00e7\u00e3o de alguns valores tem-se a presen\u00e7a de outliers.","3db7d84c":"Abaixo, temos ent\u00e3o a corre\u00e7\u00e3o das vari\u00e1veis para o conjunto de treino, assim como os plots de antes e depois destas corre\u00e7\u00f5es (j\u00e1 implementados nas fun\u00e7\u00f5es).","e0bb48dc":"* Corre\u00e7\u00e3o da vari\u00e1vel Temperatura","d7f674ec":"Podemos observar ent\u00e3o, que o modelo que obteve a maior acur\u00e1cia balanceada foi o modelo XGBClassifier, portanto iremos utilizar ele para os pr\u00f3ximos passos.","ee23adc9":"Vamos ent\u00e3o agora separar nossos dados em treino e teste para realizar o c\u00e1lculo da melhor probabilidade de corte.","7964bc98":"Destaca-se que consideramos o os valores de 0 a 30 da variavel temperatura como sendo um valor ausente.","6c39ba43":"- Corre\u00e7\u00e3o das vari\u00e1veis de press\u00e3o arterial","87d4d9d1":"# Task 04 - Sepsis Detection\n\nD\u00e9bora Mayumi Rissato - 5288223\n\nDouglas Decicino de Andrade - 10883512\n\nPaulino Ribeiro Villas Boas - 2950178\n\nRenan Silva Chun - 10691817\n\nRenan de Oliveira da Cruz - 10801090","3547afea":"* Corre\u00e7\u00e3o da vari\u00e1vel Temperatura","362479d4":"Substitu\u00edmos os valores ausentes pela mediana ","f5da5912":"* Corre\u00e7\u00e3o da vari\u00e1vel Pulso","da6ae924":"## Achando a melhor probabilidade de corte.","0184b7c4":"Abaixo temos o import de algumas bibliotecas.","c422cb55":"## Ajustes e valida\u00e7\u00e3o dos modelos.","391bd02a":"Assim, baseando-se nesse racioc\u00ednio, o conjunto de teste que temos ficaria:","a72b1ad0":"- Fun\u00e7\u00e3o para encontrar o threshold ideal para classifica\u00e7\u00e3o bin\u00e1ria:\n     * modelo: um objeto de modelo treinado (como xgboost, glmnet, ...)\n     *X: o conjunto de teste (pandas dataframe ou numpy array)\n     *y_true: os r\u00f3tulos verdadeiros da classe (lista ou matriz de 0's e 1's)","510ace60":"### XgBoost","460eba05":"### Naive Bayes","5a53c394":"### Ada boosting","59cc3be6":"Abaixo, temos ent\u00e3o a corre\u00e7\u00e3o das vari\u00e1veis para o conjunto de teste, assim como os plots de antes e depois destas corre\u00e7\u00f5es (j\u00e1 implementados nas fun\u00e7\u00f5es).","3a6109ba":"A partir do output acima notamos que, nos dados de treinamento, a vari\u00e1vel \"respira\u00e7\u00e3o\" cont\u00e9m cerca de 80% de valores ausentes. Sendo assim, optamos por excluir essa vari\u00e1vel do dataset em raz\u00e3o da n\u00famero de valores ausentes.","dee3f071":"# Conclus\u00e3o\n\nA sepse \u00e9 uma enfermidade perigosa e evolui rapidamente se n\u00e3o tratada a tempo. Em geral, o diagn\u00f3stico \u00e9 cl\u00ednico e laboratorial, com exames de sangue para contagem de leuc\u00f3citos. Entretanto, esses exames n\u00e3o s\u00e3o r\u00e1pidos, o que pode deixar o quadro do paciente evoluir rapidamente. Assim, \u00e9 essential monitorar os sinais vitais de pacientes para identificar aqueles com poss\u00edvel quadro de sepse.\n\nNesta task, tivemos o desafio de desenvolver um modelo de classifica\u00e7\u00e3o para identificar pacientes com sepse com base em seus sinais vitais. Se tiv\u00e9ssemos que implementar esse modelo em um hospital, dar\u00edamos como resposta a probabilidade do paciente estar com sepse. Em outras palavras, dar\u00edamos o grau de confian\u00e7a do modelo na classifica\u00e7\u00e3o de pacientes com sepse. Com base na curva ROC do melhor modelo e o tipo da enfermidade, definimos as seguintes faixas:\n\n* verde: Probabilidade do paciente estar com sepse entre 0 e 5%. Neste caso, o modelo tem um elevado n\u00edvel de confian\u00e7a de que o paciente est\u00e1 com sinais vitais normais, ou seja, com baixo risco de estar com sepse;\n\n* amarelo: probabilidade do paciente estar com sepse entre 5 e 30% (menor confian\u00e7a do modelo). Nesta faixa, os sinais vitais do paciente exige aten\u00e7\u00e3o, pois pode estar no in\u00edcio de um quadro de sepse. Recomendamos monitorar os dados vitais do paciente com frequ\u00eancia mais alta ou realizar outros exames cl\u00ednicos ou laboratoriais;\n\n* vermelho: probabilidade do paciente estar com sepse acima de 30%. Neste caso, o paciente tem grandes chances de estar com sepse e requer outros exames para confirma\u00e7\u00e3o, al\u00e9m de cuidados apropriados para esta enfermidade.\n\nAcreditamos que, com essas cores, a equipe do hospital pode triar os pacientes de forma objetiva e r\u00e1pida a partir dos dados vitais dos pacientes, otimizando o tempo e tratamento daqueles que mais precisarem.","990b0a9f":"* Corre\u00e7\u00e3o da vari\u00e1vel Pulso","e888c636":"Como temos um desbalanceamento consideranvelmente grande em rela\u00e7\u00e3o as observa\u00e7\u00f5es das classes, uma boa t\u00e9cnica que promete melhorar a performace do nosso modelo \u00e9 encontrar a probabilidade de corte que maximiza a nossa m\u00e9trica de valida\u00e7\u00e3o escolhida. Para isso, vamos utilizar a curva ROC.","395ffb88":"* Corre\u00e7\u00e3o das vari\u00e1veis de press\u00e3o arterial","ac82f04a":"Propor\u00e7\u00e3o de valores ausentes para cada vari\u00e1vel.","f6f6b62a":"Agora, aplicamos as fun\u00e7\u00f5es criadas nos dados.","f53512c7":"Vejemos agora a propor\u00e7\u00e3o de valores ausentes.","8af6adf1":"Nota-se que o dataset apresenta alto grau de desbalanceamento.","5538c800":"Importando os dados","0905ece5":"### Dados de Treinamento","234a09a7":"### Dados de Teste","81e3e1cc":"## Tratamento da base ","52296c27":"Abaixo, construimos algumas fun\u00e7\u00f5es que corrigem valores que acreditamos ter sido preenchidos err\u00f4neamente. Corre\u00e7\u00f5es como por exemplo:\n\n\n*   Possiveis erros de digita\u00e7\u00e3o (valores \"muito altos\" e \"muito baixos\" para a vari\u00e1vel observada). Acreditamos que o usu\u00e1rio digitou ou um zero a mais ou um a menos em alguns casos;\n*   Para vari\u00e1veis como temperatura, pulso, e PA min e max, substituimos valores igual a 0 por NAN's, pois este valor para estas vari\u00e1veis n\u00e3o faz sentido.\n\n"}}