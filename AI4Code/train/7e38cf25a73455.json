{"cell_type":{"c1cdf6b3":"code","1cc5e686":"code","90b1cb5c":"code","06b964f7":"code","ac729e03":"code","77592f6e":"code","eadc23ae":"code","e2b683b8":"code","c26f6abd":"code","91dd3af1":"code","76209005":"markdown","2c470ba9":"markdown","0a88c0c9":"markdown","a211fc70":"markdown","25068847":"markdown","f212af61":"markdown"},"source":{"c1cdf6b3":"import numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras \nimport pandas as pd\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt","1cc5e686":"ds = pd.read_csv(\"..\/input\/indian-cricketers-images\/players.csv\")\nds = ds.sample(frac=1).reset_index(drop=True)\n\nle = preprocessing.LabelEncoder()\nle.fit(ds['player'])\nds['player_trans'] = le.transform(ds['player'])\n\nn = int(len(ds))\nplayers = ds.player.nunique()\nprint(\"Number Of Players    : \",players)\nprint(\"Number Of Images     : \",n)\nprint(\"\\n\\nDistribution Per Player\")\nds['player'].value_counts().plot.bar()\n\nds = ds[:-6]\ntest = ds[-6:]","90b1cb5c":"for index,row in ds.iterrows():\n    if len(ds[ds['player']==row['player']])>20:\n        ds.drop(ds[ds['image']==row['image']].index , inplace=True)\n\nprint(\"Distribution Per Player\")\nds['player'].value_counts().plot.bar()","06b964f7":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:image = tf.image.transpose(image)\n    if p_rotate > .75:image = tf.image.rot90(image, k=3) \n    elif p_rotate > .5:image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:image = tf.image.rot90(image, k=1) \n\n    if p_pixel_1 >= .4:image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:image = tf.image.random_brightness(image, max_delta=.1)\n\n    if p_crop > .7:\n        if p_crop > .9:image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:image = tf.image.central_crop(image, central_fraction=.8)\n        else:image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(224*.8),224, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n    \n    image = tf.image.resize(image, [224,224])\n    return image,label\n\ndef load_img(image,player,player_transf):\n    path = \"..\/input\/indian-cricketers-images\/images\/\"+player+\"\/\"+image\n    img = tf.io.decode_jpeg(tf.io.read_file(path),channels=3)\n    img = tf.cast(img, tf.float32)\n    img = tf.image.resize(img, [224,224])\n    img = keras.applications.mobilenet_v2.preprocess_input(img)\n    return img,player_transf\ndataset = tf.data.Dataset.from_tensor_slices((ds.image.values,ds.player.values,ds.player_trans.values))","ac729e03":"train_ds = dataset.take(int(0.8*n))\nval_ds = dataset.skip(int(0.8*n))\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.map(load_img,num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.repeat(40).map(data_augment,num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.batch(32).prefetch(buffer_size=AUTOTUNE)\n\nval_ds = val_ds.map(load_img,num_parallel_calls=AUTOTUNE).batch(32).prefetch(buffer_size=AUTOTUNE)","77592f6e":"base_model = keras.applications.MobileNetV2(weights=\"imagenet\",include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(players, activation=\"softmax\")(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=output)\n\nfor layer in base_model.layers:\n    layer.trainable = False","eadc23ae":"checkpoint_path = \".\/checkpoints\/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)","e2b683b8":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\nhistory = model.fit(train_ds, epochs=20, validation_data=val_ds,verbose=1,callbacks=[cp_callback])","c26f6abd":"import matplotlib.pyplot as plt\npd.DataFrame(history.history)[['accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","91dd3af1":"i=0\ndef load_test_img(image,player,player_transf):\n    path = \"..\/input\/indian-cricketers-images\/images\/\"+player+\"\/\"+image\n    img = tf.io.decode_jpeg(tf.io.read_file(path),channels=3)\n    img = tf.cast(img, tf.float32)\n    img = tf.image.resize(img, [224,224])\n    img = keras.applications.mobilenet_v2.preprocess_input(img)\n    return img\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test.image.values,test.player.values,test.player_trans.values))\ntest_ds = test_ds.map(load_test_img).batch(6)\nprediction = model.predict(test_ds)\n\nfor index,row in test.iterrows():\n    img = tf.io.decode_jpeg(tf.io.read_file(\"..\/input\/indian-cricketers-images\/images\/\"+row['player']+\"\/\"+row['image']),channels=3)\n    imgplot = plt.imshow(img.numpy().astype(\"uint8\"),aspect='auto')\n    real = str(list(le.classes_)[row['player_trans']])\n    top_k_values, top_k_indices = tf.nn.top_k(prediction[i], k=3)\n    top_k_names = []\n    for k in range(3):\n        top_k_names+=[str(list(le.classes_)[top_k_indices[k]])]\n    plt.title(\"Real Value: \"+str(real)+\"\\nTop 3 Predicted Values: \"+str(top_k_names))\n    plt.show()\n    i+=1","76209005":"## Now let's make the distribution equal.","2c470ba9":"# Define Model","0a88c0c9":"# Test Cases","a211fc70":"# Training","25068847":"# Cricket Players Image Classification","f212af61":"# Import Data"}}