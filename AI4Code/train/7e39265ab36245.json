{"cell_type":{"5aec0f4f":"code","3f3142aa":"code","3a2af3c0":"code","e9ee24aa":"code","5ff935b4":"code","186e92c5":"code","e3efcac9":"code","1f72988e":"code","d6c3adf5":"code","7eb6f079":"code","8aec4064":"code","1e3d59c6":"code","e6885dad":"code","bd333b65":"code","8233615f":"code","5e0de045":"code","c9ab1d04":"code","8723bbc8":"code","fb41e68d":"code","3117c20e":"code","ba090672":"code","0e09a9c2":"code","12b75ed5":"code","70356ce4":"markdown","09ab8d52":"markdown","c8981522":"markdown","f2088125":"markdown","f9cbd4b9":"markdown","7a31c487":"markdown","abd26a19":"markdown","d0ee332b":"markdown","d9c41bf0":"markdown","b3fc5e38":"markdown","87f5502d":"markdown","06900581":"markdown","d4f3fb3a":"markdown","c380ee63":"markdown","ea7bb7a3":"markdown"},"source":{"5aec0f4f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, plot_roc_curve\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3f3142aa":"df  = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","3a2af3c0":"df.shape","e9ee24aa":"df.isnull().sum()","5ff935b4":"#check diagnosis types count\ndf['diagnosis'].value_counts()","186e92c5":"# Visualize how diagnosis distributed throghout the dataset'\nplt.figure(figsize=(10,8.5))\nsns.countplot(df['diagnosis'])\nplt.show()","e3efcac9":"#drop unwanted columns\ndf.drop(['Unnamed: 32'],axis = 1,inplace=True)","1f72988e":"#handle categorical variables\nlabel = LabelEncoder()\ndf['diagnosis'] = label.fit_transform(df['diagnosis'])\ndf","d6c3adf5":"plt.subplots(figsize = (40,40))\nsns.heatmap(df.corr(),annot=True,fmt=\"f\").set_title(\"Corelation Of Each Attributes\")\nplt.show()","7eb6f079":"x = df.drop(['diagnosis'],axis = 1)\ny = df['diagnosis']","8aec4064":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)","1e3d59c6":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","e6885dad":"#define functions for fit, & predict with each models\ndef models(mod,x_t,y_t,x_tes,y_tes,x_source,y_source):\n    \n    #Fit model\n    mod.fit(x_t,y_t)\n    \n    #Predict Model\n    pred = mod.predict(x_tes)\n    \n    #Accuracy Score\n    accuracy = accuracy_score(y_tes,pred)\n    \n    #Cross Validation Score\n    cross_validation = cross_val_score(mod,x_source,y_source,cv=5)\n    print(\"Accuracy Is : \",accuracy*100,\"%\")\n    \n    print(\"-------------------------------------------\")   \n    \n    print('Cross validations mean score ',round(np.mean(cross_validation)*100,4))\n    \n    print(\"-------------------------------------------\")\n    \n    #Confusion Metrix\n    print(confusion_matrix(y_tes, pred))\n    \n    print(\"-------------------------------------------\")    \n    \n    #Recall Score , Percision Score, F1 Score\n    print(\"Recall Score :\",recall_score(y_tes, pred, average='weighted'))\n    print(\"Percision Score :\",precision_score(y_tes, pred, average='weighted'))\n    print(\"F1 Score :\",f1_score(y_tes, pred, average='weighted'))\n    ","bd333b65":"model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=1500,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n\nmodels(model,x_train,y_train,x_test,y_test,x,y )","8233615f":"model_1 = DecisionTreeClassifier(random_state=0,criterion='gini',max_depth=None)\nmodels(model_1,x_train,y_train,x_test,y_test,x,y )","5e0de045":"model_2 = RandomForestClassifier(n_estimators=120,random_state=0)\nmodels(model_2,x_train,y_train,x_test,y_test,x,y )","c9ab1d04":"model_3 = ExtraTreesClassifier(n_estimators= 100,random_state=0)\nmodels(model_3,x_train,y_train,x_test,y_test,x,y )","8723bbc8":"model_4 = svm.SVC()\nmodels(model_4,x_train,y_train,x_test,y_test,x,y )","fb41e68d":"parameters = {'criterion':('gini', 'entropy'),\n              'n_estimators':[i for i in range(100,200,10)],\n              'min_samples_split':[i for i in range(2,10,2)],\n               'max_features':['auto', 'sqrt','log2']}\n\nbest_model = RandomForestClassifier()\n\nclf = GridSearchCV(best_model, parameters, cv=5)\nclf.fit(x_train, y_train)","3117c20e":"df_grid = pd.DataFrame(clf.cv_results_)\ndf_grid.head(5)","ba090672":"clf.best_params_","0e09a9c2":"clf.best_score_","12b75ed5":"clf.best_estimator_","70356ce4":"## Best Score","09ab8d52":"## Hyper Parameter Tuning With Random Forest Classifier Model","c8981522":"## Model Bulding","f2088125":"## **According to the above models Random Forest Classifier Model and support vecto model got 97% percent accuracy but Random Forrest Classifer also got 95.96% cross validation means score. so we can consider it has the best model for hyper parameter tuning**","f9cbd4b9":"## Import Libraries","7a31c487":"## Correlation with each variables","abd26a19":"## Decision Tree Classifer Model","d0ee332b":"## Best Estimators","d9c41bf0":"## Support Vector Model","b3fc5e38":"## Random Forest Classifier Model","87f5502d":"## Extra Tree Classifier Model","06900581":"## Getting Know About Dataset","d4f3fb3a":"## Pre Processing ","c380ee63":"## Best Parameters","ea7bb7a3":"## Logistic Regression Model"}}