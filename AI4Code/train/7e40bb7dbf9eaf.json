{"cell_type":{"1442d514":"code","63163ee0":"code","583263a4":"code","41a0f638":"code","5dd0f9c1":"code","1804f553":"code","c9b1f696":"code","4b467717":"code","a3be3d40":"code","733639b8":"code","5ee23aa2":"markdown","63aca607":"markdown","e7a7825f":"markdown","aa39b94a":"markdown","06102004":"markdown","310f84c4":"markdown","4e494e14":"markdown","d37cfc10":"markdown","8eebd97f":"markdown"},"source":{"1442d514":"import pandas as pd\n\ntrain = pd.read_csv('..\/input\/tweet-sentiment-analysis\/train.csv')\ntest = pd.read_csv('..\/input\/tweet-sentiment-analysis\/test.csv')","63163ee0":"train.head()","583263a4":"print(f\"There are {len(train)} tweets in the training data.\")\npositive = sum(train.target)\/len(train)\nprint(f\"{positive:.2f}% of the tweets are positive.\")\navg_len = sum([len(text) for text in train.text])\/len(train)\nprint(f\"The average length of the tweets is {avg_len:.1f} characters.\")","41a0f638":"from sklearn.feature_extraction.text import CountVectorizer\n\ncount_vect = CountVectorizer()\ncount_vect.fit(train['text'])\n\nbow_train = count_vect.transform(train['text'])\nbow_test = count_vect.transform(test['text'])","5dd0f9c1":"print(f\"There are {len(count_vect.vocabulary_)} words in the vocabulary.\")","1804f553":"count_vect = CountVectorizer(max_features=15000)\ncount_vect.fit(train['text'])\n\nbow_train = count_vect.transform(train['text'])\nbow_test = count_vect.transform(test['text'])","c9b1f696":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(max_iter=1000).fit(bow_train, train.target)","4b467717":"predictions = model.predict_proba(bow_test)\npredictions = [probs[1] for probs in predictions]","a3be3d40":"submission = pd.read_csv('..\/input\/tweet-sentiment-analysis\/sample_submission.csv')\nsubmission['Predicted'] = predictions","733639b8":"submission.to_csv('\/kaggle\/working\/submission.csv', index=False)","5ee23aa2":"Finally, I save the submission file to the `\/kaggle\/working` folder. After I save and run this notebook, I will submit these results to the competition and see how well my model worked.","63aca607":"First, we read in the .csv files.","e7a7825f":"The model is trained, time to do some predictions. The `predict_proba` method with give us the probability that a tweet is positive.","aa39b94a":"That seems like a lot of words. Lets run `CountVectorizer` again but only use the top 15,000 most common words.","06102004":"The `CountVectorizer` from scikit-learn makes it easy to create Bag-of-Words vectors.","310f84c4":"Now lets take a look at the training data.","4e494e14":"To generate a submission, replace the `Predicted` column in the sample submission with the above predictions.","d37cfc10":"## Tweet EDA and Logistic Regression\n\nThis is a starter notebook to show how to quickly get up-and-running with sentiment analysis. I will take a quick look at the data and use bag-of-words vectors to train a logistic regression model.","8eebd97f":"Great! Now we can fit a logistic regression model on those vectors. Scikit-learn also provides a handy `LogisticRegression` function to make modeling easy."}}