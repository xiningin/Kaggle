{"cell_type":{"be5c1d9a":"code","6528b502":"code","002dd518":"code","af519be7":"code","8ddcd832":"code","e4ca01d4":"code","85d431e9":"code","326a405a":"markdown","99f26b5e":"markdown","a49efa72":"markdown","f45ac611":"markdown"},"source":{"be5c1d9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6528b502":"def ks_table_summary(prediction,actual,bin):\n    #prediction is [:,1] of predicted probability column\n    #prob = pd.DataFrame(prediction)\n#   prob = prob.reset_index()\n    prob = prediction\n    target = actual\n#   target = pd.DataFrame(actual)\n#   target = target.reset_index()\n#   target = target.iloc[:,~0]\n    \n    qv = prob.quantile(np.linspace(0.0,1.0,num=bin),interpolation = 'linear')\n    prob_bins = pd.cut(prob,list(sorted(set(qv))),include_lowest = True)\n    df = pd.concat([prob_bins,prob,target],axis = 1)\n    df.columns = ['prob_bins','prob','target']\n    \n    grp = df.groupby('prob_bins')\n    account = grp['target'].count().astype('float')\n    event = grp['target'].sum().astype('float')\n    non_event = account-event \n    actual_non_event_rate = 1-grp['target'].mean().astype('float')\n    actual_event_rate = grp['target'].mean().astype('float')\n    grp = df.groupby('prob_bins')\n    min_score = grp['prob'].min().astype('float')\n    max_score = grp['prob'].max().astype('float')\n    pred_event_rate = grp['prob'].mean().astype('float')\n    \n    ks_tab = pd.concat([account,non_event,event,actual_non_event_rate,actual_event_rate,min_score,max_score,pred_event_rate],axis = 1)\n    ks_tab.columns = ['account','non_event','event','actual_non_event_rate','actual_event_rate','min_score','max_score','pred_event_rate']\n    \n    ks_tab['pred_event'] = ks_tab['account']*ks_tab['pred_event_rate']\n    ks_tab['pred_event'] = ks_tab['pred_event'].astype('int')\n    ks_tab['non_event_capture_rate'] = ks_tab['non_event']\/ks_tab['non_event'].sum()\n    ks_tab['event_capture_rate'] = ks_tab['event']\/ks_tab['event'].sum()\n    \n    cum_list1 = []\n    cum_list2 = []\n    lst = list(ks_tab['event_capture_rate'])\n    length = len(lst)\n    cum_list1 = [sum(lst[(length - x - 1):length]) for x in range(0,length)]\n    lst = list(ks_tab['non_event_capture_rate'])\n    cum_list2 = [sum(lst[(length - x - 1):length]) for x in range(0,length)]\n    cum_list1.reverse()\n    cum_list2.reverse()\n    ks_tab['event_cum_capture_rate'] = cum_list1\n    ks_tab['non_event_cum_capture_rate'] = cum_list2\n    ks_tab['KS_Stat'] = ks_tab['event_cum_capture_rate']-ks_tab['non_event_cum_capture_rate']\n    ks_tab['KS_Stat'] = np.round(ks_tab['KS_Stat'].astype(float),3)\n    \n    return ks_tab","002dd518":"df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/deepanshu88\/data\/master\/data.csv\")\n","af519be7":"ks_table_summary(df['p'],df['y'],11)","8ddcd832":"from scipy.stats import kstest\nimport random\nactual = np.random.randint(0,100,size = 100)\nx = kstest(actual, \"uniform\")   \nprint(x)","e4ca01d4":"#Null hypothesis assumes that the numbers are Normally distributed\nfrom scipy.stats import kstest\nimport random\nactual = np.random.randint(0,100,size = 100)\nx = kstest(actual, \"norm\")   \nprint(x)","85d431e9":"from scipy.stats import ks_2samp\ndf = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/deepanshu88\/data\/master\/data.csv\")\nks_2samp(df.loc[df.y==0,\"p\"], df.loc[df.y==1,\"p\"])","326a405a":"Null hypothesis assumes that the numbers are uniformly distributed between 0-1.","99f26b5e":"**One Sampe Kolmogorov-Smirnov Test**\n\nThe one-sample Kolmogorov-Smirnov test is used to test whether a sample comes from a specific distribution. We can use this procedure to determine whether a sample comes from a population that is normally distributed ","a49efa72":"It returns KS score 0.6033 and p-value less than 0.01 which means we can reject the null hypothesis and concluding distribution of events and non-events is different.","f45ac611":"**Two-Sample Kolmogorov-Smirnov Test**\n\nThe null hypothesis is H0: both samples come from a population with the same distribution. "}}