{"cell_type":{"c2d67904":"code","8345a704":"code","be1674f7":"code","da4fc1f7":"code","36018a6d":"code","ab450b93":"code","5e2607eb":"code","a86cf43b":"code","5ef32deb":"code","3dd3f4fa":"code","f80f7a9b":"code","e92c1b66":"code","9dfa4866":"code","45e0f558":"code","038fb7be":"code","a44aad3d":"code","8623c654":"code","7116fd39":"code","1fb12c08":"code","9c6b78b3":"code","f5acf6be":"code","66269897":"code","78001911":"code","b7cfa49e":"code","bbe81f1e":"code","f90a34d7":"markdown","bcb3b79a":"markdown","c744a274":"markdown","00139f5a":"markdown","606a5057":"markdown","2ff45278":"markdown","6bf0e428":"markdown","6ed93ce1":"markdown","ddaacdf0":"markdown","62187213":"markdown","ba374376":"markdown","65092a44":"markdown","e2536742":"markdown","6f42c24c":"markdown","141ffc42":"markdown","dac5b320":"markdown","8108f6af":"markdown","088098cd":"markdown","0dbc9227":"markdown","dc47d8ca":"markdown","58385518":"markdown"},"source":{"c2d67904":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor","8345a704":"#Importamos el set de datos\niowa_file_path = '..\/input\/home-data-for-ml-course\/train.csv'\nhome_data = pd.read_csv(iowa_file_path)\nhome_data.head()","be1674f7":"home_data.describe()","da4fc1f7":"# Create the list of features below\nfeature_names = [\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\n\n# Select data corresponding to features in feature_names\nX = home_data[feature_names]","36018a6d":"y = home_data.SalePrice","ab450b93":"X.describe()","5e2607eb":"iowa_model = DecisionTreeRegressor(random_state=1)\niowa_model.fit (X, y)","a86cf43b":"predictions = iowa_model.predict(X)","5ef32deb":"y.head()","3dd3f4fa":"print(\"Primeras predicciones de nuestra muestra:\", iowa_model.predict(X.head()))\nprint(\"Actuales valores objetivos para esos inmuebles:\", y.head().tolist())","f80f7a9b":"train_X, val_X, train_y, val_y = train_test_split (X, y,random_state=1)\niowa_model = DecisionTreeRegressor(random_state=1)\niowa_model.fit(train_X,train_y)","e92c1b66":"val_predictions = iowa_model.predict(val_X)","9dfa4866":"print (val_y.head(10),val_predictions [0:9]) ","45e0f558":"val_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"MAE:\",val_mae)","038fb7be":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","a44aad3d":"candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor max_leaf_nodes in [5, 25, 50, 100, 250, 500]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\nbest_tree_size = 100","8623c654":"final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\nfinal_model.fit(X, y)","7116fd39":"from sklearn.ensemble import RandomForestRegressor\n\n# Definici\u00f3n del modelo. Ajustamos random_state a 1\nrf_model = RandomForestRegressor(random_state=1)\n\n# Ajustamos el modelo\nrf_model.fit (train_X,train_y)\n\n#Creamos un set de datos para X a partir de los datos 'test'\niowa_data_path_test= '..\/input\/home-data-for-ml-course\/test.csv'\nX_test_full = pd.read_csv(iowa_data_path_test, index_col='Id')\nX_full= home_data\ny = X_full.SalePrice\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = X_full[features].copy()\nX_test = X_test_full[features].copy()\n\n# Calculamos el MAE de nuestro modelo Random Forest para su validaci\u00f3n.\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validaci\u00f3n MAE para modelo Random Forest: {}\".format(rf_val_mae))","1fb12c08":"X_train.head()","9c6b78b3":"# Extraemos set para validaci\u00f3n del set de entrenamiento.\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","f5acf6be":"model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\nmodel_2 = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel_3 = RandomForestRegressor(n_estimators=100, criterion='mae',random_state=0)\nmodel_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\nmodel_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n\nmodels = [model_1, model_2, model_3, model_4, model_5]","66269897":"def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n    model.fit(X_t, y_t)\n    preds = model.predict(X_v)\n    return mean_absolute_error(y_v, preds)\n\nfor i in range(0, len(models)):\n    mae = score_model(models[i])\n    print(\"Model %d MAE: %d\" % (i+1, mae))","78001911":"my_model = RandomForestRegressor(n_estimators=100,criterion='mae', random_state=0, max_depth=13)\nmae =score_model(my_model)\nprint(mae)","b7cfa49e":"my_model.fit(X, y)\npreds_test = my_model.predict(X_test)\nprint(preds_test)","bbe81f1e":"# Save predictions in format used for competition scoring\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","f90a34d7":"##### Construcci\u00f3n del modelo 'Decission Tree'\n---","bcb3b79a":"Dado que nuestras predicciones tienen aun mucho error, trataremos de mejorar y optimizar nuestro modelo. Primero, situaremos el n\u00famero de nodos \u00f3ptimo (tama\u00f1o de nuestro \u00e1rbol).","c744a274":"<center>\n \n   ## Housing Prices Competition for Kaggle Learn Users (pt. 1)\n    \n\n___","00139f5a":"##### Exploraci\u00f3n b\u00e1sica del conjunto de datos\n---","606a5057":"Creamos 'Y', que asociamos con el precio de los inmuebles.","2ff45278":"Comenzamos a construir nuestro modelo. Para su repodrucibilidad, asignamos un valor num\u00e9rico a la funci\u00f3n.","6bf0e428":"Calculamos el Mean Absolute Error (MAE). La diferencia media entre las dos variables (predicha y observada)","6ed93ce1":"Para comprobar si podemos conseguir mejores predicciones a trav\u00e9s de otro modelo, construiremos un modelo 'Random Forest'.","ddaacdf0":"Creamos cinco modelos aleatorios de 'Random Forest' y definimos los modelos","62187213":"Vamos a probar cuanto de v\u00e1lido es nuestro modelo","ba374376":"Nuestras primeras predicciones:","65092a44":"Creamos un modelo acorde al 3\u00ba de los anteriores e iteramos hasta encontrar los mejores valores posibles.","e2536742":"![housesbanner.png](attachment:c4840619-50fe-436f-98ea-9cb0b8706b14.png)","6f42c24c":"Desarrollamos una funci\u00f3n para facilitar el c\u00e1lculo del MAE","141ffc42":"En el siguiente proyecto trataremos de resolver la competici\u00f3n de 'Kaggle' [Housing Prices Competition for Kaggle Learn Users](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course) sobre la aplicaci\u00f3n de Machine Learning para la predicci\u00f3n de precios de viviendas  en Ames, Iowa. Procederemos a trav\u00e9s de algoritmos relacionados con 'Decission Trees' y 'Random Forest' a trav\u00e9s de cursos de formaci\u00f3n.\n\nLa descripci\u00f3n e introducci\u00f3n de la competici\u00f3n reza as\u00ed:\n\n- P\u00eddale a un comprador de vivienda que describa la casa de sus sue\u00f1os, y probablemente no comenzar\u00e1 con la altura del techo del s\u00f3tano o la proximidad a un ferrocarril que cruce todo el pa\u00eds. No obstante, este conjunto de datos para esta distendida competici\u00f3n demuestra que influye mucho m\u00e1s sobre el precio las negociaciones que el n\u00famero de dormitorios o una valla blanca.\n\nObjetivos para la comeptici\u00f3n:\n\n- Con 79 variables explicativas que describen (casi) todos los aspectos de las viviendas residenciales en Ames, Iowa, esta competenci\u00f3n desaf\u00eda al usuario a predecir el precio final de cada casa.\n\nHabilidades a poner en pr\u00e1ctica:\n\n- Ingenier\u00eda creativa de funciones\n- T\u00e9cnicas de regresi\u00f3n avanzadas como 'Random Forest' y 'Gradient Boosting'.","dac5b320":"##### Construcci\u00f3n de un modelo 'Random Forest'\n____","8108f6af":"Calculamos el MAE de los diferentes modelos creados.","088098cd":"Guardamos y enviamos los resultados.","0dbc9227":"Creamos 'X', que es el objetivo espec\u00edfico de predicci\u00f3n. Contiene los siguientes caracter\u00edsticas, ya que no utilizaremos todas las columnas del set de datos.","dc47d8ca":"##### Optimizaci\u00f3n del modelo\n---","58385518":"Contenidos\n- Exploraci\u00f3n b\u00e1sica del conjunto de datos\n- Construcci\u00f3n del modelo 'Decission Tree'\n- Validaci\u00f3n del modelo 'Decission Tree'\n- Construcci\u00f3n del modelo 'Random Forest'"}}