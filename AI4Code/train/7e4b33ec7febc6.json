{"cell_type":{"66214d34":"code","058954ee":"code","7f302368":"code","f1067089":"code","5b6ef9fe":"code","eaa7dd26":"code","a3a794e9":"code","e344bd9d":"code","951d33d2":"code","6e1d0a00":"code","fb964103":"code","55073a50":"code","4a99ef4d":"code","dbbc14db":"code","d5d89047":"code","42175321":"code","9fd6cb72":"code","fac8c3cc":"code","9efe6dde":"code","4e9a3a8a":"code","eff051b1":"code","0e36ebba":"code","ff7da4b8":"code","8eab04de":"code","6a2e9094":"code","00887c33":"code","7725b90f":"code","a8eac80d":"code","dc3cf848":"code","9fcd5fec":"code","3e3493e8":"code","e7224275":"code","1f25fdfc":"code","22306890":"code","f04cede3":"code","cc18f1d5":"code","09331180":"code","3616abba":"code","f4cb0aff":"code","e8468493":"code","bd6db427":"code","0f69a6e6":"code","2d83241c":"code","e72a1809":"code","4df674e3":"code","2e777141":"code","2a65cc61":"code","9bf30c92":"code","95854e33":"code","229063d9":"code","fc1bdfa7":"code","d3bb1710":"code","d27142be":"code","88e15f41":"code","26b1c0a9":"code","12247368":"code","5794800b":"code","7e96afdb":"code","f250550a":"code","cfcf78b7":"code","17235952":"code","6f14ffbb":"code","2acaae1b":"code","e5bb71bf":"code","d7b83b94":"code","f6d4d6b5":"code","04d7d964":"code","bcefd2f7":"code","6ea043cb":"markdown","f6982282":"markdown","00f27f55":"markdown","bcd421ee":"markdown","35dd5628":"markdown","568fdd3c":"markdown","cbb063c8":"markdown","99bca000":"markdown","34a8affc":"markdown","10998fc9":"markdown","381e09c4":"markdown","061c3f36":"markdown","a5a4c517":"markdown","ddbb4010":"markdown","53185d9e":"markdown","ea0b00f2":"markdown","4a45d9e1":"markdown","18fcced4":"markdown","53acb9ae":"markdown","59ef9b29":"markdown","b2f2e713":"markdown","48fb5e07":"markdown","b1d47006":"markdown","c5c2ffd5":"markdown","1fa6dd83":"markdown","60f81962":"markdown","420fba0e":"markdown","16e06622":"markdown","9b3df4e3":"markdown","75f84469":"markdown","f2e50e27":"markdown","b769590b":"markdown","bcfba262":"markdown","f6cb7da4":"markdown","aa5e242e":"markdown","5170190a":"markdown","36f3084d":"markdown","2295b271":"markdown","d07d2435":"markdown","5d1010a4":"markdown","54a95817":"markdown","263adb5d":"markdown","9663f995":"markdown","ee21899e":"markdown","02cb2e0b":"markdown","f74620a1":"markdown","495b49ce":"markdown","cd7f4e7a":"markdown"},"source":{"66214d34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","058954ee":"import numpy as np \nimport pandas as pd\nimport os\nimport glob\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import missingno as msno\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport statistics as stat\nfrom wordcloud import WordCloud, STOPWORDS\nfrom plotly.subplots import make_subplots\n#import folium\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries imported!\")","7f302368":"distdata = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\ndistdata.head(10)","f1067089":"proddata = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\nproddata.head(10)","5b6ef9fe":"path = '\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\nfiles = glob.glob(os.path.join(path, \"*.csv\"))\nfiles","eaa7dd26":"PATH = '\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \ndistdata = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\n\ntemp = []\n\nfor district in distdata.district_id.unique():\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \n    \nengagement = pd.concat(temp)\nengagement = engagement.reset_index(drop=True)","a3a794e9":"engagement.shape","e344bd9d":"\n\nprint('Total unique products : ', proddata['LP ID'].unique().size)\nprint('Total unique providers in top 372 products are : ',proddata['Provider\/Company Name'].unique().size)\nprint('Total unique sectors are : ',proddata['Sector(s)'].unique().size)\nprint('They are : ')\na=list(proddata['Sector(s)'].unique())\nfor i in a:\n    print(i)","951d33d2":"# python libraries to study missing data\nfrom wordcloud import WordCloud, STOPWORDS\nimport missingno as msno","6e1d0a00":"def missing_values(df):\n    ''' This function takes a data frame as input \n    prints the fraction of entries with missing values (NaN)\n    prints the list of columns with corresponding number of missing values\n    '''\n    # Total number of entries (rows X columns) in the dataset\n    total= df.size\n    #Number of missing values per column\n    missingCount = df.isnull().sum()\n    #Total number of missing values\n    missing_tot = missingCount.sum()\n    # Calculate percentage of missing values\n    print('Total number of missing values for each column of dataframe: \\n \\b \\b \\b',missingCount)\n    print(\"The dataset contains\", round(((missing_tot\/total) * 100), 2), \"%\", \"missing values\")\n    print('Total number of rows with at least one missing value column are ',df[df.isnull().any(axis=1)].shape[0])\n    print('% of rows with missing data ',round(((df[df.isnull().any(axis=1)].shape[0]\/df.shape[0])*100),2),'%\\n\\n')\n    \n    \ndef column_missingdata(df):\n    ''' This function takes a data frame as input \n    prints the list of columns with corresponding % of missing values\n    '''\n    #check for missing values per column\n    values=df.isnull().sum()#.sort_values(ascending=False)\n    total= df.size\n    #percentage of missing values per column\n    percentage=(values\/total) * 100\n    print('% of missing values for each column of dataframe: \\n \\b \\b \\b',percentage,'\\n\\n\\n')\n\ndef plot_missingdata(df:pd.DataFrame, title:str, xlabel:str, ylabel:str):\n    ''' This function takes a data frame as input \n    plots the list of columns with corresponding total number of missing values\n    '''\n    # Let us see what columns have missing values\n    # total number of missing values for each dataframe column\n    missing = df.isnull().sum() \n    # keeping only the columns with missing values>0 \n    missing = missing[missing > 0] \n    # sorting in order of missing values and making the change to original missing series\n    missing.sort_values(inplace=True) \n    missing.plot.bar()\n    plt.title(title, size=15,loc='left')\n    plt.xticks(fontsize=11,rotation=45)\n    plt.yticks(fontsize=11)\n    plt.xlabel(xlabel, fontsize=13)\n    plt.ylabel(ylabel, fontsize=13)\n    plt.show()\n    \n    \ndef fix_missing_mean(df,col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with it's mean value\n    '''\n    #replace missing values with mean \n    df[col].fillna(df[col].mean(), inplace = True)    \n\ndef fix_missing_mode(df,col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with it's mode value\n    '''\n    #replace missing values with mean \n    df[col].fillna(df[col].mode(), inplace = True)    \n\n    \ndef fix_missing_ffill(df, col):\n    ''' This function takes a data frame and column name as input \n    replaces the missing values of a particular column with the value from the previous row\n    '''\n    df[col] = df[col].fillna(method='ffill')  \n    \ndef fix_missing_bfill(df, col):\n    ''' This function takes a data frame as input \n    replaces the missing values of a particular column with the value from the next row\n    '''\n    df[col] = df[col].fillna(method='bfill')","fb964103":"#missing values in district\nmissing_values(distdata)\ncolumn_missingdata(distdata)\nplot_missingdata(distdata,'districts dataset columns with missing values','Column Name','No. of Missing values')","55073a50":"distdata.shape","4a99ef4d":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(distdata,figsize=(6,6))\nplt.show()","dbbc14db":"#district\n#drop nan values in state column\ndistdata_x = distdata[distdata[\"locale\"].notna()].reset_index(drop=True)\n#check missing columns in district dataset\ncolumn_missingdata(distdata_x)","d5d89047":"distdata_x.shape","42175321":"distdata_x.head(10)","9fd6cb72":"missing_values(distdata_x)","fac8c3cc":"distdata_x.shape","9efe6dde":"fix_missing_ffill(distdata_x,'pct_free\/reduced')\nfix_missing_ffill(distdata_x,'county_connections_ratio')\nfix_missing_ffill(distdata_x,'pp_total_raw') ","4e9a3a8a":"distdata_x.shape","eff051b1":"distdata_x.head()","0e36ebba":"distdata_x.shape","ff7da4b8":"missing_values(distdata_x)","8eab04de":"#missing values in products\nmissing_values(proddata)\ncolumn_missingdata(proddata)\nplot_missingdata(proddata,'products dataset columns with missing values','Column Name','No. of Missing values')","6a2e9094":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(proddata,figsize=(6,6))\nplt.show()","00887c33":"# dropping all the rows with any missing values \nproddata_x=proddata\nproddata_x.dropna(axis=0,how='any',inplace=True)\n\n#check missing columns in product dataset\ncolumn_missingdata(proddata_x)","7725b90f":"proddata_x.tail(5)","a8eac80d":"proddata_x.shape","dc3cf848":"#missing values in engagement\nmissing_values(engagement)\ncolumn_missingdata(engagement)\nplot_missingdata(engagement,'engagement dataset columns with missing values\\n\\n','Column Name','No. of Missing values')","9fcd5fec":"#heat map of missing value , it will show the corrrelation between different columns for missing values\nax = msno.heatmap(engagement,figsize=(6,6))\nplt.show()","3e3493e8":"#drop nan values in lp_id column\nengagement_x = engagement[engagement[\"lp_id\"].notna()].reset_index(drop=True)\n\n# fill the missing values with mean value of the column in the engagement dataset\nfix_missing_mean(engagement_x,'pct_access')\nfix_missing_mean(engagement_x,'engagement_index')","e7224275":"engagement.head()","1f25fdfc":"engagement_x.head()","22306890":"engagement_x.shape","f04cede3":"engagement.shape","cc18f1d5":"#check missing columns in enagement dataset\ncolumn_missingdata(engagement_x)","09331180":"#defining functions for plots\n#countplot\ndef plot_count(df:pd.DataFrame, y_col:str, title:str, xlabel:str, ylabel:str):\n    fig, ax = plt.subplots(1, 1, figsize=(10,6), sharey=True)\n    sns.countplot(data=df, y=y_col,edgecolor=\"white\",palette=\"viridis\",order=df[y_col].value_counts().index)\n    total = df[y_col].value_counts().sum()\n    for i, v in enumerate(df[y_col].value_counts().sort_values(ascending=False).values): \n        frac1 = (v\/total)*100\n        frac = \"{:.2f}\".format(frac1)\n        v1 = str(v)+' ('+str(frac)+'%)'\n        ax.text(v*1.01, i, v1,fontsize=10,color='black',weight='bold')\n   \n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \n#pieplot_for locale\ndef plot_pie(df:pd.DataFrame,column:str, title:str):\n    fig, ax  = plt.subplots(figsize=(16, 8))\n    fig.suptitle(column+' Distribution', font=\"Serif\",fontsize=20)\n    explode = (0.01, 0.01, 0.01, 0.01) \n    labels = list(df[column].value_counts().index)\n    sizes = df[column].value_counts().values\n    ax.pie(sizes, \n           explode=explode,\n           startangle=60, \n           labels=labels,\n           autopct='%1.0f%%', \n           pctdistance=0.7)\n    ax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nplt.show()\n    \n#barplot   \ndef plot_bar(df:pd.DataFrame,minimum:str,maximum:str,y_col:str, title:str, xlabel:str, ylabel:str):\n    df1 = df.groupby(y_col)[minimum, maximum].mean().sort_values([minimum, maximum],ascending=False)\n    df1.plot(kind = 'bar',color=['blue','darkblue'])\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show()\n\n\ndef plot_barh(df:pd.DataFrame, x_col:pd.DataFrame,y_col:pd.DataFrame, title:str, xlabel:str,ylabel:str):\n    fig, ax  = plt.subplots(figsize=(10,6))    \n    sns.barplot(data = df,y=y_col,x=x_col,palette=\"viridis\")\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \ndef plot_bar1(df:pd.DataFrame, x_col:pd.DataFrame,y_col:pd.DataFrame, title:str, xlabel:str,ylabel:str):\n    fig, ax  = plt.subplots(figsize=(10,6)) \n    sns.barplot(data = df,y=y_col,x=x_col,palette=\"viridis\",order=df.groupby(y_col).mean()[x_col].sort_values(ascending=False).index,ci=None)\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(xlabel, fontsize=16)\n    plt.ylabel(ylabel, fontsize=16)\n    plt.show()\n    \n    \ndef plot_bar2(df1:pd.DataFrame, x_col:str,y_col1:str, ax1_title:str, xlabel1:str,ylabel1:str,df2:pd.DataFrame,y_col2:str,ax2_title:str, xlabel2:str,ylabel2:str):\n    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n    sns.barplot(data = df1,y=y_col1,x=x_col,palette=\"viridis\", ax=ax[0])\n    ax[0].set_title(ax1_title)\n    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=90)\n    ax[0].set_xlabel(xlabel1)\n    ax[0].set_ylabel(ylabel1)\n\n    sns.barplot(data = df2,y=y_col2,x=x_col,palette=\"viridis\", ax=ax[1])\n    ax[1].set_title(ax2_title)\n    ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\n    ax[1].set_xlabel(xlabel2)\n    ax[1].set_ylabel(ylabel2)\n    plt.show()    \n    \ndef plot_scatter(df: pd.DataFrame, x_col: str, y_col: str, title: str, hue: str):\n    plt.figure(figsize=(10, 5))\n    sns.scatterplot(data = df, x=x_col, y=y_col, hue=hue, size=hue,sizes=(20, 200))\n    plt.title(title, size=20)\n    plt.xticks(fontsize=14)\n    plt.yticks( fontsize=14)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show() \n    \ndef plot_pairplot(df: pd.DataFrame):#, hue:str, diag_kind:str\n    sns.pairplot(df)\n    #pd.plotting.scatter_matrix(df, alpha=0.2)\n    plt.show() \n    \n    \ndef plot_line(df: pd.DataFrame,x_col: str, y_col: str, hue: str, title:str, xlabel:str, ylabel:str, text1:int, text2:int):#, hue:str, diag_kind:str\n    fig, ax  = plt.subplots(figsize=(15,7))    \n    sns.lineplot(data=df, x=x_col, y=y_col, hue=hue,lw=2)\n    plt.title(title, size=30)\n    plt.xticks(fontsize=20)#,rotation=45)\n    plt.yticks(fontsize=20)\n    plt.xlabel(xlabel, fontsize=30)\n    plt.ylabel(ylabel, fontsize=30)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.axvline(pd.Timestamp('2020-03-11'),color='black')\n    ax.text(pd.Timestamp(\"2020-03-11\"), text1, \"  WHO has declared Covid-19 a pandemic\",size=20,fontname = 'monospace',color='black')\n    xy = datetime(2020,6,1,0,0,0), ax.get_ylim()[0]\n    w, h = timedelta(days=92), ax.get_ylim()[1] - ax.get_ylim()[0]\n    ax.add_patch(patches.Rectangle(xy, w, h,color ='black',alpha=0.1))\n    ax.text(pd.Timestamp(\"2020-06-17\"), text2, \"Summer Break\",size=20,fontname = 'monospace',color='black')\n    plt.show() \n    \ndef plot_line_day(df: pd.DataFrame,x_col: str, y_col: str, hue: str, title:str, xlabel:str, ylabel:str, text1:int, text2:int):#, hue:str, diag_kind:str\n    fig, ax  = plt.subplots(figsize=(15,7))    \n    sns.lineplot(data=df, x=x_col, y=y_col, hue=hue,style=hue,ci=None,markers=False, dashes=False, lw=2)\n    plt.title(title, size=30)\n    plt.xticks(fontsize=20)#,rotation=45)\n    plt.yticks(fontsize=20)\n    plt.xlabel(xlabel, fontsize=30)\n    plt.ylabel(ylabel, fontsize=30)\n    plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0)\n    plt.show()","3616abba":"plot_count(distdata_x,'state','Number of districts per state','Districts Count','State')","f4cb0aff":"#barplot\nplot_count(distdata_x,'locale','Number of districts per locale type','Districts count for locale type','Locale')","e8468493":"#pie plot\nplot_pie(distdata_x,'locale','Number of districts per locale')","bd6db427":"distdata_y=distdata_x\n#'pct_black\/hispanic'\ndistdata_y[['min_pct_black\/hispanic','max_pct_black\/hispanic']] = distdata_y['pct_black\/hispanic'].str.split(\",\",expand=True)\ndistdata_y['min_pct_black\/hispanic'] = distdata_y['min_pct_black\/hispanic'].str.strip('[')\ndistdata_y['max_pct_black\/hispanic'] = distdata_y['max_pct_black\/hispanic'].str.strip('[')\n\n#'pct_free\/reduced'\ndistdata_y[['min_pct_free\/reduced','max_pct_free\/reduced']] = distdata_y['pct_free\/reduced'].str.split(\",\",expand=True)\ndistdata_y['min_pct_free\/reduced'] = distdata_y['min_pct_free\/reduced'].str.strip('[')\ndistdata_y['max_pct_free\/reduced'] = distdata_y['max_pct_free\/reduced'].str.strip('[')\n\n#'county_connections_ratio'\ndistdata_y[['min_county_connections_ratio','max_county_connections_ratio']] = distdata_y['county_connections_ratio'].str.split(\",\",expand=True)\ndistdata_y['min_county_connections_ratio'] = distdata_y['min_county_connections_ratio'].str.strip('[')\ndistdata_y['max_county_connections_ratio'] = distdata_y['max_county_connections_ratio'].str.strip('[')\n\n#'pp_total_raw'\ndistdata_y[['min_pp_total_raw','max_pp_total_raw']] = distdata_y['pp_total_raw'].str.split(\",\",expand=True)\ndistdata_y['min_pp_total_raw'] = distdata_y['min_pp_total_raw'].str.strip('[')\ndistdata_y['max_pp_total_raw'] = distdata_y['max_pp_total_raw'].str.strip('[')\n\n#import the original columns\ndistdata_y.drop(['pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw'], axis = 1, inplace = True)","0f69a6e6":"distdata_y.dtypes","2d83241c":"#convert object to numbers\ncols = distdata_y.columns.drop(['state', 'locale'])\ndistdata_y[cols] = distdata_y[cols].apply(pd.to_numeric, errors = 'coerce')","e72a1809":"#except state and locale we have converted all others object columns to numeric columns\ndistdata_y.dtypes","4df674e3":"plot_bar(distdata_y,'min_pct_black\/hispanic','max_pct_black\/hispanic','locale','Mean % of black or hispanic students by locale','Locale','Mean')\nplot_bar(distdata_y,'min_pct_free\/reduced','max_pct_free\/reduced','locale','Mean % of students eligible for free\/reduced lunch by locale','Locale','Mean')\nplot_bar(distdata_y,'min_pp_total_raw','max_pp_total_raw','locale','Mean total expenditure in USD per student by locale','Locale','Mean')\nplot_bar(distdata_y,'min_county_connections_ratio','max_county_connections_ratio','locale','Mean connection ratio by locale','Locale','Mean')","2e777141":"distdata_y[\"avg_pct_black\/hispanic\"] = distdata_y[[\"min_pct_black\/hispanic\", \"max_pct_black\/hispanic\"]].mean(axis=1)\ndistdata_y[\"avg_pct_free\/reduced\"] = distdata_y[[\"min_pct_free\/reduced\", \"max_pct_free\/reduced\"]].mean(axis=1)\ndistdata_y[\"avg_pp_total_raw\"] = distdata_y[[\"min_pp_total_raw\", \"max_pp_total_raw\"]].mean(axis=1)\ndistdata_y[\"avg_county_connections_ratio\"] = distdata_y[[\"min_county_connections_ratio\", \"max_county_connections_ratio\"]].mean(axis=1)","2a65cc61":"plot_bar1(distdata_y,'avg_pct_black\/hispanic','state','Mean % of black or hispanic students per State','Mean Student Expenditure','State')\n","9bf30c92":"plot_bar1(distdata_y,'avg_pct_free\/reduced','state','Mean % of students eligible for free\/reduced lunch per State','Mean Student Expenditure','State')\n","95854e33":"plot_bar1(distdata_y,'avg_pp_total_raw','state','Mean Student Expenditure per State','Mean Student Expenditure','State')\n","229063d9":"plot_bar1(distdata_y,'avg_county_connections_ratio','state','Mean Connection Ratio per State','Mean Connection Ratio','State')","fc1bdfa7":"s1=0\ns2=0\ns3=0\nfor s in proddata[\"Sector(s)\"]:\n    if(not pd.isnull(s)):\n        s = s.split(\";\")\n        for i in range(len(s)):\n            sub = s[i].strip()\n            if(sub == 'PreK-12'): \n                s1=s1+1\n            if(sub == 'Higher Ed'): \n                s2=s2+1\n            if(sub == 'Corporate'): \n                s3=s3+1\n\nfig, ax  = plt.subplots(figsize=(14, 8))\nfig.suptitle('Sector Distribution', font=\"Serif\",fontsize=20)\nexplode = (0.01, 0.01, 0.01)#,0.01,0.01)\n\nlabels = ['PreK-12','Higher Ed','Corporate']\nsizes = [s1,s2,s3]\nax.pie(sizes,\n       startangle=60,\n       explode=explode, \n       labels=['PreK-12','Higher Ed','Corporate'],\n       autopct='%1.2f%%', \n       pctdistance=0.7)\nax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nplt.show()","d3bb1710":"fig, ax = plt.subplots(1, 1, figsize=(10,20), sharey=True)\nsns.countplot(y = 'Primary Essential Function', \n              data = proddata_x, \n              edgecolor=\"white\",\n              palette=\"viridis\",\n              order = proddata['Primary Essential Function'].value_counts().index)\n \n\ntotal = proddata_x[\"Primary Essential Function\"].value_counts().sum()\nfor i, v in enumerate(proddata_x[\"Primary Essential Function\"].value_counts().sort_values(ascending=False).values): \n    frac1 = (v\/total)*100\n    frac = \"{:.2f}\".format(frac1)\n    v1 = str(v)+' ('+str(frac)+'%)'\n    ax.text(v*1.01, i, v1,fontsize=10,color='black',weight='bold')\n    \nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.ylabel(\"Primary Essential Function\",size=20)\nplt.xlabel(\"products count\",size=20)\nplt.title('Number of products used by Primary Essential Function',size=25)\n\nplt.show()","d27142be":"s1=0\ns2=0\ns3=0\nfor s in proddata_x[\"Primary Essential Function\"]:\n    if(not pd.isnull(s)):\n        s1 = s.count(\"CM\")+1\n        s2 = s.count(\"LC\")+1\n        s3 = s.count(\"SDO\")+1\n\nfig, ax  = plt.subplots(figsize=(16, 10))\nfig.suptitle('% Distribution of primary essential function', font=\"Serif\",fontsize=20)\nexplode = (0.01, 0.01, 0.01)#,0.01,0.01)\nlabels = ['CM','LC','SDO']\nsizes = [s1,s2,s3]\nax.pie(sizes,\n       startangle=60,\n       explode=explode, \n       labels=labels,\n       autopct='%1.2f%%', \n       pctdistance=0.7)\nax.add_artist(plt.Circle((0,0),0.5,fc='white'))\nsubgroup_names_legs=['CM:Classroom Management', 'LC:Learning & Curriculum', 'SDO:School & District Operations']\nplt.legend(subgroup_names_legs,loc='best')\nplt.show()","88e15f41":"#Subdivide primary essential function\nproddata_y=proddata_x\nproddata_y['primary_function_main'] = proddata_y['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproddata_y['primary_function_sub'] = proddata_y['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproddata_y['primary_function_sub'] = proddata_y['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n# Deleting the 'Primary Essential Function' column from the product dataset as it is no longer needed since we already have split it into two sub-columns.\nproddata_y.drop(\"Primary Essential Function\", axis=1, inplace=True)","26b1c0a9":"engagement['time'] = pd.to_datetime(engagement['time'])\nengagement['month'] = engagement['time'].dt.month\n\nfig, ax = plt.subplots(1, 1, figsize=(7,5), sharey=True)\nsns.barplot(x = 'month',y='engagement_index', \n              data = engagement.groupby(engagement['month']).mean().reset_index(), \n              edgecolor=\"white\",\n              palette=\"viridis\")\n\n\nplt.title('Mean engagement index vs month',size=15)\nplt.xlabel(\"Month\",size=15)\nplt.ylabel(\"Mean engagement index\",size=15)\nplt.show()","12247368":"#combining the three tables\nengagement_x['lp_id'] = engagement_x['lp_id'].astype('int')\nengagement_x['district_id'] = engagement_x['district_id'].astype('int')\n\n# merging engagement and district data based on district id \nData = pd.merge(engagement_x,distdata_x,how='left',on='district_id')\n\n# merging above data with prod data based on LP ID (unique product identifier)\nData = pd.merge(Data,proddata_y,how='left',left_on='lp_id',right_on='LP ID')","5794800b":"#dropping missing values from the dataset\n#Data.dropna(axis=0,how='any',inplace=True)\nData = Data[Data[\"LP ID\"].notna()].reset_index(drop=True)","7e96afdb":"Data.head()","f250550a":"plt.figure(figsize=(7,4))\nsns.histplot(Data.groupby('district_id').time.nunique(), bins=40, color = 'blue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.xlabel('Number of days', fontsize=10)\nplt.ylabel('Number of districts', fontsize=10)\nplt.title('Districts with unique days of engagement ', fontsize = 15)\n\nplt.show()","cfcf78b7":"Datax=Data.loc[((Data[\"Sector(s)\"]==\"PreK-12\")|(Data[\"Sector(s)\"]==\"PreK-12; Higher Ed\")|(Data[\"Sector(s)\"]==\"PreK-12; Higher Ed; Corporate\"))&(Data[\"primary_function_main\"]==\"LC\")]\nstate_eng=pd.DataFrame(Datax.groupby('state')[['engagement_index','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced']].mean().sort_values(['engagement_index','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced'],ascending=False))\nstate_eng=state_eng.reset_index()\nplot_barh(state_eng,'engagement_index','state','Mean Engagement Index per State','Engagement','State')\n\nstate_access=pd.DataFrame(Datax.groupby('state')[['pct_access','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced']].mean().sort_values(['pct_access','avg_pp_total_raw','avg_pct_black\/hispanic','avg_pct_free\/reduced'],ascending=False))\nstate_access=state_access.reset_index()\nplot_barh(state_access,'pct_access','state','Mean pct_access per State','Access','State')","17235952":"fig, ax = plt.subplots(1, 1, figsize=(7,5), sharey=True)\nsns.countplot(y = 'Provider\/Company Name', \n              data = proddata_x, \n              edgecolor=\"white\",\n              palette=\"viridis\",#\"rocket_r\",\n              order = proddata['Provider\/Company Name'].value_counts().index[:5])\n\nfor rect in ax.patches:\n    ax.text (rect.get_width(), rect.get_y() + rect.get_height() \/ 2,\"%.1f\"% rect.get_width(), weight='bold' )\n \n ###\nplt.xticks(size=10)\nplt.yticks(size=10)\nplt.ylabel(\"Provider\/Company Name\",size=15)\nplt.xlabel(\"products counts\",size=15)\nplt.title('Number of products per Provider\/Company Names (Top 5)',size=15)\n\nplt.show()\n","6f14ffbb":"# for our plot we only need following columns: time, engagement_index, primary_function_main \nData['time'] = pd.to_datetime(Data['time'])\nData['month'] = Data['time'].dt.month\n\nsns.catplot(x = 'month',y='engagement_index', \n              data = Data.groupby(by=['month','primary_function_main']).mean().reset_index(), \n              edgecolor=\"white\",kind='bar',\n              palette=\"viridis\",col='primary_function_main',col_wrap=2,height=4)\n\n\nplt.show()","2acaae1b":"# Correlation between different attributes.\n# Plotting correlation graphs using Pearson's correlation coefficient.\n#g = sns.pairplot(state_access)\n\nfrom scipy.stats import pearsonr\ndef corrfunc(x, y, ax=None, **kws):\n    \"\"\"Plot the correlation coefficient in the top left hand corner of a plot.\"\"\"\n    r, _ = pearsonr(x, y)\n    ax = ax or plt.gca()\n    ax.annotate(f'\u03c1 = {r:.2f}', xy=(.6, .9), xycoords=ax.transAxes)\n\n#g.map_offdiag(corrfunc)\n#plt.show()\n# lets study the engagement correlation with \ng=sns.pairplot(state_eng)\ng.map_offdiag(corrfunc)\nplt.show()","e5bb71bf":"sns.relplot(x=\"avg_pp_total_raw\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)","d7b83b94":"sns.relplot(x=\"avg_pct_black\/hispanic\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)\n","f6d4d6b5":"sns.relplot(x=\"avg_pct_free\/reduced\", y=\"engagement_index\", kind=\"line\", data=state_eng,ci=None)\n","04d7d964":"sns.relplot(x=\"avg_pct_black\/hispanic\", y=\"avg_pct_free\/reduced\", kind=\"line\", data=state_eng,ci=None)","bcefd2f7":"# lets check the correlation between different features of data or variables , \n# pct access, expenditure, black\/hispanic, free\/reduced lunch eligibility %\ng = sns.pairplot(state_access)\n\n# let's show pearson correlation coefficient (https:\/\/en.wikipedia.org\/wiki\/Pearson_correlation_coefficient) \n#above each pair plot \nfrom scipy.stats import pearsonr\ndef corrfunc(x, y, ax=None, **kws):\n    \"\"\"Plot the correlation coefficient in the top left hand corner of a plot.\"\"\"\n    r, _ = pearsonr(x, y)\n    ax = ax or plt.gca()\n    ax.annotate(f'\u03c1 = {r:.2f}', xy=(.6, .9), xycoords=ax.transAxes)\n\ng.map_offdiag(corrfunc)\nplt.show()","6ea043cb":"Above graph tells that due to shifting of learning to digital mode, Google LLC, Houghtom Mifflin Harcourt, Microsoft are the top 3 companies widely used during the course of pandemic. ","f6982282":"The intervals of pct_black\/hispanic, pct_free\/reduced, county_connections_ratio and pp_total_raw are split into two columns based on their minimum and maximum values.","00f27f55":"**Missing Values of district.info file**","bcd421ee":"**Q5. Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?**\n\n1. From the analysis, we can conclude that engagement index of Black\/Hispanic communities is comparatively less as they belong to economically weaker community.\n2. State interventions like raising funds for economically weaker communities can result in a significant growth in the engagement index of students.\n3. Evolution of different technologies and products can lead to a tremendous increase in the engagement of students not only in US , but also worldwide.\n","35dd5628":"In the above graph, we can observe that if percentage of students getting free or reduced lunch prices is less, then the engagement is high as they are not economically weak. But as the percentage of students getting free or reduced lunch prices increases, then their engegement decreases.","568fdd3c":"**Mean percentage of black\/hispanic students per state**","cbb063c8":"**Combining 233 files of Engagement folder**","99bca000":"**Corelation Graphs for different attributes**","34a8affc":"The above plot says that if the average percentage of people identified as black or hispanic is less than 50%, then the engagement is less. But if the people identified as black or hispanic are in the majority, then consequently the engagement index of students increases.","10998fc9":"**Reading Engagement data**","381e09c4":"Inference of above graph:\nChange of student engagement with different types of education technology over the course of the pandemic:\n\nEngagement index for SDO : School and district operations is comparatively higher.","061c3f36":"**Plot to identify the number of unique days provided in the data set**","a5a4c517":"From above heat map, we can conclude that\n1. Sector(s) and Provider\/Company name, Primary Essential Function and Provider\/Company name are closely correlated.\n2.  Primary Essential Function and Sector(s) are higly correlated.","ddbb4010":"**Mean percentage of free\/reduced lunch per state**","53185d9e":"The heatmap below shows correlation between the missing tuples","ea0b00f2":"**C2 : What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?**\n\n**Plot for mean engagement index and percentage of access per state**","4a45d9e1":"The above graph tells us that if the average per pupil expenditure is less, then the expenditure is also less.\nBut as it increases, there is significant increase in engagement index","18fcced4":"The heatmap below shows correlation between the missing tuples","53acb9ae":"Exploratory Data Analysis:- The analysis will be performed in the following order:\n\n1.Product Data 2.District Data 3.Engagement Data.\n\nDatasets:-\n\nThere are a total of 233 School Districts available within the data, all around USA. A school district is a geographical unit for the local administration of elementary or secondary schools in various nations.\n\nThere are a total of 372 distinct Educational Technology Products, such as tools like Meet, Zoom, Canva, educational apps like Duolingo, reading sites, or social pages like Instagram.\n\nThe data was collected between 01.01.2020 (a few months before Covid-19) until 31.12.2020. This will give a full year overview of a before the pandemic and after usage.\n\nEngagement data was collected for all the districts with ~ 22.3M datapoints.","59ef9b29":"Conclusion for the above plot:\n\n1. We observe a positive correlation between engagement index and per pupil total expenditure. This implies that if expenditure increases, we can expect a significant increase in engagement of students.\n\n2. We find a negative correlaton between engagement index and average percentage of people identified as black or hispanic because, if the number of people identified as black or hispanic is more, then the engagement is less as they are economically weaker compared to others.\n\n3. There is a strong negative correlation observed between engagement index and average percentage of people getting free or reduced lunch as people get concessions on the prices of lunch based upon their economic status. Hence, if engagement index is more then it implies that the students are not economically weak.\n\n4. We can also conclude that black\/hispanic communities also have lower engagement index","b2f2e713":"Using forward fill method to fill in the empty values.","48fb5e07":"The data include a total of 233 school districts from across the US. For the columns pct_black\/hispanic, pct_free\/reduced, county_connections ratio and pp_total_raw a range is provided add Codeadd Markdown Engagement data The engagement data are aggregated at school district level, and each file in the folder engagement_data represents data from one school district*.\n\nThe 4-digit file name represents district_id which can be used to link to district information in district_info.csv.\n\nThe lp_id can be used to link to product information in product_info.csv.\n\nName Description time date in \"YYYY-MM-DD\" lp_id The unique identifier of the product pct_access Percentage of students in the district have at least one page-load event of a given product and on a given day engagement_index Total page-load events per one thousand students of a given product and on a given day","b1d47006":"**Mean connection ratio per state**","c5c2ffd5":"**Plots for showing the student engagement in different Primary Essential Functions**","1fa6dd83":"The heatmap below shows correlation between the missing tuples","60f81962":"From above graph we can conclude that, if the average percentage of people identified as black or hispanic students is less than 50%, then most of them will be getting free or reduced lunch prices as they will be the minority.\nSimilarly, if they are more than 50%, then they will be considered as majority and their percentage of getting free or reduced lunch prices will go down.\n","420fba0e":"**Distribution of different sectors : PreK-12, Higher and Corporate.**","16e06622":"Most of the districts have the data of complete year of 2020(366 days).","9b3df4e3":"**Missing values in engagement**","75f84469":"Above graph tells us that the engagement during the months of June-July decreased marking the summer breaks. Further rise in the months of August-September mark the beginning of new academic year.","f2e50e27":"Name Description district_id :-The unique identifier of the school district\n\nstate:- The state where the district resides in\n\nlocale :-NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\n\npct_black\/hispanic:- Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n\npct_free\/reduced:- Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\ncountyconnectionsratio:- ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\n\npptotalraw:- Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.","b769590b":"**Importing Libraries**","bcfba262":"**Read Product info**","f6cb7da4":"**Plot for Number of districts per locale**","aa5e242e":"From above heatmap, we can conclude that 'state','locale','pct_black\/hispanic' are correlated with each other. Hence we can drop them.\n","5170190a":"From the above heat map, we can conclude that \n1. pct_access and lp_id, engagement_index and lp_id are very lightly correlated as the colour of heat map is slightly pinkish, but nearly equal to white(0.00).\n2. engagement_index and pct_access are also lightly correlated as the colour of the heat map is slightly bluish, but nearly equal to white(0.00).\n","36f3084d":"**Extra analysis**","2295b271":"**C3 : How does student engagement with different types of education technology change over the course of pandemic?**\n\n**Top 5 companies which provided the most of the products to facilitate digital learning**","d07d2435":"We can infer from above, that Learning Curriculum - Digital Learning Platforms use most of the products to facilitate digital learning.","5d1010a4":"**ANALYSIS**","54a95817":"**Plot for Number of districts per state** ","263adb5d":"Product information data\n\nThe product file products_info.csv includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy.\n\nSome products may not have labels due to being duplicate, lack of accurate url or other reasons.\n\nName Description LP ID:- The unique identifier of the product\n\nURL :- Web Link to the specific product\n\nProduct Name:- Name of the specific product\n\nProvider\/Company Name:- Name of the product provider\n\nSector(s):- Sector of education where the product is used\n\nPrimary Essential Function:- The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled","9663f995":"**Read District info**","ee21899e":"**Missing values in products.info file**","02cb2e0b":"**Distribution of Primary Essential Function**","f74620a1":"**Mean per pupil expenditure per state**","495b49ce":"**C1 : What is the picture of Digital Connectivity and Engagement in 2020?**\n\n**Plot to show student Engagement during the course of pandemic**","cd7f4e7a":"**The number of unique providers from product.info file**"}}