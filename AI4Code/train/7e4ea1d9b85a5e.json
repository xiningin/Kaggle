{"cell_type":{"ebba3c41":"code","5b9e6af0":"code","0a74ee3d":"code","290d76a1":"code","c833418a":"code","050225e1":"code","a1d555bd":"code","69e02f73":"code","4565b959":"code","fad7c93d":"code","d272491f":"code","881a1d37":"code","fa9e6717":"code","e639e3c7":"code","646ec325":"markdown","db06e101":"markdown","3797f234":"markdown","db5e21ed":"markdown","722c96d1":"markdown","79de5736":"markdown","6bd59351":"markdown","781c2c32":"markdown","54dec3c7":"markdown","aec4d381":"markdown","d55606e8":"markdown","cfbbed73":"markdown","45609fed":"markdown","e4715248":"markdown","480a1d21":"markdown"},"source":{"ebba3c41":"from math import sqrt\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nimport pandas as pd\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport numpy as np\nimport seaborn as sns\npy.init_notebook_mode(connected=True)\n%matplotlib inline","5b9e6af0":"data = pd.read_csv(filepath_or_buffer=\"..\/input\/btcusdkraken\/BTCUSDKRAKEN\", index_col=\"Date\")\n\n# Get the number of columns of the dataframe\nprint(\"Columns : \" + str(data.columns.values))\n# Get the shape of the dataframe\nprint(\"Shape : \" + str(data.shape))\n# Get the head(), here the first 5 elements of the dataframe\nprint(data.head(5))","0a74ee3d":"data['Weighted Price'].replace(0, np.nan, inplace=True)\ndata['Weighted Price'].fillna(method='ffill', inplace=True)\n\n# Get the head(), here the first 5 elements of the dataframe\nprint(data.head(5))","290d76a1":"from sklearn.preprocessing import MinMaxScaler\nvalues = data['Weighted Price'].values.reshape(-1,1)\nprint(values[0])\nvalues = values.astype('float32')\nprint(values[0])\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(values)\n\n# Get the type of the new item scaled\nprint(type(scaled))\n\n# Get the length of the new item scaled\nprint(\"Length of the new datframe : \" + str(len(scaled)))\n\n# Get the first 5 elements from the scaled dataframe\nprint(scaled[0:5,])","c833418a":"train_size = int(len(scaled) * 0.7)\nprint(\"Train Size : \" + str(train_size))\ntest_size = len(scaled) - train_size\nprint(\"Test Size : \" + str(test_size))\n# print(scaled[0,])\ntrain, test = scaled[0:train_size,:], scaled[train_size:len(scaled),:]\nprint(\"Length of training data : \" + str(len(train)))\nprint(\"Length of testing data : \" + str(len(test)))","050225e1":"def create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back):\n        a = dataset[i:(i + look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","a1d555bd":"look_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\nprint(trainX.shape)\nprint(trainY.shape)\nprint(testX.shape)\nprint(testY.shape)","69e02f73":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n\nprint(trainX.shape)\nprint(testX.shape)\n\n# print(trainX)\n# print(trainY)","4565b959":"# Initialise the sequential model\nmodel = Sequential()\n# Add the LSTM hidden layer with 100 units\nmodel.add(LSTM(100, input_shape=(trainX.shape[1], trainX.shape[2])))\n# Add the output layer\nmodel.add(Dense(1))\n# Compile the model with Mean Absolute Error as the loss factor and ADAM as the optimiser\nmodel.compile(loss='mae', optimizer='adam')\n# Fit the model using the training and testing data\nhistory = model.fit(trainX, trainY, epochs=300, batch_size=100, validation_data=(testX, testY), verbose=1, shuffle=False)","fad7c93d":"pyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","d272491f":"yhat = model.predict(testX) # Here yhat is the predicted value from the test set (y_pred)\nprint(yhat.shape)\nprint(yhat[0])\n\npyplot.plot(yhat, label='predict')\npyplot.plot(testY, label='true')\npyplot.legend()\npyplot.show()","881a1d37":"# scaler = MinMaxScaler(feature_range=(0, 1)) as used before for fit_transform and MinMaxScaler\nyhat_inverse = scaler.inverse_transform(yhat.reshape(-1, 1))\ntestY_inverse = scaler.inverse_transform(testY.reshape(-1, 1))\n\nprint(yhat_inverse.shape)\nprint(testY_inverse.shape)\n\nprint(yhat_inverse[0])\nprint(testY_inverse[0])","fa9e6717":"rmse = sqrt(mean_squared_error(testY_inverse, yhat_inverse))\nprint('Test RMSE: %.3f' % rmse)","e639e3c7":"pyplot.plot(yhat_inverse, label='predict')\npyplot.plot(testY_inverse, label='actual', alpha=0.5)\npyplot.legend()\npyplot.show()","646ec325":"## *Read the Data Set*","db06e101":"# *Create function for creating dataset with look back*","3797f234":"## *Split 70% of data for training and 30% for testing*","db5e21ed":"# **Bitcoin Time Series Prediction with LSTM**","722c96d1":"## *Import necessary libraries needed for the model training*","79de5736":"# *Running the LSTM model with 300 epochs*","6bd59351":"## *Plot line graph with Y as USD*","781c2c32":"## *Reshape X for model training*","54dec3c7":"## *Fill value 0 data points on `Weighted Price` with NAN and then use ffill method to fill values*","aec4d381":"## *Plot line graph to show amount loss according to the epoch*","d55606e8":"## *RMSE*","cfbbed73":"## *Generate dataset for trainX, trainY, testX, testY*","45609fed":"## *Make prediction using textX and plotting line graph against testY*","e4715248":"## *Scaler Inverse Y back to normal value*","480a1d21":"## *Use `Weighted Price` as a feature to train the LSTM model and Use MinMaxScaler to normalize `Weighted Price` to range from 0 to 1*"}}