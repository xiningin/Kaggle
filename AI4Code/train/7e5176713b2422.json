{"cell_type":{"709c1777":"code","30e7ad6c":"code","8ca3c538":"code","bdaf7e99":"code","648b65d2":"code","f876bb8f":"code","29c137ba":"code","26732411":"code","58b76310":"code","ec3ee2f7":"code","20349b02":"code","a4768e8f":"code","55ce8ed8":"code","2b7e8fff":"code","9b36d87e":"code","717b1035":"code","e8b033ba":"code","9ea3eb39":"code","55f776f1":"code","c2ba4ed8":"code","2fc41337":"code","212af93b":"code","cce727e7":"code","41ac5127":"code","015498d4":"code","4a4b30a2":"code","f2f46211":"code","e96e7bc4":"code","678692b9":"code","0a496d17":"code","6c8df23e":"code","b2556cae":"code","30bdeeac":"code","3efb9165":"code","4a73ea19":"code","a9da73e9":"code","d25a50fc":"code","e9f6849c":"code","6b1aef80":"code","890cd9d1":"markdown","a4ff9420":"markdown","6048925b":"markdown","f99fa67a":"markdown","755ad67d":"markdown","ab03a94e":"markdown","0fa394cc":"markdown","986356c7":"markdown","15b76ed5":"markdown","d490a62b":"markdown","0de6596d":"markdown","2af6c03e":"markdown","9a98d2be":"markdown","cc1b20b6":"markdown","96fe43ea":"markdown","5bbfc97a":"markdown","269168c5":"markdown","bb980c27":"markdown","55669619":"markdown","990dda8f":"markdown","be340c05":"markdown","6351daa7":"markdown","bb5f8a89":"markdown","bd77eca5":"markdown","010a2230":"markdown","fdfbfda1":"markdown","d1790f51":"markdown"},"source":{"709c1777":"# importing libraries\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline","30e7ad6c":"# reading data into the dataframe\ndf = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","8ca3c538":"# displaying first five rows\ndf.head()","bdaf7e99":"# shape of the dataframe\ndf.shape","648b65d2":"# concise summary of dataframe\ndf.info()","f876bb8f":"# column names\ndf.columns","29c137ba":"# checking for null values\ndf.isnull().sum()","26732411":"# dropping 'Unnamed: 32' column.\ndf.drop(\"Unnamed: 32\", axis=1, inplace=True)","58b76310":"# dropping id column\ndf.drop('id',axis=1, inplace=True)","ec3ee2f7":"# descriptive statistics of data\ndf.describe()","20349b02":"# countplot\nplt.figure(figsize = (8,7))\nsns.countplot(x=\"diagnosis\", data=df, palette='magma')","a4768e8f":"# heatmap\nplt.figure(figsize=(20,18))\nsns.heatmap(df.corr(), annot=True,linewidths=.5, cmap=\"Purples\")","55ce8ed8":"df.columns","2b7e8fff":"# Getting Mean Columns with diagnosis\nm_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n\n# Getting Se Columns with diagnosis\ns_col = ['diagnosis','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se']\n\n# Getting Worst column with diagnosis\nw_col = ['diagnosis','radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","9b36d87e":"# pairplot for mean columns\nsns.pairplot(df[m_col],hue = 'diagnosis', palette='Blues')","717b1035":"# pairplot for se columns\nsns.pairplot(df[s_col],hue = 'diagnosis', palette='Greens')","e8b033ba":"# pairplot for worst columns\nsns.pairplot(df[w_col],hue = 'diagnosis', palette='Oranges')","9ea3eb39":"# counts of unique rows in the 'diagnosis' column\ndf['diagnosis'].value_counts()","55f776f1":"# mapping categorical values to numerical values\ndf['diagnosis']=df['diagnosis'].map({'B':0,'M':1})","c2ba4ed8":"df['diagnosis'].value_counts()","2fc41337":"from sklearn.model_selection import train_test_split\n\n# splitting data\nX_train, X_test, y_train, y_test = train_test_split(\n                df.drop('diagnosis', axis=1),\n                df['diagnosis'],\n                test_size=0.2,\n                random_state=42)\n\nprint(\"Shape of training set:\", X_train.shape)\nprint(\"Shape of test set:\", X_test.shape)","212af93b":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_test = ss.fit_transform(X_test)","cce727e7":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\npredictions1 = logreg.predict(X_test)","41ac5127":"from sklearn.metrics import confusion_matrix, classification_report\n\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions1))\nprint('\\n')\nprint(classification_report(y_test, predictions1))","015498d4":"from sklearn.metrics import accuracy_score\n\nlogreg_acc = accuracy_score(y_test, predictions1)\nprint(\"Accuracy of the Logistic Regression Model is: \", logreg_acc)","4a4b30a2":"from sklearn.neighbors import KNeighborsClassifier","f2f46211":"# to find which value shows the lowest mean error\nerror_rate = []\n\nfor i in range(1,42):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","e96e7bc4":"plt.figure(figsize=(12,6))\nplt.plot(range(1,42), error_rate, color='purple', linestyle=\"--\",\n         marker='o', markersize=10, markerfacecolor='b')\nplt.title('Error_Rate vs K-value')\nplt.show()","678692b9":"knn = KNeighborsClassifier(n_neighbors=9)\nknn.fit(X_train, y_train)\npredictions2 = knn.predict(X_test)","0a496d17":"print(confusion_matrix(y_test, predictions2))\nprint(\"\\n\")\nprint(classification_report(y_test, predictions2))","6c8df23e":"knn_model_acc = accuracy_score(y_test, predictions2)\nprint(\"Accuracy of K Neighbors Classifier Model is: \", knn_model_acc)","b2556cae":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=300)\nrfc.fit(X_train, y_train)\npredictions4 = rfc.predict(X_test)","30bdeeac":"print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions4))\nprint(\"\\n\")\nprint(classification_report(y_test, predictions4))","3efb9165":"rfc_acc = accuracy_score(y_test, predictions4)\nprint(\"Accuracy of Random Forests Model is: \", rfc_acc)","4a73ea19":"from sklearn.svm import SVC\n\nsvc_model = SVC(kernel=\"rbf\")\nsvc_model.fit(X_train, y_train)\npredictions5 = svc_model.predict(X_test)","a9da73e9":"print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions5))\nprint(\"\\n\")\nprint(classification_report(y_test, predictions5))","d25a50fc":"svm_acc = accuracy_score(y_test, predictions5)\nprint(\"Accuracy of SVM model is: \", svm_acc)","e9f6849c":"print(logreg_acc)\nprint(knn_model_acc)\nprint(rfc_acc)\nprint(svm_acc)","6b1aef80":"plt.figure(figsize=(12,6))\nmodel_acc = [logreg_acc, knn_model_acc, rfc_acc, svm_acc]\nmodel_name = ['LogisticRegression', 'KNN', 'RandomForests', 'SVM']\nsns.barplot(x= model_acc, y=model_name, palette='magma')","890cd9d1":"## 1.1 Understanding the data","a4ff9420":"Breast cancer is cancer that forms in the cells of the breasts.<p>It arises in the lining cells (epithelium) of the ducts (85%) or lobules (15%) in the glandular tissue of the breast. Initially, the cancerous growth is confined to the duct or lobule (\u201cin situ\u201d) where it generally causes no symptoms and has minimal potential for spread (metastasis).<br>\n    \nMost types of breast cancer are easy to diagnose by microscopic analysis of a sample - or biopsy - of the affected area of the breast. Also, there are types of breast cancer that require specialized lab exams.","6048925b":"# 3. Final Results","f99fa67a":"## 2.3 Classification Models","755ad67d":"The whole column 'Unamed: 32' has NaN values.","ab03a94e":"### 2.3.2 K Nearest Neighbours","0fa394cc":"# Breast Cancer Data Analysis and Predictions","986356c7":"###  Breast Cancer","15b76ed5":"### 2.3.4 Support Vector Machines (SVM)","d490a62b":"## 2.2 Splitting the data into train and test","0de6596d":"Logistic Regression model and SVM model gave best performance with an accuracy of **98.24%**","2af6c03e":"From the heatmap, we can observe from the heatmaps that there are many negative correlations in this dataset.","9a98d2be":"## 2.1 Data Preprocessing","cc1b20b6":"# 1. Exploratory Data Analysis","96fe43ea":"### 2.3.1 Logistic Regression","5bbfc97a":"### For Worst columns","269168c5":"### 2.3.3 Random Forests","bb980c27":"From this graph, K value of 9,34,35,36,40 and 41 seem to show the lowest mean error. So using one of these values","55669619":"Please give your suggestions.<br>\nUpvote if you like the notebook\n","990dda8f":"StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance.(Unit variance means dividing all the values by the standard deviation.)","be340c05":"The accuracy of Logistic Regression Model is **98.24%**<br>\nThe accuracy of KNN model is **96.49%**<br>\nThe accuracy of Random Forest Model is **96.49%**<br>\nThe accuracy of SVM Model is **98.24%**<br>","6351daa7":"I have tried my best to explain the code very clearly. In this notebook, I will be using 4 classification models- Logistic Regression, K Nearest Neighbours, Random Forests and Support Vector Machines (SVM).","bb5f8a89":"## 1.2. Data Visualizations","bd77eca5":"### For SE columns","010a2230":"The mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.","fdfbfda1":"### For Mean Columns","d1790f51":"# 2. Data Preprocessing and Building Models"}}