{"cell_type":{"9aabbf06":"code","d7d1325d":"code","b346209d":"code","9eb6d76d":"code","3e871309":"code","fcdf1f47":"code","4f577ca4":"code","ac514235":"code","2d5161c0":"code","805edca7":"code","b8f503d3":"code","793f8a14":"code","817036ba":"markdown","b6c1cbb7":"markdown","c2a0c34a":"markdown","34cd835e":"markdown","88d7bcc4":"markdown","6317e5bc":"markdown","c75a2d42":"markdown","08897209":"markdown","47636592":"markdown"},"source":{"9aabbf06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7d1325d":"from numpy import ones\nfrom numpy import zeros\nfrom numpy.random import rand\nfrom numpy.random import randn\nfrom numpy.random import randint\n\nfrom keras.datasets.cifar10 import load_data\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LeakyReLU\nfrom keras.utils.vis_utils import plot_model\n\nfrom matplotlib import pyplot as plt","b346209d":"(trainX,trainy),(testX,testy) = load_data()\nprint('Train', trainX.shape,trainy.shape)\nprint('Test', testX.shape,testy.shape)\n","9eb6d76d":"def load_real_samples():\n    (trainX,_),(_,_) = load_data()\n    X = trainX.astype('float32')\n    X = (X-127.5)\/127.5\n    return X\n\n# Select real samples\ndef generate_real_samples(dataset,n_samples):\n    # Choose rando instances \n    ix = randint(0,dataset.shape[0],n_samples)\n    #retrieve selected images\n    X = dataset[ix]\n    # generate 'real' class labels (1)\n    y = ones((n_samples,1))\n    return X,y\n\n# generate n fake samples with class labels\ndef generate_fake_samples(n_samples):\n    # generate uniform random numbers in [0,1]\n    X = rand(32*32*3*n_samples)\n    # update to have the range [-1,1]\n    X = -1 + X*2\n    # reshape into a batch of color images\n    X = X.reshape((n_samples, 32,32,3))\n    # generate 'fake' class labels (0)\n    y = zeros((n_samples,1))\n    return X,y","3e871309":"plt.figure(figsize=(15,15))\nfor i in range(49):\n    plt.subplot(7,7,i+1)\n    plt.axis('off')\n    plt.imshow(trainX[i])\nplt.show()","fcdf1f47":"def define_discriminator(in_shape = (32,32,3)):\n    dis_model = Sequential()\n    #normal\n    dis_model.add(Conv2D(64, (3,3), padding = 'same', input_shape = in_shape))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    #downsample\n    dis_model.add(Conv2D(128,(3,3),strides = (2,2),padding = 'same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    #downsample\n    dis_model.add(Conv2D(128,(3,3),strides = (2,2),padding = 'same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    #downsample\n    dis_model.add(Conv2D(256,(3,3),strides = (2,2),padding = 'same'))\n    dis_model.add(LeakyReLU(alpha=0.2))\n    #classifier\n    dis_model.add(Flatten())\n    dis_model.add(Dropout(0.4))\n    dis_model.add(Dense(1,activation = 'sigmoid'))\n    #compile model\n    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n    dis_model.compile(loss = 'binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n    return dis_model\n\ndis_model = define_discriminator()\n\ndis_model.summary()\n\nplot_model(dis_model,to_file='discriminator_plot.png',show_shapes= True, show_layer_names = True)\n","4f577ca4":"def define_generator(latent_dim):\n    gen_model = Sequential()\n    # foundation for 4X4 image\n    n_nodes = 256 * 4 * 4\n    gen_model.add(Dense(n_nodes, input_dim= latent_dim))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    gen_model.add(Reshape((4,4,256)))\n    # upsample to 8x8\n    gen_model.add(Conv2DTranspose(128, (4,4),strides=(2,2),padding='same'))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # upsample to 16X16\n    gen_model.add(Conv2DTranspose(128, (4,4),strides=(2,2),padding='same'))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # upsample to 32X32\n    gen_model.add(Conv2DTranspose(128, (4,4),strides=(2,2),padding='same'))\n    gen_model.add(LeakyReLU(alpha=0.2))\n    # output layer\n    gen_model.add(Conv2D(3, (3,3), activation ='tanh',padding='same'))\n    return gen_model\n\n# summarize the model\ngen_model = define_generator(100)\ngen_model.summary()\n# plot the model\nplot_model(gen_model,to_file='generator_plot.png', show_shapes=True,show_layer_names=True)\n\n\n    ","ac514235":"def define_gan(g_model,d_model):\n    d_model.trainable = False\n    \n    model = Sequential()\n    model.add(g_model)\n    model.add(d_model)\n    \n    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n    model.compile(loss='binary_crossentropy',optimizer=opt)\n    return model\ngan_model = define_gan(gen_model, dis_model)\ngan_model.summary()\nplot_model(gan_model, to_file='gan_plot.png',show_shapes=True,show_layer_names=True)","2d5161c0":"# Generating the input images from the latent dimensions\ndef generate_latent_points(latent_dim,n_samples):\n    x_input = randn(latent_dim*n_samples)\n    x_input = x_input.reshape(n_samples,latent_dim)\n    return x_input\n\n# using the generator model to generate the fake samples\ndef generate_fake_samples(g_model, latent_dim,n_samples):\n    x_input = generate_latent_points(latent_dim,n_samples)\n    #predict outputs\n    X = g_model.predict(x_input)\n    #create 'fake' class\n    y = zeros((n_samples,1))\n    return X,y\n\n'''\nX, _ = generate_fake_samples(gen_model,latent_dim,n_samples)\nX  = (X+1)\/20 # scaling the pixel values from [-1,1] to [0,1]\nplt.figure(figsize=(10,10))\nfor i in range(49):\n    plt.subplot(7,7,i+1)\n    plt.axis('off')\n    plt.imshow(X[i])\nplt.show()\n'''\ndef save_plot(examples, epoch,n=7):\n    # scale from [-1,1] to [0,1]\n    examples = (examples+1)\/2.0\n    for i in range(n*n):\n        plt.subplot(n,n,i+1)\n        plt.axis('off')\n        plt.imshow(examples[i])\n    file_name = 'generated_plot_e%03d.png'%(epoch+1)\n    plt.savefig(file_name)\n    plt.close()","805edca7":"def summarize_performance(epoch,g_model,d_model,dataset,latent_dim,n_samples=150):\n    # preparing the real samples\n    X_real,y_real = generate_real_samples(dataset,n_samples)\n    # evaluate the discriminator on real examples\n    _, acc_real = d_model.evaluate(X_real,y_real,verbose=0)\n    # prepare fake samples\n    x_fake,y_fake = generate_fake_samples(g_model,latent_dim,n_samples)\n    # evaluate discriminator on fake samples\n    _, acc_fake = d_model.evaluate(x_fake,y_fake,verbose =0)\n    # summarizing discriminator performance\n    print('-> Accuracy real: %.0f%%, fake: %.0f%%' %(acc_real*100,acc_fake*100))\n    \n    # save plot\n    save_plot(x_fake,epoch)\n    # save the generator model tile file\n    file_name = 'generator_model_%03d.h5' %(epoch+1)\n    g_model.save(file_name)\n","b8f503d3":"def train(g_model,d_model,gan_model,dataset,latent_dim,n_epochs=200,n_batch=128):\n    bat_per_epo = int(dataset.shape[0]\/n_batch)\n    half_batch = int(n_batch\/2)\n    # manually enumerate epochs\n    for i in range(n_epochs):\n        # enumerate batches over the training set\n        for j in range(bat_per_epo):\n            # get ranoly selected 'real' samples\n            X_real,y_real = generate_real_samples(dataset,half_batch)\n            # update discriminator model weights\n            d_loss1, _ = d_model.train_on_batch(X_real,y_real)\n            # generate 'fake' examples\n            X_fake,y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n            # update discriminator model weights\n            d_loss2, _ = d_model.train_on_batch(X_fake,y_fake)\n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim,n_batch)\n            # create inverted labels for the fake samples\n            y_gan = ones((n_batch,1))\n            # update the generator via discriminator's error\n            g_loss = gan_model.train_on_batch(X_gan,y_gan)\n            # summarize loss on this batch\n            print('>%d, %d\/%d, d1=%.3f, d2=%.3f g =%.3f'% (i+1, j+1, bat_per_epo, d_loss1,d_loss2,g_loss))\n        # evaluate the model performance, sometimes\n        if (i+1)%10 ==0:\n            summarize_performance(i,g_model,d_model,dataset, latent_dim)\n            ","793f8a14":"# size of the latent space \nlatent_dim = 100\n# Discriminator model \nd_model = define_discriminator()\n# Generator model \ng_model = define_generator(latent_dim)\n# gan model \ngan_model = define_gan(g_model,d_model)\n# load image data \ndataset = load_real_samples()\n# training the model \ntrain(g_model,d_model,gan_model,dataset,latent_dim)","817036ba":"## Generating new Images","b6c1cbb7":"## Data Preparation ","c2a0c34a":"## Plotting the images from the training dataset","34cd835e":"## Defining the Discriminator","88d7bcc4":"## Summarizing the performance of the model\n","6317e5bc":"## Defining the GAN model","c75a2d42":"## Defining the Generator","08897209":"## Training the model","47636592":"## Importing the data"}}