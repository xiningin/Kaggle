{"cell_type":{"a020e145":"code","6cd3d990":"code","99a46ea0":"code","2b31de2a":"code","02de92e5":"code","836ba1df":"code","339be05a":"code","271fc9b0":"code","56a25308":"code","fcf90fc7":"code","91f84a79":"code","2d75a4c0":"code","33d73c56":"code","2e8dd4fa":"code","b9c6f729":"code","dd175a62":"code","19856a64":"code","085c058c":"code","ef3e9680":"code","d865f38a":"code","ac069415":"code","93e6b4cd":"code","b9feafc9":"code","847de757":"code","e8a04a5d":"code","03919fb6":"code","79454937":"code","c0388231":"code","69f15839":"code","9609ae32":"code","8ec98d1b":"code","d2ddd218":"code","bab61dc4":"code","f6d0b005":"code","2a403bbc":"code","ee308edb":"code","0908cf12":"code","b19bc79a":"code","f2d3e7dc":"code","05f1efa0":"code","e515d643":"code","12368e18":"code","c75f3481":"code","b2820cc1":"code","566c2641":"code","51c7ddcb":"code","44fda039":"markdown","4cbda958":"markdown","43fdecb2":"markdown","ebfba1ab":"markdown","175875b4":"markdown","b8e7da00":"markdown","746883ac":"markdown","b26912fc":"markdown","a1070a30":"markdown","3e8a0b67":"markdown","dc19c41e":"markdown","17e06002":"markdown","c322ecb3":"markdown","60c10953":"markdown","c5afcc68":"markdown"},"source":{"a020e145":"# Libraries\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, classification_report,f1_score,recall_score,roc_auc_score, roc_curve\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt ","6cd3d990":"# reading dataset\ndf = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","99a46ea0":"df.head()\ndf.Class.value_counts()","2b31de2a":"# RobustScaler is less prone to outliers.\nrob_scaler = RobustScaler()\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\ndf.drop(['Time','Amount'], axis=1, inplace=True)","02de92e5":"df.head()","836ba1df":"# Ratio of classes\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","339be05a":"X = df.drop(\"Class\", axis=1)\ny = df[\"Class\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)","271fc9b0":"# Accuracy 0.999%\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.3f%%\" % (accuracy))","56a25308":"# confusion_matrix\nconfusion_matrix(y_test,y_pred)","fcf90fc7":"# classification_report\nprint(classification_report(y_test, y_pred))","91f84a79":"# recall_score \nrecall_score(y_test, y_pred)","2d75a4c0":"# f1_score\nf1_score(y_test, y_pred)","33d73c56":"# Auc Roc Curve\ndef generate_auc_roc_curve(clf, X_test):\n    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)\n    auc = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n    plt.legend(loc=4)\n    plt.show()\n    pass\n\ngenerate_auc_roc_curve(model, X_test)","2e8dd4fa":"from imblearn.over_sampling import RandomOverSampler\n# define oversampling strategy\n#A floating point value can be specified to indicate the ratio of minority class majority examples in the transformed dataset. (0.5)\noversample = RandomOverSampler(sampling_strategy='minority')\n# fit and apply the transform\nX_randomover, y_randomover = oversample.fit_resample(X_train, y_train)","b9c6f729":"#before random oversampling\ny_train.value_counts()","dd175a62":"#after random oversampling\ny_randomover.value_counts()","19856a64":"model.fit(X_randomover, y_randomover)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.3f%%\" % (accuracy))","085c058c":"# confusion_matrix\nconfusion_matrix(y_test,y_pred)","ef3e9680":"# classification_report\nprint(classification_report(y_test, y_pred))","d865f38a":"# recall_score \nrecall_score(y_test, y_pred)","ac069415":"# f1_score\nf1_score(y_test, y_pred)","93e6b4cd":"generate_auc_roc_curve(model, X_test)","b9feafc9":"from imblearn.over_sampling import SMOTE\n# transform the dataset\noversample = SMOTE()\nX_smote, y_smote = oversample.fit_resample(X_train, y_train)","847de757":"#before smote oversampling\ny_train.value_counts()","e8a04a5d":"#after smote oversampling\ny_smote.value_counts()","03919fb6":"#modelling\nmodel.fit(X_smote, y_smote)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.3f%%\" % (accuracy))","79454937":"# confusion_matrix\nconfusion_matrix(y_test,y_pred)","c0388231":"# classification_report\nprint(classification_report(y_test, y_pred))","69f15839":"# recall_score \nrecall_score(y_test, y_pred)","9609ae32":"# f1_score\nf1_score(y_test, y_pred)","8ec98d1b":"generate_auc_roc_curve(model, X_test)","d2ddd218":"from imblearn.under_sampling import RandomUnderSampler\n# transform the dataset\nranUnSample = RandomUnderSampler()\nX_ranUnSample, y_ranUnSample = ranUnSample.fit_resample(X_train, y_train)","bab61dc4":"#before Random undersampling\ny_train.value_counts()","f6d0b005":"#after Random undersampling\ny_ranUnSample.value_counts()","2a403bbc":"#modelling\nmodel.fit(X_ranUnSample, y_ranUnSample)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.3f%%\" % (accuracy))","ee308edb":"# confusion_matrix\nconfusion_matrix(y_test,y_pred)","0908cf12":"# recall_score \nrecall_score(y_test, y_pred)","b19bc79a":"# f1_score\nf1_score(y_test, y_pred)","f2d3e7dc":"generate_auc_roc_curve(model, X_test)","05f1efa0":"from imblearn.under_sampling import NearMiss\n# define the undersampling method\nNearMiss1 = NearMiss(version=3)\nX_nearMiss, y_nearMiss = NearMiss1.fit_resample(X_train, y_train)","e515d643":"y_nearMiss.value_counts()","12368e18":"#modelling\nmodel.fit(X_nearMiss, y_nearMiss)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.3f%%\" % (accuracy))","c75f3481":"# confusion_matrix\nconfusion_matrix(y_test,y_pred)","b2820cc1":"# recall_score \nrecall_score(y_test, y_pred)","566c2641":"# f1_score\nf1_score(y_test, y_pred)","51c7ddcb":"generate_auc_roc_curve(model, X_test)","44fda039":"## SMOTE Oversampling \n\nCreating synthetic samples from minority class to prevent overfitting.\n\nSMOTE first selects a minority class instance a at random and finds its k nearest minority class neighbors. \nThe synthetic instance is then created by choosing one of the k nearest neighbors b at random and connecting a and b to form a line segment in the feature space. \nThe synthetic instances are generated as a convex combination of the two chosen instances a and b.","4cbda958":"The accuracy score of the model has dropped, but now the rate of correctly predicting within two classes has increased.","43fdecb2":"# Change the performance metric","ebfba1ab":"\n\n**Accuracy** is not the best metric to use when evaluating imbalanced datasets.\n\n- **Confusion Matrix:** showing correct predictions and types of incorrect predictions.\n\n- **Precision:** The number of true positives divided by all positive predictions. Low precision indicates a high number of false positives.\n\n- **Recall:** The number of true positives divided by the number of positive values in the test data. Low recall indicates a high number of false negatives.\n\n- **F1 Score**: the weighted average of precision and recall.\n\n- **AUC:** is a graph showing the performance of a classification model at all classification thresholds. ","175875b4":"# 2- Undersampling\n\nIt is the technique of balancing the data set by removing the samples belonging to the majority class.\nYou can use this technique if you have a large data set. Information may be lost due to random selection.","b8e7da00":"You create a classification model and the accuracy of this model is 95%. Everything is good.\n But you notice that your model always chooses the same class. When you examine the data set again, you see that the rate of the undetected class in the data set is 5%.\nSo the failure of your model is due to the imbalanced dataset.\n\nImbalanced classification refers to a classification predictive modeling problem where the number of examples in the training dataset for each class label is not balanced.There are several ways to deal with this problem.\n\n- Change the performance metric\n\n- Random Oversampling\n\n- SMOTE Oversampling\n\n- Random Undersampling\n\n- NearMiss Undersampling\n\nBrief explanations of the methods and how to apply them are shown in this book.","746883ac":"## **NOTE : Methods should be applied to the training set. If applied to the test set, correct evaluation cannot be made.**","b26912fc":"# Dataset\n\nOur main objective with the dataset is to prioritize accuraltely classifying fraud.","a1070a30":"## NearMiss Undersampling\nIt prevents the loss of information. It is based on the KNN algorithm. The distance between the samples belonging to the majority class and the samples belonging to the minority class is calculated. Samples whose distance is shorter than the specified value of k are preserved.\n\nThree Version:\n\n- NearMiss-1: Majority class examples with minimum average distance to three closest minority class examples.\n- NearMiss-2: Majority class examples with minimum average distance to three furthest minority class examples.\n- NearMiss-3: Majority class examples with minimum distance to each minority class example.\n\n\nThe NearMiss-3 seems desirable, given that it will only keep those majority class examples that are on the decision boundary","3e8a0b67":" # Techniques to Handle Imbalanced Dataset\n \n","dc19c41e":"# 1- Oversampling\n\nBalances the data set by copying minority class samples.","17e06002":"The concern here is that the total number of samples we use to train the model is small.","c322ecb3":"Accuracy score is 0.999 but F1 score of only 0.75 and Recall score of only 0.64. When we examine the confusion matrix, we can see that many false observations have been made.","60c10953":"##\u00a0Random Oversampling\n\nAddition of randomly selected samples from the minority class. This technique can be used if the data set is small. It may cause **overfitting**.","c5afcc68":"## Random Undersampling\nThe extracted samples are chosen at random. "}}