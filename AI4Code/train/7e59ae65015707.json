{"cell_type":{"32aec8f5":"code","733035e8":"code","9ea9197d":"code","fcfc265f":"code","87e730ce":"code","a3becf89":"code","15229537":"code","b6ab0cb5":"code","4adf5575":"code","e547228c":"code","540ba97e":"code","543d2f01":"code","6ba3f517":"code","5a52402b":"code","b10627be":"code","0998aa65":"code","4292dbf0":"code","35593ed1":"code","e07dadbb":"code","875c23fa":"code","a0abc8f6":"code","0d291bd0":"code","b9c74cc8":"code","0bdfb238":"code","3c0fa721":"code","9d30bfbb":"code","b66b3a88":"code","7c5874ec":"code","d2f3bf14":"markdown","903b2ec3":"markdown","5d4e226b":"markdown","c20f66f2":"markdown","d1941bf7":"markdown","2e68f06d":"markdown","0cb87fc6":"markdown","64b661eb":"markdown","8c774fc0":"markdown","98ee43a2":"markdown","27bffcdc":"markdown","5a6f5828":"markdown","adaccd16":"markdown","74c415e5":"markdown","a2f75ba9":"markdown","1edf6a68":"markdown","f24a27d5":"markdown","d510fd3b":"markdown","faad3ebd":"markdown","e56d24d4":"markdown","984bdaaf":"markdown","86ab6c4f":"markdown","e7a32645":"markdown"},"source":{"32aec8f5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","733035e8":"dataset = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\n\nprint(dataset.shape)\ndataset.head(10)\n","9ea9197d":"dataset.describe()","fcfc265f":"dataset.info()","87e730ce":"dataset['sentiment'].value_counts()","a3becf89":"review = dataset['review'].iloc[1]\nreview","15229537":"!pip install bs4\n","b6ab0cb5":"from bs4 import BeautifulSoup\n\nsoup = BeautifulSoup(review, 'html.parser')\nreview = soup.get_text()\nreview","4adf5575":"import re\nreview = re.sub('\\[[^]]*\/]',' ',review)\nreview = re.sub('[^a-zA-Z]',' ',review)\nreview","e547228c":"review =  review.lower()\nreview","540ba97e":"review = review.split()\nreview","543d2f01":"import nltk\n\nfrom nltk.corpus import stopwords\n\nreview = [word for word in review if not word in set(stopwords.words('english'))]\nreview","6ba3f517":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\n\nreview_stemmer = [stemmer.stem(word) for word in review]\nreview_stemmer = ' '.join(review_stemmer)\nreview_stemmer","5a52402b":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nreview_lemmatize = [lemmatizer.lemmatize(word) for word in review]\nreview_lemmatize = ' '.join(review_lemmatize)\nreview_lemmatize","b10627be":"corpus = []\ncorpus.append(review_lemmatize)\ncorpus","0998aa65":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nx = cv.fit_transform(corpus).toarray()\nx","4292dbf0":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf  =  TfidfVectorizer()\n\nreview_tfidf = tfidf.fit_transform(corpus).toarray()\nreview_tfidf","35593ed1":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dataset['review'], dataset['sentiment'], test_size=0.25, random_state=42)\n","e07dadbb":"y_train = y_train.replace({'positive':1, 'negative':0})\ny_test = y_test.replace({'positive':1, 'negative':0})","875c23fa":"x_train.iloc[1]","a0abc8f6":"import re","0d291bd0":"corpus_train = []\ncorpus_test = []\n\nfor i in range(x_train.shape[0]):\n    soup = BeautifulSoup(x_train.iloc[i],'html.parser')\n    review = soup.get_text()\n    review = re.sub('\/[[^]]*\/]',' ',review)\n    review = re.sub('[^a-zA-Z]',' ',review)\n    review = review.lower()\n    review = review.split()\n    \n    lm  = WordNetLemmatizer()\n    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_train.append(review)\n\n\nfor j in range(x_test.shape[0]):\n    soup = BeautifulSoup(x_test.iloc[j],'html.parser')\n    review = soup.get_text()\n    review = re.sub('\/[[^]]*\/]',' ',review)\n    review = re.sub('[^a-zA-Z]',' ',review)\n    review = review.lower()\n    review = review.split()\n    \n    lm = WordNetLemmatizer()\n    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_test.append(review)\n    \n    \n    \n\n\n    \n    \n  ","b9c74cc8":"corpus_train[-1]","0bdfb238":"corpus_test[-1]","3c0fa721":"tfidf = TfidfVectorizer(ngram_range = (1, 3))\n\ntfidf_train = tfidf.fit_transform(corpus_train)\ntfidf_test = tfidf.transform(corpus_test)","9d30bfbb":"from sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC(C=0.5, random_state=42)\nlinear_svc.fit(tfidf_train,y_train)\n\npredict = linear_svc.predict(tfidf_test)\n","b66b3a88":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint('Classification Report: \\n', classification_report(y_test, predict, target_names = ['Negative', 'Positive']))\nprint('Confusion Matrix: \\n', confusion_matrix(y_test, predict))\nprint('Accuracy score: \\n', accuracy_score(y_test, predict))","7c5874ec":"predict","d2f3bf14":"***Importing basic libraries***","903b2ec3":"**Vectorization using TF-IDF Technique**","5d4e226b":"**Now removal of Stopwords (common words) and for this we will create a list of words separated by .split().**\n\n**Note:- Split function splits a sentences by their whitespaces and returns a list containing words**","c20f66f2":"**Validating sample entry**","d1941bf7":"**There are two columns - review and sentiment.\nSentiment is the target column that we have to predict further.**","2e68f06d":"As seen in both the paragraphs the Stemming does not impart proper meaning to the stem word while in Lemmatizing stem words conveys a meaning ***eg-  fantasi & fantasy respectively.***\n\n**We will use Lemmatized review further**.","0cb87fc6":"***Loading dataset***","64b661eb":"**Using Linear SupportVectorClassifier(SVC) as first model-**","8c774fc0":"**Performance Metric**\n- Classification Report\n- Confusion Matrix\n- Accuracy Score","98ee43a2":"**Now we will apply the techiques on whole dataset keeping aside 25% of data for testing purposes**","27bffcdc":"**HTML tags are removed now remove everything except the lowercase\/uppercase letters using regular expressions**","5a6f5828":"**Stemming\/Lemmatization**\nWill apply and observe the differences in both the techniques.","adaccd16":"**NLP stands for Natural Language Processing which is the task of mining the text and find out some meaningful insights like Sentiments, Named Entity, Topic of Discussion and even Summary of the text.**\n\nWith this IMDB dataset we will do the Sentiment Analysis.\n\nFirstly,we will apply some text cleaning techniques i.e do some text pre-processing since textual data is in free form.\n\nSince we cannot apply text to our Machine Learning Model directly we have to convert the text into mathematical form (vector representation) and explore different Vectorization \/ Text Encoding Techniques. ","74c415e5":"1. Removal of HTML contents","a2f75ba9":"**Taking one review as sample and understanding the need of cleaning the text.**","1edf6a68":"**In general any NLP task involves the following text cleaning techniques -**\n1. Removal of HTML contents like \"\\<br>\"\n2. Removal of punctuation and special characters.\n3. Removal of stopwords like the, when, how etc which do not offer much insights.\n4. Stemming\/Lemmatization techniques to have the stem word of the words having multiple forms of words.\n5. Vectorization - encoding the textual data to numerical form after cleaning.\n6. Fitting the data to ML model.\n\n\n","f24a27d5":"Now we will do Vectorization of out text for this we will create a corpus first.","d510fd3b":"**Converting sentiments into numerical form**","faad3ebd":"**Applying the techniques to sample data to understand the process first -**","e56d24d4":"**To vectorize we will apply -**\n1. Bag of Words model ( CountVectorizer)\n2. TF - IDF model (TfidfVectorizer)\n3.\n","984bdaaf":"**Now converting everthing into lowercase**","86ab6c4f":"*Dataset is balanced and has equal number of positive and negative sentiments.*","e7a32645":"**Cleaning text and forming train and test corpus**"}}