{"cell_type":{"f877e403":"code","60905199":"code","cf7dfbe7":"code","d8284ee0":"code","3c7d8fb7":"code","8494377a":"code","8f99a8b0":"code","427af093":"code","07eaf9bf":"code","286e9da7":"code","fe443d5b":"code","0ebde3de":"code","2182336f":"code","f7d7e087":"code","0866d992":"code","1c553fa7":"code","958d6a76":"markdown","1e8c828a":"markdown","7003de6f":"markdown","65d73ec0":"markdown","4255eabb":"markdown","df9c0ebe":"markdown","db4e89a0":"markdown","f73b674f":"markdown","72b72edc":"markdown","0d6f0374":"markdown","cc1caf47":"markdown","b92b9abd":"markdown","86b70c8b":"markdown","c0d04816":"markdown","2896647a":"markdown"},"source":{"f877e403":"import os\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostRegressor\n\nplt.rcParams[\"figure.figsize\"] = (20,10)\npd.options.display.max_rows = None\npd.options.mode.chained_assignment = None  #Disable pandas warnings","60905199":"train_raw = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest_raw = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\nprint(train_raw.shape, test_raw.shape)","cf7dfbe7":"def SMAPE (A, B):\n    return 100\/len(A) * np.sum(2 * np.abs(B - A) \/ (np.abs(A) + np.abs(B)))","d8284ee0":"train_tmp = train_raw.copy()\ntest_tmp = test_raw.copy()\n\n#Convert date column to pandas datetime\ntrain_tmp['date'] = pd.to_datetime(train_tmp['date'])\ntest_tmp['date'] = pd.to_datetime(test_tmp['date'])\n\n#Day of month\ntrain_tmp['day'] = train_tmp['date'].dt.day\ntest_tmp['day'] = test_tmp['date'].dt.day\n\n#Day of year\ntrain_tmp['day_year'] = train_tmp['date'].dt.dayofyear\ntest_tmp['day_year'] = train_tmp['date'].dt.dayofyear\n\n#Month\ntrain_tmp['month'] = train_tmp['date'].dt.month\ntest_tmp['month'] = test_tmp['date'].dt.month\n\n#Day of week (0-6 for Mon-Sun)\ntrain_tmp['week_day'] = train_tmp['date'].dt.dayofweek\ntest_tmp['week_day'] = test_tmp['date'].dt.dayofweek\n\n#Week of year\ntrain_tmp['week'] = train_tmp['date'].dt.isocalendar().week.astype(int)\ntest_tmp['week'] = test_tmp['date'].dt.isocalendar().week.astype(int)\n\n#Weekend (0 if not, 1 if yes)\ntrain_tmp['weekend'], test_tmp['weekend'] = 0, 0\ntrain_tmp.loc[train_tmp['week_day'] >= 5, 'weekend'] = 1\ntest_tmp.loc[test_tmp['week_day'] >= 5, 'weekend'] = 1","3c7d8fb7":"train_tmp['seg'] = (train_tmp['country'] + train_tmp['store'] + train_tmp['product']).astype('category').cat.codes\ntest_tmp['seg'] = (test_tmp['country'] + test_tmp['store'] + test_tmp['product']).astype('category').cat.codes\n\nseg_count = train_tmp['seg'].nunique()","8494377a":"for i in range(seg_count):\n    train_tmp[train_tmp['seg'] == i]['num_sold'].plot()   ","8f99a8b0":"#Function to create lag for one segment\ndef lag_365 (df, seg):\n    df.loc[df['seg'] == seg, 'Lag_365'] = df.loc[df['seg'] == seg]['num_sold'].shift(365)\n    return df\n\n#Merge train and test set to get Lag data from the train set\nmerged = pd.concat([train_tmp, test_tmp])\n\n#The loop to create lags for 18 sements\nfor i in range(seg_count):\n    merged = lag_365(merged, i)\n\n#Split train and test set back\ntrain_tmp = merged.iloc[:len(train_tmp)]\ntest_tmp = merged.iloc[len(train_tmp):].drop('num_sold', axis=1)","427af093":"train_tmp = train_tmp.drop(['country', 'store', 'product', 'row_id'], axis=1)\ntest_tmp = test_tmp.drop(['country', 'store', 'product', 'row_id'], axis=1)","07eaf9bf":"split_date = datetime.datetime(2018, 1, 1)\n\ntrain = train_tmp[train_tmp['date'] < split_date]\nvalid = train_tmp[train_tmp['date'] >= split_date]\n\nX_train = train.drop('num_sold', axis=1)\ny_train = train[['seg','num_sold']]\nX_valid = valid.drop('num_sold', axis=1)\ny_valid = valid[['seg','num_sold']]\n\nprint(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\nprint(train.shape, valid.shape)","286e9da7":"def oof_validation (train_X, train_y, valid_X, valid_y, seg):\n    \n    #This is very simple model, almost by defalut\n    mod = CatBoostRegressor(random_seed = 17,      #Random seed\n                            thread_count = 4,      #CPU cores at Kaggle notebook\n                            verbose = 0,           #Silent mode\n                            eval_metric = 'SMAPE', #Copmetition metric\n                            has_time = True)       #Turn off shuffle\n                            \n    fit = mod.fit(\n                  train_X[train_X['seg'] == seg],\n                  train_y[train_y['seg'] == seg]['num_sold'],\n                  eval_set = (\n                              valid_X[valid_X['seg'] == seg],\n                              valid_y[valid_y['seg'] == seg]['num_sold']\n                              ),\n                  )\n    pred = mod.predict(valid_X[valid_X['seg'] == seg])\n    \n    #Here I use my function to calculate SMAPE\n    smape = SMAPE(pred, valid_y[valid_y['seg'] == seg]['num_sold'])\n    print('OOF SMAPE for segment', seg, 'is:', \"%.5f\" % smape)\n    \n    #The fuction returns SMAPE for every segment\n    return smape","fe443d5b":"score = []\nfor i in range(seg_count):\n    score.append(oof_validation(X_train, y_train, X_valid, y_valid, i))\nprint('---')\nprint('Mean OOF SMAPE is:', \"%.5f\" % (sum(score) \/ seg_count)) ","0ebde3de":"X_train_full = train_tmp.drop('num_sold', axis=1)\ny_train_full = train_tmp[['seg','num_sold']]\nX_test_full = test_tmp\nprint(X_train_full.shape, y_train_full.shape, X_test_full.shape)","2182336f":"def predictions (train_X, train_y, test_X, seg):\n    \n    mod = CatBoostRegressor(random_seed = 17,      \n                            thread_count = 4,      #CPU cores at Kaggle notebook\n                            verbose = 0,           #Silent mode\n                            eval_metric = 'SMAPE', #Copmetition metric\n                            has_time = True)       #Turn off shuffle \n                            \n    fit = mod.fit(train_X[train_X['seg'] == seg], train_y[train_y['seg'] == seg]['num_sold'])\n    pred = mod.predict(test_X[test_X['seg'] == seg])\n    test_X.loc[test_X['seg'] == seg, 'num_sold'] = pred\n    print('Predictions for segment', seg, 'complete')\n    return test_X","f7d7e087":"for j in range(seg_count):\n    df = predictions(X_train_full, y_train_full, X_test_full, j)\n    X_test_full.loc[X_test_full['seg'] == j, 'num_sold'] = df['num_sold']\nprint('---')\nprint('Predictions complete')\nX_test_full.head()","0866d992":"segment = 5 #choose any\nax = y_valid[y_valid['seg'] == segment]['num_sold'].reset_index(drop = True).plot(color = 'black')\nX_test_full[X_test_full['seg'] == segment]['num_sold'].reset_index(drop = True).plot(ax=ax)","1c553fa7":"sub = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\nsub['num_sold'] = X_test_full['num_sold']\nsub.to_csv('submission.csv', index=False) \nsub.head()","958d6a76":"### Predictions\nI will train the model on a full training set","1e8c828a":"Test plot (predictions vs. previous year) to check that prediction looks realistic","7003de6f":"Here the plot for all 18 segments","65d73ec0":"#### Title\nIn this exercise I show one of possible ways of using Catboost for time series forecast.<br>\nThis is a very basic model, so please don't expect high score, you can use it as a baseline for further experments.","4255eabb":"Here I add some basic additional features","df9c0ebe":"Split validation set from train set. I wil use 2018 for validation and all the rest for training.","db4e89a0":"The very similiar function to generate predictions","f73b674f":"Call the function 18 times to generate predictions for every segment","72b72edc":"#### Out of fold validation\nAs we have 18 segments we have to create the function to train and to validate model for every segment","0d6f0374":"There is not SMAPE metric in sklearn, so I created the own one.<br>\nAs soon as SMAPE is a symmetrical metric you can send predictions and real results (A and B arguments) in any order","cc1caf47":"Drop meanless features","b92b9abd":"Here I call the OOF function 18 times and collect SMAPE for each run","86b70c8b":"#### Segments encoding\nWe have 3 contries, 2 stores and 3 products. It means that actually we have 3 x 2 x 3 = 18 segments and have to do all operations 18 times, for each segment<br>\nHere I create and encode 18 segments (0-17) from ```country```, ```store``` and ```product``` features.","c0d04816":"#### Additional features\nFortunately, the test set continues in time with the training set that let us use 365 days lag. Here I create it for every of 18 segments.","2896647a":"#### Submission"}}