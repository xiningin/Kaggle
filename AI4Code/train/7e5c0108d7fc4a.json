{"cell_type":{"8e5a6156":"code","e130aea2":"code","dc80b582":"code","e5dd5de7":"code","6cae48bb":"code","d21cc8f5":"code","a60c84d7":"code","4cfcfbf8":"code","fa410e0c":"code","1234302a":"code","3287b8ab":"code","f460076e":"code","8ad6a899":"code","83ae85f8":"code","669e86fb":"code","eb15ecbb":"code","13c439ac":"code","8aa072b3":"code","8d84eae3":"code","0183b0ea":"code","56bb5186":"code","76283153":"code","0e614f52":"code","61708d14":"code","b5e67539":"code","111b314a":"markdown","5823c193":"markdown","9aec3f32":"markdown","225eadad":"markdown","c58e5205":"markdown","fd7f713e":"markdown","0b4d80ef":"markdown","3365d717":"markdown","34a24b51":"markdown","6a5be134":"markdown","12b9bdd0":"markdown","c50fa72a":"markdown","9c9d83b1":"markdown","b796cfcc":"markdown","75618d3b":"markdown","500cd3bb":"markdown","eb524d12":"markdown","6d5dcebe":"markdown","b40719ec":"markdown","58c0a82d":"markdown"},"source":{"8e5a6156":"# Familiar imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import recall_score, f1_score, confusion_matrix, classification_report","e130aea2":"import warnings\nwarnings.filterwarnings('ignore')","dc80b582":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)","e5dd5de7":"train.head()","6cae48bb":"train.shape","d21cc8f5":"train.dtypes.value_counts()","a60c84d7":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","4cfcfbf8":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]","fa410e0c":"plt.figure(figsize=(20, 10))\nsns.heatmap(train.isna(), cbar=False)","1234302a":"y.dtype","3287b8ab":"plt.figure(figsize=(20, 10))\nplt.plot(y.values)","f460076e":"for col in features.select_dtypes('float'):\n    plt.figure()\n    sns.histplot(features[col])","8ad6a899":"for col in features.select_dtypes('object'):\n    print(f'{col :-<50}{features[col].unique()}')","83ae85f8":"for col in features.select_dtypes('object'):\n    plt.figure()\n    x = features[col].value_counts()\n    features[col].value_counts().plot.pie(autopct = lambda x: str(round(x, 2)) + '%', \n                                          pctdistance = 2, labeldistance = 1.4,\n                                           shadow = True)","669e86fb":"sns.clustermap(features.corr(), cbar=True, annot=True)","eb15ecbb":"# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n","13c439ac":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","8aa072b3":"X_train.head()","8d84eae3":"def evaluation(model):\n    model.fit(X_train, y_train)\n    preds_valid = model.predict(X_valid)\n   \n    print(mean_squared_error(y_valid, preds_valid, squared=False))\n    ","0183b0ea":"preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))\n\nLR_model = make_pipeline(preprocessor, LinearRegression())\nRandomForest_model = make_pipeline(preprocessor, RandomForestRegressor())\nDecisionTreeRegressor_model = make_pipeline(preprocessor, DecisionTreeRegressor())\n\nlist_models = {'LR_model' : LR_model, \n               'RandomForest_model' : RandomForest_model,\n               'DecisionTreeRegressor_model' : DecisionTreeRegressor_model}\n\nfor name, model in list_models.items():\n    print(name)\n    #evaluation(model)","56bb5186":"para = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]}\n\nXGBRegressor_model = XGBRegressor()\nclf = RandomizedSearchCV(XGBRegressor_model, para, random_state=0)\n\n#search = clf.fit(X_train, y_train)\n#search.best_params_","76283153":"#preds_valid = search.best_estimator_.predict(X_valid)\n\n#print(mean_squared_error(y_valid, preds_valid, squared=False))","0e614f52":"from sklearn.ensemble import BaggingRegressor\n\nbest_para = {'min_child_weight': 7,\n 'max_depth': 4,\n 'learning_rate': 0.3,\n 'gamma': 0.2,\n 'colsample_bytree': 0.7}\n\nregr = BaggingRegressor(base_estimator=XGBRegressor(**best_para), n_estimators=10, random_state=0)\n\n#regr.fit(X_train, y_train, eval_metric = \"rmse\", early_stopping_rounds = 50)\n#preds_valid = regr.predict(X_valid)\n   \n#print(mean_squared_error(y_valid, preds_valid, squared=False))","61708d14":"xgb_params = {\n    'booster': 'gbtree',\n    'n_estimators': 10000,\n    'learning_rate': 0.05,\n    'reg_lambda': 10,\n    'reg_alpha': 26,\n    'subsample': 0.9,\n    'colsample_bytree': 0.12,\n    'max_depth': 3,\n    'random_state': 0\n}\n\nregr = XGBRegressor(**xgb_params)\n\nregr.fit(X_train, y_train, eval_metric = \"rmse\")\npreds_valid = regr.predict(X_valid)\n   \nprint(mean_squared_error(y_valid, preds_valid, squared=False))","b5e67539":"# Use the model to generate predictions\npredictions = regr.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","111b314a":"## Encode categorical features ","5823c193":"## Define target and features","9aec3f32":"## Define models","225eadad":"# 1. Import Libraries ","c58e5205":"### XGBRegressor","fd7f713e":"## View numeric data","0b4d80ef":"## Load data","3365d717":"# 3. Data preprocessing","34a24b51":"## Categorical data","6a5be134":"#### Search for the best hyperparameters","12b9bdd0":"<h1><a href='https:\/\/www.kaggle.com\/c\/30-days-of-ml\/overview'>30 Days of ML competition<\/a><\/h1>","c50fa72a":"#### No missing data","9c9d83b1":"# 2. Exploratory data analysis","b796cfcc":"## Correlation between features","75618d3b":"## View target","500cd3bb":"## Divide data into trainset and validationset","eb524d12":"# 4. Train a models","6d5dcebe":"## View categorical data","b40719ec":"#### BaggingRegressor","58c0a82d":"## View missing data "}}