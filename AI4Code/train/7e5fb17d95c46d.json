{"cell_type":{"de5f2fe4":"code","ec6a4526":"code","88b5cebf":"code","209143db":"code","946c80ed":"code","fab4bfa9":"code","abd33f84":"code","938837e6":"code","ff6c586a":"code","3ad88f67":"code","804dbc83":"code","a1ace6ad":"code","4934cbaf":"code","6664241d":"code","cc507fb6":"code","814f8c5c":"code","6b403394":"code","54f33b36":"code","8cee1cbd":"code","688f42a5":"code","8489d474":"markdown","d5ec62bd":"markdown","41a9abb9":"markdown","ce32fbdb":"markdown","7bafa7d5":"markdown","1a4351cd":"markdown","db45338f":"markdown","3914be1e":"markdown","6603f6b5":"markdown","9aa891d3":"markdown","a550ac57":"markdown","43f4f1e2":"markdown","ada4ca81":"markdown","5bfdcf87":"markdown"},"source":{"de5f2fe4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output\nseed=5","ec6a4526":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')","88b5cebf":"train.label.value_counts().plot.bar()","209143db":"train.label.value_counts()","946c80ed":"df=train.groupby('label').apply(lambda x: x.sample(3795)).reset_index(drop=True)\ndf.label.value_counts()","fab4bfa9":"df=df.sample(frac=1,random_state=seed)","abd33f84":"from sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\ntarget=df['label']\nX=df.drop('label',axis=1)\ntarget=to_categorical(target)\n\ntrain_X,val_X,train_y,val_y=train_test_split(X,target,test_size=0.01,random_state=seed)","938837e6":"train_X=train_X\/255\nval_X=val_X\/255\n\ntrain_X=train_X.values.reshape(-1,28,28,1)\nval_X=val_X.values.reshape(-1,28,28,1)","ff6c586a":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nplt.imshow(train_X[0][:,:,0])","3ad88f67":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen=ImageDataGenerator(width_shift_range=0.2,height_shift_range=0.2,\n                                rotation_range=10)\n\ntrain_datagen.fit(train_X)","804dbc83":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D,BatchNormalization,Dropout,Flatten,Dense\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau","a1ace6ad":"model=Sequential()\nmodel.add(Conv2D(64,3,input_shape=(28,28,1),padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Conv2D(128,3,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Conv2D(256,3,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Conv2D(512,3,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Conv2D(1024,3,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Conv2D(1024,3,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.8))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.8))\nmodel.add(Dense(10,activation='softmax'))\n\n","4934cbaf":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","6664241d":"est=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\nrlp=ReduceLROnPlateau(monitor='val_loss',patience=10,factor=0.1,min_delta=0.0001)\ncall_backs=[est,rlp]","cc507fb6":"#tune epochs to 30 for 100 percent accuracy on validation\n\nbatch_size=64\nresult=model.fit_generator(train_datagen.flow(train_X,train_y,batch_size=batch_size),epochs=1,\n                  callbacks=call_backs,validation_data=(val_X,val_y),validation_steps=1,\n                          steps_per_epoch=train_X.shape[0]\/\/batch_size)","814f8c5c":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.plot(result.history['loss'],label='Train loss')\nplt.plot(result.history['val_loss'],label='Validation loss')\nplt.legend(loc='best')","6b403394":"from sklearn.metrics import confusion_matrix\n\nval_pred_probs=model.predict(val_X)\nval_labels=np.argmax(val_pred_probs,axis=1)\ntrue_labels=np.argmax(val_y,axis=1)\ncm=confusion_matrix(val_labels,true_labels)\n\nplt.figure(figsize=(10,6))\nsns.heatmap(cm,annot=True)\n","54f33b36":"test=test\/255\ntest=test.values.reshape(-1,28,28,1)","8cee1cbd":"test_probs=model.predict(test)\ntest_labels=np.argmax(test_probs,axis=1)","688f42a5":"sub=pd.read_csv('..\/input\/sample_submission.csv')\nsub['label']=test_labels\nsub.to_csv('Submission.csv',index=False)","8489d474":"**9. Using callbacks to avoid overfitting**","d5ec62bd":"**Suggestions are welcomed !!**","41a9abb9":"**2. Sampling the data to get equal number of samples of each class**","ce32fbdb":"**3. Shuffling the data**","7bafa7d5":"**10. Confusion matrix**","1a4351cd":"Not even one sample is misclassified! But this can also be attributed to the fact that validation set size is very small. Nevertheless, I am amazed :D","db45338f":"Data is normalized because the optimizers converge faster when the values are between (0,1) rather than (0,255).\nWidth and height of images is 28 pixels. ","3914be1e":"**5. Normalizing and Reshaping the data**","6603f6b5":"**4. Splitting the data**","9aa891d3":"**7. Data Augmentation**","a550ac57":"We use data augmentation to generate more samples of each class and to make our model more robust.\n\n1. We shift width of samples randomly by 20 percent.\n2. We shift height of samples randomly by 20 percent.\n3. We rotate the samples randomly by 10 degrees.","43f4f1e2":"**8. Setting up the model**","ada4ca81":"**6. Plotting one of the samples**","5bfdcf87":"**1. Reading the data**"}}