{"cell_type":{"bf6beb01":"code","7b49b721":"code","f25dce3b":"code","ede907aa":"code","cb8caf29":"code","b67d87ac":"code","b4d98909":"code","e20265aa":"code","e9060220":"code","16bf5ca4":"code","2be4df8f":"code","5f74bd33":"code","4226c62f":"code","283ccda3":"code","b646e31e":"code","9a312562":"code","946ca197":"code","181e2f24":"code","8799698c":"code","a75fa86b":"code","75cbe8bb":"code","f55c7c0e":"code","2aed5f7f":"code","6012b78f":"code","ee76407d":"code","4ba2ca35":"code","eb4eeae9":"code","fee60bf7":"code","6cd30660":"code","d18f4c93":"code","91afded3":"code","57c62de0":"code","1cbbc0d3":"code","6b915a90":"code","5be01e30":"code","a2d2f928":"code","7b1eb010":"code","d00b829b":"code","4a7fe9e6":"code","977e2314":"code","2d17bf6a":"code","707594c0":"code","56e8c7da":"code","a80b6a85":"code","cea9fbb2":"code","24f63fb3":"code","d3813253":"code","2612554e":"code","9e92d308":"code","e2fd7e5b":"code","b514c705":"code","291ca29b":"code","713903c7":"code","9855693c":"code","53ead250":"code","404f0b49":"code","0f188283":"code","3495e19c":"code","a22b6c27":"code","9f4a04aa":"code","8676f150":"code","c8fcf3ff":"code","7c5ae0be":"code","11f4a88e":"code","7c8b3ae9":"code","c17ba23f":"code","1795408c":"code","fe230b07":"code","f067d9dd":"code","92af3d58":"code","069c3be3":"code","2cb4b186":"code","149a8ea7":"code","282a1229":"code","7ca8f490":"code","2be8f982":"code","6e334396":"code","beb6c560":"code","d865578d":"code","33059c35":"code","4e5f45e0":"code","71031455":"code","c9ec54f8":"code","506c9286":"code","ffe6ede8":"code","007468cd":"code","b06654ec":"code","fa34c876":"code","11445e43":"code","e8afb300":"code","4607a7ee":"code","9e6bd98a":"code","dab5bfcf":"code","2c79a97e":"code","72f9cb63":"code","7853605b":"code","7252cd32":"code","7644e6da":"code","a4e7180a":"code","03c3e17f":"code","a1b5b072":"code","55124d36":"code","2cd2aa4e":"code","10c7ec3c":"code","e533daaa":"code","01e88d2e":"code","fbd5f6d4":"code","e63df772":"code","6e3ecefb":"code","5aeeed07":"code","f366bcf5":"code","6c58f4df":"code","3136c198":"code","b1aa8493":"code","44806b6a":"code","327607d1":"code","39823362":"code","224f0a03":"code","3a6e0dab":"code","7a3a5f5c":"code","42318130":"code","e59a29fb":"code","5a4aecb5":"code","a770092f":"code","9e950bc2":"code","1eb5f2ee":"code","7f24f719":"code","d9fe1162":"code","5b4b9b43":"code","6b30de1c":"code","b595e195":"code","443a00c1":"code","c8f01ef9":"code","24f6f3d7":"code","c0f7b5e7":"code","8a966e93":"code","aa98970d":"code","38932eb0":"code","249e2424":"code","905b1f09":"code","8df25fb3":"code","58618a29":"code","fb2c6257":"code","a6afae97":"code","8f7564f2":"code","c9ae6623":"code","64572455":"code","79f3b6d7":"code","487a0360":"code","cd17e086":"markdown","d346d77f":"markdown","dba51c62":"markdown","2c703077":"markdown","fce0402b":"markdown","bc4dc01f":"markdown","6d2c725a":"markdown","16d9d227":"markdown","793ce2ba":"markdown","95f3c26e":"markdown","dbaa2f56":"markdown","46441c9d":"markdown","407348cc":"markdown","22f32b4a":"markdown","79406797":"markdown","8164dc91":"markdown","247c4fac":"markdown","befb374b":"markdown","86c635c7":"markdown","43416bc9":"markdown","10639496":"markdown","156ea4df":"markdown","f230a954":"markdown","70dcaadf":"markdown","bc98b3c0":"markdown","3cd4f948":"markdown","d52749ad":"markdown","229e2798":"markdown","fd05212b":"markdown","215af763":"markdown","685426bc":"markdown"},"source":{"bf6beb01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7b49b721":"import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score,mean_squared_error,r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport statsmodels.formula.api as smf\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","f25dce3b":"#uyar\u0131lar\u0131 kapatma\nfrom warnings import filterwarnings\nfilterwarnings('ignore', category = DeprecationWarning)\nfilterwarnings('ignore', category = FutureWarning)","ede907aa":"# bilgileri girildi\u011finde \u015feker hastal\u0131\u011f\u0131 olup olmayaca\u011f\u0131n\u0131 tahmin edebilir miyiz?\n# \u015feker hastas\u0131 olacak m\u0131s\u0131n?\ndiabetes = pd.read_csv(\"..\/input\/datasets2\/diabetes.csv\")\ndf = diabetes.copy()\ndf = df.dropna()\ndf.head()","cb8caf29":"df.info();","b67d87ac":"#ka\u00e7 ki\u015fi\ndf[\"Outcome\"].value_counts()","b4d98909":"df[\"Outcome\"].value_counts().plot.barh();","e20265aa":"# ba\u011f\u0131ms\u0131z de\u011fi\u015fkenlerin g\u00f6zlemi\ndf.describe().T","e9060220":"y = df[\"Outcome\"] # ba\u011f\u0131ml\u0131 de\u011fi\u015fken\nX = df.drop([\"Outcome\"], axis=1) # outcome d\u0131\u015f\u0131ndakilerini de ba\u011f\u0131ms\u0131z alma\n# ba\u011f\u0131ml\u0131 de\u011fi\u015fken\ny.head()","16bf5ca4":"#ba\u011f\u0131ms\u0131z de\u011fi\u015fkenler\nX.head()","2be4df8f":"#katsay\u0131lar\u0131 bulmak i\u00e7in.\n# rich ve lasso d\u00fczenleme ile katsay\u0131 bulma y\u00f6ntemleri var.\nloj_model = LogisticRegression(solver = \"liblinear\").fit(X,y)\nloj_model.get_params()","5f74bd33":"# ba\u011f\u0131ml\u0131 de\u011fi\u015fken katsay\u0131lar\u0131\nloj_model.intercept_","4226c62f":"#ba\u011f\u0131ms\u0131z de\u011fi\u015fken katsay\u0131lar\u0131, a\u011f\u0131rla\u0131klar\u0131\nloj_model.coef_","283ccda3":"# y nin tahmin edilen de\u011ferleri, \n# bu ki\u015filer \u015feker hastal\u0131\u011f\u0131 var m\u0131 yok mu? tahminleri alal\u0131m.\nloj_model.predict(X)[0:5]","b646e31e":"# y nin ger\u00e7ek de\u011ferleri \ny[:10]","9a312562":"# kurmu\u015f oldu\u011fumuz modelin ba\u015far\u0131s\u0131 nedir?\ny_pred =loj_model.predict(X)","946ca197":"# karma\u015f\u0131kl\u0131k matrisi ile hatam\u0131z\u0131 de\u011ferlendirelim mi?\nconfusion_matrix(y, y_pred)","181e2f24":"# ba\u015far\u0131 oran\u0131 1 e yakla\u015ft\u0131k\u00e7a ba\u015far\u0131 oran\u0131 art\u0131yor.\n# ger\u00e7ek de\u011fer ile tahmin edilen de\u011fer aras\u0131nda nas\u0131l bir ili\u015fki var\naccuracy_score(y, y_pred)","8799698c":"# kesinlik alma, daha detayl\u0131 rapor.\nprint(classification_report(y, y_pred))","a75fa86b":"loj_model.predict(X)[0:10]","75cbe8bb":"# s\u0131n\u0131f olas\u0131l\u0131klar\u0131n\u0131 nas\u0131l \u00f6\u011frenebilirism?\n# ileri d\u00fczey\n# iki s\u0131n\u0131f i\u00e7indeki olasl\u0131klar, e\u015fik de\u011ferine g\u00f6re d\u00f6n\u00fc\u015ft\u00fcryo\nloj_model.predict_proba(X)[0:10]","f55c7c0e":"# roc e\u011frisi, e\u011fri alt\u0131ndaki alan art\u0131k\u00e7a model ba\u015far\u0131s\u0131 y\u00fcksekti\n# train hatas\u0131 hesaplad\u0131k.\nlogit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n\nfpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc) # legendleri yans\u0131tma\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0]) # eksen ayarlanmas\u0131\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Oran\u0131')\nplt.ylabel('True Positive Oran\u0131')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","2aed5f7f":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size = 0.30,\n                                                    random_state = 42)","6012b78f":"loj_model = LogisticRegression(solver = \"liblinear\").fit(X_train,y_train) # model nesnesi\nloj_model.get_params()","ee76407d":"# test hatas\u0131 de\u011feri( test setinin ger\u00e7ek de\u011feri, tahmin de\u011ferleri )\n# skor ne kadar b\u00fcy\u00fckse ba\u015far\u0131m\u0131z o kadar y\u00fcksek\ny_pred = loj_model.predict(X_test) # model fit \u00e7al\u0131\u015ft\u0131rma\nprint(accuracy_score(y_test, y_pred))\n\n","4ba2ca35":"# model do\u011frulama\n# k katl\u0131 model do\u011frulama\n# test hatas\u0131\ncross_val_score(loj_model, X_test, y_test, cv = 5).mean()","eb4eeae9":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                   test_size=0.30,\n                                                    random_state=42)\n#random state, veri setini belli \u015fekle g\u00f6re b\u00f6lmek","fee60bf7":"df.head()","6cd30660":"knn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model.get_params()","d18f4c93":"y_pred = knn_model.predict(X_test)","91afded3":"# (y nin ger\u00e7ek de\u011ferleri, ynin tahmini de\u011ferlerri)\n# y\u00fcz hastadan 68 sekizini ba\u015far\u0131l\u0131 \u015fekilde s\u0131n\u0131fland\u0131rm\u0131\u015f\n# bir ki\u015fi hasta ise do\u011fru hastad\u0131r demi\u015f\naccuracy_score(y_test, y_pred)","57c62de0":"print(classification_report(y_test, y_pred))","1cbbc0d3":"np.arange(1,50)","6b915a90":"# aramak i\u00e7in ilgili parametre de\u011ferlerini girmek\n#\nknn_params = {\"n_neighbors\": np.arange(1,50)}","5be01e30":"knn = KNeighborsClassifier()\n#( model nesnesi, aranaccak olan paramtr, )\nknn_cv_model = GridSearchCV(knn, knn_params, cv=10).fit(X_train, y_train)","a2d2f928":"knn_cv_model.best_score_\nprint(\"En iyi skor:\" + str(knn_cv_model.best_score_))","7b1eb010":"# en iyi kom\u015fu say\u0131s\u0131 nedir?\nknn_cv_model.best_params_","d00b829b":"print(\"En iyi skor:\" + str(knn_cv_model.best_score_))\nprint(\"En iyi parametreler: \" + str(knn_cv_model.best_params_))","4a7fe9e6":"# final modeli\nknn = KNeighborsClassifier(11)\nknn_tuned = knn.fit(X_train, y_train)","977e2314":"# ba\u015far\u0131 skoru hesaplama n\u0131n ba\u015fka bir yolu.\nknn_tuned.score(X_test, y_test)","2d17bf6a":"y_pred = knn_tuned.predict(X_test)","707594c0":"accuracy_score(y_test, y_pred)\n# ba\u015far\u0131m\u0131z 68 den 73 e \u00e7\u0131kt\u0131, ba\u015far\u0131m\u0131z y\u00fckseldi","56e8c7da":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","a80b6a85":"# do\u011frusal modeli g\u00f6rmek i\u00e7in kernel, do\u011frusal ayr\u0131m yapl\u0131yor\nsvm_model = SVC(kernel = \"linear\").fit(X_train, y_train)","cea9fbb2":"svm_model.get_params()","24f63fb3":"\ny_pred = svm_model.predict(X_test)","d3813253":"#ilkel test hatas\u0131\naccuracy_score(y_test, y_pred)","2612554e":"svm_model.get_params()","9e92d308":"# bo\u015f model nesnesi olu\u015fturmak\nsvm = SVC()","e2fd7e5b":"# radial base function\n\nsvm_params = {\"C\": np.arange(1,10), \"kernel\": [\"linear\", \"rbf\"]}\n\nsmv_cv_model = GridSearchCV(svm,svm_params,\n                            cv = 10,\n                            n_jobs = -1,\n                            verbose = 2 )\n\nsmv_cv_model.fit(X_train, y_train)","b514c705":"print(\"En iyi score: \" + str(smv_cv_model.best_score_))","291ca29b":"print(\"En iyi parametreler: \" + str(smv_cv_model.best_params_))","713903c7":"# final model\nsvm_tuned = SVC( C= 2, kernel = \"linear\").fit(X_train, y_train)","9855693c":"y_pred = svm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","53ead250":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","404f0b49":"from sklearn.neural_network import MLPClassifier","0f188283":"# multi layer perceptron clasification\nmlpc= MLPClassifier().fit(X_train, y_train)","3495e19c":"# ilke test hatas\u0131\n\ny_pred = mlpc.predict(X_test)\naccuracy_score(y_test, y_pred)","a22b6c27":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\nscaler.fit(X_test)\nX_test = scaler.transform(X_test)","9f4a04aa":"mlpc.get_params()","8676f150":"\nmlpc_params = {\"alpha\": [1,5,0.1, 0.01, 0.03, 0.005, 0.0001,0.00001],\n              \"hidden_layer_sizes\": [(10,10),\n                                     (100,100,100),\n                                     (100,100),\n                                     (3,5)],\n              \"solver\" : [\"lbfgs\"]}","c8fcf3ff":"mlpc = MLPClassifier()\nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params,\n                         cv = 10,\n                         n_jobs = -1,\n                         verbose = 2)\n\nmlpc_cv_model.fit(X_train, y_train)","7c5ae0be":"print(\"En iyi parametreler: \" + str(mlpc_cv_model.best_params_))","11f4a88e":"mlpc_tuned = MLPClassifier(activation = \"logistic\",\n                           alpha = 5,\n                           hidden_layer_sizes = (3,5),\n                          solver = \"adam\")","7c8b3ae9":"mlpc_tuned.fit(X_train, y_train)","c17ba23f":"y_pred = mlpc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","1795408c":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","fe230b07":"from sklearn.tree import DecisionTreeClassifier","f067d9dd":"cart = DecisionTreeClassifier()\ncart_model = cart.fit(X_train, y_train)","92af3d58":"cart_model.get_params()","069c3be3":"y_pred =cart_model.predict(X_test)\naccuracy_score(y_test,y_pred)","2cb4b186":"#!pip install skompiler\nfrom skompiler import skompile\nprint(skompile(cart_model.predict).to(\"python\/code\"))","149a8ea7":"cart_model.get_params()","282a1229":"?cart_model","7ca8f490":"cart_grid = {\"max_depth\": [1,3,5,8,10],\n            \"min_samples_split\" : [1,3,5,8,10,20,50]}","2be8f982":"cart = DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart, cart_grid, cv = 10,\n                       n_jobs = -1,\n                       verbose = 2)\ncart_cv_model = cart_cv.fit(X_train, y_train)","6e334396":"print(\"En iyi parametreler: \" + str(cart_cv_model.best_params_))","beb6c560":"#finalmodeli","d865578d":"cart =DecisionTreeClassifier(max_depth = 5, min_samples_split = 20)\ncart_tuned = cart.fit(X_train, y_train)","33059c35":"y_pred = cart_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","4e5f45e0":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","71031455":"from sklearn.ensemble import RandomForestClassifier","c9ec54f8":"rf_model = RandomForestClassifier().fit(X_train, y_train)","506c9286":"rf_model.get_params()","ffe6ede8":"y_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","007468cd":"rf_model.get_params()","b06654ec":"?rf_model","fa34c876":"rf_params = {\"max_features\": [3,5,7,8],\n            \"n_estimators\": [100,200,500,1000],\n            \"min_samples_split\": [2,5,10,20]}","11445e43":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model,\n                           rf_params,\n                           cv = 10,\n                           n_jobs = -1,\n                           verbose = 2)","e8afb300":"rf_cv_model.fit(X_train, y_train)","4607a7ee":"print(\"En iyi parametreler: \" + str(rf_cv_model.best_params_))","9e6bd98a":"#final","dab5bfcf":"rf_tuned = RandomForestClassifier( max_features = 7,\n                                  min_samples_split = 2,\n                                  n_estimators = 100)\n\nrf_tuned.fit(X_train, y_train)","2c79a97e":"# tuned edilmi\u015f test hats\u0131n\u0131 bulma\ny_pred = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","72f9cb63":"rf_tuned.feature_importances_","7853605b":"# de\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n                         index = X_train.columns).sort_values(ascending = False)\nsns.barplot(x=feature_imp, y=feature_imp.index)\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem Skorlar\u0131\")\nplt.xlabel(\"De\u011fi\u015fkenler\")\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.show()","7252cd32":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","7644e6da":"from sklearn.ensemble import GradientBoostingClassifier","a4e7180a":"gbm_model = GradientBoostingClassifier().fit(X_train, y_train)","03c3e17f":"y_pred = gbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","a1b5b072":"gbm_model.get_params()","55124d36":"?gbm_model","2cd2aa4e":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,300,500,1000],\n             \"max_depth\": [2,3,5,8]}","10c7ec3c":"gbm = GradientBoostingClassifier()\n\ngbm_cv_model= GridSearchCV(gbm, gbm_params, cv = 10,\n                      n_jobs = -1, verbose = 2)","e533daaa":"gbm_cv_model.fit(X_train, y_train)","01e88d2e":"print(\"En iyi parametreler: \" + str(gbm_cv_model .best_params_))","fbd5f6d4":"gbm = GradientBoostingClassifier(learning_rate = 0.01,\n                                 max_depth = 5,\n                                n_estimators = 500)","e63df772":"gbm_tuned =  gbm.fit(X_train,y_train)","6e3ecefb":"y_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","5aeeed07":"# de\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n                         index = X_train.columns).sort_values(ascending = False)\nsns.barplot(x=feature_imp, y=feature_imp.index)\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem Skorlar\u0131\")\nplt.xlabel(\"De\u011fi\u015fkenler\")\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.show()","f366bcf5":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","6c58f4df":"#!pip install xgboost\nfrom xgboost import XGBClassifier","3136c198":"xgb_model = XGBClassifier().fit(X_train, y_train)","b1aa8493":"xgb_model.get_params()","44806b6a":"y_pred = xgb_model.predict(X_test)\naccuracy_score(y_test, y_pred)","327607d1":"xgb_model","39823362":"?xgb_model","224f0a03":"xgb_params = {\n        'n_estimators': [100, 500, 1000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 5,7],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        }","3a6e0dab":"xgb = XGBClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10,\n                            n_jobs = -1, verbose = 2)","7a3a5f5c":"xgb_cv_model.fit(X_train, y_train)","42318130":"xgb_cv_model.best_params_","e59a29fb":"xgb = XGBClassifier(learning_rate = 0.01,\n                    max_depth = 6,\n                    min_samples_split = 2,\n                    n_estimators = 100,\n                    subsample = 0.8)","5a4aecb5":"xgb_tuned =  xgb.fit(X_train,y_train)","a770092f":"y_pred = xgb_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","9e950bc2":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","1eb5f2ee":"#!conda install -c conda-forge lightgbm\nfrom lightgbm import LGBMClassifier","7f24f719":"lgbm_model = LGBMClassifier().fit(X_train, y_train)","d9fe1162":"y_pred = lgbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","5b4b9b43":"## Model Tuning","6b30de1c":"lgbm_model","b595e195":"?lgbm_model","443a00c1":"lgbm_params = {\n        'n_estimators': [100, 500, 1000, 2000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_child_samples\": [5,10,20]}","c8f01ef9":"lgbm = LGBMClassifier()\n\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_params,\n                             cv = 10,\n                             n_jobs = -1,\n                             verbose = 2)","24f6f3d7":"lgbm_cv_model.fit(X_train, y_train)","c0f7b5e7":"lgbm_cv_model.best_params_","8a966e93":"lgbm = LGBMClassifier(learning_rate = 0.01,\n                       max_depth = 3,\n                       subsample = 0.6,\n                       n_estimators = 500,\n                       min_child_samples = 20)","aa98970d":"lgbm_tuned = lgbm.fit(X_train,y_train)","38932eb0":"y_pred = lgbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","249e2424":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\n#X = df[\"Pregnancies\"]\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.30,\n                                                    random_state=42)","905b1f09":"#!pip install catboost\nfrom catboost import CatBoostClassifier\n# https:\/\/catboost.ai\/","8df25fb3":"cat_model = CatBoostClassifier().fit(X_train, y_train)","58618a29":"y_pred = cat_model.predict(X_test)\naccuracy_score(y_test, y_pred)","fb2c6257":"catb_params = {\n    'iterations': [200,500],\n    'learning_rate': [0.01,0.05, 0.1],\n    'depth': [3,5,8] }","a6afae97":"catb = CatBoostClassifier()\ncatb_cv_model = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1, verbose = 2)\ncatb_cv_model.fit(X_train, y_train)\ncatb_cv_model.best_params_","8f7564f2":"catb_cv_model.best_params_","c9ae6623":"catb = CatBoostClassifier(iterations = 200,\n                          learning_rate = 0.05,\n                          depth = 5)\n\ncatb_tuned = catb.fit(X_train, y_train)\ny_pred = catb_tuned.predict(X_test)","64572455":"y_pred = catb_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","79f3b6d7":"modeller = [\n    knn_tuned,\n    loj_model,\n    svc_tuned,\n    nb_model,\n    mlpc_tuned,\n    cart_tuned,\n    rf_tuned,\n    gbm_tuned,\n    catb_tuned,\n    lgbm_tuned,\n    xgb_tuned\n\n]\n\n\nfor model in modeller:\n    isimler = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    dogruluk = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(isimler + \":\" )\n    print(\"Accuracy: {:.4%}\".format(dogruluk))","487a0360":"sonuc = []\n\nsonuclar = pd.DataFrame(columns= [\"Modeller\",\"Accuracy\"])\n\nfor model in modeller:\n    isimler = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    dogruluk = accuracy_score(y_test, y_pred)\n    sonuc = pd.DataFrame([[isimler, dogruluk*100]], columns= [\"Modeller\",\"Accuracy\"])\n    sonuclar = sonuclar.append(sonuc)\n\n\nsns.barplot(x= 'Accuracy', y = 'Modeller', data=sonuclar, color=\"r\")\nplt.xlabel('Accuracy %')\nplt.title('Modellerin Do\u011fruluk Oranlar\u0131');","cd17e086":"## 9.SVM Model & Tahmin","d346d77f":"#### 19.Model Tuning","dba51c62":"## Model & Tahmin","2c703077":"# Veri Seti Hikayesi ve Problem: \u015eeker Hastala\u011f\u0131 Tahmini Lojistik Regresyon","fce0402b":"# CatBoost","bc4dc01f":"## 10. SVM Model Tuning","6d2c725a":"### statsmodels","16d9d227":"### 13. yapay sinir a\u011flar\u0131 Model Tuning","793ce2ba":"# CART","95f3c26e":"# 1.3 Model & tahmin","dbaa2f56":"# 23., 24. XGBoost","46441c9d":"## 12.Model & Tahmin","407348cc":"# 401 Makine \u00d6\u011frenmesi\n## S\u0131n\u0131fland\u0131rma Problemleri","22f32b4a":"## 31.Model Tuning","79406797":"## Model & Tahmin","8164dc91":"Birka\u00e7 Soru\n\n1. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2) \n    * Verilen kodda belirtilen X verisi 500 g\u00f6zlemden olu\u015fmaktad\u0131r. Buna g\u00f6re y_test verisi ka\u00e7 g\u00f6zleme sahiptir?\n2. A\u015fa\u011f\u0131dakilerden hangisi Gradient Boosting Machines s\u0131n\u0131fland\u0131rma modeli tune edilirken kullan\u0131lan hiper parametrelerden biri de\u011fildir?\n    1. n_estimators\n    1. subsample\n    1. max_depth\n    1. learning_rate\n    1. best_params_\n\n3. **Yapay Sinir A\u011flar\u0131 modellemesi yap\u0131l\u0131rken, a\u011f\u0131rl\u0131k optimizasyonu i\u00e7in \u00f6n tan\u0131ml\u0131 olarak b\u00fcy\u00fck veri setlerinde iyi \u00e7al\u0131\u015ft\u0131\u011f\u0131 bilinen \"adam\" algoritmas\u0131 kullan\u0131l\u0131r.** \nA\u015fa\u011f\u0131daki ifadelerden hangisi k\u00fc\u00e7\u00fck veri setlerinde a\u011f\u0131rl\u0131k optimizasyonu i\u00e7in kullan\u0131labilecek olan y\u00f6ntemdir. \n    1. sgd\n    1. lbfgs\n    1. diederik\n    1. jimmy\n    1. logistic\n4. A\u015fa\u011f\u0131dakilerden hangisi s\u0131n\u0131fland\u0131rma modellerinden biri de\u011fildir?\n    1. Lojistik Regresyon\n    1. \u00c7oklu Do\u011frusal Regresyon Modeli\n    1. Destek Vekt\u00f6r Makineleri\n    1. CART\n    1. XGBoost\n\n5. Verilen parametre de\u011ferlerinin olas\u0131 t\u00fcm kombinasyonlar\u0131n\u0131 deneyerek en iyi skoru veren parametreyi se\u00e7en fonksiyondur.  \n    * Yukar\u0131da a\u00e7\u0131klamas\u0131 verilen ve model tune etme i\u015fleminde kullan\u0131lan fonksiyon hangisidir? \n    1. GridSearchCV \n    1. CrossValidation \n    1. MeanAll \n    1. SearchAll \n    1. 5KCV\n6. CART modeli i\u00e7in ayarlanmas\u0131 gereken hiper parametrelerden birisi olan \"**min_samples_split**\" hiper parametresi hangi de\u011feri alamaz? \n    1. 1,2,10,100,501\n7. **Tahmin edilecek g\u00f6zleme en yak\u0131n k adet g\u00f6zlem ele al\u0131n\u0131r. Bu g\u00f6zlemlerin y (ba\u011f\u0131ml\u0131 de\u011fi\u015fken) de\u011ferlerine bak\u0131l\u0131r. Bu y de\u011ferlerinden en \u00e7ok tekrar eden s\u0131n\u0131f de\u011feri tahmin sonucu olarak se\u00e7ilir.**\n\n    **Yukar\u0131da \u00e7al\u0131\u015fma prensibi ifade edilen algoritma hangisidir?**\n    \n8. A\u015fa\u011f\u0131dakilerden hangisi Random Forests s\u0131n\u0131fland\u0131rma modelinin a\u011fa\u00e7 say\u0131s\u0131n\u0131 ifade eden hiper parametresidir?\n    1. max_features\n    1. n_estimators\n    1. min_samples_split\n    1. bootstrap\n    1. max_leaf_nodes \n    \n9. **loj_model.intercept_**\n    **Lojistik regresyon modelini ifade eden \"loj_model\" nesnesi ile kullan\u0131lm\u0131\u015f olan \"intercept_\" metodu hangi bilgiyi sunmaktad\u0131r?**\n    1. Modelin t\u00fcm parametre adlar\u0131 \n    1. Modelin tahmin ba\u015far\u0131s\u0131n\u0131n y\u00fczdeli\u011fi \n    1. Model denkleminin katsay\u0131lar\u0131 \n    1. Model denkleminin sabit say\u0131s\u0131 \n    1. Modelin e\u011fitilip e\u011fitilmedi\u011fi bilgisi\n    \n10. Amac\u0131 iki s\u0131n\u0131f aras\u0131ndaki ay\u0131r\u0131m\u0131n optimum olmas\u0131n\u0131 sa\u011flayacak hiper-d\u00fczlemi bulmak olan modelleme tekni\u011fi hangisidir?\n\n\n    1. I. Adaboost\u2019un s\u0131n\u0131fland\u0131rma ve regresyon problemlerine kolayca uyarlanabilen genelle\u015ftirilmi\u015f versiyonudur\n    1. II. Art\u0131klar \u00fczerine tek bir tahminsel model formunda olan modeller serisi kurulur\n    1. III. Friedman 2001\u2019de ortaya koymu\u015ftur\n11. **Yukar\u0131da \u00f6zellikleri verilen model hangisidir?**\n12. LightGBM hangi modelin e\u011fitim s\u00fcresi ve tahmin performans\u0131n\u0131 art\u0131rmaya y\u00f6nelik geli\u015ftirilen bir modeldir?\n13. XGBoost s\u0131n\u0131fland\u0131rma modeli i\u00e7in kullan\u0131lan fonksiyon hangisidir?\n    1. XGBoostClassifier\n    1. xgboost_classifier\n    1. XGBoostClassification\n    1. xGBClassifierXGBClassifier\n\n\n14. A\u015fa\u011f\u0131dakilerden hangisi Yapay Sinir A\u011flar\u0131 modellemesi i\u00e7in kullan\u0131lan isimlerden biri de\u011fildir?\n    1. Deep Learning \n    1. \u00c7ok Katmanl\u0131 Alg\u0131lay\u0131c\u0131lar \n    1. TensorFlow\n    1. Derin \u00d6\u011frenme \n    1. Neural Network\n    \n15. Jupiter notebook \u00fczerinde XGBoost modellemesi yapabilmek i\u00e7in d\u0131\u015f kaynaktan ilgili k\u00fct\u00fcphanenin indirilmesi gereklidir. Hangisi bu i\u015flemi yapan koddur?\n    1. from sklearn install xgboost\n    1. install xgboost\n    1. !pip install xgboost\n    1. !pip install XGBoost\n    1. install XGBoost\n16. S\u0131n\u0131fland\u0131rma problemleri i\u00e7in Destek Vekt\u00f6r Makineleri modelini kullanmak ad\u0131na hangi kod \u00e7al\u0131\u015ft\u0131r\u0131lmal\u0131d\u0131r?\n\n\n17. Hangi model tarih olarak en son geli\u015ftirilmi\u015ftir?\n    1. Lojistik Regresyon \n    1. \u00c7oklu Do\u011frusal Regresyon Modeli \n    1. Destek Vekt\u00f6r Makineleri \n    1. CART \n    1. XGBoost\n    \n18. A\u015fa\u011f\u0131dakilerden hangisi LightGBM model nesnesini import i\u015flemini yapan koddur?\n    1. from lightgbm import LGBMClassifier\n    1. from light_gbm import LGBM_Classifier from LightGbm\n    1. import LGBM_Classifier from lightgbm import \n    1. LGBMClassification from lightGBM import \n    1. LGBMClassificaation\n19. **Ayn\u0131 veri seti farkl\u0131 iki bilgisayar \u00fczerinde modelleme yapmak \u00fczere ele al\u0131n\u0131yor. Test-Train ayr\u0131m\u0131n\u0131n iki bilgisayarda da ayn\u0131 g\u00f6zlemlerden olu\u015fmas\u0131 i\u00e7in ne yap\u0131lmas\u0131 gerekir?**\n    1. E\u015fde\u011fer kodlar yerine tamamen ayn\u0131 kodlar kullan\u0131lmal\u0131d\u0131r \n    1. Kodlar\u0131n s\u0131ralamas\u0131 ayn\u0131 olmal\u0131d\u0131r \n    1. T\u00fcm i\u015flemler ayn\u0131 anda yap\u0131lmal\u0131d\u0131r \n    1. Train-Test ay\u0131rma fonksiyonunun random_state arg\u00fcman\u0131na ''positive'' yaz\u0131lmal\u0131d\u0131r \n    1. Train-Test ay\u0131rma fonksiyonunun random_state arg\u00fcman\u0131na ayn\u0131 say\u0131 yaz\u0131lmal\u0131d\u0131r\n20. **\u00c7oklu do\u011frusal regresyonun ufak farkl\u0131l\u0131klara tabi tutulup s\u0131n\u0131fland\u0131rma problemlerine uyarlanm\u0131\u015f bir versiyonudur. Yukarda bir \u00f6zelli\u011fi verilen model hangisidir?** \n    1. Basit Do\u011frusal Regresyon \n    1. Destek Vekt\u00f6r Makineleri \n    1. Lojistik Regresyon \n    1. Random Forests \n    1. Gradient Boosting Machines\n21. **Random Forests s\u0131n\u0131fland\u0131rma modeli i\u00e7in kullan\u0131lan fonksiyon hangisidir?** \n    1. Random_Forest_Classifier() \n    1. random_forest_classifier() \n    1. RandomForestClassifier() \n    1. Random_Forest_C() \n    1. RandomForestClassification()\n22. **Yapay sinir a\u011flar\u0131 modellemesinde s\u0131n\u0131fland\u0131rma yaparken regresyondan farkl\u0131 olarak fonksiyonel yap\u0131da a\u015fa\u011f\u0131dakilerden hangisinde de\u011fi\u015fiklik olur?** \n    1. Aktivasyon fonksiyonu \n    1. Katman yap\u0131s\u0131 \n    1. H\u00fccrelerin birbiri ile ba\u011flant\u0131s\u0131\n    1. Fonksiyona ait arg\u00fcman say\u0131s\u0131 \u00e7ok daha fazlad\u0131r \n    1. Ba\u015far\u0131 nazaran olduk\u00e7a d\u00fc\u015fer\n\n\n23. A\u015fa\u011f\u0131dakilerden hangisi 'ilkel model' olarak d\u00fc\u015f\u00fcn\u00fclebilir? \n    1. Tek de\u011fi\u015fkenli model \n    1. Tek parametreli model \n    1. Modelin e\u011fitilmemi\u015f hali \n    1. Tune edilmesi gereken hiper parametreleri oldu\u011fu halde tune edilmemi\u015f model \n    1. Model nesnesine verilen ad\n\n24. accuracy_score(data_test, data_pred)\n    * Yukar\u0131da verilen sklearn.metrics k\u00fct\u00fcphanesine ait olan fonksiyon hangi bilgiyi verir? \n    1. Model ba\u015far\u0131 skorunu verir \n    1. Tune edilmemi\u015f modelin, tune edilebilirlik skorunu verir \n    1. Girilen iki veri kullan\u0131larak model tekrar e\u011fitilir \n    1. Tune edilmemi\u015f modelin, tune edilmi\u015f hali aras\u0131ndaki a\u00e7\u0131klanabilirlik y\u00fczdesini verir \n    1. Denenen hiperparametrelerin aras\u0131ndaki skoru verir\n\n\n\n     I. Amac\u0131 veri seti i\u00e7erisindeki karma\u015f\u0131k yap\u0131lar\u0131 basit karar yap\u0131lar\u0131na d\u00f6n\u00fc\u015ft\u00fcrmek\n     II. Heterojen veri setleri, homojen alt guruplara ayr\u0131l\u0131r\n     III. Breiman 1984\u2019de bulmu\u015ftur\n\n25. Yukar\u0131da \u00f6zellikleri verilen model hangisidir?\n    1. Yapay Sinir A\u011flar\u0131 \n    1. Destek Vekt\u00f6r Makineleri\n    1. CART \n    1. K-En Yak\u0131n Kom\u015fu \n    1. Random Forests","247c4fac":"## 7.Model Tuning","befb374b":"# 32. T\u00fcm Modellerin Kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131","86c635c7":"### 16. Model Tuning","43416bc9":"# 20., 21. Gradient Boosting Machines","10639496":"![image.png](attachment:3ca509db-e6cc-42cc-9876-049ca716a0b6.png) ","156ea4df":"## 25. xboost Model Tuning","f230a954":"## Model & Tahmin","70dcaadf":"# 17., 18. Random Forests","bc98b3c0":"![image.png](attachment:50e8ff7e-81a0-47ad-a1ab-fe8e4786473e.png)\n\n![image.png](attachment:44956653-7784-416e-9541-87f31f0344e9.png)\n\n![image.png](attachment:66cf3285-fcdd-47ee-8889-e4ab9e3f681f.png)\n\n![image.png](attachment:28dbbe04-c2db-43d5-8831-999ad0ffa901.png)","3cd4f948":"# 26., 27. LightGBM","d52749ad":"# 41.4. lojistik model tuning (model do\u011frulama)","229e2798":"# 8. Destek vekt\u00f6r makineleri, Suppport vektor\n# SVM","fd05212b":"### 22.Model Tuning","215af763":"# 11.Yapay Sinir A\u011flar\u0131 (\u00c7ok katmanl\u0131 alg\u0131lay\u0131c\u0131lar)","685426bc":"# 42.1. K-En yak\u0131n kom\u015fu KNN\n![image.png](attachment:d9e830bf-0f87-401d-8cc6-2a9d4d295f90.png)\n\n![image.png](attachment:62f78036-ffb3-4c18-ad95-924454745ab0.png)\n\n![image.png](attachment:fbc2417c-c43f-47cd-a074-d66a6375b559.png)"}}