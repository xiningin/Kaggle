{"cell_type":{"9c682cee":"code","b2e3b992":"code","7f6f3097":"code","da132f5a":"code","3a8321ca":"code","cc6a4a98":"code","bd5ee283":"code","20e133bc":"code","42159f00":"code","531ad5d5":"code","e027e415":"code","ec4f6e4a":"code","c8e804a5":"code","360dea28":"code","d735a948":"code","8d5fd34f":"code","d17d6a90":"code","987f53b0":"code","2309fc49":"code","4a568179":"code","e0ba4883":"code","5575a984":"code","bd1157de":"code","01d75c4e":"code","b676e973":"code","11dd9af6":"code","2c26faa7":"code","ec83cb8a":"code","ad9ea75c":"code","245ef3e1":"code","80dab8fa":"code","99b67eb2":"code","a0992328":"code","9deb4ed1":"code","27d6f865":"code","33056ce1":"code","25aa370b":"code","6183f865":"code","b8cc0306":"code","3f518bfb":"code","be1b9aa9":"code","ed977869":"code","37787473":"code","854bf254":"code","15913ed4":"code","4ca40981":"code","d63b2589":"code","3bb55fcd":"code","7b78ae8c":"markdown","445ca3a9":"markdown","01a5e261":"markdown","22bd7323":"markdown","02596e5c":"markdown","d360469b":"markdown","bb01232b":"markdown","9e35c7d6":"markdown","7199586c":"markdown","f911e782":"markdown","58ee46c8":"markdown","67081de9":"markdown","1c8c6691":"markdown","1a70bff1":"markdown"},"source":{"9c682cee":"import fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.vision.gan import *","b2e3b992":"path = untar_data(URLs.PETS)\npath_hr = path\/'images'\npath_lr = path\/'crappy'","7f6f3097":"from PIL import Image, ImageDraw, ImageFont","da132f5a":"def crappify(fn,i):\n    dest = path_lr\/fn.relative_to(path_hr)\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    img = PIL.Image.open(fn)\n    targ_sz = resize_to(img, 96, use_min=True)\n    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n    w,h = img.size\n    q = random.randint(10,70)\n    ImageDraw.Draw(img).text((random.randint(0,w\/\/2),random.randint(0,h\/\/2)), str(q), fill=(255,255,255))\n    img.save(dest, quality=q)","3a8321ca":"il = ImageItemList.from_folder(path_hr)\nparallel(crappify, il.items)","cc6a4a98":"bs,size=32, 128\n# bs,size = 24,160\n#bs,size = 8,256\narch = models.resnet34","bd5ee283":"arch = models.resnet34\nsrc = ImageImageList.from_folder(path_lr).random_split_by_pct(0.1, seed=42)","20e133bc":"def get_data(bs,size):\n    data = (src.label_from_func(lambda x: path_hr\/x.name)\n           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n           .databunch(bs=bs, num_workers=0).normalize(imagenet_stats, do_y=True))\n\n    data.c = 3\n    return data","42159f00":"data_gen = get_data(bs,size)","531ad5d5":"data_gen.show_batch(4)","e027e415":"wd = 1e-3","ec4f6e4a":"y_range = (-3.,3.)","c8e804a5":"loss_gen = MSELossFlat()","360dea28":"def create_gen_learner():\n    return unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Weight,\n                         self_attention=True, y_range=y_range, loss_func=loss_gen)","d735a948":"learn_gen = create_gen_learner()","8d5fd34f":"learn_gen.fit_one_cycle(2, pct_start=0.8)","d17d6a90":"learn_gen.unfreeze()","987f53b0":"learn_gen.fit_one_cycle(3, slice(1e-6,1e-3))","2309fc49":"learn_gen.show_results(rows=4)","4a568179":"learn_gen.save('gen-pre2')","e0ba4883":"learn_gen.load('gen-pre2');","5575a984":"name_gen = 'image_gen'\npath_gen = path\/name_gen","bd1157de":"# shutil.rmtree(path_gen)","01d75c4e":"path_gen.mkdir(exist_ok=True)","b676e973":"def save_preds(dl):\n    i=0\n    names = dl.dataset.items\n    \n    for b in dl:\n        preds = learn_gen.pred_batch(batch=b, reconstruct=True)\n        for o in preds:\n            o.save(path_gen\/names[i].name)\n            i += 1","11dd9af6":"save_preds(data_gen.fix_dl)","2c26faa7":"PIL.Image.open(path_gen.ls()[0])","ec83cb8a":"learn_gen=None\ngc.collect()","ad9ea75c":"def get_crit_data(classes, bs, size):\n    src = ImageItemList.from_folder(path, include=classes).random_split_by_pct(0.1, seed=42)\n    ll = src.label_from_folder(classes=classes)\n    data = (ll.transform(get_transforms(max_zoom=2.), size=size)\n           .databunch(bs=bs).normalize(imagenet_stats))\n    data.c = 3\n    return data","245ef3e1":"data_crit = get_crit_data([name_gen, 'images'], bs=bs, size=size)","80dab8fa":"data_crit.show_batch(rows=3, ds_type=DatasetType.Train, imgsize=3)","99b67eb2":"loss_critic = AdaptiveLoss(nn.BCEWithLogitsLoss())","a0992328":"def create_critic_learner(data, metrics):\n    return Learner(data, gan_critic(), metrics=metrics, loss_func=loss_critic, wd=wd)","9deb4ed1":"learn_critic = create_critic_learner(data_crit, accuracy_thresh_expand)","27d6f865":"learn_critic.fit_one_cycle(6, 1e-3)","33056ce1":"learn_critic.save('critic-pre2')","25aa370b":"learn_crit=None\nlearn_gen=None\ngc.collect()","6183f865":"data_crit = get_crit_data(['crappy', 'images'], bs=bs, size=size)","b8cc0306":"learn_crit = create_critic_learner(data_crit, metrics=None).load('critic-pre2')","3f518bfb":"learn_gen = create_gen_learner().load('gen-pre2')","be1b9aa9":"switcher = partial(AdaptiveGANSwitcher, critic_thresh=0.65)\nlearn = GANLearner.from_learners(learn_gen, learn_crit, weights_gen=(1.,50.), show_img=False, switcher=switcher,\n                                 opt_func=partial(optim.Adam, betas=(0.,0.99)), wd=wd)\nlearn.callback_fns.append(partial(GANDiscriminativeLR, mult_lr=5.))","ed977869":"lr = 1e-4","37787473":"learn.fit(40,lr)","854bf254":"learn.save('gan-1c')","15913ed4":"learn.data=get_data(16,192)","4ca40981":"learn.fit(10,lr\/2)","d63b2589":"learn.show_results(rows=16)","3bb55fcd":"learn.save('gan-1c')","7b78ae8c":"For gradual resizing we can change the commented line here.","445ca3a9":"Now we'll combine those pretrained model in a GAN.","01a5e261":"To define a GAN Learner, we just have to specify the learner objects foor the generator and the critic. The switcher is a callback that decides when to switch from discriminator to generator and vice versa. Here we do as many iterations of the discriminator as needed to get its loss back < 0.5 then one iteration of the generator.\n\nThe loss of the critic is given by `learn_crit.loss_func`. We take the average of this loss function on the batch of real predictions (target 1) and the batch of fake predicitions (target 0). \n\nThe loss of the generator is weighted sum (weights in `weights_gen`) of `learn_crit.loss_func` on the batch of fake (passed throught the critic to become predictions) with a target of 1, and the `learn_gen.loss_func` applied to the output (batch of fake) and the target (corresponding batch of superres images).","22bd7323":"## Pre-train generator","02596e5c":"## Crappified data","d360469b":"Now let's pretrain the generator.","bb01232b":"Pretrain the critic on crappy vs not crappy.","9e35c7d6":"Uncomment the first time you run this notebook.","7199586c":"## Pretrained GAN","f911e782":"Prepare the input data by crappifying images.","58ee46c8":"## fin","67081de9":"## Train critic","1c8c6691":"## GAN","1a70bff1":"## Save generated images"}}