{"cell_type":{"d2a2e5db":"code","acab7a5c":"code","ddb972e4":"code","128119e1":"code","54faf293":"code","ebf5d656":"code","a9baed93":"code","32ece6aa":"code","ab47628d":"code","4a676263":"code","66f89b53":"code","5e92d3e6":"code","2461e8fc":"code","a0894708":"code","17ed5846":"code","fa664dea":"markdown","c5f3f418":"markdown"},"source":{"d2a2e5db":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior() \nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split","acab7a5c":"########## Can run the following commands to check the devices compatible with tf \n\n\n# from tensorflow.python.client import device_lib\n# device_lib.list_local_devices()\n\n\n########### Loading Dataset :\n# mnist_dataset = tf.keras.datasets.mnist\n# (x_train,y_train),(x_test, y_test) = mnist_dataset.load_data()\n\ntraining_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntesting_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","ddb972e4":"flat_labels = training_data.iloc[:,0].values\nprint(\" Image Labels :  \",flat_labels[0:20])\nimages = training_data.iloc[:,1:].values\nimages = images.astype(np.float32)","128119e1":"plt.imshow(images[6].reshape(28,28))\nplt.show()","54faf293":"# # https:\/\/www.kaggle.com\/bhushan23\/mnist-with-softmax-tensorflow-tutorial\n# class Dataset(object):\n#     def __init__(self, data):\n#         self.rows = len(data.values)\n#         self.images = data.iloc[:,1:].values\n#         self.images = self.images.astype(np.float32)\n#         self.images = np.multiply(self.images, 1.0 \/ 255.0)\n#         self.labels = np.array([np.array([int(i == l) for i in range(10)]) for l in data.iloc[:,0].values]) #one-hot\n#         self.index_in_epoch = 0\n#         self.epoch = 0\n#     def next_batch(self, batch_size):\n#         start = self.index_in_epoch\n#         self.index_in_epoch += batch_size\n#         if self.index_in_epoch > self.rows:\n#             self.epoch += 1\n#             perm = np.arange(self.rows)\n#             np.random.shuffle(perm)\n#             self.images = self.images[perm]\n#             self.labels = self.labels[perm]\n#             #next epoch\n#             start = 0\n#             self.index_in_epoch = batch_size\n#         end = self.index_in_epoch\n#         return self.images[start:end] , self.labels[start:end]\n\none_hot_encoder = OneHotEncoder(sparse = False)\nflat_labels = flat_labels.reshape(len(flat_labels), 1)\nlabels = one_hot_encoder.fit_transform(flat_labels)\nlabels = labels.astype(np.uint8)","ebf5d656":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 0)","a9baed93":"#input tensor \nx = tf.placeholder(tf.float32, [None, 784])   #None basically means it's dynamically changeable\ny_ = tf.placeholder(tf.float32, [None, 10])   #Actual Ys \n\n#variables \n\nW = tf.Variable(tf.zeros([784, 10]))     #weights \nb = tf.Variable(tf.zeros([10]))          #biases \ny = tf.nn.softmax(tf.matmul(x,W) + b)       #y_pred (out)","32ece6aa":"\n#########Defining error \/\/ Loss function\n\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ *tf.log(y), reduction_indices=[1] ))\n\n#############Optimizing algo: \ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n","ab47628d":"# train = Dataset(training_data.iloc[0:37000])\n# training_data.shape","4a676263":"# sess = tf.InteractiveSession()       ## initializing session for nn to compute\n\n# tf.global_variables_initializer().run()  #Pretty self-explanatory \n\n# for _ in range(1000):\n#     batch_x, batch_y = train.next_batch(60)\n#     sess.run(train_step, feed_dict = {x:batch_x, y_:batch_y})\n","66f89b53":"# train_data = Dataset(training_data)\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\nbatch_size = 200\nfor i in range(500):\n    batch_start = ( i * batch_size) % (x_train.shape[0] - batch_size)\n    batch_end = batch_start + batch_size \n    batch_xs = x_train[batch_start:batch_end]\n    batch_ys = y_train[batch_start:batch_end]\n#     batch_xs, batch_ys = train_data.next_batch(500)\n\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})","5e92d3e6":"correct_prediction = tf.equal(tf.argmax(y,1) , tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nprint(sess.run(accuracy, feed_dict={x: x_test, y_: y_test}))","2461e8fc":"test = testing_data.values.astype(np.float32)\ntest = np.multiply(test, 1.0\/255)","a0894708":"pred = sess.run(y, feed_dict={x:test})\npred = [np.argmax(p) for p in pred]\nresult = pd.DataFrame({\n    'ImageId' : range(1,len(pred)+1), \n    'Label' : pred\n})\n\n","17ed5846":"result.to_csv('result.csv', index = False, encoding = 'utf-8')","fa664dea":"* How the images look like:","c5f3f418":"- Train Test Split :"}}