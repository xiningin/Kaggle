{"cell_type":{"5dfe2abe":"code","2851108f":"code","739c50ff":"code","963447a4":"code","80c4cc90":"code","bd1ad970":"code","3a975373":"code","c2767f7d":"code","6e645fcc":"code","78048279":"code","468ca801":"code","d7c5abea":"code","873624c2":"code","8bd5915a":"code","9872261e":"code","3301001b":"code","700a3403":"code","9abfa36d":"code","2f9b03ec":"code","7ee1396a":"code","33097af9":"code","89f6ef8f":"code","2b83c5b8":"code","215c0d30":"code","aaf5719d":"code","4a25d958":"code","31ec3a0b":"code","c8bfc78d":"code","72528ce0":"code","31c87722":"code","7013dd45":"code","c6773ded":"code","6f0df774":"code","d2e609a3":"code","d432494b":"markdown","3c3ff54e":"markdown","3146801a":"markdown","8c3d6bd2":"markdown","3f0b6d1b":"markdown","42d92a96":"markdown","6536a986":"markdown","992eeb26":"markdown","a96c7282":"markdown","0c8ecf58":"markdown","ad737ef3":"markdown","32e0f7a9":"markdown","e013cad9":"markdown","89a8dec7":"markdown","5fceee39":"markdown","2077f082":"markdown","ec86ae45":"markdown","23b3859c":"markdown","d0e71356":"markdown","3e18394d":"markdown","5740d5d5":"markdown","1553c2a0":"markdown","8dc90f35":"markdown"},"source":{"5dfe2abe":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport scipy\nimport gc\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","2851108f":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [180, 180]\nEPOCHS = 25","739c50ff":"ds, info = tfds.load('malaria', split='train', shuffle_files=True, with_info=True)","963447a4":"print(\"Num classes: \" + str(info.features['label'].num_classes))\nprint(\"Class names: \" + str(info.features['label'].names))","80c4cc90":"vis = tfds.visualization.show_examples(ds, info)","bd1ad970":"train_images = []\ntrain_labels = []\n\nfor example in ds:\n    train_images.append(example['image'].numpy())\n    train_labels.append(example['label'].numpy())","3a975373":"train_images = np.array(train_images)\ntrain_labels = np.array(train_labels)","c2767f7d":"print(\"Image:\")\nprint(train_images[0])\nprint(\"Label: \" + str(train_labels[0]))","6e645fcc":"images_flattened = [x.flatten().astype('float64') for x in train_images]","78048279":"img_lengths = []\n\nfor img in images_flattened:\n    img_lengths.append(len(img))","468ca801":"img_lengths = np.array(img_lengths)","d7c5abea":"uninfected_lengths = img_lengths[train_labels]\nparasitized_lengths = img_lengths[train_labels == 0]","873624c2":"scipy.stats.describe(uninfected_lengths)","8bd5915a":"plt.scatter(np.arange(len(uninfected_lengths)), uninfected_lengths)","9872261e":"np.unique(uninfected_lengths)","3301001b":"scipy.stats.describe(parasitized_lengths)","700a3403":"plt.scatter(np.arange(len(parasitized_lengths)), parasitized_lengths)","9abfa36d":"np.unique(parasitized_lengths)","2f9b03ec":"del ds\ndel info\ndel train_images\ndel train_labels\ndel images_flattened\ndel img_lengths\n\ngc.collect()","7ee1396a":"BATCH_SIZE = 32\nIMAGE_SIZE = [200, 200]\n\ntrain_ds, val_ds, test_ds = tfds.load('malaria',\n                                      split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],\n                                      shuffle_files=True, as_supervised=True)","33097af9":"NUM_TRAIN_IMAGES = tf.data.experimental.cardinality(train_ds).numpy()\nprint(\"Num training images: \" + str(NUM_TRAIN_IMAGES))\n\nNUM_VAL_IMAGES = tf.data.experimental.cardinality(val_ds).numpy()\nprint(\"Num validating images: \" + str(NUM_VAL_IMAGES))\n\nNUM_TEST_IMAGES = tf.data.experimental.cardinality(test_ds).numpy()\nprint(\"Num testing images: \" + str(NUM_TEST_IMAGES))","89f6ef8f":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","2b83c5b8":"def convert(image, label):\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  return image, label\n\ndef pad(image,label):\n  image,label = convert(image, label)\n  image = tf.image.resize_with_crop_or_pad(image, 200, 200)\n  return image,label","215c0d30":"padded_train_ds = (\n    train_ds\n    .cache()\n    .map(pad)\n    .batch(BATCH_SIZE)\n) \n\npadded_val_ds = (\n    val_ds\n    .cache()\n    .map(pad)\n    .batch(BATCH_SIZE)\n) ","aaf5719d":"image_batch, label_batch = next(iter(padded_train_ds))\n\ndef show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"uninfected\")\n        else:\n            plt.title(\"parasitized\")\n        plt.axis(\"off\")","4a25d958":"show_batch(image_batch.numpy(), label_batch.numpy())","31ec3a0b":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    \n    return block\n\ndef dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","c8bfc78d":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model","72528ce0":"model = build_model()\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=tf.keras.metrics.AUC(name='auc')\n)","31c87722":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"malaria_model.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,\n                                                     restore_best_weights=True)\n\ndef exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","7013dd45":"history = model.fit(\n    padded_train_ds, epochs=20,\n    validation_data=padded_val_ds,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","c6773ded":"padded_test_ds = (\n     test_ds\n    .cache()\n    .map(pad)\n    .batch(BATCH_SIZE)\n) ","6f0df774":"model.evaluate(padded_test_ds)","d2e609a3":"model.summary()","d432494b":"## Feature extraction\n\nLet's convert our images and labels into numpy arrars for our initial analysis.","3c3ff54e":"## Loading the data\n\nWe'll be using TFDS Malaria dataset for our example. It is quite easy to load the data using TFDS API.","3146801a":"# Introduction and Set-up\n\nTensorFlow Datasets has many datasets that can be loaded and be used to learn more about image classification and various computer vision machine learning pipelines. It is a great way to learn more about TensorFlow and the architecture of computer vision models in general. This tutorial will go over the importance of data exploration as well as all the steps for a image classification machine learning problem.","8c3d6bd2":"We will divide our data into 70:15:15 ratio. We can check that our ratios are correct by checking how many images are in each dataset.","3f0b6d1b":"As we are working on a binary classification problem, we will be using a binary crossentropy loss function. Additionally, this data, luckily, is balanced. This means that half of the images are parasitized and half the images are uninfected. Because we are working with a balanced dataset, we will be using AUC-ROC as our metric. To learn more about AUC-ROC, check out this [resource](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc).","42d92a96":"We have to use `.map()` to apply our padding method to all of our images. While we are at it, we should batch our images.","6536a986":"## Evaluate results\n\nFirst let's preprocess our testing images.","992eeb26":"## Callbacks\n\nWe want to define certain callbacks so that we have the best model without overfitting.\n\nOne of the most important hyperparameters is the learning rate. A learning rate that is too high will prevent the model from converging. Conversely, a learning rate that is too slow will cause the training process to be too long and take up unnecessary resources. We'll be using an exponential decay function to change our learning rate for each epoch.\n\nThe checkpoint and early stopping callback saves the best weights for the model and stops the model once it stops improving. This will slow down overfitting and save time.","a96c7282":"# Initial Exploration\n\nWe will be using the TFDS Malaria dataset. The Malaria dataset is contains a total of 27,558 cell images with equal instances of parasitized and uninfected cells from the thin blood smear slide images of segmented cells. The original data source is from [NIH](https:\/\/lhncbc.nlm.nih.gov\/publication\/pub9932). A big aspect of machine learning is data processing. Feature engineering and normalizing data is important. Correctly formatted data will help the model train better and make better inferences about the data.","0c8ecf58":"Not all the images are of size (200, 200). Thankfully, TensorFlow Image API has a way to resize images by either cropping big pictures or padding smaller ones. Let's define our padding method.","ad737ef3":"We see that for the uninfected images, the length of the flattened image array is either 41745 or 54165. Now let's see the lengths of the parasitized images.","32e0f7a9":"As we see in our visualizations, not all of the images are of the same size. Additionally, our images, and for most computer vision problems, images will be a 3-channel matrix, meaning 3 matrices are stacked on top of each, one for each color of RGB. Sometimes, features of our image like size, length, and shape can be strong correlations with our labels.\n\nLet's evaluate the length of our images.","e013cad9":"## Reshape image input\n\nLet's see the shapes of our images.","89a8dec7":"## Build our model\n\nLet's build our deep CNN. We will be using the TensorFlow Keras API for easy implementation.\n\nWe'll create two blocks, one convolution block and one dense block so we won't have to repeat our code.","5fceee39":"As expected, we have two different classes of images: a \"parasitized\" class and an \"uninfected\" class.","2077f082":"## Visualize the data\n\nLet's use the TFDS API to visualize how our images look like.","ec86ae45":"Now we'll define our model. We want our last layer to be a dense layer with a single node. The closer the value is to 1, the higher likelihood that the image is uninfected. Values closer to 0 indice a higher probability of being parasitized.","23b3859c":"## Visualize padded images","d0e71356":"Let's see our the lengths of the images identified as \"uninfected\" differ from the lengths of the images identifies as \"parasitized\".","3e18394d":"# Model building\n\n## Loading images\n\nWe first want to load our images into three different datasets: a training dataset, a validation dataset, and a training dataset.","5740d5d5":"We see that our model has an AUC-ROC score of . A high AUC-ROC shows that our model works well at differentiating between parasitized and uninfected cells.","1553c2a0":"For the parasitized lengths, we see that images are a wide variety of lengths. For certain models, having a feature that corresponds with the label can be an issue as the model might assume that the length of an image corresponds with its classification. This will make it difficult to generalize the model as not all uninfected blood smear images are of the same size. To help prevent overfitting and to generalize our model, we will preprocess our images before inputing them.\n\nBut first, let's clear some RAM so we don't run out of resources.","8dc90f35":"## Training"}}