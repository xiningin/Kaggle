{"cell_type":{"5fb14871":"code","038b2550":"code","1d23429b":"code","a2111058":"code","2062ac17":"code","ed13939b":"code","e07c9667":"code","e4da6619":"code","d1b6f293":"code","f4fd745f":"code","44351f75":"code","4e26f28e":"code","b85505f3":"code","aff06b5f":"code","9511ad29":"code","3fb82533":"code","4fdaf958":"code","ba01ae89":"code","efa8a996":"code","55d1c0d2":"code","b0002186":"code","d9580b6d":"code","bc101c14":"code","fb87f1e0":"markdown","8774b2ed":"markdown","7d0d9f5f":"markdown","bf73ed6a":"markdown","e523349e":"markdown","06177bcf":"markdown","98d101dc":"markdown","ad6742d2":"markdown","5514864a":"markdown"},"source":{"5fb14871":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/cell_images\/cell_images\/\"))\n\n# Any results you write to the current directory are saved as output.","038b2550":"import torch\nfrom torchvision import transforms, datasets\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","1d23429b":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","a2111058":"#define transfrom to the data\ndata_transform = transforms.Compose(\n       [transforms.Resize((108,108)),\n        transforms.Pad(2),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\n#import photo data \ncell_dataset = datasets.ImageFolder(root='..\/input\/cell_images\/cell_images\/',transform=data_transform)\n\n#define dataloader\ndataset_loader = DataLoader(cell_dataset,batch_size=4, shuffle=True,num_workers=4)\n\nsplit1 = int(0.1 * len(cell_dataset))\nsplit2 = int(0.9 * len(cell_dataset))\nindex_list = list(range(len(cell_dataset)))\nnp.random.shuffle(index_list) \ntest_idx = index_list[:split1]+index_list[split2:]\ntrain_idx=index_list[split1:split2]\n\n## create training and validation sampler objects\ntr_sampler = SubsetRandomSampler(train_idx)\nval_sampler = SubsetRandomSampler(test_idx)\n#trainset=cell_dataset[split1:split2]\n\n## create iterator objects for train and valid datasets\ntrainloader = DataLoader(cell_dataset, batch_size=4,sampler=tr_sampler,num_workers=1)\nvalidloader = DataLoader(cell_dataset, batch_size=4,sampler=val_sampler,num_workers=1)","2062ac17":"# functions to show an image\nclasses=(\"Parasitized\",\"Uninfected\")\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(dataset_loader)\nimages, labels = dataiter.next()\n#encode = autoencoder2(images)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","ed13939b":"#torch.backends.cudnn.benchmark = True","e07c9667":"#torch.backends.cudnn.deterministic = True","e4da6619":"class Net3(nn.Module):\n    def __init__(self):\n        super(Net3, self).__init__()\n        \n        self.conv_layer1=nn.Sequential(\n        nn.Conv2d(3, 16, 3,padding=1,bias=False),\n        nn.BatchNorm2d(16,momentum=0.9),\n        nn.PReLU(),\n        nn.Conv2d(16, 16, 3,padding=1,bias=False),\n        nn.BatchNorm2d(16,momentum=0.9),\n        nn.PReLU(),\n        nn.MaxPool2d(2, 2)\n        )\n        #x.size=16*56*56\n        \n        self.conv_layer2 = nn.Sequential(\n        nn.Conv2d(16, 32, 3,padding=1,bias=False),\n        nn.BatchNorm2d(32,momentum=0.9),\n        nn.PReLU(),\n        nn.Conv2d(32, 32, 3,padding=1,bias=False),\n        nn.PReLU(),\n        nn.Conv2d(32, 32, 3,padding=1,bias=False),\n        nn.BatchNorm2d(32,momentum=0.9),\n        nn.PReLU(),\n        nn.MaxPool2d(2, 2)\n        )\n        #x.size=32*28*28\n        \n        self.conv_layer3 = nn.Sequential(\n        nn.Conv2d(32, 64, 3,padding=1,bias=False),\n        nn.BatchNorm2d(64,momentum=0.9),\n        nn.PReLU(),\n        nn.Conv2d(64, 64, 3,padding=1),\n        nn.PReLU(),\n        nn.Conv2d(64, 64, 3,padding=1,bias=False),\n        nn.BatchNorm2d(64,momentum=0.9),\n        nn.PReLU(),\n        nn.MaxPool2d(2, 2)\n        )\n        #x.size=64*14*14\n        \n        self.conv_layer4 = nn.Sequential(\n        nn.Conv2d(64, 128, 3,padding=1,bias=False),\n        nn.BatchNorm2d(128,momentum=0.9),\n        nn.PReLU(),\n        nn.Conv2d(128, 128, 3,padding=1,bias=False),\n        nn.BatchNorm2d(128,momentum=0.9),\n        nn.PReLU(),\n        nn.MaxPool2d(2, 2)\n        )\n        #x.size=128*7*7\n        \n        self.conv_layer5 = nn.Sequential(\n        nn.Conv2d(128, 256, 3,padding=1,bias=False),\n        nn.BatchNorm2d(256,momentum=0.9),\n        nn.PReLU(),\n        nn.Conv2d(256, 256, 3,padding=1,bias=False),\n        nn.BatchNorm2d(256,momentum=0.9),\n        nn.PReLU(),\n        nn.MaxPool2d(2, 2)\n        )\n        #x.size=256*3*3\n        \n        self.fc_layer = nn.Sequential(\n        nn.Linear(2304,1024),\n        nn.PReLU(),\n        nn.Linear(1024,256),\n        nn.PReLU(),\n        nn.Linear(256,2),\n        nn.Tanhshrink()\n        )\n        \n    def forward(self, x):\n        x = self.conv_layer1(x)\n        x = self.conv_layer2(x)    \n        x = self.conv_layer3(x)\n        x = self.conv_layer4(x)\n        x = self.conv_layer5(x)\n        #print(x.size())\n        x = x.view(-1, 256*3*3)\n        x = self.fc_layer(x)\n        \n        return x","d1b6f293":"def weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n        init.constant_(m.bias, 0.0)\n    elif classname.find('BatchNorm') != -1:\n        init.normal_(m.weight.data, 0, 0.01)\n        init.constant_(m.bias.data, 0.0)","f4fd745f":"from torch.nn import init","44351f75":"net3_2=Net3()\nnet3_2.apply(weights_init_kaiming)\n#send net to GPU and train on it\nnet3_2.to(device)","4e26f28e":"criterion = nn.CrossEntropyLoss()\noptimizer3_1 = optim.Adam(net3_2.parameters(),lr=0.0001,betas=(0.9,0.999),eps=1e-20,weight_decay=0.0002,amsgrad=True)\nscheduler = ReduceLROnPlateau(optimizer3_1,mode= 'min',factor=0.1,patience=1)","b85505f3":"for epoch in range(15):  # loop over the dataset multiple times\n    \n    running_loss=0\n    \n    for i, data in enumerate(trainloader, 0):\n        # get the inputs\n        inputs, labels = data\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        # zero the parameter gradients\n        optimizer3_1.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net3_2(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer3_1.step()\n        \n        # print statistics\n        running_loss += loss.item()\n        if i % 1000 == 999:    # print every 1000 mini-batches\n            #image_num=(i+1)*50\n            print('[%d, %5d] loss: %.3f' %(epoch + 1, i+1, running_loss\/1000))\n            running_loss = 0\n            \n    scheduler.step(running_loss)\n                  \nprint('Finished Training')","aff06b5f":"net3_2.cpu()","9511ad29":"'''\nfor param in net3_2.parameters():\n    print(param.size())\n    print('{}:grad->{}'.format(param, param.grad))\n'''","3fb82533":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in trainloader:\n        images, labels = data\n        outputs = net3_2(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the train images: %.2f %%' % (\n    100 * correct \/ total))","4fdaf958":"correct\/total","ba01ae89":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in validloader:\n        images, labels = data\n        outputs = net3_2(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %.2f %%' % (\n    100 * correct \/ total))","efa8a996":"correct\/total","55d1c0d2":"class_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\nwith torch.no_grad():\n    for data in validloader:\n        images, labels = data\n        outputs = net3_2(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(2):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(2):\n    print(\"number of correct:\",class_correct[i], \"number of total:\",class_total[i])\n    print('Accuracy of %5s : %.2f %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","b0002186":"torch.save(net3_2.state_dict(), 'net3_2params.pkl')","d9580b6d":"from IPython.display import FileLink, FileLinks\nFileLinks('.')","bc101c14":"2*1309\/2695","fb87f1e0":"send the model to CPU","8774b2ed":"build the model","7d0d9f5f":"define the optimzer","bf73ed6a":"test on the test data","e523349e":"test on the training data","06177bcf":"train the model","98d101dc":"Test model on deifferent kinds of sample","ad6742d2":"save the model ","5514864a":"import package"}}