{"cell_type":{"207214b6":"code","75b435b9":"code","b8cd9896":"code","f9f1f388":"code","62128cd8":"code","ab2e0ffc":"code","176c05af":"code","0d8fda84":"code","9f80ced8":"code","74e0723d":"code","7e01baeb":"code","d2e05d49":"code","992cebcf":"code","3a4507b7":"code","b2ba664f":"code","ad3c7095":"code","fbceeac0":"code","9ccc9fe8":"code","e5d1a0ee":"code","bbd1b814":"code","8c61ff11":"code","18101f5b":"code","31720448":"code","cc0b0272":"code","47b92a8b":"code","f484315f":"code","cf8cad52":"code","83b68abe":"code","c1fef76f":"code","ec3dc72a":"code","f4e495fe":"code","b69ab155":"code","1353c7d9":"code","e805b172":"code","7f5cded8":"code","bc1f4eee":"code","12161391":"code","cc17bc48":"code","267f6543":"code","80b0772d":"code","f9c948a8":"code","7c3e7824":"code","41f3872e":"code","521cdc0e":"code","a87ca65d":"code","22717dca":"code","0a83acdd":"code","4b0bae64":"code","b87f854d":"code","b3cd32ff":"code","776ba564":"code","6e1a8ddb":"code","cfd631ae":"code","5412e8f0":"code","20e62c35":"code","caa80123":"code","3e85a627":"code","48a43206":"code","b2b84e2b":"code","05db78f1":"code","28c8e24f":"code","85e248cf":"code","2c1b7f24":"code","13b30972":"code","90c3c376":"code","6cc4c7b5":"code","58a8f66d":"code","06ecb6b2":"code","ccb22098":"code","5dcf9c78":"code","43029423":"code","a8e7fcac":"code","2ec87b12":"code","6ad39d82":"code","d783b72d":"code","249b1855":"code","f4b09638":"code","95712521":"code","bbfc91d6":"code","e9568ac6":"code","6d503390":"code","6e4e99f6":"code","0ead09ef":"code","75450935":"code","731ad793":"code","2a0ebbb6":"code","6b00247d":"code","10064edd":"code","bdf6eb38":"code","b71339b7":"code","8044f487":"code","3decc608":"code","44565936":"code","2557176f":"code","9115efa2":"code","e71350c4":"code","6a1a1242":"code","4790dabc":"code","2f980cf9":"code","dbd0f128":"code","ee1fc53a":"code","cdad2740":"code","eb243c66":"code","233e1157":"code","7f10d161":"code","64297ac3":"code","437cdd8e":"code","eab02f09":"code","a0f265c3":"code","674ac4dd":"code","702f45ea":"code","5b34b8ba":"code","e33821dd":"code","7b62f8e3":"code","f961f799":"code","fd028d71":"code","2788a265":"code","1525d43d":"code","21a503f9":"code","4a1b7ea3":"code","ae9b1f2d":"code","bb9aafce":"code","4c2a9e9e":"code","4816de2d":"code","524844b5":"code","e76f4418":"code","fa630a3c":"code","8a878035":"code","5e31c599":"code","ecdd24e3":"code","40a697a5":"code","9a2018a5":"code","8675b8aa":"code","8a1a5e0d":"code","bf015a5e":"code","e6f29a36":"code","d520f6d8":"markdown","b69d5fb7":"markdown","9804924d":"markdown","cc0e93f3":"markdown","73ccc000":"markdown","35872be6":"markdown","36d8e4a3":"markdown","7370b317":"markdown","237e503e":"markdown","fca27328":"markdown","d492f6d8":"markdown","a80c8f29":"markdown","e7b5b2ae":"markdown","843d4209":"markdown","fa065d8b":"markdown","add3770e":"markdown","4654a4a8":"markdown","09f01961":"markdown","9e7a864b":"markdown","c03287ef":"markdown","16860416":"markdown","ad46bd26":"markdown","71f678d0":"markdown","bfe07160":"markdown","665ef3cc":"markdown","0a5cc1e1":"markdown","ada233be":"markdown","78fa0d9d":"markdown","fb2e420d":"markdown","30a9e7fe":"markdown","9529a481":"markdown","362c1253":"markdown","0715d43d":"markdown","311566d8":"markdown","37a02f13":"markdown","0f99f081":"markdown","7bcad8fb":"markdown","0e693bf9":"markdown","a97cc01b":"markdown","448e2682":"markdown","53971461":"markdown","0612b900":"markdown","f5f02e18":"markdown","56f5b6d8":"markdown","415c8cb5":"markdown","c2c9f628":"markdown","3a3d9c50":"markdown","dc35e541":"markdown","9125f25c":"markdown","a65bfb15":"markdown"},"source":{"207214b6":"#Importing the neccessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","75b435b9":"# Load the input file\nmy_local_path='..\/input\/'\ndevice_data=pd.read_csv(my_local_path+'device_failure.csv')","b8cd9896":"device_data.info()","f9f1f388":"device_data.head()","62128cd8":"device_data.describe()","ab2e0ffc":"device_data['failure'].value_counts()","176c05af":"from sklearn.preprocessing import MinMaxScaler","0d8fda84":"scale=MinMaxScaler().fit(device_data[['attribute1','attribute2','attribute3','attribute4','attribute5','attribute6',\n                                            'attribute7','attribute8','attribute9']])\ndevice_data_scaled=scale.fit_transform(device_data[['attribute1','attribute2','attribute3','attribute4','attribute5','attribute6',\n                                            'attribute7','attribute8','attribute9']])","9f80ced8":"device_df_scaled=pd.DataFrame(device_data_scaled,columns=['attribute1','attribute2','attribute3','attribute4','attribute5','attribute6',\n                                            'attribute7','attribute8','attribute9'])","74e0723d":"device_df_scaled.head()","7e01baeb":"device_df_scaled['failure']=device_data['failure']","d2e05d49":"device_df_scaled.head()","992cebcf":"corr=device_df_scaled.corr()","3a4507b7":"corr","b2ba664f":"sns.heatmap(corr,annot=True,fmt=\".1f\")","ad3c7095":"device_df_scaled.drop('attribute8',axis=1,inplace=True)","fbceeac0":"device_df_scaled.head()","9ccc9fe8":"sns.boxplot(x='failure',y='attribute1',data=device_df_scaled)","e5d1a0ee":"sns.boxplot(x='failure',y='attribute2',data=device_df_scaled)","bbd1b814":"sns.boxplot(x='failure',y='attribute3',data=device_df_scaled)","8c61ff11":"sns.boxplot(x='failure',y='attribute5',data=device_df_scaled)","18101f5b":"sns.boxplot(x='failure',y='attribute6',data=device_df_scaled)","31720448":"sns.boxplot(x='failure',y='attribute7',data=device_df_scaled)","cc0b0272":"sns.boxplot(x='failure',y='attribute9',data=device_df_scaled)","47b92a8b":"from datetime import datetime\ndevice_df_scaled['month']=pd.to_datetime(device_data['date']).dt.month","f484315f":"month_dummies=pd.get_dummies(device_df_scaled.month,prefix='month',drop_first=False)\ndevice_df_scaled=pd.concat([device_df_scaled,month_dummies],axis=1)","cf8cad52":"device_df_scaled.pivot_table(index='month',columns='failure',aggfunc='size')","83b68abe":"features=['attribute1','attribute2','attribute3','attribute4','attribute5','attribute6','attribute7','attribute9']","c1fef76f":"#Spliting the features and labels\nX=device_df_scaled[features]\nY=device_df_scaled['failure']","ec3dc72a":"X.head()","f4e495fe":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=333)","b69ab155":"x_train.shape","1353c7d9":"x_test.shape","e805b172":"np.bincount(y_train)","7f5cded8":"from imblearn.over_sampling import SMOTE","bc1f4eee":"sm=SMOTE(random_state=555)\nx_res,y_res=sm.fit_resample(x_train,y_train)","12161391":"print(\"resample data set class distrbibution :\", np.bincount(y_res))","cc17bc48":"x_res.shape","267f6543":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(criterion='entropy',max_depth =4, n_estimators = 150,max_leaf_nodes=10, random_state = 1,min_samples_leaf=5,\n                            min_samples_split=10)","80b0772d":"# Train the model with the resampled data \nmy_forest=model.fit(x_res,y_res)","f9c948a8":"# Training accuracy\nmy_forest.score(x_res,y_res)","7c3e7824":"y_train_pred=my_forest.predict(x_res)","41f3872e":"y_pred=my_forest.predict(x_test)","521cdc0e":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,accuracy_score","a87ca65d":"# Test accuracy\naccuracy_score(y_pred,y_test)","22717dca":"# Testing Confusion Matrix\nprint(confusion_matrix(y_test,y_pred))","0a83acdd":"#Training CF\nprint(confusion_matrix(y_res,y_train_pred))","4b0bae64":"cr=metrics.classification_report(y_test,y_pred)\nprint(cr)","b87f854d":"dt_parameters={\"criterion\":['gini','entropy'],\"max_depth\":[3,7],\"max_leaf_nodes\": [20,30],\"n_estimators\":[100,200,300]}","b3cd32ff":"from sklearn.model_selection  import GridSearchCV\ngrid_rf=GridSearchCV(RandomForestClassifier(),dt_parameters)","776ba564":"grid_rf_model=grid_rf.fit(x_res,y_res)","6e1a8ddb":"grid_rf_model.best_params_","cfd631ae":"grid_predictor=grid_rf_model.predict(x_test)","5412e8f0":"print(confusion_matrix(y_test,grid_predictor))","20e62c35":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=0.2)\n","caa80123":"logreg.fit(x_res,y_res)","3e85a627":"y_logi_pred=logreg.predict(x_test)","48a43206":"print(confusion_matrix(y_test,y_logi_pred))","b2b84e2b":"from sklearn.utils import resample","05db78f1":"train_data=pd.concat([x_train,y_train],axis=1)","28c8e24f":"train_data.shape","85e248cf":"df_majority = train_data[train_data.failure==0]\ndf_minority = train_data[train_data.failure==1]","2c1b7f24":"df_majority.shape","13b30972":"df_minority.shape","90c3c376":"df_minorty_upsample=resample(df_minority, \n                             replace=True,     # sample with replacement\n                             n_samples=30000,    # to some good number\n                             random_state=123) # reproducible results\n ","6cc4c7b5":"df_majoirty_downsample=resample(df_majority, \n                             replace=False,     # sample without replacement\n                             n_samples=50000,    # to some good number\n                             random_state=321) # reproducible results\n ","58a8f66d":"df_majoirty_downsample.shape","06ecb6b2":"df_minorty_upsample.shape","ccb22098":"final_sample_merged=pd.concat([df_minorty_upsample,df_majoirty_downsample],axis=0)","5dcf9c78":"final_sample_merged.head()","43029423":"final_sample_merged['failure'].value_counts()","a8e7fcac":"x_resample_train=final_sample_merged[features]\ny_resample_train=final_sample_merged['failure']","2ec87b12":"y_resample_train.shape","6ad39d82":"model_rf=RandomForestClassifier(criterion='entropy', max_depth = 6, n_estimators = 200, max_leaf_nodes=10,\n                                    min_samples_leaf=10,min_samples_split=40,random_state = 1)","d783b72d":"model_rf.fit(x_resample_train,y_resample_train)","249b1855":"y_pred_train=model_rf.predict(x_resample_train)","f4b09638":"y_pred=model_rf.predict(x_test)","95712521":"confusion_matrix(y_test,y_pred)","bbfc91d6":"print(metrics.classification_report(y_test,y_pred))","e9568ac6":"from sklearn.model_selection import cross_val_score","6d503390":"model_kfold_rf=RandomForestClassifier(criterion='entropy', max_depth = 6, n_estimators = 200, max_leaf_nodes=10,\n                                    min_samples_leaf=10,min_samples_split=40,random_state = 1,)","6e4e99f6":"scores = cross_val_score(model_kfold_rf, x_resample_train, y_resample_train, scoring='recall', cv=10)","0ead09ef":"scores","75450935":"model_kfold_rf.fit(x_resample_train,y_resample_train)","731ad793":"y_pred_prob=model_kfold_rf.predict_proba(x_test)","2a0ebbb6":"y_cv_pred=model_kfold_rf.predict(x_test)","6b00247d":"confusion_matrix(y_test,y_cv_pred)","10064edd":"print(metrics.classification_report(y_test,y_cv_pred))","bdf6eb38":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob[:,1])","b71339b7":"plt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Device Failure classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","8044f487":"roc_df=pd.DataFrame(columns={'fpr','tpr','threshold'})","3decc608":"roc_df['fpr']=fpr\nroc_df['tpr']=tpr\nroc_df['threshold']=thresholds","44565936":"roc_df.loc[(roc_df['fpr']<0.16) & (roc_df['tpr']>0.77) ]","2557176f":"def adjusted_classes(y_scores, t):\n    \"\"\"\n    This function adjusts class predictions based on the prediction threshold (t).\n    \"\"\"\n    return [1 if y >= t else 0 for y in y_scores]","9115efa2":"y_pred=adjusted_classes(y_pred_prob[:,1],0.22)","e71350c4":"confusion_matrix(y_test,y_pred)","6a1a1242":"print(metrics.classification_report(y_test,y_pred))","4790dabc":"# We will also see the Area under curve\nprint(metrics.roc_auc_score(y_test, y_pred_prob[:,1]))","2f980cf9":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=0.6)","dbd0f128":"logreg.fit(x_resample_train,y_resample_train)","ee1fc53a":"y_log_pred=logreg.predict(x_test)","cdad2740":"print(confusion_matrix(y_test,y_log_pred))","eb243c66":"y_pred_log_prob=logreg.predict_proba(x_test)","233e1157":"scores_logreg = cross_val_score(logreg, x_resample_train, y_resample_train, scoring='recall', cv=5)","7f10d161":"scores_logreg","64297ac3":"# ROC Curve for the logistic regression\nfpr_log, tpr_log, thresholds_log = metrics.roc_curve(y_test, y_pred_log_prob[:,1])\n\nplt.plot(fpr_log, tpr_log)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Device Failure classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","437cdd8e":"# We will also see the Area under curve\nprint(metrics.roc_auc_score(y_test, y_pred_log_prob[:,1]))","eab02f09":"from sklearn.ensemble import AdaBoostClassifier","a0f265c3":"adb_model=AdaBoostClassifier(n_estimators=300,\n                             learning_rate=0.2)","674ac4dd":"adb_model.fit(x_resample_train,y_resample_train)","702f45ea":"y_adb_predict=adb_model.predict(x_test)","5b34b8ba":"print(confusion_matrix(y_test,y_adb_predict))","e33821dd":"# GridSearch on Adaboost\nfrom sklearn.model_selection import  GridSearchCV\ndt_parameters={\"n_estimators\":[100,200],\"learning_rate\":[0.1,0.2,0.4]}\n\ngrid_adaboost=GridSearchCV(AdaBoostClassifier(),dt_parameters)\ngrid_adaboost.fit(x_resample_train,y_resample_train)","7b62f8e3":"grid_adaboost.best_params_","f961f799":"y_pred_adb_prob=adb_model.predict_proba(x_test)","fd028d71":"# ROC AUC Curve\nfpr_adb, tpr_adb, thresholds_adb = metrics.roc_curve(y_test, y_pred_adb_prob[:,1])\n\nplt.plot(fpr_adb, tpr_adb)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Device Failure classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","2788a265":"print(metrics.roc_auc_score(y_test, y_pred_adb_prob[:,1]))","1525d43d":"from sklearn.neural_network import MLPClassifier\nmlp_clf = MLPClassifier(learning_rate_init=0.00008)\nmlp_clf.fit(x_resample_train,y_resample_train)","21a503f9":"y_mlp_pred=mlp_clf.predict(x_test)\nconfusion_matrix(y_test,y_mlp_pred)","4a1b7ea3":"y_pred_mlp_prob=mlp_clf.predict_proba(x_test)","ae9b1f2d":"print(metrics.classification_report(y_test,y_mlp_pred))","bb9aafce":"fpr_mlp, tpr_mlp, thresholds_mlp = metrics.roc_curve(y_test, y_pred_mlp_prob[:,1])\n\nplt.plot(fpr_mlp, tpr_mlp)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for Device Failure classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","4c2a9e9e":"print(metrics.roc_auc_score(y_test, y_pred_mlp_prob[:,1]))","4816de2d":"#Build Stacking model\nfrom sklearn.model_selection import KFold\n\nbase1_clf = model_rf\nbase2_clf = logreg\nbase3_clf = adb_model\nbase4_clf = mlp_clf\nfinal_clf =logreg\n\n# Defining the K Fold\nn_folds = 5\nn_class = 2\nkf = KFold(n_splits= n_folds, shuffle=True, random_state=42)\n","524844b5":"def get_oof(clf, x_train, y_train, x_test):\n    ntest = x_test.shape[0]\n    oof_train = np.zeros((x_train.shape[0],n_class))\n    oof_test  = np.zeros((x_test.shape[0],n_class))\n    oof_test_temp = np.empty((n_folds, ntest))\n   \n    for i,(train_index, test_index) in enumerate(kf.split(x_train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n  \n        \n        clf.fit(x_tr, y_tr)\n\n        pred_te = clf.predict_proba(x_te)\n        oof_train[test_index,:] = pred_te\n        \n        pred_test = clf.predict_proba(x_test)\n        oof_test += pred_test\n\n    return oof_train, oof_test\/n_folds","e76f4418":"base1_oof_train, base1_oof_test = get_oof(base1_clf, x_resample_train.values,y_resample_train.values, x_test.values)\nbase2_oof_train, base2_oof_test = get_oof(base2_clf, x_resample_train.values,y_resample_train.values, x_test.values)\nbase3_oof_train, base3_oof_test = get_oof(base3_clf, x_resample_train.values,y_resample_train.values, x_test.values)\nbase4_oof_train, base4_oof_test = get_oof(base4_clf, x_resample_train.values,y_resample_train.values, x_test.values)","fa630a3c":"base1_oof_train","8a878035":"base1_oof_test","5e31c599":"x_train_stack = np.concatenate((base1_oof_train, \n                          base2_oof_train,\n                          base3_oof_train,\n                          base4_oof_train), axis=1)\nx_test_stack = np.concatenate((base1_oof_test,\n                         base2_oof_test,\n                         base3_oof_test,\n                         base4_oof_test),axis=1)","ecdd24e3":"x_train_stack.shape","40a697a5":"y_resample_train.shape","9a2018a5":"x_test_stack.shape","8675b8aa":"final_clf.fit(x_train_stack,y_resample_train)","8a1a5e0d":"y_stacked_predict=final_clf.predict(x_test_stack)","bf015a5e":"confusion_matrix(y_test,y_stacked_predict)","e6f29a36":"print(metrics.classification_report(y_test,y_stacked_predict))","d520f6d8":"# 5. Feature Engineering  <a id='feature'>","b69d5fb7":"# 8.4 MLPClassifier(NN) <a id='MLP'>","9804924d":"## 7.1  Random Forest <a id='SMOTE_RF'>\nWe will use the RandromForest algorithm since this is best suited for class imbalance\/non linear data.","cc0e93f3":"Lets split the sample to train and test before we do this. This will segregate the train data and then we can apply the sampling techniques with the train data","73ccc000":"**Note**:\n\nPlease note that the feature engineering has been done,howwever after executing the models, it didnt have any added value and hence has been removed. So the below models will not use this feature","35872be6":"Now, let us check the distribution of the output ,label","36d8e4a3":"## 3. Exploratory Data Analysis <a id='EDA'>","7370b317":"**Observation**: This Sensitivity(TP) rate of 0.68 is relatively better than the intial Random forest 0.58, keeping the Specificity(TN) intact","237e503e":"<h1> Table of Contents <\/h1>\n\n1. [Dataset Description](#columns)\n2. [Importing Packages and have a quick glance at the data](#packages)\n3. [Exploratory Data Analysis](#EDA)\n4. [Normalization](#Scaling)\n5. [FeatureEngineering](#feature) \n6. [Train\/Test split Before Sampling](#traintest)\n7. [Sampling the data using SMOTE](#SMOTE)\n     - 7.1 [Training a Random Forest](#SMOTE_RF)\n     - 7.2 [Logistic Regression ](#SMOTE_log )\n8. [Up-Down sample using Resampling](#Resample)\n      - 8.1 [Training a Random Forest](#Resample_RF)\n      - 8.2 [Logistic Regression](#Resample_log)\n      - 8.3 [Adaboost](#adb)\n      - 8.4 [MLPClassifier(NN)](#MLP)\n      - 8.5 [Stacking](#stacking)\n\n     \n\n","fca27328":"# 8.5  Stacking  <a id='stacking'>\n    \n    We will use all the 4 models as base models and build a stacking model to see if there is any improvement","d492f6d8":"# K Fold Cross Validation ","a80c8f29":"Before we handle the data imbalance, lets first normalise the data set and prepare the train and test data. We will use the MinMaxScaler in this case given the outliers in the data\n","e7b5b2ae":"Lets do the resampling now for both the classes","843d4209":"stacking uses predictions of base classifiers as input for training to a second-level model","fa065d8b":"## Hyperparameter tuning using Grid Search","add3770e":"\n## 8. Upsample the minorty and downsample the majority classes   \nNow, lets see a different sampling technique  <a id='Resample'>","4654a4a8":"*Observation*: From the above, we can see the right threshold is 0.218607","09f01961":"So far, we have tried diversified models like RandomForest, LogisticRegression & Adaboost ( Ensemble) algorithms.\nRandom Forest is outperforming the rest 2.\n\nNow we will also use stacking technique using all the three models and build a meta model to see if we the score is improved\n","9e7a864b":"# 8.2 Logistic Regression   <a id='Resample_log'>","c03287ef":"*Observation*: Here we see a huge class imbalance,  disproportionate ratio of observations . Out of the 124494 records in the data set, only 106 are failure cases. This needs to be handled","16860416":"## 1. Dataset Description <a id='columns'>\n\n\nThis data set contains around 125000 records containing device information with attribute combination and Whether there was a failure or not\n\n\nBelow are the columns information\n\n\n-**date**\n\n-**device id**\n\n-**attribute1 to attribute9**\n\n-**Label 'failure' indicating  if the device is failed (1) or not (0)**","ad46bd26":"*Observation* :So we dont have any null values in the given data set","71f678d0":"Scale is different for the attributes and there is a huge difference in the ranges. It needs a normalization in this case","bfe07160":"*Note*: Above parameters have been obtained through trails and grid search","665ef3cc":"*Observation* : attribute 9,7,5,3,2 have more outliers .No precise segregation of classes for the given set of attributes.\n\nConsidering the use case as the critical one , we will not be removing the outliers","0a5cc1e1":"Lets see the if there is any colinearity among the attributes","ada233be":"# 6. Train\/Test Split Before Resampling <a id='traintest'>\n","78fa0d9d":"**Observation**: TN is increased here compared to the Random Forest, although the TP is same. Bu the Area under Curve is better in case of RF after adjusting the probabilities\n","fb2e420d":"#  ROC\/AUC Curve\nLet us draw ROC AUC curve to see the correct threshold B\/W TP and FPs","30a9e7fe":"*Observation*: Above Metrics shows that the TruePositive(TP\/Sensitivity\/Recall) is not so impressive for the test data\n\nPlease note that the parameters for the tree are obtained from various combinations & as well with the Grid Search below","9529a481":"**Observation** : So far, Randorm forest with the up\/down sampling of Minority\/Majoiry data sets seems to be perfoming better , relatively","362c1253":"There are multiple ways of handling this imbalance data. \n\nIn this case we will try generate Synthetic Samples using the SMOTE algorithm, since we have a huge data imbalance as we can see above.(87070 \/ 75)\n\n# 7. Sampling the data using SMOTE <a id='SMOTE'>\n","0715d43d":"So, accordingly we need to adjust the threshold probability to have a trade off between the TruePositive\/TN rates","311566d8":"Now , we will see the ROC curves to find out the correct threshold probability to segregate the classes to  0 and 1","37a02f13":"\nNow, Lets us apply the Advanced ML boosting techinque\n# 8.3 Adaboost <a id='adb'>","0f99f081":"We see the min\/max values are too far and the standard deviation is also more for almost all the attributes","7bcad8fb":"**Conclusion**\n\nWhen it comes to the TN, stacking is performing good. But overall, the RandormForest and the MLPClassifiers are doing better as a trade of between TP and TN for the given training data.\n\n","0e693bf9":"*Obervation* Attribute 7 & 8 are strongly correlated. We can drop the attribute 8.\n             Attribute 9 is 50% correlated with attribute3","a97cc01b":"**Observation**: So far , this value is less than the RandomForest Area under curve","448e2682":"We will observe the relation of output with these attributes using the box plots","53971461":"*Observation*: So far LogisticRegression and Random Forest didnt give a good TP\/TN values","0612b900":"# 7.2  Logistic Regression <a id='SMOTE_log'>","f5f02e18":"Now, we have an equal distribution of the date class. ","56f5b6d8":"#  8.1 RandomForest  <a id='Resample_RF'>","415c8cb5":"Let us see the basic statistics of the distribution","c2c9f628":"# Device failure Data Set Description","3a3d9c50":"*Observation*: From the Curve , we can obseve that the FP,TP combination seems to be optimal at point approximately close to  (0.2,0.8). Now let us calcualte the corresponding threshold","dc35e541":"## 2. Importing Packages and have a quick glance at the data <a id='packages'>","9125f25c":"# 4. Normalization <a id='Scaling'>","a65bfb15":"Here we have used the 10 Fold cross validation to cover the entire data set so that the model will learn from all the folds and validate with 1 fold each time"}}