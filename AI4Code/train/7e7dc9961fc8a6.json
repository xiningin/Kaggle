{"cell_type":{"253f828b":"code","5a38dde3":"code","234788ac":"code","b2fbd6c6":"code","325928f1":"code","119addd3":"code","ce993297":"code","68de92b6":"code","3fbaae1d":"code","d37d7bac":"code","85b55523":"code","5213e766":"code","a436b71e":"code","e6b8e077":"code","1c72fb91":"code","ae011461":"code","84f982b4":"code","457aa055":"code","672d1ffc":"code","957bf680":"code","c5d8c55c":"code","b2e2c2f5":"code","041414a7":"code","4f94b2cd":"code","56e54af2":"code","9d5bc4ff":"code","df9703e8":"code","aa375668":"code","872148e3":"code","48d5a7be":"code","9ebb63a2":"code","f5cd4326":"code","ab20365e":"code","aff054cd":"code","4675bf0d":"code","7a7efe4b":"code","6a659b73":"code","cb4a2983":"code","e86b5460":"code","822465df":"code","3dc2d311":"code","8588d72b":"code","dfd08e06":"code","11ec830f":"code","e8404c12":"code","7a0a8609":"code","4ad15193":"code","3ee2275a":"code","0118ec22":"code","c553ebfe":"code","fbb6d6fe":"code","d91d2fc7":"code","dfb6b95e":"code","d4a97601":"code","62006508":"code","27e41d44":"code","208798e7":"code","7187a354":"markdown","55f9a52f":"markdown","2dbf745c":"markdown","338d8f3d":"markdown","74fb5aef":"markdown","84b13f44":"markdown","4469a2c8":"markdown","eb8a34cb":"markdown","6251fbf1":"markdown","244da642":"markdown","b71a1e2b":"markdown","2185161b":"markdown","9e0d6aaf":"markdown","ea8f94fb":"markdown","1a23f945":"markdown","4d6ee7d7":"markdown","f21fc911":"markdown"},"source":{"253f828b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a38dde3":"Data = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')\nData","234788ac":"Data.columns","b2fbd6c6":"for i in Data.columns:\n    print('this {} column has unique_vlaues = \\n'.format(i),Data[i].value_counts())","325928f1":"for i in Data.columns: \n    a = Data[i].isnull().sum()\n    if a !=0:\n        print(i,' has ', Data[i].isnull().sum())\n    else:\n        print('no null values')","119addd3":"\ncolor = {\"b\": 0, \"c\": 1,\"e\": 2, \"g\": 3,\"n\": 4, \"p\": 5,\"r\": 6, \"u\": 7,\"w\": 8, \"y\": 9}\n\n\nfor i, j in color.items():\n    Data[\"cap-color\"] = Data[\"cap-color\"].replace(i, j)","ce993297":"Data['gill-color'].unique()","68de92b6":"\ncolor = {\"b\": 0,\"e\": 2, \"g\": 3,\"n\": 4, \"p\": 5,\"r\": 6, \"u\": 7,\"w\": 8, \"y\": 9, 'h':10,'k':11,'o':12}\n\n\nfor i, j in color.items():\n    Data[\"gill-color\"] = Data[\"gill-color\"].replace(i, j)","3fbaae1d":"Data['veil-color'].unique()","d37d7bac":"\ncolor = {\"n\": 4,\"w\": 8, \"y\": 9,'o':12}\n\n\nfor i, j in color.items():\n    Data[\"veil-color\"] = Data[\"veil-color\"].replace(i, j)","85b55523":"Data['spore-print-color'].unique()","5213e766":"color = {\"b\": 0,\"n\": 4,\"r\": 6, \"u\": 7,\"w\": 8, \"y\": 9, 'h':10,'k':11,'o':12}\n\n\nfor i, j in color.items():\n    Data[\"spore-print-color\"] = Data[\"spore-print-color\"].replace(i, j)","a436b71e":"Data['stalk-color-above-ring'].unique()","e6b8e077":"\ncolor = {\"b\": 0, \"c\": 1,\"e\": 2, \"g\": 3,\"n\": 4, \"p\": 5, \"w\": 8, \"y\": 9,'o':12}\n\n\nfor i, j in color.items():\n    Data[\"stalk-color-above-ring\"] = Data[\"stalk-color-above-ring\"].replace(i, j)","1c72fb91":"Data['stalk-color-below-ring'].unique()","ae011461":"\ncolor = {\"b\": 0, \"c\": 1,\"e\": 2, \"g\": 3,\"n\": 4, \"p\": 5, \"w\": 8, \"y\": 9,'o':12}\n\n\nfor i, j in color.items():\n    Data[\"stalk-color-below-ring\"] = Data[\"stalk-color-below-ring\"].replace(i, j)","84f982b4":"Data['cap-shape'].unique()","457aa055":"color = {\"b\": 0,\"c\": 1,\"f\": 2, \"k\": 3,\"s\": 4, \"x\": 5}\n\n\nfor i, j in color.items():\n    Data[\"cap-shape\"] = Data[\"cap-shape\"].replace(i, j)","672d1ffc":"Data['cap-surface'].unique()","957bf680":"color = {\"f\": 2,\"s\": 4, 'g':6,'y':7}\n\n\nfor i, j in color.items():\n    Data[\"cap-surface\"] = Data[\"cap-surface\"].replace(i, j)","c5d8c55c":"Data['bruises'].unique()","b2e2c2f5":"color = {\"f\": 0,\"t\": 1}\n\n\nfor i, j in color.items():\n    Data[\"bruises\"] = Data[\"bruises\"].replace(i, j)","041414a7":"Data['odor'].unique()","4f94b2cd":"color = {'a':0,'c':1,'f':2,'l':3,'m':4,'n':5,'p':6,'s':7,'y':8}\n\n\nfor i, j in color.items():\n    Data[\"odor\"] = Data[\"odor\"].replace(i, j)","56e54af2":"Data['gill-attachment'].unique()","9d5bc4ff":"color = {\"f\": 0,\"a\": 1}\n\n\nfor i, j in color.items():\n    Data[\"gill-attachment\"] = Data[\"gill-attachment\"].replace(i, j)","df9703e8":"Data['gill-spacing'].unique()","aa375668":"color = {\"c\": 0,\"w\": 1}\n\n\nfor i, j in color.items():\n    Data[\"gill-spacing\"] = Data[\"gill-spacing\"].replace(i, j)","872148e3":"Data['gill-size'].unique()","48d5a7be":"color = {\"n\": 0,\"b\": 1}\n\n\nfor i, j in color.items():\n    Data[\"gill-size\"] = Data[\"gill-size\"].replace(i, j)","9ebb63a2":"Data['stalk-shape'].unique()","f5cd4326":"color = {\"e\": 0,\"t\": 1}\n\n\nfor i, j in color.items():\n    Data[\"stalk-shape\"] = Data[\"stalk-shape\"].replace(i, j)","ab20365e":"Data['stalk-root'].unique()","aff054cd":"color = {\"b\": 0,\"c\": 1,'e':2,'r':3,'?':4}\n\n\nfor i, j in color.items():\n    Data[\"stalk-root\"] = Data[\"stalk-root\"].replace(i, j)","4675bf0d":"Data['stalk-surface-above-ring'].unique()","7a7efe4b":"color = {\"f\": 0,\"k\": 1,'s':2,'y':3}\n\n\nfor i, j in color.items():\n    Data[\"stalk-surface-above-ring\"] = Data[\"stalk-surface-above-ring\"].replace(i, j)","6a659b73":"Data['stalk-surface-below-ring'].unique()","cb4a2983":"color = {\"f\": 0,\"k\": 1,'s':2,'y':3}\n\n\nfor i, j in color.items():\n    Data[\"stalk-surface-below-ring\"] = Data[\"stalk-surface-below-ring\"].replace(i, j)","e86b5460":"Data['veil-type'].unique()","822465df":"color = {\"p\": 0}\n\n\nfor i, j in color.items():\n    Data[\"veil-type\"] = Data[\"veil-type\"].replace(i, j)","3dc2d311":"Data['ring-number'].unique()","8588d72b":"color = {\"o\": 0,'t':1, 'n':2}\n\n\nfor i, j in color.items():\n    Data[\"ring-number\"] = Data[\"ring-number\"].replace(i, j)","dfd08e06":"Data['ring-type'].unique()","11ec830f":"color = {\"e\": 0,'f':1, 'l':2, 'n':3, 'p':4}\n\n\nfor i, j in color.items():\n    Data[\"ring-type\"] = Data[\"ring-type\"].replace(i, j)","e8404c12":"Data['population'].unique()","7a0a8609":"color = {\"a\": 0,'c':1, 'n':2, 's':3, 'v':4, 'y':5}\n\n\nfor i, j in color.items():\n    Data[\"population\"] = Data[\"population\"].replace(i, j)","4ad15193":"Data['habitat'].unique()","3ee2275a":"color = {\"d\": 0,'g':1, 'l':2, 'm':3, 'p':4, 'u':5, 'w':6}\n\n\nfor i, j in color.items():\n    Data[\"habitat\"] = Data[\"habitat\"].replace(i, j)","0118ec22":"Data['class'].unique()","c553ebfe":"color = {\"e\": 0,'p':1}\n\n\nfor i, j in color.items():\n    Data[\"class\"] = Data[\"class\"].replace(i, j)","fbb6d6fe":"Data","d91d2fc7":"Train = Data.iloc[:7000, :]\nTest = Data.iloc[7000:, :]","dfb6b95e":"Train","d4a97601":"X = Train.drop(columns=['class'])\nY = Train['class']","62006508":"test_data = Test.drop(columns='class')\ntest_class = Test['class']","27e41d44":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\n\nmodel.fit(X, Y)","208798e7":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nprediction = model.predict(test_data)\nprint('accuracy_score is ', (accuracy_score(prediction, test_class)))\nprint('classification_report is ', (classification_report(prediction, test_class)))\nprint('confusion_matrix is \\n', (confusion_matrix(prediction, test_class)))","7187a354":"**We will start with colors first**","55f9a52f":"# RANDOM FOREST","2dbf745c":"****One of the biggest advantages of random forest is its versatility. It can be used for both regression and classification tasks.One of the biggest problems in machine learning is overfitting, but most of the time this won\u2019t happen thanks to the random forest classifier. ****\n\n**The main limitation of random forest is that a large number of trees can make the algorithm too slow and ineffective for real-time predictions. In general, these algorithms are fast to train, but quite slow to create predictions once they are trained.******","338d8f3d":"**Decision Trees is the fundamental block of Random Forest**","74fb5aef":"# We are done with Feature Labeling","84b13f44":"# The low correlation between models is the key.The reason for this wonderful effect is that the trees protect each other from their individual errors. While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction.","4469a2c8":"# Bagging (Bootstrap Aggregation) \u2014 Decisions trees are very sensitive to the data they are trained on \u2014 small changes to the training set can result in significantly different tree structures. Random forest takes advantage of this by allowing each individual tree to randomly sample from the dataset with replacement, resulting in different trees. This process is known as bagging.For example, if our training data was [1, 2, 3, 4, 5, 6] then we might give one of our trees the following list [1, 2, 2, 3, 6, 6]","eb8a34cb":"# **Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model\u2019s prediction**","6251fbf1":"# ADVANTAGES AND DISADVANTAGES OF THE RANDOM FOREST ALGORITHM","244da642":"# Mapping of feature values","b71a1e2b":"![image.png](attachment:image.png)","2185161b":"![image.png](attachment:image.png)","9e0d6aaf":"# So in our random forest, we end up with trees that are not only trained on different sets of data (thanks to bagging) but also use different features to make decisions.","ea8f94fb":"# We have Record of 8123 Rows, Lets Take 7000 records for Training and 1123 records will be for Testing our model.","1a23f945":"# Random forest is a supervised learning algorithm","4d6ee7d7":"Feature Randomness ![image.png](attachment:image.png)","f21fc911":"# What do we need in order for our random forest to make accurate class predictions?\nWe need features that have at least some predictive power. After all, if we put garbage in then we will get garbage out.\nThe trees of the forest and more importantly their predictions need to be uncorrelated (or at least have low correlations with each other)."}}