{"cell_type":{"74a9e8b1":"code","8aa604f2":"code","4d00af7e":"code","ebe9a802":"code","34d5a9e2":"code","22bf7d71":"code","83a9e812":"code","6cb6aa8f":"code","c9e1899c":"code","67825427":"code","1f52244d":"code","9e98d95a":"code","4d0da1f1":"code","900bea7c":"code","759ce038":"code","bcb12beb":"code","f0562c19":"code","c60e343b":"code","926bdd09":"code","ea9775c2":"code","caa3d101":"code","a70f0c80":"code","5ead5778":"code","cbcec951":"code","ffb854c2":"code","15453bc3":"code","0c25c5d9":"code","377215f1":"code","3830ddb2":"code","86c70090":"markdown","8d0cb33e":"markdown","571edbf4":"markdown","d93e1a0a":"markdown","a69f7a4c":"markdown","bdc232d3":"markdown","34d29dc0":"markdown","72d0c37f":"markdown","9c880b5d":"markdown","c7de2df3":"markdown","2ada724d":"markdown","53c04969":"markdown","34d7659b":"markdown","739963be":"markdown","255da5a5":"markdown","447fdd71":"markdown","29804f0b":"markdown","ca7c30f1":"markdown","9ea35950":"markdown","aceba5da":"markdown","0e2ab9d7":"markdown","9403f90f":"markdown","19774e75":"markdown","6234f3db":"markdown","9d38c1a5":"markdown","96e26d34":"markdown","58256af3":"markdown","d819c6b1":"markdown","7485f99b":"markdown","05f489e2":"markdown","89961e7f":"markdown","fc46a64c":"markdown","7be7c8fe":"markdown","935e6e40":"markdown","a05348f3":"markdown","2b010511":"markdown","cefd3676":"markdown","68e72f34":"markdown","8cf26d0c":"markdown"},"source":{"74a9e8b1":"import pandas as pd\nimport numpy as np\nimport math\nimport datetime\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.metrics import r2_score\nimport warnings\nwarnings.warn = False","8aa604f2":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\nprint(\"Training set = \",train.shape)\nprint(\"Testing set = \",test.shape)\nprint(\"Sum of Missing Values (Train\/Test)= \",train.isna().sum().sum(),\"(\",test.isna().sum().sum(),\")\")","4d00af7e":"ls=[[i,train[i].isna().sum(),round(train[i].isna().sum()\/train.shape[0]*100,2)] for i in train.columns if train[i].isna().sum()>0]\nprint('Before Imputing Missing Values\\n',ls)\n\n\ntrain['Age'].fillna(train['Age'].mean(),inplace=True) # Impute Missing Value of Age with mean\n\ntrain.loc[train.Cabin.isna(),'Cabin'] = 'NAA'         # Impute Missing Value of Cabin with NAA\ntrain['Cabin'] = [i[0] for i in train.Cabin]\n\n#train.Embarked.hist()\ntrain.loc[train.Embarked.isna(),'Embarked'] = 'S'     # Impute Missing Value of Embarked with Most Frequent Value \n\n\nls=[[i,train[i].isna().sum(),round(train[i].isna().sum()\/train.shape[0]*100,2)] for i in train.columns if train[i].isna().sum()>0]\nprint('After Imputing Missing Values\\n',ls)","ebe9a802":"ls=[[i,test[i].isna().sum(),round(test[i].isna().sum()\/test.shape[0]*100,2)] for i in test.columns if test[i].isna().sum()>0]\nprint('Before Imputing Missing Values\\n',ls)\n\ntest['Age'].fillna(test['Age'].mean(),inplace=True) # Impute Missing Value of Age with mean\n\ntest.loc[test.Cabin.isna(),'Cabin'] = 'NAA'         # Impute Missing Value of Cabin with NAA\ntest['Cabin'] = [i[0] for i in test.Cabin]\n\ntest.loc[test.Fare.isna(),'Fare'] = test.Fare[test.Pclass==3].mean() # Impute Missing Value of Pclass = 3\n\nls=[[i,train[i].isna().sum(),round(train[i].isna().sum()\/train.shape[0]*100,2)] for i in train.columns if train[i].isna().sum()>0]\nprint('After Imputing Missing Values\\n',ls)","34d5a9e2":"#train = train[train.Fare<400]","22bf7d71":"#test = test[test.Fare<400]","83a9e812":"diff = max(train.Age) - min(train.Age)\ntrain['Age_Group'] = [math.floor(i) if math.floor(i)>1 else 1 for i in (train.Age-1)\/diff+1]\ntrain.drop(columns=['Age'],axis=1,inplace=True)","6cb6aa8f":"diff = max(test.Age) - min(test.Age)\ntest['Age_Group'] = [math.floor(i) if math.floor(i)>1 else 1 for i in (test.Age-1)\/diff+1]\ntest.drop(columns=['Age'],axis=1,inplace=True)","c9e1899c":"train.Fare = train.Fare\/400\ntrain.loc[train.Fare>1,'Fare'] = 1","67825427":"test.Fare  = test.Fare\/400\ntest.loc[test.Fare>1,'Fare'] = 1","1f52244d":"ohe_col = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked','Age_Group']\ntrain = pd.get_dummies(train,columns=ohe_col,drop_first=True)\ntest  = pd.get_dummies(test ,columns=ohe_col,drop_first=True)","9e98d95a":"y_train = train.Survived\nX_train = train.drop(columns=['Survived','PassengerId','Name','Ticket'],axis=1)\nX_train.head()","4d0da1f1":"X_test_passenger_id = test.PassengerId\npassenger_name = test.Name \nX_test  = test.drop(columns=['PassengerId','Name','Ticket'],axis=1)\nX_test.head()","900bea7c":"A = set(X_train.columns)\nB = set(X_test.columns)\nC = A-B\nD = B-A\nkeep_columns = list(A - C - D)\n\nX_train = X_train[keep_columns]\nX_test  = X_test[keep_columns]","759ce038":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(solver='liblinear',penalty='l1',max_iter=100,random_state=7)\nlog_reg.fit(X_train,y_train)","bcb12beb":"from sklearn.metrics import accuracy_score\ny_pred = log_reg.predict(X_train)\nprint('The accuracy score is ',round(accuracy_score(y_train,y_pred)*100,2))","f0562c19":"def get_prediction(y_train,y_pred_pa,threshold_list):\n  best_threshold = 0\n  best_score = 0\n  for i in threshold_list:\n    y_pred = [1 if j>=i else 0 for j in y_pred_pa[:,1]]\n    temp = accuracy_score(y_train,y_pred)    \n    if best_score < temp:\n      best_score = temp\n      best_threshold = i\n\n  y_pred = [1 if j>=best_threshold else 0 for j in y_pred_pa[:,1]]\n\n  return best_threshold,y_pred","c60e343b":"y_pred_pa  = log_reg.predict_proba(X_train)\n\nbest_threshold, y_pred = get_prediction(y_train,y_pred_pa,[0.1,0.3,0.5,0.7,0.9])\nprint('Accuracy Improvement ( Threshold=',best_threshold,'):',round(accuracy_score(y_train,y_pred)*100,2))\n\nbest_threshold, y_pred = get_prediction(y_train,y_pred_pa,[0.45,0.5,0.55,0.6,0.65])\nprint('Accuracy Improvement ( Threshold=',best_threshold,'):',round(accuracy_score(y_train,y_pred)*100,2))\n\n\n# Thus, optimal threshold 0.6 is chosen\ny_pred = [1 if j>=0.6 else 0 for j in y_pred_pa[:,1]]","926bdd09":"from sklearn.model_selection import cross_val_score\nscore_list = cross_val_score(log_reg,X_train,y_train,cv=10)\n\nprint('Cross Validation Score','\\n',\n      'Mean=',score_list.mean())","ea9775c2":"select_columns = [i for i,j in zip(X_train.columns,np.ravel(log_reg.coef_)) if j!=0]\nprint('Select columns from LASSO:\\n',select_columns)","caa3d101":"print('Output:',y_pred[:10])","a70f0c80":"from xgboost import XGBClassifier\nxgb = XGBClassifier(random_state=7)\nxgb.fit(X_train,y_train)","5ead5778":"y_pred=xgb.predict(X_train)\nprint(accuracy_score(y_train,y_pred))","cbcec951":"from sklearn.model_selection import GridSearchCV\nparameters = {'max_depth':[3,5,7],\n              'n_estimators':[50,100,200],\n              'learning_rate':[0.1,0.2,0.3],                            \n             }\n             \ngd = GridSearchCV(estimator=XGBClassifier(booster='gbtree',random_state=7),\n                  param_grid=parameters,                \n                  cv=10,\n                  scoring='accuracy')\ngd.fit(X_train,y_train)","ffb854c2":"print(gd.best_estimator_)\nprint(gd.best_params_)\nprint(gd.best_score_)","15453bc3":"xgb = XGBClassifier(learning_rate=0.2, max_depth=5, n_estimators=100,booster='gbtree',random_state=7)\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_train)\n\nprint('Model Accuracy = ',accuracy_score(y_train,y_pred))","0c25c5d9":"y_pred_pa = xgb.predict_proba(X_train)\n\nbest_threshold, y_pred = get_prediction(y_train,y_pred_pa,[0.1,0.3,0.5,0.7,0.9])\nprint('Accuracy Improvement ( Threshold=',best_threshold,'):',round(accuracy_score(y_train,y_pred)*100,2))\n\nbest_threshold, y_pred = get_prediction(y_train,y_pred_pa,[0.45,0.5,0.55,0.6])\nprint('Accuracy Improvement ( Threshold=',best_threshold,'):',round(accuracy_score(y_train,y_pred)*100,2))","377215f1":"y_pred_pa = xgb.predict_proba(X_test)\ny_pred = [1 if j>=0.5 else 0 for j in y_pred_pa[:,1]]\n","3830ddb2":"result = pd.DataFrame()\n\nresult['PassengerId'] = X_test_passenger_id\nresult['Survived'] = y_pred\nresult.columns = ['PassengerId','Survived']\n\nresult.to_csv(\"submission.csv\", index=False)","86c70090":"## 2.1. Missing Value Treatment (Age, Cabin, Embarked)","8d0cb33e":"### 3.3.4.1. Identify Best Parameter Setting for Training","571edbf4":"# 3.0. Predictive Modeling\n","d93e1a0a":"## 2.4. Scaling (Fare)","a69f7a4c":"### 2.1.1. Training Set","bdc232d3":"### 3.1.1 One-Hot Encoding","34d29dc0":"### 3.2.4 Cross-Validation","72d0c37f":"## 2.3. Grouping Values (Age to Age Group)","9c880b5d":"### 3.3.4.3. Improve Performance by tuning Threshold","c7de2df3":"## 3.1. Data Preparation","2ada724d":"### 3.3.5. Perform Prediction","53c04969":"### 2.3.2. Testing Dataset","34d7659b":"### 3.2.1. Training Logistic Regression Model","739963be":"## 1.1. Import Libraries","255da5a5":"### 3.3.6. Save Results","447fdd71":"### 2.4.1. Training Set","29804f0b":"### 2.4.2. Testing Set","ca7c30f1":"## 2.2. Outlier Treatment (Keep Fare < 400)","9ea35950":"- Improvement","aceba5da":"# 2.0. Feature Engineering\n","0e2ab9d7":"## 3.3. XGBoost Classifier","9403f90f":"## 1.2. Import Dataset","19774e75":"### 3.2.3. Performance Improvement\n\n**By Tuning Threshold**\n\n- User Defined Function","6234f3db":"### 2.3.1. Training Dataset","9d38c1a5":"### 3.3.1. Model Training","96e26d34":"## 3.2. Logistic Regression","58256af3":"### 2.2.1. Training Set","d819c6b1":"### 3.3.2. Model Performance","7485f99b":"#### 3.1.1.1. Training Set","05f489e2":"### 2.2.1. Testing Set","89961e7f":"### 2.1.2. Testing Dataset","fc46a64c":"### 3.2.2. Performance Evaluation","7be7c8fe":"#### 3.1.1.2. Testing Set","935e6e40":"### 3.3.4.1. Select Best Parameter Setting for Training","a05348f3":"### 3.3.4. GridSearch CV","2b010511":"### 3.2.6. Perform Prediction","cefd3676":"#### 3.1.1.3. Eliminate Uncommon Columns","68e72f34":"### 3.2.5. Identify Important Features","8cf26d0c":"# 1.0 Import"}}