{"cell_type":{"324c71b5":"code","4b9f6227":"code","14b1a309":"code","c25d762b":"code","fc7a1fea":"code","185d9b54":"code","685390dd":"code","807cd3cc":"code","7b848ee1":"code","a6bd2bae":"code","fce403c4":"code","ccb7c201":"code","a20ca54c":"code","e4e36a0d":"code","f122aa23":"code","84e81ab4":"code","39651aac":"code","c2e9512e":"code","241ba37d":"code","b723d6c1":"code","a369b97c":"code","b1976f26":"code","9ba399f0":"code","856f2e9b":"code","90c6d937":"code","22233440":"code","8bda6ac1":"code","8bea9c37":"code","357a3498":"code","79c7b1a9":"code","09723269":"code","df29f3b1":"code","a569fde5":"code","13ffb9d9":"code","82df7aec":"code","0d5c1efe":"code","a16850a3":"code","29aaf888":"code","e6d9f79f":"code","d5e23228":"markdown","99891919":"markdown","6265c64d":"markdown","785938b5":"markdown","a146bd5a":"markdown","69eb2cab":"markdown","f5eb9b5c":"markdown","72340e5d":"markdown","f855ff3f":"markdown","57adbccb":"markdown","45806699":"markdown","8af7c1f7":"markdown","3046eb8e":"markdown","dd5014bf":"markdown","d300bd2a":"markdown","b248d592":"markdown","5f850128":"markdown","722dc445":"markdown","c374eac1":"markdown","6913b3fb":"markdown"},"source":{"324c71b5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PowerTransformer\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc, classification_report, plot_confusion_matrix\nimport pickle","4b9f6227":"df = pd.read_csv('..\/input\/ethereum-frauddetection-dataset\/transaction_dataset.csv', index_col=0)\nprint(df.shape)\ndf.head()","14b1a309":"# Ommit first two columns (Index, Adress)\ndf = df.iloc[:,2:]","c25d762b":"df.info()","fc7a1fea":"# Turn object variables into 'category' dtype for more computation efficiency\ncategories = df.select_dtypes('O').columns.astype('category')\ndf[categories]","185d9b54":"# Inspect categoricals\nfor i in df[categories].columns:\n    print(f'The categorical column --{i}-- has --{len(df[i].value_counts())}-- unique values')","685390dd":"# Inspect numericals\nnumericals = df.select_dtypes(include=['float','int']).columns\ndf[numericals].describe()","807cd3cc":"# Inspect features variance\ndf[numericals].var()","7b848ee1":"# Inspect target distribution\nprint(df['FLAG'].value_counts())\n\npie, ax = plt.subplots(figsize=[15,10])\nlabels = ['Non-fraud', 'Fraud']\ncolors = ['#f9ae35', '#f64e38']\nplt.pie(x = df['FLAG'].value_counts(), autopct='%.2f%%', explode=[0.02]*2, labels=labels, pctdistance=0.5, textprops={'fontsize': 14}, colors = colors)\nplt.title('Target distribution')\nplt.show()","a6bd2bae":"# Correlation matrix\ncorr = df.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, square=True)","fce403c4":"# Visualize missings pattern of the dataframe\nplt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(), cbar=False)\nplt.show()","ccb7c201":"# Drop the two categorical features\ndf.drop(df[categories], axis=1, inplace=True)","a20ca54c":"# Replace missings of numerical variables with median\ndf.fillna(df.median(), inplace=True)","e4e36a0d":"# Visualize missings pattern of the dataframe\nprint(df.shape)\nplt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(), cbar=False)\nplt.show()","f122aa23":"# Filtering the features with 0 variance\nno_var = df.var() == 0\nprint(df.var()[no_var])\nprint('\\n')\n\n# Drop features with 0 variance --- these features will not help in the performance of the model\ndf.drop(df.var()[no_var].index, axis = 1, inplace = True)\nprint(df.var())\nprint(df.shape)","84e81ab4":"df.info()","39651aac":"# Recheck the Correlation matrix\ncorr = df.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)","c2e9512e":"drop = ['total transactions (including tnx to create contract', 'total ether sent contracts', 'max val sent to contract', ' ERC20 avg val rec',\n        ' ERC20 avg val rec',' ERC20 max val rec', ' ERC20 min val rec', ' ERC20 uniq rec contract addr', 'max val sent', ' ERC20 avg val sent',\n        ' ERC20 min val sent', ' ERC20 max val sent', ' Total ERC20 tnxs', 'avg value sent to contract', 'Unique Sent To Addresses',\n        'Unique Received From Addresses', 'total ether received', ' ERC20 uniq sent token name', 'min value received', 'min val sent', ' ERC20 uniq rec addr' ]\ndf.drop(drop, axis=1, inplace=True)","241ba37d":"# Recheck the Correlation matrix\ncorr = df.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)","b723d6c1":"columns = df.columns\ncolumns","a369b97c":"# Investigate the distribution of our features using boxplots\nb=20\n\nfig, axes = plt.subplots(6, 3, figsize=(14, 14), constrained_layout =True)\nplt.subplots_adjust(wspace = 0.7, hspace=0.8)\nplt.suptitle(\"Distribution of features\",y=0.95, size=18, weight='bold')\n\nax = sns.boxplot(ax = axes[0,0], data=df, x=columns[1])\nax.set_title(f'Distribution of {columns[1]}')\n\nax1 = sns.boxplot(ax = axes[0,1], data=df, x=columns[2])\nax1.set_title(f'Distribution of {columns[2]}')\n\nax2 = sns.boxplot(ax = axes[0,2], data=df, x=columns[3])\nax2.set_title(f'Distribution of {columns[3]}')\n\nax3 = sns.boxplot(ax = axes[1,0], data=df, x=columns[4])\nax3.set_title(f'Distribution of {columns[4]}')\n\nax4 = sns.boxplot(ax = axes[1,1], data=df, x=columns[5])\nax4.set_title(f'Distribution of {columns[5]}')\n\nax5 = sns.boxplot(ax = axes[1,2], data=df, x=columns[6])\nax5.set_title(f'Distribution of {columns[6]}')\n\nax6 = sns.boxplot(ax = axes[2,0], data=df, x=columns[7])\nax6.set_title(f'Distribution of {columns[7]}')\n\nax7 = sns.boxplot(ax = axes[2,1], data=df, x=columns[8])\nax7.set_title(f'Distribution of {columns[8]}')\n\nax8 = sns.boxplot(ax = axes[2,2], data=df, x=columns[9])\nax8.set_title(f'Distribution of {columns[9]}')\n\nax9 = sns.boxplot(ax = axes[3,0], data=df, x=columns[10])\nax9.set_title(f'Distribution of {columns[10]}')\n \nax10 = sns.boxplot(ax = axes[3,1], data=df, x=columns[11])\nax10.set_title(f'Distribution of {columns[11]}')\n\nax11 = sns.boxplot(ax = axes[3,2], data=df, x=columns[12])\nax11.set_title(f'Distribution of {columns[12]}')\n \nax12 = sns.boxplot(ax = axes[4,0], data=df, x=columns[13])\nax12.set_title(f'Distribution of {columns[13]}')\n \nax13 = sns.boxplot(ax = axes[4,1], data=df, x=columns[14])\nax13.set_title(f'Distribution of {columns[14]}')\n \nax14 = sns.boxplot(ax = axes[4,2], data=df, x=columns[15])\nax14.set_title(f'Distribution of {columns[15]}')\n \nax15 = sns.boxplot(ax = axes[5,0], data=df, x=columns[16])\nax15.set_title(f'Distribution of {columns[16]}')\n \nax16 = sns.boxplot(ax = axes[5,1], data=df, x=columns[17])\nax16.set_title(f'Distribution of {columns[17]}')\n \nax17 = sns.boxplot(ax = axes[5,2], data=df, x=columns[18])\nax17.set_title(f'Distribution of {columns[18]}')\n\nplt.show()","b1976f26":"# Some features present a small distribution\nfor i in df.columns[1:]:\n    if len(df[i].value_counts()) < 10:\n        print(f'The column {i} has the following distribution: \\n{df[i].value_counts()}')\n        print('======================================')","9ba399f0":"drops = ['min value sent to contract', ' ERC20 uniq sent addr.1']\ndf.drop(drops, axis=1, inplace=True)\nprint(df.shape)\ndf.head()","856f2e9b":"y = df.iloc[:, 0]\nX = df.iloc[:, 1:]\nprint(X.shape, y.shape)","90c6d937":"# Split into training (80%) and testing set (20%)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","22233440":"# Normalize the training features\nnorm = PowerTransformer()\nnorm_train_f = norm.fit_transform(X_train)","8bda6ac1":"norm_df = pd.DataFrame(norm_train_f, columns=X_train.columns)\nnorm_df","8bea9c37":"# Distribution of features after log transformation\n\nb=20\n\nfig, axes = plt.subplots(6, 3, figsize=(14, 14), constrained_layout =True)\nplt.subplots_adjust(wspace = 0.7, hspace=0.8)\naxes[-1, -1].axis('off') # hide axes\naxes[-1, -2].axis('off') # hide axes\nplt.suptitle(\"Distribution of features after log\",y=0.95, family='Sherif', size=18, weight='bold')\n \nax = sns.boxplot(ax = axes[0,0], data=norm_df, x=norm_df.columns[0])\nax.set_title(f'Distribution of {norm_df.columns[0]}')\n \nax1 = sns.boxplot(ax = axes[0,1], data=norm_df, x=norm_df.columns[1])\nax1.set_title(f'Distribution of {norm_df.columns[1]}')\n \nax2 = sns.boxplot(ax = axes[0,2], data=norm_df, x=norm_df.columns[2])\nax2.set_title(f'Distribution of {norm_df.columns[2]}')\n \nax3 = sns.boxplot(ax = axes[1,0], data=norm_df, x=norm_df.columns[3])\nax3.set_title(f'Distribution of {norm_df.columns[3]}')\n \nax4 = sns.boxplot(ax = axes[1,1], data=norm_df, x=norm_df.columns[4])\nax4.set_title(f'Distribution of {norm_df.columns[4]}')\n \nax5 = sns.boxplot(ax = axes[1,2], data=norm_df, x=norm_df.columns[5])\nax5.set_title(f'Distribution of {norm_df.columns[5]}')\n \nax6 = sns.boxplot(ax = axes[2,0], data=norm_df, x=norm_df.columns[6])\nax6.set_title(f'Distribution of {norm_df.columns[6]}')\n \nax7 = sns.boxplot(ax = axes[2,1], data=norm_df, x=norm_df.columns[7])\nax7.set_title(f'Distribution of {norm_df.columns[7]}')\n \nax8 = sns.boxplot(ax = axes[2,2], data=norm_df, x=norm_df.columns[8])\nax8.set_title(f'Distribution of {norm_df.columns[8]}')\n \nax9 = sns.boxplot(ax = axes[3,0], data=norm_df, x=norm_df.columns[9])\nax9.set_title(f'Distribution of {norm_df.columns[9]}')\n\nax10 = sns.boxplot(ax = axes[3,1], data=norm_df, x=norm_df.columns[10])\nax10.set_title(f'Distribution of {norm_df.columns[10]}')\n \nax11 = sns.boxplot(ax = axes[3,2], data=norm_df, x=norm_df.columns[11])\nax11.set_title(f'Distribution of {norm_df.columns[11]}')\n \nax12 = sns.boxplot(ax = axes[4,0], data=norm_df, x=norm_df.columns[12])\nax12.set_title(f'Distribution of {norm_df.columns[12]}')\n \nax13 = sns.boxplot(ax = axes[4,1], data=norm_df, x=norm_df.columns[13])\nax13.set_title(f'Distribution of {norm_df.columns[13]}')\n \nax14 = sns.boxplot(ax = axes[4,2], data=norm_df, x=norm_df.columns[14])\nax14.set_title(f'Distribution of {norm_df.columns[14]}')\n \nax15 = sns.boxplot(ax = axes[5,0], data=norm_df, x=norm_df.columns[15])\nax15.set_title(f'Distribution of {norm_df.columns[15]}')\n\nplt.show()","357a3498":"oversample = SMOTE()\nprint(f'Shape of the training before SMOTE: {norm_train_f.shape, y_train.shape}')\n\nx_tr_resample, y_tr_resample = oversample.fit_resample(norm_train_f, y_train)\nprint(f'Shape of the training after SMOTE: {x_tr_resample.shape, y_tr_resample.shape}')","79c7b1a9":"# Target distribution before SMOTE\nnon_fraud = 0\nfraud = 0\n\nfor i in y_train:\n    if i == 0:\n        non_fraud +=1\n    else:\n        fraud +=1\n\n# Target distribution after SMOTE\nno = 0\nyes = 1\n\nfor j in y_tr_resample:\n    if j == 0:\n        no +=1\n    else:\n        yes +=1\n\n\nprint(f'BEFORE OVERSAMPLING \\n \\tNon-frauds: {non_fraud} \\n \\tFauds: {fraud}')\nprint(f'AFTER OVERSAMPLING \\n \\tNon-frauds: {no} \\n \\tFauds: {yes}')","09723269":"LR = LogisticRegression(random_state=42)\nLR.fit(x_tr_resample, y_tr_resample)\n\n# Transform test features\nnorm_test_f = norm.transform(X_test)\n\npreds = LR.predict(norm_test_f)","df29f3b1":"print(y_test.shape)\ny_test.value_counts()","a569fde5":"print(classification_report(y_test, preds))\nprint(confusion_matrix(y_test, preds))\nplot_confusion_matrix(LR, norm_test_f, y_test)","13ffb9d9":"RF = RandomForestClassifier(random_state=42)\nRF.fit(x_tr_resample, y_tr_resample)\npreds_RF = RF.predict(norm_test_f)\n\nprint(classification_report(y_test, preds_RF))\nprint(confusion_matrix(y_test, preds_RF))\nplot_confusion_matrix(RF, norm_test_f, y_test)","82df7aec":"xgb_c = xgb.XGBClassifier(random_state=42)\nxgb_c.fit(x_tr_resample, y_tr_resample)\npreds_xgb = xgb_c.predict(norm_test_f)\n\nprint(classification_report(y_test, preds_xgb))\nprint(confusion_matrix(y_test, preds_xgb))\nplot_confusion_matrix(xgb_c, norm_test_f, y_test)","0d5c1efe":"params_grid = {'learning_rate':[0.01, 0.1, 0.5],\n              'n_estimators':[100,200],\n              'subsample':[0.3, 0.5, 0.9],\n               'max_depth':[2,3,4],\n               'colsample_bytree':[0.3,0.5,0.7]}\n\ngrid = GridSearchCV(estimator=xgb_c, param_grid=params_grid, scoring='recall', cv = 10, verbose = 0)\n\ngrid.fit(x_tr_resample, y_tr_resample)\nprint(f'Best params found for XGBoost are: {grid.best_params_}')\nprint(f'Best recall obtained by the best params: {grid.best_score_}')","a16850a3":"preds_best_xgb = grid.best_estimator_.predict(norm_test_f)\nprint(classification_report(y_test, preds_best_xgb))\nprint(confusion_matrix(y_test, preds_best_xgb))\nplot_confusion_matrix(grid.best_estimator_, norm_test_f, y_test)","29aaf888":"# Plotting AUC for untuned XGB Classifier\nprobs = xgb_c.predict_proba(norm_test_f)\npred = probs[:,1]\nfpr, tpr, threshold = roc_curve(y_test, pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(12,8))\nplt.title('ROC for tuned XGB Classifier')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","e6d9f79f":"# Save the model for further use\npickle_out = open('XGB_FRAUD.pickle', 'wb')\npickle.dump(xgb_c, pickle_out)\npickle_out.close()","d5e23228":"The results of XGBClassifier shows that its doing slightly better than the RF when it comes to NON-FRAUD transactions, flagging 22 cases as fraud when they were actually non-fraud.\n\nWen it comes to identifiying FRAUDS, XGBClassifier missed 16 transactions out of 422, suggesting the best recall score.\n\nConsidering that, the XGBClassifier is the choice that we want.\n\nLet's see if we can improve thesis results.","99891919":"# <p style=\"font-family: Fantasy, fantasy; line-height: 3.3; font-size: 40px; letter-spacing: 5px; text-align: center; color: #4d4dff\">Detecting FRAUD transactions of ETHEREUM<\/p>\n![](https:\/\/miro.medium.com\/max\/1000\/1*Jg_EBfBl8yOa6r1i9pCMEw.png)","6265c64d":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Modeling<\/p>","785938b5":"**XGB Classifier**","a146bd5a":"It can be observed that the values of these two variables are mosty 0s. Thus, both features will be discarded since they will not be helpful for our model","69eb2cab":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Dataset information <\/p>\n\nThis dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency.\n\nHere is a description of the rows of the dataset:\n- Index: the index number of a row\n- Address: the address of the ethereum account\n- FLAG: whether the transaction is fraud or not\n- Avg min between sent tnx: Average time between sent transactions for account in minutes\n- Avg min between received tnx: Average time between received transactions for account in minutes\n- Time Diff between first and_last (Mins): Time difference between the first and last transaction\n- Sent_tnx: Total number of sent normal transactions\n- Received_tnx: Total number of received normal transactions\n- NumberofCreated_Contracts: Total Number of created contract transactions\n- UniqueReceivedFrom_Addresses: Total Unique addresses from which account received transaction\n- UniqueSentTo_Addresses20: Total Unique addresses from which account sent transactions\n- MinValueReceived: Minimum value in Ether ever received\n- MaxValueReceived: Maximum value in Ether ever received\n- AvgValueReceived5Average value in Ether ever received\n- MinValSent: Minimum value of Ether ever sent\n- MaxValSent: Maximum value of Ether ever sent\n- AvgValSent: Average value of Ether ever sent\n- MinValueSentToContract: Minimum value of Ether sent to a contract\n- MaxValueSentToContract: Maximum value of Ether sent to a contract\n- AvgValueSentToContract: Average value of Ether sent to contracts\n- TotalTransactions(IncludingTnxtoCreate_Contract): Total number of transactions\n- TotalEtherSent:Total Ether sent for account address\n- TotalEtherReceived: Total Ether received for account address\n- TotalEtherSent_Contracts: Total Ether sent to Contract addresses\n- TotalEtherBalance: Total Ether Balance following enacted transactions\n- TotalERC20Tnxs: Total number of ERC20 token transfer transactions\n- ERC20TotalEther_Received: Total ERC20 token received transactions in Ether\n- ERC20TotalEther_Sent: Total ERC20token sent transactions in Ether\n- ERC20TotalEtherSentContract: Total ERC20 token transfer to other contracts in Ether\n- ERC20UniqSent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n- ERC20UniqRec_Addr: Number of ERC20 token transactions received from Unique addresses\n- ERC20UniqRecContractAddr: Number of ERC20token transactions received from Unique contract addresses\n- ERC20AvgTimeBetweenSent_Tnx: Average time between ERC20 token sent transactions in minutes\n- ERC20AvgTimeBetweenRec_Tnx: Average time between ERC20 token received transactions in minutes\n- ERC20AvgTimeBetweenContract_Tnx: Average time ERC20 token between sent token transactions\n- ERC20MinVal_Rec: Minimum value in Ether received from ERC20 token transactions for account\n- ERC20MaxVal_Rec: Maximum value in Ether received from ERC20 token transactions for account\n- ERC20AvgVal_Rec: Average value in Ether received from ERC20 token transactions for account\n- ERC20MinVal_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n- ERC20MaxVal_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n- ERC20AvgVal_Sent: Average value in Ether sent from ERC20 token transactions for account\n- ERC20UniqSentTokenName: Number of Unique ERC20 tokens transferred\n- RC20UniqRecTokenName: Number of Unique ERC20 tokens received\n- ERC20MostSentTokenType: Most sent token for account via ERC20 transaction\n- ERC20MostRecTokenType: Most received token for account via ERC20 transactions","f5eb9b5c":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Data information & exploration<\/p>","72340e5d":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Data Reading<\/p>","f855ff3f":"Investigating the variance of the features, it was observed that there are some features with a variance = 0","57adbccb":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Data preparation<\/p>","45806699":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Libraries<\/p>","8af7c1f7":"**Logistic Regression**","3046eb8e":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Data cleaning<\/p>","dd5014bf":"**Random Forest Classifier**","d300bd2a":"**Hyperparameters tuning for XGB Classifier**","b248d592":"The RF classifier seems to produce more efective results\n - Both FP and FN are reduced considerably increasing the recall & precision\n - Using RF, the model fails to detect 20 FRAUD cases. \n\n\nLet's see if we can increase these results.","5f850128":"Considering the confusion matrix:\n - LR model, correctly identified 373 (TP) of FRAUD cases, out of 422 (P).\n - LR model flagged as FRAUD 171 (FP) out of 1547, when this cases were actually NON-FRAUD\n \n\nDealing with a fraud detection scenario, we care more about the transactions that were actualy FRAUDS, but which were treated as NON-FRAUD by our model (FN - 49) TYPE II ERROR\n\nTherby, let's try to increase the precision using other methods.\n","722dc445":"The confusion matrix shows no improvemet, the results are very similar with those obtained by the untuned model.","c374eac1":"<p style=\"font-family: Fantasy, fantasy; line-height: 1.3;font-size: 30px; letter-spacing: 5px;  color: #4d4dff\">Handling the imbalance<\/p>\nOversampling using SMOTE","6913b3fb":"Drop one of those highly correlated features\n    "}}