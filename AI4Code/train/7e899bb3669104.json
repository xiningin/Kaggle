{"cell_type":{"c4f78da1":"code","070e263d":"code","ee31acb1":"code","d29f6094":"code","a522c4ea":"code","34135338":"code","10f8958f":"code","e4156a91":"code","64adf56d":"code","6b654ef7":"code","fb47237b":"code","b707d819":"code","fe9aa9ee":"code","7b093447":"code","af83413d":"code","bba0d588":"code","d47ccfdb":"code","2d45089d":"markdown","2adb2949":"markdown","2e26ec44":"markdown","6b91b1f2":"markdown","94f6b1d8":"markdown","b990144a":"markdown","0e71ec19":"markdown","51d2715f":"markdown","8c315ab8":"markdown","e190c141":"markdown","003e697c":"markdown","060e41da":"markdown","b8b38e2a":"markdown"},"source":{"c4f78da1":"from fastai.text.all import *\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom wordcloud import WordCloud, STOPWORDS","070e263d":"data = Path('..\/input\/commonlitreadabilityprize')\ntrain = pd.read_csv(data\/'train.csv')\n# test = pd.read_csv(data\/'test.csv')\n# sample = pd.read_csv(data\/'sample_submission.csv')","ee31acb1":"train.info()","d29f6094":"length = [len(x.split(' ')) for x in train['excerpt']]\npx.density_heatmap(y=train['target'], x=length, labels=dict(x = 'Length of Text (words)', y = 'Reading Ease (Target)'))","a522c4ea":"train.corr()","34135338":"px.scatter(y=train['target'], x=train['standard_error'], marginal_x='histogram', marginal_y='histogram', opacity=0.2, labels = dict(x = 'Standard Error', y = 'Reading Ease (Target)'))","10f8958f":"train.describe()","e4156a91":"df = train.iloc[:500]\nstandard_errors = []","64adf56d":"stopwords = set(STOPWORDS)\nwc = WordCloud(background_color=\"white\", max_words=200, stopwords=stopwords, width = 1500, height = 750)\n\nplt.figure(figsize=(16,16))\nplt.imshow(wc.generate(' '.join(df['excerpt'])))","6b654ef7":"standard_errors.append(list(df['standard_error']))","fb47237b":"df = train.iloc[500:1000]\n\nplt.figure(figsize=(16,16))\nplt.imshow(wc.generate(' '.join(df['excerpt'])))","b707d819":"standard_errors.append(list(df['standard_error']))","fe9aa9ee":"df = train.iloc[-500:]\n\nplt.figure(figsize=(16,16))\nplt.imshow(wc.generate(' '.join(df['excerpt'])))","7b093447":"standard_errors.append(list(df['standard_error']))","af83413d":"df = train.iloc[-1000:-500]\n\nplt.figure(figsize=(16,16))\nplt.imshow(wc.generate(' '.join(df['excerpt'])))","bba0d588":"standard_errors.append(list(df['standard_error']))","d47ccfdb":"group_labels = ['Top 500 Toughest to Read', 'Top 500 - 1000 Toughest to Read', 'Top 500 Easiest to Read', 'Top 500 - 1000 Easiest To Read']\nfig = ff.create_distplot(standard_errors, group_labels, bin_size=0.007)\nfig.update_xaxes(range=[0.43, 0.65])","2d45089d":"# Easiest 500 To Read","2adb2949":"# Visualising The Texts With Highest Ease of Readability","2e26ec44":"- Almost no correalation between length of words and Ease of Readability is observed","6b91b1f2":"## Top 500 - 1000 Hardest To Read Texts","94f6b1d8":"## Top 500 Hardest To Read Texts","b990144a":"## Data Exploration","0e71ec19":"- ### Interesting results... this indicates the scores are the most spread out when the text is either very easy to read or very hard to read","51d2715f":"# Visualising The Texts With Lowest Ease of Readability","8c315ab8":"### Thanks for reading!\n### Any feedback is welcome","e190c141":"# Credits\n### Thanks a lot to https:\/\/www.kaggle.com\/ruchi798\/commonlit-readability-prize-eda-baseline for the wonderful notebook! I have tried to understand their wordcloud images and implement it with my own twist","003e697c":"## Easiest 500 - 1000 to Read","060e41da":"## Importing Libraries","b8b38e2a":"- Lots of null Values in url_legal and license columns"}}