{"cell_type":{"53122120":"code","4b495497":"code","45dec5aa":"code","316b2862":"code","cbac8e21":"code","1e949e74":"code","1400ecdc":"code","ba0f1b8d":"code","f4f6f703":"code","551fec56":"code","19626572":"code","3caff5ae":"code","9ae70ff3":"code","770c2eb0":"code","f3d55fa5":"code","eb02733b":"code","ea60a7d0":"code","81000878":"code","b529caeb":"code","e0fa45bf":"code","b28842c5":"code","bae8c243":"code","116e58b0":"code","1f42cfe8":"code","8d8a3696":"code","0f58a953":"code","8ad32710":"code","9ffbe125":"code","abf9b616":"code","5a68b242":"code","f5cf370f":"code","72274b5b":"code","b43a33af":"code","c502152d":"code","e4712a54":"code","a3f53902":"code","39571b86":"code","f3fc2d0e":"code","8f28d4c1":"code","807d18c3":"code","8507781d":"code","dffbb3d9":"code","470d9968":"code","4ba0e0da":"code","c43bd7e0":"code","71e5da92":"code","1478a77e":"code","fd5516e1":"code","49c3e2f6":"code","190f5820":"code","aed7704a":"code","fadfd9c1":"code","eb00bd72":"code","faae0138":"code","1ed9b2a5":"code","360dad19":"code","56459f31":"code","7f9374bf":"code","4d5a8f48":"code","647b45b4":"code","ec48fea3":"code","d0358674":"code","36629825":"code","dc7b9546":"code","a244d2bc":"code","7182dda5":"code","3ef50de0":"code","1d785bda":"code","4df55edf":"code","b47af272":"code","d60822c1":"code","e95c515b":"code","6d2e26b1":"code","822b88d3":"code","c96f16bc":"code","699d2da5":"code","e883c861":"code","1b6c9bcc":"code","2c0c0f59":"code","5c598dff":"code","2daf7e7b":"code","1958ba32":"code","986d2a32":"code","bef3eda4":"code","53eab558":"code","e4ea727e":"code","e424d13e":"code","59937f36":"code","740d3784":"code","8b0317ab":"code","67aab7bc":"code","64d0a258":"code","0eb46c74":"code","57313be4":"code","eaf72bfc":"code","e80ba498":"code","9d7e25f8":"code","d2aa6ac6":"code","e283fb3b":"code","73f69c26":"code","bec9b755":"code","3abb5e3b":"code","72bd17d2":"code","2aa86741":"code","d49c0f6a":"code","40015455":"code","b073dfd2":"code","046e0391":"code","5a899e51":"code","49364d8e":"code","5fb1befa":"code","bc0420c5":"code","f207a058":"code","239ad04e":"code","fb833961":"code","270d84ea":"code","f42ededd":"code","c3c87d1f":"code","650d6c72":"code","afda69f7":"code","50a8d1ba":"code","0e389de1":"code","ee1353ba":"code","0b0127f9":"code","a4fa3253":"code","9a72b30f":"code","b49042d4":"code","06c98247":"code","9aabb608":"code","a7bd2ed5":"code","65673784":"code","c18eb35c":"code","488f92bd":"code","8450403b":"code","85f659cb":"code","5770f951":"code","e67fd9ec":"code","e45ecb75":"code","d6203edd":"code","a61a7074":"markdown","63a2dcd2":"markdown","c915c2b8":"markdown","71ac62ec":"markdown","6b22ffc4":"markdown","7660d812":"markdown","c2ec8ff5":"markdown","1d69360c":"markdown","b38a4eac":"markdown","dd0c838b":"markdown","e9494c3b":"markdown","815dcc13":"markdown","71bd1331":"markdown","d5ef0bc7":"markdown","ed493179":"markdown","63537fbf":"markdown","334478b0":"markdown","2b97b9c6":"markdown","425548b7":"markdown","f25e1365":"markdown","0196ec2d":"markdown","c50d63a1":"markdown","5a789fe3":"markdown","9ab68359":"markdown","da864ffd":"markdown","a8692673":"markdown","c470ae35":"markdown","dcc25de1":"markdown","22c0e8c5":"markdown","dd5add5b":"markdown","9290dd74":"markdown","9d5f93d1":"markdown","197b1938":"markdown","8137f578":"markdown","cc741a6d":"markdown","7f17268b":"markdown","17c754ba":"markdown","36fe87f8":"markdown","cbd64832":"markdown","8395ac9d":"markdown","410e1500":"markdown","6e1af288":"markdown","14e637d0":"markdown","146dcb6d":"markdown","909f35ab":"markdown","d453dfc3":"markdown","7545ec59":"markdown","9ea43d33":"markdown","89297ca0":"markdown","bbdb856c":"markdown","3687b93b":"markdown","8a0c0f38":"markdown","881f243d":"markdown","ff63fbaa":"markdown","5b9b5e58":"markdown","e2a20b25":"markdown","ea390a81":"markdown","86cc2b61":"markdown","e970bac2":"markdown","ed9fda24":"markdown","6137b708":"markdown"},"source":{"53122120":"#Load the required packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","4b495497":"#Plot styling\nimport seaborn as sns; sns.set()  # for plot styling\n%matplotlib inline","45dec5aa":"# Import stats from scipy\nfrom scipy import stats","316b2862":"#Read the csv file\norginal_dataset=pd.read_csv('..\/input\/bank-marketing\/bank_marketing_part1_Data.csv')","cbac8e21":"orginal_dataset.head()","1e949e74":"orginal_dataset.tail()","1400ecdc":"orginal_dataset.info()","ba0f1b8d":"### data dimensions\n\norginal_dataset.shape","f4f6f703":"### Checking for Missing Values\n\norginal_dataset.isnull().sum()","551fec56":"## Intital descriptive analysis of the data\n\norginal_dataset.describe(percentiles=[.25,0.50,0.75,0.90]).T","19626572":"print('Range of values: ', orginal_dataset['spending'].max()-orginal_dataset['spending'].min())","3caff5ae":"#Central values \nprint('Minimum spending: ', orginal_dataset['spending'].min())\nprint('Maximum spending: ',orginal_dataset['spending'].max())\nprint('Mean value: ', orginal_dataset['spending'].mean())\nprint('Median value: ',orginal_dataset['spending'].median())\nprint('Standard deviation: ', orginal_dataset['spending'].std())\nprint('Null values: ',orginal_dataset['spending'].isnull().any())","9ae70ff3":"#Quartiles\n\nQ1=orginal_dataset['spending'].quantile(q=0.25)\nQ3=orginal_dataset['spending'].quantile(q=0.75)\nprint('spending - 1st Quartile (Q1) is: ', Q1)\nprint('spending - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of spending is ', stats.iqr(orginal_dataset['spending']))","770c2eb0":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in spending: ', L_outliers)\nprint('Upper outliers in spending: ', U_outliers)","f3d55fa5":"print('Number of outliers in spending upper : ', orginal_dataset[orginal_dataset['spending']>24.8575]['spending'].count())\nprint('Number of outliers in spending lower : ', orginal_dataset[orginal_dataset['spending']<4.717499]['spending'].count())\nprint('% of Outlier in spending upper: ',round(orginal_dataset[orginal_dataset['spending']>24.8575]['spending'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in spending lower: ',round(orginal_dataset[orginal_dataset['spending']<4.717499]['spending'].count()*100\/len(orginal_dataset)), '%')","eb02733b":"plt.title('spending')\nsns.boxplot(orginal_dataset['spending'],orient='horizondal',color='purple')","ea60a7d0":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='spending',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('spending', fontsize=15)\nax1.set_title('Distribution of spending', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['spending'],ax=ax2)\nax2.set_xlabel('spending', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['spending'])\nax3.set_xlabel('spending', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","81000878":"print('Range of values: ', orginal_dataset['advance_payments'].max()-orginal_dataset['advance_payments'].min())","b529caeb":"#Central values \nprint('Minimum advance_payments: ', orginal_dataset['advance_payments'].min())\nprint('Maximum advance_payments: ',orginal_dataset['advance_payments'].max())\nprint('Mean value: ', orginal_dataset['advance_payments'].mean())\nprint('Median value: ',orginal_dataset['advance_payments'].median())\nprint('Standard deviation: ', orginal_dataset['advance_payments'].std())\nprint('Null values: ',orginal_dataset['advance_payments'].isnull().any())","e0fa45bf":"#Quartiles\n\nQ1=orginal_dataset['advance_payments'].quantile(q=0.25)\nQ3=orginal_dataset['advance_payments'].quantile(q=0.75)\nprint('advance_payments - 1st Quartile (Q1) is: ', Q1)\nprint('advance_payments - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of advance_payments is ', stats.iqr(orginal_dataset['advance_payments']))","b28842c5":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in advance_payments: ', L_outliers)\nprint('Upper outliers in advance_payments: ', U_outliers)","bae8c243":"print('Number of outliers in advance_payments upper : ', orginal_dataset[orginal_dataset['advance_payments']>19.1125]['advance_payments'].count())\nprint('Number of outliers in advance_payments lower : ', orginal_dataset[orginal_dataset['advance_payments']<10.052499]['advance_payments'].count())\nprint('% of Outlier in advance_payments upper: ',round(orginal_dataset[orginal_dataset['advance_payments']>19.1125]['advance_payments'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in advance_payments lower: ',round(orginal_dataset[orginal_dataset['advance_payments']<10.052499]['advance_payments'].count()*100\/len(orginal_dataset)), '%')","116e58b0":"plt.title('advance_payments')\nsns.boxplot(orginal_dataset['advance_payments'],orient='horizondal',color='purple')","1f42cfe8":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='advance_payments',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('advance_payments', fontsize=15)\nax1.set_title('Distribution of advance_payments', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['advance_payments'],ax=ax2)\nax2.set_xlabel('advance_payments', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['advance_payments'])\nax3.set_xlabel('advance_payments', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","8d8a3696":"print('Range of values: ', orginal_dataset['probability_of_full_payment'].max()-orginal_dataset['probability_of_full_payment'].min())","0f58a953":"#Central values \nprint('Minimum probability_of_full_payment ', orginal_dataset['probability_of_full_payment'].min())\nprint('Maximum probability_of_full_payment: ',orginal_dataset['probability_of_full_payment'].max())\nprint('Mean value: ', orginal_dataset['probability_of_full_payment'].mean())\nprint('Median value: ',orginal_dataset['probability_of_full_payment'].median())\nprint('Standard deviation: ', orginal_dataset['probability_of_full_payment'].std())\nprint('Null values: ',orginal_dataset['probability_of_full_payment'].isnull().any())","8ad32710":"#Quartiles\n\nQ1=orginal_dataset['probability_of_full_payment'].quantile(q=0.25)\nQ3=orginal_dataset['probability_of_full_payment'].quantile(q=0.75)\nprint('probability_of_full_payment - 1st Quartile (Q1) is: ', Q1)\nprint('probability_of_full_payment - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of probability_of_full_payment is ', stats.iqr(orginal_dataset['probability_of_full_payment']))","9ffbe125":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in probability_of_full_payment: ', L_outliers)\nprint('Upper outliers in probability_of_full_payment: ', U_outliers)","abf9b616":"print('Number of outliers in probability_of_full_payment upper : ', orginal_dataset[orginal_dataset['probability_of_full_payment']>0.9340875]['probability_of_full_payment'].count())\nprint('Number of outliers in probability_of_full_payment lower : ', orginal_dataset[orginal_dataset['probability_of_full_payment']<0.8105875]['probability_of_full_payment'].count())\nprint('% of Outlier in probability_of_full_payment upper: ',round(orginal_dataset[orginal_dataset['probability_of_full_payment']>0.9340875]['probability_of_full_payment'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in probability_of_full_payment lower: ',round(orginal_dataset[orginal_dataset['probability_of_full_payment']<0.8105875]['probability_of_full_payment'].count()*100\/len(orginal_dataset)), '%')","5a68b242":"plt.title('probability_of_full_payment')\nsns.boxplot(orginal_dataset['probability_of_full_payment'],orient='horizondal',color='purple')","f5cf370f":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='probability_of_full_payment',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('probability_of_full_payment', fontsize=15)\nax1.set_title('Distribution of probability_of_full_payment', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['probability_of_full_payment'],ax=ax2)\nax2.set_xlabel('probability_of_full_payment', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['probability_of_full_payment'])\nax3.set_xlabel('probability_of_full_payment', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","72274b5b":"print('Range of values: ', orginal_dataset['current_balance'].max()-orginal_dataset['current_balance'].min())","b43a33af":"#Central values \nprint('Minimum current_balance: ', orginal_dataset['current_balance'].min())\nprint('Maximum current_balance: ',orginal_dataset['current_balance'].max())\nprint('Mean value: ', orginal_dataset['current_balance'].mean())\nprint('Median value: ',orginal_dataset['current_balance'].median())\nprint('Standard deviation: ', orginal_dataset['current_balance'].std())\nprint('Null values: ',orginal_dataset['current_balance'].isnull().any())","c502152d":"#Quartiles\n\nQ1=orginal_dataset['current_balance'].quantile(q=0.25)\nQ3=orginal_dataset['current_balance'].quantile(q=0.75)\nprint('current_balance - 1st Quartile (Q1) is: ', Q1)\nprint('current_balance - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of current_balance is ', stats.iqr(orginal_dataset['current_balance']))","e4712a54":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in current_balance: ', L_outliers)\nprint('Upper outliers in current_balance: ', U_outliers)","a3f53902":"print('Number of outliers in current_balance upper : ', orginal_dataset[orginal_dataset['current_balance']>7.056000000000001]['current_balance'].count())\nprint('Number of outliers in current_balance lower : ', orginal_dataset[orginal_dataset['current_balance']<4.186]['current_balance'].count())\nprint('% of Outlier in current_balance upper: ',round(orginal_dataset[orginal_dataset['current_balance']>7.056000000000001]['current_balance'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in current_balance lower: ',round(orginal_dataset[orginal_dataset['current_balance']<4.186]['current_balance'].count()*100\/len(orginal_dataset)), '%')","39571b86":"plt.title('current_balance')\nsns.boxplot(orginal_dataset['current_balance'],orient='horizondal',color='purple')","f3fc2d0e":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='current_balance',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('current_balance', fontsize=15)\nax1.set_title('Distribution of current_balance', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['current_balance'],ax=ax2)\nax2.set_xlabel('current_balance', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['current_balance'])\nax3.set_xlabel('current_balance', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","8f28d4c1":"print('Range of values: ', orginal_dataset['credit_limit'].max()-orginal_dataset['credit_limit'].min())","807d18c3":"#Central values \nprint('Minimum credit_limit: ', orginal_dataset['credit_limit'].min())\nprint('Maximum credit_limit: ',orginal_dataset['credit_limit'].max())\nprint('Mean value: ', orginal_dataset['credit_limit'].mean())\nprint('Median value: ',orginal_dataset['credit_limit'].median())\nprint('Standard deviation: ', orginal_dataset['credit_limit'].std())\nprint('Null values: ',orginal_dataset['credit_limit'].isnull().any())","8507781d":"#Quartiles\n\nQ1=orginal_dataset['credit_limit'].quantile(q=0.25)\nQ3=orginal_dataset['credit_limit'].quantile(q=0.75)\nprint('credit_limit - 1st Quartile (Q1) is: ', Q1)\nprint('credit_limit - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of credit_limit is ', stats.iqr(orginal_dataset['credit_limit']))","dffbb3d9":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in credit_limit: ', L_outliers)\nprint('Upper outliers in credit_limit: ', U_outliers)","470d9968":"print('Number of outliers in credit_limit upper : ', orginal_dataset[orginal_dataset['credit_limit']>4.488375]['credit_limit'].count())\nprint('Number of outliers in credit_limit lower : ', orginal_dataset[orginal_dataset['credit_limit']<2.017375]['credit_limit'].count())\nprint('% of Outlier in credit_limit upper: ',round(orginal_dataset[orginal_dataset['credit_limit']>4.488375]['credit_limit'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in credit_limit lower: ',round(orginal_dataset[orginal_dataset['credit_limit']<2.017375]['credit_limit'].count()*100\/len(orginal_dataset)), '%')","4ba0e0da":"plt.title('credit_limit')\nsns.boxplot(orginal_dataset['credit_limit'],orient='horizondal',color='purple')","c43bd7e0":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='credit_limit',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('credit_limit', fontsize=15)\nax1.set_title('Distribution of credit_limit', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['credit_limit'],ax=ax2)\nax2.set_xlabel('credit_limit', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['credit_limit'])\nax3.set_xlabel('credit_limit', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","71e5da92":"print('Range of values: ', orginal_dataset['min_payment_amt'].max()-orginal_dataset['min_payment_amt'].min())","1478a77e":"#Central values \nprint('Minimum min_payment_amt: ', orginal_dataset['min_payment_amt'].min())\nprint('Maximum min_payment_amt: ',orginal_dataset['min_payment_amt'].max())\nprint('Mean value: ', orginal_dataset['min_payment_amt'].mean())\nprint('Median value: ',orginal_dataset['min_payment_amt'].median())\nprint('Standard deviation: ', orginal_dataset['min_payment_amt'].std())\nprint('Null values: ',orginal_dataset['min_payment_amt'].isnull().any())","fd5516e1":"#Quartiles\n\nQ1=orginal_dataset['min_payment_amt'].quantile(q=0.25)\nQ3=orginal_dataset['min_payment_amt'].quantile(q=0.75)\nprint('min_payment_amt - 1st Quartile (Q1) is: ', Q1)\nprint('min_payment_amt - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of min_payment_amt is ', stats.iqr(orginal_dataset['min_payment_amt']))","49c3e2f6":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in min_payment_amt: ', L_outliers)\nprint('Upper outliers in min_payment_amt: ', U_outliers)","190f5820":"print('Number of outliers in min_payment_amt upper : ', orginal_dataset[orginal_dataset['min_payment_amt']>8.079625]['min_payment_amt'].count())\nprint('Number of outliers in min_payment_amt lower : ', orginal_dataset[orginal_dataset['min_payment_amt']<-0.749375]['min_payment_amt'].count())\nprint('% of Outlier in min_payment_amt upper: ',round(orginal_dataset[orginal_dataset['min_payment_amt']>8.079625]['min_payment_amt'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in min_payment_amt lower: ',round(orginal_dataset[orginal_dataset['min_payment_amt']<-0.749375]['min_payment_amt'].count()*100\/len(orginal_dataset)), '%')","aed7704a":"plt.title('min_payment_amt')\nsns.boxplot(orginal_dataset['min_payment_amt'],orient='horizondal',color='purple')","fadfd9c1":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='min_payment_amt',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('min_payment_amt', fontsize=15)\nax1.set_title('Distribution of min_payment_amt', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['min_payment_amt'],ax=ax2)\nax2.set_xlabel('min_payment_amt', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['min_payment_amt'])\nax3.set_xlabel('min_payment_amt', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","eb00bd72":"print('Range of values: ', orginal_dataset['max_spent_in_single_shopping'].max()-orginal_dataset['max_spent_in_single_shopping'].min())","faae0138":"#Central values \nprint('Minimum max_spent_in_single_shopping: ', orginal_dataset['max_spent_in_single_shopping'].min())\nprint('Maximum max_spent_in_single_shoppings: ',orginal_dataset['max_spent_in_single_shopping'].max())\nprint('Mean value: ', orginal_dataset['max_spent_in_single_shopping'].mean())\nprint('Median value: ',orginal_dataset['max_spent_in_single_shopping'].median())\nprint('Standard deviation: ', orginal_dataset['max_spent_in_single_shopping'].std())\nprint('Null values: ',orginal_dataset['max_spent_in_single_shopping'].isnull().any())","1ed9b2a5":"#Quartiles\n\nQ1=orginal_dataset['max_spent_in_single_shopping'].quantile(q=0.25)\nQ3=orginal_dataset['max_spent_in_single_shopping'].quantile(q=0.75)\nprint('max_spent_in_single_shopping - 1st Quartile (Q1) is: ', Q1)\nprint('max_spent_in_single_shopping - 3st Quartile (Q3) is: ', Q3)\nprint('Interquartile range (IQR) of max_spent_in_single_shopping is ', stats.iqr(orginal_dataset['max_spent_in_single_shopping']))","360dad19":"#Outlier detection from Interquartile range (IQR) in original data\n\n# IQR=Q3-Q1\n#lower 1.5*IQR whisker i.e Q1-1.5*IQR\n#upper 1.5*IQR whisker i.e Q3+1.5*IQR\nL_outliers=Q1-1.5*(Q3-Q1)\nU_outliers=Q3+1.5*(Q3-Q1)\nprint('Lower outliers in max_spent_in_single_shopping: ', L_outliers)\nprint('Upper outliers in max_spent_in_single_shopping: ', U_outliers)","56459f31":"print('Number of outliers in max_spent_in_single_shopping upper : ', orginal_dataset[orginal_dataset['max_spent_in_single_shopping']>7.125000000000002]['max_spent_in_single_shopping'].count())\nprint('Number of outliers in max_spent_in_single_shopping lower : ', orginal_dataset[orginal_dataset['max_spent_in_single_shopping']<3.796999999999999]['max_spent_in_single_shopping'].count())\nprint('% of Outlier in max_spent_in_single_shopping upper: ',round(orginal_dataset[orginal_dataset['max_spent_in_single_shopping']>7.125000000000002]['max_spent_in_single_shopping'].count()*100\/len(orginal_dataset)), '%')\nprint('% of Outlier in max_spent_in_single_shopping lower: ',round(orginal_dataset[orginal_dataset['max_spent_in_single_shopping']<3.796999999999999]['max_spent_in_single_shopping'].count()*100\/len(orginal_dataset)), '%')","7f9374bf":"plt.title('max_spent_in_single_shopping')\nsns.boxplot(orginal_dataset['max_spent_in_single_shopping'],orient='horizondal',color='purple')","4d5a8f48":"fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))\n\n#boxplot\nsns.boxplot(x='max_spent_in_single_shopping',data=orginal_dataset,orient='v',ax=ax1)\nax1.set_ylabel('max_spent_in_single_shopping', fontsize=15)\nax1.set_title('Distribution of max_spent_in_single_shopping', fontsize=15)\nax1.tick_params(labelsize=15)\n\n#distplot\nsns.distplot(orginal_dataset['max_spent_in_single_shopping'],ax=ax2)\nax2.set_xlabel('max_spent_in_single_shopping', fontsize=15)\nax2.tick_params(labelsize=15)\n\n#histogram\nax3.hist(orginal_dataset['max_spent_in_single_shopping'])\nax3.set_xlabel('max_spent_in_single_shopping', fontsize=15)\nax3.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","647b45b4":"# Let's us only plot the distributions of independent attributes\norginal_dataset.hist(figsize=(12,16),layout=(4,2));","ec48fea3":"# Let's check the skewness values quantitatively\norginal_dataset.skew().sort_values(ascending=False)","d0358674":"# distplot combines the matplotlib.hist function with seaborn kdeplot()\n# KDE Plot represents the Kernel Density Estimate\n# KDE is used for visualizing the Probability Density of a continuous variable. \n# KDE demonstrates the probability density at different values in a continuous variable. \n\n\nplt.figure(figsize=(10,50))\nfor i in range(len(orginal_dataset.columns)):\n  plt.subplot(17, 1, i+1)\n  sns.distplot(orginal_dataset[orginal_dataset.columns[i]], kde_kws={\"color\": \"b\", \"lw\": 3, \"label\": \"KDE\"}, hist_kws={\"color\": \"g\"})\n  plt.title(orginal_dataset.columns[i])\n\nplt.tight_layout()","36629825":"sns.pairplot(orginal_dataset,diag_kind='kde');","dc7b9546":"#correlation matrix\n\norginal_dataset.corr().T","a244d2bc":"#creating a heatmap for better visualization\nplt.figure(figsize=(10,8))\nsns.heatmap(orginal_dataset.corr(),annot=True,fmt=\".2f\",cmap=\"viridis\")\nplt.show()","7182dda5":"# Let us see the significant correlation either negative or positive among independent attributes..\nc = orginal_dataset.corr().abs() # Since there may be positive as well as -ve correlation\ns = c.unstack() # \nso = s.sort_values(ascending=False) # Sorting according to the correlation\nso=so[(so<1) & (so>0.3)].drop_duplicates().to_frame() # Due to symmetry.. dropping duplicate entries.\nso.columns = ['correlation']\nso","3ef50de0":"clean_dataset=orginal_dataset.copy()","1d785bda":"def check_outliers(data):\n    vData_num = data.loc[:,data.columns != 'class']\n    Q1 = vData_num.quantile(0.25)\n    Q3 = vData_num.quantile(0.75)\n    IQR = Q3 - Q1\n    count = 0\n    # checking for outliers, True represents outlier\n    vData_num_mod = ((vData_num < (Q1 - 1.5 * IQR)) |(vData_num > (Q3 + 1.5 * IQR)))\n    #iterating over columns to check for no.of outliers in each of the numerical attributes.\n    for col in vData_num_mod:\n        if(1 in vData_num_mod[col].value_counts().index):\n            print(\"No. of outliers in %s: %d\" %( col, vData_num_mod[col].value_counts().iloc[1]))\n            count += 1\n    print(\"\\n\\nNo of attributes with outliers are :\", count)\n    \ncheck_outliers(orginal_dataset)","4df55edf":"check_outliers(clean_dataset)","b47af272":"# Let us check presence of outliers\nplt.figure(figsize=(18,14))\nbox = sns.boxplot(data=clean_dataset)\nbox.set_xticklabels(labels=box.get_xticklabels(),rotation=90);","d60822c1":"plt.title('probability_of_full_payment')\nsns.boxplot(clean_dataset['probability_of_full_payment'],orient='horizondal',color='purple')","e95c515b":"# prior to scaling \nplt.plot(clean_dataset)\nplt.show()","6d2e26b1":"# Scaling the attributes.\n\nfrom scipy.stats import zscore\nclean_dataset_Scaled=orginal_dataset.apply(zscore)\nclean_dataset_Scaled.head()","822b88d3":"#after scaling\nplt.plot(clean_dataset_Scaled)\nplt.show()","c96f16bc":"from scipy.cluster.hierarchy import dendrogram, linkage","699d2da5":"link_method = linkage(clean_dataset_Scaled, method = 'average')","e883c861":"dend = dendrogram(link_method)","1b6c9bcc":"dend = dendrogram(link_method,\n                 truncate_mode='lastp',\n                 p = 10)","2c0c0f59":"dend = dendrogram(link_method,\n                 truncate_mode='lastp',\n                 p = 25)","5c598dff":"from scipy.cluster.hierarchy import fcluster","2daf7e7b":"# Set criterion as maxclust,then create 3 clusters, and store the result in another object 'clusters'\n\nclusters_3 = fcluster(link_method, 3, criterion='maxclust')\nclusters_3","1958ba32":"cluster3_dataset=orginal_dataset.copy()","986d2a32":"cluster3_dataset['clusters-3'] = clusters_3","bef3eda4":"cluster3_dataset.head()","53eab558":"cluster3_dataset['clusters-3'].value_counts().sort_index()","e4ea727e":"aggdata=cluster3_dataset.groupby('clusters-3').mean()\naggdata['Freq']=cluster3_dataset['clusters-3'].value_counts().sort_index()\naggdata\n","e424d13e":"wardlink = linkage(clean_dataset_Scaled, method = 'ward')","59937f36":"dend_wardlink = dendrogram(wardlink)","740d3784":"dend_wardlink = dendrogram(wardlink,\n                 truncate_mode='lastp',\n                 p = 10,\n                 )","8b0317ab":"clusters_wdlk_3 = fcluster(wardlink, 3, criterion='maxclust')\nclusters_wdlk_3","67aab7bc":"cluster_w_3_dataset=orginal_dataset.copy()","64d0a258":"cluster_w_3_dataset['clusters-3'] = clusters_wdlk_3","0eb46c74":"cluster_w_3_dataset.head()","57313be4":"cluster_w_3_dataset['clusters-3'].value_counts().sort_index()","eaf72bfc":"aggdata_w=cluster_w_3_dataset.groupby('clusters-3').mean()\naggdata_w['Freq']=cluster_w_3_dataset['clusters-3'].value_counts().sort_index()\naggdata_w","e80ba498":"from sklearn.cluster import KMeans ","9d7e25f8":"k_means = KMeans(n_clusters = 1)\nk_means.fit(clean_dataset_Scaled)\nk_means.inertia_","d2aa6ac6":"k_means = KMeans(n_clusters = 2)\nk_means.fit(clean_dataset_Scaled)\nk_means.inertia_","e283fb3b":"k_means = KMeans(n_clusters = 3)\nk_means.fit(clean_dataset_Scaled)\nk_means.inertia_","73f69c26":"k_means = KMeans(n_clusters = 4)\nk_means.fit(clean_dataset_Scaled)\nk_means.inertia_","bec9b755":"wss =[] ","3abb5e3b":"    for i in range(1,11):\n        KM = KMeans(n_clusters=i)\n        KM.fit(clean_dataset_Scaled)\n        wss.append(KM.inertia_)","72bd17d2":"wss","2aa86741":"plt.plot(range(1,11), wss)\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"Inertia in the cluster\")\nplt.show()","d49c0f6a":"k_means_4 = KMeans(n_clusters = 4)\nk_means_4.fit(clean_dataset_Scaled)\nlabels_4 = k_means_4.labels_","40015455":"kmeans4_dataset=orginal_dataset.copy()","b073dfd2":"kmeans4_dataset[\"Clus_kmeans\"] = labels_4\nkmeans4_dataset.head(5)","046e0391":"from sklearn.metrics import silhouette_samples, silhouette_score","5a899e51":"silhouette_score(clean_dataset_Scaled,labels_4)","49364d8e":"from sklearn import metrics","5fb1befa":"scores = []\nk_range = range(2, 11)\n\nfor k in k_range:\n    km = KMeans(n_clusters=k, random_state=2)\n    km.fit(clean_dataset_Scaled)\n    scores.append(metrics.silhouette_score(clean_dataset_Scaled, km.labels_))\n    \nscores","bc0420c5":"#plotting the sc scores\nplt.plot(k_range,scores)\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()","f207a058":"sil_width = silhouette_samples(clean_dataset_Scaled,labels_4)","239ad04e":"kmeans4_dataset[\"sil_width\"] = sil_width\nkmeans4_dataset.head(5)","fb833961":"silhouette_samples(clean_dataset_Scaled,labels_4).min()","270d84ea":"km_3 = KMeans(n_clusters=3,random_state=123)","f42ededd":"#fitting the Kmeans \nkm_3.fit(clean_dataset_Scaled)\nkm_3.labels_","c3c87d1f":"#proportion of labels classified\n\npd.Series(km_3.labels_).value_counts()","650d6c72":"kmeans1_dataset=orginal_dataset.copy()","afda69f7":"# Fitting K-Means to the dataset\n\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(clean_dataset_Scaled)\n\n#beginning of  the cluster numbering with 1 instead of 0\n\ny_kmeans1=y_kmeans\ny_kmeans1=y_kmeans+1\n\n# New Dataframe called cluster\n\ncluster = pd.DataFrame(y_kmeans1)\n\n# Adding cluster to the Dataset1\n\nkmeans1_dataset['cluster'] = cluster\n#Mean of clusters\n\nkmeans_mean_cluster = pd.DataFrame(round(kmeans1_dataset.groupby('cluster').mean(),1))\nkmeans_mean_cluster","50a8d1ba":"def ClusterPercentage(datafr,name):\n    \"\"\"Common utility function to calculate the percentage and size of cluster\"\"\"\n    \n    size = pd.Series(datafr[name].value_counts().sort_index())\n    percent = pd.Series(round(datafr[name].value_counts()\/datafr.shape[0] * 100,2)).sort_index()\n\n    size_df = pd.concat([size, percent],axis=1)\n    size_df.columns = [\"Cluster_Size\",\"Cluster_Percentage\"]\n    \n    return(size_df)","0e389de1":"ClusterPercentage(kmeans1_dataset,\"cluster\")","ee1353ba":"#transposing the cluster\ncluster_3_T = kmeans_mean_cluster.T","0b0127f9":"cluster_3_T","a4fa3253":"km_4 = KMeans(n_clusters=4,random_state=123)","9a72b30f":"#fitting the Kmeans \nkm_4.fit(clean_dataset_Scaled)\nkm_4.labels_","b49042d4":"#proportion of labels classified\n\npd.Series(km_4.labels_).value_counts()","06c98247":"kmeans14_dataset=orginal_dataset.copy()","9aabb608":"# Fitting K-Means to the dataset\n\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(clean_dataset_Scaled)\n\n#beginning of  the cluster numbering with 1 instead of 0\n\ny_kmeans1=y_kmeans\ny_kmeans1=y_kmeans+1\n\n# New Dataframe called cluster\n\ncluster = pd.DataFrame(y_kmeans1)\n\n# Adding cluster to the Dataset1\n\nkmeans14_dataset['cluster'] = cluster\n#Mean of clusters\n\nkmeans_mean_cluster = pd.DataFrame(round(kmeans14_dataset.groupby('cluster').mean(),1))\nkmeans_mean_cluster","a7bd2ed5":"ClusterPercentage(kmeans14_dataset,\"cluster\")","65673784":"#transposing the cluster\ncluster_4_T = kmeans_mean_cluster.T","c18eb35c":"cluster_4_T","488f92bd":"kmeans15_dataset=orginal_dataset.copy()","8450403b":"# Fitting K-Means to the dataset\n\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(clean_dataset_Scaled)\n\n#beginning of  the cluster numbering with 1 instead of 0\n\ny_kmeans1=y_kmeans\ny_kmeans1=y_kmeans+1\n\n# New Dataframe called cluster\n\ncluster = pd.DataFrame(y_kmeans1)\n\n# Adding cluster to the Dataset1\n\nkmeans15_dataset['cluster'] = cluster\n#Mean of clusters\n\nkmeans_mean_cluster = pd.DataFrame(round(kmeans15_dataset.groupby('cluster').mean(),1))\nkmeans_mean_cluster","85f659cb":"ClusterPercentage(kmeans15_dataset,\"cluster\")","5770f951":"#transposing the cluster\ncluster_5_T = kmeans_mean_cluster.T","e67fd9ec":"cluster_5_T","e45ecb75":"cluster_3_T","d6203edd":"aggdata_w.T","a61a7074":"# 3 group cluster via Kmeans","63a2dcd2":"##### Importing fcluster module to create clusters","c915c2b8":"### Checking the data","71ac62ec":"## Group 1 : High Spending Group\n    \n    - Giving any reward points might increase their purchases.\n    - maximum max_spent_in_single_shopping is high for this group, so can be offered discount\/offer on next transactions upon full payment\n    - Increase there credit limit and \n    - Increase spending habits\n    - Give loan against the credit card, as they are customers with good repayment record.\n    - Tie up with luxary brands, which will drive more one_time_maximun spending\n    \n    ","6b22ffc4":"#### 5 cluster","7660d812":"##### Observation\nThough we did treated the outlier, we still see one as per the boxplot, it is okay, as it is no extrme and on lower band.","c2ec8ff5":"# 1.3 Apply hierarchical clustering to scaled data. Identify the number of optimum clusters using Dendrogram and briefly describe them","1d69360c":"##### Cluster Frequency","b38a4eac":"# Import the libraries","dd0c838b":"##### Choosing average linkage method","e9494c3b":"# Univariate analysis","815dcc13":"### advance_payments variable","71bd1331":"# Check for multicollinearity","d5ef0bc7":"##### Scaling needs to be done as the values of the variables are different.\n\n##### spending, advance_payments are in different values and this may get more weightage. \n\n##### Also have shown below the plot of the data prior and after scaling.\n\n##### Scaling will have all the values in the relative same range.\n\n##### I have used zscore to standarised the data to relative same scale -3 to +3.","ed493179":"##### Insights\n\nFrom SC Score, the number of optimal clusters could be 3 or 4","63537fbf":"## Group 3 : Medium Spending Group\n    \n    - They are potential target customers who are paying bills and doing purchases and maintaining comparatively good credit score. So we can increase credit limit or can lower down interest rate. \n    - Promote premium cards\/loyality cars to increase transcations.\n    - Increase spending habits by trying with premium ecommerce sites, travel portal, travel airlines\/hotel, as this will encourge them to spend more\n     ","334478b0":"##### Observations\n\n    - Credit limit average is around $3.258(10000s)\n    - Distrubtion is skewed to right tail for all the variable execpt probability_of_full_payment variable, which has left tail\n   \n    ","2b97b9c6":"##### max_spent_in_single_shopping variable","425548b7":"### Spending variable","f25e1365":"#### 4-Cluster Solution","0196ec2d":"# Observation\n\n##### Both the method are almost similer means , minor variation, which we know it occurs.\n\n##### We for cluster grouping based on the dendrogram, 3 or 4 looks good. Did the further analysis, and based on the dataset had gone for 3 group cluster solution based on the hierarchical clustering \n\n##### Also in real time, there colud have been more variables value captured - tenure, BALANCE_FREQUENCY, balance, purchase, installment of purchase, others.\n\n##### And three group cluster solution gives a pattern based on high\/medium\/low spending with max_spent_in_single_shopping (high value item) and probability_of_full_payment(payment made).","c50d63a1":"##### credit_limit variable","5a789fe3":"##### current_balance variable","9ab68359":"## Group 2 : Low Spending Group\n    \n    - customers should be given remainders for payments. Offers can be provided on early payments to improve their payment rate.\n    - Increase there spending habits by tieing up with grocery stores, utlities (electircity, phone, gas, others)\n    ","da864ffd":"# Strategy to remove outliers: We choose to replace attribute outlier values by their respective medians , instead of dropping them, as we will lose other column info and also there outlier are present only in two avariables and within 5 records.","a8692673":"# Data Dictionary for Market Segmentation:\n\n    - spending: Amount spent by the customer per month (in 1000s)\n    - advance_payments: Amount paid by the customer in advance by cash (in 100s)\n    - probability_of_full_payment: Probability of payment done in full by the customer to the bank\n    - current_balance: Balance amount left in the account to make purchases (in 1000s)\n    - credit_limit: Limit of the amount in credit card (10000s)\n    - min_payment_amt : minimum paid by the customer while making payments for purchases made monthly (in 100s)\n    - max_spent_in_single_shopping: Maximum amount spent in one purchase (in 1000s)","c470ae35":"##### K-Means Clustering & Cluster Information","dcc25de1":"##### -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","22c0e8c5":"###### Observation\n    - Strong positive correlation between \n            - spending & advance_payments, \n            - advance_payments & current_balance, \n            - credit_limit & spending\n            - spending & current_balance\n            - credit_limit & advance_payments\n            - max_spent_in_single_shopping\tcurrent_balance\n","dd5add5b":"# 1.5 Describe cluster profiles for the clusters defined. Recommend different promotional strategies for different clusters.","9290dd74":"# 1.2  Do you think scaling is necessary for clustering in this case? Justify","9d5f93d1":"# Multivariate analysis","197b1938":"##### Observation\nNo missing value.","8137f578":"##### Observation\n    - Based on summary descriptive, the data looks good.\n    - We see for most of the variable, mean\/medium are nearly equal\n    - Include a 90% to see variations and it looks distributely evenly\n    - Std Deviation is high for spending variable","cc741a6d":"##### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","7f17268b":"# 3 group cluster via hierarchical clustering","17c754ba":"##### Cutting the Dendrogram with suitable clusters","36fe87f8":"### Checking the Summary Statistic","cbd64832":"# Cluster Group Profiles\n\n# Group 1 : High Spending\n\n# Group 3 : Medium Spending\n    \n# Group 2 : Low Spending","8395ac9d":"# 1.4 Apply K-Means clustering on scaled data and determine optimum clusters. Apply elbow curve and silhouette score.","410e1500":"# Note \n\n# I am going with 3 clusters via kmeans, but am showing the analysis of 4 and 5 kmeans cluster, I see we based on current dataset given, 3 cluster solution makes sense based on the spending pattern (High, Medium, Low)","6e1af288":"# 3 Cluster Solution","14e637d0":"##### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","146dcb6d":"##### min_payment_amt variable","909f35ab":"### Load data","d453dfc3":"##### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","7545ec59":"##### -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","9ea43d33":"##### probability_of_full_payment variable","89297ca0":"# Observation\nMost of the outlier has been treated and now we are good to go. ","bbdb856c":"##### Creating the Dendrogram\n##### Importing dendrogram and linkage module","3687b93b":"##### ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","8a0c0f38":"##### ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","881f243d":"### K-Means Clustering & Cluster Information","ff63fbaa":"# let us remove the outliers\nfor column in clean_dataset.columns.tolist():\n    Q1 = clean_dataset[column].quantile(.25) # 1st quartile\n    Q3 = clean_dataset[column].quantile(.75) # 3rd quartile\n    IQR = Q3-Q1 # get inter quartile range\n    # Replace elements of columns that fall below Q1-1.5*IQR and above Q3+1.5*IQR\n    clean_dataset[column].replace(clean_dataset.loc[(clean_dataset[column] > Q3+1.5*IQR)|(clean_dataset[column] < Q1-1.5*IQR), column], clean_dataset[column].median())","5b9b5e58":"##### Cluster Profiles","e2a20b25":"#### Another method - ward","ea390a81":"# Promotional strategies for each cluster","86cc2b61":"# 1.1 Read the data and do exploratory data analysis. Describe the data briefly","e970bac2":"# Problem 1: Clustering\n\nA leading bank wants to develop a customer segmentation to give promotional offers to its customers. \n\nThey collected a sample that summarizes the activities of users during the past few months. \n\nYou are given the task to identify the segments based on credit card usage.","ed9fda24":"##### Observation\nData looks good based on intial records seen in top 5 and bottom 5.","6137b708":"##### Observation:\n\n- 7 variables and 210 records. \n- No missing record based on intial analysis. \n- All the variables numeric type."}}