{"cell_type":{"863f550e":"code","cb306996":"code","20a5565d":"code","14f889bd":"code","8f069745":"code","cc5c8318":"code","f30d7723":"code","fc2a2bf8":"code","6c1dff30":"code","239d674c":"code","fe56d4fa":"code","0b8f5882":"code","47dd99e7":"code","eb3a5d5a":"code","6ccb8d7d":"code","aea570d7":"code","3a8643be":"code","0a3006a0":"markdown","86a9754c":"markdown","3aff55b1":"markdown","3ce82faf":"markdown","f12979f6":"markdown","109ea4e1":"markdown"},"source":{"863f550e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport tensorflow_hub as hub #to re use existing models of ML\nimport keras\nimport keras.backend as K\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.optimizers import *\nfrom keras import Model\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport pickle    \nimport os","cb306996":"def save_obj(obj, name ):\n    with open(name + '.pkl', 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\ndef load_obj(name ):\n    with open(name + '.pkl', 'rb') as f:\n        return pickle.load(f)\n                \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","20a5565d":"# reading dataset\nsubmission = pd.read_csv('\/kaggle\/input\/google-quest-challenge\/sample_submission.csv')\ntrain = pd.read_csv(\"..\/input\/google-quest-challenge\/train.csv\")\ntest = pd.read_csv(\"..\/input\/google-quest-challenge\/test.csv\")\n# concatenating both datasets\ndf = pd.concat([train, test])\ndf.head()","14f889bd":"#loading module\nmodule_url = \"\/kaggle\/input\/universalsentenceencoderlarge4\/\"\nembed = hub.load(module_url)","8f069745":"# Shape of the Dataset\ndf.shape","cc5c8318":"# Checking Datatypes\ndf.dtypes","f30d7723":"# Checking Missing Value\ndf.isnull().sum()","fc2a2bf8":"# Selecting Target Columns\ntargets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n#inputs \ninput_columns = ['question_title','question_body','answer']","6c1dff30":"#question title column to list\nX1 = train[input_columns[0]].values.tolist()\n#question body column to list\nX2 = train[input_columns[1]].values.tolist()\n#answer column to list\nX3 = train[input_columns[2]].values.tolist()\nX1 = [x.replace('?','.').replace('!','.') for x in X1]\nX2 = [x.replace('?','.').replace('!','.') for x in X2]\nX3 = [x.replace('?','.').replace('!','.') for x in X3]\n\nX = [X1,X2,X3]\ny = train[targets].values.tolist()","239d674c":"# Plotting the channels where the Training queries comes from in the data\nfig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(111)\nwidth = 0.4\ndf.host.value_counts().plot(kind='bar', color='blue', ax=ax, width=width, position=1)\nax.set_xlabel('Sites')\nax.set_ylabel('Question Counts')","fe56d4fa":"# Plotting the category occurance of the queries\nfig = plt.figure(figsize=(7,6))\nax = fig.add_subplot(111)\nwidth = 0.2\ndf.category.value_counts().plot(kind='bar', color='green', ax=ax, width=width, position=1, legend=True)\nax.set_xlabel('Sites')\nax.set_ylabel('Question Counts')","0b8f5882":"def UniversalEmbedding(x):\n    results = embed(tf.squeeze(tf.cast(x, tf.string)))[\"outputs\"]\n    print(results)\n    return keras.backend.concatenate([results])","47dd99e7":"# build network\ndef swish(x):\n    return K.sigmoid(x) * x\n\nembed_size = 512 #must be 512 for univerasl embedding layer\n\ninput_text1 = Input(shape=(1,), dtype=tf.string)\nembedding1 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text1)\ninput_text2 = Input(shape=(1,), dtype=tf.string)\nembedding2 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text2)\ninput_text3 = Input(shape=(1,), dtype=tf.string)\nembedding3 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text3)\n\nx = Concatenate()([embedding1,embedding2,embedding3])\nx = Dense(256, activation=swish)(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(64, activation=swish, kernel_regularizer=keras.regularizers.l2(0.001))(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\noutput = Dense(len(targets),activation='sigmoid',name='output')(x)","eb3a5d5a":"#model summary\nmodel = Model(inputs=[input_text1,input_text2,input_text3], outputs=[output])\nmodel.summary()","6ccb8d7d":"# Training, clean up and optimization\nimport gc\nprint(gc.collect())\n# Train the network\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=1e-7, verbose=1)\noptimizer = Adadelta()\n\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy')\nmodel.fit(X, [y], epochs=10, validation_split=.1,batch_size=32,callbacks=[reduce_lr])","aea570d7":"# prep test data\nX1 = test[input_columns[0]].values.tolist()\nX2 = test[input_columns[1]].values.tolist()\nX3 = test[input_columns[2]].values.tolist()\nX1 = [x.replace('?','.').replace('!','.') for x in X1]\nX2 = [x.replace('?','.').replace('!','.') for x in X2]\nX3 = [x.replace('?','.').replace('!','.') for x in X3]\n\npred_X = [X1,X2,X3]\n# Make a prediction\npred_y = model.predict(pred_X)\n# Check the submission\nsubmission = pd.read_csv('\/kaggle\/input\/google-quest-challenge\/sample_submission.csv')\nsubmission[targets] = pred_y\nsubmission.head()","3a8643be":"# Save the result\nsubmission.to_csv(\"submission.csv\", index = False)","0a3006a0":"# Problem Statement\nThe data for this competition includes questions and answers from various StackExchange properties. Your task is to predict target values of 30 labels for each question-answer pair.","86a9754c":"# Section 1: Import Library","3aff55b1":"# Section 5: Submission","3ce82faf":"# Section 4: Modelling","f12979f6":"# Section 3: EDA and Feature Extraction","109ea4e1":"# Section 2: Read Data"}}