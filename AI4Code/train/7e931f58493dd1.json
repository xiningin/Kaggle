{"cell_type":{"7212c0ce":"code","4fced1e5":"code","4b9fc6ba":"code","dc56462b":"code","22fbf5e8":"code","b9a29505":"code","8ae0aa91":"code","3228bdd0":"code","a87c1023":"code","e3a06224":"code","e4ba88e4":"code","66234312":"code","7117c70c":"code","193f666d":"code","9d70ab42":"code","a6df21f4":"code","637eba01":"code","6312d709":"code","6771e0b1":"code","a0117d4f":"code","3e20d3a9":"code","4558f719":"code","0814bdee":"code","ccc7d4c4":"code","b2af4c86":"code","a946132a":"code","2dfc9148":"code","15510acb":"code","ee535873":"code","3b15200f":"code","38d66f7c":"code","915b820d":"code","0d996604":"code","a3a40b77":"code","7fd2aa45":"code","5e593c77":"code","211ca7bb":"code","68557fa0":"code","eb0d0d1c":"code","18065aeb":"code","c7f93a70":"code","9efa7c8c":"code","493b2a2b":"code","545f3baf":"code","bd91e678":"code","a704e6e5":"code","2730ffc1":"code","fe0a3b0d":"code","b6599c3c":"code","b222cccb":"code","ea3b27b3":"code","60b0d8cc":"code","22fad5a7":"code","eb371c7c":"code","2986131a":"code","41c6c6e2":"code","51381a1d":"code","fb678f73":"code","914528fe":"code","79dd70ab":"code","19c758c1":"code","dbb56086":"code","3643c26c":"code","6ed5156d":"code","fa1d379c":"code","85217831":"code","a00a5b0c":"code","f8f16f85":"code","ef56a75a":"code","5c8ee9f4":"code","7b039c39":"code","399b57dd":"code","d00aad70":"code","d03008a2":"code","ebe7b4a3":"code","533355e1":"code","646244da":"code","c556a46a":"code","94fb5e4c":"code","c1999808":"code","6a625f6e":"code","bebba47e":"code","303d9a4a":"code","c7101e21":"code","ede92f6e":"code","8a53b3c2":"code","f37ea90c":"code","344b2a3b":"markdown","aa91113b":"markdown","2f05994a":"markdown","95a50e53":"markdown","ecb995c8":"markdown","55783f22":"markdown","85e5cf08":"markdown","f65b6bc9":"markdown","8feb4789":"markdown"},"source":{"7212c0ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, for reading csv file(s).\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nimport seaborn as sb # For visualization.\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split # For splitting the dataset.\nfrom sklearn.model_selection import RandomizedSearchCV, KFold,GridSearchCV\nfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,LabelEncoder,PowerTransformer\nfrom sklearn.ensemble import GradientBoostingRegressor,StackingRegressor, RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.model_selection import KFold, cross_val_score # For cross validation.\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.decomposition import PCA\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', 5000)\npd.set_option('display.max_rows', 5000)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4fced1e5":"train=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample_sub=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","4b9fc6ba":"train.head() # Printing top 5 rows of train dataset.","dc56462b":"train[train.SalePrice>300000]","22fbf5e8":"train.tail() # Printing last 5 rows of train dataset.","b9a29505":"train.info() # For finding the number of NaNs & data types in train dataset.","8ae0aa91":"train.describe() # This describes the train dataset.","3228bdd0":"correlation_train=train.corr()\nsb.set(font_scale=2)\nplt.figure(figsize = (50,35))\nax = sb.heatmap(correlation_train, annot=True,annot_kws={\"size\": 25},fmt='.1f',cmap='YlGnBu', linewidths=.5)","a87c1023":"correlation_train.columns","e3a06224":"corr_dict=correlation_train['SalePrice'].sort_values(ascending=False).to_dict()\nimportant_columns=[]\nfor key,value in corr_dict.items():\n    if ((value>0.1) & (value<0.8)) | (value<=-0.1):\n        important_columns.append(key)\nimportant_columns","e4ba88e4":"plt.figure(figsize=(40,20))\nsb.set(font_scale=1.5)\nsb.boxplot(x='YearBuilt', y=\"SalePrice\", data=train)\nsb.swarmplot(x='YearBuilt', y=\"SalePrice\", data=train, color=\".35\")\nplt.xticks(weight='bold',rotation=90)\n","66234312":"test.head() # Printing top 5 rows of test dataset.","7117c70c":"test.tail() # Printing last 5 rows of test dataset.","193f666d":"test.info()","9d70ab42":"test.describe()","a6df21f4":"train_test=pd.concat([train,test],axis=0,sort=False) # Combining both train & test datasets.\ntrain_test.head()","637eba01":"pd.set_option('display.max_rows', 5000)\ntrain_test_null_info=pd.DataFrame(train_test.isnull().sum(),columns=['Count of NaN'])\ntrain_test_dtype_info=pd.DataFrame(train_test.dtypes,columns=['DataTypes'])\ntrain_tes_info=pd.concat([train_test_null_info,train_test_dtype_info],axis=1)\ntrain_tes_info","6312d709":"train_test.loc[train_test['Fireplaces']==0,'FireplaceQu']='Nothing'\ntrain_test['LotFrontage'] = train_test['LotFrontage'].fillna(train_test.groupby('1stFlrSF')['LotFrontage'].transform('mean'))\ntrain_test['LotFrontage'].interpolate(method='linear',inplace=True)\ntrain_test['LotFrontage']=train_test['LotFrontage'].astype(int)\ntrain_test['MasVnrArea'] = train_test['MasVnrArea'].fillna(train_test.groupby('MasVnrType')['MasVnrArea'].transform('mean'))\ntrain_test['MasVnrArea'].interpolate(method='linear',inplace=True)\ntrain_test['MasVnrArea']=train_test['MasVnrArea'].astype(int)\ntrain_test[\"Fence\"] = train_test[\"Fence\"].fillna(\"None\")\ntrain_test[\"FireplaceQu\"] = train_test[\"FireplaceQu\"].fillna(\"None\")\ntrain_test[\"Alley\"] = train_test[\"Alley\"].fillna(\"None\")\ntrain_test[\"PoolQC\"] = train_test[\"PoolQC\"].fillna(\"None\")\ntrain_test[\"MiscFeature\"] = train_test[\"MiscFeature\"].fillna(\"None\")\ntrain_test.loc[train_test['BsmtFinSF1']==0,'BsmtFinType1']='Unf'\ntrain_test.loc[train_test['BsmtFinSF2']==0,'BsmtQual']='TA'\ntrain_test['YrBltRmd']=train_test['YearBuilt']+train_test['YearRemodAdd']\ntrain_test['Total_Square_Feet'] = (train_test['BsmtFinSF1'] + train_test['BsmtFinSF2'] + train_test['1stFlrSF'] + train_test['2ndFlrSF'] + train_test['TotalBsmtSF'])\ntrain_test['Total_Bath'] = (train_test['FullBath'] + (0.5 * train_test['HalfBath']) + train_test['BsmtFullBath'] + (0.5 * train_test['BsmtHalfBath']))\ntrain_test['Total_Porch_Area'] = (train_test['OpenPorchSF'] + train_test['3SsnPorch'] + train_test['EnclosedPorch'] + train_test['ScreenPorch'] + train_test['WoodDeckSF'])\ntrain_test['exists_pool'] = train_test['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ntrain_test['exists_garage'] = train_test['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ntrain_test['exists_fireplace'] = train_test['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ntrain_test['exists_bsmt'] = train_test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ntrain_test['old_house'] = train_test['YearBuilt'].apply(lambda x: 1 if x <1990 else 0)\n\nfor i in train_test.columns:\n    if 'SalePrice' not in i:\n        if 'object' in str(train_test[str(i)].dtype):\n            train_test[str(i)]=train_test[str(i)].fillna(method='ffill')\n","6771e0b1":"columns = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', 'YrSold', 'MoSold', 'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope', 'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond')\n\nfor col in columns:\n    lbl_enc = LabelEncoder() \n    lbl_enc.fit(list(train_test[col].values)) \n    train_test[col] = lbl_enc.transform(list(train_test[col].values))","a0117d4f":"numeric_features = train_test.dtypes[train_test.dtypes != \"object\"].index\nskewed_features = train_test[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nprint(skewed_features)","3e20d3a9":"high_skewness = skewed_features[abs(skewed_features) > 0.9]\nskewed_features = high_skewness.index","4558f719":"high_skewness","0814bdee":"skewed_features","ccc7d4c4":"train_test[['MiscVal', 'PoolArea', 'exists_pool', 'LotArea', 'LowQualFinSF', '3SsnPorch', 'LandSlope', 'KitchenAbvGr', 'EnclosedPorch',\n       'ScreenPorch', 'MasVnrArea', 'OpenPorchSF', 'WoodDeckSF', 'LotFrontage', '1stFlrSF', 'Total_Porch_Area', 'GrLivArea', 'BsmtExposure',\n       'KitchenQual', 'ExterQual', 'Fence', 'ExterCond', 'PavedDrive', 'BsmtCond', 'BsmtFinType2', 'CentralAir', 'GarageQual', 'exists_garage',\n       'Functional', 'GarageCond', 'exists_bsmt', 'BsmtQual', 'Street','PoolQC']].head()","b2af4c86":"for feature in skewed_features:\n    train_test[feature] = boxcox1p(train_test[feature], boxcox_normmax(train_test[feature] + 1))","a946132a":"train_test[['MiscVal', 'PoolArea', 'exists_pool', 'LotArea', 'LowQualFinSF', '3SsnPorch', 'LandSlope', 'KitchenAbvGr', 'EnclosedPorch',\n       'ScreenPorch', 'MasVnrArea', 'OpenPorchSF', 'WoodDeckSF', 'LotFrontage', '1stFlrSF', 'Total_Porch_Area', 'GrLivArea', 'BsmtExposure',\n       'KitchenQual', 'ExterQual', 'Fence', 'ExterCond', 'PavedDrive', 'BsmtCond', 'BsmtFinType2', 'CentralAir', 'GarageQual', 'exists_garage',\n       'Functional', 'GarageCond', 'exists_bsmt', 'BsmtQual', 'Street','PoolQC']].head()","2dfc9148":"train_test=pd.get_dummies(train_test,dtype='int8')","15510acb":"train_test_null_info=pd.DataFrame(train_test.isnull().sum(),columns=['Count of NaN'])\ntrain_test_dtype_info=pd.DataFrame(train_test.dtypes,columns=['DataTypes'])\ntrain_test_info=pd.concat([train_test_null_info,train_test_dtype_info],axis=1)\ntrain_test_info","ee535873":"train=train_test[0:1460]\ntest=train_test[1460:2919]","3b15200f":"len(train) # Length of train.","38d66f7c":"train.interpolate(method='linear',inplace=True)\ntest.interpolate(method='linear',inplace=True)","915b820d":"corr_new_train=train.corr()\nplt.figure(figsize=(5,15))\nsb.heatmap(corr_new_train[['SalePrice']].sort_values(by=['SalePrice'],ascending=False).head(30),annot_kws={\"size\": 16},vmin=-1, cmap='YlGnBu', annot=True)\nsb.set(font_scale=2)","0d996604":"corr_dict2=corr_new_train['SalePrice'].sort_values(ascending=False).to_dict()\ncorr_dict2","a3a40b77":"# Printing columns with more than 40% positive or negative correlations with SalePrice.\nbest_columns=[]\nfor key,value in corr_dict2.items():\n    if ((value>=0.3175) & (value<0.9)) | (value<=-0.315):\n        best_columns.append(key)\nbest_columns","7fd2aa45":"len(best_columns)","5e593c77":"plt.figure(figsize=(25,10))\nsb.set(font_scale=1.4)\ntrain.boxplot(column=best_columns)\nplt.xticks(weight='bold',rotation=90)","211ca7bb":"train['SalePrice_Log1p'] = np.log1p(train.SalePrice)","68557fa0":"train.head()","eb0d0d1c":"print(min(train['SalePrice_Log1p']))\nprint(max(train['SalePrice_Log1p']))","18065aeb":"plt.figure(figsize=(10,8))\nsb.set(font_scale=1.2)\nsb.distplot(train['SalePrice'],color='blue')\nplt.xlabel('SalePrice',fontsize=20)\nprint('Skew Dist:',train['SalePrice'].skew())\nprint('Kurtosis Dist:',train['SalePrice'].kurt())","c7f93a70":"plt.figure(figsize=(10,8))\nsb.set(font_scale=1.2)\nsb.distplot(train['SalePrice_Log1p'],color='indigo')\nplt.xlabel('SalePrice_Log1p',fontsize=20)\nprint('Skew Dist:',train['SalePrice_Log1p'].skew())\nprint('Kurtosis Dist:',train['SalePrice_Log1p'].kurt())","9efa7c8c":"print(len(train[(train.KitchenQual==3) & (train.SalePrice>360000)].index))","493b2a2b":"len(train)","545f3baf":"plt.style.use('ggplot')\nplt.figure(figsize=(20,12))\nrbst_scaler=RobustScaler()\ntrain_rbst=rbst_scaler.fit_transform(train)\n\npca=PCA(50).fit(train_rbst)\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.xticks(np.arange(0, 50, 1))\nplt.xlabel('Number of components',fontweight='bold',size=14)\nplt.ylabel('Explanined variance ratio for number of components',fontweight='bold',size=14)\n\ntrain_pca=PCA(3).fit_transform(train_rbst)","bd91e678":"neigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(train)\ndistances, indices = nbrs.kneighbors(train)\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\nplt.figure(figsize=(15,15))\nplt.plot(distances)","a704e6e5":"dbscan = DBSCAN(eps=1400, min_samples=20).fit(train_pca)\ncore_samples_mask = np.zeros_like(dbscan.labels_, dtype=bool)\ncore_samples_mask[dbscan.core_sample_indices_] = True\nlabels=dbscan.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)","2730ffc1":"unique_labels = set(labels)\nplt.figure(figsize=(12,12))\ncolors = [plt.cm.prism(each)  for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n    \n    xy = train_pca[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = train_pca[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()","fe0a3b0d":"labels=pd.DataFrame(labels,columns=['Classes'])\nprint(labels[labels['Classes']==-1])","b6599c3c":"train=pd.concat([train,labels],axis=1)","b222cccb":"train[train.Classes==-1]","ea3b27b3":"train.drop([197,810,1170,1182,1298,1386,1423],axis=0,inplace=True)","60b0d8cc":"plt.style.use('dark_background')\nfig, axes = plt.subplots(18, 2,figsize=(20,80))\nfig.subplots_adjust(hspace=0.6)\ncolors=[plt.cm.prism_r(each) for each in np.linspace(0, 1, len(best_columns))]\nfor i,ax,color in zip(best_columns,axes.flatten(),colors):\n    sb.regplot(x=train[i], y=train[\"SalePrice\"], fit_reg=True,marker='o',scatter_kws={'s':50,'alpha':0.8},color=color,ax=ax)\n    plt.xlabel(i,fontsize=12)\n    plt.ylabel('SalePrice',fontsize=12)\n    ax.set_yticks(np.arange(0,900001,100000))\n    ax.set_title('SalePrice'+' - '+str(i),color=color,fontweight='bold',size=20)","22fad5a7":"plt.style.use('ggplot')\nfig, axes = plt.subplots(18, 2,figsize=(20,60))\nfig.subplots_adjust(hspace=0.8)\nsb.set(font_scale=1.2)\ncolors=[plt.cm.prism_r(each) for each in np.linspace(0, 1, len(best_columns))]\nfor i,ax,color in zip(best_columns,axes.flatten(),colors):\n    sb.regplot(x=train[i], y=train[\"SalePrice_Log1p\"], fit_reg=True,marker='o',scatter_kws={'s':50,'alpha':0.7},color=color,ax=ax)\n    plt.xlabel(i,fontsize=12)\n    plt.ylabel('SalePrice_Log1p',fontsize=12)\n    ax.set_title('SalePrice_Log1p'+' - '+str(i),color=color,fontweight='bold',size=20)","eb371c7c":"\"Looking at the SalePrice and SalePrice_Log1p visualizations\"\n\n#train = train.drop(train[(train.OverallQual==4) & (train.SalePrice>200000)].index)\n#train = train.drop(train[(train.OverallQual==10) & (train.SalePrice<200000)].index)\n#train = train.drop(train[(train.Total_Square_Feet>=10000) & (train.SalePrice<200000)].index)\n#train = train.drop(train[(train.Total_SF<3000) & (train.SalePrice>375000)].index)\n#train = train.drop(train[(train.GrLivArea>4500) & (train.SalePrice<200000)].index)\n#train = train.drop(train[(train.GrLivArea<3000) & (train.SalePrice>575000)].index)\n#train = train.drop(train[(train.GarageArea>1200) & (train.SalePrice<165000)].index)\n#train = train.drop(train[(train.Total_Bath.isin([5,6])) & (train.SalePrice<200000)].index)\n#train = train.drop(train[(train.TotRmsAbvGrd==10) & (train.SalePrice>700000)].index)\n#train = train.drop(train[(train.YearBuilt<1900) & (train.SalePrice>250000)].index)\n#train = train.drop(train[(train.YearBuilt>2000) & (train.SalePrice<100000)].index)\n#train = train.drop(train[(train.YearRemodAdd<1970) & (train.SalePrice>350000)].index)\n#train = train.drop(train[(train.MasVnrArea>=1400) & (train.SalePrice<250000)].index)\n#train = train.drop(train[(train.GarageYrBlt<1960) & (train.SalePrice>340000)].index)\n#train = train.drop(train[(train.Total_Porch_Area>600) & (train.SalePrice<50000)].index)\n#train = train.drop(train[(train.LotFrontage>150) & (train.SalePrice<100000)].index)\n#train = train.drop(train[(train.GarageFinish.isin([1,2])) & (train.SalePrice>470000)].index)\n#train = train.drop(train[(train.old_house==0) & (train.SalePrice<100000)].index)\n#train = train.drop(train[(train.old_house==1) & (train.SalePrice>400000)].index)\n#train = train.drop(train[(train.KitchenQual==2) & (train.SalePrice>600000)].index)\n#train = train.drop(train[(train.KitchenQual==3) & (train.SalePrice>360000)].index)\n#train = train.drop(train[(train.ExterQual==2) & (train.SalePrice>550000)].index)\n\n\ntrain = train[train.GarageArea * train.GarageCars < 3700]\ntrain = train[(train.FullBath + (train.HalfBath*0.5) + train.BsmtFullBath + (train.BsmtHalfBath*0.5))<5]","2986131a":"len(train)","41c6c6e2":"plt.style.use('dark_background')\ncorr1_new_train=train.corr()\nplt.figure(figsize=(5,15))\nsb.heatmap(corr1_new_train[['SalePrice']].sort_values(by=['SalePrice'],ascending=False).head(25),annot_kws={\"size\": 16},vmin=-1, cmap='PiYG', annot=True)\nsb.set(font_scale=2)","51381a1d":"train.isnull().sum() # Number of NaNs column-wise in train dataset.","fb678f73":"test.isnull().sum() # Number of NaNs column-wise in test dataset.","914528fe":"del test['SalePrice']","79dd70ab":"train.head()","19c758c1":"X=train.drop(['SalePrice','SalePrice_Log1p','Classes'],axis=1)\ny=train.SalePrice_Log1p","dbb56086":"def overfit_reducer(df):\n\n    overfit = []\n    for i in df.columns:\n        counts = df[i].value_counts()\n        zeros = counts.iloc[0]\n        if zeros \/ len(df) * 100 > 99.9:\n            overfit.append(i)\n    overfit = list(overfit)\n    return overfit\noverfitted_features = overfit_reducer(X)","3643c26c":"print(X.shape)\nprint(test.shape)","6ed5156d":"X.drop(overfitted_features,axis=1,inplace=True)\ntest.drop(overfitted_features,axis=1,inplace=True)\nprint('X.shape',X.shape)\nprint('test.shape',test.shape)","fa1d379c":"std_scaler=StandardScaler()\nrbst_scaler=RobustScaler()\npower_transformer=PowerTransformer()\nX_std=std_scaler.fit_transform(X)\nX_rbst=rbst_scaler.fit_transform(X)\nX_pwr=power_transformer.fit_transform(X)\n\ntest_std=std_scaler.transform(test)\ntest_rbst=rbst_scaler.transform(test)\ntest_pwr=power_transformer.transform(test)","85217831":"X_train,X_test,y_train,y_test=train_test_split(X_std,y,test_size=0.002,random_state=52)\nprint('X_train Shape :',X_train.shape)\nprint('X_test Shape :',X_test.shape)\nprint('y_train Shape :',y_train.shape)\nprint('y_test Shape :',y_test.shape)","a00a5b0c":"lgb_regressor=lgb.LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.035, n_estimators=2177, max_bin=50, bagging_fraction=0.65,bagging_freq=5, bagging_seed=7, \n                                feature_fraction=0.201, feature_fraction_seed=7,n_jobs=-1)\nlgb_regressor.fit(X_train, y_train)\ny_head=lgb_regressor.predict(X_test)\nprint('-'*10+'LGBM'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","f8f16f85":"gb_reg = GradientBoostingRegressor(n_estimators=1992, learning_rate=0.03005, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=14, loss='huber', random_state =42)\ngb_reg.fit(X_train, y_train)\ny_head=gb_reg.predict(X_test)\nprint('-'*10+'GBR'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","ef56a75a":"kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\nalphas=[1e-9,1e-8,1e-7,1e-6]\n\nridgecv_reg= make_pipeline(RidgeCV(alphas=alphas, cv=kfolds))\nridgecv_reg.fit(X_train, y_train)\ny_head=ridgecv_reg.predict(X_test)\nprint('-'*10+'RidgeCV'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","5c8ee9f4":"kfolds = KFold(n_splits=8, shuffle=True, random_state=42)\n\nlassocv_reg= make_pipeline(LassoCV(alphas=alphas, cv=kfolds))\nlassocv_reg.fit(X_train, y_train)\ny_head=lassocv_reg.predict(X_test)\nprint('-'*10+'LassoCV'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","7b039c39":"kfolds = KFold(n_splits=8, shuffle=True, random_state=42)\n\nalphas=[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006]\nl1ratio=[0.87, 0.9,0.92, 0.95,0.97, 0.99, 1]\n\nelasticv_reg= make_pipeline(ElasticNetCV(alphas=alphas, cv=kfolds, l1_ratio=l1ratio))\nelasticv_reg.fit(X_train, y_train)\ny_head=elasticv_reg.predict(X_test)\nprint('-'*10+'ElasticNetCV'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","399b57dd":"estimators = [('lgbm', lgb_regressor),\n              ('gbr', gb_reg),   \n              ('lasso', lassocv_reg),   \n              ('ridge', ridgecv_reg),   \n              ('elasticnet', elasticv_reg)]\n\nstack_reg=StackingRegressor(estimators=estimators,final_estimator=ExtraTreesRegressor(n_estimators=50),n_jobs=-1)\nstack_reg.fit(X_train, y_train)\ny_head=stack_reg.predict(X_test)\nprint('-'*10+'StackingRegressor'+'-'*10)\nprint('R square Accuracy: ',r2_score(y_test,y_head))\nprint('Mean Absolute Error Accuracy: ',mean_absolute_error(y_test,y_head))\nprint('Mean Squared Error Accuracy: ',mean_squared_error(y_test,y_head))","d00aad70":"y_head=pd.DataFrame(y_head,columns=['Predict'])\ny_test.reset_index(drop=True,inplace=True)\ny_test_y_head=pd.concat([y_test,y_head],axis=1)\ny_test_y_head.head()","d03008a2":"print('Count columns of test: ',len(test.columns))\nprint('Count columns of X: ',len(X.columns))","ebe7b4a3":"test_pred_lgb=lgb_regressor.predict(test_pwr)\ntest_pred_gb=gb_reg.predict(test_pwr)\ntest_pred_elastic=elasticv_reg.predict(test_pwr)\ntest_pred_ridge=ridgecv_reg.predict(test_pwr)\ntest_pred_lasso=lassocv_reg.predict(test_pwr)\ntest_pred_stack=stack_reg.predict(test_pwr)","533355e1":"test_pred_lgb=pd.DataFrame(test_pred_lgb,columns=['SalePrice'])\ntest_pred_gb=pd.DataFrame(test_pred_gb,columns=['SalePrice'])\ntest_pred_elastic=pd.DataFrame(test_pred_elastic,columns=['SalePrice'])\ntest_pred_ridge=pd.DataFrame(test_pred_ridge,columns=['SalePrice'])\ntest_pred_lasso=pd.DataFrame(test_pred_lasso,columns=['SalePrice'])\ntest_pred_stack=pd.DataFrame(test_pred_stack,columns=['SalePrice'])","646244da":"test_pred_lgb.SalePrice =np.floor(np.expm1(test_pred_lgb.SalePrice))\ntest_pred_gb.SalePrice =np.floor(np.expm1(test_pred_gb.SalePrice))\ntest_pred_elastic.SalePrice =np.floor(np.expm1(test_pred_elastic.SalePrice))\ntest_pred_ridge.SalePrice =np.floor(np.expm1(test_pred_ridge.SalePrice))\ntest_pred_lasso.SalePrice =np.floor(np.expm1(test_pred_lasso.SalePrice))\ntest_pred_stack.SalePrice =np.floor(np.expm1(test_pred_stack.SalePrice))","c556a46a":"test_pred_lgb.head()","94fb5e4c":"test_pred_gb.head()","c1999808":"test_pred_elastic.head()","6a625f6e":"test_pred_ridge.head()","bebba47e":"test_pred_lasso.head()","303d9a4a":"test_pred_stack.head()","c7101e21":"final_pred=(test_pred_stack*0.1665)+(test_pred_lgb*0.678)+(test_pred_ridge*0.1665)\nfinal_pred.head()","ede92f6e":"sample_sub['SalePrice']=final_pred","8a53b3c2":"sample_sub.head()","f37ea90c":"sample_sub.to_csv('SampleSubmissionForHousePrice.csv',index=False)","344b2a3b":"# These are the columns with the best correlation rate. Let's visualize them.","aa91113b":"* * # **In the heatmap above, we can see the variables that affect SalePrice.**","2f05994a":"# After the outliers were removed, Correlations are increased.","95a50e53":"# **Target is SalePrice**","ecb995c8":"# **Cleaning and Editing of Dataframes**\n\n# We will combine train and test datasets because we can do things on both at the same time.","55783f22":"# **Variables associated with SalePrice**","85e5cf08":"# **Creating Model**","f65b6bc9":"# Fillna and Feature Engineering","8feb4789":"# With the help of above visualizations, we detected outliers. Let's get rid of those!"}}