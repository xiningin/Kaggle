{"cell_type":{"62fbddd9":"code","109bc2ac":"code","bb497e42":"code","fd0c9cc4":"code","e3794a83":"code","fd09e09f":"code","00332bff":"code","3be55f77":"code","425d7af2":"code","ef5089b8":"code","76a1714b":"code","aa5dac16":"code","2d44a96b":"code","6ad35dc7":"code","9358be52":"code","2dea34ca":"code","4fad4a88":"code","8ea6e9be":"code","1837a8e1":"code","8f5ae66f":"code","df884543":"code","bc4c32fd":"code","16820c9b":"code","5024f991":"code","db02f69b":"code","75e87aa3":"code","ccdda442":"code","a146d4d1":"code","c4534485":"code","a98d9913":"code","b8bdf6af":"code","1e06699a":"code","153f0bf9":"code","f7014189":"code","ff87cb47":"code","e1e17b7f":"code","8f9fe0c0":"code","bb734f79":"code","496b8653":"code","bb6c7708":"code","6723571d":"code","c26ab612":"code","2ec3bc8e":"code","9a1092dc":"code","1d580cd0":"code","11816c9f":"code","1f81ef21":"code","369271e0":"code","2d980ef8":"code","7f2be3e8":"code","3af8c08e":"code","bb146bf7":"code","3dd2fc90":"code","dfd751e6":"code","900fc063":"code","f53804b9":"code","d9c4e014":"code","3c23cee8":"code","4d749027":"code","e7eff848":"code","de1c0564":"code","17b5e4d5":"code","12e8d96d":"code","0ebd3d7a":"code","e6b450b3":"code","1ba6572b":"code","1bf70baa":"code","a571b509":"code","cae5510f":"code","84f0eaa0":"code","e3f77b3d":"code","a256de5b":"code","352307ea":"code","af67b0d3":"code","6b3057dd":"code","c29ee7d5":"markdown","cedc6ea7":"markdown"},"source":{"62fbddd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.linear_model import LogisticRegression\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","109bc2ac":"# Load The Dataset\ndf_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","bb497e42":"# Check first 5 rows of the data\ndf_train.head()","fd0c9cc4":"# Check the columns\ndf_train.columns","e3794a83":"# Check the shape of the data\ndf_train.shape","fd09e09f":"# Check all data (mean, min,max etc) \ndf_train.describe()","00332bff":"# Check the data types of all columns in dataset\ndf_train.info()","3be55f77":"# Check how many passengers on Ship\nprint(\"Total Passenger : \",len(df_train[\"PassengerId\"]))","425d7af2":"# Check how many survived or how many not survived\nsurvived = df_train[df_train[\"Survived\"]==1]\nnot_survived = df_train[df_train[\"Survived\"]==0]","ef5089b8":"print(f\"Total Passenger Who Survived : {len(survived)}\")\nprint(f\"Total Passener Who Not Survived : {len(not_survived)}\")","76a1714b":"print(\"Survived % = \",1*len(survived)\/len(df_train)*100)\nprint(\"Not Survived % = \",1*len(not_survived)\/len(df_train)*100)","aa5dac16":"# Check which class has more passengers and check how much this impact on survived or not_survived\ndf_train[\"Pclass\"].value_counts().plot(kind=\"bar\")","2d44a96b":"plt.figure(figsize=(6,12))\nplt.subplot(211)\nsns.countplot(x=\"Pclass\",data=df_train)\nplt.subplot(212)\nsns.countplot(x=\"Pclass\",data=df_train,hue=\"Survived\",palette=\"summer\")","6ad35dc7":"## Check how much sex can impact on survived or not_survived\nplt.figure(figsize=(6,12))\nplt.subplot(211)\nsns.countplot(x=\"Sex\",data=df_train)\nplt.subplot(212)\nsns.countplot(x=\"Sex\",data=df_train,hue=\"Survived\",palette=\"winter\")","9358be52":"plt.figure(figsize=(8,12))\nplt.subplot(211)\nsns.countplot(x=\"SibSp\",data=df_train)\nplt.subplot(212)\nsns.countplot(x=\"SibSp\",data=df_train,hue=\"Survived\",palette=\"winter_d\")","2dea34ca":"plt.figure(figsize=(8,12))\nplt.subplot(211)\nsns.countplot(x=\"Parch\",data=df_train)\nplt.subplot(212)\nsns.countplot(x=\"Parch\",data=df_train,hue=\"Survived\",palette=\"winter_d\")","4fad4a88":"plt.figure(figsize=(8,12))\nplt.subplot(211)\nsns.countplot(x=\"Embarked\",data=df_train)\nplt.subplot(212)\nsns.countplot(x=\"Embarked\",data=df_train,hue=\"Survived\",palette=\"winter_d\")","8ea6e9be":"# Check the histogram of Age\ndf_train[\"Age\"].hist(bins=40)","1837a8e1":"# Check the histogram of Fare\ndf_train[\"Fare\"].hist(bins=40)","8f5ae66f":"# Check how many null values have in data\nplt.figure(figsize=(10,8))\nsns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap=\"Blues\")","df884543":"## Those column who is True are null values columns and second print showing null values columns\nprint(df_train.isna().any())\nprint(df_train.loc[:,df_train.isna().any()])","bc4c32fd":"# Now drop unussual columns like Cabin,Name,PassengerId,Ticket because this are not so useful..\ndf_train.drop([\"Ticket\",\"PassengerId\",\"Name\",\"Cabin\"],axis=1,inplace=True)\ndf_test.drop([\"Ticket\",\"PassengerId\",\"Name\",\"Cabin\"],axis=1,inplace=True)","16820c9b":"# Check the first 5 rows of data for verify that column successfull dropped\ndf_train.head()","5024f991":"# Groupby Age With Sex And Check the mean of male age and female age for fill nan(null) values\ndf_train.groupby(\"Sex\").agg({\"Age\":[\"mean\"]})","db02f69b":"df_test.groupby(\"Sex\").agg({\"Age\":[\"mean\"]})","75e87aa3":"# Create def fucntion for filling nan values of age\ndef fill_age(data):\n    age = data[0]\n    sex = data[1]\n    if pd.isnull(age):\n        if sex is \"male\":\n            return 30\n        else:\n            return 27\n    else:\n        return age","ccdda442":"def fill_age_test(data):\n    age = data[0]\n    sex = data[1]\n    if pd.isnull(age):\n        if sex is \"male\":\n            return 30\n        else:\n            return 30\n    else:\n        return age","a146d4d1":"# Now fill the nan values of age with mean of male and female\ndf_train[\"Age\"] = df_train[[\"Age\",\"Sex\"]].apply(fill_age,axis=1)\ndf_test[\"Age\"] = df_test[[\"Age\",\"Sex\"]].apply(fill_age_test,axis=1)","c4534485":"# Now verify nan values filled\nplt.figure(figsize=(10,8))\nsns.heatmap(df_train.isnull(),yticklabels=False,cbar=True,cmap=\"Blues\")","a98d9913":"df_train.isna().any()","b8bdf6af":"# Now check histogram of Embarked and check which Embarked have more passenger then fill then nan value\ndf_train[\"Embarked\"].hist()","1e06699a":"df_test[\"Embarked\"].hist()","153f0bf9":"## Embarked S Have More Passengers So That's why we choose Emabarked S For fill nan data\nprint(df_train[\"Embarked\"].value_counts())\nprint(df_train[\"Embarked\"].value_counts().idxmax())","f7014189":"df_train[\"Embarked\"].replace(np.nan,\"S\",inplace=True)\ndf_test[\"Embarked\"].replace(np.nan,\"S\",inplace=True)","ff87cb47":"# Now verify nan Data filled or not\nplt.figure(figsize=(10,8))\nsns.heatmap(df_train.isnull(),yticklabels=False,cbar=True,cmap=\"Blues\")","e1e17b7f":"# So We Successfully removed all missing value from data and drop unussual columns\ndf_train.isna().any()","8f9fe0c0":"df_test.isna().any()","bb734f79":"fare = df_test[\"Fare\"].astype(\"float64\").mean(axis=0)\nfare","496b8653":"df_test[\"Fare\"].replace(np.nan,fare,inplace=True)","bb6c7708":"df_test.isna().any()","6723571d":"df_test.dtypes","c26ab612":"# Now check dtypes of all columns\ndf_train.dtypes","2ec3bc8e":"# So we have to convert object = int or float because sklearn not take objects only take numeric values like int,float etc","9a1092dc":"# Create dummy variable for Sex\nsex_variable = pd.get_dummies(df_train[\"Sex\"],drop_first=True)\nsex_variable","1d580cd0":"# Now conat the sex_vaiable with df_train and drop the Sex columns\ndf_train = pd.concat([df_train,sex_variable],axis=1)\ndf_train.drop(\"Sex\",axis=1,inplace=True)","11816c9f":"# Verify the data correct or not\ndf_train.head()","1f81ef21":"sex_variable = pd.get_dummies(df_test[\"Sex\"],drop_first=True)","369271e0":"df_test = pd.concat([df_test,sex_variable],axis=1)\ndf_test.drop(\"Sex\",axis=1,inplace=True)","2d980ef8":"# Create dummy variable for Embarked\nembarked_var = pd.get_dummies(df_train[\"Embarked\"],drop_first=True)\nembarked_var","7f2be3e8":"# Now conat the embarked_var with df_train and drop the Embarked columns\ndf_train = pd.concat([df_train,embarked_var],axis=1)\ndf_train.drop(\"Embarked\",axis=1,inplace=True)","3af8c08e":"# Verify the data correct or not\ndf_train.head()","bb146bf7":"# Now Change the column name of Q and S with Embarked_Q and Embarked_S\ndf_train = df_train.rename(columns={\"Q\":\"Embarked_Q\",\"S\":\"Embarked_S\"})","3dd2fc90":"# Now Check the data all are correct or not\ndf_train.head()","dfd751e6":"embarked_var = pd.get_dummies(df_test[\"Embarked\"],drop_first=True)","900fc063":"df_test = pd.concat([df_test,embarked_var],axis=1)\ndf_test.drop(\"Embarked\",axis=1,inplace=True)","f53804b9":"df_test = df_test.rename(columns={\"Q\":\"Embarked_Q\",\"S\":\"Embarked_S\"})","d9c4e014":"# Now check the dtypes of all the columns all are good or not\ndf_train.dtypes","3c23cee8":"df_test.dtypes","4d749027":"X = df_train.drop(\"Survived\",axis=1).values","e7eff848":"y = df_train[\"Survived\"].values","de1c0564":"print(X.shape)\nprint(y.shape)","17b5e4d5":"# Feature Scaling\nsc = StandardScaler()\nX = sc.fit_transform(X)\ndf_test = sc.fit_transform(df_test)","12e8d96d":"X","0ebd3d7a":"df_test","e6b450b3":"# Model Training","1ba6572b":"lin_model = LogisticRegression(random_state=10)\nlin_model.fit(X,y)","1bf70baa":"Survived = lin_model.predict(df_test)","a571b509":"Survived","cae5510f":"new_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","84f0eaa0":"new_df.drop([\"Pclass\",\"Name\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"],axis=1,inplace=True)","e3f77b3d":"Survived = pd.DataFrame(Survived)","a256de5b":"Survived","352307ea":"new_df = pd.concat([new_df,Survived],axis=1)","af67b0d3":"new_df = new_df.rename(columns={0:\"Survived\"})\nnew_df.columns","6b3057dd":"new_df.to_csv(\"titanic_submissions_1\",index=False)","c29ee7d5":"## We can see those who stay in Pclass 1 and 2 Are More Survived but those who have Pclass 3 are not more survived rate","cedc6ea7":"## Sex is more impact we can see female surviving rate is more than male surviving rate"}}