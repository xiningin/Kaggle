{"cell_type":{"42eead47":"code","7470abfc":"code","b12bddec":"code","5a6ea84e":"code","01d1a8a4":"code","ac0fa1bd":"code","ac946db9":"code","35cdb4ec":"code","a90ca478":"code","dc2335bc":"code","18d681b6":"code","72490e0a":"markdown","ca132142":"markdown"},"source":{"42eead47":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nimport skimage as sk\nimport random","7470abfc":"from PIL import Image\ndef prepare_dataset(path):\n    #declare arrays\n    x=[]\n    y=[]\n    \n    #start to push images and labels to declared arrays\n    data_folders = os.listdir(path)\n    for folder in data_folders:\n        full_path = os.path.join(path,folder)\n        for img in os.listdir(full_path):\n            image = Image.open(os.path.join(full_path,img)).convert('L') #convert readed image to grayscale\n            image = image.resize((224,224),Image.ANTIALIAS)\n            x.append(np.asarray(image))\n            if('non' in full_path): #if non hemmorhage, result is 0\n                y.append(0)\n            else:\n                y.append(1)\n            \n    x = np.asarray(x)\n    y = np.asarray(y)\n    \n    \n    return (x,y)\n                    \n\n(x_train,y_train) = prepare_dataset('..\/input\/brain tumor images dataset\/Brain Tumor Images Dataset\/training_set\/')\n(x_test,y_test) = prepare_dataset('..\/input\/brain tumor images dataset\/Brain Tumor Images Dataset\/test_set\/')\n(x_validation,y_validation) = prepare_dataset('..\/input\/brain tumor images dataset\/Brain Tumor Images Dataset\/validation_set\/')\n\n#Shapes\nprint(\"Shape of x_train {}\\nShape of x_test{}\\nShape of x_validation{}\".format(x_train.shape,x_test.shape,x_validation.shape))","b12bddec":"#random examples from x_train\ndef random_example(x,y,rows,cols):\n    row = 0\n    col = 0\n    f, axarr = plt.subplots(rows,cols)\n\n    for i in range(3):\n        for k in range(2):  \n            rnd = random.randint(0,len(x))\n            axarr[row,col].imshow(x[rnd],cmap='gray')\n            if(y is not None):\n                axarr[row,col].set_title(\"Has Tumor\" if y[rnd] == 1 else \"No Tumor\")\n            col += 1\n        col = 0\n        row += 1\n        \n    #f.subplots_adjust(wspace=5)\n    f.tight_layout(pad=0.9,h_pad=2.0)\n\n    plt.show()\n    \nrandom_example(x_train,None,3,2)","5a6ea84e":"#Data Augmentation\nclass Augmentation:\n    def __init__(self):\n        pass\n        \n    def random_rotation(self,data,label):\n        # pick a random degree of rotation between 25% on the left and 25% on the right\n        augmented_images = []\n        augmented_label = []\n        random_degree = random.uniform(-25, 25)\n        counter = 0\n        for img in data:\n            img = sk.transform.rotate(img, random_degree)\n            augmented_images.append(img)\n            augmented_label.append(label[counter])\n            counter += 1\n        return (augmented_images,augmented_label)\n    \n    # add random noise to the image\n    def random_noise(self,data,label):\n        augmented_images = []\n        augmented_label = []\n        counter = 0\n        for img in data:\n            img = sk.util.random_noise(img)\n            augmented_images.append(img)\n            augmented_label.append(label[counter])\n            counter += 1\n        \n        return (augmented_images,augmented_label)\n\n    def horizontal_flip(self,data,label):\n        # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n        counter = 0\n        augmented_images = []\n        augmented_label = []\n        for img in data:\n            img = img[:, ::-1]\n            augmented_images.append(img)\n            augmented_label.append(label[counter])\n            counter += 1\n        return (augmented_images,augmented_label)\n    \n    def vertical_flip(self,data,label):\n        counter = 0\n        augmented_images = []\n        augmented_label = []\n        for img in data:\n            img = np.flip(img)\n            augmented_images.append(img)\n            augmented_label.append(label[counter])\n            counter += 1\n        return (augmented_images,augmented_label)\n    \n   \n\nAUG = Augmentation()\n\n(x_noise,y_noise) = AUG.random_noise(x_train,y_train)\n(x_h_flipped,y_h_flipped) = AUG.horizontal_flip(x_train,y_train)\n(x_v_flipped,y_v_flipped) = AUG.vertical_flip(x_train,y_train)\n(x_rotated,y_rotated) = AUG.random_rotation(x_train,y_train)\n","01d1a8a4":"#concat data \n\nx_noise = np.asarray(x_noise)\nx_h_flipped = np.asarray(x_h_flipped)\nx_v_flipped = np.asarray(x_v_flipped)\nx_rotated = np.asarray(x_rotated)\n\nx_train = np.concatenate((x_train,x_noise,x_h_flipped,x_v_flipped,x_rotated),axis=0)\n\n#----------------------------------------------------------------------------------------------------------------------------------------------------------------\n\ny_noise = np.asarray(y_noise)\ny_h_flipped = np.asarray(y_h_flipped)\ny_v_flipped = np.asarray(y_v_flipped)\ny_rotated = np.asarray(y_rotated)\n\ny_train = np.concatenate((y_train,y_noise,y_h_flipped,y_v_flipped,y_rotated),axis=0)\n\nrandom_example(x_train,y_train,3,2)","ac0fa1bd":"#convert np arrays to tensors\nimport torch\n\nx_train = torch.from_numpy(x_train)\nx_test = torch.from_numpy(x_test)\n\ny_train = torch.from_numpy(y_train)\ny_test = torch.from_numpy(y_test)\n\n\ntrain = torch.utils.data.TensorDataset(x_train,y_train) \ntrain_loader = torch.utils.data.DataLoader(train,batch_size=4,shuffle=True) \n\ntest = torch.utils.data.TensorDataset(x_test,y_test)\ntest_loader = torch.utils.data.DataLoader(test,batch_size=4,shuffle=False)\n","ac946db9":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\n\n#Resnet Architecture\n\ndef conv3x3(in_planes,out_planes,stride=1):\n    return nn.Conv2d(in_planes,out_planes,kernel_size=3,stride=stride,padding=1,bias=False)\n\ndef conv1x1(in_planes,out_planes,stride=1):\n    return nn.Conv2d(in_planes,out_planes,kernel_size=1,stride=stride,bias=False)\n\nclass BasicBlock(nn.Module): \n\n    expansion = 1\n\n    def __init__(self,inplanes,planes,stride=1,downsample=None): #planes for output\n        super(BasicBlock,self).__init__()\n        self.conv1 = conv3x3(inplanes,planes,stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.drop = nn.Dropout(0.5)\n        self.conv2 = conv3x3(planes,planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self,x):\n        identity = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out= self.relu(out)\n        out = self.drop(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.drop(out)\n\n        if(self.downsample is not None):\n            identity = self.downsample(x)\n        out += identity \n        out = self.relu(out)\n\n        return out\n","35cdb4ec":"num_classes = 2\nclass ResNet(nn.Module):\n\n    def __init__(self,block,layers,num_classes=num_classes):\n        super(ResNet,self).__init__()\n        self.inplanes = 64 # according to research paper\n        self.conv1 = nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3,bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size = 3,stride=2,padding=1)\n        self.layer1 = self._make_layer(block,64,layers[0],stride=1)\n        self.layer2 = self._make_layer(block,128,layers[1],stride=2)\n        self.layer3 = self._make_layer(block,256,layers[2],stride=2)\n        self.layer4 = self._make_layer(block,512,layers[3],stride=2)\n        \n        self.avgpooling = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(512*block.expansion,num_classes)\n\n        for m in self.modules(): \n            if isinstance(m,nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight,mode=\"fan_out\",nonlinearity=\"relu\") \n            elif isinstance(m,nn.BatchNorm2d):\n                nn.init.constant_(m.weight,1)\n                nn.init.constant_(m.bias, 0)\n\n\n    def _make_layer(self,block,planes,num_layers,stride = 1):\n        downsample = None\n        if stride!=1 or self.inplanes != planes*block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes,planes*block.expansion,stride),\n                nn.BatchNorm2d(planes*block.expansion)\n            )\n        layers = []\n        layers.append(block(self.inplanes,planes,stride,downsample))\n        self.inplanes = planes*block.expansion\n        for _ in range(1,len(layers)):\n            layers.append(block(self.inplanes,planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self,x):\n        x= self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x=self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpooling(x)\n\n        x = x.view(x.size(0),-1) #flatten\n        x = self.fc(x)\n\n        return x","a90ca478":"#resnet 50\n#model = ResNet(BottleNeck,[3,4,6,3])\n\n#resnet 18\nmodel = ResNet(BasicBlock,[2,2,2,2],num_classes=2)\nmodel.cuda()\ndevice = torch.device(\"cuda\")\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),0.0001) #0.0001 is learning rate\n\ntotal_step = len(train_loader)\nloss_list = []\ntrain_acc = []\ntest_acc = []\nbatch_size = 4\nfor epoch in range(300):\n    for i,data in enumerate(train_loader,0): #enumarete train_loader ve 0\n        # i --->index , data ----> image\n        inputs,labels= data\n        try:\n            inputs = inputs.view(batch_size,1,224,224)\n            inputs = inputs.float()\n        except:\n            continue\n        \n        \n        if torch.cuda.is_available():\n            inputs,labels = inputs.to(device),labels.to(device)\n\n        #zero gradient\n        optimizer.zero_grad()\n\n        #forward\n        outputs = model(inputs)\n        #loss\n        loss = criterion(outputs,labels) #compare outputs and labels\n        #backward\n        loss.backward()\n        #update weigths\n        optimizer.step()\n        if(i==(len(x_train)\/batch_size)-1 and epoch%10 == 0):\n            print(\"Epoch : {}\".format(epoch))\n    \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in train_loader:\n            images,labels = data\n            try:\n                images = images.view(batch_size,1,224,224)\n                images = images.float()\n            except:\n                continue #throws error because of dataset but it's not a problem to continue\n            \n            if torch.cuda.is_available():\n                images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            _,predicted = torch.max(outputs.data,1) #returns max value index\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_acc.append((100*correct\/total))\n        loss_list.append(loss.item())\n        if(epoch % 10 == 0):\n            print(\"Accuracy train: \",(100*correct\/total))\n            ","dc2335bc":"plt.subplot(2, 1, 1)\nplt.plot(loss_list)\nplt.title(\"Loss\")\n\nplt.subplot(2, 1, 2)\nplt.plot(np.array(train_acc)\/100,label=\"Train Accuracy\",color='green')\nplt.title(\"Train Accuracy\")\n\nplt.tight_layout(pad=0.9,h_pad=2.0)\n\nplt.show()\n","18d681b6":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images,labels = data\n        try:\n            images = images.view(batch_size,1,224,224)\n            images = images.float()\n        except:\n            continue\n\n        if torch.cuda.is_available():\n            images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        _,predicted = torch.max(outputs.data,1) #returns max value index\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        test_acc.append((100*correct\/total))\n\nprint(\"Test Accuracy: \",sum(test_acc)\/len(test_acc))\n","72490e0a":"**An example for BasicBlock**\n![BasicBlock](https:\/\/miro.medium.com\/max\/1140\/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)","ca132142":"**RESNET ARCHITECTURE**\n\n![ResNet Model](https:\/\/www.researchgate.net\/profile\/Muhammad_Hasan19\/publication\/323063171\/figure\/fig1\/AS:603178554904576@1520820382219\/Proposed-Modified-ResNet-18-architecture-for-Bangla-HCR-In-the-diagram-conv-stands-for.png)"}}