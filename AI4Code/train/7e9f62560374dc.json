{"cell_type":{"839bc263":"code","f0b40d25":"code","6a538329":"code","66808df8":"code","642274ea":"code","eeb24e8c":"code","f859c956":"code","73bdf8c1":"code","c2d0e3a3":"code","38031b96":"code","388e569e":"code","ce803816":"code","77c36144":"code","d9e267d1":"code","59e64371":"code","c2aa8f2d":"code","d2fb4895":"code","1b6c163f":"code","6d8a8185":"code","14bd7a43":"code","58521b25":"code","d6d4f002":"code","439aad8c":"code","b7e46f4f":"code","93a71552":"code","b6c5c638":"code","b14f17b3":"code","5d8a8a67":"code","4bf4f576":"code","b4a2f64f":"code","0237fbfa":"code","8e5fda2c":"code","dc965eb9":"code","e78ae6cc":"code","e1507000":"code","6d3a6751":"code","3a47a9cb":"code","01851415":"code","de3c10c5":"code","c8958912":"code","92e94d78":"code","b66bb1c3":"code","ce9efc93":"code","fb9bb29c":"code","240d7fec":"code","63492cb4":"code","08b3b885":"code","2e7d4130":"code","4fc683ad":"code","35c77907":"code","0ba4253a":"code","92a001ff":"code","4f2a09f9":"code","5634ae29":"code","b99bd102":"code","129dc3a0":"code","cfa32b7e":"code","3e8a9235":"code","17a1e221":"code","117f61b0":"code","ce28ee5f":"code","ff2b9b22":"code","4e5c2d30":"code","b8a013d1":"code","8b61716c":"code","6258c41a":"code","16cae9fe":"code","04ca25aa":"code","ad3ed989":"code","8456cef5":"code","fd78c12d":"code","eeb847f2":"code","7868eee6":"code","ad508ba2":"code","c8079d41":"code","5bb19ad0":"code","b5b2ac90":"code","a194e351":"code","2cda7abd":"code","9f0e7584":"code","c1c099d3":"code","81b158f0":"code","c0662947":"code","d6c39d47":"code","574089ab":"code","35bb6518":"code","9c99d202":"code","3115738d":"code","fb6f193a":"code","04fde81c":"code","2487e111":"code","2923beb4":"code","ed60f1e2":"code","e7988267":"code","4dba93bc":"code","5d3bc320":"code","f93cc60b":"code","c8ca1fd1":"code","cfbaad68":"code","db428dd7":"code","45be8824":"code","d3941303":"markdown","01c92391":"markdown","09f2269b":"markdown","cecfa24f":"markdown","80e4f4ae":"markdown","0468815e":"markdown","2f031aa6":"markdown","c3358461":"markdown","ec7de0de":"markdown","c68b3264":"markdown","05b5b23e":"markdown","be9051e2":"markdown"},"source":{"839bc263":"# imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom ml_metrics import rmse\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.model_selection import learning_curve\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, STATUS_OK, Trials\nfrom functools import partial\nfrom sklearn.metrics import make_scorer\nimport lightgbm as lgb\nimport catboost as ctb","f0b40d25":"np.random.seed(2018)","6a538329":"# display data\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_row', 1500)","66808df8":"# load data\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_test['SalePrice'] = 0","642274ea":"df_train.head(5)","eeb24e8c":"df_train.info()","f859c956":"# delete Id variable, because it is unnecessary in compute\ndf_train = df_train.drop(['Id'], axis = 1)","73bdf8c1":"df_train.shape","c2d0e3a3":"df_train.describe()","38031b96":"df_train.nunique()","388e569e":"df_train.isnull().any().any()","ce803816":"def missing_values(df):\n    for column in df.columns:\n        null_rows = df[column].isnull()\n        if null_rows.any() == True:\n            print('%s: %d nulls' % (column, null_rows.sum()))","77c36144":"missing_values(df_train)","d9e267d1":"df_train.sample(5)","59e64371":"plt.rcParams['figure.figsize']=(30,20)\nsns.heatmap(df_train.corr(method='spearman'), annot=True, linewidths=.5, cmap=\"Blues\");","c2aa8f2d":"# five most correlation variable with 'SalePrice'\ncorr = df_train.corr()\ncorr['SalePrice'].sort_values(ascending = False)[1:6]","d2fb4895":"corr['SalePrice'].sort_values(ascending = False)[-5:]","1b6c163f":"# get correlation matrix, where correlation value is greater than 70%\ncorr_matrix = df_train.corr(method='spearman')\ncorr_columns = corr_matrix[corr_matrix[corr_matrix > 0.7] < 1.0].any()\ncorr_matrix = corr_matrix[corr_columns][corr_columns.index[corr_columns]]\nplt.rcParams['figure.figsize']=(15,7)\nsns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap=\"Blues\");","6d8a8185":"print(df_train.SalePrice.skew())\n# A skewness value > 0 means, that there is more weight in the left tail of the distribution.","14bd7a43":"# target variable\nplt.rcParams['figure.figsize']=(10,5)\ndf_train['SalePrice'].hist();","58521b25":"df_train['SalePrice_bc'], _ = stats.boxcox(df_train['SalePrice'])\ndf_train['SalePrice_bc'].hist();","d6d4f002":"df_train['SalePrice_log'] = np.log2( df_train['SalePrice'] + 1)","439aad8c":"df_train['SalePrice_log'].hist();","b7e46f4f":"print(np.log2(df_train.SalePrice).skew())\n# Normally distributed data, the skewness should be about 0","93a71552":"def good_feats(df):\n    feats_from_df = set(df.select_dtypes([np.int]).columns.values)\n    bad_feats = {'SalePrice', 'SalePrice_bc'}\n    return list(feats_from_df - bad_feats)","b6c5c638":"def make_hist(df):\n    feats = good_feats(df)\n    for index, feat in enumerate(feats):\n        plt.subplot(len(feats)\/5+1, 5, index+1);\n        plt.title(feat);\n        df[feat].hist();","b14f17b3":"def make_scatter(df):\n    feats = good_feats(df)\n    for index, feat in enumerate(feats):\n        plt.subplot(len(feats)\/5+1, 5, index+1)\n        sns.regplot(x=feat, y='SalePrice', data=df_train)","5d8a8a67":"def make_bar(df):\n    cat_feats = df_train.select_dtypes(exclude = [np.int, np.float]).columns.values\n    cat_feats = cat_feats[:-1]\n    for index, feat in enumerate(cat_feats):\n        plt.subplot(len(cat_feats)\/5+1, 5, index+1)\n        sns.barplot(x=feat, y='SalePrice', data=df_train, palette=\"PRGn\");\n        plt.xticks(rotation=90);","4bf4f576":"%%time\nplt.figure(figsize=(25,25));\nplt.subplots_adjust(hspace = 0.35);\n\nmake_hist(df_train)","b4a2f64f":"%%time\nplt.figure(figsize=(25,25))\nplt.subplots_adjust(hspace = 0.3)\n\nmake_scatter(df_train)","0237fbfa":"%%time\nplt.figure(figsize=(20,40))\nplt.subplots_adjust(hspace = 0.5, wspace = 0.4)\n\nmake_bar(df_train)","8e5fda2c":"df_train.Neighborhood.head(10)","dc965eb9":"plt.rcParams['figure.figsize']=(15,8)\nsns.boxplot(x='Neighborhood', y='SalePrice', data=df_train, palette=\"PRGn\");\nplt.xticks(rotation=20);","e78ae6cc":"missing_values(df_train)","e1507000":"df_train['LotFrontage'].head(5)","6d3a6751":"LFbyN = df_train.groupby('Neighborhood')['LotFrontage'].median().to_dict()\ndf_train['LotFrontage'] = df_train.apply(lambda row: LFbyN[row['Neighborhood']]\n                                                    if pd.isnull(row['LotFrontage'])\n                                                    else row['LotFrontage'], axis = 1)","3a47a9cb":"df_train['Electrical'] = df_train['Electrical'].fillna('SBrkr')","01851415":"cats_nan = ['Alley', 'PoolQC', 'MiscFeature', 'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure',  'BsmtFinType1', 'BsmtFinType1', 'BsmtFinType2', 'GarageYrBlt']\nfor cat in cats_nan:\n    df_train[cat] = df_train[cat].fillna(\"None\")","de3c10c5":"missing_values(df_train)","c8958912":"cat_feats = df_train.select_dtypes(exclude = [np.number]).columns.values\ncat_feats","92e94d78":"def factorize(df, *columns):\n    feats = set(df.select_dtypes(exclude = [np.int, np.float]).columns.values)\n    for column in feats:\n        df[column + '_cat'] = pd.factorize(df[column])[0]","b66bb1c3":"#factorize(df_train)","ce9efc93":"#df_train = df_train.select_dtypes(include=[np.number]).interpolate().dropna()\n#df_train.head(5)","fb9bb29c":"#df_train.sample(5)","240d7fec":"def model_train_predict(model, X, y, success_metric=rmse):\n    print('split')\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    print('fit')\n    model.fit(X_train, y_train)\n    print('pred')\n    y_pred = model.predict(X_test)\n    return success_metric(y_test, y_pred)","63492cb4":"X = df_train[good_feats(df_train)].values\ny = df_train['SalePrice']","08b3b885":"model_train_predict(LinearRegression(), X, y)","2e7d4130":"# the most correlaated variable with target\ndf_train.OverallQual.isnull().any()","4fc683ad":"df_train.OverallQual.nunique()","35c77907":"df_train.OverallQual.unique()","0ba4253a":"df_train.OverallQual.value_counts()","92a001ff":"df_train.OverallQual.hist();","4f2a09f9":"plt.scatter(x=df_train['GrLivArea'], y=df_train['SalePrice']);","5634ae29":"df_train = df_train[df_train['GrLivArea'] < 4000]\ndf_test = df_test[df_test['GrLivArea'] < 4000]","b99bd102":"df_train['GrLivArea'] = np.log(df_train['GrLivArea'])\ndf_test['GrLivArea'] = np.log(df_test['GrLivArea'])","129dc3a0":"# GarageArea - correlation with target: 0.623431\ndf_train.GarageArea.head(5)","cfa32b7e":"plt.scatter(x=df_train['GarageArea'], y=df_train['SalePrice']);","3e8a9235":"# GarageCars - correlation with target: 0.640409\ndf_train.GarageCars.head(5)","17a1e221":"plt.scatter(x=df_train['GarageCars'], y=df_train['SalePrice']);","117f61b0":"df_train[['GarageCars','GarageArea']].sample(10)","ce28ee5f":"df_train = df_train[df_train['GarageArea'] < 1200]\ndf_test = df_test[df_test['GarageArea'] < 1200]\n#df_train = df_train[df_train['GarageCars'] <= 3]\n#df_test = df_test[df_test['GarageCars'] <= 3]","ff2b9b22":"df_train.TotalBsmtSF.sample(5)","4e5c2d30":"plt.scatter(x=df_train['TotalBsmtSF'], y=df_train['SalePrice']);","b8a013d1":"df_train = df_train[df_train['TotalBsmtSF'] < 3000]\ndf_test = df_test[df_test['TotalBsmtSF'] < 3000]","8b61716c":"df_train.FullBath.sample(5)","6258c41a":"plt.scatter(x=df_train['FullBath'], y=df_train['SalePrice']);","16cae9fe":"df_train.YearBuilt.sample(5)","04ca25aa":"plt.scatter(x=df_train['YearBuilt'], y=df_train['SalePrice']);","ad3ed989":"# street \ndf_train['Street'].value_counts()","8456cef5":"factorize(df_train, 'Street')\nfactorize(df_test, 'Street')","fd78c12d":"# sale condition\ndf_train['SaleCondition'].value_counts()","eeb847f2":"sns.barplot(x='SaleCondition', y='SalePrice', data=df_train, palette=\"PRGn\");","7868eee6":"df_train['SaleCondition'] = df_train['SaleCondition'].apply(lambda x: 1 if x == 'Partial' else 0)","ad508ba2":"sns.barplot(x='SaleCondition', y='SalePrice', data=df_train, palette=\"PRGn\");","c8079d41":"df_train['SaleCondition'].value_counts()","5bb19ad0":"df_train['BsmtQual'].value_counts()","b5b2ac90":"sns.barplot(x='BsmtQual', y='SalePrice', data=df_train, palette=\"PRGn\");","a194e351":"df_train['BsmtQual'] = df_train['BsmtQual'].apply(lambda x: 1 if x == 'Ex' else 0)\ndf_test['BsmtQual'] = df_test['BsmtQual'].apply(lambda x: 1 if x == 'Ex' else 0)","2cda7abd":"sns.barplot(x='BsmtQual', y='SalePrice', data=df_train, palette=\"PRGn\");","9f0e7584":"df_train['KitchenQual'].value_counts()","c1c099d3":"sns.barplot(x='KitchenQual', y='SalePrice', data=df_train, palette=\"PRGn\");","81b158f0":"df_train['KitchenQual'] = df_train['KitchenQual'].apply(lambda x: 1 if x == 'Ex' else 0)\ndf_test['KitchenQual'] = df_test['KitchenQual'].apply(lambda x: 1 if x == 'Ex' else 0)","c0662947":"sns.barplot(x='KitchenQual', y='SalePrice', data=df_train, palette=\"PRGn\");","d6c39d47":"df_train['CentralAir'].value_counts()","574089ab":"factorize(df_train, 'CentralAir')\nfactorize(df_test, 'CentralAir')","35bb6518":"df_train['TotalSF'] = df_train['TotalBsmtSF'] + df_train['1stFlrSF'] + df_train['2ndFlrSF']\ndf_test['TotalSF'] = df_test['TotalBsmtSF'] + df_test['1stFlrSF'] + df_test['2ndFlrSF']","9c99d202":"plt.scatter(x=df_train['TotalSF'], y=df_train['SalePrice']);","3115738d":"df_train.TotalSF.hist();","fb6f193a":"features = ['OverallQual', 'GrLivArea', 'GarageArea', 'FullBath', 'TotalSF', 'CentralAir_cat', 'KitchenQual_cat']","04fde81c":"X = df_train[features].values\ny = df_train['SalePrice_log']","2487e111":"model_train_predict(LinearRegression(), X, y)","2923beb4":"feats = ['OverallQual', 'GrLivArea', 'GarageArea', 'FullBath', 'TotalSF', 'CentralAir_cat', 'KitchenQual_cat']\n\nX = df_train[feats].values\ny = df_train['SalePrice_log'].values\n\nmodel = LinearRegression()\n\ncv = KFold(n_splits=4)\n\nscores = []\nfor train_idx, test_idx in cv.split(X):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = rmse(y_test, y_pred)\n    scores.append(score)\n    \n    \nprint(np.mean(scores), np.std(scores))","ed60f1e2":"def run_cv(model, X, y, folds=4, target_log=False, cv_type=KFold, success_metric=rmse):\n    cv = cv_type(n_splits=folds)\n    \n    scores = []\n    for train_idx, test_idx in cv.split(X):\n        X_train, X_test = X[train_idx], X[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n\n        if target_log:\n            y_train = np.log(y_train)\n\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        \n        if target_log: \n            y_pred = np.exp(y_pred)\n        y_pred[y_pred < 0] = 0\n\n        score = success_metric(y_test, y_pred)\n        scores.append(score)\n        \n    return np.mean(scores), np.std(scores)","e7988267":"run_cv(model, X, y, folds=3, target_log='SalePrice_log')","4dba93bc":"def plot_learning_curve(model, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \n    plt.figure(figsize=(12,8))\n    plt.title(title)\n    if ylim is not None:plt.ylim(*ylim)\n\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    \n    rmse_scorer = make_scorer(rmse)\n    \n    train_sizes, train_scores, test_scores = learning_curve(\n        model, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=rmse_scorer)\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","5d3bc320":"models = [\n    LinearRegression(),\n    DecisionTreeRegressor(max_depth=10),\n    RandomForestRegressor(max_depth=10),\n    ExtraTreesRegressor(max_depth=20)\n]\n\nfor model in models:\n    print(str(model) + \": \")\n    %time score = model_train_predict(model, X, y)\n    print(str(score) + \"\\n\")\n    plt = plot_learning_curve(model, \"Learning Curves\", X, y, ylim=(0.4, 0.0), n_jobs=4)\n    plt.show()","f93cc60b":"model = LinearRegression()\nmodel.fit(X, y)\n\nweights = list(model.coef_)\n\ndict_feats = {label :weight for label, weight in zip(feats, weights) }\nfeats = pd.DataFrame([dict_feats])\nfeats.plot(kind='bar', figsize=(13, 8), title=\"Feature importances\");","c8ca1fd1":"models = [\n    DecisionTreeRegressor(max_depth=10),\n    RandomForestRegressor(max_depth=10),\n    ExtraTreesRegressor(max_depth=20)\n]\n\nfor model in models:\n    model.fit(X, y)\n    importances = model.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    plt.figure(figsize=(10, 5))\n    plt.title('Feature importances: ' + str(model).split('(')[0])\n    plt.bar(range(X.shape[1]), model.feature_importances_[indices],\n           color = '#00bfff', align = 'center')\n    plt.xticks(range(X.shape[1]), [ good_feats(df_train)[x] for x in indices])\n    plt.xticks(rotation=90)\n    plt.xlim([-1, X.shape[1]])\n    plt.show()","cfbaad68":"feats = ['OverallQual', 'GrLivArea', 'GarageArea', 'FullBath', 'TotalSF', 'CentralAir_cat', 'KitchenQual_cat']\nX = df_train[feats].values\ny = df_train['SalePrice_log'].values\n\nrun_cv(xgb.XGBRegressor(), X, y, folds=4, target_log='SalePrice_log')","db428dd7":"X = df_train[feats].values\ny = df_train['SalePrice_log'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    \ndef objective(space):    \n    xgb_params = {\n        'max_depth': int(space['max_depth']),\n        'colsample_bytree': space['colsample_bytree'],\n        'learning_rate': space['learning_rate'],\n        'subsample': space['subsample'],\n        'seed': int(space['seed']),\n        'min_child_weight': int(space['min_child_weight']),\n        'reg_alpha': space['reg_alpha'],\n        'reg_lambda': space['reg_lambda'],\n        'n_estimators': 150\n    }\n    \n    model = xgb.XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train)\n    means_score, std_score = run_cv(xgb.XGBRegressor(), X, y, target_log=True)\n\n    print(means_score, std_score)\n    \n    print(\"SCORE: {0}\".format(score))\n    \n    return{'loss':score, 'status': STATUS_OK }\n\nspace ={\n    'max_depth': hp.quniform ('x_max_depth', 3, 8, 1),\n    'colsample_bytree': hp.uniform ('x_colsample_bytree', 0.3, 0.7),\n    'learning_rate': hp.uniform ('x_learning_rate', 0.1, 0.3), \n    'subsample': hp.uniform ('x_subsample', 0.3, 0.7),\n    'seed': hp.quniform ('x_seed', 0, 10000, 50),\n    'min_child_weight': hp.quniform ('x_min_child_weight', 1, 10, 1),\n    'reg_alpha': hp.loguniform ('x_reg_alpha', 0., 0.1),\n    'reg_lambda': hp.uniform ('x_reg_lambda', 0.9, 1.),\n    'n_estimators': hp.quniform ('x_n_estimators', 50, 300, 10)\n}\n\ntrials = Trials()\nbest_params = fmin(fn=objective,\n            space=space,\n            algo=partial(tpe.suggest, n_startup_jobs=1),\n            max_evals=100,\n            trials=trials)\n\nprint(\"The best params: \", best_params)","45be8824":"X = df_test[features].values\n\ndf_test['SalePrice'] = model.predict(X)\ndf_test[ ['Id','SalePrice'] ].to_csv('..\/lr.csv', index=False)","d3941303":"Columns: 81\nObject: 1460\nDtype: float64(3), int64(35), object(43)\nNaN: Yes\nTarget variale: SalePrice\nProblem: Regression\nMemory require: 924.0 KB\nCategorial variable: Yes\nAmount variable: Yes\nOrdinal variable: Yes\nDate: Yes (year)","01c92391":"The varable 'SalePrice' have skewed distribution, so I need transforn this variable, because Linear Regresin require it. I used log2. Also I tried use boxcox in order to comparison two transforn function.\nAfter I used log2 or boxcox I get normalize distribution.","09f2269b":"### Visualisation","cecfa24f":"### Info about data\n\nI used following function in orger to get some important info about data:\n\n    - info(): some help information\n    - shape: method, which describe shape of dataset\n    - describe(): compte descriptive statistics\n    - nunique():  number of unique elements\n    - isnull(): search missing value\n    - sample(n): return n random row\n    - corr(): compute correlation between columns","80e4f4ae":"Street is a feature, which contains information about type of road access. It has two type: pave and gravel.","0468815e":"# House Prices: Advanced Regression Techniques\n\nTarget: Predict the sales price for each house.\n\nSource: https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques#description","2f031aa6":"### Fix NaN variable","c3358461":"### Feature engineering\n\nTo feature engineering I choose feature based on correlation and visualisation. These are: OverallQual, GrLivArea, GarageCars, GarageArea, YearRemodeAdd, TotalBsmtSF, 1stFirSF, FullBath, TotRmsAbvGrd, YearBuilt, Street, SalesCondition, BsmtQual, KitchenQual, CentralAir, RoofMatl.","ec7de0de":"In dataset usually occurs type of SaleCondition is Normal type. However we must see another dependence. Namely what effect the type has on the target variable. Supreme dependence has Partial variable. Other types have the some dependence on target.","c68b3264":"### Basic model","05b5b23e":"### Transform categorial variable","be9051e2":"### Data description\n    \n   - SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n   - MSSubClass: The building class\n   - MSZoning: The general zoning classification\n   - LotFrontage: Linear feet of street connected to property\n   - LotArea: Lot size in square feet\n   - Street: Type of road access\n   - Alley: Type of alley access\n   - LotShape: General shape of property\n   - LandContour: Flatness of the property\n   - Utilities: Type of utilities available\n   - LotConfig: Lot configuration\n   - LandSlope: Slope of property\n   - Neighborhood: Physical locations within Ames city limits\n   - Condition1: Proximity to main road or railroad\n   - Condition2: Proximity to main road or railroad (if a second is present)\n   - BldgType: Type of dwelling\n   - HouseStyle: Style of dwelling\n   - OverallQual: Overall material and finish quality\n   - OverallCond: Overall condition rating\n   - YearBuilt: Original construction date\n   - YearRemodAdd: Remodel date\n   - RoofStyle: Type of roof\n   - RoofMatl: Roof material\n   - Exterior1st: Exterior covering on house\n   - Exterior2nd: Exterior covering on house (if more than one material)\n   - MasVnrType: Masonry veneer type\n   - MasVnrArea: Masonry veneer area in square feet\n   - ExterQual: Exterior material quality\n   - ExterCond: Present condition of the material on the exterior\n   - Foundation: Type of foundation\n   - BsmtQual: Height of the basement\n   - BsmtCond: General condition of the basement\n   - BsmtExposure: Walkout or garden level basement walls\n   - BsmtFinType1: Quality of basement finished area\n   - BsmtFinSF1: Type 1 finished square feet\n   - BsmtFinType2: Quality of second finished area (if present)\n   - BsmtFinSF2: Type 2 finished square feet\n   - BsmtUnfSF: Unfinished square feet of basement area\n   - TotalBsmtSF: Total square feet of basement area\n   - Heating: Type of heating\n   - HeatingQC: Heating quality and condition\n   - CentralAir: Central air conditioning\n   - Electrical: Electrical system\n   - 1stFlrSF: First Floor square feet\n   - 2ndFlrSF: Second floor square feet\n   - LowQualFinSF: Low quality finished square feet (all floors)\n   - GrLivArea: Above grade (ground) living area square feet\n   - BsmtFullBath: Basement full bathrooms\n   - BsmtHalfBath: Basement half bathrooms\n   - FullBath: Full bathrooms above grade\n   - HalfBath: Half baths above grade\n   - Bedroom: Number of bedrooms above basement level\n   - Kitchen: Number of kitchens\n   - KitchenQual: Kitchen quality\n   - TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n   - Functional: Home functionality rating\n   - Fireplaces: Number of fireplaces\n   - FireplaceQu: Fireplace quality\n   - GarageType: Garage location\n   - GarageYrBlt: Year garage was built\n   - GarageFinish: Interior finish of the garage\n   - GarageCars: Size of garage in car capacity\n   - GarageArea: Size of garage in square feet\n   - GarageQual: Garage quality\n   - GarageCond: Garage condition\n   - PavedDrive: Paved driveway\n   - WoodDeckSF: Wood deck area in square feet\n   - OpenPorchSF: Open porch area in square feet\n   - EnclosedPorch: Enclosed porch area in square feet\n   - 3SsnPorch: Three season porch area in square feet\n   - ScreenPorch: Screen porch area in square feet\n   - PoolArea: Pool area in square feet\n   - PoolQC: Pool quality\n   - Fence: Fence quality\n   - MiscFeature: Miscellaneous feature not covered in other categories\n   - MiscVal: $Value of miscellaneous feature\n   - MoSold: Month Sold\n   - YrSold: Year Sold\n   - SaleType: Type of sale\n   - SaleCondition: Condition of sale\n"}}