{"cell_type":{"c45c6487":"code","d74379ed":"code","0d23dc3d":"code","8b48ee3f":"code","cf74863e":"code","f92a741a":"code","16bc135a":"code","a3954e4a":"code","afd8afcf":"code","a0a8e2ab":"code","361aac6d":"code","0d1e50e2":"code","38fb6ce1":"code","75d83e6e":"code","35aa5e19":"code","546eb128":"code","0886a1ea":"code","5939831e":"code","cdc1036c":"code","00c4668c":"code","4bef3706":"code","8605803f":"code","e8fb91ca":"code","35deee59":"code","d1d42539":"code","388526fa":"code","2cf0e7a1":"code","1a2325e7":"code","f999a10e":"code","3ba5e693":"code","69a8c571":"code","8ebb1e79":"code","fadf55f1":"code","64d12201":"code","442b77a8":"code","aeccf34b":"code","667f5bf6":"code","28f50235":"code","7d61aab8":"code","169b5c8c":"markdown","ac327ec8":"markdown","96184804":"markdown","98aa53d8":"markdown","b1cb5b7d":"markdown","626c3aff":"markdown","914151e6":"markdown","fdf5d0a6":"markdown","69cf27f8":"markdown","60294a43":"markdown","82fbe22d":"markdown","10d00bda":"markdown","8b09054d":"markdown","bbe81518":"markdown","6a91ecce":"markdown","9b53d52b":"markdown","63e6d303":"markdown","2fe88019":"markdown","40b75e39":"markdown","cf22e17c":"markdown","7a93cbaa":"markdown"},"source":{"c45c6487":"# System\nimport os\n\n# Time\nimport time\nimport datetime\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# Tools\nimport itertools\nfrom collections import Counter\n\n# NLP\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n# from pywsd.utils import lemmatize_sentence\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom bs4 import BeautifulSoup\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# Machine Learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\n# Deep Learing Preprocessing - Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\n\n# Deep Learning Model - Keras\nfrom keras.models import Model\nfrom keras.models import Sequential\n\n# Deep Learning Model - Keras - CNN\nfrom keras.layers import Conv1D, Conv2D, Convolution1D, MaxPooling1D, SeparableConv1D, SpatialDropout1D, \\\n    GlobalAvgPool1D, GlobalMaxPool1D, GlobalMaxPooling1D \nfrom keras.layers.pooling import _GlobalPooling1D\nfrom keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n\nfrom keras.layers import MaxPooling3D, GlobalMaxPooling3D, GlobalAveragePooling3D\n\n\n\n# Deep Learning Model - Keras - RNN\nfrom keras.layers import Embedding, LSTM, Bidirectional\n\n# Deep Learning Model - Keras - General\nfrom keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\nfrom keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n\n\n\n# Deep Learning Parameters - Keras\nfrom keras.optimizers import RMSprop, Adam\n\n# Deep Learning Callbacs - Keras\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))","d74379ed":"# print date and time for given type of representation\ndef date_time(x):\n    if x==1:\n        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==2:    \n        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==3:  \n        return 'Date now: %s' % datetime.datetime.now()\n    if x==4:  \n        return 'Date today: %s' % datetime.date.today() ","0d23dc3d":"input_directory = r\"..\/input\/\"\noutput_directory = r\"..\/output\/\"\n\nif not os.path.exists(output_directory):\n    os.mkdir(output_directory)\n    \nfigure_directory = \"..\/output\/figures\"\nif not os.path.exists(figure_directory):\n    os.mkdir(figure_directory)\n    \n    \nfile_name_pred_batch = figure_directory+r\"\/result\"\nfile_name_pred_sample = figure_directory+r\"\/sample\"","8b48ee3f":"df = pd.read_csv(\"..\/input\/Tweets.csv\")","cf74863e":"df.head()","f92a741a":"df.info()","16bc135a":"columns = df.columns\ncolumns","a3954e4a":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\nplt.subplot(121)\ncol = \"airline\"\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\nsns.countplot(x=df[col])\nplt.title(\"Airlines Review Count\")\nplt.xticks(rotation=90)\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\n\n\nplt.subplot(122)\ncol = \"airline_sentiment\"\nxlabel = \"Sentiment\"\nylabel = \"Count\"\nsns.countplot(df[col])\nplt.title(\"Review Sentiment Count\")\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()","afd8afcf":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Negative Reason\"\nylabel = \"Count\"\n\ntitle = \"Negative Reason Per Airlines\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol1 = \"negativereason\"\ncol2 = \"airline\"\nsns.countplot(x=df[col1], hue=df[col2])\nplt.title(title)\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()","a0a8e2ab":"figsize=(20, 5)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\nplt.figure(figsize=figsize)\ncol1 = \"airline\"\ncol2 = \"airline_sentiment\"\nsns.countplot(x=df[col1], hue=df[col2])\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()\n","361aac6d":"x = df[\"negativereason_confidence\"].fillna(-1)\n\nfigsize=(18, 5)\n\nticksize = 12\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\nsns.distplot(x)\nplt.plot()","0d1e50e2":"figsize=(18, 30)\n\nticksize = 12\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Airlines\"\nylabel = \"Count\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol = \"user_timezone\"\ncol2 = \"airline_sentiment\"\nsns.countplot(y=df[col], hue=df[col2])\nplt.xticks(rotation=90)\nplt.plot()","38fb6ce1":"from nltk.corpus import stopwords\n\nX = df\n\nX[\"text\"] = X[\"text\"].apply(lambda x: BeautifulSoup(x, \"lxml\").get_text())\nX[\"text\"] = X[\"text\"].apply(lambda x: x.lower())\nX[\"text\"] = X[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\nX[\"text\"] = X[\"text\"].apply(lambda x: re.sub(\"\\s+\", \" \", x))\n\nX = X[X[\"airline_sentiment_confidence\"]>0.5]\n\ny = X[\"airline_sentiment\"]\nX = X[\"text\"]\n\nstopwords = stopwords.words('english')\n# vectorizer = TfidfVectorizer()\nvectorizer = CountVectorizer(stop_words=stopwords)\n\nX = vectorizer.fit_transform(X)\n\nmodel = RandomForestClassifier(n_estimators=5, n_jobs=-1, class_weight='balanced', random_state=0)\n# model = SVC()\n\nprint(cross_val_score(model, X, y, cv=3))  ","75d83e6e":"main_model_dir = output_directory + r\"models\/\"\nmain_log_dir = output_directory + r\"logs\/\"\n\ntry:\n    os.mkdir(main_model_dir)\nexcept:\n    print(\"Could not create main model directory\")\n    \ntry:\n    os.mkdir(main_log_dir)\nexcept:\n    print(\"Could not create main log directory\")\n\n\n\nmodel_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"\/\"\nlog_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n\n\ntry:\n    os.mkdir(model_dir)\nexcept:\n    print(\"Could not create model directory\")\n    \ntry:\n    os.mkdir(log_dir)\nexcept:\n    print(\"Could not create log directory\")\n    \nmodel_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"","35aa5e19":"print(\"Settting Callbacks\")\n\ncheckpoint = ModelCheckpoint(\n    model_file, \n    monitor='val_acc', \n    save_best_only=True)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    verbose=1,\n    restore_best_weights=True)\n\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=1,\n    verbose=1)\n\n\ncallbacks = [checkpoint, reduce_lr, early_stopping]\n\n# callbacks = [early_stopping]\n\nprint(\"Set Callbacks at \", date_time(1))","546eb128":"X = df.text\nY = df.airline_sentiment\n\nlabel_encoder = LabelEncoder()\n\nY = label_encoder.fit_transform(Y)\n\nY = to_categorical(Y)\n\n# Y = Y.reshape(-1, 1)\nY","0886a1ea":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n\nmax_words = len(set(\" \".join(X_train).split()))\nmax_len = X_train.apply(lambda x: len(x)).max()\n\n# max_words = 1000\n# max_len = 150\nmax_words, max_len","5939831e":"tokenizer = Tokenizer(num_words=max_words)\n\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_train_seq = sequence.pad_sequences(X_train_seq, maxlen=max_len)","cdc1036c":"# Calculate Class Weights\ndef get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current","00c4668c":"class_weight = get_weight(Y_train.flatten())","4bef3706":"def get_rnn_model(num_class=2):\n    model = Sequential()\n    \n    model.add(Embedding(max_words, 100, input_length=max_len))\n    model.add(LSTM(256))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(512, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    if num_class>2:\n        model.add(Dense(num_class, activation='softmax'))\n    else:\n        model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    \n    return model\n\n\ndef get_cnn_model(num_class=2):   \n    model = Sequential()\n    \n    model.add(Embedding(max_words, 100, input_length=max_len))\n    \n    model.add(Conv1D(1024, 3, padding='valid', activation='relu', strides=1))\n    model.add(GlobalMaxPooling1D())\n    \n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(2048, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    if num_class>2:\n        model.add(Dense(num_class, activation='softmax'))\n    else:\n        model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    return model","8605803f":"def plot_performance(history=None, figure_directory=None, ylim_pad=[0, 0]):\n    xlabel = 'Epoch'\n    legends = ['Training', 'Validation']\n\n    plt.figure(figsize=(20, 5))\n\n    y1 = history.history['acc']\n    y2 = history.history['val_acc']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[0]\n    max_y = max(max(y1), max(y2))+ylim_pad[0]\n\n\n    plt.subplot(121)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Accuracy\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Accuracy', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n\n    y1 = history.history['loss']\n    y2 = history.history['val_loss']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[1]\n    max_y = max(max(y1), max(y2))+ylim_pad[1]\n\n\n    plt.subplot(122)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Loss\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Loss', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n    if figure_directory:\n        plt.savefig(figure_directory+\"\/history\")\n\n    plt.show()\n","e8fb91ca":"num_class = 3\nmodel1 = get_rnn_model(num_class=num_class)","35deee59":"loss = 'categorical_crossentropy'\n# loss = 'binary_crossentropy'\nmetrics = ['accuracy']","d1d42539":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory1 = model1.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","388526fa":"plot_performance(history=history1)","2cf0e7a1":"num_class = 3\nmodel2 = get_cnn_model(num_class=num_class)","1a2325e7":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel2.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory2 = model2.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","f999a10e":"plot_performance(history=history2)","3ba5e693":"test_X_seq = tokenizer.texts_to_sequences(X_test)\ntest_X_seq = sequence.pad_sequences(test_X_seq, maxlen=max_len)\naccuracy1 = model1.evaluate(test_X_seq, Y_test)\naccuracy2 = model2.evaluate(test_X_seq, Y_test)","69a8c571":"print(\"Model Performance of RNN (Test Accuracy):\")\nprint('Accuracy: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy1[1]*100, accuracy1[0]))\n\nprint(\"\\nModel Performance of RNN (Test Accuracy):\")\nprint('v: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy2[1]*100, accuracy2[0]))","8ebb1e79":"ypreds1 = model1.predict_classes(test_X_seq, verbose=1)\nypreds2 = model2.predict_classes(test_X_seq, verbose=1)","fadf55f1":"def plot_model_performace(result):\n    sns.set_style(\"ticks\")\n    figsize=(22, 6)\n\n    ticksize = 12\n    titlesize = ticksize + 8\n    labelsize = ticksize + 5\n\n    xlabel = \"Model\"\n    ylabel = \"Score\"\n\n    title = \"Model Performance\"\n\n    params = {'figure.figsize' : figsize,\n              'axes.labelsize' : labelsize,\n              'axes.titlesize' : titlesize,\n              'xtick.labelsize': ticksize,\n              'ytick.labelsize': ticksize}\n\n    plt.rcParams.update(params)\n\n    col1 = \"model\"\n    col2 = \"score\"\n    sns.barplot(x=col1, y=col2, data=result)\n    plt.title(title.title())\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.plot()\n    plt.show()\n    print(result)","64d12201":"# print(classification_report(Y_test, ypreds1))","442b77a8":"plot_confusion_matrix(Y_test, ypreds1, title=\"RNN\")","aeccf34b":"# print(classification_report(Y_test, ypreds2))","667f5bf6":"# plot_confusion_matrix(Y_test, ypreds2, title=\"CNN\")","28f50235":"result = pd.DataFrame({'model': 'RNN', 'score': accuracy1[1]*100}, index=[-1])\nrow2 = pd.DataFrame({'model': 'CNN', 'score': accuracy2[1]*100}, index=[-1])\nresult = pd.concat([row2, result.ix[:]]).reset_index(drop=True)","7d61aab8":"plot_model_performace(result)","169b5c8c":"### 5.1 Output Configuration","ac327ec8":"### 10.3.1. RNN","96184804":"### 10.3.1. RNN","98aa53d8":"# 3. Visualize Data","b1cb5b7d":"## 4. Training Model","626c3aff":"Note:\n1. Most of negative confidence values are centered around 0.6-0.9","914151e6":"## 5. Deep Learning","fdf5d0a6":"Note:\n1. Most of the review present here are negative.\n2. Highest number of tweets are about \"United Airlines\", \"US Airlines\" and \"American Airlines\"","69cf27f8":"#### 10.5.1.2 Visualization","60294a43":"# 1. Import","82fbe22d":"# Reference:\n1. [Text Preprocessing and Machine Learning Modeling](https:\/\/www.kaggle.com\/futurist\/text-preprocessing-and-machine-learning-modeling)\n2. [keras mlp cnn test for text classification](https:\/\/www.kaggle.com\/jacklinggu\/keras-mlp-cnn-test-for-text-classification)","10d00bda":"### 5.2. Preprocessing","8b09054d":"#### 10.3.1.2 Visualization","bbe81518":"## 10.5 Inference\/ Prediction","6a91ecce":"#### 10.3.1.2  Visualization","9b53d52b":"# 2. Read Data","63e6d303":"![](https:\/\/diginomica.com\/wp-content\/uploads\/2015\/10\/american-airlines1.jpg)","2fe88019":"### 5.3 Model","40b75e39":"Note:\n1. Most of the negative tweets are about \"Customer Service Issue\".","cf22e17c":"### 10.5.1 Evaluation","7a93cbaa":"## 10.3. Model Trainning"}}