{"cell_type":{"5a32e620":"code","1a22ee75":"code","2422cc90":"code","815fc7ca":"code","ea8dff81":"code","5ae9d2f9":"code","841746b1":"code","be2774bc":"code","78972e0a":"code","b9e48293":"code","2dc729db":"code","de056bfa":"code","cd6f8228":"code","8a576a24":"code","236043d3":"code","44d68021":"code","de6a6be3":"code","e7866b67":"code","87ff3105":"code","2f8f692d":"code","b647176f":"code","05d8fc1d":"code","9bde6521":"code","02bfa1ff":"code","814fb84a":"code","0c95d7d1":"code","43a98cc2":"code","fad24be1":"code","79d1b07a":"code","441f3bfe":"code","5a409abe":"code","aa93eb7d":"code","3aa3decf":"code","bcce7718":"markdown","8c8b03d3":"markdown","7d5e4f55":"markdown","c269a5d2":"markdown","686561a0":"markdown","4513d17f":"markdown","074cb55f":"markdown","087f09db":"markdown","1c36ca1c":"markdown"},"source":{"5a32e620":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nimport cv2","1a22ee75":"!cp \/kaggle\/input\/gdcm-conda-install\/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline .\/gdcm\/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2","2422cc90":"root_path = \"\/kaggle\/input\/siim-covid19-detection\/\"","815fc7ca":"df_image = pd.read_csv(os.path.join(root_path, \"train_image_level.csv\"))\ndf_study = pd.read_csv(os.path.join(root_path, \"train_study_level.csv\"))","ea8dff81":"train_path = os.path.join(root_path, \"train\")\ntest_path = os.path.join(root_path, \"test\")","5ae9d2f9":"train_filenames = [os.path.join(dirname,filename) for dirname,_,filenames in os.walk(train_path) for filename in filenames]\ntest_filenames = [os.path.join(dirname,filename) for dirname,_,filenames in os.walk(test_path) for filename in filenames]","841746b1":"train_dict = {x.split('\/')[-1].replace('.dcm','_image'): x for x in train_filenames}\ntest_dict = {x.split('\/')[-1].replace('.dcm','_image'): x for x in test_filenames}","be2774bc":"df_image['path'] = df_image[\"id\"].map(train_dict)\ndf_image['id']=df_image['id'].apply(lambda x: x.replace('_image',''))\ndf_image['simplified_path']=df_image['path'].apply(lambda x: '\/'.join(x.split('\/')[5:]))\n\ndf_study = df_study.rename(columns={'id':'StudyInstanceUID'}, inplace=False)\ndf_study['StudyInstanceUID'] = df_study['StudyInstanceUID'].apply(lambda x: x.replace('_study',''))","78972e0a":"df_train = df_image.merge(df_study, how='inner', on='StudyInstanceUID')","b9e48293":"columns_reordered=['id',\n 'StudyInstanceUID',\n 'boxes',\n 'label',\n 'Negative for Pneumonia',\n 'Typical Appearance',\n 'Indeterminate Appearance',\n 'Atypical Appearance',\n 'path',\n 'simplified_path']\ndf_train = df_train[columns_reordered]","2dc729db":"from sklearn.model_selection import train_test_split\nx_train, x_valid = train_test_split(list(df_train[\"path\"]), test_size=0.2, random_state=42, shuffle=True)","de056bfa":"os.makedirs(\"dataset_det\/train\", exist_ok=True)\nos.makedirs(\"dataset_det\/valid\", exist_ok=True)\nos.makedirs(\"dataset_det\/test\", exist_ok=True)","cd6f8228":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm","8a576a24":"orig_shapes = {\"train\" : list(), \"valid\" : list(), \"test\" : list()}","236043d3":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","44d68021":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","de6a6be3":"def save_dcm_as_png(source, dest, mode = \"train\", size = 832):\n    image = read_xray(source)\n\n    orig_shapes[mode].append((image.shape[1], image.shape[0]))\n    \n    image = resize(image, size)\n    image.save(dest)","e7866b67":"for x in x_train:\n    save_dcm_as_png(x, \n                    os.path.join(\"dataset_det\/train\",\n                                 x.split(\"\/\")[-1][:-3] + \"png\"),\n                   mode = \"train\")","87ff3105":"for x in x_valid:\n    save_dcm_as_png(x, \n                    os.path.join(\"dataset_det\/valid\", \n                                    x.split(\"\/\")[-1][:-3] + \"png\"),\n                   mode = \"valid\")","2f8f692d":"\"\"\"for x in test_filenames:\n    save_dcm_as_png(x, os.path.join(\"dataset_det\/test\", \n                                    x.split(\"\/\")[-1][:-3] + \"png\"),\n                   mode = \"test\")\"\"\"","b647176f":"!cp -R dataset_det dataset_class","05d8fc1d":"import csv\nimport math","9bde6521":"def isNaN(string):\n    return string != string\n\n#csv format\ndef create_labels_for_det(input_size = 832, mode = \"train\"):\n    \n    if mode == \"train\":\n        filenames = x_train\n    elif mode == \"valid\":\n        filenames = x_valid\n    \n    labels = []\n    csv_columns = [\"path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class\"]\n    csv_file = \".\/dataset_det\/{}.csv\".format(mode)\n    \n    for i, x in enumerate(filenames):\n        _id = x.split(\"\/\")[-1][:-4]\n\n        raw_boxes = list(df_train.loc[df_train[\"id\"] == _id][\"boxes\"])[0]\n        \n        if not isNaN (raw_boxes):\n            boxes = eval(raw_boxes)\n\n            orig_w, orig_h = orig_shapes[mode][i]\n\n            for box in boxes:\n                d = {}\n                w = (box[\"width\"] \/ orig_w) * input_size \n                h = (box[\"height\"] \/ orig_h) * input_size\n\n                xmin = (box[\"x\"] \/ orig_w) * input_size\n                ymin = (box[\"y\"] \/ orig_h) * input_size\n\n                xmax = xmin + w\n                ymax = ymin + h\n\n                d[\"path\"] = \".\/{}\/{}.png\".format(mode, _id) \n                d[\"xmin\"] = xmin\n                d[\"xmax\"] = xmax\n                d[\"ymin\"] = ymin\n                d[\"ymax\"] = ymax\n                d[\"class\"] = \"opacity\"\n                labels.append(d)\n        else:\n            os.remove(\"dataset_det\/{}\/{}.png\".format(mode, _id))\n    try:\n        with open(csv_file, 'w') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n            #writer.writeheader()\n            for entry in labels:\n                writer.writerow(entry)\n    except IOError:\n        print(\"I\/O error\")","02bfa1ff":"create_labels_for_det(mode = \"valid\")\ncreate_labels_for_det(mode = \"train\")","814fb84a":"d = {\"class\" : \"opacity\", \"id\" : 0}\ncsv_columns = list(d.keys())\nd = [d]\nd","0c95d7d1":"try:\n    with open(\".\/dataset_det\/classes.csv\", 'w') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n        #writer.writeheader()\n        for entry in d:\n            writer.writerow(entry)\nexcept IOError:\n    print(\"I\/O error\")","43a98cc2":"classes = list(df_train.columns)[4:8]\nclasses","fad24be1":"def create_labels_for_class(mode = \"train\"):\n    \n    if mode == \"train\":\n        filenames = x_train\n    elif mode == \"valid\":\n        filenames = x_valid\n    \n    labels = []\n    csv_columns = [\"path\", \"class\"]\n    csv_file = \".\/dataset_class\/{}.csv\".format(mode)\n    \n    for i, x in enumerate(filenames):\n        _id = x.split(\"\/\")[-1][:-4]\n\n        gt = [list(df_train.loc[df_train[\"id\"] == _id][c])[0] for c in classes]\n        c = classes[np.argmax(gt)]\n        \n        d = {}\n        d[\"path\"] = \".\/{}\/{}.png\".format(mode, _id) \n        d[\"class\"] = c\n\n        labels.append(d)\n    try:\n        with open(csv_file, 'w') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n            #writer.writeheader()\n            for entry in labels:\n                writer.writerow(entry)\n    except IOError:\n        print(\"I\/O error\")","79d1b07a":"create_labels_for_class(mode = \"train\")\ncreate_labels_for_class(mode = \"valid\")","441f3bfe":"!mkdir dataset\n!mv .\/dataset_det .\/dataset\n!mv .\/dataset_class .\/dataset","5a409abe":"!cp ..\/input\/siim-covid19-detection\/train_image_level.csv .\/dataset\n!cp ..\/input\/siim-covid19-detection\/train_study_level.csv .\/dataset","aa93eb7d":"!cp ..\/input\/siim-covid19-detection\/train_image_level.csv .\/dataset","3aa3decf":"!zip -r dataset_siim_covid.zip .\/dataset","bcce7718":"### Split and store images","8c8b03d3":"#### Study level - Classification","7d5e4f55":"#### Image level - Detection","c269a5d2":"<a href=\".\/dataset_siim_covid.zip\"> Download File <\/a>","686561a0":"# Load Data","4513d17f":"## Create data","074cb55f":"### Convert to png","087f09db":"### Prepare zip file for dowload","1c36ca1c":"### Create Labels"}}