{"cell_type":{"ef9141fe":"code","c5b05722":"code","df3b4895":"code","f0d68ce8":"code","a291196f":"code","2d7791ad":"code","4b371ef6":"code","81a16a10":"code","fe4f9eb3":"code","88b1783d":"code","00c5b649":"code","ece96087":"code","60383de7":"code","59df0599":"code","4c0e42f0":"code","e49275b1":"code","bc31b2c0":"code","b3a080c9":"code","e237be45":"code","4108d99f":"code","58e94750":"code","d33cc51b":"code","aeb47b18":"code","030bc365":"code","d5614836":"code","8336979d":"code","0be7c504":"code","c1761ed6":"code","1353df22":"code","0ccdb79a":"code","d0f9b89b":"code","6a704764":"code","f6afb293":"code","e3a27ed4":"code","fac492eb":"code","4dcc1f1c":"code","b289a421":"code","f0efbabe":"code","dbc9a253":"code","787cce5f":"code","24814a39":"markdown","974c5025":"markdown","9e5104c3":"markdown","d62a6d56":"markdown","06b58b9b":"markdown","5d366ae9":"markdown","5ca4023e":"markdown","4df64e59":"markdown"},"source":{"ef9141fe":"### NOTE\n# Before running this notebook, run read-dicom-info to generate train_df_dicom_data.csv. \n\nimport numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nsns.set(rc={\"figure.figsize\":(12, 8)})\n","c5b05722":"train_folder = '\/kaggle\/input\/siim-covid19-detection\/train'\ntest_folder = '\/kaggle\/input\/siim-covid19-detection\/test'\ntrain_image_level = '\/kaggle\/input\/siim-covid19-detection\/train_image_level.csv'\ntrain_study_level = '\/kaggle\/input\/siim-covid19-detection\/train_study_level.csv'\nsample_submission = '\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv'","df3b4895":"df_train_image = pd.read_csv(train_image_level)\ndf_train_study = pd.read_csv(train_study_level)","f0d68ce8":"df_train_image.head(1)","a291196f":"df_train_study.head(1)","2d7791ad":"#rename id with StudyInstanceUID to merge two dataframes\ndf_train_study.rename(columns={'id':'StudyInstanceUID'},inplace=True)\ndf_train_study.head(1)","4b371ef6":"# get rid of _image and _study\ndf_train_image['id'] = df_train_image['id'].apply(lambda x: x[0:-6])\ndf_train_study['StudyInstanceUID'] = df_train_study['StudyInstanceUID'].apply(lambda x: x[0:-6])","81a16a10":"df_train_merge = pd.merge(df_train_image,df_train_study,on='StudyInstanceUID')","fe4f9eb3":"df_train_merge.head(5)","88b1783d":"#unify class columns\ndf_train_merge.loc[df_train_merge['Negative for Pneumonia']==1,'class']='negative'\ndf_train_merge.loc[df_train_merge['Typical Appearance']==1,'class']='typical'\ndf_train_merge.loc[df_train_merge['Indeterminate Appearance']==1,'class']='indeterminate'\ndf_train_merge.loc[df_train_merge['Atypical Appearance']==1,'class']='atypical'\ndf_train_merge.drop(['Negative for Pneumonia','Typical Appearance',\n                     'Indeterminate Appearance','Atypical Appearance'],axis=1,inplace=True)\ndf_train_merge.head()","00c5b649":"df_train_merge.loc[4560,'label']","ece96087":"#get boxes and opacity values\nfor c in ['bbox','confidence','label_op']:\n    df_train_merge[c] = np.nan\n    df_train_merge[c] = df_train_merge[c].astype('object')\nfor r in df_train_merge.index:\n    val_len = len(df_train_merge['label'][r].split(' '))\n    val = df_train_merge['label'][r].split(' ')\n    nbox = int(val_len\/6)\n    boxes,cc=[],[]\n    for i in range(0,nbox):\n        cc.append(val[(1+i*6)])\n        box = val[(2+i*6):(6+i*6)]\n        boxes.append(box)\n    df_train_merge.at[r,'label_op'] = val[0]\n    df_train_merge.at[r,'confidence'] = cc\n    df_train_merge.at[r,'bbox'] = boxes\n    if val[0] =='none':\n        df_train_merge.at[r,'num_box'] = 0\n    else:\n        df_train_merge.at[r,'num_box'] = len(boxes)\n            \n    ","60383de7":"df_train_merge","59df0599":"#check whether images contain mixed confidence values\ndf_train_merge['confidence'].apply(lambda x: len(list(set(x)))).unique()","4c0e42f0":"df_train_merge.shape","e49275b1":"df_train_merge.groupby('class').count()['label'].plot(kind='bar',\n                                                      title='class size');","bc31b2c0":"#existence of boxes in each class\ndf_train_merge.groupby(['class','label_op']) \\\n              .count()['id'] \\\n              .unstack() \\\n              .plot(kind='bar',title='Images that contain any number of boxes in each class');","b3a080c9":"df=df_train_merge.groupby(['class','label_op','num_box']).count().id.reset_index()\ndf","e237be45":"ax=sns.barplot(x=\"class\", y=\"id\", hue=\"num_box\", data=df)\nax.set_ylabel('Count')\nax.set_title('Number of boxes in each class');","4108d99f":"# Get paths to DICOM files\n#It looks like this:\n#set\/study\/series\/image.dcm\n!ls \/kaggle\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91","58e94750":"def read_dcm_paths():\n    #this function is taken from https:\/\/www.kaggle.com\/farhanhaikhan\/object-detection-starter-rescale-image-bbox\n    IMG_FORMAT = \".dcm\"\n    IMG_PATHS = []\n    IMAGE_IDS = []\n    IMAGE_NAMES = []\n    SETS = []\n    SERIES = []\n    STUDIES = []\n\n    for dirname, _, filenames in os.walk('\/kaggle\/input\/siim-covid19-detection'):\n        for filename in filenames:\n            if filename.endswith(IMG_FORMAT):\n                img_path = os.path.join(dirname, filename)\n                Splitted = img_path.split('\/')\n                # print(Splitted)\n                img_name = Splitted[-1]\n                img_id = img_name[:-4]\n                series_name = Splitted[-2]\n                study_name = Splitted[-3]\n                set_name = Splitted[-4]\n                IMG_PATHS.append(img_path)\n                IMAGE_NAMES.append(img_name)\n                IMAGE_IDS.append(img_id)\n                SETS.append(set_name)\n                SERIES.append(series_name)\n                STUDIES.append(study_name)\n    df_dcm = pd.DataFrame.from_dict({\n                                 \"id\":IMAGE_IDS,\n                                 \"Image_Path\":IMG_PATHS,\n                                 \"Image_Name\":IMAGE_NAMES,\n                                 \"id_set\": SETS,\n                                 \"id_series\":SERIES,\n                                 \"StudyInstanceUID\":STUDIES})\n    return df_dcm","d33cc51b":"df_dcm_path = read_dcm_paths()","aeb47b18":"#sanity check\n!ls \/kaggle\/input\/siim-covid19-detection\/train\/9d514ce429a7\/22897cd1daa0\ndf_dcm_path[df_dcm_path['Image_Name']=='0012ff7358bc.dcm']\ndf_dcm_path[df_dcm_path['id']=='0012ff7358bc']\n","030bc365":"df_dcm_path.head()","d5614836":"df_train_merge.head(5)","8336979d":"#fill to 12 characters\ndf_dcm_path['id'] = df_dcm_path['id'].apply(lambda x: (12-len(x))*'0'+x)","0be7c504":"df_train_merge_dcm = pd.merge(df_train_merge,df_dcm_path[['id','Image_Path']],on='id',how='left')","c1761ed6":"df_train_merge_dcm.head()","1353df22":"df_train_merge.shape","0ccdb79a":"len(df_train_merge['id'].unique())","d0f9b89b":"len(df_dcm_path['id'].unique())","6a704764":"df_train_merge_dcm.shape","f6afb293":"# this is precalculated\ndf_dicom_data = pd.read_csv('\/kaggle\/input\/read-dicom-info\/train_df_dicom_data.csv')","e3a27ed4":"df_dicom_data.head(5)","fac492eb":"df_train_merge_dcm.columns","4dcc1f1c":"df_train_merge_dcm.shape","b289a421":"df_train_dcm=pd.merge(df_train_merge_dcm,df_dicom_data[['id', 'Rows', 'Columns', 'PatientID', 'PatientName',\n                                           'PhotometricInterpretation', 'SamplesPerPixel',\n                                           'BitsAllocated', 'BitsStored', 'HighBit', 'PixelRepresentation',\n                                           'ImagerPixelSpacing_X', 'ImagerPixelSpacing_Y', 'ImageType', 'Modality',\n                                           'PatientSex', 'BodyPartExamined']],\n         how='left',on='id')","f0efbabe":"df_train_dcm.shape","dbc9a253":"df_train_dcm.head(5)","787cce5f":"## Save dataframes\ndf_train_dcm.to_csv('train_df_dcm_merged.csv')","24814a39":"In training dataset, confidence value for opacity is always 1.","974c5025":"## Class distribution in training set is not uniform.","9e5104c3":"## Load DICOM fields","d62a6d56":"## Merge dicom paths with image information","06b58b9b":"# Plot number of boxes in each class","5d366ae9":"## Inspect data files","5ca4023e":"# Import DICOM paths","4df64e59":"# Observations on boxes and opacity values\n* Images may have 0 to 8 number of boxes. \n* In training dataset confidence value for opacity is 1.\n* Only class 'negative' does not have any boxes.\n* For all other classes, they may or may not have boxes.\n* Number of boxes in each class is different (see the plot below). For example class 'typical' mostly have 2 boxes."}}