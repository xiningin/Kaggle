{"cell_type":{"b498df89":"code","0210fe44":"code","e502f022":"code","4f42a281":"code","6c3aece5":"code","c147079f":"code","a42ef724":"code","a1595d3e":"code","56fcfcef":"code","8c05a662":"code","ac18f45b":"code","dd325173":"code","31aebcdf":"code","60f1de14":"code","ecc3c5fa":"code","59c04a3e":"code","c7335fc3":"code","90c101a8":"code","3efaecbb":"code","63ad3110":"code","50c7ecbb":"code","7f3a7336":"code","36478cd8":"code","f5352c32":"code","ffd36e30":"code","f846a9c2":"code","6039cf22":"code","bda09551":"code","457a4b73":"code","da7742ff":"code","c043ac34":"code","e007d891":"code","94417efe":"code","80a95968":"code","b99258dd":"code","69bcb973":"code","aeeb566a":"code","f4fbdce8":"code","ea1d2c44":"code","01735ad1":"code","af3c02a4":"code","7db75c80":"code","4898c024":"code","ddf20039":"code","d91649d4":"code","3f27acf0":"code","00d3e19a":"code","2c29a1c6":"code","4aa15acc":"code","f0ea8d93":"code","6e0cc94c":"code","07751b31":"code","1a0b30f7":"code","b77e1f44":"code","7597a1c3":"code","763cd160":"code","b4239880":"code","f424b8bc":"code","315cde86":"code","2084ef4e":"markdown","29534aba":"markdown","cc91aab4":"markdown","8e962b87":"markdown","60f181b8":"markdown","fb33267b":"markdown","ce48528e":"markdown","a1981ca4":"markdown","7d6facef":"markdown","71f960d9":"markdown","f7a16e5b":"markdown","28ca1d5e":"markdown","74a61dd8":"markdown","4635b5b8":"markdown","c968bec1":"markdown","d83d430a":"markdown","3e7f46e4":"markdown","d4e3e719":"markdown","9ba16444":"markdown","a7f12db9":"markdown","7fb23d5a":"markdown","e9f8bebd":"markdown","52ebdf55":"markdown","fd804c61":"markdown","abe381d6":"markdown","b352e5e4":"markdown","89425420":"markdown","0cb7a63b":"markdown","1f5a4ebc":"markdown","66ab7661":"markdown","3c907aaf":"markdown","7bf6dedc":"markdown","0369bc37":"markdown","83f27d73":"markdown","39d2f637":"markdown","cf641867":"markdown","781fd246":"markdown","4f4911a8":"markdown","040e2a04":"markdown","8d70221c":"markdown"},"source":{"b498df89":"# Carga de las librer\u00edas y paquetes necesarios.\n\nimport numpy as np\nimport pandas as pd\nimport random\n# Librer\u00edas para operar con archivos DICOM.\nimport pydicom\n\nimport os\nimport glob\n\nfrom glob import glob\nfrom tqdm import tqdm\n\n# Librer\u00edas para la representaci\u00f3n de figuras e imn\u00e1genes.\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Librer\u00edas para trabnajar con TensorFlow Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nfrom skimage import morphology, io, color, exposure, img_as_float, transform\n\nfrom tensorflow import reduce_sum\nfrom tensorflow.keras.backend import pow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom sklearn.model_selection import train_test_split\n\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom skimage.transform import resize\n\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import constraints\nimport tensorflow.keras.utils as conv_utils\nfrom tensorflow.keras.utils import get_source_inputs\nfrom tensorflow.keras.layers import InputSpec\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import ZeroPadding2D\nfrom tensorflow.keras.losses import binary_crossentropy\nimport tensorflow.keras.callbacks as callbacks\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import multiply\n\nfrom tensorflow.keras import optimizers\nfrom keras.legacy import interfaces\n\nimport shutil\nfrom PIL import Image\n\n\n# Se limita el uso de la RAM de la GPU para evitar un run out of memory al operar con una cantidad muy grande de datos y \n# par\u00e1metros.\ntf.autograph.set_verbosity(1)\ntf.set_random_seed(1)\n\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8)\nsession_conf.gpu_options.per_process_gpu_memory_fraction = 0.5\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\ntf.compat.v1.keras.backend.set_session(sess)\n\n\n# Se establece una semilla aleatoria para TensorFlow a nivel de gr\u00e1fico.\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n    \n    \nplt.style.use('seaborn-white')\nsns.set_style(\"white\")\n    \n%matplotlib inline","0210fe44":"# Input data files are available in the read-only \"..\/input\/\" directory\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e502f022":"# Lectura de los archivos DICOM de la carpeta 'sample-random-images-train' con im\u00e1genes al azar del set de entrenamiento.\nsample_images = sorted(glob('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/sample-random-images-train\/*.dcm'))\n\n# Metadatos de una radiograf\u00eda.\nmetadata_rx_random_train = pydicom.dcmread(sample_images[0])\nprint(metadata_rx_random_train)\n\n# Imagen de una radiograf\u00eda.\nimg_rx_random_train = pydicom.read_file(sample_images[0]).pixel_array\nplt.figure(figsize=(10,10))\nplt.imshow(img_rx_random_train, cmap=plt.cm.bone)\nplt.grid(False)\nplt.show()","4f42a281":"metadata_rx_random_train.PixelData[:270]","6c3aece5":"metadata_rx_random_train.pixel_array, metadata_rx_random_train.pixel_array.shape","c147079f":"def show_dcm_info(dataset):\n    print(\"Filename.........:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)","a42ef724":"def plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","a1595d3e":"import glob\n#\ni = 1\nnum_to_plot = 10\nfor file_path in glob.glob('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/sample-random-images-train\/*.dcm'):\n    dataset = pydicom.dcmread(file_path)\n    show_dcm_info(dataset)\n    plot_pixel_array(dataset)\n    \n    if i >= num_to_plot:\n        break\n    \n    i += 1","56fcfcef":"from glob import glob\n#\n# Input donde se encuentran los datos para llevar a cabo el proyecto:\n# SIIM ACR Pneumothorax Segmentation Data. Chest X-Ray Data with Dense Segmentation\nprint(\"Inputs: SIIM ACR Pneumothorax Segmentation Data. Chest X-Ray Data with Dense Segmentation\")\nprint(os.listdir('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\"))\nprint(\"\")\n\n# Se leen todos los archivos DICOM que contiene SIIM ACR Pneumothorax Segmentation Data, tanto train como test.\ndicom_train = sorted(glob('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/*\/*\/*.dcm\"))\ndicom_test = sorted(glob('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/dicom-images-test\/*\/*\/*.dcm\"))\nprint(\"N\u00famero de muestras DICOM para el set de entrenamiento: \", len(dicom_train))\nprint(\"N\u00famero de muestras DICOM para el set de pruebas: \", len(dicom_test))\n\n# Se resetea al valor por defecto el ancho m\u00e1ximo de caracteres por columna en la estructura de datos: predeterminado=50.\npd.reset_option('max_colwidth')\n\n# Lectura del archivo .csv 'train-rle' compuesto por dos columnas:\n# -ImageId:       ID de la radiograf\u00eda-paciente.\n# -EncodedPixels: -1 si es una radiograf\u00eda sin presencia de neumot\u00f3rax, o con una codificaci\u00f3n que mapea el lugar del neumot\u00f3rax.\nmasks_rle = pd.read_csv('..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/train-rle.csv\", delimiter=\",\")\n# Se corrige un error tipogr\u00e1fico al tener el encabezado de la segunda columna un espacio al comienzo.\nmasks_rle.columns = ['ImageId', 'EncodedPixels']\nmasks_rle.head(10)","8c05a662":"# Se crea un diccionario que recoge las entidades de inter\u00e9s de cada paciente de su DICOM.\ndef dicom_to(data, file_path, masks_rle, enco_pixels=True):\n    # Se resetea al valor por defecto el ancho m\u00e1ximo de caracteres por columna en la estructura de datos: predeterminado=50.\n    pd.reset_option('max_colwidth')\n\n    # Se establecen los elementos de inter\u00e9s extraidos de la inforomaci\u00f3n asociada por DICOM:\n    # -UID: ID un\u00edvoco de la radiograf\u00eda.\n    # -EncodedPixels: -1 si es una radiograf\u00eda sin presencia de neumot\u00f3rax, o con una codificaci\u00f3n que mapea el lugar del neumot\u00f3rax.\n    # -Age: edad del paciente.\n    # -Sex: g\u00e9nero del paciente.\n    # -Modality: tipo de imagen tomada (CR: Computed Radiography).\n    # -BodyPart: parte del cuerpo de la radiograf\u00eda tomada.\n    # -ViewPosition: proyecci\u00f3n de la radiograf\u00eda.\n    # -Diagnosis: indicaci\u00f3n si afecci\u00f3n de neumot\u00f3rax (True) o no (False).\n    # -path: ubicaci\u00f3n computacional de la radiograf\u00eda.\n\n    patient = {}\n    \n    patient[\"UID\"] = data.SOPInstanceUID\n    \n    if enco_pixels:\n        encoded_pixels = masks_rle[masks_rle[\"ImageId\"] == data.SOPInstanceUID][\"EncodedPixels\"].values  \n        patient[\"EncodedPixels\"] = encoded_pixels\n        \n    patient[\"Age\"] = data.PatientAge\n    patient[\"Sex\"] = data.PatientSex\n    patient[\"Modality\"] = data.Modality\n    patient[\"BodyPart\"] = data.BodyPartExamined\n    patient[\"ViewPosition\"] = data.ViewPosition\n    \n    if enco_pixels:\n        pneumothorax = False\n        for enco_pixels in encoded_pixels:\n            if enco_pixels != ' -1':\n                pneumothorax = True\n                \n        patient['Diagnosis'] = pneumothorax\n    \n    if  enco_pixels:\n        patient[\"path\"] = '..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/dicom-images-train\/' + data.StudyInstanceUID + \"\/\" + data.SeriesInstanceUID + \"\/\" + data.SOPInstanceUID + \".dcm\"\n    else:\n        patient[\"path\"] = '..\/input\/siimacr-pneumothorax-segmentation-data\/siim-acr-pneumothorax-segmentation-data\/dicom-images-test\/' + data.StudyInstanceUID + \"\/\" + data.SeriesInstanceUID + \"\/\" + data.SOPInstanceUID + \".dcm\"\n\n    \n    return patient","ac18f45b":"# Metadata de los pacientes del set de entrenamiento (entidades de inter\u00e9s).\n\n# Se declara patients para construir un dataframe con los pacientes del set de entrenamiento.\npatients_train = []\n\n# Listado de todos los archivos DICOM del set de entrenamiento.\n#dicom_train\n\n# Variable dataframe que almacena las entidades de inter\u00e9s de cada paciente del set de entrenamiento.\ndf_patients_train = pd.DataFrame()\n\n# Construcci\u00f3n del dataframe pacientes con los elementos de inter\u00e9s del set de entrenamiento.\nfor file_path in tqdm(dicom_train):\n    data = pydicom.dcmread(file_path)\n    patients_train_metadata = dicom_to(data, file_path, masks_rle)\n    patients_train.append(patients_train_metadata)\ndf_patients_train = pd.DataFrame(patients_train)    \n\nprint(\"N\u00famero de im\u00e1genes DICOM verificadas (con informaci\u00f3n\/relaci\u00f3n) en el set de entrenamiento: \", df_patients_train.shape[0])\n# Radiograf\u00edas\/pacientes con falta de informaci\u00f3n en el set de entrenamiento.\n\ndf_patients_train.head(10)","dd325173":"# Se verifica que hay una m\u00e1scara (en train-rle) para todo paciente listado en el dataset train.\n# 'missing' es una variable que almacena el n\u00famero de radiograf\u00edas\/pacientes que presentan una falta de etiquetado.\nmissing = 0\n\nfor file_path in dicom_train:\n    data = pydicom.dcmread(file_path)\n    pat = {}\n    pat[\"UID\"] = data.SOPInstanceUID\n    try:\n        masks_rle[masks_rle[\"ImageId\"] == pat[\"UID\"]].values[0][1]\n    except:\n        missing = missing + 1\n        \n# Radiograf\u00edas\/pacientes con falta de informaci\u00f3n en el set de entrenamiento.\nprint(\"N\u00famero de im\u00e1genes DICOM del set de entrenamiento sin informaci\u00f3n de m\u00e1scara RLE: \", missing)","31aebcdf":"print(\"N\u00famero de muestras DICOM listadas en el fichero .csv train_rle: \", len(masks_rle))\nprint(\"Diferencia im\u00e1genes DICOM localizadas entre .csv y carpeta: \", len(masks_rle) - len(dicom_train))","60f1de14":"# Metadata de los pacientes del set de prueba (entidades de inter\u00e9s).\n\n# Se declara patients para construir un dataframe con los pacientes del set de prueba.\npatients_test = []\n\n# Listado de todos los archivos DICOM del set de prueba.\n#dicom_test\n\n# Variable dataframe que almacena las entidades de inter\u00e9s de cada paciente del set de prueba.\ndf_patients_test = pd.DataFrame()\n\n# Construcci\u00f3n del dataframe pacientes con los elementos de inter\u00e9s del set de prueba.\nfor file_path in tqdm(dicom_test):\n    data = pydicom.dcmread(file_path)\n    patients_test_metadata = dicom_to(data, file_path, masks_rle, enco_pixels=False)\n    patients_test.append(patients_test_metadata)\ndf_patients_test = pd.DataFrame(patients_test)    \n\nprint(\"N\u00famero de im\u00e1genes DICOM verificadas (con informaci\u00f3n\/relaci\u00f3n) en el set de prueba: \", df_patients_test.shape[0])\n# Radiograf\u00edas\/pacientes con falta de informaci\u00f3n en el set de prueba.\n\ndf_patients_test.head(10)","ecc3c5fa":"# Distribuci\u00f3n por g\u00e9nero de los pacientes del set de entrenamiento.\nwomen_train = df_patients_train[df_patients_train[\"Sex\"] == \"F\"].shape[0]\nmen_train = df_patients_train.shape[0] - women_train\nprint(\"Distribuci\u00f3n por g\u00e9nero (pacientes del set de entrenamiento)\")\nprint(\"Total mujeres: \", women_train)\nprint(\"Total hhombres: \", men_train)\nprint(\"\")\n\n# Distribuci\u00f3n por diagn\u00f3stico de los pacientes del set de entrenamiento.\nhealthy_train = df_patients_train[df_patients_train[\"Diagnosis\"] == False].shape[0]\nill_train = df_patients_train.shape[0] - healthy_train\nprint(\"Distribuci\u00f3n por diagn\u00f3stico (pacientes del set de entrenamiento)\")\nprint(\"Total sin afecci\u00f3n de neumot\u00f3rax: \", healthy_train)\nprint(\"Total con afecci\u00f3n de neumot\u00f3rax: \", ill_train)\nprint(\"\")\n\n# Distribuci\u00f3n por g\u00e9nero y diagn\u00f3stico de los pacientes del set de entrenamiento.\nwomen_healthy_train = df_patients_train[(df_patients_train[\"Sex\"] == \"F\") & (df_patients_train[\"Diagnosis\"] == False)].shape[0]\nwomen_ill_train = women_train - women_healthy_train\nmen_healthy_train = df_patients_train[(df_patients_train[\"Sex\"] == \"M\") & (df_patients_train[\"Diagnosis\"] == False)].shape[0]\nmen_ill_train = men_train - men_healthy_train\nprint(\"Distribuci\u00f3n por g\u00e9nero y diagn\u00f3stico (pacientes del set de entrenamiento)\")\nprint(\"Mujeres sin afecci\u00f3n de neumot\u00f3rax: \", women_healthy_train)\nprint(\"Mujeres con afecci\u00f3n de neumot\u00f3rax: \", women_ill_train)\nprint(\"Hombres sin afecci\u00f3n de neumot\u00f3rax: \", men_healthy_train)\nprint(\"Hombres con afecci\u00f3n de neumot\u00f3rax: \", men_ill_train)\nprint(\"\")\n\n\n# Relaci\u00f3n g\u00e9nero y\/o diagn\u00f3stico.\ntotal_by100 = (df_patients_train.shape[0])\/100\npercentage = [str(round(men_ill_train\/total_by100, 1)) \n              + \"% \\n ill\", \"healthy \\n\" \n              + str(round(men_healthy_train\/total_by100, 1)) \n              + \"%\", \"healthy \\n\" + str(round(women_healthy_train\/total_by100, 1)) \n              + \"%\",str(round(women_ill_train\/total_by100, 1)) \n              + \"% \\n ill\"]\n\n\n# Representaci\u00f3n de las distribuciones g\u00e9nero-diagn\u00f3stico de los pacientes del set de entrenamiento.\nfig, ax = plt.subplots(1, 3, figsize=(17, 6))\nfig.suptitle(\"Distribuci\u00f3n por gen\u00e9ro-diagn\u00f3stico (del set de entrenamiento)\", fontsize=18, y=1)\nmpl.rcParams['font.size'] = 15.0\n\n# Representaci\u00f3n de la distribuci\u00f3n por g\u00e9nero de los pacientes del set de entrenamiento.\nax[0].pie([women_train, men_train], labels=[\"women\", \"men\"], colors=[\"#FFB74D\", \"#42A5F5\"], autopct='%1.1f%%', pctdistance=0.5,\n          startangle=90, explode=(0.01, 0.01), wedgeprops={'linewidth': 1, 'edgecolor': \"black\"}, textprops=dict(color =\"black\"))\nax[0].axis('equal')\n\n# Representaci\u00f3n de la distribuci\u00f3n por diagn\u00f3stico de los pacientes del set de entrenamiento.\nax[1].pie([healthy_train, ill_train], labels=[\"healthy\", \"ill\"], colors=[\"#9CCC65\", \"#E57373\"], autopct='%1.1f%%', pctdistance=0.5, \n          startangle=90, explode=(0.01, 0.01), wedgeprops={'linewidth': 1, 'edgecolor': \"black\"}, textprops=dict(color =\"black\"))\nax[1].axis('equal') \n\n# Representaci\u00f3n de la distribuci\u00f3n por g\u00e9nero y diagn\u00f3stico de los pacientes del set de entrenamiento.\nmyplot1, labels1 = ax[2].pie([men_train, women_train], radius=1.3, labels=[\"men\", \"woman\"], colors=[\"#42A5F5\", \"#FFB74D\"], \n                      startangle=90, wedgeprops={'linewidth': 1, 'edgecolor': \"black\"}, textprops=dict(color =\"black\"))\nplt.setp(myplot1, width=0.4, edgecolor='white')\n\nmyplot2, labels2 = ax[2].pie([men_ill_train, men_healthy_train, women_healthy_train, women_ill_train], radius = 1.3 - 0.4, \n                       labels=percentage, labeldistance=0.61, colors = [\"#E57373\", \"#9CCC65\", \"#9CCC65\", \"#E57373\"], \n                       startangle=90, textprops=dict(color =\"black\"))\nplt.setp(myplot2, width=0.4, edgecolor='white')\nplt.margins(0,0)\n\n\n\nplt.tight_layout()\nplt.show()","59c04a3e":"# Se convierte el campo Age del dataframe patients en valor num\u00e9rico para hacerlo oeprativo.\ndf_patients_train[\"Age\"] = pd.to_numeric(df_patients_train[\"Age\"])\n\n# Se genera una lista ordenada por edades del dataframe patients del set de entrenamiento.\nsorted_ages = np.sort(df_patients_train[\"Age\"].values)\nprint(sorted_ages)\nprint()\nprint(df_patients_train.describe())","c7335fc3":"# Se muestran las im\u00e1genes y entidades de informaci\u00f3n de los valores outliers de edad.\nh=0\nfor h in range(len(df_patients_train)):\n    file_path = df_patients_train[\"path\"][h]\n    dataset = pydicom.dcmread(file_path)\n    if int(dataset.PatientAge) > 100:\n        show_dcm_info(dataset)\n        plot_pixel_array(dataset)","90c101a8":"# Se eliminan del dt patients las dos radiograf\u00edas que son outliers desde el punto de vista de la entidad edad.\ndf_pats_train = []\ndf_pats_train = df_patients_train.drop(df_patients_train[df_patients_train['Age']==413].index)\ndf_pats_train = df_pats_train.drop(df_pats_train[df_pats_train['Age']==148].index)\nprint(\"N\u00famero de muestras del dataframe patients considerando todas las muestras: \", len(df_patients_train))\nprint(\"N\u00famero de muestras del dataframe pats sin considerar los outliers de edad: \", len(df_pats_train))","3efaecbb":"# Se convierte el campo Age del dataframe pats en valor num\u00e9rico para hacerlo oeprativo.\ndf_pats_train[\"Age\"] = pd.to_numeric(df_patients_train[\"Age\"])\n# Se genera una lista ordenada por edades del dataframe pats del set de entrenamiento.\nsrted_ages = np.sort(df_pats_train[\"Age\"].values)\n\n# Representaci\u00f3n por edades de los pacientes del set de entrenamiento.\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(15, 7))\nplt.hist(srted_ages[:], bins=[i for i in range(100)])  # se excluyen los dos valores de edad al ser outlier.\nplt.title(\"Histograma pacientes por edad\", fontsize=15, pad=10)\nplt.xlabel(\"age\", labelpad=10)\nplt.xticks([i*10 for i in range(11)])\nplt.ylabel(\"count\", labelpad=10)\nplt.show()","63ad3110":"# Representaci\u00f3n de neumot\u00f3rax por g\u00e9nero y edad de los pacientes del set de entrenamiento.\nbins = [i for i in range(100)]\nplt.style.use('seaborn-whitegrid')\n\nall_men_train = np.histogram(df_pats_train[df_pats_train[\"Sex\"] == \"M\"][\"Age\"].values, bins=bins)[0]\nall_women_train = np.histogram(df_pats_train[df_pats_train[\"Sex\"] == \"F\"][\"Age\"].values, bins=bins)[0]\n\nill_men_train = np.histogram(df_pats_train[(df_pats_train[\"Sex\"] == \"M\") & \n                                               (df_pats_train[\"Diagnosis\"] == True)][\"Age\"].values, bins=bins)[0]\nill_women_train = np.histogram(df_pats_train[(df_pats_train[\"Sex\"] == \"F\") & \n                                                 (df_pats_train[\"Diagnosis\"] == True)][\"Age\"].values, bins=bins)[0]\n\nfig, axes = plt.subplots(ncols=2, sharey=True, figsize=(18, 14))\n\nfig.suptitle(\"Presencia de neumot\u00f3rax por g\u00e9nero y edad\", fontsize=18, y=0.95)\n\naxes[0].margins(x=0.07, y=0.01)\nm1 = axes[0].barh(bins[:-1], all_men_train, color='#90CAF9')\nm2 = axes[0].barh(bins[:-1], ill_men_train, color='#0D47A1')\naxes[0].set_title('Men', fontsize=17, pad=12)\naxes[0].invert_xaxis()\naxes[0].set(yticks=[i*5 for i in range(20)])\naxes[0].tick_params(axis=\"y\", labelsize=14)\naxes[0].yaxis.tick_right()\naxes[0].xaxis.tick_top()\naxes[0].legend((m1[0], m2[0]), ('healthy', 'with Pneumothorax'), loc=2, prop={'size': 16})\n\nlocs = axes[0].get_xticks()\n\naxes[1].margins(y=0.01)\nw1 = axes[1].barh(bins[:-1], all_women_train, color='#EF9A9A')\nw2 = axes[1].barh(bins[:-1], ill_women_train, color='#B71C1C')\naxes[1].set_title('Women', fontsize=17, pad=12)\naxes[1].xaxis.tick_top()\naxes[1].set_xticks(locs)\naxes[1].legend((w1[0], w2[0]), ('healthy', 'with Pneumothorax'), loc=1, prop={'size': 16})\n\n\nplt.show()","50c7ecbb":"# Revisi\u00f3n de los valores del resto de entidades extra\u00eddas de las im\u00e1genes DICOM del set de entrenamiento.\n\n# Parte del cuerpo de la radiograf\u00eda tomada.\nbodypart_train = df_pats_train[\"BodyPart\"].values\nprint(\"Parte del cuerpo de la radiograf\u00eda tomada:\", list(set(bodypart_train)))\nprint(\"\")\n\n# Tipo de imagen tomada (CR: Computed Radiography).\nmodality_train = df_pats_train[\"Modality\"].values\nprint(\"Tipo de imagen tomada:\", list(set(modality_train)))\nprint(\"\")\n\n# Valores para la proyecciones de las radiograf\u00edas.\nview_train = list(df_pats_train[\"ViewPosition\"].values)\nprint(\"Poyecciones de las radiograf\u00edas: \", list(set(view_train)))\n\npa_train = view_train.count(\"PA\")\nap_train = view_train.count(\"AP\")\nprint(\"Total de proyecciones posteroanterior (PA): \", pa_train)\nprint(\"Total de proyecciones posteroanterior (PA): \", ap_train)\n\n\n# Distribuci\u00f3n de las proyecciones de las radiograf\u00edas de las im\u00e1genes DICOM del set de entrenamiento.\npie_2_views = sns.color_palette()\nplt.style.use('seaborn-whitegrid')\nplt.pie([pa_train, ap_train], labels = [\"PA\", \"AP\"], colors=[pie_2_views[-1], pie_2_views[1]], autopct='%1.1f%%', startangle=90,\n       explode=(0.01, 0.01), wedgeprops={'linewidth': 1, 'edgecolor': \"black\"}, textprops=dict(color =\"black\"))\nplt.title(\"Reparto (%) de las proyecciones\", fontsize=14, color=\"black\")","7f3a7336":"# Funci\u00f3n original 'mask_functions.py' facilitada por el kaggle fuente:\n# SIIM-ACR Pneumothorax Segmentation. Identify Pneumothorax disease in chest x-rays.\n# https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/data\n\ndef mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","36478cd8":"# Se construye en dt con solo los pacientes con neumot\u00f3rax detectado (\"Diagnosis\" == True]).\ndf_pneumo_train = df_pats_train[df_pats_train[\"Diagnosis\"] == True]\n\n# Arrays locales para almacenar la codificaci\u00f3n de p\u00edxeles de la x-ray original y la m\u00e1scara con la localizaci\u00f3n del neumot\u00f3rax.\nimg_pneumo = []\nmask_pneumo = []\n\n# Se seleccionan 10 radiograf\u00edas aleatorias para mostrar.\nmax_len = len(df_pneumo_train)\nr = list(range(max_len))\nrandom.shuffle(r)\n\nfor i in range(10):\n    picked_photo = r[i]\n    # Se convierte el valor rle(EncodedPixels) en una str para hacerlo oeprativo para 'rle2mask'.\n    rle_tolist=list(df_pneumo_train.values[picked_photo][1])\n    rle_tostr=\" \".join(rle_tolist)\n    \n    # Se utiliza la funci\u00f3n rle2mask facilitada para la decodificaci\u00f3n RLE de la m\u00e1scara.\n    # Se llama a la transpuesta de rle2mask ya que se est\u00e1 usando una forma relativa de RLE, es decir, las ubicaciones de los \n    # p\u00edxeles se miden desde el final de la ejecuci\u00f3n anterior. Lo que equibaldr\u00eda manualmente a hacer:\n    # Rotaci\u00f3n de la m\u00e1scara 270\u00ba en sentido horario.\n    #mask = np.rot90(mask, 3)\n    # Se construye el espejo de la m\u00e1scara.\n    #mask = np.flip(mask, axis=1)\n    mask = rle2mask(rle_tostr, 1024, 1024).T\n    mask_pneumo.append(mask)\n    \n    img = pydicom.read_file(df_pneumo_train.values[picked_photo][-1]).pixel_array\n    img_pneumo.append(img)\n\n# Representaci\u00f3n de las 10 radiograf\u00edas aleatorias y sus m\u00e1scaras (ubicaci\u00f3n del neumot\u00f3rax).\nx = len(img_pneumo)\nfor j in range(x):\n    fig = plt.figure(figsize=(25, 25))\n    \n    # CP original.\n    a = fig.add_subplot(1, 3, 1)\n    plt.imshow(img_pneumo[j], cmap=plt.cm.bone)\n    a.set_title(\"CP original\")\n    plt.axis(\"off\")\n\n    # Descodificaci\u00f3n RLE: m\u00e1scara.\n    a = fig.add_subplot(1, 3, 2)\n    imgplot = plt.imshow(mask_pneumo[j], cmap='binary')\n    a.set_title(\"Descodificaci\u00f3n RLE: m\u00e1scara\")\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    #CP + m\u00e1scara: neumot\u00f3rax\n    a = fig.add_subplot(1, 3, 3)\n    plt.imshow(img_pneumo[j], cmap=plt.cm.bone)\n    plt.imshow(mask_pneumo[j], cmap='inferno', alpha=0.3)\n    a.set_title(\"CP + m\u00e1scara: neumot\u00f3rax\")\n    plt.axis(\"off\")\n\n    plt.grid(False)","f5352c32":"# Se construyen los arrays PA y AP para acumular las m\u00e1scaras de sus proyecciones.\nimg_missing_maks = 0\npa_pneumo = np.array([[0 for i in range(1024)] for j in range(1024)])\nap_pneumo = np.array([[0 for i in range(1024)] for j in range(1024)])\n\nfor x in range(len(df_pneumo_train)):\n    try:\n        # Se convierte el valor rle(EncodedPixels) en una str para hacerlo oeprativo para 'rle2mask'.\n        rle_tolist=list(df_pneumo_train.values[x][1])\n        rle_tostr=\" \".join(rle_tolist)\n        \n        # Se utiliza la funci\u00f3n rle2mask (transpuesta [.T]) facilitada para la decodificaci\u00f3n RLE de la m\u00e1scara.\n        mask = rle2mask(rle_tostr, 1024, 1024).T\n\n        if df_pneumo_train.values[x][6] == 'PA':\n            pa_pneumo = pa_pneumo + mask\n        elif df_pneumo_train.values[x][6] == 'AP':\n            ap_pneumo = ap_pneumo + mask\n    except:\n        img_missing_maks = img_missing_maks + 1","ffd36e30":"# Representaci\u00f3n de los mapas de calor para las proyecciones de PA y AP.\nfig = plt.figure(figsize=(20, 15))\nbasic_palette = sns.color_palette()\n\n# Reprsentaci\u00f3n de 'Proyecci\u00f3n PA: neumot\u00f3rax'.\nax1 = plt.subplot2grid((1, 3), (0, 0))\nax1.imshow(pa_pneumo, cmap='inferno_r')\nax1.set_title(\"Proyecci\u00f3n PA: neumot\u00f3rax\", fontsize=18, pad=20)\n# Barra crom\u00e1tica de representaci\u00f3n 'Proyecci\u00f3n PA: neumot\u00f3rax'.\nmax_pa_pneumo = int(np.max(pa_pneumo))\nchrom_bar_pa = plt.get_cmap('inferno_r', max_pa_pneumo)\nnorm = mpl.colors.Normalize()\nsm = plt.cm.ScalarMappable(cmap=chrom_bar_pa, norm=norm)\nsm.set_array([])\ncb_1 = plt.colorbar(sm,ticks=[0, 1], fraction=0.0455, ax=ax1)\ncb_1.ax.set_yticklabels([\"Sin neumotrx\", str(int(max_pa_pneumo))])\ncb_1.ax.yaxis.set_label_position('left')\n\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\n# Reprsentaci\u00f3n de 'Proyecci\u00f3n PA: neumot\u00f3rax'.\nax3 = plt.subplot2grid((1, 3), (0, 2))\nax3.imshow(ap_pneumo, cmap='inferno_r')\nax3.set_title(\"Proyecci\u00f3n AP: neumot\u00f3rax\", fontsize=18, pad=20)\n# Barra crom\u00e1tica.\nmax_ap_pneumo = int(np.max(ap_pneumo))\nchrom_bar_ap = plt.get_cmap('inferno_r', max_ap_pneumo)\nnorm = mpl.colors.Normalize()\nsm = plt.cm.ScalarMappable(cmap=chrom_bar_ap, norm=norm)\nsm.set_array([])\ncb_2 = plt.colorbar(sm,ticks=[0, 1], fraction=0.0455, ax=ax3)\ncb_2.ax.set_yticklabels([\"Sin neumotrx\", str(int(max_ap_pneumo))])\ncb_2.ax.yaxis.set_label_position('left')\n\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\n# Distribuci\u00f3n de las proyeccioines de las radiograf\u00edas de las im\u00e1genes DICOM del set de entrenamiento.\nax2 = plt.subplot2grid((1, 3), (0, 1))\nax2.pie([pa_train, ap_train], labels = [\"PA\", \"AP\"], colors=[pie_2_views[-1], pie_2_views[1]], autopct='%1.1f%%', startangle=90,\n       explode=(0.01, 0.01), wedgeprops={'linewidth': 1, 'edgecolor': \"black\"}, textprops=dict(color =\"black\"))\nax2.set_title(\"Reparto (%) de las proyecciones\", fontsize=14, color=\"black\")","f846a9c2":"# Se establecen los hiperpar\u00e1metros de configuraci\u00f3n.\nimg_size = 128 # reajuste del tama\u00f1o de la imagen.\nh = 128\nw = 128\nbatch_size = 32 # tama\u00f1o del batch para la  ResUNet.\nk_size = 1 # tama\u00f1o del kernel.","6039cf22":"# Generador de datos.\nclass DataGen(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, augmentations=None, \n                 batch_size=batch_size, img_size=128, channels=k_size, shuffle=True):\n        'Inicializaci\u00f3n'\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.augment = augmentations\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'N\u00famero de lotes por \u00e9poca'\n        return int(np.floor(len(self.file_path_list)) \/ self.batch_size)\n    \n    def __getitem__(self, index):\n        'Generaci\u00f3n de un lote de datos'\n        # Generaci\u00f3n de \u00edndices del lote.\n        indexes = self.indexes[index*self.batch_size:min((index+1)*self.batch_size,len(self.file_path_list))]\n        \n        # Generaci\u00f3n de listas de IDs.\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        \n        # Generaci\u00f3n de datos.\n        X, y = self.data_generation(file_path_list_temp)\n        \n        # Devoluci\u00f3n de datos.\n        if self.augment is None:\n            return X,np.array(y)\/255\n        else:            \n            im,mask = [],[]   \n            for x,y in zip(X,y):\n                augmented = self.augment(image=x, mask=y)\n                im.append(augmented['image'])\n                mask.append(augmented['mask'])\n            return np.array(im),np.array(mask)\/255\n            \n    def on_epoch_end(self):\n        'Actualizaci\u00f3n realizada despu\u00e9s de cada \u00e9poca'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def data_generation(self, file_path_list_temp):\n        'Generaci\u00f3n de datos que contengan muestras de tama\u00f1o de lote'\n        # Inicializaci\u00f3n.\n        X = np.empty((len(file_path_list_temp),self.img_size,self.img_size, self.channels))\n        y = np.empty((len(file_path_list_temp),self.img_size,self.img_size, 1))\n        \n        # Generaci\u00f3n de datos.\n        for idx, file_path in enumerate(file_path_list_temp):\n            \n            id = file_path.split('\/')[-1][:-4]\n            rle = self.labels.get(id)\n            \n            # Redimensi\u00f3n de las im\u00e1genes.\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            #########################################################\n            image_resized = np.array(image_resized, dtype=np.float64)\n            #########################################################\n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            \n            # Si no hay m\u00e1scara, se crea una m\u00e1scara vac\u00eda.\n            # Observe que se comienza con 1024p porque se necesita utilizar la funci\u00f3n rle2mask().\n            if rle is None:\n                mask = np.zeros((1024, 1024), dtype=np.float32)\n            else:\n                if len(rle) == 1:\n                    mask = rle2mask(rle[0], 1024, 1024).T\n                else: \n                    mask = np.zeros((1024, 1024), dtype=np.float32)\n                    for r in rle:\n                        mask =  mask + rle2mask(r, 1024, 1024).T\n                        \n            # Se almacenan las m\u00e1scaras (de haber).\n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n            y[y>0] = 255\n            \n        X = np.uint8(X)\n        y = np.uint8(y)\n            \n        return X, y","bda09551":"# from https:\/\/github.com\/sneddy\/pneumothorax-segmentation\n# Se hace uso del Albumentations definido en la soluci\u00f3n ganadora del challange SIIM-ACR Pneumothorax Segmentation pues \n# implementa de manera eficiente una amplia variedad de operaciones de transformaci\u00f3n de las im\u00e1genes que est\u00e1n optimizadas para\n# el rendimiento en segmentaci\u00f3n, aunque se evita la rotaci\u00f3n del eje vertical porque se obtienen peores resultados.\n\nfrom albumentations import (Compose, HorizontalFlip, CLAHE, HueSaturationValue, RandomBrightness, RandomContrast, RandomGamma,\n                            OneOf, ToFloat, ShiftScaleRotate, GridDistortion, ElasticTransform, JpegCompression, Resize,\n                            HueSaturationValue, RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, \n                            GaussNoise,CenterCrop, IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop)\n\nAUGMENTATIONS_TRAIN = Compose([HorizontalFlip(p=0.5), \n                               OneOf([RandomContrast(), RandomGamma(), RandomBrightness(),], p=0.3), \n                               OneOf([ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03), GridDistortion(),\n                                      OpticalDistortion(distort_limit=2, shift_limit=0.5),], p=0.3), \n                               RandomSizedCrop(min_max_height=(64, 128), height=h, width=w,p=0.25), ToFloat(max_value=1)], p=1)\n\nAUGMENTATIONS_TEST = Compose([ToFloat(max_value=1)], p=1)","457a4b73":"# Se listan l\u00e1s m\u00e1scaras de las im\u00e1genes identificadas con neumot\u00f3rax.\nmasks = {}\nfor index, row in df_patients_train[df_patients_train['Diagnosis'] == True].iterrows():\n    masks[row['UID']] = list(row['EncodedPixels'])","da7742ff":"# Se eliminan las radiograf\u00edas\/pacientes con falta de informaci\u00f3n en el set de entrenamiento: \n# radiograf\u00edas\/pacientes sin m\u00e1scara codificada en el train-rle: 37.\n\n# N\u00famero total de muestras del dataset a estudio (entrenamiento).\nn_samp_train = len(dicom_train)\n\ncont = 0\nfor i, file_path in tqdm(enumerate(dicom_train), total=n_samp_train):\n    dataset = pydicom.read_file(file_path)\n    \n    try:\n        # ID de la imagen.\n        img_id = file_path.split('\/')[-1][:-4]\n        # \u00cdndice de la imagen en train-rle (mask_rle).\n        img_id_indx = masks_rle[masks_rle['ImageId'] == img_id].index\n        \n        if len(img_id_indx) == 0:\n            if cont == 0:\n                without_rle_data = df_patients_train[df_patients_train['UID'] == img_id].index\n                df_train = df_patients_train.drop(without_rle_data)\n            else:\n                without_rle_data = df_patients_train[df_patients_train['UID'] == img_id].index\n                df_train = df_train.drop(without_rle_data)\n            cont = cont + 1\n        else:\n            df_train = pd.DataFrame(df_patients_train)\n            \n    except:\n        pass","c043ac34":"# Divisi\u00f3n de los datos de entrenamiento en datos de entrenamiento y datos de validaci\u00f3n (training and validation splits) con \n# muestreo estratificado (stratification).\n\nval_size = 0.2 # Divisi\u00f3n del set de entrenamiento: 20% para el conjunto de validaci\u00f3n (80% para el conjunto de entrenamiento)\n\nX_train, X_val, y_train, y_val = train_test_split(df_train.index, df_train['Diagnosis'].values, test_size=val_size, random_state=42)\nX_train, X_val = df_train.loc[X_train]['path'].values, df_train.loc[X_val]['path'].values","e007d891":"# Generaci\u00f3n de im\u00e1genes del conjunto de entrenamiento (con m\u00e1scaras).\ngen_norm = DataGen(X_train, masks, batch_size=64, shuffle=False)\nx,y = gen_norm.__getitem__(0)\nprint(x.shape, y.shape)\n\nmax_imagenes = 64\ngrid_width = 16\ngrid_height = int(max_imagenes \/ grid_width)\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nfor i,(im, mask) in enumerate(zip(x, y)):\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(im.squeeze(), cmap=plt.cm.bone)\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"inferno\")    \n    ax.axis('off')\n\nplt.suptitle(\"Radiograf\u00edas tor\u00e1x: con neumot\u00f3rax en amarillo.\")","94417efe":"# Generaci\u00f3n de im\u00e1genes del conjunto de entrenamiento (con m\u00e1scaras) despu\u00e9s de haber sido modificadas con 'albumentations'.\ngen_albu = DataGen(X_train, masks, batch_size=64, augmentations=AUGMENTATIONS_TRAIN, shuffle=False)\nx, y = gen_albu.__getitem__(0)\nprint(x.shape, y.shape)\n\nmax_imagenes = 64\ngrid_width = 16\ngrid_height = int(max_imagenes \/ grid_width)\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n\nfor i,(im, mask) in enumerate(zip(x, y)):\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(im[:,:,0], cmap=plt.cm.bone)\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"inferno\")    \n    ax.axis('off')\n    \nplt.suptitle(\"Radiograf\u00edas 'albumentations': con neumot\u00f3rax en amarillo.\")","80a95968":"# from https:\/\/www.kaggle.com\/iezepov\/fast-iou-scoring-metric-in-pytorch-and-numpy\n# Pero teniendo en cuenta que:\n#  -Se consideran los casos donde la m\u00e1scara est\u00e1 vac\u00eda.\n#  -No se necesita smoothing constant.\n#  -iou es calculado imagen a imagen.\n#  -https:\/\/www.kaggle.com\/cpmpml\/fast-iou-metric-in-numpy-and-tensorflow\n\ndef get_iou_vector(A, B):\n    # Numpy version    \n    batch_size = A.shape[0]\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n        \n        # deal with empty mask first\n        if true == 0:\n            metric += (pred == 0)\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection \/ union\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) \/ 10\n        \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric \/= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.compat.v1.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)","b99258dd":"def dice_coef(y_true, y_pred):\n    smooth = 1.\n    y_true_f = Flatten()(y_true)\n    y_pred_f = Flatten()(y_pred)\n    intersection = reduce_sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) \/ (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coef(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","69bcb973":"def bn_act(x, act=True):\n    'batch normalization layer with an optinal activation layer'\n    x = tf.keras.layers.BatchNormalization()(x)\n    if act == True:\n        x = tf.keras.layers.Activation('relu')(x)\n    return x\n\ndef conv_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n    'convolutional layer which always uses the batch normalization layer'\n    conv = bn_act(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv\n\ndef stem(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n    conv = Conv2D(filters, kernel_size=kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    \n    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = Add()([conv, shortcut])\n    return output\n\ndef residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n    \n    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = Add()([shortcut, res])\n    return output\n\ndef upsample_concat_block(x, xskip):\n    u = UpSampling2D((2, 2))(x)\n    c = Concatenate()([u, xskip])\n    return c","aeeb566a":"def ResUNet(img_size):\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((img_size, img_size, k_size))\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e5, f[4], strides=1)\n    b1 = conv_block(b0, f[4], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e4)\n    d1 = residual_block(u1, f[4])\n    \n    u2 = upsample_concat_block(d1, e3)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e2)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e1)\n    d4 = residual_block(u4, f[1])\n    \n    outputs = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n    model = tf.keras.models.Model(inputs, outputs)\n    return model","f4fbdce8":"# Definici\u00f3n de un diccionario donde se almacena el conjunto de modelos definidos con diferentes m\u00e9tricas de evaluaci\u00f3n una vez\n# entrenados.\nmodel_sets = {}","ea1d2c44":"# Para kaggle: creaci\u00f3n del path para guardar los outputs modelo y checkpoint.\nos.mkdir(\"\/kaggle\/working\/models\")\n\ncheckpoint_filepath = '.\/models'","01735ad1":"# from https:\/\/www.kaggle.com\/meaninglesslives\/unet-with-efficientnet-encoder-in-keras\n# SnapshotModelCheckpoint(Callback): guarda los pesos de las instant\u00e1neas del modelo.\n# Guarda los pesos del modelo en determinadas \u00e9pocas (que pueden considerarse la instant\u00e1nea del modelo en esa \u00e9poca).\n# Debe usarse con el programa de velocidad de aprendizaje 'cosine anneal' para ahorrar peso justo antes de que la velocidad de\n# aprendizaje aumente dr\u00e1sticamente.\n\nclass SnapshotCallbackBuilder:\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n        checkpoint_filepath = '.\/keras.model'\n        model_checkpoint_callback = [tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n                                                                        monitor='val_my_iou_metric', mode = 'max', \n                                                                        save_best_only=True, verbose=1), \n                                     callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)]\n        return model_checkpoint_callback\n\n    def _cosine_anneal_schedule(self, t):\n        cos_inner = np.pi * (t % (self.T \/\/ self.M))  # t - 1 is used when t has 1-based indexing.\n        cos_inner \/= self.T \/\/ self.M\n        cos_out = np.cos(cos_inner) + 1\n        return float(self.alpha_zero \/ 2 * cos_out)","af3c02a4":"tf.keras.backend.clear_session()\nmodel_iou = ResUNet(img_size)\n\n# Compilaci\u00f3n del modelo.\nadam = tf.keras.optimizers.Adam(lr = 0.0001, epsilon = 0.001)\nmodel_iou.compile(optimizer=adam, loss=bce_dice_loss, metrics=[my_iou_metric])\n\n# Arquitectura del modelo.\nmodel_iou.summary()","7db75c80":"parameters = {'img_size': img_size,\n              'batch_size': batch_size,\n              'channels': k_size,\n              'shuffle': True}\nepochs = 150\n\n# SnapshotModelCheckpoint(Callback): guarda los pesos de las instant\u00e1neas del modelo.\nsnapshot = SnapshotCallbackBuilder(nb_epochs=epochs, nb_snapshots=1, init_lr=0.001)\n\n# Generaci\u00f3n de datos para los datos de entrenamiento y los de validaci\u00f3n.\ntraining_generator_model_iou = DataGen(X_train, masks, augmentations=AUGMENTATIONS_TRAIN, **parameters)\nvalidation_generator_model_iou = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST,  **parameters)\n\n# N\u00fameros de pasos de entrenamiento.\ntrain_steps = len(X_train)\/\/batch_size\n# N\u00fameros de pasos de validaci\u00f3n.\nval_steps = len(X_val)\/\/batch_size\n\n# Entrenamiento del modelo con m\u00e9trica: IoU.\nhistory_model_iou = model_iou.fit_generator(generator=training_generator_model_iou, validation_data=validation_generator_model_iou,\n                                            steps_per_epoch=train_steps, validation_steps=val_steps, use_multiprocessing=False, \n                                            epochs=epochs, verbose=1, callbacks=snapshot.get_callbacks())\n\n# Se almacena 'history' del modelo entrenado 'model_iou'.\nmodel_sets[0] = history_model_iou","4898c024":"# Visualizaci\u00f3n de 'accuracy' y de 'loss' en el conjunto de training y validation en funci\u00f3n de las diferentes \u00e9pocas ('epochs')\n# del entrenamiento para el modelo con una m\u00e9trica de evaluaci\u00f3n IoU.\n\n# Se listan los datos que contiene 'history_model_iou'.\nprint(history_model_iou.history.keys())\nplt.figure(figsize=(25, 5))\n\n# Representaci\u00f3n del 'accuracy' del modelo.\nplt.subplot(1,2,1)\nplt.plot(history_model_iou.history['my_iou_metric'][1:])\nplt.plot(history_model_iou.history['val_my_iou_metric'][1:])\nplt.title('Modelo con IoU: accuracy', fontsize = 22)\nplt.ylabel('accuracy', fontsize = \"x-large\")\nplt.xlabel('epoch', fontsize = \"x-large\")\nplt.legend(['train', 'Validation'], loc = \"best\", fontsize = \"large\", shadow = 1, facecolor = \"inherit\")\n\n# Representaci\u00f3n de 'loss' del modelo.\nplt.subplot(1,2,2)\nplt.plot(history_model_iou.history['loss'][1:])\nplt.plot(history_model_iou.history['val_loss'][1:])\nplt.title('Modelo con IoU: loss', fontsize = 22)\nplt.ylabel('loss', fontsize = \"x-large\")\nplt.xlabel('epoch', fontsize = \"x-large\")\nplt.legend(['train', 'Validation'], loc = \"best\", fontsize = \"large\", shadow = 1, facecolor = \"inherit\")\n\n#gc.collect()\nplt.show()","ddf20039":"tf.keras.backend.clear_session()\nmodel_cl = ResUNet(img_size)\n\n# Compilaci\u00f3n del modelo.\nadam = tf.keras.optimizers.Adam(lr = 0.0001, epsilon = 0.001)\nmodel_cl.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dice_coef])\n\n# Arquitectura del modelo.\nmodel_cl.summary()","d91649d4":"parameters = {'img_size': img_size,\n              'batch_size': batch_size,\n              'channels': k_size,\n              'shuffle': True}\nepochs = 150\n\n# Generaci\u00f3n de datos para los datos de entrenamiento y los de validaci\u00f3n.\ntraining_generator_model_cl = DataGen(X_train, masks, augmentations=AUGMENTATIONS_TRAIN, **parameters)\nvalidation_generator_model_cl = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST,  **parameters)\n\n# N\u00fameros de pasos de entrenamiento.\ntrain_steps = len(X_train)\/\/batch_size\n# N\u00fameros de pasos de validaci\u00f3n.\nval_steps = len(X_val)\/\/batch_size\n\n# Entrenamiento del modelo con m\u00e9tr\u00edca: ComboLoss.\nhistory_model_cl = model_cl.fit_generator(generator=training_generator_model_cl, validation_data=validation_generator_model_cl,\n                                      steps_per_epoch=train_steps, validation_steps=val_steps, use_multiprocessing=False, \n                                      epochs=epochs, verbose=1)\n\n# Se almacena 'history' del modelo entrenado 'model_cl'.\nmodel_sets[1] = history_model_cl","3f27acf0":"# Visualizaci\u00f3n de 'accuracy' y de 'loss' en el conjunto de training y validation en funci\u00f3n de las diferentes \u00e9pocas ('epochs')\n# del entrenamiento para el modelo con una m\u00e9trica de evaluaci\u00f3n ComboLoss.\n\n# Se listan los datos que contiene 'history_model_cl'.\nprint(history_model_cl.history.keys())\nplt.figure(figsize=(25, 5))\n\n# Representaci\u00f3n del 'accuracy' del modelo.\nplt.subplot(1,2,1)\nplt.plot(history_model_cl.history['dice_coef'][1:])\nplt.plot(history_model_cl.history['val_dice_coef'][1:])\nplt.title('Modelo con ComboLoss: accuracy', fontsize = 22)\nplt.ylabel('accuracy', fontsize = \"x-large\")\nplt.xlabel('epoch', fontsize = \"x-large\")\nplt.legend(['train', 'Validation'], loc = \"best\", fontsize = \"large\", shadow = 1, facecolor = \"inherit\")\n\n# Representaci\u00f3n de 'loss' del modelo.\nplt.subplot(1,2,2)\nplt.plot(history_model_cl.history['loss'][1:])\nplt.plot(history_model_cl.history['val_loss'][1:])\nplt.title('Modelo con ComboLoss: loss', fontsize = 22)\nplt.ylabel('loss', fontsize = \"x-large\")plt.xlabel('epoch', fontsize = \"x-large\")\nplt.legend(['train', 'Validation'], loc = \"best\", fontsize = \"large\", shadow = 1, facecolor = \"inherit\")\n\n#gc.collect()\nplt.show()","00d3e19a":"# Se visualizan dos gr\u00e1ficas para el conjunto de validaci\u00f3n: una con la evoluci\u00f3n de la precisi\u00f3n para los modelos ResUNet con \n# sus diferentes m\u00e9tricas de evaluaci\u00f3n: IoU y ComboLoss; y otra con la funci\u00f3n de coste para los mismos conjuntos.\n\n# N\u00famero de \u00e9pocas establecidas en el entrenamiento de los modelos ResUNet.\nN = len(model_sets[0].history[\"my_iou_metric\"])\n\n# Bucle 'for' para representar el resultado del conjunto de validaci\u00f3n de los modelos ResUNet con sus diferentes m\u00e9tricas de \n# evaluaci\u00f3n para los datos de la evoluci\u00f3n de la precisi\u00f3n y de la evoluci\u00f3n de la funci\u00f3n de coste.\n# Modelos: 'ResUNet-IoU', 'ResUNet-ComboLoss'.\nfor t in model_sets:\n    \n    # Evoluci\u00f3n de la precisi\u00f3n para los conjuntos de validaci\u00f3n.\n    acc_fig = plt.figure(1, figsize = (25,5))\n    plot_acc = acc_fig.add_subplot(1,2,1)\n\n    if t==0:\n        plot_acc.plot(np.arange(0, N), model_sets[t].history[\"val_my_iou_metric\"], figure = acc_fig)\n    elif t==1:\n        plot_acc.plot(np.arange(0, N), model_sets[t].history[\"val_dice_coef\"], figure = acc_fig)\n    \n    plt.title(\"Evolution Validation-Accuracy\", fontsize = 22)\n    plt.ylabel(\"accuracy\", fontsize = \"x-large\")\n    plt.xlabel(\"epoch\", fontsize = \"x-large\")\n    plt.legend(['ResUNet-IoU', 'ResUNet-ComboLoss'], loc = \"best\", fontsize = \"medium\", shadow = 1, facecolor = \"inherit\")\n    \n    acc_fig.figure\n    \n    # Evoluci\u00f3n de la funci\u00f3n de coste para los conjuntos de validaci\u00f3n.\n    loss_fig = plt.figure(2, figsize = (25,5))\n    plot_loss = loss_fig.add_subplot(1,2,2)\n    \n    plot_loss.plot(np.arange(0, N), model_sets[t].history[\"val_loss\"], figure = loss_fig)\n    \n    plt.title(\"Evolution Validation-Loss\")\n    plt.ylabel(\"loss\", fontsize = \"x-large\")\n    plt.xlabel(\"epoch\", fontsize = \"x-large\")\n    plt.legend(['ResUNet-ComboLoss', 'ResUNet-IoU'], loc = \"best\", fontsize = \"medium\", shadow = 1, facecolor = \"inherit\")\n    \n    loss_fig.figure","2c29a1c6":"def predict_val_gentor(model, val_gentor, img_size): \n    predict_val = model.predict_generator(val_gentor).reshape(-1, img_size, img_size)\n    return predict_val","4aa15acc":"val_gentor = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST, img_size=img_size,shuffle=False)\n\n# Se predice tambi\u00e9n el reflejado evitando as\u00ed falsos positivos.\nAUGMENTATIONS_TEST_FLIPPED = Compose([HorizontalFlip(p=1), ToFloat(max_value=1)], p=1)\nval_gentor_flipped = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST_FLIPPED, img_size=img_size, shuffle=False)\n\nval_predi_original = predict_val_gentor(model_iou, val_gentor, img_size)\nval_predi_flipped = predict_val_gentor(model_iou, val_gentor_flipped, img_size)\nval_predi_flipped = np.array([np.fliplr(x) for x in val_predi_flipped])\nval_predictions = 0.5*val_predi_original + 0.5*val_predi_flipped","f0ea8d93":"threshold = 0.5\nnum_img = 48\ngrid_width = 6\ngrid_height = int(num_img \/ grid_width)\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*4, grid_height*4))\nfig.subplots_adjust(bottom = 0.05)\n\nval_gentor = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST, img_size=img_size, batch_size=48, shuffle=False)\nx, y = val_gentor.__getitem__(0)\n\nfor i,(im, mask) in enumerate(zip(x, y)):\n    predictns = val_predictions[i]\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(im[...,0], cmap=plt.cm.bone)\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"cividis\")    \n    ax.imshow(np.array(np.round(predictns > threshold), dtype=np.float32), alpha=0.5, cmap=\"Reds\")\n\nplt.suptitle(\"Neumot\u00f3rax (amarillo) \/ Predicciones (rojo)\", fontsize=24)\nplt.show()","6e0cc94c":"def predict_val_gentor(model, val_gentor, img_size): \n    predict_val = model.predict_generator(val_gentor).reshape(-1, img_size, img_size)\n    return predict_val","07751b31":"val_gentor = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST, img_size=img_size,shuffle=False)\n\n# Se predice tambi\u00e9n el reflejado evitando as\u00ed falsos positivos.\nAUGMENTATIONS_TEST_FLIPPED = Compose([HorizontalFlip(p=1), ToFloat(max_value=1)], p=1)\nval_gentor_flipped = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST_FLIPPED, img_size=img_size, shuffle=False)\n\nval_predi_original = predict_val_gentor(model_cl, val_gentor, img_size)\nval_predi_flipped = predict_val_gentor(model_cl, val_gentor_flipped, img_size)\nval_predi_flipped = np.array([np.fliplr(x) for x in val_predi_flipped])\nval_predictions = 0.5*val_predi_original + 0.5*val_predi_flipped","1a0b30f7":"threshold = 0.5\nnum_img = 48\ngrid_width = 6\ngrid_height = int(num_img \/ grid_width)\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*4, grid_height*4))\nfig.subplots_adjust(bottom = 0.05)\n\nval_gentor = DataGen(X_val, masks, augmentations=AUGMENTATIONS_TEST, img_size=img_size, batch_size=48, shuffle=False)\nx, y = val_gentor.__getitem__(0)\n\nfor i,(im, mask) in enumerate(zip(x, y)):\n    predictns = val_predictions[i]\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(im[...,0], cmap=plt.cm.bone)\n    ax.imshow(mask.squeeze(), alpha=0.5, cmap=\"cividis\")    \n    ax.imshow(np.array(np.round(predictns > threshold), dtype=np.float32), alpha=0.5, cmap=\"Reds\")\n\nplt.suptitle(\"Neumot\u00f3rax (amarillo) \/ Predicciones (rojo)\", fontsize=24)\nplt.show()","b77e1f44":"# Predici\u00f3n sobre el conjunto de pruebas para el modelo: ResUNet, m\u00e9trica: IoU.\nglobal graph\ngraph = tf.get_default_graph()\n\ntest_path = list(df_patients_test[\"path\"].values)\nx_test = [cv2.resize(np.array(pydicom.read_file(test_path[i]).pixel_array), (img_size, img_size)) for i in range(len(test_path))]\nx_test = np.array(x_test)\nx_test = np.array([np.repeat(im[...,None],1,2) for im in x_test])\nprint(x_test.shape)\n\nwith graph.as_default():\n    preds_test_orig = model_iou.predict(x_test, batch_size=batch_size)\n\n# Se predice tambi\u00e9n el reflejado evitando as\u00ed falsos positivos.\nx_test = np.array([np.fliplr(x) for x in x_test])\nwith graph.as_default():\n    preds_test_flipped = model_iou.predict(x_test, batch_size=batch_size)\npreds_test_flipped = np.array([np.fliplr(x) for x in preds_test_flipped])\n\npreds_test = 0.5*preds_test_orig + 0.5*preds_test_flipped","7597a1c3":"# Se visualizan algunas de las predicciones realizadas a partir del modelo: ResUNet, m\u00e9trica: IoU.\nthreshold = 0.5\nnum_img = 36\ngrid_width = 6\ngrid_height = int(num_img \/ grid_width)\n\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width*4, grid_height*4))\nfig.subplots_adjust(bottom = 0.05)\n\nfor i, idx in enumerate(test_path[:num_img]):\n    img = x_test[i]\n    pred = preds_test[i].squeeze()\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(img[...,0], cmap=plt.cm.bone)\n    ax.imshow(np.array(np.round(pred > threshold), dtype=np.float32), alpha=0.5, cmap=\"inferno\")\n\nplt.suptitle(\"Predicci\u00f3n de m\u00e1scaras (neumot\u00f3rax)\", fontsize=24)\nplt.show()","763cd160":"# Se construye la codificaci\u00f3n de las m\u00e1scaras predichas a RLE (habiendo redimensionado previamente las im\u00e1genes al tama\u00f1o \n# original: 1024x1024) del conjunto de datos de test.\n\n#import pdb\n\nthreshold = 0.5\nenco_rle = []\n\nfor g in tqdm(preds_test):\n    g = g.squeeze()\n    im = cv2.resize(g, (1024, 1024))\n    im = im > threshold\n\n    if im.sum() < 1024*2:\n        im[:] = 0\n    im = (im.T*255).astype(np.uint8)  \n    enco_rle.append(mask2rle(im, 1024, 1024))","b4239880":"img_id = [o.split('\/')[-1][:-4] for o in test_path]\ndf_pred_res = pd.DataFrame({'ImageId': img_id, 'EncodedPixels': enco_rle})\ndf_pred_res.loc[df_pred_res.EncodedPixels=='', 'EncodedPixels'] = '-1'\ndf_pred_res.head(10)","f424b8bc":"df_pred_res.tail(10)","315cde86":"df_pred_res.to_csv('predicciones_test.csv', index=False)","2084ef4e":"<div style=\"width: 100%; clear: both;\">\n<div style=\"float: left; width: 50%;\">\n<img src=\"http:\/\/www.uoc.edu\/portal\/_resources\/common\/imatges\/marca_UOC\/UOC_Masterbrand.jpg\", align=\"left\">\n<\/div>\n<\/div>\n<div style=\"float: right; width: 50%;\">\n<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.880 \u00b7 Trabajo final de m\u00e1ster<\/p>\n<p style=\"margin: 0; text-align:right;\">M\u00e1ster universitario en Ciencia de datos (Data science)<\/p>\n<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Machine Learning, im\u00e1genes y medicina (\u00c1rea Medicina [3])<\/p>\n<\/div>\n<\/div>\n<div style=\"width: 100%; clear: both;\">\n<div style=\"width:100%;\">&nbsp;<\/div>\n\n\n# TFM: Diagn\u00f3stico e identificaci\u00f3n de la enfermedad de neumot\u00f3rax\n\n + Autor: __Miguel \u00c1ngel Bermejo \u00c1gueda__\n + Tutor: __Jordi de la Torre Gallart__\n + Profesor: __Ferr\u00e1n Prados Carrasco__\n\n    \nModelo que da soluci\u00f3n al problema planteado para el proyecto final de m\u00e1ster: *Diagn\u00f3stico e identificaci\u00f3n de la enfermedad de neumot\u00f3rax*.\nSe recomienda acompa\u00f1ar la lectura del c\u00f3digo con la memoria del trabajo para una mejor comprensi\u00f3n.\n","29534aba":"<a class=\"anchor\" id=\"section2a\"><\/a> \n## **2.1 Recogida de datos por defecto (solo cuando se trabaja en Kaggle)**","cc91aab4":"#### Entrenamiento del modelo: ResUNet [con m\u00e9trica de evaluaci\u00f3n ComboLoss]","8e962b87":"### Albumentations","60f181b8":"<a class=\"anchor\" id=\"section2e\"><\/a>\n## **2.5 Codificaci\u00f3n de longitud de ejecuci\u00f3n (RLE, Run-Length-Encoding)**","fb33267b":"### Predicciones con ResUNet, m\u00e9trica: IoU (con mejor m\u00e9trica)","ce48528e":"<a class=\"anchor\" id=\"section2f\"><\/a>\n## **2.7 Creaci\u00f3n del modelo y m\u00e9tricas de evaluaci\u00f3n**","a1981ca4":"#### Entrenamiento del modelo: ResUNet [con m\u00e9trica de evaluaci\u00f3n IoU]","7d6facef":"### Data Generator","71f960d9":"<a class=\"anchor\" id=\"section2d\"><\/a>\n## **2.4 An\u00e1lisis exploratorio de datos (Exploratory Data Analysis, EDA)**","f7a16e5b":"### ResUNet, m\u00e9trica: IoU","28ca1d5e":"### Codificaci\u00f3n RLE de las m\u00e1scaras predichas para el conjunto de test","74a61dd8":"#### Predeciones sobre el conjunto de validaci\u00f3n","4635b5b8":"#### Visualizaci\u00f3n del modelo: ResUNet [con m\u00e9trica de evaluaci\u00f3n IoU]","c968bec1":"### M\u00e9tricas de evaluaci\u00f3n","d83d430a":"### Verificaci\u00f3n del modelo ResUNet, m\u00e9trica: IoU","3e7f46e4":"<a class=\"anchor\" id=\"section2f\"><\/a>\n## **2.8 Resultados y conclusiones**","d4e3e719":"#### Declaraci\u00f3n del modelo: ResUNet [con m\u00e9trica de evaluaci\u00f3n IoU]","9ba16444":"#### Visualizaci\u00f3n de las predicciones sobre el conjunto de validaci\u00f3n","a7f12db9":"<a class=\"anchor\" id=\"section2c\"><\/a>\n## **2.3 An\u00e1lisis de metadatos**","7fb23d5a":"### Hiperpar\u00e1metros","e9f8bebd":"#### Programador de tasa de aprendizaje: 'cosine anneal' como lr.","52ebdf55":"#### Visualizaciones sobre el conjunto de test","fd804c61":"#### IoU","abe381d6":"#### Arquitectura del modelo: ResUNet","b352e5e4":"#### Visualizaci\u00f3n para el conjunto de validaci\u00f3n: ResUNet-ComboLoss & ResUNet-IoU","89425420":"#### Declaraci\u00f3n del modelo: ResUNet [con m\u00e9trica de evaluaci\u00f3n ComboLoss]","0cb7a63b":"#### Split de datos: entrenamiento (80%) \/ validaci\u00f3n (20%)","1f5a4ebc":"#### Predeciones sobre el conjunto de validaci\u00f3n","66ab7661":"### ResUNet, m\u00e9trica: ComboLoss","3c907aaf":"<a class=\"anchor\" id=\"section2f\"><\/a>\n## **2.6 Ubicaci\u00f3n de neumot\u00f3rax**","7bf6dedc":"### Verificaci\u00f3n del modelo ResUNet, m\u00e9trica: ComboLoss","0369bc37":"#### Visualizaci\u00f3n de las predicciones sobre el conjunto de validaci\u00f3n","83f27d73":"<a class=\"anchor\"><\/a> \n## **_Librer\u00edas_**","39d2f637":"#### Predeciones sobre el conjunto de test","cf641867":"#### Plot: im\u00e1genes normales \/ im\u00e1genes modificadas (albumentations)","781fd246":"from: https:\/\/github.com\/nikhilroxtomar\/Deep-Residual-Unet\/blob\/master\/Deep%20Residual%20UNet.ipynb\n\nBloque de construcci\u00f3n b\u00e1sico\n\n + ResUNet utiliza unidades residuales como bloque de construcci\u00f3n b\u00e1sico en lugar de un bloque convolucional simple.\n\nLas unidades residuales constan de:\n + Dos bloques convolucionales de 3x3.\n + Un mapeo de identidad.\n + El mapeo de identidad conecta la entrada y la salida de la unidad residual.\n\nArquitectura completa\n\n + El ResUNet consta de tres partes: Codificaci\u00f3n-Puente-Descodificaci\u00f3n\n + Se aplica un paso de 2 al primer bloque de convoluci\u00f3n para reducir el mapa de caracter\u00edsticas a la mitad.\n + Antes de cada unidad de decodificaci\u00f3n, hay un muestreo ascendente de mapas de caracter\u00edsticas del nivel inferior y una concatenaci\u00f3n con los mapas de caracter\u00edsticas de la ruta de codificaci\u00f3n correspondiente.\n + Se aplica una convoluci\u00f3n 1x1 con activaci\u00f3n sigmoidea para obtener un mapa de segmentaci\u00f3n deseado.","4f4911a8":"* [Librer\u00edas](#section) \n\n* [2. Dise\u00f1o e implementaci\u00f3n del trabajo](#section2)  \n    * [2.1 Recogida de datos](#section2a)  \n    * [2.2 DICOM, Digital Imaging and COmmunications in Medicine](#section2b)\n    * [2.3 An\u00e1lisis de metadatos](#section2c)\n    * [2.4 An\u00e1lisis exploratorio de datos (Exploratory Data Analysis, EDA)](#section2d)\n    * [2.5 Codificaci\u00f3n de longitud de ejecuci\u00f3n (RLE, Run-Length-Encoding)](#section2e)\n    * [2.6 Ubicaci\u00f3n de neumot\u00f3rax.](#section2f)\n    * [2.6 Creaci\u00f3n del modelo y m\u00e9tricas de evaluaci\u00f3n.](#section2g)\n    * [2.8 Resultados y conclusiones.](#section2h)","040e2a04":"#### ComboLoss = Dice Loss + Binary Cross-Entropy","8d70221c":"### Creaci\u00f3n del fichero con la codificaci\u00f3n RLE de las m\u00e1scaras predichas para el conjunto de test"}}