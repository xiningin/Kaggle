{"cell_type":{"20713cf3":"code","eef76919":"code","290e4426":"code","ef1ba148":"code","507e069d":"code","85d71e2a":"code","3b757959":"code","dac55532":"code","ab4ff35c":"code","47c79bbd":"code","6e9d9605":"code","512d8eb7":"code","f5996e8f":"code","92814501":"code","983fde01":"code","219fe9fb":"code","b1059d81":"code","ed3b24ef":"code","12ecfc2e":"code","d10c8ca2":"code","ef868fd8":"code","90489f8e":"code","8a3b9754":"code","a126b9fc":"code","108de81d":"code","c224983e":"code","a983a358":"code","0f50de1b":"code","b90ce1d0":"code","5fcefe72":"code","78183c9a":"code","cf7d017e":"code","58dd800d":"code","6480e8ac":"code","0f54424f":"code","495da354":"code","8d7caa6d":"code","24b96077":"code","5e2771bd":"code","1a7868d6":"code","60d3ef1e":"code","9871d363":"code","3793e19d":"code","c32a3daa":"code","90273885":"code","0cba10fa":"code","5cdbdb33":"code","60325532":"code","4dcc023d":"code","65d6a1e0":"code","8fb1fc24":"code","f9075d46":"code","f2bb53d0":"code","926e307a":"code","50e302f8":"code","39b664c7":"code","939da298":"code","e7f2e78c":"code","a4375345":"code","fb0b06b2":"code","c82419d9":"code","8da2ced4":"code","d8b35848":"code","c7741c76":"code","9f3ac2b2":"markdown","478a1c68":"markdown","bf240757":"markdown","58456677":"markdown","1b1a38bf":"markdown","ab44192c":"markdown","636a740b":"markdown","f0bc28db":"markdown","cb3f2300":"markdown","20d7fab2":"markdown","8faaa0da":"markdown","71004451":"markdown","bcb309f6":"markdown","f1c13ccc":"markdown","5096aa30":"markdown","6e463cc2":"markdown","5fbf4e19":"markdown","f30e8caf":"markdown","a95817e0":"markdown","0a58d115":"markdown"},"source":{"20713cf3":"import re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\nimport xgboost as xgb\nregex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)","eef76919":"df=pd.read_csv('..\/input\/predictive-maintenance\/ai4i2020.csv')","290e4426":"df","ef1ba148":"\ndf.head()\n","507e069d":"#getting the names of columns\ndf.columns","85d71e2a":"df.shape","3b757959":"df.skew()","dac55532":" df.corr()","ab4ff35c":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        ","47c79bbd":" def Head(value=5):\n            print('\\033[1m'+'displaying the', value, 'rows'+'\\033[0m')\n            a=df.head(value)\n            return a\n            print(\"--------------------------------------------------------------------------\")\nHead()","6e9d9605":" def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()","512d8eb7":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","f5996e8f":"def Size():\n    print('\\033[1m'+\"The size of dataset is :\"+'\\033[0m')\n    siz=df.size\n    print(siz,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nSize()","92814501":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()\n","983fde01":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","219fe9fb":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","b1059d81":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","ed3b24ef":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","12ecfc2e":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     \n","d10c8ca2":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","ef868fd8":"df['Machine failure'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()","90489f8e":"df['TWF'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()","8a3b9754":"df['HDF'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()","a126b9fc":"df['PWF'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()","108de81d":"df['OSF'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()\n","c224983e":"\ndf['RNF'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.show()\n","a983a358":"df1=df[df['Machine failure']==1][['TWF', 'HDF', 'PWF', 'OSF', 'RNF']].apply(pd.value_counts)\ndf1","0f50de1b":"df2=df.drop(['TWF', 'HDF', 'PWF', 'OSF', 'RNF'],axis=1)","b90ce1d0":"df2","5fcefe72":"sns.pairplot(df2,hue='Machine failure')","78183c9a":"df\n","cf7d017e":"df.tail()","58dd800d":"df2\n","6480e8ac":"df3=df2[df2['Machine failure']==1][['UDI']].apply(pd.value_counts)\ndf3","0f54424f":"len(df3)","495da354":"percentage=(len(df3)\/len(df))*100\npercentage","8d7caa6d":"df2.columns","24b96077":"df4=df2[df2['Machine failure']==1][['Type']].apply(pd.value_counts)\ndf4","5e2771bd":"df5=df2[df2['Machine failure']==1][['Air temperature [K]']].apply(pd.value_counts)\ndf5","1a7868d6":"df5","60d3ef1e":"df6=df2[df2['Machine failure']==1][['Process temperature [K]']].apply(pd.value_counts)\ndf6","9871d363":"df7=df2[df2['Machine failure']==1][['Rotational speed [rpm]']].apply(pd.value_counts)\ndf7","3793e19d":"df8=df2[df2['Machine failure']==1][['Torque [Nm]']].apply(pd.value_counts)\ndf8","c32a3daa":"df9=df2[df2['Machine failure']==1][['Tool wear [min]']].apply(pd.value_counts)\ndf9","90273885":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    # label_encoder object knows how to understand word labels.\n    label_encoder = preprocessing.LabelEncoder()\n \n    # Encode labels in column 'species'.\n    df[c1]= label_encoder.fit_transform(df[c1])\n \n    df[c1].unique()\n    return df","0cba10fa":"df.columns","5cdbdb33":"df","60325532":"LABEL_ENCODING('Product ID')","4dcc023d":"LABEL_ENCODING('Type')","65d6a1e0":"df.rename(columns = {'Air temperature [K]':'Airtemp'}, inplace = True)","8fb1fc24":"df.rename(columns={'Process temperature [K]':'Processtemp'} ,inplace=True)","f9075d46":"df.rename(columns={'Rotational speed [rpm]':'Rotationalspeed'} ,inplace=True)","f2bb53d0":"df.rename(columns={'Torque [Nm]':'Torque'} ,inplace=True)","926e307a":"df.rename(columns={'Tool wear [min]':'Toolwear'} ,inplace=True)","50e302f8":"df","39b664c7":"X=df.drop('Machine failure',axis=1)\ny=df['Machine failure']","939da298":"X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)","e7f2e78c":"print(X_train.shape,Y_train.shape)","a4375345":"print(X_test.shape,Y_test.shape)","fb0b06b2":"D_train = xgb.DMatrix(data=X_train, label=Y_train)\nD_test = xgb.DMatrix(data=X_test, label=Y_test)","c82419d9":"param = {\n    'eta': 0.3, \n    'max_depth': 3,  \n    'objective': 'multi:softprob',  \n    'num_class': 3} \n\nsteps = 20  # The number of training iterations","8da2ced4":"model = xgb.train(param, D_train, steps)","d8b35848":"import numpy as np\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\n\npreds = model.predict(D_test)\nbest_preds = np.asarray([np.argmax(line) for line in preds])\n\nprint(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\nprint(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\nprint(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))","c7741c76":"model.dump_model('dump.raw.txt')","9f3ac2b2":"In order for XGBoost to be able to use our data, we\u2019ll need to transform it into a specific format that XGBoost can handle. That format is called DMatrix","478a1c68":"## Sub Groups For Machine Failure","bf240757":"From the above observations we can say that process temperarures 310.9,310.2,310.7,310.4,310.1 contribute more towards machine failure","58456677":"# Data Visualization","1b1a38bf":"# Importing required Libraries","ab44192c":"From the above observations Tool wears 207,208,203,215 contribute more towards machine failure","636a740b":"## Querying the data","f0bc28db":"from the above observation we can say that there are 339 rows in each column contributing towards machine failure","cb3f2300":"## Pair plot","20d7fab2":"# Data Preproccessing","8faaa0da":"From the above observations the torques 62.4,65.3,68.2,60.7,45.1 contribute more towards machine failure","71004451":"From the above observation we can see that Type L contributes more towards machine failure","bcb309f6":"From the above observations we can say that temperatures 302.6,303.4,302,302.4 contribute more towards machine failure","f1c13ccc":"# Data Modelling","5096aa30":"3.39 percent of the machine data contribute towards machine failure","6e463cc2":"From the above obseration Roational Speed 1336,1372,1379,1362,1365 contribute more towards machine failure","5fbf4e19":"## Pie plots for machine failure sub groups","f30e8caf":"# Feature Selection","a95817e0":"# Explorfatory Data Analysis","0a58d115":"# Summary of EDA"}}