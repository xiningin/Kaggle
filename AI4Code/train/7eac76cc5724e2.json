{"cell_type":{"fa256779":"code","31dc08f6":"code","272387e5":"code","0f689f7d":"code","8d6165fe":"code","33ac1e2c":"code","4c714505":"code","9e8cd102":"code","5f3bc6b4":"code","cbced59a":"code","2cfd96f4":"code","ef926d70":"code","6ff5282b":"code","f71cdb61":"code","23800774":"code","91709e47":"code","06f83a53":"code","555e8498":"code","6cd788f5":"code","ef4a5d70":"code","757bcd25":"code","8b04148d":"code","19978aea":"code","3ed3d786":"code","dd98e625":"code","334eac97":"code","cfc5cfce":"code","06cc2b07":"code","a967f8fa":"code","8bb0796f":"code","5b112580":"code","76f5f622":"code","3f811093":"code","ab45d1ee":"code","a886b19b":"code","1c30b883":"code","ba0145b0":"code","2d93f237":"code","895e0734":"code","99dbd516":"code","54d31950":"code","af9a3023":"code","f32b5ff7":"code","718f7e80":"code","0c31c17c":"code","d44cb190":"code","1b8d9587":"code","62868916":"code","9dbfd4ab":"code","f526d549":"code","2e55e1be":"code","c5c9d531":"code","9d78c48f":"code","d239138a":"code","a7bedea9":"code","afdea645":"code","49d5a2c0":"code","a91494e1":"code","7c7b617e":"markdown","d4235e9b":"markdown","9f5e8dbd":"markdown","06af66c2":"markdown","c9b47415":"markdown","e231d15a":"markdown","d1e029c8":"markdown","7aa7e13e":"markdown","9d737a9c":"markdown","d3f59b2d":"markdown","571fff58":"markdown","fbef6e08":"markdown","3f7e6849":"markdown","cbdae9d3":"markdown","3f8c5ff2":"markdown","28a906c0":"markdown","d2d1cf6f":"markdown","f715ad6e":"markdown","83261361":"markdown","ae46d0ea":"markdown","c0f945e2":"markdown","94505946":"markdown","e5a19792":"markdown","28bbeafc":"markdown","0515b0d0":"markdown","a660f7d8":"markdown","669165d1":"markdown","a6bee7ff":"markdown","28eee4dd":"markdown","49b7a844":"markdown","6cd35b69":"markdown","8385e4d0":"markdown","5ef06da9":"markdown","53fccb00":"markdown","7bc89da7":"markdown","bb2751a8":"markdown","e7ad1446":"markdown","68a41614":"markdown","b45bc8f7":"markdown","9b598072":"markdown","73a06cd2":"markdown","0d7a29c3":"markdown","bc15b4c8":"markdown","8729dc21":"markdown","68a1f9d7":"markdown","c7459ac5":"markdown","8306acb3":"markdown","2cf6e005":"markdown","8805d9a6":"markdown","5d8abc8b":"markdown","bf41fe66":"markdown","606b643b":"markdown","55f10f72":"markdown","5dedd22c":"markdown"},"source":{"fa256779":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nimport math","31dc08f6":"customer_segment = pd.read_csv(\"..\/input\/customer-segmentation\/ELD Service Provider Segmentation Dataset.csv\")","272387e5":"customer_segment.head()","0f689f7d":"customer_segment.dtypes","8d6165fe":"customer_segment['Customer Date'] =  pd.to_datetime(customer_segment['Customer Date'], infer_datetime_format=True)","33ac1e2c":"customer_segment['month_year'] = customer_segment['Customer Date'].dt.to_period('M')\ncustomer_segment['year'] = pd.DatetimeIndex(customer_segment['Customer Date']).year\ncustomer_segment['month'] = pd.DatetimeIndex(customer_segment['Customer Date']).month\ncustomer_segment.head()","4c714505":"customer_segment.describe().transpose()","9e8cd102":"sns.displot(customer_segment['Net ARR']);","5f3bc6b4":"#skewness and kurtosis\nprint(\"Skewness: %f\" % customer_segment['Net ARR'].skew())\nprint(\"Kurtosis: %f\" % customer_segment['Net ARR'].kurt())","cbced59a":"%matplotlib inline\nimport matplotlib.pyplot as plt\ncustomer_segment.hist(figsize = (50,20))\nplt.show()","2cfd96f4":"var = 'Segment'\ndata = pd.concat([customer_segment['Composite Fleet Size'], customer_segment[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"Composite Fleet Size\", data=data)\nfig.axis(ymin=0, ymax=1000);","ef926d70":"var = 'Segment'\ndata = pd.concat([customer_segment['Net ARR'], customer_segment[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"Net ARR\", data=data)\nfig.axis(ymin=0, ymax=2500000);","6ff5282b":"var = 'Territory'\ndata = pd.concat([customer_segment['Net ARR'], customer_segment[var]], axis=1)\nf, ax = plt.subplots(figsize=(100, 10))\nfig = sns.boxplot(x=var, y=\"Net ARR\", data=data)\nfig.axis(ymin=0, ymax=300000);","f71cdb61":"sns.lineplot(data=customer_segment, x=\"year\", y=\"Net ARR\")","23800774":"customer_segment[customer_segment['Number of ELD Devices']==0]","91709e47":"customer_segment[\"Number of ELD Devices\"].replace(0, np.nan, inplace=True)\n#customer_segment[\"Number of ELD Devices\"].fillna(customer_segment.groupby(\"Composite Fleet Size\")[\"Number of ELD Devices\"].transform(\"mean\"))\ncustomer_segment['Number of ELD Devices'] = customer_segment.groupby(['Composite Fleet Size'], sort=False)['Number of ELD Devices'].apply(lambda x: x.fillna(x.mean())).round().astype(int)","06f83a53":"customer_segment[customer_segment['Net ARR']==0].count()","555e8498":"#customer_segment[\"Net ARR\"].replace(0, np.nan, inplace=True)\n#customer_segment['Net ARR'] = customer_segment.groupby(['Composite Fleet Size'], sort=False)['Net ARR'].apply(lambda x: x.fillna(x.mean())).round()\n#customer_segment.groupby(['Composite Fleet Size'], sort=False)['Net ARR'].apply(lambda x: x.fillna(x.mean()))\ncustomer_segment = customer_segment[customer_segment['Net ARR'] != 0]","6cd788f5":"total = customer_segment.isnull().sum().sort_values(ascending=False)\npercent = (customer_segment.isnull().sum()\/customer_segment.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data = missing_data[missing_data['Total'] > 0]\nmissing_data","ef4a5d70":"customer_segment = customer_segment[customer_segment['Net ARR'].notna()]","757bcd25":"total = customer_segment.isnull().sum().sort_values(ascending=False)\npercent = (customer_segment.isnull().sum()\/customer_segment.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data = missing_data[missing_data['Total'] > 0]\nmissing_data","8b04148d":"corr_matrix = customer_segment.corr()\ncorr_matrix[\"Net ARR\"].sort_values(ascending = False)","19978aea":"sns.set()\nsns.pairplot(customer_segment, height = 2.5)\nplt.show();","3ed3d786":"var = 'Composite Fleet Size'\ndata = pd.concat([customer_segment['Net ARR'], customer_segment[var]], axis=1)\ndata.plot.scatter(x=var,xlim = (0,2000), y='Net ARR', ylim=(0,800000));","dd98e625":"var = 'Number of ELD Devices'\ndata = pd.concat([customer_segment['Net ARR'], customer_segment[var]], axis=1)\ndata.plot.scatter(x=var,xlim = (0,2000), y='Net ARR', ylim=(0,800000));","334eac97":"corrmat = customer_segment.corr()\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'Net ARR')['Net ARR'].index\ncm = np.corrcoef(customer_segment[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","cfc5cfce":"update_segments = customer_segment.copy()","06cc2b07":"update_segments['ARR\/Product'] = update_segments['Net ARR'].floordiv(update_segments['Number of ELD Devices'])","a967f8fa":"update_segments['Potencial Upsell Product'] = update_segments['Composite Fleet Size'] - update_segments['Number of ELD Devices']","8bb0796f":"update_segments.head()","5b112580":"update_segments.loc[update_segments['Potencial Upsell Product'] < 0, 'Potencial Upsell Product'] = 0","76f5f622":"update_segments['Potencial Upsell Product ARR'] = update_segments['ARR\/Product'] * update_segments['Potencial Upsell Product']\nupdate_segments['Potencial ARR Achieved'] = update_segments['Potencial Upsell Product ARR'] * 0.70\nupdate_segments['Potencial ARR Achieved'] = update_segments['Potencial ARR Achieved'].astype('int64')","3f811093":"update_segments['Current\/Potencial ARR'] =  update_segments['Potencial Upsell Product ARR'] + update_segments['Net ARR']","ab45d1ee":"update_segments.head()","a886b19b":"corr_matrix1 = update_segments.corr()\ncorr_matrix1[\"Net ARR\"].sort_values(ascending = False)","1c30b883":"corrmat1 = update_segments.corr()\nk = 8 #number of variables for heatmap\ncols = corrmat1.nlargest(k, 'Net ARR')['Net ARR'].index\ncm = np.corrcoef(update_segments[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","ba0145b0":"update_segments.describe().round().transpose().astype(int)","2d93f237":"segment_final = pd.DataFrame(update_segments[['Potencial Upsell Product ARR','Net ARR','Composite Fleet Size']].copy().astype(np.int32))","895e0734":"segment_final[segment_final['Net ARR'] == 0]","99dbd516":"segment_final.describe().round().transpose().astype(int)","54d31950":"def yeojohnson(x):\n    xt, _= stats.yeojohnson(x)\n    return xt\n\nsegment_boxcox = segment_final.apply(yeojohnson,axis = 0)","af9a3023":"segment_boxcox.describe().astype(int)","f32b5ff7":"sns.distplot(segment_boxcox['Net ARR'] , fit = norm)\nfig = plt.figure()","718f7e80":"#skewness and kurtosis\nprint(\"Skewness: %f\" % segment_boxcox['Net ARR'] .skew())\nprint(\"Kurtosis: %f\" % segment_boxcox['Net ARR'] .kurt())","0c31c17c":"sns.distplot(segment_boxcox['Potencial Upsell Product ARR'] , fit=norm);\nfig = plt.figure()","d44cb190":"print(\"Skewness: %f\" % segment_boxcox['Potencial Upsell Product ARR'] .skew())\nprint(\"Kurtosis: %f\" % segment_boxcox['Potencial Upsell Product ARR'] .kurt())","1b8d9587":"sns.distplot(segment_boxcox['Composite Fleet Size'] , fit=norm);\nfig = plt.figure()","62868916":"print(\"Skewness: %f\" % segment_boxcox['Composite Fleet Size'] .skew())\nprint(\"Kurtosis: %f\" % segment_boxcox['Composite Fleet Size'] .kurt())","9dbfd4ab":"scaler = StandardScaler()\nscaler.fit(segment_boxcox)\nsegment_scaled = scaler.transform(segment_boxcox)\nsegment_scaled_df = pd.DataFrame(data = segment_scaled, index = segment_boxcox.index, columns = segment_boxcox.columns)\n\nsegment_scaled_df.agg(['mean','std']).round()","f526d549":"from sklearn.cluster import KMeans\nkmeans=KMeans(n_clusters = 4)\nkmeans.fit(segment_scaled_df)\nsegment_kmeans4 = segment_final.assign(segment = kmeans.labels_)\nSegments_refined = update_segments.assign(segment = kmeans.labels_)","2e55e1be":"segment_kmeans4.groupby(['segment']).agg({\n    'Net ARR': ['mean','count'],\n    'Potencial Upsell Product ARR' : ['mean','count'],\n    'Composite Fleet Size' : ['mean','count']\n    \n}).round()","c5c9d531":"kmeans4_averages = segment_kmeans4.groupby(['segment']).mean().round(0)\nsns.heatmap(kmeans4_averages.T, cmap='YlGnBu')\nplt.show()","9d78c48f":"segment_scaled_dff = pd.DataFrame(segment_scaled, index=segment_final.index, columns=segment_final.columns)\nsegment_scaled_dff['Cluster'] = segment_kmeans4['segment']\ndf_melt = pd.melt(segment_scaled_dff.reset_index(), id_vars = ['Cluster'],value_vars = ['Composite Fleet Size','Net ARR','Potencial Upsell Product ARR'],var_name = 'Attribute',value_name = 'Value')","d239138a":"plt.figure(figsize=(15,16))\nsns.lineplot(x = \"Attribute\",y = \"Value\",hue = 'Cluster', data = df_melt)","a7bedea9":"import plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nPLOT = go.Figure()\n\nfor C in list(segment_scaled_dff.Cluster.unique()):\n    \n    PLOT.add_trace(go.Scatter3d(x = segment_scaled_dff[segment_scaled_dff.Cluster == C]['Composite Fleet Size'],\n                                y = segment_scaled_dff[segment_scaled_dff.Cluster == C]['Net ARR'],\n                                z = segment_scaled_dff[segment_scaled_dff.Cluster == C]['Potencial Upsell Product ARR'],\n                                mode = 'markers', marker_size = 8, marker_line_width = 1,\n                                name = 'segment ' + str(C)))\n\n\nPLOT.update_layout(width = 800, height = 800, autosize = True, showlegend = True,\n                   scene = dict(xaxis=dict(title = 'Composite Fleet Size', titlefont_color = 'black'),\n                                yaxis=dict(title = 'Net ARR', titlefont_color = 'black'),\n                                zaxis=dict(title = 'Potencial Upsell Product ARR', titlefont_color = 'black')),\n                   font = dict(family = \"Gilroy\", color  = 'black', size = 12))","afdea645":"sse ={}\nfor k in range(1,11):\n    kmeans = KMeans(n_clusters = k, random_state =1)\n    kmeans.fit(segment_scaled_df)\n    sse[k] = kmeans.inertia_","49d5a2c0":"plt.title('TheElbow Method')\nplt.xlabel('k'); plt.ylabel('SSE')\nsns.pointplot(x = list(sse.keys()), y = list(sse.values()))\nplt.show()","a91494e1":"Segments_refined.groupby('segment')[['Net ARR','Composite Fleet Size','Potencial Upsell Product ARR']].describe(include=[np.number]).round().transpose()","7c7b617e":"Segment here represnts the way the customers are currently being segmented\n\nAn important things to notice from these boxplots:\n* Since we know that the Composite Fleet Size is being used to determine the segments, the boxplot should indicate a difference in the values in distribution of segments on Net ARR and on the Composite Fleet Size. However, lookinmg at the data we see some overlap. Segmenting customers should rely on differentiating them as much as we can in order to target them accordingly. We therefore need to improve on the way the segments are being created\n","d4235e9b":"We will now select the features that we want to use to segment our customers: \n\nBased on our exploration, we decided that instead of just using the composite fleet size attribute, we need more information to better segment our customers. We therefore derived the Potencial Upsell revenue feature that would tell us which customers we can upsell to. Lastly we will use the Net ARR feature as its a good indicator to the amount of revenue each customer is bringing to the company and will be crucial in resource allocation as a ratio of revenue ","9f5e8dbd":"Before we move on, lets extract some useful information from the Customer Date column. We can extract the year, the month, and the year-month. These might be useful later on","06af66c2":"A few comments about the hisgrams:\n* The attributes have different scales. While the number of ELD devices and the Composite Fleet size, do take the same scale, the NETT ARR attribute is different since it represents the dollar amounts that the company is earning\n* The histograms for ELD, CFS (Composite Fleet Size) and Net ARR are tail heavy, meaning that they could be hard for some machine learning algorithms to detect patterns. We will try transforming these attributes later on to have a more bell-shaped distribution","c9b47415":"As we can see from the table above, there is only one value missing. \n\n* Since Net ARR is an indicator that a customer is a paying customer, we will drop where its null assuming that we will not consider customers that are not paying","e231d15a":"Another very informative view of the data is through the use of multiple histograms within one visualization. This helps you get a good idea about how the frequency of the data is distributed among different values that an attribute can take","d1e029c8":"# K - Means output","7aa7e13e":"Some important observations from the correlation coefficient and the pairplot:\n\n* The most correlated variable with Net ARR is the number of ELD devices which makes sense since the more devices you sell the more revenue you earn. \n* However, Composite Fleet Size does not indicate a very strong relation with Net ARR. Which means that even if the customer has a lot of trucks in their fleet, they are still not buying a lot of ELD's from our company\n\nNote that these are very important observations. Composite Fleet Size is currently being used to segment customers. However, that variable is not a very strong indicator of the revenue the company is earning. We need to think of other features that could better help us capture the segments in terms of revenue capitalization because in the end, as a business, they are concerned the most about revenue","9d737a9c":"We have seen so far that the composite fleet size by itself would not be an ideal attribute to segment the customer on. For one, it fails to truly reflect the customers, e.g there could be two customers with huge fleet sizes however one of them could be purchasing a lot from us and the other not so much and therefore the strategy to deal with them would be different. Hence, we need to add more attributes to our model","d3f59b2d":"We mentioned earlier that the attributes we have are not normally distributed which is essential for K-means clustering. We will therefore go ahead and use the yeojohnson function to normalize all the three features that we have selected","571fff58":"You can easily compute the the standard correlation coefficient (also called the Pearson's r) between every pair of attributes using the corr() method.\n\nAfter getting the correlation values, lets look at how each attribute correlates with the 'Net ARR'","fbef6e08":"# Experimenting with Attribute Combinations","3f7e6849":"## Numercial Attributes exploration","cbdae9d3":"Now one important attribue that we need to derive is the potencial of upselling to an exisiting customer. This means that we need to see as to how many trucks the compnay has and how many ELD devices the customer is currently purchashing from us. Note that here I am assuming that each truck would have one ELD device. \n\nTo calculate the Potencial Upsell ACV we will need to derive other variables before computing that:","3f8c5ff2":"In this notebook, we will go through an end to end machine learning project, making use of the Kmeans clustering algorithm to cluster customers into different segments","28a906c0":"## Feature Selection","d2d1cf6f":"With the data we have, an important thing to check are the number of records that have a value of zero. Technically 0 should not be in our dataset for Net ARR or Number of ELD devices since we are assuming that the customers we have are paying customers which have bought atleast one ELD device from the company. We will therefore check the value of 0 for both these attributes one by one","f715ad6e":"Finally we will groupby the newly created segments and then get summary statistics on actual data and not scaled or normalized data for all the features that we used to get a sense of what kind of customer is in each cluster","83261361":"Finally, we need to see as to what the ideal number of clusters should be. We can use the elbow method to derive the optimal number of clusters but one thing important to keep in mind is that it is highly encouraged to not just rely on this method but to use domain and bussiness knowledge to come up with the ideal number of clusters","ae46d0ea":"We will start with looking at the number of values that are null. We will then take the percentage of those values with respect to the total sample for that particular attribute to see how many values are missing","c0f945e2":"Most Machine Learning algorithms cannot work with missing features. You have three options when dealing with missing features:\n* Get rid of the corresponding values\n* Get rid of the whole attribute\n* Set the values to some value( zero, the mean, the median etc)","94505946":"Some important observations about the information in the snake plot above:\n\n* Cluster 0: represents customers that have a smaller fleet size but we are catering to almost all of their trucks since the potencial to upsell to them is minimal\n* Cluster 1: represents customers that have a medium sized fleet size but again we are catering to all of their trucks and hence the upsell potencial is negligible\n* Cluster 2: represents customers  that have a smaller fleet size, however they are not purchashing all ELD devices from us and therefore they have an uposell potencial\n* Cluster 3: represents customers that have medium to large fleet sizes, however again the potencial to sell more to these customers is high as can be seen from the above chart \n\nNote that the way I have attributed customer fleet sizes to different clusters depends on the statistics we caluclated previously for the averge values of each feature for each cluster\n\n\n","e5a19792":"Finally, we can use a vey useful visualization to show the correlation between nunmerical attributes; the seaborn heatmap visualization.","28bbeafc":"Lets copy the original data and add additional features to this copied dataset","0515b0d0":"## Categorical Attributes Exploration","a660f7d8":"## Optimal Number of Clusters","669165d1":"This is similar to what we did above but this time we are outputting it in terms of a visualization which is much easier to read","a6bee7ff":"#  Data Cleaning","28eee4dd":"As you can see from the graph above and from the skewness and Kurtosis, that this variable is not normally distributed. If we choose to incorporate this in our clustering analysis we will need to fit this to a normal distribution. We will go into more details on this later on","49b7a844":"# Training the Model - K-Means ","6cd35b69":"We will again use Scikit-learn package to import Kmeans. To start off, we will be choosing 4 clusters for our model to divide our data in. We can provide this information to the Kmeans function as n_clusters = x number of clusters. We then fit the scaled and normalized data to the kmeans fit method which computes the clusters. In just a few lines of code we have gotten our clustering model","8385e4d0":"Another way to check for correlation between attributes is to use the pairplot function, which plots every numercial attribute against each other numerical attribute. ","5ef06da9":"Before moving on and analyzing the dataset, lets make sure that the data types for each column are correct","53fccb00":"Note that the relationship in the exisiting data between the number of trucks and the Number of ELD devices is not one to one. However, to make things simpler, we will assume that if a customer is purchashing more devices than the number of trucks they have then we do not have any additional upsell potencial there. \n\nWe will therefore change all negative values in the \"Potencial Upsell Product\" to 0","7bc89da7":"Let's now get some basic statistical details about our data. We will use the pandas descirbe() method to get information such as mean, std, min, max etc for all the numerical attributes in our data. We will use the transpose() method in conjunction just so that its a bit easier to read","bb2751a8":"Here I will use two methods to remove the 0 values:\n\n* For the attribute, Number of ElD Devices, I will convert the 0 values to nan, then use the Composite Fleet Size column to look at similar values that were not 0 or blank and use average of those values to fill the current 0\/nan values\n* For the Net ARR, I wil keep things simple and just drop all rows that have a 0","e7ad1446":"# Data Exploration","68a41614":"We will start start off by exploring the Net ARR variable.To see the distribution of the attribute we will use the displot which is part of the seabporn library","b45bc8f7":"Finally, using the attriubutes that we have derived, we can now calculate the Potenciall Upsell revenue. \n\nNote that there is one more attribute that I am deriving, the Potenciall ARR Achieved. Basically, I am assuming that we can get 70 % of the potencial revenue from the customer. Now the '70%' itrself is completely arbitrary and I have chosen this just to show that we can also use a historical analysis of how much we upsell on averge and use that to segment customers. However, for our analysis, we will be sticking with the Potencial Upsell Product ARR (represnting all the revenue that we can achieve based on the assumptions mentioned above). ","9b598072":"# Looking for Correlations","73a06cd2":"One of the most important transformations you need to apply to your data is feature scaling. Machine learning algorithms don't work really well when the input numerical attributes have different scales.\n\nWe will use standardization wich subtracts the mean ( so standardized vales always have a 0 mean), and then it divides by the standard deviation so that the resulting distribution has unit variance. We will import StandardScaler from Sicikit Learn to do the standardization. ","0d7a29c3":"# Preparing Data for Machine Learning","bc15b4c8":"In this section we will be exploring some of the categorical attributes present in the data. We will be using the boxplot to get information on the categorical attributes. \n\nA boxplot is a standardized way of displaying the distribution of data based on a five number summary (\u201cminimum\u201d, first quartile (Q1), median, third quartile (Q3), and \u201cmaximum\u201d). It can tell you about your outliers and what their values are. It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed. \n\nThe Image below summarizes the usefulness of the boxplot:\n\n![image.png](attachment:bb8ea5df-f593-4293-8be5-1b0e15d86623.png)\n\n*important note: boxplot image and boxplot description has been taken from the following article: https:\/\/towardsdatascience.com\/understanding-boxplots-5e2df7bcbd51","8729dc21":"As we can see from the above char, 4 is the ideal number of clusters that the Elbow method is suggesting. In our case both the elbow method and the domain knwledge does give evidence to using 4 cliusters. ","68a1f9d7":"## Feature Scaling ","c7459ac5":"The correlation coefficient ranges from -1 to 1. When it is close to 1, it means there is a strong positive correlation. When the correaltion is close to -1, it means there is a strong negative correlation","8306acb3":"Now we will compute the snake plot, which I think is one of the most useful charts for kmeans clustering since it tells you for each cluster, which features contributed the most","2cf6e005":"To see some basic properties of the segments that we have created using kmeans clustering we will use the groupby method on the clusters and get mean and count for each feature that we used in our model. \n\nThis gives us a basic idea of each cluster. ","8805d9a6":"Let's now briefly go through the same process of exploring the dataset with new features. Note that since they have been derived from existing information, we do not need to go through the whole process again. We will just look at the summary statistics and general correlation between variables in this section before diving into our model","5d8abc8b":"As you can see the customer date is of the type object. However we would want to convert it to a datetime data type. We will use the pandas to_datetime method to convert the column to the relevant data type","bf41fe66":"We can also use a 3D Scatter plot to see how our clusters are divided. This provides a very good idea as to how good your Kmeans model was since by looking at the values you can see how far apart they are","606b643b":"Lets start off by exploring the contents of the dataset using the head() mehtod. This will output the first 5 rows giving a glimpse into the columns and thier values ","55f10f72":"Let's look at the the composite fleet size and number of ELD devices individually with Net ARR. just to get more information regarding the datapoints","5dedd22c":"## Normalization"}}