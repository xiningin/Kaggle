{"cell_type":{"5d45a507":"code","b3fe85a7":"code","fb800df7":"code","08d9dd05":"code","837d61aa":"code","5e885992":"code","04c9123e":"code","98d4f7e3":"code","7aaf757e":"code","fbf03fe5":"code","fa22468a":"code","3acc2979":"code","c1abfe59":"code","3e1dba0f":"code","d073039e":"code","aebd96bc":"code","5f4932bf":"code","a94ab29e":"code","b3ae796a":"code","5579d93e":"markdown","a585682d":"markdown"},"source":{"5d45a507":"!pip install Pillow","b3fe85a7":"!pip install imutils","fb800df7":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\n\nimport cv2      #open cv\nimport imutils\n\n\nfrom PIL import Image ","08d9dd05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom os import listdir\n\nfor root, dirs,files in os.walk(\"\/kaggle\/input\"):       #root, list of directories in the root, list of files in the root\n    print(root)\n    print(dirs)\n    print(files)\n    print(\"_________________________________________________________________________________________________________________________\")\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","837d61aa":"#the dataset directories\nno_dir = \"\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\/no\"       #the dataset directory without tumor\nyes_dir = \"\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\/yes\"     #the dataset directoy with tumor","5e885992":"#the training dataset\nno = [os.path.join(no_dir,im) for im in os.listdir(no_dir)]\nprint(\"Sample paths:\",no[:10])\n\nyes = [os.path.join(yes_dir,im) for im in os.listdir(yes_dir)]\nprint(\"Sample paths:\",yes[:10])\n\n\n\npaths = no+yes\nlabels = [\"no\" for i in no]+[\"yes\" for i in yes]\ndata = pd.DataFrame(data={\"Paths\":paths,\"Labels\":labels})\n\nrandom.shuffle(paths)\npaths=paths[:10]\n\nfor i, img_path in enumerate(paths):\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n    plt.axis('Off')\n    plt.show()\n","04c9123e":"print(\"Total cases of no tumor: \",len(no))\nprint(\"Total cases of detected tumor: \",len(yes))","98d4f7e3":"data = data.sample(frac=1).reset_index(drop=True)\ntrain_size = int(len(data)*0.75)\ntrain_data = data.iloc[:train_size,:].reset_index(drop=True)\ntest_data = data.iloc[train_size:,:].reset_index(drop=True)\n","7aaf757e":"del paths, labels, no,yes, data","fbf03fe5":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\ntraining_datagen = ImageDataGenerator(\n      rescale = 1.\/255,\n\t    rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = training_datagen.flow_from_dataframe(train_data, x_col=\"Paths\",y_col=\"Labels\",\n\ttarget_size=(128,128),\n\tclass_mode='binary',\n  batch_size=20\n)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(test_data, x_col=\"Paths\",y_col=\"Labels\",\n\ttarget_size=(128,128),\n\tclass_mode='binary',\n  batch_size=20\n)","fa22468a":"print(\"{} Training samples divided into {} batches.\".format(len(train_data),len(train_generator)))\nprint()\nprint(\"{} Validation samples divided into {} batches.\".format(len(test_data),len(validation_generator)))\n","3acc2979":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (2,2), activation='relu', input_shape=(128,128, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    \n    # 600 neuron hidden layer\n    tf.keras.layers.Dense(600, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(20, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory = model.fit(train_generator, epochs=50,  validation_data = validation_generator, verbose = 1, validation_steps=3)\n","c1abfe59":"\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.plot(epochs, loss, 'pink', label='Training loss')\nplt.plot(epochs, val_loss, 'cyan', label='Validation loss')\nplt.title('Training and validation accuracy and loss')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","3e1dba0f":"from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n\nmodel2 = Sequential()\n\nmodel2.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\nmodel2.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n\n\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\nmodel2.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\nmodel2.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel2.add(Dropout(0.25))\n\nmodel2.add(Flatten())\n\nmodel2.add(Dense(600, activation='relu'))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(1, activation='softmax'))\n\nmodel2.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\nprint(model2.summary())\n\n\n\n\n\n\nhistory2 = model2.fit(train_generator, epochs=25,  validation_data = validation_generator, verbose = 1, validation_steps=3)\n","d073039e":"\nacc = history2.history['accuracy']\nval_acc = history2.history['val_accuracy']\nloss = history2.history['loss']\nval_loss = history2.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.plot(epochs, loss, 'pink', label='Training loss')\nplt.plot(epochs, val_loss, 'cyan', label='Validation loss')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","aebd96bc":"from matplotlib.pyplot import imshow\n\ndef names(cat):\n    if cat==0:\n        return 'Tumor detected'\n    else:\n        return 'No detected tumor'\n    \nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/N17.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","5f4932bf":"img = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y3.jpg\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","a94ab29e":"def contour(image , plot = False):\n    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)                         #grayscaling the images\n    grayscale = cv2.GaussianBlur(grayscale, (5,5),0)                            #blur the image to bring it under the threshold\n    threshold_image = cv2.threshold(grayscale, 50, 255, cv2.THRESH_BINARY)[1]   #convert these grayscaled images to binary images\n    threshold_image = cv2.erode(threshold_image, None, iterations=2)            #to remove the regions of noise\n    threshold_image = cv2.dilate(threshold_image, None, iterations=2)           #to remove all the noises around the image\n    \n    #Now we need to find the contour and clean it to get what is inside the image.\n    contour = cv2.findContours(threshold_image.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      \n    \n    #we grab the largest contour using the max.\n    contour = imutils.grab_contours(contour)\n    c = max(contour, key=cv2.contourArea)\n    \n    #Now we limit the image by finding it's extreme points.\n    ext_left = tuple(c[c[:,:,0].argmin()][0])\n    ext_right = tuple(c[c[:,:,0].argmax()][0])\n    ext_top = tuple(c[c[:,:,1].argmin()][0])\n    ext_bot = tuple(c[c[:,:,1].argmax()][0])\n    \n    processed_image = image[ext_top[1]:ext_bot[1],ext_left[0]:ext_right[0]]\n        \n    if plot:\n        plt.figure()\n        plt.subplot(1,2,1)\n        plt.imshow(image)\n        \n        plt.tick_params(axis=\"both\", which=\"both\",\n                       top= False, bottom= False,left= False,right= False,\n                        labeltop= False, labelbottom= False,\n                        labelleft= False,labelright= False)\n        plt.title(\"ORIGINAL\")\n        \n        \n        plt.subplot(1,2,2)\n        plt.imshow(processed_image)\n        \n        plt.tick_params(axis=\"both\", which=\"both\",\n                       top= False, bottom= False,left= False,right= False,\n                        labeltop= False, labelbottom= False,\n                        labelleft= False,labelright= False)\n        plt.title(\"PROCESSED\")\n        plt.show()\n        \n    return processed_image\n    ","b3ae796a":"for path in train_data.Paths:\n    img = cv2.imread(path)\n    img = contour(img, True)\n    \"\"\"plt.imsave(img,path)\"\"\"\n","5579d93e":"## Cropping image contour \nThis removes all the noises from the images making our data one step towards ready to be modelled. ","a585682d":"Here we build a CNN classifier to tag the MRI images into two categories- with tumor or without tumor."}}