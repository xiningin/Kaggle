{"cell_type":{"2d9fd232":"code","bc8cda47":"code","eec0df5a":"code","f9796ad6":"code","bc5c74cc":"code","b72be10b":"code","54b717d8":"code","98425b65":"code","54ad6c27":"code","328df982":"code","9b8e5f9a":"code","d32cb8f3":"code","710633f5":"code","350cdfde":"markdown","fc06dce3":"markdown","6dc5c434":"markdown","11569c64":"markdown","3d5809bf":"markdown","d8c6a78a":"markdown","45b0c199":"markdown","3b17eb7f":"markdown","1f708341":"markdown","f54287fc":"markdown"},"source":{"2d9fd232":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport glob\nimport keras\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom skimage import color, exposure, transform\nimport tensorflow as tf\nfrom skimage import io\nimport os\nimport glob\n\nprint(os.listdir(\"..\/input\/gtsrb_challenge\/GTSRB_Challenge\/train\"))\n\n# Any results you write to the current directory are saved as output.","bc8cda47":"NUM_CLASSES = 43\nIMG_SIZE = 48","eec0df5a":"def preprocessing(img):\n    return transform.resize(img, (IMG_SIZE,IMG_SIZE))\n\ndef get_class(img_path):\n    return int(img_path.split('\/')[-2])\n\nroot_dir = '..\/input\/gtsrb_challenge\/GTSRB_Challenge\/train'\nimgs = []\nlabels = []\n\nall_img_paths = glob.glob(os.path.join(root_dir, '*\/*.ppm'))\nnp.random.shuffle(all_img_paths)\nfor img_path in all_img_paths:\n    img = preprocessing(io.imread(img_path))\n    label = get_class(img_path)\n    imgs.append(img)\n    labels.append(label)\n\nX = np.array(imgs, dtype='float32')\n# Make one hot targets\nY = np.eye(NUM_CLASSES, dtype='uint8')[labels]","f9796ad6":"def nameImage(img_path):\n    return img_path.split('\/')[-2]\nfig=plt.figure(figsize=(20, 20))\ncolumns = 9\nrows = 9\nfor i in range(1, columns*rows +1):\n    k = np.random.randint(0,len(imgs))\n    fig.add_subplot(rows, columns, i)\n    image = io.imread(all_img_paths[k])\n    image = preprocessing(image)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(nameImage(all_img_paths[k]))\nplt.show()","bc5c74cc":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras import backend as K\nK.set_image_data_format('channels_last')\n\n\ndef cnn_model():\n    network = Sequential()\n    network.add(Conv2D(64, (3, 3), padding='same',input_shape=(IMG_SIZE, IMG_SIZE,3),activation='relu'))\n    network.add(Conv2D(64, (3, 3), activation='relu'))\n    network.add(MaxPooling2D(pool_size=(2, 2)))\n    network.add(Dropout(0.2))\n    network.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\n    network.add(Conv2D(128, (3, 3), activation='relu'))\n    network.add(MaxPooling2D(pool_size=(2, 2)))\n    network.add(Dropout(0.2))\n    network.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n    network.add(Conv2D(512, (3, 3), activation='relu'))\n    network.add(MaxPooling2D(pool_size=(2, 2)))\n    network.add(Dropout(0.2))\n    network.add(Flatten())\n    network.add(Dense(1024, activation='relu'))\n    network.add(Dropout(0.5))\n    network.add(Dense(NUM_CLASSES, activation='softmax'))\n    return network","b72be10b":"from keras.optimizers import SGD\nnetwork = cnn_model()\nlr = 0.01\nsgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\nnetwork.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])","54b717d8":"from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\n\ndef lr_schedule(epoch):\n    return lr * (0.1 ** int(epoch \/ 10))\n\nbatch_size = 32\nepochs = 30\n\nnetwork.fit(X, Y,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.2,\n          callbacks=[LearningRateScheduler(lr_schedule),\n                     ModelCheckpoint('model_cnn.h5', save_best_only=True)]\n          )","98425b65":"network.summary()","54ad6c27":"from keras.preprocessing.image import ImageDataGenerator\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y,\n                                                  test_size=0.2, random_state=42)\n\ndatagen = ImageDataGenerator(featurewise_center=False,\n                             featurewise_std_normalization=False,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             zoom_range=0.2,\n                             shear_range=0.1,\n                             rotation_range=10.)\n\ndatagen.fit(X_train)\n\n# Reinitialize model and compile\nnetwork = cnn_model()\nnetwork.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n\n# Train again\nepochs = 5\nnetwork.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n                    steps_per_epoch=X_train.shape[0],\n                    epochs=epochs,\n                    validation_data=(X_val, Y_val),\n                    callbacks=[LearningRateScheduler(lr_schedule),\n                               ModelCheckpoint('model_T_A.h5', save_best_only=True)]\n                    )","328df982":"network.summary()","9b8e5f9a":"\nfrom keras.models import load_model\nmodel_cnn = load_model('model_cnn.h5')\n\ndef get_name(img_path):\n    return img_path.split('\/')[-1]\n\nimport csv\nwith open('submission.csv', mode='w') as f:\n    rowname = ['Filename', 'ClassId']\n    writer = csv.DictWriter(f, fieldnames=rowname)\n    writer.writeheader()\n\n    root_dir = '..\/input\/gtsrb_challenge\/GTSRB_Challenge'\n    all_img_paths = glob.glob(os.path.join(root_dir, '*\/*.ppm'))\n    np.random.shuffle(all_img_paths)\n    for img_path in all_img_paths:\n        img = preprocessing(io.imread(img_path))\n        name = get_name(img_path)\n        y_pred = model_cnn.predict_classes(img.reshape(1,48,48,3))\n        writer.writerow({'Filename': name, 'ClassId': int(y_pred)})\n        #print(name + str(y_pred))","d32cb8f3":"from keras.models import load_model\nmodel_T_A = load_model('model_T_A.h5')\n\ndef get_name(img_path):\n    return img_path.split('\/')[-1]\n\nimport csv\nwith open('submission1.csv', mode='w') as f:\n    rowname = ['Filename', 'ClassId']\n    writer = csv.DictWriter(f, fieldnames=rowname)\n    writer.writeheader()\n\n    root_dir = '..\/input\/gtsrb_challenge\/GTSRB_Challenge'\n    all_img_paths = glob.glob(os.path.join(root_dir, '*\/*.ppm'))\n    np.random.shuffle(all_img_paths)\n    for img_path in all_img_paths:\n        img = preprocessing(io.imread(img_path))\n        name = get_name(img_path)\n        y_pred = model_T_A.predict_classes(img.reshape(1,48,48,3))\n        writer.writerow({'Filename': name, 'ClassId': int(y_pred)})\n        #print(name + str(y_pred))","710633f5":"fig=plt.figure(figsize=(20, 20))\ncolumns = 9\nrows = 9\nroot_dir = '..\/input\/gtsrb_challenge\/GTSRB_Challenge'\nall_img_paths = glob.glob(os.path.join(root_dir, '*\/*.ppm'))\nfor i in range(1, columns*rows +1):\n    k = np.random.randint(0,len(all_img_paths))\n    fig.add_subplot(rows, columns, i)\n    image = io.imread(all_img_paths[k])\n    image = preprocessing(image)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    y_pred_v = model_cnn.predict_classes(image.reshape(1,48,48,3))\n    plt.title(int(y_pred_v))\nplt.show()","350cdfde":"7.2 : Prediction Of Transfer learning + Agumentation","fc06dce3":"**4.Compilation Step**","6dc5c434":"> **6. Data Agumentation + Transfer Learing**","11569c64":"**7. Predict**","3d5809bf":"7.1 : Prediction Of Normal CNN","d8c6a78a":"**5. Traning**","45b0c199":"**8. Visualize Samples Predict**","3b17eb7f":"**3.Architect**","1f708341":"**1. Import lib**","f54287fc":"**2.EDA**"}}