{"cell_type":{"395bffc9":"code","135abe34":"code","b54edf5e":"code","dd233536":"code","b31635fd":"code","ad439fd6":"code","848b2a19":"code","d660c021":"code","9bd7c50b":"code","df85a65a":"code","b2ab2858":"code","5b867004":"code","0719e661":"code","01c22ddc":"code","2c927f2d":"code","59ea77e0":"code","e196cd60":"code","4217f09d":"code","d238964b":"code","d5c12fe9":"code","566391ed":"code","71c9caee":"code","22c39a49":"code","0dced5af":"code","5e7a71eb":"code","70ef87c0":"code","83d52eb6":"code","ff33111a":"code","aef2503f":"code","b14ff2c5":"code","9cd444fa":"code","82b07cb0":"markdown","abcd6e47":"markdown","45900f75":"markdown","63104742":"markdown","e4ac086c":"markdown","19a355a0":"markdown","3be7d0ac":"markdown","3f7f3a2b":"markdown"},"source":{"395bffc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","135abe34":"#Libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestClassifier","b54edf5e":"df = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","dd233536":"df.head()","b31635fd":"df.shape","ad439fd6":"df.info()","848b2a19":"df.describe([0, 0.05,0.25, 0.50, 0.75,0.95, 0.99, 1]).T","d660c021":"#Average of numerical variables relative to the target variable\n\ndf.groupby(\"Outcome\").agg(\"mean\")","9bd7c50b":"# Outlier observation analysis\n\n#Threshold determination\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\nlow, up = outlier_thresholds(df, \"Pregnancies\")\n","df85a65a":"#We checked for outliers\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n    \ncheck_outlier(df,\"Pregnancies\")\ncheck_outlier(df,\"BloodPressure\")\ncheck_outlier(df,\"SkinThickness\")\ncheck_outlier(df,\"Insulin\")\ncheck_outlier(df,\"BMI\")\ncheck_outlier(df,\"DiabetesPedigreeFunction\")\ncheck_outlier(df,\"Age\")","b2ab2858":"#Multivariate Outlier Analysis: Local Outlier Factor\nclf = LocalOutlierFactor(n_neighbors=20)\nclf.fit_predict(df)\n\ndf_scores = clf.negative_outlier_factor_\nnp.sort(df_scores)[0:5]\n\nscores = pd.DataFrame(np.sort(df_scores))\nscores.plot(stacked=True, xlim=[0, 50], style='.-')\nplt.show()\n\nth = np.sort(df_scores)[10]\ndf[df_scores < th]\ndf[df_scores < th].shape\n","5b867004":"#Missing observation analysis\ndf.isnull().sum()","0719e661":"#We replaced the zero values in the variables other than \"Pregnancies\" and \"Outcome\" with \"NAN\".\nzero_columns = [i for i in df.columns if (df[i].min() == 0 and i not in [\"Pregnancies\", \"Outcome\"])]\n\nfor i in zero_columns:\n    df[[i]] = df[[i]].replace(0, np.NaN)","01c22ddc":"#We checked how many missing values.\ndf.isnull().sum()","2c927f2d":"#Solving missing value problem with KNN\n\nscaler = MinMaxScaler()\ndf = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\ndf.head()","59ea77e0":"imputer = KNNImputer(n_neighbors=5)\ndf = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\ndf = pd.DataFrame(scaler.inverse_transform(df), columns=df.columns)\ndf.head()","e196cd60":"#We checked again to see if there are any missing observations\n\ndf.isnull().sum()","4217f09d":"#Solving the outlier problem: Re-assignment with thresholds\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nreplace_with_thresholds(df,\"Pregnancies\")\nreplace_with_thresholds(df,\"BloodPressure\")\nreplace_with_thresholds(df,\"SkinThickness\")\nreplace_with_thresholds(df,\"Insulin\")\nreplace_with_thresholds(df,\"BMI\")\nreplace_with_thresholds(df,\"DiabetesPedigreeFunction\")\nreplace_with_thresholds(df,\"Age\")","d238964b":"#We checked again for outliers\n\ncheck_outlier(df,\"Pregnancies\")\ncheck_outlier(df,\"BloodPressure\")\ncheck_outlier(df,\"SkinThickness\")\ncheck_outlier(df,\"Insulin\")\ncheck_outlier(df,\"BMI\")\ncheck_outlier(df,\"DiabetesPedigreeFunction\")\ncheck_outlier(df,\"Age\")","d5c12fe9":"#Correlation analysis\ndf.corrwith(df[\"Outcome\"]).sort_values(ascending=False)\ncorr_df = df.corr()\n\nsns.heatmap(corr_df, annot=True, xticklabels=corr_df.columns, yticklabels=corr_df.columns)\nplt.show()","566391ed":"df[\"Age-Insul\"] = df[\"Age\"] * df[\"Insulin\"]\ndf[\"Age-BMI\"] = df[\"Age\"] * df[\"BMI\"]\ndf[\"Preg-Insul\"] = df[\"Pregnancies\"] * df[\"Insulin\"]\ndf[\"Gluc-Insul\"] = df[\"Glucose\"] * df[\"Insulin\"]\ndf[\"SkinT-Age\"] = df[\"SkinThickness\"] * df[\"Age\"]\ndf[\"Preg-SkinT\"] = df[\"SkinThickness\"] * df[\"Pregnancies\"]","71c9caee":"#Classification of blood pressure variable\n\ndef new_insulin(row):\n    if row[\"BloodPressure\"]>80:\n        return \"Hipertansiyon\"\n    elif row[\"BloodPressure\"]<60:\n        return \"Hipotansiyon\"\n    else:\n        return \"Normal\"\n\ndf = df.assign(NewInsulin=df.apply(new_insulin, axis=1))","22c39a49":"#Classifying the age variable\n\ndef new_age(row):\n    if row[\"Age\"]>40:\n        return \"Olgunya\u015f\"\n    elif row[\"Age\"]<=40 and row[\"Age\"]>30:\n        return \"Ortaya\u015f\"\n    elif row[\"Age\"]<=30 and row[\"Age\"]>=25:\n        return \"Gen\u00e7ya\u015f\"\n    else:\n        return \"Ergen\"\n\ndf = df.assign(NewAge=df.apply(new_age, axis=1))\n","0dced5af":"#Classifying the BMI variable\n\ndef new_bm\u0131(row):\n    if row[\"BMI\"]>40:\n        return \"Morbidobez\"\n    elif row[\"BMI\"]<=40 and row[\"BMI\"]>35:\n        return \"Tip2obez\"\n    elif row[\"BMI\"]<=35 and row[\"BMI\"]>30:\n        return \"Tip1obez\"\n    elif row[\"BMI\"]<=30 and row[\"BMI\"]>25:\n        return \"Fazlakilolu\"\n    else:\n        return \"Normal\"\n\ndf = df.assign(NewBMI=df.apply(new_bm\u0131, axis=1))","5e7a71eb":"#Classifying the glucose variable\n\ndef new_glucose(row):\n    if row[\"Glucose\"] <70:\n        return \"D\u00fc\u015f\u00fck\"\n    elif row[\"Glucose\"] <100 and row[\"Glucose\"] >= 70:\n        return \"Normal\"\n    elif row[\"Glucose\"] < 125 and row[\"Glucose\"] >=100:\n        return \"Potansiyel\"\n    else:\n        return \"Y\u00fcksek\"\n\ndf = df.assign(NewGlucose=df.apply(new_glucose, axis=1))","70ef87c0":"df.head()","83d52eb6":"#By converting categorical variables to 1-0, we have expressed it in a language that the machine learning algorithm can understand.\n#One-Hot Encoding\ndf = pd.get_dummies(df, columns=[\"NewGlucose\"], drop_first=True)\ndf = pd.get_dummies(df, columns=[\"NewBMI\"], drop_first=True)\ndf = pd.get_dummies(df, columns=[\"NewAge\"], drop_first=True)\ndf = pd.get_dummies(df, columns=[\"NewInsulin\"], drop_first=True)","ff33111a":"#Identifying dependent and independent variables\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)","aef2503f":"#Testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)","b14ff2c5":"#Model-1\nrf_model = DecisionTreeRegressor(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)","9cd444fa":"#Model-2\nrf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)","82b07cb0":"There are no missing observations in the data. But some variables have a minimum value of zero.\nFor example, a person's skin thickness cannot be zero..\nWe should also take the zero values as missing observations.","abcd6e47":"# Model creation","45900f75":"We converted some numeric variables to categorical variables.","63104742":"# Dataset analysis","e4ac086c":"# Conclusion","19a355a0":"Generating new variables according to the Corr relationship","3be7d0ac":"DecisionTreeRegressor - 0.75\n\nRandomForestClassifier- 0.78\n\nRandom Forest Classifier has higher prediction success, so this can be preferred.","3f7f3a2b":"# Feature Engineering"}}