{"cell_type":{"795ed6cd":"code","54196f25":"code","b1cb752f":"code","ae0113b1":"code","a9892519":"code","73a101f3":"code","738f88a8":"code","f66f1348":"code","24115a99":"code","3288bd43":"code","43df1318":"code","62f025c2":"code","4a904f0c":"code","37b943d5":"code","e0b102a8":"code","8ad2871e":"code","30ec80a9":"code","f15fef5d":"code","c8672b68":"code","a73b5b9f":"markdown","d5b4e35b":"markdown","d28dbd26":"markdown","211c1e75":"markdown","926fd911":"markdown","0eb3d244":"markdown","7c123a1e":"markdown","3e9edb50":"markdown","afb90ceb":"markdown","d138c39c":"markdown","92726b78":"markdown"},"source":{"795ed6cd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nfrom datetime import datetime\nimport time\nimport matplotlib.pyplot as plt\n#from pycocotools.coco import COCO\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nfrom pathlib import Path\nfrom typing import Optional\nfrom PIL import Image\nfrom PIL import Image, ImageDraw, ImageFont\n\n# torch\nimport torch\n\n# Albumenatations\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#from pycocotools.coco import COCO\nfrom sklearn.model_selection import StratifiedKFold\n\n# glob\nfrom glob import glob\n\n# numba\nimport numba\nfrom numba import jit\n\nimport warnings\nwarnings.filterwarnings('ignore') #Ignore \"future\" warnings and Data-Frame-Slicing warnings.","54196f25":"image = Image.open(\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Training\/20-11-2017 - THE INDIAN EXPRESS - SHASHI THAKUR.pdf_page1.png\")\nimage = image.convert(\"RGB\")\nnew_image = image.resize((300, 600))\nnew_image","b1cb752f":"path_train_json=\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Training\/article_segmentation_train.json\"\npath_valid_json=\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Validation\/article_segmentation_train.json\"\n\n\npath_train=\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Training\/\"\npath_valid=\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Validation\/\"\n","ae0113b1":"f = open(path_train_json)\ndata = json.load(f)\nthing_classes  = []\n#thing_classes_id = {}\nfor i in data['_via_attributes'][\"region\"][\"page_part\"][\"options\"]:\n    thing_classes.append(i)\n\nthing_classes_id = {thing_classes: index for index, thing_classes in enumerate(thing_classes)}\n\nprint(thing_classes)\nprint(thing_classes_id)","a9892519":"data_annotations=[]\ndata_images=[]\nfor i in data[\"_via_img_metadata\"]:\n    name=i # Name\n    image_id=data[\"_via_img_metadata\"][i][\"filename\"]\n    image_path = str(f'{path_train}{image_id}')\n    image = cv2.imread(image_path)\n    image_height, image_width, ch = image.shape\n    img_obj ={\"name\": i,\"image_id\": image_id,\"width\":image_width,\"height\":image_height}\n    data_images.append(img_obj)\n    for j in data[\"_via_img_metadata\"][i][\"regions\"]:\n        category_id=j[\"region_attributes\"][\"page_part\"]\n        if j[\"shape_attributes\"][\"name\"]==\"rect\" :\n            x_min=j[\"shape_attributes\"][\"x\"]\n            y_min=j[\"shape_attributes\"][\"y\"]\n            x_max=j[\"shape_attributes\"][\"x\"]+j[\"shape_attributes\"][\"width\"]\n            y_max=j[\"shape_attributes\"][\"y\"]+j[\"shape_attributes\"][\"height\"]\n            annot_obj ={\"name\": i,\"image_id\": image_id,\"category_id\":category_id,\n              \"x_min\":x_min, #left\n              \"y_min\":y_min, #top\n              \"x_max\":x_max, #left+width\n              \"y_max\":y_max #top+hieght\n             }\n        data_annotations.append(annot_obj)","73a101f3":"train_df = pd.DataFrame(data_annotations)\ntrain_meta  = pd.DataFrame(data_images)\nprint(\"train_meta size=\",len(train_meta),\"train_df size=\",len(train_df))\ndisplay(train_meta.head(5))\ndisplay(train_df.head(5))\n#train_meta.style.set_properties(subset=['name'],**{'width': '450px'})","738f88a8":"train_df_selected=train_df[train_df.image_id==\"20-11-2017 - THE INDIAN EXPRESS - SHASHI THAKUR.pdf_page1.png\"]\ntrain_df_selected","f66f1348":"Color_labeled = {\"header\": \"Red\",\"article\": \"Green\",\"ad\": \"Blue\"}\n\ndef Draw_BBox(image_path,_bbox_labeled: pd.DataFrame):\n    actual_boxes = []\n    for idx, row in _bbox_labeled.iterrows():\n        x0 = row['x_min']\n        y0 = row['y_min']\n        x1 = row['x_max']\n        y1 = row['y_max']\n        label= row['category_id']\n        color=Color_labeled[label]\n        actual_box = [x0, y0, x1, y1] # we turn it into (left, top, left+width, top+height) to get the actual box \n        draw = ImageDraw.Draw(image, \"RGB\")\n        draw.rectangle(actual_box, outline=color,width=20)\n        new_image = image.resize((400, 700))\n    return new_image","24115a99":"print(\"header-->Red\",\"article-->Green\",\"ad-->Blue\")\nimage = Image.open(\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Training\/20-11-2017 - THE INDIAN EXPRESS - SHASHI THAKUR.pdf_page1.png\")\nDraw_BBox(image,train_df_selected)","3288bd43":"import shutil\nimport os\nimport subprocess\nfrom pdf2image import convert_from_path\nfrom PIL import Image\nimport pytesseract\n\nsrc = '..\/input\/papers-images\/ara.traineddata'\ndest = '\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/'\nshutil.copy(src, dest)\n\n\nsrc = '..\/input\/papers-images\/deu.traineddata'\ndest = '\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/'\nshutil.copy(src, dest)\n\nsrc = '..\/input\/papers-images\/fra.traineddata'\ndest = '\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/'\nshutil.copy(src, dest)\n\nfilenames = os.listdir('\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/')\nprint(filenames) # check that the file is added in this directory which was not present before.","43df1318":"def ocr_extract(image):\n    width, height = image.size\n    w_scale = 1000\/width\n    h_scale = 1000\/height\n\n    ocr_df = pytesseract.image_to_data(image, output_type='data.frame', lang='ara+eng+fra+deu') \\\n    #text3 = pytesseract.image_to_string(image, lang='ara+eng' )\n\n\n    ocr_df = ocr_df.dropna() \\\n                   .assign(left_scaled = ocr_df.left*w_scale,\n                           width_scaled = ocr_df.width*w_scale,\n                           top_scaled = ocr_df.top*h_scale,\n                           height_scaled = ocr_df.height*h_scale,\n                           right_scaled = lambda x: x.left_scaled + x.width_scaled,\n                           bottom_scaled = lambda x: x.top_scaled + x.height_scaled)\n\n    float_cols = ocr_df.select_dtypes('float').columns\n    ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)\n    return ocr_df\ndef ocr_words_extract(im,bbox,label,image_id):\n    width_img, height_img = im.size\n    w_scale = 1\n    h_scale = 1\n    \n    im = im.crop(bbox)\n    ocr_df = pytesseract.image_to_data(im, output_type='data.frame', lang='ara+eng+fra+deu') \\\n\n    ocr_df = ocr_df.dropna() \n\n    float_cols = ocr_df.select_dtypes('float').columns\n    ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)\n    \n    cols=[\"left\",\"top\",\"width\",\"height\",\"conf\",\"text\"]\n    \n    ocr_df_final=ocr_df[cols]\n    \n    ocr_df_final[\"left\"]=ocr_df_final[\"left\"]+bbox[0]\n    ocr_df_final[\"top\"]=ocr_df_final[\"top\"]+bbox[1]\n    \n    ocr_df_final[\"label\"]=label\n    ocr_df_final[\"image_id\"]=image_id\n    ocr_df_final[\"width_img\"]=width_img\n    ocr_df_final[\"height_img\"]=height_img\n    return ocr_df_final\n\ndef ocr_block_extract(im,bbox):\n    im = im.crop(bbox)\n    text = pytesseract.image_to_string(im, lang='ara+eng+fra+deu' )\n    return text.replace('\\n','')","62f025c2":"train_df_selected=train_df_selected.head(3)","4a904f0c":"df_st_training=[]\nfor index, train_row in tqdm(train_df_selected.iterrows(), total=len(train_df_selected)):\n    n,image_id,category_id, x0,y0,x1,y1 = train_row.values  \n    filename = str(f'{path_train}\/{image_id}')\n    image = Image.open(filename)\n    bbox= [\n            float(x0),\n            float(y0),\n            float(x1),\n            float(y1),\n            ]\n    text= ocr_block_extract(image,bbox)\n    df_st_obj ={\"image_id\": image_id,\"label\":category_id,\"text\": text,\n              \"x0\":x0, #left\n              \"y0\":y0, #top\n              \"x1\":x1, #left+width\n              \"y1\":y1 #top+hieght\n             }\n    df_st_training.append(df_st_obj)\n    \ndf_st_training = pd.DataFrame(df_st_training)\ndf_st_training.style.set_properties(subset=['text'],**{'width': '450px'})","37b943d5":"train_df.shape","e0b102a8":"train_df_s=train_df.tail(3000)\ntrain_df_s.shape","8ad2871e":"total_block_error=0\n\ncols=[\"left\",\"top\",\"width\",\"height\",\"conf\",\"text\",\"label\",\"image_id\",\"width_img\",\"height_img\"]\ndf_data = pd.DataFrame(columns=cols)\n\nfor index, train_row in tqdm(train_df_s.iterrows(), total=len(train_df_s)):\n    n,image_id,category_id, x0,y0,x1,y1 = train_row.values\n    filename = str(f'{path_train}\/{image_id}')\n    image = Image.open(filename)\n    bbox= [\n            float(x0),\n            float(y0),\n            float(x1),\n            float(y1),\n            ]\n    try:\n        df_ocr=ocr_words_extract(image,bbox,category_id,image_id)\n    except:\n        total_block_error=total_block_error+1\n\n    df_data = pd.concat([df_data, df_ocr])\n   \nprint(\"total_block=\",index+1,\"total_block_error=\",total_block_error)    ","30ec80a9":"df_data.to_csv('df_train2.csv', index = False, encoding='utf-8-sig')\ndf_data.head(3)","f15fef5d":"#df_data[df_data.image_id][0]","c8672b68":"Color_labeled = {\"header\": \"Red\",\"article\": \"Green\",\"ad\": \"Yellow\"}\ndf_data=df_data[df_data.text.apply(lambda x: len(str(x))>1)]\ndef Draw_BBox(image_path,_bbox_labeled: pd.DataFrame):\n    actual_boxes = []\n    for idx, row in _bbox_labeled.iterrows():\n        x0 = row[\"left\"]\n        y0 = row[\"top\"]\n        x1 = row[\"width\"]+row[\"left\"]\n        y1 = row[\"height\"]+row[\"top\"]\n        label= row['label']\n        color=Color_labeled[label]\n        actual_box = [x0, y0, x1, y1] # we turn it into (left, top, left+width, top+height) to get the actual box \n        draw = ImageDraw.Draw(image, \"RGB\")\n        draw.rectangle(actual_box, outline=color,width=3)\n        new_image = image.resize((1000, 1000))\n    return image\n\nsample_filename=\"20-11-2017 - THE INDIAN EXPRESS - SHASHI THAKUR.pdf_page20.png\"\n\nfrom PIL import Image, ImageDraw, ImageFont\nimage = Image.open(f\"..\/input\/segmented-articles\/Segmented_articles\/Segmented_articles\/Training\/{sample_filename}\")\nimage = image.convert(\"RGB\")\nsample_image_df = df_data[df_data['image_id'] == sample_filename]\n#image\nsample_image_df=sample_image_df.head(100)\nDraw_BBox(image,sample_image_df)","a73b5b9f":"https:\/\/www.programcreek.com\/python\/example\/104330\/pytesseract.image_to_string","d5b4e35b":"# Blocks","d28dbd26":"# Words","211c1e75":"# show Bounding box","926fd911":"# Functions","0eb3d244":"## Arabic Text","7c123a1e":"# OCR","3e9edb50":"image = Image.open(\"..\/input\/segmented-articles\/Segmented_articles\/Training\/Der_Tagesspiegel_-_29_06_2019.pdfpage 20.png\")\nnew_image = image.resize((600, 800))\nnew_image\nocr_df=ocr_extract(image)\nprint(ocr_df.shape)\nocr_df.sample(5)","afb90ceb":"## German Text","d138c39c":"# **1-Newspaper Segmentation (Data Preparation)**","92726b78":"image = Image.open(\"..\/input\/segmented-articles\/Segmented_articles\/Validation\/alqabas 28-7.pdf page 24.png\")\nnew_image = image.resize((600, 800))\nnew_image\nocr_df=ocr_extract(image)\nprint(ocr_df.shape)\nocr_df.head(5)"}}