{"cell_type":{"e1d310f7":"code","d3d3fdbf":"code","1a421c50":"code","19e8f18f":"code","938af534":"code","6bc2ec75":"code","2cafccb8":"code","d7e35e6e":"code","669d24d0":"code","9f368675":"code","d325d789":"code","2bee9faa":"code","8d137d3d":"code","3cc96867":"code","abac4fab":"code","851181fd":"code","37bbc39c":"code","acaf3785":"code","62e6ac45":"code","9e8ad989":"code","1062bf88":"code","f0dff169":"code","3f17828c":"code","abd3fdf2":"code","72fad46a":"code","fcafe66f":"code","228ac105":"code","d39bb502":"code","e6eef0eb":"code","2a10b731":"code","a5b3f2b1":"code","29cd2b8a":"code","b98867b5":"code","9d27d936":"code","a7b4791f":"code","0c5e5a4a":"code","a19a1ab0":"code","a3c2077d":"code","e269b6ef":"code","1dc22359":"code","c6fbd68d":"code","3589fc57":"code","9fcf9c54":"code","f3a0c2f6":"code","487c51b1":"code","cf6cfd03":"code","b602dc7a":"code","108c8c80":"code","d83a30de":"code","3b9e424a":"code","8758cc5c":"code","bcb57f4f":"code","2be6af91":"code","8863edcb":"code","29e1dcc5":"code","cc5b79af":"code","f5a50f9e":"markdown","f6e11fba":"markdown"},"source":{"e1d310f7":"!pip install git+https:\/\/github.com\/tensorflow\/examples.git","d3d3fdbf":"# GENERAL\n\nimport os\nimport os.path\nfrom pathlib import Path\nimport time\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport math\nimport glob\nimport cv2\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n\n# I PACKAGES\n\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\n# WARNINGS\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\n\n\nAUTOTUNE = tf.data.AUTOTUNE","1a421c50":"BAROQUE_PATH = Path(\"..\/input\/architecture-dataset\/arcDataset\/Baroque architecture\")\nGOTHIC_PATH = Path(\"..\/input\/architecture-dataset\/arcDataset\/Gothic architecture\")","19e8f18f":"B_JPG_LIST = list(BAROQUE_PATH.glob(r\"*.JPG\"))\n\nADD_JPG_LIST = list(BAROQUE_PATH.glob(r\"*.jpg\"))\n\nfor x_add_jpg in ADD_JPG_LIST:\n    \n    B_JPG_LIST.append(x_add_jpg)","938af534":"print(len(B_JPG_LIST))","6bc2ec75":"G_JPG_LIST = list(GOTHIC_PATH.glob(r\"*.jpg\"))","2cafccb8":"print(len(G_JPG_LIST))","d7e35e6e":"B_JPG_LIST = B_JPG_LIST[:108]","669d24d0":"print(len(B_JPG_LIST))","9f368675":"print(len(B_JPG_LIST) == len(G_JPG_LIST))","d325d789":"Bar_SERIES = pd.Series(B_JPG_LIST,name=\"BAROQUE\").astype(str)\nGot_SERIES = pd.Series(G_JPG_LIST,name=\"GOTHIC\").astype(str)\n\nCOM_DATA = pd.concat([Bar_SERIES,Got_SERIES],axis=1)","2bee9faa":"COM_DATA","8d137d3d":"figure,axis = plt.subplots(3,3,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = cv2.cvtColor(cv2.imread(COM_DATA[\"BAROQUE\"][x_number]),cv2.COLOR_BGR2RGB)\n    \n    x_operators.set_title(\"BAROQUE\")\n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()","3cc96867":"figure,axis = plt.subplots(3,3,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = cv2.cvtColor(cv2.imread(COM_DATA[\"GOTHIC\"][x_number]),cv2.COLOR_BGR2RGB)\n    \n    x_operators.set_title(\"GOTHIC\")\n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()","abac4fab":"BAROQUE_IMG = []\nGOTHIC_IMG = []\n\nfor x_bar,x_got in zip(COM_DATA.BAROQUE,COM_DATA.GOTHIC):\n    \n    BAR_READING = cv2.cvtColor(cv2.imread(x_bar),cv2.COLOR_BGR2RGB)\n    GOT_READING = cv2.cvtColor(cv2.imread(x_got),cv2.COLOR_BGR2RGB)\n    \n    BAR_READING = cv2.resize(BAR_READING,(256,256))\n    GOT_READING = cv2.resize(GOT_READING,(256,256))\n    \n    BAR_READING = (BAR_READING \/ 127.5) - 1\n    GOT_READING = (GOT_READING \/ 127.5) - 1\n    \n    BAROQUE_IMG.append(BAR_READING)\n    GOTHIC_IMG.append(GOT_READING)\n","851181fd":"print(np.shape(np.array(BAROQUE_IMG)))\nprint(np.shape(np.array(GOTHIC_IMG)))","37bbc39c":"figure,axis = plt.subplots(3,3,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = BAROQUE_IMG[x_number]\n    \n    x_operators.set_title(\"BAROQUE\")\n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()","acaf3785":"figure,axis = plt.subplots(3,3,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = GOTHIC_IMG[x_number]\n    \n    x_operators.set_title(\"GOTHIC\")\n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()","62e6ac45":"ARRAY_BAR = np.array(BAROQUE_IMG,dtype=\"float32\")\nARRAY_GOT = np.array(GOTHIC_IMG,dtype=\"float32\")","9e8ad989":"print(ARRAY_BAR.shape)\nprint(ARRAY_GOT.shape)","1062bf88":"BUFFER_SIZE = 1000\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nOUTPUT_CHANNELS = 3\nLAMBDA = 5\nEPOCHS = 30","f0dff169":"SLICE_BAR = tf.data.Dataset.from_tensor_slices(ARRAY_BAR).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nSLICE_GOT = tf.data.Dataset.from_tensor_slices(ARRAY_GOT).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","3f17828c":"print(SLICE_BAR.element_spec)\nprint(SLICE_GOT.element_spec)","abd3fdf2":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","72fad46a":"def random_crop(IMG):\n    \n    CROPPED_IMG = tf.image.random_crop(IMG,size=[IMG_WIDTH,IMG_HEIGHT,3])\n    \n    return CROPPED_IMG","fcafe66f":"def normalize(IMG):\n    \n    NORM_IMG = tf.cast(IMG,tf.float32)\n    \n    return NORM_IMG","228ac105":"def random_jitter(IMG):\n    \n    RE_IMG = tf.image.resize(IMG,[256,256],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    \n    RE_IMG = random_crop(RE_IMG)\n    \n    RE_IMG = tf.image.random_flip_left_right(RE_IMG)\n    \n    return RE_IMG","d39bb502":"def preprocess_image_test(IMG):\n    \n    NORM_IMG = normalize(IMG)\n    \n    return NORM_IMG","e6eef0eb":"BAROQUE_IMG_PREP = SLICE_BAR.map(preprocess_image_test,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nGOTHIC_IMG_PREP = SLICE_GOT.map(preprocess_image_test,num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","2a10b731":"print(type(BAROQUE_IMG_PREP))\nprint(type(GOTHIC_IMG_PREP))","a5b3f2b1":"SAMPLE_BAR_EX = next(iter(BAROQUE_IMG_PREP))\nSAMPLE_GOT_EX = next(iter(GOTHIC_IMG_PREP))","29cd2b8a":"print(type(SAMPLE_BAR_EX))\nprint(type(SAMPLE_GOT_EX))","b98867b5":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL BAROQUE SAMPLE\")\naxis[0].imshow(SAMPLE_BAR_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"JITTERING BAROQUE SAMPLE\")\naxis[1].imshow(random_jitter(SAMPLE_BAR_EX[0][0]) * 0.5 + 0.5)\n\n\nplt.tight_layout()\nplt.show()","9d27d936":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL GOTHIC SAMPLE\")\naxis[0].imshow(SAMPLE_GOT_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"JITTERING GOTHIC SAMPLE\")\naxis[1].imshow(random_jitter(SAMPLE_GOT_EX[0][0]) * 0.5 + 0.5)\n\n\nplt.tight_layout()\nplt.show()","a7b4791f":"generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS,norm_type=\"instancenorm\")\ngenerator_f = pix2pix.unet_generator(OUTPUT_CHANNELS,norm_type=\"instancenorm\")\n\ndiscriminator_x = pix2pix.discriminator(norm_type=\"instancenorm\",target=False)\ndiscriminator_y = pix2pix.discriminator(norm_type=\"instancenorm\",target=False)","0c5e5a4a":"BAR_RES_EXP = generator_g(SAMPLE_BAR_EX[0])\nGOT_RES_EXP = generator_f(SAMPLE_GOT_EX[0])","a19a1ab0":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL BAROQUE SAMPLE\")\naxis[0].imshow(SAMPLE_BAR_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"FINE RESULT\")\naxis[1].imshow(BAR_RES_EXP[0] * 0.5 * 8 + 0.5)\n\n\nplt.tight_layout()\nplt.show()","a3c2077d":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL GOTHIC SAMPLE\")\naxis[0].imshow(SAMPLE_GOT_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"FINE RESULT\")\naxis[1].imshow(GOT_RES_EXP[0] * 0.5 * 8 + 0.5)\n\n\nplt.tight_layout()\nplt.show()","e269b6ef":"BAR_RES_DIS = discriminator_x(SAMPLE_BAR_EX[0])\nGOT_RES_DIS = discriminator_y(SAMPLE_GOT_EX[0])","1dc22359":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL BAROQUE SAMPLE\")\naxis[0].imshow(SAMPLE_BAR_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"DISCRIMINATOR RESULT\")\naxis[1].imshow(BAR_RES_DIS[0],cmap=\"gist_ncar\")\n\n\nplt.tight_layout()\nplt.show()","c6fbd68d":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\naxis[0].set_title(\"ORIGINAL GOTHIC SAMPLE\")\naxis[0].imshow(SAMPLE_GOT_EX[0][0] * 0.5 + 0.5)\n\naxis[1].set_title(\"DISCRIMINATOR RESULT\")\naxis[1].imshow(GOT_RES_DIS[0],cmap=\"gist_ncar\")\n\n\nplt.tight_layout()\nplt.show()","3589fc57":"def Discriminator_Loss(real,generated):\n    \n    Real_Loss = Loss_Function(tf.ones_like(real),real)\n    Generator_Loss = Loss_Function(tf.zeros_like(generated),generated)\n    \n    Total_Loss = Real_Loss + Generator_Loss\n    \n    return Total_Loss * 0.5","9fcf9c54":"def Generator_Loss(generated):\n    \n    return Loss_Function(tf.ones_like(generated),generated)","f3a0c2f6":"def Cycle_Reduce_Mean(real_IMG,cycled_IMG):\n    \n    Loss_Tar_1 = tf.reduce_mean(tf.abs(real_IMG-cycled_IMG))\n    \n    return LAMBDA * Loss_Tar_1","487c51b1":"def Identy_Loss(real_IMG,same_out):\n    \n    Loss_Tar_2 = tf.reduce_mean(tf.abs(real_IMG-same_out))\n    \n    return LAMBDA * 0.5 * Loss_Tar_2","cf6cfd03":"Generator_G_Optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nGenerator_F_Optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\nDiscriminator_X_Optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nDiscriminator_Y_Optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","b602dc7a":"def generate_images(model, test_input):\n    \n    prediction = model(test_input)\n\n        \n    plt.figure(figsize=(12, 12))\n    plt.imshow(prediction[0] * 0.5 + 0.5)\n    plt.savefig('output_{:04d}.png'.format(epoch))\n    plt.axis('off')\n    plt.show()","108c8c80":"@tf.function\ndef Train_Step(real_IMG_x,real_IMG_y):\n    \n    with tf.GradientTape(persistent=True) as T_Gra:\n        \n        fake_y = generator_g(real_IMG_x,training=True)\n        cycled_x = generator_f(real_IMG_y,training=True)\n        \n        fake_x = generator_f(real_IMG_y,training=True)\n        cycled_y = generator_g(real_IMG_x,training=True)\n        \n        same_x = generator_f(real_IMG_x,training=True)\n        same_y = generator_g(real_IMG_y,training=True)\n        \n        disc_real_x = discriminator_x(real_IMG_x,training=True)\n        disc_real_y = discriminator_y(real_IMG_y,training=True)\n        \n        disc_fake_x = discriminator_x(fake_x,training=True)\n        disc_fake_y = discriminator_y(fake_y,training=True)\n        \n        \n        gen_g_loss = Generator_Loss(disc_fake_y)\n        gen_f_loss = Generator_Loss(disc_fake_x)\n        \n        total_cycle_loss = Cycle_Reduce_Mean(real_IMG_x, cycled_x) + Cycle_Reduce_Mean(real_IMG_y, cycled_y)\n        total_gen_g_loss = gen_g_loss + total_cycle_loss + Identy_Loss(real_IMG_y, same_y)\n        total_gen_f_loss = gen_f_loss + total_cycle_loss + Identy_Loss(real_IMG_x, same_x)\n        \n        disc_x_loss = Discriminator_Loss(disc_real_x, disc_fake_x)\n        disc_y_loss = Discriminator_Loss(disc_real_y, disc_fake_y)\n        \n        generator_g_gradients = T_Gra.gradient(total_gen_g_loss, \n                                        generator_g.trainable_variables)\n        generator_f_gradients = T_Gra.gradient(total_gen_f_loss, \n                                        generator_f.trainable_variables)\n        \n        \n        discriminator_x_gradients = T_Gra.gradient(disc_x_loss, \n                                            discriminator_x.trainable_variables)\n        discriminator_y_gradients = T_Gra.gradient(disc_y_loss, \n                                            discriminator_y.trainable_variables)\n        \n        \n        Generator_G_Optimizer.apply_gradients(zip(generator_g_gradients, \n                                            generator_g.trainable_variables))\n\n        Generator_F_Optimizer.apply_gradients(zip(generator_f_gradients, \n                                                generator_f.trainable_variables))\n\n        Discriminator_X_Optimizer.apply_gradients(zip(discriminator_x_gradients,\n                                                    discriminator_x.trainable_variables))\n\n        Discriminator_Y_Optimizer.apply_gradients(zip(discriminator_y_gradients,\n                                                    discriminator_y.trainable_variables))\n","d83a30de":"for epoch in range(EPOCHS):\n    \n    start = time.time()\n\n    n = 0\n    \n    for image_x, image_y in tf.data.Dataset.zip((SLICE_BAR, SLICE_GOT)):\n        \n        Train_Step(image_x, image_y)\n        \n        if n % 10 == 0:\n            \n            print ('.', end='')\n        n += 1\n\n    clear_output(wait=True)\n\n    generate_images(generator_g, SAMPLE_BAR_EX[0])","3b9e424a":"ED_PATH = Path(\"..\/input\/architecture-dataset\/arcDataset\/Edwardian architecture\")\nED_LIST = list(ED_PATH.glob(r\"*.jpg\"))\nprint(len(ED_LIST))","8758cc5c":"ED_SERIES = pd.Series(ED_LIST,name=\"INPUT\").astype(str)","bcb57f4f":"ED_IMG = []\n\n\nfor x_got in COM_DATA.BAROQUE:\n    \n    ED_READING = cv2.cvtColor(cv2.imread(x_got),cv2.COLOR_BGR2RGB)\n    \n    ED_READING = cv2.resize(ED_READING,(256,256))\n    \n    ED_READING = (ED_READING \/ 127.5) - 1\n    \n    ED_IMG.append(ED_READING)\n","2be6af91":"ED_ARRAY = np.array(ED_IMG[:20],dtype=\"float32\")","8863edcb":"ED_SLICE = tf.data.Dataset.from_tensor_slices(ED_ARRAY).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","29e1dcc5":"print(ED_SLICE.element_spec)","cc5b79af":"for input_ed in ED_SLICE.take(5):\n    \n      generate_images(generator_g, input_ed)","f5a50f9e":"# BEFORE TRAINING","f6e11fba":"# TRAINING DATA AND FUNCTIONS"}}