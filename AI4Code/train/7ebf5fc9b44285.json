{"cell_type":{"b3c1481e":"code","122e045d":"code","c3b31727":"code","a524eedb":"code","1c25b81f":"code","8d4458e4":"code","c44945f2":"code","e46b7eda":"markdown"},"source":{"b3c1481e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","122e045d":"import os\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import scale, minmax_scale\nfrom scipy.stats import norm","c3b31727":"random_state = 42\nnp.random.seed(random_state)\ntrain = pd.read_csv('..\/input\/train.csv')[:]\ntest = pd.read_csv('..\/input\/test.csv')[:]\n\nfeatures = [c for c in train.columns if c not in ['id', 'target']]\n\nlen_train = len(train)\ntrain['target'] = 1\ntrain = train.append(test).reset_index(drop = True)\ntrain['target'] = train['target'].fillna(0)","a524eedb":"lgb_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'verbose': 1,\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'feature_fraction': 0.7,\n    'min_data_in_leaf': 200,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 20,\n    'min_hessian': 0.01,\n    'feature_fraction_seed': 2,\n    'bagging_seed': 3,\n    \"seed\": random_state\n}","1c25b81f":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = train[['id', 'target']]\noof['predict'] = 0\nval_aucs = []","8d4458e4":"for fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['target'])):\n    X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n    X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    trn_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    evals_result = {}\n    lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        7500,\n                        valid_sets=[val_data],\n                        early_stopping_rounds=100,\n                        verbose_eval=50,\n                        evals_result=evals_result)\n\n    p_valid = lgb_clf.predict(X_valid[features], num_iteration=lgb_clf.best_iteration)\n\n    oof['predict'][val_idx] = p_valid\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n","c44945f2":"mean_auc = np.mean(val_aucs)\nstd_auc = np.std(val_aucs)\nall_auc = roc_auc_score(oof['target'], oof['predict'])\nprint(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))","e46b7eda":"> TRUST LOCAL CV!"}}