{"cell_type":{"f52b1186":"code","625db187":"code","bdac63e4":"code","7cbb3440":"code","8cd4348b":"code","fcc39fbe":"code","ce8d9ba0":"code","5be1cee0":"code","01f195ad":"code","866c3a63":"code","e30543a6":"code","02738914":"code","9c9edc9a":"code","7025479f":"code","6f0fa1e2":"code","885f65ce":"code","4c11d63f":"markdown","6a5f05a5":"markdown","e33d40b8":"markdown","2dc5350a":"markdown","8b6d7957":"markdown","3ad0851a":"markdown","d34fa5ed":"markdown","f8040db1":"markdown","022a570c":"markdown"},"source":{"f52b1186":"import os\nprint(os.listdir(\"..\/input\/amazon-fine-food-reviews\"))","625db187":"import sqlite3\nimport pandas as pd\ncon = sqlite3.connect('..\/input\/amazon-fine-food-reviews\/database.sqlite')\ndata = pd.read_sql_query(\"\"\"select * from Reviews\"\"\",con)","bdac63e4":"import matplotlib.pyplot as plt\ndata['Score'] = data['Score'].map(lambda x: 0 if x<4 else (1))\ndata = data.drop_duplicates(subset={\"ProductId\",\"UserId\",\"Score\",\"Text\"},keep=\"first\",inplace=False)\nX = data['Summary']\nY = data['Score']\nY.value_counts().plot(kind='bar',colormap='Paired')\nplt.ylabel('Count')\nplt.show()","7cbb3440":"import re\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\n\nX = X.apply( lambda x: x.lower() )\nX = X.apply( lambda x: re.sub( re.compile('<.*?>') , ' ' , x ) )\nX = X.apply( lambda x: re.sub( r'[?|!|\\'|\"|#]' , r'' , x ) )\nX = X.apply( lambda x: re.sub( r'[.|,|)|(|\\|\/]' , r'' , x ) )\nX = X.apply( lambda x: [i for i in x.split() if i not in stop ] )\nX = X.apply( lambda x: Counter(x) )","8cd4348b":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","fcc39fbe":"import operator\ndef most_common_pos(X,epoch):\n    total = {}\n    ini = 0\n    while ini + epoch < len(X):\n        most_common = X_train[ini:ini+epoch].sum().most_common(30)\n        dic = { w:c for w,c in most_common }\n        total = { k: dic.get(k, 0) + total.get(k, 0) for k in set(dic) | set(total) }\n        ini += epoch\n    sorted_total = sorted(total.items(), key=operator.itemgetter(1))\n    sorted_total = sorted_total[::-1]\n    sorted_total = sorted_total[:23]\n    return sorted_total","ce8d9ba0":"X_train_pos = X_train[ Y_train == 1 ]\nmost_common = most_common_pos( X_train_pos , 300 )","5be1cee0":"from wordcloud import WordCloud, STOPWORDS\n\nwordcloud = WordCloud( background_color='white',\n                      max_words=200,\n                      max_font_size=40,\n                      random_state=42).generate(str(X_train_pos))\n\nplt.figure(figsize=(8, 4), dpi=90, facecolor='w', edgecolor='k')\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","01f195ad":"import numpy as np\nvocabulary = {word: index + 1 for index, (word, count) in enumerate(most_common)}\nX_train = X_train.apply(lambda x : np.asarray( [vocabulary.get(word, 0) for word, count in x.items()] ))\nX_test = X_test.apply(lambda x : np.asarray( [vocabulary.get(word, 0) for word, count in x.items()] ))","866c3a63":"from scipy.sparse import csr_matrix\ndef transform(X):\n    rows = []\n    cols = []\n    data = []\n    for row, listy in enumerate(X):\n        for col , numy in enumerate(listy):\n            rows.append(row)\n            cols.append(col)\n            data.append(numy)\n    return csr_matrix((data, (rows, cols)), shape=(len(X), 20 ))","e30543a6":"X_train = transform(X_train)\nX_test = transform(X_test)","02738914":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\nlog_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\nscores = cross_val_score(log_clf, X_train , Y_train , cv=5, verbose=3)","9c9edc9a":"print('Scores for all folds: ', str(np.around( scores , 3)))\nprint('Average Score: ', str(np.around( scores.mean() , 3)))\nprint('Standard deviation of Scores: ', str(np.around( scores.std() , 4)))","7025479f":"from sklearn.model_selection import cross_val_predict\nY_scores = cross_val_predict(log_clf, X_train , Y_train, cv=3, method=\"decision_function\")","6f0fa1e2":"from sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(Y_train, Y_scores)","885f65ce":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n    plt.xlabel(\"Threshold\", fontsize=16)\n    plt.legend(loc=\"lower left\", fontsize=16)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(8, 4), dpi=80, facecolor='w', edgecolor='k')\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","4c11d63f":"In this study, we are training a SGD linear regression classifier on Amazon's fine food review dataset. This dataset consists of ~500,000 reviews. The reviews include product and user information, ratings, and a plain text review. The objective is to predict food rating based on costumers' written review. First, data are fetched.","6a5f05a5":"The following function computes the most frequent vocabularies in the body of positive reviews and determines their frequency in each email. Transformed reviews will be vectors of numbers.","e33d40b8":"Both the training and the test datasets will be transformed.","2dc5350a":"The target attribute, Score, is converted into a binary class. Summary column is selected as the feature variable.","8b6d7957":"The main dataset is split into training and test datasets.","3ad0851a":"The transformed test dataset is now used to make new predictions. Precision, recall, thresholds, and scores will be computed accordingly.","d34fa5ed":"Input vectors are transformed into CSR matrix using Scipy library.","f8040db1":"A logisitc regression classifier is used to train the dataset. The cross-validation method is implemented to evalute the modle performance.","022a570c":"The following functions remove HTML code, upper case letters, digit numbers, and punctuations from the reviews.\n\n"}}