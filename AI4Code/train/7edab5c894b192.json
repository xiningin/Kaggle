{"cell_type":{"9a7c0735":"code","7c72b3b4":"code","df8ce310":"code","24feda31":"code","eb857e31":"code","9f1b9eb0":"code","6668997b":"code","635e6f9c":"code","274cc5bd":"code","1fd9ed85":"code","fe43ff19":"code","6deee52e":"code","85f87001":"code","c3f86d44":"code","3fcef445":"code","96b051a4":"code","2f56a004":"code","a6871d83":"code","813bfbe2":"code","ff7fbf0b":"code","72aa0066":"code","0b9da347":"code","5ed37fbb":"code","a3cb3c2b":"code","88cbc1e8":"code","00831f67":"code","d57dbbc9":"code","939415aa":"code","3315604f":"code","32a3273c":"code","cd7d6077":"code","54729a1e":"code","1e7f3f98":"code","56dcd739":"code","82c31a1e":"code","63788fc3":"code","4189f8a6":"markdown","68c53cc8":"markdown","1855bef1":"markdown","6513ff2b":"markdown","a75af065":"markdown","6aaa81bb":"markdown","c66ddc80":"markdown","d8e248d8":"markdown","263713c8":"markdown","eae41517":"markdown","de4a48ad":"markdown","aad460b0":"markdown","25075f70":"markdown","65c6f1a5":"markdown","c4f6bf0f":"markdown","aa38159f":"markdown","09851438":"markdown"},"source":{"9a7c0735":"import numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport warnings\nwarnings.filterwarnings('ignore')","7c72b3b4":"PATH = '..\/input\/corn-or-maize-leaf-disease-dataset\/data'\nCATEGORIES = os.listdir(PATH)\nNUM_CLASSES = len(CATEGORIES)","df8ce310":"CATEGORIES","24feda31":"SIZE = 100\nBATCH_SIZE = 32\nEPOCHS = 12","eb857e31":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=(SIZE,SIZE),\n    batch_size=BATCH_SIZE,\n    class_names=CATEGORIES,\n    label_mode='categorical',\n)","9f1b9eb0":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(15, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(10):\n        ax = plt.subplot(3, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(CATEGORIES[np.argmax(labels[i])])\n        plt.axis(\"off\")","6668997b":"for i in CATEGORIES:\n    directory = os.path.join(PATH, i)\n    print(\"Images of label \\\"\" + i + \"\\\":\\t\", len(os.listdir(directory)))","635e6f9c":"from tensorflow.keras.applications.resnet import ResNet101\nfrom keras.applications.resnet import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input, Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D, Activation, Dropout, Flatten, Dense, Input","274cc5bd":"# = = = = = ResNet101 CNN Model = = = = =\nbase_model1 = ResNet101(weights='..\/input\/pretrained-models\/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\nbase_model1.trainable = False","1fd9ed85":"# = = = = = Inception = = = = =\n\nbase_model2 = InceptionV3(weights='..\/input\/pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop (1).h5', include_top=False)\nbase_model2.trainable = False","fe43ff19":"# = = = = = VGG16 = = = = =\n\nbase_model3 = VGG16(weights='..\/input\/pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\nbase_model3.trainable = False","6deee52e":"# = = = = = TOP NN Model = = = = =\ndef top_layer(base_model,neurons,act):\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(neurons*3, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons*2, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons*1, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons\/2, activation=act)(x)\n    x = Dropout(0.1)(x)\n\n# = = = = = Coupling = = = = =\n\n    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\n# = = = = = Complete Model = = = = =\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    model.summary()\n    \n    \n    history= model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)\n\n    return  history,model\n","85f87001":"# = = = = = TOP NN Model para Inception= = = = =\nfrom keras import backend\nbackend.set_image_data_format('channels_last')\n\ndef top_layer2(base_model,neurons,act):\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(neurons*3, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons*2, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons*1, activation=act)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(neurons\/4, activation=act)(x)\n    x = Dropout(0.1)(x)\n\n# = = = = = Coupling = = = = =\n\n    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n\n# = = = = = Complete Model = = = = =\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    model.summary()\n    \n    \n    history= model.fit(train_ds, epochs=EPOCHS*2, validation_data=val_ds) #DOBLE DE EPOCHS AL SER MAS RAPIDO\n\n    return  history,model\n","c3f86d44":"#rom keras.utils.vis_utils import plot_model\n#pot_model(model1, show_shapes=True, show_layer_names=True)","3fcef445":"history1,model1=top_layer(base_model1,512,\"relu\")","96b051a4":"score1= model1.evaluate(train_ds, verbose=0)\nval_score1= model1.evaluate(val_ds, verbose=0)\nprint('Test loss:', val_score1[0])\nprint('Test accuracy:', val_score1[1])","2f56a004":"history2,model2=top_layer2(base_model2,1024,\"relu\")","a6871d83":"score2= model2.evaluate(train_ds, verbose=0)\nval_score2= model2.evaluate(val_ds, verbose=0)\nprint('Test loss:', val_score2[0])\nprint('Test accuracy:', val_score2[1])","813bfbe2":"history3,model3=top_layer(base_model3,512,\"relu\")","ff7fbf0b":"score3= model3.evaluate(train_ds, verbose=0)\nval_score3= model3.evaluate(val_ds, verbose=0)\nprint('Test loss:', val_score3[0])\nprint('Test accuracy:', val_score3[1])","72aa0066":"m1_accu = score1[1]\nm1_accu_val =  val_score1[1]\nm2_accu = score2[1]\nm2_accu_val =  val_score2[1]\nm3_accu = score3[1]\nm3_accu_val = val_score3[1]","0b9da347":"s = pd.DataFrame({\"Model\":[\"ResNet101\",\"Inception\",\"VGG16\"],\"Test\":[m1_accu,m2_accu,m3_accu],\"Validation\":[m1_accu_val,m2_accu_val,m3_accu_val]})\ntableMk=s.to_markdown(tablefmt=\"grid\")","5ed37fbb":"print(tableMk)","a3cb3c2b":"def visualiza(history,name):\n    plt.plot(history.history[\"accuracy\"])\n    plt.plot(history.history[\"val_accuracy\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(name)\n    plt.legend([\"Train\", \"Validation\"])\n    plt.show()\n    \n    plt.plot(history.history[\"loss\"])\n    plt.plot(history.history[\"val_loss\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"name\")\n    plt.legend([\"Train\", \"Validation\"])\n    plt.show()","88cbc1e8":"visualiza(history1,\"ResNet 101\")","00831f67":"visualiza(history2,\"Inception\")","d57dbbc9":"visualiza(history3,\"VGG16\")","939415aa":"val_samples = sum([y.shape[0] for [_, y] in val_ds])\nval_samples","3315604f":"def pred(model):\n    y_val = []\n    y_val_pred = []\n    for images, targets in val_ds:\n        for image, target in zip(images, targets):\n            img_array = image.numpy().astype(\"uint8\")\n            prediction = model.predict(np.array([img_array]))\n            y_val_pred.append(np.argmax(prediction))\n            y_val.append(np.argmax(target))\n            \n    return y_val, y_val_pred","32a3273c":"import plotly.express as px\nfrom sklearn.metrics import confusion_matrix\n\ndef print_cf(model):\n    y_val, y_val_pred=pred(model)\n    cm = confusion_matrix(y_val, y_val_pred,normalize='true')\n    fig = px.imshow(cm, labels=dict(x=\"Predicted\", y=\"Real\"), x=CATEGORIES,y=CATEGORIES)\n    fig.update_xaxes(side=\"top\")\n    fig.show()","cd7d6077":"print_cf(model1)","54729a1e":"plt.figure(figsize=(20, 17))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model1.predict(np.array([img_array]))\n        prediction_name = CATEGORIES[np.argmax(prediction)]\n        real_name = CATEGORIES[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})","1e7f3f98":"print_cf(model2)","56dcd739":"plt.figure(figsize=(20, 17))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model2.predict(np.array([img_array]))\n        prediction_name = CATEGORIES[np.argmax(prediction)]\n        real_name = CATEGORIES[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})","82c31a1e":"print_cf(model3)","63788fc3":"plt.figure(figsize=(20, 17))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model3.predict(np.array([img_array]))\n        prediction_name = CATEGORIES[np.argmax(prediction)]\n        real_name = CATEGORIES[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})","4189f8a6":"### 2. Evaluaci\u00f3n de los modelos; accuracy training y validation\nMuestre los accuracy y val_accuracy de cada modelo base mediante una tabla en markdown (3 pts)","68c53cc8":"#### 4.3 VGG16","1855bef1":"#### 4.1 Resnet 101","6513ff2b":"#### 1.1 ResNet101","a75af065":"#### 1.5 Top Layers","6aaa81bb":"### 1. Transfer Learning\nUtilice Transfer Learning con al menos 3 modelos base diferentes (3 pts c\/u).","c66ddc80":"Se revisa si el dataset est\u00e1 balanceado","d8e248d8":"### 3. Accuracy and Loss a lo largo del tiempo\nMuestre el accuracy y el loss a lo largo del tiempo \/ epochs (2 pts)","263713c8":"#### Predicci\u00f3n Modelo 2","eae41517":"#### Visualizaci\u00f3n de im\u00e1genes","de4a48ad":"#### Prueba de predicci\u00f3n con Modelo 1","aad460b0":"### 0. Carga del dataset","25075f70":"#### 1.2 InceptionV3","65c6f1a5":"#### Predicci\u00f3n Modelo 3","c4f6bf0f":"#### 4.2 Inception V3","aa38159f":"### 4. Matriz de confusi\u00f3n\nMuestre sus resultados con una matriz de confusi\u00f3n o un reporte (2 pts)","09851438":"#### 1.4 VGG16"}}