{"cell_type":{"6ee74882":"code","8d31260c":"code","42963a3f":"code","e536785c":"code","fd9075c4":"code","e4586a98":"code","8067b589":"code","2d3ea03c":"code","98cb0545":"code","ef14f66b":"code","3fcea920":"code","8617bae7":"code","52cd8a1e":"code","05e5e5ea":"code","723f0a75":"code","d7117d09":"markdown","fb91d1b5":"markdown","c5f24909":"markdown","fa60f3c7":"markdown","c760cee1":"markdown","b7abbad3":"markdown","2c617337":"markdown"},"source":{"6ee74882":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.graph_objs as go\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","8d31260c":"df = pd.read_csv('\/kaggle\/input\/online-shoppers-intention\/online_shoppers_intention.csv')","42963a3f":"df.head()","e536785c":"df.groupby('Month')['Revenue'].value_counts().unstack('Revenue').plot(kind='bar', stacked=True, figsize=(10, 5))","fd9075c4":"df.groupby('Weekend')['Revenue'].value_counts().unstack('Revenue').plot(kind='bar', stacked=True, figsize=(7, 7))","e4586a98":"df['VisitorType'].value_counts().plot.pie(y='VisitorType', figsize=(7, 7))","8067b589":"df_pvt=df[['Administrative_Duration','Informational_Duration','ProductRelated_Duration','VisitorType']]\npd.pivot_table(df_pvt, values=['Administrative_Duration','Informational_Duration','ProductRelated_Duration'],columns=['VisitorType'], aggfunc='mean').plot(kind='bar', figsize=(10, 5))","2d3ea03c":"df.hist(bins=50, figsize=(20,15))\nplt.show()","98cb0545":"\nMonth={'Feb':2, 'Mar':3, 'May':5, 'Oct':10, 'June':6, 'Jul':7, 'Aug':8, 'Nov':11, 'Sep':9,'Dec':12}\ndf['Month']=df['Month'].map(Month)\n\nVisitorType={'Returning_Visitor':3, 'New_Visitor':2, 'Other':1}\ndf['VisitorType']=df['VisitorType'].map(VisitorType)\nd={True:1,False:0}\ndf['Weekend']=df['Weekend'].map(d)\ndf['Revenue']=df['Revenue'].map(d)","ef14f66b":"\nVar_Corr = df.corr()\nfig, ax = plt.subplots(figsize=(15,15))  \nsns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns, annot=True)","3fcea920":"from sklearn.preprocessing import StandardScaler \n  \nscaler = StandardScaler() \n  \nscaler.fit(df.drop('Revenue', axis = 1)) \nscaled_features = scaler.transform(df.drop('Revenue', axis = 1)) \n  \ndf_feat = pd.DataFrame(scaled_features, columns = df.columns[:-1]) \ndf_feat.head() ","8617bae7":"from sklearn.model_selection import train_test_split \nimport scikitplot as skplt\n  \nX_train, X_test, y_train, y_test = train_test_split( \n      scaled_features, df['Revenue'], test_size = 0.30) \n  \nfrom sklearn.neighbors import KNeighborsClassifier \n  \nknn = KNeighborsClassifier(n_neighbors = 17) \n  \nknn.fit(X_train, y_train) \npred = knn.predict(X_test) \n\nfrom sklearn.metrics import classification_report, confusion_matrix \nplt_2 = skplt.metrics.plot_confusion_matrix(y_test,pred, normalize=True)\nprint(classification_report(y_test, pred)) ","52cd8a1e":"from sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n\n\n\n\nns_probs = [0 for _ in range(len(y_test))]\nlr_probs = knn.predict_proba(X_test)\nlr_probs = lr_probs[:, 1]\nns_auc = roc_auc_score(y_test, ns_probs)\nlr_auc = roc_auc_score(y_test, lr_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('KNN: ROC AUC=%.3f' % (lr_auc))\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='KNN')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","05e5e5ea":"from sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_curve\ny_pred1 = (knn.predict_proba(X_test)[:,1] >= 0.15).astype(int) # set threshold as 0.3\nrecall_score(y_test, y_pred1)","723f0a75":"plt_2 = skplt.metrics.plot_confusion_matrix(y_test,y_pred1, normalize=True)","d7117d09":"# Data Cleaning and Standardization","fb91d1b5":"# K Nearest Neighbor","c5f24909":"**Observation 2**\n\n1. We don't have much correlation.\n2. Only BounceRate and ExitRate has good correlation.","fa60f3c7":"# Data Visualization","c760cee1":"# ROC curve","b7abbad3":"**Observation 1**\n\n1. Data is not distributed evenly.\n2. Revenue is less on weekend.\n3. Revenue is more in Nov month.","2c617337":"**Observation 3**\n\n1. TP is good but FN is also high value, we need to correct that.\n2. We can use ROC curve to increase calue of recall."}}