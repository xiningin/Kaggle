{"cell_type":{"e3f6ac02":"code","e5d9a2fe":"code","d791c013":"code","12ee0fe5":"code","c9bd5e61":"code","674339d3":"code","164ce750":"code","f4f5457f":"code","6a600417":"code","348d956c":"code","1fe5c18c":"code","58800a88":"code","ec8ccda8":"code","2b3129f2":"code","00d1c947":"code","6a5d0804":"code","ad220da1":"code","3e391b44":"code","3d9ea2e9":"code","6c4d004f":"code","64444028":"code","ae5202fe":"code","204a86b8":"code","bf898462":"code","e29cc359":"code","0314f280":"code","702136cb":"code","c8210687":"code","2decbe69":"code","7f7749c8":"code","0eb27ed0":"code","1356fa76":"code","496e3c49":"code","5b303aa9":"code","c6f6202b":"code","d3442321":"code","dfb8cfa1":"code","40eaac70":"code","88690eb5":"code","e99b7678":"markdown","73768b7d":"markdown","47189916":"markdown","1be797e7":"markdown","286e55aa":"markdown"},"source":{"e3f6ac02":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\nimport psutil","e5d9a2fe":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d791c013":"houses = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nhouses.head()","12ee0fe5":"houses_test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nhouses_test.head()","c9bd5e61":"houses.shape","674339d3":"houses_test.shape","164ce750":"#houses.info()","f4f5457f":"houses.dtypes.value_counts()","6a600417":"houses['SalePrice'].describe()","348d956c":"plt.figure(figsize =(10,8))\n#histogram\nsns.distplot(houses['SalePrice'])","1fe5c18c":"print(\"Skewness: %f\" % houses['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % houses['SalePrice'].kurt())","58800a88":"plt.scatter(x = houses['GrLivArea'], y = houses['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)","ec8ccda8":"#Deleting outliers\ntrain = houses.drop(houses[(houses['GrLivArea']>4000) & (houses['SalePrice']<300000)].index)\nplt.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)","2b3129f2":"def disregardCol(df):\n    l=[]\n    x = df.isna().mean()\n    for k,v in x.items():\n        if(v>0.3):\n            l.append(k)\n    return [l,len(l)]\nprint(disregardCol(train)[0],disregardCol(train)[1],end='\\n')","00d1c947":"# Dropping Columns having more than 30% missing values of total values\ntrain=train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1)\n# train.columns\ntrain.shape","6a5d0804":"#OverallQual is a categorical column\ntrain.OverallQual.unique()","ad220da1":"train.OverallQual.value_counts().plot.bar()","3e391b44":"train.OverallCond.value_counts().plot.bar()","3d9ea2e9":"train.OverallQual.value_counts()","6c4d004f":"plt.figure(figsize =(10,8))\nsns.boxplot(x=\"OverallCond\",y=\"SalePrice\", data=train)","64444028":"plt.figure(figsize =(10,8))\nsns.boxplot(x='OverallQual', y=\"SalePrice\", data=train)","ae5202fe":"plt.figure(figsize =(15,10))\nplt.xticks(rotation=90)\nsns.boxplot(x=\"Neighborhood\", y=\"SalePrice\", data=train)","204a86b8":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols], height = 2.5)\nplt.show()","bf898462":"train.columns","e29cc359":"train['YearBuilt'].unique()","0314f280":"plt.figure(figsize =(10,8))\n#plt.xticks(rotation=45)\nsns.lineplot(y='SalePrice', x='YearBuilt', data=houses)","702136cb":"plt.figure(figsize =(10,8))\nsns.boxplot(x='HouseStyle', y='SalePrice', data=train)","c8210687":"sns.lineplot(x='YearRemodAdd', y='SalePrice', data=train)","2decbe69":"# lets drop Id because its of no use to us\ntrain.drop(\"Id\",1,inplace = True)","7f7749c8":"# Let's display the variables with more than 0 null values\nnull_cols = []\nfor col in train.columns:\n    if train[col].isnull().sum() > 0 :\n        print(\"Column\",col, \"has\", train[col].isnull().sum(),\"null values\")    \n        null_cols.append(col)","0eb27ed0":"# lets visualize the null vaues\nplt.figure(figsize=(12,10))\nsns.barplot(x=train[null_cols].isnull().sum().index, y=train[null_cols].isnull().sum().values)\nplt.xticks(rotation=45)\nplt.show()","1356fa76":"# lets check if these null values actually have any relation with the target variable\n\ntrain_eda = train.copy()\n\nfor col in null_cols:\n    train_eda[col] = np.where(train_eda[col].isnull(), 1, 0)  \n\n# lets see if these null values have to do anything with the sales price\nplt.figure(figsize = (16,48))\nfor idx,col in enumerate(null_cols):\n    plt.subplot(10,2,idx+1)\n    sns.barplot(x = train_eda.groupby(col)[\"SalePrice\"].median(),y =train_eda[\"SalePrice\"])\nplt.show()","496e3c49":"# making list of date variables\nyr_vars = []\nfor col in train.columns:\n    if \"Yr\" in col or \"Year\" in col:\n        yr_vars.append(col)\n\nyr_vars = set(yr_vars)\nyr_vars","5b303aa9":"#Let's check relation of these fields with the target variable\n\nplt.figure(figsize = (15,12))\nfor idx,col in enumerate(yr_vars):\n    plt.subplot(2,2,idx+1)\n    plt.plot(train.groupby(col)[\"SalePrice\"].median())\n    plt.xlabel(col)\n    plt.ylabel(\"SalePrice\")","c6f6202b":"#Make a note of the trend of sale price with the field \"YrSold\", it shows a decreasing trend which seems unreal in real state scenario, price is expected to increase as the time passes by, but here it shows opposite. Does it look right? can we do anything about it? Yes, We can Surely do!! Let's create \"Age\" variables out of these \"Year\" variables\n\n#Let's check variations or different values present in the columns, we will start by seperating two seperate lists, one for categorical variabels and another one for numeric variables\n\n# lets create seperate lists of categorical and numeric columns\ncat_vars = []\nnum_vars = []\nfor col in train.columns.drop(\"SalePrice\"):\n    if train[col].dtypes == 'O':\n        cat_vars.append(col)\n    else:\n        num_vars.append(col)\n\n#lets check the lists created.\nprint(\"List of Numeric Columns:\",num_vars)\nprint(\"\\n\")\nprint(\"List of Categorical Columns:\",cat_vars)","d3442321":"# Let's further seperate the numeric features into continous and discrete numeric features\nnum_cont = []\nnum_disc = []\nfor col in num_vars:\n    if train[col].nunique() > 25: # if variable has more than 25 different values, we consider it as continous variable\n        num_cont.append(col)\n    else:\n        num_disc.append(col)","dfb8cfa1":"# lets check for the variance in the different continous numeric columns present in the dataset\nplt.figure(figsize = (16,48))\nplt.xticks(rotation=45)\nfor idx,col in enumerate(num_cont):\n    col_bins = col+\"_bins\"\n    train_eda[col_bins] = pd.cut(train_eda[col], 4, duplicates = 'drop') # creating bins\n    plt.subplot(9,2,idx+1)\n    sns.countplot(train_eda[col_bins])","40eaac70":"# lets check for the variance in the different continous numeric columns present in the dataset\nplt.figure(figsize = (16,48))\nfor idx,col in enumerate(num_disc):\n    plt.subplot(9,2,idx+1)\n    sns.countplot(train_eda[col])","88690eb5":"# lets check for the variance in the categorical columns present in the dataset\nplt.figure(figsize = (15,75))\nfor idx,col in enumerate(cat_vars):\n    plt.subplot(22,2,idx+1)\n    sns.countplot(train_eda[col])","e99b7678":"Since bottom right two with extremely large GrLivArea that are of a low price. These values are huge oultliers. Therefore, we can safely delete them. (because they were houses with extremely large areas for very low prices)","73768b7d":"Following variables seems to have low variance:\n\nMasVnArea\nBsmtFinSF1\nBsmtFinSF2\nBsmtUnfSF\n2ndFlrSF\nLowQualFinSF\nWoodDeckSF\nOpenPorchSF\nEnclosedPorch\n3SsnPorch\nScreenPorch,\nPoolArea,\nMiscVal.\n\nWe will see if we can drop these variables in Feature Engineering section.","47189916":"**Deleting Outliers**","1be797e7":"Posch Areas:\n*     NoRidge\tNorthridge\n*     NridgHt\tNorthridge Heights\n*     Timber\tTimberland\n*     StoneBr\tStone Brook ","286e55aa":"Possible Columns that can be discarded based on number of null values (Categorical columns mainly)\n* ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'] 5"}}