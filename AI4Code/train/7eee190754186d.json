{"cell_type":{"196c8412":"code","cfdda56a":"code","8a2857ad":"code","10a51779":"code","7a3f0c81":"markdown","ddeb4a93":"markdown","b3f396ae":"markdown","d3247c9e":"markdown"},"source":{"196c8412":"!pip install xgbtune","cfdda56a":"import pandas  as pd\nimport xgboost as xgb\n\n#===========================================================================\n# read in the data\n#===========================================================================\ntrain_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data  = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n#===========================================================================\n# select some features\n#===========================================================================\nfeatures = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', \n        'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', \n        'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n        'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n        'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n        'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', \n        'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', \n        'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n\n#===========================================================================\n#===========================================================================\nX_train       = train_data[features]\ny_train       = train_data[\"SalePrice\"]\nX_test        = test_data[features]","8a2857ad":"from xgbtune import tune_xgb_model\nparams = {'eval_metric': 'rmsle'}\nparams, round_count = tune_xgb_model(params, X_train, y_train)","10a51779":"#===========================================================================\n# now use the parameters from XGBTune\n#===========================================================================\nregressor=xgb.XGBRegressor(**params)\n\nregressor.fit(X_train, y_train)\n\n#===========================================================================\n# use the fit to predict the prices for the test data\n#===========================================================================\npredictions = regressor.predict(X_test)\n\n#===========================================================================\n# write out CSV submission file\n#===========================================================================\noutput = pd.DataFrame({\"Id\":test_data.Id, \"SalePrice\":predictions})\noutput.to_csv('submission.csv', index=False)","7a3f0c81":"### now fit using the parameters, predict, and write out the `submission.csv` file","ddeb4a93":"### run `xgbtune`\nHere we use the root of the mean squared logarithmic error regression loss (`rmsle`) as per the competition requirements","b3f396ae":"# Automatic tuning of XGBoost parameters using XGBTune\nThanks to the work of [Romain Picard](https:\/\/github.com\/MainRo) there is now a package, called [XGBTune](https:\/\/github.com\/MainRo\/xgbtune), to automatically tune the parametrs of [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html).\nFrom the GitHub page:\n\n## Tuning steps\n\nThe tuning is done in the following steps:\n\n*    compute best round\n*    tune max_depth and min_child_weight\n*    tune gamma\n*    re-compute best round\n*    tune subsample and colsample_bytree\n*    fine tune subsample and colsample_bytree\n*    tune alpha and lambda\n*    tune seed\n\nThis steps can be repeated several times. By default, two passes are done.\n\nHere we shall use the [House Prices](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques) data as an example.\n\n### Install `XGBTune`","d3247c9e":"### set up the House Prices data"}}