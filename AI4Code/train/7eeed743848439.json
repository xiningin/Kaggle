{"cell_type":{"7c93bf62":"code","01d4b54c":"code","12c82d8f":"code","555444f0":"code","cf5bfd38":"code","c70bd9af":"code","1f26d0b8":"code","cc55eb4f":"code","5fbb7268":"code","3aa593ce":"code","640341f7":"code","67b06452":"code","450d2cc0":"code","6cd4eb2c":"code","fe834243":"code","107e1182":"code","21e604bd":"markdown","c6382170":"markdown"},"source":{"7c93bf62":"# import libraries\nimport os\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \n\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.models import Sequential\nfrom keras import models\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\nfrom keras import optimizers\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","01d4b54c":"main_dir = os.listdir(\"..\/input\")[0]\nos.mkdir('.\/model_repo')","12c82d8f":"train_datagen = ImageDataGenerator(rescale=1.\/255)\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\ntrain_dir = os.path.join('..\/input', main_dir, 'dice' , 'train')\nvalid_dir = os.path.join('..\/input', main_dir, 'dice' , 'valid')\ntarget_size = 150\nbatch_size = 32\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(target_size, target_size),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = valid_datagen.flow_from_directory(\n    valid_dir,\n    target_size=(target_size, target_size),\n    batch_size=batch_size,\n    class_mode='categorical', \n    shuffle=False)","555444f0":"\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(16, 3, activation='relu', \n                        input_shape=(target_size, target_size, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D((2, 2)))\nmodel.add(layers.Conv2D(16, 5, activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\nmodel.add(layers.Conv2D(32, 5, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D((2, 2)))\nmodel.add(layers.Conv2D(64, 7, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(Dropout(0.6257491042113806))\nmodel.add(layers.Dense(6, activation='softmax'))","cf5bfd38":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n              optimizer=optimizers.RMSprop(3e-4))\n","c70bd9af":"callbacks_list = [\n    callbacks.EarlyStopping(monitor='val_acc', \n                                 patience=7 \n                                 ),\n    callbacks.ModelCheckpoint(filepath='.\/model_repo\/model.h5',\n                                    monitor='val_loss',\n                                    save_best_only=True\n    ), \n    callbacks.ReduceLROnPlateau()\n]","1f26d0b8":"history = model.fit_generator(train_generator,\n                             steps_per_epoch=int(train_generator.n \/\/ batch_size),\n                             epochs=50,\n                             verbose=1,\n                             validation_data=validation_generator,\n                             validation_steps=int(validation_generator.n \/\/ batch_size),\n                             callbacks=callbacks_list\n                             )","cc55eb4f":"\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","5fbb7268":"model = models.load_model('.\/model_repo\/model.h5')","3aa593ce":"STEP_SIZE_EVAL = validation_generator.n\/\/validation_generator.batch_size\nvalidation_generator.reset()\npreds = model.predict_generator(validation_generator, steps=STEP_SIZE_EVAL+1, verbose=1)","640341f7":"np.mean(np.argmax(preds, axis=1) == validation_generator.labels)","67b06452":"labels = (validation_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nlabels = [i[1] for i in labels.items()]","450d2cc0":"confusion_matrix(validation_generator.labels, np.argmax(preds, axis=1))","6cd4eb2c":"print(classification_report(np.argmax(preds, axis=1), validation_generator.labels))","fe834243":"misclass_list = np.where(np.argmax(preds, axis=1) != validation_generator.labels)[0]\n\nmisclassed_files = np.array(validation_generator.filepaths)[misclass_list]","107e1182":"img = np.random.choice(misclassed_files)\nimage_data = plt.imread(img)\nprint(image_data.shape)\nplt.imshow(image_data)","21e604bd":"Based on some limited sampling, most of the misclassified images seem like they are different sized images. Since the data is being resized to 150x150 there probably is a fair amount of distortion in the images. Getting it to a bigger size might solve the problem but then we might also need to enlarge the model which kinda defeats the purpose for this kernel.\n\nHope you enjoyed the kernel!","c6382170":"As an aging but devout FRP fan, I just couldn't resist writing a quick and small model for this dataset. I previously optimized the model on my own machine using Hyperopt\/Hyperas. \n\nEnjoy!"}}