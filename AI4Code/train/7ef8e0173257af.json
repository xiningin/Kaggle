{"cell_type":{"f858731b":"code","5c7f3fe0":"code","e6e4d6b9":"code","52f1b330":"code","8de820df":"code","e02bd14c":"code","c9d253d5":"code","b32a8e89":"code","9e38c2c9":"code","d30cfa87":"code","d735d3cc":"code","c42395c2":"code","79eae32b":"code","b90f1e77":"code","3b47740b":"code","9f69f17b":"code","1c60009b":"code","68365a31":"code","86440d32":"code","0c46ecfe":"code","03f445f2":"code","c287db3d":"code","32a410cf":"code","760606cc":"code","67f6ac21":"code","7841f2e1":"code","805671e6":"code","a14a3349":"code","a2ed15e9":"code","3676fc7a":"code","268cc149":"code","0dc952c5":"code","c4d9a881":"code","44d0b347":"code","0a4d30b4":"code","4ac465c1":"code","942a489d":"code","3e301c70":"code","0d8dd6a9":"code","302d5cf8":"code","718cabb8":"code","0286e068":"code","829baac9":"code","1b453785":"code","22f58a47":"code","265366df":"code","475362d5":"code","07e69b54":"code","30717702":"code","fbdae16a":"code","dcae83ae":"code","94afd05f":"code","6c3381ce":"code","02dcfba4":"code","ae3bfa87":"code","61a93ea1":"code","0e5b908d":"code","cd9c33ca":"code","543066eb":"code","eb4cf1fa":"code","fd220140":"code","7e69a5a4":"code","b0c754e8":"code","db0620f1":"code","7f16cc26":"code","66142985":"code","b46d31ab":"code","f218c35f":"code","801b1d5d":"code","cf403649":"code","b81ee81d":"code","ebc84770":"code","79f6f74a":"code","947f5229":"code","53c36f1f":"code","65b2adcb":"code","89bfa112":"code","d1656d81":"code","ba06dc92":"code","aa16517e":"code","a1f3193e":"markdown","f36c42df":"markdown","431ab3af":"markdown","c1afca33":"markdown","a8b831ce":"markdown","9dabf381":"markdown","3ce85422":"markdown","f34a404e":"markdown","afd261df":"markdown","eedbeaa5":"markdown","38ca198d":"markdown","7342a3e6":"markdown","ae437c8c":"markdown","ada635fa":"markdown","9f61c180":"markdown"},"source":{"f858731b":"!pip install tensorflow==2.1","5c7f3fe0":"!pip install -q efficientnet","e6e4d6b9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport scipy.io\nimport tarfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import optimizers\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', keras.__version__)","52f1b330":"# \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0447\u0442\u043e \u0443 \u043d\u0430\u0441 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 GPU\ntf.test.gpu_device_name()","8de820df":"!pip freeze > requirements.txt","e02bd14c":"# \u0412 \u0441\u0435\u0442\u0430\u043f \u0432\u044b\u043d\u043e\u0448\u0443 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438, \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c\n\nEPOCHS               = 5\nBATCH_SIZE           = 8 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-3\nVAL_SPLIT            = 0.2\n\nCLASS_NUM            = 102\nIMG_SIZE             = 250\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/flower-dataset-102\/'\nPATH = \"..\/working\/flower\/\"","c9d253d5":"# Setting seed for reproducibility\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","b32a8e89":"# \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u0435\u043c \u0432\u0441\u0435 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0444\u0430\u0439\u043b\u043e\u0432 \u043f\u0440\u044f\u043c \u0438\u0437 \u0430\u0440\u0445\u0438\u0432\u0430 \u0438 \u0442\u0430\u0440\u0433\u0435\u0442\u044b \u043a \u043d\u0438\u043c\ndef get_all_filenames(tar_fn):\n    with tarfile.open(tar_fn) as f:\n        return [m.name for m in f.getmembers() if m.isfile()]\n\ndf = pd.DataFrame()\ndf['Id'] = sorted(get_all_filenames(DATA_PATH+\"102flowers.tgz\"))\ndf['Category'] = scipy.io.loadmat(DATA_PATH+'imagelabels.mat')['labels'][0] - 1  # \u043a\u043b\u0430\u0441\u0441\u044b (0, 1, 2, ...)\ndf['Category'] = df['Category'].astype(str)","9e38c2c9":"df.head(5)","d30cfa87":"df['Category'].value_counts()","d735d3cc":"df['Category'].nunique()","c42395c2":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n# Will unzip the files so that you can see them..\nopened_tar = tarfile.open(DATA_PATH+\"102flowers.tgz\")\nopened_tar.extractall(PATH)\n\nprint(os.listdir(PATH+'jpg')[:5])","79eae32b":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+path)\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","b90f1e77":"# \u0443\u0431\u0435\u0434\u0438\u043c\u0441\u044f \u0447\u0442\u043e \u043c\u0435\u0442\u043a\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043b\u0438\u0441\u044c \u0432\u0435\u0440\u043d\u043e\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = df[df['Category']=='1'].sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+path)\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","3b47740b":"# \u043a\u0430\u043a \u0432\u0438\u0434\u0438\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u043c\u0435\u044e\u0442 \u0440\u0430\u0437\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440\nimage = PIL.Image.open(PATH+path)\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","9f69f17b":"# \u0442\u0440\u0435\u0439\u043d \/ \u0442\u0435\u0441\u0442\ntrain_files, test_files, train_labels, test_labels = \\\n    train_test_split(df['Id'], df['Category'], test_size=0.2, random_state=42, stratify=df['Category'])\n\ntrain_files = pd.DataFrame(train_files)\ntest_files = pd.DataFrame(test_files)\ntrain_files['Category'] = train_labels\ntest_files['Category'] = test_labels\n\ntrain_files.shape, test_files.shape","1c60009b":"train_files.head(5)","68365a31":"train_files['Category'].value_counts()","86440d32":"test_files['Category'].value_counts()","0c46ecfe":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u0430 \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u0430\u043a \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\n\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255, \n                                    rotation_range = 50,\n                                    shear_range=0.2,\n                                    zoom_range=[0.75,1.25],\n                                    brightness_range=[0.5, 1.5],\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,\n                                    horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","03f445f2":"# \"\u0417\u0430\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u043c\" \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 generator\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_files,\n    directory=PATH,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    seed=RANDOM_SEED,)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_files,\n    directory=PATH,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False, \n    seed=RANDOM_SEED,)","c287db3d":"from skimage import io\n\ndef imshow(image_RGB):\n  io.imshow(image_RGB)\n  io.show()\n\nx,y = train_generator.next()\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438\u0437 train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","32a410cf":"x,y = test_generator.next()\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438\u0437 test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","760606cc":"input_shape","67f6ac21":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","7841f2e1":"base_model.summary()","805671e6":"# first: train only the top layers (which were randomly initialized)\nbase_model.trainable = False","a14a3349":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),)\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","a2ed15e9":"model.summary()","3676fc7a":"# \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u043b\u043e\u0435\u0432\nprint(len(model.layers))","268cc149":"len(model.trainable_variables)","0dc952c5":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","c4d9a881":"LR=0.001\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","44d0b347":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","0a4d30b4":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","4ac465c1":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit_generator(\n                    train_generator,\n                    steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n                    validation_data = test_generator, \n                    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n                    epochs = 5,\n                    callbacks = callbacks_list\n                    )","942a489d":"# \u0443\u0434\u0438\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0430 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u0445\u043e\u0440\u043e\u0448\u043e \u0443\u043c\u0435\u0435\u0442 \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438!\n# \u0434\u0430\u0436\u0435 \u0431\u0435\u0437 \u0434\u043e\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u0442\u043e\u043b\u044c \u0432\u044b\u0441\u043e\u043a\u0438\u0439 Accuracy","3e301c70":"model.save('..\/working\/model_step1.hdf5')\nmodel.load_weights('best_model.hdf5')","0d8dd6a9":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","302d5cf8":"def plot_history(history):\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\nplot_history(history)","718cabb8":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","0286e068":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)\/\/2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","829baac9":"len(base_model.trainable_variables)","1b453785":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","22f58a47":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","265366df":"model.summary()","475362d5":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","07e69b54":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = 10,\n        callbacks = callbacks_list\n)","30717702":"model.save('..\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","fbdae16a":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","dcae83ae":"plot_history(history)","94afd05f":"base_model.trainable = True","6c3381ce":"LR=0.00001\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","02dcfba4":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = 10,\n        callbacks = callbacks_list\n)","ae3bfa87":"model.save('..\/working\/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","61a93ea1":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","0e5b908d":"EPOCHS               = 10\nBATCH_SIZE           = 4 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\n\nIMG_SIZE             = 512\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","cd9c33ca":"train_datagen = ImageDataGenerator(rescale=1. \/ 255, \n                                    #rotation_range = 90,\n                                    #shear_range=0.2,\n                                    zoom_range=[0.75,1.25],\n                                    #brightness_range=[0.5, 1.5],\n                                    #width_shift_range=0.1,\n                                    #height_shift_range=0.1,\n                                    horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","543066eb":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_files,\n    directory=PATH,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    seed=RANDOM_SEED,)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_files,\n    directory=PATH,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False, \n    seed=RANDOM_SEED,)","eb4cf1fa":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","fd220140":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),)\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","7e69a5a4":"model.summary()","b0c754e8":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","db0620f1":"model.load_weights('best_model.hdf5')","7f16cc26":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        )","66142985":"model.save('..\/working\/model_step4.hdf5')\nmodel.load_weights('best_model.hdf5')","b46d31ab":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","f218c35f":"plot_history(history)","801b1d5d":"from sklearn.metrics import accuracy_score","cf403649":"predictions = model.predict_generator(test_generator, verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","b81ee81d":"filenames_with_dir=test_generator.filenames\nsubmission = pd.DataFrame({'Predict':predictions}, columns=['Predict'], index=filenames_with_dir)\ntest_files.index = test_files['Id']\ntmp_y = pd.concat([submission['Predict'], test_files['Category']], axis=1, sort=False)\ntmp_y.head(5)","ebc84770":"print('Accuracy: %.2f%%' % (accuracy_score(tmp_y['Category'], tmp_y['Predict'],)*100))","79f6f74a":"model.load_weights('best_model.hdf5')","947f5229":"test_datagen = ImageDataGenerator(rescale=1. \/ 255,\n                                 rotation_range = 90,\n                                    shear_range=0.2,\n                                    zoom_range=[0.75,1.25],\n                                    brightness_range=[0.5, 1.5],\n                                    width_shift_range=0.1,\n                                    height_shift_range=0.1,)","53c36f1f":"test_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_files,\n    directory=PATH,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False, \n    seed=RANDOM_SEED,)","65b2adcb":"x,y = test_generator.next()\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438\u0437 test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\nplt.show()","89bfa112":"tta_steps = 10\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(test_generator, verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","d1656d81":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\nfilenames_with_dir=test_generator.filenames\nsubmission = pd.DataFrame({'Predict':predictions}, columns=['Predict'], index=filenames_with_dir)\ntmp_y = pd.concat([submission['Predict'], test_files['Category']], axis=1, sort=False)","ba06dc92":"print('Accuracy: %.2f%%' % (accuracy_score(tmp_y['Category'], tmp_y['Predict'],)*100))","aa16517e":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","a1f3193e":" ## Stratify Split","f36c42df":"# Step 4","431ab3af":"# Transfer learning \u0432 \u0440\u0435\u0448\u0435\u043d\u0438\u0438 \u0437\u0430\u0434\u0430\u0447\u0438 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0446\u0432\u0435\u0442\u043e\u0432\n\u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0446\u0432\u0435\u0442\u043e\u0432 (http:\/\/www.robots.ox.ac.uk\/~vgg\/data\/flowers\/102\/index.html) \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 102 \u0432\u0438\u0434\u043e\u0432 \u0446\u0432\u0435\u0442\u043e\u0432 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u0435\u043c\u044b\u0445 \u0432 \u0412\u0435\u043b\u0438\u043a\u043e\u0431\u0440\u0438\u0442\u0430\u043d\u0438\u0438. \u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430 \u0435\u0441\u0442\u044c \u043e\u0442 40 \u0434\u043e 258 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432, \u0447\u0435\u0433\u043e \u043c\u0430\u043b\u043e \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441 \u043d\u0443\u043b\u044f:\n<img src=\"http:\/\/bennycheung.github.io\/images\/deep-transfer-learning-on-small-dataset\/flower_train_samples_700.jpg\" style=\"width:50%\">","c1afca33":"## Step 3","a8b831ce":"# Data","9dabf381":"# Model","3ce85422":"\u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0443\u0436\u0435 \u0441 Tensorflow 2.1 \u043d\u043e \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0432\u0435\u0440\u0441\u0438\u0438 \u0432\u0441\u0435\u0445 \u043f\u0430\u043a\u0435\u0442\u043e\u0432","f34a404e":"## Fit","afd261df":"### Data augmentation","eedbeaa5":"### datagen","38ca198d":"# TTA","7342a3e6":"# Setup","ae437c8c":"# Final Score","ada635fa":"## clean","9f61c180":"## Step 2"}}