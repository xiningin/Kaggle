{"cell_type":{"0cb4cf94":"code","465c1713":"code","e7ee069f":"code","080f7949":"code","779c8dd3":"code","1c4db7ba":"code","f1710765":"code","27b38a6a":"code","b1d07b89":"code","6982394d":"code","ec069541":"code","d84ea7b3":"code","8fe92e86":"code","00575308":"code","b47da40b":"code","0d5258c2":"code","c5a1259c":"code","3d53ac2e":"code","cf0836cb":"code","c3ce829a":"code","99afc156":"code","e0a2ef43":"code","fa7a1b05":"markdown"},"source":{"0cb4cf94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","465c1713":"df = pd.read_csv(\"..\/input\/stacksample\/Questions.csv\", nrows=1_000_000,\n                encoding=\"ISO-8859-1\", usecols=['Title', 'Id'])\ntitles = [_ for _ in df['Title']]\ndf.head()\n","e7ee069f":"import random\n\nrandom.choices(titles, k=20)","080f7949":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")","779c8dd3":"doc = nlp(\"Show all sensors.\")\ntoken = doc[0]","1c4db7ba":"# after . press tab to see properties of the object\ntoken.is_stop","f1710765":"from spacy import displacy\n\n# render a model for our document\ndisplacy.render(doc)","27b38a6a":"# what is det or advmod in the graph?\nspacy.explain(\"det\")\n# spacy.explain(\"advmod\")","b1d07b89":"# we can also print what displacy.render shows us\nfor token in doc:\n    print(token, token.pos_, token.dep_)","6982394d":"# now lets try to find appearances of \"go\" in the titles\n\nnlp = spacy.load(\"en_core_web_sm\")\ndf = (pd.read_csv(\"..\/input\/stacksample\/Questions.csv\", nrows=2_000_000, \n                  encoding=\"ISO-8859-1\", usecols=['Title', 'Id']))\n\ntitles = [_ for _ in df.loc[lambda d: d['Title'].str.lower().str.contains(\"go\")]['Title']]\n\n# we disabled some pipes to get a better performance\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])","ec069541":"%%time\n\ndef has_golang(doc):\n    for t in doc:\n        if t.lower_ in [\"go\", \"golang\"]:\n            if t.pos_ == \"NOUN\":\n                return True \n    return False\n\ng = (doc for doc in nlp.pipe(titles) if has_golang(doc))\n[next(g) for i in range(30)]","d84ea7b3":"df_tags = pd.read_csv(\"..\/input\/stacksample\/Tags.csv\")\ngo_ids = df_tags.loc[lambda d: d['Tag'] == 'go']['Id']\n\ndef has_go_token(doc):\n    for t in doc:\n        if t.lower_ in ['go', 'golang']:\n            if t.pos_ != 'VERB':\n                return True\n    return False\n\nall_go_sentences = df.loc[lambda d: d['Id'].isin(go_ids)]['Title'].tolist()\ndetectable = [d.text for d in nlp.pipe(all_go_sentences) if has_go_token(d)]\n\nnon_detectable = (df\n                  .loc[lambda d: ~d['Id'].isin(go_ids)]\n                  .loc[lambda d: d['Title'].str.lower().str.contains(\"go\")]\n                  ['Title']\n                  .tolist())\n\nnon_detectable = [d.text for d in nlp.pipe(non_detectable) if has_go_token(d)]\n\nlen(all_go_sentences), len(detectable), len(non_detectable)","8fe92e86":"model_name = \"en_core_web_sm\"\nmodel = spacy.load(model_name, disable=[\"ner\"])\n\ndef has_go_token(doc):\n    for t in doc:\n        if t.lower_ in [\"go\", \"golang\"]:\n            if t.pos_ != \"VERB\":\n                return True\n    return False\n\nmethod = \"not-verb-but-pobj\"\n\ncorrect = sum(has_go_token(doc) for doc in model.pipe(detectable))\nwrong = sum(has_go_token(doc) for doc in model.pipe(non_detectable))\nprecision = correct\/(correct + wrong)\nrecall = correct\/len(detectable)\naccuracy = (correct + len(non_detectable) - wrong)\/(len(detectable) + len(non_detectable))\n\nf\"{precision},{recall},{accuracy},{model_name},{method}\" # this is logged","00575308":"# 2nd part of the tutorial\n# now we can detect go as a programming language, lets find other languages as well\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef has_go_token(doc):\n    for t in doc:\n        if t.lower_ in ['go', 'golang', 'python', 'ruby', 'objective-c']:\n            if t.pos_ != 'VERB':\n                return True\n    return False","b47da40b":"doc = nlp(\"i am an iOS dev and I like to code in objective-c\")\n\n# the problem is objective-c since it is composed of three tokens: objective,-,c\n# to find the pattern we will use a matcher \n[t for t in doc]","0d5258c2":"from spacy.matcher import Matcher\n\n# objective-c, objective c\nobj_c_pattern1 = [{'LOWER': 'objective'},\n                  {'IS_PUNCT': True, 'OP': '?'},\n                  {'LOWER': 'c'}]\n\nobj_c_pattern2 = [{'LOWER': 'objectivec'}]\n\ngolang_pattern1 = [{'LOWER': 'golang'}] \ngolang_pattern2 = [{'LOWER': 'go', \n                    'POS': {'NOT_IN': ['VERB']}}]\n\npython_pattern = [{'LOWER': 'python'}]\nruby_pattern   = [{'LOWER': 'ruby'}]\njs_pattern     = [{'LOWER': {'IN': ['js', 'javascript']}}]","c5a1259c":"matcher = Matcher(nlp.vocab, validate=True)\nmatcher.add(\"OBJ_C_LANG\", None, obj_c_pattern1, obj_c_pattern2)","3d53ac2e":"matcher(doc) # return matchid, match start index, match end index\ndoc[11:14]","cf0836cb":"matcher.add(\"PYTHON_LANG\", None, python_pattern)\nmatcher.add(\"GO_LANG\", None, golang_pattern1, golang_pattern2)\nmatcher.add(\"JS_LANG\", None, js_pattern)\nmatcher.add(\"RUBY_LANG\", None, ruby_pattern)","c3ce829a":"doc = nlp(\"I am an iOS dev who codes in both python, go\/golang as well as objective-c\")\nfor match_id, start, end in matcher(doc):\n    print(doc[start: end])","99afc156":"# takes go as verb so this is a problem\ndoc = nlp(\"I've done some js and ruby and go programming\")\nfor match_id, start, end in matcher(doc):\n    print(doc[start: end])","e0a2ef43":"# we can do benchmarking\n\ntitles = (_ for _ in df['Title'] if \"python\" in _.lower())\n\nfor i in range(200):\n    doc = nlp(next(titles))\n    if len(matcher(doc)) == 0:\n        print(doc)","fa7a1b05":"**This notebook is following the video tutorials of spaCy made by spaCy's developers.**\n\n**Tutorial's main purpose is detecting programming languages in the stackoverflow data.**\n\n![](http:\/\/)**Here are the links for the [first](https:\/\/youtu.be\/WnGPv6HnBok) and [second](https:\/\/youtu.be\/KL4-Mpgbahw) video of the tutorial.**"}}