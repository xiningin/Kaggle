{"cell_type":{"87674dce":"code","8c211046":"code","23b21b22":"code","89c1d82c":"code","160bc9de":"code","afbbd2a2":"code","3fb0c4e8":"markdown"},"source":{"87674dce":"import numpy as np\nimport pandas as pd\nimport random \nimport os \nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBRegressor\nimport optuna\n\nTRAIN_PATH = \"..\/input\/tabular-playground-series-jan-2022\/train.csv\"\nTEST_PATH = \"..\/input\/tabular-playground-series-jan-2022\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"row_id\"\nTARGET = \"num_sold\"\nDATE = \"date\"\n\nTEST_SIZE = 0.2\n\nOPTUNA_TRIALS = 30\nOPTUNA_ESR = 50\nOPTUNA_DIRECTION = \"minimize\"\n\nNFOLD = 20\nTREE_METHOD = 'gpu_hist'\nBOOSTER = \"gbtree\"\n\nSEED = 2002\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything()","8c211046":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntrain[DATE] = pd.to_datetime(train[DATE])\ntest[DATE]  = pd.to_datetime(test[DATE])\n\ntrain['year'] = train[DATE].dt.year\ntrain['month'] = train[DATE].dt.month\ntrain['day'] = train[DATE].dt.day\ntrain['day_of_year'] = train[DATE].dt.dayofyear\ntrain['day_of_month'] = train[DATE].dt.days_in_month\ntrain['day_of_week'] = train[DATE].dt.dayofweek\ntrain['weekday'] = train[DATE].dt.weekday\n\ntest['year'] = test[DATE].dt.year\ntest['month'] = test[DATE].dt.month\ntest['day'] = test[DATE].dt.day\ntest['day_of_year'] = test[DATE].dt.dayofyear\ntest['day_of_month'] = test[DATE].dt.days_in_month\ntest['day_of_week'] = test[DATE].dt.dayofweek\ntest['weekday'] = test[DATE].dt.weekday\n\ncat_cols = train.select_dtypes('object').columns.tolist()\ntrain = pd.get_dummies(train, columns=cat_cols)\ntest  = pd.get_dummies(test, columns=cat_cols)","23b21b22":"# split data \ny = train[TARGET]\nX = train.drop(columns=[ID, DATE, TARGET])\nX_test = test.drop(columns=[ID, DATE])\n\n# search best param\ndef smape(actual, predicted):\n    numerator = np.abs(predicted - actual)\n    denominator = (np.abs(actual) + np.abs(predicted)) \/ 2\n    \n    return np.mean(numerator \/ denominator)*100\n\ndef objective(trial, data=X, target=y):\n    \n    X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED, shuffle=False)\n    params = {\n        'max_depth': trial.suggest_int('max_depth',1, 20),\n        'eta': trial.suggest_float('eta', 1e-5, 0.1),\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.1, 0.9, 0.1),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.1, 0.9, 0.1),\n        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 1e5),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 1e5),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 1e5),\n        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1e5),\n        'predictor': \"gpu_predictor\",\n        'eval_metric': 'mape'\n    }\n    \n    model = XGBRegressor(**params,\n                         tree_method=TREE_METHOD, \n                         booster=BOOSTER,\n                         random_state=SEED)\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=OPTUNA_ESR, verbose=False)\n    preds = model.predict(X_test)\n    score = smape(y_test, preds)\n    \n    return score\n\nstudy = optuna.create_study(direction=OPTUNA_DIRECTION)\nstudy.optimize(objective, n_trials=OPTUNA_TRIALS)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\n\nparams=study.best_params\nprint(params)","89c1d82c":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/time-series-oof-function-py\/time_series_oof_py.py\", dst = \"..\/working\/time_series_oof_py.py\")\n\nfrom time_series_oof_py import *","160bc9de":"model = XGBRegressor(**params,tree_method=TREE_METHOD,booster=BOOSTER,)\ndef smape_function(actual, predicted):\n    numerator = np.abs(predicted - actual)\n    denominator = (np.abs(actual) + np.abs(predicted)) \/ 2\n    \n    return np.mean(numerator \/ denominator)*100\n\ny = train[TARGET]\nX = train.drop(columns=[ID, DATE, TARGET])\nX_test = test.drop(columns=[ID, DATE])\n\npreds = timeSeriesOOF(5,X,y,X_test,model,smape_function)","afbbd2a2":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = preds\nsub.to_csv(SUBMISSION_PATH, index=False)\nsub.head()","3fb0c4e8":"# use time series OOF"}}