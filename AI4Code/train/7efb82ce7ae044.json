{"cell_type":{"50d269d9":"code","1f3f3a59":"code","d263d5d5":"code","cac1de55":"code","fe3ad869":"code","3cf2fa29":"code","da3a9c7f":"code","3ecd3341":"code","f8bcdd2a":"code","4ed02e45":"code","6f2f8f43":"code","be582734":"code","0b919ee1":"code","a94342ce":"code","0cd06d42":"code","db2a9329":"code","a174d032":"code","92297422":"code","0f43afc8":"code","238b9eef":"code","3cdb3bb4":"code","b55f9df5":"code","e2852e11":"code","94bbda61":"code","b0be4c5b":"code","0ee7ce5e":"code","d3a2ecbd":"code","f0112aa2":"code","84f58345":"code","a82b3419":"code","10f56c40":"code","e1fb2c88":"code","f33cc904":"code","71488d67":"code","41ff5e84":"code","c5231719":"code","6c2540ea":"code","ff34b204":"code","0ccb8b04":"code","1ccabfd5":"code","97fa90b4":"code","3bb2bdc9":"code","d949bbaf":"code","ee098397":"code","882dda20":"code","e5fc32d0":"code","963799d8":"code","bb20cb52":"code","8ccac7e9":"code","cbe26085":"code","0df03d6e":"code","37ffe793":"code","96461b7b":"code","a069c538":"code","75a7b4cc":"code","328d896b":"code","4a7e9d44":"code","9c77b3fd":"markdown","2fbca3ee":"markdown","d41fae77":"markdown","5c62ab74":"markdown","bd4a24cb":"markdown","84a6623f":"markdown","029423e5":"markdown","fb62b6be":"markdown","6062ee07":"markdown","16aec7f8":"markdown","90298764":"markdown","e7bd6f01":"markdown","ec1a6033":"markdown","206cca18":"markdown","b60f458c":"markdown"},"source":{"50d269d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f3f3a59":"df = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","d263d5d5":"import numpy as np\nimport pandas as pf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")","cac1de55":"df.head()","fe3ad869":"# Let's find the dimensions of dataset.\ndf.shape","3cf2fa29":"# Basic Information about the dataframe\ndf.info()","da3a9c7f":"# Let's checkout the datatypes present there. \ndf.dtypes","3ecd3341":"#Let's check out whether there are any null values present in dataset.\ndf.isnull().sum()","f8bcdd2a":"sns.pairplot(df)","4ed02e45":"px.scatter(df, x='free sulfur dioxide',y='total sulfur dioxide', color=df['quality'])","6f2f8f43":"diag = px.pie(df, values='quality', names='quality', hole=0.5)\ndiag.show()","be582734":"labels = df['quality'].unique()\nvalues = df['quality'].value_counts()\n\n# pull is given as a fraction of the pie radius\ndiag = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0.1, 0.2, 0.2, 0.2])])\ndiag.show()","0b919ee1":"diag = px.density_heatmap(df, x=\"alcohol\", y=\"quality\", nbinsx=25, nbinsy=10, color_continuous_scale=\"thermal\")\ndiag.show()","a94342ce":"diag = px.histogram(df, x=\"citric acid\", color=\"quality\",marginal=\"violin\")\ndiag.update_traces(opacity=.90)\ndiag.show()","0cd06d42":"diag = px.histogram(df, x=\"sulphates\", color=\"quality\",marginal=\"violin\")\ndiag.update_traces(opacity=.90)\ndiag.show()","db2a9329":"diag = px.density_contour(df, x=\"pH\", color=\"quality\")\ndiag.update_traces(opacity=0.90)\ndiag.show()","a174d032":"diag = px.histogram(df, x=\"volatile acidity\", color=\"quality\")\ndiag.update_traces(opacity=0.90)\ndiag.show()","92297422":"sns.factorplot(data=df, kind='box', size=10, aspect=1.5)","0f43afc8":"diag = px.violin(df, x=\"volatile acidity\",  color=\"quality\")\ndiag.update_traces(opacity=0.90)\ndiag.show()","238b9eef":"bins = (2, 6.5, 8)\ngroup_names = ['not good', 'good']\ndf['quality'] = pd.cut(df['quality'], bins=bins, labels=group_names)","3cdb3bb4":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encod = LabelEncoder()","b55f9df5":"df.quality = label_encod.fit_transform(df.quality)","e2852e11":"X = df.drop('quality', axis=1)\ny = df.quality","94bbda61":"### Train test split to avoid overfitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)","b0be4c5b":"X_train.head()","0ee7ce5e":"from sklearn.feature_selection import mutual_info_classif\n# determine the mutual information\nmutual_info = mutual_info_classif(X_train, y_train)\nmutual_info","d3a2ecbd":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","f0112aa2":"#let's plot the ordered mutual_info values per feature\nmutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))","84f58345":"from sklearn.feature_selection import SelectKBest","a82b3419":"#Now we Will select the  top 5 important features\nsel_five_cols = SelectKBest(mutual_info_classif, k=5)\nsel_five_cols.fit(X_train, y_train)\nX_train.columns[sel_five_cols.get_support()]","10f56c40":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report","e1fb2c88":"from sklearn.tree import DecisionTreeClassifier","f33cc904":"# Creating object of the model\n\nmodel_dt = DecisionTreeClassifier(max_depth=4, random_state=42)\nmodel_dt.fit(X_train, y_train)","71488d67":"pred_dt = model_dt.predict(X_test)\ndt  = round(accuracy_score(y_test, pred_dt)*100, 2)\nprint(dt) \n","41ff5e84":"print(classification_report(y_test, pred_dt))","c5231719":"# confusion Maxtrix\ncm2 = confusion_matrix(y_test, pred_dt)\nsns.heatmap(cm2\/np.sum(cm2), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"Decision Tree Classifier Confusion Matrix\",fontsize=12)\nplt.show()","6c2540ea":"from sklearn.ensemble import RandomForestClassifier\n# Creating model object\nmodel_rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=0.16, random_state=42)\n# Training Model\nmodel_rf.fit(X_train, y_train)","ff34b204":"# Making Prediction\npred_rf = model_rf.predict(X_test)\n# Calculating Accuracy Score\nrf = round(accuracy_score(y_test, pred_rf)*100, 2)\nprint(rf)","0ccb8b04":"print(classification_report(y_test,pred_rf))","1ccabfd5":"# confusion Maxtrix\ncm3 = confusion_matrix(y_test, pred_rf)\nsns.heatmap(cm3\/np.sum(cm3), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"RandomForest Classifier Confusion Matrix\",fontsize=12)\nplt.show()\n","97fa90b4":"from xgboost import XGBClassifier\n# Creating model object\n\nmodel_xgb = XGBClassifier(max_depth= 8, n_estimators= 125, random_state= 0,  learning_rate= 0.03, n_jobs=5)\n# Training Model\n\nmodel_xgb.fit(X_train, y_train)","3bb2bdc9":"# Making Prediction\n\npred_xgb = model_xgb.predict(X_test)\n# Calculating Accuracy Score\n\nxgb = round(accuracy_score(y_test, pred_xgb)*100, 2)\nprint(xgb)","d949bbaf":"print(classification_report(y_test,pred_xgb))","ee098397":"# confusion Maxtrix\ncm4 = confusion_matrix(y_test, pred_xgb)\nsns.heatmap(cm4\/np.sum(cm4), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"XGBoost Classifier Confusion Matrix\",fontsize=12)\nplt.show()","882dda20":"from sklearn.neighbors import KNeighborsClassifier\n# Creating model object\nmodel_kn = KNeighborsClassifier(n_neighbors=9, leaf_size=20)\n# Training Model\nmodel_kn.fit(X_train, y_train)","e5fc32d0":"# Making Prediction\npred_kn = model_kn.predict(X_test)\n# Calculating Accuracy Score\nkn = round(accuracy_score(y_test, pred_kn)*100, 2)\nprint(kn)","963799d8":"print(classification_report(y_test,pred_kn))","bb20cb52":"# confusion Maxtrix\ncm5 = confusion_matrix(y_test, pred_kn)\nsns.heatmap(cm5\/np.sum(cm5), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"KN Classifier Confusion Matrix\",fontsize=12)\nplt.show()\n","8ccac7e9":"from sklearn.svm import SVC, LinearSVC\nmodel_svm = SVC(kernel='rbf', random_state = 42)\nmodel_svm.fit(X_train, y_train)","cbe26085":"# Making Prediction\n\npred_svm = model_svm.predict(X_test)\n# Calculating Accuracy Score\nsv = round(accuracy_score(y_test, pred_svm)*100, 2)\nprint(sv)","0df03d6e":"print(classification_report(y_test,pred_kn))","37ffe793":"# confusion Maxtrix\ncm6 = confusion_matrix(y_test, pred_svm)\nsns.heatmap(cm6\/np.sum(cm6), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"SVM Classifier Confusion Matrix\",fontsize=12)\nplt.show()","96461b7b":"from sklearn.ensemble import AdaBoostClassifier\nmodel_ada = AdaBoostClassifier(learning_rate= 0.002,n_estimators= 205,random_state=42)\nmodel_ada.fit(X_train, y_train)","a069c538":"# Making Prediction\n\npred_ada = model_ada.predict(X_test)\n# Calculating Accuracy Score\n\nada = round(accuracy_score(y_test, pred_ada)*100, 2)\nprint(ada)","75a7b4cc":"print(classification_report(y_test,pred_ada))","328d896b":"# confusion Maxtrix\ncm7 = confusion_matrix(y_test, pred_ada)\nsns.heatmap(cm7\/np.sum(cm7), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"Adaboost Classifier Confusion Matrix\",fontsize=12)\nplt.show()","4a7e9d44":"models = pd.DataFrame({\n    'Model':[ 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM', 'AdaBoost'],\n    'Accuracy_score' :[dt, rf, xgb, kn, sv, ada]\n})\nmodels\nsns.barplot(x='Accuracy_score', y='Model', data=models)\n\nmodels.sort_values(by='Accuracy_score', ascending=False)","9c77b3fd":"***Context***\nThe two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\nThese datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are much more normal wines than excellent or poor ones).\n\n","2fbca3ee":"**AdaBoost Classifier**","d41fae77":"**Let's import required libraries.**","5c62ab74":"**There are no null values**","bd4a24cb":"**Random Forest**","84a6623f":"**Model Building\nDecision Tree Classifer**","029423e5":"**SVM**","fb62b6be":"****Content****\nFor more information, read [Cortez et al., 2009].\n\nInput variables (based on physicochemical tests):\n\n1 - fixed acidity\n\n2 - volatile acidity\n\n3 - citric acid\n\n4 - residual sugar \n\n5 - chlorides\n\n6 - free sulfur dioxide\n\n7 - total sulfur dioxide\n\n8 - density\n\n9 - pH\n\n10 - sulphates\n\n11 - alcohol\n\nOutput variable (based on sensory data):\n\n12 - quality (score between 0 and 10)","6062ee07":"**Data Visualization**","16aec7f8":"![](http:\/\/www.medbriefnamibia.com\/wp-content\/uploads\/2019\/07\/redwine.jpeg)","90298764":"**Data Pre-processing**","e7bd6f01":"**As there are so many features let's choose the important features.**","ec1a6033":"****Let's read the dataset****","206cca18":"**XGBoost Classifier**","b60f458c":"**KNeighbours**"}}