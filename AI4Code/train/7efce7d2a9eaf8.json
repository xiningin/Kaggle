{"cell_type":{"9c6dca36":"code","406c0211":"code","9d140b7c":"code","03847490":"code","b329ab06":"code","4bc5e745":"code","94dde923":"code","37655600":"code","e631dae6":"code","d229bceb":"code","7204c01d":"code","dfc7d40c":"code","02a56c54":"code","64a90fb6":"markdown"},"source":{"9c6dca36":"#import libraries \nimport tensorflow as tf \nimport tensorflow_datasets as tfds\nimport keras \nimport numpy as np \nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd \nfrom keras.applications import VGG19,Xception,VGG16\nfrom keras.layers import Dense , Conv2D , MaxPooling2D , Dropout,Flatten,Convolution2D\nfrom keras.models  import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\n\n","406c0211":"#access my drive\nfrom google.colab import drive\ndrive.mount('\/content\/drive')","9d140b7c":"#call vgg model\nvgg_model =  VGG19(include_top=True , weights='imagenet')\nfor models in vgg_model.layers:\n  models.trainable= False","03847490":"#converting from functionally model to sequential model\n#removing the last 2 alyer to get rid of output layer in VGG16\nvgg_model = keras.Model(inputs=vgg_model.input, outputs=vgg_model.layers[-2].output)\nmodel = keras.Sequential()\nfor layer in vgg_model.layers:\n  model.add(layer)","b329ab06":"#add trianbles layers\nmodel.add(Dense(4056, activation='relu'))\nmodel.add(Dropout(0.35))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n\nearly = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)\n","4bc5e745":"train_data = defect_tree = tf.keras.preprocessing.image_dataset_from_directory(\n    '\/content\/drive\/My Drive\/archive_(1)\/images',\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(224, 224),\n    shuffle=True,\n    seed=123,\n    validation_split=0.2,\n    subset=\"training\",\n    interpolation=\"bilinear\",\n    follow_links=False,\n)\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(\n    '\/content\/drive\/My Drive\/archive_(1)\/images',\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(224, 224),\n    shuffle=True,\n    seed=123,\n    validation_split=0.2,\n    subset=\"validation\",\n    interpolation=\"bilinear\",\n    follow_links=False,\n)","94dde923":"batch_size =32\nmodel.fit(train_data,\n    validation_data = test_data, \n    callbacks=[early],\n    epochs = 50)","37655600":"#evulate mmodel\nmodel.evaluate(test_data)","e631dae6":"#predict model\ny_pred = np.array([])\ny_true = np.array([])\ni = 0\n\nfor image,label in test_data : \n  i+=1\n  y = model.predict(image)\n  y = np.argmax(y,axis=1)\n  y_true = np.append(y_true,label)\n  y_pred = np.append(y_pred,y)\n  if i == 176 \/\/ 32 + 1:\n    break\n","d229bceb":"from  sklearn .metrics import classification_report,confusion_matrix\nreport=classification_report(y_true,y_pred)\nprint(report)","7204c01d":"cm= confusion_matrix(y_true,y_pred)\nprint(cm)","dfc7d40c":"import pandas as pd\nimport seaborn \ndf_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n                  columns = [i for i in [0,1]])\nseaborn .heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d')\nplt.title('confusion matrix')\nplt.xlabel('prediction')\nplt.ylabel('Actual');","02a56c54":"model.save(\"textile.h5\")","64a90fb6":"#Unblanced data \n\n\ni had to balance the data so here you could find new data and colab notebook  \n\n\n colab : [colab.research.google.com\/drive\/141XZ18NzQHcgkV1BAceFY43m9q6lveSv?usp=sharing](http:\/\/)\n \n newdata : https:\/\/drive.google.com\/drive\/folders\/1lV_LIy2XPnIHC5Kcd_d4PsE8sNs434U6?usp=sharing"}}