{"cell_type":{"5d53ba84":"code","27aa404c":"code","3fa2c49a":"code","1970a12a":"code","0f8342b0":"code","6abc35e3":"code","5ba28c1f":"code","0ca65ca2":"code","52f074bc":"code","ceedc27c":"code","e132483f":"code","7b74b01e":"code","75a3e814":"code","49238d92":"code","2992cf59":"code","675f59c5":"code","0d729bbb":"code","d9a5a46b":"code","00c71197":"code","f5f44ab9":"code","b0307282":"code","0f77931f":"code","190502c4":"code","a98fc4e6":"code","b74b4481":"code","bc5c591f":"code","fb1aaaa8":"code","a6ea7942":"code","188563df":"code","c0f27e86":"code","dc783b2e":"code","cc3e9098":"code","2094d9f2":"code","2a889fb2":"code","4871f48e":"code","9a5da8db":"code","d0640385":"code","f23415a1":"code","50f394f1":"code","039ea631":"code","c3a8d7ca":"code","da020438":"code","c5c0689a":"code","99d38f43":"code","d2a46632":"code","d07058fb":"code","27c236f5":"code","1b0a5563":"code","b99576dc":"code","849b771d":"code","a795a81a":"code","943d2cdb":"code","744a9742":"code","68fe9b42":"code","4e895dac":"code","321a7add":"code","7a9cfb70":"code","3d97ad94":"code","7ba5114f":"code","1521a321":"code","e02dc57e":"code","7b7a0439":"code","4a50f11c":"code","682450f2":"code","c7eadbfc":"code","697a11ee":"code","ab02b21c":"code","1bae9bd6":"code","af57a38b":"code","c78d1108":"code","41828aab":"code","16c48cfe":"code","57d7230a":"code","6c3b8caa":"code","b1cccf5a":"code","b5cbaff9":"code","ede74201":"code","a4b06046":"code","44b9bf80":"code","f7188743":"code","cd30f9af":"markdown","2be8a3df":"markdown","579e9b07":"markdown","31289d4f":"markdown","87dab0b0":"markdown","f1881024":"markdown","af1b96d3":"markdown","45c9b23f":"markdown","98942f48":"markdown","53fa3688":"markdown","1c05617e":"markdown","540ad07c":"markdown","b444dae2":"markdown","6c5c71bc":"markdown","307b42d1":"markdown","1053cb03":"markdown"},"source":{"5d53ba84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns                               # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27aa404c":"df_raw = pd.read_csv('\/kaggle\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv')","3fa2c49a":"df_raw.shape","1970a12a":"df_raw.head()","0f8342b0":"df_raw.tail()","6abc35e3":"df_raw.sample(5)","5ba28c1f":"df = df_raw.copy() # get the copy of raw data","0ca65ca2":"# get the information of data\ndf.info()","52f074bc":"df.describe()","ceedc27c":"sns.pairplot(df)\n\n# bath and price have slightly linear correlation with some outliers","e132483f":"# value count of each feature\ndef value_count(df):\n  for var in df.columns:\n    print(df[var].value_counts())\n    print(\"--------------------------------\")","7b74b01e":"value_count(df)","75a3e814":"# correlation heatmap\nnum_vars = [\"bath\", \"balcony\", \"price\"]\nsns.heatmap(df[num_vars].corr(),cmap=\"coolwarm\", annot=True)\n\n# correlation of bath is greater than a balcony with price","49238d92":"df.isnull().sum() # find the homuch missing data available","2992cf59":"df.isnull().mean()*100 # % of measing value\n\n#society has 41.3% missing value (need to drop)","675f59c5":"# visualize missing value using heatmap to get idea where is the value missing\n\nplt.figure(figsize=(16,9))\nsns.heatmap(df.isnull())","0d729bbb":"df2 = df.drop('society', axis='columns')\ndf2.shape","d9a5a46b":"# fill mean value in --------> balcony feature\n# because it contain 4.5% missing value\ndf2['balcony'] = df2['balcony'].fillna(df2['balcony'].mean())\ndf2.isnull().sum()","00c71197":"# drop na value rows from df2\n# because there is very less % value missing\ndf3 = df2.dropna()\ndf3.shape","f5f44ab9":"df3.isnull().sum().sum()","b0307282":"df3.head()","0f77931f":"# to show all th ecolumns and rows\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.max_rows\", None)","190502c4":"df3['total_sqft'].value_counts()\n\n# here we observe that 'total_sqft' contain string value in diff format\n#float, int like value 1689.28,817 \n# range value: 540 - 740 \n# number and string: 142.84Sq. Meter, 117Sq. Yards, 1Grounds\n\n# best strategy is to convert it into number by spliting it","a98fc4e6":"total_sqft_int = []\nfor str_val in df3['total_sqft']:\n  try:\n    total_sqft_int.append(float(str_val)) # if '123.4' like this value in str then conver in float\n  except:\n    try:\n      temp = []\n      temp = str_val.split('-')\n      total_sqft_int.append((float(temp[0])+float(temp[-1]))\/2) # '123 - 534' this str value split and take mean\n    except:\n      total_sqft_int.append(np.nan) # if value not contain in above format then consider as nan","b74b4481":"# reset the index of dataframe\ndf4 = df3.reset_index(drop=True) # drop=True - don't add index column in df","bc5c591f":"# join df4 and total_srft_int list\ndf5 = df4.join(pd.DataFrame({'total_sqft_int':total_sqft_int}))\ndf5.head()","fb1aaaa8":"df5.isnull().sum()","a6ea7942":"# drop na value\ndf6 = df5.dropna()\ndf6.shape","188563df":"df6.info()","c0f27e86":"df6.describe()","dc783b2e":"df6['size'].value_counts()\n\n# size feature shows the number of rooms ","cc3e9098":"size_int = []\nfor str_val in df6['size']:\n  temp=[]\n  temp = str_val.split(\" \")\n  try:\n    size_int.append(int(temp[0]))\n  except:\n    size_int.append(np.nan)\n    print(\"Noice = \",str_val)","2094d9f2":"df6 = df6.reset_index(drop=True)","2a889fb2":"# join df6 and list size_int\ndf7 = df6.join(pd.DataFrame({'bhk':size_int}))\ndf7.shape","4871f48e":"df7.tail()","9a5da8db":"# function to create histogram, Q-Q plot and boxplot\n\n# for Q-Q plots\nimport scipy.stats as stats\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n\n    # define figure size\n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.distplot(df[variable], bins=30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('Variable quantiles')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n\n    plt.show()","d0640385":"num_var = [\"bath\",\"balcony\",\"total_sqft_int\",\"bhk\",\"price\"]\nfor var in num_var:\n  print(\"******* {} *******\".format(var))\n  diagnostic_plots(df7, var)","f23415a1":"# here we consider  1 BHK requierd min 350 sqft are\ndf7[df7['total_sqft_int']\/df7['bhk'] < 350].head()\n\n# no we found outliers ","50f394f1":"# if 1 BHK total_sqft are < 350 then we ae going to remove them\ndf8 = df7[~(df7['total_sqft_int']\/df7['bhk'] < 350)]\ndf8.shape","039ea631":"#price in lakh so conver into rupee and then \/ by total_sqft_int\ndf8['price_per_sqft'] = df8['price']*100000 \/ df8['total_sqft_int']  \ndf8.head()","c3a8d7ca":"df8.price_per_sqft.describe()","da020438":"# Removing outliers using help of 'price per sqrt'  taking std and mean per location\ndef remove_pps_outliers(df):\n  df_out = pd.DataFrame()\n  for key, subdf in df.groupby('location'):\n    m=np.mean(subdf.price_per_sqft)\n    st=np.std(subdf.price_per_sqft)\n    reduced_df = subdf[(subdf.price_per_sqft>(m-st))&(subdf.price_per_sqft<=(m+st))]\n    df_out = pd.concat([df_out, reduced_df], ignore_index = True)\n  return df_out\n\ndf9 = remove_pps_outliers(df8)\ndf9.shape","c5c0689a":"def plot_scatter_chart(df,location):\n  bhk2 = df[(df.location==location) & (df.bhk==2)]\n  bhk3 = df[(df.location==location) & (df.bhk==3)]\n  plt.figure(figsize=(16,9))\n  plt.scatter(bhk2.total_sqft_int, bhk2.price, color='Blue', label='2 BHK', s=50)\n  plt.scatter(bhk3.total_sqft_int, bhk3.price, color='Red', label='3 BHK', s=50, marker=\"+\")\n  plt.xlabel(\"Total Square Feet Area\")\n  plt.ylabel(\"Price\")\n  plt.title(location)\n  plt.legend()\n\nplot_scatter_chart(df9, \"Rajaji Nagar\")","99d38f43":"plot_scatter_chart(df9, \"Hebbal\")","d2a46632":"# Removing BHK outliers\ndef remove_bhk_outliers(df):\n  exclude_indices = np.array([])\n  for location, location_df in df.groupby('location'):\n    bhk_stats = {}\n    for bhk, bhk_df in location_df.groupby('bhk'):\n      bhk_stats[bhk]={\n          'mean':np.mean(bhk_df.price_per_sqft),\n          'std':np.std(bhk_df.price_per_sqft),\n          'count':bhk_df.shape[0]}\n    for bhk, bhk_df in location_df.groupby('bhk'):\n      stats=bhk_stats.get(bhk-1)\n      if stats and stats['count']>5:\n        exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n  return df.drop(exclude_indices, axis='index')\n\ndf10 = remove_bhk_outliers(df9)\ndf10.shape","d07058fb":"plot_scatter_chart(df10, \"Hebbal\")","27c236f5":"df10.bath.unique()","1b0a5563":"df10[df10.bath > df10.bhk+2]","b99576dc":"# here we are considering data only total no. bathroom =  bhk + 1\ndf11 = df10[df10.bath < df10.bhk+2]\ndf11.shape","849b771d":"plt.figure(figsize=(16,9))\nfor i,var in enumerate(num_var):\n  plt.subplot(3,2,i+1)\n  sns.boxplot(df11[var])","a795a81a":"df12 = df11.drop(['area_type', 'availability',\"location\",\"size\",\"total_sqft\"], axis =1)\ndf12.head()","943d2cdb":"df12.to_csv(\"clean_data.csv\", index=False) ","744a9742":"df13 = df11.drop([\"size\",\"total_sqft\"], axis =1)\ndf13.head()","68fe9b42":"df14 = pd.get_dummies(df13, drop_first=True, columns=['area_type','availability','location'])\ndf14.shape\n","4e895dac":"df14.head()","321a7add":"df14.to_csv('oh_encoded_data.csv', index=False) ","7a9cfb70":"df13['area_type'].value_counts()","3d97ad94":"df15 = df13.copy()\n# appy Ohe-Hot  encoding on 'area_type' feature\nfor cat_var in [\"Super built-up  Area\",\"Built-up  Area\",\"Plot  Area\"]:\n  df15[\"area_type\"+cat_var] = np.where(df15['area_type']==cat_var, 1,0)\ndf15.shape","7ba5114f":"df15[\"availability\"].value_counts()","1521a321":"df15[\"availability_Ready To Move\"] = np.where(df15[\"availability\"]==\"Ready To Move\",1,0)\ndf15.shape","e02dc57e":"location_value_count = df15['location'].value_counts()\nlocation_value_count","7b7a0439":"location_gert_20 = location_value_count[location_value_count>=20].index\nlocation_gert_20","4a50f11c":"df16 = df15.copy()\nfor cat_var in location_gert_20:\n  df16['location_'+cat_var]=np.where(df16['location']==cat_var, 1,0)\ndf16.shape","682450f2":"df17 = df16.drop([\"area_type\",\"availability\",'location'], axis =1)\ndf17.shape","c7eadbfc":"df17.head()","697a11ee":"df17.sample(3)","ab02b21c":"df17.to_csv('ohe_data_reduce_cat_class.csv', index=False) ","1bae9bd6":"path = r\"https:\/\/drive.google.com\/uc?export=download&id=1P49POlAk27uRzWKXoR2WaEfb1lyyfiRJ\"","af57a38b":"df = pd.read_csv(path)\ndf.shape","c78d1108":"X = df.drop(\"price\", axis=1)\ny = df['price']\nprint('Shape of X = ', X.shape)\nprint('Shape of y = ', y.shape)","41828aab":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 51)\nprint('Shape of X_train = ', X_train.shape)\nprint('Shape of y_train = ', y_train.shape)\nprint('Shape of X_test = ', X_test.shape)\nprint('Shape of y_test = ', y_test.shape)","16c48cfe":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train)\nX_train= sc.transform(X_train)\nX_test = sc.transform(X_test)","57d7230a":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nlr = LinearRegression()\nlr_lasso = Lasso()\nlr_ridge = Ridge()","6c3b8caa":"def rmse(y_test, y_pred):\n  return np.sqrt(mean_squared_error(y_test, y_pred))","b1cccf5a":"lr.fit(X_train, y_train)\nlr_score = lr.score(X_test, y_test) # with all num var 0.7842744111909903\nlr_rmse = rmse(y_test, lr.predict(X_test))\nlr_score, lr_rmse","b5cbaff9":"# Lasso \nlr_lasso.fit(X_train, y_train)\nlr_lasso_score=lr_lasso.score(X_test, y_test) # with balcony 0.5162364637824872\nlr_lasso_rmse = rmse(y_test, lr_lasso.predict(X_test))\nlr_lasso_score, lr_lasso_rmse","ede74201":"from sklearn.svm import SVR\nsvr = SVR()\nsvr.fit(X_train,y_train)\nsvr_score=svr.score(X_test,y_test) # with 0.2630802200711362\nsvr_rmse = rmse(y_test, svr.predict(X_test))\nsvr_score, svr_rmse","a4b06046":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor()\nrfr.fit(X_train,y_train)\nrfr_score=rfr.score(X_test,y_test) # with 0.8863376025408044\nrfr_rmse = rmse(y_test, rfr.predict(X_test))\nrfr_score, rfr_rmse","44b9bf80":"import xgboost\nxgb_reg = xgboost.XGBRegressor()\nxgb_reg.fit(X_train,y_train)\nxgb_reg_score=xgb_reg.score(X_test,y_test) # with 0.8838865742273464\nxgb_reg_rmse = rmse(y_test, xgb_reg.predict(X_test))\nxgb_reg_score, xgb_reg_rmse","f7188743":"print(pd.DataFrame([{'Model': 'Linear Regression','Score':lr_score, \"RMSE\":lr_rmse},\n              {'Model': 'Lasso','Score':lr_lasso_score, \"RMSE\":lr_lasso_rmse},\n              {'Model': 'Support Vector Machine','Score':svr_score, \"RMSE\":svr_rmse},\n              {'Model': 'Random Forest','Score':rfr_score, \"RMSE\":rfr_rmse},\n              {'Model': 'XGBoost','Score':xgb_reg_score, \"RMSE\":xgb_reg_rmse}],\n             columns=['Model','Score','RMSE']))","cd30f9af":"# Preare Data for Machine Learning Model","2be8a3df":"# Exploratory Data Analysis","579e9b07":"# DATA CLEANING","31289d4f":"# Linear Regression","87dab0b0":"# Support Vector Machine","f1881024":"# Feature Scaling","af1b96d3":"# Remove outliers using the help of 'bath' feature","45c9b23f":"# Feature Engineering","98942f48":"# XGBoost","53fa3688":"# Drop categorical variable","1c05617e":"# Categorical Variable Encoding","540ad07c":"# Random Forest Regressor","b444dae2":"# THANK YOU","6c5c71bc":"# Split Dataset in train and test","307b42d1":"# Machine Learning Model Training","1053cb03":"# Finding Outlier and Removing"}}