{"cell_type":{"ceecdfda":"code","401aec2d":"code","b1b9561d":"code","ec8de778":"code","f91a489c":"code","f7f66de3":"code","30697e16":"code","47ffcf3e":"code","e6ed9de3":"code","2a7d3324":"code","0f923cab":"code","b0fc4146":"code","28cfeb21":"code","6f2abe9a":"code","35911e27":"code","6074383e":"code","1035c1e0":"code","a60f552b":"code","89040415":"code","003fa37b":"code","f9d09f6b":"code","ca768478":"code","cdeb605b":"code","459fc6cf":"code","a94168b1":"code","087af98b":"code","23857873":"code","9570b3a4":"code","e4da94ec":"code","6aa49922":"markdown","ca15b395":"markdown","751d9418":"markdown","b617bf4a":"markdown","5648e16e":"markdown","1cb4a9ca":"markdown","dd6d161a":"markdown","b905d285":"markdown","0c16ad3e":"markdown","c097fe5f":"markdown","ad9d267f":"markdown","0296212f":"markdown"},"source":{"ceecdfda":"# Python \u22653.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Is this notebook running on Colab or Kag\nIS_KAGGLE = \"kaggle_secrets\" in sys.modules\n\n# Scikit-Learn \u22650.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"classification\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)","401aec2d":"from sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1, as_frame=False)\nmnist.keys()","b1b9561d":"X, y = mnist[\"data\"], mnist[\"target\"]\nX.shape","ec8de778":"y.shape","f91a489c":"%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = X[1]\nsome_digit_image = some_digit.reshape(28, 28)\nplt.imshow(some_digit_image, cmap=mpl.cm.binary)\nplt.axis(\"off\")\n\nsave_fig(\"some_digit_plot\")\nplt.show()","f7f66de3":"#Y is seen to be 'literal', thus converting it into int using NUMPY\ny[0]","30697e16":"y = y.astype(np.uint32)","47ffcf3e":"#splitting test data and train data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.2, shuffle=True)","e6ed9de3":"X_train[0]","2a7d3324":"y[1]","0f923cab":"train_images = np.array(X_train)\ntrain_images = train_images.reshape(len(train_images), 28,28,1)\ntrain_images = train_images.astype(\"float32\")\ntrain_images = train_images \/ 255\ntrain_labels = np.array(y_train)","b0fc4146":"fig, axes = plt.subplots(4,5, figsize=(15, 15))\naxes = axes.ravel()\n\nfor i in np.arange(0, 20):\n    axes[i].imshow(train_images[i], cmap=\"Greys\")\n    axes[i].set_title(\"Digit = %s\" % train_labels[i])\n    axes[i].axis(\"off\")\n    plt.subplots_adjust()","28cfeb21":"#Lets Train Binary Classifier, identifying whether that data is \"0\" or \"not 0\"\ny_train_0 = (y_train == 0) \ny_test_0 = (y_test == 0)\n","6f2abe9a":"#training a model using SDGclassifies\nfrom sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train_0)\n","35911e27":"#now we can detect that image\nsgd_clf.predict([some_digit])","6074383e":"#try 2 for checking for other digit than 0\nother_digit = X_train[0]\nsgd_clf.predict([other_digit])","1035c1e0":"\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_0, cv=3, scoring=\"accuracy\")\n#98% of accuracy","a60f552b":"from sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_0, cv=3)","89040415":"from sklearn.metrics import confusion_matrix\nconf_mat = confusion_matrix(y_train_0, y_train_pred)\nprint(conf_mat)","003fa37b":"from sklearn.metrics import precision_score, recall_score\nprint('{0:.2f}% Precision'.format(precision_score(y_train_0, y_train_pred)*100))\nprint('{0:.2f}% Recall'.format(recall_score(y_train_0, y_train_pred)*100))","f9d09f6b":"from sklearn.svm import SVC\nsvm_clf = SVC()\nsvm_clf.fit(X_train, y_train) # y_train, not y_train_5\nsvm_clf.predict([some_digit])","ca768478":"some_digit_scores = svm_clf.decision_function([some_digit])\nsome_digit_scores","cdeb605b":"np.argmax(some_digit_scores)\nsvm_clf.classes_","459fc6cf":"svm_clf.classes_[0]","a94168b1":"sgd_clf.fit(X_train,y_train)\nsgd_clf.predict([some_digit])","087af98b":"sgd_clf.decision_function([some_digit])","23857873":" cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n","9570b3a4":"from sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\nconf_mx = confusion_matrix(y_train, y_train_pred)","e4da94ec":"plt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()","6aa49922":"Training Binary classifier with a Stochastic Gradient Descent (SGD) classifier","ca15b395":"sgd_clfll : this is the ratio of positive instances that are correctly detected by the classifier\naccuracy of the positive predictions;","751d9418":"SGDClassifier : supports multi-class classification by combining multiple binary classifiers in a \u201cone versus all\u201d (OVA) scheme","b617bf4a":"Explanation:\nwe used decision_fuction,which returned 10 score per instance \n\nOur some_digit = 0, as observed from output of decision_fuction,The highest score is indeed the one corresponding to class 0 in output of cell-24 ","5648e16e":"splitting dataset into test data and train data","1cb4a9ca":"This code trains the SVC on the training set using the original target\nclasses from 0 to 9 (y_train), instead of the 0-versus-the-rest target classes\n(y_train_5). Then it makes a prediction (a correct one in this case). Under the hood,\nScikit-Learn actually used the OvO strategy","dd6d161a":"lets try us to use SVM(simple vector machine) used for binary classifier for multiclassification, and see the result by sklearn","b905d285":"from above matrix, its clear that some numbers are accuratly predicted such as 1 which has pure white is predicted accurately, \nwhere as at(3,3) and (5,5), the pixel have slight high density. thus, we can say that this model is not 100% accurate.","0c16ad3e":"Lets Train Binary Classifier, identifying whether that data is \"0\" or \"not 0\"","c097fe5f":"using SDG classifier gives more promising result, as obsevered other than class 0 all other classes have negative value, lets check accuracy score","ad9d267f":"Error Analysis : by showing y_original vs y_pred","0296212f":"Now, lets dig into MultiClassifier\n\nthere are various strategies that you can use to perform multiclass classification\nwith multiple binary classifiers. such as:\none-versus-the-rest (OvR)\none-versus-one (OvO)\n\nwhen you try multiclassifier on binary classifier algorithm, sckit learn will detect and perfomr OvR or OvO depending on choosen algo."}}