{"cell_type":{"169cc18b":"code","025889ad":"code","32cafbaf":"code","de38d38a":"code","4d1f1a74":"code","e790f345":"code","aa4760ec":"code","a1a3bf62":"code","64365921":"code","105c2aa8":"code","9d78e92f":"code","958e5a0f":"code","3e75a767":"code","5ddb7e3d":"code","19fecc05":"code","002f49e6":"code","84795177":"code","405b57bd":"code","b43bde76":"code","f29308dc":"code","04b4d3a6":"markdown","961c64b5":"markdown","2314301c":"markdown","315ee8df":"markdown","bafe9a3a":"markdown","300bac3f":"markdown","651c2b27":"markdown"},"source":{"169cc18b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","025889ad":"import numpy as np                                                    #importing all the necessary libraraies\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer","32cafbaf":"data     = pd.read_csv('..\/input\/spotifydata-19212020\/data.csv')                    #reading data file\nprint('Rows in Data       :',data.shape[0])                                         #display no of rows\nprint('Columns in Data    :',data.shape[1],'\\n',data.columns)                       #display no of columns","de38d38a":"data.info()                                                                                      #data.info()","4d1f1a74":"data.describe(include='all')                                                                 #data.describe()","e790f345":"cat_cols = [cols for cols in data if data[cols].dtypes=='O']                    #checking category columns\nnum_cols = [cols for cols in data if data[cols].dtypes=='float64']              #checking continuous columns\nint_cols = [cols for cols in data if data[cols].dtypes=='int64']                #checking discrete columns\nprint('Category Columns    :',cat_cols)\nprint('Continuous Columns  :',num_cols)\nprint('Discrete Columns    :',int_cols)","aa4760ec":"for cols in cat_cols:                                                            #checking same songs\/artists\n    print(cols ,len(data[cols].value_counts()))\nprint(data.duplicated().value_counts())","a1a3bf62":"plt.figure(figsize=(25,6))\nplt.subplot(131)\nsns.countplot(data['key'])\nplt.subplot(132)\nsns.countplot(data['explicit'])\nplt.subplot(133)\nsns.countplot(data['mode'])\nplt.show()","64365921":"for cols in num_cols:\n    plt.figure(figsize=(20,5))\n    \n    plt.subplot(131)\n    sns.kdeplot(data[cols],color='g',shade=True)\n    plt.title(cols+' Distribution')\n\n    plt.subplot(132)\n    sns.boxplot(y = data[cols],color='pink')\n    plt.title(cols+' Boxplot')\n    \n    plt.subplot(133)\n    sns.scatterplot(x=cols,y='popularity',data=data)\n    plt.title(cols+' versus popularity')\n    \n    plt.show()","105c2aa8":"rows=5\ncolumns=3\nfig=plt.figure(figsize=(25,40))\nfor i,cols in enumerate (data.select_dtypes(include=['int64','float64']).columns):\n    ax=plt.subplot(rows,columns,i+1)\n    sns.lineplot(x='year',y=cols,data=data,ax=ax,color='r')\n    ax.set_title(cols+'yearwise')\nfig.tight_layout()\nplt.show()","9d78e92f":"plt.figure(figsize=(12,10))\nsns.heatmap(data.corr(),annot=True)\nb,t=plt.ylim()\nb+=0.5\nt-=0.5\nplt.ylim(b,t)\nplt.show()","958e5a0f":"print(data.skew())","3e75a767":"data.min()","5ddb7e3d":"#As we can see our data is skewed and also has some negative values, we will transform this to make our data more normal and positive.\npt = PowerTransformer(method='yeo-johnson', standardize=True) \ndata_scaled = pd.DataFrame(pt.fit_transform(data[['duration_ms','instrumentalness','liveness','speechiness','loudness']]), \n                           columns=['duration_ms','instrumentalness','liveness','speechiness','loudness'])","19fecc05":"data_scaled.min()","002f49e6":"data_scaled.skew()","84795177":"num_cols = ['duration_ms','instrumentalness','liveness','speechiness','loudness']\nfor cols in num_cols:\n    plt.figure(figsize=(20,5))\n    \n    plt.subplot(131)\n    sns.kdeplot(data[cols],color='g',shade=True)\n    plt.title(cols+' Distribution')\n\n    plt.subplot(132)\n    sns.kdeplot(data_scaled[cols],color='b',shade=True)\n    plt.title(cols+' Distribution after scaling')\n    \n    plt.subplot(133)\n    sns.boxplot(y = data_scaled[cols],color='pink')\n    plt.title(cols+' Boxplot')\n    \n    plt.show()","405b57bd":"data['duration_ms']      = data_scaled['duration_ms']+9\ndata['instrumentalness'] = data_scaled['instrumentalness']+1\ndata['liveness']         = data_scaled['liveness']+3\ndata['speechiness']      = data_scaled['speechiness']+3\ndata['loudness']         = data_scaled['loudness']+5","b43bde76":"plt.figure(figsize=(12,6))\nx = data.groupby(\"name\")[\"popularity\"].mean().sort_values(ascending=False).head(10)\nax = sns.barplot(x.index, x)\nax.set_title('Top Song with Popularity')\nax.set_ylabel('Popularity')\nax.set_xlabel('Songs')\nplt.xticks(rotation = 90)","f29308dc":"plt.figure(figsize=(12,6))\nx = data.groupby(\"artists\")[\"popularity\"].sum().sort_values(ascending=False).head(10)\nax = sns.barplot(x.index, x)\nax.set_title('Top Artists with Popularity')\nax.set_ylabel('Popularity')\nax.set_xlabel('Artists')\nplt.xticks(rotation = 90)","04b4d3a6":"Our data seems to have normalized better now, hence we'll transform our original data columns and change the negative values to positive","961c64b5":"# EXPLORATOTY DATA ANALYSIS ","2314301c":"## Average Change in features over the years","315ee8df":"We see that our data is not completely normalized and also, there are outliers as well as negative values in our dataset. We would take care of them.","bafe9a3a":"### Distribution of Discrete Features","300bac3f":"We see that there are repetitive songs and artists in our dataset. Although, there are no duplicated rows. They have unique id's.","651c2b27":"### Distribution of continuous features and relationship with Popularity"}}