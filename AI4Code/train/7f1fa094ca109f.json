{"cell_type":{"44bb4926":"code","05f20e4d":"code","aabb122b":"code","aa45d3ea":"code","cc2fcc34":"code","55f99c38":"code","4654887b":"code","9f715d25":"code","c9ace534":"code","fb480e74":"code","63b58e8d":"code","28425310":"code","c5947e2a":"code","bebee51d":"code","3f0e41cc":"code","8a6d0f74":"code","c33718a5":"code","ca1b14d2":"code","622dbf67":"code","b1a48c09":"code","c1b3f68c":"code","bd4e3bdc":"code","eff754ed":"code","7044a11a":"code","5709a548":"code","4de4d4e3":"code","283065fc":"code","11c40213":"code","849f4b5e":"code","89acda6a":"code","135e6e3c":"code","859465dd":"code","0f82c928":"code","d00187a8":"code","7077217c":"code","7d898315":"code","befb635b":"markdown","81a21985":"markdown","d72768da":"markdown","3ed745a9":"markdown","cdded20c":"markdown","b9b1ce92":"markdown","d0283b0b":"markdown","395691fb":"markdown","512c4fbc":"markdown","bb463782":"markdown","00b800c5":"markdown","fd7b1503":"markdown","1d7d5ff6":"markdown"},"source":{"44bb4926":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","05f20e4d":"dataset = pd.read_csv(\"..\/input\/wine-m\/train.csv\")","aabb122b":"dataset.head()","aa45d3ea":"dataset.info()","cc2fcc34":"dataset.describe()","55f99c38":"print(dataset.target.value_counts())\ndataset.target.value_counts().plot(kind='bar')\nplt.show()","4654887b":"fig, ax = plt.subplots(5,3 , figsize = (15,20)) # Making Subplots\n\nsns.barplot(data = dataset, y =\"alcohol\", x=\"target\", ax=ax[0,0]);\nsns.barplot(data = dataset, y =\"malic_acid\", x=\"target\", ax=ax[0,1]);\nsns.barplot(data = dataset, y =\"ash\", x=\"target\", ax=ax[0,2]);\nsns.barplot(data = dataset, y =\"alcalinity_of_ash\", x=\"target\", ax=ax[1,0]);\nsns.barplot(data = dataset, y =\"magnesium\", x=\"target\", ax=ax[1,1]);\nsns.barplot(data = dataset, y =\"total_phenols\", x=\"target\", ax=ax[1,2]);\nsns.barplot(data = dataset, y =\"flavanoids\", x=\"target\", ax=ax[2,0]);\nsns.barplot(data = dataset, y =\"nonflavanoid_phenols\", x=\"target\", ax=ax[2,1]);\nsns.barplot(data = dataset, y =\"proanthocyanins\", x=\"target\", ax=ax[2,2]);\nsns.barplot(data = dataset, y =\"color_intensity\", x=\"target\", ax=ax[3,0]);\nsns.barplot(data = dataset, y =\"hue\", x=\"target\", ax=ax[3,1]);\nsns.barplot(data = dataset, y =\"od280\/od315_of_diluted_wines\", x=\"target\", ax=ax[3,2]);\nsns.barplot(data = dataset, y =\"proline\", x=\"target\", ax=ax[4,0]);","9f715d25":"# Splitting datset to X and y axis \n\nX=dataset.iloc[: , 1:14].values\ny=dataset.iloc[: ,-1].values","c9ace534":"X","fb480e74":"y","63b58e8d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)","28425310":"#Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","c5947e2a":"# Adding layers and activation function\n\nimport tensorflow as tf\nann=tf.keras.models.Sequential()\n\nann.add(tf.keras.layers.Dense(units=6,activation='relu'))\nann.add(tf.keras.layers.Dense(units=6,activation='relu'))\nann.add(tf.keras.layers.Dense(units=1,activation='tanh'))\n\n#Compiling\nann.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])","bebee51d":"# Training the model\n\nann.fit(X_train,y_train,batch_size=32,epochs=200)","3f0e41cc":"# Prediction on Test data\n\ny_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","8a6d0f74":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c33718a5":"# KNN:K Nearest Neighbour\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train,y_train)","ca1b14d2":"# Training the model\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","622dbf67":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","b1a48c09":"# Training the model\nfrom sklearn.tree import DecisionTreeClassifier  \nclassifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  \nclassifier.fit(X_train, y_train)  ","c1b3f68c":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","bd4e3bdc":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","eff754ed":"# Training the model  \nfrom sklearn.naive_bayes import GaussianNB  \nclassifier = GaussianNB()  \nclassifier.fit(X_train, y_train)  ","7044a11a":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","5709a548":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","4de4d4e3":"# Training the model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg = logreg.fit(X_train,y_train)\n","283065fc":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","11c40213":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","849f4b5e":"# Training the model\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state = 1)\nclassifier.fit(X_train,y_train)","89acda6a":"# Predicting the values\ny_pred=classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\nfinal_classifier = classifier    # since max quality is for SVM so we have stored this in a final variable","135e6e3c":"# Calculating quality for model\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","859465dd":"# In this case maximum quality is for SVM so we will use this algorithm\n\nfin_test_data = pd.read_csv('..\/input\/wine-m\/test.csv')\ntest_data = fin_test_data.drop('id',axis=1)\ntest_data = sc.fit_transform(test_data)","0f82c928":"final_pred = final_classifier.predict(test_data)\nfinal_pred","d00187a8":"sample_submit = pd.read_csv('..\/input\/wine-m\/sample_submit.csv')\nsample_submit","7077217c":"output = pd.DataFrame({'id':fin_test_data.id,'target':final_pred})\noutput.to_csv('my_submission.csv', index=False)\nfilename = \"my_submission.csv\"\nprint(\"Your submission was successfully saved!\")","7d898315":"# Download the CSV file created above\n\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\n\ndef create_download_link(title = \"Download CSV file\", filename = filename):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename=filename)","befb635b":"### Applying KNN","81a21985":"### Applying Naive Bayes","d72768da":"### Applying ANN","3ed745a9":"## Machine Learning Models","cdded20c":"## Data Visualisation","b9b1ce92":"### Applying Decision Tree","d0283b0b":"# Model Selection","395691fb":"## Loading Dataset","512c4fbc":"## Importing Libraries","bb463782":"## Splitting Data in Train and Test","00b800c5":"## Final Prediction Using most Efficient algorithm\n","fd7b1503":"### Support Vector Machine","1d7d5ff6":"### Logistic Regression"}}