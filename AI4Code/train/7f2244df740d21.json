{"cell_type":{"3b10513f":"code","8b3a27f7":"code","bff886cf":"code","a65e176e":"code","df4878be":"code","36ea9e35":"code","438f8154":"code","481882ef":"code","1eb893b3":"code","8de2a275":"code","63054957":"code","59b6039a":"code","bf772166":"code","ff81fdf0":"code","8085fb62":"code","d771556f":"code","00cad374":"code","0aea5f41":"code","df0294e2":"code","8ef040ca":"code","d8d33d49":"code","a8514ca6":"code","17a404a7":"code","e911b5ac":"code","f4a2bd15":"markdown","273b26ee":"markdown","92f4ad50":"markdown","57c95129":"markdown"},"source":{"3b10513f":"import numpy as np \nimport pandas as pd \ndataset = pd.read_csv('..\/input\/Churn_Modelling.csv')\ndataset.head()","8b3a27f7":"dataset.info()","bff886cf":"dataset = dataset.drop(['RowNumber','CustomerId','Surname'], axis=1)\ndataset.head()","a65e176e":"geography = pd.get_dummies(dataset['Geography'],drop_first=True)\n# similarly for this colimn as well. If there are n dummy columns, consider n-1\ngender = pd.get_dummies(dataset['Gender'],drop_first=True)","df4878be":"dataset = dataset.drop(['Geography','Gender'], axis=1)\ndataset = pd.concat([dataset,geography,gender],axis=1)\ndataset.head()","36ea9e35":"X = dataset.drop(\"Exited\",axis=1)\ny = dataset['Exited']","438f8154":"# Splitting the dataset into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 0)\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","481882ef":"X_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","1eb893b3":"#Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\n# Initialising the ANN\nclassifier = Sequential()","8de2a275":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform',activation = 'sigmoid'))","63054957":"# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","59b6039a":"classifier.summary()","bf772166":"#Fitting the ANN to the Training set\nhistory = classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)","ff81fdf0":"#history\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred[:5]","8085fb62":"# Making the classification report\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(y_test,y_pred))\n","d771556f":"print(accuracy_score(y_test, y_pred)*100)","00cad374":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","0aea5f41":"score = classifier.evaluate(X_test,y_test)\nprint(score)\nprint('loss = ', score[0])\nprint('acc = ', score[1])","df0294e2":"# change the epochs to 5, 10 from 2\n# we got 79% acc with 2 & 5 & 20 epochs with SGD\n# we got 83% acc with 20 epochs with adam\n# Initialising the ANN\nclassifier = Sequential()\nclassifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n# Adding the second hidden layer\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the third hidden layer\nclassifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)","8ef040ca":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred[:5]","d8d33d49":"\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(y_test,y_pred))","a8514ca6":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","17a404a7":"score = classifier.evaluate(X_test,y_test)\nprint(score)\nprint('loss = ', score[0])\nprint('acc = ', score[1])","e911b5ac":"print(accuracy_score(y_test, y_pred)*100)","f4a2bd15":"There are no null values in the data, hence the data is clean. Remove the columns that are not required for the dataset and changing the dataframe to numpy array by dividing the dependent and independent variables.","273b26ee":"Making the Confusion Matrix","92f4ad50":"Feature selection, converting the categorical to numerical.","57c95129":"Spearating dependent and independent variables."}}