{"cell_type":{"a0488901":"code","4da27026":"code","7e6c87a3":"code","85b13e3d":"code","a5ee46a8":"code","a2c3cfb5":"code","e2666224":"code","e31892d7":"code","9520630c":"code","ac75884f":"code","a7d02665":"code","c8eac9d4":"code","ec95572e":"code","e15430f9":"code","d39fbad9":"code","f601bb2d":"code","3cd3d5cc":"code","6f6f503a":"code","79855f3f":"code","4faa176a":"code","3e508db7":"markdown","e3e66908":"markdown","51d3dd47":"markdown","e007cdb0":"markdown","c4de767c":"markdown","15bf25d8":"markdown","c2780e06":"markdown","a4b6e080":"markdown","473d6831":"markdown","53a5b59c":"markdown"},"source":{"a0488901":"import numpy as np \nimport pandas as pd \nimport os, gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport math\nimport lightgbm as lgb\nimport xgboost as xgb\nimport optuna\n\nfrom sklearn.metrics import mean_squared_error, accuracy_score, log_loss\nfrom sklearn.model_selection import KFold, GridSearchCV, train_test_split, StratifiedKFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore')","4da27026":"PATH = '..\/input\/tabular-playground-series-apr-2021\/'\n\ntrain = pd.read_csv(PATH + 'train.csv')\ntest = pd.read_csv(PATH + 'test.csv')\nsample = pd.read_csv(PATH + 'sample_submission.csv')\n\nprint(train.shape, test.shape)","7e6c87a3":"train.head(10)","85b13e3d":"test.head(10)","a5ee46a8":"train.info()","a2c3cfb5":"test.info()","e2666224":"fig, ax = plt.subplots(1, 2, figsize=(16, 6))\nsns.distplot(train['Survived'], ax=ax[0])\nsns.countplot(train['Survived'], ax=ax[1])","e31892d7":"train.describe()","9520630c":"FEATURES = train.drop(['PassengerId', 'Survived'], 1).columns\nFEATURES","ac75884f":"train.head(5)","a7d02665":"fig, ax = plt.subplots(3, 2, figsize=(20, 18))\nax = ax.flatten()\n\nfor k, i in enumerate(['Pclass', 'Sex', 'Embarked', 'Parch', 'SibSp']):\n    sns.countplot(train[i], hue=train['Survived'], ax=ax[k])","c8eac9d4":"fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n\nfor k, i in enumerate(['Fare', 'Age']):\n    sns.distplot(train.loc[train['Survived'] == 1, i], ax=ax[k], label='1')\n    sns.distplot(train.loc[train['Survived'] == 0, i], ax=ax[k], label='0')\n    ax[k].legend()","ec95572e":"for i in ['Sex', 'Embarked']:\n    le = LabelEncoder()\n    le.fit(train[i])\n    train[i] = le.transform(train[i])\n    test[i] = le.transform(test[i])\n\ntrain.head()","e15430f9":"x = train.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(x, annot=True)","d39fbad9":"cv = StratifiedKFold(n_splits=5, shuffle=True)\ncv","f601bb2d":"FEATURES = ['Pclass', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Fare', 'Embarked']","3cd3d5cc":"X = train[FEATURES]\ny = train.Survived\nprint(X.shape, y.shape)","6f6f503a":"oof_df = train[['PassengerId', 'Survived']].copy()\nfold_ = 1\n\n\nfor train_idx, val_idx in cv.split(X, y):\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    model = lgb.LGBMClassifier()\n    model.fit(X_train, y_train)\n\n    val_preds = model.predict(X_val)\n    test_preds = model.predict(\n        test[FEATURES])\n\n    oof_df.loc[oof_df.iloc[val_idx].index, 'oof'] = val_preds\n    sample[f'fold{fold_}'] = test_preds\n\n    score = accuracy_score(\n        oof_df.loc[oof_df.iloc[val_idx].index]['Survived'], oof_df.loc[oof_df.iloc[val_idx].index]['oof'])\n    print(score)\n    fold_ += 1","79855f3f":"print(accuracy_score(oof_df.Survived, oof_df.oof))\nsample['Survived'] = sample.drop(['PassengerId', 'Survived'], 1).mode(axis=1)\nsample[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)","4faa176a":"sns.countplot(sample['Survived'])","3e508db7":"## <a>EDA<\/a>\n\nLet's first check the distribution of target variable.\n","e3e66908":"## <a>Loading Packages and Data<\/a>","51d3dd47":"In both the datasets, only 'Age', 'Ticket', 'Fare', 'Cabin' and 'Embarked' features have missing values.","e007cdb0":"This time we've missing values unlike the previous competitions of the series. ","c4de767c":"Both train and test are same sized datasets. Let's take a look at the train set.\n","15bf25d8":"## <a>Introduction<\/a>\n\nIn this competition, we are given a classification task. We will be predicting a binary target based on a number of feature columns given in the data. The dataset is based on the Titanic dataset and this time the features are not anonymized.\n\nLet's get started.","c2780e06":"The dataset is somewhat imbalanced, but we've enough features from both the classes. ","a4b6e080":"## <a>Model<\/a>","473d6831":"1. **Pclass** : From 1st(upper) and 2nd(middle) class, the number of passengers who survived is comparable to the number of passengers who didn't. But in 3rd(lower) class, 75% didn't survive.\n\n2. **Sex** : Over 80% of men didn't survive whereas approx. 66% of women survived. \n\n3. **Embarked** :  C = Cherbourg, Q = Queenstown, S = Southampton\n   Most of the passenger embarked from Southampton and over 50k didn't survive.","53a5b59c":"Let's separately analyze feature w.r.t the target variable. "}}