{"cell_type":{"5fa52a3c":"code","1f9bc984":"code","a7882283":"code","169548c9":"code","302fb12f":"code","ad8fe85b":"code","1bec8a5a":"code","f9d74f9e":"code","405acd07":"code","8eb7b9cc":"code","817334f1":"code","7c981f45":"code","e407933d":"code","e1281311":"code","cff98954":"code","5b3b95e7":"code","3fbef62c":"code","0a9f5e8c":"code","fe79dce1":"code","2a60b496":"code","94dd7d23":"code","c30ec225":"code","7892cc04":"code","a6aae2fb":"code","dcc51b07":"code","cf4c0995":"code","bbeb8de1":"code","e40f93bc":"code","94fa47ed":"code","c0b68ccc":"code","3d8c518a":"code","59ce6ea7":"code","d66a2cfa":"code","e652e7e4":"code","97e71e54":"code","9ce65719":"code","3d5000b7":"code","7e3a4058":"code","f6bf0ee9":"code","74fd6533":"code","2ad3c632":"code","2f42302f":"code","a0aa1b60":"code","787d06aa":"code","c32e2949":"code","c2cd4523":"code","32f23dd6":"code","8b1a3e0f":"code","92de4eab":"code","90c6a7e0":"code","ca8e34e8":"code","cc0ec4d5":"code","d5c263c9":"code","1ffb3de5":"code","53a972b9":"code","9308700c":"code","a12fabb8":"code","7c1e45ef":"code","5bf344ad":"code","b4173037":"code","fb8125ff":"code","4c2f8a76":"code","83b0ab04":"code","61ada3fa":"code","dce02672":"code","a31b1b56":"code","72744749":"code","be190b34":"code","819caa14":"code","a27015d3":"code","57ac466e":"code","815f9879":"code","e16dce98":"code","ff69df08":"code","9aa1cdfb":"code","2fa6115d":"code","598c022e":"code","267810e6":"code","64d8e6f7":"markdown","238ba775":"markdown","20bbdc01":"markdown","0dc0453c":"markdown","a50053ca":"markdown","8112481c":"markdown","af73bb24":"markdown","eb004f60":"markdown","790a7b04":"markdown","8888aaea":"markdown","ce8c126e":"markdown","414001a6":"markdown","2ecaf5e8":"markdown","baa0db40":"markdown","c4c11c5b":"markdown","738a7069":"markdown","b5fdc137":"markdown","1368b131":"markdown","930b3d39":"markdown","6900df69":"markdown","e6e4cadf":"markdown","b69f07ad":"markdown","c4293a2d":"markdown","1523ece8":"markdown","ae278e8c":"markdown","5331dd7a":"markdown","c891bfdd":"markdown"},"source":{"5fa52a3c":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, ElasticNet\n\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\npd.set_option('max_columns', None)\npd.set_option('max_rows', None)\nimport warnings\nwarnings.filterwarnings('ignore')","1f9bc984":"train_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsubmision_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","a7882283":"train_data.head()","169548c9":"train_data.info()","302fb12f":"train_data.isna().sum()","ad8fe85b":"#Drop Id column\ntrain_data = train_data.drop('Id', axis=1)","1bec8a5a":"#Fill LotFrontage with mean values\nmeanLot = train_data['LotFrontage'].mean()\ntrain_data['LotFrontage'] = train_data['LotFrontage'].fillna(meanLot)","f9d74f9e":"#Fill GarageYrBlt with constant 0 value for houses with no grarage or masonry\ntrain_data['GarageYrBlt'] = train_data['GarageYrBlt'].fillna(0)\ntrain_data['MasVnrArea'] = train_data['MasVnrArea'].fillna(0)","405acd07":"#Change data type of MSSubClass to repersent categorical data\ntrain_data['MSSubClass'] = train_data['MSSubClass'].astype(str)","8eb7b9cc":"train_data.isna().sum()","817334f1":"train_data.select_dtypes('object').loc[:, train_data.isna().sum() > 0].columns","7c981f45":"#Fill missing values with constant\nfor column in ['Alley', \n               'BsmtQual', \n               'BsmtCond',\n               'BsmtExposure', \n               'BsmtFinType1', \n               'BsmtFinType2',\n               'FireplaceQu', \n               'GarageType', \n               'GarageFinish',\n               'GarageQual', \n               'GarageCond',\n               'PoolQC', \n               'Fence'\n              ]:\n    train_data[column] = train_data[column].fillna('none')\n#Fill missing values with mode\nfor column in ['MasVnrType', \n               'Electrical', \n               'MiscFeature']:\n    mode = train_data[column].mode()\n    train_data[column] = train_data[column].fillna(mode[0])","e407933d":"train_data.isna().sum().sum()","e1281311":"numeric_corr = train_data.corr()\ncorr_pairs = numeric_corr.unstack()","cff98954":"#Find the numeric features which have the highest correlation with Sale Price\nsorted_corr = corr_pairs['SalePrice'].sort_values(ascending=False).apply(abs)\nhighNumeric = sorted_corr[sorted_corr > 0.5]\nhighNumeric","5b3b95e7":"sns.regplot(x='OverallQual', y='SalePrice', data=train_data, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\nplt.title('Overall Quality of Materials vs Sale Price')\nplt.xlabel('Overall Quality of Materials')\nplt.ylabel('Sale Price')\nplt.show()","3fbef62c":"sns.regplot(x='GrLivArea', y='SalePrice', data=train_data, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\nplt.title('Above grade (ground) Living Area  vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","0a9f5e8c":"sns.regplot(x='GarageCars', y='SalePrice', data=train_data, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\nplt.title('Size of Garage vs Sale Price')\nplt.xlabel('Size of Garage (car capacity)')\nplt.ylabel('Sale Price')\nplt.show()","fe79dce1":"sns.regplot(x='GarageArea', y='SalePrice', data=train_data, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\nplt.title('Garage Area vs Sale Price')\nplt.xlabel('Garage Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","2a60b496":"sns.regplot(x='TotalBsmtSF', y='SalePrice', data=train_data, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\nplt.title('Basement Area vs Sale Price')\nplt.xlabel('Basment Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","94dd7d23":"df_cat = train_data.copy()\ndf_cat = df_cat.select_dtypes('object')\ndf_cat.head()","c30ec225":"for column in df_cat.columns:\n    df_cat[column] = df_cat[column].astype('category').cat.codes","7892cc04":"df_cat = pd.concat([df_cat, train_data['SalePrice']], axis=1)\ndf_cat.head()","a6aae2fb":"cat_corr = df_cat.corr()\ncatcorr_pairs = cat_corr.unstack()","dcc51b07":"#Find the categorical features which have the highest correlation with Sale Price\nsorted_Catcorr = catcorr_pairs['SalePrice'].sort_values(ascending=False).apply(abs)\nhighCat = sorted_Catcorr[sorted_Catcorr >= 0.5]\nhighCat","cf4c0995":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='ExterQual')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","bbeb8de1":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='BsmtQual')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","e40f93bc":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='KitchenQual')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","94fa47ed":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='GarageFinish')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","c0b68ccc":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='FireplaceQu')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","3d8c518a":"sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_data, hue='GarageType')\nplt.title('Above Ground Living Area vs Sale Price')\nplt.xlabel('Above grade (ground) Living Area (sqft)')\nplt.ylabel('Sale Price')\nplt.show()","59ce6ea7":"import scipy.stats\ndf_skew = pd.DataFrame(train_data.select_dtypes(np.number).columns, columns=['Features'])\ndf_skew['Skew'] = df_skew['Features'].apply(lambda feature: scipy.stats.skew(train_data[feature]))\ndf_skew['Abs Skew'] = df_skew['Skew'].apply(abs)\ndf_skew['Skewed'] = df_skew['Abs Skew'].apply(lambda x: True if x >= 0.5 else False)\ndf_skew","d66a2cfa":"df_skew.query('Skewed == True')['Features']","e652e7e4":"for column in df_skew.query('Skewed == True')['Features'].values:\n    train_data[column] = np.log1p(train_data[column])","97e71e54":"features = train_data[['OverallQual', 'GrLivArea', \n                       'GarageCars', 'GarageArea', \n                       'TotalBsmtSF', '1stFlrSF', \n                       'FullBath', 'TotRmsAbvGrd', \n                       'YearBuilt', 'YearRemodAdd', \n                       'MasVnrArea', 'Fireplaces', \n                       'GarageFinish', 'KitchenQual', \n                       'BsmtQual', 'ExterQual', 'SalePrice']]\nfeatures.head()","9ce65719":"features.shape","3d5000b7":"features.select_dtypes('object').head()","7e3a4058":"ordinal_features = ['KitchenQual',\n                    'BsmtQual',\n                    'ExterQual']\n\nnominal_features = 'GarageFinish'","f6bf0ee9":"ordinal_orderings = [\n    ['Ex', 'Gd', 'TA', 'Fa', 'Po'],\n    ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'none'],\n    ['Ex', 'Gd', 'TA', 'Fa', 'Po']\n]","74fd6533":"#Ordinal Encoding\ndef ordinal_encode(df, columns, orderings):\n    df = df.copy()\n    for column, ordering in zip(columns, orderings):\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n\n#One-hot Encode Categorical Variables\ndef onehot_encode(df):\n    df = df.copy()\n    for column in df[[nominal_features]]:\n        features_one_hot = pd.get_dummies(df[column])\n        df = pd.concat([df, features_one_hot], axis =1)\n        df = df.drop(column, axis=1)\n    return df\n\ndata = ordinal_encode(features, ordinal_features, ordinal_orderings)\ndata = onehot_encode(data)\ndata.head()","2ad3c632":"data.shape","2f42302f":"data = data.astype('float64')\ndata.head()","a0aa1b60":"def preprocessing_inputs(df):\n    df = df.copy()\n    \n    #Split DataFrame\n    y = df['SalePrice']\n    X = df.drop('SalePrice', axis=1)\n    \n    #Train Test Split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n    \n    #Scale X\n    scaler = StandardScaler()\n    X_train = scaler.fit(X_train).transform(X_train)\n    X_test = scaler.fit(X_test).transform(X_test)\n    \n    return X_train, X_test, y_train, y_test","787d06aa":"X_train, X_test, y_train, y_test = preprocessing_inputs(data)","c32e2949":"print('Train set:', X_train.shape, y_train.shape)\nprint('Test set:', X_test.shape, y_test.shape)","c2cd4523":"linreg = LinearRegression()\nlinreg.fit(X_train, y_train)\nprint('Linear Regression Model Trained')","32f23dd6":"parameters = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}","8b1a3e0f":"ridge = Ridge()\nridge_cv = GridSearchCV(estimator=ridge, param_grid=parameters, cv=10)\nridge_cv.fit(X_train, y_train)\nprint('Ridge Regression Model Trained')","92de4eab":"print('Best parameters:', ridge_cv.best_params_)\nprint('Highest Accuracy:', '{:.2%}'.format(ridge_cv.best_score_))","90c6a7e0":"parameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'selection': ['cyclic', 'random']}","ca8e34e8":"lasso = Lasso()\nlasso_cv = GridSearchCV(estimator=lasso, param_grid=parameters, cv=10)\nlasso_cv.fit(X_train, y_train)\nprint('Lasso Regression Model Trained')","cc0ec4d5":"print('Best parameters:', lasso_cv.best_params_)\nprint('Highest Accuracy:', '{:.2%}'.format(lasso_cv.best_score_))","d5c263c9":"parameters = {'alpha_1': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n              'alpha_2': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n              'lambda_1': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n              'lambda_2': [0.000001, 0.00001, 0.0001, 0.001, 0.01]}","1ffb3de5":"bayr = BayesianRidge()\nbayr_cv = GridSearchCV(estimator=bayr, param_grid=parameters, cv=10)\nbayr_cv.fit(X_train, y_train)\nprint('Bayesian Ridge Regression Model Trained')","53a972b9":"print('Best parameters:', bayr_cv.best_params_)\nprint('Highest Accuracy:', '{:.2%}'.format(bayr_cv.best_score_))","9308700c":"parameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'l1_ratio': [0, 0.5, 1],\n              'selection': ['cyclic', 'random']}","a12fabb8":"enet = ElasticNet()\nenet_cv = GridSearchCV(estimator=enet, param_grid=parameters, cv=10)\nenet_cv.fit(X_train, y_train)\nprint('Elastic Net Regression Model Trained')","7c1e45ef":"print('Best parameters:', enet_cv.best_params_)\nprint('Highest Accuracy:', '{:.2%}'.format(enet_cv.best_score_))","5bf344ad":"yhat_lin = linreg.predict(X_test)\nyhat_ridge = ridge_cv.predict(X_test)\nyhat_lasso = lasso_cv.predict(X_test)\nyhat_bayr = bayr_cv.predict(X_test)\nyhat_enet = enet_cv.predict(X_test)","b4173037":"lin_r2 = r2_score(y_test, yhat_lin)\nridge_r2 = r2_score(y_test, yhat_ridge)\nlasso_r2 = r2_score(y_test, yhat_lasso)\nbayr_r2 = r2_score(y_test, yhat_bayr)\nenet_r2 = r2_score(y_test, yhat_enet)","fb8125ff":"print('        Linear Regression R2-score: ', '{:.5}'.format(lin_r2))\nprint('         Ridge Regression R2-score: ', '{:.5}'.format(ridge_r2))\nprint('         Lasso Regression R2-score: ', '{:.5}'.format(lasso_r2))\nprint('Bayesian Ridge Regression R2-score: ', '{:.5}'.format(bayr_r2))\nprint('   Elastic Net Regression R2-score: ', '{:.5}'.format(enet_r2))","4c2f8a76":"lin_mse = np.mean((yhat_lin - y_test) ** 2)\nridge_mse = np.mean((yhat_ridge - y_test) ** 2)\nlasso_mse = np.mean((yhat_lasso - y_test) ** 2)\nbayr_mse = np.mean((yhat_bayr - y_test) ** 2)\nenet_mse = np.mean((yhat_enet - y_test) ** 2)","83b0ab04":"print('        Linear Regression MSE: ', '{:.3}'.format(lin_mse))\nprint('         Ridge Regression MSE: ', '{:.3}'.format(ridge_mse))\nprint('         Lasso Regression MSE: ', '{:.3}'.format(lasso_mse))\nprint('Bayesian Ridge Regression MSE: ', '{:.3}'.format(bayr_mse))\nprint('   Elastic Net Regression MSE: ', '{:.3}'.format(enet_mse))","61ada3fa":"model_dict = {'model':['Linear', 'Ridge', 'Lasso', 'Bayesian', 'ElasticNet'],\n              'R2_score': [lin_r2, ridge_r2, lasso_r2, bayr_r2, enet_r2],\n              'MSE': [lin_mse, ridge_mse, lasso_mse, bayr_mse, enet_mse ]}\nmodel_results = pd.DataFrame.from_dict(model_dict)\nmodel_results","dce02672":"model_results.plot(kind='bar', x='model', y='R2_score', color='skyblue', figsize=(8,6))\nplt.title('Model Performance')\nplt.xlabel('Model')\nplt.xticks(rotation=25)\nplt.ylabel('R2 Score')\nplt.show()\nmodel_results.plot(kind='bar', x='model', y='MSE', color='violet', figsize=(8,6))\nplt.title('Model Performance')\nplt.xlabel('Model')\nplt.xticks(rotation=25)\nplt.ylabel('Mean Squared Error')\nplt.show()","a31b1b56":"test_data.head()","72744749":"test_features = test_data[['OverallQual', 'GrLivArea', \n                       'GarageCars', 'GarageArea', \n                       'TotalBsmtSF', '1stFlrSF', \n                       'FullBath', 'TotRmsAbvGrd', \n                       'YearBuilt', 'YearRemodAdd', \n                       'MasVnrArea', 'Fireplaces', \n                       'GarageFinish', 'KitchenQual', \n                       'BsmtQual', 'ExterQual']]\ntest_features.head()","be190b34":"test_features.isna().sum()","819caa14":"#Fill missing values with constant 0\nfor column in ['GarageCars', \n               'GarageArea', \n               'TotalBsmtSF', \n               'MasVnrArea']:\n    test_features[column] = test_features[column].fillna(0)\n\n#Fill missing values with constant\nfor column in ['BsmtQual', \n               'GarageFinish']:\n    test_features[column] = test_features[column].fillna('none')\n\n    #Fill missing values with mode\nfor column in ['KitchenQual']:\n    mode = test_features[column].mode()\n    test_features[column] = test_features[column].fillna(mode[0])","a27015d3":"test_features.isna().sum().sum()","57ac466e":"#Check for skewed columns\nfeature_skew = pd.DataFrame(test_features.select_dtypes(np.number).columns, columns=['Features'])\nfeature_skew['Skew'] = feature_skew['Features'].apply(lambda feature: scipy.stats.skew(test_features[feature]))\nfeature_skew['Abs Skew'] = feature_skew['Skew'].apply(abs)\nfeature_skew['Skewed'] = feature_skew['Abs Skew'].apply(lambda x: True if x >= 0.5 else False)\nfeature_skew","815f9879":"#Correct skewed columns\nfor column in feature_skew.query('Skewed == True')['Features'].values:\n    test_features[column] = np.log1p(test_features[column])","e16dce98":"X_test_ = ordinal_encode(test_features, ordinal_features, ordinal_orderings)\nX_test_ = onehot_encode(X_test_)\nX_test_.head()","ff69df08":"#Scale X\nscaler = StandardScaler()\nX_test_ = scaler.fit(X_test_).transform(X_test_)","9aa1cdfb":"models = {'Linear Regression': linreg,\n          'Ridge Regression': ridge_cv,\n          'Lasso Regression': lasso_cv,\n          'Bayesian Ridge Regression': bayr_cv,\n          'Elastic Net Regression': enet_cv}","2fa6115d":"predictions = (\n    0.2 * np.exp(models['Linear Regression'].predict(X_test_)) +\n    0.2 * np.exp(models['Ridge Regression'].predict(X_test_)) +\n    0.2 * np.exp(models['Lasso Regression'].predict(X_test_)) +\n    0.2 * np.exp(models['Bayesian Ridge Regression'].predict(X_test_)) +\n    0.2 * np.exp(models['Elastic Net Regression'].predict(X_test_))\n)","598c022e":"submission = pd.DataFrame({'ID': test_data['Id'],\n                           'SalePrice': predictions})\nsubmission.head()","267810e6":"submission.to_csv('Submission.csv',index=False)","64d8e6f7":"# Model Training","238ba775":"## Exploring Categorical Features","20bbdc01":"# Predicting House Prices\n## Objectives:\n* Clean data\n* Perform exploratory Data Analysis\n* Preparing Data Feature Engineering\n* Split, scale, and standardize data\n* Find best Hyperparameter for Linear Regression, Ridge Regression, Lasso Regression, Bayesian Ridge, and Elastic Net\n* Model selection for test data and submit predictions ","0dc0453c":"## Ridge Regression","a50053ca":"### Ensambling","8112481c":"### Load Test set for evaluation","af73bb24":"# Data Cleaning","eb004f60":"## Lasso","790a7b04":"# Feature Engineering\nNow that we have some preliminary insights about how each important variable would affect the Sale Price. We will select the features that will be used in prediction for our future models.","8888aaea":"## Bayesian Ridge","ce8c126e":"As we can see all our models performed similarly according, however, if we look at our R2 score and MSE, the model that peforms best is the Linear Regression model.","414001a6":"# Import Libraries & Load Data","2ecaf5e8":"### Preprocessing","baa0db40":"### Feature Engineering","c4c11c5b":"## Linear Regression","738a7069":"# Feature Transformation","b5fdc137":"# Training & Submission","1368b131":"# Exploratory Data Analysis","930b3d39":"Since, we have created our model on only a select few features we will perform our preprocessing on these features only.","6900df69":"# Training Results","e6e4cadf":"# Model Evaluation using Test set","b69f07ad":"# Data Preprocessing","c4293a2d":"## Elastic Net","1523ece8":"## Exploring Numeric Features","ae278e8c":"* Ex = Excellent\n* Gd = Good\n* TA = Average\n* Fa = Fair\n* Po = Poor","5331dd7a":"### Fill Missing Values for Categorical Data\nIn some cases, nan actually repersents a category (e.g., for the column Alley, a house may not have access to alley, therefore, nan is a valid category). For the rest of the cateogrical values we can fill missing values with the mode.","c891bfdd":"### Clean Data"}}