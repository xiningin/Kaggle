{"cell_type":{"00eb9a69":"code","f0468b18":"code","4dc52a6b":"code","56d9fcfa":"code","7c1ccf54":"code","29c3528f":"code","2362e60c":"code","166efae7":"code","8b6dbf91":"code","07ec8ab6":"code","e7c0b38c":"code","b2b1aa71":"code","93b44e62":"code","6eb0e8b4":"code","a5ec26ce":"code","bdba7580":"code","e8980292":"code","7c20bf91":"code","744da4c6":"code","e2e7c668":"code","35543ad4":"code","13f4c46f":"code","ae032f80":"code","e9676d19":"markdown","5aa63906":"markdown","a9ac7339":"markdown","67deb746":"markdown","7da9fe8e":"markdown","2916b63e":"markdown","b9789166":"markdown","41ca56b4":"markdown","15577cbb":"markdown","accf20c7":"markdown","6bb6daa5":"markdown","653bc2c9":"markdown","146b2791":"markdown","7f3f50b7":"markdown","ea077843":"markdown","fd4e35e9":"markdown","43ec91b8":"markdown","6e7e2f63":"markdown","03a20a90":"markdown","2bb1c92f":"markdown","639c3048":"markdown","df45d436":"markdown","f6b86348":"markdown","fb6117ae":"markdown"},"source":{"00eb9a69":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nimport seaborn as sns\nimport warnings\nfrom sklearn.model_selection import RandomizedSearchCV\n\npd.options.mode.chained_assignment = None  # default='warn'\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f0468b18":"train = pd.read_csv(\"\/kaggle\/input\/hsemath2020flights\/flights_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/hsemath2020flights\/flights_test.csv\")","4dc52a6b":"train.isnull().values.any(), test.isnull().values.any()","56d9fcfa":"train.columns","7c1ccf54":"target = 'dep_delayed_15min'","29c3528f":"train.describe()","2362e60c":"train[target].describe()","166efae7":"for feature in ('DEPARTURE_TIME', 'DISTANCE'):\n    uniques = sorted(train[feature].unique())\n    average_target = []\n    for value in uniques:\n        average_target.append(np.sum(train[target][train[feature] == value]) \/ len(train[target][train[feature] == value])) # \u0434\u043e\u043b\u044f \u0437\u0430\u0434\u0435\u0440\u0436\u0430\u043d\u043d\u044b\u0445 \u0440\u0435\u0439\u0441\u043e\u0432 \u043e\u0442 \u0432\u0441\u0435\u0445 \u0440\u0435\u0439\u0441\u043e\u0432 \u0441 \u044d\u0442\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\n    plt.plot(uniques, average_target, label=feature)\n    plt.legend(loc='best')\n    plt.show()","8b6dbf91":"for feature in ('DATE', 'AIRLINE', 'ORIGIN_AIRPORT','DESTINATION_AIRPORT'):\n    print(feature +  \":\")\n    uniques = sorted(train[feature].unique())\n    average_target = []\n    for value in uniques:\n        average_target.append(np.sum(train[target][train[feature] == value]) \/ len(train[target][train[feature] == value]))\n    f, ax = plt.subplots(figsize=(8, 6))\n    fig = sns.boxplot(x=uniques, y=average_target)\n    fig.axis(ymin=0, ymax=1);","07ec8ab6":"sorted(train['DATE'].unique())","e7c0b38c":"set(train['DATE'].unique()).symmetric_difference(set(test['DATE'].unique()))","b2b1aa71":"train, test = train.drop(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT'], axis=1), test.drop(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT'], axis=1)","93b44e62":"train['DATE'] = train['DATE'].apply(lambda x: x.split('-')[1])\ntest['DATE'] = test['DATE'].apply(lambda x: x.split('-')[1])","6eb0e8b4":"train['DATE']","a5ec26ce":"y, X = train['dep_delayed_15min'], train.drop('dep_delayed_15min', axis=1)","bdba7580":"testsize = test.shape[0]\ntemp = test.append(X)\ntemp = pd.get_dummies(temp)\ntest = temp[:testsize]\nX = temp[testsize:]","e8980292":"model = LogisticRegression()\ncross_val_score(model, X, y, cv=4, scoring='roc_auc')","7c20bf91":"hyperparameter = {'penalty': ['l2'], 'C': np.linspace(0.1, 1, 10)}\nsearch = RandomizedSearchCV(model, hyperparameter, n_iter=10)\nsearch.fit(X, y)\nl2 = search.best_params_\nprint(l2)","744da4c6":"model = LogisticRegression(C=l2['C'])","e2e7c668":"cross_val_score(model, X, y, cv=4, scoring='roc_auc')","35543ad4":"model.fit(X, y)","13f4c46f":"prediction = model.predict_proba(test)","ae032f80":"sample_sub = pd.read_csv('\/kaggle\/input\/hsemath2020flights\/flights_sample_submission.csv', index_col='id')\nsample_sub['dep_delayed_15min'] = prediction[:, 1]\nsample_sub.to_csv('log_prediction.csv')","e9676d19":"# CV","5aa63906":"# Check that our model is not good enough to outrun Benchmark 4:","a9ac7339":"# **Fortunately there isn't any nans in the dataframe. **\n# Now let's see what features we have how the target is distributed","67deb746":"# Let's tune the L2 parameter using randomised search cv from sklearn","7da9fe8e":"**Our features:**","2916b63e":"# The model isn't better than Benchmark 4 with score 0.72","b9789166":"# Unfortunately there are too many different values to make it clear.\n# We can't really do something with destination and origin airports but we can take a look at 'Date':","41ca56b4":"# **Getting probabilities and the results:**","15577cbb":"# Let's see how the numerical features above impact on the target:","accf20c7":"# Missing data","6bb6daa5":"**Now the result is saved to \/kaggle\/working directory and can be submitted to the competition.**","653bc2c9":"# Now let's work with categorical data:","146b2791":"**Separate target:**","7f3f50b7":"# Baseline with logistic regression\nIn the notebook below I will observe the features and make some short analysis.","ea077843":"# We are lucky we have same days in both test and train data.","fd4e35e9":"# Now we can do the cross-validation","43ec91b8":"# So now we can see that our features are not really homogeneous. For instance, left part of 'Distance' feature is more like being a signal, while the second part looks fine.","6e7e2f63":"**Make one hot encoding with train and test together:**","03a20a90":"# 1. Some includes we will use later","2bb1c92f":"# 2. **Load all data first:** ","639c3048":"# Dropping features: due to the course rule we have to drop some features and use month intstead of date:","df45d436":"# **Now we can fit the logistic regression model.**","f6b86348":"# So we have 4 categorical features and 2 numerical","fb6117ae":"# Seems like we have data for every day in 2015. Now let's check that all the days in test and train are the same: "}}