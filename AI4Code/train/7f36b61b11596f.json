{"cell_type":{"92d33430":"code","3ba89e57":"code","55e8e79c":"code","e1126665":"code","9e1c83bd":"code","e75d1c12":"code","900dd697":"code","1619ab93":"code","560092a2":"code","f899402e":"code","600b1a78":"code","2381e6a4":"code","d6d46faa":"code","ebf40231":"code","cbeadf97":"code","e74c4f20":"code","586c90e5":"code","475003ce":"code","e1e9ba15":"code","933db481":"code","f6cf8fe4":"code","26afd4f9":"code","2bd8cd6b":"code","42a3d878":"code","e734be53":"code","d8d253c2":"code","43a08eef":"code","d694c6de":"code","328f0f78":"code","39b81e75":"code","551d3920":"code","47e4e209":"code","2352306f":"code","deb72c3b":"code","9b6115a4":"code","486baa49":"code","be1867fe":"code","cdf541a5":"code","81270859":"code","3b1a6ea0":"code","e385bb68":"code","b8b45896":"code","390b0519":"code","61d67b91":"code","087c53d7":"code","9f77f9d9":"code","9c45f3fb":"code","ae1036a8":"code","9ce26a9a":"code","62dbb1cd":"code","9024889e":"code","41fddb6b":"code","ed8b2676":"code","6e65cc70":"code","b492ef2c":"markdown","3a5964d5":"markdown","d2432a9c":"markdown","c4a9b860":"markdown","0b9d851b":"markdown","dcb7faaf":"markdown","d6ca7284":"markdown","e5e0577d":"markdown"},"source":{"92d33430":"import pandas as pd\nimport numpy as np","3ba89e57":"df = pd.read_csv('..\/input\/tweets\/Constraint_Train.csv')","55e8e79c":"df = df.drop(['id'], axis = 1)\ndf.head(10)","e1126665":"# removing stopwords\nimport nltk\nnltk.download('stopwords')","9e1c83bd":"from nltk.corpus import stopwords\nstop = set(stopwords.words('english'))","e75d1c12":"df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))","900dd697":"df.head()","1619ab93":"# removing punctuations\nimport string","560092a2":"punc = set(string.punctuation)","f899402e":"def remove_punc(st):\n  for char in st:\n    if char in punc:\n      st = st.replace(char,'')\n  return st","600b1a78":"df['tweet'] = df['tweet'].apply(lambda x: remove_punc(x))\ndf.head()","2381e6a4":"# Remove link to the source\ndef remove_links(tweet):\n  indx = tweet.find('http')\n  return tweet[:indx]\n\ndf['tweet'] = df['tweet'].apply(lambda x: remove_links(x))","d6d46faa":"tweets = df['tweet']\ntweets = list(tweets)","ebf40231":"# Tokenization \nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize","cbeadf97":"tokenized = []\nfor tweet in tweets:\n  tokens = word_tokenize(tweet)\n  tokenized.append(tokens)","e74c4f20":"# lemmatization\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')","586c90e5":"lemmatizer = WordNetLemmatizer()\ntext = []\nfor i in range(len(tokenized)):\n  for j in range(len(tokenized[i])):\n    tokenized[i][j] =  lemmatizer.lemmatize(tokenized[i][j])\n  \n  text.append(\" \".join(tokenized[i])) ","475003ce":"from sklearn.feature_extraction.text import TfidfVectorizer","e1e9ba15":"vectorizer = TfidfVectorizer()","933db481":"vectorizer.fit(text)","f6cf8fe4":"vector = vectorizer.fit_transform(text)\ndf1 = pd.DataFrame(vector[10].T.todense(), index = vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\ndf1 = df1.sort_values('TF-IDF', ascending=False)\nprint (df1.head(10))","26afd4f9":"text[:11]","2bd8cd6b":"accuracy_scores = []","42a3d878":"tf_vector = TfidfVectorizer(sublinear_tf=True)\ntf_vector.fit(text)\n\nX_text = tf_vector.transform(text)\ny_values = np.array(df['label'].ravel())","e734be53":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(y_values)\nle.transform(y_values)","d8d253c2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_text, y_values, test_size=0.2, random_state=120)\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)","43a08eef":"from sklearn.metrics import accuracy_score\nscore=accuracy_score(y_test,y_predict)\nprint(f'Accuracy: {round(score*100,2)}%')","d694c6de":"from sklearn.metrics import classification_report\nprint(f\"Classification Report : \\n\\n{classification_report(y_test, y_predict)}\")","328f0f78":"from sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(text)\nX = X.toarray()\ny = df['label'].values\n\nkf = KFold(n_splits=10, random_state=None, shuffle=True)\ntotal_acc = 0\nfor train_index, test_index in kf.split(X):\n  X_train, X_test = X[train_index], X[test_index]\n  y_train, y_test = y[train_index], y[test_index]\n  model = LogisticRegression()\n  model.fit(X_train, y_train)\n  y_pred = model.predict(X_test)\n  accuracy = accuracy_score(y_test, y_pred)\n  print(f'Accuracy Score of Logistic Regression: {round(accuracy*100,2)}%')\n  total_acc += accuracy\navg_accuracy = total_acc \/ 10\naccuracy_scores.append(avg_accuracy)\nprint(f'Average accuracy of the model: {round(avg_accuracy*100,2)}%')","39b81e75":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split","551d3920":"vectorizer = CountVectorizer()\nX = vectorizer.fit_transform(text)\nX = X.toarray()","47e4e209":"y = df['label'].values","2352306f":"X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2, random_state=11)","deb72c3b":"clf = MultinomialNB()\nclf.fit(X_train, y_train)","9b6115a4":"print(\"Accuracy score with training data\",clf.score(X_train, y_train)*100)\nprint(\"Accuracy score with test data\",clf.score(X_test, y_test)*100)","486baa49":"from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=10, random_state=None, shuffle=True)\ntotal_acc = 0\nfor train_index, test_index in kf.split(X):\n  X_train, X_test = X[train_index], X[test_index]\n  y_train, y_test = y[train_index], y[test_index]\n  clf = MultinomialNB()\n  clf.fit(X_train, y_train)\n  train_acc = clf.score(X_train, y_train)\n  test_acc = clf.score(X_test, y_test)\n  print(f'Accuracy Score of train set: {round(train_acc*100,2)}%')\n  print(f'Accuracy Score of test set: {round(test_acc*100,2)}%')\n  total_acc += test_acc\navg_accuracy = total_acc \/ 10\naccuracy_scores.append(avg_accuracy)\nprint(f'Average test accuracy of the model: {round(avg_accuracy*100,2)}%')","be1867fe":"def check_tweet(tweet):      # Method to predict certain sentences are fake or real\n  vectorized_sentence = vectorizer.transform([tweet]).toarray()\n  return clf.predict(vectorized_sentence)[0]","cdf541a5":"for tweet in text[:6]:\n  print(tweet[:50])\n  print(check_tweet(tweet))","81270859":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(df['tweet'], \n                                                df['label'], test_size=0.2, \n                                                random_state=7)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\ntrain = tfidf.fit_transform(xtrain)\ntest = tfidf.transform(xtest)","3b1a6ea0":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import PassiveAggressiveClassifier\n\nX = df['tweet']\nX = X.reset_index(drop=True)\ny = df['label']\ny = y.reset_index(drop=True)\n\nkf = KFold(n_splits=10, random_state=None, shuffle=True)\ntotal_accuracy = 0\nfor train_index, test_index in kf.split(X):\n  X_train, X_test = X[train_index], X[test_index]\n  y_train, y_test = y[train_index], y[test_index]\n  pac = PassiveAggressiveClassifier(max_iter=50)\n  pac.fit(train, ytrain)\n  ypred = pac.predict(test)\n  accuracy = accuracy_score(ytest, ypred)\n  print(f'Accuracy Score of Passive Aggresive Classifier: {round(accuracy*100,2)}%')\n  total_accuracy += accuracy\naccuracy_scores.append(avg_accuracy)\navg_accuracy = total_accuracy \/ 10\nprint(f'Average accuracy of the model: {round(avg_accuracy*100,2)}%')","e385bb68":"import re\n\nfrom gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short # Preprocesssing\nfrom gensim.models import Word2Vec # Word2vec\n\nfrom sklearn import cluster # Kmeans clustering","b8b45896":"df.loc[df.label == 'real','label'] = 1\ndf.loc[df.label == 'fake','label'] = 0\ndf.head()","390b0519":"def remove_URL(s):\n    regex = re.compile(r'https?:\/\/\\S+|www\\.\\S+|bit\\.ly\\S+')\n    return regex.sub(r'',s)\n\nCUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, remove_URL, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short]\n\nprocessed_data = []\nprocessed_labels = []\n\nfor index, row in df.iterrows():\n    words_broken_up = preprocess_string(row['tweet'], CUSTOM_FILTERS)\n    # This eliminates any fields that may be blank after preprocessing\n    if len(words_broken_up) > 0:\n        processed_data.append(words_broken_up)\n        processed_labels.append(row['label'])","61d67b91":"model = Word2Vec(processed_data, min_count=1)\nmodel.wv.most_similar(\"covid\")","087c53d7":"def ReturnVector(x):\n    return model.wv[x]\n    \ndef Sentence_Vector(sentence):\n    word_vectors = list(map(lambda x: ReturnVector(x), sentence))\n    return np.average(word_vectors, axis=0).tolist()\n\nX = []\nfor data_x in processed_data:\n    X.append(Sentence_Vector(data_x))","9f77f9d9":"X_np = np.array(X)\nX_np.shape","9c45f3fb":"kmeans = cluster.KMeans(n_clusters=2, verbose=1)\n\nclustered = kmeans.fit_predict(X_np)","ae1036a8":"testing_df = {'Sentence': processed_data, 'Labels': processed_labels, 'Prediction': clustered}\ntesting_df = pd.DataFrame(data=testing_df)\n\ntesting_df.head(10)","9ce26a9a":"correct, incorrect = 0, 0\nfor index, row in testing_df.iterrows():\n    if row['Labels'] == row['Prediction']:\n        correct += 1\n    else:\n        incorrect += 1\naccuracy = correct\/(correct + incorrect)\naccuracy_scores.append(accuracy)\nprint(\"Correctly clustered news: \" + str(round((correct*100)\/(correct+incorrect),2)) + \"%\")","62dbb1cd":"from sklearn.cluster import AgglomerativeClustering \n\nagglom = AgglomerativeClustering(n_clusters=2, linkage='average')\n\nclustered = agglom.fit_predict(X_np)","9024889e":"testing_df = {'Sentence': processed_data, 'Labels': processed_labels, 'Prediction': clustered}\ntesting_df = pd.DataFrame(data=testing_df)\n\ntesting_df.head(10)","41fddb6b":"correct = 0\nincorrect = 0\nfor index, row in testing_df.iterrows():\n    if row['Labels'] == row['Prediction']:\n        correct += 1\n    else:\n        incorrect += 1\naccuracy = correct\/(correct + incorrect)\naccuracy_scores.append(accuracy)\n        \nprint(\"Correctly clustered news: \" + str(round((correct*100)\/(correct+incorrect),2)) + \"%\")","ed8b2676":"import matplotlib.pyplot as plt","6e65cc70":"models = ['Logistic Regression','Naive Bayes', 'Passive Aggressive Classifier','K-Means','Agglomerative Clustering']\nfig = plt.figure(figsize = (10, 5))\nfor i in range(len(accuracy_scores)):\n    accuracy_scores[i] *= 100\nplt.bar(models, accuracy_scores, color ='maroon',width = 0.5)\n \nplt.xlabel(\"Models\")\nplt.ylabel(\"Average Accuracy (%)\")\nplt.title(\"Accuracy Comparison\")\nplt.show()","b492ef2c":"Vectorization\n","3a5964d5":"# **Fake News Classifier** \n\n### Goutham Surendran - CSE18020\n","d2432a9c":"## 2) **Agglomerative Hierarchical Clustering**","c4a9b860":"# 1) ***Logistic Regression***","0b9d851b":"## 1) **K-Means Clustering**","dcb7faaf":"# 2) **Naive Bayes**","d6ca7284":"# 3) ***PAC Neural Network***","e5e0577d":"# **UNSUPERVISED ALGORITHMS**"}}