{"cell_type":{"97dd1010":"code","6d46c0af":"code","458a95f3":"code","b5a5a9bc":"code","5abb2039":"code","285eb9ec":"code","f562905f":"code","5e1d22ad":"code","098cf284":"code","2c1158d4":"code","2a428628":"code","d5d54600":"code","ab48e248":"code","e9b6c2bf":"code","09f5b53b":"code","9379bf68":"code","a57f0f7e":"code","c88e9292":"code","760697ce":"code","00e6bf4d":"code","1bec3692":"code","1a254538":"code","a51bdfff":"code","b73cc218":"code","2e760c4a":"code","ee0367c9":"code","c6dfd041":"code","7db96568":"code","e17709dc":"code","42d213c9":"code","c6cd05ea":"code","4d77c841":"code","55d5556e":"code","81c3553c":"code","96def109":"code","f892142c":"code","534d506f":"code","7f257dcc":"code","94a868f9":"code","878605f8":"code","400ceaa2":"code","8c9268f0":"code","cbe96e4d":"code","f15971fc":"code","9b28a0bf":"code","2e0b805d":"code","4bd44fb0":"code","e20f3a85":"code","503a5fe8":"code","9a072e5b":"code","12655bcb":"code","edca7943":"code","0da1f6dc":"code","e0d6e6d5":"code","553eb53c":"markdown"},"source":{"97dd1010":"import pandas as pd\nimport numpy as np\n\nfrom nltk.tokenize import RegexpTokenizer\n\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom gensim import corpora, models\n\n\nimport gensim","6d46c0af":"dataset = pd.read_csv('..\/input\/voted-kaggle-dataset\/voted-kaggle-dataset.csv')","458a95f3":"print(dataset['Description'][0])","b5a5a9bc":"dataset.head()","5abb2039":"\ndataset.iloc[0:3,:]","285eb9ec":"dataset.info()","f562905f":"\ndataset.columns.values","5e1d22ad":"modified_dataset = dataset.loc[ : , ['Title','Subtitle','Description']]","098cf284":"modified_dataset.iloc[0:5,:]","2c1158d4":"modified_dataset.info()","2a428628":"\nmodified_dataset.isnull()","d5d54600":"print(modified_dataset.isnull().sum())\nprint(\"total null values : \",sum(modified_dataset.isnull().values.ravel()))\nprint(\"total number of rows containing null values : \", sum([True for idx,row in modified_dataset.iterrows() if any(row.isnull())]))","ab48e248":"modified_dataset = modified_dataset.dropna()","e9b6c2bf":"print(\"total null values : \",sum(modified_dataset.isnull().values.ravel()))\nprint(\"total number of rows containing null values : \", sum([True for idx,row in modified_dataset.iterrows() if any(row.isnull())]))","09f5b53b":"modified_dataset.info()","9379bf68":"\nimport string\nimport re\n","a57f0f7e":"remove_digits = str.maketrans('', '', string.digits) # Set of all digits","c88e9292":"for column in ['Title','Subtitle','Description']:\n  modified_dataset[column] = modified_dataset[column].map(lambda x : x.lower())","760697ce":"modified_dataset.iloc[0:3,:]","00e6bf4d":"\nexclude = '[!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~]'","1bec3692":"for column in ['Title','Subtitle','Description']:\n  modified_dataset[column] = modified_dataset[column].map(lambda x : x.translate(remove_digits))\n  modified_dataset[column] = modified_dataset[column].map(lambda x : re.sub(str(exclude), '', x))","1a254538":"modified_dataset.iloc[0:3,:]","a51bdfff":"tag_dataset = dataset['Tags']\ntag_dataset.isnull().sum()\n#tag_dataset=tag_dataset.dropna()\ntag_dataset.isnull().sum()","b73cc218":"print(len(tag_dataset))","2e760c4a":"def convert(lst): \n    return (lst.split(\"\\n\"))","ee0367c9":"unique_tag = []\nfor i in range(len(tag_dataset)):\n  tag_string = str(tag_dataset[i])\n  if tag_string != \"nan\" :\n    tag_word=convert(tag_string)\n    for j in range(len(tag_word)):\n      if tag_word[j] not in unique_tag:\n        unique_tag.append(tag_word[j])\nprint(len(unique_tag))","c6dfd041":"\nfor i in range(len(unique_tag)):\n  print(unique_tag[i])","7db96568":"import nltk\nnltk.download('punkt')\ntokenized_dataframe =  modified_dataset.apply(lambda row: nltk.word_tokenize(row['Description']), axis=1)\nprint(type(tokenized_dataframe))","e17709dc":"tokenized_dataframe[0:3]","42d213c9":"#single word check......\nfrom nltk.stem import PorterStemmer \nps = PorterStemmer() \nprint(ps.stem('contains'))","c6cd05ea":"def lemmatize_text(text):\n    return [ps.stem(w)  for w in text if len(w)>5]","4d77c841":"nltk.download('wordnet')\nfrom nltk.stem import PorterStemmer \nps = PorterStemmer() \nstemmed_dataset = tokenized_dataframe.apply(lemmatize_text)","55d5556e":"type(stemmed_dataset)","81c3553c":"stemmed_dataset[0:3]","96def109":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n#dataset_words=''\n#for column in ['Title','Subtitle','Description']:\ndataset_words=''.join(list(str(stemmed_dataset.values)))\nprint(type(dataset_words))\nwordcloud = WordCloud(width = 800, height = 500, \n                background_color ='white',  \n                min_font_size = 10).generate(dataset_words) \n\nplt.figure(figsize = (5, 5), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","f892142c":"\ndictionary_of_words = gensim.corpora.Dictionary(stemmed_dataset)\n\ntype(dictionary_of_words)","534d506f":"len(dictionary_of_words)","7f257dcc":"# Creatig coupus which contains  of word id mapping with word_frequency--->(word_id, word_frequency) \nword_corpus = [dictionary_of_words.doc2bow(word) for word in stemmed_dataset]","94a868f9":"for corp in word_corpus[:1]:\n  for id, freq in corp:\n    print(dictionary_of_words[id],freq)","878605f8":"lda_model = gensim.models.ldamodel.LdaModel(corpus=word_corpus,\n                                           id2word=dictionary_of_words,\n                                           num_topics=329, \n                                           random_state=101,\n                                           update_every=1,\n                                           chunksize=300,\n                                           passes=50,\n                                           alpha='auto',\n                                           per_word_topics=True)","400ceaa2":"lda_model.print_topics()","8c9268f0":"\nfor idx, topic in lda_model.print_topics(-1):\n    print('Topic: {} \\nWords: {}'.format(idx, topic))","cbe96e4d":"from gensim.models.coherencemodel import CoherenceModel\n\ncoherence_val = CoherenceModel(model=lda_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n\nprint('Coherence Score: ', coherence_val)","f15971fc":"coherence_value = []\nfor topic_number in range(10,331,10):\n  lda_model = gensim.models.ldamodel.LdaModel(corpus=word_corpus,\n                                           id2word=dictionary_of_words,\n                                           num_topics=topic_number, \n                                           random_state=101,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=50,\n                                           alpha='auto',\n                                           per_word_topics=True)\n  models.append(lda_model)\n  coherence_model_lda = CoherenceModel(model=lda_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v')\n  coherence_lda = coherence_model_lda.get_coherence()\n  coherence_value.append(coherence_lda)\n  print(\"number of topics \",topic_number,\"coherence_value :\" , coherence_lda)","9b28a0bf":"lda_model1 = gensim.models.ldamodel.LdaModel(corpus=word_corpus,\n                                           id2word=dictionary_of_words,\n                                           num_topics=60, \n                                           random_state=1,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=50,\n                                           alpha='auto',\n                                           per_word_topics=True)","2e0b805d":"from gensim.models.coherencemodel import CoherenceModel\n\n\n# Compute Coherence Score\ncohr_val = CoherenceModel(model=lda_model1, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n\nprint('\\nCoherence Score: ', cohr_val)","4bd44fb0":"from gensim.test.utils import common_corpus, common_dictionary\nlda_multicore_model = gensim.models.ldamulticore.LdaMulticore(corpus=word_corpus, \n                                                              num_topics=60, \n                                                              id2word=dictionary_of_words,                                                             \n                                                              chunksize=100, \n                                                              passes=50,                                \n                                                              alpha='symmetric',\n                                                              eta=0.1,\n                                                              decay=0.5, \n                                                              offset=1.0, \n                                                              gamma_threshold=0.001,\n                                                              random_state=101,\n                                                              minimum_probability=0.01,\n                                                              minimum_phi_value=0.01,\n                                                              per_word_topics=False)","e20f3a85":"from gensim.models.coherencemodel import CoherenceModel\n\n\n# Compute Coherence Score\ncohr_lda_multicore_model1 = CoherenceModel(model=lda_multicore_model, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n\nprint('\\nCoherence Score: ', cohr_lda_multicore_model1)","503a5fe8":"from gensim.test.utils import common_corpus, common_dictionary\nlda_multicore_model2 = gensim.models.ldamulticore.LdaMulticore(corpus=word_corpus, \n                                                              num_topics=329, \n                                                              id2word=dictionary_of_words,                                                             \n                                                              chunksize=100, \n                                                              passes=50,                                \n                                                              alpha='symmetric',\n                                                              eta=0.1,\n                                                              decay=0.5, \n                                                              offset=1.0, \n                                                              gamma_threshold=0.001,\n                                                              random_state=101,\n                                                              minimum_probability=0.01,\n                                                              minimum_phi_value=0.01,\n                                                              per_word_topics=False)","9a072e5b":"from gensim.models.coherencemodel import CoherenceModel\n\n\n# Compute Coherence Score\ncohr_lda_multicore_model2 = CoherenceModel(model=lda_multicore_model2, texts=stemmed_dataset, dictionary=dictionary_of_words, coherence='c_v').get_coherence()\n\nprint('\\nCoherence Score: ', cohr_lda_multicore_model2)","12655bcb":"\nv = lda_model[word_corpus[2]]\nprint(type(lda_model[word_corpus[2]]))\nz=sorted(v[0], key=lambda tup: -1*tup[1])\nprint(z)\nprint(v[0])","edca7943":"for  index,score in sorted(lda_model[word_corpus[2]][0], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))","0da1f6dc":"topics = lda_model.show_topics(formatted=False)\ntopic_words = dict(topics[0][1])\nwordcloud.generate_from_frequencies(topic_words, max_font_size=100)\nplt.figure(figsize = (5, 5), facecolor = None) \nplt.title(\"topic 0\")\nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","e0d6e6d5":"fig = plt.figure(figsize=(15,15),frameon=0)\na = fig.add_subplot(1, 2, 1)\ntopic_words = dict(topics[1][1])\nwordcloud.generate_from_frequencies(topic_words, max_font_size=100)\nimgplot = plt.imshow(wordcloud)\na.set_title('topic 0')\n\na = fig.add_subplot(1, 2, 2)\ntopic_words = dict(topics[2][1])\nwordcloud.generate_from_frequencies(topic_words, max_font_size=100)\nimgplot = plt.imshow(wordcloud)\n\na.set_title('topic 1')","553eb53c":"# Tried to implement this blog - [Latent Dirichlet Allocation(LDA): A guide to probabilistic modelling approach for topic discovery](https:\/\/towardsdatascience.com\/latent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c) "}}