{"cell_type":{"6d90681f":"code","dc1a9c45":"code","bc6b70c0":"code","daa09bca":"code","04c82ef8":"code","0aedb945":"code","eb4915b5":"code","439f1add":"code","5de5cd5c":"code","ca866426":"code","55d360b5":"code","fd21a547":"code","f2b630ff":"code","f5287537":"code","36f1c8f7":"code","e41efee3":"code","a4deeb3c":"code","348404bd":"code","d1e0740b":"code","06cce917":"code","7c894dd8":"code","67b4e5d1":"code","09de7c63":"code","2a8d7fa5":"code","6abc4ac1":"markdown","3b2b3c30":"markdown","ec720a1e":"markdown","71238eea":"markdown","039e296c":"markdown"},"source":{"6d90681f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nimport os\nimport array\nfrom datetime import datetime\nimport seaborn as sns\nimport missingno as msno\nplt.rcParams['font.sans-serif'] = ['SimHei'] \nplt.rcParams['axes.unicode_minus'] = False\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc1a9c45":"df=pd.read_csv('..\/input\/jane-street-market-prediction\/features.csv')\nprint(df.head())","bc6b70c0":"df2= pd.DataFrame(df.values.T, index=df.columns, columns=df.feature)\ndf2=df2.iloc[1:]\ndf2= df2.apply(pd.to_numeric)\ndf2=df2.astype(int)\ndf_label={\"label\":pd.Series(df2.sum())}\ndf_label=pd.DataFrame(df_label)\ndf_label=df_label.reset_index()\n#print(df_label.head())\n#print(\"---\")\nlabel_gp=df_label.groupby(['label'])['feature'].count()\n#print(label_gp)\nprint(df_label.head())","daa09bca":"train=pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')","04c82ef8":"train=train[:100000]","0aedb945":"train['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\ntrain_action=train[['ts_id','action']]\ndel train['action']","eb4915b5":"train_action.groupby(['action'])['ts_id'].count()","439f1add":"train_s=train\ntrain_s=train_s.drop(['date','resp_1','resp_2','resp_3','resp_4','resp'],axis=1)\ntrain_s=train_s.fillna(0)\nfeatures_label=df_label","5de5cd5c":"train_s_L1=train_s[features_label[features_label.label==1].feature]\nL1_min=[]\nfor x in range(len(train_s_L1)):\n    a=np.array(train_s_L1.iloc[x]).min()\n    L1_min.append(a)\n    x=x+1\nL1_max=[]\nfor x in range(len(train_s_L1)):\n    a=np.array(train_s_L1.iloc[x]).max()\n    L1_max.append(a)\n    x=x+1\nL1_mean=[]\nfor x in range(len(train_s_L1)):\n    a=np.array(train_s_L1.iloc[x]).mean()\n    L1_mean.append(a)\n    x=x+1\nL1_std=[]\nfor x in range(len(train_s_L1)):\n    a=np.array(train_s_L1.iloc[x]).std()\n    L1_std.append(a)\n    x=x+1\ntrain_s['L1_min']=L1_min\ntrain_s['L1_max']=L1_max\ntrain_s['L1_mean']=L1_mean\ntrain_s['L1_std']=L1_std","ca866426":"train_s_L2=train_s[features_label[features_label.label==2].feature]\nL2_min=[]\nfor x in range(len(train_s_L2)):\n    a=np.array(train_s_L2.iloc[x]).min()\n    L2_min.append(a)\n    x=x+1\nL2_max=[]\nfor x in range(len(train_s_L2)):\n    a=np.array(train_s_L2.iloc[x]).max()\n    L2_max.append(a)\n    x=x+1\nL2_mean=[]\nfor x in range(len(train_s_L2)):\n    a=np.array(train_s_L2.iloc[x]).mean()\n    L2_mean.append(a)\n    x=x+1\nL2_std=[]\nfor x in range(len(train_s_L2)):\n    a=np.array(train_s_L2.iloc[x]).std()\n    L2_std.append(a)\n    x=x+1\ntrain_s['L2_min']=L2_min\ntrain_s['L2_max']=L2_max\ntrain_s['L2_mean']=L2_mean\ntrain_s['L2_std']=L2_std","55d360b5":"train_s_L3=train_s[features_label[features_label.label==3].feature]\nL3_min=[]\nfor x in range(len(train_s_L3)):\n    a=np.array(train_s_L3.iloc[x]).min()\n    L3_min.append(a)\n    x=x+1\nL3_max=[]\nfor x in range(len(train_s_L3)):\n    a=np.array(train_s_L3.iloc[x]).max()\n    L3_max.append(a)\n    x=x+1\nL3_mean=[]\nfor x in range(len(train_s_L3)):\n    a=np.array(train_s_L3.iloc[x]).mean()\n    L3_mean.append(a)\n    x=x+1\nL3_std=[]\nfor x in range(len(train_s_L3)):\n    a=np.array(train_s_L3.iloc[x]).std()\n    L3_std.append(a)\n    x=x+1\ntrain_s['L3_min']=L3_min\ntrain_s['L3_max']=L3_max\ntrain_s['L3_mean']=L3_mean\ntrain_s['L3_std']=L3_std","fd21a547":"train_s_L4=train_s[features_label[features_label.label==4].feature]\nL4_min=[]\nfor x in range(len(train_s_L4)):\n    a=np.array(train_s_L4.iloc[x]).min()\n    L4_min.append(a)\n    x=x+1\nL4_max=[]\nfor x in range(len(train_s_L4)):\n    a=np.array(train_s_L4.iloc[x]).max()\n    L4_max.append(a)\n    x=x+1\nL4_mean=[]\nfor x in range(len(train_s_L4)):\n    a=np.array(train_s_L4.iloc[x]).mean()\n    L4_mean.append(a)\n    x=x+1\nL4_std=[]\nfor x in range(len(train_s_L4)):\n    a=np.array(train_s_L4.iloc[x]).std()\n    L4_std.append(a)\n    x=x+1\ntrain_s['L4_min']=L4_min\ntrain_s['L4_max']=L4_max\ntrain_s['L4_mean']=L4_mean\ntrain_s['L4_std']=L4_std","f2b630ff":"train_s_d=train_s[['weight','ts_id','L1_min','L1_max','L1_mean','L1_std',\n         'L2_min','L2_max','L2_mean','L2_std',\n        'L3_min','L3_max','L3_mean','L3_std',\n        'L4_min','L4_max','L4_mean','L4_std','feature_0']]","f5287537":"train_action.head()","36f1c8f7":"train_s_with_action=pd.merge(train_s_d,train_action[['ts_id','action']],on='ts_id')\n#train_s_with_action=train_s_with_action.drop(columns=['Unnamed: 0'])\n","e41efee3":"Train=train_s_with_action[:2000000]\nTest=train_s_with_action[2000000:]","a4deeb3c":"features= ['weight', 'L1_min', 'L1_max', 'L1_mean','L1_std', 'L2_min', 'L2_max', 'L2_mean', 'L2_std', 'L3_min', 'L3_max',\n            'L3_mean', 'L3_std', 'L4_min', 'L4_max', 'L4_mean', 'L4_std',\n            'feature_0']\nX_train = Train[features]\nX_test = Test[features]\ny_train = Train['action']\ny_test = Test['action']\n","348404bd":"import xgboost as xgb","d1e0740b":"xgbr_model= xgb.XGBRegressor(max_depth = 9,n_estimators = 20,learning_rate = 0.01,subsample = 0.7,reg_alpha=0.1, reg_lambda=0.1,colsample_bytree = 0.7)\nxgbr_model.fit(X_train,y_train,eval_metric = 'rmse',eval_set = [(X_train,y_train),(X_test,y_test)])","06cce917":"# submit\n\nimport janestreet","7c894dd8":"# Create submission\nenv = janestreet.make_env()\niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test: \n    train_s=test_df\n    #train_s=train_s.drop(['date','resp_1','resp_2','resp_3','resp_4','resp'],axis=1)\n    train_s=train_s.fillna(0)\n    features_label=df_label\n    train_s_L1=train_s[features_label[features_label.label==1].feature]\n    L1_min=[]\n    for x in range(len(train_s_L1)):\n        a=np.array(train_s_L1.iloc[x]).min()\n        L1_min.append(a)\n        x=x+1\n    L1_max=[]\n    for x in range(len(train_s_L1)):\n        a=np.array(train_s_L1.iloc[x]).max()\n        L1_max.append(a)\n        x=x+1\n    L1_mean=[]\n    for x in range(len(train_s_L1)):\n        a=np.array(train_s_L1.iloc[x]).mean()\n        L1_mean.append(a)\n        x=x+1\n    L1_std=[]\n    for x in range(len(train_s_L1)):\n        a=np.array(train_s_L1.iloc[x]).std()\n        L1_std.append(a)\n        x=x+1\n    train_s['L1_min']=L1_min\n    train_s['L1_max']=L1_max\n    train_s['L1_mean']=L1_mean\n    train_s['L1_std']=L1_std\n    train_s_L2=train_s[features_label[features_label.label==2].feature]\n    L2_min=[]\n    for x in range(len(train_s_L2)):\n        a=np.array(train_s_L2.iloc[x]).min()\n        L2_min.append(a)\n        x=x+1\n    L2_max=[]\n    for x in range(len(train_s_L2)):\n        a=np.array(train_s_L2.iloc[x]).max()\n        L2_max.append(a)\n        x=x+1\n    L2_mean=[]\n    for x in range(len(train_s_L2)):\n        a=np.array(train_s_L2.iloc[x]).mean()\n        L2_mean.append(a)\n        x=x+1\n    L2_std=[]\n    for x in range(len(train_s_L2)):\n        a=np.array(train_s_L2.iloc[x]).std()\n        L2_std.append(a)\n        x=x+1\n    train_s['L2_min']=L2_min\n    train_s['L2_max']=L2_max\n    train_s['L2_mean']=L2_mean\n    train_s['L2_std']=L2_std\n    train_s_L3=train_s[features_label[features_label.label==3].feature]\n    L3_min=[]\n    for x in range(len(train_s_L3)):\n        a=np.array(train_s_L3.iloc[x]).min()\n        L3_min.append(a)\n        x=x+1\n    L3_max=[]\n    for x in range(len(train_s_L3)):\n        a=np.array(train_s_L3.iloc[x]).max()\n        L3_max.append(a)\n        x=x+1\n    L3_mean=[]\n    for x in range(len(train_s_L3)):\n        a=np.array(train_s_L3.iloc[x]).mean()\n        L3_mean.append(a)\n        x=x+1\n    L3_std=[]\n    for x in range(len(train_s_L3)):\n        a=np.array(train_s_L3.iloc[x]).std()\n        L3_std.append(a)\n        x=x+1\n    train_s['L3_min']=L3_min\n    train_s['L3_max']=L3_max\n    train_s['L3_mean']=L3_mean\n    train_s['L3_std']=L3_std\n    train_s_L4=train_s[features_label[features_label.label==4].feature]\n    L4_min=[]\n    for x in range(len(train_s_L4)):\n        a=np.array(train_s_L4.iloc[x]).min()\n        L4_min.append(a)\n        x=x+1\n    L4_max=[]\n    for x in range(len(train_s_L4)):\n        a=np.array(train_s_L4.iloc[x]).max()\n        L4_max.append(a)\n        x=x+1\n    L4_mean=[]\n    for x in range(len(train_s_L4)):\n        a=np.array(train_s_L4.iloc[x]).mean()\n        L4_mean.append(a)\n        x=x+1\n    L4_std=[]\n    for x in range(len(train_s_L4)):\n        a=np.array(train_s_L4.iloc[x]).std()\n        L4_std.append(a)\n        x=x+1\n    train_s['L4_min']=L4_min\n    train_s['L4_max']=L4_max\n    train_s['L4_mean']=L4_mean\n    train_s['L4_std']=L4_std\n    test_d=train_s[features]\n    print(test_d.head(2))\n    sample_prediction_df.action=0\n    sample_prediction_df.action = xgbr_model.predict(test_d)\n    print(sample_prediction_df.action.head(2))\n    for i in range(len(sample_prediction_df)):\n        if sample_prediction_df['action'].iloc[i]>=0.46:\n            sample_prediction_df['action'].iloc[i]=1\n        if sample_prediction_df['action'].iloc[i]<0.46:\n           sample_prediction_df['action'].iloc[i]=0\n    sample_prediction_df['action']=sample_prediction_df['action'].astype(int)\n    env.predict(sample_prediction_df)\n","67b4e5d1":" sample_prediction_df['action'].head()","09de7c63":"print(env)","2a8d7fa5":"iter_test","6abc4ac1":"![](http:\/\/)\u5220\u9664RESP\u7cfb\u5217\u503c\u540e\uff0c\u6839\u636edf_label\u5bf9train\u4e2d\u7684feature\u7684\u503c\u8fdb\u884c\u6807\u51c6\u5316\u64cd\u4f5c","3b2b3c30":"## \u5bf9features\u8fdb\u884c\u5206\u7c7b","ec720a1e":"# \u6839\u636e\u6574\u7406\u540e\u7684\u8bad\u7ec3\u96c6\u7528xgboost\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\u6570\u636e","71238eea":"**df_label\u5bf9\u5404\u4e2afeature\u8fdb\u884c\u4e86\u5206\u7c7b\u3002\u4e4b\u540e\u53ef\u4ee5\u6839\u636e\u8fd9\u4e2a\u5206\u7c7b\u60c5\u51b5\u5bf9feature\u503c\u8fdb\u884c\u6807\u51c6\u5316\u8fd0\u4f5c\u3002**","039e296c":"train_resp\u4e3atrain\u7684action\u4e3a\u6587\u4ef6\u3002"}}