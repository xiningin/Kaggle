{"cell_type":{"f8c07282":"code","ad4e05de":"code","0e9bf1a5":"code","d93cd259":"code","1e4f8f50":"code","b0d90ef5":"code","cd331e10":"code","e0cc09eb":"code","9b859ac8":"code","bf2a489a":"code","8aad7aa7":"code","d5d84cbf":"code","5d20e331":"code","30cdc678":"code","7b9d3347":"code","c867189a":"code","684d93c9":"code","400ee364":"code","31598a85":"code","2fac0185":"code","73b24cec":"code","9e143093":"code","e3975c73":"code","2eede38d":"code","ba7c7256":"code","d92bedf1":"code","59cf96a5":"code","df9854ca":"code","880d9084":"code","d086033f":"code","ed80239a":"code","d0cb5f56":"code","3e50d68a":"code","2674ab33":"code","bf984034":"markdown","e78f3c55":"markdown","26f0a890":"markdown","bec32c19":"markdown","6148e025":"markdown","b4e1530e":"markdown","51a7efee":"markdown","3cbcc9d0":"markdown","7ff5d061":"markdown","414caf6f":"markdown","fa75cb69":"markdown","68087f21":"markdown","527ea15a":"markdown","101292a4":"markdown","b58aa4ba":"markdown","192884ad":"markdown","9b320f2a":"markdown","955e25e4":"markdown","d05b438e":"markdown","bfb0462f":"markdown","b374fea0":"markdown","9c88012a":"markdown","b27ffd2d":"markdown","0c11afd1":"markdown","596c6cdb":"markdown","0d364a47":"markdown","71a6135a":"markdown","41979236":"markdown","ead14a80":"markdown","fdf386a0":"markdown","94b515fe":"markdown","9a748b12":"markdown","96edf8a8":"markdown","63817f2c":"markdown","6ecec7b0":"markdown","899b375e":"markdown","a0a67c4b":"markdown","7a0604dd":"markdown","e28de042":"markdown"},"source":{"f8c07282":"import pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau","ad4e05de":"train=pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest=pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\nsample_sub=pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')","0e9bf1a5":"print('The Train  dataset has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\nprint('The Test  dataset has {} rows and {} columns'.format(test.shape[0],test.shape[1]))\n","d93cd259":"train.head(3)","1e4f8f50":"test.head(3)\ntest=test.drop('id',axis=1)\n","b0d90ef5":"y=train.label.value_counts()\nsns.barplot(y.index,y)","cd331e10":"X_train=train.drop('label',axis=1)\nY_train=train.label","e0cc09eb":"X_train=X_train\/255\ntest=test\/255","9b859ac8":"X_train=X_train.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)","bf2a489a":"print('The shape of train set now is',X_train.shape)\nprint('The shape of test set now is',test.shape)\n","8aad7aa7":"Y_train=to_categorical(Y_train)","d5d84cbf":"X_train,X_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=42,test_size=0.15)","5d20e331":"plt.imshow(X_train[0][:,:,0])","30cdc678":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n","7b9d3347":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=.15))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=0.15))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=.15))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation = \"softmax\"))","c867189a":"model.summary()","684d93c9":"optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)","400ee364":"model.compile(optimizer=optimizer,loss=['categorical_crossentropy'],metrics=['accuracy'])","31598a85":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","2fac0185":"epochs=5 #change this to 30 if you need to get better score\nbatch_size=64","73b24cec":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","9e143093":"fig,ax=plt.subplots(2,1)\nfig.set\nx=range(1,1+epochs)\nax[0].plot(x,history.history['loss'],color='red')\nax[0].plot(x,history.history['val_loss'],color='blue')\n\nax[1].plot(x,history.history['accuracy'],color='red')\nax[1].plot(x,history.history['val_accuracy'],color='blue')\nax[0].legend(['trainng loss','validation loss'])\nax[1].legend(['trainng acc','validation acc'])\nplt.xlabel('Number of epochs')\nplt.ylabel('accuracy')\n","e3975c73":"y_pre_test=model.predict(X_test)\ny_pre_test=np.argmax(y_pre_test,axis=1)\ny_test=np.argmax(y_test,axis=1)\n","2eede38d":"conf=confusion_matrix(y_test,y_pre_test)\nconf=pd.DataFrame(conf,index=range(0,10),columns=range(0,10))\n\n","ba7c7256":"conf","d92bedf1":"plt.figure(figsize=(8,6))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(conf, annot=True,annot_kws={\"size\": 16},cmap=plt.cm.Blues)# font size","59cf96a5":"x=(y_pre_test-y_test!=0).tolist()\nx=[i for i,l in enumerate(x) if l!=False]","df9854ca":"fig,ax=plt.subplots(1,4,sharey=False,figsize=(15,15))\n\nfor i in range(4):\n    ax[i].imshow(X_test[x[i]][:,:,0])\n    ax[i].set_xlabel('Real {}, Predicted {}'.format(y_test[x[i]],y_pre_test[x[i]]))\n\n","880d9084":"test=pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')","d086033f":"test_id=test.id\n\ntest=test.drop('id',axis=1)\ntest=test\/255\ntest=test.values.reshape(-1,28,28,1)\n","ed80239a":"test.shape","d0cb5f56":"y_pre=model.predict(test)     ##making prediction\ny_pre=np.argmax(y_pre,axis=1) ##changing the prediction intro labels","3e50d68a":"sample_sub['label']=y_pre\nsample_sub.to_csv('submission.csv',index=False)\n","2674ab33":"sample_sub.head()","bf984034":"### Fitting our model <a id='5'><\/a>","e78f3c55":"## Making a Submission <a id='7'><\/a>\n","26f0a890":"## Introduction\n\nIn this Kernel We will learn about Convolution Neural Networks.After reading this notebook you will learn:\n- [Basic Understanding of data](#1)\n- [Preparing our data](#2)\n- [How a CNN works](#3)\n- [How tp build a CNN](#4)\n- [How to Make prediction](#5) \n- [How to Evaluate your model](#6)\n- [How to make submission](#7)\n\n\n<p><font size='5' color='red'> If you like my work,please consider giving an upvote !<\/font><\/p>","bec32c19":"## Modelling <a id='4' ><\/a>","6148e025":"### Encoding Target Values","b4e1530e":"Now we will encode our target value.Keras inbuild library to_categorical() is used to do the on-hot encoding.","51a7efee":"Now we will split out training data into train and validation data.15percent of the training data will be used for validation purpose.","3cbcc9d0":"It's Nine in Kannada\n","7ff5d061":"### More data !","414caf6f":"## A breif Intro to CNN <a id='3' ><\/a>\n\nWe will first learn about the convolution operation\n**Edge Detection Example**\n![](https:\/\/i2.wp.com\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/12\/Screenshot-from-2018-12-07-15-47-38.png?resize=673%2C358&ssl=1)\n\nSo, we take the first 3 X 3 matrix from the 6 X 6 image and multiply it with the filter. Now, the first element of the 4 X 4 output will be the sum of the element-wise product of these values, i.e. 10 x 1 + 10 x 0 + 10 x -1 + 10 x 1 + 10 x 0 + 10 x -1 + 10 x 1 + 10 x 0 + 10 x -1 = 0. To calculate the second element of the 4 X 4 output, we will shift our filter one step towards the right and again get the sum of the element-wise product.\nWe can see that after the entire operation the new matrix seperates the edges.\n### Padding\nwe can pad the image with an additional border, i.e., we add one pixel all around the edges. This means that the input will be an 8 X 8 matrix (instead of a 6 X 6 matrix). Applying convolution of 3 X 3 on it will result in a 6 X 6 matrix which is the original shape of the image. This is where padding comes to the fore:\n\n    Input: n X n\n    Padding: p\n    Filter size: f X f\n    Output: (n+2p-f+1) X (n+2p-f+1)\n\nThere are two common choices for padding:\n\n    Valid: It means no padding. If we are using valid padding, the output will be (n-f+1) X (n-f+1)\n    Same: Here, we apply padding so that the output size is the same as the input size, i.e.,\n    n+2p-f+1 = n\n    So, p = (f-1)\/2\n\nWe now know how to use padded convolution. This way we don\u2019t lose a lot of information and the image does not shrink either. Next, we will look at how to implement strided convolutions.\n\n### Pooling Layers\n\nPooling layers are generally used to reduce the size of the inputs and hence speed up the computation. Consider a 4 X 4 matrix as shown below:\n![](https:\/\/i2.wp.com\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/12\/Screenshot-from-2018-12-10-12-50-40.png?resize=271%2C93&ssl=1)\nApplying max pooling on this matrix will result in a 2 X 2 output.\n\n\n### CNN Example\n\nWe\u2019ll take things up a notch now. Let\u2019s look at how a convolution neural network with convolutional and pooling layer works. Suppose we have an input of shape 32 X 32 X 3:\n\n![](https:\/\/i0.wp.com\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/12\/Screenshot-from-2018-12-10-14-07-58.png?resize=767%2C200&ssl=1)\n\nThere are a combination of convolution and pooling layers at the beginning, a few fully connected layers at the end and finally a softmax classifier to classify the input into various categories. There are a lot of hyperparameters in this network which we have to specify as well.\n\nGenerally, we take the set of hyperparameters which have been used in proven research and they end up doing well. As seen in the above example, the height and width of the input shrinks as we go deeper into the network (from 32 X 32 to 5 X 5) and the number of channels increases (from 3 to 10).\n","fa75cb69":"### Optimizer\nIn simpler terms, optimizers shape and mold your model into its most accurate possible form by futzing with the weights. The loss function is the guide to the terrain, telling the optimizer when it\u2019s moving in the right or wrong direction.\n\n![](https:\/\/blog.algorithmia.com\/wp-content\/uploads\/2018\/05\/word-image.png)","68087f21":"### Reshape","527ea15a":"## Data preparation <a id='2'><\/a>","101292a4":"### Learning rate reduction","b58aa4ba":"## Evaluating our approach <a id='6'><\/a>","192884ad":"Before jumping to all complex stuff about Convolutions and all,we will simply understand our data.We will learn and gain basic understanding about this data.","9b320f2a":"All Set,We have our data reshape into 60000 examples of height 28 and width 28 and 1 channel.","955e25e4":"In order to avoid overfitting problem, we need to expand artificially our handwritten digit dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n\nFor example, the number is not centered The scale is not the same (some who write with big\/small numbers) The image is rotated...\n\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\n","d05b438e":"### Splitting train and test","bfb0462f":"### Understanding the data <a id=\"1\" ><\/a>","b374fea0":"hmm...Not all them,but some of them are a bit tough ones.","9c88012a":"In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n\nThe LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n\nIts better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n\nTo keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n\nWith the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs.","b27ffd2d":"## Further Investigation..\n\nWe will go on to see some of the misclassified images.We will simply inspect them to understand if it was a tough one to predict or not.Let's see...","0c11afd1":"Now we can see that all of the classes has equal distribution.There are 6000 examples of each numbers in kannada in the the training dataset.Cool !","596c6cdb":"### CNN\n\nI used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n\nThe first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\nDropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n\n'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n\nThe Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.\n\nHere is the link to original article.\n[credits](https:\/\/www.analyticsvidhya.com\/blog\/2018\/12\/guide-convolutional-neural-network-cnn\/)","0d364a47":"\n<html>\n<body>\n\n<p><font size=\"5\" color=\"red\">If you like my kernel please consider upvoting it<\/font><\/p>\n<p><font size=\"4\" color=\"blue\">Don't hesitate to give your suggestions in the comment section<\/font><\/p>\n<p><font size=\"3\" color=\"green\">Thank you...<\/font><\/p>\n\n\n<\/body>\n<\/html>","71a6135a":"## Importing whatever we need !","41979236":"### Normalize Pixel Values\n\nFor most image data, the pixel values are integers with values between 0 and 255.\n\nNeural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n\nIt is valid for images to have pixel values in the range 0-1 and images can be viewed normally.\n\nThis can be achieved by dividing all pixels values by the largest pixel value; that is 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the image.","ead14a80":"### Loading data","fdf386a0":"We will make our prediction using our CNN model.","94b515fe":"### Confusion matrix\n\nConfusion matrix can be pretty usefull when evaluating  multiclass classifications.We can see which are classes are misclassified by our model clearly.","9a748b12":"We will mainly use 3 libraries.\n- **pandas :** It's used to handle our csv files.\n- **matplotlib & seaborn :** Used for charting and plotting.\n- **sklearn :** Popular ML library.We will use it for splitting our data.\n- **Keras :** Popular Deep learning library,we will use it to build our CNN Network.","96edf8a8":"We have plotted the performance of our model.We can see the number of epochs in the X axis and change in model performance in Y axis.","63817f2c":"Here we can see that our model is doing a pretty good job in almost all digits.But it seems to have some confusions between \n- 0 and 1 : we can observe that some 0s and 1s are misclassified.\n- 7 and 6 : we can observe that some 6s and 7s are misclassifies.","6ecec7b0":"![](https:\/\/cdn3.vectorstock.com\/i\/1000x1000\/98\/02\/set-of-monochrome-icons-with-kannada-numbers-vector-15469802.jpg)","899b375e":"Now you can see that there are 785 columns in the training dataset given.I will describe each one of them here...\n- **Label :** This contains the label which are going to predict.That is our target value.Here it is numbers from 0 to 9.We will plot a bar graph and see the distribution of this target value later.\n- **Pixel0 to Pixel783: **These are the pixel values of the image metrics.That is each row contains 28 * 28 = 784 (0-783 here) values here.Each one of these values indicates the pixel value at i x 28 + j th pixel position in the image metric.Simple !\n","a0a67c4b":"**Unhide Above output to see the summary**","7a0604dd":"For the data augmentation, i choosed to :\n\n   - Randomly rotate some training images by 10 degrees\n   - Randomly Zoom by 10% some training images\n   - Randomly shift images horizontally by 10% of the width\n   - Randomly shift images vertically by 10% of the height\n\nI did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.","e28de042":"### Checking Target class distribution..\n"}}