{"cell_type":{"25fa080a":"code","a9187032":"code","7c7aa58f":"code","a46e03e0":"code","485975a3":"code","38647419":"code","4f934f24":"code","da2d5a39":"code","b47dace0":"code","bbce8e39":"code","6dd2cc76":"code","a3c76463":"code","c5b7e76c":"code","1a4f0018":"code","fda38e23":"code","fc576049":"code","147ae3f7":"code","16497bac":"code","2323ab64":"code","2cc0b976":"code","abe5c339":"code","2bb75e1f":"code","0d764656":"code","7ccf5231":"code","ffcc311e":"code","ffa32285":"code","1d65f459":"code","1d53a4f5":"code","76674ff2":"code","6bbd107e":"code","3ae3b19a":"code","f5e5dd7b":"code","5f9e281a":"code","44c0a59c":"code","dacad9e1":"code","67adb4fc":"code","4a9596b5":"code","17ee6760":"code","0d4ff0ae":"code","66bf3522":"code","45dfe0bd":"code","5963f788":"code","96ba4aa3":"code","0382ac7e":"code","689780f9":"markdown","d540ab2e":"markdown","50c281da":"markdown","7f3a614b":"markdown","9bef3fd3":"markdown","07d8406a":"markdown","0a0082e8":"markdown","7241e78f":"markdown","9c89036c":"markdown","653e9e8f":"markdown","550c4ede":"markdown","6cf8edac":"markdown","286c9912":"markdown"},"source":{"25fa080a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9187032":"train_data = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntrain_data.shape","7c7aa58f":"corr = (train_data.drop(['target','id'], axis=1)).corrwith(train_data[\"target\"])\n\nplt.figure(figsize=(50,10))\nplt.bar(x=corr.index, height=corr)\nplt.show()","a46e03e0":"sorted_corr = corr.sort_values()\n\nplt.figure(figsize=(50,10))\nplt.bar(x=sorted_corr.index, height=sorted_corr)\nplt.axhline(y=0.03, color='red', linestyle='--')\nplt.axhline(y=-0.03, color='red', linestyle='--')\nplt.show()\n","485975a3":"corr_df = pd.DataFrame(corr)\nthreshold = 0.03\n\nfilter_data = corr_df.loc[abs(corr_df[0]) > threshold]","38647419":"filter_id = list(filter_data.index)","4f934f24":"# Let's create a function that return filtered features column\ndef filter_index(corr, thresholds):\n    corr_df = pd.DataFrame(corr)\n\n    filter_data = corr_df.loc[abs(corr_df[0]) > thresholds]\n    filter_id = list(filter_data.index)\n    \n    return filter_id","da2d5a39":"from sklearn.model_selection import train_test_split\n\nX = train_data.drop(['id', 'target'], axis=1)\ny = train_data['target']\ny = y.astype('int')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.2)","b47dace0":"X_train.shape","bbce8e39":"y_train.head()","6dd2cc76":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nscaler.fit_transform(X_train)\n","a3c76463":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(solver='sag')\nlog_reg.fit(X_train, y_train)","c5b7e76c":"X_test_scale = scaler.fit_transform(X_test)","1a4f0018":"y_hat_lr = log_reg.predict(X_test_scale)","fda38e23":"# Getting probability for each prediction\ny_score_lr = log_reg.predict_proba(X_test_scale)[:, 1]","fc576049":"from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\nimport matplotlib.pyplot as plt\n\ndef showing_score(y_true, y_predic):\n       \n    print(\"The confusion matrix\")\n    print(confusion_matrix(y_true, y_predict))\n    print()\n    print(\"Accuracy score: \", accuracy_score(y_true, y_predict))\n    \ndef plotting_roc(y_true, y_score):\n    \n    fpr, tpr, thresholds = roc_curve(y_true ,y_score, pos_label=1)\n    \n    roc_auc = auc(fpr, tpr)\n    \n    plt.plot(fpr, tpr ,label=\"ROC line (AUC = %.2f)\" % roc_auc)\n    plt.plot([0,1], color='red', linestyle='--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.xlim(0, 1.05)\n    plt.ylabel(\"True Positive Rate\")\n    plt.ylim(0, 1.05)\n    plt.legend(loc=\"lower right\")\n    plt.title(\"ROC curve\")\n    \n    \n","147ae3f7":"plotting_roc(y_test, y_score_lr)","16497bac":"filter_id = filter_index(corr, thresholds=0.01)","2323ab64":"X_filter = X.loc[:, filter_id]","2cc0b976":"X_filter.shape","abe5c339":"X_filter_train, X_filter_test, y_filter_train, y_filter_test = train_test_split(X_filter, y, random_state=2, test_size=0.2)","2bb75e1f":"X_train_fil_scal = scaler.fit_transform(X_filter_train)\nX_test_fil_scal = scaler.fit_transform(X_filter_test)","0d764656":"log_reg_fil = LogisticRegression(solver='sag')\n\nlog_reg_fil.fit(X_train_fil_scal, y_filter_train)","7ccf5231":"y_score_train = log_reg_fil.predict_proba(X_train_fil_scal)[:, 1]\n\nplotting_roc(y_filter_train, y_score_train)","ffcc311e":"y_score_filter = log_reg_fil.predict_proba(X_test_fil_scal)[:, 1]","ffa32285":"y_score_filter","1d65f459":"plotting_roc(y_filter_test, y_score_filter)","1d53a4f5":"from sklearn.base import clone\n\ndef filter_plot(X, y, filter):\n    X_filter = X.loc[:, filter]\n    \n    X_filter_train, X_filter_test, y_filter_train, y_filter_test = train_test_split(X_filter, y, random_state=2, test_size=0.2)\n    \n    X_train_fil_scal = scaler.fit_transform(X_filter_train)\n    X_test_fil_scal = scaler.fit_transform(X_filter_test)\n    \n    log_reg_fil = LogisticRegression(solver='sag')\n\n    log_reg_fil.fit(X_train_fil_scal, y_filter_train)\n    \n    y_score_filter = log_reg_fil.predict_proba(X_test_fil_scal)[:, 1]\n    \n    plotting_roc(y_filter_test, y_score_filter)\n    plt.show()\n    \n    return clone(log_reg_fil)","76674ff2":"filter_id_005 = filter_index(corr, thresholds=0.05)","6bbd107e":"filter_plot(X, y, filter_id_005)","3ae3b19a":"filter_id_001 = filter_index(corr, thresholds=0.01)\nprint(len(filter_id_001))\nlog_reg_filter_001 = filter_plot(X, y, filter_id_001)","f5e5dd7b":"# Making a prediction on the test.csv data\n\nfilter_ind = filter_index(corr, thresholds=0.01)\n\ntest_data = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\n","5f9e281a":"test_data['id']","44c0a59c":"test_data.head()\nX_test = test_data.loc[:, filter_ind]\nX_test.shape\n","dacad9e1":"scaler.fit_transform(X_test)\n","67adb4fc":"y_hat = log_reg_fil.predict_proba(X_test)","4a9596b5":"pd.DataFrame(y_hat)","17ee6760":"y_score_test = y_hat[:, 1]\n\nsubmission_csv = pd.DataFrame({'id':test_data['id'], \n                               'target':y_score_test,}, columns=['id', 'target'])\n\nsubmission_csv.set_index('id', inplace=True)","0d4ff0ae":"submission_csv.head()","66bf3522":"# saving to csv file\nsubmission_csv.to_csv(\".\/submission.csv\")\n","45dfe0bd":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")","5963f788":"sample.head()","96ba4aa3":"1.470031e-01","0382ac7e":"9.941410e-01","689780f9":"Below is my attempt trying to change the thresholds value\n","d540ab2e":"### Here is the sample submission.","50c281da":"### Exploring the correlation in the data","7f3a614b":"From the data correlation, we found that there are very symmetrical correlation in both side\n\nWe will define a threshold to drop the data that correlation is lower than 0.3","9bef3fd3":"We have 60000 instance with 100 features","07d8406a":"### This unfiltered logistic regression model give AUC = 0.74\n\nLet's try to filter the data using the function written above","0a0082e8":"### Let's build some model.\n","7241e78f":"We use thresholds = 0.01 and as a result\n\nWe filtered the data down to 77 features","9c89036c":"We got better result as we using the threshold of 0.01","653e9e8f":"Try using logistic regression","550c4ede":"# Let's process the training data.\nWe will try using the whole dataset without applying the threshold first","6cf8edac":"### Downloading the data","286c9912":"We got worse result from using the threshold as 0.72"}}