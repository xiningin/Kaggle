{"cell_type":{"211ff7c4":"code","e7bf16d8":"code","3819227b":"code","bef5b36c":"code","cebd7e61":"code","70c2f788":"code","fb1de857":"code","ec95669a":"code","860f9a16":"code","29a08088":"code","18d525d9":"code","10addd5c":"code","ce267af7":"code","b77c5981":"code","e57e7cae":"code","b00018ed":"code","36c68a79":"code","4c52c5ae":"code","a81aa5b9":"code","85e9ead2":"code","83543967":"code","c507253d":"code","d7325981":"code","3c02b258":"code","d284f9ca":"code","29c6a0f9":"code","581e621b":"code","fd4d168e":"code","7cb25ba5":"code","6d93b3bd":"code","ee16afac":"code","0ce4433f":"code","f32a0b94":"code","a21a4857":"code","d463afd4":"code","fde864a2":"code","2c289b8b":"code","7d303bd6":"code","7a5c9b55":"code","89122115":"code","b266428f":"code","c231aee4":"code","7a9097ee":"code","792c5604":"code","517fd013":"code","99506fe2":"code","ab45d44b":"markdown","50411285":"markdown","41375cf2":"markdown","51471ca2":"markdown","d144a850":"markdown","698fa87b":"markdown","83a8d63d":"markdown","10355a4e":"markdown","6c576771":"markdown","4600021c":"markdown","9eac7e92":"markdown","52cf38ad":"markdown","dce84d2a":"markdown","77b8b6ac":"markdown","f56e58ef":"markdown","dcd3fa95":"markdown","96d34a22":"markdown","b66e92cd":"markdown","a5056d1b":"markdown","bb493234":"markdown","74d3cd18":"markdown","33618061":"markdown","63eea350":"markdown","1117bbf1":"markdown","9f7937e8":"markdown","42614570":"markdown","f5acfa9e":"markdown","ea93ef7e":"markdown","ac81028b":"markdown","5cb86886":"markdown","fe3d6df3":"markdown","8819cd0f":"markdown","7306b5ee":"markdown","2ab962c9":"markdown","52d579b7":"markdown","f89a8867":"markdown","d0e65c6b":"markdown","819a648c":"markdown","f96db787":"markdown","b2fb5b91":"markdown","9c5948fa":"markdown","e4b0c03f":"markdown","28046b95":"markdown","071bc90d":"markdown","e501ff83":"markdown","81c771ea":"markdown","fd291a53":"markdown"},"source":{"211ff7c4":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport albumentations as A\nimport random\nimport torch","e7bf16d8":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\ndef visualize(image):\n    plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(image)\n    \ndef visualize_multiple(nrows, ncols, img, transform):\n    fig, axes = plt.subplots(nrows,ncols)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    num_iter = 0\n    for row in range(nrows):\n        for col in range(ncols):\n            augmented_img = transform[num_iter](image=img)['image']\n            axes[row,col].imshow(augmented_img)\n            axes[row,col].grid(False)\n            axes[row,col].set_xticks([])\n            axes[row,col].set_yticks([])\n            num_iter += 1\n    return fig, axes","3819227b":"seed_everything(100)\nimg = cv2.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/100042118.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nvisualize(img)","bef5b36c":"blur_limits = np.arange(3,39,4)\ntransform = [A.Blur(p=1, blur_limit=[limit,limit], always_apply=True) for limit in blur_limits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Blur kernel size: ({}, {})'.format(blur_limits[num_iter], blur_limits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","cebd7e61":"params = np.arange(3,30,3)\ntransform = [A.CLAHE(clip_limit=[param, param], tile_grid_size=(param, param), always_apply=True) for param in params]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Clip limit: ({}, {}), tile grid size: ({}, {})'.format(params[num_iter], params[num_iter], params[num_iter], params[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","70c2f788":"transform = [A.ChannelDropout(channel_drop_range=(1,2), always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","fb1de857":"transform = [A.ChannelShuffle(p=1) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","ec95669a":"transform = [A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","860f9a16":"transform = [A.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","29a08088":"params = [['cv', True], ['cv', False], ['pil', True], ['pil', False]]\ntransform = [A.Equalize(mode=param[0], by_channels=param[1], always_apply=True) for param in params]\nfig, axes = visualize_multiple(2,2,img,transform)\n\nnum_iter = 0\nfor row in range(2):\n    for col in range(2):\n        text = 'Mode: {}, By channels: {}'.format(params[num_iter][0], params[num_iter][1])\n        axes[row, col].set_title(text)\n        num_iter += 1","18d525d9":"params = np.arange(0.1,1.0,0.1)\ntransform = [A.FancyPCA(alpha=param, always_apply=True) for param in params]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Alpha: {:.1f}'.format(params[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","10addd5c":"params = np.arange(1000, 10000, 1000)\ntransform = [A.GaussNoise(var_limit=(param-500, param), mean=0, always_apply=True) for param in params]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Variance range: ({}, {})'.format(params[num_iter]-500, params[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","ce267af7":"blur_limits = np.arange(3,39,4)\ntransform = [A.GaussianBlur(blur_limit=(limit, limit), always_apply=True) for limit in blur_limits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Kernel size: ({}, {})'.format(blur_limits[num_iter], blur_limits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","b77c5981":"sigmas = np.arange(0.5, 5.0, 0.5)\ntransform = [A.GlassBlur(sigma=sigma, max_delta=4, iterations=2, always_apply=True) for sigma in sigmas]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Sigma: {}'.format(sigmas[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","e57e7cae":"transform = [A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=True) for sigma in sigmas]\nfig, axes = visualize_multiple(3,3,img,transform)","b00018ed":"locs = np.arange(10,100,10)\ntransform = [A.IAAAdditiveGaussianNoise(loc=loc, scale=(2.5500000000000003, 12.75), always_apply=True) for loc in locs]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Mean: {}'.format(locs[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","36c68a79":"alphas = np.arange(0.1, 1.0, 0.1)\nlightness = np.arange(0.1, 1.0, 0.1)\ntransform = [A.IAASharpen(alpha=(alpha, alpha), lightness=(light, light), always_apply=True) for alpha, light in zip(alphas, lightness)]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Alpha: {:.1f}, Lightness: {:.1f}'.format(alphas[num_iter], lightness[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","4c52c5ae":"transform = [A.IAASuperpixels(p_replace=0.1, n_segments=100, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","a81aa5b9":"color_shifts = np.arange(0.01, 0.1, 0.01)\nintensities = np.arange(0.1, 1.0, 0.1)\ntransform = [A.ISONoise(color_shift=(shift, shift), intensity=(intensity, intensity), always_apply=True) for shift, intensity in zip(color_shifts, intensities)]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Color shift: {:.2f}, Intensity: {:.2f}'.format(color_shifts[num_iter], intensities[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","85e9ead2":"transform = [A.InvertImg(p=1.0), A.InvertImg(p=0.0), A.InvertImg(p=0.0), A.InvertImg(p=1.0)]\nfig, axes = visualize_multiple(2,2,img,transform)\n\nnum_iter = 0\nfor row in range(2):\n    for col in range(2):\n        text = 'Inverted' if num_iter==0 or num_iter==3 else 'Normal'\n        axes[row, col].set_title(text)\n        num_iter += 1","83543967":"blur_limits = np.arange(5, 30, 2)\ntransform = [A.MedianBlur(blur_limit=(limit,limit), always_apply=True) for limit in blur_limits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Blur limit: {}'.format(blur_limits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","c507253d":"blur_limits = np.arange(7, 30, 2)\ntransform = [A.MotionBlur(blur_limit=(limit,limit), always_apply=True) for limit in blur_limits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Blur limit: {}'.format(blur_limits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","d7325981":"multipliers = np.arange(0.5, 1.5, 0.1)\ntransform = [A.MultiplicativeNoise(multiplier=plier, always_apply=True) for plier in multipliers]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Multiplier: {:.1f}'.format(multipliers[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","3c02b258":"list_num_bits = np.arange(0,9,1)\ntransform = [A.Posterize(num_bits=int(num_bits), always_apply=True) for num_bits in list_num_bits]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Num bits: {}'.format(list_num_bits[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","d284f9ca":"transform = [A.RGBShift(always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","29c6a0f9":"transform = [A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","581e621b":"transform = [A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=1, alpha_coef=0.08, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","fd4d168e":"transform = [A.RandomGamma(gamma_limit=(50, 250), always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","7cb25ba5":"rain_types = [None, 'drizzle', 'heavy', 'torrential']\ntransform = [A.RandomRain(slant_lower=-10, slant_upper=10, \n                          drop_length=20, drop_width=1, drop_color=(200, 200, 200), \n                          blur_value=7, brightness_coefficient=0.7, \n                          rain_type=rain_type, always_apply=True) for rain_type in rain_types]\nfig, axes = visualize_multiple(2,2,img,transform)\n\nnum_iter = 0\nfor row in range(2):\n    for col in range(2):\n        text = 'Rain type: {}'.format(rain_types[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","6d93b3bd":"transform = [A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), \n                            num_shadows_lower=1, num_shadows_upper=4, \n                            shadow_dimension=5, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","ee16afac":"transform = [A.RandomSnow(snow_point_lower=0.1, \n                          snow_point_upper=0.3, \n                          brightness_coeff=2.5, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","0ce4433f":"transform = [A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), \n                              angle_lower=0, angle_upper=1, \n                              num_flare_circles_lower=6, \n                              num_flare_circles_upper=10, \n                              src_radius=400, src_color=(255, 255, 255),\n                              always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","f32a0b94":"thresholds = np.arange(10, 255, 20)\ntransform = [A.Solarize(threshold=int(thresh), always_apply=True) for thresh in thresholds]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Threshold: {}'.format(thresholds[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","a21a4857":"crop_sizes = np.arange(50, 500, 50)\ntransform = [A.CenterCrop(height=crop_size, width=crop_size, always_apply=True) for crop_size in crop_sizes]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Crop size: ({}, {})'.format(crop_sizes[num_iter], crop_sizes[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","d463afd4":"hole_sizes = np.arange(10, 100, 10)\ntransform = [A.CoarseDropout(max_holes=8, max_height=hole_size, max_width=hole_size, \n                             min_holes=None, min_height=hole_size, min_width=hole_size,\n                             always_apply=True) for hole_size in hole_sizes]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Hole size: ({}, {})'.format(hole_sizes[num_iter], hole_sizes[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","fde864a2":"transform = [A.Crop(x_min=random.randint(0, 100), \n                    y_min=random.randint(0, 75), \n                    x_max=random.randint(200, img.shape[1]), \n                    y_max=random.randint(200, img.shape[0]), \n                    always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","2c289b8b":"transform = [A.Flip(p=0.75) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","7d303bd6":"transform = [A.GridDistortion(always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","7a5c9b55":"transform = [A.GridDropout(ratio=0.5, \n                           unit_size_min=random.randint(0, 50), \n                           unit_size_max=random.randint(60, 100), \n                           holes_number_x=random.randint(0, 5), \n                           holes_number_y=random.randint(0, 5), \n                           always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","89122115":"transform = [A.IAAAffine(scale=1.0, \n                         translate_percent=random.randint(0,20), \n                         translate_px=None, \n                         rotate=random.randint(0,360), \n                         shear=random.randint(0,10), \n                         order=1, \n                         cval=0, \n                         mode='reflect',\n                         always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","b266428f":"transform = [A.OpticalDistortion(distort_limit=0.75, shift_limit=0.75, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","c231aee4":"grid_sizes = np.arange(2, 11, 1)\ntransform = [A.RandomGridShuffle(grid=(size,size), always_apply=True) for size in grid_sizes]\nfig, axes = visualize_multiple(3,3,img,transform)\n\nnum_iter = 0\nfor row in range(3):\n    for col in range(3):\n        text = 'Grid size: ({}, {})'.format(grid_sizes[num_iter], grid_sizes[num_iter])\n        axes[row, col].set_title(text)\n        num_iter += 1","7a9097ee":"transform = [A.RandomResizedCrop(height=300, width=400, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","792c5604":"transform = [A.RandomRotate90(p=0.75) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","517fd013":"transform = [A.RandomScale(scale_limit=0.5, always_apply=True) for _ in range(9)]\nfig, axes = visualize_multiple(3,3,img,transform)","99506fe2":"transform = [A.Transpose(p=0.5) for _ in range(9)]\nfig, axes = visualize_multiple(2,2,img,transform)","ab45d44b":"# Visualizing Augmentations\nIn this notebook, I am trying to visualize various augmentation techniques available on Albumentations. Albumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.\n\nType of augmentations:\n1. Pixel-level transforms: Pixel-level transforms will change just an input image and will leave any additional targets such as masks, bounding boxes, and keypoints unchanged. \n2. Spatial-level transforms: Spatial-level transforms will simultaneously change both an input image as well as additional targets such as masks, bounding boxes, and keypoints. ","50411285":"## 1.13. IAA Additive Gaussian Noise\nAdd gaussian noise to the input image.","41375cf2":"## 1.16. ISO Noise\nApply camera sensor noise.","51471ca2":"## 2.1. Center Crop\nCrop the central part of the input.","d144a850":"# 1.0. Pixel-Level Transforms\nPixel-level transforms will change just an input image and will leave any additional targets such as masks, bounding boxes, and keypoints unchanged.","698fa87b":"## 1.10. Gaussian Blur\nBlur the input image using a Gaussian filter with a random kernel size.","83a8d63d":"## 1.27. Random Shadow\nSimulates shadows for the image","10355a4e":"## 1.4. Channel Shuffle\nRandomly rearrange channels of the input RGB image.","6c576771":"## 1.21. Posterize\nReduce the number of bits for each color channel.","4600021c":"## 1.28. Random Snow \nBleach out some pixel values simulating snow.","9eac7e92":"## 1.30. Solarize\nInvert all pixel values above a threshold.","52cf38ad":"## 1.15. IAA Superpixels\nCompletely or partially transform the input image to its superpixel representation. Uses skimage's version of the SLIC algorithm. May be slow.","dce84d2a":"## 2.7. IAA Affine\nPlace a regular grid of points on the input and randomly move the neighbourhood of these point around via affine transformations.","77b8b6ac":"## 1.5. Color Jitter\nRandomly changes the brightness, contrast, and saturation of an image. Compared to ColorJitter from torchvision, this transform gives a little bit different results because Pillow (used in torchvision) and OpenCV (used in Albumentations) transform an image to HSV format by different formulas.","f56e58ef":"## 1.9. Gaussian Noise\nApply gaussian noise to the input image.","dcd3fa95":"## 1.2. CLAHE\nApply Contrast Limited Adaptive Histogram Equalization to the input image.","96d34a22":"## 1.7. Equalize\nEqualize the image histogram.","b66e92cd":"## 1.19. Motion Blur\nApply motion blur to the input image using a random-sized kernel.","a5056d1b":"## 2.6. Grid Dropout\nGridDropout, drops out rectangular regions of an image and the corresponding mask in a grid fashion.","bb493234":"## 2.13. Transpose\nTranspose the input by swapping rows and columns.","74d3cd18":"### Sample Image\nI pick one image from the Cassava dataset for as a sample.","33618061":"## 1.18. Median Blur\nBlur the input image using a median filter with a random aperture linear size.","63eea350":"## 1.12. Hue Saturation Value\nRandomly change hue, saturation and value of the input image.","1117bbf1":"## 1.22. RGB Shift\nRandomly shift values for each channel of the input RGB image.","9f7937e8":"## 2.4. Flip\nFlip the input either horizontally, vertically or both horizontally and vertically.","42614570":"## 1.14. IAA Sharpen\nSharpen the input image and overlays the result with the original image.","f5acfa9e":"## 2.12. Random Scale\nRandomly resize the input. Output image size is different from the input image size.","ea93ef7e":"## 1.6. Downscale\nDecreases image quality by downscaling and upscaling back.","ac81028b":"## 2.9. Random Grid Shuffle\nRandom shuffle grid's cells on image.","5cb86886":"## 1.11. Glass Blur\nApply glass noise to the input image.","fe3d6df3":"## 2.8. Optical Distortion","8819cd0f":"## 1.23. Random Brightness Contrast\nRandomly change brightness and contrast of the input image.","7306b5ee":"## 1.1. Blur\nBlur the input image using a random-sized kernel.","2ab962c9":"## 2.2. Coarse Dropout\nCoarseDropout of the rectangular regions in the image.","52d579b7":"## 1.25. Random Gamma","f89a8867":"## 1.3. Channel Dropout\nRandomly Drop Channels in the input Image.","d0e65c6b":"## 1.26. Random Rain\nAdds rain effects.","819a648c":"## 1.20. Multiplicative Noise\nMultiply image to random number or array of numbers.","f96db787":"# 2.0. Spatial-Level Transform\nSpatial-level transforms will simultaneously change both an input image as well as additional targets such as masks, bounding boxes, and keypoints.","b2fb5b91":"## 1.24. Random Fog\nSimulates fog for the image","9c5948fa":"## 2.10. Random Resized Crop\nTorchvision's variant of crop a random part of the input and rescale it to some size.","e4b0c03f":"## 2.11. Random Rotate 90\nRandomly rotate the input by 90 degrees zero or more times.","28046b95":"## 1.8. Fancy PCA\nAugment RGB image using FancyPCA from Krizhevsky's paper \"ImageNet Classification with Deep Convolutional Neural Networks\"","071bc90d":"## 2.5. Grid Distortion","e501ff83":"## 1.17. Invert Image\nInvert the input image by subtracting pixel values from 255.","81c771ea":"## 1.29. Random Sun Flare\nSimulates Sun Flare for the image","fd291a53":"## 2.3. Crop\nCrop region from image.**"}}