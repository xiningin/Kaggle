{"cell_type":{"c0237ffd":"code","2a74597f":"code","3b5b121e":"code","f252450f":"code","915429c1":"code","247c5806":"code","421c1a43":"code","d6b2e483":"code","d1342822":"code","a593ac68":"code","1172ac0d":"code","2c25ccb3":"code","1ab63f37":"code","e7cb42f1":"code","364b0ebf":"code","bd50cdc1":"markdown","3c3c05fa":"markdown","3a6e9966":"markdown","bb76353d":"markdown","a957442c":"markdown","864bb935":"markdown","1e18b000":"markdown","4847dee6":"markdown","227ceb9f":"markdown"},"source":{"c0237ffd":"# Used most of coding from this kernel \nimport optuna\nimport lightgbm as lgb\n\nimport riiideducation\nimport dask.dataframe as dd\nimport  pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score","2a74597f":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                usecols=[1, 2, 3,4,7,8,9], dtype={'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8','prior_question_elapsed_time': 'float32','prior_question_had_explanation': 'boolean'}\n              )\ntrain = train[train.content_type_id == False]\n#arrange by timestamp\n\n\ntrain = train.sort_values(['timestamp'], ascending=True)\n\ntrain.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n\nresults_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\nresults_u.columns = [\"answered_correctly_user\", 'sum']","3b5b121e":"#reading in question df\nquestions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',\n                            usecols=[0,1, 3,4],\n                            dtype={'question_id': 'int16',\n                              'part': 'int8','bundle_id': 'int8','tags': 'str'}\n                          )\ntag = questions_df[\"tags\"].str.split(\" \", n = 10, expand = True) \ntag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n\nquestions_df =  pd.concat([questions_df,tag],axis=1)\nquestions_df['tags1'] = pd.to_numeric(questions_df['tags1'], errors='coerce')\nquestions_df['tags2'] = pd.to_numeric(questions_df['tags2'], errors='coerce')\nquestions_df['tags3'] = pd.to_numeric(questions_df['tags3'], errors='coerce')\nquestions_df['tags4'] = pd.to_numeric(questions_df['tags4'], errors='coerce')\nquestions_df['tags5'] = pd.to_numeric(questions_df['tags5'], errors='coerce')\nquestions_df['tags6'] = pd.to_numeric(questions_df['tags6'], errors='coerce')","f252450f":"X = train.iloc[80000000:,:]\nX['prior_question_had_explanation'].fillna(False, inplace=True)\nX = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")\nX = pd.merge(X, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n\nX=X[X.answered_correctly!= -1 ]\nX=X.sort_values(['user_id'])\nY = X[[\"answered_correctly\"]]\nX = X.drop([\"answered_correctly\"], axis=1)","915429c1":"print('Training data shrinked from {:,} records ({:,} users) to {:,} records ({:,} users).'.format(train.shape[0], train['user_id'].nunique(), X.shape[0], X['user_id'].nunique()))","247c5806":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])\nX.head()\n\nX = X[['answered_correctly_user', 'answered_correctly_content', 'sum','bundle_id','part','prior_question_elapsed_time','prior_question_had_explanation_enc','tags1','tags2','tags3']] \nX.fillna(0.5,  inplace=True)\n\nfrom  sklearn.model_selection import train_test_split\nXt, Xv, Yt, Yv = train_test_split(X, Y, test_size = 0.2, shuffle=False)","421c1a43":"lgb_train = lgb.Dataset(Xt, Yt)\nlgb_eval = lgb.Dataset(Xv, Yv)\n\ndef objective(trial):    \n    params = {\n            'num_leaves': trial.suggest_int('num_leaves', 32, 512),\n            'boosting_type': 'gbdt',\n            'objective': 'binary',\n            'metric': 'auc',\n            'max_depth': trial.suggest_int('max_depth', 4, 16),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 16),\n            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n            'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n            'bagging_freq': trial.suggest_int('bagging_freq', 1, 8),\n            'min_child_samples': trial.suggest_int('min_child_samples', 4, 80),\n            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1.0),\n            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1.0),\n            'early_stopping_rounds': 10\n            }\n\n    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], verbose_eval=1000)\n    val_pred = model.predict(Xv)\n    score = roc_auc_score(Yv, val_pred)\n    print(f\"AUC = {score}\")\n    return score","d6b2e483":"# Bayesian optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=20)","d1342822":"print('Number of finished trials: {}'.format(len(study.trials)))\n\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('  Value: {}'.format(trial.value))\n\nprint('  Params: ')\nfor key, value in trial.params.items():\n    print('    {}: {}'.format(key, value))","a593ac68":"# plot history\nfrom optuna.visualization import plot_optimization_history\nplot_optimization_history(study)","1172ac0d":"model = lgb.train(trial.params, lgb_train, valid_sets=[lgb_train, lgb_eval], verbose_eval=1000)","2c25ccb3":"# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\n\nfi = pd.DataFrame()\nfi['features'] = X.columns.values.tolist()\nfi['importance'] = model.feature_importance(importance_type=\"gain\")\n\nsns.barplot(x='importance', y='features', data=fi.sort_values(by='importance', ascending=True))","1ab63f37":"y_pred = model.predict(Xv)\ny_true = np.array(Yv)\n\nprint('CV score (AUC) = {}'.format(roc_auc_score(y_true, y_pred)))","e7cb42f1":"env = riiideducation.make_env()","364b0ebf":"iter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.sort_values(['user_id','timestamp'], ascending=False)\n    test_df['answer_time'] = test_df.groupby(['user_id'])['prior_question_elapsed_time'].shift(1)\n    \n    test_df = pd.merge(test_df, results_u, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c, on=['content_id'],  how=\"left\")    \n    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')    \n    test_df['answered_correctly_user'].fillna(0.5, inplace=True)\n    test_df['answered_correctly_content'].fillna(0.5, inplace=True)\n    test_df['sum'].fillna(0, inplace=True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum','bundle_id','part','prior_question_elapsed_time','prior_question_had_explanation_enc',\n                                                           'tags1','tags2','tags3']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","bd50cdc1":"# Preprocess","3c3c05fa":"# Results from Optuna","3a6e9966":"# Hyperparameter Optimization","bb76353d":"# Feature importance","a957442c":"# Model fitting","864bb935":"Here I demonstrate how to use [Optuna](https:\/\/optuna.org\/) to get a better set of hyperparameters by the Bayesian Optimization.\n\nThis notebook is heavily based on \n\n- https:\/\/www.kaggle.com\/lgreig\/simple-lgbm-baseline\n- https:\/\/www.kaggle.com\/jsylas\/riiid-lgbm-starter\n\nPlease upvote these notebooks too.","1e18b000":"# Predictions","4847dee6":"# Fit with best params","227ceb9f":"# Validation Score"}}