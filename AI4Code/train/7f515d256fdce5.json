{"cell_type":{"33c03d81":"code","c49dc37e":"code","732e1d59":"code","e5f4ec0a":"code","7201c17a":"code","4289f5d7":"code","f0b10d92":"code","d21b7ce4":"code","d370b129":"code","a45f13b1":"markdown","b8f9d421":"markdown","6683ef93":"markdown","c347b2f9":"markdown","5a8d3b0e":"markdown"},"source":{"33c03d81":"!pip install bs4","c49dc37e":"from bs4 import BeautifulSoup as bSoup  # HTML data structure\nfrom urllib.request import urlopen # Web client","732e1d59":"# For an easy Web Scraping exsersice let's take AMD Motherboard as topic from Newegg.com\npage_url = \"https:\/\/www.newegg.com\/AMD-Motherboards\/SubCategory\/ID-22?Tid=7625&cm_sp=Cat_Motherboards_1-_-Visnav-_-AMD-Motherboards_2\"\n\n# opens the connection and downloads html page from url\nulink = urlopen(page_url)","e5f4ec0a":"# parses html into a soup data structure to traverse html\n# as if it were a json data type.\npage_soup = bSoup(ulink.read(), \"html.parser\")\nulink.close()","7201c17a":"#<div class=\"item-container\"> this is the html line for each item on the page\ncontainers = page_soup.findAll(\"div\", {\"class\": \"item-container\"})","4289f5d7":"# name the output file to write to local disk\nout_filename = \"mother_board.csv\"\n# header of csv file to be written\nheaders = \"brand,product_name,shipping \\n\"","f0b10d92":"# opens file, and writes headers\nf = open(out_filename, \"w\")\nf.write(headers)","d21b7ce4":"# let scrap for item at containers[0] first and then loop through for at least first 10 items in the web page.\ncontainer = containers[0]\nmake_rating_sp = container.div.select(\"a\")\nbrand = make_rating_sp[0].img[\"title\"].title()\nproduct_name = container.div.select(\"a\")[2].text\nshipping = container.findAll(\"li\", {\"class\": \"price-ship\"})[0].text.strip().replace(\"$\", \"\").replace(\" Shipping\", \"\")\nprint(brand,\"\\n\")\nprint(product_name,\"\\n\")\nprint(shipping,\"\\n\")","d370b129":"# Great let's loops for atleast 10 item\n# each product\nfor container in containers[:10]:\n    # Finds all link tags \"a\" from within the first div.\n    make_rating_sp = container.div.select(\"a\")\n\n    # Grabs the title from the image title attribute\n    # Then does proper casing using .title()\n    brand = make_rating_sp[0].img[\"title\"].title()\n\n    # Grabs the text within the second \"(a)\" tag from within\n    # the list of queries.\n    product_name = container.div.select(\"a\")[2].text\n\n    # From the product shipping information, search lists with the class \"price-ship\".\n    # To cleans the text of white space & \"Shipping $\" with strip(), so, we get number alone\n    shipping = container.findAll(\"li\", {\"class\": \"price-ship\"})[0].text.strip().replace(\"$\", \"\").replace(\" Shipping\", \"\")\n        \n    # prints the dataset to console\n    print(\"brand: \" + brand + \"\\n\")\n    print(\"product_name: \" + product_name + \"\\n\")\n    print(\"shipping: \" + shipping + \"\\n\")\n\n    # writes the dataset to file\n    f.write(brand + \", \" + product_name.replace(\",\", \"|\") + \", \" + shipping + \"\\n\")","a45f13b1":"#### Highligted line of html gives you complete item details.\n![drag.JPG](attachment:6971139d-74a6-4e3f-a8c0-da59369deba6.JPG)","b8f9d421":"### Web Scraping:\n#### Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the Web Page. Also, this ability help people\/programmers to implement data extarction algorithms with:\n#### *1. Automation.*\n#### *2. Cost-Effective.*\n#### *3. Easy Implementation.*\n#### *4. Low Maintenance.*\n#### *5. Speed.*\n#### *6. Data Accuracy.*\n#### *7. Effective Management of Data.*\n#### *8. Data Analysis.*","6683ef93":"#### A simple flow of web - scraping for over - view\n![image.png](attachment:5b8c5490-c8be-4038-9a81-447401c10f6d.png)","c347b2f9":"![image.png](attachment:eec19b68-5f2d-4357-a2b8-818a93f4a1ad.png)","5a8d3b0e":"#### 1. BeautifulSoup: \n##### Beautiful soup is a library for parsing HTML and XML documents. Requests (handles HTTP sessions and makes HTTP requests) in combination with BeautifulSoup (a parsing library) are the best package tools for small and quick web scraping.\n#### 2. Scrapy: \n##### Scrapy is a web crawling framework that provides a complete tool for scraping. In Scrapy, we create Spiders which are python classes that define how a particular site\/sites will be scrapped.\n#### 3. Selenium:\n##### For heavy-JS rendered pages or very sophisticated websites, Selenium webdriver is the best tool to choose. Selenium is a tool that automates the web-browsers, also known as a web-driver. "}}