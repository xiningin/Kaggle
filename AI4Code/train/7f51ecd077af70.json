{"cell_type":{"90af5549":"code","1117747e":"code","89687400":"code","667837c9":"code","abfb8ac2":"code","b979db2a":"code","b39534ee":"code","f60aa2e0":"code","5718d07b":"markdown","7f5d3765":"markdown","8517d4bd":"markdown","bdb87b3c":"markdown","50cc5909":"markdown","aad4142d":"markdown","f072f455":"markdown"},"source":{"90af5549":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nimport random\n\nimport cv2","1117747e":"NUM_CLASSES = 5\nNUM_SAMPLES_PER_CLASS = 1","89687400":"PATH = \"\/kaggle\/input\/omniglot\/omniglot\"\n\n# Get all alphabet folders\nalphabet_folders = [os.path.join(os.path.join(PATH, folder, alphabet))\n                    for folder in os.listdir(PATH)\n                        if os.path.isdir(os.path.join(PATH, folder))\n                            for alphabet in os.listdir(os.path.join(PATH, folder))\n                                if os.path.isdir(os.path.join(PATH, folder, alphabet))]\n\nprint(f\"The dataset contains {len(alphabet_folders)} alphabets.\")\n\n# Get all character folders\ncharacter_folders = [os.path.join(os.path.join(alphabet_path, character))\n                     for alphabet_path in alphabet_folders\n                         for character in os.listdir(alphabet_path)\n                             if os.path.isdir(os.path.join(alphabet_path, character))]\n\n# Sort alphabetically \ncharacter_folders = sorted(character_folders)\n\nprint(f\"The dataset contains {len(character_folders)} characters.\")\n\n# Get all images\nall_files = list()\nfor (dirpath, dirnames, filenames) in os.walk(PATH):\n    all_files += [os.path.join(dirpath, file) for file in filenames]\nprint(f\"The dataset contains {len(all_files)} images.\")","667837c9":"def read_and_propocess_image(img_path, image_dim=None):\n    \"\"\"\n    Takes an image path and returns a grayscale, resized, and flattened image as array\n    \n    Args:\n    * img_path: Full path to file\n    * image_dim: Resized image shape (width, height)\n    \n    Returns:\n    a grayscale, resized, and flattened image\n    \"\"\"\n    # Read image as grayscale\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    \n    # Resize image\n    if image_dim is not None:\n        img = cv2.resize(img, image_dim, interpolation = cv2.INTER_AREA) \n    \n    img = img.astype(np.float32) \/ 255.0\n    img = 1.0 - img\n    img = img.reshape(-1)\n    return img","abfb8ac2":"fig, axes = plt.subplots(nrows=10, ncols=20, figsize=(15, 14), gridspec_kw = {'wspace':0, 'hspace':0})\n\nfor i, row in enumerate(axes):\n    # Get random character\n    random.seed(i+1)\n    character_index = random.randint(0,len(character_folders))\n    \n    # Get alphabet name, character number, and images\n    alphabet_name = character_folders[character_index].split('\/')[-2]\n    character_number = character_folders[character_index].split('\/')[-1]\n    files = os.listdir(character_folders[character_index])\n    \n    # Plot all image instances\n    for j, col in enumerate(row):\n        img_path = os.path.join(character_folders[character_index], files[j])\n        img = read_and_propocess_image(img_path, (28, 28))\n        col.imshow(img.reshape([28, 28]), cmap='gray')\n        col.set_xticks([])\n        col.set_yticks([])\n        col.set_xticklabels([])\n        col.set_yticklabels([])\n        # Set title in the middle\n        if j == 10:\n            col.set_title(f\"{alphabet_name} {character_number}\", fontsize=14)","b979db2a":"BATCH_SIZE = 16\n\nclass DataLoader():\n    \"\"\"\n    Data Loader Few-Shot Learning \n    Forked from https:\/\/github.com\/cbfinn\/maml\n    \"\"\"\n    \n    def __init__(self, num_classes, num_samples_per_class):\n        \"\"\"\n        args:\n        * num_classes: N classes in support set \n        * num_samples_per_class: K samples per class in support set\n        \"\"\"\n        self.num_classes = num_classes\n        self.num_samples_per_class = num_samples_per_class\n        print(f\"Data Loader for {num_classes}-way, {num_samples_per_class}-shot Few-Shot Learning.\")\n        \n        # Dataset specific\n        self.meta_train_folders = \"\/kaggle\/input\/omniglot\/omniglot\/images_background\"\n        self.meta_val_folders = \"\/kaggle\/input\/omniglot\/omniglot\/images_evaluation\"\n        self.meta_test_folders = \"\/kaggle\/input\/omniglot\/omniglot\/images_evaluation\"\n    \n    def sample_batch(self, batch_type, batch_size):\n        \"\"\"\n        returns:\n        * image_batch with shape [batch_size, num_classes, num_samples_per_class, (im_size * im_size)]\n        * label_batch with shape [batch_size, num_classes, num_samples_per_class, num_classes]\n        \"\"\"\n        all_image_batches, all_label_batches = [], []\n        \n        # Set the folder according to purpose\n        if batch_type == 'train':\n            base_path = self.meta_train_folders\n        elif batch_type == 'val':\n            base_path = self.meta_val_folders\n        elif batch_type == 'test':\n            base_path = self.meta_test_folders\n        else: \n            print(f\"Error: '{batch_type}' is not a valid value for batch_type. batch_type must be either one of 'train', 'val', 'test'.\")\n        \n        folders = [os.path.join(base_path, folder, character)\n                      for folder in os.listdir(base_path)\n                      for character in os.listdir(os.path.join(base_path, folder))]\n        \n        for i in range(batch_size):\n            # Sample N different classes from the folders\n            sampled_character_folders = random.sample(folders, self.num_classes)\n\n            # Sample K images per class and associate labels\n            sampler = lambda x: random.sample(x, self.num_samples_per_class)\n            labels_and_images = [(i, os.path.join(path, image)) \\\n                for i, path in zip(range(self.num_classes), sampled_character_folders) \\\n                for image in sampler(os.listdir(path))]\n\n            labels = [li[0] for li in labels_and_images]\n            images = [read_and_propocess_image(li[1], (28, 28)) for li in labels_and_images]\n\n            # Format images to fit [num_classes, num_samples_per_class, (im_size * im_size)]\n            images = np.stack(images)\n            images = np.reshape(images, (self.num_classes, self.num_samples_per_class, -1))\n\n            # Format labels one-hot encoded to fit [ num_classes, num_samples_per_class, num_classes]\n            labels = np.array(labels)\n            labels = np.reshape(labels, (self.num_classes, self.num_samples_per_class))\n            labels = np.eye(self.num_classes)[labels]\n\n            batch = np.concatenate([labels, images], 2)\n\n            # Shuffle classes such that classes are not associated with the order\n            for p in range(self.num_samples_per_class):\n                np.random.shuffle(batch[:, p])\n                \n            labels = batch[:, :, :self.num_classes]\n            images = batch[:, :, self.num_classes:]\n\n            all_image_batches.append(images)\n            all_label_batches.append(labels)\n            \n        all_image_batches = np.stack(all_image_batches)\n        all_label_batches = np.stack(all_label_batches)\n\n        return all_image_batches, all_label_batches","b39534ee":"data_loader = DataLoader(NUM_CLASSES, 2)   \n\nim_batch, l_batch = data_loader.sample_batch(\"train\", BATCH_SIZE)\n\nprint(f\"Image batch shape: {im_batch.shape}\")\nprint(f\"Label batch shape: {l_batch.shape}\")\n\nfig, axes = plt.subplots(nrows=2, ncols=NUM_CLASSES, figsize=(8, 4))\nbatch_idx = 0\n\nfor i, row in enumerate(axes): # NUM_SAMPLES_PER_CLASS\n    for j, col in enumerate(row): # NUM_CLASSES\n        col.imshow(im_batch[batch_idx, j, i].reshape([28, 28]), cmap='gray')\n        col.set_title(f\"{np.argmax(l_batch[batch_idx, j, i])}\", fontsize=14)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.set_xticklabels([])\n        col.set_yticklabels([])","f60aa2e0":"data_loader = DataLoader(NUM_CLASSES, NUM_SAMPLES_PER_CLASS)   \n\nim_batch, l_batch = data_loader.sample_batch(\"train\", BATCH_SIZE)\n\nprint(f\"Image batch shape: {im_batch.shape}\")\nprint(f\"Label batch shape: {l_batch.shape}\")\n\nfig, axes = plt.subplots(nrows=BATCH_SIZE, ncols=NUM_CLASSES, figsize=(6, 22))\n\nfor i, row in enumerate(axes): # BATCH_SIZE\n    for j, col in enumerate(row): # NUM_CLASSES\n        col.imshow(im_batch[i, j, 0].reshape([28, 28]), cmap='gray')\n        col.set_title(f\"{np.argmax(l_batch[i, j, 0])}\", fontsize=14)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.set_xticklabels([])\n        col.set_yticklabels([])","5718d07b":"# Credits\nhttps:\/\/github.com\/cbfinn\/maml\n\nhttp:\/\/cs330.stanford.edu\/","7f5d3765":"Let's have a look at what a **5-way, 2-shot support set** looks like","8517d4bd":"# Data Loader\nNow, we will create a `DataLoader` that samples batches of size `BATCH_SIZE` with \n\nThe following code is based on http:\/\/cs330.stanford.edu\/ and https:\/\/github.com\/cbfinn\/maml and edited for learning purposes.","bdb87b3c":"# Few-Shot Learning Tutorial Series\nThis notebook is part of a mini tutorial series for few-shot learning (FSL).","50cc5909":"And finally, let's have a look at what a **5-way, 1-shot batch** looks like","aad4142d":"# N-Way, K-Shot\n\nBefore we get into any algorithms for FSL, we need to understand that the training for FSL is different to Supervised Learning. In Supervised Learning, the dataset is split into training, validation, and test sets. In FSL the dataset is split into training sets and test sets, whereas the  sets consist of a so-called **support set** and a **query set**.\n\nThe support set contains\n* N classes (`NUM_CLASSES`)\n* K samples per class (`NUM_SAMPLES_PER_CLASS`)\n\nFor example, in the **common 5-way, 1-shot** image classification scenario, one support set contains 1 example for each of the 5 classes.\n\nIn the following notebook, we will learn how to sample batches for training a Few-Shot Classification model by creating a `DataLoader` with the aid of the Omniglot dataset.","f072f455":"# Omniglot Dataset\n\nThe Omniglot data set was proposed by Lake et al. and consists of:\n* 1623 characters \n* from 50 different alphabets\n* each character has 20 instances\n* each image is a grayscale image\n* each image is 105 x 105 pixels\n\n**Note:** Recent advances in FSL have achieved high accuracies for the Omniglot dataset (e.g. MAML XX %). Therefore, new datasets, such as the meta-dataset have been introduced. However, the Omniglot dataset is sufficient for the purpose of this tutorial.\n\n**In contrast to the MNIST dataset**, which is commonly used for image classification in the traditional Supervised Learning setting, the Omniglot dataset has many different classes (MNIST only has 10 classes) but only 20 instances of each character (MNIST contains many instances for each character)."}}