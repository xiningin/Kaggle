{"cell_type":{"b5ea0221":"code","b091bf5b":"code","8ba097b1":"code","99a160c9":"code","88b2efa4":"code","cd00bc86":"code","0b875220":"code","85d7832a":"code","ab7bfaa1":"code","4d020c09":"code","df7295c7":"code","e9a9670a":"code","03c8cbd8":"markdown","55541621":"markdown","e6fb50e7":"markdown","483c218c":"markdown"},"source":{"b5ea0221":"# import packages\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","b091bf5b":"### Function to \"Check how many NaN values in Dataset by row,column\ndef check_null_values(df):\n    # check null values by col\n    A = df.isnull().any(axis=0)\n    A = pd.DataFrame(A,columns=['exist_null'])\n    # check number of null values by col\n    B = df.isnull().sum(axis=0)\n    B = pd.DataFrame(B,columns=['num_of_null'])\n    # merge data\n    merge = pd.concat([A,B],axis=1)\n    print(merge)\n    return\n\n### Function for \"Pre-processing on each of Columns\"\n\ndef data_preprocess(df):\n    # 1. delete too many null value column : 'Cabin'\n    df = df.dropna(thresh=300,axis=1)\n\n    # 2. 'Age', 'Fare' : replace values of NaN -> mean value\n    mean_age = np.mean(df['Age'])\n    df = df.fillna({'Age':mean_age})\n    df['Age'] = df['Age'].astype(int)\n    \n    mean_fare = np.mean(df['Fare'])\n    df = df.fillna({'Fare':mean_fare})\n        \n    # 3. 'Embarked' : drop rows of NaN\n    if 'Embarked' in df.keys():\n        df = df.dropna(subset=['Embarked'])\n\n\n    # one-hot encoding\n    df_sex = pd.get_dummies(df['Sex'])\n    df_embarked = pd.get_dummies(df['Embarked'])\n    df_pclass = pd.get_dummies(df['Pclass'])\n    \n    ## create new dataset\n    if 'Survived' in df.keys():\n        tmp1 = df[['Age','SibSp','Parch','Survived']]\n        tmp2 = pd.concat([tmp1,df_sex],axis=1)\n        tmp3 = pd.concat([tmp2,df_embarked],axis=1)\n        df = pd.concat([tmp3,df_pclass],axis=1)\n    else:\n        tmp1 = df[['PassengerId','Age','SibSp','Parch']]\n        tmp2 = pd.concat([tmp1,df_sex],axis=1)\n        tmp3 = pd.concat([tmp2,df_embarked],axis=1)\n        df = pd.concat([tmp3,df_pclass],axis=1)\n        \n    return df","8ba097b1":"# load data\ntrain_set = '..\/input\/titanic\/train.csv'\ntest_set = '..\/input\/titanic\/test.csv'\n\ndf_train = pd.read_csv(train_set,sep=',')\ndf_test = pd.read_csv(test_set,sep=',')\ndf_test_origin = pd.read_csv(test_set,sep=',')\n\n# check index & data types\nprint('[ data shape ]\\n train : {}\\n test  : {}'.format(df_train.shape,df_test.shape))\n# print('[ data type ]\\n%s' % df_train.dtypes)\n# print(df_train.head())\n# print(df_test.head())","99a160c9":"### Before data pre-process\nprint(check_null_values(df_train))\nprint(check_null_values(df_test))","88b2efa4":"### Pre-Processing Dataset\ndf_train = data_preprocess(df_train)\ndf_test = data_preprocess(df_test)","cd00bc86":"### After data pre-process\nprint(check_null_values(df_train))\nprint(check_null_values(df_test))","0b875220":"print('[ Train data samples ]\\n',df_train[:3],'\\n')\nprint('[ Test data samples ]\\n',df_test[:3])","85d7832a":"### Seperate X, Y parameters\ndf_train_x = df_train.drop(columns=['Survived'])\ndf_train_y = df_train[['Survived',]]\n\nX = np.array(df_train_x)\nY = np.array(df_train_y)","ab7bfaa1":"### Decision Tree \n\nfrom sklearn.model_selection import KFold\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score, precision_score\n\nscores =[]\n\nkf = KFold(n_splits=10,shuffle=True)\n\nfor train_id,test_id in kf.split(X):\n    x = X[train_id]\n    y = Y[train_id]\n    clf = tree.DecisionTreeClassifier()\n    clf.fit(x,y)\n    print(clf.get_params)\n    pred_y = clf.predict(X[test_id])\n    score = accuracy_score(Y[test_id],pred_y)\n    scores.append(score)\nscores = np.array(scores)\nprint(scores)\nprint(scores.mean(),scores.std())\n\n\nprint('Recall : ',recall_score(Y[test_id],pred_y))\nprint('Precision : ',precision_score(Y[test_id],pred_y))\n\n\n","4d020c09":"### Grid Search to find best params\n\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {\n    'criterion':['entropy'],\n    'max_depth':[2,4,6,8,10],\n    'min_samples_leaf':[10,20,30,40,50],\n}\n\nclf_gs = GridSearchCV(tree.DecisionTreeClassifier(),params,\n                     cv=KFold(n_splits=10,shuffle=True),scoring='accuracy')\n\nclf_gs.fit(X,Y)\n\nprint('Best Score : ',clf_gs.best_score_)\nprint('Best Params : ',clf_gs.best_params_)\n\nclf_best = tree.DecisionTreeClassifier(\n                    criterion = 'entropy',max_depth=4,min_samples_leaf=10)\nclf_best.fit(X,Y)\nfi = clf_best.feature_importances_\n\nfeatures = df_train_x.keys() \nimportances = clf_best.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","df7295c7":"### Save submission csv file\nsub_n=df_test[['PassengerId',]]\nsub_gs=df_test[['PassengerId',]]\n\npred_n = clf_best.predict(df_test.drop(columns=['PassengerId']))\nsub_n['Survived']=pred_n\n\npred_gs = clf_best.predict(df_test.drop(columns=['PassengerId']))\nsub_gs['Survived']=pred_gs\n\n# save submission data\nsub_n.to_csv('submission_n.csv',index=False)\nsub_gs.to_csv('submission_gs.csv',index=False)","e9a9670a":"### RandomForest \nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score, precision_score\n\n# y = train_data[\"Survived\"]\n\n# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n# X = pd.get_dummies(train_data[features])\n# X_test = pd.get_dummies(test_data[features])\n\n\n# model = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=2)\nmodel = RandomForestClassifier()\nmodel.fit(X, Y)\n\npred_y = model.predict(X)\nscore = accuracy_score(Y,pred_y)\nprint('Mean Score :',score)\nprint('Recall : ',recall_score(Y,pred_y))\nprint('Precision : ',precision_score(Y,pred_y))\n\npred_rf = model.predict(df_test.drop(columns=['PassengerId']))\n\nsub_rf=df_test[['PassengerId',]]\nsub_rf['Survived']=pred_rf\nsub_rf.to_csv('submission_rf.csv',index=False)","03c8cbd8":"# About data\n\n- survived : survive or not [ survived=1, dead=0 ]\n- pclass   : passenger class [ 1st class=1, 2nd class=2, 3rd class=3 ]\n- sibsp    : Number of siblings or spouses on board together\n- parch    : Number of parents or children on board together\n- ticket   : Ticket Number\n- cabin    : Cabin Number\n- embarked : Boarding place [ S=Southhampton, C=Cherbourg, Q=Queenstown ]","55541621":"# Decision Tree Model","e6fb50e7":"# RandomForest Classifier","483c218c":"# Summary\n    1. Data pre-process\n    \n        1-1. NaN values\n          - drop too many NaN value column : 'Cabin'\n          - drop a few NaN value row : 'Embarked', 'Fare'\n          - replace NaN with mean value : 'Age'\n      \n        1-2. One-Hot encoding\n          - 'Sex', 'Embarked', 'Pclass'\n      \n        1-3. Do Not use specifical column : 'PassengerId', 'Name', 'Ticket' also 'Cabin'\n\n    2. Train info\n    \n        2-1. Decision Tree Model\n          - normal fitting -> submission_n.csv \n          - GridSearch fitting -> submission_gs.csv\n      \n        2-2. RandomForest Model"}}