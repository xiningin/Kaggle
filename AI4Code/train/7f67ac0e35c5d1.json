{"cell_type":{"f61f47c1":"code","d35d44e0":"code","fffbb952":"code","460f3521":"code","ee6a53d0":"code","4324d3a8":"code","bdb5e59a":"code","4fa9c685":"code","e2f0b210":"code","eb7df3d5":"code","8a0de1ff":"code","78b26183":"code","ab5d425c":"code","2e3eff6f":"code","30fecbc2":"code","ac41a5dc":"code","9f7da35c":"code","b7536273":"code","1bc1c1ae":"markdown","8a1a9eff":"markdown","471dc35b":"markdown","ed87e81b":"markdown","4edd8e53":"markdown","805b1018":"markdown","5180281a":"markdown","1184d7ea":"markdown","80967430":"markdown","cf37d206":"markdown","d084bc04":"markdown","b20563e2":"markdown"},"source":{"f61f47c1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d35d44e0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\nfrom keras.models import Model\nfrom keras import models, layers\nfrom keras.optimizers import Adam \nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n#from keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt","fffbb952":"general_path = '..\/input\/cassava-leaf-disease-classification\/'\n\ntrain = pd.read_csv(general_path + 'train.csv')\ntrain['label'] = train['label'].astype('string')\ntrain.sample(5)\n","460f3521":"names_of_disease = pd.read_json(general_path + 'label_num_to_disease_map.json', typ='series')\nnames_of_disease","ee6a53d0":"plt.figure(figsize=(16, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    image = Image.open(general_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    plt.imshow(array)\n    label=train.iloc[i]['label']\n    plt.title(f'{names_of_disease[int(label)]}')\nplt.show()","4324d3a8":"sizes = []\nfor i in range(1, len(train), 250):\n    image = Image.open(general_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    sizes.append(array.shape)\nprint('Picture size', set(sizes))","bdb5e59a":"img_width, img_height = 380, 380","4fa9c685":"datagen = ImageDataGenerator(validation_split=0.2,\n                             rotation_range = 40,\n                             width_shift_range = 0.2,\n                             height_shift_range = 0.2,\n                             shear_range = 0.2,\n                             zoom_range = 0.2,\n                             vertical_flip=True,\n                             horizontal_flip=True)\n\ntrain_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=64,\n    subset='training',\n    seed=12345)\n\n\nvalid_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=64,\n    class_mode = 'categorical',\n    subset='validation',\n    seed=12345)","e2f0b210":"current_balance = train['label'].value_counts(normalize=True)\ncurrent_balance","eb7df3d5":"class_weight = {0: (1 - current_balance[0]) \/ (1 - current_balance.min()),\n                1: (1 - current_balance[1]) \/ (1 - current_balance.min()),\n                2: (1 - current_balance[2]) \/ (1 - current_balance.min()),\n                3: (1 - current_balance[3]) \/ (1 - current_balance.min()),\n                4: (1 - current_balance[4]) \/ (1 - current_balance.min())}\n\nclass_weight","8a0de1ff":"model =EfficientNetB4(include_top=False, input_shape=(128,128,3), weights=None, pooling='avg')\nEfficientNet = \"..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb4_notop.h5\"\nmodel.load_weights(EfficientNet)\n\nmodel = models.Sequential()\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\nmodel.add(Dropout(0.5))\nmodel.add(layers.Dense(5, activation = \"softmax\"))\n","78b26183":"early_stop = EarlyStopping(monitor = \"val_loss\",\n                                min_delta=0.001,\n                                patience=3,\n                                verbose=1,\n                                mode=\"min\",\n                                #baseline=None,\n                                restore_best_weights=False)\n\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\",\n                                factor=0.1,\n                                patience=3,\n                                verbose=1,\n                                mode=\"min\",\n                                min_delta=0.0001)\n\noptimizer = Adam(lr=0.001)\n\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizer, \n              metrics=[\"accuracy\"])","ab5d425c":"history = model.fit_generator(train_datagen_flow,\n                    validation_data=valid_datagen_flow, \n                    epochs=50,\n                    callbacks=[early_stop, reduce_lr], \n                    use_multiprocessing=True,\n                    shuffle=True,\n                    verbose=2)","2e3eff6f":"model.save('Cassava_model'+'.h5') ","30fecbc2":"def visualize_training(history, lw = 2):\n    plt.figure(figsize=(10,10))\n    plt.subplot(2,1,1)\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw, color='red')\n    plt.title('Accuracy Comparison')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.grid(True)\n    plt.legend(fontsize = 'x-large')\n    \n\n    plt.subplot(2,1,2)\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw, color='red')\n    plt.title('Loss Comparison')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.grid(True)\n    plt.show()\n\nvisualize_training(history)","ac41a5dc":"# Prediction accuracy on train data\nscore_tr = model.evaluate_generator(train_datagen_flow, verbose=1)\nprint(\"Prediction accuracy on train data =\", score_tr[1])\n\n# Prediction accuracy on test data\nscore_ts = model.evaluate_generator(valid_datagen_flow, verbose=1)\nprint(\"Prediction accuracy on test data =\", score_ts[1])","9f7da35c":"submission = pd.DataFrame(columns=['image_id','label'])\nfor image_name in os.listdir(general_path + 'test_images'):\n    image_path = os.path.join(general_path + 'test_images', image_name)\n    image = keras.preprocessing.image.load_img(image_path)\n    resized_image = image.resize((img_width, img_height))\n    numpied_image = np.expand_dims(resized_image, 0)\n    tensored_image = tf.cast(numpied_image, tf.float32)\n    submission = submission.append(pd.DataFrame({'image_id': image_name,\n                                                 'label': model.predict_classes(tensored_image)}))\n\nsubmission","b7536273":"submission.to_csv('\/kaggle\/working\/submission.csv', index=False)","1bc1c1ae":"### Resize the images","8a1a9eff":"### Visualize loss and accuracy on training and test dataset","471dc35b":"### Data Augmentation","ed87e81b":"### Prediction on test data","4edd8e53":"### Display random images","805b1018":"### Submission","5180281a":"### Load the leaf dataset","1184d7ea":"### Load all the required libraries","80967430":"![23196877-cassava-leaves.jpg](attachment:23196877-cassava-leaves.jpg)","cf37d206":"### Using EfficientNetB0 transfer learning to build a CNN model","d084bc04":"### Train the model","b20563e2":"# Cassava Leaf Disease Classification"}}