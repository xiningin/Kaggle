{"cell_type":{"ef481d15":"code","70cbc44b":"code","2af4b023":"code","2f070375":"code","e3f5d2be":"code","fb541866":"code","fefb8457":"code","0c8f2d32":"code","b99384cc":"code","c1a2b70e":"code","6fa6fed0":"code","c1c6053b":"code","eb91b634":"code","cbe7364f":"code","f5c20c15":"code","8671b143":"code","522398eb":"code","af95e91b":"code","aab1ef0a":"code","44ebffda":"code","0370ac1b":"code","deda33ac":"code","444eec8a":"code","08a3dac0":"code","1ce81a50":"code","bae51153":"code","265eade5":"code","77088c5f":"code","ffa84145":"code","7ea7ae15":"code","e61d58ce":"code","5c8713ef":"code","4d063a08":"code","2b8346b0":"code","1ec9d386":"code","0497b498":"code","e5103f9f":"code","6f0e8d0f":"markdown","c3a86c87":"markdown","a4505dcf":"markdown","79075ee2":"markdown","6ea8d8fc":"markdown","df27d1bf":"markdown","a6319ada":"markdown","3128093f":"markdown","a1839d0f":"markdown","ea5c1f73":"markdown","8ec6cf9f":"markdown","fa778c7e":"markdown","787b664f":"markdown","5c8deef5":"markdown","bc4dc971":"markdown","a3456a00":"markdown","b384076c":"markdown"},"source":{"ef481d15":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense,Activation,Dropout\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom keras.callbacks import EarlyStopping\nimport math\nimport os\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n","70cbc44b":"hotel_details=pd.read_csv('..\/input\/hotel-recommendation\/Hotel_details.csv',delimiter=',')\nhotel_rooms=pd.read_csv('..\/input\/hotel-recommendation\/Hotel_Room_attributes.csv',delimiter=',')\nhotel_cost=pd.read_csv('..\/input\/hotel-recommendation\/hotels_RoomPrice.csv',delimiter=',')","2af4b023":"hotel_details.head()","2f070375":"hotel_rooms.head()","e3f5d2be":"del hotel_details['id']\ndel hotel_rooms['id']\ndel hotel_details['zipcode']","fb541866":"hotel_details=hotel_details.dropna()\nhotel_rooms=hotel_rooms.dropna()","fefb8457":"hotel_details.drop_duplicates(subset='hotelid',keep=False,inplace=True)","0c8f2d32":"hotel=pd.merge(hotel_rooms,hotel_details,left_on='hotelcode',right_on='hotelid',how='inner')","b99384cc":"hotel.columns","c1a2b70e":"del hotel['hotelid']\ndel hotel['url']\ndel hotel['curr']\ndel hotel['Source']","6fa6fed0":"hotel.columns","c1c6053b":"def citybased(city):\n    hotel['city']=hotel['city'].str.lower()\n    citybase=hotel[hotel['city']==city.lower()]\n    citybase=citybase.sort_values(by='starrating',ascending=False)\n    citybase.drop_duplicates(subset='hotelcode',keep='first',inplace=True)\n    if(citybase.empty==0):\n        hname=citybase[['hotelname','starrating','address','roomamenities','ratedescription']]\n        return hname.head()\n    else:\n        print('No Hotels Available')","eb91b634":"print('Top 5 hotels')\ncitybased('London')","cbe7364f":"room_no=[\n     ('king',2),\n   ('queen',2), \n    ('triple',3),\n    ('master',3),\n   ('family',4),\n   ('murphy',2),\n   ('quad',4),\n   ('double-double',4),\n   ('mini',2),\n   ('studio',1),\n    ('junior',2),\n   ('apartment',4),\n    ('double',2),\n   ('twin',2),\n   ('double-twin',4),\n   ('single',1),\n     ('diabled',1),\n   ('accessible',1),\n    ('suite',2),\n    ('one',2)\n   ]","f5c20c15":"def calc():\n    guests_no=[]\n    for i in range(hotel.shape[0]):\n        temp=hotel['roomtype'][i].lower().split()\n        flag=0\n        for j in range(len(temp)):\n            for k in range(len(room_no)):\n                if temp[j]==room_no[k][0]:\n                    guests_no.append(room_no[k][1])\n                    flag=1\n                    break\n            if flag==1:\n                break\n        if flag==0:\n            guests_no.append(2)\n    hotel['guests_no']=guests_no\n\ncalc()","8671b143":"def pop_citybased(city,number):\n    hotel['city']=hotel['city'].str.lower()\n    popbased=hotel[hotel['city']==city.lower()]\n    popbased=popbased[popbased['guests_no']==number].sort_values(by='starrating',ascending=False)\n    popbased.drop_duplicates(subset='hotelcode',keep='first',inplace=True)\n    if popbased.empty==True:\n        print('Sorry No Hotels Available\\n tune your constraints')\n    else:\n        return popbased[['hotelname','roomtype','guests_no','starrating','address','roomamenities','ratedescription']].head(10)\n    \n    ","522398eb":"pop_citybased('London',4)","af95e91b":"hotel['roomamenities']=hotel['roomamenities'].str.replace(': ;',',')","aab1ef0a":"def requirementbased(city,number,features):\n    hotel['city']=hotel['city'].str.lower()\n    hotel['roomamenities']=hotel['roomamenities'].str.lower()\n    features=features.lower()\n    features_tokens=word_tokenize(features)  \n    sw = stopwords.words('english')\n    lemm = WordNetLemmatizer()\n    f1_set = {w for w in features_tokens if not w in sw}\n    f_set=set()\n    for se in f1_set:\n        f_set.add(lemm.lemmatize(se))\n    reqbased=hotel[hotel['city']==city.lower()]\n    reqbased=reqbased[reqbased['guests_no']==number]\n    reqbased=reqbased.set_index(np.arange(reqbased.shape[0]))\n    l1 =[];l2 =[];cos=[];\n    #print(reqbased['roomamenities'])\n    for i in range(reqbased.shape[0]):\n        temp_tokens=word_tokenize(reqbased['roomamenities'][i])\n        temp1_set={w for w in temp_tokens if not w in sw}\n        temp_set=set()\n        for se in temp1_set:\n            temp_set.add(lemm.lemmatize(se))\n        rvector = temp_set.intersection(f_set)\n        #print(rvector)\n        cos.append(len(rvector))\n    reqbased['similarity']=cos\n    reqbased=reqbased.sort_values(by='similarity',ascending=False)\n    reqbased.drop_duplicates(subset='hotelcode',keep='first',inplace=True)\n    return reqbased[['hotelname','roomtype','guests_no','starrating','address','roomamenities','ratedescription','similarity']].head(10)","44ebffda":"requirementbased('London',1,'I need a extra toilet and room should be completely air conditioned.I should have a bathrobe.')","0370ac1b":"from math import sin, cos, sqrt, atan2, radians\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = '4519d076b432f5'\nimport requests\nR=6373.0#Earth's Radius\nsw = stopwords.words('english')\nlemm = WordNetLemmatizer()\ndef hybrid(address,city,number,features):\n    features=features.lower()\n    features_tokens=word_tokenize(features)\n    f1_set = {w for w in features_tokens if not w in sw}\n    f_set=set()\n    for se in f1_set:\n        f_set.add(lemm.lemmatize(se))\n    data = {\n    'key': secret_value_0,\n    'q': address,\n    'format': 'json'}\n    response = requests.get(url, params=data)\n    dist=[]\n    lat1,long1=response.json()[0]['lat'],response.json()[0]['lon']\n    lat1=radians(float(lat1))\n    long1=radians(float(long1))\n    hybridbase=hotel[hotel['guests_no']==number]\n    hybridbase['city']=hybridbase['city'].str.lower()\n    hybridbase=hybridbase[hybridbase['city']==city.lower()]\n    hybridbase.drop_duplicates(subset='hotelcode',inplace=True,keep='first')\n    hybridbase=hybridbase.set_index(np.arange(hybridbase.shape[0]))\n    for i in range(hybridbase.shape[0]):\n        lat2=radians(hybridbase['latitude'][i])\n        long2=radians(hybridbase['longitude'][i])\n        dlon = long2 - long1\n        dlat = lat2 - lat1\n        a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n        distance = R * c\n        dist.append(distance)\n    hybridbase['distance']=dist\n    hybridbase=hybridbase.sort_values(by='distance',ascending=True)\n    hybridbase=hybridbase.head(15)\n    hybridbase=hybridbase.set_index(np.arange(hybridbase.shape[0]))\n    coss=[]\n    for i in range(hybridbase.shape[0]):\n        temp_tokens=word_tokenize(hybridbase['roomamenities'][i])\n        temp1_set={w for w in temp_tokens if not w in sw}\n        temp_set=set()\n        for se in temp1_set:\n            temp_set.add(lemm.lemmatize(se))\n        rvector = temp_set.intersection(f_set)\n        coss.append(len(rvector))\n    hybridbase['similarity']=coss\n    return hybridbase.sort_values(by='similarity',ascending=False).head(10)\n    \n    \n        ","deda33ac":"url = \"https:\/\/us1.locationiq.com\/v1\/search.php\"\nhybrid(\"Big Ben,London\",'London',4,'I need a extra toilet and room should be completely air conditioned.I should have a bathrobe.')","444eec8a":"hotel_cost.head()\n#onsite rate is one important feature which could be useful to recommend\n#we will drop the rest since it is present in other table and we are going to merge the \nhotel_cost=hotel_cost.drop(['id','refid','websitecode','dtcollected','ratedate','los','guests','roomtype','netrate','ratedescription','ratetype','sourceurl','roomamenities'\n,'ispromo','closed','discount','promoname','status_code','taxstatus','taxtype','taxamount','proxyused','israteperstay','hotelblock','input_dtcollected'],axis=1)","08a3dac0":"hotel_cost.columns","1ce81a50":"#To reccomend we are gonna check how much does the price vary from room to room if \n#the varience is small enough then it is better for them to recommend the hotel\nhot=hotel_cost.groupby(['hotelcode','maxoccupancy'])","bae51153":"hotel_cost.sort_values(by=['onsiterate'],ascending=False)\nhotel_cost=hotel_cost.drop_duplicates(subset=['hotelcode','maxoccupancy'],keep='first')","265eade5":"var=hot['onsiterate'].var().to_frame('varience')\nl=[]\nfor i in range(hotel_cost.shape[0]):\n    var1=var[var.index.get_level_values(0)==hotel_cost.iloc[i][0]]\n    l.append(var1[var1.index.get_level_values(1)==hotel_cost.iloc[i][3]]['varience'][0])","77088c5f":"hotel_cost['var']=l\nhotel_cost=hotel_cost.fillna(0)\nhotel_cost['mealinclusiontype']=hotel_cost['mealinclusiontype'].replace(0,'No Complimentary')","ffa84145":"hotel1=pd.merge(hotel,hotel_cost,left_on=['hotelcode','guests_no'],right_on=['hotelcode','maxoccupancy'],how='inner')","7ea7ae15":"hotel1=hotel1.drop_duplicates(subset=['hotelcode','maxoccupancy'],keep='first')","e61d58ce":"hotel1.columns","5c8713ef":"def pricing(address,city,number,features):\n    h=hybrid(address,city,number,features)\n    price_based=pd.merge(h,hotel_cost,left_on=['hotelcode','guests_no'],right_on=['hotelcode','maxoccupancy'],how='inner')\n    del price_based['maxoccupancy']\n    h=price_based.sort_values(by='var')\n    return h.head()","4d063a08":"pricing(\"Tower of London\",'London',4,'I need an alarm clock and a kettle flask.')\n#the description is just only for example.It portrays you can keep any specific request","2b8346b0":"optimum_band=pd.read_csv('..\/input\/hotel-recommendation\/hotel_price_min_max - Formula.csv')","1ec9d386":"from math import sin, cos, sqrt, atan2, radians\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = '4519d076b432f5'\nimport requests\nR=6373.0#Earth's Radius\nsw = stopwords.words('english')\nlemm = WordNetLemmatizer()\ndef hybrid(address,city,number,features):\n    features=features.lower()\n    features_tokens=word_tokenize(features)\n    f1_set = {w for w in features_tokens if not w in sw}\n    f_set=set()\n    for se in f1_set:\n        f_set.add(lemm.lemmatize(se))\n    data = {\n    'key': secret_value_0,\n    'q': address,\n    'format': 'json'}\n    response = requests.get(url, params=data)\n    dist=[]\n    lat1,long1=response.json()[0]['lat'],response.json()[0]['lon']\n    lat1=radians(float(lat1))\n    long1=radians(float(long1))\n    hybridbase=hotel\n    #hybridbase=hotel[hotel['guests_no']==number]\n    hybridbase['city']=hybridbase['city'].str.lower()\n    hybridbase=hybridbase[hybridbase['city']==city.lower()]\n    hybridbase.drop_duplicates(subset='hotelcode',inplace=True,keep='first')\n    hybridbase=hybridbase.set_index(np.arange(hybridbase.shape[0]))\n    for i in range(hybridbase.shape[0]):\n        lat2=radians(hybridbase['latitude'][i])\n        long2=radians(hybridbase['longitude'][i])\n        dlon = long2 - long1\n        dlat = lat2 - lat1\n        a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n        distance = R * c\n        dist.append(distance)\n    hybridbase['distance']=dist\n    hybridbase=hybridbase[hybridbase['distance']<=5]\n    hybridbase=hybridbase.set_index(np.arange(hybridbase.shape[0]))\n    coss=[]\n    for i in range(hybridbase.shape[0]):\n        temp_tokens=word_tokenize(hybridbase['roomamenities'][i])\n        temp1_set={w for w in temp_tokens if not w in sw}\n        temp_set=set()\n        for se in temp1_set:\n            temp_set.add(lemm.lemmatize(se))\n        rvector = temp_set.intersection(f_set)\n        coss.append(len(rvector))\n    hybridbase['similarity']=coss\n    return hybridbase.sort_values(by='similarity',ascending=False)\n\ndef price_band_based(address,city,number,features):\n    h=hybrid(address,city,number,features)\n    price_band=pd.merge(h,optimum_band,left_on=['hotelcode'],right_on=['hotelcode'],how='inner')\n    price_band=pd.merge(price_band,hotel_cost,left_on=['hotelcode'],right_on=['hotelcode'],how='inner')\n    del price_band['min']\n    del price_band['max']\n    del price_band['Diff_Min']\n    del price_band['Diff_Max']\n    del price_band['currency']\n    del price_band['country']\n    del price_band['propertytype']\n    del price_band['starrating']\n    del price_band['latitude']\n    del price_band['longitude']\n    del price_band['guests_no']\n    del price_band['var']\n    price_band=price_band[price_band['Score']<=0.5]\n    price_band=price_band[price_band['maxoccupancy']>=number]\n    return price_band","0497b498":"price_band_based(\"Tower of London\",'London',4,'I need an alarm clock and a kettle flask.').head(5)","e5103f9f":"\nimport pickle\nPkl_Filename = \"Pickle_RL_Model.pkl\"  \nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(price_band_based, file)","6f0e8d0f":"# Disadvantages of CBR\n\n<P>\nCritics of CBR argue that it is an approach that accepts anecdotal evidence as its main operating principle. Without statistically relevant data for backing and implicit generalization, there is no guarantee that the generalization is correct. However, all inductive reasoning where data is too scarce for statistical relevance is inherently based on anecdotal evidence. There is recent work that develops CBR within a statistical framework and formalizes case-based inference as a specific type of probabilistic inference; thus, it becomes possible to produce case-based predictions equipped with a certain level of confidence. One description of the difference between CBR and induction from instances is that statistical inference aims to find what tends to make cases similar while CBR aims to encode what suffices to claim similarly.   <\/P>","c3a86c87":"# Conclusion\n\nAfter all these a reccommender system from scratch is made which considers the following features while recommending<br>\n1. Closness to location\n2. Number of guests\n3. Onsite Rate\n4. Credibility of the hotel\n5. Room Ammenities\n6. Complimentary gifts(Like Free Meals,Take aways)\n7. Optimum price band\n8. Any special requests the customer needs(Using NLTK search engines)","a4505dcf":"# Recommender system based only on City and ratings about the hotel","79075ee2":"# Description of Complete Problem\n\n<html>\n    <body>\n        <br>\n        Our aim is to help managers from hotels to find how their hotels are ranked.<br>\n        In the middle eastern countries there is a concept called dynamic pricing.<br>\n        The rate of pricing in hotels change from season to season and based on demand<br>\n        Our motive is to give them an estimate to help the officials fix the price based on<br> the rank and meta data we supply.\n    <\/body>\n <\/html>","6ea8d8fc":"# Data Description\n\n<br>\nThe data contains infomations like basic name,adress,location,ratings<br>\nIn another file we have collected the corresponding hotel details and<br>\ninformation from their url and stored it which contains room amenities,roomtypes<br>\nand features the hotel had.<br>\nThere is one seperate file which is collected from booking websites(trivago) <br>\nwhich holds it pricing information.<br>\n","df27d1bf":"# COD3","a6319ada":"# Motivation\n<html>\n    <body>\nThis is a part of my internship experience which I want to share <br>\nhow I started building a hotel recommender system for managers <br>\nwho needs an insight about how their hotel is ranked compared <br>\nwith other hotels from scratch.\n    <\/body>\n<\/html>","3128093f":"# Approach Taken(Algorithm)\n\n<br>\n<p>\nWe have gone with Case Based Reasoning (CBR) approach to analyse the data.\nCase-based reasoning (CBR), broadly construed, is the process of solving new problems based on the \nsolutions of similar past problems.An auto mechanic who fixes an engine by recalling another car that\nexhibited similar symptoms is using case-based reasoning. A lawyer who advocates a particular outcome\nin a trial based on legal precedents or a judge who creates case law is using case-based reasoning.\nSo, too, an engineer copying working elements of nature (practicing biomimicry),\nis treating nature as a database of solutions to problems.\nCase-based reasoning is a prominent type of analogy solution making.<\/p>\n<p>\nIt has been argued that case-based reasoning is not only a powerful method for computer reasoning, but also a pervasive behavior in everyday human problem solving; or, more radically, that all reasoning is based on past cases personally experienced. This view is related to prototype theory, which is most deeply explored in cognitive science.<\/p>\n\n\n**Process**\n<p>\n    Retrieve: Given a target problem, retrieve from memory cases relevant to solving it. A case consists of a problem, its solution, and, typically, annotations about how the solution was derived. For example, suppose Fred wants to prepare blueberry pancakes. Being a novice cook, the most relevant experience he can recall is one in which he successfully made plain pancakes. The procedure he followed for making the plain pancakes, together with justifications for decisions made along the way, constitutes Fred's retrieved case.<\/p>\n    <p>\nReuse: Map the solution from the previous case to the target problem. This may involve adapting the solution as needed to fit the new situation. In the pancake example, Fred must adapt his retrieved solution to include the addition of blueberries.\n    <\/p>\n    <p>\nRevise: Having mapped the previous solution to the target situation, test the new solution in the real world (or a simulation) and, if necessary, revise. Suppose Fred adapted his pancake solution by adding blueberries to the batter. After mixing, he discovers that the batter has turned blue \u2013 an undesired effect. This suggests the following revision: delay the addition of blueberries until after the batter has been ladled into the pan.<\/p>\n<p>\nRetain: After the solution has been successfully adapted to the target problem, store the resulting experience as a new case in memory. Fred, accordingly, records his new-found procedure for making blueberry pancakes, thereby enriching his set of stored experiences, and better preparing him for future pancake-making demands.\n<\/p>","a1839d0f":"# Fetching the data","ea5c1f73":"# After applying Optimum band formula and simmilarity index","8ec6cf9f":"# Data Retrieval\n\nThere are several packages in Python that allow us to scrape information from webpages.<br>\nOne of the most common ones is BeautifulSoup.<br>\nBeautifulSoup allows us to parse the HTML content of a given URL and<br> \naccess its elements by identifying them with their tags and attributes.<br> \nFor this reason, we will use it to extract certain pieces of text from the websites.<br>\nIt is an extremely easy-to-use yet powerful package. <br>\nWith almost 3\u20135 lines of code we will be able to extract any text we want from the internet.<br>\n<br>\nalternate tools like scrapy,diffbot,parseHub also are famous \n<br><br> \n**For our work we have used a combination of Requests and Beautiful Soup**<br>\nWe have scraped the data from 9 different websites\n","fa778c7e":"# Targeted Audience for the application\n\nThis is primarly intended for hotel managers and stake holders to have a stand among online room bookers.<br>\nHowever this application could also be extended to clients of an e-booking platform","787b664f":"# Requirement And special needs based Recommender","5c8deef5":"# Recommendder with pricing included","bc4dc971":"Later it was converted as a flask web app and delivered to the stakeholders.","a3456a00":"# Hotel Recommendation System(ML Assignment)\n","b384076c":"# Data Cleaning and transformations"}}