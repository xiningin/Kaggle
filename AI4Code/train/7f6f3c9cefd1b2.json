{"cell_type":{"f51b7c1b":"code","6a610556":"code","e38e6f91":"code","cbc66fc0":"code","b06939fd":"code","6324588c":"code","1d7ae8b7":"code","8a663b68":"code","6ff4e2cc":"code","161e7dff":"code","88267534":"code","81e7c88d":"code","eb3f5be1":"code","580fc520":"code","b2ec7b6d":"code","4cbd0e82":"code","439c8d57":"code","5ea1b184":"code","2697aa3f":"code","1d6cf4b9":"code","7fab9796":"code","48ee2ce4":"code","69993625":"code","7c6c4edf":"code","db8df146":"code","d2fdd6e3":"code","423cc487":"code","78fcfb89":"code","c5953e2b":"code","dda61788":"code","15a269af":"code","1b317ee3":"code","82188ffd":"code","e1136e12":"code","5fff4e63":"code","97079677":"code","8658088f":"code","18db5a32":"code","9424a24c":"code","226dd904":"code","38d4bd63":"code","44cff4af":"code","a8ab6806":"code","04d034f4":"code","22ff7a46":"code","b016bc95":"code","d67e781b":"code","6d4e46c8":"code","2bf9167e":"code","b4939475":"code","c3fcafdc":"code","b8b614a0":"code","d8c764f3":"code","2efb859f":"code","42db6f86":"code","2c7e69eb":"code","37c362d2":"code","06ce6b60":"markdown","9de81162":"markdown","6a5d3dac":"markdown","c8db6816":"markdown","d0ee7d10":"markdown","cf539efc":"markdown","031f53b5":"markdown","12747515":"markdown","7d7afbba":"markdown"},"source":{"f51b7c1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6a610556":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata=pd.read_csv('..\/input\/kaggle2020surveycolumnnamesedited\/data.csv',skiprows=1)","e38e6f91":"data.Gender.value_counts()","cbc66fc0":"print('Male % in world',round(100*(data['Gender']=='Man').sum()\/((data['Gender']=='Man').sum()+(data['Gender']=='Woman').sum()),1),'%')\nprint('Female % in world',round(100*(data['Gender']=='Woman').sum()\/((data['Gender']=='Man').sum()+(data['Gender']=='Woman').sum()),1),'%')","b06939fd":"data.Country.value_counts().head(12)","6324588c":"print('Total number of Countries is',data.Country.nunique())\nprint('Top 12 countries observations is',data.Country.value_counts().head(12).sum())\nprint('Top 12 countries Observations % is',round(100*data.Country.value_counts().head(12).sum()\/data.Country.value_counts().sum(),1),'%')","1d7ae8b7":"gen=['Man','Woman']\ncountries=['India','United States of America','Brazil','Japan','Russia','United Kingdom of Great Britain and Northern Ireland','Nigeria','China','Germany','Turkey','Spain','France','Canada']\nGend=data.loc[(data['Gender'].isin(gen)) & (data['Country'].isin(countries)),['Country','Gender']]\nGendTop10=Gend.groupby('Country').Gender.value_counts()\nGendTop10","8a663b68":"GendTop10.unstack().plot(kind='bar',figsize=(18,5))\nplt.ylabel('No. of People')","6ff4e2cc":"Ungend=data.loc[(data['Gender'].isin(gen))==False,['Country','Gender']]\nUngend.Country.value_counts().head(12)","161e7dff":"percent=pd.DataFrame(index=countries,columns=['Man','Woman'])\npercent.index.name='Country'\nfor col in countries:\n    percent.loc[col,'Man']=round(100*((data.loc[(data['Gender']=='Man') & (data['Country']==col),['Gender']].size)\/((data.loc[(data['Gender']=='Man') & (data['Country']==col),['Gender']].size)+(data.loc[(data['Gender']=='Woman') & (data['Country']==col),['Gender']].size))),1)\n    percent.loc[col,'Woman']=round(100*((data.loc[(data['Gender']=='Woman') & (data['Country']==col),['Gender']].size)\/((data.loc[(data['Gender']=='Man') & (data['Country']==col),['Gender']].size)+(data.loc[(data['Gender']=='Woman') & (data['Country']==col),['Gender']].size))),1)\npercent","88267534":"data.Education.unique()","81e7c88d":"data['Education']=data.Education.map({\"Doctoral degree\":\"Doctoral\",\"Master\u2019s degree\":\"Master\",\"Bachelor\u2019s degree\":\"Bachelor\",\"No formal education past high school\":\"Low\",\"Some college\/university study without earning a bachelor\u2019s degree\":\"Degree\",\"Professional degree\":\"Professional\",\"I prefer not to answer\":\"Secret\"})\ndata.Education.unique()","eb3f5be1":"data.Education.value_counts()","580fc520":"data.Education.isnull().sum()","b2ec7b6d":"Edu=data.loc[data['Country'].isin(countries),['Country','Education']]\nEduTop10=Edu.groupby('Country').Education.value_counts()\nEduTop10.unstack().plot(kind='bar',figsize=(18,5))\nplt.ylabel('No. of People')\n#plt.rcParams[\"figure.figsize\"]=(20,8)","4cbd0e82":"data.Age.value_counts()","439c8d57":"young=['18-21','22-24','25-29','30-34']\nprint('Young data science practitioner, age between 18-34, in world is',round(100*len(data.loc[data['Age'].isin(young)])\/data['Age'].notnull().sum(),1),'%')","5ea1b184":"teen=['18-21','22-24']\nprint(data.loc[(data['Age'].isin(teen)),['Age']].size)\nprint(data.loc[(data['Age'].isin(teen)) & (data['Job_role']=='Student'),['Age']].size)","2697aa3f":"data.Code_writing_years.value_counts()","1d6cf4b9":"Code=['< 1 years','1-2 years','3-5 years','5-10 years','10-20 years','20+ years']\ncode_counts=data.Code_writing_years.value_counts()\ncode_counts=code_counts.reindex(Code)\nsns.barplot(code_counts.index,code_counts.values,alpha=0.8,)\nplt.rcParams[\"figure.figsize\"]=(10,10)\nplt.ylabel('No. of People',fontsize=20)\nplt.xlabel('Length',fontsize=20)\nplt.show()","7fab9796":"greencode=['I have never written code','< 1 years','1-2 years','3-5 years']\ndata.loc[(data.Code_writing_years.isin(greencode)),['Age']].size","48ee2ce4":"pro=['20+ years','10-20 years']\ndata.loc[(data.Code_writing_years.isin(pro)),['Job_role']].Job_role.value_counts()","69993625":"program=['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','P_None','P_Other']\nprograms=pd.DataFrame(index=program,columns=['Count'])\nprograms.index.name='Programmes'\nfor col in program:\n    programs.loc[col,'Count']=data[col].notnull().sum()\nprograms.plot(kind='bar',figsize=(18,5))\nplt.ylabel('Count')","7c6c4edf":"data.Prog_lang_recom.value_counts().plot(kind='bar',figsize=(18,8))","db8df146":"platform=['Jupyter','Rstudio','Visual_Studio','Vscode','PyCharm','Spyder','Notepad++','Sublime_Text','Vim_Emacs','MATLAB_IDE','MATLAB','IDE_None','IDE_Other']\nplatforms=pd.DataFrame(index=platform,columns=['Count'])\nplatforms.index.name='Platforms'\nfor col in platform:\n    platforms.loc[col,'Count']=data[col].notnull().sum()\nplatforms.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","d2fdd6e3":"#Most people uses Kaggle, colab or no notebook.\nnotebook=['Kaggle_NB','Colab_NB','Azure_NB','Paperspace_NB','Binder_NB','Code_Ocean_NB','IBM_Watson_Studio_NB','Amazon_Sage_NB','Amazon_EMR_NB','Google_Cloud_AI_NB','Google_Cloud_Datalab_NB','Databricks_NB','NB_None','NB_Other']\nnotebooks=pd.DataFrame(index=notebook,columns=['Count'])\nnotebooks.index.name='Notebooks'\nfor col in notebook:\n    notebooks.loc[col,'Count']=data[col].notnull().sum()\nnotebooks.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","423cc487":"#Almost 70% use personal computers to work on data science.\ndata.PC_platform.value_counts().plot(kind='bar',figsize=(10,5))\nplt.ylabel('Count')","78fcfb89":"#Most people either use GPUs or none.\nhardware=['GPUs_HW','TPUs_HW','HW_None','HW_Other']\nhardwares=pd.DataFrame(index=hardware,columns=['Count'])\nhardwares.index.name='Hardwares'\nfor col in hardware:\n    hardwares.loc[col,'Count']=data[col].notnull().sum()\nhardwares.plot(kind='bar',figsize=(10,5))\nplt.ylabel('Count')","c5953e2b":"#Most people never use TPUs.\ndata.TPU_use.value_counts().plot(kind='bar',figsize=(10,5))\nplt.ylabel('Count')","dda61788":"#Matplotlib and Seaborn are mostly preferred. They are much easier and faster to learn.\nvisual=['Matplotlib_vis','Seaborn_vis','Plotly_vis','Ggplot_vis','Shiny_vis','D3_vis','Altair_vis','Bokeh_vis','Geoplotlib_vis','Leaflet_vis','Vis_None','Vis_Other']\nvisuals=pd.DataFrame(index=visual,columns=['Count'])\nvisuals.index.name='Visuals'\nfor col in visual:\n    visuals.loc[col,'Count']=data[col].notnull().sum()\nvisuals.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","15a269af":"#Machine learning is quite new and evolving, many have 2 years or less experience.\ndata.ML_use.value_counts().plot(kind='bar',figsize=(10,5))\nplt.ylabel('Count')","1b317ee3":"#Scikit learn is mostly preferred, as many new to this field starts with it and learn starting with it.\nframework=['Scikit_learn_ML','TensorFlow_ML','Keras_ML','PyTorch_ML','Fast.ai_ML','MXNet_ML','Xgboost_ML','LightGBM_ML','CatBoost_ML','Prophet_ML','H2O_3_ML','Caret_ML','Tidymodels_ML','JAX_ML','ML_None','ML_Other']\nframeworks=pd.DataFrame(index=framework,columns=['Count'])\nframeworks.index.name='Frameworks'\nfor col in framework:\n    frameworks.loc[col,'Count']=data[col].notnull().sum()\nframeworks.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","82188ffd":"#Everyone learning machine learning starts with linear regression, and many problems could be easily solved by just linear regression.\nalgo=['Linear_Regression_alg','Decision_Trees_alg','GBM_alg','Bayesian_alg','Evolutionary_alg','DNN_alg','CNN_alg','GAN_alg','RNN_alg','TN_alg','alg_None','alg_Other']\nalgos=pd.DataFrame(index=algo,columns=['Count'])\nalgos.index.name='Algorithms'\nfor col in algo:\n    algos.loc[col,'Count']=data[col].notnull().sum()\nalgos.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","e1136e12":"#Image classification is mainly use on vision problems.\nvision=['General_purpose_vision','Image_segmentation_vision','Object_detection_vision','Image_classification_vision','Generative_Networks_vision','vision_None','vision_Other']\nvisions=pd.DataFrame(index=vision,columns=['Count'])\nvisions.index.name='Visions'\nfor col in vision:\n    visions.loc[col,'Count']=data[col].notnull().sum()\nvisions.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","5fff4e63":"#Most basic word embedding is widely used in natural language processing\nnlp=['Word_nlp','Encoder_nlp','Contextualized_nlp','Transformer_nlp','nlp_None','nlp_Other']\nnlps=pd.DataFrame(index=nlp,columns=['Count'])\nnlps.index.name='NLP'\nfor col in nlp:\n    nlps.loc[col,'Count']=data[col].notnull().sum()\nnlps.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","97079677":"#Most work in a relative small companies of less than 49 employees.\nC_size=['0-49 employees','50-249 employees','250-999 employees','1000-9,999 employees','10,000 or more employees']\nCom_size=data.Company_size.value_counts()\nCom_size=Com_size.reindex(C_size)\nsns.barplot(Com_size.index,Com_size.values,alpha=0.8,)\nplt.rcParams[\"figure.figsize\"]=(20,8)\nplt.ylabel('No. of People',fontsize=20)\nplt.xlabel('Size',fontsize=20)\nplt.show()","8658088f":"#Most of the companies either needs a few data scientist, a small company, or over 20, a consultant company.\nDS_no=data.DS_indiv.value_counts()\nDS={'1-Feb':'1-2','3-Apr':'3-4','5-Sep':'5-9','Oct-14':'10-14','15-19':'15-19','20+':'20+','0':'0'}\nDSS=['0','1-2','3-4','5-9','10-14','15-19','20+']\nDS_no.index=DS_no.index.to_series().map(DS)\nDS_no=DS_no.reindex(DSS)\nDS_no.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')\nplt.xticks(rotation=0)","18db5a32":"#Majority of the companies still have not deploy machine learning yet.\ndata.ML_usage.value_counts()","9424a24c":"#Use a mapping to convert the long sentence to short phase\nML_U=data.ML_usage.value_counts()\nml={'We are exploring ML methods (and may one day put a model into production)':'Maybe','No (we do not use ML methods)':'No','We have well established ML methods (i.e., models in production for more than 2 years)':'>2','We recently started using ML methods (i.e., models in production for less than 2 years)':'<2','I do not know':'Unknown','We use ML methods for generating insights (but do not put working models into production)':'Try_out'}\nML_U.index=ML_U.index.to_series().map(ml)\n\n#Reorder the category from high usage to none\nmll=['>2','<2','Maybe','Try_out','Unknown','No']\nML_U=ML_U.reindex(mll)\nML_U.plot(kind='bar',figsize=(10,5))\nplt.ylabel('Count')","226dd904":"#Most of the job scope are on analysis of data.\nact=['Analyze_work','Data_infra_work','Prototypes_work','Service_work','Experimentation_work','Research_work','work_None','work_Other']\nacts=pd.DataFrame(index=act,columns=['Count'])\nacts.index.name='Activities'\nfor col in act:\n    acts.loc[col,'Count']=data[col].notnull().sum()\nacts.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","38d4bd63":"#Surprisingly many were pay less than a thousand. They could be students on internships. The rest of the range are quite flat.\npay=['$0-999','1,000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999','15,000-19,999','20,000-24,999','25,000-29,999','30,000-39,999','40,000-49,999','50,000-59,999','60,000-69,999','70,000-79,999','80,000-89,999','90,000-99,999','100,000-124,999','125,000-149,999','150,000-199,999','200,000-249,999','250,000-299,999','300,000-500,000','> $500,000']\npay_grade=data.Annual_pay.value_counts()\npay_grade=pay_grade.reindex(pay)\npay_grade.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","44cff4af":"#Many companies could be not convinced yet or not ready yet to spend on machine learning or cloud computing.\nspent=['$0 ($USD)','$1-$99','$100-$999','$1000-$9,999','$10,000-$99,999','$100,000 or more ($USD)']\nspent_amt=data.Dollar_spent.value_counts()\nspent_amt=spent_amt.reindex(spent)\nspent_amt.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","a8ab6806":"#Most people prefer to use Amazon cloud.\ncloud_plt=['AWS_cloud','Azure_cloud','Google_cloud','IBM_cloud','Oracle_cloud','SAP_cloud','Salesforce_cloud','Vmware_cloud','Alibaba_cloud','Tencent_cloud','cloud_None','cloud_Other']\ncloud_plts=pd.DataFrame(index=cloud_plt,columns=['Count'])\ncloud_plts.index.name='Cloud_Platform'\nfor col in cloud_plt:\n    cloud_plts.loc[col,'Count']=data[col].notnull().sum()\ncloud_plts.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","04d034f4":"cloud_prod=['Amazon_EC2_cloudprod','AWS_Lambda_cloudprod','Amazon_Elastic_cloudprod','Azure_Cloud_cloudprod','Microsoft_Azure_cloudprod','Azure_Functions_cloudprod','Google_Cloud_compute_cloudprod','Google_Cloud_Functions_cloudprod','Google_Cloud_Run_cloudprod','Google_Cloud_App_cloudprod','cloudprod_None','cloudprod_Other']\ncloud_prods=pd.DataFrame(index=cloud_prod,columns=['Count'])\ncloud_prods.index.name='Cloud_Products'\nfor col in cloud_prod:\n    cloud_prods.loc[col,'Count']=data[col].notnull().sum()\ncloud_prods.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","22ff7a46":"#Consistently, not many are ready to purchase a machine learning product to use.\nML_prod=['Amazon_SageMaker_Mlprod','Amazon_Forecast_MLprod','Amazon_Rekognition_Mlprod','Azure_Studio_Mlprod','Azure_Cognitive_Mlprod','Google_Cloud_AI_Mlprod','Google_Cloud_Video_Mlprod','Google_Cloud_NL_Mlprod','Google_Cloud_Vision_Mlprod','Mlprod_None','Mlprod_Other']\nML_prods=pd.DataFrame(index=ML_prod,columns=['Count'])\nML_prods.index.name='Machine_Learning_Products'\nfor col in ML_prod:\n    ML_prods.loc[col,'Count']=data[col].notnull().sum()\nML_prods.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","b016bc95":"#MySQL and Microsoft SQL are mostly preferred.\nbig_use=['MySQL_big','PostgresSQL_big','SQLite_big','Oracle_big','MongoDB_big','Snowflake_big','IBM_big','Microsoft_SQL_Server_big','Microsoft_Access_big','Microsoft_Azure_big','Amazon_Redshift_big','Amazon_Athena_big','Amazon_DynamoDB_big','Google_Cloud_BigQuery_big','Google_Cloud_SQL_big','Google_Cloud_Firestore_big','big_None','big_Other']\nbig_uses=pd.DataFrame(index=big_use,columns=['Count'])\nbig_uses.index.name='Big_Data_Products_Used'\nfor col in big_use:\n    big_uses.loc[col,'Count']=data[col].notnull().sum()\nbig_uses.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","d67e781b":"big_d=['MySQL ','PostgresSQL ','SQLite ','Oracle Database ','MongoDB ','Snowflake ','IBM Db2 ','Microsoft SQL Server ','Microsoft Access ','Microsoft Azure Data Lake Storage ','Amazon Redshift ','Amazon Athena ','Amazon DynamoDB ','Google Cloud BigQuery ','Google Cloud SQL ','Google Cloud Firestore ','Other']\nbig_data=data.big_data_products.value_counts()\nbig_data=big_data.reindex(big_d)\nbig_data.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","6d4e46c8":"#Most do not use any business intelligence, but some are using PowerBI or Tableau.\nbi_reg=['Amazon_QuickSight_BI','Microsoft_Power_BI_BI','Google_Data_Studio_BI','Looker_BI','Tableau_BI','Salesforce_BI','Einstein_Analytics_BI','Qlik_BI','Domo_BI','TIBCO_Spotfire_BI','Alteryx_BI','Sisense_BI','SAP_BI','BI_None','BI_Other']\nbi_regs=pd.DataFrame(index=bi_reg,columns=['Count'])\nbi_regs.index.name='Business_Intelligence_Used'\nfor col in bi_reg:\n    bi_regs.loc[col,'Count']=data[col].notnull().sum()\nbi_regs.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","2bf9167e":"BI_O=['Amazon QuickSight','Microsoft Power BI','Google Data Studio','Looker','Tableau','Salesforce','Einstein Analytics','Qlik','Domo','TIBCO Spotfire','Alteryx ','Sisense ','SAP Analytics Cloud ','Other']\nBI_often=data.BI_tools.value_counts()\nBI_often=BI_often.reindex(BI_O)\nBI_often.plot(kind='bar',figsize=(18,8))\nplt.ylabel('Count')","b4939475":"#Many are not using Automated maching learning, it could be still quite new.\nAuto_MLtype=['Automated_data_autoML','Automated_feature_autoML','Automated_model_selection_autoML','Automated_model_architecture_autoML','Automated_hyperparameter_autoML','Automation_pipelines_autoML','autoML_None','autoML_Other']\nAuto_MLtypes=pd.DataFrame(index=Auto_MLtype,columns=['Count'])\nAuto_MLtypes.index.name='Automatic_ML_Usage'\nfor col in Auto_MLtype:\n    Auto_MLtypes.loc[col,'Count']=data[col].notnull().sum()\nAuto_MLtypes.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","c3fcafdc":"Auto_MLtool=['Google_Cloud_AutoMLprod','H20_Driverless_AI_autoMLprod','Databricks_AutoMLprod','DataRobot_AutoMLprod','Tpot_autoMLprod','Auto_Keras_autoMLprod','Auto_Sklearn_autoMLprod','Auto_ml_autoMLprod','Xcessiv_autoMLprod','Mlbox_autoMLprod','autoMLprod_None','autoMLprod_Other']\nAuto_MLtools=pd.DataFrame(index=Auto_MLtool,columns=['Count'])\nAuto_MLtools.index.name='Automatic_ML_Tools'\nfor col in Auto_MLtool:\n    Auto_MLtools.loc[col,'Count']=data[col].notnull().sum()\nAuto_MLtools.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","b8b614a0":"#Many are not using Automated maching experiments, it could be still quite new.\nML_exp=['Neptune.ai_exp','Weights&Biases_exp','Comet.ml_exp','Sacred_Omniboard_exp','TensorBoard_exp','Guild.ai_exp','Polyaxon_exp','Trains_exp','Domino_exp','exp_None','exp_Other']\nML_exps=pd.DataFrame(index=ML_exp,columns=['Count'])\nML_exps.index.name='Machine_Learning_Experiments'\nfor col in ML_exp:\n    ML_exps.loc[col,'Count']=data[col].notnull().sum()\nML_exps.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","d8c764f3":"#Most dont share their confidential codes from work, or engaged in competition in kaggle or just share hobbyist code on Github.\nshare=['Plotly_Dash_da','Streamlit_da','NBViewer_da','GitHub_da','Personal_blog_da','Kaggle_da','Colab_da','Shiny_da','da_None','da_Other']\nshares=pd.DataFrame(index=share,columns=['Count'])\nshares.index.name='Publicly_share'\nfor col in share:\n    shares.loc[col,'Count']=data[col].notnull().sum()\nshares.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","2efb859f":"#University courses are eaier to get a job, but those that are still working would take kaggle free course as a start. but to get proper certifacation, would go to udemy and coursera\ncourse=['Coursera_course','edX_course','Kaggle_course','DataCamp_course','Fast.ai_course','Udacity_course','Udemy_course','LinkedIn_course','Cloud_course','University_courses','course_None','course_Other']\ncourses=pd.DataFrame(index=course,columns=['Count'])\ncourses.index.name='Data_Science_Course'\nfor col in course:\n    courses.loc[col,'Count']=data[col].notnull().sum()\ncourses.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","42db6f86":"#Most are still using Excell or Jupyterlab as primary tool, but even more are not using any.\ndata.Analyze_tools.value_counts()","2c7e69eb":"data.Analyze_tools.isnull().sum()","37c362d2":"#The three most preferred media are Kaggle, youtube and Blogs. They are more visited by the data science community.\nmedia=['Twitter_media','Email_media','Reddit_media','Kaggle_media','Course_Forums_media','YouTube_media','Podcasts_media','Blogs_media','Publications_media','Slack_media','media_None','media_Other']\nmedias=pd.DataFrame(index=media,columns=['Count'])\nmedias.index.name='Favourite_Media_Source'\nfor col in media:\n    medias.loc[col,'Count']=data[col].notnull().sum()\nmedias.plot(kind='bar',figsize=(12,5))\nplt.ylabel('Count')","06ce6b60":"**Country**\nThere are a total of 55 countries, and it is too much to show. so taking the top 12 countries is already about 70% of all entries. In this top 12 countries, the gender balance is again checked.\nIt seem only the top 2 countries, india and USA have over 22% of woman. Other countries in the top 12, having almost 20% woman are in western europe. Canada has the highest at 24% while Japan has the lowest at 6%. the null values of from each countries are quite proportional to the number of entires per country.","9de81162":"**Programming Language**\nAlmost 80% of all users use python to program and just over 70% would recommend python. 20% uses R, and 40% uses SQL instead probably due to job requirements. R would have more data science functions than python.","6a5d3dac":"**Age**\nOver 70% of all entries are in between a young age of 18-34. Majority of those between 18-24 are students.\nData science is a new and only appear over the last ten years or so.","c8db6816":"**Gender**\nThere are five choices in this question. Only the choices of definitely a man and a woman are taken.\nIt shows that in the world, about 80% are male and 20% are female in the data science community.","d0ee7d10":"Thanks for reading. If I have more time, I would improve the bar charts, compare with previous years' data and comments more, but i can only do so much with 7 nights. Just finished a datascience bootcamp, and still learning to code in python. Please support. Thanks again.","cf539efc":"**Education**\nMost of the entries have either a bachelor or a master degree. It does not need a doctorate degree. It can also suggest that to get a job in data science, it is better to get a least a bachelor and it is better to get a master.","031f53b5":"Import relevant libraries, import data from pre-prepared CSV file.\nThe feature columns are changed from being a questions to short phases for easy coding.\nIt was easier to change in excel format.\nWhile importing the first row of question numbers were ignored.","12747515":"Number of code writing years\nAlmost 70% of entires have less then 5 years of coding experience. these people are either students or first few years on the job, as data science is still pretty new. Those whom had more than 10 years of coding experience are mainly in the software, research scientist or seasoned data scientist.","7d7afbba":"**Platform**\nJupyter is mostly prefered. For new comer to data science, jupyter has a much easier to get familiar fast."}}