{"cell_type":{"b4c86496":"code","19c1c34e":"code","cb19d0c1":"code","b5c5e45b":"code","73b682fe":"code","23242e28":"code","d108833d":"code","a45ed1da":"code","d2728924":"code","c3db79d6":"code","4b22147f":"code","8796cbac":"code","109ab834":"code","bb419062":"code","a6c4f751":"code","d952b911":"code","a55cdecb":"code","a6b483b1":"code","a8459ce2":"code","1abc0a20":"code","c20cbd4c":"code","7562d493":"markdown","0c8e1378":"markdown","12fa1d4d":"markdown","10169e37":"markdown","bcd874fb":"markdown"},"source":{"b4c86496":"%matplotlib inline\nimport os, sys\nbase_data_dir = os.path.join('..', 'input')\nsys.path.append(os.path.join(base_data_dir, 'fitparse', 'python-fitparse-master'))\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport fitparse\nplt.style.use('ggplot')","19c1c34e":"experiments_list = {os.path.dirname(x) for x in glob(os.path.join(base_data_dir, '*', '*.fit'))}\nexperiments_list","cb19d0c1":"test_exp = list(experiments_list)[0]\ncur_fit = glob(os.path.join(test_exp, '*.fit'))[0]\ncur_csv = glob(os.path.join(test_exp, '*.csv'))[0]\ncur_aud = glob(os.path.join(test_exp, '*.wav'))[0]","b5c5e45b":"fit_data = fitparse.FitFile(cur_fit)\nfit_df = pd.DataFrame([\n    {k['name']: k['value']\n     for k in a.as_dict()['fields']} \n    for a in fit_data.get_messages('record')])\nfit_df['elapsed_time'] = (fit_df['timestamp']-fit_df['timestamp'].min()).dt.total_seconds()\nfit_df.sample(3)","73b682fe":"fit_df.plot(x='elapsed_time', y='altitude')\nfit_df.plot(x='elapsed_time', y='heart_rate')","23242e28":"sl_df = pd.read_csv(cur_csv)\nsl_df = 0.5*(sl_df.fillna(method='backfill')+sl_df.fillna(method='ffill'))\nsl_df = sl_df.fillna(method='backfill').fillna(method='ffill')\nsl_df.plot(x='relative_time', y='LinearAccelerometerSensor')\nsl_df.sample(4)","d108833d":"SAMPLING_RATE = 8000 # [4000, 8000, 16000, 22000]\naudio_dat, sr = librosa.core.load(cur_aud, sr=SAMPLING_RATE)\nprint(audio_dat.shape)\nplt.plot(audio_dat)","a45ed1da":"from scipy.linalg import norm\nhop_length = 1000\nN_MEL_COUNT = 512\nNORMALIZE = False\nUSE_DB = True\naudio_spect = librosa.feature.melspectrogram(audio_dat, sr=sr, hop_length=hop_length, n_mels=N_MEL_COUNT)\nif USE_DB:\n    audio_spect = librosa.amplitude_to_db(audio_spect, ref=np.max)\nif NORMALIZE:\n    audio_spect = audio_spect\/norm(audio_spect, axis=0, keepdims=True)\nprint('Spectra per second: {:2.1f}'.format(sr\/hop_length))\nprint(audio_spect.shape)\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 5))\nplt.colorbar(ax1.imshow(audio_spect, cmap='viridis'))\nax1.set_aspect(3)","d2728924":"audio_time = np.linspace(0, audio_spect.shape[1]\/(sr\/hop_length), num=audio_spect.shape[1])","c3db79d6":"from scipy.interpolate import interp1d\nDIV_GROUPS = 4\nhr_iter_func = interp1d(fit_df['elapsed_time'], fit_df['heart_rate'], \n                        kind='nearest', fill_value='extrapolate')\nhr_full_time = hr_iter_func(audio_time)\ncat_cut = pd.qcut(hr_full_time, DIV_GROUPS)\nfig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\nfor i in np.unique(cat_cut.codes):\n    c_x = cat_cut.codes==i\n    ax1.plot(audio_time[c_x], hr_full_time[c_x], '.', label=str(i))\nax1.legend()","4b22147f":"train_max = audio_time.shape[0]\/\/2\ntrain_X = audio_spect[:, :train_max].swapaxes(0,1)\ntrain_y = cat_cut.codes[:train_max]\nvalid_X = audio_spect[:, train_max:].swapaxes(0,1)\nvalid_y = cat_cut.codes[train_max:]\nprint('Training:', train_X.shape, train_y.shape)\nprint('Validation:', valid_X.shape, valid_y.shape)","8796cbac":"from keras import layers, models\nfrom keras.optimizers import Adam\ndef get_simple_mlp():\n    simple_model = models.Sequential()\n    simple_model.add(layers.BatchNormalization(input_shape=train_X.shape[1:]))\n    simple_model.add(layers.GaussianNoise(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(128, activation='linear'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(16, activation='linear'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Dense(train_y.max()+1, activation='softmax'))\n    simple_model.compile(loss='sparse_categorical_crossentropy',\n                        metrics = ['sparse_categorical_accuracy'],\n                        optimizer=Adam(lr=1e-4))\n    simple_model.summary()\n    return simple_model\nmodel_simple = get_simple_mlp()","109ab834":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom IPython.display import clear_output\nweight_path=\"{}_weights.best.hdf5\".format('heart_detector')\ndef fit_model(in_model, batch_size=512):\n    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n    early = EarlyStopping(monitor=\"val_loss\", \n                          mode=\"min\", \n                          patience=15) # probably needs to be more patient, but kaggle time is limited\n    callbacks_list = [checkpoint, early, reduceLROnPlat]\n    fit_results = in_model.fit(train_X, train_y,\n                               batch_size=batch_size,\n                              epochs=50,\n                               shuffle=True,\n                              validation_data=(valid_X, valid_y),\n                               callbacks=callbacks_list\n                              )\n    clear_output()\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n    ax1.plot(fit_results.history['loss'], label='Training')\n    ax1.plot(fit_results.history['val_loss'], label='Validation')\n    ax1.legend()\n    ax1.set_title('Loss')\n    b_name = in_model.metrics_names[1]\n    ax2.plot(fit_results.history[b_name], label='Training')\n    ax2.plot(fit_results.history['val_{}'.format(b_name)], label='Validation')\n    ax2.legend()\n    ax2.set_title(b_name.replace('_', ' '))\n    ax2.set_ylim(0, 1)\n    for k, v in zip(in_model.metrics_names,\n                    in_model.evaluate(valid_X, valid_y)):\n        print('{}: {:2.1f}'.format(k, v))\n    return in_model","bb419062":"fit_model(model_simple);","a6c4f751":"def get_simple_cnn(depth=5):\n    simple_model = models.Sequential()\n    simple_model.add(layers.BatchNormalization(input_shape=train_X.shape[1:]))\n    simple_model.add(layers.GaussianNoise(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Reshape(train_X.shape[1:]+(1,)))\n    for i in range(depth):\n        simple_model.add(layers.Conv1D(4*2**i, 3, activation='linear'))\n        simple_model.add(layers.LeakyReLU(0.1))\n        simple_model.add(layers.MaxPool1D(2))\n    simple_model.add(layers.Flatten())\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(8, activation='linear'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(train_y.max()+1, activation='softmax'))\n    simple_model.compile(loss='sparse_categorical_crossentropy',\n                        metrics = ['sparse_categorical_accuracy'],\n                        optimizer='adam')\n    simple_model.summary()\n    return simple_model\nmodel_cnn = get_simple_cnn()","d952b911":"fit_model(model_cnn);","a55cdecb":"from keras.utils import to_categorical\ntrain_max = audio_time.shape[0]\/\/2\ntrain_X = audio_spect[:, :train_max].swapaxes(0,1)\ntrain_y = cat_cut.codes[:train_max]\nvalid_X = audio_spect[:, train_max:].swapaxes(0,1)\nvalid_y = cat_cut.codes[train_max:]\n\ndef _chunk_it(in_x, raw_y, chunk_size=36):\n    out_x, out_y = [], []\n    in_y = to_categorical(raw_y)\n    for i in range(in_x.shape[0]-chunk_size):\n        out_x += [in_x[i:(i+chunk_size)]]\n        out_y += [np.mean(in_y[i:(i+chunk_size)], 0)]\n    return np.stack(out_x, 0), np.stack(out_y, 0)\ntrain_X, train_y = _chunk_it(train_X, train_y)\nvalid_X, valid_y = _chunk_it(valid_X, valid_y)\nprint('Training:', train_X.shape, train_y.shape)\nprint('Validation:', valid_X.shape, valid_y.shape)","a6b483b1":"def get_better_cnn(base_count=4, depth=2):\n    simple_model = models.Sequential()\n    simple_model.add(layers.BatchNormalization(input_shape=train_X.shape[1:]))\n    simple_model.add(layers.GaussianNoise(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    for i in range(depth):\n        simple_model.add(layers.Conv1D(base_count*2**i, 3, activation='linear', padding='same'))\n        simple_model.add(layers.LeakyReLU(0.1))\n        simple_model.add(layers.MaxPool1D(2))\n    simple_model.add(layers.Flatten())\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(8, activation='linear'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Dropout(0.25))\n    simple_model.add(layers.Dense(train_y.shape[1], activation='softmax'))\n    simple_model.compile(loss='categorical_crossentropy',\n                        metrics = ['categorical_accuracy'],\n                        optimizer='adam')\n    simple_model.summary()\n    return simple_model\nmodel_bcnn = get_better_cnn(128)","a8459ce2":"fit_model(model_bcnn);","1abc0a20":"def get_lstm(base_count=4):\n    simple_model = models.Sequential()\n    simple_model.add(layers.BatchNormalization(input_shape=train_X.shape[1:]))\n    simple_model.add(layers.GaussianNoise(0.2))\n    simple_model.add(layers.Dropout(0.75))\n    simple_model.add(layers.Conv1D(base_count*2**i, 3, activation='linear', padding='same'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Bidirectional(layers.LSTM(base_count)))\n    simple_model.add(layers.Dropout(0.5))\n    simple_model.add(layers.Dense(16, activation='linear'))\n    simple_model.add(layers.LeakyReLU(0.1))\n    simple_model.add(layers.Dropout(0.5))\n    simple_model.add(layers.Dense(train_y.shape[1], activation='softmax'))\n    simple_model.compile(loss='categorical_crossentropy',\n                        metrics = ['categorical_accuracy'],\n                        optimizer=Adam(1e-4))\n    simple_model.summary()\n    return simple_model\nmodel_lstm = get_lstm(128)","c20cbd4c":"fit_model(model_lstm);","7562d493":"# Load Audio Data","0c8e1378":"# Parse Garmin Fit Data","12fa1d4d":"# Convert to Spectrograms","10169e37":"# Load Science Lab Data","bcd874fb":"# Temporal Chunks\nHere we use temporal chunks instead of just one time-slice"}}