{"cell_type":{"44f4a037":"code","99b19611":"code","93e9e530":"code","82bdf6a8":"code","a36469e1":"code","27747beb":"code","41126c70":"code","ea591cbf":"code","1d58bbc9":"code","4342bb9e":"code","cc43571d":"code","9dee3108":"code","1a7f9091":"code","6515e472":"code","ba56004c":"code","9435ae72":"code","16ff67de":"code","aa659b88":"code","29a003f4":"code","fa7618e8":"code","677c5dcd":"code","9bd1992d":"code","2203e748":"code","177d9e5c":"code","16fb7fa5":"code","2973b267":"code","51a57ff4":"code","13f2c0dc":"code","7ae8ac48":"code","889c051c":"code","c4780da7":"code","987a1c8e":"code","6c17402f":"code","da654b1b":"code","eaf025d8":"code","571617f4":"code","942ae87b":"code","eae10b80":"code","e19ea83a":"code","44c43178":"code","e4c7fe23":"code","1a41f37d":"code","9eed5da1":"code","0957e4b4":"code","74e7b522":"code","691f2b21":"code","4799350f":"code","984706d8":"code","2b595691":"code","8121162c":"markdown","aae13037":"markdown","1316bc9c":"markdown","dd2a191d":"markdown"},"source":{"44f4a037":"import os\nos.listdir('..\/input\/covidct\/CT_COVID')","99b19611":"import cv2\nim = cv2.imread('..\/input\/covidct\/CT_COVID\/2020.01.24.919183-p27-133.png')","93e9e530":"im.shape","82bdf6a8":"import matplotlib.pyplot as plt\nplt.imshow(im)\nplt.show()","a36469e1":"imt = im.transpose(2,0,1)","27747beb":"plt.imshow(imt[0])\nplt.show()","41126c70":"plt.imshow(imt[1])\nplt.show()","ea591cbf":"plt.imshow(imt[2])\nplt.show()","1d58bbc9":"from tqdm import tqdm\n\nloc1 = '..\/input\/covidct\/CT_COVID'\nloc2 = '..\/input\/covidct\/CT_NonCOVID'\n\nfeatures = []\n\nfor img in tqdm(os.listdir(loc1)):\n    f = cv2.imread(os.path.join(loc1,img),0)\n    fr = cv2.resize(f,(70,70))\n    features.append(fr)\n    \nfor img in tqdm(os.listdir(loc2)):\n    f = cv2.imread(os.path.join(loc2,img),0)\n    fr = cv2.resize(f,(70,70))\n    features.append(fr)","4342bb9e":"import numpy as np\nX = np.array(features)","cc43571d":"X.shape","9dee3108":"plt.imshow(X[0])\nplt.show()","1a7f9091":"labels = []\nfor img in tqdm(os.listdir(loc1)):\n    labels.append(1)\n    \nfor img in tqdm(os.listdir(loc2)):\n    labels.append(0)","6515e472":"Y = np.array(labels)\nY","ba56004c":"X.shape\nXf = X.reshape(746,4900)\nYf = Y.reshape(746,1)","9435ae72":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(Xf,Yf)","16ff67de":"from keras.utils import np_utils\nytrain_h = np_utils.to_categorical(ytrain)\nytest_h = np_utils.to_categorical(ytest)","aa659b88":"xtrain_n = xtrain\/xtrain.max()\nxtest_n = xtest\/xtest.max()","29a003f4":"import pandas as pd\ndfc = pd.DataFrame(np.hstack((Yf,Xf)))\ndfc.to_csv('CT_Scan_Lungs.csv')","fa7618e8":"from keras import models\nfrom keras import layers","677c5dcd":"model1 = models.Sequential()\nmodel1.add(layers.Dense(256 , activation = 'relu' ,input_shape = xtrain.shape[1:]))\nmodel1.add(layers.Dropout(0.4))\n\nmodel1.add(layers.Dense(128 , activation = 'relu'))\nmodel1.add(layers.Dropout(0.3))\n\nmodel1.add(layers.Dense(256 , activation = 'relu'))\nmodel1.add(layers.Dropout(0.4))\n\nmodel1.add(layers.Dense(2 , activation = 'sigmoid'))","9bd1992d":"model1.summary()","2203e748":"from keras import optimizers\nfrom keras import metrics\n\nmodel1.compile(optimizer='sgd',\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","177d9e5c":"model1.fit(xtrain_n , ytrain_h , epochs=100, validation_data=(xtest_n,ytest_h))","16fb7fa5":"print(model1.evaluate(xtrain,ytrain_h))","2973b267":"print(model1.evaluate(xtest,ytest_h))","51a57ff4":"model1.save('ann_model.h5')","13f2c0dc":"plt.imshow(xtrain[4].reshape(70,70))\nplt.show()","7ae8ac48":"plt.imshow(xtrain_n[4].reshape(70,70))\nplt.show()","889c051c":"xtrain_n","c4780da7":"model1.predict(xtest_n[89].reshape(1,4900))","987a1c8e":"predicted_Label = np.array(['Covid','Non_Covid'])","6c17402f":"predicted_Label[np.argmax(model1.predict(xtest_n[89].reshape(1,4900)))]","da654b1b":"ytest[89]","eaf025d8":"#Confusion_Matrix for model Analysis\nytest_pred = []\nfor rows in model1.predict(xtest_n):\n    ytest_pred.append(np.argmax(rows))","571617f4":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(ytest,ytest_pred)","942ae87b":"xtest_n.shape","eae10b80":"#Data transformation as per CNN\nxtrain_cnn = xtrain_n.reshape(559,70,70,1)\nxtest_cnn = xtest_n.reshape(187,70,70,1)","e19ea83a":"import keras\nfrom keras.models import Sequential\nfrom keras.utils import np_utils\nfrom keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras import regularizers","44c43178":"wd = 1e-4\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3) , padding='same' , kernel_regularizer=regularizers.l2(wd), input_shape=xtrain_cnn.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(512,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512,(3,3) , kernel_regularizer=regularizers.l2(wd) ,padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(1024,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(1024,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(1024,(3,3) , kernel_regularizer=regularizers.l2(wd) , padding='same' ))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='softmax'))","e4c7fe23":"model.summary()","1a41f37d":"from keras import optimizers\nfrom keras import metrics\n\nmodel.compile(optimizer='sgd',loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","9eed5da1":"model.fit(xtrain_cnn , ytrain_h , epochs=100, validation_data=(xtest_cnn,ytest_h))","0957e4b4":"print(model.evaluate(xtrain_cnn,ytrain_h))","74e7b522":"print(model.evaluate(xtest_cnn,ytest_h))","691f2b21":"#Save the CNN Model\nmodel.save('cnn_model.h5')","4799350f":"#Confusion_Matrix for model Analysis\nytest_pred_cnn = []\nfor rows in model.predict(xtest_cnn):\n    ytest_pred_cnn.append(np.argmax(rows))","984706d8":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(ytest,ytest_pred_cnn)","2b595691":"xtrain_cnn.shape","8121162c":"**Create a Deep Learning Neural Network Model to train using the existing set of data**","aae13037":"**save the ANN Model and Download**","1316bc9c":"**Create a feature matrix with the features of all the images to form structured data**","dd2a191d":"**CNN for Image Data**"}}