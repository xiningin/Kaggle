{"cell_type":{"73bc76d2":"code","2fa0cb60":"code","943804cc":"code","ef85533e":"code","ef9a39e2":"code","132e875d":"code","9b5563ae":"code","4ee9c222":"code","ed919221":"code","088237e0":"code","c01a565e":"code","606c6544":"code","8044c21c":"code","3ea10704":"code","9623b2f2":"code","5119d95d":"code","615d23b9":"code","e55bd13b":"markdown","9f8e28a8":"markdown","a61ea5a0":"markdown","d10057c6":"markdown","8be0fbf0":"markdown","e211f730":"markdown","b644165f":"markdown","027f8bde":"markdown"},"source":{"73bc76d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fa0cb60":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python\n# Any results you write to the current directory are saved as output.\n#Sharpening\n\nimage = cv2.imread('\/kaggle\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Image Sharpening\")\nplt.imshow(sharpened)\n\nplt.show()","943804cc":"#Thresholding, Binarization & Adaptive Thresholding\n# Load our new image\n\nimage = cv2.imread('\/kaggle\/input\/cusersmarildownloadsjackjpg\/jack.jpg', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","ef85533e":"image = cv2.imread('\/kaggle\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)\n\n# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Erosion\")\nplt.imshow(erosion)\n\n# \ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.subplot(3, 2, 3)\nplt.title(\"Dilation\")\nplt.imshow(dilation)\n\n\n# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(3, 2, 4)\nplt.title(\"Opening\")\nplt.imshow(opening)\n\n# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(3, 2, 5)\nplt.title(\"Closing\")\nplt.imshow(closing)","ef9a39e2":"image = cv2.imread('\/kaggle\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nheight, width,_ = image.shape\n\n# Extract Sobel Edges\nsobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\nsobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Sobel X\")\nplt.imshow(sobel_x)\n\nplt.subplot(3, 2, 3)\nplt.title(\"Sobel Y\")\nplt.imshow(sobel_y)\n\nsobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n\nplt.subplot(3, 2, 4)\nplt.title(\"sobel_OR\")\nplt.imshow(sobel_OR)\n\nlaplacian = cv2.Laplacian(image, cv2.CV_64F)\n\nplt.subplot(3, 2, 5)\nplt.title(\"Laplacian\")\nplt.imshow(laplacian)\n\n# Canny Edge Detection uses gradient values as thresholds\n# The first threshold gradient\ncanny = cv2.Canny(image, 50, 120)\n\nplt.subplot(3, 2, 6)\nplt.title(\"Canny\")\nplt.imshow(canny)","132e875d":"#Perpsective Transform\n\nimage = cv2.imread('\/kaggle\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n\n\nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)","9b5563ae":"# load image\nfrom matplotlib import pyplot\n\nfrom PIL import Image\nimage = Image.open('..\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\n# horizontal flip\nhoz_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\n# vertical flip\nver_flip = image.transpose(Image.FLIP_TOP_BOTTOM)\n# plot all three images using matplotlib\npyplot.subplot(311)\npyplot.imshow(image)\npyplot.subplot(312)\npyplot.imshow(hoz_flip)\npyplot.subplot(313)\npyplot.imshow(ver_flip)\npyplot.show()","4ee9c222":"# load image\nimage = Image.open('..\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\n# plot original image\npyplot.subplot(311)\npyplot.imshow(image)\n# rotate 45 degrees\npyplot.subplot(312)\npyplot.imshow(image.rotate(45))\n# rotate 90 degrees\npyplot.subplot(313)\npyplot.imshow(image.rotate(90))\npyplot.show()\n#rotates 270 degrees\npyplot.imshow(image.rotate(270))\npyplot.show()","ed919221":"from PIL import Image\n# load image\nimage = Image.open('..\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\n# create a cropped image\ncropped = image.crop((100, 100, 200, 200))\n# show cropped image\npyplot.imshow(cropped)","088237e0":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","c01a565e":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","606c6544":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/cusersmarildownloadsjackjpg\/jack.jpg', loader_transform)","8044c21c":"#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","3ea10704":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('..\/input\/cusersmarildownloadsjackjpg\/jack.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","9623b2f2":"from PIL import Image\n\nimage = Image.open(\"..\/input\/cusersmarildownloadsjackjpg\/jack.jpg\")\nimage","5119d95d":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#7332a8','#7d32a8','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Happy Halloween' )","615d23b9":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Trick or Treat! Jack-o-Lantern and Mar\u00edlia Prata  @mpwolke were here' )","e55bd13b":"#Thresholding, Binarization & Adaptive Thresholding","9f8e28a8":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcS_nly6MNuSFczbZuZEuneEG0P8qD0yswDrNQ&usqp=CAU)becastanheiradepera.blogs.sapo.pt","a61ea5a0":"#Jack-o'-lantern - Trick or Treat!\n\nThe connection between the pumpkin and Halloween is intuitive: pumpkins require warm weather and frostless ground to grow, so they can only be grown during the summer and harvested during the fall. Pumpkin harvest season begins in September and goes through October, when the vegetables are at their freshest and most delicious. This is the only time of year they can be enjoyed properly, making them the perfect addition to Halloween folklore.\n\nThe Jack-o-Lantern, however, does not simply refer to a carved pumpkin. It is the term used for any carved fruit or vegetable, usually gourds. The name Jack-o-Lantern comes from the legend of Stingy Jack of the Lantern. Jack was a very clever thief from Western Europe with the devil on his tail. He used his wits to trap the devil up a tree by drawing a cross at its trunk and would only let him go if he promised never to take Jack\u2019s soul. When Jack died his soul was not pure enough to be taken to Heaven, but the devil couldn\u2019t take him to Hell, so he was forced to wander the world as a lost soul. Satan wanted Jack to have at least a taste of Hell, so he gave him an ember from the flames of Hades to guide his way. Jack put the ember inside of a carved turnip (the preferred jack-o-lantern gourd of the time) and the carved vegetables were named for him and his hellish lantern.\n\nCarving vegetables is a tradition that predates the name Jack-o-lantern and even the predecessor to Halloween: the festival of Samhain. People have been making these carvings since at least 10,000 years ago when gourds became the earliest domesticated plant, possibly due to their ideal shape and size for carving. At this time, turnips, beets, potatoes, and rutabagas were most likely used. Pumpkins were discovered in America, so it would be centuries before they would become a part of the tradition.\n\nIn Ireland Samhain was considered a time when spirits both good and evil were free to roam the Earth. Carving gourds was already a tradition, so it was easily added into celebrations of Samhain. People carved Jack-o-lanterns into scary shapes and faces, lit a candle inside using the communal bonfire every community had during Samhain, and put them in front of their windows and doors to scare Stingy Jack and his fellow evil spirits away.\n\nWhen Irish immigrants came to the United States, they brought their Halloween celebrations with them, including the Jack-o-lanterns. Here they found pumpkins, which were larger and easier to carve than anything they had used before, so the pumpkin quickly became the new vegetable of choice. https:\/\/www.holidaysmart.com\/articles\/history-jack-o-lantern","d10057c6":"![](https:\/\/media4.giphy.com\/media\/Ss66uSY07ugFlmunA0\/200.webp?cid=ecf05e476hdgkooh6jut6woqnfgzcfwsep1oo13ykwzsh42q&rid=200.webp)","8be0fbf0":"#Code from Salman Ibne Eunus https:\/\/www.kaggle.com\/salmaneunus\/mechanical-tools-warehouse-classification","e211f730":"#Codes by Naim Mhedhbi https:\/\/www.kaggle.com\/naim99\/data-augmentation-techniques","b644165f":"#Perpsective Transform","027f8bde":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python"}}