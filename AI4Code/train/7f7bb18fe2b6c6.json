{"cell_type":{"3aa84f77":"code","082402cf":"code","207d3732":"code","790da734":"code","f34234e9":"code","a210a843":"code","8545f14f":"code","e1a27f17":"code","eb032a6e":"code","753854aa":"code","2894b423":"code","19cbfc3b":"code","98500905":"code","372a213b":"code","cb286f67":"code","ed9a5b31":"code","e58a102e":"code","6323ed7a":"markdown","52abcabc":"markdown","6dfcb9bf":"markdown","b931ab1a":"markdown","10334693":"markdown","140c3e99":"markdown"},"source":{"3aa84f77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","082402cf":"import os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.transforms as transforms\n\n#For converting the dataset to torchvision dataset format\nclass VowelConsonantDataset(Dataset):\n    def __init__(self, file_path,train=True,transform=None):\n        self.transform = transform\n        self.file_path=file_path\n        self.train=train\n        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n        self.len = len(self.file_names)\n        if self.train:\n            self.classes_mapping=self.get_classes()\n    def __len__(self):\n        return len(self.file_names)\n    \n    def __getitem__(self, index):\n        file_name=self.file_names[index]\n        image_data=self.pil_loader(self.file_path+\"\/\"+file_name)\n        if self.transform:\n            image_data = self.transform(image_data)\n        if self.train:\n          file_name_splitted=file_name.split(\"_\")\n          Y1 = self.classes_mapping[file_name_splitted[0]]\n          Y2 = self.classes_mapping[file_name_splitted[1]]\n          z1,z2=torch.zeros(10),torch.zeros(10)\n          z1[Y1-10],z2[Y2]=1,1\n          label=torch.stack([z1,z2])\n\n          return image_data, label\n\n        else:\n          return image_data, file_name\n          \n    def pil_loader(self,path):\n      with open(path, 'rb') as f:\n        img = Image.open(f)\n        return img.convert('RGB')\n\n      \n    def get_classes(self):\n        classes=[]\n        for name in self.file_names:\n            name_splitted=name.split(\"_\")\n            classes.extend([name_splitted[0],name_splitted[1]])\n        classes=list(set(classes))\n        classes_mapping={}\n        for i,cl in enumerate(sorted(classes)):\n            classes_mapping[cl]=i\n        return classes_mapping","207d3732":"# check if CUDA is available\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","790da734":"!unzip ..\/input\/padhai-hindi-vowel-consonant-classification\/train.zip\n!unzip ..\/input\/padhai-hindi-vowel-consonant-classification\/test.zip","f34234e9":"# define training and test data directories\ndata_dir = '..\/input\/output'\ntrain_dir = os.path.join(data_dir, 'train\/')\ntest_dir = os.path.join(data_dir, 'test\/')","a210a843":"data_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n    ])","8545f14f":"# load and transform data\ndata = VowelConsonantDataset('train',train=True,transform=data_transform)\ntrain_size = int(0.85 * len(data))\ntest_size = len(data) - train_size \ntrain_data, validation_data = random_split(data, [train_size, test_size])\ntest_data=VowelConsonantDataset('test',train=False,transform=data_transform)\n\n# print out some data stats\nprint('Num training images: ', train_size)\nprint('Num validation images: ', test_size)\nprint('Num test images: ', len(test_data))","e1a27f17":"# define dataloader parameters\nbatch_size = 20\nnum_workers=1\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n                                           num_workers=num_workers, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, \n                                          num_workers=num_workers, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n                                          num_workers=num_workers, shuffle=True)","eb032a6e":"# Visualize some sample data\n\n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    # ax.set_title([labels[idx]])","753854aa":"from torchvision import models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport copy\nclass MyModel(nn.Module):\n    def __init__(self, num_classes1, num_classes2):\n        super(MyModel, self).__init__()\n        self.model_resnet50 = models.resnet50(pretrained=True)\n        final_in_features = self.model_resnet50.fc.in_features\n        self.model_resnet50.fc = nn.Sequential()\n        self.fc1 = nn.Sequential(\n              nn.BatchNorm1d(final_in_features),\n              nn.Dropout(0.3),\n              nn.Linear(in_features=final_in_features, out_features=1000,bias=True),\n              nn.ReLU(),\n              nn.BatchNorm1d(1000, eps=1e-05, momentum=0.3),\n              nn.Dropout(0.3),\n              nn.Linear(in_features=1000,out_features=num_classes1,bias=True))\n        self.fc2 = nn.Sequential(\n              nn.BatchNorm1d(final_in_features), \n              nn.Dropout(0.3),\n              nn.Linear(in_features=final_in_features,out_features=1000,bias=True),\n              nn.ReLU(),\n              nn.BatchNorm1d(1000, eps=1e-05, momentum=0.3),\n              nn.Dropout(0.3),\n              nn.Linear(in_features=1000, out_features=num_classes2,bias=True))\n\n    def forward(self, x):\n        x = self.model_resnet50(x)\n        out1 = self.fc1(x)\n        out2 = self.fc2(x)\n        return out1, out2","2894b423":"net  = MyModel(10,10)\nnet = net.to(device)","19cbfc3b":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.001\noptimizer = optim.SGD(net.parameters(), lr=0.01,momentum=0.9)","98500905":"def evaluation(dataloader,model):\n    total,correct=0,0\n    for data in dataloader:\n        inputs,labels=data\n        inputs,labels=inputs.to(device),labels.to(device)\n        out1,out2=model(inputs)\n        _,pred1=torch.max(out1.data,1)\n        _,pred2=torch.max(out2.data,1)\n        _,labels1=torch.max(labels[:,0,:].data,1)\n        _,labels2=torch.max(labels[:,1,:].data,1)\n        total+=labels.size(0)\n        fin1=(pred1==labels1)\n        fin2=(pred2==labels2)\n        \n        correct+=(fin1==fin2).sum().item()\n    return 100*correct\/total","372a213b":"loss_epoch_arr = []\nloss_arr = []\nmax_epochs = 6\nmin_loss = 1000\nbatch_size = 32\nn_iters = np.ceil(9000\/batch_size)\nfor epoch in range(max_epochs):\n    for i, data in enumerate(train_loader, 0):\n        net.train()\n        images, labels = data\n#         print(images.shape)\n        images = images.to(device)\n        targetnp=labels[:,0,:].cpu().numpy()\n        targetnp1 = labels[:,1,:].cpu().numpy()\n        # Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\n        with torch.no_grad():\n            new_targets1 = np.argmax(targetnp,axis=1)\n            new_targets2 = np.argmax(targetnp1,axis=1)\n        new_targets1=torch.LongTensor(new_targets1)\n        new_targets2=torch.LongTensor(new_targets2)\n        new_targets1 = new_targets1.to(device)\n        new_targets2 = new_targets2.to(device)\n        optimizer.zero_grad()\n        out = net.forward(images)\n        loss_fc1 = criterion(out[0], new_targets1)\n        loss_fc2 = criterion(out[1],new_targets2)\n        loss = torch.add(loss_fc1,loss_fc2)\n        loss.backward()\n        optimizer.step()   \n        if min_loss > loss.item():\n            min_loss = loss.item()\n            best_model = copy.deepcopy(net.state_dict())\n            print('Min loss %0.2f' % min_loss)\n#         if min_loss < 0.8:\n#             opt = optim.SGD(my_model.parameters(),lr=0.01,momentum=0.99,nesterov=True)\n        if i % 100 == 0:\n            print('Iteration: %d\/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n        del images, labels, out\n        torch.cuda.empty_cache()\n        loss_arr.append(loss.item())\n    print(\"Epoch number :\",epoch)\n    print(\"Train Accuracy :\",evaluation(train_loader,net))\n    print(\"Test Accuracy :\"  ,evaluation(validation_loader,net))\n    loss_epoch_arr.append(loss.item())\n#     my_model.load_state_dict(best_model)\nplt.plot(loss_arr)\nplt.show()","cb286f67":"print(evaluation(validation_loader,net))","ed9a5b31":"net.eval()\nplist=[]\nfinal_list=[]\nfor inputs_test, fn in test_loader:\n    inputs_test=inputs_test.to(device)\n    out1,out2=net.forward(inputs_test)\n    _,pred1=torch.max(out1,1)\n    pred1=pred1.tolist()\n    _,pred2=torch.max(out2,1)\n    pred2=pred2.tolist()\n    for x,y,z in zip(pred1,pred2,fn):\n        p=\"V\"+str(x)+\"_\"+\"C\"+str(y)\n        plist.append(p)\n        final_list.append(z)","e58a102e":"submission = pd.DataFrame({\"ImageId\":final_list, \"Class\":plist})\nsubmission.to_csv('submission.csv', index=False)","6323ed7a":"# Specify Loss Function and Optimizer","52abcabc":"# Traning","6dfcb9bf":"# DataLoaders and Data Visualization","b931ab1a":"# Transforming the Data","10334693":"# Testing","140c3e99":"# Define Model"}}