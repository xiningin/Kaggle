{"cell_type":{"40c9661a":"code","793e705d":"code","1cff0a52":"code","df213983":"code","8bec7be7":"code","6edee6d2":"code","d9e56592":"code","b35ef01f":"code","480c42f3":"code","0a6b9f72":"code","55a8a443":"code","72b0e3b5":"code","1d27aceb":"code","fba5c669":"code","c71b3a99":"code","9cd13d7d":"code","d86b1b74":"code","7dfb5c85":"code","719539d5":"code","a021413f":"code","320f721b":"code","77856907":"code","04c624a2":"code","b7affae2":"code","633cc4b0":"code","74d0decf":"code","5e5d7ed6":"code","0ab00ee8":"code","d9321926":"code","e442b44e":"code","355f9cec":"code","3f17b6cf":"markdown","30a1a22c":"markdown","8483f1cf":"markdown","aab0afe6":"markdown","4681df2d":"markdown","c6f1c7f3":"markdown","06e69ffa":"markdown","f6db3fa2":"markdown","325e62b5":"markdown"},"source":{"40c9661a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","793e705d":"df = pd.read_csv('..\/input\/iris\/Iris.csv', index_col='Id')\ndf","1cff0a52":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf['Species'] = label_encoder.fit_transform(df['Species'])\ndf ","df213983":"df.Species.value_counts()","8bec7be7":"import tensorflow as tf \nfrom tensorflow import keras\ntf.__version__","6edee6d2":"df_val = df.sample(frac=0.2, random_state=33)\ndf_train = df.drop(df_val.index)","d9e56592":"df_train","b35ef01f":"df_val","480c42f3":"df_train.Species.value_counts()","0a6b9f72":"df_val.Species.value_counts()","55a8a443":"len(df_train), len(df_val)","72b0e3b5":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n  my_df = dataframe.copy()\n  labels = my_df.pop(target)\n  ds = tf.data.Dataset.from_tensor_slices((dict(my_df), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","1d27aceb":"train_ds = df_to_dataset(dataframe=df_train, target='Species')\nval_ds = df_to_dataset(dataframe=df_val,  target='Species')","fba5c669":"for b in train_ds.take(1):\n    print(b)","c71b3a99":"from tensorflow import feature_column\n\nfeatures = []\nfor col in df_train.columns:\n    if col == 'Species':\n        continue \n    features.append(feature_column.numeric_column(col))\nfeatures","9cd13d7d":"model = keras.models.Sequential()\nmodel.add(keras.layers.DenseFeatures(features))\nmodel.add(keras.layers.Dense(28, activation='relu'))\nmodel.add(keras.layers.Dense(28, activation='relu'))\nmodel.add(keras.layers.Dense(3, activation='softmax'))\n","d86b1b74":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n             metrics=['accuracy'])","7dfb5c85":"model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=0)","719539d5":"model.summary()","a021413f":"model.evaluate(val_ds)","320f721b":"model.predict(val_ds)","77856907":"import numpy as np \nnp.argmax(model.predict(val_ds), axis=1)","04c624a2":"np.argmax([1.38895875e-05, 3.55398387e-01, 6.44587755e-01])","b7affae2":"np.argmax([0.1, 0.3, 0.8])","633cc4b0":"np.argmax([0.91, 0.3, 0.18])","74d0decf":"np.argmax([0.91, 0.93, 0.18])","5e5d7ed6":"df.keys()","0ab00ee8":"new_data = {\n    'SepalLengthCm': [5.0],\n    'SepalWidthCm': [1.2], \n    'PetalLengthCm': [3.5],\n    'PetalWidthCm': [0.7]\n}\nnew_data","d9321926":"input_dict = {name: tf.convert_to_tensor([value]) for name, value in new_data.items()}\ninput_dict","e442b44e":"model.predict(input_dict)","355f9cec":"np.argmax(model.predict(input_dict))","3f17b6cf":"# convert data from DF into tensor data ","30a1a22c":"# Import TF and check version ","8483f1cf":"# compile model ","aab0afe6":"# Load data ","4681df2d":"# define the model ","c6f1c7f3":"# Encode Species Column","06e69ffa":"# Split data into train and val ","f6db3fa2":"# fit the model ","325e62b5":"# perpare input features "}}