{"cell_type":{"298fe6f4":"code","ccf8ae88":"code","9d4f119c":"code","2cc32843":"code","7cce0112":"code","3ebc9a0b":"code","d4484ed1":"code","3363f411":"code","b5e0ef68":"code","d7cf092e":"code","3a14bee1":"code","9ed5962f":"code","65ecce4b":"code","2326e6b6":"code","d69266c2":"code","814d42c9":"code","c48c5e82":"code","c588b7a3":"code","ad3a36a8":"code","7b4fa49b":"code","b302be0a":"code","48b5b624":"code","38648ff2":"code","447b0b5c":"code","51e6a199":"code","781dfd63":"code","21a2b925":"code","f4d2d2bf":"code","3beaa5b4":"code","f86e3d2a":"code","7945ad03":"code","4597780e":"code","7e920e73":"code","c0a08785":"code","7247e9a9":"code","493bc400":"code","9778e068":"code","d5d14c33":"code","9de29af1":"code","c2630507":"code","343dcd1e":"markdown","6a7bb943":"markdown","133029ad":"markdown","fa3f25e0":"markdown","b69cf396":"markdown","3264cd24":"markdown","c58f3d0f":"markdown","76aadd82":"markdown"},"source":{"298fe6f4":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns","ccf8ae88":"dataset= pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","9d4f119c":"dataset.tail(20)","2cc32843":"dataset.isnull().sum()","7cce0112":"dataset.describe()","3ebc9a0b":"plt.figure(figsize =(16,7))\nsns.heatmap(dataset.corr())","d4484ed1":"dataset['DEATH_EVENT'].value_counts()","3363f411":"plt.figure(figsize=( 12,5))\nsns.countplot(x = 'DEATH_EVENT' ,data =  dataset, )","b5e0ef68":"X= dataset.iloc[:,:-1].values\nY= dataset.iloc[:,-1].values","d7cf092e":"X.shape , Y.shape","3a14bee1":"X","9ed5962f":"Y","65ecce4b":"from sklearn.model_selection import train_test_split\nX_train , X_test , Y_train, Y_test = train_test_split(X, Y , test_size = 0.1, random_state = 42)","2326e6b6":"X_train.shape , X_test.shape , Y_train.shape , Y_test.shape","d69266c2":"from sklearn.preprocessing import MinMaxScaler \nsc = MinMaxScaler()\n# here we use MinMaxScaler instead of StandardScaler beacuse we have time column also , which won't be negative ","814d42c9":"X_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","c48c5e82":"X_train","c588b7a3":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 42)\nclassifier.fit(X_train , Y_train)","ad3a36a8":"Y_pred_L = classifier.predict(X_test)","7b4fa49b":"Y_pred_L","b302be0a":"from sklearn.metrics import confusion_matrix , accuracy_score\ncm = confusion_matrix(Y_pred_L , Y_test)\nsns.heatmap(cm)\naccuracy_score( Y_pred_L , Y_test)","48b5b624":"\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_KN = KNeighborsClassifier( n_neighbors=5 , metric='minkowski')\nclassifier_KN.fit(X_train , Y_train)\nY_pred_KN = classifier_KN.predict(X_test)","38648ff2":"cm = confusion_matrix(Y_pred_KN , Y_test)\nsns.heatmap(cm)\naccuracy_score( Y_pred_KN , Y_test)","447b0b5c":"from sklearn.svm import SVC \nclassifier_svc = SVC(kernel='linear' ,  random_state = 42)\nclassifier_svc.fit(X_train , Y_train)","51e6a199":"Y_pred_svc = classifier_svc.predict(X_test)\ncm = confusion_matrix(Y_pred_svc , Y_test)\nsns.heatmap(cm)\naccuracy_score( Y_pred_svc , Y_test)","781dfd63":"from xgboost import XGBClassifier\nclassifier_xgb = XGBClassifier()\nclassifier_xgb.fit(X_train , Y_train)","21a2b925":"Y_pred_xgb = classifier_xgb.predict(X_test)","f4d2d2bf":"cm = confusion_matrix(Y_pred_xgb , Y_test)\nsns.heatmap(cm)\naccuracy_score( Y_pred_xgb , Y_test)","3beaa5b4":"import tensorflow as tf","f86e3d2a":"ann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units = 6 , activation = 'relu'))","7945ad03":"ann.add(tf.keras.layers.Dense(units = 6 , activation = 'relu'))","4597780e":"ann.add(tf.keras.layers.Dense(units = 1 , activation = 'sigmoid'))","7e920e73":"ann.compile(optimizer = 'adam' ,loss = 'binary_crossentropy' ,metrics = ['accuracy'] )","c0a08785":"\nann.fit(X_train , Y_train , batch_size = 32  , epochs = 100 )","7247e9a9":"Y_pred = ann.predict(X_test)","493bc400":"Y_pred","9778e068":"Y_pred = np.where(Y_pred >0.5 , 1 , 0)","d5d14c33":"Y_pred","9de29af1":"Y_test","c2630507":"from sklearn.metrics import confusion_matrix , accuracy_score\ncm = confusion_matrix(Y_pred , Y_test)\nsns.heatmap(cm)\naccuracy_score(Y_test , Y_pred)","343dcd1e":"## Logistic regression ","6a7bb943":"## ANN","133029ad":"## Import Libraries","fa3f25e0":"## Import dataset","b69cf396":"## Splitting of Dataset into train_set and test_set","3264cd24":"## SVM (Support vector Machine )","c58f3d0f":"## KNeighbors Classifier","76aadd82":"## XG_Boost Classifier"}}