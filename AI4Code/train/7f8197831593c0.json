{"cell_type":{"3ed6e736":"code","653fa109":"code","3c979ae3":"code","156e45dc":"code","9cf36cdb":"code","e003a01b":"code","3d888d56":"code","f0a3cf04":"code","fe6a7bee":"code","7838d9d2":"code","7e4f540c":"code","04ea4db8":"code","b17316ba":"code","bae0c652":"code","374740ef":"code","2c84ca22":"markdown","9eeff529":"markdown","321ffca9":"markdown","ca11652d":"markdown","4c3a1851":"markdown","b5349ce6":"markdown","da311d92":"markdown","01960fa4":"markdown","e72a282a":"markdown","ed15ca8c":"markdown","b27607e4":"markdown","9b1e561e":"markdown","970a2680":"markdown","112e5f62":"markdown","9bc273c9":"markdown","38c2634c":"markdown","8c198861":"markdown","d5d5db85":"markdown","565c84de":"markdown","53548326":"markdown","138f88cb":"markdown","86c885bd":"markdown","3e275253":"markdown"},"source":{"3ed6e736":"# Load all csv datas using pandas\nimport os\nimport pandas as pd\n\nWORKING_DIR = \"\/kaggle\/input\/microsoft-azure-predictive-maintenance\/\"\n\ndf_tele = pd.read_csv(WORKING_DIR + 'PdM_telemetry.csv')\ndf_fail = pd.read_csv(WORKING_DIR + 'PdM_failures.csv')\ndf_err = pd.read_csv(WORKING_DIR + 'PdM_errors.csv')\ndf_maint = pd.read_csv(WORKING_DIR + 'PdM_maint.csv')","653fa109":"# print the top 5 rows from the failure dataframe\ndf_fail.head(n=5)","3c979ae3":"df_sel = df_tele.loc[df_tele['machineID'] == 11].reset_index(drop=True)\ndf_sel.head(n=5)","156e45dc":"# Check failure record of machine 11\nsel_fail = df_fail.loc[df_fail['machineID'] == 11]\npd.DataFrame(sel_fail)","9cf36cdb":"# Check error record of machine 11\nsel_err = df_err.loc[df_err['machineID'] == 11]\npd.DataFrame(sel_err).head()","e003a01b":"import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nfig, ax = plt.subplots()\n\n# For a simpler plot, we will use two different values in the y-axis to differentiate between error and failure\ny_category = list()\n\nfor iter in range(0, len(sel_fail)):\n  y_category.append('Failure')\n\nfor iter in range(0, len(sel_err)):\n  y_category.append('Error')\n\n# Get timestamp from error and selected failure\ndf_timestamp = pd.concat([sel_fail['datetime'], sel_err['datetime']], ignore_index=True, axis=0)\ndf_plot = pd.DataFrame({\"timestamp\": df_timestamp, \"category\": y_category})\ndf_plot.loc[:, 'timestamp'] = pd.to_datetime(df_plot.loc[:, 'timestamp'])\ndf_plot.sort_values(by=['timestamp'], inplace=True, ignore_index=True)\n\n\n# Plot the data with timestamp as x-axis\nax.scatter('timestamp', 'category', data = df_plot)\nyearfmt = mdates.DateFormatter('%Y-%m-%d')\nax.xaxis.set_major_formatter(yearfmt)\nax.tick_params(axis='x', rotation=45)\nax.grid()","3d888d56":"# Change datatype of the timestamp column from object to datetime\ndf_sel.loc[:, 'datetime'] = pd.to_datetime(df_sel.loc[:, 'datetime'])\n\n# Select the date to check from failure records\nst = df_sel.loc[df_sel['datetime'] == \"2015-02-19\"].index.values[0]\n\n# Then, filter the telemetry data by the date and allow 7 days before and after\n# the error occurs to observe any abnormalities.\nselect = df_sel.loc[st-7*24:st + 7*24,:]\n\n# Plot volt and rotation feature\nfig, ax = plt.subplots(nrows=2, sharex=True)\nax[0].plot('datetime', 'volt', data=select)\nax[0].set_ylabel(\"Volt\")\n\nax[1].plot('datetime', 'rotate', data=select)\nax[1].tick_params(axis='x', rotation=45)\nax[1].set_xlabel(\"Timestamp\")\nax[1].set_ylabel(\"Rotation\")","f0a3cf04":"# Plot pressure and vibration feature\nfig, ax = plt.subplots(nrows=2, sharex=True)\nax[0].plot('datetime', 'pressure', data=select)\nax[0].set_ylabel(\"Pressure\")\n\nax[1].plot('datetime', 'vibration', data=select)\nax[1].tick_params(axis='x', rotation=45)\nax[1].set_xlabel(\"Timestamp\")\nax[1].set_ylabel(\"Vibration\")","fe6a7bee":"# Import plotting function\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# Autocorrelation plot\nplot_acf(df_sel['pressure'], lags = 40)\nplt.show()","7838d9d2":"# Partial autocorrelation plot\nplot_pacf(df_sel['pressure'], lags = 40)\nplt.show()","7e4f540c":"import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# Select the date to check from failure records\nst_train = df_sel.loc[df_sel['datetime'] == \"2015-02-19\"].index.values[0]\n\n# Then, filter the data to include approximately one month window\nstart_period = st_train - 14*24\nend_period = st_train + 14*24\n\ndef create_feature(start, end):\n  # create features from the selected machine\n  pressure = df_sel.loc[start: end, 'pressure']\n  timestamp = pd.to_datetime(df_sel.loc[start: end, 'datetime'])\n  timestamp_hour = timestamp.map(lambda x: x.hour)\n  timestamp_dow = timestamp.map(lambda x: x.dayofweek)\n\n  # apply one-hot encode for timestamp data\n  timestamp_hour_onehot = pd.get_dummies(timestamp_hour).to_numpy()\n\n  # apply min-max scaler to numerical data\n  scaler = MinMaxScaler()\n  pressure = scaler.fit_transform(np.array(pressure).reshape(-1,1))\n\n  # combine features into one\n  feature = np.concatenate([pressure, timestamp_hour_onehot], axis=1)\n\n  X = feature[:-1]\n  y = np.array(feature[5:,0]).reshape(-1,1)\n\n  return X, y, scaler\n\nX, y, pres_scaler = create_feature(start_period, end_period)","04ea4db8":"def shape_sequence(arr, step, start):\n    out = list()\n    for i in range(start, arr.shape[0]):\n        low_lim = i\n        up_lim = low_lim + step\n        out.append(arr[low_lim: up_lim])\n\n        if up_lim == arr.shape[0]:\n          # print(i)\n          break\n\n    out_seq = np.array(out)\n    return out_seq\n\n# Shape the sequence according to the length specified\nX_seq = shape_sequence(X, 5, 0)\ny_seq = shape_sequence(y, 1, 0)\n\n# Separate the input and output for train and validation\nX_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n\nprint(\"Training data shape = \", X_train.shape)\nprint(\"Validation data shape = \", X_val.shape)","b17316ba":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow.keras.losses as loss\n\n\ndef create_model(X_train, y_train):\n  shape = X_train.shape[1]\n  feat_length = X_train.shape[2]\n\n  model = Sequential()\n  model.add(LSTM(shape, activation='tanh', input_shape=(shape, feat_length), return_sequences=True))\n  model.add(LSTM(shape, activation='tanh', input_shape=(shape, feat_length), return_sequences=False))\n  model.add(Dense(shape, activation='relu'))\n  model.add(Dense(1, activation='linear'))\n  model.compile(optimizer=Adam(lr=0.035),\n                loss=loss.mean_squared_error)\n  model.fit(X_train, y_train, verbose=1, epochs=500)\n\n  return model\n\nmodel = create_model(X_train, y_train)","bae0c652":"# Predict validation data using the trained model\ny_pred = model.predict(X_val)\nmse = MeanSquaredError()\nval_err = mse(y_val.reshape(-1,1), y_pred)\nprint(\"Validation error = \", val_err.numpy())\n# Return the value using inverse transform to allow better observation\nplt.plot(pres_scaler.inverse_transform(y_val.reshape(-1,1)), 'k', label='Original')\nplt.plot(pres_scaler.inverse_transform(y_pred.reshape(-1,1)), 'r', label='Prediction')\nplt.ylabel(\"Pressure\")\nplt.xlabel(\"Datapoint\")\nplt.title(\"Validation data prediction\")\nplt.legend()\nplt.show()","374740ef":"# Select the date where another failure occurred\nst_test = df_sel.loc[df_sel['datetime'] == \"2015-04-20\"].index.values[0]\n\n# Then, filter the data to include approximately two-weeks window\nstart_period_test = st_test - 7*24\nend_period_test = st_test + 7*24\nX_test, y_test, test_scaler = create_feature(start_period_test, end_period_test)\n\n# Shape the sequence \nX_test_seq = shape_sequence(X_test, 5, 0)\ny_test_seq = shape_sequence(y_test, 1, 0)\n\n# Predict the testing data\ny_pred_test = model.predict(X_test_seq)\ntest_err = mse(y_test_seq.reshape(-1,1), y_pred_test)\nprint(\"Testing error = \", test_err.numpy())\n\n# Select first 200 datapoints to allow for better plotting\n# Return the value using inverse transform to allow better observation\nplt.plot(test_scaler.inverse_transform(y_pred_test[:200].reshape(-1, 1)), 'r', label='Prediction')\nplt.plot(test_scaler.inverse_transform(y_test_seq[:200].reshape(-1, 1)), 'k', label='Original')\nplt.ylabel(\"Pressure\")\nplt.xlabel(\"Datapoints\")\nplt.legend()\nplt.show()","2c84ca22":"## Create prediction model","9eeff529":"We observe that the model can predict the sensor reading even in the event of machine failure. The key here is to make sure that the training data that we use to train include past failure event as well.","321ffca9":"# Further Steps\nNow that we know how to construct a time-series forecasting model to predict anomalies, there are several possible steps on how to develop a complete predictive maintenance solution:\n* Develop machine learning \/ deep learning model to predict the chance of machine breakdown by feeding it prediction results from our developed time-series forecasting model.\n* Look into signal processing algorithm to smoothen the signal before feeding it to time-series forecasting model, which could improve model's performance.\n* Use bigger subset of data in training process and check how does the model change, better or worse? \n* Do hyperparameter optimization to further optimize the performance of time-series forecasting model. ","ca11652d":"For simplicity purpose, we will select a single machine that we are going to use for analysis. In this notebook, we will select machine number 11.","4c3a1851":"## Check autocorrelation and partial autocorrelation\nIn time-series data, it is beneficial to check the autocorrelation and partial autocorrelation function of the data that will influence our model selection and parameter selection.","b5349ce6":"From the partial autocorrelation plot, the correlation between values of two different points in time is also quite weak, decaying to zero starting in the 15th lags. This information will be used in determining the lag in the model.","da311d92":"## Feature check\nHere, we will select the time window from the failure record, then plot each feature and check their response in the event of failures.","01960fa4":"Between pressure and vibration, abnormality around the period of 2015-02-19 is more noticeable. Thus, in the next step, we will use <font color='red'>**pressure**<\/font> as feature and predictor. ","e72a282a":"From the explanation regarding the difference between failure and error in Kaggle, it is described that error refers to non-breaking events while failure refers to events that cause the machine to fail. Then, we will see in chronological plot how does the two events relate to each other.","ed15ca8c":"# Model Selection","b27607e4":"## Check validation result\nWe will check the model's performance with validation data.","9b1e561e":"# Conclusion\nIn this notebook, we have looked into an example predictive maintenance data from Kaggle, do some prior analysis on it, and construct a time-series forecasting model that will predict sensor reading values in the future. Hopefully, this notebook could provide some insights regarding how to implement time-series forecasting with deep learning in predictive maintenance.","970a2680":"Create a simple 2-layer LSTM model with input shape matching the shape of the data sequence provided.","112e5f62":"For our experiment, we will use training data of 1 month containing 2015-02-19 period where failure happened to predict another failure which occurs at 2015-04-20 according to the failure record. The feature used will be the pressure reading and timestamp (one-hot encoded).","9bc273c9":"As we observe volt and rotation readings, no noticeable anomalies are shown around the period of 2015-02-19. Then, next we will check both pressure and vibration features by plotting them.","38c2634c":"# Time-Series Forecasting with Deep Learning for Predictive Maintenance\n\nThis notebook is the Kaggle notebook version of the notebook I uploaded in [my Github](https:\/\/github.com\/jegun19\/predictive_maintenance)","8c198861":"## Check test result\n\nFrom the plot, we can see that some of the data points are inaccurate, which can be caused by the highly fluctuating nature of the hourly data points. Next, we will see whether the model can predict the sensor reading correctly in the event of anomalies. We are going to pick another date where failure occurred (2015-04-20).","d5d5db85":"Then, we will look into the error and failure record and then filter it only to show records belonging to machine number 11.","565c84de":"From the plot above, we can see that failures are oftentimes preceded by error in the machine. However, not all error result in immediate failures. Some time may passes before the failure in machine occurs. Thus, in the next step, we are going to focus on the failure data and check which feature is affected by machine's failure.","53548326":"## Select one machine\nIn this step, we will take a look at the overall characteristic of the data, and then select one machine that we want to analyze and use for doing the predictive maintenance task.","138f88cb":"## Prepare data input and output\nIn this notebook, we will use LSTM model, one of the famous prediction model in time-series forecasting task. To use it, first we need to provide input and output data in the correct format.","86c885bd":"Then, we need to shape the input further into a sequence (3-dimensional numpy array). We will use a function to return input and output sequence where each input sequence consists of 5-points observation. Simply put, observations of the <font color='red'>**past five hours**<\/font>  will be used to predict the sensor reading for the next <font color='red'>**one hour**<\/font> .","3e275253":"From the autocorrelation plot, we can see that the data is positively correlated up to lags of 40, where the autocorrelation value itself is quite low, indicating that the data does not have a strong autocorrelation properties. "}}