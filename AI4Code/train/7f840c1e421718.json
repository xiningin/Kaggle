{"cell_type":{"f8e54b25":"code","277284c3":"code","bf648be8":"code","b86b36a8":"code","a6cf2cac":"code","e7eb91ad":"code","13ab62bd":"code","2237f5bc":"code","6e501e72":"code","e7c4058f":"code","364552df":"code","369b0aba":"code","30f6baf9":"code","58d85a02":"code","dc0021fb":"markdown","f6d22239":"markdown","93d5c7d2":"markdown","8bda5914":"markdown","f64f9f97":"markdown","7c646a5f":"markdown","1212d6ff":"markdown","d720a4a4":"markdown","aabe96c8":"markdown","47c4c502":"markdown","e3810862":"markdown"},"source":{"f8e54b25":"# Import python packages\nimport os\nfrom os import walk\nimport shutil\nfrom shutil import copytree, ignore_patterns\nfrom PIL import Image\nfrom wand.image import Image as Img\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\n%matplotlib inline","277284c3":"pdf = '..\/input\/cityofla\/CityofLA\/Additional data\/PDFs\/2014\/April 2014\/040414\/PORT POLICE SERGEANT 3222.pdf'\nImg(filename=pdf, resolution=200)","bf648be8":"pdf = '..\/input\/cityofla\/CityofLA\/Additional data\/PDFs\/2018\/December\/Dec 14\/CABLE TELEVISION PRODUCTION MANAGER 1801 121418.pdf'\nImg(filename=pdf, resolution=200)","b86b36a8":"sample_output_df = pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/sample job class export template.csv\")\nsample_output_df.head(3)","a6cf2cac":"data_dict_df = pd.read_csv(\"..\/input\/cityofla\/CityofLA\/Additional data\/kaggle_data_dictionary.csv\")\ndata_dict_df.head()","e7eb91ad":"job_bulletins_path = \"..\/input\/cityofla\/CityofLA\/Job Bulletins\/\"\nprint(\"Number of Job bulletins : \",len(os.listdir(job_bulletins_path)))","13ab62bd":"with open(job_bulletins_path + os.listdir(job_bulletins_path)[0]) as f: \n    print (f.read(1000))","2237f5bc":"jobs_list = []\nfor file_name in os.listdir(job_bulletins_path):\n    with open(job_bulletins_path + file_name, encoding = \"ISO-8859-1\") as f:\n        content = f.read()\n        jobs_list.append([file_name, content])\njobs_df = pd.DataFrame(jobs_list)\njobs_df.columns = [\"FileName\", \"Content\"]\njobs_df.head()","6e501e72":"def extract_title(text):\n    text = text.replace(\"CAMPUS INTERVIEWS ONLY\", \"\")\n    return text.strip().split(\"\\n\")[0].split(\"\\t\")[0]\n\njobs_df[\"JobClassTitle\"] = jobs_df[\"Content\"].apply(lambda x: extract_title(x))\njobs_df.head()","e7c4058f":"cnt_srs = jobs_df['JobClassTitle'].value_counts()[:8]\n#cnt_srs = cnt_srs.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\nplt.xticks(rotation='vertical')\nplt.xlabel('Job Title', fontsize=12)\nplt.ylabel('Number of occurrences', fontsize=12)\nplt.title(\"Job Class Title\")\nplt.show()","364552df":"def extract_class_code(text):\n    class_code = None\n    for line in text.strip().split(\"\\n\"):\n        if \"Class Code:\" in line:\n            class_code = line.replace(\"Class Code:\",\"\").strip().split(\"\\t\")[0]\n        elif \"Class  Code:\" in line:\n            class_code = line.replace(\"Class  Code:\",\"\").strip().split(\"\\t\")[0]\n    #if class_code is None:\n    #    print(text.strip().split(\"\\n\"))\n    #    raise\n    return class_code\n        \n\njobs_df[\"JobClassCode\"] = jobs_df[\"Content\"].apply(lambda x: extract_class_code(x))\njobs_df.head()","369b0aba":"def extract_open_date(text):\n    open_date = None\n    for line in text.strip().split(\"\\n\"):\n        if \"Open Date:\" in line:\n            open_date = line.replace(\"Open Date:\",\"\").strip().split(\"\\t\")[0]\n        elif \"Open date:\" in line:\n            open_date = line.replace(\"Open date:\",\"\").strip().split(\"\\t\")[0]\n#     if open_date is None:\n#         print(text.strip().split(\"\\n\"))\n#         raise\n    return open_date\n        \n\njobs_df[\"JobOpenDate\"] = jobs_df[\"Content\"].apply(lambda x: extract_open_date(x))\njobs_df.head()","30f6baf9":"def extract_annual_salary(text):\n    extracted_text = \"\"\n    start = 0\n    for line in text.strip().split(\"\\n\"):\n        if \"ANNUAL SALARY\" in line or \"ANNUALSALARY\" in line:\n            start = 1\n        elif start and line.isupper():\n            start = 0\n        if start:\n            extracted_text += line + \"\\n\"\n    extracted_text = extracted_text.replace(\"ANNUAL SALARY\",\"\").replace(\"ANNUALSALARY\",\"\").strip().split(\"\\n\")[0]\n    \n    ### Multiple salaries are available per job so extract all of them and save in a liot\n    salary_list = []\n    salary_split = extracted_text.split()\n    for i, v in enumerate(salary_split):\n        if v.lower() == \"to\":\n            salary = salary_split[i-1] + \" to \" + salary_split[i+1]\n            salary_list.append(salary)\n    if len(salary_list) == 0:\n        salary = extracted_text.split(\"and\")\n        salary_list.extend(salary)\n    return salary_list\n            \njobs_df[\"JobAnnualSalary\"] = jobs_df[\"Content\"].apply(lambda x: extract_annual_salary(x))\njobs_df.head(7)","58d85a02":"def clean_salary(salary):\n    ### Remove commas and $ \n    return salary.replace(\"$\",\"\").replace(\",\", \"\").replace(\";\",\"\").replace(\";\",\"\").strip()\n\ndef get_nth_salary(salary_list, n):\n    try:\n        salary = salary_list[n]\n    except:\n        salary = None\n    if salary is not None:\n        salary = clean_salary(salary)\n    return salary\n    \njobs_df[\"JobAnnualSalary_1\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 0))\njobs_df[\"JobAnnualSalary_2\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 1))\njobs_df[\"JobAnnualSalary_3\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 2))\njobs_df[\"JobAnnualSalary_4\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 3))\njobs_df[\"JobAnnualSalary_5\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 4))\njobs_df[\"JobAnnualSalary_6\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 5))\njobs_df[\"JobAnnualSalary_7\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 6))\njobs_df[\"JobAnnualSalary_8\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 7))\njobs_df[\"JobAnnualSalary_9\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 8))\njobs_df[\"JobAnnualSalary_10\"] = jobs_df[\"JobAnnualSalary\"].apply(lambda x: get_nth_salary(x, 9))\njobs_df.head(7)","dc0021fb":"Looks like the job postings have a generic format which they adhere to like \n\n1. Job Title at the first line\n2. Job code in the next line\n3. Job open date in the next line \n4. Annual Salary in the next part\n5. Duties in the next part\n6. Requirements \/ Qualifications in the next part\n7. Where to apply information\n8. Application deadline information\n\nSo the aim of the contest (as well as this notebook) is to parse the application and to get some structured information out of these files. Also we will do some analysis to understand the content of the job postings.\n\nWe have also got a sample template on how the parsed file will look like. Let us have a look at it. ","f6d22239":"We are also given the job descriptions in plain text files. Let us get the total number of files and have a look at top few lines of one of the files.","93d5c7d2":"We need to extract the contents and make it structureds like the above one. We also need to create a data dictionary like the below one for the created fields.","8bda5914":"#### Annual Salary\n\nNow let us extract the annual salary from job bulletin","f64f9f97":"## Introduction\n\nThanks to Paul Mooney's [Kernel](https:\/\/www.kaggle.com\/paultimothymooney\/explore-job-postings), let us first start by looking at some of the job postings to get an idea of how they look like.","7c646a5f":"#### Open date\n\nNow let us extract the open date of the job ","1212d6ff":"Only 5 job titles occur twice. Rest all occur only once. \n\n#### Job Class Code\n\nIn this section let us extract the job class code from the bulletins. We can see from the example files at the top that they occur next to job title and starts with \"Class Code:\". So let us extract the line having these words and then use them to extract job class code.","d720a4a4":"#### Job Class Title\n\nWe can see that the first line of the file represents the job title. So let us start with extracting them.\n\nTo extract the job title, we are going to split by new line character and then get the first line. There are three instances where first line is \"Campus interviews only\" and so we need to take the second line for those documents.","aabe96c8":"## Data Extraction\n\nIn this section, let us extract the data and create a structured table out of it.\n","47c4c502":"### More to come. Stay tuned! ","e3810862":"## Problem Objective:\n\n#### Help the City of Los Angeles to structure and analyze its job descriptions\n\n![City of LA](https:\/\/www.lacity.org\/sites\/g\/files\/wph1196\/f\/styles\/large_hero_1920_x_700\/public\/bigstock-Human-Resources-Interview-Recr-116624942.jpg?itok=WoA_6y_C)\n\nThe City of Los Angeles faces a big hiring challenge: 1\/3 of its 50,000 workers are eligible to retire by July of 2020. The city has partnered with Kaggle to create a competition to improve the job bulletins that will fill all those open positions.\n\nThe content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor\u2019s Office wants to reimagine the city\u2019s job bulletins by using text analysis to identify needed improvements.\n\nThe goal is to convert a folder full of plain-text job postings into a structured CSV file and then to use this data to: \n\n(1) identify language that can negatively bias the pool of applicants; \n\n(2) improve the diversity and quality of the applicant pool; and\/or \n\n(3) make it easier to determine which promotions are available to employees in each job class."}}