{"cell_type":{"a7a09e24":"code","e295020b":"code","32b69ab5":"code","b233d626":"code","bc8fc139":"code","fe87cc0b":"code","77bf714b":"code","32e34d42":"code","3c1e0cad":"code","da287609":"code","2745839b":"code","e7844245":"code","f9080240":"code","f1f6a1b9":"code","2591c1cd":"code","35f7a123":"code","06c8f8e8":"code","eb87f1c6":"code","57f7a278":"code","1d9ab5c7":"code","38366444":"code","13fa2806":"code","ff826d83":"code","278ec212":"code","b74752fa":"code","a16a2286":"code","681ef0af":"code","338a03ab":"code","3d15bc01":"code","c04f1491":"code","b341a5d8":"markdown","a1d00616":"markdown","671013a2":"markdown","882c64da":"markdown","845be865":"markdown","3b07ee3f":"markdown","215eb575":"markdown","c4f20ebe":"markdown","745a7899":"markdown","d8754179":"markdown","7f93b364":"markdown","13bf1714":"markdown","107e4657":"markdown"},"source":{"a7a09e24":"!pip install -U git+https:\/\/github.com\/paoloripamonti\/face-recognition.git","e295020b":"from face_recognition import FaceRecognition\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, precision_recall_curve, roc_auc_score, accuracy_score\n\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport pandas as pd\nimport random\nimport numpy as np\nimport cv2\nimport base64\nfrom tqdm import tqdm\nimport requests\nfrom pprint import pprint","32b69ab5":"ROOT_Train =\"\/kaggle\/input\/masked-unmasked-mixed\/mixed\/train\"\nROOT_Test = \"\/kaggle\/input\/masked-unmasked-mixed\/mixed\/test\"","b233d626":"train = []\nfor path in glob.iglob(os.path.join(ROOT_Train, \"**\", \"*.jpg\")):\n    person = path.split(\"\/\")[-2]\n    train.append({\"person\":person, \"path\": path})\n  \ntrain = pd.DataFrame(train)\ntrain = train.groupby(\"person\").filter(lambda x: len(x) > 0)\ntrain.head(10)","bc8fc139":"train.groupby(\"person\").count()[:50].plot(kind='bar', figsize=(20,5))","fe87cc0b":"print(\"number of person in train dataset : %s\" %(len(train.groupby(\"person\"))))\nprint(\"number of image in train dataset : %s\" %(len(train)))","77bf714b":"trainx, valid = train_test_split(train, test_size=0.1, random_state=42, shuffle=True)","32e34d42":"print(\"number of person in train dataset : %s\" %(len(trainx.groupby(\"person\"))))\nprint(\"number of image in train dataset : %s\" %(len(trainx)))\nprint(\"number of person in validation dataset : %s\" %(len(valid.groupby(\"person\"))))\nprint(\"number of image in validation dataset: %s\" %(len(valid)))","3c1e0cad":"plt.figure(figsize=(20,10))\nfor i in range(10):\n    idx = random.randint(0, len(train))\n    img = plt.imread(train.path.iloc[idx])\n    plt.subplot(4, 5, i+1)\n    plt.imshow(img)\n    plt.title(train.person.iloc[idx])\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()\nplt.show()","da287609":"test = []\nfor path in glob.iglob(os.path.join(ROOT_Test, \"**\", \"*.jpg\")):\n    person = path.split(\"\/\")[-2]\n    test.append({\"person\":person, \"path\": path})\ntest = pd.DataFrame(test)\ntest = test.groupby(\"person\").filter(lambda x: len(x) > 0)\ntest.head(10)","2745839b":"print(\"number of person in test dataset : %s\" %(len(test.groupby(\"person\"))))\nprint(\"number of image in test dataset : %s\" %(len(test)))","e7844245":"test.groupby(\"person\").count()[:50].plot(kind='bar', figsize=(20,5))","f9080240":"plt.figure(figsize=(20,10))\nfor i in range(10):\n    idx = random.randint(0, len(test))\n    img = plt.imread(test.path.iloc[idx])\n    plt.subplot(4, 5, i+1)\n    plt.imshow(img)\n    plt.title(test.person.iloc[idx])\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()\nplt.show()","f1f6a1b9":"print(\"Train:\",len(trainx))\nprint(\"Test:\",len(test))","2591c1cd":"%%time\nfr = FaceRecognition()","35f7a123":"%%time\nfr.fit_from_dataframe(trainx) ","06c8f8e8":"fr.save('masked_unmasked_model.pkl')","eb87f1c6":"%%time\nvalid_test, valid_pred, valid_scores = [],[],[]\nfor idx in tqdm(range(len(valid))):\n    path = valid.path.iloc[idx]\n    result = fr.predict(path)\n    for prediction in result[\"predictions\"]:\n        valid_pred.append(prediction[\"person\"])\n        valid_scores.append(prediction[\"confidence\"])\n        valid_test.append(valid.person.iloc[idx])","57f7a278":"%%time\ny_test, y_pred, y_scores = [],[],[]\nfor idx in tqdm(range(len(test))):\n    path = test.path.iloc[idx]\n    result = fr.predict(path)\n    for prediction in result[\"predictions\"]:\n        y_pred.append(prediction[\"person\"])\n        y_scores.append(prediction[\"confidence\"])\n        y_test.append(test.person.iloc[idx])","1d9ab5c7":"print(classification_report(y_test, y_pred))","38366444":"print(\"Train Accuracy: %f\" % accuracy_score(valid_test, valid_pred))","13fa2806":"print(\"Test Accuracy: %f\" % accuracy_score(y_test, y_pred))","ff826d83":"person = y_test[2]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nprint(result[\"predictions\"][0][\"confidence\"])\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","278ec212":"person = y_test[3]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","b74752fa":"person = y_test[4]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","a16a2286":"person = y_test[6]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","681ef0af":"person = y_test[7]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","338a03ab":"person = y_test[9]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","3d15bc01":"person = y_test[0]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","c04f1491":"person = y_test[20]\npath = test[test.person==person][\"path\"].iloc[0]\nimg = cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresult = fr.predict(path)\nfile_bytes = np.fromstring(base64.b64decode(result[\"frame\"]), np.uint8)\noutput = cv2.imdecode(file_bytes,1)\n\nplt.figure(figsize=(10,5))\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(person)\nplt.subplot(1, 2, 2)\nplt.imshow(output)\nplt.title(\"%s (%f)\" % (result[\"predictions\"][0][\"person\"], result[\"predictions\"][0][\"confidence\"]))\nplt.tight_layout()\nplt.show()","b341a5d8":"## Training Model","a1d00616":"# Save Model","671013a2":"## Train Dataset","882c64da":"# Evaluate","845be865":"### Size of train & test dataset","3b07ee3f":"## Test Dataset","215eb575":"# Fit Face Recognition","c4f20ebe":"# Needed Libraries","745a7899":"## Initialize Model","d8754179":"# Read dataset","7f93b364":"### Settings","13bf1714":"# Face Recognition\n\nSee: https:\/\/github.com\/paoloripamonti\/face-recognition.git","107e4657":"# Examples"}}