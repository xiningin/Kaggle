{"cell_type":{"8f0ffdfb":"code","7c9a530d":"code","95fdb079":"code","b294e34d":"code","111de3b6":"code","a4c2b365":"code","b5b57a8f":"code","bed49104":"code","60934b38":"code","8afd71db":"code","49fc5b1f":"code","d152972b":"code","5a4cdab3":"code","2aa2164b":"code","c56f9bf5":"code","be3b1893":"code","ee0b11a0":"code","3169be28":"code","c5a48867":"code","22fe9432":"code","a6b92512":"code","cc11ade7":"code","9a9cbbab":"code","47970b46":"code","f5ea1c3a":"code","61a50709":"code","b64fdcc0":"code","068657a2":"code","6af5c887":"code","f9c826b8":"code","c89f5001":"code","24b1bc0d":"code","323671d5":"code","6c406822":"code","bd300a16":"code","0df914f3":"code","c2ff774b":"code","99739d80":"code","f810fd8c":"code","9b5c11ec":"code","481d0933":"code","dd1af2b4":"code","796db870":"code","efb5adf5":"code","4de7c227":"code","dbe0a052":"code","b7a955cc":"code","a3bcba75":"code","5e769288":"code","9b7c3f4d":"code","2d091680":"code","ddd2aac1":"code","60b07f63":"code","4a27d99d":"code","99aff06f":"code","f0cc1882":"code","e0cd415b":"code","76787614":"code","a3d1912e":"code","3ce4beab":"code","fc30baee":"code","29f7137c":"code","fece931e":"code","2993745a":"code","6987d424":"code","0afc5cbd":"code","2ea1b88a":"code","b5d9b28e":"code","177fa901":"code","0a550ac1":"code","d4a4ecaa":"code","7191d5ea":"code","b40b7de7":"code","cbd9ace2":"markdown","6f81f902":"markdown","73c75939":"markdown","e289601c":"markdown","2b682ef8":"markdown","ff266aa2":"markdown","6ffca203":"markdown","e601e927":"markdown","9582c255":"markdown","8156a0e4":"markdown","469c8a52":"markdown","bfc995e2":"markdown","b007938d":"markdown","e661a98a":"markdown"},"source":{"8f0ffdfb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c9a530d":"\n# # Python library to interact with the file system.\n# import os\n\n# #Visualization\n# import plotly.express as px\n\n# # Software library written for data manipulation and analysis.\n# import pandas as pd\n# from tqdm import tqdm as tq\n# tq.pandas()\n\n# # fastai library for computer vision tasks\n# # from fastai.vision.all import *\n# # from fastai.callback.wandb import *\n\n# # Developing and training neural network based deep learning models.\n# # import torch\n# # from torch import nn\n\n# # Python library for image augmentation\n# #import albumentations as A\n\n# # import wandb\n# # wandb.login()\n# #add Codeadd Markdown\n# # ls ..\/input\/g2net-gravitational-wave-detection\/\n# # add Codeadd Markdown\n# # path = Path('..\/kaggle\/input\/g2net-gravitational-wave-detection\/')\n# # add Codeadd Markdown\n# # train_df = pd.read_csv(path\/'training_labels.csv')\n# # train_df\n# # add Codeadd Markdown\n# # train_df['path'] = train_df.id.\n# # (lambda x: str(path)+'\/train\/'+'\/'.join([char for char in x[:3]])+'\/'+x+'.npy')","95fdb079":"# cd \/kaggle\/input\/g2net-gravitational-wave-detection\/","b294e34d":"# ls \/kaggle\/input\/g2net-gravitational-wave-detection\/","111de3b6":"# train_labels = pd.read_csv(\"training_labels.csv\")\n# train_labels.head()","a4c2b365":"# cd \/kaggle\/input\/g2net-gravitational-wave-detection\/train\/0\/0\/0\/","b5b57a8f":"\n# import os\n\n# path, dirs, files = next(os.walk(\"\/kaggle\/input\/g2net-gravitational-wave-detection\/train\/0\/0\/0\/\"))\n# file_count = len(files)\n# files","bed49104":"# x=np.load(\"0002cc5125.npy\")\n# x","60934b38":"# import numpy as np\n# #create a n\n# df = pd.DataFrame(columns=['wave name','value'])\n# #x=np.empty([3, 4096])\n# #x=np.load(str(files[0]))\n# #df[\"value\"].loc[0,1]=x\n# # df.loc[0, 'value']=x\n# # df.loc[0, 'wave name']=str(files[0]).split(\".\")[0]\n# #df[\"wave name\"].loc[0,0]=str(files[file])\n# for file in range(file_count):\n#     #x=np.append(x,np.load(str(file)),axis=0)\n#     x=np.load(str(files[file]))\n#     df.loc[file, 'value']=x\n#     df.loc[file, 'wave name']=str(files[file]).split(\".\")[0]\n\n# x.shape","8afd71db":"# df.head()\n#cd \/kaggle\/input\/g2net-gravitational-wave-detection\/\n","49fc5b1f":"# cd \/kaggle\/input\/g2net-gravitational-wave-detection\/","d152972b":"#I was trying to merge the 2 pds together\n# training_target=pd.read_csv(\"training_labels.csv\")\n\n# df[\"label\"]=training_target[\"target\"][df[\"wave name\"]==training_target[\"id\"]]\n# df.head()","5a4cdab3":"# df_final=pd.merge(df,training_target.rename(columns={'id':'wave name'}))\n# df_final       ","2aa2164b":"# df_final[\"value\"][df_final[\"wave name\"]==\"0003d34cd0\"]\n#df_final[\"value\"][df_final[\"wave name\"]==\"0003d34cd0\"].reset_index()","c56f9bf5":"\n# import matplotlib.pyplot as plt\n# plt.figure(figsize=(20,5))\n# plt.subplot(2,1,1)\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0002cc5125\"][0][0], c=\"firebrick\", label=\"detector 1\")\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0002cc5125\"][0][1], c=\"blue\", label=\"detector 1\")\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0002cc5125\"][0][2], c=\"green\", label=\"detector 1\")\n# plt.subplot(2,1,2)\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0003d34cd0\"][1][0], c=\"firebrick\", label=\"detector 1\")\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0003d34cd0\"][1][1], c=\"blue\", label=\"detector 1\")\n# plt.plot(df_final[\"value\"][df_final[\"wave name\"]==\"0003d34cd0\"][1][2], c=\"green\", label=\"detector 1\")","be3b1893":"# from scipy.fft import fft, fftfreq\n# # Number of sample points\n# N = 600\n# # sample spacing\n# T = 1.0 \/ 800.0\n# x = np.linspace(0.0, N*T, N, endpoint=False)\n# y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n# yf = fft(y)\n# xf = fftfreq(N, T)[:N\/\/2]\n# import matplotlib.pyplot as plt\n# plt.plot(xf, 2.0\/N * np.abs(yf[0:N\/\/2]))\n# plt.grid()\n# plt.show()","ee0b11a0":"from glob import glob\nimport pandas as pd\nfrom random import sample\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","3169be28":"\npaths = glob(\"..\/input\/g2net-gravitational-wave-detection\/train\/*\/*\/*\/*\")\n#paths","c5a48867":"paths.split(\"\/\")[-1].split(\".\")[0] \n","22fe9432":"# list of ids of .npy files \nids = [path.split(\"\/\")[-1].split(\".\")[0] for path in paths]\n\n# data frame containing paths and ids of .npy files \npath_df = pd.DataFrame({\"path\":paths,\"id\":ids})\npath_df\nlabels = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/training_labels.csv\")\n\n\ntrain_df = pd.merge(left=labels,right=path_df,on=\"id\")\ntrain_df.shape","a6b92512":"display(train_df.head())","cc11ade7":"train_df.head()","9a9cbbab":"target_1 = train_df[train_df.target==1]\ntarget_0 = train_df[train_df.target==0]\ntarget_waves = target_1.sample(50).path.values\n#target_waves","47970b46":"\nplt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    pos=np.load(target_waves[i-1])\n    plt.subplot(10,1,i)\n    plt.plot(pos[0], c=\"firebrick\")\n    plt.plot(pos[1], c=\"blue\")\n    plt.plot(pos[2], c=\"green\")\n    \npos.shape","f5ea1c3a":"non_target_waves=target_0.sample(50).path.values\n#non_target_waves\n","61a50709":"plt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    neg=np.load(non_target_waves[i-1])\n    plt.subplot(10,1,i)\n    plt.plot(neg[0], c=\"firebrick\")\n    plt.plot(neg[1], c=\"blue\")\n    plt.plot(neg[2], c=\"green\")","b64fdcc0":"plt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    neg=np.load(non_target_waves[i-1])\n    plt.subplot(10,1,i)\n    sns.kdeplot(neg[0], color=\"firebrick\")\n    sns.kdeplot(neg[1], color=\"blue\")\n    sns.kdeplot(neg[2], color=\"green\")","068657a2":"\nplt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    pos=np.load(target_waves[i-1])\n    plt.subplot(10,1,i)\n    sns.kdeplot(pos[0], color=\"firebrick\")\n    sns.kdeplot(pos[1], color=\"blue\")\n    sns.kdeplot(pos[2], color=\"green\")","6af5c887":"# plt.figure(figsize=(20,15))\n# #VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \n# for i in range(1,len(target_waves)+1):\n# #     pos =np.load(target_waves[i-1])[1]\n# #for obtain the detector 1 only values\n#     pos=np.load(target_waves[i-1])\n#     plt.subplot(10,1,i)\n#     sns.scatterplot(data=pos[0], color=\"firebrick\")\n#     sns.scatterplot(data=pos[1], color=\"blue\")\n#     sns.scatterplot(data=pos[2], color=\"green\")","f9c826b8":"# plt.figure(figsize=(20,15))\n# #VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \n# for i in range(1,len(target_waves)+1):\n# #     pos =np.load(target_waves[i-1])[1]\n# #for obtain the detector 1 only values\n#     neg=np.load(non_target_waves[i-1])\n#     plt.subplot(10,1,i)\n#     sns.scatterplot(data=neg[0], color=\"firebrick\")\n#     sns.scatterplot(data=neg[1], color=\"blue\")\n#     sns.scatterplot(data=neg[2], color=\"green\")","c89f5001":"plt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    neg=np.load(non_target_waves[i-1])\n    plt.subplot(50,1,i)\n    sns.boxplot(x=neg[0], color=\"firebrick\")\n    #sns.boxplot(x=neg[1], color=\"blue\")\n    #sns.boxplot(x=neg[2], color=\"green\")","24b1bc0d":"plt.figure(figsize=(20,15))\n#VISUALIZE 10 random samples form detectors 1 and they are gravitational wave \nfor i in range(1,len(target_waves)+1):\n#     pos =np.load(target_waves[i-1])[1]\n#for obtain the detector 1 only values\n    pos=np.load(target_waves[i-1])\n    plt.subplot(50,1,i)\n    sns.boxplot(x=pos[0], color=\"firebrick\")\n    #sns.boxplot(x=pos[1], color=\"blue\")\n    #sns.boxplot(x=pos[2], color=\"green\")","323671d5":"!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2","6c406822":"\nQ_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(id)\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        #print(image.squeeze().shape)\n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        #plt.plot(image.squeeze())\n        #sns.heatmap(image.squeeze())\n        #np.vstack(()) to make the 3 graphs stacked overeach other\n        #image.squeeze() remove the third dimension as the original tensor dimension is [1,69,129]\n        plt.title(signal_names[i], fontsize=14)\n        \n    \n    plt.show()","bd300a16":"non_target_waves[1]\ntrain_df.target[train_df[\"path\"]==non_target_waves[1]]","0df914f3":"# for i in range(1,len(target_waves)+1):\n#     #plt.subplot(plt.subplot(50,1,i))\n#     visualize_sample_qtransform(non_target_waves[i-1], train_df.target[train_df[\"path\"]==non_target_waves[i-1]])","c2ff774b":"# # for i in range(1,len(target_waves)+1):\n# #     #plt.subplot(plt.subplot(50,1,i))\n# #     visualize_sample_qtransform(target_waves[i-1], train_df.target[train_df[\"path\"]==target_waves[i-1]])\nvisualize_sample_qtransform(target_waves[1], train_df.target[train_df[\"path\"]==target_waves[1]])","99739d80":"import librosa\nimport librosa.display","f810fd8c":"def visualize_sample_mfcc(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(_id)\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        mfccs = librosa.feature.mfcc(x[i] \/ x[i].max(), sr=sr)\n        print(max(mfccs[1]))\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(mfccs, sr=sr, x_axis=\"time\", vmin=-200, vmax=60, cmap=\"coolwarm\")\n        plt.title(signal_names[i], fontsize=14)\n        plt.colorbar()\n\n \n\n    plt.show()","9b5c11ec":"from sklearn.decomposition import PCA\ndef mfcc_transformation(_id,sr=2048):\n    mfcc_coef=[]\n    x = np.load(_id)\n    for i in range(3):\n        mfccs = librosa.feature.mfcc(x[i] \/ x[i].max(), sr=sr)\n        pca = PCA(n_components=3)\n        principalComponents = pca.fit_transform(mfccs)\n        mfcc_coef.append(principalComponents)\n    return mfcc_coef","481d0933":" librosa.display.specshow(np.load(\"..\/input\/g2net-n-mels-128-train-images\/00000e74ad.npy\"))","dd1af2b4":"train_df\nlen(train_df)","796db870":"# import pandas as pd\n# from tqdm import tqdm\n\n# target_waves1 = train_df[0:50000].path.values\n# feature_dataset1=pd.DataFrame(columns = [\"feature_pca\"])\n# for i in tqdm(range(len(target_waves1))):\n#         feature_dataset1.loc[i, 'feature_pca']=mfcc_transformation(target_waves1[i])\n    \n","efb5adf5":"# feature_dataset1","4de7c227":"# feature_dataset1.to_csv('.\/part1.csv')","dbe0a052":"# target_waves2 = train_df[50000:100000].path.values\n# feature_dataset2=pd.DataFrame(columns = [\"feature_pca\"])\n# for i in tqdm(range(len(target_waves2))):\n#         feature_dataset2.loc[i, 'feature_pca']=mfcc_transformation(target_waves2[i])\n\n","b7a955cc":"# feature_dataset2.to_csv('.\/part2.csv')","a3bcba75":"# target_waves2 = train_df[50000:100000].path.values\n# feature_dataset2=pd.DataFrame(columns = [\"feature_pca\"])\n# for i in tqdm(range(len(target_waves2))):\n#         feature_dataset2.loc[i, 'feature_pca']=mfcc_transformation(target_waves2[i])\n\n","5e769288":"feature_dataset2","9b7c3f4d":"(mfcc_transformation(target_waves[2])[1]).tolist()","2d091680":"mfcc_transformation(target_waves[2])\n#plt.plot(mfcc_transformation(target_waves[2])[1])\nsns.scatterplot(data=(mfcc_transformation(target_waves[2])[1]).tolist()[3], color=\"firebrick\")","ddd2aac1":"visualize_sample_mfcc(target_waves[2], train_df.target[train_df[\"path\"]==target_waves[2]])","60b07f63":"from glob import glob\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nfrom random import sample\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","4a27d99d":"\npaths_train = glob(\"..\/input\/g2net-n-mels-128-train-images\/*\")\npaths_test=glob(\"..\/input\/g2net-n-mels-128-test-images\/*\")","99aff06f":"# list of ids of .npy files \nids_train = [path.split(\"\/\")[-1].split(\".\")[0] for path in paths_train]\n\n# data frame containing paths and ids of .npy files \npath_train_df = pd.DataFrame({\"path\":paths_train,\"id\":ids_train})\nlabel_train = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/training_labels.csv\")\ntrain_df = pd.merge(left=path_train_df,right=label_train,on=\"id\")\n","f0cc1882":"train_df","e0cd415b":"# list of ids of .npy files \nids_test = [path.split(\"\/\")[-1].split(\".\")[0] for path in paths_test]\n\n# data frame containing paths and ids of .npy files \npath_test_df = pd.DataFrame({\"path\":paths_test,\"id\":ids_test})\nlabel_test = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\ntest_df = pd.merge(left=path_test_df,right=label_test,on=\"id\")\n","76787614":"import pandas as pd\nfrom tqdm import tqdm\n","a3d1912e":"NUM_BATCHES = 1\nBATCH_SIZE = train_df.shape[0]\/NUM_BATCHES","3ce4beab":"def batch_transform(data_df, is_train=True):\n    waves_data = []\n    for path in tqdm(data_df.path, total=data_df.shape[0]):\n        wave=np.load(path) \n        waves_data.append(wave)\n    X = np.array(waves_data)\n    nsamples, nx, ny = X.shape\n    d2_X=X.reshape((nsamples,nx*ny))\n    if is_train:        \n        y= data_df['target'].values\n        #     y = to_categorical(y) ## If using a softmax layer for prediction\n        return d2_X,y\n    else:\n        return d2_X\n","fc30baee":"data_df=train_df[0:10]\nx,u=batch_transform(data_df)\nnsamples, nx, ny = x.shape\nprint(nsamples)\nprint(nx)\nprint(ny)\nd2_train_dataset = x.reshape((nsamples,nx*ny))\nclf.fit(d2_train_dataset, u)\nd2_train_dataset.shape","29f7137c":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nRF_CL = RandomForestClassifier(max_depth=20, random_state=0)\nADA_CL = AdaBoostClassifier()","fece931e":"offset = 0\nfor i in range(1,NUM_BATCHES+1): ## Get Next batch\n    limit= i*BATCH_SIZE\n    print(f'BATCH_NO: {i}   ----  From: {offset} ===> To: {limit}')\n    X,y = batch_transform(train_df[int(offset):int(limit)]) # Transform the data\n    RF_CL.fit(X, y) # Training the model\n    print(\"done batch\")\n    offset = limit","2993745a":"# data_df=train_df[0:10]\n# x,u=batch_transform(data_df)\n# data_df","6987d424":"NUM_BATCHES = 1\nBATCH_SIZE = test_df.shape[0]\/NUM_BATCHES\nprint(\"BATCH SIZE = \"+ str(BATCH_SIZE))\n\noffset = 0\nall_test_preds = []\nfor i in range(1,NUM_BATCHES+1): ## Get Next batch\n    limit= i*BATCH_SIZE\n    print(f'BATCH_NO: {i}   ----  From: {offset} ===> To: {limit}')\n    X = batch_transform(test_df[int(offset):int(limit)], is_train=False) # Transform the data\n    preds = RF_CL.predict(X)  # Predicting the test set\n    all_test_preds.append(preds.flatten())\n    offset = limit","0afc5cbd":"sample_submission = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\nall_preds= np.array([list(pred) for pred in all_test_preds])","2ea1b88a":"sample_submission['target']= all_preds.flatten()","b5d9b28e":"sample_submission.to_csv('my_submission.csv', index=False)","177fa901":"sample_submission","0a550ac1":"NUM_BATCHES = 100\nBATCH_SIZE = test_df.shape[0]\/NUM_BATCHES\nprint(\"BATCH SIZE = \"+ str(BATCH_SIZE))\n\noffset = 0\nall_test_preds = []\nfor i in range(1,NUM_BATCHES+1): ## Get Next batch\n    limit= i*BATCH_SIZE\n    print(f'BATCH_NO: {i}   ----  From: {offset} ===> To: {limit}')\n    X = batch_transform(test_df[int(offset):int(limit)], is_train=False) # Transform the data\n    preds = RF_CL.predict(X)  # Predicting the test set\n    all_test_preds.append(preds.flatten())\n    offset = limit\n\n","d4a4ecaa":">>>\n>>> from sklearn.datasets import make_classification\n>>> X, y = make_classification(n_samples=1000, n_features=4,\n...                            n_informative=2, n_redundant=0,\n...                            random_state=0, shuffle=False)\n>>> \n>>> clf.fit(X, y)\nAdaBoostClassifier(n_estimators=100, random_state=0)\n>>> clf.predict([[0, 0, 0, 0]])\narray([1])\n>>> clf.score(X, y)\n","7191d5ea":"# from sklearn.model_selection import cross_val_score\n# from sklearn.datasets import make_blobs\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.ensemble import ExtraTreesClassifier\n# from sklearn.tree import DecisionTreeClassifier\n\n# #X, y = make_blobs(n_samples=10000, n_features=10, centers=100,random_state=0)\n\n# clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n# scores = cross_val_score(clf, X, y, cv=5)\n# # >>> scores.mean()\n# 0.98...\n\n# >>> clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n# ...     min_samples_split=2, random_state=0)\n# >>> scores = cross_val_score(clf, X, y, cv=5)\n# >>> scores.mean()\n# 0.999...\nfinal_df=pd.DataFrame.from_records(np.load(train_df.path[1]))\nfinal_df\ntrain_df.loc[1, 'value']=final_df[0:26]\ntrain_df","b40b7de7":"final_df[0:26]","cbd9ace2":"### Ensemble learning ","6f81f902":"As the black holes spiral closer and closer in together, the frequency of the gravitational waves increases. Scientists call these sounds \"chirps,\" because some events that generate gravitation waves would sound like a bird's chirp\n\n[Gravitational wave sound from caltech's website](http:\/\/https:\/\/www.ligo.caltech.edu\/video\/ligo20160211v2)","73c75939":"**We can hear gravitational waves, in the same sense that sound waves travel through water, or seismic waves move through the earth. The difference is that sound waves vibrate through a medium, like water or soil. For gravitational waves, spacetime is the medium. It just takes the right instrument to hear them.**\n\n**Detecting gravitational waves on Earth was a challenge that took roughly a century to complete, since the ones that wash through the planet are incredibly tiny.**[national geographic's article about gravitational waves](http:\/\/https:\/\/www.nationalgeographic.com\/science\/article\/gravitational-waves#:~:text=We%20can%20hear%20gravitational%20waves,right%20instrument%20to%20hear%20them.)","e289601c":"first trial \n","2b682ef8":"In mathematics and signal processing, the constant-Q transform, simply known as CQT transforms a data series to the frequency domain. It is related to the Fourier transform and very closely related to the complex Morlet wavelet transform","ff266aa2":"second trial","6ffca203":"A standard DFT uses a constant buffer size throughout all frequencies. This typically leads to a pretty consistent, fully continuous transform. However, the constant bin size for all frequencies leads to some problems when you map frequency on a logarithmic scale. Specifically, peaks on the lower end are incredibly wide (sometimes up to half an octave), lacking any sort of detail.\n\nThis is an issue for emulating human perception because humans perceive frequency on a logarithmic scale.\n\nA Constant Q transform seeks to solve this problem by increasing the buffer size for lower frequencies, and alleviate some of the computational strain caused by this by reducing the buffer size used for high frequencies. It's pretty effective at this, but has a few drawbacks.[answer is here ](http:\/\/https:\/\/dsp.stackexchange.com\/questions\/43811\/what-is-the-difference-between-constant-q-transform-and-wavelet-transform-and-wh)","e601e927":"**what is discovered here from the 2 50s plots that the targeted wave\"gravitational wave\" has more outliers than the other waves specialy in detector one**","9582c255":"**When the target is 1 it can be seen in the above plot that the peak of the histogram is much more spread than the peak in target 0 which means that when the target is 0 the gw waves have values mostly zero but when the target is 1 then there are waves with values other than 0 which contribute to the peak of the data**","8156a0e4":"the output of the plot will be time on x axis vs \\frequencies on y axis and the z axis in the amplitude of the signal at the moment with this frequency","469c8a52":"[forbes's article about gravitational wwaves](http:\/\/https:\/\/www.forbes.com\/sites\/startswithabang\/2020\/08\/21\/ask-ethan-why-dont-light-and-gravitational-waves-arrive-simultaneously\/#:~:text=Whenever%20masses%20accelerate%20through%20curved,%2C%20rather%20than%20electromagnetic%2C%20radiation.)","bfc995e2":"### Mel-frequency cepstrum","b007938d":"## Visulaizing the Q Transform","e661a98a":"## What is the difference between FFT and Constant Q transfrom ? "}}