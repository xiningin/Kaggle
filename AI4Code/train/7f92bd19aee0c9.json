{"cell_type":{"5b03d668":"code","e108d536":"code","311a095d":"code","de468adb":"code","bfe48450":"code","12c2fa9b":"code","9fc32174":"code","57fdf592":"code","7203b41c":"code","25499349":"code","3471080d":"code","c6fa2780":"code","a80a6852":"code","b0230bc9":"code","595930e2":"code","c24b1a69":"code","00bcd172":"code","3f0b6afb":"code","4f4a5d02":"code","41d3d1bd":"code","1d81c1f7":"code","8fbd354a":"code","725416d2":"code","c94ef1c9":"code","5c23809d":"code","db1c7fcb":"code","cc3f92e5":"code","657f8931":"code","b184b12d":"code","dda9655a":"code","fad95e75":"code","9499b839":"code","5653591f":"code","a1f016a3":"code","f11e366f":"code","476c5368":"code","535418a6":"code","069a0d7b":"code","f7d5f294":"code","c86ec71f":"code","710383c4":"code","56456551":"code","e0f5e29f":"code","62c0d2c4":"code","9df40384":"code","3359254c":"code","62574514":"code","bb93a234":"code","b158fd92":"code","b24a7d9c":"code","6b85cef3":"code","71518e52":"code","3d525b3b":"code","e3d1966d":"code","3921f8ec":"markdown","99aa3435":"markdown","a7948c38":"markdown","3a1d4450":"markdown","896b8686":"markdown","502e6dc4":"markdown","f49b1641":"markdown","c894cc93":"markdown","a877c472":"markdown","9e23ec8b":"markdown","d7ebb4d3":"markdown","cb2a54d8":"markdown","e3d9d7aa":"markdown","b2faa515":"markdown","28ea609f":"markdown","467d3412":"markdown","ae121fe8":"markdown","b1b7fb67":"markdown","f35d1db9":"markdown","60b74092":"markdown","5b16f3bb":"markdown","68b26c78":"markdown","792850d5":"markdown","accb893b":"markdown"},"source":{"5b03d668":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e108d536":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings","311a095d":"warnings.filterwarnings('ignore')","de468adb":"insurence_df=pd.read_csv('\/kaggle\/input\/health-insurance-dataset\/Health_insurance.csv')","bfe48450":"insurence_df.shape","12c2fa9b":"insurence_df.head()","9fc32174":"insurence_df.info()","57fdf592":"{col:list(insurence_df[col].unique()) for col in insurence_df.select_dtypes('object')}","7203b41c":"region_serie=insurence_df.groupby('region').size()\nsmoker_serie=insurence_df.groupby('smoker').size()\nsex_serie=insurence_df.groupby('sex').size()\n\nseries={\n    \n    'Sex':sex_serie,\n    'Region':region_serie,\n    'Smoker':smoker_serie\n    \n}\n\n\ndef pie_plot(serie,title):\n    \n    \n    serie.plot(kind='pie',title=title, figsize=[20,8],colors=['#77dd77','#fdfd96','#84b6f4','#fdcae1'],\n          autopct=lambda p: '{:.2f}%({:.0f})'.format(p,(p\/100)*serie.sum()))\n\n    plt.ylabel(None)","25499349":"for i,j in series.items():\n    \n    plt.subplots(1,1)\n    pie_plot(j,i)","3471080d":"insurence_df.children.value_counts()","c6fa2780":"\nsns.set_style(style='whitegrid')\nfig,(ax_hist,ax_box)=plt.subplots(1,2,figsize=(20,8))\n\nax_hist.set_title('Charges')\n\nax_hist.hist(insurence_df['charges'],ec='k',color='#ffffbf')\n\nax_hist.axvline(insurence_df['charges'].mean(),linestyle='-',lw=4,c='red',label='Mean')\nax_hist.axvline(insurence_df['charges'].median(),linestyle='-',lw=4,c='blue',label='Median')\nax_hist.legend()\n\n\nax_box.set_title('Charges')\nsns.boxplot(x='charges',data=insurence_df,color='#ffffbf',ax=ax_box)\n\nplt.show()","a80a6852":"plt.subplots(1,1,figsize=(20,8))\n\nplt.title('Charges vs Region vs Smoker')\nsns.boxplot(x='smoker',y='charges',data=insurence_df,palette='cool')\nplt.show()","b0230bc9":"\nplt.subplots(1,1,figsize=(20,8))\n\nplt.title('Charges vs Region vs Smoker')\nsns.boxplot(x='region',y='charges',hue='smoker',data=insurence_df,palette='cool')\nplt.show()","595930e2":"plt.subplots(1,1,figsize=(20,8))\n\nplt.title('BMI')\nsns.boxplot(x='bmi',data=insurence_df,palette='cool')\nplt.show()","c24b1a69":"insurence_df['bmi']=np.where(insurence_df['bmi']<18,18,insurence_df['bmi'])\ninsurence_df['bmi']=np.where(insurence_df['bmi']>45,45,insurence_df['bmi'])","00bcd172":"plt.subplots(1,1,figsize=(20,8))\n\nplt.title('BMI')\nsns.boxplot(x='bmi',data=insurence_df,palette='cool')\nplt.show()","3f0b6afb":"smoker_no=insurence_df[insurence_df['smoker']=='no']","4f4a5d02":"plt.subplots(1,1,figsize=(20,8))\nsns.scatterplot(x='age',y='charges',data=smoker_no,color='c')\nplt.show()","41d3d1bd":"smoker_no['charges'].mean()+1.5*smoker_no['charges'].std()","1d81c1f7":"smoker_no=smoker_no[smoker_no['charges']<17424]","8fbd354a":"plt.subplots(1,1,figsize=(20,8))\nsns.scatterplot(x='age',y='charges',data=smoker_no,color='c')\nplt.show()","725416d2":"adults_young=smoker_no[(smoker_no['age']>=18) & (smoker_no['age']<30)]\nadults=smoker_no[(smoker_no['age']>=30) & (smoker_no['age']<=45)]\nadults_old=smoker_no[smoker_no['age']>45]","c94ef1c9":"fig,(ax_1,ax_2,ax_3)=plt.subplots(1,3,figsize=(20,8))\n\nsns.scatterplot(x='age',y='charges',data=adults_young,ax=ax_1,color='c')\nsns.scatterplot(x='age',y='charges',data=adults,ax=ax_2,color='r')\nsns.scatterplot(x='age',y='charges',data=adults_old,ax=ax_3,color='lightgreen')\n\nplt.show()","5c23809d":"adults_young=adults_young[adults_young['charges']<6000]\nadults=adults[adults['charges']<10000]\nadults_old=adults_old[adults_old['charges']<16000]","db1c7fcb":"fig,(ax_1,ax_2,ax_3)=plt.subplots(1,3,figsize=(20,8))\n\nsns.scatterplot(x='age',y='charges',data=adults_young,ax=ax_1,color='c')\nsns.scatterplot(x='age',y='charges',data=adults,ax=ax_2,color='r')\nsns.scatterplot(x='age',y='charges',data=adults_old,ax=ax_3,color='lightgreen')\n\nplt.show()","cc3f92e5":"smoker_no_clear=pd.concat([adults_young,adults,adults_old])","657f8931":"plt.subplots(1,1,figsize=(20,8))\nsns.scatterplot(x='age',y='charges',data=smoker_no_clear,color='c')\nplt.show()","b184b12d":"smoker_yes=insurence_df[insurence_df['smoker']=='yes']","dda9655a":"plt.subplots(1,1,figsize=(20,8))\nsns.scatterplot(x='age',y='charges',data=smoker_yes,color='c')\nplt.show()","fad95e75":"smoker_yes=smoker_yes[smoker_yes['charges']<50000]\nsmoker_yes=smoker_yes[smoker_yes['children']<4]","9499b839":"smoker_yes_clear=smoker_yes","5653591f":"insurence_clear=pd.concat([smoker_yes_clear,smoker_no_clear])","a1f016a3":"fig,(ax_1,ax_2)=plt.subplots(1,2,figsize=(20,8))\n\nax_1.set_title('After')\nsns.boxplot(x='smoker',y='charges',hue='region',data=insurence_df,palette='cool',ax=ax_1)\n\nax_2.set_title('Before')\nsns.boxplot(x='smoker',y='charges',hue='region',data=insurence_clear,palette='cool',ax=ax_2)\nplt.show()","f11e366f":"insurence_clear=pd.get_dummies(insurence_clear,drop_first=True)","476c5368":"insurence_clear.head()","535418a6":"from sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\n\ninsurence_clear[['age','bmi']]=sc.fit_transform(insurence_clear[['age','bmi']])","069a0d7b":"insurence_clear.head()","f7d5f294":"from sklearn.model_selection import train_test_split,cross_val_score\n\nX=insurence_clear.drop(['charges'],axis='columns')\ny=np.log(insurence_clear['charges'])\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.25,random_state=11)\n\nX_train.shape,X_test.shape","c86ec71f":"from sklearn.linear_model import LinearRegression,RidgeCV\nlm=LinearRegression()\nlm_ridge=RidgeCV()","710383c4":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr=GradientBoostingRegressor(max_depth=3,learning_rate=0.1)","56456551":"from sklearn.preprocessing import PolynomialFeatures\n\npoly=PolynomialFeatures(degree=2)\n\nX_train_poly=poly.fit_transform(X_train)\nX_test_poly=poly.fit_transform(X_test)\n\n\npoly.fit(X_train_poly,Y_test)\n\nlm_poly=LinearRegression()\n\nlm_poly.fit(X_train_poly,Y_train)","e0f5e29f":"def train_model(model):\n    \n    return model.fit(X_train,Y_train)\n\n\nmodels={'Linear Regression':lm,\n       'Ridge Regression':lm_ridge,\n       'Gradient Boosting Regression':gbr}\n\n\n\nfor model in models.values():\n    \n    train_model(model)","62c0d2c4":"for name,model  in models.items():\n    \n    \n    print(model,f'R2 score {model.score(X_test,Y_test)}')","9df40384":"for name,model  in models.items():\n    \n    \n    print(model,f'R2 score {model.score(X_train,Y_train)}')","3359254c":"lm_poly.score(X_train_poly,Y_train),lm_poly.score(X_test_poly,Y_test)","62574514":"cross_val_score(lm_poly,X_test_poly,Y_test,cv=10).mean()","bb93a234":"cross_val_score(gbr,X_test,Y_test,cv=10).mean()","b158fd92":"cross_val_score(lm,X_test,Y_test,cv=10).mean()","b24a7d9c":"from sklearn.metrics import mean_squared_error","6b85cef3":"\nprint(f'Train MSE {mean_squared_error(Y_train,gbr.predict(X_train))}')\nprint(f'Test MSE {mean_squared_error(Y_test,gbr.predict(X_test))}')","71518e52":"test=pd.DataFrame({'True values': np.exp(Y_test),\n                   'Gradient Boosting Predicted': np.exp(gbr.predict(X_test)),\n                  'Polynomial Regression Predicted':np.exp(lm_poly.predict(X_test_poly)),\n                  'Linear Regression Predicted':np.exp(lm.predict(X_test))})","3d525b3b":"fig,(ax_1,ax_2,ax_3)=plt.subplots(1,3,figsize=(20,8))\n\nax_1.set_title('Gradient Boosting')\nsns.scatterplot(x='True values',y='Gradient Boosting Predicted',data=test,ax=ax_1,color='c')\nsns.lineplot(x='True values',y='True values',data=test,ax=ax_1,color='c')\n\nax_2.set_title('Polynomial Regression')\nsns.scatterplot(x='True values',y='Polynomial Regression Predicted',data=test,ax=ax_2,color='r')\nsns.lineplot(x='True values',y='True values',data=test,ax=ax_2,color='r')\n\nax_3.set_title('Linear Regression')\nsns.scatterplot(x='True values',y='Linear Regression Predicted',data=test,ax=ax_3,color='lightgreen')\nsns.lineplot(x='True values',y='True values',data=test,ax=ax_3,color='lightgreen')\n\n\nplt.show()","e3d1966d":"test[:50]","3921f8ec":"There is still some bias, so I will have to separate the data frame into 3 categories, the first is for young people, the second is for adults and the last is for people over 45 years of age in order to eliminate the bias of the values.","99aa3435":"We will replace the values \u200b\u200bwhere the BMI is greater than 18 and those that are greater than 45 in order to eliminate the outliers.","a7948c38":"It is appreciated that the smoker variable plays an important role in predicting the medical cost.","3a1d4450":"The vast majority of cases can explain our model, it gives predictions very close to the real value.","896b8686":"We calculate the upper interval in order to eliminate outliers.","502e6dc4":"Many outliers are seen, it may be that more characteristics are missing that can explain these values.","f49b1641":"### Cross validation\n\nIt consists of creating small folds of the data set in order to see the percentage of generalization of the model and thus have a more realistic view of the performance.","c894cc93":"# Selection of the best model","a877c472":"### Polynomial Regression","9e23ec8b":"# EDA","d7ebb4d3":"# Feature engineering","cb2a54d8":"Gradient Boosting Win !! :)","e3d9d7aa":"We will divide the dataframe for people who smoke and those who do not in order to give a better data cleaning.","b2faa515":"### One hot transform","28ea609f":"### Gradient Boosting","467d3412":"We observe that there is a linear relationship with age between the values \u200b\u200bof the medical charge less than 10,000 dollars.","ae121fe8":"### Training and validation data separation.","b1b7fb67":"The higher the degree of R2, the more will be the explanatory power of the regression model.","f35d1db9":"\nBetter cleaning with data was appreciated.","60b74092":"I will only leave the values \u200b\u200bfor people who smoke who have a medical charge of less than $ 50,000 since there are very few people who have that medical insurance charge.","5b16f3bb":"# Data standardization\n\nSo that the data is comparable to each other.","68b26c78":"### Linear regression and Ridge regression","792850d5":"# Preprocessing of data","accb893b":"# Conclusion\n\n\n**Linear regression** is good for predicting health insurance charges for non-smokers, whereas it does not give predictions very far from true values.\n\n**Polynomial regression** also gives good predictions for those insured who do not smoke and for some who do.\n\nThe **gradien boosting regression** gives very good predictions for both cases, which is the one that generalizes better and it has better predictions and a smaller squared error."}}