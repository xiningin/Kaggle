{"cell_type":{"84e72092":"code","44371f1f":"code","ee037300":"code","202200b5":"code","9bfdf59c":"code","65b4c852":"code","7309ce63":"code","d9e7cc41":"code","666dbe25":"code","8c38d3d5":"code","bc79241c":"code","11e1c5df":"code","339b1e6d":"code","2073d433":"code","fa3281b7":"code","8844cc1f":"code","519796b5":"code","208a47d5":"code","79ee11f6":"code","2c20f25e":"code","6938c2b0":"code","9bf22a37":"code","bb42c6b7":"code","eea6e8fa":"code","52e734ec":"code","40ea02e7":"markdown","a63d089f":"markdown","ab649cad":"markdown","d45a1ef7":"markdown","79103a9f":"markdown","567337f1":"markdown","a912f404":"markdown","c5ca4e5c":"markdown","917890ae":"markdown","6f42a0cf":"markdown","b8ed6e7d":"markdown","5de34e9b":"markdown","8c91a3a6":"markdown","d6c6de8c":"markdown","80ec1b7c":"markdown","fc47fac2":"markdown","7b687696":"markdown","3f84bc19":"markdown","5593c6ff":"markdown","e378721c":"markdown","fd4b7d70":"markdown"},"source":{"84e72092":"import seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport random\nfrom keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt \nimport glob as gb\nfrom kaggle_datasets import KaggleDatasets\n!pip install -q efficientnet\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential","44371f1f":"train_df = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/train.csv\")\nIMAGE_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/images\/\"","ee037300":"size = []\nfiles = gb.glob(pathname= str(\"..\/input\/plant-pathology-2020-fgvc7\/images\/*.jpg\"))\nfor file in files: \n    image = plt.imread(file)\n    size.append(image.shape)\npd.Series(size).value_counts()\n# Because it take looong time the output is below\n# (1365, 2048, 3)    3620\n# (2048, 1365, 3)      22","202200b5":"train_df.head(10)\n# train_df.shape","9bfdf59c":"fig,ax=plt.subplots(2,2,figsize=(14,14))\nsns.barplot(x=train_df.healthy.value_counts().index,y=train_df.healthy.value_counts(),ax=ax[0,0])\nax[0,0].set_xlabel('Healthy',size=9)\nax[0,0].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.multiple_diseases.value_counts().index,y=train_df.multiple_diseases.value_counts(),ax=ax[0,1])\nax[0,1].set_xlabel('Multiple Diseases',size=9)\nax[0,1].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.rust.value_counts().index,y=train_df.rust.value_counts(),ax=ax[1,0])\nax[1,0].set_xlabel('Rust',size=9)\nax[1,0].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.scab.value_counts().index,y=train_df.scab.value_counts(),ax=ax[1,1])\nax[1,1].set_xlabel('Scab',size=9)\nax[1,1].set_ylabel('Count',size=9)","65b4c852":"healthy = list(train_df[train_df[\"healthy\"]==1].image_id)\nmultiple_diseases = list(train_df[train_df[\"multiple_diseases\"]==1].image_id)\nrust = list(train_df[train_df[\"rust\"]==1].image_id)\nscab = list(train_df[train_df[\"scab\"]==1].image_id)","7309ce63":"def load_image(filenames):\n    sample = random.choice(filenames)\n    image = load_img(\"..\/input\/plant-pathology-2020-fgvc7\/images\/\"+sample+\".jpg\")\n    plt.imshow(image) ","d9e7cc41":"load_image(healthy)","666dbe25":"load_image(multiple_diseases)","8c38d3d5":"load_image(rust)","bc79241c":"load_image(scab)","11e1c5df":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n#to verify your dir\n!gsutil ls $GCS_DS_PATH","339b1e6d":"def format_path_gcs(st):\n    return GCS_DS_PATH + '\/images\/' + st + '.jpg'\n#===============================================================\n#===============================================================\nX = train_df.image_id.apply(format_path_gcs).values\ny = np.float32(train_df.loc[:, 'healthy':'scab'].values)\n\nX_train, X_val, y_train, y_val =train_test_split(X, y, test_size=0.1, random_state=43)\nprint('done!')","2073d433":"print('Shape of X_train : ',X_train.shape)\nprint('Shape of y_train : ',y_train.shape)\nprint('===============================================')\nprint('Shape of X_val : ',X_val.shape)\nprint('Shape of y_val : ',y_val.shape)","fa3281b7":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","8844cc1f":"BATCH_SIZE = 4 * strategy.num_replicas_in_sync\nSTEPS_PER_EPOCH = y_train.shape[0] \/\/ BATCH_SIZE","519796b5":"def decode_image(filename, label=None, image_size=(1024,1024)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.3)\n    \n    \n    if label is None:\n        return image\n    else:\n        return image, label","208a47d5":"train_dataset = (\n    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    .map(decode_image,num_parallel_calls=AUTO)\n    .map(data_augment,num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(256)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_val, y_val))\n    .map(decode_image,num_parallel_calls=AUTO)\n    .cache()\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","79ee11f6":"def build_lrfn(lr_start=0.00001, lr_max=0.00005,lr_min=0.00001, lr_rampup_epochs=5,lr_sustain_epochs=0, lr_exp_decay=.8):\n    \n    lr_max = lr_max * strategy.num_replicas_in_sync\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs- lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","2c20f25e":"lrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\nEarlyStopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,verbose=True, mode=\"min\")","6938c2b0":"# reduce_lr =  tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 10,\n#   verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,\n#   min_lr = 1e-5)\n# es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\" , verbose = 1 , mode = 'min' , patience = 10 )\n#weights='noisy-student',","9bf22a37":"def Eff_B7_NS():\n    model_EfficientNetB7_NS = Sequential([efn.EfficientNetB7(input_shape=(1024,1024,3),weights='noisy-student',include_top=False),\n                                 tf.keras.layers.GlobalAveragePooling2D(),\n                                 tf.keras.layers.Dense(128,activation='relu'),\n                                 tf.keras.layers.Dense(64,activation='relu'),\n                                 tf.keras.layers.Dense(4,activation='softmax')])               \n    model_EfficientNetB7_NS.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics=['categorical_accuracy'])\n    \n    \n    return model_EfficientNetB7_NS","bb42c6b7":"with strategy.scope():\n    model_Eff_B7_NS=Eff_B7_NS()\n    \nmodel_Eff_B7_NS.summary()\n#del model_Eff_B7_NS","eea6e8fa":"EfficientNetB7_NS = model_Eff_B7_NS.fit(train_dataset,\n                    epochs=50,\n                    callbacks=[lr_schedule,EarlyStopping],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","52e734ec":"plt.figure()\nfig,(ax1, ax2)=plt.subplots(1,2,figsize=(19,7))\nax1.plot(EfficientNetB7_NS.history['loss'])\nax1.plot(EfficientNetB7_NS.history['val_loss'])\nax1.legend(['training','validation'])\nax1.set_title('loss')\nax1.set_xlabel('epoch')\n\nax2.plot(EfficientNetB7_NS.history['categorical_accuracy'])\nax2.plot(EfficientNetB7_NS.history['val_categorical_accuracy'])\nax2.legend(['training','validation'])\nax2.set_title('Acurracy')\nax2.set_xlabel('epoch')\n","40ea02e7":"## 2.1 Import Libraries","a63d089f":"# 4. CNN","ab649cad":"But first let's setup TPU","d45a1ef7":"## 4.3. Evaluate Model","79103a9f":"![](https:\/\/raw.githubusercontent.com\/tensorflow\/tpu\/master\/models\/official\/efficientnet\/g3doc\/params.png)","567337f1":"\n\n\n### If you like my work, please hit upvote since it will keep me motivated","a912f404":"### Before the trip begin\n\n#####  If you like my work, please hit upvote since it will keep me motivated","c5ca4e5c":"## 2.4 Split to Train and Validaiton","917890ae":"## 2.2 Load Data","6f42a0cf":"# 1. Introduction\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/ad\/Black_rot_lifecycle.tif\/lossy-page1-1200px-Black_rot_lifecycle.tif.jpg)\n\n### Problem Statement\nMisdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection.\n\n### Importance of Plant Pathology\nPlant Pathology has advanced techniques to protect crops from losses due to diseases. The science of plant pathology has contributed disease free certified seed production. Most of the diseases with known disease cycle can now be avoided by the modification of cultural practices","b8ed6e7d":"### Let's check all the categories we have ","5de34e9b":"Everything look fine !","8c91a3a6":"## 2.3 Check Data","d6c6de8c":"## 4.1. Define Callbacks","80ec1b7c":"# 2. Data Preparation","fc47fac2":"As you can see after no improvment EarlyStop did its job ,and for this model I think is the best to choose between 14-17 epochs . ","7b687696":"EfficientNets rely on AutoML and compound scaling to achieve superior performance without compromising resource efficiency. The AutoML Mobile framework has helped develop a mobile-size baseline network, EfficientNet-B0, which is then improved by the compound scaling method to obtain EfficientNet-B1 to B7.","3f84bc19":"# 3. Create Dataset","5593c6ff":"## 4.2. Efficientnet-B7","e378721c":"This one below is to check the most common resolution of pictures among all Train data","fd4b7d70":"* **1. Introduction**   \n* **2. Data Preparation**\n   * 2.1 Import Libaries\n   * 2.2 Load Data\n   * 2.3 Check the Data\n   * 2.4 Split to train and test\n* **3. Data Augmentation**\n* **4. CNN**\n   * 4.1 Define Callbacks\n   * 4.2 Efficientnet-B7\n   * 4.3 Evaluate the Model"}}