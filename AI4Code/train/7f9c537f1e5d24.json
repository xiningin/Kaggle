{"cell_type":{"47d7afec":"code","0eeeb6f9":"code","bab52459":"code","f1025956":"code","2a522a91":"code","b1bf6fd8":"code","6402a700":"code","4f7e7f13":"code","7e9a1f20":"code","ace35c84":"code","8d8d9d95":"code","3c922758":"code","aa180779":"code","759ce64d":"code","b09ab740":"code","68a3beac":"code","7874e24b":"code","b2d12df7":"code","5e4efd5a":"code","05eeac42":"code","31e77dd6":"code","99d11473":"code","829515b5":"code","72af4fa5":"code","208611fe":"code","c0c9ce6d":"code","5dbe28ba":"code","f2af47d7":"code","8c14c9f2":"code","2ce63f55":"code","37722e4e":"code","7ee8d7bd":"code","ed82ed62":"code","3b64133d":"code","1c3e0d1f":"code","b0c4c71e":"code","87207310":"code","66b77c2f":"code","f0fbfc14":"markdown"},"source":{"47d7afec":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv\nfrom abc import ABC, abstractmethod\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.base import TransformerMixin, clone\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import log_loss, make_scorer\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.feature_selection import f_classif, chi2, mutual_info_classif, SelectKBest, RFE, SelectFromModel\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0eeeb6f9":"# Reduce the size of your train and test data to model more easily\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","bab52459":"# Read Data from Kaggle\ndf = pd.read_csv('\/kaggle\/input\/pokemon\/pokemon.csv')","f1025956":"df.head(3)","2a522a91":"#Check the presence of missing values\ndf.isnull().values.any()","b1bf6fd8":"# Search the column names with missing values\ncols_missing_val = df.columns[df.isnull().any()].tolist()\nprint(cols_missing_val)","6402a700":"#Count missing values in each column:\nfor col in cols_missing_val:\n    print(\"%s : %d\" % (col, df[col].isnull().sum()))","4f7e7f13":"sns.heatmap(df[cols_missing_val].isnull(), yticklabels=False, cbar=False)","7e9a1f20":"#Hence genderless pokemons can be assigned '-1'\ndf['percentage_male'].fillna(np.int(-1), inplace=True)","ace35c84":"#Unique values\ndf['type2'].unique()","8d8d9d95":"#Replace nan with new type2\ndf['type2'].fillna('hormann', inplace=True)","3c922758":"#Replace the missing values with 0.\ndf['height_m'].fillna(np.int(0), inplace=True)\ndf['weight_kg'].fillna(np.int(0), inplace=True)","aa180779":"#Memory Consumption\nmem = df.memory_usage(index=True).sum()\nprint(\"Memory consumed by training set  :   {} MB\" .format(mem\/ 1024**2))","759ce64d":"df.isnull().values.any()","b09ab740":"df = reduce_mem_usage(df, verbose=True)","68a3beac":"#Classfication\ndf['classfication'].nunique()","7874e24b":"df.dtypes","b2d12df7":"for label,content in df.items():\n    if pd.api.types.is_float_dtype(content):\n        df[label] = df[label].astype('int')","5e4efd5a":"df.dtypes","05eeac42":"for label,content in df.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        df[label] = df[label].astype('category')\ndf.dtypes","31e77dd6":"for label,content in df.items():\n    if pd.api.types.is_categorical_dtype(content):\n        df[label] = pd.Categorical(content).codes + 1","99d11473":"df.dtypes","829515b5":"X = df.drop('is_legendary', axis=1)\ny = df['is_legendary']","72af4fa5":"## For modelling :\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Modelling tools :\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nfrom sklearn.metrics import roc_curve,roc_auc_score\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn.model_selection import cross_val_score,RandomizedSearchCV,GridSearchCV ","208611fe":"model_a = RandomForestClassifier()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nmodel_a.fit(X_train, y_train)\nmodel_a.score(X_test, y_test)","c0c9ce6d":"model_b = GradientBoostingClassifier()\nmodel_b.fit(X_train,y_train)\nmodel_b.score(X_test,y_test)","5dbe28ba":"# Lets check the cross val score\ny_preds = model_a.predict_proba(X_test)\ncvm = cross_val_score(model_a,X,y,cv=10)\nnp.mean(cvm)","f2af47d7":"# Classification metrics :\ny_preds = model_a.predict(X_test)\n\nprecision = precision_score(y_test,y_preds)\nrecall = recall_score(y_test,y_preds)\naccuracy = accuracy_score(y_test,y_preds)\naccuracy,recall,precision","8c14c9f2":"## Lets get the legendary predictions : \nPokemon = pd.DataFrame()\ny_preds = model_a.predict(X)\nPokemon['Default values'] = y\nPokemon['Predictions'] = y_preds","2ce63f55":"Pokemon","37722e4e":"fig,axes = plt.subplots()\naxes.stackplot(Pokemon['Default values'],Pokemon['Predictions'],color=['red','blue']);","7ee8d7bd":"#Create a Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.tree import DecisionTreeClassifier","ed82ed62":"#Logistic Regression Pipeline\npipeline_lr=Pipeline([('scalar1',StandardScaler()),\n                     ('pca1',PCA(n_components=2)),\n                     ('lr_classifier',LogisticRegression(random_state=0))])","3b64133d":"pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n                     ('pca2',PCA(n_components=2)),\n                     ('dt_classifier',DecisionTreeClassifier())])","1c3e0d1f":"pipeline_lr.fit(X_train, y_train)","b0c4c71e":"pipeline_lr.score(X_test, y_test)","87207310":"pipeline_dt.fit(X_train, y_train)","66b77c2f":"pipeline_dt.score(X_test, y_test)","f0fbfc14":"**Exploratory Data Analysis**"}}