{"cell_type":{"14d9b20f":"code","080d6a18":"code","d1fa3940":"code","ddf4c5fa":"code","fed6f950":"code","ac564218":"code","fa90879e":"code","246f58bf":"code","3c3a8e47":"code","af2f12fb":"code","d0dbeeb3":"code","056a074a":"code","655fb30a":"code","b2f2a9e2":"code","498dc351":"markdown","3d4b5be2":"markdown","67f4f197":"markdown","44d0023b":"markdown","6c88cb62":"markdown","5a46fd18":"markdown","33eb8e68":"markdown"},"source":{"14d9b20f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize \n\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom itertools import islice\n\nimport string\nimport seaborn as sns; sns.set()\n\nfrom IPython.display import HTML, display","080d6a18":"df=pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv',usecols=['title','journal','abstract','authors','doi','publish_time','sha'])\ndf=df.fillna('N\/A')\npublish_times= ['2019','2020']\ndf=df[df['publish_time'].str.contains('|'.join(publish_times))]\n\ndf[\"key_search\"] = df[\"abstract\"].str.lower()+df[\"title\"].str.lower()\ncovid_keys = ['cov','covid','cov19','covid-19','covid19','-covid','-cov-2','cov2','ncov']\ndf = df[df['key_search'].str.contains('|'.join(covid_keys))]\n\ndf = df.drop_duplicates(subset='title', keep=\"first\")\nprint (df.shape)\ndf.head()","d1fa3940":"punctuations = string.punctuation\nstop_words = list(STOP_WORDS)\nstop_words += punctuations\nstop_words += ['ll','ve','et', 'al','copyright', 'peer']\nstop_words[:10]","ddf4c5fa":"def tfidf_calculate(df,stop_words):\n    abstract = df['abstract'].values\n    vectorizer = TfidfVectorizer(max_features=2 ** 12,stop_words=stop_words)\n    tfidf = vectorizer.fit_transform(abstract)\n    return tfidf,vectorizer\n\ndef print_first(n, iterable):\n    return list(islice(iterable, n))\n\ndef stemming(keys_query):\n    stemmer = PorterStemmer()\n    stemmed_keys=[]\n    for key_query in keys_query:\n        stemmed_keys.append(stemmer.stem(key_query))\n    return stemmed_keys\n\ndef doc_isrelevant(doc,keys_query):\n    stemmed_keys = stemming(keys_query)\n    new_doc = doc[doc['abstract'].str.contains('|'.join(stemmed_keys))].copy()\n    return new_doc\n\ndef doc_relevance_calculate(stemmed_keys,doc,vectorizer):\n    total_score=0\n    df1 = pd.DataFrame(doc.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n    df1 = df1.reset_index().rename(columns={\"index\":\"term\"})\n    total_score = df1.where(df1[\"term\"].str.contains('|'.join(stemmed_keys))).sum(axis = 0, skipna = True)\n    return total_score\n \ndef top_relevant(query,df,stop_words):\n    new_docs = doc_isrelevant(df,query)\n    stemmed_keys = stemming(query)\n    new_docs[\"total_score\"] = 0.0\n    tfidf,vectorizer = tfidf_calculate(new_docs,stop_words)\n    i=0\n    for row in new_docs.itertuples():\n        total_score = doc_relevance_calculate(stemmed_keys,tfidf[i],vectorizer)\n        new_docs.loc[row.Index,'total_score'] = total_score.tfidf\n        i +=1\n    sorted_df = new_docs.sort_values(by=['total_score'], ascending=False)\n    return sorted_df\n\ndef filter_query(query,stop_words):\n    query = query.lower()\n    word_tokens = word_tokenize(query) \n    filtered_query = [w for w in word_tokens if not w in stop_words] \n    return filtered_query\n\ndef process_query(query,df,stop_words):\n    filtered_query = filter_query(query,stop_words)\n    result = top_relevant(filtered_query,df,stop_words)\n    return result\n\ndef print_results(data_relevant,query):\n    data_relevant=data_relevant.sort_values(by=['total_score'],ascending = False)\n    html_ranks = \"\"\n    for i in range(0,5):\n        html_ranks += \"<h4 style='color: brown;'>Rank: \"+str(i+1)+\" (Score: \"+str(round(data_relevant.iloc[i]['total_score'],3))+\")<\/h4><br\/><h4>\"+data_relevant.iloc[i]['title']+\"<\/h4><p id='abstract\"+str(i)+\"' style='margin-top: 20px;margin-bottom: 20px;'>\"+data_relevant.iloc[i]['abstract'][:500]+ \"...<\/p><a onclick='show_more(\"+str(i)+\")'><\/a><br\/>\"\n    html_scripts = \"<script type='text\/javascript'>function show_more(number){let abstractContent = document.getElementById('abstract'+number); alert(abstractContent);\/*abstractContent.innerHTML = \\\"\"+html_ranks+\"\\\"*\/;}<\/script>\"\n    html_show = \"<html>\"+html_scripts+\"<head><\/head><body><h1 style='color:blue;'> Query: \"+query+\"<\/h1><br\/>\"+html_ranks+\"<\/body><\/html>\"\n    display(HTML(html_show))\n    return\n\n\ndef plot_scores(data_relevant):\n    #test = result1[:2000]\n    data_relevant['score_range'] = pd.cut(data_relevant['total_score'], 10)\n    data_relevant=data_relevant.sort_values(by=['score_range'],ascending = False)\n    bins_obj = data_relevant['score_range'].value_counts()\n    \n    ax = sns.barplot(x=bins_obj.index.categories, y=bins_obj)\n    ax.set_ylabel('Count')\n    ax.set_xlabel('Score Range')\n    ax.set_title('Count of relative documents in score ranges')\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=70, ha='right')\n    return","fed6f950":"query1 = \"Range of incubation periods for the disease in humans.\"\nresult1 = process_query(query1,df,stop_words)\nprint_results(result1,query1)\nplot_scores(result1)","ac564218":"query2 = \"Incubation varying across age groups\"\nresult2 = process_query(query2,df,stop_words)\nprint_results(result2,query2)\nplot_scores(result2)","fa90879e":"query3 = \"How long individuals are contagious after recovery?\"\nresult3 = process_query(query3,df,stop_words)\nprint_results(result3,query3)\nplot_scores(result3)","246f58bf":"query4 = \"Persistence of virus on surfaces of different materials\"\nresult4 = process_query(query4,df,stop_words)\nprint_results(result4,query4)\nplot_scores(result4)","3c3a8e47":"query5 = \"Seasons affecting transmission of virus\"\nresult5 = process_query(query5,df,stop_words)\nprint_results(result5,query5)\nplot_scores(result5)","af2f12fb":"query6 = \"Does immune diseases affect recovery?\"\nresult6 = process_query(query6,df,stop_words)\nprint_results(result6,query6)\nplot_scores(result6)","d0dbeeb3":"query7 = \"Immunity system response to the disease\"\nresult7 = process_query(query7,df,stop_words)\nprint_results(result7,query7)\nplot_scores(result7)","056a074a":"query8 = \"Role of the environment in transmission\"\nresult8 = process_query(query8,df,stop_words)\nprint_results(result8,query8)\nplot_scores(result8)","655fb30a":"query9 = \"Does wearing personal protective equipment such as gloves and masks reduce disease transmission in healthcare community?\"\nresult9 = process_query(query9,df,stop_words)\nprint_results(result9,query9)\nplot_scores(result9)","b2f2a9e2":"query10 = \"Natural history of the virus and shedding of it from an infected person.\"\nresult10 = process_query(query10,df,stop_words)\nprint_results(result10,query10)\nplot_scores(result10)","498dc351":"## TF-IDF\nAs we are trying to find relevance to some queries we might ask about this virus, we will use the tf-idf which is `term frequency - inverse document frequency` to calculate how relevant is each document to a certain query. NLP technics are used to ensure valid data processing, such as **stemming**; operation responsible for the reduction of words to their original form, and **word-tokenization** where a query is translated into list of tokens\/terms.\n\nThe following methods are helpers to perform the final operation which is `top_relevant`; with input `Query`, `DataFrame` and `stop_words` it is responsible to return a sorted list of all the relevant documents according to the `Query`, each document having `total_score` column referring to its scored points of relevancy to the proposed `Query`. \n\nThe methods `print_results` and `plot_scores` are used to display needed information. ","3d4b5be2":"## Queries\nWe will conduct several queries in order to test our methods and try find useful documents that would help narrowing down the search.","67f4f197":"## Stop words\nStop words are some basic words used in the majority of sentences, we will use the following `stop_words` for our query answers relevance calculation.","44d0023b":"Note that we had to drop duplicates, which are identical records retrieved by different keywords.","6c88cb62":"## Loading & Preprocessing of the data\nWe will exert some preprocessing operations over the data before having a look at the causes we are trying to answer.\nStarting by importing all the documents that contain the keywords mentioned below in their `abstract` or `title`. This will be done by creating a new column which will help us perform a more efficient search, this column will be called `key_search`. A strict publishing time will be forced while retrieving the documents as well, since we are interested in tackling the issue for this year, we are focusing to find the most relevant answer thus we set a time extent to a full year; `2019 (previous year)`, `2020 (current year)`.\n\n**Keywords**: `['cov','covid','cov19','covid-19','covid19','-covid','-cov-2','cov2','ncov']`.","5a46fd18":"# Relevance check of research papers\n\n## Approach\n- First we loaded and preprocessed the data. We were only interested in retrieving documents related to Covid-19 and we mainly worked on the abstracts found in the metadata. \n- The main technique used in our project was the tf-idf which was used to test relevance between selected queries and the retrieved documents. \n- The most 5 relevant abstracts are then displayed along with their corresponding total score of the tfidf function. \n- Queries are selected according to the requirements of Task : [What is known about transmission, incubation, and environmental stability?\n](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge\/tasks?taskId=568)\n- Then a bar graph is used to compare counts of the different ranges of the calculated score.\n\n## Pros \n- Could be generalised for other tested queries.\n- Usage of stemming and tfidf vectorizer resulted in accurate calculation of score. \n\n## Cons \n- Heavy computations result to slow processing time.\n- Use of only abstracts is not precise enough to retrieve answers of the query for future expansion of the algorithm. ","33eb8e68":"## Used Packages"}}