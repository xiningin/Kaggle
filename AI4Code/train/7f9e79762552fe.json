{"cell_type":{"db60cae2":"code","d4f425e6":"code","77c9a3ac":"code","0874e7f1":"code","1e381c82":"code","12a2dc74":"code","09336214":"code","d4f855fd":"code","b268eae5":"code","7bfc74c8":"markdown","f6ed6c81":"markdown"},"source":{"db60cae2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4f425e6":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import minmax_scale\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns  # visualization tool\nimport json #for parse \"properties\" parameter\nimport warnings\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom keras import optimizers\nwarnings.filterwarnings('ignore')\n","77c9a3ac":"# D\u1eef li\u1ec7u\ndoc = pd.read_csv('\/kaggle\/input\/protonx-tf02-linear-regression\/train.csv', delimiter=',', index_col=0)\n# Drop c\u1ed9t Chance of Admit\ndoc1 = doc.copy()\nX_df = doc1.drop('ChanceOfAdmit', 1)\n#print(X_df)\nX = X_df.to_numpy()\nX = np.asarray(X)\nX = X[:]\nX.shape\nX = minmax_scale(X)\nY = doc['ChanceOfAdmit']\nY = Y.to_numpy()\nprint(Y.shape)\ny = Y.reshape(-1,1)\n#Y = pd.DataFrame.values()\nprint(y.shape)\n#Y\ndoc","0874e7f1":"doc.describe()","1e381c82":"# T\u1ea1o ma tr\u1eadn theta ng\u1eabu nhi\u00ean 7 chi\u1ec1u r\u1ed3i \u0111\u1ea3o l\u1ea1i 1 chi\u1ec1u 7 h\u00e0ng\ntheta = np.random.normal(size=7).reshape(7,1)\n\n# Khai b\u00e1o h\u00e0m t\u1ed1i \u01b0u\ndef gradient(X, theta , y):\n  return X.T.dot((X.dot(theta) - y))\n\n# Khai b\u00e1o h\u00e0m m\u1ea5t m\u00e1t\ndef loss (X, theta, y):\n  return 1\/2 * np.mean((X.dot(theta)- y )**2)\n\n# Khai b\u00e1o c\u00e1c tham s\u1ed1 v\u00f2ng l\u1eadp v\u00e0 t\u1ed1c \u0111\u1ed9 h\u1ecdc\nepochs = 100000\nalpha = 0.01 # 0.01 \nm = y.shape[0]\n\n# B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n\nfor i in range (epochs):\n  grad  = gradient(X, theta , y)\n  # C\u1eadp nh\u1eadt Gradient\n  theta = theta - alpha * 1\/m * grad #\n  # print loss\n  if (i + 1) % 10000 == 1:\n    print(\"Epoch {} : Loss is {}\".format(i,loss(X, theta, y)))\n  if i == epochs-1:\n    print(\"Epoch {} : Loss is {}\".format(i,loss(X, theta, y))) \n","12a2dc74":"test_set = pd.read_csv('\/kaggle\/input\/protonx-tf02-linear-regression\/sample_submission.csv', delimiter=',', index_col=0)\n# Drop c\u1ed9t Chance of Admit\ntest = test_set.copy()\nX_test = test.drop('ChanceOfAdmit', 1)\nX_test = X_test.to_numpy()\nX_test = np.asarray(X_test)\nX_test = X_test[:]\nX_test = minmax_scale(X_test)\nY_test = test_set['ChanceOfAdmit']\nY_test = Y_test.to_numpy()\ny_test = Y_test.reshape(-1,1)\ndef hypo(X, theta):\n  return X.dot(theta)\ntest","09336214":"hypo(X_test, theta)","d4f855fd":"result =pd.DataFrame(hypo(X_test, theta), columns=['ChanceOfAdmit'])\nx = pd.DataFrame ({'ChanceOfAdmit':'NaN'},index =[0])\nresult = pd.concat ([x,result],axis=0).reset_index(drop = True) \nk = test.drop('ChanceOfAdmit', 1)\nfull = pd.concat([k, result], axis=1)\nfull = full.drop(full.index[0])\nfull","b268eae5":"full.describe()","7bfc74c8":"![linear](https:\/\/miro.medium.com\/max\/4800\/1*h6PuI6-PdPE8d4dTnhcg3w.png)","f6ed6c81":"![ok](https:\/\/i.pinimg.com\/originals\/82\/10\/4c\/82104c95f4e0250ed4aa66355be24a54.png)"}}