{"cell_type":{"3d9c65b2":"code","e16caad4":"code","07591fd9":"code","ce7b4326":"code","9afcab9f":"code","7ff4961c":"code","50ce7f25":"code","60ae4db3":"code","816d970e":"markdown","3dcb2884":"markdown","8101d38e":"markdown","bc2e6ec7":"markdown","342e2103":"markdown","9f757781":"markdown","d7ca7d03":"markdown","8b1af9ac":"markdown"},"source":{"3d9c65b2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom keras.models import load_model\nfrom keras.preprocessing import image\n\nfrom sklearn.preprocessing import LabelEncoder\nimport glob","e16caad4":"# Load the labels:\nlabels = pd.read_csv('..\/input\/geekhub-ds-2019-challenge\/{}'.format('train_labels.csv'))\n\n# Encoding:\nle = LabelEncoder(); \nlabels['Classes'] = le.fit_transform(labels['Category'])\n\n# Show classes:\nfor i, c in enumerate(le.classes_): \n    print(i, '=', c)\n    \n# Load the Data:\nanomaly_ids = {\n    4, 6, 11, 30, 32, 78, 79, 107, 167, 178, 200, 231, 257, 261, 288, 374, 435, 451,\n    462, 484, 561, 613, 711, 725, 750,  820, 843, 940, 974, 994, 974, 1037, 1169, \n    1207, 1217, 1269, 1271, 1306, 1337, 1365, 1368, 1378, 1427, 1437, 1468, 1587, \n    1610, 1659, 1685, 1722, 1759, 1830, 1834, 1859, 1871, 1893, 2011,  2119, 2135, \n    2198, 2203, 2308, 2366, 2370, 2453, 2460, 2461, 2520, 2525,  2543, 2461, 2520, \n    2525, 2552, 2606, 2616, 2621, 2635, 2666, 2708, 2733, 2753, 2764, 2829, 2922, \n    2990, 2977, 2937, 2651, 2912, 2720, 2765, 2821, 2947, 2977, 2195}\nX = []\nfor image_path in np.sort(glob.glob('..\/input\/geekhub-ds-2019-challenge\/train\/train'+\"\/*.jpg\")):\n    if int(image_path.split('\/')[-1][:-4]) not in anomaly_ids:\n        img = image.load_img(image_path, target_size=(299, 299))\n        img_data = image.img_to_array(img)\n        img_data = preprocess_input(img_data)\n        X.append(img_data)\n\nX = np.array(X)\ny = labels.drop(anomaly_ids, axis=0).Classes.values\n\nprint('\\nX_shape =', X.shape, '\\ny_shape =', y.shape, \n      '\\nShapes comformable =', X.shape[0] == y.shape[0])","07591fd9":"model = load_model('..\/input\/flowersnet\/flowers_full_model.h5')","ce7b4326":"y_pred_train = model.predict(X)\nbad_predictions = (y_pred_train.argmax(axis=1) != y)\nprint('Bad predictions:', sum(bad_predictions))","9afcab9f":"import lime\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nimport matplotlib.pyplot as plt\nimport random","7ff4961c":"explainer = lime_image.LimeImageExplainer(random_state=42)","50ce7f25":"%%time\nfig, ax = plt.subplots(5, 6, sharex='col', sharey='row')\nfig.set_figwidth(20)\nfig.set_figheight(16)\nindecies = random.sample(range(sum(bad_predictions)), 5)\nfor j in range(5):\n    explanation = explainer.explain_instance(X[bad_predictions][indecies[j]], \n                                             model.predict, \n                                             top_labels=5, hide_color=0, num_samples=1000, \n                                             random_seed=42)\n    ax[j,0].imshow(X[bad_predictions][indecies[j]])\n    ax[j,0].set_title(le.classes_[y[bad_predictions][indecies[j]]])\n    for i in range(5):\n        temp, mask = explanation.get_image_and_mask(i, positive_only=True, \n                                                    num_features=5, hide_rest=True)\n        ax[j,i+1].imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\n        ax[j,i+1].set_title('p({}) = {:.4f}'.format(le.classes_[i], y_pred_train[bad_predictions][indecies[j]][i]))","60ae4db3":"%%time\nfig, ax = plt.subplots(5, 6, sharex='col', sharey='row')\nfig.set_figwidth(20)\nfig.set_figheight(16)\nindecies = random.sample(range(X.shape[0]), 5)\nfor j in range(5):\n    explanation = explainer.explain_instance(X[indecies[j]], model.predict, \n                                             top_labels=5, hide_color=0, num_samples=1000, \n                                             random_seed=42)\n    ax[j,0].imshow(X[indecies[j]])\n    ax[j,0].set_title(le.classes_[y[indecies[j]]])\n    for i in range(5):\n        temp, mask = explanation.get_image_and_mask(i, positive_only=True, \n                                                    num_features=5, hide_rest=True)\n        ax[j,i+1].imshow(mark_boundaries(temp \/ 2 + 0.5, mask))\n        ax[j,i+1].set_title('p({}) = {:.4f}'.format(le.classes_[i], y_pred_train[indecies[j]][i]))","816d970e":"## Other Kernels\n\n* Eplaining XGB-Model with LIME **(tabular data)** [ [link](https:\/\/www.kaggle.com\/yohanb\/explaining-xgb-model-with-lime) ]\n* Explaining RF-Model with LIME **(text classifier)** [ [link](https:\/\/www.kaggle.com\/yohanb\/explaining-rf-model-with-lime) ] \n","3dcb2884":"## LIME (Local Interpretable Model-Agnostic Explanations)","8101d38e":"Explain 5 random bad predictions.","bc2e6ec7":"Explain 5 random predictions.","342e2103":"## References\n\n* **LIME** on GitHub [ [link](https:\/\/github.com\/marcotcr\/lime) ]\n* \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier (Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin) [ [link](https:\/\/arxiv.org\/abs\/1602.04938) ]","9f757781":"## Loading Pre-Trained Model (Inception-ResNet V2)\nFrom https:\/\/www.kaggle.com\/astrib\/flowersnet (output).","d7ca7d03":"## Loading Data (Train only)","8b1af9ac":"Predicting our labes."}}