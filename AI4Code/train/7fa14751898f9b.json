{"cell_type":{"9e189205":"code","4be3179d":"code","4025c52a":"code","ce50ac83":"code","d9801ab8":"code","4675ebf9":"code","33f06f3b":"code","1e6efa0e":"code","baf7259e":"code","27e91b3f":"code","1621d7f1":"code","da46ac21":"code","49131aba":"code","d3c8776f":"code","7038f543":"code","7ad9297d":"code","8dc402e3":"code","11b9c6ff":"code","d4187daa":"code","78c862a8":"code","939f8026":"code","7dc11d2d":"code","664148ae":"code","f9e9b1fc":"code","9bb6145c":"code","8d917f6f":"code","702b6d31":"code","d5d42f06":"code","d401c7a6":"code","26fe7b1b":"code","64d32de3":"markdown","d3e2bcaf":"markdown","ee4a03b8":"markdown","4e635571":"markdown"},"source":{"9e189205":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4be3179d":"# Read Data\nimport numpy as np                     # Linear Algebra (calculate the mean and standard deviation)\nimport pandas as pd                    # manipulate data, data processing, load csv file I\/O (e.g. pd.read_csv)\n\n# Visualization\nimport seaborn as sns                  # Visualization using seaborn\nimport matplotlib.pyplot as plt        # Visualization using matplotlib\n%matplotlib inline\nimport plotly                          # Visualization using Plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n# style\nplt.style.use(\"fivethirtyeight\")       # Set Graphs Background style using matplotlib\nsns.set_style(\"darkgrid\")              # Set Graphs Background style using seaborn\n\n# ML model building; Pre Processing & Evaluation\nfrom sklearn.model_selection import train_test_split                     # split  data into training and testing sets\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge          # Linear Regression, Lasso and Ridge\nfrom sklearn.linear_model import LogisticRegression                      # Logistic Regression\nfrom sklearn.tree import DecisionTreeRegressor                           # Decision tree Regression\nfrom sklearn.ensemble import RandomForestRegressor                       # this will make a Random Forest Regression\nfrom sklearn import svm                                                  # this will make a SVM classificaiton\nfrom sklearn.svm import SVC                                              # import SVC from SVM\nimport xgboost\nfrom sklearn.metrics import confusion_matrix, classification_report      # this creates a confusion matrix\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import roc_curve,auc                                # ROC\nfrom sklearn.preprocessing import StandardScaler                         # Standard Scalar\nfrom sklearn.model_selection import GridSearchCV                         # this will do cross validation\nfrom sklearn.decomposition import PCA                                    # to perform PCA to plot the data\n\nimport warnings                                                          # Ignore Warnings\nwarnings.filterwarnings(\"ignore\")","4025c52a":"# Import first 5 rows\ntrain = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")","ce50ac83":"display(train.head())\ndisplay(test.head())","d9801ab8":"# checking dimension (num of rows and columns) of dataset\nprint(\"Training data shape (Rows, Columns):\",train.shape)\nprint(\"Test data shape (Rows, Columns):\",test.shape)","4675ebf9":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntrain.info()","33f06f3b":"# check dataframe structure like columns and its counts, datatypes & Null Values\ntest.info()","1e6efa0e":"test.dtypes.value_counts()","baf7259e":"train['MSZoning'].value_counts()","27e91b3f":"# Listing Number of missing values by feature column wise\ntrain_missing = train.isnull().sum().sort_values(ascending=False)\ntrain_missing = train_missing[train_missing > 0]\ntrain_missing","1621d7f1":"# Listing Number of missing values by feature column wise\ntest_missing = test.isnull().sum().sort_values(ascending=False)\ntest_missing = test_missing[test_missing > 0]\ntest_missing","da46ac21":"plt.figure(figsize=(17,10))\nsns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')","49131aba":"# Percentage of Missing values in train dataset\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = ((train.isnull().sum()\/train.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","d3c8776f":"# Percentage of Missing values in train dataset\ntotal = test.isnull().sum().sort_values(ascending=False)\npercent = ((test.isnull().sum()\/test.isnull().count())*100).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, join='outer', keys=['Total Missing Count', '% of Total Observations'])\nmissing_data.index.name =' Numeric cols'\n\nmissing_data.head(20)","7038f543":"plt.figure(figsize = (14,12))\nplt.title('Correlation of Numeric Features with Sale Price', y=1, size=16)\nsns.heatmap(train.corr(), square = True, vmax=0.8)","7ad9297d":"# descriptive statistics (numerical columns)\ntrain.describe()","8dc402e3":"# Transform discrete values to columns with 1 and 0s\ntrain_OHE = pd.get_dummies(train)\n\n# Do the same for competition data\ntest_OHE = pd.get_dummies(test)","11b9c6ff":"display(train_OHE.head())\ndisplay(test_OHE.head())","d4187daa":"\nprint(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","78c862a8":"# There is a differece between features in the training data set and the test data set\n# We will try dropping the features that are not present in both sets\n\nmissingFeatures_train = list(set(train_OHE.columns.values) - set(test_OHE.columns.values))\ntrain_OHE = train_OHE.drop(missingFeatures_train, axis=1)\n\nmissingFeatures_test = list(set(test_OHE.columns.values) - set(train_OHE.columns.values))\ntest_OHE = test_OHE.drop(missingFeatures_test, axis=1)","939f8026":"print(\"Training Data Shape (Rows,Columns):\",train_OHE.shape)\nprint(\"Competition Data Shape (Rows,Columns):\", test_OHE.shape)","7dc11d2d":"# Independant variable\nX = train_OHE                     # All rows & columns exclude Target features\n\n# Dependant variable\ny = train['SalePrice']        # Only target feature","664148ae":"# split  data into training and testing sets of 80:20 ratio\n# 20% of test size selected\n# random_state is random seed\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)","f9e9b1fc":"# shape of X & Y test \/ train\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","9bb6145c":"import xgboost\nreg_xgb = xgboost.XGBRegressor()\nreg_xgb.fit(X_train,y_train)","8d917f6f":"# predicting X_test\ny_pred_xgb = reg_xgb.predict(X_test)","702b6d31":"print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))","d5d42f06":"df = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")","d401c7a6":"y_pred_test_OHE = reg_xgb.predict(test_OHE)","26fe7b1b":"submission = pd.DataFrame({'Id': df.Id, 'SalePrice': y_pred_test_OHE})\nsubmission.to_csv('Housing_submission.csv', index=False)","64d32de3":"### Model building and Evaluation\nOneHotEncoding","d3e2bcaf":"## Submission","ee4a03b8":"## XGBoost","4e635571":"### 3. EDA (Exploratory Data Analysis)"}}