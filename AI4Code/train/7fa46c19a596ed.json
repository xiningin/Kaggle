{"cell_type":{"973edb76":"code","ca34a17f":"code","01a5e58b":"code","4ebc2c63":"code","2cfa5f8c":"code","45f6b5c8":"code","afa088eb":"code","279fcca4":"code","f5316751":"code","39661eee":"code","4c9ff701":"code","9e5b1dbd":"code","c05c8443":"code","9190c249":"code","82c102c1":"markdown"},"source":{"973edb76":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport numpy as np\nimport os\nfrom os import listdir\nlistdir('..\/input')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom keras.utils import to_categorical\nimport sys\nimport os\nimport keras\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense, Activation\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.optimizers import Adam,SGD\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n","ca34a17f":"len(trainarr)","01a5e58b":"trainarr=[]\ntrainclass=[]\nvalarr=[]\nvalclass=[]\nfor count,i in enumerate(listdir('..\/input\/trainimage1\/')):\n    image=cv2.imread('..\/input\/trainimage1\/'+i)\n    image=cv2.resize(image,(224,224))\n    if count<25:\n        trainarr.append(image)\n        trainclass.append(0)\n    else: \n        valarr.append(image)\n        valclass.append(0)\nfor count,i in enumerate(listdir('..\/input\/trainimage2\/')):\n    image=cv2.imread('..\/input\/trainimage2\/'+i)\n    image=cv2.resize(image,(224,224))\n    if count<25:\n        trainarr.append(image)\n        trainclass.append(1)\n    else: \n        valarr.append(image)\n        valclass.append(1)  \n        \nfor count,i in enumerate(listdir('..\/input\/trainimage3\/')):\n    image=cv2.imread('..\/input\/trainimage3\/'+i)\n    image=cv2.resize(image,(224,224))\n    if count<25:\n        trainarr.append(image)\n        trainclass.append(2)\n    else: \n        valarr.append(image)\n        valclass.append(2)    \n\n\n\n","4ebc2c63":"valarr=np.array(valarr)","2cfa5f8c":"trainarr=np.array(trainarr)","45f6b5c8":"for count,i in enumerate(valarr):\n    valarr[count]=i\/255","afa088eb":"for count,i in enumerate(trainarr):\n    trainarr[count]=i\/255","279fcca4":"model = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(224, 224, 3), kernel_size=(11, 11), \\\n                 strides=(4, 4), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\nmodel.summary()\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11, 11), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='valid',data_format = 'channels_last'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape=(224 * 224 * 3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\n\nmodel.compile(\n    optimizer=Adam(lr=0.0001),\n    loss='categorical_crossentropy',\n    metrics=[categorical_crossentropy,\n             categorical_accuracy])\nmodel.summary()","f5316751":"model.fit(\ntrainarr,\ny,\nvalidation_data=(valarr,z),\nbatch_size=16,\nepochs=10\n)","39661eee":"y = to_categorical(trainclass, num_classes=3)","4c9ff701":"model.predict(valarr[3:5])","9e5b1dbd":"from matplotlib.pyplot import imshow\nimshow(trainarr[0])","c05c8443":"from os import listdir\nlistdir('..\/input\/trainimage1')","9190c249":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom os import listdir\nlistdir('..\/input')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport sys\nimport os\nimport keras\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense, Activation\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.optimizers import Adam,SGD\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n\n\n\n\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\n\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n    Only computes a batch-wise average of recall.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\n\ndef fbeta_score(y_true, y_pred, beta=1):\n    \"\"\"Computes the F score.\n    The F score is the weighted harmonic mean of precision and recall.\n    Here it is only computed as a batch-wise average, not globally.\n    This is useful for multi-label classification, where input samples can be\n    classified as sets of labels. By only using accuracy (precision) a model\n    would achieve a perfect score by simply assigning every class to every\n    input. In order to avoid this, a metric should penalize incorrect class\n    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n    computes this, as a weighted mean of the proportion of correct class\n    assignments vs. the proportion of incorrect class assignments.\n    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n    correct classes becomes more important, and with beta > 1 the metric is\n    instead weighted towards penalizing incorrect class assignments.\n    \"\"\"\n    if beta < 0:\n        raise ValueError('The lowest choosable beta is zero (only precision).')\n\n    # If there are no true positives, fix the F score at 0 like sklearn.\n    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n        return 0\n\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    bb = beta ** 2\n    fbeta_score = (1 + bb) * (p * r) \/ (bb * p + r + K.epsilon())\n    return fbeta_score\n\n\ndef fmeasure(y_true, y_pred):\n    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n    Here it is only computed as a batch-wise average, not globally.\n    \"\"\"\n    return fbeta_score(y_true, y_pred, beta=1)\n\n\ndef categorical_crossentropy(y_true, y_pred):\n    return K.mean(K.categorical_crossentropy(y_pred, y_true))\n\n\n\n\"\"\"\nParameters\n\"\"\"\nimg_width, img_height = 224, 224\nbatch_size = 32\nsamples_per_epoch = 75\nvalidation_steps = 1806\nnb_filters1 = 32\nnb_filters2 = 64\nconv1_size = 3\nconv2_size = 2\npool_size = 2\nclasses_num = 3\nlr = 0.0004\ndecay=0.1\nepochs = 2\n\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(224, 224, 3), kernel_size=(11, 11), \\\n                 strides=(4, 4), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\nmodel.summary()\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11, 11), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='valid',data_format = 'channels_last'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape=(224 * 224 * 3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=lr),\n              metrics=['accuracy', precision, recall, fmeasure])\nmodel.compile(\n    optimizer=Adam(lr=0.0001),\n    loss='categorical_crossentropy',\n    metrics=[categorical_crossentropy,\n             categorical_accuracy])\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    )\n\ntest_datagen = ImageDataGenerator(validation_split=0.3,rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(directory=r\"..\/input\",\n    target_size=(img_height, img_width),\n    color_mode='rgb',\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    directory=r\"..\/input\",\n    color_mode='rgb',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation')\n\n\"\"\"\nTensorboard log\n\"\"\"\nlog_dir = '.\/tf-log\/'\ntb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, update_freq='batch')\nfilepath = '.\/models\/weights.{epoch:02d}-{val_loss:.2f}.h5'\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False,\n                                             save_weights_only=False, mode='auto', period=5)\ncbks = [tb_cb, checkpoint]\nmodel.summary()\n\nmodel.fit_generator(\n    train_generator,\n    samples_per_epoch=samples_per_epoch,\n    epochs=epochs,\n    validation_data=validation_generator,\n    callbacks=cbks,\n    validation_steps=validation_steps)\n\n\n\ntarget_dir = '.\/models\/'\nif not os.path.exists(target_dir):\n    os.mkdir(target_dir)\nmodel.save('.\/models\/model.h5')\nmodel.save_weights('.\/models\/face_detect_weights.h5')\n","82c102c1":"z = to_categorical(valclass, num_classes=3)"}}