{"cell_type":{"66b8ad7d":"code","0efe2bc5":"code","54d91146":"code","314fe6b4":"code","6c31d261":"code","781d9f63":"code","769b2d52":"code","a28ca561":"code","59da8e32":"code","2cb4ce63":"code","18cc856f":"code","517c790b":"code","95125060":"code","6bdce3b7":"code","9c8abac7":"code","49014d78":"code","6d406c25":"code","51c5afac":"code","47b092f3":"code","cd2ec887":"code","b2a8cad6":"code","2652eaf9":"code","76911ff7":"code","cb2363e2":"code","fe5a6695":"code","fcfc2eba":"code","a0c38043":"code","bd8bc69a":"code","20adc2c3":"code","a019ab65":"code","3ece4a49":"code","42b2d75f":"code","dadcb273":"code","27762edf":"code","2b992729":"code","fd110aef":"code","2d2ff368":"code","66a38b2a":"code","12a9593f":"code","33bb5be1":"code","6601ae34":"code","7f87566f":"code","7d1e2e89":"code","feb7eb1e":"code","4c07f0e0":"code","16c7efa0":"code","b8f178a3":"code","4aeeedc8":"markdown","2f6f5f00":"markdown","4f231a8b":"markdown","3472eb70":"markdown","8fe7aefd":"markdown","785db35c":"markdown","889fb959":"markdown","3808a0d3":"markdown"},"source":{"66b8ad7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0efe2bc5":"import matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams[\"figure.figsize\"] = 20,15\n#importin the dataset for Gold price\nG = pd.read_csv(\"\/kaggle\/input\/gold-and-nifty50-20002020\/Gold.csv\")\nG[\"Date\"] = pd.to_datetime(G[\"Date\"], infer_datetime_format=True)\niG = G.set_index([\"Date\"])#iG is just Indexed as date for Gold price(Indexed gold= iG)\n#importing the datset for NIFTY50\nN = pd.read_csv(\"\/kaggle\/input\/gold-and-nifty50-20002020\/Nifty.csv\")\nN[\"Date\"] = pd.to_datetime(N[\"Date\"], infer_datetime_format=True)\niN = N.set_index([\"Date\"])#similar to gold naming","54d91146":"iN.head()","314fe6b4":"iN.shape","6c31d261":"iG.head()","781d9f63":"iG.shape","769b2d52":"plt.xlabel(\"Months\")\nplt.ylabel(\"Price\")\nplt.plot(iN)","a28ca561":"plt.xlabel(\"Months\")\nplt.ylabel(\"Price\")\nplt.plot(iG)","59da8e32":"#Determine Rolling statistics\n\nGrm = iG.rolling(window=12).mean()#gold rolling mean = Grm\nNrm = iN.rolling(window=12).mean()#NIFTY50 rolling mean = Nrm\nGrs = iG.rolling(window=12).std()#Gold rolling standard deviation = Grs\nNrs = iN.rolling(window=12).std()#NIFTY50 rolling standard deviation = Nrs\nprint(\"for gold : \\t\",Grm,Grs)\nprint(\"for NIFTY : \\t\",Nrm,Nrs)","2cb4ce63":"#plot Gold and its rm, rs\nOriginal = plt.plot(iG, color=\"Blue\", label=\"Original\")\nMean = plt.plot(Grm, color=\"Red\", label=\"Rolling mean\")\nstd = plt.plot(Grs, color=\"Black\", label=\"Rolling Std\")\nplt.legend(loc=\"best\")\nplt.title(\" GOLD Rolling Mean and Standard Deviation\")\nplt.show(block=False)","18cc856f":"#plot NIFTY50 and its rm, rs\nOriginal = plt.plot(iN, color=\"Blue\", label=\"Original\")\nMean = plt.plot(Nrm, color=\"Red\", label=\"Rolling mean\")\nstd = plt.plot(Nrs, color=\"Black\", label=\"Rolling Std\")\nplt.legend(loc=\"best\")\nplt.title(\"NIFTY50 Rolling Mean and Standard Deviation\")\nplt.show(block=False)","517c790b":"from statsmodels.tsa.stattools import adfuller \n#defining a function to test both rolling statistics and Dickey fuller test\ndef ad_test(dataset):\n    print(\"Result of Dickey-Fuller Test :\")\n    dftest = adfuller(dataset, autolag= \"AIC\") #Akaike Information Criterion (AIC) or Bayesian Information Criteria (BIC) to determine how many lags to consider, as described in Comparing ARIMA Models. Thus we can now use the full version of the ADFTEST function which was introduced in Dickey-Fuller Test.\n    dfval = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"No. of Lags used\", \"No. of observations used for ADF Regression and Critical values Calculation\"])\n    for key, val in dftest[4].items():\n        dfval[\"Critical Value (%s)\" %key] = val\n    print(dfval) \n    \n    print(\"To Determine Rolling Statistics\")\n    rm = dataset.rolling(window=12).mean()\n    rs = dataset.rolling(window=12).std()\n    \n    #plot the rolling statistics\n    o = plt.plot(dataset, color = \"blue\", label = \"Original\")\n    m = plt.plot(rm, color = \"red\", label = \"Rolling mean\")\n    s = plt.plot(rs, color = \"Black\", label = \"Rolling Std. Dev.\")\n    plt.legend(loc=\"best\")\n    plt.show(block=False)","95125060":"ad_test(iG)","6bdce3b7":"ad_test(iN)\n#p-values < 0.05 Means dataset is stationary.\n#critical value > test statistic","9c8abac7":"#log of indexed gold(i.e. \"iG\") = liG\nliG = np.log(iG)\nplt.plot(liG)","49014d78":"#log of indexed NIFTY50(i.e. \"iN\") = liN\nliN = np.log(iN)\nplt.plot(liN)","6d406c25":"lGrm = liG.rolling(window=12).mean()\nlGrs = liG.rolling(window=12).std()\nplt.plot(liG)\nplt.plot(lGrm, color=\"red\")","51c5afac":"lNrm = liN.rolling(window=12).mean()\nlNrs = liN.rolling(window=12).std()\nplt.plot(liN)\nplt.plot(lNrm, color=\"red\")","47b092f3":"#adjusted Gold = aG\naG = liG-lGrm\naG.head(12)","cd2ec887":"#remove NaN values\naG.dropna(inplace = True)\naG.head(10)","b2a8cad6":"#adjusted NIFTY50 = aN\naN = liN-lNrm\naN.head(12)","2652eaf9":"#remove NaN values\naN.dropna(inplace = True)\naN.head(10)","76911ff7":"ad_test(aN)","cb2363e2":"ad_test(aG)","fe5a6695":"# I ran out of creativity by here, its just bG, with no specific meaning but in case, \"b\" is just another transformation i.e. subtracting by lag\nbG = liG - liG.shift()\nplt.plot(bG)","fcfc2eba":"# I ran out of creativity by here, its just bN, with no specific meaning but in case, just \"b\" is just another transformation i.e. subtracting by lag\nbN = liN - liN.shift()\nplt.plot(bN)","a0c38043":"bG.dropna(inplace=True)\nbN.dropna(inplace=True)","bd8bc69a":"ad_test(bG)","20adc2c3":"ad_test(bN)","a019ab65":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(liG, period=12)\n#to check the seasonality of log of Original dataset\nG_trend = decomposition.trend\nG_seasonal = decomposition.seasonal\nG_residual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(liG, label=\"Original\")\nplt.legend(loc=\"best\")\nplt.subplot(412)\nplt.plot(G_trend, label = \"Trend\")\nplt.legend(loc=\"best\")\nplt.subplot(413)\nplt.plot(G_seasonal, label=\"Seasonality\")\nplt.legend(loc=\"best\")\nplt.subplot(414)\nplt.plot(G_residual, label=\"Residuals\")\nplt.legend(loc=\"best\")\nplt.tight_layout()\n\ndldG = G_residual\ndldG.dropna(inplace=True)\nad_test(dldG)","3ece4a49":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(liN, period=12)\n#to check the seasonality of log of Original dataset\nN_trend = decomposition.trend\nN_seasonal = decomposition.seasonal\nN_residual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(liN, label=\"Original\")\nplt.legend(loc=\"best\")\nplt.subplot(412)\nplt.plot(N_trend, label = \"Trend\")\nplt.legend(loc=\"best\")\nplt.subplot(413)\nplt.plot(N_seasonal, label=\"Seasonality\")\nplt.legend(loc=\"best\")\nplt.subplot(414)\nplt.plot(N_residual, label=\"Residuals\")\nplt.legend(loc=\"best\")\nplt.tight_layout()\n\ndldN = N_residual\ndldN.dropna(inplace=True)\nad_test(dldN)","42b2d75f":"#storing the residual of log of original dataset\nrG = G_residual\nrG.dropna(inplace=True)\nad_test(rG)","dadcb273":"#storing the residual of log of original dataset\nrN = N_residual\nrN.dropna(inplace=True)\nad_test(rN)","27762edf":"from statsmodels.tsa.stattools import acf,pacf\n#to get the value of p and q for ARIMA(p,d,q),by using graph.\n\nG_lag_acf = acf(bG, nlags=20, fft=False)\nG_lag_pacf = pacf(bG, nlags=20, method=\"ols\")#ordinary least square method\n\n#plot ACF: #value of q\nplt.subplot(121)\nplt.plot(G_lag_acf)\nplt.axhline(y=0, linestyle=\"--\", color=\"gray\")\nplt.axhline(y=-1.96\/np.sqrt(len(bG)),linestyle=\"--\", color=\"gray\")\nplt.axhline(y=1.96\/np.sqrt(len(bG)),linestyle=\"--\", color=\"gray\")\nplt.grid()\nplt.title(\"Autocorrelation Function\")\n\n#plot PACF #value of p\nplt.subplot(122)\nplt.plot(G_lag_pacf)\nplt.axhline(y=0, linestyle=\"--\", color=\"gray\")\nplt.axhline(y=-1.96\/np.sqrt(len(bG)),linestyle=\"--\", color=\"gray\")\nplt.axhline(y=1.96\/np.sqrt(len(bG)),linestyle=\"--\", color=\"gray\")\nplt.grid()\nplt.title(\"Partial Autocorrelation Function\")\nplt.tight_layout()","2b992729":"from statsmodels.tsa.stattools import acf,pacf\n#to get the value of p and q for ARIMA(p,d,q),by using graph.\n\nN_lag_acf = acf(bN, nlags=20, fft=False)\nN_lag_pacf = pacf(bN, nlags=20, method=\"ols\")#ordinary least square method\n\n#plot ACF: #value of q\nplt.subplot(121)\nplt.plot(N_lag_acf)\nplt.axhline(y=0, linestyle=\"--\", color=\"gray\")\nplt.axhline(y=-1.96\/np.sqrt(len(bN)),linestyle=\"--\", color=\"gray\")\nplt.axhline(y=1.96\/np.sqrt(len(bN)),linestyle=\"--\", color=\"gray\")\nplt.grid()\nplt.title(\"Autocorrelation Function\")\n\n#plot PACF #value of p\nplt.subplot(122)\nplt.plot(N_lag_pacf)\nplt.axhline(y=0, linestyle=\"--\", color=\"gray\")\nplt.axhline(y=-1.96\/np.sqrt(len(bN)),linestyle=\"--\", color=\"gray\")\nplt.axhline(y=1.96\/np.sqrt(len(bN)),linestyle=\"--\", color=\"gray\")\nplt.grid()\nplt.title(\"Partial Autocorrelation Function\")\nplt.tight_layout()","fd110aef":"#to get the value of p,d,q from algorithm","2d2ff368":"pip install pmdarima","66a38b2a":"from pmdarima import auto_arima\n#ignore harmless warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","12a9593f":"#to know the best order\nG_of = auto_arima(bG,d=1, trace = True, suppress_warnings=True)\nG_of.summary()","33bb5be1":"#to know the best order\nN_of = auto_arima(bN,d=1, trace = True, suppress_warnings=True)\nN_of.summary()\n","6601ae34":"from statsmodels.tsa.arima_model import ARIMA\n#AR model\nG_model = ARIMA(bG, order=(1,1,1))#by using the values from pmdarima.auto_arima() function\nG_results_AR = G_model.fit(disp=-1)\nplt.plot(bG)\nplt.plot(G_results_AR.fittedvalues, color=\"red\")\nplt.title(\"RSS: %.4f\"% sum((G_results_AR.fittedvalues-bG[\"Price\"])**2))#residual sum of square\nprint(\"Plotting AR model\")\nG_results_AR.summary()","7f87566f":"#AR model\nN_model = ARIMA(bN, order=(1,1,1))#by using the values from the graph\nN_results_AR = N_model.fit(disp=-1)\nplt.plot(bN)\nplt.plot(N_results_AR.fittedvalues, color=\"red\")\nplt.title(\"RSS: %.4f\"% sum((N_results_AR.fittedvalues-bN[\"Price\"])**2))#residual sum of square\nprint(\"Plotting AR model\")\nN_results_AR.summary()","7d1e2e89":"#RSS","feb7eb1e":"G_pred = pd.Series(G_results_AR.fittedvalues, copy=True)\nprint(G_pred.head())","4c07f0e0":"#convert to cumulative sum\nG_pred_cumsum = G_pred.cumsum()\nprint(G_pred_cumsum.head())","16c7efa0":"lG_pred = pd.Series(bG[\"Price\"].iloc[0], index=bG.index)\nlG_pred = lG_pred.add(G_pred_cumsum,fill_value = 0)\nlG_pred.head()","b8f178a3":"G_pred_ARIMA= np.exp(lG_pred)\nplt.plot(iG)\nplt.plot(G_pred_ARIMA)","4aeeedc8":"FIRSTLY WE IMPORT THE DATA AND USE DATE AS INDEX.","2f6f5f00":"# DATA","4f231a8b":"WE will use the value of p and q from whichever is giving the least value of RSS.#ignoring it","3472eb70":"p = 1 and q = 1 from the above graph.","8fe7aefd":"q = 1 and p = 1 from the above graph.","785db35c":"NOW TO SEE THE DATA.","889fb959":"VISUALIZING THE DATA.","3808a0d3":"Our data is not stationary from the above 2 graphs."}}