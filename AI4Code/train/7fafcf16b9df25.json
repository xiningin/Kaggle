{"cell_type":{"d4a19891":"code","a84d8ce1":"code","aa5cf957":"code","016d04e4":"code","07c2dae0":"code","3bb99e3a":"code","67c0caea":"code","012c60eb":"code","f68e027a":"code","b688c48b":"code","f4c13e62":"code","c408a1f8":"code","2ce68a4d":"markdown"},"source":{"d4a19891":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nimport cv2\nplt.style.use('ggplot')\nfrom IPython.display import Video\nfrom IPython.display import HTML","a84d8ce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","aa5cf957":"# SKLearn Implemention\nfrom sklearn.metrics import log_loss\nlog_loss([\"REAL\", \"FAKE\", \"FAKE\", \"REAL\"],\n         [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])","016d04e4":"!ls -GFlash ..\/input\/deepfake-detection-challenge","07c2dae0":"!du -sh ..\/input\/deepfake-detection-challenge\/","3bb99e3a":"train_sample_metadata = pd.read_json('..\/input\/deepfake-detection-challenge\/train_sample_videos\/metadata.json').T\ntrain_sample_metadata.head()","67c0caea":"train_sample_metadata.groupby('label')['label'].count().plot(figsize=(15, 5), kind='bar', title='Distribution of Labels in the Training Set')\nplt.show()","012c60eb":"import cv2 as cv\nimport os\nimport matplotlib.pylab as plt\ntrain_dir = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/'\nfig, ax = plt.subplots(1,1, figsize=(15, 15))\ntrain_video_files = [train_dir + x for x in os.listdir(train_dir)]\n# video_file = train_video_files[30]\nvideo_file = '\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/akxoopqjqz.mp4'\ncap = cv.VideoCapture(video_file)\nsuccess, image = cap.read()\nimage = cv.cvtColor(image, cv.COLOR_BGR2RGB)\ncap.release()   \nax.imshow(image)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\nax.title.set_text(f\"FRAME 0: {video_file.split('\/')[-1]}\")\nplt.grid(False)","f68e027a":"!pip install face_recognition","b688c48b":"import face_recognition\nface_locations = face_recognition.face_locations(image)\n\n# https:\/\/github.com\/ageitgey\/face_recognition\/blob\/master\/examples\/find_faces_in_picture.py\nfrom PIL import Image\n\nprint(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n\nfor face_location in face_locations:\n\n    # Print the location of each face in this image\n    top, right, bottom, left = face_location\n    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n\n    # You can access the actual face itself like this:\n    face_image = image[top:bottom, left:right]\n    fig, ax = plt.subplots(1,1, figsize=(5, 5))\n    plt.grid(False)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n    ax.imshow(face_image)","f4c13e62":"ss = pd.read_csv(\"\/kaggle\/input\/deepfake-detection-challenge\/sample_submission.csv\")\nss['label'] = 0.5\nss.loc[ss['filename'] == 'aassnaulhq.mp4', 'label'] = 0 # Guess the true value\nss.loc[ss['filename'] == 'aayfryxljh.mp4', 'label'] = 0\nss.to_csv('submission.csv', index=False)","c408a1f8":"ss.head()","2ce68a4d":"## Locating a face within an image"}}