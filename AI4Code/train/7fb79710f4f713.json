{"cell_type":{"357b1a97":"code","19e0ebb1":"code","1c382466":"code","a276a446":"code","67cd7d8a":"code","c03967d1":"code","15fd67d5":"code","bc1b1914":"code","e140159b":"code","fcb34864":"code","a563f365":"code","0d337d5a":"code","87f6ef16":"code","71d8fb27":"code","759a03c2":"code","17c36739":"code","1cfbba8d":"markdown","5028e561":"markdown","7ad3bc54":"markdown","c201293c":"markdown","8b07a311":"markdown","b506cba0":"markdown"},"source":{"357b1a97":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom zipfile import ZipFile\nimport tensorflow as tf\nsns.set()","19e0ebb1":"## Configuration Class\nclass config:\n    batch_size = 32\n    image_size = (256, 256) ## Size of the image\n    validation_split = 0.2\n    patterns = os.listdir(\"..\/input\/candle-data\/candle_images\")\n    ## Image directory Path\n    img_dir = \"..\/input\/candle-data\/candle_images\"  \n    epochs = 5","1c382466":"## Read train data from image directory \nds_train = tf.keras.preprocessing.image_dataset_from_directory(\n    config.img_dir,\n    labels = \"inferred\",\n    label_mode = \"categorical\",\n    class_names = config.patterns,\n    color_mode = \"rgb\",\n    batch_size = config.batch_size,\n    image_size = config.image_size,\n    shuffle = True,\n    seed = 123,\n    validation_split = config.validation_split,\n    subset = \"training\"\n)\n\n## Read validation data from image directory \nds_val = tf.keras.preprocessing.image_dataset_from_directory(\n    config.img_dir,\n    labels = \"inferred\",\n    label_mode = \"categorical\",\n    class_names = config.patterns,\n    color_mode = \"rgb\",\n    batch_size = config.batch_size,\n    image_size = config.image_size,\n    shuffle = True,\n    seed = 123,\n    validation_split = config.validation_split,\n    subset = \"validation\"\n)","a276a446":"## Perform autotuning to increase model performance\nAUTOTUNE = tf.data.AUTOTUNE\nds_train = ds_train.prefetch(buffer_size = AUTOTUNE)\nds_val = ds_val.prefetch(buffer_size = AUTOTUNE)","67cd7d8a":"## Function to build model architecture\ndef build_model(img_shape = (256, 256)):\n    \n    print(\"[INFO] loading network...\")\n    \n    ## load the VGG16 network\n    base_model = tf.keras.applications.VGG16(include_top = False, weights='imagenet')\n    \n    ## Freeze all VGG16 layers \n    base_model.trainable = False\n    \n    ## input image shape\n    img_shape = img_shape + (3,)\n    inputs = tf.keras.Input(shape=(img_shape))\n  \n    ## Preprocessing layer of VGG16 \n    preprocess_input = tf.keras.applications.vgg16.preprocess_input\n    x = preprocess_input(inputs)\n    \n    ## layer to perform scaling \n    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n    x = normalization_layer(x)\n    \n    ## perform feature extraction\n    x = base_model(x)\n\n    ## Custom CNN model \n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(8, activation='softmax')(x)\n    \n    ## Functional API\n    model_transfer = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"vgg16_features_model\")\n\n    ## Compile the model\n    model_transfer.compile(loss = 'categorical_crossentropy', \n                      optimizer = tf.keras.optimizers.Adam(0.01),\n                      metrics = ['accuracy'])\n\n    ## print the model summary\n    print(model_transfer.summary(), \"\\n\")\n\n    return model_transfer","c03967d1":"## To run on CPU\ndef cpu(device_name, ds_train, ds_val):\n    with tf.device(device_name):\n        model_transfer = build_model()\n        history = model_transfer.fit(ds_train, \n                                     batch_size = config.batch_size, \n                                     epochs = config.epochs,\n                                     validation_data = ds_val,\n                                     verbose = 2, \n                                     shuffle = True)\n        return model_transfer, history\n\n## To run on GPU \ndef gpu(device_name, ds_train, ds_val):\n    with tf.device(device_name):\n        model_transfer = build_model()\n        history = model_transfer.fit(ds_train, \n                                     batch_size = config.batch_size, \n                                     epochs = config.epochs,\n                                     validation_data = ds_val,\n                                     verbose = 2, \n                                     shuffle = True)\n        return model_transfer, history","15fd67d5":"## Check for GPU devices else run on CPU\nif len(tf.config.list_physical_devices('GPU')) != 0:\n    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n    device_name = tf.test.gpu_device_name()\n    \n    print(\"Running on GPU\", device_name)\n    model_transfer, history = gpu(device_name, ds_train, ds_val)\nelse:\n    device_name = \"\/device:CPU:0\"\n    print(\"Running on CPU:\", device_name)\n    model_transfer, history = cpu(device_name, ds_train, ds_val)","bc1b1914":"# Function to plot loss and binary accuracy of training and validation set  \ndef plot_results(history, epochs, FE_name = \"VGG16\", model_name = \"vgg16_fe\", version = 1):\n   \n    ## Create the dataframe\n    data = pd.DataFrame()\n    data[\"Epoch\"] = [i for i in range(epochs)]\n    data[\"loss\"] = history.history[\"loss\"]\n    data[\"val_loss\"] = history.history[\"val_loss\"]\n    data[\"accuracy\"] = history.history[\"accuracy\"]\n    data[\"val_accuracy\"] = history.history[\"val_accuracy\"]\n\n    ## Create subplots\n    fig, ax = plt.subplots(1, 2, figsize = (18, 8))\n\n    ## Show title\n    fig.suptitle(f\"{FE_name} as Feature Extractor Performance\", color = \"red\")\n\n    ## plot loss\n    sns.lineplot(x = \"Epoch\", y = \"loss\", data = data, ax = ax[0])\n    sns.lineplot(x = \"Epoch\", y = \"val_loss\", data = data, ax = ax[0])\n    ax[0].legend([\"train_loss\", \"val_loss\"], loc='best')\n    ax[0].title.set_text(\"Categorical Cross Entropy\")\n\n    ## plot accuracy\n    sns.lineplot(x = \"Epoch\", y = \"accuracy\", data = data, ax = ax[1])\n    sns.lineplot(x = \"Epoch\", y = \"val_accuracy\", data = data, ax = ax[1])\n    ax[1].legend([\"train_accuracy\", \"val_accuracy\"], loc='best')\n    ax[1].title.set_text(\"Categorical Accuracy\")\n\n    ## Remove padding\n    fig.tight_layout()\n    \n    # Save accuracy plot\n    os.makedirs(f\".\/models\", exist_ok = True)\n    plt.savefig(f\".\/models\/{model_name}_performance.png\")\n\n    plt.show()\n\nplot_results(history, epochs = config.epochs, FE_name = \"VGG16\", model_name = \"vgg16_fe\")","e140159b":"## Create annotations \nannotations = dict(zip([i for i in range(len(config.patterns))], config.patterns))\nannotations","fcb34864":"import os\nimport pickle\n\n## Function to save model related files\ndef save_model_and_annotations(model, annotations, model_dir = \".\/models\", model_name = \"vgg16_fe\",\n                               annotations_file = \"annotations.pickle\"):\n    ## Save whole model\n    os.makedirs(model_dir, exist_ok = True)\n    model_transfer.save(f'{model_dir}\/{model_name}')\n    \n    ## Save annotations\n    with open(f\".\/{model_dir}\/{annotations_file}\", 'wb') as handle: \n        pickle.dump(annotations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    ## Save model architecture\n    tf.keras.utils.plot_model(model, to_file = f\".\/{model_dir}\/model_architecture.png\", show_shapes=True)\n    \nsave_model_and_annotations(model_transfer, annotations, model_dir = \".\/models\", \n                           model_name = \"vgg16_fe\", annotations_file = \"annotations.pickle\")","a563f365":"## Make ZIP file of output\nimport shutil \nshutil.make_archive(\"vgg16_feature_extractor\", 'zip', \".\/models\")","0d337d5a":"from tqdm.auto import tqdm\nfrom sklearn.metrics import classification_report\n\nclass Tester:\n    def __init__(self, model, images_paths, images_to_test = 10):\n        self.images_paths = images_paths\n        self.model = model\n        self.images_to_test = images_to_test\n        \n        self.test(self.create_actual())\n        \n    def create_actual(self):\n        test_images, test_labels, test_counter = [], [], 0\n        for pattern in config.patterns:\n            dir_path = f\"{images_paths}\/{pattern}\"\n            for dir in tqdm(os.listdir(dir_path)[:self.images_to_test]):\n                image_path = f\"{dir_path}\/{dir}\"\n                image = Image.open(image_path)\n                image = image.resize(config.image_size)\n                image = image.convert(\"RGB\")\n                image = np.asarray(image)\n\n                test_images.append(image)\n                test_labels.append(test_counter)\n        \n            test_counter += 1\n        \n        test_images = np.asarray(test_images)\n        self.test_labels = np.asarray(test_labels)\n        \n        return test_images\n    \n    def test(self, test_images):\n        predictions = []\n        for image in tqdm(test_images):\n            image = np.asarray(image, dtype=np.float32)\n            pred_ = self.model.predict(np.array([image]))\n            predictions.append(np.argmax(pred_))\n    \n        self.test_predictions = np.asarray(predictions)\n        \n    def generate_classification_report(self):\n        print(classification_report(self.test_labels, self.test_predictions, \n                                    target_names = config.patterns))","87f6ef16":"images_paths = \"..\/input\/test-data\/SP_test_images\"\ntester = Tester(model_transfer, images_paths, images_to_test = 400)\ntester.generate_classification_report()","71d8fb27":"!pip install -q mplfinance\n!pip install -q yfinance","759a03c2":"import os\nfrom tqdm.auto import tqdm\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport mplfinance as mpf\nimport yfinance as yf\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\n\nclass AutoTester:\n    \n    rc =  {'axes.labelcolor': '#101010',\n                            'axes.edgecolor' : 'f0f0f0',\n                            'axes.grid.axis' : 'y',\n                            'ytick.color'    : '#a02128',\n                            'xtick.color'    : '#006340'\n                        }\n\n    mc = mpf.make_marketcolors(edge='white', up ='#006340', down = '#a02128', wick={'up':'#006340','down':'#a02128'})\n\n    style  = mpf.make_mpf_style(marketcolors = mc, rc = rc, gridcolor = '#a02128')\n    \n    def __init__(self, stock_name : str, model, annotations = None,\n                 timestamp : int = 0, period : str = \"10d\", no_of_candles : int = 10,  image_size = (256, 256)\n                ):\n        \n        self.stock_name = stock_name\n        self.timestamp = timestamp\n        self.period = period\n        self.no_of_candles = no_of_candles\n        self.image_size = image_size\n        \n        self.model = model\n        self.annotations = annotations\n        \n        \n        # Get historical data of stock\n        self.historical_data = self.get_historical_data()\n        self.historical_data['Predictions'] = self.get_images(self.image_size)\n    \n    def get_images(self, image_size):\n        \n        predicted = [\"-\" for i in range(self.historical_data.shape[0])]\n        for index in tqdm(range(self.no_of_candles - 3)):\n            \n            self.plot(index)\n            \n            image = Image.open(f\".\/temp_{index}.png\")\n            image = image.resize(image_size)\n            image = image.convert(\"RGB\")\n            image = np.asarray(image, dtype = np.float32)\n            \n            pred_ = self.predict(image)\n            predicted[index + 2] = pred_\n        \n        return predicted\n    \n    def predict(self, image):\n        \n        pred = self.model.predict(np.array([image]))\n        pred_max_ = np.argmax(pred)\n        \n        if pred[0][pred_max_] < 0.7:\n            return \"No\"\n        \n        return self.annotations[pred_max_]\n    \n    \n    def get_historical_data(self):\n     \n        stock_ = yf.Ticker(self.stock_name)\n        \n        # get historical market data\n        historical_data = stock_.history(period = self.period)\n        \n        return historical_data\n\n    def get_dates(self, data):\n        \n        year, month, day = str(data.index[0]).split(\"-\")\n        datetimeobj = datetime(int(year), int(month), int(day[0]), 0, 0, 0)\n        dates = [(datetimeobj - timedelta(days=i)).date() for i in range(data.shape[0])]\n        data['Date'] = dates\n        \n        data.set_index('Date', inplace = True)\n        return data\n    \n    def plot(self, index):\n        data = self.historical_data.iloc[index:index+3,:]\n        data.index = ['2020-08-01', '2020-08-02', '2020-08-03']\n        data.index = pd.to_datetime(data.index)\n            \n        mpf.plot(data, style = self.style, type = \"candle\", show_nontrading=True, axisoff=True, scale_padding = 0.0, \n                        savefig = f\".\/temp_{index}.png\")\n","17c36739":"auto_tester = AutoTester(\"SBIN.NS\", model_transfer, annotations = annotations)\nauto_tester.historical_data.head(10)","1cfbba8d":"## Testing on unknown data","5028e561":"<a id='Read_Data'><\/a>\n## 2. Read the Data","7ad3bc54":"## Real Time Testing","c201293c":"<a id='Build_Model'><\/a>\n## 3. Build The Model","8b07a311":"# BE Project : Stock Market Analysis using Deep Learning\n<hr>\n\n## Team Members\n\n- A 702 Arun Addagatla\n- A 704 Sanamdeep Singh\n- A 705 Saumit Andhari\n\n**Guide :** Prof. Dilip M. Dalgade","b506cba0":"<a id='import_packages'><\/a>\n## 1. Import Packages"}}