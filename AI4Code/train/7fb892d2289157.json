{"cell_type":{"1f9bad04":"code","0efc5d7f":"code","39c03aca":"code","e9f9c6ae":"code","a0006df8":"code","6fbdd7f9":"code","5208eff0":"code","faae96b5":"code","7d41a0f7":"code","2f4ea24b":"code","fb0d7840":"code","4a7311bc":"code","a3e96ef2":"code","fc8688ef":"code","9c9debc9":"code","6a3ff958":"code","14c364d2":"code","cd0c6abb":"markdown","afcd1bfc":"markdown","7aa6b4bf":"markdown","1d55c385":"markdown","8152afa7":"markdown","6e8e5971":"markdown","276cc870":"markdown","07172638":"markdown","8d8e2cb1":"markdown","8c439d56":"markdown","a9d8a0de":"markdown","84d73d8b":"markdown","25f87e51":"markdown","bada4aaa":"markdown"},"source":{"1f9bad04":"import numpy as np\nimport pandas as pd","0efc5d7f":"trainData = pd.read_csv('..\/input\/train.csv')\ntestData = pd.read_csv(\"..\/input\/test.csv\")","39c03aca":"print(trainData.dtypes.sort_values())\nprint(testData.dtypes.sort_values())","e9f9c6ae":"trainData.isnull().sum()[trainData.isnull().sum()>0]","a0006df8":"testData.isnull().sum()[testData.isnull().sum()>0]","6fbdd7f9":"trainData.Age=trainData.Age.fillna(trainData.Age.mean())\ntestData.Age=testData.Age.fillna(trainData.Age.mean())\n\ntrainData.Fare=trainData.Fare.fillna(trainData.Fare.mean())\ntestData.Fare=testData.Fare.fillna(trainData.Fare.mean())\n\n\ntrainData.Embarked=trainData.Embarked.fillna(trainData.Embarked.mode()[0])\ntestData.Embarked=testData.Embarked.fillna(trainData.Embarked.mode()[0])","5208eff0":"trainData.head()\ntestData.head()\n","faae96b5":"trainData.drop(['PassengerId','Name','Cabin','Ticket'],axis=1,inplace=True)\ntestData.drop(['PassengerId','Name','Cabin','Ticket'],axis=1,inplace=True)","7d41a0f7":"testData.head()\n","2f4ea24b":"combined=pd.concat([trainData, testData], sort=False)\nprint(combined.dtypes.sort_values())","fb0d7840":"length = trainData.shape[0]\ncombined=pd.concat([trainData, testData], sort=False)\ncombined=pd.get_dummies(combined)\ntrainData=combined[:length]\ntestData=combined[length:]\n\ntrainData.Survived=trainData.Survived.astype('int')","4a7311bc":"x=trainData.drop(\"Survived\",axis=1)\ny=trainData['Survived']\nxtest=testData.drop(\"Survived\",axis=1)","a3e96ef2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error","fc8688ef":"RF = RandomForestClassifier(random_state=1)\nresults = cross_val_score(RF,x,y,scoring='accuracy',cv=5)\nprint(results)\nnp.mean(results)\n","9c9debc9":"RF.fit(x, y)\n","6a3ff958":"print(RF)","14c364d2":"predictions=RF.predict(xtest)\ncolumn_name = pd.read_csv('..\/input\/test.csv')\noutput=pd.DataFrame({'PassengerId':column_name['PassengerId'],'Survived':predictions})\noutput.to_csv('submission.csv', index=False)","cd0c6abb":"##### Storing the result in a csv file","afcd1bfc":"##### we also have to take care of null values also called NaN values so that R.F algorith can process the data properly****","7aa6b4bf":"## Creating a RandomForest Model","1d55c385":"##### a categorical variable is a variable that can take on one of a limited, and usually fixed number of possible values, e.g sex has only male and female , In ML we make use of various techniques like one-hot encoding etc to change catagorical columns into numerical columns . i've used the get_dummies function of pandas to change all the catagorical variables at once . you can read more about catagorical variables and how to process them here , the given link only talks about one-hot encoding but you'll get the gist of the idea.","8152afa7":"##### now to work with the dataset we'll either have to drop the colomns with null values or sustitute suitable values in their positions to determine wether a colomn is important enough to not drop or use in R.F algo is called feature importance .Here i'll fill the nan values with mean value of that particular column .","6e8e5971":"##### droppig coloums we wont be using","276cc870":"##### spliting the dataframe into dependant variables (y) and independant variabeles (x)","07172638":"##### Taking a look at our tabel ","8d8e2cb1":"![](https:\/\/images.immediate.co.uk\/production\/volatile\/sites\/7\/2018\/01\/TIT011DJ_0-345b632.jpg?quality=90&resize=620,413)","8c439d56":"reason for creating a combined tabel : due to error at time of fitting the Model , solution of which was found [Here](https:\/\/stackoverflow.com\/questions\/44026832\/valueerror-number-of-features-of-the-model-must-match-the-input)\n","a9d8a0de":"###### Note ot self: below colomn added after error in fitting Randomforest due to mismatch of newly added colomns from caterorical colomns . Prefered way to do \"pd.concat\"","84d73d8b":"##### the first half \"trainData.isnull().sum()\" calculates all total occurance of NaN data type in each of the colomns of trainData.the secong half \"[trainData.isnull().sum()>0]\" acts as like a condition on firt hlaf and only produces sum of NaNs where no of Nan values is greater than 0","25f87e51":"##### Since RandomForest cannot work with text data , we'll take a look at all the columns, and see which ones are text and which ones** are numeric","bada4aaa":"## Converting categorical variables into numerical"}}