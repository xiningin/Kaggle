{"cell_type":{"e4b5e551":"code","5861b2d4":"code","dfca216b":"code","45a4aeae":"code","288b3b89":"code","50c517d0":"code","cdd40e32":"code","44c43be4":"code","c08c6f7d":"code","b08f2cf4":"code","a27b95ca":"code","0914c15f":"code","28838751":"code","9c1696ee":"code","b5decb6d":"code","10cc7a16":"code","835328f4":"code","e56f5e6f":"code","565db619":"code","b75d8323":"code","66f4ae57":"code","e7d89da1":"code","9657cea9":"code","0600ae0c":"code","ffa9c677":"code","04fbef1a":"code","8643482c":"code","4ba26a2f":"code","7b19b8b4":"code","5a37112e":"code","d5f4964d":"code","f3dc239a":"code","c022efda":"code","1882c12f":"code","bc730213":"code","525130b1":"code","e20d679e":"code","f191f6b4":"code","781019fd":"code","0cc67e00":"code","747589cd":"code","ea6e785a":"code","b1268d61":"code","6d9271d8":"code","43050ac4":"code","e9089e4c":"code","b444b90f":"code","ba1088d2":"markdown","a29dc40a":"markdown","22625b5d":"markdown","5b15928d":"markdown","25b275d0":"markdown","6484c79d":"markdown","1fff9be4":"markdown","bbe4b5e3":"markdown","5270b8f9":"markdown","bdd02b57":"markdown","0086fe91":"markdown","8ea37825":"markdown","aa10bbee":"markdown","6caf2b4f":"markdown","636e2df8":"markdown","4989412b":"markdown","fd2f33f8":"markdown","86c24178":"markdown","96752137":"markdown","bd998233":"markdown","5a6780d6":"markdown","657309cd":"markdown","440efc0d":"markdown","fe257dd6":"markdown","f3c17467":"markdown"},"source":{"e4b5e551":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5861b2d4":"import pandas as pd\ndata = pd.read_csv(\"..\/input\/hotel-booking-demand\/hotel_bookings.csv\")","dfca216b":"data.head()","45a4aeae":"data.describe()","288b3b89":"data.info()","50c517d0":"print(\"Nan in each columns\" , data.isna().sum(), sep='\\n')","cdd40e32":"data = data.drop(['company'], axis = 1)\ndata = data.dropna(axis = 0)","44c43be4":"data1 = data.copy()","c08c6f7d":"data.info()","b08f2cf4":"data['hotel'].unique()","a27b95ca":"data['hotel'] = data['hotel'].map({'Resort Hotel':0, 'City Hotel':1})\ndata['hotel'].unique()","0914c15f":"data['arrival_date_month'].unique()","28838751":"data['arrival_date_month'] = data['arrival_date_month'].map({'January':1, 'February': 2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7,\n                                                            'August':8, 'September':9, 'October':10, 'November':11, 'December':12})\ndata['arrival_date_month'].unique()","9c1696ee":"data['customer_type'].unique()","b5decb6d":"data['deposit_type'].unique()","10cc7a16":"data['reservation_status'].unique()","835328f4":"data['assigned_room_type'].unique()","e56f5e6f":"# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column. \ndata['customer_type']= label_encoder.fit_transform(data['customer_type']) \ndata['assigned_room_type'] = label_encoder.fit_transform(data['assigned_room_type'])\ndata['deposit_type'] = label_encoder.fit_transform(data['deposit_type'])\ndata['reservation_status'] = label_encoder.fit_transform(data['reservation_status'])\ndata['meal'] = label_encoder.fit_transform(data['meal'])\ndata['country'] = label_encoder.fit_transform(data['country'])\ndata['distribution_channel'] = label_encoder.fit_transform(data['distribution_channel'])\ndata['market_segment'] = label_encoder.fit_transform(data['market_segment'])\ndata['reserved_room_type'] = label_encoder.fit_transform(data['reserved_room_type'])\ndata['reservation_status_date'] = label_encoder.fit_transform(data['reservation_status_date'])\n  \nprint('customer_type:', data['customer_type'].unique())\nprint('reservation_status', data['reservation_status'].unique())\nprint('deposit_type', data['deposit_type'].unique())\nprint('assigned_room_type', data['assigned_room_type'].unique())\nprint('meal', data['meal'].unique())\nprint('Country:',data['country'].unique())\nprint('Dist_Channel:',data['distribution_channel'].unique())\nprint('Market_seg:', data['market_segment'].unique())\nprint('reserved_room_type:', data['reserved_room_type'].unique())\n","565db619":"from sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.ensemble import AdaBoostRegressor","b75d8323":"X = data.drop(['previous_cancellations'], axis = 1)\ny = data['previous_cancellations']","66f4ae57":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nregressor = LinearRegression()  \nregressor.fit(X_train, y_train) #training the algorithm\ny_pred = regressor.predict(X_test)\n\nprint('Mean Absolute Error_lng:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_lng:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_lng:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_lng:', r2_score(y_test, y_pred).round(3))\n\n## Linear Regression above##","e7d89da1":"ridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train) #training the algorithm\n\ny_pred = ridge.predict(X_test)\n\nprint('Mean Absolute Error_ridge:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_ridge:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_ridge:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_ridge:', r2_score(y_test, y_pred).round(3))\n\n## Ridge Regression above##","9657cea9":"clf = Lasso(alpha=0.1)\n\nclf.fit(X_train, y_train) #training the algorithm\n\ny_pred = clf.predict(X_test)\n\nprint('Mean Absolute Error_lasso:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_lasso:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_lasso:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_lasso:', r2_score(y_test, y_pred).round(3))\n\n## Lasso Regression above##","0600ae0c":"logreg = LogisticRegression(solver = 'lbfgs')\n# fit the model with data\nlogreg.fit(X_train,y_train)\ny_pred=logreg.predict(X_test)\n\nprint('Mean Absolute Error_logreg:', metrics.mean_absolute_error(y_test, y_pred).round(3))  \nprint('Mean Squared Error_logreg:', metrics.mean_squared_error(y_test, y_pred).round(3))  \nprint('Root Mean Squared Error_logreg:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))\nprint('r2_score_logreg:', r2_score(y_test, y_pred).round(3))\n\n## Logistics Regression above ##","ffa9c677":"# Ridge Regression with Gridsearch ##\nfrom sklearn.model_selection import GridSearchCV\n\nparameters= {'alpha':[50,75,100,200, 230, 250], 'random_state':[5,10,20,50,], 'max_iter':[0.1,0.5,1,2,3,5]}\n\ngrid = GridSearchCV(ridge, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint (\"Best_Score_Ridge : \", grid.best_score_)\nprint('best_para_Ridge:', grid.best_params_)","04fbef1a":"# Lasso Regression with Gridsearch ##\nfrom sklearn.model_selection import GridSearchCV\n\nparameters= {'alpha':[200, 230, 250,265, 270, 275, 290, 300], 'random_state':[2,5,10,20,50,], 'max_iter':[5,10,15,20,30,50,100]}\n\ngrid = GridSearchCV(clf, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint (\"Best_Score_Lasso : \", grid.best_score_)\nprint('best_para_Lasso:', grid.best_params_)","8643482c":" # create regressor object \nrfe = RandomForestRegressor(n_estimators = 100, random_state = 42) \n  \n# fit the regressor with x and y data \nrfe.fit(X, y)   \ny_pred=rfe.predict(X_test)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('r2_score_RFE:', r2_score(y_test, y_pred).round(3))","4ba26a2f":"ABR = AdaBoostRegressor(n_estimators = 100, random_state = 42) \n  \n# fit the regressor with x and y data \nABR.fit(X, y)   \ny_pred=ABR.predict(X_test)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('r2_score_ABR:', r2_score(y_test, y_pred).round(3))","7b19b8b4":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","5a37112e":"plt.figure(figsize=(10,5))\nsns.barplot(x ='arrival_date_year', y = 'lead_time', data = data1)","d5f4964d":"plt.figure(figsize = (12,5))\nsns.barplot(x ='arrival_date_month', y = 'adults', data = data1)","f3dc239a":"\ndata1.groupby(['arrival_date_year', 'arrival_date_month']).size().plot.bar(figsize=(15,5))","c022efda":"data1.groupby(['arrival_date_month'])['arrival_date_year'].size().plot.bar(figsize=(15,5))","1882c12f":"plt.figure(figsize = (30,10))\n\ndata1.groupby(['country']).size().sort_values(ascending= False).head(15).plot.bar()","bc730213":"data1.groupby(['country']).size().sort_values(ascending=False)","525130b1":"\ndata.groupby(['arrival_date_month','arrival_date_year'])['children', 'babies'].sum().plot.bar(figsize=(15,5))\n\n","e20d679e":"plt.title('Cancellation')\nplt.ylabel('Cancel_Sum')\n\ndata1.groupby(['hotel','arrival_date_year'])['is_canceled'].sum().plot.bar(figsize=(10,5))","f191f6b4":"data1.groupby(['hotel'])['booking_changes'].sum().plot.pie(radius = 2)\nplt.show()","781019fd":"data1.groupby(['country'])['required_car_parking_spaces'].sum().sort_values(ascending=False)","0cc67e00":"data1.groupby(['country'])['required_car_parking_spaces'].sum().sort_values(ascending=False).head(15).plot.bar(figsize=(10,5))","747589cd":"data1.groupby(['deposit_type']).size().plot.bar()","ea6e785a":"data1.country.unique()","b1268d61":"df_us = data1[data1.country == 'USA']\ndf_uk = data1[data1.country == 'GBR']\ndf_po = data1[data1.country == 'PRT']\ndf_ger = data1[data1.country == 'DEU']\ndf_sp = data1[data1.country == 'ESP']","6d9271d8":"df_us.head()","43050ac4":"df_merged = pd.concat([df_us, df_uk, df_po, df_ger, df_sp])","e9089e4c":"plt.figure(figsize=(15,5))\nsns.barplot(x= 'arrival_date_month', y = 'booking_changes', data = df_us)","b444b90f":"plt.figure(figsize=(15,5))\nsns.scatterplot(x= 'stays_in_weekend_nights', y='stays_in_week_nights', hue = 'country', data = df_merged )","ba1088d2":"Year on year arrival count is depecited in above graph","a29dc40a":"Average month count of arrival of all the three years is shown in above chart ","22625b5d":"Country Has 488 missing Values, Agent has 16340 missing value & company has 112593 missing value","5b15928d":"We have converted strings and object data into machine readable format","25b275d0":"with the above code line we have converted object values to integer values of 0 & 1\nWith below codes we will convert all the object type data into integer values which machine can read","6484c79d":"***Above figures show that the tourists arriving from Poland, Spain,France, GB & Germany require car parking\nThis is also shown in the chart below.***","1fff9be4":"***Above Pie chart shows in which hotels booking changes were maximum.***","bbe4b5e3":"***Above chart shows in which month US visitors are arriving the most & also the booking change frequency***","5270b8f9":"# Let's analyse data for US visitors","bdd02b57":"Now we have 31 columns with equal data i.e. 102894","0086fe91":"***Stay in weekend nights or the five countries is decipted below***","8ea37825":"***Lead time for booking year on year***","aa10bbee":"> ***From the above chart you can see how many childrens and babies arrived ***","6caf2b4f":"Agent, Company, country  have some missing data, ","636e2df8":"***Above chart shows in the years which hotels were mostly cancelled***","4989412b":"As company has maximum missing data lets drop that column\nAslo drop all the rows that have NaN in them as per above code","fd2f33f8":"******","86c24178":"in the above chart you can see from which country maximum tourist are arriving.\nAs shown below, numbers show that the top five countries are Poland, Britan, France, Spain & Germany","96752137":"Our Target is y with previous_cancellations, & X contains all the data except previous_cancellation\nwith below codes we will train_test_split the data","bd998233":"Showing only top 15 countries requiring parking space at hotel","5a6780d6":"Conclusion:\nBasd on the r2_square evalaution, Lasso Regression (r2_square= 0.039) is the best fit model ","657309cd":"Let's now use Regression modles to check the best one.","440efc0d":"> ***Data Visualization***\nLets do some data visualization","fe257dd6":"> ***What Kind of deposits are people paying is shown above***","f3c17467":"Lets now check the unique values in each column"}}