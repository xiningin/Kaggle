{"cell_type":{"dcd08286":"code","31a98806":"code","56811c7d":"code","ffa76088":"code","c9744fee":"code","b4fcd621":"code","8f552476":"code","2e5f7711":"code","a8b704d4":"code","0fcd0072":"code","07c55076":"code","118bc218":"code","2342741c":"code","7c9cec80":"code","0bcb8367":"code","f04089ae":"code","df3ca9da":"code","698027d1":"code","2cb5322d":"code","46437a20":"markdown","9cc55707":"markdown","9b59fd22":"markdown","01661d22":"markdown","62687640":"markdown","bd06929c":"markdown","55fc8ba3":"markdown","e162c696":"markdown","e874b429":"markdown","845975e4":"markdown","18f0aad9":"markdown","ccffc65b":"markdown","0230e779":"markdown","b6666f6f":"markdown","89767588":"markdown","1e77c8c7":"markdown","b6be79d6":"markdown","bd1b7051":"markdown"},"source":{"dcd08286":"!pip install grad-cam\n!pip install torch torchvision timm pandas requests\n\nfrom pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom tqdm import tqdm\nimport zipfile\nimport gzip\nimport os\nimport shutil \nfrom glob import glob\nimport numpy as np \n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nfrom scipy import  ndimage as ndimage\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2 \nimport os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport uuid\n# Ignore warnings\nimport warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom PIL import Image\nplt.ion()   # interactive mode\nfrom ignite.metrics import ConfusionMatrix, Accuracy,Precision,Recall,Loss\nfrom  ignite.engine  import create_supervised_evaluator\nimport albumentations\nimport albumentations.pytorch","31a98806":"BATCH_SIZE = 64\nLEARNING_RATE= 0.0001\nLEARNING_DECAY_GAMA = 0.9\nLEARNING_DECAY_STEPS= 10\nEPOCHS= 40\nMODEL_Name = \"mri_calssification_deit_40_epoch.pth\"","56811c7d":"ixi = glob(os.path.join(\"..\/input\/brain-mri-classification-ixi-dataset\/dataset\/normal*\/\",\"*\" , \"*\"))\nbrast_normal = glob(os.path.join(\"..\/input\/brain-mri-classification-brast-dataset\/dataset\/normal_brast\/\",\"BraTS2021*\" , \"*\"))\nother_normal = glob(os.path.join(\"..\/input\/brain-mri-classification-brast-dataset\/dataset\/normal\/\",\"*\" , \"*\"))\n\nbrast_tumor = glob(os.path.join(\"..\/input\/brain-mri-classification-brast-dataset\/dataset\/tumor_brast\/\",\"BraTS2021*\" , \"*\"))\ntcga_tumor = glob(os.path.join(\"..\/input\/brain-mri-classification-brast-dataset\/dataset\/tumor_tcga\/\",\"*\" , \"*\"))\n\nother_tumor = glob(os.path.join(\"..\/input\/brain-mri-classification-brast-dataset\/dataset\/tumor\/\",\"*\" , \"*\"))\nnp.random.shuffle(ixi)\nnp.random.shuffle(brast_normal)\nnp.random.shuffle(other_normal)\nnp.random.shuffle(brast_tumor)\nnp.random.shuffle(other_tumor)\nnp.random.shuffle(tcga_tumor)\n\n\nprint(\"All ixi Normal samples:\",len(ixi))\nprint(\"All BraST Normal samples:\",len(brast_normal))\nprint(\"All Other Normal samples:\",len(other_normal))\n\nprint(\"All BraST Tumor samples:\",len(brast_tumor))\nprint(\"All Tumor samples except BraST:\",len(other_tumor))\nprint(\"All Tumor samples TCGA:\",len(tcga_tumor))\n\n\n\n\nnormals = np.concatenate([ixi[:4000],other_normal,brast_normal[:8000]])\nnp.random.shuffle(normals)\ntumors = np.concatenate([brast_tumor[:8000],other_tumor[:2760], tcga_tumor[:1370]])\nnp.random.shuffle(tumors)\n\n# normals = normals[:100]\n# tumors = tumors[:100]\nprint(f\"Selected normals: {len(normals)}, Selected tumors: {len(tumors)}\")\n\n\n\nnormals = [[p,0] for p in normals]\ntumors= [[p,1] for p in tumors]\nmixed = np.concatenate([normals,tumors])\nnp.random.shuffle(mixed)\nfrom sklearn.model_selection import train_test_split\n\ntrain , valid = train_test_split(mixed, test_size=0.1)\n\n","ffa76088":"class BrainDataset(Dataset):\n    \"\"\" dataset of brain MRI images\"\"\"\n    def __init__(self, data_path_and_label ,transformer=None) -> Dataset:\n        \"\"\" Args: \n            data_path (list of string): list of  images\n        \n         \"\"\"\n        self.data_path_and_label = data_path_and_label\n        self.transformer = transformer\n        super().__init__()\n    def __len__(self):\n        return len(self.data_path_and_label)\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        path= self.data_path_and_label[idx][0]\n        label = self.data_path_and_label[idx][1]\n        image = np.asanyarray(cv2.imread(path))\n        if self.transformer is not None:\n            image = self.transformer(image=image)[\"image\"]\n        label =int(label)\n        image = image.float()\n        image = (image - image.min())\/(image.max()+ 1e-5)\n\n        return image,label\n\nalbumation_train = albumentations.Compose([\n    albumentations.Resize(256, 256), \n    albumentations.RandomCrop(224, 224),\n    albumentations.OneOf([\n                          albumentations.HorizontalFlip(p=1),\n                          albumentations.RandomRotate90(p=1),\n                          albumentations.VerticalFlip(p=1)            \n    ], p=1),\n    albumentations.OneOf([\n                          albumentations.MotionBlur(p=1),\n                          albumentations.OpticalDistortion(p=1),\n                          albumentations.GaussNoise(p=1)                 \n    ], p=1),\n    albumentations.OneOf([\n    albumentations.augmentations.transforms.ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=1),\n    albumentations.augmentations.transforms.Equalize (mode='cv', by_channels=True, mask=None, mask_params=(), always_apply=False, p=0.5),\n    albumentations.augmentations.transforms.RandomBrightnessContrast(0.5, 0.2, True, p=1),\n    ], p=1),\n\n    albumentations.pytorch.ToTensorV2()\n])\nalbumation_valid =  albumentations.Compose([\n    albumentations.Resize(256, 256), \n    albumentations.CenterCrop(224, 224),\n    albumentations.pytorch.ToTensorV2()\n])\ndata_transforms=  {\"train\":albumation_train, \"val\":albumation_valid}\n\n#####################################################\nbrain_datasets = {\n\"train\":BrainDataset(train,data_transforms[\"train\"]),\n\"val\": BrainDataset(valid,data_transforms[\"val\"]),\n}\ndataloaders = {x: DataLoader(brain_datasets[x], batch_size=BATCH_SIZE,\n                                             shuffle=True, num_workers=2)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(brain_datasets[x]) for x in ['train', 'val']}\nclass_names = {0:\"normal\", 1:\"tumor\"}\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndef gpu_dataloader(dataloader):\n    for i, (images, lables) in  enumerate(dataloader):\n        yield images.to(device), lables.to(device)\n","c9744fee":"fig , axes = plt.subplots(4,4, figsize =(20,20))\naxes = np.concatenate(axes, axis =-1)\n\nfor index in range(16):\n    image, label =  brain_datasets[\"train\"][index]\n    axes[index].imshow(image[0], cmap=\"gray\", interpolation=\"nearest\")\n    axes[index].set_title(\"Image  {}\".format(index))\nplt.show()","b4fcd621":"\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            if phase == 'val':\n                scheduler.step(epoch_loss)\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","8f552476":"model = torch.hub.load('facebookresearch\/deit:main', 'deit_base_patch16_224', pretrained=True)\n\nnum_ftrs = model.head.in_features\n    \nmodel.head = nn.Linear(num_ftrs, 2)\n\nmodel = model.to(device)\n\n    \n    \ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nreduce_plt_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=10 ,verbose=True)\n# Decay LR by a factor of 0.9 every 10 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=LEARNING_DECAY_STEPS, gamma=LEARNING_DECAY_GAMA)","2e5f7711":"model = train_model(model, criterion, optimizer, reduce_plt_scheduler,\n                       num_epochs=EPOCHS)","a8b704d4":"torch.save(model.state_dict(),MODEL_Name)\n","0fcd0072":"model.eval()\n\nwith torch.no_grad():\n    # prediction_loader = torch.utils.data.DataLoader(brain_dataset, batch_size=10)\n    images, labels= next(iter(dataloaders[\"val\"]))\n    images = images.to(device)\n    preds = model(images)\n    images = images.data.cpu().numpy()\n    labels = labels.data.cpu().numpy()\n    preds = [class_names[p] for p in preds.argmax(dim=1).data.cpu().numpy()]\n    labels = [class_names[p] for p in labels]\n    fig , axes = plt.subplots(4,4, figsize =(20,20))\n    axes = np.concatenate(axes, axis =-1)\n\n    for index in range(16):\n        image = np.transpose(images[index], (1,2,0))\n        image = (image - image.min()) \/ (image.max() - image.min()+1.0) * 255.0 \n        image = image.astype(np.uint8)\n        axes[index].imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n        axes[index].set_title(\"label :{} predicted  {}\".format(labels[index],preds[index]))\n    plt.show()","07c55076":"import ignite\n# bring model to device\ndef data_in_device():\n    for i in range(dataset_sizes[\"val\"]):\n        x, y = next(iter(dataloaders[\"val\"]))\n        yield x.to(device), y.to(device)\nmodel.cuda()\ndef binary_one_hot_output_transform(output):\n    y_pred, y = output\n    y_pred =torch.sigmoid(y_pred).round().long()\n    y_pred = ignite.utils.to_onehot(y_pred, 2)\n    y = ignite.utils.to_onehot(y, 2)\n    # y = y.long()\n    return y_pred, y\n\nmetrics = {\n    \"confusion_matrix\": ConfusionMatrix(2, output_transform=binary_one_hot_output_transform),\n    \"Accuracy\": Accuracy(),\n    \"Precision\": Precision(),\n    \"Recall\":Recall()\n\n}\n\nevaluator = create_supervised_evaluator(\n    model, metrics=metrics, output_transform=lambda x, y, y_pred: (y_pred, y)\n)\n\n    \nstate = evaluator.run(iter(data_in_device()))\nprint(state)","118bc218":"print(\"confusion_matrix: \\n\",state.metrics[\"confusion_matrix\"].data.cpu().numpy())\nprint(\"Precision: \\n\",state.metrics[\"Precision\"].data.cpu().numpy())\nprint(\"Recall: \\n\",state.metrics[\"Recall\"].data.cpu().numpy())\nprint(\"Accuracy: \",state.metrics[\"Accuracy\"])","2342741c":"def show_cam(cam, inputs, labels, preds, nums=16):\n    grayscale_cams = cam(input_tensor=inputs,eigen_smooth=True,aug_smooth=True)\n    fig , axes = plt.subplots(nums,2, figsize =(20,nums*5))\n    inputs_transposed =inputs.cpu().numpy().transpose(0,2,3,1)\n\n    for index in range(nums):\n        grayscale_cam = grayscale_cams[index, :]\n        original_image = inputs_transposed[index]\n        visualization = show_cam_on_image(original_image, grayscale_cam,colormap=cv2.COLORMAP_HOT)\n        axes[index][0].imshow(visualization, interpolation=\"nearest\")\n        axes[index][0].set_title(\"Predicted  {}\".format(preds[index]))\n        axes[index][1].imshow(original_image[:,:,0],cmap=\"gray\" , interpolation=\"nearest\")\n        axes[index][1].set_title(\"Original label:{}\".format(labels[index]))      \n    plt.show()","7c9cec80":"# # grad cam \n# model.eval()\n# target_layers = [model.layer4[-1]]\n# (inputs, labels)= next(gpu_dataloader(dataloaders[\"val\"]))\n# (inputs_pos, labels_pos) = (inputs[labels==1], labels[labels==1])\n# (inputs_neg, labels_neg) = (inputs[labels==0], labels[labels==0])\n# inputs = torch.cat([inputs_pos[:8], inputs_neg[:8]])\n# labels = torch.cat([labels_pos[:8], labels_neg[:8]])\n\n# preds = model(inputs)\n# preds = [class_names[p] for p in preds.argmax(dim=1).data.cpu().numpy()]\n# labels = [class_names[p] for p in labels.data.cpu().numpy()]\n\n# cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\n# show_cam(cam, inputs, labels, preds,16)","0bcb8367":"# # # grad cam from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n\n# cam = GradCAMPlusPlus(model=model, target_layers=target_layers, use_cuda=True)\n# show_cam(cam, inputs, labels, preds,16)\n","f04089ae":"\n# cam = ScoreCAM(model=model, target_layers=target_layers, use_cuda=True)\n# show_cam(cam, inputs, labels, preds,16)\n","df3ca9da":"# cam = AblationCAM(model=model, target_layers=target_layers, use_cuda=True)\n# show_cam(cam, inputs, labels, preds,16)","698027d1":"# cam = XGradCAM(model=model, target_layers=target_layers, use_cuda=True)\n# show_cam(cam, inputs, labels, preds,16)","2cb5322d":"# cam = EigenCAM(model=model, target_layers=target_layers, use_cuda=True)\n# show_cam(cam, inputs, labels, preds,16)","46437a20":"# GRADCAM","9cc55707":"# Hyper Parameters","9b59fd22":"# Prediction ","01661d22":"# Optimizer and learning rate","62687640":"# ScoreCAM","bd06929c":"# Train","55fc8ba3":"# Iteration","e162c696":"# Dataset ","e874b429":"# Data Quanties","845975e4":"# Metrics ","18f0aad9":"# AblationCAM ","ccffc65b":"# Save model","0230e779":"# XGradCAM","b6666f6f":"# GradCAMPlusPlus","89767588":"# Dataloader","1e77c8c7":"# ","b6be79d6":"# EigenCAM","bd1b7051":"# Data example"}}