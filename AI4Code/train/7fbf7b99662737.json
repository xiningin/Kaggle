{"cell_type":{"e7e27b53":"code","78366c3b":"code","53827485":"code","f768b538":"code","4528e802":"code","d532f8d6":"code","834ca0c3":"code","3e8e8773":"code","8547922a":"code","db82da0c":"code","f5308023":"code","00f01be3":"code","42391dea":"code","a3935fc3":"code","c2711a95":"code","76456860":"code","94818ce3":"code","209870dc":"code","ba2bff40":"code","d0da7fe4":"code","cf1b7ba2":"code","505634e5":"code","334d9212":"code","69cbaa31":"code","fe512e21":"code","5bdbb2cb":"code","511313ac":"code","4d772f8e":"code","9e514dfd":"code","2bdfdb85":"code","046f4583":"code","8a94633a":"code","051e7c6c":"code","8ffa3a3a":"code","0005d2cd":"code","7fd9fddb":"code","aca4595a":"code","0ef919cd":"code","73c0bd4e":"code","3c4f7dfb":"code","b16b2805":"code","0298b009":"code","716a918f":"code","42d86b89":"code","722eddbe":"code","d26a1df2":"code","b3afcd2c":"code","9457285b":"code","c876f2f8":"code","340583b2":"code","c9328f9b":"code","012684cc":"code","b4cfd79b":"markdown","08a3320d":"markdown","bc4a85d2":"markdown","b7b48f94":"markdown","a48843f7":"markdown","d52cf63d":"markdown","c002d58a":"markdown","a452ef62":"markdown","96f9a08e":"markdown","437196e6":"markdown","1b8c7e0f":"markdown","f3135e96":"markdown","aca1e861":"markdown","af915876":"markdown","2c5c9562":"markdown","2e784e45":"markdown","3e1201b9":"markdown","d6bf1d14":"markdown","77741d5c":"markdown","ff8d8ca8":"markdown","00382e39":"markdown","0789c354":"markdown","9e51efd7":"markdown","e84e26c4":"markdown","1a83d559":"markdown","46c1f645":"markdown","1a6f9abe":"markdown","7aabf68a":"markdown","7e5f558d":"markdown","6f31d41e":"markdown","b7a521aa":"markdown","44514ae6":"markdown","a00e66c7":"markdown","509941de":"markdown","56e8650e":"markdown","e3b063d9":"markdown","06acf040":"markdown","c31688d6":"markdown"},"source":{"e7e27b53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.","78366c3b":"import numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","53827485":"df_train = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')","f768b538":"df_train.describe()","4528e802":"print(df_train.isnull().sum(axis = 0))\nprint(df_test.isnull().sum(axis = 0))","d532f8d6":"fig,ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train['count'].plot(kind = 'hist', bins=100, ax =ax[0])\ndf_train['count'].plot(kind = 'box', ax =ax[1])","834ca0c3":"print('Before removing the outliers ', df_train.shape)\ndf_train = df_train[abs(df_train['count'] - df_train['count'].mean()) < 3*df_train['count'].std()]\nprint('After removing the outliers ', df_train.shape)\ndf_train.reset_index(drop = True, inplace = True)","3e8e8773":"df_train.head()","8547922a":"fig, ax = plt.subplots(1, 3)\nfig.set_size_inches(20, 10)\nsns.distplot(df_train[\"count\"], ax = ax[0])\nsns.distplot(df_train[\"casual\"], ax = ax[1])\nsns.distplot(df_train[\"registered\"], ax = ax[2])","db82da0c":"df_train['count'] = np.log(df_train['count'] + 1)\ndf_train['registered'] = np.log(df_train['registered'] + 1)\nfig, ax = plt.subplots(1, 3)\nfig.set_size_inches(20, 10)\nsns.distplot(df_train[\"count\"], ax = ax[0])\nsns.distplot(df_train[\"casual\"], ax = ax[1])\nsns.distplot(df_train[\"registered\"], ax = ax[2])\n","f5308023":"def add_month(dataframe):\n    month = pd.DatetimeIndex(dataframe['datetime']).month\n    return month\n\ndef add_time(dataframe):\n    time = pd.DatetimeIndex(dataframe['datetime']).hour\n    return time\n\ndef add_year(dataframe):\n    year = pd.DatetimeIndex(dataframe['datetime']).year\n    return year\n\ndef add_day(dataframe):\n    day = pd.DatetimeIndex(dataframe['datetime']).dayofweek\n    return day","00f01be3":"df_train['month'] = add_month(df_train)\ndf_train['time'] = add_time(df_train)\ndf_train['year'] = add_year(df_train)\ndf_train['day'] = add_day(df_train)\ndf_train.head()","42391dea":"corr = df_train.corr()\ncorr","a3935fc3":"df_train.groupby('time')['count'].mean().plot(kind = 'bar')","c2711a95":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('month')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('season')['count'].mean().plot('bar', ax = ax[1])","76456860":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('temp')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('humidity')['count'].mean().plot('bar', ax = ax[1])","94818ce3":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('holiday')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('workingday')['count'].mean().plot('bar', ax = ax[1])\nprint(\"mean of count according to holidays \", df_train.groupby('holiday')['count'].mean())\nprint(\"No of holiday = 1 and holdays = 0 \", df_train.groupby('holiday')['count'].count())","209870dc":"df_train[df_train['windspeed'] == 0].shape","ba2bff40":"df_train.groupby('windspeed')['count'].count().plot(kind='bar')\ndf_train.groupby('windspeed')['count'].count()","d0da7fe4":"df_train_windspeed_0 = df_train[df_train['windspeed'] == 0]\ndf_train_windspeed_not_0 = df_train[df_train['windspeed'] != 0]\nprint(df_train_windspeed_0.head())\nprint(df_train_windspeed_not_0.head())","cf1b7ba2":"print(df_train_windspeed_0.shape)\nprint(df_train_windspeed_not_0.shape)","505634e5":"columns_for_windspeed = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity']","334d9212":"from sklearn.ensemble import RandomForestRegressor\nrf_windspeed = RandomForestRegressor().fit(df_train_windspeed_not_0[columns_for_windspeed], df_train_windspeed_not_0['windspeed'])\ndf_train_windspeed_0['windspeed'] = rf_windspeed.predict(df_train_windspeed_0[columns_for_windspeed])\n\ndf_train = df_train_windspeed_0.append(df_train_windspeed_not_0, sort = 'datetime')","69cbaa31":"print(df_train.shape)\ndf_train.head()","fe512e21":"print(df_train[df_train['windspeed'] == 0])\ndf_train.groupby('windspeed')['count'].count()","5bdbb2cb":"categorical_columns = ['holiday', 'season', 'workingday', 'weather', 'month', 'time', 'year', 'day']\nfor category in categorical_columns:\n    df_train = df_train.join(pd.get_dummies(df_train[category], prefix = category))\n    \ndf_train.head()","511313ac":"'''\ndef one_hot_encode(dataframe, column):\n    for i in dataframe.groupby(column).count().index:\n        s = column + \"_\" + str(i)\n        a = []\n        for element in dataframe[column]:\n            if element == i:\n                a.append(1)\n            else:\n                a.append(0)\n        dataframe[s] = a\n    return dataframe\n'''","4d772f8e":"df_train.columns","9e514dfd":"def normalize(dataframe, columns):\n    for column in columns:\n        dataframe[column]=((dataframe[column]-dataframe[column].min())\/(dataframe[column].max()-dataframe[column].min()))\n    return dataframe","2bdfdb85":"df_train = normalize(df_train, columns=['temp', 'humidity', 'windspeed'])\ndf_train.head()","046f4583":"def remove_columns(dataframe, columns):\n    dataframe = dataframe.drop(columns, axis = 1)\n    return dataframe","8a94633a":"df_train = remove_columns(df_train, ['datetime', 'atemp']) \nprint(df_train.columns)\ndf_train.head()","051e7c6c":"df_train_y = df_train[['count', 'casual', 'registered']]\ndf_train_x = remove_columns(df_train, ['casual', 'registered', 'count'])","8ffa3a3a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.15, random_state=42)","0005d2cd":"y_train_casual = y_train['casual']\ny_train_registered = y_train['registered']\ny_train_total = y_train['count']\ny_test_casual = y_test['casual']\ny_test_registered = y_test['registered']\ny_test_total = y_test['count']","7fd9fddb":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_log_error","aca4595a":"all_predictions = []\n\n#as we have the one hot vector we will remove this categorical data\ncategorical_data = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day']\nlr_train_x = remove_columns(x_train, categorical_data)\nlr_test_x = remove_columns(x_test, categorical_data)\n\nlr = LinearRegression().fit(lr_train_x, y_train_total)\nlr_predictions_on_test_data = np.exp(lr.predict(lr_test_x)) - 1\n\nlr_predictions_on_train_data = np.exp(lr.predict(lr_train_x))\n\nall_predictions.append(lr_predictions_on_train_data)\nall_predictions.append(lr_predictions_on_test_data)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","0ef919cd":"all_predictions = []\n\ntraining_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ntrain_x = x_train[training_columns]\ntest_x = x_test[training_columns]\n\nrf = RandomForestRegressor(n_estimators=100, max_depth = 10, min_samples_split=5).fit(train_x, y_train_total)\npredictions_on_test_data = np.exp(rf.predict(test_x)) - 1\n\npredictions_on_train_data = np.exp(rf.predict(train_x))\n\nall_predictions.append(predictions_on_train_data)\nall_predictions.append(predictions_on_test_data)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","73c0bd4e":"all_predictions = []\n\ntraining_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ntrain_x = x_train[training_columns]\ntest_x = x_test[training_columns]\n\nrf_casual = RandomForestRegressor(n_estimators=300, max_depth = 10, min_samples_split=8).fit(train_x, y_train_casual)\npredictions_casual = rf_casual.predict(test_x)\n\n\nrf_registered = RandomForestRegressor().fit(train_x, y_train_registered)\npredictions_registered = np.exp(rf_registered.predict(test_x))-1\n\npredictions = predictions_casual + predictions_registered\n\npredictions_casual_train = rf_casual.predict(train_x)\npredictions_registered_train = np.exp(rf_registered.predict(train_x))-1\n\npredictions_train = predictions_casual_train + predictions_registered_train\n\nall_predictions.append(predictions_train)\nall_predictions.append(predictions)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","3c4f7dfb":"df_test.head()","b16b2805":"df_test['month'] = add_month(df_test)\ndf_test['time'] = add_time(df_test)\ndf_test['year'] = add_year(df_test)\ndf_test['day'] = add_day(df_test)\ndf_test.head()","0298b009":"df_test_windspeed_0 = df_test[df_test['windspeed'] == 0]\ndf_test_windspeed_not_0 = df_test[df_test['windspeed'] != 0]\ncolumns_for_windspeed = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity']\n\ndf_test_windspeed_0['windspeed'] = rf_windspeed.predict(df_test_windspeed_0[columns_for_windspeed])\n\ndf_test = df_test_windspeed_0.append(df_test_windspeed_not_0, sort = 'datetime')","716a918f":"df_test.head()","42d86b89":"df_test = df_test.sort_values(by='datetime')\ndf_test.head()","722eddbe":"categorical_columns = ['holiday', 'season', 'workingday', 'weather', 'month', 'time', 'year', 'day']\nfor category in categorical_columns:\n    df_test = df_test.join(pd.get_dummies(df_test[category], prefix = category))\n    \nprint(df_test.head())\nprint(df_test.columns)","d26a1df2":"df_test = normalize(df_test, columns=['temp', 'humidity', 'windspeed'])\ndf_test.head()","b3afcd2c":"df_datetime = df_test['datetime']\ndf_test = remove_columns(df_test, ['datetime', 'atemp']) \nprint(df_test.columns)","9457285b":"df_test.columns.shape == df_train_x.columns.shape","c876f2f8":"training_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ndf_test_final = df_test[training_columns]\npredictions = np.exp(rf.predict(df_test_final))-1","340583b2":"'''\npredictions_casual = rf_casual.predict(df_test_final)\n\npredictions_registered = np.exp(rf_registered.predict(df_test_final))-1\n\npredictions = predictions_casual + predictions_registered\n\nprint(predictions[:5])\n'''\n","c9328f9b":"data = {'datetime': df_datetime, 'count': predictions}\ndf = pd.DataFrame(data)\ndf.head()","012684cc":"df.to_csv('submission.csv', index = False)","b4cfd79b":"### We can see that there is a positive relation of temperature with count and a negative relation of humidity with the count, this verifies the correlation values that we got above ","08a3320d":"## **Checking for the null values**","bc4a85d2":"### We can see that the maximum is around 7-9 am and 5-6 pm ","b7b48f94":"### Extract the month, hour, year from the datetime column. I am not considering the day as the training set contains only dates from 1 to 19 and test data is of 20th day of each month.","a48843f7":"### 1. Time ","d52cf63d":"### 3. Temperature and Humidity","c002d58a":"### 4. Holiday amd Workingday","a452ef62":"## **Importing the libraries**","96f9a08e":"### As we can see that it contains the outliers. It happens when we have more rented bikes than ususal. So we need to remove the outliers as they can affect our models for predictions.","437196e6":"### We can observe from the above graphs that the number of rented bikes are less in season 1 as compared to others","1b8c7e0f":"### Now the distribution is more normally distributed but remember we have added 1 before taking the log as np.log(0) will give infinity","f3135e96":"### Split the dataset into training and testing","aca1e861":"\nThree reasons to discard holiday and working day: \n1. Correlation value is low\n2. Examples where holiday = 1 is less than 3 percent\n3. The mean is almost similar\nBut we will make different models one with holiday and workingday and one without these features","af915876":"### If you want to predict using 2 models","2c5c9562":"### We will make 2 models in the first one we directly estimate the variable \"Count\" and in the 2nd one we will estimate \"Casual\" and \"Registered\" and \"Count\" will be equal to their summition","2e784e45":"## ** While training for submitting use the entire dataset to train **","3e1201b9":"### 2. Month and Season","d6bf1d14":"### As most of the machine learning models work best when the output variable is normally distributed, we will apply the log transformation to \"Count\" and \"Registered\" to make it more normally distributed","77741d5c":"### As we can not use the categorical values as input for models like linear regression we will convert it to one hot vector using pd.get_dummies","ff8d8ca8":"## **Lets first explore the output value (Count)**","00382e39":"### Below function is equaivalent to pd.get_dummies","0789c354":"## Lets explore how the count is varying with different features","9e51efd7":"### We can draw the following obsevations from it:\n#### 1. The correlation between temp and atemp is very high so we can discard any of the variable\n#### 2. The correlation between count and time is highest and the correlation of count with year, month, temp,humidity is also significant","e84e26c4":"### As we can see now that the windspeed is not 0 for any example","1a83d559":"### As a lot of values are 0 in windspeed we can consider the following scenerios:\n1.  It can actually be 0 at these points.\n2.  It is too low to be measured, for example varying from 0 to 5.\n3.  All zeros or part of them are nothing but NAs.\n\n\n## So we will be estimating the missing values using the random forest","46c1f645":"### Random Forest with different model for \"Casual\" and \"Registered\"","1a6f9abe":"## Processing of the test data\n### 1. Addition of the day, month, time, year\n### 2. Removing the zero in the windspeed\n### 3. Sorting the data according to datetime\n### 4. Adding the one hot vector in case you want to predict the count using Linear Regression\n### 5. Normalisation\n### 6. Prediction\n### 7. Storing","7aabf68a":"### Luckily we do not have to deal with null values","7e5f558d":"### Split the dataset into input and output","6f31d41e":"## **Loading the dataset**","b7a521aa":"### Using Linear Regression","44514ae6":"### Importing the Machine Learning Libraries","a00e66c7":"### For the Random Forest we do not need the one hot encoding for the categorical variables","509941de":"### Lets visualize the distribution of the output variable","56e8650e":"### Some algorithms performed better when the input data is normalized so we will normalize temp, humidity and windspeed","e3b063d9":"### As we have taken all the information from the datetime column we can remove that","06acf040":"### To find the dependence of independent variable on dependent variable we will calculate the correlation between them","c31688d6":"### 5. Windspeed"}}