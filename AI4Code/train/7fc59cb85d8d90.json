{"cell_type":{"d5445703":"code","c9956e0e":"code","c906189d":"code","69b8ea4c":"code","61628e2f":"code","82ac9d4a":"code","376618e7":"code","bd43831c":"code","66cd5e40":"code","6ade26d3":"code","b991b45e":"code","ab389f7f":"markdown","7da9926b":"markdown","cbb88054":"markdown","09e65d5d":"markdown","ce252f56":"markdown","15855197":"markdown","7354d5a3":"markdown"},"source":{"d5445703":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Model\n# Any results you write to the current directory are saved as output.","c9956e0e":"df = pd.read_csv(\"..\/input\/iris.csv\")\ndf.head()","c906189d":"df.info()","69b8ea4c":"df.describe()","61628e2f":"df['Species'].value_counts()","82ac9d4a":"sns.pairplot(df,hue ='Species')","376618e7":"#Splitting data into training and testing categories as well as input\/output\ntraining_data = df[0:104]\ntraining_results = training_data['Species']\ntraining_data = training_data.drop(columns='Species')\n\ntesting_data = df[105::]\ntesting_results = testing_data['Species']\ntesting_data = testing_data.drop(columns='Species')","bd43831c":"#normalize data\ntraining_data = (training_data - training_data.mean())\/training_data.std()\ntraining_data.describe()\n","66cd5e40":"sns.pairplot(training_data)","6ade26d3":"#initialize a sequential model object\nmodel = keras.Sequential()\n\n#add input layer\n#Add a Dense layer with the input shape of the training data.Use\n#a reLu function for nonlinear activation.\nmodel.add(keras.layers.Dense(64, activation=tf.nn.relu,\n                       input_shape=(training_data.shape[1],)))\n\n#add hidden layer\n#Add a Dense layer again using a reLu function.\nmodel.add(keras.layers.Dense(64, activation=tf.nn.relu))\n\nmodel.add(keras.layers.Dense(1))\n\nmodel.summary()","b991b45e":"#RMSProp used to speed up gradient descent\noptimizer = tf.train.RMSPropOptimizer(0.001)\n\n#mean squared error loss(error) function to be minimized for the NN.\nmodel.compile(loss='mse',\n        optimizer=optimizer,\n        metrics=['accuracy'])\n\nhistory = model.fit(training_data, training_results, epochs=500,\n                    validation_split=0.3, verbose=0)\n\n#TODO: Convert training_reults into floating points? Review optimizers and \n#loss functions.","ab389f7f":"Now we can see that the training data has roughly the same scale, all having the same standard deviation and meanas close to zero. I wanted to know why exactly normalization is so important, and upon further research I found that normalization takes different variables that might be scaled differently and have different means\/standard deviations and makes them directly comparable. This is great for regression analysis where we must compare the different features of the data.\n\nNow we must create a model.","7da9926b":"Hello, my name is Rohan. I am interested in learning more techniques and tools in data analytics to strengthen my skills. I hope to work with a series of Kaggle datasets slowly tackling more and more complex problems and learning new techniques along the way. \n\nIn this first notebook I will be working with a \"beginner\" dataset. This will just be to get hands on experience in the Kaggle Kernel and explore some more basic data science libraries in Python. I have previously used Python pandas, numpy and Matplotlib for basic visualization. In this notebook I hope to describe, visualize and extend the Iris data to be able to predict Iris species based on given parameters. I hope to use either Logistical Regression or K-nearest neighbors (or both) for class fitting. I will be outlining my steps as I go for reference.\n\nI start with some basic imports and commands to view the structure of the data.","cbb88054":"The input features would be Sepal length, Sepal Width, Petal Length and Petal Width to predict Species. We examine the species variable further.","09e65d5d":"I want to get more familiar with the Python Tensorflow and Keras libraries so I will be using them to perform a simple regression analysis. \n\nI first need to separate the data into training and testing data and then prep the data by normalizing it (making the different features scale the same and have the same range). This can be done as follows:\n\n![](http:\/\/www.statisticshowto.com\/wp-content\/uploads\/2016\/11\/alternate-z-score.png)\n\nWhere:\nxi is a data point (x1, x2\u2026xn).\nx\u0304 is the sample mean.\ns is the sample standard deviation.\n\nSo we separate the data (70:30 training to testing) and then apply this formula to the Pandas Dataframe.","ce252f56":"So I didn't know about this library, the seaborn library. This pairplot command constructs a square matrix for each variable plotting one against the other, and the diagonals showing the distribution of the univariable.","15855197":"Above we've created a simple neural network. This takes the training data variables as inputs to the network and assigns them arbitrary weights. Regression (back propogation) is used to find the best fit for these weights so divulge how each data parameter most likely affects the species result. The activation parameter uses a rectifier function (ReLU) to nonlinearize the data and extend it to predict more sophisticated models. \n\n![](https:\/\/cdn-images-1.medium.com\/max\/1000\/0*kETHX4MtZfu8_0sE.png)\n\nNow let's train our model.","7354d5a3":"The hue parameter labels the different categories in the \"Species\" column of the dataframe. So we see how each parameter plotted against another can result in different species. For example, the bottom row - second column shows how low petal width and low sepal length flowers tend to be Setosa species. These plots show a large distance between the different groups, which makes me think the nearest neighbors algorithm might be a promising classification method. \n\nLooking at the diagonals we see that Petal length and Width are significantly smaller and separated for the Setosa species. Sepal Width by itself is almost undistinguishable for the three different types of species, and thus when we look at the data plotted against other parameters we see the classes of species separated in only a vertical or horizontal direction for graphs in the middle row or column. \n\nNow that I have visualized the data, let's try and train the data."}}