{"cell_type":{"9bc44b32":"code","d7341695":"code","4a5bfe0c":"code","ee45f407":"code","76d88256":"code","75aee2f4":"code","49db92fe":"code","1de8ecd2":"code","a35da9ce":"code","57c80a00":"code","44737595":"code","50dac716":"code","7947bcee":"code","511f9069":"code","97d11685":"markdown","f63d7438":"markdown","39de499e":"markdown","2b90f2c0":"markdown","845b3f55":"markdown","219dc3c1":"markdown","f4efd334":"markdown","d20b9cc9":"markdown","5d6bff4a":"markdown","490842e7":"markdown"},"source":{"9bc44b32":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom yellowbrick.cluster import KElbowVisualizer","d7341695":"#Import Dataset\ndata = '..\/input\/data-user-modeling\/Data_User_Modeling_Dataset.csv'\ndf = pd.read_csv(data)\ndf","4a5bfe0c":"#drop data Unnamed: 6, Unnamed: 7, Unnamed: 8\ndf.drop(['Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8'], axis=1, inplace=True)","ee45f407":"#Informasi tabel\ndf.info()","76d88256":"df.isnull().sum()","75aee2f4":"X = df\ny = df[' UNS']","49db92fe":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[' UNS'] = le.fit_transform(X[' UNS'])\ny = le.transform(y)","1de8ecd2":"from sklearn.preprocessing import MinMaxScaler\ncols = X.columns\nms = MinMaxScaler()\nX = ms.fit_transform(X)\nX = pd.DataFrame(X, columns=[cols])\nX.head()","a35da9ce":"# Generate synthetic dataset with 8 random clusters\nX, y = make_blobs(n_samples=1000, n_features=12, centers=8, random_state=42)\n\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(4,12))\n\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","57c80a00":"#model K-means with two clusters (K optimal Dengan Elbow Method) \nkmeans = KMeans(n_clusters=7, random_state=0) \nkmeans.fit(X) \ninersia = kmeans.inertia_ \n# check how many of the samples were correctly labeled \nlabels = kmeans.labels_ \ncorrect_labels = sum(y == labels) \nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, \ny.size)) \nprint('Accuracy score: {0:0.2f}'. format(correct_labels\/float(y.size))) \nprint('Jumlah Momen Inersia Yang Dihasilkan = ',end='')\nprint(inersia)","44737595":"#model K-means with 4 clusters (K Sembarang )\nkmeans = KMeans(n_clusters=4, random_state=0)\n\nkmeans.fit(X)\ninersia = kmeans.inertia_\n# check how many of the samples were correctly labeled\nlabels = kmeans.labels_\n\ncorrect_labels = sum(y == labels)\nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\nprint('Accuracy score: {0:0.2f}'. format(correct_labels\/float(y.size)))\nprint('Jumlah Momen Inersia Yang Dihasilkan =  ', end='')\nprint(inersia)","50dac716":"y_km = kmeans.fit_predict(X) \n# plot the 7 clusters \nplt.scatter( \n X[y_km == 0, 0], X[y_km == 0, 1], \n s=50, c='lightgreen', \n marker='s', edgecolor='black', \n label='cluster 1' \n) \nplt.scatter( \n X[y_km == 1, 0], X[y_km == 1, 1], \n s=50, c='orange', \n marker='o', edgecolor='black', \n label='cluster 2' \n) \nplt.scatter( \n X[y_km == 2, 0], X[y_km == 2, 1], \n s=50, c='lightblue', \n marker='v', edgecolor='black', \n label='cluster 3' \n) \nplt.scatter( \n X[y_km == 3, 0], X[y_km == 3, 1], \n s=50, c='white', \n marker='d', edgecolor='black', \n label='cluster 4' \n) \nplt.scatter( \n X[y_km == 4, 0], X[y_km == 4, 1], \n s=50, c='blue', \n marker='d', edgecolor='black', \n label='cluster 5' \n) \nplt.scatter( \n X[y_km == 5, 0], X[y_km == 5, 1], \n s=50, c='pink', \n marker='d', edgecolor='black', \n label='cluster 6' \n) \nplt.scatter( \n X[y_km == 6, 0], X[y_km == 6, 1], \n s=50, c='silver', \n marker='d', edgecolor='black', \n label='cluster 7' \n)\n# plot the centroids \nplt.scatter( \n kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n s=250, marker='*', \n c='red', edgecolor='black', \n label='centroids' \n) \nplt.legend(scatterpoints=1) \nplt.grid() \nplt.show()","7947bcee":"y_km = kmeans.fit_predict(X)\n# plot the 4 clusters\nplt.scatter(\n    X[y_km == 0, 0], X[y_km == 0, 1],\n    s=50, c='lightgreen',\n    marker='s', edgecolor='black',\n    label='cluster 1'\n)\n\nplt.scatter(\n    X[y_km == 1, 0], X[y_km == 1, 1],\n    s=50, c='orange',\n    marker='o', edgecolor='black',\n    label='cluster 2'\n)\n\nplt.scatter(\n    X[y_km == 2, 0], X[y_km == 2, 1],\n    s=50, c='lightblue',\n    marker='v', edgecolor='black',\n    label='cluster 3'\n)\n\nplt.scatter(\n    X[y_km == 3, 0], X[y_km == 3, 1],\n        s=50, c='white',\n    marker='d', edgecolor='black',\n    label='cluster 4'\n)\n\n# plot the centroids\nplt.scatter(\n    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n    s=250, marker='*',\n    c='red', edgecolor='black',\n    label='centroids'\n)\nplt.legend(scatterpoints=1)\nplt.grid()\nplt.show()","511f9069":"# Memeriksa keseimbangan cluster menggunakan metode silhouette\n\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\n# Instantiate the clustering model and visualizer\nkm = KMeans (n_clusters=7)\nvisualizer = SilhouetteVisualizer(km, colors='yellowbrick')\n\nvisualizer.fit(df) # Fit the training data to the visualizer\nvisualizer.poof() # Draw\/show\/poof the data","97d11685":"# #Plot Scatter\/Penyebaran Cluster dengan nilai k = 7 dan Titik Centroids","f63d7438":"# #Model Clustering","39de499e":"# #Import Dataset","2b90f2c0":"# #Melakukan Pemodelan Dengan Jumlah Cluster (K) Optimal Elbow Method","845b3f55":"# #Menentukan Jumlah Cluster Optimal Menggunakan Elbow Method","219dc3c1":"# #Penentuan Feature Vector dan Target Variable","f4efd334":"# #Plot Scatter\/Penyebaran Cluster dengan nilai k = 4 dan Menampilkan Titik Centroids","d20b9cc9":"# #Feature Scaling","5d6bff4a":"# #Melakukan Converting Pada Data yang Masih Categorical ke Integer","490842e7":"# #Melakukan Pemodelan Dengan Jumlah Cluster (K) Sembarang"}}