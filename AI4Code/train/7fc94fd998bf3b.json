{"cell_type":{"7085ab21":"code","fcedcf25":"code","94f62080":"code","da57ac7d":"code","2491329b":"code","deacc153":"code","c0c87f28":"code","aecfd3ef":"code","c4ed1996":"code","2d359737":"code","48c5bd30":"code","604498e8":"code","00cf6339":"code","824c6818":"markdown","3f3af746":"markdown","a929825d":"markdown","bcd44e93":"markdown","7be87dcd":"markdown","19e5a1a5":"markdown","8f889ee9":"markdown","c789ca31":"markdown","bbafb87e":"markdown","a8991fe3":"markdown"},"source":{"7085ab21":"import os\nimport time\nfrom tqdm import tqdm\n\nfrom collections import OrderedDict\n\nimport numpy as np\nfrom numpy.random import choice\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport PIL\n\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport torchvision\n\nnp.random.seed(42)","fcedcf25":"DATA_DIR = '..\/input'\ntrain_dir = os.path.join(DATA_DIR, 'train')\ntest_dir  = os.path.join(DATA_DIR, 'test')\n\n\ndef train_validation_split(df, val_fraction=0.1):\n    val_ids  = np.random.choice(df.id, size=int(len(df) * val_fraction))\n    val_df   = df.query('id     in @val_ids')\n    train_df = df.query('id not in @val_ids')\n    return train_df, val_df\n\n\ntrain_label_df, val_label_df = train_validation_split(pd.read_csv(os.path.join(DATA_DIR, 'train_labels.csv')),\n                                                      val_fraction=0.1)","94f62080":"def function_timer(function):\n    \n    def wrapper(*args, **kwargs):\n        start    = time.time()\n        result   = function(*args, **kwargs)\n        duration = time.time() - start\n        \n        hours    = int(duration \/\/ 60**2)\n        minutes  = int((duration % 60**2) \/\/ 60)  \n        seconds  = int(duration % 60)\n        print(f'execution-time of function \"{function.__name__}\": {hours}h {minutes}m {seconds}s')\n        \n        return result\n        \n    return wrapper\n\n\nclass HistoPatches(Dataset):\n    \n    def __init__(self,\n                 image_dir: str,\n                 label_df=None,\n                 transform=transforms.ToTensor(),\n                 sample_n=None,\n                 in_memory=False):\n        \"\"\"\n        @ image_dir:   path to directory with images\n        @ label_df:    df with image id (str) and label (0\/1) - only for labeled test-set\n        @ transforms:  image transformation; by default no transformation\n        @ sample_n:    if not None, only use that many observations\n        \"\"\"\n        self.image_dir = image_dir\n        self.label_df  = label_df\n        self.transform = transform\n        self.in_memory = in_memory\n        \n        if label_df is not None:\n            if sample_n:\n                self.label_df = self.label_df.sample(n=sample_n)\n            ids = set(self.label_df.id)\n            self.img_files = [f for f in os.listdir(image_dir) if f.split('.')[0] in ids]\n        else:\n            if sample_n is not None:\n                print('subsampling is currently only implemented when a label-dataframe is provided.')\n                return\n            self.img_files = os.listdir(image_dir)\n        \n        if in_memory:\n            self.id2image = self._load_images()\n\n        print(f'Initialized datatset with {len(self.img_files)} images.\\n')\n        \n    @function_timer\n    def _load_images(self):\n        print('loading images in memory...')\n        id2image = {}\n        \n        for file_name in self.img_files:\n            img = PIL.Image.open(os.path.join(self.image_dir, file_name))\n            X   = self.transform(img)\n            id_ = file_name.split('.')[0]\n            id2image[id_] = X\n            \n        return id2image\n    \n    def __getitem__(self, idx):\n        file_name = self.img_files[idx]\n        id_ = file_name.split('.')[0]\n        \n        if self.in_memory:\n            X = self.id2image[id_]\n        else:\n            img = PIL.Image.open(os.path.join(self.image_dir, file_name))\n            X   = self.transform(img)\n            \n        if self.label_df is not None:\n            y = float(self.label_df.query('id == @id_').label)\n            return X, y\n        else:\n            return X, id_\n    \n    def __len__(self):\n        return len(self.img_files)\n\n    \nmemory      = False\nbatchsize   = 64\nimage_trans = transforms.Compose([#transforms.CenterCrop(30),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize(mean=[0.70017236, 0.5436771, 0.6961061], \n                                                       std=[0.22246036, 0.26757348, 0.19798167])\n                                ])\ntrain_trans = transforms.Compose([transforms.ToTensor(),\n                                  transforms.Normalize(mean=[0.70017236, 0.5436771, 0.6961061], \n                                                       std=[0.22246036, 0.26757348, 0.19798167]),\n                                  transforms.RandomRotation((-180, 180)),\n                                  transforms.RandomHorizontalFlip()])\n                                 \ntrain = HistoPatches(train_dir,\n                     train_label_df,\n                     transform=image_trans,\n                     #sample_n=1000,\n                     in_memory=memory)\n\nval   = HistoPatches(train_dir,\n                     val_label_df,\n                     transform=image_trans,\n                     #sample_n=100,\n                     in_memory=memory)\n\ntrain_loader = DataLoader(train, batch_size=batchsize, shuffle=True)\nval_loader   = DataLoader(val,   batch_size=batchsize, shuffle=False)\n\nX, y = next(iter(train_loader))\nprint('batch-dimensions: ', X.shape, y.shape)","da57ac7d":"def conv_dim(in_dim, k=3, s=1, p=0, p_left=None, p_right=None):\n    \"\"\"\n    Helper function for interactively checking output-dimensions of conv-layers.\n    \"\"\"\n    if p is not None:\n        p_left = p_right = p\n    assert p_left is not None and p_right is not None\n        \n    tmp = (in_dim - k + p_left + p_right) \/ s\n    out_dim = int(np.floor(tmp) + 1)\n    \n    if tmp % 1 != 0:\n        print('no exact output-dim; using Gauss-brackets.')\n    print(f'out-dim: {out_dim}')\n\n\nconv_dim(30, k=3, s=1, p=0)","2491329b":"net = models.densenet121(pretrained=False)\nnet.features = nn.Sequential(\n    nn.Sequential(OrderedDict([\n            ('conv0', nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)),\n            ('norm0', nn.BatchNorm2d(64)),\n            ('relu0', nn.ReLU(inplace=True))\n        ])),  # 96**2 -> 48**2\n    net.features[4:])\n\nnet.classifier = nn.Sequential(\n    nn.Linear(1024, 512),\n    nn.Dropout(p=0.1),\n    nn.ReLU(),\n    nn.Linear(512, 1)\n)","deacc153":"myloss = nn.BCEWithLogitsLoss()\nnet.cuda()\nX, y = next(iter(train_loader))\nX , y = X.cuda(), y.cuda()\nprint('X, y shapes: ', X.shape, y.shape)\nout = net(X).squeeze()\nprint(f'loss: {myloss(y, out.type(torch.DoubleTensor).cuda()).item()}')","c0c87f28":"@function_timer\ndef train_model(net, train, validation, optimizer, device, max_epoch=100, verbose=False):\n    \"\"\"\n    This function returns nothing. The parametes of @net are updated in-place\n    and the error statistics are written to a global variable. This allows to\n    stop the training at any point and still have the results.\n  \n    @ net: a defined model - can also be pretrained\n    @ train, test: DataLoaders of training- and test-set\n    @ max_epoch: stop training after this number of epochs\n    \"\"\"\n    global error_df  # to track error log even when training aborted\n    error_df = pd.DataFrame(columns=['train_bce', 'train_acc', 'train_auc', 'val_bce', 'val_acc', 'val_auc'])\n  \n    criterion = nn.BCEWithLogitsLoss()\n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n\n    net.to(device)\n  \n    print('epoch\\tLR\\ttr-BCE\\ttr-Acc\\ttr-AUC\\t\\tval-BCE\\tval-Acc\\tval-AUC')\n    for epoch in range(max_epoch):\n        net.train()\n        training_bce = training_acc = training_auc = 0\n    \n        for X, y in train:\n            \n            X , y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n\n            # prediction and error:\n            out  = net(X).squeeze()\n            \n            labels = y.detach().cpu().numpy()\n            probabilities = torch.sigmoid(out).detach().cpu().numpy()\n            predictions = probabilities.round()\n            loss = criterion(out.type(torch.DoubleTensor).cuda(), y)\n            \n            training_bce += loss.item()\n            training_acc += np.mean(labels == predictions) * 100\n            training_auc += roc_auc_score(y_true=labels, y_score=probabilities)\n\n            # update parameters:\n            loss.backward()\n            optimizer.step()\n\n        with torch.no_grad():  # no backpropagation necessary\n            net.eval()\n            validation_bce = validation_acc = validation_auc = 0\n\n            for X, y in validation:\n                X , y = X.to(device), y.to(device)\n\n                # prediction and error:\n                out  = net(X).squeeze()\n\n                labels = y.detach().cpu().numpy()\n                probabilities = torch.sigmoid(out).detach().cpu().numpy()\n                predictions = probabilities.round()\n\n                validation_bce += criterion(out.type(torch.DoubleTensor).cuda(), y).item()\n                validation_acc += np.mean(labels == predictions) * 100\n                validation_auc += roc_auc_score(y_true=labels, y_score=probabilities)\n    \n        # convert to batch loss:\n        training_bce   \/= len(train)\n        training_acc   \/= len(train)\n        training_auc   \/= len(train)\n        \n        validation_bce \/= len(validation)\n        validation_acc \/= len(validation)\n        validation_auc \/= len(validation)\n        scheduler.step()\n       \n        #torch.save(net.state_dict(), f'epoch{epoch}.pt')\n        error_stats = [training_bce, training_acc, training_auc, validation_bce, validation_acc, validation_auc]\n        error_df = error_df.append(pd.Series(error_stats, index=error_df.columns), ignore_index=True)\n        print('{}\\t{:.4f}\\t{:.4f}\\t{:.2f}\\t{:.4f}\\t\\t{:.4f}\\t{:.2f}\\t{:.4f}'.format(epoch, optimizer.param_groups[0]['lr'], *error_stats))","aecfd3ef":"optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0)  #5e-6)\n\ntrain_model(net,\n            train_loader,\n            val_loader,\n            optimizer,\n            device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n            max_epoch=9,\n            verbose=False)\ntorch.save(net.state_dict(), 'swag_net.pt')","c4ed1996":"def predict_and_display(net, testset, n=10):\n    \"\"\"\n    Predict @n random examples from the test-set and show images + predictions\n    \"\"\"\n    net.eval()\n    for i in choice(range(len(testset)), size=n):\n        image, label = test_set[i]\n        output = net(image.unsqueeze(0).cuda())\n        prob, pred = prediction_from_output(output.unsqueeze(0))\n        prob, pred = prob.item(), pred.item()\n        evaluation = 'correct' if pred == label else 'mistake'\n\n        plt.figure( figsize=(2, 2) )\n        print(f'\\ntruth: {label} | pred: {pred} | prob: {prob:.2f}')\n        print(f'{evaluation}: ({class_name(label)} vs. {class_name(pred)})')\n        show_image(image, means=channel_means, stdevs=channel_standard_devs)\n\n\ndef plot_error_curves(training_error, validation_error, error_name='error', ylim=None, save_fig=True):\n    \"\"\"\n    @ errors_over_time: list of tuples: (training-error, validation-error)\n    \"\"\"\n    assert len(training_error) == len(validation_error) > 1\n    \n    fig, ax = plt.subplots()\n    ax.plot(range(len(training_error)), training_error)\n    ax.plot(range(len(validation_error)), validation_error)\n    \n    if ylim:\n        ax.set_ylim(*ylim)\n    \n    ax.set_xlabel('epoch')\n    ax.set_ylabel('CE')\n    ax.legend(('training', 'validation'))\n    ax.set_title(f'{error_name} over time')\n    \n    if save_fig:\n        fig.savefig(f'{error_name.replace(\" \", \"_\")}_learning_curve', bbox_inches='tight', transparent=True)\n    \n    plt.show();","2d359737":"plot_error_curves(error_df.train_bce, error_df.val_bce, error_name='Binary Cross Entropy', ylim=(0, 1))","48c5bd30":"plot_error_curves(error_df.train_acc, error_df.val_acc, error_name='Accuracy')","604498e8":"plot_error_curves(error_df.train_auc, error_df.val_auc, error_name='Area Under the Curve')","00cf6339":"def write_submission_file():\n    test = HistoPatches(image_dir=os.path.join(DATA_DIR, 'test'), transform=image_trans)\n    test_loader = DataLoader(test, batch_size=16)\n    prediction_df = pd.DataFrame(columns=['id', 'label'])\n\n    for i, (X, ids) in enumerate(test_loader):\n\n        out = net(X.cuda()).squeeze()\n        probabilities = torch.sigmoid(out).detach().cpu().numpy()\n        df = pd.DataFrame({'id': ids, 'label': probabilities})\n        prediction_df = prediction_df.append(df)\n\n    display(prediction_df.head())\n    prediction_df.to_csv('submission.csv', index=False)\n    os.listdir('.')\n\n\nwrite_submission_file()","824c6818":"# Background\n\n#### Playground competition: [Histopathologic Cancer Detection](https:\/\/www.kaggle.com\/c\/histopathologic-cancer-detection)\n\nThis kernel was created for a data-science project at the University of Salzburg in collaboration with my collegue [Marcel](https:\/\/www.kaggle.com\/msteger93). Check out his version of our kernel [here](https:\/\/www.kaggle.com\/msteger93\/best-swagoverflowkernel-clr)!\n\n#### Architecture\n\nWe used the [densenet121 implemenation](https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/densenet.py) of the  [DenseNet architecture](https:\/\/arxiv.org\/abs\/1608.06993) and made a couple of changes to adapt it for the use-case at hand.\n\n#### Data\n\nAt first, we tried using only the center 32x32 region because we thought that maybe only the region (possibly) containing tumor tissue is relevant (see [PCAM data-set description](https:\/\/github.com\/basveeling\/pcam)). An advantage of this approach would have been that the cropped dataset fits into memory and would allow faster training and experimentation. Unfortunately, the performance turned out to be lower than with the full images so we reverted to using the full images again.\n\n**Data Augmentation**:\n\nThe Data is inherently rotation-equivariant as described in the [paper](https:\/\/arxiv.org\/abs\/1806.03962) written by the Benchmark-creators. Simply put: if you rotate an image by a random number of degrees, it still looks like any other image and is an equally valid training example.\n\nFor this reason, we added random rotations and random horizontal flips as data augementation to increase the diversity of the training set.\n\n","3f3af746":"# Results and inference","a929825d":"Check the architecture by processing a single batch:","bcd44e93":"# Architecture adaptation","7be87dcd":"# Load data\n\nFor experimenting, it's convenient to use only a subset of the dataset (up to 50k) and load it into memory. It takes a few minutes to load but greatly speeds up the training processes and allows to quicky examine different hyperparameter settings.\n\nAs the whole data-set doesn't fit into memory, it has to read from disk and training takes too long for interactive sessions => only for commiting the kernel.","19e5a1a5":"## Make predictions\nIf all the memory is used up during training, the kernel frequently crashes when making the predictions. For this reason, we calculate the predictions only on the CPU even though it takes a while.","8f889ee9":"The densenet121 architecture expects 224x224 input images and has 1000 output neurons (for the 1000 classes of ImageNet). For the PCAM dataset, we need to adapt the first part of the conv-net for the 96x96 images. In short, we just need less downsampling. Instead of using one large-kernel (7x7), stride=2 convolution as well as max-pooling layer, we only use one stride=2 convolution which downsamples the feature-maps to half the resolution (48x48). The four dense-blocks are left unchange. Finally, of course the classifier hast to be exchanged for a binary classifier. We chose to try a two-layer MLP instead of a single fully connected layer although it probably doesn't make much difference.","c789ca31":"### [densenet121 architecture](https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/densenet.py)\n\n![image.png](attachment:image.png)","bbafb87e":"**Download for interactive session:**  \n<a href=\"submission.csv\"> submission-file <\/a>   \n<a href=\"swag_net\"> net parameters<\/a>  ","a8991fe3":"# Train model"}}