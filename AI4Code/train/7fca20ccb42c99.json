{"cell_type":{"f2cc76b4":"code","1c860d24":"code","bc7df231":"code","10c4fbe8":"code","0591d3e6":"code","34eb8c7c":"code","f2f89859":"code","a91db9ac":"code","fbfdcbda":"code","acd245f0":"code","a37ab797":"code","78f5c306":"code","9f121959":"code","a5ec9889":"code","a8227280":"code","021d60e1":"code","335f2c0f":"code","5b24280b":"code","7a38a668":"code","cf3e1eab":"markdown","b1c9c24d":"markdown","411503f1":"markdown","8b4c86cf":"markdown","d09f0092":"markdown","3c5d6395":"markdown","b61050e5":"markdown"},"source":{"f2cc76b4":"from bs4 import BeautifulSoup\nimport requests\nimport numpy as np\nimport pandas as pd\nimport re\nimport os","1c860d24":"#path to write excel versions of dataframes to [change to whatever you prefer]\n#path_name = r'C:\\Skating_Data'","bc7df231":"event_details_links=[\n    r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT003SEG003.html'  #1 Eastern Great Lakes Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT004SEG004.html'  #2 Eastern Great Lakes Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT005SEG005.html'  #3 Eastern Great Lakes Group C \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT006SEG006.html'  #4 Eastern Great Lakes Group D\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT007SEG007.html'  #5 Eastern Great Lakes Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/CAT007SEG008.html'  #6 Eastern Great Lakes Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27736\/CAT001SEG001.html'  #7 Central Pacific Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27736\/CAT001SEG002.html'  #8 Central Pacific Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/CAT007SEG001.html'  #9 North Atlantic Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/CAT008SEG002.html'  #10 North Atlantic Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/CAT009SEG003.html'  #11 North Atlantic Group C \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/CAT010SEG008.html'  #12 North Atlantic Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/CAT010SEG009.html'  #13 North Atlantic Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT004SEG004.html'  #14 Upper Great Lakes Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT005SEG005.html'  #15 Upper Great Lakes Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT006SEG006.html'  #16 Upper Great Lakes Group C\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT007SEG007.html'  #17 Upper Great Lakes Group D\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT019SEG029.html'  #18 Upper Great Lakes Short Program \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/CAT019SEG030.html'  #19 Upper Great Lakes Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27734\/CAT003SEG003.html'  #20 Northwest Pacific Short Program \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27734\/CAT003SEG004.html'  #21 Northwest Pacific Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/CAT007SEG001.html'  #22 Southwest Pacific Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/CAT006SEG002.html'  #23 Southwest Pacific Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/CAT005SEG003.html'  #24 Southwest Pacific Group C\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/CAT008SEG010.html'  #25 Southwest Pacific Short Program \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/CAT008SEG011.html'  #26 Southwest Pacific Free Skate \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT006SEG001.html'  #27 New England Group A \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT007SEG002.html'  #28 New England Group B \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT008SEG003.html'  #29 New England Group C \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT009SEG004.html'  #30 New England Group D \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT010SEG005.html'  #31 New England Group E\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT011SEG010.html'  #32 New England Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/CAT011SEG011.html'  #33 New England Free Skate \n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT005SEG005.html'  #34 South Atlantic Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT006SEG006.html'  #35 South Atlantic Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT007SEG007.html'  #36 South Atlantic Group C\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT008SEG008.html'  #37 South Atlantic Group D\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT009SEG009.html'  #38 South Atlantic Group E\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT010SEG010.html'  #39 South Atlantic Group F\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT026SEG017.html'  #40 South Atlantic Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/CAT026SEG018.html'  #41 South Atlantic Free Skate\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/CAT005SEG005.html'  #42 Southwestern Group A\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/CAT006SEG006.html'  #43 Southwestern Group B\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/CAT007SEG007.html'  #44 Southwestern Group C\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/CAT008SEG008.html'  #45 Southwestern Short Program\n   ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/CAT008SEG009.html'  #46 Southwestern Free Skate\n]","10c4fbe8":"protocol_links=[\n     r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM003.html'  #1 Eastern Great Lakes Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM004.html'  #2 Eastern Great Lakes Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM005.html'  #3 Eastern Great Lakes Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM006.html'  #4 Eastern Great Lakes Group D\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM007.html'  #5 Eastern Great Lakes Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27729\/SEGM008.html'  #6 Eastern Great Lakes Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27736\/SEGM001.html'  #7 Central Pacific Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27736\/SEGM002.html'  #8 Central Pacific Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/SEGM001.html'  #9 North Atlantic Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/SEGM002.html'  #10 North Atlantic Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/SEGM003.html'  #11 North Atlantic Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/SEGM008.html'  #12 North Atlantic Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27723\/SEGM009.html'  #13 North Atlantic Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM004.html'  #14 Upper Great Lakes Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM005.html'  #15 Upper Great Lakes Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM006.html'  #16 Upper Great Lakes Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM007.html'  #17 Upper Great Lakes Group D\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM029.html'  #18 Upper Great Lakes Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27732\/SEGM030.html'  #19 Upper Great Lakes Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27734\/SEGM003.html'  #20 Northwest Pacific Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27734\/SEGM004.html'  #21 Northwest Pacific Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/SEGM001.html'  #22 Southwest Pacific Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/SEGM002.html'  #23 Southwest Pacific Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/SEGM003.html'  #24 Southwest Pacific Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/SEGM010.html'  #25 Southwest Pacific Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27738\/SEGM011.html'  #26 Southwest Pacific Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM001.html'  #27 New England Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM002.html'  #28 New England Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM003.html'  #29 New England Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM004.html'  #30 New England Group D\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM005.html'  #31 New England Group E\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM010.html'  #32 New England Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27721\/SEGM011.html'  #33 New England Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM005.html'  #34 South Atlantic Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM006.html'  #35 South Atlantic Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM007.html'  #36 South Atlantic Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM008.html'  #37 South Atlantic Group D\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM009.html'  #38 South Atlantic Group E\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM010.html'  #39 South Atlantic Group F\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM017.html'  #40 South Atlantic Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27725\/SEGM018.html'  #41 South Atlantic Free Skate\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/SEGM005.html'  #42 Southwestern Group A\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/SEGM006.html'  #43 Southwestern Group B\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/SEGM007.html'  #44 Southwestern Group C\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/SEGM008.html'  #45 Southwestern Short Program\n    ,r'https:\/\/ijs.usfigureskating.org\/leaderboard\/results\/2020\/27727\/SEGM009.html'  #46 Southwester\n]  ","0591d3e6":"def event_details(protocols, eventdeets):\n    \n    eventindex_list=[]\n    eventindex2_list=[]\n    title_list=[]\n    event_list=[]\n    eventdate_list=[]\n    seg_list=[]\n    starttime_list=[]\n    #venue_list=[]\n    \n    for i in range(0,len(protocols)):\n        website=protocols[i]\n        #print(protocols[i])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n        \n        #Get the Event Title\n        for link in soup.find_all('h2',class_='title'):\n            event_list.append(link.get_text(strip=True)) \n            eventindex_list.append(i+1) \n            \n        #get the Event Segment info\n        for link in soup.find_all('h2',class_='catseg'):\n            seg_list.append(link.get_text(strip=True))     \n            \n    for j in range(0,len(eventdeets)):\n        website=eventdeets[j]\n        #print(eventdeets[j])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n           \n        #Get the event start time\n        for link in soup.find_all('span', {\"class\":\"segStartTime\"}):\n            starttime_list.append(link.get_text(strip=True))  \n            eventindex2_list.append(j+1)\n            \n        #I had a hart time extracting venue information - skipping!  \n        #Will certainly welcome constructive feedback on how to extract this :)\n    \n    Event_Details=pd.DataFrame(eventindex_list, columns=['Event_Index'])\n    Event_Details['Event']=pd.DataFrame(event_list)\n    Event_Details['Event_Segment']=pd.DataFrame(seg_list)\n    Event_Details['Event_Name']=Event_Details['Event_Segment'].str.split(' \/ ', expand=True)[0]\n    Event_Details['Program_Type']=Event_Details['Event_Segment'].str.split(' \/ ', expand=True)[1]\n    Event_Details['Group']=Event_Details['Event_Segment'].str.extract(pat = '([Grp ].)')\n    \n    #Borrowing a trick from stackoverflow to extract if strings contained in a list\n    #https:\/\/stackoverflow.com\/questions\/41954822\/extract-string-from-a-dataframe-comparing-to-a-list\n    levels = ['Juvenile', 'Intermediate', 'Novice', 'Junior', 'Senior']\n    gender = ['Girls', 'Boys', 'Ladies', 'Men']\n    group = ['Grp A', 'Grp B', 'Grp C', 'Grp D', 'Grp E', 'Grp F', 'Grp G', 'Grp H', 'Grp I', 'Grp J', 'Grp K', 'Grp L',\n             'Grp M', 'Grp N', 'Grp O', 'Grp P', 'Grp Q', 'Grp R', 'Grp S', 'Grp T', 'Grp U', 'Grp V', 'Grp W', 'Grp X',\n             'Grp Y', 'Grp Z']  #don't love how I did this one, but struggled for something slicker\n    region = ['New England', 'North Atlantic', 'South Atlantic', 'Eastern Great Lakes', 'Southwestern', 'Upper Great Lakes',\n     'Central Pacific', 'Northwest Pacific', 'Southwest Pacific']\n    region_section_dic = {'Region' : region, 'Section' :\n     ['Eastern', 'Eastern', 'Eastern', 'Midwestern', 'Midwestern', 'Midwestern', 'Pacific', 'Pacific', 'Pacific']}\n    region_section = pd.DataFrame(data=region_section_dic)\n    Event_Details['Level'] = Event_Details['Event_Segment'].str.extract(\"(\" + \"|\".join(levels) +\")\", expand=False)\n    Event_Details['Gender'] = Event_Details['Event_Segment'].str.extract(\"(\" + \"|\".join(gender) +\")\", expand=False)\n    Event_Details['Group'] = Event_Details['Event_Segment'].str.extract(\"(\" + \"|\".join(group) +\")\", expand=False)\n    Event_Details['Group']=np.where(Event_Details['Group'].isna(), \" \", Event_Details['Group'].str.get(-1))\n    Event_Details['Round']=np.where(Event_Details['Group']==\" \", \"Final\", \"Qualifying\")\n    Event_Details['Region'] = Event_Details['Event'].str.extract(\"(\" + \"|\".join(region) +\")\", expand=False)\n    #Note: region\/section might not be applicable for all protocols, \n    #so may make sense to comment this out depending on the events of interest OR add additional arguments to the function\n    \n    Event_Details2=pd.DataFrame(eventindex2_list, columns=['Event_Index'])\n    Event_Details2['Event_StartTime']=pd.DataFrame(starttime_list)\n    Event_Details2['Event_Date']=Event_Details2['Event_StartTime'].str.split(',', expand=True)[0]\n    Event_Details2['Event_Time']=Event_Details2['Event_StartTime'].str.split(',', expand=True)[1]\n    Event_Details2.drop(columns={'Event_StartTime'}, inplace=True)\n    \n    Event_Details=Event_Details.merge(Event_Details2, how='left', on='Event_Index')\n    Event_Details=Event_Details.merge(region_section, how='left', on='Region')\n    \n    order_list=['Event_Index', 'Section', 'Region', 'Event', 'Level', 'Gender', 'Round', 'Group', 'Program_Type', \n                'Event_Date', 'Event_Time']\n    \n    return Event_Details[order_list]","34eb8c7c":"Event_Details = event_details(protocols=protocol_links, eventdeets=event_details_links)\nEvent_Details","f2f89859":"#Event_Details.to_csv(os.path.join(path_name, r'Scraped_Event_Details.csv'), index=False)","a91db9ac":"def official_details(eventdeets):\n    \n    eventindex_list=[]\n    officials_list=[]\n    \n    for j in range(0,len(eventdeets)):\n        website=eventdeets[j]\n        #print(eventdeets[j])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n        \n        for elem in soup.find_all(\"table\", {\"class\":\"officials ladies\"}):\n            #officials_list.append([td.get_text() for td in elem.find_all('td')])\n            for td in elem.find_all('td'):\n                eventindex_list.append(j+1)\n                officials_list.append([td.get_text()])\n        for elem in soup.find_all(\"table\", {\"class\":\"officials men\"}):\n            #officials_list.append([td.get_text() for td in elem.find_all('td')])\n            for td in elem.find_all('td'):\n                eventindex_list.append(j+1)\n                officials_list.append([td.get_text()])\n                \n    officials_list=list(np.concatenate(officials_list).flat)\n    length=int(len(officials_list)\/2)\n    officials_list=np.asarray(officials_list)\n    officials_list=officials_list.reshape(length, 2)\n    \n    Official_Details=pd.DataFrame(officials_list ,columns=['Official','Official_NameLocation'])\n    Official_Details['Official_Name']=Official_Details['Official_NameLocation'].str.split(',', expand=True)[0]\n    Official_Details['Official_City']=Official_Details['Official_NameLocation'].str.split(',', expand=True)[1]\n    Official_Details['Official_StateOrCountry']=Official_Details['Official_NameLocation'].str.split(',', expand=True)[2]\n    Official_Details.drop(['Official_NameLocation'], axis='columns', inplace=True)\n    Official_Details['Official_Name']=Official_Details['Official_Name'].str.strip()\n    Official_Details['Official_City']=Official_Details['Official_City'].str.strip()\n    Official_Details['Official_StateOrCountry']=Official_Details['Official_StateOrCountry'].str.strip()\n    \n    Official_Details['Event_Index']=pd.DataFrame(eventindex_list[::2]) #the ::2 slice is to just grab every other row\n\n    order_list = ['Event_Index', 'Official', 'Official_Name', 'Official_City', 'Official_StateOrCountry']\n    \n    return Official_Details[order_list]","fbfdcbda":"Official_Details = official_details(eventdeets=event_details_links)\nOfficial_Details","acd245f0":"#Official_Details.to_csv(os.path.join(path_name, r'Scraped_Official_Details.csv'), index=False)","a37ab797":"def skater_details(protocols, eventdeets, show_Nation=False):\n    \n    eventindex_list=[]\n    eventindex2_list=[]\n    rank_list=[]\n    nameclub_list=[]\n    nameclub2_list=[]\n    nation_list=[]\n    totSeg_list=[]\n    totElm_list=[]\n    totComp_list=[]\n    totDed_list=[]\n    dedname_list = []\n    dedval_list = []\n    start_list=[]\n    dedname_list = []\n    dedval_list = []\n    falls_ded=[]\n    costumeprop_ded=[]\n    timeviolation_ded=[]\n    falls_counter=0\n    costumeprop_counter=0\n    timeviolation_counter=0\n    \n    for i in range(0,len(protocols)):\n        \n        website=protocols[i]\n        #print(protocols[i])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n        \n        #Get the skater placements\n        for link in soup.find_all('td',class_='rank'):\n            rank_list.append(link.get_text(strip=True))\n            eventindex_list.append(i+1)\n        \n        #Get the skater name and club name\n        for elem in soup.find_all(\"table\", {\"class\":\"sum\"}):\n            nameclub_list.append(td.get_text(strip=True) for td in elem.find_all('td', class_='name'))\n\n        #Get the skater nation (not relevant for Intermediate Ladies but for international competitions would be)\n        if show_Nation==True:\n            for link in soup.find_all('td',class_='nation'):\n                nation_list.append(link.get_text(strip=True))\n            Skater_Details['Skater_Nation']=pd.DataFrame(nation_list)\n        else:\n            pass\n        \n        #Get the total segment score\n        for link in soup.find_all('td',class_='totSeg'):\n            totSeg_list.append(link.get_text(strip=True))\n        \n        #Get the total element score\n        for link in soup.find_all('td',class_='totElm'):\n            totElm_list.append(link.get_text(strip=True))\n\n        #Get the total component score\n        for link in soup.find_all('td',class_='totComp'):\n            totComp_list.append(link.get_text(strip=True))\n            \n        #Get the total deduction score\n        for link in soup.find_all('td',class_='totDed'):\n            totDed_list.append(link.get_text(strip=True))    \n        \n        #Get details on deductions - comes out as lists of lists\n        for elem in soup.find_all(\"table\", {\"class\":\"ded\"}):\n            dedname_list.append([td.get_text() for td in elem.find_all('td', class_='name')])\n            dedval_list.append([td.get_text() for td in elem.find_all('td', class_='value')])\n   \n    #Lengthy code below is to get the individual deductions for falls, time violations, and costume\/prop    \n    for ded in dedname_list: \n        if 'Falls:' in ded:\n            falls_ded.append(dedval_list[falls_counter][ded.index('Falls:')])\n        else:\n            falls_ded.append(0)\n        falls_counter=falls_counter+1\n        \n    for ded in dedname_list: \n        if 'Costume failure:' in ded:\n            costumeprop_ded.append(dedval_list[costumeprop_counter][ded.index('Costume failure:')])\n        else:\n            costumeprop_ded.append(0)\n        costumeprop_counter=costumeprop_counter+1\n\n    for ded in dedname_list: \n        if 'Time violation:' in ded:\n            timeviolation_ded.append(dedval_list[timeviolation_counter][ded.index('Time violation:')])\n        else:\n            timeviolation_ded.append(0)\n        timeviolation_counter=timeviolation_counter+1\n    \n    #Shape lists into an initial dataframe\n    Skater_Details=pd.DataFrame(data=eventindex_list, columns=['Event_Index'])\n    Skater_Details['Skater_Placement']=pd.DataFrame(rank_list)\n    Skater_Details['Skater_NameClub']=pd.DataFrame(nameclub_list)  \n    Skater_Details['Total_Segment_Score']=pd.DataFrame(totSeg_list).astype('float')\n    Skater_Details['Total_Element_Score']=pd.DataFrame(totElm_list).astype('float')\n    Skater_Details['Total_Component_Score']=pd.DataFrame(totComp_list).astype('float')\n    Skater_Details['Deductions_Total']=pd.DataFrame(totDed_list)\n    Skater_Details['Deductions_Total']=pd.to_numeric(Skater_Details['Deductions_Total'], errors='coerce')*-1\n    Skater_Details['Deductions_Falls']=pd.DataFrame(falls_ded)\n    Skater_Details['Deductions_Falls']=pd.to_numeric(Skater_Details['Deductions_Falls'], errors='coerce')\n    Skater_Details['Deductions_CostumeOrPropFailure']=pd.DataFrame(costumeprop_ded)\n    Skater_Details['Deductions_CostumeOrPropFailure']=pd.to_numeric(Skater_Details['Deductions_CostumeOrPropFailure'], errors='coerce')\n    Skater_Details['Deductions_TimeViolation']=pd.DataFrame(timeviolation_ded)\n    Skater_Details['Deductions_TimeViolation']=pd.to_numeric(Skater_Details['Deductions_TimeViolation'], errors='coerce')\n    \n    for j in range(0,len(eventdeets)):\n        website=eventdeets[j]\n        #print(eventdeets[j])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n        \n        #Get the start order\n        for link in soup.find_all('td',class_='start'):\n            start_list.append(link.get_text(strip=True))\n            eventindex2_list.append(j+1)\n            \n        #Get the start order\n        for link in soup.find_all('td',class_='name'):\n            nameclub2_list.append(link.get_text(strip=True)) \n    \n    Event_Details=pd.DataFrame(data=eventindex2_list, columns=['Event_Index'])\n    Event_Details['Skate_Order']=pd.DataFrame(start_list).astype('int64', errors='ignore')\n    Event_Details['Skater_NameClub']=pd.DataFrame(nameclub2_list)\n    \n    Skater_Details=Skater_Details.merge(Event_Details, how='outer', on=['Event_Index','Skater_NameClub'])\n    Skater_Details['Skater_Name']=Skater_Details['Skater_NameClub'].str.split(',', expand=True)[0]\n    Skater_Details['Skater_Club']=Skater_Details['Skater_NameClub'].str.split(',', expand=True)[1]\n    Skater_Details['Skater_Club']=Skater_Details['Skater_Club'].str.strip()\n    Skater_Details['Skate_Order']=np.where(Skater_Details['Skate_Order']=='','WD',Skater_Details['Skate_Order'])\n    Skater_Details['Skater_Placement']=np.where(Skater_Details['Skater_Placement'].isnull(),'WD',\n                                                Skater_Details['Skater_Placement'])\n    \n    order_list=['Event_Index','Skater_Placement','Skate_Order','Skater_NameClub','Skater_Name','Skater_Club', \n                'Total_Segment_Score','Total_Element_Score','Total_Component_Score',\n                'Deductions_Total','Deductions_Falls','Deductions_CostumeOrPropFailure','Deductions_TimeViolation']\n    \n    return Skater_Details[order_list]","78f5c306":"Skater_Details=skater_details(protocols=protocol_links, eventdeets=event_details_links, show_Nation=False)\nSkater_Details","9f121959":"#Skater_Details.to_csv(os.path.join(path_name, r'Scraped_Skater_Details.csv'), index=False)","a5ec9889":"def element_details(protocols):\n    \n    eventindex_list=[]\n    elemnum_list=[]\n    elem_list=[]\n    eleminfo_list=[]\n    elembv_list=[]\n    elem2ndhalf_list=[]\n    elemgoe_list=[]\n    elempsv_list=[]\n    elemjud_list=[]\n    rank_list=[]\n    skater_counter=0\n    \n    for i in range(0,len(protocols)):\n        \n        website=protocols[i]\n        #print(protocols[i])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')\n        \n        #Get the element number, and add the event index\n        for link in soup.find_all('td',class_='num'):\n            elemnum_list.append(link.get_text(strip=True))\n            eventindex_list.append(i+1)\n    \n        #Get the element name\n        for link in soup.find_all('td',class_='elem'):\n            elem_list.append(link.get_text(strip=True))\n    \n        #Get the information on element errors\n        for link in soup.find_all('td',class_='info'):\n            eleminfo_list.append(link.get_text(strip=True))\n    \n        #Get the element base value\n        for link in soup.find_all('td',class_='bv'):\n            elembv_list.append(link.get_text(strip=True))\n    \n        #Get the indicator for whether or not the element was in the second half of the program\n        for link in soup.find_all('td',class_='two'):\n            elem2ndhalf_list.append(link.get_text(strip=True))\n    \n        #Get the GOE\n        for link in soup.find_all('td',class_='goe'):\n            elemgoe_list.append(link.get_text(strip=True))\n    \n        #Get the Panel Scores (BV + GOE)\n        for link in soup.find_all('td',class_='psv'):\n            elempsv_list.append(link.get_text(strip=True))        \n        \n        #Get the individual judges' GOEs\n        for elem in soup.find_all(\"table\", {\"class\":\"elm\"}):\n            elemjud_list.append([td.get_text(strip=True) for td in elem.find_all('td', class_='jud')]) \n        \n    #Get the skater placements\n    elemnum_list=[int(i) for i in elemnum_list]\n    nexteventindex_list=eventindex_list[1::] \n    nexteventindex_list.append(np.NaN) \n    skater_counter=0\n    \n    for i in range(0, len(elemnum_list)):\n        if ((elemnum_list[i] == 1) & (eventindex_list[i]==nexteventindex_list[i])):\n            skater_counter=skater_counter+1\n            rank_list.append(skater_counter)\n        elif eventindex_list[i]!=nexteventindex_list[i]:\n            rank_list.append(skater_counter)\n            skater_counter=0\n        else:\n            rank_list.append(skater_counter)\n    \n    # convert list to numpy array, flatten, then back again\n    elemjud_list=np.asarray(elemjud_list,  dtype=object)\n    elemjud_list=list(np.concatenate(elemjud_list).flat)\n    elemjud_list=np.asarray(elemjud_list,  dtype=object)\n\n    # reshape array into 4 rows x 2 columns, and transpose the result\n    elemjud_list = elemjud_list.reshape(len(elemnum_list), 10)\n\n    #make into dataframe\n    Technical_Scores=pd.DataFrame(elemjud_list,columns=['J1_GOE','J2_GOE','J3_GOE','J4_GOE','J5_GOE',\n                                                 'J6_GOE','J7_GOE','J8_GOE','J9_GOE','DEL'])\n    Technical_Scores.drop('DEL', axis=1, inplace=True)\n    Technical_Scores=Technical_Scores.apply(pd.to_numeric, errors='ignore')\n    \n    Technical_Scores['Event_Index']=pd.DataFrame(eventindex_list)\n    Technical_Scores['Skater_Placement']=pd.DataFrame(rank_list)\n    Technical_Scores['Element_Number']=pd.DataFrame(elemnum_list)\n    Technical_Scores['Element']=pd.DataFrame(elem_list)\n    Technical_Scores['I']=pd.DataFrame(eleminfo_list)\n    Technical_Scores['Base_Value']=pd.DataFrame(elembv_list).astype('float')\n    Technical_Scores['FreeSkate2ndHalfJump_Flag']=pd.DataFrame(elem2ndhalf_list)\n    Technical_Scores['GOE']=pd.DataFrame(elemgoe_list).astype('float')     \n    Technical_Scores['PanelScores_Technical']=pd.DataFrame(elempsv_list).astype('float')  \n\n    order_list=['Event_Index', 'Skater_Placement', 'Element_Number', 'Element', 'I', 'Base_Value', 'FreeSkate2ndHalfJump_Flag', \n               'GOE','J1_GOE','J2_GOE','J3_GOE','J4_GOE','J5_GOE','J6_GOE','J7_GOE','J8_GOE','J9_GOE', 'PanelScores_Technical']\n\n    return Technical_Scores[order_list]","a8227280":"Technical_Scores=element_details(protocols=protocol_links)\nTechnical_Scores","021d60e1":"#Technical_Scores.to_csv(os.path.join(path_name, r'Scraped_Technical_Scores.csv'), index=False)","335f2c0f":"def component_details(protocols):\n    \n    eventindex_list=[]\n    eventindex2_list=[]\n    rank_list=[]\n    rank2_list=[]\n    compgcfv_list=[]\n    compnames_list=[]\n    compcf_list=[]\n    compcjud_list=[]\n    comppanel_list=[]\n    skater_counter=0\n    \n    for i in range(0,len(protocols)):\n        \n        website=protocols[i]\n        #print(protocols[i])\n        \n        #Get The HTML\n        result = requests.get(website)\n        content = result.text\n        soup = BeautifulSoup(content, 'html.parser')       \n            \n        #Get component names\n        for link in soup.find_all('td',class_='cn'):\n            compnames_list.append(link.get_text(strip=True))\n            eventindex_list.append(i+1)\n            \n        #Get component factors\n        for link in soup.find_all('td',class_='cf'):\n            compcf_list.append(link.get_text(strip=True))\n    \n        #Get factored panel scores\n        for link in soup.find_all('td',class_='panel'):\n            comppanel_list.append(link.get_text())\n            \n        #Get individual raw judge scores\n        for link in soup.find_all('td',class_='cjud'):\n            compcjud_list.append(link.get_text(strip=True))  \n        \n        #Get the general component factor - this will be of a different shape than the rest\n        for link in soup.find_all('td',class_='gcfv'):\n            compgcfv_list.append(link.get_text(strip=True))\n            eventindex2_list.append(i+1)\n            \n        #Get the skater placements for general component factor matrix\n        for link in soup.find_all('td',class_='rank'):\n            rank2_list.append(link.get_text(strip=True))    \n        \n                 \n    #Get the skater placements\n    nexteventindex_list=eventindex_list[1::]\n    nexteventindex_list.append(np.NaN) \n    skater_counter=0\n    for i in range(0, len(compnames_list)):\n        if ((compnames_list[i] == 'Skating Skills') & (eventindex_list[i]==nexteventindex_list[i])):\n            skater_counter=skater_counter+1\n            rank_list.append(skater_counter)\n        elif eventindex_list[i]!=nexteventindex_list[i]:\n            rank_list.append(skater_counter)\n            skater_counter=0\n        else:\n            rank_list.append(skater_counter)\n        \n            \n    # convert list to numpy array, flatten, then back again\n    compcjud_list=np.asarray(compcjud_list)\n\n    # reshape array into 4 rows x 2 columns, and transpose the result\n    compcjud_list = compcjud_list.reshape(len(compnames_list), 9)\n    \n    #make into dataframe\n    Component_Scores=pd.DataFrame(compcjud_list,columns=['J1_PC','J2_PC','J3_PC','J4_PC','J5_PC',\n                                                 'J6_PC','J7_PC','J8_PC','J9_PC'])    \n    \n    Component_Scores=Component_Scores.apply(pd.to_numeric, errors='coerce')\n    \n    Component_Scores['Event_Index']=pd.DataFrame(eventindex_list)\n    Component_Scores['Program_Components']=pd.DataFrame(compnames_list)\n    Component_Scores['PC_Factor']=pd.DataFrame(compcf_list).astype('float')\n    Component_Scores['PanelScores_PC']=pd.DataFrame(comppanel_list).astype('float')\n    Component_Scores['Skater_Placement']=pd.DataFrame(rank_list)\n    \n    Component_Scores2= pd.DataFrame(eventindex2_list, columns=['Event_Index'])\n    Component_Scores2['Skater_Placement']=pd.DataFrame(rank2_list)\n    Component_Scores2['Skater_Placement']=pd.to_numeric(Component_Scores2['Skater_Placement'])\n    Component_Scores2['PC_Factor_General']=pd.DataFrame(compgcfv_list).astype('float')\n\n    Component_Scores= Component_Scores.merge(Component_Scores2, how='left', on=['Event_Index','Skater_Placement'])\n    \n    order_list=['Event_Index', 'Skater_Placement', 'Program_Components', 'PC_Factor', 'PC_Factor_General', \n                'J1_PC','J2_PC','J3_PC','J4_PC','J5_PC','J6_PC','J7_PC','J8_PC','J9_PC', 'PanelScores_PC']\n    \n    return Component_Scores[order_list]","5b24280b":"Component_Scores  = component_details(protocols=protocol_links)\nComponent_Scores","7a38a668":"#Component_Scores.to_csv(os.path.join(path_name, r'Scraped_Component_Scores.csv'), index=False)","cf3e1eab":"# Library Imports & Data HTML Links","b1c9c24d":"# Component Scores Dataframe","411503f1":"# Skater Detail Dataframe","8b4c86cf":"# Officials Details Dataframe","d09f0092":"\n# Technical Element Scores Dataframe","3c5d6395":"# Background\n\nSkating event protocols for the 2020 Intermediate Ladies Regional Challenge can be found here:   \nhttps:\/\/usfigureskatingfanzone.com\/sports\/figure-skating\/schedule\/2019-20\n\nThe links for the relevant events are itemized below (the order is not chronological and admittedly somewhat random in terms of region order).  The HTML is pretty simple; not a lot of navigating of the HTML trees was really needed.\n\nCode was tested on some other US events (e.g. Junior Men Eastern Great Lakes Regional competitions) and seemed to generalize fairly well.  \n\nNote that the event detail links and protocols are a little different for international events, and therefore this code would need a some tweaking to work on those events.\n","b61050e5":"# Event Details Dataframe"}}