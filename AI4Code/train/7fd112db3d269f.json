{"cell_type":{"c7aaf908":"code","7e57baaa":"code","cd164454":"code","377ebaa8":"code","ed67e50d":"code","687a0165":"code","b9129402":"code","39be916c":"markdown","ecf1ff59":"markdown","18d80df1":"markdown","10ac5baa":"markdown","82000dc2":"markdown","5b160032":"markdown","bc039a54":"markdown","c469a6ed":"markdown","f5071a29":"markdown","9e4c5027":"markdown","4b690740":"markdown","f5d28a5b":"markdown","05b1d45d":"markdown"},"source":{"c7aaf908":"from PIL import Image, ImageEnhance\nimport numpy as np\nfrom PIL import ImageFilter\nimport colorsys\nimport os\nfrom skimage.filters import gabor, gaussian\nfrom IPython.display import display \nfrom matplotlib.pyplot import imshow\nfrom pywt import dwt2\nimport pickle\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nprint(os.listdir(\"..\/input\/\"))\n%matplotlib inline","7e57baaa":"image1 = \"..\/input\/slab.jpg\"\nimage = Image.open(image1).convert('RGB')\nimage_size = image.size\nprint(image_size)\ndisplay(image)","cd164454":"def enhance_brightness(image):\n    \"\"\"\n    :param image: unenhanced image\n    :return: Image with enhanced brightness. The new brightness is within the range of [0.3, 1] if the original brightness is greater than 0.1 else it is set to 0.1\n    \"\"\"\n    mean_brightness = get_brightness(image)\n    a, b = [0.3, 1]\n    if mean_brightness<0.1:\n        a = 0.1\n    min_, max_ = [0, 1]\n    new_brightness = (b - a) * (mean_brightness - min_) \/ (max_ - min_) + a\n        \n    brightness_factor = new_brightness\/mean_brightness\n    enhancer = ImageEnhance.Brightness(image)\n    enhanced_image = enhancer.enhance(brightness_factor)\n    return enhanced_image\n\n\ndef get_brightness(image):\n    \"\"\"\n    :param image: unenhanced image\n    :return: mean brightness of the image\n    \"\"\"\n    brightness = []\n    pixel_values = list(image.getdata())\n    for values in pixel_values:\n        R, G, B = values\n        bright = np.sqrt(0.299 * R ** 2 + 0.587 * G ** 2 + 0.114 * B ** 2) \/ 255\n        brightness.append(bright)\n    return np.mean(brightness)\n\nconverter = ImageEnhance.Color(image)\nimage = converter.enhance(0.5) #enchance color by a factor of 0.5\nimage = enhance_brightness(image)\n# convert to grayscale\nimage = image.convert('L')\ndisplay(image)","377ebaa8":"def get_image_energy(pixels):\n    \"\"\"\n    :param pixels: image array\n    :return: Energy content of the image\n    \"\"\"\n    _, (cH, cV, cD) = dwt2(pixels.T, 'db1')\n    energy = (cH ** 2 + cV ** 2 + cD ** 2).sum() \/ pixels.size\n    return energy\n\n\ndef get_energy_density(pixels):\n    \"\"\"\n    :param pixels: image array\n    :param size: size of the image\n    :return: Energy density of the image based on its size\n    \"\"\"\n    energy = get_image_energy(pixels)\n    energy_density = energy \/ (pixels.shape[0]*pixels.shape[1])\n    return round(energy_density*100,5) # multiplying by 100 because the values are very small\n\npixels = np.asarray(image, dtype=\"int32\")\nenergy_density = get_energy_density(pixels)\n# get fixed bandwidth using energy density\nbandwidth = abs(0.4*energy_density - 0.5)","ed67e50d":"def get_magnitude(response):\n    \"\"\"\n    :param response: original gabor response in the form: [real_part, imag_part] \n    :return: the magnitude response for the input gabor response\n    \"\"\"\n    magnitude = np.array([np.sqrt(response[0][i][j]**2+response[1][i][j]**2)\n                        for i in range(len(response[0])) for j in range(len(response[0][i]))])\n    return magnitude\n\nmagnitude_dict = {}\nfor theta in np.arange(0, np.pi, np.pi \/ 6):\n    for freq in np.array([1.4142135623730951, 2.414213562373095, 2.8284271247461903, 3.414213562373095]): \n        filt_real, filt_imag = gabor(image, frequency=freq, bandwidth=bandwidth, theta=theta)\n        # get magnitude response\n        magnitude = get_magnitude([filt_real, filt_imag])\n        ''' uncomment the lines below to visualize each magnitude response '''\n        # im = Image.fromarray(magnitude.reshape(image_size)).convert('L')\n        # display(im)\n        magnitude_dict[(theta, freq)] = magnitude.reshape(image.size)\n","687a0165":"def apply_pca(array):\n    \"\"\"\n    :param array: array of shape pXd\n    :return: reduced and transformed array of shape dX1\n    \"\"\"\n    # apply dimensionality reduction to the input array\n    standardized_data = StandardScaler().fit_transform(array)\n    pca = PCA(n_components=1)\n    pca.fit(standardized_data)\n    transformed_data = pca.transform(standardized_data)\n    return transformed_data\n\n# apply gaussian smoothing\ngabor_mag = []\nfor key, values in magnitude_dict.items():\n    # the value of sigma is chosen to be half of the applied frequency\n    sigma = 0.5*key[1]\n    smoothed = gaussian(values, sigma = sigma)\n    gabor_mag.append(smoothed)\ngabor_mag = np.array(gabor_mag)\n\n# reshape so that we can apply PCA\nvalue = gabor_mag.reshape((-1, image_size[0]*image_size[1]))\n\n# get dimensionally reduced image\npcaed = apply_pca(value.T).astype(np.uint8)\nresult = pcaed.reshape((image_size[0], image_size[1]))\nresult_im = Image.fromarray(result, mode='L')","b9129402":"display(result_im)","39be916c":"**And here's the result**","ecf1ff59":"## Post-processing","18d80df1":"You can further experiment with orientation, bandwidth and frequency values to get more suitable results. ","10ac5baa":"Now we have obtained the magnitude of 24 gabor filters. The next step is to smooth and reduce the magnitude array. We can apply gaussian smoothing to each of the magnitude response and then apply PCA to reduce the dimensions.  ","82000dc2":"## References\n1. https:\/\/www.mathworks.com\/help\/images\/texture-segmentation-using-gabor-filters.html\n<p>\n2. https:\/\/pdfs.semanticscholar.org\/a53b\/78ff23daf515a344d47f4848e1f2528b3074.pdf","5b160032":"First, we will get the example image and display it. ","bc039a54":"## Applying Gabor Filter","c469a6ed":"While applying gabor filters, we have to careful about the following three paramenters:\n<ol>\n<li>bandwidth<\/li>\n<li>frequency<\/li>\n<li>orientation<\/li>\n<\/ol>\n","f5071a29":"**Gabor Filters** are known best to depict the mammalian multi-channel approach of vision for interpreting and segmenting textures. This notebook shows an implementation of gabor filters in python using sklearn and other libraries to segment textures within an image. We will take an example of a slab image and segment the textures within the image using gabor filter. Our implementation shows three steps: pre-processing, gabor filter and post-processing.\n\nNow lets begin with the required imports.","9e4c5027":"Enhace the color and brightness of the image. Then convert the image to gray scale.","4b690740":"**Theta**:\nTheta represents the orientation of the gabor filter. In this implementation, we have used six orientations from 0 degree to 150 degree with a seperation of 30 degree each. Instead of this, we can also take an orientation seperation of 45 degree but, this would not produce as good results. \n<p>\n**Frequency**:\nAccording to this, for an orientation seperation of 30 degree, the total number of gabor filters required is: 6log2(Nc\/2) where, Nc is the width of the image. The frequencies that should be used are:\n1sqrt(2), 2sqrt(2), 4sqrt(2) ... Nc\/4sqrt(2)<p>\nHowever, in case of our image, we have experimentally chosen the following set of frequencies:\nsqrt(2), 1+sqrt(2), 2+sqrt(2), 2sqrt(2)<p>\nYou can visualize the result of each gabor filter to decide for yourself.\n<p>\nHence we have a total of 24 gabor filters.\n<p>\nThe gabor filter gives a complex response. So we take the magnitude of the response for further processing. ","f5d28a5b":"**Bandwidth**:\nNarrower bandwidth is desirable because they make finer distinction in texture. In this implementation, we have determined the value of bandwidth using energy density of image. The higher the energy density, the lesser the bandwidth so that more textured areas do not overpower less textured areas. ","05b1d45d":"## Pre-processing"}}