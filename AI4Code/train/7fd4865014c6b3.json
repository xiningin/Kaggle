{"cell_type":{"bd0c2ad3":"code","5cc3639c":"code","42385fae":"code","c4e58c34":"code","2e501644":"code","9f76b054":"code","b6e787b9":"code","ff62f14a":"code","7ff4ee84":"code","2c4d5faa":"code","a867e3ed":"code","e426ec08":"code","e03cc7e6":"code","a0786787":"code","69e34892":"code","71dc1cc8":"code","3f76d9a9":"code","4a70b8db":"code","0eae3b7e":"code","9ba1e954":"code","25807350":"code","773e685f":"code","1810d50c":"code","642023d6":"code","466bbb92":"code","1f739207":"code","2b126886":"code","e76ca859":"code","58db0477":"code","c46587b1":"code","ca25960d":"code","71e7bf64":"code","8dcb67a1":"code","6bb98b0d":"code","38bc1c8e":"code","ab5eb8f0":"code","98aee1c9":"code","c14cfc47":"code","da6d420e":"code","6969e52b":"code","60a10d44":"code","b8600d22":"code","72f43084":"code","34ef3385":"code","6e5e715f":"code","4d07cf39":"code","1a7149f1":"code","ddc38c19":"code","04a8edba":"code","6c9638e6":"markdown","55744bd8":"markdown","ab3d2c5c":"markdown","fb7082f7":"markdown","4a50e0b1":"markdown","ed1adc08":"markdown","095f7b07":"markdown","10defc7f":"markdown","26038f9a":"markdown","f9bc67e8":"markdown","f3c6a817":"markdown","25cfc28a":"markdown","54f722b2":"markdown","ca6f1a2f":"markdown","adbb9873":"markdown","dbeb720b":"markdown","27a54c0a":"markdown"},"source":{"bd0c2ad3":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\n\nfrom sklearn.preprocessing import StandardScaler\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report","5cc3639c":"from sklearn.datasets import load_breast_cancer\ndata = load_breast_cancer()\ndata.keys()","42385fae":"print('Target Names:-')\nlist(data['target_names'])","c4e58c34":"print('\\nDescription of the Datasets:-\\n')\nprint(data.DESCR)","2e501644":"x = pd.DataFrame(data['data'],columns=data['feature_names'])\ny = pd.DataFrame(data['target'],columns=['Cancer'])\nx.shape,y.shape","9f76b054":"Df = pd.concat([y,x],1).copy()\nDf.head(2)","b6e787b9":"Df.to_csv(\"data.csv\",index=False)","ff62f14a":"plt.figure(figsize=(16,4))\nsns.heatmap(Df.isnull(),yticklabels=False,cmap='viridis',cbar=False)\nplt.show()\nprint(\"Total Null Values =\",Df.isnull().sum().sum())","7ff4ee84":"dict = {0:'Malignant',1:'Benign'}\n\nynum = y['Cancer'].map(dict)","2c4d5faa":"plt.rcParams['font.size'] =13\nsns.set_style('darkgrid')\nsns.countplot(ynum)\nplt.xlabel(' ')\nplt.title('Cancer data ratio')\nplt.show()","a867e3ed":"Df.describe()","e426ec08":"print('Pearson Co-relation of independent-features with Cancer(target):-\\n')\nplt.figure(figsize=(20,2))\nsns.heatmap(Df.corr()[['Cancer']].T,annot=True,linewidths=1,cmap='viridis',cbar=False)\nplt.show()","e03cc7e6":"scaler=StandardScaler()\nX = scaler.fit_transform(x)","a0786787":"del Df","69e34892":"X = pd.DataFrame(X,columns=x.columns)","71dc1cc8":"del x","3f76d9a9":"print('Standard Normal Distribution & Box-Plot :')\nfor col in X.columns:\n    plt.rcParams['font.size'] =13\n    f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,5))\n    a = X[col]\n    b = y['Cancer']\n    sns.distplot(a,color='g',ax=ax1)\n    sns.boxplot(b,a,ax=ax2)\n    plt.show()","4a70b8db":"f,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(20,5))\nax1.scatter(X['worst concave points'],X['worst perimeter'],c=y.Cancer,marker='.',cmap='rainbow')\nax2.scatter(X['worst concave points'],X['mean concave points'],c=y.Cancer,marker='.',cmap='rainbow')\nax3.scatter(X['worst concave points'],X['smoothness error'],c=y.Cancer,marker='.',cmap='rainbow')\nax4.scatter(X['mean concave points'],X['worst perimeter'],c=y.Cancer,marker='.',cmap='rainbow')\n\nax1.set_xlabel('worst concave points')\nax1.set_ylabel('worst perimeter')\nax2.set_xlabel('worst concave points')\nax2.set_ylabel('mean concave points')\nax3.set_xlabel('worst concave points')\nax3.set_ylabel('smoothness error')\nax4.set_xlabel('mean concave points')\nax4.set_ylabel('worst perimeter')\nsns.despine()\nplt.show()","0eae3b7e":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.1, max_iter=2000)\nlasso.fit(X,y)\n\ncoeff_values = pd.DataFrame({'coeff':lasso.coef_},index=X.columns).sort_values(by='coeff')\nc = (abs(coeff_values.coeff) > 0)\ncol_imp = list(X.columns[c])\ncol_imp","9ba1e954":"x = X[col_imp].copy()\nx.shape","25807350":"df = pd.concat([x,ynum],1).copy()\nsns.pairplot(df,hue='Cancer',height=4)\nplt.show()","773e685f":"benign = df[df['Cancer']== 'Benign']\nbx = benign['mean texture']\nsns.distplot(bx)\nplt.show()\nprint('Skew :',round(bx.skew(),2))","1810d50c":"def Zscore(data,left,right):\n    index= []\n    mean = data.mean()\n    std = data.std()\n    for i in range(len(data)):\n        z = (data.iloc[i]-mean)\/std\n        if (z >= -left) and (z <= right): \n            index.append(i)\n        else:\n            pass\n    return index ","642023d6":"index = Zscore(bx,4,2.2)\nlen(bx)-len(index)","466bbb92":"bx = bx.iloc[index].reset_index(drop=True)\nsns.distplot(bx)\nplt.show()\nprint('Skew :',round(bx.skew(),2))","1f739207":"index1 = df[df['Cancer']== 'Malignant'].index\nclean_index = list(index1) + index\nlen(clean_index)","2b126886":"df = df.iloc[clean_index].reset_index(drop=True)\nsns.pairplot(df,hue='Cancer',height=4)\nplt.show()","e76ca859":"del df,X,bx\ndf = pd.concat([y,x],1).copy()\nDf = df.iloc[clean_index].reset_index(drop=True).copy()\nDf.shape","58db0477":"del df,x,y\nX = Df.drop('Cancer',1).copy()\ny = Df['Cancer'].copy()","c46587b1":"del Df\nX.shape,y.shape","ca25960d":"sp = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\nfor train_index,test_index in sp.split(X,y):\n    xtrain,xtest = X.iloc[train_index],X.iloc[test_index]\n    ytrain,ytest = y.iloc[train_index],y.iloc[test_index]\n\nprint(\"Lenth of train data:\",len(ytrain))\nprint(\"Lenth of test data :\",len(ytest))","71e7bf64":"f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,4))\nsns.countplot(ytrain,ax=ax1,hue=None)\nax1.set_title('Train data ratio of Cancer')\nax1.set_axis_off()\nsns.countplot(ytest,ax=ax2)\nax2.set_title('Test data ratio of Cancer')\nax2.set_axis_off()\nplt.show()","8dcb67a1":"model =  xgb.XGBClassifier(random_state=0,n_jobs=1)\nmodel.fit(xtrain,ytrain)\npred = model.predict(xtest)\naccuracy_score(pred,ytest)","6bb98b0d":"param =[{\"max_depth\":[2,3,4,5],\n    \"learning_rate\":[0.001,0.01,0.1,1],\n    \"n_estimators\":[100,150,200,250]}]\nsearch = GridSearchCV(estimator=model,iid=False,param_grid=param,scoring='accuracy',cv=6,n_jobs=-1)\noutput = search.fit(X,y)\nprint('Best perameter :',output.best_params_)\nprint('Acccuracy      :',round(output.best_score_,2)*100,'%')","38bc1c8e":"def train(X,y,rs=0):\n    model =  xgb.XGBClassifier(max_depth=4,learning_rate=0.1,n_estimators=250,random_state=rs,n_jobs=1)\n    sp = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=rs)\n    for train_index,test_index in sp.split(X,y):\n        xtrain,xtest = X.iloc[train_index],X.iloc[test_index]\n        ytrain,ytest = y.iloc[train_index],y.iloc[test_index]\n        model.fit(xtrain,ytrain)\n        pred = model.predict(xtest)\n        acc = accuracy_score(pred,ytest)\n    print(f'Random State :{rs} & Accuracy :{round(acc*100,2)}')","ab5eb8f0":"train(X,y)","98aee1c9":"for i in range(42):\n    train(X,y,i)   ","c14cfc47":"train(X,y,38)","da6d420e":"model =  xgb.XGBClassifier(max_depth=5,learning_rate=1,random_state=38,n_jobs=1)\nsp = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=38)\nfor train_index,test_index in sp.split(X,y):\n    xtrain,xtest = X.iloc[train_index],X.iloc[test_index]\n    ytrain,ytest = y.iloc[train_index],y.iloc[test_index]\n    model.fit(xtrain,ytrain)\n    pred = model.predict(xtest)\n    acc = accuracy_score(pred,ytest)*100\n    conf = pd.DataFrame(confusion_matrix(pred,ytest),\n                        columns=['Benign','Malignant'],index=['Benign','Malignant'])\n    clas = classification_report(pred,ytest)\n    predr = model.predict(xtrain)\n    accr = accuracy_score(predr,ytrain)*100\n    confr = pd.DataFrame(confusion_matrix(predr,ytrain),\n                         columns=['Benign','Malignant'],index=['Benign','Malignant'])\n    clasr = classification_report(predr,ytrain)\n    \n    \n \nprint(\"\\n\")\nprint(f\"Accuracy Score for Test Data :{acc}%\")\nprint(\"Classification Report for Test Data :-\")\nprint(\"\\n\")\nprint(clas)\nprint(\"\\n\")\nprint(f\"Accuracy Score for Train Data :{accr}%\")\nprint(f\"Classification Report for Train Data :\")\nprint(\"\\n\")\nprint(clasr)\n\nc = confusion_matrix(ytest,pred)\nprint('Result for test data:-\\n')\nprint('Total test data    :',len(ytest))\nprint('Correct Prediction :',(c[0][0]+c[1][1]))\nprint('False Positive     :',c[0][1])\nprint('False Negetive     :',c[1][0])\nprint('Accurecy           :',round((c[0][0]+c[1][1])*100\/len(ytest),2),'%')\nprint('\\n')\n\nf,(ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\nsns.heatmap(conf,annot=True,cbar=False,cmap='rainbow',fmt='.3g',ax=ax1)\nax1.set_title(\"Confusion Matrix for Test Data\")\nsns.heatmap(confr,annot=True,cbar=False,cmap='rainbow',fmt='.3g',ax=ax2)\nax2.set_title(\"Confusion Matrix for Train Data\")\nplt.show()\n\nfig = plt.figure(figsize=(18,2))\nplt.bar(np.arange(1,(len(xtest)+1)),(pred-ytest),color='r',lw = 0.3)\nplt.plot(np.arange(1,(len(xtest)+1)),np.zeros(len(xtest)),color='k',lw = 5)\nplt.title('Confusion Graph : False Positive [Upper Red Line] || False Negetive [Lower Red Line]')\nplt.xlabel('Test Data Range')\nplt.yticks([-1,0,1])\nplt.show()","6969e52b":"import pickle\n#saving model\npkl = open(\"model.pickle\",\"wb\")\npickle.dump(model,pkl)\npkl.close()","60a10d44":"# saving X-data\nX.to_csv('X.csv',index=False)","b8600d22":"del model\ndel xtrain,ytrain,xtest,ytest","72f43084":"#opening model\ntry:\n    model = open(\"model.pickle\",\"rb\")\n    model = pickle.load(model)\n    print('model loaded...')\nexcept:\n    print('Error...model not loaded...')","34ef3385":"#opening data\ntry:\n    X = pd.read_csv('X.csv')\n    print('X data loaded...')\nexcept:\n    print('Error...data not loaded...')  ","6e5e715f":"def prediction(data=X,index=0):\n    try:\n        pred = model.predict(X.iloc[[index]])[0]\n        if pred == 0:\n            print(\"prediction is : Malignant\")\n        else:\n            print(\"prediction is : Benign\")\n    except:\n        print('Index Error...')\n        print(f'Input index within :{len(X)-1}  You have Entered :{index}..')","4d07cf39":"prediction(index=555)","1a7149f1":"prediction(index=505)","ddc38c19":"prediction(index=55)","04a8edba":"print('Thanks..')","6c9638e6":"## Application of the Model using index value","55744bd8":"### This is one of the famous datasets to diagonise the Breast Cancer obtained from sklearn library..\n### Here, I will show how we can get 100% accuracy with LASSO feature Selection And XGBoost Classifier!****","ab3d2c5c":"You can clearly see the difference from the distribution plot","fb7082f7":"### Making Random State Tuning","4a50e0b1":"* So, this is better than before, here only 18 rows to be removed\n\n* here you can look the difference\n\n##### Making clean indices","ed1adc08":"## opening :- model and processed X-data","095f7b07":"## Training and Evaluating of Model with Xgboost classifier","10defc7f":"#### **I will remove few outliers from 'Mean Texture'-Benign, see the distribution plot is overlaping right end , otherwise classification is perfect for all other features","26038f9a":"### Conclusion:-\n* To get 100% accuracy I have done followings:-\n\n1. From EDA I first tried to understand whethere the dataset is normally distributed, and are there some outliers or not? I found there are 18 outliers, so I removed it. \n\n2. I found from LASSO method that not all 30 but only 4 features are most important features,which regulates the target values,however other 26 features are not important to diagonise the breast cancer. So, I took only 4 features.\n\n3. I splitted the datasets into train sets and test sets by stratified shuffle split so, it evenly distributed as per target values, which have helped much to train the model.\n\n4. In case of tunning, I first go for Grid search CV after that I further tuned it with randon state tuning taken into account the hyperparameter values obtained from Grid search. Hence I got 100% accuracy for test sets and train sets as well.\n\n* So you easily can deploy it into surver with heroku or with other platform for use it by any one..","f9bc67e8":"## Saving  :- model and processed X-data","f3c6a817":"#### Z-score - method","25cfc28a":"##### ploting the target & chequing whethere it is abnormal or not!","54f722b2":"### Hyperperametre Tuning with Grid Search CV","ca6f1a2f":"# EDA","adbb9873":"## Training the Model with Stratified train test split","dbeb720b":"* Scatter plot showing classification\n\n### Feature Selection LASSO Method ","27a54c0a":"### Required Libraries"}}