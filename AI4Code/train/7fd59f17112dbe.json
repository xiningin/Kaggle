{"cell_type":{"102113b9":"code","86081a6c":"code","260469f9":"code","66471bae":"code","1069de06":"code","9ecdf3c3":"code","19952ac4":"code","209973fb":"code","fac470fd":"code","6ab07a8f":"code","0831be93":"code","f86cc0d7":"code","da663db4":"code","b6f58e20":"code","d23c8a70":"code","88851dd3":"code","568e5362":"code","fc598730":"code","0564b61a":"code","0eb6e78a":"code","4840d633":"code","4cc1bc10":"code","cfcb2301":"code","a0601a81":"code","1716a883":"code","099201da":"code","80a26cc4":"code","326a7d98":"code","0ca3abf7":"code","ef4f5ff5":"code","80beb1a5":"code","5ba7b2c5":"code","76966b18":"code","7c8b2e88":"code","03ea3456":"code","90cf26b0":"code","5ecdcf78":"code","538962eb":"code","48202bdc":"code","bcc07e85":"code","eacea5d3":"code","524aac44":"code","407e00b4":"code","951232c4":"code","5e32074a":"markdown","0122a43b":"markdown","e71a8020":"markdown"},"source":{"102113b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","86081a6c":"import numpy as np\nimport pandas as pd\n\n## we will import the libraries as and when required.","260469f9":"import os\nprint(\"Current Directory:%s\"%os.getcwd())\nprint(\"List Directories\")\nos.listdir('..\/input\/kddcup99\/kddcup.data')","66471bae":"##  print first 5 lines of file  using python\nfor each_index,each_line in enumerate(open('..\/input\/kddcup99\/kddcup.data\/kddcup.data')):\n    if each_index < 5:\n        print(each_line.strip())","1069de06":"## directly using the unix command line .\n!head -5 '..\/input\/kddcup99\/kddcup.data\/kddcup.data'","9ecdf3c3":"## got the list of column from KDD website. Its not provided here\n\ncolumns_list =[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]","19952ac4":"kdd_raw =pd.read_csv('..\/input\/kddcup99\/kddcup.data\/kddcup.data',names=columns_list,header=None)","209973fb":"kdd_raw.shape","fac470fd":"kdd_raw.head(3)","6ab07a8f":"kdd_raw.service.value_counts()","0831be93":"##  we will work only on http request.\nkdd_http =kdd_raw[kdd_raw[\"service\"]=='http']","f86cc0d7":"kdd_http.service.value_counts()","da663db4":"kdd_http.label.value_counts()\n## other than normal we have some anomolies. which we need to build a model to idenitify non-normal ones.","b6f58e20":"kdd_http.info()\n## we have few object data types. also since we want to go with tree models than the distance models. we are fine with only label encoding. Dont need any one hot encoding.\n##  tree models work fine with categorical variables , also no need of normalization.","d23c8a70":"## using select_dtypes we were able to get the list of non-numeric columns which might be cateogorical\/\nkdd_http.select_dtypes(exclude=np.number).columns","88851dd3":"## so there are only fixed number of columns, lets do label encoding.\nfor each_col in list(kdd_http.select_dtypes(exclude=np.number)):\n    print(each_col)\n    print('*'*20)\n    print(kdd_http[each_col].value_counts())","568e5362":"from sklearn.preprocessing  import LabelEncoder","fc598730":"for each_col in list(kdd_http.select_dtypes(exclude=np.number)):\n    label_encoder = LabelEncoder()\n    label_encoder.fit(kdd_http[each_col])\n    kdd_http[each_col]=label_encoder.transform(kdd_http[each_col])","0564b61a":"kdd_http.head(5)","0eb6e78a":"## We dont have any non-numeric columns\nkdd_http.select_dtypes(exclude=np.number).columns","4840d633":"### lets shuffle our Data frame before we do train,test and validation split.\n## we will use np.random.permutation and iloc combination for the same.\n## we will shuffle for 3 times.\n\nfor each_shuffle in range(3):\n    kdd_http=kdd_http.iloc[np.random.permutation(len(kdd_http))]","4cc1bc10":"kdd_http.head(5)","cfcb2301":"kdd_http.shape","a0601a81":"kdd_http.head(2)","1716a883":"train,test,validation=np.split(kdd_http.sample(frac=1),[int(len(kdd_http)*0.6),int(len(kdd_http)*0.8)])","099201da":"print(\"shape of Train:%s\"%str(train.shape))\ntrain.head(2)","80a26cc4":"print(\"shape of Test:%s\"%str(test.shape))\ntest.head(2)","326a7d98":"print(\"shape of validation:%s\"%str(validation.shape))\nvalidation.head(2)","0ca3abf7":"#### Doing a  X and Y split in each of the Train , test and validation\nX_train=train.loc[:,train.columns!='label']\ny_train=train.loc[:,train.columns=='label']\nX_test=test.loc[:,test.columns!='label']\ny_test=test.loc[:,test.columns=='label']\nX_validation=validation.loc[:,validation.columns!='label']\ny_validation=validation.loc[:,validation.columns=='label']","ef4f5ff5":"print(\"X and Y Shape for Train is  %s and %s\"%(str(X_train.shape),str(y_train.shape)))\nprint(\"X and Y Shape for test is  %s and %s\"%(str(X_test.shape),str(y_test.shape)))\nprint(\"X and Y Shape for validation is  %s and %s\"%(str(X_validation.shape),str(y_validation.shape)))\n","80beb1a5":"from sklearn.ensemble  import IsolationForest\nisolation_forest=IsolationForest(n_estimators=100,max_samples=256,contamination=0.1,random_state=123)","5ba7b2c5":"isolation_forest.fit(X_train)","76966b18":"## decission function gives the Average Anomoly score .lets calculate for the x_validation .\n\nanomaly_scores=isolation_forest.decision_function(X_validation)","7c8b2e88":"## lts plot the Anomoly score . so we can see anomolies.\nimport matplotlib.pyplot as plt\n%matplotlib inline ","03ea3456":"plt.figure(figsize=[20,20])\nplt.hist(anomaly_scores,bins=100)\nplt.xlabel(\"Average Path Lengths\")\nplt.ylabel(\"Number of Data Points\")\n\n## we can see Anomolies at Average Path length below  <  -0.2 . since there might be outliers too, we will take less than -0.19","90cf26b0":"from sklearn.metrics import roc_auc_score","5ecdcf78":"label_encoder.classes_","538962eb":"list(label_encoder.classes_).index('normal.')","48202bdc":"anomalies=anomaly_scores > -0.19\nmatches=y_validation==4\nauc=roc_auc_score(anomalies,matches)\nprint(auc)\nprint(\"AUC : {:.2%}\".format(auc))","bcc07e85":"## good score on validation. Lets test that on testdataset","eacea5d3":"anomaly_scores_test=isolation_forest.decision_function(X_test)","524aac44":"plt.figure(figsize=[20,20])\nplt.hist(anomaly_scores_test,bins=100)\nplt.xlabel(\"Average Path Lengths\")\nplt.ylabel(\"Number of Data Points\")","407e00b4":"test_anomalies=anomaly_scores_test > -0.19\nmatches_test=y_test==4\nauc_test=roc_auc_score(test_anomalies,matches_test)\nprint(auc_test)\nprint(\"AUC of Test : {:.2%}\".format(auc_test))","951232c4":"### Overall The Model is performing good on both validation and test data.","5e32074a":"## Model Building using isolation Forest","0122a43b":"###  Model evaluation  - using ROC curver - F1 score curve","e71a8020":"## We will do a Train, Test and validation with 60,20,20 using np.split"}}