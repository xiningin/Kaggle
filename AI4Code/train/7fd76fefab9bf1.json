{"cell_type":{"b76de72b":"code","590dae45":"code","6c7a7bc5":"code","69f29b25":"code","d4e1ee6b":"code","64690c5d":"code","c562c736":"code","15f9730d":"code","3b72618b":"code","71fa29f5":"code","a619e0bb":"code","969e0188":"code","2ed8117c":"code","d2486d41":"code","ebd5444d":"code","9f840cdc":"code","c0c653dd":"code","831dee0e":"code","b79a2339":"code","a6c68ecd":"code","85e0c6dd":"code","19b2d636":"code","483c3ece":"code","fde33d14":"code","165476ce":"code","fb57aef1":"code","da6a11f5":"markdown","b1e995f2":"markdown","a690028b":"markdown","7dec059b":"markdown","624aa710":"markdown","4b83b9c5":"markdown","acfaf4b0":"markdown","a3e546a3":"markdown","4f319653":"markdown","be53de57":"markdown","77a26a61":"markdown","d739a877":"markdown"},"source":{"b76de72b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","590dae45":"import sklearn\nimport keras\nimport warnings\nimport missingno as msno\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom collections import Counter\n\nplt.style.use('seaborn')\nsns.set(font_scale=1.5)\n\n# ignore warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\nos.listdir(\"..\/input\")","6c7a7bc5":"df_train = pd.read_csv(\n    \"..\/input\/tabular-playground-series-jan-2021\/train.csv\")\ndf_test = pd.read_csv(\n    \"..\/input\/tabular-playground-series-jan-2021\/test.csv\")\ndf_submit = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')","69f29b25":"df_train.head()\n# \uc798 \ubd88\ub7ec\uc84c\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.","d4e1ee6b":"df_test.head()","64690c5d":"df_submit.head()","c562c736":"df_train.shape, df_test.shape, df_submit.shape\n# train \ub370\uc774\ud130\ub294 300000\uac1c\uc758 \ub370\uc774\ud130\uc640 16\uac1c\uc758 feature\n# test \ub370\uc774\ud130\ub294 200000\uac1c\uc758 \ub370\uc774\ud130\uc640 15\uac1c\uc758 feature\uac00 \uc788\uc2b5\ub2c8\ub2e4.","15f9730d":"df_train.columns","3b72618b":"df_train.describe()","71fa29f5":"df_train.info()\n# \uacb0\uce21\uce58\ub294 \uc5c6\uc2b5\ub2c8\ub2e4.","a619e0bb":"def detect_outliers(df, n, features):\n    outlier_indices = []\n    for col in features:\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col], 75)\n        IQR = Q3 - Q1\n\n        outlier_step = 1.5 * IQR\n\n        outlier_list_col = df[(df[col] < Q1 - outlier_step)\n                              | (df[col] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col)\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)\n\n    return multiple_outliers","969e0188":"Outliers_to_drop = detect_outliers(df_train, 2, ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14', 'target'])","2ed8117c":"# train \ub370\uc774\ud130\uc758 \uc774\uc0c1\uce58\ub97c \ud0d0\uc0c9\ud569\ub2c8\ub2e4.\n# IQR(\ud29c\ud0a4\uc758 \ubc29\ubc95)\uc744 \uc774\uc6a9\ud55c \ud568\uc218\ub97c \uc9c0\uc815\ud558\uc5ec \uc774\uc0c1\uce58 \ud0d0\uc0c9\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n\ndf_train.loc[Outliers_to_drop].sum()\n# \ud559\uc2b5\ub370\uc774\ud130\uc5d0 \uc774\uc0c1\uce58\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.","d2486d41":"for col in df_train.columns:\n    print('{:15}'.format(col),\n          'Skewness: {:05.2f}'.format(df_train[col].skew()),\n          '   ',\n          'Kurtosis: {:06.2f}'.format(df_train[col].kurt())\n          )\n\n# Skewness(\uc65c\ub3c4), Kurtosis(\ucca8\ub3c4)\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.\n# \uc774\ub294 \ubd84\ud3ec\uac00 \uc5bc\ub9c8\ub098 \ube44\ub300\uce6d\uc744 \ub744\ub294\uac00 \uc54c\ub824\uc8fc\ub294 \ucc99\ub3c4\uc785\ub2c8\ub2e4. (\uc65c\ub3c4: a=0\uc774\uba74 \uc815\uaddc\ubd84\ud3ec, a<0 \uc774\uba74 \uc624\ub978\ucabd\uc73c\ub85c \uce58\uc6b0\uce68, a>0\uc774\uba74 \uc67c\ucabd\uc73c\ub85c \uce58\uc6b0\uce68)\n# \ub370\uc774\ud130\uc758 \uc65c\ub3c4\ub294 \ud06c\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.","ebd5444d":"corr_data = df_train[['target', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']]\n\ncolormap = plt.cm.PuBu\nsns.set(font_scale=1.0)\n\nk = 15\ncols = corr_data.corr().nlargest(k, 'target')['target'].index\nprint(cols)\ncm = np.corrcoef(df_train[cols].values.T)\nf, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(cm, vmax=.8, linewidths=0.1, square=True, annot=True, cmap=colormap,\n            linecolor=\"white\", xticklabels=cols.values, annot_kws={'size': 10}, yticklabels=cols.values)\n\n# Heat Map\uc740 seaborn \ub355\ubd84\uc5d0 \uc9c1\uad00\uc801\uc73c\ub85c \uc774\ud574\uac00 \uac00\ub2a5\ud558\uc5ec \ubcc0\uc218 \uac04 \uc0c1\uad00\uad00\uacc4\uc5d0 \ub300\ud558\uc5ec \uc27d\uac8c \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# \ud604\uc7ac target\uc740 \ub300\ubd80\ubd84\uc758 feature\uc5d0 \ub300\ud574 \uba85\ud655\ud55c \uc0c1\uad00\uad00\uacc4\ub97c \uac00\uc9c0\uace0 \uc788\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.","9f840cdc":"from sklearn.model_selection import train_test_split\n\nX_train = df_train.drop([\"id\", \"target\"], axis=1).values\ntarget_label = df_train[\"target\"].values\nX_test = df_test.drop(\"id\", axis=1).values\n\nX_train.shape, X_test.shape","c0c653dd":"X_tr, X_vld, y_tr, y_vld = train_test_split(\n    X_train, target_label, test_size=0.2, random_state=2000)\n\n# Test\ud558\uae30 \uc804 Validation \uacfc\uc815\uc744 \uaca8\ucc98\uc90d\ub2c8\ub2e4.\n# train\ub370\uc774\ud130\uc758 20%\ub97c validation\uc73c\ub85c \uc8fc\uace0 80%\uc744 train\uc73c\ub85c \ub0a8\uaca8\uc8fc\uc5b4 \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n\ny_tr.shape, y_vld.shape","831dee0e":"from sklearn.model_selection import cross_val_score\nimport xgboost\nfrom sklearn import metrics\n\nregressor = xgboost.XGBRegressor()\nregressor.fit(X_tr, y_tr)\n\n# XGBoost \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4\uc90d\ub2c8\ub2e4.","b79a2339":"y_hat = regressor.predict(X_tr)\n\nplt.scatter(y_tr, y_hat, alpha=0.2)\nplt.xlabel('Targets (y_tr)', size=18)\nplt.ylabel('Predictions (y_hat)', size=18)\nplt.show()\n\n# \uc608\uce21 \ub41c y \uac12 (y_hat)\uc5d0 \ub300\ud55c Scatter Plot\uc744 \uadf8\ub824\ubd05\ub2c8\ub2e4.","a6c68ecd":"regressor.score(X_tr, y_tr)","85e0c6dd":"\ny_hat_test = regressor.predict(X_vld)\n\n\nplt.scatter(y_vld, y_hat_test, alpha=0.2)\nplt.xlabel('Targets (y_vld)', size=18)\nplt.ylabel('Predictions (y_hat_test)', size=18)\nplt.show()\n\n# validation\uc73c\ub85c \uc608\uce21\ud574\ubd05\ub2c8\ub2e4.","19b2d636":"regressor.score(X_vld, y_vld)\n\naccuracies = cross_val_score(estimator=regressor, X=X_tr, y=y_tr, cv=10)\n\n# k-fold validation\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.","483c3ece":"print(accuracies.mean())\nprint(accuracies.std())\n\n# \uc815\ud655\ub3c4\ub97c \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.","fde33d14":"df_submit.head()","165476ce":"prediction = regressor.predict(X_test)\ndf_submit['target'] = prediction","fb57aef1":"df_submit.to_csv('my_first_submission.csv', index=False)","da6a11f5":"1. xgboost","b1e995f2":"1. Correlation Heat Map","a690028b":"3. Detect outliers","7dec059b":"1. Data check","624aa710":"# 4. Modeling","4b83b9c5":"\uc9c0\uae08\uae4c\uc9c0 \uac04\ub2e8\ud55c ML\uacfc DL \ubb38\uc81c\ub9cc\uc744 \ud480\ub2e4\uac00 \ucc98\uc74c\uc73c\ub85c \ub178\ud2b8\ubd81\uc744 \uc62c\ub9ac\uac8c\ub418\uc5c8\uc2b5\ub2c8\ub2e4.<br>\n\uc9c0\uae08\uaecf \ub2e4\ub978 \ub178\ud2b8\ubd81\ub4f1\uc744 \ud1b5\ud574 \uc815\ub9ac\ud55c \uae30\ubc95\uc744 \ud1a0\ub300\ub85c \uc774\ubc88 \ub178\ud2b8\ubd81\uc774 \uc791\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4.","acfaf4b0":"# 2. Data check","a3e546a3":"# 3. EDA","4f319653":"# 5. Submission","be53de57":"4. Skewness","77a26a61":"# 1. Import modules","d739a877":"2. Detect missing value"}}