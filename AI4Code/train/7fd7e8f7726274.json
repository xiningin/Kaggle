{"cell_type":{"a930280d":"code","4675f5ea":"code","9c35f3e3":"code","20d30e4d":"code","79228e98":"code","e14db9df":"code","1a3726b9":"code","306d4d0c":"code","d4ec1486":"code","24d188bb":"code","535d94fb":"code","3177cbd5":"code","24bbefb6":"code","d4697e82":"code","2204f62a":"code","b881ce2e":"code","dbd5a4d8":"code","a3646e67":"code","82ead9d3":"code","c2607d80":"code","cc36f0b5":"code","5b0dedd1":"code","3a6a21f0":"code","1556f63b":"code","3c9c4229":"code","3e471fba":"code","ad81e090":"code","3d8e24b4":"code","11100bcf":"code","f589b28e":"code","7809168e":"code","0b96a423":"code","a839c3c0":"code","e1f932b4":"code","54702b45":"code","1024bd68":"code","5b3064b1":"code","70bbbd7a":"code","ae655283":"code","f7f12721":"code","2b52cc1a":"code","44926b7e":"code","6928b05a":"code","f8d7451c":"code","e65c92f3":"code","81467f43":"code","7e45d224":"code","caa299b4":"code","81858e45":"code","29a96442":"code","1b2dad18":"code","5b51bd4b":"code","79784c71":"code","89ee2d95":"code","42996878":"code","c4759130":"code","306cf90f":"code","961709f4":"code","5ae5ab38":"code","d81d246c":"code","644aabc1":"code","706e09dc":"code","5a3e1b3c":"code","235238b9":"code","b76b37a4":"code","5b4f1434":"code","8e102966":"code","3d4ece93":"markdown","216d4416":"markdown","baded83e":"markdown","8c39cfe1":"markdown","48853481":"markdown","2a37e19a":"markdown","7e30ab50":"markdown","46a32e8b":"markdown","a7ee1081":"markdown","7291623b":"markdown","369524e7":"markdown","cf057948":"markdown","c7c870a5":"markdown","6597c804":"markdown"},"source":{"a930280d":"!wget https:\/\/he-s3.s3.amazonaws.com\/media\/hackathon\/hackerearth-machine-learning-challenge-pet-adoption\/pet-adoption-9-5838c75b\/a01c26dcd27711ea.zip","4675f5ea":"!unzip a01c26dcd27711ea.zip","9c35f3e3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n!pip install rfpimp\n!pip install catboost\nfrom sklearn.metrics import mean_absolute_error,accuracy_score\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV,GroupKFold,train_test_split,StratifiedShuffleSplit\nfrom rfpimp import *\nfrom tqdm import tqdm\nfrom catboost import *\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder","20d30e4d":"train = pd.read_csv('Dataset\/train.csv')\ntest = pd.read_csv('Dataset\/test.csv')","79228e98":"train.head(5)","e14db9df":"test.head(5)","1a3726b9":"train.isnull().sum(),test.isnull().sum(),train.shape,test.shape,train.dtypes","306d4d0c":"df=pd.concat([train,test])\n#df=train.append(test,ignore_index=True)","d4ec1486":"#df['pet_id']=df.pet_id.str.extract('(\\d+)').astype(int)","24d188bb":"k=['issue_date','listing_date']\nfor i in k:\n  df[i] = pd.to_datetime(df[i])\ndf['diff']=df['listing_date']-df['issue_date']\ndf['diff']=abs(df['diff'].astype(int))\/1000000000000","535d94fb":"k=['issue_date','listing_date']\nfor i in k:\n  df[i+'_'+'year'] = df[i].dt.year\n  df[i+'_'+'day'] = df[i].dt.day\n  df[i+'_'+'weekofyear'] = df[i].dt.weekofyear\n  df[i+'_'+'month'] = df[i].dt.month\n  df[i+'_'+'dayofweek'] =df[i].dt.dayofweek\n  df[i+'_'+'weekend'] = (df[i].dt.weekday >=5).astype(int)\n  df[i+'_'+'hour'] = df[i].dt.hour\n  df[i+'_'+'minute'] = df[i].dt.minute\nfor i in k:\n  del df[i]","3177cbd5":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf[\"col_cond\"] = df[\"condition\"].fillna('-9999').astype(str)+\"_\"+df[\"color_type\"]\ndf[\"col_cond\"] = le.fit_transform(df[\"col_cond\"])","24bbefb6":"df['condition']=df['condition'].fillna(3.0)\ndf['condition']=df['condition']+1\n#df['condition']=df['condition'].fillna(method='bfill')","d4697e82":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['color_type'] = le.fit_transform(df['color_type'])\nle.classes_","2204f62a":"#extraa\nimport math\ndf['length(m)']=df['length(m)']*100\ndf['area']=(df['height(cm)']*df['length(m)'])+(df['X1']+df['X2'])\n#df['val']=df['height(cm)']*df['length(m)']*2*math.pi\ndf['Ag_x']=df['color_type']*df['condition']\ndf['Ag_y']=df['condition']*df['X1']\ndf['Ag_z']=df['condition']*df['X2']\nm=(df['issue_date_year'].min())-1\ndf['Ag_a']=(df['issue_date_year']-m)*df['color_type']\ndf['Ag_b']=(df['issue_date_year']-m)*df['condition']\ndf[\"X12col\"] = df[\"X1\"]+df[\"X2\"] + df[\"col_cond\"]\n#df['power']=df['diff']\/(df['Ag_a']*(df['color_type']+df['condition']))#new\n#df['xor']=df['diff']\/(df['X1']*df['condition'])#new","b881ce2e":"temp = df.groupby(['color_type']).agg({'X1':['count','mean','sum','median'], #median\n                                            'X2':['count','mean','sum'],#median\n                                       #'X12col':['count','mean','sum','median'],#new\n                                       #'diff':['count','mean','sum','median'], #new\n                                   #'length(m)':['count','sum','min','max','mean'],\n                                   #'height(cm)':['count','sum','min','max','mean'],\n                                   #'issue_date_weekofyear':['min','max','count'],\n                                   #'issue_date_day':['min','max','count'],\n                                   #'listing_date_weekofyear':['min','max','count'],\n                                   'condition':['count','mean',],#median\n                                       'color_type':['count','mean','sum']})\ntemp.columns = ['_'.join(x) for x in temp.columns]\ndf = pd.merge(df,temp,on=['color_type'],how='left')","dbd5a4d8":"temp = df.groupby(['condition']).agg({\n                                       'color_type':['count','sum','mean','max'],\n                                      #'X1':['count','mean','sum','median'],\n                                      #'X2':['count','mean','sum','median']\n                                      })\ntemp.columns = ['_condd_'.join(x) for x in temp.columns]\ndf = pd.merge(df,temp,on=['condition'],how='left')","a3646e67":"df = pd.get_dummies(df, columns=['condition','color_type','X1','X2'])\ndel df['issue_date_hour']\ndel df['issue_date_minute']","82ead9d3":"train = df[df['breed_category'].isnull()==False]\ntest = df[df['breed_category'].isnull()==True]\ndel test['breed_category']\ndel test['pet_category']\n","c2607d80":"train_df=train.copy()\ntest_df=test.copy()","cc36f0b5":"from math import sqrt \nfrom sklearn.metrics import f1_score","5b0dedd1":"train_df=train.copy()\ntest_df=test.copy()","3a6a21f0":"x=train_df['pet_category']\ndel train_df['pet_category']\nindex=test_df['pet_id']\ndel train_df['pet_id']\ndel test_df['pet_id']","1556f63b":"X = train_df.drop(labels=['breed_category'], axis=1)\ny = train_df['breed_category'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.10, random_state=101)","3c9c4229":"X_train.shape, y_train.shape, X_cv.shape, y_cv.shape","3e471fba":"categorical_features_indices = np.where(X_train.dtypes == 'category')[0]\ncategorical_features_indices","ad81e090":"from catboost import CatBoostClassifier\ncat = CatBoostClassifier(loss_function='MultiClass', \n                         eval_metric='TotalF1', \n                         classes_count=3,\n                         depth=10,\n                         random_seed=121, \n                         iterations=3500, \n                         learning_rate=0.1,\n                         leaf_estimation_iterations=1,\n                         l2_leaf_reg=1,\n                         bootstrap_type='Bayesian', \n                         bagging_temperature=1, \n                         random_strength=1,\n                         od_type='Iter', \n                         border_count=100,\n                         od_wait=500)\ncat.fit(X_train, y_train, verbose=100,\n        use_best_model=True,\n        cat_features=categorical_features_indices,\n        eval_set=[(X_train, y_train),(X_cv, y_cv)],\n        plot=False)\npredictions = cat.predict(X_cv)\nprint('accuracy:', f1_score(y_cv, predictions, average='weighted'))","3d8e24b4":"print('accuracy:', f1_score(y_cv, predictions, average='weighted'))","11100bcf":"import seaborn as sns\nfeature_imp = pd.DataFrame(sorted(zip(cat.feature_importances_, X.columns), reverse=True)[:50], \n                           columns=['Value','Feature'])\nplt.figure(figsize=(15,15))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('Catboost Features')\nplt.tight_layout()\nplt.show()","f589b28e":"Xtest = test_df","7809168e":"from sklearn.model_selection import KFold\n\nerrcat = []\ny_pred_totcat = []\n\nfold = KFold(n_splits=10, shuffle=True, random_state=101)\n\nfor train_index, test_index in fold.split(X):\n    X_train, X_test = X.loc[train_index], X.loc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    cat = CatBoostClassifier(loss_function='MultiClass', \n                         eval_metric='TotalF1', \n                         classes_count=3,\n                         depth=6,\n                         random_seed=121, \n                         iterations=3500, \n                         learning_rate=0.1,\n                         leaf_estimation_iterations=1,\n                         l2_leaf_reg=1,\n                         bootstrap_type='Bayesian', \n                         bagging_temperature=0.8, \n                         random_strength=1,\n                         od_type='Iter', \n                         border_count=100,\n                         od_wait=500)\n    cat.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=200, cat_features=categorical_features_indices)\n\n    y_pred_cat = cat.predict(X_test)\n    print(\"Accuracy: \", f1_score(y_test,y_pred_cat, average='weighted'))\n\n    errcat.append(f1_score(y_test,y_pred_cat, average='weighted'))\n    p = cat.predict(Xtest)\n    y_pred_totcat.append(p)","0b96a423":"np.mean(errcat,0)","a839c3c0":"cat_final = np.mean(y_pred_totcat,0).round().astype(int)\ncat_final","e1f932b4":"xxx = pd.DataFrame(data=cat_final, columns=['breed_category'])","54702b45":"train_df=train.copy()\ntest_df=test.copy()","1024bd68":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['pet_category'] = le.fit_transform(train_df['pet_category'])\nle.classes_","5b3064b1":"x=train_df['breed_category']\ndel train_df['breed_category']\nindex=test_df['pet_id']\ndel train_df['pet_id']\ndel test_df['pet_id']","70bbbd7a":"X = train_df.drop(labels=['pet_category'], axis=1)\ny = train_df['pet_category'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.10, random_state=101)","ae655283":"X_train.shape, y_train.shape, X_cv.shape, y_cv.shape","f7f12721":"categorical_features_indices = np.where(X_train.dtypes == 'category')[0]\ncategorical_features_indices","2b52cc1a":"from catboost import CatBoostClassifier\ncat = CatBoostClassifier(loss_function='MultiClass', \n                         eval_metric='TotalF1', \n                         classes_count=4,\n                         depth=6,\n                         random_seed=42, \n                         iterations=3500, \n                         learning_rate=0.1,\n                         leaf_estimation_iterations=1,\n                         l2_leaf_reg=1,\n                         bootstrap_type='Bayesian', \n                         bagging_temperature=0.8, \n                         random_strength=1,\n                         #od_pval=0.00001,\n                         od_type='Iter', \n                         border_count=100,\n                         od_wait=500)\ncat.fit(X_train, y_train, verbose=100,\n        use_best_model=True,\n        cat_features=categorical_features_indices,\n        eval_set=[(X_train, y_train),(X_cv, y_cv)],\n        plot=False)","44926b7e":"predictions = cat.predict(X_cv)\nprint('accuracy:', f1_score(y_cv, predictions, average='weighted'))","6928b05a":"import seaborn as sns\nfeature_imp = pd.DataFrame(sorted(zip(cat.feature_importances_, X.columns), reverse=True)[:50], \n                           columns=['Value','Feature'])\nplt.figure(figsize=(15,15))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('Catboost Features')\nplt.tight_layout()\nplt.show()","f8d7451c":"Xtest = test_df","e65c92f3":"from sklearn.model_selection import KFold\n\nerrcat = []\ny_pred_totcat = []\n\nfold = KFold(n_splits=10, shuffle=True, random_state=42)\n\nfor train_index, test_index in fold.split(X):\n    X_train, X_test = X.loc[train_index], X.loc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    cat = CatBoostClassifier(loss_function='MultiClass', \n                         eval_metric='TotalF1', \n                         classes_count=4,\n                         depth=6,\n                         random_seed=42, \n                         iterations=3500, \n                         learning_rate=0.07,\n                         leaf_estimation_iterations=1,\n                         l2_leaf_reg=1,\n                         bootstrap_type='Bayesian', \n                         bagging_temperature=0.8, \n                         random_strength=1,\n                         #od_pval=0.1,\n                         od_type='Iter', \n                         border_count=150,\n                         od_wait=100)\n    cat.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=100, cat_features=categorical_features_indices)\n\n    y_pred_cat = cat.predict(X_test)\n    print(\"Accuracy: \", f1_score(y_test,y_pred_cat, average='weighted'))\n\n    errcat.append(f1_score(y_test,y_pred_cat, average='weighted'))\n    p = cat.predict(Xtest)\n    y_pred_totcat.append(p)","81467f43":"np.mean(errcat,0)","7e45d224":"cat_final_x = np.mean(y_pred_totcat,0).round().astype(int)\ncat_final_x","caa299b4":"yyy = pd.DataFrame(data=cat_final_x, columns=['pet_category'])","81858e45":"id=test['pet_id']","29a96442":"submission = pd.DataFrame({\n        \"pet_id\":id,\n        \"breed_category\": xxx['breed_category'],\n        \"pet_category\": yyy['pet_category']\n    })\nsubmission.to_csv('.\/submission.csv', index=False)\nprint(submission)","1b2dad18":"train_df=train.copy()\ntest_df=test.copy()","5b51bd4b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['pet_category'] = le.fit_transform(train_df['pet_category'])\nle.classes_","79784c71":"x=train_df['breed_category']\ndel train_df['breed_category']\nindex=test_df['pet_id']\ndel train_df['pet_id']\ndel test_df['pet_id']","89ee2d95":"df_train = train_df\ndf_test = test_df","42996878":"X_train = train_df.drop(['pet_category'],axis=1)\ny_train = train_df['pet_category']","c4759130":"x=[]\nfor i in test_df.columns:\n  x.append(i)\nx=np.array(x)\nfeats=x","306cf90f":"splits = 15\nfolds =StratifiedKFold(n_splits=splits, random_state=42,shuffle=True)\noof_preds = np.zeros((len(df_test), 4))\nfeature_importance_df = pd.DataFrame()\nfeature_importance_df['Feature'] = X_train.columns\nfinal_preds = []\nrandom_state = [22,44,66,77,88,99,101]\ncounter = 0\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values,y_train)):\n        print(\"iter_ {}\".format(fold_))\n        X_trn,y_trn = X_train[feats].iloc[trn_idx],y_train.iloc[trn_idx]\n        X_val,y_val = X_train[feats].iloc[val_idx],y_train.iloc[val_idx]\n        clf = lgb.LGBMClassifier(boosting='gbdt',learning_rate=0.1, n_estimators=1000, random_state=101, subsample=0.9,max_depth=-1,num_leaves=31)#\n         #,\n         #min_data_in_leaf=11,\n         #bagging_fraction=0.90,\n         #bagging_freq=2,\n         #bagging_seed=3,\n         #feature_fraction=0.90,\n         #feature_fraction_seed=2,\n         #early_stopping_round=200,\n         #max_bin=1000)#(n_estimators=1000,max_depth=4,random_state=42)#dart\n        clf.fit(X_trn, y_trn,eval_set=[(X_trn, y_trn), (X_val, y_val)],verbose=0,\n                eval_metric='multi_error',early_stopping_rounds=100)\n        \n        imp = importances(clf,X_val,y_val)\n        imp.rename(columns={'Importance':f'Importance_{fold_}'},inplace=True)\n        feature_importance_df = pd.merge(feature_importance_df,imp,on='Feature')\n        final_preds.append(accuracy_score(y_pred=clf.predict(X_val),y_true=y_val))\n        \n        oof_preds += clf.predict_proba(df_test[feats])\noof_preds = oof_preds\/splits\nprint(sum(final_preds)\/splits)","961709f4":"preds_x = [np.argmax(x) for x in oof_preds]","5ae5ab38":"train_df=train.copy()\ntest_df=test.copy()","d81d246c":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['breed_category'] = le.fit_transform(train_df['breed_category'])\nle.classes_","644aabc1":"x=train_df['pet_category']\ndel train_df['pet_category']\nindex=test_df['pet_id']\ndel train_df['pet_id']\ndel test_df['pet_id']","706e09dc":"df_train = train\ndf_test = test","5a3e1b3c":"X_train = train.drop(['breed_category'],axis=1)\ny_train = train['breed_category']","235238b9":"splits = 20\nfolds =StratifiedKFold(n_splits=splits, random_state=42,shuffle=True)\noof_preds = np.zeros((len(df_test), 3))\nfeature_importance_df = pd.DataFrame()\nfeature_importance_df['Feature'] = X_train.columns\nfinal_preds = []\nrandom_state = [22,44,66,77,88,99,101,201]\ncounter = 0\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values,y_train)):\n        print(\"iter_ {}\".format(fold_))\n        X_trn,y_trn = X_train[feats].iloc[trn_idx],y_train.iloc[trn_idx]\n        X_val,y_val = X_train[feats].iloc[val_idx],y_train.iloc[val_idx]\n        clf = lgb.LGBMClassifier(boosting='gbdt',learning_rate=0.1, n_estimators=1000, random_state=101, subsample=0.9)\n        clf.fit(X_trn, y_trn,eval_set=[(X_trn, y_trn), (X_val, y_val)],verbose=0,\n                eval_metric='multi_error',early_stopping_rounds=100)\n        \n        imp = importances(clf,X_val,y_val)\n        imp.rename(columns={'Importance':f'Importance_{fold_}'},inplace=True)\n        feature_importance_df = pd.merge(feature_importance_df,imp,on='Feature')\n        final_preds.append(accuracy_score(y_pred=clf.predict(X_val),y_true=y_val))\n\n        oof_preds += clf.predict_proba(df_test[feats])\noof_preds = oof_preds\/splits\nprint(sum(final_preds)\/splits)","b76b37a4":"preds_y = [np.argmax(x) for x in oof_preds]","5b4f1434":"id=test['pet_id']","8e102966":"submission = pd.DataFrame({\n        \"pet_id\":id,\n        \"breed_category\": preds_y,\n        \"pet_category\":preds_x\n    })\nsubmission.to_csv('.\/submission.csv', index=False)\nprint(submission)","3d4ece93":"# ensem","216d4416":"y_pred1 = np.array(df1['breed_category'])\ny_pred2 = np.array(df2['breed_category'])\ny_pred3 = np.array(df3['breed_category'])\ny_pred4 = np.array(df2['breed_category'])\ny_pred5 = np.array(df3['breed_category'])","baded83e":"df1.to_csv('ensemble.csv', index=False)","8c39cfe1":"# f4","48853481":"df1['breed_category']=y_pred\ndf1['pet_category']=z_pred1","2a37e19a":"y_pred = y_pred1*0.37 + y_pred2*0.33 + y_pred3*0.15 +y_pred4*0.10 + y_pred5*0.05","7e30ab50":"y_pred","46a32e8b":"# F2","a7ee1081":"x=[]\nfor i in df1['pet_category']:\n  if i==3:\n    x.append(4)\n  else:\n    x.append(i)\ndf1['pet_category']=x","7291623b":"df1['breed_category']=df1['breed_category'].round().astype(int)\ndf1['pet_category']=df1['pet_category'].round().astype(int)","369524e7":"df1 = pd.read_csv('ensemble_91.33846.csv')\ndf2 = pd.read_csv('ensemble_91.19216.csv')\ndf3 = pd.read_csv('ensemble_91.16458.csv')\ndf4 = pd.read_csv('ensemble_91.15620.csv')\ndf5 = pd.read_csv('ensemble_91.08938.csv')","cf057948":"z_pred","c7c870a5":"z_pred =z_pred1*0.60 + z_pred2*0.20 + z_pred3*0.10 +z_pred4*0.05 + z_pred5*0.05","6597c804":"z_pred1 = np.array(df1['pet_category'])\nz_pred2 = np.array(df2['pet_category'])\nz_pred3 = np.array(df3['pet_category'])\nz_pred4 = np.array(df2['pet_category'])\nz_pred5 = np.array(df3['pet_category'])"}}