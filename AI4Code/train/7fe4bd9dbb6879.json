{"cell_type":{"c790bbd1":"code","85769842":"code","b9e44c64":"code","f1f59a67":"code","e2f0c169":"code","00e127a0":"code","0eb10ca1":"code","b1cd7760":"code","92079369":"code","a1180524":"code","0c2f39d1":"code","9a5422c1":"code","6c75e269":"code","609b8cfa":"code","4375a862":"code","11400503":"code","928b0574":"code","61b5215e":"code","afb14b94":"code","f3238ffd":"code","4c24f831":"code","4ae7c4d5":"code","af7cc900":"code","2c6c133e":"code","9c3d8156":"code","31907108":"code","e15dbaff":"code","75a0ba67":"code","5ada7a9e":"code","4367c61f":"code","cb53fa82":"code","dc02b794":"code","a7f86705":"code","e5fdb125":"code","e1a75ca9":"code","062345fd":"code","2696772a":"code","4082216e":"code","3776e7c4":"code","4f1d4189":"code","acf5d14b":"code","e21a73bf":"code","abfe9d22":"code","33b6a62f":"code","e1777660":"code","03b78d95":"code","15106956":"code","dca373f7":"code","e22a7ee4":"code","6b5b617f":"code","f685f1b3":"code","d0774075":"code","3525d818":"code","fb214928":"code","2491774a":"code","62e8b647":"code","3f50017d":"code","b93cf7f6":"code","cb739e8c":"code","7d25662a":"code","542ab571":"code","33bc9c78":"code","befee6b4":"code","d724cc0d":"code","11aed0d2":"code","847bd78c":"code","8351c650":"code","e97f45a1":"code","7cfe43f9":"code","222a0ce5":"markdown","93c0ee7d":"markdown","4b9840e3":"markdown","f071e7b3":"markdown","e519927b":"markdown","b23fae8c":"markdown","30cde7ac":"markdown","ecd11b76":"markdown","030bf5cf":"markdown","ac00e7ea":"markdown","b7bc66d5":"markdown","067dc9b3":"markdown","d5bc20d9":"markdown","2eea4cb0":"markdown","8f70bf11":"markdown","762d1812":"markdown","af8361b1":"markdown","f6bca93e":"markdown","dc4de31c":"markdown","6c7f7658":"markdown","8ec8f444":"markdown","c68b0ee0":"markdown","6909125c":"markdown","22707512":"markdown","9d984ff0":"markdown","4798203a":"markdown","a35ac5f1":"markdown"},"source":{"c790bbd1":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt, seaborn as sns\n%matplotlib inline","85769842":"# Reading from CSV\nbm0= pd.read_csv(\"\/kaggle\/input\/bank-marketing.csv\")\nprint(\"Dataset with rows {} and columns {}\".format(bm0.shape[0],bm0.shape[1]))\nbm0.head()","b9e44c64":"bm0.info()","f1f59a67":"bm0.describe()","e2f0c169":"bm0.pdays.describe()","00e127a0":"bm1=bm0.copy()","0eb10ca1":"bm1.drop(bm1[bm1['pdays'] < 0].index, inplace = True) ","b1cd7760":"bm1.pdays.describe()","92079369":"bm1.groupby(['education'])['balance'].median().plot.barh()","a1180524":"bm1.pdays.plot.box()\nplt.show()","0c2f39d1":"bm1.response.value_counts(normalize=True)","9a5422c1":"bm1.replace({'response': {\"yes\": 1,'no':0}},inplace=True)","6c75e269":"bm1.response.value_counts()","609b8cfa":"# here we are seperating object and numerical data types \nobj_col = []\nnum_col = []\nfor col in bm1.columns:\n    if bm1[col].dtype=='O':\n        obj_col.append(col)\n    else:\n        num_col.append(col)","4375a862":"print(\"Object data type features \",obj_col)\nprint(\"Numerical data type features \",num_col)","11400503":"from numpy import median\nfor col in obj_col[1:]:\n    plt.figure(figsize=(8,6))\n    sns.violinplot(bm1[col],bm1[\"response\"])\n    plt.title(\"Response vs \"+col,fontsize=15)\n    plt.xlabel(col,fontsize=10)\n    plt.ylabel(\"Response\",fontsize=10)\n    plt.show()\n#sns.despine()\n# violin plots give best of both worlds \n# it gives boxplot and distribution of data like whether the data is skewed or not.\n# if normally distributed then it's the best you can get.\n# you can also use barplots in this case.","928b0574":"plt.figure(figsize=(8,6))\nsns.heatmap(bm1.corr(),annot=True,cmap='RdBu_r')\nplt.title(\"Correlation Of Each Numerical Features\")\nplt.show()","61b5215e":"for col in num_col[:-1]:\n    plt.figure(figsize=(10,8))\n    sns.jointplot(x = bm1[col],y = bm1[\"response\"],kind='reg')\n    plt.xlabel(col,fontsize = 15)\n    plt.ylabel(\"Response\",fontsize = 15)\n    plt.grid()\n    plt.show()","afb14b94":"from sklearn.preprocessing import LabelEncoder","f3238ffd":"bm2 = bm1[obj_col].apply(LabelEncoder().fit_transform)","4c24f831":"bm2.head()","4ae7c4d5":"bm3 = bm2.join(bm1[num_col])","af7cc900":"bm3.head()","2c6c133e":"bm3.corr()","9c3d8156":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nnp.random.seed(42)","31907108":"import warnings\nwarnings.filterwarnings(\"ignore\")","e15dbaff":"X = bm3.drop(\"response\", axis=1)\nX.head()","75a0ba67":"y= bm3[['response']]\ny.head()","5ada7a9e":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42)","4367c61f":"lr = LogisticRegression()","cb53fa82":"lr.fit(X_train,y_train)","dc02b794":"cv_score= cross_val_score(lr,X_train,y_train, cv=5)\nnp.mean(cv_score)","a7f86705":"y_pred = lr.predict(X_test)","e5fdb125":"print(classification_report(y_test, y_pred))","e1a75ca9":"confusion_matrix(y_pred,y_test)","062345fd":"f1_score(y_pred,y_test)","2696772a":"from sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nrfe = RFE(lr, 5)\nrfe.fit(X_train,y_train)","4082216e":"rfe.support_","3776e7c4":"X_train.columns[rfe.support_]","4f1d4189":"cols = X_train.columns[rfe.support_]","acf5d14b":"lr.fit(X_train[cols],y_train)","e21a73bf":"y_pred2 = lr.predict(X_test[cols])","abfe9d22":"f1_score(y_pred2,y_test)","33b6a62f":"confusion_matrix(y_pred2,y_test)","e1777660":"import statsmodels.api as sm","03b78d95":"X_train.head()","15106956":"X_train_sm = sm.add_constant(X_train[cols])\nX_train_sm.head()","dca373f7":"lr1 = sm.OLS(y_train, X_train_sm).fit()","e22a7ee4":"lr1.summary()","6b5b617f":"from statsmodels.stats.outliers_influence import variance_inflation_factor","f685f1b3":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","d0774075":"from sklearn.ensemble import RandomForestClassifier","3525d818":"rfc = RandomForestClassifier(max_depth=5, random_state=42,max_leaf_nodes=50)","fb214928":"rfc.fit(X_train,y_train)","2491774a":"cv1_score= cross_val_score(rfc,X_train,y_train, cv=5)\nnp.mean(cv1_score)","62e8b647":"y_pred1 = rfc.predict(X_test)","3f50017d":"print(classification_report(y_test, y_pred1))","b93cf7f6":"f1_score(y_test,y_pred1)","cb739e8c":"confusion_matrix(y_test,y_pred1)","7d25662a":"from sklearn.metrics import roc_auc_score","542ab571":"roc_auc_score(y_test,y_pred1)","33bc9c78":"from sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nrfe1 = RFE(rfc, 5)\nrfe1.fit(X_train,y_train)","befee6b4":"rfe1.support_","d724cc0d":"X_train.columns[rfe1.support_]","11aed0d2":"cols = X_train.columns[rfe1.support_]","847bd78c":"rfc.fit(X_train[cols],y_train)","8351c650":"y_pred3 = rfc.predict(X_test[cols])","e97f45a1":"f1_score(y_pred3,y_test)","7cfe43f9":"confusion_matrix(y_pred3,y_test)","222a0ce5":"#### Plot a horizontal bar graph with the median values of balance for each education level value. Which group has the highest median?","93c0ee7d":"#### Univariate Analysis","4b9840e3":"#### Describe the pdays column, make note of the mean, median and minimum values. Anything fishy in the values?","f071e7b3":"#### Bi- variate Analysis","e519927b":"#### Describe the pdays column again, this time limiting yourself to the relevant values of pdays. How different are the mean and the median values?","b23fae8c":"#### Label Encoding of Categorical Variables.","30cde7ac":"#### Make suitable plots for associations with numerical features and categorical features\u2019","ecd11b76":"#### Model Building","030bf5cf":"#### Random Forest Classifier","ac00e7ea":"#### Converting the response variable to a convenient form","b7bc66d5":"#### VIF","067dc9b3":"If we purely look at numerical summary ie mean and standard deviation, we can't see that lot of values is -1. We can see that 75% values of pdays are -1. So -1 has special meaning over here ie previous campaign was made to them or not. So in our case if we want to make decision on customer who did have campaign previously, then we must exclude all the cases of -1. So, by doing this we can get to customer who had previously campaign. ","d5bc20d9":"Housing, loan, default, poutcome are imp feature from logistic regression model perspective","2eea4cb0":"Thus, we can conclude from graph that customer with tertiary level of education has highest median value for balance.","8f70bf11":"This time mean and median has changed significantly because we have removed the case where pdays value is -1 ie we have removed the customer that were not contacted previously for campaign.","762d1812":"Add intercept manually for statsmodel to work","af8361b1":"#### Logistic Regression Model","f6bca93e":"#### use statsmodel","dc4de31c":"#### RFE","6c7f7658":"we can see that duration variable is highly correlated with response variable 'Response Flag' . Whereas pdays variable is not highly correlated with response variable 'Response Flag'.","8ec8f444":"#### RFE","c68b0ee0":"#### Make a box plot for pdays. Do you see any outliers?","6909125c":"Hence dataset does not contain any missing value.","22707512":"Yes, from the above box plot we can see that there are outliers present in pdays.","9d984ff0":"Housing, month, pdays, poutcome, duration are imp feature from RANDOM FOREST perspective.","4798203a":" pdays  uses -1 as indicator and not value. Hence treat these value as missing\n - Ignore these values in our average\/median\/state calculations.\n - Keep it NaN  \n Wherever pdays is -1, replace with NaN  ","a35ac5f1":"#### The final goal is to make a predictive model to predict if the customer will respond positively to the campaign or not. The target variable is \u201cresponse\u201d. So performing bi-variate analysis to identify the features that are directly associated with the target variable.\n"}}