{"cell_type":{"50080c83":"code","6bbbb7ae":"code","a06621d6":"code","4a47a9ed":"code","58dca388":"code","3a9faf67":"code","d503a16c":"code","590546cd":"code","5b4f1bf0":"code","046c2e9d":"code","4ca4b965":"code","37b4c8cb":"code","ec7e95ec":"code","2de25480":"code","b77773b5":"code","f29c6a8d":"code","b379a449":"code","5cd9356b":"code","d88beccc":"code","f5db9124":"code","e07e05e3":"code","10ffb8bd":"code","ea846a65":"code","7e2036f3":"code","ec6bf604":"code","5d92d28c":"code","855071e3":"code","c22c1085":"code","f503ce71":"code","3288c969":"code","1b38a11e":"code","2bcf8ba8":"code","48bcad03":"markdown","c043b86c":"markdown","112017f5":"markdown","a1ac339c":"markdown","f20ea204":"markdown","dbd2c7bd":"markdown","9f7eb021":"markdown","9eb383ab":"markdown","76c179f4":"markdown","0fc7fbd5":"markdown"},"source":{"50080c83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6bbbb7ae":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"..\/input\/dogs-vs-cats\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n    print(\"File name: \", filenames)","a06621d6":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"..\/input\/dogs-vs-cats-for-pytorch\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n    print(\"File name: \", filenames)","4a47a9ed":"import torch\nimport torch.nn as nn\nfrom torchvision import datasets ,models,transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim import lr_scheduler\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nimport numpy as np","58dca388":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","3a9faf67":"PATH=Path('..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data')\nPATH1=Path('..\/input\/dogs-vs-cats\/test1')","d503a16c":"TRAIN =Path(PATH\/'train')\nVALID = Path(PATH\/'test')\nTEST=Path(PATH1)\nprint(TRAIN)\nprint(VALID)\nprint(TEST)","590546cd":"ls ..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data\/train\/dog -1 | wc -l","5b4f1bf0":"ls ..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data\/train\/cat -1 | wc -l","046c2e9d":"ls ..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data\/test\/dog -1 | wc -l","4ca4b965":"ls ..\/input\/dogs-vs-cats-for-pytorch\/cat_dog_data\/Cat_Dog_data\/test\/cat -1 | wc -l","37b4c8cb":"ls ..\/input\/dogs-vs-cats\/test1\/test1 -1 | wc -l","ec7e95ec":"# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 32\n\n# convert data to a normalized torch.FloatTensor\ntrain_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\nvalid_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n# choose the training and test datasets\n\ntest_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n# choose the training and test datasets\ntrain_data = datasets.ImageFolder(TRAIN, transform=train_transforms)\nvalid_data=datasets.ImageFolder(VALID,transform=valid_transforms)\ntest_data = datasets.ImageFolder(PATH1, transform=test_transforms)\n\n# obtain training indices that will be used for validation\n#num_train = len(train_data)\n#indices = list(range(num_train))\n#np.random.shuffle(indices)\n#split = int(np.floor(valid_size * num_train))\n#print(\"Split Index\",split)\n#train_idx, valid_idx = indices[split:], indices[:split]\n# define samplers for obtaining training and validation batches\n","2de25480":"print(train_data.class_to_idx)\nprint(valid_data.class_to_idx)","b77773b5":"# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,  num_workers=num_workers)","f29c6a8d":"images,labels=next(iter(train_loader))","b379a449":"images.shape,labels.shape","5cd9356b":"import matplotlib.pyplot as plt\n%matplotlib inline\nclasses = ['cat','dog']\nmean , std = torch.tensor([0.485, 0.456, 0.406]),torch.tensor([0.229, 0.224, 0.225])\n\n\ndef denormalize(image):\n  image = transforms.Normalize(-mean\/std,1\/std)(image) #denormalize\n  image = image.permute(1,2,0) #Changing from 3x224x224 to 224x224x3\n  image = torch.clamp(image,0,1)\n  return image\n\n# helper function to un-normalize and display an image\ndef imshow(img):\n    img = denormalize(img) \n    plt.imshow(img)","d88beccc":"# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 8))\n# display 20 images\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(\"{} \".format( classes[labels[idx]]))","f5db9124":"vgg_19=models.vgg19_bn(pretrained=True)\nvgg_19","e07e05e3":"# Freeze parameters so we don't backprop through them\nfor param in vgg_19.parameters():\n    param.requires_grad = False\n\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(25088, 1028)),\n                          ('relu1', nn.ReLU()),\n                          ('dropout1',nn.Dropout(0.5)),\n                          ('fc2', nn.Linear(1028, 512)),\n                          ('relu2', nn.ReLU()), \n                          ('dropout2',nn.Dropout(0.5)),\n                          ('fc3', nn.Linear(512, 2)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nvgg_19.classifier = classifier","10ffb8bd":"vgg_19","ea846a65":"criterion = nn.NLLLoss()\noptimizer=torch.optim.Adam(vgg_19.parameters(),lr=0.01)","7e2036f3":"# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,  num_workers=num_workers)","ec6bf604":"if train_on_gpu:\n    vgg_19.cuda()\n# number of epochs to train the model\nn_epochs = 3\n\nvalid_loss_min = np.Inf # track change in validation loss\n\n#train_losses,valid_losses=[],[]\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    vgg_19.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    vgg_19.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    #train_losses.append(train_loss\/len(train_loader.dataset))\n    #valid_losses.append(valid_loss.item()\/len(valid_loader.dataset)\n    train_loss = train_loss\/len(train_loader.dataset)\n    valid_loss = valid_loss\/len(valid_loader.dataset)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(vgg_19.state_dict(), 'model_vgg19.pth')\n        valid_loss_min = valid_loss","5d92d28c":"valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\nbatch_size=4\n# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nvgg_19.eval()\n# iterate over valid data\nfor data, target in valid_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = vgg_19(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss\/len(valid_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","855071e3":"batch_size=32\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\nvgg_19.cpu()\n# obtain one batch of test images\ndataiter = iter(valid_loader)\nimages, labels = dataiter.next()\n\n# move model inputs to cuda, if GPU available\n#if train_on_gpu:\n    #images = images.cuda()\n\n# get sample outputs\noutput = vgg_19(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","c22c1085":"print(\"The state dict keys: \\n\\n\", vgg_19.state_dict().keys())","f503ce71":"torch.save(vgg_19.state_dict(), 'checkpoint_97.pth')","3288c969":"# Criteria NLLLoss which is recommended with Softmax final layer\ncriterion = nn.NLLLoss()\n# Observe that all parameters are being optimized\noptimizer = torch.optim.Adam(vgg_19.classifier.parameters(), lr=0.001)\n# Decay LR by a factor of 0.1 every 3 epochs\nscheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n# Number of epochs","1b38a11e":"if train_on_gpu:\n    vgg_19.cuda()\n# number of epochs to train the model\nn_epochs = 2\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    vgg_19.train()\n    \n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        scheduler.step()\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    vgg_19.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.dataset)\n    valid_loss = valid_loss\/len(valid_loader.dataset)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(vgg_19.state_dict(), 'model_vgg19_2.pth')\n        valid_loss_min = valid_loss","2bcf8ba8":"batch_size=4\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\n# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nvgg_19.eval()\n# iterate over test data\nfor data, target in valid_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = vgg_19(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss\/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            classes[i], 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","48bcad03":"No of Cat images for validation","c043b86c":"rgb_img = np.squeeze(images[3])\nchannels = ['red channel', 'green channel', 'blue channel']\n\nfig = plt.figure(figsize = (36, 36)) \nfor idx in np.arange(rgb_img.shape[0]):\n    ax = fig.add_subplot(1, 3, idx + 1)\n    img = rgb_img[idx]\n    ax.imshow(img, cmap='gray')\n    ax.set_title(channels[idx])\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            val = round(img[x][y],2) if img[x][y] !=0 else 0\n            ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center', size=8,\n                    color='white' if img[x][y]<thresh else 'black')","112017f5":"vgg_19.load_state_dict(state_dict)","a1ac339c":"References\n<br>\n[Notebook](https:\/\/www.kaggle.com\/pocahontas1010\/cats-dogs-classifier-with-pytorch\/notebook)\n<br>\n[Sorting data into subdirectories](https:\/\/www.kaggle.com\/c\/dog-breed-identification\/discussion\/48908)\n<br>\n[Model evaluation](https:\/\/www.kaggle.com\/carloalbertobarbano\/vgg16-transfer-learning-pytorch)\n<br>\n[Pytorch Models](https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html[Pytorch Models])\n<br>\n[Pytorch Augmetation](https:\/\/colab.research.google.com\/drive\/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll)","f20ea204":"Implementation","dbd2c7bd":"No of Dog images for validation","9f7eb021":"![](http:\/\/)Load the model VGG -19","9eb383ab":"No of Cat images for training","76c179f4":"No of dog images for training","0fc7fbd5":"No of images to predict"}}