{"cell_type":{"f7f1e770":"code","2ad9f15d":"code","29e16e36":"code","e19c3032":"code","dd8c650b":"code","caa6066f":"code","c3bc8d0a":"code","787dd032":"code","16a3afb1":"code","a30c16e8":"code","b7624b22":"code","7a2fbee1":"code","fffc9912":"code","69514857":"code","d4c66bab":"code","bd67bf4e":"code","be4f5845":"code","cf316b99":"markdown","68b69417":"markdown"},"source":{"f7f1e770":"# \u9996\u5148\u5bfc\u5165\u5305\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\n# This is for the progress bar.\nfrom tqdm import tqdm\nimport seaborn as sns\n","2ad9f15d":"# \u770b\u770blabel\u6587\u4ef6\u957f\u5565\u6837\nlabels_dataframe = pd.read_csv('..\/input\/classify-leaves\/train.csv')\nlabels_dataframe.head(5)","29e16e36":"labels_dataframe.describe()","e19c3032":"#function to show bar length\n\ndef barw(ax): \n    \n    for p in ax.patches:\n        val = p.get_width() #height of the bar\n        x = p.get_x()+ p.get_width() # x- position \n        y = p.get_y() + p.get_height()\/2 #y-position\n        ax.annotate(round(val,2),(x,y))\n        \n#finding top leaves\n\nplt.figure(figsize = (15,30))\nax0 =sns.countplot(y=labels_dataframe['label'],order=labels_dataframe['label'].value_counts().index)\nbarw(ax0)\nplt.show()","dd8c650b":"# \u628alabel\u6587\u4ef6\u6392\u4e2a\u5e8f\nleaves_labels = sorted(list(set(labels_dataframe['label'])))\nn_classes = len(leaves_labels)\nprint(n_classes)\nleaves_labels[:10]","caa6066f":"# \u628alabel\u8f6c\u6210\u5bf9\u5e94\u7684\u6570\u5b57\nclass_to_num = dict(zip(leaves_labels, range(n_classes)))\nclass_to_num","c3bc8d0a":"# \u518d\u8f6c\u6362\u56de\u6765\uff0c\u65b9\u4fbf\u6700\u540e\u9884\u6d4b\u7684\u65f6\u5019\u4f7f\u7528\nnum_to_class = {v : k for k, v in class_to_num.items()}","787dd032":"# \u7ee7\u627fpytorch\u7684dataset\uff0c\u521b\u5efa\u81ea\u5df1\u7684\nclass LeavesData(Dataset):\n    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=256, resize_width=256):\n        \"\"\"\n        Args:\n            csv_path (string): csv \u6587\u4ef6\u8def\u5f84\n            img_path (string): \u56fe\u50cf\u6587\u4ef6\u6240\u5728\u8def\u5f84\n            mode (string): \u8bad\u7ec3\u6a21\u5f0f\u8fd8\u662f\u6d4b\u8bd5\u6a21\u5f0f\n            valid_ratio (float): \u9a8c\u8bc1\u96c6\u6bd4\u4f8b\n        \"\"\"\n        \n        # \u9700\u8981\u8c03\u6574\u540e\u7684\u7167\u7247\u5c3a\u5bf8\uff0c\u6211\u8fd9\u91cc\u6bcf\u5f20\u56fe\u7247\u7684\u5927\u5c0f\u5c3a\u5bf8\u4e0d\u4e00\u81f4#\n        self.resize_height = resize_height\n        self.resize_width = resize_width\n\n        self.file_path = file_path\n        self.mode = mode\n\n        # \u8bfb\u53d6 csv \u6587\u4ef6\n        # \u5229\u7528pandas\u8bfb\u53d6csv\u6587\u4ef6\n        self.data_info = pd.read_csv(csv_path, header=None)  #header=None\u662f\u53bb\u6389\u8868\u5934\u90e8\u5206\n        # \u8ba1\u7b97 length\n        self.data_len = len(self.data_info.index) - 1\n        self.train_len = int(self.data_len * (1 - valid_ratio))\n        \n        if mode == 'train':\n            # \u7b2c\u4e00\u5217\u5305\u542b\u56fe\u50cf\u6587\u4ef6\u7684\u540d\u79f0\n            self.train_image = np.asarray(self.data_info.iloc[1:self.train_len, 0])  #self.data_info.iloc[1:,0]\u8868\u793a\u8bfb\u53d6\u7b2c\u4e00\u5217\uff0c\u4ece\u7b2c\u4e8c\u884c\u5f00\u59cb\u5230train_len\n            # \u7b2c\u4e8c\u5217\u662f\u56fe\u50cf\u7684 label\n            self.train_label = np.asarray(self.data_info.iloc[1:self.train_len, 1])\n            self.image_arr = self.train_image \n            self.label_arr = self.train_label\n        elif mode == 'valid':\n            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:, 0])  \n            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:, 1])\n            self.image_arr = self.valid_image\n            self.label_arr = self.valid_label\n        elif mode == 'test':\n            self.test_image = np.asarray(self.data_info.iloc[1:, 0])\n            self.image_arr = self.test_image\n            \n        self.real_len = len(self.image_arr)\n\n        print('Finished reading the {} set of Leaves Dataset ({} samples found)'\n              .format(mode, self.real_len))\n\n    def __getitem__(self, index):\n        # \u4ece image_arr\u4e2d\u5f97\u5230\u7d22\u5f15\u5bf9\u5e94\u7684\u6587\u4ef6\u540d\n        single_image_name = self.image_arr[index]\n\n        # \u8bfb\u53d6\u56fe\u50cf\u6587\u4ef6\n        img_as_img = Image.open(self.file_path + single_image_name)\n\n        #\u5982\u679c\u9700\u8981\u5c06RGB\u4e09\u901a\u9053\u7684\u56fe\u7247\u8f6c\u6362\u6210\u7070\u5ea6\u56fe\u7247\u53ef\u53c2\u8003\u4e0b\u9762\u4e24\u884c\n#         if img_as_img.mode != 'L':\n#             img_as_img = img_as_img.convert('L')\n\n        #\u8bbe\u7f6e\u597d\u9700\u8981\u8f6c\u6362\u7684\u53d8\u91cf\uff0c\u8fd8\u53ef\u4ee5\u5305\u62ec\u4e00\u7cfb\u5217\u7684nomarlize\u7b49\u7b49\u64cd\u4f5c\n        if self.mode == 'train':\n            transform = transforms.Compose([\n                transforms.Resize((224, 224)),\n                transforms.RandomHorizontalFlip(p=0.5),   #\u968f\u673a\u6c34\u5e73\u7ffb\u8f6c \u9009\u62e9\u4e00\u4e2a\u6982\u7387\n                transforms.ToTensor()\n            ])\n        else:\n            # valid\u548ctest\u4e0d\u505a\u6570\u636e\u589e\u5f3a\n            transform = transforms.Compose([\n                transforms.Resize((224, 224)),\n                transforms.ToTensor()\n            ])\n        \n        img_as_img = transform(img_as_img)\n        \n        if self.mode == 'test':\n            return img_as_img\n        else:\n            # \u5f97\u5230\u56fe\u50cf\u7684 string label\n            label = self.label_arr[index]\n            # number label\n            number_label = class_to_num[label]\n\n            return img_as_img, number_label  #\u8fd4\u56de\u6bcf\u4e00\u4e2aindex\u5bf9\u5e94\u7684\u56fe\u7247\u6570\u636e\u548c\u5bf9\u5e94\u7684label\n\n    def __len__(self):\n        return self.real_len\n","16a3afb1":"train_path = '..\/input\/classify-leaves\/train.csv'\ntest_path = '..\/input\/classify-leaves\/test.csv'\n# csv\u6587\u4ef6\u4e2d\u5df2\u7ecfimages\u7684\u8def\u5f84\u4e86\uff0c\u56e0\u6b64\u8fd9\u91cc\u53ea\u5230\u4e0a\u4e00\u7ea7\u76ee\u5f55\nimg_path = '..\/input\/classify-leaves\/'\n\ntrain_dataset = LeavesData(train_path, img_path, mode='train')\nval_dataset = LeavesData(train_path, img_path, mode='valid')\ntest_dataset = LeavesData(test_path, img_path, mode='test')\nprint(train_dataset)\nprint(val_dataset)\nprint(test_dataset)","a30c16e8":"# \u5b9a\u4e49data loader\ntrain_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=8, \n        shuffle=False,\n        num_workers=5\n    )\n\nval_loader = torch.utils.data.DataLoader(\n        dataset=val_dataset,\n        batch_size=8, \n        shuffle=False,\n        num_workers=5\n    )\ntest_loader = torch.utils.data.DataLoader(\n        dataset=test_dataset,\n        batch_size=8, \n        shuffle=False,\n        num_workers=5\n    )","b7624b22":"# \u7ed9\u5927\u5bb6\u5c55\u793a\u4e00\u4e0b\u6570\u636e\u957f\u5565\u6837\ndef im_convert(tensor):\n    \"\"\" \u5c55\u793a\u6570\u636e\"\"\"\n    \n    image = tensor.to(\"cpu\").clone().detach()\n    image = image.numpy().squeeze()\n    image = image.transpose(1,2,0)\n    image = image.clip(0, 1)\n\n    return image\n\nfig=plt.figure(figsize=(20, 12))\ncolumns = 4\nrows = 2\n\ndataiter = iter(val_loader)\ninputs, classes = dataiter.next()\n\nfor idx in range (columns*rows):\n    ax = fig.add_subplot(rows, columns, idx+1, xticks=[], yticks=[])\n    ax.set_title(num_to_class[int(classes[idx])])\n    plt.imshow(im_convert(inputs[idx]))\nplt.show()","7a2fbee1":"# \u770b\u4e00\u4e0b\u662f\u5728cpu\u8fd8\u662fGPU\u4e0a\ndef get_device():\n    return 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndevice = get_device()\nprint(device)","fffc9912":"# \u662f\u5426\u8981\u51bb\u4f4f\u6a21\u578b\u7684\u524d\u9762\u4e00\u4e9b\u5c42\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        model = model\n        for param in model.parameters():\n            param.requires_grad = False\n# resnet34\u6a21\u578b\ndef res_model(num_classes, feature_extract = False, use_pretrained=True):\n\n    model_ft = models.resnet34(pretrained=use_pretrained)\n    set_parameter_requires_grad(model_ft, feature_extract)\n    num_ftrs = model_ft.fc.in_features\n    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n\n    return model_ft","69514857":"# \u8d85\u53c2\u6570\nlearning_rate = 3e-4\nweight_decay = 1e-3\nnum_epoch = 50\nmodel_path = '.\/pre_res_model.ckpt'","d4c66bab":"\n# Initialize a model, and put it on the device specified.\nmodel = res_model(176)\nmodel = model.to(device)\nmodel.device = device\n# For the classification task, we use cross-entropy as the measurement of performance.\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n\n# The number of training epochs.\nn_epochs = num_epoch\n\nbest_acc = 0.0\nfor epoch in range(n_epochs):\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train() \n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n    # Iterate the training set by batches.\n    for batch in tqdm(train_loader):\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n        imgs = imgs.to(device)\n        labels = labels.to(device)\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits = model(imgs)\n        # Calculate the cross-entropy loss.\n        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n        loss = criterion(logits, labels)\n        \n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n        # Compute the gradients for parameters.\n        loss.backward()\n        # Update the parameters with computed gradients.\n        optimizer.step()\n        \n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n        \n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = sum(train_loss) \/ len(train_loss)\n    train_acc = sum(train_accs) \/ len(train_accs)\n\n    # Print the information.\n    print(f\"[ Train | {epoch + 1:03d}\/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n    \n    \n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n    # These are used to record information in validation.\n    valid_loss = []\n    valid_accs = []\n    \n    # Iterate the validation set by batches.\n    for batch in tqdm(val_loader):\n        imgs, labels = batch\n        # We don't need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits = model(imgs.to(device))\n            \n        # We can still compute the loss (but not the gradient).\n        loss = criterion(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n        \n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss = sum(valid_loss) \/ len(valid_loss)\n    valid_acc = sum(valid_accs) \/ len(valid_accs)\n\n    # Print the information.\n    print(f\"[ Valid | {epoch + 1:03d}\/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n    \n    # if the model improves, save a checkpoint at this epoch\n    if valid_acc > best_acc:\n        best_acc = valid_acc\n        torch.save(model.state_dict(), model_path)\n        print('saving model with acc {:.3f}'.format(best_acc))","bd67bf4e":"saveFileName = '.\/submission.csv'","be4f5845":"## predict\nmodel = res_model(176)\n\n# create model and load weights from checkpoint\nmodel = model.to(device)\nmodel.load_state_dict(torch.load(model_path))\n\n# Make sure the model is in eval mode.\n# Some modules like Dropout or BatchNorm affect if the model is in training mode.\nmodel.eval()\n\n# Initialize a list to store the predictions.\npredictions = []\n# Iterate the testing set by batches.\nfor batch in tqdm(test_loader):\n    \n    imgs = batch\n    with torch.no_grad():\n        logits = model(imgs.to(device))\n    \n    # Take the class with greatest logit as prediction and record it.\n    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n\npreds = []\nfor i in predictions:\n    preds.append(num_to_class[i])\n\ntest_data = pd.read_csv(test_path)\ntest_data['label'] = pd.Series(preds)\nsubmission = pd.concat([test_data['image'], test_data['label']], axis=1)\nsubmission.to_csv(saveFileName, index=False)\nprint(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!\")","cf316b99":"\u4ee5\u524d\u90fd\u662f\u5b66\u7740\u522b\u4eba\u7684baseline\u7528\uff0c\u8fd9\u6b21\u7ec8\u4e8e\u8f6e\u5230\u6211\u53ef\u4ee5\u4e3a\u5927\u5bb6\u8d21\u732e\u4e00\u4e0b\u4e86\u54c8\u54c8\u54c8","68b69417":"\u8981\u662f\u5927\u5bb6\u89c9\u5f97\u6709\u7528\u7684\u8bdd \u591a\u591a\u7ed9vote\u54c8\u54c8\u54c8"}}