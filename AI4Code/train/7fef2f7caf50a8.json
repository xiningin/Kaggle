{"cell_type":{"f8dcbbd7":"code","b2bddb69":"code","199ac680":"code","32131a9c":"code","2e513843":"code","a5a26c5f":"code","c44480f2":"code","2482bc3e":"code","18064b51":"code","bff78ed6":"code","e412ff08":"code","988e2cc5":"code","26032782":"code","1e5a6037":"code","3bfab4a6":"code","ac5bbf72":"code","10ce4c95":"code","92420fae":"code","ca79757a":"code","67ed1af7":"code","bb54ae51":"code","5822d9b9":"code","bf3a46d3":"code","ae24e6a4":"code","b43357e9":"code","66b9887e":"code","e432ce3e":"code","1fbb5544":"code","98bd2a6f":"code","066e326e":"code","a4961cdd":"markdown","5657eca4":"markdown","0345f7ce":"markdown","51d9496a":"markdown","8702fd66":"markdown","374e1270":"markdown","75b0f5fb":"markdown"},"source":{"f8dcbbd7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input in read-only \"..\/input\/\" \n# Current directory: \/kaggle\/working. Save \n# Temp files: \/kaggle\/temp\/","b2bddb69":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","199ac680":"train.head(10) # Select first 10 rows\ntrain.tail(10) # Select last 10 rows","32131a9c":"train[\"Survived\"]     #Select columns with their names","2e513843":"train[[\"Survived\", \"Age\"]] #Make sure you put a list inside the index brackets","a5a26c5f":"train.loc[train[\"Fare\"] > 200] #Put a conditional expression in the index notation","c44480f2":"#Combine different conditions\ntrain.loc[train[\"Fare\"] > 200][[\"Fare\", \"Survived\"]].tail(3)","2482bc3e":"train[\"Survived\"] + 1","18064b51":"m = train.shape[0]           #Get tuple (num_rows, num_cols)\nrandom = np.random.randn(m)  #Get 1D array with num_rows random numbers\ntrain[\"NewCol\"] = random     #Create new column\ntrain.head()","bff78ed6":"train = train.drop(\"NewCol\", axis=1)    #0 axis is the rows, 1 axis is the columns\ntrain.head()","e412ff08":"train.info()","988e2cc5":"train[\"Female\"] = train[\"Sex\"] == \"female\" # Convert Booleans to integers\ntrain[\"Female\"] = train[\"Female\"].astype(int)\ntrain = train.drop(\"Sex\", axis=1)  # Make sure you set the output from train.drop() to a variable\ntrain.head()","26032782":"#Approach 1 to turning 'categorical' data into numbers: map each class to a number.\n\ntrain[\"Embarked\"] = train[\"Embarked\"].astype('category') #Tell Pandas we have categorical data\ncategories = train[\"Embarked\"].cat.categories\ncodes = train[\"Embarked\"].cat.codes\nprint(categories)\nprint(codes)","1e5a6037":"cat_to_code = {}   #Just creating 'records' of which number maps with which category\ncode_to_cat = {}\nfor i in range(len(categories)): \n    cat = categories[i]\n    cat_to_code[cat] = i\n    code_to_cat[i] = cat\nprint(cat_to_code)\n\ntrain[\"Embarked\"] = codes\ntrain.head()","3bfab4a6":"#Approach 2 to turning 'categorical' data into numbers: 'one-hot' encoding\none_hot = pd.get_dummies(train[\"Embarked\"])\nprint(one_hot)","ac5bbf72":"one_hot = one_hot.drop(-1, axis=1)\none_hot = one_hot.rename(columns=code_to_cat) #0 --> C for example\none_hot.head()","10ce4c95":"train = pd.concat([train, one_hot], axis=1)\ntrain = train.drop(\"Embarked\", axis=1)\ntrain.head()","92420fae":"# Dealing with undefined data\ntrain.info()","ca79757a":"# Approach 1: Ignore the null data\nnot_null = train.loc[train[\"Age\"].notnull()]\nnot_null.info()","67ed1af7":"#Approach 2: Look at context\nhas_cabin = train.loc[train[\"Cabin\"].notnull()]   #.notnull() selects data that have a value\nhas_cabin_and_survived = has_cabin[\"Survived\"] == 1\nhas_cabin_and_survived = has_cabin_and_survived.astype(int)\npercent_survived = has_cabin_and_survived.sum() \/ len(has_cabin) * 100  #len gets num rows\nprint(percent_survived)","bb54ae51":"#Approach 3: Assume the most likely option\nOG_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nOG_data.info()","5822d9b9":"most_common = OG_data[\"Embarked\"].mode()[0]      #Slice notation with a number selects the indices\nprint(most_common)\nOG_data.loc[OG_data[\"Embarked\"].isnull()] = most_common\nOG_data.info()","bf3a46d3":"#Option 1: Save as csv - good for sharing data open-source. Understandable.\ntrain.to_csv(\".\/train.csv\")","ae24e6a4":"#Option 2: Save as numpy array - good for algorithms. Make sure you have numbers only.\nnum = train.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1).to_numpy()\nprint(num.shape)","b43357e9":"np.save(\".\/train.npy\", num)         #First filepath, then object","66b9887e":"#Option 3: Save as deep learning framework object - same as above. But less flexible.\nimport torch\nnum = num.astype('float32')\ntensor = torch.from_numpy(num)\ntorch.save(tensor, \".\/train.pt\")    #First object, then filepath","e432ce3e":"#Option 4: Save as compressed file - ex: saving millions of trained parameters\nimport joblib\njoblib.dump(num, \".\/train0.joblib\", compress=0) #No compression (default)\njoblib.dump(num, \".\/train9.joblib\", compress=9) #Max compression","1fbb5544":"reloaded = joblib.load(\".\/train9.joblib\")\nreloaded.shape","98bd2a6f":"corr = train.corr()       # Get correlations between all the columns","066e326e":"import seaborn\nseaborn.heatmap(corr)     # Graph correlations between all the columns","a4961cdd":"## Q: How do you know which data to use?\nAnswer: visualization. This is an entire lesson of it's own! But feel free to look into libraries like `seaborn`, `matplotlib`, `Plotly`, etc. \n\nHere's a basic approach though: generate a 'heatmap' (a graph of which columns correlate with which others. The goal is to find columns that correlate most with the outcome we want to predict (Survival). The closer a correlation is to 1, the better we can use one variable to predict the other. ","5657eca4":"### Subcategory: preparing data to be used in AI algorithms","0345f7ce":"## Save processed data","51d9496a":"This notebook is accompanied by a [video](https:\/\/youtu.be\/AF6jmPZh6_s) of me explaining the code. Follow along if you'd like!\n\n---","8702fd66":"Things this notebook will teach\n- Getting datasets from Kaggle\n- Turning CSV data into Pandas dataframes\n- Selecting only certain data in the pandas dataframe (both in terms of features and examples)\n- Converting categorical data in the pandas dataframe\n- Converting true\/false into 0\/1\n- Dealing with null\/undefined data\n- Finding correlations\/making heatmaps to figure out which features to select\n- Turning Pandas dataframes into tensors\n- Acknowledge that you'd then have to do more preprocessing with computer vision and natural language processing.","374e1270":"## Modifying Data","75b0f5fb":"## Actually loading and viewing the data"}}