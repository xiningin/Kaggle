{"cell_type":{"f60e405d":"code","0f4a522b":"code","62fe41c2":"code","0d67e83e":"code","535da87c":"code","93f7c9b6":"code","ca1d4f13":"code","7ec5470d":"code","494ff5a0":"code","1dbf8bc1":"code","8df832c0":"code","027733da":"code","2734f7f5":"code","cbdd91cd":"code","1c5573e4":"code","94455772":"code","0f3983b8":"code","82ef21e6":"code","d3b7605d":"code","1ed05019":"code","4a476153":"code","d109876f":"code","7a62ac7f":"code","f948d995":"code","abe01f61":"code","988893a8":"code","d982fe89":"code","99519d46":"code","71dfe3d2":"code","4eb540e3":"code","9bbc6692":"code","50b83b7c":"code","58f0d6cd":"code","c512be47":"code","a62c0a43":"code","7f059532":"code","ed05ee2d":"code","a3152c44":"code","3d9cf332":"code","75a0accf":"code","d397bf1f":"code","05cf6f3f":"code","6736f096":"code","1032e880":"code","98d6994c":"code","0a104035":"code","87aecfd8":"code","9689b37e":"code","69f0c7ef":"code","b57edf4c":"code","ebba894c":"code","7604b517":"code","fea58b5b":"code","1c686141":"code","5898f1c3":"code","b5946292":"code","3db97323":"code","e4851774":"code","8638373b":"code","a7314a90":"code","cc4ebbe3":"code","0b0228ae":"code","0390c740":"code","35be6ae8":"code","e80326e2":"code","333fefed":"code","d450376f":"code","abce954b":"code","9c06efe4":"code","97c2eb55":"code","0f0ed2bf":"code","6cb8e5cf":"code","9a0a99b3":"code","168b8ce7":"markdown","e2e19cc2":"markdown","ba8a08f1":"markdown","29b15620":"markdown","0ce649c3":"markdown","c4e7dcc2":"markdown","a58f2d26":"markdown","7cf29e57":"markdown","3fc8b413":"markdown","afbd95d3":"markdown","0e4e30a9":"markdown","5f2c76c2":"markdown","b54cc030":"markdown","ffcc600a":"markdown","b201094f":"markdown","c0a4c46b":"markdown","51a371d5":"markdown"},"source":{"f60e405d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0f4a522b":"# Fastai Library\nfrom fastai import *\nfrom fastai.tabular import *\n\n# visualization library\nfrom wordcloud import WordCloud\nimport seaborn as sb\nsb.set(rc={'figure.figsize':(11.7,8.27)})","62fe41c2":"df_train = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')","0d67e83e":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', True)","535da87c":"df_train.head(1).T","93f7c9b6":"df_train.isnull().sum()","ca1d4f13":"df_test.isnull().sum()","7ec5470d":"df_train.info()","494ff5a0":"df_train.columns = df_train.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_test.columns = df_test.columns.str.strip().str.lower().str.replace(' ', '_')","1dbf8bc1":"df_train.revenue.min()","8df832c0":"df_train.budget.min()","027733da":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.revenue, ax=ax1)\nsb.distplot(np.log1p(df_train.revenue), ax=ax2)\nax1.set_title('Distribution of revenue')\nax2.set_title('Distribution of log of revenue')","2734f7f5":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.budget, ax=ax1)\nsb.distplot(np.log1p(df_train.budget), ax=ax2)\nax1.set_title('Distribution of Budget')\nax2.set_title('Distribution of log of Budget')","cbdd91cd":"df_train['log_revenue'] = np.log1p(df_train.revenue)\ndf_train['log_budget'] = np.log1p(df_train.budget)\n\ndf_test['log_budget'] = np.log1p(df_test.budget)","1c5573e4":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.popularity, ax=ax1)\nsb.distplot(np.log1p(df_train.popularity), ax=ax2)\nax1.set_title('Distribution of popularity')\nax2.set_title('Distribution of log of popularity')","94455772":"df_train.fillna({'runtime': df_train['runtime'].mean()}, inplace=True)\ndf_test.fillna({'runtime': df_test['runtime'].mean()}, inplace=True)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.runtime, ax=ax1)\nsb.distplot(np.log1p(df_train.runtime), ax=ax2)\nax1.set_title('Distribution of runtime')\nax2.set_title('Distribution of log of runtime')","0f3983b8":"df_train['log_popularity'] = np.log1p(df_train.popularity)\ndf_train['log_runtime'] = np.log1p(df_train.runtime)\n\ndf_test['log_popularity'] = np.log1p(df_test.popularity)\ndf_test['log_runtime'] = np.log1p(df_test.runtime)","82ef21e6":"nan_percentage = pd.DataFrame({'ColName':df_train.columns, 'NaN%':df_train.isnull().mean()})\nplt.figure(figsize=(16, 8))\nchart = sb.barplot(x=nan_percentage['ColName'], y=nan_percentage['NaN%'])\nplt.xticks(rotation=45, horizontalalignment='right', fontweight='light', fontsize='x-large')","d3b7605d":"import ast\nfor df in (df_train, df_test):\n    df.belongs_to_collection = df.belongs_to_collection.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.genres = df.genres.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.production_companies = df.production_companies.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.production_countries = df.production_countries.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.spoken_languages = df.spoken_languages.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.keywords = df.keywords.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.cast = df.cast.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.crew = df.crew.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))","1ed05019":"# df_train.belongs_to_collection.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","4a476153":"df_train.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","d109876f":"sb.barplot(x=df_train.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","7a62ac7f":"# df_train.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","f948d995":"sb.barplot(x=df_train.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","abe01f61":"# df_train.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","988893a8":"sb.barplot(x=df_train.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","d982fe89":"# df_train.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","99519d46":"sb.barplot(x=df_train.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","71dfe3d2":"# df_train.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","4eb540e3":"sb.barplot(x=df_train.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","9bbc6692":"# df_train.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","50b83b7c":"sb.barplot(x=df_train.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","58f0d6cd":"# df_train.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","c512be47":"sb.barplot(x=df_train.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","a62c0a43":"def extract_features(df, col):\n    #     Separate features into  individual features\n    features = set()\n    for f in df[col]:\n        if np.any(pd.notna(f)):\n            for x in range(len(f)):\n                features.add(str(f[x]['name']))\n            \n    return features\n    \ndef create_features(df, col, features):\n    for f in features:\n        df[col+'_'+f]=0\n        \n    for index, f in enumerate(df[col]):\n        if np.any(pd.notna(f)):\n            for x in range(len(f)):\n                if f[x]['name'] in features:\n                    df.loc[index, col+'_'+f[x]['name']] = 1","7f059532":"f_train = extract_features(df_train, 'genres')\nf_test = extract_features(df_test, 'genres')\nlen(f_train), len(f_test)","ed05ee2d":"f_train - f_test","a3152c44":"for df in (df_train, df_test):\n    # Create features from belongs to collection\n    # df['collection_name'] = df.belongs_to_collection.apply(lambda x: x[0]['name'] if np.any(pd.notna(x)) else x)\n    df['is_series'] = df.belongs_to_collection.apply(lambda x: 1 if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual genres\n    create_features(df, 'genres', f_train)\n    df['total_genres'] = df.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    \n    # Create features for individual production_companies\n    # create_features(df, 'production_companies')\n    df['total_production_companies'] = df.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual production_countries\n    # create_features(df, 'production_countries')\n    df['total_production_countries'] = df.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual spoken_languages\n    # create_features(df, 'spoken_languages')\n    df['total_spoken_languages'] = df.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual keywords\n    # create_features(df, 'keywords')\n    df['total_keywords'] = df.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual cast\n    # create_features(df, 'cast')\n    df['total_cast'] = df.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual crew\n    # create_features(df, 'crew')\n    df['total_crew'] = df.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create feature from date\n    add_datepart(df, 'release_date')","3d9cf332":"fig, ax = plt.subplots(4, 5, figsize=(16, 16))\nsb.barplot(df_train.genres_Action, df_train.revenue, ax=ax[0,0])\nsb.barplot(df_train.genres_Adventure, df_train.revenue, ax=ax[0,1])\nsb.barplot(df_train.genres_Animation, df_train.revenue, ax=ax[0,2])\nsb.barplot(df_train.genres_Comedy, df_train.revenue, ax=ax[0,3])\nsb.barplot(df_train.genres_Crime, df_train.revenue, ax=ax[0,4])\nsb.barplot(df_train.genres_Documentary, df_train.revenue, ax=ax[1,0])\nsb.barplot(df_train.genres_Drama, df_train.revenue, ax=ax[1,1])\nsb.barplot(df_train.genres_Family, df_train.revenue, ax=ax[1,2])\nsb.barplot(df_train.genres_Fantasy, df_train.revenue, ax=ax[1,3])\nsb.barplot(df_train.genres_Foreign, df_train.revenue, ax=ax[1,4])\nsb.barplot(df_train.genres_History, df_train.revenue, ax=ax[2,0])\nsb.barplot(df_train.genres_Horror, df_train.revenue, ax=ax[2,1])\nsb.barplot(df_train.genres_Music, df_train.revenue, ax=ax[2,2])\nsb.barplot(df_train.genres_Mystery, df_train.revenue, ax=ax[2,3])\nsb.barplot(df_train.genres_Romance, df_train.revenue, ax=ax[2,4])\nsb.barplot(df_train.genres_Thriller, df_train.revenue, ax=ax[3,0])\nsb.barplot(df_train.genres_War, df_train.revenue, ax=ax[3,1])\nsb.barplot(df_train.genres_Western, df_train.revenue, ax=ax[3,2])","75a0accf":"# df_train.production_companies.apply(lambda x: print(x))","d397bf1f":"# df_train.production_companies.apply(lambda x: ' ' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x))).replace(' ', '_'))","05cf6f3f":"prod_comp = ','.join(df_train.production_companies.apply(lambda x: 'NaN' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x))).replace(' ', '_')))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(prod_comp)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","6736f096":"filtered_words = [word for word in prod_comp.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(20):\n    words.append(letter)\n    counts.append(count)\n    \n\nsb.barplot(x=counts, y=words)","1032e880":"df_train['prod_wb'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Warner Bros.' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_up'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Universal Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_pp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Paramount Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_tcffc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Twentieth Century Fox Film Corporation' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_cp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_mgm'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Metro-Goldwyn-Mayer (MGM)' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_nlc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'New Line Cinema' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_tp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Touchstone Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_wdp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Walt Disney Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_cpc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures Corporation' in list((map(lambda y: y['name'], x))) else 0)\n\ndf_train['prod_wb'].value_counts(), df_train['prod_up'].value_counts(), df_train['prod_pp'].value_counts(), df_train['prod_tcffc'].value_counts(), df_train['prod_cp'].value_counts(), df_train['prod_mgm'].value_counts(), df_train['prod_nlc'].value_counts(), df_train['prod_tp'].value_counts(), df_train['prod_wdp'].value_counts(), df_train['prod_cpc'].value_counts()","98d6994c":"df_test['prod_wb'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Warner Bros.' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_up'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Universal Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_pp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Paramount Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_tcffc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Twentieth Century Fox Film Corporation' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_cp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_mgm'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Metro-Goldwyn-Mayer (MGM)' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_nlc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'New Line Cinema' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_tp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Touchstone Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_wdp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Walt Disney Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_cpc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures Corporation' in list((map(lambda y: y['name'], x))) else 0)","0a104035":"fig, ax = plt.subplots(2, 5, figsize=(16, 8))\nsb.barplot(df_train.prod_wb, df_train.revenue, ax=ax[0,0])\nsb.barplot(df_train.prod_up, df_train.revenue, ax=ax[0,1])\nsb.barplot(df_train.prod_pp, df_train.revenue, ax=ax[0,2])\nsb.barplot(df_train.prod_tcffc, df_train.revenue, ax=ax[0,3])\nsb.barplot(df_train.prod_cp, df_train.revenue, ax=ax[0,4])\nsb.barplot(df_train.prod_mgm, df_train.revenue, ax=ax[1,0])\nsb.barplot(df_train.prod_nlc, df_train.revenue, ax=ax[1,1])\nsb.barplot(df_train.prod_tp, df_train.revenue, ax=ax[1,2])\nsb.barplot(df_train.prod_wdp, df_train.revenue, ax=ax[1,3])\nsb.barplot(df_train.prod_cpc, df_train.revenue, ax=ax[1,4])","87aecfd8":"lang = ','.join(df_train.spoken_languages.apply(lambda x: '' if np.any(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(lang)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","9689b37e":"filtered_words = [word for word in lang.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(20):\n    words.append(letter)\n    counts.append(count)\n    \nsb.barplot(x=counts, y=words)","69f0c7ef":"# (df_train.keywords.apply(lambda x: '' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))","b57edf4c":"keys = ','.join(df_train.keywords.apply(lambda x: 'NaN' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(keys)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","ebba894c":"filtered_words = [word for word in keys.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(10):\n    words.append(letter)\n    counts.append(count)\n    \nsb.barplot(x=counts, y=words)","7604b517":"df_train['key_women'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'woman director' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_independent'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'independent film' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_credit'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'duringcreditsstinger' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_murder'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'murder' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_novel'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'based on novel' in list((map(lambda y: y['name'], x))) else 0)\n\ndf_train.key_women.value_counts(), df_train.key_independent.value_counts(), df_train.key_murder.value_counts(), df_train.key_credit.value_counts(), df_train.key_novel.value_counts()","fea58b5b":"fig, ax = plt.subplots(1, 5, figsize=(16, 4))\nsb.barplot(df_train.key_women, df_train.revenue, ax=ax[0])\nsb.barplot(df_train.key_independent, df_train.revenue, ax=ax[1])\nsb.barplot(df_train.key_credit, df_train.revenue, ax=ax[2])\nsb.barplot(df_train.key_murder, df_train.revenue, ax=ax[3])\nsb.barplot(df_train.key_novel, df_train.revenue, ax=ax[4])","1c686141":"df_test['key_women'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'woman director' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_independent'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'independent film' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_credit'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'duringcreditsstinger' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_murder'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'murder' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_novel'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'based on novel' in list((map(lambda y: y['name'], x))) else 0)","5898f1c3":"df_train.columns = df_train.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_test.columns = df_test.columns.str.strip().str.lower().str.replace(' ', '_')","b5946292":"len(df_train.columns), len(df_test.columns)","3db97323":"for df in (df_train, df_test):\n    print('='*10)\n    for column in df:\n        if (df[column].apply(lambda x: True if np.any(pd.isna(x)) else False).max()): print(column)","e4851774":"df_train.columns","8638373b":"cat_names = ['original_language', 'status',\n             'is_series', 'genres_war', 'genres_thriller', 'genres_science_fiction',\n             'genres_mystery', 'genres_foreign', 'genres_tv_movie', 'genres_western',\n             'genres_drama', 'genres_crime', 'genres_fantasy', 'genres_romance',\n             'genres_adventure', 'genres_family', 'genres_comedy',\n             'genres_documentary', 'genres_history', 'genres_music', 'genres_action',\n             'genres_animation', 'genres_horror', 'total_genres',\n             'total_production_companies', 'total_production_countries',\n             'total_spoken_languages', 'total_keywords', 'total_cast', 'total_crew',\n             'release_year', 'release_month', 'release_week', 'release_day',\n             'release_dayofweek', 'release_dayofyear', 'release_is_month_end',\n             'release_is_month_start', 'release_is_quarter_end',\n             'release_is_quarter_start', 'release_is_year_end',\n             'release_is_year_start', 'release_elapsed', 'prod_wb', 'prod_up',\n             'prod_pp', 'prod_tcffc', 'prod_cp', 'prod_mgm', 'prod_nlc', 'prod_tp',\n             'prod_wdp', 'prod_cpc', 'key_women', 'key_independent', 'key_credit',\n             'key_murder', 'key_novel'\n            ]\ncont_names = ['log_budget', 'log_popularity', 'log_runtime']\ndep_var = 'log_revenue'\nprocs = [Categorify, FillMissing, Normalize]\n","a7314a90":"for c in cont_names:\n    df_train[cont_names] = df_train[cont_names].fillna(0).astype('float32')\n    df_test[cont_names] = df_test[cont_names].fillna(0).astype('float32')","cc4ebbe3":"db_test = TabularList.from_df(df_test, cat_names=cat_names, cont_names=cont_names, procs=procs)","0b0228ae":"db_train = (TabularList.from_df(df_train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n            .split_by_idx(list(range(700)))\n            .label_from_df(cols=dep_var)\n            .add_test(db_test, label = 0)\n            .databunch())","0390c740":"#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n# def rmsle(y, y_pred):\n#     assert len(y) == len(y_pred)\n#     terms_to_sum = [(np.log(y_pred[i] + 1) - np.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n#     return (sum(terms_to_sum) * (1.0\/len(y))) ** 0.5\n\ndef rmsle(y, y_pred):\n#     print(len(y), len(y_pred))\n    sum=0.0\n    assert len(y) == len(y_pred)\n    for x in range(len(y_pred)):\n#         print(y[x], y_pred[x])\n        if y_pred[x]<0 or y[x]<0: #check for negative values\n            continue\n        p = np.log(y_pred[x]+1)\n        r = np.log(y[x]+1)\n        sum = sum + (p - r)**2\n    return (sum\/len(y_pred))**0.5","35be6ae8":"learn = tabular_learner(db_train, layers=[200, 100], metrics=rmsle)","e80326e2":"learn.lr_find()\nlearn.recorder.plot()","333fefed":"learn.fit(5)","d450376f":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","abce954b":"learn.save('TMDB')\nlearn.load('TMDB')","9c06efe4":"predictions, _ = learn.get_preds(DatasetType.Test)\npredictions = np.exp(predictions) - 1","97c2eb55":"pred = list()\nfor each in predictions.data.tolist():\n    pred.append(each[0])","0f0ed2bf":"pd.read_csv('..\/input\/tmdb-box-office-prediction\/sample_submission.csv')","6cb8e5cf":"submission_df = pd.DataFrame({'id': df_test['id'], 'revenue': pred})\nsubmission_df.to_csv('submission.csv', index=False)","9a0a99b3":"from IPython.display import HTML\nimport base64\n\ndef create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = f'<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    return HTML(html)\n\ncreate_download_link(submission_df)","168b8ce7":"Movies with 3 and 2222 production countries contribute a lot towards revenue.","e2e19cc2":"Rename all columns lowercase names and replacing space with _","ba8a08f1":"Two columns(revenue and log_revenue) are not there in test dataset which is fine.","29b15620":"Load data and inspect it","0ce649c3":"belongs_to_collection and homepage have very high NaN%, so probably will discard those columns","c4e7dcc2":"The data in many columns are in string containg list of dictionary format so lets convert them to list of dictionary","a58f2d26":"Check for null columns in train and test data","7cf29e57":"Movies with 1, 3, 7, 118, 775 production companies contribute a lot towards revenue.","3fc8b413":"Data visualization of all individual genres","afbd95d3":"Revenue data is skewed so will take log(log1p) to make it normal distribution. Log1p because we have value 0 in budget.","0e4e30a9":"Budget data is skewed so will take log(log1p) to make it normal distribution. Log1p because we have value 0 in budget.","5f2c76c2":"Create new features with most popular item","b54cc030":"Create new features from existing features","ffcc600a":"Inspect continuous variable column to see if the distribution is normal","b201094f":"We will inspect data for NaN percentage and ignore columns with very high NaN percentage in our model creation","c0a4c46b":"This graph tells us the number of genres makes a huge impact on revenue. Movies with 1 and 6 genres contribute a lot towards revenue.","51a371d5":"Mostly all films are in English so will ignore individual feature "}}