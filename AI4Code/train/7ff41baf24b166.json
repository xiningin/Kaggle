{"cell_type":{"cdd67de9":"code","9bc44e79":"code","4ca39b54":"code","a8eea8cf":"code","b3e513b3":"code","43d81090":"code","9e7d58c5":"code","2c7fa057":"code","93bdb104":"code","7b5f0a9a":"code","35f81290":"code","f126c814":"code","c9071020":"code","1aad0ef9":"code","856a6059":"code","428f98b6":"code","6e188b33":"code","f08fe80f":"code","648d64d2":"code","4e8837a2":"code","69077870":"markdown","bf95c5ff":"markdown","dc1e74df":"markdown"},"source":{"cdd67de9":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nimport seaborn as sns \n%matplotlib inline","9bc44e79":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","4ca39b54":"#Size and shape of the dataset\nprint(train_data.shape)\nprint(test_data.shape)","a8eea8cf":"# Checking if there are any NA values in the data\nprint(train_data.isnull().any().sum())\nprint(test_data.isnull().any().sum())","b3e513b3":"test_data.head(3)","43d81090":"# Seperating the label which we want to predict from rest of the pixel values\nY_train = train_data[\"label\"]\nx_train = train_data.drop(labels=\"label\",axis=1)\n","9e7d58c5":"# The data has fine balance of classes \"5\" has less images but will be Okay.\ntrain_data[\"label\"].value_counts()","2c7fa057":"# Scaling the pixel values from 0.0 to 255.0 to 0.0 to 1.0 \nx_train = x_train \/ 255.0\n\ntest_data = test_data \/ 255.0","93bdb104":"from keras.utils.np_utils import to_categorical\nx_train = x_train.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)\n\n# We are converting the \"label\" column into categorical values\n\nY_train = to_categorical(Y_train, num_classes = 10)","7b5f0a9a":"# Simple split in train data \nfrom sklearn.model_selection import train_test_split\nX_train,X_val,Y_train, Y_val = train_test_split(x_train,Y_train,test_size = .1,random_state = 7)","35f81290":"for i in range(5):\n    #print(i)\n    plt.figure(figsize=(10,10)).add_subplot(2,5,i+1)\n    plt.imshow(x_train[i][:,:,0])","f126c814":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n#from keras.optimizers import RMSprop\nmodel = keras.models.Sequential([\n    \n    \n    tf.keras.layers.Conv2D(filters= 32 ,kernel_size = (5,5),padding = 'Same',activation = 'relu', input_shape=(28,28,1)),\n    \n    tf.keras.layers.MaxPool2D(\n    pool_size=(2, 2)),\n    \n    \n    tf.keras.layers.Conv2D(filters= 64 ,kernel_size = (3,3),padding = 'Same',activation = 'relu'),\n    tf.keras.layers.Conv2D(filters= 64 ,kernel_size = (3,3),padding = 'Same',activation = 'relu'),\n    \n    tf.keras.layers.MaxPool2D(\n    pool_size=(2, 2)),\n    \n        \n    tf.keras.layers.Conv2D(filters= 128 ,kernel_size = (3,3),padding = 'Same',activation = 'relu'),\n    tf.keras.layers.Conv2D(filters= 128 ,kernel_size = (3,3),padding = 'Same',activation = 'relu'),\n    \n    tf.keras.layers.MaxPool2D(\n    pool_size=(2, 2)),\n    \n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation=\"sigmoid\"),\n    tf.keras.layers.Dropout(0.25),\n        \n    tf.keras.layers.Dense(512, activation=\"sigmoid\"),\n    tf.keras.layers.Dropout(0.25),\n        \n    tf.keras.layers.Dense(256, activation=\"sigmoid\"),\n    tf.keras.layers.Dropout(0.1),\n        \n    tf.keras.layers.Dense(10, activation=\"sigmoid\")\n\n    \n    \n])\n\n\n\n","c9071020":"# We are defining which optimizer to use \n# And also specifying loss i.e  categorical_crossentropy as we have our label in categorical form\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nmodel.compile(optimizer = \"Adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","1aad0ef9":"#history = model.fit(X_train, Y_train, batch_size = 86, epochs = 1, \n   #      validation_data = (X_val, Y_val), verbose = 2)","856a6059":"# this is data augment step i.e we are adding angle , zoom, and width shift\n#to our images in order to increase our training set and improve out model\n# note I have stopped \" horizontal_flip\" and \"vertical_flip\" as they will create issue with 6 and 9\ndatagen =  tf.keras.preprocessing.image.ImageDataGenerator(   \n    rotation_range=20,\n    width_shift_range=0.20,\n    shear_range=15,\n    zoom_range=0.10,\n    validation_split=0.25,\n    horizontal_flip=False,\n    vertical_flip=False)\n\ndatagen.fit(X_train)\n","428f98b6":"# This is a callback  function which reduces learing rate as the epochs go on \nfrom keras.callbacks import ReduceLROnPlateau\nlrr = ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=2,factor=0.5, min_lr=0.00001)","6e188b33":"history = model.fit(datagen.flow(X_train, Y_train, batch_size = 86), epochs = 30, \n         validation_data = (X_val, Y_val),callbacks=[lrr], verbose = 2)","f08fe80f":"model.summary()","648d64d2":"pd.DataFrame(history.history).plot(figsize=(8,5))\nplt.gca().set_ylim(0,1)\nplt.show()","4e8837a2":"# test_df = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n# test_df.shape\n# test_data = test_df.values\n# test_data = test_data.reshape(-1, 28, 28, 1)\n# test_data.shape\n# test_data = test_data \/ 255.0\n# predictions = model.predict(test_data).argmax(axis=1)\n\n# submission_df = pd.DataFrame({'ImageId':np.arange(1, len(predictions)+1), 'Label':predictions})\n# submission_df.to_csv('submission.csv', index=False)","69077870":"### Prepare\n\n* The data has 42,000+ 28,000 rows and 785 columns.\n* Out of 785 columns, 784 represents a unique pixel value (0 to 255) of an image and the remaining column \"label\" tell   us the class of that particular image.\n* The data does not have any \"NA\" or any missing value.\n","bf95c5ff":"### Objective\n\n* Our objective is to correctly identify digits from a dataset of handwritten images.\n* The dataset contains 10 class which are 0,1,2,3,4,5,6,7,8,9.","dc1e74df":"# Digit Recognizer: Kaggle Competition"}}