{"cell_type":{"7648f226":"code","12244270":"code","48c8191d":"code","62a215f7":"code","59f52b16":"code","c61b9b6c":"code","68e8dfd9":"code","51a6fefd":"code","8bc8d453":"code","d1f60fcf":"code","79679902":"code","4065ee52":"code","8c104067":"code","d1e11f1d":"code","c70a4076":"code","f6e47a37":"code","134e26b2":"code","7ab921e0":"code","67c30454":"code","68f9b8cd":"code","a23d51a3":"markdown","ee846c4e":"markdown","d98913d1":"markdown","c72b9f86":"markdown","56ca3fd7":"markdown","70671581":"markdown","06e9e48f":"markdown","f40055a9":"markdown","340863b8":"markdown","cbc3a2c0":"markdown"},"source":{"7648f226":"IMG_ROWS = 480\nIMG_COLS = 320\n\nTEST_IMG_ROWS = 1918\nTEST_IMG_COLS = 1280","12244270":"import cv2\nimport numpy as np\nimport imageio\nfrom scipy import ndimage\nfrom glob import glob\nimport zipfile\n\nSAMPLE = 1000","48c8191d":"path_to_zip_file = \"..\/input\/carvana-image-masking-challenge\/train.zip\"\ndirectory_to_extract_to = \"..\/output\/kaggle\/working\"\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)\n    \npath_to_zip_file = \"..\/input\/carvana-image-masking-challenge\/train_masks.zip\"\ndirectory_to_extract_to = \"..\/output\/kaggle\/working\"\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","62a215f7":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/output\/kaggle\/working\"]).decode(\"utf8\"))","59f52b16":"train_img_paths = sorted(glob('..\/output\/kaggle\/working\/train\/*.jpg'))[:SAMPLE]\ntrain_mask_paths = sorted(glob('..\/output\/kaggle\/working\/train_masks\/*.gif'))[:SAMPLE]","c61b9b6c":"train_imgs = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n                        for path in train_img_paths])\n\ntrain_masks = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n                        for path in train_mask_paths])\n\ntrain_masks = train_masks.astype(np.float32)\ntrain_masks[train_masks<=127] = 0.\ntrain_masks[train_masks>127] = 1.\ntrain_masks = np.reshape(train_masks, (*train_masks.shape, 1))","68e8dfd9":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(0, figsize=(20, 20))\nfig.add_subplot(1, 2, 1)\nplt.imshow(train_imgs[0])\nfig.add_subplot(1, 2, 2)\nplt.imshow(np.squeeze(train_masks[0]), cmap='gray')","51a6fefd":"from keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import BatchNormalization\nfrom keras.layers import concatenate\nfrom keras.models import Model","8bc8d453":"inputs = Input((IMG_COLS, IMG_ROWS, 3))\nbnorm1 = BatchNormalization()(inputs)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(bnorm1)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\nup6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\nup7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\nup8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\nup9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\nconv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])","d1f60fcf":"from tensorflow.python.client import device_lib;print(device_lib.list_local_devices())","79679902":"model.summary()","4065ee52":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\n\nSMOOTH = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + SMOOTH) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + SMOOTH)\n\ndef bce_dice_loss(y_true, y_pred):\n    return 0.5 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)","8c104067":"from tensorflow.keras.optimizers import Adam\nmodel.compile(Adam(lr=1e-4),\n              bce_dice_loss,\n              metrics=[binary_crossentropy, dice_coef])","d1e11f1d":"model.fit(train_imgs[50:], train_masks[50:],\n          batch_size=12, epochs=10, \n          validation_data=(train_imgs[:50], train_masks[:50]))","c70a4076":"path_to_zip_file = \"..\/input\/carvana-image-masking-challenge\/test.zip\"\ndirectory_to_extract_to = \"..\/output\/kaggle\/working\"\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract_to)","f6e47a37":"test_paths = sorted(glob('..\/output\/kaggle\/working\/test\/*.jpg'))\n\n#test_imgs = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n #                       for path in train_img_paths])","134e26b2":"def rle_encode(mask):\n    pixels = mask.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] = runs[1::2] - runs[:-1:2]\n    return runs","7ab921e0":"with open('submit.txt', 'w') as dst:\n    dst.write('img,rle_mask\\n')\n    for path in test_paths:\n        img = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])\n        pred_mask = model.predict(img)[0]\n        bin_mask = 255. * cv2.resize(pred_mask, (TEST_IMG_ROWS, TEST_IMG_COLS))\n        bin_mask[bin_mask<=127] = 0\n        bin_mask[bin_mask>127] = 1\n        rle = rle_encode(bin_mask.astype(np.uint8))\n        rle = ' '.join(str(x) for x in rle)\n        dst.write('%s,%s\\n' % (path.split('\/')[-1], rle))","67c30454":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/working\"]).decode(\"utf8\"))","68f9b8cd":"import csv\n\nwith open('..\/working\/submit.txt', 'r') as in_file:\n    stripped = (line.strip() for line in in_file)\n    lines = (line.split(\",\") for line in stripped if line)\n    with open('submission.csv', 'w') as out_file:\n        writer = csv.writer(out_file)\n        writer.writerows(lines)","a23d51a3":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442","ee846c4e":"## \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","d98913d1":"## \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443 U-Net","c72b9f86":"def test_img_generator(test_paths):\n    while True:\n        for path in test_paths:\n            yield np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])","56ca3fd7":"## \u041f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u0438","70671581":"## \u0417\u0430\u0434\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0442\u0435\u0440\u044c","06e9e48f":"pred = model.predict(test_img_generator(test_paths[:10]), len(test_paths[:10]))","f40055a9":"fig = plt.figure(0, figsize=(20, 10))\nk = 5\nfig.add_subplot(2, 2, 1)\nplt.imshow(imageio.imread(test_paths[k]))\nfig.add_subplot(2, 2, 2)\nplt.imshow(np.squeeze(cv2.resize(pred[k], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')\nfig.add_subplot(2, 2, 3)\nplt.imshow(imageio.imread(test_paths[k+1]))\nfig.add_subplot(2, 2, 4)\nplt.imshow(np.squeeze(cv2.resize(pred[k+1], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')","340863b8":"## \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","cbc3a2c0":"# Carvana Image Masking Challenge"}}