{"cell_type":{"a5d43233":"code","234723a7":"code","ac8984fb":"code","3ea3e465":"code","b442b289":"code","0851ec3b":"code","fc733af8":"code","d3f6d5dd":"code","a99b24ef":"code","afd45ed0":"code","a5590908":"code","71f50206":"code","02250293":"code","dd016794":"code","161b0007":"code","92d3b3d6":"code","e36f975d":"code","fefb746a":"code","cbcb060a":"code","56f1de9e":"code","e54e8737":"code","fd01bfd3":"code","4d3ec783":"code","652ba8b8":"code","0e016a8b":"code","a1b239f5":"code","42113b4e":"markdown","a56bf0b9":"markdown","55703673":"markdown","3071f7e9":"markdown","193c4fd4":"markdown","d8ca4a85":"markdown","b4aa4b26":"markdown","c297fdf0":"markdown","9e253bdc":"markdown","5b63f5b7":"markdown","aa2db878":"markdown","22a3e444":"markdown","475d3fb9":"markdown","0a0290dd":"markdown","65815bf3":"markdown"},"source":{"a5d43233":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Dropout\n# from tensorflow.keras.applications import EfficientNetB0\n# from tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.applications import EfficientNetB5\nfrom keras.callbacks import EarlyStopping\nfrom pathlib import Path\n\nprint(\"Tensorflow version \" + tf.__version__)","234723a7":"root_path = '..\/input\/cassava-leaf-disease-classification\/'","ac8984fb":"train = pd.read_csv(root_path + 'train.csv')\ntrain['label'] = train['label'].astype('string')\ntrain.sample(5)","3ea3e465":"names_of_disease = pd.read_json(root_path + 'label_num_to_disease_map.json', typ='series')\nnames_of_disease","b442b289":"from PIL import Image,ImageFilter\nimport os\n\nplt.figure(figsize=(16, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    image = Image.open(root_path + 'train_images\/' + train.iloc[i]['image_id'])\n    print(root_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    plt.imshow(array)\n    label=train.iloc[i]['label']\n    print(label)\n    plt.title(f'{names_of_disease[int(label)]}')\n    break\nplt.show()\n\n  \n#Read image\n\n","0851ec3b":"sizes = []\nfor i in range(1, len(train), 250):\n    image = Image.open(root_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    sizes.append(array.shape)\nprint('Picture size', set(sizes))","fc733af8":"128*800\/600.0","d3f6d5dd":"# img_width, img_height = 224, 224\n# img_width, img_height = 128, 128\n# img_width, img_height = 164, 164\nimg_width, img_height = 256, 256","a99b24ef":"train['label'].value_counts(normalize=True)","afd45ed0":"datagen = ImageDataGenerator(validation_split=0.2,\n                             vertical_flip=True,\n                             horizontal_flip=True,\n                             rotation_range=90,\n                             brightness_range=[0.5,1.0],\n                             shear_range=25,\n                             zoom_range=[0.5,1.0]\n                            )                            \n\ntrain_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=root_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=32,\n    subset='training',\n    shuffle = True,\n    #seed=12345,\n    class_mode='categorical'\n)\n","a5590908":"valid_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=root_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=32,\n    subset='validation',\n    #seed=12345,\n    class_mode = 'categorical',\n    shuffle = True\n)","71f50206":"early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=4)","02250293":"model = Sequential()\nmodel.add(EfficientNetB5(include_top = False, weights = \"imagenet\",\n                        input_shape=(img_width, img_height, 3)))\n# model.add(Dropout(0.2))\n# model.add(tf.keras.layers.GlobalAveragePooling2D())\n\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.AveragePooling2D(pool_size=(3, 3)))\n\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(512, activation = \"relu\"))\nmodel.add(tf.keras.layers.Dense(64, activation = \"relu\"))\nmodel.add(tf.keras.layers.Dense(5, activation = \"softmax\"))\n# model.add(Dropout(0.5))\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n# optimizer = 'adam'\nmodel.compile(optimizer = optimizer,\n            loss = \"categorical_crossentropy\",\n            metrics = [\"accuracy\"])\n\n# from tensorflow.keras.applications import EfficientNetB0\n\n# with strategy.scope():\n#     inputs = layers.Input(shape=(img_width, img_height, 3))\n#     x = img_augmentation(inputs)\n#     outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n\n#     model = tf.keras.Model(inputs, outputs)\n#     model.compile(\n#         optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n#     )\n\n# model.summary()\n\n# epochs = 40  # @param {type: \"slider\", min:10, max:100}\n# hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)","dd016794":"model.summary()","161b0007":"from tensorflow.keras import utils\n\nutils.plot_model(model)","92d3b3d6":"from keras.callbacks import LearningRateScheduler\nlrs = LearningRateScheduler(my_learning_rate)","e36f975d":"def my_learning_rate(epoch, lrate):\n\n if (epoch < 5) :\n  lrate = (1e-3)\n elif (epoch < 10) :\n  lrate = 1e-4\n else:\n  lrate = 1e-5\n    \n return lrate\n\n\n\n","fefb746a":"my_learning_rate(9, 1e-4)","cbcb060a":"history = model.fit_generator(train_datagen_flow,\n                            epochs = 15,\n                            validation_data = valid_datagen_flow,\n                             callbacks = [early_stopping,lrs])\n\n\nmodel.save('Cassava_model'+'.h5') ","56f1de9e":"import matplotlib.pyplot as plt\n\n\ndef plot_hist(history):\n    plt.plot(history.history[\"accuracy\"])\n    plt.plot(history.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()\n\n\nplot_hist(history)","e54e8737":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot()","fd01bfd3":"# import os\n# import keras\n# RUN_NAME = 'run 1 with 25 nodes'\n# logger = keras.callbacks.TensorBoard(\n#     log_dir='kaggle\/working\/logs\/ {}'.format(RUN_NAME),\n#     histogram_freq=5,\n#     write_graph=True\n# )\n# os.getcwd()\n# tf.tensorboard --logdir=\/logs\/\n# tensorboard --logdir=summaries","4d3ec783":"# model.load_weights('model_weights.h5')","652ba8b8":"# os.path.join(root_path + 'test_images', image_name)","0e016a8b":"# Evaluating the model\n\nimport keras\n\nfinal_model = keras.models.load_model('Cassava_model.h5')\n\nsubmission = pd.DataFrame(columns=['image_id','label'])\n\nfor image_name in os.listdir(root_path + 'test_images'):\n    image_path = os.path.join(root_path + 'test_images', image_name)\n    image = tf.keras.preprocessing.image.load_img(image_path)\n    resized_image = image.resize((img_width, img_height))\n    numpied_image = np.expand_dims(resized_image, 0)\n    tensored_image = tf.cast(numpied_image, tf.float32)\n    submission = submission.append(pd.DataFrame({'image_id': image_name,\n                                                 'label': final_model.predict_classes(tensored_image)}))\n\nsubmission","a1b239f5":"submission.to_csv('submission.csv', index = False)","42113b4e":"# Run and save model","a56bf0b9":"# Read the input data","55703673":"1. # Model EfficientNetB5","3071f7e9":"# Reload the model trained weights","193c4fd4":"# Test (Validating)","d8ca4a85":"Build the Model","b4aa4b26":"Submission","c297fdf0":"# Disease catagory","9e253bdc":"# Running the model","5b63f5b7":"# Predict Test Image","aa2db878":"# Training","22a3e444":"### * Version 2: 856\/856 [==============================] - 1894s 2s\/step - loss: 1.1880 - accuracy: 0.6146 - val_loss: 1.1774 - val_accuracy: 0.6165\n**\n* Version 3: 856\/856 [==============================] - 274s 321ms\/step - loss: 0.8554 - accuracy: 0.6764 - val_loss: 0.8232 - val_accuracy: 0.6843\n* Version 4: \n    image size 64x64  accuracy: 0.6823\n    856\/856 [==============================] - 652s 762ms\/step - loss: 0.8481 - accuracy: 0.6823 - val_loss: 0.8613 - val_accuracy: 0.6686\n* Version 5:\n    convolution... filters=64, kernel_size=4\n* Version 6: \n    back to basic  accuracy: 0.64  after epocs =8\n* Version 8: \n    Early stopping, epocs 100\n* Version 9: EfficientNetB0 epocs 10 --> accuracy: 0.7385\n\n* Version 11-13: EfficientNetB0 epocs 50 --> accuracy: 0.84  validation=0.72\n* Version 14: EfficientNetB0 epocs 20 --> accuracy:?\n* Version 15: TODO: Batchsize 128 and dropout 0.6  make the model worst\n* Version 16: Batchsize 32 + flatten +drop+ dense512 +ephocs =10  accuracy: 0.74  validation=0.72 \n* Version 17: image size 128x128 accuracy: 0.81  validation=0.79\n* Version 18: image size 256x256 , epoch=6 (<8H) occuracy 0.84 validation=0.8441\n* version 19: image size 128X170 , epoch=6  occuracy=0.787 Valid=0.787\n* version 20: image size 164X164 , epoch=6 , change from B0 to EfficientNetB4\n* version 21: image size 164X164 , epoch=8 , change from B0 to EfficientNetB4 -accuaracy 0.81 validation 0.79\n* Version 22: image size 164X164 , epoch=6 , change from B4 to EfficientNetB5  accuracy 078 valid=0.79\n* Version 23: fix output submission\n* version 25: save model file  +epoch=10  accuracy: 0.8186 - val_loss: 0.5699 - val_accuracy: 0.8004  (score 0.772)\n* version 26: 256X256 +epoch=10 loss: 0.4181 - accuracy: 0.8583 - val_loss: 0.4416 - val_accuracy: 0.8537  (score 0.862)\n* version 26: 256X256 BatchNormalization(32) +epoch=10 got worst\n* Version:  use callback for dynamic learn-rate ... callback [... ,lrs]  increase as we goes (big degradation from 0.8 to 0.6)\n* use callback for dynamic learn-rate ... callback [... ,lrs]  decrease as we goes \n\nBase on: https:\/\/www.kaggle.com\/bununtadiresmenmor\/starter-keras-efficientnet?select=sample_submission.csv\n\n","475d3fb9":"# Setup","0a0290dd":"# Logs","65815bf3":"# Check Data input Distribution"}}