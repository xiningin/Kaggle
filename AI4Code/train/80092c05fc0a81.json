{"cell_type":{"85031a73":"code","34a1d4f1":"code","0e2bb3bb":"code","51ebd292":"code","38bd6ada":"code","3dcd654c":"code","f98ac43a":"code","d7b91fa9":"code","52fe59d8":"code","784585ec":"code","c4096392":"code","22982955":"code","d97df598":"code","cfa8abf4":"code","fbd988dd":"code","534953ca":"code","974872f4":"code","6c007db7":"code","f7d391e5":"code","d8b655b8":"code","bed4953e":"code","a51eb451":"code","18213913":"code","1c872d2f":"code","8fb14fc8":"code","7196c1bc":"code","9fef58c9":"code","60a5a068":"code","727b6445":"code","399de84a":"code","a72bdb21":"code","152e126c":"code","6d8d27c3":"code","7b0240d1":"code","9e9991e8":"code","4e39418e":"code","8071a2e4":"code","580f3a40":"code","b4625fc4":"code","84da0601":"code","8d71b400":"code","d4d59ce9":"code","a0e6aa9e":"code","c38eea95":"code","b00f28b7":"code","b4bac1f7":"code","5c0d1727":"markdown","a2a5fc24":"markdown","37a11e84":"markdown","d43a26a7":"markdown","fe1b6129":"markdown","b2eab936":"markdown","3aa0d27e":"markdown","1380225a":"markdown","b516012f":"markdown","e240aa7d":"markdown","76560515":"markdown","0ca69c40":"markdown","dbe03bf1":"markdown","4a5b24ac":"markdown","0faec884":"markdown","6f1208a0":"markdown","bf6488cb":"markdown","3c23b1c6":"markdown","df9014e1":"markdown","efc40527":"markdown","ff997b49":"markdown","55e6c26a":"markdown","d3d156bc":"markdown","a9584daf":"markdown","45f1a86a":"markdown","14299f70":"markdown","224b9e18":"markdown","64a07a30":"markdown","9846755f":"markdown","b3db7ff8":"markdown","8750a614":"markdown"},"source":{"85031a73":"import numpy as np\nimport pandas as pd\nfrom fastai.tabular import *\nfrom fastai.collab import *","34a1d4f1":"movies = pd.read_csv('\/kaggle\/input\/movietweetings\/movies.dat', delimiter='::', engine='python', header=None, names = ['Movie ID', 'Movie Title', 'Genre'])\nusers = pd.read_csv('\/kaggle\/input\/movietweetings\/users.dat', delimiter='::', engine='python', header=None, names = ['User ID', 'Twitter ID'])\nratings = pd.read_csv('\/kaggle\/input\/movietweetings\/ratings.dat', delimiter='::', engine='python', header=None, names = ['User ID', 'Movie ID', 'Rating', 'Rating Timestamp'])\nmovies.head()","0e2bb3bb":"users.head()","51ebd292":"ratings.head()","38bd6ada":"for i in [movies, users, ratings]:\n    print(i.shape)","3dcd654c":"df = ratings.merge(movies[['Movie ID','Movie Title']], on='Movie ID')","f98ac43a":"df = df.rename(columns={'User ID':'userID','Movie ID':'movieID','Rating':'rating','Rating Timestamp':'timestamp', 'Movie Title': 'title'})\ndf.head()","d7b91fa9":"df.rating = df.rating\/2.0","52fe59d8":"data = CollabDataBunch.from_df(df, seed=42, valid_pct=0.1, item_name='title')","784585ec":"data.show_batch()","c4096392":"y_range = [0,5.5]","22982955":"learn = collab_learner(data, n_factors=40, y_range=y_range, wd=1e-1)","d97df598":"learn.lr_find()\nlearn.recorder.plot()","cfa8abf4":"learn.fit_one_cycle(5, 1e-3)","fbd988dd":"learn.save('dotprod')","534953ca":"learn.load('dotprod');","974872f4":"g = df.groupby('title')['rating'].count()\ntop_movies = g.sort_values(ascending=False).index.values[:1000]\ntop_movies[:10]","6c007db7":"movie_bias = learn.bias(top_movies, is_item=True)\nmovie_bias.shape","f7d391e5":"mean_ratings = df.groupby('title')['rating'].mean()*2\nmovie_ratings = [(b, i, mean_ratings.loc[i]) for i,b in zip(top_movies,movie_bias)]","d8b655b8":"item0 = lambda o:o[0]","bed4953e":"sorted(movie_ratings, key=item0)[:15]","a51eb451":"df2 = df.copy()\ndf2.rating = df2.rating*2","18213913":"df2[df2.title == 'The Thin Red Line (1998)'].groupby('rating')['title'].count()","1c872d2f":"sorted(movie_ratings, key=lambda o: o[0], reverse=True)[:15]","8fb14fc8":"df2[df2.title == 'Be Somebody (2016)'].groupby('rating')['title'].count()","7196c1bc":"movie_w = learn.weight(top_movies, is_item=True)\nmovie_w.shape","9fef58c9":"movie_pca = movie_w.pca(3)\nmovie_pca.shape","60a5a068":"fac0,fac1,fac2 = movie_pca.t()\nmovie_comp = [(f, i) for f,i in zip(fac0, top_movies)]","727b6445":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","399de84a":"sorted(movie_comp, key=itemgetter(0))[:10]","a72bdb21":"movie_comp = [(f, i) for f,i in zip(fac1, top_movies)]","152e126c":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","6d8d27c3":"sorted(movie_comp, key=itemgetter(0))[:10]","7b0240d1":"movie_comp = [(f, i) for f,i in zip(fac2, top_movies)]\nsorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","9e9991e8":"sorted(movie_comp, key=itemgetter(0))[:10]","4e39418e":"idxs = np.random.choice(len(top_movies), 75, replace=False)\nidxs = list(range(75))\nX = fac0[idxs]\nY = fac1[idxs]\nplt.figure(figsize=(15,15))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.xlabel(\"<------- Movies like Movie43 and Scary Movie 5                     [fac0]                            Gritty Heros------>\")\nplt.ylabel(\"<------- Big Action                                [fac1]                                         Thriller\/Horrors------>\")\nplt.title(\"75 Top Movies\")\nplt.show()","8071a2e4":"df.userID.value_counts()[:10]","580f3a40":"learn.export()","b4625fc4":"learn = load_learner('\/kaggle\/input\/export\/')","84da0601":"h = df.groupby('movieID')['rating'].count()\nall_films = h.sort_values(ascending=False).index.values[:10000]","8d71b400":"def get_top_suggested(user_id):\n    user_films = df[df.userID == user_id].movieID.sort_values().values\n    unseen_films = [i for i in all_films if i not in user_films]\n    user_df = pd.Series(unseen_films, name='movieID').to_frame()\n    user_df['userID'] = user_id\n    user_df = user_df.reindex(columns=['userID','movieID'])\n    user_df = user_df.merge(df[['movieID','title']], on='movieID')\n    user_df = user_df.groupby('title').mean().reset_index()\n    learn = load_learner('\/kaggle\/input\/export\/', test=CollabList.from_df(user_df, cat_names=['userID', 'movieID'], path='\/kaggle\/input\/export\/'))\n    preds = learn.get_preds(ds_type=DatasetType.Test)\n    user_df['rating'] = preds[0]*2\n    user_df['rating'] = round(user_df['rating'],1)\n    return user_df.sort_values(by='rating', ascending=False).reset_index()[['title','rating']].head(20)","d4d59ce9":"get_top_suggested(24249)","a0e6aa9e":"def rating_comparison(user_id):\n    learn = load_learner('\/kaggle\/input\/export\/', test=CollabList.from_df(df[df.userID == 24249], cat_names=['userID', 'movieID'], path='\/kaggle\/input\/export\/'))\n    preds = learn.get_preds(ds_type=DatasetType.Test)\n    df2 = df[df.userID == 24249].copy()\n    df2['prediction'] = preds[0]*2\n    df2['rating'] = df2['rating']*2\n    df2['diff'] = abs(df2['prediction'] - df2['rating'])\n    return df2.sort_values(by='prediction', ascending=False).reset_index()[['title','rating','prediction','diff']]","c38eea95":"rating_comparison(24249).head(20)","b00f28b7":"learn = load_learner('\/kaggle\/input\/export\/', test=CollabList.from_df(df, cat_names=['userID', 'movieID'], path='\/kaggle\/input\/export\/'))\npreds = learn.get_preds(ds_type=DatasetType.Test)","b4bac1f7":"df['prediction'] = preds[0]*2\ndf['difference'] = abs(df['prediction'] - df['rating']*2)\ndf2 = df.groupby('userID')[['difference']].agg(['count','mean'])\ndf2.difference.plot(x='mean',y='count',kind='scatter',figsize=(20,10))","5c0d1727":"## Testing The Model","a2a5fc24":"To try and find some patterns in taste we can look at the weights, of which there are 40x1000. That's beacuse we used 40 factors for the training model and there's 1000 movies.\nWe are going to cram these 40 factors into just 3 using Principal Components Analysis.\nI'm told this is done with a simple linear transformation that takes an input matrix and tries to find a smaller number of columns that cover a lot of the space in that original matrix.","37a11e84":"We're now going to use the model to suggest some films to one of the users.","d43a26a7":"n_factors is just the embedding size. I had no idea what size would be best so I looped through 20,30,40,60,80 and found 40 to give the smallest loss.","fe1b6129":"Since this learning model is using a sigmoid function which asymptotes at the end meaning if you plotted this function on a graph from 0 to 5, it never actually reaches 5 so we need to aim a little higher then that.","b2eab936":"## Training The Model","3aa0d27e":"All film ratings have some form of bias attached to them. This is because no film is inherently good or bad, and are based on people's own preferances. I may like action films more than most, therefore films with action in have my bias attached to it's rating. We need a way to unbias them, by adding a bias to our model we can effectively try to cancel this out.","1380225a":"Be Somebody, Joker, and Shawshank Redemption have quite a high bias. This means we can expect to see these films suggested the most often.\n\nBe Somebody is rated 5.6 on imdb though so lets also look into movie.","b516012f":"## Preparing The Data","e240aa7d":"The largest error in this list of the top 20 looks to be Back to the Future, which the user voted a 7 but our algorithm predicts 8.8. Overall this is extremely good and we can be quite confident in our recommendation model.","76560515":"Create the DataBunch, with 10% used for validation.","0ca69c40":"This is just a random sampling of 75 of the most popular movies, with fac0 and fac1 on the X and Y axis. ","dbe03bf1":"Saving and reloading the model so we won't have to retrain each time we comeback to the notebook.","4a5b24ac":"show_batch lets you peak at the data. \nThis just allows you to make sure your data is being interpreted correctly by CollabDataBunch.","0faec884":"The first factor appears to group darker hero adventures. People who are fans of these types of films are least likely to want to watch films like Scare Movie 5 and Movie 43.","6f1208a0":"This is a list of the top ten users who voted on the most films, and would get the most accurate recommendations when testing the model.","bf6488cb":"movie_ratings provides a list of each of the 1000 films in top_movies, with their bias, title, and what there mean rating is.","3c23b1c6":"This function finds all the movies in the top 1000 most voted for, which a user has not yet rated on, and lists the top 20 movies it believes that user would rate the highest.","df9014e1":"Now to compare how many films a user has rated with their mean error","efc40527":"I'd like to see just how well these predictions are, so this function lists the top 20 movies it thinks a user will like, and compares the difference between the user's actual predicitions.","ff997b49":"## Interpreting The Model","55e6c26a":"Our dataframe is just about ready to use. All we need to do is normalise the ratings so they are between 0 and 5 so they can work with the fast.ai learner.","d3d156bc":"Looks like a 168 people rated this film 1\/10 for some reason.","a9584daf":"The next factor is definitely looking at people who like thriller-horrors, and these fans seem to not be huge lovers of big action films.","45f1a86a":"Using fast.ai I'm going to use collaborative filtering to train a neural network to recommend films based on theirs and others likes and dislikes.","14299f70":"Movies that have been rated the highest number of times.\nGravity being the highest with 3066 votes.","224b9e18":"# Building a Movie Recommendation Model ","64a07a30":"Lastly it looks like superhero films, where these fans are least interested in more serious slower films.","9846755f":"Running for five epochs gave a RMSE of 0.66 which is a MSE of 0.43. That's to say for a rating out of ten, the model can predict on average within 0.87 points, which is really quite impressive.","b3db7ff8":"These films have the lowest bias, meaning they are some of the least liked. That means when it looks at recommending one of these films to someone because it's very familier to a bunch of other films that person liked it'll not rate it as high as it would without the attached bias because it understands that this is a very unlikable film.\n\nWhat's interesting is the film The Thin Red Line. It's rated 7.6 on IMBD but Twitter users are voting it a measley 3.5. Let's look into this.","8750a614":"Again, all except one person who rated 'Be Somebody' rated it a 10. Why though?"}}