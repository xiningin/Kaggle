{"cell_type":{"0fcadd64":"code","d76c3717":"code","e89dead1":"code","e39ca0f8":"code","ff45be58":"code","f14c7d2b":"code","21d620ad":"code","bcb2b3a9":"code","9992a75c":"code","40b3d6e3":"code","12320cdf":"code","03ca2b56":"code","8dde8956":"code","4a6a74cd":"code","2d97ce3d":"code","8ffbe166":"code","bf8ca450":"code","82e3f41b":"code","2cabfe72":"code","bd5356cb":"code","42d39ace":"markdown","7798f54a":"markdown","c1f13cd7":"markdown","7f9885b2":"markdown","24de2e08":"markdown","d511d8b4":"markdown","1bf3c7b5":"markdown","d352a4be":"markdown","2d44bb35":"markdown"},"source":{"0fcadd64":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d76c3717":"laptops = pd.read_csv('\/kaggle\/input\/laptop-price\/laptop_price.csv',encoding='latin-1')\nlaptops = laptops.set_index('laptop_ID')\nlaptops.head()","e89dead1":"laptops.info()","e39ca0f8":"laptops.describe()","ff45be58":"laptops['Company'].value_counts()\nfig_dims = (20, 6)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.countplot(x=\"Company\", data=laptops, ax=ax)","f14c7d2b":"laptops[\"Ram\"] = laptops[\"Ram\"].str.replace('GB', '')\nlaptops[\"Weight\"] = laptops[\"Weight\"].str.replace('kg', '')\nlaptops['Memory'] = laptops['Memory'].astype(str).replace('\\.0', '', regex=True)\nlaptops[\"Memory\"] = laptops[\"Memory\"].str.replace('GB', '')\nlaptops[\"Memory\"] = laptops[\"Memory\"].str.replace('TB', '000')\nnew2 = laptops[\"Memory\"].str.split(\"+\", n = 1, expand = True)\nlaptops[\"first\"]= new2[0]\nlaptops[\"first\"]=laptops[\"first\"].str.strip()\nlaptops[\"second\"]= new2[1]\nlaptops[\"Layer1HDD\"] = laptops[\"first\"].apply(lambda x: 1 if \"HDD\" in x else 0)\nlaptops[\"Layer1SSD\"] = laptops[\"first\"].apply(lambda x: 1 if \"SSD\" in x else 0)\nlaptops[\"Layer1Hybrid\"] = laptops[\"first\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\nlaptops[\"Layer1Flash_Storage\"] = laptops[\"first\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\nlaptops['first'] = laptops['first'].str.replace(r'\\D', '')\nlaptops[\"second\"].fillna(\"0\", inplace = True)\nlaptops[\"Layer2HDD\"] = laptops[\"second\"].apply(lambda x: 1 if \"HDD\" in x else 0)\nlaptops[\"Layer2SSD\"] = laptops[\"second\"].apply(lambda x: 1 if \"SSD\" in x else 0)\nlaptops[\"Layer2Hybrid\"] = laptops[\"second\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\nlaptops[\"Layer2Flash_Storage\"] = laptops[\"second\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\nlaptops['second'] = laptops['second'].str.replace(r'\\D', '')\nlaptops[\"first\"] = laptops[\"first\"].astype(int)\nlaptops[\"second\"] = laptops[\"second\"].astype(int)\nlaptops[\"Total_Memory\"]=(laptops[\"first\"]*(laptops[\"Layer1HDD\"]+laptops[\"Layer1SSD\"]+laptops[\"Layer1Hybrid\"]+laptops[\"Layer1Flash_Storage\"])+laptops[\"second\"]*(laptops[\"Layer2HDD\"]+laptops[\"Layer2SSD\"]+laptops[\"Layer2Hybrid\"]+laptops[\"Layer2Flash_Storage\"]))\nlaptops[\"Memory\"]=laptops[\"Total_Memory\"]\nlaptops[\"HDD\"]=(laptops[\"first\"]*laptops[\"Layer1HDD\"]+laptops[\"second\"]*laptops[\"Layer2HDD\"])\nlaptops[\"SSD\"]=(laptops[\"first\"]*laptops[\"Layer1SSD\"]+laptops[\"second\"]*laptops[\"Layer2SSD\"])\nlaptops[\"Hybrid\"]=(laptops[\"first\"]*laptops[\"Layer1Hybrid\"]+laptops[\"second\"]*laptops[\"Layer2Hybrid\"])\nlaptops[\"Flash_Storage\"]=(laptops[\"first\"]*laptops[\"Layer1Flash_Storage\"]+laptops[\"second\"]*laptops[\"Layer2Flash_Storage\"])\nnew = laptops[\"ScreenResolution\"].str.split(\"x\", n = 1, expand = True) \nlaptops[\"X_res\"]= new[0]\nlaptops[\"Y_res\"]= new[1]\nlaptops[\"Y_res\"]= pd.to_numeric(laptops[\"Y_res\"])\nlaptops[\"Y_res\"]= laptops[\"Y_res\"].astype(float)\nlaptops[\"X_res\"]=(laptops['X_res'].str.replace(',','').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: pd.Series(x).astype(int)).mean(1))\nlaptops[\"X_res\"]=pd.to_numeric(laptops[\"X_res\"])\nlaptops[\"PPI\"]=(((laptops[\"X_res\"]**2+laptops[\"Y_res\"]**2)**(1\/2))\/laptops[\"Inches\"]).astype(float)\nlaptops[\"ScreenResolution\"]=(laptops[\"X_res\"]*laptops[\"Y_res\"]).astype(float)\nlaptops[\"Ram\"] = laptops[\"Ram\"].astype(int)\nlaptops[\"Weight\"] = laptops[\"Weight\"].astype(float)\nlaptops=laptops.drop(['first','second','Layer1HDD','Layer1SSD','Layer1Hybrid','Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage','Total_Memory'],axis=1)","21d620ad":"laptops.head(5)","bcb2b3a9":"def correlation_heatmap(train):\n    correlations = train.corr()\n    \n    fig, ax = plt.subplots(figsize=(16,16))\n    sb.heatmap(correlations, vmax=1.0, center=0, fmt='.2f', square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\":.70})\n    plt.show()\ncorrelation_heatmap(laptops)","9992a75c":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.scatterplot(data=laptops, x=\"Price_euros\", y=\"Ram\", ax=ax, s=75)","40b3d6e3":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.scatterplot(data=laptops, x=\"Price_euros\", y=\"SSD\", ax=ax, s=75)","12320cdf":"X = laptops.drop(['Price_euros'],axis=1)\nY = laptops['Price_euros'].values\nX = X.select_dtypes(exclude=['object'])","03ca2b56":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)","8dde8956":"SGDreg = SGDRegressor()\nSGDreg.fit(X_train, y_train)","4a6a74cd":"pred = SGDreg.predict(X_train)\nsgd_mse = mean_squared_error(y_train, pred)\nsgd_rmse = np.sqrt(sgd_mse)\nsgd_rmse","2d97ce3d":"param_grid = {\n    'alpha': 10.0 ** -np.arange(1, 7),\n    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n    'penalty': ['l2', 'l1', 'elasticnet'],\n    'learning_rate': ['constant', 'optimal', 'invscaling'],\n    'max_iter': [1000, 5000, 10000]\n}\n\ngrid_search = GridSearchCV(SGDreg, param_grid)\ngrid_search.fit(X_train, y_train)\nprint(\"Best score: \" + str(grid_search.best_score_))","8ffbe166":"Kreg = KNeighborsRegressor()\nKreg.fit(X_train, y_train)","bf8ca450":"pred = Kreg.predict(X_train)\nk_mse = mean_squared_error(y_train, pred)\nk_rmse = np.sqrt(k_mse)\nk_rmse","82e3f41b":"param_grid = {'n_neighbors': np.arange(1, 12, 2),\n              'weights': ['uniform', 'distance']}\ngrid_search = GridSearchCV(Kreg, param_grid)\ngrid_search.fit(X_train, y_train)\nprint(\"Best score: \" + str(grid_search.best_score_))","2cabfe72":"final_model = grid_search.best_estimator_\nfinal_pred = final_model.predict(X_test)\nfinal_pred = final_pred.tolist()\nfor pred in range(0, len(final_pred)):\n    print(\"Predicition: \" + str(round(final_pred[pred], 2)) + \" Actual: \" + str(y_test[pred]))","bd5356cb":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nax.scatter(y_test, final_pred)\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","42d39ace":"## Variable Identification\nFirst I will explore each variable first, I want to find out the data type of each and how many null entries I have in the dataset.","7798f54a":"## Data Cleaning & Prep\nNext, I will clean up all of the confusing categorical data","c1f13cd7":"## Univariate Analysis\nNow I will visualize some features to try and find some outliers and see if we can find some interesting stats.","7f9885b2":"## Split Current Data\nNow I will split the target feature and from the dataset and sort out the current object features.","24de2e08":"# Laptop Prices Prediction\nThis analysis and model will be used to find correlation between specs and laptop price aswell as being used to predict laptop prices in the future.","d511d8b4":"## Train Models\nNow I will train a few models and compare them","1bf3c7b5":"Now let's plot our predicted prices compared to the actual prices.","d352a4be":"## Bi-variate Analysis\nNow I will compare features against each other to try and find some correlation between them.","2d44bb35":"Wow! Not one missing entry! Don't you love it when this happens."}}