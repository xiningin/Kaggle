{"cell_type":{"0120135b":"code","124fbc60":"code","5089af59":"code","020492ca":"code","0d42c51b":"code","91438fe3":"markdown","a3f77329":"markdown","18c26e3a":"markdown","121c967b":"markdown","2c6c3671":"markdown","25e20722":"markdown"},"source":{"0120135b":"!pip install wandb\nimport wandb","124fbc60":"wandb.login()","5089af59":"import random\n\nfor run in range(5):\n    wandb.init(\n        project=\"basic-intro\",\n        config={\n            \"learning-rate\":0.02,\n            \"architecture\":\"CNN\",\n            \"dataset\":\"MNIST\",\n        }\n    )\n\noffset= random.random()\/5\nfor ii in range(2,10):\n    acc = 1 - 2 ** -ii - random.random() \/ ii - offset\n    loss = 2 ** -ii + random.random() \/ ii + offset\n      # 2\ufe0f\u20e3 Log metrics from your script to W&B\n    wandb.log({\"acc\": acc, \"loss\": loss})\n\nwandb.finish()\n    ","020492ca":"%wandb stacey\/deep-drive\/runs\/1wyssjcx -h 720","0d42c51b":"import random\n\nimport numpy as np\nimport tensorflow as tf\nfrom wandb.keras import WandbCallback\n\n# Simple Keras Model\n\n# Launch 20 experiments, trying different dropout rates\nfor run in range(20):\n  # Start a run, tracking hyperparameters\n  wandb.init(\n      project=\"keras-intro\",\n      # Set entity to specify your username or team name\n      # ex: entity=\"wandb\",\n      config={\n          \"layer_1\": 512,\n          \"activation_1\": \"relu\",\n          \"dropout\": random.uniform(0.01, 0.80),\n          \"layer_2\": 10,\n          \"activation_2\": \"softmax\",\n          \"optimizer\": \"sgd\",\n          \"loss\": \"sparse_categorical_crossentropy\",\n          \"metric\": \"accuracy\",\n          \"epoch\": 6,\n          \"batch_size\": 256\n      })\n  config = wandb.config\n\n  # Get the data\n  mnist = tf.keras.datasets.fashion_mnist\n  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n  x_train, x_test = x_train \/ 255.0, x_test \/ 255.0\n  x_train, y_train = x_train[::5], y_train[::5]  # Subset data for a faster demo\n  x_test, y_test = x_test[::20], y_test[::20]\n  labels = [str(digit) for digit in range(np.max(y_train) + 1)]\n\n  # Build a model\n  model = tf.keras.models.Sequential([\n      tf.keras.layers.Flatten(input_shape=(28, 28)),\n      tf.keras.layers.Dense(config.layer_1, activation=config.activation_1),\n      tf.keras.layers.Dropout(config.dropout),\n      tf.keras.layers.Dense(config.layer_2, activation=config.activation_2)\n      ])\n\n  model.compile(optimizer=config.optimizer,\n                loss=config.loss,\n                metrics=[config.metric]\n                )\n\n  # WandbCallback auto-saves all metrics from model.fit(), plus predictions on validation_data\n  logging_callback = WandbCallback(log_evaluation=True)\n\n  history = model.fit(x=x_train, y=y_train,\n                      epochs=config.epoch,\n                      batch_size=config.batch_size,\n                      validation_data=(x_test, y_test),\n                      callbacks=[logging_callback]\n                      )\n\n  # Mark the run as finished\n  wandb.finish()","91438fe3":"## \ud83d\udc5f Run an experiment\n1\ufe0f\u20e3. **Start a new run** and pass in hyperparameters to track\n\n2\ufe0f\u20e3. **Log metrics** from training or evaluation\n\n3\ufe0f\u20e3. **Visualize results** in the dashboard","a3f77329":"## \ud83e\udd55 Simple Keras DNN\nRun this model to train a simple MNIST classifier, and click on the project page link to see your results stream in live to a W&B project.","18c26e3a":"\n## \ud83d\udd12 Data & Privacy\n\nWe take security very seriously, and our cloud-hosted dashboard uses industry standard best practices for encryption. If you're working with datasets that cannot leave your enterprise cluster, we have [on-prem](https:\/\/docs.wandb.com\/self-hosted) installations available. \n\nIt's also easy to download all your data and export it to other tools\u2014 like custom analysis in a Jupyter notebook. Here's [more on our API](https:\/\/docs.wandb.com\/library\/api).\n\n\n","121c967b":"# interacting in the kernel","2c6c3671":"Discovered weights and biases recently. https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/intro\/Intro_to_Weights_%26_Biases.ipynb#scrollTo=Ja6PVWTT_77U","25e20722":"<img src=\"http:\/\/wandb.me\/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" \/>\n<!--- @wandbcode{intro-colab} -->\n\n# \ud83c\udfc3\u200d\u2640\ufe0f Quickstart\nUse Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.\n\n<img src=\"http:\/\/wandb.me\/mini-diagram\" width=\"650\" alt=\"Weights & Biases\" \/>\n"}}