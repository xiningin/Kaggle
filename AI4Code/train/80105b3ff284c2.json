{"cell_type":{"3284d54f":"code","1b6ac789":"code","702bb174":"code","684722d6":"code","396bcdee":"code","d132eeb3":"code","112d37ea":"code","eb8b98a1":"code","61562cd3":"code","7dcfce2b":"code","7393023e":"code","a9d6ac72":"code","c3130e7a":"code","ff3575f6":"code","ebf66b1f":"code","f43e9ec5":"code","f7e74d27":"code","3834ba09":"code","b6b6aad7":"code","d9a0f47b":"code","ecafb5a6":"code","e179a57e":"code","520902a2":"code","bc72a73c":"code","d9a14f53":"code","25506cc7":"code","ac85dc53":"code","d4f60488":"code","4f432a06":"code","2223bc4c":"code","95665d5a":"code","c090181e":"code","cd001020":"code","7d9906a9":"code","cdcd7a99":"code","72832aab":"code","7643f478":"code","66895432":"code","6bb072d7":"code","f599d6b9":"code","3f7152a0":"code","b8e141d9":"code","2e6ac5b8":"code","474a1c30":"code","cec06bc4":"code","00230343":"code","db061dd9":"code","e4dce1e6":"code","e3e26c65":"code","be842606":"code","e0d34e24":"code","aa325dcc":"code","32fa93c6":"code","2b21f2ae":"code","783f101f":"code","ddcde0f7":"code","4e04e2a2":"code","dedfef7d":"code","0eaa88d8":"code","b71259d4":"markdown","a6f035dd":"markdown","669247fb":"markdown","7f970375":"markdown","5990e31c":"markdown","8219c813":"markdown","418ed57f":"markdown","e23c3bf0":"markdown","30c70e3b":"markdown","8b85d1af":"markdown"},"source":{"3284d54f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b6ac789":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", context=\"talk\")\n\nimport re\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, confusion_matrix, classification_report, cohen_kappa_score, recall_score, precision_score\nfrom sklearn import ensemble\nfrom sklearn.inspection import permutation_importance\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","702bb174":"testing = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = testing.copy()\n\ntarget = 'Survived'\n\ndata = pd.concat([train, test], axis = 0)\ndata.info()\ndata.head(5)","684722d6":"plt.subplots(figsize=(10, 4))\nplt.pie(data['Survived'].value_counts()\n        ,labels = data['Survived'].value_counts().index\n        ,autopct='%1.1f%%'\n        ,shadow=True\n        ,explode = (0.05, 0.0)\n       )\nplt.title('Survived')\nplt.show()","396bcdee":"data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])","d132eeb3":"data[data['Fare'].isna()]","112d37ea":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Fare']","eb8b98a1":"data['Fare'] = data['Fare'].fillna(data.groupby(['Pclass'])['Fare'].transform('median'))","61562cd3":"data.isna().sum()","7dcfce2b":"data['Family_size'] =  data[\"Parch\"] + data[\"SibSp\"] + 1\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Family_size',y = 'Survived')\nplt.show()","7393023e":"# data.loc[ data['Family_size'] == 1, 'Family_size_group'] = 0\ndata.loc[(data['Family_size'] > 1) & (data['Family_size'] <= 4), 'small_family_size'] = 1\ndata.loc[(data['Family_size'] > 4) | (data['Family_size'] == 1), 'small_family_size'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'small_family_size',y = 'Survived')\nplt.show()","a9d6ac72":"data.loc[data['Family_size'] == 1, 'Alone'] = 1\ndata.loc[data['Family_size'] > 1, 'Alone'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Alone',y = 'Survived')\nplt.show()","c3130e7a":"data['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\ndata['Title'].unique()","ff3575f6":"data['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Title', y='Survived')\nplt.show()","ebf66b1f":"data['Title'].value_counts(normalize = True).round(3)","f43e9ec5":"data['Age'].isna().sum()","f7e74d27":"data[data['Age'] < 1]","3834ba09":"data.loc[data['Age'] < 1, 'Age'] = None\ndata['Age'].isna().sum()","b6b6aad7":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']","d9a0f47b":"# np.random.seed(42)\n# data['Age'][data['Age'].isna()] = np.random.randint(high = data['Age'].mean() + data['Age'].std()\n#                                                     ,low = data['Age'].mean() - data['Age'].std()\n#                                                     ,size = data['Age'].isna().sum())\n\ndata['Age'] = data['Age'].fillna(data.groupby(['Pclass', 'Title'])['Age'].transform('median'))\n\ndata['Age'].isna().sum()","ecafb5a6":"data.groupby('Title')['Age'].median()","e179a57e":"plt.subplots(figsize = (10, 5))\nsns.distplot(data['Age'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 15)\nsns.distplot(data['Age'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 15)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()","520902a2":"data.info()","bc72a73c":"data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']","d9a14f53":"def age_grouping(age):\n    if (age < 4):\n        return 'Infants'\n    elif (age >= 4) & (age < 6):\n        return 'Preschool'\n    elif (age >= 6) & (age < 13):\n        return 'Children'\n    elif (age >= 13) & (age < 19):\n        return 'Adolescents'\n    elif (age >= 19) & (age < 45):\n        return 'Adults'\n    elif (age >= 45) & (age < 60):\n        return 'Middle age'\n    else:\n        return 'Seniors'  \n    \ndata['age_group'] = np.vectorize(age_grouping)(data['Age'])\n    \nplt.subplots(figsize=(18, 5))\nsns.barplot(data = data, x = 'age_group', y = 'Survived')\nplt.show()","25506cc7":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Parch', y='Survived')\nplt.show()","ac85dc53":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='SibSp', y='Survived')\nplt.show()","d4f60488":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Pclass', y='Survived')\nplt.show()","4f432a06":"plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Embarked', y='Survived')\nplt.show()","2223bc4c":"data[['Pclass', 'Embarked', 'Survived']].groupby(['Pclass', 'Embarked']).mean().round(2)","95665d5a":"data['Cabin'].unique()","c090181e":"data['Cabin_group'] = data['Cabin'].str[:1]\ndata.loc[data['Cabin'].isna(), 'Cabin_group'] = 'unkown'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()","cd001020":"print('Pclass: ', data[data['Cabin_group'] == 'T']['Pclass'].values)\ndata.loc[data['Cabin'] == 'T', 'Cabin_group'] = 'A'","7d9906a9":"data[['Cabin_group', 'Pclass', 'Survived']].groupby(['Cabin_group', 'Pclass']).mean().round(2)","cdcd7a99":"data.loc[data['Cabin_group'].isin(['A', 'B', 'C']), 'Cabin_group'] = 'ABC'\ndata.loc[data['Cabin_group'].isin(['D', 'E']), 'Cabin_group'] = 'DE'\ndata.loc[data['Cabin_group'].isin(['F', 'G']), 'Cabin_group'] = 'FG'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()","72832aab":"plt.subplots(figsize = (10, 7))\nsns.distplot(data['Fare'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 8)\nsns.distplot(data['Fare'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 8)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()","7643f478":"data.head()","66895432":"data['Cabin_group'].unique()","6bb072d7":"data['Sex_int'] = data['Sex'].replace({'male': 1, 'female': 0})\ndata['Embarked_int'] = data['Embarked'].replace({'S': 0, 'C': 1, 'Q':2})\ndata['Title_int'] = data['Title'].replace({'Mr': 0, 'Mrs': 1, 'Miss':2, 'Master':3, 'Special':4})\ndata['age_group_int'] = data['age_group'].replace({'Adults': 0, 'Middle age': 1, 'Infants':2, 'Adolescents':3, 'Preschool':4, 'Children':5, 'Seniors':6})\ndata['Cabin_group_int'] = data['Cabin_group'].replace({'unkown': 0, 'ABC': 1, 'DE':2, 'FG':3})","f599d6b9":"corrMatrix = data.corr()\n\nplt.subplots(figsize=(22, 10))\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","3f7152a0":"plt.subplots(figsize=(12, 4))\ncorrMatrix['Survived'].drop(['Survived']).sort_values().plot(kind = 'bar')\nplt.show()","b8e141d9":"data = data.loc[:,~data.columns.str.endswith('_int')]","2e6ac5b8":"data.info()\ndata.head()","474a1c30":"# Preparing features for analysis\ndummy_features = ['Sex'\n                  , 'Pclass'\n                  , 'Embarked'\n                  , 'Cabin_group'\n                  , 'Title'\n                  , 'age_group'\n                 ]\n\nfor col in dummy_features:\n    data[col] = data[col].astype(object)\n    \ndrop_features = ['PassengerId', 'Ticket', 'Name', 'Cabin'\n                 ,'small_family_size'\n#                  ,'Family_size'\n                 ,'Alone'\n                 ,'SibSp'\n                 ,'Parch'\n#                  ,'Embarked'\n#                  ,'Cabin_group'\n#                  ,'Title'\n                 ,'Age'\n#                  ,'age_group'\n                ]\n    \ndata = pd.concat([data, pd.get_dummies(data[dummy_features], drop_first = True)], axis = 1, sort = False)\ndata.drop(columns = data[dummy_features], inplace = True)\ndata.drop(columns = data[drop_features], inplace = True)\n\ndata.tail()","cec06bc4":"test = data[data['Survived'].isnull()].drop(['Survived'], axis = 1)\ntrain = data[data['Survived'].notnull()]\n\ntrain.info()\nprint('-'*70)\ntest.info()","00230343":"# Drop Nan just to be safe\ntrain.dropna(inplace = True)\ntest.dropna(inplace = True)","db061dd9":"# Separating target column from other features\ny = train['Survived']\nx = train.drop(columns = target)\n\n# Train and Test dataset split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42\n                                                    , stratify = y\n                                                   )","e4dce1e6":"# random forest model hyper-tuned\nRF = ensemble.RandomForestClassifier()\nparams = {\n          'n_estimators':[n for n in range(100, 250, 50)] # default 100 \n          ,'max_depth':[n for n in range(3, 8)] # default None \n#           ,'criterion': ['gini', 'entropy'] # default 'gini'\n          ,'min_samples_leaf': [n for n in range(3, 6, 1)] # default 1\n          ,'max_features' : [None] # default 'sqrt'\n          ,'random_state' : [42]\n          }\n\nRF_model = GridSearchCV(RF, param_grid = params, cv = 5, n_jobs = -1).fit(x_train, y_train)\nprint(\"Best Hyper Parameters:\",RF_model.best_params_)\n\n# Area under the curve probability score\nRF_probs = RF_model.predict_proba(x_test)\nRF_probs = RF_probs[:, 1]\nRF_auc = roc_auc_score(y_test, RF_probs)\nprint('AUC: %.3f' % RF_auc)\n\nRF_predictions = RF_model.predict(x_test).astype(int)\nRF_accuracy = accuracy_score(y_test, RF_predictions)\nprint(\"RF accuracy: %.3f\" % RF_accuracy)\nprint(\"RF Recall: \" + '%.3f' % recall_score(y_test, RF_predictions)) # The recall is intuitively the ability of the classifier to find all the positive samples.\nprint(\"RF Precission: \" + '%.3f' % precision_score(y_test, RF_predictions)) # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\nprint(\"RF cohen_kappa_score: %.3f\" % cohen_kappa_score(y_test, RF_predictions)) # Scores above .8 are generally considered good agreement\n\n# AUC plot\nplt.figure(figsize = (8, 6))\nRF_fpr, RF_tpr, RF_thresholds = roc_curve(y_test, RF_probs)\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.plot(RF_fpr, RF_tpr, color = 'tab:green')\nplt.show()","e3e26c65":"cm = confusion_matrix(y_test, RF_predictions)\nplot_confusion_matrix(cm)\nplt.title('RF')\nplt.show()","be842606":"plt.figure(figsize = [6, 6])\npd.Series(RF_model.best_estimator_.feature_importances_, index = x.columns).nlargest(10).plot(kind = 'barh')\nplt.show()","e0d34e24":"perm_importance = permutation_importance(RF_model, x_test, y_test)\nsorted_idx = perm_importance.importances_mean.argsort()\n\nplt.figure(figsize = [8, 8])\nplt.barh(x.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\nplt.xlabel(\"Permutation Importance\")\nplt.show()","aa325dcc":"# from sklearn.feature_selection import SelectFromModel\n# selector = SelectFromModel(RF_model.best_estimator_, threshold = 0.05, prefit = True)\n# feature_idx = selector.get_support()\n# feature_name = x.columns[feature_idx]\n# feature_name","32fa93c6":"data['churn_proba'] = RF_model.best_estimator_.predict_proba(data[x.columns])[:,1]","2b21f2ae":"import shap\nshap.initjs()\n\nexplainer = shap.TreeExplainer(RF_model.best_estimator_)\nshap_values = explainer.shap_values(data[x.columns])\n\nshap.summary_plot(shap_values[1], data[x.columns], plot_type = \"bar\")","783f101f":"shap.summary_plot(shap_values[1], data[x.columns])","ddcde0f7":"shap.dependence_plot(\"Fare\", shap_values[1], data[x.columns])","4e04e2a2":"row = 1\n\nshap.force_plot(explainer.expected_value[1], shap_values[1][:1000], data[x.columns].iloc[:1000], matplotlib = False)\n\nclass ShapObject:\n    def __init__(self, base_values, data, values, feature_names):\n        self.base_values = base_values # Single value\n        self.data = data # Raw feature values for 1 row of data\n        self.values = values # SHAP values for the same row of data\n        self.feature_names = feature_names # Column names\n        \nshap_object = ShapObject(base_values = explainer.expected_value[1],\n                         values = shap_values[1][row,:],\n                         feature_names = data[x.columns].columns,\n                         data = data[x.columns].iloc[row,:])\n\nshap.waterfall_plot(shap_object)","dedfef7d":"shap.force_plot(explainer.expected_value[1], shap_values[1][:500], data[x.columns].iloc[:500], matplotlib = False)","0eaa88d8":"predict_RF = RF_model.predict(test).astype(int)\nsubmit_RF = pd.DataFrame({'PassengerId': testing['PassengerId'],\n                          'Survived': predict_RF})\n\n#creating submission file\nfilename_RF = 'Titanic Prediction RF.csv'\nsubmit_RF.to_csv(filename_RF,index=False)\nprint('Saved file: ' + filename_RF)","b71259d4":" # Model investigation","a6f035dd":"# Prep before model","669247fb":"# Feature Importance","7f970375":"# Data cleansing","5990e31c":"# Libraries ","8219c813":"# Feature engineering","418ed57f":"# EDA","e23c3bf0":"# Export data","30c70e3b":"# Data input","8b85d1af":"# Modelling"}}