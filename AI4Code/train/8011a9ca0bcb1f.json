{"cell_type":{"a13e2ec5":"code","4bd9af5c":"code","17353e8b":"code","6a953834":"code","c050ae57":"code","e6cdde53":"code","3a78effa":"code","fb11f517":"code","2c527152":"code","e7b81fb3":"code","e6fa35ac":"markdown","f32fbc66":"markdown","af34fffe":"markdown","871e4004":"markdown","aaf1d9ca":"markdown"},"source":{"a13e2ec5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4bd9af5c":"#importing all the required libraries\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB  # Gaussian naive Bayes classifier\nimport scikitplot as skplt","17353e8b":"data= pd.read_csv('..\/input\/iris\/Iris.csv')\nprint(data.shape)\ndata.head()","6a953834":"#checking for missing values using heat map\nsns.heatmap(data.isnull(),linecolor=\"white\");","c050ae57":"#correlation between data\ndata.corr()\n","e6cdde53":"#using heatmap to show data correlation along with tabular corelation\nsns.heatmap(data.corr(),annot=True,linecolor='grey');","3a78effa":"#splitting the data and storing it\ntrainSet, testSet = train_test_split(data, test_size = 0.33)#test set is chosen to be 1\/3rd of dataset","fb11f517":"trainData = pd.DataFrame(trainSet[['SepalLengthCm', 'PetalLengthCm', 'PetalWidthCm']]).values\ntrainTarget = pd.DataFrame(trainSet[['Species']]).values.ravel()\ntestData = pd.DataFrame(testSet[['SepalLengthCm', 'PetalLengthCm', 'PetalWidthCm']]).values\ntestTarget = pd.DataFrame(testSet[['Species']]).values.ravel()","2c527152":"classifier = GaussianNB()\nclassifier.fit(trainData, trainTarget)\npredicted_value = classifier.predict(testData)\n\npredictions = dict()\naccuracy = accuracy_score(testTarget,predicted_value) \npredictions['Naive-Bayes']=accuracy*100\nprint(\"The accuracy of the model is {}\".format(accuracy))\nconfusionmatrix = confusion_matrix(testTarget, predicted_value)\ncm=pd.DataFrame(confusion_matrix(testTarget, predicted_value))\nprint(\"The confusion matrix of the model is \\n{}\".format(cm))","e7b81fb3":"skplt.metrics.plot_confusion_matrix(testTarget, predicted_value, normalize=True,cmap=plt.cm.Greys)\nplt.show()","e6fa35ac":"Using **Naive Bayes** to train the model\n","f32fbc66":"Loading data in data frames\n\nThis is one of the basic methods to do so","af34fffe":"As the heatmap is even and without any discrepancies, and hence, no missing values are found","871e4004":"All the required libraries  are imported. Moving on to Importing the Data\n","aaf1d9ca":"Train and Test data Seperation"}}