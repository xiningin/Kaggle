{"cell_type":{"02000ceb":"code","a9e981c2":"code","d4c61d0c":"code","93ceb0fc":"code","8495983e":"code","ec47608f":"code","cfe9beae":"code","082a204f":"code","1e397197":"code","6b9361c6":"code","9ca44fa6":"code","b66a059d":"code","08ed82b8":"code","ea3f8b52":"code","90fe73c9":"code","6f93ead5":"code","807a26ac":"code","4b18f1d7":"code","8abc067d":"code","2c0b1618":"code","e187626b":"code","c1dbec7b":"code","e3c24fc1":"code","9bb4a784":"code","55ba96b2":"code","2c238786":"code","f7c95aa1":"code","758d3031":"code","97f24772":"code","47cb33b8":"code","275dde58":"code","5172af3b":"code","4075af32":"code","56c4d665":"code","993dd65f":"code","b327b132":"code","60f775b4":"code","cac3a9e7":"code","818024da":"code","84917b51":"code","8c655a7f":"code","603fd865":"code","3ed52278":"code","38ee439f":"code","d66418fe":"code","af884fcf":"code","b949466a":"code","8d2b6cf0":"code","b7ec9967":"code","683ad0b0":"code","189a293b":"code","4da537fb":"code","733b5b35":"code","493b8858":"code","7ae599e6":"markdown","7ecf3939":"markdown","b658c54d":"markdown","166cc810":"markdown","a8b66884":"markdown","a4b9d755":"markdown","6264da78":"markdown","2d9fe416":"markdown","348f60b9":"markdown","d0a4d6fe":"markdown","0d02d8ee":"markdown","87dd79f0":"markdown","8a258836":"markdown","4601abbe":"markdown","df29a71f":"markdown","ca59bff1":"markdown","0c6db16e":"markdown","ab9b0e46":"markdown","422bf30d":"markdown"},"source":{"02000ceb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/land classification challenge\/socialcops_challenge\"))\n\n# Any results you write to the current directory are saved as output.","a9e981c2":"dataset = pd.read_csv('..\/input\/land classification challenge\/socialcops_challenge\/land_train.csv')\ntest = pd.read_csv('..\/input\/land classification challenge\/socialcops_challenge\/land_test.csv')","d4c61d0c":"print(dataset.columns)\nprint(test.columns)","93ceb0fc":"dataset.isna().sum()","8495983e":"test.isna().sum()","ec47608f":"dataset['target'].hist()","cfe9beae":"print(dataset[['target' , 'X1']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X1']].groupby(['target']).mean())\nsns.catplot(x='target', y='X1',  kind='bar', data=dataset)","082a204f":"print(dataset[['target' , 'X2']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X2']].groupby(['target']).mean())\nsns.catplot(x='target', y='X2',  kind='bar', data=dataset)","1e397197":"print(dataset[['target' , 'X3']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X3']].groupby(['target']).mean())\nsns.catplot(x='target', y='X3',  kind='bar', data=dataset)","6b9361c6":"print(dataset[['target' , 'X4']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X4']].groupby(['target']).mean())\nsns.catplot(x='target', y='X4',  kind='bar', data=dataset)","9ca44fa6":"print(dataset[['target' , 'X5']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X5']].groupby(['target']).mean())\nsns.catplot(x='target', y='X5',  kind='bar', data=dataset)","b66a059d":"print(dataset[['target' , 'X6']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'X6']].groupby(['target']).mean())\nsns.catplot(x='target', y='X6',  kind='bar', data=dataset)","08ed82b8":"print(dataset[['target' , 'I1']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I1']].groupby(['target']).mean())\nsns.catplot(x='target', y='I1',  kind='bar', data=dataset)","ea3f8b52":"print(dataset[['target' , 'I2']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I2']].groupby(['target']).mean())\nsns.catplot(x='target', y='I2',  kind='bar', data=dataset)","90fe73c9":"print(dataset[['target' , 'I3']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I3']].groupby(['target']).mean())\nsns.catplot(x='target', y='I3',  kind='bar', data=dataset)","6f93ead5":"print(dataset[['target' , 'I4']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I4']].groupby(['target']).mean())\nsns.catplot(x='target', y='I4',  kind='bar', data=dataset)","807a26ac":"print(dataset[['target' , 'I5']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I5']].groupby(['target']).mean())\nsns.catplot(x='target', y='I5',  kind='bar', data=dataset)","4b18f1d7":"print(dataset[['target' , 'I6']].groupby(['target']).mean())\nplt.plot(dataset[['target' , 'I6']].groupby(['target']).mean())\nsns.catplot(x='target', y='I6',  kind='bar', data=dataset)","8abc067d":"sns.heatmap(dataset.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","2c0b1618":"print(dataset.min())\nprint(dataset.max())","e187626b":"dataset.iloc[: , 6:-1] = dataset.iloc[: , 6:-1] + 5\ntest.iloc[: , 6:-1] = test.iloc[: , 6:] + 5","c1dbec7b":"from sklearn.utils import shuffle\ndataset = shuffle(dataset)\ndataset = shuffle(dataset).reset_index()\ndataset.drop('index' , axis = 1 , inplace = True)","e3c24fc1":"dataset","9bb4a784":"print(dataset.min())\nprint(dataset.max())","55ba96b2":"y_train = dataset.iloc[: , -1:]\ndataset.drop('target' , axis =1 , inplace = True)","2c238786":"from imblearn.over_sampling import SMOTE","f7c95aa1":"sm = SMOTE(random_state= 2)\nx_train , y = sm.fit_sample (dataset , y_train)","758d3031":"pd.DataFrame(y).hist()","97f24772":"x_train = pd.DataFrame(x_train , columns= ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6'])","47cb33b8":"from sklearn.decomposition import PCA\npca_x = PCA()\nx_train.iloc[: ,:6] = pca_x.fit_transform(x_train.iloc[: ,:6])\ntest.iloc[: , :6] = pca_x.transform(test.iloc[: , :6])","275dde58":"pca_x.explained_variance_ratio_","5172af3b":"pca_i = PCA()\nx_train.iloc[: ,6:] = pca_i.fit_transform(x_train.iloc[: ,6:])\ntest.iloc[: , 6:] = pca_x.transform(test.iloc[: , 6:])","4075af32":"pca_i.explained_variance_ratio_","56c4d665":"x_train.columns","993dd65f":"x_train.drop([ 'I5' , 'I6'] , axis =1 ,inplace =True)\ntest.drop(['I5' , 'I6'] , axis =1 ,inplace =True)","b327b132":"x_train","60f775b4":"from sklearn.preprocessing import MinMaxScaler\n","cac3a9e7":"normalizer_x = MinMaxScaler()  #for normalizing x1-x6\nnormalizer_i = MinMaxScaler()  #for normalizing i1-i6","818024da":"test.shape","84917b51":"x_train.iloc[: , :6] = normalizer_x.fit_transform(x_train.iloc[: , :6])\nx_train.iloc[: , 4:] = normalizer_i.fit_transform(x_train.iloc[: , 4:])\n\ntest.iloc[: , :6] = normalizer_x.fit_transform(test.iloc[: , :6])\ntest.iloc[: , 4:] = normalizer_i.fit_transform(test.iloc[: , 4:])\n","8c655a7f":"print(x_train.min())\nprint(x_train.max())","603fd865":"y = y.reshape((len(y) , 1))","3ed52278":"#now as our dependant variable is categorical. therefore preprocessing it\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()","38ee439f":"y = ohe.fit_transform(y)","d66418fe":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'softmax'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(x_train ,y, batch_size = 100, epochs = 25 , validation_split = 0.1)\n","af884fcf":"# storing the results\ny_pred_1 = np.argmax( classifier.predict(test) , axis = 1)","b949466a":"y_pred_1 = y_pred_1 + 1","8d2b6cf0":"y_pred_1 = pd.DataFrame(y_pred_1)","b7ec9967":"y_pred_1.hist()","683ad0b0":"final = pd.read_csv('..\/input\/land classification challenge\/socialcops_challenge\/land_test.csv')","189a293b":"final['target'] = np.array(y_pred_1)","4da537fb":"final","733b5b35":"final['target'].value_counts()","493b8858":"final.to_csv('result_2.csv' , index=False)","7ae599e6":"***NOW MAKING PREDICTIONS .................................................................***","7ecf3939":"HENCE WE HAVE REMOVED THE IMBALANCED DATA PROBLEM","b658c54d":"As we can see with the above histogram, the data is imbalanced. Therefore training on this data may lead to results that are biased towards the categories that have higher occurence in training data","166cc810":"**NOW NORMALIZING THE DATA**","a8b66884":"HENCE WITH A SIMPLE 3 LAYER NN WE ARE ABLE ACHIEVE ABOVE 85% VALIDATION ACCURACY. WHICH IS DESCENT !\nHENCE OUR MODEL IS ABLE TO GENERALIZE.","a4b9d755":"GREAT BOTH THE TRAINING AND THE TESTING DATA ARE FREE FREOM MISSING VALUES :)","6264da78":"**First of all checking the dataset for missing values**","2d9fe416":"**Importing the test data and the train data**","348f60b9":"identifying the training features and the dependent variable (target)","d0a4d6fe":"**DEALING WITH THE IMBALANCED DATA USING OVER SAMPLING**","0d02d8ee":"HENCE WE CAN DROP X5, X6 ,I5,I6 BASED ON THEIR LOW EIGEN VALUE ","87dd79f0":"**Now analyzing the significanve level of each feature in predicting the target variable**","8a258836":"as we can notice X1 - X6 features are all positive integers spanning from 0 - 10000 and I1-I6 \n\nso to simplify the training process and making our model better,lets transform the I1-I6 features to positive values by adding a bias","4601abbe":"WE CAN OBSERVE THAT TARGET VARIABLE IS HIGHLY CORRELATED WITH X1,X2,X3,X5,X6,I2 FEATURES","df29a71f":"AS THE DATASET SET PROVIDED ID NOT SHUFFLED ON THE DEPENDANT VARIABLE. HENCE SHUFFLIING IT.","ca59bff1":"**ANALYZING THE X1 - X6 FEATURES AGAINST THE TARGET VARIABLE**","0c6db16e":"**NOW THE TRAINING PART BEGINS**","ab9b0e46":"FROM THE ABOVE PLOTS WE HAVE OBSERVED THAT, CATEGORY 3 AND 4, GENERALLY HAVE THE HIGHER VALUE FOR X1-X6 FEATURES\n\nAND THE MAGNITUDE OF FEATURE VALUES I1-U6 IS GREATER FOR TARGET VALUE 1 AND 2","422bf30d":"**AS WE HAVE 4 POSSIBLE VALUES FOR THE 'TARGET' VARIABLE, HENCE CHECKING WHETHER THE DATA CORRESPONDING TO THESE 4 CATEGORIES IS BALANCED OR NOT **"}}