{"cell_type":{"4691c0f3":"code","aeb0680b":"code","80301a5c":"code","c5f68b67":"code","93fa8ed8":"code","f21f0ab3":"code","f82c75df":"code","09e63ab1":"code","b7973b10":"code","7927851f":"code","44718744":"code","e0cbf492":"markdown","f90dd829":"markdown","6e54a441":"markdown"},"source":{"4691c0f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aeb0680b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","80301a5c":"df = pd.read_csv(\"\/kaggle\/input\/real-estate-dataset\/data.csv\")\ndf = df.fillna(0)\ndf.head()","c5f68b67":"#bins=len(np.unique(df_train[[col]].T))\/\/2\n\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(22,18))\nfig.subplots_adjust(hspace=0.25)\n\nfor ax, col in zip(axes.flatten(), df.columns):\n    ax.hist(df[[col]].values, bins=100)\n    ax.set(title=str(col).lower() + \" distribution\")","93fa8ed8":"s_fig, s_ax = plt.subplots(figsize=(16, 16))\n\ncols = df.columns\nsns.heatmap(df[cols].corr(), ax=s_ax, cmap='RdBu_r', annot=True, center=0.0)","f21f0ab3":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(df.drop([\"CRIM\"], axis=1))\ny_scaled = scaler.fit_transform(df[[\"CRIM\"]])","f82c75df":"clf_linear = linear_model.LinearRegression()\npred_linear = cross_val_predict(clf_linear, X_scaled, y_scaled, cv=5)\n\nscores_linear = cross_val_score(clf_linear, X_scaled, y_scaled, cv=5, scoring=\"neg_mean_squared_error\")\nmse_linear = mean_squared_error(y_scaled, pred_linear)\nprint (f\"linear cross_val_scores: {scores_linear}\")\nprint (f\"linear mse_score:        {mse_linear:.10}\")","09e63ab1":"clf_ridge = linear_model.Ridge(alpha = 100)\npred_ridge = cross_val_predict(clf_ridge, X_scaled, y_scaled, cv=5)\n\nscores_ridge = cross_val_score(clf_ridge, X_scaled, y_scaled, cv=5, scoring=\"neg_mean_squared_error\")\nmse_ridge = mean_squared_error(y_scaled, pred_ridge)\nprint (f\"ridge cross_val_scores: {scores_ridge}\")\nprint (f\"ridge mse_score:        {mse_ridge:.10}\")","b7973b10":"clf_sgd = linear_model.SGDRegressor()\npred_sgd = cross_val_predict(clf_sgd, X_scaled, y_scaled, cv=5)\n\nscores_sgd = cross_val_score(clf_ridge, X_scaled, y_scaled, cv=5, scoring=\"neg_mean_squared_error\")\nmse_sgd = mean_squared_error(y_scaled, pred_sgd)\nprint (f\"sgd cross_val_scores: {scores_sgd}\")\nprint (f\"sgd mse_score:        {mse_sgd:.10}\")","7927851f":"df_output = pd.DataFrame()\ndf_output[\"CRIM\"] = df[\"CRIM\"]\ndf_output[\"pred\"] = pred_ridge\ndf_output[\"abs_err\"] = abs(df_output[\"CRIM\"] - df_output[\"pred\"])","44718744":"df_output[[\"CRIM\", \"abs_err\"]].to_csv(\"submission_20201114_v2.csv\")","e0cbf492":"# Submission","f90dd829":"# Train linear models","6e54a441":"# **EDA**"}}