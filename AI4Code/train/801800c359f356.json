{"cell_type":{"da03550c":"code","396b5299":"code","803a786a":"code","8d9488d1":"code","ae775887":"code","83b6bb2d":"code","ec8e1623":"code","5ccdfca4":"code","2a9b73cc":"code","3c6353e2":"code","476dedfe":"code","943c2440":"code","9c9b2f59":"code","659d6d47":"code","b11bc3ec":"code","5f867e7c":"code","0e60c0c5":"code","0d694884":"code","a12a6404":"code","806d003d":"code","346d4c22":"code","034a21f7":"code","7a35af5a":"code","9658ba3f":"code","21feaa98":"code","74e2f62d":"code","0c41eb0f":"code","2ab9af9c":"code","f9fedd64":"code","ab0cf441":"markdown","2da520a4":"markdown","badf7959":"markdown","552f75c6":"markdown","198ebefb":"markdown","ad0bbed9":"markdown","ab9ad88b":"markdown","5e3e7616":"markdown","2e606183":"markdown","c60f2b15":"markdown","84fa8870":"markdown","370768b6":"markdown","6b5b4666":"markdown","08fe9af6":"markdown","27bbf5c6":"markdown","aaa846a9":"markdown","96cbf4f7":"markdown","7e81b684":"markdown","4fbafbc2":"markdown","54cf03e4":"markdown","60e98967":"markdown","6c95789b":"markdown","236bbb62":"markdown","2afa2e9c":"markdown","a817d450":"markdown","92c5585a":"markdown","d4db5bd1":"markdown","3d19cc58":"markdown","910922cd":"markdown","4df99bcd":"markdown","f7b8a9de":"markdown","49d779ea":"markdown","33c17c35":"markdown","6936b6f5":"markdown","b3631bd2":"markdown","49adfd70":"markdown","0a2a2330":"markdown","d495866f":"markdown","9ffd3d72":"markdown","ed2e3bea":"markdown","d8f29717":"markdown","15bd86e1":"markdown"},"source":{"da03550c":"import numpy as np\nimport os\nimport pandas as pd\nimport sys\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport seaborn as sns\nsns.set(color_codes=True)\nfrom wordcloud import WordCloud,STOPWORDS\nimport warnings\nwarnings.filterwarnings('ignore')\n# plotly\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom IPython.display import Image\n","396b5299":"answers = pd.read_csv('..\/input\/data-science-for-good-careervillage\/answers.csv')\ncomments = pd.read_csv('..\/input\/data-science-for-good-careervillage\/comments.csv')\nemails = pd.read_csv(\"..\/input\/data-science-for-good-careervillage\/emails.csv\")\ngroup_memberships = pd.read_csv('..\/input\/data-science-for-good-careervillage\/group_memberships.csv')\ngroups = pd.read_csv('..\/input\/data-science-for-good-careervillage\/groups.csv')\nmatches = pd.read_csv('..\/input\/data-science-for-good-careervillage\/matches.csv')\nprofessionals = pd.read_csv(\"..\/input\/data-science-for-good-careervillage\/professionals.csv\")\nquestions = pd.read_csv('..\/input\/data-science-for-good-careervillage\/questions.csv')\nschool_memberships = pd.read_csv('..\/input\/data-science-for-good-careervillage\/school_memberships.csv')\nstudents = pd.read_csv('..\/input\/data-science-for-good-careervillage\/students.csv')\ntag_questions = pd.read_csv(\"..\/input\/data-science-for-good-careervillage\/tag_questions.csv\")\ntag_users = pd.read_csv('..\/input\/data-science-for-good-careervillage\/tag_users.csv')\ntags = pd.read_csv('..\/input\/data-science-for-good-careervillage\/tags.csv')","803a786a":"df_list = [answers,comments,emails,group_memberships,groups,matches,professionals,questions,school_memberships,students,tag_questions,tag_users,tags]","8d9488d1":"Image(filename=\"..\/input\/cv-graph-schema2\/graph_schema_kaggle.png\")","ae775887":"Image(filename=\"..\/input\/temp-pics\/new_schema.png\")","83b6bb2d":"Image(filename=\"..\/input\/temp-pics\/question_tags.png\")","ec8e1623":"print(os.listdir(\"..\/input\/temp-pics\"))","5ccdfca4":"Image(filename=\"..\/input\/temp-pics\/dab_q_tag.png\")","2a9b73cc":"Image(filename=\"..\/input\/temp-pics\/q_519_tag.png\")","3c6353e2":"# Merge Question Title and Body\nquestions['questions_full_text'] = questions['questions_title'] +'\\r\\n\\r\\n'+ questions['questions_body']","476dedfe":"import spacy\nnlp = spacy.load('en')\nnlp.remove_pipe('parser')\nnlp.remove_pipe('ner')\n\n# Spacy Tokenfilter for part-of-speech tagging\ntoken_pos = ['NOUN', 'VERB', 'PROPN', 'ADJ', 'INTJ', 'X']\n\ndef nlp_preprocessing(data):\n    \"\"\" Use NLP to transform the text corpus to cleaned sentences and word tokens\n\n    \"\"\"    \n    def token_filter(token):\n        \"\"\" Keep tokens who are alphapetic, in the pos (part-of-speech) list and not in stop list\n\n        \"\"\"    \n        return not token.is_stop and token.is_alpha and token.pos_ in token_pos\n    \n    processed_tokens = []\n    data_pipe = nlp.pipe(data)\n    for doc in data_pipe:\n        filtered_tokens = [token.lemma_.lower() for token in doc if token_filter(token)]\n        processed_tokens.append(set(filtered_tokens))\n    return processed_tokens\n\n# Get NLP Tokens\nquestions['nlp_tokens'] = nlp_preprocessing(questions['questions_full_text'])","943c2440":"questions['nlp_tokens'].head()","9c9b2f59":"all_q_tokens = list(questions['nlp_tokens'])","659d6d47":"type(all_q_tokens)","b11bc3ec":"all_unique_q_tokens = set([token for token_list in all_q_tokens for token in token_list])\nflat_q_tokens = [token for token_list in all_q_tokens for token in token_list]","5f867e7c":"len(all_q_tokens)","0e60c0c5":"all_q_tokens[:5]","0d694884":"len(all_unique_q_tokens)","a12a6404":"list(all_unique_q_tokens)[:5]","806d003d":"len(flat_q_tokens)","346d4c22":"flat_q_tokens[:5]","034a21f7":"from collections import Counter,OrderedDict","7a35af5a":"tokens_sum = Counter(flat_q_tokens)\nsorted_ord_tokens = sorted(tokens_sum.items(), key=lambda kv: kv[1],reverse=True)","9658ba3f":"sorted_ord_tokens","21feaa98":"import spacy\nnlp = spacy.load('en')\nnlp.remove_pipe('parser')\nnlp.remove_pipe('ner')\n\n# Spacy Tokenfilter for part-of-speech tagging\ntoken_pos = ['NOUN', 'VERB', 'PROPN', 'ADJ', 'INTJ', 'X']\n\ndef nlp_preprocessing(data):\n    \"\"\" Use NLP to transform the text corpus to cleaned sentences and word tokens\n\n    \"\"\"    \n    def token_filter(token):\n        \"\"\" Keep tokens who are alphapetic, in the pos (part-of-speech) list and not in stop list\n\n        \"\"\"    \n        return not token.is_stop and token.is_alpha and token.pos_ in token_pos\n    \n    processed_tokens = []\n    data_pipe = nlp.pipe(data)\n    for doc in data_pipe:\n        filtered_tokens = [token.lemma_.lower() for token in doc if token_filter(token)]\n        temp_string = ','\n        processed_tokens.append(temp_string.join(list(set(filtered_tokens))))\n    return processed_tokens\n\n# Get NLP Tokens\nquestions['nlp_tokens'] = nlp_preprocessing(questions['questions_full_text'])","74e2f62d":"questions['nlp_tokens'].head()","0c41eb0f":"q_exp = questions[['questions_id','nlp_tokens']]","2ab9af9c":"q_exp.to_csv(\"q_exp_id_and_nlp_tokens.csv\", index=False)","f9fedd64":"q_exp.head().to_csv(\"q_exp_test_5.csv\", index=False)","ab0cf441":"This was it for today, thanks for following it through, I will continue the improvement :)","2da520a4":"***Approach Two to Recommendation Engine*** recommend a professional who had answered questions with similar tags","badf7959":"### Removing token which are more than x% of the questions","552f75c6":"We could go deeper, and get lost in the graph but I would like to take and iterative approach to build the recommendation engine and explore the graph along the path.","198ebefb":"So it is quite powerful, considering it is only a query in a db with 2M nodes and 6M relationships and had given these results in 211 ms so it has real time applications","ad0bbed9":"* Old schema (up)\n* New DB schema (down) after a few modification showed in the previous kernel:\n*Location of students and professionals and the industry of a professional where extracted into nodes.*\n","ab9ad88b":"> MATCH (q:Question {_id:\"5194c9cac7134c868beb02f83c1a5bbf\"})-[r:HAS_TAG]-(t:Tag) return q,r,t limit 300","5e3e7616":"As you can see the best improvement opportunity is to upgrade the tagging system.","2e606183":"Question with 3 tags:\n> MATCH (q_o:Question {_id:\"dab7b240dc394d30a54dd0c5862d5fe3\"})-[:HAS_TAG]-(t:Tag)-[:HAS_TAG]-(q_s1:Question)-[:IS_REPLY_TO]-(a:Answer)-[:AUTHOR_OF]-(p:Professional)-[:AUTHOR_OF]-(a_o:Answer)-[:IS_REPLY_TO]-(q_s2:Question)-[:HAS_TAG]-(:Tag)-[:HAS_TAG]-(q_o)\nRETURN q_o.title AS Question_WithOut_Answer, p._id AS Professional, count(distinct t) as tag_count, count(distinct a_o) as p_a_count ORDER BY tag_count desc, p_a_count desc limit 5\n\n|Professional |  tag_count | p_a_count  | \n|---|---|---|\n|\"36ff3b3666df400f956f8335cf53e09e\"|9          |134        |\n|\"05ab77d4c6a141b999044ebbf5415b0d\"|8      |61         |\n|\"0355aaad83704ad98e6d71b79db85849\"|8      |19         |\n|\"a1006e6a58a0447592e2435caa230f78\"|7        |94         |\n|\"a6d33c38902546849c36ea7e9e9f0870\"|7         |52         |\n","c60f2b15":"It was a bit slower 1139ms and you can build a recommendation function for a push of a button.","84fa8870":"One questions tags are connecting other questions, professionals and student to each other:\n*Red: Student\nDust: Professional\nDarkBlue: Question\nLightBlue: Tag*\n","370768b6":"**How many nodes whe have?**","6b5b4666":"### WIP, you can use this code to generate mora tags based on the questions, and answer tags.","08fe9af6":"### Answering Jared's questions:\n\nDid you decide to predict Pros given a Question, or predict Questions given a Pro? Why?\n*I did the former because it's more suitable for the email notification systome, however if I turn around the query it can recommend unanswered questions for a given professional real time.*\nDoes your model address the \"cold start\" problem for Professionals who just signed up but have not yet answered any questions? How'd you approach that challenge?\n*Not directly, however witht the Graph database and the Cypher query language it could be solved by Jaccard score and closeness in the graph*\nDid your model have any novel approaches to ensuring that \"no question gets left behind\"?\n*The unanswered questions could be queried real time to build a burn down board for the CV site.*\nWhat types of models did you try, and why did you pick the model architecture that you picked?\nI considered a few approaches (ML, NLP, networkx, Neo4j), but the Neo4j graph approach turned out the best for the current tactical needs and future strategis directions\nDid you engineer any new data features? Which ones worked well for your model?\nThe Jaccard score was great to find out similar questions, with more tags (for NLP or from users) it could be even more precise.\nIs there anything built into your approach to protect certain Professionals from being \"overburdened\" with a disproportionately high share of matches?\n*No, but it could be done easily by a query builded into the recommendation system.*\nWhat do you wish you could use in the future (that perhaps we could try out on our own as an extension of your work)?\n*The graph based link predicton ML approach, the book got out a few days ago...*","27bbf5c6":"**Get similar answers based on Jaccard index for the question with 3 tags:**\n> MATCH (q_or:Question {_id:\"dab7b240dc394d30a54dd0c5862d5fe3\"})-[:HAS_TAG]-(t:Tag)-[:HAS_TAG]-(q_ot:Question)-[IS_REPLY_TO]-(a:Answer)\nWITH q_or, q_ot, COUNT(t) AS intersection, COLLECT(t.name) AS i\nMATCH (q_or)-[:HAS_TAG]-(o_or:Tag)\nWITH q_or, q_ot, intersection,i, COLLECT(o_or.name) AS s1\nMATCH (q_ot)-[:HAS_TAG]-(o_ot:Tag)\nWITH q_or, q_ot,intersection,i, s1, COLLECT(o_ot.name) AS s2\n\nWITH q_or, q_ot,intersection,s1,s2\n\nWITH q_or, q_ot,intersection,s1+filter(x IN s2 WHERE NOT x IN s1) AS union, s1, s2\n\nRETURN q_or.title, q_ot.title, s1,s2,((1.0*intersection)\/SIZE(union)) AS jaccard ORDER BY jaccard DESC LIMIT 20\n","aaa846a9":"> MATCH (q:Question {_id:\"dab7b240dc394d30a54dd0c5862d5fe3\"})-[r]-(k) return q,r,k","96cbf4f7":"**The whole recommendation engine's idea was based on this system:**\n[https:\/\/neo4j.com\/sandbox-v2\/#](https:\/\/neo4j.com\/sandbox-v2\/#) look for the recommendation engine sandbox. Moreover you can understand why we need the hearts :)","7e81b684":"**Simpler solution and example with the 3 tags:**\n> MATCH (q_o:Question {_id:\"dab7b240dc394d30a54dd0c5862d5fe3\"})-[:HAS_TAG]-(t:Tag)-[:HAS_TAG]-(q_s:Question)-[IS_REPLY_TO]-(a:Answer)-[:IS_REPLY_TO]-(c:Comment)\nRETURN q_o.title AS Question_WithOut_Answer, q_s.title AS Similar_Question, a.body AS Answers, count(distinct t) as tag_count, count(distinct c) as comment_count ORDER BY tag_count desc,comment_count desc limit 5\n\n* **Original question title: \"Are there any resume items which would make my college application really stand out?\"**\n* Most similar question:\"When applying to universities, the people at admissions always enjoy reading unconventional essays. How does one know that what they are writing fits this criteria?\"\n* Second:\"Can someone proofread my college transfer essay?\"","4fbafbc2":"I'm doing the tag enrichment based on this [kernel](https:\/\/www.kaggle.com\/danielbecker\/careervillage-org-recommendation-engine), to improve the connection density and improve the recommendation's quality.","54cf03e4":"***EDA***","60e98967":"**How many relationships we have grouped by type?**","6c95789b":"> MATCH (n) RETURN COUNT(n) AS CountOfNodes\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502\"CountOfNodes\"\u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u25022027427       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n","236bbb62":"# ***Hi, This is the continuation of [this](https:\/\/www.kaggle.com\/ironben\/rdbs-to-graphdb-neo4j-network-approach\/) data transformation kernel, with EDA, NLP and the Recommendation Engine*** \n*Feel free to ask questions and upvote it if you think it is useful for you.*","2afa2e9c":"USING PERIODIC COMMIT 10000 \nLOAD CSV WITH HEADERS FROM \"file:\/\/\/q_exp_id_and_nlp_tokens.csv\"AS row\nMATCH (q:Question {_id:row.questions_id})\nWITH SPLIT(row.nlp_tokens, \",\") AS tags,q,row\nUNWIND tags as tag\n\tCREATE (t:Token:Tag {name:tag})\n\tCREATE (q)-[:HAS_TAG]->(t)\n\nCREATE INDEX ON :Tag(name)\nCREATE INDEX ON :Token(name)\n\nMATCH (n:Tag)\nWITH n.name AS name, COLLECT(n) AS nodelist, COUNT(*) AS count\nWHERE count > 1\nCALL apoc.refactor.mergeNodes(nodelist) YIELD node\nRETURN node\n","a817d450":"As you can see an unanswered question on has 3 types of nodes in the neighbourhood, the tags, the email and the author, our best path is on the tags.","92c5585a":"Question with 3 tags:\n> MATCH (q_o:Question {_id:\"dab7b240dc394d30a54dd0c5862d5fe3\"})-[:HAS_TAG]-(t:Tag)-[:HAS_TAG]-(q_s1:Question)-[:IS_REPLY_TO]-(a:Answer)-[:AUTHOR_OF]-(p:Professional)-[:AUTHOR_OF]-(a_o:Answer)-[:IS_REPLY_TO]-(q_s2:Question)-[:HAS_TAG]-(:Tag)-[:HAS_TAG]-(q_o)\nRETURN q_o.title AS Question_WithOut_Answer, p._id AS Professional, count(distinct t) as tag_count, count(distinct a_o) as p_a_count ORDER BY tag_count desc, p_a_count desc limit 5\n\n|Professional |  tag_count | p_a_count  | \n|---|---|---|\n|\"36ff3b3666df400f956f8335cf53e09e\"|3          |36         |\n|\"05ab77d4c6a141b999044ebbf5415b0d\"|2          |23     |\n|\"a1006e6a58a0447592e2435caa230f78\"|2          |8        |\n|\"bb4fe08bb5424f08972927d90bad9642\"|2          |5          |\n|\"369f1c8646b649f6997eae7809696bd5\"|2          |5          |","d4db5bd1":"* **Original question title: \"Are there any resume items which would make my college application really stand out?\"**\n* Most similar question: \"How do you make your university application stand out?\"\n* Second: \"Can someone proofread my college transfer essay?\"\n* Third: \"What should I look for if I am considering transferring colleges?\"\n* Fourth: \"How do you build your resume in college?\"\n* Fifth: \"How did you decide which college to attend?\"\n","3d19cc58":"Check out these questions, the \"5194c9cac7134c868beb02f83c1a5bbf\" with 14 tags and the \"dab7b240dc394d30a54dd0c5862d5fe\" one with 3 tags.","910922cd":"***Approach One to Recommendation Engine*** Get similar questions (with answers) to the student's unanswered questions, because this is THE fastes way to get answers to the students because it only depends on past professional activity and do not need future one, in most cases, ***I call this as a first line of help.***","4df99bcd":"# NLP based tag enrichment !RUN OUT OF TIME TO DO THIS PROPERLY!","f7b8a9de":"> MATCH ()-[m]->() RETURN COUNT(m) AS CountOfRels\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502\"CountOfRels\"\u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u25026619257      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","49d779ea":"TODO for recommendation improvement: \n* NLP based question tagging for more connections,\n* professional activity dates in the query to filter out inactive professionals\n* use heart data \n* NLP based answer tagging for answer recommendation for an unanswered question ?\n* student get todolist data from competition owners\n","33c17c35":"**Get similar answers based on Jaccard index for the question with 14 tags:**\n> MATCH (q_or:Question {_id:\"5194c9cac7134c868beb02f83c1a5bbf\"})-[:HAS_TAG]-(t:Tag)-[:HAS_TAG]-(q_ot:Question)-[IS_REPLY_TO]-(a:Answer)\nWITH q_or, q_ot, COUNT(t) AS intersection, COLLECT(t.name) AS i\nMATCH (q_or)-[:HAS_TAG]-(o_or:Tag)\nWITH q_or, q_ot, intersection,i, COLLECT(o_or.name) AS s1\nMATCH (q_ot)-[:HAS_TAG]-(o_ot:Tag)\nWITH q_or, q_ot,intersection,i, s1, COLLECT(o_ot.name) AS s2\nWITH q_or, q_ot,intersection,s1,s2\nWITH q_or, q_ot,intersection,s1+filter(x IN s2 WHERE NOT x IN s1) AS union, s1, s2\nRETURN q_or.title, q_ot.title, s1,s2,((1.0*intersection)\/SIZE(union)) AS jaccard ORDER BY jaccard DESC LIMIT 20\n\n","6936b6f5":"**How many node labels we have grouped by type?**","b3631bd2":"# Import tags into database a rerun the tests","49adfd70":"**Relationships?**","0a2a2330":"**Check out the unanswered questions:**","d495866f":"Import the files for later for the NLP tokenisation:","9ffd3d72":"* **Original question title: \"What are the best free resources for MCAT prep?\"**\n* Most similar question: \"How have you reacted to the people who have told you that you don't have what it takes to become a doctor\/surgeon?\"\n* Second: \"What helps you study for a test?\"\n* Third: \"How do I decide between career paths?\"\n* Fourth: \"What is the most rewarding part about being a doctor?\"\n* Fifth: \"What would you tell a high school\/college student who has goals of attending Medical School but isn't sure what to specialize in?\"","ed2e3bea":"> CALL db.labels()\nYIELD label\nCALL apoc.cypher.run(\"MATCH (:\"+`label`+\") RETURN count(*) as count\", null)\nYIELD value\nRETURN label, value.count AS count\nORDER BY count DESC\n\nlabel\tcount\n* \"Email\"\t1850101\n* \"Answer\"\t51123\n* \"Student\"\t30971\n* \"Professional\"\t28152\n* \"Question\"\t23931\n* \"Tag\"\t16269\n* \"Comment\"\t14966\n* \"Location\"\t6682\n* \"School\"\t2706\n* \"Industry\"\t2470\n* \"Group\"\t49\n* \"Group_Type\"\t7\n* \"Matches\"\t0","d8f29717":"> MATCH (q:Question)\nWHERE not exists ((q)-[:IS_REPLY_TO]-(:Answer))\nWITH q\nMATCH (q)-[:HAS_TAG]-(t:Tag)\nreturn  q._id AS question_id, count(t) as tag_c order by tag_c desc\n\nquestion_id\ttag_c\n* \"5194c9cac7134c868beb02f83c1a5bbf\"\t14\n* \"9ee85a6f4ab14a878928871ab3e86616\"\t10\n* \"72affe86909d49c09761a1d376476c92\"\t9\n* \"f4790c8029064b41bd410f66c5039890\"\t9\n* \"c7cb6c54dbb34c0ab2eb23751deea6ad\"\t9\n* \"785f2a8c69bb4f9787fa87a4d487014f\"\t9\n* \"fd8c6ff37c0d4439980a04d9d3ec5ffe\"\t9\n* \"4189060e1882495fb4af4cdd7447d074\"\t8\n* \"00a1ac3d65094cba96d9a719ace341d9\"\t8\n* ....\n* \"dab7b240dc394d30a54dd0c5862d5fe3\" 3\n* ...\n\n**The dataset has 807 unanswered questions, and the db had given this result in 154 ms**\n\n","15bd86e1":"> CALL db.relationshipTypes()\nYIELD relationshipType\nCALL apoc.cypher.run(\"MATCH ()-[:\"+`relationshipType` +\"] -> () RETURN count(*) as count\", null)\nYIELD value\nRETURN relationshipType, value.count AS count\nORDER BY count DESC\n\nrelationshipType\tcount\n* \"IS_IN\"\t4316275\n* \"GOT_EMAIL\"\t1850101\n* \"HAS_TAG\"\t212460\n* \"AUTHOR_OF\"\t88264\n* \"IS_REPLY_TO\"\t66089\n* \"BASED_IN\"\t53992\n* \"WORKING_IN\"\t25576\n* \"MEMBER_IN\"\t6451\n* \"HAS_TYPE\"\t49"}}