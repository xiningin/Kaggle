{"cell_type":{"b4680d85":"code","98617f03":"code","7d9ff0e5":"code","8d8e9ef5":"code","b6fda2ec":"code","806af956":"code","0f409140":"code","6bc75bcd":"code","9e700e8d":"code","540bb78a":"code","c1ed7a73":"code","8c2d4ff5":"code","85b5b9a3":"code","0ee0bb4e":"code","1e031456":"markdown","9eba20d9":"markdown","cf2c7349":"markdown","ccd502e2":"markdown","a35d137f":"markdown","dfcdd96a":"markdown","5d2f074f":"markdown","d3e5bc55":"markdown","5f6c1877":"markdown","17a7d12b":"markdown","90da26a9":"markdown","7df2542d":"markdown"},"source":{"b4680d85":"import pandas as pd\nimport numpy as np\nimport time\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBClassifier\n\nfrom pathlib import Path","98617f03":"class Config:\n    debug = False\n    competition = \"TPS_202111\"\n    seed = 42\n    NFOLDS = 5\n    EPOCHS = 10\n","7d9ff0e5":"data_dir = Path('..\/input\/tabular-playground-series-nov-2021') # Change me every month","8d8e9ef5":"%%time\ntrain_df = pd.read_csv(data_dir \/ \"train.csv\",\n#                       nrows=100000\n                      )\n\ntest_df = pd.read_csv(data_dir \/ \"test.csv\")\nsample_submission = pd.read_csv(data_dir \/ \"sample_submission.csv\")\n\nprint(f\"train data: Rows={train_df.shape[0]}, Columns={train_df.shape[1]}\")\nprint(f\"test data : Rows={test_df.shape[0]}, Columns={test_df.shape[1]}\")\n","b6fda2ec":"features = [col for col in train_df.columns if col not in ('id', 'target')]","806af956":"# scaler = StandardScaler()\n\n# train_df[features] = scaler.fit_transform(train_df[features])\n# test_df[features] = scaler.transform(test_df[features])","0f409140":"y = train_df.target\n\ntest_df = test_df.drop([\"id\"], axis=1)\nX = train_df.drop([\"id\", \"target\"], axis=1)\nX.head()","6bc75bcd":"xgb_params_v1 = {\n    'max_depth': 6,\n    'learning_rate': 0.007,\n    'n_estimators': 10000, # 9500\n    'subsample': 0.7,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.6000000000000001,\n    'min_child_weight': 56.41980735551558,\n    'reg_lambda': 75.56651890088857,\n    'reg_alpha': 0.11766857055687065,\n    'gamma': 0.6407823221122686,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n    }","9e700e8d":"xgb_params = {\n    \"objective\": \"binary:logistic\",\n    \"use_label_encoder\": False,\n    \"n_estimators\": 70000,\n    'learning_rate': 0.007,\n\n#     \"learning_rate\": 0.15525187869673937,\n    \"subsample\": 0.66,\n    \"colsample_bytree\": 0.9500000000000001,\n    \"max_depth\": 4,\n    \"booster\": \"gbtree\",\n    \"gamma\": 1.7000000000000002,\n    \"tree_method\": \"gpu_hist\",\n    \"reg_lambda\": 0.9541035898656812,\n    \"reg_alpha\": 2.3445012085324084,\n    \"random_state\": 42,\n    \"n_jobs\": 4,\n    \"min_child_weight\": 256,\n}","540bb78a":"final_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nkf = StratifiedKFold(n_splits=Config.NFOLDS, shuffle=True, random_state=Config.seed)\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X, y = y)):\n\n    print(10*\"=\", f\"Fold={fold}\", 10*\"=\")\n    start_time = time.time()\n    x_train = X.loc[train_idx, :]\n    x_valid = X.loc[valid_idx, :]\n    \n    y_train = y[train_idx]\n    y_valid = y[valid_idx]\n    model = XGBClassifier(**xgb_params)\n\n    model.fit(x_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(x_valid, y_valid)],\n          eval_metric='auc',\n          verbose=0)\n\n    \n    preds_valid = model.predict_proba(x_valid)[:, -1]\n    final_valid_predictions.update(dict(zip(valid_idx, preds_valid)))\n    \n    auc = roc_auc_score(y_valid,  preds_valid)\n    scores.append(auc)\n\n    run_time = time.time() - start_time\n    print(f\"Fold={fold}, auc: {auc:.8f}, Run Time: {run_time:.2f}\")\n    \n    test_preds = model.predict_proba(test_df[features])[:, -1]\n    final_test_predictions.append(test_preds)\n","c1ed7a73":"best_oof_mean = 0.74291098\n\nmean_auc = np.mean(scores)\n\nmean_diff = mean_auc - best_oof_mean\nprint(f\"OOF Mean Score difference: {mean_diff}\")","8c2d4ff5":"print(f\"Scores -> mean: {np.mean(scores):.8f}, std: {np.std(scores):.8f}\")","85b5b9a3":"final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)","0ee0bb4e":"sample_submission['target'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.to_csv(\"test_pred_1.csv\",index=None)\nsample_submission.to_csv(\"submission.csv\",index=None)\nsample_submission","1e031456":"```\nScores -> mean: 0.74291098, std: 0.00163617\nScores -> mean: 0.74291098, std: 0.00163617\nScores -> mean: 0.74291098, std: 0.00163617\n\n```","9eba20d9":"# Features","cf2c7349":"# Load Libraries","ccd502e2":"In addition to submission.csv, generates OOF predictions.\n\n- train_pred_1.csv\n- test_pred_1.csv (same as submission file)\n\n# Versions\n\n- V3:\n  - Tried Standardization.  No effect. \n  - Increased n_estimators to 70,000.  Increased early_stopping=200\n  - Back to a lower learning_rate.\n         'learning_rate': 0.007,\n         #\"learning_rate\": 0.15525187869673937,\n- V2: Try a different set of Optuna hyperparameters. Save OOF in train_pred_1.csv\n- V1: Original","a35d137f":"# Submission File","dfcdd96a":"# Save OOF Predictions","5d2f074f":"# Configuration","d3e5bc55":"# Standardize\/Normalize Data\n\nDon't necessarily need to do this for Trees","5f6c1877":"# Extract Target and Drop Unused Columns","17a7d12b":"# Model","90da26a9":"# Load Train\/Test Data","7df2542d":"### Are we improving?"}}