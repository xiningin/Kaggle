{"cell_type":{"e8c5cb3a":"code","ef7de2a0":"code","4628ff1d":"code","2137c3a9":"code","b89df1a9":"code","41d48827":"code","abc0293a":"code","b91d1f65":"markdown","01c089ee":"markdown","6748b7a1":"markdown","56f1388f":"markdown","f22fe530":"markdown"},"source":{"e8c5cb3a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef generate_noise(images, noise_factor=0.5):\n    return images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)","ef7de2a0":"# network output data\n(y_train, _), (y_test, _) = keras.datasets.mnist.load_data()\ny_train = y_train.astype(\"float32\") \/ 255.\ny_test = y_test.astype(\"float32\") \/ 255.\n\n# network input data\nx_train = generate_noise(y_train)\nx_test = generate_noise(y_test)\n\n# dataset sizes\nprint(f\"x_train.shape:{x_train.shape} y_train.shape:{y_train.shape}\")\nprint(f\"x_test.shape:{x_test.shape} y_test.shape:{y_test.shape}\")","4628ff1d":"# image size\ninput_dim  = x_train[0].shape + (1,)# + 1 color channel\noutput_dim = y_train[0].shape + (1,)# + 1 color channel\n\n# build model\nmodel = keras.Sequential([\n    keras.Input(shape=input_dim),\n    layers.Flatten(),# (28, 28, 1) -> (784, )\n    layers.Dense(784, activation=\"relu\"),\n    layers.Reshape((28, 28, 1))# (784, ) -> (28, 28, 1)\n])\n\nmodel.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n# print(model.summary())","2137c3a9":"epochs = 15\nbatch_size = 128\n\n# train model\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)","b89df1a9":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(f\"Test loss : {score[0]}\")\nprint(f\"Test accuracy : {score[1]}\")","41d48827":"predictions = model.predict(x_test)","abc0293a":"# display model [input <> output]\nfor i in range(5):\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    ax1.set_title(\"before model\")\n    ax1.imshow(x_test[i], cmap=plt.get_cmap(\"gray\"))\n\n    ax2.set_title(\"after model\")\n    ax2.imshow(predictions[i], cmap=plt.get_cmap(\"gray\"))\n\n    plt.show()","b91d1f65":"I hope you learned how this works,  \nKeep in mind that we can as well do the other way around that we remove the digit in place of the noisy pixels.  \nThis can also be helpfull in other Clasification problems where you have the target image and the current wrong image.  \n\n\nKind Regards,\n\nNiek Tuytel","01c089ee":"We have build the filter model that can filter noise pixels out of a image using the train data.  \nWe will use the test data to see how the network perform on unknown data.","6748b7a1":"## Model\n\nWe will now build some filter that can filter out the wrong pixel value.  \nNeuron is a filter as he will filter out the good nor bad information ([`more info about the Neuron`](https:\/\/github.com\/niektuytel\/Machine_Learning\/tree\/main\/deep_learning\/artificial_neural_networks\/perceptron)).  \n\nIn my head i always think of a paint filter. \n<center>\n    <img src=\"https:\/\/cf.shopee.ph\/file\/0e68086666e25733aab2680ca5a9f50a\" width=\"250\"\/>\n<\/center>","56f1388f":"## Purpose of this notebook\n\nWe will build a Denoising Autoencoder on The MNIST dataset.  \nThis is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.  \nMore info can be found at the [`wiki`](https:\/\/en.wikipedia.org\/wiki\/MNIST_database).\n\n<center>\n    <img src=\"https:\/\/miro.medium.com\/max\/724\/1*qKiQ1noZdw8k05-YRIl6hw.jpeg\" width=\"500\"\/>\n<\/center>\n\nWhen we need to train this network to remove unwanted pixels from images we need 2 types of images:  \n1. Images that are wrong, what the network need to edit  \n2. Images that are correct, what the network need to learn from how it has to be when the network edit it.\n\nAs we use the MNIST dataset we only have the correct looking images,  \nso we need to generate the noisy wrong images.","f22fe530":"The `keras.Flatten()` will bring the image that is a 28x28x1 pixels to a single array of 784 pixels.  \nThan we are using 1 layer of 784 neurons to filter out the unwanted data.  \nThe `keras.Reshape((28, 28, 1))` will bring the single array back to image format"}}