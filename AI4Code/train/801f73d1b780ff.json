{"cell_type":{"793c3e43":"code","bdb79da4":"code","cbdd90f4":"code","ffaac913":"code","8c49b786":"code","bffd1473":"code","9fab222f":"code","fe8864f8":"code","e8c3fecc":"code","354188ec":"code","382a02b0":"code","974380a3":"code","42a99ea7":"code","95d013d2":"code","f5cea468":"code","c1bbb433":"code","82790013":"code","474f53be":"code","e08dfe09":"code","702dd611":"code","df486245":"code","7211c2a3":"code","9830f2e6":"code","beabc56c":"code","0454458e":"code","5eecfc04":"code","ceaca085":"code","4ded7d3e":"code","c5777c1c":"code","4c28dea6":"markdown","002999f2":"markdown","1734fb8c":"markdown","749e9ce6":"markdown","72121cc9":"markdown","cab630a8":"markdown","3341497e":"markdown","5185acb5":"markdown","dd4d38f8":"markdown","20f7db16":"markdown","b14b7489":"markdown","9701ff32":"markdown","4239b6e5":"markdown","302b1b45":"markdown","6919d4e1":"markdown","6069df43":"markdown","42b8c94b":"markdown","3aa67944":"markdown","6fe9065f":"markdown","eb5f10de":"markdown","2df7f5fa":"markdown","20498c9f":"markdown","c3d1d652":"markdown","6cb24928":"markdown","fce49464":"markdown","06c1cffd":"markdown"},"source":{"793c3e43":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for plotting data\nimport seaborn as sns #for plotting data\n\nfrom sklearn.preprocessing import LabelEncoder #to convert categorical variables into numerical values\n\n#for ignoring warnings\nimport warnings\nwarnings.filterwarnings('ignore')","bdb79da4":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntrain.describe(include = 'all')","cbdd90f4":"train.head()","ffaac913":"train.isnull().sum()","8c49b786":"print(\"Percentage of Pclass = 1 who survived:\", round(train[\"Survived\"][train[\"Pclass\"] == 1]\n                                                      .value_counts(normalize = True)[1]*100),\"%\")\n\nprint(\"Percentage of Pclass = 2 who survived:\", round(train[\"Survived\"][train[\"Pclass\"] == 2]\n                                                      .value_counts(normalize = True)[1]*100),\"%\")\n\nprint(\"Percentage of Pclass = 3 who survived:\", round(train[\"Survived\"][train[\"Pclass\"] == 3]\n                                                      .value_counts(normalize = True)[1]*100),\"%\")\n\nsns.catplot(x = 'Pclass' , y = 'Survived',kind = 'point',data = train);\n\n\n","bffd1473":"print(\"Survival % of Male:\", round(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100),\"%\")\n\nprint(\"Survival % of Female:\", round(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100),\"%\")\nsns.catplot(x = 'Sex' , y = 'Survived',kind = 'point',data = train);","9fab222f":"fig = plt.figure(figsize=(8,8))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\ng1=sns.catplot(x = 'SibSp',kind = 'count',data = train,ax = ax1);\ng2=sns.catplot(x = 'SibSp' , y = 'Survived',kind = 'bar',data = train,ax = ax2);\nplt.close(g1.fig)\nplt.close(g2.fig)\nplt.show()","fe8864f8":"for i in range(0,max(train[\"SibSp\"])+1):\n    if i in (6,7):\n        continue\n    else:\n        print(\"Total passengers with\", i , \"siblings and\/or spouse:\" ,train[\"SibSp\"].value_counts(sort = False)[i])","e8c3fecc":"fig = plt.figure(figsize=(8,8))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\ng1=sns.catplot(x = 'Parch',kind = 'count',data = train,ax = ax1);\ng2=sns.catplot(x = 'Parch' , y = 'Survived',kind = 'bar',data = train,ax = ax2);\nplt.close(g1.fig)\nplt.close(g2.fig)\nplt.show()","354188ec":"for i in range(0,max(train[\"Parch\"])+1):\n    print(\"Total passengers with\", i , \"parent or child:\" ,train[\"Parch\"].value_counts(sort = False)[i])","382a02b0":"test.head(10)","974380a3":"test.isnull().sum()","42a99ea7":"# combining both train and test datasets because both have missing Age values\nTrainTest = [train, test]\n\n#extract a title for each Name in the train and test datasets\nfor data in TrainTest:\n    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","95d013d2":"#To ease the analysis combining the titles into fewer categories\nfor data in TrainTest:\n    data['Title'] = data['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    data['Title'] = data['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n","f5cea468":"test.head()","c1bbb433":"#Calculating the average age according to each title\ntitle= ['Mr','Miss','Mrs','Master','Royal','Rare'];\nmr_age = round(train[train[\"Title\"] == 'Mr'][\"Age\"].mean()) \nprint('Average age of title Mr: ',mr_age)\nmiss_age = round(train[train[\"Title\"] == 'Miss'][\"Age\"].mean())\nprint('Average age of title Miss: ',miss_age)\nmrs_age = round(train[train[\"Title\"] == 'Mrs'][\"Age\"].mean())\nprint('Average age of title Mrs: ',mrs_age)\nmaster_age = round(train[train[\"Title\"] == 'Master'][\"Age\"].mean())\nprint('Average age of title Master: ',master_age)\nroyal_age = round(train[train[\"Title\"] == 'Royal'][\"Age\"].mean())\nprint('Average age of title Royal: ',royal_age)\nrare_age = round(train[train[\"Title\"] == 'Rare'][\"Age\"].mean())\nprint('Average age of title Rare: ',rare_age)\navg_age = [mr_age,miss_age,mrs_age,master_age,royal_age,rare_age]","82790013":"#Filling the missing values in train dataset\nn_rows= train.shape[0]   \nn_titles= len(title)\nfor i in range(0, n_rows):\n    if np.isnan(train.Age[i])==True:\n        for j in range(0, n_titles):\n            if train.Title[i] == title[j]:\n                train.Age[i] = avg_age[j]\n\ntrain['Age'].isnull().sum()","474f53be":"#Filling the missing values in test dataset  \nn_rows= test.shape[0]   \nn_titles= len(title)\nfor i in range(0, n_rows):\n    if np.isnan(test.Age[i])==True:\n        for j in range(0, n_titles):\n            if test.Title[i] == title[j]:\n                test.Age[i] = avg_age[j]\n\ntest['Age'].isnull().sum()\n","e08dfe09":"#Creating different AgeGroups\nbins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","702dd611":"print(\"Number of people embarking in S:\",train[train[\"Embarked\"] == \"S\"].shape[0]) \n\n\nprint(\"Number of people embarking in C:\",train[train[\"Embarked\"] == \"C\"].shape[0])\n\n\nprint(\"Number of people embarking in Q:\",train[train[\"Embarked\"] == \"Q\"].shape[0])\n\nsns.catplot(x='Embarked',kind = 'count',data=train)\nplt.show()","df486245":"train = train.fillna({\"Embarked\": \"S\"})\ntrain['Embarked'].isnull().sum()","7211c2a3":"train.head(10)\n","9830f2e6":"test.head(10)","beabc56c":"#Age Group\nlabelEncoder = LabelEncoder()\ntrain.AgeGroup=labelEncoder.fit_transform(train.AgeGroup)\ntest.AgeGroup=labelEncoder.fit_transform(test.AgeGroup)","0454458e":"#Sex\ntrain.Sex=labelEncoder.fit_transform(train.Sex)\ntest.Sex=labelEncoder.fit_transform(test.Sex)","5eecfc04":"train.Embarked=labelEncoder.fit_transform(train.Embarked)\ntest.Embarked=labelEncoder.fit_transform(test.Embarked)","ceaca085":"train=train.drop(['Name','Age','Ticket','Fare','Cabin','Title'],axis=1)\ntest=test.drop(['Name','Age','Ticket','Fare','Cabin','Title'],axis=1)","4ded7d3e":"train.head()","c5777c1c":"test.head()","4c28dea6":"## 2)Importing and understanding the data","002999f2":"### 'Embarked' feature\n\n\nSince there are only 2 missing values in training set and none in test set hence we will directly fill those 2 missing values with the maximum occuring option.","1734fb8c":"## 4) Data cleaning","749e9ce6":"__This shows that the Upper class are the ones with the best survival percentage.__","72121cc9":"## Mapping the features 'AgeGroup' ,'Embarked' and 'Sex'","cab630a8":"-  __Babies have the greatest chance of survival__","3341497e":"### NOTE: \nI could not decide whether to perform analysis on __\"Embarked\"__ and __\"Age\"__ features before or after filling the missing values.\nIs there any rule on whether we should perform data cleaning  first followed by data analysis or vice versa???? If there is then please explain in the comments.\nI have decided to first clean the data and then perform analysis on above two features. ","5185acb5":"__Females have a significant higher chance of surviving than males__","dd4d38f8":"-  __'Cabin'__ feature has a lot of NULL values and does not give much useful information so it may be dropped\n-  __'Fare' and 'Ticket'__ features may  also be dropped.\n-  __'Age'__ feature is important so missing values has to be filled.\n\n__So we need to fill 'Age' and 'Embarked' missing values in our training dataset and 'Age' missing values in our test dataset__\n__Unnecessary features will be dropped once the cleaning part  is done__","20f7db16":"### Some initial conclusions(by looking at raw data)\n\n-  Three features __'Age'__ , __'Cabin'__ and __'Embarked'__ have missing values.These need to be adressed.\n-  'Age' seems to be an important feature for predicting survival rates and hence we should not discard it.\n-  'Cabin' has a lot of NULL values and may not provide much information so it may be discarded.\n-  'Embarked' only has 2 NULL values so they  will be filled with the  maximum ocurring category.","b14b7489":"## Dropping features which are not required","9701ff32":"### c) Survival based on SibSp and Parch","4239b6e5":"Now our data is clean and ready.","302b1b45":"__Clearly most of the people embarked at 'S' so we will fill the missing values with the same.__","6919d4e1":"### Since this was my first attempt at this, I had to take some ideas  from other amazing  sources present here...\n### Here are the link to these amazing notebooks\n\n-  https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n-  https:\/\/www.kaggle.com\/omarelgabry\/a-journey-through-titanic\n-  https:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner\n-  https:\/\/www.kaggle.com\/rochellesilva\/simple-tutorial-for-beginners\n\n\n# Please provide your valuable feedback on this and ways to improve it!!!\n# Thank You","6069df43":"__At the beginning we looked at our training dataset. Now let's take a look at our test dataset before cleaning them.__","42b8c94b":"### b. Survival based on Sex","3aa67944":"## 3)Exploratory data analysis and data visualization","6fe9065f":"This is my first attempt to create an analytical notebook. It involves Exploratory Data Analysis on the \"Titanic\" dataset .\nConstructive feedback will be appreciated :)\n\n## STEPS\n\n1)Importing necessary Libraries\n\n2)Importing and understanding the required data\n\n3)Exploratory data analysis and data visualization\n\n4)Data cleaning\n\n","eb5f10de":"-  __Since the sample size of passengers with SibSp > 2 is very less(less than 20),hence the survival rate trends can be misleading for them.__\n-  __But it can clearly be seen that those with 1 or 2 SibSp had a higher rate of survival than those with 0 SibSp.__\n","2df7f5fa":"### Working with 'Age' feature\n\nSince there are a lot of missing values so rather than just filling them with average age I will first calculate the average age corresponding to each __title__(Title will be extracted out from the __'Name'__ feature) and then missing age values will be filled with avg age value corresponding  to  the title of the person whose age is missing.  ","20498c9f":"## 1)Importing necessary libraries","c3d1d652":"__Now that all the missing values of important features have been filled ,the two things left to do are:__  \n1.  to map the non-numerical feature values into numerical values before using them to train the model\n2.  to drop the unnecessary features\n\nBut first let us take a look at our training and test dataset.","6cb24928":"__Creating this notebook was really fun and I got to learn a lot of things.No doubt this is the best way to learn  for newbies like me. \nI hope this notebook will be useful in someway for people new to this.__","fce49464":"### a. Survival based on the passenger class","06c1cffd":"-  __Again since the sample size of passengers with Parch > 2 is very less(less than 10),hence the survival rate trends can be misleading for them.__\n-  __But it can clearly be seen that those with 1 or 2 Parch had a higher rate of survival than those with 0 SibSp.__"}}