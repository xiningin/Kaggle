{"cell_type":{"0dc2703b":"code","dfe5a3ad":"code","230c4d52":"code","da8ed5de":"code","c850f145":"code","6395b672":"code","cc9ccea9":"code","bd195f4e":"code","192221d1":"code","cde965da":"code","977398a0":"code","ed37c601":"code","c27a4301":"code","cdc3d120":"code","749262d4":"code","08871ff7":"code","8df81a9f":"code","7a8dc072":"code","5a046d47":"code","a25f9ece":"code","10622f65":"code","89877f4d":"code","2f8a3456":"code","13eefebf":"code","81521f48":"code","e948c7a9":"code","908ee6ba":"code","0de607d3":"code","008d5ba6":"code","6aee1327":"code","e2787284":"code","80fd6381":"code","206ec613":"code","11c8e509":"markdown","8bbd9fc8":"markdown","b97752ba":"markdown","4dfce61e":"markdown","acb81fef":"markdown","1ca0a516":"markdown","ae3fde7d":"markdown","d6497151":"markdown","86682185":"markdown","8a9dad49":"markdown","5d5e2c67":"markdown","86ae23d2":"markdown"},"source":{"0dc2703b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom tensorflow import keras\nfrom keras import losses\nfrom keras import metrics\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Plot Confusion matrix function\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix',cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return None\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dfe5a3ad":"train_df            = pd.read_csv(\"..\/input\/train.csv\")\nunlabeled_images_df = pd.read_csv(\"..\/input\/test.csv\")","230c4d52":"#Para el conjunto de entrenamiento separa la imagen de su etiqueta de clase\ntrain_images_df     = train_df.iloc[:,1:]\ntrain_labels_df     = train_df.iloc[:,0:1]\n\n#Convierte los datos de pandas df a numpy array\nlabeled_images      = train_images_df.values\nlabels              = train_labels_df.values\nunlabeled_images    = unlabeled_images_df.values\n\n#Convierte la etiqueta de clase en multicategorical\none_hot_labels      = keras.utils.to_categorical(labels, num_classes=10)\n\n#Normaliza las imagenes de rango (0, 255) al rango (0,1) \nlabeled_images      = labeled_images\/255\nunlabeled_images    = unlabeled_images\/255\n\n#Cambia la forma de las imagenes de vector size = 784 a matrix size = (28,28,1)\nlabeled_images      = np.reshape(labeled_images,(labeled_images.shape[0],28,28,1))\nunlabeled_images    = np.reshape(unlabeled_images,(unlabeled_images.shape[0],28,28,1))","da8ed5de":"random_seed = 2\n\n#Define el tama\u00f1o del conjunto con el que se va a entrenar la red\ntest_set_percentage       = 0.15\nvalidation_set_percentage = 0.2\n\ntrain_images,test_images,train_labels,test_labels                   = train_test_split(labeled_images, one_hot_labels, test_size = test_set_percentage, random_state=random_seed)\npretrain_images,validation_images,pretrain_labels,validation_labels = train_test_split(train_images, train_labels, test_size = validation_set_percentage, random_state=random_seed)","c850f145":"train_images_df.isnull().any().describe()","6395b672":"unlabeled_images_df.isnull().any().describe()","cc9ccea9":"plt.title(\"Set sizes\")\nplot_image = [train_labels.shape[0],validation_labels.shape[0],test_labels.shape[0]]\nplt.bar([\"Train\",\"Validation\",\"Test\"],height=plot_image)\nplt.show()","bd195f4e":"size_of_img = (12,12)\nfig         =plt.figure(figsize=(72,72))\nax          =fig.add_subplot(12,12,1)\n\nplt.title(\"Train set\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Label\")\nplot_image = train_labels.sum(axis=0)\nax.bar([0,1,2,3,4,5,6,7,8,9],height=plot_image)\nax         =fig.add_subplot(12,12,2)\n\nplt.title(\"Validation set\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Label\")\nplot_image = validation_labels.sum(axis=0)\nax.bar([0,1,2,3,4,5,6,7,8,9],height=plot_image)\nax         =fig.add_subplot(12,12,3)\n\nplt.title(\"Test set\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Label\")\nplot_image = test_labels.sum(axis=0)\nax.bar([0,1,2,3,4,5,6,7,8,9],height=plot_image)\nplt.show()","192221d1":"size_of_img = (int(np.sqrt(unlabeled_images.shape[1])),int(np.sqrt(unlabeled_images.shape[1])))\nfig=plt.figure(figsize=(72,72))\nfor i in range(60):\n    ax         =fig.add_subplot(12,12,i+1)\n    plot_image = unlabeled_images[random.randint(0,1000),:,:,0]\n    ax.imshow(plot_image)\nplt.show()","cde965da":"data_gen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, \n                                                        samplewise_center=False, \n                                                        featurewise_std_normalization=False, \n                                                        samplewise_std_normalization=False, \n                                                        zca_whitening=False, \n                                                        zca_epsilon=1e-06, \n                                                        rotation_range=20, \n                                                        width_shift_range=0.05, \n                                                        height_shift_range=0.05, \n                                                        brightness_range=None, \n                                                        shear_range=0.05, \n                                                        zoom_range=0.05, \n                                                        channel_shift_range=0.0, \n                                                        fill_mode='nearest', \n                                                        cval=0.0, \n                                                        horizontal_flip=False, \n                                                        vertical_flip=False, \n                                                        rescale=0, \n                                                        preprocessing_function=None, \n                                                        data_format=None, \n                                                        validation_split=0.0, \n                                                        dtype=None)","977398a0":"data_gen.fit(pretrain_images)","ed37c601":"adam_optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)","c27a4301":"learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.3, patience=2, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001)","cdc3d120":"model_1 = keras.Sequential()\n\nmodel_1.add(keras.layers.Conv2D(filters = 64,kernel_size = (3,3),padding = 'Same',activation='relu',input_shape=(28,28,1)))\nmodel_1.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_1.add(keras.layers.Dropout(0.25))\n\nmodel_1.add(keras.layers.Conv2D(filters = 64,kernel_size = (3,3),padding = 'Same',activation='relu'))\nmodel_1.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_1.add(keras.layers.Dropout(0.25))\n\nmodel_1.add(keras.layers.Flatten())\nmodel_1.add(keras.layers.Dense(128, activation='relu'))\nmodel_1.add(keras.layers.Dense(10, activation='softmax'))","749262d4":"model_2 = keras.Sequential()\n\nmodel_2.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel_2.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel_2.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_2.add(keras.layers.Dropout(0.25))\n\nmodel_2.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel_2.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel_2.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel_2.add(keras.layers.Dropout(0.25))\n\nmodel_2.add(keras.layers.Flatten())\nmodel_2.add(keras.layers.Dense(256, activation = \"relu\"))\nmodel_2.add(keras.layers.Dropout(0.5))\nmodel_2.add(keras.layers.Dense(10, activation = \"softmax\"))","08871ff7":"model_3 = keras.Sequential()\n\nmodel_3.add(keras.layers.Conv2D(filters = 32,kernel_size = (3,3),padding = 'Same',activation='relu',input_shape=(28,28,1)))\nmodel_3.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_3.add(keras.layers.Dropout(0.25))\n\nmodel_3.add(keras.layers.Conv2D(filters = 64,kernel_size = (3,3),padding = 'Same',activation='relu',input_shape=(28,28,1)))\nmodel_3.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_3.add(keras.layers.Dropout(0.25))\n\nmodel_3.add(keras.layers.Conv2D(filters = 64,kernel_size = (3,3),padding = 'Same',activation='relu'))\nmodel_3.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel_3.add(keras.layers.Dropout(0.25))\n\nmodel_3.add(keras.layers.Flatten())\nmodel_3.add(keras.layers.Dense(128, activation='relu'))\nmodel_3.add(keras.layers.Dense(10, activation='softmax'))","8df81a9f":"model_1.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy',metrics=['accuracy'])\nmodel_2.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy',metrics=['accuracy'])\nmodel_3.compile(optimizer = adam_optimizer, loss = 'categorical_crossentropy',metrics=['accuracy'])","7a8dc072":"test_epochs  = 20","5a046d47":"start          = time.time()\nmodel1_history = model_1.fit_generator(data_gen.flow(pretrain_images, pretrain_labels, batch_size=32), epochs=test_epochs, validation_data=(validation_images,validation_labels), callbacks=[learning_rate_reduction])\nend            = time.time()\nmodel1_training_time = end - start","a25f9ece":"start          = time.time()\nmodel2_history = model_2.fit_generator(data_gen.flow(pretrain_images, pretrain_labels, batch_size=32), epochs=test_epochs, validation_data=(validation_images,validation_labels), callbacks=[learning_rate_reduction])\nend            = time.time()\nmodel2_training_time = end - start","10622f65":"start          = time.time()\nmodel3_history = model_3.fit_generator(data_gen.flow(pretrain_images, pretrain_labels, batch_size=32), epochs=test_epochs, validation_data=(validation_images,validation_labels), callbacks=[learning_rate_reduction])\nend            = time.time()\nmodel3_training_time = end - start","89877f4d":"acc      = model1_history.history['acc']\nval_acc  = model1_history.history['val_acc']\nloss     = model1_history.history['loss']\nval_loss = model1_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","2f8a3456":"acc      = model2_history.history['acc']\nval_acc  = model2_history.history['val_acc']\nloss     = model2_history.history['loss']\nval_loss = model2_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","13eefebf":"acc      = model3_history.history['acc']\nval_acc  = model3_history.history['val_acc']\nloss     = model3_history.history['loss']\nval_loss = model3_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","81521f48":"eval_model1 = model_1.evaluate(test_images, test_labels, batch_size=36)","e948c7a9":"eval_model2 = model_2.evaluate(test_images, test_labels, batch_size=36)","908ee6ba":"eval_model3 = model_3.evaluate(test_images, test_labels, batch_size=36)","0de607d3":"models_accuracy = [eval_model1[1],eval_model2[1],eval_model3[1]]\ntraining_times  = [model1_training_time,model2_training_time,model3_training_time]","008d5ba6":"# Predict the values from the validation dataset\nmodel1_pred = model_1.predict(test_images)\nmodel2_pred = model_2.predict(test_images)\nmodel3_pred = model_3.predict(test_images)\n# Convert predictions classes to one hot vectors \nmodel1_pred_classes = np.argmax(model1_pred,axis = 1) \nmodel2_pred_classes = np.argmax(model2_pred,axis = 1) \nmodel3_pred_classes = np.argmax(model3_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(test_labels, axis = 1) ","6aee1327":"# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, model1_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","e2787284":"# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, model2_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","80fd6381":"# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, model3_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","206ec613":"size_of_img = (12,12)\nfig         =plt.figure(figsize=(72,72))\n\nax          =fig.add_subplot(12,12,1)\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Model\")\nplot_image = models_accuracy\nax.bar([1,2,3],height=plot_image)\n\nax         =fig.add_subplot(12,12,2)\nplt.title(\"Training time\")\nplt.ylabel(\"Time\")\nplt.xlabel(\"Model\")\nplot_image = training_times\nax.bar([1,2,3],height=plot_image)\n\nplt.show()","11c8e509":"1.5. Data augmentation","8bbd9fc8":"1.5 Split the labeled images into train, validation and test sets","b97752ba":"2.Define the models\n\n* Set the optimezer and its parameters\n* Set the learning rate reduction \n* Define the model 1 architecture\n* Define the model 2 architecture\n* Define the model 3 architecture\n* Compile the models","4dfce61e":"A plot of a few examples of the images.","acb81fef":"1.2 Prepare the data  \n   * Separate the labels from the images on the train images  \n   * Transform labels from dimension 1 to dimension 10  \n   * Normalize images to a range of 0 to 1   \n   * Reshape the images from dimension (1, 784) to dimension (28, 28)","1ca0a516":" 3.Compare the models  \n*  Models training set to 20 epochs  \n* Analisis of model 1   \n* Analisis of model 2  ","ae3fde7d":"## Comparing two CNN architectures on digit classification\n\n   1. Introduction\n   2. Data preparation and exploration   \n       2.1. Load the data  \n       2.2. Prepare the data   \n       2.3. Split the labeled data into train, test and validation sets  \n       2.4. Exploration  \n       2.5. Data augmentation\n   3. Define the models    \n       3.1. Define the optimizer for the models     \n       3.2. Define model 1 architecture  \n       3.3. Define model 2 architecture  \n       3.4. Define model 3 architecture   \n       3.5. Compile the models    \n   4. Compare the models  \n       4.1. Train the models  \n       4.4. Analisis of models  \n           4.4.1. Training vs validation accuracy curve\n           4.4.2. Training vs validation loss curve\n           4.4.3. Model evaluation\n           4.4.4. Confusion matrix","d6497151":"1. Introduction  \nIn this kernel we compare three different convolutional neural network architectures, the principal information to compare is the accuracy of the model and the training time, so we can choose the model with the highest accuracy and the lowest training time.","86682185":"1.6. Exploration\n* Looking for missing values\n* Plot the train, validation and test set sizes\n* Plot the train, validation and test set label distributions\n* Plot some of the unlabeled images\n","8a9dad49":"1.1 Load the data","5d5e2c67":"There is no missing values in the labeled images neither in the unlabeled images.  ","86ae23d2":"In the following two plots is described the training, validation and test sets sizes and distributions, we observe that the sizes are in good proportions and the distributions for the different sets are similar, so is a good split."}}