{"cell_type":{"54f686ae":"code","00a29487":"code","c887cb1a":"code","e55db268":"code","d08dfa14":"code","01f7362b":"code","402595f0":"code","bddbfb54":"code","0c2d2913":"code","ad1aaf24":"code","21a521f6":"code","8b8508f6":"code","0f7467dc":"code","2506a9ce":"code","bbbf4dc8":"code","e24c12f2":"code","77e8001a":"code","f4cd1488":"code","78c9a7d5":"code","dd110e23":"code","173bd643":"code","aa0b3935":"code","f9c002b7":"code","e60c881e":"code","861a4a14":"code","8c89b81f":"code","11e88f3e":"code","01367776":"code","8fbeecf8":"code","b1b390d9":"code","14c8e271":"code","8bf9014b":"code","6a832cf4":"code","f5ee52d0":"code","c85bea14":"code","b9c5216f":"code","a13a2a5e":"code","42b11bfc":"code","55eb5335":"code","74ada590":"code","b20f9f4d":"code","10dded64":"code","c62fcd0d":"code","6b1092e3":"code","5a2091f4":"code","f8fb1946":"code","946dd773":"code","7b957644":"code","e3a1b007":"code","5dda5f03":"code","79665847":"code","7f766d64":"code","1f47b434":"code","6ba0026f":"code","9971f930":"code","69b3e600":"code","6385475e":"code","cc6fe79c":"code","e1039ec3":"code","341018a8":"code","cf329172":"code","a6a8cbfa":"code","3e46cf2f":"code","7c653602":"code","e71ea734":"code","ac93512b":"code","4127586f":"code","ca6d4257":"code","f90c951e":"code","1d275abd":"code","40c892f0":"code","88afbca1":"code","6fa8b31e":"code","2a73e917":"code","1c3d84e0":"code","2f38a80d":"code","b97763ce":"code","e0cd06cb":"code","652ebe96":"code","4079bac4":"code","be883898":"code","c71944ac":"code","8d88c6d3":"code","248a3322":"code","5975dd91":"code","70c7aa4f":"code","d6b569dc":"code","6aebc3c1":"code","9d50510c":"code","adacaf3a":"code","f96ca094":"code","a32fd3f6":"code","d9c89f2d":"code","c6621d00":"code","309cda07":"code","5de3d5fa":"code","52e90397":"code","885f5ff4":"code","486d045a":"code","abcb3c64":"code","9b125abe":"code","2f5b590f":"code","2d8d152a":"code","36832b16":"code","c14eddbd":"code","20ce86c1":"code","08c6bf0a":"code","7f8bc3df":"code","5a7b62df":"code","c46b4044":"code","92aaedcb":"code","8735e566":"code","b90086e6":"code","8a7335f9":"code","d4d3a7dd":"code","1a48d2fc":"code","ac5eacd5":"code","d0d47ced":"code","5d078d7d":"code","754e541a":"code","fb29aac1":"code","75d9cb8f":"code","cee2c62b":"code","cc8008f4":"code","2a74c43c":"code","f488a5c5":"code","67444099":"code","c3efef2e":"code","d8c1a5e4":"code","8ad292ec":"code","36b2a515":"code","fe81b2d3":"code","0cc21381":"code","49e89686":"code","ea7ccf06":"code","1e0caf0e":"code","8e97a9c9":"code","1230dfac":"code","ef5221f4":"code","91902719":"code","294e65c4":"code","c0437a5d":"code","91ebc291":"code","baf3c02a":"code","4c952d7a":"code","3685fcd2":"code","61b61bb7":"code","859fc0b4":"code","ac252d96":"code","f5c91d31":"code","1f47828c":"code","66c77795":"code","af2719d3":"code","7ac9ec55":"code","4421b8c8":"code","597169c7":"code","df6ffaca":"code","19c1d82a":"code","9dd51188":"code","9c9418b9":"code","b6a1c7dd":"code","0c33e736":"code","eb255349":"code","1dbb7c58":"code","e139a8e7":"code","6187c15b":"code","5f42a155":"code","d0fe8aa2":"code","b1f77bc4":"code","037d0dc8":"code","f6d73140":"code","671b97a3":"code","c7291401":"code","aaa31799":"code","8ea178c0":"code","9922c8ca":"code","eb65cff6":"code","63691030":"code","5e1f1367":"code","e25616f2":"code","ba80791a":"code","8d406bd0":"code","044c628d":"code","64202dc4":"code","fb9a647b":"code","f7dcbc3a":"code","277e575d":"code","16ad3a5e":"code","498c94c3":"code","d9724c6f":"code","0febf549":"code","ace84c59":"code","16431821":"code","eafa1e94":"code","09f5f17f":"code","fc0803fd":"code","e994728d":"code","b21de20e":"code","43fe4fe6":"code","1960dd3e":"code","95ea5e8d":"code","6a4d2cc7":"code","9286cb50":"code","4e772d7c":"code","f6863f65":"code","9f9370fc":"code","1a50f2ac":"code","9735e9ac":"code","55cb88a5":"code","217fc4b0":"code","f5772c51":"code","dc01e48c":"code","0c0e163a":"code","56ce1591":"code","57c580e8":"code","00ab471d":"code","fe41666d":"markdown","a494b640":"markdown","1510ba6e":"markdown","946ca074":"markdown","a1554a88":"markdown","49f03c4b":"markdown","2a452b0c":"markdown","e8bd1af3":"markdown","dac87ee3":"markdown","125ccbca":"markdown","f86ef510":"markdown","cf3fccfc":"markdown","44a9af8a":"markdown","b6058999":"markdown","ef571ab5":"markdown","9f467afb":"markdown","3677a01e":"markdown","85c974db":"markdown","83bcca05":"markdown","a5165466":"markdown","caa9c3ea":"markdown","9dbf619b":"markdown","9615f843":"markdown","583b3d38":"markdown","d68ce105":"markdown","e5588031":"markdown","24a57131":"markdown","f276ab55":"markdown","2654dbfd":"markdown","a6bc83e6":"markdown","733debf0":"markdown","9df144b4":"markdown","c14eed1b":"markdown","39c0f585":"markdown","9b5566e5":"markdown","fa26e7d6":"markdown","56959d06":"markdown","a39c3a00":"markdown","8243ee92":"markdown","3663b2df":"markdown","2bc65c38":"markdown","0d29ce85":"markdown","ac013535":"markdown","48ecd6a4":"markdown","6f7a8251":"markdown","45eb58dc":"markdown","e9762f1a":"markdown","5c685b0b":"markdown","14ca6d3e":"markdown","a9a109c2":"markdown","78faebde":"markdown","16c7cade":"markdown","db533e4f":"markdown","167f4647":"markdown","0a8ea1e5":"markdown","b3ccbe36":"markdown","a63d4770":"markdown","8e351891":"markdown","44dfbbab":"markdown"},"source":{"54f686ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport time, datetime\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import stats\nimport statsmodels.api as sm\n\nimport missingno\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport matplotlib.pylab as pylab\npylab.rcParams['figure.figsize'] = 22, 6 \n\nmpl.style.use(['Solarize_Light2'])\nprint(\"Using style of 'Solarize_Light2' to plot\")\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n# Plot the Figures Inline\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","00a29487":"%load_ext watermark\n%watermark --iversions","c887cb1a":"test_X = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_raw = pd.read_csv(\"..\/input\/titanic\/train.csv\")","e55db268":"ID = test_X['PassengerId'].tolist()","d08dfa14":"train_raw.head(2)","01f7362b":"train_X = train_raw.drop('Survived', axis = 1)\ntrain_y = train_raw['Survived']","402595f0":"train_X.head(2)","bddbfb54":"test_X.head(2)","0c2d2913":"print(f\"The training set is of shape of {train_X.shape}\\nThe testing set is of shape of {test_X.shape}\")","ad1aaf24":"train_X.columns == test_X.columns","21a521f6":"train_X.columns","8b8508f6":"train_X.dtypes == test_X.dtypes","0f7467dc":"train_X.dtypes","2506a9ce":"train_X.info()","bbbf4dc8":"test_X.info()","e24c12f2":"train_X.describe()","77e8001a":"test_X.describe()","f4cd1488":"train_X.describe(include = 'object')","78c9a7d5":"test_X.describe(include = 'object')","dd110e23":"missingno.matrix(train_X)\nplt.show()","173bd643":"missingno.matrix(test_X)\nplt.show()","aa0b3935":"print('Traing set missings info:\\n')\nfor i in train_X.columns:\n    print(f\"\\tFor {i}: missing num is of: {train_X[i].isna().sum()}\")","f9c002b7":"print('Test set missings info:\\n')\nfor i in test_X.columns:\n    print(f\"\\tFor {i}: missing num is of: {test_X[i].isna().sum()}\")","e60c881e":"train_X.columns","861a4a14":"train_Pclass, test_Pclass = set(), set()\nfor i in train_X['Pclass'].unique():\n    train_Pclass.add(i)\nfor j in test_X['Pclass'].unique():\n    test_Pclass.add(j)\n    \nprint(f\"train_X's Pclass column values is of {train_Pclass}\\ntest_X's Pclass column values is of\\\n     {test_Pclass}\\ntest_X's Pclass a subset of train_X's Pclass is: {test_Pclass.issubset(train_Pclass)}\")","8c89b81f":"train_Sex, test_Sex = set(), set()\nfor i in train_X['Sex'].unique():\n    train_Sex.add(i)\nfor j in test_X['Sex'].unique():\n    test_Sex.add(j)\n\nprint(f\"train_X's Sex column values is of {train_Sex}\\ntest_X's Sex column values is of\\\n     {test_Sex}\\ntest_X's Sex a subset of train_X's Sex is: {test_Sex.issubset(train_Sex)}\")","11e88f3e":"train_X_Age_no_nan = train_X['Age'].dropna()\ntrain_X_Age_no_nan = train_X_Age_no_nan.to_numpy()\ntest_X_Age_no_nan = test_X['Age'].dropna()\ntest_X_Age_no_nan = test_X_Age_no_nan.to_numpy()\n\nprint(f\"The range of train_X's Age is of: {train_X_Age_no_nan.max() - train_X_Age_no_nan.min()}\\nThe range of test_X's Age is of:\\\n      {test_X_Age_no_nan.max() - test_X_Age_no_nan.min()}\")","01367776":"train_SibSp, test_SibSp = set(), set()\nfor i in train_X['SibSp'].unique():\n    train_SibSp.add(i)\nfor j in test_X['SibSp'].unique():\n    test_SibSp.add(j)\n    \nprint(f\"train_X's SibSp column values is of {train_SibSp}\\ntest_X's SibSp column values is of\\\n      {test_SibSp}\\ntest_X's SibSp a subset of train_X's SibSp is: {test_SibSp.issubset(train_SibSp)}\")","8fbeecf8":"train_Parch, test_Parch = set(), set()\nfor i in train_X['Parch'].unique():\n    train_Parch.add(i)\nfor j in test_X['Parch'].unique():\n    test_Parch.add(j)\n    \nprint(f\"train_X's Parch column values is of {train_Parch}\\ntest_X's Parch column values is of\\\n     {test_Parch}\\ntest_X's Parch a subset of train_X's Parch is: {test_Parch.issubset(train_Parch)}\")","b1b390d9":"train_X_Fare_no_nan = train_X['Fare'].dropna()\ntrain_X_Fare_no_nan = train_X_Fare_no_nan.to_numpy()\ntest_X_Fare_no_nan = test_X['Fare'].dropna()\ntest_X_Fare_no_nan = test_X_Fare_no_nan.to_numpy()\n\nprint(f\"The range of train_X's Fare is of: {train_X_Fare_no_nan.max() - train_X_Fare_no_nan.min()}\\nThe range of test_X's Fare is of:\\\n     {test_X_Fare_no_nan.max() - test_X_Fare_no_nan.min()}\")","14c8e271":"train_Embarked, test_Embarked = set(), set()\nfor i in train_X['Embarked'].unique():\n    train_Embarked.add(i)\nfor j in test_X['Embarked'].unique():\n    test_Embarked.add(j)\n    \nprint(f\"train_X's Embarked column values is of {train_Embarked}\\ntest_X's Embarked column values is of\\\n     {test_Embarked}\\ntest_X's Embarked a subset of train_X's Embarked is: {test_Embarked.issubset(train_Embarked)}\")","8bf9014b":"train_Cabin, test_Cabin = set(), set()\n\nfor i in train_X['Cabin']:\n    try:\n        train_Cabin.add(i[0])\n    except:\n        train_Cabin.add('U')\n        \nfor i in test_X['Cabin']:\n    try:\n        test_Cabin.add(i[0])\n    except:\n        test_Cabin.add('U')\n        \nprint(f\"train_X's Cabin column values is of {train_Cabin}\\ntest_X's Cabin column values is of\\\n      {test_Cabin}\\ntest_X's Cabin a subset of train_X's cabin is: {test_Cabin.issubset(train_Cabin)}\")","6a832cf4":"train_X['Name'].sample(10)","f5ee52d0":"titles = set()\nfor name in train_X['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\n\nprint(titles)","c85bea14":"title_Dict = {\"Capt\": \"Officer\",\n              \"Col\": \"Officer\",\n              \"Major\": \"Officer\",\n              \"Jonkheer\": \"Royalty\",\n              \"Don\": \"Royalty\",\n              \"Sir\" : \"Royalty\",\n              \"Dr\": \"Officer\",\n              \"Rev\": \"Officer\",\n              \"the Countess\":\"Royalty\",\n              \"Mme\": \"Mrs\",\n              \"Mlle\": \"Miss\",\n              \"Ms\": \"Mrs\",\n              \"Mr\" : \"Mr\",\n              \"Mrs\" : \"Mrs\",\n              \"Miss\" : \"Miss\",\n              \"Master\" : \"Master\",\n              \"Lady\" : \"Royalty\"}","b9c5216f":"train_X.head(2)","a13a2a5e":"def get_titles(df):\n    df['title'] = df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n    df['title'] = df['title'].map(title_Dict)\n    return df","42b11bfc":"train_X = get_titles(train_X)","55eb5335":"train_X.sample(3)","74ada590":"train_X['title'].isna().sum()","b20f9f4d":"train_X['Cabin'].unique()","10dded64":"def process_cabin(df):   \n    df['Cabin'].fillna('U', inplace=True)\n    df['Cabin'] = df['Cabin'].map(lambda i: i[0])\n    return df","c62fcd0d":"train_X = process_cabin(train_X)","6b1092e3":"train_X.sample(2)","5a2091f4":"train_X['Age'].isna().sum()","f8fb1946":"train_X['Age'].describe()","946dd773":"train_X['Age'].mode()","7b957644":"fig = plt.figure(figsize = (22, 4))\nsns.distplot(train_X['Age'].dropna())\nplt.show()","e3a1b007":"train_X_groupd_median = train_X.groupby(['Pclass', 'Sex', 'title']).median()\ntrain_X_groupd_median = train_X_groupd_median.reset_index()[['Pclass', 'Sex', 'title', 'Age']]\ntrain_X_groupd_median","5dda5f03":"def fill_age(row):\n    condition = (\n        (train_X_groupd_median['Sex'] == row['Sex']) & \n        (train_X_groupd_median['title'] == row['title']) & \n        (train_X_groupd_median['Pclass'] == row['Pclass'])\n                ) \n    return train_X_groupd_median[condition]['Age'].values[0]","79665847":"def process_age(df):\n    df['Age'] = df.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis = 1)\n    return df","7f766d64":"train_X = process_age(train_X)","1f47b434":"train_X['Age'].isna().sum()","6ba0026f":"np.where(train_X['Fare'].isna() == True)","9971f930":"np.where(test_X['Fare'].isna() == True)","69b3e600":"train_X['Fare'].median()","6385475e":"np.where(train_X['Embarked'].isna() == True)","cc6fe79c":"train_X.iloc[61]","e1039ec3":"train_X.iloc[829]","341018a8":"np.where(test_X['Embarked'].isna() == True)","cf329172":"train_X['Embarked'].value_counts()","a6a8cbfa":"class_embarked_cross_tab = pd.crosstab(train_X['Embarked'], train_X['Pclass'], margins = False) \nclass_embarked_cross_tab","3e46cf2f":"train_X.loc[829, 'Embarked'] = 'S'\ntrain_X.loc[61, 'Embarked'] = 'S'","7c653602":"for i in train_X.columns:\n    print(f\"For {i}: missing num is of: {train_X[i].isna().sum()}\")","e71ea734":"test_X.head(2)","ac93512b":"test_X = get_titles(test_X)","4127586f":"test_X.sample(2)","ca6d4257":"test_X['title'].isna().sum()","f90c951e":"np.where(test_X['title'].isna() == True)","1d275abd":"test_X.loc[414]","40c892f0":"test_X.loc[414, 'title'] = 'Royalty'","88afbca1":"test_X['title'].isna().sum()","6fa8b31e":"test_X = process_cabin(test_X)","2a73e917":"test_X['Cabin'].isna().sum()","1c3d84e0":"test_X.head(2)","2f38a80d":"test_X = process_age(test_X)","b97763ce":"test_X['Age'].isna().sum()","e0cd06cb":"np.where(test_X['Fare'].isna())","652ebe96":"test_X.loc[152]","4079bac4":"test_X.loc[152, 'Fare'] = train_X['Fare'].median()","be883898":"for i in test_X.columns:\n    print(f\"For {i}: missing num is of: {test_X[i].isna().sum()}\")","c71944ac":"train_X.sample(2)","8d88c6d3":"test_X.sample(2)","248a3322":"train_X['relatives_num'] = train_X['SibSp'] + train_X['Parch']\ntest_X['relatives_num'] = test_X['SibSp'] + test_X['Parch']","5975dd91":"train_X.loc[train_X['relatives_num'] == 0, 'travelled_alone'] = 'Yes'\ntrain_X.loc[train_X['relatives_num'] != 0, 'travelled_alone'] = 'No'","70c7aa4f":"test_X.loc[test_X['relatives_num'] == 0, 'travelled_alone'] = 'Yes'\ntest_X.loc[test_X['relatives_num'] != 0, 'travelled_alone'] = 'No'","d6b569dc":"train_X.loc[train_X['travelled_alone'] == 'Yes']","6aebc3c1":"train_X.sample(2)","9d50510c":"for i in train_X.columns:\n    print(f\"For {i}: missing num is of: {train_X[i].isna().sum()}\")","adacaf3a":"train_X.head(2)","f96ca094":"train_X_y = pd.concat([train_X, train_y], axis = 1)","a32fd3f6":"train_X_y.drop(['PassengerId','Name', 'Ticket'], axis = 1, inplace = True)","d9c89f2d":"train_X_y.head(2)","c6621d00":"train_X_y.dtypes","309cda07":"header_numerical = [\"Age\", \"Fare\"]","5de3d5fa":"header_string = [\"Pclass\", 'Sex', 'Cabin', \"SibSp\", \"Parch\", 'Embarked', 'title', 'travelled_alone', 'Survived']","52e90397":"for i in header_numerical:\n    train_X_y[i] = train_X_y[i].astype(float)","885f5ff4":"for i in header_string:\n    train_X_y[i] = train_X_y[i].astype(str)","486d045a":"header_string","abcb3c64":"for i in header_string:\n    fig = plt.figure(figsize=(22,2))\n    sns.countplot(y = i, data = train_X_y)\n    plt.show()","9b125abe":"header_numerical","2f5b590f":"for i in header_numerical:\n    fig = plt.figure(figsize=(22, 2))\n    sns.distplot(train_X_y[i], kde = True)\n    plt.show()","2d8d152a":"df_class_fare = train_X_y.copy()","36832b16":"df_class_fare[['Pclass', 'Fare']].describe(include = 'all')","c14eddbd":"fig = plt.figure(figsize=(22,2))\nsns.distplot(df_class_fare['Fare'])\nplt.show()","20ce86c1":"df_class_fare_greater_100 = df_class_fare[df_class_fare['Fare'] >= 100]\ndf_class_fare_less_100 = df_class_fare[df_class_fare['Fare'] < 100]","08c6bf0a":"df_class_fare_greater_100.shape","7f8bc3df":"df_class_fare_less_100.shape","5a7b62df":"df_class_fare_greater_100[df_class_fare_greater_100['Pclass'] == '1'].shape","c46b4044":"class_fare_cross_tab_greater_100 = pd.crosstab(df_class_fare_greater_100['Pclass'], df_class_fare_greater_100['Fare'], margins = False) ","92aaedcb":"print(class_fare_cross_tab_greater_100)","8735e566":"cross_tab_greater_100 = sm.stats.Table.from_data(df_class_fare_greater_100[['Pclass', 'Fare']])","b90086e6":"print(cross_tab_greater_100)","8a7335f9":"print(cross_tab_greater_100.table_orig)","d4d3a7dd":"rslt = cross_tab_greater_100.test_nominal_association()\nprint(rslt)","1a48d2fc":"print(cross_tab_greater_100.chi2_contribs)","ac5eacd5":"def plot_distribution(dataset, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    mpl.style.use(['Solarize_Light2'])\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(dataset.shape[1]) \/ cols)\n    for i, column in enumerate(dataset.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        if dataset.dtypes[column] == np.object:\n            g = sns.countplot(y=column, data=dataset)\n            substrings = [s.get_text()[:18] for s in g.get_yticklabels()]\n            g.set(yticklabels=substrings)\n            plt.xticks(rotation=25)\n        else:\n            g = sns.distplot(dataset[column])\n            plt.xticks(rotation=25)","d0d47ced":"plot_distribution(train_X_y, cols=3, width=20, height=15, hspace=0.45, wspace=0.5)\nplt.show()","5d078d7d":"train_X_y.head(2)","754e541a":"train_X_y.dtypes","fb29aac1":"def plot_bivariate_bar(dataset, hue, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    dataset = dataset.select_dtypes(include=[np.object])\n    mpl.style.use(['Solarize_Light2'])\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(dataset.shape[1]) \/ cols)\n    for i, column in enumerate(dataset.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        if dataset.dtypes[column] == np.object:\n            g = sns.countplot(y=column, hue=hue, data=dataset)\n            substrings = [s.get_text()[:10] for s in g.get_yticklabels()]\n            g.set(yticklabels=substrings)","75d9cb8f":"plot_bivariate_bar(train_X_y, hue = 'Survived', cols=3, width=20, height=12, hspace=0.4, wspace=0.5)\nplt.show()","cee2c62b":"# Effect of Embarked on Fare, across Survived.\ng = sns.FacetGrid(train_X_y, col='Embarked', height=4, aspect=.7)\ng = g.map(sns.boxplot, 'Survived', 'Fare')\nplt.show()","cc8008f4":"g = sns.pairplot(data = train_X_y[['Fare', 'Age', 'Pclass', 'Embarked', 'Survived']], hue = 'Survived')\ng.fig.set_figheight(8)\ng.fig.set_figwidth(26)\nplt.show()","2a74c43c":"train_X.drop(['Name', 'Ticket', 'relatives_num'], axis = 1, inplace = True)\ntest_X.drop(['Name', 'Ticket', 'relatives_num'], axis = 1, inplace = True)","f488a5c5":"train_X.head(3)","67444099":"columns_to_enc = ['Pclass', 'Sex', 'Cabin', 'Embarked', 'title', 'travelled_alone']","c3efef2e":"train_X_le = train_X[columns_to_enc]","d8c1a5e4":"le = LabelEncoder()","8ad292ec":"train_X_label_enc = train_X_le.apply(le.fit_transform)","36b2a515":"train_X_label_enc","fe81b2d3":"for i in train_X_le.columns:\n    arr = train_X_le[i].unique()\n    le_arr = train_X_label_enc[i].unique()\n    print(f'Following is the name\/label code for {i}:')\n    for j, k in zip(arr, le_arr):\n        print(f\"{j}'s code after label encoding is: {k}\")\n    print(f'\\n')","0cc21381":"test_X_le = test_X[columns_to_enc]","49e89686":"test_X_le","ea7ccf06":"test_X_label_enc = test_X_le.apply(le.fit_transform)","1e0caf0e":"test_X_label_enc","8e97a9c9":"for i in test_X_le.columns:\n    arr = test_X_le[i].unique()\n    le_arr = test_X_label_enc[i].unique()\n    print(f'Following is the name\/label code for {i}:')\n    for j, k in zip(arr, le_arr):\n        print(f\"{j}'s code after label encoding is: {k}\")\n    print(f'\\n')","1230dfac":"test_X_le","ef5221f4":"make_up_obs_dict = {'Pclass': 1, 'Sex': 'male', 'Cabin': 'T', 'Embarked': 'C', 'title': 'Mr', 'travelled_alone': 'No'}","91902719":"make_up_obs_df = pd.DataFrame([make_up_obs_dict])","294e65c4":"test_X_le = pd.concat([test_X_le, make_up_obs_df], ignore_index=True)","c0437a5d":"test_X_le","91ebc291":"test_X_label_enc = test_X_le.apply(le.fit_transform)","baf3c02a":"for i in test_X_le.columns:\n    arr = test_X_le[i].unique()\n    le_arr = test_X_label_enc[i].unique()\n    print(f'Following is the name\/label code for {i}:')\n    for j, k in zip(arr, le_arr):\n        print(f\"{j}'s code after label encoding is: {k}\")\n    print(f'\\n')","4c952d7a":"test_X_label_enc.tail(3)","3685fcd2":"test_X_label_enc.drop(418, inplace = True)","61b61bb7":"test_X_label_enc.tail(2)","859fc0b4":"one_hot_enc = OneHotEncoder()","ac252d96":"train_X_hot_enc = one_hot_enc.fit_transform(train_X_label_enc).toarray()","f5c91d31":"train_X_hot_enc","1f47828c":"train_X_hot_enc.shape","66c77795":"test_X_hot_enc = one_hot_enc.transform(test_X_label_enc).toarray()","af2719d3":"test_X_hot_enc","7ac9ec55":"test_X_hot_enc.shape","4421b8c8":"train_X.head(3)","597169c7":"columns_to_scale = ['PassengerId', 'Age', 'SibSp', 'Parch', 'Fare']","df6ffaca":"train_X_scale = train_X[columns_to_scale]","19c1d82a":"train_X_scale.head(2)","9dd51188":"sc = StandardScaler()","9c9418b9":"train_X_scale = sc.fit_transform(train_X_scale)","b6a1c7dd":"train_X_scale","0c33e736":"train_X_scale.shape","eb255349":"test_X_scale = test_X[columns_to_scale]","1dbb7c58":"test_X_scale = sc.transform(test_X_scale)","e139a8e7":"test_X_scale","6187c15b":"test_X_scale.shape","5f42a155":"train_X_arr = np.hstack((train_X_hot_enc, train_X_scale))\ntest_X_arr = np.hstack((test_X_hot_enc, test_X_scale))","d0fe8aa2":"train_X_arr.shape","b1f77bc4":"test_X_arr.shape","037d0dc8":"train_y_arr = train_y.values","f6d73140":"train_y_arr.shape","671b97a3":"train_X_df = pd.DataFrame(train_X_arr)\ntest_X_df = pd.DataFrame(test_X_arr)","c7291401":"train_X_df.head(2)","aaa31799":"print(train_X_hot_enc[0])\nprint(train_X_hot_enc[1])","8ea178c0":"test_X_df.head(2)","9922c8ca":"print(test_X_hot_enc[0])\nprint(test_X_hot_enc[1])","eb65cff6":"dict_1 = {0: 'Pclass_1', 1: 'Pclass_2', 2: 'Pclass_3',\n          3: 'Sex_male', 4: 'Sex_female',\n          5: 'Cabin_U', 6: 'Cabin_B', 7: 'Cabin_E', 8: 'Cabin_A', 9: 'Cabin_C', 10: 'Cabin_D', 11: 'Cabin_F', 12: 'Cabin_G', 13: 'Cabin_T',\n          14: 'Embarked_Q', 15: 'Embarked_S', 16: 'Embarked_C',\n          17: 'title_Mr', 18: 'title_Mrs', 19: 'title_Miss', 20: 'title_Master', 21: 'title_Officer', 22: 'title_Royalty',\n          23: 'travelled_alone_Yes', 24: 'travelled_alone_No'}","63691030":"dict_2 = {25: 'PassengerId',\n          26: 'Age',\n          27: 'SibSp',\n          28: 'Parch',\n          29: 'Fare'}","5e1f1367":"dict_1.update(dict_2)","e25616f2":"dict_1","ba80791a":"train_X_df.rename(columns = dict_1, inplace = True)\ntest_X_df.rename(columns = dict_1, inplace = True)","8d406bd0":"train_X_df.head(2)","044c628d":"test_X_df.head(2)","64202dc4":"clf_svc = svm.SVC()","fb9a647b":"clf_svc.fit(train_X_arr, train_y_arr)","f7dcbc3a":"pred_clf_svc = clf_svc.predict(test_X_arr)","277e575d":"result_svc = pd.DataFrame([ID, pred_clf_svc])\nresult_svc = result_svc.T\nresult_svc.columns = ['PassengerId', 'Survived']\nresult_svc.to_csv('result_svc_OneHot.csv')","16ad3a5e":"clf_logit = LogisticRegression()","498c94c3":"clf_logit.fit(train_X_arr, train_y_arr)","d9724c6f":"pred_clf_logit = clf_logit.predict(test_X_arr)","0febf549":"result_logit = pd.DataFrame([ID, pred_clf_logit])\nresult_logit = result_logit.T\nresult_logit.columns = ['PassengerId', 'Survived']\nresult_logit.to_csv('result_logit_one_hot.csv')","ace84c59":"clf_dt = DecisionTreeClassifier()","16431821":"clf_dt.fit(train_X_arr, train_y_arr)","eafa1e94":"pred_clf_dt = clf_dt.predict(test_X_arr)","09f5f17f":"result_dt = pd.DataFrame([ID, pred_clf_dt])\nresult_dt = result_dt.T\nresult_dt.columns = ['PassengerId', 'Survived']\nresult_dt.to_csv('result_dt_one_hot.csv')","fc0803fd":"clf_rf = RandomForestClassifier()","e994728d":"clf_rf.fit(train_X_arr, train_y_arr)","b21de20e":"pred_clf_rf = clf_rf.predict(test_X_arr)","43fe4fe6":"result_rf = pd.DataFrame([ID, pred_clf_rf])\nresult_rf = result_rf.T\nresult_rf.columns = ['PassengerId', 'Survived']\nresult_rf.to_csv('result_rf_one_hot.csv')","1960dd3e":"clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf = clf.fit(train_X_df, train_y)","95ea5e8d":"features = pd.DataFrame()\nfeatures['feature'] = train_X_df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(22,8))\nplt.show()","6a4d2cc7":"features.sort_values(by = 'importance', ascending = False)","9286cb50":"features_subset = features[features['importance'] > 0.01]","4e772d7c":"features_subset = features_subset.index.tolist()\nfeatures_subset","f6863f65":"train_X_df_subset = train_X_df[features_subset]\ntest_X_df_subset = test_X_df[features_subset]","9f9370fc":"train_X_df_subset.columns == test_X_df_subset.columns","1a50f2ac":"clf_svc = svm.SVC()","9735e9ac":"clf_svc.fit(train_X_df_subset, train_y)","55cb88a5":"pred_clf_svc = clf_svc.predict(test_X_df_subset)","217fc4b0":"result_svc = pd.DataFrame([ID, pred_clf_svc])\nresult_svc = result_svc.T\nresult_svc.columns = ['PassengerId', 'Survived']\nresult_svc.to_csv('result_svc_one_hot_subset.csv')","f5772c51":"clf_svc = svm.SVC()","dc01e48c":"param_grid = {'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100], \n              'gamma': [1, 0.1, 0.01, 0.001],\n              'kernel': ['rbf', 'poly', 'sigmoid']}\n\ngrid = GridSearchCV(estimator=clf_svc,\n                    param_grid=param_grid,\n                    scoring='accuracy',\n                    verbose=1,\n                    n_jobs=-1)\ngrid_result = grid.fit(train_X_arr, train_y_arr)\n\nprint('Best Score: ', grid_result.best_score_)\nprint('Best Params: ', grid_result.best_params_)","0c0e163a":"clf_svc_one_hot_searched_params = svm.SVC(C=30, \n                                          gamma=0.01, \n                                          kernel='rbf')","56ce1591":"clf_svc_one_hot_searched_params.fit(train_X_arr, train_y_arr)","57c580e8":"pred_svc_searched_params = clf_svc_one_hot_searched_params.predict(test_X_arr)","00ab471d":"result_svc_one_hot_searched_params = pd.DataFrame([ID, pred_svc_searched_params])\nresult_svc_one_hot_searched_params = result_svc_one_hot_searched_params.T\nresult_svc_one_hot_searched_params.columns = ['PassengerId', 'Survived']\nresult_svc_one_hot_searched_params.to_csv('result_svc_one_hot_searched_params.csv')","fe41666d":"# First glance of data","a494b640":"### Age nan","1510ba6e":"# Preliminary feature engineering of train_X","946ca074":"all statsmodel's metrics shows correctly by saying df(degree of freedom) = 0 with a p_value of nan since all Fare >= 100 is Pclass = 1, should get meaningful numbers when it applies on the Fare < 100 subset","a1554a88":"# Data Viz","49f03c4b":"OK, now we combine hot-encoded arrays with scaled ones into traing and testing set","2a452b0c":"Only check train_X's Name for titles since we don't touch test_X","e8bd1af3":"### One-Hot Encoding columns of ['Pclass', 'Sex', 'Cabin', 'Embarked', 'title', 'travelled_alone']","dac87ee3":"# Hyper parameter tuning (grid search is needed for potential 'better' params)","125ccbca":"### Cabin nan","f86ef510":"For Name column, I don't see useful info at first glance, the reason is mainly becoz the only useful info is its embeddings of \"Mr\", \"Miss\" and \"Mrs\" etc., but those info are already presented in the features such as Sex & Age, however, when check in deep, it also contains info such as 'Matser.', 'Dr.' and many other status-showing titles even for Royalties becoz in early 1900s, many european passengers on board still use traditioanl titles, thus, it not only provides info on Sex & Age, but other important info of status as well, so we'll need to extract that info.\n","cf3fccfc":"### SVC worse\n0.78468","44a9af8a":"1. train_X_arr\n1. train_y_arr\n1. test_X_arr","b6058999":"### OR:\n\nhttps:\/\/www.statsmodels.org\/stable\/contingency_tables.html\n","ef571ab5":"# Build base-line models (all params are default)","9f467afb":"### Name -> title\n\nExtract info from Name and derive a new column of \"title\"\n","3677a01e":"# Using Random-Forest to check feature importance","85c974db":"### Derive a new column of \"relative_num\"","83bcca05":"# Value check for some columns from train_X and test_X to see if there are any exceptions, tho not much helpful when we do One-Hot encoding, it still serves as a good comparison b\/w train_X & test_X","a5165466":"We see this lady is a Dona, which is a counterpart of Don for males, so change it to 'Royalty'","caa9c3ea":"### Random Forest","9dbf619b":"### Decision Tree","9615f843":"### SVC worse","583b3d38":"# Re-run the base-line model","d68ce105":"And we also know the feature names for the varibales that been feature scaled:","e5588031":"We now define a dict for later information extraction of Name column","24a57131":"Decide to impute Miss. Amelie & Mrs. George Nelson's start port with 'S' for it's the mode for Pclass == 1","f276ab55":"Wanna see if high priced fare is also high class","2654dbfd":"### SVC","a6bc83e6":"### Fare nan","733debf0":"### Embarked nan\u00b6","9df144b4":"OK, looks like it matches the record, we just need to know what columns 0 - 24 really are, we do know that info","c14eed1b":"### Subsetting features","39c0f585":"PassengerId\nAge\t\nSibSp\t\nParch\t\nFare","9b5566e5":"### Name -> title\n\nExtract info from Name and derive a new column of \"title\"","fa26e7d6":"### Cabin nan","56959d06":"So the high Fare(Fare>=100) is indeed associated with high Pclass (100%)","a39c3a00":"fill na with granuality of \"Pclass\", \"Sex\" and \"title\"","8243ee92":"### Feature scaling of continous variables","3663b2df":"## NOTE: \n1. I have played with this data for a quite while, so I know where the tweak it needs, thus, some certain steps I did when you might think odd is because I know it needed for the following steps, after all, the lesson is that the more you know your data in hand, the better you can come up with at the end.  \n2. I did not show metrics (accuracy\/recall\/precision\/roc\/auc etc.) since we don't have y_test, that's what Kaggle prevent us from getting cheat. \n3. The model I got so far only achieves 0.804 when predicted results submitted, so there still have a lot of improvements can be done\n4. But that's not for today, a good Friday night, maybe later, peace out!","2bc65c38":"### Logistic","0d29ce85":"### Age nan\nImpute this using the same strategy that were employed on train_X","ac013535":"Looks like way more than half of ppl traveled alone","48ecd6a4":"### Multi-variate cross checking","6f7a8251":"So, when fillna in test_X, we need to impute that nan with train_X median","45eb58dc":"### Fare nan","e9762f1a":"So use above searched params","5c685b0b":"We see this one is a Pclass == 3 passenger, we impute with train_X's Fare median","14ca6d3e":"A liitle divert for the interesting contingency table analysis","a9a109c2":"### Uni-variate checking","78faebde":"OK, now both datasets have the same label encodings and don't forget to delete the last make-up obs","16c7cade":"# For future explicit use, I re-construct the DataFrame from ndarrays for train_X & test_X","db533e4f":"# Deep feature engineering of both train_X & test_X","167f4647":"A little divert here just for the interesting contingency table","0a8ea1e5":"One problem is that for Cabin , there ani't no 'T' in test_X, so need a little tweak on that, other features share the same strategy for both.\nWhat I do is make a new obs at the end with value 'T' and do it again, after that, we delete that make-up obsdataset","b3ccbe36":"# Label Encoding columns of ['Pclass', 'Sex', 'Cabin', 'Embarked', 'title', 'travelled_alone']","a63d4770":"# Preliminary feature engineering of test_X","8e351891":"OK, re-do label encoding","44dfbbab":"Plotting each feature's distribution-wise figure in a single summary graph"}}