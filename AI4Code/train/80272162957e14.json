{"cell_type":{"5d92efaa":"code","20320206":"code","8aa09fd3":"code","68f258d0":"code","a3bb0bd9":"code","a57fe0e8":"code","b130e15f":"code","54534472":"code","a65f333b":"code","83044b81":"code","655d58fe":"markdown","cae3fe85":"markdown","c1dcd56e":"markdown","4724cee4":"markdown","1bb83be8":"markdown","36894dca":"markdown","7b3ec63d":"markdown","67c18a0b":"markdown","517aee6f":"markdown","069cb541":"markdown","4a8eabfd":"markdown","bd64f35f":"markdown"},"source":{"5d92efaa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ndataset = pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")","20320206":"dataset.info()","8aa09fd3":"dataset.head()","68f258d0":"X = dataset.iloc[:, 1:8] #All rows and all columns except first and last ones are independent variables. \nX.head()","a3bb0bd9":"y = dataset.iloc[:, 8] #Only the last column in our data is the dependent variable column. \ny.head()","a57fe0e8":"from sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 1\/5, random_state=0)","b130e15f":"#Fitting SVR for the training sets\nfrom sklearn.svm import SVR\nregressor_SVR = SVR (kernel ='linear') #default kernel is 'rbf'.\nregressor_SVR.fit(train_X, train_y)\n\n#Making the necessary predictions\npreds = regressor_SVR.predict(test_X)\n\n#Measuring the accuracy\nfrom sklearn.metrics import r2_score,mean_absolute_error\nprint(f'R^2 score: {r2_score(test_y, preds):.2f}')\nprint(f'MAE: {mean_absolute_error(test_y, preds):.2f}')\n","54534472":"#Fitting Decision Tree Regressor to training sets\nfrom sklearn.tree import DecisionTreeRegressor\nregressor_Tree = DecisionTreeRegressor (random_state = 0)\nregressor_Tree.fit (train_X, train_y)\n\n#Making the necessary predictions\npreds_Tree = regressor_Tree.predict(test_X)\n\n#Measuring the accuracy\nfrom sklearn.metrics import r2_score,mean_absolute_error\nprint(f'R^2 score: {r2_score(test_y, preds_Tree):.2f}')\nprint(f'MAE: {mean_absolute_error(test_y, preds_Tree):.2f}')\n","a65f333b":"#Fitting Random Forest Regressor to training sets\nfrom sklearn.ensemble import RandomForestRegressor\nregressor_Forest = RandomForestRegressor (random_state = 0, n_estimators = 50)\n#n_estimators is the number of trees we want to generate. \n#For n_estimators=10, R^2 score: 0.73; MAE:0.05\n#For n_estimators=20, R^2 score: 0.75; MAE:0.05\n#For n_estimators=30, R^2 score: 0.76; MAE:0.04\n#For n_estimators=40, R^2 score: 0.77; MAE:0.04\n#For n_estimators=50, R^2 score: 0.76; MAE:0.04\n#So we see that after 40 trees, the R^2 score decreases and hence the most optimum no. of trees is 40, which gives the best predictions. \nregressor_Forest.fit (train_X, train_y)\n\n#Making the necessary predictions\npreds_Forest = regressor_Forest.predict(test_X)\n\n#Measuring the accuracy\nfrom sklearn.metrics import r2_score,mean_absolute_error\nprint(f'R^2 score: {r2_score(test_y, preds_Forest):.2f}')\nprint(f'MAE: {mean_absolute_error(test_y, preds_Forest):.2f}')","83044b81":"from xgboost.sklearn import XGBClassifier\nclassifier_XGB = XGBClassifier()\nclassifier_XGB.fit(train_X, train_y)\n\npreds_XGB = classifier_XGB.predict(test_X)\n\nfrom sklearn.metrics import r2_score,mean_absolute_error\nprint(f'R^2 score: {r2_score(test_y, preds_Forest):.2f}')\nprint(f'MAE: {mean_absolute_error(test_y, preds_Forest):.2f}')","655d58fe":"## **4. XGBoost**","cae3fe85":"The CSV file has 500 non-null columns with `integer` and `float` values. \n\nAnd our dataset looks like this. ","c1dcd56e":"Our `dataset` has the following columns :\n- **Serial No.** - Mentions the number of candidate for whom the details are listed. \n- **GRE Score** - GRE Score of the candidate, out of 340.\n- **TOEFL Score** - TOEFL Score of the candidate, out of 120.\n- **University Rating** - The rating of the university which the candidate has applied for, according to pre-applied parameters, out of 5.\n- **SOP** - A qualitative score of Statement of Purpose, out of 5. \n- **LOR** -  A qualitative score of Letter of Recommendation, out of 5. \n- **CGPA** - Averaged CGPA of the candidate in his Under-Graduate period, out of 10.\n- **Research** - Whether the candidate has any research experience while doing UG, 0 or 1. \n- **Chance of Admit** - The chance of admit of the candidate, based on all other factors, expressed as a floating point number, on a range of 0 to 1.","4724cee4":"# **Data Preprocessing**\n<br>\nLet's first slice the `dataset` into two sets - independent variable dataframe `X` and dependent variable array `y`.","1bb83be8":"# **Introduction**\nAdmission to US universities are based on several criterias, some of which include :\n- **A good GRE score (out of 340)** - The GRE aims to measure verbal reasoning, quantitative reasoning, analytical writing, and critical thinking skills that have been acquired over a long period of learning. The content of the GRE consists of certain specific algebra, geometry, arithmetic, and vocabulary. The GRE is owned and administered by Educational Testing Service (ETS). The test was established in 1936 by the Carnegie Foundation for the Advancement of Teaching.\n- **A respectable TOEFL score (out of 120)** - Test of English as a Foreign Language (TOEFL) is a standardized test to measure the English language ability of non-native speakers wishing to enroll in English-speaking universities. The test is accepted by many English-speaking academic and professional institutions. \n- **A detailed Statement of Purpose** - SOP, or Statement of Purpose, is an essay that you write on your life. It contains many different stories about you, such as your experience, tasks assigned to you, research work etc.\n- **A Letter of Recommendation from a reputable source** - A recommendation letter or letter of  recommendation is a letter in which the writer assesses the qualities,  characteristics, and capabilities of the person being recommended in  terms of that individual\u2019s ability to perform a particular task or  function  \u2013 in this case getting admitted to the graduate programme at some  university.\n\n**This dataset collects data from many students about all of these above characteristics and some more criterias in a float or integer format and tells us whether that candidate was granted admission or not. At the end of this notebook, we will have built a predictor for university admission which takes input (described in the coming steps) and outputs chance of admission in an university.**\n\n# **Accessing the data**","36894dca":"## **3. Random Forest Regression**","7b3ec63d":"# **Applying algorithms**\n<br>\nThe first intuition we can derive from the above data is that this is a **regression problem**, as we have to predict a value, i.e., the percentage chance of admission. The chance of admit is ought to depend on all the other columns of the above data, via different weightages, like we can say instinctively that if a candidate has been involved in a research project in his Bachelors, he will have a better chance of admission, but if a candidate has very good exam scores, a fantasic SoP and LoR and also a commendable GPA but no research project, he should theoretically get an admit too. \n\nThe best way to see which algorithm does the finest is the plain old hit and trial method. In this notebook, we will each and every regression algorithm to this data and check out the regression metrics to find out accuracy and conclude then which algorithm does the best for this data.","67c18a0b":"Now, we divide these `X` and `y` dataframes into training and test sets to apply algorithms and make predictions respectively. ","517aee6f":"# **Teasing the data more**","069cb541":"## **1. Support Vector Regression**","4a8eabfd":"## **2. Decision Tree Regression**","bd64f35f":"# **Conclusion**\n\nWe find out via trial and error that **Random Forest Regression with 50 trees** and **XGBoost** gives us the best estimation. And that is how we will proceed in predictions. "}}