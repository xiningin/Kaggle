{"cell_type":{"616585dc":"code","b37e3416":"code","5aceb574":"code","f53a291c":"code","586e4c2a":"code","01a4c712":"code","ee0f054e":"code","9563745c":"code","0756552a":"code","36433ceb":"code","87e03e72":"markdown","e3ce062b":"markdown","d4ff0ff0":"markdown","c8008082":"markdown"},"source":{"616585dc":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom tqdm import tqdm_notebook\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.mixture import GaussianMixture\nimport warnings\nwarnings.filterwarnings('ignore')","b37e3416":"n_folds = 5\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\nprint(train.shape, test.shape)","5aceb574":"from sklearn.covariance import GraphicalLasso\n\ndef get_mean_cov(x,y):\n    model = GraphicalLasso()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    model.fit(x2)\n    p1 = model.precision_\n    m1 = model.location_\n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    model.fit(x2b)\n    p2 = model.precision_\n    m2 = model.location_\n    \n    ms = np.stack([m1,m2])\n    ps = np.stack([p1,p2])\n    return ms,ps","f53a291c":"oof = np.zeros(len(train))\n\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n    for train_index, val_index in skf.split(train2, train2['target']):\n\n        clf = QuadraticDiscriminantAnalysis(0.5)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof[idx1[val_index]] = clf.predict_proba(train3[val_index,:])[:,1]\n\nauc = roc_auc_score(train['target'], oof)\nprint(f'AUC: {auc:.5}')","586e4c2a":"new_train = train.copy()\nnew_train.loc[oof > 0.98, 'target'] = 1\nnew_train.loc[oof < 0.02, 'target'] = 0","01a4c712":"oof_gm = np.zeros(len(train))\noof_bc_qda = np.zeros(len(train))\noof_bc_knn = np.zeros(len(train))\noof_svc = np.zeros(len(train))\n\npreds_gm = np.zeros(len(test))\npreds_bc_qda = np.zeros(len(test))\npreds_bc_knn = np.zeros(len(test))\npreds_svc = np.zeros(len(test))\n\nfor i in tqdm_notebook(range(512)):\n\n    train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n    for train_index, val_index in skf.split(train2, train2['target']):\n\n        clf_qda = QuadraticDiscriminantAnalysis(0.5)        \n        clf = BaggingClassifier(base_estimator=clf_qda, n_estimators=40, n_jobs=-1, random_state=42)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_bc_qda[idx1[val_index]] = clf.predict_proba(train3[val_index,:])[:,1]\n        preds_bc_qda[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf_knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n        clf = BaggingClassifier(base_estimator=clf_knn, n_estimators=40, n_jobs=-1, random_state=42)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_bc_knn[idx1[val_index]] = clf.predict_proba(train3[val_index,:])[:,1]\n        preds_bc_knn[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n\n        clf_svc = SVC(random_state=42, probability=True)\n        clf_svc.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_svc[idx1[val_index]] = clf_svc.predict_proba(train3[val_index,:])[:,1]\n        preds_svc[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n\n        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001, reg_covar=0.001, max_iter=100, n_init=1, means_init=ms, precisions_init=ps)\n        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        oof_gm[idx1[val_index]] = gm.predict_proba(train3[val_index,:])[:,0]\n        oof_gm[idx2] += gm.predict_proba(test3)[:,0] \/ skf.n_splits\n\nauc = roc_auc_score(train['target'], oof_bc_qda)\nprint(f'AUC bc qda: {auc:.5}')\n\nauc = roc_auc_score(train['target'], oof_svc)\nprint(f'AUC svc: {auc:.5}')\n\nauc = roc_auc_score(train['target'], oof_bc_knn)\nprint(f'AUC bc knn: {auc:.5}')\n\nauc = roc_auc_score(train['target'], oof_gm)\nprint(f'AUC gm: {auc:.5}')","ee0f054e":"preds_blend1 = 0.68*preds_gm + 0.32*preds_svc\npreds_blend = 0.55*preds_bc_qda + 0.25*preds_blend1 + 0.2*preds_bc_knn\n\noof_blend1 = 0.68*oof_gm + 0.32*oof_svc\noof_blend = 0.55*oof_bc_qda + 0.25*oof_blend1 + 0.2*oof_bc_knn\n\nauc = roc_auc_score(train['target'], oof_blend)\nprint(f'AUC: {auc:.7}')","9563745c":"for itr in range(2):\n    \n    test['target'] = preds_blend\n    test.loc[test['target'] > 0.60, 'target'] = 1\n    test.loc[test['target'] < 0.40, 'target'] = 0\n        \n    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n    print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n    oof_gm = np.zeros(len(train))\n    oof_bc_qda = np.zeros(len(train))\n    oof_bc_knn = np.zeros(len(train))\n    oof_svc = np.zeros(len(train))\n    preds_gm = np.zeros(len(test))\n    preds_bc_qda = np.zeros(len(test))\n    preds_knn = np.zeros(len(test))\n    preds_svc = np.zeros(len(test))\n    \n    for i in tqdm_notebook(range(512)):\n\n        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n        idx2 = test2.index\n        train2.reset_index(drop=True,inplace=True)\n\n        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n        pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n        data2 = pipe.fit_transform(data[cols])\n        train3 = data2[:train2.shape[0]]\n        test3 = data2[train2.shape[0]:]\n\n        skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n        for train_index, val_index in skf.split(train2, train2['target']):\n            oof_val_index = [t for t in val_index if t < len(idx1)]\n            \n            clf_qda = QuadraticDiscriminantAnalysis(0.5)            \n            clf = BaggingClassifier(base_estimator=clf_qda, n_estimators=40, n_jobs=-1, random_state=42)\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_val_index) > 0:\n                oof_bc_qda[idx1[oof_val_index]] = clf.predict_proba(train3[oof_val_index,:])[:,1]\n            preds_bc_qda[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n                \n            clf_knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)            \n            clf = BaggingClassifier(base_estimator=clf_knn, n_estimators=40, n_jobs=-1, random_state=42)\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_val_index) > 0:\n                oof_bc_knn[idx1[oof_val_index]] = clf.predict_proba(train3[oof_val_index,:])[:,1]\n            preds_bc_knn[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n                \n            clf = SVC(random_state=42, probability=True)\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_val_index) > 0:\n                oof_svc[idx1[oof_val_index]] = clf.predict_proba(train3[oof_val_index,:])[:,1]\n            preds_svc[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n            \n            ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n            gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001, reg_covar=0.001, max_iter=100, n_init=1, means_init=ms, precisions_init=ps)\n            gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n            if len(oof_val_index) > 0:\n                oof_gm[idx1[oof_val_index]] = gm.predict_proba(train3[oof_val_index,:])[:,0]\n            preds_gm[idx2] += gm.predict_proba(test3)[:,0] \/ skf.n_splits\n    \n    auc = roc_auc_score(train['target'], oof_bc_qda)\n    print(f'AUC bc qda: {auc:.5}')\n\n    auc = roc_auc_score(train['target'], oof_svc)\n    print(f'AUC svc: {auc:.5}')\n\n    auc = roc_auc_score(train['target'], oof_bc_knn)\n    print(f'AUC bc knn: {auc:.5}')\n\n    auc = roc_auc_score(train['target'], oof_gm)\n    print(f'AUC gm: {auc:.5}')\n    \n    preds_blend1 = 0.68*preds_gm + 0.32*preds_svc\n    preds_blend = 0.55*preds_bc_qda + 0.25*preds_blend1 + 0.2*preds_bc_knn\n\n    oof_blend1 = 0.68*oof_gm + 0.32*oof_svc\n    oof_blend = 0.55*oof_bc_qda + 0.25*oof_blend1 + 0.2*oof_bc_knn\n\n    auc = roc_auc_score(train['target'], oof_blend)\n    print(f'AUC blend: {auc:.7}')","0756552a":"import matplotlib.pyplot as plt\nplt.hist(preds_blend,bins=100)\nplt.title('Final Test.csv predictions')\nplt.show()","36433ceb":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nif len(test) != 131073:\n    sub['target'] = preds_blend\nsub.to_csv('submission.csv',index=False)","87e03e72":"## QDA + KNN + SVC + GaussianMixture","e3ce062b":"## Add pseudo label","d4ff0ff0":"## First QDA to flip labels","c8008082":"## Flip labels"}}