{"cell_type":{"d5046ed9":"code","9f0e4991":"code","30f39f19":"code","36d3b77e":"code","850961ba":"code","bc08147e":"code","e3a38a05":"code","dcdcf8bc":"code","ddb77a1b":"code","5f528ad7":"code","9d4693f8":"code","f7fb33fe":"code","503a795b":"code","5513d46f":"code","51348d51":"code","451bc144":"code","2d0533fd":"code","182ffcf4":"code","21a6135f":"code","0074d2f5":"code","39b857d0":"code","548a31f6":"code","6bfb270c":"code","c1a58306":"code","0d56bb9e":"code","425f3e1b":"code","23efd7de":"code","6634e0b4":"code","3ea0a26b":"code","d181548b":"code","691647ce":"code","632e19e5":"code","2b75da7e":"code","db09dfca":"code","859bbb26":"code","dd5641d4":"code","e068bdd8":"code","cdbd2b25":"code","50b55070":"code","b499769f":"code","5e5dbded":"code","a55bbe9e":"code","88242700":"code","5caadc8e":"code","a7bca405":"code","c3a88696":"code","8229d7c2":"code","d8cac26f":"code","7c902db8":"code","fa9c59da":"code","b31f0ecf":"code","f6d728a0":"code","cf63791c":"code","0bf6c5a9":"code","0c3a9894":"code","24a6306d":"code","cdd50cf9":"code","7b8b14eb":"code","e8883ad7":"code","f3333c80":"code","b8943f09":"code","a472e443":"code","03b4f74a":"markdown","7777d224":"markdown","f2abd98f":"markdown","4e3660de":"markdown","103dc0d2":"markdown","2de85e52":"markdown","03f09df3":"markdown","2f0c051b":"markdown","2d738bac":"markdown","6e430cbf":"markdown","e92c08c4":"markdown","d8fa91a8":"markdown","059a60d3":"markdown","07110f39":"markdown","3376da9b":"markdown","86a01f1e":"markdown","7ee55b47":"markdown","acdf81a1":"markdown","67b56ea7":"markdown","daceade0":"markdown","22774263":"markdown","8dfd35b6":"markdown","73452372":"markdown","32cef595":"markdown","c892069c":"markdown","def255ff":"markdown","264b4af3":"markdown","88da861e":"markdown","7d27744c":"markdown","0d43aab3":"markdown","5538259d":"markdown","bee2c697":"markdown","e9000d60":"markdown","1925038b":"markdown","c2e3819d":"markdown","5329b344":"markdown","636ca175":"markdown","f78fc574":"markdown","4c17bde5":"markdown","c4010de6":"markdown","2ba51853":"markdown","b92c1525":"markdown","0c796d6d":"markdown"},"source":{"d5046ed9":"import os\nprint(os.listdir(\"..\/input\"))","9f0e4991":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","30f39f19":"# This is how we assign the datasets to variables in python using pandas.\ntrain=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","36d3b77e":"train.head()","850961ba":"test.head()","bc08147e":"#To get the number of rows and columns of the dataset\ntrain.shape","e3a38a05":"test.shape","dcdcf8bc":"#Gives us statistical information about the dataset\ntrain.describe()","ddb77a1b":"train.isnull().sum()","5f528ad7":"test.isnull().sum()","9d4693f8":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","f7fb33fe":"sns.set_style(\"whitegrid\")\nsns.countplot(x='Survived',data=train,palette='viridis')","503a795b":"train.Pclass.value_counts()","5513d46f":"train.groupby('Pclass').Survived.value_counts()","51348d51":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","451bc144":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=train,palette='rainbow')","2d0533fd":"train.Sex.value_counts()","182ffcf4":"train.groupby('Survived').Sex.value_counts()","21a6135f":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=train,palette='RdBu_r')","0074d2f5":"tab = pd.crosstab(train['Pclass'], train['Sex'])\nprint (tab)","39b857d0":"sns.distplot(train['Age'].dropna(),kde=False,color='darkred',bins=30)","548a31f6":"sns.countplot(x='SibSp',data=train)","6bfb270c":"train['Fare'].hist(color='green',bins=40,figsize=(8,4))","c1a58306":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=train,palette='winter')","0d56bb9e":"#We are doing this because the test doesn't have the Target column.\ntrain2=train.drop('Survived',axis=1)","425f3e1b":"#We are combining train and test dataset as it will be easier for us to process the data together.\ndata = train2.append(test,sort=False)","23efd7de":"data.head()","6634e0b4":"#We drop the PassengerId column as the values from this column wont contribute to our model.\ndata.drop(['PassengerId'],axis=1,inplace=True)","3ea0a26b":"data['Title'] =data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\ndata['Name_Len'] = data['Name'].apply(lambda x: len(x))\ndata.drop(labels='Name', axis=1, inplace=True)","d181548b":"data.Name_Len = (data.Name_Len\/10).astype(np.int64)+1","691647ce":"training_age_n = data.Age.dropna(axis=0)","632e19e5":"fx, axes = plt.subplots(1, 2, figsize=(15,5))\naxes[0].set_title(\"Age vs frequency\")\naxes[1].set_title(\"Age vise Survival rate\")\nfig1_age = sns.distplot(a=training_age_n, bins=15, ax=axes[0], hist_kws={'rwidth':0.7})\n\n# Creating a new list of survived and dead\n\npass_survived_age = train[train.Survived == 1].Age\npass_dead_age = train[train.Survived == 0].Age\n\naxes[1].hist([data.Age, pass_survived_age, pass_dead_age], bins=5, range=(0, 100), label=['Total', 'Survived', 'Dead'])\naxes[1].legend()\nplt.show()","2b75da7e":"#Null Ages in Training set (177 null values)\ntrain_age_mean = data.Age.mean()\ntrain_age_std = data.Age.std()\ntrain_age_null = data.Age.isnull().sum()\nrand_tr_age = np.random.randint(train_age_mean - train_age_std, train_age_mean + train_age_std, size=train_age_null)\ndata['Age'][np.isnan(data['Age'])] = rand_tr_age\ndata['Age'] = data['Age'].astype(int) + 1\n\n# Null Ages in Test set (86 null values)\ntest_age_mean = data.Age.mean()\ntest_age_std = data.Age.std()\ntest_age_null = data.Age.isnull().sum()\nrand_ts_age = np.random.randint(test_age_mean - test_age_std, test_age_mean + test_age_std, size=test_age_null)\ndata['Age'][np.isnan(data['Age'])] = rand_ts_age\ndata['Age'] = data['Age'].astype(int)\n\ndata.Age = (data.Age\/15).astype(np.int64) + 1","db09dfca":"data['FamilySize'] = data['SibSp'] + data['Parch'] + 1","859bbb26":"data['isAlone'] =data['FamilySize'].map(lambda x: 1 if x == 1 else 0)","dd5641d4":"data.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)\ndata.head()","e068bdd8":"# We drop the Cabin column as it has too many null values.\ndata.drop(['Cabin'],axis=1,inplace=True)","cdbd2b25":"data['Ticket_Len'] = data['Ticket'].apply(lambda x: len(x))","50b55070":"data.drop(labels='Ticket', axis=1, inplace=True)","b499769f":"data['Fare'][np.isnan(data['Fare'])] = data.Fare.mean()","5e5dbded":"data.Fare = (data.Fare \/20).astype(np.int64) + 1","a55bbe9e":"data['Embarked'].isnull().sum()","88242700":"data['Embarked'] = data['Embarked'].fillna('S')","5caadc8e":"data.head()","a7bca405":"from sklearn.preprocessing import LabelEncoder","c3a88696":"lr=LabelEncoder()","8229d7c2":"data['Sex'] = lr.fit_transform(data['Sex'])\ndata['Embarked']=lr.fit_transform(data['Embarked'])\ndata['Title']=lr.fit_transform(data['Title'])","d8cac26f":"train.shape","7c902db8":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","fa9c59da":"data.head()","b31f0ecf":"#Splitting the data back\ntrain2=data.iloc[0:891,:]\ntest2=data.iloc[891:1310,:]","f6d728a0":"train2.shape","cf63791c":"#Splitting the dataset back into the train and test.\nX=train2\ny=train['Survived']","0bf6c5a9":"from sklearn.linear_model import LogisticRegression","0c3a9894":"logmodel = LogisticRegression()\nlogmodel.fit(X,y)","24a6306d":"predictions_log = logmodel.predict(test2)","cdd50cf9":"from sklearn.ensemble import RandomForestClassifier","7b8b14eb":"# n_estimators refers to the number of tress.\nrfc=RandomForestClassifier(n_estimators=250)\nrfc.fit(X,y)","e8883ad7":"predictions_rfc=rfc.predict(test2)","f3333c80":"predictions_log.shape","b8943f09":"#my_submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions_log})\n#my_submission.to_csv('submission.csv', index=False)","a472e443":"my_submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions_rfc})\nmy_submission.to_csv('submission.csv', index=False)","03b4f74a":"We will use the .head() function to display the first five columns of the dataset to get a feel of the dataset.","7777d224":"<h1>Introduction<\/h1>\n\nThis notebook is a very basic and simple approach to this beginner classification problem. This problem serves as an excellent starter for any new aspiring Data Scientists and is perfect for laying down the foundation to newcomers ML Journey. I myself am a new comer to Kaggle and sincerely hope to do justice in conveying the concept in an easy to understand Manner. Please feel free to leave any comments that will help me to further improve this kernel and supplement my knowledge. And If you like my kernel please do upvote it.\n\nThis notebook is divided into six major parts:\n<ol>\n    <li>Introduction<\/li>\n    <li>Competition Description<\/li>\n    <li>Data Description<\/li>\n    <li>Exploratory Data Analyis or EDA (in short)<\/li>\n    <li>Data Pre-Processing<\/li>\n    <li>Modeling<\/li>\n<\/ol>\nFollowing the famous data science mantra we will spending the majority of our time in EDA and preprocessing compared to Modeling in a 80:20 ratio.","f2abd98f":"The empty values in the Fare column is filled with the mean of the Fare column.","4e3660de":"From the above data we can come to the conclusion that there is a higher percentage of female passengers who survived.","103dc0d2":"A plot to visualise the Target Distribution.","2de85e52":"We will perform the same analysis that we have done in passenger class.","03f09df3":"From the above displayed data we can see our Target Variable (which we have to predict) has the values. This indicates that it is a binary classification problem. We will also have to convert the categorical variables Embarked and Sex column onto its numerical counterpart so that our ML Algorithm can understand it.","2f0c051b":"A feature isAlone is created that checks if the FamilySize is 1 or greater.","2d738bac":"The test dataset has the same numeber of columns as the train dataset without the Target Variable. ","6e430cbf":"<h3>Passenger Class (Pclass) column<\/h3>","e92c08c4":"The plot below gives us the insight that the age of the passegners tend to be higher if they are from a higher passenger class. We wil be using this insight to later fill the Age column.","d8fa91a8":"Now let us see the ratio of males and females for each passenger class.","059a60d3":"The below code shows us the percentage of people who survived in each class. From this data we can come to the conclusion that there is a higher likelihood of people surviving in the higher class compared to the lower class","07110f39":"We will convert the categorical values into its binary equivalent.","3376da9b":"<h1>Data Description<\/h1>\n\n<h3>Overview<\/h3>\n\nThe data has been split into two groups:\n<ul>\n    <li>training set (train.csv)<\/li>\n    <li>test set (test.csv)<\/li>\n<\/ul>\n\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.","86a01f1e":"<h2>Logistic Regression <\/h2>","7ee55b47":"<font size=\"4\">This also gave us a score of 0.76555<\/font>","acdf81a1":"\n# Data Preprocessing","67b56ea7":"We can find the number of people who survived in each class by grouping them with 'Pclass' column","daceade0":"<h3>Gender Column<\/h3>","22774263":"The empty values in the Embarked column is filled with S.","8dfd35b6":"Now let us look into the Gender Column","73452372":"# Importing the Libraries","32cef595":"<font size=\"4\">Gives us a score of 0.76555<\/font>","c892069c":"From the plot below we can tell that the majority of the passegner's age lies between 20 and 40.","def255ff":"<h1>Submission<\/h1>","264b4af3":"The below is a pictorial representation of the above data.","88da861e":"Let us look into the Pclass column now which is basically the passenger class","7d27744c":"We fill the Age column with average age values of the passenger class. ","0d43aab3":"This is where the actual fun begins. We start off by importing all the libraries that we will need later on. We will be using Numpy and pandas for data analysis and matplotlib (Matlab for python), seaborn for data visualisation.","5538259d":"To visualise the missing values we can plot it out onto a heatmap.","bee2c697":"<h1>Competition Description<\/h1>\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.","e9000d60":"\nFrom the above data we can tell that the Age column is missing a lot of values. To better understand the number of missing values we run the following code.","1925038b":"<h3>2. Random Forest<\/h3>","c2e3819d":"# Modeling \nModeling is by far the easiest part in the ML Workflow. All we have to do is import the library then fit the model and predict our values.\n<h3>1. Logistic Regression<\/h3>","5329b344":"It was found that the Title from the names such as Mr, Miss, Mrs etc do contribute to the prediction. Threfore we create a feature out of it. It is also found that the length of the Name contributes as well.","636ca175":"Now we don't have any null values present in the datset.","f78fc574":"The Ticket length also gives us a useful feature that increases our accuracy.","4c17bde5":"# Exploratory Data Analysis","c4010de6":"<h2>Random Forest <\/h2>","2ba51853":"We create a feature known as FamilySize by adding the SibSP and Parch column.","b92c1525":"From the above plot we can tell that Cabin has an enormous amount of missing values therefore we can do nothing but drop that column and we will impute the Age column with values derived from a concrete hypotheis in the preprocessing section","0c796d6d":"From the below plot we can see that majority of the paasengers didnt have any siblings."}}