{"cell_type":{"7fb42ffd":"code","d16442e0":"code","6854b255":"code","d081a215":"code","c5ca3668":"code","38e31486":"code","9b8d4c00":"code","d3a7f0f9":"code","3548ea8d":"code","11437926":"code","9497d612":"code","3f6b0e41":"code","27d376d0":"code","7c08bed6":"code","9ce9d83b":"code","ab373ced":"code","19c05acf":"code","ec0d7927":"code","1c7f876b":"code","582ceb17":"code","3d0a8f27":"code","daa5386a":"markdown","938c4700":"markdown"},"source":{"7fb42ffd":"#Importing Necessary Libraries\n#Preprocessing Libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n\n#Feature Selection Libraries\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\n# ML Libraries (Random Forest, Naive Bayes, SVM)\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n \n# Evaluation Metrics\nfrom yellowbrick.classifier import ClassificationReport\nfrom sklearn import metrics","d16442e0":"#Read Iris Dataset into DataFrame & Print sample dataset\ndf = pd.read_csv('..\/input\/Iris.csv', error_bad_lines=False)\ndf.head()","6854b255":"#Check if NA Exist\ndf.info()\n\n#If no NA Exist, proceed\n#df = df.dropna()","d081a215":"#Drop unusable Attributes: ID\n#Reason: ID is the unique identifier that directly linked to each instance, which makes it not meaningful for training\ndf = df.drop(['Id'], axis=1)\n","c5ca3668":"#Display Target Class\ndf['Species'].unique()","38e31486":"#Encode labels into categorical variables:\ndf['Species'] = pd.factorize(df[\"Species\"])[0] \nTarget = 'Species'\ndf['Species'].unique()","9b8d4c00":"#Define Full Feature Set\nFeatures = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\nprint('Full Features: ', Features)","d3a7f0f9":"# Feature Selection using Recursive Feature Elimination\n# Split Dataframe to target class and features\nX_fs = df[Features]\nY_fs = df[Target]\n  \n# Feature Selection Model Fitting\nmodel = LogisticRegression(solver='lbfgs', multi_class='auto')\n\n#Mark the Number of Features to be selected, Adjust this Number to enhance the Model Performance\nrfe = RFE(model, 3) \nfit = rfe.fit(X_fs, Y_fs)\n\nprint(\"Number of Features Selected : %s\" % (fit.n_features_))\nprint(\"Feature Ranking             : %s\" % (fit.ranking_))\nprint(\"Selected Features           : %s\" % (fit.support_))\n\n# At Current Point, the attributes is select manually based on Feature Selection Part. \nFeatures = ['SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\nprint(\"Selected Features           :\", Features)\n","3548ea8d":"#Split dataset to Training Set & Test Set\nx, y = train_test_split(df, \n                        test_size = 0.2, \n                        train_size = 0.8, \n                        random_state= 3)\n\nx1 = x[Features]    #Features to train\nx2 = x[Target]      #Target Class to train\ny1 = y[Features]    #Features to test\ny2 = y[Target]      #Target Class to test\n\nprint('Feature Set Used    : ', Features)\nprint('Target Class        : ', Target)\nprint('Training Set Size   : ', x.shape)\nprint('Test Set Size       : ', y.shape)","11437926":"# Gaussian Naive Bayes\n# Create Model with configuration\nnb_model = GaussianNB() \n\n# Model Training\nnb_model.fit(X=x1, y=x2)\n\n# Prediction with Test Set\nresult= nb_model.predict(y[Features]) ","9497d612":"# Model Evaluation\nac_sc = accuracy_score(y2, result)\nrc_sc = recall_score(y2, result, average=\"weighted\")\npr_sc = precision_score(y2, result, average=\"weighted\")\nf1_sc = f1_score(y2, result, average='micro')\nconfusion_m = confusion_matrix(y2, result)\n\nprint(\"========== Naive Bayes Results ==========\")\nprint(\"Accuracy    : \", ac_sc)\nprint(\"Recall      : \", rc_sc)\nprint(\"Precision   : \", pr_sc)\nprint(\"F1 Score    : \", f1_sc)\nprint(\"Confusion Matrix: \")\nprint(confusion_m)","3f6b0e41":"# Classification Report\n# Instantiate the classification model and visualizer\ntarget_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\nvisualizer = ClassificationReport(nb_model, classes=target_names)\nvisualizer.fit(X=x1, y=x2)     # Fit the training data to the visualizer\nvisualizer.score(y1, y2)       # Evaluate the model on the test data\n\nprint('================= Classification Report =================')\nprint('')\nprint(classification_report(y2, result, target_names=target_names))\n\ng = visualizer.poof()             # Draw\/show\/poof the data","27d376d0":"# Random Forest\n# Create Model with configuration\nrf_model = RandomForestClassifier(n_estimators=70, # Number of trees\n                                  min_samples_split = 30,\n                                  bootstrap = True, \n                                  max_depth = 50, \n                                  min_samples_leaf = 25)\n\n# Model Training\nrf_model.fit(X=x1,\n             y=x2)\n\n# Prediction\nresult = rf_model.predict(y[Features])","7c08bed6":"# Model Evaluation\nac_sc = accuracy_score(y2, result)\nrc_sc = recall_score(y2, result, average=\"weighted\")\npr_sc = precision_score(y2, result, average=\"weighted\")\nf1_sc = f1_score(y2, result, average='micro')\nconfusion_m = confusion_matrix(y2, result)\n\nprint(\"========== Random Forest Results ==========\")\nprint(\"Accuracy    : \", ac_sc)\nprint(\"Recall      : \", rc_sc)\nprint(\"Precision   : \", pr_sc)\nprint(\"F1 Score    : \", f1_sc)\nprint(\"Confusion Matrix: \")\nprint(confusion_m)","9ce9d83b":"# Classification Report\n# Instantiate the classification model and visualizer\ntarget_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\nvisualizer = ClassificationReport(rf_model, classes=target_names)\nvisualizer.fit(X=x1, y=x2)     # Fit the training data to the visualizer\nvisualizer.score(y1, y2)       # Evaluate the model on the test data\n\nprint('================= Classification Report =================')\nprint('')\nprint(classification_report(y2, result, target_names=target_names))\n\ng = visualizer.poof()             # Draw\/show\/poof the data","ab373ced":"# Support Vector Machine\n# Create Model with configuration\nsvm_model = SVC(kernel='linear')\n\n# Model Training\nsvm_model.fit(X=x1, y=x2)  \n\n# Prediction\nresult = svm_model.predict(y[Features])  ","19c05acf":"# Model Evaluation\nac_sc = accuracy_score(y2, result)\nrc_sc = recall_score(y2, result, average=\"weighted\")\npr_sc = precision_score(y2, result, average=\"weighted\")\nf1_sc = f1_score(y2, result, average='micro')\nconfusion_m = confusion_matrix(y2, result)\n\nprint(\"============= SVM Results =============\")\nprint(\"Accuracy    : \", ac_sc)\nprint(\"Recall      : \", rc_sc)\nprint(\"Precision   : \", pr_sc)\nprint(\"F1 Score    : \", f1_sc)\nprint(\"Confusion Matrix: \")\nprint(confusion_m)","ec0d7927":"# Classification Report\n# Instantiate the classification model and visualizer\ntarget_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\nvisualizer = ClassificationReport(svm_model, classes=target_names)\nvisualizer.fit(X=x1, y=x2)     # Fit the training data to the visualizer\nvisualizer.score(y1, y2)       # Evaluate the model on the Test Set\n\nprint('================= Classification Report =================')\nprint('')\nprint(classification_report(y2, result, target_names=target_names))\n\ng = visualizer.poof()             # Draw\/show\/poof the data","1c7f876b":"# Ensemble Voting Model\n# Combine 3 Models to create an Ensemble Model\n\n# Create Model with configuration\neclf1 = VotingClassifier(estimators=[('svm', svm_model), ('rf', rf_model), ('gnb', nb_model)], \n                         weights=[1,1,1],\n                         flatten_transform=True)\neclf1 = eclf1.fit(X=x1, y=x2)   \n\n# Prediction\nresult = eclf1.predict(y[Features])","582ceb17":"# Model Evaluation\nac_sc = accuracy_score(y2, result)\nrc_sc = recall_score(y2, result, average=\"weighted\")\npr_sc = precision_score(y2, result, average=\"weighted\")\nf1_sc = f1_score(y2, result, average='micro')\nconfusion_m = confusion_matrix(y2, result)\n\nprint(\"============= Ensemble Voting Results =============\")\nprint(\"Accuracy    : \", ac_sc)\nprint(\"Recall      : \", rc_sc)\nprint(\"Precision   : \", pr_sc)\nprint(\"F1 Score    : \", f1_sc)\nprint(\"Confusion Matrix: \")\nprint(confusion_m)","3d0a8f27":"# Classification Report\n# Instantiate the classification model and visualizer\ntarget_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\nvisualizer = ClassificationReport(eclf1, classes=target_names)\nvisualizer.fit(X=x1, y=x2)     # Fit the training data to the visualizer\nvisualizer.score(y1, y2)       # Evaluate the model on the test data\n\nprint('================= Classification Report =================')\nprint('')\nprint(classification_report(y2, result, target_names=target_names))\n\ng = visualizer.poof()             # Draw\/show\/poof the data","daa5386a":"** Machine Learning Model **","938c4700":"**The Purpose of this notebook is to demonstrate the application of basic Machine Learning Models and some basic Model Evaluation Metrics to perform classification task with IRIS Dataset**\n\nIn this example, Naive Bayes, Random Forest and SVM is used to create an Ensemble Voting Model for the classification task. Feel free to drop a comment and feedback."}}