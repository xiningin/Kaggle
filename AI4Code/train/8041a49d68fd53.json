{"cell_type":{"61201355":"code","40e85f27":"code","7b9bb328":"code","9b96b8c4":"code","4ea01fc4":"code","9c62a970":"code","d6a7d401":"code","04d38283":"code","25515d72":"code","8fbaa48b":"code","b483b4f3":"code","504c99a9":"code","8ede2acf":"code","77caa47d":"code","914b337d":"code","af6c3942":"code","8a0fc68b":"code","68458348":"markdown","5cd29c58":"markdown","35ae557b":"markdown","e5562cd3":"markdown","81fed9f4":"markdown","3af7c377":"markdown","78363bf9":"markdown","7a3ffa99":"markdown","0b7edeff":"markdown","17613b61":"markdown","399c7917":"markdown","04ea8fd8":"markdown","2c1807af":"markdown","056edeaf":"markdown"},"source":{"61201355":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\nfrom fastai.tabular.all import *","40e85f27":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2022\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2022\/test.csv\")","7b9bb328":"train.target.unique()","9b96b8c4":"train.target.value_counts(normalize=True)","4ea01fc4":"train_df = train.drop(columns=['target', 'row_id'])\nf = plt.figure(figsize=(12, 12))\nplt.matshow(train_df.corr(), fignum=f.number)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","9c62a970":"cont_names = train.columns[1:-1].tolist() # Removed target & row_id columns\ncat_names = []\nprocs = [Normalize] # Normalizing the numeric columns\ndep_var = 'target'\n\npath = \"\/kaggle\/input\/tabular-playground-series-feb-2022\/\"","d6a7d401":"dls = TabularDataLoaders.from_csv(path + 'train.csv',\n                                  path=path,\n                                  y_names=\"target\",\n                                  cat_names = cat_names,\n                                  cont_names = cont_names,\n                                  procs = [Normalize],\n                                  y_block = CategoryBlock())\n\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train))\n\nto = TabularPandas(train, procs=[Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='target',\n                   splits=splits,\n                  y_block = CategoryBlock())\n\ndls = to.dataloaders(bs=64)","04d38283":"# Checking if data is loaded successfully\ndls.show_batch()","25515d72":"loss_func = CrossEntropyLossFlat()\nlearn = tabular_learner(dls, metrics=accuracy, loss_func=loss_func)","8fbaa48b":"# Finding the optimal learning rate\nlearn.lr_find()","b483b4f3":"# Rounded off the valley score from the previous code block\n# Increase epochs while training\nlearn.fit_one_cycle(10, 0.0015)","504c99a9":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)","8ede2acf":"test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2022\/test.csv\")\ntest_df = test.copy()\ntest_df.drop(['row_id'], axis=1, inplace=True)\ndl = learn.dls.test_dl(test_df)","77caa47d":"# Extracting the labels for the test examples\npreds_probs, dummy, preds  = learn.get_preds(dl=dl, with_decoded=True)","914b337d":"new_df = pd.DataFrame(\n    data = {\n        'row_id': test.row_id,\n        'target_value': preds\n    })\n\ndict_pd = pd.DataFrame(\n    data = {\n        'target_value': np.arange(0, 10, 1),\n        'target': learn.dls.vocab\n    }\n)","af6c3942":"submission = new_df.merge(dict_pd, on='target_value')\nsubmission.drop(['target_value'], axis=1, inplace=True)\nsubmission = submission.sort_values(by='row_id')\nsubmission.head(5)","8a0fc68b":"submission.to_csv(\"submission.csv\", index=False)","68458348":"# 4. Training fastai model","5cd29c58":"# 3. Loading data to fastai TabularDataLoaders","35ae557b":"# Future work\n- Use ROC_AUC as another metric for measuring accuracy\n- Mix this model with other NNs or Tree based methods to improve validation score\n- Implement CrossEntropy loss (good for Multiclass classification)\n- Add & engineer features","e5562cd3":"The code below assigns the appropriate label to the predicted class label.\nLike ","81fed9f4":"# 1. Importing packages + data","3af7c377":"With a different learning rate and greater epochs, I have gotten 0.95+ validation accuracy.","78363bf9":"10 labels in the multiclassification problem.","7a3ffa99":"- `coli`,`enterica` and `pyogenes` give a lot of misclassified predicted labels.\n- Accuracy is a bad metric for assessing the leaderboard in the competition. It is possible that the leaderboard is being calcualted on categories which are not misclassified a lot. (`jejuni` and `aureus`)\n- Two things would be important going forward:\n    1. Validation scores\n    2. The metric used to arrive at that validation score.","0b7edeff":"Classes are balanced!","17613b61":"- I'm grateful that you spent your time reading\/skimming all the way through. \n- Comments\/suggestions\/criticisms on the notebook would be highly appreciated.\n- Check out my other work on [Kaggle](https:\/\/www.kaggle.com\/rrrohit).","399c7917":"# 2. Preliminary data","04ea8fd8":"# 6. Making predictions on test set","2c1807af":"We have a lot of highly correlated features. This would be bad for generalization. Need to do feature selection in future work.","056edeaf":"# 5.  Interpretation of training results"}}