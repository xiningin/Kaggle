{"cell_type":{"12933a43":"code","1d3064b1":"code","af321d81":"code","b5bd1e08":"code","29c8c60b":"code","7885b04c":"code","8684de28":"code","423d48f5":"code","2ca8b8ef":"code","db1baeef":"code","bd9377a9":"code","d6d7dd36":"code","d3d3e348":"code","2886b435":"code","2c525002":"code","9eab889c":"code","92f86128":"code","f3faf984":"code","1d1c2b47":"markdown","b6ee5b51":"markdown","e069cb11":"markdown","e20f3741":"markdown","81e29746":"markdown"},"source":{"12933a43":"# Importando as bibliotecas\nimport os\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport cv2\n\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimport seaborn as sns\n\nprint(tf.__version__)","1d3064b1":"#Criando vari\u00e1veis para referenciar o caminho dos arquivos\ndata_dir = \"..\/input\/coin-images\/coins\/data\"\n\ndata_train_path =  data_dir + '\/train'\ndata_valid_path = data_dir + '\/validation'\ndata_test_path =  data_dir + '\/test'\n\nprint(os.listdir(\"..\/input\/coin-images\/coins\/data\"))","af321d81":"#Criando o tradutor das classes de moedas\nwith open('..\/input\/coin-images\/cat_to_name.json', 'r') as json_file:\n    cat_2_name = json.load(json_file)\n\n\n# Listando 10 classes aleat\u00f3rias\nfor i in np.random.choice(a = range(1,211), size = 10, replace=False):\n    print('Classe '+str(i)+': '+cat_2_name[str(i)])","b5bd1e08":"#Criando um dataframe com as informa\u00e7\u00f5es relevantes\nfileray = []\nclassray = []\npartitionray = []\nclassnameray = []\n\n\nfor dirname, _, filenames in os.walk(data_train_path):\n    for filename in filenames:\n        fileray.append(os.path.join(dirname, filename))\n        classray.append(int(dirname.replace(data_train_path+'\/','')))\n        partitionray.append(0)\n        classnameray.append(cat_2_name[dirname.replace(data_train_path+'\/','')])\n\nfor dirname, _, filenames in os.walk(data_valid_path):\n    for filename in filenames:\n        fileray.append(os.path.join(dirname, filename))\n        classray.append(int(dirname.replace(data_valid_path+'\/','')))\n        partitionray.append(1)\n        classnameray.append(cat_2_name[dirname.replace(data_valid_path+'\/','')])\n        \nfor dirname, _, filenames in os.walk(data_test_path):\n    for filename in filenames:\n        fileray.append(os.path.join(dirname, filename))\n        classray.append(int(dirname.replace(data_test_path+'\/','')))\n        partitionray.append(2)\n        classnameray.append(cat_2_name[dirname.replace(data_test_path+'\/','')])\n        \ndf = pd.DataFrame(list(zip(fileray, partitionray, classray, classnameray)), \n               columns =['File', 'Partition', 'Class', 'Class Name']) \n\ndf.set_index('File', inplace=True)","29c8c60b":"# Tamanho das parti\u00e7\u00f5es\npd.value_counts(df['Partition'])","7885b04c":"# Fun\u00e7\u00e3o para carregar e mudar o formato das imagens\ndef load_reshape_img(fname):\n    x = cv2.imread(fname)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n    x = cv2.resize(x, (224, 224))\n    x = img_to_array(x)\/255.\n\n    return x\n\n# Fun\u00e7\u00e3o para gerar as parti\u00e7\u00f5es de dados\ndef generate_df(partition, num_samples):\n    df_ = df[df['Partition'] == partition].sample(int(num_samples))\n    \n    x_ = np.array([load_reshape_img(fname) for fname in df_.index])\n    y_ = df_['Class'].values\n\n    return x_, y_","8684de28":"#Tamanho das amostras\ntrain_sample = 6413 # 6413 max\nvalid_sample = 844 # 844 max\ntest_sample = 844 # 844 max\n\n#Dados de Treino\nx_train, y_train = generate_df(0, train_sample)\n\n#Dados de Valida\u00e7\u00e3o\nx_valid, y_valid = generate_df(1, valid_sample)\n\n#Dados de Teste\nx_test, y_test = generate_df(2, test_sample)","423d48f5":"# Gera quantidade X de imagens de exemplo\nqtd_imagens = 8\n\nfig = plt.figure(figsize=(20,10))\nfig.subplots_adjust(wspace=0.2, hspace=0.4)\n\ncount = 0\nfor i in np.random.choice(range(0,len(x_train)-1), size=qtd_imagens):\n    ax = fig.add_subplot(2, 4, count + 1, xticks=[], yticks=[], title=cat_2_name[str(y_train[i])])\n    ax.imshow(x_train[i])\n    count += 1","2ca8b8ef":"# Quantidade de classes\nK = 212\nprint(\"\u00daltima camada:\", K)\n# Quantidade de \u00c9pocas\nepocas = 8\nprint(\"Quantidade de epochs:\", epocas)\n\ni = Input(shape=x_train[0].shape)\nx = Conv2D(32, (3, 3), activation='relu')(i)\nx = MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2))(x)\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2))(x)\n#x = Conv2D(128, (3, 3), activation='relu')(x)\n#x = MaxPooling2D(data_format=\"channels_last\",pool_size=(2, 2))(x)\nx = Flatten()(x)\n#x = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dense(K, activation='softmax')(x)\n\nmodel = Model(i, x)\n\nmodel.compile(optimizer=Adam(lr=0.0015),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nr = model.fit(x_train,\n              y_train, \n              validation_data=(x_valid, y_valid),\n              epochs=epocas)","db1baeef":"plt.figure(figsize=(20,12))\n\nprint(\"\\n\\t\\t\\t\\tEvolu\u00e7\u00e3o Loss e Accuracy ao longo das Epochs (Qtd: \" + str(epocas) + \")\")\n\nplt.subplot(2,2,1)\nplt.plot(r.history['loss'], label='treino')\nplt.plot(r.history['val_loss'], label='validacao')\nplt.title(\"Loss\")\nplt.legend()\n\nplt.subplot(2,2,2)\nplt.plot(r.history['accuracy'], label='treino')\nplt.plot(r.history['val_accuracy'], label='validacao')\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.show()","bd9377a9":"p_test = model.predict(x_test).argmax(axis=1)\ntotal = len(list(p_test))\nacertos = len(list(p_test)) - len(list(np.where(p_test != y_test))[0].tolist())\nerros = len(list(np.where(p_test != y_test))[0].tolist())\n\nprint(\"Resultado da base de Teste\", \"\\n\\tTotal:\\t\", total, \"\\n\\tAcertos:\", acertos, \"\\n\\tErros:\\t\", erros)\nprint(\"\\nPorcentagem de acerto: \" + str(round(acertos * 100 \/ total, 2)) + \"%\")","d6d7dd36":"df_resultado = pd.DataFrame([p_test, y_test]).T\ndf_resultado.columns = [\"Previsto\", \"Real\"]\nfor key in cat_2_name.keys():\n    df_resultado.replace(int(key), cat_2_name[key], inplace=True)\ndf_resultado[\"Acertos\"] = df_resultado[\"Previsto\"] == df_resultado[\"Real\"]\ndf_resultado[\"Acertos\"] = df_resultado[\"Acertos\"].astype(str).replace(\"True\", \"1\").replace(\"False\", \"0\").astype(int)\n\ndf_resultado[\"Erros\"] = df_resultado[\"Previsto\"] != df_resultado[\"Real\"]\ndf_resultado[\"Erros\"] = df_resultado[\"Erros\"].astype(str).replace(\"True\", \"1\").replace(\"False\", \"0\").astype(int)\n\nqtd_acertos_erros = df_resultado.groupby(['Real'])\\\n    .agg({'Acertos':'sum', 'Erros':'sum', 'Previsto':'count'})\\\n    .rename(columns={'Acertos':'Qtd Acertos', 'Erros':'Qtd Erros', 'Previsto':'Qtd imagens'})\\\n    .reset_index()\n\nqtd_acertos_erros.head()","d3d3e348":"qtd_acertos_erros[\"% Acertos\"] = round((qtd_acertos_erros[\"Qtd Acertos\"] \/ qtd_acertos_erros[\"Qtd imagens\"]) * 100, 2)\nqtd_acertos_erros[\"% Erros\"] = round((qtd_acertos_erros[\"Qtd Erros\"] \/ qtd_acertos_erros[\"Qtd imagens\"]) * 100, 2)\nqtd_acertos_erros.head()","2886b435":"distribuicao_acertos = qtd_acertos_erros.groupby(['% Acertos'])\\\n    .agg({'% Erros':'count'})\\\n    .rename(columns={'% Erros':'Quantidade'})\\\n    .reset_index()\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(\n    data=distribuicao_acertos,\n    x='% Acertos', \n    y='Quantidade',\n    palette='Blues_d')\n\nfor index, row in distribuicao_acertos.iterrows():    \n    ax.text(index, row['Quantidade'], row['Quantidade'].astype(int), color='black', va='bottom', rotation=0)\n\nplt.title(\"Distribui\u00e7\u00e3o da porcentagem de acertos\")\nplt.xlabel(\"\")\nplt.tight_layout()\nplt.show()","2c525002":"top10_acertos = qtd_acertos_erros.sort_values('% Acertos')\\\n    .nlargest(15, '% Acertos')\\\n    .reset_index()\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(\n    data=top10_acertos,\n    y='Real', \n    x='% Acertos',\n    palette='Blues_d')\n\nplt.title(\"As 15 moedas com maior porcentagem de acertos\")\nplt.xlabel(\"\")\nplt.tight_layout()\nplt.show()","9eab889c":"# Lista 6 casos em que houve acerto na previs\u00e3o\nqtd_imagens = 6\n\nfig = plt.figure(figsize=(20,10))\nfig.subplots_adjust(wspace=0.2, hspace=0.4)\n\n_classerr_idx = np.where(p_test == y_test)[0]\n\nacertos = np.random.choice(a = _classerr_idx, size = qtd_imagens, replace=False)\ncount = 0\n\nprint(\"\\t\\t\\t\\t\\tCasos em que houve acerto na previs\u00e3o\")\n    \nfor x in acertos:    \n    ax = fig.add_subplot(2, 3, count + 1, xticks=[], yticks=[], \n                         title=\"Real: \" + cat_2_name[str(y_test[x])] +\n                                \"\\nPrevisto: \" + cat_2_name[str(p_test[x])]\n    )\n    ax.imshow(x_test[x])\n    count += 1","92f86128":"top10_erros = qtd_acertos_erros.sort_values('% Erros')\\\n    .nlargest(15, '% Erros')\\\n    .reset_index()\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(\n    data=top10_erros,\n    y='Real', \n    x='% Erros',\n    palette='Blues_d')\n\nplt.title(\"As 15 moedas com maior porcentagem de erros\")\nplt.xlabel(\"\")\nplt.tight_layout()\nplt.show()","f3faf984":"# Lista 6 casos em que houve falha na previs\u00e3o\nqtd_imagens = 6\n\nfig = plt.figure(figsize=(20,10))\nfig.subplots_adjust(wspace=0.2, hspace=0.4)\n\n_classerr_idx = np.where(p_test != y_test)[0]\n\nerros = np.random.choice(a = _classerr_idx, size = qtd_imagens, replace=False)\ncount = 0\n\nprint(\"\\t\\t\\t\\t\\tCasos em que houve falha na previs\u00e3o\")\n    \nfor x in erros:    \n    ax = fig.add_subplot(2, 3, count + 1, xticks=[], yticks=[], \n                         title=\"Real: \" + cat_2_name[str(y_test[x])] +\n                                \"\\nPrevisto: \" + cat_2_name[str(p_test[x])]\n    )\n    ax.imshow(x_test[x])\n    count += 1","1d1c2b47":"# CNN","b6ee5b51":"# Preparando os dados","e069cb11":"# An\u00e1lise Explorat\u00f3ria","e20f3741":"Ramonn Grando \u2013 1931133052\n<br\/>Hermes Araujo - 1931133054","81e29746":"# Apresenta\u00e7\u00e3o dos Resultados"}}