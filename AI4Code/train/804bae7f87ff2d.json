{"cell_type":{"97c546f1":"code","aa7b24ab":"code","bae7f461":"code","60760aba":"code","461142d4":"code","26a6c064":"code","7dc2b91a":"code","88c68429":"code","f9454606":"code","d383012d":"code","6f2ee9a0":"code","a8a2cda1":"code","e9f39426":"code","9a5041e9":"code","1b3e7966":"code","a7616e94":"code","ace65d1d":"code","c2cd5687":"code","02cae901":"code","d6f2fefb":"code","3fa009d0":"markdown","d1291278":"markdown","732012bf":"markdown","825f5e87":"markdown","9ade5870":"markdown","2e998395":"markdown","b5e51f9a":"markdown","8fbb59ce":"markdown","e85fd246":"markdown","f9e668be":"markdown","1d0ee7e1":"markdown","38637a3d":"markdown","3b796a8b":"markdown","e0364f76":"markdown","085cb5b5":"markdown","fe26f9e4":"markdown","ba114f02":"markdown","9964d12f":"markdown"},"source":{"97c546f1":"import numpy as np \nimport pandas as pd \n\n# Importe two csv files\noriginal_data_1=pd.read_csv(\"\/kaggle\/input\/wine-reviews\/winemag-data_first150k.csv\")\noriginal_data_2=pd.read_csv(\"\/kaggle\/input\/wine-reviews\/winemag-data-130k-v2.csv\")","aa7b24ab":"original_data_1.head()","bae7f461":"original_data_2.head()","60760aba":"# Create a single DataFrame that contains variety and description only. Delete any rows that are duplicated or contain missing data.\nvariety_description= original_data_1[[\"variety\", \"description\"]].append(original_data_2[[\"variety\", \"description\"]])\nvariety_description=variety_description.drop_duplicates().dropna()\nvariety_description.head()","461142d4":"# How many grape varieties are there in this DataFrame?\nlen(variety_description[\"variety\"].unique().tolist())","26a6c064":"variety_description.shape","7dc2b91a":"# Create and display the chart showing the number of reviews per grape variety for the top 30 wines\nvariety_description[\"variety\"].value_counts().iloc[:30].plot.bar()","88c68429":"# Count the number of reviews per grape variety. This returns a series.\nvariety_rev_number=variety_description[\"variety\"].value_counts()\n\n# Convert the Series to Dataframe\ndf_rev_number=pd.DataFrame({'variety':variety_rev_number.index, 'rev_number':variety_rev_number.values})\ndf_rev_number[(df_rev_number[\"rev_number\"]>1)].shape","f9454606":"# Create a ist of grape varieties that have more than one review\nvariety_multi_reviews=df_rev_number[(df_rev_number[\"rev_number\"]>1)][\"variety\"].tolist()\n\n# Create a ist of grape varieties that have only one review\nvariety_one_review=df_rev_number[(df_rev_number[\"rev_number\"]==1)][\"variety\"].tolist()","d383012d":"# This demo is modified from https:\/\/kavita-ganesan.com\/tfidftransformer-tfidfvectorizer-usage-differences\/\n\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n\ndocs=[\"there was a king named Matati\", \n      \"He had a lot of gold\", \n      \"He loved the gold most\", \n      \"The beginning of the Matati gold story\"]\n\ncv=CountVectorizer()\n\nword_count_vect=cv.fit_transform(docs)\n\n# Display the result of CountVectorizer output (Reference: https:\/\/gist.github.com\/larsmans\/3745866)\n\nprint(\"the result of CountVectorizer\") \nprint(pd.DataFrame(word_count_vect.A, columns=cv.get_feature_names()).to_string())\n\n\n# Use TfidfTransformer to compute the IDF values\ntfidf_trans=TfidfTransformer(smooth_idf=True, use_idf=True)\ntfidf_trans.fit(word_count_vect)\n\n# Display the IDF value for each term in the text\ndf_idf=pd.DataFrame(tfidf_trans.idf_, index=cv.get_feature_names(), columns=[\"idf_values\"])\ndf_idf.sort_values(by=['idf_values'])","6f2ee9a0":"variety_description=variety_description.set_index(\"variety\")","a8a2cda1":"from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n\nvariety_description_2=pd.DataFrame(columns=[\"variety\",\"description\"])\n\n# Define a CountVectorizer object\n    # stop_words=\"english\": Remove all the uninformative words such as 'and', 'the' from analysis\n    # ngram=range(1,2): means unigrams and bigrams\ncv=CountVectorizer(stop_words=\"english\", ngram_range=(2,2))\n\n# Define a TfidfTransformer object\ntfidf_transformer=TfidfTransformer(smooth_idf=True, use_idf=True)\n\nfor grape in variety_multi_reviews:\n\n    df=variety_description.loc[[grape]]\n\n    # Generate word counts for the words used in the reviews of a specific grape variety\n    word_count_vector=cv.fit_transform(df[\"description\"])\n\n    # Compute the IDF values\n    tfidf_transformer.fit(word_count_vector)\n\n    # Obtain top 100 common words (meaning low IDF values) used in the reviews. Put the IDF values in a DataFrame\n    df_idf=pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(), columns=[\"idf_weights\"])\n    df_idf.sort_values(by=[\"idf_weights\"], inplace=True)\n\n    # Collect top 100 common words in a list\n    common_words=df_idf.iloc[:100].index.tolist()\n   \n    # Convert the list to a string and create a dataframe\n    common_words_str=\", \".join(elem for elem in common_words)\n    new_row= {\"variety\":grape, \"description\":common_words_str}\n\n    # Add the variety and its common review words to a new dataframe\n    variety_description_2=variety_description_2.append(new_row, ignore_index=True)\n\n","e9f39426":"variety_description_2=variety_description_2.set_index(\"variety\")\nvariety_description_2=variety_description_2.append(variety_description.loc[variety_one_review])\nvariety_description_2","9a5041e9":"variety_description_2.shape","1b3e7966":"# Load a relevant library\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Define a TfidVectorizer object. Remove all the uninformative words such as 'and,' 'the,' and 'him' from analysis. Bigrams only (ngram_range=(2,2)).\ntfidf=TfidfVectorizer(stop_words=\"english\", ngram_range=(2,2))\n\n# Count the words in each description, calculate idf, and multiply idf by tf.\ntfidf_matrix=tfidf.fit_transform(variety_description_2[\"description\"])\n\n# Resulting matrix should be # of descriptions (row) x # of bigrams (column)\ntfidf_matrix.shape","a7616e94":"# Since we used TfidfVectorizer to convert the text into a matrix, we can use linear_kernel to get cosine similarity, instead of sklearn's cosine_similarity\n# Load linear_kernel\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","ace65d1d":"# Create a Series, where the index is the grape variety and the element is the index of the wine in the dataset.\nvariety_description_2=variety_description_2.reset_index()\nindices = pd.Series(variety_description_2.index, index=variety_description_2['variety'])","c2cd5687":"# Make a function that takes in the grape variety as an input and produces a DataFrame of three similar varieties and key words of their reviews\n\ndef what_should_I_drink_next(grape, cosine_sim=cosine_sim):\n    # Get the index of the input wine\n    idx = indices[grape]\n\n    # Get the pairwise similarity scores between the input wine and all the wines\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the wines based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Select the top three similarity scores\n    sim_scores = sim_scores[1:4]\n\n    # Get the grape variety indices\n    wine_idx_list = [i[0] for i in sim_scores]\n     \n    # Create the output dataframe\n    df=pd.DataFrame(columns=[\"similar wines\", \"Top 6 common words in wine reviews\"])\n     \n    for wine_idx in wine_idx_list:\n     \n        g_variety=variety_description_2.iloc[wine_idx][\"variety\"]\n    \n        # Get top 6 common words in the review\n        des=variety_description_2.iloc[wine_idx][\"description\"]\n        \n        if g_variety in variety_multi_reviews:     # If the wine has more than one reviews\n            des_split=des.split(\", \")\n            key_words_list=des_split[:6]\n            key_words_str=\", \".join(key_words_list)\n        \n        else:\n            key_words_str = des\n            \n        new_row={\"similar wines\": g_variety, \"Top 6 common words in wine reviews\": key_words_str}\n        df=df.append(new_row, ignore_index=True)\n    \n    df.set_index(\"similar wines\") \n    \n    # Widen the column width so that all common words could be displayed\n    pd.set_option('max_colwidth', 500)\n   \n    return df  ","02cae901":"what_should_I_drink_next(\"Pinot Noir\")","d6f2fefb":"what_should_I_drink_next(\"Shiraz\")","3fa009d0":"> Our 756 grape varieties are in rows and there are 65484 bigrams used in the reviews.","d1291278":"## Cosine Similarity\n### How can we \"measure\" the similarity between the descriptions of two different grape varieties?\n\n* There are several ways to quantify the similarity, but here we will be using **cosine similarity**.\n* Cosine similarity:\n![Screen%20Shot%202020-06-17%20at%207.23.42%20PM.png](attachment:Screen%20Shot%202020-06-17%20at%207.23.42%20PM.png)\n    * Using TfidfVectorizer, we converted a text into a matrix of TF-IDF values. \n    * Imagine plotting descriptions of two wines, such as Pinot Noir and Chardonnay, onto a space (although the graph above is only 2-dimensional). \n    * The angle between them indicates how close or far they are.\n    * Thus, the more similar two descriptions are, the smaller angle is, and the higher cosine is.\n    * A detailed explanation of the cosine similarity could be found [here](https:\/\/www.machinelearningplus.com\/nlp\/cosine-similarity\/)","732012bf":"> Pinot Noir has the most reviews (16652 reviews or 10% of the total reviews), followed by Chardonnay and Cabernet Sauvignon.","825f5e87":"The cosine similarity matrix above does not contain the grape variety information anymore. So, we need a Series that we can use later to find the grape variety based on the index.","9ade5870":"# Which wine should I try next?\n## -Creating a recommendation system using sklearn's CountVecterizer and TfidfVectorizer-\n\nI like wine, but I am not a wine aficionado. Yet. In a wine shop, I mostly find myself overwhelmed by so many different types of wine. Even 20 minutes in, I still cannot pick a bottle to buy.\n\n\nOne of the safest ways to venture out and expand a list of wines you like would be to find grape varieties that are similar to your favorite. In this kernel, we will use **CountVecterizer and TfidfVectorizer in sklearn.feature_extraction.text** to create a recommendation system that takes in your favorite grape variety as an input and generates a DataFrame displaying three similar wines and key words in their reviews.\n\nYou can find the dataset used in this kernel [here](https:\/\/www.kaggle.com\/zynicide\/wine-reviews). This kernel is inspired by a fellow Kaggler's [kernel](https:\/\/www.kaggle.com\/ibtesama\/getting-started-with-a-movie-recommendation-system) about different recommendation systems. I highly recommend reading [her work](https:\/\/www.kaggle.com\/ibtesama\/getting-started-with-a-movie-recommendation-system).\n\nLet's explore the databset first!","2e998395":"# Data exploration","b5e51f9a":"### Let's work on our dataset","8fbb59ce":"## What is TF-IDF?\n* We already know that IDF stands for Inverse Document Frequency. TF-IDF is simply IDF multiplied by TF (Term frequency). TF-IDF will be high if 1) the term is unique (high IDF) in the whole document and 2) that term appeared frequently in a given text (e.g., a description of a specific wine).\n* Thus, the higher TF-IDF score of a term is, the more informative the term is.\n* We will do TF-IDF calculation using TfidfVectorizer. We can use CountVectorizer and then TfidfTransformer, just like above, but TfidfVectorizer would do all the steps required to get TF-IDF at once.","e85fd246":"# TF-IDF analysis using TfidfVectorizer","f9e668be":"# Get top 100 common words in the review using CounterVectorizer and TfidfTransformer\n## Why do we need to do this step?\n\n* When people want a recommendation based on the wine they like, they are looking for a different grape variety, *not* the same wine from a differen region.  \n* A total of 603 varieties of grape has multiple reviews in this dataset.\n* Then, what is the best way to get a **representative review** per grape variety?  ---> Get the **top 100 words commonly used** in the reviews on the same grape variety. In other words:\n![Screen%20Shot%202020-06-17%20at%203.35.57%20PM.png](attachment:Screen%20Shot%202020-06-17%20at%203.35.57%20PM.png)\n\n* How can I extract top 100 common words? Use CountVectorizer!\n\n","1d0ee7e1":"> Looks good. Tinta de Toro? I've never heard of it!","38637a3d":"> Out of 756 grape varieties, 603 have more than one reviews. These will be subject to the process in which we will grab top 100 common words from multiple reviews on a single grape variety.","3b796a8b":"# Thank you so much for reading this kernel!\n\nI always learn a lot from other Kagglers' work and I hope mine was helpful to someone.","e0364f76":">There are **756 different varieties of grapes** represented in this dataset and **a total of 169,451 descriptions** of different wines. This indicate that we have multiple descriptions for a given wine.","085cb5b5":"## CountVectorizer and TfidfTransformer\n* CountVectorizer counts how many times each word in a given text appears.\n    * eg. \"he\": 2, \"most\":3, \"the\": 2.\n* Then, how can we extract the commonly used words in the text? We can use IDF (Inverse Document Frequency), which indicates which term\/word is unique (or less frequently used). It's inverse, meaning that the lower IDF is, the more frequently the term is appearing in the text.\n* TfidfTransformer computes the IDF value for each term in the text.\n* Actually seeing the results of CountVectorizer and TfidfTransformer will help understand what they do. So, I ran them using a very simple text as an example below.\n\n### Demo of CountVectorizer with a simple example","fe26f9e4":"The recommendation system we will create needs two pieces of information only: variety and description. Let's create a DataFrame containing these two columns.","ba114f02":"> Great! We have the information about all 756 grape varieties. Now we are ready to do TF-IDF analysis!","9964d12f":"> Here, the resulting DataFrame only has the grape varities with multipe reviews. We should add the grape varieties that got only one review."}}