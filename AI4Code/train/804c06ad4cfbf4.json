{"cell_type":{"d38b1bde":"code","037f90b0":"code","bc7a1833":"code","5c8d9c09":"code","1a545f31":"code","52243a0c":"code","b5297cad":"code","228502c9":"code","686524cc":"code","d5048482":"code","727d5556":"code","4e61597d":"code","b702eb59":"code","e57c455c":"code","05a4c2a0":"code","c165c7a6":"code","961f6756":"code","dc8da10a":"code","adfb4567":"code","e812a5f7":"code","07a6b23a":"code","ccee7b0b":"code","23413a3c":"code","f9c7e4bc":"code","b32911b3":"code","39d3771a":"code","68687afc":"code","9c995cbb":"code","abc7f3f5":"code","f5ab59e5":"markdown","8f00a74e":"markdown","7b1c8099":"markdown"},"source":{"d38b1bde":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","037f90b0":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bc7a1833":"df_train = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\ndf_train","5c8d9c09":"df_train.shape","1a545f31":"df_test = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")\ndf_test","52243a0c":"df_test.shape","b5297cad":"X_t = df_train.drop([\"label\"], axis=1)\nY_t = df_train.label.values\nprint(X_t.shape, Y_t.shape)","228502c9":"X_test = df_test.drop([\"label\"], axis=1)\nY_test = df_test.label.values\nprint(X_test.shape, Y_test.shape)","686524cc":"plt.figure(figsize=(8, 8))\nX = X_t.to_numpy().reshape(60000, 28, 28)\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X[i], cmap=plt.cm.binary)\n    plt.xlabel(str(Y_t[i]))\nplt.show()","d5048482":"X_train, X_val, Y_train, Y_val = train_test_split(X_t, Y_t, test_size=0.2, stratify = Y_t, random_state = 42)","727d5556":"print(X_train.shape, Y_train.shape)\nprint(X_val.shape, Y_val.shape)","4e61597d":"X_train.values.dtype","b702eb59":"X_train = X_train.astype(\"float64\")\/255\nX_val = X_val.astype(\"float64\")\/255\nX_test = X_test.astype(\"float64\")\/255","e57c455c":"Y_train[0]","05a4c2a0":"# one hot encoding\nY_train = to_categorical(Y_train, 10)\nY_val = to_categorical(Y_val, 10)\nY_test = to_categorical(Y_test, 10)","c165c7a6":"Y_train[0]","961f6756":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten","dc8da10a":"model = Sequential()\nmodel.add(Dense(256, input_dim=784, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","adfb4567":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","e812a5f7":"history = model.fit(X_train, Y_train,\n          batch_size=200,\n          epochs=20,\n          verbose=1, \n          validation_data=(X_val, Y_val))","07a6b23a":"# \ubaa8\ub378 \ud559\uc2b5 \uacfc\uc815\nfig, loss_ax = plt.subplots()\nacc_ax = loss_ax.twinx()\n\nloss_ax.plot(history.history['loss'], 'y', label='train loss')\nloss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n\nacc_ax.plot(history.history['accuracy'], 'b', label='train acc')\nacc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nacc_ax.set_ylabel('accuracy')\n\nloss_ax.legend(loc='upper left')\nacc_ax.legend(loc='lower left')\n\nplt.show()","ccee7b0b":"score = model.evaluate(X_test, Y_test, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","23413a3c":"# CNN \ubaa8\ub378 \ub77c\uc774\ube0c\ub7ec\ub9ac\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical","f9c7e4bc":"X_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\nX_val = X_val.values.reshape(X_val.shape[0], 28, 28, 1)\nprint(X_train.shape, X_val.shape)","b32911b3":"# \ubaa8\ub378 define\nmodel2 = Sequential()\nmodel2.add(Conv2D(32, kernel_size =(3,3), input_shape = (28, 28, 1), activation='relu'))\nmodel2.add(Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size = 2))\nmodel2.add(Dropout(0.25))\nmodel2.add(Flatten())\nmodel2.add(Dense(64, activation='relu'))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(10, activation = 'softmax'))\n\nmodel2.summary()","39d3771a":"model2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","68687afc":"history = model2.fit(X_train, Y_train,\n          batch_size=200,\n          epochs=30,\n          verbose=1, \n          validation_data=(X_val, Y_val))","9c995cbb":"# \ubaa8\ub378 \ud559\uc2b5 \uacfc\uc815\nfig, loss_ax = plt.subplots()\nacc_ax = loss_ax.twinx()\n\nloss_ax.plot(history.history['loss'], 'y', label='train loss')\nloss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n\nacc_ax.plot(history.history['accuracy'], 'b', label='train acc')\nacc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nacc_ax.set_ylabel('accuracy')\n\nloss_ax.legend(loc='upper left')\nacc_ax.legend(loc='lower left')\n\nplt.show()","abc7f3f5":"X_test = X_test.values.reshape(X_test.shape[0], 28, 28, 1)\n\nscore = model2.evaluate(X_test, Y_test, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","f5ab59e5":"### labels\n* 0 : T-shirt\/top\n* 1 : Trouser\n* 2 : Pullover\n* 3 : Dress\n* 4 : Coat\n* 5 : Sandal\n* 6 : Shirt\n* 7 : Sneaker\n* 8 : Bag\n* 9 : Ankel boot","8f00a74e":"# \ubaa8\ub378 \uc0dd\uc131","7b1c8099":"# CNN \ubaa8\ub378 \uc0dd\uc131"}}