{"cell_type":{"5c077220":"code","9784f8e5":"code","d049df80":"code","f14b740f":"code","ce9a0500":"code","751c6db4":"code","089282fd":"code","f63f4f76":"code","92c93e1f":"code","4078c3dd":"code","c539bfa0":"code","bc02b4ae":"code","6684a5db":"code","5e94cdc7":"code","2c3cef2b":"code","f3431147":"code","17646acc":"code","5b55d2fb":"code","3cbd9930":"code","e3803fa6":"code","969b09d9":"code","f4fa030b":"code","1601de55":"code","7e08b933":"code","63846359":"code","7ba87d56":"code","f6fe2931":"code","d7bd48e5":"code","a28cf85b":"code","2320113b":"code","17a1bfa3":"code","26477edc":"code","33c810e3":"code","ebeceb4d":"code","dd0309f9":"code","cb0492db":"code","d2dc70ec":"markdown","4dd44ee3":"markdown","6c7df9de":"markdown","b9dd2a9b":"markdown","b8c09da0":"markdown","d1d978fc":"markdown","cea74651":"markdown"},"source":{"5c077220":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno \nimport sklearn.metrics as metrics\n\nfrom tqdm.notebook import tqdm \nfrom collections import Counter","9784f8e5":"#DATA_PATH = '\/home\/dlobatog\/workspace\/kaggle\/ventilator\/'\n\n#sub = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n#df_train = pd.read_csv(DATA_PATH + 'train.csv')\n#df_test = pd.read_csv(DATA_PATH + 'test.csv')\n\n\ndf_train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","d049df80":"df_train['u_in_cumsum'] = (df_train['u_in']).groupby(df_train['breath_id']).cumsum()\ndf_train.head()","f14b740f":"df_test['u_in_cumsum'] = (df_test['u_in']).groupby(df_test['breath_id']).cumsum()\ndf_test.head()","ce9a0500":"missingno.matrix(df_train, figsize = (30,10))","751c6db4":"def plot_sample(sample_id, df):\n    df_breath = df[df['breath_id'] == sample_id]\n    r, c  = df_breath[['R', 'C']].values[0]\n\n    cols = ['u_in', 'u_out', 'pressure'] if 'pressure' in df.columns else ['u_in', 'u_out']\n    \n    plt.figure(figsize=(12, 4))\n    for col in ['u_in', 'u_out', 'pressure']:\n        plt.plot(df_breath['time_step'], df_breath[col], label=col)\n        \n    plt.legend()\n    plt.title(f'Sample {sample_id} - R={r}, C={c}')\n\n\ndf_sample = df_train[df_train['breath_id'] < 5]","089282fd":"for i in df_sample['breath_id'].unique():\n    plot_sample(i, df_train)","f63f4f76":"sns.heatmap(df_train.corr())","92c93e1f":"\n#### Tried a few gradient tree models - no dice.\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn import tree\n\n#===========================================================================\n# select some features of interest\n#===========================================================================\nfeatures = ['R', 'C', 'time_step', 'u_in', 'u_out', 'u_in_cumsum']\n\n#===========================================================================\n#===========================================================================\nX_train = df_train[features]\ny_train = df_train[\"pressure\"]","4078c3dd":"clf = tree.DecisionTreeRegressor()\nclf.fit(X_train, y_train)","c539bfa0":"predictions = clf.predict(df_test[features])","bc02b4ae":"output = pd.DataFrame({\"id\":df_test.id, \"pressure\":predictions})\noutput.to_csv('submission.csv', index=False)","6684a5db":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)","5e94cdc7":"import xgboost as xgb\n\n# params for XGB are taked from this great kernel https:\/\/www.kaggle.com\/hamzaghanmi\/xgboost-hyperparameter-tuning-using-optuna \n# by Hamza Ghanmi\n\nregressor = xgb.XGBRegressor(\n                 colsample_bytree=0.9,\n                 alpha=0.01563,\n                 #gamma=0.0,\n                 learning_rate=0.01,\n                 max_depth=9,\n                 min_child_weight=257,\n                 n_estimators=500,                                                                  \n                 #reg_alpha=0.9,\n                 reg_lambda=0.003,\n                 subsample=0.9,\n                 random_state=2020,\n                 metric_period=100,\n                 silent=1)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=1)\n","2c3cef2b":"predictions = regressor.predict(df_test[features])\noutput = pd.DataFrame({\"id\":df_test.id, \"pressure\":predictions})\noutput.to_csv('submission_xgboost.csv', index=False)","f3431147":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=4)\npca.fit(X_train)","17646acc":"X_train_pca = pca.fit_transform(X_train)","5b55d2fb":"columns = ['pca_%i' % i for i in range(4)]\nX_train_pca = pd.DataFrame(pca.transform(X_train), columns=columns, index=X_train.index)\nX_train_pca.head()","3cbd9930":"#X_test_pca = pd.DataFrame(pca.transform(X_test), columns=columns, index=X_test.index)\ny_train.head()","e3803fa6":"regressor = xgb.XGBRegressor()\nregressor.fit(X_train_pca, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=1)","969b09d9":"from autosklearn.regression import AutoSklearnRegressor\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\nautoml = AutoSklearnRegressor(time_left_for_this_task=15*60, \n                              n_jobs=8,\n                              per_run_time_limit=30)\nautoml.fit(X_train, y_train)\nautoml.cv_results_\nautoml.performance_over_time_.plot(\n   x='Timestamp',\n   kind='line',\n   legend=True,\n   title='Auto-sklearn accuracy over time',\n   grid=True,\n)\n\nplt.show()","f4fa030b":"print(automl.leaderboard())\n","1601de55":"predictions = automl.predict(df_test[features])\noutput = pd.DataFrame({\"id\":df_test.id, \"pressure\":predictions})\noutput.to_csv('submission_automl.csv', index=False)","7e08b933":"############# Not too much success with decision trees. Give it one last try with improved features\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag'] = df['u_in'].shift(2).fillna(0)\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(df_train)\ntest = add_features(df_test)\n\ntrain.describe()","63846359":"fig, ax = plt.subplots(figsize = (12, 8))\nplt.subplot(2, 2, 1)\nsns.countplot(x='R', data=df_train)\nplt.title('Counts of R in train');\nplt.subplot(2, 2, 2)\nsns.countplot(x='R', data=df_test)\nplt.title('Counts of R in test');\nplt.subplot(2, 2, 3)\nsns.countplot(x='C', data=df_train)\nplt.title('Counts of C in train');\nplt.subplot(2, 2, 4)\nsns.countplot(x='C', data=df_test)\nplt.title('Counts of C in test')","7ba87d56":"df_train.groupby(\"breath_id\")[\"time_step\"].count().unique().item()","f6fe2931":"fig, ax1 = plt.subplots(figsize = (12, 8))\n\nbreath_1 = df_train.loc[df_train['breath_id'] == 4]\nax2 = ax1.twinx()\n\nax1.plot(breath_1['time_step'], breath_1['pressure'], 'r-', label='pressure')\nax1.plot(breath_1['time_step'], breath_1['u_in'], 'g-', label='u_in')\nax2.plot(breath_1['time_step'], breath_1['u_out'], 'b-', label='u_out')\n\nax1.set_xlabel('Timestep')\n\nax1.legend(loc=(1.1, 0.8))\nax2.legend(loc=(1.1, 0.7))\nplt.show()\n","d7bd48e5":"breath_928 = df_train.query('breath_id == 928').reset_index(drop = True)\nfig, ax = plt.subplots(1, 1, figsize=(9, 5))\nax.plot(breath_928[\"time_step\"],breath_928[\"u_in\"], lw=2, label='u_in')\nax.plot(breath_928[\"time_step\"],breath_928[\"pressure\"], lw=2, label='pressure')\nax.set(xlim=(0,1))\nax.legend(loc=\"upper right\")\nax.set_xlabel(\"time_id\", fontsize=14)\nplt.show();","a28cf85b":"df_train['u_in_shifted'] = df_train.groupby('breath_id')['u_in'].shift(2).fillna(method=\"backfill\")\ndf_test['u_in_shifted']  = df_test.groupby('breath_id')['u_in'].shift(2).fillna(method=\"backfill\")","2320113b":"for df in (df_train, df_test):\n    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()\n    df['u_in_shift_2'] = df.groupby('breath_id')['u_in'].shift(2).fillna(method=\"backfill\")\n    df['u_in_shift_4'] = df.groupby('breath_id')['u_in'].shift(4).fillna(method=\"backfill\")\n    df['u_in_first']  = df.groupby('breath_id')['u_in'].transform('first')\n    df['u_in_mean']   = df.groupby('breath_id')['u_in'].transform('mean')\n    df['u_in_median'] = df.groupby('breath_id')['u_in'].transform('median')\n    df['u_in_last']   = df.groupby('breath_id')['u_in'].transform('last')\n    df['u_in_min']    = df.groupby('breath_id')['u_in'].transform('min')\n    df['u_in_max']    = df.groupby('breath_id')['u_in'].transform('max')\n    df['rolling_10_mean'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True).fillna(0)\n    df['rolling_10_max'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).max().reset_index(level=0,drop=True).fillna(0)\n    df['rolling_10_std'] = df.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).std().reset_index(level=0,drop=True).fillna(0)\n    df['expand_mean'] = df.groupby('breath_id')['u_in'].expanding(2).mean().reset_index(level=0,drop=True).fillna(0)\n    df['expand_max'] = df.groupby('breath_id')['u_in'].expanding(2).max().reset_index(level=0,drop=True).fillna(0)\n    df['expand_std'] = df.groupby('breath_id')['u_in'].expanding(2).std().reset_index(level=0,drop=True).fillna(0)\n    df['ewm_u_in_mean'] = df.groupby('breath_id')['u_in'].transform(\n        lambda x: x.ewm(halflife=10).mean()\n    ).reset_index(level=0,drop=True).fillna(0)\n    df['ewm_u_in_std'] = df.groupby('breath_id')['u_in'].transform(\n        lambda x: x.ewm(halflife=10).std()\n    ).reset_index(level=0,drop=True).fillna(0)\n    df['ewm_u_in_corr'] = df.groupby('breath_id')['u_in'].transform(\n        lambda x: x.ewm(halflife=10).corr()\n    ).reset_index(level=0,drop=True).fillna(0)\n    \n","17a1bfa3":"df_test.head()","26477edc":"targets = df_train[['pressure']].to_numpy().reshape(-1, 80)\ndf_train.drop(['pressure', 'id', 'breath_id'], axis = 1, inplace = True)\ndf_test = df_test.drop(['id', 'breath_id'], axis = 1)","33c810e3":"from sklearn.preprocessing import RobustScaler, normalize\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom sklearn.model_selection import KFold, GroupKFold\n\nRS = RobustScaler()\ntrain = RS.fit_transform(df_train)\ntest = RS.transform(df_test)","ebeceb4d":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","dd0309f9":"EPOCH = 300\nBATCH_SIZE = 1024\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits = 5, shuffle = True, random_state = 228)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape = train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(400, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(300, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences = True)),\n            keras.layers.Dense(50, activation = 'selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer = \"adam\", loss = \"mae\")\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose = 1)\n\n        model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = EPOCH, batch_size = BATCH_SIZE, callbacks = [lr])\n\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","cb0492db":"ss = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\nss['pressure'] = sum(test_preds) \/ 5\nss.to_csv('lstm.csv', index = False)","d2dc70ec":"There seems to be a shift of around 0.1 seconds between u_in and pressure change. So we need to take that into account by shifting roughly 1 or 2 timesteps in each breath u_in. ","4dd44ee3":"Let's check how many timesteps do we have per breath ID and check how a breath looks like. WE only care about the inspiratory time pressure.","6c7df9de":"From the data above, we have to predict one value: `pressure`","b9dd2a9b":"![PVP1_typical_cycle.png](attachment:PVP1_typical_cycle.png)","b8c09da0":"# Exploratory analysis\n\n![2020-10-02%20Ventilator%20diagram.svg](attachment:2020-10-02%20Ventilator%20diagram.svg)\n\nLet's explore the training set. We want to see variance, mean, plot, etc... of the features\n1. What question(s) are you trying to solve (or prove wrong)?\n    - What is the pressure needed for each new example in the test\n2. What kind of data do you have and how do you treat different types?\n    - breath_id: an identifier for each breath. numeric\n    - R (restriction): how restricted the lung is in cmH2O\/L\/S (pressure per volume per unit of time).  Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n    - C (compliance): lung attribute indicating how compliant the lung is (in mL\/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon\u2019s latex, with higher C having thinner latex and easier to blow.\n    - time_step: timestamp\n    - u_in: control input in inspiratory solenoid valve, ranges 0 to 100\n    - u_out: control input in expiratory solenoid valve, either 0 or 1\n    - pressure: actual pressure measured in circuit in cmH2O\n    \n    - The first control input is a continuous variable from 0 to 100 representing the percentage the inspiratory solenoid valve is open to let air into the lung (i.e., 0 is completely closed and no air is let in and 100 is completely open). The second control input is a binary variable representing whether the exploratory valve is open (1) or closed (0) to let air out.\n  \n3. What\u2019s missing from the data and how do you deal with it?\n    - See missingno below, all values are populated.\n4. Where are the outliers and why should you care about them?\n\n5. How can you add, change or remove features to get more out of your data?\n    - Add cumulative u_in. Pressure in the lungs is going to be relative to the cumulative air volume pumped into them. \n    - `df_train['u_in_cumsum'] = (df_train['u_in']).groupby(df_train['breath_id']).cumsum()`\n    - `df_test['u_in_cumsum'] = (df_test['u_in']).groupby(df_test['breath_id']).cumsum()`\n\n\nBuckets: \n\n1. Numerical:\n    - breath_id \n    - R\n    - C\n    - time_step\n    - u_in\n2. Categorical\n    - u_out\n    \n\n","d1d978fc":"Let's try adding Lag features. A lag feature is just a fancy name for a feature that contains data about previous time steps. First off, check the shift between pressure and u_in. ","cea74651":"Also according to [this blogpost](https:\/\/machinelearningmastery.com\/basic-feature-engineering-time-series-data-python\/), it tends to help to add a set of summary statistics to the model. "}}