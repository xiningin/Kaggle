{"cell_type":{"8af74f77":"code","f2df9371":"code","57237681":"code","c0d5b99f":"code","7834b82e":"code","6e577de9":"code","a3a831f7":"code","55de7b95":"code","ff96968b":"code","0593622f":"code","afe81c21":"code","502a8ffc":"markdown","ae7d300a":"markdown","cc9f202e":"markdown","e81e6d9f":"markdown","ac3f4ad7":"markdown","257d46de":"markdown","a230cbd7":"markdown","5f30671b":"markdown","eefb3b76":"markdown","f05ad165":"markdown"},"source":{"8af74f77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f2df9371":"data=pd.read_csv(\"\/kaggle\/input\/sars-outbreak-2003-complete-dataset\/sars_2003_complete_dataset_clean.csv\")\ndata.head()","57237681":"for col in data.columns:\n    print(data[col].value_counts)","c0d5b99f":"data.isnull().sum()","7834b82e":"list_country=data.Country.unique()\ncount_country=len(list_country)\nprint(\"Number of countries: \"+str(count_country))\nprint(\"List of countries: \"+str(list_country))\n","6e577de9":"dict_country={}\n\nprint(\"Country name \\t Cases \\t Death \\t Recovered \\n\")\nfor country in list_country:\n    \n    cases=data[(data[\"Country\"]==country)][\"Cumulative number of case(s)\"].sum()\n    death=data[(data[\"Country\"]==country)][\"Number of deaths\"].sum()\n    recover=data[(data[\"Country\"]==country)][\"Number recovered\"].sum()\n    \n    dict_country[country]=[cases,death,recover]\n\n    print(country + \"\\t\" + str(cases) + \"\\t\" + str(death) + \"\\t\" + str(recover))    \n","a3a831f7":"sort_country={key: val for key, val in sorted(dict_country.items(), key=lambda item: item[1][0],reverse=True)}\nsort_country","55de7b95":"# defining the color and label which we will use frequently \n\ncolors=[\"#58D68D\",'#45B39D',\"#138D75\"]\nlabel=[\"Number of Cases\",\"Number of people Died\",\"Number of people Recovered\"]\n","ff96968b":"X=np.arange(10)\n\n\nfig, axs = plt.subplots(3, 1)\nfig.set_size_inches(20, 15)\n\n# plotting the graph\nfor count,country in enumerate(list(sort_country)[0:10]):\n    axs[0].bar(X[count],sort_country[country][0],color=colors[0])\n    axs[1].bar(X[count],sort_country[country][1],color=colors[1])\n    axs[2].bar(X[count],sort_country[country][2],color=colors[2])\n\n# changing the x axis labels to country name for all three graphs\nfor i in range(3):\n    plt.sca(axs[i])\n    plt.title(label[0])\n    plt.xticks(X,list(sort_country)[0:10])\n\nplt.show()","0593622f":"# grouping the date data to monthly data\ndata['Date']=pd.to_datetime(data['Date'])\n\ndate_group = data.groupby(pd.Grouper(key='Date', freq='1M')).sum() # groupby 1 month \ndate_group.index =date_group.index.strftime('%B')\n\ndate_group","afe81c21":"months=[\"March\",\"April\",\"May\",\"June\",\"July\"]\n\nX=np.arange(len(months))\n\nfig, axs = plt.subplots(1, 3)\nfig.set_size_inches(25, 10)\n\n# plotting the graph\naxs[0].bar(months,date_group[\"Cumulative number of case(s)\"],color=colors[0])    \naxs[1].bar(months,date_group[\"Number of deaths\"],color=colors[1])    \naxs[2].bar(months,date_group[\"Number recovered\"],color=colors[2])    \n\n# changing the x axis labels to country name for all three graphs\nfor i in range(3):\n    plt.sca(axs[i])\n    plt.title(label[i])\n\nplt.show()","502a8ffc":"Now check for NaN values in each column.","ae7d300a":"**Conclusion :**  The number of cases were at peak in `May and June`. Same goes for the number of deaths and recovery.\n\n***\n\n### Thank You ###\n\n***","cc9f202e":"Plotting for the same.","e81e6d9f":"## Data Preparation ##\n\nThe first step is to remove any ambiguity from the data so that we can use it afterwards for visualization. So let's load the data first.","ac3f4ad7":"Use value counts to find ant outliers or to understand what does each column contains and what datatype.","257d46de":"Plotting the graph for each top 10 affected countries against the number of cases, deaths and recovery. ","a230cbd7":"**Conclusion:**  The most affected areas are `Hong Kong and Taiwan` and the most affeceted country is `China`.\n***\n\nNow will try to anlayse the effect of Sars in each month. As we have the date data , let's group it to monthly data.","5f30671b":"Now we will find the number of cases, deaths and recovery in each country","eefb3b76":"As we can see there are no NaN values.The data seems okay.Let's start the exploration part.\n\n***\n\n## Data Exploration ##\n\nWe are trying to analyse the situation of each country during this epidemic. For this, first we have to find out the countries which are affected by sars.","f05ad165":"Now, sort the dictionary according to number of cases so that we can easily find the most affected area."}}