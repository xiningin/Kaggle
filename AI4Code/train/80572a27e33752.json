{"cell_type":{"febc6411":"code","c1be5b2f":"code","414f2d6a":"code","9e358fbe":"code","3049d2d1":"code","a22fb5f4":"code","8d718270":"code","e8325bc7":"code","37b3b7ae":"code","f802aa13":"code","2a56b36f":"code","1cb4ad62":"code","610c7bb4":"code","09134e09":"code","38fc7e76":"code","b4a3491c":"code","7e2122b3":"code","eceaf85a":"code","c53b87c6":"code","6d2a85ae":"code","8262264c":"code","9e299e05":"code","18a2eb7d":"code","a915880d":"code","bd0fcf77":"code","b1b70582":"code","af91516d":"code","b28dd625":"code","67652fa0":"code","903aa247":"markdown","69f1dec4":"markdown","23b643a8":"markdown","d2e37234":"markdown","f79ac13f":"markdown","5eee6b4d":"markdown","b5e46766":"markdown","9ac00ea1":"markdown","17665114":"markdown","f4d93bfc":"markdown","ab74f534":"markdown","db0c53b7":"markdown","14bf0418":"markdown","eefa7f4a":"markdown","d6f7afc2":"markdown","e0502b77":"markdown","258a2164":"markdown","be5699bb":"markdown","732af969":"markdown","8ca9be58":"markdown"},"source":{"febc6411":"import pandas as pd \nimport numpy as np\nfrom sklearn.model_selection import train_test_split","c1be5b2f":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nsample_sub = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\npseudo = pd.read_csv('..\/input\/blending-tool-tps-aug-2021\/file1_7.85192_file2_7.85192_blend.csv')","414f2d6a":"test['loss'] = pseudo['loss']","9e358fbe":"train.head()","3049d2d1":"test.head()","a22fb5f4":"test.shape, train.shape","8d718270":"train.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)","e8325bc7":"all_data = [train, test]","37b3b7ae":"for df in all_data:\n    df['f77^2\/f52^2'] = (df['f77']**2)\/(df['f52']**2)\n    df['f74^2\/f81^2'] = (df['f74']**2)\/(df['f81']**2)\n    df['f77\/f69'] = df['f77']\/df['f69']\n    df['f81^2\/f77^2'] = (df['f81']**2)\/(df['f77']**2)\n    df['f96\/f28'] = df['f96']\/df['f28']\n    df['f96^2\/f73^2'] = (df['f96']**2)\/(df['f73']**2)\n    df['f78\/f28'] = df['f78']\/df['f28']\n    df['f73\/f28'] = df['f73']\/df['f28']\n    df['f66\/f69'] = df['f66']\/df['f69']\n    df['f46^2\/f4^2'] = (df['f46']**2)\/(df['f4']**2)\n    df['f4\/f75'] = df['f4']\/df['f75']\n    df['f69^2\/f96^2'] = (df['f69']**2)\/(df['f96']**2)\n    df['f25\/f69'] = df['f25']\/df['f69']\n    df['f78\/f69'] = df['f78']\/df['f69']\n    df['f96^2\/f77^2'] = (df['f96']**2)\/(df['f77']**2)\n    df['f4^2\/f52^2'] = (df['f4']**2)\/(df['f52']**2)\n    df['f66^2\/f52^2'] = (df['f66']**2)\/(df['f52']**2)\n    df['f4^2\/f81^2'] = (df['f4']**2)\/(df['f81']**2)\n    df['f46^2\/f81^2'] = (df['f46']**2)\/(df['f81']**2)\n    df['f47\/f69'] = df['f47']\/df['f69']\n    df['f74xf70'] = df['f74']*df['f70']\n    df['f46^2\/f66^2'] = (df['f46']**2)\/(df['f66']**2)\n    df['f74\/f47'] = df['f74']\/df['f47']\n    df['f96^2xf69^2'] = (df['f96']**2)\/(df['f69']**2)\n    df['f66\/f46'] = df['f66']\/df['f46']\n    df['f25xf96'] = df['f25']*df['f96']\n    df['f28xf81'] = df['f28']*df['f81']\n    df['f52xf66'] = df['f52']*df['f66']\n    df['f46^2xf81^2'] = (df['f46']**2)*(df['f81']**2)\n    df['f46xf74'] = df['f46']*df['f74']\n    df['f28_log'] = np.log2(df['f28'])\n    df['f28xf70'] = df['f28']*df['f70']\n    df['f52_log'] = np.log2(df['f52'])\n    df['f47_log'] = np.log2(df['f47'])\n    df['f66xf73'] = df['f66']*df['f73']\n    df['f69_log'] = np.log2(df['f69'])\n    df['f96\/f78'] = df['f96']\/df['f78']\n    \n    ","f802aa13":"test.shape, train.shape","2a56b36f":"test.fillna(0, inplace=True)\ntrain.fillna(0, inplace=True)","1cb4ad62":"corr = train.corr()\ncolumns_to_delete = corr[corr.loss<0.001][corr.loss>-0.001].index","610c7bb4":"train.drop(columns_to_delete, axis=1, inplace=True)\ntest.drop(columns_to_delete, axis=1, inplace=True)","09134e09":"full_data = pd.concat([train, test])","38fc7e76":"X = full_data.drop(['loss'], axis=1)\ny = full_data['loss']\nX_test = test.drop(['loss'], axis=1)","b4a3491c":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler_x = MinMaxScaler()\nscaler_y = StandardScaler()","7e2122b3":"scaler_x.fit(X)\nX = scaler_x.transform(X)\nX_test = scaler_x.transform(X_test)","eceaf85a":"scaler_y.fit(y.to_numpy().reshape(-1, 1))\ny = scaler_y.transform(y.to_numpy().reshape(-1, 1)).ravel()","c53b87c6":"!pip install scikit-learn-intelex -q --progress-bar off","6d2a85ae":"from sklearnex import patch_sklearn\npatch_sklearn()","8262264c":"from sklearn.svm import NuSVR","9e299e05":"params = {'C': 0.9335786569734156, 'nu': 0.9426690319592885}","18a2eb7d":"%%time\nfinal_model = NuSVR(**params).fit(X, y)","a915880d":"%%time\ny_pred = final_model.predict(X_test)","bd0fcf77":"y_pred = scaler_y.inverse_transform(y_pred)","b1b70582":"sample_sub['loss'] = y_pred\nsample_sub.to_csv('submission.csv', index=False)\nsample_sub.head(10)","af91516d":"# from sklearnex import unpatch_sklearn\n# unpatch_sklearn()","b28dd625":"# from sklearn.svm import NuSVR","67652fa0":"# %%time\n# final_model = NuSVR(**params).fit(X, y)","903aa247":"<big>Save the results in 'submission.csv'.<\/big>","69f1dec4":"<big>Unfortunately, the original scikit-learn <strong>does not have time to train the model in 9 hours<\/strong> on the provided data.<\/big><br>\n<big>On 10% of the total dataset, the patched version is trained in 1 minute 25 seconds, and the stock version in 33 minutes 42 seconds.<\/big>","23b643a8":"<big>Drop 'id' field<\/big>","d2e37234":"<big>Delete features with low correlation.<\/big>","f79ac13f":"<big>Normalize data.<\/big>","5eee6b4d":"<big>Let's look at the test and train sets.<\/big>","b5e46766":"<big>Concateate train and test sets.<\/big>","9ac00ea1":"<big>Importing data<\/big>","17665114":"# Installing Intel(R) Extension for Scikit-learn\n\n<big>Use Intel\u00ae Extension for Scikit-learn* for fast compute Scikit-learn estimators.<\/big>","f4d93bfc":"<big>Split the data into 'X' and 'y' <\/big>","ab74f534":"# Now we use the same algorithm with original scikit-learn","db0c53b7":"<big><strong>Pseudodating<\/strong><\/big><br><br>\n<big>I took the previously predicted labels and added them to the test dataset.<\/big>","14bf0418":"# Train nuSVR model\n<big>Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. The advantage of support vector machines is effective in high dimensional spaces.<\/big><br><br>\n\n<big>NuSVR similar to SVR, but uses a parameter nu to control the number of support vectors. Nu replaces the parameter epsilon of epsilon-SVR<\/big><br><br>\n<big>The process of selecting the parameters is too long and computationally intensive, so I selected the parameters in advance.<\/big><br><br>\n<big>Parameters: <\/big><br>\n<big>* <code>C<\/code> -  Parameter inverse to the regularization coefficient.<br><\/big>\n<big>* <code>nu<\/code> - An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors..<br><br> <\/big>","eefa7f4a":"# Conclusions\n<big>We can see that using only one classical machine learning algorithm may give you a pretty hight accuracy score. We also use well-known libraries Scikit-learn and Optuna, as well as the increasingly popular library Intel\u00ae Extension for Scikit-learn. Noted that Intel\u00ae Extension for Scikit-learn gives you opportunities to:<\/big>\n\u200b\n* <big>Use your Scikit-learn code for training and inference without modification.<\/big>\n* <big>Speed up selection of parameters <strong>from 9+ hours to 2 hours and 30 minutes.<\/strong><\/big>\n* <big>Get predictions of the similar quality.<\/big>\n\u200b","d6f7afc2":"<big>For classical machine learning algorithms, we often use the most popular Python library, Scikit-learn. With Scikit-learn you can fit models and search for optimal parameters, but\u202fit\u202fsometimes works for hours.<\/big><br><br>\n\u200b\n<big>I want to show you how to use Scikit-learn library and get the results faster without changing the code. To do this, we will make use of another Python library, <strong>\u202f<a href='https:\/\/github.com\/intel\/scikit-learn-intelex'>Intel\u00ae Extension for Scikit-learn*<\/a><\/strong>.<\/big><br><br>\n\u200b\n<big>I will show you how to <strong>speed up your kernel more than 4 times<\/strong> without changing your code!<\/big><big>","e0502b77":"<big>I added features that were obtained as a result of research <code>feature_importances_<\/code><\/big>","258a2164":"# Prediction","be5699bb":"# Preprocessing","732af969":"<big>Patch original scikit-learn.<\/big>","8ca9be58":"<big>Import libraries<\/big>"}}