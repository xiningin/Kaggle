{"cell_type":{"ccafec50":"code","d7af6b97":"code","b264a6a9":"code","b593f150":"code","e71ad0ea":"code","ae858b5c":"code","130a6b2b":"code","ae9f6a81":"code","2a310a1a":"code","74d159e7":"code","17d4a132":"code","ef1e32b5":"code","7d95fec1":"code","f4f9195f":"code","9956794a":"code","f6bbddac":"code","9ef9e0ad":"code","32828705":"code","0fcc4128":"code","20e8f0e6":"code","0c0ae2f8":"code","2e9fde6c":"code","9f78027f":"code","79473c0a":"markdown","e0406a9b":"markdown","a9c06a5e":"markdown"},"source":{"ccafec50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7af6b97":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore',category=FutureWarning)\n# lib for modelling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score,roc_auc_score,roc_curve,confusion_matrix,classification_report\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.api as sm\n# import EDA library\nfrom pandas_profiling import ProfileReport","b264a6a9":"# loading the dataset \ndf=pd.read_csv('..\/input\/predicting-churn-for-bank-customers\/Churn_Modelling.csv')","b593f150":"# generating report for the data for the better visualization\nProfileReport(df)","e71ad0ea":"# lets look for the column in data \ndf.head(5)","ae858b5c":"# Data pre - processing\ndf.drop(['CustomerId','Surname'],axis=1,inplace=True) \n### let's drop few columns which won't contribute to the model as we have seen above in report","130a6b2b":"#  one hot encoding for the column `Geo` \nGeography_dummies = pd.get_dummies(prefix='Geo',data=df,columns=['Geography'])","ae9f6a81":"# label encoding for the gender column  as its just male and female we have not done on hot as its nor ordinal data\nGender_dummies = Geography_dummies.replace(to_replace={'Gender': {'Female': 1,'Male':0}})","2a310a1a":"df_new = Gender_dummies\ndf_new.head()","74d159e7":"# Doing EDA for the dataset since pandas profiling had done our most of the work but still we need to work out\n# Check the distribution of y variable to see if it's a case of unbalanced class\n\nsns.countplot(y=df_new.Exited ,data=df_new)\nplt.xlabel(\"Count of each Target class\")\nplt.ylabel(\"Target classes\")\nplt.show()","17d4a132":"# Check the distribution of all the features\n\ndf_new.hist(figsize=(15,12),bins = 15)\nplt.title(\"Features Distribution\")\nplt.show()","ef1e32b5":"# as we have seen that there is imbalanced in the dataset for the target hence we need to balance the data\n# Split the y variable series and x variables dataset\n\nX = df_new.drop(['Exited'],axis=1)\ny = df_new.Exited\nfrom imblearn.over_sampling import SMOTE\nsmt = SMOTE(random_state=0)\nX, y = smt.fit_resample(X, y)\nprint(X.shape)\nprint(y.shape)","7d95fec1":"# Splitting the data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","f4f9195f":"# using power transfor to normalise the data\nfrom sklearn.preprocessing import PowerTransformer\npt=PowerTransformer()\nXpowertrain=pt.fit_transform(X_train)\nxpowertest=pt.transform(X_test)","9956794a":"# apply logit model\nmodel=sm.Logit(y,sm.add_constant(X)).fit()\nprint(model.summary())","f6bbddac":"lr=LogisticRegression()","9ef9e0ad":"lr.fit(Xpowertrain,y_train)","32828705":"lr.score(Xpowertrain,y_train)","0fcc4128":"lr.score(xpowertest,y_test)","20e8f0e6":"# Predicting target values by using x_test and our model:\ny_pred = lr.predict(xpowertest)\n","0c0ae2f8":"print ('Confusion Matrix :')\nprint(confusion_matrix(y_test, y_pred))\nprint('Accuracy Score :',accuracy_score(y_test, y_pred) )\nprint('Recall Score :',recall_score(y_test, y_pred) )\nprint('Precision Score :',precision_score(y_test, y_pred) )\nprint('Report : ')\nprint(classification_report(y_test, y_pred))\n\n      ","2e9fde6c":"# ROC AUC curve\ny_pred_prob1 = lr.predict_proba(xpowertest)[:,1]\nfpr1 , tpr1, thresholds1 = roc_curve(y_test, y_pred_prob1)","9f78027f":"plt.plot(fpr1, tpr1, label= \"Logistic Regression\")\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title('ROC-AUC curve')\nplt.show()","79473c0a":"# Model evalution metric","e0406a9b":"# We are not checking for the multicollinearity as we have already looked the same in profile report","a9c06a5e":"# As per the model location gender has lesser pvalue but we can not drop it as per domain knowledge as we need it identify for the location and gender as a factor to churn"}}