{"cell_type":{"5984e996":"code","f709246f":"code","a9c13c6f":"code","e50b4592":"code","57804bd0":"code","2f518d94":"code","ecfc2a68":"code","470ca4a0":"code","e9b2bac3":"code","50d4ba89":"code","e8780ae5":"code","8cdc8141":"code","eb0720f1":"code","3f632e4f":"code","e119aa7b":"code","fffe4615":"code","44a0b222":"code","0c047208":"code","8e940d9b":"code","fadf3ace":"code","a07a0117":"code","a173ce8a":"code","2ab01ab7":"code","6e35d1bd":"code","58f4afeb":"code","17a7aa2b":"code","e4928eff":"code","93747136":"code","df155ecf":"code","a69c4ab5":"code","648ba0a7":"code","3aadab4f":"code","1c6a86fa":"code","22a9a0a0":"code","a7c37d90":"code","e36ada77":"code","56626199":"code","b6ef4f6f":"code","e58e9e94":"code","1b314824":"code","ebb7a565":"code","db4e0502":"code","44a592ca":"code","c4b39dba":"code","0b8a58cc":"code","1bbce447":"code","c69fedfd":"code","96034278":"code","7bfdb515":"code","8ead8280":"code","c18423d4":"code","909379c0":"code","d39e1ce3":"code","e91000ab":"code","cd3cc236":"code","452e633f":"code","2d43a30c":"code","28722190":"code","1e12d50e":"code","13847fd1":"code","4c615440":"code","370b8b15":"code","8bbad367":"code","cdcd97ba":"code","41d90ef2":"code","ba0602df":"code","6a9a308f":"code","e6decff2":"code","7ad7b67b":"code","30ec7650":"code","3546ec8c":"code","4bdaafae":"code","b0140fb1":"code","1fb6944b":"code","2726d527":"code","8d5e8f80":"code","6c6fdf9c":"code","cd0829f4":"code","7b085bd6":"code","24ae2372":"code","628d227c":"code","3131e8b3":"code","bdbeb25f":"code","7702a45c":"code","3df44e88":"code","147283b2":"code","76d2b807":"code","b5574c7b":"code","17c345c0":"code","cdd2e5b9":"code","131f3c4f":"code","e0f1ba0b":"code","6b12f424":"code","e39686cb":"code","2095e79a":"code","00a27171":"code","da376fd3":"markdown","c5b4022f":"markdown","2ece6bae":"markdown","23b51315":"markdown","dd5dda79":"markdown","5b0421c6":"markdown","214fb918":"markdown","fb05af03":"markdown","75cfd215":"markdown","fd578903":"markdown","4da1857e":"markdown","fd9dc8b5":"markdown","5d7a7067":"markdown","f1f867d4":"markdown","cc1c4f3e":"markdown","4b53d02a":"markdown","bc89c263":"markdown","8c08ab26":"markdown","ff1a7477":"markdown","efb3a3c6":"markdown","f96c9d6d":"markdown","5845c581":"markdown","2bff7283":"markdown","3db3ab72":"markdown","17e3fbc5":"markdown","ec103c74":"markdown","830270ad":"markdown","c40d4c05":"markdown","c896db66":"markdown","632d6662":"markdown","244ef08f":"markdown","0def8c62":"markdown","dbf8ac3d":"markdown","b6163f16":"markdown","c060e2fe":"markdown","fe943285":"markdown","86b9b215":"markdown","9169b980":"markdown","0e11a2e5":"markdown","5915538b":"markdown","210f4f8d":"markdown","1d8eb7cb":"markdown","9fdb9bc0":"markdown","6cf5aa63":"markdown","ef89e221":"markdown","3cf3357c":"markdown","23f8dde5":"markdown","ffd10f22":"markdown","5b43dc1d":"markdown","996d6904":"markdown","02ba6937":"markdown","6a45b782":"markdown","f264b350":"markdown","36c7f8df":"markdown","e6cc0c82":"markdown","369d0f5f":"markdown","08786308":"markdown","3ac74cab":"markdown","3c7106ad":"markdown","56077b8e":"markdown","3a918537":"markdown","7c826c15":"markdown","5ee7ae53":"markdown"},"source":{"5984e996":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport warnings\nwarnings.filterwarnings('ignore')","f709246f":"df=pd.read_csv('..\/input\/avacado-price-prediction\/Avocado.csv')","a9c13c6f":"df.head()","e50b4592":"df.shape","57804bd0":"df.nunique()","2f518d94":"df.isnull().sum()","ecfc2a68":"df.dtypes","470ca4a0":"df.skew()","e9b2bac3":"df.describe()","50d4ba89":"df.nunique()","e8780ae5":"#We separate categorical and continuous features\ncat=['year','region','type']\ncont=[ 'Total Volume', '4046', '4225','4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags']","8cdc8141":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\ndf['type'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(df['type'])\ndf['type'].value_counts()","eb0720f1":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\ndf['year'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(df['year'])\ndf['year'].value_counts()","3f632e4f":"plt.figure(figsize=(25,10))\nsns.countplot(df['region'])\nplt.xticks(rotation=90)\nprint('Total number of regions',df['region'].nunique())","e119aa7b":"plt.figure(figsize=(8,6))\nsns.distplot(df['AveragePrice'],color='m', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['AveragePrice'].min())\nprint('Maximum',df['AveragePrice'].max())","fffe4615":"plt.figure(figsize=(8,6))\nsns.distplot(df['Total Volume'],color='r', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['Total Volume'].min())\nprint('Maximum',df['Total Volume'].max())","44a0b222":"plt.figure(figsize=(8,6))\nsns.distplot(df['4046'],color='g', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['4046'].min())\nprint('Maximum',df['4046'].max())","0c047208":"plt.figure(figsize=(8,6))\nsns.distplot(df['4770'],color='y', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['4770'].min())\nprint('Maximum',df['4770'].max())","8e940d9b":"plt.figure(figsize=(8,6))\nsns.distplot(df['4225'],color='b', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['4225'].min())\nprint('Maximum',df['4225'].max())","fadf3ace":"plt.figure(figsize=(8,6))\nsns.distplot(df['Total Bags'],color='y', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['Total Bags'].min())\nprint('Maximum',df['Total Bags'].max())","a07a0117":"plt.figure(figsize=(8,6))\nsns.distplot(df['Small Bags'],color='b', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['Small Bags'].min())\nprint('Maximum',df['Small Bags'].max())","a173ce8a":"plt.figure(figsize=(8,6))\nsns.distplot(df['Large Bags'],color='g', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['Large Bags'].min())\nprint('Maximum',df['Large Bags'].max())","2ab01ab7":"plt.figure(figsize=(8,6))\nsns.distplot(df['XLarge Bags'],color='r', kde_kws={\"color\": \"k\"})\nprint('Minimum',df['XLarge Bags'].min())\nprint('Maximum',df['XLarge Bags'].max())","6e35d1bd":"fig,ax=plt.subplots(4,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.boxplot(df[n],ax=ax[r,c])\n    c+=1","58f4afeb":"plt.figure(figsize=(8,20))\nsns.stripplot(x='year',y='region',data=df)","17a7aa2b":"plt.figure(figsize=(8,6))\nsns.stripplot(x='year',y='AveragePrice',data=df)","e4928eff":"plt.figure(figsize=(8,6))\nsns.stripplot(x='type',y='AveragePrice',data=df)","93747136":"plt.figure(figsize=(20,8))\nsns.boxplot(x='region',y='AveragePrice',data=df)\nplt.xticks(rotation=90)","df155ecf":"fig,ax=plt.subplots(4,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.scatterplot(x=n,y='AveragePrice',data=df,ax=ax[r,c],color='r')\n    c+=1","a69c4ab5":"fig,ax=plt.subplots(4,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.scatterplot(x=n,y='Total Volume',data=df,ax=ax[r,c],color='k')\n    c+=1","648ba0a7":"plt.figure(figsize=(20,10))\nsns.barplot(x='region',y='Total Volume',data=df)\nplt.xticks(rotation=90)","3aadab4f":"plt.figure(figsize=(20,10))\nsns.barplot(x='region',y='Total Bags',data=df)\nplt.xticks(rotation=90)","1c6a86fa":"fig,ax=plt.subplots(4,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.stripplot(x='year',y=n,data=df,ax=ax[r,c])\n    c+=1","22a9a0a0":"fig,ax=plt.subplots(4,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.stripplot(x='type',y=n,data=df,ax=ax[r,c])\n    c+=1","a7c37d90":"data=df.groupby(['AveragePrice','year']).apply(lambda x:x['Total Volume'].count()).reset_index(name='Volume')\npx.line(data,x='AveragePrice',y='Volume',color='year',title='Average Price of Avacados by Volume for year 2015 and 2016  ')","e36ada77":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Total Volume',y='Total Bags',hue='AveragePrice',data=df)","56626199":"plt.figure(figsize=(10,10))\nsns.scatterplot(x='Total Bags',y='4225',hue='AveragePrice',data=df)","b6ef4f6f":"plt.figure(figsize=(13,10))\nsns.heatmap(df.corr(),annot=True,cmap='Greys')","e58e9e94":"#year column also need to be removed as we already have date column.\ndf.drop(['Unnamed: 0','year'],axis=1,inplace=True)","1b314824":"#Converting date column into datetime format\ndf['Date']=pd.to_datetime(df['Date'])","ebb7a565":"#Extracting month, day and year info from date column then dropping it.\ndf['Month']=df['Date'].apply(lambda x:x.month)\ndf['Day']=df['Date'].apply(lambda x:x.day)\ndf['Year']=df['Date'].apply(lambda x:x.year)\ndf.drop('Date',axis=1,inplace=True)","db4e0502":"plt.figure(figsize=(15,8))\nsns.lineplot(x='Month',y='AveragePrice',hue='Year',ci=18,data=df)","44a592ca":"#We replace 2015 by 1 and 2016 by 2 for more simplicity\ndf['Year'].replace(2015,1,inplace=True)\ndf['Year'].replace(2016,2,inplace=True)\ndf['Year'].replace(2017,3,inplace=True)\ndf['Year'].replace(2018,24,inplace=True)","c4b39dba":"#we create a time column using year,month and day column and then drop these 3.\ndf['Time']=(df['Year']*365)+(df['Month']*30)+(df['Day'])\ndf.drop(['Year','Month','Day'],axis=1,inplace=True)","0b8a58cc":"from sklearn.preprocessing import OrdinalEncoder\no=OrdinalEncoder()","1bbce447":"df['region']=o.fit_transform(df['region'].values.reshape(-1,1))\ndf['type']=o.fit_transform(df['type'].values.reshape(-1,1))","c69fedfd":"#Function to choose the right threshold \ndef threhold(z,d):\n    for i in np.arange(3,4,0.01):\n        data=d.copy()\n        data=data[(z<i).all(axis=1)]\n        loss=(d.shape[0]-data.shape[0])\/d.shape[0]*100\n        print('With threshold {} data loss is {}%'.format(np.round(i,2),np.round(loss,2))) ","96034278":"#Using zscore method to remove outliers\nfrom scipy.stats import zscore\nz=np.abs(zscore(df))\nthrehold(z,df)","7bfdb515":"#We use threshold as 3.57 because we cannot afford to loose much data\ndf=df[(z<3.57).all(axis=1)]","8ead8280":"cont.append('Time')","c18423d4":"from sklearn.preprocessing import PowerTransformer\npt=PowerTransformer()","909379c0":"#We make use of power transformer to remove skewness from all columns except from Total volume as it was incapable\nfor i in cont:\n    if np.abs(df[i].skew())>0.5 and i!='Total Volume':\n        df[i]=pt.fit_transform(df[i].values.reshape(-1,1))\n\n# To remove skewness from total volume column we ise log transformation\ndf['Total Volume']=np.log(df['Total Volume'])","d39e1ce3":"fig,ax=plt.subplots(5,2,figsize=(15,25))\nr=0\nc=0\nfor i,n in enumerate(cont):\n    if r==4 and c==1:\n        break\n    if i%2==0 and i>0:\n        r+=1\n        c=0\n    sns.distplot(df[n],ax=ax[r,c])\n    c+=1","e91000ab":"df.skew()","cd3cc236":"x=df.copy()\nx.drop('AveragePrice',axis=1,inplace=True)\n\ny=df['AveragePrice']","452e633f":"#Scaling the data using min max scaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()","2d43a30c":"xd=scaler.fit_transform(x)\nx=pd.DataFrame(xd,columns=x.columns)","28722190":"from sklearn.model_selection import train_test_split,cross_val_score","1e12d50e":"#importing models\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\nfrom xgboost import XGBRegressor","13847fd1":"from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error","4c615440":"#Choosing the best random state using Logistic regression\ndef randomstate(a,b):\n    maxx=1000\n    for state in range(1,201):\n        xtrain,xtest,ytrain,ytest=train_test_split(a,b,test_size=0.25,random_state=state)\n        model=LinearRegression()\n        model.fit(xtrain,ytrain)\n        p=model.predict(xtest)\n        mse=mean_squared_error(p,ytest)\n        if maxx>mse:\n            maxx=mse\n            j=state\n    return j","370b8b15":"#Creating list of models and another list mapped to their names\nmodels=[KNeighborsRegressor(),SVR(),LinearRegression(),Lasso(),Ridge(),ElasticNet(),DecisionTreeRegressor(),\n       RandomForestRegressor(),AdaBoostRegressor(),GradientBoostingRegressor(),XGBRegressor()]\n\nnames=['KNeighborsRegressor','SVR','LinearRegression','Lasso','Ridge','ElasticNet','DecisionTreeRegressor',\n       'RandomForestRegressor','AdaBoostRegressor','GradientBoostingRegressor','XGBRegressor']","8bbad367":"def createmodels(model_list,independent,dependent,n):\n    xtrain,xtest,ytrain,ytest=train_test_split(independent,dependent,test_size=0.25,random_state=randomstate(independent,dependent))\n    name=[]\n    meanabs=[]\n    meansqd=[]\n    rootmeansqd=[]\n    r2=[]\n    mcv=[]\n    \n    #Creating models\n    for i,model in enumerate(model_list):\n        model.fit(xtrain,ytrain)\n        p=model.predict(xtest)\n        score=cross_val_score(model,independent,dependent,cv=10)\n        \n        #Calculating scores of the model and appending them to a list\n        name.append(n[i])\n        meanabs.append(np.round(mean_absolute_error(p,ytest),4))\n        meansqd.append(np.round(mean_squared_error(p,ytest),4))\n        rootmeansqd.append(np.round(np.sqrt(mean_squared_error(p,ytest)),4))\n        r2.append(np.round(r2_score(p,ytest),2))\n        mcv.append(np.round(np.mean(score),4))\n    \n    #Creating Dataframe\n    data=pd.DataFrame()\n    data['Model']=name\n    data['Mean Absolute Error']=meanabs\n    data['Mean Squared Error']=meansqd\n    data['Root Mean Squared Error']=rootmeansqd\n    data['R2 Score']=r2\n    data['Mean of Cross validaton Score']=mcv\n    data.set_index('Model',inplace = True)\n    return data\n        ","cdcd97ba":"createmodels(models,x,y,names)","41d90ef2":"from sklearn.model_selection import GridSearchCV","ba0602df":"param_grid={'alpha':[1e-15,1e-10,1e-8,1e-5,1e-3,0.1,1,5,10,15,20,30,35,45,50,55,65,100,110,150,1000]}\nm1=GridSearchCV(Lasso(),param_grid,scoring='neg_mean_squared_error',cv=10)\nm1.fit(x,y)\nprint(m1.best_params_)","6a9a308f":"m1=Lasso(alpha=1e-05)\nm1.fit(x,y)","e6decff2":"importance = np.abs(m1.coef_)","7ad7b67b":"dfcolumns = pd.DataFrame(x.columns)\ndfimp=pd.DataFrame(importance)\nfeatureScores = pd.concat([dfcolumns,dfimp],axis=1)\nfeatureScores.columns = ['Features','Coefficients']  #naming the dataframe columns\nfeatureScores","30ec7650":"featureScores.sort_values(by=['Coefficients'],ascending=False)","3546ec8c":"#We remove 1 feature\nlassoxt=x.copy()\nlassoxt.drop(['XLarge Bags'],axis=1,inplace=True)\ncreatemodels(models,lassoxt,y,names)","4bdaafae":"#We remove these 2 features\nlassoxt=x.copy()\nlassoxt.drop(['XLarge Bags','4046'],axis=1,inplace=True)\ncreatemodels(models,lassoxt,y,names)","b0140fb1":"xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25,random_state=randomstate(x,y))","1fb6944b":"leaf = list(range(1,50))\nk = list(range(1,30))\nparams={'n_neighbors':k,'leaf_size':leaf,'weights':['uniform','distance'],'metric':['euclidean','manhattan']}","2726d527":"g=GridSearchCV(KNeighborsRegressor(),params,cv=10)","8d5e8f80":"g.fit(xtrain,ytrain)","6c6fdf9c":"print(g.best_estimator_)\nprint(g.best_params_)\nprint(g.best_score_)","cd0829f4":"m=KNeighborsRegressor(leaf_size=1, metric='manhattan', n_neighbors=3,weights='distance')\nm.fit(xtrain,ytrain)\np=m.predict(xtest)\nscore=cross_val_score(m,x,y,cv=10)","7b085bd6":"print('Mean Absolute Error is',np.round(mean_absolute_error(p,ytest),4))\nprint('Mean Squared Error is',np.round(mean_squared_error(p,ytest),4))\nprint('Root Mean Squared Error is',np.round(np.sqrt(mean_squared_error(p,ytest)),4))\nprint('R2 Score is',np.round(r2_score(p,ytest),4)*100)\nprint('Mean of cross validaton Score is',np.round(np.mean(score)*100,4))","24ae2372":"from sklearn.model_selection import RandomizedSearchCV","628d227c":"params={'n_estimators':[100, 300, 500, 700],\n        'min_samples_split':[1,2,3,4],\n        'min_samples_leaf':[1,2,3,4],\n            'max_depth':[None,1,2,3,4,5,6,7,8]}","3131e8b3":"g=RandomizedSearchCV(RandomForestRegressor(),params,cv=10)","bdbeb25f":"g.fit(xtrain,ytrain)","7702a45c":"print(g.best_estimator_)\nprint(g.best_params_)\nprint(g.best_score_)","3df44e88":"m=RandomForestRegressor(max_depth=8, min_samples_leaf=2, min_samples_split=3,n_estimators=500)\nm.fit(xtrain,ytrain)\np=m.predict(xtest)\nscore=cross_val_score(m,x,y,cv=10)","147283b2":"print('Mean Absolute Error is',np.round(mean_absolute_error(p,ytest),4))\nprint('Mean Squared Error is',np.round(mean_squared_error(p,ytest),4))\nprint('Root Mean Squared Error is',np.round(np.sqrt(mean_squared_error(p,ytest)),4))\nprint('R2 Score is',np.round(r2_score(p,ytest),4)*100)\nprint('Mean of cross validaton Score is',np.round(np.mean(score)*100,4))","76d2b807":"params={\n \"learning_rate\"    : [0.001,0.05, 0.10, ] ,\n \"max_depth\"        : [ 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n    }","b5574c7b":"g=RandomizedSearchCV(XGBRegressor(verbosity=0),params,cv=10)","17c345c0":"g.fit(xtrain,ytrain)","cdd2e5b9":"print(g.best_estimator_)\nprint(g.best_params_)\nprint(g.best_score_)","131f3c4f":"m=XGBRegressor(colsample_bytree=0.5,gamma=0.1,learning_rate=0.1,max_depth=15,min_child_weight=7)\nm.fit(xtrain,ytrain)\np=m.predict(xtest)\nscore=cross_val_score(m,x,y,cv=10)","e0f1ba0b":"print('Mean Absolute Error is',np.round(mean_absolute_error(p,ytest),4))\nprint('Mean Squared Error is',np.round(mean_squared_error(p,ytest),4))\nprint('Root Mean Squared Error is',np.round(np.sqrt(mean_squared_error(p,ytest)),4))\nprint('R2 Score is',np.round(r2_score(p,ytest),4)*100)\nprint('Mean of cross validaton Score is',np.round(np.mean(score)*100,4))","6b12f424":"model=XGBRegressor(colsample_bytree=0.5,gamma=0.1,learning_rate=0.1,max_depth=15,min_child_weight=7)\nmodel.fit(xtrain,ytrain)\np=model.predict(xtest)\nscore=cross_val_score(m,x,y,cv=10)","e39686cb":"print('Mean Absolute Error is',np.round(mean_absolute_error(p,ytest),4))\nprint('Mean Squared Error is',np.round(mean_squared_error(p,ytest),4))\nprint('Root Mean Squared Error is',np.round(np.sqrt(mean_squared_error(p,ytest)),4))\nprint('R2 Score is',np.round(r2_score(p,ytest),4)*100)\nprint('Mean of cross validaton Score is',np.round(np.mean(score)*100,4))","2095e79a":"plt.scatter(x=ytest,y=p,color='r')\nplt.plot(ytest,ytest,color='b')\nplt.xlabel('Actual Average Price')\nplt.ylabel('Predicted Average Price')\nplt.title('XGBRegressor')","00a27171":"import joblib\njoblib.dump(model,'avacadoprice.obj')","da376fd3":"Average price shows positive relationship with the year column while negative correlation with all the other column. Intresting thing to notice here is that independent features show more than 90% correlation with each other. This is a case of multicollinearity. We need to remove some features to resolve this problem.","c5b4022f":"###### Separating the dependent and independent variables.","2ece6bae":"###### Xtreme Gradient Boost","23b51315":"###### Knearest Neighbor","dd5dda79":"Skewness is almost negligible after using tranformations techniques. Only XLarge bags shows skewness in graph but it is still reduced considerably.","5b0421c6":"Most of the Total volume of Avacados is concentrated below 1e7 volumes while it goes upto 62505646.52 volumes. Data is higly skewed to the right, which needs to be taken care of ahead.","214fb918":"###### Random Forest","fb05af03":"### Bivariate Analysis","75cfd215":"There are 54 regions in total. All the region produces almost equal amounts of avocados except for west tex new mexico which has slightly less number.","fd578903":"# **If you like my work please upvote!!!! Thanks**","4da1857e":"All the columns have count equal to 18249. Mean and median have high difference except for Average price stating that data has high skewness present. There is high variance in all the columns except for Average price and year column. Difference between min, max and interquartile ranges is uneven hence there are a no. of outliers present in the data.","fd9dc8b5":"There are no null values.","5d7a7067":"There are a large number of outliers present in all the features that is needed to be removed.","f1f867d4":"With the increase in total volumes of avacado, quatity of all types of bags as well as PLU's also increases. This is logical as if volume of avacado's increases, no. of bags needed to carry it and PLU's inreases.","cc1c4f3e":"Large bags has most of its density near to its minimum value which is 0 and goes up to a range of 13384586.8 with its maximum value. Data is clearly skewed to the right.","4b53d02a":"# Hyperparameter Tuning","bc89c263":"Avocados are collected from all the regions irrespective of the year. For each year avocados are collected from all the same regions.","8c08ab26":"Average price of avacado's is high in the month of September October November. As the season for avocado's is in the summer, off season fruit is expensive. We have data for year 2018 till march only","ff1a7477":"###### Removing Outliers","efb3a3c6":"Organic Avacoados are more expensive than the conventional ones.","f96c9d6d":"Avacados with Product look up code 4225 is mostly concentrated near the minimum and the minimum equal to 0, whereas the range goes up to 20470572.61 as the maximum. Data is higly skewed to the right, which needs to be taken care of ahead in the data engineering process.","5845c581":"As the total volume increases, Total bags also increases to carry it but the average price seem to decrease. When the volumes of avacados are low average price increases of avacados.","2bff7283":"Xtra large bags are densely populated in the range 0 to 5000, whereas they are spread till values more than 5 lakh. Distribution of data is highly right skewed.","3db3ab72":"Data is higly skewed in almost all the columns.","17e3fbc5":"As removing features also leads to some data loss, so the model's performance have decreased, therefore we will not remove any features.","ec103c74":"![](https:\/\/www.sickchirpse.com\/wp-content\/uploads\/2015\/07\/Avocado-Price.jpg)","830270ad":"Average price is highest in the year 2016, but relatively price seem to increase as the time passes except for the year 2018 which is an exception. ","c40d4c05":"Average price of avacado's for the year 2016 was way more than any other year, but highest volumes of avacado's were produced in 2015,reaching to a mark of 85, after that the produce of avocados seem to decrease. It is also to be noted that high volumes of avocados are sold at lower average price.","c896db66":"### Removing multicollinearity ussing L1 Regularisation","632d6662":"Most of the data is from 2017 followed by 2016 and 2015 respectively, while 2018 has the least data.","244ef08f":"XGBRegressor is giving the best performance with minimum error compared to all the models, so we choose it as out final model.","0def8c62":"Dataframe have 3 columns with object type data, which we need to encode.","dbf8ac3d":"As PlU's increases so does the no. of total bags but as we know if supply of something increases its price decreases. Same thing can be seen here.","b6163f16":"### Finalizing the Model","c060e2fe":"Total bags has most of its density near to its minimum value and goes up to a range of 19373134.37 with its maximum value. Data is clearly skewed to the right.","fe943285":"Average price shows a negative correlation as the average price seem to decrease as total volumes, PLU's and types of bags increases which means that average price decreases as the quantity of avacado's decreases.","86b9b215":"###### Encoding","9169b980":"There are no constant or identifier column.","0e11a2e5":"Data is similar to the previous bar chart, as the volumes of avacado increases in a region, total bags also increases to carry those avacado's.","5915538b":"###### Scaling the data","210f4f8d":"### Multivariate Analysis","1d8eb7cb":"# Feature Engineering","9fdb9bc0":"Average price of avacados little skewed, price ranging from 0.44 t0 3.25 ","6cf5aa63":"# Evaluation Metrics","ef89e221":"Unnamed: 0 seems to be a identifier column and needs to be removed.","3cf3357c":"###### Handling date column","23f8dde5":"# EDA","ffd10f22":"###### Removing identifier and constant columns","5b43dc1d":"There two types organic and conventional are almost equal and balanced.","996d6904":"Importing neccessary modules","02ba6937":"There are 18249 rows and 14 columns","6a45b782":"Highest average price for avacaodo's were in San diego, Las vegas and cahrlotte regions while the least was from phoenix tucson. It is also to be noted that highest average price belong from areas where there is more development.","f264b350":"Avacados with Product look up code 4770 is mostly concentrated near the minimum and the minimum equal to 0, whereas the range goes up to 2546439.11 as the maximum. Data is higly skewed to the right, which needs to be taken care of ahead in the data engineering process.","36c7f8df":"Highest volumes of avacado's are found in the US. That could be the reason price of avacado's low there. As supply increases price decreases,whereas region with less volume such as las vegas have the highest price of avacado's.","e6cc0c82":"# Saving the Model","369d0f5f":"Avacados with Product look up code 4046 is mostly concentrated near the minimum whereas the range goes up to 22743616.17. Data is higly skewed to the right, which needs to be taken care of ahead.","08786308":"###### We apply Hperparameter tuning on Knearest Neighbor, Random Forest and xtreme Gradient Boost as they are giving the best performance for our dataset","3ac74cab":"Toal volumes. types of bags, and PLU's are all high for convetional type of avocados, this states that although price of organic type is high but cobventional types of avocados are more produced.","3c7106ad":"###### Removing Skewness","56077b8e":"Though data for the year 2018 is very low but we can see that total volume, types of bags and PLUs are highest for 2018. As the time has passed volumes, bags to carry avocados  and plus have increased without any doubt.","3a918537":"# Modelling Phase","7c826c15":"### Univariate Analysis","5ee7ae53":"Large bags has most of its density near to its minimum value which is 0 and goes up to a range of 5719096.61 with its maximum value. Data is clearly skewed to the right."}}