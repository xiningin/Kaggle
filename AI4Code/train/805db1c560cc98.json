{"cell_type":{"dc65b836":"code","04252cfc":"code","b4df7612":"code","8d0481c5":"code","829ce526":"code","0137e1c5":"code","38091915":"code","b5d147c8":"code","525b951c":"markdown","e658c315":"markdown","874480b7":"markdown","6639737c":"markdown","1907b70d":"markdown","f83637a4":"markdown"},"source":{"dc65b836":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Import the sklearn\nfrom sklearn import * ","04252cfc":"df=pd.read_csv('\/kaggle\/input\/iris\/Iris.csv',index_col='Id')\nprint('No. of Row: {}'.format(df.shape[0]))\nprint('----------------------------------')\nprint(df.head())\nprint('-----------------------------------')\n\ntarget='Species'\nfeatures=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']","b4df7612":"df.groupby(by=['Species']).count().plot(y='PetalLengthCm',kind='pie',\n                                        title='Count of Iris Species',\n                                        ylabel='',\n                                        figsize=(6,6),fontsize=18,\n                                        legend=False,\n                                       );","8d0481c5":"import matplotlib.pyplot as plt\n\n#Distribution of the features\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(20,10))\ndf.plot(y='SepalLengthCm',kind='kde',ax=axes[0,0],title='SepalLengthCm',legend=False)\ndf.plot(y='SepalWidthCm',kind='kde',ax=axes[0,1],title='SepalWidthCm',legend=False)\ndf.plot(y='PetalLengthCm',kind='kde',ax=axes[1,0],title='PetalLengthCm',legend=False)\ndf.plot(y='PetalWidthCm',kind='kde',ax=axes[1,1],title='PetalWidthCm',legend=False);","829ce526":"X_train, X_test, y_train, y_test = model_selection.train_test_split(df[features], \n                                                                     df[target],\n                                                                     test_size=.3, \n                                                                     random_state=42)\n\nle = preprocessing.LabelEncoder()\n\ny_train=le.fit_transform(y_train)\ny_test=le.transform(y_test)","0137e1c5":"#Define the model\nmodel = ensemble.RandomForestClassifier()\n# model_two= tree.DecisionTreeClassifier()\n\n#Define the model pipeline with Scaler value with will MinMaxScaler which scale between the 0 to 1\nclf=pipeline.Pipeline(steps=[('preprocessor', preprocessing.MinMaxScaler()),\n                              ('model', model)\n                             ])\n# fit model \nclf.fit(X_train, y_train)\n\n# Preprocessing of validation data, get prediction\ny_preds = clf.predict(X_test)\n\n\n#Obtain the score between 0 to 1\nscore=metrics.accuracy_score(y_test, y_preds)\nprint('\\n--------------------------------------')\nprint('Accuracy Score:  {}'.format(score))","38091915":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport eli5\neli5.show_weights(clf, feature_names = features)","b5d147c8":"# import shap  # package used to calculate Shap values\n\n# # Create object that can calculate shap values\n# explainer = shap.TreeExplainer(clf.named_steps[\"model\"],)\n\n# # Calculate Shap values\n# data_for_prediction=X_valid.iloc[0]\n# shap_values = explainer.shap_values(data_for_prediction)\n\n\n# shap.initjs()\n# shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","525b951c":"### EDA","e658c315":"### Distribution of the features\n\nAll features are more or less normally spread","874480b7":"All target classes data is evenly spread","6639737c":"# Model Weight ","1907b70d":"### Build the model pipeline","f83637a4":"### Split the data into 70 : 30 ratio as train and test data & Encode the target data into labelEncoder"}}