{"cell_type":{"a390e985":"code","557c5caf":"code","7754b369":"code","4531d293":"code","fa87cfb9":"code","e7e2d788":"code","7e085cc0":"code","81994739":"code","0e7d164c":"code","5412a472":"code","587e9262":"code","cf5b04a3":"code","4c3b0d38":"code","2f1ef945":"code","75f60fe4":"code","95096a7d":"code","d982a34a":"code","38af50c7":"code","b3008d0c":"code","7ba16613":"code","7acf8249":"code","416f4ce5":"code","1e719ab7":"code","8c27e292":"code","42d2142a":"code","38c44b12":"code","3e972adc":"code","9bf952a9":"markdown","416cdead":"markdown","20158629":"markdown","37bd8f5e":"markdown","38c017d9":"markdown","dc270f97":"markdown"},"source":{"a390e985":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import TruncatedSVD\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","557c5caf":"df_samp=pd.read_csv(r'\/kaggle\/input\/estee-hackathon-2020\/SampleSubmission.csv')\ndf_samp","7754b369":"df_tr=pd.read_csv(r'\/kaggle\/input\/estee-hackathon-2020\/TrainingData.csv')\ndf_tr","4531d293":"df_ts=pd.read_csv(r'\/kaggle\/input\/estee-hackathon-2020\/TestingData.csv')\ndf_ts","fa87cfb9":"df_tr['Date']=df_tr['Timestamp'].apply(lambda x: x.split(' ')[0])\ndf_tr['Time']=df_tr['Timestamp'].apply(lambda x: x.split(' ')[1])\ndf_tr","e7e2d788":"df_tr=df_tr.drop(columns=['Timestamp'])\ndf_tr","7e085cc0":"df_tr['Date']=df_tr['Date'].astype(str)\ndf_tr['Time']=df_tr['Time'].astype(str)","81994739":"df_tr['Year']=df_tr['Date'].apply(lambda x: x.split('-')[0])\ndf_tr['Month']=df_tr['Date'].apply(lambda x: x.split('-')[1])\ndf_tr['Day']=df_tr['Date'].apply(lambda x: x.split('-')[2])\ndf_tr['Hour']=df_tr['Time'].apply(lambda x: x.split(':')[0])\ndf_tr['Min']=df_tr['Time'].apply(lambda x: x.split(':')[1])\ndf_tr['Sec']=df_tr['Time'].apply(lambda x: x.split(':')[2])\ndf_tr","0e7d164c":"df_tr=df_tr.drop(columns=['Date'])\ndf_tr=df_tr.drop(columns=['Time'])\ndf_tr","5412a472":"main_df=df_tr","587e9262":"df_target=df_tr[['Return']]\ndf_target","cf5b04a3":"df_tr=df_tr.drop(columns=['Return'])\ndf_tr","4c3b0d38":"scaler = StandardScaler()\n# Fit on training set only.\nscaler.fit(df_tr)\n# Apply transform to both the training set and the test set.\ntrain_img = scaler.transform(df_tr)","2f1ef945":"# Make an instance of the Model\npca = PCA(.96)","75f60fe4":"pca.fit(train_img)","95096a7d":"df1 = pca.transform(df_tr)\ndf1","d982a34a":"df1=pd.DataFrame(df1)\ndf1","38af50c7":"df1.columns=[\"pc_\"+str(i) for i in range(len(df1.columns))]\ndf1","b3008d0c":"df_tr=pd.concat([df_target,df1],axis=1)\ndf_tr","7ba16613":"# df_tr.to_csv(\"TrainingData_pca.csv\",index=False)\n# df_tr","7acf8249":"df=main_df\ndf","416f4ce5":"df_target=df[['Return']]\ndf=df.drop(columns=['Return'])\ndf","1e719ab7":"print(\"Original Matrix:\")\nprint(df)\n\nsvd =  TruncatedSVD(n_components = 100)\nA_transf = svd.fit_transform(df)\n\nprint(\"Singular values:\")\nprint(svd.singular_values_)\n\nprint(\"Transformed Matrix after reducing to 100 features:\")\nprint(A_transf)","8c27e292":"df1=pd.DataFrame(A_transf)\ndf1","42d2142a":"df1.columns=[\"svd_\"+str(i) for i in range(len(df1.columns))]\ndf1","38c44b12":"df_tr=pd.concat([df_target,df1],axis=1)\ndf_tr","3e972adc":"# df_tr.to_csv(\"TrainingData_svd.csv\",index=False)\n# df_tr","9bf952a9":"### PCA","416cdead":"Storing the main dataframe for future reference ","20158629":"# Training Data","37bd8f5e":"## Dimension Reduction","38c017d9":"Now once this dimensionality reduction techniques have been applied and processed we can now used ML algorithms from henceforth.","dc270f97":"### Truncated SVD"}}