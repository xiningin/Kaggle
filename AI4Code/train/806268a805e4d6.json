{"cell_type":{"0ae165d5":"code","53671809":"code","4affe95c":"code","a6fab3ba":"code","0c30a320":"code","6c464051":"code","47f4c03f":"code","de26fca8":"code","987d80ea":"code","3f17ac8c":"code","9f063645":"code","013d4e8d":"code","b6b3a092":"code","fc35e321":"code","dc8cf6b4":"code","76904c74":"code","254f021a":"code","1a526f9e":"code","4536621a":"code","87b7bee9":"code","da0e5cb6":"code","1659c95e":"code","cd5f8d23":"code","2944cf16":"code","d537195d":"code","b0881e5c":"code","9f1b237c":"code","a36b5c72":"code","ab0f06a9":"code","ba656e23":"code","b9c5af5d":"code","0cf3192e":"code","b4a41ba9":"code","54f93de0":"code","ad2d50de":"code","63520c5b":"code","3dd9c451":"code","864ef3de":"code","e7683dae":"markdown"},"source":{"0ae165d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53671809":"#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt","4affe95c":"#Retrieving training and test data\ntrain_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nboth = [train_df, test_df]","a6fab3ba":"#Columns\nprint('train columns \\n')\nprint(train_df.columns.values)\nprint('\\ntest columns \\n')\nprint(test_df.columns.values)","0c30a320":"train_df.info()","6c464051":"train_df.describe()","47f4c03f":"test_df.describe()","de26fca8":"train_df.describe(include=['O'])","987d80ea":"#train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","3f17ac8c":"import seaborn as sns","9f063645":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","013d4e8d":"sb.barplot(x='Pclass', y='Survived', data=train_df, color='r')","b6b3a092":"sb.barplot(x='Sex', y='Survived', data=train_df, color='r')","fc35e321":"sb.barplot(x='Parch', y='Survived', data=train_df, color='r')","dc8cf6b4":"sb.barplot(x='Survived', y='Fare', data=train_df, color='r')","76904c74":"train_df = train_df.drop(columns=['PassengerId', 'Ticket', 'Cabin', 'Name'])\ntest_Ids = test_df['PassengerId']\ntest_df = test_df.drop(columns=['PassengerId', 'Ticket', 'Cabin', 'Name'])","254f021a":"train_df.head()","1a526f9e":"for cols in train_df:\n    print(\"col : {} -- {}= {}\".format(type(train_df[cols][0]),cols,train_df[cols].isnull().sum()))","4536621a":"for cols in test_df:\n    print(\"col : {} -- {}= {}\".format(type(test_df[cols][0]),cols,test_df[cols].isnull().sum()))","87b7bee9":"train_df = train_df.fillna(train_df['Age'].mean())\ntrain_df = train_df.fillna(train_df['Embarked'].mode())\n\ntest_df = test_df.fillna(test_df['Age'].mean())\ntest_df = test_df.fillna(test_df['Fare'].mean())","da0e5cb6":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n","1659c95e":"encoder = LabelEncoder()\ntrain_df['Sex'] = encoder.fit_transform(train_df['Sex'].astype(str))\ntrain_df['Embarked'] = encoder.fit_transform(train_df['Embarked'].astype(str))\n\ntest_df['Sex'] = encoder.fit_transform(test_df['Sex'].astype(str))\ntest_df['Embarked'] = encoder.fit_transform(test_df['Embarked'].astype(str))\n\ntest_df.head()","cd5f8d23":"#Getting training data using train test split\nx_train, x_val, y_train, y_val = train_test_split(train_df.drop('Survived', axis=1), train_df['Survived'], \n                                                 test_size=0.25, random_state=42)\n","2944cf16":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","d537195d":"#Logistic Regression\nlg = LogisticRegression()\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","b0881e5c":"#Gaussian Naive Bayes\nGNB = GaussianNB()\nGNB.fit(x_train, y_train)\ny_pred = GNB.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","9f1b237c":"#Random Forest\nRF = RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=8,random_state=7,\n                            class_weight='balanced')\nRF.fit(x_train, y_train)\ny_pred = RF.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","a36b5c72":"RF = RandomForestClassifier(n_estimators=300)\nRF.fit(x_train, y_train)\ny_pred = RF.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","ab0f06a9":"RF250 = RandomForestClassifier(criterion='entropy',n_estimators=250,max_depth=9,random_state=7,\n                            class_weight='balanced')\nRF250.fit(x_train, y_train)\ny_pred = RF250.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","ba656e23":"RF300 = RandomForestClassifier(criterion='entropy',n_estimators=300,max_depth=9,random_state=7,\n                            class_weight='balanced')\nRF300.fit(x_train, y_train)\ny_pred = RF300.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","b9c5af5d":"#Support Vector Machines\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","0cf3192e":"#KNearest Neighbour\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","b4a41ba9":"#Perceptron\npn = Perceptron()\npn.fit(x_train, y_train)\ny_pred = pn.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","54f93de0":"#Linear SVC\nlinSVC = LinearSVC()\nlinSVC.fit(x_train, y_train)\ny_pred = linSVC.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","ad2d50de":"tree = DecisionTreeClassifier()\ntree.fit(x_train, y_train)\ny_pred = tree.predict(x_val)\nprint(accuracy_score(y_pred, y_val))","63520c5b":"#Random Forest 250 estimators, most accurate model\n\nmodel = RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=8,random_state=7,\n                            class_weight='balanced')\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_val)\nprint(accuracy_score(y_pred, y_val))\n\n","3dd9c451":"#retrieving passenger Ids\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_passenger_Id = test['PassengerId']","864ef3de":"predictions = model.predict(test_df)\noutput = pd.DataFrame({'PassengerId': test_passenger_Id, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e7683dae":"Checking Data"}}