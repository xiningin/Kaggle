{"cell_type":{"139f21b5":"code","43e51492":"code","3afbe48a":"code","3c20a3e1":"code","93f250c0":"code","727dfd79":"code","c52d41b5":"code","483a2bcc":"code","3afec407":"code","86927653":"code","bebe1906":"code","8c60e3ac":"code","16b6f76e":"code","eb1f2b87":"code","da7c3b8e":"code","1cbc5c38":"code","01adf6ad":"code","57d92ccf":"code","63391a1e":"code","4c34223c":"code","f5c4c438":"code","103899f8":"code","eb9299fd":"code","5d72f676":"code","1172c106":"code","973fd7fc":"code","27bc5855":"code","3212dbb5":"markdown","f934cc82":"markdown","a89c36bb":"markdown","fe35103c":"markdown","aca88d9a":"markdown","04a9525f":"markdown","08c01715":"markdown","68ddec77":"markdown","b463f0b0":"markdown","1aa0faf9":"markdown","0fe9241d":"markdown","23ee391e":"markdown","f7f05c13":"markdown"},"source":{"139f21b5":"from IPython.display import clear_output\n!pip install timm\n!pip install git+https:\/\/github.com\/fbcotter\/pytorch_wavelets\nclear_output()","43e51492":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.distributions import Categorical\nimport math\n\nfrom torchvision import models\nimport timm \nfrom pytorch_wavelets import DWT1DForward, DWT1DInverse,ScatLayer\n\nfrom torch.utils.data import Dataset,DataLoader\n\nimport gc\nimport time\nimport matplotlib.pyplot as plt","3afbe48a":"class VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        all_feat_cols = np.arange(143360)\n        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n        self.dropout0 = nn.Dropout(0.2)\n\n        dropout_rate = 0.2\n        hidden_size = 256\n        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n\n        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n\n        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n\n#         self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n\n        self.Relu = nn.ReLU(inplace=True)\n        self.PReLU = nn.PReLU()\n        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        # self.GeLU = nn.GELU()\n        self.RReLU = nn.RReLU()\n\n    def forward(self, x):\n        x = self.batch_norm0(x)\n        x = self.dropout0(x)\n\n        x1 = self.dense1(x)\n        x1 = self.batch_norm1(x1)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x1 = self.LeakyReLU(x1)\n        x1 = self.dropout1(x1)\n\n        x = torch.cat([x, x1], 1)\n\n        x2 = self.dense2(x)\n        x2 = self.batch_norm2(x2)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x2 = self.LeakyReLU(x2)\n        x2 = self.dropout2(x2)\n\n        x = torch.cat([x1, x2], 1)\n\n        x3 = self.dense3(x)\n        x3 = self.batch_norm3(x3)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x3 = self.LeakyReLU(x3)\n        x3 = self.dropout3(x3)\n\n        x = torch.cat([x2, x3], 1)\n\n        x4 = self.dense4(x)\n        x4 = self.batch_norm4(x4)\n        # x = F.relu(x)\n        # x = self.PReLU(x)\n        x4 = self.LeakyReLU(x4)\n        x4 = self.dropout4(x4)\n\n        x = torch.cat([x3, x4], 1)\n\n#         x = self.dense5(x)\n\n        return x","3c20a3e1":"class Sparsemax(nn.Module):\n    def __init__(self, dim=None):\n        super(Sparsemax, self).__init__()\n        self.dim = -1 if dim is None else dim\n\n    def forward(self, input):\n        input = input.transpose(0, self.dim)\n        original_size = input.size()\n        input = input.reshape(input.size(0), -1)\n        input = input.transpose(0, 1)\n        dim = 1\n\n        number_of_logits = input.size(dim)\n        \n        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n        range = torch.arange(start=1, end=number_of_logits + 1, device=device,step=1, dtype=input.dtype).view(1, -1)\n        range = range.expand_as(zs)\n\n        bound = 1 + range * zs\n        cumulative_sum_zs = torch.cumsum(zs, dim)\n        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n        zs_sparse = is_gt * zs\n        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) \/ k\n        taus = taus.expand_as(input)\n        self.output = torch.max(torch.zeros_like(input), input - taus)\n        output = self.output\n        output = output.transpose(0, 1)\n        output = output.reshape(original_size)\n        output = output.transpose(0, self.dim)\n        return output\n    def backward(self, grad_output):\n        dim = 1\n        nonzeros = torch.ne(self.output, 0)\n        sum = torch.sum(grad_output * nonzeros, dim=dim) \/ torch.sum(nonzeros, dim=dim)\n        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n        return self.grad_input\n    \ndef initialize_non_glu(module,inp_dim,out_dim):\n    gain = np.sqrt((inp_dim+out_dim)\/np.sqrt(4*inp_dim))\n    torch.nn.init.xavier_normal_(module.weight, gain=gain)\n    \nclass GBN(nn.Module):\n    def __init__(self,inp,vbs=128,momentum=0.01):\n        super().__init__()\n        self.bn = nn.BatchNorm1d(inp,momentum=momentum)\n        self.vbs = vbs\n    def forward(self,x):\n        chunk = torch.chunk(x,max(1,x.size(0)\/\/self.vbs),0)\n        res = [self.bn(y) for y in chunk ]\n        return torch.cat(res,0)\n\nclass GLU(nn.Module):\n    def __init__(self,inp_dim,out_dim,fc=None,vbs=128):\n        super().__init__()\n        if fc:\n            self.fc = fc\n        else:\n            self.fc = nn.Linear(inp_dim,out_dim*2)\n        self.bn = GBN(out_dim*2,vbs=vbs) \n        self.od = out_dim\n    def forward(self,x):\n        x = self.bn(self.fc(x))\n        return x[:,:self.od]*torch.sigmoid(x[:,self.od:])\n    \n\nclass FeatureTransformer(nn.Module):\n    def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):\n        super().__init__()\n        first = True\n        self.shared = nn.ModuleList()\n        if shared:\n            self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))\n            first= False    \n            for fc in shared[1:]:\n                self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))\n        else:\n            self.shared = None\n        self.independ = nn.ModuleList()\n        if first:\n            self.independ.append(GLU(inp,out_dim,vbs=vbs))\n        for x in range(first, n_ind):\n            self.independ.append(GLU(out_dim,out_dim,vbs=vbs))\n        self.scale = torch.sqrt(torch.tensor([.5],device=device))\n    def forward(self,x):\n        if self.shared:\n            x = self.shared[0](x)\n            for glu in self.shared[1:]:\n                x = torch.add(x, glu(x))\n                x = x*self.scale\n        for glu in self.independ:\n            x = torch.add(x, glu(x))\n            x = x*self.scale\n        return x\n    \nclass AttentionTransformer(nn.Module):\n    def __init__(self,inp_dim,out_dim,relax,vbs=128):\n        super().__init__()\n        self.fc = nn.Linear(inp_dim,out_dim)\n        self.bn = GBN(out_dim,vbs=vbs)\n#         self.smax = Sparsemax()\n        self.r = torch.tensor([relax],device=device)\n    def forward(self,a,priors):\n        a = self.bn(self.fc(a))\n        mask = torch.sigmoid(a*priors)\n        priors =priors*(self.r-mask)\n        return mask\n\nclass DecisionStep(nn.Module):\n    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):\n        super().__init__()\n        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)\n        self.atten_tran = AttentionTransformer(n_a,inp_dim,relax,vbs)\n    def forward(self,x,a,priors):\n        mask = self.atten_tran(a,priors)\n        loss = ((-1)*mask*torch.log(mask+1e-10)).mean()\n        x = self.fea_tran(x*mask)\n        return x,loss\n\nclass TabNet(nn.Module):\n    def __init__(self,inp_dim,final_out_dim,n_d=64,n_a=64,n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):\n        super().__init__()\n        if n_shared>0:\n            self.shared = nn.ModuleList()\n            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))\n            for x in range(n_shared-1):\n                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))\n        else:\n            self.shared=None\n        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) \n        self.steps = nn.ModuleList()\n        for x in range(n_steps-1):\n            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))\n        self.fc = nn.Linear(n_d,final_out_dim)\n        self.bn = nn.BatchNorm1d(inp_dim)\n        self.n_d = n_d\n    def forward(self,x):\n        x = self.bn(x)\n        x_a = self.first_step(x)[:,self.n_d:]\n        loss = torch.zeros(1).to(x.device)\n        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n        priors = torch.ones(x.shape).to(x.device)\n        for step in self.steps:\n            x_te,l = step(x,x_a,priors)\n            out += F.relu(x_te[:,:self.n_d])\n            x_a = x_te[:,self.n_d:]\n            loss += l\n        return self.fc(out),loss\n    \nclass TabNetWithEmbed(nn.Module):\n    def __init__(self,inp_dim,final_out_dim,n_d=64,n_a=64,n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):\n        super().__init__()\n        self.tabnet = TabNet(inp_dim,final_out_dim,n_d,n_a,n_shared,n_ind,n_steps,relax,vbs)\n        self.cat_embed = []\n        self.emb1 = nn.Embedding(2,1)\n        self.emb3 = nn.Embedding(3,1)\n        self.cat_embed.append(self.emb1)\n        self.cat_embed.append(self.emb3)\n        \n    def forward(self,catv,contv):\n        catv = catv.to(device)\n        contv = contv.to(device)\n        embeddings = [embed(catv[:,idx]) for embed,idx in zip(self.cat_embed,range(catv.size(1)))]\n        catv = torch.cat(embeddings,1)\n        x = torch.cat((catv,contv),1).contiguous()\n        x,l = self.tabnet(x)\n        return torch.sigmoid(x),l","93f250c0":"# for this run of the nn I used a feature extraction backbone, then a VAE for dim-reduction, and then finally self attention and final output layer\n\n# I would like to work more with DWT, but I don't know if it'll really be effective, I would have to try many configurations, find the one with the least error to complexity (number of coefficients).\n# DWT\/CWT coefficients may in fact be a good set of features for classification instead, I will have to read into the documentation of the library I'm using to extract them.  \n# If I can avoid the DWT entirely by doing things end to end, that would be nice, however I will not discount feature augmentation, the melspectrogram kernels use some transforms which could be \n# useful here\n\nclass NN(nn.Module):\n    def __init__(self):\n        super(NN, self).__init__()\n        #this convolutional upsample layer is a placeholder for if you are working with grayscale images and want to convert from (1,h,w) to (3,h,w)\n        #self.conv_upsample = nn.ConvTranspose2d(in_channels = 1, out_channels=3,kernel_size=1)\n        \n        #I may use this in the future for denoising the signal or extracting signal coefficients \n        #self.decompose = DWT1DForward(wave='db6', J=3)\n\n        #feature extracting backbone\n        self.timm = timm.create_model('tf_efficientnetv2_b0',features_only =True)\n        #VAE (dimensionality reduction)\n        self.vae = VAE()\n        #self attention, so as to create a better feature representation\n        self.tabnet = TabNet(512,100)\n        #Mixed Density Network (distribution modeling), this is likely unnecessary for the following problem because the problem has clearly been shown to be modelable\n        #self.mdn = MDN(100,1,7)\n        self.final = nn.Linear(100,1) \n    def forward(self,x):\n        \n        #x = self.conv_upsample(x)\n        #print(x.shape)\n        #x = torch.cat([torch.reshape(self.decompose(inp)[0],(1,3, 4096, 9)) for inp in x],dim=0) \n        \n        # extract, flatten, and concatenate the feature maps of the input \n        tim = torch.cat([torch.reshape(output,(output.shape[0],-1)) for output in self.timm(x)],dim=1)\n        #use the autencoder and the tabnet in one step\n        out,loss = self.tabnet(self.vae(tim))\n        #finally, output the results \n        return F.sigmoid(self.final(out))","727dfd79":"train_labels = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\nsample_submission = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')","c52d41b5":"train_labels.head()","483a2bcc":"y = train_labels['target'].values","3afec407":"path = list(train_labels['id'])\nfor i in range(len(path)):\n    path[i] = '..\/input\/g2net-gravitational-wave-detection\/train\/' +path[i][0]+'\/'+path[i][1]+'\/'+path[i][2]+'\/' + path[i] + '.npy'","86927653":"device = torch.device(\"cuda\")","bebe1906":"NNN = NN().to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(NNN.parameters())","8c60e3ac":"NNN.train()\nbatch_size = 10\nn_epochs = 10\nbatch_iterations  = 17\nfor i in range(n_epochs):\n    idxs = list(np.random.random_integers(0,len(path),size = batch_size))\n    train_samples = torch.Tensor(np.array([np.load(pth) for pth in np.array(path)[idxs]]).reshape(-1,3,4096,1)).to(device)\n    targets = torch.Tensor(y[idxs]).to(device)\n    loss = 0\n    for sub_step in range(batch_iterations):\n        optimizer.zero_grad()\n        outputs = NNN(train_samples)\n        loss = criterion(outputs,targets.unsqueeze(1))\n        loss.backward()\n        print(loss.item())\n        optimizer.step()\n    torch.cuda.empty_cache()\n    gc.collect() ","16b6f76e":"torch.cuda.empty_cache()\ngc.collect() ","eb1f2b87":"outputs","da7c3b8e":"def id_to_path(idx,train=True):\n    path = '..\/input\/g2net-gravitational-wave-detection\/'\n    if train:\n        folder = 'train\/'\n    else:\n        folder = 'test\/'\n    path+=folder+idx[0]+'\/'+idx[1]+'\/'+idx[2]+'\/'+idx+'.npy'\n    return path","1cbc5c38":"class ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n\n    def __call__(self, sample):\n        signal = sample['signals']\n\n        return {'signals': torch.from_numpy(signal)}","01adf6ad":"class GravDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, paths , transform=ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.paths = paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        samp = np.load(self.paths[idx]).reshape(3,4096,1)\n        \n        sample = {'signals': samp}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample","57d92ccf":"# train_idx =  train_labels['id'].values\ntest_idx = sample_submission['id'].values","63391a1e":"path = list(test_idx)\nfor i in range(len(path)):\n    path[i] = '..\/input\/g2net-gravitational-wave-detection\/test\/' +path[i][0]+'\/'+path[i][1]+'\/'+path[i][2]+'\/' + path[i] + '.npy'","4c34223c":"dataset = GravDataset(path)\nloader = DataLoader(dataset,batch_size=100,num_workers=4,shuffle = False)","f5c4c438":"NNN = NNN.cuda().float()\nclear_output()","103899f8":"preds = []","eb9299fd":"(.1*(len(path)\/100))\/(60**1 )","5d72f676":"NNN.eval()\nwith torch.no_grad():\n    for batch in loader:\n#         init_time = time.time()\n        test_batch = batch['signals'].float().cuda()\n        output = NNN(test_batch).cpu().numpy().ravel().tolist()\n        preds.extend(output)\n#         fin_time = time.time()\n#         print(fin_time - init_time)\n#     test_batch = torch.Tensor(np.array([np.load(pth) for pth in np.array(path)[idxs]]).reshape(-1,3,4096,1)).to(device)","1172c106":"submission = pd.DataFrame({'id':sample_submission['id'],'target':preds})","973fd7fc":"submission","27bc5855":"submission.to_csv('submission.csv',index=False)","3212dbb5":"# Model","f934cc82":"Lets take a look at train_labels","a89c36bb":"# Everything Related to Tabnet is below","fe35103c":"<h2><center>Work in Progress ... \u23f3<\/center><\/h2>","aca88d9a":"<div style=\"font-size:15px\">\n We are given 2 npy files and 2 csv files:-\n<ul>\n    <li><code>train:<\/code> the training set files, one npy file per observation; labels are provided in a files shown below\n<\/li>\n    <li><code>test:<\/code> the test set files; you must predict the probability that the observation contains a gravitational wave<\/li>\n    <li><code>training_labels.csv:<\/code> target values of whether the associated signal contains a gravitational wave<\/li>\n    <li><code>sample_submission.csv:<\/code> a sample submission file in the correct format\n<\/li>\n<\/ul>    \n<\/div>","04a9525f":"# About the Competition\ud83d\udea9\n<p style=\"font-size:15px\">It's been said that teamwork makes the dream work. This couldn't be truer for the breakthrough discovery of gravitational waves (GW), signals from colliding binary black holes in 2015. It required the collaboration of experts in physics, mathematics, information science, and computing. GW signals have led researchers to observe a new population of massive, stellar-origin black holes, to unlock the mysteries of neutron star mergers, and to measure the expansion of the Universe. These signals are unimaginably tiny ripples in the fabric of space-time and even though the global network of GW detectors are some of the most sensitive instruments on the planet, the signals are buried in detector noise. Analysis of GW data and the detection of these signals is a crucial mission for the growing global network of increasingly sensitive GW detectors. These challenges in data analysis and noise characterization could be solved with the help of data science.\n<\/p><p>\nIn this competition, you\u2019ll aim to detect GW signals from the mergers of binary black holes. Specifically, you'll build a model to analyze simulated GW time-series data from a network of Earth-based detectors.\n<\/p><p>\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n<\/p>","08c01715":"# This is an implementation of an MLP variational autoencoder","68ddec77":"# Data Description","b463f0b0":"# Train Dataset","1aa0faf9":"# Here's the deal, I don't want to use any melspectrograms, so I just gathered every bit of code I found cool together instead!\nThe list goes:\n* MLP Variational Autoencoder (I think)     \n* TabNet (Self attention)\n* Efficientnet\n* Wavelet calculation (in pytorch)","0fe9241d":"Good rule of thumb, if you get much poorer results when evaluating your NN with float weights\/parameters instead of double (high precision values), your NN may need additional complexity, or more training","23ee391e":"# Complete NN and thoughts","f7f05c13":"# EDA"}}