{"cell_type":{"814d5fd7":"code","2ae70aca":"code","bdeb1b80":"code","bfa4939f":"code","c971114c":"code","bbad7e84":"code","2f169248":"code","28aad5fd":"code","c8ff6a4a":"code","192803d9":"code","2e06c0ab":"code","ee721921":"code","d6b5db76":"code","8d3c7d17":"code","7e200edc":"code","66d9f693":"code","8e2dcf09":"code","ae4d4a86":"code","afe5e097":"code","7f296442":"code","462533c7":"code","740a5f9e":"code","8a54b487":"code","fa840c23":"code","b3da437b":"code","40b06045":"code","668d24d9":"code","ed1bb100":"code","a80aab69":"code","2a02379d":"code","2b37c293":"code","9623dbc9":"code","b0e4171e":"code","10567be3":"code","a3e3446b":"code","cf058e7e":"code","c42787c3":"code","b3065028":"code","35135cd4":"code","5cdad740":"code","7a829ff2":"code","daf4014c":"code","9dca8060":"code","13ef8b14":"code","db68bfc9":"code","d963f874":"code","633a7df4":"code","effb8548":"code","440dd35e":"code","1dba83d9":"code","26f05bb7":"code","f68d4301":"code","136fcc72":"code","fb318e47":"markdown","62cfa0ea":"markdown"},"source":{"814d5fd7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ae70aca":"#_______________________________________________\n# Charegement des libraries Keras \n#\nfrom tensorflow.keras.models import Sequential\n### Conv2d pour des photos - 2D si Video ou coleur alors 3D \nfrom  tensorflow.keras.layers import Conv2D\n### Pour la phse de Pooling 2D si  couleur ou Videos alors 3D\nfrom  tensorflow.keras.layers import MaxPooling2D\n### Etape 3 - Applatir dans un vector Vertical \nfrom  tensorflow.keras.layers import Flatten\n### Dense pour ajouter des couches connect\u00e9es.\nfrom  tensorflow.keras.layers import Dense\n### Droput si necessaire\nfrom tensorflow.keras.layers import MaxPool2D,Dropout\n### import Metrics\nfrom  tensorflow.keras.metrics import *\n#import keras","bdeb1b80":"#from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.optimizers import Adam, Adagrad, Adadelta, Adamax, RMSprop\nfrom  tensorflow.keras.metrics import *\nfrom tensorflow.keras import Model\n#from keras import backend as \nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\n## With Regularization\nfrom tensorflow.keras import regularizers, optimizers","bfa4939f":"from tensorflow.keras import Input\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.models import Model\nfrom tensorflow.keras.layers import Activation","c971114c":"import keras \nfrom keras import backend as K\n\n","bbad7e84":"keras.__version__","2f169248":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","28aad5fd":"# Name Label Dictionary\nname_label_dict = {\n0:  \"Nucleoplasm\", \n1:  \"Nuclear membrane\",   \n2:  \"Nucleoli\",   \n3:  \"Nucleoli fibrillar center\" ,  \n4:  \"Nuclear speckles\"   ,\n5:  \"Nuclear bodies\"   ,\n6:  \"Endoplasmic reticulum\",   \n7:  \"Golgi apparatus\"   ,\n8:  \"Intermediate filaments\",   \n9:  \"Actin filaments\"   ,\n10:  \"Microtubules\"   ,\n11:  \"Mitotic spindle\"   ,\n12:  \"Centrosome\" , \n13:  \"Plasma membrane\",   \n14:  \"Mitochondria\"   ,\n15:  \"Aggresome\"   ,\n16:  \"Cytosol\",  \n17:  \"Vesicles and punctate cytosolic patterns\",   \n18:  \"Negative\" \n}","c8ff6a4a":"#Load Train Dataset \npath_to_train = '..\/input\/hpa-single-cell-image-classification\/train\/'\ndata = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/train.csv')","192803d9":"data.head(), data.shape","2e06c0ab":"def build_labels(df):\n    # dataframe with column for each class\n    labels = list()\n    \n    for index, sample in df.iterrows():\n        # zero out class array\n        label = [0] * 19\n        \n        # for each class found in training sample, flip lablel value to one\n        for cls in sample['Label'].split('|'):\n            label[int(cls)] = 1\n\n        # Append label to list\n        labels.append( np.array(label) )\n\n    return np.vstack(labels)","ee721921":"df_train_labels = build_labels(data)\ndf_train_labels.shape","d6b5db76":"#____________________________________________________\n# Add full path to images files\ndata['image_path']=path_to_train + data['ID']","8d3c7d17":"## Join train_labels \n## Just Testing Green \"Cells\"\ndf_train_green = pd.DataFrame(data['image_path']).join(pd.DataFrame(df_train_labels))","7e200edc":"df_train_green.head()","66d9f693":"df_train_green['image_path'] = df_train_green['image_path']+'_green.png'","8e2dcf09":"pd.set_option('display.max_colwidth', None)\ndf_train_green.head()","ae4d4a86":"classes = []\nfor key, value in name_label_dict.items():\n    print(value)\n    classes.append(value)\nprint(classes)","afe5e097":"df_train_green.columns = ['path']+classes\ndf_train_green.head(2)","7f296442":"## Save dataset\n## df_train_green.to_csv('.\/df_train_green.csv', index=False)","462533c7":"## Load dataset\ndf_train_green = pd.read_csv('..\/input\/df-train-green-csv\/df_train_green.csv') ## Multioutpt Classes 19 Columns\ndf_train_green.head()","740a5f9e":"classes,type(classes)","8a54b487":"classes = ['Nucleoplasm', 'Nuclear membrane', 'Nucleoli', 'Nucleoli fibrillar center', \n           'Nuclear speckles', 'Nuclear bodies', 'Endoplasmic reticulum', 'Golgi apparatus', \n           'Intermediate filaments', 'Actin filaments', 'Microtubules', 'Mitotic spindle', \n           'Centrosome', 'Plasma membrane', 'Mitochondria', 'Aggresome', 'Cytosol', \n           'Vesicles and punctate cytosolic patterns', 'Negative']\ntype(classes)","fa840c23":"output_list=[]\nloss_list = []\nfor p in enumerate(classes):\n    #print(p[0])\n    print('output'+str(p[0])+',')\n    output_list.append('output'+str(p[0]))\n    loss_list.append(\"binary_crossentropy\")\noutput_list, loss_list","b3da437b":"\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   #validation_split=0.3, ## Not Yet Compiled - \n                                   horizontal_flip = True)\n\n### pour le Test set\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","40b06045":"training_set = train_datagen.flow_from_dataframe(dataframe=df_train_green[:200],\n                                                 x_col='path',\n                                                 y_col= classes,\n                                                 #directory='..\/input\/hpa-single-cell-image-classification\/train',\n                                                 target_size = (128, 128),\n                                                 batch_size = 256,\n                                                 validation_split = .3,\n                                                 seed = 7,\n                                                 class_mode = 'multi_output')  ## if \"raw\" need wrapper_generator function ","668d24d9":"### \n\ntest_set = test_datagen.flow_from_dataframe(dataframe=df_train_green[200:300],\n                                                 x_col='path',\n                                                 y_col= classes,\n                                            #directory='..\/input\/hpa-single-cell-image-classification\/train'\n                                            #imagepath_test,\n                                            target_size = (128, 128),\n                                            batch_size = 256,\n                                            seed = 7,\n                                            shuffle=False,  ## Si nous voulons utiliser X_test dans Matrice Conf.\n                                            #index_array = None,  ## Si nous voulons utiliser X_test dans Matrice Conf.\n                                            class_mode = 'multi_output')  ## if \"raw\" need wrapper_generator function ","ed1bb100":"inp = Input(shape = (128,128,3))\nx = Conv2D(32, (3, 3), padding = 'valid')(inp)\nx = Activation('relu')(x)\nx = Conv2D(32, (3, 3))(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size = (2, 2))(x)\nx = Dropout(0.25)(x)\nx = Conv2D(64, (3, 3), padding = 'valid')(x)\nx = Activation('relu')(x)\nx = Conv2D(64, (3, 3))(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size = (2, 2))(x)\nx = Dropout(0.25)(x)\nx = Flatten()(x)\nx = Dense(32)(x)\nx = Activation('relu')(x)\nx = Dropout(0.5)(x)\noutput0 = Dense(1, activation = 'sigmoid')(x)\noutput1 = Dense(1, activation = 'sigmoid')(x)\noutput2 = Dense(1, activation = 'sigmoid')(x)\noutput3 = Dense(1, activation = 'sigmoid')(x)\noutput4 = Dense(1, activation = 'sigmoid')(x)\noutput5 = Dense(1, activation = 'sigmoid')(x)\noutput6 = Dense(1, activation = 'sigmoid')(x)\noutput7 = Dense(1, activation = 'sigmoid')(x)\noutput8 = Dense(1, activation = 'sigmoid')(x)\noutput9 = Dense(1, activation = 'sigmoid')(x)\noutput10 = Dense(1, activation = 'sigmoid')(x)\noutput11 = Dense(1, activation = 'sigmoid')(x)\noutput12 = Dense(1, activation = 'sigmoid')(x)\noutput13 = Dense(1, activation = 'sigmoid')(x)\noutput14 = Dense(1, activation = 'sigmoid')(x)\noutput15 = Dense(1, activation = 'sigmoid')(x)\noutput16 = Dense(1, activation = 'sigmoid')(x)\noutput17 = Dense(1, activation = 'sigmoid')(x)\noutput18 = Dense(1, activation = 'sigmoid')(x)","a80aab69":"model = Model(inp,[output0,\noutput1,\noutput2,\noutput3,\noutput4,\noutput5,\noutput6,\noutput7,\noutput8,\noutput9,\noutput10,\noutput11,\noutput12,\noutput13,\noutput14,\noutput15,\noutput16,\noutput17,\noutput18])\n","2a02379d":"import tensorflow as tf","2b37c293":"rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 2, verbose = 0, \n                            min_delta = 1e-4, mode = 'max')\nes = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 2, mode = 'max', \n                       baseline = None, restore_best_weights = True, verbose = 0)\nckp = ModelCheckpoint('.\/model_1.hdf5', monitor = 'val_AUC', verbose = 0, \n                        save_best_only = True, save_weights_only = False, mode = 'max')","9623dbc9":"model.compile(optimizer = Adam(lr = 0.001, decay = 1e-6),\n              loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 1e-3), \n              #metrics = [BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5), Precision(name='precision'), Recall(name='recall')] \n              metrics = [tf.keras.metrics.CategoricalCrossentropy(name='categorical_crossentropy'), tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'), \\\n                         Precision(name='precision'), Recall(name='recall') ] \n              #metrics = ['categorical_accuracy', 'accuracy'],\n             )","b0e4171e":"# Show a summary of the model. Check the number of trainable parameters\nmodel.summary()","10567be3":"from tensorflow.keras.utils import plot_model\n# plot the autoencoder\nplot_model(model, 'HPA-model1.png', show_shapes=True)","a3e3446b":"## IF \"raw\" in \ndef generator_wrapper(generator):\n    for batch_x,batch_y in generator:\n        yield (batch_x,[batch_y[:,i] for i in range(19)])","cf058e7e":"\nSTEP_SIZE_TRAIN=training_set.n\/\/training_set.batch_size\n#STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n#STEP_SIZE_TEST=test_set.n\/\/test_set.batch_size\nmodel.fit(generator_wrapper(training_set),\n                  #(np.asarray(training_set).astype(\"float32\")),\n                    #steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=generator_wrapper(test_set),\n                    #batch_size=4096, \n                    #validation_steps=STEP_SIZE_VALID,\n                    epochs=3,\n                    callbacks = [rlr,ckp,es],\n                    #verbose=2\n         )","c42787c3":"STEP_SIZE_TRAIN=training_set.n\/\/training_set.batch_size\n#STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n#STEP_SIZE_TEST=test_set.n\/\/test_set.batch_size\nmodel.fit(training_set,\n                  #(np.asarray(training_set).astype(\"float32\")),\n                    #steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=test_set,\n                    #batch_size=4096, \n                    #validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    callbacks = [rlr,ckp,es],\n                    #verbose=2\n         )","b3065028":"model_name = 'HPA-model1-green-data'\nprint(model_name)\nmodel.save('.\/'+model_name+'.hdf5')","35135cd4":"%%time\ntest_set.reset() ## To get the output in same oder as y_test\npred=model.predict(test_set,\nverbose=1)","5cdad740":"pred[:1]","7a829ff2":"pd.DataFrame(np.asarray(pred).reshape(100,-1))","daf4014c":"df_train_green.iloc[200:206,1:]","9dca8060":"(np.asarray(pred).reshape(100,-1)==).all()","13ef8b14":"len([[0.24326178],\n[0.24545057],\n[0.18905358],\n[0.22454323],\n[0.17228684],\n[0.23446988],\n[0.23484272],\n[0.19753459],\n[0.26074097],\n[0.2010675 ],\n[0.10761576],\n[0.22031462],\n[0.23193006],\n[0.22713315],\n[0.11388983],\n[0.23554248],\n[0.1785873 ],\n[0.25215697],\n[0.18093413],\n[0.1990953 ],\n[0.20176446],\n[0.19727392],\n[0.2491296 ],\n[0.11087943],\n[0.22272176],\n[0.21852216],\n[0.207871  ],\n[0.1856019 ],\n[0.2678131 ],\n[0.20906556],\n[0.27924448],\n[0.27829096],\n[0.13388641],\n[0.2648097 ],\n[0.24399373],\n[0.24952464],\n[0.157573  ],\n[0.23329581],\n[0.23566657],\n[0.27109227],\n[0.22023298],\n[0.21330912],\n[0.28557703],\n[0.17392349],\n[0.17297237],\n[0.24998474],\n[0.24437207],\n[0.06390683],\n[0.20857255],\n[0.23521458]])","db68bfc9":"def clean_prediction(prediction):\n    prediction = prediction.copy()\n    for batch_index in range(len(prediction)):\n        for class_index in range(len(prediction[batch_index])):\n            prediction[batch_index][class_index] = 1 if prediction[batch_index][class_index] >= 0.4 else 0\n    return np.array(prediction).astype(np.int) ","d963f874":"clean_pred = clean_prediction(pred)","633a7df4":"pd.set_option('display.max_colwidth', None)\npd.DataFrame(clean_pred.reshape(100,19))","effb8548":"(clean_pred.reshape(100,19) == df_train_green.iloc[200:300,1:].values).all()","440dd35e":"## testing 1 output for change in classe mode from raw to multi_output\ninp = Input(shape = (128,128,3))\nx = Conv2D(32, (3, 3), padding = 'valid')(inp)\nx = Activation('relu')(x)\nx = Conv2D(32, (3, 3))(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size = (2, 2))(x)\nx = Dropout(0.25)(x)\nx = Conv2D(64, (3, 3), padding = 'valid')(x)\nx = Activation('relu')(x)\nx = Conv2D(64, (3, 3))(x)\nx = Activation('relu')(x)\nx = MaxPooling2D(pool_size = (2, 2))(x)\nx = Dropout(0.25)(x)\nx = Flatten()(x)\nx = Dense(32)(x)\nx = Activation('relu')(x)\nx = Dropout(0.5)(x)\noutput0 = Dense(1, activation = 'sigmoid')(x)","1dba83d9":"## testing for change in classe mode from raw to multi_output\nmodel = Model(inp,output0)","26f05bb7":"STEP_SIZE_TRAIN=training_set.n\/\/training_set.batch_size\n#STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n#STEP_SIZE_TEST=test_set.n\/\/test_set.batch_size\nmodel.fit(training_set,\n                  #(np.asarray(training_set).astype(\"float32\")),\n                    #steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=test_set,\n                    #batch_size=4096, \n                    #validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    callbacks = [rlr,ckp,es],\n                    #verbose=2\n         )","f68d4301":"test_set.reset()\npred=model.predict(test_set,\nverbose=1)","136fcc72":"pred","fb318e47":"## Prepare Dataset","62cfa0ea":"## #Only 1 Output"}}