{"cell_type":{"b21b4cb6":"code","84e6f0e7":"code","6c62d77d":"code","6ddf64cb":"code","b6e39f35":"code","0c70829e":"code","13580c0e":"code","8b1a41f4":"code","3bf0186f":"code","d30e8f7f":"code","d65fe0d8":"code","e54a6249":"code","df61ca23":"code","d1bbf10b":"code","e7a64bcd":"code","7ec4ac86":"code","4c252822":"code","f0b2153d":"code","e8c9ddba":"code","2692f959":"code","d36ca9f9":"code","19a7933c":"code","5183a75a":"code","99ac0c1e":"code","3cd3e5a3":"code","28d53549":"code","f5e15f75":"markdown","535f1316":"markdown","ca3f2f3a":"markdown","bf8d27bc":"markdown","2e75f427":"markdown","efc97f6e":"markdown","3e9bd51b":"markdown","fe90efaf":"markdown","204445cf":"markdown","818e1453":"markdown","f2e3c027":"markdown","a6b5293c":"markdown","5e556ea1":"markdown","e3b63b08":"markdown","c55e2030":"markdown","898461d4":"markdown","a4d93688":"markdown","76aac115":"markdown","2cab111b":"markdown","c631b539":"markdown","620620a7":"markdown","0b760ae2":"markdown","2e1e637c":"markdown","72a0f86e":"markdown","d0adccda":"markdown","f705c1eb":"markdown","00249c0e":"markdown","a11339bc":"markdown","a552bd9d":"markdown","9c8fcb7b":"markdown","7cc87c68":"markdown","04cc1feb":"markdown","63daf64f":"markdown","7d3ce091":"markdown","4627041a":"markdown","b9648422":"markdown","f52e0e0c":"markdown","bbe71a0e":"markdown","4d1bb349":"markdown"},"source":{"b21b4cb6":"import tensorflow as tf                       # deep learning library\nimport numpy as np                            # for matrix operations\nimport matplotlib.pyplot as plt               # for visualization\n%matplotlib inline","84e6f0e7":"from tensorflow.keras.datasets.mnist import load_data    # To load the MNIST digit dataset\n\n(X_train, y_train) , (X_test, y_test) = load_data()      # Loading data","6c62d77d":"print(\"There are \", len(X_train), \"images in the training dataset\")     # checking total number of records \/ data points available in the X_train dataset\nprint(\"There are \", len(X_test), \"images in the test dataset\")     # checking total number of records \/ data points available in the X_test dataset","6ddf64cb":"# Checking the shape of one image\nX_train[0].shape","b6e39f35":"# Take a look how one image looks like\nX_train[0]","0c70829e":"plt.matshow(X_train[0])","13580c0e":"# we can use y_train to cross check\ny_train[0]","8b1a41f4":"# code to view the images\nnum_rows, num_cols = 2, 5\nf, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n                     squeeze=True)\n\nfor r in range(num_rows):\n    for c in range(num_cols):\n      \n        image_index = r * 5 + c\n        ax[r,c].axis(\"off\")\n        ax[r,c].imshow( X_train[image_index], cmap='gray')\n        ax[r,c].set_title('No. %d' % y_train[image_index])\nplt.show()\nplt.close()","3bf0186f":"\nX_train = X_train \/ 255\nX_test = X_test \/ 255\n\n\"\"\"\nWhy divided by 255?\nThe pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value. \"\"\"","d30e8f7f":"X_train[0]","d65fe0d8":"X_train.shape","e54a6249":"X_train_flattened = X_train.reshape(len(X_train), 28*28)    # converting our 2D array representin an image to one dimensional\nX_test_flattened = X_test.reshape(len(X_test), 28*28)","df61ca23":"X_train_flattened.shape","d1bbf10b":"# Defining the Model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')     # The input shape is 784. \n])","e7a64bcd":"model.summary()","7ec4ac86":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","4c252822":"model.fit(X_train_flattened, y_train, epochs=5)","f0b2153d":"model.evaluate(X_test_flattened, y_test)","e8c9ddba":"y_train[0]","2692f959":"y_predicted = model.predict(X_test_flattened)\ny_predicted[0]","d36ca9f9":"np.argmax(y_predicted[0])","19a7933c":"plt.matshow(X_test[0])","5183a75a":"# Defining the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n    tf.keras.layers.Dense(100, input_shape=(100,),activation='relu'),\n    tf.keras.layers.Dense(10, activation='sigmoid')\n])\nmodel.summary()\n","99ac0c1e":"# Compiling the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)","3cd3e5a3":"# Evaluate the model\nmodel.evaluate(X_test_flattened,y_test)","28d53549":"# saving the model\nsave_dir = \"\/results\/\"\nmodel_name = 'keras_mnist.h5'\nmodel.save(model_name)\nmodel_path = save_dir + model_name\nprint('Saved trained model at %s ' % model_path)","f5e15f75":"## Data Preprocessing","535f1316":"# Agenda\n*  About the Data\n*  Loading Libraries\n*  Loading Data\n*  Basic EDA\n*  Data Preprocessing\n*  Model Building\n  *  Simple Neural Network With No Hidden Layer\n  *  Building Model Using Hidden Layer\n*  Summary","ca3f2f3a":"**Define the model**","bf8d27bc":"![simple neural network](https:\/\/dphi-courses.s3.ap-south-1.amazonaws.com\/Deep+Learning+Bootcamp\/mnist1.png)","2e75f427":"# Introduction\nIn this notebook we will build a Neural Network multi-class classification model using a dataset popularly known as **'MNIST'**\n\n","efc97f6e":"The predicted digit is 7.","3e9bd51b":"Let's normalize our data (i.e. both X_train and X_test). Normalization is a process that changes the range of pixel intensity values to the range 0 to 1.\n\nBut why to normalize?\n\nThe motivation to normalize is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction and reduce the data redundancy. Also, normalizing the data can help you improve the model performance.","fe90efaf":"Each image in the dataset is of shape 28X28 numbers (i.e. pixels)","204445cf":"**predict for the X_test**","818e1453":"### Building Neural Network Model Using hidden layer","f2e3c027":"## About the Data\n**MNIST (Modified National Institute of Standards and Technology database)** is a large database of 70,000 handwritten digits. \n\nIt has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST (National Institute of Standards and Technology).\n\nThe objective here is to build a model that would recognize the correct digit that the given image is representing.\n\n","a6b5293c":"**Fit the model**","5e556ea1":"**Try yourself**: \nChange the values of epochs and try adding more hidden layers. Are you able to increase the accuracy above 97.5%?","e3b63b08":"You can play with different number of epochs.","c55e2030":"Now one can easily say the above number is 5. Well we want to build a model that will tell you what digit does that 28X28 array represent.","898461d4":"The performance of the model on very simple model with no hidden layer is around 92 %. Not Bad!","a4d93688":"## Building Models\n### Very simple neural network with no hidden layers","76aac115":"# Saving and loading the model","2cab111b":"### **Reference**\n[Neural Network For Handwritten Digits Classification](https:\/\/www.youtube.com\/watch?v=iqQgED9vV7k&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=7)","c631b539":"**np.argmax finds a maximum element from an array and returns the index of it**","620620a7":"Now if you look at the data, each pixel value should be in range 0 to 1.","0b760ae2":"Only numbers! Can't understand what digit does it represent. \n\nThere is a function in matplotlib called as 'matshow()', it helps to display the image of the array of numbers","2e1e637c":"Hence the prediction is correct","72a0f86e":"The activation function used here is 'sigmoid'. ","d0adccda":"# Summary\n*  We learned why we need to normalize and flatten the data.\n*  We observed the performance of very simple neural network with no hidden layer and that of with one hidden layer with 100 hidden neurons. The performance of later model was better than earlier","f705c1eb":"*  **adam** is an optimization algorithm which is faster than Stochastic Gradient Descent.\n\n*  **sparse_categorical_crossentropy** is a loss function similar to **binary_crossentropy**, the only difference is that if the target variable is binary we use binary_crossentropy but if your target values are normal integers more then two, use sparse categorical crossentropy. Why not use **categorical_crossentropy**? [this article](https:\/\/jovianlin.io\/cat-crossentropy-vs-sparse-cat-crossentropy\/) will help you understand it.\n\n*  The metrics used to evaluate the model is **accuracy**. Accuracy calculates how often the predictions calculated by the model are correct.","00249c0e":"The above numbers are the probabilities values for different digits. The maximum probability will confirm what is the predicted digit for first image in X_test.\n\nThe value at the 0th index in above array of numbers is saying the probability of the digit being 0. \n\n**Generalize:** The value at the nth index in above array of numbers is saying the probability of the digit being n","a11339bc":"## Loading Data\nThe MNIST dataset is available in the TensorFlow only. Let's load the data:","a552bd9d":"**Compile the model**","9c8fcb7b":"Now if you check the shape of our data, it should be 2 dimensional","7cc87c68":"**Flatten the Data**\n\nWe simply convert a 2 dimensional data (i.e. one image data) to 1 dimensional.\n\nWhy to flatten data?\n\nBefore understanding why let's check the shape of the data","04cc1feb":"## Objective\nIn this notebook we will classify handwritten digits using a simple neural network which has only input and output layers. We will then add a hidden layer and see how the performance of the model improves","63daf64f":"## Loading Libraries\n","7d3ce091":"The data is 3 dimensional. The first value i.e. 60000 is nothing but the number of records or images in this case. The second and third dimension represent each individual image i.e. each image is of shape 28X28. \n\nMost of the the supervised learning algorithms that execute classification and regression tasks, as well as some deep learning models built for this purposes, are fed with two-dimensional data. Since we have our data as three-dimensional, we will need to flatten our data to make it two-dimensional.","4627041a":"## Basic EDA","b9648422":"**Evaluate the model on unseen data (i.e. X_test_flattened)**","f52e0e0c":"Let's see the original digit at first index in X_test. Can see this using matshow() function.","bbe71a0e":"**A sample example showing the conversion of 3D data to 2D**\n![3Dto2D](https:\/\/dphi-courses.s3.ap-south-1.amazonaws.com\/Deep+Learning+Bootcamp\/3D+to++2D.png)","4d1bb349":"Generally for multi-class classification problem, it is suggested to use softmax. We tried both softmax activation and sigmoid activation, but sigmoid found to give better performance. You can also try using both and keep the one which gives better performance."}}