{"cell_type":{"74f65d36":"code","0994d108":"code","407c6689":"code","9a9ee593":"code","70f380aa":"code","6db700b5":"code","3fdb7960":"code","038a64ec":"code","ae747748":"code","5b2840d4":"markdown","cc333f38":"markdown","bf53a643":"markdown","c92962ea":"markdown","c62e4cf8":"markdown"},"source":{"74f65d36":"!pip install -qq skorch\n\nimport os\nfrom urllib import request\nfrom zipfile import ZipFile\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, models, transforms\n\nfrom skorch import NeuralNetClassifier\nfrom skorch.helper import predefined_split\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import GridSearchCV\nfrom skorch.callbacks import LRScheduler\nfrom skorch.callbacks import Checkpoint\nfrom skorch.callbacks import Freezer\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntorch.manual_seed(360);","0994d108":"data_dir = '..\/input\/famous-iconic-women\/output\/'\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\ntrain_ds = datasets.ImageFolder(\n    os.path.join(data_dir, 'train'), train_transforms)\n\nval_ds = datasets.ImageFolder(\n    os.path.join(data_dir, 'valid'), val_transforms)","407c6689":"y_train = torch.LongTensor([train_ds[i][1] for i in range(len(train_ds))])\ny_test = torch.LongTensor([val_ds[i][1] for i in range(len(val_ds))])","9a9ee593":"class ResNet(nn.Module):\n    '''\n        Pretrained ResNet18\n    '''\n    def __init__(self, output_features):\n        super().__init__()\n        path = '..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth'\n        model = models.resnet18(pretrained=False)\n        model.load_state_dict(torch.load(path, map_location='cuda'))\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, output_features)\n        self.model = model\n        \n    def forward(self, x):\n        return self.model(x)","70f380aa":"lrscheduler = LRScheduler(\n    policy='StepLR', step_size=7, gamma=0.1)\n\ncheckpoint = Checkpoint(\n    f_params='best_model.pt', monitor='valid_acc_best')\n\nfreezer = Freezer(lambda x: not x.startswith('model.fc'))","6db700b5":"nr_features = len(os.listdir(data_dir + 'train\/'))\n\nnet = NeuralNetClassifier(\n    ResNet, \n    criterion=nn.CrossEntropyLoss,\n    lr=0.001,\n    batch_size=16,\n    max_epochs=15,\n    module__output_features=nr_features,\n    optimizer=optim.SGD,\n    optimizer__momentum=0.9,\n    iterator_train__shuffle=True,\n    iterator_train__num_workers=4,\n    iterator_valid__shuffle=True,\n    iterator_valid__num_workers=4,\n    train_split=predefined_split(val_ds),\n    callbacks=[lrscheduler, checkpoint, freezer],\n    device='cuda'\n)","3fdb7960":"_ = net.fit(train_ds, y=None)","038a64ec":"params = {\n    'lr': [0.001, 0.002],\n    'max_epochs': [25, 25],\n    'device': ['cuda']\n}\n\nclf = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')\n_ = clf.fit(train_ds, y=None)","ae747748":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\naxes[0].set_title('Mean Fit Time')\naxes[0].plot(clf.cv_results_['mean_fit_time'])\n\naxes[1].set_title('Std Fit Time')\naxes[1].plot(clf.cv_results_['std_fit_time'])\nfig.tight_layout()","5b2840d4":"<h1 id=\"dataset\" style=\"color:white; background:#dcbac2; border:0.5px dotted;\"> \n    <center>Datasets\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","cc333f38":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1182746\/1978927\/a4269f6476e87ddd1f70217024c055c0\/dataset-cover.jpg\"\/>\n<\/div>","bf53a643":"<h1 id=\"model\" style=\"color:white; background:#dcbac2; border:0.5px dotted;\"> \n    <center>Model\n        <a class=\"anchor-link\" href=\"#model\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","c92962ea":"<h1 id=\"training\" style=\"color:white; background:#dcbac2; border:0.5px dotted;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","c62e4cf8":"<h1 id=\"analysis\" style=\"color:white; background:#dcbac2; border:0.5px dotted;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}