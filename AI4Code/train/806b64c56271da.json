{"cell_type":{"24d5ebee":"code","6ca1a4f4":"code","64f596fc":"code","752a91d6":"code","3d0fbd2d":"code","aa73870d":"code","d88c755b":"code","a5546e01":"code","cd66b646":"code","98e26177":"markdown","9f384374":"markdown","3a43a19c":"markdown","3117c348":"markdown","8b188986":"markdown","008cd12d":"markdown","09b3838c":"markdown","acc13117":"markdown","b84c1e7d":"markdown"},"source":{"24d5ebee":"!git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","6ca1a4f4":"!pip install GPUtil\n!pip install pylg","64f596fc":"import os\nimport sys\nsys.path.append('monk_v1\/monk\/')\n\nfrom pytorch_prototype import prototype\nptf = prototype(verbose=1)\nptf.Prototype('oregon-wildlife', 'oregon-pytorch-freezed')","752a91d6":"data_dir = '..\/input\/oregon-wildlife\/oregon_wildlife\/oregon_wildlife'\n\nptf.Default(dataset_path = data_dir,\n           model_name = 'vgg16',\n           freeze_base_network = True,\n          num_epochs=7)","3d0fbd2d":"lrs = [0.01, 0.03, 0.06]\npercent_data = 5 \nepochs = 5\n\nanalysis1 = ptf.Analyse_Learning_Rates('lr-cycle', lrs, percent_data, num_epochs=epochs, state='keep_none')","aa73870d":"optimizers = ['sgd', 'adam', 'momentum-rmsprop']\n\nanalysis2 = ptf.Analyse_Optimizers('optim-cycle', optimizers, percent_data, num_epochs=epochs, state='keep_none')","d88c755b":"ptf.Training_Params(save_intermediate_models = False,\n                   num_epochs = 7)\n\n# after reloading num_epochs changes to 10, after reloading some hyperparams change idk why\n\nptf.optimizer_momentum_rmsprop(0.01, weight_decay = 0.01)\nptf.Reload()","a5546e01":"ptf.Train()","cd66b646":"ptf = prototype(verbose=1);\nptf.Prototype(\"oregon-wildlife\", \"oregon-pytorch-freezed\", eval_infer=True);\n\nptf.Dataset_Params(dataset_path=data_dir);\nptf.Dataset();\n\naccuracy, class_based_accuracy = ptf.Evaluate()","98e26177":"# Using Monk Library for Image Classification\n\n[Monk](https:\/\/github.com\/Tessellate-Imaging\/monk_v1) is one of the easiest to learn computer vision library! It is a unified wrapper built on top of popular frameworks like Tensorflow, PyTorch and MxNet. It is a great library for people who have to switch between different frameworks, and also for people who just want to get a model working without writing too much code. It has great features for visualisation and also for tracking the model's training and performance.\n\nIn this notebook, we will go through some of the elemental features of monk which makes it so easy to use!","9f384374":"### Time to train!\n","3a43a19c":"### Default mode :\n\n* We will be using Default mode to train our model. It is the easiest way to train a classification network!\n* All we have to do is send in the required parameters to the Default method and it takes care of everything else.\n* Arguments :\n     - dataset_path = the path of the training data\n     - model_name = specify which model you want to use for the training. You can check the available models using List_Models() method.\n     - freeze_base_network (*type : bool*) = You have the option to either use the pretrained weights or not. True would mean you want\n       to use pretrained weights and only train the final layer of the model. False would mean\n       you want to train the entire network from scratch. Now you know why the experiment name is 'oregon-pytorch-***freezed***'\n     - num_epochs = specify the number of epochs for which you want to train.","3117c348":"### Initialisation :\n\nprototype.Prototype( *project name*, *experiment name*)\n    \n   This creates files and directories in the following manner :\n   \n       - WORKSPACE -\n                 PROJECT NAME - \n                              EXPERIMENT NAME -\n                                              1) experiment.json\n                                              2) output - \n                                                        1) logs (all training graphs are stored here)\n                                                        2) models (all trained models are stored here)\n                                                         \n   We can have different names for the project and experiments. We can store multiple different experiments under the same project. This\n    is really helpful when we want to compare different models for the same data. Monk library has a great feature for comparing different\n    experiments too!\n    \n   We will using the [Oregon wildlife dataset](http:\/\/https:\/\/www.kaggle.com\/virtualdvid\/oregon-wildlife) to train a classifier.\n   Our project name will be 'oregon-wildlife' and experiment name 'oregon-pytorch-freezed' since we'll be using PyTorch backend.\n   \n   Monk often outputs the summary of the model after everytime we make a change. Going through it will help you understand what operations\/preprocessing it is carrying out. We can also change it if we have some specific operations in mind, different from the default choices. To get started, the default operations usually work pretty well and we won't have to change it most of the times.  ","8b188986":"Great! We have a classification model ready with just a few lines of code. We can also see how the model performs over different\ncategories of data which gives nice insights on which categories our model finds difficult. We can use this information to improve upon our\nexisting model.\n\nYou can check out the Monk library by visiting their [GitHub](https:\/\/github.com\/Tessellate-Imaging\/monk_v1) page. They have a detailed\nroadmap covering everything from how to train your first model using monk to how you can use all the powerful features to your advantage.","008cd12d":"### Evaluating the model\n\nSince we do not have an expilicit test set for this dataset, we treat our training set as the test set and evaluate our model on it.","09b3838c":"### Hyperparamater Tuning!\n\n* One of the most useful features of monk is hyperparameter analysis. Using this we can analyse which hyperparameters would work best for our\nmodel. Here we define a list of learning rates (lrs) and optimizers we want to test along with the percentage of training data and the number of epochs. The analyser works in the following way -\n\n   Given a model, it keeps all the other hyperparameters\/model constant and runs through the percentage of the training data we want for a given number of epochs. It iterates throught the list of the hyperparameter we wish to analyse, and changes it after it completes going through the train set for the specified number of epochs. \n\nThis cell demonstrates how we can analyse the learning rate and optimizer using the monk analyser & then update our model according to the results of the analysis.","acc13117":"### Now we update the training parameters and optimizer according to the analyser results\n\nBy default monk saves the model weights after every epoch. We can change this by using the Training_Params method. This saves precious disk space.","b84c1e7d":"### Cloning the Monk_v1 repository and installing required packges and dependencies"}}