{"cell_type":{"23cb8d8c":"code","07217b64":"code","889c7943":"code","b9168c8e":"code","0f96cd91":"code","288b0a34":"code","a945236a":"code","37d65ca2":"code","eeda04f3":"code","ac563466":"code","b4f67d97":"code","6dca9034":"code","55ab4df2":"code","40828925":"code","f8bec707":"code","e061add1":"code","74633819":"code","3b43109d":"code","87e822cf":"code","0f815c93":"code","8f1dd63d":"code","8eb45600":"code","8bbd8bf7":"code","60df7e3c":"code","efcfcd17":"code","f6414c3e":"code","9af750f9":"code","85f95498":"code","b54476c4":"code","c9ecf769":"code","6d7f68e4":"code","8a0abb6a":"code","f1c1c5f1":"code","ad05a9d8":"code","3ab740c8":"code","1e9c78f4":"code","0b01f2a5":"code","b9eed684":"markdown","e676fbb4":"markdown","d58dc7a2":"markdown","d211bc46":"markdown","05858763":"markdown","e49cf366":"markdown","93417b45":"markdown","0193253b":"markdown","98a1cfed":"markdown","62c54f03":"markdown","88ed35eb":"markdown","7c05344a":"markdown","3b482642":"markdown","eac1023f":"markdown","2b9c73ad":"markdown","1d469e6c":"markdown","b052f058":"markdown","586d5d4a":"markdown","37428a89":"markdown","34e15741":"markdown","5f2f6543":"markdown","2aa61e2a":"markdown","5a854313":"markdown","5c803ce0":"markdown","bc1ed5dd":"markdown","c2d5e306":"markdown","1a3af2ca":"markdown","8703d6d3":"markdown","5c8b7c72":"markdown","9bba86dc":"markdown","d8cca641":"markdown","40862265":"markdown"},"source":{"23cb8d8c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","07217b64":"train = pd.read_csv('..\/input\/titanic\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/titanic\/test.csv', index_col=0)","889c7943":"train.head()","b9168c8e":"train.info()","0f96cd91":"train['Sex'].value_counts()","288b0a34":"train[\"Survived\"].value_counts(normalize=True)","a945236a":"train[train['Sex'] == 'male'][\"Survived\"].value_counts(normalize=True)","37d65ca2":"train[train['Sex'] == 'female'][\"Survived\"].value_counts(normalize=True, ascending=True)","eeda04f3":"fig, axes = plt.subplots(1, 2, figsize=(12,5))\n\nsns.barplot(data=train, x=\"Pclass\", y=\"Survived\", ax=axes[0])\nsns.countplot(data=train, x=\"Pclass\", ax=axes[1])","ac563466":"fig, axes = plt.subplots(1, 2, figsize=(12,5))\n\nsns.barplot(data=train, x=\"Sex\", y=\"Survived\", hue=\"Pclass\", ax=axes[0])\nsns.countplot(data=train, x=\"Sex\", hue=\"Pclass\", ax=axes[1])\naxes[0].set_title('Survival rate')\naxes[1].set_title('Number of observations per group')","b4f67d97":"train.isna().sum()","6dca9034":"train[train['Age'].isna()]['Sex'].value_counts()","55ab4df2":"train[train['Age'].isna()]['Survived'].mean()","40828925":"g = sns.FacetGrid(data=train, col=\"Sex\", height=3.5, aspect=1.75)\ng.map_dataframe(sns.histplot, binwidth=5, x='Age', hue='Survived', multiple='dodge', shrink=.8)\ng.set_axis_labels(\"Age\", \"Count\")","f8bec707":"fig, axes = plt.subplots(1, 2, figsize=(12,5))\n\nsns.countplot(data=train, x=\"SibSp\", hue='Survived', ax=axes[0])\nsns.countplot(data=train, x=\"Parch\", hue='Survived', ax=axes[1])\naxes[1].legend(loc='right')\n","e061add1":"surv_rates_cabin = train[train['Cabin'].notnull()]['Survived'].groupby(train['Cabin'].str[:1]).agg(['mean', 'count'])\nsurv_rates_cabin.rename(columns={'mean': 'survival rate'})","74633819":"train['Survived'][train['Cabin'].isna()].mean()","3b43109d":"sns.countplot(data=train, x='Embarked', hue='Survived')","87e822cf":"sns.histplot(data=train, binwidth=50, x=\"Fare\", hue='Survived', multiple=\"dodge\", shrink=.8)\nplt.xlim(0, 300)","0f815c93":"train.select_dtypes(include='number').corr()","8f1dd63d":"train_copy = train.copy()  # make copy to not overwrite original data\ntarget_train = train_copy[['Survived']]\ntrain_copy.drop(columns=['Survived'], inplace=True)\n\n","8eb45600":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler","8bbd8bf7":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# a bit of help here from \n# https:\/\/medium.com\/analytics-vidhya\/scikit-learn-pipelines-with-custom-transformer-a-step-by-step-guide-9b9b886fd2cc\n# but not 100% copied.\n\nclass CabinTransformer(BaseEstimator, TransformerMixin):       \n    def fit(self, X):\n        # X is a Pd.series\n        X.fillna('U', inplace=True)\n        X = X.str[:1]  # only slice the cabin letter\n        cabin_dummies = pd.get_dummies(X, prefix='Cabin')\n        self.cabin_columns = cabin_dummies.columns\n        return self\n    \n    def transform(self, X):\n        X.fillna('U', inplace=True)\n        X = X.str[:1]\n        cabin_dummies = pd.get_dummies(X, prefix='Cabin')\n        cabin_dummies = cabin_dummies.reindex(columns=self.cabin_columns, fill_value=0)\n        \n        X = pd.concat([X, cabin_dummies], axis=1)\n        X.drop(X.columns[0], axis=1, inplace=True)\n        \n        return X\n        ","60df7e3c":"# make a pipeline for the numerical variables. First impute the missing values for Age and then standardize\n\nnum_attribs = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('std_scaler', StandardScaler())\n])","efcfcd17":"# make a pipeline for the embarked feature as well. First impute the mode (2 missing values), and then use One Hot encoding\nemb_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')), \n    ('ohe', OneHotEncoder())\n])","f6414c3e":"full_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"embarked\", emb_pipeline, ['Embarked']),\n    (\"gender\", OrdinalEncoder(), [\"Sex\"]),\n    (\"c_transformer\", CabinTransformer(), \"Cabin\"),\n])\n","9af750f9":"train_prepared = full_pipeline.fit_transform(train_copy)","85f95498":"test_prepared = full_pipeline.transform(test)","b54476c4":"from sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nsvc_clf = SVC()\ntarget_predictions = cross_val_predict(svc_clf, train_prepared, target_train, cv=10)\nprint(f'Accuracy score with standard SVC: {accuracy_score(target_train, target_predictions)}')\n\n\nrf_clf = RandomForestClassifier(random_state=42)\ntarget_predictions = cross_val_predict(rf_clf, train_prepared, target_train, cv=10)\nprint(f'Accuracy score with standard RF: {accuracy_score(target_train, target_predictions)}')\n\ndt_clf = DecisionTreeClassifier(random_state=42)\ntarget_predictions = cross_val_predict(dt_clf, train_prepared, target_train, cv=10)\nprint(f'Accuracy score with standard Decision Tree: {accuracy_score(target_train, target_predictions)}')\n\n\n","c9ecf769":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n               'C': np.arange(0.1, 4, 0.2)}\n","6d7f68e4":"grid_search = GridSearchCV(svc_clf, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(train_prepared, target_train)","8a0abb6a":"svm_clf = grid_search.best_estimator_\nsvm_clf","f1c1c5f1":"cross_val_score(svm_clf, train_prepared, target_train, scoring='accuracy', cv=10)","ad05a9d8":"svm_clf.fit(train_prepared, target_train)","3ab740c8":"predictions = svm_clf.predict(test_prepared)","1e9c78f4":"pd.DataFrame(predictions, index=test.index, columns=['Survived']).to_csv('submission.csv')","0b01f2a5":"best_estimator.fit(train_prepared, target_train)\npredictions = best_estimator.predict(test_prepared)\n\npd.DataFrame(predictions, index=test.index, columns=['Survived']).to_csv('submission.csv')","b9eed684":"### procedure to save predictions ","e676fbb4":"## Embarked","d58dc7a2":"# Model selection","d211bc46":"### Pclass ","05858763":"## correlations of the numerical data","e49cf366":"Hence it looks like on average, women were much more likely to survive than men. This will be an informative feature.","93417b45":"It appears that females have a much higher survival rate across all social classes (Pclass). 97% of the females in the upper class survived whereas only 37% of men in the upper class survived. Note that men in the middle and lower class are not very likely to survive (only about 15% survived). In the lower class, still 50% of all females managed to survive and females in the middle class were also very likely to survive the disaster. All groups include quite some observations.\n","0193253b":"### Hyperparameter tuning for SVC","98a1cfed":"There is also a significant difference in the survival rate between people from different classes. The upper class has the highest survival rate, whereas the lower class (Pclass=3) has the lowest survival rate.","62c54f03":"I will first deal with the unknown observations. For Age, let's impute the mean age (don't want to delete 177 rows). For Cabin, I will treat NaN values as a category (because observations with NaN cabin values tend to die more often). \n\nEncode Sex by 0: female, 1: male. \n\nOne Hot Encode cabins (A, B, C, D, E, F, G, T, None). \n\nImpute 2 missing values for Embarked and then One Hot Encode ","88ed35eb":"# Data Preperation","7c05344a":"In the training set there are almost twice as many men as there were women.","3b482642":"There are 177 missing values in this column:","eac1023f":"Here we can see that a lot of people in the groups with cheap tickets did not survive, and that in the groups with higher ticket prices the survival rate was higher. This is quite logical as they might have had better Cabins etc. ","2b9c73ad":"There are 687 observations with unknown Cabin. Let's look at the observations with known cabin. We group the observations by their cabin type. (A, B, C, D, E, F, G, T) and we look at the rates. ","1d469e6c":"# Exploratory Data Analysis","b052f058":"## Gender & Pclass ","586d5d4a":"### Survival rate men","37428a89":"Pclass and Fare have a strong negative correlation, because upper class (lower value for Pclass) could buy more expensive tickets. Also, as people get older, they tend to belong to a higher social class (lower value for Pclass). ","34e15741":"### Survival rate women","5f2f6543":"The persons of which no age is known are mostly male (exceeding the overall male\/female ratio of less than 2 in the training set). Hence we would expect that the survival rate is less than the overall rate (0.38) as well:","2aa61e2a":"No really weird pattern here. The small differences could be related to the social classes, gender, age etc. Don't think this feature is very informative but we still include it in our models. ","5a854313":"The NaN values in the Age column do not give us a lot of extra information at the first sight. We will now analyze the observations with known Age. ","5c803ce0":"## Fare","bc1ed5dd":"## Age","c2d5e306":"And the survival rate of people with unknown cabin is about 0.30. Hence the survival rate of people with known cabin number is higher than the survival rate of people with unknown cabin number. This could be due to some other factors but for now let's leave it like this. ","1a3af2ca":"### Load train and test data","8703d6d3":"## Cabin","5c8b7c72":"## SibSp","9bba86dc":"In the age group < 5 years old for males, the survival rate was higher than 50%. In the other groups it was much smaller. This could mean that these boys still had a decent probability of surviving. In contrast, the 5 - 10 years group of girls was least likely to survive based on the training data. However, there was very little observations for this group so it could be just a coincidence. ","d8cca641":"We don't see much of a pattern here. However, it seems that people with more than 2 SibSp are more likely to not have survived.","40862265":"SVC looks like a promising model, hence I will try to improve the performance of this algorithm. I use Grid Search."}}