{"cell_type":{"267d454a":"code","c329bf57":"code","3c61b99a":"code","9c67cc60":"code","ec872e3d":"code","d84b6b75":"code","08d2d044":"code","43b233f7":"code","43fd8275":"code","1669173e":"code","3cf8ecba":"code","1b5127bb":"code","addd3ba6":"code","e69b555f":"code","6190bed2":"code","c2b3511b":"code","3ee25e87":"code","b39b9fe6":"code","c6d697a9":"code","41f0c3f1":"code","4148aeb3":"code","c97ed5b6":"code","27ab48ff":"code","90272182":"code","e9e5cd01":"code","d2cf3c81":"code","e506147e":"code","c6243d0f":"code","1bcef375":"code","4057323f":"code","262aef10":"code","02b9b8b8":"code","fca62f5d":"code","8e9539e4":"code","3ac19ebd":"code","dabfe032":"code","3cc1cf34":"code","17e30dcf":"code","b1e3c4b3":"code","93514056":"code","fcf11dbd":"code","6f6bc0c0":"code","691d8baa":"code","4ebb8a3a":"code","3a159a92":"code","c94715a7":"code","6fd98f24":"code","c04b1886":"code","24f1bdd7":"code","a3777872":"code","4f473bee":"code","635653bb":"code","fa6a3f50":"code","c06ba465":"code","29cfb19e":"code","7ecc5018":"code","75f57bc2":"code","8d3d9479":"code","66cf3b2a":"code","04f81cbf":"code","43d9bdd0":"code","050bf211":"code","9b54a6e0":"code","c390b3e1":"code","601eda09":"code","ceb1c37a":"code","aa2b9324":"code","f8d9a215":"markdown","589626c8":"markdown","6a329bd3":"markdown","4c25a2d4":"markdown","25236c7c":"markdown","779572b9":"markdown","c2bc9500":"markdown","c5d59fb0":"markdown","278c00d1":"markdown","14844fc3":"markdown","6f79c831":"markdown","e451dace":"markdown","84d27d51":"markdown","2bf25847":"markdown","5162f338":"markdown","255c2b90":"markdown","b307a05e":"markdown","112492d3":"markdown","088d57c4":"markdown","c955d748":"markdown","7d4030c9":"markdown","4c231380":"markdown","23be40f6":"markdown","144485ee":"markdown","50df87bf":"markdown","0397aeec":"markdown","8d862800":"markdown","066c237f":"markdown"},"source":{"267d454a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sklearn\nimport matplotlib.pyplot as plt","c329bf57":"# defines dataframe\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\n# displays the top 5 rows of dataframe\ndf.head()","3c61b99a":"# defines the numeric features in the dataset\ndf_num=df[['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']]","9c67cc60":"# displays the top 5 rows of the numeric features\ndf_num.head()","ec872e3d":"# check the data type of each features in dataframe\ndf.info()","d84b6b75":"# displays statistical summary of numeric features\ndf_num.describe().transpose()","08d2d044":"# displays the dimensions of the data\nprint('number of rows:', df.shape[0])\nprint('number of columns:', df.shape[1])","43b233f7":"# check missing value in each features\nprint('Checking missing data:')\ndf.isnull().any()","43fd8275":"# defines mean of the numerical features in each categorical features\nround(df.groupby(['DEATH_EVENT','sex','anaemia','diabetes','high_blood_pressure','smoking'],as_index=False).mean(),2)","1669173e":"# defines death event as label and the numeric features in data\ndf_DE_and_num=df[['DEATH_EVENT','age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']]","3cf8ecba":"# defines mean of the numerical features in each death event labels\ndf_group_DE = round(df_DE_and_num.groupby(['DEATH_EVENT'],as_index=False).mean(),2)\ndf_group_DE","1b5127bb":"# Bar chart visualization of the mean numerical feature in each death event labels\n\nf, axes = plt.subplots(ncols=3, figsize=(26, 8))\n\ndf_group_DE['age'].plot(kind=\"bar\",color=['darkcyan', 'grey'], ax=axes[0])\naxes[0].set_title('Mean of Age in each category Death Event', fontsize = 16)\naxes[0].set_xlabel('Category Death Event', fontsize = 14)\naxes[0].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[0].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[0].text(i.get_x()+.16, i.get_height()+.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\ndf_group_DE['creatinine_phosphokinase'].plot(kind=\"bar\", color=['darkcyan', 'grey'], ax=axes[1])\naxes[1].set_title('Mean of Creatinine Phosphokinase in each category Death Event', fontsize = 16)\naxes[1].set_xlabel('Category Death Event', fontsize = 14)\naxes[1].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[1].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[1].text(i.get_x()+.16, i.get_height()+2.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\ndf_group_DE['ejection_fraction'].plot(kind=\"bar\",color=['darkcyan', 'grey'], ax=axes[2])\naxes[2].set_title('Mean of Ejection Fraction in each category Death Event', fontsize = 16)\naxes[2].set_xlabel('Category Death Event', fontsize = 14)\naxes[2].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[2].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[2].text(i.get_x()+.16, i.get_height()+.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\nplt.show()","addd3ba6":"# Bar chart visualization of the mean numerical feature in each death event labels\n\nf, axes = plt.subplots(ncols=2, figsize=(26, 8))\n\ndf_group_DE['platelets'].plot(kind=\"bar\", color=['darkcyan', 'grey'], ax=axes[0])\naxes[0].set_title('Mean of Platelets in each category Death Event', fontsize = 18)\naxes[0].set_xlabel('Category Death Event', fontsize = 14)\naxes[0].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[0].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[0].text(i.get_x()+.12, i.get_height()+1.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\ndf_group_DE['serum_creatinine'].plot(kind=\"bar\",color=['darkcyan', 'grey'], ax=axes[1])\naxes[1].set_title('Mean of Serum Creatinine in each category Death Event', fontsize = 18)\naxes[1].set_xlabel('Category Death Event', fontsize = 14)\naxes[1].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[1].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[1].text(i.get_x()+.16, i.get_height()+.02, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\nplt.show()","e69b555f":"# Bar chart visualization of the mean numerical feature in each death event labels\n\nf, axes = plt.subplots(ncols=2, figsize=(26, 8))\n\ndf_group_DE['serum_sodium'].plot(kind=\"bar\", color=['darkcyan', 'grey'], ax=axes[0])\naxes[0].set_title('Mean of Serum Sodium in each category Death Event', fontsize = 18)\naxes[0].set_xlabel('Category Death Event', fontsize = 14)\naxes[0].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[0].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[0].text(i.get_x()+.16, i.get_height()+1.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\ndf_group_DE['time'].plot(kind=\"bar\",color=['darkcyan', 'grey'], ax=axes[1])\naxes[1].set_title('Mean of Time in each category Death Event', fontsize = 18)\naxes[1].set_xlabel('Category Death Event', fontsize = 14)\naxes[1].set_ylabel('Count', fontsize = 12)\n# set individual bar lables \nfor i in axes[1].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[1].text(i.get_x()+.16, i.get_height()+1.5, \\\n            str(i.get_height()), fontsize=16,\n                color='black')\n\nplt.show()","6190bed2":"# Histogram visualization of numerical feature\n\nf, axes = plt.subplots(ncols=4, figsize=(24, 6))\n\nsns.histplot(x='age', color='darkred', kde=True, data=df,ax=axes[0])\naxes[0].set_title('Histogram of Age', fontsize = 14)\n\nsns.histplot(x='creatinine_phosphokinase', color='darkred', kde=True, data=df,ax=axes[1])\naxes[1].set_title('Histogram of Creatinine Phosphokinase', fontsize = 14)\n\nsns.histplot(x='ejection_fraction', color='darkred', kde=True, data=df,ax=axes[2])\naxes[2].set_title('Histogram of Ejection Fraction', fontsize = 14)\n\nsns.histplot(x='platelets', color='darkred', kde=True, data=df,ax=axes[3])\naxes[3].set_title('Histogram of Platelets', fontsize = 14)\n\nplt.show()","c2b3511b":"# Histogram visualization of numerical feature\n\nf, axes = plt.subplots(ncols=3, figsize=(24, 6))\n\nsns.histplot(x='serum_creatinine', color='darkred', kde=True, data=df,ax=axes[0])\naxes[0].set_title('Histogram of Serum Creatinine', fontsize = 14)\n\nsns.histplot(x='serum_sodium', color='darkred', kde=True, data=df,ax=axes[1])\naxes[1].set_title('Histogram of Serum Sodium', fontsize = 14)\n\nsns.histplot(x='time', color='darkred', kde=True, data=df,ax=axes[2])\naxes[2].set_title('Histogram of Time', fontsize = 14)\n\nplt.show()","3ee25e87":"f, axes = plt.subplots(ncols=3, figsize=(24, 8))\n\n# BARCHART ANAEMIA vs DEATH EVENT\nsns.countplot(x='anaemia',hue='DEATH_EVENT', data=df, ax=axes[0])\naxes[0].set_title('Bar Plot Anaemia berdasarkan Death Event', fontsize = 18)\naxes[0].set_xlabel('Category Anaemia', fontsize = 15)\naxes[0].set_ylabel('Count', fontsize = 12)\ntotals0 = []\n# find the values and append to list\nfor i in axes[0].patches:\n    totals0.append(i.get_height())\n# set individual bar lables using above list    \ntotal0 = sum(totals0)\nfor i in axes[0].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[0].text(i.get_x()+.1, i.get_height()+.5, \\\n            str(round((i.get_height()\/total0)*100, 2))+'%', fontsize=14,\n                color='black')\n\n# BARCHART DIABETES vs DEATH EVENT\nsns.countplot(x='diabetes',hue='DEATH_EVENT', data=df, ax=axes[1])\naxes[1].set_title('Bar Plot Diabetes berdasarkan Death Event', fontsize = 18)\naxes[1].set_xlabel('Category Diabetes', fontsize = 15)\naxes[1].set_ylabel('Count', fontsize = 12)\ntotals1 = []\n# find the values and append to list\nfor i in axes[1].patches:\n    totals1.append(i.get_height())\n# set individual bar lables using above list    \ntotal1 = sum(totals1)\nfor i in axes[1].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[1].text(i.get_x()+.1, i.get_height()+.5, \\\n            str(round((i.get_height()\/total1)*100, 2))+'%', fontsize=14,\n                color='black')\n\n# BARCHART HIGH BLOOD PRESSURE vs DEATH EVENT\nsns.countplot(x='high_blood_pressure',hue='DEATH_EVENT', data=df, ax=axes[2])\naxes[2].set_title('Bar Plot High Blood Pressure berdasarkan Death Event', fontsize = 18)\naxes[2].set_xlabel('Category High Blood Pressure', fontsize = 15)\naxes[2].set_ylabel('Count', fontsize = 12)\ntotals2 = []\n# find the values and append to list\nfor i in axes[2].patches:\n    totals2.append(i.get_height())\n# set individual bar lables using above list    \ntotal2 = sum(totals2)\nfor i in axes[2].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[2].text(i.get_x()+.1, i.get_height()+.5, \\\n            str(round((i.get_height()\/total2)*100, 2))+'%', fontsize=14,\n                color='black')\n\nplt.show()","b39b9fe6":"f, axes = plt.subplots(ncols=2, figsize=(24, 8))\n\n# BARCHART SEX vs DEATH EVENT\nsns.countplot(x='sex',hue='DEATH_EVENT', data=df, ax=axes[0])\naxes[0].set_title('Bar Plot Sex berdasarkan Death Event', fontsize = 18)\naxes[0].set_xlabel('Category Sex', fontsize = 15)\naxes[0].set_ylabel('Count', fontsize = 12)\ntotals0 = []\n# find the values and append to list\nfor i in axes[0].patches:\n    totals0.append(i.get_height())\n# set individual bar lables using above list    \ntotal0 = sum(totals0)\nfor i in axes[0].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[0].text(i.get_x()+.1, i.get_height()+.5, \\\n            str(round((i.get_height()\/total0)*100, 2))+'%', fontsize=16,\n                color='black')\n\n# BARCHART SMOKING vs DEATH EVENT\nsns.countplot(x='smoking',hue='DEATH_EVENT', data=df, ax=axes[1])\naxes[1].set_title('Bar Plot Smoking Habits berdasarkan Death Event', fontsize = 18)\naxes[1].set_xlabel('Category Smoking', fontsize = 15)\naxes[1].set_ylabel('Count', fontsize = 12)\ntotals1 = []\n# find the values and append to list\nfor i in axes[1].patches:\n    totals1.append(i.get_height())\n# set individual bar lables using above list    \ntotal1 = sum(totals1)\nfor i in axes[1].patches:\n    # get_x pulls left or right; get_height pushes up or down\n    axes[1].text(i.get_x()+.1, i.get_height()+.5, \\\n            str(round((i.get_height()\/total1)*100, 2))+'%', fontsize=16,\n                color='black')\n\nplt.show()","c6d697a9":"# Boxplot visualization for outlier detection\n\nfig, axs = plt.subplots(ncols=4, nrows=2, figsize=(14, 8))\nindex = 0\naxs = axs.flatten()\n\nfor k,v in df_num.items():\n    sns.boxplot(y=k, color='grey', data=df_num, ax=axs[index])\n    index += 1\n    plt.tight_layout(pad=1, w_pad=2, h_pad=5.0)","41f0c3f1":"# defines outlier\ndef detect_outliers(df, x):\n    Q1 = df[x].describe()['25%']\n    Q3 = df[x].describe()['75%']\n    IQR = Q3-Q1\n    return df_num[(df[x] < Q1-1.5*IQR) | (df[x] > Q3+1.5*IQR)]","4148aeb3":"# displays data based on outliers in the Creatinine Phosphokine\ndetect_outliers(df_num,'creatinine_phosphokinase')[['creatinine_phosphokinase']]","c97ed5b6":"# displays data based on outliers in the Ejection Fraction\ndetect_outliers(df_num,'ejection_fraction')[['ejection_fraction']]","27ab48ff":"# displays data based on outliers in the Platelets\ndetect_outliers(df_num,'platelets')[['platelets']]","90272182":"# displays data based on outliers in the Serum Creatinine\ndetect_outliers(df_num,'serum_creatinine')[['serum_creatinine']]","e9e5cd01":"# displays data based on outliers in the Serum Sodium\ndetect_outliers(df_num,'serum_sodium')[['serum_sodium']]","d2cf3c81":"# kendall correlation of each numerical feature and death event label\ncorr = df_DE_and_num.corr(method='kendall')\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, cmap='coolwarm', annot=True)\nplt.show()","e506147e":"# numerical feature with higher correlation to death event\ncorr[abs(corr['DEATH_EVENT']) > 0.24]['DEATH_EVENT']","c6243d0f":"from sklearn.feature_selection import chi2","1bcef375":"df_cat=df[['sex','anaemia','diabetes','high_blood_pressure','smoking']]","4057323f":"df_cat.head()","262aef10":"f_score=chi2(df_cat,df[['DEATH_EVENT']])   #returns f score and p value \nf_score","02b9b8b8":"# printing p values for each categorical features\np_value = pd.Series(f_score[1],index=df_cat.columns)\np_value.sort_values(ascending=True,inplace=True)\np_value","fca62f5d":"p_value.plot(kind=\"bar\")\nplt.xlabel(\"Features\",fontsize=12)\nplt.ylabel(\"p-values\",fontsize=12)\nplt.title(\"Chi-squared test base on p-value\", fontsize=15)\nplt.show()","8e9539e4":"from sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\nStandardScaler = StandardScaler()\ncolumns_to_scale=['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\ndf[columns_to_scale] = StandardScaler.fit_transform(df[columns_to_scale])","3ac19ebd":"# displays the top 5 rows of data after normalization\ndf.head()","dabfe032":"# defines X and y\nX=df.drop(['DEATH_EVENT'], axis = 1)\ny=df['DEATH_EVENT']","3cc1cf34":"# defines Training set and Testing set\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","17e30dcf":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 10\nmean_acc_train = np.zeros((Ks-1))\nmean_acc_test = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat_train=neigh.predict(X_train)\n    yhat_test=neigh.predict(X_test)\n    mean_acc_train[n-1] = metrics.accuracy_score(y_train, yhat_train)\n    mean_acc_test[n-1] = metrics.accuracy_score(y_test, yhat_test) \n    std_acc[n-1]=np.std(yhat_test==y_test)\/np.sqrt(yhat_test.shape[0])\n\nprint(\"Akurasi Training\", np.round(mean_acc_train,3))\nprint(\"Akurasi Testing\", np.round(mean_acc_test,3))","b1e3c4b3":"plt.plot(range(1,Ks),mean_acc_test,'g')\nplt.fill_between(range(1,Ks),mean_acc_test - 1 * std_acc,mean_acc_test + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","93514056":"print( \"The best accuracy value is\", np.round(mean_acc_test.max(),3), \"with k=\", mean_acc_test.argmax()+1) ","fcf11dbd":"# use the best k\nk = 6\n\n# predict  \nyhat = neigh.predict(X_test)\n\n# matrix confusion\nfrom sklearn.metrics import confusion_matrix\ncm_knn = confusion_matrix(y_test,yhat)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_knn, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix KNN (with all features)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","6f6bc0c0":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, yhat))","691d8baa":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n# predict\nyhat_test = LR.predict(X_test)","4ebb8a3a":"# probability of the predict\nyhat_prob = LR.predict_proba(X_test)\nyhat_prob","3a159a92":"# matrix confusion\ncm_logreg = confusion_matrix(y_test,yhat_test)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_logreg, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix Logistic Regression (with all features)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","c94715a7":"from sklearn.metrics import accuracy_score\n\nmylist = []\nac_train = accuracy_score(y_train, yhat_train)\nac_test = accuracy_score(y_test, yhat_test)\nmylist.append(ac_train)\nmylist.append(ac_test)\nprint('Accuracy training:', np.round(ac_train,3))\nprint('Accuracy testing:', np.round(ac_test,3))","6fd98f24":"print(classification_report(y_test, yhat_test))","c04b1886":"from sklearn import svm\n\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)\n# predict\nyhat_test = clf.predict(X_test)","24f1bdd7":"# matrix confusion\ncm_svm = confusion_matrix(y_test,yhat_test)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_svm, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix SVM (with all features)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","a3777872":"from sklearn.metrics import accuracy_score\n\nmylist = []\nac_train = accuracy_score(y_train, yhat_train)\nac_test = accuracy_score(y_test, yhat_test)\nmylist.append(ac_train)\nmylist.append(ac_test)\nprint('Accuracy training:', np.round(ac_train,3))\nprint('Accuracy testing:', np.round(ac_test,3))","4f473bee":"print(classification_report(y_test, yhat_test))","635653bb":"# defines X1\n\nX1=df[['ejection_fraction', 'serum_creatinine', 'time']]","fa6a3f50":"# defines Training set and Testing set\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split( X1, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train1.shape,  y_train1.shape)\nprint ('Test set:', X_test1.shape,  y_test1.shape)","c06ba465":"Ks = 10\nmean_acc_train1 = np.zeros((Ks-1))\nmean_acc_test1 = np.zeros((Ks-1))\nstd_acc1 = np.zeros((Ks-1))\nConfustionMx1 = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh1 = KNeighborsClassifier(n_neighbors = n).fit(X_train1,y_train1)\n    yhat_train1=neigh1.predict(X_train1)\n    yhat_test1=neigh1.predict(X_test1)\n    mean_acc_train1[n-1] = metrics.accuracy_score(y_train1, yhat_train1)\n    mean_acc_test1[n-1] = metrics.accuracy_score(y_test1, yhat_test1) \n    std_acc1[n-1]=np.std(yhat_test1==y_test1)\/np.sqrt(yhat_test1.shape[0])\n\nprint(\"Akurasi Training\", np.round(mean_acc_train1,3))\nprint(\"Akurasi Testing\", np.round(mean_acc_test1,3))","29cfb19e":"plt.plot(range(1,Ks),mean_acc_test1,'g')\nplt.fill_between(range(1,Ks),mean_acc_test1 - 1 * std_acc1,mean_acc_test1 + 1 * std_acc1, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","7ecc5018":"print(\"The best accuracy value is\", np.round(mean_acc_test1.max(),3), \"with k=\", mean_acc_test1.argmax()+1) ","75f57bc2":"# use the best k\nk = 3\n\n# Predict  \nyhat1 = neigh1.predict(X_test1)\n\n# matrix confusion\ncm_knn1 = confusion_matrix(y_test1,yhat1)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_knn1, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix KNN (with features selection)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","8d3d9479":"print(classification_report(y_test1, yhat1))","66cf3b2a":"LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train1,y_train1)\n# predict\nyhat_test1 = LR.predict(X_test1)","04f81cbf":"# probability of the predict\nyhat1_prob = LR.predict_proba(X_test1)\nyhat1_prob","43d9bdd0":"# matrix confusion\ncm_logreg1 = confusion_matrix(y_test1,yhat_test1)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_logreg1, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix Logistic Regression (with features selection)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","050bf211":"mylist = []\nac_train = accuracy_score(y_train1, yhat_train1)\nac_test = accuracy_score(y_test1, yhat_test1)\nmylist.append(ac_train)\nmylist.append(ac_test)\nprint('Accuracy training:', np.round(ac_train,3))\nprint('Accuracy testing:', np.round(ac_test,3))","9b54a6e0":"print(classification_report(y_test1, yhat_test1))","c390b3e1":"clf = svm.SVC(kernel='rbf')\nclf.fit(X_train1, y_train1)\n# predict\nyhat_test1 = clf.predict(X_test1)","601eda09":"# matrix confusion\ncm_svm1 = confusion_matrix(y_test1,yhat_test1)\n\nf, ax = plt.subplots(figsize=(6,4))\nsns.heatmap(cm_svm1, annot = True, fmt='.0f', ax = ax)\nplt.title('Confusion Matrix SVM (with features selection)')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","ceb1c37a":"mylist = []\nac_train = accuracy_score(y_train1, yhat_train1)\nac_test = accuracy_score(y_test1, yhat_test1)\nmylist.append(ac_train)\nmylist.append(ac_test)\nprint('Accuracy training:', np.round(ac_train,3))\nprint('Accuracy testing:', np.round(ac_test,3))","aa2b9324":"print(classification_report(y_test1, yhat_test1))","f8d9a215":"#### Relationship between Categorical Features","589626c8":"Logistic Regression\n---\n(with all features)","6a329bd3":"With all the features, we get the SVM model with an accuracy of 0.83","4c25a2d4":"If we see above plot we can conclude that all categorical features in df_cat has p-value > 0.05 hence all categorical features does not have significance on target variable (death event).","25236c7c":"### Numeric Features","779572b9":"Logistic Regression\n---\n(with features selection)","c2bc9500":"With features ejection fraction, serum creatinine, and time, we get the KNN model with an accuracy of 0.82","c5d59fb0":"Modeling with Feature Selection\n----","278c00d1":"KNN (K Nearest Neighbor)\n----\n(with all features)","14844fc3":"With features ejection fraction, serum creatinine, and time, we get the Logistic Regression model with an accuracy of 0.90","6f79c831":"KNN (K Nearest Neighbor)\n---\n(with feature selection)","e451dace":"With all the features, we get the KNN model with an accuracy of 0.75","84d27d51":"Outlier Detection\n-----","2bf25847":"Data Preparation\n------","5162f338":"Modeling\n---","255c2b90":"##### So, it can be concluded that using the classification model selection feature will have a higher accuracy. In this dataset, the best model that can predict heart failure is Logistic Regression which has an accuracy of 90%. With features selection applied based on the control correlation, the model was built using three features are ejection fraction, serum creatinine, and time.","b307a05e":"Analyzing relationships between variables\n-----","112492d3":"Exploration Data Analysis\n-------","088d57c4":"we can conclude that some of the numerical features which have the highest correlation are ejection fraction, serum creatinin, and time.","c955d748":"Normalization\n---","7d4030c9":"There are various ways of dealing with outliers. Among them is to impute outliers, remove outliers, or keep them. To determine what steps to take, you need to research and seek knowledge about outliers, data sets, and maybe some domain knowledge before dealing with outliers. We need to know an understanding of the possible ranges contained in each feature. When I researched a little bit, I found that all of the outliers values were within the possible range of values. So the step taken in this case is to keep the value in the dataset.","4c231380":"SVM (Support Vector Machine)\n---\n(with all features)","23be40f6":"SVM (Support Vector Machine)\n----\n(with feature selection)","144485ee":"With features ejection fraction, serum creatinine, and time, we get the SVM model with an accuracy of 0.85","50df87bf":"With all the features, we get the Logistic Regression model with an accuracy of 0.87","0397aeec":"### Categorical Features","8d862800":"email : febrianasulistyap@gmail.com\n\nHEART FAILURE PREDICTION\n-----\n### Modeling with Classification (KNN, LogReg, SVM)","066c237f":"#### Relationship between Numerical Features"}}