{"cell_type":{"da538ac9":"code","fcb2577b":"code","f022a0aa":"code","1d415f33":"code","e38a29d8":"code","7ecd6b1f":"code","98535896":"code","1fdb419c":"code","1dd2c1e1":"code","710bc032":"code","734af91f":"code","d7cc8d5d":"code","cb7b16ee":"code","d6294685":"code","47a1b357":"code","5f12a912":"code","706d5fdc":"code","157ea36b":"code","4221aed6":"code","ea59ce02":"code","ec214c25":"code","573d1dda":"code","479d0663":"code","8be8886a":"code","3fb5cdc2":"code","e35f2d30":"code","cab3e700":"code","628653ca":"code","fbffa5e4":"code","d0469cc2":"code","3364df83":"code","b4d6690a":"code","de8830fb":"markdown","7bb3d3b2":"markdown","619cdbe9":"markdown","07ecbe6a":"markdown","899d6425":"markdown","76616cfd":"markdown","11f967a6":"markdown","e27204dc":"markdown","0fa8ab2b":"markdown","4e8456bd":"markdown","ec17c7bf":"markdown","79709a2e":"markdown","8351378e":"markdown","806b8bf9":"markdown"},"source":{"da538ac9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fcb2577b":"df = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv',delimiter=',', encoding='utf-8')\ndf.head()","f022a0aa":"#Fifth row, fourth column \n\ndf.iloc[4,3]","1d415f33":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport matplotlib.pyplot as plt\nimport re\nimport os\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","e38a29d8":"#Two thousand eight hundred seventeenth row, fourth column \n\ndf.iloc[2817,3]","7ecd6b1f":"df.shape","98535896":"df.isnull().sum()","1fdb419c":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>0 and df[feature].dtypes=='O']\nprint(categorical_nan)","1dd2c1e1":"#Two thousand eight hundred fourteenth row, fourth column \n\ndf.iloc[2814,3]","710bc032":"# replacing missing values in categorical features\nfor feature in categorical_nan:\n    df[feature] = df[feature].fillna('None')","734af91f":"df[categorical_nan].isna().sum()","d7cc8d5d":"remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)","cb7b16ee":"tokenize = lambda x: word_tokenize(x)","d6294685":"ps = PorterStemmer()\nstem = lambda w: [ ps.stem(x) for x in w ]","47a1b357":"lemmatizer = WordNetLemmatizer()\nleammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]","5f12a912":"#Two thousand eight hundred nineteenth row, fourth column \n\ndf.iloc[2819,3]","706d5fdc":"print('Processing : [=', end='')\ndf['excerpt'] = df['excerpt'].apply(remove_non_alphabets)\nprint('=', end='')\ndf['excerpt'] = df['excerpt'].apply(tokenize) # [ word_tokenize(row) for row in data['MESSAGE']]\nprint('=', end='')\ndf['excerpt'] = df['excerpt'].apply(stem)\nprint('=', end='')\ndf['excerpt'] = df['excerpt'].apply(leammtizer)\nprint('=', end='')\ndf['excerpt'] = df['excerpt'].apply(lambda x: ' '.join(x))\nprint('] : Completed', end='')\ndf.head()","157ea36b":"max_words = 10000\ncv = CountVectorizer(max_features=max_words, stop_words='english')\nsparse_matrix = cv.fit_transform(df['excerpt']).toarray()","4221aed6":"sparse_matrix.shape","ea59ce02":"#Two thousand eight hundred twenty second row, fourth column \n\ndf.iloc[2822,3]","ec214c25":"x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(df['standard_error']))","573d1dda":"class LogisticRegression(nn.Module):\n    def __init__(self):\n        super(LogisticRegression, self).__init__()\n        self.linear1 = nn.Linear(10000, 100)\n        self.linear2 = nn.Linear(100, 10)\n        self.linear3 = nn.Linear(10, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","479d0663":"model = LogisticRegression()","8be8886a":"#Two thousand eight hundred nineteenth row, fourth column \n\ndf.iloc[2829,3]","3fb5cdc2":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)","e35f2d30":"x_train = Variable(torch.from_numpy(x_train)).float()\ny_train = Variable(torch.from_numpy(y_train)).long()","cab3e700":"epochs = 20\nmodel.train()\nloss_values = []\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    loss_values.append(loss.item())\n    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n    acc = pred * 100.0 \/ len(x_train)\n    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n    loss.backward()\n    optimizer.step()","628653ca":"#Two thousand eight hundred sixteenth row, fourth column \n\ndf.iloc[2816,3]","fbffa5e4":"plt.plot(loss_values)\nplt.title('Loss Value vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Loss'])\nplt.show()","d0469cc2":"x_test = Variable(torch.from_numpy(x_test)).float()\ny_test = Variable(torch.from_numpy(y_test)).long()","3364df83":"model.eval()\nwith torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n    print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))","b4d6690a":"#Third row, fourth column \n\ndf.iloc[2,3]","de8830fb":"#You know that wind and water can shape Earth\u2019s land. But did you know that glaciers can too?\n\n![](https:\/\/www.whatihavelearnedteaching.com\/wp-content\/uploads\/2016\/02\/Processes-that-Shape-the-Earth-2A-Wind-and-Water-Change-Land.jpeg)whatilearnedteaching.com","7bb3d3b2":"#Roger or anybody else in Patty Blossom (by Carolyn Wells) could predict that I would 100% fail.","619cdbe9":"#Augmented reality (AR)\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRG2O9FQ1bmBxp2qvtiK4FLCIpR_HxqvM9aJA&usqp=CAU)qualitymag.com","07ecbe6a":"# **<span style=\"color:#DC143C;\">The more you read. The more you write. The better you code.<\/span>**","899d6425":"\"Can machine learning identify the appropriate reading level of a passage of text, and help inspire learning? Reading is an essential skill for academic success. When students have access to engaging passages offering the right level of challenge, they naturally develop reading skills.\"\n\nhttps:\/\/www.kaggle.com\/c\/commonlitreadabilityprize","76616cfd":"#Reaction time. More specifically delayed reaction, cited as a key contributor to vehicular accidents\n\n![](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S0001457516302366-gr13.jpg)sciencedirect.com","11f967a6":"#I wanted to use target however it resulted in error when I ran the model and epochs below. \nTherefore I changed to standard error, which is probably another error.","e27204dc":"#Patty Blossom (by Carolyn Wells)\n\n![](https:\/\/tile.loc.gov\/image-services\/iiif\/service:gdc:dcmsiabooks:pa:tt:yb:lo:ss:om:00:we:ll:pattyblossom00well:pattyblossom00well_0031\/full\/pct:12.5\/0\/default.jpg)loc.gov","0fa8ab2b":"#Have you ever found strange holes in your clothes? They might have been made by a hungry moth larva!\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTw76gUx_q9nAWT2ud85tGT-kLxFRkkRl5ekg&usqp=CAU)onlinepestcontrol.com","4e8456bd":"<h1 style=\"background-color:#DC143C; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% \/ 10% 40%\">Reading, an Essential Skill for Academic Success<\/h1>","ec17c7bf":"![](https:\/\/files.realpython.com\/media\/Use-Sentiment-Analysis-With-Python-to-Classify-Reviews_Watermarked.e73ba441d870.jpg)realpython.com","79709a2e":"#Once upon a time there were Three Bears who lived together in a house of their own in a wood.\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRcnbcTqYqDuTucIMWcUsNL9VgHLQGYBvoTxw&usqp=CAU)amazon.com","8351378e":"#A baby boom is any period marked by a greatly increased birth rate.\n\n![](https:\/\/resquiciosdahistoria.files.wordpress.com\/2013\/08\/baby-boomer-chart1.gif)resquiciosdahistoria.wordpress.com","806b8bf9":"#When you think of dinosaurs and where they lived, what do you picture?\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRQ80wUK9kCb2FOH54ihPrKTB5jn82lZMa2dA&usqp=CAU)pubs.usgs.gov"}}