{"cell_type":{"89d5f54c":"code","2e604889":"code","0bb825e9":"code","333ec69d":"code","94ec9eac":"code","2b2a80bf":"code","b8ea9620":"code","8f2980ae":"code","c4ed31d9":"code","cdb33cc8":"code","468f4197":"code","99192f84":"code","e7311139":"code","e4e1e059":"code","4ddd9f0c":"code","92c0b3be":"code","2dd5f460":"code","35aa3e19":"code","72de9ae4":"code","b9fa0f0c":"code","5252fbd7":"code","6e1ad07f":"code","2c01d06f":"code","d1bba2a4":"code","01e1a9f4":"code","60259e88":"code","a5d5b5e8":"code","44890723":"code","61dd2096":"code","9ac33d85":"code","310c85c3":"code","583114c8":"markdown","b8a1cdaa":"markdown","a4a5c6f3":"markdown","71f4b953":"markdown","4054861c":"markdown","1763b0b4":"markdown","3eae570a":"markdown","ca8745ad":"markdown","0ea1dcc2":"markdown"},"source":{"89d5f54c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e604889":"import re\nimport time","0bb825e9":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds","333ec69d":"with open('\/kaggle\/input\/englishfrench-corpus\/europarl-v7.fr-en.en', mode='r', encoding='utf-8') as f:\n    europarl_en = f.read()\n\nwith open('\/kaggle\/input\/englishfrench-corpus\/europarl-v7.fr-en.fr', mode='r', encoding='utf-8') as f:\n    europarl_fr = f.read()\n    \nwith open('\/kaggle\/input\/englishfrench-corpus\/P85-Non-Breaking-Prefix.en', mode='r', encoding='utf-8') as f:\n    non_breaking_prefix_en = f.read()\n    \nwith open('\/kaggle\/input\/englishfrench-corpus\/P85-Non-Breaking-Prefix.fr', mode='r', encoding='utf-8') as f:\n    non_breaking_prefix_fr = f.read()","94ec9eac":"# Creation of list of prefixes\nnon_breaking_prefix_en = non_breaking_prefix_en.split('\\n')\nnon_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]\n\nnon_breaking_prefix_fr = non_breaking_prefix_fr.split('\\n')\nnon_breaking_prefix_fr = [' ' + pref + '.' for pref in non_breaking_prefix_fr]","2b2a80bf":"# Cleaning the Data\ncorpus_en = europarl_en\n\nfor prefix in non_breaking_prefix_en:\n    corpus_en = corpus_en.replace(prefix, prefix + '###')\n\ncorpus_en = re.sub(r'\\.(?=[0-9]|[a-z]|[A-Z])', '.###', corpus_en)\ncorpus_en = re.sub(r'\\.###', '', corpus_en)\ncorpus_en = re.sub(r'  +', ' ', corpus_en)\ncorpus_en = corpus_en.split('\\n')\n\ncorpus_fr = europarl_fr\n\nfor prefix in non_breaking_prefix_fr:\n    corpus_fr = corpus_fr.replace(prefix, prefix + '###')\n\ncorpus_fr = re.sub(r'\\.(?=[0-9]|[a-z]|[A-Z])', '.###', corpus_fr)\ncorpus_fr = re.sub(r'\\.###', '', corpus_fr)\ncorpus_fr = re.sub(r'  +', ' ', corpus_fr)\ncorpus_fr = corpus_fr.split('\\n')","b8ea9620":"# Tokenizing the corpuses\n\ntokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n        corpus_en, target_vocab_size=2**13)\ntokenizer_fr = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n        corpus_fr, target_vocab_size=2**13)","8f2980ae":"VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # 2 extra spaces are for starting and ending of sentence\nVOCAB_SIZE_FR = tokenizer_fr.vocab_size + 2","c4ed31d9":"#Creation of input and output formats\ninputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1] for sentence in corpus_en]\n\noutputs = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1] for sentence in corpus_fr]","cdb33cc8":"# Removing too long sentences\n\nMAX_LENGTH = 20\nidx_to_remove = [count for count, sent in enumerate(inputs) if len(sent) > MAX_LENGTH]\n\nfor idx in reversed(idx_to_remove):\n    del inputs[idx]\n    del outputs[idx]\n    \nidx_to_remove = [count for count, sent in enumerate(outputs) if len(sent) > MAX_LENGTH]\n\nfor idx in reversed(idx_to_remove):\n    del inputs[idx]\n    del outputs[idx]","468f4197":"# Padding inputs and outputs\n\ninputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                       value=0,\n                                                       padding='post',\n                                                       maxlen=MAX_LENGTH)\n\noutputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n                                                        value=0,\n                                                        padding='post',\n                                                        maxlen=MAX_LENGTH)","99192f84":"BATCH_SIZE = 128\nBUFFER_SIZE = 20000\n\ndataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n\ndataset = dataset.cache() # To increase speed\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) #Data is prefetched to increase speed","e7311139":"# Custom Positional Encoding Layer\n\nclass PositionalEncoding(layers.Layer):\n    '''\n    Custom Positional Encoding Class. Inherited from tensorflow.keras.layers.Layer\n    '''\n    def __init__(self):\n        super(PositionalEncoding, self).__init__()\n        \n    def get_angles(self, pos, i, d_model): # Input shapes -- pos: (seq_length, 1); i: (1, d_model)\n        angles = 1 \/ np.power(10000., (2*(i\/\/2))\/np.float32(d_model)) # Angles have even index both for odd and even indices\n        return pos * angles # Returns matrix of shape (seq_length, d_model)\n    \n    def call(self, inputs):\n        \n        seq_length = inputs.shape.as_list()[-2]\n        d_model = inputs.shape.as_list()[-1]\n        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n                                 np.arange(d_model)[np.newaxis, :],\n                                 d_model)\n        \n        angles[:, 0::2] = np.sin(angles[:, 0::2]) # Gives a step-size of 2 to include only even numbers\n        angles[:, 1::2] = np.cos(angles[:, 1::2]) # Gives a step-size of 2 to include only odd numbers\n        pos_encoding = angles[np.newaxis, ...] # Adding an extra dimension for batching compatibility\n        \n        return inputs + tf.cast(pos_encoding, tf.float32)","e4e1e059":"def scaled_dot_product_attention(queries, keys, values, mask):\n    '''\n    queries: Q Matrix\n    keys: K Matrix\n    values: V Matrix\n    mask: can be used for both look-ahead masking and masking for padded zeroes\n    '''\n    \n    product = tf.matmul(queries, keys, transpose_b=True)\n    \n    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32) # dk value\n    \n    scaled_product = product \/ tf.math.sqrt(keys_dim)\n    \n    if mask is not None:\n        scaled_product += (mask * -1e9) # adding a very small number for mask so that softmax value for it becomes zero\n        \n    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n    \n    return attention### Multi-head attention sublayer","4ddd9f0c":"#Custom Multi-Head Attention Layer\nclass MultiHeadAttention(layers.Layer):\n    '''\n    Custom Multi-head Attention Class. Inherited from tensorflow.keras.layers.Layer\n    nb_proj: Number of projections that matrices should be split into\n    '''\n    \n    def __init__(self, nb_proj):\n        super(MultiHeadAttention, self).__init__()\n        self.nb_proj = nb_proj\n    \n    def build(self, input_shape):\n        '''\n        Runs when object if first time used. Unlike init function, which runs when the object is created\n        '''\n        \n        self.d_model = input_shape[-1] # Input Shape is the shape of Q matrix\n        assert self.d_model % self.nb_proj == 0\n        \n        self.d_proj = self.d_model \/\/self.nb_proj\n        \n        self.query_lin = layers.Dense(units = self.d_model)\n        self.key_lin = layers.Dense(units = self.d_model)\n        self.value_lin = layers.Dense(units = self.d_model)\n        self.final_lin = layers.Dense(units = self.d_model)\n        \n    def split_proj(self, inputs, batch_size):\n        '''\n        Function for splitting input matrix into projections\n        inputs: input tensor with shape (batch_size, seq_length, d_model)\n        returns a tensor of shape(batch_size, nb_proj, seq_length, d_proj)\n        '''\n        \n        shape = (batch_size,\n                 -1,\n                 self.nb_proj,\n                 self.d_proj)\n        # print(shape, tf.shape(inputs)) --Debugging print\n        \n        splitted_inputs = tf.reshape(inputs, shape=shape) # shape of splitted_inputs: (batch_size, seq_length, nb_proj, d_proj)\n        \n        return tf.transpose(splitted_inputs, perm=[0, 2, 1, 3])\n        \n    def call(self, queries, keys, values, mask):\n        '''\n        queries: Q Matrix\n        keys: K Matrix\n        values: V Matrix\n        mask: can be used for both look-ahead masking and masking for padded zeroes\n        '''\n        batch_size = tf.shape(queries)[0]\n        \n        queries = self.query_lin(queries) # Applying Big Linear function to Q Matrix\n        keys = self.key_lin(keys) # Applying Big Linear function to K Matrix\n        values = self.value_lin(values) # Applying Big Linear function to V Matrix\n        \n        queries = self.split_proj(queries, batch_size) # Splitting into projections\n        keys = self.split_proj(keys, batch_size) # Splitting into projections\n        values = self.split_proj(values, batch_size) # Splitting into projections\n        \n        attention = scaled_dot_product_attention(queries, keys, values, mask)\n        \n        #Concatinating the splitted projections after attention in reverse process of split_proj function\n        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n        concat_attention = tf.reshape(attention,\n                                      shape=(batch_size, -1, self.d_model))\n        \n        # Applying final Linear function\n        outputs = self.final_lin(concat_attention)\n        \n        return outputs","92c0b3be":"# Custom Encoder Layer\n\nclass EncoderLayer(layers.Layer):\n    '''\n    Custom Encoder Layer Class. Inherited from tensorflow.keras.layers.Layer\n    FFN_units: Feed Forward Network units\n    nb_proj: Number of Projections\n    dropout: Dropout Rate\n    '''\n    \n    def __init__(self, FFN_units, nb_proj, dropout):\n        super(EncoderLayer, self).__init__()\n        self.FFN_units = FFN_units\n        self.nb_proj = nb_proj\n        self.dropout = dropout\n    \n    def build(self, input_shape):\n        '''\n        Runs when object if first time used. Unlike init function, which runs when the object is created\n        '''\n        self.d_model = input_shape[-1]\n        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n        self.dropout_1 = layers.Dropout(rate=self.dropout)\n        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n        self.dense_2 = layers.Dense(units=self.d_model)\n        self.dropout_2 = layers.Dropout(rate=self.dropout)\n        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n        \n    def call(self, inputs, mask, training):\n        attention = self.multi_head_attention(inputs,\n                                              inputs,\n                                              inputs,\n                                              mask)\n        \n        attention = self.dropout_1(attention, training=training)\n        attention = self.norm_1(attention + inputs)\n        \n        outputs = self.dense_1(attention)\n        outputs = self.dense_2(outputs)\n        outputs = self.dropout_2(outputs)\n        outputs = self.norm_2(outputs + attention)\n        \n        return outputs","2dd5f460":"# Custom Encoder\n\nclass Encoder(layers.Layer):\n    '''\n    Custom Encoder Class. Inherited from tensorflow.keras.layers.Layer\n    nb_layers: Number of layers of encoders\n    FFN_units: Feed Forward Network units\n    nb_proj: Number of Projections\n    dropout: Dropout Rate\n    vocab_size: Vocabulary Size\n    d_model: last dimension of input matrix\n    '''\n    \n    def __init__(self,\n                 nb_layers,\n                 FFN_units,\n                 nb_proj,\n                 dropout,\n                 vocab_size,\n                 d_model,\n                 name='encoder'):\n        super(Encoder, self).__init__(name=name)\n        self.nb_layers = nb_layers\n        self.d_model = d_model\n        \n        self.embedding = layers.Embedding(vocab_size, d_model)\n        self.pos_encoding = PositionalEncoding()\n        self.dropout = layers.Dropout(rate=dropout)\n        self.enc_layers = [EncoderLayer(FFN_units,\n                                        nb_proj,\n                                        dropout)\n                           for _ in range(nb_layers)]\n        \n    def call(self, inputs, mask, training):\n        outputs = self.embedding(inputs)\n        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        outputs = self.pos_encoding(outputs)\n        outputs = self.dropout(outputs, training)\n        \n        for i in range(self.nb_layers):\n            outputs = self.enc_layers[i](outputs, mask, training)\n        \n        return outputs","35aa3e19":"# Custom Decoder Layer\n\nclass DecoderLayer(layers.Layer):\n    '''\n    Custom Decoder Layer Class. Inherited from tensorflow.keras.layers.Layer\n    FFN_units: Feed Forward Network units\n    nb_proj: Number of Projections\n    dropout: Dropout Rate\n    '''\n    \n    def __init__(self, FFN_units, nb_proj, dropout):\n        super(DecoderLayer, self).__init__()\n        self.FFN_units = FFN_units\n        self.nb_proj = nb_proj\n        self.dropout = dropout\n    \n    def build(self, input_shape):\n        '''\n        Runs when object if first time used. Unlike init function, which runs when the object is created\n        '''\n        self.d_model = input_shape[-1]\n        \n        # Layers for Phase I\n        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n        self.dropout_1 = layers.Dropout(rate=self.dropout)\n        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n        \n        # Layers for Phase II\n        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n        self.dropout_2 = layers.Dropout(rate=self.dropout)\n        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n        \n        # Layers for Phase III\n        self.dense_1 = layers.Dense(units=self.FFN_units, activation='relu')\n        self.dense_2 = layers.Dense(units=self.d_model)\n        self.dropout_3 = layers.Dropout(rate=self.dropout)\n        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n        \n    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n        \n        # Phase I\n        attention = self.multi_head_attention_1(inputs,\n                                                inputs,\n                                                inputs,\n                                                mask_1)\n        attention = self.dropout_1(attention, training)\n        attention = self.norm_1(attention + inputs)\n        \n        # Phase II\n        attention_2 = self.multi_head_attention_2(attention,\n                                                enc_outputs,\n                                                enc_outputs,\n                                                mask_2)\n        attention_2 = self.dropout_2(attention_2, training)\n        attention_2 = self.norm_2(attention_2 + attention)\n        \n        # Phase III\n        outputs = self.dense_1(attention_2)\n        outputs = self.dense_2(outputs)\n        outputs = self.dropout_3(outputs, training)\n        outputs = self.norm_3(outputs + attention_2)\n        \n        return outputs","72de9ae4":"# Custom Decoder\n\nclass Decoder(layers.Layer):\n    '''\n    Custom Decoder Class. Inherited from tensorflow.keras.layers.Layer\n    nb_layers: Number of layers of decoders\n    FFN_units: Feed Forward Network units\n    nb_proj: Number of Projections\n    dropout: Dropout Rate\n    vocab_size: Vocabulary Size\n    d_model: last dimension of input matrix\n    '''\n    \n    def __init__(self,\n                 nb_layers,\n                 FFN_units,\n                 nb_proj,\n                 dropout,\n                 vocab_size,\n                 d_model,\n                 name='decoder'):\n        super(Decoder, self).__init__(name=name)\n        self.d_model = d_model\n        self.nb_layers = nb_layers\n        \n        self.embedding = layers.Embedding(vocab_size, d_model)\n        self.pos_encoding = PositionalEncoding()\n        self.dropout = layers.Dropout(rate=dropout)\n        \n        self.dec_layers = [DecoderLayer(FFN_units,\n                                        nb_proj,\n                                        dropout)\n                          for _ in range(nb_layers)]\n        \n    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n        \n        outputs = self.embedding(inputs)\n        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        outputs = self.pos_encoding(outputs)\n        outputs = self.dropout(outputs, training)\n        \n        for i in range(self.nb_layers):\n            outputs = self.dec_layers[i](outputs,\n                                         enc_outputs,\n                                         mask_1,\n                                         mask_2,\n                                         training)\n            \n        return outputs","b9fa0f0c":"# Custom Transformer Model\n\nclass Transformer(tf.keras.Model):\n    '''\n    Custom Transformer Model Class. Inherited from tensorflow.keras.Model\n    nb_layers: Number of layers of Encoders and Decoders\n    FFN_units: Feed Forward Network units\n    nb_proj: Number of Projections\n    dropout: Dropout Rate\n    vocab_size_enc: Vocabulary Size of encoder\n    vocab_size_dec: Vocabulary Size of decoder\n    d_model: last dimension of input matrix\n    '''\n    \n    def __init__(self,\n                 vocab_size_enc,\n                 vocab_size_dec,\n                 d_model,\n                 nb_layers,\n                 FFN_units,\n                 nb_proj,\n                 dropout,\n                 name='transformer'):\n        super(Transformer, self).__init__(name=name)\n        \n        self.encoder = Encoder(nb_layers,\n                               FFN_units,\n                               nb_proj,\n                               dropout,\n                               vocab_size_enc,\n                               d_model)\n        \n        self.decoder = Decoder(nb_layers,\n                               FFN_units,\n                               nb_proj,\n                               dropout,\n                               vocab_size_dec,\n                               d_model)\n        self.last_linear = layers.Dense(units = vocab_size_dec)\n        \n    \n    def create_padding_mask(self, seq):\n        '''\n        Function for creating Padding masks\n        seq: sequence of numbers post-tokenization of shape (batch_size, seq_length)\n        '''\n        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n        return mask[:, tf.newaxis, tf.newaxis, :]\n    \n    def create_look_ahead_mask(self, seq):\n        '''\n        Function for creating Look Ahead masks\n        '''\n        seq_len = tf.shape(seq)[1]\n        look_ahead_mask = 1- tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n        return look_ahead_mask\n        \n    def call(self, enc_inputs, dec_inputs, training):\n        \n        enc_mask = self.create_padding_mask(enc_inputs)\n        dec_mask_1 = tf.maximum(\n                                self.create_padding_mask(dec_inputs),\n                                self.create_look_ahead_mask(dec_inputs))\n        dec_mask_2 = self.create_padding_mask(enc_inputs)\n        \n        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n        dec_outputs = self.decoder(dec_inputs,\n                                   enc_outputs,\n                                   dec_mask_1,\n                                   dec_mask_2,\n                                   training)\n        \n        outputs = self.last_linear(dec_outputs)\n        \n        return outputs\n    ","5252fbd7":"tf.keras.backend.clear_session()\n\n#Hyper-Parameters, with article parameters given as comments\nD_MODEL = 128 # 512\nNB_LAYERS = 4 # 6\nFFN_UNITS = 512 # 2048\nNB_PROJ = 8 # 8\nDROPOUT = 0.1 # 0.1","6e1ad07f":"transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n                          vocab_size_dec=VOCAB_SIZE_FR,\n                          d_model=D_MODEL,\n                          nb_layers=NB_LAYERS,\n                          FFN_units=FFN_UNITS,\n                          nb_proj=NB_PROJ,\n                          dropout=DROPOUT)","2c01d06f":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n                                                            reduction='none')\n\ndef loss_function(target, pred):\n    '''\n    Custom loss function with no reduction and loss for padding tokens is masked to zero\n    '''\n    mask = tf.math.logical_not(tf.math.equal(target, 0))\n    loss_ = loss_object(target, pred)\n    \n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    \n    return tf.reduce_mean(loss_)\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')","d1bba2a4":"#Custom Learning Rate Scheduler\n\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    '''\n    Custom Learning Rate Scheduler Class. Inherited from tensorflow.keras.optimizers.schedules.LearningRateSchedule\n    warmup_steps: steps till which learning rate is increased linearly and after which it is decreased exponentially\n    '''\n    \n    def __init__(self, d_model, warmup_steps=4000):\n        super(CustomSchedule, self).__init__()\n        \n        self.d_model = tf.cast(d_model, tf.float32)\n        self.warmup_steps = warmup_steps\n        \n    def __call__(self, step):\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps**-1.5)\n        \n        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n    \nlearning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate,\n                                     beta_1=0.9,\n                                     beta_2=0.98,\n                                     epsilon=1e-9)","01e1a9f4":"checkpoint_path = '\/ckpt\/'\n\nckpt = tf.train.Checkpoint(transformer=transformer,\n                           optimizer=optimizer)\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print(\"Latest checkpoint restored!!\")","60259e88":"EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    \n    print(\"Start of epoch {}\".format(epoch+1))\n    start = time.time()\n    \n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    \n    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n        \n        dec_inputs = targets[:, :-1]\n        dec_outputs_real = targets[:, 1:]\n        \n        with tf.GradientTape() as tape:\n            predictions = transformer(enc_inputs, dec_inputs, True)\n            loss = loss_function(dec_outputs_real, predictions)\n        \n        gradients = tape.gradient(loss, transformer.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n        \n        train_loss(loss)\n        train_accuracy(dec_outputs_real, predictions)\n        \n        if batch % 50 == 0:\n            print(\"Epoch: {} Batch: {} Loss: {:.4f} Accuracy: {:.4f}\".format(\n                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n            \n    ckpt_save_path = ckpt_manager.save()\n    print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))\n    \n    print(\"Time taken for epoch {}: {}\".format(epoch + 1 , time.time() - start))","a5d5b5e8":"def evaluate(inp_sentence):\n    inp_sentence = \\\n        [VOCAB_SIZE_EN-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_EN-1]\n    enc_input = tf.expand_dims(inp_sentence, axis=0)\n    \n    output = tf.expand_dims([VOCAB_SIZE_FR-2], axis=0)\n    \n    for _ in range(MAX_LENGTH):\n        predictions = transformer(enc_input, output, False) # shape of predictions: (1, seq_length, vocab_size_fr)\n        prediction = predictions[:, -1:, :]\n        \n        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n        \n        if predicted_id == VOCAB_SIZE_FR-1:\n            return tf.squeeze(output, axis=0)\n        \n        output = tf.concat([output, predicted_id], axis=-1)\n        \n    return tf.squeeze(output, axis=0)\n        ","44890723":"def translate(sentence):\n    output = evaluate(sentence).numpy()\n    \n    predicted_sentence = tokenizer_fr.decode(\n        [i for i in output if i < VOCAB_SIZE_FR-2]\n    )\n    \n    print(\"Input: {}\".format(sentence))\n    print(\"Predicted translation: {}\".format(predicted_sentence))","61dd2096":"translate(\"Good morning\")\ntranslate(\"How are you\")\ntranslate(\"Let us start working\")","9ac33d85":"translate(\"I hate this\")\ntranslate(\"This is bad\")\ntranslate(\"We need to do better\")","310c85c3":"translate(\"You are mad\")\ntranslate(\"The probability of this happening is negligible\")\ntranslate(\"I just need a long sentence that will break this\")","583114c8":"## Transformer","b8a1cdaa":"# MODEL BUILDING\n\nPositional encoding formulae:\n\n$PE_{(pos,2i)} =\\sin(pos\/10000^{2i\/dmodel})$\n\n$PE_{(pos,2i+1)} =\\cos(pos\/10000^{2i\/dmodel})$","a4a5c6f3":"### Multi-head attention sublayer","71f4b953":"$Attention(Q, K, V ) = \\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_k}}\\right)V $","4054861c":"## Decoder","1763b0b4":"# Training","3eae570a":"### Attention computation","ca8745ad":"## Encoder","0ea1dcc2":"## Attention"}}