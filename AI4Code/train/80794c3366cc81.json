{"cell_type":{"f64ece7d":"code","462f45de":"code","9e262565":"code","cc45cecf":"code","494fee5e":"code","7cb6f6e6":"code","6955ec7b":"code","87032757":"code","068eba90":"code","7960e8e9":"code","648ec695":"code","6085a7fc":"code","cb6135ae":"code","3591fdf8":"code","b974e3a7":"code","6b6069ab":"code","8e5eb9d8":"code","5150638f":"code","1b091617":"code","0f62d5d6":"code","67dbd967":"code","f3c26dcb":"code","adbcdfb4":"code","8971c0e8":"code","bc586419":"code","3630a974":"markdown","f3cae6a8":"markdown","56d9f7f3":"markdown","5e4a4b8a":"markdown","613e5ec8":"markdown","30237e73":"markdown","e98a3ad3":"markdown","d0c1792b":"markdown","f1043998":"markdown","ecc00eaa":"markdown","e14a6e34":"markdown","969c5d46":"markdown","e53b55fd":"markdown","a3940641":"markdown","b570ad2d":"markdown","12493d26":"markdown","0b861562":"markdown","0153cab9":"markdown"},"source":{"f64ece7d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LassoCV, Ridge\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing, svm","462f45de":"train_path = '\/kaggle\/input\/titanic\/train.csv'\ngender_path = '\/kaggle\/input\/titanic\/gender_submission.csv'\ntest_path = '\/kaggle\/input\/titanic\/test.csv'\ntrain = pd.read_csv(train_path)\ngender = pd.read_csv(gender_path)\ntest =pd.read_csv(test_path)\ntest['Survived'] = np.empty((len(test), 0)).tolist()\nTotal = train.append(test)\nTotal.set_index('PassengerId', inplace = True)\nTotal","9e262565":"for column in Total:\n    if Total[column].isnull().sum() != 0:\n        print('Missing values in',column,':', Total[column].isnull().sum())","cc45cecf":"Total = Total.drop(['Ticket','Cabin'], axis = 1)\nfare_mode = Total['Fare'].mode().iat[0]\nTotal['Fare'].fillna(fare_mode,inplace = True)\nembarked_mode = Total['Embarked'].mode().iat[0]\nTotal['Embarked'].fillna(embarked_mode, inplace = True)\nfor column in Total:\n    if Total[column].isnull().sum() != 0:\n        print('Missing values in',column,':', Total[column].isnull().sum())","494fee5e":"sex_dummy = pd.get_dummies(Total['Sex'])\nTotal = Total.drop('Sex', axis = 1)\nTotal = pd.concat([Total, sex_dummy], axis = 1)\nembark_dummy = pd.get_dummies(Total['Embarked'])\nTotal = Total.drop('Embarked', axis = 1)\nTotal = pd.concat([Total, embark_dummy], axis = 1)\nTotal","7cb6f6e6":"title = lambda x: x.split(',')[1].split('.')[0].strip()\nTotal['Title']=Total['Name'].map(title)\nTotal = Total.drop('Name', axis = 1)\nTotal","6955ec7b":"title_dummy = pd.get_dummies(Total['Title'])\ntitle_dummy\ntitle_dummy['Mil'] = title_dummy['Capt']+title_dummy['Col']+title_dummy['Major']\ntitle_dummy = title_dummy.drop(['Capt','Col','Major'], axis = 1)\ntitle_dummy['Senior Male Honorific'] = title_dummy['Don']+title_dummy['Sir']\ntitle_dummy = title_dummy.drop(['Don','Sir'], axis = 1)\ntitle_dummy['Senior Female Honorific'] = title_dummy['Dona']+title_dummy['Mme']+title_dummy['Lady']\ntitle_dummy = title_dummy.drop(['Dona','Mme','Lady'], axis = 1)\ntitle_dummy['Ms+Mlle'] = title_dummy['Ms']+title_dummy['Mlle']\ntitle_dummy = title_dummy.drop(['Ms','Mlle'], axis = 1)\ntitle_dummy['Fancy'] = title_dummy['Jonkheer']+title_dummy['the Countess']\ntitle_dummy = title_dummy.drop(['Jonkheer','the Countess'], axis = 1)\nTotal = Total.drop('Title', axis = 1)\nTotal = pd.concat([Total, title_dummy], axis = 1)\nTotal","87032757":"Age_Total = Total\nAge_Total = Age_Total.dropna()\nAge_Total\ndef nans(df): return df[df.isnull().any(axis=1)]\nAge_Total_Predict = nans(Total)\nAge_Total_Predict","068eba90":"col = list(Age_Total.columns)\ncol.remove('Age')\ncol.remove('Survived')\nAge_Total[col]","7960e8e9":"x = Age_Total[col]\nx_test = Age_Total_Predict[col]\ny_train = Age_Total['Age']\nx_train = StandardScaler().fit(x).transform(x)\nx_test = StandardScaler().fit(x_test).transform(x_test)","648ec695":"lasso = LassoCV(alphas = [0.01, 0.05, 0.1, 0.15,0.5]).fit(x_train, y_train)\nalpha = 0.1\nlasso_tuned = LassoCV(alphas = [0.8*alpha, 0.9*alpha, alpha, 1.1*alpha, 1.2*alpha]).fit(x_train, y_train)","6085a7fc":"svm_age = svm.SVR(kernel = 'rbf')\nsvm_age.fit(x_train, y_train)","cb6135ae":"ridge = Ridge()\nparameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\nridge_age = GridSearchCV(ridge, parameters, scoring = 'neg_root_mean_squared_error', cv=5)\nridge_age.fit(x_train, y_train)\nprint(ridge_age.best_params_)\nprint(-ridge_age.best_score_)","3591fdf8":"print('The average R squared score for the lasso model is:', -cross_val_score(lasso_tuned, x_train, y_train, scoring ='neg_root_mean_squared_error').mean())\nprint('The average R squared score for the svm model is:', -cross_val_score(svm_age, x_train, y_train, scoring ='neg_root_mean_squared_error').mean())\nprint('The average R squared score for the ridge model is:', -ridge_age.best_score_)\n#Gonna use the lasso model, since it has the lowest RSME","b974e3a7":"predicted_ages = pd.DataFrame(lasso_tuned.predict(x_test), columns=['Age']) \nAge_Total_Predict.drop('Age',axis = 1)\nAge_Total_Predict = Age_Total_Predict.assign(Age = lasso_tuned.predict(x_test).round())\nAge_Total_Predict['PassengerId'] = Age_Total_Predict.index\nAge_Total_Predict = Age_Total_Predict.reset_index(drop=True)\nAge_Total_Predict","6b6069ab":"Age_Total['PassengerId'] = Age_Total.index\nAge_Total = Age_Total.reset_index(drop=True)\nTotal_Processed = pd.concat([Age_Total_Predict,Age_Total])\nTotal_Processed.set_index('PassengerId', inplace = True)\nTotal_Processed = Total_Processed.sort_index()\nfix_neg = lambda x: x + 11.148738330664404 if x < 0 else x\nTotal_Processed['Age'] = Total_Processed['Age'].apply(fix_neg)\nTotal_Processed","8e5eb9d8":"Train_Processed = Total_Processed[:len(train)]\nTest_Processed = Total_Processed[len(train):]","5150638f":"col = list(Train_Processed.columns)\ncol.remove('Survived')\nx_train = Train_Processed[col]\ny_train = Train_Processed['Survived']\ny_train = y_train.astype('int')\nx_final = Test_Processed[col]\nx_train = preprocessing.StandardScaler().fit(x_train).transform(x_train)\nx_final= preprocessing.StandardScaler().fit(x_final).transform(x_final)","1b091617":"k_score = []\nk_range = range(1,16)\nfor k in k_range:\n    neigh = KNeighborsClassifier(n_neighbors = k).fit(x_train,y_train)\n    \n    score =  -cross_val_score(neigh, x_train, y_train, scoring ='neg_root_mean_squared_error').mean()\n    \n    k_score.append(score)\n\nScores = pd.DataFrame(k_score, columns = ['Score'])\nScores.index += 1\nScores.sort_values('Score')","0f62d5d6":"neigh = KNeighborsClassifier(n_neighbors = 8).fit(x_train,y_train)\ny_KNN = pd.DataFrame(neigh.predict(x_final), columns = ['Survived'])\ny_KNN = y_KNN.assign(PassengerId = Test_Processed.index)\ncols = y_KNN.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ny_KNN = y_KNN[cols]\nfilename = 'Titanic Predictions KNN.csv'\ny_KNN.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","67dbd967":"svm_lin = svm.SVC(kernel='linear').fit(x_train, y_train)\nprint('The average R squared score for the svm_lin is:', cross_val_score(svm_lin, x_train, y_train, scoring ='accuracy').mean())\nsvm_rbf = svm.SVC(kernel='rbf').fit(x_train, y_train)\nprint('The average R squared score for the svm_rbf is:', cross_val_score(svm_rbf, x_train, y_train, scoring ='accuracy').mean())","f3c26dcb":"gammas = [0.01,0.1, 1, 10, 100]\nfor gamma in gammas:\n    svm_rbf = svm.SVC(kernel='rbf').fit(x_train, y_train)\n    print('The average R squared score for the svm_rbf with a gamma of',gamma,' is:', cross_val_score(svm_rbf, x_train, y_train, scoring ='accuracy').mean())","adbcdfb4":"cs = [0.65,0.67]\nfor c in cs:\n    svm_rbf = svm.SVC(kernel='rbf', C=c).fit(x_train, y_train)\n    print('The average R squared score for the svm_rbf with a C of',c,' is:', cross_val_score(svm_rbf, x_train, y_train, scoring ='accuracy').mean())","8971c0e8":"svm_rbf = svm.SVC(kernel='rbf').fit(x_train, y_train)\ny_SVM = pd.DataFrame(svm_rbf.predict(x_final), columns = ['Survived'])\ny_SVM = y_SVM.assign(PassengerId = Test_Processed.index)\ncols = y_SVM.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ny_SVM = y_SVM[cols]\nfilename = 'Titanic Predictions SVM.csv'\ny_SVM.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","bc586419":"print('The average accuracy score for the SVM model is:', cross_val_score(svm_rbf, x_train, y_train, scoring ='accuracy').mean())\n","3630a974":"First thing I'm doing is searching for any NaN values.","f3cae6a8":"### Creating a K Nearest Neighbors Model\n   A KNN model will be testing and optimized to find the best K to use.","56d9f7f3":"Our Fare and Embarked columns now have no Nan values. Now we will start working towards creating an age regression to predict the missing age values. To do this we need to process some of the remaning columns. We will be creating dummy variables for Sex, Embarked, and Title.","5e4a4b8a":"The dataframe above(Age_Total_Predict) will act as our testing set. And the dataframe below(Age_Total) will act as our training set.","613e5ec8":"The predicted ages have been rounded to match the original age data. The lasso model has predicted some ages that are negative so to combat this we will be adding the RSME value of the model to any age value that is below 0. We will also be adding the testing and training dataframes back together to make the Total_Processed dataframe.","30237e73":"At a K of 8 the KNN model seems to perform the best so when we test the KNN model against others we will use a K of 8. Below is the model with a K of 8. ","e98a3ad3":"Now we can start to create a regression for age. We will test 3 types of regressions and score them using RMSE. The model with the lowest RMSE will be used for the age prediction.","d0c1792b":"Out of the Lasso, SVM, and Ridge models, the Lasso model provided the lowest RMSE so it will be used to predict the missing ages. Below we will be predicting the ages, and adding them back to the Total dataframe to fill in the NaN values.","f1043998":"# 3. Data Processing","ecc00eaa":"The original columns for Sex and Embarked have been dropped, and their respective dummy variable columns have been added. Now for Title, we will need to seperate the names from the actual titles in the Title column before we can create fdummy variables.","e14a6e34":"Now that we just have the titles of each of the passengers we can create dummy variable columns for each title. Also, since some titles overlap one another, similar titles will be added together.","969c5d46":"The only missing data points we have now are some of the ages of the passengers, so we will now be creating a regression to find those points. First thing we need to do is get rid of the survival column, since it wont be used to predict age. Next we are also getting rid of all the rows with missing age values, since those are the valus we will be predicting.","e53b55fd":"# 2. Loading and Reading Dataset","a3940641":"# 4. Model Testing\n   Now that we have filled all the missing Nan values, we can get to creating a model to predict Titanic survival. The first thing we need to do is resplit the processed dataframe back into the original training and testing sets. We will also be processing the data using standard scaler. A KNN, a SVM, a GaussianNB, a XGBC, and an AdaBoost model will all be tested and the one with the highest accuracy will be used for our final survival predictions. Additionally all prediction outputs for each model will be saved in their own csv file.","b570ad2d":"The missing values for survival are from the test set so we can disregard those. To fill in the missing values for age we construct a regression. Cabin is missing the majority of its data points, so it should be dropped. Since there is only one value missing for Fare we will just use the mode of Fare to fill in the NaNs. The 2 rows that have missing embarked will be replaced with the mode of Embarked. Although ticket has all its values and could be used to determine family survival, it will be dropped for this project.","12493d26":"# 1. Importing Required Libraries","0b861562":"### Creating a SVM Model\n   Kernel, gamma, and c will all try to be optimized.","0153cab9":"Here we combine the test and training sets together to make cleaning the data easier."}}