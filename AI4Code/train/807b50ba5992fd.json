{"cell_type":{"b6ddd9e4":"code","d5bdb1f5":"code","1fc0ee0f":"code","7cd33681":"code","4a6a68bc":"code","4d9380e1":"code","bf2688c7":"code","dd0d2dd1":"code","0f11deb4":"code","250b4234":"code","25ef88d1":"code","c4d7eef4":"code","5c782a67":"code","7d2d4a2d":"code","898b9e01":"code","d24528c1":"code","eaa28335":"code","9acf125a":"code","9509c7f2":"code","c0f9d0df":"code","465d7624":"code","625bf34c":"code","4cf54f52":"code","00e9b4bb":"code","12a107bf":"code","5966e553":"code","38e89b4a":"markdown","430bae06":"markdown","a477ba06":"markdown","322ae0eb":"markdown","8d2dda24":"markdown","5fcbd980":"markdown","8fc71f86":"markdown","8d5b8dd1":"markdown","8a6949ba":"markdown","65f9dff9":"markdown"},"source":{"b6ddd9e4":"#All Necessary Imports\nimport numpy as np\nimport os\nimport time\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import merge, Input\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n","d5bdb1f5":"#loading base model\nbase_model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n#freeze_layers(base_model)\nbase_model.summary()\n#model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n","1fc0ee0f":"# Freeze the layers except the last 4 layers\nfor layer in base_model.layers[:-3]:\n    layer.trainable = False\n# Check the trainable status of the individual layers\nfor layer in base_model.layers:\n    print(layer, layer.trainable)\nbase_model.summary()","7cd33681":"from keras.utils.vis_utils import plot_model\nplot_model(base_model, to_file='base_model_plot.png', show_shapes=True, show_layer_names=True)","4a6a68bc":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(base_model).create(prog='dot', format='svg'))","4d9380e1":"#batch_size to train\nbatch_size = 32\n# number of output classes\nnb_classes = 5\n# number of epochs to train\nnb_epoch = 10","bf2688c7":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\n \n# Create the model\nmodel = models.Sequential()\n \n# Add the vgg convolutional base model\nmodel.add(base_model)\n \n# Add new layers\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(nb_classes, activation='softmax', name ='output'))\n \n# Show a summary of the model. Check the number of trainable parameters\nmodel.summary()\n","dd0d2dd1":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='finetune_model_plot.png', show_shapes=True, show_layer_names=True)","0f11deb4":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","250b4234":"import pandas as pd\ntrainLabels = pd.read_csv(\"..\/input\/trainLabels.csv\")\ntrainLabels.head()","25ef88d1":"import seaborn as sns\nsns.countplot(\"level\",data= trainLabels)","c4d7eef4":"#from imblearn.over_sampling import SMOTE\n\n#print(\"Before OverSampling, counts of severity '0': {}\".format(sum(trainLabels.level==0)))\n#print(\"Before OverSampling, counts of severity '1': {} \".format(sum(trainLabels.level==1)))\n#print(\"Before OverSampling, counts of severity '2': {}\".format(sum(trainLabels.level==2)))\n#print(\"Before OverSampling, counts of severity '3': {} \".format(sum(trainLabels.level==3)))\n#print(\"Before OverSampling, counts of severity '4': {} \".format(sum(trainLabels.level==4)))\n\n#sm = SMOTE(random_state=2)\n#trainLables.image, trainLabels.level = sm.fit_sample(trainLabels.image, trainLabels.level.ravel())","5c782a67":"import os\n\nlisting = os.listdir(\"..\/input\") \nlisting.remove(\"trainLabels.csv\")\nnp.size(listing)","7d2d4a2d":"from PIL import Image\n\n# input image dimensions\nimg_rows, img_cols = 224, 224\n\nimmatrix = []\nimlabel = []\n\nfor file in listing:\n    base = os.path.basename(\"..\/input\/\" + file)\n    fileName = os.path.splitext(base)[0]\n    imlabel.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0])\n    im = Image.open(\"..\/input\/\" + file)   \n    img = im.resize((img_rows,img_cols))\n    rgb = img.convert('RGB')\n    immatrix.append(np.array(rgb).flatten())","898b9e01":"\nfrom sklearn.utils import shuffle\n\n#converting images & labels to numpy arrays\nimmatrix = np.asarray(immatrix)\nimlabel = np.asarray(imlabel)\n\n\ndata,Label = shuffle(immatrix,imlabel, random_state=2)\ntrain_data = [data,Label]\ntype(train_data)","d24528c1":"import matplotlib.pyplot as plt\nimport matplotlib\nfor i in range (10):\n    img=immatrix[i].reshape(img_rows,img_cols,3)\n    print('severity',imlabel[i])\n    if(imlabel[i]>0):\n        plt.imshow(img)\n    ","eaa28335":"(X, y) = (train_data[0],train_data[1])\nfrom sklearn.cross_validation import train_test_split\n\n# STEP 1: split X and y into training and testing sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n\nX_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 3)\nX_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 3)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","9acf125a":"# X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 3)\n# X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 3)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255\nX_test \/= 255\n\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')","9509c7f2":"from keras.utils import np_utils\n\n# convert class vectors to binary class matrices\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)","c0f9d0df":"from keras.preprocessing.image import ImageDataGenerator\n\n# create generators  - training data will be augmented images\nvalidationdatagenerator = ImageDataGenerator()\ntraindatagenerator = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,rotation_range=15,zoom_range=0.1 )\n\nbatchsize=8\ntrain_generator=traindatagenerator.flow(X_train, Y_train, batch_size=batchsize) \nvalidation_generator=validationdatagenerator.flow(X_test, Y_test,batch_size=batchsize)","465d7624":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])","625bf34c":"history= model.fit_generator(train_generator, steps_per_epoch=int(len(X_train)\/batchsize), \n                    epochs=10, validation_data=validation_generator, \n                    validation_steps=int(len(X_test)\/batchsize))\n","4cf54f52":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model_accuracy.png')\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('model_loss.png')","00e9b4bb":"score = model.evaluate(X_test, Y_test, verbose=0)\nprint(score)","12a107bf":"from keras.models import load_model\nmodel.save('retinopathy_predict.h5')","5966e553":"print(X_train.shape)\nprint(X_test[0].shape)\ny_pred = []\np = 100\nfor i in range (200):\n    image = X_train[i]\n    imagematrix =  np.asarray(image)\n    #img1=imagematrix.reshape(img_rows,img_cols,3)\n    #plt.imshow(img1)\n    #print(imagematrix.shape)\n    imagepredict = np.expand_dims(imagematrix, axis=0)\n    #print(imagepredict.shape)\n    y_pred1 = model.predict(imagepredict)\n    y_pred2 = [x * p for x in y_pred1]\n    y_pred3 = np.max(y_pred2)\n    y_pred.append(y_pred3)\n    print(y_pred3)\ny_pred = np.asarray(y_pred)\n    \n    \n\n","38e89b4a":"**Diabetic RetinopathyDetection**\n\nThis Notebook aims to provide a prediction kernel using Transfer learning - Fine Tuned VGG-16 architecture.\n","430bae06":"**Fine Tune : VGG-16**\n\nWe move on to add customised layers on top of our pre-loaded model for purpose of fine-tuning.\nThe following layers were added :\n* Dense Relu\n* Dropout\n* Dense Softmax","a477ba06":"**Model Selection**\n\nWe load the base model, which is a VGG-16 model pretrained on imagenet weights.\nWe then move on to freeze all the layers except the last three.","322ae0eb":"**Finding class distribution**","8d2dda24":"Loading the dataset","5fcbd980":"**Performing Image augmentation**","8fc71f86":"Before we go about pre processing data and training our loaded model, we fix the following\n* Batch Size of the data required for training\n* nb_classes -> indicates the number of output classes\n* nb_epoch -> induicates the number of iterations during training ","8d5b8dd1":"Splitting Dataset to training and test samples","8a6949ba":"**Image to Numpy Array**","65f9dff9":"The dataset is highly imbalanced with maximum data having severity 0, i.e., no Diabetic Retinopathy"}}