{"cell_type":{"75562845":"code","aa73247e":"code","ba14d40f":"code","1274735f":"code","46442c18":"code","9ddedfcd":"code","5ac68697":"code","1532310f":"code","f92da088":"code","4cff4e18":"code","742c724d":"code","f51f4bb9":"code","5ee40ab9":"code","9315e59a":"code","223ae50f":"code","c3da4710":"code","951dbc8c":"code","57f6fb3d":"code","3e420401":"code","4544b79d":"code","35095498":"code","de172718":"code","c0786336":"code","b248d934":"code","5ded030c":"code","c54b7062":"code","c616999f":"code","7ad1633e":"code","1752b189":"markdown","a478a40c":"markdown","08fe46a4":"markdown","d2c10455":"markdown","f0734e8d":"markdown","d4cbd541":"markdown","9d2d214a":"markdown","df883f2a":"markdown","1eef1c53":"markdown","e52dcaec":"markdown","ad0d647a":"markdown","13256413":"markdown"},"source":{"75562845":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc,os,sys\n\nfrom sklearn import metrics, preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.feature_selection import RFE, RFECV, VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.svm import NuSVC\n\nsns.set_style('darkgrid')\npd.options.display.float_format = '{:,.3f}'.format\n\nprint(os.listdir(\"..\/input\"))","aa73247e":"%%time\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(train.shape, test.shape)","ba14d40f":"train.head()","1274735f":"null_cnt = train.isnull().sum().sort_values()\nprint('null count:', null_cnt[null_cnt > 0])","46442c18":"c = train['target'].value_counts().to_frame()\nc.plot.bar()\nprint(c)","9ddedfcd":"fig, ax = plt.subplots(1, 3, figsize=(16,3), sharey=True)\n\ntrain['muggy-smalt-axolotl-pembus'].hist(bins=50, ax=ax[0])\ntrain['dorky-peach-sheepdog-ordinal'].hist(bins=50, ax=ax[1])\ntrain['slimy-seashell-cassowary-goose'].hist(bins=50, ax=ax[2])","5ac68697":"for col in train.columns:\n    unicos = train[col].unique().shape[0]\n    if unicos < 1000:\n        print(col, unicos)","1532310f":"train['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))\n#test['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))","f92da088":"print(train['wheezy-copper-turtle-magic'].describe())\nprint()\nprint('unique value count:', train['wheezy-copper-turtle-magic'].nunique())","4cff4e18":"numcols = train.drop(['id','target','wheezy-copper-turtle-magic'],axis=1).select_dtypes(include='number').columns.values","742c724d":"pca = PCA()\n#pca.fit(train[list(numcols) + ['wheezy-copper-turtle-magic']])\npca.fit(train[numcols])\nev_ratio = pca.explained_variance_ratio_\nev_ratio = np.hstack([0,ev_ratio.cumsum()])\n\nplt.xlabel('components')\nplt.plot(ev_ratio)\nplt.show()","f51f4bb9":"X_subset = train[train['wheezy-copper-turtle-magic'] == 0][numcols]\n\npca.fit(X_subset)\nev_ratio = pca.explained_variance_ratio_\nev_ratio = np.hstack([0,ev_ratio.cumsum()])\n\nplt.xlabel('components')\nplt.plot(ev_ratio)\nplt.show()","5ee40ab9":"from sklearn.neighbors import KNeighborsClassifier\n\nX_subset = train[train['wheezy-copper-turtle-magic'] == 0][numcols]\nY_subset = train[train['wheezy-copper-turtle-magic'] == 0]['target']\n\nfor k in range(2, 10):\n    knc = KNeighborsClassifier(n_neighbors=k)\n    knc.fit(X_subset, Y_subset)\n    score = knc.score(X_subset, Y_subset)\n    print(\"[{}] score: {:.2f}\".format(k, score))","9315e59a":"all_data = train.append(test, sort=False).reset_index(drop=True)\ndel train, test\ngc.collect()\n\nall_data.head()","223ae50f":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","c3da4710":"corr_matrix = all_data.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.95)]\ndel upper\n\ndrop_column = all_data.columns[to_drop]\nprint('drop columns:', drop_column)\n#all_data.drop(drop_column, axis=1, inplace=True)","951dbc8c":"X_train = all_data[all_data['target'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['target'].isnull()].drop(['target'], axis=1).reset_index(drop=True)\ndel all_data\ngc.collect()\n\n# drop ID_code\nX_train.drop(['id'], axis=1, inplace=True)\nX_test_ID = X_test.pop('id')\n\nY_train = X_train.pop('target')\n\nprint(X_train.shape, X_test.shape)","57f6fb3d":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nsplits = 11\n\nfor i in range(512):\n    train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n    train2_y = Y_train[X_train['wheezy-copper-turtle-magic'] == i]\n    test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5)\n    train2 = sel.fit_transform(train2)\n    test2 = sel.transform(test2)    \n    \n    skf = StratifiedKFold(n_splits=splits, random_state=42)\n    for train_index, test_index in skf.split(train2, train2_y):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_index], train2_y.iloc[train_index])\n        oof_preds[idx1[test_index]] = clf.predict_proba(train2[test_index])[:,1]\n        sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","3e420401":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","4544b79d":"len(X_train[(oof_preds > 0.3) & (oof_preds < 0.7)])","35095498":"X_train = X_train[(oof_preds <= 0.3) | (oof_preds >= 0.7)]\nY_train = Y_train[(oof_preds <= 0.3) | (oof_preds >= 0.7)]","de172718":"X_test_p1 = X_test[(sub_preds <= 0.01)].copy()\nX_test_p2 = X_test[(sub_preds >= 0.99)].copy()\nX_test_p1['target'] = 0\nX_test_p2['target'] = 1\nprint(X_test_p1.shape, X_test_p2.shape)\n\nY_train = pd.concat([Y_train, X_test_p1.pop('target'), X_test_p2.pop('target')], axis=0)\nX_train = pd.concat([X_train, X_test_p1, X_test_p2], axis=0)\nY_train.reset_index(drop=True, inplace=True)\nX_train.reset_index(drop=True, inplace=True)","c0786336":"_='''\n'''\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nfor i in range(512):\n    train_f = (X_train['wheezy-copper-turtle-magic'] == i)\n    test_f = (X_test['wheezy-copper-turtle-magic'] == i)\n    X_train_sub = X_train[train_f][numcols]\n    Y_train_sub = Y_train[train_f]\n    X_test_sub = X_test[test_f][numcols]\n\n    lda = LDA(n_components=1)\n    lda.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'lda'] = lda.transform(X_train_sub).reshape(-1)\n    X_test.loc[test_f, 'lda'] = lda.transform(X_test_sub).reshape(-1)\n    \n    knc = KNeighborsClassifier(n_neighbors=3)\n    knc.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'knc'] = knc.predict_proba(X_train_sub)[:,1]\n    X_test.loc[test_f, 'knc'] = knc.predict_proba(X_test_sub)[:,1]\n","b248d934":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nsplits = 11\n\nfor i in range(512):\n    train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n    train2_y = Y_train[X_train['wheezy-copper-turtle-magic'] == i]\n    test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5)\n    train2 = sel.fit_transform(train2)\n    test2 = sel.transform(test2)    \n    \n    skf = StratifiedKFold(n_splits=splits, random_state=42)\n    for train_index, test_index in skf.split(train2, train2_y):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_index], train2_y.iloc[train_index])\n        oof_preds[idx1[test_index]] = clf.predict_proba(train2[test_index])[:,1]\n        sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","5ded030c":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","c54b7062":"submission = pd.DataFrame({\n    'id': X_test_ID,\n    'target': sub_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","c616999f":"submission['target'].hist(bins=25, alpha=0.6)\nprint(submission['target'].sum() \/ len(submission))","7ad1633e":"submission.head()","1752b189":"### target","a478a40c":"### any feature","08fe46a4":"# Load data","d2c10455":"# Submit","f0734e8d":"### 'wheezy-copper-turtle-magic'","d4cbd541":"# Data analysis","9d2d214a":"### Add pseudo labeled data","df883f2a":"# Predict","1eef1c53":"# Feature engineering","e52dcaec":"### KNeighborsClassifier","ad0d647a":"# Prepare","13256413":"### PCA"}}