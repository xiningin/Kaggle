{"cell_type":{"e5c827e7":"code","5d56e82b":"code","904b0e51":"code","60ccc77e":"code","4949a414":"code","d6ec5993":"code","23e44cd4":"code","ce390307":"code","8d7b4462":"code","8fca8279":"code","dc7b84eb":"code","3eef0e8d":"code","3780260f":"code","4dc59d6a":"code","96c583ee":"code","d7e08e13":"code","8937180b":"code","c2509a63":"code","8ad9a7a1":"code","e88e001f":"code","57fc778b":"code","c195d569":"code","9f49c762":"code","359d9a45":"code","81f880b8":"code","58de4b2b":"code","32c814a4":"code","b8192cb3":"code","1e88c22d":"code","02949305":"code","16adf688":"code","095f7d41":"code","a37976b0":"code","25beb2e7":"code","bccd9958":"code","63265032":"code","63d38cc8":"code","2ff1f4b5":"code","c43fe998":"code","f267c589":"code","3182fab4":"code","f9ef07c3":"code","ed5ddb0d":"code","da24026d":"code","6c51012e":"code","89d581e8":"code","2d1e0158":"code","25ac9508":"code","9b51b949":"code","c32dee3d":"code","ed628759":"code","807f8b7d":"markdown","02cd3ff4":"markdown","a6278b9f":"markdown","d3e8501b":"markdown","ef09e7c5":"markdown"},"source":{"e5c827e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_squared_log_error, log_loss, roc_curve, confusion_matrix, plot_roc_curve\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom category_encoders import OrdinalEncoder\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport seaborn as sns","5d56e82b":"path = '\/kaggle\/input\/sales-prediction-of-clothes-in-e-commerce\/'\ntarget =['units_sold']","904b0e51":"df_train = pd.read_csv(path + 'train.csv', index_col=0)\n\ny_train = df_train.units_sold\nX_train = df_train.drop(target, axis=1)\n\nX_test = pd.read_csv(path + 'test.csv', index_col=0)","60ccc77e":"X_train.head(10)","4949a414":"#\u884c\u6570\u3068\u5217\u6570\u306e\u78ba\u8a8d\nprint(X_train.shape, X_test.shape)","d6ec5993":"features = X_train.columns\nfeatures","23e44cd4":"# \u6570\u5024\u5909\u6570\u3092\u62bd\u51fa\nfeatures_int = X_train.select_dtypes(include=[float, int]).columns.to_list()\nfeatures_int","ce390307":"# \u6570\u5024\u5909\u6570\u4ee5\u5916\u3092\u62bd\u51fa\nfeatures_object = X_train.select_dtypes(include=object).columns.to_list()\nfeatures_object","8d7b4462":"#X_train.describe()","8fca8279":"#X_test.describe()","dc7b84eb":"# for catg in list(features_object) :\n#     print(X_train[catg].value_counts())\n#     print('#'*50)","3eef0e8d":"# for catg in list(features_object) :\n#     print(X_test[catg].value_counts())\n#     print('#'*50)","3780260f":"# # # \u6b20\u640d\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\uff08\u8a13\u7df4\u30c7\u30fc\u30bf\uff09\n# nan_flg = X_train.isnull()\n\n# nan_df = pd.concat({'count': nan_flg.sum(), 'rate': 100*nan_flg.mean()}, axis=1)\n# nan_df.query('count > 0').sort_values('rate')","4dc59d6a":"# # # \u6b20\u640d\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\uff08\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff09\n# nan_flg = X_test.isnull()\n\n# nan_df = pd.concat({'count': nan_flg.sum(), 'rate': 100*nan_flg.mean()}, axis=1)\n# nan_df.query('count > 0').sort_values('rate')","96c583ee":"# # \u30e6\u30cb\u30fc\u30af\u6570\u306e\u78ba\u8a8d\n# stats = []\n# for col in X_train.columns:\n#     stats.append((col,\n#                   X_train[col].nunique(),\n#                   X_train[col].value_counts().index[0],\n#                   X_train[col].value_counts().values[0],\n#                   X_train[col].isnull().sum() * 100 \/ X_train.shape[0],\n#                   X_train[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n#                   X_train[col].dtype))\n# stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique values', 'Most frequent item', 'Freuquence of most frequent item', 'Percentage of missing values', 'Percentage of values in the biggest category', 'Type'])\n# stats_df.sort_values('Percentage of missing values', ascending=False)","d7e08e13":"# #\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\n# X_train.hist(bins=50, figsize=(80,60))\n# plt.show()","8937180b":"# #\u76f8\u95a2\n# fig, ax = plt.subplots(figsize=(12, 9)) \n# sns.heatmap(X_train.corr(), square=True, vmax=1, vmin=-1, center=0)","c2509a63":"# Target\u3068\u306e\u76f8\u95a2\n# df_train.corr()[target]","8ad9a7a1":"#tag\u306e\u6570\nX_train['tags_counts'] = X_train['tags'].str.count(',') + 1\nX_test['tags_counts'] = X_test['tags'].str.count(',') + 1","e88e001f":"# \u9664\u304d\u305f\u3044\u5909\u6570\u3092\u30ea\u30b9\u30c8\ndrop_val = ['merchant_title', 'merchant_id', 'title', 'tags'] ","57fc778b":"X_train.drop(drop_val, axis=1, inplace=True)\nX_test.drop(drop_val, axis=1, inplace=True)","c195d569":"#\u3000\u8a55\u4fa1\u6570\u306e\u5408\u8a08\nX_train[\"count_sum\"] = X_train[\"rating_five_count\"] + X_train[\"rating_four_count\"] + X_train[\"rating_three_count\"]  + X_train[\"rating_two_count\"] + X_train[\"rating_one_count\"] \nX_test[\"count_sum\"] = X_test[\"rating_five_count\"] + X_test[\"rating_four_count\"] + X_test[\"rating_three_count\"]  + X_test[\"rating_two_count\"] + X_test[\"rating_one_count\"] \n\n# \u8a55\u4fa1\u6570\u306e\u5272\u5408\nX_train[\"rating_five_percent\"] = X_train[\"rating_five_count\"]\/X_train[\"count_sum\"]\nX_train[\"rating_four_percent\"] = X_train[\"rating_four_count\"]\/X_train[\"count_sum\"]\nX_train[\"rating_three_percent\"] = X_train[\"rating_three_count\"]\/X_train[\"count_sum\"]\nX_train[\"rating_two_percent\"] = X_train[\"rating_two_count\"]\/X_train[\"count_sum\"]\nX_train[\"rating_one_percent\"] = X_train[\"rating_one_count\"]\/X_train[\"count_sum\"]\n\nX_test[\"rating_five_percent\"] = X_test[\"rating_five_count\"]\/X_test[\"count_sum\"]\nX_test[\"rating_four_percent\"] = X_test[\"rating_four_count\"]\/X_test[\"count_sum\"]\nX_test[\"rating_three_percent\"] = X_test[\"rating_three_count\"]\/X_test[\"count_sum\"]\nX_test[\"rating_two_percent\"] = X_test[\"rating_two_count\"]\/X_test[\"count_sum\"]\nX_test[\"rating_one_percent\"] = X_test[\"rating_one_count\"]\/X_test[\"count_sum\"]","9f49c762":"X_train[\"diff\"] = (X_train[\"retail_price\"] - X_train[\"price\"])\nX_train[\"diff_rates\"] = X_train[\"diff\"] \/X_train[\"retail_price\"]\n\nX_test[\"diff\"] = (X_test[\"retail_price\"] - X_test[\"price\"])\nX_test[\"diff_rates\"] = X_test[\"diff\"] \/X_test[\"retail_price\"]","359d9a45":"print(X_train['product_color'].value_counts(), X_train['product_variation_size_id'].value_counts())","81f880b8":"X_train[\"product_color\"] = X_train[\"product_color\"].str.upper()\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].str.upper()\n\nX_test[\"product_color\"] = X_test[\"product_color\"].str.upper()\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].str.upper()","58de4b2b":"X_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].str.lstrip()\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].str.lstrip()","32c814a4":"# SIZE\u306f\uff08.\u3068'SIZE\u2019\uff09\u3092\u524a\u9664\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('SIZE', '', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('XS.', 'XS', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('S.', 'S', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('M.', 'M', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('L.', 'L', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('-XXS', 'XXS', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('-XS', 'XS', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('-S', 'S', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('-M', 'M', regex=True)\nX_train[\"product_variation_size_id\"] = X_train[\"product_variation_size_id\"].replace('-L', 'L', regex=True)\n\n\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('SIZE', '', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('XS.', 'XS', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('S.', 'S', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('M.', 'M', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('L.', 'L', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('-XXS', 'XXS', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('-XS', 'XS', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('-S', 'S', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('-M', 'M', regex=True)\nX_test[\"product_variation_size_id\"] = X_test[\"product_variation_size_id\"].replace('-L', 'L', regex=True)","b8192cb3":"X_train['product_variation_size_id'].unique()","1e88c22d":"X_test['product_variation_size_id'].unique()","02949305":"# print(X_train['product_color'].value_counts(), X_test['product_color'].value_counts(),\n#       X_train['product_variation_size_id'].value_counts(), X_test['product_variation_size_id'].value_counts())","16adf688":"# # SIZE\u3092\u6570\u5024\u5909\u6570\u306b\u3059\u308b\uff08XS >>> XXL\u306e\u3088\u3046\u306b)\nX_train['size_num'] = -9999\nX_train.loc[X_train['product_variation_size_id'] == 'XXXS', 'size_num'] = 10\nX_train.loc[X_train['product_variation_size_id'] == 'XXS', 'size_num'] = 50\nX_train.loc[X_train['product_variation_size_id'] == 'XS', 'size_num'] = 75\nX_train.loc[X_train['product_variation_size_id'] == 'S', 'size_num'] = 100\nX_train.loc[X_train['product_variation_size_id'] == 'M', 'size_num'] = 100\nX_train.loc[X_train['product_variation_size_id'] == 'L', 'size_num'] = 100\nX_train.loc[X_train['product_variation_size_id'] == 'XL', 'size_num'] = 75\nX_train.loc[X_train['product_variation_size_id'] == 'XXL', 'size_num'] = 50\nX_train.loc[X_train['product_variation_size_id'] == 'XXXL', 'size_num'] = 10\n\nX_test['size_num'] = -9999\nX_test.loc[X_test['product_variation_size_id'] == 'XXXS', 'size_num'] = 10\nX_test.loc[X_test['product_variation_size_id'] == 'XXS', 'size_num'] = 50\nX_test.loc[X_test['product_variation_size_id'] == 'XS', 'size_num'] = 75\nX_test.loc[X_test['product_variation_size_id'] == 'S', 'size_num'] = 100\nX_test.loc[X_test['product_variation_size_id'] == 'M', 'size_num'] = 100\nX_test.loc[X_test['product_variation_size_id'] == 'L', 'size_num'] = 100\nX_test.loc[X_test['product_variation_size_id'] == 'XL', 'size_num'] = 75\nX_test.loc[X_test['product_variation_size_id'] == 'XXL', 'size_num'] = 50\nX_test.loc[X_test['product_variation_size_id'] == 'XXXL', 'size_num'] = 10","095f7d41":"# print(X_train[['product_variation_size_id', 'size_num']].head(), X_test[['product_variation_size_id', 'size_num']].head())","a37976b0":"X_train['size_price'] = X_train.groupby(\"size_num\")['price'].transform(np.median)\nX_train['size_retail_price'] = X_train.groupby(\"size_num\")['retail_price'].transform(np.median)\n\nX_test['size_price'] = X_test.groupby(\"size_num\")['price'].transform(np.median)\nX_test['size_retail_price'] = X_test.groupby(\"size_num\")['retail_price'].transform(np.median)","25beb2e7":"features_int = X_train.select_dtypes(include=[float, int]).columns.to_list()\nfeatures_object = X_train.select_dtypes(include=object).columns.to_list()","bccd9958":"#\u3000\u6570\u5024\u5909\u6570\u4ee5\u5916\u306f\u3068\u308a\u3042\u3048\u305a\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\noe = OrdinalEncoder(cols=features_object)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","63265032":"#\u5bfe\u6570\u5909\u63db\nX_train['price']   = X_train['price'].apply(np.log1p)\nX_train['retail_price']  = X_train['retail_price'].apply(np.log1p)\nX_train['rating_five_count']    = X_train['rating_five_count'].apply(np.log1p)\nX_train['rating_four_count']   = X_train['rating_four_count'].apply(np.log1p) \nX_train['rating_three_count'] = X_train['rating_three_count'].apply(np.log1p)\nX_train['rating_two_count']   = X_train['rating_two_count'].apply(np.log1p)\nX_train['rating_one_count'] = X_train['rating_one_count'].apply(np.log1p)\nX_train['count_sum'] = X_train['count_sum'].apply(np.log1p)\nX_train['size_price'] = X_train['size_price'].apply(np.log1p)\nX_train['size_retail_price'] = X_train['size_retail_price'].apply(np.log1p)\n\n\nX_test['price'] = X_test['price'].apply(np.log1p)\nX_test['retail_price']  = X_test['retail_price'].apply(np.log1p)\nX_test['rating_five_count']    = X_test['rating_five_count'].apply(np.log1p)\nX_test['rating_four_count']   = X_test['rating_four_count'].apply(np.log1p) \nX_test['rating_three_count'] = X_test['rating_three_count'].apply(np.log1p)\nX_test['rating_two_count']   = X_test['rating_two_count'].apply(np.log1p)\nX_test['rating_one_count'] = X_test['rating_one_count'].apply(np.log1p)\nX_test['count_sum'] = X_test['count_sum'].apply(np.log1p)\nX_test['size_price'] = X_test['size_price'].apply(np.log1p)\nX_test['size_retail_price'] = X_test['size_retail_price'].apply(np.log1p)","63d38cc8":"# \u6b20\u6e2c\u3092\u3068\u308a\u3042\u3048\u305a\u57cb\u3081\u308b\nX_train[features_int].fillna(-99999, inplace=True)\nX_test[features_int].fillna(-99999, inplace=True)","2ff1f4b5":"X_train['rating_five_count']    = X_train['rating_five_count'].fillna(X_train['rating_five_count'].median())\nX_train['rating_four_count']    = X_train['rating_four_count'].fillna(X_train['rating_four_count'].median())\nX_train['rating_three_count']    = X_train['rating_three_count'].fillna(X_train['rating_three_count'].median())\nX_train['rating_two_count']    = X_train['rating_two_count'].fillna(X_train['rating_two_count'].median())\nX_train['rating_one_count']    = X_train['rating_one_count'].fillna(X_train['rating_one_count'].median())\n\nX_test['rating_five_count']    = X_test['rating_five_count'].fillna(X_test['rating_five_count'].median())\nX_test['rating_four_count']    = X_test['rating_four_count'].fillna(X_test['rating_four_count'].median())\nX_test['rating_three_count']    = X_test['rating_three_count'].fillna(X_test['rating_three_count'].median())\nX_test['rating_two_count']    = X_test['rating_two_count'].fillna(X_test['rating_two_count'].median())\nX_test['rating_one_count']    = X_test['rating_one_count'].fillna(X_test['rating_one_count'].median())","c43fe998":"X_train.head()","f267c589":"X_test.head()","3182fab4":"fold=5\nscores = []\ny_pred1 = np.zeros(len(X_test)) \n\nskf = KFold(n_splits=fold, random_state=21, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n    reg = LGBMRegressor(boosting_type='gbdt', class_weight=None,\n                                importance_type='split')\n    \n    reg.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='mape', eval_set=[(X_val, y_val)])\n\n    y_pred = reg.predict(X_val)\n    scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n    \n    y_pred1 += reg.predict(X_test) ","f9ef07c3":"#\u4e88\u5b9f\u306e\u78ba\u8a8d\nplt.figure(figsize=[7,7])\nplt.scatter(y_val, y_pred, s=5)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","ed5ddb0d":"scores = np.array(scores)\nprint('Ave. CV score is %f' % scores.mean())","da24026d":"y_pred1 \/= fold\ny_pred1","6c51012e":"# XGBoost\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nclf = xgb.XGBRegressor()\n\n# \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u63a2\u7d22\nclf_cv = GridSearchCV(clf, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\nclf_cv.fit(X_train, y_train, eval_metric='mae')\nprint(clf_cv.best_params_, clf_cv.best_score_)\n\n# \u6539\u3081\u3066\u6700\u9069\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u5b66\u7fd2\nclf = xgb.XGBRegressor(**clf_cv.best_params_)\nclf.fit(X_train, y_train)\ny_pred2 = clf.predict(X_test)\ny_pred2","89d581e8":"#CatBoost\nfrom catboost import CatBoostRegressor, FeaturesData, Pool\nimport math\n\nfold=5\nscores = []\ny_pred3 = np.zeros(len(X_test)) \n\nskf = KFold(n_splits=fold, random_state=31, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    params = {\n        # \u640d\u5931\u95a2\u6570\u306b RMSE \u3092\u4f7f\u3046\n        'loss_function': 'RMSE',\n        'num_boost_round': 1000,\n        'early_stopping_rounds': 10,\n    }\n\n    cat_model = CatBoostRegressor(loss_function='RMSE', num_boost_round=200, early_stopping_rounds=10)\n    cat_model.fit(X_train_, y_train_, early_stopping_rounds=200, eval_set=[(X_val, y_val)])\n    \n    y_pred = cat_model.predict(X_val)\n    \n    scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n    \n    y_pred3 += cat_model.predict(X_test) \n    \n    # \u6700\u7d42\u7684\u306a\u30e2\u30c7\u30eb\u306e RMSE \u3092\u8a08\u7b97\u3059\u308b\n    mse = mean_squared_error(y_val, y_pred)\n    print('RMSE:', math.sqrt(mse))\n","2d1e0158":"scores = np.array(scores)\nprint('Ave. CV score is %f' % scores.mean())","25ac9508":"y_pred3 \/= fold\ny_pred3","9b51b949":"submission = pd.read_csv(path+'sample_submission.csv', index_col=0)","c32dee3d":"submission['y_pred1'] = y_pred1 \nsubmission['y_pred2'] = y_pred2 \nsubmission['y_pred3'] = y_pred3\nsubmission['units_sold_'] = submission['y_pred1'] * 0.2 + submission['y_pred2'] * 0.4 + submission['y_pred3'] * 0.4\nsubmission","ed628759":"submission.loc[submission[\"units_sold_\"] > 0, \"units_sold\"] = 100 \nsubmission.loc[submission[\"units_sold_\"] > 150, \"units_sold\"] = 200 \nsubmission.loc[submission[\"units_sold_\"] > 250, \"units_sold\"] = 500 \nsubmission.loc[submission[\"units_sold_\"] > 750, \"units_sold\"] = 1000 \nsubmission.loc[submission[\"units_sold_\"] > 2500, \"units_sold\"] = 5000\nsubmission.loc[submission[\"units_sold_\"] > 7500, \"units_sold\"] = 10000\nsubmission.loc[submission[\"units_sold_\"] > 15000, \"units_sold\"] = 20000 \n\nd_v = [\"units_sold_\", \"y_pred1\", \"y_pred2\", \"y_pred3\"]\nsubmission.drop(d_v, axis = 1, inplace=True)\n\nsubmission.to_csv('submission.csv')\nsubmission.head() # \u307e\u305a\u306f\u521d\u56desubmit\u3057\u3066\u307f\u307e\u3057\u3087\u3046\uff01\u3053\u308c\u304b\u3089\u3053\u306e\u30e2\u30c7\u30eb\u306e\u6539\u5584\u3092\u9032\u3081\u3066\u3044\u304f\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002","807f8b7d":"# \u524d\u51e6\u7406","02cd3ff4":"\u63fa\u3089\u304e\u3092\u306a\u304f\u3057\u305f\u3044(color, size)","a6278b9f":"# \u7279\u5fb4\u91cf\u306e\u78ba\u8a8d","d3e8501b":"# \u30e2\u30c7\u30ea\u30f3\u30b0","ef09e7c5":"\u7279\u5fb4\u91cf\u306e\u4f5c\u6210"}}