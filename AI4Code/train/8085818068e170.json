{"cell_type":{"1d99ae45":"code","445074a3":"code","ba47283b":"code","24f5772b":"code","efe0c2de":"code","41d99d8b":"code","c7076e75":"code","069feece":"code","c9212dcf":"code","f436082f":"code","bf012026":"code","a0a6a8a4":"code","dbb0d06d":"code","692ef146":"code","671a9d08":"code","1639ccf7":"code","f4c2a156":"code","8e7c7b6b":"code","75577c8f":"code","5fbf8efc":"code","69a9f362":"code","7177acbc":"code","8acc576e":"code","059b7558":"code","81b60f0b":"code","7593ec07":"code","bf794ea1":"code","545ee135":"code","91a32ea3":"code","b21e5529":"code","e3f3b2bd":"code","031c618a":"code","61bb68f9":"code","a22466fe":"code","bad73433":"code","46c7a886":"code","c92df201":"code","1ae3c918":"code","bed5d19a":"markdown","bf57b546":"markdown","9999977e":"markdown","81179b52":"markdown","afee4ffe":"markdown","114202bb":"markdown","13c4e9a5":"markdown","5c01a185":"markdown","98f1afe7":"markdown","0db58556":"markdown"},"source":{"1d99ae45":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sklearn\nimport lightgbm as lgb\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import *\nfrom keras.layers.wrappers import *\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import CSVLogger, EarlyStopping\n\nfrom hyperopt import tpe,hp,Trials\nfrom hyperopt.fmin import fmin\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\nrandom_seed = 20","445074a3":"keras.__version__","ba47283b":"X_train = pd.read_csv('..\/input\/traintest-data\/train_features.csv')\nX_test = pd.read_csv('..\/input\/traintest-data\/test_features.csv')\ny_train = pd.read_csv('..\/input\/traintest-data\/train_labels.csv')","24f5772b":"sub = pd.read_csv('..\/input\/traintest-data\/sample_submission.csv')","efe0c2de":"train = X_train.merge(y_train, on = 'id', how = 'left')\ntrain","41d99d8b":"#standard scaling\ntrain_scaled = train.copy()\nfor col in ['acc_x','acc_y','acc_z','gy_x','gy_y','gy_z']:\n    train_scaled[col] = (train_scaled[col]-train_scaled[col].mean()) \/ train_scaled[col].std()\ntrain_scaled","c7076e75":"label = y_train['label_desc'].unique()","069feece":"label","c9212dcf":"non_repetition_idx = train[train.label_desc.isin(['Non-Exercise', 'Device on Table', 'Tap Right Devices',\n                                                  'Side Plank Right side', 'Plank', ''])].index\ntrain['repetition'] = 1\ntrain.loc[non_repetition_idx, 'is_exercising'] = 0","f436082f":"label_list = list(y_train['label_desc'].unique())","bf012026":"fig = plt.figure(figsize = (15, 5))\nsns.countplot(y_train.label_desc, color = 'blue')\nplt.xticks(rotation = 90)","a0a6a8a4":"for col in ['acc_x', 'acc_y', 'acc_z', 'gy_x', 'gy_y', 'gy_z']:\n    fig = plt.figure(figsize = (10,5))\n    sns.distplot(X_train[col])","dbb0d06d":"by_label_time = train_scaled.groupby(['label_desc', 'time'])[['acc_x','acc_y','acc_z','gy_x','gy_y','gy_z']].mean().reset_index()","692ef146":"#\uc6b4\ub3d9 \ub3d9\uc791\ubcc4\ub85c \ub79c\ub364\ud558\uac8c \ud55c \uba85\uc744 \uc120\ud0dd\ud558\uc5ec \uc2dc\uac01\ud654\nfig = plt.figure(figsize = (15, 400))\ni = 1\nfor label in label_list:\n    df = train_scaled[train_scaled.label_desc == label]\n    ids = np.unique(df['id'])\n    rd_ids = np.random.choice(ids, 1)\n    for rd_id in rd_ids:\n        rd_df = df[df['id']==rd_id]\n        plt.subplot(61*3,1,i)\n        sns.lineplot(data = rd_df, x = 'time', y = 'acc_x', color = 'red')\n        sns.lineplot(data = rd_df, x = 'time', y = 'acc_y', color = 'pink')\n        sns.lineplot(data = rd_df, x = 'time', y = 'acc_z', color = 'purple')\n        sns.lineplot(data = rd_df, x = 'time', y = 'gy_x', color = 'blue')\n        sns.lineplot(data = rd_df, x = 'time', y = 'gy_y', color = 'skyblue')\n        sns.lineplot(data = rd_df, x = 'time', y = 'gy_z', color = 'navy')\n        plt.title(label)\n        plt.xlabel('')\n        plt.ylabel('')\n        plt.xticks([])\n        i += 1","671a9d08":"#not exercising \uc5d0 \ub300\ud574 EDA\nnon_exercising = train_scaled[(train_scaled.label_desc == 'Non-Exercise')]","1639ccf7":"fig = plt.figure(figsize=(15, 15))\nfor i in range(5):\n    rd_df = non_exercising[600*i:600*(i+1)]\n    plt.subplot(5,1,i+1)\n    sns.lineplot(data = rd_df, x = 'time', y = 'acc_x', color = 'red')\n    sns.lineplot(data = rd_df, x = 'time', y = 'acc_y', color = 'pink')\n    sns.lineplot(data = rd_df, x = 'time', y = 'acc_z', color = 'purple')\n    sns.lineplot(data = rd_df, x = 'time', y = 'gy_x', color = 'blue')\n    sns.lineplot(data = rd_df, x = 'time', y = 'gy_y', color = 'skyblue')\n    sns.lineplot(data = rd_df, x = 'time', y = 'gy_z', color = 'navy')\n    plt.title('non_exercising')\n    plt.xlabel('')\n    i += 1","f4c2a156":"train_mean = X_train.iloc[:,2:].mean(axis=0)\ntrain_std = X_train.iloc[:,2:].std(axis=0)","8e7c7b6b":"n_feats = 6\nn_ts = 600\nX_train_lstm = np.zeros((3125, n_ts, n_feats))\nfor id in range(3125):\n    df = X_train[X_train.id == id].iloc[:,2:]\n    X_train_lstm[id,:,:] = (df - train_mean)\/ train_std\n    \nX_test_lstm = np.zeros((782, n_ts, n_feats))\nfor id in range(782):\n    df = X_test[X_test.id == id+3125].iloc[:,2:]\n    X_test_lstm[id,:,:] = (df - train_mean)\/ train_std","75577c8f":"y_train_ohe = pd.get_dummies(y_train['label_desc'])","5fbf8efc":"X_tr, X_val, y_tr, y_val = train_test_split(X_train_lstm, y_train_ohe, random_state = random_seed, stratify = y_train_ohe, test_size = 200\/3125)","69a9f362":"y_tr = y_tr.reset_index().drop('index', axis=1)","7177acbc":"non_ex_idx = y_tr[y_tr['Non-Exercise']==1].index\nex_idx = y_tr[y_tr['Non-Exercise']==0].index\n\nX_tr_ex = X_tr[ex_idx,:,:]\ny_tr_ex = y_tr.iloc[ex_idx,:]","8acc576e":"X_tr_non_ex = X_tr[non_ex_idx,:,:]\ny_tr_non_ex = y_tr.iloc[non_ex_idx,:]","059b7558":"#executing data augumentation on data which are not of 'Non-Exercise'\ndef aug(data, ax, shift = 0):\n    shift_data = np.roll(data, shift, axis=ax)\n    return shift_data\n\nX_train_aug = np.zeros((1504*30, 600, n_feats))\nfor i in range(30):\n    aug_data = aug(X_tr_ex, 1, int(np.random.random()*600))\n    X_train_aug[1504*i:1504*(i+1), :,:] = aug_data\n    \ny_train_aug = np.zeros((1504*30, 61))\nfor i in range(30):\n    y_train_aug[1504*i:1504*(i+1), :] = y_tr_ex.values","81b60f0b":"X_tr_aug_cnn = np.vstack([X_tr_non_ex, X_train_aug])\ny_tr_aug_cnn = np.vstack([y_tr_non_ex.values, y_train_aug])","7593ec07":"#test data preparation for Test Time Augmentation\ndef tta(model, X_test, aug_size, classes):\n    predictions = np.zeros((X_test.shape[0], 61))\n    for s in range(X_test.shape[0]):\n        X_test_sample = X_test_lstm[s]\n        X_test_augs = np.zeros((aug_size, 600, 6))\n        for i in range(aug_size):\n            X_test_aug = aug(X_test_sample, 0, int(np.random.random()*600))\n            X_test_augs[i,:,:] = X_test_aug\n        \n        preds = model.predict(X_test_augs)\n        preds = preds.mean(axis=0)\n        predictions[s,:] = preds\n    return predictions    ","bf794ea1":"def build_cnnlstm(f1, k1, s1, f2, k2, s2, f3, k3, s3, pool_size1, pool_size2, pool_size3, n_lstm, n_dense, n_features):\n    model = keras.models.Sequential([\n        Conv1D(filters=f1, kernel_size=k1, strides=s1, padding = 'same', activation='relu', input_shape=[600, n_features]),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size1),\n        Conv1D(filters=f2, kernel_size=k2, strides=s2, padding = 'valid', activation='relu'),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size2),\n        Conv1D(filters=f3, kernel_size=k3, strides=s3, padding = 'valid', activation='relu'),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size3),\n        LSTM(n_lstm, return_sequences = True),\n        Dropout(0.5),\n        LSTM(n_lstm),\n        BatchNormalization(),\n        Dense(n_dense, activation ='relu'),\n        BatchNormalization(),\n        Dense(61, activation='softmax')\n        ])\n    optimizer_adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n    model.compile(loss='categorical_crossentropy',\n                             optimizer=optimizer_adam,\n                             metrics =['categorical_crossentropy'])\n    return model","545ee135":"#building model\ncnnlstm_model = build_cnnlstm(\n    **{'f1': 60,\n     'f2': 120,\n     'f3': 180,\n     'k1': 7,\n     'k2': 3,\n     'k3': 3,\n     'n_dense': 100,\n     'n_lstm': 120,\n     'pool_size1': 2,\n     'pool_size2': 2,\n     'pool_size3': 2,\n     's1': 2,\n     's2': 2,\n     's3': 2},\n     n_features = 6)","91a32ea3":"cnnlstm_model.summary()","b21e5529":"#model training\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('cnnlstm_model.h5', save_best_only=True)\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\nhistory = cnnlstm_model.fit(X_tr_aug_cnn, y_tr_aug_cnn, epochs=1000, \n       validation_data = (X_val, y_val), verbose=1, batch_size = 32,\n              callbacks = [checkpoint_cb, earlystopping_cb, lr_scheduler])","e3f3b2bd":"test_pred = tta(cnnlstm_model, X_test_lstm, 10, 61)","031c618a":"sub.iloc[:,1:] += test_pred","61bb68f9":"def build_cnn(f1, k1, s1, f2, k2, s2, f3, k3, s3, pool_size1, pool_size2, pool_size3, n_dense, n_features):\n    model = keras.models.Sequential([\n        Conv1D(filters=f1, kernel_size=k1, strides=s1, padding = 'same', activation='relu', input_shape=[600, n_features]),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size1),\n        Conv1D(filters=f2, kernel_size=k2, strides=s2, padding = 'valid', activation='relu'),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size2),\n        Conv1D(filters=f3, kernel_size=k3, strides=s3, padding = 'valid', activation='relu'),\n        BatchNormalization(),\n        MaxPooling1D(pool_size = pool_size3),\n        BatchNormalization(),\n        GlobalAveragePooling1D(),\n        Dense(n_dense, activation ='relu'),\n        BatchNormalization(),\n        Dense(61, activation='softmax')\n        ])\n    optimizer_adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n    model.compile(loss='categorical_crossentropy',\n                             optimizer=optimizer_adam,\n                             metrics =['categorical_crossentropy'])\n    return model","a22466fe":"#building model\ncnn_model = build_cnn(\n    **{'f1': 60,\n     'f2': 120,\n     'f3': 180,\n     'k1': 7,\n     'k2': 3,\n     'k3': 3,\n     'n_dense': 100,\n     'pool_size1': 2,\n     'pool_size2': 2,\n     'pool_size3': 2,\n     's1': 2,\n     's2': 2,\n     's3': 2},\n     n_features = n_feats)","bad73433":"#training model\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('cnn_model.h5', save_best_only=True)\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\nhistory = cnn_model.fit(X_tr_aug_cnn, y_tr_aug_cnn, epochs=1000, \n       validation_data = (X_val, y_val), verbose=1, batch_size = 64,\n              callbacks = [checkpoint_cb, earlystopping_cb, lr_scheduler])","46c7a886":"test_pred = tta(cnn_model, X_test_lstm, 10, 61)\nsub.iloc[:,1:] += test_pred","c92df201":"#Voting Ensemble on two model\nsub.iloc[:,1:] \/= 2","1ae3c918":"sub.to_csv('submission.csv')","bed5d19a":"* x\ucd95\uc740 \uc55e\ub4a4\uc758 \uc6c0\uc9c1\uc784, y\ucd95\uc740 \uc88c\uc6b0\uc758 \uc6c0\uc9c1\uc784, z\ucd95\uc740 \uc704\uc544\ub798\uc758 \uc6c0\uc9c1\uc784\uc744 \ub098\ud0c0\ub0b8\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc74c\n* \ud50c\ub7ad\ud06c \ub958\uc758 \uc6b4\ub3d9\uc740 \ud30c\ub3d9\uc774 \uac70\uc758 \uc5c6\uc74c","bf57b546":"# 2. Data Preprocessing","9999977e":"## 2. CNN with Global Avarage Pooling","81179b52":"### train on total train set and generate submission","afee4ffe":"## 1. Conv1D LSTM model","114202bb":"# 3. Modeling","13c4e9a5":"* Imbalance in target label is observed. There are too many 'Non-Exercise' data!","5c01a185":"## Data Augumentation on Training set","98f1afe7":"# 1. Explaratory Data Analysis","0db58556":"## 1.1. target label"}}