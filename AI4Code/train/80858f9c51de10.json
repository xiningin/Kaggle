{"cell_type":{"ef3169f9":"code","50284708":"code","70c725d7":"code","e295d069":"code","7c415f8a":"code","208178e9":"code","2071e092":"code","e272f588":"code","76a9de23":"code","70aaabb3":"code","ead0482c":"code","7db16799":"code","965b23c0":"code","550fdab1":"code","5e72f671":"code","0db0d284":"code","b87a50f0":"code","29c275f0":"code","8ae08a93":"code","6cc199e7":"code","9168226b":"code","16116ee1":"code","76c7ad28":"code","a4a6eca6":"code","471275be":"code","ec5ab346":"code","11560fbd":"code","e15005fe":"code","2cfcf679":"code","58533ab3":"code","796540bf":"code","620ed519":"code","0ea5c182":"code","abf16b84":"code","d6d35886":"code","21cd9447":"code","b4c92535":"code","5b234755":"code","a25172c5":"code","64754cc8":"code","a70346fa":"code","4f8035b0":"code","f3b8e694":"code","a1c2b3ec":"code","236cee47":"code","0eba1d83":"code","16e9a1d8":"code","2384c64a":"code","6b09f804":"code","d2ba5a94":"code","33c21d7f":"code","2689d430":"code","8838d038":"code","658d6aa3":"markdown","3936f194":"markdown","baaa1e31":"markdown","7da4224c":"markdown","d6342dc5":"markdown","56fe6a03":"markdown","70b618aa":"markdown","e5bcb4ab":"markdown","bb85bd76":"markdown","29a4b3be":"markdown","4978ad29":"markdown","c540b026":"markdown","93afa14b":"markdown","39690844":"markdown","81011b3c":"markdown","1b8b4055":"markdown","61c36ca6":"markdown","68c12546":"markdown","d751812d":"markdown","3528c6e6":"markdown","3002c152":"markdown","1a574e5e":"markdown","ac3a2d06":"markdown","0bdfc8e9":"markdown","a7a227e0":"markdown","68c90f54":"markdown","32e5df87":"markdown","3c6f8235":"markdown","6df326e3":"markdown","ae806a2a":"markdown","c987ad74":"markdown","d6f969dc":"markdown","a0db3d0a":"markdown","0e48ac66":"markdown","722a708b":"markdown"},"source":{"ef3169f9":"pip install odsclient","50284708":"# -- import libraries -- \nimport os\nfrom datetime import date\nfrom collections import Counter\nimport pickle\n\n# linear algebra\nimport numpy as np \n\n# data source\nfrom odsclient import get_whole_dataframe\n\n# data preprocessing\nimport pandas as pd \nfrom sklearn import model_selection\nfrom sklearn.preprocessing import StandardScaler\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# model\nimport xgboost as xgb","70c725d7":"# -- Global variables -- \nDATASET_ID = \"airbnb-listings\"\nMODEL_FILE = \"xgb_reg.pkl\"","e295d069":"df = get_whole_dataframe(DATASET_ID, platform_id='public')\n\n# -- Taking only Paris for predictions --  \nparis_airbnb_ = df.loc[df['City'] == 'Paris']","7c415f8a":"paris_airbnb_.to_csv(\"paris_airbnb\", index=False)","208178e9":"paris_airbnb = pd.read_csv(\"paris_airbnb\") ","2071e092":"print(\"shape of the dataset: \", paris_airbnb.shape)\nparis_airbnb.head(1)","e272f588":"print(\"duplicated rows: \", paris_airbnb.duplicated().sum())","76a9de23":"paris_airbnb.info()","70aaabb3":"columns_to_drop = ['Country','City', 'State', 'Host Location', 'Name', 'Host Name', 'Market', 'Zipcode', \n                   'Host About', 'Host Acceptance Rate', 'Neighbourhood Cleansed', 'Neighbourhood Group Cleansed', \n                   'Calendar Updated', 'Picture Url', 'Listing Url', 'Jurisdiction Names','Experiences Offered', \n                   'Interaction', 'Experiences Offered', 'Has Availability','License','Host Thumbnail Url', \n                   'Thumbnail Url', 'Medium Url', 'XL Picture Url','Host Picture Url', 'Access', 'Notes', \n                   'Neighborhood Overview', 'House Rules', 'Description', 'Space','Summary','Square Feet', \n                   'Host URL', 'Country Code','Host ID', 'Smart Location', 'ID', 'Scrape ID']\n\nparis_airbnb = paris_airbnb.drop(columns=columns_to_drop, axis=1)\nprint('dataset shape after dropping irrelevant columns: ', paris_airbnb.shape)","ead0482c":"# checking how many empty cells there are in each column\nnullseries = paris_airbnb.isnull().sum()\nprint(nullseries[nullseries > 0])","7db16799":"null_rows = paris_airbnb[paris_airbnb[\"Price\"].isnull()].index\n\nparis_airbnb.fillna({'Weekly Price':-1}, inplace=True)\nparis_airbnb.fillna({'Monthly Price':-1}, inplace=True)\n\nfor idx in null_rows:\n    weekly_price = paris_airbnb.loc[idx,\"Weekly Price\"]\n    monthly_price = paris_airbnb.loc[idx,\"Monthly Price\"]\n    \n    if not (weekly_price == -1):\n        paris_airbnb.loc[idx,\"Price\"] = weekly_price \/ 7\n        \n    elif not (monthly_price == -1):\n        paris_airbnb.loc[idx,\"Price\"] = monthly_price \/ 30\n\n# columns \"Weekly Price\", \"Monthly Price\" - are not needed anymore:\nparis_airbnb = paris_airbnb.drop(columns=[\"Weekly Price\", \"Monthly Price\"], axis=1)\n        \n# let's see if there are empty cells left:\nprint('\\nremaining null prices: ', paris_airbnb[\"Price\"].isnull().sum())","965b23c0":"paris_airbnb = paris_airbnb.dropna(subset=[\"Price\"])\nparis_airbnb[\"Price\"].isnull().sum()","550fdab1":"paris_airbnb[\"Price\"].describe()","5e72f671":"price_boxplot = dict(markerfacecolor='b', markeredgecolor='b', marker='.')\nparis_airbnb['Price'].plot(kind='box', xlim=(0, 2000), vert=False, flierprops=price_boxplot, figsize=(16,2));","0db0d284":"# removing zeros and outliers:\nparis_airbnb.drop(paris_airbnb[(paris_airbnb['Price'] == 0) | (paris_airbnb['Price'] > 1000)].index, axis=0, inplace=True)","b87a50f0":"paris_airbnb.fillna({'Reviews per Month':0}, inplace=True)\nparis_airbnb.fillna({'Cleaning Fee': 0.0}, inplace=True)\nparis_airbnb.fillna({'Security Deposit': 0.0}, inplace=True)","29c275f0":"paris_airbnb.fillna({'Review Scores Rating': paris_airbnb['Review Scores Rating'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Accuracy': paris_airbnb['Review Scores Accuracy'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Cleanliness': paris_airbnb['Review Scores Cleanliness'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Checkin': paris_airbnb['Review Scores Checkin'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Communication': paris_airbnb['Review Scores Communication'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Location': paris_airbnb['Review Scores Location'].mean()}, inplace=True)\nparis_airbnb.fillna({'Review Scores Value': paris_airbnb['Review Scores Value'].mean()}, inplace=True)\nparis_airbnb.fillna({'Host Response Rate': paris_airbnb['Host Response Rate'].mean()}, inplace=True)","8ae08a93":"paris_airbnb.fillna({'Host Response Time': 'Not mentioned'}, inplace=True)","6cc199e7":"today = date.today()\n\nparis_airbnb.fillna({'Host Since': today}, inplace=True)\n\n#min_date = date.min\nparis_airbnb.fillna({'First Review': 0}, inplace=True)\nparis_airbnb.fillna({'Last Review': 0}, inplace=True)","9168226b":"paris_airbnb.fillna({'Host Listings Count': 1}, inplace=True)\nparis_airbnb.fillna({'Host Total Listings Count': 1}, inplace=True)","16116ee1":"# -- Bathrooms --\n# property types in the missing bathrooms rows\ntmp = paris_airbnb[paris_airbnb['Bathrooms'].isnull()]\nprint(tmp['Property Type'].unique())","76c7ad28":"#filling empty cells with the mean value of for each property type:\n\nnull_idxs = paris_airbnb[paris_airbnb['Bathrooms'].isnull()].index\n\nfor idx in null_idxs:\n    property_type = paris_airbnb.loc[idx, 'Property Type']\n                     \n    if property_type == 'Loft' :\n        mean_bathrooms = round(paris_airbnb.Bathrooms[paris_airbnb['Property Type'] == 'Loft'].mean())\n        paris_airbnb.loc[idx, 'Bathrooms'] = mean_bathrooms\n    \n    if property_type == 'Bed & Breakfast':\n        mean_bathrooms = round(paris_airbnb.Bathrooms[paris_airbnb['Property Type'] == 'Bed & Breakfast'].mean())\n        paris_airbnb.loc[idx, 'Bathrooms'] = mean_bathrooms\n    \n    if property_type == 'House':\n        mean_bathrooms = round(paris_airbnb.Bathrooms[paris_airbnb['Property Type'] == 'House'].mean())\n        paris_airbnb.loc[idx, 'Bathrooms'] = mean_bathrooms\n        \n    if property_type == 'Apartment':\n        mean_bathrooms = round(paris_airbnb.Bathrooms[paris_airbnb['Property Type'] == 'Apartment'].mean())\n        paris_airbnb.loc[idx, 'Bathrooms'] = mean_bathrooms   \n        \n#check again:\nparis_airbnb['Bathrooms'].isnull().sum()","a4a6eca6":"# -- Beds -- \ntmp = paris_airbnb[paris_airbnb['Beds'].isnull()]\nprint(tmp['Property Type'].unique())","471275be":"null_idxs = paris_airbnb[paris_airbnb['Beds'].isnull()].index\n\nfor idx in null_idxs:\n    property_type = paris_airbnb.loc[idx, 'Property Type']\n                     \n    if property_type == 'Bed & Breakfast':\n        mean_beds = round(paris_airbnb.Beds[paris_airbnb['Property Type'] == 'Bed & Breakfast'].mean())\n        paris_airbnb.loc[idx, 'Beds'] = mean_beds\n    \n    if property_type == 'Loft' :\n        mean_beds = round(paris_airbnb.Beds[paris_airbnb['Property Type'] == 'Loft'].mean())\n        paris_airbnb.loc[idx, 'Beds'] = mean_beds\n        \n    if property_type == 'Apartment':\n        mean_beds = round(paris_airbnb.Beds[paris_airbnb['Property Type'] == 'Apartment'].mean())\n        paris_airbnb.loc[idx, 'Beds'] = mean_beds  \n    \n    if property_type == 'House':\n        mean_beds = round(paris_airbnb.Beds[paris_airbnb['Property Type'] == 'House'].mean())\n        paris_airbnb.loc[idx, 'Beds'] = mean_beds\n        \n#check again:\nparis_airbnb['Beds'].isnull().sum()","ec5ab346":"# -- Bedrooms -- \nnew = paris_airbnb[paris_airbnb['Bedrooms'].isnull()]\nprint(new['Property Type'].unique())","11560fbd":"null_idxs = paris_airbnb[paris_airbnb['Bedrooms'].isnull()].index\n\nfor idx in null_idxs:\n    property_type = paris_airbnb.loc[idx, 'Property Type']\n                     \n    if property_type == 'Loft' :\n        mean_bedrooms = round(paris_airbnb.Bedrooms[paris_airbnb['Property Type'] == 'Loft'].mean())\n        paris_airbnb.loc[idx, 'Bedrooms'] = mean_bedrooms\n        \n    if property_type == 'Apartment':\n        mean_bedrooms = round(paris_airbnb.Bedrooms[paris_airbnb['Property Type'] == 'Apartment'].mean())\n        paris_airbnb.loc[idx, 'Bedrooms'] = mean_bedrooms\n    \n    if property_type == 'Condominium':\n        mean_bedrooms = round(paris_airbnb.Bedrooms[paris_airbnb['Property Type'] == 'Condominium'].mean())\n        paris_airbnb.loc[idx, 'Bedrooms'] = mean_bedrooms  \n    \n    if property_type == 'House':\n        mean_bedrooms = round(paris_airbnb.Bedrooms[paris_airbnb['Property Type'] == 'House'].mean())\n        paris_airbnb.loc[idx, 'Bedrooms'] = mean_bedrooms\n        \n#check again:\nparis_airbnb['Bedrooms'].isnull().sum()","e15005fe":"#check that everything has been taken care of:\nnullseries = paris_airbnb.isnull().sum()\nprint(nullseries[nullseries > 0])","2cfcf679":"categorical_columns = ['Host Response Time', 'Bed Type', 'Cancellation Policy', 'Property Type', 'Room Type',\n                       'Neighbourhood', 'Street']\n\nfor col in categorical_columns:\n    items = paris_airbnb[col].unique()\n    for i in range(len(items)):\n        paris_airbnb[col] = paris_airbnb[col].replace(items[i], i)","58533ab3":"paris_airbnb.loc[paris_airbnb['Host Neighbourhood'] == paris_airbnb['Neighbourhood'], 'Host Neighbourhood'] = 1\nparis_airbnb.loc[paris_airbnb['Host Neighbourhood'] != 1, 'Host Neighbourhood'] = 0\n\nparis_airbnb[\"Host Neighbourhood\"] = paris_airbnb[\"Host Neighbourhood\"].astype('int')\n\nparis_airbnb.rename(columns = {'Host Neighbourhood': 'Airbnb_in_host_neighbourhood'}, inplace = True)","796540bf":"paris_airbnb['Host Since'] = pd.to_datetime(paris_airbnb['Host Since']).astype(int)\nparis_airbnb['First Review'] = pd.to_datetime(paris_airbnb['First Review']).astype(int)\nparis_airbnb['Last Review'] = pd.to_datetime(paris_airbnb['Last Review']).astype(int)\nparis_airbnb['Calendar last Scraped'] = pd.to_datetime(paris_airbnb['Calendar last Scraped']).astype(int)\nparis_airbnb['Last Scraped'] = pd.to_datetime(paris_airbnb['Last Scraped']).astype(int)","620ed519":"# print all amenities:\nparis_airbnb['Amenities'].head()","0ea5c182":"# make a dictionary from the amenities\namenities_counter = Counter()\n\n# delete {},\"\",\/,\\, and split them by comma\nparis_airbnb['Amenities'].astype('str').str.strip('{}')\\\n                                       .str.replace('\"', '')\\\n                                       .str.lstrip('\\\"')\\\n                                       .str.rstrip('\\\"')\\\n                                       .str.split(',')\\\n                                       .apply(amenities_counter.update)\n\n# check how many amenities we have in total\nprint(len(amenities_counter))\n\n# print the most common items\namenities_counter.most_common(10)","abf16b84":"# for the purpose of the project I'll take only the most 30 common amenities\nfor item,_ in amenities_counter.most_common(30):\n    col_name = 'amenity_' + item.replace(\" \", \"_\")\n    paris_airbnb[col_name] = paris_airbnb['Amenities'].astype('str').apply(lambda x: int(item in x))\n\nparis_airbnb.head(1) ","d6d35886":"# delete 'Amenities' column\nparis_airbnb.drop(columns=['Amenities'], axis=1, inplace=True)","21cd9447":"paris_airbnb['Host Verifications'].head()","b4c92535":"# make a dictionary from the 'Host Verifications'\nverifications_counter = Counter()\n\n# delete {},\"\",\/,\\\nparis_airbnb['Host Verifications'].astype('str').str.strip('{}')\\\n                                       .str.replace('\"', '')\\\n                                       .str.lstrip('\\\"')\\\n                                       .str.rstrip('\\\"')\\\n                                       .str.split(',')\\\n                                       .apply(verifications_counter.update)\n\n# check how many verifications we have in total\nprint(len(verifications_counter))\n\n# print the most common items\nverifications_counter.most_common(10)","5b234755":"# I'll take only the most 10 common verifications\nfor item,_ in verifications_counter.most_common(10):\n    col_name = 'host_verification' + item.replace(\" \", \"_\")\n    paris_airbnb[col_name] = paris_airbnb['Host Verifications'].astype('str').apply(lambda x: int(item in x))\n\n# delete 'Host Verifications' column\nparis_airbnb.drop(columns=['Host Verifications'], axis=1, inplace=True)\n\nprint(paris_airbnb.shape)","a25172c5":"paris_airbnb['Features'].head()","64754cc8":"# make a dictionary from the 'Features'\nfeatures_counter = Counter()\n\n# delete {},\"\",\/,\\\nparis_airbnb['Features'].astype('str').str.strip('{}')\\\n                                       .str.replace('\"', '')\\\n                                       .str.lstrip('\\\"')\\\n                                       .str.rstrip('\\\"')\\\n                                       .str.split(',')\\\n                                       .apply(features_counter.update)\n\n# check how many features we have in total\nprint(len(features_counter))\n\n# print the most common features\nfeatures_counter.most_common(5)","a70346fa":"# I'll take only the most 5 common verifications\nfor item,_ in features_counter.most_common(5):\n    col_name = item.replace(\" \", \"_\")\n    paris_airbnb[col_name] = paris_airbnb['Features'].astype('str').apply(lambda x: int(item in x))\n\n# delete 'Features' column\nparis_airbnb.drop(columns=['Features'], axis=1, inplace=True)\n\nprint(paris_airbnb.shape)","4f8035b0":"paris_airbnb.fillna({'Transit': ''}, inplace=True)\n\nparis_airbnb['Transit_Bus'] = paris_airbnb['Transit'].str.contains('Bus').astype('int')\nparis_airbnb['Transit_Metro'] = paris_airbnb['Transit'].str.contains('|'.join(['Metro','M\u00e9tro'])).astype('int')\nparis_airbnb['Transit_Train'] = paris_airbnb['Transit'].str.contains('|'.join(['Train','Ligne'])).astype('int')\n\nparis_airbnb.drop(columns=['Transit'], axis=1, inplace=True)","f3b8e694":"# (After writing that, I realized that there are already columns of latitude and longitude in this \n# dataset, have no idea why they needed another column for 'geolocation')\n\n#latitude_N_longitude = paris_airbnb['Geolocation'].astype('str').str.split(',', expand=True).astype('float64')\n#latitude_N_longitude.rename(columns={0: 'latitude', 1: 'longitude'}, inplace=True)\n#paris_airbnb = pd.concat([paris_airbnb, latitude_N_longitude],axis = 1)\n\nparis_airbnb = paris_airbnb.drop(columns=['Geolocation'], axis=1)","a1c2b3ec":"paris_airbnb.plot(kind=\"scatter\", \n                  x=\"Longitude\", y=\"Latitude\", \n                  alpha=0.4, figsize=(14,7), \n                  c=\"Price\", cmap=\"gist_heat_r\", \n                  colorbar=True, sharex=False);","236cee47":"#make sure all the columns left are really useful:\nparis_airbnb.info()","0eba1d83":"y = paris_airbnb.loc[:,'Price']\nX = paris_airbnb.drop(columns=['Price'], axis=1)\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n                                                                    test_size=0.25, \n                                                                    random_state=42)","16e9a1d8":"# -- Grid search -- \nxgb_model = xgb.XGBRegressor()\n\ngrid_param = {'n_estimators': [50, 100, 200],\n              'learning_rate': [1e-01, 5e-02, 1e-03], \n              'max_depth': [3, 5, 7],\n              'colsample_bytree': [0.5, 0.7, 1],\n              'gamma': [0.0, 0.2, 1, 10]}   # how much conservative the algoritem will be \n\nxgb_grid_search = model_selection.GridSearchCV(xgb_model, \n                                               grid_param, \n                                               cv=2,   # k-fold parameter for cross-validation \n                                               n_jobs=-1 # number of jobs in parallel, -1 means using all processors\n                                               )\n\nxgb_grid_search.fit(X_train, y_train)\n\n# -- Print the best parameters that found -- \nbest_param = xgb_grid_search.best_params_\n#print(best_param)","2384c64a":"# -- instantiate xgboost with best parameters --\nbooster = xgb.XGBRegressor(colsample_bytree=0.5, \n                           gamma=0.2,\n                           learning_rate=0.05,\n                           max_depth=5,\n                           n_estimators=200,\n                           random_state=42, \n                           alpha=10)\n\n# -- Train --\nevalset = [(X_train, y_train), (X_test,y_test)]\nresult = booster.fit(X_train, y_train,eval_metric=['rmse'] ,eval_set=evalset, verbose=0)\n\nresults = booster.evals_result()","6b09f804":"# -- plot learning curves --\nplt.plot(results['validation_0']['rmse'], label='Train')\nplt.plot(results['validation_1']['rmse'], label='Test')\nplt.legend()\nplt.show()","d2ba5a94":"_, ax = plt.subplots(1,1,figsize=(14, 7))\nxgb.plot_importance(booster=booster, ax=ax, max_num_features=20)\nplt.show()","33c21d7f":"# -- cross validation -- \nbest_param = {'objective': 'reg:squarederror',  #regression with squared loss\n              'colsample_bytree': 0.5,\n              'learning_rate': 0.05,\n              'max_depth': 5, \n              'gamma':0.2}\n\n\nxg_train = xgb.DMatrix(data=X_train, label=y_train) # help to speed up the procces and to save memory space\n\ncv_results = xgb.cv(dtrain=xg_train, \n                    params=best_param, \n                    nfold=5,\n                    num_boost_round=200, \n                    early_stopping_rounds=10, \n                    metrics=\"rmse\",  # root mean square error (for regression)\n                    as_pandas=True) \n\ncv_results.tail()","2689d430":"# -- save model --\npickle.dump(booster, open(MODEL_FILE, \"wb\"))","8838d038":"# -- load model --\nxgb_model = pickle.load(open(MODEL_FILE, \"rb\"))","658d6aa3":"**We can see that the closer the airbnb is to the city center, the higher the price.**","3936f194":"* **Features, Amenities, Host Verifications,Transit** - will take care in feature engineering.\n* **Host Neighbourhood, Neighbourhood** - (3,4)\n\n\ud83d\ude43\ud83d\ude43\ud83d\ude43\n","baaa1e31":"We can see that the features Longitude and Latitude has been given the highest importance score among all the features. (based upon this importance score, we can select the features with highest importance score and discard the redundant ones)","7da4224c":"1.  removing unnecessary features:\n    * **'Country','City', 'State', 'Jurisdiction Names', 'Host Location', 'Market', 'Zipcode','Country Code', 'Smart Location'**: since we are going to predict prices only for paris, we can take them off.\n    * prices: since most of the airbnb don't have a special price for a whole week or month, we will drop **'Weekly Price'** and **'Monthly Price'** columns, and predict only daily price. (but I'll do that after filling null values in price column) \n    * **'Name', 'ID', 'Host Name', 'Host ID', 'Calendar Updated', 'Listing Url', 'Picture Url', 'Neighbourhood Cleansed', 'Interaction', 'Host Thumbnail Url', 'Thumbnail Url', 'Medium Url', 'XL Picture Url','Host Picture Url', 'Host URL'**: columns that will not help us in prediction \n    * empty columns: **'Host Acceptance Rate', 'Neighbourhood Group Cleansed', 'Experiences Offered', 'Experiences Offered', 'Has Availability', 'License'**\n    * **'Host About'**: since I don't want to be racist in my solution I decided to delete this column, (some hosts wrote their gender, race, age ..) \n    * more columns that I'll not use for now (free-text columns): **'Access', 'Notes', 'Neighborhood Overview', 'House Rules', 'Description', 'Space', 'Summary'** \n    * **'Square Feet'**: this column is almost completly empty","d6342dc5":"**Load the dataset:** ","56fe6a03":"**Preprocessing:**","70b618aa":"* getting info on the columns: (types, 'not null' count)","e5bcb4ab":"2. **Host Verifications** (Using the same concept as Amenities)","bb85bd76":"**Train, Test Split**","29a4b3be":"4. **'Host Neighbourhood'**: label the same or not the same (1 or 0) as the Airbnb neighbourhood.\nalso fill empty cells with 0.","4978ad29":"**Feature Engineering:**","c540b026":"* **'Bathrooms', 'Bedrooms', 'Beds'**: will try to get information about the missing values from the column **'Property Type'**","93afa14b":"* columns: **'Review Scores Rating','Review Scores Accuracy','Review Scores Cleanliness','Review Scores Checkin',  \n'Review Scores Communication','Review Scores Location', 'Review Scores Value', 'Host Response Rate'**, I'll fill them with the mean value of each column, to give them the benefit of the doubt. cause maybe their clients never rated them from laziness or they are newbies.\n\n\n","39690844":"* dates-type columns: \n    * **'Host Since'**: fill with today's date \n    * **'First Review', 'Last Review'**: fill with the date '0001\/01\/01' and it will represent 'never rated'. ","81011b3c":"* **'Host Response Time'**: fill with new category: 'Not mentioned'","1b8b4055":"**let's plot the airbnb-prices according to the longitude and latitude:**","61c36ca6":"**Model**\n\n* one of the most popular ML-algorithem is **XGB** (Extreme Gradient Boosting), that based on the 'wisdom of the crowd' methodology, where collective opinion of a group of individuals is better then a single expert.\n'XGB' is using a grup of weak-learners (stamp-trees), to give predictions that more accurate then a single strong-learner algorithem.\n\n* also I'll use **grid search** that will find the best parameters to use in XGB with this specific data.\n\n* and **cross validation** to test the model's ability to predict new data that was not used in estimating. ","68c12546":"**check the data:**","d751812d":"plot feature importance based on fitted model:\n\n(this way we can see which features was matter the most in the model, by counting the number of times each feature is split across all trees in the model. it helps in feature selection and more)","3528c6e6":"5. **'Geolocation'**: using this column we can extract 2 new columns: 'latitude' and 'longitude'","3002c152":"5. dates columns: **'Host Since','Calendar last Scraped','Last Scraped','First Review','Last Review'**- convert into datetime.","1a574e5e":"we can see clearly that there is one airbnb that is not in the standard prices, since it's only one airbnb, I guess it's a typo, so I'll delete this row:","ac3a2d06":"2. filling empty cells:","0bdfc8e9":"* **'Reviews per Month', 'Cleaning Fee', 'Security Deposit'** - if not mentioned it's a zero. ","a7a227e0":"1. First let's take a look at the column **Amenities**:\n\n    Each airbnb has different amenities and we want to be able to give this information to the model by encoding this column into new columns for each amenity, with the value 1 or 0, that represent whether or not this amenity provided in this airbnb.\nThen delete the column 'Amenities' since it's not needed anymore.","68c90f54":"* check that we don't have duplicated rows in the dataset:","32e5df87":"let's analyze the missing data:\n* **'price'** - there are ~50 rows without daily prices, we will try to get the price per day from columns 'Weekly Price', 'Monthly Price', but if they are also empty - I will have to delete this row.","3c6f8235":"learning curves:","6df326e3":"4. **Transit**: this is a free-text column, i'll create 3 new columns (bus, train, metro) and fill them according to column 'transit'.","ae806a2a":"3. **Features**  (Using the same concept as Amenities)","c987ad74":"3. label categorical variables with an implied order:\n\n    it means that in this categorical features the order is important for predicting the price, for example 'Bed Type': Real Bed is much better then a couch. \n\n    columns to convert into integers: **'Host Response Time', 'Bed Type', 'Cancellation Policy', 'Property Type', 'Room Type', 'Neighbourhood', 'Street'**","d6f969dc":"loading the dataset, using the command above, takes more then an hour, so to save that time, I saved the data as csv file, in this way it takes only few minutes to load the data:","a0db3d0a":"There are still 43 rows without prices, so I will delete those rows from the database:","0e48ac66":"* **'Host Listings Count', 'Host Total Listings Count'**: for empty cells the assumption is that they have only one airbnb (the current one).","722a708b":"**Paris Airbnb - Prices Prediction - Using XGBoost**\n\nIn the following notebook, I use airbnb-data in Paris to try to predict daily price for an airbnb.\n\n**references:**\n* Data source: https:\/\/public.opendatasoft.com\/explore\/dataset\/airbnb-listings\n* https:\/\/smarie.github.io\/python-odsclient\/"}}