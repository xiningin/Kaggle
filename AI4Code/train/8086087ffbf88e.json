{"cell_type":{"4e332d02":"code","92c08506":"code","063e5862":"code","4e7f7caa":"code","cb677560":"code","610d3853":"code","d911efc0":"code","d0306fb2":"code","04b86117":"code","6ce1b4ab":"code","659b4554":"code","a7ba40e5":"code","43e67519":"code","e231072f":"code","5e3221a8":"code","08f9da3e":"code","d899aa5d":"code","fb93fcfb":"code","b6502465":"code","f392df9c":"code","d3a0e345":"code","57540fe7":"code","9893b8f6":"code","2ab3bfc1":"code","24d7b5b8":"code","773f0187":"code","1b0ba768":"code","abec1d4c":"code","a3280375":"code","33411018":"code","2fc2ff6d":"code","d1d5c8da":"code","cfb5242d":"code","e6a99386":"code","f4d60a72":"code","fc2ec6b4":"code","b7450d7d":"code","7803690a":"code","c19d9dc1":"code","94a28715":"code","b3497d46":"code","76582bf6":"code","9530701a":"code","8642e418":"code","0b6c5076":"code","3dce9766":"code","03c79d1e":"code","079f020b":"code","217751dc":"code","3913daab":"code","5f9a3d99":"code","7ca011b5":"code","42de782a":"code","3c9f3d82":"code","5631c3b6":"code","62d52766":"code","ed41310e":"code","a1faaab4":"code","d703b779":"code","e1103b3f":"code","846683ce":"code","4169823a":"code","c89ad353":"code","f4164383":"code","208a9b12":"code","89408cfc":"code","9c4df349":"code","9848c0a1":"code","921c07b6":"code","368f8890":"code","cb5ef7da":"code","87598d3a":"code","3822bfb7":"code","10916151":"code","f5a9bbad":"code","4c48750f":"code","6116abe3":"code","8c7ccfb8":"code","b314f0b8":"code","efcbcc79":"code","f8be1538":"code","5e311886":"code","aec6b625":"code","95e5b8a1":"code","a302940c":"code","c87a3ea6":"code","93ada52b":"code","12f8d28e":"code","5cce7a39":"code","9f875702":"code","e7b06f14":"code","03f915fc":"code","18384330":"code","a349b69d":"code","5128e23f":"code","07e63b0f":"code","f67a51a4":"code","b0e80eb6":"code","722eb52d":"code","5063fc89":"code","ac76a49a":"code","c96216cd":"code","923ded5d":"code","588ef203":"code","821e021c":"code","5870cd03":"code","222d8e91":"markdown","c0ea5b49":"markdown","b15a81d3":"markdown","43c09b77":"markdown","b51cdc9f":"markdown","06e331ba":"markdown","05e1d66b":"markdown","97a60d7a":"markdown","5e420aa4":"markdown","bad0ddd2":"markdown","583ebb18":"markdown","fedbba20":"markdown","1bc83e48":"markdown","59a7e81d":"markdown","d77c9d64":"markdown","1267fa35":"markdown","9fe64d3b":"markdown","600d70f0":"markdown","2f27fc53":"markdown","0cac1841":"markdown","2a579d1a":"markdown","b0b4ef05":"markdown","8da7cafb":"markdown","05f0423f":"markdown","cc381748":"markdown","17b9d5e5":"markdown","c133a075":"markdown","5000d2b6":"markdown","7a9718d4":"markdown"},"source":{"4e332d02":"%matplotlib inline\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score","92c08506":"#data_path = r\"C:\\Users\\Reljod\\Desktop\\Study Materials\\kaggle\\dataset\\titanic\"","063e5862":"train_path = \"..\/input\/train.csv\"\ntest_path = \"..\/input\/test.csv\"\nsubmission_path = \"..\/input\/gender_submission.csv\"","4e7f7caa":"train_raw = pd.read_csv(train_path)\ntest_raw = pd.read_csv(test_path)","cb677560":"train_raw.head()","610d3853":"test_raw.head()","d911efc0":"train_raw.shape","d0306fb2":"test_raw.shape","04b86117":"# Make a copy, it is always advisable to save a copy of the raw train data\ndf_train = train_raw.copy()\ndf_test = test_raw.copy()","6ce1b4ab":"dfs = [df_train, df_test]","659b4554":"df_train.columns","a7ba40e5":"for df in dfs:    \n    df.set_index('PassengerId', inplace=True)","43e67519":"df_train.head()","e231072f":"df_test.head()","5e3221a8":"# Setting the plotting style into seaborn style\nsns.set()","08f9da3e":"target = df_train[\"Survived\"]\nx_surv = target.value_counts().keys()\ny_surv = target.value_counts()\n_ = plt.bar(x_surv, y_surv, tick_label=[\"Dead\",\"Alive\"])\n_ = plt.title(\"Passengers' state\", {'fontsize': 15})\n_ = plt.ylabel(\"Count\", {'fontsize': 15}, labelpad=20)\n_ = plt.show()","d899aa5d":"pclass = df_train[\"Pclass\"]\nx_pclass = pclass.value_counts().keys()\ny_pclass = pclass.value_counts()\n_ = plt.bar(x_pclass, y_pclass, tick_label=['3: Lower', '1: Upper', '2: Middle',])\n_ = plt.title(\"Ticket Class\", {'fontsize': 15})\n_ = plt.ylabel(\"Count\", {'fontsize': 15}, labelpad=20)\n_ = plt.show()","fb93fcfb":"df_train.corr()","b6502465":"df_train.mean()","f392df9c":"df_train.mode(numeric_only=True).transpose()","d3a0e345":"df_train.std()","57540fe7":"df_train.var()","9893b8f6":"datainfo = df_train.info()\nprint(datainfo)","2ab3bfc1":"for df in dfs:\n    df.drop([\"Cabin\"], axis=1, inplace=True)","24d7b5b8":"## Checking if the cabin column is gone...\ndf_train.head()","773f0187":"print(df_train.Age.describe())\n### Looking at the description, we can see that the there's a variety of age groups looking at the std, there's an infant, \n### a senior but most of them lies between 20 to 38 years old age group. The median and the mean also doesn't differ much\n### at 28.5.","1b0ba768":"for df in dfs:\n    df[\"Age\"].fillna(df.Age.median(), inplace=True)","abec1d4c":"df_train.info()","a3280375":"print(df_train[\"Embarked\"].value_counts())\nprint(df_train[\"Embarked\"].unique())","33411018":"dfs[1][pd.isnull(dfs[1]).any(axis=1)]","2fc2ff6d":"### Removing the rows with nan-values\nfor i, df in enumerate(dfs):    \n    if i == 0:\n        df.dropna(inplace=True)\n    if i == 1:\n        df.fillna(df[\"Fare\"].median(), inplace=True)","d1d5c8da":"dfs[1].info()","cfb5242d":"## Checking again, it seems there is no null values anymore!\ndf_train.info()","e6a99386":"df_train_obj = df_train.select_dtypes(['object']).copy()\ndf_test_obj = df_test.select_dtypes(['object']).copy()","f4d60a72":"df_objects = [df_train_obj, df_test_obj]","fc2ec6b4":"for df_obj in df_objects:    \n    df_obj.drop([\"Name\", \"Ticket\"], axis=1, inplace=True)","b7450d7d":"df_train_obj.tail()","7803690a":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder","c19d9dc1":"df_ohes = []\nsex_cols = []","94a28715":"ohe = OneHotEncoder(categories='auto')\nfor df_obj in df_objects:\n    df_ohes.append(ohe.fit_transform(df_obj[\"Sex\"].values.reshape(-1,1)))\n    sex_cols.append(list(ohe.categories_[0]))","b3497d46":"df_train_ohe_sex = pd.DataFrame(df_ohes[0].toarray(), columns=sex_cols[0], dtype=np.int)\ndf_test_ohe_sex = pd.DataFrame(df_ohes[1].toarray(), columns=sex_cols[1], dtype=np.int)","76582bf6":"df_train_ohe_sex.set_index(df_train.index, inplace=True)\ndf_test_ohe_sex.set_index(df_test.index, inplace=True)","9530701a":"df_train_ohe_sex.head()","8642e418":"df_train_ohe_sex.shape","0b6c5076":"df_test_ohe_sex.head()","3dce9766":"ohe_emb = []\nemb_cols = []","03c79d1e":"for df_obj in df_objects:\n    ohe_emb.append(ohe.fit_transform(df_obj[\"Embarked\"].values.reshape(-1,1)))\n    emb_cols.append(list(ohe.categories_[0]))","079f020b":"df_train_ohe_emb = pd.DataFrame(ohe_emb[0].toarray(), columns=emb_cols[0], dtype=np.int)\ndf_test_ohe_emb = pd.DataFrame(ohe_emb[1].toarray(), columns=emb_cols[1], dtype=np.int)","217751dc":"df_train_ohe_emb.set_index(df_train.index, inplace=True)\ndf_test_ohe_emb.set_index(df_test.index, inplace=True)","3913daab":"df_train_ohe_emb.head()","5f9a3d99":"df_test_ohe_emb.head()","7ca011b5":"### Just creating a copy\ndf1 = df_train.copy()\ndf_test1 = df_test.copy()\ndfs1 = [df1, df_test1]","42de782a":"target = df1.pop(\"Survived\")","3c9f3d82":"df1.head()","5631c3b6":"### Dropping some columns\nfor dfx in dfs1:\n    dfx.drop([\"Name\", \"Sex\", \"Ticket\", \"Embarked\"], axis=1, inplace=True)","62d52766":"### Adding the one hot encoded columns\ndf_train_ohe = pd.concat([df1, df_train_ohe_sex, df_train_ohe_emb], axis=1)\ndf_test_ohe = pd.concat([df_test1, df_test_ohe_sex, df_test_ohe_emb], axis=1)","ed41310e":"df_ohe = [df_train_ohe, df_test_ohe]","a1faaab4":"df_train_ohe.head(10)","d703b779":"df_train_ohe.info()","e1103b3f":"df_test_ohe.head(10)","846683ce":"df_train_ohe.Pclass.value_counts()","4169823a":"df_test_ohe.Pclass.value_counts()","c89ad353":"ohe_pclass = []\npclass_cols = []","f4164383":"ohe = OneHotEncoder(categories=\"auto\")\nfor df_x in df_ohe:\n    ohe_pclass.append(ohe.fit_transform(df_x.Pclass.values.reshape(-1,1)))\n    #pclass_cols.append(list(ohe.categories_[0]))","208a9b12":"pclass_cols = list(ohe.categories_[0])\n#print(pclass_cols)\npclass_names = [\"upper\", \"middle\", \"lower\"]\npclass_dict = dict(zip(pclass_names, pclass_cols))\nprint(pclass_dict)\nprint(pclass_dict.keys())","89408cfc":"df_train_pclass_ohe = pd.DataFrame(ohe_pclass[0].toarray(), index=df_train.index, columns=pclass_dict.keys(), dtype=np.int)\ndf_test_pclass_ohe = pd.DataFrame(ohe_pclass[1].toarray(), index=df_test.index, columns=pclass_dict.keys(), dtype=np.int)\ndf_train_pclass_ohe.head()","9c4df349":"df_test_pclass_ohe.head()","9848c0a1":"df_train_ohe.SibSp.value_counts()","921c07b6":"df_train_ohe.Parch.value_counts()","368f8890":"df_train_ohe.Parch.head()","cb5ef7da":"new_SibSp = []\nnew_Parch = []","87598d3a":"for df_x in df_ohe:\n    new_SibSp.append(df_x.SibSp.apply(lambda x: 'NoSibSp' if x==0 else 'HasSibSp'))","3822bfb7":"for df_x in df_ohe:\n    new_Parch.append(df_x.Parch.apply(lambda x: 'NoParch' if x==0 else 'HasParch'))","10916151":"print(new_SibSp[0].value_counts())\nprint(new_SibSp[1].value_counts())","f5a9bbad":"print(new_Parch[0].value_counts())\nprint(new_Parch[1].value_counts())","4c48750f":"ohe_train_sibsp = ohe.fit_transform(new_SibSp[0].values.reshape(-1,1))\nohe_test_sibsp = ohe.fit_transform(new_SibSp[1].values.reshape(-1,1))","6116abe3":"sibsp_cols = list(ohe.categories_[0])\nprint(sibsp_cols)","8c7ccfb8":"ohe_train_parch = ohe.fit_transform(new_Parch[0].values.reshape(-1,1))\nohe_test_parch = ohe.fit_transform(new_Parch[1].values.reshape(-1,1))\nohe.categories_","b314f0b8":"parch_cols = list(ohe.categories_[0])\nprint(parch_cols)","efcbcc79":"df_train_sibsp_ohe = pd.DataFrame(ohe_train_sibsp.toarray(), columns=sibsp_cols, index=df_train.index, dtype=np.int)\ndf_test_sibsp_ohe = pd.DataFrame(ohe_test_sibsp.toarray(), columns=sibsp_cols, index=df_test.index, dtype=np.int)\ndf_train_sibsp_ohe.head(10)","f8be1538":"df_test_sibsp_ohe.head(10)","5e311886":"df_train_parch_ohe = pd.DataFrame(ohe_train_parch.toarray(), columns=parch_cols, index=df_train.index, dtype=np.int)\ndf_test_parch_ohe = pd.DataFrame(ohe_test_parch.toarray(), columns=parch_cols, index=df_test.index, dtype=np.int)\ndf_train_parch_ohe.head(10)","aec6b625":"df_test_parch_ohe.head(10)","95e5b8a1":"#for df_x in df_ohe:\n#    df_x.drop([\"Pclass\"], axis=1, inplace=True)","a302940c":"df_train_num = pd.concat([df_ohe[0], df_train_pclass_ohe, df_train_sibsp_ohe, df_train_parch_ohe], axis=1)\ndf_test_num = pd.concat([df_ohe[1], df_test_pclass_ohe, df_test_sibsp_ohe, df_test_parch_ohe], axis=1)","c87a3ea6":"df_train_num.values","93ada52b":"df_test = df_test_num.copy()","12f8d28e":"X_train, X_test, y_train, y_test = train_test_split(df_train_num, target, test_size=0.3, random_state=10)","5cce7a39":"X_train.head()","9f875702":"print(\"Train data: \", X_train.shape)\nprint(\"Train label: \", y_train.shape)\nprint(\"Test data: \", X_test.shape)\nprint(\"Test label: \", y_test.shape)","e7b06f14":"from sklearn.ensemble import RandomForestClassifier","03f915fc":"rfc = RandomForestClassifier(n_estimators=200,\n                            max_depth=4,\n                            random_state=10, min_samples_leaf=1, n_jobs=-1)","18384330":"rfc.fit(X_train, y_train)","a349b69d":"y_pred = rfc.predict(X_test)","5128e23f":"y_pred_train = rfc.predict(X_train)","07e63b0f":"acc_train = accuracy_score(y_train, y_pred_train)\nprint(\"-------------------------------------------------------------\")\nprint(\"The Accuracy of the model in the Training Data is {:.3f}%\".format(acc_train*100))\nprint(\"-------------------------------------------------------------\")","f67a51a4":"acc_test = accuracy_score(y_test, y_pred)\nprint(\"-------------------------------------------------------------\")\nprint(\"The Accuracy of the model in the Training Data is {:.3f}%\".format(acc_test*100))\nprint(\"-------------------------------------------------------------\")","b0e80eb6":"test_prediction = rfc.predict(df_test)","722eb52d":"test_prediction.shape","5063fc89":"df_submission = pd.read_csv(submission_path, index_col=\"PassengerId\")","ac76a49a":"print(len(df_submission))\nprint(len(df_submission)==len(test_prediction)) #equality","c96216cd":"acc = accuracy_score(df_submission[\"Survived\"], test_prediction)\nprint(\"The Accuracy of the model in the Unseen Test Data is {:.3f}%\".format(acc*100))","923ded5d":"rfc_submission = pd.DataFrame({'Survived':test_prediction})","588ef203":"rfc_submission.set_index(df_test.index, inplace=True)","821e021c":"rfc_submission.shape","5870cd03":"rfc_submission.to_csv(\"RandomForestClassifer_submission.csv\")","222d8e91":"### Observing the relationship of features to survivability\n - One way of doing this is by **graphing**.","c0ea5b49":"### Changing the SibSp and Parch feature\n>**SibSp**\n - We will split it into only two categories: ***NoSibSp*** and ***HasSibSp***\n \n>**Parch**\n- We will also split it into only two categories: ***NoParch*** and ***HasParch***","b15a81d3":"### Cleaning the data","43c09b77":"### Predicting using the X_train data","b51cdc9f":" - As we can see in the info, there are two missing values in the **Embarked** column and we can choose two ways. One is to just *remove the entire row where there is a missing value* and two, just *fill it with a value* that is mean value or a mode value.\n - I chose dropping the entire row because removing just two rows is insignificant.","06e331ba":"### Converting SibSp and Parch to One Hot Encoding","05e1d66b":"### Submission","97a60d7a":"### Convert Other Ordinal data to Categorical data","5e420aa4":" + **Cabin has only 204 nun-null values** and its null values can affect our prediction. It is my decision to just remove the whole feature because filling the null values might lead as to a inaccurate prediction. Furthermore, you wont be able to drop rows also because it will affect the number of training samples. Therefore, my say is to just **drop the whole column.**","bad0ddd2":"### Predicting Test Data using trained model","583ebb18":"### Converting Sex feature to One hot Encoding","fedbba20":"### Training the model","1bc83e48":"#### This is the Model's input data\n - **Train** : df_train_num\n - **Test** : df_test","59a7e81d":"### Joining the New Features into the original dataframe","d77c9d64":"## Checking data","1267fa35":"### Make sure to study the features\n\n**pclass**: A proxy for socio-economic status (SES)<br>\n> - 1 = Upper <br>\n> - 2 = Middle <br>\n> - 3 = Lower <br>\n\n**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5 <br>\n\n**sibsp**: # of siblings \/ spouses aboard the Titanic <br> \n >The dataset defines family relations in this way... <br>\n - Sibling = brother, sister, stepbrother, stepsister <br>\n - Spouse = husband, wife (mistresses and fianc\u00e9s were ignored) <br>\n\n**parch**:  # of parents \/ children aboard the Titanic <br>\n >The dataset defines family relations in this way... <br>\n - Parent = mother, father <br>\n - Child = daughter, son, stepdaughter, stepson <br>\n - Some children travelled only with a nanny, therefore parch=0 for them. <br>\n\n**ticket**:\tTicket number\t\n\n**fare**:\tPassenger fare\t\n\n**cabin**:\tCabin number\n\n**embarked**: Port of Embarkation <br>\n> - C = Cherbourg <br>\n> - Q = Queenstown <br>\n> - S = Southampton <br>","9fe64d3b":"### Converting Embarked Feature to One hot Encoding","600d70f0":"##### Comment\n\n 1. There's clearly a null value that we must get rid of\n 2. We must convert all non-numeric values to numeric before we feed it to the model\n 3. Also, we must do a slight feature engineering to this","2f27fc53":"#### Comment\n - There's a lot more lower class than any other classes\n - We can hypothesize that the high frequency of dead passengers are because of the high frequency of lower class tickets. Let's invistigate it further","0cac1841":"### Predicting using the X_test data","2a579d1a":"### Removing Null Values","b0b4ef05":"#### Comment\nThe training data contains less survived passengers <br>\nLet's see if this **imbalanced** will affect our model's prediction later.","8da7cafb":"### Comment\n> - The accuracy of the model in *train data* is **almost similar** to the accuracy of model in the *test data*.\n> - It means that our model **does not overfit nor underfit.**","05f0423f":"### Creating a Random Forest Classifier Model","cc381748":"##### Thoughts in Train Data\nThe training data only has <b>891 instances<\/b>, a miniscule number of data.<br>\nThe data also have <b>12 features<\/b>, one as a target feature.<br>\n","17b9d5e5":"##### Comment in Age column\nLooking at the description, I decided that I will just fill the nan values into the median of the age column.","c133a075":"### Splitting the dataset for training","5000d2b6":"### Converting Object data to numerical data","7a9718d4":"### Joining the Pclass, SibSp, and Parch One Hot Encoded features"}}