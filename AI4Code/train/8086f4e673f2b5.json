{"cell_type":{"79225b31":"code","afe7b20c":"code","0bb37c6b":"code","b534d0b5":"code","504d2e7b":"code","c24d5309":"code","f6af3ef3":"code","eac7cb20":"code","882d564f":"code","9b4bb879":"code","3f1f1143":"code","d52211ee":"code","beb76a17":"code","dae9191e":"code","1b4378f3":"code","e89047ae":"code","e3d21c6e":"code","68219690":"code","48d551e6":"markdown","ff03fc15":"markdown","0a1bf767":"markdown","041963f5":"markdown","c01a1fd3":"markdown","c3b6ea5f":"markdown","1184b81e":"markdown","09856ea3":"markdown","de6464c6":"markdown"},"source":{"79225b31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","afe7b20c":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras import Model, layers\nfrom keras.callbacks import *\nfrom keras.models import load_model, model_from_json","0bb37c6b":"def plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n        \n        \nplotImages(\"Random Forensics images in Gray Scale\",\"..\/input\/djpeg-forensics-dataset-in-gray-scale\/val\/QF1_70\/RF_13\/QF2_70\/**\")","b534d0b5":"from tqdm import tqdm\nfrom PIL import Image as Img\nfrom keras import Input\nfrom keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop","504d2e7b":"PIC_DIR = f'..\/input\/djpeg-forensics-dataset-in-gray-scale\/val\/QF1_70\/RF_13\/QF2_70\/'\n\nIMAGES_COUNT = 1125\n\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) \/\/ 2\n\nWIDTH = 128\nHEIGHT = 128\n\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic))","c24d5309":"#Image shape\nimages = np.array(images) \/ 255\nprint(images.shape)","f6af3ef3":"#Display first 25 images\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","eac7cb20":"LATENT_DIM = 32\nCHANNELS = 3\n\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n\n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n\n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n\n    generator = Model(gen_input, x)\n    return generator","882d564f":"def create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n\n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n\n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n\n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n\n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n\n    return discriminator","9b4bb879":"from IPython.display import Image\nfrom keras.utils.vis_utils import model_to_dot","3f1f1143":"generator = create_generator()\ngenerator.summary()","d52211ee":"Image(model_to_dot(generator, show_shapes=True).create_png())","beb76a17":"discriminator = create_discriminator()\ndiscriminator.trainable = False\ndiscriminator.summary()","dae9191e":"Image(model_to_dot(discriminator, show_shapes=True).create_png())","1b4378f3":"gan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)","e89047ae":"optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')","e3d21c6e":"gan.summary()","68219690":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, not a DS @mpwolke was Here.' )","48d551e6":"#Create a Generator","ff03fc15":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQz-_-CGiFAyvLhL8euBJ3INrad0Z1JjLjLMw&usqp=CAU)cloudstate.eu","0a1bf767":"#Define a Gan Model","041963f5":"#Display the 1st (25) Images","c01a1fd3":"#Codes by Nagesh Singh Chauhan https:\/\/www.kaggle.com\/nageshsingh\/generate-realistic-human-face-using-gan","c3b6ea5f":"#Load data. Resize images","1184b81e":"If I have an issue with the snippet below in https:\/\/www.kaggle.com\/mpwolke\/weather-gan  check input 6","09856ea3":"#Train the model: Take a look at inputs 19 and 20  https:\/\/www.kaggle.com\/mpwolke\/weather-gan\n#Requires GPU and more than 6 hours. Sorry, I'm out.","de6464c6":"#Create a Discriminator"}}