{"cell_type":{"6a9d6f3c":"code","55bd4ae4":"code","85c3c58a":"code","10449096":"code","201d6fcd":"code","970997ce":"code","db8beddd":"code","3db1bad4":"markdown","b754fc55":"markdown","a5dcd58c":"markdown","8fd5b137":"markdown","5ed22d34":"markdown","c660a360":"markdown"},"source":{"6a9d6f3c":"import os\nimport cv2\nfrom tqdm import tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.measure import label, regionprops\nship_dir = '..\/input'\ntrain_image_dir = os.path.join(ship_dir, 'train')\ntest_image_dir = os.path.join(ship_dir, 'test')\n\nfrom skimage.morphology import label\ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\n# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list, all_masks=None):\n    # Take the individual ship masks and create a single mask array for all ships\n    if all_masks is None:\n        all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)","55bd4ae4":"masks = pd.read_csv(os.path.join('..\/input\/',\n                                 'train_ship_segmentations.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks.head()","85c3c58a":"images_with_ship = masks.ImageId[masks.EncodedPixels.isnull()==False]\nimages_with_ship = np.unique(images_with_ship.values)\nprint('There are ' +str(len(images_with_ship)) + ' image files with masks')","10449096":"plotme = 1\n\nfor i in tqdm(range(0, 10)):\n    image = images_with_ship[i]\n\n    if plotme == 1:\n        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5))\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    rle_0 = masks.query('ImageId==\"'+image+'\"')['EncodedPixels']\n    mask_0 = masks_as_image(rle_0)\n    #\n    # \n    lbl_0, lbl_cnt = label(mask_0, return_num=True) \n    #props = regionprops(lbl_0)\n    img_1 = img_0.copy()\n    #print ('Image', image, lbl_cnt)\n    for i in range(1, lbl_cnt+1):\n        mask = np.array((lbl_0 == i).astype('uint8')[..., 0])\n        mask = cv2.resize(mask, (768, 768))\n        _, cnts, hierarchy = cv2.findContours((255*mask).astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        rect = cv2.minAreaRect(cnts[0])\n        if rect[1][1]>rect[1][0]:\n            angle = 90-rect[2]\n        else:\n            angle = -rect[2]\n        box = cv2.boxPoints(rect)\n        #print (box)\n        box = np.int0(box)\n\n        if plotme == 1:\n            cv2.drawContours(img_1,[box],0,(0,191,255),2)\n        x = int(rect[0][0])\n        y = int(rect[0][1])\n        #print (rect, angle, 360*((props[i-1].orientation + np.pi\/2)\/(2*np.pi)), x, y)\n        if plotme == 1:\n            cv2.circle(img_1, ( x, y ), 5, (255, 0, 0), 3)\n        print(str(rect[0][0]) + ' ' + str(rect[0][1]) + ' ' + str(rect[1][0]) + ' ' + str(rect[1][1]) + ' ' + '1' + ' ' + str(angle) + '\\n' )\n\n    if plotme == 1:\n        ax1.imshow(img_0)\n        ax1.set_title('Image')\n        ax2.set_title('Mask')\n        ax3.set_title('Image with derived bounding box')\n        ax2.imshow(mask_0[...,0], cmap='gray')\n        ax3.imshow(img_1)\n        plt.show()","201d6fcd":"plotme = 0\nrot_bboxes_dict = {}\n\nfor i in tqdm(range(0, len(images_with_ship))):\n    image = images_with_ship[i]\n\n    if plotme == 1:\n        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5))\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    rle_0 = masks.query('ImageId==\"'+image+'\"')['EncodedPixels']\n    mask_0 = masks_as_image(rle_0)\n    #\n    # \n    lbl_0, lbl_cnt = label(mask_0, return_num=True) \n    #props = regionprops(lbl_0)\n    img_1 = img_0.copy()\n    bboxes = []\n    for i in range(1, lbl_cnt+1):\n        mask = np.array((lbl_0 == i).astype('uint8')[..., 0])\n        mask = cv2.resize(mask, (768, 768))\n        _, cnts, hierarchy = cv2.findContours((255*mask).astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        rect = cv2.minAreaRect(cnts[0])\n        if rect[1][1]>rect[1][0]:\n            angle = 90-rect[2]\n        else:\n            angle = -rect[2]\n        box = cv2.boxPoints(rect)\n        #print (box)\n        box = np.int0(box)\n\n        if plotme == 1:\n            cv2.drawContours(img_1,[box],0,(0,191,255),2)\n        x = int(rect[0][0])\n        y = int(rect[0][1])\n        if plotme == 1:\n            cv2.circle(img_1, ( x, y ), 5, (255, 0, 0), 3)\n        bboxes.append([rect[0][0], rect[0][1], rect[1][0], rect[1][1], angle])\n        \n    rot_bboxes_dict[image] = bboxes.copy()\n    if plotme == 1:\n        ax1.imshow(img_0)\n        ax1.set_title('Image')\n        ax2.set_title('Mask')\n        ax3.set_title('Image with derived bounding box')\n        ax2.imshow(mask_0[...,0], cmap='gray')\n        ax3.imshow(img_1)\n        plt.show()","970997ce":"bboxes_df = pd.DataFrame([rot_bboxes_dict])\nbboxes_df = bboxes_df.transpose()\nbboxes_df.columns = ['bbox_list']\nbboxes_df.head()","db8beddd":"bboxes_df.to_csv('rotated_bbox_dictionary.csv')","3db1bad4":"In order to extract the bounding box we:\n1. Load mask as binary numpy array using Kevin's `masks_as_image`)\n\n2. Label  connected regions of this mask using `skimage.measure.label`\n\n3. Measure morphological properties of these connected regions and keep the bounding box (`skimage.measure.regionprops`). For each connected region a bounding box we will use a combination of `cv2.findContours` and `cv2.minAreaRect`. To extend the angle in the range [0, 180] we perform a simple test that finds the longest of the two sizes and adapts the angle accordingly.\n\n(*Note: I aven't fully tested the results. Any help on that would be welcome* )\n\nLet us view some  examples:","b754fc55":"Let us read the masks:","a5dcd58c":"Export these bounding boxes for everyone to use in a Pandas dataframe.","8fd5b137":"Here we calculate the rotated bounding boxes for all `29070` images and save then into a dictionary. ","5ed22d34":"and keep only those that contain ships. Keep in mind that image files can be repeated many times in the csv file. So a unique operator will give us the unique filenames that contain ships.","c660a360":"In this kernel we will slightly extend the ideas from https:\/\/www.kaggle.com\/voglinio\/from-masks-to-bounding-boxes in order to create *rotated* bounding boxes. We will define rotation angle in degrees in a range between 0 and 180, without taking account the orientation of the ship (aft and bow). This script will create a rotated bounding box `center_x, center_y, size_x, size_y, angle)`."}}