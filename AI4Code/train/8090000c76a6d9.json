{"cell_type":{"db9609e3":"code","a3c0f852":"code","9c7503ee":"code","df161dec":"code","f2228f45":"code","54e0dc7f":"code","30e34f94":"code","69861818":"code","289409be":"code","048e45ef":"code","beffc662":"code","da577b31":"code","d23a8e46":"code","d145f49a":"code","cc252f4c":"code","b9a36dac":"code","1d899e80":"code","2681ef00":"code","25bf21f4":"code","8ef2e1c7":"code","1690e109":"code","87864c39":"code","8129e2f8":"code","47d94dac":"markdown","a6088556":"markdown","adc9bb4f":"markdown","23527998":"markdown","d5a3ec3b":"markdown","f521b050":"markdown","4e70c614":"markdown","e141736b":"markdown","fc9bcfaf":"markdown","008a293b":"markdown"},"source":{"db9609e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a3c0f852":"import zipfile\n\nzf = zipfile.ZipFile('..\/input\/bosch-production-line-performance\/train_numeric.csv.zip') \ntrain_numeric_chunks = pd.read_csv(zf.open('train_numeric.csv'), iterator=True, chunksize=100000)\n\nzf = zipfile.ZipFile('..\/input\/bosch-production-line-performance\/train_categorical.csv.zip') \ntrain_categorical_chunks = pd.read_csv(zf.open('train_categorical.csv'), iterator=True, chunksize=100000, low_memory=False)\n\nzf = zipfile.ZipFile('..\/input\/bosch-production-line-performance\/train_date.csv.zip') \ntrain_date_chunks = pd.read_csv(zf.open('train_date.csv'), iterator=True, chunksize=100000)\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None","9c7503ee":"'''\ntotal_number_of_lines_numeric = 0\ntotal_number_of_lines_categorical = 0\ntotal_number_of_lines_date = 0\n\nfor chunk in train_numeric_chunks:\n    total_number_of_lines_numeric += chunk.shape[0]\n\nfor chunk in train_categorical_chunks:\n    total_number_of_lines_categorical += chunk.shape[0]\n    \nfor chunk in train_date_chunks:\n    total_number_of_lines_date += chunk.shape[0]\n    \nprint(\"Number of lines in numeric data is {}\".format(total_number_of_lines_numeric))\nprint(\"Number of lines in categorical data is {}\".format(total_number_of_lines_categorical))\nprint(\"Number of lines in date data is {}\".format(total_number_of_lines_date))\n'''\n\ntotal_number_of_lines_numeric = 1183747\ntotal_number_of_lines_categorical = 1183747\ntotal_number_of_lines_date = 1183747","df161dec":"def get_numeric_frame():\n    for data_frame in train_numeric_chunks:\n        yield data_frame\n        \ndef get_categorical_frame():\n    for data_frame in train_categorical_chunks:\n        yield data_frame\n        \ndef get_date_frame():\n    for data_frame in train_date_chunks:\n        yield data_frame\n\nget_df_numeric = get_numeric_frame()\nget_df_categorical = get_categorical_frame()\nget_df_date = get_date_frame()","f2228f45":"df_numeric = next(get_df_numeric)\ndf_categorical = next(get_df_categorical)\ndf_date = next(get_df_date)","54e0dc7f":"df_numeric.info()","30e34f94":"print(\"numeric has {} columns\".format(len(df_numeric.columns)))\n#df_numeric.columns.tolist()","69861818":"#df_numeric\ndf_numeric.head()","289409be":"df_numeric.describe()","048e45ef":"df_categorical.info()","beffc662":"print(\"categorical has {} columns\".format(len(df_categorical.columns)))\n#df_categorical.columns.tolist()","da577b31":"#df_categorical\ndf_categorical.head()","d23a8e46":"df_categorical.describe()","d145f49a":"df_date.info()","cc252f4c":"print(\"date has {} columns\".format(len(df_date.columns)))\n#df_date.columns.tolist()","b9a36dac":"#df_date\ndf_date.head()","1d899e80":"df_date.describe()","2681ef00":"fail_parts_numeric = df_numeric[df_numeric.Response == 1]\nfail_parts_categorical = df_categorical[df_numeric.Response == 1]\nfail_parts_date = df_date[df_numeric.Response == 1]\nworking_parts = df_numeric[df_numeric.Response == 0]","25bf21f4":"print(\"Number of fails in first 100000 parts: {}\".format(len(fail_parts_numeric)))\nprint(\"Number of working parts in first 100000 parts: {}\".format(len(working_parts)))\nprint(\"Fail\/Working ratio: {}\".format(len(fail_parts_numeric)\/len(working_parts)))","8ef2e1c7":"df_numeric['Response'].value_counts().sort_index().plot.bar()","1690e109":"#fail_parts_numeric\nfail_parts_numeric.head()","87864c39":"#fail_parts_categorical\nfail_parts_categorical.head()","8129e2f8":"#fail_parts_date\nfail_parts_date.head()","47d94dac":"# **DATE**","a6088556":"Total number of lines in train csv files is 1183747","adc9bb4f":"# FAIL PARTS","23527998":"2141 feature columns","d5a3ec3b":"1157 feature columns","f521b050":"Generator structure is used for loading chunks","4e70c614":"Numeric data has 970 feature columns starting with *Id* ending with *Response*","e141736b":"# **CATEGORICAL**","fc9bcfaf":"# **NUMERIC**","008a293b":"Since data is huge, it is not possible to load at once, needs to be splitted into chunks. "}}