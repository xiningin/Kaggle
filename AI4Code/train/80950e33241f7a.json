{"cell_type":{"5b87597d":"code","70aaa3a9":"code","ad9b6359":"code","4cab0506":"code","d63a9a78":"code","35478f16":"code","b13e0e4b":"code","bd784df6":"code","a476da21":"code","a34d80b1":"code","47c8f02a":"code","2d5fccf0":"code","9158b1fb":"code","cc57aa59":"code","00b808fd":"code","7559bfb7":"code","0021d9ee":"code","164ddc44":"code","ee25b21d":"code","3b962139":"code","03de4123":"markdown","ed773df1":"markdown","cfd3e067":"markdown","c896ec10":"markdown","5717b1a3":"markdown","b74c8a63":"markdown","439831bc":"markdown","2e31a3ef":"markdown","efe0c057":"markdown","77fd72e3":"markdown","077e2249":"markdown","019f8e66":"markdown","4f6dba02":"markdown","178cb932":"markdown","a6c1300c":"markdown","ccdbdb41":"markdown","8f1a44d1":"markdown","d38420aa":"markdown","5a17764a":"markdown","8fa40f23":"markdown","7584c0be":"markdown","6dce33be":"markdown","d19ac56d":"markdown","ce0361ec":"markdown","f46b8e84":"markdown"},"source":{"5b87597d":"#Libraries for Data Manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Libraries for Data Visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n\n#Libraries for Model Preparation\nfrom sklearn.model_selection import train_test_split #Splits the data into training and testing sets\n\n#Libraires for Classification Models\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.metrics import classification_report,plot_confusion_matrix #Metrics for analyzing the model performance.\n\n#Library for importing data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","70aaa3a9":"#Importing Training data\ntrain_data=pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntrain_data.info()\ntrain_data.head()","ad9b6359":"#Importing Testing data\ntest_data=pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\ntest_data.info()\ntest_data.head()","4cab0506":"#Checking columns with missing data\nMiss_Percent=100*(train_data.isnull().sum()\/len(train_data))\n\n#Sorting the data columns by their percentage in descending order\nMiss_Percent=Miss_Percent[Miss_Percent>0].sort_values(ascending=False).round(1)\n\n#Creating a dataframe to show percentage of missing data and its respective data column in table\nDataFrame=pd.DataFrame(Miss_Percent)\nmiss_percent_table=DataFrame.rename(columns={0:'% of Missing Values'})\nMissPercent=miss_percent_table\n\n#Displaying Missing Value table\nMissPercent","d63a9a78":"#Checking columns with missing data\nMiss_Percent=100*(test_data.isnull().sum()\/len(test_data))\n\n#Sorting the data columns by their percentage in descending order\nMiss_Percent=Miss_Percent[Miss_Percent>0].sort_values(ascending=False).round(1)\n\n#Creating a dataframe to show percentage of missing data and its respective data column in table\nDataFrame=pd.DataFrame(Miss_Percent)\nmiss_percent_table=DataFrame.rename(columns={0:'% of Missing Values'})\nMissPercent=miss_percent_table\n\n#Displaying Missing Value table\nMissPercent","35478f16":"train_data['song_duration_ms']=train_data['song_duration_ms'].fillna(train_data['song_duration_ms'].median())\ntrain_data['liveness']=train_data['liveness'].fillna(train_data['liveness'].median())\ntrain_data['key']=train_data['key'].fillna(train_data['key'].median())\ntrain_data['danceability']=train_data['danceability'].fillna(train_data['danceability'].median())\ntrain_data['acousticness']=train_data['acousticness'].fillna(train_data['acousticness'].median())\ntrain_data['instrumentalness']=train_data['instrumentalness'].fillna(train_data['instrumentalness'].median())\ntrain_data['energy']=train_data['energy'].fillna(train_data['energy'].median())\ntrain_data['loudness']=train_data['loudness'].fillna(train_data['loudness'].median())","b13e0e4b":"train_data.isnull().sum()","bd784df6":"test_data['song_duration_ms']=test_data['song_duration_ms'].fillna(test_data['song_duration_ms'].median())\ntest_data['liveness']=test_data['liveness'].fillna(test_data['liveness'].median())\ntest_data['key']=test_data['key'].fillna(test_data['key'].median())\ntest_data['danceability']=test_data['danceability'].fillna(test_data['danceability'].median())\ntest_data['acousticness']=test_data['acousticness'].fillna(test_data['acousticness'].median())\ntest_data['instrumentalness']=test_data['instrumentalness'].fillna(test_data['instrumentalness'].median())\ntest_data['energy']=test_data['energy'].fillna(test_data['energy'].median())\ntest_data['loudness']=test_data['loudness'].fillna(test_data['loudness'].median())","a476da21":"test_data.isnull().sum()","a34d80b1":"## **Replacing Null values with Median**\ntrain_data=train_data.drop(['id'],axis=1)","47c8f02a":"## **Replacing Null values with Median**\ntest_data=test_data.drop(['id'],axis=1)","2d5fccf0":"train_data.describe().T","9158b1fb":"sns.pairplot(train_data)","cc57aa59":"#Calculating Correlation \ncorrelation=train_data.corr()\n\n#Plotting the Correlation in HeatMap\nplt.figure(figsize=(12,12))\nCorr_Heatmap=sns.heatmap(correlation,annot=True,cmap=\"GnBu\")","00b808fd":"#Spliting into data into training and validation sets\nX = train_data.drop('song_popularity',axis=1)\ny = train_data['song_popularity']\n\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)\n\nprint(\"X_train shape: \",X_train.shape)\nprint(\"X_val shape: \",X_val.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_val shape: \",y_val.shape)","7559bfb7":"class_LR  = LogisticRegression().fit(X_train, y_train)\ny_pred_LR = class_LR.predict(X_val)\nclass_rep_LR = classification_report(y_val, y_pred_LR)\nprint('\\t\\t\\tClassification report:\\n\\n', class_rep_LR, '\\n')\nplot_confusion_matrix(class_LR, X_val, y_val) \nplt.show()","0021d9ee":"test_pred_LR = class_LR.predict(test_data)\nprint(test_pred_LR)","164ddc44":"submission=pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")\nsubmission=submission.drop(['song_popularity'],axis=1)\nsubmission.head()","ee25b21d":"submission['song_popularity'] = test_pred_LR\nsubmission","3b962139":"submission.to_csv(\"song_popularity.csv\",index=False)\nprint(\"Completed\")","03de4123":"**Importing testing data**","ed773df1":"# **Data Preparation**","cfd3e067":"**Statistics of training data**","c896ec10":"**Correlation**","5717b1a3":"# **Model building and Testing**","b74c8a63":"**Testing data**","439831bc":"## **Dropping ID as it it irrlevant to popularity of the song**","2e31a3ef":"## **Checking for Null values**","efe0c057":"# **Model Preparation**\n\nHere, the training data will be seperated into X and y, X will consist of features and Y will consist of traget variable.","77fd72e3":"**Testing Data**","077e2249":"Something is wrong with the data, as model has predicted popular songs as unpopular as well. This issue will be observed and studied, and will be addressed in the next version of the notebook.","019f8e66":"## **Importing the dataset**","4f6dba02":"**Importing training data**","178cb932":"**Testing Data**","a6c1300c":"**Training data**","ccdbdb41":"**Training Data**","8f1a44d1":"**Testing Data**","d38420aa":"# **Submission**\n\nThe submission will be done by storing the result of test file into a CSV file. the CSV file will be submitted to the competition.","5a17764a":"# **Setting up the environment**","8fa40f23":"# **Explanatory Data Analysis**","7584c0be":"**Training Data**","6dce33be":"**Training Data**","d19ac56d":"**Thank you for visiting this notebook, please upvote if you liked it**","ce0361ec":"## **Replacing Null values with Median**","f46b8e84":"**Logistic Regression**"}}