{"cell_type":{"d13f8779":"code","14fd3621":"code","dcf3029c":"code","979ed952":"code","dbb1e6c9":"code","4a688aeb":"code","0435038d":"code","3db9adc6":"code","fa967366":"code","95dc6948":"code","7686c0f7":"code","9fab605b":"code","edd98ac3":"code","9e6c1dd3":"code","4d7cd97f":"code","1d84397c":"code","98b9c6fe":"code","1e86ae8a":"code","9b161d3a":"code","5129c658":"code","ced43047":"code","53f0f532":"code","b260067e":"code","e97a336f":"code","d915678a":"code","5fb0b9dd":"markdown","c08d4f38":"markdown","f3d79ea1":"markdown","408c8b1f":"markdown","0db76e21":"markdown"},"source":{"d13f8779":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/validation\/BB-8'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","14fd3621":"!pip install imutils","dcf3029c":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten,AveragePooling2D\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.optimizers import Adam\nfrom keras.layers import Input \n#from keras.appications.inception_v3 import preprocess_input, decode_predictions\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nimport shutil\nimport cv2\nimport os\nfrom imutils import paths","979ed952":"dataset_path = '..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/train'","dbb1e6c9":"def ceildiv(a, b):\n    return -(-a \/\/ b)\n\ndef plots_from_files(imspaths, figsize=(100, 100), rows=1, titles=None, maintitle=None):\n    \"\"\"Plot the images in a grid\"\"\"\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=48)\n    for i in range(len(imspaths)):\n        if i <3 :\n            sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n            sp.axis('Off')\n            if titles is not None: sp.set_title(titles[i] , fontsize= 48)\n            img = plt.imread(imspaths[i])\n            plt.imshow(img)","4a688aeb":"BB8_images = list(paths.list_images(f\"{dataset_path}\/BB-8\"))","0435038d":"%matplotlib inline\nplots_from_files(BB8_images, rows=10)","3db9adc6":"# remove directories : '.ipynb_checkpoints' and '.ipynb_checkpoints'\nimagePaths = list(paths.list_images(dataset_path))\nfor imagePath in imagePaths:\n    # extract the class label from the filename\n    if imagePath.split(os.path.sep)[-2] == '.ipynb_checkpoints' or imagePath.split(os.path.sep)[-2] == '.ipynb_checkpoints':\n        os.remove(imagePath)","fa967366":"# grab the list of images in our dataset directory, then initialize\n# the list of data (i.e., images) and class images\n\nprint(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(dataset_path))\n\ndata = []\nlabels = []\n\n# loop over the image paths\nfor imagePath in imagePaths:\n    # extract the class label from the filename    \n    label = imagePath.split(os.path.sep)[-2]\n    # load the image, swap color channels, and resize it to be a fixed       \n    image = cv2.imread(imagePath)\n    #\u8f49\u70baRGB\u683c\u5f0f\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #resize # 224x224 pixels while ignoring aspect ratio\n    image = cv2.resize(image, (299, 299))\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append(label)\n# convert the data and labels to NumPy arrays while scaling the pixel\n# intensities to the range [0, 1]\nprint(labels)\n#normalize\u52300-1\u4e4b\u524d\u7684\u503c\uff0c\u53ef\u8a66\u8a66\u4e0d\u8981\u9664\ndata = np.array(data) \/ 255.0\nlabels = np.array(labels)","95dc6948":"from sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder","7686c0f7":"print(labels.shape)","9fab605b":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\n#\u82e5\u5206\u985e\u53ea\u67092\u985e\u6642\n#labels = to_categorical(labels)\n#lb.classes_","edd98ac3":"print(labels)","9e6c1dd3":"# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=5)\n# initialize the training data augmentation object\ntrainAug = ImageDataGenerator(rotation_range=15,width_shift_range=1.0,height_shift_range=1, fill_mode=\"nearest\")\nlb.classes_","4d7cd97f":"# initialize the initial learning rate, number of epochs to train for,and batch size\n#\u53c3\u8003\u4f86\u6e90\n#https:\/\/www.itread01.com\/content\/1548936569.html\n#https:\/\/codertw.com\/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80\/557816\/#outline__1\n\nINIT_LR = 1e-3\n#INIT_LR = 0.01\n#1\u500bepoch\u7b49\u65bc\u4f7f\u7528\u8a13\u7df4\u96c6\u4e2d\u7684\u5168\u90e8\u6a23\u672c\u8a13\u7df4\u4e00\u6b21\nEPOCHS = 30 \n#batch_size\u662f\u4e00\u6b21\u8a13\u7df4\u7684\u6a23\u672c\u6578\u76ee\uff0c\u5f71\u97ff\u6a21\u578b\u7684\u512a\u5316\u7a0b\u5ea6\u548c\u901f\u5ea6\u3002\n#batchsize\u7684\u6b63\u78ba\u9078\u64c7\u662f\u70ba\u4e86\u5728\u8a18\u61b6\u9ad4\u6548\u7387\u548c\u8a18\u61b6\u9ad4\u5bb9\u91cf\u4e4b\u9593\u5c0b\u627e\u6700\u4f73\u5e73\u8861\u3002\nBS = 3 \nfrom keras.layers import Input ","1d84397c":"# load the VGG16 network, ensuring the head FC layer sets are left off\nmodel= \"\"\nbaseModel = \"\"\nbaseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(2, 2))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(299, activation=\"relu\")(headModel) # the same with resize\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(5, activation=\"softmax\")(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n    layer.trainable = False\n    \nmodel.summary()","98b9c6fe":"# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n# train the head of the network\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) \/\/ BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ BS,\n    epochs=EPOCHS)","1e86ae8a":"import numpy as np\ndef mean_squared_error(y,t):\n    return 0.5*np.sum((y-t)**2)\n#\u5047\u8a2d\u6b63\u78ba\u7b54\u6848\u70ba2\nt=[0,0,1,0,0,0,0,0,0,0]\n\n#example 1\n#\u75762\u7684\u6a5f\u7387\u6700\u9ad8\u6642\ny=[0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\nprint(mean_squared_error(np.array(y),np.array(t)))\n\n#example 2\n#\u75767\u7684\u6a5f\u7387\u6700\u9ad8\u6642\ny=[0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\nprint(mean_squared_error(np.array(y),np.array(t)))","9b161d3a":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n#plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n#plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on Who is she\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","5129c658":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))","ced43047":"# compute the confusion matrix and and use it to derive the raw\n# accuracy, sensitivity, and specificity\ncm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]+ cm[2, 2]+ cm[3, 3]+ cm[4, 4]) \/ total\n#sensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\n#specificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n# show the confusion matrix, accuracy, sensitivity, and specificity\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\n#print(\"sensitivity: {:.4f}\".format(sensitivity))\n#print(\"specificity: {:.4f}\".format(specificity))","53f0f532":"def loadimg(imagfile):\n    # 224x224 pixels while ignoring aspect ratio\n    image = cv2.imread(imagfile)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (299, 299)) \n    return (np.array(image)\/255).reshape(1,299,299,3)","b260067e":"\n\ntest_d= loadimg(\"..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/validation\/r2d2\/ia_10114.jpg\")\n#test_d= loadimg(\"\/kaggle\/input\/covid19\/covid19\/test_image\/cov.jpg\")\npredIdxs = model.predict(test_d, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\n#predIdxs = np.argmax(predIdxs, axis=1)\nprint(predIdxs)\npredIdxs = np.argmax(predIdxs)\nif predIdxs == 2 :\n    print('r2')\nelif predIdxs == 3 :\n    print('stormtrooper')\nelif predIdxs == 4 :\n    print('vadar')\nelif predIdxs == 0 :\n    print('BB-8')\nelif predIdxs == 1 :\n    print('C-3PO')\n             \nimport matplotlib.pyplot as plt\n\nimg = plt.imread(\"..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/validation\/r2d2\/ia_10114.jpg\")\nplt.imshow(img)\n","e97a336f":"\n\ntest_d= loadimg(\"..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/validation\/BB-8\/BB-8_182.jpg\")\n#test_d= loadimg(\"\/kaggle\/input\/covid19\/covid19\/test_image\/cov.jpg\")\npredIdxs = model.predict(test_d, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\n#predIdxs = np.argmax(predIdxs, axis=1)\nprint(predIdxs)\npredIdxs = np.argmax(predIdxs)\nif predIdxs == 2 :\n    print('r2')\nelif predIdxs == 3 :\n    print('stormtrooper')\nelif predIdxs == 4 :\n    print('vadar')\nelif predIdxs == 0 :\n    print('BB-8')\nelif predIdxs == 1 :\n    print('C-3PO')\n\n             \nimport matplotlib.pyplot as plt\n\nimg = plt.imread(\"..\/input\/starwars-images\/star-wars-images\/star_wars\/filtered\/validation\/BB-8\/BB-8_182.jpg\")\nplt.imshow(img)\n","d915678a":"model.save(\"MayTheForceBeWithYou.h5\")","5fb0b9dd":"# **May the force be with you.**\n![](https:\/\/i.imgur.com\/8As75xM.jpg)\n\n\n\n\n## **CNN \u5be6\u6230\u7df4\u7fd2\uff0c\u9019\u6b21\u4f86\u6311\u6230\u661f\u969b\u5927\u6230\u89d2\u8272\u8fa8\u8b58^^**\n\n\u984c\u76ee\u985e\u578b - \u5206\u985e\u554f\u984c\uff1a<br>\nclass \u7e3d\u5171\u6709 5 \u4f4d\u5076\u50cf\uff0c\u5206\u5225\u70ba class 0, 1, 2, 3, 4\uff0c\u5176\u4e2d<br>\n\nclass 0 = BB-8<br>\nclass 1 = C-3PO<br>\nclass 3 = R2D2<br>\nclass 2 = Stormtrooper<br>\nclass 4 = DarthVader<br>\n","c08d4f38":"train loss \u4e0d\u65ad\u4e0b\u964d\uff0ctest loss\u4e0d\u65ad\u4e0b\u964d\uff0c\u8bf4\u660e\u7f51\u7edc\u4ecd\u5728\u5b66\u4e60;\n\ntrain loss \u4e0d\u65ad\u4e0b\u964d\uff0ctest loss\u8d8b\u4e8e\u4e0d\u53d8\uff0c\u8bf4\u660e\u7f51\u7edc\u8fc7\u62df\u5408;\n\ntrain loss \u8d8b\u4e8e\u4e0d\u53d8\uff0ctest loss\u4e0d\u65ad\u4e0b\u964d\uff0c\u8bf4\u660e\u6570\u636e\u96c6100%\u6709\u95ee\u9898;\n\ntrain loss \u8d8b\u4e8e\u4e0d\u53d8\uff0ctest loss\u8d8b\u4e8e\u4e0d\u53d8\uff0c\u8bf4\u660e\u5b66\u4e60\u9047\u5230\u74f6\u9888\uff0c\u9700\u8981\u51cf\u5c0f\u5b66\u4e60\u7387\u6216\u6279\u91cf\u6570\u76ee;\n\ntrain loss \u4e0d\u65ad\u4e0a\u5347\uff0ctest loss\u4e0d\u65ad\u4e0a\u5347\uff0c\u8bf4\u660e\u7f51\u7edc\u7ed3\u6784\u8bbe\u8ba1\u4e0d\u5f53\uff0c\u8bad\u7ec3\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0d\u5f53\uff0c\u6570\u636e\u96c6\u7ecf\u8fc7\u6e05\u6d17\u7b49\u95ee\u9898\u3002\n\n\u539f\u6587\u94fe\u63a5\uff1ahttps:\/\/blog.csdn.net\/SMF0504\/java\/article\/details\/71698354","f3d79ea1":"# \u95dc\u65bc VGG\n\n\u7531\u65bc\uff0c\u9019\u4e9b\u6a21\u578b\u4f7f\u7528\u4e86\u5927\u91cf\u8cc7\u6599\u4f5c\u8a13\u7df4\uff0c\u4e14\u4f7f\u7528\u975e\u5e38\u591a\u5c64\u7684\u8655\u7406\uff0c\u4f8b\u5982 VGG \u4f7f\u7528ImageNet 100\u842c\u5f35\u5716\u7247\uff0c\u5171 1000 \u7a2e\u985e\u5225\uff0c\u5e7e\u4e4e\u6db5\u84cb\u65e5\u5e38\u751f\u6d3b\u770b\u5230\u7684\u4e8b\u7269\uff0c\u4f8b\u5982\u52d5\u7269\u3001\u4ea4\u901a\u5de5\u5177...\u7b49\uff0c\u8a13\u7df4\u51fa\u4f86\u7684\u6a21\u578b\uff0c\u5c31\u8b8a\u6210\u4e00\u7a2e\u300e\u901a\u7528\u89e3\u6c7a\u65b9\u6848\u300f(Generic Solution)\uff0c\u5982\u679c\u8981\u8fa8\u8b58\u7167\u7247\u5167\u4e8b\u7269\u5c6c\u65bc\u90191000\u985e\uff0c\u4f8b\u5982\u8c93\u3001\u72d7\u3001\u5927\u8c61\u7b49\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u62ffVGG\u6a21\u578b\u4f86\u7528\u4e86\uff0c\u53cd\u4e4b\uff0c\u5982\u679c\uff0c\u8981\u8fa8\u8b58\u7684\u5167\u5bb9\u4e0d\u5c6c\u65bc1000\u985e\uff0c\u4e5f\u53ef\u4ee5\u63db\u6389input\u5377\u7a4d\u5c64\uff0c\u53ea\u5229\u7528\u4e2d\u9593\u5c64\u8403\u53d6\u7684\u7279\u5fb5\uff0c\u9019\u7a2e\u80fd\u529b\u7a31\u70ba\u300eTransfer Learning\u300f\u3002","408c8b1f":"# the meaning of loss function\n\u5728\u795e\u7d93\u7db2\u8def\u5b78\u7fd2\u904e\u7a0b\u4e2d\uff0c\u8861\u91cf\u5b78\u7fd2\u597d\u58de\u7684\u6307\u6a19\uff0c\u6700\u5e38\u898b\u6709mean squared error\u8207cross entropy error","0db76e21":"## This is for VGG16 transform learning\n1. 2012\u5e74\u51a0\u8ecd AlexNet \u932f\u8aa4\u7387\u6bd4\u524d\u4e00\u5e74\u6e1b\u5c11\u8d85\u904e10%\uff0c\u4e14\u9996\u5ea6\u5f15\u7528 Dropout \u5c64\u3002\n2.  2014\u5e74\u4e9e\u8ecd VGGNet \u627f\u8972 AlexNet \u601d\u8def\uff0c\u5efa\u7acb\u66f4\u591a\u5c64\u7684\u6a21\u578b\uff0c\u9054\u5230 16\u53ca19 \u500b\u96b1\u85cf\u5c64\u3002\n3. 2014\u5e74\u5716\u50cf\u5206\u985e\u51a0\u8ecd GoogNet & Inception \u540c\u6642\u4f7f\u7528\u591a\u7a2e\u4e0d\u540c\u5927\u5c0f\u7684Kernel\uff0c\u8b93\u7cfb\u7d71\u6c7a\u5b9a\u6700\u4f73\u7684Kernel\u3002Inception \u5f15\u5165 Batch Normalization \u7b49\u89c0\u5ff5\uff0c\u53c3\u898bBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\u3002\n4. 2015\u5e74\u51a0\u8ecd ResNets \u767c\u73fe 20 \u5c64\u4ee5\u4e0a\u7684\u6a21\u578b\u524d\u9762\u5e7e\u5c64\u6703\u767c\u751f\u512a\u5316\u9000\u5316(degradation)\u7684\u72c0\u6cc1\uff0c\u56e0\u800c\u63d0\u51fa\u4ee5\u300e\u6b98\u5dee\u300f(Residual)\u89e3\u6c7a\u554f\u984c\uff0c\u53c3\u898bDeep Residual Learning for Image Recognition\u3002\n\n## Keras\u628a\u5b83\u5011\u90fd\u6536\u9304\u9032\u6846\u67b6\u5167\uff0c\u7a31\u70baKeras Applications \uff0c\u5305\u62ec\u4e0b\u5217\u5e7e\u9805\uff1a\n\n* Xception\n* VGG16\n* VGG19\n* ResNet50\n* InceptionV3\n* InceptionResNetV2\n* MobileNet\n\n## \u5b83\u5011\u7684\u6a21\u578b\u7d50\u69cb\u8cc7\u8a0a\u5982\u4e0b\u8868\uff1a\n![](https:\/\/i.imgur.com\/wgQ8u73.png)\n\n\u8a3b\uff1a\n\n* Top-1\u8868\u793a\u53ea\u9810\u6e2c\u4e00\u6b21\u4e14\u6b63\u78ba\u7684\u6a5f\u7387\u3002\n* Top-5\u8868\u793a\u9810\u6e2c\u4e94\u6b21\u53ea\u8981\u4e00\u6b21\u731c\u5c0d\u5c31\u7b97\u6b63\u78ba\u7684\u6a5f\u7387\u3002\n* Size\uff1a\u8a18\u61b6\u9ad4\u7684\u6700\u9ad8\u4f54\u64da\u91cf\u3002\n* Parameters\uff1a\u53c3\u6578\u7684\u6578\u91cf\uff0c\u6108\u591a\u5c31\u9808\u8a08\u7b97\u6108\u4e45\u3002\n* Depth\uff1afilters\u7684\u6578\u76ee\u3002\n\n\u8cc7\u6599\u4f86\u6e90 https:\/\/ithelp.ithome.com.tw\/articles\/10192162\n"}}