{"cell_type":{"0da41982":"code","cb29ce14":"code","38d9b312":"code","ec275fa9":"code","a65d4f5a":"code","9a79a04e":"code","103500c6":"code","9b29169b":"code","ba79affd":"code","87ad8371":"markdown"},"source":{"0da41982":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport os\nos.chdir('\/kaggle\/input\/tensorflow-great-barrier-reef')\nos.listdir()\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb29ce14":"df_train_df = pd.read_csv(\"train.csv\")\ndf_train_df","38d9b312":"##Checking for duplicates\ndf_train_df.duplicated().sum()","ec275fa9":"###checking frames with annotations\ndf_train_df[df_train_df.annotations.str.len() > 2]","a65d4f5a":"## Visualizing the annotations\nimport ast\nast.literal_eval(df_train_df.iloc[16].annotations)","9a79a04e":"## Verify in there is corrupted data","103500c6":"from os import listdir\nfrom PIL import Image\ndef validate_images(video_id):\n    path = 'train_images\/video_{}\/'.format(video_id) \n    print(\"Verifying that video {} frames are valid...\".format(video_id))\n    for filename in listdir(path):\n        if filename.endswith('.jpg'):\n            try:\n                img = Image.open(path+filename)\n                img.verify() \n            except (IOError, SyntaxError) as e:\n                print('Bad file:', filename) # Print out the names of corrupt files\n    print(\"Verified! Video {} has all valid images\".format(video_id))\n\nfor video_id in range(3):\n    validate_images(video_id)\n    ","9b29169b":"### Loading Sequences of images with annotations\nfrom PIL import Image, ImageDraw\n\ndef fetch_image_list(df_tmp, video_id, num_images, start_frame_idx):\n    def fetch_image(frame_id):\n        path_base = 'train_images\/video_{}\/{}.jpg'\n        raw_img = Image.open(path_base.format(video_id, frame_id))\n\n        row_frame = df_tmp[(df_tmp.video_id == video_id) & (df_tmp.video_frame == frame_id)].iloc[0]\n        bounding_boxes = ast.literal_eval(row_frame.annotations)\n\n        for box in bounding_boxes:\n            draw = ImageDraw.Draw(raw_img)\n            x0, y0, x1, y1 = (box['x'], box['y'], box['x']+box['width'], box['y']+box['height'])\n            draw.rectangle( (x0, y0, x1, y1), outline=180, width=3)\n        return raw_img\n\n    return [np.array(fetch_image(start_frame_idx + index)) for index in range(num_images)]\n\nimages = fetch_image_list(df_train_df, video_id = 0, num_images = 80, start_frame_idx = 25)\n\nprint(\"Num images: \", len(images))\nplt.imshow(images[0], interpolation='nearest')\nplt.axis('off')\nplt.show()","ba79affd":"##visualizing list of images as animations\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(9, 9))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000\/\/12)\n\ncreate_animation(images)","87ad8371":"## Videos"}}