{"cell_type":{"c1d9a7e3":"code","259c0e44":"code","0494935a":"code","c2d04b89":"code","6ced1cd2":"code","4dad4009":"code","eab99463":"code","b9a6c89d":"code","968305b6":"code","3f6f6576":"code","855ca8b9":"code","aae137d2":"code","9f144e0f":"code","d519bd09":"code","2875edd3":"code","507bd449":"code","e854ff92":"code","3b38400f":"code","08d64be4":"code","8aa43cbf":"code","1494c3bd":"code","9045f870":"code","a38030e5":"code","fb403306":"code","fcd3abde":"code","8c0cfd24":"code","fc3ee44c":"markdown","59b62bc9":"markdown","9bc8e39b":"markdown","c612650e":"markdown","467a19b7":"markdown","a2891488":"markdown","4a58e823":"markdown"},"source":{"c1d9a7e3":"import pandas as pd\nimport numpy as np","259c0e44":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","0494935a":"data = pd.read_csv(\"..\/input\/spam.csv\",encoding='latin-1')","c2d04b89":"data.head()","6ced1cd2":"# Checking the shape of data\ndata.shape","4dad4009":"# Checking how many of them are null\ndata.isnull().sum()","eab99463":"# Drop column and name change\ndata.drop(labels=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)","b9a6c89d":"data.rename(columns={'v1':'Class','v2':'Text'},inplace=True)","968305b6":"# convert label to a numerical variable\ndata['numClass'] = data['Class'].map({'ham':0, 'spam':1})","3f6f6576":"# Count the number of words in each Text\ndata['Count']=0\nfor i in np.arange(0,len(data.Text)):\n    data.loc[i,'Count'] = len(data.loc[i,'Text'])\n\n# Unique values in target set\nprint(\"Unique values in the Class set: \", data.Class.unique())","855ca8b9":"# displaying the new table\ndata.head()","aae137d2":"# collecting ham messages in one place \nham  = data[data.numClass == 0]\nham_count  = pd.DataFrame(pd.value_counts(ham['Count'],sort=True).sort_index())\nprint(\"Number of ham messages in data set:\", ham['Class'].count())\nprint(\"Ham Count value\", ham_count['Count'].count())","9f144e0f":"# collecting spam messages in one place \nspam = data[data.numClass == 1]\nspam_count = pd.DataFrame(pd.value_counts(spam['Count'],sort=True).sort_index())\nprint(\"Number of spam messages in data set:\", spam['Class'].count())\nprint(\"Spam Count value:\", spam_count['Count'].count())","d519bd09":"fig, ax = plt.subplots(figsize=(17,5))\nspam_count['Count'].value_counts().sort_index().plot(ax=ax, kind='bar',facecolor='red');\nham_count['Count'].value_counts().sort_index().plot(ax=ax, kind='bar',facecolor='green');","2875edd3":"import nltk, os\n\n#if true it will download all the stopwords\nif True:\n    os.system('python -m nltk.downloader')","507bd449":"# importing Natural Language Toolkit \nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#if true will create vectorizer with stopwords\nif True:\n    stopset = set(stopwords.words(\"english\"))\n    vectorizer = TfidfVectorizer(stop_words=stopset,binary=True)","e854ff92":"#if true will create vectorizer without any stopwords\nif True:\n    vectorizer = TfidfVectorizer()","3b38400f":"# Extract feature column 'Text'\nX = vectorizer.fit_transform(data.Text)\n# Extract target column 'Class'\ny = data.numClass","08d64be4":"#Shuffle and split the dataset into the number of training and testing points\nif True: \n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, train_size=0.80, random_state=42)\n\n# Show the results of the split\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))","8aa43cbf":"# Import the models from sklearn\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import learning_curve,validation_curve\nfrom sklearn.model_selection import KFold\n\nobjects = ('Multi-NB', 'DTs', 'AdaBoost', 'KNN', 'RF')","1494c3bd":"# function to train classifier\ndef train_classifier(clf, X_train, y_train):    \n    clf.fit(X_train, y_train)\n\n# function to predict features \ndef predict_labels(clf, features):\n    return(clf.predict(features))","9045f870":"# Initialize the three models\nA = MultinomialNB(alpha=1.0,fit_prior=True)\nB = DecisionTreeClassifier(random_state=42)\nC = AdaBoostClassifier(n_estimators=100) \nD = KNeighborsClassifier(n_neighbors=1)\nE = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)","a38030e5":"# loop to call function for each model\nclf = [A,B,C,D,E]\npred_val = [0,0,0,0,0]\n\nfor a in range(0,5):\n    train_classifier(clf[a], X_train, y_train)\n    y_pred = predict_labels(clf[a],X_test)\n    pred_val[a] = f1_score(y_test, y_pred) \n    print(pred_val[a])","fb403306":"# ploating data for F1 Score\ny_pos = np.arange(len(objects))\ny_val = [ x for x in pred_val]\nplt.bar(y_pos,y_val, align='center', alpha=0.7)\nplt.xticks(y_pos, objects)\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy of Models')\nplt.show()","fcd3abde":"# defining the variable for learning curve\nsize, score, cv = np.linspace(.1, 1.0, 5), 'f1', KFold(n_splits= 5, random_state= 42)\n\n# calling the learning_curve function from defined variables\nsize, train, test = learning_curve(C, X, y, cv= cv, scoring=score, n_jobs=1, train_sizes=size)\n\n# Mean and standard deviation of train and test score\ntrain_mean,test_mean  =  np.mean( train, axis=1), np.mean( test, axis=1)\ntrain_std,  test_std  =  np.std(train, axis=1) , np.std(test, axis=1)\n\n# Ploating the Grid\nplt.grid()\n\n# Ploating the curve \nplt.fill_between(size, train_mean - train_std, train_mean + train_std, alpha=0.1,color=\"r\")\nplt.fill_between(size,  test_mean - test_std,   test_mean + test_std,  alpha=0.1,color=\"g\")\n\n# Ploating the axis name and legend \nplt.plot(size, train_mean, 'o-', color=\"r\",label=\"Training score\")\nplt.plot(size, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\nplt.legend(loc=\"best\");","8c0cfd24":"# ploating data for Accuracy Score\n# ploating data for Accuracy of Models between 1.00 - 0.90 for better visualization\nobjects = ('','Untunded', 'Tuned','')\ny_pos = np.arange(4)\ny_val = [0,0.03470790378,0.037062937063,0 ]\nplt.bar(y_pos,y_val, align='center',width = 0.5, alpha=0.6)\nplt.xticks(y_pos, objects)\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy of AdaBoost')\nplt.show()","fc3ee44c":"# MESSAGE SPAM DETECTION \n\nThe purpose of this paper is to explore the results of applying machine learning techniques to Message spam detection. SMS spam (sometimes called cell phone spam) is any junk message delivered to a mobile phone as text messaging through the Short Message Service (SMS). The dataset for this project originates from the [UCI Machine Learning Repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/SMS+Spam+Collection). This dataset is tab-separated values (TSV) file. More detail about dataset can be found on [this page](http:\/\/www.dt.fee.unicamp.br\/~tiago\/smsspamcollection\/).\n* This dataset has been collected from free or free for research sources at the Internet. \n* The collection is composed by just one text file, where each line has the correct class followed by the raw message.","59b62bc9":"## Result Analysis","9bc8e39b":"## Data Exploration","c612650e":"## Training and Evaluating Models","467a19b7":"## Import Libraries & Data","a2891488":"## Introduction\n\nMobile phone spam also known as (unsolicited messages, especially advertising), directed at the text messaging or other communications services of mobile phones or smartphones. Fighting SMS spam is complicated by several factors (compared to Internet email), including the lower rate of SMS spam, which has allowed many users and service providers to ignore the issue, and the limited availability of mobile phone spam-filtering software. \n\nIn the paper we would try to analysis different methods to identify spam\/ham messages. We will use different approach to establish relation between the text and the category, based on size of message, word count, special keywords, using term-frequency inverse document-frequency (tf-idf) transform.","4a58e823":"## Preparing the Data"}}