{"cell_type":{"c0017186":"code","8c916681":"code","d17f4503":"code","14a3f9c0":"code","e29c7a4f":"code","9fd172ce":"code","d44aa6bb":"code","a424c6bd":"code","5756d356":"code","d21c3f57":"code","fcefa818":"code","3c8c4907":"code","21fd983d":"code","ebe40289":"code","8f54c509":"code","ac2158c5":"code","5c3a9a94":"code","9408cd8e":"code","8cc2aac6":"code","fc2a2719":"code","e1602943":"code","cb91624f":"code","af5f7b3a":"code","ccfd658b":"code","c804969e":"code","40bae967":"code","220369f8":"code","e696a33e":"code","bb87b10e":"code","28619472":"code","e81886d3":"code","ea7f49a1":"code","4ad734e1":"code","389b0e00":"markdown","41dd96f6":"markdown","523c7592":"markdown","ad5d2556":"markdown","79d7873e":"markdown","64f9bbda":"markdown","7b9c9f10":"markdown","f3e74259":"markdown","ffe99160":"markdown","47929de7":"markdown","293ed444":"markdown","f00b49ec":"markdown","bc40fbe5":"markdown","54aa3392":"markdown","82789d20":"markdown","f85d9801":"markdown","7593b058":"markdown","4751ff2b":"markdown","5716af10":"markdown","824167ff":"markdown","1961dec9":"markdown","8c9dcee7":"markdown"},"source":{"c0017186":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c916681":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nplt.style.use('ggplot')\n\nimport cufflinks as cf\nimport plotly.express as px\nimport plotly.offline as py\nfrom plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","d17f4503":"train_df = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/test.csv\")","14a3f9c0":"print(\"We have :\", train_df.shape[0], \"Rows in the Train set\")\ntrain_df.head()","e29c7a4f":"print(\"We have :\", test_df.shape[0], \"Rows in the Test set\")\ntrain_df.head()","9fd172ce":"train_df = train_df.drop([\"id\"], axis=1)\ntest_df = test_df.drop([\"id\"], axis=1)","d44aa6bb":"null_train = train_df.isnull().sum().sum()\nnull_test = test_df.isnull().sum().sum()\n\nprint(\"There's\", null_train, \"null value in the Train set\")\nprint(\"There's\", null_test, \"null value in the Test set\")","a424c6bd":"train_df[\"Response\"].value_counts().plot.bar(colormap=\"autumn\")","5756d356":"negative_response = train_df[train_df[\"Response\"] == 0].value_counts().sum()\npositive_response = train_df[train_df[\"Response\"] == 1].value_counts().sum()\nprint(\"The percentage of positive response is :\", round(positive_response*100\/negative_response), \"%\")","d21c3f57":"pd.crosstab(train_df['Response'], train_df['Gender']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Gender\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Female\", \"Male\"])\n\nplt.xticks(rotation=0);","fcefa818":"pd.crosstab(train_df['Response'], train_df['Previously_Insured']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Previously Insured\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Client without Insurance\", \"Client with already Insurance\"])\n\nplt.xticks(rotation=0);","3c8c4907":"pd.crosstab(train_df['Response'], train_df['Driving_License']).plot(kind=\"bar\", figsize=(8,6), colormap=\"autumn\")\n\nplt.title(\"Response by Driving License\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Client without Driving License\", \"Client with Driving License\"])\n\nplt.xticks(rotation=0);","21fd983d":"train_df = train_df.drop([\"Driving_License\"], axis=1)\ntest_df = test_df.drop([\"Driving_License\"], axis=1)","ebe40289":"pd.crosstab(train_df['Response'], train_df['Vehicle_Age']).plot(kind=\"bar\", figsize=(10,6), colormap=\"autumn\")\n\nplt.title(\"Response by Vehicle Age\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"1-2 Year\", \"< 1 Year\", \"> 2 Years\"])\n\nplt.xticks(rotation=0);","8f54c509":"pd.crosstab(train_df['Response'], train_df['Vehicle_Damage']).plot(kind=\"bar\", figsize=(10,6), colormap=\"autumn\")\n\nplt.title(\"Response by Vehicle Damage\")\n\nplt.xlabel(\"0 : Customer Not interested, 1 : Customer Interested\")\nplt.ylabel(\"Count\")\n\nplt.legend([\"Vehicle damage\", \"No vehicle damage\"])\n\nplt.xticks(rotation=0);","ac2158c5":"#Graph : Age by responses\nfig = px.bar(train_df[\"Age\"].value_counts(), orientation=\"v\", color=train_df[\"Age\"].value_counts(), color_continuous_scale=px.colors.sequential.Plasma, \n             log_x=False, labels={'value':'Count', \n                                'index':'Ages',\n                                 'color':'None'\n                                })\n\nfig.update_layout(\n    font_color=\"black\",\n    title_font_color=\"red\",\n    legend_title_font_color=\"green\",\n    title_text=\"Age by number of responses\"\n)\n\nfig.show()","5c3a9a94":"train_df.head()","9408cd8e":"def encoding_gender(item):\n    if item == \"Male\":\n        return 0\n    else:\n        return 1\n    \ntrain_df[\"Gender\"] = train_df[\"Gender\"].apply(encoding_gender)\ntest_df[\"Gender\"] = test_df[\"Gender\"].apply(encoding_gender)\n\ntrain_df[\"Gender\"].value_counts()","8cc2aac6":"def encoding_vehicle_age(item):\n    if item == \"< 1 Year\":\n        return 0\n    elif item == \"1-2 Year\":\n        return 1\n    else:\n        return 2\n    \ntrain_df[\"Vehicle_Age\"] = train_df[\"Vehicle_Age\"].apply(encoding_vehicle_age)\ntest_df[\"Vehicle_Age\"] = test_df[\"Vehicle_Age\"].apply(encoding_vehicle_age)\n\ntrain_df[\"Vehicle_Age\"].value_counts()","fc2a2719":"def encoding_vehicle_dmg(item):\n    if item == \"No\":\n        return 0\n    else:\n        return 1\n    \ntrain_df[\"Vehicle_Damage\"] = train_df[\"Vehicle_Damage\"].apply(encoding_vehicle_dmg)\ntest_df[\"Vehicle_Damage\"] = test_df[\"Vehicle_Damage\"].apply(encoding_vehicle_dmg)\n\ntrain_df[\"Vehicle_Damage\"].value_counts()","e1602943":"train_df.head()","cb91624f":"test_df.head()","af5f7b3a":"plt.figure(figsize=(12, 8))\nsns.heatmap(train_df.corr(), annot=True)","ccfd658b":"from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold, GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score,recall_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import preprocessing","c804969e":"#Standardization\n\nnumerical_cols = ['Age', 'Vintage', 'Policy_Sales_Channel', 'Region_Code']\n\nscaler = StandardScaler()\ntrain_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n\nscaler_2 = MinMaxScaler()\ntrain_df[[\"Annual_Premium\"]] = scaler_2.fit_transform(train_df[[\"Annual_Premium\"]])\n\ntrain_df.head()","40bae967":"X = train_df.drop([\"Response\"], axis=1)\ny = train_df['Response']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","220369f8":"# r = 42\n\n# RFC = RandomForestClassifier(random_state = r)\n# LGR = LogisticRegression(max_iter=10000)\n# KNN = KNeighborsClassifier(n_neighbors = 10)\n# SGD = SGDClassifier()\n\n# classifiers = [RFC, ADA, KNN, XGB]\n# classifiers_names = ['Random Forest',\n#                      'Logistic Regreesion',\n#                      'KNeighborsClassifier',\n#                      'SGD Classifier']\n# acc_mean = []\n\n# for cl in classifiers:\n#     acc = cross_val_score(estimator = cl, X = X_train, y  = y_train, cv = 2)\n#     acc_mean.append(acc.mean()*100)\n    \n# acc_df = pd.DataFrame({'Classifiers': classifiers_names,\n#                        'Accuracies Mean': acc_mean})\n\n# acc_df.sort_values('Accuracies Mean',ascending=False)","e696a33e":"final_model = KNeighborsClassifier(n_neighbors = 11)\n\nfinal_model.fit(X_train, y_train)\ny_pred_final_model = final_model.predict(X_test)\naccuracy_score(y_test, y_pred_final_model)","bb87b10e":"#k_range = list(range(1,31))\n#weight_options = [\"uniform\", \"distance\"]\n\n#param_grid = dict(n_neighbors = k_range, weights = weight_options)\n#print (param_grid)\n#KNN = KNeighborsClassifier()\n\n#grid = GridSearchCV(KNN, param_grid, cv = 10, scoring = 'accuracy')\n#grid.fit(X,y)\n\n#print(grid.best_score_)\n#print(grid.best_params_)\n#print(grid.best_estimator_)","28619472":"KNN = KNeighborsClassifier()\n\nfinal_model = KNeighborsClassifier(n_neighbors = 30, weights = \"uniform\")\n\nfinal_model.fit(X_train, y_train)\ny_pred_final_model = final_model.predict(X_test)\naccuracy_score(y_test, y_pred_final_model)","e81886d3":"roc_auc_score(y_test, y_pred_final_model, average = 'weighted')","ea7f49a1":"f1_score(y_test, y_pred_final_model, average='weighted')","4ad734e1":"recall_score(y_test, y_pred_final_model, average='weighted')","389b0e00":"So, Previously Insured has the worst corr coef with ***-0.34*** and at the opposite, Vehicle Damage has the best corr coef with ***0.35***.","41dd96f6":"### Driving license (Not Intersted \/ Interested)","523c7592":"Driving license is too messy.\nFor the moment, I prefer too drop this column.","ad5d2556":"### Vehicules Damage (Not interested \/ Interested)","79d7873e":"### Responses (Not interested \/ Interested)","64f9bbda":"The best params are n_neighbors = 30 et weights = uniform.","7b9c9f10":"### Gender (Not interested \/ Interested)","f3e74259":"At first, we have to change our data into numerical data.\nFor that, i will encode some features.","ffe99160":"## Reading Data \ud83d\udcdd","47929de7":"## Data Exploration \ud83d\udcca","293ed444":"### Previously Insured (Not interested \/ Interested)","f00b49ec":"## Modelling \ud83d\udfe9","bc40fbe5":"We want to predict the response of a customer. For that we have some features :\n\n* **id** :\tUnique ID for the customer\n* **Gender** :\tGender of the customer\n* **Age** :\tAge of the customer\n* **Driving_License** :\n   * 0 : Customer does not have DL \n   * 1 : Customer already has DL\n* **Region_Code** :\tUnique code for the region of the customer\n* **Previously_Insured** :\n   * 1 : Customer already has Vehicle Insurance \n   * 0 : Customer doesn't have Vehicle Insurance\n* **Vehicle_Age** :\tAge of the Vehicle\n* **Vehicle_Damage** :\n   * 1 : Customer got his\/her vehicle damaged in the past. \n   * 0 : Customer didn't get his\/her vehicle damaged in the past.\n* **Annual_Premium** :\tThe amount customer needs to pay as premium in the year\n* **PolicySalesChannel** :\tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n* **Vintage** :\tNumber of Days, Customer has been associated with the company\n* **Response** :\n   * 1 : Customer is interested \n   * 0 : Customer is not interested","54aa3392":"Ours datasets are now, completely clean. Before modeling a model, I want to see the correlation between features.","82789d20":"## Feature Engineering \ud83c\udff7\ufe0f","f85d9801":"### After to improve my work :\n\n**-- Confusion Matrix**\n\n**-- Roc plot**\n\n**-- Oversampling**","7593b058":"## What do we want?","4751ff2b":"## Correlation \ud83d\udd04","5716af10":"### Distribution of ages","824167ff":"### Vehicules age (Not interested \/ Interested)","1961dec9":"### If you have any suggestion or advice to improve my notebook, don't hesitate! If you liked it, don't hesitate to like it either! It will help me a lot. I'll improve my work as I go. Thanks again !","8c9dcee7":"## Import librairies \ud83d\udcda"}}