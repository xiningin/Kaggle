{"cell_type":{"212629e4":"code","81c773b1":"code","a1ccf708":"code","678937de":"code","0c05d9e8":"code","98c42a64":"code","766e48c9":"code","1028a6c4":"code","168f34ca":"code","7214915c":"code","ddaf335a":"code","db07cf9a":"code","13131a35":"code","f89e895b":"code","ae44fd58":"code","9280f061":"code","0b149ba7":"code","f33a984b":"code","c98791d2":"code","bf0bd216":"code","04fac146":"code","b6923f5b":"code","98c5f188":"code","d11201f8":"code","7f081fb4":"code","16f3fd60":"code","43671892":"code","59767cdb":"code","5594847e":"code","1eb3aaf4":"code","ce38a5af":"code","68a2d2b7":"code","37daf437":"code","7ce003c0":"code","6f5d1e34":"code","b6e977d5":"code","90bf1a6c":"code","54b68dce":"code","3ef8556a":"code","f9270b2d":"code","99611bb8":"code","f2e1caa7":"code","37d0afe2":"code","c6d472bc":"code","b7f73992":"code","cec286f1":"code","8e5ec279":"code","a3b1d45f":"code","dd943981":"code","e2d955fa":"code","fb2e0cb6":"code","d9b433cf":"code","ed971669":"code","74328976":"code","344ace04":"code","36d05a73":"code","9db41387":"code","73f3f9eb":"code","ff343046":"code","517b7d74":"code","605ecec7":"code","308647e1":"code","2c12e4e5":"code","ea30e0a8":"code","9f9a1b44":"code","9aaa3378":"code","5f7ccb87":"code","124e5704":"code","88ad37d1":"code","460a5719":"code","52eb2d4b":"code","29ab2bbf":"code","045466a4":"code","3d5c3458":"markdown","42b5c917":"markdown","1c4f8b0b":"markdown","d11d524d":"markdown","906ee8fe":"markdown","13298e84":"markdown","d5bdc270":"markdown","9daa814b":"markdown","9184e0ea":"markdown","4986daa4":"markdown","40c5c63b":"markdown","f7b7efc0":"markdown","354e3f83":"markdown","ee17b62b":"markdown","ddfb8fad":"markdown","f9b58482":"markdown","f39e7792":"markdown","8e50ba39":"markdown","1a2dcf8b":"markdown","8fa9cfb2":"markdown","1882c06a":"markdown","7a7861c5":"markdown"},"source":{"212629e4":"# import libraries\n\nimport os, types\nimport io, requests\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, learning_curve, TimeSeriesSplit\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.utils import check_X_y, check_array\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\n\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n\n%matplotlib inline","81c773b1":"# import historical electricity load data\n\nurl = \"https:\/\/raw.githubusercontent.com\/WiDSTexas2021\/datathon-code\/main\/data\/ercot_hourly_load.csv\"\ns=requests.get(url).content\nhr_load_raw =pd.read_csv(io.StringIO(s.decode('utf-8')))","a1ccf708":"hr_load_raw.head(3)","678937de":"# helper function to prep electricity load data by filling in Nans, changing the \"Hour_Ending\" column to the \n# datetime format than making it the index\n\ndef prep_load_data(df):\n    df.fillna(method='ffill', inplace=True)\n    df[\"hour_ending\"] =  df[\"Hour_Ending\"].apply(lambda word: pd.to_datetime(word[:-6]))\n    df = df.set_index(\"hour_ending\")\n    df = df[df.index.year >= 2008]\n    df.drop([\"Hour_Ending\"], axis=1, inplace=True)\n    return df","0c05d9e8":"# use helper function to prepare the electrical load data\n\nhr_load = prep_load_data(hr_load_raw)","98c42a64":"hr_load.shape","766e48c9":"hr_load.head(3)","1028a6c4":"hr_load.describe()","168f34ca":"# visualize the raw electrical load data\n\nregions = [\"Coast\", \"East\", \"Far West\", \"North\", \"North Central\", \"South\", \"South Central\", \"West\"]\n\nfig, axes = plt.subplots(nrows=8, ncols=1, figsize=(12,20))\nfor ax, region in zip(axes.flat, regions):\n    ax.plot(hr_load.index, hr_load[region])\n    ax.set_title(region)","7214915c":"# import the historic weather data. Only import columns with metric measurements and those that are included in \n# the weather forecast data (which will be used to make predictions).  Omit some columns that seem less likely \n# to be useful. \n\ncoi = ['date', 'time', 'city', 'tempC', 'windspeedKmph', 'weatherCode', 'precipMM', 'humidity',\n      'visibility', 'pressure', 'cloudcover', 'HeatIndexC', 'DewPointC', 'WindGustKmph', 'FeelsLikeC', 'uvIndex']\n\nurl = \"https:\/\/raw.githubusercontent.com\/WiDSTexas2021\/datathon-code\/main\/data\/weather_history.csv\"\n\ns=requests.get(url).content\nweather_his_raw =pd.read_csv(io.StringIO(s.decode('utf-8')), usecols=coi)","ddaf335a":"weather_his_raw.head()","db07cf9a":"# look for correlation between weather features\n\nweather_corr = weather_his_raw.corr()\nsns.heatmap(weather_corr)","13131a35":"# helper function to prep historical weather data by filling in Nans, changing the \"Hour_Ending\" column to the \n# datetime format than making it the index, and dropping highly correlated columns\n\ndef prep_weather_data(df):\n    df.loc[:, 'time'] = df.loc[:, 'time'].apply(lambda time: str(time).zfill(4))\n    df[\"hour_ending\"] = df[\"date\"] + \" \" + df[\"time\"]\n    df[\"hour_ending\"] = pd.to_datetime(df[\"hour_ending\"], format=\"%Y-%m-%d %H%M\")\n    df.drop(['time', 'date', 'HeatIndexC', 'FeelsLikeC', 'WindGustKmph'], axis=1, inplace=True)\n    df = df.set_index(\"hour_ending\")\n    df = df[df.index.year >= 2008]\n    return df","f89e895b":"# use helper function to prepare the historical weather data\n\nweather_his = prep_weather_data(weather_his_raw)","ae44fd58":"weather_his.head(3)","9280f061":"# since this notebook specifically predicts electrical load for a specified week, limit downloaded data to that\n# collected before the week begins \n\nstart = '2009-01-01 00:00:00'\nend = '2021-06-13 00:00:00'\nweather_his_trunc = weather_his.truncate(before=start, after=end)\nhr_load_trunc = hr_load.truncate(before=start, after=end)","0b149ba7":"city_list = ['Abilene', 'Corpus Christi', 'Dallas', 'Houston', 'Midland', 'San Antonio', 'Tyler', 'Wichita Falls']\nercot_regions = [\"West\", \"South\", \"North Central\", \"Coast\", \"Far West\", \"South Central\", \"East\", \"North\" ]","f33a984b":"# group weather data by city then create a dictionary where the keys are ERCOT regions and the the values\n# are the grouped weather history for the coresponding city\n\nregion_df_dict = {}\nweather_cities = weather_his_trunc.groupby(\"city\")\nfor city, region in zip(city_list, ercot_regions):\n    region_df_dict[region] = weather_cities.get_group(city)   ","c98791d2":"# the historical weather data is reported every 3 hours, resample so it is hourly\n\nfor key, df in region_df_dict.items():\n    region_df_dict[key] = df.resample(\"1H\").mean().ffill()    ","bf0bd216":"region_df_dict[\"West\"].head()","04fac146":"# the weatherCode column contains 46 different codes. Place codes into 6 broad classes of like weather types. \n# Code to weather class relationships are defined in the dictionary below. \n\n# Weather code meanings came from this website: https:\/\/gist.github.com\/dawnvoh\/a1f513123f7b6a42577d\n\nweather_dict = {113: \"clear\", 248: \"cloudy\", 122: \"cloudy\", 119: \"cloudy\", 116: \"cloudy\", 386: \"light_rain\", \n                353: \"light_rain\", 296: \"light_rain\", 293: \"light_rain\", 176: \"light_rain\", 143: \"light_rain\",\n                389: \"heavy_rain\", 359: \"heavy_rain\", 356: \"heavy_rain\", 350: \"heavy_rain\", 308: \"heavy_rain\", \n                305: \"heavy_rain\", 302: \"heavy_rain\", 299: \"heavy_rain\", 200: \"heavy_rain\", 392: \"light_winter_precip\",\n                374: \"light_winter_precip\", 368: \"light_winter_precip\", 362: \"light_winter_precip\", 326: \"light_winter_precip\",\n                323: \"light_winter_precip\", 317: \"light_winter_precip\", 311: \"light_winter_precip\", 281: \"light_winter_precip\",\n                266: \"light_winter_precip\", 263: \"light_winter_precip\", 260: \"light_winter_precip\", 185: \"light_winter_precip\",\n                182: \"light_winter_precip\", 179: \"light_winter_precip\", 395: \"heavy_winter_precip\", 377: \"heavy_winter_precip\", \n                371: \"heavy_winter_precip\", 365: \"heavy_winter_precip\", 338: \"heavy_winter_precip\", 335: \"heavy_winter_precip\", \n                332: \"heavy_winter_precip\", 329: \"heavy_winter_precip\", 320: \"heavy_winter_precip\", 314: \"heavy_winter_precip\", \n                284: \"heavy_winter_precip\", 230: \"heavy_winter_precip\", 227: \"heavy_winter_precip\"}","b6923f5b":"# create a \"weather_class\" column that contains the class that corresponds with the given weather code\n\nfor region in ercot_regions:\n    region_df_dict[region][\"weather_class\"] = region_df_dict[region][\"weatherCode\"].map(weather_dict)\n    region_df_dict[region].drop(\"weatherCode\", inplace=True, axis=1)","98c5f188":"# add the electricy load data to the weather history dataframes \n# make all electricity load dataframes consistent by renamimg the column containing the load data \"load\"\n\ncolumn_rename_load = {\"West\": \"load\", \"South\": \"load\", \"North Central\": \"load\", \"Coast\": \"load\", \"Far West\": \"load\",\n                 \"South Central\": \"load\", \"East\": \"load\", \"North\": \"load\"}\n\nfor region in ercot_regions:\n    region_df_dict[region] = region_df_dict[region].join(hr_load_trunc[region], how='inner')\n    region_df_dict[region] = region_df_dict[region].rename(columns=column_rename_load)","d11201f8":"region_df_dict[\"West\"].tail(3)","7f081fb4":"# create date time features\n\nfor region in ercot_regions: \n    region_df_dict[region]['year'] = region_df_dict[region].index.year\n    region_df_dict[region]['month'] = region_df_dict[region].index.month\n    region_df_dict[region][\"day_of_week\"] = region_df_dict[region].index.weekday\n    region_df_dict[region][\"hour\"] = region_df_dict[region].index.hour\n    region_df_dict[region][\"weekend\"] = region_df_dict[region].loc[:, 'day_of_week'].apply(lambda x:  1 if x > 4 else 0)","16f3fd60":"# create a yearly lag feature \n# other lag featureas (ie daily or weekly) might be useful, but since our model needs to predict one week out,\n# these values would not be available for the final predictions \n\nfor region in ercot_regions:\n    load = region_df_dict[region][\"load\"].copy()\n    load_monthly = load.resample('M').mean()\n    load_monthly_shift = load_monthly.shift(12)\n    load_hourly_shift = load_monthly_shift.resample('1H').mean().ffill()\n    region_df_dict[region] = region_df_dict[region].join(load_hourly_shift, how=\"left\", rsuffix='year_lag')\n    region_df_dict[region].dropna(inplace=True)\n    ","43671892":"region_df_dict[\"West\"].head(3)","59767cdb":"region_df_dict[\"West\"].shape","5594847e":"# for each region, set aside the last 4320 instances (24 * 180 - 6 months of data) to serve as the final validation \n# set for the \"best\" model.  The remainder of the data will be used to create training and testing sets.  Save in\n# a dictionary with the structure \"region\": [train, validate]\n\ntrain_val_dict = {}\nfor region in region_df_dict:\n    df_list = []\n    train = region_df_dict[region].iloc[:-4320, :]\n    df_list.append(train)\n    validate = region_df_dict[region].iloc[-4320:, :]\n    df_list.append(validate)\n    train_val_dict[region] = df_list","1eb3aaf4":"# standard scale numerical columns and one-hot encode categorical columns that include categories other than 0 and 1\n# in preparation for model testing. \n\nnum_columns = ['tempC', 'windspeedKmph', 'precipMM', 'humidity', 'visibility', 'pressure', 'cloudcover',\n              'DewPointC', 'uvIndex', 'loadyear_lag']\ncat_columns = ['weather_class', 'year', 'month', 'day_of_week', 'hour']\n    \ncol_preprocessing = ColumnTransformer([\n    ('numeric_col_preprocessing', StandardScaler(), num_columns),\n    ('cat_col_preprocessing', OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'), cat_columns)], \n    remainder='passthrough')\n\ndata_prep_pipeline = Pipeline([\n    ('col_preprocessing', col_preprocessing)],\n    verbose=True)","ce38a5af":"# create a naive predictor model to serve as a null\/baseline model.  It takes the last load value of the training \n# set and returns it as every predicted value. \n# code inspired by: https:\/\/towardsdatascience.com\/build-your-own-custom-scikit-learn-regression-5d0d718f289\n\nclass NaivePredictor(RegressorMixin, BaseEstimator):\n    def __init__(self):\n        pass\n    def fit(self, X, y):\n        X, y = check_X_y(X, y)  # checks X and y for consistent length, makes sure X is 2D and y is 1D, no nans in y\n        \n        self.target_ = y[-1]\n        return self\n    def predict(self, X):\n        check_is_fitted(self)  # checks estimator is fitted by looking for fitted attributes (those with trailing underscores)\n        X = check_array(X)  # makes X is non empty 2D array containing finite values,  \n        return np.full(X.shape[0], self.target_)   \n    \nnull_naive = NaivePredictor()","68a2d2b7":"# regression models to try.  Early testing included SVM models but they preformed poorly and took a long time to \n# run so they were ommited from later rounds of testing.\n\nlin_reg = LinearRegression()\nSGD_reg = SGDRegressor()\nridge_reg = Ridge()\nlasso_reg = Lasso()\nEN_reg = ElasticNet()\nDT_reg = DecisionTreeRegressor()\nRF_reg = RandomForestRegressor(n_estimators=100)\nGB_reg = GradientBoostingRegressor()\nKN_reg = KNeighborsRegressor()\nXGB_reg = XGBRegressor()\n#SVM_reg = SVR()\n\nall_model_name_list = [\"null_naive\", \"lin_reg\", \"SGD_reg\", \"ridge_reg\", \"lasso_reg\", \n                       \"EN_reg\", \"DT_reg\", \"RF_reg\", \"GB_reg\", \"KN_reg\", \"XGB_reg\"]\n\nall_model_list = [null_naive, lin_reg, SGD_reg, ridge_reg, lasso_reg, \n                  EN_reg, DT_reg, RF_reg, GB_reg, KN_reg, XGB_reg]","37daf437":"train_val_dict[\"West\"][0].shape","7ce003c0":"# this function implements a sliding window walk forward validation scheme with 4 folds then tests \n# the provided list of models.  It returns a dataframe with the columns \"model\", \"k1_rmse\", \"k2_rmse\", \n# \"k3_rmse\", \"k4_rmse\", \"rmse_mean\", \"rmse_std\". \n\ndef time_series_model_testing_slide_wind(X_data, y_data, models, model_names):\n    results_list = []   \n    for name, model in zip(model_names, models):\n        print(\"running with stepped window\", name)\n        length = X.shape[0]\n        n_train_step = 19046\n        n_test = 4320\n        model_list = [name]\n        rmse_list = []\n        for i in range(n_train_step, length-n_train_step, n_train_step):\n            X_train, X_test = X[i-n_train_step:i], X[i:i+4320]\n            y_train, y_test = y[i-n_train_step:i], y[i:i+4320]\n            #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n            #print(rmse_list)\n            rmse_list.append(rmse)\n        model_list.extend(rmse_list)    \n        model_list.append(np.mean(rmse_list))\n        model_list.append(np.std(rmse_list))\n        #print(model_list)\n        results_list.append(model_list)\n    df = pd.DataFrame(results_list, columns=[\"model\", \"k1_rmse\", \"k2_rmse\", \"k3_rmse\", \"k4_rmse\", \"rmse_mean\", \"rmse_std\"])  \n    return df","6f5d1e34":"# this function implements a expanding window walk forward validation scheme with 4 folds then tests \n# the provided list of models.  It returns a dataframe with the columns \"model\", \"k1_rmse\", \"k2_rmse\", \n# \"k3_rmse\", \"k4_rmse\", \"rmse_mean\", \"rmse_std\". \n\ndef time_series_model_testing_exp_wind(X_data, y_data, models, model_names):\n    results_list = []   \n    for name, model in zip(model_names, models):\n        print(\"running with exp window\", name)\n        length = X.shape[0]\n        n_train_step = 19046\n        n_test = 4320\n        model_list = [name]\n        rmse_list = []\n        for i in range(n_train_step, length-n_train_step, n_train_step):\n            X_train, X_test = X[0:i], X[i:i+4320]\n            y_train, y_test = y[0:i], y[i:i+4320]\n            #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n            #print(rmse_list)\n            rmse_list.append(rmse)\n        model_list.extend(rmse_list)    \n        model_list.append(np.mean(rmse_list))\n        model_list.append(np.std(rmse_list))\n        #print(model_list)\n        results_list.append(model_list)\n    df = pd.DataFrame(results_list, columns=[\"model\", \"k1_rmse\", \"k2_rmse\", \"k3_rmse\", \"k4_rmse\", \"rmse_mean\", \"rmse_std\"])  \n    return df","b6e977d5":"# use the expanding and sliding\/step window walk forward validation schemes to test a list of regression models\n# assemble results in a dataframe for comparison purposes\n\nresults = {}\nfor region in train_val_dict:\n    print(region)\n    y = train_val_dict[region][0].loc[:, 'load']\n    X_train = train_val_dict[region][0].drop([\"load\"], axis=1)\n    #print(y.shape, X_train.shape)\n    X = data_prep_pipeline.fit_transform(X_train.copy())\n    #print(X.shape, y.shape)\n    step_results = time_series_model_testing_slide_wind(X, y, all_model_list, all_model_name_list)\n    exp_results = time_series_model_testing_exp_wind(X, y, all_model_list, all_model_name_list)\n    compare = pd.concat([step_results[\"model\"], step_results[\"rmse_mean\"], exp_results[\"rmse_mean\"]], axis=1)\n    compare.columns = ['model', 'slide_rmse', 'exp_rmse']\n    results[region] = [compare, step_results, exp_results] ","90bf1a6c":"# print results for comparison purposes\n\nfor region in ercot_regions:\n    print(region)\n    print(results[region][0])\n    print()","54b68dce":"# Look at the top 30 features for each regional model\n\nfeatures = ['tempC', 'windspeedKmph', 'precipMM', 'humidity', 'visibility', 'pressure', 'cloudcover',\n              'DewPointC', 'uvIndex', 'loadyear_lag', 'weather_class', 'weather_class', 'weather_class',\n                'weather_class', 'weather_class', 'weather_class', 'year1', 'year2', 'year3', 'year4', 'year5', \n                'year6', 'year7', 'year8', 'year9', 'year10', 'year11', 'month1', 'month2', 'month3', 'month4', \n                'month5', 'month6', 'month7', 'month8', 'month9', 'month10', 'month11', 'month12', 'day_of_week1', \n                'day_of_week2', 'day_of_week3', 'day_of_week4', 'day_of_week5', 'day_of_week6', 'day_of_week7', \n                'hour1', 'hour2', 'hour3', 'hour4', 'hour5', 'hour6', 'hour7', 'hour8', 'hour9', 'hour10', 'hour11',\n                'hour12', 'hour13', 'hour14', 'hour15', 'hour16', 'hour17', 'hour18', 'hour19', 'hour20', 'hour21', \n                'hour22', 'hour23', 'hour24', 'weekend']\n\nfor region in ercot_regions:\n    print(region)\n    train = train_val_dict[region][0].iloc[:-360, :]\n    test = train_val_dict[region][0].iloc[-360:, :]\n    y = train.loc[:, 'load']\n    X_train = train.drop([\"load\"], axis=1)\n    print(y.shape, X_train.shape)\n    X = data_prep_pipeline.fit_transform(X_train.copy())\n    XGB_reg.fit(X, y)\n    feat_import = XGB_reg.feature_importances_\n    feat_import_df = pd.DataFrame(feat_import, index=features, columns=[\"importance\"])\n    print(feat_import_df.sort_values(\"importance\", ascending=False).head(30))","3ef8556a":"# Look at the bottom 30 features for each regional model\n\nfor region in ercot_regions:\n    print(region)\n    train = train_val_dict[region][0].iloc[:-360, :]\n    test = train_val_dict[region][0].iloc[-360:, :]\n    y = train.loc[:, 'load']\n    X_train = train.drop([\"load\"], axis=1)\n    print(y.shape, X_train.shape)\n    X = data_prep_pipeline.fit_transform(X_train.copy())\n    XGB_reg.fit(X, y)\n    feat_import = XGB_reg.feature_importances_\n    feat_import_df = pd.DataFrame(feat_import, index=features, columns=[\"importance\"])\n    print(feat_import_df.sort_values(\"importance\", ascending=True).head(30))","f9270b2d":"# remove less important features from the original feature sets.  Save smaller feature sets in a dictionay keyed by\n# region. \n\nregion_small_df_dict = {}\nfor region in ercot_regions:\n    region_small_df_dict[region] = region_df_dict[region].drop(['weather_class', \"day_of_week\", \"precipMM\", \n                                                               \"windspeedKmph\", \"visibility\", \"humidity\", \n                                                                \"cloudcover\", 'pressure'], axis=1)    ","99611bb8":"# redo the training and validation split for the smaller feature set\n\nsmall_train_val_dict = {}\nfor region in region_small_df_dict:\n    df_list = []\n    train = region_small_df_dict[region].iloc[:-4320, :]\n    df_list.append(train)\n    validate = region_small_df_dict[region].iloc[-4320:, :]\n    df_list.append(validate)\n    small_train_val_dict[region] = df_list","f2e1caa7":"# standard scale numerical columns and one-hot encode categorical columns that include categories other than 0 and 1\n# in preparation for model testing.  Pipeline for the small feature set.\n\nsmall_num_columns = ['tempC','DewPointC', 'uvIndex', 'loadyear_lag']\nsmall_cat_columns = ['year', 'month', 'hour']\n    \nsmall_col_preprocessing = ColumnTransformer([\n    ('numeric_col_preprocessing', StandardScaler(), small_num_columns),\n    ('cat_col_preprocessing', OneHotEncoder(sparse=False, categories='auto'), small_cat_columns)], \n    remainder='passthrough')\n\ndata_prep_small_pipeline = Pipeline([\n    ('col_preprocessing', small_col_preprocessing)],\n    verbose=True)","37d0afe2":"# use the expanding and sliding window walk forward validation schemes to test XGB_reg model on the smaller \n# feature set then assemble results in a dataframe for comparison purposes. \n\nresults = {}\nfor region in small_train_val_dict:\n    print(region)\n    y = small_train_val_dict[region][0].loc[:, 'load']\n    X_train = small_train_val_dict[region][0].drop([\"load\"], axis=1)\n    #print(y.shape, X_train.shape)\n    X = data_prep_small_pipeline.fit_transform(X_train.copy())\n    #print(X.shape, y.shape)\n    step_results = time_series_model_testing_slide_wind(X, y, [XGB_reg], [\"XGB_reg\"])\n    exp_results = time_series_model_testing_exp_wind(X, y, [XGB_reg], [\"XGB_reg\"])\n    compare = pd.concat([step_results[\"model\"], step_results[\"rmse_mean\"], exp_results[\"rmse_mean\"]], axis=1)\n    compare.columns = ['model', 'step_rmse', 'exp_rmse']\n    results[region] = [compare, step_results, exp_results] ","c6d472bc":"# print results for comparison purposes \n\nfor region in ercot_regions:\n    print(region)\n    print(results[region][0])\n    print()","b7f73992":"# initalize the domain space\n\nspace={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n       'gamma': hp.uniform ('gamma', 1, 9),\n       'reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n        'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n       'colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n       'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n        'n_estimators': 180,\n        'seed': 0\n    }","cec286f1":"# define the objective function\n\ndef hyperparameter_tuning(space):\n    model=XGBRegressor(n_estimators=space['n_estimators'], max_depth=int(space['max_depth']), gamma=space['gamma'],\n                         reg_alpha=int(space['reg_alpha']), min_child_weight=space['min_child_weight'],\n                         colsample_bytree=space['colsample_bytree'])\n    \n    evaluation = [(X_validate, y_validate)]\n    \n    model.fit(X_train, y_train,\n            eval_set=evaluation, eval_metric=\"rmse\",\n            early_stopping_rounds=10, verbose=False)\n\n    pred = model.predict(X_validate)\n    mse = mean_squared_error(y_validate, pred)\n    return {'loss': mse, 'status': STATUS_OK, 'model': model}   ","8e5ec279":"# tune all regions\nlarge_tuning_results = {}\nfor region in ercot_regions:\n    print(region)\n    data = train_val_dict[region][0]\n    data_X = data.drop([\"load\"], axis=1)\n    y = data.loc[:, 'load']\n    X = data_prep_pipeline.fit_transform(data_X.copy())\n    X_train = X[:-4320]\n    X_validate = X[-4320:]\n    y_train = y[:-4320]\n    y_validate = y[-4320:]\n    trials = Trials()\n    best = fmin(fn=hyperparameter_tuning,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=200,\n            trials=trials)\n    large_tuning_results[region] = best","a3b1d45f":"  large_tuning_results","dd943981":"# dictionary of XGB_reg models with the tuned hyperparameters specific to each region\n\nopt_XGB_reg = {\"West\": XGBRegressor(colsample_bytree=0.7274177109461611,\n  gamma=6.109037711661932, max_depth=8, min_child_weight=7, reg_alpha=77,\n  reg_lambda=0.7411131263811439), \n  'South': XGBRegressor(colsample_bytree=0.8807697826784431,\n  gamma=7.622094005671151, max_depth=4, min_child_weight=6, reg_alpha=55,\n  reg_lambda=0.8646601679667565),\n  'North Central': XGBRegressor(colsample_bytree=0.8321988823431581,\n  gamma=8.972661538506525, max_depth=5, min_child_weight=8, reg_alpha=147,\n  reg_lambda=0.8597622130820659),\n  'Coast': XGBRegressor(colsample_bytree=0.8037745842635384,\n  gamma=2.5019634695680484, max_depth=4, min_child_weight=10, reg_alpha=152, \n  reg_lambda=0.47819270061391045),\n  'Far West': XGBRegressor(colsample_bytree=0.8808916212036829,\n  gamma=3.8061263263320435, max_depth=9, min_child_weight=0,\n  reg_alpha=86, reg_lambda=0.37433909282607963),\n  'South Central': XGBRegressor(colsample_bytree=0.9214407455437166,\n  gamma=7.0287687769057525, max_depth=5, min_child_weight=0,\n  reg_alpha=173, reg_lambda=0.47465511546868056),\n  'East': XGBRegressor(colsample_bytree=0.5726099997759762,\n  gamma=1.1464658737314208, max_depth=5, min_child_weight=1,\n  reg_alpha=92, reg_lambda=0.7280653035524614),\n  'North': XGBRegressor(colsample_bytree=0.8208201441078663,\n  gamma=4.841409685512929, max_depth=16, min_child_weight=3,\n  reg_alpha=146, reg_lambda=0.00956097020153629)}","e2d955fa":"# test the optimized parameters to see how they perform compared to the default paraments\n\nXGB_reg = XGBRegressor()\nfor region in ercot_regions:    \n    print(region)\n    data = train_val_dict[region][0]\n    data_X = data.drop([\"load\"], axis=1)\n    y = data.loc[:, 'load']\n    X = data_prep_pipeline.fit_transform(data_X.copy())\n    XGB_reg_df = time_series_model_testing_exp_wind(X, y, [XGB_reg], [\"XGB_reg\"])\n    print(\"default hyperparameters\")\n    print(XGB_reg_df)\n    opt_XGB_reg_df = time_series_model_testing_exp_wind(X, y, [opt_XGB_reg[region]], [\"region\"])\n    print(\"optimized hyperparameters\")\n    print(opt_XGB_reg_df)\n    print()","fb2e0cb6":"# dictionary of final XGB_regression models for each region\n\nfinal_XGB_reg = {\"West\": XGBRegressor(colsample_bytree=0.7274177109461611,\n  gamma=6.109037711661932, max_depth=8, min_child_weight=7, reg_alpha=77,\n  reg_lambda=0.7411131263811439), \n  'South': XGBRegressor(colsample_bytree=0.8807697826784431,\n  gamma=7.622094005671151, max_depth=4, min_child_weight=6, reg_alpha=55,\n  reg_lambda=0.8646601679667565),\n  'North Central': XGBRegressor(colsample_bytree=0.8321988823431581,\n  gamma=8.972661538506525, max_depth=5, min_child_weight=8, reg_alpha=147,\n  reg_lambda=0.8597622130820659),\n  'Coast': XGBRegressor(colsample_bytree=0.8037745842635384,\n  gamma=2.5019634695680484, max_depth=4, min_child_weight=10, reg_alpha=152, \n  reg_lambda=0.47819270061391045),\n  'Far West': XGBRegressor(colsample_bytree=0.8808916212036829,\n  gamma=3.8061263263320435, max_depth=9, min_child_weight=0,\n  reg_alpha=86, reg_lambda=0.37433909282607963),\n  'South Central': XGBRegressor(colsample_bytree=0.9214407455437166,\n  gamma=7.0287687769057525, max_depth=5, min_child_weight=0,\n  reg_alpha=173, reg_lambda=0.47465511546868056),\n  'East': XGBRegressor(),\n  'North': XGBRegressor()}","d9b433cf":"# train the models using all the training data, transform the validation data, fit it to the models, \n# generate the predictions, calculate the RMSE and save in a dictionary.  Train both the best model (XGB_reg) for\n# each region and the null model. Training a null model at this stage is not typical, but will provide reassurance \n# that my models are creating predictions that do better than using a random electrical load amount. \n\nval_rmse = {}\nnull_val_rmse = {}\nfor region in ercot_regions:\n    print(region)\n    data = train_val_dict[region][0]\n    data_X = data.drop([\"load\"], axis=1)\n    y = data.loc[:, 'load']\n    X_t = data_prep_pipeline.fit_transform(data_X.copy())\n    XGB_model = final_XGB_reg[region].fit(X_t, y)\n    null_model = null_naive.fit(X_t, y)\n    y_val = train_val_dict[region][1].loc[:, 'load']\n    X_val = train_val_dict[region][1].drop([\"load\"], axis=1)\n    X_v = data_prep_pipeline.transform(X_val.copy())\n    XGB_y_val_pred = XGB_model.predict(X_v)\n    XGB_rmse = np.sqrt(mean_squared_error(y_val, XGB_y_val_pred))\n    val_rmse[region] = XGB_rmse\n    null_y_val_pred = null_model.predict(X_v)\n    null_rmse = np.sqrt(mean_squared_error(y_val, null_y_val_pred))\n    null_val_rmse[region] = null_rmse","ed971669":"compare_df = pd.DataFrame([null_val_rmse, val_rmse], index=[\"null_model\", 'XGB_reg'])\ncompare_df = compare_df.T\ncompare_df[\"times_better\"] = compare_df[\"null_model\"]\/compare_df[\"XGB_reg\"]\ncompare_df","74328976":"# how do the models do on one week of data?\n\nweek_val_rmse = {}\nweek_null_val_rmse = {}\nfor region in ercot_regions:\n    print(region)\n    data = train_val_dict[region][0]\n    data_X = data.drop([\"load\"], axis=1)\n    y = data.loc[:, 'load']\n    X_t = data_prep_pipeline.fit_transform(data_X.copy())\n    XGB_model = final_XGB_reg[region].fit(X_t, y)\n    null_model = null_naive.fit(X_t, y)\n    one_week = train_val_dict[region][1].iloc[0:168, :]\n    y_val = one_week.loc[:, 'load']\n    X_val = one_week.drop([\"load\"], axis=1)\n    X_v = data_prep_pipeline.transform(X_val.copy())\n    XGB_y_val_pred = XGB_model.predict(X_v)\n    XGB_rmse = np.sqrt(mean_squared_error(y_val, XGB_y_val_pred))\n    week_val_rmse[region] = XGB_rmse\n    null_y_val_pred = null_model.predict(X_v)\n    null_rmse = np.sqrt(mean_squared_error(y_val, null_y_val_pred))\n    week_null_val_rmse[region] = null_rmse","344ace04":"week_compare_df = pd.DataFrame([week_null_val_rmse, week_val_rmse], index=[\"null_model\", 'XGB_reg'])\nweek_compare_df = week_compare_df.T\nweek_compare_df[\"times_better\"] = week_compare_df[\"null_model\"]\/week_compare_df[\"XGB_reg\"]\nweek_compare_df","36d05a73":"# import the weather forecast data\n\nurl = \"https:\/\/raw.githubusercontent.com\/WiDSTexas2021\/datathon-code\/main\/data\/weather_forecast.csv\"\n\ns=requests.get(url).content\nweather_for_raw =pd.read_csv(io.StringIO(s.decode('utf-8')), usecols=coi)","9db41387":"weather_for_raw.head(3)","73f3f9eb":"# prep the weather forecast data with the same steps used to prep the historical weather data\n# add a section that limits the data to the one week peroid being forecast\n\ndef prep_weather_data(df):\n    df.loc[:, 'time'] = df.loc[:, 'time'].apply(lambda time: str(time).zfill(4))\n    df[\"hour_ending\"] = df[\"date\"] + \" \" + df[\"time\"]\n    df[\"hour_ending\"] = pd.to_datetime(df[\"hour_ending\"], format=\"%Y-%m-%d %H%M\")\n    df.drop(['time', 'date', 'HeatIndexC', 'FeelsLikeC', 'WindGustKmph'], axis=1, inplace=True)\n    df = df.set_index(\"hour_ending\")\n    df = df[df.index.year >= 2008]\n    return df\n\nweather_for = prep_weather_data(weather_for_raw)\n\n# limit data to the one week period being forecast\nstart = '2021-06-13 00:01:00'\nend = '2021-06-20 00:00:00'\nweather_for_trunc = weather_for.truncate(before=start, after=end)\n\npred_region_df_dict = {}\npred_weather_cities = weather_for_trunc.groupby(\"city\")\nfor city, region in zip(city_list, ercot_regions):\n    pred_region_df_dict[region] = pred_weather_cities.get_group(city)   \n\nfor key, df in pred_region_df_dict.items():\n    pred_region_df_dict[key] = df.resample(\"1H\").mean().ffill()\n    \nfor region in ercot_regions:\n    pred_region_df_dict[region][\"weather_class\"] = pred_region_df_dict[region][\"weatherCode\"].map(weather_dict)\n    pred_region_df_dict[region].drop(\"weatherCode\", inplace=True, axis=1)   ","ff343046":"pred_region_df_dict[\"West\"].shape","517b7d74":"pred_region_df_dict[\"West\"].head(3)","605ecec7":"# add the two hours that are missing in the front of each regional dataframe\n\nfor region in ercot_regions:\n    row = pred_region_df_dict[region].iloc[0, :]\n    pred_region_df_dict[region].loc[pd.to_datetime('2021-06-13 01:00:00')] = row\n    pred_region_df_dict[region].loc[pd.to_datetime('2021-06-13 02:00:00')] = row\n    pred_region_df_dict[region] = pred_region_df_dict[region].sort_index()","308647e1":"pred_region_df_dict[\"West\"].head(3)","2c12e4e5":"pred_region_df_dict[\"West\"].shape","ea30e0a8":"# add date time features\n\nfor region in ercot_regions: \n    pred_region_df_dict[region]['year'] = pred_region_df_dict[region].index.year\n    pred_region_df_dict[region]['month'] = pred_region_df_dict[region].index.month\n    pred_region_df_dict[region][\"day_of_week\"] = pred_region_df_dict[region].index.weekday\n    pred_region_df_dict[region][\"hour\"] = pred_region_df_dict[region].index.hour\n    pred_region_df_dict[region][\"weekend\"] = pred_region_df_dict[region].loc[:, 'day_of_week'].apply(lambda x:  1 if x > 4 else 0)","9f9a1b44":"# take the appropriate 'loadyear_lag' from the training dataframes and add it to the prediction dataframes\n\nfor region in ercot_regions:\n    pred_region_df_dict[region]['loadyear_lag'] = region_df_dict[region].loc['2020-06-13 01:00:00':'2020-06-20 00:00:00', 'loadyear_lag'].values","9aaa3378":"pred_region_df_dict[\"West\"].head(3)","5f7ccb87":"pred_region_df_dict[\"West\"].shape","124e5704":"# train the final models using all the data available (train + validation) and the tuned XGB_reg models.  \n# Fit the forecast data and save the predictions in a dictionary.  \n\nfinal_predictions = {}\nfor region in ercot_regions:\n    print(region)\n    data = region_df_dict[region]\n    data_X = data.drop([\"load\"], axis=1)\n    y = data.loc[:, 'load']\n    X = data_prep_pipeline.fit_transform(data_X.copy())\n    model = final_XGB_reg[region].fit(X, y)\n    forecast_data = pred_region_df_dict[region]\n    X_fore = data_prep_pipeline.transform(forecast_data.copy())\n    y_val_pred = model.predict(X_fore)\n    final_predictions[region] = y_val_pred","88ad37d1":"# convert the prediction dictionary to a dataframe\n\nfinal_predict_df = pd.DataFrame(final_predictions)\nfinal_predict_df.head()","460a5719":"# add back a datetime column\n\nfinal_predict_df[\"Hour_Ending\"] = pd.date_range(start='6\/13\/2021 01:00:00', end='6\/20\/2021 00:00:00', freq=\"1H\")\nfinal_predict_df","52eb2d4b":"# reorder the dataframe to match submission standards\n\nfinal_predict_df = final_predict_df[['Hour_Ending', 'Coast', 'East', 'Far West', 'North', 'North Central', 'South', 'South Central', 'West']]","29ab2bbf":"final_predict_df.head(3)","045466a4":"# save predictions to a .csv for submission to the competition! \n\nfinal_predict_df.to_csv(\"final_predictions.csv\")","3d5c3458":"# Feature Engineering","42b5c917":"# Hyperparameter Optimization\n\nThe XGB_reg model parameters will be tuned using an AutoML Tuner, HyperOpt. \n\nCode snippets for setting up HyperOpt and its parameters from https:\/\/medium.com\/analytics-vidhya\/hyperparameter-tuning-hyperopt-bayesian-optimization-for-xgboost-and-neural-network-8aedf278a1c9 and \nhttps:\/\/www.kaggle.com\/prashant111\/a-guide-on-xgboost-hyperparameters-tuning","1c4f8b0b":"Submission to the 2021 WIDS Datathon\n\nThe goal of this project is to predict the hourly energy usage or \"load\" for the 8 ERCOT regions of Texas for a 1 week period beginning midnight on Sunday, June 13 and ending at midnight on Saturday, June 20, 2021 (168 hourly values).  Electricity load forecasting is a time series problem and can be modeled using traditional time series forecasting methods (ie ARIMA or SARIMA), machine learning regression methods, or more advanced methods including neural networks. I tested various machine learning regression models and found that Extreme Gradient Boosting Regression (XGB_reg) models gave the best results.  \n\nBelow is Python code showing my data preparation, cross validation scheme, model testing, model tuning, and the final modeling and predictions.  \n\nNote:  All the code was originally run in a Jupyter Notebook on my personal machine.  I did not run every code block in this demo notebook because of the length of time some of the code takes to run. Also some of the results were slightly different in this notebook that the Jupyter notebook, but the comments were written to explain the results in my Jupyter Notebook.  I sumitted the final results from my Jupyter Notebook.  ","d11d524d":"## Initial model testing","906ee8fe":"### Comments on validation test results\n\nThe RMSE calucated when comparing the predicted values and the actual values of the validation set are larger than the RMSE values seen during the training process. This is normal, but may suggest some overfitting of the training data. All of the XGB_reg models except one performed at least marginally better than the null models, but there is room for future improvement. \n\nWhile many XGB_reg models did perform better than the null models (1.3 to 3.4x better), this is over 6 months and the chosen naive\/null model is expected to perform poorly over such a long time frame.  It would be interesting to see how the models compare generating only one week of predictions. ","13298e84":"### Comment on the one week validation test\n\nIn this test, all the XGB_reg models performed marginally better than the null models (1.1x to 3.4x better).","d5bdc270":"### Comments on hyperparameter tuning\n\nHyper parameter optimization did not result in large gains in model performance though 6 of the 8 models did show decreased mean RMSE. The optimized parameters identified above will be used for the West, South, North Central, Coast, Far West, and South Central regions.  The default parameters will be used for East and North regions. ","9daa814b":"### Comment on initial model testing results:\n\nAll models tested outperformed the null naive model.  None of the linear regression models performed well. The tree based models had the best performance with the XGB_reg ensemble model doing especially well for most ERCOT regions. The XGB_reg model with either the expanded or stepwise validation scheme was the first or second model in 7 out of 8 regions and the 3rd best model in the final region. ","9184e0ea":"# Final training of selected models and testing of validation data","4986daa4":"## Create a feature dataframe for each ERCOT region","40c5c63b":"### The validation plan:\n\nThis model needs to forecast 1 week of electrical data accurately.  Unlike with tabular data, we cannot use cross validation to validate models since it is not appropriate to use future data to predict the past or present values.  Instead of cross validation, one option for time series forecasting is to use walk forward validation.  There are two ways to implement walk forward validation:  sliding window and expanding window. \n\nIn sliding window walk forward validation, a training window of data at the beginning of the time series is specified followed by a test set.  A second window of training data is selected immediately following the first and again a second testing window following the second training window is set aside.  The training data is split up in this manner producing a predetermined number of k-folds.  The candidate models are trained on each training fold and used to make predictions for the following test folds.  An evaluation metric is calculated (I use RMSE here) for each fold and averaged. \n\nIn expanding window walk forward validation, the principles are the similar except that the training folds are not exclusive.  The first training and testing folds are created as in the sliding window version, but when the second training fold is created, it is added to the data of the first training fold and so on.  Thus each training fold increases in size and the final fold contains most of the training data (except that set aside as testing data for the final fold).  Again candidate models are trained on each training fold and used to make predictions for the following test folds.  An evaluation metric is calculated for each fold and averaged. \n\nA good explanation of different validaton schemes for time series forecasting can be found here: \nhttps:\/\/machinelearningmastery.com\/backtest-machine-learning-models-time-series-forecasting\/","f7b7efc0":"### Comment on feature importance results\n\nAfter looking at the top 30 features for each model, a few things stand out.  First tempC is the most important feature for all the models except one.  Also common in the top feature lists are hour categories, year categories, loadyear_lag, and month categories.  UVIndex, weekend, and DewPointC also are in the top 30 for some models.  In the bottom 30 features, weather_class categories and day_of_week categories are the least useful along with the weather related numbers such as windspeedKmph, visability, humidity, pressure, and cloudcover.  I'm going to remove these less useful features and see if XGB_reg model performance improves. ","354e3f83":"## Feature Importance","ee17b62b":"# Preparation of prediction data","ddfb8fad":"### Comment on additional raw data initially explored\n\nI originally included COVID cases as I was exploring models, but later feature importance tests showed that COVID cases were not important to the strongest models so I did not use that data in this demo notebook. ","f9b58482":"# Data preparation\n\nFeatures important for predicting electricity usage include past electricity usage and weather conditions since air conditioning demands drive electricity load flucuations. In this section, I import and clean historical electricity load data for the 8 ERCOT regions and historical weather data for 8 major cities located in those ERCOT regions. ","f39e7792":"## Train - validation split","8e50ba39":"# Next Steps\n\nThis project represents a preliminary effort at solving the electricity load forecasting problem proposed by the WIDS Datathon.  The following will improve the project and the results:  \n* More initial exploratory data analysis and visualizations \n* Analyze the residuals and use the results to better evaluate the models\n* More feature engineering and selection\n* More hyper paramenter tuning\n* The electrical load data is not stationary (data not shown - ADF and KPSS test results were not included in this notebook).  After making the load data stationary, try a combination of SARIMA models and machine learning models. \n* Try neural networks\n* More individualization of the separate region model\n* Refactor the code and make more use of scikit learn pipelines to simplify the analysis and model making","1a2dcf8b":"### Comments on XGB_reg using the smaller feature set\n\nAfter comparing this recent result with the original model testing results, the mean RMSEs of the expanding window tests shows that all of the regions' mean RMSE is lower (better) when the larger dataset is used. Proceed using the larger dataset. ","8fa9cfb2":"### Comment on electricity load data\nAll the ERCOT regions show an annual periodicity and most show a slight trend up as time progresses.  This trend is especially pronounced in the Far West region.  Looking at the data on a smaller scale also shows a daily periodicity (plots not shown).","1882c06a":"### Comment on the correlation plot:\nThe following features have the highest correlation:  HeatIndexC and tempC, FeelsLikeC and tempC, HeatIndexC and FeelsLikeC.  \nThe following features are also highly correlated: windspeedKmph and WindGustsKmph, HeatIndexC and DewPointC, FeelsLikeC and DewPointC, tempC and DewPointC. \n\nOn the basis of these correlations, drop the following columns:  HeatIndexC, FeelsLikeC, WindGustKmph ","7a7861c5":"# Modeling Testing"}}