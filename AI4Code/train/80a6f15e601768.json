{"cell_type":{"e2698b86":"code","7c7c97e5":"code","617420b9":"code","3f974129":"code","741ce802":"code","912661ff":"code","89c2e9ff":"code","1e00fb98":"code","256135be":"code","aac1f7ef":"code","5427d739":"code","1e44cb07":"code","37296e2a":"code","3c1320b8":"code","1667b871":"code","83eca595":"code","4ba70e3c":"code","f8bd5d65":"code","1c5811ca":"code","69ba102b":"code","1f3b8d9d":"code","db8ba732":"code","c1b6a2ab":"code","f2532a1d":"code","344f8d8d":"code","8bba63ee":"code","ac7b4d4d":"markdown","645c6a7a":"markdown","6262f03f":"markdown","5af76691":"markdown","fe9c0dc3":"markdown","dc287d68":"markdown","1ee12faa":"markdown"},"source":{"e2698b86":"!pip install -q mlflow","7c7c97e5":"import numpy as np\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","617420b9":"image_path_train = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/'\nmask_path_train = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/'\nimage_path_test = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/test\/' ","3f974129":"images = os.listdir(image_path_train)\nmask = os.listdir(mask_path_train)\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]","741ce802":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\", len(check))","912661ff":"testing_files = set(os.listdir(image_path_train)) & set(os.listdir(mask_path_train))\ntraining_files = check","89c2e9ff":"def getData(X_shape, flag = \"MONT\"):\n    im_array = []\n    mask_array = []\n    shape = (X_shape, X_shape)\n    # X_shape = image_size\n    if flag == \"MONT\":\n        for i in tqdm(testing_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i))\n            im = cv2.resize(im, shape)[:, :, 0]\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i))\n            mask = cv2.resize(mask, shape)[:, :, 0]\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    \n    if flag == \"SHEN\":\n        for i in tqdm(training_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i.split(\"_mask\")[0] + \".png\"))\n            im = cv2.resize(im, shape)[:, :, 0]\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i + \".png\"))\n            mask = cv2.resize(mask, shape)[:, :, 0]\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    # return list\n    return im_array, mask_array","1e00fb98":"def get_test(X_shape, n_samples = 100):\n    im_array = []\n    shape = (X_shape, X_shape)\n    test_files = random.choices(list(os.listdir(image_path_test)), k=n_samples)\n    for i in tqdm(test_files):\n        im = cv2.imread(os.path.join(image_path_test, i))\n        im = cv2.resize(im, shape)[:, :, 0]\n        im = cv2.equalizeHist(im)\n        im_array.append(im)\n    return im_array","256135be":"dim, n_samples = 256, 50 # n_samples = [1, 96]\n\nimage_shen, mask_shen = getData(dim, flag = \"SHEN\")\nimage_mont, mask_mont = getData(dim, flag = \"MONT\")\nX_test = get_test(dim, n_samples = n_samples)","aac1f7ef":"image_shen = np.array(image_shen).reshape(len(image_shen), dim, dim, 1)\nmask_shen = np.array(mask_shen).reshape(len(mask_shen), dim, dim, 1)\n\nimage_mont = np.array(image_mont).reshape(len(image_mont), dim, dim, 1)\nmask_mont = np.array(mask_mont).reshape(len(mask_mont), dim, dim, 1)\n\nX_test = np.array(X_test).reshape(len(X_test), dim, dim, 1)","5427d739":"print(image_shen.shape, mask_shen.shape)\nprint(image_mont.shape, mask_mont.shape)\nprint(X_test.shape)","1e44cb07":"i = 25\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(9, 13))\naxs[0, 0].imshow(image_shen[i], cmap='gray')\naxs[0, 1].imshow(mask_shen[i], cmap='gray')\naxs[0, 0].set_ylabel('Shenzhen')\n\naxs[1, 0].imshow(image_mont[i], cmap='gray')\naxs[1, 1].imshow(mask_mont[i], cmap='gray')\naxs[1, 0].set_ylabel('Montgomery')\n\naxs[2, 0].imshow(X_test[i], cmap='gray')\naxs[2, 0].set_ylabel('NIH')\n\naxs[0, 0].set_title('CXR')\naxs[1, 0].set_title('CXR')\naxs[2, 0].set_title('CXR')\n\naxs[0, 1].set_title('mask')\naxs[1, 1].set_title('mask')\n\nfig.delaxes(axs[2, 1])","37296e2a":"assert image_shen.shape == mask_shen.shape\nassert image_mont.shape == mask_mont.shape\nimages = np.concatenate((image_shen, image_mont), axis=0)\nmasks  = np.concatenate((mask_shen, mask_mont), axis=0)\n\nprint(images.shape, masks.shape)","3c1320b8":"X_train, X_val, Y_train, Y_val = train_test_split((images - 127.0) \/ 127.0, \n                                                  (masks > 127).astype(np.float32), \n                                                  test_size = 0.15, \n                                                  random_state = 2018)\nX_testNorm = (X_test - 127.0) \/ 127.0","1667b871":"import tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport mlflow\nimport mlflow.tensorflow","83eca595":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef jaccard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) \/ (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef jaccard_coef_loss(y_true, y_pred):\n    return 1 - jaccard_coef(y_true, y_pred) ","4ba70e3c":"def bn_act(x, act=True):\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    if act == True:\n        x = tensorflow.keras.layers.Activation(\"relu\")(x)\n    return x\n\ndef conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = bn_act(x)\n    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv\n\ndef stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    \n    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = tensorflow.keras.layers.Add()([conv, shortcut])\n    return output\n\ndef residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n    \n    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = tensorflow.keras.layers.Add()([shortcut, res])\n    return output\n\ndef upsample_concat_block(x, xskip):\n    u = tensorflow.keras.layers.UpSampling2D((2, 2))(x)\n    c = tensorflow.keras.layers.Concatenate()([u, xskip])\n    return c","f8bd5d65":"def ResUNet():\n    f = [16, 32, 64, 128, 256]\n    inputs = tensorflow.keras.layers.Input((dim, dim, 1))\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e5, f[4], strides=1)\n    b1 = conv_block(b0, f[4], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e4)\n    d1 = residual_block(u1, f[4])\n    \n    u2 = upsample_concat_block(d1, e3)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e2)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e1)\n    d4 = residual_block(u4, f[1])\n    \n    outputs = tensorflow.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n    model = tensorflow.keras.models.Model(inputs, outputs)\n    return model","1c5811ca":"metrics = [dice_coef, jaccard_coef,\n           'binary_accuracy', \n           tf.keras.metrics.Precision(), \n           tf.keras.metrics.Recall()]\n\nloss = [dice_coef_loss, \n        jaccard_coef_loss,\n        'binary_crossentropy']","69ba102b":"mlflow.autolog()","1f3b8d9d":"model = ResUNet()\nadam = tensorflow.keras.optimizers.Adam()\nmodel.compile(optimizer=adam, loss=loss, metrics=metrics)\nmodel.summary()","db8ba732":"weight_path=\"{}_res_unet.hdf5\".format('cxr_seg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)","c1b6a2ab":"res = model.fit(X_train, Y_train, \n                validation_data=(X_val, Y_val), \n                batch_size=32, epochs=80,\n                callbacks=[checkpoint])","f2532a1d":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(res.history['loss'], '-', label = 'Loss')\nax1.plot(res.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100 * np.array(res.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100 * np.array(res.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend();","344f8d8d":"preds = model.predict(X_testNorm)","8bba63ee":"fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n\nfor i in range(5):\n    for j in range(2):\n        if j != 1:\n            axs[i, j].imshow(X_testNorm[i + 10], cmap='gray')\n            axs[i, j].set_title('CXR')\n        else:\n            axs[i, j].imshow(preds[i + 10], cmap='gray')\n            axs[i, j].set_title('predicted mask')","ac7b4d4d":"## plot model response","645c6a7a":"# Loading images and masks","6262f03f":"### images\n* 'CHNCXR_0242_0.png'\n* 'MCUCXR_0017_0.png'\n\n### mask\n* 'MCUCXR_0017_0.png'\n* 'CHNCXR_0337_1_mask.png'","5af76691":"## prediction on test set","fe9c0dc3":"**image size** = (256 x 256) \n\n_for memory matters_","dc287d68":"# Dataset\n### Montgomery and Shenzhen for train\nhttps:\/\/www.kaggle.com\/nikhilpandey360\/chest-xray-masks-and-labels","1ee12faa":"# Rsidual U-Net\n\nbased on https:\/\/github.com\/nikhilroxtomar\/Deep-Residual-Unet?ref=morioh.com&utm_source=morioh.com"}}