{"cell_type":{"d317c07e":"code","48b9be2c":"code","e2aa895d":"code","edaac3c0":"code","c6c40195":"code","73ceb37c":"code","267d4887":"code","71996ce8":"markdown","469791e0":"markdown","b3d05ac0":"markdown","687a7fcb":"markdown","d194a9c5":"markdown","ce64fa93":"markdown","cb6d63ef":"markdown"},"source":{"d317c07e":"import pandas as pd\nimport numpy as np\nimport os\nimport time\nimport cv2\nimport matplotlib.pyplot as plt\n\nprint(os.listdir(\"..\/input\"))","48b9be2c":"FOLDER = '..\/input\/'\nIMAGES = FOLDER + 'train_images\/'\nlen(os.listdir(IMAGES))","e2aa895d":"df_train = pd.read_csv(FOLDER + 'train.csv')\n# df_sub = pd.read_csv(FOLDER + 'sample_submission.csv')\nunicode_map = {codepoint: char for codepoint, char in pd.read_csv(FOLDER + 'unicode_translation.csv').values}","edaac3c0":"df_train_idx = df_train.set_index(\"image_id\")\nidx_train = df_train['image_id']","c6c40195":"df_char_train = pd.DataFrame()\nstart = time.time()\n\n# for idx in idx_train: \nfor idx in idx_train[:100]: # for displaying only\n    label = df_train_idx.loc[idx]\n    try:\n        label_arr = np.array(label['labels'].split(' ')).reshape(-1, 5) # labels are configured as [unicode, x, y, w, h]\n    except:\n        continue\n    df_char = pd.DataFrame(label_arr, columns=['unicode', 'x', 'y', 'w', 'h'])\n    df_char['image_id'] = idx\n    df_char_train = pd.concat([df_char_train, df_char], axis=0)\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","73ceb37c":"unicode_arr = df_char_train['unicode'].unique()\nunicode = unicode_arr[0]\n\nprint('-'*10, unicode, ' : ',  unicode_map[unicode], '-'*10)\n\ndf_code_char0 = df_char_train.query('unicode == \"{}\"'.format(unicode))\nimages_char0 = df_code_char0['image_id'].unique()\n\ncnt = 0\n\nnum = len(images_char0)\n# for n in range(num):\nfor n in range(3):\n    \n    fname = images_char0[n]\n    print('-'*10, fname, '-'*10)\n\n    image_path = IMAGES + fname + '.jpg'\n    im_original = cv2.imread(image_path)\n    im_original = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)\n    positions = df_code_char0.query('image_id == \"{}\"'.format(fname))[['x', 'y', 'w', 'h']].values.astype('int')\n\n    for pos in positions:\n        x, y, w, h = pos\n        im = im_original[y:y+h, x:x+w]\n        plt.imshow(im) # to be canceled for saving images\n        \n#         cv2.imwrite(\"{}_{}.jpg\".format(unicode, cnt), im)\n#         cnt += 1\n        \n        plt.show() # to be canceled for saving images","267d4887":"# unicode_arr = df_char_train['unicode'].unique()\n# for unicode in unicode_arr:\n#     print('-'*10, unicode, ' : ',  unicode_map[unicode], '-'*10)\n\n#     df_code_char0 = df_char_train.query('unicode == \"{}\"'.format(unicode))\n#     images_char0 = df_code_char0['image_id'].unique()\n\n#     cnt = 0\n#     num = len(images_char0)\n#     for n in range(num):\n#         fname = images_char0[n]\n#         print('-'*10, fname, '-'*10)\n\n#         image_path = IMAGES + fname + '.jpg'\n#         im_original = cv2.imread(image_path)\n#         im_original = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)\n#         positions = df_code_char0.query('image_id == \"{}\"'.format(fname))[['x', 'y', 'w', 'h']].values.astype('int')\n\n#         for pos in positions:\n#             x, y, w, h = pos\n#             im = im_original[y:y+h, x:x+w]  \n#             cv2.imwrite(PROCESSED_DATA + \"{}_{}.jpg\".format(unicode, cnt), im)\n#             cnt += 1\n","71996ce8":"## preparation","469791e0":"If iteration is carried out fully, we get all extracted characters from training images. However, whole data is huge. Here, execution is tried partially.","b3d05ac0":"setting index can help us for fast finding data.","687a7fcb":"to get extracted data fully, below code is executed.","d194a9c5":"# Extraction each character","ce64fa93":"Hello, kagglers.\n\nI've just prepared starter code to extract each character as training images. Those extracted images may be required to build CNN or something.","cb6d63ef":"Labels are configured as [unicode, x, y, w, h]. Pandas DataFrame is more useful to operate analysis."}}