{"cell_type":{"b9de5a7e":"code","b5fea7ed":"code","666461c7":"code","e9ec2eb1":"code","68d82394":"code","b3c68c9e":"code","6a09e37a":"code","70100956":"code","996719c5":"code","45e5a5e8":"code","e763d5fa":"code","e6758cd5":"code","75169071":"code","b209b448":"code","325f1b7a":"code","ce605058":"code","614426a1":"code","2bd34e05":"code","cd076452":"code","559fa273":"code","17dc1e14":"code","4ab15cea":"code","725eac86":"code","e089cf7f":"markdown","f8939597":"markdown","04782b3a":"markdown","4cf327c6":"markdown","e4260547":"markdown","894f6497":"markdown","60403960":"markdown","250ffd82":"markdown","a06c24a9":"markdown","d17dea51":"markdown","3c74523f":"markdown"},"source":{"b9de5a7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5fea7ed":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nfrom xgboost import XGBRegressor\n\ninput_path = Path('\/kaggle\/input\/tabular-playground-series-jan-2021\/')","666461c7":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\ndisplay(train.head())","e9ec2eb1":"test = pd.read_csv(input_path \/ 'test.csv', index_col='id')\ndisplay(test.head())","68d82394":"submission = pd.read_csv(input_path \/ 'sample_submission.csv', index_col='id')\ndisplay(submission.head())","b3c68c9e":"desc=train.apply(pd.DataFrame.describe)\ndesc","6a09e37a":"features = [f'cont{x}'for x in range(1,15)]\ndata= train[features]\ntrain.isnull().sum()","70100956":"#setting up the platform\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n\nsns.distplot(train['target'], color=\"g\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Values\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","996719c5":"i = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(14, 24))\nfor feature in features:\n    plt.subplot(5, 3,i)\n    sns.distplot(train[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(test[feature],color=\"red\", kde=True,bins=120, label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","45e5a5e8":"i = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(14, 24))\nfor feature in features:\n    plt.subplot(5, 3,i)\n    sns.scatterplot(x=train[feature],y = train['target'],color=\"blue\", label='train')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","e763d5fa":"train[train['target'] == 0]","e6758cd5":"for col in train.columns[:-1]:\n    plt.boxplot([train[feature], test[feature]], labels=['train', 'test'])\n    plt.title(col)\n    plt.legend()\n    plt.show()\n    sns.set()","75169071":"def replace_outliers(data):\n    for col in data.columns:\n        Q1 = data[col].quantile(0.25)\n        Q3 = data[col].quantile(0.75)\n        IQR = Q3 - Q1\n        median_ = data[col].median()\n        data.loc[((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)), col] = median_\n    return data","b209b448":"train = replace_outliers(train)","325f1b7a":"corr = train.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"YlGnBu\", square=True)","ce605058":"corr_feature = ['cont6','cont7','cont8','cont9','cont10','cont11','cont12','cont13']\ncorr_in = train[corr_feature]","614426a1":"corr = corr_in.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"YlGnBu\", square=True)","2bd34e05":"train_data = ( train - train.mean())\/train.std()\ntest_data = ( test - test.mean())\/test.std()","cd076452":"train = train.drop(284103)","559fa273":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.60)","17dc1e14":"#parameters used from another kaggle notebook \nmodel = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\nmodel.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)],\n             verbose=False)","4ab15cea":"y_pred = model.predict(X_test)\nscore  = mean_squared_error(y_test, y_pred, squared=False)\nprint(score)","725eac86":"submission['target'] = model.predict(test)\nsubmission.to_csv('xgb_regressor.csv')","e089cf7f":"Removing Outliner with IQR","f8939597":"Scatter Plot for Better Understanding","04782b3a":"# EDA","4cf327c6":"Imports","e4260547":"## Target Distribution","894f6497":"using XGBRegressor","60403960":"Finding target With 0 value","250ffd82":"**PLOTING**","a06c24a9":"CHECKING NULL VALUE","d17dea51":"Dropping feild with target value 0","3c74523f":"Strong Correlation b\/w corr_feature"}}