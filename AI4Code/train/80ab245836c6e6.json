{"cell_type":{"31776833":"code","28368c83":"code","244c8369":"code","2dbf4fb4":"code","e0c5787f":"code","63b050f2":"code","053e4a4d":"code","e531fec3":"code","25788c42":"code","5bea56b8":"code","32d4945c":"code","fcff77ed":"code","f2ed1315":"code","262bd8df":"code","fbd9fb04":"code","1bcc769c":"code","3665a967":"code","0868e43b":"code","ff60cd1b":"code","30e9742f":"code","ae91e047":"code","17ea6d25":"code","180a3108":"code","11e17801":"code","7c6c5ffb":"code","de50fbb3":"code","b35f86ce":"code","6c5ddf48":"code","b4f0bbeb":"code","e0e8738e":"code","94543bbd":"code","84461b6f":"code","0e272052":"code","51ff589c":"code","f1d5fac4":"code","b53b67db":"code","adcd6d10":"code","7cc5f8f1":"code","b3fc7f7a":"code","edf75ea0":"code","6400f243":"code","8d46e71d":"code","f77d5a38":"code","321a9ce5":"code","ec090fd1":"code","bc3b7d3f":"code","23c82949":"code","9b456a8f":"code","9c8655cd":"code","fdb8f1ce":"code","91e6e6fa":"code","a0807d64":"code","2dec7d39":"code","00fd65aa":"code","326cac77":"code","cfe85565":"code","b264d092":"code","464bdd08":"code","04621a9e":"code","4626d09f":"code","4e369ac0":"code","17f0e497":"code","ffd660cf":"code","e3fb41cb":"code","9007f01c":"code","76554382":"code","b8d8e863":"code","5651d1bf":"code","feaae582":"code","65405c5f":"code","3f5f5258":"markdown","513acf1c":"markdown","b77ca7d4":"markdown","f923d2b0":"markdown","413baf85":"markdown","80055a2b":"markdown","41e39d58":"markdown","d0dbb166":"markdown","60869a21":"markdown","199512f1":"markdown","971d0da6":"markdown","125a2cd1":"markdown","2f4fdc44":"markdown","38fe7d46":"markdown","4647c2ed":"markdown","a5a7e5de":"markdown","16f5c728":"markdown","693b4069":"markdown","f08d8316":"markdown","6b5fba42":"markdown"},"source":{"31776833":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt        \nimport seaborn as sns\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","28368c83":"path = '\/kaggle\/input\/store-sales-time-series-forecasting\/'\nos.listdir(path)","244c8369":"data_oil = pd.read_csv(path+'oil.csv')\ntrain_data = pd.read_csv(path+'train.csv', index_col=0)\ntest_data = pd.read_csv(path+'test.csv', index_col=0)\nsamp_subm = pd.read_csv(path+'sample_submission.csv')\ndata_holi = pd.read_csv(path+'holidays_events.csv')\ndata_store =  pd.read_csv(path+'stores.csv')\ndata_trans = pd.read_csv(path+'transactions.csv')","2dbf4fb4":"print(f'Number of data_oil samples: {data_oil.shape}')\nprint(f'Number of train_data samples: {train_data.shape}')\nprint(f'Number of test_data samples: {test_data.shape}')\nprint(f'Number of samp_subm samples: {samp_subm.shape}')\nprint(f'Number of data_holi samples: {data_holi.shape}')\nprint(f'Number of data_store samples: {data_store.shape}')\nprint(f'Number of data_trans samples: {data_trans.shape}')\nprint(train_data.info())\nprint(train_data.columns)\nprint(train_data.head())","e0c5787f":"print(data_trans.head())\nprint(train_data.head())","63b050f2":"print(train_data['store_nbr'].count())\nprint(train_data['store_nbr'].unique())","053e4a4d":"print(data_oil.head())","e531fec3":"ax = data_oil.set_index('date').plot(figsize = (16, 8))\nax.set_xlabel('Date', fontsize = 'large')\nax.set_ylabel(\"Crude Oil\", fontsize = 'large')","25788c42":"avg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n#daily_avg_sales['weekly_avg_sales'] = daily_avg_sales['sales'].rolling(window=7).mean()\navg_sales['weekly_avg_sales'] = avg_sales['sales'].ewm(span=7, adjust=False).mean()\n#ax = daily_avg_sales.set_index('date').plot(figsize = (16, 8))\nax1 = avg_sales.plot(x= 'date', y= ['sales', 'weekly_avg_sales'], figsize=(18,6))\n\navg_transactions = data_trans.groupby('date').agg({'transactions': 'mean'}).reset_index()\n#avg_transaction['weekly_avg_sales'] = avg_transaction['transactions'].rolling(window=7).mean()\navg_transactions['weekly_avg_transactions'] = avg_transactions['transactions'].ewm(span=7, adjust=False).mean()\n\nax2 = avg_transactions.plot(x= 'date', y= ['transactions', 'weekly_avg_transactions'], figsize=(18,6))","5bea56b8":"print(data_oil.head())\nprint(avg_sales.head())\nprint(avg_transactions.head())","32d4945c":"data_oil['sales'] = avg_sales['sales']\ndata_oil['transactions'] = avg_transactions['transactions']\n#print(data_oil.head())\ndata_oil.corr()","fcff77ed":"print(train_data.family.unique())\nprint(len(train_data.family.unique()))\ntrain_data['family'] = train_data['family'].astype('category')\ntrain_data['family_category'] = train_data['family'].cat.codes\n\nfamily_category = dict( zip( train_data['family'].cat.codes, train_data['family'] ) )\nfamily_category","f2ed1315":"data_grouped_family_types = train_data.groupby(['family_category']).mean()[['sales', 'onpromotion']]\n\n\ndata_grouped_family_types['%_s'] = 100 * data_grouped_family_types['sales'] \/ data_grouped_family_types['sales'].sum()\ndata_grouped_family_types['%_s'] = data_grouped_family_types['%_s'].round(decimals = 3)\n\n\npercent = 100 * data_grouped_family_types['sales'] \/ data_grouped_family_types['sales'].sum()\npercent = percent.round(decimals = 3)\npatches, texts = plt.pie(data_grouped_family_types['%_s'], startangle=90, radius=1.5)\n\n\nlables_2 = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(family_category.values(), percent)]\n\n\nsort_legend = True\nif sort_legend:\n    patches, labels, dummy =  zip(*sorted(zip(patches, lables_2, data_grouped_family_types['%_s']),\n                                          key=lambda x: x[2],\n                                          reverse=True))\n    \nplt.legend(patches, labels, loc='best', bbox_to_anchor=(-0.1, 1.),\n           fontsize=8)","262bd8df":"data_grouped_family_types = train_data.groupby(['family_category']).mean()[['sales', 'onpromotion']]\n\n\ndata_grouped_family_types['%_p'] = 100 * data_grouped_family_types['onpromotion'] \/ data_grouped_family_types['onpromotion'].sum()\ndata_grouped_family_types['%_p'] = data_grouped_family_types['%_p'].round(decimals = 3)\n\n\npercent = 100 * data_grouped_family_types['onpromotion'] \/ data_grouped_family_types['onpromotion'].sum()\npercent = percent.round(decimals = 3)\npatches, texts = plt.pie(data_grouped_family_types['%_p'], startangle=90, radius=1.5)\n\n\nlables_2 = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(family_category.values(), percent)]\n\n\nsort_legend = True\nif sort_legend:\n    patches, labels, dummy =  zip(*sorted(zip(patches, lables_2, data_grouped_family_types['%_p']),\n                                          key=lambda x: x[2],\n                                          reverse=True))\n    \nplt.legend(patches, labels, loc='best', bbox_to_anchor=(-0.1, 1.),\n           fontsize=8)","fbd9fb04":"train_data['date'] = pd.to_datetime(train_data['date'])\ntrain_data['day_of_week'] = train_data['date'].dt.dayofweek\ntrain_data['month'] = train_data['date'].dt.month\ntrain_data['year'] = train_data['date'].dt.year","1bcc769c":"data_grouped_day = train_data.groupby(['day_of_week']).mean()['sales']\ndata_grouped_month = train_data.groupby(['month']).mean()['sales']\ndata_grouped_year = train_data.groupby(['year']).mean()['sales']\n\nplt.subplots(3,1, figsize=(20,5))\nplt.subplot(131)\nplt.title('sales - day')\ndata_grouped_day.plot(kind='bar', stacked=True)\nplt.subplot(132)\nplt.title('sales - month')\ndata_grouped_month.plot(kind='bar', stacked=True)\nplt.subplot(133)\nplt.title('sales - year')\ndata_grouped_year.plot(kind='bar', stacked=True)","3665a967":"print(data_holi['type'].unique())\nprint(data_holi['type'].value_counts())\n\nday_type = data_holi[['date', 'type']]\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n\nday_type['date'] = pd.to_datetime(day_type['date'])\navg_sales['date'] = pd.to_datetime(avg_sales['date'])\n\n#print(day_type.head())\n#print(avg_sales.head())\n\ndf = pd.merge_asof(day_type, avg_sales, on = 'date')\ndf.dropna(inplace= True)\ndf.reset_index(drop = True, inplace= True)\n\n#print(df.head())\n\ndf_1 = df.groupby(['type']).mean()['sales']\naverage_holiday_sales = df_1.mean()\n#print(df_1.head())\n\nprint(f'average holiday sales is {average_holiday_sales}')\n\ndf_1.plot(kind='bar', figsize = (12,6)).set_title('average holiday sales')","0868e43b":"avg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\navg_sales['Time'] = np.arange(len(avg_sales.index))\navg_sales.head()","ff60cd1b":"import seaborn as sns\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(12, 6),\n    titlesize=18,\n    titleweight='bold',\n)\n\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\n\n# Use it for the Lag_1 plot later.\nplot_params = dict(\n    color = '0.75',\n    style = \".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n\n%config InlineBackend.figure_format = 'retina' # You can remove\n\nfig, ax = plt.subplots()\nax.plot('Time', 'sales', data=avg_sales, color='0.75')\nax = sns.regplot(x='Time', y='sales', data=avg_sales, ci=None, scatter_kws=dict(color='0.25'))\nax.set_title('Time Plot of sales');","30e9742f":"avg_sales['Lag_1'] = avg_sales['sales'].shift(1)\navg_sales = avg_sales.reindex(columns = ['date','sales', 'Lag_1','Time'])\navg_sales.head()","ae91e047":"fig, ax = plt.subplots()\nax = sns.regplot(x = 'Lag_1', y = 'sales', data = avg_sales, ci = None, scatter_kws = dict(color='0.25'))\nax.set_aspect('equal')\nax.set_title('Lag Plot of sales')","17ea6d25":"from sklearn.linear_model import LinearRegression\n\n# Training data\nX = avg_sales.loc[:, ['Time']] # features\ny = avg_sales.loc[:, 'sales'] # target\n\n# Train the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Store the fitted values as a time series with the same time index as\n# the training data\ny_pred = pd.Series(model.predict(X), index = X.index)\ny_pred","180a3108":"ax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, linewidth = 3)\nax.set_title('Time Plot of sales');","11e17801":"from sklearn.linear_model import LinearRegression\n\nX = avg_sales.loc[:, ['Lag_1']]\nX.dropna(inplace = True) # drop missing values in the feature set\ny = avg_sales.loc[:, 'sales'] # create the target\ny, X = y.align(X, join = 'inner') # drop corresponding values in target\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_pred","7c6c5ffb":"fig, ax = plt.subplots()\nax.plot(X['Lag_1'], y, '.', color='0.25')\nax.plot(X['Lag_1'], y_pred)\nax.set_aspect('equal')\nax.set_ylabel('sales')\nax.set_xlabel('Lag_1')\nax.set_title('Lag Plot of sales');","de50fbb3":"ax = y.plot(**plot_params)\nax = y_pred.plot()","b35f86ce":"from pathlib import Path\nfrom warnings import simplefilter\n\nsimplefilter(\"ignore\")  # ignore warnings to clean up output cells\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\n# Load the sales dataset\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n#avg_sales = avg_sales.set_index('date')\n#avg_sales.index = pd.to_datetime(avg_sales.index)\navg_sales = avg_sales.set_index('date').to_period(\"D\")\navg_sales.head()","6c5ddf48":"moving_average = avg_sales.rolling(\n    window=365,       # 365-day window\n    center=True,      # puts the average at the center of the window\n    min_periods=183,  # choose about half the window size\n).mean()              # compute the mean (could also do median, std, min, max, ...)\n\nax = avg_sales.plot(style=\".\", color=\"0.5\")\nmoving_average.plot(\n    ax=ax, linewidth=3, title=\"sales - 365-Day Moving Average\", legend=False,\n);","b4f0bbeb":"from statsmodels.tsa.deterministic import DeterministicProcess\n\ndp = DeterministicProcess(\n    index=avg_sales.index,  # dates from the training data\n    constant=True,       # dummy feature for the bias (y_intercept)\n    order=1,             # the time dummy (trend)\n    drop=True,           # drop terms if necessary to avoid collinearity\n)\n# `in_sample` creates features for the dates given in the `index` argument\nX = dp.in_sample()\n\nX.head()","e0e8738e":"from sklearn.linear_model import LinearRegression\ny = avg_sales[\"sales\"]  # the target\n\n# The intercept is the same as the `const` feature from\n# DeterministicProcess. LinearRegression behaves badly with duplicated\n# features, so we need to be sure to exclude it here.\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)","94543bbd":"ax = avg_sales.plot(style=\".\", color=\"0.5\", title=\"sales - Linear Trend\")\n_ = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\")","84461b6f":"X = dp.out_of_sample(steps=180)\n\ny_fore = pd.Series(model.predict(X), index=X.index)\n\ny_fore.head()","0e272052":"ax = avg_sales[\"2013-01\":].plot(title=\"Tunnel Traffic - Linear Trend Forecast\", **plot_params)\nax = y_pred[\"2013-01\":].plot(ax=ax, linewidth=3, label=\"Trend\")\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color=\"C3\")\n_ = ax.legend()","51ff589c":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\n\n# annotations: https:\/\/stackoverflow.com\/a\/49238256\/5769929\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}\/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\n# Load the sales dataset\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\navg_sales = avg_sales.set_index('date').to_period(\"D\")\navg_sales.head()","f1d5fac4":"X = avg_sales.copy()\n\n# days within a week\nX['day'] = X.index.dayofweek # the x-axis (freq)\nX['week'] = X.index.week # the seasonal period (period)\n\n# days within a year\nX['dayofyear'] = X.index.dayofyear\nX['year'] = X.index.year\n\nfig, (ax0, ax1) = plt.subplots(2, 1, figsize=(11, 6))\nseasonal_plot(X, y=\"sales\", period=\"week\", freq=\"day\", ax=ax0)\nseasonal_plot(X, y=\"sales\", period=\"year\", freq=\"dayofyear\", ax=ax1);","b53b67db":"#plot_periodogram(avg_sales.sales);\n\ny_deseason = y - y_pred\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(y, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodogram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","adcd6d10":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier = CalendarFourier(freq=\"A\", order=10)  # 10 sin\/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=avg_sales.index,\n    constant=True,   # dummy feature for bias (y-intercept)\n    order=1,         # trend ( order 1 means linear)\n    seasonal=True,   # weekly seasonality (indicators)\n    additional_terms=[fourier], # annual seasonality\n    drop=True,       # drop terms to avoid collinearity\n)\n\nX = dp.in_sample() # create features for dates in tunnel.index\n#X.head()","7cc5f8f1":"y = avg_sales[\"sales\"]\n\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=180)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","b3fc7f7a":"comp_dir = Path('..\/input\/store-sales-time-series-forecasting')\n\nholidays_events = pd.read_csv(\n    comp_dir \/ \"holidays_events.csv\",\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events = holidays_events.set_index('date').to_period('D')\n\n# National and regional holidays in the training set\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\n\ndisplay(holidays)","edf75ea0":"ax = y_deseason.plot(**plot_params)\nplt.plot_date(holidays.index, y_deseason[holidays.index], color='C3')\nax.set_title('National and Regional Holidays');","6400f243":"# Scikit-learn solution\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(sparse=False)\n\nX_holidays = pd.DataFrame(\n    ohe.fit_transform(holidays),\n    index=holidays.index,\n    columns=holidays.description.unique(),\n)\n\n\n# Pandas solution\nX_holidays = pd.get_dummies(holidays)\n\n\n# Join to training data\nX2 = X.join(X_holidays, on='date').fillna(0.0)","8d46e71d":"model = LinearRegression().fit(X2, y)\ny_pred = pd.Series(\n    model.predict(X2),\n    index=X2.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X2), index=X2.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","f77d5a38":"store_sales = pd.read_csv(\n    comp_dir \/ 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\ny = store_sales.unstack(['store_nbr', 'family']).loc[\"2017\"]\n\n# Create training data\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()\nX['NewYear'] = (X.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)","321a9ce5":"STORE_NBR = '1'  # 1 - 54\nFAMILY = 'PRODUCE'\n# Uncomment to see a list of product families\n# display(store_sales.index.get_level_values('family').unique())\n\nax = y.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params)\nax = y_pred.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(ax=ax)\nax.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');","ec090fd1":"df_test = pd.read_csv(\n    comp_dir \/ 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ndf_test['date'] = df_test.date.dt.to_period('D')\ndf_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\n# Create features for test set\nX_test = dp.out_of_sample(steps=16)\nX_test.index.name = 'date'\nX_test['NewYear'] = (X_test.index.dayofyear == 1)\n\n\ny_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\ny_submit = y_submit.stack(['store_nbr', 'family'])\ny_submit = y_submit.join(df_test.id).reindex(columns=['id', 'sales'])\ny_submit.to_csv('submission.csv', index=False)","bc3b7d3f":"from learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_lags, make_lags, make_leads\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nstore_sales = pd.read_csv(\n    comp_dir \/ 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean() \n    .unstack('family')\n    .loc['2017', ['sales', 'onpromotion']]\n)\n\nmag_sales = family_sales.loc(axis=1)[:, 'MAGAZINES']\n\nstore_sales.head()","23c82949":"y = mag_sales.loc[:, 'sales'].squeeze()\n\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    constant=True,\n    index=y.index,\n    order=1,\n    seasonal=True,\n    drop=True,\n    additional_terms=[fourier],\n)\nX_time = dp.in_sample()\nX_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_time, y)\ny_deseason = y - model.predict(X_time)\ny_deseason.name = 'sales_deseasoned'\n\nax = y_deseason.plot()\nax.set_title(\"Magazine Sales (deseasonalized)\");","9b456a8f":"# YOUR CODE HERE\ny_ma = y.rolling(7, center=True).mean()\n\n\n# Plot\nax = y_ma.plot()\nax.set_title(\"Seven-Day Moving Average\");","9c8655cd":"plot_pacf(y_deseason, lags=8);\nplot_lags(y_deseason, lags=8, nrows=2);","fdb8f1ce":"onpromotion = mag_sales.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n\n# Drop the New Year outlier\nplot_lags(x=onpromotion.iloc[1:], y=y_deseason.iloc[1:], lags=3, leads=3, nrows=1);","91e6e6fa":"# YOUR CODE HERE: Make features from `y_deseason`\nX_lags = make_lags(y_deseason, lags = 1)\n\n# YOUR CODE HERE: Make features from `onpromotion`\n# You may want to use `pd.concat`\nX_promo = pd.concat([\n    make_lags(onpromotion, lags= 1),\n    onpromotion,\n    make_leads(onpromotion, leads = 1),\n], axis=1)\n\n# YOUR CODE HERE: Make features from `oil`\nX_oil = pd.DataFrame()\n\nX = pd.concat([X_lags, X_promo, X_oil], axis=1).dropna()\ny, X = y.align(X, join='inner')","a0807d64":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n\nmodel = LinearRegression(fit_intercept=False).fit(X_train, y_train)\ny_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\ny_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n\nrmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\nax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\nax.legend();","2dec7d39":"y_lag = mag_sales.loc[:, 'sales'].shift(1)\nonpromo = mag_sales.loc[:, 'onpromotion']\n\n# 28-day mean of lagged target\nmean_7 = y_lag.rolling(7).mean()\n# YOUR CODE HERE: 14-day median of lagged target\nmedian_14 = y_lag.rolling(14).median()\n# YOUR CODE HERE: 7-day rolling standard deviation of lagged target\nstd_7 = y_lag.rolling(7).std()\n# YOUR CODE HERE: 7-day sum of promotions with centered window\npromo_7 = onpromo.rolling(7, center=True).sum()","00fd65aa":"family_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean()\n    .unstack('family')\n    .loc['2017']\n)\n\nfamily_sales.head()","326cac77":"# You'll add fit and predict methods to this minimal class\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method","cfe85565":"def fit(self, X_1, X_2, y):\n    # Train model_1\n    self.model_1.fit(X_1, y)\n\n    # Make predictions\n    y_fit = pd.DataFrame(\n        self.model_1.predict(X_1), \n        index=X_1.index, \n        columns=y.columns,\n    )\n\n    # Compute residuals\n    y_resid = y - y_fit\n    y_resid = y_resid.stack().squeeze() # wide to long\n\n    # Train model_2 on residuals\n    self.model_2.fit(X_2, y_resid)\n\n    # Save column names for predict method\n    self.y_columns = y.columns\n    # Save data for question checking\n    self.y_fit = y_fit\n    self.y_resid = y_resid\n\n\n# Add method to class\nBoostedHybrid.fit = fit","b264d092":"def predict(self, X_1, X_2):\n    # Predict with model_1\n    y_pred = pd.DataFrame(\n        self.model_1.predict(X_1), \n        index=X_1.index, columns=self.y_columns,\n    )\n    y_pred = y_pred.stack().squeeze()  # wide to long\n\n    # Add model_2 predictions to model_1 predictions\n    y_pred += self.model_2.predict(X_2)\n\n    return y_pred.unstack()\n\n\n# Add method to class\nBoostedHybrid.predict = predict","464bdd08":"from sklearn.preprocessing import LabelEncoder\n\n# Target series\ny = family_sales.loc[:, 'sales']\n\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n\n# X_2: Features for XGBoost\nX_2 = family_sales.drop('sales', axis=1).stack()  # onpromotion feature\n\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.day  # values are day of the month","04621a9e":"from xgboost import XGBRegressor\n# YOUR CODE HERE: Create LinearRegression + XGBRegressor hybrid with BoostedHybrid\nmodel = BoostedHybrid(\n    model_1 = LinearRegression(),\n    model_2 = XGBRegressor(),\n)\n\n# YOUR CODE HERE: Fit and predict\nmodel.fit(X_1, X_2, y)\ny_pred = model.predict(X_1, X_2)\n\ny_pred = y_pred.clip(0.0)","4626d09f":"# Model 1 (trend)\nfrom pyearth import Earth\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\n\n# Model 2\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Boosted Hybrid\n\n# YOUR CODE HERE: Try different combinations of the algorithms above\nmodel = BoostedHybrid(\n    model_1=Ridge(),\n    model_2=KNeighborsRegressor(),\n)","4e369ac0":"y_train, y_valid = y[:\"2017-07-01\"], y[\"2017-07-02\":]\nX1_train, X1_valid = X_1[: \"2017-07-01\"], X_1[\"2017-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2017-07-01\"], X_2.loc[\"2017-07-02\":]\n\n# Some of the algorithms above do best with certain kinds of\n# preprocessing on the features (like standardization), but this is\n# just a demo.\nmodel.fit(X1_train, X2_train, y_train)\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)\n\nfamilies = y.columns[0:6]\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,\n)\n_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)","17f0e497":"#family_sales.head()\n\ntest = pd.read_csv(\n    comp_dir \/ 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ntest['date'] = test.date.dt.to_period('D')\ntest = test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\ntest.head()","ffd660cf":"import ipywidgets as widgets\nfrom learntools.time_series.utils import (create_multistep_example,\n                                          load_multistep_data,\n                                          make_lags,\n                                          make_multistep_target,\n                                          plot_multistep)\n\ndatasets = load_multistep_data()\n\ndata_tabs = widgets.Tab([widgets.Output() for _ in enumerate(datasets)])\nfor i, df in enumerate(datasets):\n    data_tabs.set_title(i, f'Dataset {i+1}')\n    with data_tabs.children[i]:\n        display(df)\n\ndisplay(data_tabs)","e3fb41cb":"#print(\"Training Data\", \"\\n\" + \"-\" * 13 + \"\\n\", store_sales)\n#print(\"\\n\")\n#print(\"Test Data\", \"\\n\" + \"-\" * 9 + \"\\n\", test)","9007f01c":"y = family_sales.loc[:, 'sales']\n\nX = make_lags(y, lags=4).dropna()\n\ny = make_multistep_target(y, steps=16).dropna()\n\ny, X = y.align(X, join='inner', axis=0)","76554382":"le = LabelEncoder()\nX = (X\n    .stack('family')  # wide to long\n    .reset_index('family')  # convert index to column\n    .assign(family=lambda x: le.fit_transform(x.family))  # label encode\n)\ny = y.stack('family')  # wide to long\n\ndisplay(y)","b8d8e863":"from sklearn.multioutput import RegressorChain\n\nmodel = RegressorChain(base_estimator=XGBRegressor())","5651d1bf":"model.fit(X, y)\n\ny_pred = pd.DataFrame(\n    model.predict(X),\n    index=y.index,\n    columns=y.columns,\n).clip(0.0)","feaae582":"FAMILY = 'BEAUTY'\nSTART = '2017-04-01'\nEVERY = 16\n\ny_pred_ = y_pred.xs(FAMILY, level='family', axis=0).loc[START:]\ny_ = family_sales.loc[START:, 'sales'].loc[:, FAMILY]\n\nfig, ax = plt.subplots(1, 1, figsize=(11, 4))\nax = y_.plot(**plot_params, ax=ax, alpha=0.5)\nax = plot_multistep(y_pred_, ax=ax, every=EVERY)\n_ = ax.legend([FAMILY, FAMILY + ' Forecast'])","65405c5f":"for category in family_category.values():\n    FAMILY = category\n    START = '2017-04-01'\n    EVERY = 16\n\n    y_pred_ = y_pred.xs(FAMILY, level='family', axis=0).loc[START:]\n    y_ = family_sales.loc[START:, 'sales'].loc[:, FAMILY]\n\n    fig, ax = plt.subplots(1, 1, figsize=(11, 4))\n    ax = y_.plot(**plot_params, ax=ax, alpha=0.5)\n    ax = plot_multistep(y_pred_, ax=ax, every=EVERY)\n    _ = ax.legend([FAMILY, FAMILY + ' Forecast'])","3f5f5258":"# Correlation between oil and sales and transaction suggests that the country's economic status and everyday grocery consumption do not have a particular relationship.","513acf1c":"# Time Series as Features","b77ca7d4":"# Hybrids Models","f923d2b0":"**Tutorial done**\n\nMore clean up to do","413baf85":"School and office supplies show funny chart.","80055a2b":"# Seasonality","41e39d58":"# The average holiday sales are equivalent to Saturday and Sunday sales.","d0dbb166":"Thanks for all\n\nhttps:\/\/www.kaggle.com\/kashishrastogi\/store-sales-forecasting\n\nhttps:\/\/www.kaggle.com\/shivamb\/store-sales-forecasting-exploration\n\nhttps:\/\/www.kaggle.com\/drcapa\/storesales-ts-starter\n\nhttps:\/\/www.kaggle.com\/kalilurrahman\/store-sales-eda-prediction-with-ts\n\nhttps:\/\/www.kaggle.com\/shrutisaxena\/store-sales-eda-using-plotly\n\nhttps:\/\/www.kaggle.com\/veleirx\/store-sales-fast-eda#2.-Stores\n\nSpecial thanks for Kaggle team member, Ryan Holbrook. \n\nhttps:\/\/www.kaggle.com\/learn\/time-series","60869a21":"# Let's check items that are most sold and the promotion to see which items influence the most for the total sales.","199512f1":"# Sales analysis in different time frame\n * In a daily basis, Saturday and Sunday show the highest sales.\n * In a month basis, December sales are particularly strong.\n * In a yearly basis, It is growing at steady pace.","971d0da6":"# Trend\n\nhttps:\/\/www.kaggle.com\/ryanholbrook\/trend","125a2cd1":"**Indeed, linear regression alone can get rid of noise. Chart looks simliar to my 7 days moving average**","2f4fdc44":"Not many people are interested in books during the summer :)) Maybe the trend has changed because of covid lockdown since 2020? ","38fe7d46":"# Let's follow the template provided by Kaggle moderator for future sales prediction. Start with linear regression\nhttps:\/\/www.kaggle.com\/ryanholbrook\/linear-regression-with-time-series\/notebook","4647c2ed":"# Equador's economy is dependent on the crude oil price. Let's examine first the relationship between crude oil and grocery sales and transactions.","a5a7e5de":"# Let's check sales in different time frames.","16f5c728":"# Check sales for holidays","693b4069":"Submission.","f08d8316":"# The top 5 most sold are Grocery, beverages, cleaning, dairy, and produce. Grocery + beverage account for more than 50% of total sales. ","6b5fba42":"# Forecasting with Machine Learning"}}