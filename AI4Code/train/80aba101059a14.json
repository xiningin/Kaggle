{"cell_type":{"8171cd51":"code","9f7dd02a":"code","d64ed14a":"code","1d45bc49":"code","dcf1e9eb":"code","db403d6e":"code","3efd8fbc":"code","0cb2fe7d":"code","e6c20556":"code","5cdfc021":"code","e661be41":"code","297515ea":"code","c23408f7":"code","7b9a3e18":"code","8b486fa7":"markdown","1e16d93a":"markdown","57d3dfb5":"markdown","b64d8fdd":"markdown","87bf0499":"markdown"},"source":{"8171cd51":"import numpy as np\nimport pandas as pd","9f7dd02a":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","d64ed14a":"full =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\nfull","1d45bc49":"full = full.drop('PassengerId', axis=1)\nfull","dcf1e9eb":"full.shape","db403d6e":"train.shape","3efd8fbc":"train_size = train.shape[0]\ntrain_size","0cb2fe7d":"test.shape","e6c20556":"full.shape","5cdfc021":"# Fill Fare missing values with the median value\nfull[\"Fare\"] = full[\"Fare\"].fillna(full[\"Fare\"].median())\n\n# Fill Embarked nan values of dataset with the mode\nfull[\"Embarked\"] = full[\"Embarked\"].fillna(full[\"Embarked\"].mode()[0])\n\n# Fill Age with the median age of similar rows according to Pclass and SibSp\n# If no similar crew memeber are found, we will use the full crew age's median\nnan_age_ids = list(full[\"Age\"][full[\"Age\"].isnull()].index)\n\nfor i in nan_age_ids :\n    age_med = full[\"Age\"].median()\n    age_pred = full[\"Age\"][((full['SibSp'] == full.iloc[i][\"SibSp\"]) & (full['Pclass'] == full.iloc[i][\"Pclass\"]))].median()\n    \n    if not np.isnan(age_pred) :\n        full['Age'].iloc[i] = age_pred\n    else :\n        full['Age'].iloc[i] = age_med\n        \nfull[\"Cabin\"] = full['Cabin'].apply(lambda x: 'Z' if pd.isnull(x) else x[0])\n\ncorr = full.corr()\n\nfull['Ticket'] = full['Ticket'].apply(lambda x: 'Z' if x.isdigit() else x.replace('.',' ').replace('\/','').strip().split(' ')[0])\nfull['Ticket'].head()\n\nfull['Title'] = full['Name'].apply(lambda x: x.split('.')[0].split(' ')[-1])\nfull['Title'].value_counts()\n\n# Now we can drop Name column\nfull = full.drop('Name', axis=1)\n\nfull[\"Title\"] = full[\"Title\"].replace(\n    ['Lady','Countess','Capt', 'Mme', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Mlle', 'Ms'], \n    'Rare'\n)\nfull[\"Title\"] = full[\"Title\"].replace(\n    'Miss', \n    'Mrs'\n)\nfull['Title'].value_counts()\n\nfull[\"Fsize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n\n# Create new feature of family size\nfull['Single'] = full['Fsize'].map(lambda s: 1 if s == 1 else 0)\nfull['SmallF'] = full['Fsize'].map(lambda s: 1 if  2 <= s <= 3  else 0)\nfull['LargeF'] = full['Fsize'].map(lambda s: 1 if s >= 4 else 0)\n\n# Finding all the categorical columns from the data\ncategorical_columns = full.select_dtypes(exclude=['int64','float64']).columns\nnumerical_columns = full.drop('Survived', axis=1).select_dtypes(include=['int64','float64']).columns\ncategorical_columns\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nfull['Sex'] = le.fit_transform(full['Sex'])\n\ncategorical_columns = full.select_dtypes(exclude=['int64','float64']).columns\ncategorical_columns\n\n# One hot encoding independent variable x\ndef encode_and_bind(original_dataframe, feature_to_encode):\n    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n    res = pd.concat([original_dataframe, dummies], axis=1)\n    res = res.drop([feature_to_encode], axis=1)\n    return(res) \n\nfor feature in categorical_columns:\n    full = encode_and_bind(full, feature)\n\nfull.head()","e661be41":"train2 = full[:train_size]\ntest2 = full[train_size:]\ntest2 = test2.drop(labels=[\"Survived\"], axis=1)","297515ea":"train2.shape","c23408f7":"test2.shape","7b9a3e18":"import h2o\nfrom h2o.automl import H2OAutoML\nfrom sklearn import metrics\n\nh2o.init()\n\nhf = h2o.H2OFrame(train2)\ntest_hf = h2o.H2OFrame(test2)\nhf.head()\n\n# Select the predictor variables and the target\nhf['Survived'] = hf['Survived'].asfactor()\npredictors = hf.drop('Survived').columns\nresponse = 'Survived'\n\n# Split into train and test\ntrain_hf, valid_hf = hf.split_frame(ratios=[.8], seed=1234)\n\n# Add a Stopping Creterias: max number of models and max time\n# We are going to exclude DeepLearning algorithms because they are too slow\naml = H2OAutoML(\n    max_models=20,\n    max_runtime_secs=300,\n    seed=1234,\n    # exclude_algos = [\"DeepLearning\"]\n)\n\n# Train the model\naml.train(x=predictors,\n        y=response,\n        training_frame=hf,\n)\n\n# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=5)  # Print the first 5 rows\n\nvalid_pred = aml.leader.predict(valid_hf)\n\nmetrics.accuracy_score(valid_pred.as_data_frame()['predict'], valid_hf.as_data_frame()['Survived'])\n\ntest_ids = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')['PassengerId']\n\ntest_pred = aml.predict(test_hf)\n\nsubmission = pd.concat([test_ids, test_pred.as_data_frame()['predict']], axis=1)\nsubmission.columns = ['PassengerId', 'Survived']\nsubmission.head()\n\nsubmission.to_csv(\"submission_h2o_automl.csv\",index=False)","8b486fa7":"# Modeling and Predict ","1e16d93a":"# Devide full data (Full => Train2 + Test2)","57d3dfb5":"# Preprocession (Full)","b64d8fdd":"# Load Data","87bf0499":"# Train + Test => Full"}}