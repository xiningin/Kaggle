{"cell_type":{"38d073ab":"code","69024006":"code","7b3aec78":"code","aa3760a1":"code","5badef24":"code","033030a2":"code","0cad0a44":"code","ba2e1626":"code","862c326c":"code","e871aa2b":"code","d289bae1":"code","5f35a012":"code","cfead083":"code","3dbf1ac1":"code","b790674a":"markdown","5c8d6bc1":"markdown","6694f9d5":"markdown","f947e1eb":"markdown"},"source":{"38d073ab":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nimport albumentations as A\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = cv2.imread('..\/input\/dog-breed-identification\/train\/' + img_row['id'] + '.jpg')\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1))\n        return image, label\n\ntransform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1),\n                       A.HorizontalFlip(p=0.5),\n                       A.VerticalFlip(p=0.5),\n                       A.MotionBlur(blur_limit=3, p=1),\n                       A.Rotate(limit=45, p=1),\n                       A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=True, p=1.0)])\n\ndata_loader = DataLoader(DogDataset(transform=transform), batch_size=64, shuffle=True, num_workers=2)","69024006":"%%timeit -r 2 -n 5\nopencv_alb_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = image.cuda()\n    label = label.cuda()\n    pass\nopencv_alb_time = time.time() - start_time\nopencv_alb_times.append(opencv_alb_time)\nprint(str(opencv_alb_time) + ' sec')","7b3aec78":"!apt-get install libturbojpeg\n!pip install jpeg4py","aa3760a1":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nimport albumentations as A\nimport jpeg4py as jpeg\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = jpeg.JPEG('..\/input\/dog-breed-identification\/train\/' + img_row['id'] + '.jpg').decode()\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1))\n        return image, label\n\ntransform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1),\n                       A.HorizontalFlip(p=0.5),\n                       A.VerticalFlip(p=0.5),\n                       A.MotionBlur(blur_limit=3, p=1),\n                       A.Rotate(limit=45, p=1),\n                       A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=True, p=1.0)])\n\ndata_loader = DataLoader(DogDataset(transform=transform), batch_size=64, shuffle=True, num_workers=2)","5badef24":"%%timeit -r 2 -n 5\njpeg4py_alb_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = image.cuda()\n    label = label.cuda()\n    pass\njpeg4py_alb_time = time.time() - start_time\njpeg4py_alb_times.append(jpeg4py_alb_time)\nprint(str(jpeg4py_alb_time) + ' sec')","033030a2":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport jpeg4py as jpeg\n\nimport albumentations as A\nimport kornia.augmentation as K\nimport torch.nn as nn\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = jpeg.JPEG('..\/input\/dog-breed-identification\/train\/' + img_row['id'] + '.jpg').decode()\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1).astype(np.float32))\n        return image, label\n\nalb_transform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1)])\n\nmean_std = torch.Tensor([0.5, 0.5, 0.5])*255\nkornia_transform = nn.Sequential(\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomMotionBlur(3, 35., 0.5),\n    K.RandomRotation(degrees=45.0),\n    K.Normalize(mean=mean_std,std=mean_std)\n)\n\ndata_loader = DataLoader(DogDataset(transform=alb_transform), batch_size=64, shuffle=True, num_workers=2)","0cad0a44":"%%timeit -r 2 -n 5\njpeg4py_kornia_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = kornia_transform(image.cuda())\n    label = label.cuda()\n    pass\njpeg4py_kornia_time = time.time() - start_time\njpeg4py_kornia_times.append(jpeg4py_kornia_time)\nprint(str(jpeg4py_kornia_time) + ' sec')","ba2e1626":"!pip install --extra-index-url https:\/\/developer.download.nvidia.com\/compute\/redist nvidia-dali-cuda100","862c326c":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n\nimport kornia.augmentation as K\nimport torch.nn as nn","e871aa2b":"from nvidia.dali.pipeline import Pipeline\nfrom nvidia.dali.plugin.pytorch import DALIGenericIterator\nimport nvidia.dali.ops as ops\nimport nvidia.dali.types as types","d289bae1":"class DALIPipeline(Pipeline):\n    def __init__(self, batch_size, num_threads, device_id):\n        super(DALIPipeline, self).__init__(batch_size, num_threads, device_id)\n        self.img_list = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv')\n\n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n        \n        self.img_list['label'] = self.img_list['breed'].map(self.breed2idx)\n        self.img_list['data'] = '..\/input\/dog-breed-identification\/train\/' + self.img_list['id'] + '.jpg'\n        \n        self.img_list[['data', 'label']].to_csv('dali.txt', header=False, index=False, sep=' ')\n        \n        self.input = ops.FileReader(file_root='.', file_list='dali.txt')\n        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.DALIImageType.RGB)\n        #self.decode = ops.ImageDecoderRandomCrop(device = \"mixed\", output_type = types.DALIImageType.RGB)\n        self.resize = ops.RandomResizedCrop(device = \"gpu\", size=(224, 224))\n        self.transpose = ops.Transpose(device='gpu', perm = [2, 0, 1])\n        self.cast = ops.Cast(device='gpu', dtype=types.DALIDataType.FLOAT)\n\n    def define_graph(self):\n        images, labels = self.input(name=\"Reader\")\n        images = self.decode(images)\n        images = self.resize(images)\n        images = self.cast(images)\n        output = self.transpose(images)\n        return (output, labels)","5f35a012":"def DALIDataLoader(batch_size):\n    num_gpus = 1\n    pipes = [DALIPipeline(batch_size=batch_size, num_threads=2, device_id=device_id) for device_id in range(num_gpus)]\n\n    pipes[0].build()\n    dali_iter = DALIGenericIterator(pipelines=pipes, output_map=['data', 'label'], \n                                    size=pipes[0].epoch_size(\"Reader\"), reader_name=None, \n                                    auto_reset=True, fill_last_batch=True, dynamic_shape=False, \n                                    last_batch_padded=True)\n    return dali_iter\n\ndata_loader = DALIDataLoader(batch_size=64)\n\nmean_std = torch.Tensor([0.5, 0.5, 0.5])*255\nkornia_transform = nn.Sequential(\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomMotionBlur(3, 35., 0.5),\n    K.RandomRotation(degrees=45.0),\n    K.Normalize(mean=mean_std,std=mean_std)\n)","cfead083":"%%timeit -r 2 -n 5\ndali_kornia_times = []\nstart_time = time.time()\nfor feed in data_loader:\n    # image is already on GPU\n    image = kornia_transform(feed[0]['data'])\n    label = feed[0]['label'].cuda()\n    pass\ndali_kornia_time = time.time() - start_time\ndali_kornia_times.append(dali_kornia_time)\nprint(str(dali_kornia_time) + ' sec')","3dbf1ac1":"import numpy as np\nimport matplotlib.pyplot as plt\n \nleft = np.array([1, 2, 3, 4])\nheight = np.array([71, 41.5, 26.2, 8.1])\nlabel = [\"OpenCV\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nKornia\", \"NVIDIA DALI\\n+\\nKornia\"]\nplt.bar(left, height, tick_label=label, align=\"center\")","b790674a":"# jpeg4py + Albumentations","5c8d6bc1":"# OpenCV + Albumentation","6694f9d5":"# NVIDIA DALI + Kornia","f947e1eb":"# jpeg4py + Kornia"}}