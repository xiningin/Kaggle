{"cell_type":{"f2f026ee":"code","6995ca46":"code","60bb0751":"code","da559b3d":"code","b8c3399a":"code","f723cb85":"code","85920388":"code","2019829c":"code","da2216b4":"code","b989b669":"code","798eceda":"code","30bbdd51":"code","b93554f9":"code","79d70ef7":"code","e8afcb16":"code","7624b366":"code","76378769":"markdown","ee1200ba":"markdown","0ff1cc10":"markdown","608a6154":"markdown","740c0274":"markdown","ad25d163":"markdown","de61f41e":"markdown","1d7886ad":"markdown","29f15786":"markdown","8ae0b958":"markdown","ddc63b55":"markdown","ab27b2a2":"markdown","0d0d5ce1":"markdown","397db589":"markdown","89b2426b":"markdown","e1556635":"markdown","4e2121c9":"markdown","a1071150":"markdown","977a6997":"markdown","4dbe07a5":"markdown","344cda76":"markdown","5b31b194":"markdown","a290e811":"markdown","76de4fcf":"markdown","fe2df579":"markdown","f77961e9":"markdown","c02dd21b":"markdown","1710ce98":"markdown","6a016f8f":"markdown"},"source":{"f2f026ee":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nfull = pd.concat([train, test])\n\nseed = 42","6995ca46":"###############################\n# Extracting Title and LastName\n###############################\nfull[\"Title\"] = full[\"Name\"].apply(lambda x: str.strip(str.split(str.split(x,\",\")[1],\".\")[0] + \".\"))\nfull[\"LastName\"] = full[\"Name\"].apply(lambda x: str.strip(str.split(x,\",\")[0]))\n\n#################\n# Grouping titles\n#################\ndef transformTitle(title):\n    if(title in ['Mr.','Mrs.','Miss.','Master.']):\n        return title\n    elif (title in  ['Ms.', 'Mme.']):\n        return 'Mrs.'\n    elif(title=='Mlle.'):\n        return 'Miss.'\n    elif(title in  ['Sir', 'Don.', 'Jonkheer.', 'Dr.', 'Col.', 'Capt.', 'Major.', 'Rev.']): \n        return 'Mr.'\n    elif(title in ['Lady.', 'the Countess.']):\n        return 'Mrs.'\n    else:\n        return 'Mr.'\n    \nfull['Title'] = full['Title'].apply(lambda x: transformTitle(x))\n\n# Fixing some discrepancies\n# The above change created a discrepancy. Dr Alice Leader is a woman. Therefore, let's correct it with a Mrs.\nfull.loc[796,'Title']='Mrs.'\n# Changing this 11 year old passenger title from Mr. to Master?\nfull.loc[731,'Title']='Master.'","60bb0751":"################################\n# Handling missing values -- Age\n################################\ndef estimate_age(age, title, sex, pclass, parch):\n    if(np.isnan(age)):\n        if(title == 'Mr.'):\n            if(pclass==1):\n                return 42\n            elif(pclass==2):\n                return 33\n            else:\n                return 28\n        elif(title == 'Mrs.'):\n            if(pclass==1):\n                return 40\n            elif(pclass==2):\n                return 33\n            else:\n                return 33\n        elif(title == 'Master.'):\n            if(pclass==1):\n                return 5\n            elif(pclass==2):\n                return 3\n            else:\n                return 5\n        elif(title == 'Miss.' and parch==0):\n            if(pclass==1):\n                return 34\n            elif(pclass==2):\n                return 30\n            else:\n                return 21\n        elif(title == 'Miss.' and parch > 0):\n            if(pclass==1):\n                return 21\n            elif(pclass==2):\n                return 10\n            else:\n                return 6\n    return age\n\nfull[\"Age\"] = full.apply(lambda x: estimate_age(x[\"Age\"],x[\"Title\"],x[\"Sex\"],x[\"Pclass\"],x[\"Parch\"]), axis=1)\n\n#####################################\n# Handling missing values -- Embarked\n#####################################\nfull['Embarked'] = full['Embarked'].fillna('S')\n\n#################################\n# Handling missing values -- Fare\n#################################\nfull['Fare'] = full['Fare'].fillna(8)\n\n##################################\n# Handling missing values -- Cabin\n##################################\nfull['Cabin'] = full['Cabin'].fillna('M')\nfull.loc[full[full['Cabin']=='T'].index,'Cabin'] = 'M' #there is only one record with Cabin=T...","da559b3d":"full.head()","b8c3399a":"full['AgeCat'] = pd.cut(full['Age'], 16, right=False, labels=range(16))\nfull['FareCat'] = pd.cut(full['Fare'], 25, right=False, labels=range(25))\nfull['FamilySize'] = full['SibSp'] + full['Parch'] + 1\nfull['FamilyType'] = full['FamilySize'].apply(lambda x: 'alone' if x==1 else 'small' if x in [2,3,4] else 'big')\nfull['GroupSize'] = full['Ticket'].map(full.groupby('Ticket')['PassengerId'].count())\nfull['GroupType'] = full['GroupSize'].apply(lambda x: 'alone' if x==1 else 'small' if x in [2,3,4] else 'big')\n# Adding CabinGroup\nfull['CabinLetter'] = full['Cabin'].apply(lambda x: x[0])\nfull['CabinGroup'] = full['CabinLetter']\ndi = {'A':'A', 'B':'BDEF', 'C':'C', 'D':'BDEF', 'E':'BDEF', 'F':'BDEF', 'G':'GM', 'M':'GM'}\nfull.replace({'CabinGroup': di}, inplace=True)","f723cb85":"# Feature Engineering for Families & Groups\n# MixedGroup=1 means the Group is mixed i.e. composed of male and female.\nfull['Sex_tmp'] = full['Sex'].apply(lambda x: 1 if x=='male' else 0) \nfull['Sex_mean_tmp'] = full['Ticket'].map(full.groupby('Ticket')['Sex_tmp'].mean())\nfull['MixedGroup'] = full['Sex_mean_tmp'].apply(lambda x: 0 if round(x)==x else 1)\nfull.drop(['Sex_tmp','Sex_mean_tmp'], axis=1, inplace=True)\n# 'NbSurvivors' = minimum number of survivors in the passenger's Group and # 'NbDead' = minimum number of dead in the passenger's Group\nfull['NbSurvivors'] = full['Ticket'].map(full[full['Survived']==1].groupby('Ticket')['Survived'].count()).fillna(0)\nfull['NbDead'] = full['Ticket'].map(full[full['Survived']==0].groupby('Ticket')['Survived'].count()).fillna(0)\n# Let's repeat with male & female split\nfull['NbMaleSurvivors'] = full['Ticket'].map(full[(full['Survived']==1) & (full['Sex']=='male')].groupby('Ticket')['Survived'].count()).fillna(0)\nfull['NbMaleDead'] = full['Ticket'].map(full[(full['Survived']==0) & (full['Sex']=='male')].groupby('Ticket')['Survived'].count()).fillna(0)\nfull['NbFemaleSurvivors'] = full['Ticket'].map(full[(full['Survived']==1) & (full['Sex']=='female')].groupby('Ticket')['Survived'].count()).fillna(0)\nfull['NbFemaleDead'] = full['Ticket'].map(full[(full['Survived']==0) & (full['Sex']=='female')].groupby('Ticket')['Survived'].count()).fillna(0)","85920388":"full.head()","2019829c":"train_full = full[full['Survived'].isna()==False].copy()\ntest_full = full[full['Survived'].isna()==True].copy()\n\ny_train_full = train_full['Survived']\n\nX_train_full = train_full[['Embarked','Title','Sex','FareCat','Pclass','AgeCat','FamilyType','GroupSize','CabinGroup']]\n\nX_test_full = test_full[['Embarked','Title','Sex','FareCat','Pclass','AgeCat','FamilyType','GroupSize','CabinGroup']]","da2216b4":"preprocessor = ColumnTransformer(\n    [('onehot', OneHotEncoder(), ['Embarked', 'Title','Sex','Pclass','FamilyType','CabinGroup']), \n     ('scale', StandardScaler(), ['FareCat','AgeCat','GroupSize'])], \n    remainder='passthrough') ","b989b669":"param_grid = {\n        #RandomForestClassifier\n        'classifier__n_estimators': [100, 50, 200, 300, 600, 1000, 1500, 2000],\n        'classifier__min_samples_leaf': [1, 5, 10, 20],\n        'classifier__min_samples_split' : [2, 3, 4, 6],\n        'classifier__max_depth' : [None, 3, 5, 7],\n        'classifier__max_features': ['auto', None],\n        'classifier__random_state' : [seed],\n        'classifier__oob_score' : ['True'],\n        'classifier__n_jobs' : [-1]\n    }\n\n#pipe = Pipeline(steps=[('preprocessor', preprocessor),('classifier', RandomForestClassifier())])\n#grid = GridSearchCV(pipe, cv=10, n_jobs=-1, param_grid=param_grid, scoring='accuracy', refit=True)\n#grid.fit(X_train_full, y_train_full)\n\n################################\n## Let's display the best models\n################################\n#results_df = pd.DataFrame(grid.cv_results_).sort_values(by=['rank_test_score'])\n#for p in results_df['params'][0]:\n#    colname = str.split(p,'__')[1]\n#    results_df[colname] = results_df[\"params\"].apply(lambda x: x[p])\n#results_df[results_df['rank_test_score']<10][['n_estimators', 'min_samples_leaf', 'min_samples_split', 'max_depth','max_features','rank_test_score', 'mean_test_score', 'std_test_score']]","798eceda":"pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(n_estimators=50, min_samples_leaf=5, min_samples_split=4, max_depth=5, max_features='auto', random_state=seed))]) \n\npipe.fit(X_train_full, y_train_full)\ny_test_full = pipe.predict(X_test_full)","30bbdd51":"full_group = full[(full['GroupSize']>1) & (full['NbSurvivors'] + full['NbDead']>0)].copy()\n\n# Let's get the train and test set for passengers with group\ntrain_group = full_group[full_group['Survived'].isna()==False].copy()\ntest_group = full_group[full_group['Survived'].isna()==True].copy()\n\ny_train_group = train_group['Survived']\nX_train_group = train_group[['Embarked','Title','Sex','FareCat','Pclass','AgeCat','GroupType','GroupSize','CabinGroup','MixedGroup','NbSurvivors','NbDead','NbMaleSurvivors','NbFemaleDead']]\n\nX_test_group = test_group[['Embarked','Title','Sex','FareCat','Pclass','AgeCat','GroupType','GroupSize','CabinGroup','MixedGroup','NbSurvivors','NbDead','NbMaleSurvivors','NbFemaleDead']]","b93554f9":"preprocessor = ColumnTransformer(\n    #[('onehot', OneHotEncoder(handle_unknown='ignore'), ['Embarked', 'Title','Sex','Pclass','GroupType']), #handle_unknown='ignore' there is a master in X_train_alone\n    [('onehot', OneHotEncoder(), ['Embarked', 'Title','Sex','Pclass','GroupType','CabinGroup']), \n     ('scale', StandardScaler(), ['FareCat','AgeCat','GroupSize','NbSurvivors','NbDead','NbMaleSurvivors','NbFemaleDead'])], \n    remainder='passthrough') #passthrough for 'MixedGroup' ","79d70ef7":"param_grid = {\n        #SVC\n        'classifier__C': [1, 0.2, 0.4, 0.6, 0.8, 1.2], \n        'classifier__kernel': ['rbf', 'poly'], \n        'classifier__degree': [3, 2, 4], # Used by polynomial kernel function. Ignored by all other kernels.\n        'classifier__gamma': ['scale', 'auto'],\n        'classifier__random_state' : [seed]\n    }\n\n#pipe = Pipeline(steps=[('preprocessor', preprocessor),('classifier', SVC())])\n#grid = GridSearchCV(pipe, cv=10, n_jobs=-1, param_grid=param_grid, scoring='accuracy', refit=True)\n#grid.fit(X_train_group, y_train_group)\n\n################################\n## Let's display the best models\n################################\n#results_df = pd.DataFrame(grid.cv_results_).sort_values(by=['rank_test_score'])\n#for p in results_df['params'][0]:\n#    colname = str.split(p,'__')[1]\n#    results_df[colname] = results_df[\"params\"].apply(lambda x: x[p])\n#results_df[results_df['rank_test_score']<10][['C', 'kernel', 'degree', 'gamma', 'rank_test_score', 'mean_test_score', 'std_test_score']]","e8afcb16":"# C=0.4, kernel='rbf', degree=4, gamma='scale' --> CV result : rank_test_score=1\npipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', SVC(C=0.4, kernel='rbf', degree=4, gamma='scale', random_state=seed))]) \n\npipe.fit(X_train_group, y_train_group)\ny_test_group = pipe.predict(X_test_group)","7624b366":"# output_full = output of the generic model \noutput_full = pd.DataFrame({'PassengerId': test_full['PassengerId'], 'Survived': y_test_full.astype('int')})\n\n# output_alone = subset of output_full. Only passengers travelling alone or having all their group members on the test set are retained in this output. \noutput_alone = output_full[output_full['PassengerId'].isin(test_full[(test_full['GroupSize']==1) | (test_full['NbSurvivors']+test_full['NbDead']==0)]['PassengerId'].to_list())].copy()\n\n# output_full = output of the specific model. This model was applied to passengers traveling in group and having one or more group members in train set \noutput_group = pd.DataFrame({'PassengerId': test_group['PassengerId'], 'Survived': y_test_group.astype('int')})\n\n# concatenating the 2 outputs and submitting the file\noutput = pd.concat([output_alone, output_group]).sort_values(by='PassengerId')\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","76378769":"#  Merging the predictions of the 2 models and file submission <a id='Merging'><\/a>\n[Go back to the agenda](#Agenda)","ee1200ba":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>Agenda<\/p>\n<\/div>","0ff1cc10":"#  Random Forest Classifier - Predictions <a id='RFC-Prediction'><\/a>\n[Go back to the agenda](#Agenda)","608a6154":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>Generic Model<\/p>\n<\/div>","740c0274":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>Feature Engineering<\/p>\n<\/div>","ad25d163":"# Feature Engineering (passengers in group) <a id='Feature-engineering-2'><\/a>\n[Go back to the agenda](#Agenda)","de61f41e":"This notebook contains my model to predict the surival or the death of the Titanic passengers. This work is the continuation of my EDA of the Titanic dataset that can be found [here](https:\/\/www.kaggle.com\/arnrob\/titanic-eda).\n\nBased on the findings of the EDA, I implemented the following approach :  \n1\/ Create a generic model that can be applied to all passengers.   \n2\/ Create a specific model that can be applied to passengers travelling in groups (e.g. family or groups of friends...)  \n\nFor the generic model, I got my best result (0.78229) using a RandomForestClassifier with this set of features :   \"Embarked\", \"Title\", \"Sex\", \"FareCat\", \"Pclass\", \"AgeCat\", \"FamilyType\", \"GroupSize\", \"CabinGroup\".\n\nFor the specific model that can be applied to passengers travelling in group, I got my best result using a SVC with this set of features :  \n\"Embarked\", \"Title\", \"Sex\", \"FareCat\", \"Pclass\", \"AgeCat\", \"FamilyType\", \"GroupSize\", \"CabinGroup\", \"MixedGroup\", \"NbSurvivors\", \"NbDead\", \"NbMaleSurvivors\", \"NbFemaleDead\".\n\n**Overwriting the predictions of the generic model with the ones of the specific model for passengers travelling in group boosted the performance of the model from 0.78229 to 0.80143 on the test set.**\n\nI'm sure that there is plenty of room for improvement. I'll come back to this competition one day and explore new strategies. ","1d7886ad":"# Checking the new dataset <a id='Checking-data-2'><\/a>\n[Go back to the agenda](#Agenda)","29f15786":"#  Encoding categorical features and scaling numeric features <a id='Encoding-1'><\/a>\n[Go back to the agenda](#Agenda)","8ae0b958":"# Splitting train and test sets <a id='Splitting-2'><\/a>\n[Go back to the agenda](#Agenda)","ddc63b55":"#  Encoding categorical features and scaling numeric features <a id='Encoding-2'><\/a>\n[Go back to the agenda](#Agenda)","ab27b2a2":"# Loading libraries and datasets <a id='Loading-data'><\/a>\n[Go back to the agenda](#Agenda)","0d0d5ce1":"#  SVC - Tuning Hyperparameters <a id='SVC-Tuning'><\/a>\n[Go back to the agenda](#Agenda)","397db589":"# Data cleaning <a id='Data-cleaning'><\/a>\n[Go back to the agenda](#Agenda)","89b2426b":"The code below creates these new features:\n- \"Title\" will be extracted from \"Name\" and we will group title into 4 categories \"Mr.\", \"Mrs.\", \"Master.\", \"Miss.\"\n- \"AgeCat\" will be created from \"Age\" by grouping close ages into the same category\n- \"FareCat\" will be created from \"Fare\" by grouping close fares into the same category\n- \"CabinGroup\" will be created from \"Cabin\" by grouping cabins as follows : group 'A', group 'BDEF', group 'C' and group 'GM'\n- \"FamilySize\" will be created from \"Parch\" and \"SibSp\" (FamilySize=Parch+SibSp+1) \n- \"FamilyType\" will be created from \"FamilySize\". FamilyType will be set to either alone or small (2-4 members) or big\n- \"GroupSize\" will be created from \"Ticket\" (GroupSize=the number of passengers having the same ticket)\n- \"GroupType\" will be created from \"GroupSize\". GroupType will be set to either alone or small (2-4 members) or big","e1556635":"The code below creates these new features that apply to passengers travelling in group:  \n- \"MixedGroup\" means the Group is mixed i.e. composed of male and female.\n- \"NbSurvivors\" = nb of survivors in the train set for this group \n- \"NbDead\" = nb of dead in the train set for this group \n- \"NbMaleSurvivors\" = nb of males who survived in the train set for this group \n- \"NbFemaleSurvivors\" = nb of females who survived in the train set for this group \n- \"NbMaleDead\" = nb of males who perished in the train set for this group \n- \"FemaleDead\" = nb of females who perished in the train set for this group ","4e2121c9":"# Feature Engineering (all passengers) <a id='Feature-engineering-1'><\/a>\n[Go back to the agenda](#Agenda)","a1071150":"In the code below, I merged the output of the 2 models so the output of the specific model overwrites the output of the generic model for the passengers traveling in group.","977a6997":"The specific model can be applied to passengers travelling in group having one or more group members in the train set. In my [EDA](https:\/\/www.kaggle.com\/arnrob\/titanic-eda), I found that :\n1. Circa 60% of the families and 85% of the groups shared the same fate (all survived or all perished)\n2. The survival of a male very often implied the survival of the entire family\n3. The death of a female implied the death of the entire family\n\nI created this model to benefit from these patterns that (may) exist in groups.\n\nFor these passengers, I added extra features :\n- \"MixedGroup\" : means the Group is mixed i.e. composed of male and female.\n- \"NbSurvivors\" : nb of survivors in the train set for this group.\n- \"NbDead\" : nb of dead in the train set for this group.\n- \"NbMaleSurvived\" : nb of males who survived in the train set for this group.\n- \"NbFemaleDied\" : nb of females who perished in the train set for this group.\n\nTo select this model : \n- I benchmarked 3 classifiers : Random Forest Classifier, Logistic Regression and Support Vector Classifier. \n- I used GridSearchCV into a pipeline for tuning the hyperparameters.\n\n**Overwriting the predictions of the generic model with the ones of the specific model for passengers travelling in group boosted the performance of the model from 0.78229 to 0.80143 on the test set.**","4dbe07a5":"Detailed agenda of this notebook : <a id='Agenda'><\/a> \n\n- Data preparation : \n\n    - [Loading libraries and datasets](#Loading-data)\n    - [Data cleaning](#Data-cleaning)\n    - [Handling missing values](#Handling-NAs)\n    - [Checking the new dataset](#Checking-data-1)\n\n\n- Feature Engineering :\n\n    - [Feature engineering (all passengers)](#Feature-engineering-1)\n    - [Feature engineering (passengers in group)](#Feature-engineering-2)\n    - [Checking the new dataset](#Checking-data-2)\n\n\n- Generic Model :\n\n    - [Splitting train and test sets](#Splitting-1)\n    - [Encoding categorical features and scaling numeric features](#Encoding-1)\n    - [Random Forest Classifier - Hyperparmater Tuning](#RFC-Tuning)\n    - [Random Forest Classifier - Prediction](#RFC-Tuning)\n\n\n- Specific Model :\n\n    - [Splitting train and test sets](#Splitting-2)\n    - [Encoding categorical features and scaling numeric features](#Encoding-2)\n    - [Support Vector Classifier - Hyperparmater Tuning](#SVC-Tuning)\n    - [Support Vector Classifier - Predictions](#SVC-Predictions)\n\n\n- File Submission :\n\n    - [Merging the predictions of the 2 models and submit the predictions](#Merging)","344cda76":"# Splitting train and test sets <a id='Splitting-1'><\/a>\n[Go back to the agenda](#Agenda)","5b31b194":"# Checking the new dataset <a id='Checking-data-1'><\/a>\n[Go back to the agenda](#Agenda)","a290e811":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>File Submission<\/p>\n<\/div>","76de4fcf":"The generic model can be applied to all the passengers. To select this model : \n- I benchmarked 3 classifiers : Random Forest Classifier, Logistic Regression and Support Vector Classifier. \n- I used GridSearchCV into a pipeline for tuning the hyperparameters.\n- I compared different set of features.\n\n**I achieved my best result (0.78229) against the test set with:**\n\n**- a Random Forest Classifier**   \n\n**- this set of hyperparameters n_estimators=50, min_samples_leaf=5, min_samples_split=4, max_depth=5, max_features='auto'**  \n\n**- this set of features \"Embarked\", \"Title\", \"Sex\", \"FareCat\", \"Pclass\", \"AgeCat\", \"FamilyType\", \"GroupSize\", \"CabinGroup\".**","fe2df579":"#  SVC - Predictions <a id='SVC-Predictions'><\/a>\n[Go back to the agenda](#Agenda)","f77961e9":"#  Random Forest Classifier - Tuning Hyperparameters<a id='RFC-Tuning'><\/a>\n[Go back to the agenda](#Agenda)","c02dd21b":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>Specific Model<\/p>\n<\/div>","1710ce98":"# Handling missing values <a id='Handling-NAs'><\/a>\n[Go back to the agenda](#Agenda)","6a016f8f":"<div style=\"display:fill; background-color:#000000;border-radius:5px;\">\n    <p style=\"font-size:300%; color:white;text-align:center\";>Abstract<\/p>\n<\/div>"}}