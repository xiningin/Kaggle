{"cell_type":{"d983daf6":"code","34a57a72":"code","418cb40d":"code","a0bac5c4":"code","e478f002":"code","1fe11911":"code","af5b2068":"code","c5b74e57":"code","86da7de8":"code","58fd3d3b":"code","94a17c6f":"code","bf3a39aa":"code","7c0056b3":"code","4e7d60c7":"code","c9a42b71":"code","b52e8d5d":"code","d419c054":"code","7ed2b7af":"code","4c7a3774":"code","073c45ee":"markdown","2be5c3ad":"markdown","a74a8825":"markdown","0fe10519":"markdown","d7ebc33e":"markdown","5fa1e352":"markdown","58d719c1":"markdown","6334b82f":"markdown","ef94ef43":"markdown","bce9ca1e":"markdown","f59d4654":"markdown","1e636024":"markdown","1bfd2a98":"markdown","8a404707":"markdown","2428ccf3":"markdown","441d45d4":"markdown"},"source":{"d983daf6":"!pip install mglearn","34a57a72":"import mglearn\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport warnings\nwarnings.filterwarnings('ignore')","418cb40d":"! wget -nc http:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/aclImdb_v1.tar.gz -P data\n! tar xzf data\/aclImdb_v1.tar.gz --skip-old-files -C data","a0bac5c4":"!tree -dL 2 data\/aclImdb","e478f002":"!rm -r data\/aclImdb\/train\/unsup","1fe11911":"from sklearn.datasets import load_files\n\nreviews_train = load_files(\"data\/aclImdb\/train\/\")\n# load_files returns a bunch, containing training texts and training labels\ntext_train, y_train = reviews_train.data, reviews_train.target\nprint(\"type of text_train: {}\".format(type(text_train)))\nprint(\"length of text_train: {}\".format(len(text_train)))\nprint(\"text_train[6]:\\n{}\".format(text_train[6]))","af5b2068":"text_train = [doc.replace(b\"<br \/>\", b\" \") for doc in text_train]","c5b74e57":"np.unique(y_train)","86da7de8":"print(\"Samples per class (training): {}\".format(np.bincount(y_train)))","58fd3d3b":"reviews_test = load_files(\"data\/aclImdb\/test\/\")\ntext_test, y_test = reviews_test.data, reviews_test.target\nprint(\"Number of documents in test data: {}\".format(len(text_test)))\nprint(\"Samples per class (test): {}\".format(np.bincount(y_test)))\ntext_test = [doc.replace(b\"<br \/>\", b\" \") for doc in text_test]","94a17c6f":"from sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer().fit(text_train)\nX_train = vect.transform(text_train)\nprint(\"X_train:\\n{}\".format(repr(X_train)))","bf3a39aa":"feature_names = vect.get_feature_names()\nprint(\"Number of features: {}\".format(len(feature_names)))\nprint(\"First 20 features:\\n{}\".format(feature_names[:20]))\nprint(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\nprint(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))","7c0056b3":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nscores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\nprint(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))","4e7d60c7":"# C - apply regulation","c9a42b71":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\ngrid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\ngrid.fit(X_train, y_train)\nprint(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\nprint(\"Best parameters: \", grid.best_params_)","b52e8d5d":"X_test = vect.transform(text_test)\nprint(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))","d419c054":"vect = CountVectorizer(min_df=5).fit(text_train)\nX_train = vect.transform(text_train)\nprint(\"X_train with min_df: {}\".format(repr(X_train)))","7ed2b7af":"feature_names = vect.get_feature_names()\n\nprint(\"First 50 features:\\n{}\".format(feature_names[:50]))\nprint(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\nprint(\"Every 700th feature:\\n{}\".format(feature_names[::700]))","4c7a3774":"grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\ngrid.fit(X_train, y_train)\nprint(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))","073c45ee":"###  accuracy -> nan \n### this case is bad ","2be5c3ad":"max_dffloat in range [0.0, 1.0] or int, default=1.0\nWhen building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n\nmin_dffloat in range [0.0, 1.0] or int, default=1\nWhen building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.","a74a8825":"### get features","0fe10519":"# clean  train data ","d7ebc33e":"### get best params and predict train data","5fa1e352":"# load train data","58d719c1":"# load test data -> split data -> clean data","6334b82f":"### get features","ef94ef43":"# check train label percent","bce9ca1e":"### predict test data and get test score","f59d4654":"## cross validation ","1e636024":"# Case 1 - if min_df  == no limit ","1bfd2a98":"# Case 2 - if min_df == 5 ","8a404707":"# fetch data","2428ccf3":"# check train labels ","441d45d4":"### get best param and predict train data "}}