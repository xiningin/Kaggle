{"cell_type":{"2ec8c6f0":"code","cdd34ef3":"code","3d4d67e5":"code","931475af":"code","8b91d235":"code","6d27bdc1":"code","f9a600d9":"code","b4a72e37":"code","ffd84641":"code","ea077bd1":"code","a9d7739d":"code","63419b79":"code","89abded6":"code","005ce548":"code","0fa5f358":"code","dde4df99":"code","f58b0030":"code","b1702bb0":"code","76d4f3c4":"code","0f40ce73":"markdown"},"source":{"2ec8c6f0":"import sys\npackage_dir = \"..\/input\/pretrained-models\/pretrained-models\/pretrained-models.pytorch-master\/\"\nsys.path.insert(0, package_dir)\nimport numpy as np\nimport pandas as pd\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nfrom torchvision import transforms\nimport os\nimport pretrainedmodels\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","cdd34ef3":"class RetinopathyDatasetTest(Dataset):\n    def __init__(self, csv_file, transform):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join('..\/input\/aptos2019-blindness-detection\/test_images', self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n        image = self.transform(image)\n        return {'image': image}","3d4d67e5":"model = pretrainedmodels.__dict__['resnet101'](pretrained=None)\n\nmodel.avg_pool = nn.AdaptiveAvgPool2d(1)\nmodel.last_linear = nn.Sequential(\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.25),\n                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n                          nn.ReLU(),\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(in_features=2048, out_features=1, bias=True),\n                         )\nmodel.load_state_dict(torch.load(\"..\/input\/mmmodel\/model.bin\"))\nmodel = model.to(device)","931475af":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.eval()","8b91d235":"test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_dataset = RetinopathyDatasetTest(csv_file='..\/input\/aptos2019-blindness-detection\/sample_submission.csv',\n                                      transform=test_transform)","6d27bdc1":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds1 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds1[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","f9a600d9":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds2 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds2[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","b4a72e37":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds3 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds3[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","ffd84641":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds4 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds4[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","ea077bd1":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds5 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds5[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","a9d7739d":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds6 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds6[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","63419b79":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds7 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds7[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","89abded6":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds8 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds8[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","005ce548":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds9 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds9[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","0fa5f358":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds10 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"]\n    pred = model(x_batch.to(device))\n    test_preds10[i * 32:(i + 1) * 32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)","dde4df99":"test_preds = (test_preds1 + test_preds2 + test_preds3 + test_preds4 + test_preds5\n             + test_preds6 + test_preds7 + test_preds8 + test_preds9 + test_preds10) \/ 10.0","f58b0030":"coef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(test_preds):\n    if pred < coef[0]:\n        test_preds[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        test_preds[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        test_preds[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        test_preds[i] = 3\n    else:\n        test_preds[i] = 4\n\n\nsample = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","b1702bb0":"sample","76d4f3c4":"test_preds4","0f40ce73":"#### TTA for the lazy, like me"}}