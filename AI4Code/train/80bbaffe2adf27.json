{"cell_type":{"c316280e":"code","60970e31":"code","2c54cda0":"code","deda1456":"code","26ca92b8":"code","c0300322":"code","74158054":"code","96969760":"code","376ac0d2":"code","5a2d6918":"code","98d41dc8":"code","f53f8c1d":"markdown","f3501989":"markdown","d3a1a899":"markdown","cc304e89":"markdown","dce971bb":"markdown","75d5898d":"markdown","3ccaa2a1":"markdown","6d9f1f2e":"markdown","fa3643b9":"markdown","8ec98ef9":"markdown","5f36a3ce":"markdown"},"source":{"c316280e":"# First imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nimport random\nimport shutil","60970e31":"#Delete working directory from previous experiment if exists\nfileListToDelete = ['\/kaggle\/working\/train', '\/kaggle\/working\/validation', '\/kaggle\/working\/test']\nfor fileName in fileListToDelete:\n    try:\n        shutil.rmtree(fileName)\n        break\n    except:\n        print(\"Directory \",fileName,\" not found to delete.\")\n\n#Create directories for training, validation and test data\nsubdirs  = ['train\/', 'validation\/', 'test\/']\nfor subdir in subdirs:\n    labeldirs = ['CT_COVID', 'CT_NonCOVID']\n    for labldir in labeldirs:\n        newdir = subdir + labldir\n        os.makedirs(newdir, exist_ok=True)","2c54cda0":"# Copy randomly files from directories to working directory separated in train, validation and set with a likelihood of 70& train, 20% validation, 10% test\ntrain_size = 0        \nvalidation_size = 0\ntest_size = 0 \npath_COVID = os.path.join('\/kaggle\/input\/covidct\/CT_COVID\/')\npath_NonCOVID = os.path.join('\/kaggle\/input\/covidct\/CT_NonCOVID\/')\ncovid_images = glob(os.path.join(path_COVID,\"*.png\"))\ncovid_images.extend(glob(os.path.join(path_COVID,\"*.jpg\")))\nnoncovid_images = glob(os.path.join(path_NonCOVID,\"*.png\"))\nnoncovid_images.extend(glob(os.path.join(path_NonCOVID,\"*.jpg\")))\n\nfor filename in covid_images: #copy to positive directory\n    randNumber = random.uniform(0, 1)\n    if(randNumber<0.7) : #train set\n        shutil.copy(filename, \"\/kaggle\/working\/train\/CT_COVID\/\")\n        train_size = train_size + 1\n    elif(randNumber<0.9) : #validation set\n        shutil.copy(filename, \"\/kaggle\/working\/validation\/CT_COVID\/\")\n        validation_size = validation_size + 1\n    else: #test set\n        shutil.copy(filename, \"\/kaggle\/working\/test\/CT_COVID\/\")\n        test_size = test_size +1\n        \nfor filename in noncovid_images: #copy to negative directory\n    randNumber = random.uniform(0, 1)\n    if(randNumber<0.7) : #train set\n        shutil.copy(filename, \"\/kaggle\/working\/train\/CT_NonCOVID\/\")\n        train_size = train_size + 1\n    elif(randNumber<0.9) : #validation set\n        shutil.copy(filename, \"\/kaggle\/working\/validation\/CT_NonCOVID\/\")\n        validation_size = validation_size + 1\n    else: #test set\n        shutil.copy(filename, \"\/kaggle\/working\/test\/CT_NonCOVID\/\")\n        test_size = test_size +1","deda1456":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\n","26ca92b8":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2)\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","c0300322":"# Some variables\nIMG_HEIGHT = 150\nIMG_WIDTH = 150\ntrain_dir = os.path.join('\/kaggle\/working\/train\/')\nvalidation_dir = os.path.join('\/kaggle\/working\/validation')\ntest_dir = os.path.join('\/kaggle\/working\/test\/')\nbatch_size = 16\nepochs = 15","74158054":"print(\"Training set:\")\ntraining_set = train_datagen.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary')\nprint(\"Validation set:\")\nvalidation_set = train_datagen.flow_from_directory(batch_size=batch_size,\n                                                           directory=validation_dir,\n                                                           shuffle=True,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary')\nprint(\"Test set:\")\ntest_set = test_datagen.flow_from_directory(batch_size=batch_size,\n                                                              directory=test_dir,\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                              class_mode='binary')","96969760":"#Creation of the CNN\n\nclassifier = Sequential()                                                                           \n# Step 1 - Convolution\nclassifier.add(Conv2D(32, (3, 3), input_shape = (IMG_HEIGHT, IMG_WIDTH, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Conv2D(32, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Conv2D(32, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(units = 64, activation = 'relu'))\nclassifier.add(Dropout(0.4))\nclassifier.add(Dense(units = 1, activation = 'sigmoid'))\n\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nprint(classifier.summary())","376ac0d2":"#epochs = 2; #Uncomment to test quick\n#set early stopping criteria\nfrom keras.callbacks import EarlyStopping\nepochsWithOutImprovement = 3 #this is the number of epochs with no improvment after which the training will stop\nearly_stopping = EarlyStopping(monitor='val_loss', patience=epochsWithOutImprovement, verbose=1)\n                               \nhistory = classifier.fit_generator(training_set,\n                         steps_per_epoch = train_size,\n                         epochs = epochs,\n                         validation_data = validation_set,\n                         validation_steps = validation_size,\n                         callbacks=[early_stopping])","5a2d6918":"# Plot accuracy and loss over epochs\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","98d41dc8":"test_accuracy = classifier.evaluate_generator(test_set,steps=test_size)\nprint('Testing Accuracy with TEST SET: {:.2f}%'.format(test_accuracy[1] * 100))\n","f53f8c1d":"We set a stop criteria if there is no improvement in some epochs, to avoid an eternal training with too much epochs.\n","f3501989":"We'll start deleting previous output if it exist.","d3a1a899":"We'll use data augmentation with ImageDataGenerator() class from Keras to aid us to avoid overfitting.<br><br>\n\nThree separate sets for train, validation and test.<br>\nOne improvement here will be to use cross-validation and tune sizes of the sets.<br>\nAll images rescaled to 1.\/255 so we'll get a convenient value for the model between 0-1 (rescaled from 0-255).\nshear_range will randomly apply shear transformations to the data, zoom_range for randomly zooming images. only in the train set to avoid overfitting.<br>\nNot used parameters are horizontal_flip to randomly flip images in our dataset, rotation_range which is the value in degrees the image may be randomly rotated, width_shift_range and height_shift_range for randomly translating images.\n","cc304e89":"We test the accuracy with the test set, so we can get a more real idea of the performance of the model.","dce971bb":"Generation of training, validation and test set.","75d5898d":"We get to the creation of the CNN model.<br>\n*Conv2D -> MaxPooling -> Conv2D -> MaxPooling -> Conv2D -> MaxPooling -> Flatten -> Neural Network with Dropout*","3ccaa2a1":"We have the data as we wish, time to start with Keras!","6d9f1f2e":"Then we'll randomly copy files from input to output in train, validation and test directories.","fa3643b9":"As initial data is splitted randomly each time, we get different accuracy values for test set.<br>\nThis time we get **84.36%**\n\nThanks for your interest and remember I wish any feedback to learn and improve, and I would appreciate a vote too.\nRegards.","8ec98ef9":"Plot the accuracy and loss value over epochs","5f36a3ce":"<h1> Another Simple Convolutional Neural Network (First Notebook) <\/h1>\n\nSorry about my bad English ;-) (I'm not native...)<br>\nThe objective of this Notebook is create a simple to follow CNN to anyone interested and start practising and learning.<br>\nI would appreciate any feedback and of course a vote will motivate me to continue, but as the main objective is to learn I prefer coment focus on my learnig, what can be done better etc.\n\nPerhaps I'll improve this notebook with the comments, some of them I can imagine now as \"use cross validation\" but as it's a first minimun CNN (but I think it's ok for this objective) no more improvements to make it simple to understand will be made at the moment, maybe I will make a second version of the notebook if the improvements mean more than a marginal improvement of the result...<br>\nKindly regards to everyone reading this!!!"}}