{"cell_type":{"860492d0":"code","dca47e03":"code","ac6b1ee9":"code","ed8187ca":"code","a06af663":"code","e0099b2f":"code","0650e1da":"code","2334a54d":"code","32b930ac":"code","0cf21ffe":"code","af943231":"code","5e73b67e":"code","0eadd7e1":"code","29999969":"code","fbbdd930":"code","a88b4cc3":"code","a91d205c":"markdown","bfc123d3":"markdown","01d62161":"markdown","e357a243":"markdown","8161cef7":"markdown","ab026e39":"markdown","5e8a1a69":"markdown","19f412d8":"markdown","ee5ee97f":"markdown","b503a0cb":"markdown","0076266f":"markdown","c354c5ac":"markdown","1bd587e1":"markdown","2b443484":"markdown"},"source":{"860492d0":"from os import listdir\nimport cv2\nimport numpy as np\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras import models\nfrom keras.layers.convolutional import Conv2D\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nimport pickle","dca47e03":"default_image_size = tuple((256, 256))","ac6b1ee9":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None:\n            image =cv2.resize(image, default_image_size)\n            image =cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n            return img_to_array(image)\n        else:\n            return  np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","ed8187ca":"directory_root = '..\/input\/plantdiseasedataset\/plantdiseasedataset'","a06af663":"X=[]\nY=[]\ntry:\n    print(\"Foto\u011fraf Y\u00fckleniyor...\")\n    root_dir = listdir(directory_root)\n\n    for color_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}\/{color_folder}\")\n        \n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"{plant_disease_folder} Y\u00fckleniyor...\")\n            plant_disease_image_list = listdir(f\"{directory_root}\/{color_folder}\/{plant_disease_folder}\/\")\n\n            for image in plant_disease_image_list[:200]:\n                image_directory = f\"{directory_root}\/{color_folder}\/{plant_disease_folder}\/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    X.append(convert_image_to_array(image_directory))\n                    Y.append(plant_disease_folder)\n    print(\"Foto\u011fraf Y\u00fckleme Tamamland\u0131\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","e0099b2f":"Y_binarizer = LabelBinarizer()\nY = Y_binarizer.fit_transform(Y)\nprint(Y_binarizer.classes_)","0650e1da":"np_X = np.array(X,dtype=np.float16) \/ 255.0\n","2334a54d":"print(\"Veri Train Test Olarak Ayr\u0131l\u0131yor...\")\nx_train, x_test, y_train, y_test = train_test_split(np_X, Y, test_size=0.2, random_state = 42)","32b930ac":"DataAugmentation = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2,\n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","0cf21ffe":"model = models.Sequential()\ninputShape = (256, 256, 1)\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=inputShape))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(Dropout(0.50))\n\nmodel.add(layers.Dense(512, activation='relu'))\n\nmodel.add(layers.Dense(33, activation='softmax'))\n\nmodel.summary()","af943231":"model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(), metrics=['accuracy'])","5e73b67e":"history = model.fit_generator(DataAugmentation.flow(x_train, y_train,batch_size=32),validation_data=(x_test,y_test),steps_per_epoch=len(x_train)\/32, epochs=25, verbose=1)","0eadd7e1":"model_json=model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)","29999969":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'b', label='Training accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","fbbdd930":"model.save(\"model.h5\")\nprint(\"H5 ile model kaydedildi.\")","a88b4cc3":"pickle.dump(model,open('model.pkl','wb'))\nprint(\"Pickle ile model kaydedildi.\")","a91d205c":"Data augmentation i\u015flemi kullan\u0131larak modelin fit edilmesi.","bfc123d3":"Compile i\u00e7in uygun optimizer ve metric de\u011ferlerinin atanmas\u0131. 33 veri \u00fczerinde \u00e7al\u0131\u015f\u0131ld\u0131\u011f\u0131 i\u00e7in categorical crossentropy se\u00e7ildi.","01d62161":"Datan\u0131n diziye atanmas\u0131.","e357a243":"Veriseti i\u00e7erisindeki farkl\u0131 hastal\u0131kl\u0131 yaprak t\u00fcrlerine ait klas\u00f6rlerin labellar\u0131n al\u0131nmas\u0131.","8161cef7":"Veriseti \u00fczerinde train test ayr\u0131m\u0131n\u0131n ger\u00e7ekle\u015ftirilmesi. Train verisi 0.8 test verisi 0.2 olacak \u015fekilde ayr\u0131lmas\u0131.","ab026e39":"Model e\u011fitiminde ezberlemeyi \u00f6nleyerek ba\u015far\u0131m\u0131 artt\u0131rmak i\u00e7in yap\u0131lan i\u015flemlerden birisi data augmentation i\u015flemidir. Bu i\u015flem bize veriseti i\u00e7erisindeki foto\u011fraflar\u0131n farkl\u0131 k\u0131s\u0131mlar\u0131n\u0131 alarak, b\u00fcy\u00fcterek veya y\u00f6n\u00fcn\u00fc de\u011fi\u015ftirerek bir foto\u011fraf\u0131 birden fazla foto\u011fraf gibi g\u00f6sterip az bir veriseti ile model e\u011fitimi yap\u0131lsa dahi uygulanmad\u0131\u011f\u0131 duruma g\u00f6re daha iyi sonu\u00e7lar almam\u0131z\u0131 sa\u011flar.","5e8a1a69":"Model olu\u015fturma i\u015fleminin ger\u00e7ekle\u015ftirilmesi.","19f412d8":"Default image size atamanmas\u0131.","ee5ee97f":"Model predict edilerek accuracy score'un hesaplanmas\u0131. ","b503a0cb":"Modelin pickle ve h5 olarak kaydedilmesi.","0076266f":"Al\u0131nan dataset \u00fczerinden farkl\u0131 klas\u00f6rlerdeki hastal\u0131kl\u0131 yaprak foto\u011fraflar\u0131n\u0131n y\u00fcklenmesi.","c354c5ac":"Bir veri \u00f6n i\u015fleme \u00e7e\u015fidi olan normalizasyon i\u015fleminin ger\u00e7ekle\u015ftirilmesi.","1bd587e1":"Grafik g\u00f6rselle\u015ftirilmesi.","2b443484":"Kamera \u00fczerinden al\u0131nan g\u00f6r\u00fcnt\u00fc i\u00e7in kullan\u0131lmak \u00fczere modelin json olarak kaydedilmesi."}}