{"cell_type":{"cd6eb8ae":"code","1d2d2f28":"code","1a588874":"code","762270a3":"code","bbf05167":"code","71ca47bc":"code","e75ffe38":"code","1a585988":"code","eafddb56":"code","a809cbd1":"code","00a603a8":"code","bdd6c7ff":"code","aebb06b5":"code","75aa15e7":"code","f39a7076":"code","aaa51834":"code","2b07df8c":"code","526d6662":"code","4c9cfd31":"code","d93980ba":"code","6f8f857c":"code","66c986b3":"code","6a6daf95":"code","d1a26f35":"code","8f0b7b86":"code","ccf59c9d":"code","9933b3ce":"code","b2ec80b6":"code","cf7fc3bc":"code","2d7719b8":"code","b823e3ec":"code","aaaa2f25":"code","faaa2af4":"code","2a3829a3":"code","7979a8ed":"markdown","e77a9788":"markdown","2b1af85f":"markdown","2fa6ef95":"markdown","df45cbfa":"markdown","cb076ebb":"markdown","e2ce9afe":"markdown","3df7625e":"markdown","ab22b6db":"markdown","e5e85c9b":"markdown","754709a0":"markdown","6e58d62e":"markdown","37b5bdd0":"markdown","639a64a5":"markdown"},"source":{"cd6eb8ae":"#import libraries\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cufflinks as cf\nimport plotly.express as px\nfrom math import pi\nfrom plotly import __version__\n%matplotlib inline\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nfrom IPython.core.display import HTML\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom sklearn import metrics\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nfrom pandas import DataFrame\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL\n","1d2d2f28":"#import dataset\ndf=pd.read_csv(\"..\/input\/source-based-news-classification\/news_articles.csv\")","1a588874":"df.head()","762270a3":"df.info()","bbf05167":"df.shape","71ca47bc":"df.columns","e75ffe38":"df.isnull().sum()","1a585988":"df=df.dropna()\ndf.head()","eafddb56":"df.groupby('label').describe()","a809cbd1":"import pandas_profiling\ndf.profile_report()","00a603a8":"import seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.countplot(df['label']);","bdd6c7ff":"df['type'].value_counts().plot.pie(figsize = (15,12), startangle = 75,autopct = \"%.1f%%\",shadow=True)\nplt.title('Types of Articles', fontsize = 25)\nplt.axis('off')\nplt.legend()\nplt.show()","aebb06b5":"title_len=df['title'].apply(len)\ntext_len=df['text'].apply(len)\n\nplt.figure(figsize = (15,10))\n#sns.scatterplot(data=df, x=text_len, y=title_len,hue='label',style=\"label\",col='label')\nsns.relplot(\n    data=df, x=text_len, y=title_len,\n    col=\"label\", hue=\"label\", style=\"label\",\n    kind=\"scatter\"\n)\nplt.show()","75aa15e7":"sns.stripplot(x=\"label\", y=\"type\", data=df,size=8,palette=\"Set1\")\n","f39a7076":"plt.figure(figsize = (8,10))\nsns.set_style(\"dark\")\n#chart = sns.countplot(x = \"label\", hue = \"type\" , data = df , palette = 'muted')\n#chart.set_xticklabels(chart.get_xticklabels(),rotation=30)\n\nsns.catplot(x=\"label\", hue=\"type\", col=\"label\",\n                data=df, kind=\"count\",\n                height=4, aspect=.7);","aaa51834":"def get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_words(df['text_without_stopwords'], 20)\ncommon_words_df = DataFrame (common_words,columns=['word','freq'])\nfig = px.bar(common_words_df, x='word', y='freq',color='freq',\n             labels={'Top 20 word & their frequency'}, height=400)\n\nfig.show()","2b07df8c":"# Generate a word cloud image\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nstopwords = set(STOPWORDS)\nmask = np.array(Image.open(\"..\/input\/input-img\/News_mask.PNG\"))\n\n\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", mode=\"RGBA\", max_words=1000, mask=mask).generate(' '.join(df['text_without_stopwords']))\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[20,20])\nplt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.axis(\"off\")\n\n# store to file\nplt.savefig(\"news.png\", format=\"png\")\n  \n","526d6662":"# Generate word cloud\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(' '.join(df['text_without_stopwords']))\n\nplt.figure(figsize=[8,10])\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")","4c9cfd31":"# lower max_font_size, change the maximum number of word and lighten the background:\nwordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(' '.join(df['text_without_stopwords']))\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","d93980ba":"text = (' '.join(df['text_without_stopwords']))\nwordcloud = WordCloud().generate(text)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.figure()\nplt.show()","6f8f857c":"import seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.countplot(df['language'])","66c986b3":"def get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","6a6daf95":"fig = plt.subplots(figsize=(14,4))\ncommon_words = get_top_n_words(df['text_without_stopwords'], 20)\ndf2 = DataFrame (common_words,columns=['word','count'])\nchart = df2.groupby('word').sum()['count'].sort_values(ascending=False).plot(kind='bar')\nchart.set_xticklabels(chart.get_xticklabels(),rotation=45, horizontalalignment='right')\nchart.set_title(\"Top 20 Unigrams\",size=16)","d1a26f35":"fig = plt.subplots(figsize=(14,4))\ncommon_words = get_top_n_bigram(df['text_without_stopwords'], 20)\ndf3 = pd.DataFrame(common_words, columns = ['word' ,'count'])\nchart = df3.groupby('word').sum()['count'].sort_values(ascending=False).plot(kind='bar')\nchart.set_xticklabels(chart.get_xticklabels(),rotation=45, horizontalalignment='right')\nchart.set_title(\"Top 20 bigrams\",size=16)","8f0b7b86":"g = plt.subplots(figsize=(14,4))\ncommon_words = get_top_n_trigram(df['text_without_stopwords'], 10)\ndf4 = pd.DataFrame(common_words, columns = ['word' ,'count'])\nchart = df4.groupby('word').sum()['count'].sort_values(ascending=False).plot(kind='bar')\nchart.set_xticklabels(chart.get_xticklabels(),rotation=45, horizontalalignment='right')\nchart.set_title(\"Top 10 trigrams\",size=16)","ccf59c9d":"features = df[['site_url', 'text_without_stopwords']]\nfeatures.head(5)","9933b3ce":"features['url_text'] = features[\"site_url\"].astype(str) + \" \" + features[\"text_without_stopwords\"]\nfeatures.drop(['site_url', 'text_without_stopwords'], axis = 1, inplace = True)","b2ec80b6":"x = features\ny = df['label']","cf7fc3bc":"y = y.tolist()","2d7719b8":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)\n\ntfidf_vect = TfidfVectorizer(stop_words = 'english')\ntfidf_train = tfidf_vect.fit_transform(x_train['url_text'])\ntfidf_test = tfidf_vect.transform(x_test['url_text'])\ntfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vect.get_feature_names())","b823e3ec":"Random = RandomForestClassifier(n_estimators=150,random_state=0)\nRandom.fit(tfidf_train,y_train)\ny_pred = Random.predict(tfidf_test)\nRFscore = metrics.accuracy_score(y_test,y_pred)\nprint(\"accuracy:  %0.2f\" %(RFscore*100))","aaaa2f25":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\n\ncm=confusion_matrix(y_test, y_pred)\n\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)","faaa2af4":"Adab = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10),n_estimators=5,random_state=0)\nAdab.fit(tfidf_train, y_train)\ny_pred = Adab.predict(tfidf_test)\nABscore = metrics.accuracy_score(y_test,y_pred)\nprint(\"accuracy: %0.2f\" %(ABscore*100))","2a3829a3":"cm=confusion_matrix(y_test, y_pred)\n\nfig, ax = plot_confusion_matrix(conf_mat=cm,\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)","7979a8ed":"<h1 style=\"background-color:#ffffff;font-size:40px;font-family:Monaco;color:#045F5F;text-align:left;border-radius: 100px 100px;\">Exploratory Data Analysis \ud83d\udcca\ud83c\udfa8<\/h1>","e77a9788":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Distribution of Types of Artices<\/h1>","2b1af85f":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Different Languages of Articles<\/h1>","2fa6ef95":"<h1 style=\"background-color:#ffffff;font-size:60px;font-family:Monaco;color:#045F5F;text-align:Center;border-radius: 100px 100px;\">\ud83d\udcf0Fake News Recognization\ud83d\udd0d using NLP<\/h1>","df45cbfa":"<h1 style=\"background-color:#ffffff;font-size:40px;font-family:Monaco;color:#045F5F;text-align:left;border-radius: 100px 100px;\">Data Modelling \u26cf\ufe0f<\/h1>","cb076ebb":"<h1 style=\"background-color:#ffffff;font-size:40px;font-family:Monaco;color:#045F5F;text-align:left;border-radius: 100px 100px;\">Import Dataset \ud83d\uddc2\ufe0f<\/h1>","e2ce9afe":"<h1 style=\"background-color:#ffffff;font-size:40px;font-family:Monaco;color:#045F5F;text-align:left;border-radius: 100px 100px;\">Introduction \ud83d\udcd6\ud83d\udcd6<\/h1>\n<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Now a day's Fake news is an increasingly common concern in our society. The term 'Fake news' is refers as disinformation\/misleading information\/misinformation\/hoax\/rumor. which are actually different varients of false information. It is spread through traditional media such as News paper or by online medium such as websites and social media. Misleading information is spread to harm the reputation of the person  or an organization.<\/h1>\n\n","3df7625e":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Word_cloud \u2601\ufe0f<\/h1>","ab22b6db":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Unigram & Bigram<\/h1>","e5e85c9b":"<h1 style=\"background-color:#ffffff;font-size:40px;font-family:Monaco;color:#045F5F;text-align:left;border-radius: 100px 100px;\">Import Libraries \ud83d\udcda<\/h1>","754709a0":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Most Frequent word<\/h1>","6e58d62e":"\n<h1 style = \"font-size:30px; font-family:Papyrus ; font-weight : bold; color : #045F5F; text-align: center; border-radius: 10px 15px;\"> \ud83d\udcdaKeep Coding!!\ud83d\udc4d\ud83d\udc4d<\/h1>\n","37b5bdd0":"<h1 style=\"background-color:#FFFFFF;font-size:20px;color:#045F5F;font-weight : bold;font-family:Papyrus\">Let's check null values<\/h1>","639a64a5":"![fake-news.jpg](attachment:4de6f722-90f1-4e4e-bb42-571c5a894ef5.jpg)"}}