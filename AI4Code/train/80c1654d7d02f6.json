{"cell_type":{"06f5e367":"code","a0385fdd":"code","a414b24e":"code","384ca3e6":"code","f36a9683":"code","f3e5384a":"code","50f7d6d5":"code","9ab63c92":"code","1ef4114b":"code","1286fc8f":"code","708951f9":"code","520a2ed3":"code","6a01783b":"code","e695e9b9":"code","4e5b8f9e":"code","9ca0c07a":"code","caf26739":"code","23765586":"code","a69f7872":"code","30cb5ffd":"code","f145a751":"code","0031aafd":"markdown","390bb801":"markdown","e17ec3b8":"markdown","a301572c":"markdown","815277c8":"markdown","3a7a2c7f":"markdown","a58f35c0":"markdown","5ef8ee64":"markdown","9a23d3f8":"markdown","154acfde":"markdown","c5b74cfb":"markdown","8da3cfb5":"markdown","e94fad47":"markdown","817f932f":"markdown","2cfa703d":"markdown","20fb41ff":"markdown"},"source":{"06f5e367":"import matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nplt.style.use('fivethirtyeight')\nimport pickle \nimport os \nimport numpy as np\nimport cv2 \n%matplotlib inline","a0385fdd":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 200\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","a414b24e":"train = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\ntest = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\nval = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')","384ca3e6":"pnenumonia = 0 \nnormal = 0 \n\nfor i, j in train:\n    if j == 0:\n        pnenumonia+=1\n    else:\n        normal+=1\n        \nprint('Pneumonia:', pnenumonia)\nprint('Normal:', normal)\nprint('Pneumonia - Normal:', pnenumonia-normal)","f36a9683":"plt.imshow(train[1][0], cmap='gray')\nplt.axis('off')\nprint(labels[train[1][1]])","f3e5384a":"X = []\ny = []\n\nfor feature, label in train:\n    X.append(feature)\n    y.append(label)\n\nfor feature, label in test:\n    X.append(feature)\n    y.append(label)\n    \nfor feature, label in val:\n    X.append(feature)\n    y.append(label)\n\n\n# resize data for deep learning \nX = np.array(X).reshape(-1, img_size, img_size, 1)\ny = np.array(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=32)","50f7d6d5":"X_train = X_train \/ 255\nX_test = X_test \/ 255\nX_val = X_val \/ 255","9ab63c92":"# good for balancing out disproportions in the dataset \ndatagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=90, \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=True,  \n        vertical_flip=True)  \n\ndatagen.fit(X_train)","1ef4114b":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:], padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Conv2D(16, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nearly_stop = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\nadam = Adam(learning_rate=0.0001)\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['acc'])","1286fc8f":"model.summary()","708951f9":"history = model.fit(datagen.flow(X_train, y_train, batch_size=10), callbacks=[early_stop], validation_data=(X_val, y_val), epochs=15)","520a2ed3":"model.evaluate(X_test, y_test)","6a01783b":"plt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['acc'])\nplt.title('Model Accuracy')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['loss'])\nplt.title('Model Loss')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['val_acc'])\nplt.title('Model Validation Accuracy')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['val_loss'])\nplt.title('Model Validation Loss')\nplt.legend(['train'], loc='upper left')\nplt.show()","e695e9b9":"pred = model.predict(X_train)\nprecisions, recalls, thresholds = precision_recall_curve(y_train, pred)\nfpr, tpr, thresholds2 = roc_curve(y_train, pred)","4e5b8f9e":"def plot_precision_recall(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--')\n    plt.plot(thresholds, recalls[:-1], 'g-')\n    plt.title('Precision vs. Recall')\n    plt.xlabel('Thresholds')\n    plt.legend(['Precision', 'Recall'], loc='best')\n    plt.show()\n\ndef plot_roc(fpr, tpr):\n    plt.plot(fpr, tpr)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.title('FPR (False Positive rate) vs TPR (True Positive Rate)')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate (Recall)')\n    plt.show()\n    \nplot_precision_recall(precisions, recalls, thresholds)\nplot_roc(fpr, tpr)","9ca0c07a":"predictions = model.predict(X_test)","caf26739":"binary_predictions = []\nthreshold = thresholds[np.argmax(precisions >= 0.80)]\nfor i in predictions:\n    if i >= threshold:\n        binary_predictions.append(1)\n    else:\n        binary_predictions.append(0) ","23765586":"print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\nprint('Precision on testing set:', precision_score(binary_predictions, y_test))\nprint('Recall on testing set:', recall_score(binary_predictions, y_test))","a69f7872":"matrix = confusion_matrix(binary_predictions, y_test)\nplt.figure(figsize=(16, 9))\nax= plt.subplot()\nsns.heatmap(matrix, annot=True, ax = ax)\n\n# labels, title and ticks\nax.set_xlabel('Predicted Labels', size=20)\nax.set_ylabel('True Labels', size=20)\nax.set_title('Confusion Matrix', size=20) \nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)","30cb5ffd":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train.reshape(-1, img_size, img_size)[i], cmap='gray')\n    if(binary_predictions[i]==y_test[i]):\n        plt.xlabel(labels[binary_predictions[i]], color='blue')\n    else:\n        plt.xlabel(labels[binary_predictions[i]], color='red')\nplt.show()","f145a751":" model.save('pneumonia_detection_ai_version_3.h5')","0031aafd":"<h2>Reflection: <\/h2>\n<h3> There are a lot of rooms to improve. If you have any questions or suggestions, please leave a comment below.<\/h3>","390bb801":"<h2>Plotting the confusion matrix. Here is how we interpet one. <\/h2>\n\nImage source: https:\/\/silvrback.s3.amazonaws.com\/uploads\/4ab81a17-4a77-4e9e-b092-de5fac2afa07\/confusionmatrix_large.png","e17ec3b8":"<h2>Prepare data for precision vs. recall and ROC<\/h2>","a301572c":"<h2 >CNN (Convolutional Neural Network) <\/h2>\nImage source: https:\/\/www.researchgate.net\/publication\/321286547\/figure\/download\/fig6\/AS:564402564472832@1511575465150\/A-convolutional-neural-networks-CNN.png","815277c8":"<h2>This notebook tackles pneumonia classification using CNN (Convolutional Neural Network). In addition, this will also experiment with threshold values. \n\n<br><br>Pneumonia is an inflammatory condition of the lung affecting primarily the small air sacs known as alveoli. Typically, symptoms include some combination of productive or dry cough, chest pain, fever and difficulty breathing. <\/h2>\n\n<h3> Learn more from: <a href='https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/pneumonia'>World Health Organization<\/a> <\/h3>\n<br>Accuracy on testing set: 0.9104095563139932\n<br>Precision on testing set: 0.9148936170212766\n<br>Recall on testing set: 0.7962962962962963\n<center><img src='https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/2a\/Chest_X-ray_in_influenza_and_Haemophilus_influenzae_-_annotated.jpg\/1200px-Chest_X-ray_in_influenza_and_Haemophilus_influenzae_-_annotated.jpg' alt='Pneumonia' height='800' width='300'> <\/center>\n<p>Image Source: Wikipedia<\/p> ","3a7a2c7f":"![](https:\/\/www.researchgate.net\/publication\/321286547\/figure\/download\/fig6\/AS:564402564472832@1511575465150\/A-convolutional-neural-networks-CNN.png)","a58f35c0":"<h2>Download the model<\/h2>","5ef8ee64":"<h2>Visualize training images<\/h2>","9a23d3f8":"Data augmentation ","154acfde":"<h2>Visualizing our training progress<\/h2>","c5b74cfb":"<h2>Set thresholds for our model, we want the results to be precise while not sacraficing too much recall <\/h2>","8da3cfb5":"<h2>Process the images and resize them to the preferred size <\/h2>","e94fad47":"<h2>Preparing the training and testing data<\/h2>","817f932f":"![](https:\/\/silvrback.s3.amazonaws.com\/uploads\/4ab81a17-4a77-4e9e-b092-de5fac2afa07\/confusionmatrix_large.png)","2cfa703d":"<h2>View some results from a sample of 25 images<\/h2>","20fb41ff":"<h2 >We are incoprating the validation data into the training data because it does not contain enough examples. <\/h2>"}}