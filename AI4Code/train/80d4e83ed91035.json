{"cell_type":{"9e706c92":"code","048050c7":"code","a3b2337b":"code","5c532ece":"code","40d75815":"code","afa1d246":"code","0d98d15c":"code","9ecd5918":"code","a7166ce0":"code","46d9320c":"code","d88f3632":"code","c2049388":"code","b191b2f9":"code","c2d66411":"code","515228b9":"code","48247ce8":"code","dbaa4275":"code","5e85456e":"code","5d9fd0e2":"code","6de4a162":"code","ae4c272c":"code","51ae1ec9":"code","8c1d2cdf":"code","701b729b":"code","147648d9":"code","1bdfcc7e":"markdown"},"source":{"9e706c92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","048050c7":"!unzip ..\/input\/facial-keypoints-detection\/test.zip -d \/kaggle\/working\/\n!unzip ..\/input\/facial-keypoints-detection\/training.zip -d \/kaggle\/working\/","a3b2337b":"test = pd.read_csv(\".\/test.csv\")\ntrain = pd.read_csv(\".\/training.csv\")","5c532ece":"train.columns","40d75815":"train =train.dropna()","afa1d246":"df_without_images = train.drop(\"Image\",1)\nimages = train[\"Image\"]\n","0d98d15c":"df_without_images.head()","9ecd5918":"img_data = []\nfor img in images:\n    img = [int(i) for i in img.split(\" \")]\n    img = np.array(img)\n    img = img.reshape(96,96,1)\n    img_data.append(img)\nimg_data = np.array(img_data)","a7166ce0":"keypoint_features = []\nfor idx, features in df_without_images.iterrows():\n    keypoint_features.append(features)\nkeypoint_features = np.array(keypoint_features, dtype=float)","46d9320c":"img_data.shape","d88f3632":"rand_indexes = np.random.randint(0,img_data.shape[0],9)\nprint(rand_indexes)\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(3*4, 3*4))\nfor r in range(3):\n    for c in range(3):\n        idx = r * 3 + c\n        axes[r, c].imshow(img_data[rand_indexes[r+c]])\n        axes[r, c].scatter(keypoint_features[rand_indexes[r+c]][0::2], keypoint_features[rand_indexes[r+c]][1::2], s=20,c=\"white\")","c2049388":"norm_images = img_data \/ 255.0\nnorm_keypoints = keypoint_features \/ 96.0","b191b2f9":"import tensorflow as tf\ntf.random.set_seed(101)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,Activation,BatchNormalization\nfrom tensorflow.keras.models import Sequential,Model,load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","c2d66411":"def conv2d_model():\n    model = Sequential()\n    \n    model.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\n    pretrained_model = MobileNetV2(input_shape=(96,96,3), include_top=False, weights='imagenet')\n    pretrained_model.trainable = True\n    model.add(pretrained_model)\n    \n    model.add(Flatten())\n    #flatten = GlobalAveragePooling2D()(flatten)\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(32, activation=\"relu\"))\n\n    model.add(Dense(30))\n    model.compile(loss='mse', optimizer=Adam(learning_rate =0.003),metrics=['accuracy',\"mse\"])\n\n    return model","515228b9":"model = conv2d_model()","48247ce8":"model.summary()","dbaa4275":"EarlyStopper = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\ncheckpoint_path_quality = f\"\/kaggle\/working\/face_kp.h5\"\n\ncheckpoint = ModelCheckpoint(checkpoint_path_quality, \n                             monitor='mse', \n                             verbose=1,\n                             save_best_only=True, \n                             mode='min')\nlearning_rate_reduction = ReduceLROnPlateau(monitor='mse',\n                                            patience=2,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.000001)","5e85456e":"history = model.fit(norm_images,norm_keypoints, batch_size = 16,\n\tepochs=20,callbacks = [checkpoint,learning_rate_reduction,EarlyStopper])","5d9fd0e2":"test_images = test[\"Image\"]","6de4a162":"test_img_data = []\nfor img in test_images:\n    img = [int(i) for i in img.split(\" \")]\n    img = np.array(img)\n    img = img.reshape(96,96,1)\n    test_img_data.append(img)\ntest_img_data = np.array(test_img_data)\ntest_img_data = test_img_data\/ 255.0","ae4c272c":"loaded_model = load_model(\"\/kaggle\/working\/face_kp.h5\")","51ae1ec9":"test_predict = loaded_model.predict(test_img_data)","8c1d2cdf":"test_predict = test_predict * 96","701b729b":"rand_indexes = np.random.randint(0,test_img_data.shape[0],9)\nprint(rand_indexes)\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(3*4, 3*4))\nfor r in range(3):\n    for c in range(3):\n        idx = r * 3 + c\n        axes[r, c].imshow(test_img_data[rand_indexes[r+c]])\n        axes[r, c].scatter(test_predict[rand_indexes[r+c]][0::2], test_predict[rand_indexes[r+c]][1::2], s=20,c=\"white\")","147648d9":"idlookup_file = pd.read_csv('..\/input\/facial-keypoints-detection\/IdLookupTable.csv')\nfeature_names = list(idlookup_file['FeatureName'])\nimage_ids = list(idlookup_file['ImageId']-1)\nrow_ids = list(idlookup_file['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_predict[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","1bdfcc7e":"# Test"}}