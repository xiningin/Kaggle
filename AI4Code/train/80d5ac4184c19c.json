{"cell_type":{"1a12b4fa":"code","e05bc654":"code","d3242554":"code","19517154":"code","cebf1695":"code","bb1b56c1":"code","ea559d3b":"code","9d2bea65":"code","ad549226":"code","0d72aadc":"code","59bbee1b":"code","688c973e":"code","38170a24":"code","861c4ba3":"code","812f04fb":"code","18b04260":"code","17afec07":"code","d969125b":"code","1c56087d":"code","7bc6990b":"code","18b988fe":"markdown","45e9de23":"markdown","97b73ac3":"markdown","a84d5289":"markdown","ebc9a389":"markdown"},"source":{"1a12b4fa":"import pandas as pd\nratings=pd.read_csv('\/kaggle\/input\/the-movies-dataset\/ratings.csv')\ncredits=pd.read_csv('\/kaggle\/input\/the-movies-dataset\/credits.csv')\nmovie=pd.read_csv('\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv')\nlinks=pd.read_csv('\/kaggle\/input\/the-movies-dataset\/links.csv')\nmovie.head()","e05bc654":"#Mean of vote average column\nC=movie[\"vote_average\"].mean()\nprint(C)","d3242554":"#Calculate minimum no. of votes required to be in chart\nm=movie[\"vote_count\"].quantile(0.90)\nprint(m)","19517154":"# Filter out all qualified movies into a new DataFrame\nq_movie=movie.copy().loc[movie['vote_count']>=m]\nq_movie.shape","cebf1695":"movie.shape","bb1b56c1":"movie.describe()\n","ea559d3b":"q_movie.describe()\n","9d2bea65":"# function that compute the weighted rating of each movie\ndef weighted_rating(x,m=m,C=C):\n    v=x[\"vote_count\"]\n    R=x[\"vote_average\"]\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","ad549226":"# Define a new feature 'score' and calculate its value with `weighted_rating()`\nq_movie['score'] = q_movie.apply(weighted_rating, axis=1)","0d72aadc":"q_movie=q_movie.sort_values('score',ascending=False)\nq_movie[['title', 'vote_count', 'vote_average', 'score']].head(20)","59bbee1b":"#Print plot overviews of the first 5 movies.\nmovie['overview'].head()","688c973e":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntf=TfidfVectorizer(stop_words='english')\n\n#Replace NaN with an empty string\nmovie['overview']=movie['overview'].fillna('')\n\ntf_matrix=tf.fit_transform(movie[\"overview\"])\n\ntf_matrix.shape","38170a24":"#Array mapping from feature integer indices to feature name.\ntf.get_feature_names()[5000:5010]","861c4ba3":"from sklearn.metrics.pairwise import linear_kernel\n# Compute the cosine similarity matrix\ncosine_sim=linear_kernel(tf_matrix,tf_matrix)","812f04fb":"cosine_sim.shape","18b04260":"#Construct a reverse map of indices and movie titles\nindices=pd.Series(movie.index, index=movie['title']).drop_duplicates()","17afec07":"indices[:10]","d969125b":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return metadata['title'].iloc[movie_indices]","1c56087d":"get_recommendations('The Dark Knight Rises')","7bc6990b":"get_recommendations('The Godfather')","18b988fe":"It is not possible to compute the similarity between any two overviews in their raw forms. To do this, you need to compute the word vectors of each overview or document. Word vectors are vectorized representation of words in a document. The vectors carry a semantic meaning with it.\nTerm Frequency-Inverse Document Frequency (TF-IDF) vectors for each document.","45e9de23":"# Recommender System\nIt is a simple Recommender system which offer generalized recommendations to every user, based on movie popularity and\/or genre. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience. An example could be IMDB Top 250.\nThorugh this also can expand to Content based recommender or Collaborative filtering engines\n","97b73ac3":"## Content Based Recommendation\n### Plot Description Based Recommender\nBuild a system that recommends movies that are similar to a particular movie. To achieve this, you will compute pairwise cosine similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score threshold.","a84d5289":"## Don't Forget to Upvote if you Like the NoteBook!!","ebc9a389":"Since you are trying to build a clone of IMDB's Top 250, let's use its weighted rating formula as a metric\/score. Mathematically, it is represented as follows:\n\n#### WeightedRating(WR)=(vv+m\u22c5R)+(mv+m\u22c5C)\nIn the above equation,\n\n*v is the number of votes for the movie;*\n\n*m is the minimum votes required to be listed in the chart;*\n\n*R is the average rating of the movie;*\n\n*C is the mean vote across the whole report.*"}}