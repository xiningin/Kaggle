{"cell_type":{"136c0fe6":"code","4b75600e":"code","cb555e2c":"code","510efcbf":"code","1ac79dec":"code","f71aed8e":"code","5431ea7a":"code","3202c54c":"code","b5281a7f":"code","74f56897":"code","74cf672d":"code","1db8da46":"code","69f65f71":"code","b964c29c":"code","74d34955":"code","411d7d30":"code","0c0e4550":"code","f522de0c":"code","bc425fb8":"code","8246b411":"code","aa7047ff":"code","c5cd1b7c":"code","dbd8128a":"markdown","f36eb3b9":"markdown","fdcc1ae8":"markdown","1d3cacf9":"markdown","73f9c477":"markdown","de793efd":"markdown","d9ae18a5":"markdown","12b49033":"markdown","995cfc3f":"markdown","7930881f":"markdown","8abab8d1":"markdown","96b04dc5":"markdown","755e518c":"markdown","5295eafb":"markdown"},"source":{"136c0fe6":"# import required libraries\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, Activation\nfrom keras.layers import SeparableConv2D, MaxPool2D, BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","4b75600e":"import warnings\nwarnings.filterwarnings('ignore')","cb555e2c":"# define some variables for later usage\nepochs = 10\nimg_size = 150\nbatch_size = 32\ndrct_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/'","510efcbf":"fig, ax = plt.subplots(2, 3, figsize = (15, 9))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train', 'val', 'test']):\n    set_path = drct_path + _set\n    ax[i].imshow(plt.imread(set_path + '\/NORMAL\/' + os.listdir(set_path + '\/NORMAL')[0]), cmap = 'gray')\n    ax[i].set_title('Data: {} \\n Type: Normal'.format(_set), fontsize = 13)\n    ax[i+3].imshow(plt.imread(set_path + '\/PNEUMONIA\/' + os.listdir(set_path + '\/PNEUMONIA')[0]), cmap = 'gray')\n    ax[i+3].set_title('Data: {} \\n Type: Pneumonia'.format(_set), fontsize = 13)","1ac79dec":"# check the shape of some images from both types\nimg_n = plt.imread(set_path + '\/NORMAL\/' + os.listdir(set_path + '\/NORMAL')[0])\nimg_p = plt.imread(set_path + '\/PNEUMONIA\/' + os.listdir(set_path + '\/PNEUMONIA')[0])\nprint(f'Normal size:  {img_n.shape}')\nprint(f'Pneumonia size:  {img_p.shape}')","f71aed8e":"# check the no. of validating images for each type\nprint ('Normal counts: {}'.format(len(os.listdir(drct_path + 'val\/NORMAL\/'))))\nprint ('Pneumonia counts: {}'.format(len(os.listdir(drct_path + 'val\/PNEUMONIA\/'))))","5431ea7a":"# check the no. of test images for each type\nprint ('Normal counts: {}'.format(len(os.listdir(drct_path + 'test\/NORMAL\/'))))\nprint ('Pneumonia counts: {}'.format(len(os.listdir(drct_path + 'test\/PNEUMONIA\/'))))","3202c54c":"# check the no. of training images for each type\nprint ('Normal counts: {}'.format(len(os.listdir(drct_path + 'train\/NORMAL\/'))))\nprint ('Pneumonia counts: {}'.format(len(os.listdir(drct_path + 'train\/PNEUMONIA\/'))))","b5281a7f":"# ImageDataGenerator allows the network to \"see\" more diversified,\n# but still representative, data points during training\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255, # transform pixeles from range 0-255 to range 0-1\n                                   zoom_range = 0.3, # randomly zoom image \n                                   vertical_flip = True) # randomly flip images\n\n# load a mini batch of images directly from the source folder then convert them into a vector of attributes\ntraining_set = train_datagen.flow_from_directory(directory = drct_path + 'train',\n                                                 batch_size = batch_size,\n                                                 target_size = (img_size, img_size),\n                                                 shuffle = True,\n                                                 class_mode = 'binary')","74f56897":"# prepare test data\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_set = test_datagen.flow_from_directory(directory = drct_path + 'test',\n                                            batch_size = batch_size,\n                                            target_size = (img_size, img_size),\n                                            shuffle = True,\n                                            class_mode = 'binary')","74cf672d":"# prepare validation data\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nvalidation_set = val_datagen.flow_from_directory(directory = drct_path + 'val',\n                                                    batch_size = batch_size,\n                                                    target_size = (img_size, img_size),\n                                                    shuffle = True,\n                                                    class_mode = 'binary')","1db8da46":"model = Sequential()\n\n# 1st conv\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), input_shape = (img_size, img_size, 3), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size = (2, 2)))\n\n# 2nd conv\nmodel.add(SeparableConv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(SeparableConv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2, 2)))\n\n# 3rd conv\nmodel.add(SeparableConv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(SeparableConv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# 4th conv\nmodel.add(SeparableConv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(SeparableConv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.2))\n\n# 5th conv\nmodel.add(SeparableConv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(SeparableConv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.2))\n\n# fully connected layer\nmodel.add(Flatten())\nmodel.add(Dense(units = 512, activation = 'relu'))\nmodel.add(Dropout(rate = 0.7))\nmodel.add(Dense(units = 128, activation = 'relu'))\nmodel.add(Dropout(rate = 0.5))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dropout(rate = 0.3))\n\n# output layer\nmodel.add(Dense(units = 1, activation = 'sigmoid'))","69f65f71":"# show the complete summary of the model\nmodel.summary()","b964c29c":"# compile the sequential model\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","74d34955":"# callbacks\ncheckpoint = ModelCheckpoint(filepath = 'best_weights.hdf5', save_best_only = True, save_weights_only = True)\nlr_reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, patience = 2, verbose = 2, mode = 'max')\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.1, patience = 1, mode = 'min')","411d7d30":"# fit the data to the cnn model\ncnn = model.fit_generator(training_set,\n                          epochs = epochs,\n                          steps_per_epoch = training_set.samples \/\/ batch_size,\n                          validation_data = validation_set,\n                          validation_steps = test_set.samples \/\/ batch_size,\n                          callbacks = [checkpoint, lr_reduce])","0c0e4550":"from keras.preprocessing import image\nrand_img = np.random.randint(0, len(os.listdir(drct_path + 'val\/PNEUMONIA\/')))\nrand_img_path = drct_path + 'val\/PNEUMONIA\/' + os.listdir(drct_path + 'val\/PNEUMONIA\/')[rand_img]\n\nimg = plt.imread(rand_img_path)\nimg = cv2.resize(img, (img_size, img_size))\nimg = np.dstack([img, img, img])\nimg = img.astype('float32') \/ 255\nresult = model.predict(np.expand_dims(image.img_to_array(img), axis = 0))  \n\nif result[0][0] > 0.5:\n  prediction = 'Pnuemonia'\nelse:\n  prediction = 'Normal'\n  \nprint(f'Predicted : ' + prediction)\nprint ('Actual : Pnuemonia')\n\nimage = plt.imread(rand_img_path)\nplt.imshow(image)\nplt.title('Pnuemonia')\nplt.imshow(image, cmap = 'gray')\n","f522de0c":"fig, ax = plt.subplots(1, 2, figsize = (10, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(cnn.history[met])\n    ax[i].plot(cnn.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","bc425fb8":"test_data = []\ntest_labels = []\n\nfor title in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(drct_path + 'test' + title)):\n            img = plt.imread(drct_path + 'test' + title + img)\n            img = cv2.resize(img, (img_size, img_size))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if title == '\/NORMAL\/':\n                label = 0\n            elif title == '\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n# get predictions\npreds = model.predict(test_data)\n\nacc = accuracy_score(test_labels, np.round(preds))*100\n# get the confusion matrix\nmat = confusion_matrix(test_labels, np.round(preds))","8246b411":"from sklearn.metrics import ConfusionMatrixDisplay\ncmd = ConfusionMatrixDisplay(mat, display_labels=['Normal', 'Pneumonia'])\ncmd.plot(cmap = plt.cm.Blues)\nplt.title('Confusion Matrix')","aa7047ff":"# calculate precision and recall\ntn, fp, fn, tp = mat.ravel()\nprint('Test Metrics:')\nprecision = tp \/ (tp + fp) * 100\nrecall = tp \/ (tp + fn) * 100\nprint('Accuracy: {}%'.format(acc))\nprint('Precision: {}%'.format(precision))\nprint('Recall: {}%'.format(recall))\nprint('F1-score: {}'.format(2*precision*recall\/(precision+recall)))","c5cd1b7c":"print('Train Metric:')\nprint('Train accuracy: {}%'.format(np.round(cnn.history['accuracy'][-1]*100, 2)))","dbd8128a":"# Deep Learning for Automatic Pneumonia Detection","f36eb3b9":"# Build the Model","fdcc1ae8":"# Model Evaluation","1d3cacf9":"For the data augmentation, we gonna to:\n\n1. Rescale pixel values from the range of 0-255 to the range 0-1\n2. Randomly Zoom by 30% some training images\n3. Randomly flip images vertically","73f9c477":"This notebook builds and trains a convolutional neural network (CNN) from scratch to classify and detect the presence of pneumonia from a collection of chest X-ray image samples. The point of constructing the network from scratch is to extract features from a given chest X-ray image and classify it to determine a person as either having pneumonia or not having pneumonia.\n\nWhat makes this model distinctive is that it was trained from scratch, which separates it from other methods that rely heavily on transfer learning approach.","de793efd":"The above script shows how the dataset is highly imbalanced as the number of pneumonia classes by far exceeds the number of normal classes. However this is very normal situation  when it comes to medical data. Now we need to tackle this imbalanced issue","d9ae18a5":"Before start training we gonna define callbacks such as ModelCheckpoint to save a copy of the best performing model only when an epoch that improves the metrics ends, and EarlyStopping to prevent overfitting especially when difference between training and validation error) starts to increase","12b49033":"# Compile and Train the Model","995cfc3f":"We can handle this imbalanced issue by applying data augmentation technique to enlarge the size of the minority class (Normal images) in order to optimise the performance of the model and avoid overfitting. Moreover, data augmentation doesn't affect the distribution of labels in the original dataset\nand improve variance","7930881f":"We gonna build a CNN that has 5 Convolution layers. After each convolution, we will add a Pooling layer using max-pooling. After the final convolutional layer, we will add some Fully Connected layers after the flattening step, these nodes will act as an input layer to these fully-connected layers. Dense is the function to add a fully connected layer, \"units\" is where we define the number of nodes that should be present in this hidden layer. The last Fully Connected layer or the output layer has only 1 \"unit\" becuase it needs to predict the respective output (if someone has pneumonia)","8abab8d1":"Let's visualise the loss and accuracy plots","96b04dc5":"Let\u2019s plot the confusion matrix and get some other metrics like precision, recall, F1 score and accuracy","755e518c":"The model is able to achieve an accuracy greater 90% which is quite good considering the size of data that is used. Yet, the main reason behind this low accuracy is that we don't have enough observations as it's difficult to obtain a large amount of pneumonia dataset for this classification task, unlike other deep learning classification tasks that have sufficient image repository","5295eafb":"Now that we have trained our model lets see how it did on the data:"}}