{"cell_type":{"0cc2133e":"code","4133f80f":"code","bf848385":"code","21e44685":"code","5f96e285":"code","5aba1205":"code","39772e43":"code","b96571a2":"code","a85a2ad5":"code","c4b828c4":"code","6ef5adc6":"code","92092895":"code","67a1c457":"code","6f0ed0c2":"code","6cb70585":"code","3f1c8d45":"code","52f216ae":"code","2abf0aeb":"code","91f4efa2":"code","b929be50":"code","9340a455":"code","716f733b":"code","5e45dc4f":"code","b77a37c6":"code","dabe6eec":"code","519c68a2":"markdown","b87d3bc5":"markdown","c1088d2d":"markdown","08f745a8":"markdown","2d85c3bb":"markdown"},"source":{"0cc2133e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4133f80f":"import matplotlib.pyplot as plt\nimport seaborn as sns","bf848385":"import warnings\nwarnings.filterwarnings(\"ignore\")","21e44685":"train_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-oct-2021\/train.csv', sep=',')","5f96e285":"train_df.head()","5aba1205":"print('Dataset shape: ', train_df.shape )","39772e43":"train_df.info()","b96571a2":"train_df.describe().transpose()","a85a2ad5":"print(\"There are\", train_df.isna().any().sum(), \"missing values\")\nprint()\nprint(train_df.isna().sum())\nprint()\nprint(train_df.isnull().sum())","c4b828c4":"min_cat_n = train_df.select_dtypes(include='int64').drop(['id', 'target'], axis=1).nunique().min()\nmax_cat_n = train_df.select_dtypes(include='int64').drop(['id', 'target'], axis=1).nunique().max()\n\nprint('The minimum number of classes in the categorical variables is', min_cat_n)\nprint('The maximum number of classes in the categorical variables is', max_cat_n)","6ef5adc6":"fig, ax = plt.subplots(15,3, figsize=(15,25))\nax = ax.flatten()\ncolumns = train_df.select_dtypes(include='int64').drop(['id', 'target'], axis=1).columns\n\nfor i, column in enumerate(columns):\n    sns.countplot(x=train_df[column], ax=ax[i])\n\nplt.tight_layout()\nfig.show()","92092895":"# Target Distribution\nsns.countplot(train_df['target'])\nplt.title('Distribution of classes in target variable (target) \\n')\nplt.xlabel('Target')\nplt.ylabel('Count')","67a1c457":"fig, axes = plt.subplots(48,5,figsize=(15, 75))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\ncolumns = train_df.select_dtypes(include='float64').columns\n\nfor i, ax in enumerate(axes):\n    sns.kdeplot(data=train_df[columns], x=columns[i],ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(columns[i], loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average (float features)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","6f0ed0c2":"train_df.select_dtypes(include='float64').hist(figsize=(32, 32), sharey=True);\nplt.tight_layout()","6cb70585":"del train_df","3f1c8d45":"test_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv', sep=',')","52f216ae":"test_df.head()","2abf0aeb":"print('Dataset shape: ', test_df.shape )","91f4efa2":"test_df.info()","b929be50":"test_df.describe().transpose()","9340a455":"print(\"There are\", test_df.isna().any().sum(), \"missing values\")\nprint()\nprint(test_df.isna().sum())\nprint()\nprint(test_df.isnull().sum())","716f733b":"min_cat_n = test_df.select_dtypes(include='int64').drop(['id'], axis=1).nunique().min()\nmax_cat_n = test_df.select_dtypes(include='int64').drop(['id'], axis=1).nunique().max()\n\nprint('The minimum number of classes in the categorical variables is', min_cat_n)\nprint('The maximum number of classes in the categorical variables is', max_cat_n)","5e45dc4f":"fig, ax = plt.subplots(15,3, figsize=(15,25))\nax = ax.flatten()\ncolumns = test_df.select_dtypes(include='int64').drop(['id'], axis=1).columns\n\nfor i, column in enumerate(columns):\n    sns.countplot(x=test_df[column], ax=ax[i])\n\nplt.tight_layout()\nfig.show()","b77a37c6":"fig, axes = plt.subplots(48,5,figsize=(15, 75))\naxes = axes.flatten()\nsns.set_palette(sns.color_palette([\"#2a9d8f\", \"#e9c46a\"]))\ncolumns = test_df.select_dtypes(include='float64').columns\n\nfor i, ax in enumerate(axes):\n    sns.kdeplot(data=test_df[columns], x=columns[i],ax=ax,palette = [\"#2a9d8f\"])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    ax.spines['left'].set_visible(False)\n    ax.set_title(columns[i], loc='right', weight='bold', fontsize=10)\n\nfig.supxlabel('Average (float features)', ha='center', fontweight='bold')\n\nfig.tight_layout()\nplt.show()","dabe6eec":"test_df.select_dtypes(include='float64').hist(figsize=(32, 32), sharey=True);\nplt.tight_layout()","519c68a2":"# Train dataset\n\nLets first explore the train dataset and subsequently the test dataset.","b87d3bc5":"# Summary 1\n\nThe dataset contains 1 million of rows and 287 variables. Of those 287, 240 variables are of float64 type and 47 of int type. Those of int type suggest some categorical variables, lets verify how many categories are there among these variables.","c1088d2d":"# Tabular Playground Series - Oct 2021\n\nThe tabular series on kaggle are meant to help novices in data science field like me get acquainted with kaggle competitions.\n\nThe dataset created for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the biological response of molecules given various chemical properties. \n\nThe first step in almost every data science project is to perfom some exploratory data analysis. This is what we will present here in this notebook.","08f745a8":"# Summary 2\n\nAs can be seen, the target variable isn't unbalanced, however there are many categorical variables that are unbalanced. When trainning a model we can test removing those to see how they affect the overall performance. \n\nNow lets check the non-categorical variables distribution.","2d85c3bb":"# Test dataset\n\nHere we will do the same analysis to test datast "}}