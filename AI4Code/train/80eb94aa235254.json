{"cell_type":{"557592ce":"code","272732a3":"code","f6c489ae":"code","ae50b137":"code","60894c5c":"code","3b747cb3":"code","c2258185":"code","f7305d42":"code","52ee17c9":"code","79683d94":"code","9b7d5c1c":"code","5d566805":"code","8bc6cfaf":"code","4d1dfd78":"code","498fbbc6":"code","e8921164":"code","a86150ff":"code","12dacaad":"code","a4bb6bba":"code","b4d11804":"code","59c826fc":"code","794bb97c":"code","8d508675":"code","8050cf4f":"markdown","38c943b7":"markdown","1c3475bb":"markdown","dbb9ef5d":"markdown","a21cd93a":"markdown","6fdcdf95":"markdown","b63d2aea":"markdown","e5f24903":"markdown","71380137":"markdown","c44bb0ca":"markdown"},"source":{"557592ce":"from IPython.display import display\nimport gc\nimport joblib as jb\nfrom tqdm.auto import tqdm, trange\n\n# data manipulation\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection, pipeline\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# unsupervised learning\nfrom sklearn import decomposition, cluster\n\n# supervised learning\nfrom sklearn import metrics, feature_selection, linear_model, ensemble, svm","272732a3":"df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", index_col=0)\n\ndisplay(df.head())\nprint(\"\\nEntries: {}\".format(df.shape[0]))\nprint(\"Features: {}\".format(df.shape[1]))","f6c489ae":"# replace None string with NaN\nprint(\"'None' labels: {}\".format((df == \"None\").sum().sum()))\ndf = df.replace(\"None\", np.nan)","ae50b137":"null_pct = (df.isnull().sum() \/ df.shape[0] * 100).loc[lambda x: x!=0]\n\nfig,ax = plt.subplots(figsize=(15,5))\nax.set_title(\"Null values percentage\")\nax.set_xlabel(\"feature\")\nax.set_ylabel(\"percentage (%)\")\nax.tick_params(axis=\"x\", rotation=45)\nax.grid(axis=\"y\")\nax = sns.barplot(x=null_pct.index, y=null_pct.values, color=\"C0\", ax=ax)\n\ndel null_pct","60894c5c":"df = df.drop(columns=\"PoolQC\")","3b747cb3":"# fill missing values\nprint(\"Missing values filled: {}\".format(df.isnull().sum().sum()))\ndf = df.fillna(value=0)","c2258185":"# encode labels\nlabel_encoders = {}\nfor col in df.dtypes.loc[lambda x: x==object].index:\n    label_encoders[col] = preprocessing.LabelEncoder().fit(df.loc[df.loc[:,col] != 0, col].values)\n    df.loc[df.loc[:,col] != 0, col] = label_encoders[col].transform(df.loc[df.loc[:,col] != 0, col].values) + 1 # 0 value has been used previously for null values","f7305d42":"train, valid = model_selection.train_test_split(df, train_size=0.7, random_state=1)\nprint(\"Train shape: {}\".format(train.shape))\nprint(\"Valid shape: {}\".format(valid.shape))","52ee17c9":"target = \"SalePrice\"\n\ndef get_arr(df, target = \"SalePrice\"):\n    return df.drop(columns=target), df.loc[:,target]\n\nx_train, y_train = get_arr(train)\nx_valid, y_valid = get_arr(valid)","79683d94":"pca_pipe = pipeline.Pipeline([\n    (\"scaler\", preprocessing.StandardScaler()),\n    (\"pca\", decomposition.PCA(random_state=1))\n])\npca_pipe = pca_pipe.fit(x_train)\n\npca = pca_pipe.named_steps[\"pca\"]\nax = sns.lineplot(x=np.arange(1,pca.n_components_+1), y=pca.explained_variance_ratio_.cumsum())\nax.set_title(\"PCA\")\nax.set_xlabel(\"components\")\n_ = ax.set_ylabel(\"cumulative explained var. ratio\")","9b7d5c1c":"def get_inertia(n, x_train):\n    cluster_pipe = pipeline.Pipeline([\n        (\"scaler\", preprocessing.StandardScaler()),\n        (\"cluster\", cluster.KMeans(n_clusters=n, random_state=1))\n    ])\n    cluster_pipe = cluster_pipe.fit(x_train)\n    return cluster_pipe.named_steps[\"cluster\"].inertia_\n\nN = 200\ninertia = jb.Parallel(n_jobs=-1)(jb.delayed(get_inertia)(n, x_train) for n in trange(1,N+1, leave=False))\n\nax = sns.lineplot(x=np.arange(1,N+1), y=inertia)\nax.set_title(\"KMeans\")\nax.set_xlabel(\"clusters\")\n_ = ax.set_ylabel(\"inertia\")","5d566805":"N = 25 # clusters\n\ncluster_pipe = pipeline.Pipeline([\n    (\"scaler\", preprocessing.StandardScaler()),\n    (\"cluster\", cluster.KMeans(n_clusters=N, random_state=1))\n])\ncluster_pipe = cluster_pipe.fit(x_train)\n\ntrain.insert(loc=train.shape[1], column=\"Cluster\", value=cluster_pipe.predict(x_train))\nvalid.insert(loc=valid.shape[1], column=\"Cluster\", value=cluster_pipe.predict(x_valid))\n\nx_train, y_train = get_arr(train)\nx_valid, y_valid = get_arr(valid)","8bc6cfaf":"def perform_model(x_train, y_train, x_valid, y_valid, estimator, cv_param_grid):\n    \n    cv = model_selection.GridSearchCV(\n        estimator=estimator, param_grid=cv_param_grid,\n        scoring=\"neg_mean_squared_error\", n_jobs=-1\n    )\n    \n    estimator = cv.fit(x_train, y_train).best_estimator_\n    \n    print(\"CV best params:\")\n    display(pd.Series(cv.best_params_))\n    print()\n\n    y_pred = estimator.predict(x_valid)\n    print(\"Valid MSE: {:.2f}\".format(metrics.mean_squared_error(y_valid, y_pred)))\n    \n    return estimator, cv","4d1dfd78":"forest_model, forest_cv = perform_model(\n    x_train, y_train, x_valid, y_valid,\n    ensemble.RandomForestRegressor(random_state=1, n_jobs=-1),\n    cv_param_grid={\"n_estimators\": [100, 500, 1000, 5000], \"min_samples_split\": [None, 0.2, 0.5], \"max_features\": [\"auto\", \"sqrt\"]}\n)","498fbbc6":"fig,ax = plt.subplots(figsize=(7,15))\nax = sns.barplot(x=forest_model.feature_importances_, y=x_train.columns, color=\"C0\", ax=ax)","e8921164":"boosted_model, boosted_cv = perform_model(\n    x_train, y_train, x_valid, y_valid,\n    ensemble.GradientBoostingRegressor(random_state=1),\n    cv_param_grid={\"n_estimators\": [100, 500, 1000, 5000], \"min_samples_split\": [None, 0.2, 0.5], \"max_features\": [\"auto\", \"sqrt\"]}\n)","a86150ff":"fig,ax = plt.subplots(figsize=(7,15))\nax = sns.barplot(x=boosted_model.feature_importances_, y=x_train.columns, color=\"C0\", ax=ax)","12dacaad":"svm_pipe, svm_pipe_cv = perform_model(\n    x_train, y_train, x_valid, y_valid,\n    pipeline.Pipeline([(\"scaler\", preprocessing.StandardScaler()), (\"svm\", svm.SVR(tol=1e-4, cache_size=1024))]),\n    cv_param_grid={\"svm__kernel\": [\"linear\", \"poly\", \"rbf\"], \"svm__C\": [1e-2, 1e-1, 1, 10]}\n)","a4bb6bba":"rmsle = np.array([metrics.mean_squared_log_error(y_valid, estimator.predict(x_valid))**0.5 for estimator in [forest_model, boosted_model, svm_pipe]])\nprint(\"RMSLE: {}\".format(rmsle))","b4d11804":"model = [forest_model, boosted_model, svm_pipe][rmsle.argmin()]\nprint(\"Best model: \" + [\"RandomForest\", \"GradientBoosting\", \"SVR\"][rmsle.argmin()])\nprint(\"Best RMSLE: {:.2f}\".format(rmsle.min()))","59c826fc":"x_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\", index_col=0)\nx_test.head()","794bb97c":"# preprocess\nx_test = x_test.replace(\"None\", np.nan)\nx_test = x_test.drop(columns=\"PoolQC\")\nx_test = x_test.fillna(value=0)\n\n# labels\nfor col,encoder in label_encoders.items():\n    x_test.loc[x_test.loc[:,col] != 0, col] = encoder.transform(x_test.loc[x_test.loc[:,col] != 0, col]) + 1\n\n# cluster\nx_test.insert(loc=x_test.shape[1], column=\"Cluster\", value=cluster_pipe.predict(x_test))","8d508675":"submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\", index_col=0)\nsubmission.SalePrice = model.predict(x_test)\nsubmission.to_csv(\"submission.csv\")","8050cf4f":"# Clustering","38c943b7":"Clusters inertia elbow is around $25$ clusters.","1c3475bb":"# Supervised learning","dbb9ef5d":"Some missing values are valid and registered with `None` label. To avoid leaving them in data they are replaced with `NaN` to be filled afterwards with other missing values.","a21cd93a":"# Submission","6fdcdf95":"# Dataset preprocessing","b63d2aea":"`PoolQC` does not contain any value, so it is removed.","e5f24903":"Remaining missing values can be replaced with $0$. Features with floats does not contain $0$ and categorical features will be encoded with values in range $[1,\\text{N}]$ with $\\text{N}$ number of categories.","71380137":"# Principal Component Analysis","c44bb0ca":"PCA shows that is not possible to reduce very much the original dimensionality because of the slow rise of cumulative explained variance ratio value."}}