{"cell_type":{"73c182ce":"code","e4241eb2":"code","108c3037":"code","4a3c7149":"code","407e478b":"code","afb755f1":"code","5fea7785":"code","ca43c601":"code","b0430d37":"code","a3f05a68":"code","bff724a8":"code","1a3bf819":"code","5bbce487":"code","9cf0c5a2":"code","16dc7174":"code","ea1ece59":"code","d5d64be2":"code","458f600b":"code","38edfa47":"code","63c779e8":"code","b8a5a164":"code","32e0b7b9":"code","e3feee22":"code","4c4198cc":"code","10b6e2d1":"code","49f9b337":"code","df261759":"code","fca13388":"code","418ab847":"code","c30fe5e4":"code","3f4562c4":"code","b706ac48":"code","fdb0bf6b":"code","2ac941f6":"code","efecaf3b":"code","9eb0ed31":"code","a6651293":"code","8e6f85d4":"code","849e3e0c":"code","87a12d69":"code","25dcb666":"code","1e6dae10":"code","e59c5f02":"code","02321891":"code","caa6b2e8":"code","917f56d9":"code","3e5c287c":"markdown","c17894ef":"markdown","7bb13922":"markdown","27805e78":"markdown","22c2357b":"markdown"},"source":{"73c182ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4241eb2":"data=pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\")\ndata.head()","108c3037":"data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\ndata.head()","4a3c7149":"data['v1'].unique()","407e478b":"data=data.rename(columns = {\"v1\" : \"target\", \"v2\" : \"sms\"})","afb755f1":"data.head()","5fea7785":"data['lenght']=data['sms'].str.len()","ca43c601":"data.head()","b0430d37":"y=pd.get_dummies(data['target'], drop_first = True)\ndata=pd.concat([data,y],axis=1)\ndata.drop(\"target\",axis=1,inplace=True)","a3f05a68":"def meassage_lenght(msg):\n    msg_words=msg.split(\" \")\n    len_msg=len(msg_words)\n    \n    return len_msg","bff724a8":"print(meassage_lenght(data.iloc[1][0]))","1a3bf819":"data['word_count']=data['sms'].apply(meassage_lenght)","5bbce487":"data.head()","9cf0c5a2":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.hist(data['word_count'],bins=50,alpha=0.5)\nplt.hist(data['lenght'],bins=50,alpha=0.5)\nplt.xlabel(\"word lenght\")\nplt.ylabel(\"Group lenght\")\nplt.title(\"word Lenght histgoramm\")","16dc7174":"data1=data[(data['word_count']>80) & (data['lenght']>100)]","ea1ece59":"data1","d5d64be2":"import string\nstring.punctuation","458f600b":"def remove_punctuation(text):\n    new_text=\"\".join([char for char in text if char not in string.punctuation])\n    return new_text","38edfa47":"data['new_sms']=data['sms'].apply(lambda row:remove_punctuation(row))","63c779e8":"data.head()","b8a5a164":"import re\ndef tockenize(text):\n    tokens=re.split('\\W+',text)\n    return tokens","32e0b7b9":"data['tokenized_row']=data['new_sms'].apply(lambda row:tockenize(row.lower()))","e3feee22":"data.head()","4c4198cc":"import nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstopwords[:5]","10b6e2d1":"def revomestopword(text):\n    clean_text=[char for char in text if char not in stopwords]\n    return clean_text","49f9b337":"data['clean_text']=data['tokenized_row'].apply(lambda x: revomestopword(x))","df261759":"data.head()","fca13388":"import nltk\nfrom nltk.stem.porter import *\nps=PorterStemmer()\nfrom nltk import PorterStemmer\ndef stemming(tokenized_row):\n    stemmed_text=[ps.stem(char) for char in tokenized_row]\n    return stemmed_text","418ab847":"data['stemmed_text']=data['clean_text'].apply(lambda char :stemming(char))","c30fe5e4":"data[['sms','stemmed_text']].head()","3f4562c4":"def final_text(stemmed_text):\n    final_text=\" \".join(char for char in stemmed_text)\n    return final_text","b706ac48":"data['final_text']=data['stemmed_text'].apply(lambda x:final_text(x))","fdb0bf6b":"data.head()","2ac941f6":"df=data.drop(['new_sms','tokenized_row','clean_text','stemmed_text','word_count'],axis=1)","efecaf3b":"df.head()","9eb0ed31":"x=df.drop(['spam'],axis=1)\ny=df['spam']","a6651293":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","8e6f85d4":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\ncv=CountVectorizer(max_features=500)\ntemp_train=cv.fit_transform(x_train['final_text']).toarray()\ntemp_test=cv.transform(x_test['final_text']).toarray()","849e3e0c":"tf=TfidfTransformer()\ntemp_train=tf.fit_transform(temp_train)\ntemp_test=tf.transform(temp_test)","87a12d69":"temp_train=pd.DataFrame(temp_train.toarray(),index=x_train.index)\ntemp_test=pd.DataFrame(temp_test.toarray(),index=x_test.index)\nx_train=pd.concat([x_train,temp_train],axis=1,sort=False)\nx_test=pd.concat([x_test,temp_test],axis=1,sort=False)","25dcb666":"x_train.head()","1e6dae10":"x_train.drop(['sms','final_text'],axis=1,inplace=True)\nx_test.drop(['sms','final_text'],axis=1,inplace=True)\nx_train.head()","e59c5f02":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","02321891":"model=MultinomialNB()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_score:\",accuracy_score(y_test,y_pred))","caa6b2e8":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_Score:\",accuracy_score(y_test,y_pred))","917f56d9":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_score:\",accuracy_score(y_test,y_pred))","3e5c287c":"# Count Vectorization\nIt involves counting the number of occurrences of each word\/token in a given text.","c17894ef":"# Random Forest","7bb13922":"# Multinomial Naive Bayes","27805e78":"# Decision Tree","22c2357b":"# Model Train"}}