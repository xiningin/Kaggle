{"cell_type":{"34fb2f82":"code","3e09dc60":"code","aa9d1a82":"code","25557e14":"code","ad1ff88a":"code","d23f6cff":"code","0203a3a0":"code","11409e5e":"code","289908c5":"code","a3856516":"code","ed8f1cdb":"code","7291fc2f":"code","54eb52d6":"code","d352cc30":"code","b713244e":"code","18ab50ee":"code","984ff721":"code","1b73318d":"code","256106eb":"code","1d4c9eca":"code","15468075":"code","506651ac":"code","6693bd51":"code","ae3aab27":"code","699a0029":"code","b83eabf2":"code","e531f2e6":"code","f50076e8":"code","b594feb0":"code","d07a11b7":"code","3626d014":"code","1c95d106":"code","1429a017":"code","7afe0f13":"code","33aee4b9":"code","e8ad69ff":"code","7691b201":"code","6eb43f8e":"code","27682acc":"markdown","9e2639c0":"markdown","a79d107e":"markdown","ea380a8a":"markdown","19d60eab":"markdown","dde6aeda":"markdown","86583910":"markdown","ac5c6e6b":"markdown","5d51aa25":"markdown","a3d0c347":"markdown","f7f02643":"markdown","1f0c2d48":"markdown","56af895b":"markdown","7cfc25f9":"markdown","d6113c46":"markdown","11f0ffb9":"markdown","fc224fa4":"markdown","85039013":"markdown","2ef19d1b":"markdown","813fc74e":"markdown","1bc66a47":"markdown","c5721a24":"markdown","735a13b4":"markdown"},"source":{"34fb2f82":"!pip install -q -U pip\n!pip install -q -U seaborn","3e09dc60":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport cv2\nimport tifffile","aa9d1a82":"BASE_PATH = \"..\/input\/hubmap-kidney-segmentation\/\"\nTRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n\nprint(os.listdir(BASE_PATH))","25557e14":"df_train = pd.read_csv(\n    os.path.join(BASE_PATH, \"train.csv\")\n)\ndf_train","ad1ff88a":"df_sub = pd.read_csv(\n    os.path.join(BASE_PATH, \"sample_submission.csv\"))\ndf_sub","d23f6cff":"print(f\"Number of train images: {df_train.shape[0]}\")\nprint(f\"Number of test images: {df_sub.shape[0]}\")","0203a3a0":"df_info = pd.read_csv(\n    os.path.join(BASE_PATH, \"HuBMAP-20-dataset_information.csv\")\n)\ndf_info.sample(3)","11409e5e":"# https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef rle2mask(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [\n        np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])\n    ]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape).T\n\n\ndef read_image(image_id, scale=None, verbose=1):\n    image = tifffile.imread(\n        os.path.join(BASE_PATH, f\"train\/{image_id}.tiff\")\n    )\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    mask = rle2mask(\n        df_train[df_train[\"id\"] == image_id][\"encoding\"].values[0], \n        (image.shape[1], image.shape[0])\n    )\n    \n    if verbose:\n        print(f\"[{image_id}] Image shape: {image.shape}\")\n        print(f\"[{image_id}] Mask shape: {mask.shape}\")\n    \n    if scale:\n        new_size = (image.shape[1] \/\/ scale, image.shape[0] \/\/ scale)\n        image = cv2.resize(image, new_size)\n        mask = cv2.resize(mask, new_size)\n        \n        if verbose:\n            print(f\"[{image_id}] Resized Image shape: {image.shape}\")\n            print(f\"[{image_id}] Resized Mask shape: {mask.shape}\")\n        \n    return image, mask\n\n\ndef read_test_image(image_id, scale=None, verbose=1):\n    image = tifffile.imread(\n        os.path.join(BASE_PATH, f\"test\/{image_id}.tiff\")\n    )\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    if verbose:\n        print(f\"[{image_id}] Image shape: {image.shape}\")\n    \n    if scale:\n        new_size = (image.shape[1] \/\/ scale, image.shape[0] \/\/ scale)\n        image = cv2.resize(image, new_size)\n        \n        if verbose:\n            print(f\"[{image_id}] Resized Image shape: {image.shape}\")\n        \n    return image\n\n\ndef plot_image_and_mask(image, mask, image_id):\n    plt.figure(figsize=(16, 10))\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(f\"Image {image_id}\", fontsize=18)\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(image)\n    plt.imshow(mask, cmap=\"hot\", alpha=0.5)\n    plt.title(f\"Image {image_id} + mask\", fontsize=18)    \n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(mask, cmap=\"hot\")\n    plt.title(f\"Mask\", fontsize=18)    \n    \n    plt.show()\n    \n    \ndef plot_grid_image_with_mask(image, mask):\n    plt.figure(figsize=(16, 16))\n    \n    w_len = image.shape[0]\n    h_len = image.shape[1]\n    \n    min_len = min(w_len, h_len)\n    w_start = (w_len - min_len) \/\/ 2\n    h_start = (h_len - min_len) \/\/ 2\n    \n    plt.imshow(image[w_start : w_start + min_len, h_start : h_start + min_len])\n    plt.imshow(\n        mask[w_start : w_start + min_len, h_start : h_start + min_len], cmap=\"hot\", alpha=0.5,\n    )\n    plt.axis(\"off\")\n            \n    plt.show()\n    \n\ndef plot_slice_image_and_mask(image, mask, start_h, end_h, start_w, end_w):\n    plt.figure(figsize=(16, 5))\n    \n    sub_image = image[start_h:end_h, start_w:end_w, :]\n    sub_mask = mask[start_h:end_h, start_w:end_w]\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(sub_image)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(sub_image)\n    plt.imshow(sub_mask, cmap=\"hot\", alpha=0.5)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(sub_mask, cmap=\"hot\")\n    plt.axis(\"off\")\n    \n    plt.show()","289908c5":"small_ids = [\n    \"0486052bb\", \"095bf7a1f\", \"1e2425f28\", \"2f6ecfcdf\",\n    \"54f2eec69\", \"aaa6a05cc\", \"cb2d976f4\", \"e79de561c\",\n]\nsmall_images = []\nsmall_masks = []\n\nfor small_id in small_ids:\n    tmp_image, tmp_mask = read_image(small_id, scale=20, verbose=0)\n    small_images.append(tmp_image)\n    small_masks.append(tmp_mask)","a3856516":"plt.figure(figsize=(16, 16))\nfor ind, (tmp_id, tmp_image) in enumerate(zip(small_ids, small_images)):\n    plt.subplot(3, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.axis(\"off\")","ed8f1cdb":"plt.figure(figsize=(16, 16))\nfor ind, (tmp_id, tmp_image, tmp_mask) in enumerate(zip(small_ids, small_images, small_masks)):\n    plt.subplot(3, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.imshow(tmp_mask, cmap=\"hot\", alpha=0.5)\n    plt.axis(\"off\")","7291fc2f":"small_ids = [\n    \"26dc41664\", \"afa5e8098\", \"b2dc8411c\", \"b9a3865fc\", \"c68fe75ea\",\n]\nsmall_images = []\n\nfor small_id in small_ids:\n    tmp_image = read_test_image(small_id, scale=20, verbose=0)\n    small_images.append(tmp_image)","54eb52d6":"plt.figure(figsize=(16, 11))\nfor ind, (tmp_id, tmp_image) in enumerate(zip(small_ids, small_images)):\n    plt.subplot(2, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.axis(\"off\")","d352cc30":"image_id = \"0486052bb\"\nimage, mask = read_image(image_id, 2)","b713244e":"plot_image_and_mask(image, mask, image_id)","18ab50ee":"plot_slice_image_and_mask(image, mask, 5000, 7500, 2500, 5000)\nplot_slice_image_and_mask(image, mask, 5250, 5720, 3500, 4000)\nplot_slice_image_and_mask(image, mask, 5375, 5575, 3650, 3850)","984ff721":"plot_grid_image_with_mask(image, mask)","1b73318d":"image_id = \"095bf7a1f\"\nimage, mask = read_image(image_id, scale=2)","256106eb":"plot_image_and_mask(image, mask, image_id)","1d4c9eca":"plot_slice_image_and_mask(image, mask, 7500, 10000, 10000, 12500)","15468075":"plot_grid_image_with_mask(image, mask)","506651ac":"image_id = \"1e2425f28\"\nimage, mask = read_image(image_id, scale=2)","6693bd51":"plot_image_and_mask(image, mask, image_id)","ae3aab27":"image_id = \"2f6ecfcdf\"\nimage, mask = read_image(image_id, scale=2)","699a0029":"plot_image_and_mask(image, mask, image_id)","b83eabf2":"plot_slice_image_and_mask(image, mask, 10000, 12000, 8000, 10000)","e531f2e6":"image_id = \"aaa6a05cc\"\nimage, mask = read_image(image_id)","f50076e8":"plot_image_and_mask(image, mask, image_id)","b594feb0":"plot_slice_image_and_mask(image, mask, 6500, 8500, 7000, 9000)","d07a11b7":"image_id = \"e79de561c\"\nimage, mask = read_image(image_id)","3626d014":"plot_image_and_mask(image, mask, image_id)","1c95d106":"plot_slice_image_and_mask(image, mask, 4000, 6000, 2000, 4000)","1429a017":"pd.read_json(\n    os.path.join(BASE_PATH, \"train\/0486052bb-anatomical-structure.json\")\n)","7afe0f13":"pd.read_json(\n    os.path.join(BASE_PATH, \"train\/0486052bb.json\")\n)","33aee4b9":"df_info[\"split\"] = \"test\"\ndf_info.loc[df_info[\"image_file\"].isin(os.listdir(os.path.join(BASE_PATH, \"train\"))), \"split\"] = \"train\"","e8ad69ff":"df_info[\"area\"] = df_info[\"width_pixels\"] * df_info[\"height_pixels\"]","7691b201":"df_info.head()","6eb43f8e":"plt.figure(figsize=(16, 35))\nplt.subplot(6, 2, 1)\nsn.countplot(x=\"race\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 2)\nsn.countplot(x=\"ethnicity\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 3)\nsn.countplot(x=\"sex\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 4)\nsn.countplot(x=\"laterality\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 5)\nsn.histplot(x=\"age\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 6)\nsn.histplot(x=\"weight_kilograms\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 7)\nsn.histplot(x=\"height_centimeters\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 8)\nsn.histplot(x=\"bmi_kg\/m^2\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 9)\nsn.histplot(x=\"percent_cortex\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 10)\nsn.histplot(x=\"percent_medulla\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 11)\nsn.histplot(x=\"area\", hue=\"split\", data=df_info);","27682acc":"**train.csv** contains the unique IDs for each image, as well as an RLE-encoded representation of the mask for the objects in the image. See the evaluation tab for details of the RLE encoding scheme.","9e2639c0":"## Utility functions","a79d107e":"# WORK IN PROGRESS...","ea380a8a":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/22990\/logos\/header.png)","19d60eab":"<a id=\"1\"><\/a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>Basic Data Exploration<center><h2>","dde6aeda":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:#EAA6D1; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [1. Basic Data Exploration](#1)\n* [2. Image and Masks Visualizations](#2)\n* [3. Metadata Analysis](#3)","86583910":"### Train and test metadata","ac5c6e6b":"## Train images","5d51aa25":"## Test images","a3d0c347":"<a id=\"2\"><\/a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>Image and Masks Visualizations<center><h2>","f7f02643":"**HuBMAP-20-dataset_information.csv** contains additional information (including anonymized patient data) about each image.","1f0c2d48":"## Train images + masks","56af895b":"## 2f6ecfcdf","7cfc25f9":"## aaa6a05cc","d6113c46":"# HuBMAP - Exploratory Data Analysis\n\nQuick Exploratory Data Analysis for [HuBMAP: Hacking the Kidney](https:\/\/www.kaggle.com\/c\/hubmap-kidney-segmentation) challenge\n\nThe HuBMAP data used in this hackathon includes 11 fresh frozen and 9 Formalin Fixed Paraffin Embedded (FFPE) PAS kidney images. Glomeruli FTU annotations exist for all 20 tissue samples; some of these will be shared for training, and others will be used to judge submissions.","11f0ffb9":"## e79de561c","fc224fa4":"## 0486052bb","85039013":"<a id=\"3\"><\/a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>Metadata Analysis<center><h2>","2ef19d1b":"## 1e2425f28","813fc74e":"## 095bf7a1f","1bc66a47":"### Submission df","c5721a24":"### Train masks","735a13b4":"### Number of samples"}}