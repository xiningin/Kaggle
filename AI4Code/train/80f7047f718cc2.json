{"cell_type":{"38dafe29":"code","0482665d":"code","49f5fe4d":"code","818f0da9":"code","f48026da":"code","8ac56fcf":"code","f685536c":"code","dd0999c6":"code","7f36b5a7":"code","c1df27bc":"code","c0d37a82":"code","dab9fa6a":"code","38f57ea0":"code","fbbbb5f3":"code","a31e143c":"code","aee249e4":"code","c8a78ee0":"code","6e1da9e2":"code","e35ad459":"code","45d4d3d3":"code","710bd131":"code","32697990":"code","651cbdac":"code","9584fd74":"code","42358f6d":"code","9070d931":"code","5d7f7744":"code","1da3fc7e":"code","bd70f467":"markdown","c885666e":"markdown","bd148547":"markdown","b3b49f7b":"markdown","f14fb359":"markdown","bc008adf":"markdown","0b22aa6f":"markdown","c2784cb8":"markdown","97c13988":"markdown","b19dfa22":"markdown","4ad62195":"markdown","6f8850cf":"markdown"},"source":{"38dafe29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas  as pd #Data manipulation\nimport numpy as np #Data manipulation\nimport matplotlib.pyplot as plt # Visualization\nimport seaborn as sns #Visualization\npd.set_option('display.max_columns', 500)\n\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0482665d":"df = pd.read_csv('..\/input\/student-grade-prediction\/student-mat.csv')\ndf.head()","49f5fe4d":"df.shape","818f0da9":"df.info()","f48026da":"df.describe()","8ac56fcf":"df.columns","f685536c":"plt.figure(figsize=(12,4))\nsns.heatmap(df.isnull(),cbar=False,cmap='viridis',yticklabels=False)\nplt.title('Missing value in the dataset');","dd0999c6":"# Correlation Plot\n\ncorr = df.corr()\nsns.heatmap(corr)","7f36b5a7":"from sklearn.model_selection import train_test_split\nX = df[['G1', 'G2','studytime', 'failures', 'absences']] #Independent variable \ny = df['G3'] #dependent variable \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","c1df27bc":"from sklearn.linear_model import LinearRegression \n\nlm = LinearRegression() ","c0d37a82":"lm.fit(X_train,y_train) ","dab9fa6a":"print(lm.intercept_)","38f57ea0":"predictions = lm.predict(X_test)  ","fbbbb5f3":"plt.scatter(y_test,predictions)","a31e143c":"sns.distplot((y_test-predictions)); ","aee249e4":"from sklearn import metrics","c8a78ee0":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","6e1da9e2":"from sklearn.metrics import r2_score\nprint(r2_score(y_test, predictions))","e35ad459":"from sklearn.model_selection import cross_val_score\nmse=cross_val_score(lm,X,y,scoring='neg_mean_squared_error',cv=5)\nmean_mse=np.mean(mse)\nprint(mean_mse)","45d4d3d3":"from sklearn.ensemble import RandomForestRegressor\nrandom_regressor = RandomForestRegressor(n_estimators=10, random_state=0)\nrandom_regressor.fit(X_train, y_train)","710bd131":"y_pred = random_regressor.predict(X_test)\n","32697990":"from sklearn.metrics import r2_score\nprint(r2_score(y_test, y_pred))","651cbdac":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\n\nridge=Ridge()\nparameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\nridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\nridge_regressor.fit(X,y)","9584fd74":"print(ridge_regressor.best_params_)\nprint(ridge_regressor.best_score_)","42358f6d":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nlasso=Lasso()\nparameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\nlasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n\nlasso_regressor.fit(X,y)\nprint(lasso_regressor.best_params_)\nprint(lasso_regressor.best_score_)","9070d931":"prediction_lasso=lasso_regressor.predict(X_test)\nprediction_ridge=ridge_regressor.predict(X_test)","5d7f7744":"import seaborn as sns\n\nsns.distplot(y_test-prediction_lasso)\nplt.title(\"Lasso Prediction plot\")\nplt.show()","1da3fc7e":"import seaborn as sns\n\nsns.distplot(y_test-prediction_ridge)\nplt.title(\"Ridge Predictions plot\")\nplt.show()","bd70f467":"# Ridge Regression","c885666e":"Here, we can see that **Ridge Prediction plot** is more stable than Lasso Prediction plot.","bd148547":"# Linear Regression","b3b49f7b":"Plot","f14fb359":"## Cross Validation","bc008adf":"There is no missing value data","0b22aa6f":"## Model Building ##\n\nIn this step build model using our linear regression equation  \u03b8=(XTX)\u22121XTy . In first step we need to add a feature  x0=1  to our original data set.","c2784cb8":"Checking for missing value","97c13988":"This score is very good, since it's closer to zero. Model performs well when this value is closer to zero.","b19dfa22":"# Random Forest Regression","4ad62195":"## Train Test split ","6f8850cf":"# Lasso Regression"}}