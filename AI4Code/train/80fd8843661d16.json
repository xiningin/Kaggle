{"cell_type":{"f060c6a2":"code","78739515":"code","e5a48f9f":"code","a0cce747":"code","2d1434ad":"code","d9d8974f":"code","e30e0389":"code","2f754310":"code","7f7d3659":"code","458a202b":"code","267723ed":"code","038a8fae":"code","3fa66cb3":"code","60d694c0":"code","fdead73a":"code","a319e10b":"code","fdea395a":"code","918a2f23":"code","1ac992e6":"code","c5063e51":"code","a221840e":"code","058b34ac":"code","28230965":"code","40652895":"code","f635f27d":"code","2958213f":"code","727ecdee":"markdown","d743aa1f":"markdown","c01e98c4":"markdown","99b2bf22":"markdown","3c9aea4d":"markdown","e7bb04d1":"markdown","29ffbdf6":"markdown","cc1ddaf8":"markdown","2d500ceb":"markdown","a72701f0":"markdown","79552965":"markdown","41a3c60f":"markdown","01ae72e4":"markdown","c587a164":"markdown","7c58268d":"markdown","a3bc3786":"markdown"},"source":{"f060c6a2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","78739515":"import sys\nprint(sys.executable)","e5a48f9f":"!nvidia-smi","a0cce747":"# uncomment\/Comment below line to install\/skip-install hugging-face transformers\n\n!pip install transformers","2d1434ad":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nimport torch\nimport transformers as ppb # pytorch-transformers by huggingface\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')","d9d8974f":"#initiating Garbage Collector for GPU environment setup\nimport gc\nfor obj in gc.get_objects():\n    try:\n        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n            print(type(obj), obj.size())\n    except:\n        pass","e30e0389":"torch.cuda.is_available()","2f754310":"path = '..\/input\/stanford-sentiment-treebank-v2-sst2\/datasets\/'\n\n# to read via CSV files...\n# df = pd.read_csv(path + 'csv-format\/train.csv')\n\ndf = pd.read_csv(path + 'tsv-format\/train.tsv', delimiter='\\t')","7f7d3659":"df.shape","458a202b":"batch_1 = df[:2000]\nbatch_1['Ratings'].value_counts()","267723ed":"# https:\/\/www.kaggle.com\/dansbecker\/running-kaggle-kernels-with-a-gpu\nUSE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n    print('using device: cuda')\nelse:\n    print('using device: cpu')","038a8fae":"use_cuda = not False and torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")","3fa66cb3":"print(time.ctime())\n\n\nmodel_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n\n## Want BERT instead of distilBERT? Uncomment the following line:\n#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n\n# Load pretrained model\/tokenizer\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\nmodel = model_class.from_pretrained(pretrained_weights).to(device)\n\nprint(time.ctime())","60d694c0":"tokenized = batch_1['Reviews'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))","fdead73a":"tokenized.shape","a319e10b":"print(time.ctime())\n\nmax_len = 0\nfor i in tokenized.values:\n    if len(i) > max_len:\n        max_len = len(i)\n\npadded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n\nprint(time.ctime())","fdea395a":"np.array(padded).shape","918a2f23":"attention_mask = np.where(padded != 0, 1, 0)\nattention_mask.shape","1ac992e6":"# with GPU usage...\n\n\nprint(time.ctime())\n\n\nif USE_GPU and torch.cuda.is_available():\n    print('using GPU...')\n    input_ids = torch.tensor(padded).to(device)  \n    attention_mask = torch.tensor(attention_mask).to(device)\n\n    with torch.no_grad():\n        last_hidden_states = model(input_ids, attention_mask=attention_mask)# .to(device)\n        \nprint(time.ctime())","c5063e51":"# add .cpu to convert cuda tensor to numpy()\n\nfeatures = last_hidden_states[0][:,0,:].cpu().numpy()","a221840e":"labels = batch_1['Ratings']","058b34ac":"train_features, test_features, train_labels, test_labels = train_test_split(features, labels)","28230965":"\n# parameters = {'C': np.linspace(0.0001, 100, 20)}\n# grid_search = GridSearchCV(LogisticRegression(), parameters)\n# grid_search.fit(train_features, train_labels)\n\n# print('best parameters: ', grid_search.best_params_)\n# print('best scrores: ', grid_search.best_score_)","40652895":"lr_clf = LogisticRegression()\nlr_clf.fit(train_features, train_labels)","f635f27d":"lr_clf.score(test_features, test_labels)","2958213f":"from sklearn.dummy import DummyClassifier\nclf = DummyClassifier()\n\nscores = cross_val_score(clf, train_features, train_labels)\nprint(\"Dummy classifier score: %0.3f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","727ecdee":"### loading dataset files","d743aa1f":"### Loading model class, weight matrices, and tokenizer classes from pre-trained DistillBERT model.","c01e98c4":"### to check GPU-configurations and current usage.","99b2bf22":"#### ensuring python environment","3c9aea4d":"## Different versions of BERT and their performance standards:\n\n![bert-variants](https:\/\/miro.medium.com\/max\/1243\/1*5PzGl1dNt_5jMH3_mm3PpA.png)","e7bb04d1":"![BERT-versions-anime](http:\/\/jalammar.github.io\/images\/transformer-ber-ulmfit-elmo.png)","29ffbdf6":"![training-Bert](http:\/\/jalammar.github.io\/images\/bert-transfer-learning.png)\n\n#### The two steps of how BERT is developed. You can download the model pre-trained in step 1 (trained on un-annotated data), and only worry about fine-tuning it for step 2.","cc1ddaf8":"## Shoutouts :\n\n#### to these Kernels for providing useful code snippets to fully utilize GPU\/CUDA for Pytorch.\n\n1. [Simple PyTorch with kaggle's GPU](https:\/\/www.kaggle.com\/leighplt\/simple-pytorch-with-kaggle-s-gpu) - @leighplt\n\n2. [Testing GPU-enabled Notebooks MNIST + Pytorch](https:\/\/www.kaggle.com\/scottclowe\/testing-gpu-enabled-notebooks-mnist-pytorch) - @scottclowe\n\n3. [CUDA Out of memory](https:\/\/www.kaggle.com\/c\/jigsaw-unintended-bias-in-toxicity-classification\/discussion\/91081) - @thawatt","2d500ceb":"# note:::::::\n\n\n### I get the error (CUDA out of memory) in below code cell with batch size > = 2500. Can some one suggest me any algo\/procedure with a code snippet on how to overcome that problem??\n\n### Like, How can I make use of complete dataset : 6920 rows, instead of just 2000 (i used here).\n\nPossible suggestion :  USe for loop and run the algo for the complete dataset...","a72701f0":"#### cross-checking if GPU is used in this notebook","79552965":"### Applying attention mask to avoid Biasness.","41a3c60f":"# Introduction :\n\n### This kernel is a leading one for [this kernel](https:\/\/www.kaggle.com\/atulanandjha\/distillbert-extensive-tutorial-starter-kernel), where i had implemented DISTILLBERT on CPU. Here, I am extending the same task on GPU, much faster and better accuracy.","01ae72e4":"### Note : for now I am working on a sample of dataset, 2000 rows for now. although, we can loop across batches of equal sizes to cover whole dataset as well.\n\n### <span style=\"color:red;\"> Consider Upvoting the kernel if you have come this far and you liked it.<\/span>","c587a164":"# <span style=\"color:red\"># DO UPVOTE if you like this kernel. Feedbacks are always welcomed! <\/span>\n\n# THANKS !","7c58268d":"### Other tasks that can be performed on top of BERT Architecture.\n\n![bert-appplications](http:\/\/jalammar.github.io\/images\/openai-input%20transformations.png)","a3bc3786":"## References:\n1. [Papers-with-code-DISTILLBERT](https:\/\/paperswithcode.com\/paper\/distilbert-a-distilled-version-of-bert)\n2. [Jay-Alammar-Evolution-of-BERT-architectures](http:\/\/jalammar.github.io\/illustrated-bert\/)"}}