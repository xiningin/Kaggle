{"cell_type":{"1e3d5ba3":"code","41e5fd68":"code","cd09be36":"code","852da18c":"code","af39973e":"code","ef6577b6":"code","4a1e3b15":"code","46c4c12b":"code","c1b69b6c":"code","580be39f":"code","3f5c578f":"code","d71685a2":"code","2f3ccaa5":"code","ebec66f9":"code","63486c31":"code","61b19d17":"code","6288e09c":"code","1e763ab0":"code","c7155583":"markdown","206458a3":"markdown","d3d8ab8f":"markdown","30f174ea":"markdown"},"source":{"1e3d5ba3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport collections\n#from datetime import datetime\nfrom datetime import date\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41e5fd68":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\nimport sklearn.metrics","cd09be36":"dirnames=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    if \"our_world_in_data\" in dirname:\n        for filename in filenames:\n            #if (\"statistics-and-research (1)\" in dirname)or(\"testing-latest-data\" in dirname):\n            dirnames.append(os.path.join(dirname, filename))\n            #print(os.path.join(dirname, filename))\nprint(dirnames)","852da18c":"print(dirnames[2],\"\\t\",dirnames[-1])","af39973e":"data1=pd.read_csv(dirnames[1])\ndata2=pd.read_csv(dirnames[2])\ndata3=pd.read_csv(dirnames[3])#si\nprint(np.shape(data1))\nprint(np.shape(data2))\nprint(np.shape(data3))","ef6577b6":"counter=collections.Counter(data3[\"location\"])       \nprint(np.shape(list(counter.keys())))\ncountries=list(counter.keys())\nf=list(counter.values())","4a1e3b15":"#it's for checking the minimum amount of data needed\nprint(np.sort(f))\nfor i in range(len(f)):\n    if(f[i]==21):\n        print(countries[i])\nn_data=21","46c4c12b":"data3\n# print(data3[\"date\"][:5])\n# a=date.fromisoformat(data3[\"date\"][0])\n# b=date.fromisoformat(data3[\"date\"][1])\n# print(date.toordinal(a))\n# print(date.toordinal(b))","c1b69b6c":"temp=[]\nt_min=date.toordinal(date.fromisoformat(data3[\"date\"][0]))\nfor i in range(1,len(data3[\"date\"])):\n        t_min=min([date.toordinal(date.fromisoformat(data3[\"date\"][i])),t_min])\n        #dates.append(date.toordinal(date.fromisoformat(data3[\"date\"][j])))\nprint(t_min)\nprint(date.fromordinal(t_min))","580be39f":"#las categor\u00edas son los meses del a\u00f1o\nimport datetime\nY2=[]\nfor i in range(len(data3[\"date\"])):\n    datee = datetime.datetime.strptime(data3[\"date\"][i], \"%Y-%m-%d\")\n    Y2=np.append(Y2,datee.month+datee.year-2019)","3f5c578f":"#another y that will be tested\nY2=[0]\nF=0\ncnt=0\nfor i in range(len(f)):\n    F+=f[i]\n    if(i>0):\n        cnt=0\n        for j in range(F_last,F):\n            if(np.abs(data3[\"total_cases\"][i-1]-data3[\"total_cases\"][i])<1e-4):\n                cnt+=1\n            if(cnt>3):\n                Y2.append(1)\n            else:\n                Y2.append(0)\n        F_last=F\nprint(Y2)","d71685a2":"F=0\nF_last=0\nplt.figure()\nfor i in range(len(f)-2):\n    F+=f[i]\n    dates=[]\n    for j in range(F_last,F):\n        dates.append(date.toordinal(date.fromisoformat(data3[\"date\"][j]))-t_min)\n    if(\"Colombia\" in countries[i])or(\"Sao Tome and Principe\" in countries[i]):\n        plt.scatter(dates[:],data3[F_last:F][\"total_cases\"],label=\"{}\".format(countries[i]))\n    F_last=F\nplt.xlabel('time(days)')\nplt.ylabel('Infected cases')\nplt.legend(loc=(1.05,0.25))\n################################################################\nplt.figure()\nF=0\nF_last=0\nfor i in range(len(f)-2):\n    F+=f[i]\n    dates=[]\n    for j in range(F_last,F):\n        dates.append(date.toordinal(date.fromisoformat(data3[\"date\"][j]))-t_min)\n    if(\"Colombia\" in countries[i])or(\"Sao Tome and Principe\" in countries[i]):\n        plt.scatter(dates[-n_data:],data3[F-n_data:F][\"total_cases\"],label=\"{}\".format(countries[i]))\n    F_last=F\nplt.xlabel('time(days)')\nplt.ylabel('Infected cases')\nplt.legend(loc=(1.05,0.25))","2f3ccaa5":"F=0\nF_last=0\nX=[]\nY=[]\nY22=[]\nfor i in range(len(f)-2):\n    F+=f[i]\n    dates=[]\n    for j in range(F_last,F):\n        dates.append(date.toordinal(date.fromisoformat(data3[\"date\"][j]))-t_min)\n    if(f[i]>=21):\n        X.append(dates[-n_data:])\n        Y.append(np.array(data3[F-n_data:F][\"total_cases\"]))\n        Y22.append(Y2[F-n_data:F])\n    plt.plot(dates,data3[F_last:F][\"total_cases\"])#,label=\"{}\".format(countries[i]))\n    if(\"Colombia\" in countries[i])or(\"United States\"== countries[i])or(\"Peru\" in countries[i]):\n        plt.scatter(dates,data3[F_last:F][\"total_cases\"],label=\"{}\".format(countries[i]))\n        print(np.shape(data3[F-n_data:F][\"total_cases\"]))\n    F_last=F\nplt.xlabel('time(days)')\nplt.ylabel('Infected cases')\nplt.legend(loc=(1.05,0.25))","ebec66f9":"print(np.shape(X),np.shape(Y))\nprint(np.shape(Y[0][:]))\nprint(np.shape(Y22[0][:]))","63486c31":"# Vamos a hacer un split training test\nscaler = StandardScaler()\nx_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.5)\nx_train = scaler.fit_transform(x_train).T\nx_test = scaler.transform(x_test).T\n#y_train = scaler.fit_transform(y_train.reshape(-1, 1))\n#y_train=np.array(y_train).T\n#y_test=np.array(y_test).T\n#y_test = scaler.transform(y_test.reshape(-1, 1))\n#x_train=x_train.T\nprint(np.shape(x_train))\nprint(np.shape(x_test))\nprint(np.shape(y_train[0][:]))\n# x_train.mean(axis=0)\n# x_train.std(axis=0)","61b19d17":"#proba_test  = clf.predict_proba(np.array(X[0][:]).reshape(-1, 1))\n#prec, rec, th = sklearn.metrics.precision_recall_curve(np.array(Y[0][:]).reshape(-1, 1), proba_test[:,1], pos_label=1)\nproba_test_tot=[]\nprec_tot=[]\nrec_tot=[]\nF1_tot=[]\nfor Ci in np.arange(1e3,1e5,1e3):\n    clf = linear_model.LogisticRegression(C=Ci)\n    # clf.fit(np.array(X[0][:]).reshape(-1, 1), np.array(Y[0][:]).reshape(-1, 1))\n    clf.fit(x_train, y_train[0][:])\n    proba_test  = clf.predict_proba(x_test)#.reshape(-1, 1))\n    proba_test_tot.append(proba_test)\n    prec, rec, th = sklearn.metrics.precision_recall_curve(y_test[0][:], proba_test[:,1], pos_label=1)\n    prec_tot.append(prec)\n    rec_tot.append(rec)\n    F1= 2.0*prec[:-1]*rec[:-1]\/(prec[:-1]+rec[:-1] +1E-10)\n    F1_tot.append(F)\n    print(proba_test[:,1])\n    print(prec,\"\\t\",rec,\"\\t\",th)\n","6288e09c":"F1= 2.0*prec[:-1]*rec[:-1]\/(prec[:-1]+rec[:-1] +1E-10)\nprint(F1)","1e763ab0":"cnt=0\nfor i in range(len(data2[\"date\"][:])):\n    if(\"2020-04-28\" in data2[\"date\"][i]):\n        print(data2[\"entity\"][i].format())#data1.iloc[[i]]) #\n        cnt+=1\nprint(cnt)","c7155583":"## Plot of N\u00b0 of infected cases\nIt starts from 2019-12-31","206458a3":"# Entrada de directorios\nEn este caso utilizaremos los archivos coronavirus-disease-covid-19-statistics-and-research (1).csv y covid-19-testing-latest-data-and-source-details.csv encontrados en our world in data","d3d8ab8f":"* Selection of countries and amount of dates with data","30f174ea":"# model"}}