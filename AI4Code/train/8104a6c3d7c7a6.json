{"cell_type":{"d0662523":"code","25041f6b":"code","0022bc37":"code","035f90b7":"code","02579182":"code","33cb2055":"code","362cb66d":"code","33886f91":"code","ebb33891":"code","537e602c":"code","7fb96ed3":"code","1a5632fc":"code","1d67e25c":"code","3e0bec80":"code","426ae8ec":"code","a0c2f30e":"code","b298093b":"code","fb1c90f4":"code","0d07d2f3":"code","e3cc573c":"code","90bd1f26":"code","7afa7eab":"code","c6e61c7e":"code","3a4f4388":"code","ba335d50":"code","0956ff0e":"code","c157657c":"code","1d99bc88":"code","438f1d56":"code","543e1fe5":"code","b4154d61":"code","b18a9240":"code","a0b9c90b":"code","3d20a2e5":"code","029eea57":"code","279af721":"code","b5c73cb5":"code","08853dab":"code","6e1bf0e7":"code","9cbfd51e":"code","0fc4a024":"code","2cf2f089":"code","d82b15b2":"code","16879109":"code","202b2290":"code","43f97339":"code","d8e85716":"code","f12c2341":"code","cc25f6b7":"markdown","d533f00a":"markdown","b25ad53c":"markdown","9b9ef5ff":"markdown","6b8014fe":"markdown","18f249d7":"markdown","cd683ece":"markdown","51748dcb":"markdown","b4f1bdf5":"markdown","a4fc8b4d":"markdown","f12bf5d0":"markdown","d04a11b0":"markdown","b5d7389a":"markdown","3a88750e":"markdown","cba8d710":"markdown","8107aa8c":"markdown","f8445c18":"markdown","53f7ec4b":"markdown","8d9069b6":"markdown","97d06ea7":"markdown","f0cea801":"markdown","1077ba7c":"markdown","1b04d386":"markdown","93bbf500":"markdown","8996e37c":"markdown","597c8bc6":"markdown","2efbb264":"markdown","e1165ebb":"markdown","2b95709c":"markdown","cf5c1bdb":"markdown","a5789bcc":"markdown","962a2f22":"markdown"},"source":{"d0662523":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport datetime as dt\nimport matplotlib.pyplot as plt\nimport squarify\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import MinMaxScaler\n#\nfrom sklearn.cluster import KMeans\n#\nimport plotly.offline as pyo \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n#\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","25041f6b":"data = pd.read_csv(\"\/kaggle\/input\/ecommerce-data\/data.csv\",encoding = 'unicode_escape')\ndata.head()","0022bc37":"# Count of Countries \ndata[\"Country\"].value_counts()","035f90b7":"# Check missing values\ndata.isnull().sum()","02579182":"#Total Price\ndata['TotalPrice'] = data['UnitPrice'] * data['Quantity']\ndata.head()","33cb2055":"# Total Spending of Countries\ndata_country = data.groupby(\"Country\").agg({'TotalPrice': lambda x: x.sum()})","362cb66d":"# Drop Unnecessary Countries for Visualization \ndata_country.drop([\"RSA\",\"Unspecified\",\"EIRE\",\"European Community\",\"Channel Islands\"],axis=0,inplace=True)\ndata_country.head()","33886f91":"price = []\nfor i in range(len(data_country[\"TotalPrice\"])):\n    price.append(data_country[\"TotalPrice\"][i])\n\ncountry_price = pd.DataFrame(index=[\"AUS\",\"AUT\",\"BHR\",\"BEL\",\"BRA\",\"CAN\",\"CYP\",\"CZE\",\"DNK\",\"FIN\",\"FRA\",\"DEU\",\"GRC\",\"HKG\",\"ISL\",\"ISR\",\n                                    \"ITA\",\"JPN\",\"LBN\",\"LTU\",\"MLT\",\"NLD\",\"NOR\",\"POL\",\"PRT\",\"SAU\",\"SGP\",\"ESP\",\"SWE\",\"CHE\",\"USA\",\n                                    \"ARE\",\"GBR\"],columns=[\"TotalPrice\",\"country\"])\ncountry_price[\"country\"] = data_country.index\ncountry_price[\"TotalPrice\"] = price\ncountry_price.head()","ebb33891":"worldmap = [dict(type = 'choropleth', locations = country_price['country'], locationmode = 'country names',\n                 z = country_price['TotalPrice'], autocolorscale = True, reversescale = False, \n                 marker = dict(line = dict(color = 'rgb(180,180,180)', width = 0.5)), \n                 colorbar = dict(autotick = False, title = 'Total Price'))]\n\nlayout = dict(title = 'Total Price For Each Country', geo = dict(showframe = False, showcoastlines = True, \n                                                                projection = dict(type = 'Mercator')))\n\nfig = dict(data=worldmap, layout=layout)\npyo.iplot(fig, validate=False)","537e602c":"data.head()","7fb96ed3":"data.shape","1a5632fc":"# Change Data Type:\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n\n# Adjust today:\ntoday = dt.datetime(2012,1,1)\nprint(today)\n\n# Bigger than zero and just UK\ndata = data[data['Quantity'] > 0]\ndata = data[data['TotalPrice'] > 0]\ndata = data[data[\"Country\"] == \"United Kingdom\"]\ndata.shape","1d67e25c":"data.info()","3e0bec80":"# Recency and Monetary \ndata_x = data.groupby('CustomerID').agg({'TotalPrice': lambda x: x.sum(),\n                                        'InvoiceDate': lambda x: (today - x.max()).days})\ndata_x.head()","426ae8ec":"# Dataset is basis on StockCode    \ndata_y = data.groupby(['CustomerID','InvoiceNo']).agg({'TotalPrice': lambda x: x.sum()})\ndata_y.head(20)","a0c2f30e":"# Find Frequency\ndata_z = data_y.groupby('CustomerID').agg({'TotalPrice': lambda x: len(x)})\ndata_z.head()","b298093b":"# RFM Dataframe\nrfm_table= pd.merge(data_x,data_z, on='CustomerID')\n\n# Change Column Name\nrfm_table.rename(columns= {'InvoiceDate': 'Recency',\n                          'TotalPrice_y': 'Frequency',\n                          'TotalPrice_x': 'Monetary'}, inplace= True)\nrfm_table.head()","fb1c90f4":"#Frequency bulma\ndef FScore(x,p,d):\n    if x <= d[p][0.20]:\n        return 0\n    elif x <= d[p][0.40]:\n        return 1\n    elif x <= d[p][0.60]: \n        return 2\n    elif x <= d[p][0.80]:\n        return 3\n    else:\n        return 4\n\nquantiles = rfm_table.quantile(q=[0.20,0.40,0.60,0.80])\nquantiles = quantiles.to_dict()\nrfm_table['Freq_Tile'] = rfm_table['Frequency'].apply(FScore, args=('Frequency',quantiles,))\n\n#Recency \nrfm_table = rfm_table.sort_values('Recency',ascending=True)\nrfm_table['Rec_Tile'] = pd.qcut(rfm_table['Recency'],5,labels=False)\n\n#Monetary \nrfm_table['Mone_Tile'] = pd.qcut(rfm_table['Monetary'],5,labels=False)\n\n# instead of zero, plus 1 \nrfm_table['Rec_Tile'] = rfm_table['Rec_Tile'] + 1\nrfm_table['Freq_Tile'] = rfm_table['Freq_Tile'] + 1\nrfm_table['Mone_Tile'] = rfm_table['Mone_Tile'] + 1\n\n# Add to dataframe\nrfm_table['RFM Score'] = rfm_table['Rec_Tile'].map(str) + rfm_table['Freq_Tile'].map(str) + rfm_table['Mone_Tile'].map(str)\nrfm_table.head()","0d07d2f3":"rfm_table[rfm_table['RFM Score'] == '555'].sort_values('Monetary', ascending=False).head()","e3cc573c":"#Customers who's recency value is low\nrfm_table[rfm_table['Rec_Tile'] <= 2 ].sort_values('Monetary', ascending=False).head()","90bd1f26":"#Customers who's recency, frequency as well as monetary values are low \nrfm_table[rfm_table['RFM Score'] == '111'].sort_values('Recency',ascending=False).head()","7afa7eab":"#Customers with high frequency value\n\nrfm_table[rfm_table['Freq_Tile'] >= 3 ].sort_values('Monetary', ascending=False).head()","c6e61c7e":"# Calculate RFM_Score\nrfm_table['RFM_Sum'] = rfm_table[['Freq_Tile','Rec_Tile','Mone_Tile']].sum(axis=1)\nrfm_table.head()","3a4f4388":"# Define rfm_level function\ndef rfm_level(df):\n    if df['RFM_Sum'] >= 9:\n        return 'Can\\'t Loose Them'\n    elif ((df['RFM_Sum'] >= 8) and (df['RFM_Sum'] < 9)):\n        return 'Champions'\n    elif ((df['RFM_Sum'] >= 7) and (df['RFM_Sum'] < 8)):\n        return 'Loyal'\n    elif ((df['RFM_Sum'] >= 6) and (df['RFM_Sum'] < 7)):\n        return 'Potential'\n    elif ((df['RFM_Sum'] >= 5) and (df['RFM_Sum'] < 6)):\n        return 'Promising'\n    elif ((df['RFM_Sum'] >= 4) and (df['RFM_Sum'] < 5)):\n        return 'Needs Attention'\n    else:\n        return 'Require Activation'\n# Create a new variable RFM_Level\nrfm_table['RFM_Level'] = rfm_table.apply(rfm_level, axis=1)\n# Print the header with top 5 rows to the console\nrfm_table.head()","ba335d50":"rfm_table[\"RFM_Level\"].value_counts()","0956ff0e":"# Calculate average values for each RFM_Level, and return a size of each segment \nrfm_level_agg = rfm_table.groupby('RFM_Level').agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'Monetary': ['mean', 'count']}).round(1)\n# Print the aggregated dataset\nprint(rfm_level_agg)","c157657c":"rfm_level_agg.columns = rfm_level_agg.columns.droplevel()\nrfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n#Create our plot and resize it.\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 9)\nsquarify.plot(sizes=rfm_level_agg['Count'], \n              label=['Can\\'t Loose Them',\n                     'Champions',\n                     'Loyal',\n                     'Needs Attention',\n                     'Potential', \n                     'Promising', \n                     'Require Activation'], alpha=.6 )\nplt.title(\"RFM Segments\",fontsize=18,fontweight=\"bold\")\nplt.axis('off')\nplt.show()","1d99bc88":"plt.figure(figsize=(12,10))\n# Plot distribution of R\nplt.subplot(3, 1, 1); sns.distplot(rfm_table['Recency'],fit=norm)\n# Plot distribution of F\nplt.subplot(3, 1, 2); sns.distplot(rfm_table['Frequency'],fit=norm)\n# Plot distribution of M\nplt.subplot(3, 1, 3); sns.distplot(rfm_table['Monetary'],fit=norm)\n# Show the plot\nplt.show()","438f1d56":"clustering_fm = rfm_table[['Recency',\"Frequency\",\"Monetary\"]].copy()\nclustering_fm.head()","543e1fe5":"min_max_scaler = MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(clustering_fm)\ndata_scaled2 = pd.DataFrame(x_scaled)","b4154d61":"data_scaled2.head()","b18a9240":"wscc = []\nfor i in range(1,15): \n    kmeans = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    kmeans.fit(data_scaled2)\n    wscc.append(kmeans.inertia_)  \n\nplt.plot(range(1,15),wscc,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters\")","a0b9c90b":"kmeans = KMeans(n_clusters = 4, init='k-means++', n_init =10,max_iter = 300)\nkmeans.fit(data_scaled2)\npred = kmeans.predict(data_scaled2)","3d20a2e5":"np.unique(kmeans.labels_)","029eea57":"from sklearn.metrics import silhouette_score\nscore = silhouette_score (data_scaled2, kmeans.labels_)\nprint(\"Score = \", score)","279af721":"y_kmeans = kmeans.predict(data_scaled2)","b5c73cb5":"y_kmeans[:4]","08853dab":"# Count of Clusters\nd_frame = pd.DataFrame(clustering_fm)\nd_frame['cluster'] = y_kmeans\nd_frame['cluster'].value_counts()","6e1bf0e7":"d_frame.head()","9cbfd51e":"d_frame.groupby('cluster').mean()","0fc4a024":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","2cf2f089":"data_apriori = data[data['Country']=='United Kingdom']\ndata_apriori.head()","d82b15b2":"data_apriori[\"Description\"].nunique()","16879109":"# Which Product and Their Count \ndata_apr = data_apriori.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\ndata_apr.head()","202b2290":"def num(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\nbasket_new = data_apr.applymap(num)\nbasket_new.head()","43f97339":"from mlxtend.frequent_patterns import fpgrowth\nrule_fp = fpgrowth(basket_new, min_support=0.02, use_colnames=True)\nrule_fp","d8e85716":"items = apriori(basket_new, min_support=0.02, use_colnames=True)\nitems","f12c2341":"rule = association_rules(items, metric=\"lift\", min_threshold=1)\nrule","cc25f6b7":"### Recency and Frequency Grid\n* A low recency and frequency score (bottom left) represents hibernating users who haven\u2019t been active recently or frequently. A high recency and frequency score (top right) represents users who have been active recently and frequently, indicating your app\u2019s champions.\n\n* Users are then ranked in order of percentile. For example, a user who has performed the activity most recently would constitute the 100th percentile. Users are then ranked by a score of 1 through 5, based on their percentile, with 5 being the highest.\n\n### The Recency and Frequency Grid breaks your user base down into:\n\n* Champions [R(4 \u2013 5), F(4 \u2013 5)]\n* Loyal Customers [R(3 \u2013 4), F(4 \u2013 5)]\n* Potential Loyalists [R(4 \u2013 5), F(2 \u2013 3)]\n* Promising [R(3 \u2013 4), F(0 \u2013 1)]\n* Can\u2019t Lose Them [R(1 \u2013 2), F(4 \u2013 5)]\n* At Risk [R(1 \u2013 2), F(3 \u2013 4)]\n* About to Sleep [R(2 \u2013 3), F(1-2)]\n* Hibernating [R(1 \u2013 2), F(1 \u2013 2)]\n* New Customers R [(4 \u2013 5), F(0 \u2013 1)]\n* Need Attention R [(2 \u2013 3), F(2 \u2013 3)]","d533f00a":"<a id = \"16\"><\/a><br>\n## K-Means Segmentation","b25ad53c":"<a id = \"7\"><\/a><br>\n## RFM Segmentation\n\n* Customers with the lowest recency, highest frequency and monetary amounts considered as top customers.","9b9ef5ff":"## RFM Analysis & Association Rules For Successful Customer Segmentation\n*\u201cRFM is a method used for analyzing customer value\u201d.*\n* It groups customers based on their transaction history :\n  * Recency        \u2014 How many days ago was their last purchase?\n  * Frequency      \u2014 How many times has the customer purchased from our store?\n  * Monetary Value \u2014 How much do they spend?\n\n\n<hr>","6b8014fe":"# Introduction\n<br>\n<font color = 'blue'>\n<b>Content: <\/b>\n\n1. [Load Libraries](#1)\n1. [Load Dataset](#2)\n1. [Spending of Countries](#3)\n1. [How RFM Analysis Works](#4)\n1. [Find Recency, Monetary and Frequency](#5)\n    * [RFM Dataframe](#6)\n    * [RFM Segmentation](#7)\n    * [RFM Segmentation Readily Answers These Questions For Business](#8)\n        * [Who are my best customers?](#9)\n        * [Which customers are at the verge of churning?](#10)\n        * [Who are the lost customers?](#11)\n        * [Who are the loyal customers?](#12)\n    * [Summing the RFM Score](#13)\n        * [Making Classification For Customers Depends On RFM Sum Score](#14) \n        * [RFM Segmentation Visualization](#15)\n1. [K-Means Segmentation](#16)\n    * [Plot RFM Distributions](#17)\n    * [Normalization](#18)\n    * [Elbow Method](#19)\n    * [KMeans Clustering with 4 Clusters](#20)\n    * [Which Cluster Is Our Best Customers](#21)\n1. [Association Rules](#22)\n    * [Support & Confidence Values](#23)","18f249d7":"<a id = \"6\"><\/a><br>\n## RFM Dataframe","cd683ece":"<a id = \"11\"><\/a><br>\n## Who are the lost customers?","51748dcb":"<a id = \"9\"><\/a><br>\n## Who are my best customers?","b4f1bdf5":"<hr>","a4fc8b4d":"* We can get creative and hypothesize about what each score range entails, but for this exercise I will take inspiration from some common segment names.","f12bf5d0":"* Confidence\n<br>\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*E3mNKHcudWzHySGMvo_vPg.png)","d04a11b0":"<a id = \"1\"><\/a><br>\n## Load Libraries","b5d7389a":"<a id = \"18\"><\/a><br>\n## Normalization","3a88750e":"<a id = \"12\"><\/a><br>\n## Who are the loyal customers?","cba8d710":"<a id = \"17\"><\/a><br>\n## Plot RFM distributions","8107aa8c":"<a id = \"2\"><\/a><br>\n## Load Dataset","f8445c18":"<a id = \"5\"><\/a><br>\n## Find Recency, Monetary and Frequency","53f7ec4b":"<a id = \"4\"><\/a><br>\n## How RFM Analysis Works","8d9069b6":"<a id = \"10\"><\/a><br>\n## Which customers are at the verge of churning?","97d06ea7":"<a id = \"23\"><\/a><br>\n## Support & Confidence Values\t","f0cea801":"* Choose the event that signifies activity for your application, and set the date range you want to analyze. An ecommerce app might track purchases, while a media app might monitor content viewed or rated.\n\n* For every user who has performed the defined event, the Analysis will calculate:\n\n  * How many times the event has occurred\n  * The last time a user performed the event\nView a complete analysis of your user base on a Recency and Frequency Grid, broken down into segments.","1077ba7c":"<a id = \"21\"><\/a><br>\n## Which Cluster Is Our Best Customers","1b04d386":"<a id = \"22\"><\/a><br>\n## Association Rules\n* Apriori is an algorithm for frequent item set mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.","93bbf500":"<a id = \"8\"><\/a><br>\n## RFM Segmentation Readily Answers These Questions For Business","8996e37c":"* Support\n<br>\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*bqdq-z4Ec7Uac3TT3H_1Gg.png)","597c8bc6":"![](https:\/\/d35fo82fjcw0y8.cloudfront.net\/2017\/12\/06085307\/In-content-screen-shot-1.png)","2efbb264":"<a id = \"20\"><\/a><br>\n## KMeans clustering with 4 clusters","e1165ebb":"<a id = \"13\"><\/a><br>\n## Summing the RFM Score\n* One of the most straightforward methods is to sum our scores to a single number and define RFM levels for each score range.","2b95709c":"<a id = \"3\"><\/a><br>\n## Spending of Countries","cf5c1bdb":"<a id = \"14\"><\/a><br>\n## Making Segmentation For Customers Depends On RFM Sum Score","a5789bcc":"<a id = \"15\"><\/a><br>\n## RFM Segmentation Visualization","962a2f22":"<a id = \"19\"><\/a><br>\n## Elbow Method"}}