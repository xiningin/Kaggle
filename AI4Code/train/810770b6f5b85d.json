{"cell_type":{"c05d44c2":"code","48223ed9":"code","5b70f17b":"markdown"},"source":{"c05d44c2":"### Basado en:\n# https:\/\/www.kaggle.com\/krutarthhd\/simple-credit-card-fraud-detection-95-accuracy\n\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Dropout,Dense,Flatten,Conv1D\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow import keras\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\n\npath = '\/kaggle\/input\/stock-market-prediction\/'\npathOutput = '.\/'\ncompletoTrain='dataset_train_validation.csv'\ncompletoTest='dataset_test.csv'\n\n# INPUT\ndf = pd.read_csv(os.path.join(path, completoTrain))\ndf_a_predecir = pd.read_csv(os.path.join(path, completoTest))\n\n\n####################### ELIMINACION de filas con null\ndef filter_rows_by_values(df, col, values):\n    return df[~df[col].isin(values)]\n\n#####################################################\n# Eliminaci\u00f3n de filas a null para la soluci\u00f3n \ntest = filter_rows_by_values(df_a_predecir, \"TARGET\", [\"null\"])\n\ncolumns = [col for col in df_a_predecir.columns if col not in ['TARGET']]\nsubmission = df_a_predecir[columns]\nsolucion = df_a_predecir['TARGET']\n\n\nnf = df[df.TARGET==0]\nf = df[df.TARGET==1]\n\nnf = nf.sample(12)\n\ndata = f.append(nf,ignore_index=True)\n\nX = data.drop(['TARGET'],axis=1)\ny=data['TARGET']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,stratify=y)\n\n# S\u00f3lo se dejan las features \u00fatiles para Deep Learning\nX_train=X_train.drop(columns=['company', 'market'])\nX_test=X_test.drop(columns=['company', 'market'])\nsubmission=submission.drop(columns=['company', 'market'])\n\nscaler=RobustScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\nsubmission=scaler.transform(submission)\n\ny_train=y_train.to_numpy()\ny_test=y_test.to_numpy()\n\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1],1)\nX_test=X_test.reshape(X_test.shape[0],X_test.shape[1],1)\nsubmission=submission.reshape(submission.shape[0],submission.shape[1],1)\n\n############################### Creation of DL Model\nTHRESHOLD = 0.5\nfrom keras import backend as K\ndef precision(y_true, y_pred, threshold_shift=0.5-THRESHOLD):\n\n    # just in case \n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n\n    precision = tp \/ (tp + fp)\n    return precision\n\n\ndef recall(y_true, y_pred, threshold_shift=0.5-THRESHOLD):\n\n    # just in case \n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fn = K.sum(K.round(K.clip(y_true - y_pred_bin, 0, 1)))\n\n    recall = tp \/ (tp + fn)\n    return recall\n\n\ndef fbeta(y_true, y_pred, threshold_shift=0.5-THRESHOLD):\n    beta = 2\n\n    # just in case \n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n\n    precision = tp \/ (tp + fp)\n    recall = tp \/ (tp + fn)\n\n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) \/ (beta_squared * precision + recall) \n\n\ndef model_fit(X,y,X_test,y_test):\n    callbacks = [keras.callbacks.ModelCheckpoint(\"model_at_epoch_{epoch}.h5\")]\n    class_weight={1: 1\/(np.sum(y) \/ len(y)),0:1}\n    np.random.seed(47)\n    \n    model=Sequential()\n    model.add(Conv1D(32,2,activation='relu',input_shape=X_train[0].shape))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Conv1D(64,2,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(64,activation='relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(1,activation='sigmoid'))\n\n    \n    model.compile(loss='binary_crossentropy', optimizer='adamax',metrics=['accuracy'])\n    model.fit(X, y,validation_data=(X_test,y_test), epochs=200, batch_size=50, verbose=2,class_weight = class_weight)\n    return model\n\n\nmodel=model_fit(X_train,y_train, X_test,y_test)\n\n######################################################\n\n# PRECISI\u00d3N del training\n\nprobTrain=model.predict(X_train)\n# S\u00f3lo aplicable si hay sigmoid en la \u00faltima cap\nprediccionTrain=(probTrain > 0.5).astype(\"int32\")\n\na=y_train\nb=prediccionTrain\nacc=sum(1 for x,y in zip(a,b) if (x == y and y == 1)) \/ sum(b)\nprint(\"PRECISION (TP\/(TP+FP)) FOR TRAIN DATASET: \", acc)\n\nfrom sklearn.metrics import confusion_matrix\ncm = pd.DataFrame(data= confusion_matrix(y_train, prediccionTrain, labels=[0, 1]),index=[\"NO-FRAUD\", \"FRAUD\"],\ncolumns=[\"NO_FRAUD\", \"FRAUD\"])\nimport seaborn as sns\nsns.heatmap(cm,annot=True,fmt=\"d\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_train, prediccionTrain))","48223ed9":"probPredicha=model.predict(submission)\n# S\u00f3lo aplicable si hay sigmoid en la \u00faltima cap\nprediccion=(probPredicha > 0.5).astype(\"int32\")\n\n# PRECISION independiente\na=solucion\nb=prediccion\nacc=sum(1 for x,y in zip(a,b) if (x == y and y == 1)) \/ sum(b)\nprint(\"PRECISION (TP\/(TP+FP)) FOR TEST DATASET: \", acc)\n\nprint(\"FIN\")","5b70f17b":"\n\n# **Independent prediction:**\n\n"}}