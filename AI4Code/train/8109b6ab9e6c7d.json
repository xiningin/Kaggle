{"cell_type":{"339877b4":"code","6efa5327":"code","bfe6cb84":"code","551a14c3":"code","50bba1d0":"code","9ac983c5":"code","9d4f827f":"code","317eeb31":"code","a10a3017":"code","81da091d":"code","a5c98c4d":"code","3ff09f6e":"code","b9989c2a":"code","b8f9af7f":"code","9fc5713d":"code","cae8c773":"code","402cadbb":"code","bf8ca650":"code","fd714341":"code","af92182e":"code","7c927e7e":"code","55374288":"code","91fe7cb1":"code","d3e902c3":"code","ef7dbd9c":"code","5a42c2c9":"code","68c41ad0":"code","8c1619a7":"code","5b8bea95":"markdown","215972e6":"markdown","53986cc3":"markdown","f3e92c30":"markdown","52a0a423":"markdown","dcd6ed17":"markdown","c589e3b9":"markdown","77105ce9":"markdown","af4e922a":"markdown","1097a3ca":"markdown","88f929ca":"markdown","689be92f":"markdown","4c308df3":"markdown","4a04c2e1":"markdown","f95ad456":"markdown","b81e3589":"markdown","4692dc70":"markdown"},"source":{"339877b4":"import numpy as np\nimport os\nfrom math import ceil\nimport glob\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom skimage.util.shape import view_as_blocks\nfrom skimage import io, transform\nfrom sklearn.model_selection import train_test_split, KFold\nfrom keras.utils.vis_utils import plot_model\nfrom keras import layers, models, optimizers\nfrom keras.initializers import he_normal, lecun_normal\nfrom keras import backend as K\nimport keras\nimport warnings\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom tqdm import tqdm_notebook as tqdm\n\n\nwarnings.filterwarnings('ignore')","6efa5327":"TESTING=False\n\nSQUARE_SIZE = 40#must be less than 400\/8==50\ntrain_size = 3000\ntest_size = 500\nBATCH_SIZE= 128\nSEED=2019\nEpoch=100\nk_folds=5\nPATIENCE=5\nif TESTING:\n    train_size=2000\n    test_size=100\n    BATCH_SIZE=64\n    SEED=SEED\n    Epoch=2\n    k_folds=3\n    PATIENCE=2","bfe6cb84":"random.seed(SEED)\nfrom numpy.random import seed\nseed(SEED)\nfrom tensorflow import set_random_seed\nset_random_seed(SEED)","551a14c3":"DATA_PATH='..\/input\/dataset'\nTRAIN_IMAGE_PATH=os.path.join(DATA_PATH, 'train')\nTEST_IMAGE_PATH=os.path.join(DATA_PATH, 'test')","50bba1d0":"def get_image_filenames(image_path, image_type):\n    if(os.path.exists(image_path)):\n        return glob.glob(os.path.join(image_path, '*.'+image_type))\n    return","9ac983c5":"train = get_image_filenames(TRAIN_IMAGE_PATH, \"jpeg\")#train \uc774\ubbf8\uc9c0 \uc774\ub984 \ub9ac\uc2a4\ud2b8\ntest = get_image_filenames(TEST_IMAGE_PATH, \"jpeg\")#test \uc774\ubbf8\uc9c0 \uc774\ub984 \ub9ac\uc2a4\ud2b8\n\nrandom.shuffle(train)\nrandom.shuffle(test)\n\ntrain = train[:train_size]\ntest = test[:test_size]\n\npiece_symbols = 'prbnkqPRBNKQ'","9d4f827f":"def fen_from_filename(filename):\n  base = os.path.basename(filename)\n  return os.path.splitext(base)[0]","317eeb31":"print(fen_from_filename(train[0]))\nprint(fen_from_filename(train[1]))\nprint(fen_from_filename(test[2]))","a10a3017":"f, axarr = plt.subplots(1,3, figsize=(120, 120))\n\nfor i in range(0,3):\n    axarr[i].set_title(fen_from_filename(train[i]), fontsize=70, pad=30)\n    axarr[i].imshow(mpimg.imread(train[i]))\n    axarr[i].axis('off')","81da091d":"def onehot_from_fen(fen):\n    eye = np.eye(13)\n    output = np.empty((0, 13))\n    fen = re.sub('[-]', '', fen)\n\n    for char in fen:\n        if(char in '12345678'):\n            output = np.append(output, np.tile(eye[12], (int(char), 1)), axis=0)\n        else:\n            idx = piece_symbols.index(char)\n            output = np.append(output, eye[idx].reshape((1, 13)), axis=0)\n\n    return output\n\ndef fen_from_onehot(one_hot):\n    output = ''\n    for j in range(8):\n        for i in range(8):\n            if(one_hot[j][i] == 12):\n                output += ' '\n            else:\n                output += piece_symbols[one_hot[j][i]]\n        if(j != 7):\n            output += '-'\n\n    for i in range(8, 0, -1):\n        output = output.replace(' ' * i, str(i))\n\n    return output","a5c98c4d":"def process_image(img):\n    downsample_size = SQUARE_SIZE*8\n    square_size = SQUARE_SIZE\n    img_read = io.imread(img)\n    img_read = transform.resize(img_read, (downsample_size, downsample_size), mode='constant')\n    tiles = view_as_blocks(img_read, block_shape=(square_size, square_size, 3))\n    tiles = tiles.squeeze(axis=2)\n    return tiles.reshape(64, square_size, square_size, 3)","3ff09f6e":"def train_gen(features, batch_size):\n    i=0\n    while True:\n        batch_x=[]\n        batch_y=[]\n        for b in range(batch_size):\n            if i==len(features):\n                i=0\n                random.shuffle(features)\n            img=str(features[i])\n            y = onehot_from_fen(fen_from_filename(img))\n            x = process_image(img)\n            for x_part in x:\n                batch_x.append(x_part)\n            for y_part in y:\n                batch_y.append(y_part)\n            i+=1\n        yield (np.array(batch_x), np.array(batch_y))\n\ndef pred_gen(features, batch_size):\n    for i, img in enumerate(features):\n        yield process_image(img)","b9989c2a":"#def train_gen(features, batch_size):\n#    x_batch=[]\n#    y_batch=[]\n#    cnt=0\n#    while True:\n#        for i, img in enumerate(features):\n#            y_batch += onehot_from_fen(fen_from_filename(img))\n#            x_batch += process_image(img)\n#        yield (np.array(x_batch), np.array(y_batch))\n#\n#def pred_gen(features, batch_size):\n#    for i, img in enumerate(features):\n#        yield process_image(img)","b8f9af7f":"def get_callbacks(model_name, patient):\n    ES = EarlyStopping(\n        monitor='val_loss', \n        patience=patient, \n        mode='min', \n        verbose=1)\n    RR = ReduceLROnPlateau(\n        monitor = 'val_loss', \n        factor = 0.5, \n        patience = patient \/ 2, \n        min_lr=0.000001, \n        verbose=1, \n        mode='min')\n    MC = ModelCheckpoint(\n        filepath=model_name, \n        monitor='val_loss', \n        verbose=1, \n        save_best_only=True, \n        mode='min')\n\n    return [ES, RR, MC]","9fc5713d":"def weighted_categorical_crossentropy(weights):\n    \"\"\"\n    A weighted version of keras.objectives.categorical_crossentropy\n    \n    Variables:\n        weights: numpy array of shape (C,) where C is the number of classes\n    \n    Usage:\n        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n        loss = weighted_categorical_crossentropy(weights)\n        model.compile(loss=loss,optimizer='adam')\n    \"\"\"\n    \n    weights = K.variable(weights)\n        \n    def loss(y_true, y_pred):\n        # scale predictions so that the class probas of each sample sum to 1\n        y_pred \/= K.sum(y_pred, axis=-1, keepdims=True)\n        # clip to prevent NaN's and Inf's\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n        # calc\n        loss = y_true * K.log(y_pred) * weights\n        loss = -K.sum(loss, -1)\n        return loss\n    \n    return loss","cae8c773":"def get_model(image_size):#(model_name, image_size)\n    model = models.Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(image_size, image_size, 3)))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(128, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(13, activation='softmax', kernel_initializer='lecun_normal'))\n    \n#    model.summary()\n    \n    weights=np.array([1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(64-10)])\n    model.compile(loss=weighted_categorical_crossentropy(weights), optimizer='nadam', metrics=['acc'])#weight the inverse of expected pieces\n    \n    return model","402cadbb":"#model=get_model(DenseNet121, SQUARE_SIZE)\n#model=get_model(SQUARE_SIZE)","bf8ca650":"#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","fd714341":"kf = KFold(n_splits=k_folds, random_state=SEED)","af92182e":"j = 1\nmodel_names=[]\nfor (train_fold, valid_fold) in kf.split(train):\n    print(\"=========================================\")\n    print(\"====== K Fold Validation step => %d\/%d =======\" % (j,k_folds))\n    print(\"=========================================\")\n    \n    model_name = '..\/'+ str(j) + '.hdf5'\n    model_names.append(model_name)\n    model=get_model(SQUARE_SIZE)\n    \n    history=model.fit_generator(train_gen([train[i] for i in tqdm(train_fold)], batch_size=BATCH_SIZE), steps_per_epoch=ceil(train_size*(1-1\/k_folds)\/BATCH_SIZE), epochs=Epoch, validation_data=train_gen([train[i] for i in tqdm(valid_fold)], batch_size=BATCH_SIZE), validation_steps=ceil(train_size\/k_folds\/BATCH_SIZE), verbose=1, shuffle=False, callbacks=get_callbacks(model_name, PATIENCE))\n    j+=1#single batch is actually 64*batch_size, since there are 64 pieces on the board","7c927e7e":"for name in tqdm(model_names):\n    res = (\n      (keras.models.load_model(name, custom_objects={'loss':weighted_categorical_crossentropy(np.array([1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(64-10)]))})).predict_generator(pred_gen(test, 64), steps=test_size)\n      .argmax(axis=1)\n      .reshape(-1, 8, 8)\n    )\n    pred_fens = np.array([fen_from_onehot(one_hot) for one_hot in res])\n    test_fens = np.array([fen_from_filename(fn) for fn in test])\n    \n    final_accuracy = (pred_fens == test_fens).astype(float).mean()\n    \n    print(\"Model Name: \", name, \"Final Accuracy: {:1.5f}%\".format(final_accuracy))","55374288":"def load_all_models(names):\n    models=[]\n    for model_name in names:\n        models.append(keras.models.load_model(model_name, custom_objects={'loss':weighted_categorical_crossentropy(np.array([1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(0.30*4), 1\/(0.20*4), 1\/(0.20*4), 1\/(0.20*4), 1\/1,  1\/(0.10*4), 1\/(64-10)]))}))\n    return models","91fe7cb1":"def get_stacked_model(models):\n    input_layer=keras.layers.Input(shape=(SQUARE_SIZE, SQUARE_SIZE, 3,))\n    xs=[model(input_layer) for model in models]\n    out=keras.layers.Add()(xs)\n    \n    model=keras.models.Model(inputs=[input_layer], outputs=out)\n    return model","d3e902c3":"model=get_stacked_model(load_all_models(model_names))","ef7dbd9c":"res_stacked = (\n  model.predict_generator(pred_gen(test, 64), steps=test_size)\n  .argmax(axis=1)\n  .reshape(-1, 8, 8)\n)","5a42c2c9":"pred_fens = np.array([fen_from_onehot(one_hot) for one_hot in res_stacked])\ntest_fens = np.array([fen_from_filename(fn) for fn in test])\n\nfinal_accuracy = (pred_fens == test_fens).astype(float).mean()\n\nprint(\"Final Accuracy: {:1.5f}%\".format(final_accuracy))","68c41ad0":"def display_with_predicted_fen(image):\n    pred = model.predict(process_image(image)).argmax(axis=1).reshape(-1, 8, 8)\n    fen = fen_from_onehot(pred[0])\n    imgplot = plt.imshow(mpimg.imread(image))\n    plt.axis('off')\n    plt.title(fen)\n    plt.show()","8c1619a7":"display_with_predicted_fen(test[0])\ndisplay_with_predicted_fen(test[1])\ndisplay_with_predicted_fen(test[2])","5b8bea95":"### Define Custom loss (weighted categorical crossentropy):","215972e6":"### Data Import","53986cc3":"### Define a model:","f3e92c30":"#### Examples:","52a0a423":"### Functions to convert FEN to one-hot encoded vectors and vice-versa","dcd6ed17":"### Functions for sampling batches for training and evaluation:","c589e3b9":"### Function to extract FEN from filename","77105ce9":"### Calculating the accuracy of each model:","af4e922a":"### Testing the model:","1097a3ca":"### Stacking the models from KFold","88f929ca":"### Parameters","689be92f":"### Plotting samples","4c308df3":"### Train the model:","4a04c2e1":"#### Function to proccess an image:\n-  downsample an image to 200 by 200 pixel\n-  split an image of the chess board to 64 images of individual squares\n-  drop redundant dimensions, reshape","f95ad456":"### Callbacks","b81e3589":"### Sample images and display predicted FEN ","4692dc70":"**Acknowledgement**\n\nThis is a slightly enhanced version \nbased on https:\/\/www.kaggle.com\/koryakinp\/chess-fen-generator .\n\nMost of the credit should go to the original version's owner.\n> (I do not know the appropriate way to notify this, if anyone has any idea, leave it as a comment please)"}}