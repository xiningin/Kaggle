{"cell_type":{"14d6155b":"code","6293a565":"code","08b826ff":"code","2adb06ce":"code","37f2bec5":"code","4a5799bd":"code","2561d726":"code","73be25e2":"code","35dfa887":"code","34a43c77":"code","54596538":"code","a7d3948c":"code","a1aed3f9":"code","9036d3d6":"code","26a18f7f":"code","e975a98c":"code","9d8d9bbb":"code","d9024fce":"code","dd9f4565":"code","7aec9d40":"code","4d2e18dd":"code","0286fbfb":"code","0f7dbabe":"code","c44cfd03":"code","2cadd345":"markdown","5641cd4d":"markdown","3002f755":"markdown"},"source":{"14d6155b":"import numpy as np\nimport pandas as pd\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport glob\n# from sklearn import cluster\nimport cv2","6293a565":"# glob.glob('\/kaggle\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full_2\/youtube_faces_with_keypoints_full_2\/*')","08b826ff":"videoDF = pd.read_csv('..\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full.csv')\nvideoDF.head()","2adb06ce":"print('Number of Videos is %d' %(videoDF.shape[0]))\nprint('Number of Unique Individuals is %d' %(len(videoDF['personName'].unique())))","37f2bec5":"# create a dictionary that maps videoIDs to full file paths\nnpzFilesFullPath = glob.glob('..\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full_1\/youtube_faces_with_keypoints_full_1\/*.npz')\nnpzFilesFullPath=np.append(npzFilesFullPath,glob.glob('..\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full_2\/youtube_faces_with_keypoints_full_2\/*.npz'))\nnpzFilesFullPath=np.append(npzFilesFullPath,glob.glob('..\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full_3\/youtube_faces_with_keypoints_full_3\/*.npz'))\nnpzFilesFullPath=np.append(npzFilesFullPath,glob.glob('..\/input\/youtube-faces-with-facial-keypoints\/youtube_faces_with_keypoints_full_4\/youtube_faces_with_keypoints_full_4\/*.npz'))\n\nprint(npzFilesFullPath[0])\nvideoIDs = [x.split('\/')[-1].split('.')[0] for x in npzFilesFullPath]\nfullPaths = {}\nfor videoID, fullPath in zip(videoIDs, npzFilesFullPath):\n    fullPaths[videoID] = fullPath\n\nvideoDF = videoDF.loc[videoDF.loc[:,'videoID'].isin(fullPaths.keys()),:].reset_index(drop=True)\nprint('Number of Videos is %d' %(videoDF.shape[0]))\nprint('Number of Unique Individuals is %d' %(len(videoDF['personName'].unique())))","4a5799bd":"videoDF.head()","2561d726":"# show several frames from each video and overlay 2D keypoints\nnp.random.seed(0)\nnumVideos = 4\nframesToShowFromVideo = np.array([0.1,0.3,0.6,0.9])\nnumFramesPerVideo = len(framesToShowFromVideo)\n\n# select a random subset of 'numVideos' from the available videos\nrandVideoIDs = videoDF.loc[np.random.choice(videoDF.index,size=numVideos,replace=False),'videoID']\n# print(listOfAllConnectedPoints.shape)\nfig, axArray = plt.subplots(nrows=numVideos,ncols=numFramesPerVideo,figsize=(14,18))\nfor i, videoID in enumerate(randVideoIDs):\n    # load video\n    videoFile = np.load(fullPaths[videoID])\n    colorImages = videoFile['colorImages']\n    boundingBox = videoFile['boundingBox']\n    landmarks2D = videoFile['landmarks2D']\n\n    selectedFrames = (framesToShowFromVideo*(colorImages.shape[3]-1)).astype(int)\n    for j, frameInd in enumerate(selectedFrames):\n        axArray[i][j].imshow(colorImages[:,:,:,frameInd])\n        axArray[i][j].scatter(x=landmarks2D[:,0,frameInd],y=landmarks2D[:,1,frameInd],s=5,c='b')\n        axArray[i][j].set_title('\"%s\" (t=%d)' %(videoID,frameInd), fontsize=12)\n        axArray[i][j].set_axis_off()","73be25e2":"len(videoDF['videoID'])","35dfa887":"#selecting first frame of each person\nimages=[]\nimg_size=90\nfor i, videoID in enumerate(videoDF['videoID']):\n    if (i%500)==0:\n        print(i*10, ' images saved')\n    videoFile = np.load(fullPaths[videoID])\n    colorImages = videoFile['colorImages']\n    landmarks = videoFile['landmarks2D']\n    images.append(cv2.resize(colorImages[:,:,:,0],(img_size,img_size))\/255)","34a43c77":"images=np.array(images)","54596538":"key_pts=[]\nfor i, videoID in enumerate(videoDF['videoID']):\n    if (i%500)==0:\n        print(i)\n    videoFile = np.load(fullPaths[videoID])\n    org_h,org_w=videoFile['colorImages'][:,:,:,0].shape[:2]\n    scale_h,scale_w=img_size\/org_h,img_size\/org_w\n    landmarks = videoFile['landmarks2D']\n    keyPts=landmarks[:,:,0]\n    keyPts[:,0]=keyPts[:,0]*scale_w\n    keyPts[:,1]=keyPts[:,1]*scale_h\n    key_pts.append(keyPts)","a7d3948c":"keypts=np.array(key_pts)","a1aed3f9":"fig,ax=plt.subplots(nrows=1,ncols=4,figsize=(15,15))\nfor i in range(4):\n    ax[i].imshow(images[i])\n    ax[i].scatter(keypts[i,:,0],keypts[i,:,1],s=5)","9036d3d6":"# img_size=90\ny_data=keypts.reshape(keypts.shape[0],-1)\ny_train = np.reshape( y_data , ( -1 , 1 , 1 , 136 ))\/img_size","26a18f7f":"fig,ax=plt.subplots(nrows=1,ncols=4,figsize=(15,15))\nfor i in range(4):\n    ax[i].imshow(images[i])\n    x=np.reshape(y_train[i,:,:,np.arange(0,136,2)],(68))*img_size\n    y=np.reshape(y_train[i,:,:,np.arange(1,136,2)],(68))*img_size\n    ax[i].scatter(x,y,s=5)","e975a98c":"y_train.shape","9d8d9bbb":"import tensorflow\nfrom tensorflow import keras","d9024fce":"model_layers=[\n    keras.layers.Conv2D( 256, input_shape=( img_size , img_size , 3 ) , kernel_size=( 5 , 5 ) , strides=1 , activation='relu',name=\"input_layer\"),\n    keras.layers.Conv2D( 256 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 256, kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n    keras.layers.Conv2D( 256, kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 200, kernel_size=( 5 , 5 ) , strides=2 , activation='relu'),\n    keras.layers.Conv2D( 200 , kernel_size=( 5 , 5 ) , strides= 1, activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 200, kernel_size=( 5 , 5 ) , strides=1 , activation='relu'),\n    keras.layers.Conv2D( 200 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' ),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 170, kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n    keras.layers.Conv2D( 170, kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=1 , activation='relu'),\n    keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=2 , activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    \n    keras.layers.Conv2D( 136, kernel_size=( 3 , 3 ) , strides=2 , activation='relu'),\n    keras.layers.Conv2D( 136 , kernel_size=( 3 , 3 ) , strides=1 , activation='sigmoid'),\n\n    \n]\nmodel=keras.Sequential(model_layers)\nmodel.compile( loss= keras.losses.mean_squared_error , optimizer= keras.optimizers.Adam( lr=0.001 ) )\nmodel.summary()","dd9f4565":"train=model.fit(images,y_train,epochs=3,batch_size=32)","7aec9d40":"m=keras.models.load_model('model.pb')","4d2e18dd":"test_images=[]\ntest_bbox=[]\nfor i, videoID in enumerate(videoDF['videoID']):\n    if i==30:\n        break\n    videoFile = np.load(fullPaths[videoID])\n    colorImages = videoFile['colorImages']\n    bbox=videoFile['boundingBox']\n    org_h,org_w=colorImages[:,:,:,0].shape[:2]\n    scale_h,scale_w=img_size\/org_h,img_size\/org_w\n    \n    box=bbox[:,:,-1]\n    box[:,0]=box[:,0]*scale_w\n    box[:,1]=box[:,1]*scale_h\n    test_bbox.append(box)\n    test_images.append(cv2.resize(colorImages[:,:,:,-1],(img_size,img_size))\/255)","0286fbfb":"test_bbox=np.array(test_bbox)\ntest_bbox.shape","0f7dbabe":"test_images=np.array(test_images)\ntest_keypts=np.array(test_keyPts)\nfig,ax=plt.subplots(nrows=1,ncols=4,figsize=(15,15))\nfor i in range(4):\n    ax[i].imshow(test_images[i])\n    ax[i].scatter(test_bbox[i,:,0],test_bbox[i,:,1],s=5)","c44cfd03":"fig,ax = plt.subplots(6,5,figsize=(20,20))\n\nfor i in range(1,30):\n    r=i\/\/5\n    c=i%5\n    sample_image = test_images[i]\n    pred = m.predict( test_images[ i : i +1  ] ) \n    x=np.reshape(pred[:,:,:,np.arange(0,136,2)],(68))*img_size\n    y=np.reshape(pred[:,:,:,np.arange(1,136,2)],(68))*img_size\n    ax[r][c].imshow(sample_image)\n    ax[r][c].scatter( x,y, c='yellow',s=6)\n","2cadd345":"# Preparing test dataset","5641cd4d":"# Preparing Dataset","3002f755":"# Model(CNN)"}}