{"cell_type":{"7fb15911":"code","20fc0506":"code","eb9ce09f":"code","7a635175":"code","84cb1e43":"code","67806264":"code","d1885a5b":"code","6928d6ae":"code","1574368a":"code","1304b4e8":"code","e9ed10cd":"code","b248deac":"code","823b46e2":"code","3a273264":"code","0c702b35":"code","56e06f46":"code","30b27524":"code","9017a58d":"code","c13c4950":"markdown","237ad369":"markdown","8610917e":"markdown","88d06f81":"markdown","774ef597":"markdown","2e9317a3":"markdown","0f69b095":"markdown","2fe190d9":"markdown","c8172ffa":"markdown","0be26a82":"markdown","7de1b619":"markdown","c6c9f384":"markdown","7f56d653":"markdown","e407e4c6":"markdown","fed3e95c":"markdown","08eb2ae9":"markdown"},"source":{"7fb15911":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\n#Setting Style for Plotting\nplt.style.use('fivethirtyeight')","20fc0506":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","eb9ce09f":"df.shape","7a635175":"df.info()","84cb1e43":"df.describe()","67806264":"df.quality.unique()","d1885a5b":"df.quality.value_counts()","6928d6ae":"df['quality'].hist()","1574368a":"fig, ax = plt.subplots(figsize=(15,7))\nsns.heatmap(df.corr(),cmap='viridis', annot=True)","1304b4e8":"l = df.columns.values\nnumber_of_columns=12\nnumber_of_rows = len(l)-1\/number_of_columns\nplt.figure(figsize=(number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.set_style('whitegrid')\n    sns.boxplot(df[l[i]],color='green',orient='v')\n    plt.tight_layout()","e9ed10cd":"plt.figure(figsize=(2*number_of_columns,5*number_of_rows))\nfor i in range(0,len(l)):\n    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n    sns.distplot(df[l[i]],kde=True) ","b248deac":"print(\"Skewness  \\n \",df.skew())\nprint(\"\\n Kurtosis  \\n \", df.kurt())","823b46e2":"# Read and load Data\ntrain = pd.read_csv(\"..\/input\/housepricesadvancedregressiontechniquestrain\/train.csv\")\ntrain.describe()","3a273264":"#Plot Histogram for 'SalePrice'\nsns.distplot(train['SalePrice'])","0c702b35":"# Skewness and Kurtosis\nprint(\"Skewness : %f\" % train['SalePrice'].skew())\nprint(\"Kurtosis : %f\" % train['SalePrice'].kurt())","56e06f46":"target = np.log(train.SalePrice)\nprint(\"Skewness : %f\" % target.skew())\nprint(\"Kurtosis : %f\" % target.kurt())","30b27524":"train = train[train['GarageArea'] < 1200]\n","9017a58d":"# Histogram and normal probability plot\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\n\nsns.distplot(train['SalePrice'], fit = norm)\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'],plot = plt)","c13c4950":"# Finding Outliers\n\nFocusing on outliers, defined by Gladwell as people who do not fit into our normal understanding of achievement. Outliers deals with exceptional people, especially those who are smart, rich, and successful, and those who operate at the extreme outer edge of what is statistically plausible. An outlier is a data point that is distant from other similar points. They may be due to variability in the measurement or may indicate experimental errors. If possible, outliers should be excluded from the data set. We'll do a quick analysis through the standard deviation of 'SalePrice' and a set of scatter plots.","237ad369":"# Skewness and Kurtosis on House Price Prediction\n","8610917e":"Please Upvote, Share and Comment to show your Support and Appreciation. Thanks for all the support.","88d06f81":"The describe() function in pandas is very handy in getting various summary statistics.This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data.\n\nThere is notably a large difference between 75th %tile and max values of predictors \u201cresidual sugar\u201d,\u201dfree sulfur dioxide\u201d,\u201dtotal sulfur dioxide\u201d.\nThus observation suggests that there are extreme values-Outliers in our data set.\n","774ef597":"# How can you visually discover Correlation between features ?\n\nTo use linear regression for modelling,its necessary to remove correlated variables to improve your model. One can find correlations using pandas \u201c.corr()\u201d function and can visualize the correlation matrix using a heatmap in seaborn.\n\nDark shades represents positive correlation while lighter shades represents negative correlation.\nIf you set annot=True, you\u2019ll get values by which features are correlated to each other in grid-cells.\n\n1). Here we can infer that \u201cdensity\u201d has strong positive correlation with \u201cresidual sugar\u201d whereas it has strong negative correlation with \u201calcohol\u201d.\n\n2). \u201cfree sulphur dioxide\u201d and \u201ccitric acid\u201d has almost no correlation with \u201cquality\u201d.\n\nSince correlation is zero we can infer there is no linear relationship between these two predictors (\u201cfree sulphur dioxide\u201d and \u201ccitric acid\u201d).However it is safe to drop these features in case you\u2019re applying Linear Regression model to the dataset.","2e9317a3":"Find total number of rows and columns in the dataset using shape ","0f69b095":"It is also a good practice to know the columns and their corresponding data types, along with finding whether they contain null values or not.","2fe190d9":"\nThis tells us vote count of each quality score in descending order.\u201cquality\u201d has most values concentrated in the categories 5, 6 and 7.\nOnly a few observations made for the categories 3 and 8.","c8172ffa":"# How can we find Distribution-Skewness in a given Feature Space ?\n\nAccording to Wikipedia,\u201d In\u00a0probability theory\u00a0and\u00a0statistics,\u00a0skewness\u00a0is a measure of the asymmetry of the\u00a0probability distribution\u00a0of a\u00a0real-valued\u00a0random variable\u00a0about its mean.\u201d","0be26a82":"# Descriptive Statistics\n\nDescriptive statistics can give you great insight into the shape of each attribute.\n\nOften you can create more summaries than you have time to review. The describe() function on the Pandas DataFrame lists 8 statistical properties of each attribute:\n\na). Count\n\nb). Mean\n\nc). Standard Deviation\n\nd). Minimum Value\n\ne). 25th Percentile\n\nf). 50th Percentile (Median)\n\ng). 75th Percentile\n\nh). Maximum Value\n\nThe describe() function in pandas is very handy in getting various summary statistics.This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data.","7de1b619":"To starts with,I imported necessary libraries (for this example pandas, numpy,matplotlib and seaborn) and loaded the data set.","c6c9f384":"# How will you understand Target Variable Distribution, and why is this so important ?\n\nFew key insights just by looking at dependent variable.\n\n1. Target variable\/Dependent variable is discrete and categorical in nature.\n2. \u201cquality\u201d score scale ranges from 1 to 10;where 1 being poor and 10 being the best.\n3. You can identify class imbalance which can help you understand and hopefully fix classification errors at a later stage","7f56d653":"## Most Important Exploratory Data Analysis Questions\n\n- How will you understand Target Variable Distribution, and why is this so important ?\n- How can you visually discover Correlation between features, and why is it so important ?\n- How can we identify Outliers in a given Feature Space ?\n- How can we find Distribution-Skewness in a given Feature Space ?\n\n","e407e4c6":"# Introduction\n\nExploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n\nBefore making inferences from data it is essential to examine all your variables.\nWhy?\n\n1). To listen to the data\n\n2). To catch errors, anomalies\n\n3). To see patterns in the data\n\n4). To find violations of statistical assumptions\n\n5). To generate hypotheses\n\nExploratory data analysis involves a number of processes or activities including :-\n\n1). Generating and analyzing descriptive statistics for each of the features\n\n2). Checking correlations\n\n3). Checking outliers\n\n4). Analyzing target variables\n\n5). Finding errors and anomalies in the features","fed3e95c":"# How can we identify Outliers in a given Feature Space ?\n\nThis is a commonly overlooked mistake we tend to make. The temptation is to start building models on the data you\u2019ve been given. But that\u2019s essentially setting yourself up for failure.\n\nData exploration consists of many things, such as variable identification, treating missing values, feature engineering, etc. Detecting and treating outliers is also a major cog in the data exploration stage. The quality of your inputs decide the quality of your output!\n","08eb2ae9":"## Loading Data and Initial Exploration to Understand Data"}}