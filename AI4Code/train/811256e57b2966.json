{"cell_type":{"40d67c1a":"code","adb487c4":"code","241565da":"code","ec58b283":"code","1277e198":"code","00483d7f":"code","b07d84a1":"code","021df8f9":"code","e07ed87b":"code","072e25ce":"code","dabc538c":"code","82a0634b":"markdown","40c7a99a":"markdown","c774cffc":"markdown","d98ceea6":"markdown","7b3e6ed0":"markdown","8d49a4e6":"markdown","c730fb38":"markdown","77fdbf93":"markdown","6501a66b":"markdown","671912f1":"markdown"},"source":{"40d67c1a":"import os\nimport subprocess\nimport custom_preprocess\nfrom IPython.display import Image, display","adb487c4":"%%bash\n\ncd \/kaggle\/working\ngit clone https:\/\/github.com\/microsoft\/unilm.git\ncd unilm\/layoutlm\npip install .","241565da":"os.chdir('\/kaggle\/working\/unilm\/layoutlm\/examples\/seq_labeling')\nsubprocess.run('.\/preprocess.sh') ","ec58b283":"%%bash\n\nls data\necho \"\"\ncat data\/labels.txt","1277e198":"! python run_seq_labeling.py  --data_dir data \\\n                            --model_type layoutlm \\\n                            --model_name_or_path \/kaggle\/input\/layoutlm\/layoutlm-base-uncased \\\n                            --do_lower_case \\\n                            --max_seq_length 512 \\\n                            --do_train \\\n                            --num_train_epochs 60 \\\n                            --logging_steps 10 \\\n                            --save_steps -1 \\\n                            --overwrite_output_dir \\\n                            --output_dir output \\\n                            --labels data\/labels.txt \\\n                            --per_gpu_train_batch_size 16 \\\n                            --per_gpu_eval_batch_size 16 \\\n                            --seed 12","00483d7f":"!python run_seq_labeling.py  --do_eval \\\n                            --data_dir data \\\n                            --model_type layoutlm \\\n                            --model_name_or_path output \\\n                            --do_lower_case \\\n                            --output_dir output \\\n                            --labels data\/labels.txt \\\n                            --fp16","b07d84a1":"!cat output\/eval_results.txt","021df8f9":"display(Image(filename='\/kaggle\/input\/test-image\/82252956_2958.png'))","e07ed87b":"transform=custom_preprocess.custom_img_annotation_()\nocr_df=transform.write_annoteFile('\/kaggle\/input\/test-image\/82252956_2958.png')\ntransform.convert()\ntransform.seg()","072e25ce":"!python run_seq_labeling.py  --do_predict \\\n                            --data_dir data \\\n                            --model_type layoutlm \\\n                            --model_name_or_path output \\\n                            --do_lower_case \\\n                            --output_dir output \\\n                            --labels data\/labels.txt \\\n                            --fp16","dabc538c":"!cat output\/test_predictions.txt","82a0634b":"**Prediciting the sequence labeling in new Image**","40c7a99a":"test_pridictions.txt isn't a linked output. **Hit a like if you liked the notebook.**","c774cffc":"According to github repo, \"First, we need to preprocess the JSON file into txt. We can run the preprocessing scripts funsd_preprocess.py in the scripts directory. ","d98ceea6":"Evaluating the model in FUNSD test dataset","7b3e6ed0":"# Setting up the Environment","8d49a4e6":"# Predicting in a New Image\nWe can do evaluation or inference by replacing --do_train with --do_eval or --do_predict. Inorder to prepare our custom image for the preprocessing script, Pytessaract is used.","c730fb38":"Pytessaract has done poorly to detect words, has ommitted many words and has read many words wrongly. Maybe, poor resolution might be a reason. ","77fdbf93":"Output are tagged in **BIESO format** (B-beginning, I-intermediate, E-end, S-single word\nentity and O-outside) format.","6501a66b":"# Model \n\nThe LayoutLM model has been pretrained on 11M documents using BERT uncased models (base and large) along with the token coordinates. We can use the pretrained model to label parts of other document sets with only minimal tuning.  We can use the FUNSD dataset to tune the model.","671912f1":"# Train the model with the command given in the github repo"}}