{"cell_type":{"b68ec332":"code","a919bf69":"code","f248204f":"code","7a83cd13":"code","28101874":"code","56f98772":"code","b7084778":"code","70c55d4e":"code","0a388645":"code","f820f103":"code","62d1ad9e":"code","a2410ae6":"code","ab000a06":"code","51dcff10":"code","aba4d1a0":"code","e4af0547":"code","0558e21e":"code","033f6953":"code","e5f36fa0":"code","cb850876":"code","b105bd24":"code","a5402b6e":"code","1dc59f3b":"code","17afd6e9":"code","7ec0d684":"code","5c5d6a9b":"code","8cec53e8":"code","1da7b089":"code","812e05d8":"markdown","bdf0d1dc":"markdown","965f90da":"markdown","fba2ee01":"markdown","1c4915d6":"markdown"},"source":{"b68ec332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ntrain_df = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/train.csv\", index_col = 'Id')\ntest_df = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv\", index_col = 'ForecastId')\npd.set_option('display.max_columns', 150)\npd.set_option('display.max_rows', 150)\ntrain_df.head()","a919bf69":"train_df.info()","f248204f":"test_df.head()","7a83cd13":"train_df.shape, test_df.shape","28101874":"y_train_cc = np.array(train_df['ConfirmedCases'].astype(int))\ny_train_ft = np.array(train_df['Fatalities'].astype(int))\ncols = ['ConfirmedCases', 'Fatalities']\n\nfull_df = pd.concat([train_df.drop(cols, axis=1), test_df])\nindex_split = train_df.shape[0]\nfull_df = pd.get_dummies(full_df, columns=full_df.columns)\n\nx_train = full_df[:index_split]\nx_test= full_df[index_split:]\n#x_train.shape, x_test.shape, y_train_cc.shape, y_train_ft.shape","56f98772":"#Regular Random Forest Regressor\nrf = RandomForestRegressor(n_estimators=100, n_jobs= -1, min_samples_leaf=3, random_state=17)\n\nrf.fit(x_train,y_train_cc)","b7084778":"y_pred_cc = rf.predict(x_test)\ny_pred_cc = y_pred_cc.astype(int)\ny_pred_cc[y_pred_cc <0]=0","70c55d4e":"rf_f = RandomForestRegressor(n_estimators=100, n_jobs= -1, min_samples_leaf=3, random_state=17)\n\nrf_f.fit(x_train,y_train_ft)","0a388645":"y_pred_ft = rf_f.predict(x_test)\ny_pred_ft = y_pred_ft.astype(int)\ny_pred_ft[y_pred_ft <0]=0\npredicted_df_rf = pd.DataFrame([y_pred_cc, y_pred_ft], index = ['ConfirmedCases','Fatalities'], columns= np.arange(1, y_pred_cc.shape[0] + 1)).T\npredicted_df_rf.to_csv('submission_rf.csv', index_label = \"ForecastId\")","f820f103":"from sklearn.preprocessing import LabelEncoder\n\ncols = ['ConfirmedCases', 'Fatalities']\nindex_split = train_df.shape[0]\n\nfull_df = pd.concat([train_df.drop(cols, axis=1), test_df])\nfull_df.Date = pd.to_datetime(full_df.Date)\nfull_df.Date = full_df.Date.astype('int64')\n#full_df['Date'] = full_df['Date'].apply(pd.to_datetime)\n#full_df['day_of_week'] = full_df['Date'].apply(lambda ts: ts.weekday()).astype('int')\n#full_df['month'] = full_df['Date'].apply(lambda ts: ts.month)\n#full_df['day'] = full_df['Date'].apply(lambda ts: ts.day)\n#full_df.drop(['Date', 'Province_State'],axis=1, inplace= True )\nfull_df.drop(['Province_State'],axis=1, inplace= True )\n\nle = LabelEncoder()\ndef CustomLabelEncoder(df):\n    for c in df.columns:\n        if df.dtypes[c] == object:\n            le.fit(df[c].astype(str))\n            df[c] = le.transform(df[c].astype(str))\n    return df\n\nfull_df_encoded = CustomLabelEncoder(full_df)\n\ntrain_encoded = full_df[:index_split]\ntest_encoded= full_df[index_split:]","62d1ad9e":"#from sklearn.ensemble import RandomForestClassifier\n\nrf_params = {'max_features':  [1, 2, 3], 'min_samples_leaf': [5, 10, 15, 20], 'max_depth': [8, 10, 20, 30]}\nrf = RandomForestRegressor(n_estimators=100, random_state=17, n_jobs= -1)\n#gcv = GridSearchCV(rf, rf_params, n_jobs=-1, cv=5, verbose=1)\n#gcv.fit(train_encoded,y_train_cc)","a2410ae6":"#gcv.best_params_ #for RF Classifier {'max_depth': 8, 'max_features': 1, 'min_samples_leaf': 15}\n                 #RF Regressor ","ab000a06":"rf = RandomForestRegressor(max_depth = 8, min_samples_leaf=20, random_state=17, n_estimators=100, n_jobs= -1)\n\nrf.fit(train_encoded,y_train_cc)","51dcff10":"y_pred_cc = rf.predict(test_encoded)\ny_pred_cc = y_pred_cc.astype(int)\ny_pred_cc[y_pred_cc <0]=0","aba4d1a0":"y_train_ft.shape, train_encoded.shape, test_encoded.shape","e4af0547":"#gcv.fit(train_encoded,y_train_ft)","0558e21e":"#gcv.best_params_ #RF Classifier {'max_depth': 8, 'max_features': 1, 'min_samples_leaf': 20}\n                 #RF Regressor ","033f6953":"rf = RandomForestRegressor(max_depth = 8, min_samples_leaf=20, random_state=17, n_estimators=100, n_jobs= -1)\n\nrf.fit(train_encoded,y_train_ft)","e5f36fa0":"y_pred_ft = rf.predict(test_encoded)\ny_pred_ft = y_pred_ft.astype(int)\ny_pred_ft[y_pred_ft <0] = 0","cb850876":"from sklearn.ensemble import RandomForestClassifier\n\nrfcla = RandomForestClassifier(n_estimators=100, max_samples=0.8,\n                        random_state=1)\n# We train model\nrfcla.fit(train_encoded, y_train_cc)","b105bd24":"predictions = rfcla.predict(test_encoded)","a5402b6e":"rfcla.fit(train_encoded,y_train_ft)","1dc59f3b":"predictions1 = rfcla.predict(test_encoded)","17afd6e9":"submission = pd.DataFrame({'ForecastId': test_df.index,'ConfirmedCases':predictions,'Fatalities':predictions1})\nfilename = 'submission.csv'\n\nsubmission.to_csv(filename,index=False)","7ec0d684":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\nfrom sklearn.model_selection import cross_val_score\n\ndef RMSLError(y_test, predictions):\n    return np.sqrt(mean_squared_log_error(y_test, predictions))\n    \nrmsle_score = make_scorer(RMSLError, greater_is_better=False)\ntime_split = TimeSeriesSplit(n_splits=10)\n\ncv_scores = cross_val_score(rfcla, train_encoded, y_train_cc, cv=time_split,  scoring=rmsle_score, n_jobs=2)\ncv_scores * (-1)","5c5d6a9b":"np.array([2.79932766, 2.00873436, 4.07550427, 1.90746791, 2.11054789,\n       1.32860041, 2.52991252, 2.78177521, 1.13328816, 1.39190609]).mean()","8cec53e8":"cv_scores = cross_val_score(rf, train_encoded, y_train_cc, cv=time_split,  scoring=rmsle_score, n_jobs=2)\n[cv_scores * (-1)].mean()","1da7b089":"np.array([2.56756208, 2.02996862, 6.17504173, 1.62328543, 2.08334431, \\\n 2.64283866, 1.9898001 , 3.19179292, 1.26391612, 1.83892938]).mean()","812e05d8":"Random Forest Classifier","bdf0d1dc":"Initialize the set of parameters for exhaustive search and fit to find out the optimal parameters","965f90da":"Encode the features and extract day of the week, day, and month","fba2ee01":"### Random Forest regressor using GridSearchSV\n\nThis is an ongoing notebook that gets updated.\n\n### Please upvote if you like this notebook\n\nTo find the best parameters, I perform a grid search over specified parameter values using scikit-sklearn implemented GridSearchCV. ","1c4915d6":"TimeSeriesSplit"}}