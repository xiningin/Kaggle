{"cell_type":{"01f41a18":"code","829928b8":"code","f6f1e910":"code","c94656c0":"code","d9c36b39":"code","7a3f1bbf":"code","53a58643":"code","dbe9617c":"code","e73fc148":"markdown","beb3a144":"markdown"},"source":{"01f41a18":"#import pandas as our tool of choice\nimport pandas as pd","829928b8":"# import data frame\ndf = pd.read_csv(\"..\/input\/dsm-beuth-edl-demodata-dirty.csv\")\ndf","f6f1e910":"#drop rows with NaN only. No missing values\ndf = df.dropna(how = 'all')\n\n# with out how = 'all' as an argument it would drop every row with any missing value.","c94656c0":"#now let's drop duplicates\ndf = df.drop_duplicates(subset=[\"full_name\", \"email\"])\ndf","d9c36b39":"#once again\ndf = df.dropna(how = 'all')\ndf","7a3f1bbf":"#Now we want to fix the column age\n\n#first let's ensure that everything is a number\ndf[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").fillna(0) \n#I wanted to use .filnna(\"\") for errors instead of, but then the next step couldnt be done easily.\ndf","53a58643":"#then we want to set negative numbers to positive, asuming the \"-\" was an accident.\ndf[\"age\"] = df[\"age\"].map(lambda age: int(age) if int(age) > 0 else int(age)*-1)\ndf","dbe9617c":"#Now lets erase for the E-Mail NaN values with blank spaces to avoid missunderstanding\ndf[\"email\"] = df[\"email\"].fillna('')\ndf","e73fc148":"Now the data set is a bit cleaner. As stated in between alignen the different operation in a propper order and also writing the into as small functions as possible to call parts when needed might be an approach for optimizing the cleaning process displayed in this notebook. Thinking of futzzy matching on df[\"full_name\"] to detect duplicates with typicons could be usefull as well. ","beb3a144":"It's observable we have for the dropped column again missing values so we need to drop the values again. So probably erasing duplicates could be done before dropping missing value lines. Also writing all these in functions wich can then be called might be a better way of doing so. You could write a function set of data cleaning as a toolkit and depending on the data set, suiting function could be used."}}