{"cell_type":{"b2b52451":"code","35daf9ad":"code","44743741":"code","d2b8abc2":"code","d3299c7f":"code","6e67ed48":"code","36793594":"code","1dbd59e7":"code","1130ecd2":"markdown","1377d233":"markdown","950b0353":"markdown","90be3381":"markdown","d498f632":"markdown","85952be9":"markdown"},"source":{"b2b52451":"import spacy\n\nnlp = spacy.load('en_core_web_sm')\n\nprint(nlp.pipe_names)\n\nprint(nlp.pipeline)","35daf9ad":"import spacy\n\ndef length_component(doc):\n    doc_length = len(doc)\n    print(f\"This document is {doc_length} tokens long.\")\n    return doc\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nnlp.add_pipe(length_component, first=True)\nprint(nlp.pipe_names)\n\ndoc = nlp(\"This is a sentence.\")","44743741":"import spacy\nfrom spacy.matcher import PhraseMatcher\nfrom spacy.tokens import Span\n\nnlp = spacy.load(\"en_core_web_sm\")\nanimals = [\"Golden Retriever\", \"cat\", \"trutule\", \"Rattus norvegicus\"]\nanimal_patterns = list(nlp.pipe(animals))\nprint(\"animal_patterns: \", animal_patterns)\nmatcher = PhraseMatcher(nlp.vocab)\nmatcher.add(\"ANIMAL\", None, *animal_patterns)\n\ndef animal_component(doc):\n    matches = matcher(doc)\n    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n    \n    doc.ents = spans\n    return doc\n\nnlp.add_pipe(animal_component, after=\"ner\")\nprint(nlp.pipe_names)\n\ndoc = nlp(\"I have a cat and a Golden Retriever\")\nprint([(ent.text, ent.label_) for ent in doc.ents])","d2b8abc2":"from spacy.lang.en import English\nfrom spacy.tokens import Token\n\nnlp = English()\n\nToken.set_extension(\"is_country\", default=False)\n\ndoc = nlp(\"I live in Spain.\")\ndoc[3]._.is_country = True\n\nprint([(token.text, token._.is_country) for token in doc])","d3299c7f":"from spacy.lang.en import English\nfrom spacy.tokens import Token\n\nnlp = English()\n\ndef get_reversed(token):\n    return token.text[::-1]\n\nToken.set_extension(\"reversed\", getter=get_reversed)\n\ndoc = nlp(\"All generalizations are false, including this one.\")\n\nfor token in doc:\n    print(\"reversed:\", token._.reversed)","6e67ed48":"from spacy.lang.en import English\nfrom spacy.tokens import Doc\n\nnlp = English()\n\ndef get_has_number(doc):\n    return any(token.like_num for token in doc)\n\nDoc.set_extension(\"has_number\", getter=get_has_number)\n\ndoc = nlp(\"The museum closed for five years in 2012.\")\nprint(\"has_number:\", doc._.has_number)","36793594":"from spacy.lang.en import English\nfrom spacy.tokens import Span\n\nnlp = English()\n\ndef to_html(span, tag):\n    return f\"<{tag}>{span.text}<\/{tag}>\"\n\nSpan.set_extension(\"to_html\", method=to_html)\n\ndoc = nlp(\"Hello world, this is a sentence.\")\nspan = doc[0:2]\nprint(\"to_html\", span._.to_html('strong'))","1dbd59e7":"import spacy\nfrom spacy.tokens import Span\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef get_wikipedia_url(span):\n    if span.label_ in (\"PERSON\", \"ORG\", \"GPE\", \"LOCATION\"):\n        entity_text = span.text.replace(\" \", \"_\")\n        return \"https:\/\/en.wikipedia.org\/w\/index.php?search=\"+entity_text\n    \n    \nSpan.set_extension(\"wikipedia_url\", getter=get_wikipedia_url)\n\ndoc = nlp(\n    \"In over fifty years from his very first recordings right through to his \"\n    \"last album, David Bowie was at the vanguard of contemporary culture.\"\n)\n\nfor ent in doc.ents:\n    print(ent.text, ent._.wikipedia_url)","1130ecd2":"# 2. Inspecting the Pipeline","1377d233":"# 4. Complex Components","950b0353":"# 5. Setting Extension Attributes","90be3381":"# 1. What happens when you call nlp?\n\n- Tokenize the text and apply each pipeline component in order. The tokenizer turns a string of text into a `Doc` object. spaCy then applies every component in the pipeline on document, in order.","d498f632":"# 3. Simple Components\n","85952be9":"# 6. Entities and Extensions"}}