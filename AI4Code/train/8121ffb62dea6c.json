{"cell_type":{"c07421dd":"code","0e741fb6":"code","4a1574a7":"code","0a836cbb":"code","40bcaec8":"code","9e55ef8e":"code","1d17891b":"code","b6e52d52":"code","85a7c9e8":"code","378a2c10":"code","d746c0f9":"code","8902d472":"code","ec701d8a":"code","8bfa03e3":"code","cf4ba911":"code","dcaaf789":"code","3c3951c8":"code","3ed584f8":"code","3956b850":"code","fabd1af5":"code","01da44e7":"code","66317889":"code","33a579c5":"code","a69f0714":"code","fade7f07":"code","c3b4a2fe":"code","1bfe05c8":"code","f31a7658":"code","086ee4ad":"code","49ac069a":"code","9f59ef8b":"markdown","abd24741":"markdown","b9e553d6":"markdown","b64ce16b":"markdown","10cf0983":"markdown","04cf5081":"markdown","5bdd03f5":"markdown","abaac67b":"markdown","40d99ccb":"markdown","d75e95a4":"markdown","fa91ae7c":"markdown","3fb74dec":"markdown","854fae87":"markdown"},"source":{"c07421dd":"# Common lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Utils\nfrom tqdm import tqdm\nimport datetime\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import auc, confusion_matrix, precision_recall_curve\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, AveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\nprint('Import successfully!')","0e741fb6":"# Init variables\ninput_folder = '..\/input\/coronahack-chest-xraydataset'\ntest_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'test')\ntrain_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'train')\nmetadata_df = pd.read_csv(os.path.join(input_folder, 'Chest_xray_Corona_Metadata.csv'), index_col=0)","4a1574a7":"# Split to train & test set\ntrain_df = metadata_df[metadata_df.Dataset_type == 'TRAIN'].reset_index(drop=True)\ntest_df = metadata_df[metadata_df.Dataset_type == 'TEST'].reset_index(drop=True)\n\n# Check train_df size + test_df size == metadata_df size\nassert train_df.size + test_df.size == metadata_df.size\n\nprint(f'Shape of train data: { train_df.shape }')\nprint(f'Shape of test data: { test_df.shape }')\n\ntrain_df.sample(10)","0a836cbb":"# fill na\ntrain_df.fillna('unknow', inplace=True)\ntest_df.fillna('unknow', inplace=True)","40bcaec8":"train_datagen = ImageDataGenerator(rotation_range=10,\n                              brightness_range=(0.8, 1.2),\n                              horizontal_flip=True,\n                              zoom_range=[0.75, 1])\ntest_datagen = ImageDataGenerator()","9e55ef8e":"train_df, valid_df = train_test_split(train_df, test_size=0.2, shuffle=True, random_state=42)","1d17891b":"train_batches = train_datagen.flow_from_dataframe(train_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\nvalid_batches = test_datagen.flow_from_dataframe(valid_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\ntest_batches = test_datagen.flow_from_dataframe(test_df,\n                                            directory=test_img_folder,\n                                            x_col='X_ray_image_name',\n                                            y_col='Label',\n                                            class_mode='binary',\n                                            batch_size=8,\n                                            shuffle=False)","b6e52d52":"print(f'Label encode: { train_batches.class_indices }')","85a7c9e8":"train_batches_series = pd.Series(train_batches.classes)\nvalid_batches_series = pd.Series(valid_batches.classes)\n\nprint(f'Value count in train_batches: \\n{ train_batches_series.value_counts() }')\nprint(f'Value count in valid_batches: \\n{ valid_batches_series.value_counts() }')","378a2c10":"def create_dir(dir_path):\n    if not os.path.exists(dir_path):\n        os.mkdir(dir_path)\n        \ncreate_dir('models')","d746c0f9":"resize_and_rescale = Sequential([\n    Resizing(224, 224),\n    Rescaling(1.\/255)\n])","8902d472":"metrics = [TruePositives(name='TP'),\n           TrueNegatives(name='TN'),\n           FalsePositives(name='FP'),\n           FalseNegatives(name='FN'),\n           AUC(curve='PR', name='AUC')]","ec701d8a":"pretrained_vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3), pooling='avg')","8bfa03e3":"# Preprocessing layer\nft_vgg16 = Sequential([resize_and_rescale])\n# Feature extractor layer\nft_vgg16.add(pretrained_vgg16)\n# Classifier layer\nft_vgg16.add(Dense(1, activation='sigmoid'))","cf4ba911":"# Freeze\n#for layer in ft_vgg16.layers[:3]:\n#    layer.trainable = False","dcaaf789":"model_dir = 'models\/resnet16'\nmodel_file = 'best_resnet16.hdf5'\n\ncreate_dir(model_dir)\n\ncheckpoint = ModelCheckpoint(os.path.join(model_dir, model_file),\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             save_weights_only=False)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=30,\n                               verbose=1,\n                               restore_best_weights=True)","3c3951c8":"epochs = 200\nlr = 1e-4\n\nft_vgg16.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=metrics)\n\ntraining_time_start = datetime.datetime.now()\n\nvgg16_history = ft_vgg16.fit(train_batches,\n                                epochs=epochs,\n                                verbose=2,\n                                callbacks=[checkpoint, early_stopping],\n                                validation_data=valid_batches,\n                                steps_per_epoch=len(train_batches),\n                                validation_steps=len(valid_batches))\n\ntraining_time_end = datetime.datetime.now()","3ed584f8":"total_training_seconds = (training_time_end - training_time_start).seconds\nprint('Total training time: ', str(datetime.timedelta(seconds=total_training_seconds)))","3956b850":"vgg16_hist_df = pd.DataFrame(vgg16_history.history)","fabd1af5":"vgg16_hist_df.loc[:, ['loss', 'val_loss']].plot()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","01da44e7":"vgg16_hist_df.loc[:, ['AUC', 'val_AUC']].plot()\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.show()","66317889":"num_of_epochs = vgg16_hist_df.shape[0]\nhalf_epoch = int(num_of_epochs \/ 2)\n\nfirst_half_vgg16_hist = vgg16_hist_df.loc[:half_epoch]\nfirst_title = f'Loss value at epoch 0 - { half_epoch }'\n\nlast_half_vgg16_hist = vgg16_hist_df.loc[half_epoch:len(vgg16_hist_df)]\nlast_title = f'Loss value at epoch { half_epoch } - { len(vgg16_hist_df) }'\n\nhists = [first_half_vgg16_hist, last_half_vgg16_hist]\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['loss', 'val_loss']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss value')\n    ax.set_title(titles[i])\nplt.show()","33a579c5":"first_title = f'AUC value at epoch 0 - { half_epoch }'\nlast_title = f'AUC value at epoch { half_epoch } - { len(vgg16_hist_df) }'\n\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['AUC', 'val_AUC']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('AUC value')\n    ax.set_title(titles[i])\nplt.show()","a69f0714":"evaluate_vgg16 = ft_vgg16.evaluate(test_batches, verbose=1)","fade7f07":"loss, tp, tn, fp, fn, auc = evaluate_vgg16[0], evaluate_vgg16[1], evaluate_vgg16[2], evaluate_vgg16[3], evaluate_vgg16[4], evaluate_vgg16[5]\nprint(f'Test loss: { loss }')\nprint(f'True positive: { tp }')\nprint(f'True negative: { tn }')\nprint(f'False positive: { fp }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","c3b4a2fe":"def find_optimal_threshold(precision, recall, threshold):\n    f1_score = (2 * precision * recall) \/ (precision + recall)\n    best_idx = np.argmax(f1_score)\n    best_threshold = threshold[best_idx]\n    return best_threshold, best_idx","1bfe05c8":"y_true = test_batches.classes\ny_predict = ft_vgg16.predict(test_batches)\nprecision, recall, threshold = precision_recall_curve(y_true, y_predict)\nbest_threshold, best_idx = find_optimal_threshold(precision, recall, threshold)\nprint('Best threshold: {}'.format(best_threshold))","f31a7658":"plt.figure(figsize=(7, 5))\nauc_score = auc(recall, precision)\nplt.plot([1, 0], [0, 1], linestyle='--', color='black', label='No skill')\nplt.plot(recall, precision, linewidth=3, label='ResNet18')\nplt.plot(recall[best_idx], precision[best_idx], \n         marker='o', color='black', \n         label='Best_theshold', linestyle='', markersize='7')\nplt.xlabel('Recall', size=13)\nplt.ylabel('Precision', size=13)\nplt.title('Precision-Recall curve (AUC - {:.4f})'.format(auc_score), size=15)\nplt.legend()\nplt.show()","086ee4ad":"y_predict = (y_predict >= best_threshold).astype('int')\ny_predict = np.reshape(y_predict, -1)\ncfs_matrix = confusion_matrix(y_true, y_predict)","49ac069a":"label = ['Normal', 'Pneumonia']\n\nplt.figure(figsize=(6, 5))\nplt.imshow(cfs_matrix, cmap=plt.cm.Blues)\nplt.colorbar()\nfor i in range(len(label)):\n    for j in range(len(label)):\n        plt.text(j, i, cfs_matrix[i, j],\n                 horizontalalignment='center', verticalalignment='center', size=14)\nplt.xticks(np.arange(len(label)), label)\nplt.yticks(np.arange(len(label)), label)\nplt.xlabel('Predicted label', size=13)\nplt.ylabel('True label', size=13)\nplt.title('Confusion matrix of ResNet18', size=15)\nplt.show()","9f59ef8b":"**Find the best threshold**","abd24741":"**Preprocessing layer**","b9e553d6":"## 4. Evaluate","b64ce16b":"# 2. Prepare data","10cf0983":"**Plot over half first and first last epochs**","04cf5081":"## 3. Fine tuning ","5bdd03f5":"**Plot over entire epochs**","abaac67b":"# 1. Import libs","40d99ccb":"## **Note**\n\nIn this notebook, i just prepare the data then fine tuning VGG16 to diagnosis pneumonia.\nIf you wanna see insight the dataset, please visit this notebook: \n\n-> https:\/\/www.kaggle.com\/luukhang\/build-alexnet-to-classifies-pneumonia\n\nComparing the performance of pretrained of VGG16 and ResNet18, plese visit this notebook:\n\n-> https:\/\/www.kaggle.com\/luukhang\/transfer-learning-resnet18-to-classifies-pneumonia","d75e95a4":"**Plot ROC curve**","fa91ae7c":"## 6. Predict and plot confusion matrix","3fb74dec":"## 5. Plot PR curve and find optimal threshold","854fae87":"**Initialize metric**"}}